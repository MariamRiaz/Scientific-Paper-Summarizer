8	26	For example, both Michael Jordan and Richard Sutton are researchers with very high citation counts and h-index, but they are authoritative in different topics, Jordan in the more general machine learning topic of statistical learning, and Sutton in the topic of reinforcement learning.
10	63	Fortunately, various academic publication archives contain the full contents, references, and meta-data including titles, venues, and authors.
11	15	With such data, we can build and fit a model to partition researchers’ scholarly domains into topics at a much finer-grain and discover their academic authority within each topic.
12	145	To do that, we propose a model named Latent Topical-Authority Indexing (LTAI), based on the LDA, to jointly model the topics, authors’ topical authority, and citations among the publications.
36	26	Also, in the LTAI, when there are multiple authors in a single cited publication, their contribution of forming citations with respect to different citing papers varies according to their topical authority.
63	137	Therefore, if topic distributions of paper i and j are similar and if η values of the cited paper’s authors are high, the citation formation probability increases.
64	15	On the other hand, dissimilar or topically irrelevant pair of papers with less authoritative authors on the cited paper will be assigned with low probability of citation formation.
70	15	Setting different values to the precision parameter ci←j according to xi←j induces cyclic dependencies between the two variables.
80	12	Since computing the posterior distribution of the LTAI is intractable, we use variational inference to optimize variational parameters each of which correspond to original content-related variables.
101	12	We elucidate how stochastic variational inference (Hoffman et al., 2013) is applied in our model to update global per-topic-word variational parameter λ.
136	16	Compared to other models, LDA only uses the content information.
137	31	LTAI-n%: In LTAI-n%, we remove n% of actual citations and displace them with arbitrarily selected false connections.
139	15	If the citation links are just removed, the LTAI and LTAIn% cannot be fairly compared as the density of the citation structures will be affected and each model needs different concentration values.
144	18	Thus, the performance edge of the LTAI over LTAI-SEP highlights the necessity of the LTAI’s joint modeling in which both topic and authority related variables reshape one another in an iterative fashion.
147	20	Author-Link Topic Model: ALTM (Kataria et al., 2011) is a variation of author topic model (ATM) (Rosen-Zvi et al., 2004) that models both topical interests and influence of authors in scientific corpora.
150	15	Dynamic Author-Citation Topic Model: DACTM (Kataria et al., 2011) is an extension of ALTM that requires publication corpora which preserves sentence structures.
190	55	Similar to citation prediction, we predict which author is more likely to write the cited publication based on the topic proportions of cited publication i and a set of citing publications J .
193	31	For author prediction, we choose the author that maximizes the above probability.
200	20	In the table, we observe that all authors with top h-indices have written at least 18 papers and earned at least 207 citations, which are the top 0.8% and 0.2% values respectively.
203	13	We now stress attributes of topical authority index that are different from other topic irrelevant statistics.
204	25	From Tables 3 to 5, we show four example topics extracted by our model and list notable authors within each topic with their topical authority indices, h-indices, number of citations, and number of papers.
205	14	In the tables, we first find that all four authors with highest topical authority values, Monica Lam, Alex Pentland, Michael Jordan, and Mihir Bellare are also listed in the topic-irrelevant authority rankings in Table 2.
208	104	In Table 5, Oded Goldreich has lower topical authority score for the computer security topic while having higher topic irrelevant scores than the above four researchers, because his main research filed is in the theory of computation and randomness.
210	19	Similarity, when comparing Federico Girosi and Tomaso Poggio in Table 4, the two researchers have similar authority indices for this topic while Tomaso Poggio has higher values for the other three topic-irrelevant indices.
212	18	Federico Girosi has relatively focused academic interest, with his publication history being skewed towards machine-learning-related subjects, while Tomaso Poggio has broader topical interests that include computer vision and statistical learning, while also co-authoring most of the papers that Federico Girosi wrote.
220	14	We proposed Latent Topical Authority Indexing (LTAI) to model the topical-authority of academic researchers.
224	15	On the other hand, our model combines the merits of both topic-specific and individual-specific indices to provide topical authority information for academic researchers.
227	18	Finally, we qualitatively demonstrated the interpretability by topical-authority outcomes of the LTAI from the CORA corpus.
228	154	Finally, there are issues that can be dealt with in future work.
229	86	We do not consider time information in terms of when papers are published and when pairs of papers are linked; we can use datasets that incorporate timestamps to enhance the model capability to predict future citations and authorships.

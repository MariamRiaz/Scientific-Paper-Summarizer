{"sections": [{"heading": "1. Introduction", "text": "We consider the problem of regularized empirical risk minimization (ERM) of linear predictors. Let a1, . . . , an \u2208 Rd be the feature vectors of n data samples, \u03c6i : R \u2192 R be a convex loss function associated with the linear prediction aTi x, for i = 1, . . . , n, and g : Rd \u2192 R be a convex regularization function for the predictor x \u2208 Rd. ERM amounts to solving the following convex optimization problem:\nmin x\u2208Rd\n{ P (x)\ndef = 1n \u2211n i=1 \u03c6i(a T i x) + g(x) } . (1)\nThis formulation covers many well-known classification and regression problems. For example, logistic regression is obtained by setting \u03c6i(z) = log(1 + exp(\u2212biz)) where bi \u2208 {\u00b11}. For linear regression problems, the loss\n1Department of Computer Science, The University of Chicago, Chicago, Illinois 60637, USA. 2Microsoft Research, Redmond, Washington 98052, USA. Correspondence to: Jialei Wang <jialei@uchicago.edu>, Lin Xiao <lin.xiao@microsoft.com>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nfunction is \u03c6i(z) = (1/2)(z \u2212 bi)2, and we get ridge regression with g(x) = (\u03bb/2)\u2016x\u201622 and the elastic net with g(x) = \u03bb1\u2016x\u20161 + (\u03bb2/2)\u2016x\u201622. LetA = [a1, . . . , an]T be the n by d data matrix. Throughout this paper, we make the following assumptions: Assumption 1. The functions \u03c6i, g and matrix A satisfy:\n\u2022 Each \u03c6i is \u03b4-strongly convex and 1/\u03b3-smooth where \u03b3 > 0 and \u03b4 \u2265 0, and \u03b3\u03b4 \u2264 1;\n\u2022 g is \u03bb-strongly convex where \u03bb \u2265 0; \u2022 \u03bb+ \u03b4\u00b52 > 0, where \u00b5 = \u221a \u03bbmin(ATA).\nThe strong convexity and smoothness mentioned above are with respect to the standard Euclidean norm, denoted as \u2016x\u2016 = \u221a xTx. (See, e.g., Nesterov (2004, Sections 2.1.1 and 2.1.3) for the exact definitions.) We allow \u03b4 = 0, which simply means \u03c6i is convex. Let R = maxi{\u2016ai\u2016} and assuming \u03bb > 0, then R2/(\u03b3\u03bb) is a popular definition of condition number for analyzing complexities of different algorithms. The last condition above means that the primal objective function P (x) is strongly convex, even if \u03bb = 0.\nThere have been extensive research activities in recent years on developing efficiently algorithms for solving problem (1). A broad class of randomized algorithms that exploit the finite sum structure in the ERM problem have emerged as very competitive both in terms of theoretical complexity and practical performance. They can be put into three categories: primal, dual, and primal-dual.\nPrimal randomized algorithms work with the ERM problem (1) directly. They are modern versions of randomized incremental gradient methods (e.g., Bertsekas, 2012; Nedic & Bertsekas, 2001) equipped with variance reduction techniques. Each iteration of such algorithms only process one data point ai with complexity O(d). They includes SAG (Roux et al., 2012), SAGA (Defazio et al., 2014), and SVRG (Johnson & Zhang, 2013; Xiao & Zhang, 2014), which all achieve the iteration complexity O ( (n+R2/(\u03b3\u03bb)) log(1/\u01eb) ) to find an \u01eboptimal solution. In fact, they are capable of exploiting the strong convexity from data, meaning that the condition number R2/(\u03b3\u03bb) in the complexity can be replaced by the more favorable oneR2/(\u03b3(\u03bb+\u03b4\u00b52/n)). This improvement can be achieved without explicit knowledge of \u00b5 from data.\nDual algorithms solve Fenchel dual of (1) by maximizing\nD(y) def = 1n \u2211n i=1 \u2212\u03c6\u2217i (yi)\u2212 g\u2217 ( \u2212 1n \u2211n i=1 yiai ) (2) using randomized coordinate ascent algorithms. (Here \u03c6\u2217i and g\u2217 denotes the conjugate functions of \u03c6i and g.) They include SDCA (Shalev-Shwartz & Zhang, 2013), Nesterov (2012) and Richta\u0301rik & Taka\u0301c\u030c (2014). They have the same complexity O ( (n+R2/(\u03b3\u03bb)) log(1/\u01eb) ) , but cannot exploit strong convexity, if any (when \u03b4\u00b52 > 0), from data.\nPrimal-dual algorithms solve the convex-concave saddle point problem minxmaxy L(x, y) where\nL(x, y) def= 1n \u2211n i=1 ( yi\u3008ai, x\u3009 \u2212 \u03c6\u2217i (yi) ) + g(x). (3)\nIn particular, SPDC (Zhang & Xiao, 2015) achieves an accelerated linear convergence rate with iteration complexity O ( (n+ \u221a nR/ \u221a \u03b3\u03bb) log(1/\u01eb) ) , which is better than the aforementioned non-accelerated complexity when R2/(\u03b3\u03bb) > n. Lan & Zhou (2015) developed dual-free variants of accelerated primal-dual algorithms, but without considering the linear predictor structure in ERM. Balamurugan & Bach (2016) extended SVRG and SAGA to solving saddle point problems.\nAccelerated primal and dual randomized algorithms have also been developed. Nesterov (2012), Fercoq & Richta\u0301rik (2015) and Lin et al. (2015b) developed accelerated coordinate gradient algorithms, which can be applied to solve the dual problem (2). Allen-Zhu (2016) developed an accelerated variant of SVRG. Acceleration can also be obtained using the Catalyst framework (Lin et al., 2015a). They all achieve the same O ( (n+ \u221a nR/ \u221a \u03b3\u03bb) log(1/\u01eb) ) complexity. A common feature of accelerated algorithms is that they require good estimate of the strong convexity parameter. This makes hard for them to exploit strong convexity from data because the minimum singular value \u00b5 of the data matrix A is very hard to estimate in general.\nIn this paper, we show that primal-dual algorithms are capable of exploiting strong convexity from data if the algorithm parameters (such as step sizes) are set appropriately. While these optimal setting depends on the knowledge of the convexity parameter \u00b5 from the data, we develop adaptive variants of primal-dual algorithms that can tune the parameter automatically. Such adaptive schemes rely critically on the capability of evaluating the primal-dual optimality gaps by primal-dual algorithms.\nA major disadvantage of primal-dual algorithms is that the required dual proximal mapping may not admit closedform or efficient solution. We follow the approach of Lan & Zhou (2015) to derive dual-free variants of the primal-dual algorithms customized for ERM problems with the linear predictor structure, and show that they can also exploit strong convexity from data with correct choices of parameters or using an adaptation scheme.\nAlgorithm 1 Batch Primal-Dual (BPD) Algorithm input: parameters \u03c4 , \u03c3, \u03b8, initial point (x\u0303(0) = x(0), y(0))\nfor t = 0, 1, 2, . . . do y(t+1) = prox\u03c3f\u2217 ( y(t) + \u03c3Ax\u0303(t) )\nx(t+1) = prox\u03c4g ( x(t) \u2212 \u03c4AT y(t+1) )\nx\u0303(t+1) = x(t+1) + \u03b8(x(t+1) \u2212 x(t)) end for"}, {"heading": "2. Batch primal-dual algorithms", "text": "We first study batch primal-dual algorithms, by considering a \u201cbatch\u201d version of the ERM problem (1),\nminx\u2208Rd { P (x) def = f(Ax) + g(x) } . (4)\nwhere A \u2208 Rn\u00d7d. We make the following assumptions: Assumption 2. The functions f , g and matrix A satisfy:\n\u2022 f is \u03b4-strongly convex and 1/\u03b3-smooth where \u03b3 > 0 and \u03b4 \u2265 0, and \u03b3\u03b4 \u2264 1;\n\u2022 g is \u03bb-strongly convex where \u03bb \u2265 0; \u2022 \u03bb+ \u03b4\u00b52 > 0, where \u00b5 = \u221a \u03bbmin(ATA).\nUsing conjugate functions, we can derive the dual of (4) as\nmaxy\u2208Rn { D(y) def = \u2212f\u2217(y)\u2212 g\u2217(\u2212AT y) } , (5)\nand the convex-concave saddle point formulation is\nmin x\u2208Rd max y\u2208Rn\n{ L(x, y) def= g(x) + yTAx\u2212 f\u2217(y) } . (6)\nWe consider the primal-dual first-order algorithm proposed by Chambolle & Pock (2011; 2016) for solving the saddle point problem (6), given in Algorithm 1, where prox\u03c8(\u00b7), for any convex function \u03c8 : Rn \u222a {\u221e}, is defined as\nprox\u03c8(\u03b2) = arg min \u03b1\u2208Rn\n( \u03c8(\u03b1) + (1/2)\u2016\u03b1\u2212 \u03b2\u20162 ) .\nAssuming that f is smooth and g is strongly convex, Chambolle & Pock (2011; 2016) showed that Algorithm 1 achieves accelerated linear convergence rate if \u03bb > 0. However, they did not consider the case where additional or the sole source of strong convexity comes from f(Ax). In the following theorem, we show how to set the parameters \u03c4 , \u03c3 and \u03b8 to exploit both sources of strong convexity to achieve fast linear convergence.\nTheorem 1. Suppose Assumption 2 holds and (x\u22c6, y\u22c6) is the unique saddle point of L defined in (6). Let L = \u2016A\u2016 =\u221a \u03bbmax(ATA). If we set the parameters in Algorithm 1 as\n\u03c3 = 1L\n\u221a \u03bb+\u03b4\u00b52\n\u03b3 , \u03c4 = 1 L\n\u221a \u03b3\n\u03bb+\u03b4\u00b52 , (7)\nand \u03b8 = max{\u03b8x, \u03b8y} where\n\u03b8x = ( 1\u2212 \u03b4(\u03b4+2\u03c3) \u00b52 L2 ) 1 1+\u03c4\u03bb , \u03b8y = 1 1+\u03c3\u03b3/2 , (8)\nthen we have (\n1 2\u03c4 + \u03bb 2 ) \u2016x(t) \u2212 x\u22c6\u20162 + \u03b34 \u2016y(t) \u2212 y\u22c6\u20162 \u2264 \u03b8tC,\nL(x(t), y\u22c6)\u2212 L(x\u22c6, y(t)) \u2264 \u03b8tC,\nwhereC = (\n1 2\u03c4 + \u03bb 2\n) \u2016x(0)\u2212x\u22c6\u20162+ ( 1 2\u03c3+ \u03b3 4 ) \u2016y(0)\u2212y\u22c6\u20162.\nThe proof of Theorem 1 is given in Appendices B and C. Here we give a detailed analysis of the convergence rate. Substituting \u03c3 and \u03c4 in (7) into the expressions for \u03b8y and \u03b8x in (8), and assuming \u03b3(\u03bb+ \u03b4\u00b52) \u226a L2, we have\n\u03b8x \u2248 1\u2212 \u03b3\u03b4\u00b5 2\nL2\n( 2 \u221a \u03b3(\u03bb+\u03b4\u00b52) L + \u03b3\u03b4 )\u22121 \u2212 \u03bbL \u221a \u03b3 \u03bb+\u03b4\u00b52 ,\n\u03b8y = 1 1+ \u221a \u03b3(\u03bb+\u03b4\u00b52)/(2L)\n\u2248 1\u2212 \u221a \u03b3(\u03bb+\u03b4\u00b52)\n2L .\nSince the overall condition number of the problem is L2 \u03b3(\u03bb+\u03b4\u00b52) , it is clear that \u03b8y is an accelerated convergence rate. Next we examine \u03b8x in two special cases.\nThe case of \u03b4\u00b52 = 0 but \u03bb > 0. In this case, we have \u03c4 = 1L \u221a \u03b3 \u03bb and \u03c3 = 1 L \u221a \u03bb \u03b3 , and thus\n\u03b8x= 1 1+ \u221a \u03b3\u03bb/L \u2248 1\u2212 \u221a \u03b3\u03bb L , \u03b8y= 1 1+ \u221a \u03b3\u03bb/(2L) \u2248 1\u2212 \u221a \u03b3\u03bb 2L . Therefore we have \u03b8 = max{\u03b8x, \u03b8y} \u2248 1 \u2212 \u221a \u03bb\u03b3 2L . This indeed is an accelerated convergence rate, recovering the result of Chambolle & Pock (2011; 2016).\nThe case of \u03bb = 0 but \u03b4\u00b52 > 0. In this case, we have \u03c4 = 1L\u00b5 \u221a \u03b3 \u03b4 and \u03c3 = \u00b5 L \u221a \u03b4 \u03b3 , and\n\u03b8x = 1\u2212 \u03b3\u03b4\u00b5 2 L2 \u00b7 12\u221a\u03b3\u03b4\u00b5/L+\u03b3\u03b4 , \u03b8y \u2248 1\u2212 \u221a \u03b3\u03b4\u00b5 2L .\nNotice that 1\u03b3\u03b4 L2\n\u00b52 is the condition number of f(Ax). Next we assume \u00b5\u226a L and examine how \u03b8x varies with \u03b3\u03b4.\n\u2022 If \u03b3\u03b4 \u2248 \u00b52L2 , meaning f is badly conditioned, then\n\u03b8x \u2248 1\u2212 \u03b3\u03b4\u00b5 2 L2 \u00b7 13\u221a\u03b3\u03b4\u00b5/L = 1\u2212 \u221a \u03b3\u03b4\u00b5 3L .\nBecause the overall condition number is 1\u03b3\u03b4 L2\n\u00b52 , this is an accelerated linear rate, and so is \u03b8 = max{\u03b8x, \u03b8y}.\n\u2022 If \u03b3\u03b4 \u2248 \u00b5L , meaning f is mildly conditioned, then\n\u03b8x \u2248 1\u2212 \u00b5 3 L3 1 2(\u00b5/L)3/2+\u00b5/L \u2248 1\u2212 \u00b52L2 .\nThis represents a half-accelerated rate, because the overall condition number is 1\u03b3\u03b4 L2 \u00b52 \u2248 L 3 \u00b53 .\n\u2022 If \u03b3\u03b4 = 1, i.e., f is a simple quadratic function, then\n\u03b8x \u2248 1\u2212 \u00b5 2 L2 1 2\u00b5/L+1 \u2248 1\u2212 \u00b52 L2 .\nThis rate does not have acceleration, because the overall condition number is 1\u03b3\u03b4 L2 \u00b52 \u2248 L 2 \u00b52 .\nAlgorithm 2 Adaptive Batch Primal-Dual (Ada-BPD) input: problem constants \u03bb, \u03b3, \u03b4, L and \u00b5\u0302 > 0, initial\npoint (x(0), y(0)), and adaptation period T . Compute \u03c3, \u03c4 , and \u03b8 as in (7) and (8) using \u00b5 = \u00b5\u0302 for t = 0, 1, 2, . . . do y(t+1) = prox\u03c3f\u2217 ( y(t) + \u03c3Ax\u0303(t) )\nx(t+1) = prox\u03c4g ( x(t) \u2212 \u03c4AT y(t+1) ) x\u0303(t+1) = x(t+1) + \u03b8(x(t+1) \u2212 x(t)) if mod(t+ 1, T ) == 0 then\n(\u03c3, \u03c4, \u03b8) = BPD-Adapt ( {P (s), D(s)}t+1s=t\u2212T )\nend if end for\nAlgorithm 3 BPD-Adapt (simple heuristic) input: previous estimate \u00b5\u0302, adaption period T , primal and\ndual objective values {P (s), D(s)}ts=t\u2212T if P (t) \u2212D(t) < \u03b8T (P (t\u2212T ) \u2212D(t\u2212T )) then \u00b5\u0302 := \u221a 2\u00b5\u0302 else \u00b5\u0302 := \u00b5\u0302/ \u221a 2 end if Compute \u03c3, \u03c4 , and \u03b8 as in (7) and (8) using \u00b5 = \u00b5\u0302\noutput: new parameters (\u03c3, \u03c4, \u03b8)\nIn summary, the extent of acceleration in the dominating factor \u03b8x (which determines \u03b8) depends on the relative size of \u03b3\u03b4 and \u00b52/L2, i.e., the relative conditioning between the function f and the matrix A. In general, we have full acceleration if \u03b3\u03b4 \u2264 \u00b52/L2. The theory predicts that the acceleration degrades as the function f gets better conditioned. However, in our numerical experiments, we often observe acceleration even if \u03b3\u03b4 gets closer to 1.\nAs explained in Chambolle & Pock (2011), Algorithm 1 is equivalent to a preconditioned ADMM. Deng & Yin (2016) characterized various conditions for ADMM to obtain linear convergence, but did not derive the convergence rate for the case we consider in this paper."}, {"heading": "2.1. Adaptive batch primal-dual algorithms", "text": "In practice, it is often very hard to obtain a good estimate of the problem-dependent constants, especially \u00b5 =\u221a \u03bbmin(ATA), in order to apply the algorithmic parameters specified in Theorem 1. Here we explore heuristics that can enable adaptive tuning of such parameters, which often lead to much improved performance in practice.\nA key observation is that the convergence rate of the BPD algorithm changes monotonically with the overall convexity parameter \u03bb + \u03b4\u00b52, regardless of the extent of acceleration. In other words, the larger \u03bb + \u03b4\u00b52 is, the faster the convergence. Therefore, if we can monitor the progress of\nAlgorithm 4 BPD-Adapt (robust heuristic) input: previous rate estimate \u03c1 > 0, \u2206 = \u03b4\u00b5\u03022, period T ,\nconstants c < 1 and c > 1, and {P (s), D(s)}ts=t\u2212T Compute new rate estimate \u03c1\u0302 = P\n(t)\u2212D(t) P (t\u2212T )\u2212D(t\u2212T )\nif \u03c1\u0302 \u2264 c \u03c1 then \u2206 := 2\u2206, \u03c1 := \u03c1\u0302 else if \u03c1\u0302 \u2265 c \u03c1 then \u2206 := \u2206/2, \u03c1 := \u03c1\u0302 else \u2206 := \u2206 end if \u03c3 = 1L \u221a \u03bb+\u2206 \u03b3 , \u03c4 = 1 L \u221a \u03b3 \u03bb+\u2206\nCompute \u03b8 using (8) or set \u03b8 = 1 output: new parameters (\u03c3, \u03c4, \u03b8)\nthe convergence and compare it with the predicted convergence rate in Theorem 1, then we can adjust the estimated parameters to exploit strong convexity from data. More specifically, if the observed convergence rate is slower than the predicted rate, then we should reduce the estimate of \u00b5; otherwise we should increase \u00b5 for faster convergence.\nWe formalize the above reasoning in Algorithm 2 (called Ada-BPD). This algorithm maintains an estimate \u00b5\u0302 of the true constant \u00b5, and adjust it every T iterations. We use P (t) and D(t) to represent the primal and dual objective values at P (x(t)) and D(y(t)), respectively. We give two implementations of the tuning procedure BPD-Adapt: Algorithm 3 is a simple heuristic for tuning the estimate \u00b5\u0302, where the increasing and decreasing factor \u221a 2 can be changed to other values larger than 1. Algorithm 4 is a more robust heuristic. It does not rely on the specific convergence rate \u03b8 established in Theorem 1. Instead, it simply compares the current estimate of objective reduction rate \u03c1\u0302 with the previous estimate \u03c1. It also specifies a non-tuning range of changes in \u03c1, specified by the interval [c, c].\nThe capability of accessing both the primal and dual objective values allows primal-dual algorithms to have good estimate of the convergence rate, which enables effective tuning heuristics. Automatic tuning of primal-dual algorithms have also been studied by, e.g., Malitsky & Pock (2016) and Goldstein et al. (2013), but with different goals."}, {"heading": "3. Randomized primal-dual algorithm", "text": "In this section, we come back to the ERM problem and consider its saddle-point formulation in (3). Due to its finite sum structure in the dual variables yi, we can develope randomized algorithms to exploit strong convexity from data. In particular, we extend the stochastic primal-dual coordinate (SPDC) algorithm by Zhang & Xiao (2015). SPDC is\nAlgorithm 5 Adaptive SPDC (Ada-SPDC) input: parameters \u03c3, \u03c4 , \u03b8 > 0, initial point (x(0), y(0)),\nand adaptation period T . Set x\u0303(0) = x(0) for t = 0, 1, 2, . . . do pick k \u2208 {1, . . . , n} uniformly at random for i \u2208 {1, . . . , n} do\nif i == k then y (t+1) k = prox\u03c3\u03c6\u2217k ( y (t) k + \u03c3a T k x\u0303 (t) ) else y (t+1) i = y (t) i\nend if end for\nx(t+1) = prox\u03c4g\n( x(t)\u2212 \u03c4 ( u(t)+ (y\n(t+1) k \u2212y (t) k )ak\n))\nu(t+1) = u(t) + 1n (y (t+1) k \u2212 y (t) k )ak x\u0303(t+1) = x(t+1) + \u03b8(x(t+1) \u2212 x(t)) if mod(t+ 1, T \u00b7 n) = 0 then\n(\u03c4, \u03c3, \u03b8) = SPDC-Adapt ( {P (t\u2212sn), D(t\u2212sn)}Ts=0 )\nend if end for\na special case of the Ada-SPDC algorithm in Algorithm 5, by setting the adaption period T = \u221e (no adaption). The following theorem is proved in Appendix E. Theorem 2. Suppose Assumption 1 holds. Let (x\u22c6, y\u22c6) be the saddle point of the function L defined in (3), and R = max{\u2016a1\u2016, . . . , \u2016an\u2016}. If we set T = \u221e in Algorithm 5 (no adaption) and let\n\u03c4 = 14R\n\u221a \u03b3\nn\u03bb+\u03b4\u00b52 , \u03c3 = 1 4R\n\u221a n\u03bb+\u03b4\u00b52\n\u03b3 , (9)\nand \u03b8 = max{\u03b8x, \u03b8y} where\n\u03b8x = ( 1\u2212 \u03c4\u03c3\u03b4\u00b522n(\u03c3+4\u03b4) ) 1 1+\u03c4\u03bb , \u03b8y = 1+((n\u22121)/n)\u03c3\u03b3/2 1+\u03c3\u03b3/2 , (10)\nthen we have (\n1 2\u03c4 + \u03bb 2\n) E [ \u2016x(t) \u2212 x\u22c6\u20162 ] + \u03b34E [ \u2016y(t) \u2212 y\u22c6\u20162 ] \u2264 \u03b8tC,\nE [ L(x(t), y\u22c6)\u2212 L(x\u22c6, y(t)) ] \u2264 \u03b8tC,\nwhereC = (\n1 2\u03c4 + \u03bb 2\n) \u2016x(0)\u2212x\u22c6\u20162+ ( 1 2\u03c3+ \u03b3 4 ) \u2016y(0)\u2212y\u22c6\u20162.\nThe expectation E[\u00b7] is taken with respect to the history of random indices drawn at each iteration.\nBelow we give a detailed discussion on the expected convergence rate established in Theorem 2.\nThe cases of \u03c3\u00b52 = 0 but \u03bb > 0. In this case we have \u03c4 = 14R \u221a \u03b3 n\u03bb and \u03c3 = 1 4R \u221a n\u03bb \u03b3 , and\n\u03b8x = 1 1+\u03c4\u03bb = 1\u2212 11+4R\u221an/(\u03bb\u03b3) ,\n\u03b8y = 1+((n\u22121)/n)\u03c3\u03b3/2 1+\u03c3\u03b3/2 = 1\u2212 1n+8R\u221an/(\u03bb\u03b3) .\nHence \u03b8 = \u03b8y . These recover the parameters and convergence rate of the standard SPDC (Zhang & Xiao, 2015).\nThe cases of \u03c3\u00b52 > 0 but \u03bb = 0. In this case we have \u03c4 = 14R\u00b5 \u221a \u03b3 \u03b4 and \u03c3 = \u00b5 4R \u221a \u03b4 \u03b3 , and\n\u03b8x = 1\u2212 \u03c4\u03c3\u03b4\u00b5 2 2n(\u03c3+4\u03b4) = 1\u2212 \u03b3\u03b4\u00b52 32nR2 \u00b7 1\u221a\u03b3\u03b4\u00b5/(4R)+4\u03b3\u03b4 . \u03b8y = 1\u2212 1n+8nR/(\u00b5\u221a\u03b3\u03b4) \u2248 1\u2212 \u221a \u03b3\u03b4\u00b5 8nR ( 1 + \u221a \u03b3\u03b4\u00b5 8R )\u22121 .\nSince the objective is R2/\u03b3-smooth and \u03b4\u00b52/n-strongly convex, \u03b8y is an accelerated rate if \u221a \u03b3\u03b4\u00b5 8R \u226a 1 (otherwise \u03b8y \u2248 1\u2212 1n ). For \u03b8x, we consider different situations:\n\u2022 If \u00b5 \u2265 R, then we have \u03b8x \u2248 1\u2212 \u221a \u03b3\u03b4\u00b5 nR , which is an\naccelerated rate. So is \u03b8 = max{\u03b8x, \u03b8y}. \u2022 If \u00b5 < R and \u03b3\u03b4 \u2248 \u00b52R2 , then \u03b8x \u2248 1\u2212 \u221a \u03b3\u03b4\u00b5 nR , which\nrepresents an accelerated rate. The iteration complexity of SPDC is O\u0303( nR\n\u00b5 \u221a \u03b3\u03b4 ), which is better than that of\nSVRG in this case, which is O\u0303( nR 2\n\u03b3\u03b4\u00b52 ).\n\u2022 If \u00b5 < R and \u03b3\u03b4 \u2248 \u00b5R , then we get \u03b8x \u2248 1\u2212 \u00b52\nnR2 . This is a half-accelerated rate, because in this case SVRG requires O\u0303(nR 3\n\u00b53 ) iterations, versus O\u0303( nR2 \u00b52 ) for SPDC.\n\u2022 If \u00b5 < R and \u03b3\u03b4 \u2248 1, meaning the \u03c6i\u2019s are well conditioned, then we get \u03b8x \u2248 1 \u2212 \u03b3\u03b4\u00b5 2 nR2 \u2248 1 \u2212 \u00b52\nnR2 , which is a non-accelerated rate. The corresponding iteration complexity is the same as SVRG."}, {"heading": "3.1. Parameter adaptation for SPDC", "text": "The SPDC-Adapt procedure called in Algorithm 5 follows the same logics as the batch adaption schemes in Algorithms 3 and 4, and we omit the details here. One thing we emphasize here is that the adaptation period T is in terms of epochs, or number of passes over the data. In addition, we only compute the primal and dual objective values after each pass or every few passes, because computing them exactly usually need to take a full pass of the data.\nUnlike the batch case where the duality gap decreases monotonically, the duality gap for randomized algorithms can fluctuate wildly. So instead of using only the two end values P (t\u2212Tn) \u2212 D(t\u2212Tn) and P (t) \u2212 D(t), we can use more points to estimate the convergence rate through a linear regression. Suppose the primaldual objective values for the last T + 1 passes are (P (0), D(0)), (P (1), D(1)), . . . , (P (T ), D(T )), and we need to estimate \u03c1 (rate per pass) such that\nP (t)\u2212D(t) \u2248 \u03c1t ( P (0)\u2212D(0) ) , t = 1, . . . , T.\nWe can turn it into a linear regression problem after taking logarithm and obtain the estimate \u03c1\u0302 through\nlog(\u03c1\u0302) = 112+22+\u00b7\u00b7\u00b7+T 2 \u2211T t=1 t log P (t)\u2212D(t) P (0)\u2212D(0) .\nAlgorithm 6 Dual-Free BPD Algorithm input: parameters \u03c3, \u03c4 , \u03b8 > 0, initial point (x(0), y(0))\nSet x\u0303(0) = x(0) and v(0) = (f\u2217)\u2032(y(0)) for t = 0, 1, 2, . . . do v(t+1) = v (t)+\u03c3Ax\u0303(t)\n1+\u03c3 , y (t+1) = f \u2032(v(t+1))\nx(t+1) = prox\u03c4g ( x(t) \u2212 \u03c4AT y(t+1) )\nx\u0303(t+1) = x(t+1) + \u03b8(x(t+1) \u2212 x(t)) end for"}, {"heading": "4. Dual-free Primal-dual algorithms", "text": "Compared with primal algorithms, one major disadvantage of primal-dual algorithms is the requirement of computing the proximal mapping of the dual function f\u2217 or \u03c6\u2217i , which may not admit closed-formed solution or efficient computation. This is especially the case for logistic regression, one of the most popular loss functions used in classification.\nLan & Zhou (2015) developed \u201cdual-free\u201d variants of primal-dual algorithms that avoid computing the dual proximal mapping. Their main technique is to replace the Euclidean distance in the dual proximal mapping with a Bregman divergence defined over the dual loss function itself. We show how to apply this approach to solve the structured ERM problems considered in this paper. They can also exploit strong convexity from data if the algorithmic parameters are set appropriately or adapted automatically."}, {"heading": "4.1. Dual-free BPD algorithm", "text": "First, we consider the batch setting. We replace the dual proximal mapping (computing y(t+1)) in Algorithm 1 with\ny(t+1)=argmin y\n{ f\u2217(y)\u2212yTAx\u0303(t)+ 1\u03c3D(y, y(t)) } , (11)\nwhere D is the Bregman divergence of a strictly convex kernel function h, defined as\nDh(y, y(t)) = h(y)\u2212 h(y(t))\u2212 \u3008\u2207h(y(t)), y \u2212 y(t)\u3009. Algorithm 1 is obtained in the Euclidean setting with h(y) = 12\u2016y\u20162 and D(y, y(t)) = 12\u2016y\u2212y(t)\u20162. Here we use f\u2217 as the kernel function, and show that it allows us to compute y(t+1) in (11) very efficiently. The following lemma explains the details (Cf. Lan & Zhou, 2015, Lemma 1). Lemma 1. Let the kernel h \u2261 f\u2217 in the Bregman divergence D. If we construct a sequence of vectors {v(t)} such that v(0) = (f\u2217)\u2032(y(0)) and for all t \u2265 0,\nv(t+1) = v (t)+\u03c3Ax\u0303(t)\n1+\u03c3 , (12)\nthen the solution to problem (11) is y(t+1) = f \u2032(v(t+1)).\nProof. Suppose v(t) = (f\u2217)\u2032(y(t)) (true for t = 0), then\nD(y, y(t)) = f\u2217(y)\u2212 f\u2217(y(t))\u2212 v(t)T (y \u2212 y(t)).\nThe solution to (11) can be written as\ny(t+1)= argmin y\n{ f\u2217(y)\u2212yTAx\u0303(t)+ 1\u03c3 ( f\u2217(y)\u2212v(t)T y )}\n= argmin y\n{( 1 + 1\u03c3 ) f\u2217(y)\u2212 ( Ax\u0303(t) + 1\u03c3v (t) )T y }\n= argmax y\n{( v(t)+\u03c3Ax\u0303(t)\n1+\u03c3\n)T y \u2212 f\u2217(y) }\n= argmax y\n{ v(t+1) T y \u2212 f\u2217(y) } = f \u2032(v(t+1)),\nwhere in the last equality we used the property of conjugate function when f is strongly convex and smooth. Moreover,\nv(t+1) = (f \u2032)\u22121(y(t+1)) = (f\u2217)\u2032(y(t+1)),\nwhich completes the proof.\nAccording to Lemma 1, we only need to provide initial points such that v(0) = (f\u2217)\u2032(y(0)) is easy to compute. We do not need to compute (f\u2217)\u2032(y(t)) directly for any t > 0, because it is can be updated as v(t) in (12). Consequently, we can update y(t) in the BPD algorithm using the gradient f \u2032(v(t)), without the need of dual proximal mapping. The resulting dual-free algorithm is given in Algorithm 6. Theorem 3. Suppose Assumption 2 holds and let (x\u22c6, y\u22c6) be the unique saddle point of L defined in (6). If we set the parameters in Algorithm 6 as\n\u03c4 = 1L\n\u221a \u03b3\n\u03bb+\u03b4\u00b52 , \u03c3 = 1 L\n\u221a \u03b3(\u03bb+ \u03b4\u00b52), (13)\nand \u03b8 = max{\u03b8x, \u03b8y} where\n\u03b8x = ( 1\u2212 \u03c4\u03c3\u03b4\u00b52(4+2\u03c3) ) 1 1+\u03c4\u03bb , \u03b8y = 1 1+\u03c3/2 , (14)\nthen we have (\n1 2\u03c4 + \u03bb 2 ) \u2016x(t) \u2212 x\u22c6\u20162 + 12D(y\u22c6, y(t)) \u2264 \u03b8tC,\nL(x(t), y\u22c6)\u2212 L(x\u22c6, y(t)) \u2264 \u03b8tC,\nwhere C = (\n1 2\u03c4 + \u03bb 2\n) \u2016x(0) \u2212 x\u22c6\u20162 + ( 1 \u03c3+ 1 2 ) D(y\u22c6, y(0)).\nTheorem 3 is proved in Appendices B and D. Assuming \u03b3(\u03bb+ \u03b4\u00b52) \u226a L2, we have\n\u03b8x \u2248 1\u2212 \u03b3\u03b4\u00b5 2 16L2 \u2212 \u03bb2L \u221a \u03b3 \u03bb+\u03b4\u00b52 , \u03b8y \u2248 1\u2212 \u221a \u03b3(\u03bb+\u03b4\u00b52) 4L .\nAgain, we gain insights by consider the special cases:\n\u2022 If \u03b4\u00b52 = 0 and \u03bb > 0, then \u03b8y \u2248 1 \u2212 \u221a \u03b3\u03bb 4L and \u03b8x \u2248\n1\u2212 \u221a \u03b3\u03bb 2L . So \u03b8 = max{\u03b8x, \u03b8y} is an accelerated rate.\n\u2022 If \u03b4\u00b52 > 0 and \u03bb = 0, then \u03b8y \u2248 1 \u2212 \u221a \u03b3\u03b4\u00b52\n4L and\n\u03b8x \u2248 1\u2212 \u03b3\u03b4\u00b5 2 16L2 . Thus \u03b8 = max{\u03b8x, \u03b8y} \u2248 1\u2212 \u03b3\u03b4\u00b52\n16L2 is not accelerated. This conclusion does not depends on the relative sizes of \u03b3\u03b4 and \u00b52/L2, and it is the major difference from the Euclidean case in Section 2.\nAlgorithm 7 Adaptive Dual-Free SPDC (ADF-SPDC) input: parameters \u03c3, \u03c4 , \u03b8 > 0, initial point (x(0), y(0)),\nand adaptation period T .\nSet x\u0303(0) = x(0) and v(0)i = (\u03c6 \u2217 i ) \u2032(y(0)i ) for i = 1, . . . , n for t = 0, 1, 2, . . . do\npick k \u2208 {1, . . . , n} uniformly at random for i \u2208 {1, . . . , n} do\nif i == k then\nv (t+1) k =\nv (t) k +\u03c3a T k x\u0303 (t)\n1+\u03c3 , y (t+1) k = \u03c6 \u2032 k(v (t+1) k )\nelse v (t+1) i = v (t) i , y (t+1) i = y (t) i\nend if end for\nx(t+1) = prox\u03c4g\n( x(t)\u2212 \u03c4 ( u(t)+ (y\n(t+1) k \u2212y (t) k )ak\n))\nu(t+1) = u(t) + 1n (y (t+1) k \u2212 y (t) k )ak x\u0303(t+1) = x(t+1) + \u03b8(x(t+1) \u2212 x(t)) if mod(t+ 1, T \u00b7 n) = 0 then\n(\u03c4, \u03c3, \u03b8) = SPDC-Adapt ( {P (t\u2212sn), D(t\u2212sn)}Ts=0 )\nend if end for\nIf both \u03b4\u00b52 > 0 and \u03bb > 0, then the extent of acceleration depends on their relative size. If \u03bb is on the same order as \u03b4\u00b52 or larger, then accelerated rate is obtained. If \u03bb is much smaller than \u03b4\u00b52, then the theory predicts no acceleration."}, {"heading": "4.2. Dual-free SPDC algorithm", "text": "Following the same approach, we can derive an Adaptive Dual-Free SPDC algorithm, given in Algorithm 7. On related work, Shalev-Shwartz & Zhang (2016) and (Shalev-Shwartz, 2016) introduced dual-free SDCA.\nThe following theorem characterizes the choice of algorithmic parameters that can exploit strong convexity from data to achieve linear convergence (proof given in Appendix F). Theorem 4. Suppose Assumption 1 holds. Let (x\u22c6, y\u22c6) be the saddle point of L in (3) andR=max{\u2016a1\u2016, . . . , \u2016an\u2016}. If we set T = \u221e in Algorithm 7 (non adaption) and let\n\u03c3 = 14R \u221a \u03b3(n\u03bb+ \u03b4\u00b52), \u03c4 = 14R \u221a \u03b3 n\u03bb+\u03b4\u00b52 , (15)\nand \u03b8 = max{\u03b8x, \u03b8y} where\n\u03b8x = ( 1\u2212 \u03c4\u03c3\u03b4\u00b52n(4+2\u03c3) ) 1 1+\u03c4\u03bb , \u03b8y = 1+((n\u22121)/n)\u03c3/2 1+\u03c3/2 ,\n(16) then we have (\n1 2\u03c4 + \u03bb 2\n) E [ \u2016x(t) \u2212 x\u22c6\u20162 ] + \u03b34E [ D(y\u22c6, y(t)) ] \u2264 \u03b8tC,\nE [ L(x(t), y\u22c6)\u2212 L(x\u22c6, y(t)) ] \u2264 \u03b8tC,\nwhere C = (\n1 2\u03c4 + \u03bb 2\n) \u2016x(0) \u2212 x\u22c6\u20162 + ( 1 \u03c3+ 1 2 ) D(y\u22c6, y(0)).\nNow we discuss the results of Theorem 4 in further details.\nThe cases of \u03c3\u00b52 = 0 but \u03bb > 0. In this case we have \u03c4 = 14R \u221a \u03b3 n\u03bb and \u03c3 = 1 4R \u221a n\u03b3\u03bb, and\n\u03b8x = 1\u2212 1 1+4R \u221a n/(\u03bb\u03b3) , \u03b8y = 1\u2212 1 n+8R \u221a n/(\u03bb\u03b3) .\nThe rate is the same as for SPDC in Zhang & Xiao (2015).\nThe cases of \u03c3\u00b52 > 0 but \u03bb = 0. In this case we have \u03c4 = 14R\u00b5 \u221a \u03b3 \u03b4 and \u03c3 = \u00b5 4R \u221a \u03b4\u03b3, thus\n\u03b8x = 1\u2212 \u03c4\u03c3\u03b4\u00b5 2 2n(\u03c3+4) = 1\u2212 \u03b3\u03b4\u00b52 32nR2 \u00b7 1\u221a\u03b3\u03b4\u00b5/(4R)+4 , \u03b8y = 1+((n\u22121)/n)\u03c3/2\n1+\u03c3/2 = 1\u2212 1n+8nR/(\u00b5\u221a\u03b3\u03b4) .\nWe note that the primal function now is R2/\u03b3-smooth and \u03b4\u00b52/n-strongly convex. We discuss the following cases:\n\u2022 If \u221a\u03b3\u03b4\u00b5 > R, then we have \u03b8x \u2248 1 \u2212 \u221a \u03b3\u03b4\u00b5\n8nR and \u03b8y \u2248 1\u2212 1n . Therefore \u03b8 = max{\u03b8x, \u03b8y} \u2248 1\u2212 1n .\n\u2022 Otherwise, we have \u03b8x \u2248 1 \u2212 \u03b3\u03b4\u00b5 2\n64nR2 and \u03b8y is of the same order. This is not an accelerated rate, and we have the same iteration complexity as SVRG.\nFinally, we give concrete examples of how to compute the initial points y(0) and v(0) such that v(0)i = (\u03c6 \u2217 i ) \u2032(y(0)i ).\n\u2022 For squared loss, \u03c6i(\u03b1) = 12 (\u03b1 \u2212 bi)2 and \u03c6\u2217i (\u03b2) = 1 2\u03b2 2 + bi\u03b2. So v (0) i = (\u03c6 \u2217 i ) \u2032(y(0)i ) = y (0) i + bi. \u2022 For logistic regression, we have bi \u2208 {1,\u22121} and \u03c6i(\u03b1) = log(1 + e\n\u2212bi\u03b1). The conjugate function is \u03c6\u2217i (\u03b2) = (\u2212bi\u03b2) log(\u2212bi\u03b2) + (1 + bi\u03b2) log(1 + bi\u03b2) if bi\u03b2 \u2208 [\u22121, 0] and +\u221e otherwise. We can choose y (0) i =\u2212 12bi and v (0) i =0 such that v (0) i =(\u03c6 \u2217 i ) \u2032(y(0)i ).\nFor logistic regression, we have \u03b4 = 0 over the full domain of \u03c6i. However, each \u03c6i is locally strongly convex in bounded domain (Bach, 2014): if z \u2208 [\u2212B,B], then we know \u03b4 = minz \u03c6i\u2032\u2032(z) \u2265 exp(\u2212B)/4. Therefore it is well suitable for an adaptation scheme similar to Algorithm 4 that do not require knowledge of either \u03b4 or \u00b5."}, {"heading": "5. Preliminary experiments", "text": "We present preliminary experiments to demonstrate the effectiveness of our proposed algorithms. First, we consider batch primal-dual algorithms for ridge regression over a synthetic dataset. The data matrix A has sizes n = 5000 and d = 3000, and its entries are sampled from multivariate normal distribution with mean zero and covariance matrix \u03a3ij = 2|i\u2212j|/2. We normalize all datasets\nsuch that ai = ai/ (maxj \u2016aj\u2016), to ensure the maximum norm of the data points is 1. We use \u21132-regularization g(x) = (\u03bb/2)\u2016x\u20162 with three choices of parameter \u03bb: 1/n, 10\u22122/n and 10\u22124/n, which represent the strong, medium, and weak levels of regularization, respectively.\nFigure 1 shows the performance of four different algorithms: the primal accelerated gradient (Primal AG) algorithm (Nesterov, 2004) using \u03bb as strong convexity parameter, the BPD algorithm (Algorithm 1) that uses the same \u03bb and \u00b52\u03b4 = 0, the optimal BPD algorithm (Opt-BPD) that uses \u00b52\u03b4 = \u03bbmin(A\nTA) n \u2248 0.022n computed from data,\nand the Ada-BPD algorithm (Algorithm 2) with the robust adaptation heuristic (Algorithm 4) with T = 10, c = 0.95 and c = 1.5. As expected, the performance of Primal-AG is very similar to that of BPD, and Opt-BPD has the fastest convergence. The Ada-BPD algorithm can partially exploit strong convexity from data without knowledge of \u00b5.\nNext we compare DF-SPDC (Algorithm 5 without adaption) and ADF-SPDC (Algorithm 7 with adaption) against several state-of-the-art randomized algorithms for ERM: SVRG (Johnson & Zhang, 2013), SAGA (Defazio et al., 2014) Katyusha (Allen-Zhu, 2016) and the standard SPDC method (Zhang & Xiao, 2015). For SVRG and Katyusha (an accelerated variant of SVRG), we choose the variance reduction period as m = 2n. The step sizes of all algorithms are set as their original paper suggested. For\nAda-SPDC and ADF-SPDC, we use the robust adaptation scheme with T = 10, c = 0.95 and c = 1.5.\nWe first compare these randomized algorithms for ridge regression over the cpuact data from the LibSVM website (https://www.csie.ntu.edu.tw/\u02dccjlin/libsvm/). The results are shown in Figure 2. With relatively strong regularization \u03bb = 1/n, all methods perform similarly as predicted by theory. When \u03bb becomes smaller, the nonaccelerated algorithms (SVRG and SAGA) automatically exploit strong convexity from data, so they become faster than the non-adaptive accelerated methods (Katyusha, SPDC and DF-SPDC). The adaptive accelerated method, ADF-SPDC, has the fastest convergence. This indicates that our theoretical results, which predict no acceleration in this case, may be further improved.\nFinally we compare these algorithms for logistic regression on the rcv1 dataset (from LibSVM website) and another synthetic dataset with n = 5000 and d = 500, generated similarly as before but with covariance matrix \u03a3ij = 2\n|i\u2212j|/100. For the standard SPDC, we compute the coordinate-wise dual proximal mapping using a few steps of scalar Newton\u2019s method to high precision. The dualfree SPDC algorithms only use gradients of the logistic function. The results are presented in Figure 3. For both datasets, the strong convexity from data is very weak, and the accelerated algorithms performs better."}], "year": 2017, "references": [{"title": "Katyusha: Accelerated variance reduction for faster sgd", "authors": ["Allen-Zhu", "Zeyuan"], "venue": "ArXiv e-print", "year": 2016}, {"title": "Adaptivity of averaged stochastic gradient descent to local strong convexity for logistic regression", "authors": ["Bach", "Francis"], "venue": "Journal of Machine Learning Research,", "year": 2014}, {"title": "Stochastic variance reduction methods for saddle-point problems", "authors": ["Balamurugan", "Palaniappan", "Bach", "Francis"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "year": 2016}, {"title": "Incremental gradient, subgradient, and proximal methods for convex optimization: A survey", "authors": ["Bertsekas", "Dimitri P"], "venue": "Optimization for Machine Learning,", "year": 2012}, {"title": "A first-order primal-dual algorithm for convex problems with applications to imaging", "authors": ["Chambolle", "Antonin", "Pock", "Thomas"], "venue": "Journal of Mathematical Imaging and Vision,", "year": 2011}, {"title": "On the ergodic convergence rates of a first-order primal\u2013dual algorithm", "authors": ["Chambolle", "Antonin", "Pock", "Thomas"], "venue": "Mathematical Programming, Series A,", "year": 2016}, {"title": "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives", "authors": ["Defazio", "Aaron", "Bach", "Francis", "Lacoste-Julien", "Simon"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2014}, {"title": "On the global and linear convergence of the generalized alternating direction method of multipliers", "authors": ["Deng", "Wei", "Yin", "Wotao"], "venue": "Journal of Scientific Computing,", "year": 2016}, {"title": "Accelerated, parallel, and proximal coordinate descent", "authors": ["Fercoq", "Oliver", "Richt\u00e1rik", "Peter"], "venue": "SIAM Journal on Optimization,", "year": 2015}, {"title": "Adaptive primal-dual hybrid gradient methods for saddle-point problems", "authors": ["Goldstein", "Tom", "Li", "Min", "Yuan", "Xiaoming", "Esser", "Ernie", "Baraniuk", "Richard"], "venue": "arXiv preprint arXiv:1305.0546,", "year": 2013}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "authors": ["Johnson", "Rie", "Zhang", "Tong"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2013}, {"title": "An optimal randomized incremental gradient method", "authors": ["Lan", "Guanghui", "Zhou", "Yi"], "venue": "arXiv preprint arXiv:1507.02000,", "year": 2015}, {"title": "A universal catalyst for first-order optimization", "authors": ["Lin", "Hongzhou", "Mairal", "Julien", "Harchaoui", "Zaid"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2015}, {"title": "An accelerated randomized proximal coordinate gradient method and its application to regularized empirical risk minimization", "authors": ["Lin", "Qihang", "Lu", "Zhaosong", "Xiao"], "venue": "SIAM Journal on Optimization,", "year": 2015}, {"title": "A first-order primal-dual algorithm with linesearch", "authors": ["Malitsky", "Yura", "Pock", "Thomas"], "venue": "arXiv preprint arXiv:1608.08883,", "year": 2016}, {"title": "Incremental subgradient methods for nondifferentiable optimization", "authors": ["Nedic", "Angelia", "Bertsekas", "Dimitri P"], "venue": "SIAM Journal on Optimization,", "year": 2001}, {"title": "Introductory Lectures on Convex Optimization: A Basic Course", "authors": ["Nesterov", "Yurii"], "year": 2004}, {"title": "Efficiency of coordinate descent methods on huge-scale optimization problems", "authors": ["Nesterov", "Yurii"], "venue": "SIAM Journal on Optimization,", "year": 2012}, {"title": "Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function", "authors": ["Richt\u00e1rik", "Peter", "Tak\u00e1\u010d", "Martin"], "venue": "Mathematical Programming,", "year": 2014}, {"title": "A stochastic gradient method with an exponential convergence rate for finite training sets", "authors": ["Roux", "Nicolas L", "Schmidt", "Mark", "Bach", "Francis"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2012}, {"title": "SDCA without duality, regularization, and individual convexity", "authors": ["Shalev-Shwartz", "Shai"], "venue": "In Proceedings of The 33rd International Conference on Machine Learning,", "year": 2016}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "authors": ["Shalev-Shwartz", "Shai", "Zhang", "Tong"], "venue": "Journal of Machine Learning Research,", "year": 2013}, {"title": "Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization", "authors": ["Shalev-Shwartz", "Shai", "Zhang", "Tong"], "venue": "Mathematical Programming,", "year": 2016}, {"title": "A proximal stochastic gradient method with progressive variance reduction", "authors": ["Xiao", "Lin", "Zhang", "Tong"], "venue": "SIAM Journal on Optimization,", "year": 2014}, {"title": "Stochastic primal-dual coordinate method for regularized empirical risk minimization", "authors": ["Zhang", "Yuchen", "Xiao", "Lin"], "venue": "In Proceedings of The 32nd International Conference on Machine Learning,", "year": 2015}], "id": "SP:c6baf181bf67bc1f5283f3ce28070705c7c7085a", "authors": [{"name": "Jialei Wang", "affiliations": []}, {"name": "Lin Xiao", "affiliations": []}], "abstractText": "We consider empirical risk minimization of linear predictors with convex loss functions. Such problems can be reformulated as convex-concave saddle point problems and solved by primal-dual first-order algorithms. However, primal-dual algorithms often require explicit strongly convex regularization in order to obtain fast linear convergence, and the required dual proximal mapping may not admit closed-form or efficient solution. In this paper, we develop both batch and randomized primal-dual algorithms that can exploit strong convexity from data adaptively and are capable of achieving linear convergence even without regularization. We also present dual-free variants of adaptive primal-dual algorithms that do not need the dual proximal mapping, which are especially suitable for logistic regression.", "title": "Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms"}
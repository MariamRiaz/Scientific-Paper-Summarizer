0,1,label2,summary_sentences
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1948–1958 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1948",text,[0],[0]
"With the recent surge of interest in deep learning, one question that is being asked across a number of fronts is: can deep learning techniques be harnessed for creative purposes?",1 Introduction,[0],[0]
"Creative applications where such research exists include the composition of music (Humphrey et al., 2013; Sturm et al., 2016; Choi et al., 2016), the design of sculptures (Lehman et al., 2016), and automatic choreography (Crnkovic-Friis and Crnkovic-Friis, 2016).",1 Introduction,[0],[0]
"In this paper, we focus on a creative textual task: automatic poetry composition.
",1 Introduction,[0],[0]
"A distinguishing feature of poetry is its aesthetic forms, e.g. rhyme and rhythm/",1 Introduction,[0],[0]
"meter.1 In this work, we treat the task of poem generation as a constrained language modelling task, such that lines of a given poem rhyme, and each line follows a canonical meter and has a fixed number
1Noting that there are many notable divergences from this in the work of particular poets (e.g. Walt Whitman) and poetry types (such as free verse or haiku).
",1 Introduction,[0],[0]
Shall I compare thee to a summer’s day?,1 Introduction,[0],[0]
"Thou art more lovely and more temperate: Rough winds do shake the darling buds of May, And summer’s lease hath all too short a date:
",1 Introduction,[0],[0]
"Figure 1: 1st quatrain of Shakespeare’s Sonnet 18.
of stresses.",1 Introduction,[0],[0]
"Specifically, we focus on sonnets and generate quatrains in iambic pentameter (e.g. see Figure 1), based on an unsupervised model of language, rhyme and meter trained on a novel corpus of sonnets.
",1 Introduction,[0],[0]
"Our findings are as follows:
• our proposed stress and rhyme models work very well, generating sonnet quatrains with stress and rhyme patterns that are indistinguishable from human-written poems and rated highly by an expert; • a vanilla language model trained over our son-
net corpus, surprisingly, captures meter implicitly at human-level performance; • while crowd workers rate the poems generated
by our best model as nearly indistinguishable from published poems by humans, an expert annotator found the machine-generated poems to lack readability and emotion, and our best model to be only comparable to a vanilla language model on these dimensions; • most work on poetry generation focuses on me-
ter (Greene et al., 2010; Ghazvininejad et al., 2016; Hopkins and Kiela, 2017); our results suggest that future research should look beyond meter and focus on improving readability.
",1 Introduction,[0],[0]
"In this, we develop a new annotation framework for the evaluation of machine-generated poems, and release both a novel data of sonnets and the full source code associated with this research.2
2https://github.com/jhlau/deepspeare",1 Introduction,[0],[0]
"Early poetry generation systems were generally rule-based, and based on rhyming/TTS dictionaries and syllable counting (Gervás, 2000; Wu et al., 2009; Netzer et al., 2009; Colton et al., 2012; Toivanen et al., 2013).",2 Related Work,[0],[0]
"The earliest attempt at using statistical modelling for poetry generation was Greene et al. (2010), based on a language model paired with a stress model.
",2 Related Work,[0],[0]
Neural networks have dominated recent research.,2 Related Work,[0],[0]
"Zhang and Lapata (2014) use a combination of convolutional and recurrent networks for modelling Chinese poetry, which Wang et al. (2016) later simplified by incorporating an attention mechanism and training at the character level.",2 Related Work,[0],[0]
"For English poetry, Ghazvininejad et al. (2016) introduced a finite-state acceptor to explicitly model rhythm in conjunction with a recurrent neural language model for generation.",2 Related Work,[0],[0]
"Hopkins and Kiela (2017) improve rhythm modelling with a cascade of weighted state transducers, and demonstrate the use of character-level language model for English poetry.",2 Related Work,[0],[0]
"A critical difference over our work is that we jointly model both poetry content and forms, and unlike previous work which use dictionaries (Ghazvininejad et al., 2016) or heuristics (Greene et al., 2010) for rhyme, we learn it automatically.",2 Related Work,[0],[0]
"The sonnet is a poem type popularised by Shakespeare, made up of 14 lines structured as 3 quatrains (4 lines) and a couplet (2 lines);3 an example quatrain is presented in Figure 1.",3 Sonnet Structure and Dataset,[0],[0]
"It follows a number of aesthetic forms, of which two are particularly salient: stress and rhyme.
",3 Sonnet Structure and Dataset,[0],[0]
"A sonnet line obeys an alternating stress pattern, called the iambic pentameter, e.g.:
S− S+ S− S+ S− S+ S− S+ S− S+
Shall I compare thee to a summer’s day?",3 Sonnet Structure and Dataset,[0],[0]
"where S− and S+ denote unstressed and stressed syllables, respectively.
",3 Sonnet Structure and Dataset,[0],[0]
"A sonnet also rhymes, with a typical rhyming scheme being ABAB CDCD EFEF GG.",3 Sonnet Structure and Dataset,[0],[0]
"There are a number of variants, however, mostly seen in the quatrains; e.g. AABB or ABBA are also common.
",3 Sonnet Structure and Dataset,[0],[0]
"We build our sonnet dataset from the latest image of Project Gutenberg.4 We first create a
3There are other forms of sonnets, but the Shakespearean sonnet is the dominant one.",3 Sonnet Structure and Dataset,[0],[0]
"Hereinafter “sonnet” is used to specifically mean Shakespearean sonnets.
",3 Sonnet Structure and Dataset,[0],[0]
"4https://www.gutenberg.org/.
(generic) poetry document collection using the GutenTag tool (Brooke et al., 2015), based on its inbuilt poetry classifier and rule-based structural tagging of individual poems.
",3 Sonnet Structure and Dataset,[0],[0]
"Given the poems, we use word and character statistics derived from Shakespeare’s 154 sonnets to filter out all non-sonnet poems (to form the “BACKGROUND” dataset), leaving the sonnet corpus (“SONNET”).5 Based on a small-scale manual analysis of SONNET, we find that the approach is sufficient for extracting sonnets with high precision.",3 Sonnet Structure and Dataset,[0],[0]
"BACKGROUND serves as a large corpus (34M words) for pre-training word embeddings, and SONNET is further partitioned into training, development and testing sets.",3 Sonnet Structure and Dataset,[0],[0]
Statistics of SONNET are given in Table 1.6,3 Sonnet Structure and Dataset,[0],[0]
"We propose modelling both content and forms jointly with a neural architecture, composed of 3 components: (1) a language model; (2) a pentameter model for capturing iambic pentameter; and (3) a rhyme model for learning rhyming words.
",4 Architecture,[0],[0]
"Given a sonnet line, the language model uses standard categorical cross-entropy to predict the next word, and the pentameter model is similarly trained to learn the alternating iambic stress patterns.7 The rhyme model, on the other hand, uses a margin-based loss to separate rhyming word pairs from non-rhyming word pairs in a quatrain.",4 Architecture,[0],[0]
"For generation we use the language model to generate one word at a time, while applying the pentame-
5The following constraints were used to select sonnets: 8.0 6 mean words per line 6 11.5; 40 6 mean characters per line 6 51.0; min/max number of words per line of 6/15; min/max number of characters per line of 32/60; and min letter ratio per line > 0.59.
6The sonnets in our collection are largely in Modern English, with possibly a small number of poetry in Early Modern English.",4 Architecture,[0],[0]
"The potentially mixed-language dialect data might add noise to our system, and given more data it would be worthwhile to include time period as a factor in the model.
",4 Architecture,[0],[0]
"7There are a number of variations in addition to the standard pattern (Greene et al., 2010), but our model uses only the standard pattern as it is the dominant one.
",4 Architecture,[0],[0]
ter model to sample meter-conforming sentences and the rhyme model to enforce rhyme.,4 Architecture,[0],[0]
The architecture of the joint model is illustrated in Figure 2.,4 Architecture,[0],[0]
We train all the components together by treating each component as a sub-task in a multitask learning setting.8,4 Architecture,[0],[0]
"The language model is a variant of an LSTM encoder–decoder model with attention (Bahdanau et al., 2015), where the encoder encodes the preceding context (i.e. all sonnet lines before the current line) and the decoder decodes one word at a time for the current line, while attending to the preceding context.
",4.1 Language Model,[0],[0]
"In the encoder, we embed context words zi using embedding matrix Wwrd to yield wi, and feed them to a biLSTM9 to produce a sequence of encoder hidden states",4.1 Language Model,[0],[0]
hi =,4.1 Language Model,[0],[0]
[~hi; ~hi].,4.1 Language Model,[0],[0]
"Next we apply
8We stress that although the components appear to be disjointed, the shared parameters allow the components to mutually influence each other during joint training.",4.1 Language Model,[0],[0]
"To exemplify this, we found that the pentameter model performs very poorly when we train each component separately.
",4.1 Language Model,[0],[0]
"9We use a single layer for all LSTMs.
",4.1 Language Model,[0],[0]
"a selective mechanism (Zhou et al., 2017) to each hi.",4.1 Language Model,[0],[0]
"By defining the representation of the whole context h = [~hC ; ~h1] (where C is the number of words in the context), the selective mechanism filters the hidden states hi using h as follows:
h′i = hi σ(Wahi",4.1 Language Model,[0],[0]
"+Uah+ ba)
where denotes element-wise product.",4.1 Language Model,[0],[0]
"Hereinafter W, U and b are used to refer to model parameters.",4.1 Language Model,[0],[0]
"The intuition behind this procedure is to selectively filter less useful elements from the context words.
",4.1 Language Model,[0],[0]
"In the decoder, we embed words xt in the current line using the encoder-shared embedding matrix (Wwrd) to produce wt.",4.1 Language Model,[0],[0]
"In addition to the word embeddings, we also embed the characters of a word using embedding matrix Wchr to produce ct,i, and feed them to a bidirectional (character-level) LSTM:
~ut,i = LSTMf (ct,i, ~ut,i−1) ~ut,i = LSTMb(ct,i, ~ut,i+1)
(1)
We represent the character encoding of a word by concatenating the last forward and first back-
ward hidden states ut =",4.1 Language Model,[0],[0]
"[~ut,L; ~ut,1], where L is the length of the word.",4.1 Language Model,[0],[0]
"We incorporate character encodings because they provide orthographic information, improve representations of unknown words, and are shared with the pentameter model (Section 4.2).10 The rationale for sharing the parameters is that we see word stress and language model information as complementary.
",4.1 Language Model,[0],[0]
"Given the word embedding wt and character encoding ut, we concatenate them together and feed them to a unidirectional (word-level) LSTM to produce the decoding states:
st = LSTM([wt;ut], st−1) (2)
We attend st to encoder hidden states h′i and compute the weighted sum of h′i as follows:
eti = v ᵀ b tanh(Wbh ′",4.1 Language Model,[0],[0]
"i +Ubst + bb) at = softmax(et)
h∗t",4.1 Language Model,[0],[0]
= ∑ i atih ′,4.1 Language Model,[0],[0]
"i
To combine st and h∗t , we use a gating unit similar to a GRU (Cho et al., 2014; Chung et al., 2014): s′t = GRU(st,h ∗ t ).",4.1 Language Model,[0],[0]
"We then feed s ′ t to a linear layer with softmax activation to produce the vocabulary distribution (i.e. softmax(Wouts′t + bout), and optimise the model with standard categorical cross-entropy loss.",4.1 Language Model,[0],[0]
"We use dropout as regularisation (Srivastava et al., 2014), and apply it to the encoder/decoder LSTM outputs and word embedding lookup.",4.1 Language Model,[0],[0]
"The same regularisation method is used for the pentameter and rhyme models.
",4.1 Language Model,[0],[0]
"As our sonnet data is relatively small for training a neural language model (367K words; see Table 1), we pre-train word embeddings and reduce parameters further by introducing weight-sharing between output matrix Wout and embedding matrix Wwrd via a projection matrix",4.1 Language Model,[0],[0]
"Wprj (Inan et al., 2016; Paulus et al., 2017; Press and Wolf, 2017):
Wout = tanh(WwrdWprj)",4.1 Language Model,[0],[0]
This component is designed to capture the alternating iambic stress pattern.,4.2 Pentameter Model,[0],[0]
"Given a sonnet line,
10We initially shared the character encodings with the rhyme model as well, but found sub-par performance for the rhyme model.",4.2 Pentameter Model,[0],[0]
"This is perhaps unsurprising, as rhyme and stress are qualitatively very different aspects of forms.
",4.2 Pentameter Model,[0],[0]
"the pentameter model learns to attend to the appropriate characters to predict the 10 binary stress symbols sequentially.11 As punctuation is not pronounced, we preprocess each sonnet line to remove all punctuation, leaving only spaces and letters.",4.2 Pentameter Model,[0],[0]
"Like the language model, the pentameter model is fashioned as an encoder–decoder network.
",4.2 Pentameter Model,[0],[0]
"In the encoder, we embed the characters using the shared embedding matrix Wchr and feed them to the shared bidirectional character-level LSTM (Equation (1)) to produce the character encodings for the sentence: uj = [~uj ; ~uj ].
",4.2 Pentameter Model,[0],[0]
"In the decoder, it attends to the characters to predict the stresses sequentially with an LSTM:
gt = LSTM(u∗t−1,gt−1)
where u∗t−1 is the weighted sum of character encodings from the previous time step, produced by an attention network which we describe next,12 and gt is fed to a linear layer with softmax activation to compute the stress distribution.
",4.2 Pentameter Model,[0],[0]
"The attention network is designed to focus on stress-producing characters, whose positions are monotonically increasing (as stress is predicted sequentially).",4.2 Pentameter Model,[0],[0]
"We first compute µt, the mean position of focus:
µ′t = σ(v ᵀ c tanh(Wcgt +Ucµt−1 + bc)) µt =M ×min(µ′t + µt−1, 1.0)
where M is the number of characters in the sonnet line.",4.2 Pentameter Model,[0],[0]
"Given µt, we can compute the (unnormalised) probability for each character position:
ptj = exp",4.2 Pentameter Model,[0],[0]
"( −(j − µt)2
2T 2 ) where standard deviation T is a hyper-parameter.",4.2 Pentameter Model,[0],[0]
"We incorporate this position information when computing u∗t : 13
u′j = p t juj",4.2 Pentameter Model,[0],[0]
dtj = v ᵀ d tanh(Wdu ′,4.2 Pentameter Model,[0],[0]
j,4.2 Pentameter Model,[0],[0]
"+Udgt + bd)
f t = softmax(dt + logpt) u∗t = ∑ j btjuj
11That is, given the input line Shall I compare thee to a summer’s day?",4.2 Pentameter Model,[0],[0]
the model is required to output S− S+ S− S+ S− S+ S− S+,4.2 Pentameter Model,[0],[0]
"S− S+, based on the syllable boundaries from Section 3.
",4.2 Pentameter Model,[0],[0]
"12Initial input (u∗0) and state (g0) is a trainable vector and zero vector respectively.
",4.2 Pentameter Model,[0],[0]
"13Spaces are masked out, so they always yield zero attention weights.
",4.2 Pentameter Model,[0],[0]
"Intuitively, the attention network incorporates the position information at two points, when computing: (1) dtj by weighting the character encodings; and (2) f t by adding the position log probabilities.",4.2 Pentameter Model,[0],[0]
"This may appear excessive, but preliminary experiments found that this formulation produces the best performance.
",4.2 Pentameter Model,[0],[0]
"In a typical encoder–decoder model, the attended encoder vector u∗t would be combined with the decoder state gt to compute the output probability distribution.",4.2 Pentameter Model,[0],[0]
"Doing so, however, would result in a zero-loss model as it will quickly learn that it can simply ignore u∗t to predict the alternating stresses based on gt.",4.2 Pentameter Model,[0],[0]
"For this reason we use only u∗t to compute the stress probability:
P (S−) = σ(Weu ∗ t + be)
which gives the loss Lent = ∑
t− logP (S?t ) for the whole sequence, where S?t is the target stress at time step t.
We find the decoder still has the tendency to attend to the same characters, despite the incorporation of position information.",4.2 Pentameter Model,[0],[0]
"To regularise the model further, we introduce two loss penalties: repeat and coverage loss.
",4.2 Pentameter Model,[0],[0]
"The repeat loss penalises the model when it attends to previously attended characters (See et al., 2017), and is computed as follows:
Lrep = ∑ t ∑ j min(f tj , t−1∑ t=1 f tj )
By keeping a sum of attention weights over all previous time steps, we penalise the model when it focuses on characters that have non-zero history weights.
",4.2 Pentameter Model,[0],[0]
"The repeat loss discourages the model from focussing on the same characters, but does not assure that the appropriate characters receive attention.",4.2 Pentameter Model,[0],[0]
"Observing that stresses are aligned with the vowels of a syllable, we therefore penalise the model when vowels are ignored:
Lcov = ∑ j∈V ReLU(C − 10∑ t=1 f tj )
where V is a set of positions containing vowel characters, and C is a hyper-parameter that defines the minimum attention threshold that avoids penalty.
",4.2 Pentameter Model,[0],[0]
"To summarise, the pentameter model is optimised with the following loss:
Lpm = Lent + αLrep + βLcov (3)
where α and β are hyper-parameters for weighting the additional loss terms.",4.2 Pentameter Model,[0],[0]
"Two reasons motivate us to learn rhyme in an unsupervised manner: (1) we intend to extend the current model to poetry in other languages (which may not have pronunciation dictionaries); and (2) the language in our SONNET data is not Modern English, and so contemporary dictionaries may not accurately reflect the rhyme of the data.
",4.3 Rhyme Model,[0],[0]
"Exploiting the fact that rhyme exists in a quatrain, we feed sentence-ending word pairs of a quatrain as input to the rhyme model and train it to learn how to separate rhyming word pairs from non-rhyming ones.",4.3 Rhyme Model,[0],[0]
"Note that the model does not assume any particular rhyming scheme — it works as long as quatrains have rhyme.
",4.3 Rhyme Model,[0],[0]
"A training example consists of a number of word pairs, generated by pairing one target word with 3 other reference words in the quatrain, i.e. {(xt, xr), (xt, xr+1), (xt, xr+2)}, where xt is the target word and xr+i are the reference words.14",4.3 Rhyme Model,[0],[0]
We assume that in these 3 pairs there should be one rhyming and 2 non-rhyming pairs.,4.3 Rhyme Model,[0],[0]
From preliminary experiments we found that we can improve the model by introducing additional non-rhyming or negative reference words.,4.3 Rhyme Model,[0],[0]
"Negative reference words are sampled uniform randomly from the vocabulary, and the number of additional negative words is a hyper-parameter.
",4.3 Rhyme Model,[0],[0]
For each word x in the word pairs we embed the characters using the shared embedding matrix Wchr and feed them to an LSTM to produce the character states uj,4.3 Rhyme Model,[0],[0]
.15,4.3 Rhyme Model,[0],[0]
"Unlike the language and pentameter models, we use a unidirectional forward LSTM here (as rhyme is largely determined by the final characters), and the LSTM parameters are not shared.",4.3 Rhyme Model,[0],[0]
"We represent the encoding of the whole word by taking the last state u = uL, where L is the character length of the word.
",4.3 Rhyme Model,[0],[0]
"Given the character encodings, we use a
14E.g.",4.3 Rhyme Model,[0],[0]
"for the quatrain in Figure 1, a training example is {(day, temperate), (day, may), (day, date)}.
",4.3 Rhyme Model,[0],[0]
"15The character embeddings are the only shared parameters in this model.
margin-based loss to optimise the model:
Q = {cos(ut,ur), cos(ut,ur+1), ...}",4.3 Rhyme Model,[0],[0]
"Lrm = max(0, δ − top(Q, 1) + top(Q, 2))
where top(Q, k) returns the k-th largest element in Q, and δ is a margin hyper-parameter.
",4.3 Rhyme Model,[0],[0]
"Intuitively, the model is trained to learn a sufficient margin (defined by δ) that separates the best pair with all others, with the second-best being used to quantify all others.",4.3 Rhyme Model,[0],[0]
"This is the justification used in the multi-class SVM literature for a similar objective (Wang and Xue, 2014).
",4.3 Rhyme Model,[0],[0]
"With this network we can estimate whether two words rhyme by computing the cosine similarity score during generation, and resample words as necessary to enforce rhyme.",4.3 Rhyme Model,[0],[0]
"We focus on quatrain generation in this work, and so the aim is to generate 4 lines of poetry.",4.4 Generation Procedure,[0],[0]
During generation we feed the hidden state from the previous time step to the language model’s decoder to compute the vocabulary distribution for the current time step.,4.4 Generation Procedure,[0],[0]
"Words are sampled using a temperature between 0.6 and 0.8, and they are resampled if the following set of words is generated: (1) UNK token; (2) non-stopwords that were generated before;16 (3) any generated words with a frequency > 2; (4) the preceding 3 words; and (5) a number of symbols including parentheses, single and double quotes.17",4.4 Generation Procedure,[0],[0]
"The first sonnet line is generated without using any preceding context.
",4.4 Generation Procedure,[0],[0]
We next describe how to incorporate the pentameter model for generation.,4.4 Generation Procedure,[0],[0]
"Given a sonnet line, the pentameter model computes a loss Lpm (Equation (3))",4.4 Generation Procedure,[0],[0]
that indicates how well the line conforms to the iambic pentameter.,4.4 Generation Procedure,[0],[0]
"We first generate 10 candidate lines (all initialised with the same hidden state), and then sample one line from the candidate lines based on the pentameter loss values (Lpm).",4.4 Generation Procedure,[0],[0]
"We convert the losses into probabilities by taking the softmax, and a sentence is sampled with temperature = 0.1.
",4.4 Generation Procedure,[0],[0]
"To enforce rhyme, we randomly select one of the rhyming schemes (AABB, ABAB or ABBA) and resample sentence-ending words as necessary.",4.4 Generation Procedure,[0],[0]
"Given a pair of words, the rhyme model produces a cosine similarity score that estimates how well the
16We use the NLTK stopword list (Bird et al., 2009).",4.4 Generation Procedure,[0],[0]
"17We add these constraints to prevent the model from being
too repetitive, in generating the same words.
",4.4 Generation Procedure,[0],[0]
two words rhyme.,4.4 Generation Procedure,[0],[0]
We resample the second word of a rhyming pair (e.g. when generating the second A in AABB) until it produces a cosine similarity > 0.9.,4.4 Generation Procedure,[0],[0]
"We also resample the second word of a nonrhyming pair (e.g. when generating the first B in AABB) by requiring a cosine similarity 6 0.7.18
When generating in the forward direction we can never be sure that any particular word is the last word of a line, which creates a problem for resampling to produce good rhymes.",4.4 Generation Procedure,[0],[0]
"This problem is resolved in our model by reversing the direction of the language model, i.e. generating the last word of each line first.",4.4 Generation Procedure,[0],[0]
We apply this inversion trick at the word level (character order of a word is not modified) and only to the language model; the pentameter model receives the original word order as input.,4.4 Generation Procedure,[0],[0]
"We assess our sonnet model in two ways: (1) component evaluation of the language, pentameter and rhyme models; and (2) poetry generation evaluation, by crowd workers and an English literature expert.",5 Experiments,[0],[0]
"A sample of machine-generated sonnets are included in the supplementary material.
",5 Experiments,[0],[0]
We tune the hyper-parameters of the model over the development data (optimal configuration in the supplementary material).,5 Experiments,[0],[0]
"Word embeddings are initialised with pre-trained skip-gram embeddings (Mikolov et al., 2013a,b) on the BACKGROUND dataset, and are updated during training.",5 Experiments,[0],[0]
"For optimisers, we use Adagrad (Duchi et al., 2011) for the language model, and Adam (Kingma and Ba, 2014) for the pentameter and rhyme models.",5 Experiments,[0],[0]
"We truncate backpropagation through time after 2 sonnet lines, and train using 30 epochs, resetting the network weights to the weights from the previous epoch whenever development loss worsens.",5 Experiments,[0],[0]
We use standard perplexity for evaluating the language model.,5.1.1 Language Model,[0],[0]
"In terms of model variants, we have:19 • LM: Vanilla LSTM language model; • LM∗: LSTM language model that incorporates
character encodings (Equation (2)); 18Maximum number of resampling steps is capped at 1000.",5.1.1 Language Model,[0],[0]
"If the threshold is exceeded the model is reset to generate from scratch again.
",5.1.1 Language Model,[0],[0]
"19All models use the same (applicable) hyper-parameter configurations.
",5.1.1 Language Model,[0],[0]
• LM∗∗: LSTM language model that incorporates both character encodings and preceding context; • LM∗∗-C:,5.1.1 Language Model,[0],[0]
"Similar to LM∗∗, but preceding con-
text is encoded using convolutional networks, inspired by the poetry model of Zhang and Lapata (2014);20 • LM∗∗+PM+RM: the full model, with joint training of the language, pentameter and rhyme models.",5.1.1 Language Model,[0],[0]
Perplexity on the test partition is detailed in Table 2.,5.1.1 Language Model,[0],[0]
"Encouragingly, we see that the incorporation of character encodings and preceding context improves performance substantially, reducing perplexity by almost 10 points from LM to LM∗∗.",5.1.1 Language Model,[0],[0]
The inferior performance of LM∗∗-C compared to LM∗∗ demonstrates that our approach of processing context with recurrent networks with selective encoding is more effective than convolutional networks.,5.1.1 Language Model,[0],[0]
"The full model LM∗∗+PM+RM, which learns stress
20In Zhang and Lapata (2014), the authors use a series of convolutional networks with a width of 2 words to convert 5/7 poetry lines into a fixed size vector; here we use a standard convolutional network with max-pooling operation (Kim, 2014) to process the context.
and rhyme patterns simultaneously, also appears to improve the language model slightly.",5.1.1 Language Model,[0],[0]
"To assess the pentameter model, we use the attention weights to predict stress patterns for words in the test data, and compare them against stress patterns in the CMU pronunciation dictionary.21 Words that have no coverage or have nonalternating patterns given by the dictionary are discarded.",5.1.2 Pentameter Model,[0],[0]
"We use accuracy as the metric, and a predicted stress pattern is judged to be correct if it matches any of the dictionary stress patterns.
",5.1.2 Pentameter Model,[0],[0]
"To extract a stress pattern for a word from the model, we iterate through the pentameter (10 time steps), and append the appropriate stress (e.g. 1st time step = S−) to the word if any of its characters receives an attention > 0.20.
",5.1.2 Pentameter Model,[0],[0]
For the baseline (Stress-BL) we use the pretrained weighted finite state transducer (WFST) provided by Hopkins and Kiela (2017).22 The WFST maps a sequence word to a sequence of stresses by assuming each word has 1–5 stresses and the full word sequence produces iambic pentameter.,5.1.2 Pentameter Model,[0],[0]
"It is trained using the EM algorithm on a sonnet corpus developed by the authors.
",5.1.2 Pentameter Model,[0],[0]
We present stress accuracy in Table 2.,5.1.2 Pentameter Model,[0],[0]
"LM∗∗+PM+RM performs competitively, and informal inspection reveals that a number of mistakes are due to dictionary errors.",5.1.2 Pentameter Model,[0],[0]
"To understand the predicted stresses qualitatively, we display attention heatmaps for the the first quatrain of Shakespeare’s Sonnet 18 in Figure 3.",5.1.2 Pentameter Model,[0],[0]
"The y-axis represents the ten stresses of the iambic pentameter, and
21http://www.speech.cs.cmu.edu/cgi-bin/ cmudict.",5.1.2 Pentameter Model,[0],[0]
"Note that the dictionary provides 3 levels of stresses: 0, 1 and 2; we collapse 1 and 2 to S+.
22https://github.com/JackHopkins/ ACLPoetry
x-axis the characters of the sonnet line (punctuation removed).",5.1.2 Pentameter Model,[0],[0]
"The attention network appears to perform very well, without any noticeable errors.",5.1.2 Pentameter Model,[0],[0]
"The only minor exception is lovely in the second line, where it predicts 2 stresses but the second stress focuses incorrectly on the character e rather than y. Additional heatmaps for the full sonnet are provided in the supplementary material.",5.1.2 Pentameter Model,[0],[0]
"We follow a similar approach to evaluate the rhyme model against the CMU dictionary, but score based on F1 score.",5.1.3 Rhyme Model,[0],[0]
Word pairs that are not included in the dictionary are discarded.,5.1.3 Rhyme Model,[0],[0]
"Rhyme is determined by extracting the final stressed phoneme for the paired words, and testing if their phoneme patterns match.
",5.1.3 Rhyme Model,[0],[0]
"We predict rhyme for a word pair by feeding them to the rhyme model and computing cosine similarity; if a word pair is assigned a score > 0.8,23 it is considered to rhyme.",5.1.3 Rhyme Model,[0],[0]
"As a baseline (Rhyme-BL), we first extract for each word the last vowel and all following consonants, and predict a word pair as rhyming if their extracted sequences match.",5.1.3 Rhyme Model,[0],[0]
"The extracted sequence can be interpreted as a proxy for the last syllable of a word.
",5.1.3 Rhyme Model,[0],[0]
Reddy and Knight (2011) propose an unsupervised model for learning rhyme schemes in poems via EM.,5.1.3 Rhyme Model,[0],[0]
"There are two latent variables: φ specifies the distribution of rhyme schemes, and θ defines
230.8 is empirically found to be the best threshold based on development data.
",5.1.3 Rhyme Model,[0],[0]
the pairwise rhyme strength between two words.,5.1.3 Rhyme Model,[0],[0]
The model’s objective is to maximise poem likelihood over all possible rhyme scheme assignments under the latent variables φ and θ.,5.1.3 Rhyme Model,[0],[0]
"We train this model (Rhyme-EM) on our data24 and use the learnt θ to decide whether two words rhyme.25
Table 2 details the rhyming results.",5.1.3 Rhyme Model,[0],[0]
"The rhyme model performs very strongly at F1 > 0.90, well above both baselines.",5.1.3 Rhyme Model,[0],[0]
"Rhyme-EM performs poorly because it operates at the word level (i.e. it ignores character/orthographic information) and hence does not generalise well to unseen words and word pairs.26
To better understand the errors qualitatively, we present a list of word pairs with their predicted cosine similarity in Table 3.",5.1.3 Rhyme Model,[0],[0]
Examples on the left side are rhyming word pairs as determined by the CMU dictionary; right are non-rhyming pairs.,5.1.3 Rhyme Model,[0],[0]
"Looking at the rhyming word pairs (left), it appears that these words tend not to share any wordending characters.",5.1.3 Rhyme Model,[0],[0]
"For the non-rhyming pairs, we spot several CMU errors: (sire, ire) and (queen, been) clearly rhyme.",5.1.3 Rhyme Model,[0],[0]
"Following Hopkins and Kiela (2017), we present a pair of quatrains (one machine-generated and one human-written, in random order) to crowd workers on CrowdFlower, and ask them to guess which is the human-written poem.",5.2.1 Crowdworker Evaluation,[0],[0]
"Generation quality is estimated by computing the accuracy of workers at correctly identifying the human-written poem (with lower values indicate better results for the model).
",5.2.1 Crowdworker Evaluation,[0],[0]
"We generate 50 quatrains each for LM, LM∗∗ and LM∗∗+PM+RM (150 in total), and as a control, generate 30 quatrains with LM trained for one epoch.",5.2.1 Crowdworker Evaluation,[0],[0]
An equal number of human-written quatrains was sampled from the training partition.,5.2.1 Crowdworker Evaluation,[0],[0]
"A HIT contained 5 pairs of poems (of which one is a control), and workers were paid $0.05 for each HIT.",5.2.1 Crowdworker Evaluation,[0],[0]
"Workers who failed to identify the human-written poem in the control pair reliably (minimum accuracy = 70%) were removed by CrowdFlower automati-
24We use the original authors’ implementation: https: //github.com/jvamvas/rhymediscovery.
",5.2.1 Crowdworker Evaluation,[0],[0]
"25A word pair is judged to rhyme if θw1,w2 > 0.02; the threshold (0.02) is selected based on development performance.
",5.2.1 Crowdworker Evaluation,[0],[0]
"26Word pairs that did not co-occur in a poem in the training data have rhyme strength of zero.
cally, and they were restricted to do a maximum of 3 HITs.",5.2.1 Crowdworker Evaluation,[0],[0]
"To dissuade workers from using search engines to identify real poems, we presented the quatrains as images.
",5.2.1 Crowdworker Evaluation,[0],[0]
Accuracy is presented in Table 4.,5.2.1 Crowdworker Evaluation,[0],[0]
"We see a steady decrease in accuracy (= improvement in model quality) from LM to LM∗∗ to LM∗∗+PM+RM, indicating that each model generates quatrains that are less distinguishable from human-written ones.",5.2.1 Crowdworker Evaluation,[0],[0]
"Based on the suspicion that workers were using rhyme to judge the poems, we tested a second model, LM∗∗+RM, which is the full model without the pentameter component.",5.2.1 Crowdworker Evaluation,[0],[0]
"We found identical accuracy (0.532), confirming our suspicion that crowd workers depend on only rhyme in their judgements.",5.2.1 Crowdworker Evaluation,[0],[0]
These observations demonstrate that meter is largely ignored by lay persons in poetry evaluation.,5.2.1 Crowdworker Evaluation,[0],[0]
"To better understand the qualitative aspects of our generated quatrains, we asked an English literature expert (a Professor of English literature at a major English-speaking university; the last author of this paper) to directly rate 4 aspects: meter, rhyme, readability and emotion (i.e. amount of emotion the poem evokes).",5.2.2 Expert Judgement,[0],[0]
All are rated on an ordinal scale between 1 to 5 (1 = worst; 5 = best).,5.2.2 Expert Judgement,[0],[0]
"In total, 120 quatrains were annotated, 30 each for LM, LM∗∗, LM∗∗+PM+RM, and human-written poems (Human).",5.2.2 Expert Judgement,[0],[0]
The expert was blind to the source of each poem.,5.2.2 Expert Judgement,[0],[0]
"The mean and standard deviation of the ratings are presented in Table 5.
",5.2.2 Expert Judgement,[0],[0]
"We found that our full model has the highest ratings for both rhyme and meter, even higher than
human poets.",5.2.2 Expert Judgement,[0],[0]
"This might seem surprising, but in fact it is well established that real poets regularly break rules of form to create other effects (Adams, 1997).",5.2.2 Expert Judgement,[0],[0]
"Despite excellent form, the output of our model can easily be distinguished from humanwritten poetry due to its lower emotional impact and readability.",5.2.2 Expert Judgement,[0],[0]
"In particular, there is evidence here that our focus on form actually hurts the readability of the resulting poems, relative even to the simpler language models.",5.2.2 Expert Judgement,[0],[0]
"Another surprise is how well simple language models do in terms of their grasp of meter: in this expert evaluation, we see only marginal benefit as we increase the sophistication of the model.",5.2.2 Expert Judgement,[0],[0]
"Taken as a whole, this evaluation suggests that future research should look beyond forms, towards the substance of good poetry.",5.2.2 Expert Judgement,[0],[0]
"We propose a joint model of language, meter and rhyme that captures language and form for modelling sonnets.",6 Conclusion,[0],[0]
"We provide quantitative analyses for each component, and assess the quality of generated poems using judgements from crowdworkers and a literature expert.",6 Conclusion,[0],[0]
"Our research reveals that vanilla LSTM language model captures meter implicitly, and our proposed rhyme model performs exceptionally well.",6 Conclusion,[0],[0]
"Machine-generated generated poems, however, still underperform in terms of readability and emotion.",6 Conclusion,[0],[0]
"In this paper, we propose a joint architecture that captures language, rhyme and meter for sonnet modelling.",abstractText,[0],[0]
We assess the quality of generated poems using crowd and expert judgements.,abstractText,[0],[0]
"The stress and rhyme models perform very well, as generated poems are largely indistinguishable from human-written poems.",abstractText,[0],[0]
"Expert evaluation, however, reveals that a vanilla language model captures meter implicitly, and that machine-generated poems still underperform in terms of readability and emotion.",abstractText,[0],[0]
"Our research shows the importance expert evaluation for poetry generation, and that future research should look beyond rhyme/meter and focus on poetic language.",abstractText,[0],[0]
"Deep-speare: A joint neural model of poetic language, meter and rhyme",title,[0],[0]
The composition of polyphonic chorale music in the style of J.S. Bach has represented a major challenge in automatic music composition over the last decades.,1. Introduction,[0],[0]
"The corpus of the chorale harmonizations by Johann Sebastian Bach is remarkable by its homogeneity and its size (389 chorales in (Bach, 1985)).",1. Introduction,[0],[0]
"All these short pieces (approximately one minute long) are written for a four-part chorus (soprano, alto, tenor and bass) using similar compositional principles: the composer takes a well-known (at that time) melody from a Lutheran hymn and harmonizes it i.e. the three lower parts (alto, tenor and bass) accompanying the soprano (the highest part) are composed, see Fig.1 for an example.
",1. Introduction,[0],[0]
"1LIP6, Université Pierre et Marie Curie 2Sony CSL, Paris 3Sony CSL, Japan.",1. Introduction,[0],[0]
"Correspondence to: Gaëtan Hadjeres <gaetan.hadjeres@etu.upmc.fr>, François",1. Introduction,[0],[0]
"Pachet <pachetcsl@gmail.com>, Frank Nielsen <Frank.Nielsen@acm.org>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Moreover, since the aim of reharmonizing a melody is to give more power or new insights to its text, the lyrics have to be understood clearly.",1. Introduction,[0],[0]
"We say that voices are in homophony, i.e. they articulate syllables simultaneously.",1. Introduction,[0],[0]
"This implies characteristic rhythms, variety of harmonic ideas as well as characteristic melodic movements which make the style of these chorale compositions easily distinguishable, even for non experts.
",1. Introduction,[0],[0]
"The difficulty, from a compositional point of view comes from the intricate interplay between harmony (notes sounding at the same time) and voice movements (how a single voice evolves through time).",1. Introduction,[0],[0]
"Furthermore, each voice has its own “style” and its own coherence.",1. Introduction,[0],[0]
"Finding a chorale-like reharmonization which combines Bach-like harmonic progressions with musically interesting melodic movements is a problem which often takes years of practice for musicians.
",1. Introduction,[0],[0]
"From the point of view of automatic music generation, the first solution to this apparently highly combinatorial problem was proposed by (Ebcioglu, 1988) in 1988.",1. Introduction,[0],[0]
"This problem is seen as a constraint satisfaction problem, where the system must fulfill numerous hand-crafted constraints characterizing the style of Bach.",1. Introduction,[0],[0]
It is a rule-based expert system which contains no less than 300 rules and tries to reharmonize a given melody with a generate-and-test method and intelligent backtracking.,1. Introduction,[0],[0]
"Among the short examples presented at the end of the paper, some are flawless.",1. Introduction,[0],[0]
"The drawbacks of this method are, as stated by the author, the considerable effort to generate the rule base and the fact that the harmonizations produced “do not sound like Bach, except for occasional Bachian patterns and cadence formulas.”",1. Introduction,[0],[0]
"In our opinion, the requirement of an expert knowledge implies a lot of subjective choices.
",1. Introduction,[0],[0]
"A neural-network-based solution was later developed by (Hild et al., 1992).",1. Introduction,[0],[0]
"This method relies on several neural networks, each one trained for solving a specific task: a harmonic skeleton is first computed then refined and ornamented.",1. Introduction,[0],[0]
"A similar approach is adopted in (Allan & Williams, 2005), but uses Hidden Markov Models (HMMs) instead of neural networks.",1. Introduction,[0],[0]
"Chords are represented as lists of intervals and form the states of the Markov mod-
2https://www.youtube.com/watch?v=",1. Introduction,[0],[0]
"73WF0M99vlg
els.",1. Introduction,[0],[0]
These approaches produce interesting results even if they both use expert knowledge and bias the generation by imposing their compositional process.,1. Introduction,[0],[0]
"In (Whorley et al., 2013; Whorley & Conklin, 2016), authors elaborate on those methods by introducing multiple viewpoints and variations on the sampling method (generated sequences which violate “rules of harmony” are put aside for instance).",1. Introduction,[0],[0]
"However, this approach does not produce a convincing chorale-like texture, rhythmically as well as harmonically and the resort to hand-crafted criteria to assess the quality of the generated sequences might rule out many musically-interesting solutions.
",1. Introduction,[0],[0]
"Recently, agnostic approaches (requiring no knowledge about harmony, Bach’s style or music) using neural networks have been investigated with promising results.",1. Introduction,[0],[0]
"In (Boulanger-Lewandowski et al., 2012), chords are modeled with Restricted Boltzmann Machines (RBMs).",1. Introduction,[0],[0]
Their temporal dependencies are learned using Recurrent Neural Networks (RNNs).,1. Introduction,[0],[0]
"Variations of these architectures based on Long Short-Term Memory (LSTM) units ((Hochreiter & Schmidhuber, 1997; Mikolov et al., 2014)) or GRUs (Gated Recurrent Units) have been developed by (Lyu et al., 2015) and (Chung et al., 2014) respectively.",1. Introduction,[0],[0]
"However, these models which work on piano roll representations of the music are too general to capture the specificity of Bach chorales.",1. Introduction,[0],[0]
"Also, a major drawback is their lack of flexibility.",1. Introduction,[0],[0]
Generation is performed from left to right.,1. Introduction,[0],[0]
A user cannot interact with the system: it is impossible to do reharmonization for instance which is the essentially how the corpus of Bach chorales was composed.,1. Introduction,[0],[0]
"Moreover, their invention capacity and non-plagiarism abilities are not demonstrated.
",1. Introduction,[0],[0]
"A method that addresses the rigidity of sequential generation in music was first proposed in (Sakellariou et al., 2015; Sakellariou et al., 2016) for monophonic music and later generalized to polyphony in (Hadjeres et al., 2016).",1. Introduction,[0],[0]
"These approaches advocate for the use of Gibbs sampling as a generation process in automatic music composition.
",1. Introduction,[0],[0]
"The most recent advances in chorale harmonization is arguably the BachBot model (Liang, 2016), a LSTMbased approach specifically designed to deal with Bach
chorales.",1. Introduction,[0],[0]
This approach relies on little musical knowledge (all chorales are transposed in a common key) and is able to produce high-quality chorale harmonizations.,1. Introduction,[0],[0]
"However, compared to our approach, this model is less general (produced chorales are all in the C key for instance) and less flexible (only the soprano can be fixed).",1. Introduction,[0],[0]
"Similarly to our work, the authors evaluate their model with an online Turing test to assess the efficiency of their model.",1. Introduction,[0],[0]
"They also take into account the fermata symbols (Fig. 2) which are indicators of the structure of the chorales.
",1. Introduction,[0],[0]
"In this paper we introduce DeepBach, a dependency network (Heckerman et al., 2000) capable of producing musically convincing four-part chorales in the style of Bach by using a Gibbs-like sampling procedure.",1. Introduction,[0],[0]
"Contrary to models based on RNNs, we do not sample from left to right which allows us to enforce positional, unary user-defined constraints such as rhythm, notes, parts, chords and cadences.",1. Introduction,[0],[0]
"DeepBach is able to generate coherent musical phrases and provides, for instance, varied reharmonizations of melodies without plagiarism.",1. Introduction,[0],[0]
"Its core features are its speed, the possible interaction with users and the richness of harmonic ideas it proposes.",1. Introduction,[0],[0]
"Its efficiency opens up new ways of composing Bach-like chorales for non experts in an interactive manner similarly to what is proposed in (Papadopoulos et al., 2016) for leadsheets.
",1. Introduction,[0],[0]
In Sect.,1. Introduction,[0],[0]
2 we present the DeepBach model for four-part chorale generation.,1. Introduction,[0],[0]
We discuss in Sect.,1. Introduction,[0],[0]
3 the results of an experimental study we conducted to assess the quality of our model.,1. Introduction,[0],[0]
"Finally, we provide generated examples in Sect.",1. Introduction,[0],[0]
4.3 and elaborate on the possibilities offered by our interactive music composition editor in Sect.,1. Introduction,[0],[0]
4.,1. Introduction,[0],[0]
All examples can be heard on the accompanying web page3 and the code of our implementation is available on GitHub4.,1. Introduction,[0],[0]
"Even if our presentation focuses on Bach chorales, this model has been successfully applied to other styles and composers including Monteverdi five-voice madrigals to Palestrina masses.
",1. Introduction,[0],[0]
"3https://sites.google.com/site/ deepbachexamples/
4https://github.com/Ghadjeres/DeepBach",1. Introduction,[0],[0]
In this paper we introduce a generative model which takes into account the distinction between voices.,2. DeepBach,[0],[0]
Sect.,2. DeepBach,[0],[0]
2.1 presents the data representation we used.,2. DeepBach,[0],[0]
This representation is both fitted for our sampling procedure and more accurate than many data representation commonly used in automatic music composition.,2. DeepBach,[0],[0]
Sect.,2. DeepBach,[0],[0]
2.2 presents the model’s architecture and Sect.,2. DeepBach,[0],[0]
2.3 our generation method.,2. DeepBach,[0],[0]
"Finally, Sect. 2.4 provides implementation details and indicates how we preprocessed the corpus of Bach chorale harmonizations.",2. DeepBach,[0],[0]
We use MIDI pitches to encode notes and choose to model voices separately.,2.1.1. NOTES AND VOICES,[0],[0]
"We consider that only one note can be sung at a given time and discard chorales with voice divisions.
",2.1.1. NOTES AND VOICES,[0],[0]
"Since Bach chorales only contain simple time signatures, we discretize time with sixteenth notes, which means that each beat is subdivided into four equal parts.",2.1.1. NOTES AND VOICES,[0],[0]
"Since there is no smaller subdivision in Bach chorales, there is no loss of information in this process.
",2.1.1. NOTES AND VOICES,[0],[0]
"In this setting, a voice Vi = {Vti }t is a list of notes indexed by t ∈",2.1.1. NOTES AND VOICES,[0],[0]
"[T ]5, where T is the duration piece (in sixteenth notes).",2.1.1. NOTES AND VOICES,[0],[0]
We choose to model rhythm by simply adding a hold symbol “ ” coding whether or not the preceding note is held to the list of existing notes.,2.1.2. RHYTHM,[0],[0]
"This representation is thus unambiguous, compact and well-suited to our sampling method (see Sect.",2.1.2. RHYTHM,[0],[0]
2.3.4).,2.1.2. RHYTHM,[0],[0]
The music sheet (Fig. 1b) conveys more information than only the notes played.,2.1.3. METADATA,[0],[0]
"We can cite:
• the lyrics,
• the key signature,
• the time signature,
• the beat index,
• an implicit metronome (on which subdivision of the beat the note is played),
• the fermata symbols (see Fig. 2), 5We adopt the standard notation [N ] to denote the set of inte-
gers {1, . . .",2.1.3. METADATA,[0],[0]
", N} for any integer N .
",2.1.3. METADATA,[0],[0]
"In the following, we will only take into account the fermata symbols, the subdivision indexes and the current key signature.",2.1.3. METADATA,[0],[0]
"To this end, we introduce:
•",2.1.3. METADATA,[0],[0]
"The fermata list F that indicates if there is a fermata symbol, see Fig. 2, over the current note, it is a Boolean value.",2.1.3. METADATA,[0],[0]
"If a fermata is placed over a note on the music sheet, we consider that it is active for all time indexes within the duration of the note.
",2.1.3. METADATA,[0],[0]
•,2.1.3. METADATA,[0],[0]
The subdivision list S that contains the subdivision indexes of the beat.,2.1.3. METADATA,[0],[0]
It is an integer between 1 and 4: there is no distinction between beats in a bar so that our model is able to deal with chorales with three and four beats per measure.,2.1.3. METADATA,[0],[0]
"We represent a chorale as a couple
(V,M) (1)
composed of voices and metadata.",2.1.4. CHORALE,[0],[0]
"For Bach chorales, V is a list of 4 voices Vi for i ∈",2.1.4. CHORALE,[0],[0]
"[4] (soprano, alto, tenor and bass) andM a collection of metadata lists (F and S).
",2.1.4. CHORALE,[0],[0]
Our choices are very general and do not involve expert knowledge about harmony or scales but are only mere observations of the corpus.,2.1.4. CHORALE,[0],[0]
The list S acts as a metronome.,2.1.4. CHORALE,[0],[0]
The list F is added since fermatas in Bach chorales indicate the end of each musical phrase.,2.1.4. CHORALE,[0],[0]
The use of fermata to this end is a specificity of Bach chorales that we want to take advantage of.,2.1.4. CHORALE,[0],[0]
We choose to consider the metadata sequences in M as given.,2.2. Model Architecture,[0],[0]
"For clarity, we suppose in this section that our dataset is composed of only one chorale written as in Eq. 1 of size T .",2.2. Model Architecture,[0],[0]
"We define a dependency network on the finite set of variables V = {V ti } by specifying a set of conditional probability distributions (parametrized by parameter θi,t){
pi,t(V t i |V\i,t,M, θi,t) } i∈[4],t∈[T ] , (2)
where Vti indicates the note of voice i at time index t and V\i,t all variables in V except from the variable Vti .",2.2. Model Architecture,[0],[0]
"As we want our model to be time invariant so that we can apply it to sequences of any size, we share the parameters between all conditional probability distributions on variables lying in the same voice, i.e.
θi := θi,t, pi := pi,t ∀t ∈",2.2. Model Architecture,[0],[0]
"[T ].
Finally, we fit each of these conditional probability distributions on the data by maximizing the log-likelihood.",2.2. Model Architecture,[0],[0]
"Due to weight sharing, this amounts to solving four classification problems of the form:
max θi ∑ t log pi(Vti |V\i,t,M, θi), for i ∈",2.2. Model Architecture,[0],[0]
"[4], (3)
where the aim is to predict a note knowing the value of its neighboring notes, the subdivision of the beat it is on and the presence of fermatas.",2.2. Model Architecture,[0],[0]
"The advantage with this formulation is that each classifier has to make predictions within a small range of notes whose ranges correspond to the notes within the usual voice ranges (see 2.4).
",2.2. Model Architecture,[0],[0]
"For accurate predictions and in order to take into account the sequential aspect of the data, each classifier is modeled using four neural networks: two Deep Recurrent Neural Networks (Pascanu et al., 2013), one summing up past information and another summing up information coming from the future together with a non-recurrent neural network for notes occurring at the same time.",2.2. Model Architecture,[0],[0]
Only the last output from the uppermost RNN layer is kept.,2.2. Model Architecture,[0],[0]
"These three outputs are then merged and passed as the input of a fourth neural network whose output is pi(Vti |V\i,t,M, θ).",2.2. Model Architecture,[0],[0]
Figure 4 shows a graphical representation for one of these models.,2.2. Model Architecture,[0],[0]
Details are provided in Sect.,2.2. Model Architecture,[0],[0]
2.4.,2.2. Model Architecture,[0],[0]
These choices of architecture somehow match real compositional practice on Bach chorales.,2.2. Model Architecture,[0],[0]
"Indeed, when reharmonizing a given melody, it is often simpler to start from the cadence and write music “backwards.”",2.2. Model Architecture,[0],[0]
Generation in dependency networks is performed using the pseudo-Gibbs sampling procedure.,2.3.1. ALGORITHM,[0],[0]
"This Markov Chain
Monte Carlo (MCMC) algorithm is described in Alg.1.",2.3.1. ALGORITHM,[0],[0]
"It is similar to the classical Gibbs sampling procedure (Geman & Geman, 1984) on the difference that the conditional distributions are potentially incompatible (Chen & Ip, 2015).",2.3.1. ALGORITHM,[0],[0]
This means that the conditional distributions of Eq.,2.3.1. ALGORITHM,[0],[0]
(2) do not necessarily comes from a joint distribution p(V) and that the theoretical guarantees that the MCMC converges to this stationary joint distribution vanish.,2.3.1. ALGORITHM,[0],[0]
"We experimentally verified that it was indeed the case by checking that the Markov Chain of Alg.1 violates Kolmogorov’s criterion (Kelly, 2011): it is thus not reversible and cannot converge to a joint distribution whose conditional distributions match the ones used for sampling.
",2.3.1. ALGORITHM,[0],[0]
"However, this Markov chain converges to another stationary distribution and applications on real data demonstrated that this method yielded accurate joint probabilities, especially when the inconsistent probability distributions are learned from data (Heckerman et al., 2000).",2.3.1. ALGORITHM,[0],[0]
"Furthermore, nonreversible MCMC algorithms can in particular cases be better at sampling that reversible Markov Chains (Vucelja, 2014).",2.3.1. ALGORITHM,[0],[0]
The advantage of this method is that we can enforce userdefined constraints by tweaking Alg.,2.3.2. FLEXIBILITY OF THE SAMPLING PROCEDURE,[0],[0]
"1:
• instead of choosing voice i from 1 to 4 we can choose to fix the soprano and only resample voices from 2, 3
Algorithm 1 Pseudo-Gibbs sampling 1: Input: Chorale length L, metadataM containing lists
of length L, probability distributions (p1, p2, p3, p4), maximum number of iterations M 2: Create four lists V = (V1,V2,V3,V4) of length L 3: {The lists are initialized with random notes drawn from
the ranges of the corresponding voices (sampled uniformly or from the marginal distributions of the notes)}
4: for m from 1 to M do 5: Choose voice i uniformly between 1 and 4 6: Choose time t uniformly between 1 and L 7: Re-sample Vti from pi(Vti |V\i,t,M, θi) 8: end for 9: Output: V = (V1,V2,V3,V4)
and 4 in step (3) in order to provide reharmonizations of the fixed melody
• we can choose the fermata list F in order to impose end of musical phrases at some places
• more generally, we can impose any metadata
• for any t and any i, we can fix specific subsets Rti of notes within the range of voice i.",2.3.2. FLEXIBILITY OF THE SAMPLING PROCEDURE,[0],[0]
"We then restrict ourselves to some specific chorales by re-sampling Vti from
pi(Vti |V\i,t,M, θi,Vti ∈",2.3.2. FLEXIBILITY OF THE SAMPLING PROCEDURE,[0],[0]
"Rti)
at step (5).",2.3.2. FLEXIBILITY OF THE SAMPLING PROCEDURE,[0],[0]
"This allows us for instance to fix rhythm (since the hold symbol is considered as a note), impose some chords in a soft manner or restrict the vocal ranges.",2.3.2. FLEXIBILITY OF THE SAMPLING PROCEDURE,[0],[0]
Note that it is possible to make generation faster by making parallel Gibbs updates on GPU.,2.3.3. PERFORMANCE,[0],[0]
Steps (3) to (5) from Alg. 1 can be run simultaneously to provide significant speedups.,2.3.3. PERFORMANCE,[0],[0]
"Even if it is known that this approach is biased (De Sa et al., 2016) (since we can update simultaneously variables which are not conditionally independent), we experimentally observed that for small batch sizes (16 or 32), DeepBach still generates samples of great musicality while running ten times faster than the sequential version.",2.3.3. PERFORMANCE,[0],[0]
"This allows DeepBach to generate chorales in a few seconds.
",2.3.3. PERFORMANCE,[0],[0]
"It is also possible to use the hard-disk-configurations generation algorithm (Alg.2.9 in (Krauth, 2006)) to appropriately choose all the time indexes at which we parallelly resample so that:
• every time index is at distance at least δ from the other time indexes
• configurations of time indexes satisfying the relation above are equally sampled.
",2.3.3. PERFORMANCE,[0],[0]
This trick allows to assert that we do not update simultaneously a variable and its local context.,2.3.3. PERFORMANCE,[0],[0]
We emphasize on this section the importance of our particular choice of data representation with respect to our sampling procedure.,2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"The fact that we obtain great results using pseudo-Gibbs sampling relies exclusively on our choice to integrate the hold symbol into the list of notes.
",2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"Indeed, Gibbs sampling fails to sample the true joint distribution p(V|M, θ) when variables are highly correlated, creating isolated regions of high probability states in which the MCMC chain can be trapped.",2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"However, many data representations used in music modeling such as
• the piano-roll representation,
• the couple (pitch, articulation) representation where articulation is a Boolean value indicating whether or not the note is played or held,
tend to make the musical data suffer from this drawback.
",2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"As an example, in the piano-roll representation, a long note is represented as the repetition of the same value over many variables.",2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"In order to only change its pitch, one needs to change simultaneously a large number of variables (which is exponentially rare) while this is achievable with only one variable change with our representation.",2.3.4. IMPORTANCE OF THE DATA REPRESENTATION,[0],[0]
"We implemented DeepBach using Keras (Chollet, 2015) with the Tensorflow (Abadi et al., 2015) backend.",2.4. Implementation Details,[0],[0]
"We used the database of chorale harmonizations by J.S. Bach included in the music21 toolkit (Cuthbert & Ariza, 2010).",2.4. Implementation Details,[0],[0]
"After removing chorales with instrumental parts and chorales containing parts with two simultaneous notes (bass parts sometimes divide for the last chord), we ended up with 352 pieces.",2.4. Implementation Details,[0],[0]
"Contrary to other approaches which transpose all chorales to the same key (usually in C major or A minor), we choose to augment our dataset by adding all chorale transpositions which fit within the vocal ranges defined by the initial corpus.",2.4. Implementation Details,[0],[0]
This gives us a corpus of 2503 chorales and split it between a training set (80%) and a validation set (20%).,2.4. Implementation Details,[0],[0]
"The vocal ranges contains less than 30 different pitches for each voice (21, 21, 21, 28) for the soprano, alto, tenor and bass parts respectively.
",2.4. Implementation Details,[0],[0]
"As shown in Fig. 4, we model only local interactions between a note Vti and its context (V\i,t, M) i.e. only elements with time index t between t − ∆t and t + ∆t are
taken as inputs of our model for some scope ∆t.",2.4. Implementation Details,[0],[0]
"This approximation appears to be accurate since musical analysis reveals that Bach chorales do not exhibit clear long-term dependencies.
",2.4. Implementation Details,[0],[0]
The reported results in Sect.,2.4. Implementation Details,[0],[0]
3 and examples in Sect.,2.4. Implementation Details,[0],[0]
4.3 were obtained with ∆t = 16.,2.4. Implementation Details,[0],[0]
"We chose as the “neural network brick” in Fig. 4 a neural network with one hidden layer of size 200 and ReLU (Nair & Hinton, 2010)",2.4. Implementation Details,[0],[0]
"nonlinearity and as the “Deep RNN brick” two stacked LSTMs (Hochreiter & Schmidhuber, 1997; Mikolov et al., 2014), each one being of size 200 (see Fig. 2 (f) in (Li & Wu, 2015)).",2.4. Implementation Details,[0],[0]
"The “embedding brick” applies the same neural network to each time slice (Vt,Mt).",2.4. Implementation Details,[0],[0]
"There are 20% dropout on input and 50% dropout after each layer.
",2.4. Implementation Details,[0],[0]
We experimentally found that sharing weights between the left and right embedding layers improved neither validation accuracy nor the musical quality of our generated chorales.,2.4. Implementation Details,[0],[0]
We evaluated the quality of our model with an online test conducted on human listeners.,3. Experimental Results,[0],[0]
"For the parameters used in our experiment, see Sect 2.4.",3.1. Setup,[0],[0]
"We compared our model with two other models: a Maximum Entropy model (MaxEnt) as in (Hadjeres et al., 2016) and a Multilayer Perceptron (MLP) model.
",3.1. Setup,[0],[0]
The Maximum Entropy model is a neural network with no hidden layer.,3.1. Setup,[0],[0]
"It is given by:
pi(Vti |V\i,t,M, Ai, bi) = Softmax(AX + b) (4)
where X is a vector containing the elements in V\i,t ∪Mt, Ai a (ni,mi) matrix and bi a vector of size mi with mi being the size of X , ni the number of notes in the voice range i and Softmax the softmax function given by
Softmax(z)j = ezj∑K k=1 e zk for j ∈",3.1. Setup,[0],[0]
"[K],
for a vector z = (z1, . . .",3.1. Setup,[0],[0]
", zK).
",3.1. Setup,[0],[0]
"The Multilayer Perceptron model we chose takes as input elements in V\i,t∪M, is a neural network with one hidden layer of size 500 and uses a ReLU (Nair & Hinton, 2010)",3.1. Setup,[0],[0]
"nonlinearity.
",3.1. Setup,[0],[0]
"All models are local and have the same scope ∆t, see Sect. 2.4.
",3.1. Setup,[0],[0]
Subjects were asked to give information about their musical expertise.,3.1. Setup,[0],[0]
"They could choose what category fits them best between:
1.",3.1. Setup,[0],[0]
"I seldom listen to classical music
2.",3.1. Setup,[0],[0]
"Music lover or musician
3.",3.1. Setup,[0],[0]
"Student in music composition or professional musician.
",3.1. Setup,[0],[0]
"The musical extracts have been obtained by reharmonizing 50 chorales from the validation set by each of the three models (MaxEnt, MLP, DeepBach).",3.1. Setup,[0],[0]
"We rendered the MIDI files using the Leeds Town Hall Organ soundfont6 and cut two extracts of 12 seconds from each chorale, which gives us 400 musical extracts for our test: 4 versions for each of the 100 melody chunks.",3.1. Setup,[0],[0]
"We chose our rendering so that the generated parts (alto, tenor and bass) can be distinctly heard and differentiated from the soprano part (which is fixed and identical for all models): in our mix, dissonances are easily heard, the velocity is the same for all notes as in a real organ performance and the sound does not decay, which is important when evaluating the reharmonization of long notes.",3.1. Setup,[0],[0]
Subjects were presented series of only one musical extract together with the binary choice “Bach” or “Computer”.,3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
Fig. 5 shows how the votes are distributed depending on the level of musical expertise of the subjects for each model.,3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
"For this experiment, 1272 people took this test, 261 with musical expertise 1, 646 with musical expertise 2 and 365 with musical expertise 3.
",3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
The results are quite clear: the percentage of “Bach” votes augment as the model’s complexity increase.,3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
"Furthermore, the distinction between computer-generated extracts and Bach’s extracts is more accurate when the level of musical expertise is higher.",3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
"When presented a DeepBach-generated
6https://www.samplephonics.com/products/ free/sampler-instruments/the-leeds-townhall-organ
extract, around 50% of the voters would judge it as composed by Bach.",3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
"We consider this to be a good score knowing the complexity of Bach’s compositions and the facility to detect badly-sounding chords even for non musicians.
",3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
We also plotted specific results for each of the 400 extracts.,3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
Fig. 6 shows for each reharmonization extract the percentage of Bach votes it collected: more than half of the DeepBach’s automatically-composed extracts has a majority of votes considering them as being composed by J.S. Bach while it is only a third for the MLP model.,3.2. Discrimination Test: “Bach or Computer” experiment,[0],[0]
We developed a plugin on top of the MuseScore music editor allowing a user to call DeepBach on any rectangular region.,4.1. Description,[0],[0]
"Even if the interface is minimal (see Fig.7), the possibilities are numerous: we can generate a chorale from scratch, reharmonize a melody and regenerate a given chord, bar or part.",4.1. Description,[0],[0]
We believe that this interplay between a user and the system can boost creativity and can interest a wide range of audience.,4.1. Description,[0],[0]
We made two major changes between the model we described for the online test and the interactive composition tool.,4.2. Adapting the model,[0],[0]
We changed the MIDI encoding of the notes to a full name encoding of the notes.,4.2.1. NOTE ENCODING,[0],[0]
"Indeed, some information is lost when reducing a music sheet to its MIDI representation since we cannot differentiate between two enharmonic
notes (notes that sound the same but that are written differently e.g. F# and Gb).",4.2.1. NOTE ENCODING,[0],[0]
"This difference in Bach chorales is unambiguous and it is thus natural to consider the full name of the notes, like C#3, Db3 or E#4.",4.2.1. NOTE ENCODING,[0],[0]
"From a machine learning point of view, these notes would appear in totally different contexts.",4.2.1. NOTE ENCODING,[0],[0]
"This improvement enables the model to generate notes with the correct spelling, which is important when we focus on the music sheet rather than on its audio rendering.",4.2.1. NOTE ENCODING,[0],[0]
We added the current key signature list K to the metadataM. This allows users to impose modulations and key changes.,4.2.2. STEERING MODULATIONS,[0],[0]
Each element Kt of this list contains the number of sharps of the estimated key for the current bar.,4.2.2. STEERING MODULATIONS,[0],[0]
It is a integer between -7 and 7.,4.2.2. STEERING MODULATIONS,[0],[0]
The current key is computed using the key analyzer algorithm from music21.,4.2.2. STEERING MODULATIONS,[0],[0]
We now provide and comment on examples of chorales generated using the DeepBach plugin.,4.3. Generation examples,[0],[0]
Our aim is to show the quality of the solutions produced by DeepBach.,4.3. Generation examples,[0],[0]
"For these examples, no note was set by hand and we asked DeepBach to generate regions longer than one bar and covering all four voices.
",4.3. Generation examples,[0],[0]
"Despite some compositional errors like parallel octaves, the musical analysis reveals that the DeepBach compositions reproduce typical Bach-like patterns, from characteristic cadences to the expressive use of nonchord tones.",4.3. Generation examples,[0],[0]
As discussed in Sect.,4.3. Generation examples,[0],[0]
"4.2, DeepBach also learned the correct spelling of the notes.",4.3. Generation examples,[0],[0]
"Among examples in Fig. 8, examples (a) and (b) share the same metadata (S,F and K).",4.3. Generation examples,[0],[0]
"This demonstrates that even with fixed metadata it is possible to generate contrasting chorales.
",4.3. Generation examples,[0],[0]
"Since we aimed at producing music that could not be distinguished from actual Bach compositions, we had all provided extracts sung by the Wishful Singing choir.",4.3. Generation examples,[0],[0]
These audio files can be heard on the accompanying website.,4.3. Generation examples,[0],[0]
"We described DeepBach, a probabilistic model together with a sampling method which is flexible, efficient and provides musically convincing results even to the ears of professionals.",5. Discussion and future work,[0],[0]
"The strength of our method is the possibility to let users impose unary constraints, which is a feature often neglected in probabilistic models of music.",5. Discussion and future work,[0],[0]
"Through our graphical interface, the composition of polyphonic music becomes accessible to non-specialists.",5. Discussion and future work,[0],[0]
The playful interaction between the user and this system can boost creativity and help explore new ideas quickly.,5. Discussion and future work,[0],[0]
"We believe that this approach could form a starting point for a novel com-
positional process that could be described as a constructive dialogue between a human operator and the computer.",5. Discussion and future work,[0],[0]
This method is general and its implementation simple.,5. Discussion and future work,[0],[0]
"It is not only applicable to Bach chorales but embraces a wider range of polyphonic music.
",5. Discussion and future work,[0],[0]
"Future work aims at refining our interface, speeding up
generation and handling datasets with small corpora.",5. Discussion and future work,[0],[0]
"This paper introduces DeepBach, a graphical model aimed at modeling polyphonic music and specifically hymn-like pieces.",abstractText,[0],[0]
"We claim that, after being trained on the chorale harmonizations by Johann Sebastian Bach, our model is capable of generating highly convincing chorales in the style of Bach.",abstractText,[0],[0]
DeepBach’s strength comes from the use of pseudo-Gibbs sampling coupled with an adapted representation of musical data.,abstractText,[0],[0]
This is in contrast with many automatic music composition approaches which tend to compose music sequentially.,abstractText,[0],[0]
"Our model is also steerable in the sense that a user can constrain the generation by imposing positional constraints such as notes, rhythms or cadences in the generated score.",abstractText,[0],[0]
We also provide a plugin on top of the MuseScore music editor making the interaction with DeepBach easy to use.,abstractText,[0],[0]
DeepBach: a Steerable Model for Bach Chorales Generation ,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1125–1135 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
User comments play a central role in social media and online discussion fora.,1 Introduction,[0],[0]
"News portals and blogs often also allow their readers to comment to get feedback, engage their readers, and build customer loyalty.1 User comments, however, and more generally user content can also be abusive (e.g., bullying, profanity, hate speech) (Cheng et al., 2015).",1 Introduction,[0],[0]
"Social media are under pressure to combat abusive content, but so far rely mostly on user reports and tools that detect frequent words and phrases of reported posts.2 Wulczyn et al. (2017) estimated that only 17.9% of personal attacks in Wikipedia discussions were followed by moderator actions.",1 Introduction,[0],[0]
"News portals also
1 See, for example, http://niemanreports.org/ articles/the-future-of-comments/.
2 Consult, for example, https://www.facebook.",1 Introduction,[0],[0]
com/help/131671940241729 and https://www.,1 Introduction,[0],[0]
"theguardian.com/technology/2017/feb/07/ twitter-abuse-harassment-crackdown.
suffer from abusive user comments, which damage their reputations and make them liable to fines, e.g., when hosting comments encouraging illegal actions.",1 Introduction,[0],[0]
"They often employ moderators, who are frequently overwhelmed, however, by the volume and abusiveness of comments.3 Readers are disappointed when non-abusive comments do not appear quickly online because of moderation delays.",1 Introduction,[0],[0]
"Smaller news portals may be unable to employ moderators, and some are forced to shut down their comments sections entirely.
",1 Introduction,[0],[0]
"We examine how deep learning (Goodfellow et al., 2016; Goldberg, 2016, 2017) can be employed to moderate user comments.",1 Introduction,[0],[0]
We experiment with a new dataset of approx.,1 Introduction,[0],[0]
"1.6M manually moderated (accepted or rejected) user comments from a Greek sports news portal (called Gazzetta), which we make publicly available.4 This is one of the largest publicly available datasets of moderated user comments.",1 Introduction,[0],[0]
We also provide word embeddings pre-trained on 5.2M comments from the same portal.,1 Introduction,[0],[0]
"Furthermore, we experiment on the ‘attacks’ dataset of Wulczyn et al. (2017), approx.",1 Introduction,[0],[0]
"115K English Wikipedia talk page comments labeled as containing personal attacks or not.
",1 Introduction,[0],[0]
"In a fully automatic scenario, there is no moderator and a system accepts or rejects comments.",1 Introduction,[0],[0]
"Although this scenario may be the only available one, e.g., when news portals cannot afford moderators, it is unrealistic to expect that fully automatic moderation will be perfect, because abusive comments may involve irony, sarcasm, harassment without profane phrases etc., which are particularly difficult for a machine to detect.",1 Introduction,[0],[0]
"When moderators are available, it is more realistic to develop semi-
3See, e.g., https://www.wired.com/2017/04/ zerochaos-google-ads-quality-raters and https://goo.gl/89M2bI.
4The portal is http://www.gazzetta.gr/. Instructions to download the dataset will become available at http://nlp.cs.aueb.gr/software.html.
1125
automatic systems aiming to assist, rather than replace the moderators, a scenario that has not been considered in previous work.",1 Introduction,[0],[0]
"In this case, comments for which the system is uncertain (Fig. 1) are shown to a moderator to decide; all other comments are accepted or rejected by the system.",1 Introduction,[0],[0]
"We discuss how moderation systems can be tuned, depending on the availability and workload of the moderators.",1 Introduction,[0],[0]
"We also introduce additional evaluation measures for the semi-automatic scenario.
",1 Introduction,[0],[0]
"On both datasets (Gazzetta and Wikipedia comments) and for both scenarios (automatic, semiautomatic), we show that a recurrent neural network (RNN) outperforms the system of Wulczyn et al. (2017), the previous state of the art for comment moderation, which employed logistic regression or a multi-layer Perceptron (MLP), and represented each comment as a bag of (character or word) n",1 Introduction,[0],[0]
-grams.,1 Introduction,[0],[0]
We also propose an attention mechanism that improves the overall performance of the RNN.,1 Introduction,[0],[0]
"Our attention mechanism differs from most previous ones (Bahdanau et al., 2015; Luong et al., 2015) in that it is used in a classification setting, where there is no previously generated output subsequence to drive the attention, unlike sequence-to-sequence models (Sutskever et al., 2014).",1 Introduction,[0],[0]
"In that sense, our attention is similar to that of of Yang et al. (2016), but our attention mechanism is a deeper MLP and it is only applied to words, whereas Yang et al. also have a second attention mechanism that assigns attention scores to entire sentences.",1 Introduction,[0],[0]
"In effect, our attention detects the words of a comment that affect most the classification decision (accept, reject), by examining them in the context of the particular comment.
",1 Introduction,[0],[0]
"Although our attention mechanism does not always improve the performance of the RNN, it has the additional advantage of allowing the RNN to highlight suspicious words that a moderator could consider to decide more quickly if a comment should be accepted or rejected.",1 Introduction,[0],[0]
"The highlighting
comes for free, i.e., the training data do not contain highlighted words.",1 Introduction,[0],[0]
"We also show that words highlighted by the attention mechanism correlate well with words that moderators would highlight.
",1 Introduction,[0],[0]
Our main contributions are: (i),1 Introduction,[0],[0]
We release a dataset of 1.6M moderated user comments.,1 Introduction,[0],[0]
"(ii) We introduce a novel, deep, classification-specific attention mechanism and we show that an RNN with our attention mechanism outperforms the previous state of the art in user comment moderation.",1 Introduction,[0],[0]
"(iii) Unlike previous work, we also consider a semiautomatic scenario, along with threshold tuning and evaluation measures for it.",1 Introduction,[0],[0]
"(iv) We show that the attention mechanism can automatically highlight suspicious words for free, without manually highlighting words in the training data.",1 Introduction,[0],[0]
"We first discuss the datasets we used, to help acquaint the reader with the problem.",2 Datasets,[0],[0]
There are approx.,2.1 Gazzetta comments,[0],[0]
"1.45M training comments (covering Jan. 1, 2015 to Oct. 6, 2016) in the Gazzetta dataset; we call them G-TRAIN-L (Table 1).",2.1 Gazzetta comments,[0],[0]
"Some experiments use only the first 100K comments of G-TRAIN-L, called G-TRAIN-S. An additional set of 60,900 comments (Oct. 7 to Nov. 11, 2016) was split to development (G-DEV, 29,700 comments), large test (G-TEST-L, 29,700), and small test set (G-TEST-S, 1,500).",2.1 Gazzetta comments,[0],[0]
"Gazzetta’s moderators (2 full-time, plus journalists occasionally helping) are occasionally instructed to be stricter (e.g., during violent events).",2.1 Gazzetta comments,[0],[0]
"To get a more accurate view of performance in normal situtations, we manually re-moderated (labeled as ‘accept’ or ‘reject’)",2.1 Gazzetta comments,[0],[0]
"the comments of G-TEST-S, producing G-TEST-SR.",2.1 Gazzetta comments,[0],[0]
The reject ratio is approx.,2.1 Gazzetta comments,[0],[0]
"30% in all subsets, except for G-TEST-S-R where it drops to 22%, because there are no occasions where the moderators were instructed to be stricter in G-TEST-S-R.
Each G-TEST-S-R comment was re-moderated by five annotators.",2.1 Gazzetta comments,[0],[0]
"Krippendorff’s (2004) alpha was 0.4762, close to the value (0.45) reported by Wulczyn et al. (2017) for the Wikipedia ‘attacks’ dataset.",2.1 Gazzetta comments,[0],[0]
"Using Cohen’s Kappa (Cohen, 1960), the mean pairwise agreement was 0.4749.",2.1 Gazzetta comments,[0],[0]
The mean pairwise percentage of agreement (% of comments each pair of annotators agreed on) was 81.33%.,2.1 Gazzetta comments,[0],[0]
"Cohen’s Kappa and Krippendorff’s alpha lead to lower scores, because they account for agreement by chance, which is high when there is class imbalance (22% reject, 78% accept in G-TEST-S-R).
",2.1 Gazzetta comments,[0],[0]
"During the re-moderation of G-TEST-S-R, the annotators were also asked to highlight snippets they considered suspicious, i.e., words or phrases that could lead a moderator to consider rejecting each comment.5",2.1 Gazzetta comments,[0],[0]
"We also asked the annotators to classify each snippet into one of the following categories: calumniation (e.g., false accusations), discrimination (e.g., racism), disrespect (e.g., looking down at a profession), hooliganism (e.g., calling for violence), insult (e.g., making fun of appearance), irony, swearing, threat, other.",2.1 Gazzetta comments,[0],[0]
"Figure 2 shows how many comments of G-TEST-S-R contained at least one snippet of each category, according to the majority of annotators; e.g., a comment counts as containing irony if at least 3 annotators annotated it with an irony snippet (not necessarily the same).",2.1 Gazzetta comments,[0],[0]
The gold class of each comment (accept or reject) is determined by the majority of the annotators.,2.1 Gazzetta comments,[0],[0]
"Irony and disrespect are particularly frequent in both classes, followed by calumniation, swearing, hooliganism, insults.",2.1 Gazzetta comments,[0],[0]
"Notice that comments that contain irony, disrespect etc. are not necessarily rejected.",2.1 Gazzetta comments,[0],[0]
"They are, however, more likely in the rejected class, considering that the accepted comments are 2.5 times more
5Treating snippet overlaps as agreements, the mean pairwise Dice coefficient for snippet highlighting was 50.03%.
",2.1 Gazzetta comments,[0],[0]
than the rejected ones (78% vs. 22%).,2.1 Gazzetta comments,[0],[0]
"We also provide 300-dimensional word embeddings, pre-trained on approx.",2.1 Gazzetta comments,[0],[0]
"5.2M comments (268M tokens) from Gazzetta using WORD2VEC (Mikolov et al., 2013a,b).6 This larger dataset cannot be used to directly train classifiers, because most of its comments are from a period (before 2015) when Gazzetta did not employ moderators.",2.1 Gazzetta comments,[0],[0]
"The Wikipedia ‘attacks’ dataset (Wulczyn et al., 2017) contains approx.",2.2 Wikipedia comments,[0],[0]
"115K English Wikipedia talk page comments, which were labeled as containing personal attacks or not.",2.2 Wikipedia comments,[0],[0]
Each comment was labeled by at least 10 annotators.,2.2 Wikipedia comments,[0],[0]
"Inter-annotator agreement, measured on a random sample of 1K comments using Krippendorff’s (2004) alpha, was 0.45.",2.2 Wikipedia comments,[0],[0]
"The gold label of each comment is determined by the majority of annotators, leading to binary labels (accept, reject).",2.2 Wikipedia comments,[0],[0]
"Alternatively, the gold label is the percentage of annotators that labeled the comment as ‘accept’ (or ‘reject’), leading to probabilistic labels.7",2.2 Wikipedia comments,[0],[0]
"The dataset is split in three parts (Table 1): training (W-ATT-TRAIN, 69,526 comments), development (W-ATT-DEV, 23,160), and test (W-ATT-TEST, 23,178).",2.2 Wikipedia comments,[0],[0]
"In all three parts, the rejected comments are 12%, but this is an artificial ratio (Wulczyn et al. oversampled comments posted by banned users).",2.2 Wikipedia comments,[0],[0]
"By contrast, the ratio of rejected comments in all the Gazzetta subsets is the truly observed one.",2.2 Wikipedia comments,[0],[0]
"The Wikipedia comments are also longer (median length 38 tokens) compared to Gazzetta’s (median length 25 tokens).
",2.2 Wikipedia comments,[0],[0]
"Wulczyn et al. (2017) also provide two additional datasets of English Wikipedia talk page comments, which are not used in this paper.",2.2 Wikipedia comments,[0],[0]
"The first one, called ‘aggression’ dataset, contains the same comments as the ‘attacks’ dataset, now labeled as ‘aggressive’ or not.",2.2 Wikipedia comments,[0],[0]
"The (probabilistic) labels of the ‘attacks’ and ‘aggression’ datasets are very highly correlated (0.8992 Spearman, 0.9718 Pearson) and we did not consider the aggression dataset any further.",2.2 Wikipedia comments,[0],[0]
"The second additional dataset, called ‘toxicity’ dataset, contains approx.",2.2 Wikipedia comments,[0],[0]
160K comments labeled as being toxic or not.,2.2 Wikipedia comments,[0],[0]
"Experiments we reported elsewhere (Pavlopoulos et al., 2017) show that results on the ‘attacks’ and ‘toxicity’ datasets are very similar; we do not include
6We used CBOW, window size 5, min. term freq.",2.2 Wikipedia comments,[0],[0]
"5, negative sampling, obtaining a vocabulary size of approx.",2.2 Wikipedia comments,[0],[0]
"478K.
7 We also construct probabilistic labels for G-TEST-S-R, where there are five annotators.
results on the latter in this paper to save space.",2.2 Wikipedia comments,[0],[0]
"We experimented with an RNN operating on word embeddings, the same RNN enhanced with our attention mechanism (a-RNN), a vanilla convolutional neural network (CNN) also operating on word embeddings, the DETOX system of Wulczyn et al. (2017), and a baseline that uses word lists.",3 Methods,[0],[0]
"DETOX (Wulczyn et al., 2017) was the previous state of the art in comment moderation, in the sense that it had the best reported results on the Wikipedia datasets (Section 2.2), which were in turn the largest previous publicly available dataset of moderated user comments.8 DETOX represents each comment as a bag of word n-grams (n ≤ 2, each comment becomes a bag containing its 1- grams and 2-grams) or a bag of character n-grams (n ≤ 5, each comment becomes a bag containing character 1-grams, . . .",3.1 DETOX,[0],[0]
", 5-grams).",3.1 DETOX,[0],[0]
"DETOX can rely on a logistic regression (LR) or MLP classifier, and it can use binary or probabilistic gold labels (Section 2.2) during training.
",3.1 DETOX,[0],[0]
"We used the DETOX implementation provided by Wulczyn et al. and the same grid search (and code) to tune the hyper-parameters of DETOX that select word or character n-grams, classifier (LR or MLP), and gold labels (binary or probabilistic).",3.1 DETOX,[0],[0]
"For Gazzetta, only binary gold labels were possible, since G-TRAIN-L and G-TRAIN-S have a single gold label per comment.",3.1 DETOX,[0],[0]
"Unlike Wulczyn et al., we tuned the hyper-parameters by evaluating (computing AUC and Spearman, Section 4) on a random 2% of held-out comments of W-ATTTRAIN or G-TRAIN-S, instead of the development subsets, to be able to obtain more realistic results from the development sets while developing the methods.",3.1 DETOX,[0],[0]
"For both Wikipedia and Gazzetta, the tuning selected character n-grams, as in the work of Wulczyn et al.",3.1 DETOX,[0],[0]
"Also, for both Wikipedia and Gazzetta, it preferred LR to MLP, whereas Wulczyn et al. reported slightly higher performance
8Two of the co-authors of Wulczyn et al. (2017) are with Jigsaw, who recently announced Perspective, a system to detect ‘toxic’ comments.",3.1 DETOX,[0],[0]
"Perspective is not the same as DETOX (personal communication), but we were unable to obtain scientific articles describing it.",3.1 DETOX,[0],[0]
An API for Perspective is available at https://www.perspectiveapi.,3.1 DETOX,[0],[0]
"com/, but we did not have access to the API at the time the experiments of this paper were carried out.
for the MLP on W-ATT-DEV.9",3.1 DETOX,[0],[0]
"The tuning also selected probabilistic labels for Wikipedia, as in the work of Wulczyn et al.",3.1 DETOX,[0],[0]
RNN:,3.2 RNN-based methods,[0],[0]
"The RNN method is a chain of GRU cells (Cho et al., 2014) that transforms the tokens w1 . .",3.2 RNN-based methods,[0],[0]
.,3.2 RNN-based methods,[0],[0]
", wk of each comment to the hidden states h1 . . .",3.2 RNN-based methods,[0],[0]
", hk, followed by an LR layer that uses hk to classify the comment (accept, reject).",3.2 RNN-based methods,[0],[0]
"Formally, given the vocabulary V , a matrixE ∈ Rd×|V | containing d-dimensional word embeddings, an initial h0, and a comment c = 〈w1, . . .",3.2 RNN-based methods,[0],[0]
", wk〉, the RNN computes h1, . . .",3.2 RNN-based methods,[0],[0]
", hk as follows (ht ∈ Rm):
h̃t = tanh(Whxt + Uh(rt ht−1) + bh) ht = (1− zt) ht−1",3.2 RNN-based methods,[0],[0]
+ zt h̃t zt = σ(Wzxt + Uzht−1 + bz) rt = σ(Wrxt + Urht−1,3.2 RNN-based methods,[0],[0]
"+ br)
where h̃t ∈ Rm is the proposed hidden state at position t, obtained by considering the word embedding xt of token wt and the previous hidden state ht−1; denotes element-wise multiplication; rt ∈ Rm is the reset gate (for rt all zeros, it allows the RNN to forget the previous state ht−1); zt ∈ Rm is the update gate (for zt all zeros, it allows the RNN to ignore the new proposed h̃t, hence also xt, and copy ht−1 as ht); σ is the sigmoid function; Wh,Wz,Wr ∈ Rm×d; Uh, Uz, Ur ∈ Rm×m; bh, bz, br ∈ Rm.",3.2 RNN-based methods,[0],[0]
"Once hk has been computed, the LR layer estimates the probability that comment c should be rejected, with Wp ∈ R1×m, bp ∈ R:
PRNN(reject|c) = σ(Wphk + bp)
a-RNN: When the attention mechanism is added, the LR layer considers the weighted sum hsum of all the hidden states, instead of",3.2 RNN-based methods,[0],[0]
just hk (Fig.,3.2 RNN-based methods,[0],[0]
"3):10
hsum = k∑ t=1 atht (1)
Pa−RNN(reject|c) = σ(Wphsum + bp)
",3.2 RNN-based methods,[0],[0]
"The weights at are produced by an attention mech-
9We repeated the tuning by evaluating on W-ATT-DEV, and again character n-grams with LR were selected.
",3.2 RNN-based methods,[0],[0]
"10We tried replacing the LR layer by a deeper classification MLP, and the RNN chain by a bidirectional RNN (Schuster and Paliwal, 1997), but there were no improvements.
",3.2 RNN-based methods,[0],[0]
"anism, which is an MLP with l layers:
a (1) t = RELU(W (1)ht + b(1)) (2) . .",3.2 RNN-based methods,[0],[0]
".
",3.2 RNN-based methods,[0],[0]
a (l−1) t = RELU(W (l−1)a(l−2)t + b,3.2 RNN-based methods,[0],[0]
"(l−1))
",3.2 RNN-based methods,[0],[0]
a (l) t = W (l)a (l−1) t + b,3.2 RNN-based methods,[0],[0]
"(l)
at = softmax(a (l) t ; a (l) 1 , . . .",3.2 RNN-based methods,[0],[0]
", a (l) k ) (3)
where a(1)t , . . .",3.2 RNN-based methods,[0],[0]
", a (l−1) t ∈",3.2 RNN-based methods,[0],[0]
"Rr, a(l)t , at ∈ R, W (1) ∈",3.2 RNN-based methods,[0],[0]
"Rr×m, W (2), . . .",3.2 RNN-based methods,[0],[0]
",W (l−1) ∈",3.2 RNN-based methods,[0],[0]
"Rr×r, W (l) ∈",3.2 RNN-based methods,[0],[0]
"R1×r, b(1), . . .",3.2 RNN-based methods,[0],[0]
", b(l−1) ∈",3.2 RNN-based methods,[0],[0]
"Rr, b(l) ∈",3.2 RNN-based methods,[0],[0]
R.,3.2 RNN-based methods,[0],[0]
"The softmax operates across the a(l)t (t = 1, . . .",3.2 RNN-based methods,[0],[0]
", k), making the weights at sum to 1.",3.2 RNN-based methods,[0],[0]
"Our attention mechanism differs from most previous ones (Mnih et al., 2014; Bahdanau et al., 2015; Xu et al., 2015; Luong et al., 2015) in that it is used in a classification setting, where there is no previously generated output subsequence (e.g., partly generated translation) to drive the attention (e.g., assign more weight to source words to translate next), unlike seq2seq models (Sutskever et al., 2014).",3.2 RNN-based methods,[0],[0]
"It assigns larger weights at to hidden states ht corresponding to positions where there is more evidence that the comment should be accepted or rejected.
",3.2 RNN-based methods,[0],[0]
"Yang et al. (2016) use a similar attention mechanism, but ours is deeper.",3.2 RNN-based methods,[0],[0]
"In effect they always set l = 2, whereas we allow l to be larger (tuning selects l = 4).11",3.2 RNN-based methods,[0],[0]
"On the other hand, the attention mechanism of Yang et al. is part of a classification method for longer texts (e.g., product reviews).",3.2 RNN-based methods,[0],[0]
"Their method uses two GRU RNNs, both bidirectional (Schuster and Paliwal, 1997), one turning the word embeddings of each sentence to a sentence embedding, and one turning the sentence embeddings to a document embedding, which is then fed to an LR layer.",3.2 RNN-based methods,[0],[0]
"Yang et al. use their attention mechanism in both RNNs, to assign attention scores to words and sentences.",3.2 RNN-based methods,[0],[0]
"We consider shorter texts (comments), we have a single RNN, and we assign attention scores to words only.12
da-CENT: We also experiment with a variant of a-RNN, called da-CENT, which does not use the hidden states of the RNN.",3.2 RNN-based methods,[0],[0]
"The input to the first layer of the attention mechanism is now directly the embedding xt instead of ht (cf. Eq. 2), and
11Yang et al. use tanh instead of RELU in Eq. 2, which works worse in our case, and no bias b(l) in the l-th layer.
",3.2 RNN-based methods,[0],[0]
"12We tried a bidirectional instead of unidirectional GRU chain in our methods, also replacing the LR layer by a deeper classification MLP, but there were no improvements.
hsum is now the weighted sum (centroid) of word embeddings hsum = ∑k t=1 atxt (cf. Eq. 1).",3.2 RNN-based methods,[0],[0]
"13
We set l = 4, d = 300, r = m = 128, having tuned all hyper-parameters on the same 2% held-out comments of W-ATT-TRAIN or G-TRAINS that were used to tune DETOX.",3.2 RNN-based methods,[0],[0]
"We use Glorot initialization (Glorot and Bengio, 2010), categorical cross-entropy loss, and Adam (Kingma and Ba, 2015).14",3.2 RNN-based methods,[0],[0]
Early stopping evaluates on the same held-out subsets.,3.2 RNN-based methods,[0],[0]
"For Gazzetta, word embeddings are initialized to the WORD2VEC embeddings we provide (Section 2.1).",3.2 RNN-based methods,[0],[0]
"For Wikipedia, they are initialized to GLOVE embeddings (Pennington et al., 2014).15",3.2 RNN-based methods,[0],[0]
"In both cases, the embeddings are updated during backpropagation.",3.2 RNN-based methods,[0],[0]
"Out of vocabulary (OOV) words, meaning words for which we have no initial embeddings, are mapped to a single randomly initialized embedding, also updated.",3.2 RNN-based methods,[0],[0]
We also compare against a vanilla CNN operating on word embeddings.,3.3 CNN,[0],[0]
"We describe the CNN only briefly, because it is very similar to that of of Kim (2014); see also Goldberg (2016) for an introduction to CNNs, and Zhang and Wallace (2015).
",3.3 CNN,[0],[0]
"For Wikipedia comments, we use a ‘narrow’ convolution layer, with kernels sliding (stride 1) over (entire) embeddings of word n-grams of sizes n = 1, . . .",3.3 CNN,[0],[0]
", 4.",3.3 CNN,[0],[0]
"We use 300 kernels for each n value, a total of 1,200 kernels.",3.3 CNN,[0],[0]
"The outputs of each kernel, obtained by applying the kernel to the different n-grams of a comment c, are then
13 For experiments with additional variants of a-RNN, consult Pavlopoulos et al. (2017).
",3.3 CNN,[0],[0]
"14We implemented the methods of this sub-section using Keras (keras.io) and TensorFlow (tensorflow.org).
",3.3 CNN,[0],[0]
"15See https://nlp.stanford.edu/projects/ glove/. We use ‘Common Crawl’ (840B tokens).
",3.3 CNN,[0],[0]
"max-pooled, leading to a single output per kernel.",3.3 CNN,[0],[0]
"The resulting feature vector (1,200 maxpooled outputs) goes through a dropout layer (Hinton et al., 2012) (p = 0.5), and then to an LR layer, which provides PCNN(reject|c).",3.3 CNN,[0],[0]
"For Gazzetta, the CNN is the same, except that n = 1, . . .",3.3 CNN,[0],[0]
", 5, leading to 1,500 features per comment.",3.3 CNN,[0],[0]
All hyperparameters were tuned on the 2% held-out comments of W-ATT-TRAIN or G-TRAIN-S that were used to tune the other methods.,3.3 CNN,[0],[0]
"Again, we use 300-dimensional embeddings, which are now randomly initialized, since tuning indicated this was better than initializing to pre-trained embeddings.",3.3 CNN,[0],[0]
OOV words are treated as in the RNN-based methods.,3.3 CNN,[0],[0]
All embeddings are updated during backpropagation.,3.3 CNN,[0],[0]
Early stopping evaluates on the heldout subsets.,3.3 CNN,[0],[0]
"Again, we use Glorot initialization, categorical cross-entropy loss, and Adam.16",3.3 CNN,[0],[0]
"A baseline, called LIST, collects every word w that occurs in more than 10 (for W-ATT-TRAIN, G-TRAIN-S) or 100 comments (for G-TRAIN-L) in the training set, along with the precision of w, i.e., the ratio of rejected training comments containing w divided by the total number of training comments containing",3.4 LIST baseline,[0],[0]
w.,3.4 LIST baseline,[0],[0]
"The resulting lists contain 10,423, 16,864, and 21,940 word types, when using W-ATT-TRAIN, G-TRAIN-S, G-TRAIN-L, respectively.",3.4 LIST baseline,[0],[0]
"For a comment c, LIST returns as PLIST(reject|c) the maximum precision of all the words in c.",3.4 LIST baseline,[0],[0]
"All methods produce a p = P (reject|c) per comment c. In semi-automatic moderation (Fig. 1), a comment is directly rejected if its p is above a rejection theshold tr, it is directly accepted if p is below an acceptance threshold ta, and it is shown to a moderator if ta ≤ p ≤ tr (gray zone of Fig. 4).
",3.5 Tuning thresholds,[0],[0]
"In our experience, moderators (or their employers) can easily specify the approximate percentage of comments they can afford to check manually (e.g., 20% daily) or, equivalently, the approximate percentage of comments the system should
16We implemented the CNN directly in TensorFlow.
handle automatically.",3.5 Tuning thresholds,[0],[0]
"We call coverage the latter percentage; hence, 1 − coverage is the approximate percentage of comments to be checked manually.",3.5 Tuning thresholds,[0],[0]
"By contrast, moderators are baffled when asked to tune tr and ta directly.",3.5 Tuning thresholds,[0],[0]
"Consequently, we ask them to specify the approximate desired coverage.",3.5 Tuning thresholds,[0],[0]
"We then sort the comments of the development set (G-DEV or W-ATT-DEV) by p, and slide ta from 0.0 to 1.0 (Fig. 4).",3.5 Tuning thresholds,[0],[0]
"For each ta value, we set tr to the value that leaves a 1 − coverage percentage of development comments in the gray zone (ta ≤ p ≤ tr).",3.5 Tuning thresholds,[0],[0]
"We then select the ta (and tr) that maximizes the weighted harmonic mean Fβ(Preject, Paccept) on the development set:
Fβ(Preject, Paccept) =",3.5 Tuning thresholds,[0],[0]
"(1 + β2) · Preject · Paccept β2 · Preject + Paccept
where Preject is the rejection precision (correctly rejected comments divided by rejected comments) and Paccept is the acceptance precision (correctly accepted divided by accepted).",3.5 Tuning thresholds,[0],[0]
"Intuitively, coverage sets the width of the gray zone, whereas Preject and Paccept show how certain we can be that the red (reject) and green (accept) zones are free of misclassified comments.",3.5 Tuning thresholds,[0],[0]
"We set β = 2, emphasizing Paccept, because moderators are more worried about wrongly accepting abusive comments than wrongly rejecting non-abusive ones.17 The selected ta, tr (tuned on development data) are then used in experiments on test data.",3.5 Tuning thresholds,[0],[0]
"In fully automatic moderation, coverage = 100 and ta = tr; otherwise, threshold tuning is identical.",3.5 Tuning thresholds,[0],[0]
"Following Wulczyn et al. (2017), we report in Table 2 AUC scores (area under ROC curve), along with Spearman correlations between systemgenerated probabilities P (accept|c) and human probabilistic gold labels (Section 2.2) when probabilistic gold labels are available.18",4.1 Comment classification evaluation,[0],[0]
"Wulczyn et al. reported DETOX results only on W-ATT-DEV, shown in brackets.",4.1 Comment classification evaluation,[0],[0]
"Table 2 shows that RNN is
17More precisely, when computing Fβ , we reorder the development comments by time posted, and split them into batches of 100.",4.1 Comment classification evaluation,[0],[0]
"For each ta (and tr) value, we compute Fβ per batch and macro-average across batches.",4.1 Comment classification evaluation,[0],[0]
"The resulting thresholds lead to Fβ scores that are more stable over time.
",4.1 Comment classification evaluation,[0],[0]
"18When computing AUC, the gold label is the majority label of the annotators.",4.1 Comment classification evaluation,[0],[0]
"When computing Spearman, the gold label is probabilistic (% of annotators that accepted the comment).",4.1 Comment classification evaluation,[0],[0]
"The decisions of the systems are always probabilistic.
always better than CNN and DETOX; there is no clear winner between CNN and DETOX.",4.1 Comment classification evaluation,[0],[0]
"Furthermore, a-RNN is always better than RNN on Gazzetta comments, but not on Wikipedia comments, where RNN is overall slightly better according to Table 2.",4.1 Comment classification evaluation,[0],[0]
"Also, da-CENT is always worse than a-RNN and RNN, confirming that the hidden states (intuitively, context-aware word embeddings) of the RNN chain are important, even with the attention mechanism.",4.1 Comment classification evaluation,[0],[0]
Increasing the size of the Gazzetta training set (G-TRAIN-S to G-TRAINL) significantly improves the performance of all methods.,4.1 Comment classification evaluation,[0],[0]
"The implementation of DETOX could not handle the size of G-TRAIN-L, which is why we do not report DETOX results for G-TRAIN-L. Notice, also, that the Wikipedia dataset is easier than the Gazzetta one (all methods perform better on Wikipedia comments, compared to Gazzetta).
",4.1 Comment classification evaluation,[0],[0]
"Figure 5 shows F2(Preject, Paccept) on G-TESTL and W-ATT-TEST, when ta, tr are tuned on GDEV, W-ATT-DEV for varying coverage.",4.1 Comment classification evaluation,[0],[0]
"For GTEST-L, we show results training on G-TRAIN-S (solid lines) and G-TRAIN-L (dotted).",4.1 Comment classification evaluation,[0],[0]
"The differ-
ences between RNN and a-RNN are again small, but it is now easier to see that a-RNN is overall better.",4.1 Comment classification evaluation,[0],[0]
"Again, a-RNN and RNN are better than CNN and DETOX.",4.1 Comment classification evaluation,[0],[0]
All three deep learning methods benefit from the larger training set (dotted).,4.1 Comment classification evaluation,[0],[0]
"In Wikipedia, a-RNN obtains Paccept, Preject ≥ 0.94 for all coverages (Fig. 5, call-outs).",4.1 Comment classification evaluation,[0],[0]
"On the more difficult Gazzetta dataset, a-RNN still obtains Paccept, Preject ≥ 0.85 when tuned for 50% coverage.",4.1 Comment classification evaluation,[0],[0]
"When tuned for 100% coverage, comments for which the system is uncertain (gray zone) cannot be avoided and there are inevitably more misclassifications; the use of F2 during threshold tuning places more emphasis on avoiding wrongly accepted comments, leading to high Paccept (0.82), at the expense of wrongly rejected comments, i.e., sacrificing Preject (0.59).",4.1 Comment classification evaluation,[0],[0]
"On the re-moderated G-TEST-S-R (similar diagrams, not shown), Paccept, Preject become 0.96, 0.88 for coverage 50%, and 0.92, 0.48 for coverage 100%.
",4.1 Comment classification evaluation,[0],[0]
"We also repeated the annotator ensemble experiment of Wulczyn et al. (2017) on 8K randomly chosen comments of W-ATT-TEST (4K comments
from random users, 4K comments from banned users).19 The decisions of 10 randomly chosen annotators (possibly different per comment) were used to construct the gold label of each comment.",4.1 Comment classification evaluation,[0],[0]
"The gold labels were then compared to the decisions of the systems and the decisions of an ensemble of k other annotators, k ranging from 1 to 10.",4.1 Comment classification evaluation,[0],[0]
"Table 3 shows the mean AUC and Spearman scores, averaged over 25 runs of the experiment, along with standard errrors (in brackets).",4.1 Comment classification evaluation,[0],[0]
"We conclude that RNN and a-RNN are as good as an ensemble of 7 human annotators; CNN is as good as 4 annotators; DETOX is as good as 4 in AUC and 3 annotators in Spearman correlation, which is consistent with the results of Wulczyn et al. (2017).",4.1 Comment classification evaluation,[0],[0]
"To investigate if the attention scores of a-RNN can highlight suspicious words, we focused on GTEST-S-R, the only dataset with suspicious snippets annotated by humans.",4.2 Snippet highlighting evaluation,[0],[0]
"We removed comments with no human-annotated snippets, leaving 841 comments (515 accepted, 326 rejected), a total of 40,572 tokens, of which 13,146 were inside a suspicious snippet of at least one annotator.",4.2 Snippet highlighting evaluation,[0],[0]
"In each remaining comment, each token was assigned a gold suspiciousness score, defined as the percentage of annotators that included it in their snippets.
",4.2 Snippet highlighting evaluation,[0],[0]
We evaluated three methods that score each token wt of a comment c for suspiciousness.,4.2 Snippet highlighting evaluation,[0],[0]
"The first one assigns to each wt the attention score at
19We used the protocol, code, and data of Wulczyn et al.
",4.2 Snippet highlighting evaluation,[0],[0]
(Eq. 3) of a-RNN (trained on G-TRAIN-L).,4.2 Snippet highlighting evaluation,[0],[0]
"The second method assigns to each wt its precision, as computed by LIST (Section 3.4).",4.2 Snippet highlighting evaluation,[0],[0]
The third method (RAND) assigns to each wt a random (uniform distribution) score between 0 and 1.,4.2 Snippet highlighting evaluation,[0],[0]
"In the latter two methods, a softmax is applied to the scores of all the tokens per comment, as in a-RNN.",4.2 Snippet highlighting evaluation,[0],[0]
"Figure 6 shows three comments (from W-ATT-TEST) highlighted by a-RNN; heat corresponds to attention.20
We computed Pearson and Spearman correlations between the gold suspiciousness scores and the scores of the three methods on the 40,572 tokens.",4.2 Snippet highlighting evaluation,[0],[0]
Figure 7 shows the correlations on comments that were accepted (left) and rejected (right) by the majority of moderators.,4.2 Snippet highlighting evaluation,[0],[0]
"In both cases, a-RNN performs better than LIST and RAND by both Pearson and Spearman correlations.",4.2 Snippet highlighting evaluation,[0],[0]
The high Pearson correlations of a-RNN also show that its attention scores are to a large extent linearly related to the gold ones.,4.2 Snippet highlighting evaluation,[0],[0]
"By contrast, LIST performs reasonably well in terms of Spearman correlation, but much worse in terms of Pearson, indicating that its precision scores rank reasonably well the tokens from most to least suspicious ones, but are not linearly related to the gold scores.",4.2 Snippet highlighting evaluation,[0],[0]
"Djuric et al. (2015) experimented with 952K manually moderated comments from Yahoo Finance, but their dataset is not publicly available.",5 Related work,[0],[0]
"They convert each comment to a comment embedding using DOC2VEC (Le and Mikolov, 2014), which is then fed to an LR classifier.",5 Related work,[0],[0]
Nobata et al. (2016) experimented with approx.,5 Related work,[0],[0]
3.3M manually moderated comments from Yahoo Finance and News,5 Related work,[0],[0]
; their data are also not available.21,5 Related work,[0],[0]
"They used Vowpal Wabbit22 with character n-grams (n = 3, . . .",5 Related work,[0],[0]
", 5) and word n-grams (n = 1, 2), handcrafted features (e.g., number of capitalized or black-listed words), features based on dependency
20In innocent comments, a-RNN spreads its attention to all tokens, leading to quasi-uniform low color intensity.
21According to Nobata et al., their clean test dataset (2K comments) would be made available, but it is currently not.
22See http://hunch.net/˜vw/.
trees, averages of WORD2VEC embeddings, and DOC2VEC-like embeddings.",5 Related work,[0],[0]
Character n,5 Related work,[0],[0]
"-grams were the best, on their own outperforming Djuric et al. (2015).",5 Related work,[0],[0]
"The best results, however, were obtained using all features.",5 Related work,[0],[0]
"We use no hand-crafted features and parsers, making our methods more easily portable to other domains and languages.
",5 Related work,[0],[0]
"Mehdad et al. (2016) train a (token or characterbased) RNN language model per class (accept, reject), and use the probability ratio of the two models to accept or reject user comments.",5 Related work,[0],[0]
"Experiments on the dataset of Djuric et al. (2015), however, showed that their method (RNNLMs) performed worse than a combination of SVM and Naive Bayes classifiers (NBSVM) that used character and token n-grams.",5 Related work,[0],[0]
"An LR classifier operating on DOC2VEC-like comment embeddings (Le and Mikolov, 2014) also performed worse than NBSVM.",5 Related work,[0],[0]
"To surpass NBSVM, Mehdad et al. used an SVM to combine features from their three other methods (RNNLMs, LR with DOC2VEC, NBSVM).
",5 Related work,[0],[0]
Wulczyn et al. (2017) experimented with character and word n-grams.,5 Related work,[0],[0]
We included their dataset and moderation system (DETOX) in our experiments.,5 Related work,[0],[0]
Waseem et al. (2016) used approx.,5 Related work,[0],[0]
17K tweets annotated for hate speech.,5 Related work,[0],[0]
"Their best results were obtained using an LR classifier with character n-grams (n = 1, . . .",5 Related work,[0],[0]
", 4), plus gender.",5 Related work,[0],[0]
"Warner and Hirschberg (2012) aimed to detect anti-semitic speech, experimenting with 9K paragraphs and a linear SVM.",5 Related work,[0],[0]
"Their features consider windows of at most 5 tokens, examining the tokens of each window, their order, POS tags, Brown clusters etc., following Yarowsky (1994).
",5 Related work,[0],[0]
Cheng et al. (2015) aimed to predict which users would be banned from on-line communities.,5 Related work,[0],[0]
"Their best system used a random forest or LR classifier, with features examining readability, activity (e.g., number of posts daily), community and moderator reactions (e.g., up-votes, number of deleted posts).
",5 Related work,[0],[0]
"Sood et al. (2012a; 2012b) experimented with 6.5K comments from Yahoo Buzz, moderated via crowdsourcing.",5 Related work,[0],[0]
"They showed that a linear SVM, representing each comment as a bag of word bigrams and stems, performs better than word lists.",5 Related work,[0],[0]
"Their best results were obtained by combining the SVM with a word list and edit distance.
",5 Related work,[0],[0]
Yin et al. (2009) used posts from chat rooms and discussion fora (<15K posts in total) to train an SVM to detect online harassment.,5 Related work,[0],[0]
"They used TF-IDF, sentiment, and context features (e.g., sim-
ilarity to other posts in a thread).",5 Related work,[0],[0]
"Our methods might also benefit by considering threads, rather than individual comments.",5 Related work,[0],[0]
"Yin at al. point out that unlike other abusive content, spam in comments or dicsussion fora (Mishne et al., 2005; Niu et al., 2007) is off-topic and serves a commercial purpose.",5 Related work,[0],[0]
"Spam is unlikely in Wikipedia discussions and not an issue in the Gazzetta dataset (Fig. 2).
",5 Related work,[0],[0]
"For a more extensive discussion of related work, consult Pavlopoulos et al. (2017).",5 Related work,[0],[0]
We experimented with a new publicly available dataset of 1.6M moderated user comments from a Greek sports news portal and an existing dataset of 115K English Wikipedia talk page comments.,6 Conclusions,[0],[0]
"We showed that a GRU RNN operating on word embeddings outpeforms the previous state of the art, which used an LR or MLP classifier with character or word n-gram features, also outperforming a vanilla CNN operating on word embeddings, and a baseline that uses an automatically constructed word list with precision scores.",6 Conclusions,[0],[0]
"A novel, deep, classification-specific attention mechanism improves further the overall results of the RNN, and can also highlight suspicious words for free, without including highlighted words in the training data.",6 Conclusions,[0],[0]
"We considered both fully automatic and semi-automatic moderation, along with threshold tuning and evaluation measures for both.
",6 Conclusions,[0],[0]
"We plan to consider user-specific information (e.g., ratio of comments rejected in the past) (Cheng et al., 2015; Waseem and Hovy, 2016) and explore character-level RNNs or CNNs (Zhang et al., 2015), e.g., as a first layer to produce embeddings of unknown words from characters (dos Santos and Zadrozny, 2014; Ling et al., 2015), which would then be passed on to our current methods that operate on word embeddings.",6 Conclusions,[0],[0]
"This work was funded by Google’s Digital News Initiative (project ML2P, contract 362826).23 We are grateful to Gazzetta for the data they provided.",Acknowledgments,[0],[0]
"We also thank Gazzetta’s moderators for their feedback, insights, and advice.
23See https://digitalnewsinitiative.com/.",Acknowledgments,[0],[0]
"Experimenting with a new dataset of 1.6M user comments from a news portal and an existing dataset of 115K Wikipedia talk page comments, we show that an RNN operating on word embeddings outpeforms the previous state of the art in moderation, which used logistic regression or an MLP classifier with character or word n-grams.",abstractText,[0],[0]
"We also compare against a CNN operating on word embeddings, and a word-list baseline.",abstractText,[0],[0]
"A novel, deep, classificationspecific attention mechanism improves the performance of the RNN further, and can also highlight suspicious words for free, without including highlighted words in the training data.",abstractText,[0],[0]
We consider both fully automatic and semi-automatic moderation.,abstractText,[0],[0]
Deeper Attention to Abusive User Content Moderation,title,[0],[0]
"A fundamental challenge in artificial intelligence, robotics, and language processing is sequential prediction: to reason, plan, and make a sequence of predictions or decisions to minimize accumulated cost, achieve a long-term goal, or
1Robotics Institute, Carnegie Mellon University, USA 2Machine Learning Department, Carnegie Mellon University, USA 3College of Computing, Georgia Institute of Technology, USA.",1. Introduction,[0],[0]
"Correspondence to: Wen Sun <wensun@cs.cmu.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"optimize for a loss acquired only after many predictions.
",1. Introduction,[0],[0]
"Although conventional supervised learning of deep models has been pivotal in advancing performance in sequential prediction problems, researchers are beginning to utilize Reinforcement Learning (RL) methods to achieve even higher performance (Ranzato et al., 2015; Bahdanau et al., 2016; Li et al., 2016).",1. Introduction,[0],[0]
"In sequential prediction tasks, future predictions often depend on the history of previous predictions; thus, a poor prediction early in the sequence can lead to high loss (cost) for future predictions.",1. Introduction,[0],[0]
"Viewing the predictor as a policy ⇡, deep RL algorithms are able to reason about the future accumulated cost in sequential prediction problems.",1. Introduction,[0],[0]
"These approaches have dramatically advanced the state-of-the-art on a number of problems including high-dimensional robotics control tasks and video and board games (Schulman et al., 2015; Silver et al., 2016).
",1. Introduction,[0.9999998980182221],"['These approaches have dramatically advanced the state-of-the-art on a number of problems including high-dimensional robotics control tasks and video and board games (Schulman et al., 2015; Silver et al., 2016).']"
"In contrast with general reinforcement learning methods, imitation learning and related sequential prediction algorithms such as SEARN (Daumé III et al., 2009), DaD (Venkatraman et al., 2015), AggreVaTe (Ross & Bagnell, 2014), and LOLS (Chang et al., 2015b) reduce the sequential prediction problems to supervised learning by leveraging a (near) optimal cost-to-go oracle that can be queried for the next (near)-best prediction at any point during training.",1. Introduction,[1.0],"['In contrast with general reinforcement learning methods, imitation learning and related sequential prediction algorithms such as SEARN (Daumé III et al., 2009), DaD (Venkatraman et al., 2015), AggreVaTe (Ross & Bagnell, 2014), and LOLS (Chang et al., 2015b) reduce the sequential prediction problems to supervised learning by leveraging a (near) optimal cost-to-go oracle that can be queried for the next (near)-best prediction at any point during training.']"
"Specifically, these methods assume access to an oracle that provides an optimal or near-optimal action and the future accumulated loss Q⇤, the so-called cost-to-go.",1. Introduction,[1.0],"['Specifically, these methods assume access to an oracle that provides an optimal or near-optimal action and the future accumulated loss Q⇤, the so-called cost-to-go.']"
"For robotics control problems, this oracle may be a human expert guiding the robot during the training phase (Abbeel & Ng, 2004) or the policy from an optimal MDP solver (Ross et al., 2011; Kahn et al., 2016; Choudhury et al., 2017) that is either too slow to use at test time or leverages information unavailable at test time.",1. Introduction,[1.0],"['For robotics control problems, this oracle may be a human expert guiding the robot during the training phase (Abbeel & Ng, 2004) or the policy from an optimal MDP solver (Ross et al., 2011; Kahn et al., 2016; Choudhury et al., 2017) that is either too slow to use at test time or leverages information unavailable at test time.']"
"For sequential prediction problems, an oracle can be constructed by optimization (e.g., beam search) or by a clairvoyant greedy algorithm (Daumé III et al., 2009; Ross et al., 2013; Rhinehart et al., 2015; Chang et al., 2015a) that, given the training data’s ground truth, is near-optimal on the task-specific performance metric (e.g., cumulative reward, IoU, Unlabeled Attachment Score, BLEU).
",1. Introduction,[0.9999999881708745],"['For sequential prediction problems, an oracle can be constructed by optimization (e.g., beam search) or by a clairvoyant greedy algorithm (Daumé III et al., 2009; Ross et al., 2013; Rhinehart et al., 2015; Chang et al., 2015a) that, given the training data’s ground truth, is near-optimal on the task-specific performance metric (e.g., cumulative reward, IoU, Unlabeled Attachment Score, BLEU).']"
"Expert, demonstrator, and oracle are used interchangeably.
",1. Introduction,[0.9999999618681616],"['Expert, demonstrator, and oracle are used interchangeably.']"
We stress that the oracle is only required to be available during training.,1. Introduction,[0],[0]
"Therefore, the goal of IL is to learn a policy ⇡̂ with the help of the oracle (⇡⇤, Q⇤) during the training session, such that ⇡̂ achieves similar or better performance at test time when the oracle is unavailable.",1. Introduction,[1.0],"['Therefore, the goal of IL is to learn a policy ⇡̂ with the help of the oracle (⇡⇤, Q⇤) during the training session, such that ⇡̂ achieves similar or better performance at test time when the oracle is unavailable.']"
"In contrast to IL, reinforcement learning methods often initialize with a random policy ⇡
0 or cost-to-go estimate Q 0 that may be far from optimal.",1. Introduction,[1.0000000882034379],"['In contrast to IL, reinforcement learning methods often initialize with a random policy ⇡ 0 or cost-to-go estimate Q 0 that may be far from optimal.']"
"The optimal policy (or cost-to-go) must be found by exploring, often with random actions.
",1. Introduction,[1.0000000050535895],"['The optimal policy (or cost-to-go) must be found by exploring, often with random actions.']"
A classic family of IL methods is to collect data from running the demonstrator or oracle and train a regressor or classifier via supervised learning.,1. Introduction,[1.0],['A classic family of IL methods is to collect data from running the demonstrator or oracle and train a regressor or classifier via supervised learning.']
"These methods (Abbeel & Ng, 2004; Syed et al., 2008; Ratliff et al., 2006; Ziebart et al., 2008; Finn et al., 2016; Ho & Ermon, 2016) learn either a policy ⇡̂⇤ or ˆQ⇤ from a fixed-size dataset precollected from the oracle.",1. Introduction,[1.0],"['These methods (Abbeel & Ng, 2004; Syed et al., 2008; Ratliff et al., 2006; Ziebart et al., 2008; Finn et al., 2016; Ho & Ermon, 2016) learn either a policy ⇡̂⇤ or ˆQ⇤ from a fixed-size dataset precollected from the oracle.']"
"Unfortunately, these methods exhibit a pernicious problem: they require the training and test data to be sampled from the same distribution, despite the fact they explicitly change the sample policy during training.",1. Introduction,[0],[0]
"As a result, policies learned by these methods can fail spectacularly (Ross & Bagnell, 2010).",1. Introduction,[0],[0]
"Interactive approaches to IL such as SEARN (Daumé III et al., 2009), DAgger (Ross et al., 2011), and AggreVaTe (Ross & Bagnell, 2014) interleave learning and testing to overcome the data mismatch issue and, as a result, work well in practical applications.",1. Introduction,[1.0],"['Interactive approaches to IL such as SEARN (Daumé III et al., 2009), DAgger (Ross et al., 2011), and AggreVaTe (Ross & Bagnell, 2014) interleave learning and testing to overcome the data mismatch issue and, as a result, work well in practical applications.']"
"Furthermore, these interactive approaches can provide strong theoretical guarantees between training time loss and test time performance through a reduction to no-regret online learning.
",1. Introduction,[1.0000000292249076],"['Furthermore, these interactive approaches can provide strong theoretical guarantees between training time loss and test time performance through a reduction to no-regret online learning.']"
"In this work, we introduce AggreVaTeD, a differentiable version of AggreVaTe (Aggregate Values to Imitate (Ross & Bagnell, 2014)) which allows us to train policies with efficient gradient update procedures.",1. Introduction,[1.0],"['In this work, we introduce AggreVaTeD, a differentiable version of AggreVaTe (Aggregate Values to Imitate (Ross & Bagnell, 2014)) which allows us to train policies with efficient gradient update procedures.']"
AggreVaTeD extends and scales interactive IL for use in sequential prediction and challenging continuous robot control tasks.,1. Introduction,[1.0],['AggreVaTeD extends and scales interactive IL for use in sequential prediction and challenging continuous robot control tasks.']
"We provide two gradient update procedures: a regular gradient update developed from Online Gradient Descent (OGD) (Zinkevich, 2003) and a natural gradient update (Kakade, 2002; Bagnell & Schneider, 2003), which is closely related to Weighted Majority (WM) (Littlestone & Warmuth, 1994), a popular no-regret algorithm that enjoys an almost dimension-free property (Bubeck et al., 2015).
",1. Introduction,[0.9999999031566968],"['We provide two gradient update procedures: a regular gradient update developed from Online Gradient Descent (OGD) (Zinkevich, 2003) and a natural gradient update (Kakade, 2002; Bagnell & Schneider, 2003), which is closely related to Weighted Majority (WM) (Littlestone & Warmuth, 1994), a popular no-regret algorithm that enjoys an almost dimension-free property (Bubeck et al., 2015).']"
AggreVaTeD leverages the oracle to learn rich polices that can be represented by complicated non-linear function approximators.,1. Introduction,[1.0],['AggreVaTeD leverages the oracle to learn rich polices that can be represented by complicated non-linear function approximators.']
"Our experiments with deep neural networks on various robotics control simulators and on a dependency parsing sequential prediction task show that AggreVaTeD can achieve expert-level performance and even super-expert performance when the oracle is sub-optimal, a result rarely achieved by non-interactive IL approaches.
",1. Introduction,[0.9999999852017007],"['Our experiments with deep neural networks on various robotics control simulators and on a dependency parsing sequential prediction task show that AggreVaTeD can achieve expert-level performance and even super-expert performance when the oracle is sub-optimal, a result rarely achieved by non-interactive IL approaches.']"
"i.e., the regret bound depends on poly-log of the dimension of parameter space.
",1. Introduction,[1.0000000275347762],"['i.e., the regret bound depends on poly-log of the dimension of parameter space.']"
"The differentiable nature of AggreVaTeD additionally allows us to employ Recurrent Neural Network policies, e.g., Long Short-Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997), to handle partially observable settings (e.g., observe only partial robot state).",1. Introduction,[1.0],"['The differentiable nature of AggreVaTeD additionally allows us to employ Recurrent Neural Network policies, e.g., Long Short-Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997), to handle partially observable settings (e.g., observe only partial robot state).']"
"Empirical results demonstrate that by leveraging an oracle, IL can learn much faster than RL.
",1. Introduction,[1.000000034542889],"['Empirical results demonstrate that by leveraging an oracle, IL can learn much faster than RL.']"
"In addition to providing a set of practical algorithms, we develop a comprehensive theoretical study of IL on discrete MDPs.",1. Introduction,[0],[0]
We construct an MDP that demonstrates exponentially better sample efficiency for IL than any RL algorithm.,1. Introduction,[1.0],['We construct an MDP that demonstrates exponentially better sample efficiency for IL than any RL algorithm.']
"For general discrete MDPs, we provide a regret upper bound for AggreVaTeD with WM, which shows IL can learn dramatically faster than RL.",1. Introduction,[1.0],"['For general discrete MDPs, we provide a regret upper bound for AggreVaTeD with WM, which shows IL can learn dramatically faster than RL.']"
"We provide a regret lower bound for any IL algorithm, which demonstrates that AggreVaTeD with WM is near-optimal.
",1. Introduction,[0.9999999357232952],"['We provide a regret lower bound for any IL algorithm, which demonstrates that AggreVaTeD with WM is near-optimal.']"
"To summarize the contributions of this work: (1) AggreVaTeD allows us to handle continuous action spaces and employ recurrent neural network policies for Partially Observable Markov Decision Processes (POMDPs); (2) understanding IL from a perspective that is related to policy gradient allows us to leverage advances from the wellstudied RL policy gradient literature (e.g., gradient variance reduction techniques, efficient natural gradient computation); (3) we provide a new sample complexity study of IL and compare to RL, showing that we can expect up to exponentially lower sample complexity.",1. Introduction,[0],[0]
"Our experimental and theoretical results support the proposition:
Imitation Learning is a more effective strategy than Reinforcement Learning for sequential prediction with near-optimal cost-to-go oracles.",1. Introduction,[0.9999999743115856],['Our experimental and theoretical results support the proposition: Imitation Learning is a more effective strategy than Reinforcement Learning for sequential prediction with near-optimal cost-to-go oracles.']
"A Markov Decision Process consists of a set of states, actions (that come from a policy), cost (loss), and a model that transitions states given actions.",2. Preliminaries,[1.0],"['A Markov Decision Process consists of a set of states, actions (that come from a policy), cost (loss), and a model that transitions states given actions.']"
"Interestingly, most sequential prediction problems can be framed in terms of MDPs (Daumé III et al., 2009).",2. Preliminaries,[1.0],"['Interestingly, most sequential prediction problems can be framed in terms of MDPs (Daumé III et al., 2009).']"
"The actions are the learner’s (e.g., RNN’s) predictions.",2. Preliminaries,[1.0],"['The actions are the learner’s (e.g., RNN’s) predictions.']"
"The state is then the result of all the predictions made so far (e.g., the dependency tree constructed so far or the words translated so far).",2. Preliminaries,[0],[0]
"The cumulative cost is the performance metric such as (negative) UAS, received at the end (horizon) or after the final prediction.",2. Preliminaries,[0],[0]
"For robotics control problems, the robot’s configuration is the state, the controls (e.g., joint torques) are the actions, and the cost is related to achieving a task (e.g., distance walked).
",2. Preliminaries,[0],[0]
"Formally, a finite-horizon Markov Decision Process (MDP) is defined as (S,A, P, C, ⇢
0 , H).",2. Preliminaries,[1.000000005473268],"['Formally, a finite-horizon Markov Decision Process (MDP) is defined as (S,A, P, C, ⇢ 0 , H).']"
"Here, S is a set of S states and A is a set of A actions; at time step t, Pt is the transition dynamics such that for any st 2 S, st+1 2 S, at 2 A,
Pt(st+1|st, at) is the probability of transitioning to state st+1 from state st by taking action at at step t; C is the cost distribution such that a cost ct at step t is sampled from Ct(·|st, at).",2. Preliminaries,[1.0000000526699955],"['Here, S is a set of S states and A is a set of A actions; at time step t, Pt is the transition dynamics such that for any st 2 S, st+1 2 S, at 2 A, Pt(st+1|st, at) is the probability of transitioning to state st+1 from state st by taking action at at step t; C is the cost distribution such that a cost ct at step t is sampled from Ct(·|st, at).']"
"Finally, we denote c̄t(st, at) as the expected cost, ⇢
0",2. Preliminaries,[0],[0]
"as the initial distribution of states,",2. Preliminaries,[0],[0]
and,2. Preliminaries,[0],[0]
"H 2 N+ as the finite horizon (max length) of the MDP.
",2. Preliminaries,[0],[0]
"We define a stochastic policy ⇡ such that for any state s 2 S , ⇡(·|s) 2 (A), where (A) is a A-dimensional simplex, conditioned on state s. ⇡(a|s) 2",2. Preliminaries,[0],[0]
"[0, 1] outputs the probability of taking action a at state s.",2. Preliminaries,[0],[0]
"The distribution of trajectories ⌧ = (s
1 , a 1 , . . .",2. Preliminaries,[0],[0]
", aH 1, sH) is determined by ⇡ and the MDP, and is defined as
⇢⇡(⌧) = ⇢0(s1) HY
t=2
⇡(at 1|st 1)Pt 1(st|st 1, at 1).
",2. Preliminaries,[0],[0]
"The distribution of the states at time step t, induced by running the policy ⇡ until t, is defined 8st:
d⇡t (st) = X
{si,ai}it 1
⇢ 0",2. Preliminaries,[0],[0]
"(s 1 )
t 1Y
i=1
⇡(ai|si)Pi(si+1|si, ai).
",2. Preliminaries,[0],[0]
Note that the summation above can be replaced by an integral if the state or action space is continuous.,2. Preliminaries,[0],[0]
"The average state distribution ¯d⇡(s) = PH t=1 d ⇡ t (s)/H .
",2. Preliminaries,[0],[0]
"The expected average cost of a policy ⇡ can be defined with respect to ⇢⇡ or {d⇡t }:
µ(⇡) = E ⌧⇠⇢⇡
"" HX
t=1
c̄t(st, at) # = HX
t=1
E s⇠d⇡t (s),a⇠⇡(a|s)",2. Preliminaries,[0],[0]
"[c̄t(s, a)] .
We define the state-action value Q⇡t (s, a) (i.e., cost-to-go) for policy ⇡ at time step t as:
Q⇡t (st, at) = c̄t(st, at) + E s⇠Pt(·|st,at),a⇠⇡(·|s) Q⇡t+1(s, a),
where the expectation is taken over the randomness of the policy ⇡ and the MDP.
",2. Preliminaries,[0],[0]
"We define ⇡⇤ as the expert policy (e.g., human demonstrators, search algorithms equipped with ground-truth) and Q⇤t (s, a) as the expert’s cost-to-go oracle.",2. Preliminaries,[0],[0]
"We emphasize that ⇡⇤ may not be optimal, i.e., ⇡⇤ 62 argmin⇡ µ(⇡).",2. Preliminaries,[0],[0]
"Throughout the paper, we assume Q⇤t (s, a) is known or can be estimated without bias (e.g., by rolling out ⇡⇤: starting from state s, applying action a, and then following ⇡⇤ for H t steps).
",2. Preliminaries,[0],[0]
"When ⇡ is represented by a function approximator, we use the notation ⇡✓ to represent the policy parametrized by ✓ 2 Rd: ⇡(·|s; ✓).",2. Preliminaries,[0],[0]
In this work we specifically consider optimizing policies in which the parameter dimension d may be large.,2. Preliminaries,[0],[0]
"We also consider the partially observable setting in our experiments, where the policy ⇡(·|o
1 , a 1 , ..., ot; ✓)
is defined over the whole history of observations and actions (ot is generated from the hidden state st).",2. Preliminaries,[0],[0]
"We use both LSTM and Gated Recurrent Unit (GRU) (Chung et al., 2014) based policies where the RNN’s hidden states provide a compressed feature of the history.",2. Preliminaries,[0],[0]
"To our best knowledge, this is the first time RNNs are employed in an IL framework to handle partially observable environments.",2. Preliminaries,[0],[0]
Policy based imitation learning aims to learn a policy ⇡̂ that approaches the performance of the expert ⇡⇤ at test time when ⇡⇤ is no longer available.,3. Differentiable Imitation Learning,[0],[0]
"In order to learn rich policies such as LSTMs or deep networks (Schulman et al., 2015), we derive a method related to policy gradients for imitation learning and sequential prediction.",3. Differentiable Imitation Learning,[0],[0]
"To do this, we leverage the reduction of IL and sequential prediction to online learning as shown in (Ross & Bagnell, 2014) to learn policies represented by expressive differentiable function approximators.
",3. Differentiable Imitation Learning,[0],[0]
"The fundamental idea in Ross & Bagnell (2014) is to use a no-regret online learner to update policies using the following loss function at each episode n:
`n(⇡)",3. Differentiable Imitation Learning,[0],[0]
"= 1
H
HX
t=1
E st⇠d⇡nt
h E
a⇠⇡(·|st) [Q⇤t (st, a)]
i .",3. Differentiable Imitation Learning,[0],[0]
"(1)
",3. Differentiable Imitation Learning,[0],[0]
"The loss function intuitively encourages the learner to find a policy that minimize the expert’s cost-to-go under the state distribution resulting from the current learned policy ⇡n. Specifically, Ross & Bagnell (2014) suggest an algorithm named AggreVaTe (Aggregate Values to Imitate) that uses Follow-the-Leader (FTL) (ShalevShwartz et al., 2012) to update policies: ⇡n+1 = argmin⇡2⇧",3. Differentiable Imitation Learning,[0],[0]
Pn i=1,3. Differentiable Imitation Learning,[0],[0]
"`n(⇡), where ⇧ is a pre-defined convex policy set.",3. Differentiable Imitation Learning,[0],[0]
"When `n(⇡) is strongly convex with respect to ⇡ and ⇡⇤ 2 ⇧, after N iterations AggreVaTe with FTL can find a policy ⇡̂ with:
µ(⇡̂)  µ(⇡⇤) ✏N +O(ln(N)/N), (2)
where ✏N =",3. Differentiable Imitation Learning,[0],[0]
[ PN n=1 `n(⇡ ⇤ ) min⇡ PN n=1 `n(⇡)]/N .,3. Differentiable Imitation Learning,[0],[0]
"Note that ✏N 0 and the above inequality indicates that ⇡̂ can outperform ⇡⇤ when ⇡⇤ is not (locally) optimal (i.e., ✏n > 0).",3. Differentiable Imitation Learning,[0],[0]
"Our experimental results support this observation.
",3. Differentiable Imitation Learning,[0],[0]
A simple implementation of AggreVaTe that aggregates the values (as the name suggests) will require an exact solution to a batch optimization procedure in each episode.,3. Differentiable Imitation Learning,[0],[0]
"When ⇡ is represented by large, non-linear function approximators, the argmin procedure generally takes more and more computation time as n increases.",3. Differentiable Imitation Learning,[0],[0]
"Hence an efficient incremental update procedure is necessary for the method to scale.
",3. Differentiable Imitation Learning,[0],[0]
"To derive an incremental update procedure, we can take one of two routes.",3. Differentiable Imitation Learning,[0],[0]
"The first route, suggested already by (Ross & Bagnell, 2014), is to update our policy with an incremental no-regret algorithm such as weighted majority (Littlestone & Warmuth, 1994), instead of with a batch algorithm like FTRL.",3. Differentiable Imitation Learning,[0],[0]
"Unfortunately, for rich policy classes such as deep networks, no-regret learning algorithms may not be available (e.g., a deep network policy is non-convex with respect to its parameters).",3. Differentiable Imitation Learning,[0],[0]
"So instead we propose a novel second route: we directly differentiate Eq. 1, yielding an update related to policy gradient methods.",3. Differentiable Imitation Learning,[0],[0]
"We work out the details below, including a novel update rule for IL based on natural gradients.
",3. Differentiable Imitation Learning,[0],[0]
"Interestingly, the two routes described above yield almost identical algorithms if our policy class is simple enough: e.g., for a tabular policy, AggreVaTe with weighted majority yields the natural gradient version of AggreVaTeD described below.",3. Differentiable Imitation Learning,[0],[0]
"And, the two routes yield complementary theoretical guarantees: the first route yields a regret bound for simple-enough policy classes, while the second route yields convergence to a local optimum for extremely flexible policy classes.",3. Differentiable Imitation Learning,[0],[0]
"For discrete actions, the gradient of `n(⇡✓) (Eq. 1) with respect to the parameters ✓ of the policy is
r✓`n(✓) = 1
H
HX
t=1
E st⇠d ⇡✓n t
X
a
r✓⇡(a|st; ✓)Q⇤t (st, a).
",3.1. Online Gradient Descent,[0],[0]
"(3)
For continuous action spaces, we cannot simply replace the summation by integration since in practice it is hard to evaluate Q⇤t (s, a) for infinitely many a, so, instead, we use importance weighting to re-formulate `n (Eq. 1) as
`n(⇡✓)",3.1. Online Gradient Descent,[0],[0]
"= 1
H
HX
t=1
E s⇠d
⇡✓n t ,a⇠⇡(·|s;✓n)
⇡(a|s; ✓) ⇡(a|s; ✓n) Q⇤t (s, a)
=
1
H E
⌧⇠⇢⇡✓n
HX
t=1
⇡(at|st; ✓) ⇡(at|st; ✓n) Q⇤t (st, at).",3.1. Online Gradient Descent,[0],[0]
"(4)
See Appendix B for the derivation of the above equation.",3.1. Online Gradient Descent,[0],[0]
"With this reformulation, the gradient with respect to ✓ is
r✓`n(✓) = 1 H E
⌧⇠⇢⇡✓n
HX
t=1
r✓⇡(at|st; ✓) ⇡(at|st; ✓n) Q⇤t (st, at)
=
1 H E⌧⇠⇢⇡✓n
HX
t=1
r✓ ln(⇡(at|st; ✓n))Q⇤t (st, at).",3.1. Online Gradient Descent,[0],[0]
"(5)
The above gradient computation enables a very efficient update procedure with online gradient descent: ✓n+1 = ✓n ⌘nr✓`n(✓)|✓=✓n , where ⌘n is the learning rate.",3.1. Online Gradient Descent,[0],[0]
"We derive a natural gradient update procedure for imitation learning inspired by the success of natural gradient descent in RL (Kakade, 2002; Bagnell & Schneider, 2003; Schulman et al., 2015).",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"Following (Bagnell & Schneider, 2003), we define the Fisher information matrix I(✓n) using trajectory likelihood:
I(✓n) = 1 H2 E ⌧⇠⇢⇡✓n r✓n log(⇢⇡✓n (⌧))",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
r,3.2. Policy Updates with Natural Gradient Descent,[0],[0]
✓n log(⇢⇡✓n (⌧)),3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"T ,
(6)
where r✓ log(⇢⇡⌧ (⌧)) is the gradient of the log likelihood of the trajectory ⌧ which can be computed asPH
t=1 r✓ log(⇡✓(at|st)).",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"Note that this representation is equivalent to the original Fisher information matrix proposed by (Kakade, 2002).",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"Now, we can use Fisher information matrix together with the IL gradient derived in the previous section (Eq. 53) to compute the natural gradient as I(✓n)",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"1r✓`n(✓)|✓=✓n , which yields a natural gradient update: ✓n+1 = ✓n µnI(✓n)",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"1r✓`n(✓)|✓=✓n .
",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"Interesting, as we mentioned before, when the given MDP is discrete and the policy class is in a tabular representation, AggreVaTe with Weighted Majority (Littlestone & Warmuth, 1994) yields an extremely similar update procedure as AggreVaTeD with natural gradient.",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"Due to space limitation, we defer the detailed similarity between AggreVaTe with Weighted Majority and AggreVaTeD with natural gradient to Appendix A.",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"As Weighted Majority can speed up online learning (i.e., almost dimension free (Bubeck et al., 2015)) and AggreVaTe with Weighted Majority enjoys strong theoretical guarantees on the performance of the learned policy (Ross & Bagnell, 2014), this similarity provides an intuitive explanation why we can expect AggreVaTeD with natural gradient to speed up IL and learn a high quality policy.",3.2. Policy Updates with Natural Gradient Descent,[0],[0]
"In the previous section, we derived a regular gradient update procedure and a natural gradient update procedure for IL.",4. Sample-Based Practical Algorithms,[0],[0]
Note that all of the computations of gradients and Fisher information matrices assumed it was possible to exactly compute expectations including Es⇠d⇡ and Ea⇠⇡(a|s).,4. Sample-Based Practical Algorithms,[0],[0]
"In this section, we provide practical algorithms where we approximate the gradients and Fisher information matrices using finite samples collected during policy execution.",4. Sample-Based Practical Algorithms,[0],[0]
"We consider an episodic framework where given a policy ⇡n at episode n, we roll out ⇡n K times to collect K trajectories {⌧ni }, for i 2",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"[K], ⌧ni = {s i,n 1 , ai,n 1
, ...}.",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"For gradient r✓`n(✓)|✓=✓n we can compute an unbiased estimate
using {⌧ni }i2[K]:
˜r✓n = 1
HK
KX
i=1
HX
t=1
X
a
r✓n⇡✓n(a|s",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"i,n t )Q ⇤ t (s i,n t , a),
(7)
˜r✓n = 1
HK
KX
i=1
HX
t=1
r✓n ln(⇡✓n(a i,n t |s",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"i,n t ))",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"Q ⇤ t (s i,n t , a i,n t ).
",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"(8)
for discrete and continuous setting respectively.
",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"When we can compute V ⇤t (s), we can replace Q⇤t (s i,n t , a) by the state-action advantage function A⇤t (s i,n t , a) = Q⇤t (s i,n t , a) V ⇤t (s i,n t ), which leads to the following unbiased and variance-reduced gradient estimation for continuous action setting (Greensmith et al., 2004):
˜r✓n = 1
HK
KX
i=1
HX
t=1
r✓n ln(⇡✓n(a i,n t |s",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"i,n t ))",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"A ⇤ t (s i,n t , a i,n t ),
(9)
",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"In fact, we can use any baselines to reduce the variance by replacing Q⇤t (st, at) by Q⇤t (st, at) b(st), where b(st) : S !",4.1. Gradient Estimation and Variance Reduction,[0],[0]
R is a action-independent function.,4.1. Gradient Estimation and Variance Reduction,[0],[0]
Ideally b(st) should be some function approximator that approximates V ⇤(st).,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"In our experiments, we test linear function approximator b(s) = wT s, which is online learned using ⇡⇤’s roll-out data.
",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"The Fisher information matrix (Eq. 19) is approximated as:
˜I(✓n)",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"= 1
H2K
KX
i=1
r✓n log(⇢⇡✓n (⌧i))r✓n log(⇢⇡✓n (⌧i))",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"T
= SnS T n , (10)
where, for notation simplicity, we denote Sn as a d⇥K matrix where the i’s th column is r✓n log(⇢⇡✓n (⌧i))/(H p K).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
Namely the Fisher information matrix is represented by a sum of K rank-one matrices.,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"For large policies represented by neural networks, K ⌧ d, and hence ˜I(✓n) a low rank matrix.",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"One can find the descent direction ✓n by solving the linear system SnSTn ✓n = ˜r✓n for ✓n using Conjugate Gradient (CG) with a fixed number of iterations, which is equivalent to solving the above linear systems using Partial Least Squares (Phatak & de Hoog, 2002).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"This approach is used in TRPO (Schulman et al., 2015).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
The difference is that our representation of the Fisher matrix is in the form of SnSTn and in CG we never need to explicitly compute or store SnSTn which requires d2 space and time.,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"Instead, we only compute and store Sn (O(Kd)) and the total computational time is still O(K2d).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"The learning-rate for natural gradient descent can be chosen as ⌘n = q KL/( ˜rT✓n ✓n), such that KL(⇢⇡✓n+1 (⌧)k⇢⇡✓n (⌧)) ⇡",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"KL 2 R +
Algorithm 1",4.1. Gradient Estimation and Variance Reduction,[0],[0]
AggreVaTeD (Differentiable AggreVaTe) 1: Input: The given MDP and expert ⇡⇤.,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"Learning rate
{⌘n}.",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"Schedule rate {↵i}, ↵n ! 0, n !",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"1. 2: Initialize policy ⇡✓1 (either random or supervised
learning).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
3: for n = 1 to N do 4: Mixing policies: ⇡̂n = ↵n⇡⇤ + (1 ↵n)⇡✓n .,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"5: Starting from ⇢
0 , roll out by executing ⇡̂n on the given MDP to generate K trajectories {⌧ni }.
6: Using Q⇤ and {⌧ni }i, compute the descent direction ✓n",4.1. Gradient Estimation and Variance Reduction,[0],[0]
"(Eq. 7, Eq. 8, Eq. 9, or CG).",4.1. Gradient Estimation and Variance Reduction,[0],[0]
7: Update: ✓n+1 = ✓n ⌘n ✓n .,4.1. Gradient Estimation and Variance Reduction,[0],[0]
8: end for 9: Return: the best hypothesis ⇡̂ 2 {⇡n}n on validation.,4.1. Gradient Estimation and Variance Reduction,[0],[0]
"Summarizing the above discussion, we present the differentiable imitation learning framework AggreVaTeD, in Alg. 1.",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"At every iteration n, the roll out policy ⇡̂n is a mix of the expert policy ⇡⇤ and the current policy ⇡✓n , with mixing rate ↵ (↵n !",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"0, n !",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"1): at every step, with probability ↵ ⇡̂n picks ⇡⇤ and picks ⇡✓n otherwise.",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"This mixing strategy with the decay rate was first introduced in (Ross et al., 2011) for IL, and later on was used in sequence prediction (Bengio et al., 2015).",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"In Line 6, one can either choose Eq. 8 or the corresponding variance reduced estimation Eq. 9 to perform regular gradient descent, and choose CG to perform natural gradient descent.",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"AggreVaTeD is extremely simple: we do not need to perform any data aggregation (i.e., we do not need to store all {⌧i}i from all previous iterations); the computational complexity of each policy update scales in O(d).
",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"When we use non-linear function approximators to represent the polices, the analysis of AggreVaTe from (Ross & Bagnell, 2014) will not hold, since the loss function `n(✓) is not convex with respect to parameters ✓.",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
"Nevertheless, as we will show in experiments, in practice AggreVaTeD is still able to learn a policy that is competitive with, and sometimes superior to, the oracle’s performance.",4.2. Differentiable Imitation Learning: AggreVaTeD,[0],[0]
How much faster can IL learn a good policy than RL?,5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
In this section we quantify the gap on discrete MDPs when IL can (1) query for an optimal Q⇤ or (2) query for a noisy but unbiased estimate of Q⇤.,5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
"To measure the speed of learning, we look at the cumulative regret of the entire learning process, defined as RN = PN n=1(µ(⇡n) µ(⇡⇤)).",5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
A smaller regret rate indicates faster learning.,5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
"Throughout this section, we assume the expert ⇡⇤ is optimal.",5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
"We consider finite-horizon, episodic IL and RL algorithms.",5. Quantify the Gap: An Analysis of IL vs RL,[0],[0]
"We consider an MDP M shown in Fig. 1 which is a depthK binary tree-structure with S = 2K 1 states and two actions al, ar: go-left and go-right.",5.1. Exponential Gap,[0],[0]
"The transition is deterministic and the initial state s
0 (root) is fixed.",5.1. Exponential Gap,[0],[0]
The cost for each non-leaf state is zero; the cost for each leaf is i.i.d sampled from a given distribution (possibly different distributions per leaf).,5.1. Exponential Gap,[0],[0]
"Below we show that for M, IL can be exponentially more sample efficient than RL.
Theorem 5.1.",5.1. Exponential Gap,[0],[0]
"For M, the regret RN of any finite-horizon, episodic RL algorithm is at least:
E[RN ] ⌦( p SN).",5.1. Exponential Gap,[0],[0]
"(11)
",5.1. Exponential Gap,[0],[0]
The expectation is with respect to random generation of cost and internal randomness of the algorithm.,5.1. Exponential Gap,[0],[0]
"However, for the same MDP M, with the access to Q⇤, we show IL can learn exponentially faster:
Theorem 5.2.",5.1. Exponential Gap,[0],[0]
"For the MDP M, AggreVaTe with FTL can achieve the following regret bound:
RN  O(ln (S)).",5.1. Exponential Gap,[0],[0]
"(12)
Fig. 1 illustrates the intuition behind the theorem.",5.1. Exponential Gap,[0],[0]
"Assume during the first episode, the initial policy ⇡
1 picks the rightmost trajectory (bold black) to explore.",5.1. Exponential Gap,[0],[0]
"We query from the cost-to-go oracle Q⇤ at s
0 for al and ar, and learn that Q⇤(s
0 , al) <",5.1. Exponential Gap,[0],[0]
"Q⇤(s0, ar).",5.1. Exponential Gap,[0],[0]
"This immediately tells us that the optimal policy will go left (black arrow) at s
0 .",5.1. Exponential Gap,[0],[0]
"Hence the algorithm does not have to explore the right sub-tree (dotted circle).
",5.1. Exponential Gap,[0],[0]
"Next we consider a more difficult setting where one can only query for a noisy but unbiased estimate of Q⇤ (e.g., by rolling out ⇡⇤ finite number of times).",5.1. Exponential Gap,[0],[0]
The above halving argument will not apply since deterministically eliminating nodes based on noisy estimates might permanently remove good trajectories.,5.1. Exponential Gap,[0],[0]
"However, IL can still achieve a poly-log regret with respect to S, even in the noisy setting:
Theorem 5.3.",5.1. Exponential Gap,[0],[0]
"With only access to unbiased estimate of Q⇤, for the MDP M, AggreVaTeD with WM can achieve the
following regret with probability at least 1 :
RN  O ⇣ ln(S)( p ln(S)N + p ln(2/ )N)",5.1. Exponential Gap,[0],[0]
⌘ .,5.1. Exponential Gap,[0],[0]
"(13)
",5.1. Exponential Gap,[0],[0]
"The detailed proofs of the above three theorems can be found in Appendix E,F,G respectively.",5.1. Exponential Gap,[0],[0]
"In summary, for MDP M, IL is is exponentially faster than RL.",5.1. Exponential Gap,[0],[0]
We next quantify the gap in general discrete MDPs and also show that AggreVaTeD is near-optimal.,5.2. Polynomial Gap and Near-Optimality,[0],[0]
"We consider the harder case where we can only access an unbiased estimate of Q⇤t , for any t and state-action pair.",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"The policy ⇡ is represented as a set of probability vectors ⇡s,t 2 (A), for all s 2 S and t 2",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"[H]: ⇡ = {⇡s,t}s2S,t2[H].",5.2. Polynomial Gap and Near-Optimality,[0],[0]
Theorem 5.4.,5.2. Polynomial Gap and Near-Optimality,[0],[0]
"With access to unbiased estimates of Q⇤t , AggreVaTeD with WM achieves the regret upper bound:
RN  O HQe
max
p S ln(A)N .",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"(14)
",5.2. Polynomial Gap and Near-Optimality,[0],[0]
Here Qe max is the maximum cost-to-go of the expert.,5.2. Polynomial Gap and Near-Optimality,[0],[0]
The total regret shown in Eq. 14 allows us to compare IL algorithms to RL algorithms.,5.2. Polynomial Gap and Near-Optimality,[0],[0]
"For example, the Upper Confidence Bound (UCB) based, near-optimal optimistic RL algorithms from (Jaksch et al., 2010), specifically designed for efficient exploration, admit regret ˜O(HS",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"p HAN), leading to a gap of approximately p HAS compared to the regret bound of imitation learning shown in Eq. 14.
",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"We also provide a lower bound on RN for the H = 1 case which shows the dependencies on N,A, S are tight:
Theorem 5.5.",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"There exists an MDP (H=1) such that, with only access to unbiased estimates of Q⇤, any finite-horizon episodic imitation learning algorithm must have:
E[RN ] ⌦( p S ln(A)N).",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"(15)
The proofs of the above two theorems regarding general MDPs can be found in Appendix H,I.",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"In summary for discrete MDPs, one can expect at least a polynomial gap and a possible exponential gap between IL and RL.",5.2. Polynomial Gap and Near-Optimality,[0],[0]
"We evaluate our algorithms on robotics simulations from OpenAI Gym (Brockman et al., 2016) and on Handwritten Algebra Dependency Parsing (Duyck & Gordon, 2015).",6. Experiments,[0],[0]
"We report reward instead of cost, since OpenAI Gym by default uses reward and dependency parsing aims to maximize UAS score.",6. Experiments,[0],[0]
"As our approach only promises there
Here we assume Qe max is a constant compared to H .",6. Experiments,[0],[0]
"If Qe
max = ⇥(H), then the expert is no better than a random policy of which the cost-to-go is around ⇥(H).
exists a policy among all of the learned polices that can perform as well as the expert, we report the performance of the best policy so far: max{µ(⇡
1 ), ..., µ(⇡i)}.",6. Experiments,[0],[0]
"For regular gradient descent, we use ADAM (Kingma & Ba, 2014) which is a first-order no-regret algorithm, and for natural gradient, we use CG to compute the descent direction.",6. Experiments,[0],[0]
"For RL we use REINFORCE (Williams, 1992) and Truncated Natural Policy Gradient (TNPG)",6. Experiments,[0],[0]
"(Duan et al., 2016).",6. Experiments,[0],[0]
"We consider CartPole Balancing, Acrobot Swing-up, Hopper and Walker.",6.1. Robotics Simulations,[0],[0]
"For generating an expert, similar to previous work (Ho & Ermon, 2016), we used a Deep Q-Network (DQN) to generate Q⇤ for CartPole and Acrobot (e.g., to simulate the settings where Q⇤ is available), while using the publicly available TRPO implementation to generate ⇡⇤ for Hopper and Walker to simulate the settings where one has to estimate Q⇤ by Monte-Carlo roll outs ⇡⇤.
",6.1. Robotics Simulations,[0],[0]
Discrete Action Setting We use a one-layer (16 hidden units) neural network with ReLu activation functions to represent the policy ⇡ for the Cart-pole and Acrobot benchmarks.,6.1. Robotics Simulations,[0],[0]
"The value function Q⇤ is obtained from the DQN (Mnih et al., 2015) and represented by a multi-layer fully connected neural network.",6.1. Robotics Simulations,[0],[0]
The policy ⇡✓1 is initialized with common ReLu neural network initialization techniques.,6.1. Robotics Simulations,[0],[0]
"For the scheduling rate {↵i}, we set all ↵i = 0: namely we did not roll-in using the expert’s actions during training.",6.1. Robotics Simulations,[0],[0]
"We set the number of roll outs K = 50 and horizon H = 500 for CartPole and H = 200 for Acrobot.
",6.1. Robotics Simulations,[0],[0]
Fig.,6.1. Robotics Simulations,[0],[0]
2a and 2b shows the performance averaged over 10 random trials of AggreVaTeD with regular gradient descent and natural gradient descent.,6.1. Robotics Simulations,[0],[0]
Note that AggreVaTeD outperforms the experts’ performance significantly: Natural gradient surpasses the expert by 5.8% in Acrobot and 25% in Cart-pole.,6.1. Robotics Simulations,[0],[0]
"Also, for Acrobot swing-up, at horizon H = 200, with high probability a randomly initialized neural network policy won’t be able to collect any reward signals.",6.1. Robotics Simulations,[0],[0]
Hence the improvement rates of REINFORCE and TNPG are slow.,6.1. Robotics Simulations,[0],[0]
"In fact, we observed that for a short horizon such as H = 200, REINFORCE and Truncated Natural Gradient often even fail to improve the policy at all (failed
6 times among 10 trials).",6.1. Robotics Simulations,[0],[0]
"On the contrary, AggreVaTeD does not suffer from the delayed reward signal issue, since the expert will collect reward signals much faster than a randomly initialized policy.
",6.1. Robotics Simulations,[0],[0]
Fig. 2c shows the performance of AggreVaTeD with an LSTM policy (32 hidden states) in a partially observed setting where the expert has access to full states but the learner has access to partial observations (link positions).,6.1. Robotics Simulations,[0],[0]
RL algorithms did not achieve any improvement while AggreVaTeD still achieved 92% of the expert’s performance.,6.1. Robotics Simulations,[0],[0]
"In Appendix K, we provide extra experiments on partial observable CartPole with GRU-based policies, where we demonstrate that even in partial observable setting, AggreVaTeD can learn RNN polices that outperform experts.
",6.1. Robotics Simulations,[0],[0]
Continuous Action Setting We test our approaches on two robotics simulators with continuous actions: (1) the 2-d Walker and (2) the Hopper from the MuJoCo physics simulator.,6.1. Robotics Simulations,[0],[0]
"Following the neural network settings described in Schulman et al. (2015), the expert policy ⇡⇤ is obtained from TRPO with one hidden layer (64 hidden states), which is the same structure that we use to represent our policies ⇡✓.",6.1. Robotics Simulations,[0],[0]
We set K = 50 and H = 100.,6.1. Robotics Simulations,[0],[0]
"We initialize ⇡✓1 by collecting K expert demonstrations and then maximize the likelihood of these demonstrations (i.e., supervised learning).",6.1. Robotics Simulations,[0],[0]
"We use a linear baseline b(s) = wT s for RL and IL.
Fig.",6.1. Robotics Simulations,[0],[0]
2e and 2d show the performance averaged over 5 random trials.,6.1. Robotics Simulations,[0],[0]
Note that AggreVaTeD outperforms the expert in the Walker by 13.7% while achieving 97% of the expert’s performance in the Hopper problem.,6.1. Robotics Simulations,[0],[0]
"After 100 iterations, we see that by leveraging the help from experts, AggreVaTeD can achieve much faster improvement rate than the corresponding RL algorithms (though eventually we can expect RL to catch up).",6.1. Robotics Simulations,[0],[0]
"In Walker, we also tested AggreVaTeD without linear baseline, which still outperforms the expert but performed slightly worse than AggreVaTeD with baseline as expected.",6.1. Robotics Simulations,[0],[0]
"We consider a sequential prediction problem: transitionbased dependency parsing for handwritten algebra with raw image data (Duyck & Gordon, 2015).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"The parsing task
for algebra is similar to the classic dependency parsing for natural language (Chang et al., 2015a) where the problem is modelled in the IL setting and the state-of-the-art is achieved by AggreVaTe with FTRL (using Data Aggregation).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
The additional challenge here is that the inputs are handwritten algebra symbols in raw images.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
We directly learn to predict parse trees from low level image features (Histogram of Gradient features (HoG)).,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"During training, the expert is constructed using the ground-truth dependencies in training data.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"The full state s during parsing consists of three data structures: Stack, Buffer and Arcs, which store raw images of the algebraic symbols.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"Since the sizes of stack, buffer and arcs change during parsing, a common approach is to featurize the state s by taking the features of the latest three symbols from stack, buffer and arcs (e.g., (Chang et al., 2015a)).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"Hence the problem falls into the partially observable setting, where the feature o is extracted from state s and only contains partial information about s. The dataset consists of 400 sets of handwritten algebra equations.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"We use 80% for training, 10% for validation, and 10% for testing.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"We include an example of handwritten algebra equations and its dependency tree in Appendix J. Note that different from robotics simulators where at every episode one can get fresh data from the simulators, the dataset is fixed and sample efficiency is critical.
",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"The RNN policy follows the design from (Sutskever et al., 2014).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
It consists of two LSTMs.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"Given a sequence of algebra symbols ⌧ , the first LSTM processes one symbol at a time and at the end outputs its hidden states and memory (i.e., a summary of ⌧ ).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
The second LSTM initializes its own hidden states and memory using the outputs of the first LSTM.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"At every parsing step t, the second LSTM takes the current partial observation ot (ot consists of features of the most recent item from stack, buffer and arcs) as input, and uses its internal hidden state and memory to compute the action distribution ⇡(·|o
1 , ..., ot, ⌧) conditioned on history.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"We also tested reactive policies constructed as fully connected ReLu neural networks (NN) (one-layer with 1000 hidden states) that directly maps from observation ot to action a, where ot uses the most three recent items.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"We use variance reduced gradient estimations, which give better performance in practice.",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
The performance is summarised in Table 1.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"Due to the partial observability of the problem, AggreVaTeD with a LSTM policy achieves significantly better UAS scores compared to the NN reactive pol-
icy and DAgger with a Kernelized SVM (Duyck & Gordon, 2015).",6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
Also AggreVaTeD with a LSTM policy achieves 97% of optimal expert’s performance.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
Fig. 3 shows the improvement rate of regular gradient and natural gradient on both validation set and test set.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
Overall we observe that both methods have similar performance.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
Natural gradient achieves a better UAS score in validation and converges slightly faster on the test set but also achieves a lower UAS score on test set.,6.2. Dependency Parsing on Handwritten Algebra,[0],[0]
"We introduced AggreVaTeD, a differentiable imitation learning algorithm which trains neural network policies for sequential prediction tasks such as continuous robot control and dependency parsing on raw image data.",7. Conclusion,[0],[0]
We showed that in theory and in practice IL can learn much faster than RL with access to optimal cost-to-go oracles.,7. Conclusion,[0],[0]
The IL learned policies were able to achieve expert and sometimes super-expert levels of performance in both fully observable and partially observable settings.,7. Conclusion,[0],[0]
The theoretical and experimental results suggest that IL is significantly more effective than RL for sequential prediction with near optimal cost-to-go oracles.,7. Conclusion,[0],[0]
This research was supported in part by ONR 36060-1b1141268.,Acknowledgement,[0],[0]
"Recently, researchers have demonstrated stateof-the-art performance on sequential prediction problems using deep neural networks and Reinforcement Learning (RL).",abstractText,[0],[0]
"For some of these problems, oracles that can demonstrate good performance may be available during training, but are not used by plain RL methods.",abstractText,[0],[0]
"To take advantage of this extra information, we propose AggreVaTeD, an extension of the Imitation Learning (IL) approach of Ross & Bagnell (2014).",abstractText,[0],[0]
"AggreVaTeD allows us to use expressive differentiable policy representations such as deep networks, while leveraging training-time oracles to achieve faster and more accurate solutions with less training data.",abstractText,[0],[0]
"Specifically, we present two gradient procedures that can learn neural network policies for several problems, including a sequential prediction task and several high-dimensional robotics control problems.",abstractText,[0],[0]
We also provide a comprehensive theoretical study of IL that demonstrates that we can expect up to exponentially-lower sample complexity for learning with AggreVaTeD than with plain RL algorithms.,abstractText,[0],[0]
Our results and theory indicate that IL (and AggreVaTeD in particular) can be a more effective strategy for sequential prediction than plain RL.,abstractText,[0],[0]
Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential Prediction,title,[0],[0]

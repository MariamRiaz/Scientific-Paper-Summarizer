0	38	During the last decade, social media have become extremely popular, on which billions of usergenerated contents are posted every day.
1	34	Many users have been writing about their thoughts and lives on the go.
2	25	The massive unstructured data from social media provides valuable information for a variety of applications such as stock prediction (Bollen et al., 2011), public health analysis (Wilson and Brownstein, 2009; Paul and Dredze, 2011), real-time event detection (Sakaki et al., 2010), and so on.
12	26	Hence, most POS tagging methods cannot achieve the same performance as reported on newswire domain when applied on Twitter (Owoputi et al., 2013).
19	34	Social media users often use informal ways of expressing their ideas and often spell words phonetically (e.g., “2mor” for “tomorrow”).
23	52	To tackle the challenges posed by the lack of training data and the out-of-vocabulary words, in this paper, we propose a novel recurrent neural network, which we call Target Preserved Adversarial Neural Network (TPANN) to perform the task.
24	32	It can make use of a large quantity of annotated data from other resourcerich domains, unlabeled in-domain data, and a small amount of labeled in-domain data.
25	36	All of these datasets can be easily obtained.
33	58	In this work, we propose a novel recurrent neural network, Target Preserved Adversarial Neural Network (TPANN), to learn common features between resource-rich domain and target domain, simultaneously to preserve target domain-specific features.
37	14	In the following sections, we will detail each part of the proposed architecture and training methods.
38	21	The feature extractor F adopts CNN to extract character embedding features, which can tackle the out-of-vocabulary word problem effectively.
40	25	Utilizing a bi-LSTM to model sentences, F can extract sequential relations and context information.
57	16	They are standard feed-forward networks with a softmax layer for classification.
82	31	When the adversarial networks try to optimize the hidden representation to common representation hcommon, The target domain autoencoder counteracts a tendency of the adversarial network to erase target domain features by optimizing the common representation to be informative on the target-domain data.
84	32	Our ultimate training goal is to minimize the total loss function with parameters {θf , θy, θr, θd} as follows: Ltotal = αLtask + βLtarget + γLtype, (6) where α, β, γ are the weights to balance the effects of P ,R and Q.
85	19	For obtaining domain-invariant representation hcommon, inspired by (Ganin and Lempitsky, 2015), we introduce a special gradient reversal layer (GRL), which does nothing during forward propagation, but negates the gradients if it receives backward propagation, i.e. g(F(x)) = F(x) but ∇g(F(x)) = −λ∇F(x).
98	19	For training and evaluating POS tagging approaches, we compare the proposed method with other approaches on three benchmarks: RIT-Twitter (Ritter et al., 2011), NPSCHAT (Forsyth, 2007), and ARKTwitter (Gimpel et al., 2011).
135	19	Taking a variety of linguistic features and many other resources into consideration, the T-POS, GATE tagger, and ARK tagger can achieve better performance.
137	35	According to the results of word level, we can see that word2vec can provide valuable information.
140	14	bi-LSTM(combine) combines word with character features, as described in Section 2.1, which achieves the best results at 89.48% in the bi-LSTM based baseline systems and shows that the morphological features and pre-trained word vectors are both useful for POS tagging.
143	18	Compared with the architecture without an adversarial model, our method is almost 1% better.
147	20	To better understand why adversarial networks can help transfer domains from newswire to Twitter, in this work we also followed the method Ganin and Lempitsky (2015) used to visualize the outputs of LSTM with tSNE (Van Der Maaten, 2013).
149	23	From the figure, we can see that the adversary in our method makes the two distributions of features much more similar, which means that the outputs of bi-LSTM are domain-invariant.
170	25	From the results, we can see that our method can achieve a better result than (Gimpel et al., 2011).
176	62	So, our model is also competitive when lacking of manual feature knowledge.
191	48	In this work, we propose a novel adversarial neural network to address the POS tagging problem.
192	26	Besides learning common representations between source domain and target domain, it can simultaneously preserve specific features of target domain.
193	43	The proposed method leverages newswire resources and large scale in-domain unlabeled data to help POS tagging classification on Twitter, which has a few of labeled data.
195	44	In most of the cases, the proposed method can achieve better performance than previous methods.
196	83	Experimental results demonstrate that the proposed method can make full use of these resources, which can be easily obtained.

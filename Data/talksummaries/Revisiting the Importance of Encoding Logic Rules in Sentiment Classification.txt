1	56	While simple bag-of-words or lexicon-based methods (Pang and Lee, 2005; Wang and Manning, 2012; Iyyer et al., 2015) achieve good performance on this task, they are unequipped to deal with syntactic structures that affect sentiment, such as contrastive conjunctions (i.e., sentences of the form “A-but-B”) or negations.
9	21	Intuitively, the logic rule for such sentences is that the sentiment associated with the whole sentence should be the same as the sentiment associated with phrase “B”.1 More formally, let pθ(y|x) denote the probability assigned to the label y ∈ {+,−} for an input x by the baseline model using parameters θ.
12	13	Next, we discuss the two techniques from Hu et al. (2016) for incorporating rules into models: projection, which directly alters a trained model, and distillation, which progressively adjusts the loss function during training.
13	15	The first technique is to project a trained model into a rule-regularized subspace, in a fashion similar to Ganchev et al. (2010).
15	70	(1− Ey←q(·|x)[rθ(x, y)]) ≤ ξx Here q(X,Y ) denotes the distribution of (x, y) when x is drawn uniformly from the set X and y is drawn according to q(·|x).
16	15	Iterative Rule Knowledge Distillation.
17	21	The second technique is to transfer the domain knowledge encoded in the logic rules into a neural network’s parameters.
18	33	Following Hinton et al. (2015), a “student” model pθ can learn from the “teacher” model qθ, by using a loss function πH(pθ, Ptrue)+ (1− π)H(pθ, qθ) during training, where Ptrue denotes the distribution implied by the ground truth, H(·, ·) denotes the cross-entropy function, and π is a hyperparameter.
19	10	Hu et al. (2016) computes qθ after every gradient update by projecting the current pθ, as described above.
20	12	Note that both mechanisms can be combined: After fully training pθ using the iterative distillation process above, the projection step can be applied one more time to obtain qθ which is then used as the trained model.
21	17	All of our experiments (as well as those in Hu et al. (2016)) use the SST2 dataset, a binarized subset of the popular Stanford Sentiment Treebank (SST) (Socher et al., 2013).
24	35	In this section we reanalyze the effectiveness of the techniques of Hu et al. (2016) and find that most of the performance gain is due to projection and not knowledge distillation.
27	40	We run the baseline CNN by Kim (2014) across 100 random seeds, training on sentence-level la- bels.
29	28	The inset density plot in Figure 1 shows the range of accuracies (83.47 to 87.20) along with 25, 50 and 75 percentiles.3 The figure also shows how the variance persists even after the average converges: the accuracies of 100 models trained for 20 epochs each are plotted in gray, and their average is shown in red.
33	40	Our analysis reveals that the reported performance of their two mechanisms (projection and distillation) is in fact affected by the high variability across random seeds.
46	32	In contrast, contextualized embeddings are dynamic representations, dependent on the current context of the word.
47	15	We hypothesize that contextualized word embeddings might inherently capture these logic rules due to increasing the effective context size for the CNN layer in Kim (2014).
54	11	As further evidence that ELMo helps on these specific constructions, the non-ELMo baseline model (no-project, no-distill) gets 255 sentences wrong in the test corpus on average, only 89 (34.8%) of which are A-but-B style or negations.
55	22	Statistical Significance: Using a two-sided Kolmogorov-Smirnov statistic (Massey Jr, 1951) with α = 0.001 for the results in Table 2, we find that ELMo and projection each yield statistically significant improvements, but distillation does not.
59	10	We confirm that ELMo’s predictions are much closer to the A-but-B rule’s manifold than those of the other models by computing KL(qθ||pθ) where pθ and qθ are the original and projected distributions: Averaged across all A-butB sentences and 100 seeds, this gives 0.27, 0.26 and 0.13 for the Kim (2014), Hu et al. (2016) with distillation and ELMo systems respectively.
61	28	We compare the intra-sentence similarity for fine-tuned word2vec embeddings (baseline), ELMo embeddings without fine-tuning and finally fine-tuned ELMo embeddings in Figure 3.
62	51	In the fine-tuned ELMo embeddings, we notice the words within the A and within the B part of the A-but-B sentence share the same part of the vector space.
64	9	This observation is indicative of ELMo’s ability to learn specific rules for A-but-B sentences in sentiment classification.
68	17	Our crowdsourced experiment was conducted on Figure Eight.8 Nine workers scored the sentiment of each A-but-B and negation sentence in the test SST2 split as 0 (negative), 0.5 (neutral) or 1 (positive).
76	26	As expected, inter-annotator agreement is higher for higher thresholds (less ambiguous sentences).
78	9	We next compute the accuracy of our model for each threshold by removing the corresponding neutral sentences.
82	10	Across all thresholds, we notice trends similar to previous sections: 1) ELMo performs the best among all models on A-but-B style sentences, and projection results in only a slight improvement; 2) models in Hu et al. (2016) (with and without distillation) benefit considerably from projection; but 3) distillation offers little improvement (with or without projection).
85	35	We present an analysis comparing techniques for incorporating logic rules into sentiment classification systems.
86	45	Our analysis included a metastudy highlighting the issue of stochasticity in performance across runs and the inherent ambiguity in the sentiment classification task itself, which was tackled using an averaged analysis and https://github.com/martiansideofthemoon/ logic-rules-sentiment.
97	39	# Judgments Average Sentence Positive Negative Neutral 1 1 7 0.50 the fight scenes are fun , but it grows tedious 3 2 4 0.56 it ’s not exactly a gourmet meal but the fare is fair , even coming from the drive thru 2 3 4 0.44 propelled not by characters but by caricatures 4 2 3 0.61 not everything works , but the average is higher than in mary and most other recent comedies Table A1: Examples of neutral sentences for a threshold of 0.66 # Judgments Average Original Sentence Positive Negative Neutral 1 5 3 0.28 Positive de niro and mcdormand give solid performances , but their screen time is sabotaged by the story ’s inability to create interest 6 0 3 0.83 Negative son of the bride may be a good half hour too long but comes replete with a flattering sense of mystery and quietness 0 5 4 0.22 Positive wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of hubert ’s punches ) , but it should go down smoothly enough with popcorn Table A2: Examples of flipped sentiment sentences, for a threshold of 0.66 Model 1 vs Model 2 Significant distill no-project distill project Yes no-distill no-project no-distill project Yes ELMo no-project ELMo project No no-distill no-project distill no-project No no-distill project distill project No no-distill no-project ELMo no-project Yes distill no-project ELMo no-project Yes no-distill project ELMo project Yes distill project ELMo project Yes Table A3: Statistical significance using a two-sided Kolmogorov-Smirnov statistic (Massey Jr, 1951) with α = 0.001. al l en ds we ll , so rt of , bu t th e fre nz ie d co m ic m om en ts ne ve r cli ck all ends well , sort of , but the frenzied comic moments never click 0.1 0.0 0.1 0.2 0.3 0.4 al l en ds we ll , so rt of , bu t th e fre nz ie d co m ic m om en ts ne ve r cli ck all ends well , sort of , but the frenzied comic moments never click 0.1 0.2 0.3 0.4 0.5 0.6 al l en ds we ll , so rt of , bu t th e fre nz ie d co m ic m om en ts ne ve r cli ck all ends well , sort of , but the frenzied comic moments never click 0.1 0.2 0.3 0.4 0.5 m ar isa to m ei is go od , bu t ju st a ki ss is ju st a m es s marisa tomei is good , but just a kiss is just a mess 0.1 0.0 0.1 0.2 0.3 0.4 m ar isa to m ei is go od , bu t ju st a ki ss is ju st a m es s marisa tomei is good , but just a kiss is just a mess 0.2 0.3 0.4 0.5 0.6 m ar isa to m ei is go od , bu t ju st a ki ss is ju st a m es s marisa tomei is good , but just a kiss is just a mess 0.0 0.1 0.2 0.3 0.4 0.5 0.6 th e irw in s em er ge un sc at he d , bu t th e fic tio na l fo ot ag e is un co nv in cin g an d cr im in al ly ba dl y ac te d the irwins emerge unscathed , but the fictional footage is unconvincing and criminally badly acted 0.1 0.0 0.1 0.2 0.3 th e irw in s em er ge un sc at he d , bu t th e fic tio na l fo ot ag e is un co nv in cin g an d cr im in al ly ba dl y ac te d the irwins emerge unscathed , but the fictional footage is unconvincing and criminally badly acted 0.1 0.2 0.3 0.4 0.5 0.6 th e irw in s em er ge un sc at he d , bu t th e fic tio na l fo ot ag e is un co nv in cin g an d cr im in al ly ba dl y ac te d the irwins emerge unscathed , but the fictional footage is unconvincing and criminally badly acted 0.1 0.2 0.3 0.4 0.5 Figure A1: Heat map showing the cosine similarity between pairs of word vectors within a single sentence.

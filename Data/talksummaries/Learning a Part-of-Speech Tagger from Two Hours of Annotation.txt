15	52	Here, we evaluate on the languages Malagasy and Kinyarwanda, as well as English as a control language.
16	32	Furthermore, we are interested in whether type-supervision or tokensupervision is more effective, given the strict time constraint; accordingly, we had annotators produce both a tag dictionary and a set of labeled sentences.
17	24	The data produced under our conditions differs in several ways from the labeled data used in previous work.
20	97	Our training data is also much noisier than the data from a typical corpus: the annotations were produced by a single non-native-speaker working alone for two hours.
24	23	We then apply a novel weighted variant of the model minimization procedure originally developed by Ravi and Knight (2009) to estimate sequence and word-tag frequency information from an unlabeled corpus by approximating the minimal set of tag bigrams needed to explain the data.
25	26	This combination of techniques turns a tiny, unweighted, initial tag dictionary into a weighted tag dictionary that covers the entire corpus’s vocabulary.
26	37	This weighted information limits the potential damage of tag dictionary noise and bootstraps frequency information to approximate a good starting point for the learning of an HMM using expectation-maximization (EM), and far outperforms just using EM on the raw annotations themselves.
43	24	The first annotation task was to directly produce a dictionary of words to their possible POS tags—i.e., collecting an actual tag dictionary of the form that is typically simulated in POS-tagging experiments.
58	64	The input to our system is a raw corpus and either a human-generated tag dictionary or human-tagged sentences.
70	21	The graph contains a TOKEN node for each token of the labeled corpus (when available) and raw corpus.
73	39	The PREVWORD x and NEXTWORD x nodes represent the features of a token being preceded by or followed by word type x in the corpus.
75	52	To capture shallow morphological relatedness, we use prefix and suffix nodes that connect word types that share prefix or suffix character sequences up to length 5.
82	44	With tokensupervision, labels for tokens are injected into the corresponding TOKEN nodes with a weight of 1.0.
87	26	Our technique thus subsumes theirs as it can infer tag dictionary entries for words whose suffixes do not show up in the labeled data (or with enough frequency to be reliable predictors).
103	23	From this we can extract an expanded tag dictionary for use in subsequent stages that, crucially, provides tag information for words not covered by the human-supplied tag dictionary.
110	47	Model minimization is a natural fit for our system since we start with little or no frequency information and automatic dictionary expansion introduces noise.
111	89	We extend the greedy model minimization procedure of Ravi et al. (2010), and its enhancements by Garrette and Baldridge (2012), to develop a novel weighted minimization procedure that uses the tag weights from LP to find a minimal model that is biased toward keeping tag bigrams that have consistently high weights across the entire corpus.
112	38	The new weighted minimization procedure fits well in our pipeline by allowing us to carry the tag distributions forward from LP instead of simply throwing that information away and using a traditional tag dictionary.
113	20	In brief, the procedure works by creating a graph such that each possible tag of each raw-corpus token is a vertex (see Figure 2).
115	66	The algorithm first selects tag bigrams until every token is covered by at least one bigram, then selects tag bigrams that fill gaps between existing edges until there is a complete bigram path for every sentence in the raw corpus.8 Ravi et al. (2010) select tag bigrams that cover the most new words (stage 1) or fill the most holes in the tag paths (stage 2).
131	23	The HMM produced by stage three is not used directly for tagging since it will contain zeroprobabilities for test-corpus words that were unseen during training.
137	86	(2) uses LP to infer an expanded tag dictionary and tag distributions over raw corpus tokens, but then takes the highest-weighted tag from each token for use as noisily-labeled training data to initialize EM.
182	32	The type is not in the tag dictionary, so EM assumes all tags are valid and uses many labels.
208	44	With just two hours of annotation, we obtain 71-78% accuracy for POS-tagging across three languages using both type and token supervision.
209	18	Without tag dictionary expansion and model minimization, performance is much worse, from 63-74%.
210	50	We dramatically improve performance on unknown words: the range of 37-58% improves to 53-70%.
211	69	We also have a provisional answer to whether annotation should be on types or tokens: use typesupervision if you also expand and minimize.
212	67	These methods can identify missing word/tag entries and estimate frequency information, and they produce as good or better results compared to starting with token supervision.
213	24	The case of Kinyarwanda was most dramatic: 71% accuracy for token-supervision compared to 79% for type-supervision.
214	53	Studies using more annotators and across more languages would be necessary to make any stronger claim about the relative efficacy of the two strategies.

3	61	People exchange verbal messages which not only contain syntactic information, but also information conveying their mental and emotional states.
5	37	The automated processing of affect in human verbal communication is of great importance to understanding spoken language systems, particularly for emerging applications such as dialogue systems and conversational agents.
7	15	There has been a resurgence of research effort in recurrent neural networks for language modeling (Mikolov et al., 2010), which have yielded performances far superior to baseline language models based on n-gram approaches.
12	8	Figure 1 provides an overview of our Affect-LM and its ability to generate emotionally colored conversational text in a number of affect categories with varying affect strengths.
15	26	Our primary research questions in this paper are: Q1:Can Affect-LM be used to generate affective sentences for a target emotion with varying degrees of affect strength through a customizable model parameter?
43	95	3.2 Proposed Model: Affect-LM The proposed model Affect-LM has an additional energy term in the word prediction, and can be de- scribed by the following equation: P (wt = i|ct−1, et−1) = exp (Ui T f(ct−1) + βViTg(et−1) + bi)∑V j=1 exp(Uj T f(ct−1) + βVjTg(et−1) + bj) (3) et−1 is an input vector which consists of affect category information obtained from the words in the context during training, and g(.)
46	31	The parameter β defined in Equation 3, which we call the affect strength defines the influence of the affect category information (frequency of emotionally colored words) on the overall prediction of the target word wt given its context.
48	57	Our proposed model learns a generative model of the next word wt conditioned not only on the previous words w1, w2, ..., wt−1 but also on the affect category et−1 which is additional information about emotional content.
49	10	During model training, the affect category is inferred from the context data itself.
65	12	The Fisher English Training Speech Corpus is the main corpus used for training the proposed model, in addition to which we have chosen three emotionally colored conversational corpora.
70	12	Distress Assessment Interview Corpus (DAIC): The DAIC corpus introduced by Gratch (2014) consists of 70+ hours of dyadic interviews between a human subject and a virtual human, where the virtual human asks questions designed to diagnose symptoms of psychological distress in the subject such as depression or PTSD (Post Traumatic Stress Disorder).
71	18	SEMAINE dataset: SEMAINE (McKeown et al., 2012) is a large audiovisual corpus consisting of interactions between subjects and an operator simulating a SAL (Sensitive Artificial Listener).
86	70	To evaluate whether additional emotional information could improve the prediction performance, we train the corpora detailed in Section 4.1 in two stages as described below: (1) Training and validation of the language models on Fisher dataset- The Fisher corpus is split in a 75:15:10 ratio corresponding to the training, validation and evaluation subsets respectively, and following the implementation in Zaremba et al. (2014), we train the language models (both the baseline and Affect-LM) on the training split for 13 epochs, with a learning rate of 1.0 for the first four epochs, and the rate decreasing by a factor of 2 after every subsequent epoch.
92	27	For each model adapted on a corpus, we compare the perplexities obtained by Affect-LM and the baseline model when evaluated on that corpus.
93	56	We assess Affect-LM’s ability to generate emotionally colored text of varying degrees without severely deteriorating grammatical correctness, by conducting an extensive perception study on Amazon’s Mechanical Turk (MTurk) platform.
95	56	Specifically, we generated more than 200 sentences for four sentence beginnings (namely the three sentence beginnings listed in Table 2 as well as an end of sentence token indicating that the model should generate a new sentence) in five affect categories happy(positive emotion), angry, sad, anxiety, and negative emotion.
100	16	We measured inter-rater agreement using Krippendorffs α and observed considerable agreement between raters across all categories (e.g., for valence α = 0.510 and grammatical correctness α = 0.505).
105	76	Table 2 shows three sentences generated by the model for input sentence beginnings I feel so ..., Why did you ... and I told him to ... for each of five affect categories - happy(positive emotion), angry, sad anxiety, and neutral(no emotion).
106	13	They have been selected from a pool of 20 generated sentences for each category and sentence beginning.
108	12	The multivariate result was significant for positive emotion generated sentences (Pillai’s Trace=.327, F(4,437)=6.44, p<.0001).
115	19	This finding is in concordance with the intended LIWC category of negative affect that forms a parent category above the more specific emotions, such as angry, sad, and anxious (Pennebaker et al., 2001).
116	51	Grammatical correctness was also significantly influenced by the affect strength β and results show that the correctness deteriorates with increasing β (see Figure 3).
118	9	The multivariate result was significant for angry generated sentences (Pillai’s Trace=.199, F(4,433)=3.76, p<.0001).
134	9	For all corpora, we find that Affect-LM achieves lower perplexity on average than the baseline model, implying that affect category information obtained from the context words improves language model prediction.
138	54	In Equation 3, Affect-LM learns a weight matrix V which captures the correlation between the predicted word wt, and the affect category et−1.
141	41	Words colored grey are those not in the LIWC dictionary.
142	23	In Figure 4, we observe that the embeddings contain affective information, where the positive emotion is highly separated from the negative emotions (sad, angry, anxiety) which are clustered together.
144	48	MTurk perception studies show that the model can generate expressive text at varying degrees of emotional strength without affecting grammatical correctness.
145	115	We also evaluate Affect-LM as a language model and show that it achieves lower perplexity than a baseline LSTM model when the affect category is obtained from the words in the context.
146	256	For future work, we wish to extend this model by investigating language generation conditioned on other modalities such as facial images and speech, and to applications such as dialogue generation for virtual agents.

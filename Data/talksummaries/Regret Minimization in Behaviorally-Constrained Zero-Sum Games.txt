17	31	Our algorithm also converges at the same rate in the unperturbed game, almost until the point where the imposed behavioral constraints necessarily prevent further convergence.
41	28	We denote by R+ and R− the set of non-negative and non-positive reals, respectively.
42	94	A two-player zero-sum normal-form game (for the rest of the paper, simply normal-form game or NFG) is a tuple (A1, A2, u) where A1 represents the finite set of actions that player 1 can play,A2 represents the finite set of actions that player 2 can play, and u : A1×A2 → R is the payoff function for player 1, mapping the pair of actions (a1, a2) of the players into the payoff for player 1.
49	11	When players play according to mixed strategies π1 and π2 respectively, the expected payoff is given by Eπ1,π2(u) = ∑ a1∈A1 ∑ a2∈A2 π1(a1)π2(a2)u(a1, a2).
57	21	Using Equation 1, we conclude that Γ is equivalent to the generalized two-player zero-sum normal-form game Γ∗ = (X ,Y, u∗), where u∗(x, y) = x>Uy for all (x, y) ∈ X × Y .
63	21	Ii is the information partition of player i, while the sets in Ii are called the information sets of player i.
65	13	The corresponding utility for player 2 is given by −u(z).
93	15	We now turn to the class of perturbed games (Selten, 1975).
94	12	Intuitively, a perturbation restricts the set of playable strategies by enforcing a lower bound on the probability of playing each action.
102	46	Let Γ = (H,Z,A, P, fc, I1, I2, u) be an extensive-form game.
104	53	The corresponding perturbed EFG Γp is the analogous game where each action a at each information set I has to be played with probability at least p(I, a).
105	68	Perturbations play an important role in equilibrium refinement, as they form the basis for the concept of equilibrium perfection (Selten, 1975).
106	20	In this paper we only focus on the case of extensive-form perfect equilibria (EFPEs).
107	37	A strategy pair (x, y) ∈ X ×Y is an EFPE of Γ if it is a limit point of a sequence {(xp, yp)}p→0 where (xp, yp) is a Nash equilibrium of the perturbed game Γp.
112	103	Let Γ = (X ,Y, u) be a generalized normalform game played on the finitely-generated convex polytopes X and Y .
118	78	Let f∗ be any of regret-minimizing schemes for normal-form games (e.g., RM or RM+).
125	126	Another way to think about the construction above is that at each iteration, we compute the regret for not playing each of the “strategies” forming the vertices of the polytope, and updating the next strategy by taking a convex combination of the vertices, in a way proportional to the regret against them.
129	77	Given a generalized normal-form game (X ,Y, u) with finitely generated X and Y , the maximum average external regret for player 1 at iteration T , when player 1 plays according to Algorithm 1, is bounded by max x̂∈X R̄T1 (x̂) ≤ γ √ |X |√ T where γ .= maxx,y u(x, y) − minx,y u(x, y), and |X | denotes the number of vertices of X .
130	18	Algorithm 1 RM+ algorithm for generalized normal-form games played over finitely-generated convex polytopes.
133	26	do 5: if rt−1 ∈ Rn− then 6: xt ← any action ∈ X̃p 7: else 8: Λt−1 ← n∑ i=1 [rt−1] + i 9: xt ← B [rt−1]+ Λt−1 10: play action xt 11: observe yt ∈ Y played by opponent 12: rt ← rt−1 + u(b1, yt)− u(xt, yt)... u(bn, yt)− u(xt, yt)   + 13: x̄← t− 1 t x̄+ 1 t xt .
136	52	In order to obtain a regret minimizer for a behaviorally-constrained EFG, we could try to cast the game as a generalized NFG by means of the normal-form or sequence form representation (see Observation 2).
137	44	However, the number of vertices of this representation is exponential, and therefore it does not work well with Theorem 4.
138	25	Counterfactual Regret (CFR, Zinkevich et al. 2007) solves this problem, by defining a regretminimizing scheme that runs in polynomial time in the size of the game.
139	22	Intuitively, CFR minimizes a variant of instantaneous regret, called immediate counterfactual regret, at each information set separately, and later combines the strategies computed at each information set.
142	39	We can then use Theorem 4 to get regret minimizers for each information set.
143	26	Perturbations can be handled as a special case.
145	26	For this approach to be practical, we need the set of vertices for each information set to be of manageable size, as reflected in the dependence on maxI∈I √ |QI | in Theorem 5, where |QI | is the number of vertices in the behaviorally-constrained simplex at information set I .
146	14	Let (H,Z,A, P, fc, I1, I2, u) be an extensive-form game; let QI ⊆ ∆|A(I)| represent the behaviorally-constrained strategy space at information set I , for all I ∈ I1 ∪ I2.
147	81	The maximum average external regret for player 1 in the constrained game at iteration T , when player 1 plays according to CFR+, is bounded by R̄T1 ≤ γ|I1| √ maxI∈I1 |QI |√ T , where γ .= maxx,y u(x, y)−minx,y u(x, y).
148	18	Section 4 established that, in general, the problem of finding an approximate Nash equilibrium for player 1 in the generalized normal-form game Γ = (X ,Y, u), where X is a convex polytope generated by n vectors, can be solved via regret-matching.

0	69	Open domain Question Answering (QA) is the task of finding answers to questions posed in natural language.
1	14	Historically, this required a specialized pipeline consisting of multiple machinelearned and hand-crafted modules (Ferrucci et al., 2010).
2	7	Recently, the paradigm has shifted towards training end-to-end deep neural network models for the task (Chen et al., 2017; Liang et al., 2017; Raison et al., 2018; Talmor and Berant, 2018; Iyyer et al., 2017).
3	287	Most existing models, however, answer questions using a single information source, usually either text from an encyclopedia, or a single knowledge base (KB).
4	4	Intuitively, the suitability of an information source for QA depends on both its coverage and ∗Haitian Sun and Bhuwan Dhingra contributed equally to this work.
5	8	the difficulty of extracting answers from it.
15	23	Instead, we focus on an early fusion strategy, where a single model is trained to extract answers from a question subgraph (Fig 1) containing relevant KB facts as well as text sentences.
16	6	Early fusion allows more flexibility in combining information from multiple sources.
17	10	To enable early fusion, in this paper we propose a novel graph convolution based neural network, called GRAFT-Net (Graphs of Relations Among Facts and Text Networks), specifically designed to operate over heterogeneous graphs of KB facts and text sentences.
19	32	First, we propose heterogeneous update rules that handle KB nodes differently from the text nodes: for instance, LSTM-based updates are used to propagate information into and out of text nodes (§ 3.2).
20	20	Second, we introduce a directed propagation method, inspired by personalized Pagerank in IR (Haveliwala, 2002), which constrains the propagation of embeddings in the graph to follow paths starting from seed nodes linked to the question (§ 3.3).
22	46	We evaluate these methods on a new suite of benchmark tasks for testing QA models when both KB and text are present.
23	24	Using WikiMovies (Miller et al., 2016) and WebQuestionsSP (Yih et al., 2016), we construct datasets with a varying amount of training supervision and KB completeness, and with a varying degree of question complexity.
24	53	We report baselines for future comparison, including Key Value Memory Networks (Miller et al., 2016; Das et al., 2017c), and show that our proposed GRAFT-Nets have superior performance across a wide range of conditions (§ 5).
25	2	We also show that GRAFT-Nets are competitive with the state-of-the-art methods developed specifically for text-only QA, and state-of-the art methods developed for KB-only QA (§ 5.4)1.
26	227	A knowledge base is denoted as K = (V, E ,R), where V is the set of entities in the KB, and the edges E are triplets (s, r, o) which denote that relation r ∈ R holds between the subject s ∈ V and object o ∈ V .
27	53	A text corpus D is a set of documents {d1, .
29	12	We further assume that an (imperfect) entity linking system has been run on the collection of documents whose output is a set L of links (v, dp) connecting an entity v ∈ V with a word at position p in document d, and we denote with Ld the set of all entity links in document d. For entity mentions spanning multiple words in d, we include links to all the words in the mention in L. The task is, given a natural language question q = (w1, .
31	18	In this paper, we assume that the answers are entities from either the documents or the KB.
32	120	We are interested in a wide range of settings, where the KB K varies from highly incomplete to complete for answering the questions, and we will introduce datasets for testing our models under these settings.
33	12	To solve this task we proceed in two steps.
34	30	First, we extract a subgraph Gq ⊂ G which contains the answer to the question with high probability.

24	22	Our experiments in both environments with a variety of settings present the strength of explicitly modeling programs for reasoning underlying conditions and the necessity of the proposed components (the summarizer module and the auxiliary tasks).
25	20	In summary, in this paper, we introduce a novel problem of program synthesis from diverse demonstration videos and a method to address it.
26	7	This substantially enables machines to explicitly interpret decision making logic and interact with humans.
40	41	In this section, we define our formulation for program synthesis from diverse demonstration videos.
45	13	Note that we focus on perceptions with boolean types in this paper, although a more generic perception type constraint is possible.
46	5	A program η is a deterministic function that outputs an action a ∈ A given a history of states at time step t, Ht = (s1, s2, ..., st), where s ∈ S is a state of the environment.
47	18	The generation of an action given the history of states is represented as at = η (Ht).
50	6	The following state s2 is generated by a state transition function T : s2 ∼ T (s1, a1).
55	5	Note that our objective is not about inferring a code perfectly but instead generating a code that can infer the underlying program, which models the diverse behaviors appearing in the demonstrations in an executable form.
57	54	• Summarizer Module discovers and summarizes where actions diverge between demonstrations and upon which branching conditions subsequent actions are taken.
58	10	• Program Decoder represents the summarized understanding of demonstrations as a code sequence.
59	15	The details of the three main components are described in the Section 4.1, and the learning objective of the proposed model is described in Section 4.2.
61	8	Figure 3 illustrates the overall architecture of the proposed model, The details of each component are described in the following sections.
64	1	Since the demonstration encoder needs to handle demonstrations with variable numbers of frames, we employ an LSTM (Long Short Term Memory) (Hochreiter & Schmidhuber, 1997) to encode each state vector and summarized representation at the same time.
66	5	While final state tuples (cTenc, h T enc) encode the overall idea of the demonstration, intermediate hidden states {h1enc, h2enc, ..., hTenc} contain high level understanding of each state, which are used as an input to the following modules.
67	32	Note that these operations are applied to allK demonstrations while the index k is dropped in the equations for simplicity.
68	25	Inferring an underlying program from demonstrations that exhibits different behaviors requires the ability to discover and summarize where actions diverge between demonstrations and upon which branching conditions subsequent actions are taken.
69	148	The summarizer module first re-encodes each demonstration with the context of all encoded demonstrations to infer branching conditions.
70	50	Then, the module aggregates all encoded demonstration vectors to obtain the summarized representation.
71	52	An illustration of the summarizer is shown in Figure 4.
72	24	The first summarization is performed by a reviewer module, an LSTM initialized with the average-pooled final state tuples of the demonstration encoder outputs, which can be written as follows: c0review = 1 K K∑ k=1 cT,kenc , h 0 review = 1 K K∑ k=1 hT,kenc , (2) where (cT,kenc , h T,k enc ) is the final state tuple of the kth demonstration encoder.
73	28	Then the reviewer LSTM encodes the hidden states by ct,kreview, h t,k review = LSTMreview(h t,k enc, c t−1,k review , h t−1,k review ), (3) where the final hidden state becomes a demonstration vector vkdemo = h T,k review ∈ Rd, which includes the summarized information within a single demonstration.
77	16	vsummary = RN ( v1demo, ..., v K demo ) = 1 K2 K∑ i,j gθ(v i demo, v j demo), (4) where vsummary ∈ Rd is the summarized demonstration vector and gθ is an MLP parameterized by θ jointly trained with the summarizer module.
79	23	The program decoder synthesizes programs from a summarized representation of all the demonstrations.
80	3	We use LSTMs similar to (Sutskever et al., 2014; Vinyals et al., 2015) as a program decoder.
83	18	The proposed model learns a conditional distribution between a set of demonstrations D and a corresponding code C = {w1, w2, ..., wN}.

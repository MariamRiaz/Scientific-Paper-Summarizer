0	34	Grapheme-to-phoneme (G2P) conversion is the problem of converting a string of letters into a string of phonetic symbols.
2	16	The classical learning paradigm in each of these settings is to train a model on pairs of strings {(x,y)} and then to evaluate model performance on test data.
3	12	While there are exceptions (e.g., (Rao et al., 2015)), most state-of-the-art modelings (e.g., (Jiampojamarn et al., 2007; Bisani and Ney, 2008; Jiampojamarn et al., 2008; Jiampojamarn et al., 2010; Novak et al., 2012)) view string transduction as a two-stage process in which string pairs (x,y) in the training data are first aligned, and then a subsequent (e.g., sequence labeling) module is learned on the aligned data.
4	87	State-of-the-art alignments in G2P are characterized by the following properties: (i) Alignments are monotone in that the ordering of characters in input and output sequences is preserved by the alignments.
5	19	Furthermore, they are many-to-many in the sense that several x sequence characters may be matched up with several y sequence characters as illustrated in Table 1.
6	17	(ii) The alignment is a latent variable and learnt in an unsupervised manner from pairs of strings in the training data.
22	13	Section 4 presents our data and Section 5 our experiments.
28	11	,yk) be the corresponding induced segmentation of y.
33	32	We call an alignment model f a unigram alignment model if f takes the form, for any Ax,y ∈ AS(x,y), f(Ax,y) = k∑ i=1 sim1(xi,yi) (1) where sim1 is an arbitrary (real-valued) similarity function measuring similarity of two subsequences.
34	38	We call an alignment model f a bigram alignment model if f takes the form f(Ax,y) = k∑ i=1 sim2 ( (xi,yi), (xi−1,yi−1) ) (2) where sim2 is an arbitrary (real-valued) similarity function measuring similarity of successive pairs of subsequences.
36	125	Then, funi is a unigram alignment model that assigns the score
71	17	The reason is that a (probabilistic) unigram alignment model adds log-probabilities of matched-up subsequences, which, if not appropriately corrected for, makes alignments with few match-ups a priori more likely than alignments with many matchups, when probabilities of individual match-ups are uniformly or randomly initialized (as is typically the case for EM maximum likelihood estimation in unsupervised models).
75	42	Our own alignment model is, as indicated, supervised.
77	60	Here, logp(z) denotes the log-probability — estimated from the training data — of observing the object z, and α, β, γ and δ are parameters.
79	31	We refer to this unigram alignment model as uniα,β,γ,δ.
82	16	We refer to this bigram alignment model as biα,β,γ,δ.
88	13	We employ two measures of alignment quality.
106	73	Unsurprisingly, the supervised alignment models perform better than the unsupervised ones (Tables 5 and 6).
107	134	Surprisingly, however, they do so with very little training data; fewer than 100 aligned string pairs suffice to outperform the unsupervised models under good calibrations.
108	13	When there is sufficient training data, the supervised models perform splendidly, with a peak accuracy of 99.43% for the bigram alignment model that includes appropriate features (scoring lengths of aligned subsequences, etc.).
109	36	We also note that the bigram alignment model is almost consistently better than the unigram alignment model, with a surplus of about 1% point, depending on specific parametrizations.
111	117	Results are quite similar except that unigram and bigram alignment model have indistinguishable performance on the German data, indicating (the known fact) that G2P is a more complex task in English, apparently not requiring bigram alignment models.
112	76	Error analysis Concerning errors that the unigram model commits and the bigram model does not, the majority of errors (roughly 80%) involve match-ups of ed/d and d. For example, the unigram model aligns as in t w i n k le d t w I N k @l d while the gold-standard alignment is t w i n k l ed t w I N k @l d While all match-ups in both alignments are plausible, the bigram model assigns here higher probability to the correct ed/d match-up in terminal position (consistently favored in the data set), which has a particular meaning there, namely, that of a suffix marker for past tense.8,9 In the German data, there is a single instance where the unigram and bigram alignment model disagree, namely, in the alignment of s-t-o-ff-f-l-a-sch-e/S-t-O-f-f-l-&S-@, which the unigram model falsely aligns as s-t-o-f-ff-l-a-sch-e/S-t-O-f-f-l-&-S-@; note that in the correct alignment f must follow ff, not vice versa, which depends on context information, e.g., that o/O signifies a short vowel which is followed by a double consonant, not a single consonant.
120	77	We first note that, as the supervised aligner receives more training data from which to align the 5 000 string pairs, the overall G2P accuracy of both DirecTL+ and Phonetisaurus increase substantially (and as a convex function of training set size).
121	36	Apparently, the better alignments produced by more training data for the particular supervised aligner considered directly translate into better overall G2P accuracy.
126	12	In each of these cases, we obtained an alignment quality score and a subsequent overall G2P system performance.
128	51	This figure seems to corroborate the linear relationship (apparently present in Figure 1) between alignment quality and overall G2P system accuracy, particularly, when alignment quality is measured in the more finegrained metric of edit distance.
129	19	To formally test this, we regress overall G2P system performance (measured in word accuracy) on edit distance and other variables.10 This yielded the coefficients as given in Table 8; in each case, the goodness-offit of the linear model was quite large, with R2 values above 90% for the English data and about 84% for the German data.
134	36	In these, we align training sets of sizes 100, 500, 1 000, 2 000, 10 000, 20 000, 40 000 and 60 000 via our several alignment systems.
138	101	Table 9 shows that training G2P systems from the human gold standard alignments in each case yields better overall G2P transcriptions than training them from either of the three unsupervised alignments considered here.

14	1	The main contributions are: (1) deterministic procedure to generate potential interpretations by manipulating syntactic dependencies; (2) analysis showing that dependencies yield finer-grained interpretations and better results than previous work using semantic roles; (3) a corpus of negations and their positive interpretations;1 and (4) experimental results with gold-standard and predicted linguistic information.
52	1	Scope of negation detection has received a lot of attention, mostly using two corpora: BioScope in the medical domain (Szarvas et al., 2008) and CDSCO (Morante and Daelemans, 2012).
65	1	Their approach has 2 limitations.
67	1	Second, because they select as focus a semantic role, they only consider coarsegrained foci.
79	1	With predicted linguistic information, Rosenberg and Bergler (2012) report an Fmeasure of 58.4 using 4 linguistically sound heuristics, and Zou et al. (2014) an F-measure of 65.62 using contextual discourse information.
84	1	First, we deterministically generate potential positive interpretations from verbal negations by manipulating syntactic dependencies (Section 4.1).
88	1	After pilot experiments, it became clear that asking annotators to propose positive interpretations complicates the annotation effort (lower agreements) as well as learning.
100	1	Remove the negation mark by deleting the token with syntactic dependency neg.
102	1	For example (before: after), doesn’t go: goes, didn’t go: went, won’t go: will go.
114	1	Additionally, we discard potential foci that consist only of (1) the determiners the, a and an, or (2) a single token with part-of-speech tag TO, CC, UH, POS, XX, IN, WP or dependency relation prt.
118	1	Similarly, from It is not supported by the text or history of the Constitution, we avoid generating potential interpretation It is supported by X text or history of the Constitution, but not by the text or history of the Constitution (focus would be the); and from You don’t want to get yourself too upset about these things, potential interpretation You want X get yourself too upset about these things, but not to get (focus would be to, with part-of-speech tag TO).
128	1	This simple guidelines were sufficient to reliably score plausible positive interpretations automatically generated (Section 5).
130	1	Out of all these potential positive interpretations, we annotate 1700 (1008 coarse- and 692 fine-grained).
136	1	Overall Pearson correlation was 0.75.
145	1	Specifically, Interpreta- tion 2.1: Those concerns are avoided in public (focus is expressed), Interpretation 2.2: Something is expressed in public (focus is Those concerns), Interpretation 2.4: Some concerns (but not problematic or secret concerns) are expressed in public (focus is Those), and Interpretation 2.5: Those concerns are expressed in private (focus is in public).
171	1	All models are trained with gold-standard linguistic annotations, and tested with either gold-standard or predicted linguistic annotations.
173	1	Training with the word form of the negation mark is virtually useless, it yields a Pearson correlation of −0.109.
191	9	The mean score is 3.20 (out of 5.0), thus we extract a substantial amount of positive meaning.
192	64	The work presented in this paper is not tied to any existing semantic representation.
193	64	While we rely heavily on syntactic dependencies, positive interpretations are generated in plain text, and they could be processed, along with the original negated statement, with any NLP pipeline.

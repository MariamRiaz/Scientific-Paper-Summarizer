0,1,label2,summary_sentences
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2357–2366, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"As science advances, scientists around the world continue to produce a large number of research articles, which provide the technological basis for worldwide dissemination of scientific discoveries.",1 Introduction,[0],[0]
"Online digital libraries such as Google Scholar, CiteSeerx, and PubMed store and index millions of such research articles and their metadata, and make it easier for researchers to search for scientific information.",1 Introduction,[0],[0]
These libraries require effective and efficient methods for topic classification of research articles in order to facilitate the retrieval of content that is tailored to the interests of specific individuals or groups.,1 Introduction,[0],[0]
"Supervised approaches for topic classification of research articles have been developed, which generally use either the content of the articles (Caragea et al., 2011), or take into account the citation relation between research articles (Lu and Getoor, 2003).
",1 Introduction,[0],[0]
"To be successful, these supervised approaches assume the availability of large amounts of labeled
data, which require intensive human labeling effort.",1 Introduction,[0],[0]
"In this paper, we explore a semi-supervised approach that can exploit large amounts of unlabeled data together with small amounts of labeled data for accurate topic classification of research articles, while minimizing the human effort required for data labeling.",1 Introduction,[0],[0]
"In the scholarly domain, research articles (or papers) are highly interconnected in giant citation networks, in which papers cite or are cited by other papers.",1 Introduction,[0],[0]
"We posit that, in addition to a document’s textual content and its local neighborhood in the citation network, other information exists that has the potential to improve topic classification.",1 Introduction,[0],[0]
"For example, in a citation network, information flows from one paper to another via the citation relation (Shi et al., 2010).",1 Introduction,[0],[0]
"This information flow and the topical influence of one paper on another are specifically captured by means of citation contexts, i.e., short text segments surrounding a citation’s mention.
",1 Introduction,[0],[0]
"These contexts are not arbitrary, but they often serve as brief summaries of a cited paper.",1 Introduction,[0],[0]
"We therefore hypothesize that these micro-summaries can be successfully used as an independent view of a research article in a co-training framework to reduce the amount of labeled data needed for the task of topic classification.
",1 Introduction,[0],[0]
"The idea of using terms from citation contexts stems from the analysis of hyperlinks and the graph structure of the Web, which are instrumental in Web search (Manning et al., 2008).",1 Introduction,[0],[0]
"Many search engines follow the intuition that the anchor text pointing to a page is a good descriptor of its content, and thus anchor text terms are used as additional index terms for a target webpage.",1 Introduction,[0],[0]
"The use of links and anchor text was thoroughly researched for information retrieval (Koolen and Kamps, 2010), broadening a user’s search (Chakrabarti et al., 1998), query refinement (Kraft and Zien, 2004), and enriching document representations (Metzler et al., 2009).",1 Introduction,[0],[0]
"Blum and
2357
Mitchell (1998) introduced the co-training algorithm using hyperlinks and anchor text as a second, independent view of the data for classifying webpages, in addition to a webpage content.
",1 Introduction,[0],[0]
Contributions and Organization.,1 Introduction,[0],[0]
"We present a co-training approach to topic classification of research papers that effectively incorporates information from a citation network, in addition to the information contained in each paper.",1 Introduction,[0],[0]
"The result of this classification task will aid indexing of documents in digital libraries, and hence, will lead to improved organization, search, retrieval, and recommendation of scientific documents.",1 Introduction,[0],[0]
"Our contributions are as follows:
• We propose the use of citation contexts as an additional view in a co-training approach, which results in high accuracy classifiers.",1 Introduction,[0],[0]
"To our knowledge, this has not been addressed in the literature.",1 Introduction,[0],[0]
"• We show experimentally that our co-training
classifiers significantly outperform: (1) supervised classifiers trained using either content or citation contexts independently, for the same fraction of labeled data; and (2) several other semi-supervised classifiers, trained on the same fractions of labeled and unlabeled data as co-training.",1 Introduction,[0],[0]
"• We also show that using the citation context
information available in citation networks, the human effort involved in data labeling for training accurate classifiers can be largely reduced.",1 Introduction,[0],[0]
"Our co-training classifiers trained on a very small sample of labeled data and a large sample of unlabeled data yield accurate topic classification of research articles.
",1 Introduction,[0],[0]
The rest of the paper is organized as follows.,1 Introduction,[0],[0]
"In Section 2, we discuss related work.",1 Introduction,[0],[0]
"Section 3 describes our data and its characteristics, followed by the presentation of our proposed co-training approach in Section 4.",1 Introduction,[0],[0]
"We present experiments and results in Section 5, and conclude the paper and present future directions of our work in Section 6.",1 Introduction,[0],[0]
We discuss here the most relevant works to our study.,2 Related Work,[0],[0]
A large variety of methods have been proposed in the literature with regard to automatic text classification and topic prediction.,2 Related Work,[0],[0]
"Different classifiers have been applied on the Vector Space Model (VSM), in which a document is represented as a vector of words or phrases asso-
ciated with their TF-IDF score, i.e. term frequency - inverse document frequency (Zhang et al., 2011; Kansheng et al., 2011).",2 Related Work,[0],[0]
"VSM is the most used method due to its simple, efficient and easy to understand implementation.",2 Related Work,[0],[0]
"Another widely used model is the Latent Semantic Indexing (LSI) where co-occurrences are analyzed to find semantic relationships between words or phrases (Zhang et al., 2011; Ganiz et al., 2011).",2 Related Work,[0],[0]
"Moreover, a great range of classifiers were used for this task, including: Naı̈ve Bayes (Lewis and Ringuette, 1994), Knearest neighbors (Yang, 1999) and Support Vector Machines (Joachims, 1998).",2 Related Work,[0],[0]
"These techniques, however, all require a large number of labeled documents in order to build accurate classifiers.",2 Related Work,[0],[0]
"In contrast, we propose a co-training algorithm that only requires a small amount of labeled data in order to make accurate topic classification.
Semi-supervised methods essentially involve different means of transferring labels from labeled to unlabeled samples in the process of learning a classifier that can generalize well on new unseen data.",2 Related Work,[0],[0]
"Co-training was originally introduced in (Blum and Mitchell, 1998) where it was used to classify web pages into academic course home page or not.",2 Related Work,[0],[0]
"This approach has two views of the data as follows: the content of a web page, and the words found in the anchor text of the hyperlinks that point to the web page.",2 Related Work,[0],[0]
"Wan (2009) used co-training for cross-lingual sentiment classification of product reviews, where English and Chinese features were considered as two independent views of the data.",2 Related Work,[0],[0]
"Furthermore, Gollapalli et al. (2013) used co-training to identify authors’ homepages from the current-day university websites.",2 Related Work,[0],[0]
"The paper presents novel features, extracted from the URL of a page, that were used in conjunction with content features, forming two complementary views of the data.
",2 Related Work,[0],[0]
Citation networks have been used before in other problems.,2 Related Work,[0],[0]
Caragea et al. (2014) used citation contexts to extract informative features for keyphrase extraction.,2 Related Work,[0],[0]
"Lu and Getoor (2003) proposed an approach for document classification that used only citation links, without any textual data from the citation contexts.",2 Related Work,[0],[0]
Ritchie et al. (2006) used a combination of terms from citation contexts and existing index terms of a paper to improve indexing of cited papers.,2 Related Work,[0],[0]
"Citation contexts were also used to improve the performance of citation recommendation systems (Kataria et al., 2010) and to study author influence in document networks
(Kataria et al., 2011).",2 Related Work,[0],[0]
"Moreover, citation contexts were used for scientific paper summarization (Abu-Jbara and Radev, 2011; Qazvinian et al., 2010; Qazvinian and Radev, 2008; Mei and Zhai, 2008; Lehnert et al., 1990)",2 Related Work,[0],[0]
"For example, in Qazvinian et al. (2010), a set of important keyphrases is extracted first from the citation contexts in which the paper to be summarized is cited by other papers and then the “best” subset of sentences that contain such keyphrases is returned as the summary.",2 Related Work,[0],[0]
Mei and Zhai (2008) used information from citation contexts to determine what sentences of a paper are of high impact (as measured by the influence of a target paper on further studies of similar or related topics).,2 Related Work,[0],[0]
"These sentences constitute the impact-based summary of the paper.
",2 Related Work,[0],[0]
"Despite the use of citation contexts and anchor text in many information retrieval and natural language processing tasks, to our knowledge, we are the first to propose the incorporation of citation context information available in citation networks in a co-training framework for topic classification of research papers.",2 Related Work,[0],[0]
The dataset used in our experiments is a subset sampled from the CiteSeerx digital library1 and labeled by Dr. Lise Getoor’s research group at the University of Maryland.,3 Data,[0],[0]
"This subset was previously used in several studies including (Lu and Getoor, 2003) and (Kataria et al., 2010).",3 Data,[0],[0]
"The dataset consists of 3186 labeled papers, with each paper being categorized into one of six classes: Agents, Artificial Intelligence (AI), Information Retrieval (IR), Machine Learning (ML), HumanComputer Interaction (HCI) and Databases (DB).",3 Data,[0],[0]
"For each paper, we acquire the citation contexts directly from CiteSeerx.",3 Data,[0],[0]
A citation context is defined as a window of n words surrounding a citation mention.,3 Data,[0],[0]
"We differentiate between cited and citing contexts for a paper as follows: let d be a target paper and C be a citation network such that d ∈ C. A cited context for d is a context in which d is cited by some paper di in C. A citing context for d is a context in which d is citing some paper dj in C. If a paper is cited in multiple contexts within another paper, the contexts are aggregated into a single context.",3 Data,[0],[0]
"For each paper in the dataset, we have at least one cited or one citing context.",3 Data,[0],[0]
"A summary of the dataset is provided in Table 1.
",3 Data,[0],[0]
"1http://citeseerx.ist.psu.edu/
As expected, we have a higher number of cited contexts than citing contexts.",3 Data,[0],[0]
This is due to the page restrictions often imposed to research articles that can limit the number of papers each article can cite.,3 Data,[0],[0]
"On the other hand, a good research paper can accumulate hundreds of citations, and hence, cited contexts over the years.
",3 Data,[0],[0]
Context lengths.,3 Data,[0],[0]
"In CiteSeerx, citation contexts have about 50 words on each side of a citation mention.",3 Data,[0],[0]
A previous study by Ritchie et al. (2008) shows that a fixed window length of about 100 words around a citation mention is generally effective for information retrieval tasks.,3 Data,[0],[0]
"For this reason, we use the contexts provided by CiteSeerx directly.",3 Data,[0],[0]
"In future, it would be interesting to study more sophisticated approaches to identifying the text that is relevant to a target citation (Abu-Jbara and Radev, 2012; Teufel, 1999) and study the influence of context lengths on our task.
",3 Data,[0],[0]
"For all experiments, our labeled dataset is split in train, validation and test sets.",3 Data,[0],[0]
The validation and test sets have about 200 papers each.,3 Data,[0],[0]
"We sampled another set of papers from the labeled dataset in order to simulate the existence of unlabeled data, with a fixed size of around 2000 papers.",3 Data,[0],[0]
The remaining 786 papers are used as labeled training data.,3 Data,[0],[0]
Each experiment was repeated 10 times with 10 different random seeds and the results were averaged.,3 Data,[0],[0]
Blum and Mitchell (1998) proposed the cotraining algorithm in the context of webpage classification.,4 Co-Training for Topic Classification,[0],[0]
"In co-training, the idea is that two classifiers trained on two different views of the data teach one another by re-training each classifier on the data enriched with predicted examples that the other classifier is most confident about.",4 Co-Training for Topic Classification,[0],[0]
"In Blum and Mitchell (1998), webpages are represented using two different views: (1) using terms from webpages’ content and (2) using terms from the anchor text of hyperlinks pointing to these pages.
",4 Co-Training for Topic Classification,[0],[0]
"Algorithm 1 Co-Training Input: L, U , ‘s’
L1 ← L, L2 ← L while U 6= ∅",4 Co-Training for Topic Classification,[0],[0]
"do
Train classifier C1 on L1 Train classifier C2 on L2 S ← ∅",4 Co-Training for Topic Classification,[0],[0]
"Move ‘s’ examples from U to S U ← U\S S1, S2 ← GetMostConfidentExamples(S,
C1, C2) L1 ← L1 ∪ S1, L2 ← L2 ∪ S2 U ← U ∪",4 Co-Training for Topic Classification,[0],[0]
"[S\(S1 ∪ S2)]
end while Ouput: The combined classifier C of C1 and C2
In this paper, we study the applicability and extension of the co-training algorithm to the task of topic classification of research papers, which are embedded in large citation networks.",4 Co-Training for Topic Classification,[0],[0]
"Here, in addition to the information contained in a paper itself, citing and cited papers capture different aspects (e.g., topicality, domain of study,",4 Co-Training for Topic Classification,[0],[0]
"algorithms used) about the target paper (Teufel et al., 2006), with citation contexts playing an instrumental role.",4 Co-Training for Topic Classification,[0],[0]
"We conjecture that citation contexts, which act as brief summaries about a cited paper, provide important clues in predicting the topicality of a target paper.",4 Co-Training for Topic Classification,[0],[0]
These clues give rise to the design of our co-training based model for topic classification of research papers.,4 Co-Training for Topic Classification,[0],[0]
"In our model, we use the content of a paper as one view and the citation contexts as another view of our data.",4 Co-Training for Topic Classification,[0],[0]
"In particular, for the content of a paper, we use its title and abstract as it is commonly used in the literature (Lu and Getoor, 2003); for the citation contexts, we use both the cited and citing contexts, as described in the previous section.
",4 Co-Training for Topic Classification,[0],[0]
Our co-training procedure is described in Algorithm 1.,4 Co-Training for Topic Classification,[0],[0]
L and U represent the labeled and unlabeled datasets and contain instances from both views.,4 Co-Training for Topic Classification,[0],[0]
The fractions of the training set are obtained from the 786 papers by selecting k% random examples from each class.,4 Co-Training for Topic Classification,[0],[0]
"For a round of co-training, we train classifiers C1 and C2 on the two views.",4 Co-Training for Topic Classification,[0],[0]
"Next, s examples are sampled from the unlabeled data into S, and C1, C2 are used to obtain predictions for these s examples.",4 Co-Training for Topic Classification,[0],[0]
"The GetMostConfidentExamples method is a generic placeholder that stands for a function that deter-
mines what examples from S are chosen to be added into training.",4 Co-Training for Topic Classification,[0],[0]
"Finally, at the end of an iteration, the examples left into S are moved back to U , and the algorithm iterates until there are no more unlabeled examples in U .",4 Co-Training for Topic Classification,[0],[0]
The final classifier C is obtained by combining C1 and C2 using the product of their class probability distributions.,4 Co-Training for Topic Classification,[0],[0]
"The class with the highest posterior probability (of the product of the two distributions) is chosen as the predicted class.
",4 Co-Training for Topic Classification,[0],[0]
"Unlike the original co-training algorithm described by Blum and Mitchell (1998), which tackled a binary classification task (course vs. noncourse page classification), we address a multiclass classification problem, where each example (i.e., research paper) is classified into one of six different classes.",4 Co-Training for Topic Classification,[0],[0]
"Moreover, in Blum and Mitchell (1998), the co-training algorithm moves p highest confidence positive examples and n highest confidence negative examples from S to L, where p : n represents the class distribution in the original labeled training set (i.e., if there are 10 positive examples and 90 negative examples in the labeled set L, then p = 1 positive and n = 9 negative examples are moved to the labeled set at each iteration of co-training).",4 Co-Training for Topic Classification,[0],[0]
"Unlike, this approach that preserves the class distribution of the original labeled training set, we move into L all examples that are classified with a confidence above a certain threshold.",4 Co-Training for Topic Classification,[0],[0]
"First, the proposed method is evaluated on the validation set.",5 Results and Discussion,[0],[0]
We first compare it against various supervised and semi-supervised baselines.,5 Results and Discussion,[0],[0]
"Next, we report the performance of our co-training algorithm under different scenarios, where either cited or citing contexts are used.",5 Results and Discussion,[0],[0]
We also show the most informative words for each classifier.,5 Results and Discussion,[0],[0]
"Finally, with the best parameters obtained on the validation set, we report the precision, recall and F1-score, obtained by each method, on the test set.
",5 Results and Discussion,[0],[0]
"In experiments, the sample size ‘s’ from Algorithm 1 is set to 300, i.e. the number of documents sampled from the unlabeled pool at each iteration; the confidence threshold is set to 0.95, i.e. if both classifiers agree on the class label and have a confidence ≥ 0.95, the instance is labeled and moved into the labeled training set.",5 Results and Discussion,[0],[0]
"These parameters are estimated on the validation set, but the results are not shown due to space limitation.
",5 Results and Discussion,[0],[0]
Evaluation Measures.,5 Results and Discussion,[0],[0]
We report results averaged over ten different runs with random splits.,5 Results and Discussion,[0],[0]
"For each random split, we return the weighted average precision, recall and F1-score.",5 Results and Discussion,[0],[0]
"In all the experiments, we use the Naı̈ve Bayes Multinomial classifier and its Weka implementation2, with term-frequencies as feature values.",5 Results and Discussion,[0],[0]
"We experimented with both TF and TF-IDF scores, using different classifiers (Support Vector Machine, Naı̈ve Bayes Multinomial, and simple Naı̈ve Bayes classifiers), but Naive Bayes Multinomial with TF performed best.",5 Results and Discussion,[0],[0]
How does co-training compare with supervised learning techniques?,5.1 Baseline Comparisons,[0],[0]
"In this experiment, we compare our co-training method with two supervised baselines: (1) when only document content is used and (2) when only citation contexts are used.
",5.1 Baseline Comparisons,[0],[0]
Figure 1 shows the F1-scores achieved using different initial training sizes.,5.1 Baseline Comparisons,[0],[0]
"We can see that overall, the citation contexts are better at predicting the topic of a document compared with the content, outperforming them in 9 out of 10 experimental settings.",5.1 Baseline Comparisons,[0],[0]
"The only exception to this trend is when a small number (5%) of training instances is available, in which case the supervised content view performs better, reaching an F1-score of 0.534.",5.1 Baseline Comparisons,[0],[0]
"Regardless, the co-training method shows significant improvement over both baselines, in all experiments.",5.1 Baseline Comparisons,[0],[0]
"Starting with an F1-score of 0.572, it continues to improve its performance as the training percentage is increasing.",5.1 Baseline Comparisons,[0],[0]
"The maximum F1score, i.e. 0.742, is reached when 30% of the labeled training set is used.",5.1 Baseline Comparisons,[0],[0]
"Note that the difference in performance between co-training and the two supervised baselines is statistically significant for
2http://www.cs.waikato.ac.nz/ml/weka/
a p value of 0.05.
",5.1 Baseline Comparisons,[0],[0]
A fully supervised baseline that uses 100% of the training set achieves an F1-score of 0.720 (using content) and 0.738 (using citation contexts).,5.1 Baseline Comparisons,[0],[0]
"In contrast, co-training requires only 15% of the labeled training set to outperform the fully supervised content baseline and 30% of the training set to outperform the fully supervised citation contexts baseline.",5.1 Baseline Comparisons,[0],[0]
"Consequently, using a co-training approach that includes citation contexts as well as the document content can not only increase the performance, but will also significantly reduce the need of expensive labeled instances.
",5.1 Baseline Comparisons,[0],[0]
"Figure 2 illustrates the confusion matrices of three experiments: (a) supervised content view, i.e. the title and abstract, (b) supervised citation contexts view, and (c) co-training that uses both views.",5.1 Baseline Comparisons,[0],[0]
These experiments use 10% of the training set.,5.1 Baseline Comparisons,[0],[0]
"Each of the matrices are represented by a heat map, i.e. the redder the color, the higher the value assigned to that position.",5.1 Baseline Comparisons,[0],[0]
An accuracy of 1 will be represented by a matrix with red blocks on the main diagonal and white blocks everywhere else.,5.1 Baseline Comparisons,[0],[0]
"This experiment was performed 10 times with 10 different seeds and the results have been averaged.
",5.1 Baseline Comparisons,[0],[0]
"As can be seen, the matrix that uses only titles and abstracts, i.e. left side, is showing the highest percentage of misclassified documents, classifying correctly about 58.8% instances, on average.",5.1 Baseline Comparisons,[0],[0]
"Using only citation contexts in a supervised framework, i.e. center matrix, we reach a higher accuracy of 60.7%.",5.1 Baseline Comparisons,[0],[0]
"The co-training method, which uses the content of the paper and citations as two independent views, significantly increases the average accuracy to 67.3%.",5.1 Baseline Comparisons,[0],[0]
This experiment shows that citation contexts are better than titles and abstracts at predicting the topic of a document.,5.1 Baseline Comparisons,[0],[0]
"Furthermore, our proposed approach, which uses the content of the paper as well as citation contexts, achieves higher results than each view used separately.",5.1 Baseline Comparisons,[0],[0]
"The difference in accuracy is statistically significant across all three experiments for a p value of 0.05.
",5.1 Baseline Comparisons,[0],[0]
"Overall, the Agents class seem to be the easiest to classify, reaching an accuracy value of 91.6% when using co-training.",5.1 Baseline Comparisons,[0],[0]
"On the other hand, the AI class is the hardest to classify.",5.1 Baseline Comparisons,[0],[0]
One reason for this is that the AI class contains the lowest number of instances in the dataset.,5.1 Baseline Comparisons,[0],[0]
"Another can be that the AI class is the most general among all classes and therefore, classifying documents with this la-
Left: using titles and abstracts; Center: using citation contexts;",5.1 Baseline Comparisons,[0],[0]
"Right: using co-training.
bel can be a difficult task even for a human.",5.1 Baseline Comparisons,[0],[0]
"Other common misclassifications occur between classes like HCI and Agents, ML and IR or AI and ML, due to their similarity.
",5.1 Baseline Comparisons,[0],[0]
How does our co-training method compare with other supervised approaches?,5.1 Baseline Comparisons,[0],[0]
"In this experiment, we compare the performance of co-training against two other methods: early and late fusion.",5.1 Baseline Comparisons,[0],[0]
"In early fusion, the feature vectors of the two views are concatenated, creating a single representation of the data.",5.1 Baseline Comparisons,[0],[0]
"In contrast, late fusion trains two separate classifiers and then combines them by taking the label with the highest confidence.
",5.1 Baseline Comparisons,[0],[0]
Figure 3 shows this comparison over different training sizes.,5.1 Baseline Comparisons,[0],[0]
"The results show that the cotraining method is more accurate than all others, performing best in all 10 experimental settings.",5.1 Baseline Comparisons,[0],[0]
"Late fusion has an overall lower performance compared with co-training, but is in a tight correlation with it.",5.1 Baseline Comparisons,[0],[0]
"On the other hand, early fusion achieves the lowest F1-score across the experiments.",5.1 Baseline Comparisons,[0],[0]
"The reported results are statistically significant at p value of 0.05, when the training percentage is between 5 and 35.",5.1 Baseline Comparisons,[0],[0]
"Therefore, we can say that train-
ing two separate classifiers, one of each view, yields higher performance compared with training a single classifier that incorporates both views.",5.1 Baseline Comparisons,[0],[0]
"Moreover, using a co-training approach that incorporates information from unlabeled data into the model, will help the two classifiers increase their confidences and minimize the error rate.
",5.1 Baseline Comparisons,[0],[0]
How does co-training compare with semisupervised methods?,5.1 Baseline Comparisons,[0],[0]
"Here, we present results comparing co-training with two other wellknown semi-supervised techniques: self-training and Naı̈ve Bayes with Expectation Maximization.
Self-Training.",5.1 Baseline Comparisons,[0],[0]
"First, we show results of the comparison of co-training with two variations of selftraining: (1) self-training using only document content, and (2) self-training using only citation contexts.",5.1 Baseline Comparisons,[0],[0]
Figure 4 shows the results of this experiment.,5.1 Baseline Comparisons,[0],[0]
"Self-training is similar to co-training, except that it uses only one view of the data (Zhu, 2005).",5.1 Baseline Comparisons,[0],[0]
"Self-training parameters, e.g., sample size ‘s’ or number of iterations, are estimated as in cotraining.
",5.1 Baseline Comparisons,[0],[0]
"Although the document content version of selftraining outperforms co-training when using 5%
of the training instances, we can see that overall, there is a significant difference in terms of F1score values in the favor of co-training.",5.1 Baseline Comparisons,[0],[0]
"In 9 out of 10 experiments, our co-training approach is superior to both self-training methods.",5.1 Baseline Comparisons,[0],[0]
"The results are statistically significant across all experimental setups for a p value of 0.05.
",5.1 Baseline Comparisons,[0],[0]
Expectation Maximization.,5.1 Baseline Comparisons,[0],[0]
"Figure 5 shows the F1-score values obtained after running NBM with EM with the same training, unlabeled and test sets.",5.1 Baseline Comparisons,[0],[0]
"The EM algorithm uses the same classifier, i.e. NBM, and the weight for each unlabeled instance is set to 1, as this setting achieved the highest results.",5.1 Baseline Comparisons,[0],[0]
"Two different experiments were performed using EM: (1) using only document content, and (2) using only citation contexts.",5.1 Baseline Comparisons,[0],[0]
"As can be seen in the figure, overall, the co-training approach significantly outperforms both variations of EM.",5.1 Baseline Comparisons,[0],[0]
"However, the co-training method falls short when using 5% of the training instances, where EM Content and EM Citations methods are achieving higher F1-score values.",5.1 Baseline Comparisons,[0],[0]
"Nonetheless, both EM variations tend to achieve an F1-score value below or equal to 0.710, whereas co-training reaches performance values of 0.74 or higher.",5.1 Baseline Comparisons,[0],[0]
"Again, the comparison results between co-training and both variations of EM are statistically significant for training sizes between 10% and 50%, for a p value of 0.05.",5.1 Baseline Comparisons,[0],[0]
Which of the two types of citation contexts (cited or citing) help the task of topic classification more and how does co-training perform in the absence of either one?,5.2 Using Different Citation Context Types,[0],[0]
The answer to this question is important as there are cases in which citation contexts are not readily available.,5.2 Using Different Citation Context Types,[0],[0]
"One frequently encountered example includes newly published research papers that have no cited contexts.
",5.2 Using Different Citation Context Types,[0],[0]
"In this case, it is important to know how our method performs when we only have one type of citation contexts.",5.2 Using Different Citation Context Types,[0],[0]
"Figure 6 shows the difference in performance when using: (1) only cited contexts, (2) only citing contexts, and (3) both context types.",5.2 Using Different Citation Context Types,[0],[0]
"Note that the content view remains the same across all three experiments.
",5.2 Using Different Citation Context Types,[0],[0]
The plot is showing that citing contexts are bringing in a significantly higher margin of knowledge compared with cited contexts.,5.2 Using Different Citation Context Types,[0],[0]
"This is consistent over different training set sizes, as shown in the figure, with a more prominent impact when a small training size is used, i.e. 5-30%.",5.2 Using Different Citation Context Types,[0],[0]
"The fact that the citing contexts achieve higher F1-score than cited contexts is consistent with the intuition that when citing a paper y, an author generally summarizes the main ideas from y using important words from a target paper x, making the citing contexts to have higher overlap with words from x.",5.2 Using Different Citation Context Types,[0],[0]
"In turn, a paper z that cites x may use paraphrasing to summarize ideas from x with words more similar to those from the content of z.
When the two types of contexts are used, cotraining achieves higher results compared with cases when only one context type is used.",5.2 Using Different Citation Context Types,[0],[0]
This experiment shows that our method can be applied for both old and new research articles.,5.2 Using Different Citation Context Types,[0],[0]
Citing contexts will be available in the text of the target paper and are independent of the existence of the cited contexts.,5.2 Using Different Citation Context Types,[0],[0]
What are the most informative words from each view: document content and citation contexts?,5.3 Informative Features,[0],[0]
Figure 7 shows the words from each view that are most useful for our topic classification task.,5.3 Informative Features,[0],[0]
"The larger the word, the more informative is for our
task.",5.3 Informative Features,[0],[0]
"To determine the informativeness of a word, we used its Information Gain score.",5.3 Informative Features,[0],[0]
"For these experiments, we used training sets consisting of 30% of the instances, setting in which we achieved the best results on the validation and test sets using our proposed co-training approach.
",5.3 Informative Features,[0],[0]
"As can be seen, the two word clouds have a high word overlap.",5.3 Informative Features,[0],[0]
"Words such as agent, database or query are almost equally important in the two views, dominating both clouds.",5.3 Informative Features,[0],[0]
"However, differences can be observed.",5.3 Informative Features,[0],[0]
"For example, words like learning, multi-agent or interface are more important in the content view.",5.3 Informative Features,[0],[0]
"On the other hand, words such as document or text achieve a higher information gain score for the citation contexts view.",5.3 Informative Features,[0],[0]
"Table 2 summarizes the results obtained by all the baselines used so far, in comparison with our proposed co-training method.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"For this experiment, we show the training percentage used, the precision, recall and F1-score for each method, in the setting in which it returned the best results.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"All mea-
sures were averaged after 10 runs with 10 different seeds.
",5.4 Co-Training vs. All Other Approaches,[0],[0]
"The results in Table 2 show that the proposed co-training method outperforms all compared models, reaching the highest F1-score of 0.742, while using the smallest amount of labeled documents, i.e. 30%.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"Using only the citing contexts, the performance is similar to that of co-training when both context types are used.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"However, using only the cited contexts, the performance decreases compared to that of the full model that uses both context types.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"We see that the citing contexts perform better, reaching an F1-score value of 0.740 compared against 0.714 when only cited contexts are used.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"Moreover, the method that uses only the citing contexts is using 10% less labeled data.
",5.4 Co-Training vs. All Other Approaches,[0],[0]
Self-training and EM show decreased performance compared with co-training.,5.4 Co-Training vs. All Other Approaches,[0],[0]
"Late Fusion outperforms Early Fusion, i.e., 0.738 vs. 0.714, both obtaining lower results than co-training, while using significantly more labeled data.
",5.4 Co-Training vs. All Other Approaches,[0],[0]
"The last two lines of the table show the results when all documents (except those in the validation and test), are used for training, in a supervised framework.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"As can be seen, a supervised method that uses only citations will achieve a higher performance, compared against a method that uses titles and abstracts.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"Nonetheless, co-training obtains higher results than both fully supervised approaches, while using only 30% of the labeled data.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"In this paper, we studied the problem of using citation contexts in order to predict more accurately the topic of a research article.",6 Conclusion and Future Work,[0],[0]
"We showed that a co-training technique, which uses the paper content and its citation contexts as two conditionally independent and sufficient views of the data, can effectively incorporate cheap, unlabeled data to improve the classification performance and to reduce the need of labeled examples to only a fraction.",6 Conclusion and Future Work,[0],[0]
"The results of the experiments showed that the proposed approach performs better than other semi-supervised and supervised methods.
",6 Conclusion and Future Work,[0],[0]
This study also shows that citation contexts are rich sources of information that can be successfully used in various IR and NLP tasks.,6 Conclusion and Future Work,[0],[0]
We showed that document content and citation contexts unified under the same algorithm can dramatically decrease the annotation costs as well.,6 Conclusion and Future Work,[0],[0]
"In the future, we plan to extend co-training to include active learning for more robust classification.",6 Conclusion and Future Work,[0],[0]
"Moreover, it would be interesting to extend the co-training approach to multi-views that could potentially handle more than two feature spaces, e.g., it could include topics by Latent Dirichlet Allocation (Blei et al., 2003) as an additional view.",6 Conclusion and Future Work,[0],[0]
We are thankful to Dr. Lise Getoor for making the Citeseerx labeled subset publicly available.,Acknowledgments,[0],[0]
"We are also grateful to Dr. C. Lee Giles for the CiteSeerx data, which helped extract the citation contexts of the research papers in the collection.",Acknowledgments,[0],[0]
We very much thank our anonymous reviewers for their constructive feedback.,Acknowledgments,[0],[0]
This research is supported in part by the NSF award #1423337 to Cornelia Caragea.,Acknowledgments,[0],[0]
"Any opinions, findings, and conclusions expressed here are those of the authors and do not necessarily reflect the views of NSF.",Acknowledgments,[0],[0]
"With the exponential growth of scholarly data during the past few years, effective methods for topic classification are greatly needed.",abstractText,[0],[0]
Current approaches usually require large amounts of expensive labeled data in order to make accurate predictions.,abstractText,[0],[0]
"In this paper, we posit that, in addition to a research article’s textual content, its citation network also contains valuable information.",abstractText,[0],[0]
We describe a co-training approach that uses the text and citation information of a research article as two different views to predict the topic of an article.,abstractText,[0],[0]
"We show that this method improves significantly over the individual classifiers, while also bringing a substantial reduction in the amount of labeled data required for training accurate classifiers.",abstractText,[0],[0]
Co-Training for Topic Classification of Scholarly Data,title,[0],[0]
"Combinatorial optimization is a important topic of computer science and discrete mathematics, with a wide spectrum of applications ranging from resource allocation and job scheduling, to automated planning and configuration softwares.",1. Introduction,[0],[0]
"A common problem is to minimize a modular loss function ` over a discrete space S ⊆ {0, 1}d of feasible solutions represented in a concise manner by a set of combinatorial constraints.",1. Introduction,[0],[0]
"In the offline version of this problem, all information necessary to define the optimization task is available beforehand, and the challenge is to develop algorithms which are provably or practically better than enumerating all feasible solutions.",1. Introduction,[0],[0]
"Contrastingly, in the online version of this problem (Audibert et al., 2014), the objective function ` is subject to change over time.",1. Introduction,[0],[0]
"The challenge here is more acute, since the optimization algorithm is required to perform repeated choices on S so as to minimize their average cost in the long run.
",1. Introduction,[0],[0]
"*Equal contribution 1CRIL, CNRS UMR 8188, Université d’Artois, France.",1. Introduction,[0],[0]
"Correspondence to: Frederic Koriche <koriche@cril.fr>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"Conceptually, an online combinatorial optimization problem can be cast as a repeated prediction game between a learning algorithm and its environment (Audibert et al., 2011; 2014).",1. Introduction,[0],[0]
"During each trial t, the learner chooses a feasible solution st from its decision set S and, simultaneously, the environment selects a loss vector `t ∈",1. Introduction,[0],[0]
"[0, 1]d.",1. Introduction,[0],[0]
"Then, the learner incurs the loss 〈`t, st〉 = ∑d i=1",1. Introduction,[0],[0]
"`t(i)st(i) and, in light of the feedback provided by its environment, updates its strategy in order to improve the chance of selecting better solutions on subsequent trials.
",1. Introduction,[0],[0]
"Several classes of combinatorial prediction games can be distinguished, depending on the type of decision set, and the type of observed feedback.",1. Introduction,[0],[0]
"In this paper, we focus on full information games in which it is assumed that the feedback supplied at trial t by the environment is the entire vector `t. On the other hand, we make very few assumptions about the decision set: S may be described by an arbitrary SAT formula, that is, any set of combinatorial constraints representable by Boolean clauses.",1. Introduction,[0],[0]
"As SAT encodings of discrete solution spaces are frequently used in academic and industrial applications (Biere et al., 2009), our setting covers an important class of combinatorial prediction games.
",1. Introduction,[0],[0]
"As usual, the performance of an online learning algorithm is measured according to two metrics.",1. Introduction,[0],[0]
"The first, called regret, measures the difference in cumulative loss between the algorithm and the best solution in hindsight.",1. Introduction,[0],[0]
"In this study, we make no assumption about the sequence of loss vectors; in particular `t may depend on the previous decisions s1, · · · , st−1 made by the learner.",1. Introduction,[0],[0]
"In such non-oblivious or adversarial environments, the learner is generally allowed to make decisions in a randomized way, and its predictive performance is measured by the expected regret:
RT = E",1. Introduction,[0],[0]
"[ T∑ t=1 〈`t, st〉 ] −min",1. Introduction,[0],[0]
"s∈S T∑ t=1 〈`t, s〉
The second metric is computational complexity, i.e. the amount of resources required to compute st at each round t, given the sequence of feedbacks observed so far.
",1. Introduction,[0],[0]
Related Work.,1. Introduction,[0],[0]
"In the literature of combinatorial prediction games, three main strategies have been proposed to attain an expected regret that is sublinear in the game horizon T and polynomial in the input dimension d. The
first, and arguably simplest strategy, is to Follow the Perturbed Leader (FPL): on each trial t, the learner draws at random a perturbation vector zt ∈ Rd, and then selects in S a minimizer of ηLt + zt, where η ∈ (0, 1] is a step-size parameter, andLt is the cumulative lossLt = `1 + · · ·+`t−1.",1. Introduction,[0],[0]
"Based on the pioneering work of Hannan (1957), refined in (Hutter & Poland, 2005; Kalai & Vempala, 2005), the FPL algorithm achieves an expected regret of O(d 32 √ T ).
",1. Introduction,[0],[0]
"The second strategy is based on the popular exponentially weighted average forecaster in the framework of prediction with expert advice (Cesa-Bianchi & Lugosi, 2006).",1. Introduction,[0],[0]
"The overall idea is to maintain a weight for each feasible solution s ∈ S, which decays exponentially according to the estimated cumulative loss of s. Specifically, on each trial t, the learner draws a solution st ∈ S at random from the exponential family pt(s) ∼ exp(−η〈Lt, s〉).",1. Introduction,[0],[0]
"This strategy, referred to as Expanded Hedge (EH) in (Koolen et al., 2010), attains an expected regret of O(d 32 √ T ).
",1. Introduction,[0],[0]
"Finally, the third strategy is to Follow the Regularized Leader, a paradigm often advocated in online convex optimization (Hazan, 2016).",1. Introduction,[0],[0]
"Here, the learner operates on the convex hull of S, denoted conv(S).",1. Introduction,[0],[0]
"On each trial t, the learner starts by choosing a point pt ∈ conv(S) that minimizes η〈L̂t,p〉 + F (p), where F is a regularization function.",1. Introduction,[0],[0]
"Next, pt is decomposed as a convex composition of feasible solutions in S, and then, a decision st is picked at random according to the resulting distribution.",1. Introduction,[0],[0]
"For modular loss functions, this strategy is equivalent to the Online Stochastic Mirror Descent (OSMD) algorithm (Audibert et al., 2014; Rajkumar & Agarwal, 2014), which iteratively performs a gradient descent in the dual space of conv(S) under F , and projects back to the primal space according to the Bregman divergence defined from F .",1. Introduction,[0],[0]
"Notably, when F is the Euclidean regularizer, OSMD coincides with the popular stochastic gradient descent (SGD) algorithm (Robbins & Monro, 1951).",1. Introduction,[0],[0]
"Alternatively, when F is the entropic regularizer, OSMD corresponds to the Component Hedge (CH) algorithm (Koolen et al., 2010), which achieves an optimal expected regret of O(d √ T ).
",1. Introduction,[0],[0]
"From the viewpoint of regret, the results outlined above indicate that few improvements remain to be made in full information games.",1. Introduction,[0],[0]
"However, we get a different picture if computational considerations are taken into account: all aforementioned algorithms rely on powerful oracles for making decisions in spaces S represented by combinatorial constraints.",1. Introduction,[0],[0]
"Namely, the EH algorithm is required, at each iteration, to sample a solution according to an exponential family over S , a problem which is generally #P-hard (Dyer et al., 2009).",1. Introduction,[0],[0]
"Similarly, the FPL strategy has to repeatedly solve a linear optimization task over S, which is generally NP-hard (Creignou et al., 2001).",1. Introduction,[0],[0]
"For the OSMD algorithm, and its specializations SGD and CH, the computational issue
is exacerbated by the fact that, even if the learner has access to a linear optimization oracle, it still has to perform, at each trial, a Bregman projection step for which the best known algorithms run in O(d6) time (Suehiro et al., 2012).
",1. Introduction,[0],[0]
"Although combinatorial prediction games are generally intractable, efficient implementations of sampling and optimization oracles may be obtained for several decision sets S. For example, when the feasible solutions in S coincide with the bases of a binary matroid, or the perfect matchings of a bipartite graph, linear optimization can be performed in polynomial time, and tractable forms of FPL and OSMD may be derived (Helmbold & Warmuth, 2009; Koolen et al., 2010; Takimoto & Hatano, 2013; Rajkumar & Agarwal, 2014).",1. Introduction,[0],[0]
"On the other hand, when the feasible solutions in S correspond to the paths or multi-paths of a rooted Directed Acyclic Graph (DAG), the sampling oracle may be implemented by the weight pushing technique (Mohri, 1998), that recursively evaluates the partition function of an exponential family over the edges of the input DAG.",1. Introduction,[0],[0]
"Based on this technique, tractable forms of EH can be derived (Takimoto & Warmuth, 2003; Rahmanian & Warmuth, 2017).
",1. Introduction,[0],[0]
Our Results.,1. Introduction,[0],[0]
Viewing feasible solutions as paths in a DAG is only one of many abstractions that have been proposed in the literature of circuit complexity for representing combinatorial spaces.,1. Introduction,[0],[0]
"In the related field of knowledge compilation (Darwiche & Marquis, 2002), various classes of Boolean circuits have been identified, each associated with a set of inference tasks which can be performed in polynomial time.",1. Introduction,[0],[0]
These theoretical results naturally motivate the following question: can we compile a set of constraints representing a combinatorial space S into a compact and Boolean circuit for which both solution sampling and linear optimization are tractable?,1. Introduction,[0],[0]
"By viewing the compilation process as a “pre-processing step”, we may get for free efficient implementations of sampling and optimization oracles, provided that the size of the resulting circuit is not too large.
",1. Introduction,[0],[0]
"The present study aims at solving combinatorial prediction games, by compiling decision sets into deterministic Decomposable Negation Normal Form (dDNNF) circuits (Darwiche, 2001).",1. Introduction,[0],[0]
"This class comes with generic compilers which take as input a SAT formula representing a decision set S, and return a dDNNF circuit C that encodes S (Darwiche, 2002; Lagniez & Marquis, 2017).",1. Introduction,[0],[0]
"Although the size of C may grow exponentially in the treewidth of the input formula, it is usually much smaller in practice; existing compilers are able to compress combinatorial spaces defined over thousands of variables and constraints.
",1. Introduction,[0],[0]
"With these compilation tools in hand, our contributions are threefold: (i) we show that for dDNNF circuits, the sampling oracle in EH and the linear optimization oracle in FPL, run in linear time using a simple variant of the weight-
pushing technique; (ii) for the SGD and CH strategies, we develop a Bregman projection-decomposition method that uses O(d2 ln(dT ))",1. Introduction,[0],[0]
"calls to the linear optimization oracle; (iii) we experimentally show on online configuration and planning tasks that EH and FPL are fast, but our variants of SGD and CH are more efficient to minimize the empirical regret.
",1. Introduction,[0],[0]
"Before proceeding to the core of the paper, we emphasize that the compilation approach to online optimization is not entirely new.",1. Introduction,[0],[0]
"Recently, Sakaue et.",1. Introduction,[0],[0]
"al. (2018) used the class of Ordered Binary Decision Diagrams (OBDDs) (Bryant, 1986) for implementing the EWA forecaster in combinatorial bandits.",1. Introduction,[0],[0]
"Here, S is described by a graph over d edges, together with a constraint specifying the type of objects we desire (e.g. paths or cliques).",1. Introduction,[0],[0]
"By contrast, our study assumes that S is described with an arbitrary set of Boolean constraints.",1. Introduction,[0],[0]
"So, both studies are targeting different classes of combinatorial prediction games.",1. Introduction,[0],[0]
"Moreover, it is known that dDNNF is strictly more succinct than OBDD (Darwiche & Marquis, 2002).",1. Introduction,[0],[0]
"Namely, any OBDD can be transformed in linear time and space into an equivalent dDNNF circuit, but the converse is not true: dDNNF includes simple circuits which require an exponential size representation in OBDD.",1. Introduction,[0],[0]
"In fact, the key point of compiling combinatorial prediction games is to use both tractable and succinct languages, for allowing prediction strategies to be efficient on a wide variety of combinatorial domains.",1. Introduction,[0],[0]
"For the combinatorial prediction games considered in this paper, we assume that the input decision space S is defined from a set of n binary-valued attributes, and we use X = {x1, · · · , xd}, where d = 2n, to denote the set of all “attribute-value” pairs, called literals.",2. Tractable Inference via Compilation,[0],[0]
"A solution is a vector s ∈ {0, 1}d such that s(i) + s(j) = 1 for every pair of distinct literals xi, xj ∈ X defined on the same attribute.",2. Tractable Inference via Compilation,[0],[0]
"Thus, ‖s‖1 = n for any feasible solution s ∈ S.
An NNF circuit over X is a rooted DAG, whose internal nodes are labeled by ∨ (or-node) or ∧ (and-node), and whose leaves are labeled by either a literal in X , or a constant in {0, 1}.",2. Tractable Inference via Compilation,[0],[0]
"The size of C, denoted |C|, is given by the number of its edges.",2. Tractable Inference via Compilation,[0],[0]
"The set of attributes occurring in the subgraph of C rooted at some node c is denoted att(c).
",2. Tractable Inference via Compilation,[0],[0]
"For the sake of clarity, we assume that any NNF circuit C satisfies two basic properties, namely (i) any internal node c in C has exactly two children, denoted cl and cr, and (ii) att(cl) = att(cr) 6=",2. Tractable Inference via Compilation,[0],[0]
∅ for any or-node c of C. An NNF circuit satisfying both conditions is called smooth.,2. Tractable Inference via Compilation,[0],[0]
"As shown in (Darwiche, 2001), any Boolean circuitC can be transformed in to an equivalent smooth NNF circuit of size linear in |C|.
",2. Tractable Inference via Compilation,[0],[0]
"By viewing literals as “input gates”, and nodes as “output gates”, we may specify various inference tasks on Boolean
circuits, depending on the type of input values and the semantics of nodes.",2. Tractable Inference via Compilation,[0],[0]
"As suggested by Friesen & Domingos for sum-product functions (2016), inference tasks can be captured through semiring operations.",2. Tractable Inference via Compilation,[0],[0]
"To this point, recall that a commutative semiring is a tuple (R,⊕,⊗,⊥,>) such that R is a set including the elements ⊥ and >, ⊕ is a associative and commutative binary operation on R with identity element ⊥, ⊗ is an associative binary operation on R with identity element > and absorbing element ⊥, and the operator ⊗ left and right distributes over the operator ⊕.
Inference tasks on an NNF circuit C are defined using a commutative semiring Q = (R,⊕,⊗,⊥,>) and an input vector w ∈ Rd.",2. Tractable Inference via Compilation,[0],[0]
"The output of a node c in C for Q given w is denoted Q(c |w), and recursively defined by
Q(c |w) =  w(i) if c is the literal xi, > if c is the constant 1, ⊥ if c is the constant 0, Q(cl |w)⊕Q(cr |w) if c is a node ∨, and Q(cl |w)⊗Q(cr |w) if c is a node ∧
By Q(C |w), we denote the output of the root of C for Q givenw.",2. Tractable Inference via Compilation,[0],[0]
"Of particular interest in this study are the semirings described in Table 1; maxmin, minsum, and sumprod, and used to capture the inference tasks of model checking, linear optimization, and model sampling, respectively.",2. Tractable Inference via Compilation,[0],[0]
"Given an NNF circuit C over X , the task of model checking is to decide whether a Boolean input s ∈ {0, 1}d is true in C according to the propositional semantics of nodes.",2.1. Model Checking,[0],[0]
"Obviously, s is a model of C iff maxmin(C | s) = 1, which can be determined in O(|C|) time.",2.1. Model Checking,[0],[0]
"An NNF circuit C is called a representation of a set of feasible solutions S ⊆ {0, 1}d if sol(C) = S, where sol(C) is the set of models of C.
Apart from model checking, virtually all inference tasks in NNF circuits are NP-hard.",2.1. Model Checking,[0],[0]
"Indeed, the NNF language covers the class of SAT formulas.",2.1. Model Checking,[0],[0]
"So, we need to refine this class in order to get tractable forms of optimization and sampling.",2.1. Model Checking,[0],[0]
"A Boolean circuit C is decomposable if for every and-node c of C, we have att(cl) ∩ att(cr) = ∅.",2.2. Decomposability and Optimization,[0],[0]
The class of decomposable NNF circuits is denoted DNNF.,2.2. Decomposability and Optimization,[0],[0]
"For such circuits, which are similar to Boolean sum-product networks (Poon & Domingos, 2011), we can get an efficient implementation of the linear optimization oracle.
",2.2. Decomposability and Optimization,[0],[0]
Proposition 1.,2.2. Decomposability and Optimization,[0],[0]
"Let S ⊆ {0, 1}d be a (nonempty) decision set represented by a DNNF circuit C, and let w ∈ Rd be a modular objective.",2.2. Decomposability and Optimization,[0],[0]
"Then, finding a minimizer of w in S can be done in O(|C|) time.
",2.2. Decomposability and Optimization,[0],[0]
Proof.,2.2. Decomposability and Optimization,[0],[0]
"Based on the minsum semiring, we have
min s∈S 〈w, s〉 = min s∈sol(C) 〈w, s〉 = minsum(C |w)
",2.2. Decomposability and Optimization,[0],[0]
This observation suggests a two-pass weight pushing method for finding a minimizer s of w in S in O(|C|) time.,2.2. Decomposability and Optimization,[0],[0]
"Given a topological ordering of C, the first pass stores the value Q(c |w) of each node c ∈ C, using Q = minsum.",2.2. Decomposability and Optimization,[0],[0]
"The second pass performs a top-down search over C, by selecting all children of a visited and-node, and by selecting exactly one child c′ ∈ {cl, cr} of a visited or-node c such that Q(c′ | w) = Q(c | w).",2.2. Decomposability and Optimization,[0],[0]
"Let T be the corresponding search tree, and let s ∈ {0, 1}d be the indicator vector of the set of literals occurring in T .",2.2. Decomposability and Optimization,[0],[0]
"By construction, we have Q(T |w) = Q(C |w), which implies that s is a minimizer ofw.",2.2. Decomposability and Optimization,[0],[0]
"Since S is not empty, we know that Q(C |w) <",2.2. Decomposability and Optimization,[0],[0]
"+∞. This, together with the fact",2.2. Decomposability and Optimization,[0],[0]
that minmax(T,2.2. Decomposability and Optimization,[0],[0]
| s) = 1,2.2. Decomposability and Optimization,[0],[0]
"whenever Q(T |w) < +∞, implies that s ∈ S.",2.2. Decomposability and Optimization,[0],[0]
"As the problem of counting the number of models in a DNNF circuit is #P-hard (Darwiche & Marquis, 2002), we need to refine this class in order to get an efficient implementation of the sampling oracle.",2.3. Determinism and Sampling,[0],[0]
"To this end, an NNF circuit C is called deterministic if minmax(cl | s) +",2.3. Determinism and Sampling,[0],[0]
minmax(cr | s) ≤ 1 for every or-node c ∈ C and every feasible solution s.,2.3. Determinism and Sampling,[0],[0]
"The class of deterministic DNNF circuits is denoted dDNNF.
",2.3. Determinism and Sampling,[0],[0]
Proposition 2.,2.3. Determinism and Sampling,[0],[0]
"Let S ⊆ {0, 1}d be a decision set represented by a dDNNF circuit C, and for a vector w ∈ Rd, let Pw be the exponential family on S given by:
Pw(s) = exp〈w, s〉∑
s′∈S exp〈w, s′〉
Then, sampling s ∼ Pw can be done in O(|C|) time.
",2.3. Determinism and Sampling,[0],[0]
Proof.,2.3. Determinism and Sampling,[0],[0]
"Based on the sumprod semiring, we have
Pw(s) = exp〈w, s〉∑
s′∈sol(C) exp〈w, s′〉 =
exp〈w, s〉 sumprod(C |w′)
wherew′",2.3. Determinism and Sampling,[0],[0]
"= (ew(1), · · · , ew(d)).",2.3. Determinism and Sampling,[0],[0]
"Again, such an equivalence suggests a two-pass weight pushing method for sampling a solution s according to Pw in O(|C|) time.",2.3. Determinism and Sampling,[0],[0]
"Using a topological ordering of C, the first pass stores the values Q(c |w′), where Q = sumprod.",2.3. Determinism and Sampling,[0],[0]
"The second pass performs a top-down randomized search over C, by selecting all children of a visited and-node, and by drawing at random one of the children of a visited or-node c according to the distribution p(cl) =",2.3. Determinism and Sampling,[0],[0]
Q(cl | w′)/Q(c | w′) and p(cr),2.3. Determinism and Sampling,[0],[0]
= 1− p(cl).,2.3. Determinism and Sampling,[0],[0]
"Let T be the tree of visited nodes, and s be the indicator vector of the literals in T .",2.3. Determinism and Sampling,[0],[0]
"Since S 6= ∅, we must have Q(C |w) > 0.",2.3. Determinism and Sampling,[0],[0]
"Thus, each Bernoulli test performed in T is valid, and hence, s ∈ S .",2.3. Determinism and Sampling,[0],[0]
"For any literal xi occurring in T , let p(xi) denote the probability of the (unique) path connecting the root to xi.",2.3. Determinism and Sampling,[0],[0]
"By a telescoping product of Bernoulli distributions, we get that p(xi) = ew(i)/Q(C |w′).",2.3. Determinism and Sampling,[0],[0]
"Therefore, p(s) = ∏",2.3. Determinism and Sampling,[0],[0]
"i:s(i)=1 p(xi) = Pw(s), as desired.
",2.3. Determinism and Sampling,[0],[0]
We close this section by highlighting some interesting subclasses of dDNNF.,2.3. Determinism and Sampling,[0],[0]
"A decision node is an or-node of the form (xi ∧ c′l) ∨ (xi ∧ c′r), where xi and xi are opposite literals, and c′l and c ′",2.3. Determinism and Sampling,[0],[0]
r are arbitrary nodes.,2.3. Determinism and Sampling,[0],[0]
"The class of Free Binary Decision Diagrams (FBDD) is the subset of dDNNF in which every or-node is a decision node, and at least one child of any and-node is a literal (Wegener, 2000).",2.3. Determinism and Sampling,[0],[0]
"For example, if in the dDNNF circuit of Figure 1, we replace the or-node (in blue) by a simple literal, say x3, then we get an FBDD circuit.",2.3. Determinism and Sampling,[0],[0]
The family of Ordered Binary Decision Diagrams (OBDD) is the subclass of FBDD obtained by imposing a fixed ordering on the decision variables.,2.3. Determinism and Sampling,[0],[0]
"Alternatively, the well-known family of (Binary) Decision Trees (DT) is the subclass of FBDD circuits for which the primal graph is cycle-free.",2.3. Determinism and Sampling,[0],[0]
"Since all these classes are (strict) subsets of dDNNF, they admit linear-time algorithms for linear optimization and model sampling.",2.3. Determinism and Sampling,[0],[0]
"After an excursion into compilation languages, we are now ready to provide efficient characterizations of combinatorial prediction strategies.",3. Tractable Prediction via Compilation,[0],[0]
"Our results are summarized in Table 2.
",3. Tractable Prediction via Compilation,[0],[0]
"Notably, using the fact that ‖s‖1 = d/2, the regret bounds for EH and FPL can easily be derived from (Audibert et al., 2011) and (Hutter & Poland, 2005), respectively.",3. Tractable Prediction via Compilation,[0],[0]
Both strategies are straightforward to implement on dDNNF circuits.,3. Tractable Prediction via Compilation,[0],[0]
"Indeed, recall that EH draws, at each trial t, a feasible solution st ∈ S at random according to the distribution P−ηLt , where Lt = `1 + · · ·+ `t−1.",3. Tractable Prediction via Compilation,[0],[0]
"So, by direct application of Proposition 2, this strategy runs in O(|C|) time per round, using a dDNNF representation C of the decision set S. For the FPL strategy, each round t is performed by choosing a minimizer st ∈ S of the objective function ηLt − zt, where zt ∈ Rd is a perturbation vector whose components are independent exponentially distributed random variables.",3. Tractable Prediction via Compilation,[0],[0]
"By Proposition 1, the FPL strategy also runs inO(|C|) time per round, using a dDNNF encoding C of S, and the fact that |C| is in Ω(d).
",3. Tractable Prediction via Compilation,[0],[0]
"However, the OSMD strategy and its specializations, SGD and CH, require more attention, due to the projectiondecomposition step involved at each iteration.",3. Tractable Prediction via Compilation,[0],[0]
"The overall idea of Online Mirror Descent (OMD) is to “follow the regularized leader” through a primal-dual approach (Nemirovski & Yudin, 1983; Beck & Teboulle, 2003).",3.1. Online Stochastic Mirror Descent,[0],[0]
"Let K be a convex set, and let int(K) denotes its interior.",3.1. Online Stochastic Mirror Descent,[0],[0]
"Given a regularization function F defined on K, OMD iteratively performs a gradient descent in the interior of the dual space K∗, and projects back the dual point into the primal space K.",3.1. Online Stochastic Mirror Descent,[0],[0]
"The connection between K and K∗ is ensured using the gradients ∇F and ∇F ∗, where F ∗ is the convex conjugate of F , defined on K∗.",3.1. Online Stochastic Mirror Descent,[0],[0]
"The projection step is captured by the Bregman divergence of F , which is a function BF : K × int(K)→ R given by:
BF (p, q) = F (p)− F (q)− 〈∇F (q),p− q〉
In the stochastic variant of OMD, introduced by Audibert et.",3.1. Online Stochastic Mirror Descent,[0],[0]
"al. (2011; 2014), and specified in Algorithm 1, each projection is performed onto the subset conv(S) of K, and the resulting point pt is decomposed into a convex combination of feasible solutions in S, from which one is picked at random for the prediction task.
",3.1. Online Stochastic Mirror Descent,[0],[0]
"Algorithm 1 OSMD
Input: decision set S ⊆ {0, 1}d, horizon T ∈ Z+ Parameters: regularizer F on K ⊇ conv(S), step-size η ∈ (0, 1]
set u1 = 0 for t",3.1. Online Stochastic Mirror Descent,[0],[0]
"= 1 to T do
set pt ∈ Argminp∈conv(S)BF (p,∇F ∗(ut))",3.1. Online Stochastic Mirror Descent,[0],[0]
"play st ∼ pt and observe `t set ut+1 = ∇F (pt)− η`t
end for
For common regularizers, the gradient∇F (pt) and its dual ∇F ∗(ut) are easily calculable, and we shall assume that the time spent for their construction is negligible compared with the running time of the linear optimization oracle.",3.1. Online Stochastic Mirror Descent,[0],[0]
"In fact, the computational bottleneck of OSMD is to find a minimizer pt of BF (p,∇F ∗(ut)) in the convex hull of S, and to decompose pt into a convex combination of solutions in S. Fortunately, under reasonable assumptions about the curvature of BF , this projection-decomposition step can be efficiently computed, using recent results in projection-free convex optimization algorithms.
",3.1. Online Stochastic Mirror Descent,[0],[0]
"To this end, we need additional definitions.",3.1. Online Stochastic Mirror Descent,[0],[0]
"For a convex set K, a differentiable function f : K → R is called α-strongly convex with respect to a norm ‖ · ‖ if
f(p′)− f(p) ≥ 〈∇f(p),p′ − p〉+ α 2 ‖p′",3.1. Online Stochastic Mirror Descent,[0],[0]
"− p‖2
",3.1. Online Stochastic Mirror Descent,[0],[0]
"Furthermore, f is called β-smooth1 with respect to ‖ · ‖ if
f(p′)− f(p) ≤",3.1. Online Stochastic Mirror Descent,[0],[0]
"〈∇f(p),p′ − p〉+ β 2 ‖p′",3.1. Online Stochastic Mirror Descent,[0],[0]
"− p‖2
Based on these notions, we say that a Bregman divergence BF has the condition number β/α if BF is both α-strongly convex and β-smooth with respect to the Euclidean norm ‖ · ‖2 in its first argument.",3.1. Online Stochastic Mirror Descent,[0],[0]
"For such regularizers, the next result states that the projection-decomposition step can be approximated in low polynomial time, by exploiting the Pairwise Conditional Gradient (PCG) method, a variant of the Frank-Wolfe convex optimization algorithm, whose convergence rate has been analyzed in (Lacoste-Julien & Jaggi, 2015; Garber & Meshi, 2016; Bashiri & Zhang, 2017).
",3.1. Online Stochastic Mirror Descent,[0],[0]
Lemma 1.,3.1. Online Stochastic Mirror Descent,[0],[0]
"Let S ⊆ {0, 1}d be a decision set represented by a dDNNF circuit C, and F be a regularizer onK ⊇ conv(S) such that BF has condition number β/α.",3.1. Online Stochastic Mirror Descent,[0],[0]
"Then, for any q ∈ int(K) and ∈ (0, 1), one can find inO(βαd
2|C|ln βd ) time a convex decomposition of p ∈ conv(S) such that
BF (p, q)− min p′∈conv(C) BF (p ′, q) ≤
1This notion of geometric smoothness should not be confused with the structural smoothness of NNF circuits in Section 2.
",3.1. Online Stochastic Mirror Descent,[0],[0]
"Algorithm 2 PCG
Input: S ⊆ {0, 1}d, f : K → R, m ∈ Z+",3.1. Online Stochastic Mirror Descent,[0],[0]
"Parameters: step-sizes {ηj}mj=1
let p1 be some point in S for j",3.1. Online Stochastic Mirror Descent,[0],[0]
"= 1 to m do
let ∑j i=1",3.1. Online Stochastic Mirror Descent,[0],[0]
"αisi be the convex decomposition of pj set s+j ∈ Argminp∈conv(S)〈∇f(pj),p〉 set s−j ∈ Argmins∈{s1,···,sj}〈−∇f(pj), s〉 set pj+1 = pj +",3.1. Online Stochastic Mirror Descent,[0],[0]
"ηj(s+j − s − j )
end for
Proof.",3.1. Online Stochastic Mirror Descent,[0],[0]
"Observe that conv(S) is a simplex-like polytope (Bashiri & Zhang, 2017), defined by the linear constraints p ≥ 0, ∑N i=1",3.1. Online Stochastic Mirror Descent,[0],[0]
"αisi = p, α ≥ 0, and ∑N i=1",3.1. Online Stochastic Mirror Descent,[0],[0]
"αi = 1, where N = |S|.",3.1. Online Stochastic Mirror Descent,[0],[0]
"So, conv(S) and BF satisfy the conditions of Theorem 1 in (Garber & Meshi, 2016), and using the step-sizes advocated by the authors, we get that
BF (pm, q)−BF (p∗, q) ≤ βd
2 exp
( − α
8βd2 m ) where pm is the point obtained at the last iteration of PCG, and p∗ is the (unique) minimizer of BF (p, q) on conv(S).",3.1. Online Stochastic Mirror Descent,[0],[0]
"Therefore, after m ≥ (8d2β/α) ln(βd/(2 )) iterations, we haveBF (pm, q)−BF (p∗, q) ≤ .",3.1. Online Stochastic Mirror Descent,[0],[0]
"Finally, since each iteration of PCG makes one call to the linear optimization oracle, the runtime complexity follows from Proposition 1.
",3.1. Online Stochastic Mirror Descent,[0],[0]
"By OSMD+PCG, we denote the refined version of the OSMD algorithm that uses the PCG method at each trial t in order to approximate the Bregman projection-decomposition step.",3.1. Online Stochastic Mirror Descent,[0],[0]
"In addition to a regularizer F and a step-size η, OSMD+PCG takes as parameters a sequence { t}Tt=1 such that
BF (pt, qt)−BF (p∗t , qt) ≤ t
where pt is the point returned by PCG, qt = ∇F ∗(ut), and p∗t is the minimizer of BF (p, qt) over conv(S).
",3.1. Online Stochastic Mirror Descent,[0],[0]
Theorem 1.,3.1. Online Stochastic Mirror Descent,[0],[0]
"Suppose that OSMD+PCG takes as input a dDNNF representation C of a decision set S ⊆ {0, 1}d, and a horizon T , and uses a regularizer F on K ⊇ conv(S) such thatBF has condition number β/α, together with a stepsize η ∈ (0, 1] and a sequence of { t}Tt=1 such that t = γ/t2 for γ > 0.",3.1. Online Stochastic Mirror Descent,[0],[0]
"Then, OSMD+PCG attains the expected regret
(1) RT ≤
√ 2γd
α (lnT + 1) +
1 η max s∈S BF (s,p ∗ 1)
+ 1
η T∑ t=1 BF∗(∇F (p∗t )− η`t,∇F (pt))
with a per-round running time in O ( β
α d2|C|ln βdT γ
) .
",3.1. Online Stochastic Mirror Descent,[0],[0]
Proof.,3.1. Online Stochastic Mirror Descent,[0],[0]
Let s∗ ∈ S be the optimal solution chosen with the benefit of hindsight.,3.1. Online Stochastic Mirror Descent,[0],[0]
"By decomposing the regret, we have
RT = T∑ t=1 〈`t,p∗t − s∗〉+ T∑ t=1",3.1. Online Stochastic Mirror Descent,[0],[0]
"E〈`t, st − p∗t 〉 (2)
",3.1. Online Stochastic Mirror Descent,[0],[0]
"By Theorem 2 in (Audibert et al., 2014), the first term in (2) is bounded by the last two terms in (1).",3.1. Online Stochastic Mirror Descent,[0],[0]
"For the second term in (2), we get from the Cauchy-Schwarz inequality that
E〈`t, st − p∗t 〉 ≤ ‖`t‖2‖pt − p∗t ‖2≤",3.1. Online Stochastic Mirror Descent,[0],[0]
"√ d‖pt − p∗t ‖2
Moreover, by applying the Generalized Pythagorean Theorem (Cesa-Bianchi & Lugosi, 2006), we know that BF (p, qt) ≥ BF (p,p∗t ) + BF (p∗t , qt), for any p ∈ conv(S).",3.1. Online Stochastic Mirror Descent,[0],[0]
"Using p = pt and rearranging,
BF (pt,p ∗ t ) ≤ BF (pt, qt)−BF (p∗t , qt) ≤ t (3)
Since BF is α-strongly convex with respect to ‖ · ‖2 in its first argument, we also have α2 ‖pt",3.1. Online Stochastic Mirror Descent,[0],[0]
"− p ∗ t ‖22≤ BF (pt,p∗t ).",3.1. Online Stochastic Mirror Descent,[0],[0]
"Thus by plugging this inequality into (3), we get that E〈`t, st − p∗t 〉 ≤ √ 2d t/α.",3.1. Online Stochastic Mirror Descent,[0],[0]
"Finally, by substituting t with ρ/t2, summing other T , and applying the logarithmic bound on harmonic series, we obtain the desired result.",3.1. Online Stochastic Mirror Descent,[0],[0]
The (online) SGD algorithm is derived from OSMD using the Euclidean regularizer F (p) = 12 ‖p‖ 2 2.,3.2. Stochastic Gradient Descent,[0],[0]
"In this simple framework, the primal and dual spaces coincide with Rd, and hence, F ∗(u) = u, ∇F (p) = p, and ∇F ∗(u) =",3.2. Stochastic Gradient Descent,[0],[0]
"u. Furthermore, BF has the condition number 1/1, since BF (p, q) = 1 2 ‖p− q‖ 2 2.",3.2. Stochastic Gradient Descent,[0],[0]
"We denote by SGD+PCG the instance of OSMD+PCG defined on the Euclidean regularizer.
",3.2. Stochastic Gradient Descent,[0],[0]
Proposition 3.,3.2. Stochastic Gradient Descent,[0],[0]
"The SGD+PCG algorithm achieves an expected regret bounded by d( √ T + lnT + 1) with a per-round runtime complexity in O(d2|C|ln(dT )) using η = 1/ √ T and γ = d/2.
Proof.",3.2. Stochastic Gradient Descent,[0],[0]
"This simply follows from Theorem 1, together with the fact that maxs∈S BF (s,p∗1) ≤",3.2. Stochastic Gradient Descent,[0],[0]
d and ‖`t‖22≤ d.,3.2. Stochastic Gradient Descent,[0],[0]
The CH algorithm is derived from OSMD using the entropic regularizer F (p) = ∑d i=1,3.3. Component Hedge,[0],[0]
"p(i)(ln p(i)− 1), for which the
conjugate is F ∗(u) = ∑d i=1",3.3. Component Hedge,[0],[0]
expu(i).,3.3. Component Hedge,[0],[0]
"Here, we cannot find a finite condition number for the associated divergence BF (p, q) = ∑d i=1",3.3. Component Hedge,[0],[0]
p(i),3.3. Component Hedge,[0],[0]
ln p(i) q(i),3.3. Component Hedge,[0],[0]
− (p(i),3.3. Component Hedge,[0],[0]
"− q(i)), since its gradient is unbounded.",3.3. Component Hedge,[0],[0]
"This issue may, however, be circumvented using a simple trick advocated in (Krichene et al., 2015), which consists in replacing the entropic regularizer with the function Fδ(p) = F (p + δ), where
δ ∈ (0, 1) and δ = (δ, · · · , δ).",3.3. Component Hedge,[0],[0]
"For this function, the primal space is (−δ,+∞), and since F ∗δ (u) = F ∗(u) − 〈u, δ〉, the dual space is Rd.",3.3. Component Hedge,[0],[0]
"It is easy to show that
∂Fδ(p)
∂p(i) = ln(p(i)",3.3. Component Hedge,[0],[0]
"+ δ)
∂F ∗δ",3.3. Component Hedge,[0],[0]
"(u)
∂u(i) = eu(i)",3.3. Component Hedge,[0],[0]
"− δ
BFδ(p, q) = BF (p+δ, q+δ) B ∗",3.3. Component Hedge,[0],[0]
"Fδ (u,v) =",3.3. Component Hedge,[0],[0]
"B∗F (u,v)
where B∗F (u,v) = ∑d i=1",3.3. Component Hedge,[0],[0]
"e
v(i)(ev(i)−u(i) +v(i)−u(i)−1).",3.3. Component Hedge,[0],[0]
"Furthermore, since the first and second order partial derivatives of B∗Fδ(p, q) at the coordinate p(i) are
∂BFδ(p, q)
∂p(i) =",3.3. Component Hedge,[0],[0]
"ln
p(i)",3.3. Component Hedge,[0],[0]
"+ δ
q(i) + δ
∂2BFδ(p, q)
∂2p(i)",3.3. Component Hedge,[0],[0]
"= ln
1
p(i)",3.3. Component Hedge,[0],[0]
"+ δ
it follows that BFδ has the condition number 1+δ/δ.",3.3. Component Hedge,[0],[0]
"Indeed, given an arbitrary point q ∈ int(−δ,+∞), let Hq(p) denote the the Hessian matrix of BFδ(p, q) at p ∈ conv(S).",3.3. Component Hedge,[0],[0]
"Then, for any z ∈ Rd, the diagonal entries of Hq(p) satisfy
1 1 + δ ≤ ∂
2BF (p, q)
∂2p(i) z(i)2 ≤ 1 δ
using the fact that p(i) ∈",3.3. Component Hedge,[0],[0]
"[0, 1].",3.3. Component Hedge,[0],[0]
"Thus, αI 4 Hq(p) 4 βI for α = 1/1+δ and β = 1/δ.",3.3. Component Hedge,[0],[0]
"In what follows, the instance of OSMD+PCG that uses Fδ as regularizer is called δ-CH+PCG.
Proposition 4.",3.3. Component Hedge,[0],[0]
"The δ-CH+PCG algorithm achieves an expected regret bounded by d(1 + 2δ)( √ T + lnT + 1)
with a per-round runtime complexity in O ( d2|C|/δ ln dT/δ ) using η = 1/√T and γ = 2d(1/2 + δ)/(1 + δ).
",3.3. Component Hedge,[0],[0]
Proof.,3.3. Component Hedge,[0],[0]
The runtime complexity simply follows from Theorem 1.,3.3. Component Hedge,[0],[0]
"The regret bound is obtained by bounding the second and third terms of (1), and using the above values for η and γ.",3.3. Component Hedge,[0],[0]
"Using s∗1 as a maximizer of the second term of (1), we have BFδ(s ∗ 1,p ∗ 1) = Fδ(s ∗ 1)",3.3. Component Hedge,[0],[0]
− Fδ(p∗1).,3.3. Component Hedge,[0],[0]
"Using the notation p̃1 = p∗1 + δ and r = d(1/2 + δ), we get that
Fδ(s ∗ 1)− Fδ(p∗1) ≤ d∑ i=1",3.3. Component Hedge,[0],[0]
p̃1(i),3.3. Component Hedge,[0],[0]
ln 1 p̃1(i) ≤,3.3. Component Hedge,[0],[0]
"r ln d r
which is bounded by r.",3.3. Component Hedge,[0],[0]
"For the third term of (1), observe that Fδ is 1(1+δ)d -strongly convex with respect to the norm ‖ · ‖1, since ‖p",3.3. Component Hedge,[0],[0]
− p′‖21≤ d‖p,3.3. Component Hedge,[0],[0]
− p′‖22.,3.3. Component Hedge,[0],[0]
"By Theorem 3 in (Kakade et al., 2012), it follows that F ∗δ is (1 + δ)d-smooth with respect to the norm ‖ · ‖∞.",3.3. Component Hedge,[0],[0]
"Therefore,
1 η BF∗(∇F (p∗t )− η`t,∇F (pt)) ≤",3.3. Component Hedge,[0],[0]
η 2,3.3. Component Hedge,[0],[0]
d(1,3.3. Component Hedge,[0],[0]
"+ δ)‖`t‖2∞
",3.3. Component Hedge,[0],[0]
which is bounded by ηr.,3.3. Component Hedge,[0],[0]
"In order to evaluate the performance of the different online combinatorial optimization strategies examined in Section 3, we have considered 16 instances of the SAT Library,2 described in Table 3.",4. Experiments,[0],[0]
"Namely, the first six rows of the table are (car) configuration tasks, while the remaining rows are planning problems.",4. Experiments,[0],[0]
"In the first four columns of the table are reported the name of the SAT instance, the number of attributes (d/2), the number of constraints (|SAT|), and the number |S| of feasible solutions.",4. Experiments,[0],[0]
"We have used the recent D4 compiler 3 (Lagniez & Marquis, 2017) for transforming SAT instances into dDNNF circuits.",4. Experiments,[0],[0]
"The size |C| of the compiled circuit is reported in the fifth column.
",4. Experiments,[0],[0]
"In order to simulate combinatorial prediction games, we have used the following protocol.",4. Experiments,[0],[0]
"Suppose that the set X = {x1, · · · , xd} of literals is sorted in a lexicographic way, so that for each odd integer i, the pair (xi, xi+1) encodes both configurations of the same binary attribute.",4. Experiments,[0],[0]
"First, we construct a vector µ0 of d/2 independent Bernoulli variables.",4. Experiments,[0],[0]
"At each round t ∈ {1, · · · , T}, µt is set to µt−1 with probability 0.9, or picked uniformly at random from [0, 1]d/2 with probability 0.1.",4. Experiments,[0],[0]
"Then, the feedback supplied to the learner is a vector `t ∈ {0, 1}d such that `t(i) + `t(i + 1) = 1, and `t(i) = 1 with probability µt(i+1/2) for each odd integer i.",4. Experiments,[0],[0]
"So, `t(i + 1) = 1 with probability 1 − µt(i+1/2).",4. Experiments,[0],[0]
"Although this protocol is essentially stochastic, the environment secretly resets µt with probability 0.1 at each round to foil the learner.
",4. Experiments,[0],[0]
"The combinatorial prediction strategies were implemented in C++ and tested on a six-core Intel i7-5930K with 32 GiB RAM.4 For the FPL and EH algorithms, we used the step-size η reported in (Audibert et al., 2011) and (Hutter & Poland, 2005), respectively.",4. Experiments,[0],[0]
"Concerning the SGD+PCG and δ-CH+PCG algorithms, we used for η and γ the values determined by our theoretical analysis; the step-sizes {ηt} of PCG were computed from binary search as advocated by Garber & Meshi (2016) in their experiments, and the value of δ was fixed to 1/ln d",4. Experiments,[0],[0]
in order to keep a quadratic runtime complexity for δ-CH+PCG.,4. Experiments,[0],[0]
"Finally, the horizon T was set to 103, and a timeout of one day was fixed for learning.
",4. Experiments,[0],[0]
"In our experiments, the regret is measured by the difference in cumulative loss between the algorithm and the best feasible solution in hindsight, which is obtained using the linear optimization oracle at horizon T .",4. Experiments,[0],[0]
"This measure is averaged on 10 simulations, and divided by T to yield an average empirical regret.",4. Experiments,[0],[0]
"Similarly, the per-round runtimes (in seconds) are averaged on 10 simulations.",4. Experiments,[0],[0]
"The corresponding results are reported in the last four columns of Table 3.
2www.cs.ubc.ca/˜hoos/SATLIB/ 3www.cril.univ-artois.fr/KC/d4.html 4www.github.com/frederic-koriche/ccpg.git
Here, the symbol “−” indicates that the learner was not able to perform the T rounds in one day.",4. Experiments,[0],[0]
"From the viewpoint of regret, SGD+PCG and δ-CH+PCG outperform EH and FPL, which confirms our theoretical results.",4. Experiments,[0],[0]
We mention in passing that SGD+PCG and δ-CH+PCG are remarkably stable.,4. Experiments,[0],[0]
"Contrastingly, FPL exhibits a larger variance.
",4. Experiments,[0],[0]
"Concerning runtimes, EH and FPL are unsurprisingly faster than SGD+PCG and δ-CH+PCG.",4. Experiments,[0],[0]
"Notably, for the hard-to-compile instances c140-fc and c163-fw, both EH and FPL were able to perform each trial in few tens of seconds, while OSMD+PCG algorithms took several minutes per-round (and hence, they were unable to process 103 rounds in one day), due to the time spent in approximating the Bregman projection step.",4. Experiments,[0],[0]
"Yet, it is important to emphasize that the convergence rate of PCG is, in practice, much faster than the theoretical bound of Õ(d2|C|).",4. Experiments,[0],[0]
Both SGD+PCG and δ-CH+PCG were able to process nearly all instances in few seconds per round.,4. Experiments,[0],[0]
"For circuits of moderate size, all algorithms run in less than one second per trial.",4. Experiments,[0],[0]
"We also observed that SGD+PCG is slightly faster than δ-CH+PCG, especially for large domains where small values of δ have a significant impact on the the runtime complexity.",4. Experiments,[0],[0]
"In essence, SGD+PCG offers the best compromise between predictive performance and running time; since all feasible solutions are dense (‖s‖1= d/2), there is no significant difference in accuracy between SGD+PCG and δ-CH+PCG.",4. Experiments,[0],[0]
"We have proposed a general framework for compiling online combinatorial optimization problems, whose space of feasible solutions is described using a set of Boolean constraints.",5. Conclusions,[0],[0]
"Namely, we have focused on the class of dDNNF circuits which is endowed with fast inference algorithms for the linear optimization oracle and the sampling oracle.",5. Conclusions,[0],[0]
"Based on
this framework, we have shown than both EH and FPL admit fast implementation for tackling large scale online combinatorial problems.",5. Conclusions,[0],[0]
"A particular attention was devoted to the generic OSMD strategy, which involves a computationally expensive projection-decomposition step at each iteration.",5. Conclusions,[0],[0]
"To this point, we made use of projection-free algorithms, and in particular the PCG method, for approximating this operation.",5. Conclusions,[0],[0]
"The resulting algorithms, SGD+PCG and δ-CH-PCG, are inevitably slower than EH and FPL, but achieve a better regret performance, as corroborated by our experiments.
",5. Conclusions,[0],[0]
We conclude with a few remarks.,5. Conclusions,[0],[0]
"In light of the current results, a natural perspective of research is to extend our framework to other classes of combinatorial prediction games.",5. Conclusions,[0],[0]
"Notably, the semi-bandit setting seems within reach.",5. Conclusions,[0],[0]
"Indeed, the semi-bandit variant of EH, often referred to as EXP2 (Audibert et al., 2014), uses importance weights for estimating the loss at each iteration.",5. Conclusions,[0],[0]
"By simple adaptation of Proposition 2, such weights can be computed in linear time.",5. Conclusions,[0],[0]
"Similarly, the semi-bandit extension of FPL exploits the geometric sampling method for estimating loss vectors (Neu & Bartók, 2016).",5. Conclusions,[0],[0]
"Again, this iterative method can be implemented in linear time (per iteration) using Proposition 1.",5. Conclusions,[0],[0]
"Less obvious, however, is the extension of OSMD to semi-bandits: although the extension of CH achieves an optimal expected regret in this setting, its practical use remain limited due to projection-decomposition step.",5. Conclusions,[0],[0]
"An interesting open question is to determine whether a combination of CH with PCG is able, in the semi-bandit case, to achieve a quasi-optimal regret in low-polynomial time.",5. Conclusions,[0],[0]
"Of course, the bandit setting is even more challenging.",5. Conclusions,[0],[0]
"To this point, Sakaue et.",5. Conclusions,[0],[0]
"al. (2018) have paved the way using OBDDs for an efficient implementation of the COMBBAND algorithm (Cesa-Bianchi & Lugosi, 2012), Extending their approach to dDNNF, which is more succinct than OBDD, is a promising direction of future research.",5. Conclusions,[0],[0]
"In online optimization, the goal is to iteratively choose solutions from a decision space, so as to minimize the average cost over time.",abstractText,[0],[0]
"As long as this decision space is described by combinatorial constraints, the problem is generally intractable.",abstractText,[0],[0]
"In this paper, we consider the paradigm of compiling the set of combinatorial constraints into a deterministic and Decomposable Negation Normal Form (dDNNF) circuit, for which the tasks of linear optimization and solution sampling take linear time.",abstractText,[0],[0]
"Based on this framework, we provide efficient characterizations of existing combinatorial prediction strategies, with a particular attention to mirror descent techniques.",abstractText,[0],[0]
These strategies are compared on several real-world benchmarks for which the set of Boolean constraints is preliminarily compiled into a dDNNF circuit.,abstractText,[0],[0]
Compiling Combinatorial Prediction Games,title,[0],[0]
"Researchers have demonstrated impressive successes in building agents that can achieve excellent performance in difficult tasks, e.g. (Mnih et al., 2015; Silver et al., 2016).",1. Introduction,[0],[0]
"However, these successes have mostly been confined to situations where it is possible to train a large number of times on a single known task.",1. Introduction,[0],[0]
"On the other hand, in some situations, the tasks of interest are not known at training time or the space of tasks is so large that an agent will not realistically be able to train many times on any single task in the space.
",1. Introduction,[0],[0]
"We might hope that the tasks of interest are compositional: for example, cracking an egg is the same whether one is
*Equal contribution 1Facebook AI Research, New York, NY, USA 2New York University, New York, NY, USA.",1. Introduction,[0],[0]
"Correspondence to: Adam Lerer <alerer@fb.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
making pancakes or an omelette.",1. Introduction,[0],[0]
"If the space of tasks we want an agent to be able to solve has compositional structure, then a state abstraction that exposes this structure could be used both to specify instructions to the agent, and to plan through sub-tasks that allow the agent to complete its instructions.
",1. Introduction,[0],[0]
In this work we show how to train agents that can solve complex tasks by planning over a sequence of previously experienced simpler ones.,1. Introduction,[0],[0]
"The training protocol relies on a state abstraction that is manually specified, consisting of a set of binary attributes designed to capture properties of the environment we consider important.",1. Introduction,[0],[0]
"These attributes, learned at train time from a set of (state, attribute) pairs, provide a natural way to specify tasks, and a natural state abstraction for planning.",1. Introduction,[0],[0]
"Once the agent learns how its actions affect the environment in terms of the attribute representation, novel tasks can be solved compositionally by executing a plan consisting of a sequence of transitions between abstract states defined by those attributes.",1. Introduction,[0],[0]
"Thus, as in (Dayan & Hinton, 1992; Dietterich, 2000; Vezhnevets et al., 2017), temporal abstractions are explicitly linked with state abstractions.
",1. Introduction,[0],[0]
"Our approach is thus a form of model-based planning, where the agent first learns a model of its environment (the mapping from states to attributes, and the attribute transition graph), and then later uses that model for planning.",1. Introduction,[0],[0]
"There is no supervision or reward given for completing the tasks of interest; outside of the (state, attribute) pairs, the agent receives no other reward or extrinsic supervision.",1. Introduction,[0],[0]
"In the experiments below, we will show empirically that this kind of approach can be useful on problems that can be challenging for standard reinforcement learning.
",1. Introduction,[0],[0]
We evaluate compositional planning in several environments.,1. Introduction,[0],[0]
"We first consider 3D block stacking, and show that we can compose single-action tasks seen during training to perform multi-step tasks.",1. Introduction,[0],[0]
"Second, we plan over multi-step policies in 2-D grid world tasks.",1. Introduction,[0],[0]
"Finally, we see how our approach scales to a unit-building task in StarCraft.
2.",1. Introduction,[0],[0]
The Attribute Planner Model,1. Introduction,[0],[0]
"We consider an agent in a Markov environment, i.e. at each time the agent observes the state s and takes action
a, which uniquely determines the probability P (s, a, s0) of transitioning from s to s0.",1. Introduction,[0],[0]
We augment the environment with a map f : S ! {⇢} from states to a set of userdefined attributes ⇢.,1. Introduction,[0],[0]
"We assume that either f is provided or a small set of hand-labeled (s, ⇢) pairs are provided in order to learning a mapping f̂ .",1. Introduction,[0],[0]
"Hence, the attributes are human defined and constitute a form of supervision.",1. Introduction,[0],[0]
Here we consider attributes that are sets of binary vectors.,1. Introduction,[0],[0]
"These user-specified attributes parameterize the set of goals that can be specified at test time.
",1. Introduction,[0],[0]
"The agent’s objective at test time is, given a set of goal attributes ⇢g , to take a sequence of actions in the environment that end with the agent in a state that maps to ⇢g. During training, the agent constructs a model with three parts:
1.",1. Introduction,[0],[0]
"a neural-net based attribute detector f̂ , which maps states s to a set of attributes ⇢, i.e. ⇢ = f̂(s).
2.",1. Introduction,[0],[0]
"a neural net-based policy ⇡(s, ⇢g) which takes a pair of inputs: the current state s and attributes of an (intermediate) goal state ⇢g , and outputs a distribution over actions.
",1. Introduction,[0],[0]
3.,1. Introduction,[0],[0]
"a transition table c⇡(⇢i, ⇢j) that records the empirical probability that ⇡(s⇢i , ⇢j) can succeed at transiting successfully from ⇢i to ⇢j in a small number of steps.
",1. Introduction,[0],[0]
The transition table c⇡ can be interpreted as a graph where the edge weights are probabilities.,1. Introduction,[0],[0]
"This high-level attribute graph is then searched at test time to find a path to the goal with maximum probability of success, with the policy network performing the low-level actions to transition between adjacent attribute sets.",1. Introduction,[0],[0]
"The first step in training the Attribute Planner is to fit the neural network detector f̂ that maps states s to attributes ⇢, using the labeled states provided.",2.1. Training the Attribute Planner,[0],[0]
"If a hardcoded function f is provided, then this step can be elided.
",2.1. Training the Attribute Planner,[0],[0]
"In the second step, the agent explores its environment using an exploratory policy.",2.1. Training the Attribute Planner,[0],[0]
"Every time an attribute transition (⇢i, ⇢j) is observed, it is recorded in an intermediate transition table c⇡e .",2.1. Training the Attribute Planner,[0],[0]
"This table will be used in later steps to keep track of which transitions are possible.
",2.1. Training the Attribute Planner,[0],[0]
"The most naive exploratory policy takes random actions, but the agent can explore more efficiently if it performs count-based exploration in attribute space.",2.1. Training the Attribute Planner,[0],[0]
"We use a neural network exploration policy that we train via reinforcement learning with a count-based reward1 proportional to c⇡e(⇢i, ⇢j) 0.5 upon every attribute transition (⇢i, ⇢j), where c⇡e(⇢i, ⇢j) is the visit count of this transition during exploration.",2.1. Training the Attribute Planner,[0],[0]
"This bonus is as in (Strehl & Littman, 2008), but with no empirical reward from the environment.",2.1. Training the Attribute Planner,[0],[0]
The precise choice of exploration bonus is discussed in App.,2.1. Training the Attribute Planner,[0],[0]
"A.
",2.1. Training the Attribute Planner,[0],[0]
"Now that we have a graph of possible transitions, we next train the low-level goal-conditional policy ⇡ and the main transition table c⇡ .",2.1. Training the Attribute Planner,[0],[0]
"From state s with attributes ⇢, the model picks an attribute set ⇢g randomly from the neighbors of ⇢ in c⇡e weighted by their visit count in the Explore phase and sets that as the goal for ⇡.",2.1. Training the Attribute Planner,[0],[0]
"Once the goal is achieved or a timeout is reached, the policy is updated and the main transition table c⇡ is updated to reflect the success or failure.",2.1. Training the Attribute Planner,[0],[0]
"⇡ is updated via reinforcement learning, with a reward r of
1Although the reward is non-stationary, we find (as in the literature) that it is empirically effective.
1 if ⇢g was reached and 0 otherwise2.",2.1. Training the Attribute Planner,[0],[0]
"See Algorithm 1 for pseudocode of AP training.
",2.1. Training the Attribute Planner,[0],[0]
"In the case of block stacking (Sec. 4.1), the attribute transitions consist of a single step, so we treat ⇡ as an “inverse model” in the style of (Agrawal et al., 2016; Andrychowicz et al., 2017), and rather than using reinforcement learning, we can train ⇡ in a supervised fashion by taking random actions and training ⇡ to predict the action taken given the initial state and final attributes.
",2.1. Training the Attribute Planner,[0],[0]
"Algorithm 1 Attribute Planner Training Input: Labeled pairs {(si, ⇢i)}, exploratory policy ⇡e, N1, N2, tmax.
//",2.1. Training the Attribute Planner,[0],[0]
"Step 1: Train attribute detector Fit f̂ on {(si, ⇢i)} with supervised learning.
",2.1. Training the Attribute Planner,[0],[0]
"// Step 2: Explore
for t = 1 ...",2.1. Training the Attribute Planner,[0],[0]
N1 do Act according to ⇡e(st 1).,2.1. Training the Attribute Planner,[0],[0]
"Compute attributes ⇢t f̂(st) if ⇢t 6= ⇢t 1 then
Record the transition: c⇡e(⇢t 1, ⇢t) +",2.1. Training the Attribute Planner,[0],[0]
"= 1 Optional: Update ⇡e with count-based reward.
//",2.1. Training the Attribute Planner,[0],[0]
"Step 3: Train policy ⇡ and c⇡ tlast 0, ⇢s ;, ⇢e RandNeighbor(c⇡e , ⇢s) for t = 1 ...",2.1. Training the Attribute Planner,[0],[0]
"N2 do
Compute attributes ⇢t f̂(st)",2.1. Training the Attribute Planner,[0],[0]
"if t = 1 or ⇢t 6= ⇢s or t tlast tmax then
r 1 if ⇢t = ⇢e, otherwise 0.",2.1. Training the Attribute Planner,[0],[0]
"UpdatePolicy(⇡, r) Record attempt: A⇡(⇢t 1, ⇢t) += 1 Record success: S⇡(⇢t 1, ⇢t) += r ⇢s ⇢t, ⇢e RandNeighbor(c⇡e , ⇢s) tlast t
Take an action according to ⇡(st 1, ⇢e)
for (⇢i, ⇢j) 2",2.1. Training the Attribute Planner,[0],[0]
"A⇡ do c⇡(⇢i, ⇢j) S⇡(⇢i, ⇢j)/A⇡(⇢i, ⇢j).",2.1. Training the Attribute Planner,[0],[0]
Once the model has been built we can use it for planning.,2.2. Evaluating the model,[0],[0]
"That is, given an input state s and target set of attributes ⇢T , we find a path [⇢0, ⇢1, ..., ⇢m] on the graph G with ⇢0 = f(s) and ⇢m = ⇢T minimizing Pm 1 i=0 log c⇡(⇢i, ⇢i+1) which maximizes the probability of success of the path (assuming independence).",2.2. Evaluating the model,[0],[0]
"The probability c⇡ is computed in Algorithm 1 as the ratio of observed successes and attempts
2Since c⇡ is collecting statistics about ⇡ which is nonstationary.",2.2. Evaluating the model,[0],[0]
"So c⇡ should really be updated only after a burn-in period of ⇡, or a moving average should be used for the statistics.
during training.
",2.2. Evaluating the model,[0],[0]
"The optimal path can be found using Dijkstra’s algorithm with a distance metric of log(c⇡(⇢i, ⇢i+1)).",2.2. Evaluating the model,[0],[0]
"The policy is then used to move along the resulting path between attribute set, i.e. we take actions according to a = ⇡(s, ⇢1), then once f(s) = ⇢1, we change to a = ⇡(s, ⇢2) and so on.",2.2. Evaluating the model,[0],[0]
"At each intermediate step, if the current attributes don’t match the attributes on the computed path, then a new path is computed using the current attributes as a starting point (or, equivalently, the whole path is recomputed at each step).
",2.2. Evaluating the model,[0],[0]
"Algorithm 2 Attribute Planner Inference Input: Low-level policy ⇡, graph c⇡, attribute detector f̂ , target attributes ⇢T .",2.2. Evaluating the model,[0],[0]
"do
⇢ f̂(s)",2.2. Evaluating the model,[0],[0]
"[⇢0, ..., ⇢m] ShortestPath(c⇡, ⇢, ⇢g) Act according to ⇡(st 1, ⇢1).
",2.2. Evaluating the model,[0],[0]
"while ⇢ 6= ⇢T
2.3.",2.2. Evaluating the model,[0],[0]
"An Aside: Which attributes should we include?
",2.2. Evaluating the model,[0],[0]
"Since we use user-specified attributes for planning, which attributes are important to include?",2.2. Evaluating the model,[0],[0]
"The set of attributes must be able to specify our goals of interest, and should be parsimonious since extra attributes will increase the size of the graph and thus degrade the statistics on each edge/.
On the other hand, the attributes should have a property that we will call “ignorability” which says that the probability of being able to transition from ⇢i to ⇢j should only depend on the attributes ⇢i, not the exact state; i.e. P⇡(f(st0) = ⇢j |f(st))",2.2. Evaluating the model,[0],[0]
=,2.2. Evaluating the model,[0],[0]
P⇡(f(st0) = ⇢j |st) 3.,2.2. Evaluating the model,[0],[0]
"To the extent that this condition is violated, then transitions are aliased, and a planned transition may not be achievable by the policy from the particular state s even though it’s achievable from other states with the same properties, causing the model to fail to achieve its goal.",2.2. Evaluating the model,[0],[0]
"For example, in the block stacking task in 4.1, there will be nontrivial aliasing; we will show that some amount of aliasing is not deadly for our model.",2.2. Evaluating the model,[0],[0]
"Many researchers have recognized the importance of methods that can divide a MDP into subprocesses (Thrun & Schwartz, 1994; Parr & Russell, 1998; Sutton et al., 1999; Dietterich, 2000).",3. Related work,[0],[0]
"Perhaps the most standard formalism today is the options framework of (Sutton et al., 1999), which deals with multistep “macro-actions” in the setting of reinforcement learning.",3. Related work,[0],[0]
"Recent works, like (Kulkarni et al., 2016; Harb et al., 2017), have shown how options can be used (and even discovered in (Harb et al., 2017)) with
3The particular sequence of actions that effects the transition from ⇢i to ⇢j may still be conditional on the state.
function approximation via deep learning.
",3. Related work,[0],[0]
Our work is also a hierarchical approach to controlling an agent in a Markovian environment.,3. Related work,[0],[0]
"However, the paradigm we consider differs from reinforcement learning: we consider a setup where no reward or supervision is provided other than the (s, f(s)) pairs, and show than an agent can learn to decompose a transition between far away ⇢, ⇢0 into a sequence of short transitions.",3. Related work,[0],[0]
"If we were to frame the problem as HRL, considering each ⇡(·, ⇢) as a macro action4, in order for the agent to learn to sequence the ⇡(·, ⇢i), the environment would need to give reward for the completion of complex tasks, not just simple ones.
",3. Related work,[0],[0]
"As in (Sutton et al., 2011; Schaul et al., 2015; Dosovitskiy & Koltun, 2016; Fern et al., 2004), we have policies parameterized by state and target attributes.",3. Related work,[0],[0]
"In (Dosovitskiy & Koltun, 2016), an agent is given supervision of future values of attributes of the state considered important for describing tasks.",3. Related work,[0],[0]
"Unlike in that work, our attributes are functions of the current state, and the model uses its own estimator to learn the dynamics at the level of attributes as a graph.",3. Related work,[0],[0]
"Thus, our model gets no extrinsic supervision of environment dynamics or goal attainment at the level of attributes.",3. Related work,[0],[0]
"Our training of c⇡ and then using cpi for task generation recalls (Fern et al., 2004).",3. Related work,[0],[0]
"In that work, as training progresses, goals are farther and farther away (as measured by the steps of a random walk on attributes); but in our work the goals are always one attribute away.",3. Related work,[0],[0]
"This is because our ⇡ only needs to know how to transition between nearby attribute sets, thanks to the planner.",3. Related work,[0],[0]
"In contrast (Fern et al., 2004) aims to train a reactive policy that can handle long transitions too, obviating the need for a planner.",3. Related work,[0],[0]
"Moreover, (Fern et al., 2004) works entirely in the symbolic space, whereas we interfaces the perceptual space with the symbolic space.",3. Related work,[0],[0]
"In (van Seijen et al., 2017), human provided attributes are used as a general value function (GVF) in Ms. Pacman, showing that using a weighted combination of these can lead to higher scores than standard rewards; but again, in contrast to our work, their goal is a better reactive policy.
",3. Related work,[0],[0]
"Our approach is closely related to factored MDP (Boutilier et al., 1995; 2000; Guestrin et al., 2003b).",3. Related work,[0],[0]
"In these works, it is assumed that the environment can be represented by discrete attributes, and that transitions between the attributes by an action can be modeled as a Bayesian network.",3. Related work,[0],[0]
The value of each attribute after an action is postulated to depend in a known way on attributes from before the action.,3. Related work,[0],[0]
The present work differs from these in that the attributes do not determine the state and the dependency graph is not assumed to be known.,3. Related work,[0],[0]
"More importantly, the focus in this work is on
4All the “macro actions’ in our examples in 4.1 are degenerate in the sense that they return after one step, but we still are able to show generalization to long trajectories from (unsupervised) training only on short ones
organizing the space of tasks through the attributes rather than being able to better plan a specific task; and in particular being able to generalize to new, more complex tasks at test time.
",3. Related work,[0],[0]
"Our approach is also related to Relational MDP and Object Oriented MDP (Hernandez-Gardiol & Kaelbling, 2003; van Otterlo, 2005; Diuk et al., 2008; Abel et al., 2015), where states are described as a set of objects, each of which is an instantiation of canonical classes, and each instantiated object has a set of attributes.",3. Related work,[0],[0]
"Our work is especially related to (Guestrin et al., 2003a), where the aim is to show that by using a relational representation of an MDP, a policy from one domain can generalize to a new domain.",3. Related work,[0],[0]
"However, in the current work, the attributes are taken directly as functions of the state, as opposed to defined for object classes, and we do not have any explicit encoding of how objects interact.",3. Related work,[0],[0]
"The model is given some examples of various attributes, and builds a parameterized model that maps into the attributes.
",3. Related work,[0],[0]
"The Programmable Agents of (Denil et al., 2017) put the notions of objects and attributes (as in relational MDP) into an end-to-end differentiable neural architecture.",3. Related work,[0],[0]
"Their model also learns mappings from states to attributes, and is evaluated on a block manipulation task.",3. Related work,[0],[0]
"In their work, the attributes are used to generalize to different combinations of object properties at test time, while we use it to generalize compositionally to more complex tasks.",3. Related work,[0],[0]
"Also, while our model uses explicit search to reason over attributes, they use an end-to-end neural architecture.
",3. Related work,[0],[0]
There is a large literature on quickly adapting to a new learning problem given a set or a history of related learning problems.,3. Related work,[0],[0]
"Our approach in this work has a similar motivation to (Isele et al., 2016), where tasks are augmented with descriptors and featurized, and the coefficients of the task features in a sparse dictionary are used to weight a set of vectors defining the model for the associated task.",3. Related work,[0],[0]
"Similarly, the task is specified by a feature as an input into a model in (Lopez-Paz & Ranzato, 2017).",3. Related work,[0],[0]
"However, in our work, although the attributes are used to parameterize tasks, rather than directly featurize the tasks, they are features of a state; and we learn the mapping from state to attributes.",3. Related work,[0],[0]
"This allows our agent to learn how to transit between sets of attributes unsupervised, and plan in that space.
",3. Related work,[0],[0]
Several recent deep reinforcement learning works have used modular architectures and hierarchy to achieve generalization to new tasks.,3. Related work,[0],[0]
"For example, (Tessler et al., 2017) uses pre-trained skills for transfer.",3. Related work,[0],[0]
"(Oh et al., 2017) uses a metacontroller that selects parameterized skills and analogical supervision on outer-product structured tasks.",3. Related work,[0],[0]
"However, our “meta-controller” is the search over attributes, rather than a reactive model, which allows explicit planning.",3. Related work,[0],[0]
"Furthermore, although our assignments of attributes serves a similar purpose to their analogical supervision (and outer-
product task structure),the methods are complementary; we can imagine augmenting our attributes with analogical supervision.
",3. Related work,[0],[0]
"In (Andreas et al., 2017), generalization is achieved through supervision in the form of “policy sketches”, which are symbolic representations of the high level steps necessary to complete a given task.",3. Related work,[0],[0]
The low level steps in executing modules in the sketches are composable.,3. Related work,[0],[0]
"Our work is similar in that high level annotation is used to enable generalization, but the mechanism in this work is different.",3. Related work,[0],[0]
"Note that the approaches in (Andreas et al., 2017) is also complementary to the one described here; in future work we wish to explore combining them.
",3. Related work,[0],[0]
In this work we use an explicit memory of sets of attributes the model has seen.,3. Related work,[0],[0]
"Several previous works have used nonparametric memories for lowering the sample complexity of learning, e.g. (Blundell et al., 2016; Pritzel et al., 2017).",3. Related work,[0],[0]
"Like these, we lean on the fact that with a good representation of a state, it can be useful to memorize what to do in given situation (having only done it a small number of times) and explicitly look it up.",3. Related work,[0],[0]
"In our case, the “good representation” is informed by the user-specified attributes.
",3. Related work,[0],[0]
"Our approach is also related to (Machado et al., 2017), which builds up a multiscale representation of an MDP using Eigenvectors of the transition matrix of the MDP, in the sense that we collect data on possible transitions between attributes in a first phase of training, and then use this knowledge at test time.
",3. Related work,[0],[0]
"There is a large literature on using symbolic representations for planning, for example the STRIPS formalism (Fikes & Nilsson, 1971).",3. Related work,[0],[0]
"In (Konidaris et al., 2018), the authors propose a model that learns the symbols for a STRIPS-style representation.",3. Related work,[0],[0]
"Like in our work, their model learns the interface between the raw state observations and the planner.",3. Related work,[0],[0]
"However, in that work, the abstract structure is given by a set of pre-defined options with fixed policies.",3. Related work,[0],[0]
We perform experiments with the Attribute Planner (AP) in three environments.,4. Experiments,[0],[0]
"First, we consider a 3D block stacking environment.",4. Experiments,[0],[0]
"Here, we demonstrate that AP allows compositional generalization by training a low level policy on single-action tasks in a supervised fashion and showing that with the AP algorithm it can perform multi-step tasks at test time.
",4. Experiments,[0],[0]
"Second, we consider 2D grid worlds in Mazebase (Sukhbaatar et al., 2015), where we evaluate AP’s performance when the low-level policy is temporally extended and must be learned via RL.
",4. Experiments,[0],[0]
"Finally, we evaluate AP on a build order planning task in
Starcraft to see how AP scales to a more complex task that is of broader interest We further show that an exploratory policy over attributes allows the agent to explore attribute transitions where random search fails.
",4. Experiments,[0],[0]
Baselines:,4. Experiments,[0],[0]
"In all experiments, we compare against baseline policies trained with reinforcement learning.",4. Experiments,[0],[0]
"These baseline policies take the state and goal as inputs, and use the same neural network architecture as the policy used for the Attribute Planner.",4. Experiments,[0],[0]
We consider several training regimes for the baseline policies: (i) training only with nearby goals like AP; (ii) training on the multi-step evaluation tasks; and (iii) training on a curriculum that transitions from nearby goals to evaluation tasks.,4. Experiments,[0],[0]
"Policies (ii) and (iii) are trained on full sequences, thus have an inherent advantage over our model.
",4. Experiments,[0],[0]
"In the block stacking task, we further compare against a state-of-the-art algorithm for hierarchical RL: Option-Critic with deliberation cost (Harb et al., 2017), as well as an inverse model trained by supervised learning.",4. Experiments,[0],[0]
"We consider a 3D block stacking environment in Mujoco (Todorov et al., 2012).",4.1. Block Stacking,[0],[0]
"In this experiment, we train AP only on single-action trajectories and evaluate on multi-step tasks, in order to evaluate AP’s ability to generalize using planning.",4.1. Block Stacking,[0],[0]
"We compare AP with baselines trained on both single-action, multi-action, and curriculum tasks.
",4.1. Block Stacking,[0],[0]
"In this environment, there are 4 blocks of different colors, and actions consist of dropping a block in a 3 ⇥ 3 grid of positions, resulting in 36 total actions.",4.1. Block Stacking,[0],[0]
"A block cannot be moved when it is underneath another block, so some actions have no effect.
",4.1. Block Stacking,[0],[0]
"The input to the model is the observed image, and there are a total of 36 binary properties corresponding to the relative x and y positions of the blocks and whether blocks are stacked on one another.",4.1. Block Stacking,[0],[0]
"For example, one property corresponds to “blue is on top of yellow”.",4.1. Block Stacking,[0],[0]
"Each training episode is initiated from a random initial state and lasts only one step, i.e. dropping a single block in a new location.",4.1. Block Stacking,[0],[0]
"Further model and training details and results on a continuous variant of this environment are provided in Appendix B.
Table 1 compares the performance of different models on several block stacking tasks.",4.1. Block Stacking,[0],[0]
"In the multi-step task, the goal is chosen as the properties of a new random initialization.",4.1. Block Stacking,[0],[0]
These tasks typically require 3 8 steps to complete.,4.1. Block Stacking,[0],[0]
"In the 4-stack task, the goal is a vertical stack of blocks in the order red, green, blue, yellow.",4.1. Block Stacking,[0],[0]
"In the underspecified task, we consider a multi-step goal where only 70% of the attributes are provided at random.",4.1. Block Stacking,[0],[0]
"The AP model handles these naturally by finding the shorted path to any satisfactory attribute set.
",4.1. Block Stacking,[0],[0]
"The single-step reactive policies perform similarly to AP when evaluated on the single-step tasks it sees during training (see Table 5 in the Appendix), but perform poorly when transferred to multi-step tasks, while AP generalizes well to complex task.",4.1. Block Stacking,[0],[0]
"The AP model also solves underspecified tasks even though they are not seen explicitly during training.
",4.1. Block Stacking,[0],[0]
The attribute detector f̂ predicts the full attribute set with < 0.1% error when trained on the full dataset of 1 million examples.,4.1. Block Stacking,[0],[0]
"If trained on only 10,000 examples, the attribute detector has an error rate of 1.4%.",4.1. Block Stacking,[0],[0]
"Training the AP model with this less-accurate attribute detector degrades multi-step performance by only 0.9%.
",4.1. Block Stacking,[0],[0]
"We also consider a variant of the block stacking task with a continuous action space, in which an action consists of dropping a block at any x-y position.",4.1. Block Stacking,[0],[0]
"While performance degrades substantially for all models in the continuous action space, AP continues to outperform reactive policies on multi-step tasks.",4.1. Block Stacking,[0],[0]
"See Appendix B for the full results.
",4.1. Block Stacking,[0],[0]
Property Aliasing: The “ignorability” assumption we made in Section 2 is violated in the block stacking task.,4.1. Block Stacking,[0],[0]
"To see why, consider a transition from “red left of blue and yellow” to “red right of blue and yellow”.",4.1. Block Stacking,[0],[0]
"This can typically be accomplished in one step, but if blue and yellow are already on the far right, it cannot.",4.1. Block Stacking,[0],[0]
"Thus, states where this transition are possible and impossible are aliased with the same properties.",4.1. Block Stacking,[0],[0]
"Table 2 shows that the performance is nearly perfect for individual transitions (1-step tasks), and the graph is well-connected after 1 million training examples, so the main source of error on these tasks is in fact
aliasing.",4.1. Block Stacking,[0],[0]
"Figure 3 shows an example plan that becomes stuck due to aliasing.
",4.1. Block Stacking,[0],[0]
The transition table c⇡ is important for mitigating the effects of aliasing in the block stacking task.,4.1. Block Stacking,[0],[0]
"The graph search finds the path with the highest probability of success (i.e. the product of probabilities on each edge), so it avoids edges that have high aliasing.",4.1. Block Stacking,[0],[0]
"In Table 1, we consider an ablation of c⇡ from the AP model, in which the probability of transitioning from an edge (⇢i, ⇢j) is estimated as the fraction of transitions from ⇢i that ended in ⇢j during the Explore phase.",4.1. Block Stacking,[0],[0]
This ablation performs substantially worse than the full AP model.,4.1. Block Stacking,[0],[0]
"We next consider tasks in which a multi-step low-level policy is required to transition between neighboring attributes.
",4.2. Grid Worlds,[0],[0]
"We consider two classes of small 2-D environments in Mazebase (Sukhbaatar et al., 2015), where the worlds are randomly generated for each episode.",4.2. Grid Worlds,[0],[0]
"The action space for each consists of movements in the four cardinal directions plus additional environment-specific actions.
",4.2. Grid Worlds,[0],[0]
"Colored Switches The first environment consists of four switches, each with four possible colors.",4.2. Grid Worlds,[0],[0]
An extra toggle action cycles the color of a switch if the agent is standing on it.,4.2. Grid Worlds,[0],[0]
"The attributes for this environment are the states of the switches and the tasks are to change the switches into
a specified configuration, as shown in Fig. 4(right).",4.2. Grid Worlds,[0],[0]
"The locations and colors of the switches are randomly initialized for each episode.
",4.2. Grid Worlds,[0],[0]
"Crafting In the second environment, similar to the one used in (Andreas et al., 2017), an agent needs to collect resources and combine them to form items.",4.2. Grid Worlds,[0],[0]
"In addition to moving in the cardinal directions, the agent has a “grab” action that allows it to pick up a resource from the current location and add it to its inventory.",4.2. Grid Worlds,[0],[0]
The agent also has a “craft” action that combines a set of items to create a new item if the agent has the prerequisite items in its inventory and the agent is standing on a special square (a “crafting table”) corresponding to the item to be crafted.,4.2. Grid Worlds,[0],[0]
"The attributes for this environment are the items in the inventory, and the task is to add a specified (crafted) item to the inventory.",4.2. Grid Worlds,[0],[0]
"In the environment, there are three types of resources and three types of products (see Fig. 4(left)).",4.2. Grid Worlds,[0],[0]
"The game always starts with three resources and an empty inventory.
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
Goal:
Crafting key:
Switch color gameCrafting game
Goal:
Figure 4.",4.2. Grid Worlds,[0],[0]
Left: Crafting mazebase game.,4.2. Grid Worlds,[0],[0]
Right: Colored switches game.,4.2. Grid Worlds,[0],[0]
"See text for details.
",4.2. Grid Worlds,[0],[0]
"In both environments, the agent’s observation consists of a bag of words, where the words correspond to (feature, location).",4.2. Grid Worlds,[0],[0]
"Features consist of item types, names, and their other properties.",4.2. Grid Worlds,[0],[0]
"The locations include position relative to the agent in the maze, and also a few special slots for inventory, current, and target attributes.
",4.2. Grid Worlds,[0],[0]
Training proceeds according to Algorithm 1.,4.2. Grid Worlds,[0],[0]
"During the explore phase, an exploratory policy is trained with reinforcement learning using a count-based reward proportional
to c⇡e(⇢i, ⇢j)P",4.2. Grid Worlds,[0],[0]
"i,j c⇡e(⇢i, ⇢j) + 0.001 !",4.2. Grid Worlds,[0],[0]
"0.5
for making a transition (⇢i, ⇢j), where c⇡e(⇢i, ⇢j) is the number of times transition (⇢i, ⇢j) has been seen so far.",4.2. Grid Worlds,[0],[0]
"We discuss this exploration bonus in Appendix A.
During the final phase of training we simultaneously compute ⇡ and c⇡ , so we use an exponentially decaying average of the success rate of ⇡ to deal with it’s nonstationarity:
c⇡(⇢i, ⇢j) =
PT t=1
T tSt⇡(⇢i, ⇢j)PT t=1 T tAt⇡(⇢i, ⇢j) ,
where T is the number of training epochs, At⇡ is the number of attempted transitions (⇢i, ⇢j) during epoch t, and St⇡ is the number of successful transitions.",4.2. Grid Worlds,[0],[0]
A decay rate of = 0.9 is used.,4.2. Grid Worlds,[0],[0]
"More details of the model and training are provided in Appendix C.
In the switches environment, multi-step test tasks are generated by setting a random attribute as target, which can require up to 12 attribute transitions.",4.2. Grid Worlds,[0],[0]
"In the crafting environment, test tasks are generated by randomly selecting a (crafted) item as a target.",4.2. Grid Worlds,[0],[0]
"Since we do not care about other items in the inventory, the target state is underspecified.
",4.2. Grid Worlds,[0],[0]
We produce a curriculum baseline by gradually increase the upper bound on the difficulty of tasks during training.,4.2. Grid Worlds,[0],[0]
"In the switches environment, the difficulty corresponds to the number of toggles necessary for solving the task.",4.2. Grid Worlds,[0],[0]
"The craft environment has two levels of difficulty: tasks can be completed by a single grab or craft action, and tasks that require multiple such actions.
",4.2. Grid Worlds,[0],[0]
Table 3 compares our Attribute Planner (AP) to a reinforcement learning baseline on the mazebase tasks.,4.2. Grid Worlds,[0],[0]
"The AP planning outperforms purely reactive training regardless of whether one-step, multi-step, or a curriculum of training examples is provided.",4.2. Grid Worlds,[0],[0]
"Finally, we test our approach for planning a build order in StarCraft: Brood War (Synnaeve et al., 2016).",4.3. StarCraft,[0],[0]
"We consider the space of tasks of building particular units in a fixed time of 500 steps, e.g. “build 1 barracks and 2 marines“.
",4.3. StarCraft,[0],[0]
"This task is challenging for RL because the agent must complete a number of distinct steps, e.g. mine enough ore, then build a barracks, and finally train marines using the barracks, before receiving a reward.",4.3. StarCraft,[0],[0]
Each of these steps requires the agent have to control multiple units of different types using low-level actions similar to how a human plays the game.,4.3. StarCraft,[0],[0]
"See Appendix D for more details.
",4.3. StarCraft,[0],[0]
"As in (Sukhbaatar et al., 2017), we restrict the game to the Terran race and only allow construction of certain units.",4.3. StarCraft,[0],[0]
"In the small version, the agent can mine ore and build SCVs, supply depots, barracks, and marines.",4.3. StarCraft,[0],[0]
"In the large version, an engineering bay and missile turrets are included as well.",4.3. StarCraft,[0],[0]
"The attributes are chosen to be the number of units and resources of each type, specifically
{min(bNore/25c, 40), NSCV , Ndepot, Nbarracks, Nmarine}
where Nx is the number of x present in the game, including units under construction.",4.3. StarCraft,[0],[0]
"The large version also include {Neng.bay, Nturrets}.
",4.3. StarCraft,[0],[0]
Models are trained for a total of 30 million steps.,4.3. StarCraft,[0],[0]
AP uses 16 million steps for exploration and 14 million steps for training ⇡.,4.3. StarCraft,[0],[0]
"Table 4 shows the final performance of the AP model and reactive RL baselines on this task after 30 million steps of training.
",4.3. StarCraft,[0],[0]
"AP exploration finds 120,000 and 420,000 edges for the small and large versions, respectively.",4.3. StarCraft,[0],[0]
The size and scaling of this graph show the limitations of a fully explicit graph.,4.3. StarCraft,[0],[0]
"In fact, we represent the ore attribute as bNore/25c because it decreases the size of the graph by a factor of 25: otherwise for each transition w.r.t.",4.3. StarCraft,[0],[0]
"the other attributes, the graph would have a separate edge for each valid value of total ore.
",4.3. StarCraft,[0],[0]
Count-based exploration over attributes is vital during the Explore phase in StarCraft.,4.3. StarCraft,[0],[0]
"If a random policy is used in the small version, only 2047 edges are discovered as opposed to 120,000 using count-based exploration, and the final performance is reduced from 31.7% to 6.4%.",4.3. StarCraft,[0],[0]
Our results show that structuring the space of tasks with high level attributes allows an agent to compose policies for simple tasks into solutions of more complex tasks.,5. Discussion,[0],[0]
"The agent plans a path to the final goal at the level of the attributes, and executes the steps in this path with a reactive policy.",5. Discussion,[0],[0]
"Thus, supervision of an agent by labeling attributes can lead to generalization from simple tasks at train time to more complex tasks at test time.",5. Discussion,[0],[0]
"There are several fronts for further work:
Sample complexity of the planning module: In Table 2 we can see both the benefits and the liabilities of the explicit non-parametric form for c⇡ .",5. Discussion,[0],[0]
"By 10K samples, the parametric lower level policy is already able to have a reasonable success rate.",5. Discussion,[0],[0]
"However, because in this environment, there are over 200K edges in the graph, most of the edges have not been seen, and without any weight-sharing, our model cannot estimate these transition probabilities.",5. Discussion,[0],[0]
"On the other hand, by 100K samples the model has seen enough of the graph to make nontrivial plans; and the non-parametric form of the graph makes planning straightforward.
",5. Discussion,[0],[0]
"In future work, we hope to combine parametric models for c⇡ with search to increase the sample efficiency of the planning module.",5. Discussion,[0],[0]
"Alternatively, we might hope to make progress on dynamic abstraction (projecting out some of the attributes) depending on the current state and goal, which would make the effective number of edges of the graph smaller.
",5. Discussion,[0],[0]
"Exploration We have shown that the attributes ⇢ and counts c⇡, in addition to their usefulness for planning, provide a framework for incentivizing exploration.",5. Discussion,[0],[0]
"In this work we considered a simple count-based exploration strategy, which achieved better exploration in attribute space than random exploration.",5. Discussion,[0],[0]
"However, this setting of pure exploration where there are no empirical rewards is different from the classic problem of exploration in an MDP, and warrants further exploration (see Appendix A).
",5. Discussion,[0],[0]
Learning the attributes: Discovering the attributes automatically would remove much of the need for human supervision.,5. Discussion,[0],[0]
"Recent work, such as (Thomas et al., 2017), demonstrates how this could be done.",5. Discussion,[0],[0]
"Another avenue for discovering attributes is to use a few “seed” attributes, which is necessary for task specification anyway, and use aliasing as a signal that some attributes need to be refined.",5. Discussion,[0],[0]
The tasks that an agent will need to solve often are not known during training.,abstractText,[0],[0]
"However, if the agent knows which properties of the environment are important then, after learning how its actions affect those properties, it may be able to use this knowledge to solve complex tasks without training specifically for them.",abstractText,[0],[0]
"Towards this end, we consider a setup in which an environment is augmented with a set of user defined attributes that parameterize the features of interest.",abstractText,[0],[0]
"We propose a method that learns a policy for transitioning between “nearby” sets of attributes, and maintains a graph of possible transitions.",abstractText,[0],[0]
"Given a task at test time that can be expressed in terms of a target set of attributes, and a current state, our model infers the attributes of the current state and searches over paths through attribute space to get a high level plan, and then uses its low level policy to execute the plan.",abstractText,[0],[0]
"We show in 3D block stacking, gridworld games, and StarCraft that our model is able to generalize to longer, more complex tasks at test time by composing simpler learned policies.",abstractText,[0],[0]
Composable Planning with Attributes,title,[0],[0]
"Clustering is one of the most widely used techniques in data analysis (Xu & Wunsch, 2005; Jain, 2010).",1. Introduction,[0],[0]
"Despite a rich literature on pure continuous data or pure categorical data, the clustering problem remains challenging for mixed-type data, i.e., data with both types of attributes (Everitt et al., 2001).",1. Introduction,[0],[0]
"Mixed-type data are ubiquitous in real world domains, e.g., social science, biomedicine and finance, where categorical attributes often describe demographic information or questionnaire responses, and continuous attributes often correspond to quantitative measurements.",1. Introduction,[0],[0]
"However, only a very limited number of clustering methods have been proposed for such data (Everitt et al., 2001; Huang, 1998).",1. Introduction,[0],[0]
"The major challenge is the lack of a good geometric intuition of data on the mixed-type domain;
1City University of New York (CUNY), New York, USA 2University of Sussex, Falmer, United Kingdom 3National Research University Higher School of Economics, Moscow, Russia 4Ohio State University, Columbus, USA.",1. Introduction,[0],[0]
"Correspondence to: Chao Chen <chao.chen.cchen@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"such intuition is the important basis of many successful geometric clustering methods, e.g., k-means (MacQueen et al., 1967), Ward’s method (Ward Jr, 1963), DBSCAN (Ester et al., 1996), to name a few.",1. Introduction,[0],[0]
"In practice, what usually being done is to convert mixed-type data to either pure continuous or pure categorical domain, and subsequently use existing geometric clustering methods.",1. Introduction,[0],[0]
"A metric for directly dealing with mixed-type data is also available, based on Gower’s coefficient (1971).",1. Introduction,[0],[0]
The uptake of geometric clustering methods is mostly driven by their lightweight computational requirements.,1. Introduction,[0],[0]
"However, these methods lack a well justified underlying probabilistic model, are sensitive to the choice of underlying metric, and do not give a principled answer to the fundamental question of required number of clusters for the data at hand.
",1. Introduction,[0.9999999452903363],"['However, these methods lack a well justified underlying probabilistic model, are sensitive to the choice of underlying metric, and do not give a principled answer to the fundamental question of required number of clusters for the data at hand.']"
"In this paper, we propose a probabilistic clustering method for mixed-type data, which admits at least four attractive properties.",1. Introduction,[0],[0]
"First, our probabilistic method goes beyond the widely-adopted class conditional independence assumption of feature variables, e.g., as in the latent class model (McCutcheon, 1987).",1. Introduction,[1.0],"['First, our probabilistic method goes beyond the widely-adopted class conditional independence assumption of feature variables, e.g., as in the latent class model (McCutcheon, 1987).']"
"Second, our method is based on the global topographical features, i.e., peaks and mountains, of the density function, rather than the distances between data points.",1. Introduction,[0],[0]
The argument for topographical features is to sidestep a premature specification of the metric space in which our mixed-type data will achieve the best grouping.,1. Introduction,[0],[0]
"Third, our method is able to utilize a persistent homology theory to automatically determine the number of clusters in the data.",1. Introduction,[0],[0]
"Fourth, the proposed method can be easily parallelized to achieve a competitive running time with respect to many lightweight geometric clustering methods.
",1. Introduction,[1.0000000095408983],"['Fourth, the proposed method can be easily parallelized to achieve a competitive running time with respect to many lightweight geometric clustering methods.']"
"From the modeling perspective, we compose tree graphical models with topographical features to achieve a probabilistic mixed-type clustering model.",1. Introduction,[0],[0]
Graphical models provide a way of factorizing a joint probability distribution into a product of local interactions.,1. Introduction,[0],[0]
These local interactions capture dependency among feature variables.,1. Introduction,[0],[0]
While a Bayesian network or a Markov random field can be built with a set of nodes representing each feature variable.,1. Introduction,[0],[0]
The graph structure and parameter estimation can be computationally expensive.,1. Introduction,[0],[0]
"By constraining the graph to be a tree, the structure and parameter can be learned efficiently.",1. Introduction,[0],[0]
"Other than computational benefits, tree-structured
graphical models also provide a modeling elegance; with a tree structure, we have a factorization that explicitly corresponds to empirical univariate and bivariate marginal distributions.",1. Introduction,[0],[0]
"For the bivariate distributions, we can then adapt the product kernel density estimation (Scott, 2015) to capture interaction between continuous-continuous variables, between categorical-categorical variables, and between categorical-continuous variables.
",1. Introduction,[0],[0]
"Having modeled the data generation process via a tree graphical model, we are left with finding a robust approach for assigning each data point to its cluster.",1. Introduction,[1.0],"['Having modeled the data generation process via a tree graphical model, we are left with finding a robust approach for assigning each data point to its cluster.']"
"To achieve this, we adopt a topological perspective, namely, we view a probability distribution as a terrain function, called the density landscape, and capture its topographical features as the basis for defining clusters.",1. Introduction,[0],[0]
The topographical features include modes (peaks) and their attractive basins.,1. Introduction,[0],[0]
"For high-dimension and sparse data, it is natural to have many modes.",1. Introduction,[0],[0]
"To avoid over-segmentation of the data and generation of many clusters with only few members, we employ a persistent homology theory (Edelsbrunner & Harer, 2010) to measure the saliency of all modes and merge the trivial ones.",1. Introduction,[0],[0]
Our principled method for clustering mixed-type data respects the underlying topographical features of the density landscape and achieves competitive performance on real data.,1. Introduction,[0],[0]
Clustering has been extensively studied in machine learning and data mining.,1.1. Related Work,[0],[0]
Many comprehensive surveys have been produced detailing the landscape of clustering problems and models.,1.1. Related Work,[0],[0]
"Here we will review related work in the context of geometric versus probabilistic clustering methods for mixed-type data and clustering methods that rely on topographical features such as modes and their attractive basins.
",1.1. Related Work,[0],[0]
Geometric clustering methods A straightforward approach for mixed-type data clustering is to map them into either pure continuous or pure categorical domains before applying a standard clustering method.,1.1. Related Work,[0],[0]
"A metric based on Gower’s coefficient (Gower, 1971) has been proposed for mixed-type data, which rescales the difference in all dimensions, continuous or categorical, and take the average.",1.1. Related Work,[0],[0]
One can apply any distance based method using these metrics.,1.1. Related Work,[0],[0]
"However, all these methods are heuristic; there is no good justification for the underlying geometric intuition of these methods on such a counter-intuitive metric space, despite some successful stories in practice.",1.1. Related Work,[0],[0]
"For example, K-Prototypes algorithm (Huang, 1998) uses a weighted sum of the Euclidean distance and Hamming distance and adopts the K-Means method (Faber, 1994), which iteratively finds the mean of each cluster and re-associates data to different clusters.",1.1. Related Work,[0],[0]
"When the data is pure categorical, the method is called K-Modes (Huang, 1997).",1.1. Related Work,[0],[0]
"Chiu et al. (2001) proposed a hierarchical clustering method, in
which distance between clusters are measured using their log-likelihood, which treat continuous and categorical domain separately.
",1.1. Related Work,[0],[0]
Probabilistic clustering methods Graphical models have been applied to clustering before.,1.1. Related Work,[0],[0]
"Zhang (2004) proposed a latent tree model, i.e., a Bayesian tree whose leaf nodes correspond to all observed dimensions and internal nodes are latent variables determining different clusters.",1.1. Related Work,[0],[0]
"Such tree structure can be learned using efficient algorithms (Chen et al., 2012; Liu et al., 2015).",1.1. Related Work,[0],[0]
"However, this method is only restricted to categorical data.",1.1. Related Work,[0],[0]
Lee & Hastie (2015) proposed a loopy graphical model to model mixed-type data.,1.1. Related Work,[0],[0]
"Their model reduces to a discrete Markov random field when all attributes are categorical, and a Gaussian graphical model when all attributes are continuous.",1.1. Related Work,[0],[0]
"Parameters are learned using pseudo-likelihood estimation (Besag, 1975) and edges are selected using group sparsity penalties (Yuan & Lin, 2006; Huang & Zhang, 2010).",1.1. Related Work,[0],[0]
"However, an efficient inference model is missing in order to apply such model to clustering.
",1.1. Related Work,[0],[0]
Clustering by mode-seeking The density landscape has been exploited before to extract global properties of the data and to achieve better clustering quality.,1.1. Related Work,[0],[0]
"Mode-seeking methods, i.e., associating data to modes representing clusters, have been proposed before in continuous domain (Cheng, 1995; Comaniciu & Meer, 2002b).",1.1. Related Work,[0],[0]
"But such methods rely on a kernel density estimation, which suffers from the curse of dimensionality and thus do not scale to high dimensions (Wasserman, 2013, chap. 20).",1.1. Related Work,[0],[0]
Chen & Quadrianto (2016) proposed a mode-seeking method for categorical data clustering.,1.1. Related Work,[0],[0]
"However, their method tends to produce trivial modes/clusters and thus over-segments the data, mainly due to the lack a principled way to merge modes into clusters of proper size.
",1.1. Related Work,[0],[0]
"Persistent homology for merging clusters In recent years, novel approaches have been proposed to merge modes/clusters based on the topographical landscape of the density function.",1.1. Related Work,[0],[0]
Chazal et al. (2013) used topological persistence to guide the merging of data into clusters.,1.1. Related Work,[0],[0]
"Their method, although theoretically sound, relies on a k-nearest neighbor graph of the data and a given density function, e.g., a kernel density estimation (Silverman, 1986) or a distance from measure (Chazal et al., 2011).",1.1. Related Work,[0],[0]
This method assumes that the data is a high quality sample of the domain and the k-nearest neighbor graph faithfully captures the topographical characteristics of the distribution.,1.1. Related Work,[0],[0]
"However, this condition is often too strong to assume in practice, where most datasets are relatively sparse.",1.1. Related Work,[0],[0]
"In this paper, we propose to start with mode-seeking, and leverage these modes and the gradient paths as a more accurate account of the density landscape.",1.1. Related Work,[0],[0]
Our idea proves to be a better solution and a good complement to the theoretical tool.,1.1. Related Work,[0],[0]
"We also refer to other topological and geometrical studies into the
global structures of hierarchical clustering (Eldridge et al., 2015; Carlsson & Mémoli, 2010).",1.1. Related Work,[0],[0]
"A probabilistic graphical model (Koller & Friedman, 2009) consists of a set of inter-dependent random variables X = (X1, . . .",2. Background,[0.992651890049033],"['A probabilistic graphical model (Koller & Friedman, 2009) consists of a set of inter-dependent random variables X = (X1, .']"
", XD), a potential function f , and a graph G = (V, E).",2. Background,[0],[0]
Each element in the node set V represents one random variable from X .,2. Background,[0],[0]
The edges represents the dependence relations between pairs of variables.,2. Background,[1.0],['The edges represents the dependence relations between pairs of variables.']
There are two different kinds of variables in our setting: continuous ones and discrete ones variables.,2. Background,[0],[0]
"For simplification, we assume each discrete variable takes discrete values Xi ∈ L = {1, . . .",2. Background,[0],[0]
", L}.",2. Background,[0],[0]
"In this paper, we use discrete and categorical interchangeably and focus on non-ordinal discrete variables, although ordinal discrete variables are of interest in practice as well.",2. Background,[1.0],"['In this paper, we use discrete and categorical interchangeably and focus on non-ordinal discrete variables, although ordinal discrete variables are of interest in practice as well.']"
"In our setting, only Hamming distance can be used for discrete variables.
",2. Background,[0],[0]
"A value assignment to all random variables x = (x1, . . .",2. Background,[0],[0]
", xD) is called a configuration.",2. Background,[0],[0]
"A potential function f : x → R assigns to each configuration a real value, which is inversely proportional to the logarithm of the probability distribution, p(x) = exp(−f(x)",2. Background,[0],[0]
"− A), where A is the log-partition function.",2. Background,[0],[0]
"In this paper, we focus on tree structured graphical models, represented by T = (V, E).",2. Background,[0],[0]
"For a tree model, the probability and potential of a configuration can be factorized into a product (Bach & Jordan, 2003):
p(x) = ∏
(i,j)∈E
p(xi, xj)
p(xi)p(xj)",2. Background,[0],[0]
"∏ k∈V p(xk), (2.1)
where p(xi, xj) is the bivariate marginal density of the variable Xi and Xj , and p(xk) is the univariate marginal density of the variable Xk.
",2. Background,[0],[0]
"When the true distribution can be represented by a tree, we can use the algorithm by Chow & Liu (1968) to reconstruct the tree model.",2. Background,[0],[0]
"First, we compute the mutual information between all pairs of variables:
MIij = ∫ xi,xj p(xi, xj) log p(xi, xj) p(xi)p(xj)",2. Background,[0],[0]
"dxidxj ,
using empirical univariate and bivariate marginals.",2. Background,[0],[0]
The integral is replaced by sum when Xi and Xj have discrete values.,2. Background,[0],[0]
"Next, we compute the maximum spanning tree of a complete graph with D nodes, using the mutual information as edge weights.",2. Background,[0],[0]
"The computed tree is the desired tree model with the optimal KL-divergence from the true tree distribution (Liu et al., 2011).",2. Background,[0],[0]
More details of the selection of the models for univariate and bivariate densities will be given in Section 3.,2. Background,[0],[0]
Our method first estimates the underlying probabilistic density function from given data.,3. Method,[0],[0]
We choose tree-models as they strike a elegant balance between computational efficiency and flexibility of the model.,3. Method,[1.0],['We choose tree-models as they strike a elegant balance between computational efficiency and flexibility of the model.']
"Next, we propose to cluster data based on the density landscape: associating data with modes/peaks of the density, and merge them based on advanced persistent homology theory.",3. Method,[0],[0]
"First, we formalize the definition of modes in the mixed-type domain.",3. Method,[0],[0]
"Then we present algorithms for modes-seeking (Section 3.2) and for modes-merging (Section 3.3).
",3. Method,[0],[0]
We first formalize what a mode is in a D-dimensional mixed-type data domain.,3. Method,[0],[0]
Our definition is not restricted to the underlying model.,3. Method,[0],[0]
Denote by Id and Ic the index sets of discrete- and continuous-valued random variables.,3. Method,[0],[0]
"Denote by distH(x, x′) the Hamming distance between x and x′ within the discrete dimensions, and distL2(x, x′) the L2 distance within the continuous dimensions.",3. Method,[0],[0]
We call a discrete neighborhood of x with radius δ > 0,3. Method,[0],[0]
"as all elements with no more than δ Hamming distance and zero Euclidean distance from x, formally,
N dδ (x) = {x′ | distd(x, x′) ≤ δ ∧ distc(x, x′) = 0}.
",3. Method,[0],[0]
"Similarly, we define a continuous neighborhood of x with radius > 0",3. Method,[0],[0]
"as
N c (x) = {x′ | distd(x, x′) = 0 ∧ distc(x, x′) ≤ }.
",3. Method,[0],[0]
"Given a probability density function, p(X), a mode is a local maximum in both the continuous neighborhood and discrete neighborhood, formally: Definition 1 (Modes).",3. Method,[1.0],"['Given a probability density function, p(X), a mode is a local maximum in both the continuous neighborhood and discrete neighborhood, formally: Definition 1 (Modes).']"
A point x ∈ X is a mode if and only if there exists positive numbers > 0,3. Method,[0],[0]
and δ > 0 such that (1) p(x) ≥ p(x′) for any x′ ∈ N c (x); and (2) p(x) ≥ p(x′) for any x′ ∈ N dδ,3. Method,[0],[0]
(x).,3. Method,[0],[0]
"It suffices to use the smallest positive integer for the discrete neighborhood, δ = 1.",3. Method,[0],[0]
"In this paper, we focus on a tree-structured graphical model.",3. Method,[0],[0]
"Next, we describe our tree model in details within the mixed-type setting.",3. Method,[0],[0]
"We formalize the univariate and bivariate marginal densities p(xi) and p(xi, xj) in the tree model (Eq. (2.1)).",3.1. Instantiating the Tree Model,[0],[0]
"We assume a set of N data {y1, y2, · · · , yN} is given.",3.1. Instantiating the Tree Model,[0],[0]
"For discrete dimensions, we use Multinoulli distribution with Dirichlet prior α = 1, ∀i, j ∈",3.1. Instantiating the Tree Model,[0],[0]
"Id:
p(xi) = Nxi + 1
N + L , with Nxi = N∑ n=1 Jyni = xiK,
p(xi, xj) = Nxi,xj + 1
N + L2 ,
with Nxi,xj = N∑ n=1 Jyni = xi ∧ ynj = xjK.
For continuous variables, we use one-dimensional kernel density estimation for univariate density, and product kernel (Scott, 2015) for univariate and bivariate marginal density.",3.1. Instantiating the Tree Model,[0],[0]
"Formally, ∀i, j ∈ Ic,
p(xi) = 1
N N∑ n=1 Kh1i(y n",3.1. Instantiating the Tree Model,[0],[0]
i,3.1. Instantiating the Tree Model,[0],[0]
"− xi), and
",3.1. Instantiating the Tree Model,[0],[0]
"p(xi, xj) = 1
N N∑ n=1",3.1. Instantiating the Tree Model,[0],[0]
{,3.1. Instantiating the Tree Model,[0],[0]
Kh2i(y n,3.1. Instantiating the Tree Model,[0],[0]
i,3.1. Instantiating the Tree Model,[0],[0]
"− xi)Kh2j (ynj − xj) } ,
(3.1)
We use a one-dimensional Gaussian kernel, denoted as Kh(z) =
1√ 2πh
exp ( − z 2
2h2
) .",3.1. Instantiating the Tree Model,[0],[0]
"Following standard non-
parametric statistics literature (Fan & Gijbels, 1996; Tsybakov, 2009), the kernel bandwidths for univariate and bivariate density are chosen as
hti = 1.06·min { σ∗i , q∗i,0.75 − q∗i,0.25 1.34 } ·N− 1 2β+t , t = 1, 2,
where σ∗i , q ∗ i,0.75 and q ∗ i,0.25 are the standard deviation, the 75% and 25% sample quantiles of Xi, respectively.",3.1. Instantiating the Tree Model,[0],[0]
"The variable β is the order of the kernel (Fan & Gijbels, 1996) and is set to 2 by default.
",3.1. Instantiating the Tree Model,[0],[0]
The choice of a product kernel is justified by two reasons.,3.1. Instantiating the Tree Model,[0],[0]
"First, a product kernel reduces to the product of onedimensional kernels, which are more reliable that a direct 2D kernel density estimation.",3.1. Instantiating the Tree Model,[0],[0]
"Second, the product kernel proves to be convenient to be adopt to bivariate densities for variables with mixed-type as follows.",3.1. Instantiating the Tree Model,[0],[0]
"For a mixed-type pair of variables, (Xi, Xj), i ∈ Ic, j ∈",3.1. Instantiating the Tree Model,[0],[0]
"Id, we take the limit of h2i to zero in the product kernel formula (Equation (3.1)).",3.1. Instantiating the Tree Model,[0],[0]
"The first kernel becomes the Dirac-delta function, leading to the following bivariate marginal
p(xi, xj) = 1
N N∑ n=1",3.1. Instantiating the Tree Model,[0],[0]
{,3.1. Instantiating the Tree Model,[0],[0]
Jynj = xjKKh2i(yni,3.1. Instantiating the Tree Model,[0],[0]
"− xi) } .
",3.1. Instantiating the Tree Model,[0],[0]
Building the tree model.,3.1. Instantiating the Tree Model,[0],[0]
"Using these empirical univariate and bivariate marginal densities, we estimate all pairwise mutual information, and then compute the tree (V, E) using the Chow-Liu algorithm.",3.1. Instantiating the Tree Model,[0],[0]
Plugging the univariate and bivariate marginal densities into Eq.,3.1. Instantiating the Tree Model,[0],[0]
"(2.1), we have the complete density distribution (the tree model).",3.1. Instantiating the Tree Model,[0],[0]
"Next, we present our algorithm for finding the modes over the density landscape of the computed model.",3.1. Instantiating the Tree Model,[0],[0]
Our algorithm assigns each data to a mode via a gradient ascent procedure.,3.2. Mode-Seeking Algorithm,[0],[0]
"For a mixed-domain, a gradient is not well defined.",3.2. Mode-Seeking Algorithm,[0],[0]
"Following the definition of modes (Def. 1), we formulate a gradient step as an optimization within either the continuous neighborhood N c (x) or the discrete
neighborhood N dδ (x), with δ = 1.",3.2. Mode-Seeking Algorithm,[0],[0]
"The two procedures have to be taken alternatively in order to continue increasing the probability until a mode is reached.
",3.2. Mode-Seeking Algorithm,[0],[0]
"Our algorithm starts at each data, s, iteratively walks to a nearby point with bigger probability until convergence.",3.2. Mode-Seeking Algorithm,[0],[0]
"The final position is the mode of interest and will be associated with the data, s. For ease of computation, we use the potential function f(x) instead of the probability density function:
f(x) =",3.2. Mode-Seeking Algorithm,[0],[0]
"− ∑
(i,j)∈E log p(xi, xj)− ∑ i∈V (1− di) log p(xi),
(3.2) in which di is the degree of node i in the tree.",3.2. Mode-Seeking Algorithm,[0],[0]
It is easy to verify that p(x) ∝ −f(x).,3.2. Mode-Seeking Algorithm,[0],[0]
"Therefore, modes of p(x) are the local minima of f(x), following the same definition in Def. 1.",3.2. Mode-Seeking Algorithm,[0],[0]
"We follow the aforementioned iterative procedure, except at each step, we find a nearby point with smaller potential.
",3.2. Mode-Seeking Algorithm,[0],[0]
"At each step of the algorithm, we first update all discrete variables until no better elements exist within the discrete neighborhood N dδ",3.2. Mode-Seeking Algorithm,[0],[0]
(x),3.2. Mode-Seeking Algorithm,[0],[0]
with δ = 1.,3.2. Mode-Seeking Algorithm,[0],[0]
"Next, we update all continuous variables using gradient descent, until the gradient of f at continuous dimensions∇cf becomes zero.",3.2. Mode-Seeking Algorithm,[1.0],"['Next, we update all continuous variables using gradient descent, until the gradient of f at continuous dimensions∇cf becomes zero.']"
"Our main algorithm is summarized in Alg. 1.
",3.2. Mode-Seeking Algorithm,[0],[0]
Algorithm 1 Mode-Seeking Algorithm 1,3.2. Mode-Seeking Algorithm,[0],[0]
": Input: Data D = {si | i = 1, · · · , N}; a potential
function f .",3.2. Mode-Seeking Algorithm,[0],[0]
"2: Output: A set of modes,M; mode indices associated
to each data {ci | i = 1, · · · , N} 3: M← ∅ 4: for i = 1 to N do 5: x← si 6: repeat 7: repeat 8: x← argminz∈Nd1 (x) f(z) 9: until x converges
10: repeat 11: x← x− η∇cf 12: until x converges 13: until x converges 14: if x /∈M then 15: M←M∪ {x} 16: end if 17: ci ← the index of x inM 18: end for
Here η is the stepsize.",3.2. Mode-Seeking Algorithm,[0],[0]
"The best neighbor within Hamming distance one, argminz∈Nd1 (x) f(z), can be computed using dynamic programming.",3.2. Mode-Seeking Algorithm,[1.0],"['The best neighbor within Hamming distance one, argminz∈Nd1 (x) f(z), can be computed using dynamic programming.']"
"This can be achieved by directly adapting the algorithm by (Chen & Quadrianto, 2016).
",3.2. Mode-Seeking Algorithm,[0],[0]
"It remains to compute the gradient of f in the contin-
uous domain, ∇cf .",3.2. Mode-Seeking Algorithm,[0.9999999422974657],"['It remains to compute the gradient of f in the contin- uous domain, ∇cf .']"
For each continuous variable,3.2. Mode-Seeking Algorithm,[0],[0]
"i ∈ Ic, relevant terms in the energy function (Eq. (3.2)) can be divided into three groups, the univariate term, the bivariate terms with a continuous neighbor, j ∈ Ic, and the bivariate terms with a discrete neighbor, j ∈ Id. Treating them differently, the partial derivative:
∂f(x)
∂xi = −(1− di)
∑N n=1 Kh1i(y n",3.2. Mode-Seeking Algorithm,[0],[0]
"i − xi)
yni",3.2. Mode-Seeking Algorithm,[0],[0]
"−xi h21i∑N
n=1 Kh1i(y n",3.2. Mode-Seeking Algorithm,[0],[0]
i,3.2. Mode-Seeking Algorithm,[0],[0]
"− xi)
",3.2. Mode-Seeking Algorithm,[0],[0]
"− ∑
j∈Ic:(i,j)∈E
∑N n=1 Kh2i(y n",3.2. Mode-Seeking Algorithm,[0],[0]
i,3.2. Mode-Seeking Algorithm,[0],[0]
"− xi)Kh2j (ynj − xj)
",3.2. Mode-Seeking Algorithm,[0],[0]
yni,3.2. Mode-Seeking Algorithm,[0],[0]
"−xi h22i∑N
n=1 Kh2i(y n i",3.2. Mode-Seeking Algorithm,[0],[0]
"− xi)Kh2j (ynj − xj)
",3.2. Mode-Seeking Algorithm,[0],[0]
"− ∑
k∈Id:(i,j)∈E
∑N n=1 Kh2i(y n",3.2. Mode-Seeking Algorithm,[0],[0]
i,3.2. Mode-Seeking Algorithm,[0],[0]
"− xi)Jynk = xkK
yni",3.2. Mode-Seeking Algorithm,[0],[0]
"−xi h22i∑N
n=1 Kh2i(y n i − xi)
(3.3)
",3.2. Mode-Seeking Algorithm,[0],[0]
"Algorithm 2 Merging Data Using Topological Persistence
1: Input: Ĝ = (V̂, Ê), density function p : V̂ → R+, persistence threshold τ 2: Output: Clusters C 3: C ← ∅ 4: Sort elements in V̂ according to the density function
values, so that p(vi) ≥ p(vi+1), ∀vi, vi+1 ∈ V̂ .",3.2. Mode-Seeking Algorithm,[0],[0]
"5: for i = 1 to |V̂| do 6: nbd← {vj | (vi, vj) ∈ Ê ∧ j < i} 7: // neighbors of vi with smaller indices (bigger p) 8: if nbd = ∅",3.2. Mode-Seeking Algorithm,[0],[0]
"then 9: create a new cluster c = {vi}
10: birth(c)← p(vi) 11: C ← C ∪ {c} 12: else 13:",3.2. Mode-Seeking Algorithm,[0],[0]
Cnbd ← all clusters containing nodes in nbd 14: cmax ← argmaxc∈Cnbd birth(c) 15: for all c ∈ Cnbd and c 6= cmax do 16: persistence(c)← birth(c)− p(vi) 17: if persistence(c) < τ,3.2. Mode-Seeking Algorithm,[0],[0]
then 18: // merge c into cmax 19: cmax ← cmax ∪ c 20: C ← C\{c} 21: end if 22: end for 23: // assign vi to cmax 24: cmax ← cmax ∪ {vi} 25: end if 26: end for,3.2. Mode-Seeking Algorithm,[0],[0]
The modes computed in Alg. 1 provide a clustering of the data.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"However, in practice, the data is often relatively sparse.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"In such cases, the method tends to produce a large
number of modes, and thus over-segments the data into small clusters.",3.3. Merging Clusters Using Topological Persistence,[0.9999999771676027],"['In such cases, the method tends to produce a large number of modes, and thus over-segments the data into small clusters.']"
"There are ways to merge these small clusters (Ward Jr, 1963; Day & Edelsbrunner, 1984).",3.3. Merging Clusters Using Topological Persistence,[0],[0]
But they rely on a distance metric to measure similarities between clusters.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"Instead, we propose a principled approach that is only based on the density landscape, i.e., the topographical features such as peaks, ridges, valleys.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
Our method is built on the theory of persistent homology.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"We focus on zerodimensional topological structures in this paper, although the theory is much more general.
",3.3. Merging Clusters Using Topological Persistence,[0.9999999770866506],"['We focus on zerodimensional topological structures in this paper, although the theory is much more general.']"
Persistence of modes.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"We estimate the saliency of a peak (mode) using its “relative height”, namely, the difference between its height and the level at which its basin of attraction meets the one of another higher mode.",3.3. Merging Clusters Using Topological Persistence,[1.0],"['We estimate the saliency of a peak (mode) using its “relative height”, namely, the difference between its height and the level at which its basin of attraction meets the one of another higher mode.']"
"Formally, we filter the domain using a function value threshold t from +∞ to −∞. As t decreases, we monitor the topological changes of the progressively growing superlevel set, X t = {x ∈ X | p(x) ≥ t}, that is, the domain whose probability density value is no smaller than t. Each mode attributes to the birth of a new connected component in the superlevel set and the component is killed when it meets another component created by a higher mode.",3.3. Merging Clusters Using Topological Persistence,[0.9950531326207063],"['As t decreases, we monitor the topological changes of the progressively growing superlevel set, X t = {x ∈ X | p(x) ≥ t}, that is, the domain whose probability density value is no smaller than t. Each mode attributes to the birth of a new connected component in the superlevel set and the component is killed when it meets another component created by a higher mode.']"
"The density value of the creating mode and the density value of the point at which the two components meet (called a saddle) are called the birth and death times, and their difference, called the persistence, measures the saliency of this mode.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"See Figure 1 for an illustration.
",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"The merging of connected components as we decrease the threshold t provides a natural way to merge modes; when two connected components meet, we merge them if one of them has≤ τ",3.3. Merging Clusters Using Topological Persistence,[0],[0]
persistence (Figure 1).,3.3. Merging Clusters Using Topological Persistence,[0],[0]
This gives us a principled way to merge modes.,3.3. Merging Clusters Using Topological Persistence,[1.0],['This gives us a principled way to merge modes.']
"Based on the convergence of tree-model estimation (Liu et al., 2011) and the stability
of persistent homology (Cohen-Steiner et al., 2007), this method is guaranteed to be robust to noise and L∞ perturbation of the density function.
",3.3. Merging Clusters Using Topological Persistence,[0],[0]
Sample-based persistence computation.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"Given a dense uniform sampling of the whole domain X , we can trust these samples will describe the density landscape faithfully.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"In practice, however, a uniform sampling will have exponential size to the dimension.",3.3. Merging Clusters Using Topological Persistence,[1.0],"['In practice, however, a uniform sampling will have exponential size to the dimension.']"
"Chazal et al. (2013) used the k-nearest neighbor graph of the input data, D, assuming they are good samples from the density function.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"However, in practice, the data is often relatively sparse and cannot represent the landscape well enough to produce a high quality mode-merging hierarchy.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"In fact, it is very likely that the modes are not included in the data and thus the birth time (as well as the persistence) will be under-estimated.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"See Figure 2(left) for an illustration.
",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"In this paper, we propose to compute persistence based on all points we encountered during the mode-seeking procedure.",3.3. Merging Clusters Using Topological Persistence,[1.0],"['In this paper, we propose to compute persistence based on all points we encountered during the mode-seeking procedure.']"
"In Algorithm 1, we collect the point x computed after each iteration (after line 12).",3.3. Merging Clusters Using Topological Persistence,[0],[0]
The gradient step also provides a natural edge connecting these points.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
This tree structured graph give us a high-quality description of the attractive basin of each mode.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
This provides us a well-suited underlying graph describing the density landscape.,3.3. Merging Clusters Using Topological Persistence,[1.0],['This provides us a well-suited underlying graph describing the density landscape.']
See Figure 2(right).,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"Finally, to ensure the graph is fully connected, and the space between modes are well described, we add edges (green edges) connecting points from neighboring attractive basins, as well as the lowest point along these edges (green markers).",3.3. Merging Clusters Using Topological Persistence,[1.0],"['Finally, to ensure the graph is fully connected, and the space between modes are well described, we add edges (green edges) connecting points from neighboring attractive basins, as well as the lowest point along these edges (green markers).']"
Note that this is the only time when the distance metric plays a role in our model.,3.3. Merging Clusters Using Topological Persistence,[1.0],['Note that this is the only time when the distance metric plays a role in our model.']
"We use a sum of the Hamming distance and Euclidean distance.
Algorithm.",3.3. Merging Clusters Using Topological Persistence,[0.9940359150766261],['We use a sum of the Hamming distance and Euclidean distance.']
"Given a graph Ĝ = (V̂, Ê), in which each node is assigned a probability density, we compute the persistence-based merge tree as follows.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
Sort all nodes in decreasing order of their density function values.,3.3. Merging Clusters Using Topological Persistence,[1.0],['Sort all nodes in decreasing order of their density function values.']
Add them into the superlevel set one-by-one.,3.3. Merging Clusters Using Topological Persistence,[1.0],['Add them into the superlevel set one-by-one.']
"To add a node vi, we check whether it is adjacent to any nodes that have been included.",3.3. Merging Clusters Using Topological Persistence,[1.0],"['To add a node vi, we check whether it is adjacent to any nodes that have been included.']"
"If not, vi, which must be a mode itself, creates a new connected component with the birth time p(vi).",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"If vi is connected to multiple existing connected components, we keep the one with the earliest birth time, cmax, and merge some others into cmax.",3.3. Merging Clusters Using Topological Persistence,[1.0],"['If vi is connected to multiple existing connected components, we keep the one with the earliest birth time, cmax, and merge some others into cmax.']"
"In particular, for each other adjacent connected component, we check whether its life length so far is less than τ .",3.3. Merging Clusters Using Topological Persistence,[0],[0]
The ones with ≤ τ,3.3. Merging Clusters Using Topological Persistence,[0],[0]
life length will be merged into cmax.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
We add vi into,3.3. Merging Clusters Using Topological Persistence,[0],[0]
the connected component cmax See Figure 3 for an illustration.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
See Alg. 2 for the pseudocode.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"We compare our methods with existing clustering methods on several real world mixed-type datasets from UCI repository (Lichman, 2013): Contraceptive Method Choice dataset (CMC), Credit Approval dataset (CRX),
German Credit Approval (German), and Statlog Heart Disease dataset (Heart).",4. Experiments,[0],[0]
See the table below for more details.,4. Experiments,[0],[0]
"All datasets have 60% to 70% of the features being discrete.
",4. Experiments,[0],[0]
Table 1.,4. Experiments,[0],[0]
"Datasets
Data # of samples Dimension # of clusters CMC 1473 9 3 Heart 297 13 5 CRX 653 15 2
German 1000 20 2",4. Experiments,[0],[0]
Our method can be straightforwardly parallelized.,4. Experiments,[0],[0]
We run the mode-seeking for all data points (the for-loop in Alg. 1) in parallel.,4. Experiments,[0],[0]
"On average, the mode-seeking of a single data takes 6 gradient ascent steps and 5.87 seconds.",4. Experiments,[0],[0]
"On a cluster with 48 cores, our program finishes within 3 minutes for any of the datasets.",4. Experiments,[0],[0]
"If running in a sequential manner, the time will be linear to the dataset size.",4. Experiments,[0],[0]
"After all data are processed, we collect all relevant points and run a persistence-based merging sequentially.",4. Experiments,[0],[0]
This step takes less than 20 seconds for any of the datasets.,4. Experiments,[0],[0]
The persistence-based merging depends on a threshold τ .,4. Experiments,[0],[0]
It is hard to select a universal one due to the large variation among datasets.,4. Experiments,[0],[0]
"Instead, we choose the τ for each dataset so that the desired the nubmer of clusters remain after merging.",4. Experiments,[0],[0]
This is a fair comparison; all clustering methods we compare with use an oracle number of clusters.,4. Experiments,[0],[0]
We empirically set the parameter δ to one.,4. Experiments,[0],[0]
"Using a bigger δ hurts the performance as it would try to ‘smooth’ the landscape in the categorical domain.
",4. Experiments,[0],[0]
"All methods can be grouped into five different groups, based on the underlying domain and the approach.",4. Experiments,[0],[0]
The first group assumes a continuous domain and an Euclidean metric.,4. Experiments,[0],[0]
"We project the mixed-type data into the continuous domain and directly apply such methods, including k-means (Faber, 1994), Affinity Propagation (Frey & Dueck, 2007), Mean Shift (Cheng, 1995; Comaniciu & Meer, 2002a), Spectral Clustering (Kamvar et al., 2003), Ward’s algorithm (Ward Jr, 1963), Agglomerative clustering (Day & Edelsbrunner, 1984) and DBSCAN (Ester et al., 1996).
",4. Experiments,[0],[0]
"The second group are methods designed for pure categorical domain, e.g., K-Modes (Huang, 1997), ROCK (Guha et al., 1999), mixture of multinoulli (latent class analysis) (McCutcheon, 1987).",4. Experiments,[0],[0]
We convert mixed-type data into categorical data by thresholding continuous values at the median.,4. Experiments,[0],[0]
"We also include Affinity Propagation, Spectral Clustering and DBSCAN in this group; these methods can be applied to any distance metrics.",4. Experiments,[0],[0]
"We compute pairwise Hamming distance between data as the input of these three methods.
",4. Experiments,[0],[0]
"For the third group, we use these three methods, but using a distance matrix based on Gower’s coefficient (Gower, 1971), which was designed specifically for mixed-domain.",4. Experiments,[0],[0]
The fourth group uses a simply sum of the Euclidean distance (restricted to continuous dimensions) and Hamming distance (restricted to categorical dimensions).,4. Experiments,[0],[0]
"A good rep-
resentative in such group is K-Prototypes (Huang, 1998).",4. Experiments,[0],[0]
"We again applied the three methods (Affinity, Spectral and DBSCAN) on this new metric.
",4. Experiments,[0],[0]
"In the last group, we compare our method and a few other topological methods.",4. Experiments,[0],[0]
We compare to the method using only modes for clustering.,4. Experiments,[0],[0]
"This is essentially an adaptation of (Chen & Quadrianto, 2016) to the mixed-type domain.",4. Experiments,[0],[0]
"We also compare to (Chazal et al., 2013) by computing the persistence on the k-nearest neighbor graph, using our tree-model as the underlying density estimation.",4. Experiments,[0],[0]
"Finally, we also show the result of our method.
",4. Experiments,[0],[0]
The results are listed in Table 2.,4. Experiments,[0],[0]
"We use the Adjusted Mutual Information (AMI) (Vinh et al., 2010) and Adjusted Rand Score (ARS) (Hubert & Arabie, 1985) to evaluate all
methods.",4. Experiments,[0],[0]
"For all methods requiring random initializations, we run each one for 10 times and take the average performance.",4. Experiments,[0],[0]
"When necessary, we provide a true number of clusters as an oracle.",4. Experiments,[0],[0]
The cells with N/A correspond to the cases when the program crashes.,4. Experiments,[0],[0]
"It is most likely because the Gower’s coefficient and Hamming distance does not give us a well-conditioned distance matrix for the spectral clustering method.
",4. Experiments,[0],[0]
Discussion.,4. Experiments,[0],[0]
"Our method outperforms most methods from all other four groups, using different types of metrics.",4. Experiments,[0],[0]
We also observe that a few methods based on pure categorical domain are quite competitive.,4. Experiments,[0],[0]
"Similarly, K-prototype, a popular tool for mixed-type data, has good performance on some data.",4. Experiments,[0],[0]
"Outperforming other topological methods (modes only and persistence only) demonstrate the significance of our contribution.
",4. Experiments,[0],[0]
Our current experiments assume the correct number of clusters is given.,4. Experiments,[0],[0]
"It is possible to prove that with sufficient samples and the correct threshold τ , the persistence-based clustering can find the correct number of cluster and the right clustering for most data points in a sense similar to the elegant result in (Chazal et al., 2013).",4. Experiments,[0],[0]
"A closely related theoretical result is in (Eldridge et al., 2015), which shows that the hierarchical clustering tree constructed by a similar merging procedure is consistent for points sampled from a nice density distribution over RD.",4. Experiments,[0],[0]
"In this paper, we propose a probabilistic clustering method for mixed-type data.",5. Conclusions,[0],[0]
We design a tree-structured graphical model for the mixed-type domain.,5. Conclusions,[0],[0]
We also develop methods based on a topographical view of the density landscape.,5. Conclusions,[0],[0]
"We design algorithms to capture modes of the density landscape and merge trivial modes based on the theory of persistent homology.
Acknowledgments.",5. Conclusions,[0],[0]
XN and CC have been partly funded by the grant PSC-CUNY 69844-00 47.,5. Conclusions,[0],[0]
NQ has been partly funded by the Russian Academic Excellence Project ‘5- 100’.,5. Conclusions,[0],[0]
YW has been partly supported by the grant NSF DMS-1547357.,5. Conclusions,[0],[0]
The authors gratefully acknowledge use of the services and facilities of CUNY Queens Colleges Center for Computational Infrastructure for the Sciences (CCIS).,5. Conclusions,[0],[0]
Clustering data with both continuous and discrete attributes is a challenging task.,abstractText,[0],[0]
Existing methods often lack a principled probabilistic formulation.,abstractText,[0],[0]
"In this paper, we propose a clustering method based on a tree-structured graphical model to describe the generation process of mixed-type data.",abstractText,[0],[0]
"Our tree-structured model factorizes into a product of pairwise interactions, and thus localizes the interaction between feature variables of different types.",abstractText,[0],[0]
"To provide a robust clustering method based on the tree-model, we adopt a topographical view and compute peaks of the density function and their attractive basins for clustering.",abstractText,[0],[0]
"Furthermore, we leverage the theory from topology data analysis to adaptively merge trivial peaks into large ones in order to achieve meaningful clusterings.",abstractText,[0],[0]
Our method outperforms state-of-the-art methods on mixed-type data.,abstractText,[0],[0]
Composing Tree Graphical Models with Persistent Homology Features for Clustering Mixed-Type Data,title,[0],[0]

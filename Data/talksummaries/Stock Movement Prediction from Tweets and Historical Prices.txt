2	18	In natural language processing (NLP), public news and social media are two primary content resources for stock market prediction, and the models that use these sources are often discriminative.
8	29	Compared to discriminative models, generative models have the natural advantage in depicting the generative process from market information to stock signals and introducing randomness.
9	22	However, these models underrepresent chaotic social texts with bag-of-words and employ simple discrete latent variables.
12	36	For instance, when a company suffers from a major scandal on a trading day d1, generally, its stock price will have a downtrend in the coming trading days until day d2, i.e. [d1, d2].2 If a stock predictor can recognize this decline pattern, it is likely to benefit all the predictions of the movements during [d1, d2].
14	37	This predictive dependency is a result of the fact that public information, e.g. a company scandal, needs time to be absorbed into movements over time (Luss and d’Aspremont, 2015), and thus is largely shared across temporally-close predictions.
16	39	To better incorporate stochastic factors, we generate stock movements from latent driven factors modeled with recurrent, continuous latent variables.
18	30	To the best of our knowledge, StockNet is the first deep generative model for stock movement prediction.
20	45	We build market sources by referring to both fundamental information, e.g. tweets, and technical features, e.g. historical stock prices (Section 5.1).3 To accurately depict predictive dependencies, we assume that the movement prediction for a stock can benefit from learning to predict its historical movements in a lag window.
24	22	We aim at predicting the movement of a target stock s in a pre-selected stock collection S on a target trading day d. Formally, we use the market information comprising of relevant social media corporaM, i.e. tweets, and historical prices, in the lag [d −∆d, d − 1] where ∆d is a fixed lag size.
65	26	Besides, when t < T , yt is independent of z<t while our main prediction target, yT is made dependent on z<T through a temporal attention mechanism (Section 5.3).
70	22	Attentive Temporal Auxiliary (ATA) that integrates temporal loss through an attention mechanism for model training.
74	32	The basic strategy of acquiring ct is to first feed messages into the Message Embedding Layer for their low-dimensional representations, then selectively gather them according to their quality.
87	16	(8) Since it is the price change that determines the stock movement rather than the absolute price value, instead of directly feeding the raw price vector p̃t = [ p̃ct , p̃ h t , p̃ l t ] comprising of the adjusted closing, highest and lowest price on a trading day t, into the networks, we normalize it with its last adjusted closing price, pt = p̃t/p̃ct−1 − 1.
92	49	We first employ a variational approximator qφ (zt|z<t, x≤t, yt) for the intractable posterior.
107	36	Finally, we integrate deterministic features and the final prediction hypothesis is given as gt = tanh(Wg[xt, h s t , zt] + bg) (21) ỹt = ζ(Wygt + by), t < T (22) where Wg,Wy are weight matrices and bg, by are biases.
113	20	Since each hypothesis of a temporal auxiliary contributes unequally to the main prediction and model training, as shown in Figure 3, temporal attention calculates their weights in these two contributions by employing two scoring components: an information score and a dependency score.
122	32	To incorporate varied temporal importance at the objective level, we first break down the approximated L into a series of temporal objectives f ∈ RT×1 where ft comprises a likelihood term and a KL term for a trading day t, ft = log pθ (yt|x≤t, z≤t) (27) − λDKL [qφ (zt|z<t, x≤t, yt) ‖ pθ (zt|z<t, x≤t)] where we adopt the KL term annealing trick (Bowman et al., 2016; Semeniuta et al., 2017) and add a linearly-increasing KL term weight λ ∈ (0, 1] to gradually release the KL regularization effect in the training procedure.
123	17	Then we reuse v∗ to build the final temporal weight vector v ∈ R1×T , v = [αv∗, 1] (28) where 1 is for the main prediction and we adopt the auxiliary weight α ∈ [0, 1] to control the overall auxiliary effects on the model training.
124	17	α is tuned on the development set and its effects will be discussed at length in Section 6.5.
139	38	• ARIMA: Autoregressive Integrated Moving Average, an advanced technical analysis method using only price signals (Brown, 2004) .
148	34	Since stock prediction is a challenging task and a minor improvement usually leads to large potential profits, the accuracy of 56% is generally reported as a satisfying result for binary stock movement prediction (Nguyen and Shirai, 2015).
151	75	Our model, HEDGEFUNDANALYST achieves the best performance of 58.23 in accuracy and 0.080796 in MCC, outperforming TLSDA and HAN with 4.16, 0.59 in accuracy, and 0.015414, 0.028996 in MCC, respectively.
152	140	Though slightly better than random guess, classic technical analysis, e.g. ARIMA, does not yield satisfying results.
153	39	Similar in using only historical prices, TECHNICALANALYST shows an obvious advantage in this task compared ARIMA.
154	109	We believe there are two major reasons: (1) TECHNICALANALYST learns from training data and incorporates more flexible non-linearity; (2) our test set contains a large number of stocks while ARIMA is more sensitive to peculiar sequence stationarity.
156	69	The performance of FUNDAMENTALANALYST and TECHNICALANALYST confirm the positive effects from tweets and historical prices in stock movement prediction, respectively.
157	34	As an effective ensemble of the two market information, HEDGEFUNDANALYST gains even better performance.
162	21	(28), the temporal auxiliary weight α controls the overall effects of the objective-level temporal auxiliary to our model.
163	30	Figure 4 presents how the performance of HEDGEFUNDANALYST and DISCRIMINATIVEANALYST fluctuates with α.
175	38	We demonstrated the effectiveness of deep generative approaches for stock movement prediction from social media data by introducing StockNet, a neural network architecture for this task.

8	56	Minecraft has previously been used for work on planning and navigation (Oh et al., 2016; Tessler et al., 2016), and we expand on this by using it for grounded language understanding.
9	81	As a sandbox game, it can be used to construct a wide variety of environments that capture many interesting aspects of the real world.
12	64	Our task is formulated in terms of locating a pink, cube-shaped character named Misty given a scene, a natural language description, and a set of locations to choose from.
40	19	In Figure 1, we show an instance of our task, which consists of the following components: • W : a perceptual representation of the world • x: the natural language description • {y1, y2, .
46	17	To better anchor the language, we populate the target location with a cube-shaped character we name Misty, and ask workers to describe Misty’s location (Section 3.3).
55	30	Each Minecraft world W is encoded as a 3D grid of voxels, where a voxel may be empty or contain a particular type of “block,” e.g. stone or wood.
56	44	In general, what humans would interpret as single objects will be made of multiple Minecraft blocks – for example, the table in Figure 1 consists of a “wooden pressure plate” block on top of a “wooden fencepost” block.
81	32	Throughout this section, we will use the example description Misty is to the right of the table and just under the torch.
89	43	Finally, our model aggregates localizations across all words in the sentence, combining the information provided by the phrases to the right of the table and just under the torch (Figure 3e).
91	41	The first component of our model is responsible for associating words with the voxels that they refer to.
93	19	High scores correspond to high compatibility; for any given word, we can visualize the set s(xt, ·) of scores assigned to different voxels by interpreting it as logits that encode a probability distribution over blocks in the scene.
94	59	In the example, the word table would ideally be matched to the uniform reference distribution over blocks that are part of a table, and similarly for the word torch (Figure 3a).
95	18	The word-voxel scores are computed by combining word and block embeddings.
97	33	The function f consists of the first two layers of a convolutional neural network that is pretrained on the task of predicting a voxel’s identity given the 5x5x5 neighborhood around it.
107	21	For example, if probability mass is placed on the “oneblock-to-the-right” offset vector, this corresponds to predicting that Misty will be one block to the right of the voxels that a word refers to.
108	35	Offset scores ot are assigned based on the context the word xt occurs in, which allows the model to incorporate information from words such as right or under in its decisions.
109	17	This is accomplished by running a bidirectional LSTM over the embeddings wt of the words in the sentence, and using its output to compute offset probabilities: [z0, z1, .
110	42	o′t = Mzt ot(i) ∝ exp ( o′t(i) ) Each set of offset scores ot is reshaped into a 3x3x3 convolutional filter, except that we structurally disallow assigning any probability to the no-offset vector in the center.
114	31	Localizations are then summed across all words in the sentence, resulting in a single score for each voxel in the scene (Figure 3e).
115	28	These scores are interpreted as logits corresponding to a probability distribution over possible locations for Misty: dt(y) = s(xt, y) ∗ ot p(y) ∝ exp {∑ t dt(y) } Not all words will have localizations that provide information about Misty – for some words the localizations will just be a uniform distribution.
117	32	Our offset filters ot are much smaller than our voxel grid, which means that convolving any offset filter with a uniform reference distribution over the voxel grid will also result in a uniform localization distribution (edge effects are immaterial given the small filter size and the fact that Misty is generally not at the immediate edges of the scene).
160	19	At the same time, there remains a gap between our model and individual human performance.
183	54	This shows that our model is capable of representing compositional objects, and can learn to do so in an end-to-end manner.
186	55	The offset vector distribution at the word platform, shown in Figure 5b, shows that the model assigns high proba- Misty is between the wall and the flowers that are close to the corner.
188	236	This intersective interpretation is sufficient to correctly guess Misty’s location in this scene (as well as others in the dataset).
189	33	bility to Misty being above the platform.
190	52	In Figure 5c, we show the effects of replacing the phrase right above with the words in front of.
191	31	This example illustrates our model’s capacity for learning spatial directions.
202	19	In practice, however, we find that the intersective interpretation suffices for many of the descriptions that occur in our dataset.
204	18	We show that convolutional neural networks can be used to reason about regions in space as firstclass entities.

0	43	Recently, various neural network models were proposed and successfully applied to the tasks of questions answering (QA) and/or reading comprehension (Xiong et al., 2016; Dhingra et al., 2016; Yang et al., 2017).
4	25	Although larger question answering datasets with hundreds of thousands of question-answer pairs have been collected, including SQuAD (Rajpurkar et al., 2016), MSMARCO (Nguyen et al., 2016), and NewsQA (Trischler et al., 2016a), the data collection process is expensive and time-consuming in practice.
7	110	In this work, we study the following problem of semi-supervised question answering: is it possible to leverage unlabeled text to boost the performance of question answering models, especially when only a small amount of labeled data is available?
11	16	The starting point of our framework is to use linguistic tags to extract possible answer chunks in the unlabeled text, and then train a generative model to generate questions given the answer chunks and their contexts.
41	20	Given a paragraph p = (p1, p2, · · · , pT ) and the answer a = (pj , pj+1, · · · , pk−1, pk), we extract (pj−W , pj−W+1, · · · , pj−1, pk+1, pk+2, pk+W ) from the paragraph and treat it as the question.
45	18	Surprisingly, this simple baseline method leads to substantial improvements when labeled data is limited.
58	14	The question and paragraph representations are combined with the gated-attention (GA) mechanism (Dhingra et al., 2016).
63	24	Learning from both human-generated data and model-generated data can thus lead to a biased model.
82	31	Let UG denote the dataset obtained by generating questions on the unlabeled dataset U with the generative model G. The objective of the discriminative model is then to maximize J for both labeled and unlabeled data under the domain adaptation notions, i.e., J(L, d true, D) + J(UG, d gen, D).
85	27	In this case, the generative model aims to generate questions that can be reconstructed by the discriminative model, i.e., maximizing J(UG, d gen, D).
86	24	However, this objective function can lead to degenerate solutions because the questions can be thought of as an overcomplete representation of the answers (Vincent et al., 2010).
88	12	We propose to define an adversarial training objective J(UG, d true, D).
91	34	We first pretrain the generative model on the labeled data L with maximum likelihood estimation (MLE): max G N∑ i=1 T ′∑ t=1 logPG(q (i) t |q (i) <t, p (i), a(i)) where PG is the probability defined by Eq.
92	14	We then alternatively update D and G based on their objectives.
99	24	The generator G has two training phases–MLE training and RL training, which are different in that: 1) RL training does not require labels, so G can explore a broader data domain of p using unlabeled data, while MLE training requires labels; 2) MLE maximizes logP (q|p, a), while RL maximizes logPD(a|q, p).
104	12	To extract answers from massive unlabelled Wikipedia articles, we first sample 205,511 Wikipedia articles that are not used in the training, development and test sets in the SQuAD dataset.
109	12	Next, we use Stanford Named Entity Recognizer (NER) (Finkel et al., 2005) to assign each word with one of the seven labels, i.e., “Date”, “Money”, “Percent”, “location”, “Organization” and “Time”.
132	14	The highest labeling rate in Table 2 is 0.9 because 10% of the training instances are used for testing.
137	44	Such improvements are substantial when labeled data is limited.
138	22	For example, the GDANs improve over supervised learning by 9.87 points in F1 and 7.26 points in EM when the labeling rate is 0.1.
139	25	With our semisupervised learning approach, we can use only 0.1 training instances to obtain even better performance than a supervised learning approach with 0.2 training instances, saving more than half of the labeling costs.
144	22	With labeling rate 0.9, adding domain tags still leads to better performance but adversarial training does not seem to improve the performance by much.
150	58	We observe that the training loss for D on RLgenerated questions is lower than MLE-generated questions, which confirms that RL training maximizes logP (a|p, q).
151	18	Samples of Generated Questions.
154	21	Compared to MLE-generated questions, RL-generated questions are more informative (Cf., P1, P2, and P4), and contain less “UNK” (unknown) tokens (Cf., P1).
174	22	We study a critical and challenging problem, semi-supervised question answering.
175	12	We propose a novel neural framework called Generative Domain-Adaptive Nets, which incorporate domain adaptation techniques in combination with generative models for semi-supervised learning.
177	89	In the future, we plan to apply our approach to more question answering datasets in different domains.
178	53	It will also be intriguing to generalize GDANs to other applications.
179	63	This work was funded by the Office of Naval Research grants N000141512791 and N000141310721 and NVIDIA.

0	59	A stochastic differential equation (SDE) defines a diffusion process, which evolves randomly over time, by describing its instantaneous behaviour.
1	31	As such, SDEs are powerful modelling tools used extensively in fields such as econometrics (Black & Scholes, 1973; Eraker, 2001), biology (Gillespie, 2000; Golightly & Wilkinson, 2011), physics (van Kampen, 2007) and epidemiology (Fuchs, 2013).
2	10	It is only possible to work with analytic solutions to SDEs in special cases.
3	19	Therefore it is common to use a numerical approximation, such as the Euler-Maruyama scheme.
4	10	Here the diffusion process is defined only on a grid of time points, and the transition density between successive diffusion states is approximated as Gaussian.
12	9	The RNN learns how to supply Gaussian state transitions between successive time points which closely match those for the intractable conditioned diffusion process.
40	23	In this case, (1) defines a diffusion process.
41	16	Such processes are always Markovian (i.e. memoryless).
42	24	We further assume partial noisy observations of the latent process.
44	8	In the simplest case, these times are equally spaced, separated by a time-step of ∆t.
45	16	Let ytj be a vector of p0 observations at time tj , for some p0 ≤ p. Following Golightly & Wilkinson (2008), among others, we assume that ytj = F ′Xtj + ωtj , ωtj indep∼ N(0,Σ), (2) where F is a constant p×p0 matrix, and Σ is a p0×p0 matrix which may be assumed known or the object of inference.
47	11	Upon choosing a prior density p(θ), Bayesian inference proceeds via the parameter posterior p(θ|y), or alternatively the joint posterior p(θ, x|y).
71	14	This motivates us to use a variational approximation in which the diffusion matrix is not constrained to follow (9), and instead is allowed to shrink.
87	8	When variational inference outputs a good match to the posterior distribution, importance sampling (IS) (see e.g. Robert, 2004) can correct remaining inaccuracies and provide near-exact posterior inference.
109	8	A generative definition is xτi+1 = h ( xτi + α̃(xτi , y, θ, τi;φx)∆τ + √ β̃(xτi , y, θ, τi;φx)∆τzi+1 ) , (18) where α̃ and β̃ are drift and diffusion functions.
113	9	To express x with a non-centred parameterisation, let 2 ∼ N(0, Ipm) be the flattened vector of (z1, z2, .
120	14	So the network just discussed forms a cell of an overall recurrent neural network (RNN) structure for q(x|θ;φx).
128	8	It can be interpreted as constraining the variational approximation based on prior beliefs about positivity of diffusion paths.
138	15	Exploratory work showed that the RNN produces a much better approximation of the conditioned process with these features as input rather than simply xτi , y, θ and τi.
150	11	Many of these violate the assumptions used by existing diffusion bridge constructs (Whitaker et al., 2017b).
156	28	Lotka-Volterra models describe simple predator-prey population dynamics combining three types of event: prey reproduction, predation (in which prey are consumed and predators have the resources to reproduce) and predator death.
159	9	A single observation time with known parameters We begin with the case of a single observation time and known parameter values, where we follow Boys et al. (2008) by taking θ = (0.5, 0.0025, 0.3)′ and x0 = (71, 79)′.
164	8	Table 1 shows the resulting ESS values.
179	12	Convergence takes 2 hours, and importance sampling with 500,000 iterations produces an ESS of 635.4.
188	7	Constant population size is assumed.
215	17	Model comparison The two models produce visually similar diffusion paths, but close inspection shows some differences.
222	24	A better estimate of the parameter posteriors would allow formal model comparison based on importance sampling evidence estimates.
224	10	This performs inference for a broad class of SDEs with minimal tuning requirements.
226	12	Approximate parameter inference is also possible, with our results recovering known parameters for synthetic data (Section 5.1), and previous results for real data (Section 5.2), using only a few hours of computation for a desktop PC.
227	18	An interesting future direction is develop choices of q(x|θ;φx) more efficent than standard RNNs, to further reduce computing time and enable real-time applications of this methodology.

0	88	Question answering (QA) has been a long standing research problem in natural language processing, with the first systems attempting to answer questions by directly reading documents (Voorhees and Tice, 2000).
1	171	The development of large-scale Knowledge Bases (KBs) such as Freebase (Bollacker et al., 2008) helped organize information into structured forms, prompting recent progress to focus on answering questions by converting them into logical forms that can be used to query such databases (Berant et al., 2013; Kwiatkowski et al., 2013; Fader et al., 2014).
2	41	Unfortunately, KBs have intrinsic limitations such as their inevitable incompleteness and fixed schemas that cannot support all varieties of answers.
3	26	Since information extraction (IE) (Craven et al., 2000), intended to fill in missing information in KBs, is neither accurate nor reliable enough, collections of raw textual resources and documents such as Wikipedia will always contain more information.
6	53	Retrieving answers directly from text is harder than from KBs because information is far less structured, is indirectly and ambiguously expressed, and is usually scattered across multiple documents.
9	14	To this end, this paper introduces WIKIMOVIES, a new analysis tool that allows for measuring the performance of QA systems when the knowledge source is switched from a KB to unstructured documents.
10	112	WIKIMOVIES contains ∼100k questions in the movie domain, and was designed to be answerable by using either a perfect KB (based on OMDb1), Wikipedia pages or an imper- 1400 fect KB obtained through running an engineered IE pipeline on those pages.
11	23	To bridge the gap between using a KB and reading documents directly, we still lack appropriate machine learning algorithms.
29	30	The Key-Value Memory Network model is based on the Memory Network (MemNNs) model (Weston et al., 2015; Sukhbaatar et al., 2015) which has proven useful for a variety of document reading and question answering tasks: for reading children’s books and answering questions about them (Hill et al., 2016), for complex reasoning over sim- ulated stories (Weston et al., 2016) and for utilizing KBs to answer questions (Bordes et al., 2015).
30	17	Key-value paired memories are a generalization of the way context (e.g. knowledge bases or documents to be read) are stored in memory.
35	30	Our model is based on the end-to-end Memory Network architecture of Sukhbaatar et al. (2015).
37	32	At test time one is given a query (e.g. the question in QA tasks), which is used to iteratively address and read from the memory (these iterations are also referred to as “hops”) looking for relevant information to answer the question.
40	16	Figure 1 illustrates the KV-MemNN model architecture.
41	33	In KV-MemNNs we define the memory slots as pairs of vectors (k1, v1) .
44	77	This is done using an inverted index that finds a subset (kh1 , vh1), .
45	40	, (khN , vhN ) of memories of size N where the key shares at least one word with the question with frequency < F = 1000 (to ignore stop words), following Dodge et al. (2016).
46	37	More sophisticated retrieval schemes could be used here, see e.g. Manning et al. (2008), • Key Addressing: during addressing, each candidate memory is assigned a relevance probability by comparing the question to each key: phi = Softmax(AΦX(x) ·AΦK(khi)) where Φ· are feature maps of dimension D, A is a d×D matrix and Softmax(zi) = ezi/ ∑ j e zj .
47	19	We discuss choices of feature map in Sec.
48	38	• Value Reading: in the final reading step, the values of the memories are read by taking their weighted sum using the addressing probabilities, and the vector o is returned: o = ∑ i phiAΦV (vhi) .
51	41	The memory access is then repeated (specifically, only the addressing and reading steps, but not the hashing), using a different matrix Rj on each hop, j.
53	13	The motivation for this is that new evidence can be combined into the query to focus on and retrieve more pertinent information in subsequent accesses.
54	194	Finally, after a fixed number H hops, the resulting state of the controller is used to compute a final prediction over the possible outputs: â = argmaxi=1,...,CSoftmax(q > H+1BΦY (yi)) where yi are the possible candidate outputs, e.g. all the entities in the KB, or all possible candidate answer sentences in the case of a dataset like WIKIQA (see Sec.
56	51	The whole network is trained end-to-end, and the model learns to perform the iterative accesses to output the desired target a by minimizing a standard cross-entropy loss between â and the correct answer a. Backpropagation and stochastic gradient descent are thus used to learn the matrices A,B and R1, .
57	136	To obtain the standard End-To-End Memory Network of Sukhbaatar et al. (2015) one can simply set the key and value to be the same for all memories.
59	35	We will now go on to describe specific applications of key-value memories for the task of reading KBs or documents.
61	33	The ability to encode prior knowledge in this way is an important component of KV-MemNNs, and we are free to define ΦX ,ΦY ,ΦK and ΦV for the query, answer, keys and values respectively.
63	50	KB Triple Knowledge base entries have a structure of triple “subject relation object” (see Table 1 for examples).
67	47	For a standard MemNN that does not have key-value pairs the whole triple has to be encoded into the same memory slot.
69	63	Both the key and the value encode the entire sentence as a bag-of-words.
71	59	Window Level Documents are split up into windows of W words; in our tasks we only include windows where the center word is an entity.

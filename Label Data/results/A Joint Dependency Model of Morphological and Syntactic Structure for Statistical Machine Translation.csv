0,1,label2,summary_sentences
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2081–2087, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"When translating between two languages that differ in their degree of morphological synthesis, syntactic structures in one language may be realized as morphological structures in the other.",1 Introduction,[0],[0]
"Machine Translation models that treat words as atomic units have poor learning capabilities for such translation units, and morphological segmentations are commonly used (Koehn and Knight, 2003).",1 Introduction,[0],[0]
"Like words in a sentence, the morphemes of a word have a hierarchical structure that is relevant in translation.",1 Introduction,[0],[0]
"For instance, compounds in Germanic languages are head-final, and the head is the segment that determines agreement within the noun phrase, and is relevant for selectional preferences of verbs.
",1 Introduction,[0],[0]
"1. sie erheben eine Hand|gepäck|gebühr.
",1 Introduction,[0],[0]
"they charge a carry-on bag fee.
",1 Introduction,[0],[0]
"In example 1, agreement in case, number and gender is enforced between eine ’a’ and Gebühr ’fee’, and selectional preference between erheben ’charge’ and Gebühr ’fee’.",1 Introduction,[0],[0]
"A flat representation, as is common in phrase-based SMT, does not encode these relationships, but a dependency representation does so through dependency links.
",1 Introduction,[0],[0]
"In this paper, we investigate a dependency representation of morphologically segmented words for SMT.",1 Introduction,[0],[0]
"Our representation encodes syntactic and morphological structure jointly, allowing a single model to learn the translation of both.",1 Introduction,[1.0],"['Our representation encodes syntactic and morphological structure jointly, allowing a single model to learn the translation of both.']"
"Specifically, we work with a string-to-tree model with GHKM-style rules (Galley et al., 2006), and a relational dependency language model (Sennrich, 2015).",1 Introduction,[1.0],"['Specifically, we work with a string-to-tree model with GHKM-style rules (Galley et al., 2006), and a relational dependency language model (Sennrich, 2015).']"
"We focus on the representation of German syntax and morphology in an English-to-German system, and two morphologically complex word classes in German that are challenging for translation, compounds and particle verbs.
",1 Introduction,[0.9999999657177324],"['We focus on the representation of German syntax and morphology in an English-to-German system, and two morphologically complex word classes in German that are challenging for translation, compounds and particle verbs.']"
"German makes heavy use of compounding, and compounds such as Abwasserbehandlungsanlage ‘waste water treatment plant’ are translated into complex noun phrases in other languages, such as French station d’épuration des eaux résiduaires.
",1 Introduction,[0.999999957623879],"['German makes heavy use of compounding, and compounds such as Abwasserbehandlungsanlage ‘waste water treatment plant’ are translated into complex noun phrases in other languages, such as French station d’épuration des eaux résiduaires.']"
German particle verbs are difficult to model because their surface realization differs depending on the finiteness of the verb and the type of clause.,1 Introduction,[1.0],['German particle verbs are difficult to model because their surface realization differs depending on the finiteness of the verb and the type of clause.']
"Verb particles are separated from the finite verb in
2081
main clauses, but prefixed to the verb in subordinated clauses, or when the verb is non-finite.",1 Introduction,[1.0000000294312612],"['Verb particles are separated from the finite verb in 2081 main clauses, but prefixed to the verb in subordinated clauses, or when the verb is non-finite.']"
"The infinitive marker zu ’to’, which is normally a premodifying particle, appears as an infix in particle verbs.",1 Introduction,[1.0],"['The infinitive marker zu ’to’, which is normally a premodifying particle, appears as an infix in particle verbs.']"
Table 1 shows an illustrating example.,1 Introduction,[0],[0]
"The main focus of research on compound splitting has been on the splitting algorithm (Popovic et al., 2006; Nießen and Ney, 2000; Weller et al., 2014; Macherey et al., 2011).",2 A Dependency Representation of Compounds and Particle Verbs,[1.0],"['The main focus of research on compound splitting has been on the splitting algorithm (Popovic et al., 2006; Nießen and Ney, 2000; Weller et al., 2014; Macherey et al., 2011).']"
"Our focus is not the splitting algorithm, but the representation of compounds.",2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
"For splitting, we use an approach similar to (Fritzinger and Fraser, 2010), with segmentation candidates identified by a finite-state morphology (Schmid et al., 2004; Sennrich and Kunz, 2014), and statistical evidence from the training corpus to select a split (Koehn and Knight, 2003).
",2 A Dependency Representation of Compounds and Particle Verbs,[0.9999999662266393],"['For splitting, we use an approach similar to (Fritzinger and Fraser, 2010), with segmentation candidates identified by a finite-state morphology (Schmid et al., 2004; Sennrich and Kunz, 2014), and statistical evidence from the training corpus to select a split (Koehn and Knight, 2003).']"
"German compounds are head-final, and premodifiers can be added recursively.",2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
Compounds are structurally ambiguous if there is more than one modifier.,2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
Consider the distinction between (Stadtteil)projekt (literally: ’(city part) project)’) and Stadt(teilprojekt) ’city sub-project’.,2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
"We opt for a left-branching representation by default.1 We also split linking elements, and represent them as a postmodifier of each non-final segment, including the empty string ("" "").",2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
"We use the same representation for noun compounds and adjective compounds.
",2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
An example of the original2 and the proposed compound representation is shown in Figure 1.,2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
"Importantly, the head of the compound is also the parent of the determiners and attributes in the noun phrase, which makes a bigram dependency language model sufficient to enforce agreement.",2 A Dependency Representation of Compounds and Particle Verbs,[1.0],"['Importantly, the head of the compound is also the parent of the determiners and attributes in the noun phrase, which makes a bigram dependency language model sufficient to enforce agreement.']"
"Since we model morphosyntactic agreement within the main translation step, and not in a separate step as in (Fraser et al., 2012), we deem it useful that inflection is marked at the head of the compound.",2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
"Consequently, we do not split off inflectional or derivational morphemes.
",2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
"For German particle verbs, we define a common representation that abstracts away from the various surface realizations (see Table 1).",2 A Dependency Representation of Compounds and Particle Verbs,[1.0],"['For German particle verbs, we define a common representation that abstracts away from the various surface realizations (see Table 1).']"
"Separated
1We follow prior work in leaving frequent words or subwords unsplit, which has a disambiguating effect.",2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
"With more aggressive splitting, frequency information could be used for the structural disambiguation of internal structure.
",2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
"2The original dependency trees follow the annotation guidelines by Foth (2005).
verb particles are reordered to be the closest premodifier of the verb.",2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
"Prefixed particles and the zuinfix are identified by the finite-state-morphology, and split from the verb so that the particle is the closest, the zu marker the next-closest premodifier of the verb, as shown in Figure 2.",2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
"Agreement, selectional preferences, and other phenomena involve the verb and its dependents, and the proposed representation retains these dependency links, but reduces data sparsity from affixation and avoids discontinuity of the verb and its particle.",2 A Dependency Representation of Compounds and Particle Verbs,[0],[0]
"We follow Williams et al. (2014) and map dependency trees into a constituency representation, which allows for the extraction of GHKM-style translation rules (Galley et al., 2006).",3 Tree Binarization,[0],[0]
"This conversion is lossless, and we can still apply a de-
pendency language model (RDLM).",3 Tree Binarization,[0],[0]
"Figure 3 (a) shows the constituency representation of the example in Figure 1.
",3 Tree Binarization,[0],[0]
"Our model should not only be able to produce new words productively, but also to memorize words it has observed during training.",3 Tree Binarization,[0],[0]
"Looking at the compound Handgepäckgebühr in Figure 3 (a), we can see that it does not form a constituent, and cannot be extracted with GHKM extraction heuristics.",3 Tree Binarization,[0],[0]
"To address this, we binarize the trees in our training data (Wang et al., 2007).
",3 Tree Binarization,[0],[0]
A complicating factor is that the binarization should not impair the RDLM.,3 Tree Binarization,[0],[0]
"During decoding, we map the internal tree structure of each hypothesis back to the unbinarized form, which is then scored by the RDLM.",3 Tree Binarization,[0],[0]
Virtual nodes introduced by the binarization must also be scorable by RDLM if they form the root of a translation hypothesis.,3 Tree Binarization,[0],[0]
A simple right or left binarization would produce virtual nodes without head and without meaningful dependency representation.,3 Tree Binarization,[0],[0]
We ensure that each virtual node dominates the head of the full constituent through a mixed binarization.3,3 Tree Binarization,[0],[0]
"Specifically, we perform right binarization of the head and all pre-modifiers, then left binarization of all post-modifiers.",3 Tree Binarization,[0],[0]
"This head-binarized representation is illustrated in Figure 3 (b).4
Head binarization ensures that even hypotheses whose root is a virtual node can be scored by the RDLM.",3 Tree Binarization,[0],[0]
"This score is only relevant for pruning, and discarded when the full constituent is scored.",3 Tree Binarization,[0],[0]
"Still, these hypotheses require special treatment in the RDLM to mitigate search errors.",3 Tree Binarization,[0],[0]
"The virtual node labels (such as OBJA) are unknown symbols to the RDLM, and we simply replace them with the original label (OBJA).",3 Tree Binarization,[0],[0]
"The RDLM uses sibling context, and this is normally padded with special start and stop symbols, analogous to BOS/EOS symbols in n-gram models.",3 Tree Binarization,[0],[0]
These start and stop symbols let the RDLM compute the probability that a node is the first or last child of its ancestor node.,3 Tree Binarization,[0],[0]
"However, computing these probabilities for virtual nodes would unfairly bias the search, since the first/last child of a virtual node is not necessarily the first/last child of the full constituent.",3 Tree Binarization,[0],[0]
"We adapt the representation of virtual nodes in
3In other words, every node is a fixed well-formed dependency structure (Shen et al., 2010) with our binarization.
",3 Tree Binarization,[0],[0]
"4Note that our definition of head binarization is different from that of Wang et al. (2007), who left-binarize a node if the head is the first child, and right-binarize otherwise.",3 Tree Binarization,[0],[0]
"Our algorithm also covers cases where the head has both pre- and post-modifiers, as erheben and gepäck do in Figure 3.
RDLM to take this into account.",3 Tree Binarization,[0],[0]
"We distinguish between virtual nodes based on whether their span is a string prefix, suffix, or infix of the full constituent.",3 Tree Binarization,[0],[0]
"For prefixes and infixes, we do not add a stop symbol at the end, and use null symbols, which denote unavailable context, for padding to the right.",3 Tree Binarization,[0],[0]
"For suffixes and infixes, we do the same at the start.",3 Tree Binarization,[0],[0]
"For SMT, all German training and development data is converted into the representation described in sections 2–3.",4 Post-Processing,[0],[0]
"To restore the original representation, we start from the tree output of the stringto-tree decoder.",4 Post-Processing,[1.0],"['To restore the original representation, we start from the tree output of the stringto-tree decoder.']"
"Merging compounds is trivial: all segments and linking elements can be identified by the tree structure, and are concatenated.
",4 Post-Processing,[0.9999999847788589],"['Merging compounds is trivial: all segments and linking elements can be identified by the tree structure, and are concatenated.']"
"For verbs that dominate a verb particle, the original order is restored through three rules:
1. non-finite verbs are concatenated with the particle, and zu-markers are infixed.
2. finite verbs that head a subordinated clause (identified by its dependency label) are concatenated with the particle.
3.",4 Post-Processing,[0],[0]
"finite verbs that head a main clause have the
particle moved to the right clause",4 Post-Processing,[0],[0]
"bracket.5
Previous work on particle verb translation into German proposed to predict the position of particles with an n-gram language model (Nießen and Ney, 2001).",4 Post-Processing,[0],[0]
"Our rules have the advantage that they are informed by the syntax of the sentence and consider the finiteness of the verb.
",4 Post-Processing,[0],[0]
Our rules only produce projective trees.,4 Post-Processing,[1.0],['Our rules only produce projective trees.']
"Verb particles may also appear in positions that violate projectivity, and we leave it to future research to determine if our limitation to projective trees affects translation quality, and how to produce nonprojective trees.",4 Post-Processing,[0],[0]
We train English–German string-to-tree SMT systems on the training data of the shared translation task of the Workshop on Statistical Machine Translation (WMT) 2015.,5.1 Data and Models,[0],[0]
"The data set consists of 4.2 million sentence pairs of parallel data, and 160 million sentences of monolingual German data.
",5.1 Data and Models,[0],[0]
We base our systems on that of Williams et al. (2014).,5.1 Data and Models,[0],[0]
"It is a string-to-tree GHKM translation system implemented in Moses (Koehn et al., 2007), and using the dependency annotation by ParZu (Sennrich et al., 2013).",5.1 Data and Models,[0],[0]
"Additionally, our baseline system contains a dependency language model (RDLM) (Sennrich, 2015), trained on the target-side of the parallel training data.
",5.1 Data and Models,[0],[0]
"We report case-sensitive BLEU scores on the newstest2014/5 test sets from WMT, averaged over 3 optimization runs of k-batch MIRA (Cherry and Foster, 2012) on a subset of newstest2008-12.6
We split all particle verbs and hyphenated compounds, but other compounds are only split if they are rare (frequency in parallel text < 5).
",5.1 Data and Models,[0],[0]
"For comparison with the state-of-the-art, we train a full system on our restructured representation, which incorporates all models and settings of our WMT 2015 submission system (Williams et al., 2015).7 Note that our WMT 2015 submission
5We use the last position in the clause as default location, but put the particle before any subordinated and coordinated clauses, which occur in the Nachfeld (the ‘final field’ in topological field theory).
",5.1 Data and Models,[0],[0]
"6We use mteval-v13a.pl for comparability to official WMT results; all significance values reported are obtained with MultEval (Clark et al., 2011).
",5.1 Data and Models,[0],[0]
"7In contrast to our other systems in this paper, RDLM is trained on all monolingual data for the full system, and two models are added: a 5-gram Neural Network language model
uses the dependency representation of compounds and tree binarization introduced in this paper; we achieve additional gains over the submission system through particle verb restructuring.",5.1 Data and Models,[0],[0]
Table 2 shows translation quality (BLEU) with different representations of German compounds and particle verbs.,5.2 SMT Results,[0],[0]
"Head binarization not only yields improvements over the baseline, but also allows for larger gains from morphological segmentation.",5.2 SMT Results,[0],[0]
"We attribute this to the fact that full compounds, and prefixed particle verbs, are not always a constituent in the segmented representation, and that binarization compensates this theoretical drawback.
",5.2 SMT Results,[0],[0]
"With head binarization, we find substantial improvements from compound splitting of 0.7–1.1 BLEU.",5.2 SMT Results,[0],[0]
"On newstest2014, the improvement is almost twice of that reported in related work (Williams et al., 2014), which also uses a hierarchical representation of compounds, albeit one that does not allow for dependency modelling.",5.2 SMT Results,[1.0],"['On newstest2014, the improvement is almost twice of that reported in related work (Williams et al., 2014), which also uses a hierarchical representation of compounds, albeit one that does not allow for dependency modelling.']"
"Examples of correct, unseen compounds generated include Staubsauger|roboter ’vacuum cleaner robot’, Gravitation|s|wellen ’gravitational waves’, and NPD|-|verbot|s|verfahren ’NPD banning process’.8
(Vaswani et al., 2013), and soft source-syntactic constraints (Huck et al., 2014).
",5.2 SMT Results,[0],[0]
"8Note that Staubsauger, despite being a compound, is not
Particle verb restructuring yields additional gains of 0.1–0.4 BLEU.",5.2 SMT Results,[0],[0]
"One reason for the smaller effect of particle verb restructuring is that the difficult cases – separated particle verbs and those with infixation – are rarer than compounds, with 2841 rare compounds [that would be split by our compound splitter] in the reference texts, in contrast to 553 separated particle verbs, and 176 particle verbs with infixation, as Table 3 illustrates.",5.2 SMT Results,[0],[0]
"If we only evaluate the sentences containing a particle verb with zu-infix in the reference, 165 in total for newstest2014/5, we observe an improvement of 0.8 BLEU on this subset (22.1→22.9), significant with p < 0.05.
",5.2 SMT Results,[0],[0]
The positive effect of restructuring is also apparent in frequency statistics.,5.2 SMT Results,[0],[0]
Table 3 shows that the baseline system severely undergenerates compounds and separated/infixed particle verbs.,5.2 SMT Results,[1.0],['Table 3 shows that the baseline system severely undergenerates compounds and separated/infixed particle verbs.']
"Binarization, compound splitting, and particle verb restructuring all contribute to bringing the distribution of compounds and particle verbs closer to the reference.
",5.2 SMT Results,[1.000000011275907],"['Binarization, compound splitting, and particle verb restructuring all contribute to bringing the distribution of compounds and particle verbs closer to the reference.']"
"In total, the restructured representation yields improvements of 1.4–1.8 BLEU over our baseline.",5.2 SMT Results,[0],[0]
The full system is competitive with official submissions to the WMT 2015 shared translation tasks.,5.2 SMT Results,[1.0],['The full system is competitive with official submissions to the WMT 2015 shared translation tasks.']
"It outperforms our submission (Williams et al., 2015) by 0.4 BLEU, and outperforms other phrase-based and syntax-based submissions by 0.8 BLEU or more.",5.2 SMT Results,[1.0],"['It outperforms our submission (Williams et al., 2015) by 0.4 BLEU, and outperforms other phrase-based and syntax-based submissions by 0.8 BLEU or more.']"
"The best reported result according to BLEU is an ensemble of Neural MT systems (Jean et al., 2015), which achieves 24.9 BLEU.",5.2 SMT Results,[0],[0]
"In the human evaluation, both our submission and the Neural MT system were ranked 1–2 (out of 16), with no significant difference between them.",5.2 SMT Results,[0],[0]
We perform a synthetic experiment to test our claim that a dependency representation allows for the modelling of agreement between morphemes.,5.3 Synthetic LM Experiment,[1.0],['We perform a synthetic experiment to test our claim that a dependency representation allows for the modelling of agreement between morphemes.']
"For 200 rare compounds [that would be split by our compound splitter] in the newstest2014/5 references, we artificially introduce agreement errors by changing the gender of the determiner.",5.3 Synthetic LM Experiment,[1.0],"['For 200 rare compounds [that would be split by our compound splitter] in the newstest2014/5 references, we artificially introduce agreement errors by changing the gender of the determiner.']"
"For instance, we create the erroneous sentence sie erheben ein Handgepäckgebühr as a complement to Example 1.",5.3 Synthetic LM Experiment,[0],[0]
We measure the ability of language models to prefer (give a higher probability to) the original reference sentence over the erroneous one.,5.3 Synthetic LM Experiment,[1.0],['We measure the ability of language models to prefer (give a higher probability to) the original reference sentence over the erroneous one.']
"In the original representation, both a Kneser-
segmented due to its frequency.
",5.3 Synthetic LM Experiment,[0],[0]
"Ney 5-gram LM and RDLM perform poorly due to data sparseness, with 70% and 57.5% accuracy, respectively.",5.3 Synthetic LM Experiment,[0],[0]
"In the split representation, the RDLM reliably prefers the correct agreement (96.5% accuracy), whilst the performance of the 5-gram model even deteriorates (to 60% accuracy).",5.3 Synthetic LM Experiment,[1.0],"['In the split representation, the RDLM reliably prefers the correct agreement (96.5% accuracy), whilst the performance of the 5-gram model even deteriorates (to 60% accuracy).']"
"This is because the gender of the first segment(s) is irrelevant, or even misleading, for agreement.",5.3 Synthetic LM Experiment,[1.0],"['This is because the gender of the first segment(s) is irrelevant, or even misleading, for agreement.']"
"For instance, Handgepäck is neuter, which could lead a morpheme-level n-gram model to prefer the determiner ein, but Handgepäckgebühr is feminine and requires eine.",5.3 Synthetic LM Experiment,[0],[0]
Our main contribution is that we exploit the hierarchical structure of morphemes to model them jointly with syntax in a dependency-based stringto-tree SMT model.,6 Conclusion,[1.0],['Our main contribution is that we exploit the hierarchical structure of morphemes to model them jointly with syntax in a dependency-based stringto-tree SMT model.']
"We describe the dependency annotation of two morphologically complex word classes in German, compounds and particle verbs, and show that our tree representation yields improvements in translation quality of 1.4–1.8 BLEU in the WMT English–German translation task.9
The principle of jointly representing syntactic and morphological structure in dependency trees can be applied to other language pairs, and we expect this to be helpful for languages with a high degree of morphological synthesis.",6 Conclusion,[0.9999999639549328],"['We describe the dependency annotation of two morphologically complex word classes in German, compounds and particle verbs, and show that our tree representation yields improvements in translation quality of 1.4–1.8 BLEU in the WMT English–German translation task.9 The principle of jointly representing syntactic and morphological structure in dependency trees can be applied to other language pairs, and we expect this to be helpful for languages with a high degree of morphological synthesis.']"
"However, the annotation needs to be adapted to the respective languages.",6 Conclusion,[1.0],"['However, the annotation needs to be adapted to the respective languages.']"
"For example, French compounds such as arc-en-ciel ’rainbow’ are head-initial, in contrast to head-final Germanic compounds.",6 Conclusion,[1.0],"['For example, French compounds such as arc-en-ciel ’rainbow’ are head-initial, in contrast to head-final Germanic compounds.']"
This project received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreements 645452,Acknowledgments,[0],[0]
"(QT21), 644402 (HimL), 644333 (TraMOOC), and from the Swiss National Science Foundation under grant P2ZHP1_148717.",Acknowledgments,[0],[0]
"When translating between two languages that differ in their degree of morphological synthesis, syntactic structures in one language may be realized as morphological structures in the other, and SMT models need a mechanism to learn such translations.",abstractText,[0],[0]
"Prior work has used morpheme splitting with flat representations that do not encode the hierarchical structure between morphemes, but this structure is relevant for learning morphosyntactic constraints and selectional preferences.",abstractText,[0],[0]
"We propose to model syntactic and morphological structure jointly in a dependency translation model, allowing the system to generalize to the level of morphemes.",abstractText,[0],[0]
We present a dependency representation of German compounds and particle verbs that results in improvements in translation quality of 1.4–1.8 BLEU in the WMT English–German translation task.,abstractText,[0],[0]
A Joint Dependency Model of Morphological and Syntactic Structure for Statistical Machine Translation,title,[0],[0]

1	39	In order to estimate a causal effect, the desired effect must be identified or uniquely expressible in terms of the probability distribution over the available data.
2	37	Causal effects are identified by design in randomized control trials, but in many applications, such experiments are not possible.
3	59	When only observational data is available, determining whether a causal effect is identified requires modeling the underlying causal structure, which is generally done using structural equation models (SEMs) (also called structural causal models) (Pearl, 2009; Bareinboim and Pearl, 2016).
4	34	A structural equation model consists of a set of equations that describe the underlying data-generating process for a set of variables.
6	15	A linear SEM consists of a set of equations of the form, X = ΛX + U , where X = [x1, ..., xn]t is a vector containing the model variables, Λ is a matrix containing the coefficients of the model, and Λij represents the direct effect of xi on xj , and U = [u1, ..., un]t is a vector of normally distributed error terms, which represents omitted or latent variables.1 The matrix Λ contains zeroes on the diagonal, and Λij = 0 whenever xi is not a cause of xj .
8	12	In this paper, we will restrict our attention to semi-Markovian models (Pearl, 2009), models where the rows of Λ can be arranged so that it is lower triangular, and the corresponding graph is acyclic.
11	55	Similarly, restricting Ωij to zero reflects the assumption that there are no unobserved common causes of both Yi and Yj .
28	19	The intuition behind auxiliary variables is simple: if the coefficient from variable w to z, β, is known, then we would like to remove the direct effect of w on z by subtracting it from z.
57	17	In this case, Left(π) = ∪ki=1vLi ∪ {x, vT } and Right(π) = ∪ j i=1v R i ∪ {y, vT }.
74	35	In some cases, x∗ allows the identification of coefficients and testable implications using existing methods when x could not, due to the fact that the back-door paths from x to y that go through β cancel with the back-door paths from x∗ to y that go through −β.
77	26	Both of these methods assume that the underlying causal relationships between variables are linear, in addition to other causal assumptions that guarantee identification.
78	12	The single-door criterion (Pearl, 2009) graphically characterizes when the assumptions sufficient to estimate a causal effect using regression are satisfied in a linear SEM.
86	23	(Brito and Pearl, 2002a) Given a linear model with graph G, the coefficients for a set of edges E = {(x1, y), ..., (xk, y)} are identified if there exists triplets (z1,W1, p1), ..., (zk,Wk, pk) such that for i = 1, ..., k, (i) (zi |= y|Wi)GE− , where W does not contain any descendants of y and GE− is the graph obtained by deleting the edges, E from G, (ii) pi is a path between zi and xi that is not blocked by Wi, and (iii) the set of paths, {p1, ..., pk} has no sided intersection.7 If the above conditions are satisfied, we say that Z is a generalized instrumental set for E or simply an instrumental set for E.8 In some cases, a variable z may not satisfy condition (i) above but an auxiliary variable z∗ does.
87	58	For example, in Figure 1a, we cannot identify α using Theorem 2.
91	40	Now, α can be identified using x∗ as an auxiliary instrument given w1.
96	14	α can only be identified if we block the paths x ↔ w1 → y and x ↔ w1 → w2 → y by conditioning on w1.
101	11	Now, z is not technically an instrument for α, but it can be shown that α = rY ∗Z.WrXZ .
111	16	(ii) for i = 1, ..., k, pi is a path between zi and xi that is not blocked by Wi, where xi = He(αi), and (iii) the set of paths {p1, ..., pk} has no sided intersection Theorem 3.
114	38	Given a linear SEM with graph G, z∗ is a quasi-IV for α given W if W does not contain any descendants of z, and z is an IV for α given W in GEz∪Ey−, where Ez ⊆ Inc(z) and Ey ⊆ Inc(y) are sets of edges whose coefficient values are known.
115	21	Auxiliary and quasi-IV sets enable a bootstrapping procedure whereby complex models can be identified by iteratively identifying coefficients and using them to generate new auxiliary variables.
119	21	Now, the identification of e allows us to identify a and d using v∗5 , since v5 is an IV for a and d when the edge for e is removed (see Figure 3c).
140	18	The algorithm is polynomial if the degree of each node in the graph is bounded.
143	13	Now, the first edge to be identified would be a using w1 as an IV.
148	15	Algorithm 1 qID(G,Σ, IDEdges) Initialize: EdgeSets← all connected edge sets in G repeat for all ES in EdgeSets such that ES 6⊆ IDEdges do y ← He(ES) for all E ⊆ ES such that E 6⊆ IDEdges do (Z,W )← FindQIS(G,ES, IDEdges) if (Z,W ) 6=⊥ then Identify ES using Z∗ as an auxiliary instrumental set in G(IDEdges∩Inc(Z))+ IDEdges← IDEdges ∪ ES end if end for end for until All coefficients have been identified or no coefficients have been identified in the last iteration In contrast, Figure 4b is not identified using simple instrumental sets and auxiliary variables.
151	16	Moreover, qID will identify any coefficients that are identifiable using auxiliary variables and simple instrumental sets, giving us the following theorem.
152	25	Given an arbitrary linear causal model, if a set of coefficients is identifiable using the g-HT algorithm, then it is identifiable using qID.
153	35	Additionally, there are models that are not identified using the g-HT algorithm, but identified using qID.
154	29	Theorem 1 also enables us to derive new vanishing partial correlation constraints that can be used to test the model.
162	106	Shpitser et al. (2009) noticed a similar phenomenon when deriving dormant independences in non-parametric models, and their explanation applies to conditional independence constraints among AVs as well.
163	62	The idea is the following: When the model implies that two variables are conditionally independent, it relies on the modeled assumption that there is no edge between those variables.

1	30	There have been two major streams of research in this direction, namely task oriented dialog and general purpose dialog (i.e., chit-chat).
3	27	In recent years, the latter has at- tracted much attention in both academia and industry as a way to explore the possibility in developing a general purpose AI system in language (e.g., chatbots).
4	30	A widely adopted approach to general purpose dialog is learning a generative conversational model from large scale social conversation data.
12	30	Previous Seq2Seq models, which treat all the utteranceresponse pairs uniformly and employ a single model to learn the relationship between them, will inevitably favor such general responses with high frequency.
13	31	Although these responses are safe for replying different utterances, they are boring and trivial since they carry little information, and may quickly lead to an end of the conversation.
22	30	The key idea is inspired by our observation on everyday conversation between humans.
23	50	In human-human conversation, people often actively control the specificity of responses depending on their own response purpose (which might be affected by a variety of underlying factors like their current mood, knowledge state and so on).
24	23	For example, they may provide some interesting and specific responses if they like the conversation, or some general responses if they want to end it.
27	21	We employ a Seq2Seq framework and further introduce an explicit specificity control variable to represent the response purpose of the agent.
28	21	Meanwhile, we assume that each word, beyond the semantic representation which relates to its meaning, also has another representation which relates to the usage preference under different response purpose.
30	41	The specificity control variable then interacts with the usage representation of words through a Gaussian Kernel layer, and guides the Seq2Seq model to generate responses at different specificity levels.
81	48	The decoder is to generate a response Y given the hidden representations of the input utterance X under some specificity level denoted by the control variable s. Specifically, at step t, we define the probability of generating any target word yt by a “mixture” of probabilities: p(yt) = βpM (yt) + γpS(yt), (1) where pM (yt) denotes the semantic-based generation probability, pS(yt) denotes the specificitybased generation probability, β and γ are the coefficients.
88	26	The specificity control variable s then interacts with the usage representations through the Gaussian Kernel layer to produce the specificity-based generation probability pS(yt): pS(yt = w) = 1√ 2πσ exp(−(ΨS(U,w)− s) 2 2σ2 ), ΨS(U,w) = σ(wT(U ·WU + bU )), (4) where σ2 is the variance, and ΨS(·) maps the word usage representation into a real value with the specificity control variable s as the mean of the Gaussian distribution.
90	20	Note here in general we can use any realvalue function to define ΨS(U,w).
91	19	In this work, we use the sigmoid function σ(·) for ΨS(U,w) since we want to define s within the range [0,1] so that each end has very clear meaning on the specificity, i.e., 0 denotes the most general response while 1 denotes the most specific response.
100	20	Specifically, we first build the response collection R by extracting all the responses from D. For a response Y ∈ R, let fY denote its corpus frequency in R, we compute its Inverse Response Frequency (IRF) as: IRFY = log(1 + |R|)/fY, (6) where |R| denotes the size of the response collection R. Next, we use the min-max normalization method (Jain et al., 2005) to obtain the NIRF value.
105	19	Hence, we can use the inverse corpus frequency of the words to indicate the specificity level of a response.
112	32	Given a new input utterance, we can employ the learned SC-Seq2Seq model to generate responses at different specificity levels by varying the control variable s. In this way, we can simulate human conversations where one can actively control the response specificity depending on his/her own mind.
115	25	If we want the agent to be more dynamic, we can sample s within the range [0,1] to enrich the styles in the response.
149	30	For each model, given a test utterance, we vary the control variable s by setting it to five different values (i.e., 0, 0.2, 0.5, 0.8, 1) to check whether the learned model can actually achieve different specificity levels.
157	22	The results indicate that the max inverse word frequency in a response is a good distant label for the response specificity.
166	28	(4) By setting the control variable s to 1, our SC-Seq2SeqNIWF model can achieve the best specificity performance as evaluated by the distinct metrics.
167	28	By setting the control variable s to 0.5, our SC-Seq2SeqNIWF model can best fit the ground truth data as evaluated by the BLEU scores, Average and Extrema.
201	19	In these responses, we can find many informative words.
209	19	Furthermore, given some sampled target words, we also show the top-5 similar words based on cosine similarity under both representations in Table 6.
210	25	Again, we can see that the nearest neighbors of a same word are quite different under two representations.
211	25	Neighbors based on semantic representations are semantically related, while neighbors based on usage representations are not so related but with similar specificity levels.
212	44	We propose a novel controlled response generation mechanism to handle different utteranceresponse relationships in terms of specificity.
213	75	We introduce an explicit specificity control variable into the Seq2Seq model, which interacts with the usage representation of words to generate responses at different specificity levels.
214	43	Empirical results showed that our model can generate either general or specific responses, and significantly outperform state-of-the-art generation methods.

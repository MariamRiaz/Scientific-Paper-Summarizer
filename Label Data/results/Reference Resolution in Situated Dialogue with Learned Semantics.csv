0,1,label2,summary_sentences
"Deep neural networks achieve near-human accuracy on many perception tasks (He et al., 2016; Amodei et al., 2015).",1. Introduction,[0],[0]
"However, they lack robustness to small alterations of the inputs at test time (Szegedy et al., 2014).",1. Introduction,[0],[0]
"Indeed when presented with a corrupted image that is barely distinguishable from a legitimate one by a human, they can predict incorrect labels, with high-confidence.",1. Introduction,[0],[0]
"An adversary can design such so-called adversarial examples, by adding a small perturbation to a legitimate input to maximize the likelihood of an incorrect class under constraints on the magnitude of the perturbation (Szegedy et al., 2014; Goodfellow et al., 2015; Moosavi-Dezfooli et al., 2015; Pa-
1Facebook AI Research.",1. Introduction,[0],[0]
"Correspondence to: Moustapha Cisse <moustaphacisse@fb.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"pernot et al., 2016a).",1. Introduction,[0],[0]
"In practice, for a significant portion of inputs, a single step in the direction of the gradient sign is sufficient to generate an adversarial example (Goodfellow et al., 2015) that is even transferable from one network to another one trained for the same problem but with a different architecture (Liu et al., 2016; Kurakin et al., 2016).
",1. Introduction,[0.964843999330061],"['Besides reference resolution in situated dialogue, there is also a research direction in which machine learning models are used to learn the semantics of noun phrases in order to map noun phrases to objects in a related environment (Kennington and Schlangen, 2015; Liang et al., 2009; Naim et al., 2014; Kushman et al., 2014).']"
The existence of transferable adversarial examples has two undesirable corollaries.,1. Introduction,[0],[0]
"First, it creates a security threat for production systems by enabling black-box attacks (Papernot et al., 2016a).",1. Introduction,[0],[0]
"Second, it underlines the lack of robustness of neural networks and questions their ability to generalize in settings where the train and test distributions can be (slightly) different as is the case for the distributions of legitimate and adversarial examples.
",1. Introduction,[0.9510668325659191],"['As Section 3.2 describes, dialogue and task history are used to filter the objects in the environment to build a candidate list of referents, and then as Section 3.3 describes, a ranking-based classification approach is used to select the best matching referent.']"
"Whereas the earliest works on adversarial examples already suggested that their existence was related to the magnitude of the hidden activations gradient with respect to their inputs (Szegedy et al., 2014), they also empirically assessed that standard regularization schemes such as weight decay or training with random noise do not solve the problem (Goodfellow et al., 2015; Fawzi et al., 2016).",1. Introduction,[0],[0]
The current mainstream approach to improving the robustness of deep networks is adversarial training.,1. Introduction,[0],[0]
"It consists in generating adversarial examples on-line using the current network’s parameters (Goodfellow et al., 2015; Miyato et al., 2015; Moosavi-Dezfooli et al., 2015; Szegedy et al., 2014; Kurakin et al., 2016) and adding them to the training data.",1. Introduction,[0],[0]
"This data augmentation method can be interpreted as a robust optimization procedure (Shaham et al., 2015).
",1. Introduction,[0],[0]
"In this paper, we introduce Parseval networks, a layerwise regularization method for reducing the network’s sensitivity to small perturbations by carefully controlling its global Lipschitz constant.",1. Introduction,[0],[0]
"Since the network is a composition of functions represented by its layers, we achieve increased robustness by maintaining a small Lipschitz constant (e.g., 1) at every hidden layer; be it fully-connected, convolutional or residual.",1. Introduction,[0],[0]
"In particular, a critical quantity governing the local Lipschitz constant in both fully connected and convolutional layers is the spectral norm of the weight matrix.",1. Introduction,[0],[0]
"Our main idea is to control this norm by parameterizing the network with parseval tight frames (Kovačević & Chebira, 2008), a generalization of orthogonal matrices.
",1. Introduction,[0],[0]
"The idea that regularizing the spectral norm of each weight
matrix could help in the context of robustness appeared as early as (Szegedy et al., 2014), but no experiment nor algorithm was proposed, and no clear conclusion was drawn on how to deal with convolutional layers.",1. Introduction,[0],[0]
"Previous work, such as double backpropagation (Drucker & Le Cun, 1992) has also explored jacobian normalization as a way to improve generalization.",1. Introduction,[0],[0]
Our contribution is twofold.,1. Introduction,[0],[0]
"First, we provide a deeper analysis which applies to fully connected networks, convolutional networks, as well as Residual networks (He et al., 2016).",1. Introduction,[0],[0]
"Second, we propose a computationally efficient algorithm and validate its effectiveness on standard benchmark datasets.",1. Introduction,[0],[0]
"We report results on MNIST, CIFAR-10, CIFAR-100 and Street View House Numbers (SVHN), in which fully connected and wide residual networks were trained (Zagoruyko & Komodakis, 2016) with Parseval regularization.",1. Introduction,[0],[0]
"The accuracy of Parseval networks on legitimate test examples matches the state-of-the-art, while the results show notable improvements on adversarial examples.",1. Introduction,[0],[0]
"Besides, Parseval networks train significantly faster than their vanilla counterpart.
",1. Introduction,[0],[0]
"In the remainder of the paper, we first discuss the previous work on adversarial examples.",1. Introduction,[0],[0]
"Next, we give formal definitions of the adversarial examples and provide an analysis of the robustness of deep neural networks.",1. Introduction,[0],[0]
"Then, we introduce Parseval networks and its efficient training algorithm.",1. Introduction,[0],[0]
Section 5 presents experimental results validating the model and providing several insights.,1. Introduction,[0],[0]
"Early papers on adversarial examples attributed the vulnerability of deep networks to high local variations (Szegedy et al., 2014; Goodfellow et al., 2015).",2. Related work,[0],[0]
"Some authors argued that this sensitivity of deep networks to small changes in their inputs is because neural networks only learn the discriminative information sufficient to obtain good accuracy rather than capturing the true concepts defining the classes (Fawzi et al., 2015; Nguyen et al., 2015).
",2. Related work,[0],[0]
"Strategies to improve the robustness of deep networks include defensive distillation (Papernot et al., 2016b), as well as various regularization procedures such as contractive networks (Gu & Rigazio, 2015).",2. Related work,[0],[0]
"However, the bulk of recent proposals relies on data augmentation (Goodfellow et al., 2015; Miyato et al., 2015; Moosavi-Dezfooli et al., 2015; Shaham et al., 2015; Szegedy et al., 2014; Kurakin et al., 2016).",2. Related work,[0],[0]
It uses adversarial examples generated online during training.,2. Related work,[0],[0]
"As we shall see in the experimental section, regularization can be complemented with data augmentation; in particular, Parseval networks with data augmentation appear more robust than either data augmentation or Parseval networks considered in isolation.",2. Related work,[0],[0]
"We consider a multiclass prediction setting, where we have Y classes in Y = {1, ..., Y }.",3. Robustness in Neural Networks,[0],[0]
"A multiclass classifier is a function ĝ : (x ∈ RD,W ∈ W) 7→ argmaxȳ∈Y",3. Robustness in Neural Networks,[0],[0]
"gȳ(x,W ), where W are the parameters to be learnt, and gȳ(x,W ) is the score given to the (input, class) pair (x, ȳ) by a function g :",3. Robustness in Neural Networks,[0],[0]
RD × W → RY .,3. Robustness in Neural Networks,[0],[0]
"We take g to be a neural network, represented by a computation graph G = (N , E), which is a directed acyclic graph with a single root node, and each node n ∈ N takes values in Rd (n) out and is a function of its children in the graph, with learnable parameters W (n):
n : x 7→ φ(n) ( W (n), ( n′(x) )",3. Robustness in Neural Networks,[0],[0]
"n′:(n,n′)∈E ) .",3. Robustness in Neural Networks,[0],[0]
"(1)
The function g we want to learn is the root of G. The training data ((xi, yi))mi=1 ∈",3. Robustness in Neural Networks,[0],[0]
"(X × Y)m is an i.i.d. sample of D, and we assume X ⊂",3. Robustness in Neural Networks,[0],[0]
RD is compact.,3. Robustness in Neural Networks,[0],[0]
"A function ` : RY × Y → R measures the loss of g on an example (x, y); in a single-label classification setting for instance, a common choice for ` is the log-loss:
` ( g(x,W ), y ) = −gy(x,W ) + log (∑ ȳ∈Y egȳ(x,W ) ) .",3. Robustness in Neural Networks,[0],[0]
"(2)
The arguments that we develop below depend only on the Lipschitz constant of the loss, with respect to the norm of interest.",3. Robustness in Neural Networks,[0],[0]
"Formally, we assume that given a p-norm of interest ‖.‖p, there is a constant λp such that
∀z, z′ ∈ RY ,∀ȳ ∈ Y, |`(z, ȳ)−`(z′, ȳ)| ≤",3. Robustness in Neural Networks,[0],[0]
"λp‖z−z′‖p .
",3. Robustness in Neural Networks,[0],[0]
"For the log-loss of (2), we have λ2 ≤ √
2 and λ∞ ≤ 2.",3. Robustness in Neural Networks,[0],[0]
"In the next subsection, we define adversarial examples and the generalization performance of the classifier.",3. Robustness in Neural Networks,[0],[0]
"Then, we make the relationship between robustness to adversarial examples and the lipschitz constant of the networks.",3. Robustness in Neural Networks,[0],[0]
"Given an input (train or test) example (x, y), an adversarial example is a perturbation of the input pattern x̃ = x",3.1. Adversarial examples,[0],[0]
"+ δx where δx is small enough so that x̃ is nearly undistinguishable from x (at least from the point of view of a human annotator), but has the network predict an incorrect label.",3.1. Adversarial examples,[0],[0]
"Given the network parameters and structure g(.,W ) and a p-norm, the adversarial example is formally defined as
x̃ = argmax x̃:‖x̃−x‖p≤
` ( g(x̃,W ), y ) , (3)
where represents the strength of the adversary.",3.1. Adversarial examples,[0],[0]
"Since the optimization problem above is non-convex, Shaham et al. (2015) propose to take the first order taylor expansion of x 7→ `(g(x,W ), y) to compute δx by solving
x̃ = argmax x̃:‖x̃−x‖p≤
( ∇x`(g(x,W ), y) )",3.1. Adversarial examples,[0],[0]
T (x̃− x) .,3.1. Adversarial examples,[0],[0]
"(4)
If p = ∞, then x̃ = x + sign(∇x`(g(x,W ), y)).",3.1. Adversarial examples,[0],[0]
This is the fast gradient sign method.,3.1. Adversarial examples,[0],[0]
"For the case p = 2, we obtain x̃ = x + ∇x`(g(x,W ), y).",3.1. Adversarial examples,[0],[0]
"A more involved method is the iterative fast gradient sign method, in which several gradient steps of (4) are performed with a smaller stepsize to obtain a local minimum of (3).",3.1. Adversarial examples,[0],[0]
"In the context of adversarial examples, there are two different generalization errors of interest:
L(W )",3.2. Generalization with adversarial examples,[0],[0]
"= E (x,y)∼D
[ `(g(x,W ), y) ] ,
Ladv(W,p, ) =",3.2. Generalization with adversarial examples,[0],[0]
"E (x,y)∼D
[ max
x̃:‖x̃−x‖p≤ `(g(x̃,W ), y)
] .
",3.2. Generalization with adversarial examples,[0],[0]
"By definition, L(W )",3.2. Generalization with adversarial examples,[0],[0]
"≤ Ladv(W,p, ) for every p and >0.",3.2. Generalization with adversarial examples,[0],[0]
"Reciprocally, denoting by λp and Λp the Lipschitz constant (with respect to ‖.‖p) of ` and g respectively, we have:
Ladv(W,p, ) ≤ L(W )",3.2. Generalization with adversarial examples,[0],[0]
+,3.2. Generalization with adversarial examples,[0],[0]
"E
(x,y)∼D
[ max
x̃:‖x̃−x‖p≤ |`(g(x̃,W ), y)− `(g(x,W ), y)| ] ≤ L(W ) +",3.2. Generalization with adversarial examples,[0],[0]
"λpΛp .
",3.2. Generalization with adversarial examples,[0],[0]
This suggests that the sensitivity to adversarial examples can be controlled by the Lipschitz constant of the network.,3.2. Generalization with adversarial examples,[0],[0]
"In the robustness framework of (Xu & Mannor, 2012), the Lipschitz constant also controls the difference between the average loss on the training set and the generalization performance.",3.2. Generalization with adversarial examples,[0],[0]
"More precisely, let us denote by Cp(X , γ) the covering number of X using γ-balls for ‖.‖p.",3.2. Generalization with adversarial examples,[0],[0]
"Using M = supx,W,y `(g(x,W ), y), Theorem 3 of (Xu & Mannor, 2012) implies that for every δ ∈ (0, 1), with probability 1− δ over the i.i.d. sample ((xi, yi)mi=1, we have:
L(W )",3.2. Generalization with adversarial examples,[0],[0]
≤ 1 m m∑ i=1,3.2. Generalization with adversarial examples,[0],[0]
"`(g(xi,W ), yi)
+ λpΛpγ",3.2. Generalization with adversarial examples,[0],[0]
"+M
√ 2Y Cp(X , γ2 )",3.2. Generalization with adversarial examples,[0],[0]
"ln(2)− 2 ln(δ)
m .
",3.2. Generalization with adversarial examples,[0],[0]
"Since covering numbers of a p-norm ball in RD increases exponentially with RD, the bound above suggests that it is critical to control the Lipschitz constant of g, for both good generalization and robustness to adversarial examples.",3.2. Generalization with adversarial examples,[0],[0]
"From the network structure we consider (1), for every node n ∈",3.3. Lipschitz constant of neural networks,[0],[0]
"N , we have (see below for the definition of Λ(n,n ′) p ):
",3.3. Lipschitz constant of neural networks,[0],[0]
"‖n(x)− n(x̃)‖p ≤ ∑
n′:(n,n′)∈E
Λ(n,n ′) p ‖n′(x)− n′(x̃)‖p ,
for any Λ(n,n ′)
p that is greater than the worst case variation of n with respect to a change in its input n′(x).",3.3. Lipschitz constant of neural networks,[0],[0]
"In particular we can take for Λ(n,n ′)",3.3. Lipschitz constant of neural networks,[0],[0]
"p any value greater than the
supremum over x0 ∈ X of the Lipschitz constant for ‖.‖p of the function (1n′′ = n′ is 1 if n′′ = n′ and 0 otherwise):
x 7→ φ(n) ( W (n), ( n′′(x0+1n ′′ = n′(x−x0)) )",3.3. Lipschitz constant of neural networks,[0],[0]
"n′′:(n,n′′)∈E ) .
",3.3. Lipschitz constant of neural networks,[0],[0]
"The Lipschitz constant of n, denoted by Λ(n)p satisfies:
Λ(n)p ≤ ∑
n′:(n,n′)∈E
Λ(n,n ′) p Λ (n′) p (5)
",3.3. Lipschitz constant of neural networks,[0],[0]
"Thus, the Lipschitz constant of the network g can grow exponentially with its depth.",3.3. Lipschitz constant of neural networks,[0],[0]
"We now give the Lipschitz constants of standard layers as a function of their parameters:
Linear layers: For layer n(x) = W (n)n′(x) where n′ is the unique child of n in the graph, the Lipschitz constant for ‖.‖p is, by definition, the matrix norm of W (n) induced by ‖.‖p, which is usually denoted ‖W (n)‖p and defined by
‖W (n)‖p = sup z:‖z‖p=1 ‖W (n)z‖p .
",3.3. Lipschitz constant of neural networks,[0],[0]
"Then Λ(n)2 = ‖W (n)‖2Λ (n′) 2 , where ‖W (n)‖2, called the spectral norm of W (n), is the maximum singular value of W (n).",3.3. Lipschitz constant of neural networks,[0],[0]
"We also have Λ(n)∞ = ‖W (n)‖∞Λ(n ′) ∞ , where
‖W (n)‖∞ = maxi ∑ j |W (n)",3.3. Lipschitz constant of neural networks,[0],[0]
ij,3.3. Lipschitz constant of neural networks,[0],[0]
| is the maximum 1-norm of the rows.,3.3. Lipschitz constant of neural networks,[0],[0]
"W (n).
",3.3. Lipschitz constant of neural networks,[0],[0]
"Convolutional layers: To simplify notation, let us consider convolutions on 1D inputs without striding, and we take the width of the convolution to be 2k + 1 for k ∈ N. To write convolutional layers in the same way as linear layers, we first define an unfolding operator U , which prepares the input z, denoted by U(z).",3.3. Lipschitz constant of neural networks,[0],[0]
"If the input has length T with din inputs channels, the unfolding operator maps z",3.3. Lipschitz constant of neural networks,[0],[0]
"For a convolution of the unfolding of z considered as a T × (2k + 1)din matrix, its j-th column is:
Uj(z) =",3.3. Lipschitz constant of neural networks,[0],[0]
"[zj−k; ...; zj+k] ,
where “;” is the concatenation along the vertical axis (each zi is seen as a column din-dimensional vector), and zi",3.3. Lipschitz constant of neural networks,[0],[0]
= 0,3.3. Lipschitz constant of neural networks,[0],[0]
if i is out of bounds (0-padding).,3.3. Lipschitz constant of neural networks,[0],[0]
"A convolutional layer with dout output channels is then defined as
n(x) =",3.3. Lipschitz constant of neural networks,[0],[0]
"W (n) ∗ n′(x) = W (n)U(n′(x)) ,
where W (n) is a dout × (2k + 1)din matrix.",3.3. Lipschitz constant of neural networks,[0],[0]
"We thus have Λ
(n) 2 ≤ ‖W‖2‖U(n′(x))‖2.",3.3. Lipschitz constant of neural networks,[0],[0]
"Since U is a linear operator that essentially repeats its input (2k + 1) times, we have ‖U(n′(x))",3.3. Lipschitz constant of neural networks,[0],[0]
− U(n′(x̃))‖22 ≤ (2k + 1)‖n′(x),3.3. Lipschitz constant of neural networks,[0],[0]
"− n′(x̃)‖22, so that Λ(n)2 ≤ √ 2k + 1‖W‖2Λ(n ′) 2 .",3.3. Lipschitz constant of neural networks,[0],[0]
"Also, ‖U(n′(x))",3.3. Lipschitz constant of neural networks,[0],[0]
"− U(n′(x̃))‖∞ = ‖n′(x) − n′(x̃)‖∞, and so for a convolutional layer, Λ(n)∞ ≤ ‖W (n)‖∞Λ(n ′) ∞ .
",3.3. Lipschitz constant of neural networks,[0],[0]
"Aggregation layers/transfer functions: Layers that perform the sum of their inputs, as in Residual Netowrks (He et al., 2016), fall in the case where the values Λ(n,n ′) p in (5) come into play.",3.3. Lipschitz constant of neural networks,[0],[0]
"For a node n that sums its inputs, we have Λ (n,n′) p = 1, and thus Λ (n) p ≤ ∑ n′:(n,n′)∈E Λ (n′) p .",3.3. Lipschitz constant of neural networks,[0],[0]
"If n is a tranfer function layer (e.g., an element-wise application of ReLU)",3.3. Lipschitz constant of neural networks,[0],[0]
"we can check that Λ(n)p ≤ Λ(n ′) p , where n′ is the input node, as soon as the Lipschitz constant of the transfer function (as a function R→ R) is ≤ 1.",3.3. Lipschitz constant of neural networks,[0],[0]
"Parseval regularization, which we introduce in this section, is a regularization scheme to make deep neural networks robust, by constraining the Lipschitz constant (5) of each hidden layer to be smaller than one, assuming the Lipschitz constant of children nodes is smaller than one.",4. Parseval networks,[0],[0]
"That way, we avoid the exponential growth of the Lipschitz constant, and a usual regularization scheme (i.e., weight decay) at the last layer then controls the overall Lipschitz constant of the network.",4. Parseval networks,[0],[0]
"To enforce these constraints in practice, Parseval networks use two ideas: maintaining orthonormal rows in linear/convolutional layers, and performing convex combinations in aggregation layers.",4. Parseval networks,[0],[0]
"Below, we first explain the rationale of these constraints and then describe our approach to efficiently enforce the constraints during training.",4. Parseval networks,[0],[0]
"Orthonormality of weight matrices: For linear layers, we need to maintain the spectral norm of the weight matrix at 1.",4.1. Parseval Regularization,[0],[0]
Computing the largest singular value of weight matrices is not practical in an SGD setting unless the rows of the matrix are kept orthogonal.,4.1. Parseval Regularization,[0],[0]
"For a weight matrix W ∈ Rdout×din with dout ≤ din, Parseval regularization maintains WTW",4.1. Parseval Regularization,[0],[0]
"≈ Idout×dout , where I refers to the identity matrix.",4.1. Parseval Regularization,[0],[0]
"W is then approximately a Parseval tight frame (Kovačević & Chebira, 2008), hence the name of Parseval networks.",4.1. Parseval Regularization,[0],[0]
"For convolutional layers, the matrix W ∈ Rdout×(2k+1)din is constrained to be a Parseval tight frame (with the notations of the previous section), and the output is rescaled by a factor (2k + 1)−1/2.",4.1. Parseval Regularization,[0],[0]
"This maintains all singular values of W to (2k+ 1)−1/2, so that Λ
(n) 2 ≤ Λ (n′) 2 where n
′ is the input node.",4.1. Parseval Regularization,[0],[0]
"More generally, keeping the rows of weight matrices orthogonal makes it possible to control both the spectral norm and the ‖.‖∞ of a weight matrix through the norm of its individual rows.",4.1. Parseval Regularization,[0.9573550322755929],"['We segment referring expressions and label the semantics of each segment using the CRF and the result is a set of segments, each of which represents some attribute of its referent.']"
Robustness for ‖.‖∞ is achieved by rescaling the rows so that their 1-norm is smaller than 1.,4.1. Parseval Regularization,[0],[0]
"For now, we only experimented with constraints on the 2-norm of the rows, so we aim for robustness in the sense of ‖.‖2.
",4.1. Parseval Regularization,[0],[0]
Remark 1 (Orthogonality is required).,4.1. Parseval Regularization,[0],[0]
"Without orthogonality, constraints on the 2-norm of the rows of weight ma-
trices are not sufficient to control the spectral norm.",4.1. Parseval Regularization,[0],[0]
"Parseval networks are thus fundamentally different from weight normalization (Salimans & Kingma, 2016).
",4.1. Parseval Regularization,[0],[0]
Aggregation Layers:,4.1. Parseval Regularization,[0],[0]
"In parseval networks, aggregation layers do not make the sum of their inputs, but rather take a convex combination of them:
n(x) = ∑
n′:(n,n′)∈E
α(n,n ′)n′(x)
with ∑ n′:(n,n′)∈E α (n,n′) = 1 and α(n,n ′) ≥ 0.",4.1. Parseval Regularization,[0],[0]
"The parameters α(n,n ′) are learnt, but using (5), these constraint guarantee that Λ(n)p ≤ 1 as soon as the children satisfy the inequality for the same p-norm.",4.1. Parseval Regularization,[0],[0]
Orthonormality constraints: The first significant difference between Parseval networks and its vanilla counterpart is the orthogonality constraint on the weight matrices.,4.2. Parseval Training,[0],[0]
"This requirement calls for an optimization algorithm on the manifold of orthogonal matrices, namely the Stiefel manifold.",4.2. Parseval Training,[0],[0]
"Optimization on matrix manifolds is a well-studied topic (see (Absil et al., 2009) for a comprehensive survey).",4.2. Parseval Training,[0],[0]
The simplest first-order geometry approaches consist in optimizing the unconstrained function of interest by moving in the direction of steepest descent (given by the gradient of the function) while at the same time staying on the manifold.,4.2. Parseval Training,[0],[0]
"To guarantee that we remain in the manifold after every parameter update, we need to define a retraction operator.",4.2. Parseval Training,[0],[0]
"There exist several pullback operators for embedded submanifolds such as the Stiefel manifold based for example on Cayley transforms (Absil et al., 2009).",4.2. Parseval Training,[0],[0]
"However, when learning the parameters of neural networks, these methods are computationally prohibitive.",4.2. Parseval Training,[0],[0]
"To overcome this difficulty, we use an approximate operator derived from the following layer-wise regularizer of weight matrices to ensure their parseval tightness (Kovačević & Chebira, 2008):
Rβ(Wk) =",4.2. Parseval Training,[0],[0]
"β
2 ‖W>k Wk − I‖22.
Optimizing Rβ(Wk) to convergence after every gradient descent step (w.r.t the main objective) guarantees us to stay on the desired manifold but this is an expensive procedure.",4.2. Parseval Training,[0],[0]
"Moreover, it may result in parameters that are far from the ones obtained after the main gradient update.",4.2. Parseval Training,[0],[0]
"We use two approximations to make the algorithm more efficient: First, we only do one step of descent on the function Rα(Wk).",4.2. Parseval Training,[0],[0]
The gradient of this regularization term is∇WkRβ(Wk) =,4.2. Parseval Training,[0],[0]
β(WkW > k − I)Wk.,4.2. Parseval Training,[0],[0]
"Consequently, after every main update we perform the following secondary update:
Wk ← (1 + β)Wk",4.2. Parseval Training,[0],[0]
"− βWkW>k Wk.
Algorithm 1 Parseval Training Θ = {Wk,αk}Kk=1, e← 0",4.2. Parseval Training,[0],[0]
"while e ≤ E do
Sample a minibatch {(xi, yi)}Bi=1.",4.2. Parseval Training,[0],[0]
"for k ∈ {1, . . .",4.2. Parseval Training,[0],[0]
",K} do
Compute the gradient:",4.2. Parseval Training,[0],[0]
"GWk ← ∇Wk`(Θ, {(xi, yi)}), Gαk ← ∇αk`(Θ, {(xi, yi)}).",4.2. Parseval Training,[0],[0]
Update the parameters: Wk ←Wk − ·GWk αk ← αk − ·Gαk .,4.2. Parseval Training,[0],[0]
"if hidden layer then
Sample a subset S of rows of Wk.",4.2. Parseval Training,[0],[0]
Projection: WS ← (1 + β)WS,4.2. Parseval Training,[0],[0]
− βWSW>S WS .,4.2. Parseval Training,[0],[0]
αk ← argminγ∈∆K−1‖αK,4.2. Parseval Training,[0],[0]
"− γ‖22
e← e+ 1.
Optionally, instead of updating the whole matrix, one can randomly select a subset S of rows and perform the update from Eq.",4.2. Parseval Training,[0],[0]
(4.2) on the submatrix composed of rows indexed by S. This sampling based approach reduces the overall complexity to O(|S|2d).,4.2. Parseval Training,[0],[0]
"Provided the rows are carefully sampled, the procedure is an accurate Monte Carlo approximation of the regularizer loss function (Drineas et al., 2006).",4.2. Parseval Training,[0],[0]
"The optimal sampling probabilities, also called statistical leverages are approximately equal if we start from an orthogonal matrix and (approximately) stay on the manifold throughout the optimization since they are proportional to the eigenvalues of W (Mahoney et al., 2011).",4.2. Parseval Training,[0],[0]
"Therefore, we can sample a subset of columns uniformly at random when applying this projection step.
",4.2. Parseval Training,[0],[0]
"While the full update does not result in an increased overhead for convolutional layers, the picture can be very different for large fully connected layers making the sampling approach computationally more appealing for such layers.",4.2. Parseval Training,[0],[0]
We show in the experiments that the weight matrices resulting from this procedure are (quasi)-orthogonal.,4.2. Parseval Training,[0],[0]
"Also, note that quasi-orthogonalization procedures similar to the one described here have been successfully used previously in the context of learning overcomplete representations with independent component analysis (Hyvärinen & Oja, 2000).
",4.2. Parseval Training,[0],[0]
"Convexity constraints in aggregation layers: In Parseval networks, aggregation layers output a convex combination of their inputs instead of e.g., their sum as in Residual networks (He et al., 2016).",4.2. Parseval Training,[0],[0]
"For an aggregation node n of the network, let us denote by α = (α(n,n
′))n′:(n,n′)∈E the K-size vector of coefficients used for the convex combination output by the layer.",4.2. Parseval Training,[0],[0]
"To ensure that the Lipschitz constant at the node n is such that Λ(n)p ≤ 1, the constraints of 4.1 call for a euclidean projection of α onto the positive simplex after a gradient update:
α∗ = argmin γ∈∆K−1 ‖α− γ‖22 ,
where ∆K−1 = {γ ∈ RK |1>γ = 1,γ ≥ 0}.",4.2. Parseval Training,[0],[0]
"This is a well studied problem (Michelot, 1986; Pardalos & Kovoor, 1990; Duchi et al., 2008; Condat, 2016).",4.2. Parseval Training,[0],[0]
"Its solution is of the form: α∗i = max(0, αi − τ(α)), with τ : RK → R the unique function satisfying ∑ i(xi − τ(α))",4.2. Parseval Training,[0],[0]
= 1 for every x ∈ RK .,4.2. Parseval Training,[0],[0]
"Therefore, the solution essentially boils down to a soft thresholding operation.",4.2. Parseval Training,[0],[0]
If we denote α1 ≥ α2 ≥ . . .,4.2. Parseval Training,[0],[0]
"αK the sorted coefficients and k(α) = max{k ∈ (1, . . .",4.2. Parseval Training,[0],[0]
",K)|1+kαk > ∑ j≤k αj}, the optimal thresholding is given by (Duchi et al., 2008):
τ(α) =",4.2. Parseval Training,[0],[0]
"( ∑ j≤k(α) αj)− 1 k(α)
",4.2. Parseval Training,[0],[0]
"Consequently, the complexity of the projection is O(K log(K))",4.2. Parseval Training,[0],[0]
since it is only dominated by the sorting of the coefficients and is typically cheap because aggregation nodes will only have few children in practice (e.g. 2).,4.2. Parseval Training,[0],[0]
"If the number of children is large, there exist efficient linear time algorithms for finding the optimal thresholding τ(α) (Michelot, 1986; Pardalos & Kovoor, 1990; Condat, 2016).",4.2. Parseval Training,[0],[0]
"In this work, we use the method detailed above (Duchi et al., 2008) to perform the projection of the coefficient α after every gradient update step.",4.2. Parseval Training,[0],[0]
"We evaluate the effectiveness of Parseval networks on well-established image classification benchmark datasets namely MNIST, CIFAR-10, CIFAR-100 (Krizhevsky, 2009) and Street View House Numbers (SVHN) (Netzer et al.).",5. Experimental evaluation,[0],[0]
We train both fully connected networks and wide residual networks.,5. Experimental evaluation,[0],[0]
"The details of the datasets, the models, and the training routines are summarized below.",5. Experimental evaluation,[0],[0]
CIFAR.,5.1. Datasets,[0],[0]
Each of the CIFAR datasets is composed of 60K natural scene color images of size 32 × 32 split between 50K training images and 10K test images.,5.1. Datasets,[0],[0]
CIFAR-10 and CIFAR-100 have respectively 10 and 100 classes.,5.1. Datasets,[0],[0]
"For these two datasets, we adopt the following standard preprocessing and data augmentation scheme (Lin et al., 2013;",5.1. Datasets,[0],[0]
"He et al., 2016; Huang et al., 2016a; Zagoruyko & Komodakis, 2016): Each training image is first zero-padded with 4 pixels on each side.",5.1. Datasets,[0],[0]
The resulting image is randomly cropped to produce a new 32 × 32 image which is subsequently horizontally flipped with probability 0.5.,5.1. Datasets,[0],[0]
We also normalize every image with the mean and standard deviation of its channels.,5.1. Datasets,[0],[0]
"Following the same practice as (Huang et al., 2016a), we initially use 5K images from the training as a validation set.",5.1. Datasets,[0],[0]
"Next, we train de novo the best model on the full set of 50K images and report the results on the test set.",5.1. Datasets,[0],[0]
SVHN The Street View House Number dataset is a set of 32× 32 color digit images officially split into 73257 training images and 26032 test images.,5.1. Datasets,[0],[0]
"Following common practice (Zagoruyko & Komodakis, 2016; He et al., 2016; Huang et al., 2016a;b), we randomly sample 10000 images from the available extra set of about 600K images as a validation set and combine the rest of the pictures with the official training set.",5.1. Datasets,[0],[0]
We divide the pixel values by 255 as a preprocessing step and report the test set performance of the best performing model on the validation set.,5.1. Datasets,[0],[0]
ConvNet Models.,5.2. Models and Implementation details,[0],[0]
"For the CIFAR and SVHN datasets, we trained wide residual networks (Zagoruyko & Komodakis, 2016) as they perform on par with standard resnets (He et al., 2016) while being faster to train thanks to a reduced depth.",5.2. Models and Implementation details,[0],[0]
We used wide resnets of depth 28 and width 10 for both CIFAR-10 and CIFAR-100.,5.2. Models and Implementation details,[0],[0]
For SVHN we used wide resnet of depth 16 and width 4.,5.2. Models and Implementation details,[0],[0]
"For each architecture, we compare Parseval networks with the vanilla model trained with standard regularization both in the adversarial and the non-adversarial training settings.
",5.2. Models and Implementation details,[0],[0]
ConvNet Training.,5.2. Models and Implementation details,[0],[0]
We train the networks with stochastic gradient descent using a momentum of 0.9.,5.2. Models and Implementation details,[0],[0]
"On CIFAR datasets, the initial learning rate is set to 0.1 and scaled by a factor of 0.2 after epochs 60, 120 and 160, for a total number of 200 epochs.",5.2. Models and Implementation details,[0],[0]
We used mini-batches of size 128.,5.2. Models and Implementation details,[0],[0]
"For SVHN, we trained the models with mini-batches of size 128 for 160 epochs starting with a learning rate of 0.01 and decreasing it by a factor of 0.1 at epochs 80 and 120.",5.2. Models and Implementation details,[0],[0]
"For all the vanilla models, we applied by default weight decay regularization (with parameter λ = 0.0005) together with batch normalization and dropout since this combination resulted in better accuracy and increased robustness in preliminary experiments.",5.2. Models and Implementation details,[0],[0]
"The dropout rate use
is 0.3 for CIFAR and 0.4 for SVHN.",5.2. Models and Implementation details,[0],[0]
"For Parseval regularized models, we choose the value of the retraction parameter to be β = 0.0003 for CIFAR datasets and β = 0.0001 for SVHN based on the performance on the validation set.",5.2. Models and Implementation details,[0],[0]
"In all cases, We also adversarially trained each of the models on CIFAR-10 and CIFAR-100 following the guidelines in (Goodfellow et al., 2015; Shaham et al., 2015; Kurakin et al., 2016).",5.2. Models and Implementation details,[0],[0]
"In particular, we replace 50% of the examples of every minibatch by their adversarially perturbed version generated using the one-step method to avoid label leaking (Kurakin et al., 2016).",5.2. Models and Implementation details,[0],[0]
"For each mini-batch, the magnitude of the adversarial perturbation is obtained by sampling from a truncated Gaussian centered at 0 with standard deviation 2.
Fully Connected Model.",5.2. Models and Implementation details,[0],[0]
We also train feedforward networks composed of 4 fully connected hidden layers of size 2048 and a classification layer.,5.2. Models and Implementation details,[0],[0]
The input to these networks are images unrolled into a C × 1024 dimensional vector where C is the number of channels.,5.2. Models and Implementation details,[0],[0]
We used these models on MNIST and CIFAR-10 mainly to demonstrate that the proposed approach is also useful on non-convolutional networks.,5.2. Models and Implementation details,[0],[0]
We compare a Parseval networks to vanilla models with and without weight decay regularization.,5.2. Models and Implementation details,[0],[0]
"For adversarially trained models, we follow the guidelines previously described for the convolutional networks.
",5.2. Models and Implementation details,[0],[0]
Fully Connected Training.,5.2. Models and Implementation details,[0],[0]
We train the models with SGD and divide the learning rate by two every 10 epochs.,5.2. Models and Implementation details,[0],[0]
We use mini-batches of size 100 and train the model for 50 epochs.,5.2. Models and Implementation details,[0],[0]
We chose the hyperparameters on the validation set and retrain the model on the union of the training and validation sets.,5.2. Models and Implementation details,[0],[0]
"The hyperparameters are β, the size of the row subset S, the learning rate and its decrease rate.",5.2. Models and Implementation details,[0],[0]
Using a subset S of 30% of all the rows of each of weight matrix for the retraction step worked well in practice.,5.2. Models and Implementation details,[0],[0]
We first validate that Parseval training (Algorithm 1) indeed yields (near)-orthonormal weight matrices.,5.3.1. (QUASI)-ORTHOGONALITY.,[0],[0]
"To do so, we analyze the spectrum of the weight matrices of the different models by plotting the histograms of their singular values, and compare these histograms for Parseval networks to networks trained using standard SGD with and without weight decay (SGD-wd and SGD).
",5.3.1. (QUASI)-ORTHOGONALITY.,[0],[0]
The histograms representing the distribution of singular values at layers 1 and 4 for the fully connected network (using S = 30%) trained on the dataset CIFAR-10 are shown in Fig. 2 (the figures for convolutional networks are similar).,5.3.1. (QUASI)-ORTHOGONALITY.,[0],[0]
The singular values obtained with our method are tightly concentrated around 1.,5.3.1. (QUASI)-ORTHOGONALITY.,[0],[0]
"This experiment confirms that the weight matrices produced by the proposed opti-
mization procedure are (almost) orthonormal.",5.3.1. (QUASI)-ORTHOGONALITY.,[0],[0]
"The distribution of the singular values of the weight matrices obtained with SGD has a lot more variance, with nearly as many small values as large ones.",5.3.1. (QUASI)-ORTHOGONALITY.,[0],[0]
"Adding weight decay to standard SGD leads to a sparse spectrum for the weight matrices, especially in the higher layers of the network suggesting a low-rank structure.",5.3.1. (QUASI)-ORTHOGONALITY.,[0],[0]
"This observation has motivated recent work on compressing deep neural networks (Denton et al., 2014).",5.3.1. (QUASI)-ORTHOGONALITY.,[0],[0]
"We evaluate the robustness of the models to adversarial noise by generating adversarial examples from the test set, for various magnitudes of the noise vector.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"Following common practice (Kurakin et al., 2016), we use the fast gradient sign method to generate the adversarial examples (using ‖.‖∞, see Section 3.1).",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"Since these adversarial examples transfer from one network to the other, the fast gradient sign method allows to benchmark the network for reasonable settings where the opponent does not know the network.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
We report the accuracy of each model as a function of the magnitude of the noise.,5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"To make the results easier to interpret, we compute the corresponding Signal to Noise Ratio (SNR).",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"For an input x and perturbation δx, the SNR is defined as SNR(x, δx) = 20 log10 ‖x‖2 ‖δx‖2 .",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"We show some adversarial examples in Fig. 1.
Fully Connected Nets.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
Figure 3 depicts a comparison of Parseval and vanilla networks with and without adversarial training at various noise levels.,5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"On both MNIST and CIFAR-10, Parseval networks consistently outperforms weight decay regularization.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"In addition, it is as robust as
adversarial training (SGD-wd-da) on CIFAR-10.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"Combining Parseval Networks and adversarial training results in the most robust method on MNIST.
ResNets.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"Table 1 summarizes the results of our experiments with wide residual Parseval and vanilla networks on CIFAR-10, CIFAR-100 and SVHN.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"In the table, we denote Parseval(OC) the Parseval network with orthogonality constraint and without using a convex combination in aggregation layers.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
Parseval indicates the configuration where both of the orthogonality and convexity constraints are used.,5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
We first observe that Parseval networks outperform vanilla ones on all datasets on the clean examples and match the state of the art performances on CIFAR-10 (96.28%) and SVHN (98.44%).,5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"On CIFAR-100, when we use Parseval wide Resnet of depth 40 instead of 28, we achieve an accuracy of 81.76%.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"In comparison, the best performance achieved by a vanilla wide resnet (Zagoruyko & Komodakis, 2016) and a pre-activation resnet (He et al., 2016) are respectively 81.12% and 77.29%.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"Therefore, our proposal is a useful regularizer for legitimate examples.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"Also note that in most cases, Parseval networks combining both the orthogonality constraint and the convexity constraint is superior to use the orthogonality constraint solely.
",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
The results presented in the table validate our most important claim: Parseval networks significantly improve the robustness of vanilla models to adversarial examples.,5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"When no adversarial training is used, the gap in accuracy be-
tween the two methods is significant (particularly in the high noise scenario).",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"For an SNR value of 40, the best Parseval network achieves 55.41% accuracy while the best vanilla model is at 44.62%.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"When the models are adversarially trained, Parseval networks remain superior to vanilla models in most cases.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"Interestingly, adversarial training only slightly improves the robustness of Parseval networks in low noise setting (e.g. SNR values of 45-50) and sometimes even deteriorates it (e.g. on CIFAR-10).",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"In contrast, combining adversarial training and Parseval networks is an effective approach in the high noise setting.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"This result suggests that thanks to the particular form of regularizer (controlling the Lipschitz constant of the network), Parseval networks achieves robustness to adversarial examples located in the immediate vicinity of each data point.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"Therefore, adversarial training only helps for adversarial examples found further away from the legitimate patterns.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"This observation holds consistently across all our datasets.
",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"Better use of capacity Given the distribution of singular values observed in Figure 2, we want to analyze the intrinsic dimensionality of the representation learned by the different networks at every layer.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0.9581375472156548],"['However, these prior approaches operated at the granularity of single of the corpus utilized in this work.']"
"To that end, we use the local covariance dimension (Dasgupta & Freund, 2008) which can be measured from the covariance matrix of the data.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"For each layer k of the fully connected network, we compute the activation’s empirical covariance matrix 1 n",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"∑n i=1 φk(x)φk(x)
",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
>,5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
and obtain its sorted eigenvalues σ1 ≥ · · · ≥ σd.,5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"For each method and each layer, we select the smallest integer p such that ∑p i=1",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
σi ≥ 0.99 ∑d i=1,5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
σi.,5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
This gives us the number of dimensions that we need to explain 99% of the covariance.,5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"We can also compute the same quantity for the examples of each class, by only considering in the empirical estimation of the covariance of the examples xi such that yi = c. Table 2 report these numbers for all examples and the per-class average on CIFAR-10.
Table 2 shows that the local covariance dimension of all the data is consistently higher for Parseval networks than all the other approaches at any layer of the network.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"SGDwd-da contracts all the data in very low dimensional spaces at the upper levels of the network by using only 0.4% of the total dimension (layer 3 and 4) while Parseval networks use about 81% and 56% at of the whole dimension respectively
in the same layers.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"This is intriguing given that SGD-wd-da also increases the robustness of the network, apparently not in the same way as Parseval networks.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"For the average local covariance dimension of the classes, SGD-wd-da contracts each class into the same dimensionality as it contracts all the data at the upper layers of the network.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"For Parseval, the data of each class is contracted in about 30% and 19% of the overall dimension.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"These results suggest that Parseval contracts the data of each class in a lower dimensional manifold (compared to the intrinsic dimensionality of the whole data) hence making classification easier.
faster convergence Parseval networks converge significantly faster than vanilla networks trained with batch normalization and dropout as depicted by figure 4.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"Thanks to the orthogonalization step following each gradient update, the weight matrices are well conditioned at each step during the optimization.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
We hypothesize this is the main explanation of this phenomenon.,5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"For convolutional networks (resnets), the faster convergence is not obtained at the expense of larger wall-time since the cost of the projection step is negligible compared to the total cost of the forward pass on modern GPU architecture thanks to the small size of the filters.",5.3.2. ROBUSTNESS TO ADVERSARIAL NOISE.,[0],[0]
"We introduced Parseval networks, a new approach for learning neural networks that are intrinsically robust to adversarial noise.",6. Conclusion,[0],[0]
We proposed an algorithm that allows us to optimize the model efficiently.,6. Conclusion,[0],[0]
Empirical results on three classification datasets with fully connected and wide residual networks illustrate the performance of our approach.,6. Conclusion,[0],[0]
"As a byproduct of the regularization we propose, the model trains faster and makes a better use of its capacity.",6. Conclusion,[0],[0]
Further investigation of this phenomenon is left to future work.,6. Conclusion,[0],[0]
"The authors would like to thank M.A. Ranzato, Y. Tian, A. Bordes and F. Perronnin for their valuable feedback on this work.",Acknowledgements,[0],[0]
"We introduce Parseval networks, a form of deep neural networks in which the Lipschitz constant of linear, convolutional and aggregation layers is constrained to be smaller than 1.",abstractText,[0],[0]
Parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation.,abstractText,[0],[0]
"The most important feature of Parseval networks is to maintain weight matrices of linear and convolutional layers to be (approximately) Parseval tight frames, which are extensions of orthogonal matrices to non-square matrices.",abstractText,[0],[0]
We describe how these constraints can be maintained efficiently during SGD.,abstractText,[0],[0]
"We show that Parseval networks match the state-of-the-art in terms of accuracy on CIFAR-10/100 and Street View House Numbers (SVHN), while being more robust than their vanilla counterpart against adversarial examples.",abstractText,[0],[0]
"Incidentally, Parseval networks also tend to train faster and make a better usage of the full capacity of the networks.",abstractText,[0],[0]
Parseval Networks: Improving Robustness to Adversarial Examples,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2331–2336, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
We recast syntactic parsing as a language modeling problem and use recent advances in neural network language modeling to achieve a new state of the art for constituency Penn Treebank parsing — 93.8 F1 on section 23, using 2-21 as training, 24 as development, plus tri-training. When trees are converted to Stanford dependencies, UAS and LAS are 95.9% and 94.1%.",text,[0],[0]
"Recent work on deep learning syntactic parsing models has achieved notably good results, e.g., Dyer et al. (2016) with 92.4 F1 on Penn Treebank constituency parsing and Vinyals et al. (2015) with 92.8 F1.",1 Introduction,[0],[0]
"In this paper we borrow from the approaches of both of these works and present a neural-net parse reranker that achieves very good results, 93.8 F1, with a comparatively simple architecture.
",1 Introduction,[0],[0]
In the remainder of this section we outline the major difference between this and previous work — viewing parsing as a language modeling problem.,1 Introduction,[0],[0]
Section 2 looks more closely at three of the most relevant previous papers.,1 Introduction,[0],[0]
"We then describe our exact model (Section 3), followed by the experimental setup and results (Sections 4 and 5).",1 Introduction,[0],[0]
"Formally, a language model (LM) is a probability distribution over strings of a language:
P (x) = P (x1, · · · , xn)
=
n∏
t=1
P (xt|x1, · · · , xt−1), (1)
where x is a sentence and t indicates a word position.",1.1 Language Modeling,[0],[0]
"The efforts in language modeling go into computing P (xt|x1, · · · , xt−1), which as described next is useful for parsing as well.",1.1 Language Modeling,[0],[0]
"A generative parsing model parses a sentence (x) into its phrasal structure (y) according to
argmax y′∈Y(x)
P (x,y′),
where Y(x) lists all possible structures of x.",1.2 Parsing as Language Modeling,[0],[0]
"If we think of a tree (x,y) as a sequence (z) (Vinyals et
2331
al., 2015) as illustrated in Figure 1, we can define a probability distribution over (x,y) as follows:
P (x,y) = P (z) = P (z1, · · · , zm)
= m∏
t=1
P (zt|z1, · · · , zt−1), (2)
which is equivalent to Equation (1).",1.2 Parsing as Language Modeling,[0],[0]
"We have reduced parsing to language modeling and can use language modeling techniques of estimating P (zt|z1, · · · , zt−1) for parsing.",1.2 Parsing as Language Modeling,[0],[0]
We look here at three neural net (NN) models closest to our research along various dimensions.,2 Previous Work,[0],[0]
"The first (Zaremba et al., 2014) gives the basic language modeling architecture that we have adopted, while the other two (Vinyals et al., 2015; Dyer et al., 2016) are parsing models that have the current best results in NN parsing.",2 Previous Work,[0],[0]
"The LSTM-LM of Zaremba et al. (2014) turns (x1, · · · , xt−1) into ht, a hidden state of an LSTM (Hochreiter and Schmidhuber, 1997; Gers et al., 2003; Graves, 2013), and uses ht to guess xt:
P (xt|x1, · · · , xt−1) = P (xt|ht) = softmax(Wht)[xt],
where W is a parameter matrix and [i] indexes ith element of a vector.",2.1 LSTM-LM,[0],[0]
"The simplicity of the model makes it easily extendable and scalable, which has inspired a character-based LSTM-LM that works well for many languages (Kim et al., 2016) and an ensemble of large LSTM-LMs for English with astonishing perplexity of 23.7 (Jozefowicz et al., 2016).",2.1 LSTM-LM,[0],[0]
"In this paper, we build a parsing model based on the LSTM-LM of Zaremba et al. (2014).",2.1 LSTM-LM,[0],[0]
"Vinyals et al. (2015) observe that a phrasal structure (y) can be expressed as a sequence and build a machine translation parser (MTP), a sequence-tosequence model, which translates x into y using a
conditional probability:
P (y|x)",2.2 MTP,[0],[0]
"= P (y1, · · · , yl|x)
= l∏
t=1
P (yt|x, y1, · · · , yt−1),
where the conditioning event (x, y1, · · · , yt−1) is modeled by an LSTM encoder and an LSTM decoder.",2.2 MTP,[0],[0]
"The encoder maps x into he, a set of vectors that represents x, and the decoder obtains a summary vector (h′t) which is concatenation of the decoder’s hidden state (hdt ) and weighted sum of word representations ( ∑n i=1 αih e i ) with an alignment vector (α).",2.2 MTP,[0],[0]
Finally the decoder predicts yt given h′t.,2.2 MTP,[0],[0]
"Inspired by MTP, our model processes sequential trees.",2.2 MTP,[0],[0]
"Recurrent Neural Network Grammars (RNNG), a generative parsing model, defines a joint distribution over a tree in terms of actions the model takes to generate the tree (Dyer et al., 2016):
P (x,y) = P (a) =
m∏
t=1
P (at|a1, · · · , at−1), (3)
where a is a sequence of actions whose output precisely matches the sequence of symbols in z, which implies Equation (3) is the same as Equation (2).",2.3 RNNG,[0],[0]
"RNNG and our model differ in how they compute the conditioning event (z1, · · · , zt−1): RNNG combines hidden states of three LSTMs that keep track of actions the model has taken, an incomplete tree the model has generated and words the model has generated whereas our model uses one LSTM’s hidden state as shown in the next section.",2.3 RNNG,[0],[0]
"Our model, the model of Zaremba et al. (2014) applied to sequential trees and we call LSTM-LM from now on, is a joint distribution over trees:
P (x,y)",3 Model,[0],[0]
"= P (z) = m∏
t=1
P (zt|z1, · · · , zt−1)
=
m∏
t=1
P (zt|ht)
= m∏
t=1
softmax(Wht)[zt],
where ht is a hidden state of an LSTM.",3 Model,[0],[0]
"Due to lack of an algorithm that searches through an exponentially large phrase-structure space, we use an n-best parser to reduce Y(x) to Y ′(x), whose size is polynomial, and use LSTM-LM to find y that satisfies
argmax y′∈Y ′(x)
P (x,y′).",3 Model,[0],[0]
(4),3 Model,[0],[0]
"The model has three LSTM layers with 1,500 units and gets trained with truncated backpropagation through time with mini-batch size 20 and step size 50.",3.1 Hyper-parameters,[0],[0]
"We initialize starting states with previous minibatch’s last hidden states (Sutskever, 2013).",3.1 Hyper-parameters,[0],[0]
"The forget gate bias is initialized to be one (Jozefowicz et al., 2015) and the rest of model parameters are sampled from U(−0.05, 0.05).",3.1 Hyper-parameters,[0],[0]
"Dropout is applied to non-recurrent connections (Pham et al., 2014) and gradients are clipped when their norm is bigger than 20 (Pascanu et al., 2013).",3.1 Hyper-parameters,[0],[0]
"The learning rate is 0.25 · 0.85max( −15, 0) where is an epoch number.",3.1 Hyper-parameters,[0],[0]
"For simplicity, we use vanilla softmax over an entire vocabulary as opposed to hierarchical softmax (Morin and Bengio, 2005) or noise contrastive estimation (Gutmann and Hyvärinen, 2012).",3.1 Hyper-parameters,[0],[0]
"We describe datasets we use for evaluation, detail training and development processes.1",4 Experiments,[0],[0]
"We use the Wall Street Journal (WSJ) of the Penn Treebank (Marcus et al., 1993) for training (2-21), development (24) and testing (23) and millions of auto-parsed “silver” trees (McClosky et al., 2006; Huang et al., 2010; Vinyals et al., 2015) for tritraining.",4.1 Data,[0],[0]
"To obtain silver trees, we parse the entire section of the New York Times (NYT) of the fifth Gigaword (Parker et al., 2011) with a product of eight Berkeley parsers (Petrov, 2010)2 and ZPar (Zhu et al., 2013) and select 24 million trees on which both parsers agree (Li et al., 2014).",4.1 Data,[0],[0]
"We do not resample trees to match the sentence length distribution of the NYT to that of the WSJ (Vinyals et
1The code and trained models used for experiments are available at github.com/cdg720/emnlp2016.
",4.1 Data,[0],[0]
2We use the reimplementation by Huang et al. (2010).,4.1 Data,[0],[0]
"al., 2015) because in preliminary experiments Charniak parser (Charniak, 2000) performed better when trained on all of 24 million trees than when trained on resampled two million trees.
",500 97.0 91.8 40.0,[0],[0]
"Given x, we produce Y ′(x), 50-best trees, with Charniak parser and find y with LSTM-LM as Dyer et al. (2016) do with their discriminative and generative models.3",500 97.0 91.8 40.0,[0],[0]
"We unk words that appear fewer than 10 times in the WSJ training (6,922 types) and drop activations with probability 0.7.",4.2.1 Supervision,[0],[0]
"At the beginning of each epoch, we shuffle the order of trees in the training data.",4.2.1 Supervision,[0],[0]
Both perplexity and F1 of LSTM-LM (G) improve and then plateau (Figure 2).,4.2.1 Supervision,[0],[0]
"Perplexity, the
3Dyer et al. (2016)’s discriminative model performs comparably to Charniak (89.8 vs. 89.7).
model’s training objective, nicely correlates with F1, what we care about.",4.2.1 Supervision,[0],[0]
Training takes 12 hours (37 epochs) on a Titan X. We also evaluate our model with varying n-best trees including optimal 51-best trees that contain gold trees (51o).,4.2.1 Supervision,[0],[0]
"As shown in Table 1, the LSTM-LM (G) is robust given sufficiently large n, i.e. 50, but does not exhibit its full capacity because of search errors in Charniak parser.",4.2.1 Supervision,[0],[0]
We address this problem in Section 5.3.,4.2.1 Supervision,[0],[0]
"We unk words that appear at most once in the training (21,755 types).",4.2.2 Semi-supervision,[0],[0]
"We drop activations with probability 0.45, smaller than 0.7, thanks to many silver trees, which help regularization.",4.2.2 Semi-supervision,[0],[0]
"We train LSTM-LM (GS) on the WSJ and a different set of 400,000 NYT trees for each epoch except for the last one during which we use the WSJ only.",4.2.2 Semi-supervision,[0],[0]
Training takes 26 epochs and 68 hours on a Titan X. LSTMLM (GS) achieves 92.5 F1 on the development.,4.2.2 Semi-supervision,[0],[0]
"As shown in Table 2, with 92.6 F1 LSTM-LM (G) outperforms an ensemble of five MTPs (Vinyals et al., 2015) and RNNG (Dyer et al., 2016), both of which are trained on the WSJ only.",5.1 Supervision,[0],[0]
"We compare LSTM-LM (GS) to two very strong semi-supervised NN parsers: an ensemble of five MTPs trained on 11 million trees of the highconfidence corpus4 (HC) (Vinyals et al., 2015); and an ensemble of six one-to-many sequence models
4The HC consists of 90,000 gold trees, from the WSJ, English Web Treebank and Question Treebank, and 11 million silver trees, whose sentence length distribution matches that of the WSJ, parsed and agreed on by Berkeley parser and ZPar.
trained on the HC and 4.5 millions of EnglishGerman translation sentence pairs (Luong et al., 2016).",5.2 Semi-supervision,[0],[0]
We also compare LSTM-LM (GS) to best performing non-NN parsers in the literature.,5.2 Semi-supervision,[0],[0]
Parsers’ parsing performance along with their training data is reported in Table 3.,5.2 Semi-supervision,[0],[0]
LSTM-LM (GS) outperforms all the other parsers with 93.1 F1.,5.2 Semi-supervision,[0],[0]
"Due to search errors – good trees are missing in 50-best trees – in Charniak (G), our supervised and semi-supervised models do not exhibit their full potentials when Charniak (G) provides Y ′(x).",5.3 Improved Semi-supervision,[0],[0]
"To mitigate the search problem, we tri-train Charniak (GS) on all of 24 million NYT trees in addition to the WSJ, to yield Y ′(x).",5.3 Improved Semi-supervision,[0],[0]
"As shown in Table 3, both LSTM-LM (G) and LSTM-LM (GS) are affected by the quality of Y ′(x).",5.3 Improved Semi-supervision,[0],[0]
"A single LSTM-LM (GS) together with Charniak (GS) reaches 93.6 and an ensemble of eight LSTM-LMs (GS) with Charniak (GS) achieves a new state of the art, 93.8 F1.",5.3 Improved Semi-supervision,[0],[0]
"When trees are converted to Stanford dependencies,5 UAS and LAS are 95.9% and 94.1%,6 more than 1% higher than those of the state of the art dependency parser (Andor et al., 2016).",5.3 Improved Semi-supervision,[0],[0]
"Why an indirect method (converting trees to dependencies) is more accurate than a direct one (dependency parsing) remains unanswered (Kong and Smith, 2014).",5.3 Improved Semi-supervision,[0],[0]
The generative parsing model we presented in this paper is very powerful.,6 Conclusion,[0],[0]
"In fact, we see that a generative parsing model, LSTM-LM, is more effective than discriminative parsing models (Dyer et al., 2016).",6 Conclusion,[0],[0]
"We suspect building large models with character embeddings would lead to further improvement as in language modeling (Kim et al., 2016; Jozefowicz et al., 2016).",6 Conclusion,[0],[0]
We also wish to develop a complete parsing model using the LSTMLM framework.,6 Conclusion,[0],[0]
"We thank the NVIDIA corporation for its donation of a Titan X GPU, Tstaff of Computer Science
5Version 3.3.0.",Acknowledgments,[0],[0]
6We use the CoNLL evaluator available through the CoNLL website: ilk.uvt.nl/conll/software/eval.pl.,Acknowledgments,[0],[0]
"Following the convention, we ignore punctuation.
at Brown University for setting up GPU machines and David McClosky for helping us train Charniak parser on millions trees.",Acknowledgments,[0],[0]
"We recast syntactic parsing as a language modeling problem and use recent advances in neural network language modeling to achieve a new state of the art for constituency Penn Treebank parsing — 93.8 F1 on section 23, using 2-21 as training, 24 as development, plus tri-training.",abstractText,[0],[0]
"When trees are converted to Stanford dependencies, UAS and LAS are 95.9% and 94.1%.",abstractText,[0],[0]
Parsing as Language Modeling,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 69–81 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"While parsing has become a relatively mature technology for written text, parser performance on conversational speech lags behind.",1 Introduction,[0],[0]
"Speech poses challenges for parsing: transcripts may contain errors and lack punctuation; even perfect transcripts can be difficult to handle because of disfluencies (restarts, repetitions, and self-corrections), filled pauses (“um”, “uh”), interjections (“like”), parentheticals (“you know”, “I mean”), and sentence fragments.",1 Introduction,[0],[0]
"Some of these phenomena can be handled in standard grammars, but disfluencies typically require extensions of the model.",1 Introduction,[0],[0]
"Different approaches have been explored in both constituency parsing (Charniak and Johnson, 2001; Johnson and Charniak, 2004) and dependency parsing (Rasooli and Tetreault, 2013; Honnibal and Johnson, 2014).
∗Equal Contribution.
",1 Introduction,[0],[0]
"Despite these challenges, speech carries helpful extra information – beyond the words – associated with the prosodic structure of an utterance and encoded via variation in timing and intonation.",1 Introduction,[0],[0]
"Speakers pause in locations that are correlated with syntactic structure (Grosjean et al., 1979), and listeners use prosodic structure in resolving syntactic ambiguities (Price et al., 1991).",1 Introduction,[0],[0]
"Prosodic cues also signal disfluencies by marking the interruption point (Shriberg, 1994).",1 Introduction,[0],[0]
"However, most speech parsing systems in practice take little advantage of these cues.",1 Introduction,[0],[0]
"Our study focuses on this last challenge, aiming to incorporate prosodic cues in a neural parser, handling disfluencies as constituents via a neural attention mechanism.
",1 Introduction,[0],[0]
"A challenge of incorporating prosody in parsing is that multiple acoustic cues interact to signal prosodic structure, including pauses, lengthening, fundamental frequency modulation, and spectral shape.",1 Introduction,[0],[0]
"These cues also vary with the phonetic segment, emphasis, emotion and speaker, so feature extraction typically involves multiple time windows and normalization techniques.",1 Introduction,[0],[0]
"The most successful constituent parsers have mapped these features to prosodic boundary posteriors by using labeled training data (Kahn et al., 2005; Hale et al., 2006; Dreyer and Shafran, 2007).",1 Introduction,[0],[0]
The approach proposed here takes advantage of advances in neural networks to automatically learn a good feature representation without the need to explicitly represent prosodic constituents.,1 Introduction,[0.9515524894806069],['It is hoped that this line of investigation will enable rich natural language dialogue interactions to support users in a wide variety of complex situated tasks.']
"To narrow the scope of this work and facilitate error analysis, our experiments use known transcripts and sentence segmentation.
",1 Introduction,[0],[0]
Our work offers the following contributions.,1 Introduction,[0],[0]
We introduce a framework for directly integrating acoustic-prosodic features with text in a neural encoder-decoder parser that does not require handannotated prosodic structure.,1 Introduction,[0],[0]
"We demonstrate improvements in constituent parsing of conversational
69
speech over a high-quality text-only parser and provide analyses showing where prosodic features help and that assessment of their utility is affected by human transcription errors.",1 Introduction,[0],[0]
Our model maps a sequence of word-level input features to a linearized parse output sequence.,2 Task and Model Description,[0],[0]
"The word-level input feature vector consists of the concatenation of (learnable) word embeddings ei and several types of acoustic-prosodic features, described in Section 2.3.",2 Task and Model Description,[0],[0]
"We assume the availability of a training treebank of conversational speech (in our case, SwitchboardNXT (Calhoun et al., 2010)) and corresponding constituent parses.",2.1 Task Setup,[0],[0]
The transcriptions are preprocessed by removing punctuation and lower-casing all text to better mimic the speech recognition setting.,2.1 Task Setup,[0],[0]
"Following Vinyals et al. (2015), the parse trees are linearized, and pre-terminals are normalized as “XX” (see Appendix A.1).",2.1 Task Setup,[0],[0]
Our attention-based encoder-decoder model is similar to the one used by Vinyals et al. (2015).,2.2 Encoder-Decoder Parser,[0],[0]
"The encoder is a deep long short-term memory recurrent neural network (LSTM-RNN) (Hochreiter and Schmidhuber, 1997) that reads in a word-level inputs,1 represented as a sequence of vectors x = (x1, · · · ,xTs), and outputs high-level features h = (h1, · · · ,hTs) where hi = LSTM(xi,hi−1).2
",2.2 Encoder-Decoder Parser,[0],[0]
"The parse decoder is also a deep LSTM-RNN that predicts the linearized parse sequence y = (y1, · · · , yTo) as follows:
P (y|x) = To∏
t=1
P (yt|h,y<t)
",2.2 Encoder-Decoder Parser,[0],[0]
"In attention-based models, the posterior distribution of the output yt at time step t is given by:
P (yt|h,y<t) =",2.2 Encoder-Decoder Parser,[0],[0]
softmax(W s[ct;dt],2.2 Encoder-Decoder Parser,[0],[0]
"+ bs),
where vector bs and matrix W s are learnable parameters; ct is referred to as a context vector that summarizes the encoder’s output h; and dt is the
1As in Vinyals et al. (2015)",2.2 Encoder-Decoder Parser,[0],[0]
"the input sequence is processed in reverse order, as shown in Figure 1.
",2.2 Encoder-Decoder Parser,[0],[0]
2For brevity we omit the LSTM equations.,2.2 Encoder-Decoder Parser,[0],[0]
"The details can be found, e.g., in Zaremba et al. (2014).
",2.2 Encoder-Decoder Parser,[0],[0]
"decoder hidden state at time step t, which captures the previous output sequence context y<t.
uit = v >",2.2 Encoder-Decoder Parser,[0],[0]
tanh(W 1hi,2.2 Encoder-Decoder Parser,[0],[0]
"+W 2dt + ba)
",2.2 Encoder-Decoder Parser,[0],[0]
"αt = softmax(ut) ct = Ts∑
i=1
αtihi
where vectors v, ba and matrices W 1, W 2 are learnable parameters; ut and αt are the attention score and attention weight vector, respectively, for decoder time step t.
The above attention mechanism is only contentbased, i.e., it is only dependent on hi, dt.",2.2 Encoder-Decoder Parser,[0],[0]
"It is not location-aware, i.e., it does not consider the “location” of the previous attention vector.",2.2 Encoder-Decoder Parser,[0],[0]
"For parsing conversational text, location awareness is beneficial since disfluent structures can have duplicate words/phrases that may “confuse” the attention mechanism.
",2.2 Encoder-Decoder Parser,[0],[0]
"In order to make the model location-aware, the attention mechanism takes into account the previous attention weight vector αt−1.",2.2 Encoder-Decoder Parser,[0],[0]
"In particular, we use the attention mechanism proposed by Chorowski et al. (2015), in which αt−1 is represented via a feature vector f t = F ∗αt−1, where F ∈ Rk×r represents k learnable convolution filters of width r. The filters are used for performing 1-D convolution over αt−1 to extract k features f ti for each time step i of the input sequence.",2.2 Encoder-Decoder Parser,[0],[0]
"The extracted features are then incorporated in the alignment score calculation as:
uit = v >",2.2 Encoder-Decoder Parser,[0],[0]
tanh(W 1hi,2.2 Encoder-Decoder Parser,[0],[0]
+W 2dt,2.2 Encoder-Decoder Parser,[0],[0]
"+W ff ti + ba)
where W f is another learnable parameter matrix.",2.2 Encoder-Decoder Parser,[0],[0]
"Finally, the decoder state dt is computed as dt = LSTM([ỹt−1; ct−1],dt−1), where ỹt−1 is the embedding vector corresponding to the previous output symbol yt−1.",2.2 Encoder-Decoder Parser,[0],[0]
"As we will see in Sec. 4.1, the location-aware attention mechanism is especially useful for handling disfluencies.",2.2 Encoder-Decoder Parser,[0],[0]
"In previous work using encoder-decoder models for parsing (Vinyals et al., 2015; Luong et al., 2016), vector xi is simply the word embedding ei of the word at position i of the input sentence.",2.3 Acoustic-Prosodic Features,[0],[0]
"For parsing conversational speech, we can incorporate acousticprosodic features.",2.3 Acoustic-Prosodic Features,[0],[0]
"Here we explore four types of features widely used in computational models of prosody: pauses, duration lengthening, fundamental frequency, and energy.",2.3 Acoustic-Prosodic Features,[0],[0]
"Since prosodic cues are
at sub- and multi-word time scales, they are integrated with the encoder-decoder using different mechanisms.
",2.3 Acoustic-Prosodic Features,[0],[0]
All features are extracted from transcriptions that are time-aligned at the word level.3,2.3 Acoustic-Prosodic Features,[0],[0]
We use time alignments associated with the corpus to be consistent with other studies.,2.3 Acoustic-Prosodic Features,[0],[0]
"In a small number of cases, the time alignment for a particular word boundary is missing.",2.3 Acoustic-Prosodic Features,[0],[0]
Some cases are due to tokenization.,2.3 Acoustic-Prosodic Features,[0],[0]
"For example, contractions, such as don’t in the original transcript, are treated as separated words for the parser (do and n’t), and the internal word boundary time is missing.",2.3 Acoustic-Prosodic Features,[0],[0]
"In such cases, these internal times are estimated.",2.3 Acoustic-Prosodic Features,[0],[0]
"In other cases, there are transcription mismatches that lead to missing time alignments, where we cannot estimate times.",2.3 Acoustic-Prosodic Features,[0],[0]
"For the roughly 1% of sentences where time alignments are missing, we simply back off to the text-based parser.
Pause.",2.3 Acoustic-Prosodic Features,[0],[0]
"The pause feature vector pi for word i is the concatenation of pre-word pause feature ppre,i and post-word pause feature ppost,i, where each subvector is a learned embedding for 6 pause categories: no pause, missing, 0 < p ≤ 0.05 s, 0.05 s < p ≤ 0.2 s, 0.2 < p ≤ 1 s, and p > 1 s (including turn boundaries).",2.3 Acoustic-Prosodic Features,[0],[0]
The bins are chosen based on the observed distribution (see Appendix A.1).,2.3 Acoustic-Prosodic Features,[0],[0]
"We did not use (real-valued) pause duration directly, for two main reasons: (1) to handle missing time alignments; and (2) duration of pause does
3The assumption of known word alignments is standard for prosodic feature extraction in many spoken language processing studies.",2.3 Acoustic-Prosodic Features,[0],[0]
"Time alignments can be obtained as a by-product of recognition or from forced alignment.
not matter beyond a threshold (e.g. p > 1 s).
",2.3 Acoustic-Prosodic Features,[0],[0]
Word duration.,2.3 Acoustic-Prosodic Features,[0],[0]
"Both word duration and wordfinal duration lengthening are strong cues to prosodic phrase boundaries (Wightman et al., 1992; Pate and Goldwater, 2013).",2.3 Acoustic-Prosodic Features,[0],[0]
"The word duration feature δi is computed as the actual word duration divided by the mean duration of the word, clipped to a maximum value of 5.",2.3 Acoustic-Prosodic Features,[0],[0]
The sample mean is used for frequent words (count ≥ 15).,2.3 Acoustic-Prosodic Features,[0],[0]
For infrequent words we estimate the mean as the sum over the sample means for the phonemes in the word’s dictionary pronunciation.,2.3 Acoustic-Prosodic Features,[0],[0]
"We refer to the manually defined prosodic feature pair of pi and δi as φi.
Fundament frequency (f0) and Energy (E) contours (f0/E).",2.3 Acoustic-Prosodic Features,[0],[0]
We use a CNN to automatically learn the mapping from the time series of f0/E features to a word-level vector.,2.3 Acoustic-Prosodic Features,[0],[0]
"The contour features are extracted from 25-ms frames with 10-ms hops using Kaldi (Povey et al., 2011).",2.3 Acoustic-Prosodic Features,[0],[0]
"Three f0 features are used: warped Normalized Cross Correlation Function (NCCF), log-pitch with Probability of Voicing (",2.3 Acoustic-Prosodic Features,[0],[0]
"POV)-weighted mean subtraction over a 1.5-second window, and the estimated derivative (delta) of the raw log pitch.",2.3 Acoustic-Prosodic Features,[0],[0]
"Three energy features are extracted from the Kaldi 40-mel-frequency filter bank features: Etotal, the log of total energy normalized by dividing by the speaker side’s max total energy; Elow, the log of total energy in the lower 20 mel-frequency bands, normalized by total energy, and Ehigh, the log of total energy in the higher 20 mel-frequency bands, normalized by total energy.",2.3 Acoustic-Prosodic Features,[0],[0]
"Multi-band energy features are used as a
simple mechanism to capture articulatory strengthening at prosodic constituent onsets (Fourgeron and Keating, 1997).
",2.3 Acoustic-Prosodic Features,[0],[0]
Figure 1 summarizes the feature learning approach.,2.3 Acoustic-Prosodic Features,[0],[0]
The f0 and E features are processed at the word level: each sequence of frames corresponding to a time-aligned word (and potentially its surrounding context) is convolved with N filters of m sizes (a total of mN filters).,2.3 Acoustic-Prosodic Features,[0],[0]
The motivation for the multiple filter sizes is to enable the computation of features that capture information on different time scales.,2.3 Acoustic-Prosodic Features,[0],[0]
"For each filter, we perform a 1-D convolution over the 6-dimensional f0/E features with a stride of 1.",2.3 Acoustic-Prosodic Features,[0],[0]
"Each filter output is max-pooled, resulting in mN -dimensional speech features si.",2.3 Acoustic-Prosodic Features,[0],[0]
"Our overall acoustic-prosodic feature vector is the concatenation of pi, δi, and si in various combinations.",2.3 Acoustic-Prosodic Features,[0],[0]
"Our core corpus is Switchboard-NXT (Calhoun et al., 2010), a subset of the Switchboard corpus (Godfrey and Holliman, 1993): 2,400 telephone conversations between strangers; 642 of these were hand-annotated with syntactic parses and further augmented with richer layers of annotation facilitated by the NITE XML toolkit (Calhoun et al., 2010).",3.1 Dataset,[0],[0]
"Our sentence segmentations and syntactic trees are based on the annotations from the Treebank set, with a few manual corrections from the NXT release.",3.1 Dataset,[0],[0]
"This core dataset consists of 100K sentences, totaling 830K tokens forming a vocabulary of 13.5K words.",3.1 Dataset,[0],[0]
"We use the time alignments available from NXT, which is based on a corrected word transcript that occasionally differs from the Treebank, leading to some missing time alignments.",3.1 Dataset,[0],[0]
"We follow the sentence boundaries defined by the parsed data available,4 and the data split (90% train; 5% dev; 5% test) defined by related work done on Switchboard (Charniak and Johnson, 2001; Kahn et al., 2005; Honnibal and Johnson, 2014).",3.1 Dataset,[0],[0]
"The standard evaluation metric for constituent parsing is the parseval metric which uses bracketing precision, recall, and F1, as in the canonical implementation of EVALB.5",3.2 Evaluation Metrics and Baselines,[0],[0]
"For written text, punc-
4Note that these sentence units can be inconsistent with other layers of Switchboard annotations, such as slash units.
",3.2 Evaluation Metrics and Baselines,[0],[0]
"5http://nlp.cs.nyu.edu/evalb/
tuation is sometimes represented as part of the sequence and impacts the final score, but for speech the punctuation is not explicitly available so it does not contribute to the score.",3.2 Evaluation Metrics and Baselines,[0],[0]
Another challenge of transcribed speech is the presence of disfluencies.,3.2 Evaluation Metrics and Baselines,[0],[0]
"Speech repairs are indicated under “EDITED” nodes in Switchboard parse trees, which include structure under these nodes that is not of interest for simple text clean-up.",3.2 Evaluation Metrics and Baselines,[0],[0]
"Therefore, some studies report flattened-edit parseval F1 scores (“flatF1”), which is parseval computed on trees where the structure under edit nodes has been eliminated so that all leaves are immediate children.",3.2 Evaluation Metrics and Baselines,[0],[0]
"We report both scores for the baseline text-only model showing that the differences are small, then use the standard parseval F1 score for most results.6
Disfluencies are particularly problematic for statistical parsers, as explained by Charniak and Johnson (2001), and some systems incorporate a separate disfluency detection stage.",3.2 Evaluation Metrics and Baselines,[0],[0]
"For this reason, and because it is useful for understanding system performance, most studies also report disfluency detection performance, which is measured in terms of the F1 score for detecting whether a word is in an edit region.",3.2 Evaluation Metrics and Baselines,[0],[0]
"Our approach does not involve a separate disfluency detection stage, but identifies disfluencies implicitly via the parse structure.",3.2 Evaluation Metrics and Baselines,[0],[0]
"Consequently, the disfluency detection results are not competitive with work that directly optimize for disfluency detection.",3.2 Evaluation Metrics and Baselines,[0],[0]
"We report disfluency detection scores primarily as a diagnostic.
",3.2 Evaluation Metrics and Baselines,[0],[0]
"Most previous work on integrating prosody and parsing has used the Switchboard corpus, but it is still difficult to compare results because of differences in constraints, objectives and the use of constituent vs. dependency structure, as discussed further in Section 6.",3.2 Evaluation Metrics and Baselines,[0],[0]
The most relevant prior studies (on constituent parsing) that we compare to are a bit old.,3.2 Evaluation Metrics and Baselines,[0],[0]
The text-only result from our neural parser represents a stronger baseline and is important for decoupling the impact of prosody vs. the parsing framework.,3.2 Evaluation Metrics and Baselines,[0],[0]
Both the encoder and decoder are 3-layer deep LSTM-RNNs with 256 hidden units in each layer.,3.3 Model Training and Inference,[0],[0]
"For the location-aware attention, the convolution operation uses 5 filters of width 40 each.",3.3 Model Training and Inference,[0],[0]
"We use 512-dimensional embedding vectors to repre-
6A variant of the “flat-F1” score is used in (Charniak and Johnson, 2001; Kahn et al., 2005), which uses a relaxed edited node precision and recall but also ignores filled pauses.
sent words and linearized parsing symbols, such as “(S”.7
A number of configurations are explored for the acoustic-prosodic features, tuning based on dev set parsing performance.",3.3 Model Training and Inference,[0],[0]
"Pause embeddings are tuned over {4, 16, 32} dimensions.",3.3 Model Training and Inference,[0],[0]
"For the CNN, we try different configurations of filter widths w ∈ {",3.3 Model Training and Inference,[0],[0]
"[10, 25, 50], [5, 10, 25, 50]} and number of filters N ∈ {16, 32, 64, 128} for each filter width.8 These filter size combinations are chosen to capture f0 and energy phenomena on various levels: w = 5, 10 for sub-word, w = 25 for word, and w = 50 for word and extended context.",3.3 Model Training and Inference,[0],[0]
Our best model uses 32-dimensional pause embeddings and N = 32 filters of widthsw =,3.3 Model Training and Inference,[0],[0]
"[5, 10, 25, 50], which corresponds to m = 4 and 128 filters.
",3.3 Model Training and Inference,[0],[0]
"For optimization we use Adam (Kingma and Ba, 2014) with a minibatch size of 64.",3.3 Model Training and Inference,[0],[0]
"The initial learning rate is 0.001 which is decayed by a factor of 0.9 whenever training loss, calculated after every 500 updates, degrades relative to the worst of its previous 3 values.",3.3 Model Training and Inference,[0],[0]
All models are trained for up to 50 epochs with early stopping.,3.3 Model Training and Inference,[0],[0]
"For regularization, dropout with 0.3 probability is applied on the output of all LSTM layers (Pham et al., 2014).
",3.3 Model Training and Inference,[0],[0]
"For inference, we use a greedy decoder to generate the linearized parse.",3.3 Model Training and Inference,[0],[0]
The output token with maximum posterior probability is chosen at every time step and fed as input in the next time step.,3.3 Model Training and Inference,[0],[0]
The decoder stops upon producing the end-of-sentence symbol.,3.3 Model Training and Inference,[0],[0]
"We use TensorFlow (Abadi et al., 2015) to implement all models.9",3.3 Model Training and Inference,[0],[0]
"7The number of layers, dimension of hidden units, dimension of embedding, and convolutional attention filter parameters of the text-only parser were explored in earlier experiments on the development set and then fixed as described.
8Note that a filter of width 10 has size 6 × 10, since the features are of dimension 6.
",4.1 Text-only Results,[0],[0]
"9Our code resources can be found in Appendix A.1.
",4.1 Text-only Results,[0],[0]
"We first show our results on the model using only text (i.e. xi = ei) to establish a strong baseline, on top of which we can add acousticprosodic features.",4.1 Text-only Results,[0],[0]
We experiment with the contentonly attention model used by Vinyals et al. (2015) and the content+location attention of Chorowski et al. (2015).,4.1 Text-only Results,[0],[0]
"For comparison with previous nonneural models, we use a high-quality latent-variable parser, the Berkeley parser (Petrov et al., 2006), retrained on our Switchboard data.",4.1 Text-only Results,[0],[0]
Table 1 compares the three text-only models.,4.1 Text-only Results,[0],[0]
"In terms of F1, the content+location attention beats the Berkeley parser by about 2.5% and content-only attention by about 4.5%.",4.1 Text-only Results,[0],[0]
"Flat-F1 scores for both encoder-decoder models is lower than their corresponding F1 scores, suggesting that the encoder-decoder models do well on predicting the internal structure of EDIT nodes while the reverse is true for the Berkeley parser.
",4.1 Text-only Results,[0],[0]
"To explain the gains of content+location attention over content-only attention, we compare their scores on fluent (without EDIT nodes) and disfluent sentences, shown in Table 1.",4.1 Text-only Results,[0],[0]
It is clear that most of the gains for content+location attention are from disfluent sentences.,4.1 Text-only Results,[0],[0]
"A possible explanation is the presence of duplicate words or phrases in disfluent sentences, which can be problematic for a contentonly attention model.",4.1 Text-only Results,[0],[0]
"Since our best model is the content+location attention model, we will henceforth refer to it as the “CL-attn” text-only model.",4.1 Text-only Results,[0],[0]
"All models using acoustic-prosodic features are extensions of this model, which provides a strong text-only baseline.",4.1 Text-only Results,[0],[0]
"We extend our CL-attn model with the three kinds of acoustic-prosodic features: pause (p), word duration (δ), and CNN mappings of fundamental frequency (f0) and energy (E) features (f0/E-CNN).
",4.2 Adding Acoustic-Prosodic Features,[0],[0]
The results of several model configurations on our dev set are presented in Table 2.,4.2 Adding Acoustic-Prosodic Features,[0],[0]
"First, we note that adding any combination of acoustic-prosodic features (individually or in sets) improves performance over the text-only baseline.",4.2 Adding Acoustic-Prosodic Features,[0],[0]
"However, certain combinations of acoustic-prosodic features are not always better than their subsets.",4.2 Adding Acoustic-Prosodic Features,[0],[0]
The text + p + δ + f0/E-CNN model that uses all three types of features has the best performance with a gain of 0.7% over the already-strong text-only baseline.,4.2 Adding Acoustic-Prosodic Features,[0],[0]
"We will henceforth refer to the text + p + δ + f0/E-CNN model as our “best model”.
",4.2 Adding Acoustic-Prosodic Features,[0],[0]
"As a robustness check, we report results of averaging 10 runs on the CL-attn text-only and the best model in Table 3.",4.2 Adding Acoustic-Prosodic Features,[0],[0]
"We performed a bootstrap test (Efron and Tibshirani, 1993) that simulates 105 random test draws on the models giving median performance on the dev set.",4.2 Adding Acoustic-Prosodic Features,[0],[0]
These median models gave a statistically significant difference between the text-only and best model (p-value < 0.02).,4.2 Adding Acoustic-Prosodic Features,[0],[0]
"Additionally, a simple t-test over the two sets of 10 results also shows statistical significance p-value < 0.03.
",4.2 Adding Acoustic-Prosodic Features,[0],[0]
Table 4 presents the results on the test set.,4.2 Adding Acoustic-Prosodic Features,[0],[0]
"Again, adding the acoustic-prosodic features improves over the text-only baseline.",4.2 Adding Acoustic-Prosodic Features,[0],[0]
"The gains are statistically significant for the best model with p-value < 0.02, again using a bootstrap test with simulated 105 random test draws on the two models.
",4.2 Adding Acoustic-Prosodic Features,[0],[0]
"Table 5 includes results from prior studies that compare systems using text alone with ones that incorporate prosody, given hand transcripts and sentence segmentation.",4.2 Adding Acoustic-Prosodic Features,[0],[0]
"It is difficult to compare systems directly, because of the many differences in the experimental set-up.",4.2 Adding Acoustic-Prosodic Features,[0],[0]
"For example, the original Charniak and Johnson (2001) result (reporting F=85.9 for parsing and F=78.2 for disfluencies) leverages punctuation in the text stream, which is not realistic for speech transcripts and not used in most other work.",4.2 Adding Acoustic-Prosodic Features,[0],[0]
"Our work benefits from more text training material than others, but others benefit from gold part-of-speech tags.",4.2 Adding Acoustic-Prosodic Features,[0],[0]
Kahn et al. (2005) use a modified sentence segmentation.,4.2 Adding Acoustic-Prosodic Features,[0],[0]
There are probably minor differences in handling of word fragments and scoring edit regions.,4.2 Adding Acoustic-Prosodic Features,[0],[0]
"Thus, this table primarily shows that our framework leads to more benefits from sentence-internal prosodic cues than others have obtained.",4.2 Adding Acoustic-Prosodic Features,[0],[0]
Effect of sentence length.,5 Analysis,[0],[0]
"Figure 2 shows performance differences between our best model and the text-only model for varying sentence lengths.
",5 Analysis,[0],[0]
"Both models do worse on longer sentences, as expected since the corresponding parse trees tend to be more complex.",5 Analysis,[0],[0]
The performance difference between our best model and the text-only model increases with sentence length.,5 Analysis,[0],[0]
"This is likely because longer sentences more often have multiple prosodic phrases and disfluencies.
",5 Analysis,[0],[0]
Effect of disfluencies.,5 Analysis,[0],[0]
"Table 6 presents parse scores on the subsets of fluent and disfluent sentences, showing that the performance gain is in the disfluent set (65% of the dev set sentences).",5 Analysis,[0],[0]
"Because sentence boundaries are given, and so many fluent sentences in spontaneous speech are short, there is less potential for benefit from prosody in the fluent set.
",5 Analysis,[0],[0]
Types of errors.,5 Analysis,[0],[0]
"We use the Berkeley Parser Analyzer (Kummerfeld et al., 2012) to compare the types of errors made by the different parsers.10 Table 7 presents the relative error reductions over the text-only baseline achieved by the text + p model and our best model for disfluent sentences.",5 Analysis,[0],[0]
The two models differ in the types of error reductions they provide.,5 Analysis,[0],[0]
"Including pause information gives largest improvements on PP attachment and Modifier at-
10This analysis omits the 1% of the sentences that did not have timing information.
tachment errors.",5 Analysis,[0],[0]
"Adding the remaining acousticprosodic features helps to correct more types of attachment errors, especially VP and NP attachment.",5 Analysis,[0],[0]
Figure 3 demonstrates one case where the pause feature helps in correcting a PP attachment error made by a text-only parser.,5 Analysis,[0],[0]
"Other interesting examples (see Appendix A.2) suggest that the learned f0/E features help reduce NP attachment errors where the audio reveals a prominent word at the constituent boundary, even though there is no pause at that word.
",5 Analysis,[0],[0]
Effect of transcription errors.,5 Analysis,[0],[0]
The results and analyses so far have assumed that we have reliable transcripts.,5 Analysis,[0],[0]
"In fact, the original transcripts contained errors, and the Treebank annotators used these without reference to audio files.",5 Analysis,[0],[0]
"Mississippi State University (MS-State) ran a clean-up project
that produced more accurate word transcripts and time alignments (Deshmukh et al., 1998).",5 Analysis,[0],[0]
"The NXT corpus provides reconciliation between Treebank and MS-State transcripts in terms of annotating missed/extra/substituted words, but parses were not re-annotated.",5 Analysis,[0],[0]
The transcript errors mean that the acoustic signal is inconsistent with the “gold” parse tree.,5 Analysis,[0],[0]
"Below are some examples of “fluent” sentences (according to the Treebank transcripts) with transcription errors, for which prosodic features “hurt” parsing.",5 Analysis,[0],[0]
Words that transcribers missed are in brackets and those inserted are underlined.,5 Analysis,[0],[0]
S1: and because <,5 Analysis,[0],[0]
uh> like if your spouse died <all of a sudden you be> all alone it ’d be nice to go someplace with people similar to you to have friends S2: uh uh <i have had>,5 Analysis,[0],[0]
"my wife ’s picked up a couple of things saying uh boy if we could refinish that ’d be a beautiful piece of furniture
Multi-syllable errors are especially problematic, leading to serious inconsistencies between the text and the acoustic signal.",5 Analysis,[0],[0]
"Further, the missed words lead to an incorrect attachment in the “gold” parse in S1 and a missing restart edit in S2.",5 Analysis,[0],[0]
"Indeed, for sentences with consecutive transcript errors, which we expect to impact the prosodic features, there is a statistically significant (p-value < 0.05) negative effect on parsing with prosody.",5 Analysis,[0],[0]
"Not included in this analysis are sentence boundary errors, which also change the “gold” parse.",5 Analysis,[0],[0]
"Thus, prosody may be more useful than results here indicate.",5 Analysis,[0],[0]
"Related work on parsing conversational speech has mainly addressed four problems: speech recognition errors, unknown sentence segmentation, disfluencies, and integrating prosodic cues.",6 Related Work,[0],[0]
"Our work addresses the last two problems, which involve studies based on hand-transcribed text and known sentence boundaries, as in much speech parsing work.",6 Related Work,[0],[0]
The related studies are thus the focus of this discussion.,6 Related Work,[0],[0]
"We describe studies using the Switchboard corpus, since it has dominated work in this area, being the largest source of treebanked English spontaneous speech.
",6 Related Work,[0],[0]
"One major challenge of parsing conversational speech is the presence of disfluencies, which are grammatical and prosodic interruptions.",6 Related Work,[0],[0]
Disfluencies include repetitions (‘I am +,6 Related Work,[0],[0]
"I am’), repairs (‘I am +",6 Related Work,[0],[0]
"we are’), and restarts (‘What I",6 Related Work,[0],[0]
+,6 Related Work,[0],[0]
"Today is the...’), where the ‘+’ corresponds to an interruption point.",6 Related Work,[0],[0]
"Repairs often involve parallel grammatical
constructions, but they can be more complex, involving hedging, clarifications, etc.",6 Related Work,[0],[0]
"Charniak and Johnson (Charniak and Johnson, 2001; Johnson and Charniak, 2004) demonstrated that disfluencies are different in character than other constituents and that parsing performance improves from combining a PCFG parser with a separate module for disfluency detection via parse rescoring.",6 Related Work,[0],[0]
Our approach does not use a separate disfluency detection module; we hypothesized that the location-sensitive attention model helps handle these differences based on analysis of the text-only results (Table 1).,6 Related Work,[0],[0]
"However, more explicit modeling of disfluency pattern match characteristics in a dependency parser (Honnibal and Johnson, 2014) leads to better disfluency detection performance (F = 84.1 vs. 76.7 for our text only model).",6 Related Work,[0],[0]
"Pattern match features also benefit a neural model for disfluency detection alone (F = 87.0) (Zayats et al., 2016), and similar gains are observed by formulating disfluency detection in a transition-based framework (F = 87.5) (Wang et al., 2017).",6 Related Work,[0],[0]
"Experiments with oracle disfluencies as features improve the CL-attn text-only parsing performance from 87.85 to 89.38 on the test set, showing that more accurate disfluency modeling is a potential area of improvement.
",6 Related Work,[0],[0]
"It is well known that prosodic features play a role in human resolution of syntactic ambiguities, with more than two decades of studies seeking to incorporate prosodic features in parsing.",6 Related Work,[0],[0]
"A series of studies looked at constituent parsing informed by the presence (or likelihood) of prosodic breaks at word boundaries (Kahn et al., 2004, 2005; Hale et al., 2006; Dreyer and Shafran, 2007).",6 Related Work,[0],[0]
"Our approach improves over performance of these systems using raw acoustic features, without the need for handlabeling prosodic breaks.",6 Related Work,[0],[0]
"The gain is in part due to the improved text-based parser, but the incremental benefit of prosody here is similar to that in these prior studies.",6 Related Work,[0],[0]
"(In prior work using acoustic feature directly (Gregory et al., 2004), prosody actually degraded performance.)",6 Related Work,[0],[0]
"Our analyses of the impact of prosody also extends prior work.
",6 Related Work,[0],[0]
"Prosody is also known to provide useful cues to sentence boundaries (Liu et al., 2006), and automatic sentence segmentation performance has been shown to have a significant impact on parsing performance (Kahn and Ostendorf, 2012).",6 Related Work,[0],[0]
"In our study, sentence boundaries are given so as to focus on the role of prosody in resolving sentenceinternal parse ambiguity, for which prior work had
obtained smaller gains.",6 Related Work,[0],[0]
"Studies have also shown that parsing lattices or confusion networks can improve ASR performance (Kahn and Ostendorf, 2012; Yoshikawa et al., 2016).",6 Related Work,[0],[0]
"Our analysis of performance degradation for the system with prosody when the gold transcript and associated parse are in error suggests that prosody may have benefits for parsers operating on alternative ASR hypotheses.
",6 Related Work,[0],[0]
The results we compare to in Section 4 are relatively old.,6 Related Work,[0],[0]
"More recent parsing results on spontaneous speech involve dependency parsers using only text (Rasooli and Tetreault, 2013; Honnibal and Johnson, 2014; Yoshikawa et al., 2016), with the exception of a study on unsupervised dependency parsing (Pate and Goldwater, 2013).",6 Related Work,[0],[0]
"With the recent success of transition-based neural approaches in dependency parsing, researchers have adapted transition-based ideas to constituent parsing (Zhu et al., 2013; Watanabe and Sumita, 2015; Dyer et al., 2016).",6 Related Work,[0],[0]
"These approaches have not yet been used with speech, to our knowledge, but we expect it to be straightforward to extend our prosody integration framework to these systems, both for dependency and constituency parsing.",6 Related Work,[0],[0]
We have presented a framework for directly integrating acoustic-prosodic features with text in a neural encoder-decoder parser that does not require hand-annotated prosodic structure.,7 Conclusion,[0],[0]
"On conversational sentences, we obtained strong results when including word-level acoustic-prosodic features over using only transcriptions.",7 Conclusion,[0],[0]
"The acousticprosodic features provide the largest gains when sentences are disfluent or long, and analysis of error types shows that these features are especially helpful in repairing attachment errors.",7 Conclusion,[0],[0]
"In cases where prosodic features hurt performance, we observe a statistically significant negative effect caused by imperfect human transcriptions that make the “ground truth” parse tree and the acoustic signal inconsistent, which suggests that there is more to be gained from prosody than observed in prior studies.",7 Conclusion,[0],[0]
"We thus plan to investigate aligning the Treebank and MS-State versions of Switchboard for future work.
",7 Conclusion,[0],[0]
"Here, we assumed known sentence boundaries and hand transcripts, leaving open the question of whether increased benefits from prosody can be gained by incorporating sentence segmentation in parsing and/or in parsing ASR lattices.",7 Conclusion,[0],[0]
"Most prior work using prosody in parsing has been on con-
stituent parsing, since prosodic cues tend to align with constituent boundaries.",7 Conclusion,[0],[0]
"However, it remains an open question as to whether dependency, constituency or other parsing frameworks are better suited to leveraging prosody.",7 Conclusion,[0],[0]
"Our study builds on a parser that uses reverse order text processing, since it provides a stronger text-only baseline.",7 Conclusion,[0],[0]
"However, the prosody modeling component relies only on a 1 second lookahead of the current word (for pause binning), so it could be easily incorporated in an incremental parser.",7 Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful feedback.,Acknowledgement,[0],[0]
"We also thank Pranava Swaroop Madhyastha, Hao Tang, Jon Cai, Hao Cheng, and Navdeep Jaitly for their help with initial discussions and code setup.",Acknowledgement,[0],[0]
"This research was partially funded by a Google Faculty Research Award to Mohit Bansal, Karen Livescu, and Kevin Gimpel; and NSF grant no. IIS-1617176.",Acknowledgement,[0],[0]
The opinions expressed in this work are those of the authors and do not necessarily reflect the views of the funding agency.,Acknowledgement,[0],[0]
"A.1 Miscellany
Our main model code is available at https://github.com/shtoshni92/ speech_parsing.",A Appendix,[0],[0]
Most of the data preprocessing code is available at https://github. com/trangham283/seq2seq_parser/ tree/master/src/data_preps.,A Appendix,[0],[0]
"Part of our data preprocessing pipeline also uses https: //github.com/syllog1sm/swbd_tools.
",A Appendix,[0],[0]
Table 8 shows statistics of our Switchboard dataset.,A Appendix,[0],[0]
"As defined, for example, in (Charniak and Johnson, 2001; Honnibal and Johnson, 2014), the splits are: conversations sw2000 to sw3000 for training, sw4500 to sw4936 for validation (dev), and sw4000 to sw4153 for evaluation (test).",A Appendix,[0],[0]
"In addition, previous work has reserved sw4154 to sw4500 for “future use” (dev2), but we added this set to our training set.",A Appendix,[0],[0]
"That is, all of our models are trained on Switchboard conversations sw2000 to sw3000 as well as sw4154 to sw4500.
",A Appendix,[0],[0]
Figure 4 illustrates the data preprocessing step.,A Appendix,[0],[0]
"On the decoder end, we also use a post-processing step that merges the original sentence with the decoder output to obtain the standard constituent tree representation.",A Appendix,[0],[0]
"During inference, in rare cases (and virtually none as our models converge), the decoder does not generate a valid parse sequence, due to the mismatch in brackets and/or the mismatch in the number of pre-terminals and terminals, i.e., num(XX) 6= num(tokens).",A Appendix,[0],[0]
"In such cases, we simply add/remove brackets from either end of the parse, or add/remove pre-terminal symbols XX in the middle of the parse to match the number of input tokens.
",A Appendix,[0],[0]
Figure 5 shows the distribution of pause durations in our training data.,A Appendix,[0],[0]
"Our pause buckets of
0 < p ≤ 0.05 s, 0.05 s < p ≤ 0.2 s, 0.2 < p ≤ 1 s, and p > 1 s described in the main paper were based on this distribution of pause lengths.
",A Appendix,[0],[0]
"Table 9 shows the comprehensive error counts in all error categories defined in the Berkeley Parse Analyzer (Kummerfeld et al., 2012) in both the fluent and disfluent subsets.
",A Appendix,[0],[0]
"A.2 Tree Examples In figures 6, 7, and 8, we follow node correction notations as in (Kummerfeld et al., 2012).",A Appendix,[0],[0]
"In particular, missing nodes are marked in blue on the gold tree, extra nodes are marked red in the predicted tree, and yellow nodes denote crossing.",A Appendix,[0],[0]
"In conversational speech, the acoustic signal provides cues that help listeners disambiguate difficult parses.",abstractText,[0],[0]
"For automatically parsing spoken utterances, we introduce a model that integrates transcribed text and acoustic-prosodic features using a convolutional neural network over energy and pitch trajectories coupled with an attention-based recurrent neural network that accepts text and prosodic features.",abstractText,[0],[0]
"We find that different types of acoustic-prosodic features are individually helpful, and together give statistically significant improvements in parse and disfluency detection F1 scores over a strong text-only baseline.",abstractText,[0],[0]
"For this study with known sentence boundaries, error analyses show that the main benefit of acousticprosodic features is in sentences with disfluencies, attachment decisions are most improved, and transcription errors obscure gains from prosody.",abstractText,[0],[0]
Parsing Speech: A Neural Approach to Integrating Lexical and Acoustic-Prosodic Information,title,[0],[0]
"General treebank analyses are graph structured, but parsers are typically restricted to tree structures for efficiency and modeling reasons. We propose a new representation and algorithm for a class of graph structures that is flexible enough to cover almost all treebank structures, while still admitting efficient learning and inference. In particular, we consider directed, acyclic, one-endpoint-crossing graph structures, which cover most long-distance dislocation, shared argumentation, and similar tree-violating linguistic phenomena. We describe how to convert phrase structure parses, including traces, to our new representation in a reversible manner. Our dynamic program uniquely decomposes structures, is sound and complete, and covers 97.3% of the Penn English Treebank. We also implement a proofof-concept parser that recovers a range of null elements and trace types.",text,[0],[0]
"Many syntactic representations use graphs and/or discontinuous structures, such as traces in Government and Binding theory and f-structure in Lexical Functional Grammar (Chomsky 1981; Kaplan and Bresnan 1982).",1 Introduction,[0],[0]
"Sentences in the Penn Treebank (PTB, Marcus et al. 1993) have a core projective tree structure and trace edges that represent control structures, wh-movement and more.",1 Introduction,[0],[0]
"However, most parsers and the standard evaluation metric ignore these edges and all null elements.",1 Introduction,[0],[0]
"By leaving out parts of the structure, they fail to provide key relations to downstream tasks such as question answering.",1 Introduction,[0],[0]
"While there has been work on capturing
some parts of this extra structure, it has generally either been through post-processing on trees (Johnson 2002; Jijkoun 2003; Campbell 2004; Levy and Manning 2004; Gabbard et al. 2006) or has only captured a limited set of phenomena via grammar augmentation (Collins 1997; Dienes and Dubey 2003; Schmid 2006; Cai et al. 2011).
",1 Introduction,[0],[0]
We propose a new general-purpose parsing algorithm that can efficiently search over a wide range of syntactic phenomena.,1 Introduction,[0],[0]
"Our algorithm extends a non-projective tree parsing algorithm (Pitler et al. 2013; Pitler 2014) to graph structures, with improvements to avoid derivational ambiguity while maintaining an O(n4) runtime.",1 Introduction,[0],[0]
"Our algorithm also includes an optional extension to ensure parses contain a directed projective tree of non-trace edges.
",1 Introduction,[0],[0]
Our algorithm cannot apply directly to constituency parses–it requires lexicalized structures similar to dependency parses.,1 Introduction,[0],[0]
We extend and improve previous work on lexicalized constituent representations (Shen et al. 2007; Carreras et al. 2008; Hayashi and Nagata 2016) to handle traces.,1 Introduction,[0],[0]
"In this form, traces can create problematic structures such as directed cycles, but we show how careful choice of head rules can minimize such issues.
We implement a proof-of-concept parser, scoring 88.1 on trees in section 23 and 70.6 on traces.",1 Introduction,[0],[0]
"Together, our representation and algorithm cover 97.3% of sentences, far above the coverage of projective tree parsers (43.9%).",1 Introduction,[0],[0]
"This work builds on two areas: non-projective tree parsing, and parsing with null elements.
",2 Background,[0],[0]
"Non-projectivity is important in syntax for rep-
441
Transactions of the Association for Computational Linguistics, vol. 5, pp.",2 Background,[0],[0]
"441–454, 2017.",2 Background,[0],[0]
Action Editor: Marco Kuhlmann.,2 Background,[0],[0]
"Submission batch: 4/2017; Published 11/2017.
",2 Background,[0],[0]
c©2017 Association for Computational Linguistics.,2 Background,[0],[0]
"Distributed under a CC-BY 4.0 license.
",2 Background,[0],[0]
"resenting many structures, but inference over the space of all non-projective graphs is intractable.",2 Background,[0],[0]
"Fortunately, in practice almost all parses are covered by well-defined subsets of this space.",2 Background,[0],[0]
"For dependency parsing, recent work has defined algorithms for inference within various subspaces (GómezRodrı́guez and Nivre 2010; Pitler et al. 2013).",2 Background,[0],[0]
We build upon these algorithms and adapt them to constituency parsing.,2 Background,[0],[0]
"For constituency parsing, a range of formalisms have been developed that are mildlycontext sensitive, such as CCG (Steedman 2000), LFG (Kaplan and Bresnan 1982), and LTAG (Joshi and Schabes 1997).
",2 Background,[0],[0]
"Concurrently with this work, Cao et al. (2017) also proposed a graph version of Pitler et al. (2013)’s One-Endpoint Crossing (1-EC) algorithm.",2 Background,[0],[0]
"However, Cao’s algorithm does not consider the direction of edges1 and so it could produce cycles, or graphs with multiple root nodes.",2 Background,[0],[0]
"Their algorithm also has spurious ambiguity, with multiple derivations of the same parse structure permitted.",2 Background,[0],[0]
"One advantage of their algorithm is that by introducing a new item type it can handle some cases of the Locked-Chain we define below (specifically, when N is even), though in practise they also restrict their algorithm to ignore such cases.",2 Background,[0],[0]
"They also show that the class of graphs they generate corresponds to the 1-EC pagenumber-2 space, a property that applies to this work as well2.
",2 Background,[0],[0]
Parsing with Null Elements in the PTB has taken two general approaches.,2 Background,[0],[0]
"The first broadly effective system was Johnson (2002), which post-processed the output of a parser, inserting extra elements.",2 Background,[0],[0]
"This was effective for some types of structure, such as null complementizers, but had difficulty with long distance dependencies.",2 Background,[0],[0]
The other common approach has been to thread a trace through the tree structure on the non-terminal symbols.,2 Background,[0],[0]
"Collins (1997)’s third model used this approach to recover wh-traces, while Cai et al. (2011) used it to recover null pronouns, and others have used it for a range of movement types (Dienes and Dubey 2003; Schmid 2006).",2 Background,[0],[0]
"These approaches have the disadvantage that each
1 To produce directed edges, their parser treats the direction as part of the edge label.
",2 Background,[0],[0]
2,2 Background,[0],[0]
This is a topological space with two half-planes sharing a boundary.,2 Background,[0],[0]
"All edges are drawn on one of the two half-planes and each half-plane contains no crossings.
",2 Background,[0],[0]
additional trace dramatically expands the grammar.,2 Background,[0],[0]
Our representation is similar to LTAG-Spinal (Shen et al. 2007) but has the advantage that it can be converted back into the PTB representation.,2 Background,[0],[0]
Hayashi and Nagata (2016) also incorporated null elements into a spinal structure but did not include a representation of co-indexation.,2 Background,[0],[0]
"In related work, dependency parsers have been used to assist in constituency parsing, with varying degrees of representation design, but only for trees (Hall, Nivre, and Nilsson 2007; Hall and Nivre 2008; FernándezGonzález and Martins 2015; Kong et al. 2015).
",2 Background,[0],[0]
"Kato and Matsubara (2016) described a new approach, modifying a transition-based parser to recover null elements and traces, with strong results, but using heuristics to determine trace referents.",2 Background,[0],[0]
"Our algorithm is a dynamic program, similar at a high level to CKY (Kasami 1966;",3 Algorithm,[0],[0]
Younger 1967; Cocke 1969).,3 Algorithm,[0],[0]
The states of our dynamic program (items) represent partial parses.,3 Algorithm,[0],[0]
"Usually in CKY, items are defined as covering the n words in a sentence, starting and ending at the spaces between words.",3 Algorithm,[0],[0]
"We follow Eisner (1996), defining items as covering the n−1 spaces in a sentence, starting and ending on words, as shown in Figure 1.",3 Algorithm,[0],[0]
"This means that we process each word’s left and right dependents separately, then combine the two halves.
",3 Algorithm,[0],[0]
"We use three types of items: (1) a single edge, linking two words, (2) a continuous span, going from one word to another, representing all edges linking pairs of words within the span, (3) a span (as defined in 2) plus an additional word outside the span, enabling the inclusion of edges between that word and words in the span.
",3 Algorithm,[0],[0]
"Within the CKY framework, the key to defining our algorithm is a set of rules that specify which items are allowed to combine.",3 Algorithm,[0],[0]
"From a bottom-up perspective, a parse is built in a series of steps, which come in three types: (1) adding an edge to an item, (2) combining two items that have non-overlapping adjacent spans to produce a new item with a larger span, (3) combining three items, similarly to (2).
",3 Algorithm,[0],[0]
"Example: To build intuition for the algorithm, we will describe the derivation in Figure 1.",3 Algorithm,[0],[0]
"Note, item sub-types (I, X, and N) are defined below, and in-
cluded here for completeness.",3 Algorithm,[0],[0]
"(1) We initialize with spans of width one, going between adjacent words, e.g. between ROOT and We. ∅",3 Algorithm,[0],[0]
"7→ I0,1 (2) Edges can be introduced in exactly two ways, either by linking the two ends of a span, e.g. like– running, or by linking one end of a span with a word outside the span, e.g. like–. (which in this case forms a new item that has a span and an external word).
",3 Algorithm,[0],[0]
"I2,3 ∧ like–running 7→ I2,3 I3,4 ∧ like–. 7→ X3,4,2
(3) We add a second edge to one of the items.",3 Algorithm,[0],[0]
"I1,2 ∧ running–We 7→ X1,2,3 (4) Now that all the edges to We have been added, the two items either side of it are combined to form an item that covers it.",3 Algorithm,[0],[0]
"I0,1 ∧ X1,2,3 7→",3 Algorithm,[0],[0]
"N0,2,3 (5) We add an edge, creating a crossing because We is an argument of a word to the right of like.",3 Algorithm,[0],[0]
"N0,2,3 ∧ ROOT–like 7→ N0,2,3 (7) We use a ternary rule to combine three adjacent items.",3 Algorithm,[0],[0]
"In the process we create another crossing.
",3 Algorithm,[0],[0]
"N0,2,3 ∧ I2,3 ∧ X3,4,2 7→ I0,6",3 Algorithm,[0],[0]
"Notation Vertices are p, q, etc.",3.1 Algorithm definition,[0],[0]
"Continuous ranges are [pq], [pq), (pq], or (pq), where the brackets indicate inclusion, [ ], or exclusion, ( ), of each endpoint.",3.1 Algorithm definition,[0],[0]
A span [pq] and vertex o that are part of the same item are [pq.o].,3.1 Algorithm definition,[0],[0]
"Two vertices and an arrow indicate an edge, ~pq.",3.1 Algorithm definition,[0],[0]
"Two vertices without an arrow are an edge in either direction, pq. Ranges and/or vertices connected by a dash define a set of edges, e.g. the
set of edges between o and (pq) is o–(pq) (in some places we will also use this to refer to an edge from the set, rather than the whole set).",3.1 Algorithm definition,[0],[0]
"If there is a path from p to q, q is reachable from p.
Item Types As shown in Figure 1, our items start and end on words, fully covering the spaces in between.",3.1 Algorithm definition,[0],[0]
"Earlier we described three item types: an edge, a span, and a span plus an external vertex.",3.1 Algorithm definition,[0],[0]
"Here we define spans more precisely as I , and divide the span plus an external point case into five types differing in the type of edge crossing they contain: p qI , Interval A span for which there are no edges sr :",3.1 Algorithm definition,[0],[0]
r ∈ (pq) and s /∈,3.1 Algorithm definition,[0],[0]
"[pq].
o X , Exterval An interval and either op or oq, where",3.1 Algorithm definition,[0],[0]
o /∈,3.1 Algorithm definition,[0],[0]
[pq].,3.1 Algorithm definition,[0],[0]
"B, Both A span and vertex [pq.o], for which there are no edges sr : r ∈ (pq) and s /∈",3.1 Algorithm definition,[0],[0]
"[pq] ∪ o. Edges o–[pq] may be crossed by pq, p–(pq) or q–(pq), and at least one crossing of the second and third types occurs.",3.1 Algorithm definition,[0],[0]
Edges o–(pq) may not be crossed by (pq)–(pq) edges.,3.1 Algorithm definition,[0],[0]
"L, Left Same as B, but o–(pq) edges may only cross p–(pq] edges.",3.1 Algorithm definition,[0],[0]
"R, Right Symmetric with L. N , Neither An interval and a vertex [pq.o], with at least one o–(pq) edge, which can be crossed by pq, but no other [pq]–[pq] edges.
",3.1 Algorithm definition,[0],[0]
Items are further specified as described in Alg.,3.1 Algorithm definition,[0],[0]
1.,3.1 Algorithm definition,[0],[0]
"Most importantly, for each pair of o, p, and q in an item, the rules specify whether one is a parent of the other, and if they are directly linked by an edge.
",3.1 Algorithm definition,[0],[0]
"For an item H with span [ij], define covered(H) as (ij), and define visible(H) as {i, j}.",3.1 Algorithm definition,[0],[0]
"When an external vertex x is present, it is in visible(H).",3.1 Algorithm definition,[0],[0]
"Call the union of multiple such sets covered(F,G,H), and visible(F,G,H).
",3.1 Algorithm definition,[0],[0]
Deduction Rules To make the deduction rules manageable,3.1 Algorithm definition,[0],[0]
", we use templates to define some constraints explicitly, and then use code to generate the rules.",3.1 Algorithm definition,[0],[0]
"During rule generation, we automatically apply additional constraints to prevent rules that would leave a word in the middle of a span without a parent or that would form a cycle (proven possible below).",3.1 Algorithm definition,[0],[0]
Algorithm 1 presents the explicit constraints.,3.1 Algorithm definition,[0],[0]
"Once expanded, these give rules that specify all properties for each item (general type, external vertex position
Algorithm 1 Dynamic program for Lock-Free, One-Endpoint Crossing, Directed, Acyclic graph parsing.",3.1 Algorithm definition,[0],[0]
Adding Edges: Consider a span [lr] and vertex x /∈,3.1 Algorithm definition,[0],[0]
[lr].,3.1 Algorithm definition,[0],[0]
"Edges between l and r can be added to items I , N , L, R, and B (making L̂ and N̂ in those cases).",3.1 Algorithm definition,[0],[0]
"Edges between l and x can be added to items I (forming an X), R, and N .",3.1 Algorithm definition,[0],[0]
"Edges between r and x can be added to items I (forming an X), L, and N .",3.1 Algorithm definition,[0],[0]
"The l–r edge cannot be added after another edge, and N items cannot get both l–x and r–x edges.",3.1 Algorithm definition,[0],[0]
Combining Items: In the rules below the following notation is used: For this explanation items are T,3.1 Algorithm definition,[0],[0]
[lr crl clr] and T,3.1 Algorithm definition,[0],[0]
[lrx crl cxl clr cxr clx crx].,3.1 Algorithm definition,[0],[0]
T is the type of item.,3.1 Algorithm definition,[0],[0]
Multiple letters indicate any of those types are allowed.,3.1 Algorithm definition,[0],[0]
"For the next three types of notation, if an item does not have a mark, either option is valid.",3.1 Algorithm definition,[0],[0]
˙ T and T : indicate the number of edges between the external vertex and the span: one or more than one respectively.,3.1 Algorithm definition,[0],[0]
·T and T · indicate the position of the external vertex relative to the item’s span (left or right respectively).,3.1 Algorithm definition,[0],[0]
T̂ indicates for N and L that ∀p ∈,3.1 Algorithm definition,[0],[0]
(ij)∃rs : i≤r<p<s≤j.,3.1 Algorithm definition,[0],[0]
"In (11) and (12) it is optional, but true for output iff true for input.",3.1 Algorithm definition,[0],[0]
"l, r, and x: the position of the left end of the span, the right end, and the external vertex, respectively.",3.1 Algorithm definition,[0],[0]
"crl, cxl, etc: connectivity of each pair of visible vertices, from the first subscript to the second.",3.1 Algorithm definition,[0],[0]
"Using crl as an example, these can be .",3.1 Algorithm definition,[0],[0]
"(unconstrained), d ( ~rl must exist), p (l is reachable from r, but ~rl does not exist), n",3.1 Algorithm definition,[0],[0]
"(l is not reachable from r), d (= p ∨ n), n",3.1 Algorithm definition,[0],[0]
(= d ∨ p).,3.1 Algorithm definition,[0],[0]
Note:,3.1 Algorithm definition,[0],[0]
"In the generated rules every value is d, p, or n, leading to multiple rules per template below.
I[ij nd]← max   (Init) j = i+1 (1) I[i i+1 nn] I[i+1 j nn] maxk∈(i,j)   (2) I[ik nd] I[kj",3.1 Algorithm definition,[0],[0]
..],3.1 Algorithm definition,[0],[0]
(3) BLRN · [ikj nndddd] I[kj ..],3.1 Algorithm definition,[0],[0]
"maxl∈(k,j){ (4) RN ·",3.1 Algorithm definition,[0],[0]
[ikl nndddd] I[kl ..] ·LNX[ljk .d..d.] (5) BLRN · [ikl nndddd] I[kl ..] I[lj ..],3.1 Algorithm definition,[0],[0]
"maxl∈(i,k){ (6) I[il n.] ·LN [lki .d.dnn]",3.1 Algorithm definition,[0],[0]
"·N : [kjl ddd.d.]
(7) RNX· [ilk nn.ddd] I[lk ..]",3.1 Algorithm definition,[0],[0]
"·LN :: [kjl .d..d.]
B· [ijx nndddd]← maxk∈(i,j)  
(8) L̂N̂ ·",3.1 Algorithm definition,[0],[0]
[ikx nn.ddd] R·,3.1 Algorithm definition,[0],[0]
[kjx ...d.d] (9) L̂N̂ ·,3.1 Algorithm definition,[0],[0]
[ikx nn.ddd] N ·,3.1 Algorithm definition,[0],[0]
[kjx d.dd.d] (10) L̂N̂ ·,3.1 Algorithm definition,[0],[0]
[ikx nn.ddd] N ·,3.1 Algorithm definition,[0],[0]
"[kjx d.dd.d]
˙ L̂[ijx dddddd]←",3.1 Algorithm definition,[0],[0]
"maxk∈(i,j){
(11) X[ikx .d.dnn] · L̂N̂",3.1 Algorithm definition,[0],[0]
[kji .d.ddd] (12) X[ikx .d.ddd,3.1 Algorithm definition,[0],[0]
],3.1 Algorithm definition,[0],[0]
· L̂N̂,3.1 Algorithm definition,[0],[0]
"[kji .d.ddd]
L :",3.1 Algorithm definition,[0],[0]
"[ijx dddddd]← maxk∈(i,j)   (13) LN",3.1 Algorithm definition,[0],[0]
[ikx .d.ddd],3.1 Algorithm definition,[0],[0]
·N,3.1 Algorithm definition,[0],[0]
[kji dddddd] (14) LN,3.1 Algorithm definition,[0],[0]
[ikx .d.ddd],3.1 Algorithm definition,[0],[0]
·N,3.1 Algorithm definition,[0],[0]
[kji dddddd] (15) L[ikx .d.ddd] I[kj ..],3.1 Algorithm definition,[0],[0]
(16) L[ikx .d.ddd] I[kj ..],3.1 Algorithm definition,[0],[0]
(17) N,3.1 Algorithm definition,[0],[0]
[ikx dddddd] I[kj ..],3.1 Algorithm definition,[0],[0]
(18) N,3.1 Algorithm definition,[0],[0]
[ikx dddddd] I[kj ..],3.1 Algorithm definition,[0],[0]
(19) N,3.1 Algorithm definition,[0],[0]
[ikx dddddd] I[kj ..,3.1 Algorithm definition,[0],[0]
"]
(20) N",3.1 Algorithm definition,[0],[0]
"[ikx dddddd] I[kj ..]
N :",3.1 Algorithm definition,[0],[0]
"[ijx dddddd]← maxk∈(i,j)   (21) ·N [ikx dddddd] I[kj ..]",3.1 Algorithm definition,[0],[0]
(22) ·N [ikx dddddd] I[kj ..] (23) I[ik ..] N ·,3.1 Algorithm definition,[0],[0]
[kjx dddddd] (24) I[ik ..] N ·,3.1 Algorithm definition,[0],[0]
"[kjx dddddd]
˙ N",3.1 Algorithm definition,[0],[0]
"[ijx dddddd]← maxk∈(i,j)   (25) ·X[ikx .d.ddd] I[kj ..] (26) ·X[ikx .d.ddd] I[kj ..] (27) I[ik ..]",3.1 Algorithm definition,[0],[0]
X· [kjx .d.ddd] (28) I[ik ..],3.1 Algorithm definition,[0],[0]
"X· [kjx .d.ddd]
I[ij pn], ·B[ijx ddnndd], R : [ijx dddddd], and ˙ R[ijx dddddd] are symmetric with cases above.
",3.1 Algorithm definition,[0],[0]
"relative to the item spans, connectivity of every pair of vertices in each item, etc).
",3.1 Algorithm definition,[0],[0]
The final item for n vertices is an interval where the left end has a parent.,3.1 Algorithm definition,[0],[0]
For parsing we assume there is a special root word at the end of the sentence.,3.1 Algorithm definition,[0],[0]
Definition 1.,3.2 Properties,[0],[0]
"A graph is One-Endpoint Crossing if, when drawn with vertices along the edge of a halfplane and edges drawn in the open half-plane above, for any edge e, all edges that cross e share a vertex.",3.2 Properties,[0],[0]
"Let that vertex be Pt(e).
",3.2 Properties,[0],[0]
"Aside from applying to graphs, this is the same as
Pitler et al. (2013)’s 1-EC tree definition.
",3.2 Properties,[0],[0]
Definition 2.,3.2 Properties,[0],[0]
"A Locked-Chain (shown in Fig. 2) is formed by a set of consecutive vertices in order from 0 to N , where N > 3, with edges {(0, N−1), (1, N)} ∪ {(i, i+2)∀i ∈",3.2 Properties,[0],[0]
"[0, N−2]}.",3.2 Properties,[0],[0]
Definition 3.,3.2 Properties,[0],[0]
"A graph is Lock-Free if it does not contain edges that form a Locked-Chain.
",3.2 Properties,[0],[0]
"Note that in practice, most parse structures satisfy 1-EC, and the Locked-Chain structure does not occur in the PTB when using our head rules.
",3.2 Properties,[0],[0]
Theorem 1.,3.2 Properties,[0],[0]
"For the space of Lock-Free OneEndpoint Crossing graphs, the algorithm is sound, complete and gives unique decompositions.
",3.2 Properties,[0],[0]
Our proof is very similar in style and structure to Pitler et al. (2013).,3.2 Properties,[0],[0]
"The general approach is to consider the set of structures an item could represent, and divide them into cases based on properties of the internal structure.",3.2 Properties,[0],[0]
"We then show how each case can be decomposed into items, taking care to ensure all the properties that defined the case are satisfied.",3.2 Properties,[0],[0]
Uniqueness follows from having no ambiguity in how a given structure could be decomposed.,3.2 Properties,[0],[0]
"Completeness and soundness follow from the fact that our rules apply equally well in either direction, and so our top-down decomposition implies a bottom-up formation.",3.2 Properties,[0],[0]
"To give intuition for the proof, we show the derivation of one rule below.",3.2 Properties,[0],[0]
The complete proof can be found in Kummerfeld (2016).,3.2 Properties,[0],[0]
"We do not include it here due to lack of space.
",3.2 Properties,[0],[0]
"We do provide the complete set of rule templates in Algorithm 1, and in the proof of Lemma 2 we show that the case in which an item cannot be decomposed occurs if and only if the graph contains a Locked-Chain.",3.2 Properties,[0],[0]
"To empirically check our rule generation code, we checked that our parser uniquely decomposes all 1-EC parses in the PTB and is unable to decompose the rest.
",3.2 Properties,[0],[0]
"Note that by using subsets of our rules, we can restrict the space of structures we generate, giving parsing algorithms for projective DAGs, projective trees (Eisner 1996), or 1-EC trees (Pitler et al. 2013).",3.2 Properties,[0],[0]
"Versions of these spaces with undirected edges could also be easily handled with the same approach.
",3.2 Properties,[0],[0]
p qs t Derivation of rule (4) in Algorithm 1:,3.2 Properties,[0],[0]
"This rule applies to intervals with the substructure shown, and with no parent in this item for p.",3.2 Properties,[0],[0]
They have at least one p–(pq) edge (otherwise rule 1 applies).,3.2 Properties,[0],[0]
"The longest p–(pq) edge, ps, is crossed (otherwise rule 2 applies).",3.2 Properties,[0],[0]
Let C be the set of (ps)–(sq) edges (note: these cross ps).,3.2 Properties,[0],[0]
"Either all of the edges in C have a common endpoint t ∈ (sq), or if |C| = 1 let t be the endpoint in (sq) (otherwise rule 6 or 7 applies).",3.2 Properties,[0],[0]
Let D be the set of s–(tq) edges.,3.2 Properties,[0],[0]
|D| > 0,3.2 Properties,[0],[0]
"(otherwise rule 3 or 5 applies).
",3.2 Properties,[0],[0]
We will break this into three items.,3.2 Properties,[0],[0]
"First, (st)–(tq] edges would violate the 1-EC property and (st)–[ps) edges do not exist by construction.",3.2 Properties,[0],[0]
"Therefore, the middle item is an Interval [st], the left item is [ps.t], and the right item is [tq.s] (since |C| > 0 and |D| > 0).",3.2 Properties,[0],[0]
"The left item can be either
an N or R, but not an L or B because that would violate the 1-EC property for the C edges.",3.2 Properties,[0],[0]
"The right item can be an X , L, or N , but not an R or B because that would violate the 1-EC property for the D edges.",3.2 Properties,[0],[0]
"We will require edge ps to be present in the first item, and not allow pt.",3.2 Properties,[0],[0]
"To avoid a spurious ambiguity, we also prevent the first or third items from having st (which could otherwise occur in any of the three items).",3.2 Properties,[0],[0]
"Now we have broken down the original item into valid sub-items, and we have ensured that those sub-items contain all of the structure used to define the case in a unique way.
",3.2 Properties,[0],[0]
"Now we will further characterize the nature of the Lock-Free restriction to the space of graphs.
",3.2 Properties,[0],[0]
Lemma 1.,3.2 Properties,[0],[0]
No edge in a Locked-Chain in a 1-EC graph is crossed by edges that are not part of it.,3.2 Properties,[0],[0]
Proof.,3.2 Properties,[0],[0]
"First, note that: Pt((0, N−1))",3.2 Properties,[0],[0]
"= N , Pt((1, N))",3.2 Properties,[0],[0]
"= 0, and {Pt((i, i+2))",3.2 Properties,[0],[0]
= i+1,3.2 Properties,[0],[0]
∀i ∈,3.2 Properties,[0],[0]
"[0, N−2]} Call the set {(i, i+2)∀i ∈",3.2 Properties,[0],[0]
"[0, N−2]}, the chain.
Consider an edge e that crosses an edge f in a Locked-Chain.",3.2 Properties,[0],[0]
"Let ein be the end of e that is between the two ends of f , and eout be the other end.",3.2 Properties,[0],[0]
"One of e’s endpoints is at Pt(f), and Pt(e) is an endpoint of f .",3.2 Properties,[0],[0]
"There are three cases:
(i) f",3.2 Properties,[0],[0]
"= (1, N).",3.2 Properties,[0],[0]
"Here, eout = Pt(f) = 0, and ein ∈ (1, N).",3.2 Properties,[0],[0]
"For all vertices v ∈ (1, N) there is an edge g in the chain such that v is between the endpoints of g. Therefore, e will cross such an edge g. To satisfy the 1-EC property, g must share an endpoint with f , which means g is either (1, 3) or (N−2, N).",3.2 Properties,[0],[0]
"In the first case, the 1-EC property forces e = (0, 2), and in the second e = (0, N−1), both of which are part of the Locked-Chain.
(ii) f = (0, N−1), symmetrical with (i).",3.2 Properties,[0],[0]
"(iii) f = (i, i+2), for some i ∈",3.2 Properties,[0],[0]
"[0, N−2].",3.2 Properties,[0],[0]
"Here, ein = Pt(f) = i+1.",3.2 Properties,[0],[0]
"We can assume e does not cross (0, N−1) or (1, N), as those cases are covered by (i).",3.2 Properties,[0],[0]
"As in (i), e must cross another edge in the chain, and that edge must share an endpoint with f .
",3.2 Properties,[0],[0]
"This forces e to be either (i−1, i+1) or (i+1, i+3) (excluding one or both if they cross (0, N−1) or (1, N)), which are both in the Locked-Chain.
",3.2 Properties,[0],[0]
Our rules define a unique way to decompose almost any item into a set of other items.,3.2 Properties,[0],[0]
"The exception is B, which in some cases can not be divided into two items (i.e. has no valid binary division).
",3.2 Properties,[0],[0]
Lemma 2.,3.2 Properties,[0],[0]
A B[ij.x] has no valid binary division if and only if the graph has a Locked-Chain.,3.2 Properties,[0],[0]
Proof.,3.2 Properties,[0],[0]
Consider the k and l that give the longest ik and lj edges in a B with no valid binary division (at least one edge of each type must exist by definition).,3.2 Properties,[0],[0]
"No vertex in (ik) or (jl) is a valid split point, as they would all require one of the items to have two external vertices.
",3.2 Properties,[0],[0]
"Now, consider p ∈",3.2 Properties,[0],[0]
[kj].,3.2 Properties,[0],[0]
"If there is no edge l1r1, where i ≤ l1 < p < r1 ≤ j, then p would be a valid split point.",3.2 Properties,[0],[0]
"Therefore, such an edge must exist.",3.2 Properties,[0],[0]
"Consider l1, either l1 ∈ (ik) or there is an edge l2c, where i ≤ l2",3.2 Properties,[0],[0]
< l1 < c ≤ j (by the same logic as for l1r1).,3.2 Properties,[0],[0]
"Similarly, either r1 ∈ (jl) or there is an edge cr2 (it must be c to satisfy 1-EC).",3.2 Properties,[0],[0]
"We can also apply this logic to edges l2c and cr2, giving edges l3l1 and r1r3.",3.2 Properties,[0],[0]
This pattern will terminate when it reaches lu ∈ (ik) and rv ∈ (jl) with edges lulu−2 and rv−2rv.,3.2 Properties,[0],[0]
"Note that k = lu−1 and l = rv−1, to satisfy 1-EC.
",3.2 Properties,[0],[0]
"Since it is a B, there must be at least two x–(ij) edges.",3.2 Properties,[0],[0]
"To satisfy 1-EC, these end at lu−1 and rv−1.
",3.2 Properties,[0],[0]
"Let x be to the right (the left is symmetrical), and call i = 0, j = N−1, and x = N .",3.2 Properties,[0],[0]
"Comparing with the Locked-Chain definition, we have all the edges except one: 0 to N−1.",3.2 Properties,[0],[0]
"However, that edge must be present in the overall graph, as all B items start with an ij edge (see rules 3 and 5 in Algorithm 1).",3.2 Properties,[0],[0]
"Therefore, if there is no valid split point for a B, the overall graph must contain a Locked-Chain.
",3.2 Properties,[0],[0]
"Now, for a graph that contains a Locked-Chain, consider the items that contain the Locked-Chain.",3.2 Properties,[0],[0]
"Grouping them by their span [ij], there are five valid options:",3.2 Properties,[0],[0]
"[0, N−1], [1, N ], [0, N ], (i ≤ 0",3.2 Properties,[0],[0]
"∧ j > N ), and (i < 0",3.2 Properties,[0],[0]
∧ j ≥ N ).,3.2 Properties,[0],[0]
"Items of the last three types would be divided by our rules into smaller items, one of which contains the whole Locked-Chain.",3.2 Properties,[0],[0]
"The first two are Bs of the type discussed above.
",3.2 Properties,[0],[0]
"Now we will prove that our code to generate rules from the templates can guarantee a DAG is formed.
",3.2 Properties,[0],[0]
Lemma 3.,3.2 Properties,[0],[0]
"For any item H , ∀v ∈ covered(H) ∃u ∈ visible(H) : v is reachable from u. Proof.",3.2 Properties,[0],[0]
"This is true for initial items because covered(H) = ∅. To apply induction, consider adding edges and combing items.",3.2 Properties,[0],[0]
The lemma clearly remains true when adding an edge.,3.2 Properties,[0],[0]
"Consider combining items E, F , G to form H[ij.x], and assume the lemma is true for E, F , and G (the binary case is similar).",3.2 Properties,[0],[0]
"Since all vertices are reachable from visible(E,F,G), we only need to ensure that ∀v ∈",3.2 Properties,[0],[0]
"visible(E,F,G) ∃u ∈",3.2 Properties,[0],[0]
visible(H) : v is reachable from u.,3.2 Properties,[0],[0]
"The connectivity between all pairs {(u, v) | u ∈ visible(H), v ∈",3.2 Properties,[0],[0]
"visible(E,F,G)} can be inferred from the item definitions, and so this requirement can be enforced in rule generation.
",3.2 Properties,[0],[0]
Lemma 4.,3.2 Properties,[0],[0]
The final item is a directed acyclic graph.,3.2 Properties,[0],[0]
Proof.,3.2 Properties,[0],[0]
"First, consider acyclicity.",3.2 Properties,[0],[0]
Initial items do not contain any edges and so cannot contain a cycle.,3.2 Properties,[0],[0]
"For induction, there are two cases:
(i) Adding an Edge ~pq to an item H: Assume that H does not contain any cycles.",3.2 Properties,[0],[0]
"~pq will create a cycle if and only if p is reachable from q. By construction, p and q ∈ visible(H), and so the item definition contains whether p is reachable from q.
(ii)",3.2 Properties,[0],[0]
"Combining Items: Assume that in isolation, none of the items being combined contain cycles.",3.2 Properties,[0],[0]
"Therefore, a cycle in the combined item must be composed of paths in multiple items.",3.2 Properties,[0],[0]
A path in one item can only continue in another item by passing through a visible vertex.,3.2 Properties,[0],[0]
"Therefore, a cycle would have to be formed by a set of paths between visible vertices.",3.2 Properties,[0],[0]
"But the connectivity of every pair of visible vertices is specified in the item definitions.
",3.2 Properties,[0],[0]
"In both cases, rules that create a cycle can be excluded during rule generation.
",3.2 Properties,[0],[0]
"By induction, the items constructed by our algorithm do not contain cycles.",3.2 Properties,[0],[0]
"Together with Lemma 3 and the final item definition, this means the final structure is an acyclic graph with all vertices reachable from vertex n.
Next, we will show two properties that give intuition for the algorithm.",3.2 Properties,[0],[0]
"Specifically, we will prove which rules add edges that are crossed in the final derivation.
",3.2 Properties,[0],[0]
Lemma 5.,3.2 Properties,[0],[0]
An edge ij added to I[ij] is not crossed.,3.2 Properties,[0],[0]
Proof.,3.2 Properties,[0],[0]
"First, we will show three properties of any pair of items in a derivation (using [ij.x] and [kl.y]).
",3.2 Properties,[0],[0]
(1) It is impossible for either i <,3.2 Properties,[0],[0]
k,3.2 Properties,[0],[0]
< j < l or k,3.2 Properties,[0],[0]
< i,3.2 Properties,[0],[0]
<,3.2 Properties,[0],[0]
"l < j, i.e., items cannot have partially overlapping spans.",3.2 Properties,[0],[0]
"As a base case, the final item is an interval spanning all vertices, and so no other item can partially overlap with it.",3.2 Properties,[0],[0]
"Now assume it is true for an item H and consider the rules in reverse, breaking H up.",3.2 Properties,[0],[0]
"By construction, each rule divides H into items with spans that are adjacent, overlapping only at their visible vertices.",3.2 Properties,[0],[0]
"Since the new items are nested within H , they do not overlap with any items H did not overlap with.",3.2 Properties,[0],[0]
"By induction, no pair of items have partially overlapping spans.
",3.2 Properties,[0],[0]
(2) For items with nested spans (i ≤ k,3.2 Properties,[0],[0]
"< l ≤ j), y ∈",3.2 Properties,[0],[0]
[ij]∪{x}.,3.2 Properties,[0],[0]
"Following the argument for the previous case, the [ij.x] item must be decomposed into a set of items that includes [kl.y].",3.2 Properties,[0],[0]
"Now, consider how those items are combined.",3.2 Properties,[0],[0]
"The rules that start with an item with an external vertex produce an item that either has the same external vertex, or with the external vertex inside the span of the new item.",3.2 Properties,[0],[0]
"Therefore, y must either be equal to x or inside [ij].
(3) For items without nested spans, x /∈",3.2 Properties,[0],[0]
(kl).,3.2 Properties,[0],[0]
Assume x ∈,3.2 Properties,[0],[0]
(kl) for two items without nested spans.,3.2 Properties,[0],[0]
"None of the rules combine such a pair of items, or allow one to be extended so that the other is nested within it.",3.2 Properties,[0],[0]
"However, all items are eventually combined to complete the derivation.",3.2 Properties,[0],[0]
"By contradiction, x /∈ (kl).
",3.2 Properties,[0],[0]
"Together, these mean that given an interval H with span [ij], and another item G, either ∀v ∈ visible(G), v ∈",3.2 Properties,[0],[0]
"[ij] or ∀v ∈ visible(G),",3.2 Properties,[0],[0]
v /∈,3.2 Properties,[0],[0]
(ij).,3.2 Properties,[0],[0]
"Since edges are only created between visible vertices, no edge can cross edge ij.
Lemma 6.",3.2 Properties,[0],[0]
"All edges aside from those considered in Lemma 5 are crossed.
",3.2 Properties,[0],[0]
Proof.,3.2 Properties,[0],[0]
"First, consider an edge ij added to an item [ij.x] of type B, L, R, or N. This edge is crossed by all x–(ij) edges, and in these items |x–(ij)| ≥ 1 by definition.",3.2 Properties,[0],[0]
"Note, by the same argument as Lemma 5, the edge is not crossed later in the derivation.
",3.2 Properties,[0],[0]
"Second, consider adding e ∈ {xi, xj}, to H , an item with [ij] or [ij.x], forming an item G[ij.x].",3.2 Properties,[0],[0]
"Note, e does not cross any edges in H .",3.2 Properties,[0],[0]
Let E(F,3.2 Properties,[0],[0]
[kl.y]) be the set of y–[kl] edges in some item F .,3.2 Properties,[0],[0]
Note that e ∈ E(G).,3.2 Properties,[0],[0]
"We will show how this set of edges is affected by the rules and what that implies for e. Consider each input item A[kl.y] in each
rule, with output item C. Every item A falls into one of four categories: (1) ∀f ∈ E(A), f is crossed by an edge in another of the rule’s input items, (2) E(A) ⊆ E(C), (3) A∧ kl 7→ C",3.2 Properties,[0],[0]
"and there are no ky or ly edges in A, (4)",3.2 Properties,[0],[0]
"A contains edge kl and there are no ky or ly edges in A.
Cases 2-4 are straightforward to identify.",3.2 Properties,[0],[0]
"For an example of the first case, consider the rightmost item in rule 4.",3.2 Properties,[0],[0]
"The relevant edges are k–(lj] (by construction, kl is not present).",3.2 Properties,[0],[0]
"Since the leftmost item is either an R or N, |l–(ik)| ≥ 1.",3.2 Properties,[0],[0]
Since i < k,3.2 Properties,[0],[0]
"< l < j, all k–(lj] edges will cross all l–[ik) edges.",3.2 Properties,[0],[0]
"Therefore applying this rule will cross all k–(lj] edges in the rightmost item.
",3.2 Properties,[0],[0]
"Initially, e is not crossed and e ∈ E(G).",3.2 Properties,[0],[0]
"For each rule application, edges in E(A) are either crossed (1 and 3), remain in the set E(C)",3.2 Properties,[0],[0]
"(2), or must already be crossed (4).",3.2 Properties,[0],[0]
Since the final item is an interval and E(Interval) =,3.2 Properties,[0],[0]
"∅, there must be a subsequent rule that is not in case 2.",3.2 Properties,[0],[0]
Therefore e will be crossed.,3.2 Properties,[0],[0]
"Our algorithm is based on Pitler et al. (2013), which had the crucial idea of One-Endpoint crossing and a complete decomposition of the tree case.",3.3 Comparison with Pitler et al. (2013),[0],[0]
"Our changes and extensions provide several benefits:
Extension to graphs: By extending to support multiple parents while preventing cycles, we substantially expand the space of generatable structures.
",3.3 Comparison with Pitler et al. (2013),[0],[0]
Uniqueness:,3.3 Comparison with Pitler et al. (2013),[0],[0]
By avoiding derivational ambiguity we reduce the search space and enable efficient summing as well as maxing.,3.3 Comparison with Pitler et al. (2013),[0],[0]
Most of the cases in which ambiguity arises in Pitler et al. (2013)’s algorithm are due to symmetry that is not explicitly broken.,3.3 Comparison with Pitler et al. (2013),[0],[0]
"For example, the rule we worked through in the previous section defined t ∈ (sq)",3.3 Comparison with Pitler et al. (2013),[0],[0]
when |C| = 1.,3.3 Comparison with Pitler et al. (2013),[0],[0]
"Picking t ∈ (ps) would also lead to a valid set of rules, but allowing either creates a spurious ambiguity.",3.3 Comparison with Pitler et al. (2013),[0],[0]
"This ambiguity is resolved by tracking whether there is only one edge to the external vertex or more than one, and requiring more than one in rules 6 and 7.",3.3 Comparison with Pitler et al. (2013),[0],[0]
"Other changes include ensuring equivalent structures cannot be represented by multiple item types and enforcing a unique split point in B items.
",3.3 Comparison with Pitler et al. (2013),[0],[0]
"More concise algorithm definition: By separating edge creation from item merging, and defining our rules via a combination of templates and code, we are able to define our algorithm more concisely.",3.3 Comparison with Pitler et al. (2013),[0],[0]
Edge labels can be added by calculating either the sum or max over edge types when adding each edge.,3.4.1 Edge Labels and Word Labels,[0],[0]
"Word labels (e.g., POS Tags) must be added to the state, specifying a label for each visible word (p, q and o).",3.4.1 Edge Labels and Word Labels,[0],[0]
This state expansion is necessary to ensure agreement when combining items.,3.4.1 Edge Labels and Word Labels,[0],[0]
"Our algorithm constrains the space of graph structures, but we also want to ensure that our parse contains a projective tree of non-trace edges.
",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"To ensure every word gets one and only one structural parent, we add booleans to the state, indicating whether p, q and o have structural parents.",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"When adding edges, a structural edge cannot be added if a word already has a structural parent.",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"When combining items, no word can receive more than one structural parent, and words that will end up in the middle of the span must have exactly one.",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"Together, these constraints ensure we have a tree.
",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"To ensure the tree is projective, we need to prevent structural edges from crossing.",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"Crossing edges are introduced in two ways, and in both we can avoid structural edges crossing by tracking whether there are structural o–[pq] edges.",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"Such edges are present if a rule adds a structural op or oq edge, or if a rule combines an item with structural o–[pq] edges and o will still be external in the item formed by the rule.
",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"For adding edges, every time we add a pq edge in the N , L, R and B items we create a crossing with all o–(pq) edges.",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"We do not create a crossing with oq or op, but our ordering of edge creation means these are not present when we add a pq edge, so tracking structural o–[pq] edges gives us the information we need to prevent two structural edges crossing.
",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"For combining items, in Lemma 6 we showed that during combinations, o–[pq] edges in each pair of items will cross.",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"As a result, knowing whether any o–[pq] edge is structural is sufficient to determine whether two structural edges will cross.",3.4.2 Ensuring a Structural Tree is Present,[0],[0]
"Consider a sentence with n tokens, and let E and S be the number of edge types and word labels in our grammar respectively.
",3.5 Complexity,[0],[0]
"Parses without word or edge labels: Rules have up to four positions, leading to complexity of O(n4).",3.5 Complexity,[0],[0]
"Note, there is also an important constant–once our templates are expanded, there are 49,292 rules.
",3.5 Complexity,[0],[0]
"With edge labels: When using a first-order model, edge labels only impact the rules for edge creation, leading to a complexity of O(n4 + En2).
",3.5 Complexity,[0],[0]
"With word labels: Since we need to track word labels in the state, we need to adjust every n by a factor of S, leading to O(S4n4 + ES2n2).",3.5 Complexity,[0],[0]
Our algorithm relies on the assumption that we can process the dependents to the left and right of a word independently and then combine the two halves.,4 Parse Representation,[0],[0]
"This means we need lexicalized structures, which the PTB does not provide.",4 Parse Representation,[0],[0]
We define a new representation in which each non-terminal symbol is associated with a specific word (the head).,4 Parse Representation,[0],[0]
"Unlike dependency parsing, we retain all the information required to reconstruct the constituency parse.
",4 Parse Representation,[0],[0]
"Our approach is related to Carreras et al. (2008) and Hayashi and Nagata (2016), with three key differences: (1) we encode non-terminals explicitly, rather than implicitly through adjunction operations, which can cause ambiguity, (2) we add representations of null elements and co-indexation, (3) we modify head rules to avoid problematic structures.
",4 Parse Representation,[0],[0]
Figure 3 shows a comparison of the PTB representation and ours.,4 Parse Representation,[0],[0]
"We add lexicalization, assigning each non-terminal to a word.",4 Parse Representation,[0],[0]
"The only other changes are visual notation, with non-terminals moved to be directly above the words to more clearly show the distinction between spines and edges.
",4 Parse Representation,[0],[0]
Spines:,4 Parse Representation,[0],[0]
"Each word is assigned a spine, shown im-
mediately above the word.",4 Parse Representation,[0],[0]
"A spine is the ordered set of non-terminals that the word is the head of, e.g. SVP for like.",4 Parse Representation,[0],[0]
"If a symbol occurs more than once in a spine, we use indices to distinguish instances.
",4 Parse Representation,[0],[0]
"Edges: An edge is a link between two words, with a label indicating the symbols it links in the child and parent spines.",4 Parse Representation,[0],[0]
"In our figures, edge labels are indicated by where edges start and end.
",4 Parse Representation,[0],[0]
"Null Elements: We include each null element in the spine of its parent, unlike Hayashi and Nagata (2016), who effectively treated null elements as words, assigning them independent spines.",4 Parse Representation,[0],[0]
"We also considered encoding null elements entirely on edges but found this led to poorer performance.
",4 Parse Representation,[0],[0]
Co-indexation:,4 Parse Representation,[0],[0]
"The treebank represents movement with index pairs on null elements and nonterminals, e.g. *1 and NP1 in Figure 3.",4 Parse Representation,[0],[0]
"We represent co-indexation with edges, one per reference, going from the null element to the non-terminal.",4 Parse Representation,[0],[0]
There are three special cases of co-indexation: (1) It is possible for trace edges to have the same start and end points as a non-trace edge.,4 Parse Representation,[0],[0]
We restrict this case to allow at most one trace edge.,4 Parse Representation,[0],[0]
This decreases edge coverage in the training set by 0.006%.,4 Parse Representation,[0],[0]
"(2) In some cases the reference non-terminal only spans a null element, e.g. the WHNP in Figure 4a.",4 Parse Representation,[0],[0]
For these we use a reversed edge to avoid creating a cycle.,4 Parse Representation,[0],[0]
"Figure 4a shows a situation where the trace edge links two positions in the same spine, which we assign with the spine during parsing.",4 Parse Representation,[0],[0]
(3) For parallel constructions the treebank coindexes arguments that fulfill the same roles (Fig. 4b).,4 Parse Representation,[0],[0]
These are distinct from the previous cases because neither index is on a null element.,4 Parse Representation,[0],[0]
"We considered two options: add edges from the repetition
to the referent (middle), or add edges from the repetition to the parent of the first occurrence (bottom).",4 Parse Representation,[0],[0]
"Option two produces fewer non-1-EC structures and explicitly represents all predicates, but only implicitly captures the original structure.",4 Parse Representation,[0],[0]
Prior work on parsing with spines has used radjunction to add additional non-terminals to spines.,4.1 Avoiding Adjunction Ambiguity,[0],[0]
"This introduces ambiguity, because edges modifying the same spine from different sides may not have a unique order of application.",4.1 Avoiding Adjunction Ambiguity,[0],[0]
We resolve this issue by using more articulated spines with the complete set of non-terminals.,4.1 Avoiding Adjunction Ambiguity,[0],[0]
"We found that 0.045% of spine instances in the development set are not observed in training, though in 70% of those cases an equivalent spine sans null elements is observed in training.",4.1 Avoiding Adjunction Ambiguity,[0],[0]
"To construct the spines, we lexicalize with head rules that consider the type of each non-terminal and its children.",4.2 Head Rules,[0],[0]
Different heads often represent more syntactic or semantic aspects of the phrase.,4.2 Head Rules,[0],[0]
"For trees, all head rules generate valid structures.",4.2 Head Rules,[0],[0]
"For graphs, head rules influence the creation of two problematic structures:
Cycles: These arise when the head chosen for a phrase is also an argument of another word in the phrase.",4.2 Head Rules,[0],[0]
Figure 5a shows a cycle between which and proposed.,4.2 Head Rules,[0],[0]
"We resolve this by changing the head of an SBAR to be an S rather than a Wh-noun phrase.
",4.2 Head Rules,[0],[0]
"One-Endpoint Crossing Violations: Figure 5b shows an example, with the trace from CEO to Page crossing two edges with no endpoints in common.",4.2 Head Rules,[0],[0]
We resolve this case by changing the head for VPs to be a child VP rather than an auxiliary.,4.2 Head Rules,[0],[0]
Algorithm Coverage: In Table 1 we show the impact of design decisions for our representation.,5 Results,[0],[0]
The percentages indicate how many sentences in the training set are completely recoverable by our algorithm.,5 Results,[0],[0]
"Each row shows the outcome of an addition to the previous row, starting from no traces at all, going to our representation with the head rules of Carreras et al. (2008), then changing the head rules, reversing null-null edges, and changing the target of edges in parallel constructions.",5 Results,[0],[0]
"The largest gain comes from changing the head rules, which is unsurprising since Carreras et al. (2008)’s rules were designed for trees (any set of rules form valid structures for trees).
",5 Results,[0],[0]
"Problematic Structures: Of the sentences we do not cover, 54% contain a cycle, 45% contain a 1- EC violation, and 1% contain both.",5 Results,[0],[0]
"To understand these problematic sentences, we manually inspected a random sample of twenty parses that contained a cycle and twenty parses with a 1-EC violation (these forty are 6% of all problematic parses, enough to identify the key remaining challenges).
",5 Results,[0],[0]
"For the cycles, eleven cases related to sentences containing variations of NP said interposed between two parts of a single quote.",5 Results,[0],[0]
A cycle was present because the top node of the parse was co-indexed with a null argument of said while said was an argument of the head word of the quote.,5 Results,[0],[0]
"The remaining cases were all instances of pseudo-attachment, which the treebank uses to show that non-adjacent constituents are related (Bies et al. 1995).",5 Results,[0],[0]
"These cases were split between use of Expletive (5) and Interpret Constituent Here (4) traces.
",5 Results,[0],[0]
It was more difficult to determine trends for cases where the parse structure has a 1-EC violation.,5 Results,[0],[0]
"The same three cases, Expletive, Interpret Constituent Here, and NP said accounted for half of the issues.",5 Results,[0],[0]
We implemented a parser with a first-order model using our algorithm and representation.,5.1 Implementation,[0],[0]
"Code for the parser, for conversion to and from our representation, and for our metrics is available3.",5.1 Implementation,[0],[0]
"Our parser uses a linear discriminative model, with features based on McDonald et al. (2005).",5.1 Implementation,[0],[0]
"We train
3 https://github.com/jkkummerfeld/ 1ec-graph-parser
with an online primal subgradient approach (Ratliff et al. 2007) as described by Kummerfeld, BergKirkpatrick, et al. (2015), with parallel lock-free sparse updates.
",5.1 Implementation,[0],[0]
"Loss Function: We use a weighted Hamming distance for loss-augmented decoding, as it can be efficiently decomposed within our dynamic program.",5.1 Implementation,[0],[0]
Calculating the loss for incorrect spines and extra edges is easy.,5.1 Implementation,[0],[0]
"For missing edges, we add when a deduction rule joins two spans that cover an end of the edge, since if it does not exist in one of those items it is not going to be created in future.",5.1 Implementation,[0],[0]
"To avoid double counting we subtract when combining two halves that contain the two ends of a gold edge4.
",5.1 Implementation,[0],[0]
Inside–Outside Calculations:,5.1 Implementation,[0],[0]
"Assigning scores to edges is simple, as they are introduced in a single item in the derivation.",5.1 Implementation,[0],[0]
"Spines must be introduced in multiple items (left, right, and external positions) and must be assigned a score in every case to avoid ties in beams.",5.1 Implementation,[0],[0]
"We add the score every time the spine is introduced and then subtract when two items with a spine in common are combined.
",5.1 Implementation,[0],[0]
Algorithm rule pruning: Many 1-EC structures are not seen in our data.,5.1 Implementation,[0],[0]
"We keep only the rules used in gold training parses, reducing the set of 49,292 from the general algorithm to 627 (including rules for both adding arcs and combining items).",5.1 Implementation,[0],[0]
"Almost every template in Algorithm 1 generates some unnecessary rules, and no items of type B are needed.
",5.1 Implementation,[0],[0]
"4 One alternative is to count half of it on each end, removing the need for subtraction later.",5.1 Implementation,[0],[0]
"Another is to add it during the combination step.
",5.1 Implementation,[0],[0]
"The remaining rules still have high coverage of the development set, missing only 15 rules, each applied once (out of 78,692 rule applications).",5.1 Implementation,[0],[0]
"By pruning in this way, we are considering the intersection of 1-EC graphs and the true space of structures used in language.
",5.1 Implementation,[0],[0]
"Chart Pruning: To improve speed we use beams and cube pruning (Chiang 2007), discarding items based on their Viterbi inside score.",5.1 Implementation,[0],[0]
We divide each beam into sub-beams based on aspects of the state.,5.1 Implementation,[0],[0]
"This ensures diversity and enables consideration of only compatible items during binary and ternary compositions.
",5.1 Implementation,[0],[0]
"Coarse to Fine Pruning: Rather than parsing immediately with the full model we use several passes with progressively richer structure (Goodman 1997): (1) Projective parsing without traces or spines, and simultaneously a trace classifier, (2) Non-projective parsing without spines, and simultaneously a spine classifier, (3) Full structure parsing.",5.1 Implementation,[0],[0]
"Each pass prunes using parse max-marginals and classifier scores, tuned on the development set.",5.1 Implementation,[0],[0]
The third pass also prunes spines that are not consistent with any unpruned edge from the second pass.,5.1 Implementation,[0],[0]
"For the spine classifier we use a bidirectional LSTM tagger, implemented in DyNet (Neubig et al. 2017).
",5.1 Implementation,[0],[0]
Speed: Parsing took an average of 8.6 seconds per sentence for graph parsing and 0.5 seconds when the parser is restricted to trees5.,5.1 Implementation,[0],[0]
"Our algorithm is also amenable to methods such as semi-supervised and adaptive supertagging, which can improve the speed of a parser after training (Kummerfeld, Roesner, et al. 2010; Lewis and Steedman 2014).
",5.1 Implementation,[0],[0]
Tree Accuracy:,5.1 Implementation,[0],[0]
"On the standard tree-metric, we score 88.1.",5.1 Implementation,[0],[0]
"Using the same non-gold POS tags as input, Carreras et al. (2008) score 90.9, probably due to their second-order features and head rules tuned for performance6.",5.1 Implementation,[0],[0]
"Shifting to use their head rules, we score 88.9.",5.1 Implementation,[0],[0]
"Second-order features could be added to our model through the use of forest reranking, an improvement that would be orthogonal to this paper’s contributions.
",5.1 Implementation,[0],[0]
We can also evaluate on spines and edges.,5.1 Implementation,[0],[0]
"Since their system produces regular PTB trees, we con-
5 Using a single core of an Amazon EC2 m4.2xlarge instance (2.4 GHz Xeon CPU and 32 Gb of RAM).
",5.1 Implementation,[0],[0]
"6 Previous work has shown that the choice of head can significantly impact accuracy (Schwartz et al. 2012).
vert its output to our representation and compare its results with our system using their head rules.",5.1 Implementation,[0],[0]
"We see slightly lower accuracy for our system on both spines (94.0 vs. 94.3) and edges (90.4 vs. 91.1).
",5.1 Implementation,[0],[0]
Trace Accuracy: Table 2 shows results using Johnson (2002)’s trace metric.,5.1 Implementation,[0],[0]
"Our parser is competitive with previous work that has highly-engineered models: Johnson’s system has complex non-local features on tree fragments, and similarly Kato and Matsubara (K&M 2016) consider complete items in the stack of their transition-based parser.",5.1 Implementation,[0],[0]
On co-indexation our results fall between Johnson and K&M.,5.1 Implementation,[0],[0]
"Converting to our representation, our parser has higher precision than K&M on trace edges (84.1 vs. 78.1) but lower recall (59.5 vs. 71.3).",5.1 Implementation,[0],[0]
"One modeling challenge we observed is class imbalance: of the many places a trace could be added, only a small number are correct, and so our model tends to be conservative (as shown by the P/R tradeoff).",5.1 Implementation,[0],[0]
We propose a representation and algorithm that cover 97.3% of graph structures in the PTB.,6 Conclusion,[0],[0]
"Our algorithm is O(n4), uniquely decomposes parses, and enforces the property that parses are composed of a core tree with additional traces and null elements.",6 Conclusion,[0],[0]
A proof of concept parser shows that our algorithm can be used to parse and recover traces.,6 Conclusion,[0],[0]
"We thank Greg Durrett for advice on parser implementation and debugging, and the action editor and anonymous reviewers for their helpful feedback.",Acknowledgments,[0],[0]
"This research was partially supported by a General Sir John Monash Fellowship and the Office of Naval
Research under MURI Grant",Acknowledgments,[0],[0]
No. N000140911081.,Acknowledgments,[0],[0]
"General treebank analyses are graph structured, but parsers are typically restricted to tree structures for efficiency and modeling reasons.",abstractText,[0],[0]
"We propose a new representation and algorithm for a class of graph structures that is flexible enough to cover almost all treebank structures, while still admitting efficient learning and inference.",abstractText,[0],[0]
"In particular, we consider directed, acyclic, one-endpoint-crossing graph structures, which cover most long-distance dislocation, shared argumentation, and similar tree-violating linguistic phenomena.",abstractText,[0],[0]
"We describe how to convert phrase structure parses, including traces, to our new representation in a reversible manner.",abstractText,[0],[0]
"Our dynamic program uniquely decomposes structures, is sound and complete, and covers 97.3% of the Penn English Treebank.",abstractText,[0],[0]
We also implement a proofof-concept parser that recovers a range of null elements and trace types.,abstractText,[0],[0]
Parsing with Traces: An O(n) Algorithm and a Structural Representation,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2411–2420 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"During the last decade, social media have become extremely popular, on which billions of usergenerated contents are posted every day.",1 Introduction,[0],[0]
Many users have been writing about their thoughts and lives on the go.,1 Introduction,[0],[0]
"The massive unstructured data from social media provides valuable information for a variety of applications such as stock prediction (Bollen et al., 2011), public health analysis (Wilson and Brownstein, 2009; Paul and Dredze, 2011), real-time event detection (Sakaki et al., 2010), and so on.",1 Introduction,[0],[0]
"The quality of these applications is highly impacted by the performance of natural language processing tasks.
∗Corresponding author.
",1 Introduction,[0],[0]
Part-of-speech (POS) tagging is one of the most important natural language processing tasks.,1 Introduction,[0],[0]
"It has also been widely used in the social media analysis systems (Ritter et al., 2012; Lamb et al., 2013; Kiritchenko et al., 2014).",1 Introduction,[0],[0]
Most stateof-the-art POS tagging approaches are based on supervised methods.,1 Introduction,[0],[0]
"Hence, they usually require a large amount of annotated data to train models.",1 Introduction,[0],[0]
Many datasets have been constructed for POS tagging task.,1 Introduction,[0],[0]
"Because newswire articles are carefully edited, benchmarks usually use them for annotation (Marcus et al., 1993).",1 Introduction,[0],[0]
"However, usergenerated contents on social media are usually informal and contain many nonstandard lexical items.",1 Introduction,[0],[0]
"Moreover, the difference in domains between training data and evaluation data may heavily impact the performance of approaches based on supervised methods (Caruana and NiculescuMizil, 2006).",1 Introduction,[0],[0]
"Hence, most POS tagging methods cannot achieve the same performance as reported on newswire domain when applied on Twitter (Owoputi et al., 2013).
",1 Introduction,[0],[0]
"To perform the Twitter POS tagging task, some approaches have been proposed to perform the task.",1 Introduction,[0],[0]
"Gimpel et al. (2011) manually annotated 1,827 tweets and carefully studied various fea-
2411
tures.",1 Introduction,[0],[0]
"Ritter et al. (2011) also constructed a labeled dataset, which contained 787 tweets, to empirically evaluate the performance of supervised methods on Twitter.",1 Introduction,[0],[0]
Owoputi et al. (2013) incorporated word clusters into the feature sets and further improved the performance.,1 Introduction,[0],[0]
"From these works, we can observe that the size of the training data was much smaller than the newswire domain’s.
",1 Introduction,[0],[0]
"Besides the challenge of lack of training data, the frequent use of out-of-vocabulary words also makes this problem difficult to address.",1 Introduction,[0],[0]
"Social media users often use informal ways of expressing their ideas and often spell words phonetically (e.g., “2mor” for “tomorrow”).",1 Introduction,[0],[0]
"In addition, they also make extensive use of emoticons and abbreviations (e.g., “:-)” for smiling emotion and “LOL” for laughing out loud).",1 Introduction,[0],[0]
"Moreover, new symbols, abbreviations, and words are constantly being created.",1 Introduction,[0],[0]
"Figure 1 shows an example of tagged Tweet.
",1 Introduction,[0],[0]
"To tackle the challenges posed by the lack of training data and the out-of-vocabulary words, in this paper, we propose a novel recurrent neural network, which we call Target Preserved Adversarial Neural Network (TPANN) to perform the task.",1 Introduction,[0],[0]
"It can make use of a large quantity of annotated data from other resourcerich domains, unlabeled in-domain data, and a small amount of labeled in-domain data.",1 Introduction,[0],[0]
All of these datasets can be easily obtained.,1 Introduction,[0],[0]
"To make use of unlabeled data, motivated by the work of Goodfellow et al. (2014) and Chen et al. (2016), the proposed method extends the bi-directional long short-term memory recurrent neural network (bi-LSTM) with an adversarial predictor.",1 Introduction,[0],[0]
"To overcome the defect that adversarial networks can merely learn the common features, we propose to use an autoencoder only acting on target dataset to preserve its own specific features.",1 Introduction,[0],[0]
"For tackling the out-of-vocabulary problem, the proposed method also incorporates a character level convolutional neutral network to leverage subword information.
",1 Introduction,[0],[0]
"The contributions of this work are as follows:
• We propose to incorporate large scale unlabeled in-domain data, out-of-domain labeled data, and in-domain labeled data for Twitter part-of-speech tagging task.
",1 Introduction,[0],[0]
"• We introduce a novel recurrent neural network, which can learn domain-invariant rep-
resentations through in-domain and out-ofdomain data and construct a cross domain POS tagger through the learned representations.",1 Introduction,[0],[0]
"The proposed method also tries to preserve the specific features of target domain.
",1 Introduction,[0],[0]
• Experimental results demonstrate that the proposed method can lead to better performance in most of cases on three different datasets.,1 Introduction,[0],[0]
"In this work, we propose a novel recurrent neural network, Target Preserved Adversarial Neural Network (TPANN), to learn common features between resource-rich domain and target domain, simultaneously to preserve target domain-specific features.",2 Approach,[0],[0]
It extends the bi-directional LSTM with adversarial network and autoencoder.,2 Approach,[0],[0]
The architecture of TPANN is illustrated in Figure 2.,2 Approach,[0],[0]
"The model consists of four components: Feature Extractor, POS Tagging Classifier, Domain Discriminator and Target Domain Autoencoder.",2 Approach,[0],[0]
"In the following sections, we will detail each part of the proposed architecture and training methods.",2 Approach,[0],[0]
"The feature extractor F adopts CNN to extract character embedding features, which can tackle the out-of-vocabulary word problem effectively.",2.1 Feature Extractor,[0],[0]
"To incorporate word embedding features, we concatenate word embedding to character embedding as the input of bi-LSTM on the next layer.",2.1 Feature Extractor,[0],[0]
"Utilizing a bi-LSTM to model sentences, F can extract sequential relations and context information.
",2.1 Feature Extractor,[0],[0]
"We denote the input sentence as x and the i-th word as xi. xi ∈ S(x) and xi ∈ T (x) represent input samples are from source domain and target domain, respectively.",2.1 Feature Extractor,[0],[0]
We denote the parameters of F as θf .,2.1 Feature Extractor,[0],[0]
"Let V be the vocabulary of words, and C be the vocabulary of characters.",2.1 Feature Extractor,[0],[0]
d is the dimensionality of character embedding then Q ∈ Rd×|C| is the representation matrix of vocabulary.,2.1 Feature Extractor,[0],[0]
We assume that word xi ∈ V is made up of a sequence of characters Ci =,2.1 Feature Extractor,[0],[0]
"[c1, c2, . . .",2.1 Feature Extractor,[0],[0]
", cl], where l is the max length of word and every word will be padded to this length.",2.1 Feature Extractor,[0],[0]
"Then Ci ∈ Rd×l would be the inputs of CNN.
",2.1 Feature Extractor,[0],[0]
"We apply a narrow convolution between Ci and filter H ∈ Rd×k, where k is the width of the filter.
",2.1 Feature Extractor,[0],[0]
After that we add a bias and apply nonlinearity to obtain a feature map mi ∈ Rl−k+1.,2.1 Feature Extractor,[0],[0]
"Specifically, the j-th element of mi is given by:
ik[j] = tanh(〈Ci[∗, j : j + k",2.1 Feature Extractor,[0],[0]
"− 1],H〉+ b), (1)
where Ck[∗, j : j + k",2.1 Feature Extractor,[0],[0]
− 1] is the j-to-(j + k,2.1 Feature Extractor,[0],[0]
"− 1)-th column of Ci and 〈A,B〉 = Tr(ABT ) is the Frobenius inner product.",2.1 Feature Extractor,[0],[0]
"We then apply a max-over-time pooling operation (Collobert et al., 2011) over the feature map.",2.1 Feature Extractor,[0],[0]
CNN uses multiple filters with varying widths to obtain the feature vector ~ci for word xi.,2.1 Feature Extractor,[0],[0]
"Then, the character-level feature vector ~ci is concatenated to the word embedding ~wi to form the input of bi-LSTM on the next layer.",2.1 Feature Extractor,[0],[0]
The word embedding ~w is pretrained on 30 million tweets.,2.1 Feature Extractor,[0],[0]
"Then, the hidden states h of bi-LSTM turn into the features that will be transfered to P , Q andR, i.e. F(x) = h.",2.1 Feature Extractor,[0],[0]
POS tagging classifier P and domain discriminator Q take F(x) as input.,2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
They are standard feed-forward networks with a softmax layer for classification.,2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"P predicts POS tagging label to get classification capacity, and Q discriminates domain label to make F(x) domain-invariant.
",2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
The POS tagging classifier P maps the feature vector F(xi) to its label.,2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
We denote the parameters of this mapping as θy.,2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"The POS tagging
classifier is trained on Ns samples from the source domain with the cross entropy loss:
",2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
Ltask =,2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
− Ns∑ i=1,2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"yi ∗ log ŷi, (2)
where yi is the one-hot vector of POS tagging label corresponding to xi ∈ S(x), ŷi is the output of top softmax layer:",2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
ŷi = P(F(xi)).,2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"During the training time, The parameters θf and θy are optimized to minimize the classification loss Ltask.",2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"This ensures that P(F(xi)) can make accurate prediction on the source domain.
",2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"Conversely, domain discriminator maps the same hidden states h to the domain labels with parameters θd.",2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"The domain discriminator aims to discriminate the domain label with following loss function: Ltype = − Ns+Nt∑
i=1",2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
{di log d̂i+(1−di),2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"log(1− d̂i)}, (3)
where di is the ground truth domain label for sample",2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"i, d̂i is the output of top layer: d̂i = Q(F(xi)).",2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
Nt meansNt samples from the target domain.,2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"The domain discriminator is trained towards a saddle point of the loss function through minimizing the loss over θd while maximizing the loss over θf (Ganin et al., 2016).",2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"Optimizing θf ensures that the domain discriminator can’t discriminate
the domain, i.e., the feature extractor finds the common features between the two domains.",2.2 POS Tagging Classifier and Domain Discriminator,[0],[0]
"Through training adversarial networks, we can obtain domain-invariant features hcommon, but it will weaken some domain-specific features which are useful for POS tagging classification.",2.3 Target Domain Autoencoder,[0],[0]
"Merely obtaining domain invariant features would therefore limit the classification ability.
",2.3 Target Domain Autoencoder,[0],[0]
"Our model tries to tackle this defect by introducing domain-specific autoencoder R, which attempts to reconstruct target domain data.",2.3 Target Domain Autoencoder,[0],[0]
"Inspired by (Sutskever et al., 2014) but different from (Dai and Le, 2015), we treat the feature extractor F as encoder.",2.3 Target Domain Autoencoder,[0],[0]
"In addition, we combine the last hidden states of the forward LSTM and backward LSTM in F as the initial state h0(dec) of the decoder LSTM.",2.3 Target Domain Autoencoder,[0],[0]
"Hence, we don’t need to reverse the order of words of the input sentences and the model avoids the difficulty of ”establish communication” between the input and the output (Sutskever et al., 2014).
",2.3 Target Domain Autoencoder,[0],[0]
"Similar to (Zhang et al., 2016), we use h0(dec) and embedding vector of the previous word as the inputs of the decoder, but in a computationally more efficient manner by computing previous word representation.",2.3 Target Domain Autoencoder,[0],[0]
"We assume that (x̂1, · · · , x̂T ) is the output sequence.",2.3 Target Domain Autoencoder,[0],[0]
"zt is the t-th word representation: zt = MLP (ht), and MLP is the multiple perceptron function.",2.3 Target Domain Autoencoder,[0],[0]
Hidden state ht = LSTM([h0(dec) :,2.3 Target Domain Autoencoder,[0],[0]
"zt−1], ht−1), where [· : ·] is the concatenation operation.",2.3 Target Domain Autoencoder,[0],[0]
"We estimate the conditional probability p(x̂1, · · · , x̂T |h0(dec))",2.3 Target Domain Autoencoder,[0],[0]
"as follows:
p(x̂1, · · · , x̂T |h0(dec))",2.3 Target Domain Autoencoder,[0],[0]
"= T∏
t=1
p(x̂t|h0(dec), z1, · · · , zt−1), (4)
where each p(x̂t|h0(dec), z1, · · · , zt−1) distribution is computed with softmax over all the words in the vacabulary.
",2.3 Target Domain Autoencoder,[0],[0]
"Our aim is to minimize the following loss function with respect to parameters θr:
Ltarget = − Nt∑ i=1",2.3 Target Domain Autoencoder,[0],[0]
"xi ∗ log x̂i, (5)
where xi is the one-hot vector of i-th word.",2.3 Target Domain Autoencoder,[0],[0]
"This makes h0(dec) learn an undercomplete and most salient sentence representation of target domain
data.",2.3 Target Domain Autoencoder,[0],[0]
"When the adversarial networks try to optimize the hidden representation to common representation hcommon, The target domain autoencoder counteracts a tendency of the adversarial network to erase target domain features by optimizing the common representation to be informative on the target-domain data.",2.3 Target Domain Autoencoder,[0],[0]
"Our model can be trained end-to-end with standard back-propagation, which we will detail in this section.
",2.4 Training,[0],[0]
"Our ultimate training goal is to minimize the total loss function with parameters {θf , θy, θr, θd} as follows:
Ltotal = αLtask + βLtarget + γLtype, (6) where α, β, γ are the weights to balance the effects of P ,R and Q.
For obtaining domain-invariant representation hcommon, inspired by (Ganin and Lempitsky, 2015), we introduce a special gradient reversal layer (GRL), which does nothing during forward propagation, but negates the gradients if it receives backward propagation, i.e. g(F(x))",2.4 Training,[0],[0]
= F(x) but ∇g(F(x)),2.4 Training,[0],[0]
= −λ∇F(x).,2.4 Training,[0],[0]
"We insert the GRL between F and Q, which can run standard Stochastic Gradient Descent with respect to θf and θd.",2.4 Training,[0],[0]
The parameter −λ drives the parameters θf not to amplify the dissimilarity of features when minimize Ltpye.,2.4 Training,[0],[0]
"So by introducing a GRL, F can drive its parameters θf to extract hidden representations that help the POS tagging classification and hamper the domain discrimination.
",2.4 Training,[0],[0]
"In order to preserve target domain-specific features, we only optimize the autoencoder on target domain data for reconstruction tasks.
",2.4 Training,[0],[0]
"Through above procedures, the model can learn the common features between domains, simultaneously preserve target domain-specific features.",2.4 Training,[0],[0]
"Finally, we can update the parameters as follows:
θf = θf − µ(α∂L i task
∂θf + β",2.4 Training,[0],[0]
"∂Litarget ∂θf − γ · λ∂L i type ∂θf )
θy = θy − µ · α∂L i task
∂θy
θr = θr − µ · β ∂Litarget ∂θr θd = θd − µ · γ ∂Litype ∂θd ,
(7)
where µ is the learning rate.",2.4 Training,[0],[0]
"Because the size of the WSJ is more than 100 times that of the labeled Twitter dataset, if we directly train the model with the combined dataset, the final results are much worse than those using two training steps.",2.4 Training,[0],[0]
"So, we adopt adversarial training on WSJ and unlabeled Twitter dataset at the first step, then use a small number of in-domain labeled data to fine-tune the parameters with a low learning rate.",2.4 Training,[0],[0]
"In this section, we will detail the datasets used for experiments and experimental setup.",3 Experiments,[0],[0]
"The methods proposed in this work incorporate out-of-domain labeled data from resource-rich domains, large scale unlabeled in-domain data, and a small number of labeled in-domain data.",3.1 Datasets,[0],[0]
The datasets used in this work are as follows: Labeled out-of-domain data.,3.1 Datasets,[0],[0]
"We use a standard benchmark dataset for adversarial POS tagging, namely the Wall Street Journal (WSJ) data from the Penn TreeBank v3 (Marcus et al., 1993), sections 0-24 for the out-of-domain data.",3.1 Datasets,[0],[0]
Labeled in-domain data.,3.1 Datasets,[0],[0]
"For training and evaluating POS tagging approaches, we compare the proposed method with other approaches on three benchmarks: RIT-Twitter (Ritter et al., 2011), NPSCHAT (Forsyth, 2007), and ARKTwitter (Gimpel et al., 2011).",3.1 Datasets,[0],[0]
Unlabeled in-domain data.,3.1 Datasets,[0],[0]
"For training the adversarial network, we need to use a dataset that has large scale unlabeled tweets.",3.1 Datasets,[0],[0]
"Hence, in this work, we construct large scale unlabeled data (UNL), from Twitter using its API.
",3.1 Datasets,[0],[0]
The detailed data statistics of the datasets used in this work are listed in Table 1.,3.1 Datasets,[0],[0]
"We select both state-of-the-art and classic methods for comparison, as follows:
• Stanford POS",3.2 Experimental Setup,[0],[0]
Tagger:,3.2 Experimental Setup,[0],[0]
"Stanford POS Tagger is a widely used tool for newswire domains (Toutanova et al., 2003).",3.2 Experimental Setup,[0],[0]
"In this work, we train it using two different sets, the WSJ (sections 0-18) and a WSJ, IRC, and Twitter mixed corpus.",3.2 Experimental Setup,[0],[0]
"We use StanfordWSJ and Stanford-MIX to represent them, respectively.
",3.2 Experimental Setup,[0],[0]
"• T-POS: T-Pos (Ritter et al., 2011) adopts the Conditional Random Fields and clustering algorithm to perform the task.",3.2 Experimental Setup,[0],[0]
"It was trained from a mixture of hand-annotated tweets and existing POS-labeled data.
",3.2 Experimental Setup,[0],[0]
• GATE,3.2 Experimental Setup,[0],[0]
"Tagger: GATE tagger (Derczynski et al., 2013) is based on vote-constrained bootstrapping with unlabeled data.",3.2 Experimental Setup,[0],[0]
"It combines cases where available taggers use different tagsets.
",3.2 Experimental Setup,[0],[0]
"• ARK Tagger: ARK tagger (Owoputi et al., 2013) is a system that reports the best accuracy on the RIT dataset.",3.2 Experimental Setup,[0],[0]
"It uses unsupervised word clustering and a variety of lexical features.
",3.2 Experimental Setup,[0],[0]
• bi-LSTM:,3.2 Experimental Setup,[0],[0]
"Bidirectional Long Short-Term Memory (LSTM) networks have been widely used in a variety of sequence labeling tasks (Graves and Schmidhuber, 2005).",3.2 Experimental Setup,[0],[0]
"In this work, we evaluate it at character level, word level, and combining them together.",3.2 Experimental Setup,[0],[0]
bi-LSTM (word level) uses one layer of bi-LSTM to extract word-level features and adopts a random initialization method to transform words to vectors.,3.2 Experimental Setup,[0],[0]
"bi-LSTM (character level) represents a method that combines bi-LSTM and CNN-based character embedding, a similar approach with character-aware neural network described in (Kim et al., 2015) to handle the out-ofvocabulary words.",3.2 Experimental Setup,[0],[0]
"bi-LSTM (word level pretrain) architecture is the same as that of bi-LSTM(word level) but adopts word2vec tool (Mikolov et al., 2013) to vectorize.",3.2 Experimental Setup,[0],[0]
"bi-LSTM (combine) concatenates word to character features.
",3.2 Experimental Setup,[0],[0]
The hyper-parameters used for our model are as follows.,3.2 Experimental Setup,[0],[0]
AdaGrad optimizer trained with crossentropy loss is used with 0.1 as the default learning rate.,3.2 Experimental Setup,[0],[0]
The dimensionality of word embedding is set to 200.,3.2 Experimental Setup,[0],[0]
The dimensionality for random initialized character embedding is set to 25.,3.2 Experimental Setup,[0],[0]
We adopt a bi-LSTM for encoding with each layer consisting of 250 hidden neurons.,3.2 Experimental Setup,[0],[0]
We set three layers of standard LSTM for decoding.,3.2 Experimental Setup,[0],[0]
Each LSTM layer consists of 500 hidden neurons.,3.2 Experimental Setup,[0],[0]
Adam optimizer trained with cross-entropy loss is used to fine-tune with 0.0001 as the default learning rate.,3.2 Experimental Setup,[0],[0]
Finetuning is run for 100 epochs using early stop.,3.2 Experimental Setup,[0],[0]
"In this section, we will report experimental results and a detailed analysis of the results for the three different datasets.",4 Results and Discussion,[0],[0]
"The RIT-Twitter is split into training, development and evaluation sets (RIT-Train, RIT-Dev, RITTest).",4.1 Evaluation on RIT-Twitter,[0],[0]
"The splitting method is shown in (Derczynski et al., 2013), and the dataset statistics are listed in Table 1.",4.1 Evaluation on RIT-Twitter,[0],[0]
Table 2 shows the results of our method and other approaches on the RIT-Twitter dataset.,4.1 Evaluation on RIT-Twitter,[0],[0]
"RIT-Twitter uses the PTB tagset with several Twitter-specific tags: retweets, @usernames, hashtags, and urls.",4.1 Evaluation on RIT-Twitter,[0],[0]
"Since words in these
categories can be tagged almost perfectly using simple regular expressions, similar to (Owoputi et al., 2013), we use regular expressions to tags these words appropriately for all systems.
",4.1 Evaluation on RIT-Twitter,[0],[0]
"From the results of the Stanford-WSJ, we can observe that the newswire domain is different from Twitter.",4.1 Evaluation on RIT-Twitter,[0],[0]
"Although the token-level accuracy of the Stanford POS Tagger is higher than 97.0% on the PTB dataset, its performance on Twitter drops sharply to 73.37%.",4.1 Evaluation on RIT-Twitter,[0],[0]
"By incorporating some indomain labeled data for training, the accuracy of Stanford POS Tagger can reach up to 83.14%.",4.1 Evaluation on RIT-Twitter,[0],[0]
"Taking a variety of linguistic features and many other resources into consideration, the T-POS, GATE tagger, and ARK tagger can achieve better performance.
",4.1 Evaluation on RIT-Twitter,[0],[0]
"The second part of Table 2 shows the results of the bi-LSTM based methods, which are trained on the RIT-Train dataset.",4.1 Evaluation on RIT-Twitter,[0],[0]
"According to the results of word level, we can see that word2vec can provide valuable information.",4.1 Evaluation on RIT-Twitter,[0],[0]
"The pre-trained word vectors in bi-LSTM(word level pretrain) give almost 10% higher accuracy than bi-LSTM(word level).
",4.1 Evaluation on RIT-Twitter,[0],[0]
"Comparing the character-level bi-LSTM with word-level bi-LSTM with random initialization, we can observe that the character-level method can achieve better performance than the word-level method.",4.1 Evaluation on RIT-Twitter,[0],[0]
"bi-LSTM(combine) combines word with character features, as described in Section 2.1,
which achieves the best results at 89.48% in the bi-LSTM based baseline systems and shows that the morphological features and pre-trained word vectors are both useful for POS tagging.
",4.1 Evaluation on RIT-Twitter,[0],[0]
"The third part of Table 2 shows the results of our methods incorporating out-of-domain labeled data, in-domain unlabeled data, and in-domain labeled data.",4.1 Evaluation on RIT-Twitter,[0],[0]
"Putting everything together, our model can achieve 90.92% on this dataset.",4.1 Evaluation on RIT-Twitter,[0],[0]
"Compared with the architecture without an adversarial model, our method is almost 1% better.",4.1 Evaluation on RIT-Twitter,[0],[0]
It demonstrates that adversarial networks can significantly help with tasks of this nature.,4.1 Evaluation on RIT-Twitter,[0],[0]
"Through introducing the autoencoder in target domain, we can preserve domain-specific features for better performance.",4.1 Evaluation on RIT-Twitter,[0],[0]
"Compared with the ARK tagger, which achieves the previous best result on this dataset, our model is also 0.52% better, the error reduction rate is more than 5.5%.
",4.1 Evaluation on RIT-Twitter,[0],[0]
"To better understand why adversarial networks can help transfer domains from newswire to Twitter, in this work we also followed the method Ganin and Lempitsky (2015) used to visualize the outputs of LSTM with tSNE (Van Der Maaten, 2013).",4.1 Evaluation on RIT-Twitter,[0],[0]
Figure 3 shows the visualization results.,4.1 Evaluation on RIT-Twitter,[0],[0]
"From the figure, we can see that the adversary in our method makes the two distributions of features much more similar, which means that the outputs of bi-LSTM are domain-invariant.",4.1 Evaluation on RIT-Twitter,[0],[0]
"Hence, the PTB training data can provide much more help than directly combining PTB and RIT-Train together.",4.1 Evaluation on RIT-Twitter,[0],[0]
"IRC, which contains Internet relay room messages from 2006, is a medium of online conversational text.",4.2 Evaluation on NPSChat,[0],[0]
Its content is very similar to tweets.,4.2 Evaluation on NPSChat,[0],[0]
"We evaluate the proposed method on the NPSChat corpus (Forsyth, 2007), a PTB-part-of-speech annotated dataset of IRC.
",4.2 Evaluation on NPSChat,[0],[0]
"We compared our method with a tagger in the same setup as experiments with (Forsyth, 2007).",4.2 Evaluation on NPSChat,[0],[0]
The training part contains 90% of the data.,4.2 Evaluation on NPSChat,[0],[0]
The testing part contains the other 10%.,4.2 Evaluation on NPSChat,[0],[0]
Table 3 shows the results of the ARK Tagger and our method.,4.2 Evaluation on NPSChat,[0],[0]
"We used PTB, unlabeled Twitter, and the training part of NPSChat to train our model.",4.2 Evaluation on NPSChat,[0],[0]
"From the results, we can see that our model achieved 94.1% accuracy.",4.2 Evaluation on NPSChat,[0],[0]
"This is significantly better than the result Forsyth (2007) reported, which was 90.8%.",4.2 Evaluation on NPSChat,[0],[0]
"They trained their tagger with a mix of several POS-annotated corpora (12K from Twitter, 40K from IRC, and 50K from PTB).",4.2 Evaluation on NPSChat,[0],[0]
"Our method also outperforms state-of-the-art results 93.4%±0.3%, which was achieved by the ARK Tagger with various external corpus and features, e.g., Brown clustering, PTB, Freebase lists of celebrities, and video games.",4.2 Evaluation on NPSChat,[0],[0]
"ARK-Twitter data contains an entire dataset consisting of a number of tweets sampled from one particular day (October 27, 2010) described in (Gimpel et al., 2011).",4.3 Evaluation on ARK-Twitter,[0],[0]
This part is used for training.,4.3 Evaluation on ARK-Twitter,[0],[0]
"They also created another dataset, which consists of 547 tweets, for evaluation (DAILY547).",4.3 Evaluation on ARK-Twitter,[0],[0]
"This dataset consists of one random English tweet from every day between January 1, 2011 and June 30, 2012.",4.3 Evaluation on ARK-Twitter,[0],[0]
"The distribution of training data may be slightly different from the testing data, for example a substantial fraction of the messages in the training data are about a basketball game.",4.3 Evaluation on ARK-Twitter,[0],[0]
"Since ARK-Twitter uses a different tagset with PTB, we manually construct a table to link tags for the two datasets.
",4.3 Evaluation on ARK-Twitter,[0],[0]
Table 4 shows the results of different methods on this dataset.,4.3 Evaluation on ARK-Twitter,[0],[0]
"From the results, we can see that our method can achieve a better result than (Gimpel et al., 2011).",4.3 Evaluation on ARK-Twitter,[0],[0]
"However, the performance of our method is worse than the ARK Tagger.",4.3 Evaluation on ARK-Twitter,[0],[0]
"Through analyzing the errors, we find that 16.7% errors occurr between nouns and proper nouns.",4.3 Evaluation on ARK-Twitter,[0],[0]
"Since our method do not include any ontology or knowledge, proper nouns can not be easily detected.",4.3 Evaluation on ARK-Twitter,[0],[0]
"However, the ATK Tagge add a tokenlevel name list feature.",4.3 Evaluation on ARK-Twitter,[0],[0]
"The name list is useful for proper nouns recognition, which fires on names from many sources, such as Freebase lists of celebrities, the Moby Words list of US Locations, proper names from Mark Kantrowitz’s name corpus and so on.",4.3 Evaluation on ARK-Twitter,[0],[0]
"So, our model is also competitive when lacking of manual feature knowledge.",4.3 Evaluation on ARK-Twitter,[0],[0]
Part-of-Speech tagging is an important preprocessing step and can provide valuable information for various natural language processing tasks.,5 Related Work,[0],[0]
"In recent years, deep learning algorithms have been successfully used for POS tagging.",5 Related Work,[0],[0]
A number of approaches have been proposed and have achieved some progress.,5 Related Work,[0],[0]
"Santos and Guimaraes (2015) proposed
using a character-based convolutional neural network to perform the POS tagging problem.",5 Related Work,[0],[0]
"Bi-LSTMs with word, character or unicode byte embedding were also introduced to achieve the POS tagging and named entity recognition tasks (Plank et al., 2016; Chiu and Nichols, 2015; Ma and Hovy, 2016).",5 Related Work,[0],[0]
"In this work, we study the problem from a domain adaption perspective.",5 Related Work,[0],[0]
"Inspired by these works, we also propose to use character-level methods to handle out-ofvocabulary words and bi-LSTMs to model the sequence relations.
",5 Related Work,[0],[0]
"Adversarial networks were successfully used for image generation (Goodfellow et al., 2014; Dosovitskiy et al., 2015; Denton et al., 2015), domain adaption (Tzeng et al., 2014; Ganin et al., 2016), and semi-supervised learning (Denton et al., 2016).",5 Related Work,[0],[0]
"The key idea of adversarial networks for domain adaption is to construct invariant features by optimizing the feature extractor as an adversary against the domain classifier (Zhang et al., 2017).
",5 Related Work,[0],[0]
Sequence autoencoder reads the input sequence into a vector and then tries to reconstruct it.,5 Related Work,[0],[0]
Dai and Le (2015) used the model on a number of different tasks and verified its validity.,5 Related Work,[0],[0]
"Li et al. (2015) introduced the model to hierarchically build an embedding for a paragraph, showing that the model was able to encode texts to preserve syntactic, semantic, and discourse coherence.
",5 Related Work,[0],[0]
"In this work, we incorporate adversarial networks with autoencoder to obtain domaininvariant features and keep domain-specific features.",5 Related Work,[0],[0]
Our model is more suitable for target domain tasks.,5 Related Work,[0],[0]
"In this work, we propose a novel adversarial neural network to address the POS tagging problem.",6 Conclusion,[0],[0]
"Besides learning common representations between source domain and target domain, it can simultaneously preserve specific features of target domain.",6 Conclusion,[0],[0]
"The proposed method leverages newswire resources and large scale in-domain unlabeled data to help POS tagging classification on Twitter, which has a few of labeled data.",6 Conclusion,[0],[0]
We evaluate the proposed method and several state-ofthe-art methods on three different corpora.,6 Conclusion,[0],[0]
"In most of the cases, the proposed method can achieve better performance than previous methods.",6 Conclusion,[0],[0]
"Experimental results demonstrate that the proposed
method can make full use of these resources, which can be easily obtained.",6 Conclusion,[0],[0]
The authors wish to thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
"This work was partially funded by National Natural Science Foundation of China (No. 61532011, 61473092, and 61472088) and STCSM (No.16JC1420401).",Acknowledgments,[0],[0]
"In this work, we study the problem of partof-speech tagging for Tweets.",abstractText,[0],[0]
"In contrast to newswire articles, Tweets are usually informal and contain numerous out-ofvocabulary words.",abstractText,[0],[0]
"Moreover, there is a lack of large scale labeled datasets for this domain.",abstractText,[0],[0]
"To tackle these challenges, we propose a novel neural network to make use of out-of-domain labeled data, unlabeled in-domain data, and labeled indomain data.",abstractText,[0],[0]
"Inspired by adversarial neural networks, the proposed method tries to learn common features through adversarial discriminator.",abstractText,[0],[0]
"In addition, we hypothesize that domain-specific features of target domain should be preserved in some degree.",abstractText,[0],[0]
"Hence, the proposed method adopts a sequence-to-sequence autoencoder to perform this task.",abstractText,[0],[0]
Experimental results on three different datasets show that our method achieves better performance than state-of-the-art methods.,abstractText,[0],[0]
Part-of-Speech Tagging for Twitter with Adversarial Neural Networks,title,[0],[0]
"This paper is about weighted correlation clustering (Bansal et al., 2004), a combinatorial optimization problem whose feasible solutions are all clusterings of a graph, and whose objective function is a sum of weights w0, w1 : E → R+0 defined on the edgesE of the graph.",1. Introduction,[0],[0]
"The weightw0e is added to the sum if the nodes {u, v} = e ∈",1. Introduction,[0],[0]
"E are in the same cluster, and the weight w1e is added to the sum if these nodes are in distinct clusters.",1. Introduction,[0],[0]
"The problem consists in finding a clustering of minimum weight.
",1. Introduction,[0],[0]
"Weighted correlation clustering has found applications in the fields of network analysis (Cesa-Bianchi et al., 2012) and, more recently, computer vision (Kappes et al., 2011; Keuper et al., 2015; Insafutdinov et al., 2016; Beier et al., 2017; Tang et al., 2017), partly due to its key property that the number of clusters is not fixed, constrained or penalized in the problem statement but is instead defined by the (any)
1Max Planck Institute for Informatics, Saarbrücken, Germany 2Saarland University, Saarbrücken, Germany 3Bosch Center for AI, Renningen, Germany 4University of Tübingen, Germany.",1. Introduction,[0],[0]
"Correspondence to: Jan-Hendrik Lange <jlange@mpi-inf.mpg.de>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
solution.",1. Introduction,[0],[0]
"Weighted correlation clustering in general graphs is hard to solve exactly and hard to approximate (Demaine et al., 2006).",1. Introduction,[0],[0]
Remarkable progress has been made toward algorithms that find feasible solutions by approximations or heuristics (cf. Section 2).,1. Introduction,[0],[0]
"Yet, the computation of lower bounds remains challenging for large instances (Swoboda & Andres, 2017).
",1. Introduction,[0],[0]
"We make the following contributions: Firstly, in order to reduce instances in size, we establish partial optimality conditions on the graph and weights that can be checked combinatorially in polynomial time and determine the values of some variables in an optimal solution.",1. Introduction,[0],[0]
"By applying these conditions recursively, we reduce an instance in size without restricting the quality of solutions.",1. Introduction,[0],[0]
"For series-parallel graphs, our algorithm solves weighted correlation clustering exactly and in linear time, as we show.",1. Introduction,[0],[0]
"For general graphs, we demonstrate its effectiveness empirically.
",1. Introduction,[0],[0]
"Secondly, in order to compute lower bounds to the optimal objective value efficiently, we define an algorithm that outputs a heuristic solution to a packing problem that is the dual of a reformulation of weighted correlation clustering.",1. Introduction,[0],[0]
"Empirically, this algorithm is shown to exhibit a run-time/tightness trade-off that is different from both the cutting plane algorithm of Kappes et al. (2015) and the message passing algorithm of Swoboda & Andres (2017), both of which solve a canonical linear program relaxation of weighted correlation clustering.
",1. Introduction,[0],[0]
"Thirdly, toward the goal of obtaining primal feasible solutions, we define a transformation of the weights w.r.t.",1. Introduction,[0],[0]
our heuristic solution to the dual problem.,1. Introduction,[0],[0]
This transformation is again a heuristic and is motivated by complementary slackness.,1. Introduction,[0],[0]
"Empirically, local search algorithms are shown to find feasible solutions of lower original weight when applied to instances with transformed weights.
",1. Introduction,[0],[0]
"In the supplementary material, we provide additional results that were omitted from the main paper for the sake of space.",1. Introduction,[0],[0]
Implementations of our algorithms are provided on GitHub.,1. Introduction,[0],[0]
Weighted correlation clustering has a long history in the field of combinatorial optimization.,2. Related Work,[0],[0]
"Grötschel & Wakabayashi (1989) state an equivalent problem for complete graphs and
devise a branch-and-cut algorithm for solving this problem exactly.",2. Related Work,[0],[0]
"The polyhedral geometry of its feasible set is studied by Grötschel & Wakabayashi (1990); Deza et al. (1990; 1992), in the case of general graphs by Chopra & Rao (1993); Chopra (1994) and, for a more general problem, by Horňáková et al. (2017).",2. Related Work,[0],[0]
"For uniform absolute edge costs, Bansal et al. (2004) coined the name correlation clustering, established NP-hardness and the first approximation results.",2. Related Work,[0],[0]
The connection between correlation clustering in general weighted graphs and weighted multicuts was made by Demaine et al. (2006) who thus established APX-hardness and obtained anO(log|V |) approximation algorithm for the problem.,2. Related Work,[0],[0]
"Further hardness results and improved approximation algorithms for particular classes of graphs are due to Charikar et al. (2005); Chawla et al. (2006; 2015); Ailon et al. (2012); Klein et al. (2015).
",2. Related Work,[0],[0]
Approximation algorithms are typically based on rounding the solution of a linear or semi-definite program relaxation.,2. Related Work,[0],[0]
"Due to its importance, tailored algorithms for solving the linear program relaxation more efficiently than standard methods have been proposed by Yarkony et al. (2012; 2015); Swoboda & Andres (2017).",2. Related Work,[0],[0]
"Complementary to these lower bounds, a variety of fast primal heuristics have been developed to tackle large instances (Beier et al., 2014; Pan et al., 2015; Levinkov et al., 2017).",2. Related Work,[0],[0]
"Although it has been observed that, in practice, heuristic solutions are often good, it remains difficult for large instances to determine non-trivial bounds on their optimality gap.
",2. Related Work,[0],[0]
"Partial optimality concepts have been developed and exploited successfully for node labeling problems that arise from pseudo-Boolean optimization and from maximum a-posteriori inference in Markov Random Fields, cf.",2. Related Work,[0],[0]
"(Shekhovtsov, 2014; Swoboda et al., 2016).",2. Related Work,[0],[0]
"Transferring this knowledge to weighted correlation clustering is nontrivial, due to the different nature of the problem.",2. Related Work,[0],[0]
Two partial optimality conditions for weighted correlation clustering are established by Alush & Goldberger (2012) and are here generalized.,2. Related Work,[0],[0]
"Weighted correlation clustering is a combinatorial optimization problem whose feasible solutions are all clusterings of a graph.
",3.1. Weighted Correlation Clustering,[0],[0]
"Let G = (V,E) be a simple graph.",3.1. Weighted Correlation Clustering,[0],[0]
"We call a partition Π of V a clustering if every S ∈ Π induces a connected subgraph (cluster) of G. For any clustering Π of G, we denote by E0Π the set of those edges whose nodes are in the same cluster, and by E1Π the (complementary) set of those edges whose
nodes are in distinct clusters:
E0Π = {uv ∈ E",3.1. Weighted Correlation Clustering,[0],[0]
"| ∃S ∈ Π : u ∈ S and v ∈ S}, (1) E1Π = E",3.1. Weighted Correlation Clustering,[0],[0]
\,3.1. Weighted Correlation Clustering,[0],[0]
"E0Π. (2)
",3.1. Weighted Correlation Clustering,[0],[0]
"The set of edges E1Π is known as the multicut of G that corresponds to the clustering Π.
Definition 1.",3.1. Weighted Correlation Clustering,[0],[0]
"For any graph G = (V,E) and any w0, w1 : E → R+0 , the instance of weighted correlation clustering w.r.t.",3.1. Weighted Correlation Clustering,[0],[0]
"G, w0 and w1 is the optimization problem
min Π ∑ e∈E0Π w0e + ∑ e∈E1Π w1e .",3.1. Weighted Correlation Clustering,[0],[0]
(3),3.1. Weighted Correlation Clustering,[0],[0]
Weighted correlation clustering is commonly stated in the form of a binary program whose feasible solutions are the incidence vectors of the multicuts of the graph.,3.2. Minimum Cost Multicut,[0],[0]
The incidence vector xΠ ∈,3.2. Minimum Cost Multicut,[0],[0]
"{0, 1}E corresponding to the multicut induced by Π is defined as
xΠe = { 1 if e ∈",3.2. Minimum Cost Multicut,[0],[0]
"E1Π 0 else.
",3.2. Minimum Cost Multicut,[0],[0]
"(4)
Definition 2.",3.2. Minimum Cost Multicut,[0],[0]
"For any graph G = (V,E) and any c : E → R, the instance of the minimum cost multicut problem w.r.t.",3.2. Minimum Cost Multicut,[0],[0]
"G and c is the binary program
min Π ∑ e∈E ce x Π e .",3.2. Minimum Cost Multicut,[0],[0]
"(5)
The minimizers of an instance of weighted correlation clustering (Def. 1) coincide with the minimizers of the instance of minimum cost multicut (Def. 2) with c = w1−w0, since
min Π ∑ e∈E0Π w0e + ∑ e∈E1Π w1e (6)
",3.2. Minimum Cost Multicut,[0],[0]
= min Π ∑ e∈E ( w0e (1− xΠe ) +,3.2. Minimum Cost Multicut,[0],[0]
"w1e xΠe ) (7)
= ∑ e∈E
w0e︸ ︷︷ ︸ const.",3.2. Minimum Cost Multicut,[0],[0]
"+ min Π
∑ e∈E (w1e − w0e)︸ ︷︷ ︸ ce xΠe .",3.2. Minimum Cost Multicut,[0],[0]
(8),3.2. Minimum Cost Multicut,[0],[0]
"By taking the convex hull of multicut incidence vectors
MC(G) := conv{xΠ | Π clustering of G}, (9)
the minimum cost multicut problem (Def. 2) can be written as the integer linear programming problem
min x∈MC(G) ∑ e∈E ce xe.",3.3. Linear Program Relaxation,[0],[0]
"(PMC)
The set MC(G) is called multicut polytope of G (Chopra & Rao, 1993).",3.3. Linear Program Relaxation,[0],[0]
"As the minimum cost multicut problem is NP-hard, a full description of the multicut polytope in terms of its facets is impractical.",3.3. Linear Program Relaxation,[0],[0]
"For practical purposes a linear programming (LP) relaxation of PMC is derived as follows.
",3.3. Linear Program Relaxation,[0],[0]
"Denote by C(G) the set of all simple cycles of G. For any cycle C ∈ C(G), we write EC for the edge set of C. It is straight-forward to check the fact that any multicut incidence vector xΠ satisfies the system of linear inequalities
∀C ∈ C(G) ∀f",3.3. Linear Program Relaxation,[0],[0]
"∈ EC : xf ≤ ∑
e∈EC\{f}
xe , (10)
the so-called cycle inequalities (Chopra & Rao, 1993).",3.3. Linear Program Relaxation,[0],[0]
"Therefore, the standard linear programming relaxation is given by the program
min x∈CYC(G) ∑ e∈E ce xe (PCYC)
",3.3. Linear Program Relaxation,[0],[0]
"whose feasible set
CYC(G) :",3.3. Linear Program Relaxation,[0],[0]
= { x ∈,3.3. Linear Program Relaxation,[0],[0]
"[0, 1]E ∣∣x satisfies (10)} (11) is also known as the cycle relaxation of MC(G).",3.3. Linear Program Relaxation,[0],[0]
"The problem PCYC is practical, because the cycle inequalities in (10) can be separated in polynomial time.",3.3. Linear Program Relaxation,[0],[0]
"The lower bounds thus obtained can serve to solve (small) instances of the minimum cost multicut problem by branch-and-cut because the cycle relaxation has no integer vertices except the incidence vectors of multicuts, according to Lemma 1.
",3.3. Linear Program Relaxation,[0],[0]
Lemma 1 (Chopra & Rao (1993)).,3.3. Linear Program Relaxation,[0],[0]
"For any graph G = (V,E), it holds that MC(G) = CYC(G) ∩ ZE .
",3.3. Linear Program Relaxation,[0],[0]
A reference algorithm that we use for the experiments in Section 7 further exploits the fact that a cycle inequality in (10) defines a facet of MC(G) iff the associated cycle is chordless.,3.3. Linear Program Relaxation,[0],[0]
"For the presentation of this paper, we employ an alternative (integer) linear programming formulation in terms of covering cycles, which was similarly considered, e.g., by Demaine et al. (2006) for the combinatorial problem and by Charikar et al. (2005) in connection with the LP relaxation for complete graphs.",3.4. Cycle Covering Formulation,[0],[0]
"We rewrite the feasible set of the general LP relaxation relative to the cost vector c. Therefore, let G and c be fixed.
",3.4. Cycle Covering Formulation,[0],[0]
We call an edge e ∈ E repulsive if ce < 0,3.4. Cycle Covering Formulation,[0],[0]
and we call it attractive if ce > 0.,3.4. Cycle Covering Formulation,[0],[0]
"Note that we may w.l.o.g. remove all edges e ∈ E with ce = 0, since the choice of xe is irrelevant to the objective.",3.4. Cycle Covering Formulation,[0],[0]
"We write E = E+ ∪ E− where E+, E− collect all attractive and repulsive edges, respectively.
",3.4. Cycle Covering Formulation,[0],[0]
We call a cycle of G conflicted w.r.t.,3.4. Cycle Covering Formulation,[0],[0]
"(G, c) if it contains precisely one repulsive edge.",3.4. Cycle Covering Formulation,[0],[0]
"We denote by C−(G, c) ⊆ C(G) the set of all such cycles.
",3.4. Cycle Covering Formulation,[0],[0]
We consider the relaxation of CYC(G) that is constrained only by conflicted cycles.,3.4. Cycle Covering Formulation,[0],[0]
"More specifically, we consider the system
∀C ∈ C−(G, c), f ∈ EC ∩",3.4. Cycle Covering Formulation,[0],[0]
E− :,3.4. Cycle Covering Formulation,[0],[0]
"xf ≤ ∑
e∈EC\{f}
xe
(12)
of only those linear inequalities of (10) for which the edge on the left-hand side is repulsive and all other edges are attractive.",3.4. Cycle Covering Formulation,[0],[0]
"Defining
CYC−(G, c) := { x ∈",3.4. Cycle Covering Formulation,[0],[0]
"[0, 1]E ∣∣ x satisfies (12)} (13) and replacing CYC(G) by CYC−(G, c) in PCYC has no effect on the solutions, due to the following lemma, a weaker form of which was also given by Yarkony et al. (2015).",3.4. Cycle Covering Formulation,[0],[0]
Lemma 2.,3.4. Cycle Covering Formulation,[0],[0]
"For any c : E → R it holds that
min x∈CYC(G)",3.4. Cycle Covering Formulation,[0],[0]
"c>x = min x∈CYC−(G,c) c",3.4. Cycle Covering Formulation,[0],[0]
">x (14)
and
min x∈MC(G)",3.4. Cycle Covering Formulation,[0],[0]
"c>x = min x∈CYC−(G,c)∩ZE c>x. (15)
",3.4. Cycle Covering Formulation,[0],[0]
Proof.,3.4. Cycle Covering Formulation,[0],[0]
Let x∗ be an optimal solution to the right-hand side of (14).,3.4. Cycle Covering Formulation,[0],[0]
We show that x∗ satisfies all cycle inequalities (10) by contradiction.,3.4. Cycle Covering Formulation,[0],[0]
"To this end, suppose there exists a cycle C ∈ C(G) and f ∈ EC such that
x∗f > ∑
e∈EC\{f}
x∗e.
",3.4. Cycle Covering Formulation,[0],[0]
"If any edge g ∈ EC \ {f} is repulsive, then increasing x∗g would lower the objective.",3.4. Cycle Covering Formulation,[0],[0]
"Since x
∗ is optimal, there must be a conflicted cycle C ′",3.4. Cycle Covering Formulation,[0],[0]
"with g ∈ EC′ such that x∗g = ∑ e∈EC′\{g}
x∗e .",3.4. Cycle Covering Formulation,[0],[0]
Note that this means f /∈ EC′ .,3.4. Cycle Covering Formulation,[0],[0]
We write C4C ′ for the cycle obtained from the symmetric difference of EC and EC′ .,3.4. Cycle Covering Formulation,[0],[0]
"Apparently, the cycle C4C ′ has one repulsive edge less and f ∈ EC4C′ .",3.4. Cycle Covering Formulation,[0],[0]
"Therefore, by repeating the argument, we may w.l.o.g. assume that all edges in EC \ {f} are attractive.",3.4. Cycle Covering Formulation,[0],[0]
"Now assume that f is attractive as well, then decreasing x∗f would lower the objective.",3.4. Cycle Covering Formulation,[0],[0]
"Therefore, since x
∗ is optimal, there is a conflicted cycle C ′ with f ∈ EC′ and g ∈ EC′ ∩ E− such that
x∗g = x ∗",3.4. Cycle Covering Formulation,[0],[0]
"f + ∑ e∈EC′\{f,g} x∗e
> ∑
e∈EC\{f}
x∗e + ∑
e∈EC′\{f,g}
x∗e
≥ ∑
e∈EC4C′\{g}
x∗e.
",3.4. Cycle Covering Formulation,[0],[0]
Note that C4C ′ is a conflicted cycle.,3.4. Cycle Covering Formulation,[0],[0]
"Thus, we conclude that x∗ violates an inequality of (12) and hence cannot be feasible.",3.4. Cycle Covering Formulation,[0],[0]
"This concludes the proof of (14), the argument for (15) is analogous.
",3.4. Cycle Covering Formulation,[0],[0]
"With the help of Lemma 2, we formulate PMC as a set covering problem: Definition 3.",3.4. Cycle Covering Formulation,[0],[0]
"For any graph G = (V,E) and any c ∈ RE , we call
min x̂∈SC(G,c) ∑ e∈E |ce| x̂e (PSC)
with SC(G, c) the convex hull of all x̂ ∈ ZE that satisfy the system
∀C ∈ C−(G, c) : ∑ e∈EC",3.4. Cycle Covering Formulation,[0],[0]
"x̂e ≥ 1 (16)
∀e ∈ E : x̂e ≥ 0 (17)
the set covering problem w.r.t.",3.4. Cycle Covering Formulation,[0],[0]
"conflicted cycles, and we call SC(G, c) the set covering polyhedron w.r.t.",3.4. Cycle Covering Formulation,[0],[0]
conflicted cycles.,3.4. Cycle Covering Formulation,[0],[0]
Lemma 3.,3.4. Cycle Covering Formulation,[0],[0]
"For any graph G = (V,E) and any c ∈ RE , we have
min x∈CYC−(G,c)∩ZE ∑ e∈E ce xe
= Ltriv + min x̂∈SC(G,c) ∑ e∈E |ce| x̂e (18)
with
Ltriv = ∑ e∈E− ce (19)
the sum of negative edge costs (a trivial lower bound to the optimal value of PMC).
",3.4. Cycle Covering Formulation,[0],[0]
Proof.,3.4. Cycle Covering Formulation,[0],[0]
We define x̂ via x̂e,3.4. Cycle Covering Formulation,[0],[0]
:= xe for any attractive edge e ∈ E+,3.4. Cycle Covering Formulation,[0],[0]
and x̂e,3.4. Cycle Covering Formulation,[0],[0]
:= 1− xe for any repulsive edge e ∈,3.4. Cycle Covering Formulation,[0],[0]
"E−. Since any conflicted cycle C ∈ C−(G, c) has precisely one repulsive edge, all conflicted cycle inequalities (12) become covering inequalities.",3.4. Cycle Covering Formulation,[0],[0]
"In this section, we study partial optimality for PMC.",4. Partial Optimality,[0],[0]
"More precisely, we establish conditions on an edge e ∈ E which guarantee that xe assumes one particular value, either 0 or 1, in at least one optimal solution (weak persistency).",4. Partial Optimality,[0],[0]
"Fixations to 0 are of particular interest as they can be implemented as edge contractions (with subsequent merging of parallel edges), which effectively reduce the size of a given instance of the problem.",4. Partial Optimality,[0],[0]
"As a corollary, we obtain an algorithm that solves weighted correlation clustering problems on seriesparallel graphs in linear time.",4. Partial Optimality,[0],[0]
A direct consequence from Lemma 3 is that we may disregard all edges that are not contained in any conflicted cycle.,4.1. Basic Conditions,[0],[0]
There are (at least) two ways this can happen: 1.,4.1. Basic Conditions,[0],[0]
"An edge e ∈ E is not contained in any cycle at all, that is, e is a bridge.",4.1. Basic Conditions,[0],[0]
2.,4.1. Basic Conditions,[0],[0]
"The endpoints of a repulsive edge e = {u, v} ∈",4.1. Basic Conditions,[0],[0]
"E− belong to different components of G+ = (V,E+).",4.1. Basic Conditions,[0],[0]
"In both cases, for any optimal solution x∗ of PMC, it holds that x∗e = 0",4.1. Basic Conditions,[0],[0]
"if e is attractive, and x ∗ e",4.1. Basic Conditions,[0],[0]
= 1 if e is repulsive.,4.1. Basic Conditions,[0],[0]
"Thus, we can restrict the instance of the problem to the maximal components ofG that are connected in G+ and biconnected in G. This was also observed by Alush & Goldberger (2012).
",4.1. Basic Conditions,[0],[0]
"Below, we establish more general partial optimality conditions.",4.1. Basic Conditions,[0],[0]
"To this end, we need the following notation.",4.1. Basic Conditions,[0],[0]
"A cut of G is a bipartition B = (S1, S2) of the nodes V , i.e. V = S1 ∪̇S2.",4.1. Basic Conditions,[0],[0]
The edge set of the cut B is denoted by EB = {uv ∈ E,4.1. Basic Conditions,[0],[0]
"| u ∈ S1, v ∈ S2}.",4.1. Basic Conditions,[0],[0]
Definition 4.,4.2. Dominant Edges,[0],[0]
"Let G = (V,E) be any graph and let c ∈ RE .",4.2. Dominant Edges,[0],[0]
An edge f ∈ E is called dominant attractive iff cf > 0,4.2. Dominant Edges,[0],[0]
"and there exists a cut B with f ∈ EB such that
cf ≥ ∑
e∈EB\{f}
|ce| .",4.2. Dominant Edges,[0],[0]
"(20)
An edge f ∈",4.2. Dominant Edges,[0],[0]
E− is called dominant repulsive iff cf < 0,4.2. Dominant Edges,[0],[0]
"and there exists a cut B with f ∈ EB such that
|cf | ≥ ∑
e∈EB∩E+ ce.",4.2. Dominant Edges,[0],[0]
"(21)
",4.2. Dominant Edges,[0],[0]
"An edge is called dominant iff it is dominant attractive or dominant repulsive.
",4.2. Dominant Edges,[0],[0]
Lemma 4.,4.2. Dominant Edges,[0],[0]
"Let G = (V,E) be any graph and let c ∈ RE .
",4.2. Dominant Edges,[0],[0]
(i),4.2. Dominant Edges,[0],[0]
"If f ∈ E is dominant attractive, then x∗f = 0 in at least one optimal solution x∗ of PMC.
(ii) If f ∈ E is dominant repulsive, then x∗f = 1 in at least one optimal solution x∗ of PMC.
",4.2. Dominant Edges,[0],[0]
Proof.,4.2. Dominant Edges,[0],[0]
(i),4.2. Dominant Edges,[0],[0]
We use the set covering formulation of PMC.,4.2. Dominant Edges,[0],[0]
Suppose f ∈ E+ is dominant and x̂∗f = 1 in an optimal solution x̂∗ of PSC.,4.2. Dominant Edges,[0],[0]
"Every conflicted cycle that contains f also contains some edge e ∈ EB , since B is a cut.",4.2. Dominant Edges,[0],[0]
"Therefore, the vector x̂ ∈ {0, 1}E defined by
x̂e =  0",4.2. Dominant Edges,[0],[0]
"if e = f 1 if e ∈ EB , e 6= f x̂∗e else
is a feasible solution to PSC.",4.2. Dominant Edges,[0],[0]
"It has the same objective value as x̂∗, since f is dominant and x̂∗ is optimal.
",4.2. Dominant Edges,[0],[0]
(ii) Suppose f ∈,4.2. Dominant Edges,[0],[0]
E− is dominant and x̂∗f,4.2. Dominant Edges,[0],[0]
= 1 in an optimal solution x̂∗ of PSC,4.2. Dominant Edges,[0],[0]
.,4.2. Dominant Edges,[0],[0]
Every conflicted cycle that contains f also contains some edge e ∈ EB ∩,4.2. Dominant Edges,[0],[0]
"E+, since B is a cut and every conflicted cycle contains only one repulsive edge.",4.2. Dominant Edges,[0],[0]
"Then the vector x̂ ∈ {0, 1}E defined by x̂f = 0, x̂e = 1 for all e ∈ EB ∩ E+ and x̂e = x̂∗e elsewhere is a feasible solution to PSC.",4.2. Dominant Edges,[0],[0]
"It has the same objective value as x̂∗, since f is dominant and x̂∗ is optimal.
",4.2. Dominant Edges,[0],[0]
"Lemma 4 generalizes the basic conditions discussed in Section 4.1, since each edge f ∈ E that is not contained in any conflicted cycle is also dominant.",4.2. Dominant Edges,[0],[0]
"Dominance of edges can be decided in polynomial time, by computing minimum st-cuts in G for a suitable choice of capacities.",4.2. Dominant Edges,[0],[0]
"In practice, the required computational effort may be mitigated by constructing a cut tree of G (Gomory & Hu, 1961).",4.2. Dominant Edges,[0],[0]
"The practically most relevant cuts can even be checked in linear time, which we discuss in the following section.",4.2. Dominant Edges,[0],[0]
"In practice, it is expected that dominant edges are more likely to be found in cuts that are relatively sparse.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"We discuss two special cases of sparse cuts that are of particular interest, due to the following reasons.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"First, they can be checked in linear time, which gives rise to a fast preprocessing algorithm.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"Second, we show that our techniques solve PMC to optimality if G is series-parallel.
",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
Two-edge cuts.,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"Suppose B is a two-edge cut of G, i.e. EB = {e, f} for two edges e, f ∈",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
E.,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"Apparently, according to (20) and (21), at least one of them must be dominant.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"Further, it is guaranteed that we can simplify the instance by edge deletions or contractions.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"To see this, distinguish the following cases.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"If both e and f are repulsive, then both of them are dominant and we can delete them, as they are not contained in any conflicted cycle.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"If f is dominant attractive, we can contract f .",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"Finally, if f is dominant repulsive and e is attractive, then we can switch the signs of their coefficients and redefine xf := 1 − xf as well as xe := 1 − xe.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"Since |EB | = 2, this operation does not change the set of conflicted cycles of G and thus is valid (while only adding a constant to the objective).",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"Afterwards, the edge f is dominant attractive and we can contract f .",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"The two-edge cuts of G can be found in linear time, by computing the 3-edge-connected components of G, cf.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"(Mehlhorn et al., 2017).
",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
Single-node cuts.,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"For any v ∈ V , let Bv = ({v}, V \ {v}) denote the cut that is induced by v. Whether EBv contains a dominant edge is easily decided by considering all edges incident to v. Moreover, if deg v = 2, then Bv is also a two-edge cut and we can apply the operation described in
Algorithm 1 Single-Node Cut Preprocessing input G = (V,E), c :",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"E → R
1: Initialize objective value offset ∆ = 0.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
2: Initialize a queue Q = V .,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
3: while Q 6= ∅,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
do 4: Extract a vertex v ∈ Q. 5: if deg v = 1 then 6: Get neighbor u ∈ V .,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"7: if cuv ≥ 0 then 8: Set xuv = 0 and contract uv ∈ E. 9: else
10: Set xuv = 1, ∆ = ∆ + cuv and delete uv ∈ E. 11: end if 12: else if deg v = 2 then 13: Get neighbors u,w ∈ V with |cuv| ≥ |cwv|.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
14: if uv ∈ E+ then 15: Set xuv = 0 and contract uv ∈ E. 16: else if uv ∈,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
E− and wv ∈,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
E− then 17: Adjust offset ∆ = ∆ + cuv + cwv .,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"18: Set xuv = xwv = 1 and delete uv,wv ∈",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
E. 19: else if uv ∈,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
E− and wv ∈ E+ then 20:,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
Adjust offset ∆ = ∆ + cuv + cwv .,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"21: Redefine xuv = 1− xuv , xwv = 1− xwv and cuv = −cuv , cwv = −cwv .",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
22: Set xuv = 0 and contract uv ∈ E. 23: end if 24: else if ∃f ∈ Bv dominant attractive then 25: Set xf = 0 and contract f ∈,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
E. 26: end if 27:,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
Add to Q all vertices u /∈,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
Q whose neighborhood was changed.,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"28: end while 29: return (G, c), x,∆
the last paragraph.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
Updating the graph and applying these techniques recursively as specified in Algorithm 1 takes linear time.,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"This has the following theoretical consequence.
",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
Corollary 1.,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"If G has treewidth at most 2, then Algorithm 1 can be implemented to solve PMC exactly in O(|V |) time.
",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
Proof.,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
Place the vertices of G into buckets of ascending degree and always pick a vertex of minimal degree.,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
Every graph of treewidth 2 has a vertex v with deg v ≤ 2.,4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"Since Algorithm 1 only contracts or deletes edges, fixing the variables according to Lemma 4, the updated graph still has treewidth at most 2.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"The number of nodes decreases by 1 in every iteration, hence the algorithm terminates in time O(|E|) = O(|V |) and outputs an optimal solution.",4.3. Two-Edge Cuts & Single-Node Cuts,[0],[0]
"In this section, we define an algorithm for computing lower bounds for PMC.",5. Dual Lower Bounds,[0],[0]
"This algorithm exploits the structure of
Algorithm 2 Iterative Cycle Packing (ICP) input G = (V,E), c :",5. Dual Lower Bounds,[0],[0]
"E → R
1: Initialize we = |ce| for all e ∈ E and y = 0, L = Ltriv. 2: for ` = 3 . . .",5. Dual Lower Bounds,[0],[0]
"|E| do 3: while ∃C ∈ C−(G, c) : |EC | ≤ ` do 4: Pick C ∈ C−(G, c) such that |EC | ≤",5. Dual Lower Bounds,[0],[0]
"`. 5: Compute yC = mine∈EC we.
6: Redefine we = { we − yC",5. Dual Lower Bounds,[0],[0]
if e ∈ EC we else.,5. Dual Lower Bounds,[0],[0]
7: Increase lower bound L = L+ yC .,5. Dual Lower Bounds,[0],[0]
"8: Remove all edges e ∈ E with we = 0 from G. 9: end while
10: if C−(G, c) = ∅ then 11: return y, L 12: end if 13: end for
the reformulation PSC.",5. Dual Lower Bounds,[0],[0]
"It computes a heuristic solution to the dual of its LP relaxation.
",5. Dual Lower Bounds,[0],[0]
"The LP relaxation (up to the constant Ltriv) of problem PSC is given by
min ∑ e∈E |ce|x̂e (22)
subject to ∑ e∈EC x̂e ≥ 1 ∀C ∈ C−(G, c) (23)
",5. Dual Lower Bounds,[0],[0]
"x̂e ≥ 0 ∀e ∈ E .
",5. Dual Lower Bounds,[0],[0]
"The corresponding dual program reads
max ∑
C∈C−(G,c)
yC (24)
subject to ∑
C: e∈EC
yC ≤ |ce| ∀e ∈ E (25)
yC ≥ 0 ∀C ∈ C−(G, c) .
",5. Dual Lower Bounds,[0],[0]
"A heuristic solution of (24), and thus a lower bound for (22), is found by Algorithm 2 that we call Iterative Cycle Packing (ICP).",5. Dual Lower Bounds,[0],[0]
It works as follows:,5. Dual Lower Bounds,[0],[0]
"Firstly, it chooses a conflicted cycle C and increases yC as much as possible.",5. Dual Lower Bounds,[0],[0]
"Secondly, it decreases the weights we (initially |ce|) of all edges e ∈ EC by yC and removes all edges of zero weight.",5. Dual Lower Bounds,[0],[0]
"These steps are repeated until there are no conflicted cycles left.
",5. Dual Lower Bounds,[0],[0]
Implementation details.,5. Dual Lower Bounds,[0],[0]
"The absolute running time of ICP as well as the quality of the output lower bounds depends on the choice of cycles C. We pursue the following strategy that we found to perform well empirically in both aspects: In each iteration of the main loop, we choose a repulsive edge e = uv ∈",5. Dual Lower Bounds,[0.9561460448962725],"['We treat the set of all possible attributes of objects as a vector, and for each object oi in the environment we instantiate and populate an attribute vector Att V eci.']"
"E− such that u and v are in the same connected component of G+ = (V,E+).",5. Dual Lower Bounds,[0],[0]
"Then, we find a conflicted cycle containing e by searching for a shortest path
(in terms of hop distance) from u to v in G+.",5. Dual Lower Bounds,[0],[0]
"We apply this search for conflicted cycles in rounds of increasing cycle length, using breadth-first search with an early termination criterion based on the hop distance.",5. Dual Lower Bounds,[0],[0]
We also maintain and periodically update a component labeling of G+ in order to to reduce the number of redundant shortest path searches.,5. Dual Lower Bounds,[0],[0]
"In this section, we exploit the dual solution in primal algorithms.",6. Re-weighting for Primal Algorithms,[0],[0]
"The motivation is due to complementary slackness, which is made explicit in the following lemma.
",6. Re-weighting for Primal Algorithms,[0],[0]
Lemma 5.,6. Re-weighting for Primal Algorithms,[0],[0]
"Assume the primal LP (22) is tight, i.e., its optimal solution x̂∗ also solves PSC, and the solution output by ICP solves the dual (24) optimally.",6. Re-weighting for Primal Algorithms,[0],[0]
"Then, for every e ∈ E with positive residual weight we > 0, it holds that x̂∗e = 0.
",6. Re-weighting for Primal Algorithms,[0],[0]
Proof.,6. Re-weighting for Primal Algorithms,[0],[0]
"If we > 0, the constraint (25) at e ∈ E is inactive at the optimal dual solution.",6. Re-weighting for Primal Algorithms,[0],[0]
"Thus, x̂∗e = 0 in the optimal primal solution, by complementary slackness.
",6. Re-weighting for Primal Algorithms,[0],[0]
"Of course, the assumption of Lemma 5 is too strong for practical purposes.",6. Re-weighting for Primal Algorithms,[0],[0]
"However, the intuition is that if the LP relaxation is fairly tight and the obtained dual solution is close to optimal, it can still provide useful information about the primal problem.",6. Re-weighting for Primal Algorithms,[0],[0]
"More specifically, the weights we output by ICP can be interpreted as an indication of how likely the primal variable x̂e is zero in an optimal solution.",6. Re-weighting for Primal Algorithms,[0],[0]
"In order to make use of this information, we propose to shift the weights of the primal problem to a convex combination λ|ce|+ (1− λ)we of the original and residual weights, for a suitable choice of λ ∈ (0, 1).",6. Re-weighting for Primal Algorithms,[0],[0]
Experiments in Section 7 show that this shift can guide primal heuristics toward better feasible solutions to the original problem.,6. Re-weighting for Primal Algorithms,[0],[0]
"In this section, we study partial optimality, dual lower bounds and re-weightings empirically, for all instances of
the weighted correlation clustering problem from Kappes et al. (2015) and Leskovec et al. (2010).
Instances.",7. Experiments,[0],[0]
"From Kappes et al. (2015), we consider all three collections of instances: Image Segmentation contains instances w.r.t.",7. Experiments,[0],[0]
planar superpixel adjacency graphs of photographs.,7. Experiments,[0],[0]
Knott-3D contains instances w.r.t.,7. Experiments,[0],[0]
non-planar supervoxel adjacency graphs of volume images taken by a serial sectioning electron microscope.,7. Experiments,[0],[0]
Modularity Clustering contains instances w.r.t.,7. Experiments,[0],[0]
complete graphs.,7. Experiments,[0],[0]
"In all three collections, the edge costs ce are fractional and non-uniform.",7. Experiments,[0],[0]
"For all these instances, except one in the collection Modularity Clustering, optimal solutions are accessible and are computed here as a reference.",7. Experiments,[0],[0]
"From Leskovec et al. (2010), we consider directed graphs of the social networks Epinions and Slashdot, each with more than half a million edges labeled either +1 or −1.",7. Experiments,[0],[0]
"Instances of the minimum cost multicut problem are defined here by removing the orientation of edges, by deleting all self-loops, and by replacing parallel edges by a single edge with the sum of their costs1.",7. Experiments,[0],[0]
"In order to study the partial optimality conditions of Section 4 empirically, we process the above instances as follows: First, we remove all edges of cost 0, all bridges, as well as all repulsive edges whose nodes belong to distinct connected components of G+.",7.1. Partial Optimality,[0],[0]
"Second, we check for every v ∈ V whether the cut Bv = ({v}, V \ {v}) induces dominant edges.",7.1. Partial Optimality,[0],[0]
"If we find dominant attractive edges or vertices of degree ≤ 2, we perform contractions and deletions according to Alg. 1.",7.1. Partial Optimality,[0],[0]
"Both steps are repeated until no further edges can be removed or contracted.
",7.1. Partial Optimality,[0],[0]
"After the main reduction step, which takes linear time and is thus very fast, we further check all remaining edges uv ∈ E for dominance in any (general) uv-cut.",7.1. Partial Optimality,[0],[0]
"To this end, we construct a cut tree of G with the help of Gusfield’s algorithm (Gusfield, 1990), which takes |V | − 1 max-flow computations.",7.1. Partial Optimality,[0],[0]
"Despite the increased computational effort, we only found a small number of additional dominant attractive edges and thus could only perform few further contractions.",7.1. Partial Optimality,[0],[0]
"However, we found a significant number of additional dom-
1This results in 2703 edges of cost 0 for Epinions, and 1949 such edges for Slashdot.
inant repulsive edges.
",7.1. Partial Optimality,[0],[0]
The effect of our method in the total number of nodes and edges is shown in Table 1.,7.1. Partial Optimality,[0],[0]
We also report the number of remaining edges that are not dominant repulsive.,7.1. Partial Optimality,[0],[0]
It can be seen from this table that the numbers are effectively reduced.,7.1. Partial Optimality,[0],[0]
"This is explained, firstly, by the sparsity of the graphs and, secondly, by the non-uniformity of the costs.",7.1. Partial Optimality,[0],[0]
"From the comparison to the number of remaining non-persistent variables when only the criteria of Alush & Goldberger (2012) are applied, it can be seen that our more general criteria reveal considerably more persistency.
",7.1. Partial Optimality,[0],[0]
It may be expected that optimization methods benefit in terms of runtime from the reduced size of the instances.,7.1. Partial Optimality,[0],[0]
"On the instances of Kappes et al. (2015), we found the effect to be insignificant due to their small original size.",7.1. Partial Optimality,[0],[0]
"On Epinions and Slashdot, however, the runtime of the local search algorithm GAEC+KLj (cf. Section 7.3) decreased by more than 70%.",7.1. Partial Optimality,[0],[0]
"For completeness, we provide the numbers in the supplements.",7.1. Partial Optimality,[0],[0]
"In order to put into perspective the dual lower bounds output by Iterative Cycle Packing (ICP) as described in Section 5, we compare this algorithm, firstly, to the cutting plane algorithm for PCYC of Kappes et al. (2015), with Gurobi for solving the LPs (denoted here by LP) and, secondly, to the message passing algorithm of Swoboda & Andres (2017), applied to PCYC, with code and parameter settings kindly provided by the authors (denoted here by MPC).
",7.2. Dual Lower Bounds,[0],[0]
Results are shown in Figure 1 and Table 2.,7.2. Dual Lower Bounds,[0],[0]
"It can be seen from the figure and the table that, for the large and hard instances Epinions and Slashdot, ICP converges at under 102 seconds, outputting lower bounds that are matched and exceeded by MPC at around 103 seconds.",7.2. Dual Lower Bounds,[0],[0]
"It can be seen from Table 2 that the situation is similar for the smaller instances: The lower bounds output by ICP are a bit worse than those output by LP or MPC (here compared to the best optimal solution known) but are obtained faster (by as much as three orders of magnitude for Knott-3D-450).
",7.2. Dual Lower Bounds,[0],[0]
"It is known from Kappes et al. (2015) that their instances can be solved faster than their LP relaxations by means of branch-and-cut, separating only integer infeasible points
·105
Epinions
·105
Slashdot
by cycle inequalities using BFS (instead of Dijkstra’s algorithm), and resorting to the strong (undisclosed) cuts of Gurobi for cutting off fractional solutions.",7.2. Dual Lower Bounds,[0],[0]
We restrict our comparison here to algorithms that seek to solve the LP relaxation PCYC.,7.2. Dual Lower Bounds,[0],[0]
This is justified by the fact that size ultimately renders integer linear programming intractable.,7.2. Dual Lower Bounds,[0],[0]
We conclude that ICP is capable of computing non-trivial lower bounds fast.,7.2. Dual Lower Bounds,[0],[0]
"In order to study the re-weighting described in Section 6, we measure its effect on heuristic algorithms for finding feasible solutions.",7.3. Re-weighting,[0],[0]
"To this end, we employ the implementations of Levinkov et al. (2017) of Greedy Additive Edge Contraction (GAEC), an algorithm that starts from singleton clusters and greedily contracts attractive edges with maximum nonnegative cost, and of KLj, the well-known Kernighan-Lin heuristic for graph partitioning that recursively improves an initial clustering by splitting, merging or exchanging nodes between neighboring clusters.
",7.3. Re-weighting,[0],[0]
"A comparison between the feasible solutions found by applying the heuristics GAEC and GAEC+KLj to original instances, on the one hand, and to instances re-weighted by ICP with λ = 12 , on the other hand, can be found in Table
3.",7.3. Re-weighting,[0],[0]
"Note that we only re-weight the input to GAEC and let KLj run with original weights, starting from the solution returned by GAEC, as we found this approach to be advantageous.",7.3. Re-weighting,[0],[0]
It can be seen from Table 3 that our re-weighting consistently improves the gap.,7.3. Re-weighting,[0],[0]
"On average, it is slightly less effective than the reparameterization with the more accurate dual solutions obtained from MPC, as proposed by Swoboda & Andres (2017).",7.3. Re-weighting,[0],[0]
A more detailed comparison is provided in the supplements.,7.3. Re-weighting,[0],[0]
"We have established partial optimality conditions, a heuristic lower bound and a heuristic re-weighting for instances of the weighted correlation clustering problem.",8. Conclusion,[0],[0]
We have shown advantages of each of these constructions empirically.,8. Conclusion,[0],[0]
Checking a subset of our partial optimality conditions recursively gives a fast combinatorial algorithm that efficiently reduces the size of problem instances.,8. Conclusion,[0],[0]
"Conceptually, it solves the problem for series-parallel graphs to optimality, in linear time.",8. Conclusion,[0],[0]
Our dual heuristic algorithm provides nontrivial lower bounds and valuable dual information fast.,8. Conclusion,[0],[0]
"For future work, it is relevant to examine if more sophisticated dual solvers such as MPC benefit from a “warm-start” that transforms and exploits the heuristic dual solution.",8. Conclusion,[0],[0]
Weighted correlation clustering is hard to solve and hard to approximate for general graphs.,abstractText,[0],[0]
Its applications in network analysis and computer vision call for efficient algorithms.,abstractText,[0],[0]
"To this end, we make three contributions: We establish partial optimality conditions that can be checked efficiently, and doing so recursively solves the problem for series-parallel graphs to optimality, in linear time.",abstractText,[0],[0]
"We exploit the packing dual of the problem to compute a heuristic, but non-trivial lower bound faster than that of a canonical linear program relaxation.",abstractText,[0],[0]
We introduce a re-weighting with the dual solution by which efficient local search algorithms converge to better feasible solutions.,abstractText,[0],[0]
The effectiveness of our methods is demonstrated empirically on a number of benchmark instances.,abstractText,[0],[0]
Partial Optimality and Fast Lower Bounds for Weighted Correlation Clustering,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3719–3728 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3719",text,[0],[0]
Many interpretation methods for neural networks explain the model’s prediction as a counterfactual: how does the prediction change when the input is modified?,1 Introduction,[0],[0]
"Adversarial examples (Szegedy et al., 2014; Goodfellow et al., 2015) highlight the instability of neural network predictions by showing how small perturbations to the input dramatically change the output.
",1 Introduction,[0],[0]
"A common, non-adversarial form of model interpretation is feature attribution: features that are crucial for predictions are highlighted in a heatmap.",1 Introduction,[0],[0]
One can measure a feature’s importance by input perturbation.,1 Introduction,[0],[0]
"Given an input for text classification, a word’s importance can be measured by the difference in model confidence before and after that word is removed from the input—the word is important if confidence decreases significantly.",1 Introduction,[0],[0]
"This is the leave-one-out method (Li et al., 2016b).",1 Introduction,[0],[0]
"Gradients can also measure feature importance; for example, a feature is influential to the prediction if its gradient is a large positive value.",1 Introduction,[0],[0]
"Both perturbation and gradient-based methods can generate heatmaps, implying that the model’s prediction is highly influenced by the highlighted, important words.
",1 Introduction,[0],[0]
"Instead, we study how the model’s prediction is influenced by the unimportant words.",1 Introduction,[0],[0]
"We use input reduction, a process that iteratively removes the unimportant words from the input while maintaining the model’s prediction.",1 Introduction,[0],[0]
"Intuitively, the words remaining after input reduction should be important for prediction.",1 Introduction,[0],[0]
"Moreover, the words
should match the leave-one-out method’s selections, which closely align with human perception (Li et al., 2016b; Murdoch et al., 2018).",1 Introduction,[0],[0]
"However, rather than providing explanations of the original prediction, our reduced examples more closely resemble adversarial examples.",1 Introduction,[0],[0]
"In Figure 1, the reduced input is meaningless to a human but retains the same model prediction with high confidence.",1 Introduction,[0],[0]
"Gradient-based input reduction exposes pathological model behaviors that contradict what one expects based on existing interpretation methods.
",1 Introduction,[0],[0]
"In Section 2, we construct more of these counterintuitive examples by augmenting input reduction with beam search and experiment with three tasks: SQUAD (Rajpurkar et al., 2016) for reading comprehension, SNLI (Bowman et al., 2015) for textual entailment, and VQA (Antol et al., 2015) for visual question answering.",1 Introduction,[0],[0]
Input reduction with beam search consistently reduces the input sentence to very short lengths—often only one or two words—without lowering model confidence on its original prediction.,1 Introduction,[0],[0]
"The reduced examples appear nonsensical to humans, which we verify with crowdsourced experiments.",1 Introduction,[0],[0]
"In Section 3, we draw connections to adversarial examples and confidence calibration; we explain why the observed pathologies are a consequence of the overconfidence of neural models.",1 Introduction,[0],[0]
This elucidates limitations of interpretation methods that rely on model confidence.,1 Introduction,[0],[0]
"In Section 4, we encourage high model uncertainty on reduced examples with entropy regularization.",1 Introduction,[0],[0]
"The pathological model behavior under input reduction is mitigated, leading to more reasonable reduced examples.",1 Introduction,[0],[0]
"To explain model predictions using a set of important words, we must first define importance.",2 Input Reduction,[0],[0]
"After defining input perturbation and gradient-based approximation, we describe input reduction with these importance metrics.",2 Input Reduction,[0],[0]
Input reduction drastically shortens inputs without causing the model to change its prediction or significantly decrease its confidence.,2 Input Reduction,[0],[0]
Crowdsourced experiments confirm that reduced examples appear nonsensical to humans: input reduction uncovers pathological model behaviors.,2 Input Reduction,[0],[0]
"Ribeiro et al. (2016) and Li et al. (2016b) define importance by seeing how confidence changes when a feature is removed; a natural approximation is to use the gradient (Baehrens et al., 2010; Simonyan et al., 2014).",2.1 Importance from Input Gradient,[0],[0]
We formally define these importance metrics in natural language contexts and introduce the efficient gradient-based approximation.,2.1 Importance from Input Gradient,[0],[0]
"For each word in an input sentence, we measure its importance by the change in the confidence of the original prediction when we remove that word from the sentence.",2.1 Importance from Input Gradient,[0],[0]
"We switch the sign so that when the confidence decreases, the importance value is positive.
",2.1 Importance from Input Gradient,[0],[0]
"Formally, let x = 〈x1, x2, . . .",2.1 Importance from Input Gradient,[0],[0]
"xn〉 denote the input sentence, f(y |x)",2.1 Importance from Input Gradient,[0],[0]
"the predicted probability of label y, and y = argmaxy′ f(y
′ |x)",2.1 Importance from Input Gradient,[0],[0]
the original predicted label.,2.1 Importance from Input Gradient,[0],[0]
"The importance is then
g(xi",2.1 Importance from Input Gradient,[0],[0]
| x) = f(y |x)− f(y |x−i).,2.1 Importance from Input Gradient,[0],[0]
"(1)
To calculate the importance of each word in a sentence with n words, we need n forward passes of the model, each time with one of the words left out.",2.1 Importance from Input Gradient,[0],[0]
"This is highly inefficient, especially for longer sentences.",2.1 Importance from Input Gradient,[0],[0]
"Instead, we approximate the importance value with the input gradient.",2.1 Importance from Input Gradient,[0],[0]
"For each word in the sentence, we calculate the dot product of its word embedding and the gradient of the output with respect to the embedding.",2.1 Importance from Input Gradient,[0],[0]
The importance of n words can thus be computed with a single forward-backward pass.,2.1 Importance from Input Gradient,[0],[0]
"This gradient approximation has been used for various interpretation methods for natural language classification models (Li et al., 2016a; Arras et al., 2016); see Ebrahimi et al. (2017) for further details on the derivation.",2.1 Importance from Input Gradient,[0],[0]
We use this approximation in all our experiments as it selects the same words for removal as an exhaustive search (no approximation).,2.1 Importance from Input Gradient,[0],[0]
Instead of looking at the words with high importance values—what interpretation methods commonly do—we take a complementary approach and study how the model behaves when the supposedly unimportant words are removed.,2.2 Removing Unimportant Words,[0],[0]
"Intuitively, the important words should remain after the unimportant ones are removed.
",2.2 Removing Unimportant Words,[0],[0]
Our input reduction process iteratively removes the unimportant words.,2.2 Removing Unimportant Words,[0],[0]
"At each step, we remove the word with the lowest importance value until the model changes its prediction.",2.2 Removing Unimportant Words,[0],[0]
"We experi-
ment with three popular datasets: SQUAD (Rajpurkar et al., 2016) for reading comprehension, SNLI (Bowman et al., 2015) for textual entailment, and VQA (Antol et al., 2015) for visual question answering.",2.2 Removing Unimportant Words,[0],[0]
"We describe each of these tasks and the model we use below, providing full details in the Supplement.
",2.2 Removing Unimportant Words,[0],[0]
"In SQUAD, each example is a context paragraph and a question.",2.2 Removing Unimportant Words,[0],[0]
The task is to predict a span in the paragraph as the answer.,2.2 Removing Unimportant Words,[0],[0]
We reduce only the question while keeping the context paragraph unchanged.,2.2 Removing Unimportant Words,[0],[0]
"The model we use is the DRQA Document Reader (Chen et al., 2017).
",2.2 Removing Unimportant Words,[0],[0]
"In SNLI, each example consists of two sentences: a premise and a hypothesis.",2.2 Removing Unimportant Words,[0],[0]
"The task is to predict one of three relationships: entailment, neutral, or contradiction.",2.2 Removing Unimportant Words,[0],[0]
We reduce only the hypothesis while keeping the premise unchanged.,2.2 Removing Unimportant Words,[0],[0]
"The model we use is Bilateral Multi-Perspective Matching (BIMPM) (Wang et al., 2017).
",2.2 Removing Unimportant Words,[0],[0]
"In VQA, each example consists of an image and a natural language question.",2.2 Removing Unimportant Words,[0],[0]
We reduce only the question while keeping the image unchanged.,2.2 Removing Unimportant Words,[0],[0]
"The model we use is Show, Ask, Attend, and Answer (Kazemi and Elqursh, 2017).
",2.2 Removing Unimportant Words,[0],[0]
"During the iterative reduction process, we ensure that the prediction does not change (exact same span for SQUAD); consequently, the model accuracy on the reduced examples is identical to the original.",2.2 Removing Unimportant Words,[0],[0]
The predicted label is used for input reduction and the ground-truth is never revealed.,2.2 Removing Unimportant Words,[0],[0]
"We use the validation set for all three tasks.
",2.2 Removing Unimportant Words,[0],[0]
Most reduced inputs are nonsensical to humans (Figure 2) as they lack information for any reasonable human prediction.,2.2 Removing Unimportant Words,[0],[0]
"However, models make confident predictions, at times even more confident than the original.
",2.2 Removing Unimportant Words,[0],[0]
"To find the shortest possible reduced inputs (potentially the most meaningless), we relax the requirement of removing only the least important word and augment input reduction with beam search.",2.2 Removing Unimportant Words,[0],[0]
"We limit the removal to the k least important words, where k is the beam size, and decrease the beam size as the remaining input is shortened.1",2.2 Removing Unimportant Words,[0],[0]
We empirically select beam size five as it produces comparable results to larger beam sizes with reasonable computation cost.,2.2 Removing Unimportant Words,[0],[0]
"The requirement of maintaining model prediction is unchanged.
",2.2 Removing Unimportant Words,[0],[0]
"1We set beam size to max(1,min(k, L − 3))",2.2 Removing Unimportant Words,[0],[0]
"where k is maximum beam size and L is the current length of the input sentence.
",2.2 Removing Unimportant Words,[0],[0]
"With beam search, input reduction finds extremely short reduced examples with little to no decrease in the model’s confidence on its original predictions.",2.2 Removing Unimportant Words,[0],[0]
Figure 3 compares the length of input sentences before and after the reduction.,2.2 Removing Unimportant Words,[0],[0]
"For all three tasks, we can often reduce the sentence to only one word.",2.2 Removing Unimportant Words,[0],[0]
Figure 4 compares the model’s confidence on original and reduced inputs.,2.2 Removing Unimportant Words,[0],[0]
"On SQUAD and SNLI the confidence decreases slightly, and on VQA the confidence even increases.",2.2 Removing Unimportant Words,[0],[0]
"On the reduced examples, the models retain their original predictions despite short input lengths.",2.3 Humans Confused by Reduced Inputs,[0],[0]
"The following experiments examine whether these predictions are justified or pathological, based on how humans react to the reduced inputs.
",2.3 Humans Confused by Reduced Inputs,[0],[0]
"For each task, we sample 200 examples that are correctly classified by the model and generate their reduced examples.",2.3 Humans Confused by Reduced Inputs,[0],[0]
"In the first setting, we compare the human accuracy on original and reduced examples.",2.3 Humans Confused by Reduced Inputs,[0],[0]
"We recruit two groups of crowd workers and task them with textual entailment, reading comprehension, or visual question answering.",2.3 Humans Confused by Reduced Inputs,[0],[0]
We show one group the original inputs and the other the reduced.,2.3 Humans Confused by Reduced Inputs,[0],[0]
"Humans are no longer able to give
the correct answer, showing a significant accuracy loss on all three tasks (compare Original and Reduced in Table 1).
",2.3 Humans Confused by Reduced Inputs,[0],[0]
The second setting examines how random the reduced examples appear to humans.,2.3 Humans Confused by Reduced Inputs,[0],[0]
"For each of the original examples, we generate a version where words are randomly removed until the length matches the one generated by input reduction.",2.3 Humans Confused by Reduced Inputs,[0],[0]
We present the original example along with the two reduced examples and ask crowd workers their preference between the two reduced ones.,2.3 Humans Confused by Reduced Inputs,[0],[0]
"The workers’ choice is almost fifty-fifty (the vs. Random in Table 1): the reduced examples appear almost random to humans.
",2.3 Humans Confused by Reduced Inputs,[0],[0]
These results leave us with two puzzles: why are the models highly confident on the nonsensical reduced examples?,2.3 Humans Confused by Reduced Inputs,[0],[0]
"And why, when the leave-oneout method selects important words that appear reasonable to humans, the input reduction process selects ones that are nonsensical?",2.3 Humans Confused by Reduced Inputs,[0],[0]
"Having established the incongruity of our definition of importance vis-à-vis human judgements, we now investigate possible explanations for these results.",3 Making Sense of Reduced Inputs,[0],[0]
We explain why model confidence can empower methods such as leave-one-out to generate reasonable interpretations but also lead to pathologies under input reduction.,3 Making Sense of Reduced Inputs,[0],[0]
We attribute these results to two issues of neural models.,3 Making Sense of Reduced Inputs,[0],[0]
"Neural models are overconfident in their predictions (Guo et al., 2017).",3.1 Model Overconfidence,[0],[0]
One explanation for overconfidence is overfitting: the model overfits the negative log-likelihood loss during training by learning to output low-entropy distributions over classes.,3.1 Model Overconfidence,[0],[0]
Neural models are also overconfident on examples outside the training data distribution.,3.1 Model Overconfidence,[0],[0]
"As Goodfellow et al. (2015) observe for image classification, samples from pure noise can sometimes trigger highly confident predictions.",3.1 Model Overconfidence,[0],[0]
"These socalled rubbish examples are degenerate inputs that
a human would trivially classify as not belonging to any class but for which the model predicts with high confidence.",3.1 Model Overconfidence,[0],[0]
Goodfellow et al. (2015) argue that the rubbish examples exist for the same reason that adversarial examples do: the surprising linear nature of neural models.,3.1 Model Overconfidence,[0],[0]
"In short, the confidence of a neural model is not a robust estimate of its prediction uncertainty.
",3.1 Model Overconfidence,[0],[0]
"Our reduced inputs satisfy the definition of rubbish examples: humans have a hard time making predictions based on the reduced inputs (Table 1), but models make predictions with high confidence (Figure 4).",3.1 Model Overconfidence,[0],[0]
"Starting from a valid example, input reduction transforms it into a rubbish example.
",3.1 Model Overconfidence,[0],[0]
"The nonsensical, almost random results are best explained by looking at a complete reduction path (Figure 5).",3.1 Model Overconfidence,[0],[0]
"In this example, the transition from valid to rubbish happens immediately after the first step: following the removal of “Broncos”, humans can no longer determine which team the question is asking about, but model confidence remains high.",3.1 Model Overconfidence,[0],[0]
"Not being able to lower its confidence on rubbish examples—as it is not trained to do so— the model neglects “Broncos” and eventually the process generates nonsensical results.
",3.1 Model Overconfidence,[0],[0]
"In this example, the leave-one-out method will not highlight “Broncos”.",3.1 Model Overconfidence,[0],[0]
"However, this is not a failure of the interpretation method but of the model itself.",3.1 Model Overconfidence,[0],[0]
"The model assigns a low importance to “Broncos” in the first step, causing it to be removed—leave-one-out would be able to expose this particular issue by not highlighting “Broncos”.",3.1 Model Overconfidence,[0],[0]
"However, in cases where a similar issue only appear after a few unimportant words are removed, the leave-one-out method would fail to expose the unreasonable model behavior.
",3.1 Model Overconfidence,[0],[0]
Input reduction can expose deeper issues of model overconfidence and stress test a model’s uncertainty estimation and interpretability.,3.1 Model Overconfidence,[0],[0]
"So far, we have seen that the output of a neural model is sensitive to small changes in its input.",3.2 Second-order Sensitivity,[0],[0]
"We call this first-order sensitivity, because interpretation based on input gradient is a first-order Taylor expansion of the model near the input (Simonyan et al., 2014).",3.2 Second-order Sensitivity,[0],[0]
"However, the interpretation also shifts drastically with small input changes (Figure 6).",3.2 Second-order Sensitivity,[0],[0]
"We call this second-order sensitivity.
",3.2 Second-order Sensitivity,[0],[0]
"The shifting heatmap suggests a mismatch between the model’s first- and second-order sensi-
tivities.",3.2 Second-order Sensitivity,[0],[0]
"The heatmap shifts when, with respect to the removed word, the model has low first-order sensitivity but high second-order sensitivity.
",3.2 Second-order Sensitivity,[0],[0]
Similar issues complicate comparable interpretation methods for image classification models.,3.2 Second-order Sensitivity,[0],[0]
"For example, Ghorbani et al. (2017) modify image inputs so the highlighted features in the interpretation change while maintaining the same prediction.",3.2 Second-order Sensitivity,[0],[0]
"To achieve this, they iteratively modify the input to maximize changes in the distribution of feature importance.",3.2 Second-order Sensitivity,[0],[0]
"In contrast, the shifting heatmap we observe occurs by only removing the least impactful features without a targeted optimization.",3.2 Second-order Sensitivity,[0],[0]
They also speculate that the steepest gradient direction for the first- and secondorder sensitivity values are generally orthogonal.,3.2 Second-order Sensitivity,[0],[0]
"Loosely speaking, the shifting heatmap suggests that the direction of the smallest gradient value can sometimes align with very steep changes in second-order sensitivity.
",3.2 Second-order Sensitivity,[0],[0]
"When explaining individual model predictions, the heatmap suggests that the prediction is made based on a weighted combination of words, as in a linear model, which is not true unless the model is indeed taking a weighted sum such as in a DAN (Iyyer et al., 2015).",3.2 Second-order Sensitivity,[0],[0]
"When the model composes representations by a non-linear combination of words, a linear interpretation oblivious to second-order sensitivity can be misleading.",3.2 Second-order Sensitivity,[0],[0]
The previous section explains the observed pathologies from the perspective of overconfidence: models are too certain on rubbish examples when they should not make any prediction.,4 Mitigating Model Pathologies,[0],[0]
Human experiments in Section 2.3 confirm that the reduced examples fit the definition of rubbish examples.,4 Mitigating Model Pathologies,[0],[0]
"Hence, a natural way to mitigate the pathologies is to maximize model uncertainty on the reduced examples.",4 Mitigating Model Pathologies,[0],[0]
"To maximize model uncertainty on reduced examples, we use the entropy of the output distribution as an objective.",4.1 Regularization on Reduced Inputs,[0],[0]
"Given a model f trained on a dataset (X ,Y), we generate reduced examples using input reduction for all training examples X .",4.1 Regularization on Reduced Inputs,[0],[0]
"Beam search often yields multiple reduced versions with the same minimum length for each input x, and we collect all of these versions together to form X̃ as the “negative” example set.
",4.1 Regularization on Reduced Inputs,[0],[0]
Let H (·) denote the entropy and f(y |x) denote the probability of the model predicting y given x.,4.1 Regularization on Reduced Inputs,[0],[0]
"We fine-tune the existing model to simultaneously maximize the log-likelihood on regular examples and the entropy on reduced examples:∑ (x,y)∈(X ,Y) log(f(y |x))",4.1 Regularization on Reduced Inputs,[0],[0]
+ λ,4.1 Regularization on Reduced Inputs,[0],[0]
"∑ x̃∈X̃ H (f(y | x̃)) , (2) where hyperparameter λ controls the trade-off between the two terms.",4.1 Regularization on Reduced Inputs,[0],[0]
"Similar entropy regularization is used by Pereyra et al. (2017), but not in
combination with input reduction; their entropy term is calculated on regular examples rather than reduced examples.",4.1 Regularization on Reduced Inputs,[0],[0]
"On regular examples, entropy regularization does no harm to model accuracy, with a slight increase for SQUAD (Accuracy in Table 2).
",4.2 Regularization Mitigates Pathologies,[0],[0]
"After entropy regularization, input reduction produces more reasonable reduced inputs (Figure 7).",4.2 Regularization Mitigates Pathologies,[0],[0]
"In the SQUAD example from Figure 1, the reduced question changed from “did” to “spend Astor money on ?”",4.2 Regularization Mitigates Pathologies,[0],[0]
after fine-tuning.,4.2 Regularization Mitigates Pathologies,[0],[0]
The average length of reduced examples also increases across all tasks (Reduced length in Table 2).,4.2 Regularization Mitigates Pathologies,[0],[0]
"To verify that model overconfidence is indeed mitigated— that the reduced examples are less “rubbish” compared to before fine-tuning—we repeat the human experiments from Section 2.3.
",4.2 Regularization Mitigates Pathologies,[0],[0]
Human accuracy increases across all three tasks (Table 3).,4.2 Regularization Mitigates Pathologies,[0],[0]
"We also repeat the vs. Random experiment: we re-generate the random examples to match the lengths of the new reduced examples from input reduction, and find humans now prefer the reduced examples to random ones.",4.2 Regularization Mitigates Pathologies,[0],[0]
"The increase in both human performance and preference suggests that the reduced examples are more reasonable; model pathologies have been mitigated.
",4.2 Regularization Mitigates Pathologies,[0],[0]
"While these results are promising, it is not clear whether our input reduction method is necessary to achieve them.",4.2 Regularization Mitigates Pathologies,[0],[0]
"To provide a baseline, we finetune models using inputs randomly reduced to the same lengths as the ones generated by input reduction.",4.2 Regularization Mitigates Pathologies,[0],[0]
This baseline improves neither the model accuracy on regular examples nor interpretability under input reduction (judged by lengths of reduced examples).,4.2 Regularization Mitigates Pathologies,[0],[0]
Input reduction is effective in generating negative examples to counter model overconfidence.,4.2 Regularization Mitigates Pathologies,[0],[0]
"Rubbish examples have been studied in the image domain (Goodfellow et al., 2015; Nguyen et al., 2015), but to our knowledge not for NLP.",5 Discussion,[0],[0]
Our input reduction process gradually transforms a valid input into a rubbish example.,5 Discussion,[0],[0]
"We can often determine which word’s removal causes the transition to occur—for example, removing “Broncos” in Figure 5.",5 Discussion,[0],[0]
"These rubbish examples are particularly interesting, as they are also adversarial: the difference from a valid example is small, unlike image rubbish examples generated from pure noise which are far outside the training data distribution.
",5 Discussion,[0],[0]
"The robustness of NLP models has been studied extensively (Papernot et al., 2016; Jia and Liang, 2017; Iyyer et al., 2018; Ribeiro et al., 2018), and most studies define adversarial examples similar to the image domain: small perturbations to the input lead to large changes in the output.",5 Discussion,[0],[0]
"HotFlip (Ebrahimi et al., 2017) uses a gradient-based approach, similar to image adversarial examples, to flip the model prediction by perturbing a few characters or words.",5 Discussion,[0],[0]
"Our work and Belinkov and Bisk (2018) both identify cases where noisy
user inputs become adversarial by accident: common misspellings break neural machine translation models; we show that incomplete user input can lead to unreasonably high model confidence.
",5 Discussion,[0],[0]
Other failures of interpretation methods have been explored in the image domain.,5 Discussion,[0],[0]
"The sensitivity issue of gradient-based interpretation methods, similar to our shifting heatmaps, are observed by Ghorbani et al. (2017) and Kindermans et al. (2017).",5 Discussion,[0],[0]
They show that various forms of input perturbation—from adversarial changes to simple constant shifts in the image input—cause significant changes in the interpretation.,5 Discussion,[0],[0]
"Ghorbani et al. (2017) make a similar observation about secondorder sensitivity, that “the fragility of interpretation is orthogonal to fragility of the prediction”.
",5 Discussion,[0],[0]
Previous work studies biases in the annotation process that lead to datasets easier than desired or expected which eventually induce pathological models.,5 Discussion,[0],[0]
We attribute our observed pathologies primarily to the lack of accurate uncertainty estimates in neural models trained with maximum likelihood.,5 Discussion,[0],[0]
"SNLI hypotheses contain artifacts that allow training a model without the premises (Gururangan et al., 2018); we apply input reduction at test time to the hypothesis.",5 Discussion,[0],[0]
"Similarly, VQA images are surprisingly unimportant for training a model; we reduce the question.",5 Discussion,[0],[0]
"The recent SQUAD 2.0 (Rajpurkar et al., 2018) augments the original reading comprehension task with an uncertainty modeling requirement, the goal being to make the task more realistic and challenging.
",5 Discussion,[0],[0]
Section 3.1 explains the pathologies from the overconfidence perspective.,5 Discussion,[0],[0]
"One explanation for overconfidence is overfitting: Guo et al. (2017) show that, late in maximum likelihood training,
the model learns to minimize loss by outputting low-entropy distributions without improving validation accuracy.",5 Discussion,[0],[0]
"To examine if overfitting can explain the input reduction results, we run input reduction using DRQA model checkpoints from every training epoch.",5 Discussion,[0],[0]
"Input reduction still achieves similar results on earlier checkpoints, suggesting that better convergence in maximum likelihood training cannot fix the issues by itself—we need new training objectives with uncertainty estimation in mind.",5 Discussion,[0],[0]
We use the reduced examples generated by input reduction to regularize the model and improve its interpretability.,5.1 Methods for Mitigating Pathologies,[0],[0]
"This resembles adversarial training (Goodfellow et al., 2015), where adversarial examples are added to the training set to improve model robustness.",5.1 Methods for Mitigating Pathologies,[0],[0]
"The objectives are different: entropy regularization encourages high uncertainty on rubbish examples, while adversarial training makes the model less sensitive to adversarial perturbations.
",5.1 Methods for Mitigating Pathologies,[0],[0]
Pereyra et al. (2017) apply entropy regularization on regular examples from the start of training to improve model generalization.,5.1 Methods for Mitigating Pathologies,[0],[0]
"A similar method is label smoothing (Szegedy et al., 2016).",5.1 Methods for Mitigating Pathologies,[0],[0]
"In comparison, we fine-tune a model with entropy regularization on the reduced examples for better uncertainty estimates and interpretations.
",5.1 Methods for Mitigating Pathologies,[0],[0]
"To mitigate overconfidence, Guo et al. (2017) propose post-hoc fine-tuning a model’s confidence with Platt scaling.",5.1 Methods for Mitigating Pathologies,[0],[0]
This method adjusts the softmax function’s temperature parameter using a small held-out dataset to align confidence with accuracy.,5.1 Methods for Mitigating Pathologies,[0],[0]
"However, because the output is calibrated using the entire confidence distribution, not individual values, this does not reduce overconfidence on specific inputs, such as the reduced examples.",5.1 Methods for Mitigating Pathologies,[0],[0]
"To highlight the erratic model predictions on short examples and provide a more intuitive demonstration, we present paired-input tasks.",5.2 Generalizability of Findings,[0],[0]
"On these tasks, the short lengths of reduced questions and hypotheses obviously contradict the necessary number of words for a human prediction (further supported by our human studies).",5.2 Generalizability of Findings,[0],[0]
"We also apply input reduction to single-input tasks including sentiment analysis (Maas et al., 2011) and Quizbowl (BoydGraber et al., 2012), achieving similar results.
",5.2 Generalizability of Findings,[0],[0]
"Interestingly, the reduced examples transfer to other architectures.",5.2 Generalizability of Findings,[0],[0]
"In particular, when we feed fifty reduced SNLI inputs from each class—generated with the BIMPM model (Wang et al., 2017)—through the Decomposable Attention Model (Parikh et al., 2016),2 the same prediction is triggered 81.3% of the time.",5.2 Generalizability of Findings,[0],[0]
"We introduce input reduction, a process that iteratively removes unimportant words from an input while maintaining a model’s prediction.",6 Conclusion,[0],[0]
"Combined with gradient-based importance estimates often used for interpretations, we expose pathological behaviors of neural models.",6 Conclusion,[0],[0]
"Without lowering model confidence on its original prediction, an input sentence can be reduced to the point where it appears nonsensical, often consisting of one or two words.",6 Conclusion,[0],[0]
"Human accuracy degrades when shown the reduced examples instead of the original, in contrast to neural models which maintain their original predictions.
",6 Conclusion,[0],[0]
We explain these pathologies with known issues of neural models: overconfidence and sensitivity to small input changes.,6 Conclusion,[0],[0]
The nonsensical reduced examples are caused by inaccurate uncertainty estimates—the model is not able to lower its confidence on inputs that do not belong to any label.,6 Conclusion,[0],[0]
"The second-order sensitivity is another issue why gradient-based interpretation methods may fail to align with human perception: a small change in the input can cause, at the same time, a minor change in the prediction but a large change in the interpretation.",6 Conclusion,[0],[0]
Input reduction perturbs the input multiple times and can expose deeper issues of model overconfidence and oversensitivity that other methods cannot.,6 Conclusion,[0],[0]
"Therefore, it can be used to stress test the interpretability of a model.
",6 Conclusion,[0],[0]
"Finally, we fine-tune the models by maximizing entropy on reduced examples to mitigate the deficiencies.",6 Conclusion,[0],[0]
"This improves interpretability without sacrificing model accuracy on regular examples.
",6 Conclusion,[0],[0]
"To properly interpret neural models, it is important to understand their fundamental characteristics: the nature of their decision surfaces, robustness against adversaries, and limitations of their training objectives.",6 Conclusion,[0],[0]
We explain fundamental difficulties of interpretation due to pathologies in neural models trained with maximum likelihood.,6 Conclusion,[0],[0]
"Our
2http://demo.allennlp.org/ textual-entailment
work suggests several future directions to improve interpretability: more thorough evaluation of interpretation methods, better uncertainty and confidence estimates, and interpretation beyond bagof-word heatmap.",6 Conclusion,[0],[0]
Feng was supported under subcontract to Raytheon BBN Technologies by DARPA award HR0011-15-C-0113.,Acknowledgments,[0],[0]
JBG is supported by NSF Grant IIS1652666.,Acknowledgments,[0],[0]
"Any opinions, findings, conclusions, or recommendations expressed here are those of the authors and do not necessarily reflect the view of the sponsor.",Acknowledgments,[0],[0]
"The authors would like to thank Hal Daumé III, Alexander M. Rush, Nicolas Papernot, members of the CLIP lab at the University of Maryland, and the anonymous reviewers for their feedback.",Acknowledgments,[0],[0]
"One way to interpret neural model predictions is to highlight the most important input features—for example, a heatmap visualization over the words in an input sentence.",abstractText,[0],[0]
"In existing interpretation methods for NLP, a word’s importance is determined by either input perturbation—measuring the decrease in model confidence when that word is removed—or by the gradient with respect to that word.",abstractText,[0],[0]
"To understand the limitations of these methods, we use input reduction, which iteratively removes the least important word from the input.",abstractText,[0],[0]
This exposes pathological behaviors of neural models: the remaining words appear nonsensical to humans and are not the ones determined as important by interpretation methods.,abstractText,[0],[0]
"As we confirm with human experiments, the reduced examples lack information to support the prediction of any label, but models still make the same predictions with high confidence.",abstractText,[0],[0]
"To explain these counterintuitive results, we draw connections to adversarial examples and confidence calibration: pathological behaviors reveal difficulties in interpreting neural models trained with maximum likelihood.",abstractText,[0],[0]
"To mitigate their deficiencies, we fine-tune the models by encouraging high entropy outputs on reduced examples.",abstractText,[0],[0]
Fine-tuned models become more interpretable under input reduction without accuracy loss on regular examples.,abstractText,[0],[0]
Pathologies of Neural Models Make Interpretations Difficult,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1805–1816, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Recent progress in NLP has given rise to the field of personality profiling - automated classification of personality traits based on written, verbal and multimodal behavior of an individual.",1 Introduction,[0],[0]
"This research builds upon findings from classical personality psychology and has applications in a wide range of areas from medicine (suicide prevention) across security (forensics, paedophile detection, cyberbullying) to marketing and sales (recommendation systems, target group profiles).",1 Introduction,[0],[0]
"The gold standard labels for an objective evaluation of personality are mostly obtained by means of personality tests of the Five Factor Model (FFM) (McCrae and Costa, 1987; Goldberg, 1990), which is wellknown and widely accepted in psychology and other research fields.",1 Introduction,[0],[0]
"The FFM defines personality
along five bipolar scales: Extraversion (sociable vs. reserved), Emotional stability (secure vs. neurotic), Agreeableness (friendly vs. unsympathic), Conscientiousness (organized vs. careless) and Openness to experience (insightful vs. unimaginative).",1 Introduction,[0],[0]
"Psychologists have shown that these five personality traits are stable across individual lifespan, demographical and cultural differences (John and Srivastava, 1999) and affect many life aspects.",1 Introduction,[0],[0]
"(Terracciano et al., 2008; Rentfrow et al., 2011).
",1 Introduction,[0],[0]
"It has been shown that the personality traits of readers impact their literature preferences (Tirre and Dixit, 1995; Mar et al., 2009).",1 Introduction,[0],[0]
"Psychology researchers also found that perceived similarity is predictive of interpersonal attraction (Montoya et al., 2008; Byrne, 1961; Chartrand and Bargh, 1999).",1 Introduction,[0],[0]
"More explicitly, recent research (Kaufman and Libby, 2012) shows that readers of a narrative develop more favorable attitudes and less stereotype application towards a character, if his difference (e.g. racial) is revealed only later in the story.",1 Introduction,[0],[0]
We therefore hypothesize that readers might have a preference for reading novels depicting fictional characters that are similar to themselves.,1 Introduction,[0],[0]
Finding a direct link between reader’s and protagonist’s personality traits would advance the development of content-based recommendation systems.,1 Introduction,[0],[0]
"As a first step to explore this hypothesis further, it needs to be determined if we are able to construct a personality profile of a fictional character in a similar way as it is done for humans, and which aspects of personality profiling can be exploited to automatize such procedure.
",1 Introduction,[0],[0]
"In this paper, we open this research topic by presenting a novel collaboratively built dataset of fictional character personality in Section 3, which we make available on our website.1 Framing the personality prediction as a text classification task, we incorporate features of both lexical-
1https://www.ukp.tu-darmstadt.de/data/ personality-profiling/
1805
resource-based and vector space semantics, including WordNet and VerbNet sense-level information and vectorial word representations.",1 Introduction,[0],[0]
"We evaluate three machine learning models based on the speech (Section 4), actions (Section 5) and predicatives (Section 6) of the protagonists, and show that especially on the direct speech and action data the lexical-semantic features significantly outperform the baselines.",1 Introduction,[0],[0]
Qualitative analysis reveals that the most predictive features correspond to reported findings in psychology and NLP.,1 Introduction,[0],[0]
"Research in the the area of content-based recommendation systems have shown that incorporating semantic information is valuable for the user and leads to measurable improvements (Passant, 2010; Di Noia et al., 2012; Heitmann and Hayes, 2010).",2 Related work,[0],[0]
De Clercq et al. (2014) incorporated semantic frames from FrameNet into the recommendation system for books.,2 Related work,[0],[0]
They represent the plot of each book with a sequence of ca.,2 Related work,[0],[0]
200 semantic frames,2 Related work,[0],[0]
and has shown that the frame information (such as Killing - Revenge - Death) outperforms the bag-of-words approach.,2 Related work,[0],[0]
Recent NLP experiments begin to reveal the importance of entitycentric models in a variety of tasks.,2 Related work,[0],[0]
"Chambers (2013) show improvement in event schema induction by learning entity-centric rules (e.g., a victim is likely to be a person).",2 Related work,[0],[0]
"Bamman et al. (2014) and Smith et al. (2013) present latent variable models for unsupervised learning of latent character types in movie plot summaries and in English novels, taking authorial style into account.",2 Related work,[0],[0]
"However, even the state-of-the-art NLP work rather describes personas of fictional characters by their role in the story - e.g., action hero, valley girl, best friend, villain etc. - or by their relations to other characters, such as mother or daughter (Elson et al., 2010; Kokkinakis and Malm, 2011), rather than by their inner preferences and motivations.",2 Related work,[0],[0]
It is important to note here that determining a personality of a character is a very different task from determining its role in the story.,2 Related work,[0],[0]
"Psychological understanding of personality, in contrast to role attribution requires a certain detached objectivity - even outright villains may have traits considered desirable in real life.",2 Related work,[0],[0]
"For example, the devil has in many tales a very high aspiration level, appearing highly conscientious and agreeable.",2 Related work,[0],[0]
"We hypothesize that these deeper personality aspects are
those which drive reader’s affiliation to the character, thus deserve to be examined closer.
",2 Related work,[0],[0]
"Also literary scholars formulate ad hoc personality descriptions for their experiments, for example to test hypotheses from evolutionary psychology (Johnson et al., 2011) or examine fictional portrayals of physicists (Dotson, 2009).",2 Related work,[0],[0]
"These descriptions are usually adjusted to the experiment focus (e.g. emotions, relationships, ambitions).",2 Related work,[0],[0]
"As McCrae et al. () point out, a standard set of personality traits, that encompass the full range of characteristics found in all characters in literature (p.77), is needed for a better comparison.
",2 Related work,[0],[0]
Hence we base our present study primarily on the previous NLP research on personality prediction of human individuals.,2 Related work,[0],[0]
"Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author have been found in numerous experiments, with extraversion receiving the most attention (Pennebaker and King, 1999; Dewaele and Furnham, 1999; Gill and Oberlander, 2002; Mehl et al., 2006; Aran and Gatica-Perez, 2013; Lepri et al., 2010).",2 Related work,[0],[0]
"The LIWC lexicon (Pennebaker et al., 2001) established its position as a powerful mean of such analysis.
",2 Related work,[0],[0]
"The first machine learning experiments in this area were conducted by Argamon et al. (2005), Oberlander and Nowson (2006) and Mairesse et al. (2007).",2 Related work,[0],[0]
"Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets.",2 Related work,[0],[0]
"Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC psycholinguistic database (Coltheart, 1981) and prosodic features.",2 Related work,[0],[0]
Additional improvement is reported when the extraversion was labeled by external judges rather than by self-testing.,2 Related work,[0],[0]
"Extended studies on larger datasets achieve accuracies around 55% (Nowson, 2007; Estival et al., 2007).",2 Related work,[0],[0]
"More recent work in this area focuses on the personality prediction in social networks (Kosinski et al., 2013; Kosinski et al., 2014) and multimodal personality prediction (Biel and Gatica-Perez, 2013; Aran and Gatica-Perez, 2013).",2 Related work,[0],[0]
"These trends emphasized the correlation of network features and audiovisual features with extraversion, giving rise to the Workshop on Computational Personality Recognition (for an overview see (Celli et al., 2013; Celli et al., 2014).",2 Related work,[0],[0]
"Traditionally, the gold standard for this supervised classification task is obtained by the means of personality questionnaires, used for the Five-Factor Model, taken by each of the individuals assessed.",3 Data set construction,[0],[0]
This poses a challenge for fictional characters.,3 Data set construction,[0],[0]
"However, strong correlations have been found between the self-reported and perceived personality traits (Mehl et al., 2006).",3 Data set construction,[0],[0]
Our gold standard benefits from the fact that readers enjoy discussing the personality of their favourite book character online.,3 Data set construction,[0],[0]
"A popular layman instrument for personality classification is the Myers-Brigggs Type Indicator (Myers et al., 1985), shortly MBTI, which sorts personal preferences into four opposite pairs, or dichotomies, such as Thinking vs. Feeling or Judging vs. Perceiving.",3 Data set construction,[0],[0]
"While the MBTI validity has been questioned by the research community (Pittenger, 2005), the Extraversion scale is showing rather strong validity and correlation to similar trait in the Five-Factor Model (McCrae and Costa, 1989; MacDonald et al., 1994).",3 Data set construction,[0],[0]
"Our study hence focuses on the Extraversion scale.
",3 Data set construction,[0],[0]
"Our data was collected from the collaboratively constructed Personality Databank2 where the readers can vote if a book character is, among other aspects, introverted or extraverted.",3 Data set construction,[0],[0]
"While the readers used codes based on the MBTI typology, they did not apply the MBTI assessment strategies.",3 Data set construction,[0],[0]
There was no explicit annotation guideline and the interpretation was left to readers’ intuition and knowledge.3,3 Data set construction,[0],[0]
This approach of gold standard collection has several obvious drawbacks.,3 Data set construction,[0],[0]
"First, the question is posed as dichotomic, while in reality the extraversion is a normally distributed trait in human population (Goldberg, 1990).",3 Data set construction,[0],[0]
"Second, users can view the vote of previous participants, which may influence their decision.",3 Data set construction,[0],[0]
"While we address both of these issues in our ongoing data collection project based on the Five-Factor Model, we consider them acceptable for this study due to the exploratory character of our pilot research.
",3 Data set construction,[0],[0]
"We have collected extraversion ratings for 298 book characters, of which 129 (43%) are rather extraverted and 166 (56%) rather introverted.",3 Data set construction,[0],[0]
"Rated
2http://www.mbti-databank.com/ 3MBTI defines extraversion as “getting energy from active involvement in events, having a lot of different activities, enjoying being around people.”",3 Data set construction,[0],[0]
"In the NEO Five-Factor Inventory (Costa and McCrae, 1992), underlying facets of extraversion are warmth, gregariousness, assertiveness, activity, excitement seeking and positive emotion.
",3 Data set construction,[0],[0]
"characters come from a wide range of novels that the online users are familiar with, often covering classical literature which is part of the high school syllabus, as well as the most popular modern fiction, such as the Harry Potter series, Twilight, Star Wars or A Game of Thrones.",3 Data set construction,[0],[0]
A sample of the most rated introverts and extraverts is given in table 1.,3 Data set construction,[0],[0]
The rating distribution in our data is strongly Ushaped.,3 Data set construction,[0],[0]
"The percentage agreement of voters in our data is 84.9%, calculated as:
P = 1 N N∑ i=1",3 Data set construction,[0],[0]
k∑ j=1 nij(nij,3 Data set construction,[0],[0]
"− 1) n(n− 1)
where k = 2 (introvert, extravert), N is the number of book characters and n the number of votes per character.",3 Data set construction,[0],[0]
Voters on the website were anonymous and cannot be uniquely identified for additional corrections.,3 Data set construction,[0],[0]
"There is no correlation between the extraversion and the gender of the character.
",3 Data set construction,[0],[0]
Our set of English e-books covered 220 of the characters from our gold standard.,3 Data set construction,[0],[0]
"We have built three systems to assess the following:
1.",3 Data set construction,[0],[0]
Direct speech: Does the style and content of character’s utterances predict his extraversion in a similar way as it was shown for living individuals?,3 Data set construction,[0],[0]
"2. Actions: Is the behavior, of which a character is an agent, predictive for extraversion?",3 Data set construction,[0],[0]
3.,3 Data set construction,[0],[0]
"Predicatives and adverbs: Are the explicit (John was an exhibitionist) or implicit (John shouted abruptly) descriptions of the character in the book predictive for extraversion?
",3 Data set construction,[0],[0]
In the next three sections we present the experimental settings and results for each of the systems.,3 Data set construction,[0],[0]
"The system for the direct speech resembles the most to the previous systems developed for author personality profiling, e.g. on stream of consciousness essays (Mairesse et al., 2007) or social media posts (Celli et al., 2013) and therefore provides the best opportunity for comparison between human individuals and fictional characters.",4 Direct speech of fictional characters,[0],[0]
"On top of the comparison to previous research, we exploit the sense links between WordNet and VerbNet to extract additional features - an approach which is novel for this type of task.",4 Direct speech of fictional characters,[0],[0]
"We process the book text using freely available components of the DKPro framework (Gurevych et al., 2007).",4.1 Extraction and assignment of speech,[0],[0]
The most challenging task in building the direct speech data set is assigning to the direct speech utterance the correct speaker.,4.1 Extraction and assignment of speech,[0],[0]
"We benefit from the epub format of the e-books which defines a paragraph structure in such a way, that only the indirect speech chunk immediately surrounding the direct speech can be considered:
<p> John turned to Harry.",4.1 Extraction and assignment of speech,[0],[0]
"""Let’s go,"" he said.</p>
Given the large amount of text available in the books we focus on precision and discard all utterances with no explicit speaker (i.e., 30-70% of the utterances, dependent on the book), as the performance of current systems on such utterance types is still fairly low (O’Keefe et al., 2012; He et al., 2013; Iosif and Mishra, 2014).",4.1 Extraction and assignment of speech,[0],[0]
"Similarly, conventional coreference resolution systems did not perform well on this type of data and were therefore not used in the final setup.",4.1 Extraction and assignment of speech,[0],[0]
"We adapt the Stanford Named Entity Recognizer(Finkel et al., 2005) to consider titles (Mr., Mrs., Sir...) as a part of the name and to treat the first person I as a named entity.",4.1 Extraction and assignment of speech,[0],[0]
"However, identifying only the named entity PERSON in this way is not sufficient.",4.1 Extraction and assignment of speech,[0],[0]
"On our evaluation sample consisting of A Game of Thrones and Pride and Prejudice books (the former annotated by us, the latter by He et al. (2013)), 20% of utterances with explicit named speaker were not recognized.",4.1 Extraction and assignment of speech,[0],[0]
"Of those correctly identified as a Person in the adjacent indirect speech, 17% were not the speakers.",4.1 Extraction and assignment of speech,[0],[0]
"Therefore we implemented a
custom heuristics (Algorithm 1), which additionally benefits from the WordNet semantic classes of verbs, enriching the speaker detection by grabbing the nouns .",4.1 Extraction and assignment of speech,[0],[0]
"With this method we retrieve 89% of known speakers, of which 92% is assigned correctly.",4.1 Extraction and assignment of speech,[0],[0]
"Retrieved names are grouped based on string overlap (e.g. Ser Jaime and Jaime Lannister), excluding the match on last name, and corrected for non-obvious groupings (such as Margaret and Peggy).",4.1 Extraction and assignment of speech,[0],[0]
"Algorithm 1 Assign speaker 1: nsubj← subjects in adjacent indirect speech 2: if count(nsubj(i) = PERSON) = 1 then speaker ←
nsubj 3: else if count(nsubj(i) = PERSON) ≥ 1 then
speaker ← the nearest one to directSpeech 4: else if directSpeech preceded by
VERB.COMMUNICATION then speaker ← the preceding noun(s) 5: else if directSpeech followed by VERB.COMMUNICATION then speaker ← the following noun(s) 6: else if directSpeech followed by gap & VERB.COMMUNICATION then speaker ← the noun(s) in gap 7: else if directSpeech preceded by gap & VERB.COMMUNICATION then speaker ← the noun(s) in gap return speaker
Our experimental data consists of usable direct speech sets of 175 characters - 80 extraverts (E) and 95 introverts (I) - containing 289 274 words in 21 857 utterances (on average 111 utterances for E and 136 for I, as I are often central in books).4",4.1 Extraction and assignment of speech,[0],[0]
All speech utterances of one book character are represented as one instance in our system.,4.2 Classification approach for direct speech,[0],[0]
"We use the leave-one-out classification setup due to the relatively small dataset size, using the support vector machines (SVM-SMO) classifier, which performs well on comparable tasks (Celli et al., 2013).",4.2 Classification approach for direct speech,[0],[0]
"The classification is performed through the DKPro TC Framework (Daxenberger et al., 2014).
",4.2 Classification approach for direct speech,[0],[0]
"Lexical features As a bottom-up approach we use the 1000 most frequent word uni-, bi- and trigrams, 1000 dependency word pairs, 1000 character trigrams and 500 most frequent verbs, adverbs, adjectives and interjections as binary features.
",4.2 Classification approach for direct speech,[0],[0]
"Semantic features Since the top-down approach, i.e. not focusing on individual words, has
4The data set size is comparable to ongoing personality profiling challenges - see http://pan.webis.de
been found more suitable for the personality profiling task on smaller data sets (Celli et al., 2013), we aim on capturing additional phenomena on a higher level of abstraction.",4.2 Classification approach for direct speech,[0],[0]
The main part of our features is extracted on sense level.,4.2 Classification approach for direct speech,[0],[0]
"We use the most frequent sense of WordNet (Miller, 1995) to annotate all verbs in the direct speech (a simple but well performing approach for books).",4.2 Classification approach for direct speech,[0],[0]
"We then label the disambiguated verbs with their semantic field given in WordNet (WordNet defines 14 semantic classes of verbs which group verbs by their semantic field) and we measure frequency and occurence of each of these classes (e.g. cognition, communication, motion, perception)5.",4.2 Classification approach for direct speech,[0],[0]
"Additionally, we use the lexical-semantic resource UBY (Gurevych et al., 2012) to access the WordNet and VerbNet information, and to exploit the VerbNet sense-level links which connects WordNet senses with the corresponding 273 main VerbNet classes (Kipper-Schuler, 2005).",4.2 Classification approach for direct speech,[0],[0]
"These are more fine-grained (e.g. pay, conspire, neglect, discover) than the WordNet semantic fields.",4.2 Classification approach for direct speech,[0],[0]
"WordNet covered 90% and VerbNet 86% of all the verb occurences.
",4.2 Classification approach for direct speech,[0],[0]
"On word level, we extract 81 additional features using the Linguistic Inquiry and Word Count (LIWC) tools (Pennebaker et al., 2001), which consists of lexicons related to psychological processes (cognitive, perceptual, social, biological, affective) and personal concerns (achievement, religion, death...) and other categories such as fillers, disfluencies or swear words6.",4.2 Classification approach for direct speech,[0],[0]
"Additionally, since emotion detection has been found predictive in previous personality work (Mohammad and Kiritchenko, 2013), we measure overall positive and negative sentiment expressed per character, using SentiWordNet (Esuli and Sebastiani, 2006) and NRC Emotion Lexicon (Mohammad and Turney, 2010) for the word lookup, inverting sentiment scores for negated dependency sub-tree given by the Stanford Parser.
Stylistic features Features of this group capture the syntactic and stylistic properties of the utterances of a character, disregarding the content.",4.2 Classification approach for direct speech,[0],[0]
"Starting from the surfacial properties, we measure the sentence, utterance and word length, including the proportion of words shorter than 4 or longer than 6 letters, frequency of each punctuation mark,
5https://wordnet.princeton.edu/man/ lexnames.5WN.html
6For complete overview refer to www.liwc.net
and endings of each adjective as per Corney et al. (2002).",4.2 Classification approach for direct speech,[0],[0]
"On the syntax level we measure the frequency of each part of speech as well as the 500 most frequent part-of-speech bi-, tri- and quadrigrams, and the frequency of each dependency obtained from the Stanford Parser.",4.2 Classification approach for direct speech,[0],[0]
"We additionally capture the frequency of superlatives, comparatives and modal verbs, the proportion of verbs in present, past and future tense, and the formality of the language as per the part-of-speech-based formality coefficient (Heylighen and Dewaele, 2002), and measure the average depth of the parse trees.
",4.2 Classification approach for direct speech,[0],[0]
"Word embeddings as features Since vector space semantics has been beneficial for predicting author’s personality in previous work (Neuman and Cohen, 2014), we use a pre-trained word vector model created by the GloVe algorithm (Pennington et al., 2014) on English Wikipedia.",4.2 Classification approach for direct speech,[0],[0]
GloVe employs a global log-bilinear regression model that combines the advantages of the global matrix factorization and local context window methods.,4.2 Classification approach for direct speech,[0],[0]
"We assign the resulting 300-dimensional vectors to the words in character’s direct speech, excluding stopwords, and calculate an average vector for each character.",4.2 Classification approach for direct speech,[0],[0]
"We calculate for each test character the cosine similarity to the mean vector of extravert, resp.",4.2 Classification approach for direct speech,[0],[0]
"introvert, in the training data, and to each character in the training set individually using the DL4J NLP package7.",4.2 Classification approach for direct speech,[0],[0]
We consider both the final scalar outcome and the difference of each of the individual vector dimensions as features.,4.2 Classification approach for direct speech,[0],[0]
"Table 2 shows the precision, recall, F1-score and accuracy for extraversion and introversion as a weighted average of the two class values.
",4.3 Classification results on direct speech,[0],[0]
"7http://deeplearning4j.org/
Similarly to previous research (Mairesse et al., 2007; Celli et al., 2013), the bottom-up word based approach is outperformed by top-down semantic approaches which employ a more abstract feature representation.",4.3 Classification results on direct speech,[0],[0]
"As in previous work, LIWC features exhibit good performance.",4.3 Classification results on direct speech,[0],[0]
"However, the highest performance is achieved employing the VerbNet verb classes with WordNet wordsense disambiguation.",4.3 Classification results on direct speech,[0],[0]
Also stylistic features contribute substantially to the classification despite the mixture of genres in our book corpus - especially frequencies of modal verbs and part-ofspeech ratios were particularly informative.,4.3 Classification results on direct speech,[0],[0]
"The most predictive features from each group are listed in Table 3 together with their correlation merit (Hall, 1999), and compared with previous work in Table 4.
",4.3 Classification results on direct speech,[0],[0]
"In accordance with the experiments of Pennebaker and King (1999), we observe more frequent exclusions (e.g. without, but), hedging and negation expressed by introverts, and inclusion (e.g. with, and) by extraverts.",4.3 Classification results on direct speech,[0],[0]
"Extraverts talk more in first person plural, use more back-channels and interjections, and talk more about aspects related to their body.",4.3 Classification results on direct speech,[0],[0]
"Introverts show more rationalization through insight words and more factual speech using less pronouns.
",4.3 Classification results on direct speech,[0],[0]
"Additionally, the semantic features in Table 3 confirm the broad psychological characteristics of both types in general, i.e., for introverts the rationalization, uncertainty and preference for individual or rather static activities, and for extraverts their spontaneity, talkativeness and preference for motion.",4.3 Classification results on direct speech,[0],[0]
"Furthermore, we observe certain directness in extraverts’ speech - note the predictive words fat and dirty and frequent descriptions of body functions.
",4.3 Classification results on direct speech,[0],[0]
Discussion Exploiting the links between lexicalsemantic resources (performing WordNet wordsense disambiguation and using VerbNet verb classes linked to the disambiguated senses) was particularly beneficial for this task.,4.3 Classification results on direct speech,[0],[0]
"WordNet semantic fields for verbs alone are too coarsegrained to capture the nuances in direct speech, and experiments with fine-grained VerbNet classes without WSD resulted in noisy labels.",4.3 Classification results on direct speech,[0],[0]
"We did not confirm the previously reported findings on emotional polarity - we observe that the genre of the books (e.g. love romance vs horror story) have blurred the subtle differences between individual characters, unfortunately the dataset size did not allow for genre distinctions.",4.3 Classification results on direct speech,[0],[0]
"Furthermore, a perceived extravert in our case can be a pure villain (Draco Malfoy, Joffrey Baratheon...) as well as a friendly companion (Gimli, Ron Weasley...), while the evil extravert types are possibly rarer in the experiments on human writing, or are more likely to fit under the MBTI definition of extraversion than FFM facets.",4.3 Classification results on direct speech,[0],[0]
"Another potential cause, based on the error analysis, is the different target of the same sentiment for extraverts and introverts.",4.3 Classification results on direct speech,[0],[0]
"For example, the ngram ”I fear” is highly predictive for an introvert in our data while extraverts would rather use formulations to imply that others should fear.",4.3 Classification results on direct speech,[0],[0]
"Similarly to Nowson et al. (2005), we did not find any difference in the formality measure of Heylighen and Dewaele (2002).",4.3 Classification results on direct speech,[0],[0]
"Neither we did in the complexity of sentences as per the parse tree depth
and sentence length.",4.3 Classification results on direct speech,[0],[0]
It is probable that these aspects were also impacted by our broad variety of author style (F. Dostoyevsky vs J. K. Rowling).,4.3 Classification results on direct speech,[0],[0]
"Our basic vector-based features carried no useful information in our case, in contrast to the personality research of Neuman and Cohen (2014).",4.3 Classification results on direct speech,[0],[0]
We observed that the factual content of the stories contributed to the character similarity measure more than the subtle personality differences.,4.3 Classification results on direct speech,[0],[0]
"While psycholinguists and consequenlty NLP researchers analyzed the relation between speech, resp.",5 Actions of fictional characters,[0],[0]
"writing, and personality of an individual, psychologists often evaluate extraversion through behavioral personality questionnaries (Costa and McCrae, 1992; Goldberg et al., 2006).",5 Actions of fictional characters,[0],[0]
We hypothesize that similar behavior shall be predictive for extraversion of fictional characters as perceived by the readers.,5 Actions of fictional characters,[0],[0]
"For our purpose we define actions as the subject, verb and context of a sentence, where the subject is a named entity Person and the context is either a direct object in relation dobj to the verb or a first child of the adjacent verb phrase in a parse tree.",5.1 Action extraction,[0],[0]
"After grouping the actions per character, the subject name is removed.",5.1 Action extraction,[0],[0]
"For example, a sample of actions of the character Eddard Stark of Game of Thrones would be: X paused a moment, X studied his face, X changed his mind, X unrolled the paper, X said etc., visualized in Figure 1.",5.1 Action extraction,[0],[0]
"We obtained 22 030 actions for 205 characters (102 E, 116 I), with on average 100 actions for E and 101 for I. Note that also actions for those characters who do not talk enough in the books (often first-person perspectives) could be used.",5.1 Action extraction,[0],[0]
In the system based on actions we use only a subset of the features described in 4.2.,5.2 Action classification setup,[0],[0]
From the lexical features we focus on the 500 most frequent verbs and dependency word pairs.,5.2 Action classification setup,[0],[0]
"Semantic features are used the same way as in 4.2, profiting from LIWC, WordNet, Verbnet and the sentiment lexicons.",5.2 Action classification setup,[0],[0]
Word embedding vectors for book characters are in this case computed by taking only the verbs into account rather than all content words.,5.2 Action classification setup,[0],[0]
"From the stylistic features we use the part-ofspeech bigrams and trigrams, verb modality and verb tense.",5.2 Action classification setup,[0],[0]
"Table 5 shows the performance of the classification models based on the protagonists’ actions, using different feature groups.",5.3 Classification results on actions,[0],[0]
"The overall performance is higher than for the direct speech model.
",5.3 Classification results on actions,[0],[0]
"Due to the lack of previous NLP experiments on this task, we compare our features to the actions measured in the International Personality Item Pool (Goldberg et al., 2006), frequently used personality assesment questionnaire (Table 6).
",5.3 Classification results on actions,[0],[0]
The most predictive features of this model capture the activity and excitement seeking facets of extraversion.,5.3 Classification results on actions,[0],[0]
"Stylistic features reflect the complexity difference of the verb phrases (John jumped vs. John thought about it), extraverts being characterized by plain verbs.",5.3 Classification results on actions,[0],[0]
Semantic features exhibit higher precision than stylistic ones.,5.3 Classification results on actions,[0],[0]
"Sense-linked semantic classes of VerbNet demonstrate the preference of extraverts for being active and expressing themselves - they jump, fight, shout, run in and run out, eat and drink, see and hear and get easily bored.",5.3 Classification results on actions,[0],[0]
"Extraverts in books also
often bring or hold something.",5.3 Classification results on actions,[0],[0]
"Introverts, on the other hand, seem to favor slow movements - while they are thinking, reflecting, creating, looking for explanations and find out solutions, they tend to lie down, sit or walk, eventually even sleep or snooze.",5.3 Classification results on actions,[0],[0]
"The uncertainty typical for introverts is also notable in their actions, as they often hope or wish for something they might like to do.",5.3 Classification results on actions,[0],[0]
"Additionally, semantic classes Social and Family, reported as correlated to extraversion by Pennebaker and King (1999) and not confirmed in our first model, became predictive in protaonists’ actions.",5.3 Classification results on actions,[0],[0]
"Also in this task, the VerbNet classes brought significant improvement in performance.",5.4 Discussion,[0],[0]
"The classification model based on actions outperforms not only the direct speech model, but also the state-of-the-art systems predicting authors’ extraversion from the stream-of-consciousness essays (Mairesse et al., 2007; Celli et al., 2013; Neuman and Cohen, 2014).",5.4 Discussion,[0],[0]
"While surely not directly comparable, this result hints to the fact that the personality is easier to detect from behavior than from person’s verbal expression.",5.4 Discussion,[0],[0]
"This would correspond to the findings of Mairesse et al. (2007), Biel and Gatica-Perez (2013) and Aran and Gatica-Perez (2013) on multimodal data sets.",5.4 Discussion,[0],[0]
Our third extraversion prediction system is subordinate to how fictional characters are described and to the manners in which they behave.,6 Predicatives of fictional characters,[0],[0]
We are not aware of a previous NLP work predicting extraversion using descriptive adjectives of the persons in question.,6 Predicatives of fictional characters,[0],[0]
We thus juxtapose the most predictive features of our system to the adjectival extraversion markers developed by Goldberg (1992).,6 Predicatives of fictional characters,[0],[0]
In this setup we extract predicatives of the named entities PERSON in the books - relations amod (angry John) and cop (John was smart).,6.1 Extraction of descriptive properties,[0],[0]
"As these explicit statements are very sparse in modern novels, we additionally include adverbial modifiers (advmod) related to person’s actions (John said angrily).",6.1 Extraction of descriptive properties,[0],[0]
"We extract data for 205 characters, with on average 43 words per character.",6.1 Extraction of descriptive properties,[0],[0]
"This system uses similar set of lexical, semantic and vectorial features similarly as in 5.2, this time with the focus on adjectives, nouns and adverbs instead of verbs.",6.2 Classification setup,[0],[0]
"Stylistic and VerbNet features are hence not included, word vectors are as in 4.2.",6.2 Classification setup,[0],[0]
Table 7 reports on the performance of individual feature groups.,6.3 Classification results on descriptions,[0],[0]
"With only few words per character semantic lexicons are less powerful than ngrams.
",6.3 Classification results on descriptions,[0],[0]
Table 8 displays the most predictive features in our system contrasted to the adjectival markers.,6.3 Classification results on descriptions,[0],[0]
All our systems had issues with characters rated by less than five readers and with protagonists with low agreement.,6.4 Discussion on errors,[0],[0]
"Other challenges arise from authorial style, age of the novel and speech individuality of characters (e.g. Yoda).",6.4 Discussion on errors,[0],[0]
"Varied length of information for different characters poses issues in measuring normally distributed features (e.g. ratio of jumping verbs), being in shorter texts less reliable.",6.4 Discussion on errors,[0],[0]
"Ongoing and future work on this task addresses the limitations of these initial experiments, especially the data set size and the gold standard quality.",6.4 Discussion on errors,[0],[0]
Extending the data will also enable us to examine different book genres as variables for the personality distribution and feature impact.,6.4 Discussion on errors,[0],[0]
"It will be worth examining the relations between characters, since we observed certain patterns in our data, such as the main introvert character supported by his best friend extravert.",6.4 Discussion on errors,[0],[0]
"Additionally, we want to verify if the system in Section 6 is overly optimistic due to the data size.",6.4 Discussion on errors,[0],[0]
"Automated personality profiling of fictional characters, based on rigorous models from personality psychology, has a potential to impact numerous domains.",7 Conclusion and future work,[0],[0]
We framed it as a text classification problem and presented a novel collaboratively built dataset of fictional personality.,7 Conclusion and future work,[0],[0]
"We incor-
porate features of both lexical resource-based and vectorial semantics, including WordNet and VerbNet sense-level information and vectorial word representations.",7 Conclusion and future work,[0],[0]
"In models based on the speech and actions of the protagonists, we demonstrated that the sense-linked lexical-semantic features significantly outperform the baselines.",7 Conclusion and future work,[0],[0]
The most predictive features correspond to the reported findings in personality psychology and NLP experiments on human personality.,7 Conclusion and future work,[0],[0]
"Our systems based on actions and appearance of characters demonstrate higher performance than systems based on direct speech, which is in accordance with recent research on personality in social networks (Kosinski et al., 2014; Biel and Gatica-Perez, 2013), revealing the importance of the metadata.",7 Conclusion and future work,[0],[0]
"We have shown that exploiting the links between lexical resources to leverage more accurate semantic information can be beneficial for this type of tasks, oriented to actions performed by the entity.",7 Conclusion and future work,[0],[0]
"However, the human annotator agreement in our task stays high above the performance achieved.",7 Conclusion and future work,[0],[0]
"Considering that most of the sucessful novels were produced as movies, we cannot exclude that our annotators based their decision on the multimodal representation of the protagonists.",7 Conclusion and future work,[0],[0]
"In the future we aim on collecting a more detail and rigorous gold standard through gamification and expanding our work on all five personality traits from the FiveFactor Model and their facets, and ultimately extend our system to a semi-supervised model dealing with notably larger amount of data.",7 Conclusion and future work,[0],[0]
"We also plan to examine closer the differences between perceived human and fictional personality, and the relationship between the personality of the reader and the characters.",7 Conclusion and future work,[0],[0]
This work has been supported by the Volkswagen Foundation as part of the Lichtenberg Professorship Program under grant No. I/82806 and by the German Research Foundation under grant No. GU 798/14-1.,Acknowledgments,[0],[0]
Additional support was provided by the German Federal Ministry of Education and Research (BMBF) as a part of the Software Campus program under the promotional reference 01-S12054 and by the German Institute for Educational Research (DIPF).,Acknowledgments,[0],[0]
"We also warmly thank Holtzbrinck Digital GmbH for providing a substantial part of the e-book resources, and the EMNLP reviewers for their helpful comments.",Acknowledgments,[0],[0]
This study focuses on personality prediction of protagonists in novels based on the Five-Factor Model of personality.,abstractText,[0],[0]
We present and publish a novel collaboratively built dataset of fictional character personality and design our task as a text classification problem.,abstractText,[0],[0]
"We incorporate a range of semantic features, including WordNet and VerbNet sense-level information and word vector representations.",abstractText,[0],[0]
"We evaluate three machine learning models based on the speech, actions and predicatives of the main characters, and show that especially the lexical-semantic features significantly outperform the baselines.",abstractText,[0],[0]
The most predictive features correspond to reported findings in personality psychology.,abstractText,[0],[0]
Personality Profiling of Fictional Characters using Sense-Level Links between Lexical Resources,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 700–705 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
700",text,[0],[0]
Query auto-completion (QAC) is a feature used by search engines that provides a list of suggested queries for the user as they are typing.,1 Introduction,[0],[0]
"For instance, if the user types the prefix “mete” then the system might suggest “meters” or “meteorite” as completions.",1 Introduction,[0],[0]
"This feature can save the user time and reduce cognitive load (Cai et al., 2016).
",1 Introduction,[0],[0]
"Most approaches to QAC are extensions of the Most Popular Completion (MPC) algorithm (BarYossef and Kraus, 2011).",1 Introduction,[0],[0]
MPC suggests completions based on the most popular queries in the training data that match the specified prefix.,1 Introduction,[0],[0]
"One way to improve MPC is to consider additional signals such as temporal information (Shokouhi and Radinsky, 2012; Whiting and Jose, 2014) or information gleaned from a users’ past queries (Shokouhi, 2013).",1 Introduction,[0],[0]
"This paper deals with the latter of those two signals, i.e. personalization.",1 Introduction,[0],[0]
"Personalization relies on the fact that query likelihoods are drastically different among different people depending on their needs and interests.
",1 Introduction,[0],[0]
"Recently, Park and Chiba (2017) suggested a significantly different approach to QAC.",1 Introduction,[0],[0]
"In their
work, completions are generated from a character LSTM language model instead of by ranking completions retrieved from a database, as in the MPC algorithm.",1 Introduction,[0],[0]
"This approach is able to complete queries whose prefixes were not seen during training and has significant memory savings over having to store a large query database.
",1 Introduction,[0],[0]
"Building on this work, we consider the task of personalized QAC, advancing current methods by combining the obvious advantages of personalization with the effectiveness of a language model in handling rare and previously unseen prefixes.",1 Introduction,[0],[0]
The model must learn how to extract information from a user’s past queries and use it to adapt the generative model for that person’s future queries.,1 Introduction,[0],[0]
"To do this, we leverage recent advances in contextadaptive neural language modeling.",1 Introduction,[0],[0]
"In particular, we make use of the recently introduced FactorCell model that uses an embedding vector to additively transform the weights of the language model’s recurrent layer with a low-rank matrix (Jaech and Ostendorf, 2017).",1 Introduction,[0],[0]
"By allowing a greater fraction of the weights to change during personalization, the FactorCell model has advantages over the traditional approach to adaptation of concatenating a context vector to the input of the LSTM (Mikolov and Zweig, 2012).
",1 Introduction,[0],[0]
"Table 1 provides an anecdotal example from
the trained FactorCell model to demonstrate the intended behavior.",1 Introduction,[0],[0]
The table shows the top five completions for the prefix “ba” in a cold start scenario and again after the user has completed five sports related queries.,1 Introduction,[0],[0]
"In the warm start scenario, the “baby names” and “babiesrus” completions no longer appear in the top five and have been replaced with “basketball” and “baseball”.
",1 Introduction,[0],[0]
The novel aspects of this work are the application of an adaptive language model to the task of QAC personalization and the demonstration of how RNN language models can be adapted to contexts (users) not seen during training.,1 Introduction,[0],[0]
An additional contribution is showing that a richer adaptation framework gives added gains with added data.,1 Introduction,[0],[0]
"Adaptation depends on learning an embedding for each user, which we discuss in Section 2.1, and then using that embedding to adjust the weights of the recurrent layer, discussed in Section 2.2.",2 Model,[0],[0]
"During training, we learn an embedding for each of the users.",2.1 Learning User Embeddings,[0],[0]
We think of these embeddings as holding latent demographic factors for each user.,2.1 Learning User Embeddings,[0],[0]
"Users who have less than 15 queries in the training data (around half the users but less than 13% of the queries) are grouped together as a single entity, user1, leaving k users.",2.1 Learning User Embeddings,[0],[0]
"The user embeddings matrix Uk×m, wherem is the user embedding size, is learned via back-propagation as part of the end-toend model.",2.1 Learning User Embeddings,[0],[0]
"The embedding for an individual user is the ith row of U and is denoted by ui.
",2.1 Learning User Embeddings,[0],[0]
It is important to be able to apply the model to users that are not seen during training.,2.1 Learning User Embeddings,[0],[0]
This is done by online updating of the user embeddings during evaluation.,2.1 Learning User Embeddings,[0],[0]
"When a new person, userk+1 is seen, a new row is added to U and initialized to u1.",2.1 Learning User Embeddings,[0],[0]
Each person’s user embedding is updated via back-propagation every time they select a query.,2.1 Learning User Embeddings,[0],[0]
"When doing online updating of the user embeddings, the rest of the model parameters (everything except U) are frozen.",2.1 Learning User Embeddings,[0],[0]
We consider three model architectures which differ only in the method for adapting the recurrent layer.,2.2 Recurrent Layer Adaptation,[0],[0]
"First is the unadapted LM, analogous to the model from Park and Chiba (2017), which does no personalization.",2.2 Recurrent Layer Adaptation,[0],[0]
"The second architecture was
introduced by Mikolov and Zweig (2012) and has been used multiple times for LM personalization (Wen et al., 2013; Huang et al., 2014; Li et al., 2016).",2.2 Recurrent Layer Adaptation,[0],[0]
It works by concatenating a user embedding to the character embedding at every step of the input to the recurrent layer.,2.2 Recurrent Layer Adaptation,[0],[0]
Jaech and Ostendorf (2017) refer to this model as the ConcatCell and show that it is equivalent to adding a term Vu to adjust the bias of the recurrent layer.,2.2 Recurrent Layer Adaptation,[0],[0]
"The hidden state of a ConcatCell with embedding size e and hidden state size h is given in Equation 1 where σ is the activation function, wt is the character embedding, ht−1 is the previous hidden state, and W ∈ Re+h×h and b ∈",2.2 Recurrent Layer Adaptation,[0],[0]
"Rh are the recurrent layer weight matrix and bias vector.
",2.2 Recurrent Layer Adaptation,[0],[0]
"ht = σ([wt, ht−1]W + b+Vu) (1)
",2.2 Recurrent Layer Adaptation,[0],[0]
Adapting just the bias vector is a significant limitation.,2.2 Recurrent Layer Adaptation,[0],[0]
"The FactorCell model, (Jaech and Ostendorf, 2017), remedies this by letting the user embedding transform the weights of the recurrent layer via the use of a low-rank adaptation matrix.",2.2 Recurrent Layer Adaptation,[0],[0]
"The FactorCell uses a weight matrix W′ = W +A that has been additively transformed by a personalized low-rank matrix A. Because the FactorCell weight matrix W′ is different for each user (See Equation 2), it allows for a much stronger adaptation than what is possible using the more standard ConcatCell model.1
ht = σ([wt, ht−1]W ′ + b) (2)
The low-rank adaptation matrix A is generated by taking the product between a user’s m dimensional embedding and left and right bases tensors, ZL ∈ Rm×e+h×r and ZR ∈ Rr×h×m",2.2 Recurrent Layer Adaptation,[0],[0]
"as so,
A = (ui ×1 ZL)(ZR ×3 ui) (3)
where ×i denotes the mode-i tensor product.",2.2 Recurrent Layer Adaptation,[0],[0]
The above product selects a user specific adaptation matrix by taking a weighted combination of the m rank r matrices held between ZL and ZR.,2.2 Recurrent Layer Adaptation,[0],[0]
"The rank, r, is a hyperparameter which controls the degree of personalization.",2.2 Recurrent Layer Adaptation,[0],[0]
"Our experiments make use of the AOL Query data collected over three months in 2006 (Pass et al., 2006).",3 Data,[0],[0]
"The first six of the ten files were used for
1In the case of an LSTM, W′ is extended to incorporate all of the gates.
training.",3 Data,[0],[0]
"This contains approximately 12 million queries from 173,000 users for an average of 70 queries per user (median 15).",3 Data,[0],[0]
"A set of 240,000 queries from those same users (2% of the data) was reserved for tuning and validation.",3 Data,[0],[0]
"From the remaining files, one million queries from 30,000 users are used to test the models on a disjoint set of users.",3 Data,[0],[0]
The vocabulary consists of 79 characters including special start and stop tokens.,4.1 Implementation Details,[0],[0]
Models were trained for six epochs.,4.1 Implementation Details,[0],[0]
"The Adam optimizer is used during training with a learning rate of 10−3 (Kingma and Ba, 2014).",4.1 Implementation Details,[0],[0]
"When updating the user embeddings during evaluation, we found that it is easier to use an optimizer without momentum.",4.1 Implementation Details,[0],[0]
"We use Adadelta (Zeiler, 2012) and tune the online learning rate to give the best perplexity on a held-out set of 12,000 queries, having previously verified that perplexity is a good indicator of performance on the QAC task.2
",4.1 Implementation Details,[0],[0]
"The language model is a single-layer characterlevel LSTM with coupled input and forget gates and layer normalization (Melis et al., 2018; Ba et al., 2016).",4.1 Implementation Details,[0],[0]
We do experiments on two model configurations: small and large.,4.1 Implementation Details,[0],[0]
The small models use an LSTM hidden state size of 300 and 20 dimensional user embeddings.,4.1 Implementation Details,[0],[0]
The large models use a hidden state size of 600 and 40 dimensional user embeddings.,4.1 Implementation Details,[0],[0]
Both sizes use 24 dimensional character embeddings.,4.1 Implementation Details,[0],[0]
"For the small sized models, we experimented with different values of the FactorCell rank hyperparameter between 30 and 50 dimensions finding that bigger rank is better.",4.1 Implementation Details,[0],[0]
The large sized models used a fixed value of 60 for the rank hyperparemeter.,4.1 Implementation Details,[0],[0]
"During training only and due to limited computational resources, queries are truncated to a length of 40 characters.
",4.1 Implementation Details,[0],[0]
Prefixes are selected uniformly at random with the constraint that they contain at least two characters in the prefix and that there is at least one character in the completion.,4.1 Implementation Details,[0],[0]
"To generate completions using beam search, we use a beam width of 100 and a branching factor of 4.",4.1 Implementation Details,[0],[0]
"Results are reported using mean reciprocal rank (MRR), the standard method of evaluating QAC systems.",4.1 Implementation Details,[0],[0]
"It is the mean of the reciprocal rank of the true completion in the
2Code at http://github.com/ajaech/query completion
top ten proposed completions.",4.1 Implementation Details,[0],[0]
"The reciprocal rank is zero if the true completion is not in the top ten.
",4.1 Implementation Details,[0],[0]
Neural models are compared against an MPC baseline.,4.1 Implementation Details,[0],[0]
"Following Park and Chiba (2017), we remove queries seen less than three times from the MPC training data.",4.1 Implementation Details,[0],[0]
Table 2 compares the performance of the different models against the MPC baseline on a test set of one million queries from a user population that is disjoint with the training set.,4.2 Results,[0],[0]
Results are presented separately for prefixes that are seen or unseen in the training data.,4.2 Results,[0],[0]
"Consistent with prior work, the neural models do better than the MPC baseline.",4.2 Results,[0],[0]
The personalized models are both better than the unadapted one.,4.2 Results,[0],[0]
"The FactorCell model is the best overall in both the big and small sized experiments, but the gain is mainly for the seen prefixes.
",4.2 Results,[0],[0]
Figure 1 shows the relative improvement in MRR over an unpersonalized model versus the number of queries seen per user.,4.2 Results,[0],[0]
"Both the Factor-
Cell and the ConcatCell show continued improvement as more queries from each user are seen, and the FactorCell outperforms the ConcatCell by an increasing margin over time.",4.2 Results,[0],[0]
"In the long run, we expect that the system will have seen many queries from most users.",4.2 Results,[0],[0]
"Therefore, the right side of Figure 1, where the relative gain of FactorCell is up to 2% better than that of the ConcatCell, is more indicative of the potential of these models for active users.",4.2 Results,[0],[0]
"Since the data was collected over a limited time frame and half of all users have fifteen or fewer queries, the results in Table 2 do not reflect the full benefit of personalization.
",4.2 Results,[0],[0]
Figure 2 shows the MRR for different prefix and query lengths.,4.2 Results,[0],[0]
We find that longer prefixes help the model make longer completions and (more obviously) shorter completions have higher MRR.,4.2 Results,[0],[0]
"Comparing the personalized model against the unpersonalized baseline, we see that the biggest gains are for short queries and prefixes of length one or two.
",4.2 Results,[0],[0]
We found that one reason why the FactorCell outperforms the ConcatCell is that it is able to pick up sooner on the repetitive search behaviors that some users have.,4.2 Results,[0],[0]
This commonly happens for navigational queries where someone searches for the name of their favorite website once or more per day.,4.2 Results,[0],[0]
At the extreme tail there are users who search for nothing but free online poker.,4.2 Results,[0],[0]
"Both models do well on these highly predictable users but the FactorCell is generally a bit quicker to adapt.
",4.2 Results,[0],[0]
We conducted case studies to better understand what information is represented in the user embeddings and what makes the FactorCell different from the ConcatCell.,4.2 Results,[0],[0]
From a cold start user embedding we ran two queries and allowed the model to update the user embedding.,4.2 Results,[0],[0]
"Then, we ranked
the most frequent 1,500 queries based on the ratio of their likelihood from before and after updating the user embeddings.
",4.2 Results,[0],[0]
"Tables 3 and 4 show the queries with the highest relative likelihood of the adapted vs. unadapted models after two related search queries: “high school softball” and “math homework help” for Table 3, and “Prada handbags” and “Versace eyewear” for Table 4.",4.2 Results,[0],[0]
"In both cases, the FactorCell model examples are more semantically coherent than the ConcatCell examples.",4.2 Results,[0],[0]
"In the first case, the FactorCell model identifies queries that a high school student might make, including entertainment sources and a celebrity entertainer popular with that demographic.",4.2 Results,[0],[0]
"In the second case, the FactorCell model chooses retailers that carry woman’s apparel and those that sell home goods.",4.2 Results,[0],[0]
"While these companies’ brands are not as luxurious as Prada or Versace, most of the top luxury brand names do not appear in the top 1,500 queries and our model may not be capable of being that specific.",4.2 Results,[0],[0]
There is no obvious semantic connection between the highest likelihood ratio phrases for the ConcatCell; it seems to be focusing more on orthography than semantics (e.g. “home” in the first example)..,4.2 Results,[0],[0]
Not shown are the queries which experienced the greatest decrease in likelihood.,4.2 Results,[0],[0]
"For the “high school” case, these included searches for travel agencies and airline tickets— websites not targeted towards the high school age demographic.",4.2 Results,[0],[0]
"While the standard implementation of MPC can not handle unseen prefixes, there are variants which do have that ability.",5 Related Work,[0],[0]
"Park and Chiba (2017) find that the neural LM outperforms MPC even when MPC has been augmented with the approach from Mitra and Craswell (2015) for handling rare
prefixes.",5 Related Work,[0],[0]
"There has also been work on personalizing MPC (Shokouhi, 2013; Cai et al., 2014).",5 Related Work,[0],[0]
We did not compare against these specific models because our goal was to show how personalization can improve the already-proven generative neural model approach.,5 Related Work,[0],[0]
"RNN’s have also previously been used for the related task of next query suggestion (Sordoni et al., 2015).
",5 Related Work,[0],[0]
Our results are not directly comparable to Park and Chiba (2017) or Mitra and Craswell (2015) due to differences in the partitioning of the data and the method for selecting random prefixes.,5 Related Work,[0],[0]
Prior work partitions the data by time instead of by user.,5 Related Work,[0],[0]
"Splitting by users is necessary in order to properly test personalization over longer time ranges.
",5 Related Work,[0],[0]
Wang et al. (2018) show how spelling correction can be integrated into an RNN language model query auto-completion system and how the completions can be generated in real time using a GPU.,5 Related Work,[0],[0]
"Our method of updating the model during evaluation resembles work on dynamic evaluation for language modeling (Krause et al., 2017), but differs in that only the user embeddings (latent demographic factors) are updated.",5 Related Work,[0],[0]
Our experiments show that the LSTM model can be improved using personalization.,6 Conclusion and Future Work,[0],[0]
The method of adapting the recurrent layer clearly matters and we obtained an advantage by using the FactorCell model.,6 Conclusion and Future Work,[0],[0]
The reason the FactorCell does better is in part attributable to having two to three times as many parameters in the recurrent layer as either the ConcatCell or the unadapted models.,6 Conclusion and Future Work,[0],[0]
"By design, the adapted weight matrix W′ only needs to be computed at most once per query and is reused many thousands of times during beam search.",6 Conclusion and Future Work,[0],[0]
"As a result, for a given latency budget, the FactorCell
model outperforms the Mikolov and Zweig (2012) model for LSTM adaptation.
",6 Conclusion and Future Work,[0],[0]
"The cost for updating the user embeddings is similar to the cost of the forward pass and depends on the size of the user embedding, hidden state size, FactorCell rank, and query length.",6 Conclusion and Future Work,[0],[0]
"In most cases there will be time between queries for updates, but updates can be less frequent to reduce computational costs.
",6 Conclusion and Future Work,[0],[0]
We also showed that language model personalization can be effective even on users who are not seen during training.,6 Conclusion and Future Work,[0],[0]
The benefits of personalization are immediate and increase over time as the system continues to leverage the incoming data to build better user representations.,6 Conclusion and Future Work,[0],[0]
The approach can easily be extended to include time as an additional conditioning factor.,6 Conclusion and Future Work,[0],[0]
We leave the question of whether the results can be improved by combining the language model with MPC for future work.,6 Conclusion and Future Work,[0],[0]
Query auto-completion is a search engine feature whereby the system suggests completed queries as the user types.,abstractText,[0],[0]
"Recently, the use of a recurrent neural network language model was suggested as a method of generating query completions.",abstractText,[0],[0]
We show how an adaptable language model can be used to generate personalized completions and how the model can use online updating to make predictions for users not seen during training.,abstractText,[0],[0]
The personalized predictions are significantly better than a baseline that uses no user information.,abstractText,[0],[0]
Personalized Language Model for Query Auto-Completion,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2019–2025, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Technologies are increasingly personalized, accommodating their behavior for each user.",1 Introduction,[0],[0]
Such personalization is done through user modeling where the goal is to “get to know” the user.,1 Introduction,[0],[0]
"To that end, personalization is based on users’ attributes, such as demographics (gender, age etc.), personalities, and preferences.",1 Introduction,[0],[0]
"For example, in Information Retrieval, results are customized according to the user’s information and search history (Speretta and Gauch, 2005), performance of Automatic Speech Recognition substantially improves when adapted to a specific speaker (Neumeyer et al., 1995), and Targeted Advertising makes use of the user’s location and prior purchases (Kölmel and Alexakis, 2002).
",1 Introduction,[0],[0]
Personalization in machine translation has a somewhat different nature.,1 Introduction,[0],[0]
"Providers of MT tools and services offer means to “customize” or “personalize” the translation engine for each client, mostly through domain adaptation techniques, and a great deal of effort is made to make the human-involved translation process more efficient (see Section 2.2).",1 Introduction,[0],[0]
"Most of the focus, though, goes to customization for companies or professional translators.",1 Introduction,[0],[0]
"We argue that Personalized Machine Translation (PMT below) should and can take the next step and directly address individual end-users.
∗This work was done while the first author was at Xerox Research Centre Europe.
",1 Introduction,[0],[0]
The difficulty to objectively determine whether one (automatic) translation is better than another has been repeatedly revealed in the MT literature.,1 Introduction,[0],[0]
"Our conjecture is that one reason is individual preferences, to which we refer as Translational Preferences (TP).",1 Introduction,[0],[0]
"TP come into play both when the alternative translations are all correct, and when each of them is wrong in a different way.",1 Introduction,[0],[0]
"In the former case, a preference may be a stylistic choice, and in the latter, a matter of comprehension or a selection of the least intolerable error in one’s opinion.",1 Introduction,[0],[0]
"For instance, one user may prefer shorter sentences than others; she may favor a more formal style, while another would rather have it casual.",1 Introduction,[0],[0]
A user could be fine with some reordering errors but be more picky concerning punctuations.,1 Introduction,[0],[0]
"One user will not be bothered if some words are left untranslated (perhaps because the source language belongs to the same language family as the target language that he speaks), while another will find it utterly displeasing.",1 Introduction,[0],[0]
"Such differences may be the result of the type of translation system being employed (e.g. syntax- vs. phrased-based), the specific training data or many other factors.",1 Introduction,[0],[0]
"On the user’s side, a preference may be attributed, for example, to her mother tongue, her age or her personality.
",1 Introduction,[0],[0]
"Two aspects of end-user PMT may be considered: (i) Personalized translation of texts written by a specific user, and (ii) PMT to provide better translations for a specific reader.",1 Introduction,[0],[0]
"In this work we address the second task, aiming to identify translations each user is more likely to prefer.1 Specifically, we consider a setting where at least two MT systems are available, and the goal is to predict which of the translation systems the user would choose, assuming we have no knowledge about her preference between them.",1 Introduction,[0],[0]
"Benchmarking the systems in advance with respect to a reference set, or estimating the quality of the translations (Specia et al., 2009) are viable alternatives for translation selection; these, however, are not personalized to the target user.",1 Introduction,[0],[0]
"Instead, we employ a user-user Collaborative Filtering approach, common in Recommender Systems, which we map to the TP prediction task.
",1 Introduction,[0],[0]
"We assess this approach using a collection of user rankings of MT systems from a shared translation task
1In (Mirkin et al., 2015)",1 Introduction,[0],[0]
"we investigate the first task, assessing whether the author’s demographic and personality traits are preserved over machine translation.
2019
(see Section 3).",1 Introduction,[0],[0]
"Our results show that the personalized method modestly, but consistently, outperforms several other approaches that rank the systems in general, disregarding the specific user.",1 Introduction,[0],[0]
We consider this as an indication that user feedback can be employed towards a more personalized approach to machine translation.,1 Introduction,[0],[0]
"Collaborative filtering (CF) is a common approach employed by recommender systems for suggesting to users items, such as books or movies.",2.1 Collaborative filtering,[0],[0]
"A recommender system may simply suggest to all users the most popular items; often, however, the recommendations are personalized for each individual user to fit her taste or preferences.",2.1 Collaborative filtering,[0],[0]
User-user CF relies on community preferences.,2.1 Collaborative filtering,[0],[0]
"The idea is to recommend to the user items that are liked by users similar to her, as manifested, for example, by high rating.",2.1 Collaborative filtering,[0],[0]
Similar users are those that agree with the current user on previously-rated items.,2.1 Collaborative filtering,[0],[0]
"In k-nearest-neighbors CF, a user is typically represented by a vector of her preferences, where each entry of the vector is, e.g., a rating of a movie.",2.1 Collaborative filtering,[0],[0]
k similar users are then identified by measuring the similarity between the users’ vectors.,2.1 Collaborative filtering,[0],[0]
"Cosine similarity is a popular function for that purpose, and we also use it in our work (Resnick et al., 1994; Sarwar et al., 2001; Ricci et al., 2011).",2.1 Collaborative filtering,[0],[0]
"An alternative to cosine, Pearson’s correlation coefficient (Pearson, 1895), allows addressing different rating patterns across users.",2.1 Collaborative filtering,[0],[0]
"In comparison to cosine, here vector entries are normalized with respect to the user’s average rating.",2.1 Collaborative filtering,[0],[0]
"In our case, such normalization is not very meaningful since the entries of the users vectors represent comparisons rather than absolute ratings, as will be made clear in Section 4.",2.1 Collaborative filtering,[0],[0]
"Nevertheless, we have experimented with Pearson correlation as well, and found no advantage in using it instead of cosine.",2.1 Collaborative filtering,[0],[0]
"Various means of customization and personalization are available, in both academic and commercial MT.","2.2 Customization, personalization and adaptation in MT",[0],[0]
"Many of them target the company, rather than the individual user, and much of the effort is invested in designing tools for professional translators, aiming to improve their productivity, through intelligent Computer Aided Translation (CAT).
","2.2 Customization, personalization and adaptation in MT",[0],[0]
"Domain adaptation methods are commonly used to adapt to the topic, the genre and even the style of the translated material.","2.2 Customization, personalization and adaptation in MT",[0],[0]
"Using the company’s own corpora is one of the simplest techniques to do so, but many more approaches have been proposed, including dataselection (Axelrod et al., 2011; Gascó","2.2 Customization, personalization and adaptation in MT",[0],[0]
"et al., 2012; Mirkin and Besacier, 2014), mixture models (Foster and Kuhn, 2007) and table fill-up (Bisazza et al., 2011).","2.2 Customization, personalization and adaptation in MT",[0],[0]
"Clients can utilize their own glossaries (Federico et al., 2014), corpora (parallel or monolingual) and translation memories (TM), either shared or private ones
(Caskey and Maskey, 2014; Federico et al., 2014).","2.2 Customization, personalization and adaptation in MT",[0],[0]
"Through Adaptive and Interactive MT (Nepveu et al., 2004), the system learns from the translator’s edits, in order to avoid repeating errors that have already been corrected.","2.2 Customization, personalization and adaptation in MT",[0],[0]
"Post-editions can continuously be added to the translator’s TM or be used as additional training material, for tighter adaptation to the domain of interest, through batch or incremental training.","2.2 Customization, personalization and adaptation in MT",[0],[0]
Many tasks that require annotation by humans are affected by the annotator and not only by the item being judged.,2.3 User preferences in MT,[0],[0]
"Metrics for inter-rater reliability or interannotator agreement, such as Cohen’s Kappa (Cohen, 1960), help measuring the extent to which annotators disagree.",2.3 User preferences in MT,[0],[0]
"Disagreement may be due to untrained or inattentive annotators, a result of a task that is not well defined, or when there is no obvious “truth”.",2.3 User preferences in MT,[0],[0]
Such is the case with the evaluation of translation quality – it is not always straightforward to tell whether one translation is better than another.,2.3 User preferences in MT,[0],[0]
A single sentence can be translated in multiple correct ways.,2.3 User preferences in MT,[0],[0]
The decision becomes even harder when the translations are automatically produced and are imperfect: Is one error worse than another?,2.3 User preferences in MT,[0],[0]
The answer is in the eye of the beholder.,2.3 User preferences in MT,[0],[0]
"MT papers regularly report rather low Kappa levels, even when measured on simpler tasks, such as short segments (Macháček and Bojar, 2015).
",2.3 User preferences in MT,[0],[0]
Turchi et al. (2013) refer to the issue of “subjectivity” of human annotators.,2.3 User preferences in MT,[0],[0]
"They address the task of binary classification of “good” vs. “bad” translations, and show that relying on human annotation for training a binary quality estimator is less effective than using automatically-generated labels.",2.3 User preferences in MT,[0],[0]
This subjectivity is exactly what we are after.,2.3 User preferences in MT,[0],[0]
"We treat it as a preference, trying to identify the systems or specific translations which the user subjectively prefers.
Kichhoff et al. (2012) analyze user preferences with respect to MT errors.",2.3 User preferences in MT,[0],[0]
"They show that some types, e.g. word order errors, are the most dis-preferred by users, and that this is a more important factor than the number of errors.",2.3 User preferences in MT,[0],[0]
"While very relevant for our research, their analysis is aggregated over all users participating in the study, and is not focusing on individuals’ preferences.",2.3 User preferences in MT,[0],[0]
"In this work we used the data provided for the MT Shared Task in the 2013 Workshop on Statistical Machine Translation (WMT) (Bojar et al., 2013).2",3 Data,[0],[0]
"This data was of a particularly large scale, with crowdsourced human judges, either volunteer researchers or paid Amazon Turkers.",3 Data,[0],[0]
"For each source sentence, a judge was presented with the source sentence itself, a reference translation, and the outputs of five machine translation systems.",3 Data,[0],[0]
"The five systems were randomly selected from the pool of participating systems,
2http://www.statmt.org/wmt13/ translation-task.html
and were anonymized and randomly-ordered when presented to the judge.",3 Data,[0],[0]
"The judge had to rank the translations, with ties allowed (i.e. two system can receive the same ranking).",3 Data,[0],[0]
"Hence, each annotation point provided with 10 pairwise rankings between systems.",3 Data,[0],[0]
"Translations of 10 language pairs were assessed, with 11 to 19 systems for each pair.",3 Data,[0],[0]
"In total, over 900K non-tied pairwise rankings were collected.",3 Data,[0],[0]
"The Turkers’ annotation included a control task for quality assurance, rejecting Turkers failing more than 50% of the control points.",3 Data,[0],[0]
The inter-annotator score showed on average a fair to moderate level of agreement.,3 Data,[0],[0]
"Our method, denoted CTP (Collaborative Translational Preferences), is based on a k-nearest-neighbors approach for user-user CF.",4 Translational preferences with collaborative filtering,[0],[0]
"That is, we predict the translational preferences of a user based on those of similar users.",4 Translational preferences with collaborative filtering,[0],[0]
"In our setting, a user preference is the choice between two translation systems – which system’s translations does the user prefer.",4 Translational preferences with collaborative filtering,[0],[0]
"Given two systems (or models of the same system) we wish to predict which one the user would prefer, without assuming the user has ever expressed her preference between these two specific systems.",4 Translational preferences with collaborative filtering,[0],[0]
"It is important to emphasize that the method presented here considers the users’ overall preferences of systems, and does not regard the specific sentence that is being translated.",4 Translational preferences with collaborative filtering,[0],[0]
In future work we intend to make use of this information as well.,4 Translational preferences with collaborative filtering,[0],[0]
"As mentioned in Section 3, each annotation consists of a ranking of five systems.",4.1 Representation,[0],[0]
"From that, we extract pairwise rankings for every pair of systems that were ranked for a given language pair.",4.1 Representation,[0],[0]
"For each user u ∈ U (where U are all users who annotated the language pair), we create a user-preference vector, pu, that contains an entry for each pair of translation systems.",4.1 Representation,[0],[0]
"Denoting the set of systems with S, we have |S|·(|S|−1)2 system pairs.",4.1 Representation,[0],[0]
"E.g., for Czech-English, with 11 participating systems, the user vector size is 55.",4.1 Representation,[0],[0]
"Each entry (i, j) of the vector is assigned the following value:
pu (i,j) =
w",4.1 Representation,[0],[0]
"(i,j) u − l(i,j)u w",4.1 Representation,[0],[0]
"(i,j) u +",4.1 Representation,[0],[0]
"l (i,j) u
(1)
where w(i,j)u and l (i,j) u are the number of wins and loses of system si vs. system sj as judged by user u.3
With this representation, a user vector contains values between −1 (if si always lost to sj) and 1 (if si always won).",4.1 Representation,[0],[0]
"If the user always ranked the two systems identically, the value is 0, and if she has never evaluated the pair, the entry is regarded as a missing value (NA).",4.1 Representation,[0],[0]
"Altogether, we have a matrix of users by system pairs, as depicted in Figure 1.
",4.1 Representation,[0],[0]
3We have also considered including ties in the denominator of the equation; discarding them was found superior.,4.1 Representation,[0],[0]
"Given a user preference to predict for a pair of systems (si, sj), we compute the similarity between pu and each one of pu′ for all other u′ ∈ U .",4.2 Finding similar users,[0],[0]
In our experiments we used cosine as the similarity measure.,4.2 Finding similar users,[0],[0]
The k most-similar-users (MSU ) are then selected.,4.2 Finding similar users,[0],[0]
"To be included in MSU (u), we require that u and u′ have judged at least 2 common system pairs.",4.2 Finding similar users,[0],[0]
"Given the similarity scores, to predict the user’s preference for the target system pair, we compute a weighted average of the predictions of the users in MSU (u).
",4.3 Preference prediction,[0],[0]
We include in the average only users with similarity scores above a certain positive threshold (0.05).,4.3 Preference prediction,[0],[0]
We then require that a minimum number of users meet the above criteria of common annotations and minimum similarity (we used 5).,4.3 Preference prediction,[0],[0]
"If not enough such similar users are found, we turn to a fallback, where we use the non-weighted average preference across all users (AVPF presented in Section 5).4 The prediction is then the sign of the weighted average.",4.3 Preference prediction,[0],[0]
"A positive value means si is the preferred system; a negative one means it is sj , and a zero is a draw.",4.3 Preference prediction,[0],[0]
"In our evaluation we compare this prediction to the sign of the actual preference of the user, pu(i,j).",4.3 Preference prediction,[0],[0]
"Formally, CTP computes the following prediction function f for a given user u and a system pair (si, sj):
fCTP(u)(i,j) = sign( ∑ u′ pu′",4.3 Preference prediction,[0],[0]
"(i,j) · sim(u, u′)∑
u′ sim(u, u′) )",4.3 Preference prediction,[0],[0]
"(2)
where u′ ∈ MSU (u) are the most similar users (the nearest neighbors) of u; pu′ (i,j) are the preferences of user u′ for (si, sj) and sim(u, u′) is the similarity score between the two users.5",4.3 Preference prediction,[0],[0]
"In our experiments we try to predict which one of two translation systems would be preferred by a given user.
4The fallback was used 0.1% of the times.",5.1 Evaluation methodology,[0],[0]
5The denominator is not required as long as we predict only the sign since all used similarity scores are positive.,5.1 Evaluation methodology,[0],[0]
"We keep it in order to obtain a normalized score that can be used for other decisions, e.g. ranking multiple systems.
",5.1 Evaluation methodology,[0],[0]
"We evaluate our method, as well as several other prediction functions, when compared with the user’s pairwise system preference according to the annotation – pu
(i,j), shown in Equation 1.",5.1 Evaluation methodology,[0],[0]
"For each user this is an aggregated figure over all her pairwise rankings for the pair, determining the preferred system as the one chosen by the user (i.e. ranked higher) more times.
",5.1 Evaluation methodology,[0],[0]
We conduct a leave-one-out experiment.,5.1 Evaluation methodology,[0],[0]
"For each language pair, we iterate over all non-NA entries in the user-preferences matrix, remove the entry and try to predict it.",5.1 Evaluation methodology,[0],[0]
"User similarity scores are re-computed for each evaluation point, to ensure they do not consider the target pair.",5.1 Evaluation methodology,[0],[0]
"The “gold” preference is positive when the user prefers si, negative when she prefers sj and 0 when she has no preference between them.",5.1 Evaluation methodology,[0],[0]
"Hence, each of the assessed methods is measured by the accuracy of predicting the sign of the preference.",5.1 Evaluation methodology,[0],[0]
"We compare CTP to the following prediction methods:
Always i (ALI)",5.2 Non-personalized methods,[0],[0]
This is a naı̈ve baseline showing the score when always predicting that system i wins.,5.2 Non-personalized methods,[0],[0]
"Note that the baseline is not simply 50% due to ties.
",5.2 Non-personalized methods,[0],[0]
Average rank (RANK),5.2 Non-personalized methods,[0],[0]
"Here, two systems are compared by the average of their rankings across all annotations (r ∈ {1, 2, 3, 4, 5}):
fRANK(u)(i,j) = sign(rj − ri) (3) rj and ri are the average ranks of sj and si respectively.",5.2 Non-personalized methods,[0],[0]
"Since a smaller value of r corresponds to a higher rank, we subtract the rank of si from sj and not the other way around.",5.2 Non-personalized methods,[0],[0]
"This way, if for instance, si is ranked on averaged higher than sj , the prediction would be positive, as desired.
",5.2 Non-personalized methods,[0],[0]
Expected (EXPT),5.2 Non-personalized methods,[0],[0]
"This metric, proposed by Koehn (2012) and used by Bojar et al. (2013) in order to rank the participating systems in the WMT benchmark, compares the expected wins of the two systems.",5.2 Non-personalized methods,[0],[0]
"Its intuition is explained as follows: “If the system is compared against a randomly picked opposing system, on a randomly picked sentence, by a randomly picked judge, what is the probability that its translation is ranked higher?”",5.2 Non-personalized methods,[0],[0]
"The expected wins of si, e(si), is the probability of si to win when compared to another system, estimated as the total number of wins of si relative to the total number of comparisons involving it, excluding ties, and normalized by the total number of systems excluding si, |{sk}|:
e(i)",5.2 Non-personalized methods,[0],[0]
"= 1 |{sk}| ∑ k 6=i
w(i,k)
w(i,k) + l(i,k) (4)
where w(i,k) and l(i,k) are summed over all users.",5.2 Non-personalized methods,[0],[0]
"The preference prediction is therefore:
fEXPT(u)(i,j) = sign(e(i)− e(j)) (5)
RANK and EXPT predict preferences based on a system’s performance in general, when compared to all other systems.",5.2 Non-personalized methods,[0],[0]
"We propose an additional prediction function for comparison which uses only the information concerning the system pair under consideration.
",5.2 Non-personalized methods,[0],[0]
Average user preference (AVPF),5.2 Non-personalized methods,[0],[0]
This method takes into account only the specific system pair and averages the user preferences for the pair.,5.2 Non-personalized methods,[0],[0]
"Formally:
fAVPF(u)(i,j) = sign( ∑ u′ p (i,j) u′
|{u′}| ) (6)
where u′ 6= u, and {u′} are all users except u.",5.2 Non-personalized methods,[0],[0]
"This method can be viewed as a non-personalized version of CTP, with two differences:
(1) It considers all users, and not only similar ones.",5.2 Non-personalized methods,[0],[0]
"(2) It does not weight the preferences of the other
users by their similarity to the target user.",5.2 Non-personalized methods,[0],[0]
Table 1 shows the results of an experiment comparing the performance of the various methods in terms of prediction accuracy.,5.3 Results,[0],[0]
"Figure 2 shows the micro-average scores, when giving each of the 97,412 test points an equal weight in the average.",5.3 Results,[0],[0]
"CTP outperforms all others for 9 out of 10 language pairs, and in the overall microaveraged results.",5.3 Results,[0],[0]
"The difference between CTP and each of the other metrics was found statistically significance with p < 5 · 10−6 at worse, as measured with a paired Wilcoxon signed rank test (Wilcoxon, 1945) on the predictions of the two methods.",5.3 Results,[0],[0]
"The significance test captures in this case the fact that the methods disagreed in many more cases than is visible by the score difference.
",5.3 Results,[0],[0]
"Our method was found superior to all others also when computing macro-average, taking the average of the scores of each language pair, as well as when the ties are included in the computation of pu.
",5.3 Results,[0],[0]
The parameters with which the above results were obtained are found within the method’s description in Section 4.,5.3 Results,[0],[0]
"Yet, in our experiments, CTP turned out to be rather insensitive to their values.",5.3 Results,[0],[0]
In this experiment we used a global set of parameters and did not tune them for each language pair separately.,5.3 Results,[0],[0]
It is reasonable to assume that such tuning would improve results.,5.3 Results,[0],[0]
"For instance, choosing k, the number of users to include in the average, depends on the total number of users.",5.3 Results,[0],[0]
"E.g., for en-es, where there are only 57 users in total, reducing k’s value from 50 to 25, improves results of CTP from 62.6% to 63.2%, higher than all other methods (whose scores are not affected).
",5.3 Results,[0],[0]
"Specifically in comparison to AVPF, weighting by the similarity scores was found to be a more significant factor than selecting a small subset of the users.",5.3 Results,[0],[0]
"This may not come as a surprise, since less similar users that are added to MSU (u) have a smaller impact on the final decision since their weight in the average is smaller.
",5.3 Results,[0],[0]
"One weakness of CTP, as well as of other methods, is that it poorly predict ties.",5.3 Results,[0],[0]
"In the above experiment, approximately 13.5% of the preferences were 0, none of them was correctly identified.",5.3 Results,[0],[0]
Our analysis showed that numerical accuracy is not the main cause; setting any prediction that is smaller than some values of |ε| to 0 was not found helpful.,5.3 Results,[0],[0]
"Arguably, ties need not be predicted, since if the user has no preference between two systems, any choice is just as good.",5.3 Results,[0],[0]
"Still, we believe that better ties prediction could lead to general improvement of our method and we wish to address it in future work.",5.3 Results,[0],[0]
We addressed the task of predicting user preference with respect to MT output via a collaborative filtering approach whose prediction is based on preferences of similar users.,6 Discussion,[0],[0]
This method predicts TP better than a set of non-personalized methods.,6 Discussion,[0],[0]
"The gain is modest in absolute numbers, but the results are highly statistically significant and stable over parameter values.
",6 Discussion,[0],[0]
We consider this work as a step towards more personalized MT.,6 Discussion,[0],[0]
This line of research can be extended in multiple ways.,6 Discussion,[0],[0]
"First and foremost, as mentioned, we did not consider the actual content of the sentences, but rather identified a general preference for one system over another.",6 Discussion,[0],[0]
"It is plausible, however, that one system is better – from the user’s perspective – at translating one type of text, while another is preferred for other texts.",6 Discussion,[0],[0]
"Taking the actual texts into account seems therefore es-
sential.",6 Discussion,[0],[0]
Content-based methods for recommender systems may be useful for this purpose.,6 Discussion,[0],[0]
"Another factor that may be affecting preferences is translation quality: when compared translations are all poor, preferences play a less significant role.",6 Discussion,[0],[0]
"Hence, it may be informative to assess TP prediction separately across different levels of translation quality.
",6 Discussion,[0],[0]
Large parallel corpora are typically required for training reasonable statistical translation models.,6 Discussion,[0],[0]
"Yet, parallel corpora, and even more so in-domain ones, are hard to gather.",6 Discussion,[0],[0]
"It is virtually impossible to find a user-specific parallel corpus, and methods for monolingual domain adaptation are easier to envisage if one wishes to address author-aware PMT (the first PMT task mentioned in Section 1).",6 Discussion,[0],[0]
"Collecting user feedback is another challenge, especially since most endusers do not speak the source language.",6 Discussion,[0],[0]
"For that and other reasons, it currently seems more feasible to collect preference information from professional translators, explicitly or implicitly.",6 Discussion,[0],[0]
"Yet, in this research we aim at end-users rather than translators whose preferences are often driven by the ease of correction more than anything else.",6 Discussion,[0],[0]
"We believe that one way to tackle this issue is to exploit other kinds of feedback, from which we can infer user preferences and similarity.",6 Discussion,[0],[0]
Online MT providers are recently collecting end-user feedback for their proposed translations which may be useful for TP prediction.,6 Discussion,[0],[0]
"For instance, in early 2015 Facebook introduced a feature letting users rate (Bing) translations, and Google Translate asks for suggested improvements.",6 Discussion,[0],[0]
We are hopeful that such data becomes publicly available.,6 Discussion,[0],[0]
"Nevertheless, it remains unlikely to obtain feedback from each and every user.",6 Discussion,[0],[0]
"A potential direction for both corpora and feedback collection is personalizing models and identifying preferences for groups of users based on socio-demographic traits, such as gender, age or mother tongue, or based on (e.g. Big 5) personality traits.",6 Discussion,[0],[0]
These can even be inferred by automatically analyzing user texts.,6 Discussion,[0],[0]
We wish to thank Hervé Déjean and the EMNLP reviewers for their valuable feedback on this work.,Acknowledgments,[0],[0]
"Machine Translation (MT) has advanced in recent years to produce better translations for clients’ specific domains, and sophisticated tools allow professional translators to obtain translations according to their prior edits.",abstractText,[0],[0]
We suggest that MT should be further personalized to the end-user level – the receiver or the author of the text – as done in other applications.,abstractText,[0],[0]
"As a step in that direction, we propose a method based on a recommender systems approach where the user’s preferred translation is predicted based on preferences of similar users.",abstractText,[0],[0]
"In our experiments, this method outperforms a set of non-personalized methods, suggesting that user preference information can be employed to provide better-suited translations for each user.",abstractText,[0],[0]
Personalized Machine Translation: Predicting Translational Preferences,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 208–215 New Orleans, Louisiana, June 1 - 6, 2018. c©2017 Association for Computational Linguistics",text,[0],[0]
"Predicting the next characters or words following a prefix has had multiple uses from helping handicapped people (Swiffin et al., 1987) to, more recently, helping search engine users (Cai et al., 2016).",1 Introduction,[0],[0]
"In practice, most search engines today use query auto completion (QAC) systems, consisting of suggesting queries as users type in the search box (Fiorini et al., 2017).",1 Introduction,[0],[0]
"The task suffers from high dimensionality, because the number of possible solutions increases as the length of the target query increases.",1 Introduction,[0],[0]
"Historically, the query prediction task has been addressed by relying on query logs, particularly the popularity of past queries (BarYossef and Kraus, 2011; Lu et al., 2009).",1 Introduction,[0],[0]
"The idea is to rely on the wisdom of the crowd, as popular
queries matching a typed prefix are more likely to be the user’s intent.
",1 Introduction,[0],[0]
"This traditional approach is usually referred to as MostPopularCompletion (MPC)(Bar-Yossef and Kraus, 2011).",1 Introduction,[0],[0]
"However, the performance of MPC is skewed: it is very high for popular queries and very low for rare queries.",1 Introduction,[0],[0]
"At the extreme, MPC simply cannot predict a query it has never seen.",1 Introduction,[0],[0]
"This becomes a bigger problem in academic search (Lankinen et al., 2016), where systems are typically less used, with a wider range of possible queries.",1 Introduction,[0],[0]
"Recent advances in deep learning, particularly in semantic modeling (Mitra and Craswell, 2015) and neural language modeling (Park and Chiba, 2017) showed promising results for predicting rare queries.",1 Introduction,[0],[0]
"In this work, we propose to improve the state-of-the-art approaches in neural QAC by integrating personalization and time sensitivity information as well as addressing current MPC limitations by diversifying the suggestions, thus approaching a production-ready architecture.",1 Introduction,[0],[0]
"While QAC has been well studied, the field has recently started to shift towards deep learningbased models, which can be categorized into two main classes: semantic models (using Convolutional Neural Nets, or CNNs) (Mitra and Craswell, 2015) and language models (using Recurrent Neural Nets, or RNNs) (Park and Chiba, 2017).",2.1 Neural query auto completion,[0],[0]
"Both approaches are frequently used in natural language processing in general (Kim et al., 2016) and tend to capture different features.",2.1 Neural query auto completion,[0],[0]
"In this work, we focus on RNNs as they provide a flexible solution to generate text, even when it is not previously seen in the training data.
",2.1 Neural query auto completion,[0],[0]
"Yet, recent work in this field (Park and Chiba, 2017) suffers from some limitations.",2.1 Neural query auto completion,[0],[0]
"Most importantly, the probability estimates for full queries
208
are directly correlated to the length of the suggestions, consequently favoring shorter queries in some cases and hampering some predictions (Park and Chiba, 2017).",2.1 Neural query auto completion,[0],[0]
"By appending these results to MPC’s and re-ranking the list with LambdaMART (Burges, 2010) in another step as suggested in previous work (Mitra and Craswell, 2015), they achieve state-of-the-art performance in neural query auto completion at the cost of a higher complexity and more computation time.",2.1 Neural query auto completion,[0],[0]
"Still, these preliminary approaches have yet to integrate standards in QAC, e.g. query personalization (Koutrika and Ioannidis, 2005; Margaris et al., 2018) and time sensitivity (Cai et al., 2014).",2.2 Context information,[0],[0]
This integration has to differ from traditional approaches by taking full advantage of neural language modeling.,2.2 Context information,[0],[0]
"For example, neural language models could be refined to capture interests of some users as well as their actual language or query formulation.",2.2 Context information,[0],[0]
"The same can apply to timesensitivity, where the probability of queries might change over time (e.g. for queries such as “tv guide”, or “weather”).",2.2 Context information,[0],[0]
"Furthermore, the feasibility of these approaches in real-world settings has not been demonstrated, even more so on specialized domains.
",2.2 Context information,[0],[0]
"By addressing these issues, we make the following contributions in this work compared to the previous approaches:
• We propose a more straightforward architecture with improved scalability;
• Our method integrates user information when available as well as time-sensitivity;
• We propose to use a balanced beam search for ensuring diversity;
• We test on a second dataset and compare the generalizability of different methods in a specialized domain;
•",2.2 Context information,[0],[0]
"Our method achieves stronger performance than the state of the art on both datasets.
",2.2 Context information,[0],[0]
"Finally, our source code is made available in a public repository1.",2.2 Context information,[0],[0]
"This allows complete reproducibility of our results and future comparisons.
1https://github.com/ncbi-nlp/NQAC",2.2 Context information,[0],[0]
"The justification of using a neural language model for the task of predicting queries is that it has been proven to perform well to generate text that has never been seen in the training data (Sutskever et al., 2011).",3.1 Personalized neural Language Model,[0],[0]
"Particularly, character-level models work with a finer granularity.",3.1 Personalized neural Language Model,[0],[0]
"That is, if a given prefix has not been seen in the training data (e.g. a novel or incomplete word), the model can use the information shared across similar prefixes to make a prediction nonetheless.
",3.1 Personalized neural Language Model,[0],[0]
Recurrent Neural Network,3.1 Personalized neural Language Model,[0],[0]
The difficulty of predicting queries given a prefix is that the number of candidates explodes as the query becomes longer.,3.1 Personalized neural Language Model,[0],[0]
"RNNs allow to represent each character (or word) of a sequence as a cell state, therefore reducing the dimensionality of the task.",3.1 Personalized neural Language Model,[0],[0]
"However, they also introduce the vanishing gradient problem during backpropagation, preventing them from learning long-term dependencies.",3.1 Personalized neural Language Model,[0],[0]
"Both gated recurrent units (GRU) (Cho et al., 2014) and long-short term memory cells (LSTMs) solve this limitation — albeit with a different approach — and are increasingly used.",3.1 Personalized neural Language Model,[0],[0]
"In preliminary experiments, we tried various forms of RNNs: vanilla RNNs, GRUs and LSTMs.",3.1 Personalized neural Language Model,[0],[0]
"GRUs performed similarly to LSTM with a smaller computational complexity due to fewer parameters to learn as was previously observed (Jozefowicz et al., 2015).
",3.1 Personalized neural Language Model,[0],[0]
Word embedded character-level Neural Language Model,3.1 Personalized neural Language Model,[0],[0]
"The main novelty in (Park and Chiba, 2017) is to combine a character-level neural language model with a word-embedded space character.",3.1 Personalized neural Language Model,[0],[0]
"The incentive is that character-level neural language models benefit from a finer granularity for predictions but they lack the semantic understanding words-level models provide, and vice versa.",3.1 Personalized neural Language Model,[0],[0]
"Therefore, they encode text sequences using one-hot encoding of characters, character embedding and pre-trained word embedding (using word2vec (Mikolov et al., 2013)) of the previous word when a space character is encountered.",3.1 Personalized neural Language Model,[0],[0]
"Our preliminary results showed that the character embedding does not bring much to the learning, so we traded it with the context feature vectors below to save some computation time while enriching the model with additional, diverse information.
",3.1 Personalized neural Language Model,[0],[0]
"User representation We make the assumption that the way a user types a query is a function of their actual language/vocabulary, but also a function of their interests.",3.1 Personalized neural Language Model,[0],[0]
"Therefore, a language model could capture these user characteristics to better predict the query, if we feed the learner with the information.",3.1 Personalized neural Language Model,[0],[0]
"Each query qi is a set of words such that qi = {w1, ..., wn}.",3.1 Personalized neural Language Model,[0],[0]
"U is a column matrix and a user u ∈ U is characterized by the union of words in their k past queries, i.e. Qu = ∪ki=1qi.",3.1 Personalized neural Language Model,[0],[0]
"The objective is to reduce, for each user, the vocabulary used in their queries to a vector of a dimensionality d of choice, or Qu → Rd.",3.1 Personalized neural Language Model,[0],[0]
"We chose d = 30, in order to stay in the same computation order of previous work using character embedding (Park and Chiba, 2017).",3.1 Personalized neural Language Model,[0],[0]
"To this end, we adapted the approach PV-DBOW detailed in (Le and Mikolov, 2014).",3.1 Personalized neural Language Model,[0],[0]
"That is, at each training iteration, a random word wi is sampled from Qu.",3.1 Personalized neural Language Model,[0],[0]
"The model is trained by maximizing the probability of predicting the user u given the word wi, i.e.:
1 |U | ∑
u∈U
∑
wi∈Qu log P (u|wi).",3.1 Personalized neural Language Model,[0],[0]
"(1)
The resulting vectors are stored for each user ID and are used as input for the neural net (NN) (see Architecture section).
",3.1 Personalized neural Language Model,[0],[0]
"Time representation As an example, in the background data (see Section 4.1), the query “tv guide” appears 1,682 times and it is vastly represented in evening and nights.",3.1 Personalized neural Language Model,[0],[0]
"For this reason, we propose to integrate time features in the language model.",3.1 Personalized neural Language Model,[0],[0]
"While there has been more elaborated approaches to model it in the past (Shokouhi and Radinsky, 2012), we instead propose a straightforward encoding and leave the rest of the work to the neural net.",3.1 Personalized neural Language Model,[0],[0]
"For each query, we look at the time it was issued, consisting of hour x , minute y and second z, and we derive the following features:
sin
( 2π(3600x+ 60y + z)
86400
) ,
cos
( 2π(3600x+ 60y + z)
86400
) .
",3.1 Personalized neural Language Model,[0],[0]
"(2)
This encoding has the benefit of belonging to [−1, 1], which is a range comparable to the rest of the features.",3.1 Personalized neural Language Model,[0],[0]
"It is also capable to model cyclic data, which is important particularly around boundaries (e.g. considering a query at 11:55PM
and another at 00:05AM).",3.1 Personalized neural Language Model,[0],[0]
"We proceed the same way to encode weekdays and we end up with four time features.
",3.1 Personalized neural Language Model,[0],[0]
Overall architecture An overview of the architecture is proposed in Figure 1.,3.1 Personalized neural Language Model,[0],[0]
"The input of our neural language model is a concatenation of the vectors defined above, for each character and for each query in the training set.",3.1 Personalized neural Language Model,[0],[0]
"We use zeropadding after the “\n” character to keep the sequence length consistent, and the NN learns to recognize it.",3.1 Personalized neural Language Model,[0],[0]
"We feed this input vector into 2 layers of 1024 GRUs2, each followed by a dropout layer (with a dropout rate of 50%) to prevent overfitting.",3.1 Personalized neural Language Model,[0],[0]
Each GRU cell is activated with ReLu(x) =,3.1 Personalized neural Language Model,[0],[0]
x+ and gradients are clipped to a norm of 0.5 to avoid gradient exploding problems.,3.1 Personalized neural Language Model,[0],[0]
"The output of the second dropout layer is fed to a temporal softmax layer, which allows to make predictions at each state.",3.1 Personalized neural Language Model,[0],[0]
"The softmax function returns the probability P (ci|c1, ..., ci−1) of the character ci given the previous characters of the sequence, which is then used to calculate the loss function by comparing it to the next character in the target query.",3.1 Personalized neural Language Model,[0],[0]
"Instead of using the objective denoted in (Park and Chiba, 2017), we minimize the loss L defined as the average cross entropy of this probability with the reference probability P̂ (ci) across all queries, that is
L =
− 1|Q| ∑
q∈Q
|q|−1∑
i=1
P̂ (ci+1)× log P (ci+1|c1, ..., ci).
",3.1 Personalized neural Language Model,[0],[0]
"(3)
Q is the set of queries in the training dataset, |Q| is the total number of queries in the set and |q| is the number of characters in the query q. Convergence stabilizes around 5-10 epochs for the AOL dataset (depending on the model) and 15-20 epochs for the biomedical specialized dataset (see Section 4.1).",3.1 Personalized neural Language Model,[0],[0]
"The straightforward approach for decoding the most likely output sequence — in this case, a suffix given a prefix — is to use a greedy approach.",3.2 Balanced diverse beam search,[0],[0]
"That is, we feed the prefix into the trained NN and pick the most likely output at every step, until the sequence is complete.",3.2 Balanced diverse beam search,[0],[0]
"This approach has a high
2It was reported that using more cells may not help the prediction while hurting computation (Park and Chiba, 2017).
chance to output a locally optimal sequence and a common alternative is to use a beam search instead.",3.2 Balanced diverse beam search,[0],[0]
"We propose to improve the beam search by adding a greedy heuristic within it, in order to account for the diversity in the results.",3.2 Balanced diverse beam search,[0],[0]
"A similar suggestion has been made in (Vijayakumar et al., 2016), and our proposition differs by rebalancing the probabilities after diversity was introduced.",3.2 Balanced diverse beam search,[0],[0]
"In (Vijayakumar et al., 2016), at every step the most likely prediction is not weighted while all others are, by greedily comparing them.",3.2 Balanced diverse beam search,[0],[0]
This approach effectively always prefers the most likely character over all other alternatives at each step.,3.2 Balanced diverse beam search,[0],[0]
"The first result will thus be the same as the local optimum using a greedy approach, which becomes problematic for QAC where order is critical.",3.2 Balanced diverse beam search,[0],[0]
"By rebalancing the probability of the most likely suggestion with the average diversity weight given to other suggestions, we make sure probabilities stay uniform yet suggestions are diverse.",3.2 Balanced diverse beam search,[0],[0]
We use a normalized Levenshtein distance to assess the diversity.,3.2 Balanced diverse beam search,[0],[0]
"The AOL query logs (Pass et al., 2006) are commonly used to evaluate the quality of QAC systems.",4.1 Dataset,[0],[0]
"We rely on a background dataset for the
NN; training and validation datasets for lambdaMART integrations; and a test dataset for evaluations.",4.1 Dataset,[0],[0]
"Some adaptations are done to the AOL background dataset as in (Park and Chiba, 2017), such as removing the queries appearing less than 3 times or longer that 100 characters.",4.1 Dataset,[0],[0]
"For each query in the training, validation and test datasets, we use all possible prefixes starting after the first word as in (Shokouhi, 2013).",4.1 Dataset,[0],[0]
"We use the sets from (Park and Chiba, 2017) available online, enriched with user and time information provided in the original AOL dataset.",4.1 Dataset,[0],[0]
"In addition, we evaluate the systems on a second real-world dataset from a production search engine in the biomedical domain, PubMed (Fiorini et al., 2017; Lu, 2011; Mohan et al., 2018), that was created in the same manner.",4.1 Dataset,[0],[0]
"The biomedical dataset consists of 8,490,317 queries.",4.1 Dataset,[0],[0]
"The sizes of training, validation and test sets are comparable to those used for the AOL dataset.",4.1 Dataset,[0],[0]
Systems are evaluated using the traditional Mean Reciprocal Rank (MRR) metric.,4.2 Evaluation,[0],[0]
This metric assesses the quality of suggestions by identifying the rank of the real query in the suggestions given one of its prefixes.,4.2 Evaluation,[0],[0]
"We also tested PMRR as introduced in (Park and Chiba, 2017) and observed the same trends in results as MRR, so we do not show them due to space limitation.",4.2 Evaluation,[0],[0]
"Given the set of prefixes
P in the test dataset, MRR is defined as follows:
MRR = 1 |Q| ∑
r∈P
1
rp , (4)
where rp represent the rank of the match.",4.2 Evaluation,[0],[0]
Paired t-tests measure the significance of score variations among systems and are reported in the Results section.,4.2 Evaluation,[0],[0]
We also evaluate prediction time as this is an important parameter for building production systems.,4.2 Evaluation,[0],[0]
"The prediction time is averaged over 10 runs on the test set, on the same hardware for all models.",4.2 Evaluation,[0],[0]
We do not evaluate throughput but rather compare the time required by all approaches to process one prefix.,4.2 Evaluation,[0],[0]
"We implemented the method in (Park and Chiba, 2017) and used their best-performing model as a baseline.",4.3 Systems and setups,[0],[0]
"We also compare our results to the standard MPC (Bar-Yossef and Kraus, 2011).",4.3 Systems and setups,[0],[0]
"For our method, we evaluate several incremental versions, starting with NQAC which follows the architecture detailed above but with the word embeddings and the one-hot encoding of characters only.",4.3 Systems and setups,[0.95364427076727],"['For example, in situated dialogues about programming, we can find all of the objects and extract their attributes using a source code parser.']"
We add the subscript U when the language model is enriched with user vectors and T when it integrates time features.,4.3 Systems and setups,[0],[0]
We append +D to indicate the use of the diverse beam search to predict queries instead of a standard beam search.,4.3 Systems and setups,[0],[0]
"Finally, we also study the impact of adding MPC and LambdaMART (+MPC, +λMART).",4.3 Systems and setups,[0],[0]
A summary of the results is presented in Table 1.,5 Results,[0],[0]
"Interestingly, our simple NQAC model performs similarly to the state-of-the-art on this dataset, called Neural Query Language Model (NQLM), on all queries.",5 Results,[0],[0]
It is significantly less good for seen queries (-5.6%) and significantly better for unseen queries (+4.2%).,5 Results,[0],[0]
"Although GRUs have less expressive power than LSTMs, their smaller number of parameters to train allowed them to better converge than all LSTM models we tested, including that of (Park and Chiba, 2017).",5 Results,[0],[0]
NQAC also benefits from a significantly better scalability (28% faster than NQLM) and thus seems more appropriate for production systems.,5 Results,[0],[0]
"When we enrich the language model with user information, it becomes better for seen queries (+1.9%) while being about as fast.",5 Results,[0],[0]
"Adding time sensitivity does not yield significant improvements on this
dataset overall, but improves significantly the performance for seen queries (+1.7%).",5 Results,[0],[0]
Relying on the diverse beam search significantly hurts the processing time (39% longer) while not providing significantly better performance.,5 Results,[0],[0]
Our integration of MPC differs from previous studies.,5 Results,[0],[0]
"We noticed that for Web search, MPC performs extremely well and is computationally cheap (0.24 seconds).",5 Results,[0],[0]
"On the other hand, all neural QAC systems are better for unseen queries but struggle to stay under a second of processing time.",5 Results,[0],[0]
"Since identifying if a query has been seen or not is done in constant time, we route the query either to MPC or to NQACUT and we note the overall performance as NQACUT+MPC.",5 Results,[0],[0]
This method provides a significant improvement over NQLM (+6.7%) overall while being faster on average.,5 Results,[0],[0]
"Finally, appending NQACUT ’s results to MPC’s and reranking the list with LambdaMART provides the best results on this dataset, but at the expense of greater computational cost (+60%).
",5 Results,[0],[0]
"While NQACUT+MPC appears clearly as the best compromise between performance and quality for the AOL dataset, the landscape changes drastically on the biomedical dataset and the quality drops significantly for all systems.",5 Results,[0],[0]
"This shows the potential difficulties associated with real-world systems, which particularly occur in specialized domains.",5 Results,[0],[0]
"In this case, the drop in performance is mostly due to the fact that biomedical queries are longer and it becomes more difficult for models to predict the entire query accurately only with the first keywords.",5 Results,[0],[0]
"While the generated queries make sense and are relevant candidates, the chance for generative models to predict the exact target query diminishes as the target query is longer because of combinatorial explosion.",5 Results,[0],[0]
"This is even more true when the target queries are diverse as in specialized domains (Islamaj Dogan et al., 2009; Névéol et al., 2011).",5 Results,[0],[0]
"For example, for the prefix “breast cancer”, there are 1169 diverse suffixes in a single day of logs used for training.",5 Results,[0],[0]
"These include “local recurrence”, “nodular prognosis”, “hormone receptor”, “circulating cells”, “family history”, “chromosome 4p16” or “herceptin review”, to cite only a few.",5 Results,[0],[0]
"Hence, while the model predicts plausible queries, it is a lot more difficult to predict the one the user intended.",5 Results,[0],[0]
"The target query length also has an impact on prediction time, as roughly twice the time is needed for Web searches.",5 Results,[0],[0]
"MPC is the exception, however, it per-
forms poorly even on seen queries (0.165).",5 Results,[0],[0]
This observation suggests that more elaborate models are specifically needed for specialized domains.,5 Results,[0],[0]
"On this dataset, NQAC does not perform as well as NQLM",5 Results,[0],[0]
and it seems this time that the higher number of parameters in NQLM is more appropriate for the task.,5 Results,[0],[0]
"Still, user information helps significantly for seen queries (+23%), probably because some users frequently check the same queries to keep up-to-date.",5 Results,[0],[0]
Time sensitivity seems to help significantly unseen queries (+21%) while significantly hurting the quality for seen queries (-47%).,5 Results,[0],[0]
Diversity is significantly helpful on this dataset (+19%) and provides a balance in performance for both seen and unseen queries.,5 Results,[0],[0]
"NQACUT+MPC yields the best overall MRR score for this dataset, and LambdaMART is unable to learn how to rerank the suggestions, thus decreasing the score.",5 Results,[0],[0]
"From these results, we draw several conclusions.",5 Results,[0],[0]
"First, MPC performs very well on seen queries for Web searches and it should be used on them.",5 Results,[0],[0]
"For unseen queries, the NQACUT model we propose achieves a sub-second state-of-the-art performance.",5 Results,[0],[0]
"Second, it is clear that the field of application will affect many of the decisions when designing a QAC system.",5 Results,[0],[0]
"On a specialized domain, the task is more challenging: fast approaches like MPC perform too poorly while more elaborate approaches do not meet production requirements.",5 Results,[0],[0]
"NQACU performs best on seen queries, NQACUT on unseen queries.",5 Results,[0],[0]
"Finally, NQACUT+D provides an equilibrium between the two at a greater computational cost.",5 Results,[0],[0]
Its overall MRR is similar to that of NQACUT+MPC but it is less redundant (see Table 2).,5 Results,[0],[0]
"Particularly, the system seems not to be limited anymore by the higher probability associ-
ated with shorter suggestions (e.g. “www google”, a form of “www google com”), thus bringing more diversity.",5 Results,[0],[0]
This aspect can be more useful for specialized domains where the range of possible queries is broader.,5 Results,[0],[0]
"Finally, we found that a lot more data was needed for the biomedical domain than for general Web search.",5 Results,[0],[0]
"After about a million queries, NQAC suggests meaningful and plausible queries for both datasets.",5 Results,[0],[0]
"However, for the biomedical dataset, the loss needs more epochs to stabilize than for the AOL dataset, mainly due to the combinatorial explosion mentioned above.",5 Results,[0],[0]
"To the best of our knowledge, we proposed the first neural language model that integrates user information and time sensitivity for query auto completion with a focus on scalability for real-world systems.",6 Conclusions and future work,[0],[0]
Personalization is provided through pretrained user vectors based on their past queries.,6 Conclusions and future work,[0],[0]
"By incorporating this information and by adapting the architecture, we were able to achieve stateof-the-art performance in neural query auto completion without relying on re-ranking, making this approach significantly more scalable in practice.
",6 Conclusions and future work,[0],[0]
"We studied multiple variants, their benefits and drawbacks for various use cases.",6 Conclusions and future work,[0],[0]
"We also demonstrate the utility of this method for specialized domains such as biomedicine, where the query diversity and vocabulary are broader and MPC fails to provide the same performance as in Web search.",6 Conclusions and future work,[0],[0]
We also found that user information and diversity improve the performance significantly more than for Web search engines.,6 Conclusions and future work,[0],[0]
"To allow readers to easily reproduce, evaluate and improve our models, we provide all the code on a public repository.",6 Conclusions and future work,[0],[0]
"The handling of time-sensitivity may benefit from a more elaborate integration, for example sessionbased rather than absolute time.",6 Conclusions and future work,[0],[0]
"Also, we evaluated our approaches on a general search setup for both datasets, while searches in the biomedical domain commonly contain fields (i.e. authors, title, abstract, etc.) which adds to the difficulty.",6 Conclusions and future work,[0],[0]
"The choice of a diversity metric is also important and could be faster or more efficient (e.g., using word embeddings to diversify the semantics of the suggestions).",6 Conclusions and future work,[0],[0]
These limitations warrant further work and we leave them as perspectives.,6 Conclusions and future work,[0],[0]
"This research was supported by the Intramural Research Program of the NIH, National Library of Medicine.",Acknowledgement,[0],[0]
"Query auto completion (QAC) systems are a standard part of search engines in industry, helping users formulate their query.",abstractText,[0],[0]
"Such systems update their suggestions after the user types each character, predicting the user’s intent using various signals — one of the most common being popularity.",abstractText,[0],[0]
"Recently, deep learning approaches have been proposed for the QAC task, to specifically address the main limitation of previous popularity-based methods: the inability to predict unseen queries.",abstractText,[0],[0]
"In this work we improve previous methods based on neural language modeling, with the goal of building an end-to-end system.",abstractText,[0],[0]
We particularly focus on using real-world data by integrating user information for personalized suggestions when possible.,abstractText,[0],[0]
We also make use of time information and study how to increase diversity in the suggestions while studying the impact on scalability.,abstractText,[0],[0]
"Our empirical results demonstrate a marked improvement on two separate datasets over previous best methods in both accuracy and scalability, making a step towards neural query auto-completion in production search engines.",abstractText,[0],[0]
Personalized neural language models for real-world query auto completion,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 706–711 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
706",text,[0],[0]
"Contextual, or ‘data-to-text’ natural language generation is one of the core tasks in natural language processing and has a considerable impact on various fields (Gatt and Krahmer, 2017).",1 Introduction,[0],[0]
"Within the field of recommender systems, a promising application is to estimate (or generate) personalized reviews that a user would write about a product, i.e., to discover their nuanced opinions about each of its individual aspects.",1 Introduction,[0],[0]
"A successful model could work (for instance) as (a) a highly-nuanced recommender system that tells users their likely reaction to a product in the form of text fragments; (b) a writing tool that helps users ‘brainstorm’ the review-writing process; or (c) a querying system that facilitates personalized natural lan-
guage queries (i.e., to find items about which a user would be most likely to write a particular phrase).",1 Introduction,[0],[0]
"Some recent works have explored the review generation task and shown success in generating cohesive reviews (Dong et al., 2017; Ni et al., 2017; Zang and Wan, 2017).",1 Introduction,[0],[0]
"Most of these works treat the user and item identity as input; we seek a system with more nuance and more precision by allowing users to ‘guide’ the model via short phrases, or auxiliary data such as item specifications.",1 Introduction,[0],[0]
"For example, a review writing assistant might allow users to write short phrases and expand these key points into a plausible review.
",1 Introduction,[0],[0]
"Review text has been widely studied in traditional tasks such as aspect extraction (Mukherjee and Liu, 2012; He et al., 2017), extraction of sentiment lexicons (Zhang et al., 2014), and aspectaware sentiment analysis (Wang et al., 2016; McAuley et al., 2012).",1 Introduction,[0],[0]
These works are related to review generation since they can provide prior knowledge to supervise the generative process.,1 Introduction,[0],[0]
"We are interested in exploring how such knowledge (e.g. extracted aspects) can be used in the review generation task.
",1 Introduction,[0],[0]
"In this paper, we focus on designing a review generation model that is able to leverage both user and item information as well as auxiliary, textual input and aspect-aware knowledge.",1 Introduction,[0],[0]
"Specifically, we study the task of expanding short phrases into complete, coherent reviews that accurately reflect the opinions and knowledge learned from those phrases.
",1 Introduction,[0],[0]
"These short phrases could include snippets provided by the user, or manifest aspects about the items themselves (e.g. brand words, technical specifications, etc.).",1 Introduction,[0],[0]
"We propose an encoderdecoder framework that takes into consideration three encoders (a sequence encoder, an attribute encoder, and an aspect encoder), and one decoder.",1 Introduction,[0],[0]
"The sequence encoder uses a gated recurrent unit
(GRU) network to encode text information; the attribute encoder learns a latent representation of user and item identity; finally, the aspect encoder finds an aspect-aware representation of users and items, which reflects user-aspect preferences and item-aspect relationships.",1 Introduction,[0],[0]
The aspect-aware representation is helpful to discover what each user is likely to discuss about each item.,1 Introduction,[0],[0]
"Finally, the output of these encoders is passed to the sequence decoder with an attention fusion layer.",1 Introduction,[0],[0]
The decoder attends on the encoded information and biases the model to generate words that are consistent with the input phrases and words belonging to the most relevant aspects.,1 Introduction,[0],[0]
"Review generation belongs to a large body of work on data-to-text natural language generation (Gatt and Krahmer, 2017), which has applications including summarization (See et al., 2017), image captioning (Vinyals et al., 2015), and dialogue response generation (Xing et al., 2017; Li et al., 2016; Ghosh et al., 2017), among others.",2 Related Work,[0],[0]
"Among these, review generation is characterized by the need to generate long sequences and estimate high-order interactions between users and items.
",2 Related Work,[0],[0]
Several approaches have been recently proposed to tackle these problems.,2 Related Work,[0],[0]
Dong et al. (2017) proposed an attribute-to-sequence (Attr2Seq) method to encode user and item identities as well as rating information with a multi-layer perceptron and a decoder then generates reviews conditioned on this information.,2 Related Work,[0],[0]
"They also used an attention mechanism to strengthen the alignment between
output and input attributes.",2 Related Work,[0],[0]
Ni et al. (2017) trained a collaborative-filtering generative concatenative network to jointly learn the tasks of review generation and item recommendation.,2 Related Work,[0],[0]
"Zang and Wan (2017) proposed a hierarchical structure to generate long reviews; they assume each sentence is associated with an aspect score, and learn the attention between aspect scores and sentences during training.",2 Related Work,[0],[0]
"Our approach differs from these mainly in our goal of incorporating auxiliary textual information (short phrases, product specifications, etc.) into the generative process, which facilitates the generation of higher-fidelity reviews.
",2 Related Work,[0],[0]
"Another line of work related to review generation is aspect extraction and opinion mining (Park et al., 2015; Qiu et al., 2017; He et al., 2017; Chen et al., 2014).",2 Related Work,[0],[0]
"In this paper, we argue that the extra aspect (opinion) information extracted using these previous works can effectively improve the quality of generated reviews.",2 Related Work,[0],[0]
We propose a simple but effective way to combine aspect information into the generative model.,2 Related Work,[0],[0]
We describe the review generation task as follows.,3 Approach,[0],[0]
"Given a user u, item i, several short phrases {d1, d2, ..., dM}, and a group of extracted aspects {A1, A2, ..., Ak}, our goal is to generate a review (w1, w2, ..., wT) that maximizes the probability P (w1:T|u, i, d1:M).",3 Approach,[0],[0]
"To solve this task, we propose a method called ExpansionNet which contains two parts: 1) three encoders to leverage the input phrases and aspect information; and 2) a decoder with an attention fusion layer to generate sequences and align the generation with the input
sources.",3 Approach,[0],[0]
The model structure is shown in Figure 1.,3 Approach,[0],[0]
"Our sequence encoder is a two-layer bi-directional GRU, as is commonly used in sequence-tosequence (Seq2Seq) models (Cho et al., 2014).","3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
"Input phrases first pass a word embedding layer, then go through the GRU one-by-one and finally yield a sequence of hidden states {e1, e2..., eL}.","3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
"In the case of multiple phrases, these share the same sequence encoder and have different lengths L. To simplify notation, we only consider one input phrase in this section.
","3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
The attribute encoder and aspect encoder both consist of two embedding layers and a projection layer.,"3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
"For the attribute encoder, we define two general embedding layers Eu ∈ R|U|×m and Ei ∈ R|I|×m to obtain the attribute latent factors γu and γi; for the aspect encoder, we use two aspect-aware embedding layers E ′","3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
u ∈ R|U|×k,"3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
and E ′,"3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
i ∈ R|I|×k to obtain aspect-aware latent factors βu,"3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
and βi.,"3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
"Here |U|, |I|, m and k are the number of users, number of items, the dimension of attributes, and the number of aspects, respectively.","3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
"After the embedding layers, the attribute and aspect-aware latent factors are concatenated and fed into a projection layer with tanh activation.","3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
"The outputs are calculated as:
γu = Eu(u), γi = Ei(i) (1) βu = E ′ u(u), βi = E ′ i(i) (2)
u = tanh(Wu[γu; γi] + bu) (3)
v = tanh(Wv[βu;βi] + bv) (4)
where Wu ∈","3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
"Rn×2m,","3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
"bu ∈ Rn, Wv ∈ Rn×2k, bv ∈ Rn are learnable parameters and n is the dimensionality of the hidden units in the decoder.","3.1 Sequence encoder, attribute encoder and aspect encoder",[0],[0]
The decoder is a two-layer GRU that predicts the target words given the start token.,3.2 Decoder with attention fusion layer,[0],[0]
The hidden state of the decoder is initialized using the sum of the three encoders’ outputs.,3.2 Decoder with attention fusion layer,[0],[0]
The hidden state at time-step t is updated via the GRU unit based on the previous hidden state and the input word.,3.2 Decoder with attention fusion layer,[0],[0]
"Specifically:
h0 = eL + u+ v (5)
ht = GRU(wt,ht−1), (6)
where h0 ∈ Rn is the decoder’s initial hidden state and ht ∈",3.2 Decoder with attention fusion layer,[0],[0]
"Rn is the hidden state at time-step t.
To fully exploit the encoder-side information, we apply an attention fusion layer to summarize the output of each encoder and jointly determine the final word distribution.",3.2 Decoder with attention fusion layer,[0],[0]
"For the sequence encoder, the attention vector is defined as in many other applications (Bahdanau et al., 2014; Luong et al., 2015):
a1t = L∑ j=1 α1tjej (7)
α1tj = exp(tanh(v 1 α >",3.2 Decoder with attention fusion layer,[0],[0]
"(W 1α[ej ;ht] + b 1 α)))/Z,
(8)
where a1t ∈",3.2 Decoder with attention fusion layer,[0],[0]
"Rn is the attention vector on the sequence encoder at time-step t, α1tj is the attention score over the encoder hidden state ej and decoder hidden state ht, and Z is a normalization term.
",3.2 Decoder with attention fusion layer,[0],[0]
"For the attribute encoder, the attention vector is calculated as:
a2t = ∑ j∈u,i α2tjγj (9)
α2tj = exp(tanh(v 2 α >",3.2 Decoder with attention fusion layer,[0],[0]
"(W 2α[γj ;ht] + b 2 α)))/Z,
(10)
where a2t ∈",3.2 Decoder with attention fusion layer,[0],[0]
"Rn is the attention vector on the attribute encoder, and α2tj is the attention score between the attribute latent factor γj and decoder hidden state ht.
",3.2 Decoder with attention fusion layer,[0],[0]
"Inspired by the copy mechanism (Gu et al., 2016; See et al., 2017), we design an attention vector that estimates the probability that each aspect will be discussed in the next time-step:
sui =Ws[βu;βi] + bs (11) a3t = tanh(W 3 α[sui; et;ht] + b 3 α), (12)
where sui ∈ Rk is the aspect importance considering the interaction between u and i, et is the decoder input after embedding layer at time-step t, and a3t ∈",3.2 Decoder with attention fusion layer,[0],[0]
"Rk is a probability vector to bias each aspect at time-step t. Finally, the first two attention vectors are concatenated with the decoder hidden state at time-step t and projected to obtain the output word distribution Pv.",3.2 Decoder with attention fusion layer,[0],[0]
The attention scores from the aspect encoder are then directly added to the aspect words in the final word distribution.,3.2 Decoder with attention fusion layer,[0],[0]
"The output probability for word w at time-step t is given by:
Pv(wt) =",3.2 Decoder with attention fusion layer,[0],[0]
tanh(W,3.2 Decoder with attention fusion layer,[0],[0]
[ht;a 1 t ;a 2 t ] + b),3.2 Decoder with attention fusion layer,[0],[0]
"(13)
P (wt) = Pv(wt) + a 3 t [k] · 1wt∈Ak , (14)
where wt is the target word at time-step t, a3t",3.2 Decoder with attention fusion layer,[0],[0]
"[k] is the probability that aspect k will be discussed at time-step t, Ak represents all words belonging to aspect k and 1wt∈Ak is a binary variable indicating whether wt belongs to aspect k.
During inference, we use greedy decoding by choosing the word with maximum probability, denoted as yt = argmaxwtsoftmax(P (wt)).",3.2 Decoder with attention fusion layer,[0],[0]
Decoding finishes when an end token is encountered.,3.2 Decoder with attention fusion layer,[0],[0]
"We consider a real world dataset from Amazon Electronics (McAuley et al., 2015) to evaluate our model.",4 Experiments,[0],[0]
"We convert all text into lowercase, add start and end tokens to each review, and perform tokenization using NLTK.1",4 Experiments,[0],[0]
"We discard reviews with length greater than 100 tokens and consider a vocabulary of 30,000 tokens.",4 Experiments,[0],[0]
"After preprocessing, the dataset contains 182,850 users, 59,043 items, and 992,172 reviews (sparsity 99.993%), which is much sparser than the datasets used in previous works (Dong et al., 2017; Ni et al., 2017).",4 Experiments,[0],[0]
"On average, each review contains 49.32 tokens as well as a short-text summary of 4.52 tokens.",4 Experiments,[0],[0]
"In our experiments, the basic ExpansionNet uses these summaries as input phrases.",4 Experiments,[0],[0]
"We split the dataset into training (80%), validation (10%) and test sets (10%).",4 Experiments,[0],[0]
All results are reported on the test set.,4 Experiments,[0],[0]
"We use the method2 in (He et al., 2017) to extract 15 aspects and consider the top 100 words from each aspect.",4.1 Aspect Extraction,[0],[0]
Table 2 shows 10 inferred aspects and representative words (inferred aspects are manually labeled).,4.1 Aspect Extraction,[0],[0]
"ExpansionNet calculates an attention score based on the user and item aspect-aware representation, then determines how much these representative words are biased in the output word distribution.
",4.1 Aspect Extraction,[0],[0]
1 https://www.nltk.org/ 2 https://github.com/ruidan/ Unsupervised-Aspect-Extraction,4.1 Aspect Extraction,[0],[0]
We use PyTorch3 to implement our model.4 Parameter settings are shown in Table 1.,4.2 Experiment Details,[0],[0]
"For the attribute encoder and aspect encoder, we set the dimensionality to 64 and 15 respectively.",4.2 Experiment Details,[0],[0]
"For both the sequence encoder and decoder, we use a 2- layer GRU with hidden size 512.",4.2 Experiment Details,[0],[0]
We also add dropout layers before and after the GRUs.,4.2 Experiment Details,[0],[0]
The dropout rate is set to 0.1.,4.2 Experiment Details,[0],[0]
"During training, the input sequences of the same source (e.g. review, summary) inside each batch are padded to the same length.",4.2 Experiment Details,[0],[0]
"We evaluate the model on six automatic metrics (Table 3): Perplexity, BLEU-1/BLEU-4, ROUGEL and Distinct-1/2 (percentage of distinct unigrams and bi-grams) (Li et al., 2016).",4.3 Performance Evaluation,[0],[0]
"We compare
3 http://pytorch.org/docs/master/index.html 4 https://github.com/nijianmo/textExpansion
against three baselines: Rand (randomly choose a review from the training set), GRU-LM (the GRU decoder works alone as a language model) and a state-of-the-art model Attr2Seq that only considers user and item attribute (Dong et al., 2017).",4.3 Performance Evaluation,[0],[0]
"ExpansionNet (with summary, item title, attribute and aspect as input) achieves significant improvements over Attr2Seq on all metrics.",4.3 Performance Evaluation,[0],[0]
"As we add more input information, the model continues to obtain better results, except for the ROUGE-L metric.",4.3 Performance Evaluation,[0],[0]
"This proves that our model can effectively learn from short input phrases and aspect information and improve the correctness and diversity of generated results.
",4.3 Performance Evaluation,[0],[0]
Figure 2 presents a sample generation result.,4.3 Performance Evaluation,[0],[0]
"ExpansionNet captures fine-grained item information (e.g. that the item is a tablet), which Attr2Seq fails to recognize.",4.3 Performance Evaluation,[0],[0]
"Moreover, given a phrase like “easy to use” in the summary, ExpansionNet generates reviews containing the same text.",4.3 Performance Evaluation,[0],[0]
This demonstrates the possibility of using our model in an assistive review generation scenario.,4.3 Performance Evaluation,[0],[0]
"Finally, given extra aspect information, the model successfully estimates that the screen would be an important aspect (i.e., for the current user and item); it generates phrases such as “screen is very respon-
sive” about the aspect “screen” which is also covered in the real (ground-truth) review (“display is beautiful”).
",4.3 Performance Evaluation,[0],[0]
We are also interested in seeing how the aspectaware representation can find related aspects and bias the generation to discuss more about those aspects.,4.3 Performance Evaluation,[0],[0]
We analyze the average number of aspects in real and generated reviews and show on average how many aspects in real reviews are covered in generated reviews.,4.3 Performance Evaluation,[0],[0]
We consider a review as covering an aspect if any of the aspect’s representative words exists in the review.,4.3 Performance Evaluation,[0],[0]
"As shown in Table 4, Attr2Seq tends to cover more aspects in generation, many of which are not discussed in real reviews.",4.3 Performance Evaluation,[0],[0]
"On the other hand, ExpansionNet better captures the distribution of aspects that are discussed in real reviews.",4.3 Performance Evaluation,[0],[0]
"In this paper, we focus on the problem of building assistive systems that can help users to write reviews.",abstractText,[0],[0]
"We cast this problem using an encoder-decoder framework that generates personalized reviews by expanding short phrases (e.g. review summaries, product titles) provided as input to the system.",abstractText,[0],[0]
We incorporate aspect-level information via an aspect encoder that learns ‘aspect-aware’ user and item representations.,abstractText,[0],[0]
An attention fusion layer is applied to control generation by attending on the outputs of multiple encoders.,abstractText,[0],[0]
Experimental results show that our model is capable of generating coherent and diverse reviews that expand the contents of input phrases.,abstractText,[0],[0]
"In addition, the learned aspectaware representations discover those aspects that users are more inclined to discuss and bias the generated text toward their personalized aspect preferences.",abstractText,[0],[0]
Personalized Review Generation by Expanding Phrases and Attending on Aspect-Aware Representations,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 2204–2213 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
2204",text,[0],[0]
"Despite much recent success in natural language processing and dialogue research, communication between a human and a machine is still in its infancy.",1 Introduction,[0],[0]
It is only recently that neural models have had sufficient capacity and access to sufficiently large datasets that they appear to generate meaningful responses in a chit-chat setting.,1 Introduction,[0],[0]
"Still, conversing with such generic chit-chat models for even a short amount of time quickly exposes their weaknesses (Serban et al., 2016; Vinyals and Le, 2015).
",1 Introduction,[0],[0]
"Common issues with chit-chat models include: (i) the lack of a consistent personality (Li et al., 2016a) as they are typically trained over many dialogs each with different speakers, (ii) the lack of an explicit long-term memory as they are typically trained to produce an utterance given only the recent dialogue history (Vinyals and Le, 2015);
1Work done while at Facebook AI Research.
and (iii) a tendency to produce non-specific answers like “I don’t know” (Li et al., 2015).",1 Introduction,[0],[0]
Those three problems combine to produce an unsatisfying overall experience for a human to engage with.,1 Introduction,[0],[0]
"We believe some of those problems are due to there being no good publicly available dataset for general chit-chat.
",1 Introduction,[0],[0]
"Because of the low quality of current conversational models, and because of the difficulty in evaluating these models, chit-chat is often ignored as an end-application.",1 Introduction,[0],[0]
"Instead, the research community has focused on task-oriented communication, such as airline or restaurant booking (Bordes and Weston, 2016), or else single-turn information seeking, i.e. question answering (Rajpurkar et al., 2016).",1 Introduction,[0],[0]
"Despite the success of the latter, simpler, domain, it is well-known that a large quantity of human dialogue centers on socialization, personal interests and chit-chat (Dunbar et al., 1997).",1 Introduction,[0],[0]
"For example, less than 5% of posts on Twitter are questions, whereas around 80% are about personal emotional state, thoughts or activities, authored by so called “Meformers” (Naaman et al., 2010).
",1 Introduction,[0],[0]
"In this work we make a step towards more engaging chit-chat dialogue agents by endowing them with a configurable, but persistent persona, encoded by multiple sentences of textual description, termed a profile.",1 Introduction,[0],[0]
"This profile can be stored in a memory-augmented neural network and then used to produce more personal, specific, consistent and engaging responses than a persona-free model, thus alleviating some of the common issues in chit-chat models.",1 Introduction,[0],[0]
"Using the same mechanism, any existing information about the persona of the dialogue partner can also be used in the same way.",1 Introduction,[0],[0]
"Our models are thus trained to both ask and answer questions about personal topics, and the resulting dialogue can be used to build a model of the persona of the speaking partner.
",1 Introduction,[0],[0]
"To support the training of such models, we
present the PERSONA-CHAT dataset, a new dialogue dataset consisting of 164,356 utterances between crowdworkers who were randomly paired and each asked to act the part of a given provided persona (randomly assigned, and created by another set of crowdworkers).",1 Introduction,[0],[0]
The paired workers were asked to chat naturally and to get to know each other during the conversation.,1 Introduction,[0],[0]
"This produces interesting and engaging conversations that our agents can try to learn to mimic.
",1 Introduction,[0],[0]
"Studying the next utterance prediction task during dialogue, we compare a range of models: both generative and ranking models, including Seq2Seq models and Memory Networks (Sukhbaatar et al., 2015) as well as other standard retrieval baselines.",1 Introduction,[0],[0]
We show experimentally that in either the generative or ranking case conditioning the agent with persona information gives improved prediction of the next dialogue utterance.,1 Introduction,[0],[0]
"The PERSONA-CHAT dataset is designed to facilitate research into alleviating some of the issues that traditional chitchat models face, and with the aim of making such models more consistent and engaging, by endowing them with a persona.",1 Introduction,[0],[0]
"By comparing against chit-chat models built using the OpenSubtitles and Twitter datasets, human evaluations show that our dataset provides more engaging models, that are simultaneously capable of being fluent and consistent via conditioning on a persistent, recognizable profile.",1 Introduction,[0],[0]
"Traditional dialogue systems consist of building blocks, such as dialogue state tracking components and response generators, and have typically been applied to tasks with labeled internal dialogue state and precisely defined user intent (i.e., goal-oriented dialogue), see e.g. (Young, 2000).",2 Related Work,[0],[0]
"The most successful goal-oriented dialogue systems model conversation as partially observable Markov decision processes (POMDPs) (Young et al., 2013).",2 Related Work,[0],[0]
All those methods typically do not consider the chit-chat setting and are more concerned with achieving functional goals (e.g. booking an airline flight) than displaying a personality.,2 Related Work,[0],[0]
"In particular, many of the tasks and datasets available are constrained to narrow domains (Serban et al., 2015).
",2 Related Work,[0],[0]
"Non-goal driven dialogue systems go back to Weizenbaum’s famous program ELIZA (Weizenbaum, 1966), and hand-coded systems have con-
tinued to be used in applications to this day.",2 Related Work,[0],[0]
"For example, modern solutions that build an openended dialogue system to the Alexa challenge combine hand-coded and machine-learned elements (Serban et al., 2017a).",2 Related Work,[0],[0]
"Amongst the simplest of statistical systems that can be used in this domain, that are based on data rather than handcoding, are information retrieval models (Sordoni et al., 2015), which retrieve and rank responses based on their matching score with the recent dialogue history.",2 Related Work,[0],[0]
"We use IR systems as a baseline in this work.
",2 Related Work,[0],[0]
End-to-end neural approaches are a class of models which have seen growing recent interest.,2 Related Work,[0],[0]
"A popular class of methods are generative recurrent systems like seq2seq applied to dialogue (Sutskever et al., 2014; Vinyals and Le, 2015; Sordoni et al., 2015; Li et al., 2016b; Serban et al., 2017b).",2 Related Work,[0],[0]
"Rooted in language modeling, they are able to produce syntactically coherent novel responses, but their memory-free approach means they lack long-term coherence and a persistent personality, as discussed before.",2 Related Work,[0],[0]
"A promising direction, that is still in its infancy, to fix this issue is to use a memory-augmented network instead (Sukhbaatar et al., 2015; Dodge et al., 2015) by providing or learning appropriate memories.
",2 Related Work,[0],[0]
Serban et al. (2015) list available corpora for training dialogue systems.,2 Related Work,[0],[0]
"Perhaps the most relevant to learning chit-chat models are ones based on movie scripts such as OpenSubtitles and Cornell Movie-Dialogue Corpus, and dialogue from web platforms such as Reddit and Twitter, all of which have been used for training neural approaches (Vinyals and Le, 2015; Dodge et al., 2015; Li et al., 2016b; Serban et al., 2017b).",2 Related Work,[0],[0]
Naively training on these datasets leads to models with the lack of a consistent personality as they will learn a model averaged over many different speakers.,2 Related Work,[0],[0]
"Moreover, the data does little to encourage the model to engage in understanding and maintaining knowledge of the dialogue partner’s personality and topic interests.
",2 Related Work,[0],[0]
"According to Serban et al. (2015)’s survey, personalization of dialogue systems is “an important task, which so far has not received much attention”.",2 Related Work,[0],[0]
"In the case of goal-oriented dialogue some work has focused on the agent being aware of the human’s profile and adjusting the dialogue accordingly, but without a personality to the agent itself (Lucas et al., 2009; Joshi et al., 2017).",2 Related Work,[0],[0]
"For
the chit-chat setting, the most relevant work is (Li et al., 2016a).",2 Related Work,[0],[0]
"For each user in the Twitter corpus, personas were captured via distributed embeddings (one per speaker) to encapsulate individual characteristics such as background information and speaking style, and they then showed using those vectors improved the output of their seq2seq model for the same speaker.",2 Related Work,[0],[0]
"Their work does not focus on attempting to engage the other speaker by getting to know them, as we do here.",2 Related Work,[0],[0]
"For that reason, our focus is on explicit profile information, not hard-to-interpret latent variables.
",2 Related Work,[0],[0]
3,2 Related Work,[0],[0]
"The PERSONA-CHAT Dataset
The aim of this work is to facilitate more engaging and more personal chit-chat dialogue.",2 Related Work,[0],[0]
"The PERSONA-CHAT dataset is a crowd-sourced dataset, collected via Amazon Mechanical Turk, where each of the pair of speakers condition their dialogue on a given profile, which is provided.
",2 Related Work,[0],[0]
"The data collection consists of three stages: (i) Personas: we crowdsource a set of 1155 possible personas, each consisting of at least 5 profile sentences, setting aside 100 never seen before personas for validation, and 100 for test.
",2 Related Work,[0],[0]
"(ii) Revised personas: to avoid modeling that takes advantage of trivial word overlap, we crowdsource additional rewritten sets of the same 1155 personas, with related sentences that are rephrases, generalizations or specializations, rendering the task much more challenging.
",2 Related Work,[0],[0]
"(iii) Persona chat: we pair two Turkers and assign them each a random (original) persona from the pool, and ask them to chat.",2 Related Work,[0],[0]
"This resulted in a dataset of 164,356 utterances over 10,981 dialogs, 15,705 utterances (968 dialogs) of which are set aside for validation, and 15,119 utterances (1000 dialogs) for test.
",2 Related Work,[0],[0]
"The final dataset and its corresponding data collection source code, as well as models trained on the data, are all available open source in ParlAI2.
",2 Related Work,[0],[0]
"In the following, we describe each data collection stage and the resulting tasks in more detail.",2 Related Work,[0],[0]
"We asked the crowdsourced workers to create a character (persona) description using 5 sentences, providing them only a single example:
2https://github.com/facebookresearch/ ParlAI/tree/master/projects/personachat
“I am a vegetarian.",3.1 Personas,[0],[0]
I like swimming.,3.1 Personas,[0],[0]
My father used to work for Ford.,3.1 Personas,[0],[0]
My favorite band is Maroon5.,3.1 Personas,[0],[0]
"I got a new job last month, which is about advertising design.”
",3.1 Personas,[0],[0]
"Our aim was to create profiles that are natural and descriptive, and contain typical topics of human interest that the speaker can bring up in conversation.",3.1 Personas,[0],[0]
"Because the personas are not the real profiles of the Turkers, the dataset does not contain personal information (and they are told specifically not to use any).",3.1 Personas,[0],[0]
"We asked the workers to make each sentence short, with a maximum of 15 words per sentence.",3.1 Personas,[0],[0]
"This is advantageous both for humans and machines: if they are too long, crowdsourced workers are likely to lose interest, and for machines the task could become more difficult.
",3.1 Personas,[0],[0]
Some examples of the personas collected are given in Table 1 (left).,3.1 Personas,[0],[0]
"A difficulty when constructing dialogue datasets, or text datasets in general, is that in order to encourage research progress, the task must be carefully constructed so that is neither too easy nor too difficult for the current technology (Voorhees et al., 1999).",3.2 Revised Personas,[0],[0]
"One issue with conditioning on textual personas is that there is a danger that humans will, even if asked not to, unwittingly repeat profile information either verbatim or with significant word overlap.",3.2 Revised Personas,[0],[0]
"This may make any subsequent machine learning tasks less challenging, and the solutions will not generalize to more difficult tasks.",3.2 Revised Personas,[0],[0]
"This has been a problem in some recent datasets: for example, the dataset curation technique used for the well-known SQuAD dataset suffers from this word overlap problem to a certain extent (Chen et al., 2017).
",3.2 Revised Personas,[0],[0]
"To alleviate this problem, we presented the original personas we collected to a new set of crowdworkers and asked them to rewrite the sentences so that a new sentence is about “a related characteristic that the same person may have”, hence the revisions could be rephrases, generalizations or specializations.",3.2 Revised Personas,[0],[0]
"For example “I like basketball” can be revised as “I am a big fan of Michael Jordan” not because they mean the same thing but because the same persona could contain both.
",3.2 Revised Personas,[0],[0]
"In the revision task, workers are instructed not to trivially rephrase the sentence by copying the original words.",3.2 Revised Personas,[0],[0]
"However, during the entry stage if a non-stop word is copied we issue a warning,
and ask them to rephrase, guaranteeing that the instructions are followed.",3.2 Revised Personas,[0],[0]
"For example, “My father worked for Ford.”",3.2 Revised Personas,[0],[0]
"can be revised to “My dad worked in the car industry”, but not “My dad was employed by Ford.”",3.2 Revised Personas,[0],[0]
"due to word overlap.
",3.2 Revised Personas,[0],[0]
Some examples of the revised personas collected are given in Table 1 (right).,3.2 Revised Personas,[0],[0]
"After collecting personas, we then collected the dialogues themselves, conditioned on the personas.",3.3 Persona Chat,[0],[0]
"For each dialogue, we paired two random crowdworkers, and gave them the instruction that they will chit-chat with another worker, while playing the part of a given character.",3.3 Persona Chat,[0],[0]
"We then provide them with a randomly chosen persona from our pool, different to their partners.",3.3 Persona Chat,[0],[0]
"The instructions are on
purpose quite terse and simply ask them to “chat with the other person naturally and try to get to know each other”.",3.3 Persona Chat,[0],[0]
"In an early study we noticed the crowdworkers tending to talk about themselves (their own persona) too much, so we also added the instructions “both ask questions and answer questions of your chat partner” which seemed to help.",3.3 Persona Chat,[0],[0]
We also gave a bonus for high quality dialogs.,3.3 Persona Chat,[0],[0]
"The dialog is turn-based, with a maximum of 15 words per message.",3.3 Persona Chat,[0],[0]
"We again gave instructions to not trivially copy the character descriptions into the messages, but also wrote explicit code sending them an error if they tried to do so, using simple string matching.",3.3 Persona Chat,[0],[0]
We define a minimum dialogue length which is randomly between 6 and 8 turns each for each dialogue.,3.3 Persona Chat,[0],[0]
An example dialogue from the dataset is given in Table 2.,3.3 Persona Chat,[0],[0]
"We focus on the standard dialogue task of predicting the next utterance given the dialogue history, but consider this task both with and without the profile information being given to the learning agent.",3.4 Evaluation,[0],[0]
"Our goal is to enable interesting directions for future research, where chatbots can for instance have personalities, or imputed personas could be used to make dialogue more engaging to the user.
",3.4 Evaluation,[0],[0]
"We consider this in four possible scenarios: conditioning on no persona, your own persona, their persona, or both.",3.4 Evaluation,[0],[0]
"These scenarios can be tried using either the original personas, or the revised ones.",3.4 Evaluation,[0],[0]
"We then evaluate the task using three metrics: (i) the log likelihood of the correct sequence, measured via perplexity, (ii) F1 score, and (iii) next utterance classification loss, following Lowe et al. (2015).",3.4 Evaluation,[0],[0]
"The latter consists of choosing N random distractor responses from other dialogues (in our setting, N=19) and the model selecting the best response among them, resulting in a score of one if the model chooses the correct response, and zero otherwise (called hits@1 in the experiments).",3.4 Evaluation,[0],[0]
We consider two classes of model for next utterance prediction: ranking models and generative models.,4 Models,[0],[0]
Ranking models produce a next utterance by considering any utterance in the training set as a possible candidate reply.,4 Models,[0],[0]
"Generative models generate novel sentences by conditioning on the dialogue history (and possibly, the persona), and then generating the response word-by-word.",4 Models,[0],[0]
"Note one can still evaluate the latter as ranking models by computing the probability of generating a given candidate, and ranking candidates by those scores.",4 Models,[0],[0]
"We first consider two baseline models, an IR baseline (Sordoni et al., 2015) and a supervised embedding model, Starspace (Wu et al., 2017)3.",4.1 Baseline ranking models,[0],[0]
"While there are many IR variants, we adopt the simplest one: find the most similar message in the (training) dataset and output the response from that exchange.",4.1 Baseline ranking models,[0],[0]
Similarity is measured by the tfidf weighted cosine similarity between the bags of words.,4.1 Baseline ranking models,[0],[0]
"Starspace is a recent model that also performs information retrieval but by learning the
3github.com/facebookresearch/StarSpace
similarity between the dialog and the next utterance by optimizing the embeddings directly for that task using the margin ranking loss and k-negative sampling.",4.1 Baseline ranking models,[0.9559560232925522],['This is illustrated by the observation that the reference resolution accuracy using gold-standard semantic information from referring expressions is still substantially lower than the agreement rate between human annotators.']
"The similarity function sim(q, c′) is the cosine similarity of the sum of word embeddings of the query q and candidate c′.",4.1 Baseline ranking models,[0],[0]
"Denoting the dictionary of D word embeddings as W which is a D× d matrix, where Wi indexes the ith word (row), yielding its d-dimensional embedding, it embeds the sequences q and c′.
In both methods, IR and StarSpace, to incorporate the profile we simply concatenate it to the query vector bag of words.",4.1 Baseline ranking models,[0],[0]
"Both the previous models use the profile information by combining it with the dialogue history, which means those models cannot differentiate between the two when deciding on the next utterance.",4.2 Ranking Profile Memory Network,[0],[0]
"In this model we instead use a memory network with the dialogue history as input, which then performs attention over the profile to find relevant lines from the profile to combine with the input, and then finally predicts the next utterance.",4.2 Ranking Profile Memory Network,[0],[0]
"We use the same representation and loss as in the Starspace model, so without the profile, the two models are identical.",4.2 Ranking Profile Memory Network,[0],[0]
"When the profile is available attention is performed by computing the similarity of the input q with the profile sentences pi, computing the softmax, and taking the weighted sum:
q+ = q+ ∑ sipi, si = Softmax(sim(q, pi))",4.2 Ranking Profile Memory Network,[0],[0]
where Softmax(zi) = ezi/ ∑ j e zj .,4.2 Ranking Profile Memory Network,[0],[0]
"One can then rank the candidates c′ using sim(q+, c′).",4.2 Ranking Profile Memory Network,[0],[0]
"One can also perform multiple “hops” of attention over the profile rather than one, as shown here, although that did not bring significant gains in our parameter sweeps.",4.2 Ranking Profile Memory Network,[0],[0]
"The key-value (KV) memory network (Miller et al., 2016) was proposed as an improvement to the memory network by performing attention over keys and outputting the values (instead of the same keys as in the original), which can outperform memory networks dependent on the task and definition of the key-value pairs.",4.3 Key-Value Profile Memory Network,[0],[0]
"Here, we apply this model to dialogue, and consider the keys as dialog histories (from the training set), and the values as the next dialogue utterances, i.e., the replies from the speaking partner.",4.3 Key-Value Profile Memory Network,[0],[0]
"This allows the model
to have a memory of past dialogues that it can directly use to help influence its prediction for the current conversation.",4.3 Key-Value Profile Memory Network,[0],[0]
"The model we choose is identical to the profile memory network just described in the first hop over profiles, while in the second hop, q+ is used to attend over the keys and output a weighted sum of values as before, producing q++.",4.3 Key-Value Profile Memory Network,[0],[0]
"This is then used to rank the candidates c′ using sim(q++, c′) as before.",4.3 Key-Value Profile Memory Network,[0],[0]
As the set of (key-value) pairs is large this would make training very slow.,4.3 Key-Value Profile Memory Network,[0],[0]
In our experiments we simply trained the profile memory network and used the same weights from that model and applied this architecture at test time instead.,4.3 Key-Value Profile Memory Network,[0],[0]
"Training the model directly would presumably give better results, however this heuristic already proved beneficial compared to the original network.",4.3 Key-Value Profile Memory Network,[0],[0]
The input sequence x is encoded by applying het = LSTMenc(xt | het−1).,4.4 Seq2Seq,[0],[0]
"We use GloVe (Pennington et al., 2014) for our word embeddings.",4.4 Seq2Seq,[0],[0]
"The final hidden state, het , is fed into the decoder LSTMdec as the initial state hd0.",4.4 Seq2Seq,[0],[0]
"For each time step t, the decoder then produces the probability of a word j occurring in that place via the softmax, i.e.,
p(yt,j = 1 | yt−1, . . .",4.4 Seq2Seq,[0],[0]
", y1) = exp(wjh d t )",4.4 Seq2Seq,[0],[0]
"∑K
j′=1 exp(wj′h d t ) .
",4.4 Seq2Seq,[0],[0]
The model is trained via negative log likelihood.,4.4 Seq2Seq,[0],[0]
"The basic model can be extended to include persona information, in which case we simply prepend it to the input sequence x, i.e., x = ∀p ∈ P ||",4.4 Seq2Seq,[0],[0]
"x, where || denotes concatenation.",4.4 Seq2Seq,[0],[0]
"For the OpenSubtitles and Twitter datasets trained in Section 5.2 we found training a language model (LM), essentially just the decoder part of this model, worked better and we report that instead.",4.4 Seq2Seq,[0],[0]
"Finally, we introduce a generative model that encodes each of the profile entries as individual memory representations in a memory network.",4.5 Generative Profile Memory Network,[0],[0]
"As before, the dialogue history is encoded via LSTMenc, the final state of which is used as the initial hidden state of the decoder.",4.5 Generative Profile Memory Network,[0],[0]
"Each entry pi = 〈pi,1, . . .",4.5 Generative Profile Memory Network,[0],[0]
", pi,n〉 ∈ P is then encoded via f(pi)",4.5 Generative Profile Memory Network,[0],[0]
"=∑|pi|
j αipi,j .",4.5 Generative Profile Memory Network,[0],[0]
"That is, we weight words by their inverse term frequency: αi = 1/(1 + log(1 + tf)) where tf is computed from the GloVe index via
Zipf’s law4.",4.5 Generative Profile Memory Network,[0],[0]
Let F be the set of encoded memories.,4.5 Generative Profile Memory Network,[0],[0]
"The decoder now attends over the encoded profile entries, i.e., we compute the mask at, context ct and next input x̂t as:
at = softmax(FWah d t ),
ct = a ᵀ tF ; x̂t = tanh(Wc[ct−1, xt]).
",4.5 Generative Profile Memory Network,[0],[0]
"If the model has no profile information, and hence no memory, it becomes equivalent to the Seq2Seq model.",4.5 Generative Profile Memory Network,[0],[0]
"We first report results using automated evaluation metrics, and subsequently perform an extrinsic evaluation where crowdsourced workers perform a human evaluation of our models.",5 Experiments,[0],[0]
The main results are reported in Table 3.,5.1 Automated metrics,[0],[0]
"Overall, the results show the following key points:
Persona Conditioning Most models improve significantly when conditioning prediction on their own persona at least for the original (non-revised) versions, which is an easier task than the revised ones which have no word overlap.",5.1 Automated metrics,[0],[0]
"For example, the Profile Memory generation model has improved perplexity and hits@1 compared to Seq2Seq, and all the ranking algorithms (IR baseline, Starspace and Profile Memory Networks) obtain improved hits@1.
",5.1 Automated metrics,[0],[0]
Ranking vs. Generative.,5.1 Automated metrics,[0],[0]
Ranking models are far better than generative models at ranking.,5.1 Automated metrics,[0],[0]
"This is perhaps obvious as that is the metric they are optimizing, but still the performance difference is quite stark.",5.1 Automated metrics,[0],[0]
"It may be that the word-based probability which generative models use works well, but is not calibrated well enough to give a sentencebased probability which ranking requires.",5.1 Automated metrics,[0],[0]
"Human evaluation is also used to compare these methods, which we perform in Sec. 5.2.
",5.1 Automated metrics,[0],[0]
Ranking Models.,5.1 Automated metrics,[0],[0]
"For the ranking models, the IR baseline is outperformed by Starspace due to its learnt similarity metric, which in turn is outperformed by Profile Memory networks due to the attention mechanism over the profiles (as all other parts of the models are the same).",5.1 Automated metrics,[0],[0]
"Finally KV Profile Memory networks outperform Profile Memory Networks in the no persona case due to the ability to consider neighboring dialogue history and next
4tf = 1e6 ∗ 1/(idx1.07)
utterance pairs in the training set that are similar to the current dialogue, however when using persona information the performance is similar.
",5.1 Automated metrics,[0],[0]
Revised Personas.,5.1 Automated metrics,[0],[0]
Revised personas are much harder to use.,5.1 Automated metrics,[0],[0]
We do however still see some gain for the Profile Memory networks compared to none (0.354 vs. 0.318 hits@1).,5.1 Automated metrics,[0],[0]
"We also tried two variants of training: with the original personas in the training set or the revised ones, a comparison of which is shown in Table 6 of the Appendix.",5.1 Automated metrics,[0],[0]
"Training on revised personas helps, both for test examples that are in original form or revised form, likely due to the model be forced to learn more than simple word overlap, forcing the model to generalize more (i.e., learn semantic similarity of differing phrases).
",5.1 Automated metrics,[0],[0]
Their Persona.,5.1 Automated metrics,[0],[0]
"We can also condition a model on the other speaker’s persona, or both personas at once, the results of which are in Tables 5 and 6 in the Appendix.",5.1 Automated metrics,[0],[0]
Using “Their persona” has less impact on this dataset.,5.1 Automated metrics,[0],[0]
We believe this is because most speakers tend to focus on themselves when it comes to their interests.,5.1 Automated metrics,[0],[0]
It would be interesting how often this is the case in other datasets.,5.1 Automated metrics,[0],[0]
Certainly this is skewed by the particular instructions one could give to the crowdworkers.,5.1 Automated metrics,[0],[0]
"For example if we gave the instructions “try not to talk about yourself, but about the other’s interests’ likely these metrics would change.",5.1 Automated metrics,[0],[0]
"As automated metrics are notoriously poor for evaluating dialogue (Liu et al., 2016)",5.2 Human Evaluation,[0],[0]
we also perform human evaluation using crowdsourced workers.,5.2 Human Evaluation,[0],[0]
The procedure is as follows.,5.2 Human Evaluation,[0],[0]
We perform almost exactly the same setup as in the dataset collection process itself as in Section 3.3.,5.2 Human Evaluation,[0],[0]
"In that setup, we paired two Turkers and assigned them each a random (original) persona from the collected pool, and asked them to chat.",5.2 Human Evaluation,[0],[0]
"Here, from the Turker’s point of view everything looks the same except instead of being paired with a Turker they are paired with one of our models instead (they do not know this).",5.2 Human Evaluation,[0],[0]
"In this setting, for both the Turker and the model, the personas come from the test set pool.
",5.2 Human Evaluation,[0.951924141447559],"['In each fold, annotated referring expressions from one of the tutoring sessions were taken as the test set, and data from the other five sessions were the training set.']"
"After the dialogue, we then ask the Turker some additional questions in order to evaluate the quality of the model.",5.2 Human Evaluation,[0],[0]
"We ask them to evaluate fluency, engagingness and consistency (scored between 1- 5).",5.2 Human Evaluation,[0],[0]
"Finally, we measure the ability to detect the other speaker’s profile by displaying two possible profiles, and ask which is more likely to be the profile of the person the Turker just spoke to.",5.2 Human Evaluation,[0],[0]
"More details of these measures are given in the Appendix.
",5.2 Human Evaluation,[0],[0]
"The results are reported in Table 4 for the best performing generative and ranking models, in both the No Persona and Self Persona categories, 100 dialogues each.",5.2 Human Evaluation,[0],[0]
We also evaluate the scores of human performance by replacing the chatbot with a human (another Turker).,5.2 Human Evaluation,[0],[0]
This effectively gives us upper bound scores which we can aim for with our models.,5.2 Human Evaluation,[0],[0]
"Finally, and importantly, we compare our models trained on PERSONA-CHAT with chit-chat models trained with the Twitter and OpenSubtitles datasets (2009 and 2018 versions) instead, following Vinyals and Le (2015).",5.2 Human Evaluation,[0],[0]
"Example chats from a few of the models are shown in the Appendix in Tables 7, 8, 9, 10, 11 and 12.
",5.2 Human Evaluation,[0],[0]
"Firstly, we see a difference in fluency, engagingness and consistency between all PERSONACHAT models and the models trained on OpenSubtitles and Twitter.",5.2 Human Evaluation,[0],[0]
"PERSONA-CHAT is a resource that is particularly strong at providing training data for the beginning of conversations, when the two speakers do not know each other, focusing on asking and answering questions, in contrast to other resources.",5.2 Human Evaluation,[0],[0]
"We also see suggestions of more subtle differences between the models, although these differences are obscured by the high variance of
the human raters’ evaluations.",5.2 Human Evaluation,[0],[0]
"For example, in both the generative and ranking model cases, models endowed with a persona can be detected by the human conversation partner, as evidenced by the persona detection accuracies, whilst maintaining fluency and consistency compared to their nonpersona driven counterparts.
",5.2 Human Evaluation,[0],[0]
"Finding the balance between fluency, engagement, consistency, and a persistent persona remains a strong challenge for future research.",5.2 Human Evaluation,[0],[0]
"Two tasks could naturally be considered using PERSONACHAT: (1) next utterance prediction during dialogue, and (2) profile prediction given dialogue history.",5.3 Profile Prediction,[0],[0]
"The main study of this work has been Task 1, where we have shown the use of profile information.",5.3 Profile Prediction,[0],[0]
"Task 2, however, can be used to extract such information.",5.3 Profile Prediction,[0],[0]
"While a full study is beyond the scope of this paper, we conducted some preliminary experiments, the details of which are in Appendix D. They show (i) human speaker’s profiles can be predicted from their dialogue with high accuracy (94.3%, similar to human performance in Table 4) or even from the model’s dialogue (23% with KV Profile Memory) showing the model is paying attention to the human’s interests.",5.3 Profile Prediction,[0],[0]
"Further, the accuracies clearly improve with further dialogue, as shown in Table 14.",5.3 Profile Prediction,[0],[0]
Combining Task 1 and Task 2 into a full system is an exciting area of future research.,5.3 Profile Prediction,[0],[0]
"In this work we have introduced the PERSONACHAT dataset, which consists of crowd-sourced dialogues where each participant plays the part of an assigned persona; and each (crowd-sourced) persona has a word-distinct paraphrase.",6 Conclusion & Discussion,[0],[0]
"We test various baseline models on this dataset, and show that models that have access to their own personas in addition to the state of the dialogue are scored as more consistent by annotators, although not more engaging.",6 Conclusion & Discussion,[0],[0]
"On the other hand, we show that models trained on PERSONA-CHAT (with or without personas) are more engaging than models trained on dialogue from other resources (movies, Twitter).
",6 Conclusion & Discussion,[0],[0]
We believe PERSONA-CHAT will be a useful resource for training components of future dialogue systems.,6 Conclusion & Discussion,[0],[0]
"Because we have paired human generated profiles and conversations, the data aids the construction of agents that have consistent per-
sonalities and viewpoints.",6 Conclusion & Discussion,[0],[0]
"Furthermore, predicting the profiles from a conversation moves chitchat tasks in the direction of goal-directed dialogue, which has metrics for success.",6 Conclusion & Discussion,[0],[0]
"Because we collect paraphrases of the profiles, they cannot be trivially matched; indeed, we believe the original and rephrased profiles are interesting as a semantic similarity dataset in their own right.",6 Conclusion & Discussion,[0],[0]
"We hope that the data will aid training agents that can ask questions about users’ profiles, remember the answers, and use them naturally in conversation.",6 Conclusion & Discussion,[0],[0]
"Chit-chat models are known to have several problems: they lack specificity, do not display a consistent personality and are often not very captivating.",abstractText,[0],[0]
In this work we present the task of making chit-chat more engaging by conditioning on profile information.,abstractText,[0],[0]
"We collect data and train models to (i) condition on their given profile information; and (ii) information about the person they are talking to, resulting in improved dialogues, as measured by next utterance prediction.",abstractText,[0],[0]
"Since (ii) is initially unknown, our model is trained to engage its partner with personal topics, and we show the resulting dialogue can be used to predict profile information about the interlocutors.",abstractText,[0],[0]
"Personalizing Dialogue Agents: I have a dog, do you have pets too?",title,[0],[0]
Machine Translation (MT) is a flagship of the recent successes and advances in the field of natural language processing.,1 Introduction,[0],[0]
"Its practical applications and use as a testbed for sequence transduction algorithms have spurred renewed interest in this topic.
",1 Introduction,[0],[0]
"While recent advances have reported near human-level performance on several language
†Sorbonne Universités, UPMC Univ Paris 06, CNRS, UMR 7606, LIP6, F-75005, Paris, France.
1https://github.com/facebookresearch/ UnsupervisedMT
pairs using neural approaches (Wu et al., 2016; Hassan et al., 2018), other studies have highlighted several open challenges (Koehn and Knowles, 2017; Isabelle et al., 2017; Sennrich, 2017).",1 Introduction,[0],[0]
A major challenge is the reliance of current learning algorithms on large parallel corpora.,1 Introduction,[0],[0]
"Unfortunately, the vast majority of language pairs have very little, if any, parallel data: learning algorithms need to better leverage monolingual data in order to make MT more widely applicable.
",1 Introduction,[0],[0]
"While a large body of literature has studied the use of monolingual data to boost translation performance when limited supervision is available, two recent approaches have explored the fully unsupervised setting (Lample et al., 2018; Artetxe et al., 2018), relying only on monolingual corpora in each language, as in the pioneering work by Ravi and Knight (2011).",1 Introduction,[0],[0]
"While there are subtle technical differences between these two recent works, we identify several common principles underlying their success.
",1 Introduction,[0],[0]
"First, they carefully initialize the MT system with an inferred bilingual dictionary.",1 Introduction,[0],[0]
"Second, they leverage strong language models, via training the sequence-to-sequence system (Sutskever et al., 2014; Bahdanau et al., 2015) as a denoising autoencoder (Vincent et al., 2008).",1 Introduction,[0],[0]
"Third, they turn the unsupervised problem into a supervised one by automatic generation of sentence pairs via back-translation (Sennrich et al., 2015a), i.e., the source-to-target model is applied to source sentences to generate inputs for training the targetto-source model, and vice versa.",1 Introduction,[0],[0]
"Finally, they constrain the latent representations produced by the encoder to be shared across the two languages.",1 Introduction,[0],[0]
"Empirically, these methods achieve remarkable results considering the fully unsupervised setting; for instance, about 15 BLEU points on the WMT’14 English-French benchmark.
",1 Introduction,[0],[0]
"The first contribution of this paper is a model
ar X
iv :1
80 4.
07 75
5v 2
[ cs
.C",1 Introduction,[0],[0]
"L
] 1
3 A
ug 2
01 8
that combines these two previous neural approaches, simplifying the architecture and loss function while still following the above mentioned principles.",1 Introduction,[0],[0]
The resulting model outperforms previous approaches and is both easier to train and tune.,1 Introduction,[0],[0]
"Then, we apply the same ideas and methodology to a traditional phrase-based statistical machine translation (PBSMT) system (Koehn et al., 2003).",1 Introduction,[0],[0]
"PBSMT models are well-known to outperform neural models when labeled data is scarce because they merely count occurrences, whereas neural models typically fit hundred of millions of parameters to learn distributed representations, which may generalize better when data is abundant but is prone to overfit when data is scarce.",1 Introduction,[0],[0]
"Our PBSMT model is simple, easy to interpret, fast to train and often achieves similar or better results than its NMT counterpart.",1 Introduction,[0],[0]
"We report gains of up to +10 BLEU points on widely used benchmarks when using our NMT model, and up to +12 points with our PBSMT model.",1 Introduction,[0],[0]
"Furthermore, we apply these methods to distant and low-resource languages, like EnglishRussian, English-Romanian and English-Urdu, and report competitive performance against both semi-supervised and supervised baselines.",1 Introduction,[0],[0]
"Learning to translate with only monolingual data is an ill-posed task, since there are potentially many ways to associate target with source sentences.",2 Principles of Unsupervised MT,[0],[0]
"Nevertheless, there has been exciting progress towards this goal in recent years, as discussed in the related work of Section 5.",2 Principles of Unsupervised MT,[0],[0]
"In this sec-
tion, we abstract away from the specific assumptions made by each prior work and instead focus on identifying the common principles underlying unsupervised MT.
",2 Principles of Unsupervised MT,[0],[0]
"We claim that unsupervised MT can be accomplished by leveraging the three components illustrated in Figure 1: (i) suitable initialization of the translation models, (ii) language modeling and (iii) iterative back-translation.",2 Principles of Unsupervised MT,[0],[0]
"In the following, we describe each of these components and later discuss how they can be better instantiated in both a neural model and phrase-based model.
",2 Principles of Unsupervised MT,[0],[0]
Initialization:,2 Principles of Unsupervised MT,[0],[0]
"Given the ill-posed nature of the task, model initialization expresses a natural prior over the space of solutions we expect to reach, jump-starting the process by leveraging approximate translations of words, short phrases or even sub-word units (Sennrich et al., 2015b).",2 Principles of Unsupervised MT,[0],[0]
"For instance, Klementiev et al. (2012) used a provided bilingual dictionary, while Lample et al. (2018) and Artetxe et al. (2018) used dictionaries inferred in an unsupervised way (Conneau et al., 2018; Artetxe et al., 2017).",2 Principles of Unsupervised MT,[0],[0]
"The motivating intuition is that while such initial “word-by-word” translation may be poor if languages or corpora are not closely related, it still preserves some of the original semantics.
",2 Principles of Unsupervised MT,[0],[0]
Language Modeling:,2 Principles of Unsupervised MT,[0],[0]
"Given large amounts of monolingual data, we can train language models on both source and target languages.",2 Principles of Unsupervised MT,[0],[0]
"These models express a data-driven prior about how sentences should read in each language, and they improve the quality of the translation models by per-
Algorithm 1:",2 Principles of Unsupervised MT,[0],[0]
"Unsupervised MT 1 Language models: Learn language models Ps and Pt
over source and target languages; 2 Initial translation models: Leveraging Ps and Pt,
learn two initial translation models, one in each direction: P (0)s→t and P (0) t→s;
3 for k=1 to N do 4 Back-translation: Generate source and target
sentences using the current translation models, P (k−1) t→s and P (k−1) s→t , factoring in language
models, Ps and Pt; 5 Train new translation models P (k)s→t and P (k) t→s
using the generated sentences and leveraging Ps and Pt;
6 end
forming local substitutions and word reorderings.
",2 Principles of Unsupervised MT,[0],[0]
Iterative Back-translation:,2 Principles of Unsupervised MT,[0],[0]
"The third principle is back-translation (Sennrich et al., 2015a), which is perhaps the most effective way to leverage monolingual data in a semi-supervised setting.",2 Principles of Unsupervised MT,[0],[0]
Its application in the unsupervised setting is to couple the source-to-target translation system with a backward model translating from the target to source language.,2 Principles of Unsupervised MT,[0],[0]
The goal of this model is to generate a source sentence for each target sentence in the monolingual corpus.,2 Principles of Unsupervised MT,[0],[0]
"This turns the daunting unsupervised problem into a supervised learning task, albeit with noisy source sentences.",2 Principles of Unsupervised MT,[0],[0]
"As the original model gets better at translating, we use the current model to improve the back-translation model, resulting in a coupled system trained with an iterative algorithm (He et al., 2016).",2 Principles of Unsupervised MT,[0],[0]
"Equipped with the three principles detailed in Section 2, we now discuss how to effectively combine them in the context of a NMT model (Section 3.1) and PBSMT model (Section 3.2).
",3 Unsupervised MT systems,[0],[0]
"In the reminder of the paper, we denote the space of source and target sentences by S and T , respectively, and the language models trained on source and target monolingual datasets by Ps and Pt, respectively.",3 Unsupervised MT systems,[0],[0]
"Finally, we denote by Ps→t and Pt→s the translation models from source to target and vice versa.",3 Unsupervised MT systems,[0],[0]
An overview of our approach is given in Algorithm 1.,3 Unsupervised MT systems,[0],[0]
"We now introduce a new unsupervised NMT method, which is derived from earlier work by Artetxe et al. (2018) and Lample et al. (2018).",3.1 Unsupervised NMT,[0],[0]
"We first discuss how the previously mentioned
three key principles are instantiated in our work, and then introduce an additional property of the system, the sharing of internal representations across languages, which is specific and critical to NMT.",3.1 Unsupervised NMT,[0],[0]
"From now on, we assume that a NMT model consists of an encoder and a decoder.",3.1 Unsupervised NMT,[0],[0]
"Section 4 gives the specific details of this architecture.
",3.1 Unsupervised NMT,[0],[0]
"Initialization: While prior work relied on bilingual dictionaries, here we propose a more effective and simpler approach which is particularly suitable for related languages.2 First, instead of considering words, we consider byte-pair encodings (BPE) (Sennrich et al., 2015b), which have two major advantages: they reduce the vocabulary size and they eliminate the presence of unknown words in the output translation.",3.1 Unsupervised NMT,[0],[0]
"Second, instead of learning an explicit mapping between BPEs in the source and target languages, we define BPE tokens by jointly processing both monolingual corpora.",3.1 Unsupervised NMT,[0],[0]
"If languages are related, they will naturally share a good fraction of BPE tokens, which eliminates the need to infer a bilingual dictionary.",3.1 Unsupervised NMT,[0],[0]
"In practice, we i) join the monolingual corpora, ii) apply BPE tokenization on the resulting corpus, and iii) learn token embeddings (Mikolov et al., 2013) on the same corpus, which are then used to initialize the lookup tables in the encoder and decoder.
Language Modeling: In NMT, language modeling is accomplished via denoising autoencoding, by minimizing:
Llm = Ex∼S",3.1 Unsupervised NMT,[0],[0]
[− logPs→s(x|C(x))],3.1 Unsupervised NMT,[0],[0]
+ Ey∼T [− logPt→t(y|C(y))],3.1 Unsupervised NMT,[0],[0]
"(1)
where C is a noise model with some words dropped and swapped as in Lample et al. (2018).",3.1 Unsupervised NMT,[0],[0]
"Ps→s andPt→t are the composition of encoder and decoder both operating on the source and target sides, respectively.
",3.1 Unsupervised NMT,[0],[0]
Back-translation: Let us denote by u∗(y) the sentence in the source language inferred from y ∈ T such that u∗(y) = argmaxPt→s(u|y).,3.1 Unsupervised NMT,[0],[0]
"Similarly, let us denote by v∗(x) the sentence in the target language inferred from x ∈ S such that v∗(x) = argmaxPs→t(v|x).",3.1 Unsupervised NMT,[0],[0]
"The pairs (u∗(y), y) and (x, v∗(x))) constitute automatically-generated parallel sentences which, following the back-translation principle, can be
2For unrelated languages, we need to infer a dictionary to properly initialize the embeddings (Conneau et al., 2018).
",3.1 Unsupervised NMT,[0],[0]
"used to train the two MT models by minimizing the following loss:
Lback = Ey∼T [− logPs→t(y|u∗(y))",3.1 Unsupervised NMT,[0],[0]
],3.1 Unsupervised NMT,[0],[0]
+ Ex∼S,3.1 Unsupervised NMT,[0],[0]
[− logPt→s(x|v∗(x))].,3.1 Unsupervised NMT,[0],[0]
"(2)
Note that when minimizing this objective function we do not back-prop through the reverse model which generated the data, both for the sake of simplicity and because we did not observe improvements when doing so.",3.1 Unsupervised NMT,[0],[0]
"The objective function minimized at every iteration of stochastic gradient descent, is simply the sum of Llm in Eq. 1 and Lback in Eq. 2.",3.1 Unsupervised NMT,[0],[0]
"To prevent the model from cheating by using different subspaces for the language modeling and translation tasks, we add an additional constraint which we discuss next.
",3.1 Unsupervised NMT,[0],[0]
"Sharing Latent Representations: A shared encoder representation acts like an interlingua, which is translated in the decoder target language regardless of the input source language.",3.1 Unsupervised NMT,[0],[0]
"This ensures that the benefits of language modeling, implemented via the denoising autoencoder objective, nicely transfer to translation from noisy sources and eventually help the NMT model to translate more fluently.",3.1 Unsupervised NMT,[0],[0]
"In order to share the encoder representations, we share all encoder parameters (including the embedding matrices since we perform joint tokenization) across the two languages to ensure that the latent representation of the source sentence is robust to the source language.",3.1 Unsupervised NMT,[0],[0]
"Similarly, we share the decoder parameters across the two languages.",3.1 Unsupervised NMT,[0],[0]
"While sharing the encoder is critical to get the model to work, sharing the decoder simply induces useful regularization.",3.1 Unsupervised NMT,[0],[0]
"Unlike prior work (Johnson et al., 2016), the first token of the decoder specifies the language the module is operating with, while the encoder does not have any language identifier.",3.1 Unsupervised NMT,[0],[0]
"In this section, we discuss how to perform unsupervised machine translation using a PhraseBased Statistical Machine Translation (PBSMT) system (Koehn et al., 2003) as the underlying backbone model.",3.2 Unsupervised PBSMT,[0],[0]
"Note that PBSMT models are known to perform well on low-resource language pairs, and are therefore a potentially good alternative to neural models in the unsupervised setting.
",3.2 Unsupervised PBSMT,[0],[0]
"When translating from x to y, a PBSMT system scores y according to: argmaxy P (y|x) = argmaxy P (x|y)P (y), where P (x|y) is derived
from so called “phrase tables”, and P (y) is the score assigned by a language model.
",3.2 Unsupervised PBSMT,[0],[0]
"Given a dataset of bitexts, PBSMT first infers an alignment between source and target phrases.",3.2 Unsupervised PBSMT,[0],[0]
"It then populates phrase tables, whose entries store the probability that a certain n-gram in the source/target language is mapped to another ngram in the target/source language.
",3.2 Unsupervised PBSMT,[0],[0]
"In the unsupervised setting, we can easily train a language model on monolingual data, but it is less clear how to populate the phrase tables, which are a necessary component for good translation.",3.2 Unsupervised PBSMT,[0],[0]
"Fortunately, similar to the neural case, the principles of Section 2 are effective to solve this problem.
",3.2 Unsupervised PBSMT,[0],[0]
Initialization: We populate the initial phrase tables (from source to target and from target to source) using an inferred bilingual dictionary built from monolingual corpora using the method proposed by Conneau et al. (2018).,3.2 Unsupervised PBSMT,[0],[0]
"In the following, we will refer to phrases as single words, but the very same arguments trivially apply to longer ngrams.",3.2 Unsupervised PBSMT,[0],[0]
"Phrase tables are populated with the scores of the translation of a source word to:
p(tj |si) = e 1 T cos(e(tj),We(si))∑
k e 1 T cos(e(tk),We(si))
, (3)
where tj is the j-th word in the target vocabulary and si is the i-th word in the source vocabulary, T is a hyper-parameter used to tune the peakiness of the distribution3, W is the rotation matrix mapping the source embeddings into the target embeddings (Conneau et al., 2018), and e(x) is the embedding of x.
Language Modeling: Both in the source and target domains we learn smoothed n-gram language models using KenLM (Heafield, 2011), although neural models could also be considered.",3.2 Unsupervised PBSMT,[0],[0]
"These remain fixed throughout training iterations.
",3.2 Unsupervised PBSMT,[0],[0]
"Iterative Back-Translation: To jump-start the iterative process, we use the unsupervised phrase tables and the language model on the target side to construct a seed PBSMT.",3.2 Unsupervised PBSMT,[0],[0]
We then use this model to translate the source monolingual corpus into the target language (back-translation step).,3.2 Unsupervised PBSMT,[0],[0]
"Once the data has been generated, we train a PBSMT in supervised mode to map the generated data back to the original source sentences.",3.2 Unsupervised PBSMT,[0],[0]
"Next, we perform
3We set T = 30 in all our experiments, following the setting of Smith et al. (2017).
",3.2 Unsupervised PBSMT,[0],[0]
both generation and training process but in the reverse direction.,3.2 Unsupervised PBSMT,[0],[0]
"We repeat these steps as many times as desired (see Algorithm 2 in Section A).
",3.2 Unsupervised PBSMT,[0],[0]
"Intuitively, many entries in the phrase tables are not correct because the input to the PBSMT at any given point during training is noisy.",3.2 Unsupervised PBSMT,[0],[0]
"Despite that, the language model may be able to fix some of these mistakes at generation time.",3.2 Unsupervised PBSMT,[0],[0]
"As long as that happens, the translation improves, and with that also the phrase tables at the next round.",3.2 Unsupervised PBSMT,[0],[0]
"There will be more entries that correspond to correct phrases, which makes the PBSMT model stronger because it has bigger tables and it enables phrase swaps over longer spans.",3.2 Unsupervised PBSMT,[0],[0]
We first describe the datasets and experimental protocol we used.,4 Experiments,[0],[0]
"Then, we compare the two proposed unsupervised approaches to earlier attempts, to semi-supervised methods and to the very same models but trained with varying amounts of labeled data.",4 Experiments,[0],[0]
We conclude with an ablation study to understand the relative importance of the three principles introduced in Section 2.,4 Experiments,[0],[0]
"We consider five language pairs: English-French, English-German, English-Romanian, EnglishRussian and English-Urdu.",4.1 Datasets and Methodology,[0],[0]
"The first two pairs are used to compare to recent work on unsupervised MT (Artetxe et al., 2018; Lample et al., 2018).",4.1 Datasets and Methodology,[0],[0]
"The last three pairs are instead used to test our PBSMT unsupervised method on truly low-resource pairs (Gu et al., 2018) or unrelated languages that do not even share the same alphabet.
",4.1 Datasets and Methodology,[0],[0]
"For English, French, German and Russian, we use all available sentences from the WMT monolingual News Crawl datasets from years 2007 through 2017.",4.1 Datasets and Methodology,[0],[0]
"For Romanian, the News Crawl dataset is only composed of 2.2 million sentences, so we augment it with the monolingual data from WMT’16, resulting in 2.9 million sentences.",4.1 Datasets and Methodology,[0],[0]
"In Urdu, we use the dataset of Jawaid et al. (2014), composed of about 5.5 million monolingual sentences.",4.1 Datasets and Methodology,[0],[0]
"We report results on newstest 2014 for en− fr, and newstest 2016 for en− de, en− ro and en− ru.",4.1 Datasets and Methodology,[0],[0]
"For Urdu, we use the LDC2010T21 and LDC2010T23 corpora each with about 1800 sentences as validation and test sets, respectively.
",4.1 Datasets and Methodology,[0],[0]
"We use Moses scripts (Koehn et al., 2007) for tokenization.",4.1 Datasets and Methodology,[0],[0]
"NMT is trained with 60,000 BPE
codes.",4.1 Datasets and Methodology,[0],[0]
"PBSMT is trained with true-casing, and by removing diacritics from Romanian on the source side to deal with their inconsistent use across the monolingual dataset (Sennrich et al., 2016).",4.1 Datasets and Methodology,[0],[0]
Both the NMT and PBSMT approaches require either cross-lingual BPE embeddings (to initialize the shared lookup tables) or n-gram embeddings (to initialize the phrase table).,4.2 Initialization,[0],[0]
"We generate embeddings using fastText (Bojanowski et al., 2017) with an embedding dimension of 512, a context window of size 5 and 10 negative samples.",4.2 Initialization,[0],[0]
"For NMT, fastText is applied on the concatenation of source and target corpora, which results in crosslingual BPE embeddings.
",4.2 Initialization,[0],[0]
"For PBSMT, we generate n-gram embeddings on the source and target corpora independently, and align them using the MUSE library (Conneau et al., 2018).",4.2 Initialization,[0],[0]
"Since learning unique embeddings of every possible phrase would be intractable, we consider the most frequent 300,000 source phrases, and align each of them to its 200 nearest neighbors in the target space, resulting in a phrase table of 60 million phrase pairs which we score using the formula in Eq. 3.
",4.2 Initialization,[0],[0]
"In practice, we observe a small but significant difference of about 1 BLEU point using a phrase table of bigrams compared to a phrase table of unigrams, but did not observe any improvement using longer phrases.",4.2 Initialization,[0],[0]
"Table 1 shows an extract of a French-English unsupervised phrase table, where we can see that unigrams are correctly aligned to bigrams, and vice versa.",4.2 Initialization,[0],[0]
The next subsections provide details about the architecture and training procedure of our models.,4.3 Training,[0],[0]
"In this study, we use NMT models built upon LSTM (Hochreiter and Schmidhuber, 1997) and Transformer (Vaswani et al., 2017) cells.",4.3.1 NMT,[0],[0]
For the LSTM model we use the same architecture as in Lample et al. (2018).,4.3.1 NMT,[0],[0]
"For the Transformer, we use 4 layers both in the encoder and in the decoder.",4.3.1 NMT,[0],[0]
"Following Press and Wolf (2016), we share all lookup tables between the encoder and the decoder, and between the source and the target languages.",4.3.1 NMT,[0],[0]
The dimensionality of the embeddings and of the hidden layers is set to 512.,4.3.1 NMT,[0],[0]
"We used the Adam optimizer (Kingma and Ba, 2014) with a learning rate of 10−4, β1 = 0.5, and a batch size of 32.",4.3.1 NMT,[0],[0]
"At decoding time, we generate greedily.",4.3.1 NMT,[0],[0]
The PBSMT uses Moses’ default smoothed ngram language model with phrase reordering disabled during the very first generation.,4.3.2 PBSMT,[0],[0]
PBSMT is trained in a iterative manner using Algorithm 2.,4.3.2 PBSMT,[0],[0]
"At each iteration, we translate 5 million sentences randomly sampled from the monolingual dataset in the source language.",4.3.2 PBSMT,[0],[0]
"Except for initialization, we use phrase tables with phrases up to length 4.",4.3.2 PBSMT,[0],[0]
"Moses’ implementation of PBSMT has 15 hyperparameters, such as relative weighting of each scoring function, word penalty, etc.",4.4 Model selection,[0],[0]
"In this work, we consider two methods to set these hyperparameters.",4.4 Model selection,[0],[0]
"We either set them to their default values in the toolbox, or we set them using a small validation set of parallel sentences.",4.4 Model selection,[0],[0]
"It turns out
that with only 100 labeled sentences in the validation set, PBSMT would overfit to the validation set.",4.4 Model selection,[0],[0]
"For instance, on en → fr, PBSMT tuned on 100 parallel sentences obtains a BLEU score of 26.42 on newstest 2014, compared to 27.09 with default hyper-parameters, and 28.02 when tuned on the 3000 parallel sentences of newstest 2013.",4.4 Model selection,[0],[0]
"Therefore, unless otherwise specified, all PBSMT models considered in the paper use default hyperparameter values, and do not use any parallel resource whatsoever.
",4.4 Model selection,[0],[0]
"For the NMT, we also consider two model selection procedures: an unsupervised criterion based on the BLEU score of a “round-trip” translation (source → target → source and target → source → target) as in Lample et al. (2018), and crossvalidation using a small validation set with 100 parallel sentences.",4.4 Model selection,[0],[0]
"In our experiments, we found the unsupervised criterion to be highly correlated with the test metric when using the Transformer model, but not always for the LSTM.",4.4 Model selection,[0],[0]
"Therefore, unless otherwise specified, we select the best LSTM models using a small validation set of 100 parallel sentences, and the best Transformer models with the unsupervised criterion.",4.4 Model selection,[0],[0]
The results reported in Table 2 show that our unsupervised NMT and PBSMT systems largely outperform previous unsupervised baselines.,4.5 Results,[0],[0]
We report large gains on all language pairs and directions.,4.5 Results,[0],[0]
"For instance, on the en → fr task, our unsupervised PBSMT obtains a BLEU score of 28.1, outperforming the previous best result by more than 11 BLEU points.",4.5 Results,[0],[0]
"Even on a more complex task like en → de, both PBSMT and NMT surpass the baseline score by more than 10 BLEU
points.",4.5 Results,[0],[0]
"Even before iterative back-translation, the PBSMT model significantly outperforms previous approaches, and can be trained in a few minutes.
",4.5 Results,[0],[0]
Table 3 illustrates the quality of the PBSMT model during the iterative training process.,4.5 Results,[0],[0]
"For instance, the fr → en model obtains a BLEU score of 17.5 at iteration 0 – i.e. after the unsupervised phrase table construction – while it achieves a score of 27.2 at iteration 4.",4.5 Results,[0],[0]
This highlights the importance of multiple back-translation iterations.,4.5 Results,[0],[0]
The last rows of Table 3 also show that we get additional gains by further tuning the NMT model on the data generated by PBSMT (PBSMT + NMT).,4.5 Results,[0],[0]
We simply add the data generated by the unsupervised PBSMT system to the back-translated data produced by the NMT model.,4.5 Results,[0],[0]
"By combining PBSMT and NMT, we achieve BLEU scores of 20.2 and 25.2 on the challenging en → de and de → en translation tasks.",4.5 Results,[0],[0]
"While we also tried bootstraping the PBSMT model with back-translated data generated by a NMT model (NMT + PBSMT), this did not improve over PBSMT alone.
",4.5 Results,[0],[0]
"Next, we compare to fully supervised models.",4.5 Results,[0],[0]
Figure 2 shows the performance of the same architectures trained in a fully supervised way using parallel training sets of varying size.,4.5 Results,[0],[0]
"The unsupervised PBSMT model achieves the same performance as its supervised counterpart trained on more than 100,000 parallel sentences.
",4.5 Results,[0],[0]
This is confirmed on low-resource languages.,4.5 Results,[0],[0]
"In particular, on ro → en, our unsupervised PBSMT model obtains a BLEU score of 23.9, outperforming Gu et al. (2018)’s method by 1 point, despite its use of 6,000 parallel sentences, a seed dictionary, and a multi-NMT system combining par-
allel resources from 5 different languages.",4.5 Results,[0],[0]
"On Russian, our unsupervised PBSMT model obtains a BLEU score of 16.6 on ru→ en, showing that this approach works reasonably well on distant languages.",4.5 Results,[0],[0]
"Finally we train on ur → en, which is both low resource and distant.",4.5 Results,[0],[0]
"In a supervised mode, PBSMT using the noisy and outof-domain 800,000 parallel sentences from Tiedemann (2012) achieves a BLEU score of 9.8.",4.5 Results,[0],[0]
"Instead, our unsupervised PBSMT system achieves 12.3 BLEU using only a validation set of 1800 sentences to tune Moses hyper-parameters.",4.5 Results,[0],[0]
"In Figure 3 we report results from an ablation study, to better understand the importance of the three principles when training PBSMT.",4.6 Ablation Study,[0],[0]
"This study shows that more iterations only partially compensate for lower quality phrase table initialization (Left), language models trained over less data (Middle) or less monolingual data (Right).",4.6 Ablation Study,[0],[0]
"Moreover, the influence of the quality of the language model becomes more prominent as we iterate.",4.6 Ablation Study,[0],[0]
"These findings suggests that better initialization methods and more powerful language models may further improve our results.
",4.6 Ablation Study,[0],[0]
We perform a similar ablation study for the NMT system (see Appendix).,4.6 Ablation Study,[0],[0]
"We find that backtranslation and auto-encoding are critical components, without which the system fails to learn.",4.6 Ablation Study,[0],[0]
"We also find that initialization of embeddings is very important, and we gain 7 BLEU points compared to prior work (Artetxe et al., 2018; Lample et al., 2018) by learning BPE embeddings over the concatenated monolingual corpora.",4.6 Ablation Study,[0],[0]
A large body of literature has studied using monolingual data to boost translation performance when limited supervision is available.,5 Related Work,[0],[0]
"This limited supervision is typically provided as a small set of parallel sentences (Sennrich et al., 2015a; Gulcehre et al., 2015; He et al., 2016; Gu et al., 2018; Wang et al., 2018); large sets of parallel sentences in related languages (Firat et al., 2016; Johnson et al., 2016; Chen et al., 2017; Zheng et al., 2017); cross-lingual dictionaries (Klementiev et al., 2012; Irvine and Callison-Burch, 2014, 2016); or comparable corpora (Munteanu et al., 2004; Irvine and Callison-Burch, 2013).
",5 Related Work,[0],[0]
"Learning to translate without any form of supervision has also attracted interest, but is challenging.",5 Related Work,[0],[0]
"In their seminal work, Ravi and Knight (2011) leverage linguistic prior knowledge to reframe the unsupervised MT task as deciphering and demonstrate the feasibility on short sentences with limited vocabulary.",5 Related Work,[0],[0]
"Earlier work by Carbonell et al. (2006) also aimed at unsupervised MT, but leveraged a bilingual dictionary to seed the translation.",5 Related Work,[0],[0]
"Both works rely on a language model on the target side to correct for translation fluency.
",5 Related Work,[0],[0]
"Subsequent work (Klementiev et al., 2012; Irvine and Callison-Burch, 2014, 2016) relied on bilingual dictionaries, small parallel corpora of several thousand sentences, and linguistically motivated features to prune the search space.",5 Related Work,[0],[0]
Irvine and Callison-Burch (2014) use monolingual data to expand phrase tables learned in a supervised setting.,5 Related Work,[0],[0]
"In our work we also expand phrase tables, but we initialize them with an inferred bilingual n-gram dictionary, following work from the connectionist community aimed at improving PBSMT with neural models (Schwenk, 2012; Kalchbrenner and Blunsom, 2013; Cho et al., 2014).
",5 Related Work,[0],[0]
"In recent years back-translation has become a
popular method of augmenting training sets with monolingual data on the target side (Sennrich et al., 2015a), and has been integrated in the “dual learning” framework of He et al. (2016) and subsequent extensions (Wang et al., 2018).",5 Related Work,[0],[0]
"Our approach is similar to the dual learning framework, except that in their model gradients are backpropagated through the reverse model and they pretrain using a relatively large amount of labeled data, whereas our approach is fully unsupervised.
",5 Related Work,[0],[0]
"Finally, our work can be seen as an extension of recent studies (Lample et al., 2018; Artetxe et al., 2018; Yang et al., 2018) on fully unsupervised MT with two major contributions.",5 Related Work,[0],[0]
"First, we propose a much simpler and more effective initialization method for related languages.",5 Related Work,[0],[0]
"Second, we abstract away three principles of unsupervised MT and apply them to a PBSMT, which even outperforms the original NMT.",5 Related Work,[0],[0]
"Moreover, our results show that the combination of PBSMT and NMT achieves even better performance.",5 Related Work,[0],[0]
"In this work, we identify three principles underlying recent successes in fully unsupervised MT and show how to apply these principles to PBSMT and NMT systems.",6 Conclusions and Future Work,[0],[0]
"We find that PBSMT systems often outperform NMT systems in the fully unsupervised setting, and that by combining these systems we can greatly outperform previous approaches from the literature.",6 Conclusions and Future Work,[0],[0]
"We apply our approach to several popular benchmark language pairs, obtaining state of the art results, and to several low-resource and under-explored language pairs.
",6 Conclusions and Future Work,[0],[0]
"It’s an open question whether there are more effective instantiations of these principles or other principles altogether, and under what conditions our iterative process is guaranteed to converge.",6 Conclusions and Future Work,[0],[0]
Future work may also extend to the semisupervised setting.,6 Conclusions and Future Work,[0],[0]
"In this Appendix, we report the detailed algorithm for unsupervised PBSMT, a detailed ablation study using NMT and conclude with some example translations.
",A Supplemental Material,[0],[0]
"Algorithm 2: Unsupervised PBSMT 1 Learn bilingual dictionary using Conneau
et al. (2018); 2 Populate phrase tables using Eq. 3 and learn a
language model to build P (0)s→t;
3 Use P (0)s→t to translate the source monolingual
dataset, yielding D(0)t ; 4 for i=1 to N do 5 Train model P (i)t→s using D (i−1) t ; 6 Use P (i)t→s to translate the target monolingual dataset, yielding D(i)s ; 7 Train model P (i)s→t using D (i) s ; 8 Use P (i)s→t to translate the source monolingual dataset, yielding D(i)t ; 9 end
A.1 NMT Ablation study In Table 4 we report results from an ablation study we performed for NMT using the Transformer architecture.",A Supplemental Material,[0],[0]
"All results are for the en→ fr task.
",A Supplemental Material,[0],[0]
"First, we analyze the effect of different initialization methods for the embedding matrices.",A Supplemental Material,[0],[0]
"If we switch from BPE tokens to words, BLEU drops by 4 points.",A Supplemental Material,[0],[0]
"If we used BPE but train embeddings in each language independently and then map them via MUSE (Conneau et al., 2018), BLEU drops by 3 points.",A Supplemental Material,[0],[0]
"Finally, compared to the word aligned procedure used by Lample et al. (2018), based on words and MUSE, the gain is about 7 points.",A Supplemental Material,[0],[0]
"To stress the importance of initialization, we also report performance using random initialization of BPE embeddings.",A Supplemental Material,[0],[0]
"In this case, convergence is much slower and to a much lower accuracy, achieving a BLEU score of 10.5.
",A Supplemental Material,[0],[0]
"The table also demonstrates the critical importance of the auto-encoding and back-translation terms in the loss, and the robustness of our approach to choice of architectures.
",A Supplemental Material,[0],[0]
"A.2 Qualitative study Table 5 shows example translations from the French-English newstest 2014 dataset at different
iterations of the learning algorithm for both NMT and PBSMT models.",A Supplemental Material,[0],[0]
"Prior to the first iteration of back-translation, using only the unsupervised phrase table, the PBSMT translations are similar to word-by-word translations and do not respect the syntax of the target language, yet still contain most of the semantics of the original sentences.",A Supplemental Material,[0],[0]
"As we increase the number of epochs in NMT and as we iterate for PBSMT, we observe a continuous improvement in the quality of the unsupervised translations.",A Supplemental Material,[0],[0]
"Interestingly, in the second example, both the PBSMT and NMT models fail to adapt to the polysemy of the French word “langue”, which can be translated as “tongue” or “language” in English.",A Supplemental Material,[0],[0]
"These translations were both present in the unsupervised phrase table, but the conditional probability of “language” to be the correct translation of “langue” was very high compared to the one of “tongue”: P (language|langue) = 0.92, while P (tongue|langue) = 0.0005.",A Supplemental Material,[0],[0]
"As a comparison, the phrase table of a Moses model trained in a supervised way contains P (language|langue) = 0.633, P (tongue|langue) = 0.0076, giving a higher probability for “langue” to be properly translated.",A Supplemental Material,[0],[0]
"This underlines the importance of the initial unsupervised phrase alignment procedure, as it was shown in Figure 1.
",A Supplemental Material,[0],[0]
"Finally, in Table 6 we report a random subset of test sentences translated from Russian to English, showing that the model mostly retains the semantics, while making some mistakes in the grammar as well as in the choice of words and entities.",A Supplemental Material,[0],[0]
"In Table 7, we show examples of translations from German to English with PBSMT, NMT, and PBSMT+NMT to show how the combination of these models performs better than them individually.
",A Supplemental Material,[0],[0]
"German→ English
Source Flüchtlinge brauchen Unterkünfte : Studie warnt vor Wohnungslücke PBSMT Refugees need accommodation : Study warns Wohnungslücke NMT Refugees need forestry study to warn housing gap PBSMT+NMT",A Supplemental Material,[0],[0]
"Refugees need accommodation : Study warns of housing gap Reference Refugees need accommodation : study warns of housing gap
Source Konflikte : Mehrheit unterstützt die Anti-IS-Ausbildungsmission PBSMT Conflict : Majority supports Anti-IS-Ausbildungsmission NMT Tensions support majority anti-IS-recruiting mission PBSMT+NMT",A Supplemental Material,[0],[0]
"Tensions : Majority supports the anti-IS-recruitment mission Reference Conflicts : the majority support anti ISIS training mission
Source Roboterautos : Regierung will Vorreiterrolle für Deutschland PBSMT Roboterautos : Government will step forward for Germany NMT Robotic cars will pre-reiterate government for Germany PBSMT+NMT",A Supplemental Material,[0],[0]
"Robotic cars : government wants pre-orders for Germany Reference Robot cars : Government wants Germany to take a leading role
Source Pfund steigt durch beschleunigtes Lohnwachstum im Vereinigten Königreich PBSMT Pound rises as UK beschleunigtes Lohnwachstum .",A Supplemental Material,[0],[0]
NMT £ rises through rapid wage growth in the U.S. PBSMT+NMT,A Supplemental Material,[0],[0]
"Pound rises by accelerating wage growth in the United Kingdom Reference Pound rises as UK wage growth accelerates
Source 46 Prozent sagten , dass sie die Tür offen lassen , um zu anderen Kandidaten zu wechseln .",A Supplemental Material,[0],[0]
PBSMT 52 per cent said that they left the door open to them to switch to other candidates .,A Supplemental Material,[0],[0]
NMT 46 percent said that they would let the door open to switch to other candidates .,A Supplemental Material,[0],[0]
PBSMT+NMT,A Supplemental Material,[0],[0]
46 percent said that they left the door open to switch to other candidates .,A Supplemental Material,[0],[0]
"Reference 46 percent said they are leaving the door open to switching candidates .
",A Supplemental Material,[0],[0]
"Source Selbst wenn die Republikaner sich um einen anderen Kandidaten sammelten , schlägt Trump noch fast jeden .",A Supplemental Material,[0],[0]
"PBSMT Even if the Republicans a way to other candidates collected , beats Trump , yet almost everyone .",A Supplemental Material,[0],[0]
NMT,A Supplemental Material,[0],[0]
"Even if Republicans are to donate to a different candidate , Trump takes to almost every place . PBSMT+NMT",A Supplemental Material,[0],[0]
"Even if Republicans gather to nominate another candidate , Trump still beats nearly everyone .",A Supplemental Material,[0],[0]
"Reference Even if Republicans rallied around another candidate , Trump still beats almost everyone .
",A Supplemental Material,[0],[0]
"Source Ich glaube sicher , dass es nicht genügend",A Supplemental Material,[0],[0]
"Beweise gibt , um ein Todesurteil zu rechtfertigen .",A Supplemental Material,[0],[0]
PBSMT I think for sure that there was not enough evidence to justify a death sentence .,A Supplemental Material,[0],[0]
NMT I believe it ’s not sure there ’s enough evidence to justify a executions .,A Supplemental Material,[0],[0]
PBSMT+NMT,A Supplemental Material,[0],[0]
I sure believe there is not enough evidence to justify a death sentence .,A Supplemental Material,[0],[0]
"Reference I certainly believe there was not enough evidence to justify a death sentence .
",A Supplemental Material,[0],[0]
"Source Auch wenn der Laden gut besucht ist , ist es nicht schwer , einen Parkplatz zu finden .",A Supplemental Material,[0],[0]
"PBSMT Even if the store visited it is , it is not hard to find a parking lot .",A Supplemental Material,[0],[0]
"NMT To be sure , the shop is well visited , but it ’s not a troubled driveway .",A Supplemental Material,[0],[0]
PBSMT+NMT,A Supplemental Material,[0],[0]
"Even if the shop is well visited , it is not hard to find a parking lot .",A Supplemental Material,[0],[0]
"Reference While the store can get busy , parking is usually not hard to find .
",A Supplemental Material,[0],[0]
"Source Die Suite , in dem der kanadische Sänger wohnt , kostet am Tag genau so viel , wie ihre Mama Ewa",A Supplemental Material,[0],[0]
im halben Jahr verdient .,A Supplemental Material,[0],[0]
"PBSMT The suite in which the Canadian singer grew up , costs on the day so much as their mum Vera in half year earned .",A Supplemental Material,[0],[0]
"NMT The Suite , in which the Canadian singer lived , costs day care exactly as much as her mom Ewa earned during the decade .",A Supplemental Material,[0],[0]
PBSMT+NMT,A Supplemental Material,[0],[0]
"The suite , in which the Canadian singer lived , costs a day precisely as much as her mom Ewa earned in half .",A Supplemental Material,[0],[0]
"Reference The suite where the Canadian singer is staying costs as much for one night as her mother Ewa earns in six months .
",A Supplemental Material,[0],[0]
"Source Der durchschnittliche BMI unter denen , die sich dieser Operation unterzogen , sank von 31 auf",A Supplemental Material,[0],[0]
"24,5 bis",A Supplemental Material,[0],[0]
Ende des fünften Jahres in dieser Studie .,A Supplemental Material,[0],[0]
PBSMT The average BMI among those who undergoing this operation decreased by 22 to 325 by the end of fifth year in this study .,A Supplemental Material,[0],[0]
NMT,A Supplemental Material,[0],[0]
"The average BMI among those who undergo surgery , sank from 31 to 24,500 by the end of the fifth year in that study .",A Supplemental Material,[0],[0]
PBSMT+NMT,A Supplemental Material,[0],[0]
The average BMI among those who undergo this surgery fell from 31 to 24.5 by the end of the fifth year in this study .,A Supplemental Material,[0],[0]
Reference,A Supplemental Material,[0],[0]
"The average BMI among those who had surgery fell from 31 to 24.5 by the end of their fifth year in the study .
",A Supplemental Material,[0],[0]
"Source Die 300 Plakate sind von Künstlern , die ihre Arbeit im Museum für grausame Designs in Banksys Dismaland ausgestellt haben .",A Supplemental Material,[0],[0]
PBSMT The 250 posters are by artists and their work in the museum for gruesome designs in Dismaland Banksys have displayed .,A Supplemental Material,[0],[0]
NMT,A Supplemental Material,[0],[0]
The 300 posters are posters of artists who have their work Museum for real-life Designs in Banksys and Dismalausgestellt .,A Supplemental Material,[0],[0]
PBSMT+NMT,A Supplemental Material,[0],[0]
The 300 posters are from artists who have displayed their work at the Museum of cruel design in Banksys Dismaland .,A Supplemental Material,[0],[0]
Reference,A Supplemental Material,[0],[0]
"The 300 posters are by artists who exhibited work at the Museum of Cruel Designs in Banksy ’s Dismaland .
",A Supplemental Material,[0],[0]
Source Bis zum Ende des Tages gab es einen weiteren Tod :,A Supplemental Material,[0],[0]
"Lamm nahm sich das Leben , als die Polizei ihn einkesselte .",A Supplemental Material,[0],[0]
PBSMT At the end of the day it ’s a further death :,A Supplemental Material,[0],[0]
Lamb took out life as police him einkesselte .,A Supplemental Material,[0],[0]
NMT,A Supplemental Material,[0],[0]
By the end of the day there was another death : Lamm emerged this year as police were trying to looseless him .,A Supplemental Material,[0],[0]
PBSMT+NMT,A Supplemental Material,[0],[0]
"By the end of the day , there ’s another death : Lamm took out life as police arrived to him .",A Supplemental Material,[0],[0]
"Reference By the end of the day , there would be one more death : Lamb took his own life as police closed in on him .
",A Supplemental Material,[0],[0]
"Source Chaos folgte an der Grenze , als Hunderte von Migranten sich in einem Niemandsland ansammelten und serbische Beamte mit Empörung reagierten .",A Supplemental Material,[0],[0]
"PBSMT Chaos followed at the border , as hundreds of migrants in a frontier ansammelten and Serb officers reacted with outrage .",A Supplemental Material,[0],[0]
NMT Chaos followed an avalanche as hundreds of thousands of immigrants fled to a mandsdom in answerage and Serbian officers responded with outrage . PBSMT+NMT,A Supplemental Material,[0],[0]
Chaos followed at the border as hundreds of immigrants gathered in a bush town and Serb officers reacted with outrage .,A Supplemental Material,[0],[0]
"Reference Chaos ensued at the border , as hundreds of migrants piled up in a no man ’s land , and Serbian officials reacted with outrage .
",A Supplemental Material,[0],[0]
"Source ” Zu unserer Reise gehörten viele dunkle Bahn- und Busfahrten , ebenso Hunger , Durst , Kälte und Angst ” , schrieb sie .",A Supplemental Material,[0],[0]
"PBSMT ” To our trip included many of the dark rail and bus rides , such as hunger , thirst , cold and fear , ” she wrote .",A Supplemental Material,[0],[0]
NMT ”,A Supplemental Material,[0],[0]
"During our trip , many included dark bus and bus trips , especially hunger , Durst , and cold fear , ” she wrote . PBSMT+NMT ”",A Supplemental Material,[0],[0]
"Our trip included many dark rail and bus journeys , as well as hunger , thirst , cold and fear , ” she wrote .",A Supplemental Material,[0],[0]
"Reference ” Our journey involved many dark train and bus rides , as well as hunger , thirst , cold and fear , ” she wrote .
",A Supplemental Material,[0],[0]
Table 7: Unsupervised translations: German-English.,A Supplemental Material,[0],[0]
"Examples of translations on the German-English pair of newstest 2016 using the PBSMT, NMT, and PBSMT+NMT.",A Supplemental Material,[0],[0]
"Machine translation systems achieve near human-level performance on some languages, yet their effectiveness strongly relies on the availability of large amounts of parallel sentences, which hinders their applicability to the majority of language pairs.",abstractText,[0],[0]
This work investigates how to learn to translate when having access to only large monolingual corpora in each language.,abstractText,[0],[0]
"We propose two model variants, a neural and a phrase-based model.",abstractText,[0],[0]
"Both versions leverage a careful initialization of the parameters, the denoising effect of language models and automatic generation of parallel data by iterative back-translation.",abstractText,[0],[0]
"These models are significantly better than methods from the literature, while being simpler and having fewer hyper-parameters.",abstractText,[0],[0]
"On the widely used WMT’14 English-French and WMT’16 German-English benchmarks, our models respectively obtain 28.1 and 25.2 BLEU points without using a single parallel sentence, outperforming the state of the art by more than 11 BLEU points.",abstractText,[0],[0]
"On low-resource languages like English-Urdu and English-Romanian, our methods achieve even better results than semisupervised and supervised approaches leveraging the paucity of available bitexts.",abstractText,[0],[0]
Our code for NMT and PBSMT is publicly available.1,abstractText,[0],[0]
Phrase-Based & Neural Unsupervised Machine Translation,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 559–564 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
559",text,[0],[0]
Extractive question answering (QA) is the task of selecting an answer phrase (span) to a question given an evidence document.,1 Introduction,[0],[0]
"Due to the easiness of evaluation (compared to generative QA) and the fine-grainess of the answer (compared to sentence-level QA), it has become one of the most popular QA tasks, driven by massive new datasets such as SQuAD (Rajpurkar et al., 2016) and TriviaQA (Joshi et al., 2017).",1 Introduction,[0],[0]
"Current QA models heavily rely on explicitly learning the interaction between the evidence document and the question using neural attention mechanisms (Wang and Jiang, 2017; Xiong et al., 2017; Seo et al., 2017; Lee et al., 2016, inter alia), in which the model is fully aware of the question before or as it reads the document.",1 Introduction,[0],[0]
"As a result, despite significant advances, they have not led to the standalone representation of document discourse which is never-
∗Most work done during internship with Google AI.
",1 Introduction,[0],[0]
theless a key goal of research in reading comprehension.,1 Introduction,[0],[0]
"Furthermore, QA models that condition the document representation on a question have the practical scalability downside that the entire model should be re-applied on the same document for every question.
",1 Introduction,[0],[0]
"In this paper, we formalize a modular variant of the QA task, Phrase Indexed Question Answering (PIQA), that enforces complete independence between document encoder and question encoder (Figure 1).",1 Introduction,[0],[0]
"In PIQA, all documents are processed independently of any question to generate phrase index vectors (blue nodes in the figure) for each answer candidate (left boxes in the figure).",1 Introduction,[0],[0]
"Similarly, the questions are independently mapped to query vectors (red nodes in figure).",1 Introduction,[0],[0]
"Then, at inference time, the answer is obtained by retrieving the nearest indexed phrase vector to the query vector.",1 Introduction,[0],[0]
"Hence the algorithms aimed at tackling PIQA have the inherent benefit of modularity and scalability compared to current QA systems.
",1 Introduction,[0],[0]
"The task setup is analogous to how documents or sentences are retrieved in modern search engines via similarity search algorithms (Shrivastava and Li, 2015).",1 Introduction,[0],[0]
"Nevertheless, there is a key distinction that search engines index each document by its content, while PIQA requires one to index each phrase in documents by its context.
",1 Introduction,[0],[0]
We formally define the PIQA problem and provide baseline models for the new task.,1 Introduction,[0],[0]
"Our experiments show that the constraint introduced
by PIQA leads to meaningful standalone document representations and practical scalability advantage, demonstrating the significance of the new task.",1 Introduction,[0],[0]
"Moreover, there is still a large gap between the baselines and the unconstrained state of the art, showing that the task is yet far from being solved.",1 Introduction,[0],[0]
We have set up a leaderboard1for PIQA challenge and invite the research community to participate.,1 Introduction,[0],[0]
We currently support SQuAD and plan to expand to other datasets as well.,1 Introduction,[0],[0]
Reading comprehension.,2 Related Work,[0],[0]
"Massive reading comprehension question answering datasets (Hermann et al., 2015; Hill et al., 2016; Dhingra et al., 2017; Dunn et al., 2017) have driven a large number of successful neural approaches (Kadlec et al., 2016; Hu et al., 2017, inter alia).",2 Related Work,[0],[0]
"Choi et al. (2017); Chen et al. (2017); Clark and Gardner (2017); Min et al. (2018) tackled large-scale QA by using a fast, coarse model (e.g. TF-IDF) to retrieve few documents or sentences and then using a slower, accurate model to obtain the answer.",2 Related Work,[0],[0]
Salant and Berant (2018) proposed to minimize (but not prohibit) the influence of question when modeling the document.,2 Related Work,[0],[0]
"Similarly to ours, Lee et al. (2016) proposed to explicitly learn the representation for each answer candidate (phrase) in the document, but it was conditioned (dependent) on the question.",2 Related Work,[0],[0]
Sentence retrieval.,2 Related Work,[0],[0]
"A closely related task to ours is that of retrieving a sentence/paragraph in a corpus that answers the question (Tay et al., 2017).",2 Related Work,[0],[0]
A comprehensive survey for neural approaches in information retrieval literature is discussed in Mitra and Craswell (2017).,2 Related Work,[0],[0]
"We note that our problem is focused on phrasal answer extraction, which presents a unique challenge over sentence retrieval—the need for context-based representation as opposed to the content-based representation in the sentence-retrieval literature.",2 Related Work,[0],[0]
Language representation.,2 Related Work,[0],[0]
"Recently there has been a growing interest in developing natural language representations that can be transferred across tasks (Vendrov et al., 2016; Wieting et al., 2016; Conneau et al., 2017, inter alia).",2 Related Work,[0],[0]
"In particular, SNLI (Bowman et al., 2015) and MultiNLI (Williams et al., 2017) encourage architectures that first encode the hypothesis and the premise independently before a comparator neu-
1nlp.cs.washington.edu/piqa
ral network is applied.",2 Related Work,[0],[0]
Our proposed problem shares similar traits but has a stronger constraint that only inner product comparison is allowed and one needs to model phrases instead of complete sentences.,2 Related Work,[0],[0]
Extractive question answering is the task of obtaining the answer â to a questionQ = {q1 . . .,3 Phrase-Indexed Question Answering,[0],[0]
qn} given an evidence document D = {d1 . . .,3 Phrase-Indexed Question Answering,[0],[0]
"dm}, where the answer â = (s, e) indicates the start and end of a span in the document.",3 Phrase-Indexed Question Answering,[0],[0]
The task is often formulated as learning the probabilistic distribution of the answer given the question and the document.,3 Phrase-Indexed Question Answering,[0],[0]
"In existing literature (Section 2), the distribution is mainly featurized by Pr(a|Q,D) ∝ exp(Fθ(Q,D, a)) where Fθ could be any realvalued scoring function parameterized by θ.",3 Phrase-Indexed Question Answering,[0],[0]
"Once θ is learned, the prediction â is obtained by
â = argmax a Fθ(Q,D, a).",3 Phrase-Indexed Question Answering,[0],[0]
"(1)
So far, most competitive designs of Fθ(Q,D, a) make use of attention connections between the words in Q and D. As a result, these models cannot yield a query independent representation of the document D. It is subsequently not possible to independently assess the document understanding capability of the model.",3 Phrase-Indexed Question Answering,[0],[0]
"Furthermore, Fθ(Q,D, a) needs to be re-computed for the entire document for every new question.",3 Phrase-Indexed Question Answering,[0],[0]
"We believe that this inefficiency precludes all current models as the candidates for end-to-end QA systems.
",3 Phrase-Indexed Question Answering,[0],[0]
We propose a new task—,3 Phrase-Indexed Question Answering,[0],[0]
Phrase-Indexed Question Answering (PIQA)—that addresses these issues.,3 Phrase-Indexed Question Answering,[0],[0]
"We enforce the decomposability of Fθ into two exclusive functions Gθ(Q), Hθ(D, a) ∈ Rk.",3 Phrase-Indexed Question Answering,[0],[0]
"The answer distribution is then modeled by Pr(a|Q,D) ∝ exp(Gθ(Q) •",3 Phrase-Indexed Question Answering,[0],[0]
"Hθ(D, a)), where • is the inner product.",3 Phrase-Indexed Question Answering,[0],[0]
"The prediction is obtained by
â = argmax a
Gθ(Q) •Hθ(D, a).",3 Phrase-Indexed Question Answering,[0],[0]
"(2)
",3 Phrase-Indexed Question Answering,[0],[0]
"In this setting, the document encoder Hθ learns models the document independently of the question.",3 Phrase-Indexed Question Answering,[0],[0]
"Successful question answering models that follow the structure of PIQA will have two important advantages over current QA models: full document comprehension and scalablity.
",3 Phrase-Indexed Question Answering,[0],[0]
Full document comprehension.,3 Phrase-Indexed Question Answering,[0],[0]
"Language understanding ability is widely associated with learning a good standalone representation of text (or its
components such as phrases) independent of the end task (Bowman et al., 2015).",3 Phrase-Indexed Question Answering,[0],[0]
"Under PIQA constraints, the document encoder Hθ learns the representation of the answer candidate phrases a in the document D independent of the question.",3 Phrase-Indexed Question Answering,[0],[0]
"In order to correctly answer questions, these phrase representations (index vectors) need to correctly encode their meaning with respect to their context.",3 Phrase-Indexed Question Answering,[0],[0]
"Therefore, PIQA constraint enforces evaluating research in document comprehension and phrase representation learning.
",3 Phrase-Indexed Question Answering,[0],[0]
Scalability.,3 Phrase-Indexed Question Answering,[0],[0]
"Models that adhere to the PIQA constraint only need to be run once for each document, regardless of the number of questions asked.",3 Phrase-Indexed Question Answering,[0],[0]
"To answer a question, the model then just needs to encode the question and compare it to each of the answer candidates via the inner product in Equation 2.",3 Phrase-Indexed Question Answering,[0],[0]
"Implemented naively, computing a single inner product for each answer candidate is more efficient than building a new document encoding; after the documents are pre-encoded, Equation 2 is O(k) time per word where k is the vector size (most neural models require O(k2) per word for matrix multiplications).
",3 Phrase-Indexed Question Answering,[0],[0]
"More importantly, PIQA also permits an approximate solution in sublinear time using asymmetric locality-sensitive hashing (aLSH) (Shrivastava and Li, 2014, 2015), through which Equation 2 can be approximated for N answer candidates with O(kNρ logN) time, where ρ < 1 is a function of the approximation factor and the properties of the hash functions.",3 Phrase-Indexed Question Answering,[0.9524223839992169],"['After segmenting and labeling attributes in the referring expressions, the attribute values are extracted from each semantic segment using regular expressions (Figure 2 (b)), e.g., value 2 is extracted from 2 dimensional to fill in the ARRAY DIM element in an empty Att V ec.']"
"We argue that this type of approach will be essential for the development of real world QA systems, where the number of potential answers N is extremely large.",3 Phrase-Indexed Question Answering,[0],[0]
"We introduce several baselines for PIQA that are motivated by related literature.
",4 Baseline Models,[0],[0]
"For all (neural) baselines, we represent the words in D and Q with one of three embedding mechanisms: CharCNN (Kim, 2014) +",4 Baseline Models,[0],[0]
"GloVe (Pennington et al., 2014), and ELMo (Peters et al., 2018).",4 Baseline Models,[0],[0]
"We follow the majority of the related literature and apply bidirectional LSTMs (Hochreiter and Schmidhuber, 1997) to these embeddings to build the context-aware representations of the document D = {d1 . .",4 Baseline Models,[0],[0]
.dm},4 Baseline Models,[0],[0]
and question Q = {q1 . .,4 Baseline Models,[0],[0]
".qn}, where the forward & backward LSTM outputs are concatenated to get a single word representation, i.e. di,qi ∈ R2k
where k is the hidden state size of LSTMs.",4 Baseline Models,[0],[0]
PIQA disallows cross-attention between document and question.,4 Baseline Models,[0],[0]
"However, we can still benefit from self-attention, which has become crucial for machine translation (Vaswani et al., 2017) and QA (Huang et al., 2018; Yu et al., 2018).",4 Baseline Models,[0],[0]
"In all of our baselines, each variable-length question is collapsed into a fixed length vector via the sum qSA",4 Baseline Models,[0],[0]
= ∑ i uiqi where u = {u1 . . .,4 Baseline Models,[0],[0]
un} is a vector containing a single weight for each word in the question.,4 Baseline Models,[0],[0]
"Similarly, we experiment with document side self attention to represent each document word dj as a weighted sum of itself and all neighboring words dSAj = ∑ i h j idj .",4 Baseline Models,[0],[0]
"The weight vectors u and hj are calculated as
u = softmaxi(w >qi)
hj = softmaxi(Rθ(D, j)",4 Baseline Models,[0],[0]
>,4 Baseline Models,[0],[0]
"Kθ(D, i))
where Rθ, and Kθ are trainable neural networks with the same ouptut size, and w ∈",4 Baseline Models,[0],[0]
R2k is a trainable weight vector.,4 Baseline Models,[0],[0]
We use independent BiLSTMs with hidden state size k (i.e. the output size is 2k) to model both Rθ and Kθ.,4 Baseline Models,[0],[0]
"That is, Rθ(D, j) is the j-th output of BiLSTM on top of D, and we similarly define Kθ with unshared parameters.
",4 Baseline Models,[0],[0]
"For all (neural) baselines, the question is represented using the concatenation of two copies of qSA, one that should have high inner product with the vector for the answer’s start span and another that should have high inner product with the vector for the answer’s end.",4 Baseline Models,[0],[0]
"Thus, Equation 2’s Gθ(Q) =",4 Baseline Models,[0],[0]
"[q SA s ,q SA e ] where the subscripts s (start) and e (end) imply that different sets of parameters were used.",4 Baseline Models,[0],[0]
"Now we define several baselines.
",4 Baseline Models,[0],[0]
LSTM baseline.,4 Baseline Models,[0],[0]
"An answer candidate a = (s, e) is represented using the LSTM outputs at its endpoints: from Equation 2, Hθ(D, (s, e))",4 Baseline Models,[0],[0]
=,4 Baseline Models,[0],[0]
"[ds,de] ∈ R4k and Gθ(Q) =",4 Baseline Models,[0],[0]
"[qSAs ,qSAe ] ∈ R4k.
LSTM+SA baseline.",4 Baseline Models,[0],[0]
"The LSTM outputs are augmented with the endpoint representations that come out of the document’s self-attention (SA): Hθ(D, (s, e))",4 Baseline Models,[0],[0]
=,4 Baseline Models,[0],[0]
"[ds,d SA s ,de,d SA e ] ∈ R8k and Gθ(Q) =",4 Baseline Models,[0],[0]
"[q SA s1 ,q SA s2 ,q SA e1 ,q SA e2 ] ∈ R8k.
TF-IDF.",4 Baseline Models,[0],[0]
"We lastly include a purely TF-IDFbased model, where each answer candidate phrase is associated with a bag of neighbor words within a distance of 7.",4 Baseline Models,[0],[0]
Then the BOW vector is normalized via TF-IDF and indexed.,4 Baseline Models,[0],[0]
"When the query comes in, its TF-IDF vector is queried on the indexed phrases to yield the answer.
",4 Baseline Models,[0],[0]
"For training the (neural) models, we minimize the negative log probability of getting the correct answer: the loss function for each example (D,Q, a∗) is L(θ) =",4 Baseline Models,[0],[0]
"− log Pr(a∗|D,Q) where a∗ is the correct answer.",4 Baseline Models,[0],[0]
We impose the independence restrictions from PIQA on the Stanford Question Answering Dataset2.,5 Experiments,[0],[0]
We only consider answer spans with length ≤ 7.,5 Experiments,[0],[0]
"We use the hidden state size (k) of 128, which results in a 512D (4k) and 1024D (8k) vector for each phrase in LSTM and LSTM+SA, respectively.",5 Experiments,[0],[0]
"The default embedding model is CharCNN concatenated with 200D GloVe, with an option to append ELMo vectors following the same setup for SQuAD experiments discussed in Peters et al. (2018).",5 Experiments,[0],[0]
"We use a batch size of 64 and train for 20 epochs with the default Adam optimizer (Kingma and Ba, 2015), and take the best model on the validation set during training.
Results.",5 Experiments,[0],[0]
Table 1 shows the results for the PIQA baselines (top) and the unconstrained state of the art (bottom).,5 Experiments,[0],[0]
"First, the TF-IDF model performs poorly, which signifies the limitations of traditional document retrieval models for the task.",5 Experiments,[0],[0]
"Second, we note that the addition of self-attention makes a significant impact on results, improving F1 by 2.6%.",5 Experiments,[0],[0]
"Next, we see that adding ELMo gives 3.7% and 2.9% improvement on F1 for LSTM and LSTM+SA models, respectively.",5 Experiments,[0],[0]
"Lastly, the best PIQA baseline model is 11.7% higher than the first (unconstrained) baseline model (Rajpurkar et al., 2016) and 26.6% lower than the state of the art (Yu et al., 2018).",5 Experiments,[0],[0]
"This gives us a reasonable starting point of the new task and a significant gap
2PIQA paradigm can be also extended to other extractive QA datasets.
to close for future work.
",5 Experiments,[0],[0]
Phrase representations.,5 Experiments,[0],[0]
"Since PIQA models encode all answer candidates into the same space, we expect similar answer candidates to have high inner products with one another.",5 Experiments,[0],[0]
"Table 2 shows pairs of answer candidates that come from different documents in SQuAD, but that have similar encodings (high inner product).",5 Experiments,[0],[0]
We observe that phrase representations learned through the PIQA task capture different interesting characteristics of the phrases.,5 Experiments,[0],[0]
"In all three rows, we can see that the phrase pairs seem to fit into natural categories: national, or multi-national organizational constructs; mechanical engines; and mechanical properties, respectively.",5 Experiments,[0],[0]
This suggests that the model has learned interesting typing information above the word level.,5 Experiments,[0],[0]
The second and third rows also indicate that the model has learned a rich representation of context.,5 Experiments,[0],[0]
"This is particularly obvious in the third row where the two phrases are lexically dissimilar, but preceded by the similar contexts ‘primarily accomplished through’ and ‘directly derived from’.",5 Experiments,[0],[0]
"We believe that this analysis, while not complete, points toward exciting future lines of work in learning highly contextualized phrase representations through question answering.
Scalability.",5 Experiments,[0],[0]
"PIQA can also gain massive execution time speedups once the documents are preencoded: in our simple benchmark on a consumergrade CPU and NumPy (for LSTM+SA model, 1024D vectors), one can easily perform exact search over 1 million document words per second.",5 Experiments,[0],[0]
"BiDAF (Seo et al., 2017), an open-sourced and relatively light QA model reaching 77.5% F1 (66.5% EM), can process less than 1k document words per second with an equivalent computing power (after pre-encoding the document as much as possible), which is more than 1,000x slower.3
3The difference will be even higher with a dedicated similarity search package such as Faiss (Johnson et al., 2017) or approximate search (Section 3).
",5 Experiments,[0],[0]
It is also important to consider the memory cost for storing a vector representation of each of the answer candidates.,5 Experiments,[0],[0]
We train an independent single-layer perceptron classifier that predicts whether the phrase encoding is likely to be a good one.,5 Experiments,[0],[0]
"By varying a threshold on the score assigned by this classifier, we can filter answer candidates prior to storage.",5 Experiments,[0],[0]
Figure 2 illustrates the trade-off between accuracy and memory (measured in mean number of vectors per document word) resulting from this filtering procedure for the LSTM+SA model.,5 Experiments,[0],[0]
We observe that 1.3 vectors (candidates) per word on average reaches > 98% of the model’s F1 accuracy.,5 Experiments,[0],[0]
"This is equivalent to 5.2 KB per word with 1024D (4 KB) float vectors, or around 15 TB for the entire English Wikipedia (3 billion words).",5 Experiments,[0],[0]
Future work will also involve creating a better classifier (i.e. improving the trade-off curve in Figure 2) for determining which phrase vectors to store.,5 Experiments,[0],[0]
"We introduced Phrase-Indexed Question Answering (PIQA), a new variant of the extractive question answering task that requires documents and question encoded completely independently and that they only interact each other via inner product.",6 Conclusion and Future Work,[0],[0]
We argued that building a question-agnostic document encoder for question answering should be an important consideration for those in the QA community with the research goal of learning a model that reads and comprehends documents.,6 Conclusion and Future Work,[0],[0]
"Furthermore, the imposed constraint of the task implies a sublinear scalability benefit.",6 Conclusion and Future Work,[0],[0]
"Given that SQuAD models have recently outperformed hu-
mans, PIQA formulation motivates a new challenge for which we hope that the community’s effort gradually closes the gap between our constrained baselines and the unconstrained models.",6 Conclusion and Future Work,[0],[0]
"This research was supported by ONR (N0001418-1-2826), NSF (IIS 1616112), Allen Distinguished Investigator Award, and gifts from Google, Allen Institute for AI, Amazon, and Bloomberg.",Acknowledgments,[0],[0]
We thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
We formalize a new modular variant of current question answering tasks by enforcing complete independence of the document encoder from the question encoder.,abstractText,[0],[0]
This formulation addresses a key challenge in machine comprehension by requiring a standalone representation of the document discourse.,abstractText,[0],[0]
It additionally leads to a significant scalability advantage since the encoding of the answer candidate phrases in the document can be pre-computed and indexed offline for efficient retrieval.,abstractText,[0],[0]
"We experiment with baseline models for the new task, which achieve a reasonable accuracy but significantly underperform unconstrained QA models.",abstractText,[0],[0]
"We invite the QA research community to engage in Phrase-Indexed Question Answering (PIQA, pika) for closing the gap.",abstractText,[0],[0]
The leaderboard is at: nlp.cs.washington.,abstractText,[0],[0]
Phrase-Indexed Question Answering: A New Challenge for Scalable Document Comprehension,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3729–3738 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3729",text,[0],[0]
"Following the success of word embeddings (Bengio et al., 2003; Mikolov et al., 2013), one of NLP’s next challenges has become the hunt for universal sentence encoders.",1 Introduction,[0],[0]
"The goal is to learn a general-purpose sentence encoding model on a large corpus, which can be readily transferred to other tasks.",1 Introduction,[0],[0]
"The learned sentence representations are able to generalize to unseen combination of words, which makes them highly desirable for
downstream NLP tasks, especially for those with relatively small datasets.
",1 Introduction,[0],[0]
"Previous models for sentence encoding typically rely on Recurrent Neural Networks (RNNs) (Hochreiter and Schmidhuber, 1997; Chung et al., 2014) or Convolutional Neural Networks (CNNs) (Kalchbrenner et al., 2014; dos Santos and Gatti, 2014; Kim, 2014; Mou et al., 2016) to produce context-aware representation.",1 Introduction,[0],[0]
"RNNs encode a sentence by reading words in sequential order, they are capable of learning long-term dependencies but are hard to parallelize and not time-efficient.",1 Introduction,[0],[0]
"CNNs focus on local or positioninvariant dependencies but do not perform well on many tasks (Shen et al., 2017).
",1 Introduction,[0],[0]
"Fully attention-based neural networks have attracted wide interest recently, because they can model both dependencies while being more parallelizable and requiring significantly less time to train.",1 Introduction,[0],[0]
"Vaswani et al. (2017) proposed the multihead attention to project a sentence to multiple semantic subspaces, then apply self-attention in each subspace and concatenate the attention results.",1 Introduction,[0],[0]
"Shen et al. (2017) proposed the directional self-attention, they apply forward and backward masks to the alignment score matrix to encode temporal order information, and computed attention at feature level to select the features that can best describe the word’s meaning in given context.",1 Introduction,[0],[0]
"Effective as their models are, the memory required to store the alignment scores of all the token pairs grows quadratically with the sentence length.",1 Introduction,[0],[0]
"Furthermore, the syntactic property that is intrinsic to natural language is not considered at all.
",1 Introduction,[0],[0]
"Language is inherently tree structured, and the meaning of a sentence comes largely from composing the meanings of subtrees (Chomsky, 1957).",1 Introduction,[0],[0]
"Previous syntactic tree-based sentence encoders (Socher et al., 2013; Tai et al., 2015) mainly rely on recursive networks.",1 Introduction,[0],[0]
"Although the composition-
ality can be explicitly modeled, their models need expensive recursion computation and are hard to be trained by batched gradient descent methods.
",1 Introduction,[0],[0]
"In this paper, we propose the Phrase-level SelfAttention Networks (PSAN), for RNN/CNN-free sentence encoding, it inherits all the advantages of fully attention-based models while requires much less memory consumption.",1 Introduction,[0],[0]
"In addition, syntactic information can be incorporated into the model more easily.",1 Introduction,[0],[0]
"In our model, every sentence is split into multiple phrases based on parse tree, selfattention is performed at the phrase level instead of the sentence level, thus the memory consumption reduces rapidly as the number of phrases increases.",1 Introduction,[0],[0]
"Furthermore, a gated memory component is employed to refine word representations hierarchically by incorporating longer-term context dependencies.",1 Introduction,[0],[0]
"As a result, syntactic information can be integrated into the model without expensive recursion computation.",1 Introduction,[0],[0]
"At last, multi-dimensional attention is applied on the refined word representations to obtain the final sentence representation.
",1 Introduction,[0],[0]
"Following Conneau et al. (2017), we trained our sentence encoder on the SNLI (Bowman et al., 2015) dataset, and evaluate the quality of the obtained universal sentence representations on a wide range of transfer tasks.",1 Introduction,[0],[0]
"The SNLI dataset is extremely suitable for training sentence encoders because it is the largest high-quality humanannotated dataset that involves reasoning about the semantic relationships within sentences.
",1 Introduction,[0],[0]
"The main contributions of our work can be summarized as follows:
• We propose the Phrase-level Self-Attention mechanism (PSA) for contextualization.",1 Introduction,[0],[0]
"The memory consumption can be reduced because self-attention is performed at the phrase level instead of the sentence level.
",1 Introduction,[0],[0]
"• A gated memory updating mechanism is proposed to refine each word representation hierarchically by incorporating different levels of contextual information along the parse tree.
",1 Introduction,[0],[0]
• Our proposed PSAN model outperforms the state-of-the-art supervised sentence encoders on a wide range of transfer tasks with significantly less memory consumption.,1 Introduction,[0],[0]
"In this section, we introduce the Phrase-level SelfAttention Networks (PSAN) for sentence encod-
ing.",2 Proposed Model,[0],[0]
A phrase is a group of words that carry a specific idiomatic meaning and function as a constituent in the syntax of a sentence.,2 Proposed Model,[0],[0]
Words in a phrase are syntactically and semantically related to each other.,2 Proposed Model,[0],[0]
"Therefore, it can be advantageous to learn a context-aware representation inside a phrase while filtering out information from outside the phrase using self-attention mechanism.",2 Proposed Model,[0],[0]
"In an attempt to better utilize the tree structure which is intrinsic to language, we propose the gated memory updating mechanism to combine different levels of context information.",2 Proposed Model,[0],[0]
"At last, an attention mechanism is utilized to summarize all the token representations into a fixed-length sentence vector.",2 Proposed Model,[0],[0]
The phrase structure organizes words into nested constituents which can be successively divided into their parts as we move down the constituencybased parse trees.,2.1 Phrase Division,[0],[0]
One phrase division shows only one aspect of context dependency.,2.1 Phrase Division,[0],[0]
"In order to capture different levels of context dependencies, we can split a sentence at different granularities.",2.1 Phrase Division,[0],[0]
"The number of levels T is a hyper-parameter to be tuned.
",2.1 Phrase Division,[0],[0]
"We can break down the nodes at T different layers in the parse tree to capture T levels of context dependencies1, as illustrated in Figure 1.",2.1 Phrase Division,[0],[0]
This is the core component of our model.,2.2 Phrase-level Self-Attention,[0],[0]
It aims to learn a context-aware representation for each token inside a phrase.,2.2 Phrase-level Self-Attention,[0],[0]
"In order to filter out information that is semantically or syntactically distant, self-attention is performed at the phrase level instead of the sentence level.
",2.2 Phrase-level Self-Attention,[0],[0]
"Similar to directional self-attention network (DiSAN) (Shen et al., 2017), Phrase-level SelfAttention uses multi-dimensional attention to compute the alignment score for each dimension of token embedding.",2.2 Phrase-level Self-Attention,[0],[0]
"Therefore, it can select the features that can best describe a word’s specific meaning in any given context.
",2.2 Phrase-level Self-Attention,[0],[0]
"Given a phrase P ∈ Rl×d represented as a sequence of word embeddings [p1, . . .",2.2 Phrase-level Self-Attention,[0],[0]
",pl], where l is the length of the phrase and d is the dimension of word embedding representation, we first compute the alignment score for each token pair in the
1To avoid the situation that the produced phrases are too small, a phrase will not be further divided if its length is smaller than 4.
phrase: aij = σ",2.2 Phrase-level Self-Attention,[0],[0]
"( W a1pi +W a2pj + b a ) +Mij
Mij = { 0, i 6= j −∞, i = j
(1)
where σ (·) is an activation function, W a1,W a2 ∈ Rd×d and ba ∈ Rd are parameters to be learned, and M is a diagonal-diabled mask (Hu et al., 2017) that aims to prevent a word from being aligned with itself.
",2.2 Phrase-level Self-Attention,[0],[0]
"The output of the attention mechanism is a weighted sum of embeddings from all tokens for each token in the phrase:
p̃i = l∑ j=1",2.2 Phrase-level Self-Attention,[0],[0]
"[ exp (aij)∑l k=1 exp (aik) pj ] (2)
where means point-wise product.",2.2 Phrase-level Self-Attention,[0],[0]
"Note that the alignment score for each token pair is a vector rather than a scalar in the multi-dimensional attention.
",2.2 Phrase-level Self-Attention,[0],[0]
The final output of Phrase-level Self-Attention is obtained by comparing each input representation with its attention-weighted counterpart.,2.2 Phrase-level Self-Attention,[0],[0]
We use a comparison function based on absolute difference and element-wise multiplication which was similar to Wang and Jiang (2016).,2.2 Phrase-level Self-Attention,[0],[0]
"This comparison function has the advantage of measuring the semantic similarity or relatedness of two sequences.
",2.2 Phrase-level Self-Attention,[0],[0]
ci = σ,2.2 Phrase-level Self-Attention,[0],[0]
"(W c [|pi − p̃i| ;pi p̃i] + bc) (3)
where",2.2 Phrase-level Self-Attention,[0],[0]
W c ∈ Rd×2d,2.2 Phrase-level Self-Attention,[0],[0]
and ba ∈ Rd are parameters to be learned.,2.2 Phrase-level Self-Attention,[0],[0]
"ci is the representation for the i-th word in the phrase that captures local dependencies within the phrase.
",2.2 Phrase-level Self-Attention,[0],[0]
"At last, we put together the Phrase-level SelfAttention results for non-overlapping phrases from the same phrase division of a sentence.",2.2 Phrase-level Self-Attention,[0],[0]
For the t-th phrase division we can get C(t) =,2.2 Phrase-level Self-Attention,[0],[0]
"[c1, . .",2.2 Phrase-level Self-Attention,[0],[0]
.,2.2 Phrase-level Self-Attention,[0],[0]
", cls ], the phrase-level self-attention results for the sentence from the t-th layer split, where ls is the sentence length.",2.2 Phrase-level Self-Attention,[0],[0]
Above describes the Phrase-level Self-Attention (PSA) for one split of the parse tree.,2.3 Gated Memory Updating,[0],[0]
The parse tree can be split at different granularities.,2.3 Gated Memory Updating,[0],[0]
We propose a novel gated memory updating mechanism to refine each word representation hierarchically with longer-term dependencies captured in a larger granularity.,2.3 Gated Memory Updating,[0],[0]
"Inspired by the idea of adaptive gate in highway networks (Srivastava et al., 2015), our memory mechanism add a gate to original memory networks (Weston et al., 2014; Sukhbaatar et al., 2015).",2.3 Gated Memory Updating,[0],[0]
"This gate has the ability to determine the importance of the new input and the original memory in the memory updating.
C(t) = PSA ( M (t−1) ) G(t) = sigmoid ( W g",2.3 Gated Memory Updating,[0],[0]
[ M (t−1);C(t) ],2.3 Gated Memory Updating,[0],[0]
"+ bg
) M (t) = G(t) σ",2.3 Gated Memory Updating,[0],[0]
( Wm [ M (t−1);C(t) ],2.3 Gated Memory Updating,[0],[0]
"+ bm
) (4)
whereW g,Wm ∈ Rd×2d and bg,",2.3 Gated Memory Updating,[0],[0]
bm ∈ Rd are parameters to be learned.,2.3 Gated Memory Updating,[0],[0]
"Note that in order to share representation power and to reduce the number of parameters, the parameters of gated memory updating are shared among different layers.",2.3 Gated Memory Updating,[0],[0]
"In this layer, self-attention mechanism is employed to summarize the refined representation of a sentence into a fixed-length vector.",2.4 Sentence Summarization,[0],[0]
The selfattention mechanism can explore the dependencies among tokens within the whole sentence.,2.4 Sentence Summarization,[0],[0]
"As a result, global dependencies can also be incorporated in the model.
",2.4 Sentence Summarization,[0],[0]
ei =W e2σ ( W e1m (T ),2.4 Sentence Summarization,[0],[0]
i + b e1 ) +,2.4 Sentence Summarization,[0],[0]
"be2
v = l∑ i=1",2.4 Sentence Summarization,[0],[0]
[ exp (ei)∑l j=1 exp (ej) m(T ),2.4 Sentence Summarization,[0],[0]
"i ] (5) where W g,Wm ∈ Rd×d and bg, bm ∈ Rd are parameters to be learned.",2.4 Sentence Summarization,[0],[0]
"After this step, the refined context-aware sentence representation is compressed into a fixed-length vector.",2.4 Sentence Summarization,[0],[0]
"In this section, we conduct a plethora of experiments to study the effectiveness of the PSAN model.",3 Experiments,[0],[0]
"Following Conneau et al. (2017), we train our sentence encoder using the SNLI dataset, and evaluate it across a variety of NLP tasks including sentence classification, natural language inference and sentence textual similarity.",3 Experiments,[0],[0]
"300-dimensional GloVe (Pennington et al., 2014) word embeddings (Common Crawl, uncased) are used to represent words.",3.1 Model Configuration,[0],[0]
"Following Parikh et al. (2016), out-of-vocabulary words are hashed to one of 128 random embeddings initialized by uniform distribution between (-0.05, 0.05).",3.1 Model Configuration,[0],[0]
All the word embeddings remain fixed during training.,3.1 Model Configuration,[0],[0]
Hidden dimension d is set to 300.,3.1 Model Configuration,[0],[0]
"All other parameters are initialized with Glorot normal initialization (Glorot and Bengio, 2010).",3.1 Model Configuration,[0],[0]
"Activation function σ (·) is ELU (Clevert et al., 2015) if not specified.",3.1 Model Configuration,[0],[0]
Minibatch size is set to 16.,3.1 Model Configuration,[0],[0]
The number of levels T is fixed to 3 in all of our experiments.,3.1 Model Configuration,[0],[0]
"The syntactic parse trees of SNLI are provided within the corpus. parse trees for all test corpus are produced by the Stanford PCFG Parser 3.5.2 (Klein and Manning, 2003), the same parser that produced parse trees for the SNLI dataset.
",3.1 Model Configuration,[0],[0]
"To train the model, Adadelta optimizer (Zeiler, 2012) with a learning rate of 0.75 is used on the SNLI dataset.",3.1 Model Configuration,[0],[0]
"The dropout (Srivastava et al., 2014) rate and L2 regularization weight decay factor γ are set to 0.5 and 5e-5.",3.1 Model Configuration,[0],[0]
"To test the model, the SentEval toolkit (Conneau and Kiela, 2018) is used as the evaluation pipeline for fairer comparison.",3.1 Model Configuration,[0],[0]
"Natural language inference (NLI) is a fundamental task in the field of natural language processing that involves reasoning about the semantic relationship between two sentences, which makes it a suitable task to train sentence encoding models.
",3.2 Training Setting,[0],[0]
"We conduct experiments on the Stanford Natural Language Inference (SNLI) dataset (Bowman et al., 2015).",3.2 Training Setting,[0],[0]
"The dataset has 570k human-annotated sentence pairs, each labeled with one of the following pre-defined relationships: Entailment (the premise entails the hypothesis), Contradiction (they contradict each other) and Neutral (they are irrelevant).",3.2 Training Setting,[0],[0]
"Following previous work (Bowman et al., 2015; Mou et al., 2016), we remove the instances which annotators can not reach consensus on.",3.2 Training Setting,[0],[0]
"In this way we get 549367/9842/9824 sentence pairs for train/validation/test set.
",3.2 Training Setting,[0],[0]
"Following the siamese architecture (Bromley et al., 1993), we apply PSAN to both the premise and the hypothesis with their parameters tied.",3.2 Training Setting,[0],[0]
vp and vh are fixed-length vector representations for the premise and the hypothesis respectively.,3.2 Training Setting,[0],[0]
"The final sentence-pair representation is formed by concatenating the original vectors with the absolute difference and element-wise multiplication between them:
vinp =",3.2 Training Setting,[0],[0]
[ vp;vh; ∣∣∣vp − vh∣∣∣ ;vp vh] (6),3.2 Training Setting,[0],[0]
"At last, we feed the sentence-pair representation vinp into a two layer feed-forward network and use a softmax layer to make the classification.",3.2 Training Setting,[0],[0]
This is the de facto scheme for sentence encoders trained on SNLI.,3.2 Training Setting,[0],[0]
"(Mou et al., 2016; Liu et al., 2016; Shen et al., 2017)",3.2 Training Setting,[0],[0]
"To show the modeling capacity and robustness of our proposed model, we evaluate our model across a wide range of tasks that can be solved purely based on the encoded semantics.",3.3 Evaluation Setting,[0],[0]
"The set of tasks
was selected based on what appears to be the community consensus regarding the appropriate evaluations for universal sentence representations.",3.3 Evaluation Setting,[0],[0]
"To facilitate comparison, we use the same sentence evaluation tool as Conneau et al. (2017) to automate evaluation on all the tasks mentioned in this paper.
",3.3 Evaluation Setting,[0],[0]
"The transfer tasks used in evaluation can be concluded in the following classes: sentence classification (MR, CR, MPQA, SUBJ, SST2, SST5, TREC), natural language inference (SICKE, SICK-R), semantic relatedness (STS14) and paraphrase detection (MRPC).",3.3 Evaluation Setting,[0],[0]
Table 1 presents some statistics about the datasets 2.,3.3 Evaluation Setting,[0],[0]
"We compare our model with the following supervised sentence encoders:
• BiLSTM-Max (Conneau et al., 2017) is a simple but effective baseline that performs max-pooling over a bi-directional LSTM.
",3.4 Baselines,[0],[0]
"• AdaSent (Zhao et al., 2015) forms a hierarchy of representations from words to phrases and then to sentences through recursive gated local composition of adjacent segments.
",3.4 Baselines,[0],[0]
"• TBCNN (Mou et al., 2015) is a tree-based CNN model where convolution is applied over the parse tree.
",3.4 Baselines,[0],[0]
"2For further information on the datasets, please refer to Conneau et al. (2017).
",3.4 Baselines,[0],[0]
"• DiSAN (Shen et al., 2017) is composed of a directional self-attention block with temporal order encoded, and a multi-dimensional attention that compresses the sequence into a vector representation.",3.4 Baselines,[0],[0]
Experiment results of our model and four baselines are shown in Table 2.,4.1 Overall Performance,[0],[0]
Micro and macro accuracies are two composite indicators for evaluating transfer performance of tasks whose metric is classification accuracy.,4.1 Overall Performance,[0],[0]
Macro accuracy is the proportion of true results in the population of instances from all tasks.,4.1 Overall Performance,[0],[0]
"Micro accuracy is the arithmetic mean of dev accuracies for each task.
",4.1 Overall Performance,[0],[0]
"PSAN achieves the state-of-the-art performance
with considerably fewer parameters, outperforming a RNN-based model, a CNN-based model, a fully attention-based model and a model that utilize syntactic information.",4.1 Overall Performance,[0],[0]
"Especially when compared with previous best model BiLSTM-Max, PSAN can outperform their model with only 5% of their parameter numbers, demonstrating the effectiveness of our model at extracting semantically important information from a sentence.
",4.1 Overall Performance,[0],[0]
"In Table 3, we compare our model with baseline sentence encoders in each transfer task.",4.1 Overall Performance,[0],[0]
PSAN can consistently outperform the baselines in almost every task considered.,4.1 Overall Performance,[0],[0]
"On the SICK dataset, which can be seen as an out-domain version of SNLI, our model can outperform the baselines by a large margin, demonstrating the semantic relationship learned on the SNLI can be well transfered to other domains.",4.1 Overall Performance,[0],[0]
"On the STS14 dataset, where sentence vectors can be more directly measured by the cosine distance, our model can also achieve the stateof-the-art performance, indicating that our learned sentence representations are of high quality.",4.1 Overall Performance,[0],[0]
"For thorough comparison, we implement seven extra baselines to analyze the improvements con-
tributed by each part of our PSAN model:
• PSA on the first/second/third layer only only uses the Phrase-level Self-Attention at the first/second/third layer of phrase division.
",4.2 Ablation Study,[0],[0]
"• w/o PSA applies self-attention at the sentence level and uses the gated memory updating mechanism to refine each token representation hierarchically.
",4.2 Ablation Study,[0],[0]
"• w/o syntactic division divides each sentence equally into small blocks, and applies PSA within each block.",4.2 Ablation Study,[0],[0]
"The number of blocks equals the number of phrases in that layer.
",4.2 Ablation Study,[0],[0]
"• w/o gated memory updating concatenates the outputs of Phrase-level Self-Attention from three layers of phrase division and feeds the result to a feed-forward layer.
",4.2 Ablation Study,[0],[0]
"• w/o both applies self-attention at the sentence level, and uses sentence summarization to summarize the attention results into a fixed length vector.
",4.2 Ablation Study,[0],[0]
The results are listed in Table 4.,4.2 Ablation Study,[0],[0]
"We can see that (2) performs best among (1), (2) and (3), demonstrating that the second layer split is more expressive, because the number of words per phrase in the second layer is the most suitable.",4.2 Ablation Study,[0],[0]
"It is neither too small to capture context dependencies, nor too large to filter out irrelevant noise.",4.2 Ablation Study,[0],[0]
"(8) outperforms (1), (2) and (3), showing that combining phraselevel information from different granularities can further improve performance.
",4.2 Ablation Study,[0],[0]
We also experiment on models where the alignment matrix is calculated at the sentence level or at the syntactic-irrelevant block level.,4.2 Ablation Study,[0],[0]
"(5) performs quite well, showing that hierarchical refinement on smaller units can bring about reasonable
performance gain.",4.2 Ablation Study,[0],[0]
"(8) outperforms (4) and (5), demonstrating syntactic information helps in sentence representation.
",4.2 Ablation Study,[0],[0]
"When comparing (6) with (8), we can tell that gated memory updating is a better method when used to refine token representation along the parse tree.",4.2 Ablation Study,[0],[0]
"We assume that memory updating resembles the tree structure of language in that larger phrase is composed in the knowledge of how smaller phrases are composed inside it.
",4.2 Ablation Study,[0],[0]
"Comparing (7) with (1), (2) and (3), we can find that performing self-attention at the phrase level is generally better than at the sentence level, indicating that reducing attention context into phrase level can effectively filter out words that are syntactically and semantically distant, thus focusing on the interaction with important words.",4.2 Ablation Study,[0],[0]
"Comparing (7) with (4), we can draw the conclusion that memory updating is effective even when the inputs to each layer are the same.",4.2 Ablation Study,[0],[0]
"Long-term dependencies are typically hard to capture for sequential models like RNNs (Bengio et al., 1994; Hochreiter and Schmidhuber, 1997).",4.3 Analysis of Sentence Length,[0],[0]
We conduct experiments to see how performance changes as the sentence length increases.,4.3 Analysis of Sentence Length,[0],[0]
"In Figure 2, we show the relationship between classification accuracy and the average length of sentence pair on the SNLI dataset.",4.3 Analysis of Sentence Length,[0],[0]
Sentence-level SelfAttention (w/o PSA model described in subsection 4.2) is used as a baseline for our model.,4.3 Analysis of Sentence Length,[0],[0]
"PSAN
outperforms Sentence-level Self-Attention model consistently for longer sentences of length 14 to 20.",4.3 Analysis of Sentence Length,[0],[0]
This demonstrates that incorporating syntactic information by performing self-attention at the phrase level and refining each word’s representation hierarchically can help to capture long-term dependencies across words in a sentence.,4.3 Analysis of Sentence Length,[0],[0]
We conduct experiments to analyze the memory consumption reduction resulted from Phrase-level Self-Attention.,4.4 Analysis of Memory Consumption,[0],[0]
"To this end, we re-implement two fully attention-based models (Vaswani et al., 2017; Shen et al., 2017) on the TREC dataset.",4.4 Analysis of Memory Consumption,[0],[0]
"To make fair comparison, the dimensions of sentence vectors are set to 300, the same number as our model.",4.4 Analysis of Memory Consumption,[0],[0]
Table 5 lists the results.,4.4 Analysis of Memory Consumption,[0],[0]
"Our PSAN model can outperform the other two fully attention-based models, while being more memory efficient.",4.4 Analysis of Memory Consumption,[0],[0]
reducing more than 20% of memory consumption.,4.4 Analysis of Memory Consumption,[0],[0]
"In order to analyze the attention changing process and the importance of each word in the sentence vector, we visualize the attention scores in the alignment matrix of each layer in Phraselevel Self-Attention and sentence summarization layer.",4.5 Visualization and Case Study,[0],[0]
"To facilitate the visualization of the multidimension attention vector, we use the l2 norm of the attention vector for representation.
",4.5 Visualization and Case Study,[0],[0]
"In Figure 3, we can see that, the difference in attention weights between semantically important and unimportant words gets larger as the context becomes larger.",4.5 Visualization and Case Study,[0],[0]
This implies that token representation can be gradually refined by the gated memory updating mechanism.,4.5 Visualization and Case Study,[0],[0]
"Furthermore, the alignment matrix of a phrase can be refined even if the phrase division does not change between layers.",4.5 Visualization and Case Study,[0],[0]
"For instance, the word “girl” gets larger attention weight in the second layer division than in the first layer.",4.5 Visualization and Case Study,[0],[0]
"This demonstrates that the memory
updating mechanism can gradually pick out important words for sentence representation.",4.5 Visualization and Case Study,[0],[0]
"Finally, nouns and verbs dominate the attention weights, while stop words like “a” and “its”, contribute little to the final sentence representation, this indicates that PSAN can effectively pick out semantically important words that are most representative for the meaning of the whole sentence.",4.5 Visualization and Case Study,[0],[0]
"Recently, self-attention mechanism has been successfully applied to the field of sentence encoding, it utilizes the attention mechanism to relate elements at different positions from a single sentence.",5 Related Work,[0],[0]
"Due to its direct access to each token representation, both long-term and local dependencies can be modeled flexibly.",5 Related Work,[0],[0]
Liu et al. (2016) leveraged the average-pooled word representation to attend words appear in the sentence itself.,5 Related Work,[0],[0]
"Cheng et al. (2016) proposed the LSTMN model for machine reading, an attention vector is produced for each of its hidden states during the recurrent iteration, thus empowering the recurrent network with stronger memorization capability and the ability to discover relations among tokens.",5 Related Work,[0],[0]
Lin et al. (2017) obtained a fixed-size sentence embedding matrix by introducing self-attention.,5 Related Work,[0],[0]
"Different from the feature-level attention used in our model, their attention mechanism extracted different aspects of the sentence into multiple vector representations, and utilized a penalization term to encourage the diversity of different attention results.
",5 Related Work,[0],[0]
Syntactic information can be useful for understanding a natural language sentence.,5 Related Work,[0],[0]
"Many previous researches utilized syntactic information to build sentence encoder from composing the mean-
ings of subtrees.",5 Related Work,[0],[0]
"Tree-LSTM (Tai et al., 2015; Zhu et al., 2015) composed its hidden state from an input vector and the hidden states of arbitrarily many child units.",5 Related Work,[0],[0]
"In Tree-based CNN (Mou et al., 2015, 2016), a set of subtree feature detectors slide over the parse tree of a sentence, and a max-pooling layer is utilized to aggregate information along different parts of the tree.
",5 Related Work,[0],[0]
"Apart from the models that use parse information, there have been several researches that aimed to learn the hierarchical latent structure of text by recursively composing words into sentence representation.",5 Related Work,[0],[0]
"Among them, neural tree indexer (Munkhdalai and Yu, 2017b) utilized LSTM or attentive node composition function to construct full n-ary tree for input text.",5 Related Work,[0],[0]
"Gumbel TreeLSTM (Choi et al., 2018) used Straight-Through Gumbel-Softmax estimator to decide the parent node among candidates dynamically.",5 Related Work,[0],[0]
A major drawback of these models is that the recursion computation can be expensive and hard to be processed in batches.,5 Related Work,[0],[0]
"We propose the Phrase-level Self-Attention Networks (PSAN), a fully attention-based model that can utilize syntactic information for universal sentence encoding.",6 Conclusion,[0],[0]
"By applying self-attention at the phrase level, we can filter out distant and unrelated words and focus on modeling interaction between semantically and syntactically important words, a gated memory updating mechanism is utilized to incorporate different levels of contextual information along the parse tree.",6 Conclusion,[0],[0]
Empirical results on a wide range of transfer tasks demonstrate the effectiveness of our model.,6 Conclusion,[0],[0]
Our work is supported by National Natural Science Foundation of China under Grant No.61433015 and the National Key Research and Development Program of China under Grant No.2017YFB1002101.,Acknowledgments,[0],[0]
The corresponding authors of this paper are Houfeng Wang.,Acknowledgments,[0],[0]
Universal sentence encoding is a hot topic in recent NLP research.,abstractText,[0],[0]
"Attention mechanism has been an integral part in many sentence encoding models, allowing the models to capture context dependencies regardless of the distance between elements in the sequence.",abstractText,[0],[0]
Fully attention-based models have recently attracted enormous interest due to their highly parallelizable computation and significantly less training time.,abstractText,[0],[0]
"However, the memory consumption of their models grows quadratically with sentence length, and the syntactic information is neglected.",abstractText,[0],[0]
"To this end, we propose Phrase-level Self-Attention Networks (PSAN) that perform self-attention across words inside a phrase to capture context dependencies at the phrase level, and use the gated memory updating mechanism to refine each word’s representation hierarchically with longer-term context dependencies captured in a larger phrase.",abstractText,[0],[0]
"As a result, the memory consumption can be reduced because the self-attention is performed at the phrase level instead of the sentence level.",abstractText,[0],[0]
"At the same time, syntactic information can be easily integrated in the model.",abstractText,[0],[0]
"Experiment results show that PSAN can achieve the state-ofthe-art transfer performance across a plethora of NLP tasks including sentence classification, natural language inference and sentence textual similarity.",abstractText,[0],[0]
Phrase-level Self-Attention Networks for Universal Sentence Encoding,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 114–120 New Orleans, Louisiana, June 1 - 6, 2018. c©2017 Association for Computational Linguistics",text,[0],[0]
"Neural machine translation (NMT) (Bahdanau et al., 2014; Sutskever et al., 2014) has recently achieved remarkable performance improving fluency and adequacy over phrase-based machine translation and is being deployed in commercial settings (Koehn and Knowles, 2017).",1 Introduction,[0],[0]
"However, this comes at a cost of slow decoding speeds compared to phrase-based and syntax-based SMT (see section 3).
",1 Introduction,[0],[0]
NMT models are generally trained using 32-bit floating point values.,1 Introduction,[0],[0]
"At training time, multiple sentences can be processed in parallel leveraging graphical processing units (GPUs) to good advantage since the data is processed in batches.",1 Introduction,[0],[0]
"This is also true for decoding for non-interactive applications such as bulk document translation.
",1 Introduction,[0],[0]
Why is fast execution on CPUs important?,1 Introduction,[0],[0]
"First, CPUs are cheaper than GPUs.",1 Introduction,[0],[0]
Fast CPU computation will reduce commercial deployment costs.,1 Introduction,[0],[0]
"Second, for low-latency applications such as speech-to-speech translation (Neubig et al.,
∗A piece of eight was a Spanish dollar that was divided into 8 reales, also known as Real de a Ocho.
2017a), it is important to translate individual sentences quickly enough so that users can have an application experience that responds seamlessly.",1 Introduction,[0],[0]
"Translating individual sentences with NMT requires many memory bandwidth intensive matrixvector or matrix-narrow matrix multiplications (Abdelfattah et al., 2016).",1 Introduction,[0],[0]
"In addition, the batch size is 1 and GPUs do not have a speed advantage over CPUs due to the lack of adequate parallel work (as evidenced by increasingly difficult batching scenarios in dynamic frameworks (Neubig et al., 2017b)).
",1 Introduction,[0],[0]
Others have successfully used low precision approximations to neural net models.,1 Introduction,[0],[0]
Vanhoucke et al. (2011) explored 8-bit quantization for feedforward neural nets for speech recognition.,1 Introduction,[0],[0]
Devlin (2017) explored 16-bit quantization for machine translation.,1 Introduction,[0],[0]
In this paper we show the effectiveness of 8-bit decoding for models that have been trained using 32-bit floating point values.,1 Introduction,[0],[0]
"Results show that 8-bit decoding does not hurt the fluency or adequacy of the output, while producing results up to 4-6x times faster.",1 Introduction,[0],[0]
"In addition, implementation is straightforward and we can use the models as is without altering training.
",1 Introduction,[0],[0]
"The paper is organized as follows: Section 2 reviews the attentional model of translation to be sped up, Section 3 presents our 8-bit quantization in our implementation, Section 4 presents automatic measurements of speed and translation quality plus human evaluations, Section 5 discusses the results and some illustrative examples, Section 6 describes prior work, and Section 7 concludes the paper.",1 Introduction,[0],[0]
"Our translation system implements the attentional model of translation (Bahdanau et al., 2014) consisting of an encoder-decoder network with an at-
114
tention mechanism.",2 The Attentional Model of Translation,[0],[0]
"The encoder uses a bidirectional GRU recurrent neural network (Cho et al., 2014) to encode a source sentence x = (x1, ..., xl), where xi is the embedding vector for the ith word and l is the sentence length.",2 The Attentional Model of Translation,[0],[0]
"The encoded form is a sequence of hidden states h = (h1, ..., hl) where each hi is computed as follows
hi =",2 The Attentional Model of Translation,[0],[0]
[←− hi−→ hi ] =,2 The Attentional Model of Translation,[0],[0]
"[←− f (xi, ←− h i+1)−→ f (xi, −→ h i−1) ] , (1)
where −→ h0 = ←− h0 = 0.",2 The Attentional Model of Translation,[0],[0]
Here ←− f and −→ f are GRU cells.,2 The Attentional Model of Translation,[0],[0]
"Given h, the decoder predicts the target translation y by computing the output token sequence (y1, ...ym), where m is the length of the sequence.",2 The Attentional Model of Translation,[0],[0]
"At each time t, the probability of each token yt from a target vocabulary is
p(yt|h, yt−1..y1)",2 The Attentional Model of Translation,[0],[0]
"= g(st, yt−1, Ht), (2)
where g is a two layer feed-forward network over the embedding of the previous target word (yt−1), the decoder hidden state (st), and the weighted sum of encoder states h",2 The Attentional Model of Translation,[0],[0]
"(Ht), followed by a softmax to predict the probability distribution over the output vocabulary.
",2 The Attentional Model of Translation,[0],[0]
"We compute st with a two layer GRU as
s′t = r(st−1, y ∗ t−1) (3)
and st = q(s ′ t, Ht), (4) where s′t is an intermediate state and s0 = ←− h0.",2 The Attentional Model of Translation,[0],[0]
The two GRU units r and q together with the attention constitute the conditional GRU layer of Sennrich et al. (2017).,2 The Attentional Model of Translation,[0],[0]
"Ht is computed as
Ht =
[∑l i=1(αt,i · ←− h i)∑l
i=1(αt,i · −→ h i)
] , (5)
",2 The Attentional Model of Translation,[0],[0]
"where αt,i are the elements of αt which is the output vector of the attention model.",2 The Attentional Model of Translation,[0],[0]
"This is computed with a two layer feed-forward network
α′t = v(tanh(w(hi) + u(s ′ t−1))), (6)
where w and u are weight matrices, and v is another matrix resulting in one real value per encoder",2 The Attentional Model of Translation,[0],[0]
state hi.,2 The Attentional Model of Translation,[0],[0]
"αt is then the softmax over α′t.
",2 The Attentional Model of Translation,[0],[0]
"We train our model using a program written using the Theano framework (Bastien et al.,
2012).",2 The Attentional Model of Translation,[0],[0]
"Generally models are trained with batch sizes ranging from 64 to 128 and unbiased Adam stochastic optimizer (Kingma and Ba, 2014).",2 The Attentional Model of Translation,[0],[0]
We use an embedding size of 620 and hidden layer sizes of 1000.,2 The Attentional Model of Translation,[0],[0]
We select model parameters according to the best BLEU score on a held-out development set over 10 epochs.,2 The Attentional Model of Translation,[0],[0]
Our translation engine is a C++ implementation.,3 8-bit Translation,[0],[0]
"The engine is implemented using the Eigen matrix library, which provides efficient matrix operations.",3 8-bit Translation,[0],[0]
Each CPU core translates a single sentence at a time.,3 8-bit Translation,[0],[0]
"The same engine supports both batch and interactive applications, the latter making single-sentence translation latency important.",3 8-bit Translation,[0],[0]
"We report speed numbers as both words per second (WPS) and words per core second (WPCS), which is WPS divided by the number of cores running.",3 8-bit Translation,[0],[0]
"This gives us a measure of overall scaling across many cores and memory buses as well as the single-sentence speed.
",3 8-bit Translation,[0],[0]
"Phrase-based SMT systems, such as (Tillmann, 2006), for English-German run at 170 words per core second (3400 words per second) on a 20 core Xeon 2690v2 system.",3 8-bit Translation,[0],[0]
"Similarly, syntax-based SMT systems, such as (Zhao and Al-onaizan, 2008), for the same language pair run at 21.5 words per core second (430 words per second).
",3 8-bit Translation,[0],[0]
"In contrast, our NMT system (described in Section 2) with 32-bit decoding runs at 6.5 words per core second (131 words per second).",3 8-bit Translation,[0],[0]
"Our goal is to increase decoding speed for the NMT system to what can be achieved with phrase-based systems while maintaining the levels of fluency and adequacy that NMT offers.
",3 8-bit Translation,[0],[0]
Benchmarks of our NMT decoder unsurprisingly show matrix multiplication as the number one source of compute cycles.,3 8-bit Translation,[0],[0]
In Table 1 we see that more than 85% of computation is spent in Eigen’s matrix and vector multiply routines (Eigen matrix vector product and Eigen matrix multiply).,3 8-bit Translation,[0],[0]
"It dwarfs the costs of the transcendental function computations as well as the bias additions.
",3 8-bit Translation,[0],[0]
"Given this distribution of computing time, it makes sense to try to accelerate the matrix operations as much as possible.",3 8-bit Translation,[0],[0]
One approach to increasing speed is to quantize matrix operations.,3 8-bit Translation,[0],[0]
"Replacing 32-bit floating point math operations with 8-bit integer approximations in neural nets has been shown to give speedups and similar ac-
curacy (Vanhoucke et al., 2011).",3 8-bit Translation,[0],[0]
"We chose to apply similar optimization to our translation system, both to reduce memory traffic as well as increase parallelism in the CPU.
",3 8-bit Translation,[0],[0]
Our 8-bit matrix multiply routine uses a naive implementation with no blocking or copy.,3 8-bit Translation,[0],[0]
"The code is implemented using Intel SSE4 vector instructions and computes 4 rows at a time, similar to (Devlin, 2017).",3 8-bit Translation,[0],[0]
Simplicity led to implementing 8-bit matrix multiplication with the results being placed into a 32-bit floating point result.,3 8-bit Translation,[0],[0]
This has the advantage of not needing to know the scale of the result.,3 8-bit Translation,[0],[0]
"In addition, the output is a vector or narrow matrix, so little extra memory bandwidth is consumed.
",3 8-bit Translation,[0],[0]
"Multilayer matrix multiply algorithms result in significantly faster performance than naive algorithms (Goto and Geijn, 2008).",3 8-bit Translation,[0],[0]
"This is due to the fact that there are O(N3) math operations on O(N2) elements when multiplying NxN matrices, therefore it is worth significant effort to minimize memory operations while maximizing math operations.",3 8-bit Translation,[0],[0]
"However, when multiplying an NxN matrix by an NxP matrix where P is very small (<10), memory operations dominate and performance does not benefit from the complex algorithm.",3 8-bit Translation,[0],[0]
"When decoding single sentences, we typically set our beam size to a value less than 8 following standard practice in this kind of systems (Koehn and Knowles, 2017).",3 8-bit Translation,[0],[0]
"We actually find that at such small values of P, the naive algorithm is a bit faster.
",3 8-bit Translation,[0],[0]
Table 2 shows the profile after converting the matrix routines to 8-bit integer computation.,3 8-bit Translation,[0],[0]
There is only one entry for matrix-matrix and matrix-vector multiplies since they are handled by the same routine.,3 8-bit Translation,[0],[0]
"After conversion, tanh and sigmoid still consume less than 7% of CPU time.",3 8-bit Translation,[0],[0]
"We decided not to convert these operations to integer in light of that fact.
",3 8-bit Translation,[0],[0]
"It is possible to replace all the operations with 8-bit approximations (Wu et al., 2016), but this makes implementation more complex, as the scale of the result of a matrix multiplication must be known to correctly output 8-bit numbers without dangerous loss of precision.
",3 8-bit Translation,[0],[0]
"Assuming we have 2 matrices of size 1000x1000 with a range of values [−10, 10], the individual dot products in the result could be as large as 108.",3 8-bit Translation,[0],[0]
"In practice with neural nets, the scale of the result is similar to that of the input matrices.",3 8-bit Translation,[0],[0]
"So if we scale the result to [−127, 127] assuming the worst case, the loss of precision will give us a matrix full of zeros.",3 8-bit Translation,[0],[0]
"The choices are to either scale the result of the matrix multiplication with a reasonable value, or to store the result as floating point.",3 8-bit Translation,[0],[0]
"We opted for the latter.
8-bit computation achieves 32.3 words per core second (646 words per second), compared to the 6.5 words per core second (131 words per second) of the 32-bit system (both systems load parameters from the same model).",3 8-bit Translation,[0],[0]
This is even faster than the syntax-based system that runs at 21.5 words per core second (430 words per second).,3 8-bit Translation,[0],[0]
"Table 3 summarizes running speeds for the phrase-based SMT system, syntax-based system and NMT with 32-bit decoding and 8-bit decoding.",3 8-bit Translation,[0],[0]
"To demonstrate the effectiveness of approximating the floating point math with 8-bit integer computation, we show automatic evaluation results
on several models, as well as independent human evaluations.",4 Measurements,[0],[0]
"We report results on Dutch-English, English-Dutch, Russian-English, German-English and English-German models.",4 Measurements,[0],[0]
Table 4 shows training data sizes and vocabulary sizes.,4 Measurements,[0],[0]
All models have 620 dimension embeddings and 1000 dimension hidden states.,4 Measurements,[0],[0]
Here we report automatic results comparing decoding results on 32-bit and 8-bit implementations.,4.1 Automatic results,[0],[0]
"As others have found (Wu et al., 2016), 8-bit implementations impact quality very little.
",4.1 Automatic results,[0],[0]
"In Table 6, we compared automatic scores and speeds for Dutch-English, English-Dutch, Russian-English, German-English and EnglishGerman models on news data.",4.1 Automatic results,[0],[0]
"The EnglishGerman model was run with both a single model (1x) and an ensemble of two models (2x) (Freitag et al., 2017).",4.1 Automatic results,[0],[0]
"Table 5 gives the number of sentences and average sentence length for the test sets used.
",4.1 Automatic results,[0],[0]
Speed is reported in words per core second (WPCS).,4.1 Automatic results,[0],[0]
This gives us a better sense of the speed of individual engines when deployed on multicore systems with all cores performing translations.,4.1 Automatic results,[0],[0]
Total throughput is simply the product of WPCS and the number of cores in the machine.,4.1 Automatic results,[0],[0]
The reported speed is the median of 9 runs to ensure consistent numbers.,4.1 Automatic results,[0],[0]
"The results show that we see a 4-6x speedup over 32-bit floating point de-
coding.",4.1 Automatic results,[0],[0]
German-English shows the largest deficit for the 8-bit mode versus the 32-bit mode.,4.1 Automatic results,[0],[0]
The German-English test set only includes 168 sentences so this may be a spurious difference.,4.1 Automatic results,[0],[0]
These automatic results suggest that 8-bit quantization can be done without perceptible degradation.,4.2 Human evaluation,[0],[0]
"To confirm this, we carried out a human evaluation experiment.
",4.2 Human evaluation,[0],[0]
"In Table 7, we show the results of performing human evaluations on some of the same language pairs in the previous section.",4.2 Human evaluation,[0],[0]
An independent native speaker of the language being translated to/from different than English (who is also proficient in English) scored 100 randomly selected sentences.,4.2 Human evaluation,[0],[0]
The sentences were shuffled during the evaluation to avoid evaluator bias towards different runs.,4.2 Human evaluation,[0],[0]
"We employ a scale from 0 to 5, with 0 being unintelligible and 5 being perfect translation.
",4.2 Human evaluation,[0],[0]
"The Table shows that the automatic scores shown in the previous section are also sustained
by humans.",4.2 Human evaluation,[0],[0]
8-bit decoding is as good as 32-bit decoding according to the human evaluators.,4.2 Human evaluation,[0],[0]
Having a faster NMT engine with no loss of accuracy is commercially useful.,5 Discussion,[0],[0]
"In our deployment scenarios, it is the difference between an interactive user experience that is sluggish and one that is not.",5 Discussion,[0],[0]
"Even in batch mode operation, the same throughput can be delivered with 1/4 the hardware.
",5 Discussion,[0],[0]
"In addition, this speedup makes it practical to deploy small ensembles of models.",5 Discussion,[0],[0]
"As shown above in the En-De model in Table 6, an ensemble can deliver higher accuracy at the cost of a 2x slowdown.",5 Discussion,[0],[0]
"This work makes it possible to translate with higher quality while still being at least twice as fast as the previous baseline.
",5 Discussion,[0],[0]
"As the numbers reported in Section 4 demonstrate, 8-bit and 32-bit decoding have similar average quality.",5 Discussion,[0],[0]
"As expected, the outputs produced by the two decoders are not identical.",5 Discussion,[0],[0]
"In fact, on a run of 166 sentences of De-En translation, only 51 were identical between the two.",5 Discussion,[0],[0]
"In addition, our human evaluation results and the automatic scoring suggest that there is no specific degradation by the 8-bit decoder compared to the 32-bit decoder.",5 Discussion,[0],[0]
"In order to emphasize these claims, Table 8 shows several examples of output from the two systems for a German-English system.",5 Discussion,[0],[0]
"Table 9 shows 2 more examples from a Dutch-English system.
",5 Discussion,[0],[0]
"In general, there are minor differences without any loss in adequacy or fluency due to 8-bit decoding.",5 Discussion,[0],[0]
"Sentence 2 in Table 8 shows a spelling error (“predictated”) in the 32-bit output due to re-
assembly of incorrect subword units.1",5 Discussion,[0],[0]
"Reducing the resources required for decoding neural nets in general and neural machine translation in particular has been the focus of some attention in recent years.
",6 Related Work,[0],[0]
Vanhoucke et al. (2011) explored accelerating convolutional neural nets with 8-bit integer decoding for speech recognition.,6 Related Work,[0],[0]
They demonstrated that low precision computation could be used with no significant loss of accuracy.,6 Related Work,[0],[0]
"Han et al. (2015) investigated highly compressing image classification neural networks using network pruning, quantization, and Huffman coding so as to fit completely into on-chip cache, seeing significant improvements in speed and energy efficiency while keeping accuracy losses small.
",6 Related Work,[0],[0]
"Focusing on machine translation, Devlin (2017) implemented 16-bit fixed-point integer math to speed up matrix multiplication operations, seeing a 2.59x improvement.",6 Related Work,[0],[0]
They show competitive BLEU scores on WMT English-French NewsTest2014 while offering significant speedup.,6 Related Work,[0],[0]
"Similarly, (Wu et al., 2016) applies 8-bit end-toend quantization in translation models.",6 Related Work,[0],[0]
They also show that automatic metrics do not suffer as a result.,6 Related Work,[0],[0]
"In this work, quantization requires modification to model training to limit the size of matrix outputs.",6 Related Work,[0],[0]
"In this paper, we show that 8-bit decoding for neural machine translation runs up to 4-6x times faster than a similar optimized floating point implementation.",7 Conclusions and Future Work,[0],[0]
We show that the quality of this approximation is similar to that of the 32-bit version.,7 Conclusions and Future Work,[0],[0]
"We also show that it is unnecessary to modify the training procedure to produce models compatible with 8- bit decoding.
",7 Conclusions and Future Work,[0],[0]
"To conclude, this paper shows that 8-bit decoding is as good as 32-bit decoding both in automatic measures and from a human perception perspective, while it improves latency substantially.
",7 Conclusions and Future Work,[0],[0]
In the future we plan to implement a multilayered matrix multiplication that falls back to the naive algorithm for matrix-panel multiplications.,7 Conclusions and Future Work,[0],[0]
This will provide speed for batch decoding for applications that can take advantage of it.,7 Conclusions and Future Work,[0],[0]
"We also
1In order to limit the vocabulary, we use BPE subword units (Sennrich et al., 2016) in all models.
plan to explore training with low precision for faster experiment turnaround time.
",7 Conclusions and Future Work,[0],[0]
Our results offer hints of improved accuracy rather than just parity.,7 Conclusions and Future Work,[0],[0]
Other work has used training as part of the compression process.,7 Conclusions and Future Work,[0],[0]
We would like to see if training quantized models changes the results for better or worse.,7 Conclusions and Future Work,[0],[0]
Neural machine translation has achieved levels of fluency and adequacy that would have been surprising a short time ago.,abstractText,[0],[0]
"Output quality is extremely relevant for industry purposes, however it is equally important to produce results in the shortest time possible, mainly for latency-sensitive applications and to control cloud hosting costs.",abstractText,[0],[0]
In this paper we show the effectiveness of translating with 8-bit quantization for models that have been trained using 32-bit floating point values.,abstractText,[0],[0]
Results show that 8-bit translation makes a non-negligible impact in terms of speed with no degradation in accuracy and adequacy.,abstractText,[0],[0]
Pieces of Eight: 8-bit Neural Machine Translation,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3233–3242 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3233",text,[0],[0]
The 20 Question Game (Q20 Game) is a classic game that requires deductive reasoning and creativity.,1 Introduction,[0],[0]
"At the beginning of the game, the answerer thinks of a target object and keeps it concealed.",1 Introduction,[0],[0]
"Then the questioner tries to figure out the target object by asking questions about it, and the answerer answers each question with a simple “Yes”, “No” or “Unknown”, honestly.",1 Introduction,[0],[0]
The questioner wins the game if the target object is found within 20 questions.,1 Introduction,[0],[0]
"In a Q20 game system, the
∗The work was done when the first author was an intern in Microsoft XiaoIce team.
",1 Introduction,[0],[0]
"user is considered as the answerer while the system itself acts as the questioner which requires a good question selection strategy to win the game.
",1 Introduction,[0],[0]
"As a game with the hype read your mind, Q20 has been played since the 19th century, and was brought to screen in the 1950s by the TV show Twenty Questions.",1 Introduction,[0],[0]
"Burgener’s program (Burgener, 2006) further popularized Q20 as an electronic game in 1988, and modern virtual assistants like Microsoft XiaoIce and Amazon Alexa also incorporate this game into their system to demonstrate their intelligence.
",1 Introduction,[0],[0]
"However, it is not easy to design the algorithm to construct a Q20 game system.",1 Introduction,[0],[0]
"Although the decision tree based method seems like a natural fit to the Q20 game, it typically require a well defined Knowledge Base (KB) that contains enough information about each object, which is usually not available in practice.",1 Introduction,[0],[0]
"Burgener (2006) instead uses a object-question relevance table as the pivot for question and object selection, which does not depend on an existing KB.",1 Introduction,[0],[0]
Wu et al. (2018) further improve the relevance table with a lot of engineering tricks.,1 Introduction,[0],[0]
"Since these table-based methods greedily select questions and the model parameters are only updated by rules, their models are very sensitive to noisy answers from users, which is common in the real-world Q20 games.",1 Introduction,[0],[0]
"Zhao and Maxine (2016) utilizes a value-based Reinforcement Learning (RL) model to improve the generalization ability but still relies on the existing KB.
",1 Introduction,[0],[0]
"In this paper, we formulate the process of question selction in the game as a Markov Decision Process (MDP), and further propose a novel policy-based RL framework to learn the optimal policy of question selection in the Q20 game.",1 Introduction,[0],[0]
"Our questioner agent maintains a probability distribution over all objects to model the confidence of the target object, and updates the confidence based on answers from the user.",1 Introduction,[0],[0]
At each time-step.,1 Introduction,[0],[0]
"the agent uses a policy network πθ(a|s) to take in
the confidence vector and output a question distribution for selecting the next question.",1 Introduction,[0],[0]
"To solve the problem that there is no immediate reward for each selected question, we also propose to employ a RewardNet to estimate the appropriate immediate reward at each time-step, which is further used to calculate the long-term return to train our RL model.",1 Introduction,[0],[0]
"Our RL framework makes the agent robust to noisy answers since the model parameters are fully learnable and the question distribution from πθ(a|s) provides us with a principled way to sample questions, which enables the agent to jump out of the local optimum caused by incorrect answers and also introduces more randomness during training to improve the model generalization ability.",1 Introduction,[0],[0]
"Furthermore, the ability to sample questions, compared to greedy selection, also improves the diversity of the questions asked by our agent, which is crucial for user experience.
",1 Introduction,[0],[0]
Our contributions can be summarized as follows: (1) We propose a novel RL framework to learn the optimal policy of question selection in the Q20 game without any dependencies on the existing KBs of target objects.,1 Introduction,[0],[0]
Our trained agent is robust to noisy answers and has a good diversity in its selected questions.,1 Introduction,[0],[0]
"(2) To make the reward more meaningful, we also propose a novel neural network on reward function approximation to deliver the appropriate immediate rewards at each time-step.",1 Introduction,[0],[0]
(3) Extensive experiments show that our RL method clearly outperforms a highly engineered baseline in the real-world Q20 games where noisy answers are common.,1 Introduction,[0],[0]
"Besides, our RL method is also competitive to that baseline on a noise-free simulation environment.",1 Introduction,[0],[0]
"In this section, we first describe our RL framework for playing the Q20 game, which is shown in the
Fig. 1.",2 Method,[0],[0]
The user in our system is the answerer who thinks of a target object otgt in the object set O at the beginning of the game.,2 Method,[0],[0]
Our policy-based agent acts as the questioner that can ask 20 questions to figure out what exactly otgt is.,2 Method,[0],[0]
"Specifically, an internal state vector s is maintained by our agent, which describes the confidence about otgt.",2 Method,[0],[0]
"At each time-step t, the agent picks up the promising action (select a question) according to the policy πθ(a|st), and transits from the state st to the next state st+1 after receiving the answer (“Yes”/“No”/“Unknown”) from the user.",2 Method,[0],[0]
"The historical trajectories 〈st, at, rt+1, st+1〉 are stored in a replay memory which enables the agent to be trained on previously observed data by sampling from it.",2 Method,[0],[0]
"Note that only when a guess is made about otgt at the end of game can the agent receive a reward signal, which makes it unable to distinguish the importance of each selected question.",2 Method,[0],[0]
"Therefore, we design a RewardNet to learn the more informative reward at each time-step and thus lead the agent to achieve the better performance.
",2 Method,[0],[0]
"In the rest of this section, we first describe how to formulate the Q20 game into a RL framework, and then introduce the RewardNet.",2 Method,[0],[0]
"Finally, we will demonstrate our training procedure in detail.",2 Method,[0],[0]
"In the Q20 game, the goal of our agent is to figure out the object otgt that the user thinks of at the beginning of game by asking 20 questions.",2.1 Modeling of the Q20 Game,[0],[0]
We formulate the process of question selection as a finite Markov Decision Process (MDP) which can be solved with RL.,2.1 Modeling of the Q20 Game,[0],[0]
"A tuple 〈S,A, P ,R, γ〉 is defined to represent the MDP, where S is the continuous state space, A = {a1, a2, · · · , am} is the set of all available actions, P(St+1 = s′|St = s,At = a) is the transition probability matrix,R(s, a) is the reward function and γ ∈",2.1 Modeling of the Q20 Game,[0],[0]
"[0, 1] is the discount factor used to calculate the long-time return.",2.1 Modeling of the Q20 Game,[0],[0]
"In the RL framework, at each time-step t, the agent takes an action at under the state st according to the policy πθ(a|st).",2.1 Modeling of the Q20 Game,[0],[0]
"After interacting with the environment, the agent receives a reward scalar rt+1 and transits to the next state st+1, then another time-step begins.",2.1 Modeling of the Q20 Game,[0],[0]
"All these trajectories 〈st, at, rt+1, st+1〉 in a game constitute an episode which is an instance of the finite MDP.",2.1 Modeling of the Q20 Game,[0],[0]
"The long-time return Gt of the time-step t is calculated as follows:
Gt = T∑ k=0 γkrt+k+1 (1)
",2.1 Modeling of the Q20 Game,[0],[0]
"In the following parts, we describe each component of RL corresponding to the Q20 game.
Environment.",2.1 Modeling of the Q20 Game,[0],[0]
The major component of our environment is the user in the Q20 game who decides the target object otgt and answers questions from the agent.,2.1 Modeling of the Q20 Game,[0],[0]
"Besides, the environment also needs to deliver the reward based on the outcome of the game and store historical data into the replay memory (see Fig. 1).
Action.",2.1 Modeling of the Q20 Game,[0],[0]
"Since the agent interacts with the user by asking questions, the action at ∈ A taken by our agent refers to selecting the question qat at timestep t, andA is the set of the indices to all available questions in the Q20 game.
State.",2.1 Modeling of the Q20 Game,[0],[0]
"In our method, we use the state st to keep track of the current confidence of target object otgt.",2.1 Modeling of the Q20 Game,[0],[0]
Specifically st ∈ R|O| and ∑n i=1,2.1 Modeling of the Q20 Game,[0],[0]
"st,i = 1, where O = {o1, o2, · · · , on} represents the set of all the objects that can be chosen by the user.",2.1 Modeling of the Q20 Game,[0],[0]
"Therefore, the state st is a probability distribution over all the objects and st,i is the confidence that the object oi is the target object otgt at time-step t.
The initial state s0 can either be a uniform distribution or initialized by the prior knowledge.",2.1 Modeling of the Q20 Game,[0],[0]
We observe that users typically prefer to choose popular objects which are more concerned by the public.,2.1 Modeling of the Q20 Game,[0],[0]
"For example, the founder of Tesla Inc. and the designer of SpaceX, “Elon Musk”, is more likely to be chosen compared to a CEO of a new startup.",2.1 Modeling of the Q20 Game,[0],[0]
"Motivated by this, we could use the yearly retrieval frequency C(oi) of object oi on a commercial search engine to calculate the initial state s0, where s0,i = C(oi) /",2.1 Modeling of the Q20 Game,[0],[0]
"∑n j=1C(oj).
",2.1 Modeling of the Q20 Game,[0],[0]
Transition Dynamics.,2.1 Modeling of the Q20 Game,[0],[0]
"In our method, the transition dynamics is deterministic.",2.1 Modeling of the Q20 Game,[0],[0]
"Given the object set O and the question set A, we collect the normalized probabilities of the answer over “Yes”, “No” and “Unknown” for each object-question pair.",2.1 Modeling of the Q20 Game,[0],[0]
"And the rule of state transition is define as:
st+1 = st α (2)
where α depends on the answer xt to the question qat which is selected by the agent at the step t:
α =  ",2.1 Modeling of the Q20 Game,[0],[0]
"[R(1, at), . . .",2.1 Modeling of the Q20 Game,[0],[0]
", R(|O|, at)], xt = Y es
[W (1, at), . . .",2.1 Modeling of the Q20 Game,[0],[0]
",W (|O|, at)], xt =",2.1 Modeling of the Q20 Game,[0],[0]
"No [U(1, at), . . .",2.1 Modeling of the Q20 Game,[0],[0]
", U(|O|, at)], xt = Unk
(3) where O is the object set and for each objectquestion pair (oi, qj), R(i, j) and W (i, j) are cal-
culated as follows:
R(i, j) = Cyes(i, j) + δ
Cyes(i, j) +",2.1 Modeling of the Q20 Game,[0],[0]
"Cno(i, j) +",2.1 Modeling of the Q20 Game,[0],[0]
"Cunk(i, j) + λ
W (i, j) = Cno(i, j) + δ
Cyes(i, j) + Cno(i, j) +",2.1 Modeling of the Q20 Game,[0],[0]
"Cunk(i, j) + λ
(4)
R(i, j) and W (i, j) are probabilities of answering “Yes” and “No” to question qj with respect to the object oi respectively.",2.1 Modeling of the Q20 Game,[0],[0]
"Cyes(i, j), Cno(i, j) and Cunk(i, j) are frequencies of answering “Yes”, “No” and “Unknown” to question qj with respect to the object oi.",2.1 Modeling of the Q20 Game,[0],[0]
δ,2.1 Modeling of the Q20 Game,[0],[0]
and λ are smoothing parameters.,2.1 Modeling of the Q20 Game,[0],[0]
"Then the probability of answering “Unknown” to question qj with respect to the object oi is:
U(i, j) = 1−R(i, j)−W (i, j) (5)
",2.1 Modeling of the Q20 Game,[0],[0]
"In this way, the confidence st,i that the object oi is the target object otgt is updated following the user’s answer xt to the selected question qat at the time-step t.
Policy Network.",2.1 Modeling of the Q20 Game,[0],[0]
We directly parameterize the policy πθ(a|st) with a neural network which maps the state st to a probability distribution over all available actions: πθ(a|st) = P[a|st; θ].,2.1 Modeling of the Q20 Game,[0],[0]
The parameters θ are updated to maximize the expected return which is received from the environment.,2.1 Modeling of the Q20 Game,[0],[0]
"Instead of learning a greedy policy in value-based methods like DQN, the policy network is able to learn a stochastic policy which can increase the diversity of questions asked by our agent and potentially make the agent more robust to noisy answers in the real-world Q20 game.",2.1 Modeling of the Q20 Game,[0],[0]
The policy πθ(a|s) is modeled by a Multi-Layer Perceptron (MLP) and the output layer is normalized by using a masked softmax function to avoid selecting the question that has been asked before.,2.1 Modeling of the Q20 Game,[0],[0]
Because asking the same question twice does not provide extra information about otgt in a game.,2.1 Modeling of the Q20 Game,[0],[0]
"For most reinforcement learning applications, it is always a critical part to design reward functions, especially when the agent needs to precisely take actions in a complex task.",2.2 Problem of Direct Reward,[0],[0]
"A good reward function can improve the learning efficiency and help the agent achieve better performances.
",2.2 Problem of Direct Reward,[0],[0]
"In the Q20 game, however, the immediate reward rt of selecting question qat is unknown at the time-step t (t < T ) because each selected question is just answered with a simple “Yes”, “No” or
“Unknown” and there is no extra information provided by user.",2.2 Problem of Direct Reward,[0],[0]
Only when the game ends (t = T ) can the agent receive a reward signal of win or loss.,2.2 Problem of Direct Reward,[0],[0]
So we intuitively consider the direct reward: rT = 30 and −30 for the win and loss respectively while rt = 0 for all t < T .,2.2 Problem of Direct Reward,[0],[0]
"Unfortunately, the direct reward is not discriminative because the agent receives the same immediate reward rt = 0 (t < T ) for selecting both good and bad questions.",2.2 Problem of Direct Reward,[0],[0]
"For example, if the otgt is “Donald Trump”, then selecting question (a) “Is your role the American president?” should receive more immediate reward rt than selecting question (b) “Has your role been married?”.",2.2 Problem of Direct Reward,[0],[0]
"The reason is that as for the otgt, question (a) is more relevant and can narrow down the searching space to a greater extent.
",2.2 Problem of Direct Reward,[0],[0]
"Therefore, it is necessary to design a better reward function to estimate a non-zero immediate reward rt, and make the long-time return Gt =∑T
k=0",2.2 Problem of Direct Reward,[0],[0]
γ krt+k+1 more informative.,2.2 Problem of Direct Reward,[0],[0]
"To solve the problem of the direct reward, we propose a reward function which employs a neural network to estimate a non-zero immediate reward rt at each time-step.",2.3 Reward Function Approximation by Neural Network,[0],[0]
"So that Gt can be more informative, which thus leads to a better trained questioner agent.
",2.3 Reward Function Approximation by Neural Network,[0],[0]
"The reward function takes the state-action pair (st, at) as input and outputs the corresponding immediate reward rt+1.",2.3 Reward Function Approximation by Neural Network,[0],[0]
"In our method, we use a MLP with sigmoid output to learn the appropriate immediate reward during training, and this network is referred as RewardNet.",2.3 Reward Function Approximation by Neural Network,[0],[0]
"In each episode, the long-term return Gt is used as a surrogate indicator of rt+1 to train our RewardNet with the following loss function:
L1(σ) =",2.3 Reward Function Approximation by Neural Network,[0],[0]
"(R(st, at;σ)− sigmoid(Gt))2 (6)
where σ is the network parameters.",2.3 Reward Function Approximation by Neural Network,[0],[0]
Here we apply the sigmoid function on Gt so as to prevent Gt from growing too large.,2.3 Reward Function Approximation by Neural Network,[0],[0]
"Besides, we also use the replay memory to store both old and recent experiences, and then train the network by sampling mini-batches from it.",2.3 Reward Function Approximation by Neural Network,[0],[0]
"The training process based on the experience replay technique can decorrelate the sample data and thus make the training of the RewardNet more efficient.
",2.3 Reward Function Approximation by Neural Network,[0],[0]
"Furthermore, since the target object otgt can be obtained at the end of each episode, we can
use the extra information provided by otgt to estimate a better immediate reward rt.",2.3 Reward Function Approximation by Neural Network,[0],[0]
"To capture the relevance between the selected questions and otgt in an episode, we further propose a objectaware RewardNet which takes the 〈st, at, otgt〉 tuple as input and produces corresponding rt+1 as output.",2.3 Reward Function Approximation by Neural Network,[0],[0]
The detailed training algorithm is shown in Algo.,2.3 Reward Function Approximation by Neural Network,[0],[0]
"1.
",2.3 Reward Function Approximation by Neural Network,[0],[0]
Algorithm 1: Training Object-Aware RewardNet 1 Initialize replay memory D1 to capacity N1 2 Initialize RewardNet with random weights σ 3 for episode i← 1 to Z do 4,2.3 Reward Function Approximation by Neural Network,[0],[0]
"User chooses object oi from O 5 Initialize temporary set S1 and S2 6 Play with policy πθ(at|st), and store (st, at) in S1, where t ∈",2.3 Reward Function Approximation by Neural Network,[0],[0]
"[0, T ] 7 rT ← 30 or −30 for a win or loss 8 for (st, at) in S1 do 9 Get rt+1 from RewardNet
10 Store (st, at, rt+1) tuple in S2 11 for (st, at, rt+1) in S2 do 12 Gt ← ∑T k=0",2.3 Reward Function Approximation by Neural Network,[0],[0]
"γ
krt+k+1 13 r′t+1 ← sigmoid(Gt) 14 Store (st, at, oi, r′t+1) in D1 15 if len(D1) > K1 then 16 Sample mini-batch from D1 17 Update σ with loss L1(σ) in Eq. 6",2.3 Reward Function Approximation by Neural Network,[0],[0]
"We train the policy network using REINFORCE (Williams, 1992) algorithm and the corresponding loss function is defined as follows:
L2(θ) = −Eπθ",2.4 Training the Policy-Based Agent,[0],[0]
[log πθ(at|st)(Gt − bt)],2.4 Training the Policy-Based Agent,[0],[0]
"(7)
where the baseline bt is a estimated value of the expected future reward at the state st, which is produced by a value network Vη(st).",2.4 Training the Policy-Based Agent,[0],[0]
"Similarly, the value network Vη(st) is modeled as a MLP which takes the state st as input and outputs a real value as the expected return.",2.4 Training the Policy-Based Agent,[0],[0]
"By introducing the baseline bt for the policy gradient, we can reduce the variance of gradients and thus make the training process of policy network more stable.",2.4 Training the Policy-Based Agent,[0],[0]
"The network parameters η are updated by minimizing the loss function below:
L3(η) = (Vη(st)−Gt)2 (8)
Note that, in our method, both the RewardNet and the value network Vη(st) approximate the reward during training.",2.4 Training the Policy-Based Agent,[0],[0]
But the difference lies in that the RewardNet is designed to estimate a appropriate non-zero reward rt and further derive the more informative return Gt while Vη(st) aims to learn a baseline bt to reduce the variance of policy gradients.,2.4 Training the Policy-Based Agent,[0],[0]
We combine both of two networks to improve the gradients for our policy network and thus lead to a better agent.,2.4 Training the Policy-Based Agent,[0],[0]
The training procedure is described in Algo.,2.4 Training the Policy-Based Agent,[0],[0]
"2.
",2.4 Training the Policy-Based Agent,[0],[0]
Algorithm 2: Training the Agent 1 Initialize replay memory D2 to capacity N2 2 Initialize policy net π with random weights θ 3 Initialize value net V with random weights η 4,2.4 Training the Policy-Based Agent,[0],[0]
"Initialize RewardNet with random weights σ 5 for episode i← 1 to Z do 6 Rollout, collect rewards, and save the history in S2 (4-10 in Algo.",2.4 Training the Policy-Based Agent,[0],[0]
"1) 7 for (st, at, rt+1) in S2 do 8 Gt ← ∑T k=0",2.4 Training the Policy-Based Agent,[0],[0]
"γ
krt+k+1 9 Update RewardNet (13-17 in
Algo.",2.4 Training the Policy-Based Agent,[0],[0]
"1) 10 Store (st, at, Gt) in D2 11 if len(D2) > K2 then 12 Sample mini-batch from D2 13 Update η with loss L3 in Eq. 8 14 Update θ with loss L2 in Eq. 7",2.4 Training the Policy-Based Agent,[0],[0]
We use a user simulator to train our questioner agent and test the agent with the simulated answerer and real users.,3 Experimental Setup,[0],[0]
"Specifically, our experiments answer three questions: (1) Is our method more robust in real-world Q20 games, compared to the methods based on relevance table?",3 Experimental Setup,[0],[0]
(Section. 4.2),3 Experimental Setup,[0],[0]
And how does it perform in the simulation environment?,3 Experimental Setup,[0],[0]
(Section. 4.1) (2) Does our RewardNet help in the training process?,3 Experimental Setup,[0],[0]
"(Section. 4.3) (3) How the winning rate grows with the number of questions, and whether it is possible to stop earlier?",3 Experimental Setup,[0],[0]
(Section. 4.4),3 Experimental Setup,[0],[0]
Training the RL agent is challenging because the agent needs to continuously interact with the environment.,3.1 User Simulator,[0],[0]
"To speed up the training process of the proposed RL model, we construct a user simulator
which has enough prior knowledge to choose objects and answer questions selected by the agent.
",3.1 User Simulator,[0],[0]
"We collect 1,000 famous people and 500 questions for them.",3.1 User Simulator,[0],[0]
"Besides, for every person-question pair in our dataset, a prior frequency distribution over “Yes”, “No” and “Unknown” is also collected from thousands of real users.",3.1 User Simulator,[0],[0]
"For example, as for “Donald Trump”, question (a) “Is your role the American president?” is answered with “Yes” for 9,500 times, “No” for 50 times and “Unknown” for 450 times.",3.1 User Simulator,[0],[0]
"We use Eq.4 and 5 to construct three matrices R,W,U ∈ R|O|∗|A| (|O| = 1000, |A| = 500) which are used for state transition in the Section. 2.1.",3.1 User Simulator,[0],[0]
"Then given the object oi and question qj , the user simulator answers “Yes”, “No” and “Unknown” whenR(i, j),W (i, j), andU(i, j) has the max value among them respectively.
",3.1 User Simulator,[0],[0]
"Constructed by the prior knowledge, the simulator can give noise-free answer in most cases.",3.1 User Simulator,[0],[0]
"Because the prior frequency distribution for each person-question pair is collected from thousands of users with the assumption that most of them do not lie when answering questions in the Q20 game.
",3.1 User Simulator,[0],[0]
"In an episode, the simulator randomly samples a person following the object distribution s0, which is generated from the object popularity (see the state part of Section. 2.1), as the target object.",3.1 User Simulator,[0],[0]
Then the agent gives a guess when the number of selected questions reaches 20.,3.1 User Simulator,[0],[0]
"After that, the simulator check the agent’s answer and return a reward signal of win or loss.",3.1 User Simulator,[0],[0]
There is only one chance for the agent to guess in an episode.,3.1 User Simulator,[0],[0]
The win and loss reward are 30 and -30 respectively.,3.1 User Simulator,[0],[0]
"While the architectures of the policy network, RewardNet and value network can vary in different scenarios, in this paper, we simply use the MLP with one hidden layer of size 1,000 for all of them, but with different parameters.",3.2 Implementation Details,[0],[0]
"These networks take in the state vector directly, which is a probability distribution over all objects.",3.2 Implementation Details,[0],[0]
The RewardNet further takes in the one-hot vector of action at.,3.2 Implementation Details,[0],[0]
"Based on the input of RewardNet, the objectaware RewardNet takes one more target object otgt as the feature which is also a one-hot vector.
",3.2 Implementation Details,[0],[0]
"We use the ADAM optimizer (Kingma and Ba, 2014) with the learning rate 1e-3 for policy network and 1e-2 for both RewardNet and value network.",3.2 Implementation Details,[0],[0]
The discounted factor γ for calculating the long-term return is 0.99.,3.2 Implementation Details,[0],[0]
"The model was trained up
to 2,000,000 steps (2,00,000 games) and the policy network was evaluated every 5,000 steps.",3.2 Implementation Details,[0],[0]
"Each evaluation records the agent’s performance with a greedy policy for 2,000 independent episodes.",3.2 Implementation Details,[0],[0]
"The 2,000 target objects for these 2,000 episodes are randomly selected following the distribution s0, which is generated from the object popularity and kept the same for all the training settings.",3.2 Implementation Details,[0],[0]
"We compare our RL method with the entropybased model proposed by Wu et al. (2018), which utilizes the real-world answers to each objectquestion pair to calculate an object-question relevance matrix with the entropy-based method.",3.3 Competitor,[0],[0]
The relevance matrix is then used for question ranking and object ranking via carefully designed formulas and engineering tricks.,3.3 Competitor,[0],[0]
"Since this method is shown to be effective in their production environment, we consider it to be a strong baseline to our proposed RL model.",3.3 Competitor,[0],[0]
"We first evaluate our agent and the entropy-based baseline (referred to as EntropyModel, see Section. 3.3) by using the simulated user (Section. 3.1).",4.1 Simulated Evaluation,[0],[0]
"To investigate which initialization strategy of the state s0 is better (see the state part of Section. 2.1), we further evaluate two variants of our model: the agent with uniform distribution s0 (RL uniform) and the agent with the distribution s0 initialized by the prior knowledge on the object popularity (RL popularity).
",4.1 Simulated Evaluation,[0],[0]
"Fig. 2 shows the curves on the win rate of these methods evaluated on 2,000 independent episodes
with respect to the number of training steps.",4.1 Simulated Evaluation,[0],[0]
"Note that, the EntropyModel only needs to update its statistics during training and has already accumulated a significant number of data since it has been run for over a year in their production environment.",4.1 Simulated Evaluation,[0],[0]
"Therefore, only a small fraction of its statistics can be changed, which leads to a small rise at the beginning of training, and its win rate remains at around 95% afterwards.
",4.1 Simulated Evaluation,[0],[0]
"On the other hand, both our RL models continuously improve the win rate with the growing number of interactions with the user simulator, and they achieve 50% win rate after around 20,000 steps.",4.1 Simulated Evaluation,[0],[0]
"As we can see, although the s0 initialized with the prior knowledge of object popularity keeps consistent with the object selection strategy of the simulator, the agent with uniform distribution s0 (RL uniform) still performs clearly better than the agent with s0 based on the prior knowledge (RL popularity).",4.1 Simulated Evaluation,[0],[0]
The reason is that the former can explore the Q20 game environment more fully.,4.1 Simulated Evaluation,[0],[0]
The prior knowledge based s0 helps the agent narrow down the candidate space more quickly when the target object is a popular object.,4.1 Simulated Evaluation,[0],[0]
"However, it also becomes misleading when the target object is not popular and makes the agent even harder to correct the confidence of the target object.",4.1 Simulated Evaluation,[0],[0]
"On the contrary, the uniform distribution s0 makes the agent keep track of the target object only based on the user’s answers.",4.1 Simulated Evaluation,[0],[0]
"And the superior performance of the RL uniform indicates that our question selection policy is highly effective, which means it is not necessary to use the RL popularity to increase the win rate of hot objects in the game.
",4.1 Simulated Evaluation,[0],[0]
"As shown in Fig. 2, RL uniform achieves win rate 94% which is very close to EntropyModel.",4.1 Simulated Evaluation,[0],[0]
"Compared to our RL method, EntropyModel needs more user data to calculate their entropybased relevance matrix and involves many engineering tricks.",4.1 Simulated Evaluation,[0],[0]
The fact that RL uniform is competitive to EntropyModel in the noise-free simulation environment indicates that our RL method is very cost-effective: it makes use of user data more efficiently and is easier to implement.,4.1 Simulated Evaluation,[0],[0]
"To further investigate the performance of our RL method in the real-world Q20 game where noisy answers are common, we also conduct an human evaluation experiment.",4.2 Human Evaluation,[0],[0]
"Specifically, we let real
users to play the game with EntropyModel and RL uniform for 1,000 times respectively.",4.2 Human Evaluation,[0],[0]
"In the real-world Q20 game, users sometimes make mistakes when they answer the questions during the game.",4.2 Human Evaluation,[0],[0]
"For example, as for the target object “Donald Trump”, question (a) “Is your role the American president?” is sometimes answered with “No” or “Unknown” by real users.",4.2 Human Evaluation,[0],[0]
"On the contrary, the simulator hardly makes such mistakes since we have provided it with enough prior knowledge.",4.2 Human Evaluation,[0],[0]
As shown in Table.,4.2 Human Evaluation,[0],[0]
"1, RL uniform outperforms EntropyModel by about 4.5% on win rate in the real-world Q20 games.",4.2 Human Evaluation,[0],[0]
It shows that our RL method is more robust to noisy answers than EntropyModel.,4.2 Human Evaluation,[0],[0]
"Specifically, the robustness of our RL method to the noise is shown in the following two aspects.",4.2 Human Evaluation,[0],[0]
"First, compared to the rulebased statistics update in EntropyModel, our RL model can be trained by modern neural network optimizers in a principled way, which results in the better generalization ability of our model.",4.2 Human Evaluation,[0],[0]
"Secondly, different from the EntropyModel selecting the top-ranked question at each time-step, RL uniform samples a question following its question probability distribution πθ(a|s), which enables our agent to jump out of the local optimum caused by incorrect answers from users.",4.2 Human Evaluation,[0],[0]
"And since more randomness is introduced by sampling from the question probability distribution during training, it also improves the tolerance of our model towards the unexpected question sequences.
",4.2 Human Evaluation,[0],[0]
"Besides, we also find some interesting cases during human evaluation.",4.2 Human Evaluation,[0],[0]
"Sometimes, the RL agent selects a few strange questions which seems to be not that much relevant to the chosen object, but it can still find the correct answer at the end of game.",4.2 Human Evaluation,[0],[0]
"This situation is caused by the fact that our method samples questions based on the output of policy net, rather than greedy selection during training.",4.2 Human Evaluation,[0],[0]
We find that this phenomenon increases the user experience since it makes the agent more unpredictable to the users.,4.2 Human Evaluation,[0],[0]
"To investigate the effectiveness of our RewardNet (Section. 2.3), we further evaluate three variants of our model in the simulation environment: the model trained with with direct reward, RewardNet, and object-aware RewardNet, which are referred to as DirectReward, RewardNet, and ObjectRewardNet respectively.",4.3 The Effectiveness of RewardNet,[0],[0]
"They are all trained with the uniform distribution s0.
",4.3 The Effectiveness of RewardNet,[0],[0]
"As shown in Fig. 3, DirectReward converges in the early steps and has a relatively poor performance with the win rate 89%.",4.3 The Effectiveness of RewardNet,[0],[0]
Both RewardNet and ObjectRewardNet achieve the better performance with a win rate of 94% after convergence.,4.3 The Effectiveness of RewardNet,[0],[0]
"This clear improvement shows that the more informative long-term return, calculated with the immediate reward delivered by our RewardNet method, significantly helps the training of the agent.
",4.3 The Effectiveness of RewardNet,[0],[0]
"Furthermore, as shown in Fig. 3, we can also see that ObjectRewardNet learns faster than RewardNet in the early steps.",4.3 The Effectiveness of RewardNet,[0],[0]
"This indicates that ObjectRewardNet can estimate the immediate reward more quickly with the extra information provided by the target object, which leads to the faster convergence of the agent.",4.3 The Effectiveness of RewardNet,[0],[0]
"In this section, we investigate how the win rate grows with the number of asked questions and whether a early-stop strategy can be adopted in the game.",4.4 Win Rate Regarding Question Numbers,[0],[0]
"We use the user simulator to play the game with the RL uniform agent and two settings are taken into account: the simulator samples the target object following the uniform object distribution (UnifSimulator), and samples following
the prior object distribution based on the object popularity (PopSimulator).",4.4 Win Rate Regarding Question Numbers,[0],[0]
"We perform 1,000 simulations for each number of questions, and the win rate curve is shown in Fig. 4.
",4.4 Win Rate Regarding Question Numbers,[0],[0]
As we can see that UnifSimulator achieves the win rate of 80% with only 14 questions in both settings.,4.4 Win Rate Regarding Question Numbers,[0],[0]
And the flat curves in the region after 18 questions indicate that the game can be early stopped with the almost same win rate at step 18.,4.4 Win Rate Regarding Question Numbers,[0],[0]
"Since a lower win rate is acceptable sometimes, other early-stop strategies can also be derived for the better user experience with the trade-off between the win rate and game steps.
",4.4 Win Rate Regarding Question Numbers,[0],[0]
"Besides, the fact that RL uniform performs similarly under both settings actually shows that our RL method is robust to different objects.",4.4 Win Rate Regarding Question Numbers,[0],[0]
It also performs well on infrequent objects where we may have the limited user data for constructing a well-tuned state transition dynamics.,4.4 Win Rate Regarding Question Numbers,[0],[0]
"When our agent is playing the game with real users, we select two cases from records.",4.5 Case Study,[0],[0]
"In the first case, the person that the user chooses is Cristiano Ronaldo, the famous football player.",4.5 Case Study,[0],[0]
"As we can see in Tab. 2, our agent can still figure out the target person while No.17 and No.19 questions are answered wrong by the user, which indicates our agent is robust to noisy answers.",4.5 Case Study,[0],[0]
"In the second case, the chosen person is Napoleon Bonaparte who was the French Emperor.",4.5 Case Study,[0],[0]
"Although there are some other candidates satisfied the constraints, the target person can be figured out because of the people popularity, which is shown in Tab. 3.",4.5 Case Study,[0],[0]
Q20.,5 Related Work,[0],[0]
"The Q20 game is popularized as an electronic game by the program of Robin Burgener in 1988 (Burgener, 2006), which uses a objectquestion relevance table to rank questions and target objects.",5 Related Work,[0],[0]
"Wu et al. (Wu et al., 2018) improves the relevance table with entropy-based metrics, and uses complicated engineering tricks to make it perform quite well in their production environment.",5 Related Work,[0],[0]
"These table-based methods use rules to update parameters, which makes them easily affected by noisy answers.",5 Related Work,[0],[0]
"Besides, Zhao and Maxine (2016) also explores Q20 in their dialogue state tracking research.",5 Related Work,[0],[0]
"However, they only use a small toy Q20 setting where the designed questions are about 6 person attributes in the Knowledge Base (KB).",5 Related Work,[0],[0]
"Since their method relies on the KB for narrowing down the scope of target object, it is not applicable to real-world Q20 games where a welldefined object KB is often unavailable.",5 Related Work,[0],[0]
"Compared to previous approaches, our RL method is robust to the answer noise and does not rely on the KB.
",5 Related Work,[0],[0]
Deep Reinforcement Learning.,5 Related Work,[0],[0]
"DRL has witnessed great success in playing complex games like Atari games (Mnih et al., 2015) , Go (Silver et al., 2016), and etc.",5 Related Work,[0],[0]
"In the natural language processing (NLP), DRL is also used to play text-based games (Narasimhan et al., 2015), and used to handle fundamental NLP tasks like machine translation (He et al., 2016) and machine comprehension (Hu et al., 2017) as well.",5 Related Work,[0],[0]
Our Q20 game lies in the intersection of the field of game and NLP.,5 Related Work,[0],[0]
"In this work, we propose a policy-based RL model that acts as the questioner in the Q20 game, and it exhibits the superior performance in our human evaluation.
",5 Related Work,[0],[0]
Natural Language Games.,5 Related Work,[0],[0]
"In the literature, there are some works focusing on solving and generating English riddles (De Palma and Weiner, 1992; Binsted, 1996) and Chinese character riddles (Tan et al., 2016).",5 Related Work,[0],[0]
"Compared to riddles, the Q20 game is a sequential decision process which requires careful modeling of this property.",5 Related Work,[0],[0]
"In this paper, we propose a policy-based RL method to solve the question selection problem in the Q20 Game.",6 Conclusions,[0],[0]
"Instead of using the direct reward, we further propose an object-aware RewardNet to estimate the appropriate non-zero reward and
thus make the long-time return more informative.",6 Conclusions,[0],[0]
"Compared to previous approaches, our RL method is more robust to the answer noise which is common in the real-world Q20 game.",6 Conclusions,[0],[0]
"Besides, our RL agent can also ask various questions and does not require the existing KB and complicated engineering tricks.",6 Conclusions,[0],[0]
"The experiments on a noisy-free simulation environment show that our RL method is competitive to an entropy-based engineering system, and clearly outperforms it on the human evaluation where noisy answers are common.
",6 Conclusions,[0],[0]
"As for the future work, we plan to explore methods to use machine reading to automatically construct the state transition dynamics from corpora like Wikipedia.",6 Conclusions,[0],[0]
"In this way, we can further build an end-to-end framework for the large-scale Q20 games in the real world.",6 Conclusions,[0],[0]
We gratefully thank the anonymous reviewers for their insightful comments and suggestions on the earlier version of this paper.,Acknowledgement,[0],[0]
The first author also thanks the Microsoft for providing resources for the research.,Acknowledgement,[0],[0]
The 20 Questions (Q20) game is a well known game which encourages deductive reasoning and creativity.,abstractText,[0],[0]
"In the game, the answerer first thinks of an object such as a famous person or a kind of animal.",abstractText,[0],[0]
Then the questioner tries to guess the object by asking 20 questions.,abstractText,[0],[0]
"In a Q20 game system, the user is considered as the answerer while the system itself acts as the questioner which requires a good strategy of question selection to figure out the correct object and win the game.",abstractText,[0],[0]
"However, the optimal policy of question selection is hard to be derived due to the complexity and volatility of the game environment.",abstractText,[0],[0]
"In this paper, we propose a novel policy-based Reinforcement Learning (RL) method, which enables the questioner agent to learn the optimal policy of question selection through continuous interactions with users.",abstractText,[0],[0]
"To facilitate training, we also propose to use a reward network to estimate the more informative reward.",abstractText,[0],[0]
"Compared to previous methods, our RL method is robust to noisy answers and does not rely on the Knowledge Base of objects.",abstractText,[0],[0]
Experimental results show that our RL method clearly outperforms an entropy-based engineering system and has competitive performance in a noisyfree simulation environment.,abstractText,[0],[0]
Playing 20 Question Game with Policy-Based Reinforcement Learning,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 92–102 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Every public speech involving a large audience can be seen as a game of coordination (Asch, 1951): at each moment, each individual member of the audience must decide in a split second whether to applaud at what has just been said.",1 Introduction,[0],[0]
"Applause is a potentially risky action: if an individual spontaneously claps but no one joins in, they suffer some negative social cost; the game is to judge from their own private information and content of the speech whether the rest of the audience will applaud at the same time they do.
",1 Introduction,[0],[0]
"Because of this cost, audiences respond to several interacting factors in a speaker’s behavior: a.) the content of the message; b.) their delivery (so that changes in pitch, duration and gaze signal salient moments for which applause may be licensed); and c.) the verbal design of the message—those rhetorical strategies that speakers use to signal that applause is welcome (Atkinson, 1984; Heritage and Greatbatch, 1986).
",1 Introduction,[0],[0]
"In this work, we attempt to model all three of these dimensions in developing a computational model for applause.",1 Introduction,[0],[0]
"While past work has focused on these elements in isolation (Guerini et al., 2015; Liu et al., 2017) or for related problems such as laughter detection (Purandare and Litman, 2006; Chen and Lee, 2017; Bertero and Fung, 2016), we find that developing a holistic model encompassing all three aspects yields the most robust predictor of applause.
",1 Introduction,[0],[0]
"We focus on political speeches, and in particular those at campaign rallies, which lend themselves well to analysis of rhetorical strategies for several reasons.",1 Introduction,[0],[0]
"First, the speakers at these events prioritize maintaining the crowd’s attention (Strangert, 2005).",1 Introduction,[0],[0]
"Motivated to drum up excitement and fervor among their supporters that they hope will carry beyond the event and into the voting booth, speakers pull out their strongest rhetorical tactics.",1 Introduction,[0],[0]
"Second, campaign speeches usually consist of a series of self-contained messages that can be fully expressed within a few utterances (Heritage and Greatbatch, 1986), yielding a well-defined observation of a complete rhetorical strategy.",1 Introduction,[0],[0]
"Lastly, these speeches are delivered by a single speaker to a partisan crowd, and clapping, cheering, and other responses are invited and expected.
",1 Introduction,[0],[0]
"We focus in particular in this work on operationalizating the verbal design of the speech; in so doing, one contribution we make is operationalizing the concepts of tension and release.",1 Introduction,[0],[0]
"Writers and performers often communicate with their audience on a fundamental level by building up tension, and then, at the proper time, delivering a satisfying release.",1 Introduction,[0],[0]
"These simple but pervasive concepts structure our experience of different modes of communication used throughout everyday life, including music (Madsen and Fredrickson, 1993), literature (Rabkin, 1973) and film (Carroll, 1996).
",1 Introduction,[0],[0]
"Tension in music can be built up by harmonic
92
movement away from a tonal center; release then comes with a return to that established tonic (Hindemith, 1937).",1 Introduction,[0],[0]
"One form of tension in literature is realized as suspense (Barthes and Duisit, 1975; Vorderer et al., 1996; Algee-Hewitt, 2016), in which a reader’s knowledge of events is uncertain (either because those events take place in the narrative future or are withheld from narration), and released when that knowledge is revealed.",1 Introduction,[0],[0]
"In film, sudden changes in camera perspective create graphic tension, which is then released as the shot returns to a stable position (Bordwell, 2013).",1 Introduction,[0],[0]
"Often, it is the confluence of multiple sources of tension that mark the climax of a narrative (Hume, 2017).",1 Introduction,[0],[0]
"We draw on each of these strands of work in operationalizing tension and release as a rhetorical strategy.
",1 Introduction,[0],[0]
"In this work, we make the following contributions:
• We collect a new dataset of text and audio from 310 speeches from campaign events leading up to the 2016 U.S presidential election with associated tags for over 19,000 instances of audience applause.
",1 Introduction,[0],[0]
"• We introduce new textual and acoustic features inspired by tension and release, combine and compare them with features used in previous work, and deploy those features in a logistic regression model and in an LSTM to predict when applause is likely to occur.",1 Introduction,[0],[0]
"Code, data, and trained models are openly available to the public at https://github.com/ jrgillick/Applause/.",1 Introduction,[0],[0]
"Heritage and Greatbatch (1986) conduct an extensive analysis of nearly 500 speeches from British political party conferences, manually associating each of over 2000 instances of applause with coded message types (e.g. External Attacks or Statements of Approval), rhetorical devices (e.g. Contrast/Antithesis or Headline-Punchline), and performance factors (e.g. speech stress or body language).",2.1 Rhetoric and Response,[0],[0]
"They find most of these factors to be positively correlated with applause; one especially striking result is over two thirds of observed instances of applause can be explained through a set of seven rhetorical devices (including contrast,
pursuit, position taking, and “the 3-part list”).",2.1 Rhetoric and Response,[0],[0]
"Though each device is different, a common feature of most of these techniques is that they are not always carried out within a single sentence or utterance; they often depend on the relationship between a series of utterances or phrases.",2.1 Rhetoric and Response,[0],[0]
We argue in this work that some of these relationships can be characterized and subsequently operationalized within models as tension and release.,2.1 Rhetoric and Response,[0],[0]
Recent work from Guerini et al. (2015) and Liu et al. (2017) approaches the task of applause prediction by looking at textual features of the individual sentences that immediately precede audience applause.,2.2 Predicting Applause,[0],[0]
"Both follow the methodology proposed by Danescu-Niculescu-Mizil et al. (2012) in constructing a data set for binary classification, which is composed of sentences that generated applause, each paired with a single nearby sentence from the same document that did not lead to applause.
",2.2 Predicting Applause,[0],[0]
"Guerini et al. (2015) examine a set of features designed to capture aspects of euphony, or “the inherent pleasantness of the sounds of words” that might make an utterance memorable or persuasive—such as rhyme, alliteration, homogeneity, and plosives.",2.2 Predicting Applause,[0],[0]
"On the CORPS dataset (Guerini et al., 2013), which consists of the text of several thousand political speeches dating from 1917 to 2011, they define persuasive sentences as those that preceded annotations of either applause or laughter.
",2.2 Predicting Applause,[0],[0]
"Liu et al. (2017), working with a corpus of TED talks, use logistic regression to predict applause from sentences using a combination of features: euphony (again from Guerini et al. (2015)), linguistic style markers derived from membership in LIWC categories, markers of emotional expression derived from membership in the NRC Emotion Lexicon, mentions of names, rhetorical questions (string matching for “?”), expressions of gratitude (matching a handcrafted list of word stems including “thank∗” and “grateful∗”), and expressions seeking applause (matching the pattern “applau∗”).",2.2 Predicting Applause,[0],[0]
Liu et al. (2017) also report that adding the same features for earlier sentences beyond the final sentence that preceded the applause caused the prediction accuracy to go down.,2.2 Predicting Applause,[0],[0]
"Chen and Lee (2017) and Bertero and Fung (2016) run similar binary classification experiments but pre-
dict laughter as opposed to applause.",2.2 Predicting Applause,[0],[0]
Bertero and Fung (2016) analyze punchlines from the TV sitcom “The Big Bang Theory” and report 70% accuracy using an LSTM.,2.2 Predicting Applause,[0],[0]
"They touch briefly on the notion of tension and release in humor, as punchlines typically depend on a previous line as a setup in order to be funny.",2.2 Predicting Applause,[0],[0]
"In this work, we focus on a new data set of campaign speeches from the 2016 U.S. presidential race, which we obtain from the public domain broadcasts of C-SPAN.",3.1 Corpus Acquisition,[0],[0]
"We downloaded about 500 speeches from presidential candidates, vice presidential candidates, or former presidents, collecting audio files and transcripts that were tagged in the categories “Campaign 2016” and “Speech” and which took place between 12/01/2015 and 12/01/2016.",3.1 Corpus Acquisition,[0],[0]
"We then excluded events that took place outside of a traditional campaign speech setting (e.g. town hall events) or events that contained multiple speakers without a speaker identification tied to the transcript, which yielded a final set of 310 speeches from 16 speakers.",3.1 Corpus Acquisition,[0],[0]
"Because different types of events have different social norms around when and whether applause is appropriate (Atkinson, 1984; Heritage and Greatbatch, 1986), we control for these factors to some degree by restricting our dataset to events in similar settings and within a single year.",3.1 Corpus Acquisition,[0],[0]
"As a point of comparison, the C-SPAN dataset contains 62 instances of applause per speech on average, whereas the CORPS data (Guerini et al., 2013) contains 13.",3.1 Corpus Acquisition,[0],[0]
"Since our C-SPAN data originates in video, we have access to the audio information of a speech event, which we employ both for feature extraction and for automatically identifying when applause occurs.",3.2 Applause Detection in Audio,[0],[0]
"Following Clement and McLaughlin (2016), we train an acoustic model using a set of poetry readings from the PennSound archive to distinguish applause from speech.",3.2 Applause Detection in Audio,[0],[0]
We used logistic regression on the standard set of MFCC features and found similar results on the PennSound data to the reported classification accuracy of 99.4%.,3.2 Applause Detection in Audio,[0],[0]
"In a manual inspection of 100 applause segments from 5 different speeches in the C-SPAN corpus, our applause detector achieved 92% preci-
sion, 90% recall, and 91% F1 score.",3.2 Applause Detection in Audio,[0],[0]
"Due to variation in the nature of applause in a crowd (sometimes we observe examples of isolated clapping and cheering, mixed laughter and applause, or applause interrupting the speaker), some ambiguity is inherent among the labels.
",3.2 Applause Detection in Audio,[0],[0]
"We also measure the applause by first running the speeches through the audio source separation algorithm from Chandna et al. (2017), which was trained to separate voice from music, and then measuring the RMSE loudness of the separated non-vocal track.",3.2 Applause Detection in Audio,[0],[0]
"We found that the separation worked well, qualitatively matching with the results from the applause detection classifier.",3.2 Applause Detection in Audio,[0],[0]
"To match the identified segments of applause in the audio files with the relevant text from the transcriptions, we ran forced alignment using the Kaldi Toolkit (Povey et al., 2011).",3.3 Forced Alignment,[0],[0]
"Since the CSPAN transcripts are sourced from uncorrected closed captioning, the text contains a number of misspellings and paraphrases, which we handled by discarding the 12% of words for which forced alignment failed.",3.3 Forced Alignment,[0],[0]
"Though these transcriptions are not as accurate as what we would find in professionally transcribed datasets, previous work has shown that it is possible to achieve good accuracy in downstream tasks even with high error rates in transcription (Peskin et al., 1993; Novotney and Callison-Burch, 2010).",3.3 Forced Alignment,[0],[0]
"Moreover, the caliber of transcripts derived from closed captioning is representative of the data that would be available in real time for practical use at future speech events.
",3.3 Forced Alignment,[0],[0]
"To estimate the accuracy of the closed captions, we manually transcribed selections from 5 speeches in the C-SPAN data totaling about 25 minutes and 2250 words, finding 30.9% WER relative to the reference transcriptions in our sample.",3.3 Forced Alignment,[0],[0]
"Many of the errors are due to omitted words and phrases in the closed captions, which may occur as a result of transcribers’ inability to keep up with the pace of fast speeches; in this sample, the closed caption texts contained 17% fewer words than our gold standard transcriptions.
",3.3 Forced Alignment,[0],[0]
"After finding the alignments, we segmented out a list of utterances by defining a minimum period of silence between words.",3.3 Forced Alignment,[0],[0]
"Since many of the transcripts do not have punctuation, we find that dividing the text into utterances yielded qualitatively more coherent units than sentence boundary detec-
tion.",3.3 Forced Alignment,[0],[0]
"Dividing into utterances is also conducive to building a dataset for binary classification, since every pause by the speaker yields an opportunity for applause.",3.3 Forced Alignment,[0],[0]
"We chose a pause length of 0.7 seconds, but in future work we might be able to improve our models by adapting this threshold to the rate of speech in order to maintain consistent phrase sizes across different speakers.",3.3 Forced Alignment,[0],[0]
"Given this set of utterances, we paired each utterance with a “positive” or “negative” label, determined by whether applause occurred within 1.5 seconds of the end of the utterance.",3.3 Forced Alignment,[0],[0]
"All of these preprocessing choices were made during the corpus preparation phase, prior to any experimental evaluation.
",3.3 Forced Alignment,[0],[0]
"Table 1 provides summary statistics for the number of speakers, speeches, utterances, and acts of applause in our data.",3.3 Forced Alignment,[0],[0]
"In our models, we draw features from previous work on applause or humor prediction and then supplement them with a new set of features inspired by the ideas of tension and release and by the rhetorical strategies of Heritage and Greatbatch (1986).",4 Models,[0],[0]
LIWC.,4.1 Features adapted from existing work,[0],[0]
"Features for membership in 73 LIWC categories proved to be the most effective for applause prediction in TED talks (Liu et al., 2017).
",4.1 Features adapted from existing work,[0],[0]
Euphony.,4.1 Features adapted from existing work,[0],[0]
We adopt the 4 features for “euphony” defined by Guerini et al. (2015):,4.1 Features adapted from existing work,[0],[0]
"Rhyme, Alliteration, Homogeneity, and Plosives.
",4.1 Features adapted from existing work,[0],[0]
Lexical.,4.1 Features adapted from existing work,[0],[0]
Guerini et al. (2015) find n-grams to be highly predictive of both applause and laughter.,4.1 Features adapted from existing work,[0],[0]
"We operationalize these features with bigrams, including in our model all bigrams that appear at least 5 times in the corpus.
Embeddings.",4.1 Features adapted from existing work,[0],[0]
Bertero and Fung (2016) use sentence embeddings learned from a CNN encoder as input to an LSTM.,4.1 Features adapted from existing work,[0],[0]
"We adopt this feature for use in our neural models, encoding phrases using the Skip-Thought model of Kiros et al. (2015).
Acoustic.",4.1 Features adapted from existing work,[0],[0]
Purandare and Litman (2006) use a set of features intended to capture elements of prosody in a model for humor prediction in television dialogue.,4.1 Features adapted from existing work,[0],[0]
"These features include the mean, max, min, range, and standard deviation values in an utterance’s pitch (F0) and energy (RMS), along with features for internal silence and for tempo.",4.1 Features adapted from existing work,[0],[0]
"We compute the F0 statistics with Reaper (Talkin, 2015) and the energy statistics with Librosa (McFee et al., 2015).",4.1 Features adapted from existing work,[0],[0]
Repeated Words.,4.2.1 Repetition,[0],[0]
Rhetorical strategies such as “The 3-part List” and “Contrast” rely on repetition to drive home important points.,4.2.1 Repetition,[0],[0]
"We capture this phenomenon by computing the proportion of words in each utterance that also appear in the immediately preceding phrase.
",4.2.1 Repetition,[0],[0]
Longest Common Subsequence.,4.2.1 Repetition,[0],[0]
"Repeating an entire phrase, especially one with a politically charged topic, serves to build tension through the notion of “theme and variation” as is often realized
in music (Cope, 2005); an example of this phenomenon in our data can be found in the following passage:
We will not allow the party of Lincoln and Reagan to fall into the hands of a con artist.",4.2.1 Repetition,[0],[0]
We will not allow the next president of the United States to be a socialist like Bernie Sanders.,4.2.1 Repetition,[0],[0]
"And we will not allow the next president of the United States to be someone under FBI investigation like Hillary Clinton.
",4.2.1 Repetition,[0],[0]
"[Marco Rubio, Mar. 1, 2016]
We calculate this theme and variation by measuring the longest common subsequence between adjacent phrases.",4.2.1 Repetition,[0],[0]
"Delta features (local approximations to derivatives) are commonly used in speech recognition and audio classification systems (Povey et al., 2011).",4.2.2 Deltas,[0],[0]
"In a discourse, either highly similar or drastically different neighboring pairs of utterances may indicate dramatic moments.",4.2.2 Deltas,[0],[0]
"We operationalize these features by explicitly adding a delta measurement for every feature in our model, which captures the difference between every feature at time t and the same feature at time t − 1.",4.2.2 Deltas,[0],[0]
"For K-dimensional vector embeddings, we calculate deltas as their cosine distance.",4.2.2 Deltas,[0],[0]
"Rhetorical Structure Theory (RST) provides a foundation for describing the ways in which functional components of a text combine to form a coherent whole (Thompson and Mann, 1987).",4.2.3 RST,[0],[0]
At the core of RST is a categorization system consisting of relations between elementary discourse units (EDUs).,4.2.3 RST,[0],[0]
"Relations between units are typically hierarchical (a nucleus and a satellite), but can also be defined between equally significant units (two nuclei).
",4.2.3 RST,[0],[0]
"A typical RST tree can be seen below, where the sentence “He won’t win, but I’ll vote for him anyway”, he said is decomposed into three elementary discourse units (EDUs); those discourse units form the leaves of a tree with intermediate structure between subphrases and labeled edges along each branch.
",4.2.3 RST,[0],[0]
"ATTRIBUTION
CONTRAST
“He won’t win,
but I’ll vote for him anyway”
he said.
",4.2.3 RST,[0],[0]
"Some of the rhetorical strategies defined by Heritage and Greatbatch (1986), such as “Contrast,” map directly to RST relations, while others do not have a clear one-to-one mapping but are qualitatively similar in their descriptions.",4.2.3 RST,[0],[0]
"While RST has been used with success for classification problems in the past (Ji and Smith, 2017; Bhatia et al., 2015), it has not yet been employed in existing models for applause prediction.",4.2.3 RST,[0],[0]
"In our work, we parse the rhetorical structure of the extracted sequence of phrases using the RST parser of Ji and Eisenstein (2014).",4.2.3 RST,[0],[0]
"From the structure of this RST tree, we extract two classes of features.
RST label.",4.2.3 RST,[0],[0]
"First, we operationalize the rhetorical category for an individual elementary discourse unit.",4.2.3 RST,[0],[0]
While the span of text within a single EDU is implicated in several rhetorical relations throughout the tree (as He won’t win bears a CONTRAST relationship with,4.2.3 RST,[0],[0]
but I’ll vote for him anyway and is part of the ATTRIBUTION relationship with he,4.2.3 RST,[0],[0]
"said), each EDU bears exactly one leaf relationship with the rest of the tree—here, He won’t win is a nucleus of a CONTRAST relationship, but I’ll vote for him anyway is also a nucleus of a CONTRAST relationship, and he said is the satellite of an ATTRIBUTION relationship.
",4.2.3 RST,[0],[0]
"We featurize a sentence as the set of all such typed relationships that EDUs within it hold; each typed relationship is the conjunction of the label (e.g., CONTRAST, ATTRIBUTION) and directionality (Nucleus, Satellite).
",4.2.3 RST,[0],[0]
Rhetorical phrase closures.,4.2.3 RST,[0],[0]
"In order to further operationalize the notion of predictability of applause, we measure the number of rhetorical phrases that a given discourse segment brings to closure.",4.2.3 RST,[0],[0]
"We can illustrate this with figure 1, which presents a sample RST tree with only the spans annotated (i.e., without RST labels or nucleus/satellite directed edges).",4.2.3 RST,[0],[0]
"This tree spans 10 elementary discourse units; each non-terminal node is annotated with the span of the subtree
rooted at that node (so the root spans all ten EDUs, while its left child spans only the first five).",4.2.3 RST,[0],[0]
"The final discourse unit (EDU 10) is the final EDU in three rhetorical phrases (those spanning EDUs 9-10, 6-10 and the entire discourse 1-10).",4.2.3 RST,[0],[0]
"We might hypothesize that the greater number of discourse phrases that a given discourse unit closes, the stronger the signal it provides that applause is licensed (and hence the greater likelihood to be followed by applause empirically).",4.2.3 RST,[0],[0]
"For a sentence with multiple discourse units, we featurize this value as the maximum number of rhetorical phrases closed by any unit it contains.",4.2.3 RST,[0],[0]
"We present two experiments to uncover the degree to which we are able to predict applause from different operationalizations of a politician’s campaign speech: one in which have access to a politician’s previous speeches, and can learn their specific nuances and stock phrases used to solicit applause; and another in which we seek to uncover the broader rhetorical strategies common to multiple speakers.
",5 Experiments,[0],[0]
"We refer to the following sets of features when we summarize results:
• Guerini.",5 Experiments,[0],[0]
"Euphony features from Guerini et al. (2015).
",5 Experiments,[0],[0]
• Liu.,5 Experiments,[0],[0]
"LIWC features and additional matchers for handcrafted regular expressions from Liu et al. (2017)
• Audio.",5 Experiments,[0],[0]
All acoustic features described in §4.1 above.,5 Experiments,[0],[0]
•,5 Experiments,[0],[0]
Combined.,5 Experiments,[0],[0]
"Combination of features from
Guerini, Liu, and Audio.
• Tension.",5 Experiments,[0],[0]
"Combination of RST (§4.2.3), repetition (§4.2.1), and delta features (§4.2.2).",5 Experiments,[0],[0]
• N-gram.,5 Experiments,[0],[0]
Bigram features.,5 Experiments,[0],[0]
• Skip-Thought.,5 Experiments,[0],[0]
"4800 dimensional Skip-
Thought embeddings.",5 Experiments,[0],[0]
"Access to a politician’s previous speeches provides a great deal of evidence for understanding their rhetorical strategies for soliciting applause; speakers often give variations of the same speech at different campaign events, and rely on a fixed set of stock phrases (e.g., “Yes, We Can,” “Make America Great Again”) and general strategies to solicit reactions (Lu, 1999; Miller, 1939; Petrow and Sullivan, 2007).",5.1 Intra-speaker validation,[0],[0]
"To model this, we attempt to predict a speaker’s likelihood of applause using only information from their own speeches.
",5.1 Intra-speaker validation,[0],[0]
"We use logistic regression with `2 regularization for this experiment, with hyperparameters chosen through cross-validation on the training data.",5.1 Intra-speaker validation,[0],[0]
"We run 10-fold cross validation for each speaker, and leave-one-out cross validation for those speakers with fewer than 10 speeches (we exclude Rick Santorum from this experiment because we have only one speech from him), with whole speeches divided across folds so that no utterances from the same speech ever appear in both training and test sets.",5.1 Intra-speaker validation,[0],[0]
Reported results aggregate the predictions across all speakers to calculate the final accuracies.,5.1 Intra-speaker validation,[0],[0]
"We choose utterances (or sequences of utterances) that directly precede applause as positive examples, pairing each one with a negative example randomly chosen from the same speech.",5.1 Intra-speaker validation,[0],[0]
"Since we use different amounts of data for each speaker, we are not able to compare accuracies across all speakers, but we can see that some speakers are significantly easier to model: for example, our best model reaches 0.719 accuracy on Bernie Sanders but only 0.660 on Donald Trump.
",5.1 Intra-speaker validation,[0],[0]
"Table 2 summarizes the results, comparing across different combinations of features as well as across a scope of a single phrase or multiple phrases.",5.1 Intra-speaker validation,[0],[0]
All feature combinations are scoped over a single utterance unless otherwise noted.,5.1 Intra-speaker validation,[0],[0]
"At the same time, many of the strategies identified by Heritage and Greatbatch (1986) are gener-
alized rhetorical devices used to solicit applause; we should expect then that a model trained on a fixed set of speakers should be able to generalize to speakers not in the training data.",5.2 Inter-speaker validation,[0],[0]
"To test this more realistic scenario, we performed Kfold cross-validation on all of the speakers in our dataset, holding out one speaker in turn for each fold (so that the same speaker did not appear in the training and test partitions).
",5.2 Inter-speaker validation,[0],[0]
"In this experiment, we use both logistic regression and neural models (sharing training data between speakers has the added benefit of allowing us enough data to reasonably train a neural model).",5.2 Inter-speaker validation,[0],[0]
All logistic regression models were trained in the same way is in the intra-speaker case.,5.2 Inter-speaker validation,[0],[0]
Our feedforward and LSTM models use a hidden state size of 100 for models including phrase embeddings (4800 dimensions) and a hidden state of size 25 for models without phrase embeddings.,5.2 Inter-speaker validation,[0],[0]
"All LSTM models use a standard formulation of attention (Bahdanau et al., 2014), and all neural models are trained with dropout (Srivastava et al., 2014) and the ADAM optimizer (Kingma and Ba, 2014).",5.2 Inter-speaker validation,[0],[0]
"We implemented the models using Keras (Chollet et al., 2015) and Tensorflow (Abadi et al., 2016).
",5.2 Inter-speaker validation,[0],[0]
"Table 3 summarizes these results, and table 4 shows the coefficients for the most significant features.",5.2 Inter-speaker validation,[0],[0]
"Each of the feature classes we operationalize offers some ability to recognize what Heritage and Greatbatch (1986) term the “projectability” of applause—the ability of an audience to see an applaudable moment on the horizon.
Audio.",6 Analysis,[0],[0]
"Perhaps not surprising in retrospect is the ability of acoustic features (only summary statistics of the pitch and energy) to solicit applause:
higher pitch and energy, and a broader pitch range are all predictive of applause; while past work has focused on textual indicators of applause, these results suggest that how a message is delivered is equally important.
",6 Analysis,[0],[0]
Lexical.,6 Analysis,[0],[0]
"The use of explicit n-grams improves performance significantly in the intra-speaker setting, where they are able to capture stock phrases employed by the same speaker at different events.",6 Analysis,[0],[0]
"N-grams are also predictive across different speakers, though the performance gains are not as high in the inter-speaker setting.
",6 Analysis,[0],[0]
"The strongest bigrams predictive of applause include moral declaratives like should not (e.g., “and billionaires should not be able to buy elections”",6 Analysis,[0],[0]
"[Bernie Sanders]), right to (“you have a right to be angry”",6 Analysis,[0],[0]
"[Marco Rubio]), and should be (“They should be ashamed of that kind of behavior”",6 Analysis,[0],[0]
"[Hillary Clinton]); call-outs to the audience such as this room (“Love the people in this room”
[Donald Trump]) and listening to (“our campaign is listening to our Latino brothers and sisters”",6 Analysis,[0],[0]
"[Bernie Sanders]); and politically charged topics such as political revolution, equal pay, immigration reform, planned parenthood, campaign contributors and police officers.
LIWC.",6 Analysis,[0],[0]
"Among broader lexical category features, we see the LIWC FOCUSFUTURE category strongly indicative of applause; this category includes auxilaries like will, going, gonna (including conjunctions I’ll) and future-oriented verbs like anticipate; also important are categories of BODY (including heart, hands, brain) and REWARD (including succeed, optimism, great).
",6 Analysis,[0],[0]
Rhetorical.,6 Analysis,[0],[0]
"While RST features were not as predictive for applause as other (likely correlated) features, we still see a strong alignment between the RST features most associated with applause and those rhetorical devices outlined by Heritage and Greatbatch (1986): in particular, a clear relationship between applause and the RST category of ANTITHESIS (a contrastive relation between two discourse units with a clear nucleus and satellite, rather than two equal nuclei) and PURPOSE (a relation between a discourse unit that must take place in order for another to be realized).",6 Analysis,[0],[0]
"As expected, phrases that close more discourse units tend to be more predictive of applause.
Contextual.",6 Analysis,[0],[0]
"Though lexical features from the final utterance significantly outweigh the effects of previous context in the intra-speaker setting, in the inter-speaker case we leveraged gains from longterm context in the LSTM to reach a similar level of performance attained from the lexical features,
but without access to lexical cues provided by the n-grams at all.",6 Analysis,[0],[0]
"This result suggests that the improved performance in the intra-speaker setting may be largely due to the presence of specific words and catch-phrases; the other stylistic features are more easily generalized to new speakers.
7 “Please clap”
As a further measure of out-of-sample validity, we can analyze the predictions we make for the single example where a speaker wears his communicative intent on his sleeve.",6 Analysis,[0],[0]
"On February 2, 2016, presidential candidate Jeb Bush spoke to a crowd in New Hampshire a week before their state primary.",6 Analysis,[0],[0]
"His speech ended with the following:
So here’s my pledge to you.",6 Analysis,[0],[0]
"[I] will be a commander-in-chief who will have the back of the military, I won’t trash talk, I won’t be a divider-in-chief or an agitator-in-chief, I won’t be out there blowharding talking a big game without backing it up; I think the next President needs to be a lot quieter but send a signal that we’re prepared to act in the national security interests of this country to get back in the business of creating a more peaceful world . . . . . . . . .",6 Analysis,[0],[0]
"Please clap.
",6 Analysis,[0],[0]
"[Jeb Bush, Feb 2, 2016]1
Bush’s admonition to the audience (“please clap”) earned criticism in news coverage at the time (Benen, 2016), but also presents us with a rare insight into a speaker’s true rhetorical intention; in this case, Bush was soliciting applause and was vocal about not being able to do so.
",6 Analysis,[0],[0]
Does our model recover this true intention?,6 Analysis,[0],[0]
"Indeed it does; while the opening So here’s my pledge to you is predicted to not solicit applause (with applause probability of 24.8%), the segment that ends with peaceful world is strongly predicted to have been followed by applause",6 Analysis,[0],[0]
(with an applause probability of 94.5%).,6 Analysis,[0],[0]
"The strongest features are again lexical (this country, commander in chief ), a LIWC focus on the future (elicited by will), and an RST PURPOSE relation (evoked by to get back in the business of creating a more peaceful world).
",6 Analysis,[0],[0]
1Video of this speech can be found at: https://www.,6 Analysis,[0],[0]
youtube.com/watch?v=DdCYMvaUcrA,6 Analysis,[0],[0]
"We present in this work a new dataset for the analysis of political rhetoric derived from the public campaign speeches of politicians during the 2016 United States presidential election, along with empirical results assessing the performance of different operationalizations of rhetoric derived from the theoretical work of Heritage and Greatbatch (1986) and others in order to measure and predict the occurrence of applause.",8 Conclusion,[0],[0]
"We introduce several new features designed to capture elements of tension and release in public performance, including rhetorical contrast, closure, repetition and movement across speech segments; while each of these features in isolation is able to predict applause to varying degree and comport with our prior understanding of their utility, we find that lexicalized features are among the strongest source of information in determining applause; while audiences react to many dimensions of a speaker’s style, the words they use—as slogan, stock phrases, and indicators of more complex rhetorical functions like moral valuations and imperatives—matter most.
",8 Conclusion,[0],[0]
"As detailed in previous work (Liu et al., 2017; Haider et al., 2017; Clement and McLaughlin, 2016), understanding and identifying climactic moments in speeches can be useful for a variety of reasons, including learning to give better talks, automatically summarizing videos and transcripts, and analyzing social dynamics within crowds.",8 Conclusion,[0],[0]
"One additional interesting application of this work is to bring to the surface occasions where a speaker uses typical applause-seeking devices but does not receive applause (the “Please Clap” moments); we leave to future work identifying the reverse, when speakers receive applause without invoking common techniques (for example, to identify instances of claques paid to clap).",8 Conclusion,[0],[0]
Many thanks to the anonymous reviewers for their helpful feedback.,9 Acknowledgments,[0],[0]
The research reported in this article was supported by a UC Berkeley Fellowship for Graduate Study to J.G. and by resources provided by NVIDIA.,9 Acknowledgments,[0],[0]
This work examines the rhetorical techniques that speakers employ during political campaigns.,abstractText,[0],[0]
We introduce a new corpus of speeches from campaign events in the months leading up to the 2016 U.S. presidential election and develop new models for predicting moments of audience applause.,abstractText,[0],[0]
"In contrast to existing datasets, we tackle the challenge of working with transcripts that derive from uncorrected closed captioning, using associated audio recordings to automatically extract and align labels for instances of audience applause.",abstractText,[0],[0]
"In prediction experiments, we find that lexical features carry the most information, but that a variety of features are predictive, including prosody, long-term contextual dependencies, and theoretically motivated features designed to capture rhetorical techniques.",abstractText,[0],[0]
Please Clap: Modeling Applause in Campaign Speeches,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1763–1775 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1763",text,[0],[0]
Computing the co-occurrence strength between two linguistic expressions is a fundamental task in natural language processing (NLP).,1 Introduction,[0],[0]
"For example, in collocation extraction (Manning and Schütze, 1999), word bigrams are collected from corpora and then strongly co-occurring bigrams (e.g., “New York”) are found.",1 Introduction,[0],[0]
"In dialogue response selection (Lowe et al., 2015), pairs comprising a context and its response sentence are collected from dialogue corpora and the goal is to rank the candidate responses for each given context sentence.",1 Introduction,[0],[0]
"In either case, a set of linguistic expression pairs D = {(xi, yi)}ni=1 is first collected and then the co-occurrence strength of a (new) pair (x, y) is computed.
",1 Introduction,[0],[0]
"Pointwise mutual information (PMI) (Church and Hanks, 1989) is frequently used to model the co-occurrence strength of linguistic expression pairs.",1 Introduction,[0],[0]
There are two typical types of PMI estimation (computation) method.,1 Introduction,[0],[0]
"One is a countingbased estimator using maximum likelihood estimation, sometimes with smoothing techniques, for example,
P̂MIMLE(x, y;D)= log n · c(x, y)∑ y′c(x, y ′) ∑ x′c(x ′, y) ,
(1)
where c(x, y) denotes the frequency of the pair (x, y) in given dataD. This is easy to compute and is commonly used to measure co-occurrence between words, such as in collocation extraction1; however, when data D is sparse, i.e., when x or y is a phrase or sentence, this approach is unrealistic.",1 Introduction,[0],[0]
The second method uses recurrent neural networks (RNNs).,1 Introduction,[0],[0]
"Li et al. (2016) proposed to em1 In collocation extraction, simple counting c(x, y) ∝",1 Introduction,[0],[0]
"P̂(x, y), rather than PMI, ranks undesirable function-word pairs (e.g., “of the”) higher (Manning and Schütze, 1999).
",1 Introduction,[0],[0]
ploy PMI to suppress dull responses for utterance generation in dialogue systems2.,1 Introduction,[0],[0]
"They estimated P(y) and P(y|x) using RNN language models and estimated PMI as follows:
P̂MIRNN(x, y;D) = log P̂RNN(y|x) P̂RNN(y) .",1 Introduction,[0],[0]
"(2)
This way of estimating PMI is applicable to sparse language expressions; however, learning RNN language models is computationally costly.
",1 Introduction,[0],[0]
"To eliminate this trade-off between robustness to data sparsity and learning time, in this study we propose a new kernel-based co-occurrence measure, which we call the pointwise Hilbert–Schmidt independence criterion (PHSIC) (see Table 1).",1 Introduction,[0],[0]
"Our contributions are as follows: • We formalize PHSIC, which is derived from
HSIC (Gretton et al., 2005), a kernel-based dependence measure, in the same way that PMI is derived from mutual information (Section 3).",1 Introduction,[0],[0]
• We give an intuitive explanation why PHSIC is robust to data sparsity.,1 Introduction,[0],[0]
"PHSIC is a “smoothed variant of PMI”, which allows various similarity metrics to be plugged in as kernels (Section 4).",1 Introduction,[0],[0]
"• We propose fast estimators of PHSIC, which are reduced to a simple and fast matrix calculation regardless of whether we use linear or nonlinear kernels (Section 5).",1 Introduction,[0],[0]
"• We empirically confirmed the effectiveness of PHSIC, i.e., its robustness to data sparsity and learning time, in two different types of experiment, a dialogue response selection task and a data selection task for machine translation (Section 6).",1 Introduction,[0],[0]
"Let X and Y denote random variables on X and Y , respectively.",2 Problem Setting,[0],[0]
"In this paper, we deal with the tasks of taking a set of linguistic expression pairs
D = {(xi, yi)}ni=1 ∼i.i.d.",2 Problem Setting,[0],[0]
"PXY , (3)
which is regarded as a set of i.i.d.",2 Problem Setting,[0],[0]
"samples drawn from a joint distribution PXY , and then measuring the “co-occurrence strength” for each given pair (x, y) ∈ X × Y .",2 Problem Setting,[0],[0]
"Such tasks include collocation extraction and dialogue response selection (Section 1).
",2 Problem Setting,[0],[0]
2,2 Problem Setting,[0],[0]
"In dialogue response selection or generation, a simple conditional probability P̂(y|x), rather than PMI, ranks dull responses (e.g., “I don’t know.”) higher (Li et al., 2016).",2 Problem Setting,[0],[0]
"In this section, we give the formal definition of PHSIC, a new kernel-based co-occurrence measure.",3 Pointwise HSIC,[0],[0]
We show a summary of this section in Table 2.,3 Pointwise HSIC,[0],[0]
"Intuitively, PHSIC is a “kernelized variant of PMI.”",3 Pointwise HSIC,[0],[0]
"As a preliminary step, we introduce the simple concept of dependence (see Dependence Measure in Table 2).",3.1 Dependence Measure,[0],[0]
Recall that random variables X and Y are independent if and only if the joint probability density PXY and the product of the marginals PXPY are equivalent.,3.1 Dependence Measure,[0],[0]
"Therefore, we can measure the dependence between random variables X and Y via the difference between PXY and PXPY .
",3.1 Dependence Measure,[0],[0]
"Both the mutual information and the Hilbert– Schmidt independence criterion, to be described below, are such dependence measures.",3.1 Dependence Measure,[0],[0]
"We briefly review the well-known mutual information and PMI (see MI & PMI in Table 2).
",3.2 MI and PMI,[0],[0]
"The mutual information (MI)3 between two random variables X and Y is defined by
MI(X,Y ) := KL[PXY ‖PXPY ] (4)
(Cover and Thomas, 2006), where KL[·‖·] denotes the Kullback–Leibler (KL) divergence.",3.2 MI and PMI,[0],[0]
"Thus, MI(X,Y ) is the degree of dependence between X and Y measured by the KL divergence between PXY and PXPY .
",3.2 MI and PMI,[0],[0]
"Here, by definition of the KL divergence, MI can be represented in the form of the expectation over PXY , i.e., the summation over all possible pairs (x, y) ∈ X×Y:
MI(X,Y ) =",3.2 MI and PMI,[0],[0]
"E (x,y)
[ log PXY (x, y)
PX(x)PY",3.2 MI and PMI,[0],[0]
"(y)
] .",3.2 MI and PMI,[0],[0]
"(5)
The shaded part in Equation (5) is actually the pointwise mutual information (PMI) (Church and Hanks, 1989):
PMI(x, y;X,Y )",3.2 MI and PMI,[0],[0]
":= log PXY (x, y)
",3.2 MI and PMI,[0],[0]
PX(x)PY,3.2 MI and PMI,[0],[0]
(y) .,3.2 MI and PMI,[0],[0]
"(6)
Therefore, PMI(x, y) can be thought of as the contribution of (x, y) to MI(X,Y ).
3 Conventionally, mutual information is denoted by I(X;Y ); in this paper, however, for notational consistency, mutual information is denoted by MI(X,Y ).",3.2 MI and PMI,[0],[0]
"As seen in the previous section, PMI can be derived from MI.",3.3 HSIC and PHSIC,[0],[0]
"Here, we consider replacing MI with the Hilbert–Schmidt independence criterion (HSIC).",3.3 HSIC and PHSIC,[0],[0]
"Then, in analogy with the relationship between PMI and MI, we derive PHSIC from HSIC (see HSIC & PHSIC in Table 2).
",3.3 HSIC and PHSIC,[0],[0]
Let k :,3.3 HSIC and PHSIC,[0],[0]
"X × X → R and ` : Y × Y → R denote positive definite kernels on X and Y , respectively (intuitively, they are similarity functions between linguistic expressions).",3.3 HSIC and PHSIC,[0],[0]
"The Hilbert– Schmidt independence criterion (HSIC) (Gretton et al., 2005), a kernel-based dependence measure, is defined by
HSIC(X,Y; k, `) :=MMD2k,`[PXY ,PXPY ], (7)
where MMD[·, ·] denotes the maximum mean discrepancy (MMD) (Gretton et al., 2012), which measures the difference between random variables on a kernel-induced feature space.",3.3 HSIC and PHSIC,[0],[0]
"Thus, HSIC(X,Y ; k, `) is the degree of dependence between X and Y measured by the MMD between PXY and PXPY , while MI is measured by the KL divergence (Equation (4)).
",3.3 HSIC and PHSIC,[0],[0]
"Analogous to MI in Equation (5), HSIC can be represented in the form of the expectation on PXY by a simple deformation:
HSIC(X,Y ; k, `)
= E (x,y)
",3.3 HSIC and PHSIC,[0],[0]
"[ (φ(x)−mX)>CXY (ψ(y)−mY ) ] (8)
= E (x,y)
[ E (x′,y′)",3.3 HSIC and PHSIC,[0],[0]
"[k̃(x, x′)˜̀(y, y′)]",3.3 HSIC and PHSIC,[0],[0]
"], (9)
where
φ(x) := k(x, ·), ψ(y) := `(y, ·), (10)
mX := Ex[φ(x)], mY := Ey[ψ(y)], (11)
",3.3 HSIC and PHSIC,[0],[0]
"CXY := E (x,y)
",3.3 HSIC and PHSIC,[0],[0]
"[ (φ(x)−mX)(ψ(y)−mY )> ] , (12)
k̃(x, x′)",3.3 HSIC and PHSIC,[0],[0]
":= k(x, x′)−Ex′",3.3 HSIC and PHSIC,[0],[0]
"[k(x, x′)]",3.3 HSIC and PHSIC,[0],[0]
"−Ex[k(x, x′)]",3.3 HSIC and PHSIC,[0],[0]
"+Ex,x′ [k(x, x′)].",3.3 HSIC and PHSIC,[0],[0]
"(13)
At first glance, these equations are somewhat complicated; however, the estimators of PHSIC we actually use are reduced to a simple matrix calculation in Section 5.",3.3 HSIC and PHSIC,[0],[0]
"Unlike MI in Equation (5), HSIC has two representations: Equation (8) is the representation in feature space and Equation (9) is the representation in data space.
",3.3 HSIC and PHSIC,[0],[0]
"Similar to the relationship between MI and PMI (Section 3.2), we define the pointwise Hilbert– Schmidt independence criterion (PHSIC) by the shaded parts in Equations (8) and (9):
PHSIC(x, y;X,Y, k, `)
:= (φ(x)−mX)>CXY (ψ(y)−mY ) (14)
",3.3 HSIC and PHSIC,[0],[0]
"= E (x′,y′)",3.3 HSIC and PHSIC,[0],[0]
"[k̃(x, x′)˜̀(y, y′)] .",3.3 HSIC and PHSIC,[0],[0]
"(15) Namely, PHSIC(x, y) is defined as the contribution of (x, y) to HSIC(X,Y ).
",3.3 HSIC and PHSIC,[0],[0]
"In summary, we define PHSIC such that “MI:PMI = HSIC:PHSIC” holds (see Table 2).",3.3 HSIC and PHSIC,[0],[0]
"This section gives an intuitive explanation for the first feature of PHSIC, i.e., the robustness to data sparsity, using Table 3.",4 PHSIC as Smoothed PMI,[0],[0]
"In short, we show that PHSIC is a “smoothed variant of PMI.”
",4 PHSIC as Smoothed PMI,[0],[0]
"First, the maximum likelihood estimator of PMI
in Equation (1) can be rewritten as P̂MI(x, y;D)= log n ·",4 PHSIC as Smoothed PMI,[0],[0]
"∑
iI[x=xi ∧ y=yi]∑ iI[x=xi] ∑ iI[y=yi] , (16)
where I[condition] = 1 if the condition is true and I[condition] = 0 otherwise.",4 PHSIC as Smoothed PMI,[0],[0]
"According to Equation (16), P̂MI(x, y) is the amount computed by repeating the following operation (see the first row in Table 3):
collate the given (x, y) and the observed (xi, yi) in D in order, and add the scores if (x, y) and (xi, yi) match exactly or deduct the scores if either the x side or the y side (but nor both) matches.
",4 PHSIC as Smoothed PMI,[0],[0]
"Moreover, an estimator of PHSIC in data space (Equation (15)) is
P̂HSIC(x, y;D, k, `)=",4 PHSIC as Smoothed PMI,[0],[0]
"1n ∑ i ̂̃ k(x, xi)̂˜̀(y, yi) ,
(17)
where ̂̃k(·, ·) and ̂̀̃(·, ·) are similarity functions centered on the data4.",4 PHSIC as Smoothed PMI,[0],[0]
"According to Equation (17), P̂HSIC(x, y) is the amount computed by repeating the following operation (see the second row in Table 3):
collate the given (x, y) and the observed (xi, yi) in D in order, and add the scores if the similarities on the x and y sides are both
higher (both ̂̃k(x, xi) > 0 and ̂̀̃(y, yi) > 0",4 PHSIC as Smoothed PMI,[0],[0]
"hold)5 or deduct the scores if the similarities on either the x or y sides are similar but those on the other side are not similar.
",4 PHSIC as Smoothed PMI,[0],[0]
"4 To be exact, ̂̃k(x, x′)",4 PHSIC as Smoothed PMI,[0],[0]
":= k(x, x′)",4 PHSIC as Smoothed PMI,[0],[0]
"− 1 n ∑n j=1 k(x, xj)",4 PHSIC as Smoothed PMI,[0],[0]
− 1 n ∑n i=1,4 PHSIC as Smoothed PMI,[0],[0]
"k(xi, x ′) + 1 n2 ∑n i=1",4 PHSIC as Smoothed PMI,[0],[0]
"∑n j=1 k(xi, xj), which is an estimator of the centered kernel k̃(x, x′) in Equation (13).",4 PHSIC as Smoothed PMI,[0],[0]
5,4 PHSIC as Smoothed PMI,[0],[0]
"In addition, the scores are added if the similarity on the x
side and that on the y side are both lower, that is, if ̂̃k(x, xi) < 0 and ̂̀̃(y, yi) < 0 hold.
",4 PHSIC as Smoothed PMI,[0],[0]
"As described above, when comparing the estimators of PMI and PHSIC from the viewpoint of “methods of matching the given (x, y) and the observed (xi, yi),” it is understood that PMI matches them in an exact manner, while PHSIC smooths the matching using kernels (similarity functions).
",4 PHSIC as Smoothed PMI,[0],[0]
"With this mechanism, even for completely unknown pairs, it is possible to estimate the cooccurrence strength by referring to observed pairs through the kernels.",4 PHSIC as Smoothed PMI,[0],[0]
"Therefore, PHSIC is expected to be robust to data sparsity and can be applied to phrases and sentences.
",4 PHSIC as Smoothed PMI,[0],[0]
"Available Kernels for PHSIC In NLP, a variety of similarity functions (i.e., positive definite kernels) are available.",4 PHSIC as Smoothed PMI,[0],[0]
"We can freely utilize such resources, such as cosine similarity between sentence embeddings.",4 PHSIC as Smoothed PMI,[0],[0]
"For a more detailed discussion, see Appendix A.",4 PHSIC as Smoothed PMI,[0],[0]
"Recall that we have two types of empirical estimator of PMI, the maximum likelihood estimator (Equation (1)) and the RNN-based estimator (Equation (2)).",5 Empirical Estimators of PHSIC,[0],[0]
"In this section, we describe how to rapidly estimate PHSIC from data.",5 Empirical Estimators of PHSIC,[0],[0]
"When using the linear kernel or cosine similarity (e.g., cosine similarity between sentence embeddings), PHSIC can be efficiently estimated in feature space (Section 5.1).",5 Empirical Estimators of PHSIC,[0],[0]
"When using a nonlinear kernel such as the Gaussian kernel, PHSIC can also be estimated efficiently in data space via a simple matrix decomposition (Section 5.2).",5 Empirical Estimators of PHSIC,[0],[0]
"When using the linear kernel or cosine similarity, the estimator of PHSIC in feature space (14) is as follows:
P̂HSICfeature(x, y;D, k, `)
=",5.1 Estimation Using Linear Kernel or Cosine,[0],[0]
"(φ(x)−φ(x))>ĈXY (ψ(y)−ψ(y)) , (18)
where
φ(x) = { x (k(x, x′) = x>x′)",5.1 Estimation Using Linear Kernel or Cosine,[0],[0]
"x/‖x‖ (k(x, x′) = cos(x, x′)) , (19)
φ(x) := 1
n n∑ i=1 φ(xi), ψ(y)",5.1 Estimation Using Linear Kernel or Cosine,[0],[0]
":= 1 n n∑ i=1 ψ(yi), (20)
",5.1 Estimation Using Linear Kernel or Cosine,[0],[0]
"ĈXY := 1
n n∑ i=1 φ(xi)ψ(yi)",5.1 Estimation Using Linear Kernel or Cosine,[0],[0]
>,5.1 Estimation Using Linear Kernel or Cosine,[0],[0]
− φ(x)ψ(y)>.,5.1 Estimation Using Linear Kernel or Cosine,[0],[0]
"(21)
Generally in kernel methods, a feature map φ(·) induced by a kernel k(·, ·) is unknown or highdimensional and it is difficult to compute estimated values in feature space6.",5.1 Estimation Using Linear Kernel or Cosine,[0],[0]
"However, when we use the linear kernel or cosine similarity, feature maps can be explicitly determined (Equation (19)).
",5.1 Estimation Using Linear Kernel or Cosine,[0],[0]
"Computational Cost When learning Equation (18) with feature maps φ : X → Rd and ψ : Y → Rd, computing the vectors φ(x), ψ(y) ∈ Rd and the matrix ĈXY ∈ Rd×d takes O(nd2) time and O(nd) space (linear in the size of the input, n).",5.1 Estimation Using Linear Kernel or Cosine,[0],[0]
"When estimating PHSIC(x, y), computing φ(x), ψ(y) ∈ Rd and Equation (18) takes O(d2) time (constant; does not depend on the size of the input, n).",5.1 Estimation Using Linear Kernel or Cosine,[0],[0]
"When using a nonlinear kernel such as the Gaussian kernel, it is necessary to estimate PHSIC in data space.",5.2 Estimation Using Nonlinear Kernels,[0],[0]
"Using a simple matrix decomposition, this can be achieved with the same computational cost as the estimation in feature space.",5.2 Estimation Using Nonlinear Kernels,[0],[0]
See Appendix B for a detailed derivation.,5.2 Estimation Using Nonlinear Kernels,[0],[0]
"In this section, we provide empirical evidence for the greater effectiveness of PHSIC than PMI, i.e., a very short learning time and robustness to data sparsity.",6 Experiments,[0],[0]
"Among the many potential applications of PHSIC, we choose two fundamental scenarios, (re-)ranking/classification and data selection.",6 Experiments,[0],[0]
"• In the ranking/classification scenario (measuring
the co-occurrence strength of new data pairs with reference to observed pairs), PHSIC is applied
6 One of the characteristics of kernel methods is that an intractable estimation in feature space is replaced with an efficient estimation in data space.
as a criterion for the dialogue response selection task (Section 6.2).",6 Experiments,[0],[0]
•,6 Experiments,[0],[0]
"In the data selection/filtering scenario (ordering the entire set of observed data pairs according to the co-occurrence strength), PHSIC is also applied as a criterion for data selection in the context of machine translation (Section 6.3).",6 Experiments,[0],[0]
"To take advantage of recent developments in representation learning, we used several pre-trained models for encoding sentences into vectors and several kernels between these vectors for PHSIC.
Encoders",6.1 PHSIC Settings,[0],[0]
"As sentence encorders, we used two pre-trained models without fine-tuning.",6.1 PHSIC Settings,[0],[0]
"First, the sum of the word vectors effectively represents a sentence (Mikolov et al., 2013a):
x= ∑ w∈xvec(w), y= ∑ w∈yvec(w).",6.1 PHSIC Settings,[0],[0]
"(22)
For vec(·), we used the pre-trained fastText model7, which is a high-accuracy and popular word embedding model (Bojanowski et al., 2017); models in 157 languages are publicly distributed (Grave et al., 2018).",6.1 PHSIC Settings,[0],[0]
"Second, we also used a DNN-based sentence encoder, called the universal sentence encoder (Cer et al., 2018), which utilizes the deep averaging network (DAN) (Iyyer et al., 2015).",6.1 PHSIC Settings,[0],[0]
"The pre-trained model for English sentences we used is publicly available8.
Kernels",6.1 PHSIC Settings,[0],[0]
"As kernels between these vectors, we used cosine similarity (cos)
k(x,x′) = cos(x,x′) (23)
and the Gaussian kernel (also known as the radial basis function kernel; RBF kernel)
k(x,x′) = exp ( −‖x− x
′‖22 2σ2
) , (24)
and similarly for `(y,y′).",6.1 PHSIC Settings,[0],[0]
"The experiments are ran with hyperparameter σ = 1.0 for the RBF kernel, and d = 100 for incomplete Cholesky decomposition (for more detail, see Section B).",6.1 PHSIC Settings,[0],[0]
"In the first experiment, we applied PHSIC as a ranking criterion of the task of dialogue response 7 https://fasttext.cc/docs/en/english-vectors.",6.2 Ranking: Dialogue Response Selection,[0],[0]
"html, https://fasttext.cc/docs/en/crawl-vectors.",6.2 Ranking: Dialogue Response Selection,[0],[0]
"html 8 https://www.tensorflow.org/hub/modules/google/ universal-sentence-encoder/1
selection (Lowe et al., 2015); in the task, pairs comprising a context (previous utterance sequence) and its response are collected from dialogue corpora and the goal is to rank the candidate responses for each given context sentence.
",6.2 Ranking: Dialogue Response Selection,[0],[0]
"The task entails sentence sequences (very sparse linguistic expressions); moreover, Li et al. (2016) pointed out that (RNN-based) PMI has a positive impact on suppressing dull responses (e.g., “I don’t know.”) in dialogue systems.",6.2 Ranking: Dialogue Response Selection,[0],[0]
"Therefore, PHSIC, another co-occurrence measure, is also expected to be effective for this.",6.2 Ranking: Dialogue Response Selection,[0],[0]
"With this setting, where the validity of PMI is confirmed, we investigate whether PHSIC can replace RNN-based PMI in terms of both learning time and robustness to data sparsity.
",6.2 Ranking: Dialogue Response Selection,[0],[0]
"Experimental Settings
Dataset For the training data, we gathered approximately 5× 105 reply chains from Twitter, following Sordoni et al. (2015)9.",6.2 Ranking: Dialogue Response Selection,[0],[0]
"In addition, we randomly selected {103, 104, 105} reply chains from that dataset.",6.2 Ranking: Dialogue Response Selection,[0],[0]
"Using these small subsets, we confirmed the effect of the difference in the size of the training set (data sparseness) on the learning time and predictive performance.
",6.2 Ranking: Dialogue Response Selection,[0],[0]
"For validation and test data, we used a small (approximately 2000 pairs each) but highly reliable dataset created by Sordoni et al. (2015)10, which consists only of conversations given high scores by human annotators.",6.2 Ranking: Dialogue Response Selection,[0],[0]
"Therefore, this set was not expected to include dull responses.
",6.2 Ranking: Dialogue Response Selection,[0],[0]
"For each dataset, we converted each contextmessage-response triple into a context-response pair by concatenating the context and message following Li et al. (2016).",6.2 Ranking: Dialogue Response Selection,[0],[0]
"In addition, to convert the test set (positive examples) to ten-choice multiplechoice questions, we shuffled the combinations of context and response to generate pseudo-negative examples.
",6.2 Ranking: Dialogue Response Selection,[0],[0]
Evaluation Metrics,6.2 Ranking: Dialogue Response Selection,[0],[0]
"We adopted the following evaluation metrics for the task: (i) ROC-AUC (the area under the receiver operating characteristic curve), (ii) MRR (the mean reciprocal rank), and (iii) Recall@{1,2}.
9",6.2 Ranking: Dialogue Response Selection,[0],[0]
"We collected tweets after 2017 for our training set to avoid duplication with the test set, which contains tweets from the year 2012.",6.2 Ranking: Dialogue Response Selection,[0],[0]
10 https://www.microsoft.com/en-us/download/,6.2 Ranking: Dialogue Response Selection,[0],[0]
"details.aspx?id=52375
Experimental Procedure",6.2 Ranking: Dialogue Response Selection,[0],[0]
"We used the following procedure: (i) train the model with a set of context-response pairs D = {(xi, yi)}ni=1; (ii) for each context sentence x in the test data, rank the candidate responses {yj}10j=1 by the model; and (iii) report three evaluation metrics.
",6.2 Ranking: Dialogue Response Selection,[0],[0]
"Baseline Measures As baseline measures, both (1) an RNN language model P̂RNN(y) (Mikolov et al., 2010) and (2) a conditional RNN language model P̂RNN(y|x) (Sutskever et al., 2014) were trained, and (3) PMI based on these language models, RNN-PMI, was also used for experiments (see Equation (2)).",6.2 Ranking: Dialogue Response Selection,[0],[0]
"We trained these models with all combinations of the following settings: (a) the number of dimensions of the hidden layers being 300 or 1200 and (b) the initialization of the embedding layer being random (uniform on [−0.1, 0.1]) or fastText.",6.2 Ranking: Dialogue Response Selection,[0],[0]
"For more detailed settings, see Appendix C.
Experimental Results Learning Time Table 4 shows the experimental results of the learning time11.",6.2 Ranking: Dialogue Response Selection,[0],[0]
"Regardless of the size of the training set n, the learning time for
11 The computing environment was as follows: (i) CPU: Xeon E5-1650-v3 (3.5 GHz, 6 Cores); (ii) GPU: GTX 1080 (8 GB).
",6.2 Ranking: Dialogue Response Selection,[0],[0]
PHSIC is much shorter than that of the RNN-based method.,6.2 Ranking: Dialogue Response Selection,[0],[0]
"For example, even when the size of the training set n is 5× 105, PHSIC is approximately 1400–4000 times faster than RNN-based PMI.",6.2 Ranking: Dialogue Response Selection,[0],[0]
"This is because the estimators of PHSIC are reduced to a deterministic and efficient matrix calculation (Section 5), whereas neural network-based models involve the sequential optimization of parameters via gradient descent methods.
",6.2 Ranking: Dialogue Response Selection,[0],[0]
Robustness to Data Sparsity Table 5 shows the experimental results of the predictive performance.,6.2 Ranking: Dialogue Response Selection,[0],[0]
"When the size of the training data is small (n=103, 104), that is, when the data is extremely sparse, the predictive performance of PHSIC hardly deteriorates while that of PMI rapidly decays as the number of data decreases.",6.2 Ranking: Dialogue Response Selection,[0],[0]
This indicates that PHSIC is more robust to data sparsity than RNN-based PMI owing to the effect of kernels.,6.2 Ranking: Dialogue Response Selection,[0],[0]
"Moreover, PHSIC with the simple cosine kernel outperforms the RNN-based model regardless of the number of data, while the learning time of PHSIC is thousands of times shorter than those of the baseline methods (Section 6.2).
",6.2 Ranking: Dialogue Response Selection,[0],[0]
Additionally we report Spearman’s rank correlation coefficient between models to verify whether PHSIC shows similar behavior to PMI.,6.2 Ranking: Dialogue Response Selection,[0],[0]
See Appendix D for more detail.,6.2 Ranking: Dialogue Response Selection,[0],[0]
The aim of our second experiment was to demonstrate that PHSIC is also beneficial as a criterion of data selection.,6.3 Data Selection for Machine Translation,[0],[0]
"To achieve this, we attempted to apply PHSIC to a parallel corpus filtering task that has been intensively discussed in recent (neural) machine translation (MT, NMT) studies.",6.3 Data Selection for Machine Translation,[0],[0]
"This task was first adopted as a shared task in the third conference on machine translation (WMT 2018)12.
",6.3 Data Selection for Machine Translation,[0],[0]
"Several existing parallel corpora, especially those automatically gathered from large-scale text data, such as the Web, contain unacceptable amounts of noisy (low-quality) sentence pairs that greatly affect the translation quality.",6.3 Data Selection for Machine Translation,[0],[0]
"Therefore, the development of an effective method for parallel corpus filtering would potentially have a large influence on the MT community; discarding such noisy pairs may improve the translation quality and shorten the training time.
",6.3 Data Selection for Machine Translation,[0],[0]
"We expect PHSIC to give low scores to exceptional sentence pairs (misalignments or missing 12 http://www.statmt.org/wmt18/ parallel-corpus-filtering.html
translations) during the selection process because PHSIC assigns low scores to pairs that are highly inconsistent with other pairs (see Section 4).",6.3 Data Selection for Machine Translation,[0],[0]
"Note that applying RNN-based PMI to a parallel corpus selection task is unprofitable since obtaining RNNbased PMI also has an identical computational cost for training a sequence-to-sequence model for MT, and thus, we cannot expect a reduction of the total training time.
",6.3 Data Selection for Machine Translation,[0],[0]
"Experimental Settings
Dataset",6.3 Data Selection for Machine Translation,[0],[0]
"We used the ASPEC-JE corpus13, which is an official dataset used for the MT-evaluation shared task held in the fourth workshop on Asian translation (WAT 2017)14 (Nakazawa et al., 2017).",6.3 Data Selection for Machine Translation,[0],[0]
ASPEC-JE consists of approximately three million (3M) Japanese–English parallel sentences from scientific paper abstracts.,6.3 Data Selection for Machine Translation,[0],[0]
"As discussed by Kocmi et al. (2017), ASPEC-JE contains many low-quality parallel sentences that have the potential to significantly degrade the MT quality.",6.3 Data Selection for Machine Translation,[0],[0]
"In fact, they empirically revealed that using only the reliable part of the training parallel corpus significantly improved the translation quality.",6.3 Data Selection for Machine Translation,[0],[0]
"Therefore, ASPEC-JE is a suitable dataset for evaluating the data selection ability.
",6.3 Data Selection for Machine Translation,[0],[0]
"Model For our data selection evaluation, we selected the Transformer architecture (Vaswani et al., 2017) as our baseline NMT model, which is widelyused in the NMT community and known as one of the current state-of-the-art architectures.",6.3 Data Selection for Machine Translation,[0],[0]
"We utilized fairseq15, a publicly available tool for neural sequence-to-sequence models, for building our models.
",6.3 Data Selection for Machine Translation,[0],[0]
"Experimental Procedure We used the following procedure for this evaluation: (1) rank all parallel sentences in a given parallel corpus according to each criterion, (2) extract the top K ranked parallel sentences, (3) train the NMT model using the extracted parallel sentences, and (4) evaluate the translation quality of the test data using a typical MT automatic evaluation measure, i.e., BLEU (Papineni et al., 2002)16.",6.3 Data Selection for Machine Translation,[0],[0]
In our experiments we evaluated PHSIC with K = 0.5M and 1M.,6.3 Data Selection for Machine Translation,[0],[0]
"16 We used multi-bleu.perl in the Moses tool (https:// github.com/moses-smt/mosesdecoder).
",15 https://github.com/pytorch/fairseq,[0],[0]
"Baseline Measure As a baseline measure, we utilize a publicly available script17 of fast align (Dyer et al., 2013), which is one of the state-of-theart word aligner.",15 https://github.com/pytorch/fairseq,[0],[0]
"We firstly used the fast align for the training set D = {(xi, yi)}i to obtain the word alignment between each sentence pair (xi, yi), i.e., a set of aligned word pairs with its probabilities.",15 https://github.com/pytorch/fairseq,[0],[0]
"We then computed the co-occurrence score of (xi, yi) with sentence-length normalization, i.e., the average log probability of aligned word pairs.
",15 https://github.com/pytorch/fairseq,[0],[0]
Experimental Results Table 6 shows the results of our data selection evaluation.,15 https://github.com/pytorch/fairseq,[0],[0]
It is common knowledge in NMT that more data gives better performance in general.,15 https://github.com/pytorch/fairseq,[0],[0]
"However, we observed that PHSIC successfully extracted beneficial parallel sentences from the noisy parallel 17 https://github.com/clab/fast align
corpus; the result using 1M data extracted from the 3M corpus by PHSIC was almost the same as that using 3M data (the decrease in the BLEU score was only 0.07), whereas that by random extraction reduced the BLEU score by 1.20.
",15 https://github.com/pytorch/fairseq,[0],[0]
This was actually a surprising result because PHSIC utilizes only monolingual similarity measures (kernels) without any other language resources.,15 https://github.com/pytorch/fairseq,[0],[0]
This indicates that PHSIC can be applied to a language pair poor in parallel resources.,15 https://github.com/pytorch/fairseq,[0],[0]
"In addition, the surface form and grammatical characteristics between English and Japanese are extremely different18; therefore, we expect that PHSIC will work well regardless of the similarity of the language pair.",15 https://github.com/pytorch/fairseq,[0],[0]
"Dependence Measures Measuring independence or dependence (correlation) between two random variables, i.e., estimating dependence from a set of paired data, is a fundamental task in statistics and a very wide area of data science.",7 Related Work,[0],[0]
"To measure the complex nonlinear dependence that real data has, we have several choices.
",7 Related Work,[0],[0]
"First, information-theoretic MI (Cover and Thomas, 2006) and its variants (Suzuki et al., 2009; Reshef et al., 2011) are the most commonly used dependence measures.",7 Related Work,[0],[0]
"However, to the best of our knowledge, there is no practical method of computing MIs for large-multi class high-dimensional 18",7 Related Work,[0],[0]
"For example, word order; English is an SVO (subject-verbobject) language and Japanese is an SOV (subject-object-verb) language.
",7 Related Work,[0],[0]
"(having a complex generative model) discrete data, such as sparse linguistic data.
",7 Related Work,[0],[0]
"Second, several kernel-based dependence measures have been proposed for measuring nonlinear dependence (Akaho, 2001; Bach and Jordan, 2002; Gretton et al., 2005).",7 Related Work,[0],[0]
"The reason why kernelbased dependence measures work well for real data is that they do not explicitly estimate densities, which is difficult for high-dimensional data.",7 Related Work,[0],[0]
"Among them, HSIC (Gretton et al., 2005) is popular because it has a simple estimation method, which is used for various tasks such as feature selection (Song et al., 2012), dimensionality reduction (Fukumizu et al., 2009), and",7 Related Work,[0],[0]
"unsupervised object matching (Quadrianto et al., 2009; Jagarlamudi et al., 2010).",7 Related Work,[0],[0]
"We follow this line.
",7 Related Work,[0],[0]
"Co-occurrence Measures First, In NLP, PMI (Church and Hanks, 1989) and its variants (Bouma, 2009) are the de facto co-occurrence measures between dense linguistic expressions, such as words (Bouma, 2009) and simple narrative-event expressions (Chambers and Jurafsky, 2008).",7 Related Work,[0],[0]
"In recent years, positive PMI (PPMI) has played an important role as a component of word vectors (Levy and Goldberg, 2014).
",7 Related Work,[0],[0]
"Second, there are several studies in which the pairwise ranking problem has been solved by using deep neural networks (DNNs) in NLP.",7 Related Work,[0],[0]
Li et al. (2016) proposed a PMI estimation using RNN language models; this was used as a baseline model in our experiments (see Section 6.2).,7 Related Work,[0],[0]
"Several studies have used DNN-based binary classifiers modeling P(C = positive | (x, y)) to solve the given ranking problem directly (Hu et al., 2014; Yin et al., 2016; Mueller and Thyagarajan, 2016) (these networks are sometimes called Siamese neural networks).",7 Related Work,[0],[0]
Our study focuses on comparing co-occurrence measures.,7 Related Work,[0],[0]
"It is unknown whether Siamese NNs capture the co-occurrence strength; therefore we did not deal with Siamese NNs in this paper.
",7 Related Work,[0],[0]
"Finally, to the best of our knowledge, Yokoi et al. (2017)’s paper is the first study that suggested converting HSIC to a pointwise measure.",7 Related Work,[0],[0]
"The present study was inspired by their suggestion; here, we have (i) provided a formal definition (population) of PHSIC; (ii) analyzed the relationship between PHSIC and PMI; (iii) proposed linear-time estimation methods; and (iv) experimentally verified the computation speed and robustness to data sparsity of PHSIC for practical applications.",7 Related Work,[0],[0]
"The NLP community has commonly employed PMI to estimate the co-occurrence strength between linguistic expressions; however, existing PMI estimators have a high computational cost when applied to sparse linguistic expressions (Section 1).",8 Conclusion,[0],[0]
"We proposed a new kernel-based co-occurrence measure, the pointwise Hilbert– Schmidt independent criterion (PHSIC).",8 Conclusion,[0],[0]
"As well as defining PMI as the contribution to mutual information, PHSIC is defined as the contribution to HSIC; PHSIC is intuitively a “kernelized variant of PMI” (Section 3).",8 Conclusion,[0],[0]
PHSIC can be applied to sparse linguistic expressions owing to the mechanism of smoothing by kernels.,8 Conclusion,[0],[0]
"Comparing the estimators of PMI and PHSIC, PHSIC can be interpreted as a smoothed variant of PMI, which allows various similarity metrics to be plugged in as kernels (Section 4).",8 Conclusion,[0],[0]
"In addition, PHSIC can be estimated in linear time owing to the efficient matrix calculation, regardless of whether we use linear or nonlinear kernels (Section 5).",8 Conclusion,[0],[0]
We conducted a ranking task for dialogue systems and a data selection task for machine translation (Section 6).,8 Conclusion,[0],[0]
"The experimental results show that (i) the learning of PHSIC was completed thousands of times faster than that of the RNN-based PMI while outperforming it in ranking accuracy (Section 6.2); and (ii) even when using a nonlinear kernel, PHSIC can be applied to a large dataset.",8 Conclusion,[0],[0]
"Moreover, PHSIC reduces the amount of training data to one third without sacrificing the output translation quality (Section 6.3).
",8 Conclusion,[0],[0]
"Future Work Using the PHSIC estimator in feature space (Equation (18)), we can generate the most appropriate ψ(y) for a given φ(x) (uniquely, up to scale).",8 Conclusion,[0],[0]
"That is, if a DNN-based sentence decoder is used, y (a sentence) can be restored from ψ(y) (a feature vector) so that generative models of strong co-occurring sentences can be realized.",8 Conclusion,[0],[0]
We are grateful to anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
"We also thank Weihua Hu for useful discussions, Kenshi Yamaguchi for collecting data, and Paul Reisert for proofreading.",Acknowledgments,[0],[0]
"This work was supported in part by JSPS KAKENHI Grant Number JP15H01702 and JST CREST Grant Number JPMJCR1513, Japan.",Acknowledgments,[0],[0]
"Similarity between Sentence Vectors A variety of vector representations of phrases and sentences based on the distributional hypothesis have recently been proposed, including sentence encoders (Kiros et al., 2015; Dai and Le, 2015; Iyyer et al., 2015; Hill et al., 2016; Cer et al., 2018) and the sum of word embeddings; it is known as additive compositionality (Mitchell and Lapata, 2010; Mikolov et al., 2013a; Wieting et al., 2015) that we can express the meaning of phrases and sentences well with the sum of word vectors (e.g., word2vec (Mikolov et al., 2013b), GloVe (Pennington et al., 2014), and fastText (Bojanowski et al., 2017)).",A Available Kernels for PHSIC,[0],[0]
"Note that various pre-trained models of sentence encoders and word embeddings have also been made available.
",A Available Kernels for PHSIC,[0],[0]
"The cosine of these vectors, which is a positive definite kernel, can be used as a convenient and highly accurate similarity function between phrases or sentences.",A Available Kernels for PHSIC,[0],[0]
"Other major kernels can also be used, such as the RBF kernel, the Laplacian kernel, and polynomial kernels.
",A Available Kernels for PHSIC,[0],[0]
"Structured Kernels Various structured kernels for NLP, such as tree kernels, which capture fine structure of sentences such as syntax, were devised in the support vector machine era (Collins and Duffy, 2002; Bunescu and Mooney, 2006; Moschitti, 2006).
",A Available Kernels for PHSIC,[0],[0]
"Combinations We can freely combine the previously mentioned kernels because the sum and the product of positive definite kernels are also positive definite kernels (Shawe-Taylor and Cristianini, 2004, Proposition 3.22).",A Available Kernels for PHSIC,[0],[0]
"Although estimators of HSIC and PHSIC depend on kernels k, ` and data D, hereinafter, we use the following notation for the sake of simplicity:
ĤSIC(X,Y ) := ĤSIC(X,Y ;D, k, `), (25)
P̂HSIC(x, y) := P̂HSIC(x, y;D, k, `).",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"(26)
Naı̈ve Estimation Fist, an estimator of PHSIC in the data space (15) is
P̂HSICkernel(x, y)=(k",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
− k)>,B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"( 1nH)(`− `), (27)
where k := (k(x, x1), . . .",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
", k(x, xn))",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"> ∈ Rn, so as `; and vector k := 1nK1 denotes empirical mean of {ki}ni=1, so as `.",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"This estimation has a
large computational cost.",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"When learning, computing the vectors k, ` takes O(n2) time and O(n) space.",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"When estimating PHSIC, computing k, ` and multiplying the matrix 1nH takes O(n) time.
",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
Fast Estimation via Incomplete Cholesky Decomposition Equation (27) has a large computational cost because it is necessary to construct the Gram matrices K and L ∈ Rn×n.,B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"In kernel methods, several methods have been proposed for approximating Gram matrices at low cost without constructing them explicitly, such as incomplete Cholesky decomposition (Fine and Scheinberg, 2001).
",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"By incomplete Cholesky decomposition, from data points {x1, . . .",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
", xn} ⊆ X and a positive definite kernel",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
k,B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
:,B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"X × X → R, a matrix A = (a1, . . .",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
",an)
> ∈ Rn×d (d n) can be obtained with O(nd2) time complexity.",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"This makes it possible to approximate the Gram matrix K by vectors ai ∈ Rd without configuring the entire of K:
a>",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"i aj ≈ k(xi, xj) (",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
28) AA>,B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"≈ K. (29)
",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"Also, for HSIC, an efficient approximation method utilizing incomplete Cholesky decomposition has been proposed (Gretton et al., 2005, Lemma 2):
ĤSICICD(X,Y ) = 1 n2 ‖(HA)>B‖2F, (30)
where A = (a1, . . .",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
",an)> ∈ Rn×d is a matrix satisfying AA>",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"≈ K computed via incomplete Cholesky decomposition, so as B (BB> ≈ L).",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"Equation (30) can be represented in the form of the expectation on data points:
ĤSICICD(X,Y )= 1
n n∑ i=1",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
[ (ai−a)>ĈICD(bi−b) ],B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"(31)
ĈICD :",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
= 1 n,B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"(HA)>B ∈ Rd×d, (32)
where vector a := 1nA >",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"1 ∈ Rd denotes empirical mean of {ai}ni=1, so as b := 1nB >1.
",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"Recall that PHSIC(x, y) is the contribution of (x, y) to HSIC(X,Y ) (see Section 3.3); PHSIC then can be efficiently estimated by the shaded part of Equation (31):
P̂HSICICD(x, y)= (a−a)>ĈICD(b−b) .",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"(33)
Here, the vector a ∈ Rd corresponding to the new x can be calculated by “performing from halfway”
on the incomplete Cholesky decomposition algorithm.",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"Let x(1), . . .",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
", x(d) denote the dominant xis adopted during decomposition algorithm.",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
"The jth element of a can be computed as follows:
a[j]= [ k(x, x(j))− j−1∑ m=1 a[m]Ajm ] /Ajj , (34)
so as b ∈ Rd corresponding to the new y.",B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
The estimation via incomplete Cholesky decomposition (33) is extremely efficient compared to the naive estimation (27); Equation (33)’s computational complexity is equivalent to the estimation in the feature space (18).,B Derivation of Fast PHSIC Estimation in Data Space,[0],[0]
Detailed settings for learning RNNs used in this research are as follows.,C Detailed Settings for Learning RNNs,[0],[0]
"• Hidden layers: single layer LSTMs (Hochreiter
and Schmidhuber, 1997) •",C Detailed Settings for Learning RNNs,[0],[0]
"Vocabulary: words with a frequency: 10 or more
(n = 5× 105), 2 or more (otherwise) •",C Detailed Settings for Learning RNNs,[0],[0]
"Dropout rate: 0.1 (300-dim), 0.3 (1200-dim) •",C Detailed Settings for Learning RNNs,[0],[0]
"Batch size: 64 • Max epoch number: 5 (n = 5× 105), 30 (other-
wise) • Deep learning framework: Chainer (Tokui et al.,
2015)",C Detailed Settings for Learning RNNs,[0],[0]
Table D shows Spearman’s rank correlation coefficient (Spearman’s ρ) between the co-occurrence scores on the test set computed by the models in the dialogue response selection task (Section 6.2).,D Correlation Between Models in Dialogue Response Selection Task,[0],[0]
"This shows that the behavior of RNN-based PMI and
PHSIC are considerably different.",D Correlation Between Models in Dialogue Response Selection Task,[0],[0]
"Furthermore, interestingly, the behavior of PHSICs using different kernels is also different.",D Correlation Between Models in Dialogue Response Selection Task,[0],[0]
Possible reasons for these observations are as follows: (1) the difference in the dependence measures (MI or HSIC) on which each model is based; (2) the validity or numerical stability of estimating PMI with RNN language models; and (3) differences in the behavior of PHSIC originating from differences in the plugged in kernels.,D Correlation Between Models in Dialogue Response Selection Task,[0],[0]
A more detailed analysis of the compatibility between tasks and measures (or kernels) is attractive future work.,D Correlation Between Models in Dialogue Response Selection Task,[0],[0]
"In this paper, we propose a new kernel-based co-occurrence measure that can be applied to sparse linguistic expressions (e.g., sentences) with a very short learning time, as an alternative to pointwise mutual information (PMI).",abstractText,[0],[0]
"As well as deriving PMI from mutual information, we derive this new measure from the Hilbert–Schmidt independence criterion (HSIC); thus, we call the new measure the pointwise HSIC (PHSIC).",abstractText,[0],[0]
"PHSIC can be interpreted as a smoothed variant of PMI that allows various similarity metrics (e.g., sentence embeddings) to be plugged in as kernels.",abstractText,[0],[0]
"Moreover, PHSIC can be estimated by simple and fast (linear in the size of the data) matrix calculations regardless of whether we use linear or nonlinear kernels.",abstractText,[0],[0]
"Empirically, in a dialogue response selection task, PHSIC is learned thousands of times faster than an RNNbased PMI while outperforming PMI in accuracy.",abstractText,[0],[0]
"In addition, we also demonstrate that PHSIC is beneficial as a criterion of a data selection task for machine translation owing to its ability to give high (low) scores to a consistent (inconsistent) pair with other pairs.",abstractText,[0],[0]
Pointwise HSIC: A Linear-Time Kernelized Co-occurrence Norm for Sparse Linguistic Expressions,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 469–476 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
469",text,[0],[0]
"Many recent state-of-the-art models for constituency parsing are transition based, decomposing production of each parse tree into a sequence of action decisions (Dyer et al., 2016; Cross and Huang, 2016; Liu and Zhang, 2017; Stern et al., 2017), building on a long line of work in transition-based parsing (Nivre, 2003; Yamada and Matsumoto, 2003; Henderson, 2004; Zhang and Clark, 2011; Chen and Manning, 2014; Andor et al., 2016; Kiperwasser and Goldberg, 2016).
",1 Introduction,[0],[0]
"However, models of this type, which decompose structure prediction into sequential decisions, can be prone to two issues (Ranzato et al., 2016; Wiseman and Rush, 2016).",1 Introduction,[0],[0]
"The first is exposure bias: if, at training time, the model only observes
states resulting from correct past decisions, it will not be prepared to recover from its own mistakes during prediction.",1 Introduction,[0],[0]
"Second is the loss mismatch between the action-level loss used at training and any structure-level evaluation metric, for example F1.
",1 Introduction,[0],[0]
"A large family of techniques address the exposure bias problem by allowing the model to make mistakes and explore incorrect states during training, supervising actions at the resulting states using an expert policy (Daumé III et al., 2009; Ross et al., 2011; Choi and Palmer, 2011; Chang et al., 2015); these expert policies are typically referred to as dynamic oracles in parsing (Goldberg and Nivre, 2012; Ballesteros et al., 2016).",1 Introduction,[0],[0]
"While dynamic oracles have produced substantial improvements in constituency parsing performance (Coavoux and Crabbé, 2016; Cross and Huang, 2016; Stern et al., 2017; González and Gómez-Rodrı́guez, 2018), they must be custom designed for each transition system.
",1 Introduction,[0],[0]
"To address the loss mismatch problem, another line of work has directly optimized for structurelevel cost functions (Goodman, 1996; Och, 2003).",1 Introduction,[0],[0]
"Recent methods applied to models that produce output sequentially commonly use policy gradient (Auli and Gao, 2014; Ranzato et al., 2016; Shen et al., 2016) or beam search (Xu et al., 2016; Wiseman and Rush, 2016; Edunov et al., 2017) at training time to minimize a structured cost.",1 Introduction,[0],[0]
"These methods also reduce exposure bias through exploration but do not require an expert policy for supervision.
",1 Introduction,[0],[0]
"In this work, we apply a simple policy gradient method to train four different state-of-theart transition-based constituency parsers to maximize expected F1.",1 Introduction,[0],[0]
"We compare against training with a dynamic oracle (both to supervise exploration and provide loss-augmentation) where one is available, including a novel dynamic oracle that we define for the top-down transition system of
Dyer et al. (2016).",1 Introduction,[0],[0]
"We find that while policy gradient usually outperforms standard likelihood training, it typically underperforms the dynamic oracle-based methods – which provide direct, model-aware supervision about which actions are best to take from arbitrary parser states.",1 Introduction,[0],[0]
"However, a substantial fraction of each dynamic oracle’s performance gain is often recovered using the model-agnostic policy gradient method.",1 Introduction,[0],[0]
"In the process, we obtain new state-of-the-art results for single-model discriminative transition-based parsers trained on the English PTB (92.6 F1), French Treebank (83.5 F1), and Penn Chinese Treebank Version 5.1 (87.0 F1).",1 Introduction,[0],[0]
"The transition-based parsers we use all decompose production of a parse tree y for a sentence x into a sequence of actions (a1, . . .",2 Models,[0],[0]
"aT ) and resulting states (s1, . . .",2 Models,[0],[0]
sT+1).,2 Models,[0],[0]
"Actions at are predicted sequentially, conditioned on a representation of the parser’s current state st and parameters θ:
p(y|x; θ) = T∏ t=1 p(at",2 Models,[0],[0]
"| st; θ) (1)
We investigate four parsers with varying transition systems and methods of encoding the current state and sentence: (1) the discriminative Recurrent Neural Network Grammars (RNNG) parser of Dyer et al. (2016), (2) the In-Order parser of Liu and Zhang (2017), (3) the Span-Based parser of Cross and Huang (2016), and (4) the Top-Down parser of Stern et al. (2017).1 We refer to the original papers for descriptions of the transition systems and model parameterizations.",2 Models,[0],[0]
"Likelihood training without exploration maximizes Eq. 1 for trees in the training corpus, but may be prone to exposure bias and loss mismatch (Section 1).",3 Training Procedures,[0],[0]
"Dynamic oracle methods are known to improve on this training procedure for a variety of parsers (Coavoux and Crabbé, 2016; Cross and Huang, 2016; Stern et al., 2017; González and Gómez-Rodrı́guez, 2018), supervising exploration
1Stern et al. (2017) trained their model using a nonprobabilistic, max-margin objective.",3 Training Procedures,[0],[0]
"For comparison to the other models and to allow training with policy gradient, we create a locally-normalized probabilistic variant of their model by applying a softmax function to the predicted scores for each action.
during training by providing the parser with the best action to take at each explored state.",3 Training Procedures,[0],[0]
We describe how policy gradient can be applied as an oracle-free alternative.,3 Training Procedures,[0],[0]
"We then compare to several variants of dynamic oracle training which focus on addressing exposure bias, loss mismatch, or both.",3 Training Procedures,[0],[0]
"Given an arbitrary cost function ∆ comparing structured outputs (e.g. negative labeled F1, for trees), we use the risk objective:
R(θ) =",3.1 Policy Gradient,[0],[0]
N∑ i=1,3.1 Policy Gradient,[0],[0]
"∑ y p(y | x(i); θ)∆(y,y(i))
which measures the model’s expected cost over possible outputs y for each of the training examples (x(1),y(1)), . . .",3.1 Policy Gradient,[0],[0]
", (x(N),y(N)).
",3.1 Policy Gradient,[0],[0]
"Minimizing a risk objective has a long history in structured prediction (Povey and Woodland, 2002; Smith and Eisner, 2006; Li and Eisner, 2009; Gimpel and Smith, 2010) but often relies on the cost function decomposing according to the output structure.",3.1 Policy Gradient,[0],[0]
"However, we can avoid any restrictions on the cost using reinforcement learning-style approaches (Xu et al., 2016; Shen et al., 2016; Edunov et al., 2017) where cost is ascribed to the entire output structure – albeit at the expense of introducing a potentially difficult credit assignment problem.
",3.1 Policy Gradient,[0],[0]
"The policy gradient method we apply is a simple variant of REINFORCE (Williams, 1992).",3.1 Policy Gradient,[0],[0]
"We perform mini-batch gradient descent on the gradient of the risk objective:
∇R(θ) =",3.1 Policy Gradient,[0],[0]
N∑ i=1,3.1 Policy Gradient,[0],[0]
"∑ y p(y|x(i))∆(y,y(i))∇ log p(y|x(i); θ)
",3.1 Policy Gradient,[0],[0]
≈ N∑ i=1,3.1 Policy Gradient,[0],[0]
"∑ y∈Y(x(i)) ∆(y,y(i))∇ log p(y|x(i); θ)
where Y(x(i)) is a set of k candidate trees obtained by sampling from the model’s distribution for sentence x(i).",3.1 Policy Gradient,[0],[0]
"We use negative labeled F1 for ∆.
To reduce the variance of the gradient estimates, we standardize ∆ using its running mean and standard deviation across all candidates used so far throughout training.",3.1 Policy Gradient,[0],[0]
"Following Shen et al. (2016), we also found better performance when including the gold tree y(i) in the set of k candidates Y(x(i)), and do so for all experiments reported here.2
2Including the gold tree in the set of candidates does bias",3.1 Policy Gradient,[0],[0]
"For a given parser state st, a dynamic oracle defines an action a∗(st) which should be taken to incrementally produce the best tree still reachable from that state.3
Dynamic oracles provide strong supervision for training with exploration, but require custom design for a given transition system.",3.2 Dynamic Oracle Supervision,[0],[0]
"Cross and Huang (2016) and Stern et al. (2017) defined optimal (with respect to F1) dynamic oracles for their respective transition systems, and below we define a novel dynamic oracle for the top-down system of RNNG.
",3.2 Dynamic Oracle Supervision,[0],[0]
"In RNNG, tree production occurs in a stackbased, top-down traversal which produces a leftto-right linearized representation of the tree using three actions: OPEN a labeled constituent (which fixes the constituent’s span to begin at the next word in the sentence which has not been shifted), SHIFT the next word in the sentence to add it to the current constituent, or CLOSE the current constituent (which fixes its span to end after the last word that has been shifted).",3.2 Dynamic Oracle Supervision,[0],[0]
"The parser stores opened constituents on the stack, and must therefore close them in the reverse of the order that they were opened.
",3.2 Dynamic Oracle Supervision,[0],[0]
"At a given parser state, our oracle does the following:
1.",3.2 Dynamic Oracle Supervision,[0],[0]
"If there are any open constituents on the stack which can be closed (i.e. have had a word shifted since being opened), check the topmost of these (the one that has been opened most recently).",3.2 Dynamic Oracle Supervision,[0],[0]
"If closing it would produce a constituent from the the gold tree that has not yet been produced (which is determined by the constituent’s label, span beginning position, and the number of words currently shifted), or if the constituent could not be closed at a later position in the sentence to produce a constituent in the gold tree, return CLOSE.
",3.2 Dynamic Oracle Supervision,[0],[0]
"the estimate of the risk objective’s gradient; however since in the parsing tasks we consider, the gold tree has constant and minimal cost, augmenting with the gold is equivalent to jointly optimizing the standard likelihood and risk objectives, using an adaptive scaling factor for each objective that is dependent on the cost for the trees that have been sampled from the model.",3.2 Dynamic Oracle Supervision,[0],[0]
"We found that including the gold candidate in this manner outperformed initial experiments that first trained a model using likelihood training and then fine-tuned using unbiased policy gradient.
",3.2 Dynamic Oracle Supervision,[0],[0]
"3More generally, an oracle can return a set of such actions that could be taken from the current state, but the oracles we use select a single canonical action.
2.",3.2 Dynamic Oracle Supervision,[0],[0]
"Otherwise, if there are constituents in the gold tree which have not yet been opened in the parser state, with span beginning at the next unshifted word, OPEN the outermost of these.
",3.2 Dynamic Oracle Supervision,[0],[0]
3.,3.2 Dynamic Oracle Supervision,[0],[0]
"Otherwise, SHIFT the next word.
",3.2 Dynamic Oracle Supervision,[0],[0]
"While we do not claim that this dynamic oracle is optimal with respect to F1, we find that it still helps substantially in supervising exploration (Section 5).
",3.2 Dynamic Oracle Supervision,[0],[0]
"Likelihood Training with Exploration Past work has differed on how to use dynamic oracles to guide exploration during oracle training (Ballesteros et al., 2016; Cross and Huang, 2016; Stern et al., 2017).",3.2 Dynamic Oracle Supervision,[0],[0]
"We use the same sample-based method of generating candidate sets Y as for policy gradient, which allows us to control the dynamic oracle and policy gradient methods to perform an equal amount of exploration.",3.2 Dynamic Oracle Supervision,[0],[0]
"Likelihood training with exploration then maximizes the sum of the log probabilities for the oracle actions for all states composing the candidate trees:
LE(θ) =",3.2 Dynamic Oracle Supervision,[0],[0]
N∑ i=1,3.2 Dynamic Oracle Supervision,[0],[0]
"∑ y∈Y(x(i)) ∑ s∈y log p(a∗(s) | s)
where a∗(s) is the dynamic oracle’s action for state s.
Softmax Margin Softmax margin loss (Gimpel and Smith, 2010; Auli and Lopez, 2011) addresses loss mismatch by incorporating task cost into the training loss.",3.2 Dynamic Oracle Supervision,[0],[0]
"Since trees are decomposed into a sequence of local action predictions, we cannot use a global cost, such as F1, directly.",3.2 Dynamic Oracle Supervision,[0],[0]
"As a proxy, we rely on the dynamic oracles’ action-level supervision.
",3.2 Dynamic Oracle Supervision,[0],[0]
"In all models we consider, action probabilities (Eq. 1) are parameterized by a softmax function
pML(a",3.2 Dynamic Oracle Supervision,[0],[0]
| st; θ) ∝,3.2 Dynamic Oracle Supervision,[0],[0]
"exp(z(a, st, θ))
for some state–action scoring function z.",3.2 Dynamic Oracle Supervision,[0],[0]
"The softmax-margin objective replaces this by
pSMM (a | st; θ) ∝",3.2 Dynamic Oracle Supervision,[0],[0]
"exp(z(a, st, θ) + ∆(a, a∗t ))",3.2 Dynamic Oracle Supervision,[0],[0]
"(2) We use ∆(a, a∗t )",3.2 Dynamic Oracle Supervision,[0],[0]
= 0,3.2 Dynamic Oracle Supervision,[0],[0]
if a = a ∗ t and 1 otherwise.,3.2 Dynamic Oracle Supervision,[0],[0]
"This can be viewed as a “soft” version of the maxmargin objective used by Stern et al. (2017) for training without exploration, but retains a locallynormalized model that we can use for samplingbased exploration.
",3.2 Dynamic Oracle Supervision,[0],[0]
"Softmax Margin with Exploration Finally, we train using a combination of softmax margin loss augmentation and exploration.",3.2 Dynamic Oracle Supervision,[0],[0]
"We perform the same sample-based candidate generation as for policy gradient and likelihood training with exploration, but use Eq. 2 to compute the training loss for candidate states.",3.2 Dynamic Oracle Supervision,[0],[0]
"For those parsers that have a dynamic oracle, this provides a means of training that more directly provides both exploration and cost-aware losses.",3.2 Dynamic Oracle Supervision,[0],[0]
We compare the constituency parsers listed in Section 2 using the above training methods.,4 Experiments,[0],[0]
"Our experiments use the English PTB (Marcus et al., 1993), French Treebank (Abeillé et al., 2003), and Penn Chinese Treebank (CTB) Version 5.1 (Xue et al., 2005).
",4 Experiments,[0],[0]
"Training To compare the training procedures as closely as possible, we train all models for a given parser in a given language from the same randomly-initialized parameter values.
",4 Experiments,[0],[0]
"We train two different versions of the RNNG model: one model using size 128 for the LSTMs and hidden states (following the original work), and a larger model with size 256.",4 Experiments,[0],[0]
"We perform evaluation using greedy search in the Span-Based and Top-Down parsers, and beam search with beam size 10 for the RNNG and In-Order parsers.",4 Experiments,[0],[0]
"We found that beam search improved performance for these two parsers by around 0.1-0.3 F1 on the development sets, and use it at inference time in every setting for these two parsers.
",4 Experiments,[0],[0]
"In our experiments, policy gradient typically requires more epochs of training to reach performance comparable to either of the dynamic oraclebased exploration methods.",4 Experiments,[0],[0]
"Figure 1 gives a typical learning curve, for the Top-Down parser on English.",4 Experiments,[0],[0]
"We found that policy gradient is also more sensitive to the number of candidates sampled per
sentence than either of the other exploration methods, with best performance on the development set usually obtained with k = 10 for k ∈ {2, 5, 10} (where k also counts the sentence’s gold tree, included in the candidate set).",4 Experiments,[0],[0]
"See Appendix A in the supplemental material for the values of k used.
",4 Experiments,[0],[0]
"Tags, Embeddings, and Morphology We largely follow previous work for each parser in our use of predicted part-of-speech tags, pretrained word embeddings, and morphological features.
",4 Experiments,[0],[0]
All parsers use predicted part-of-speech tags as part of their sentence representations.,4 Experiments,[0],[0]
"For English and Chinese, we follow the setup of Cross and Huang (2016): training the Stanford tagger (Toutanova et al., 2003) on the training set of each parsing corpus to predict development and test set tags, and using 10-way jackknifing to predict tags for the training set.
",4 Experiments,[0],[0]
"For French, we use the predicted tags and morphological features provided with the SPMRL dataset (Seddah et al., 2014).",4 Experiments,[0],[0]
We modified the publicly released code for all parsers to use predicted morphological features for French.,4 Experiments,[0],[0]
"We follow the approach outlined by Cross and Huang (2016) and Stern et al. (2017) for representing morphological features as learned embeddings, and use the same dimensions for these embeddings as in their papers.",4 Experiments,[0],[0]
"For RNNG and In-Order, we similarly use 10-dimensional learned embeddings for each morphological feature, feeding them as LSTM inputs for each word alongside the word and part-of-speech tag embeddings.
",4 Experiments,[0],[0]
"For RNNG and the In-Order parser, we use the same word embeddings as the original papers for English and Chinese, and train 100-dimensional word embeddings for French using the structured skip-gram method of Ling et al. (2015) on French Wikipedia.",4 Experiments,[0],[0]
Table 1 compares parser F1 by training procedure for each language.,5 Results and Discussion,[0],[0]
"Policy gradient improves upon likelihood training in 14 out of 15 cases, with improvements of up to 1.5 F1.",5 Results and Discussion,[0],[0]
"One of the three dynamic oracle-based training methods – either likelihood with exploration, softmax margin (SMM), or softmax margin with exploration – obtains better performance than policy gradient in 10 out of 12 cases.",5 Results and Discussion,[0],[0]
"This is perhaps unsurprising given the strong supervision provided by the dynamic oracles and the credit assignment problem faced by
policy gradient.",5 Results and Discussion,[0],[0]
"However, a substantial fraction of this performance gain is recaptured by policy gradient in most cases.
",5 Results and Discussion,[0],[0]
"While likelihood training with exploration using a dynamic oracle more directly addresses exploration bias, and softmax margin training more directly addresses loss mismatch, these two phenomena are still entangled, and the best dynamic oracle-based method to use varies.",5 Results and Discussion,[0],[0]
The effectiveness of the oracle method is also likely to be influenced by the nature of the dynamic oracle available for the parser.,5 Results and Discussion,[0],[0]
"For example, the oracle for RNNG lacks F1 optimality guarantees, and softmax margin without exploration often underperforms likelihood for this parser.",5 Results and Discussion,[0],[0]
"However, exploration improves softmax margin training across all parsers and conditions.
",5 Results and Discussion,[0],[0]
"Although results from likelihood training are mostly comparable between RNNG-128 and the larger model RNNG-256 across languages, policy gradient and likelihood training with exploration both typically yield larger improvements in the larger models, obtaining 92.6 F1 for English and 86.0 for Chinese (using likelihood training with exploration), although results are slightly higher for the policy gradient and dynamic oracle-based methods for the smaller model on French (including 83.5 with softmax margin with exploration).",5 Results and Discussion,[0],[0]
"Finally, we observe that policy gradient also provides large improvements for the In-Order parser, where a dynamic oracle has not been defined.
",5 Results and Discussion,[0],[0]
"We note that although some of these results (92.6 for English, 83.5 for French, 87.0 for Chinese) are state-of-the-art for single model, discriminative transition-based parsers, other work on constituency parsing achieves better performance through other methods.",5 Results and Discussion,[0],[0]
"Techniques that combine multiple models or add semi-supervised data (Vinyals et al., 2015; Dyer et al., 2016; Choe and Charniak, 2016; Kuncoro et al., 2017; Liu and Zhang, 2017; Fried et al., 2017) are orthogonal to, and could be combined with, the singlemodel, fixed training data methods we explore.",5 Results and Discussion,[0],[0]
"Other recent work (Gaddy et al., 2018; Kitaev and Klein, 2018) obtains comparable or stronger performance with global chart decoders, where training uses loss augmentation provided by an oracle.",5 Results and Discussion,[0],[0]
"By performing model-optimal global inference, these parsers likely avoid the exposure bias problem of the sequential transition-based parsers we investigate, at the cost of requiring a chart decoding procedure for inference.
",5 Results and Discussion,[0],[0]
"Overall, we find that although optimizing for F1 in a model-agnostic fashion with policy gradient typically underperforms the model-aware expert supervision given by the dynamic oracle training methods, it provides a simple method for consistently improving upon static oracle likelihood training, at the expense of increased training costs.",5 Results and Discussion,[0],[0]
DF is supported by a Huawei / Berkeley AI fellowship.,Acknowledgments,[0],[0]
"This research used the Savio computational cluster provided by the Berkeley Research Computing program at the University of California, Berkeley.",Acknowledgments,[0],[0]
"Dynamic oracles provide strong supervision for training constituency parsers with exploration, but must be custom defined for a given parser’s transition system.",abstractText,[0],[0]
We explore using a policy gradient method as a parser-agnostic alternative.,abstractText,[0],[0]
"In addition to directly optimizing for a tree-level metric such as F1, policy gradient has the potential to reduce exposure bias by allowing exploration during training; moreover, it does not require a dynamic oracle for supervision.",abstractText,[0],[0]
"On four constituency parsers in three languages, the method substantially outperforms static oracle likelihood training in almost all settings.",abstractText,[0],[0]
"For parsers where a dynamic oracle is available (including a novel oracle which we define for the transition system of Dyer et al. (2016)), policy gradient typically recaptures a substantial fraction of the performance gain afforded by the dynamic oracle.",abstractText,[0],[0]
Policy Gradient as a Proxy for Dynamic Oracles in Constituency Parsing,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2442–2452 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2442",text,[0],[0]
"Semantic parsing from denotations (SpFD) is the problem of mapping text to executable formal representations (or program) in a situated environment and executing them to generate denotations (or answer), in the absence of access to correct representations.",1 Introduction,[0],[0]
"Several problems have been handled within this framework, including question answering (Berant et al., 2013; Iyyer et al., 2017) and instructions for robots (Artzi and Zettlemoyer, 2013; Misra et al., 2015).
",1 Introduction,[0],[0]
Consider the example in Figure 1.,1 Introduction,[0],[0]
"Given the question and a table environment, a semantic parser maps the question to an executable program, in this case a SQL query, and then executes the query on the environment to generate the answer England.",1 Introduction,[0],[0]
"In the SpFD setting, the training data does not contain the correct programs.",1 Introduction,[0],[0]
"Thus, the existing learning approaches for SpFD perform two steps for every training example, a search step that explores the space of programs
Question: what nation scored the most points
Index Name Nation Points Games Pts/game 1 Karen Andrew England 44 5 8.8 2 Daniella Waterman England 40 5 8 3 Christelle Le Duff France 33 5 6.6 4 Charlotte Barras England 30 5 6 5",1 Introduction,[0],[0]
"Naomi Thomas Wales 25 5 5
Select Nation Where Points is Maximum
Program:
",1 Introduction,[0],[0]
"Answer:
Environment:
England
Figure 1: An example of semantic parsing from denotations.",1 Introduction,[0],[0]
"Given the table environment, map the question to an executable program that evaluates to the answer.
and finds suitable candidates, and an update step that uses these programs to update the model.",1 Introduction,[0.9505460779941713],['Another research direction that holds promise is to use an unsupervised approach to extract semantic information from referring expressions.']
"Figure 2 shows the two step training procedure for the above example.
",1 Introduction,[0],[0]
"In this paper, we address two key challenges in model training for SpFD by proposing a novel learning framework, improving both the search and update steps.",1 Introduction,[0],[0]
"The first challenge, the existence of spurious programs, lies in the search step.",1 Introduction,[0],[0]
"More specifically, while the success of the search step relies on its ability to find programs that are semantically correct, we can only verify if the program can generate correct answers, given that no gold programs are presented.",1 Introduction,[0],[0]
"The search step is complicated by spurious programs, which happen to evaluate to the correct answer but do not represent accurately the meaning of the natural language question.",1 Introduction,[0],[0]
"For example, for the environment in Figure 1, the program Select Nation",1 Introduction,[0],[0]
Where Name = Karen Andrew is spurious.,1 Introduction,[0],[0]
"Selecting spurious programs as positive examples can greatly affect the performance of semantic parsers as these programs generally do not gen-
eralize to unseen questions and environments.",1 Introduction,[0],[0]
"The second challenge, choosing a learning algorithm, lies in the update step.",1 Introduction,[0],[0]
"Because of the unique indirect supervision setting of SpFD, the quality of the learned semantic parser is dictated by the choice of how to update the model parameters, often determined empirically.",1 Introduction,[0],[0]
"As a result, several families of learning methods, including maximum marginal likelihood, reinforcement learning and margin based methods have been used.",1 Introduction,[0],[0]
"How to effectively explore different model choices could be crucial in practice.
",1 Introduction,[0],[0]
Our contributions in this work are twofold.,1 Introduction,[0],[0]
"To address the first challenge, we propose a policy shaping (Griffith et al., 2013) method that incorporates simple, lightweight domain knowledge, such as a small set of lexical pairs of tokens in the question and program, in the form of a critique policy (§ 3).",1 Introduction,[0],[0]
"This helps bias the search towards the correct program, an important step to improve supervision signals, which benefits learning regardless of the choice of algorithm.",1 Introduction,[0],[0]
"To address the second challenge, we prove that the parameter update step in several algorithms are similar and can be viewed as special cases of a generalized update equation (§ 4).",1 Introduction,[0],[0]
The equation contains two variable terms that govern the update behavior.,1 Introduction,[0],[0]
Changing these two terms effectively defines an infinite class of learning algorithms where different values lead to significantly different results.,1 Introduction,[0],[0]
"We study this effect and propose a novel learning framework that improves over existing methods.
",1 Introduction,[0],[0]
"We evaluate our methods using the sequential question answering (SQA) dataset (Iyyer et al., 2017), and show that our proposed improvements to the search and update steps consistently enhance existing approaches.",1 Introduction,[0],[0]
The proposed algorithm achieves new state-of-the-art and outperforms existing parsers by 5.0%.,1 Introduction,[0],[0]
"We give a formal problem definition of the semantic parsing task, followed by the general learning framework for solving it.",2 Background,[0],[0]
The problem discussed in this paper can be formally defined as follows.,2.1 The Semantic Parsing Task,[0],[0]
"Let X be the set of all possible questions, Y programs (e.g., SQL-like queries), T tables (i.e., the structured data in this work) and Z answers.",2.1 The Semantic Parsing Task,[0],[0]
We further assume access to an executor : Y ⇥ T !,2.1 The Semantic Parsing Task,[0],[0]
"Z , that given a program y 2 Y and a table t 2 T , generates an answer (y, t) 2 Z .",2.1 The Semantic Parsing Task,[0],[0]
We assume that the executor and all tables are deterministic and the executor can be called as many times as possible.,2.1 The Semantic Parsing Task,[0],[0]
"To facilitate discussion in the following sections, we define an environment function et : Y !",2.1 The Semantic Parsing Task,[0],[0]
"Z , by applying the executor to the program as et(y) = (y, t).
",2.1 The Semantic Parsing Task,[0],[0]
"Given a question x and an environment et, our aim is to generate a program y⇤ 2 Y and then execute it to produce the answer et(y⇤).",2.1 The Semantic Parsing Task,[0],[0]
"Assume that for any y 2 Y , the score of y being a correct program for x is score✓(y, x, t), parameterized by ✓.",2.1 The Semantic Parsing Task,[0],[0]
"The inference task is thus:
y⇤ = arg max y2Y score✓(y, x, t) (1)
",2.1 The Semantic Parsing Task,[0],[0]
"As the size of Y is exponential to the length of the program, a generic search procedure is typically employed for Eq.",2.1 The Semantic Parsing Task,[0],[0]
"(1), as efficient dynamic algorithms typically do not exist.",2.1 The Semantic Parsing Task,[0],[0]
"These search procedures generally maintain a beam of program states sorted according to some scoring function, where each program state represents an incomplete program.",2.1 The Semantic Parsing Task,[0],[0]
The search then generates a new program state from an existing state by performing an action.,2.1 The Semantic Parsing Task,[0],[0]
"Each action adds a set of tokens (e.g., Nation) and keyword (e.g., Select) to a
program state.",2.1 The Semantic Parsing Task,[0],[0]
"For example, in order to generate the program in Figure 1, the DynSP parser (Iyyer et al., 2017) will take the first action as adding the SQL expression Select Nation.",2.1 The Semantic Parsing Task,[0],[0]
Notice that score✓ can be used in either probabilistic or nonprobabilistic models.,2.1 The Semantic Parsing Task,[0],[0]
"For probabilistic models, we assume that it is a Boltzmann policy, meaning that p✓(y | x, t) / exp{score✓(y, x, t)}.",2.1 The Semantic Parsing Task,[0],[0]
"Learning a semantic parser is equivalent to learning the parameters ✓ in the scoring function, which is a structured learning problem, due to the large, structured output space Y .",2.2 Learning,[0],[0]
Structured learning algorithms generally consist of two major components: search and update.,2.2 Learning,[0],[0]
"When the gold programs are available during training, the search procedure finds a set of high-scoring incorrect programs.",2.2 Learning,[0],[0]
These programs are used by the update step to derive loss for updating parameters.,2.2 Learning,[0],[0]
"For example, these programs are used for approximating the partition-function in maximum-likelihood objective (Liang et al., 2011) and finding set of programs causing margin violation in margin based methods (Daumé III and Marcu, 2005).",2.2 Learning,[0],[0]
"Depending on the exact algorithm being used, these two components are not necessarily separated into isolated steps.",2.2 Learning,[0],[0]
"For instance, parameters can be updated in the middle of search (e.g., Huang et al., 2012).
",2.2 Learning,[0],[0]
"For learning semantic parsers from denotations, where we assume only answers are available in a training set {(xi, ti, zi)}Ni=1 of N examples, the basic construction of the learning algorithms remains the same.",2.2 Learning,[0],[0]
"However, the problems that search needs to handle in SpFD is more challenging.",2.2 Learning,[0],[0]
"In addition to finding a set of high-scoring incorrect programs, the search procedure also needs to guess the correct program(s) evaluating to the gold answer zi.",2.2 Learning,[0],[0]
"This problem is further complicated by the presence of spurious programs, which generate the correct answer but are semantically incompatible with the question.",2.2 Learning,[0],[0]
"For example, although all programs in Figure 2 evaluate to the same answer, only one of them is correct.",2.2 Learning,[0],[0]
The issue of the spurious programs also affects the design of model update.,2.2 Learning,[0],[0]
"For instance, maximum marginal likelihood methods treat all the programs that evaluate to the gold answer equally, while maximum margin reward networks use model score to break tie and pick one of the
programs as the correct reference.",2.2 Learning,[0],[0]
"Given a training example (x, t, z), the aim of the search step is to find a set K(x, t, z) of programs consisting of correct programs that evaluate to z and high-scoring incorrect programs.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
The search step should avoid picking up spurious programs for learning since such programs typically do not generalize.,3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"For example, in Figure 2, the spurious program Select Nation Where Index is Min will evaluate to an incorrect answer if the indices of the first two rows are swapped1.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"This problem is challenging since among the programs that evaluate to the correct answer, most of them are spurious.
",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"The search step can be viewed as following an exploration policy b✓(y|x, t, z) to explore the set of programs Y .",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"This exploration is often performed by beam search and at each step, we either sample from b✓ or take the top scoring programs.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"The set K(x, t, z) is then used by the update step for parameter update.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Most search strategies use an exploration policy which is based on the score function, for example b✓(y|x, t, z) / exp{score✓(y, t)}.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"However, this approach can suffer from a divergence phenomenon whereby the score of spurious programs picked up by the search in the first epoch increases, making it more likely for the search to pick them up in the future.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Such divergence issues are common with latent-variable learning and often require careful initialization to overcome (Rose, 1998).",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Unfortunately such initialization schemes are not applicable for deep neural networks which form the model of most successful semantic parsers today (Jia and Liang, 2016; Misra and Artzi, 2016; Iyyer et al., 2017).",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Prior work, such as ✏-greedy exploration (Guu et al., 2017), has reduced the severity of this problem by introducing random noise in the search procedure to avoid saturating the search on high-scoring spurious programs.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"However, random noise need not bias the search towards the correct program(s).",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"In this paper, we introduce a simple policy-shaping method to guide the search.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"This approach allows incorporating prior knowledge in the exploration policy and can bias the search away from spurious programs.
",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"1This transformation preserves the answer of the question.
",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Algorithm 1 Learning a semantic parser from denotation using generalized updates.
",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Input: Training set {(xi, ti, zi}Ni=1 (see Section 2), learning rate µ and stopping epoch T (̃see Section 4).",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Definitions: score✓(y, x, t) is a semantic parsing model parameterized by ✓.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
ps(y,3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"| x, t) is the policy used for exploration and search(✓, x, t, z, ps) generates candidate programs for updating parameters (see Section 3).",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
is the generalized update (see Section 4).,3 Addressing Spurious Programs: Policy Shaping,[0],[0]
Output: Model parameters ✓.,3 Addressing Spurious Programs: Policy Shaping,[0],[0]
1: » Iterate over the training data.,3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"2: for t = 1 to T , i = 1 to N do 3: » Find candidate programs using the shaped policy.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"4: K = search(✓, xi, ti, zi, ps) 5: » Compute generalized gradient updates 6: ✓ = ✓ + µ (K) 7: return ✓
Policy Shaping Policy shaping is a method to introduce prior knowledge into a policy (Griffith et al., 2013).",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Formally, let the current behavior policy be b✓(y|x, t, z) and a predefined critique policy, the prior knowledge, be pc(y|x, t).",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Policy shaping defines a new shaped behavior policy pb(y|x, t) given by:
pb(y|x, t) = b✓(y|x, t, z)pc(y|x, t)P
y02Y",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"b✓(y 0|x, t, z)pc(y0|x, t)
.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"(2)
Using the shaped policy for exploration biases the search towards the critique policy’s preference.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"We next describe a simple critique policy that we use in this paper.
",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
Lexical Policy Shaping We qualitatively observed that correct programs often contains tokens which are also present in the question.,3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"For example, the correct program in Figure 2 contains the token Points, which is also present in the question.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"We therefore, define a simple surface form similarity feature match(x, y) that computes the ratio of number of non-keyword tokens in the program y that are also present in the question",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"x.
However, surface-form similarity is often not enough.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"For example, both the first and fourth program in Figure 2 contain the token Points but only the fourth program is correct.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Therefore, we also use a simple co-occurrence feature that triggers on frequently co-occurring pairs of tokens in the program and instruction.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"For example, the token most is highly likely to co-occur with a correct program containing the keyword Max.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
This happens for the example in Figure 2.,3 Addressing Spurious Programs: Policy Shaping,[0],[0]
Similarly the token not may co-occur with the keyword NotEqual.,3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"We assume access to a lexicon ⇤ = {(wj , !j)}kj=1",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"containing
k lexical pairs of tokens and keywords.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Each lexical pair (w, !) maps the token w in a text to a keyword !",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
in a program.,3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"For a given program y and question x, we define a co-occurrence score as co_occur(y, x) = P (w,!)2⇤ {w 2 x ^ !",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
2 y}}.,3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"We define critique score critique(y, x) as the sum of the match and co_occur scores.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"The critique policy is given by:
pc(y|x, t) / exp",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"(⌘ ⇤ critique(y, x)) , (3)
where ⌘ is a single scalar hyper-parameter denoting the confidence in the critique policy.",3 Addressing Spurious Programs: Policy Shaping,[0],[0]
"Given the set of programs generated by the search step, one can use many objectives to update the parameters.",4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
"For example, previous work have utilized maximum marginal likelihood (Krishnamurthy et al., 2017; Guu et al., 2017), reinforcement learning (Zhong et al., 2017; Guu et al., 2017) and margin based methods (Iyyer et al., 2017).",4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
"It could be difficult to choose the suitable algorithm from these options.
",4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
"In this section, we propose a principle and general update equation such that previous update algorithms can be considered as special cases to this equation.",4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
Having a general update is important for the following reasons.,4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
"First, it allows us to understand existing algorithms better by examining their basic properties.",4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
"Second, the generalized update equation also makes it easy to implement and experiment with various different algorithms.",4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
"Moreover, it provides a framework that enables the development of new variations or extensions of existing learning methods.
",4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
"In the following, we describe how the commonly used algorithms are in fact very similar – their update rules can all be viewed as special cases of the proposed generalized update equation.",4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
Algorithm 1 shows the meta-learning framework.,4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
"For every training example, we first find a set of candidates using an exploration policy (line 4).",4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
We use the program candidates to update the parameters (line 6).,4 Addressing Update Strategy Selection: Generalized Update Equation,[0],[0]
"We briefly describe three algorithms: maximum marginalized likelihood, policy gradient and maximum margin reward.
",4.1 Commonly Used Learning Algorithms,[0],[0]
"Maximum Marginalized Likelihood The maximum marginalized likelihood method maximizes the log-likelihood of the training data by marginalizing over the set of programs.
",4.1 Commonly Used Learning Algorithms,[0],[0]
"JMML = log p(zi|xi, ti) = log X
y2Y p(zi|y, ti)p(y|xi, ti) (4)
",4.1 Commonly Used Learning Algorithms,[0],[0]
"Because an answer is deterministically computed given a program and a table, we define p(z | y, t) as 1 or 0 depending upon whether the y evaluates to z given t, or not.",4.1 Commonly Used Learning Algorithms,[0],[0]
"Let Gen(z, t) ✓ Y be the set of compatible programs that evaluate to z given the table t.",4.1 Commonly Used Learning Algorithms,[0],[0]
"The objective can then be expressed as:
JMML = log X
y2Gen(zi,ti)
p(y|xi, ti) (5)
",4.1 Commonly Used Learning Algorithms,[0],[0]
"In practice, the summation over Gen(.) is approximated by only using the compatible programs in the set K generated by the search step.
",4.1 Commonly Used Learning Algorithms,[0],[0]
Policy Gradient Methods Most reinforcement learning approaches for semantic parsing assume access to a reward function R : Y ⇥X ⇥Z !,4.1 Commonly Used Learning Algorithms,[0],[0]
"R, giving a scalar reward R(y, z) for a given program y and the correct answer z.2",4.1 Commonly Used Learning Algorithms,[0],[0]
"We can further assume without loss of generality that the reward is always in [0, 1].",4.1 Commonly Used Learning Algorithms,[0],[0]
"Reinforcement learning approaches maximize the expected reward JRL:
JRL = X
y2Y p(y|xi, ti)R(y, zi) (6)
JRL is hard to approximate using numerical integration since the reward for all programs may not be known a priori.",4.1 Commonly Used Learning Algorithms,[0],[0]
Policy gradient methods solve this by approximating the derivative using a sample from the policy.,4.1 Commonly Used Learning Algorithms,[0],[0]
"When the search space is large, the policy may fail to sample a correct program, which can greatly slow down the learning.",4.1 Commonly Used Learning Algorithms,[0],[0]
"Therefore, off-policy methods are sometimes introduced to bias the sampling towards high-reward yielding programs.",4.1 Commonly Used Learning Algorithms,[0],[0]
"In those methods, an additional exploration policy u(y|xi, ti, zi) is used to improve sampling.",4.1 Commonly Used Learning Algorithms,[0],[0]
"Importance weights are used to make the gradient unbiased (see Appendix for derivation).
",4.1 Commonly Used Learning Algorithms,[0],[0]
2This is essentially a contextual bandit setting.,4.1 Commonly Used Learning Algorithms,[0],[0]
Guu et al. (2017) also used this setting.,4.1 Commonly Used Learning Algorithms,[0],[0]
A general reinforcement learning setting requires taking a sequence of actions and receiving a reward for each action.,4.1 Commonly Used Learning Algorithms,[0],[0]
"For example, a program can be viewed as a sequence of parsing actions, where each action can get a reward.",4.1 Commonly Used Learning Algorithms,[0],[0]
"We do not consider the general setting here.
",4.1 Commonly Used Learning Algorithms,[0],[0]
"Maximum Margin Reward For every training example (xi, ti, zi), the maximum margin reward method finds the highest scoring program yi that evaluates to zi, as the reference program, from the set K of programs generated by the search.",4.1 Commonly Used Learning Algorithms,[0],[0]
With a margin function : Y⇥Y⇥Z !,4.1 Commonly Used Learning Algorithms,[0],[0]
"R and reference program y, the set of programs V that violate the margin constraint can thus be defined as:
V = {y0 | y0 2 Y and score✓(y, x, t)  score✓(y0, x, t)",4.1 Commonly Used Learning Algorithms,[0],[0]
+,4.1 Commonly Used Learning Algorithms,[0],[0]
"(y, y0, z)}, (7)
where (y, y0, z) = R(y, z)",4.1 Commonly Used Learning Algorithms,[0],[0]
"R(y0, z).",4.1 Commonly Used Learning Algorithms,[0],[0]
"Similarly, the program that most violates the constraint can be written as:
ȳ = arg max y02Y
{score✓(y0, x, t) +",4.1 Commonly Used Learning Algorithms,[0],[0]
"(y, y0, z)
score✓(y, x, t)}",4.1 Commonly Used Learning Algorithms,[0],[0]
"(8)
The most-violation margin objective (negative margin loss) is thus defined as:
JMMR = max{0, score✓(ȳ, xi, ti) score✓(yi, xi, ti) +",4.1 Commonly Used Learning Algorithms,[0],[0]
"(yi, ȳ, zi)}
Unlike the previous two learning algorithms, margin methods only update the score of the reference program and the program that violates the margin.",4.1 Commonly Used Learning Algorithms,[0],[0]
"Although the algorithms described in §4.1 seem very different on the surface, the gradients of their loss functions can in fact be described in the same generalized form, given in Eq.",4.2 Generalized Update Equation,[0],[0]
(9)3.,4.2 Generalized Update Equation,[0],[0]
"In addition to the gradient of the model scoring function, this equation has two variable terms, w(·), q(·).",4.2 Generalized Update Equation,[0],[0]
"We call the first term w(y, x, t, z) intensity, which is a positive scalar value and the second term q(y|x, t) the competing distribution, which is a probability distribution over programs.",4.2 Generalized Update Equation,[0],[0]
"Varying them makes the equation equivalent to the update rule of the algorithms we discussed, as shown in Table 1.",4.2 Generalized Update Equation,[0],[0]
"We also consider meritocratic update policy which uses a hyperparameter to sharpen or smooth the intensity of maximum marginal likelihood (Guu et al., 2017).
",4.2 Generalized Update Equation,[0],[0]
"Intuitively, w(y, x, t, z) defines the positive part of the update equation, which defines how aggressively the update favors program y. Likewise, q(y|x, t) defines the negative part of the learning
3See Appendix for the detailed derivation.
",4.2 Generalized Update Equation,[0],[0]
"Generalized Update Equation:
(K) = X
y2K w(y, x, t, z)
0 @r✓score✓(y, x, t) X
y02Y",4.2 Generalized Update Equation,[0],[0]
"q(y0|x, t)r✓score✓(y0, x, t)
1
A (9)
algorithm, namely how aggressively the update penalizes the members of the program set.
",4.2 Generalized Update Equation,[0],[0]
"The generalized update equation provides a tool for better understanding individual algorithm, and helps shed some light on when a particular method may perform better.
",4.2 Generalized Update Equation,[0],[0]
"Intensity versus Search Quality In SpFD, the effectiveness of the algorithms for SpFD is closely related to the quality of the search results given that the gold program is not available.",4.2 Generalized Update Equation,[0],[0]
"Intuitively, if the search quality is good, the update algorithm could be aggressive on updating the model parameters.",4.2 Generalized Update Equation,[0],[0]
"When the search quality is poor, the algorithm should be conservative.
",4.2 Generalized Update Equation,[0],[0]
The intensity w(·) is closely related to the aggressiveness of the algorithm.,4.2 Generalized Update Equation,[0],[0]
"For example, the maximum marginal likelihood is less aggressive given that it produces a non-zero intensity over all programs in the program set K that evaluate to the correct answer.",4.2 Generalized Update Equation,[0],[0]
"The intensity for a particular correct program y is proportional to its probability p(y|x, t).",4.2 Generalized Update Equation,[0],[0]
"Further, meritocratic update becomes more aggressive as becomes larger.
",4.2 Generalized Update Equation,[0],[0]
"In contrast, REINFORCE and maximum margin reward both have a non-zero intensity only on a single program in K.",4.2 Generalized Update Equation,[0],[0]
"This value is 1.0 for maximum margin reward, while for reinforcement learning, this value is the reward.",4.2 Generalized Update Equation,[0],[0]
"Maximum margin reward therefore updates most aggressively in favor of its selection while maximum marginal
likelihood tends to hedge its bet.",4.2 Generalized Update Equation,[0],[0]
"Therefore, the maximum margin methods should benefit the most when the search quality improves.
",4.2 Generalized Update Equation,[0],[0]
Stability The general equation also allows us to investigate the stability of a model update algorithm.,4.2 Generalized Update Equation,[0],[0]
"In general, the variance of update direction can be high, hence less stable, if the model update algorithm has peaky competing distribution, or it puts all of its intensity on a single program.",4.2 Generalized Update Equation,[0],[0]
"For example, REINFORCE only samples one program and puts non-zero intensity only on that program, so it could be unstable depending on the sampling results.
",4.2 Generalized Update Equation,[0],[0]
The competing distribution affects the stability of the algorithm.,4.2 Generalized Update Equation,[0],[0]
"For example, maximum margin reward penalizes only the most violating program and is benign to other incorrect programs.",4.2 Generalized Update Equation,[0],[0]
"Therefore, the MMR algorithm could be unstable during training.
",4.2 Generalized Update Equation,[0],[0]
New Model Update Algorithm,4.2 Generalized Update Equation,[0],[0]
The general equation provides a framework that enables the development of new variations or extensions of existing learning methods.,4.2 Generalized Update Equation,[0],[0]
"For example, in order to improve the stability of the MMR algorithm, we propose a simple variant of maximum margin reward, which penalizes all violating programs instead of only the most violating one.",4.2 Generalized Update Equation,[0],[0]
"We call this approach maximum margin average violation reward (MAVER), which is included in Table 1 as well.",4.2 Generalized Update Equation,[0],[0]
"Given that MAVER effectively considers
more negative examples during each update, we expect that it is more stable compared to the MMR algorithm.",4.2 Generalized Update Equation,[0],[0]
We describe the setup in §5.1 and results in §5.2.,5 Experiments,[0],[0]
"Dataset We use the sequential question answering (SQA) dataset (Iyyer et al., 2017) for our experiments.",5.1 Setup,[0],[0]
"SQA contains 6,066 sequences and each sequence contains up to 3 questions, with 17,553 questions in total.",5.1 Setup,[0],[0]
The data is partitioned into training (83%) and test (17%) splits.,5.1 Setup,[0],[0]
We use 4/5 of the original train split as our training set and the remaining 1/5 as the dev set.,5.1 Setup,[0],[0]
We evaluate using exact match on answer.,5.1 Setup,[0],[0]
"Previous state-of-theart result on the SQA dataset is 44.7% accuracy, using maximum margin reward learning.
",5.1 Setup,[0],[0]
"Semantic Parser Our semantic parser is based on DynSP (Iyyer et al., 2017), which contains a set of SQL actions, such as adding a clause (e.g., Select Column) or adding an operator (e.g., Max).",5.1 Setup,[0],[0]
"Each action has an associated neural network module that generates the score for the action based on the instruction, the table and the list of past actions.",5.1 Setup,[0],[0]
"The score of the entire program is given by the sum of scores of all actions.
",5.1 Setup,[0],[0]
We modified DynSP to improve its representational capacity.,5.1 Setup,[0],[0]
We refer to the new parser as DynSP++.,5.1 Setup,[0],[0]
"Most notably, we included new features and introduced two additional parser actions.",5.1 Setup,[0],[0]
See Appendix 8.2 for more details.,5.1 Setup,[0],[0]
"While these improvements help us achieve state-of-the-art results, the majority of the gain comes from the learning contributions described in this paper.
",5.1 Setup,[0],[0]
"Hyperparameters For each experiment, we train the model for 30 epochs.",5.1 Setup,[0],[0]
We find the optimal stopping epoch by evaluating the model on the dev set.,5.1 Setup,[0],[0]
We then train on train+dev set till the stopping epoch and evaluate the model on the held-out test set.,5.1 Setup,[0],[0]
Model parameters are trained using stochastic gradient descent with learning rate of 0.1.,5.1 Setup,[0],[0]
We set the hyperparameter ⌘ for policy shaping to 5.,5.1 Setup,[0],[0]
All hyperparameters were tuned on the dev set.,5.1 Setup,[0],[0]
We use 40 lexical pairs for defining the co-occur score.,5.1 Setup,[0],[0]
"We used common English superlatives (e.g., highest, most) and comparators (e.g., more, larger) and did not fit the lexical pairs based on the dataset.
",5.1 Setup,[0],[0]
"Given the model parameter ✓, we use a base exploration policy defined in (Iyyer et al., 2017).",5.1 Setup,[0.9543972057729755],"['First, we compare against a rankingbased model that uses dialogue history and task history features (Iida et al., 2010).']"
"This exploration policy is given by b✓(y | x, t, z) / exp( · R(y, z) + score",5.1 Setup,[0],[0]
"✓(y, ✓, z)).",5.1 Setup,[0],[0]
"R(y, z) is the reward function of the incomplete program y, given the answer z.",5.1 Setup,[0],[0]
"We use a reward function R(y, z) given by the Jaccard similarity of the gold answer z and the answer generated by the program y.",5.1 Setup,[0],[0]
"The value of is set to infinity, which essentially is equivalent to sorting the programs based on the reward and using the current model score for tie breaking.",5.1 Setup,[0],[0]
"Further, we prune all syntactically invalid programs.",5.1 Setup,[0],[0]
"For more details, we refer the reader to (Iyyer et al., 2017).",5.1 Setup,[0],[0]
Table 2 contains the dev and test results when using our algorithm on the SQA dataset.,5.2 Results,[0],[0]
We observe that margin based methods perform better than maximum likelihood methods and policy gradient in our experiment.,5.2 Results,[0],[0]
Policy shaping in general improves the performance across different algorithms.,5.2 Results,[0],[0]
"Our best test results outperform previous SOTA by 5.0%.
",5.2 Results,[0],[0]
"Policy Gradient vs Off-Policy Gradient REINFORCE, a simple policy gradient method, achieved extremely poor performance.",5.2 Results,[0],[0]
This likely due to the problem of exploration and having to sample from a large space of programs.,5.2 Results,[0],[0]
This is further corroborated from observing the much superior performance of off-policy policy gradient methods.,5.2 Results,[0],[0]
"Thus, the sampling policy is an important factor to consider for policy gradient methods.
",5.2 Results,[0],[0]
The Effect of Policy Shaping We observe that the improvement due to policy shaping is 6.0% on the SQA dataset for MAVER and only 1.3% for maximum marginal likelihood.,5.2 Results,[0],[0]
"We also observe that as increases, the improvement due to policy shaping for meritocratic update increases.",5.2 Results,[0],[0]
"This supports our hypothesis that aggressive updates of margin based methods is beneficial when the search method is more accurate as compared to maximum marginal likelihood which hedges its bet between all programs that evaluate to the right answer.
",5.2 Results,[0],[0]
"Stability of MMR In Section 4, the general update equation helps us point out that MMR could be unstable due to the peaky competing distribution.",5.2 Results,[0],[0]
MAVER was proposed to increase the stability of the algorithm.,5.2 Results,[0],[0]
"To measure stability, we cal-
culate the mean absolute difference of the development set accuracy between successive epochs during training, as it indicates how much an algorithm’s performance fluctuates during training.",5.2 Results,[0],[0]
"With this metric, we found mean difference for MAVER is 0.57% where the mean difference for MMR is 0.9%.",5.2 Results,[0],[0]
"This indicates that MAVER is in fact more stable than MMR.
",5.2 Results,[0],[0]
Other variations We also analyze other possible novel learning algorithms that are made possible due to generalized update equations.,5.2 Results,[0],[0]
Table 3 reports development results using these algorithms.,5.2 Results,[0],[0]
"By mixing different intensity scalars and competing distribution from different algorithms, we can create new variations of the model update algorithm.",5.2 Results,[0],[0]
"In Table 3, we show that by mixing the MMR’s intensity and MML’s competing distribution, we can create an algorithm that outperform MMR on the development set.
",5.2 Results,[0],[0]
"Policy Shaping helps against Spurious Programs In order to better understand if policy shaping helps bias the search away from spurious programs, we analyze 100 training examples.",5.2 Results,[0],[0]
We look at the highest scoring program in the beam at the end of training using MAVER.,5.2 Results,[0],[0]
"Without policy shaping, we found that 53 programs were spurious while using policy shaping this number came down to 23.",5.2 Results,[0],[0]
"We list few examples of spurious program errors corrected by policy shaping in Table 4.
Policy Shaping vs Model Shaping Critique policy contains useful information that can bias the search away from spurious programs.",5.2 Results,[0],[0]
"Therefore, one can also consider making the critique policy as part of the model.",5.2 Results,[0],[0]
We call this model shaping.,5.2 Results,[0],[0]
We define our model to be the shaped policy and train and test using the new model.,5.2 Results,[0],[0]
"Using MAVER updates, we found that the dev accuracy dropped to 37.1%.",5.2 Results,[0],[0]
We conjecture that the strong prior in the critique policy can hinder generalization in model shaping.,5.2 Results,[0],[0]
Semantic Parsing from Denotation Mapping natural language text to formal meaning representation was first studied by Montague (1970).,6 Related Work,[0],[0]
"Early work on learning semantic parsers rely on labeled formal representations as the supervision signals (Zettlemoyer and Collins, 2005, 2007; Zelle and Mooney, 1993).",6 Related Work,[0],[0]
"However, because getting access to gold formal representation generally requires expensive annotations by an expert, distant supervision approaches, where semantic parsers are learned from denotation only, have become the main learning paradigm (e.g., Clarke et al., 2010; Liang et al., 2011; Artzi and Zettlemoyer, 2013; Berant et al., 2013; Iyyer et al., 2017; Krishnamurthy et al., 2017).",6 Related Work,[0],[0]
"Guu et al. (2017) studied the problem of spurious programs and considered adding noise to diversify the search procedure and introduced meritocratic updates.
",6 Related Work,[0],[0]
"Reinforcement Learning Algorithms Reinforcement learning algorithms have been applied to various NLP problems including dialogue (Li et al., 2016), text-based games (Narasimhan et al., 2015), information extraction (Narasimhan et al., 2016), coreference resolution (Clark and Man-
ning, 2016), semantic parsing (Guu et al., 2017) and instruction following (Misra et al., 2017).",6 Related Work,[0],[0]
Guu et al. (2017) show that policy gradient methods underperform maximum marginal likelihood approaches.,6 Related Work,[0],[0]
Our result on the SQA dataset supports their observation.,6 Related Work,[0],[0]
"However, we show that using off-policy sampling, policy gradient methods can provide superior performance to maximum marginal likelihood methods.
",6 Related Work,[0],[0]
Margin-based Learning Margin-based methods have been considered in the context of SVM learning.,6 Related Work,[0],[0]
"In the NLP literature, margin based learning has been applied to parsing (Taskar et al., 2004; McDonald et al., 2005), text classification (Taskar et al., 2003), machine translation (Watanabe et al., 2007) and semantic parsing (Iyyer et al., 2017).",6 Related Work,[0],[0]
Kummerfeld et al. (2015) found that max-margin based methods generally outperform likelihood maximization on a range of tasks.,6 Related Work,[0],[0]
Previous work have studied connections between margin based method and likelihood maximization for supervised learning setting.,6 Related Work,[0],[0]
We show them as special cases of our unified update equation for distant supervision learning.,6 Related Work,[0],[0]
"Similar to this work, Lee et al. (2016) also found that in the context of supervised learning, margin-based algorithms which update all violated examples perform better than the one that only updates the most violated example.
",6 Related Work,[0],[0]
"Latent Variable Modeling Learning semantic parsers from denotation can be viewed as a latent variable modeling problem, where the program is the latent variable.",6 Related Work,[0],[0]
"Probabilistic latent variable models have been studied using EM-algorithm and its variant (Dempster et al., 1977).",6 Related Work,[0],[0]
"The graphical model literature has studied latent variable learning on margin-based methods (Yu and Joachims, 2009) and probabilistic models (Quattoni et al., 2007).",6 Related Work,[0],[0]
"Samdani et al. (2012) studied various vari-
ants of EM algorithm and showed that all of them are special cases of a unified framework.",6 Related Work,[0],[0]
Our generalized update framework is similar in spirit.,6 Related Work,[0],[0]
"In this paper, we propose a general update equation from semantic parsing from denotation and propose a policy shaping method for addressing the spurious program challenge.",7 Conclusion,[0],[0]
"For the future, we plan to apply the proposed learning framework to more semantic parsing tasks and consider new methods for policy shaping.",7 Conclusion,[0],[0]
"We thank Ryan Benmalek, Alane Suhr, Yoav Artzi, Claire Cardie, Chris Quirk, Michel Galley and members of the Cornell NLP group for their valuable comments.",8 Acknowledgements,[0],[0]
We are also grateful to Allen Institute for Artificial Intelligence for the computing resource support.,8 Acknowledgements,[0],[0]
This work was initially started when the first author interned at Microsoft Research.,8 Acknowledgements,[0],[0]
"Semantic parsing from denotations faces two key challenges in model training: (1) given only the denotations (e.g., answers), search for good candidate semantic parses, and (2) choose the best model update algorithm.",abstractText,[0],[0]
We propose effective and general solutions to each of them.,abstractText,[0],[0]
"Using policy shaping, we bias the search procedure towards semantic parses that are more compatible to the text, which provide better supervision signals for training.",abstractText,[0],[0]
"In addition, we propose an update equation that generalizes three different families of learning algorithms, which enables fast model exploration.",abstractText,[0],[0]
"When experimented on a recently proposed sequential question answering dataset, our framework leads to a new state-of-theart model that outperforms previous work by 5.0% absolute on exact match accuracy.",abstractText,[0],[0]
Policy Shaping and Generalized Update Equations for Semantic Parsing from Denotations,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 784–792 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1073",text,[0],[0]
"The basic idea of distributional semantics, i.e. determining the meaning of a word based on its co-occurrence with other words, is derived from the empiricists – Harris (1954) and Firth (1957).",1.1 Distributional semantics,[0],[0]
"John R. Firth drew attention to the contextdependent nature of meaning especially with his
1The dataset is obtainable at: http://zil.ipipan.waw.pl/Scwad/CDSCorpus
famous maxim “You shall know a word by the company it keeps” (Firth, 1957, p. 11).
",1.1 Distributional semantics,[0],[0]
"Nowadays, distributional semantics models are estimated with various methods, e.g. word embedding techniques (Bengio et al., 2003, 2006; Mikolov et al., 2013).",1.1 Distributional semantics,[0],[0]
"To ascertain the purport of a word, e.g. bath, you can use the context of other words that surround it.",1.1 Distributional semantics,[0],[0]
"If we assume that the meaning of this word expressed by its lexical context is associated with a distributional vector, the distance between distributional vectors of two semantically similar words, e.g bath and shower, should be smaller than between vectors representing semantically distinct words, e.g. bath and tree.",1.1 Distributional semantics,[0],[0]
"Based on empirical observations that distributional vectors encode certain aspects of word meaning, it is expected that similar aspects of the meaning of phrases and sentences can also be represented with vectors obtained via composition of distributional word vectors.",1.2 Compositional distributional semantics,[0],[0]
The idea of semantic composition is not new.,1.2 Compositional distributional semantics,[0],[0]
It is well known as the principle of compositionality:2,1.2 Compositional distributional semantics,[0],[0]
“The meaning of a compound expression is a function of the meaning of its parts and of the way they are syntactically combined.”,1.2 Compositional distributional semantics,[0],[0]
"(Janssen, 2012, p. 19).
",1.2 Compositional distributional semantics,[0],[0]
"Modelling the meaning of textual units larger than words using compositional and distributional information is the main subject of compositional distributional semantics (Mitchell and Lapata, 2010; Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Socher et al., 2012, to name a few studies).",1.2 Compositional distributional semantics,[0],[0]
"The fundamental principles of compositional distributional semantics, henceforth referred to as CDS, are mainly propagated with papers written on the topic.",1.2 Compositional distributional semantics,[0],[0]
"Apart from the papers, it was the SemEval-2014 Shared Task 1
2As the principle of compositionality is attributed to Gottlob Frege, it is often called Frege’s principle.
784
(Marelli et al., 2014) that essentially contributed to the expansion of CDS and increased an interest in this domain.",1.2 Compositional distributional semantics,[0],[0]
The goal of the task was to evaluate CDS models of English in terms of semantic relatedness and entailment on proper sentences from the SICK corpus.,1.2 Compositional distributional semantics,[0],[0]
"The SICK corpus (Bentivogli et al., 2014) consists of 10K pairs of English sentences containing multiple lexical, syntactic, and semantic phenomena.",1.3 The SICK corpus,[0],[0]
"It builds on two external data sources – the 8K ImageFlickr dataset (Rashtchian et al., 2010) and SemEval-2012 Semantic Textual Similarity dataset (Agirre et al., 2012).",1.3 The SICK corpus,[0],[0]
"Each sentence pair is human-annotated for relatedness in meaning and entailment.
",1.3 The SICK corpus,[0],[0]
The relatedness score corresponds to the degree of semantic relatedness between two sentences and is calculated as the average of ten human ratings collected for this sentence pair on the 5-point Likert scale.,1.3 The SICK corpus,[0],[0]
"This score indicates the extent to which the meanings of two sentences are related.
",1.3 The SICK corpus,[0],[0]
"The entailment relation between two sentences, in turn, is labelled with entailment, contradiction, or neutral.",1.3 The SICK corpus,[0],[0]
"According to the SICK guidelines, the label assigned by the majority of human annotators is selected as the valid entailment label.",1.3 The SICK corpus,[0],[0]
"Studying approaches to various natural language processing (henceforth NLP) problems, we have observed that the availability of language resources (e.g. training or testing data) stimulates the development of NLP tools and the estimation of NLP models.",1.4 Motivation and organisation of the paper,[0],[0]
English is undoubtedly the most prominent in this regard and English resources are the most numerous.,1.4 Motivation and organisation of the paper,[0],[0]
"Therefore, NLP methods are mostly designed for English and tested on English data, even if there is no guarantee that they are universal.",1.4 Motivation and organisation of the paper,[0],[0]
"In order to verify whether an NLP algorithm is adequate, it is not enough to evaluate it solely for English.",1.4 Motivation and organisation of the paper,[0],[0]
It is also valuable to have high-quality resources for languages typologically different to English.,1.4 Motivation and organisation of the paper,[0],[0]
"Hence, we aim at building datasets for the evaluation of CDS models in languages other than English, which are often underresourced.",1.4 Motivation and organisation of the paper,[0],[0]
"We strongly believe that the availability of test data will encourage development of CDS models in these languages and allow to better test the universality of CDS methods.
",1.4 Motivation and organisation of the paper,[0],[0]
"We start with a high-quality dataset for Polish, which is a completely different language than English in at least two dimensions.",1.4 Motivation and organisation of the paper,[0],[0]
"First, it is a rather under-resourced language in contrast to the resource-rich English.",1.4 Motivation and organisation of the paper,[0],[0]
"Second, it is a fusional language with a relatively free word order in contrast to the isolated English with a relatively fixed word order.",1.4 Motivation and organisation of the paper,[0],[0]
"If some heuristics is tested on e.g. Polish, the evaluation results can be approximately generalised to other Slavic languages.",1.4 Motivation and organisation of the paper,[0],[0]
"We hope the Slavic NLP community will be interested in designing and evaluating methods of semantic modelling for Slavic languages.
",1.4 Motivation and organisation of the paper,[0],[0]
The procedure of building an evaluation dataset for validating compositional distributional semantics models of Polish generally builds on steps designed to assemble the SICK corpus (described in Section 1.3) because we aim at building an evaluation dataset which is comparable to the SICK corpus.,1.4 Motivation and organisation of the paper,[0],[0]
"However, the implementation of particular building steps significantly differs from the original SICK design assumptions, which is caused by both lack of necessary extraneous resources for Polish (see Section 2.1) and the need for Polish-specific transformation rules (see Section 2.2).",1.4 Motivation and organisation of the paper,[0],[0]
"Furthermore, the rules of arranging sentences into pairs (see Section 2.3) are defined anew taking into account the characteristic of data and bidirectional entailment annotations, since an entailment relation between two sentences must not be symmetric.",1.4 Motivation and organisation of the paper,[0],[0]
"Even if our assumptions of annotating sentence pairs coincide with the SICK principles to a certain extent (see Section 3.1), the annotation process differs from the SICK procedure, in particular by introducing an element of human verification of correctness of automatically transformed sentences (see Section 3.2) and some additional post-corrections (see Section 3.3).",1.4 Motivation and organisation of the paper,[0],[0]
"Finally, a summary of the dataset is provided in Section 4.1 and the dataset evaluation is given in Section 4.2.",1.4 Motivation and organisation of the paper,[0],[0]
"The first step of building the SICK corpus consisted in the random selection of English sentence pairs from existing datasets (Rashtchian et al., 2010; Agirre et al., 2012).",2.1 Selection and description of images,[0],[0]
"Since we are not aware of accessibility of analogous resources for Polish, we have to select images first and then describe the selected images.
",2.1 Selection and description of images,[0],[0]
"Images are selected from the 8K ImageFlickr
dataset (Rashtchian et al., 2010).",2.1 Selection and description of images,[0],[0]
At first we wanted to take only these images the descriptions of which were selected for the SICK corpus.,2.1 Selection and description of images,[0],[0]
"However, a cursory check shows that these images are quite homogeneous, with a predominant number of dogs depictions.",2.1 Selection and description of images,[0],[0]
"Therefore, we independently extract 1K images and split them into 46 thematic groups (e.g. children, musical instruments, motorbikes, football, dogs).",2.1 Selection and description of images,[0],[0]
The numbers of images within individual thematic groups vary from 6 images in the volleyball and telephoning groups to 94 images in the various people group.,2.1 Selection and description of images,[0],[0]
"The second largest groups are children and dogs with 50 images each.
",2.1 Selection and description of images,[0],[0]
The chosen images are given to two authors who independently of each other formulate their descriptions based on a short instruction.,2.1 Selection and description of images,[0],[0]
The authors are instructed to write one single sentence (with a sentence predicate) describing the action in a displayed image.,2.1 Selection and description of images,[0],[0]
They should not describe an imaginable context or an interpretation of what may lie behind the scene in the picture.,2.1 Selection and description of images,[0],[0]
"If some details in the picture are not obvious, they should not be described either.",2.1 Selection and description of images,[0],[0]
"Furthermore, the authors should avoid multiword expressions, such as idioms, metaphors, and named entities, because those are not compositional linguistic phenomena.",2.1 Selection and description of images,[0],[0]
"Finally, descriptions should contain Polish diacritics and proper punctuation.",2.1 Selection and description of images,[0],[0]
"The second step of building the SICK corpus consisted in pre-processing extracted sentences, i.e. normalisation and expansion (Bentivogli et al., 2014, p. 3–4).",2.2 Transformation of descriptions,[0],[0]
"Since the authors of Polish descriptions are asked to follow the guidelines (presented in Section 2.1), the normalisation step is not essential for our data.",2.2 Transformation of descriptions,[0],[0]
"The expansion step, in turn, is implemented and the sentences provided by the authors are lexically and syntactically transformed in order to obtain derivative sentences with similar, contrastive, or neutral meanings.",2.2 Transformation of descriptions,[0],[0]
"The following transformations are implemented:
1.",2.2 Transformation of descriptions,[0],[0]
"dropping conjunction concerns sentences with coordinated predicates sharing a subject, e.g. Rowerzysta odpoczywa i obserwuje morze.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
‘A cyclist is resting and watching the sea.’).,2.2 Transformation of descriptions,[0],[0]
"The finite form of one of the coordinated predicates is transformed into:
• an active adjectival participle, e.g. Odpoczywający rowerzysta obserwuje
morze.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
‘A resting cyclist is watching the sea.’) or Obserwujący morze rowerzysta odpoczywa.,2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
"‘A cyclist, who is watching the sea, is resting.’), • a contemporary adverbial participle,
e.g. Rowerzysta, odpoczywając, obserwuje morze.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
"‘A cyclist is watching the sea, while resting.’)",2.2 Transformation of descriptions,[0],[0]
"or Rowerzysta odpoczywa, obserwując morze.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
"‘A cyclist is resting, while watching the sea.’).
",2.2 Transformation of descriptions,[0],[0]
"2. removing conjunct in adjuncts, i.e. the deletion of one of coordinated elements of an adjunct, e.g. Mały, ale zwinny kot miauczy.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
‘A small but agile cat miaows.’) can be changed into either Mały kot miauczy.,2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
‘A small cat miaows.’) or Zwinny kot miauczy.,2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
"‘An agile cat miaows.’).
",2.2 Transformation of descriptions,[0],[0]
3.,2.2 Transformation of descriptions,[0],[0]
"passivisation, e.g. Człowiek ujeżdża byka.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
‘A man is breaking a bull in.’) can be transformed into Byk jest ujeżdżany przez człowieka.,2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
"‘A bull is being broken in by a man.’).
",2.2 Transformation of descriptions,[0],[0]
"4. removing adjuncts, e.g. Dwa białe króliki siedzą na trawie.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
‘Two small rabbits are sitting on the grass.’) can be changed into Króliki,2.2 Transformation of descriptions,[0],[0]
siedzą.,2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
"‘The rabbits are sitting.’).
",2.2 Transformation of descriptions,[0],[0]
"5. swapping relative clause for participles, i.e. a relative clause swaps with a participle (and vice versa), e.g. Kobieta przytula psa, którego trzyma na smyczy.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
‘A woman hugs a dog which she keeps on a leash.’).,2.2 Transformation of descriptions,[0],[0]
"The relative clause is interchanged for a participle construction, e.g. Kobieta przytula trzymanego na smyczy psa.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
"‘A woman hugs a dog kept on a leash.’).
6.",2.2 Transformation of descriptions,[0],[0]
"negation, e.g. Mężczyźni w turbanach na głowach siedzą na słoniach.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
‘Men in turbans on their heads are sitting on elephants.’) can be transformed into Nikt nie siedzi na słoniach.,2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
"‘Nobody is sitting on elephants.’), Żadni mężczyźni w turbanach na głowach nie siedzą na słoniach.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
"‘No men in turbans on their heads are sitting on elephants.’), and Mężczyźni w turbanach na głowach nie siedzą na słoniach.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
"‘Men in turbans on their heads are not sitting on elephants.’).
",2.2 Transformation of descriptions,[0],[0]
7.,2.2 Transformation of descriptions,[0],[0]
constrained mixing of dependents from various sentences,2.2 Transformation of descriptions,[0],[0]
", e.g. Dwoje dzieci siedzi na wielbłądach w pobliżu wysokich gór.",2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
‘Two children are sitting on camels near high mountains.’) can be changed into Dwoje dzieci siedzi przy zastawionym stole w pobliżu wysokich gór.,2.2 Transformation of descriptions,[0],[0]
(Eng.,2.2 Transformation of descriptions,[0],[0]
"‘Two children are sitting at the table laid with food near high mountains.’).
",2.2 Transformation of descriptions,[0],[0]
"The first five transformations are designed to produce sentences with a similar meaning, the sixth transformation outputs sentences with a contradictory meaning, and the seventh transformation should generate sentences with a neutral (or unrelated) meaning.",2.2 Transformation of descriptions,[0],[0]
"All transformations are performed on the dependency structures of input sentences (Wróblewska, 2014).
",2.2 Transformation of descriptions,[0],[0]
Some of the transformations are very productive (e.g. mixing dependents).,2.2 Transformation of descriptions,[0],[0]
"Other, in turn, are sparsely represented in the output (e.g. dropping conjunction).",2.2 Transformation of descriptions,[0],[0]
The number of transformed sentences randomly selected to build the dataset is in the second column of Table 1.,2.2 Transformation of descriptions,[0],[0]
The final step of building the SICK corpus consisted in arranging normalised and expanded sentences into pairs.,2.3 Data ensemble,[0],[0]
"Since our data diverges from SICK data, the process of arranging Polish sentences into pairs also differs from pairing in the SICK corpus.",2.3 Data ensemble,[0],[0]
The general idea behind the pair-ensembling procedure was to introduce sentence pairs with different levels of relatedness into the dataset.,2.3 Data ensemble,[0],[0]
"Apart from pairs connecting two sentences originally written by humans (as described in Section 2.1), there are also pairs in which an original sentence is connected with
a transformed sentence.",2.3 Data ensemble,[0],[0]
"For each of the 1K images, the following 10 pairs are constructed (for A being the set of all sentences originally written by the first author, B being the set of all sentences originally written by the second author, a ∈ A and b ∈ B being the original descriptions of the picture):
1.",2.3 Data ensemble,[0],[0]
"(a,b)
2.",2.3 Data ensemble,[0],[0]
"(a,a1), where a1 ∈ t(a), and t(a) is the set of all transformations of the sentence a
3.",2.3 Data ensemble,[0],[0]
"(b,b1), where b1 ∈ t(b)
4.",2.3 Data ensemble,[0],[0]
"(a,b2), where b2 ∈ t(b)
5.",2.3 Data ensemble,[0],[0]
"(b,a2), where a2 ∈ t(a)
6.",2.3 Data ensemble,[0],[0]
"(a,a3), where a3 ∈ t(a′),a′ ∈",2.3 Data ensemble,[0],[0]
"A, T (a′) = T (a),a′ 6= a, for T (a) being the thematic group3 of a
7.",2.3 Data ensemble,[0],[0]
"(b,b3), where b3 ∈ t(b′),b′ ∈ B, T (b′)",2.3 Data ensemble,[0],[0]
"= T (b),b′ 6= b
8.",2.3 Data ensemble,[0],[0]
"(a,a4), where a4 ∈ A, T (a4) 6=",2.3 Data ensemble,[0],[0]
"T (a)4
9.",2.3 Data ensemble,[0],[0]
"(b,b4), where b4 ∈ B, T (b4) 6=",2.3 Data ensemble,[0],[0]
"T (b)
10.",2.3 Data ensemble,[0],[0]
"(a,a5), where a5 ∈",2.3 Data ensemble,[0],[0]
"t(a),a5 6=",2.3 Data ensemble,[0],[0]
"a1 for 50% images, (b,b5) (analogously) for other 50%.5
For each sentence pair (a,b) created according to this procedure, its reverse (b,a) is also included in our corpus.",2.3 Data ensemble,[0],[0]
"As a result, the working set consists of 20K sentence pairs.",2.3 Data ensemble,[0],[0]
The degree of semantic relatedness between two sentences is calculated as the average of all human ratings on the Likert scale with the range from 0 to 5.,3.1 Annotation assumptions,[0],[0]
"Since we do not want to excessively influence
3The thematic group of a sentence a corresponds to the thematic group of an image being the source of a (as described in Section 2.1).
4The pairs (a,a4) of the same authors’ descriptions of two images from different thematic groups are expected to be unrelated.",3.1 Annotation assumptions,[0],[0]
"The same applies to (b,b4).
",3.1 Annotation assumptions,[0],[0]
5A repetition of point 2 with a restriction that a different pair is created (pairs of very related sentences are expected).,3.1 Annotation assumptions,[0],[0]
"We alternate between authors A and B to obtain equal author proportions in the final ensemble of pairs.
",3.1 Annotation assumptions,[0],[0]
"the annotations, the guidelines given to annotators are mainly example-based:6
• 5 (very related): Kot siedzi na płocie.",3.1 Annotation assumptions,[0],[0]
(Eng.,3.1 Annotation assumptions,[0],[0]
‘A cat is sitting on the fence.’),3.1 Annotation assumptions,[0],[0]
vs. Na płocie jest duży kot.,3.1 Annotation assumptions,[0],[0]
(Eng.,3.1 Annotation assumptions,[0],[0]
"‘There is a large cat on the fence.’),
• 1–4 (more or less related): Kot siedzi na płocie.",3.1 Annotation assumptions,[0],[0]
(Eng.,3.1 Annotation assumptions,[0],[0]
‘A cat is sitting on the fence.’),3.1 Annotation assumptions,[0],[0]
vs. Kot nie siedzi na płocie.,3.1 Annotation assumptions,[0],[0]
(Eng.,3.1 Annotation assumptions,[0],[0]
‘A cat is not sitting on the fence.’); Kot siedzi na płocie.,3.1 Annotation assumptions,[0],[0]
(Eng.,3.1 Annotation assumptions,[0],[0]
‘A cat is sitting on the fence.’),3.1 Annotation assumptions,[0],[0]
vs. Właściciel dał kotu chrupki.,3.1 Annotation assumptions,[0],[0]
(Eng.,3.1 Annotation assumptions,[0],[0]
‘The owner gave kibble to his cat.’),3.1 Annotation assumptions,[0],[0]
; Kot siedzi na płocie.,3.1 Annotation assumptions,[0],[0]
(Eng.,3.1 Annotation assumptions,[0],[0]
‘A cat is sitting on the fence.’),3.1 Annotation assumptions,[0],[0]
vs. Kot miauczy pod płotem.,3.1 Annotation assumptions,[0],[0]
(Eng.,3.1 Annotation assumptions,[0],[0]
"‘A cat miaows by the fence.’).
",3.1 Annotation assumptions,[0],[0]
• 0 (unrelated): Kot siedzi na płocie.,3.1 Annotation assumptions,[0],[0]
(Eng.,3.1 Annotation assumptions,[0],[0]
‘A cat is sitting on the fence.’),3.1 Annotation assumptions,[0],[0]
vs. Zaczął padać deszcz.,3.1 Annotation assumptions,[0],[0]
(Eng.,3.1 Annotation assumptions,[0],[0]
"‘It started to rain.’).
",3.1 Annotation assumptions,[0],[0]
"Apart from these examples, there is a note in the annotation guidelines indicating that the degree of semantic relatedness is not equivalent to the degree of semantic similarity.",3.1 Annotation assumptions,[0],[0]
"Semantic similarity is only a special case of semantic relatedness, semantic relatedness is thus a more general term than the other one.
",3.1 Annotation assumptions,[0],[0]
"Polish entailment labels correspond directly to the SICK labels (i.e. entailment, contradiction, neutral).",3.1 Annotation assumptions,[0],[0]
The entailment label assigned by the majority of human judges is selected as the gold label.,3.1 Annotation assumptions,[0],[0]
"The entailment labels are defined as follows:
• a wynika z b (b entails a) – if a situation or an event described by sentence b occurs, it is recognised that a situation or an event described by a occurs as well, i.e. a and b refer to the same event or the same situation,
• a jest zaprzeczeniem b (a is the negation of b) – if a situation or an event described by b occurs, it is recognised that a situation or an event described by a may not occur at the same time,
6We realise that the boundary between semantic perception of a sentence by various speakers is fuzzy (it depends on speakers’ education, origin, age, etc.).",3.1 Annotation assumptions,[0],[0]
"It was thus our wellthought-out decision to draw only general annotation frames and to enable annotators to rely on their feel for language.
",3.1 Annotation assumptions,[0],[0]
• a jest neutralne wobec b,3.1 Annotation assumptions,[0],[0]
(a is neutral to b) – the truth of a situation described by a cannot be determined on the basis of b.,3.1 Annotation assumptions,[0],[0]
"Similar to the SICK corpus, each Polish sentence pair is human-annotated for semantic relatedness and entailment by 3 human judges experienced in Polish linguistics.7 Since for each annotated pair (a,b), its reverse (b,a) is also subject to annotation, the entailment relation is in practice determined ‘in both directions’ for 10K sentence pairs.",3.2 Annotation procedure,[0],[0]
"For the task of relatedness annotation, the order of sentences within pairs seems to be irrelevant, we can thus assume to obtain 6 relatedness scores for 10K unique pairs.
",3.2 Annotation procedure,[0],[0]
"Since the transformation process is fully automatic and to a certain extent based on imperfect dependency parsing, we cannot ignore errors in the transformed sentences.",3.2 Annotation procedure,[0],[0]
"In order to avoid annotating erroneous sentences, the annotation process is divided into two stages:
1.",3.2 Annotation procedure,[0],[0]
"a sentence pair is sent to a judge with the leader role, who is expected to edit and to correct the transformed sentence from this pair before annotation, if necessary,
2.",3.2 Annotation procedure,[0],[0]
"the verified and possibly enhanced sentence pair is sent to the other two judges, who can only annotate it.
",3.2 Annotation procedure,[0],[0]
The leader judges should correct incomprehensible and ungrammatical sentences with a minimal number of necessary changes.,3.2 Annotation procedure,[0],[0]
Unusual sentences which could be accepted by Polish speakers should not be modified.,3.2 Annotation procedure,[0],[0]
"Moreover, the modified sentence may not be identical with the other sentence in the pair.",3.2 Annotation procedure,[0],[0]
"The classification and statistics of distinct corrections made by the leader judges are provided in Table 2.
",3.2 Annotation procedure,[0],[0]
A strict classification of error types is quite hard to provide because some sentences contain more than one error.,3.2 Annotation procedure,[0],[0]
We thus order the error types from the most serious errors (i.e. ‘sense’ errors) to the redundant corrections (i.e. ‘other’ type).,3.2 Annotation procedure,[0],[0]
"If a sentence contains several errors, it is qualified for the higher order error type.
",3.2 Annotation procedure,[0],[0]
"In the case of sentences with ‘sense’ errors, the need for correction is uncontroversial and
7Our annotators have relatively strong linguistic background.",3.2 Annotation procedure,[0],[0]
"Five of them have PhD in linguistics, five are PhD students, one is a graduate, and one is an undergraduate.
arises from an internal logical contradiction.8",3.2 Annotation procedure,[0],[0]
"The sentences with ‘semantic’ changes are syntactically correct, but deemed unacceptable by the leader annotators from the semantic or pragmatic point of view.9 The ‘grammatical’ errors mostly concern missing agreement.10 The majority of ‘word order’ corrections are unnecessary, but we found some examples which can be classified as actual word or phrase order errors.11 The correction of punctuation consists in adding or deleting a comma.12 The sentences in the ‘other’ group, in turn, could as well have been left unchanged because they are proper Polish sentences, but were apparently considered odd by the leader annotators.
",3.2 Annotation procedure,[0],[0]
8An example of ‘sense’ error: the sentence Chłopak w zielonej bluzie,3.2 Annotation procedure,[0],[0]
i czapce zjeżdża na rolkach na leżąco.,3.2 Annotation procedure,[0],[0]
(Eng.,3.2 Annotation procedure,[0],[0]
‘A boy in a green sweatshirt and a cap roller-skates downhill in a lying position.’) is corrected into Chłopak w zielonej bluzie,3.2 Annotation procedure,[0],[0]
i czapce zjeżdża na rolkach.,3.2 Annotation procedure,[0],[0]
(Eng.,3.2 Annotation procedure,[0],[0]
"‘A boy in a green sweatshirt and a cap roller-skates downhill.’).
",3.2 Annotation procedure,[0],[0]
9An example of ‘semantic’ correction: the sentence Dziewczyna trzyma w pysku patyk.,3.2 Annotation procedure,[0],[0]
(Eng.,3.2 Annotation procedure,[0],[0]
‘A girl holds a stick in her muzzle.’) is corrected into Dziewczyna trzyma w ustach patyk.,3.2 Annotation procedure,[0],[0]
(Eng.,3.2 Annotation procedure,[0],[0]
"‘A girl holds a stick in her mouth.’).
",3.2 Annotation procedure,[0],[0]
10An example of ‘grammatical’ error: the sentence Grupasg.nom uśmiechających się ludzi tańcząpl.,3.2 Annotation procedure,[0],[0]
(Eng.,3.2 Annotation procedure,[0],[0]
*‘A group of smiling people are dancing.’) is corrected into Grupasg.nom uśmiechających się ludzi tańczysg .,3.2 Annotation procedure,[0],[0]
(Eng.,3.2 Annotation procedure,[0],[0]
"‘A group of smiling people is dancing.’).
",3.2 Annotation procedure,[0],[0]
"11An example of word order error: the sentence Samochód, który jest uszkodzony, koloru białego stoi na lawecie dużego auta.",3.2 Annotation procedure,[0],[0]
(lit.,3.2 Annotation procedure,[0],[0]
"‘A car that is damaged, of the white color stands on the trailer of a large car.’, Eng.",3.2 Annotation procedure,[0],[0]
‘A white car that is damaged is standing on the trailer of a large car.’),3.2 Annotation procedure,[0],[0]
"is corrected into Samochód koloru białego, który jest uszkodzony, stoi na lawecie dużego auta.
12An example of punctuation correction: the wrong comma in the sentence Nad brzegiem wody, stoją dwaj mężczyźni z wędkami.",3.2 Annotation procedure,[0],[0]
(lit.,3.2 Annotation procedure,[0],[0]
"‘On the water’s edge, two men are standing with rods.’; Eng.",3.2 Annotation procedure,[0],[0]
"‘Two men with rods are standing on the water’s edge.’) should be deleted, i.e. Nad brzegiem wody stoją dwaj mężczyźni z wędkami.",3.2 Annotation procedure,[0],[0]
During the annotation process it came out that sentences accepted by some human annotators are unacceptable for other annotators.,3.3 Impromptu post-corrections,[0],[0]
We thus decided to garner annotators’ comments and suggestions for improving sentences.,3.3 Impromptu post-corrections,[0],[0]
"After validation of these suggestions by an experienced linguist, it turns out that most of these proposals concern punctuation errors (e.g. missing comma) and typos in 312 distinct sentences.",3.3 Impromptu post-corrections,[0],[0]
These errors are fixed directly in the corpus because they should not impact the annotations of sentence pairs.,3.3 Impromptu post-corrections,[0],[0]
The other suggestions concern more significant changes in 29 distinct sentences (mostly minor grammatical or semantic problems overlooked by the leader annotators).,3.3 Impromptu post-corrections,[0],[0]
The annotations of pairs with modified sentences are resent to the annotators so that they can verify and update them.,3.3 Impromptu post-corrections,[0],[0]
Tables 3 and 4 summarise the annotations of the resulting 10K sentence pairs corpus.,4.1 Corpus statistics,[0],[0]
"Table 3 aggregates the occurrences of 6 possible relatedness scores, calculated as the mean of all 6 individual annotations, rounded to an integer.
",4.1 Corpus statistics,[0],[0]
Table 4 shows the number of the particular entailment labels in the corpus.,4.1 Corpus statistics,[0],[0]
"Since each sentence pair is annotated for entailment in both directions, the final entailment label is actually a pair of two labels:
• entailment+neutral points to ‘one-way’ entailment,
• contradiction+neutral points to ‘one-way’ contradiction,
• entailment+entailment, contradiction+contradiction, and neutral+neutral point to equivalence.
",4.1 Corpus statistics,[0],[0]
"While the actual corpus labels are ordered in the sense that there is a difference between e.g. entailment+neutral and neutral+entailment (the entailment occurs in different directions), we treat all labels as unordered for the purpose of this summary (e.g. entailment+neutral covers neutral+entailment as well, representing the same type of relation between two sentences).",4.1 Corpus statistics,[0],[0]
"The standard measure of inter-annotator agreement in various natural language labelling tasks is Cohen’s kappa (Cohen, 1960).",4.2 Inter-annotator agreement,[0],[0]
"However, this coefficient is designed to measure agreement between two annotators only.",4.2 Inter-annotator agreement,[0],[0]
"Since there are three annotators of each pair of ordered sentences, we decided to apply Fleiss’ kappa13 (Fleiss, 1971) designed for measuring agreement between multiple raters who give categorical ratings to a fixed number of items.",4.2 Inter-annotator agreement,[0],[0]
"An additional advantage of this measure is that different items can be rated by different human judges, which doesn’t impact measurement.",4.2 Inter-annotator agreement,[0],[0]
"The normalised Fleiss’ measure of inter-annotator agreement is:
κ = P̄",4.2 Inter-annotator agreement,[0],[0]
"− P̄e 1− P̄e
where the quantity P̄ − P̄e measures the degree of agreement actually attained in excess of chance, while “[t]he quantity 1 − P̄e measures the degree of agreement attainable over and above what would be predicted by chance” (Fleiss, 1971, p. 379).
",4.2 Inter-annotator agreement,[0],[0]
We recognise Fleiss’ kappa as particularly useful for measuring inter-annotator agreement with respect to entailment labelling in our evaluation dataset.,4.2 Inter-annotator agreement,[0],[0]
"First, there are more than two raters.",4.2 Inter-annotator agreement,[0],[0]
"Second, entailment labels are categorically.",4.2 Inter-annotator agreement,[0],[0]
"Measured
13As Fleiss’ kappa is actually the generalisation of Scott’s π (Scott, 1955), it is sometimes referred to as Fleiss’ multi-π, cf.",4.2 Inter-annotator agreement,[0],[0]
"Artstein and Poesio (2008).
with Fleiss’ kappa, there is an inter-annotator agreement of κ = 0.734 for entailment labels in Polish evaluation dataset, which is quite satisfactory as for a semantic labelling task.
",4.2 Inter-annotator agreement,[0],[0]
"Relative to semantic relatedness, the distinction in meaning of two sentences made by human judges is often very subtle.",4.2 Inter-annotator agreement,[0],[0]
This is also reflected in the inter-annotator agreement scores measured with Fleiss’ kappa.,4.2 Inter-annotator agreement,[0],[0]
Inter-annotator agreement measured for six semantic relatedness groups corresponding to points on the Likert scale is quite low: κ = 0.337.,4.2 Inter-annotator agreement,[0],[0]
"If we measure interannotator agreement for three classes corresponding to the three relatedness groups from the annotation guidelines (see Section 3.1), i.e. <0>, <1, 2, 3, 4>, and <5>, the Fleiss’ score is significantly higher: κ = 0.543.",4.2 Inter-annotator agreement,[0],[0]
"Hence, we conclude that Fleiss’ kappa is not a reliable measure of inter-annotator agreement in relation to relatedness scores.",4.2 Inter-annotator agreement,[0],[0]
"Therefore, we decided to use Krippendorff’s α instead.
",4.2 Inter-annotator agreement,[0],[0]
"Krippendorff’s α (Krippendorff, 1980, 2013) is a coefficient appropriate for measuring the interannotator agreement of a dataset which is annotated with multiple judges and characterised by different magnitudes of disagreement and missing values.",4.2 Inter-annotator agreement,[0],[0]
"Krippendorff proposes distance metrics suitable for various scales: binary, nominal, interval, ordinal, and ratio.",4.2 Inter-annotator agreement,[0],[0]
"In ordinal measurement14 the attributes can be rank-ordered, but distances between them do not have any meaning.",4.2 Inter-annotator agreement,[0],[0]
"Measured with Krippendorff’s ordinal α, there is an inter-annotator agreement of α = 0.780 for relatedness scores in the Polish evaluation dataset, which is quite satisfactory as well.",4.2 Inter-annotator agreement,[0],[0]
"Hence, we conclude that our dataset is a reliable resource for the purpose of evaluating compositional distributional semantics model of Polish.",4.2 Inter-annotator agreement,[0],[0]
The goal of this paper is to present the procedure of building a Polish evaluation dataset for the validation of compositional distributional semantics models.,5 Conclusions,[0],[0]
"As we aim at building an evalua-
14Nominal measurement is useless for measuring agreement between relatedness scores (α = 0.340 is the identical value as Fleiss’ kappa, since all disagreements are considered equal).",5 Conclusions,[0],[0]
"We also test interval measurement, in which the distance between the attributes does have meaning and an average of an interval variable is computed.",5 Conclusions,[0],[0]
"The interval score measured for relatedness annotations is quite high α = 0.785, but we doubt whether the distance between relatedness scores is meaningful in this case.
tion dataset which is comparable to the SICK corpus, the general assumptions of our procedure correspond to the design principles of the SICK corpus.",5 Conclusions,[0],[0]
"However, the procedure of building the SICK corpus cannot be adapted without modifications.",5 Conclusions,[0],[0]
"First, the Polish seed-sentences have to be written based on the images which are selected from 8K ImageFlickr dataset and split into thematic groups, since usable datasets are not publicly available.",5 Conclusions,[0],[0]
"Second, since the process of transforming sentences seems to be language-specific, the linguistic transformation rules appropriate for Polish have to be defined from scratch.",5 Conclusions,[0],[0]
"Third, the process of arranging Polish sentences into pairs is defined anew taking into account the data characteristic and bidirectional entailment annotations.",5 Conclusions,[0],[0]
The discrepancies relative to the SICK procedure also concern the annotation process itself.,5 Conclusions,[0],[0]
"Since an entailment relation between two sentences must not be symmetric, each sentence pair is annotated for entailment in both directions.",5 Conclusions,[0],[0]
"Furthermore, we introduce an element of human verification of correctness of automatically transformed sentences and some additional post-corrections.
",5 Conclusions,[0],[0]
The presented procedure of building a dataset was tested on Polish.,5 Conclusions,[0],[0]
"However, it is very likely that the annotation framework will work for other Slavic languages (e.g. Czech with an excellent dependency parser).
",5 Conclusions,[0],[0]
"The presented procedure results in building the Polish test corpus of relatively high quality, confirmed by the inter-annotator agreement coefficients of κ = 0.734 (measured with Fleiss’ kappa) for entailment labels and of α = 0.780 (measured with Krippendorff’s ordinal alpha) for relatedness scores.",5 Conclusions,[0],[0]
"We would like to thank the reliable and tenacious annotators of our dataset: Alicja DziedzicRawska, Bożena Itoya, Magdalena Król, Anna Latusek, Justyna Małek, Małgorzata Michalik, Agnieszka Norwa, Małgorzata Szajbel-Keck, Alicja Walichnowska, Konrad Zieliński, and some other.",Acknowledgments,[0],[0]
The research presented in this paper was supported by SONATA 8 grant no 2014/15/D/HS2/03486 from the National Science Centre Poland.,Acknowledgments,[0],[0]
The paper presents a procedure of building an evaluation dataset1.,abstractText,[0],[0]
for the validation of compositional distributional semantics models estimated for languages other than English.,abstractText,[0],[0]
"The procedure generally builds on steps designed to assemble the SICK corpus, which contains pairs of English sentences annotated for semantic relatedness and entailment, because we aim at building a comparable dataset.",abstractText,[0],[0]
"However, the implementation of particular building steps significantly differs from the original SICK design assumptions, which is caused by both lack of necessary extraneous resources for an investigated language and the need for language-specific transformation rules.",abstractText,[0],[0]
"The designed procedure is verified on Polish, a fusional language with a relatively free word order, and contributes to building a Polish evaluation dataset.",abstractText,[0],[0]
The resource consists of 10K sentence pairs which are human-annotated for semantic relatedness and entailment.,abstractText,[0],[0]
The dataset may be used for the evaluation of compositional distributional semantics models of Polish.,abstractText,[0],[0]
Polish evaluation dataset for compositional distributional semantics models,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 667–672 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
667",text,[0],[0]
"The standard approach to multilingual NLP is to design a single architecture, but tune and train a separate model for each language.",1 Introduction,[0],[0]
"While this method allows for customizing the model to the particulars of each language and the available data, it also presents a problem when little data is available: extensive language-specific annotation is required.",1 Introduction,[0],[0]
"The reality is that most languages have very little annotated data for most NLP tasks.
",1 Introduction,[0],[0]
"Ammar et al. (2016a) found that using training data from multiple languages annotated with Universal Dependencies (Nivre et al., 2016), and represented using multilingual word vectors, outperformed monolingual training.",1 Introduction,[0],[0]
"Inspired by this, we apply the idea of training one model on multiple languages—which we call polyglot training— to PropBank-style semantic role labeling (SRL).",1 Introduction,[0],[0]
"We train several parsers for each language in the CoNLL 2009 dataset (Hajič et al., 2009): a tra-
I think Peter even made some deals with the gorillas .",1 Introduction,[0],[0]
O,1 Introduction,[0],[0]
O A0 AM-ADV O,1 Introduction,[0],[0]
"O A1 AM-ADV O O
Pero el suizo difícilmente atacará a Rominger en la montaña .",1 Introduction,[0],[0]
O,1 Introduction,[0],[0]
"O arg0-agt argM-adv O O arg1-pat argM-loc O O
Četrans oslovil sedm velkých evropských výrobců nákladních automobilů.",1 Introduction,[0],[0]
O O RSTR RSTR RSTR,1 Introduction,[0],[0]
"O O PAT
Figure 1:",1 Introduction,[0],[0]
"Example predicate-argument structures from English, Spanish, and Czech.",1 Introduction,[0],[0]
"Note that the argument labels are different in each language.
ditional monolingual version, and variants which additionally incorporate supervision from English portion of the dataset.",1 Introduction,[0],[0]
"To our knowledge, this is the first multilingual SRL approach to combine supervision from several languages.
",1 Introduction,[0],[0]
"The CoNLL 2009 dataset includes seven different languages, allowing study of trends across the same.",1 Introduction,[0],[0]
"Unlike the Universal Dependencies dataset, however, the semantic label spaces are entirely language-specific, making our task more challenging.",1 Introduction,[0],[0]
"Nonetheless, the success of polyglot training in this setting demonstrates that sharing of statistical strength across languages does not depend on explicit alignment in annotation conventions, and can be done simply through parameter sharing.",1 Introduction,[0],[0]
"We show that polyglot training can result in better labeling accuracy than a monolingual parser, especially for low-resource languages.",1 Introduction,[0],[0]
We find that even a simple combination of data is as effective as more complex kinds of polyglot training.,1 Introduction,[0],[0]
We include a breakdown into label categories of the differences between the monolingual and polyglot models.,1 Introduction,[0],[0]
Our findings indicate that polyglot training consistently improves label accuracy for common labels.,1 Introduction,[0],[0]
"We evaluate our system on the semantic role labeling portion of the CoNLL-2009 shared task (Hajič et al., 2009), on all seven languages, namely Catalan, Chinese, Czech, English, German, Japanese and Spanish.",2 Data,[0],[0]
"For each language, certain tokens in each sentence in the dataset are marked as predicates.",2 Data,[0],[0]
"Each predicate takes as arguments other words in the same sentence, their relationship marked by labeled dependency arcs.",2 Data,[0],[0]
"Sentences may contain no predicates.
",2 Data,[0],[0]
"Despite the consistency of this format, there are significant differences between the training sets across languages.1 English uses PropBank role labels (Palmer et al., 2005).",2 Data,[0],[0]
"Catalan, Chinese, English, German, and Spanish include (but are not limited to) labels such as “arg0-agt” (for “agent”) or “A0” that may correspond to some degree to each other and to the English roles.",2 Data,[0],[0]
"Catalan and Spanish share most labels (being drawn from the same source corpus, AnCora; Taulé et al., 2008), and English and German share some labels.",2 Data,[0],[0]
"Czech and Japanese each have their own distinct sets of argument labels, most of which do not have clear correspondences to English or to each other.
",2 Data,[0],[0]
"We also note that, due to semi-automatic projection of annotations to construct the German dataset, more than half of German sentences do not include labeled predicate and arguments.",2 Data,[0],[0]
"Thus while German has almost as many sentences as Czech, it has by far the fewest training examples (predicate-argument structures); see Table 1.
",2 Data,[0],[0]
"1This is expected, as the datasets were annotated independently under diverse formalisms and only later converted into CoNLL format (Hajič et al., 2009).",2 Data,[0],[0]
"Given a sentence with a marked predicate, the CoNLL 2009 shared task requires disambiguation of the sense of the predicate, and labeling all its dependent arguments.",3 Model,[0.9520800374579035],"['Since a referring expression describes its referents either implicitly or explicitly, the attributes expressed in it should match the attributes of its referent.']"
"The shared task assumed predicates have already been identified, hence we do not handle the predicate identification task.
",3 Model,[0],[0]
Our basic model adapts the span-based dependency SRL model of He et al. (2017).,3 Model,[0],[0]
This adaptation treats the dependent arguments as argument spans of length 1.,3 Model,[0],[0]
"Additionally, BIO consistency constraints are removed from the original model— each token is tagged simply with the argument label or an empty tag.",3 Model,[0],[0]
"A similar approach has also been proposed by Marcheggiani et al. (2017).
",3 Model,[0],[0]
The input to the model consists of a sequence of pretrained embeddings for the surface forms of the sentence tokens.,3 Model,[0],[0]
Each token embedding is also concatenated with a vector indicating whether the word is a predicate or not.,3 Model,[0],[0]
"Since the part-ofspeech tags in the CoNLL 2009 dataset are based on a different tagset for each language, we do not use these.",3 Model,[0],[0]
Each training instance consists of the annotations for a single predicate.,3 Model,[0],[0]
"These representations are then passed through a deep, multilayer bidirectional LSTM (Graves, 2013; Hochreiter and Schmidhuber, 1997) with highway connections (Srivastava et al., 2015).
",3 Model,[0],[0]
"We use the hidden representations produced by the deep biLSTM for both argument labeling and predicate sense disambiguation in a multitask setup; this is a modification to the models of He et al. (2017), who did not handle predicate senses, and of Marcheggiani et al. (2017), who used a separate model.",3 Model,[0],[0]
"These two predictions are made independently, with separate softmaxes over different last-layer parameters; we then combine the losses for each task when training.",3 Model,[0],[0]
"For predicate sense disambiguation, since the predicate has been identified, we choose from a small set of valid predicate senses as the tag for that token.",3 Model,[0],[0]
This set of possible senses is selected based on the training data: we map from lemmatized tokens to predicates and from predicates to the set of all senses of that predicate.,3 Model,[0],[0]
"Most predicates are only observed to have one or two corresponding senses, making the set of available senses at test time quite small (less than five senses/predicate on average across all languages).",3 Model,[0],[0]
"If a particular lemma was not observed in training, we heuristically predict it as the first sense of that predicate.",3 Model,[0],[0]
"For Czech and
Japanese, the predicate sense annotation is simply the lemmatized token of the predicate, giving a one-to-one predicate-“sense” mapping.
",3 Model,[0],[0]
"For argument labeling, every token in the sentence is assigned one of the argument labels, or NULL if the model predicts it is not an argument to the indicated predicate.",3 Model,[0],[0]
We use pretrained word embeddings as input to the model.,3.1 Monolingual Baseline,[0],[0]
"For each of the shared task languages, we produced GloVe vectors (Pennington et al., 2014) from the news, web, and Wikipedia text of the Leipzig Corpora Collection (Goldhahn et al., 2012).2 We trained 300-dimensional vectors, then reduced them to 100 dimensions with principal component analysis for efficiency.",3.1 Monolingual Baseline,[0],[0]
"In the first polyglot variant, we consider multilingual sharing between each language and English by using pretrained multilingual embeddings.",3.2 Simple Polyglot Sharing,[0],[0]
This polyglot model is trained on the union of annotations in the two languages.,3.2 Simple Polyglot Sharing,[0],[0]
"We use stratified sampling to give the two datasets equal effective weight in training, and we ensure that every training instance is seen at least once per epoch.
",3.2 Simple Polyglot Sharing,[0],[0]
Pretrained multilingual embeddings.,3.2 Simple Polyglot Sharing,[0],[0]
"The basis of our polyglot training is the use of pretrained multilingual word vectors, which allow representing entirely distinct vocabularies (such as the tokens of different languages) in a shared representation space, allowing crosslingual learning (Klementiev et al., 2012).",3.2 Simple Polyglot Sharing,[0],[0]
"We produced multilingual embeddings from the monolingual embeddings using the method of Ammar et al. (2016b): for each non-English language, a small crosslingual dictionary and canonical correlation analysis was used to find a transformation of the non-English vectors into the English vector space (Faruqui and Dyer, 2014).
",3.2 Simple Polyglot Sharing,[0],[0]
"Unlike multilingual word representations, argument label sets are disjoint between language pairs, and correspondences are not clearly defined.",3.2 Simple Polyglot Sharing,[0],[0]
"Hence, we use separate label representations for each language’s labels.",3.2 Simple Polyglot Sharing,[0],[0]
"Similarly, while (for example) ENG:look and SPA:mira may be semantically connected, the senses look.01 and
2For English we used the vectors provided on the GloVe website nlp.stanford.edu/projects/glove/.
mira.01 may not correspond.",3.2 Simple Polyglot Sharing,[0],[0]
"Hence, predicate sense representations are also language-specific.",3.2 Simple Polyglot Sharing,[0],[0]
"In the second variant, we concatenate a language ID vector to each multilingual word embedding and predicate indicator feature in the input representation.",3.3 Language Identification,[0],[0]
This vector is randomly initialized and updated in training.,3.3 Language Identification,[0],[0]
"These additional parameters provide a small degree of language-specificity in the model, while still sharing most parameters.",3.3 Language Identification,[0],[0]
This third variant takes inspiration from the “frustratingly easy” architecture of Daume III (2007) for domain adaptation.,3.4 Language-Specific LSTMs,[0],[0]
"In addition to processing every example with a shared biLSTM as in previous models, we add language-specific biLSTMs that are trained only on the examples belonging to one language.",3.4 Language-Specific LSTMs,[0],[0]
"Each of these languagespecific biLSTMs is two layers deep, and is combined with the shared biSLTM in the input to the third layer.",3.4 Language-Specific LSTMs,[0],[0]
This adds a greater degree of languagespecific processing while still sharing representations across languages.,3.4 Language-Specific LSTMs,[0],[0]
It also uses the language identification vector and multilingual word vectors in the input.,3.4 Language-Specific LSTMs,[0],[0]
We present our results in Table 2.,4 Experiments,[0],[0]
"We observe that simple polyglot training improves over monolingual training, with the exception of Czech, where we observe no change in performance.",4 Experiments,[0],[0]
"The languages with the fewest training examples (German, Japanese, Catalan) show the most improvement, while large-dataset languages such as Czech or Chinese see little or no improvement (Figure 2).
",4 Experiments,[0],[0]
"The language ID model performs inconsistently; it is better than the simple polyglot model in some cases, including Czech, but not in all.",4 Experiments,[0],[0]
"The language-specific LSTMs model performs best on a few languages, such as Catalan and Chinese, but worst on others.",4 Experiments,[0],[0]
"While these results may reflect differences between languages in the optimal amount of crosslingual sharing, we focus on the simple polyglot results in our analysis, which sufficiently demonstrate that polyglot training can improve performance over monolingual training.
",4 Experiments,[0],[0]
"We also report performance of state-of-the-art systems in each of these languages, all of which make explicit use of syntactic features, Marcheg-
giani et al. (2017) excepted.",4 Experiments,[0],[0]
"While this results in better performance on many languages, our model has the advantage of not relying on a syntactic parser, and is hence more applicable to languages with lower resources.",4 Experiments,[0],[0]
"However, the results suggest that syntactic information is critical for strong performance on German, which has the fewest predicates and thus the least semantic annotation for a semantics-only model to learn from.",4 Experiments,[0],[0]
"Nevertheless, our baseline is on par with the best published scores for Chinese, and it shows strong performance on most languages.
",4 Experiments,[0],[0]
Label-wise results.,4 Experiments,[0],[0]
"Table 3 gives the F1 scores for individual label categories in the Catalan and Spanish datasets, as an illustration of the larger trend.",4 Experiments,[0],[0]
"In both languages, we find a small but consistent improvement in the most common label categories (e.g., arg1 and argM ).",4 Experiments,[0],[0]
"Less common label categories are sensitive to small changes in performance; they have the largest changes in F1 in absolute value, but without a consistent direction.",4 Experiments,[0],[0]
"This could be attributed to the addition of English data, which improves learning of representations that are useful for the most common labels, but is essentially a random perturbation for the rarer ones.",4 Experiments,[0],[0]
"This pattern is seen across languages, and consistently results in overall gains from polyglot training.
",4 Experiments,[0],[0]
"One exception is in Czech, where polyglot training reduces accuracy on several common argument labels, e.g., PAT and LOC.",4 Experiments,[0],[0]
"While the effect sizes are small (consistent with other languages), the overall F1 score on Czech decreases slightly in the polyglot condition.",4 Experiments,[0],[0]
"It may be that the Czech dataset is too large to make use of the comparatively small amount of English data, or that differences in the annotation schemes prevent
effective crosslingual transfer.",4 Experiments,[0],[0]
Future work on language pairs that do not include English could provide further insights.,4 Experiments,[0],[0]
"Catalan and Spanish, for example, are closely related and use the same argument label set (both being drawn from the AnCora corpus) which would allow for sharing output representations as well as input tokens and parameters.
",4 Experiments,[0],[0]
Polyglot English results.,4 Experiments,[0],[0]
"For each language pair, we also evaluated the simple polyglot model on the English test set from the CoNLL 2009 shared task (Table 4).",4 Experiments,[0],[0]
"English SRL consistently benefits from polyglot training, with an increase of 0.25–0.7 absolute F1 points, depending on the language.",4 Experiments,[0],[0]
"Surprisingly, Czech provides the smallest improvement, despite the large amount of data added; the absence of crosslingual transfer in both directions for the English-Czech case, breaking the pattern seen in other languages, could therefore be due to differences in annotation rather than questions of dataset size.
",4 Experiments,[0],[0]
Labeled vs. unlabeled F1.,4 Experiments,[0],[0]
Table 5 provides unlabeled F1 scores for each language pair.,4 Experiments,[0],[0]
"As can be seen here, the unlabeled F1 improvements are generally positive but small, indicating that polyglot training can help both in structure prediction and labeling of arguments.",4 Experiments,[0],[0]
"The pattern of seeing the largest improvements on the languages with the smallest datasets generally holds here: the largest F1 gains are in German and Catalan, followed by Japanese, with minimal or no improvement elsewhere.",4 Experiments,[0],[0]
Recent improvements in multilingual SRL can be attributed to neural architectures.,5 Related Work,[0],[0]
"Swayamdipta et al. (2016) present a transition-based stack LSTM model that predicts syntax and semantics jointly, as a remedy to the reliance on pipelined models.",5 Related Work,[0],[0]
Guo et al. (2016) and Roth and Lapata (2016) use deep biLSTM architectures which use syntactic information to guide the composition.,5 Related Work,[0],[0]
"Marcheggiani et al. (2017) use a simple LSTM model over word tokens to tag semantic dependencies, like our model.",5 Related Work,[0],[0]
"Their model predicts a token’s label based on the combination of the token vector and the predicate vector, and saw benefits from using POS tags, both improvements that could be added to our model.",5 Related Work,[0],[0]
"Marcheggiani and Titov (2017) apply the recently-developed graph
convolutional networks to SRL, obtaining state of the art results on English and Chinese.",5 Related Work,[0],[0]
"All of these approaches are orthogonal to ours, and might benefit from polyglot training.
",5 Related Work,[0],[0]
Other polyglot models have been proposed for semantics.,5 Related Work,[0],[0]
Richardson et al. (2018) train on multiple (natural language)-(programming language) pairs to improve a model that translates API text into code signature representations.,5 Related Work,[0],[0]
"Duong et al. (2017) treat English and German semantic parsing as a multi-task learning problem and saw improvement over monolingual baselines, especially for small datasets.",5 Related Work,[0],[0]
"Most relevant to our work is Johannsen et al. (2015), which trains a polyglot
model for frame-semantic parsing.",5 Related Work,[0],[0]
"In addition to sharing features with multilingual word vectors, they use them to find word translations of target language words for additional lexical features.",5 Related Work,[0],[0]
"In this work, we have explored a straightforward method for polyglot training in SRL: use multilingual word vectors and combine training data across languages.",6 Conclusion,[0],[0]
"This allows sharing without crosslingual alignments, shared annotation, or parallel data.",6 Conclusion,[0],[0]
"We demonstrate that a polyglot model can outperform a monolingual one for semantic analysis, particularly for languages with less data.",6 Conclusion,[0],[0]
"We thank Luke Zettlemoyer, Luheng He, and the anonymous reviewers for helpful comments and feedback.",Acknowledgments,[0],[0]
This research was supported in part by the Defense Advanced Research Projects Agency (DARPA) Information Innovation Office (I2O) under the Low Resource Languages for Emergent Incidents (LORELEI) program issued by DARPA/I2O under contract HR001115C0113 to BBN.,Acknowledgments,[0],[0]
Views expressed are those of the authors alone.,Acknowledgments,[0],[0]
"Previous approaches to multilingual semantic dependency parsing treat languages independently, without exploiting the similarities between semantic structures across languages.",abstractText,[0],[0]
"We experiment with a new approach where we combine resources from a pair of languages in the CoNLL 2009 shared task (Hajič et al., 2009) to build a polyglot semantic role labeler.",abstractText,[0],[0]
"Notwithstanding the absence of parallel data, and the dissimilarity in annotations between languages, our approach results in an improvement in SRL performance on multiple languages over a monolingual baseline.",abstractText,[0],[0]
Analysis of the polyglot model shows it to be advantageous in lower-resource settings.,abstractText,[0],[0]
Polyglot Semantic Role Labeling,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2183–2192, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
Language resources that systematically organize paraphrases for binary relations are of great value for various NLP tasks and have recently been advanced in projects like PATTY, WiseNet and DEFIE. This paper presents a new method for building such a resource and the resource itself, called POLY. Starting with a very large collection of multilingual sentences parsed into triples of phrases, our method clusters relational phrases using probabilistic measures. We judiciously leverage fine-grained semantic typing of relational arguments for identifying synonymous phrases. The evaluation of POLY shows significant improvements in precision and recall over the prior works on PATTY and DEFIE. An extrinsic use case demonstrates the benefits of POLY for question answering.",text,[0],[0]
Motivation.,1 Introduction,[0],[0]
Information extraction from text typically yields relational triples: a binary relation along with its two arguments.,1 Introduction,[0],[0]
"Often the relation is expressed by a verb phrase, and the two arguments are named entities.",1 Introduction,[0],[0]
We refer to the surface form of the relation in a triple as a relational phrase.,1 Introduction,[0],[0]
"Repositories of relational phrases are an asset for a variety of tasks, including information extraction, textual entailment, and question answering.
",1 Introduction,[0],[0]
This paper presents a new method for systematically organizing a large set of such phrases.,1 Introduction,[0],[0]
"We aim to construct equivalence classes of synonymous phrases, analogously to how WordNet organizes
unary predicates as noun-centric synsets (aka. semantic types).",1 Introduction,[0],[0]
"For example, the following relational phrases should be in the same equivalence class: sings in, is vocalist in, voice in denoting a relation between a musician and a song.
",1 Introduction,[0],[0]
State of the Art and its Limitations.,1 Introduction,[0],[0]
"Starting with the seminal work on DIRT (Lin and Pantel, 2001), there have been various attempts on building comprehensive resources for relational phrases.",1 Introduction,[0],[0]
"Recent works include PATTY (Nakashole et al., 2012), WiseNet (Moro and Navigli, 2012) and DEFIE (Bovi et al., 2015).",1 Introduction,[0],[0]
Out of these DEFIE is the cleanest resource.,1 Introduction,[0],[0]
"However, the equivalence classes tend to be small, prioritizing precision over recall.",1 Introduction,[0],[0]
"On the other hand, PPDB (Ganitkevitch et al., 2013) offers the largest repository of paraphrases.",1 Introduction,[0],[0]
"However, the paraphrases are not relation-centric and they are not semantically typed.",1 Introduction,[0],[0]
"So it misses out on the opportunity of using types to distinguish identical phrases with different semantics, for example, performance in with argument types musician and song versus performance in with types athlete and competition.
",1 Introduction,[0],[0]
Our Approach.,1 Introduction,[0],[0]
"We start with a large collection of relational triples, obtained by shallow information extraction.",1 Introduction,[0],[0]
"Specifically, we use the collection of Faruqui and Kumar (2015), obtained by combining the OLLIE tool with Google Translate and projecting multilingual sentences back to English.",1 Introduction,[0],[0]
"Note that the task addressed in that work is relational triple extraction, which is orthogonal to our problem of organizing the relational phrases in these triples into synonymy sets.
",1 Introduction,[0],[0]
"We canonicalize the subject and object arguments
2183
of triples by applying named entity disambiguation and word sense disambiguation wherever possible.",1 Introduction,[0],[0]
"Using a knowledge base of entity types, we can then infer prevalent type signatures for relational phrases.",1 Introduction,[0],[0]
"Finally, based on a suite of judiciously devised probabilistic distance measures, we cluster phrases in a type-compatible way using a graph-cut technique.",1 Introduction,[0],[0]
The resulting repository contains ca.,1 Introduction,[0],[0]
"1 Million relational phrases, organized into ca.",1 Introduction,[0],[0]
"160,000 clusters.
",1 Introduction,[0],[0]
Contribution.,1 Introduction,[0],[0]
"Our salient contributions are: i) a novel method for constructing a large repository of relational phrases, based on judicious clustering and type filtering; ii) a new linguistic resource, coined POLY, of relational phrases with semantic typing, organized in equivalence classes; iii) an intrinsic evaluation of POLY, demonstrating its high quality in comparison to PATTY and DEFIE; iv) an extrinsic evaluation of POLY, demonstrating its benefits for question answering.",1 Introduction,[0],[0]
The POLY resource is publicly available 1.,1 Introduction,[0],[0]
Our approach consists of two stages: relational phrase typing and relational phrase clustering.,2 Method Overview,[0],[0]
"In Section 3, we explain how we infer semantic types of the arguments of a relational phrase.",2 Method Overview,[0],[0]
"In Section 4, we present the model for computing synonyms of relational phrases (i.e., paraphrases) and organizing them into clusters.
",2 Method Overview,[0],[0]
A major asset for our approach is a large corpus of multilingual sentences from the work of Faruqui and Kumar (2015).,2 Method Overview,[0],[0]
That dataset contains sentences from Wikipedia articles in many languages.,2 Method Overview,[0],[0]
"Each sentence has been processed by an Open Information Extraction method (Banko et al., 2007), specifically the OLLIE tool (Mausam et al., 2012), which produces a triple of surface phrases that correspond to a relational phrase candidate and its two arguments (subject and object).",2 Method Overview,[0],[0]
"Each non-English sentence has been translated into English using Google Translate, thus leveraging the rich statistics that Google has obtained from all kinds of parallel multilingual texts.",2 Method Overview,[0],[0]
"Altogether, the data from Faruqui and Kumar (2015) provides 135 million triples in 61 languages and in English (from the translations of the corresponding sentences).",2 Method Overview,[0],[0]
"This is the noisy input to our
1www.mpi-inf.mpg.de/yago-naga/poly/
method.",2 Method Overview,[0],[0]
"Figure 1 shows two Spanish sentences, the extracted triples of Spanish phrases, the sentences’ translations to English, and the extracted triples of English phrases.
",2 Method Overview,[0],[0]
"The figure shows that identical phrases in the foreign language - “fue filmado por” - may be translated into different English phrases: “was shot by” vs. “was filmed by”, depending on the context in the respective sentences.",2 Method Overview,[0],[0]
This is the main insight that our method builds on.,2 Method Overview,[0],[0]
The two resulting English phrases have a certain likelihood of being paraphrases of the same relation.,2 Method Overview,[0],[0]
"However, this is an uncertain hypotheses only, given the ambiguity of language, the noise induced by machine translation and the potential errors of the triple extraction.",2 Method Overview,[0],[0]
"Therefore, our method needs to de-noise these input phrases and quantify to what extent the the relational phrases are indeed synonymous.",2 Method Overview,[0],[0]
We discuss this in Sections 3 and 4.,2 Method Overview,[0],[0]
This section explains how we assign semantic types to relational phrases.,3 Relation Typing,[0],[0]
"For example, the relational phrase wrote could be typed as <author> wrote <paper>, as one candidate.",3 Relation Typing,[0],[0]
The typing helps us to disambiguate the meaning of the relational phrase and later find correct synonyms.,3 Relation Typing,[0],[0]
The relational phrase shot could have synonyms directed or killed with a gun.,3 Relation Typing,[0],[0]
"However, they represent different senses of the phrase shot.",3 Relation Typing,[0],[0]
"With semantic typing, we can separate these two meanings and determine that <person> shot <person> is a synonym of <person> killed with a gun <person>, whereas <director> shot<movie> is a synonym of<director> directed <movie>.
",3 Relation Typing,[0],[0]
"Relation typing has the following steps: argument extraction, argument disambiguation, argument typing and type filtering.",3 Relation Typing,[0],[0]
The output is a set of candidate types for the left and right arguments of each English relational phrase.,3 Relation Typing,[0],[0]
"For the typing of a relational phrase, we have to determine words in the left and right arguments that give cues for semantic types.",3.1 Argument Extraction,[0],[0]
"To this end, we identify named entities, whose types can be looked up in a knowledge base, and the head words of common
noun phrases.",3.1 Argument Extraction,[0],[0]
"As output, we produce a ranked list of entity mentions and common nouns.
",3.1 Argument Extraction,[0],[0]
"To create this ranking, we perform POS tagging and noun phrase chunking using Stanford CoreNLP",3.1 Argument Extraction,[0],[0]
"(Manning et al., 2014) and Apache OpenNLP 2.",3.1 Argument Extraction,[0],[0]
"For head noun extraction, we use the YAGO Javatools3 and a set of manually crafted regular expressions.",3.1 Argument Extraction,[0],[0]
"Since the input sentences result from machine translation, we could not use dependency parsing, because sentences are often ungrammatical.
",3.1 Argument Extraction,[0],[0]
"Finally, we extract all noun phrases which contain the same head noun.",3.1 Argument Extraction,[0],[0]
"These noun phrases are then sorted according to their lengths.
",3.1 Argument Extraction,[0],[0]
"For example, for input phrase contemporary British director who also created “Inception”, our method would yield contemporary British director, British director, director in decreasing order.",3.1 Argument Extraction,[0],[0]
The second step is responsible for the disambiguation of the noun phrase and named entity candidates.,3.2 Argument Disambiguation,[0],[0]
"We use the YAGO3 knowledge base (Mahdisoltani et al., 2015) for named entities, and WordNet (Fellbaum, 1998) for noun phrases.",3.2 Argument Disambiguation,[0],[0]
"We proceed in the ranking order of the phrases from the first step.
",3.2 Argument Disambiguation,[0],[0]
"Candidate senses are looked up in YAGO3 and WordNet, respectively, and each candidate is scored.",3.2 Argument Disambiguation,[0],[0]
"The scores are based on:
• Frequency count prior: This is the number of Wikipedia incoming links for named entities in YAGO3, or the frequency count of noun phrase senses in WordNet.
",3.2 Argument Disambiguation,[0],[0]
"• Wikipedia prior: We increase scores of YAGO3 entities whose URL strings (i.e., Wikipedia titles) occur in the Wikipedia page from which the triple was extracted.
",3.2 Argument Disambiguation,[0],[0]
"2opennlp.apache.org/ 3mpi-inf.mpg.de/yago-naga/javatools/
•",3.2 Argument Disambiguation,[0],[0]
Translation prior: We boost the scores of senses whose translations occur in the original input sentence.,3.2 Argument Disambiguation,[0],[0]
"For example, the word stage is disambiguated as opera stage rather than phase, because the original German sentence contains the word Bühne",3.2 Argument Disambiguation,[0],[0]
(German word for a concert stage) and not Phase.,3.2 Argument Disambiguation,[0],[0]
"The translations of word senses are obtained from Universal WordNet (de Melo and Weikum, 2009).
",3.2 Argument Disambiguation,[0],[0]
We prefer WordNet noun phrases over YAGO3 named entities since noun phrases have lower type ambiguity (fewer possible types).,3.2 Argument Disambiguation,[0],[0]
"The final score of a sense s is:
score(s) = αfreq(s)+βwiki(s)+γtrans(s) (1)
where freq(s) is the frequency count of s, and wiki(s) and trans(s) equal maximal frequency count if the Wikipedia prior and Translation prior conditions hold (and otherwise set to 0).",3.2 Argument Disambiguation,[0],[0]
"α, β, γ are tunable hyper-parameters (set using withheld data).
",3.2 Argument Disambiguation,[0],[0]
"Finally, from the list of candidates, we generate a disambiguated argument: either a WordNet synset or a YAGO3 entity identifier.",3.2 Argument Disambiguation,[0],[0]
"In the third step of relation typing, we assign candidate types to the disambiguated arguments.",3.3 Argument Typing,[0],[0]
"To this end, we query YAGO3 for semantic types (incl. transitive hypernyms) for a given YAGO3 or WordNet identifier.
",3.3 Argument Typing,[0],[0]
The type system used in POLY consists of a subset of the WordNet noun hierarchy.,3.3 Argument Typing,[0],[0]
"We restrict ourselves to 734 types, chosen semi-automatically as follows.",3.3 Argument Typing,[0],[0]
We selected the 1000 most frequent WordNet types in YAGO3 (incl. transitive hypernyms).,3.3 Argument Typing,[0],[0]
"Redundant and non-informative types were filtered out by the following technique: all types were organized into a directed acyclic graph (DAG), and
we removed a type when the frequency count of some of its children was higher than 80% of the parent’s count.",3.3 Argument Typing,[0],[0]
"For example, we removed type trainer since more than 80% of trainers in YAGO3 are also coaches.",3.3 Argument Typing,[0],[0]
"In addition, we manually removed a few non-informative types (e.g. expressive style).
",3.3 Argument Typing,[0],[0]
"As output, we obtain lists of semantic types for the two arguments of each relational phrase.",3.3 Argument Typing,[0],[0]
"In the last step, we filter types one more time.",3.4 Type Filtering,[0],[0]
"This time we filter candidate types separately for each distinct relational phrase, in order to choose the most suitable specific type signature for each phrase.",3.4 Type Filtering,[0],[0]
"This choice is made by type tree pruning.
",3.4 Type Filtering,[0],[0]
"For each relational phrase, we aggregate all types of the left arguments and all types of the right arguments, summing up their their frequency counts.",3.4 Type Filtering,[0],[0]
"This information is organized into a DAG, based on type hypernymy.",3.4 Type Filtering,[0],[0]
"Then we prune types as follows (similarly to Section 3.3): i) remove a parent type when the relative frequency count of one of the children types is larger than 80% of the parent’s count; ii) remove a child type when its relative frequency count is smaller than 20% of the parent’s count.
",3.4 Type Filtering,[0],[0]
For each of the two arguments of the relational phrase we allow only those types which are left after the pruning.,3.4 Type Filtering,[0],[0]
"The final output is a set of relational phrases where each has a set of likely type signatures (i.e., pairs of types for the relation’s arguments).",3.4 Type Filtering,[0],[0]
The second stage of POLY addresses the relation clustering.,4 Relation Clustering,[0],[0]
"The algorithm takes semantically typed relational phrases as input, quantifies the semantic similarity between relational phrases, and organizes them into clusters of synonyms.",4 Relation Clustering,[0],[0]
The key insight that our approach hinges on is that synonymous phrases have similar translations in a different language.,4 Relation Clustering,[0],[0]
"In our setting, two English phrases are semantically similar if they were translated from the same relational phrases in a foreign language and their argument types agree (see Figure 1 for an example).",4 Relation Clustering,[0],[0]
Similarities between English phrases are cast into edge weights of a graph with phrases as nodes.,4 Relation Clustering,[0],[0]
This graph is then partitioned to obtain clusters.,4 Relation Clustering,[0],[0]
The phrase similarities in POLY are based on probabilistic measures.,4.1 Probabilistic Similarity Measures,[0],[0]
"We use the notation:
• F : a set of relational phrases from a foreign language F
• E: a set of translations of relational phrases from language F to English
• c(f, e): no. of times of translating relational phrase f ∈ F into relational phrase e ∈ E
• c(f), c(e): frequency counts for relational phrase f ∈ F and its translation e ∈ E
• p(e|f) = c(f,e)c(f) : (estimator for the) probability of translating f ∈ F into e ∈ E
• p(f |e) = c(f,e)c(e) : (estimator for the) probability of e ∈ E being a translation of f ∈ F
We define:
p(e1|e2) = ∑
f
p(e1|f) ∗ p(f |e2) (2)
as the probability of generating relational phrase e1 ∈ E from phrase e2 ∈",4.1 Probabilistic Similarity Measures,[0],[0]
"E. Finally we define:
support(e1, e2) =",4.1 Probabilistic Similarity Measures,[0],[0]
"∑
f∈F c(f, e1) ∗",4.1 Probabilistic Similarity Measures,[0],[0]
"c(f, e2) (3)
confidence(e1, e2)",4.1 Probabilistic Similarity Measures,[0],[0]
"= 2
1 p(e1|e2) + 1 p(e2|e1)
(4)
",4.1 Probabilistic Similarity Measures,[0],[0]
Confidence is the final similarity measure used in POLY.,4.1 Probabilistic Similarity Measures,[0],[0]
We use the harmonic mean in Equation 4 to dampen similarity scores that have big differences in their probabilities in Equation 2.,4.1 Probabilistic Similarity Measures,[0],[0]
"Typically, pairs e1, e2 with such wide gaps in their probabilities come from subsumptions, not synonymous phrases.",4.1 Probabilistic Similarity Measures,[0],[0]
"Finally, we compute the support and confidence for every pair of English relational phrases which have a common source phrase of translation.",4.1 Probabilistic Similarity Measures,[0],[0]
"We prune phrase pairs with low support (below a threshold), and rank the remaining pairs by confidence.",4.1 Probabilistic Similarity Measures,[0],[0]
"To compute clusters of relational phrases, we use modularity-based graph partitioning.",4.2 Graph Clustering,[0],[0]
"Specifically, we use the partitioning algorithm of Blondel et al. (2008).",4.2 Graph Clustering,[0],[0]
"The resulting clusters (i.e., subgraphs) are
then ranked by their weighted graph density multiplied by the graph size (Equation 5).",4.2 Graph Clustering,[0],[0]
"The example of a cluster is shown in Table 1.
∑ (ei,ej)∈E sim(ei, ej)
|V",4.2 Graph Clustering,[0],[0]
| ∗ |V,4.2 Graph Clustering,[0],[0]
− 1| ∗ |V,4.2 Graph Clustering,[0],[0]
| (5),4.2 Graph Clustering,[0],[0]
"For the experimental evaluation, we primarily chose triples from the German language (and their English translations).",5 Evaluation,[0],[0]
"With about 23 million triples, German is the language with the largest number of extractions in the dataset, and there are about 2.5 million distinct relational phrases from the German-toEnglish translation.",5 Evaluation,[0],[0]
"The POLY method is implemented using Apache Spark, so it scales out to handle such large inputs.
",5 Evaluation,[0],[0]
"After applying the relation typing algorithm, we obtain around 10 million typed relational phrases.",5 Evaluation,[0],[0]
"If we ignored the semantic types, we would have about 950,000 distinct phrases.",5 Evaluation,[0],[0]
"On this input data, POLY detected 1,401,599 pairs of synonyms.",5 Evaluation,[0],[0]
"The synonyms were organized into 158,725 clusters.
",5 Evaluation,[0],[0]
"In the following, we present both an intrinsic evaluation and an extrinsic use case.",5 Evaluation,[0],[0]
"For the intrinsic evaluation, we asked human annotators to judge whether two typed relational phrases are synonymous or not.",5 Evaluation,[0],[0]
We also studied source languages other than German.,5 Evaluation,[0],[0]
"In addition, we compared POLY against PATTY (Nakashole et al., 2012) and DEFIE (Bovi et al., 2015) on the relation paraphrasing task.",5 Evaluation,[0],[0]
"For the extrinsic evaluation, we considered a simple question answering system and studied to what extent similarities between typed relational phrases can contribute to answering more questions.",5 Evaluation,[0],[0]
"To assess the precision of the discovered synonymy among relational phrases (i.e., clusters of para-
phrases), we sampled POLY’s output.",5.1 Precision of Synonyms,[0],[0]
We assessed the 250 pairs of synonyms with the highest similarity scores.,5.1 Precision of Synonyms,[0],[0]
"We also assessed a sample of 250 pairs of synonyms, randomly drawn from POLY’s output.
",5.1 Precision of Synonyms,[0],[0]
These pairs of synonyms were shown to several human annotators to check their correctness.,5.1 Precision of Synonyms,[0],[0]
"Relational phrases were presented by showing the semantic types, the textual representation of the relational phrase and sample sentences where the phrase was found.",5.1 Precision of Synonyms,[0],[0]
The annotators were asked whether two relational phrases have the same meaning or not.,5.1 Precision of Synonyms,[0],[0]
"They could also abstain.
",5.1 Precision of Synonyms,[0],[0]
"The results of this evaluation are shown in Table 2 with (lower bounds and upper bounds of) the 0.95-confidence Wilson score intervals (Brown et al., 2001).",5.1 Precision of Synonyms,[0],[0]
"This evaluation task had good interannotator agreement, with Fleiss’ Kappa around 0.6.",5.1 Precision of Synonyms,[0],[0]
"Table 3 shows anecdotal examples of synonymous pairs of relational phrases.
",5.1 Precision of Synonyms,[0],[0]
These results show that POLY’s quality is comparable with state-of-the-art baselines resources.,5.1 Precision of Synonyms,[0],[0]
"WiseNet (Moro and Navigli, 2012) is reported to have precision of 0.85 for 30,000 clusters.",5.1 Precision of Synonyms,[0],[0]
This is also the only prior work where the precision of synonymy of semantically typed relational phrases was evaluated.,5.1 Precision of Synonyms,[0],[0]
The other systems did not report that measure.,5.1 Precision of Synonyms,[0],[0]
"However, they performed the evaluation of subsumption, entailment or hypernymy relationships which are related to synonymy.",5.1 Precision of Synonyms,[0],[0]
Subsumptions in PATTY have precision of 0.83 for top 100 and 0.75 for a random sample.,5.1 Precision of Synonyms,[0],[0]
Hypernyms in RELLY are reported to have precision of 0.87 for top 100 and 0.78 for a random sample.,5.1 Precision of Synonyms,[0],[0]
"DEFIE performed separate evaluations for hypernyms generated directly from WordNet (precision 0.87) and hypernyms obtained through a substring generalization algorithm (precision 0.9).
",5.1 Precision of Synonyms,[0],[0]
Typical errors in the paraphrase discovery of POLY come from incorrect translations or extraction errors.,5.1 Precision of Synonyms,[0],[0]
"For example, heard and belongs to were clustered together because they were translated from the
same semantically ambiguous German word gehört.",5.1 Precision of Synonyms,[0],[0]
An example for extraction errors is that took and participated in were clustered together because took was incorrectly extracted from a sentence with the phrase took part in.,5.1 Precision of Synonyms,[0],[0]
"Other errors are caused by swapped order of arguments in a triple (i.e., mistakes in detecting passive form) and incorrect argument disambiguation.",5.1 Precision of Synonyms,[0],[0]
"To compare POLY with the closest competitors PATTY and DEFIE, we designed an experiment along the lines of the evaluation of Information Retrieval systems (e.g. TREC benchmarks).",5.2 Comparison to Competitors,[0],[0]
"First, we randomly chose 100 semantically typed relational phrases with at least three words (to focus on the more interesting multi-word case, rather than single verbs).",5.2 Comparison to Competitors,[0],[0]
These relational phrases had to occur in all three resources.,5.2 Comparison to Competitors,[0],[0]
"For every relational phrase we retrieved synonyms from all of the systems, forming a pool of candidates.",5.2 Comparison to Competitors,[0],[0]
"Next, to remove minor syntactic variations of the same phrase, the relational phrases were lemmatized.",5.2 Comparison to Competitors,[0],[0]
"In addition, we removed all leading prepositions, modal verbs, and adverbs.
",5.2 Comparison to Competitors,[0],[0]
We manually evaluated the correctness of the remaining paraphrase candidates for each of the 100 phrases.,5.2 Comparison to Competitors,[0],[0]
Precision was computed as the ratio of the correct synonyms by one system to the number of all synonyms provided by that system.,5.2 Comparison to Competitors,[0],[0]
"Recall was computed as the ratio of the number of correct synonyms by one system to the number of all correct synonyms in the candidate pool from all three systems.
",5.2 Comparison to Competitors,[0],[0]
The results are presented in Table 4.,5.2 Comparison to Competitors,[0],[0]
All results are macro-averaged over the 100 sampled phrases.,5.2 Comparison to Competitors,[0],[0]
We performed a paired t-test for precision and recall of POLY against each of the systems and obtained p-values below 0.05.,5.2 Comparison to Competitors,[0],[0]
"POLY and DEFIE of-
fer much higher diversity of synonyms than PATTY.",5.2 Comparison to Competitors,[0],[0]
"However, DEFIE’s synonyms often do not fit the semantic type signature of the given relational phrase and are thus incorrect.",5.2 Comparison to Competitors,[0],[0]
"For example, was assumed by was found to be a synonym of <group> was acquired by <group>.",5.2 Comparison to Competitors,[0],[0]
"PATTY, on the other hand, has higher recall due to its variety of prepositions attached to relational phrases; however, these also include spurious phrases, leading to lower precision.",5.2 Comparison to Competitors,[0],[0]
"For example, succeeded in was found to be a synonym of <person> was succeeded by <leader>.",5.2 Comparison to Competitors,[0],[0]
"Overall, POLY achieves much higher precision and recall than both of these baselines.",5.2 Comparison to Competitors,[0],[0]
"To evaluate the influence of different components, we performed an ablation study.",5.3 Ablation Study,[0],[0]
"We consider versions of POLY where Wikipedia prior and Translation prior (Section 3.2) are disregarded (− disambiguation), where the type system (Section 3.3) was limited to the 100 most frequent YAGO types (Type system 100) or to the 5 top-level types from the YAGO hierarchy (Type system 5), or where the type filtering parameter (Section 3.4) was set to 70% or 90% (Type filtering 0.7/0.9).",5.3 Ablation Study,[0],[0]
"The evaluation was done on random samples of 250 pairs of synonyms.
",5.3 Ablation Study,[0],[0]
Table 5 shows the results with the 0.95-confidence Wilson score intervals.,5.3 Ablation Study,[0],[0]
"Without our argument disambiguation techniques, the precision drops heavily.",5.3 Ablation Study,[0],[0]
"When weakening the type system, our tech-
niques for argument typing and type filtering are penalized, resulting in lower precision.",5.3 Ablation Study,[0],[0]
So we see that all components of the POLY architecture are essential for achieving high-quality output.,5.3 Ablation Study,[0],[0]
Lowering the type-filtering threshold yields results with comparable precision.,5.3 Ablation Study,[0],[0]
"However, increasing the threshold results in a worse noise filtering procedure.",5.3 Ablation Study,[0],[0]
"In addition to paraphrases derived from German, we evaluated the relational phrase synonymy derived from a few other languages with lower numbers of extractions.",5.4 Evaluation with Other Languages,[0],[0]
"We chose French, Hindi, and Russian (cf.",5.4 Evaluation with Other Languages,[0],[0]
"(Faruqui and Kumar, 2015)).",5.4 Evaluation with Other Languages,[0],[0]
"The results are presented in Table 6, again with the 0.95-confidence Wilson score intervals.
",5.4 Evaluation with Other Languages,[0],[0]
Synonyms derived from French have similar quality as those from German.,5.4 Evaluation with Other Languages,[0],[0]
This is plausible as one would assume that French and German have similar quality in translation to English.,5.4 Evaluation with Other Languages,[0],[0]
Synonyms derived from Russian and Hindi have lower precision due to the lower translation quality.,5.4 Evaluation with Other Languages,[0],[0]
"The precision for Hindi is lower, as the Hindi input corpus has much fewer sentences than for the other languages.",5.4 Evaluation with Other Languages,[0],[0]
"As an extrinsic use case for the POLY resource, we constructed a simple Question Answering (QA) system over knowledge graphs such as Freebase, and determined the number of questions for which the
system can find a correct answer.",5.5 Extrinsic Evaluation: Question Answering,[0.9518471200650246],"['However, these prior approaches have employed relatively simple semantic information from the referring expressions, such as a manually created lexicon, or have operated within an environment with a limited set of pre-defined objects.']"
We followed the approach presented by Fader et al. (2014).,5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"The system consists of question parsing, query rewriting and database look-up stages.",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"We disregard the stage of ranking answer candidates, and merely test whether the system could return the right answer (i.e., would return with the perfect ranking).
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"In the question parsing stage, we use 10 highprecision parsing operators by Fader et al. (2014), which map questions (e.g., Who invented papyrus?)",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"to knowledge graph queries (e.g., (?x, invented, papyrus)).",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"Additionally, we map question words to semantic types.",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"For example, the word who is mapped to person, where to location, when to abstract entity and the rest of the question words are mapped to type entity.
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
We harness synonyms and hyponyms of relational phrases to paraphrase the predicate of the query.,5.5 Extrinsic Evaluation: Question Answering,[0],[0]
The paraphrases must be compatible with the semantic type of the question word.,5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"In the end, we use the original query, as well as found paraphrases, to query a database of subject, predicate, object triples.",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"As the knowledge graph for this experiment we used the union of collections: a triples database from OpenIE (Fader et al., 2011), Freebase (Bollacker et al., 2008), Probase (Wu et al., 2012) and NELL (Carlson et al., 2010).",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"In total, this knowledge graph contained more than 900 Million triples.
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"We compared six systems for paraphrasing semantically typed relational phrases:
• Basic: no paraphrasing at all, merely using the originally generated query.
• DEFIE: using the taxonomy of relational phrases by Bovi et al. (2015).
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"• PATTY: using the taxonomy of relational phrases by Nakashole et al. (2012).
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"• RELLY: using the subset of the PATTY taxonomy with additional entailment relationships between phrases (Grycner et al., 2015).
• POLY DE: using synonyms of relational phrases derived from the German language.
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"• POLY ALL: using synonyms of relational phrases derived from the 61 languages.
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"Since DEFIE’s relational phrases are represented by BabelNet (Navigli and Ponzetto, 2012) word sense identifiers, we generated all possible lemmas for
each identifier.",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"We ran the paraphrase-enhanced QA system for three benchmark sets of questions:
• TREC: the set of questions used for the evaluation of information retrieval QA systems (Voorhees and Tice, 2000)
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"• WikiAnswers: a random subset of questions from WikiAnswers (Fader et al., 2013).
• WebQuestions: the set of questions about Freebase entities (Berant et al., 2013).
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"From these question sets, we kept only those questions which can be parsed by one of the 10 question parsing templates and have a correct answer in the gold-standard ground truth.",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"In total, we executed 451 questions for TREC, 516 for WikiAnswers and 1979 for WebQuestions.
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"For every question, each paraphrasing system generates a set of answers.",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
We measured for how many questions we could obtain at least one correct answer.,5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"Table 7 shows the results.
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
The best results were obtained by POLY ALL.,5.5 Extrinsic Evaluation: Question Answering,[0],[0]
We performed a paired t-test for the results of POLY DE and POLY ALL against all other systems.,5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"The differences between POLY ALL and the other systems are statistically significant with pvalue below 0.05.
",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"Additionally, we evaluated paraphrasing systems which consist of combination of all of the described datasets and all of the described datasets without POLY.",5.5 Extrinsic Evaluation: Question Answering,[0],[0]
The difference between these two versions suggest that POLY contains many paraphrases which are available in none of the competing resources.,5.5 Extrinsic Evaluation: Question Answering,[0],[0]
"Knowledge bases (KBs) contribute to many NLP tasks, including Word Sense Disambiguation (Moro et al., 2014), Named Entity Disambiguation (Hoffart et al., 2011), Question Answering (Fader et al., 2014), and Textual Entailment (Sha et al., 2015).",6 Related Work,[0],[0]
"Widely used KBs are DBpedia (Lehmann et al., 2015), Freebase (Bollacker et al., 2008), YAGO (Mahdisoltani et al., 2015), Wikidata (Vrandecic and Krötzsch, 2014) and the Google Knowledge Vault (Dong et al., 2014).",6 Related Work,[0],[0]
"KBs have rich information about named entities, but are pretty sparse on relations.",6 Related Work,[0],[0]
"In the latter regard, manually created resources such as WordNet (Fellbaum, 1998), VerbNet (Kipper et al., 2008) or FrameNet (Baker et al., 1998) are much richer, but still face the limitation of labor-intensive input and human curation.
",6 Related Work,[0],[0]
The paradigm of Open Information Extraction (OIE) was developed to overcome the weak coverage of relations in automatically constructed KBs.,6 Related Work,[0],[0]
OIE methods process natural language texts to produce triples of surface forms for the arguments and relational phrase of binary relations.,6 Related Work,[0],[0]
"The first large-scale approach along these lines, TextRunner (Banko et al., 2007), was later improved by ReVerb (Fader et al., 2011) and OLLIE (Mausam et al., 2012).",6 Related Work,[0],[0]
"The focus of these methods has been on verbal phrases as relations, and there is little effort to determine lexical synonymy among them.
",6 Related Work,[0],[0]
"The first notable effort to build up a resource for relational paraphrases is DIRT (Lin and Pantel, 2001), based on Harris’ Distributional Hypothesis to cluster syntactic patterns.",6 Related Work,[0],[0]
"RESOLVER (Yates and Etzioni, 2009) introduced a probabilistic relational model for predicting synonymy.",6 Related Work,[0],[0]
Yao et al. (2012) incorporated latent topic models to resolve the ambiguity of relational phrases.,6 Related Work,[0],[0]
"Other probabilistic approaches employed matrix factorization for finding entailments between relations (Riedel et al., 2013; Petroni et al., 2015) or used probabilistic graphical models to find clusters of relations (Grycner et al., 2014).",6 Related Work,[0],[0]
"All of these approaches rely on the cooccurrence of the arguments of the relation.
",6 Related Work,[0],[0]
"Recent endeavors to construct large repositories of relational paraphrases are PATTY, WiseNet and DEFIE.",6 Related Work,[0],[0]
"PATTY (Nakashole et al., 2012) devised a sequence mining algorithm to extract relational
phrases with semantic type signatures, and organized them into synonymy sets and hypernymy hierarchies.",6 Related Work,[0],[0]
"WiseNet (Moro and Navigli, 2012) tapped Wikipedia categories for a similar way of organizing relational paraphrases.",6 Related Work,[0],[0]
"DEFIE (Bovi et al., 2015) went even further and used word sense disambiguation, anchored in WordNet, to group phrases with the same meanings.
",6 Related Work,[0],[0]
Translation models have previously been used for paraphrase detection.,6 Related Work,[0],[0]
Barzilay and McKeown (2001) utilized multiple English translations of the same source text for paraphrase extraction.,6 Related Work,[0],[0]
Bannard and Callison-Burch (2005) used the bilingual pivoting method on parallel corpora for the same task.,6 Related Work,[0],[0]
"Similar methods were performed at a much bigger scale by the Paraphrase Database (PPDB) project (Pavlick et al., 2015).",6 Related Work,[0],[0]
"Unlike POLY, the focus of these projects was not on paraphrases of binary relations.",6 Related Work,[0],[0]
"Moreover, POLY considers the semantic type signatures of relations, which is missing in PPDB.
",6 Related Work,[0],[0]
Research on OIE for languages other than English has received little attention.,6 Related Work,[0],[0]
Kim et al. (2011) uses Korean-English parallel corpora for cross-lingual projection.,6 Related Work,[0],[0]
Gamallo et al. (2012) developed an OIE system for Spanish and Portuguese using rules over shallow dependency parsing.,6 Related Work,[0],[0]
The recent work of Faruqui and Kumar (2015) extracted relational phrases from Wikipedia in 61 languages using crosslingual projection.,6 Related Work,[0],[0]
"Lewis and Steedman (2013) clustered semantically equivalent English and French phrases, based on the arguments of relations.",6 Related Work,[0],[0]
"We presented POLY, a method for clustering semantically typed English relational phrases using a multilingual corpus, resulting in a repository of semantically typed paraphrases with high coverage and precision.",7 Conclusions,[0],[0]
"Future work includes jointly processing all 61 languages in the corpus, rather than considering them pairwise, to build a resource for all languages.",7 Conclusions,[0],[0]
The POLY resource is publicly available at www.mpi-inf.mpg.de/yago-naga/poly/.,7 Conclusions,[0],[0]
"Language resources that systematically organize paraphrases for binary relations are of great value for various NLP tasks and have recently been advanced in projects like PATTY, WiseNet and DEFIE.",abstractText,[0],[0]
"This paper presents a new method for building such a resource and the resource itself, called POLY.",abstractText,[0],[0]
"Starting with a very large collection of multilingual sentences parsed into triples of phrases, our method clusters relational phrases using probabilistic measures.",abstractText,[0],[0]
We judiciously leverage fine-grained semantic typing of relational arguments for identifying synonymous phrases.,abstractText,[0],[0]
The evaluation of POLY shows significant improvements in precision and recall over the prior works on PATTY and DEFIE.,abstractText,[0],[0]
An extrinsic use case demonstrates the benefits of POLY for question answering.,abstractText,[0],[0]
POLY: Mining Relational Paraphrases from Multilingual Sentences,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 35–45 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
A basic but highly important challenge in natural language understanding is being able to populate a knowledge base with relational facts contained in a piece of text.,1 Introduction,[0],[0]
"For the text shown in Figure 1, the system should extract triples, or equivalently, knowledge graph edges, such as hPenner, per:spouse, Lisa Dillmani.",1 Introduction,[0],[0]
"Combining such extractions, a system can produce a knowledge graph of relational facts between persons, organizations, and locations in the text.",1 Introduction,[0],[0]
"This task involves entity recognition, mention coreference and/or entity linking, and relation extraction; we focus on the
most challenging “slot filling” task of filling in the relations between entities in the text.
",1 Introduction,[0],[0]
Organized relational knowledge in the form of “knowledge graphs” has become an important knowledge resource.,1 Introduction,[0],[0]
"These graphs are now extensively used by search engine companies, both to provide information to end-users and internally to the system, as a way to understand relationships.",1 Introduction,[0],[0]
"However, up until now, automatic knowledge extraction has proven sufficiently difficult that most of the facts in these knowledge graphs have been built up by hand.",1 Introduction,[0],[0]
"It is therefore a key challenge to show that NLP technology can effectively contribute to this important problem.
",1 Introduction,[0],[0]
"Existing work on relation extraction (e.g., Zelenko et al., 2003; Mintz et al., 2009; Adel et al., 2016) has been unable to achieve sufficient recall or precision for the results to be usable versus hand-constructed knowledge bases.",1 Introduction,[0],[0]
"Supervised training data has been scarce and, while techniques like distant supervision appear to be a promising way to extend knowledge bases at low cost, in practice the training data has often been too noisy for reliable training of relation extraction systems (Angeli et al., 2015).",1 Introduction,[0],[0]
"As a result most systems fail to make correct extractions even in apparently straightforward cases like Figure 1,
35
where the best system at the NIST TAC Knowledge Base Population (TAC KBP) 2015 evaluation failed to recognize the relation between Penner and Dillman.1 Consequently most automatic systems continue to make heavy use of hand-written rules or patterns because it has been hard for machine learning systems to achieve adequate precision or to generalize as well across text types.",1 Introduction,[0],[0]
"We believe machine learning approaches have suffered from two key problems: (1) the models used have been insufficiently tailored to relation extraction, and (2) there has been insufficient annotated data available to satisfy the training of data-hungry models, such as deep learning models.
",1 Introduction,[0],[0]
This work addresses both of these problems.,1 Introduction,[0],[0]
"We propose a new, effective neural network sequence model for relation classification.",1 Introduction,[0],[0]
Its architecture is better customized for the slot filling task: the word representations are augmented by extra distributed representations of word position relative to the subject and object of the putative relation.,1 Introduction,[0],[0]
This means that the neural attention model can effectively exploit the combination of semantic similarity-based attention and positionbased attention.,1 Introduction,[0],[0]
"Secondly, we markedly improve the availability of supervised training data by using Mechanical Turk crowd annotation to produce a large supervised training dataset (Table 1), suitable for the common relations between people, organizations and locations which are used in the TAC KBP evaluations.",1 Introduction,[0],[0]
"We name this dataset the TAC Relation Extraction Dataset (TACRED), and will make it available through the Linguistic Data Consortium (LDC) in order to respect copyrights on the underlying text.
",1 Introduction,[0],[0]
Combining these two gives a system with markedly better slot filling performance.,1 Introduction,[0],[0]
"This is
1Note: former spouses count as spouses in the ontology.
shown not only for a relation classification task on the crowd-annotated data but also for the incorporation of the resulting classifiers into a complete cold start knowledge base population system.",1 Introduction,[0],[0]
"On TACRED, our system achieves a relation classification F1 score that is 7.9% higher than that of a strong feature-based classifier, and 3.5% higher than that of the best previous neural architecture that we re-implemented.",1 Introduction,[0],[0]
"When this model is used in concert with a pattern-based system on the TAC KBP 2015 Cold Start Slot Filling evaluation data, the system achieves an F1 score of 26.7%, which exceeds the previous state-of-the-art by 4.5% absolute.",1 Introduction,[0],[0]
While this performance certainly does not solve the knowledge base population problem – achieving sufficient recall remains a formidable challenge – this is nevertheless notable progress.,1 Introduction,[0],[0]
"Existing work on neural relation extraction (e.g., Zeng et al., 2014; Nguyen and Grishman, 2015; Zhou et al., 2016) has focused on convolutional neural networks (CNNs), recurrent neural networks (RNNs), or their combination.",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"While these models generally work well on the datasets they are tested on, as we will show, they often fail to generalize to the longer sentences that are common in real-world text (such as in TAC KBP).
",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"We believe that existing model architectures suffer from two problems: (1) Although modern sequence models such as Long Short-Term Memory (LSTM) networks have gating mechanisms to control the relative influence of each individual word to the final sentence representation (Hochreiter and Schmidhuber, 1997), these controls are not explicitly conditioned on the entire sentence being classified; (2) Most existing work either
does not explicitly model the positions of entities (i.e., subject and object) in the sequence, or models the positions only within a local region.
",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Here, we propose a new neural sequence model with a position-aware attention mechanism over an LSTM network to tackle these challenges.",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"This model can (1) evaluate the relative contribution of each word after seeing the entire sequence, and (2) base this evaluation not only on the semantic information of the sequence, but also on the global positions of the entities within the sequence.
",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
We formalize the relation extraction task as follows: Let X =,2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"[x1, ..., xn] denote a sentence, where xi is the i-th token.",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"A subject entity s and an object entity o are identified in the sentence, corresponding to two non-overlapping consecutive spans:",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
Xs =,2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"[xs1 , xs1+1, . . .",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
", xs2 ] and Xo =",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"[xo1 , xo1+1, . . .",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
", xo2 ].",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Given the sentence X and the positions of s and o, the goal is to predict a relation r 2 R (R is the set of relations) that holds between s and o or no relation otherwise.
",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Inspired by the position encoding vectors used in Collobert et al. (2011) and Zeng et al. (2014), we define a position sequence relative to the subject entity [ps1, ..., p s n], where
psi = 8>",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
<,2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
>,2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
": i s1, i < s1 0, s1  i  s2 i s2, i > s2
(1)
",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Here s1, s2 are the starting and ending indices of the subject entity respectively, and psi 2 Z can be viewed as the relative distance of token xi to the subject entity.",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Similarly, we obtain a position sequence [po1, ..., p o n] relative to the object entities.
",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
Let x,2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
=,2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"[x1, ...,xn] be word embeddings of the sentence, obtained using an embedding matrix E. Similarly, we obtain position embedding vectors ps =",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"[ps1, ...,p s n] and p o =",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"[po1, ...,p",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
o n,2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
] using a shared position embedding matrix P respectively.,2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Next, as shown in Figure 2, we obtain hidden state representations of the sentence by feeding x into an LSTM:
{h1, ...,hn} = LSTM({x1, ...,xn}) (2)
We define a summary vector q =",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"hn (i.e., the output state of the LSTM).",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
This summary vector encodes information about the entire sentence.,2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Then for each hidden state hi, we calculate an attention weight ai as:
ui = v> tanh(Whhi + Wqq+
Wspsi +",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Wop o i ) (3)
ai = exp(ui)Pn
j=1 exp(uj) (4)
",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Here Wh,Wq 2 Rda⇥d, Ws,Wo 2 Rda⇥dp and v 2 Rda are learnable parameters of the network, where d is the dimension of hidden states, dp is the dimension of position embeddings, and da is the size of attention layer.",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Additional parameters of the network include embedding matrices E 2 R|V|⇥d and P 2 R(2L 1)⇥dp , where V is the vocabulary and L is the maximum sentence length.
",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
We regard attention weight ai as the relative contribution of the specific word to the sentence representation.,2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"The final sentence representation z is computed as:
z = Xn
i=1",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"aihi (5)
z is later fed into a fully-connected layer followed by a softmax layer for relation classification.
",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Note that our model significantly differs from the attention mechanism in Bahdanau et al. (2015) and Zhou et al. (2016) in our use of the summary vector and position embeddings, and the way our attention weights are computed.",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"An intuitive way to understand the model is to view the attention calculation as a selection process, where the goal is to select relevant contexts over irrelevant ones.
",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
"Here the summary vector (q) helps the model to base this selection on the semantic information of the entire sentence (rather than on each word only), while the position vectors (psi and p o i ) provides important spatial information between each word and the entities.",2 A Position-aware Neural Sequence Model Suitable for Relation Extraction,[0],[0]
Previous research has shown that slot filling systems can greatly benefit from supervised data.,3 The TAC Relation Extraction Dataset,[0],[0]
"For example, Angeli et al. (2014b) showed that even a small amount of supervised data can boost the end-to-end F1 score by 3.9% on the TAC KBP tasks.",3 The TAC Relation Extraction Dataset,[0],[0]
"However, existing relation extraction datasets such as the SemEval-2010 Task 8 dataset (Hendrickx et al., 2009) and the Automatic Content Extraction (ACE) (Strassel et al., 2008) dataset are less useful for this purpose.",3 The TAC Relation Extraction Dataset,[0],[0]
"This is mainly because: (1) these datasets are relatively small for effectively training high-capacity models (see Table 2), and (2) they capture very different types of relations.",3 The TAC Relation Extraction Dataset,[0],[0]
"For example, the SemEval dataset focuses on semantic relations (e.g., CauseEffect, Component-Whole) between two nominals.
",3 The TAC Relation Extraction Dataset,[0],[0]
"One can further argue that it is easy to obtain a large amount of training data using distant supervision (Mintz et al., 2009).",3 The TAC Relation Extraction Dataset,[0],[0]
"In practice, however, due to the large amount of noise in the induced data, training relation extractors that perform well becomes very difficult.",3 The TAC Relation Extraction Dataset,[0],[0]
"For example, Riedel et al. (2010) show that up to 31% of the distantly supervised labels are wrong when creating training data from aligning Freebase to newswire text.
",3 The TAC Relation Extraction Dataset,[0],[0]
"To tackle these challenges, we collect a large supervised dataset TACRED, targeted towards the TAC KBP relations.
",3 The TAC Relation Extraction Dataset,[0],[0]
Data collection.,3 The TAC Relation Extraction Dataset,[0],[0]
We create TACRED based on query entities and annotated system responses in the yearly TAC KBP evaluations.,3 The TAC Relation Extraction Dataset,[0],[0]
"In each year of the TAC KBP evaluation (2009–2015), 100 entities (people or organizations) are given as queries,
for which participating systems should find associated relations and object entities.",3 The TAC Relation Extraction Dataset,[0],[0]
We make use of Mechanical Turk to annotate each sentence in the source corpus that contains one of these query entities.,3 The TAC Relation Extraction Dataset,[0],[0]
"For each sentence, we ask crowd workers to annotate both the subject and object entity spans and the relation types.
",3 The TAC Relation Extraction Dataset,[0],[0]
Dataset stratification.,3 The TAC Relation Extraction Dataset,[0],[0]
"In total we collect 119,474 examples.",3 The TAC Relation Extraction Dataset,[0],[0]
"We stratify TACRED across years in which the TAC KBP challenge was run, and use examples corresponding to query entities from 2009 to 2012 as training split, 2013 as development split, and 2014 as test split.",3 The TAC Relation Extraction Dataset,[0],[0]
"We reserve the TAC KBP 2015 evaluation data for running slot filling evaluations, as presented in Section 4.",3 The TAC Relation Extraction Dataset,[0],[0]
"Detailed statistics are given in Table 3.
Discussion.",3 The TAC Relation Extraction Dataset,[0],[0]
Table 1 presents sampled examples from TACRED.,3 The TAC Relation Extraction Dataset,[0],[0]
"Compared to existing datasets, TACRED has four advantages.",3 The TAC Relation Extraction Dataset,[0],[0]
"First, it contains an order of magnitude more relation instances (Table 2), enabling the training of expressive models.",3 The TAC Relation Extraction Dataset,[0],[0]
"Second, we reuse the entity and relation types of the TAC KBP tasks.",3 The TAC Relation Extraction Dataset,[0],[0]
We believe these relation types are of more interest to downstream applications.,3 The TAC Relation Extraction Dataset,[0],[0]
"Third, we fully annotate all negative instances that appear in our data collection process, to ensure that models trained on TACRED are not biased towards predicting false positives on realworld text.",3 The TAC Relation Extraction Dataset,[0],[0]
"Lastly, the average sentence length in TACRED is 36.2, compared to 19.1 in the SemEval dataset, reflecting the complexity of contexts in which relations occur in real-world text.
",3 The TAC Relation Extraction Dataset,[0],[0]
"Due to space constraints, we describe the data collection and validation process, system interfaces, and more statistics and examples of TACRED in the supplementary material.",3 The TAC Relation Extraction Dataset,[0],[0]
We will make TACRED publicly available through the LDC.,3 The TAC Relation Extraction Dataset,[0],[0]
"In this section we evaluate the effectiveness of our proposed model and TACRED on improving slot
filling systems.",4 Experiments,[0],[0]
"Specifically, we run two sets of experiments: (1) we evaluate model performance on the relation extraction task using TACRED, and (2) we evaluate model performance on the TAC KBP 2015 cold start slot filling task, by training the models on TACRED.",4 Experiments,[0],[0]
"We compare our model against the following baseline models for relation extraction and slot filling:
TAC KBP 2015 winning system.",4.1 Baseline Models,[0],[0]
"To judge our proposed model against a strong baseline, we compare against Stanford’s top performing system on the TAC KBP 2015 cold start slot filling task (Angeli et al., 2015).",4.1 Baseline Models,[0],[0]
At the core of this system are two relation extractors: a pattern-based extractor and a logistic regression (LR) classifier.,4.1 Baseline Models,[0],[0]
"The pattern-based system uses a total of 4,528 surface patterns and 169 dependency patterns.",4.1 Baseline Models,[0],[0]
The logistic regression model was trained on approximately 2 million bootstrapped examples (using a small annotated dataset and high-precision pattern system output) that are carefully tuned for TAC KBP slot filling evaluation.,4.1 Baseline Models,[0],[0]
"It uses a comprehensive feature set similar to the MIML-RE system for relation extraction (Surdeanu et al., 2012), including lemmatized n-grams, sequence NER tags and POS tags, positions of entities, and various features over dependency paths, etc.
",4.1 Baseline Models,[0],[0]
Convolutional neural networks.,4.1 Baseline Models,[0],[0]
We follow the 1-dimensional CNN architecture by Nguyen and Grishman (2015) for relation extraction.,4.1 Baseline Models,[0],[0]
"This model learns a representation of the input sentence, by first running a series of convolutional operations on the sentence with various filters, and then feeding the output into a max-pooling layer to reduce the dimension.",4.1 Baseline Models,[0],[0]
The resulting representation is then fed into a fully-connected layer followed by a softmax layer for relation classification.,4.1 Baseline Models,[0],[0]
"As an extension, positional embeddings are also introduced into this model to better capture the relative position of each word to the subject and object entities and were shown to achieve improved results.",4.1 Baseline Models,[0],[0]
"We use “CNN-PE” to represent the CNN model with positional embeddings.
",4.1 Baseline Models,[0],[0]
Dependency-based recurrent neural networks.,4.1 Baseline Models,[0],[0]
"In dependency-based neural models, shortest dependency paths between entities are often used as input to the neural networks.",4.1 Baseline Models,[0],[0]
"The intuition is to eliminate tokens that are potentially less relevant
to the classification of the relation.",4.1 Baseline Models,[0],[0]
"For the example in Figure 1, the shortest dependency path between the two entities is:
[Penner] survived!",4.1 Baseline Models,[0],[0]
brother !,4.1 Baseline Models,[0],[0]
wife!,4.1 Baseline Models,[0],[0]
"[Lisa Dillman]
We follow the SDP-LSTM model proposed by Xu et al. (2015b).",4.1 Baseline Models,[0],[0]
"In this model, each shortest dependency path is divided into two separate sub-paths from the subject entity and the object entity to the lowest common ancestor node.",4.1 Baseline Models,[0],[0]
"Each sub-path is fed into an LSTM network, and the resulting hidden units at each word position are passed into a max-over-time pooling layer to form the output of this sub-path.",4.1 Baseline Models,[0],[0]
"Outputs from the two sub-paths are then concatenated to form the final representation.
",4.1 Baseline Models,[0],[0]
"In addition to the above models, we also compare our proposed model against an LSTM sequence model without attention mechanism.",4.1 Baseline Models,[0],[0]
We map words that occur less than 2 times in the training set to a special <UNK> token.,4.2 Implementation Details,[0],[0]
"We use the pre-trained GloVe vectors (Pennington et al., 2014) to initialize word embeddings.",4.2 Implementation Details,[0],[0]
"For all the LSTM layers, we find that 2-layer stacked LSTMs generally work better than one-layer LSTMs.",4.2 Implementation Details,[0],[0]
"We minimize cross-entropy loss over all 42 relations using AdaGrad (Duchi et al., 2011).",4.2 Implementation Details,[0],[0]
We apply Dropout with p = 0.5 to CNNs and LSTMs.,4.2 Implementation Details,[0],[0]
During training we also find a word dropout strategy to be very effective: we randomly set a token to be <UNK> with a probability p.,4.2 Implementation Details,[0],[0]
"We set p to be 0.06 for the SDP-LSTM model and 0.04 for all other models.
",4.2 Implementation Details,[0],[0]
Entity masking.,4.2 Implementation Details,[0],[0]
We replace each subject entity in the original sentence with a special <NER>SUBJ token where <NER> is the corresponding NER signature of the subject as provided in TACRED.,4.2 Implementation Details,[0],[0]
We do the same processing for object entities.,4.2 Implementation Details,[0],[0]
"This processing step helps (1) provide a model with entity type information, and (2) prevent a model from overfitting its predictions to specific entities.
",4.2 Implementation Details,[0],[0]
Multi-channel augmentation.,4.2 Implementation Details,[0],[0]
"Instead of using only word vectors as input to the network, we augment the input with part-of-speech (POS) and named entity recognition (NER) embeddings.",4.2 Implementation Details,[0],[0]
We run Stanford CoreNLP,4.2 Implementation Details,[0],[0]
"(Manning et al., 2014) to obtain the POS and NER annotations.
",4.2 Implementation Details,[0],[0]
We describe our model hyperparameters and training in detail in the supplementary material.,4.2 Implementation Details,[0],[0]
We first evaluate all models on TACRED.,4.3 Evaluation on TACRED,[0],[0]
We train each model for 5 separate runs with independent random initializations.,4.3 Evaluation on TACRED,[0],[0]
For each run we perform early stopping using the dev set.,4.3 Evaluation on TACRED,[0],[0]
"We then select the run (among 5) that achieves the median F1 score on the dev set, and report its test set performance.
",4.3 Evaluation on TACRED,[0],[0]
Table 4 summarizes our results.,4.3 Evaluation on TACRED,[0],[0]
"We observe that all neural models achieve higher F1 scores than the logistic regression and patterns systems, which demonstrates the effectiveness of neural models for relation extraction.",4.3 Evaluation on TACRED,[0],[0]
"Although positional embeddings help increase the F1 by around 2% over the plain CNN model, a simple (2-layer) LSTM model performs surprisingly better than CNN and dependency-based models.",4.3 Evaluation on TACRED,[0],[0]
"Lastly, our proposed position-aware mechanism is very effective and achieves an F1 score of 65.4%, with an absolute increase of 3.9% over the best baseline neural model (LSTM) and 7.9% over the baseline logistic regression system.",4.3 Evaluation on TACRED,[0],[0]
"We also run an ensemble of our position-aware attention model which takes majority votes from 5 runs with random initializations and it further pushes the F1 score up by 1.6%.
",4.3 Evaluation on TACRED,[0],[0]
We find that different neural architectures show a different balance between precision and recall.,4.3 Evaluation on TACRED,[0],[0]
CNN-based models tend to have higher precision; RNN-based models have better recall.,4.3 Evaluation on TACRED,[0],[0]
This can be explained by noting that the filters in CNNs are essentially a form of “fuzzy n-gram patterns”.,4.3 Evaluation on TACRED,[0],[0]
"Second, we evaluate the slot filling performance of all models using the TAC KBP 2015 cold start slot filling task (Ellis et al., 2015).",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
"In this task, about 50k newswire and Web forum documents are selected as the evaluation corpus.",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
A slot filling system is asked to answer a series of queries with two-hop slots (Figure 3):,4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
"The first slot asks about fillers of a relation with the query entity as the subject (Mike Penner), and we term this a hop-0 slot; the second slot asks about fillers with the system’s hop-0 output as the subject, and we term this a hop-1 slot.",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
"System predictions are then evaluated against gold annotations, and micro-averaged precision, recall and F1 scores are calculated at the hop-0 and hop-1 levels.",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
"Lastly hop-all scores are calculated by combining hop-0 and hop-1 scores.2
Evaluating relation extraction systems on slot filling is particularly challenging in that: (1) Endto-end cold start slot filling scores conflate the performance of all modules in the system (i.e., entity recognizer, entity linker and relation extractor).",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
(2) Errors in hop-0 predictions can easily propagate to hop-1 predictions.,4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
"To fairly evaluate each relation extraction model on this task, we use Stanford’s 2015 slot filling system as our basic pipeline.3 It is a very strong baseline specifically tuned for TAC KBP evaluation and ranked top in the 2015 evaluation.",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
"We then plug in the corresponding relation extractor trained on TACRED, keeping all other modules unchanged.
",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
Table 5 presents our results.,4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
"We find that: (1) by only training our logistic regression model on TACRED (in contrast to on the 2 million bootstrapped examples used in the 2015 Stanford system) and combining it with patterns, we obtain a higher hop-0 F1 score than the 2015 Stanford sys-
2In the TAC KBP cold start slot filling evaluation, a hop-1 slot is transferred to a pseudo-slot which is treated equally as a hop-0 slot.",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
"Hop-all precision, recall and F1 are then calculated by combining these pseudo-slot predictions and hop-0 predictions.
",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
3This system uses the fine-grained NER system in Stanford CoreNLP,4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
"(Manning et al., 2014) for entity detection and the Illinois Wikifier (Ratinov et al., 2011) for entity linking.
",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
"tem, and a similar hop-all F1; (2) our proposed position-aware attention model substantially outperforms the 2015 Stanford system on all hop-0, hop-1 and hop-all F1 scores.",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
"Combining it with the patterns, we achieve a hop-all F1 of 26.7%, an absolute improvement of 4.5% over the previous state-of-the-art result.",4.4 Evaluation on TAC KBP Slot Filling,[0],[0]
Model ablation.,4.5 Analysis,[0],[0]
Table 6 presents the results of an ablation test of our position-aware attention model on the development set of TACRED.,4.5 Analysis,[0],[0]
"The entire attention mechanism contributes about 1.5% F1, where the position-aware term in Eq.",4.5 Analysis,[0],[0]
"(3) alone contributes about 1% F1 score.
",4.5 Analysis,[0],[0]
Impact of negative examples.,4.5 Analysis,[0],[0]
"Figure 4 shows how the slot filling evaluation scores change as we change the amount of negative (i.e., no relation) training data provided to our proposed model.",4.5 Analysis,[0],[0]
"We find that: (1) At hop-0 level, precision increases as we provide more negative examples, while recall stays almost unchanged.",4.5 Analysis,[0],[0]
F1 score keeps increasing.,4.5 Analysis,[0],[0]
"(2) At hop-all level, F1 score increases by
about 10% as we change the amount of negative examples from 20% to 100%.
",4.5 Analysis,[0],[0]
Performance by sentence length.,4.5 Analysis,[0],[0]
Figure 5 shows performance on varying sentence lengths.,4.5 Analysis,[0],[0]
We find that: (1) Performance of all models degrades substantially as the sentences get longer.,4.5 Analysis,[0],[0]
"(2) Compared to the baseline Logistic Regression model, all neural models handle long sentences better.",4.5 Analysis,[0],[0]
"(3) Compared to CNN-PE model, RNNbased models are more robust on long sentences, and notably SDP-LSTM model is least sensitive to sentence length.",4.5 Analysis,[0],[0]
"(4) Our proposed model achieves equal or better results on sentences of all lengths, except for sentences with more than 60 tokens where SDP-LSTM model achieves the best result.
",4.5 Analysis,[0],[0]
Improvement by slot types.,4.5 Analysis,[0],[0]
We calculate the F1 score for each slot type and compare the improvement from using our proposed model across slot types.,4.5 Analysis,[0],[0]
"When compared with the CNN-PE model, our position-aware attention model achieves improved F1 scores on 30 out of the 41 slot types, with the top 5 slot types being org:members, per:country of death, org:shareholders, per:children and per:religion.",4.5 Analysis,[0],[0]
"When compared with SDP-LSTM model, our model achieves improved F1 scores on 26 out of the 41 slot types, with the top 5 slot types being org:political/religious affiliation, per:country of death, org:alternate names, per:religion and per:alternate names.",4.5 Analysis,[0],[0]
"We observe that slot types with relatively sparse training examples tend to be improved by using the position-aware attention model.
",4.5 Analysis,[0],[0]
Attention visualization.,4.5 Analysis,[0],[0]
"Lastly, Figure 6 shows the visualization of attention weights assigned by our model on sampled sentences from the development set.",4.5 Analysis,[0],[0]
"We find that the model learns to pay more attention to words that are informative for the relation (e.g., “graduated from”, “niece” and “chairman”), though it still makes mistakes (e.g., “refused to name the three”).",4.5 Analysis,[0],[0]
"We also observe that the model tends to put a lot of weight onto object entities, as the object NER signatures are very informative to the classification of relations.",4.5 Analysis,[0],[0]
Relation extraction.,5 Related Work,[0],[0]
"There are broadly three main lines of work on relation extraction: first, fully-supervised approaches (Zelenko et al., 2003; Bunescu and Mooney, 2005), where a statisti-
cal classifier is trained on an annotated dataset; second, distant supervision (Mintz et al., 2009; Surdeanu et al., 2012), where a training set is formed by projecting the relations in an existing knowledge base onto textual instances that contain the entities that the relation connects; and third, Open IE (Fader et al., 2011; Mausam et al., 2012), which views its goal as producing subject-relationobject triples and expressing the relation in text.
",5 Related Work,[0],[0]
Slot filling and knowledge base population.,5 Related Work,[0],[0]
"The most widely-known effort to evaluate slot filling and KBP systems is the yearly TAC KBP slot filling tasks, starting from 2009 (McNamee and Dang, 2009).",5 Related Work,[0],[0]
"Participants in slot filling tasks usually make use of hybrid systems that combine patterns, Open IE, distant supervision and supervised systems for relation extraction (Kisiel et al., 2015; Finin et al., 2015; Zhang et al., 2016).
",5 Related Work,[0],[0]
Datasets for relation extraction.,5 Related Work,[0],[0]
"Popular general-domain datasets include the ACE dataset (Strassel et al., 2008) and the SemEval-2010 task 8 dataset (Hendrickx et al., 2009).",5 Related Work,[0],[0]
"In addition, the BioNLP Shared Tasks (Kim et al., 2009) are yearly efforts on creating datasets and evaluations for biomedical information extraction systems.
",5 Related Work,[0],[0]
Deep learning models for relation extraction.,5 Related Work,[0],[0]
"Many deep learning models have been proposed for relation extraction, with a focus on end-to-end training using CNNs (Zeng et al., 2014; Nguyen and Grishman, 2015) and RNNs (Zhang et al., 2015).",5 Related Work,[0],[0]
"Other popular approaches include using CNN or RNN over dependency paths between entities (Xu et al., 2015a,b), augmenting RNNs with different components (Xu et al., 2016; Zhou et al., 2016), and combining RNNs and CNNs (Vu et al., 2016; Wang et al., 2016).",5 Related Work,[0],[0]
Adel et al. (2016) compares the performance of CNN models against traditional approaches on slot filling using a portion of the TAC KBP evaluation data.,5 Related Work,[0],[0]
"We introduce a state-of-the-art position-aware neural sequence model for relation extraction, as well as TACRED, a large-scale, crowd-sourced dataset that is orders of magnitude larger than previous relation extraction datasets.",6 Conclusion,[0],[0]
Our proposed model outperforms a strong feature-based classifier and all baseline neural models.,6 Conclusion,[0],[0]
"In combination with the new dataset, it improves the state-of-the-
art hop-all F1 on the TAC KBP 2015 slot filling task by 4.5% absolute.",6 Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful suggestions.,Acknowledgments,[0],[0]
We gratefully acknowledge the support of the Allen Institute for Artificial Intelligence and the support of the Defense Advanced Research Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract,Acknowledgments,[0],[0]
No. FA8750-13-2-0040.,Acknowledgments,[0],[0]
"Any opinions, findings, and conclusion or recommendations expressed in this material are those of the authors and do not necessarily reflect the view of the DARPA, AFRL, or the US government.",Acknowledgments,[0],[0]
Organized relational knowledge in the form of “knowledge graphs” is important for many applications.,abstractText,[0],[0]
"However, the ability to populate knowledge bases with facts automatically extracted from documents has improved frustratingly slowly.",abstractText,[0],[0]
This paper simultaneously addresses two issues that have held back prior work.,abstractText,[0],[0]
"We first propose an effective new model, which combines an LSTM sequence model with a form of entity position-aware attention that is better suited to relation extraction.",abstractText,[0],[0]
"Then we build TACRED, a large (119,474 examples) supervised relation extraction dataset, obtained via crowdsourcing and targeted towards TAC KBP relations.",abstractText,[0],[0]
The combination of better supervised data and a more appropriate high-capacity model enables much better relation extraction performance.,abstractText,[0],[0]
"When the model trained on this new dataset replaces the previous relation extraction component of the best TAC KBP 2015 slot filling system, its F1 score increases markedly from 22.2% to 26.7%.",abstractText,[0],[0]
Position-aware Attention and Supervised Data Improve Slot Filling,title,[0],[0]
There are many cases in Bayesian modeling where a certain choice of prior distribution allows for computationally simple or tractable inference.,1. Introduction,[0],[0]
"For example,
• Conjugate priors yield posteriors with a known parametric form and therefore allow for non-iterative, exact inference (Diaconis et al., 1979).
",1. Introduction,[0],[0]
"• Certain priors yield models with tractable conditional or marginal distributions, which allows efficient approximate inference algorithms to be applied (e.g. Gibbs sampling (Smith & Roberts, 1993), sampling
1Carnegie Mellon University, Machine Learning Department, Pittsburgh, USA 2CMU School of Computer Science.",1. Introduction,[0],[0]
"Correspondence to: Willie Neiswanger <willie@cs.cmu.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
in collapsed models (Teh et al., 2006), or mean-field variational methods (Wang & Blei, 2013)).
",1. Introduction,[0],[0]
"• Simple parametric priors allow for computationally cheap density queries, maximization, and sampling, which can reduce costs in iterative inference algorithms (e.g. Metropolis-Hastings (Metropolis et al., 1953), gradient-based MCMC (Neal, 2011), or sequential Monte Carlo (Doucet et al., 2000)).
",1. Introduction,[0],[0]
"For these reasons, one might hope to infer a result under a convenient-but-unrealistic prior, and afterwards, attempt to correct the result.",1. Introduction,[0],[0]
"More generally, given an inference result (under a convenient prior or otherwise), one might wish to incorporate updated prior information, or see a result under different prior assumptions, without having to re-run a costly inference algorithm.
",1. Introduction,[0],[0]
"This leads to the main question of this paper: for a given model, is it possible to use any convenient false prior to infer a false posterior, and afterwards, given any target prior of interest, efficiently and accurately infer the associated target posterior?
",1. Introduction,[0],[0]
One potential strategy involves sampling from the false posterior and reweighting these samples via importance sampling (IS).,1. Introduction,[0],[0]
"However, depending on the chosen target prior—both its parametric form and similarity to the false prior—the resulting inference can be inaccurate due to high or infinite variance IS estimates (demonstrated in Sec. 2.1).
",1. Introduction,[0],[0]
We instead aim to devise a method that yields accurate inferences for arbitrary target priors.,1. Introduction,[0],[0]
"Furthermore, like IS, we want to make use of the pre-inferred false posterior, without simply running standard inference algorithms on the target posterior.",1. Introduction,[0],[0]
"Note that most standard inference algorithms are iterative and data-dependent: parameter updates at each iteration involve data, and the computational cost or quality of each update depends on the amount of data used.",1. Introduction,[0],[0]
"Hence, running inference algorithms directly on the target posterior can be costly (especially given a large amount of data or many target priors of interest) and defeats the purpose of using a convenient false prior.
",1. Introduction,[0],[0]
"In this paper, we propose prior swapping, an iterative, dataindependent method for generating accurate posterior samples under arbitrary target priors.",1. Introduction,[0],[0]
"Prior swapping uses the pre-inferred false posterior to perform efficient updates that
do not depend on the data, and thus proceeds very quickly.",1. Introduction,[0],[0]
"We therefore advocate breaking difficult inference problems into two easier steps: first, do inference using the most computationally convenient prior for a given model, and then, for all future priors of interest, use prior swapping.
",1. Introduction,[0],[0]
"In the following sections, we demonstrate the pitfalls of using IS, describe the proposed prior swapping methods for different types of false posterior inference results (e.g. exact or approximate density functions, or samples) and give theoretical guarantees for these methods.",1. Introduction,[0],[0]
"Finally, we show empirical results on heavy-tailed and sparsity priors in Bayesian generalized linear models, and relational priors over components in mixture and topic models.",1. Introduction,[0],[0]
"Suppose we have a dataset of n vectors xn = {x1, . . .",2. Methodology,[0],[0]
", xn},",2. Methodology,[0],[0]
"xi ∈ Rp, and we have chosen a family of models with the likelihood function L(θ|xn) = p(xn|θ), parameterized by θ ∈ Rd.",2. Methodology,[0],[0]
"Suppose we have a prior distribution over the space of model parameters θ, with probability density function (PDF) π(θ).",2. Methodology,[0],[0]
"The likelihood and prior define a joint model with PDF p(θ, xn) = π(θ)L(θ|xn).",2. Methodology,[0],[0]
"In Bayesian inference, we are interested in computing the posterior (conditional) distribution of this joint model, with PDF
p(θ|xn) = π(θ)L(θ|x n)∫
π(θ)L(θ|xn) dθ .",2. Methodology,[0],[0]
"(1)
Suppose we’ve chosen a different prior distribution πf (θ), which we refer to as a false prior (while we refer to π(θ) as the target prior).",2. Methodology,[0],[0]
"We can now define a new posterior
pf (θ|xn) =",2. Methodology,[0],[0]
"πf (θ)L(θ|xn)∫ πf (θ)L(θ)|xn) dθ
(2)
which we refer to as a false posterior.
",2. Methodology,[0],[0]
"We are interested in the following task: given a false posterior inference result (i.e. samples from pf (θ|xn), or some exact or approximate PDF), choose an arbitrary target prior π(θ) and efficiently sample from the associated target posterior p(θ|xn)—or, more generally, compute an expectation µh = Ep [h(θ)] for some test function h(θ) with respect to the target posterior.",2. Methodology,[0],[0]
"We begin by describing an initial strategy, and existing work in a related task known as prior sensitivity analysis.
",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
Suppose we have T false posterior samples {θ̃t}Tt=1 ∼ pf (θ|xn).,2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"In importance sampling (IS), samples from an importance distribution are used to estimate the expectation of a test function with respect to a target distribution.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"A straightforward idea is to use the false posterior as an
importance distribution, and compute the IS estimate
µ̂ISh = T∑ t=1 w(θ̃t)h(θ̃t) (3)
where the weight function w(θ) ∝ p(θ|x n) pf (θ|xn) ∝ π(θ) πf (θ)
, and the T weights are normalized to sum to one.
",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
IS-based methods have been developed for the task of prior sensitivity analysis (PSA).,2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"In PSA, the goal is to determine how the posterior varies over a sequence of priors (e.g. over a parameterized family of priors π(θ; γi), i = 0, 1, . . .).",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"Existing work has proposed inferring a single posterior under prior π(θ; γ0), and then using IS methods to infer further posteriors in the sequence (Besag et al., 1995; Hastings, 1970; Bornn et al., 2010).
",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"This strategy is effective when subsequent priors are similar enough, but breaks down when two priors are sufficiently dissimilar, or are from ill-matched parametric families, which we illustrate in an example below.
",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"Note that, in general for IS, as T → ∞, µ̂ISh → µh almost surely.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"However, IS estimates can still fail in practice if µ̂ISh has high or infinite variance.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"If so, the variance of the weights w(θ̃t) will be large (a problem often referred to as weight degeneracy), which can lead to inaccurate estimates.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"In our case, the variance of µ̂ISh is only finite if
Epf [ h(θ)2 π(θ)2
πf (θ)2
] ∝",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"Ep [ h(θ)2 π(θ)
πf (θ)
]",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"<∞. (4)
",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"For a broad class of h, this is satisfied",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"if there existsM ∈ R such that π(θ)πf (θ) < M, ∀θ (Geweke, 1989)",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
.,2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"Given some preinferred pf (θ|xn) with false prior πf (θ), the accuracy of IS thus depends on the target prior of interest.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"For example, if π(θ) has heavier tails than πf (θ), the variance of µ̂ISh will be infinite for many h. Intuitively, we expect the variance to be higher for π that are more dissimilar to πf .
",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
We show a concrete example of this in Fig. 1.,2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"Consider a normal model for data xn ∼ N (θ, 1), with a standard normal false prior πf (θ) = N (θ|0, 1).",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"This yields a closedform false posterior (due to the conjugate πf ), which is also normal.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"Suppose we’d like to estimate the posterior expectation under a Laplace target prior, with mean 10 and variance 1, for test function h(θ) = θ (i.e. an estimate of the target posterior mean).",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"We draw T false posterior samples {θ̃t}Tt=1 ∼ pf (θ|xn), compute weights w(θ̃t) and IS estimate µ̂ISh , and compare it with the true expectation µh.
",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
We see in Fig. 1 that |µh,2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"− µ̂ISh | slows significantly as T increases, and maintains a high error even as T is made very large.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
We can analyze this issue theoretically.,2.1. Importance Sampling and Prior Sensitivity,[0],[0]
Suppose we want |µh,2.1. Importance Sampling and Prior Sensitivity,[0],[0]
− µ̂ISh | < δ.,2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"Since we know pf (θ|xn) is normal, we can compute a lower bound on the number of false posterior samples T that would be needed for
the expected estimate to be within δ of µh.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"Namely, if pf (θ|xn) = N (θ|m, s2), in order for |µh",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
− Epf,2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"[µ̂ISh ]| < δ, we’d need
T ≥ exp { 1
2s2 (|µh −m|",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"− δ)2
} .
",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"In the example in Fig. 1, we have m = 1, s2 = 0.25, and µh = 7.9892.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"Hence, for |µh",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
− Epf,2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"[µ̂ISh ]| < 1, we’d need T > 1031 samples (see appendix for full details of this analysis).",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"Note that this bound actually has nothing to do with the parametric form of π(θ)—it is based solely on the normal false posterior, and its distance to the target posterior mean µh.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"However, even if this distance was small, the importance estimate would still have infinite variance due to the Laplace target prior.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"Further, note that the situation can significantly worsen in higher dimensions, or if the false posterior has a lower variance.",2.1. Importance Sampling and Prior Sensitivity,[0],[0]
"We’d like a method that will work well even when false and target priors πf (θ) and π(θ) are significantly different, or are from different parametric families, with performance that does not worsen (in accuracy nor computational complexity) as the priors are made more dissimilar.
",2.2. Prior Swapping,[0],[0]
"Redoing inference for each new target posterior can be very costly, especially when the data size n is large, because the per-iteration cost of most standard inference algorithms scales with n, and many iterations may be needed for accurate inference.",2.2. Prior Swapping,[0],[0]
This includes both MCMC and sequential monte carlo (SMC) algorithms (i.e. repeated-ISmethods that infer a sequence of distributions).,2.2. Prior Swapping,[0],[0]
"In SMC, the per-iteration cost still scales with n, and the variance estimates can still be infinite if subsequent distributions are ill-matched.
",2.2. Prior Swapping,[0],[0]
"Instead, we aim to leverage the inferred false posterior to more-efficiently compute any future target posterior.",2.2. Prior Swapping,[0],[0]
We begin by defining a prior swap density ps(θ).,2.2. Prior Swapping,[0],[0]
"Suppose for now that a false posterior inference algorithm has returned a density function p̃f (θ) (we will give more details on p̃f
later; assume for now that it is either equal to pf (θ|xn) or approximates it).",2.2. Prior Swapping,[0],[0]
"We then define the prior swap density as
ps(θ) ∝",2.2. Prior Swapping,[0],[0]
"p̃f (θ)π(θ)
πf (θ) .",2.2. Prior Swapping,[0],[0]
"(5)
Note that if p̃f (θ) = pf (θ|xn), then ps(θ) = p(θ|xn).",2.2. Prior Swapping,[0],[0]
"However, depending on how we represent p̃f (θ), ps(θ) can have a much simpler analytic representation than p(θ|xn), which is typically defined via a likelihood function (i.e. a function of the data) and causes inference algorithms to have costs that scale with the data size n. Specifically, we will only use low-complexity p̃f (θ) that can be evaluated in constant time with respect to the data size",2.2. Prior Swapping,[0],[0]
"n.
Our general strategy is to use ps(θ) as a surrogate for p(θ|xn) in standard MCMC or optimization procedures, to yield data-independent algorithms with constant cost per iteration.",2.2. Prior Swapping,[0],[0]
"Intuitively, the likelihood information is captured by the false posterior—we make use of this instead of the likelihood function, which is costly to evaluate.
More concretely, at each iteration in standard inference algorithms, we must evaluate a data-dependent function associated with the posterior density.",2.2. Prior Swapping,[0],[0]
"For example, we evaluate a function proportional to p(θ|xn) in Metropolis-Hastings (MH) (Metropolis et al., 1953), and ∇θ log p(θ|xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) (Rossky et al., 1978) and Hamiltonian Monte Carlo (HMC) (Neal, 2011)) and in optimization procedures that yield a MAP point estimate.",2.2. Prior Swapping,[0],[0]
"In prior swapping, we instead evaluate ps(θ) in MH, or ∇θ log ps(θ) in LD, HMC, or gradient optimization to a MAP estimate (see appendix for algorithm pseudocode).",2.2. Prior Swapping,[0],[0]
"Here, each iteration only requires evaluating a few simple analytic expressions, and thus has O(1) complexity with respect to data size.
",2.2. Prior Swapping,[0],[0]
"We demonstrate prior swapping on our previous example (using a normal false prior and Laplace target prior) in Fig. 2, where we have a closed-form (normal PDF) p̃f (θ).",2.2. Prior Swapping,[0],[0]
"To do prior swapping, we run a Metropolis-Hastings algorithm on the target density ps(θ).",2.2. Prior Swapping,[0],[0]
"Note that drawing each
sample in this Markov chain does not involve the data xn, and can be done in constant time with respect to n (which we can see by viewing the wall time for different T ).",2.2. Prior Swapping,[0],[0]
"In Fig. 2, we draw T samples {θt}Tt=1 ∼ ps(θ), compute a sample estimate µ̂PSh = 1 T ∑T t=1 θt, and compare it with the true value µh.",2.2. Prior Swapping,[0],[0]
We see that µ̂PSh converges to µh after a relatively small number of samples T.,2.2. Prior Swapping,[0],[0]
The previous method is only applicable if our false posterior inference result is a PDF p̃f (θ) (such as in closed-form inference or variational approximations).,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Here, we develop prior swapping methods for the setting where we only have access to samples {θ̃t} Tf t=1 ∼ pf (θ|xn).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"We propose the following procedure:
1.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
Use {θ̃t} Tf t=1 to form an estimate p̃f (θ) ≈ pf (θ|xn).,2.3. Prior Swapping with False Posterior Samples,[0],[0]
2.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
Sample from ps(θ) ∝,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"π(θ)p̃f (θ)πf (θ) with prior swapping, as before.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Note that, in general, ps(θ) only approximates p(θ|xn).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"As a final step, after sampling from ps(θ), we can:
3.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Apply a correction to samples from ps(θ).
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"We will describe two methods for applying a correction to ps samples—one involving importance sampling, and one involving semiparametric density estimation.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Additionally, we will discuss forms for p̃f (θ), guarantees about these forms, and how to optimize the choice of p̃f (θ).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"In particular, we will argue why (in constrast to the initial IS strategy) these methods do not fail when p(θ|xn) and pf (θ|xn) are very dissimilar or have ill-matching parametric forms.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
Prior swap importance sampling.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Our first proposal for applying a correction to prior swap samples involves IS: after estimating some p̃f (θ), and sampling {θt}Tt=1 ∼ ps(θ), we can treat {θt}Tt=1 as importance samples, and compute the IS estimate
µ̂PSish = T∑ t=1 w(θt)h(θt) (6)
where the weight function is now
w(θ) ∝ p(θ|x n) ps(θ) ∝",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"pf (θ|x n) p̃f (θ) (7)
and the weights are normalized so that ∑T t=1 w(θt) = 1.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
The key difference between this and the previous IS strategy is the weight function.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Recall that, previously, an accurate estimate depended on the similarity between π(θ) and πf (θ); both the distance to and parametric form of π(θ) could produce high or infinite variance estimates.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
This was an issue because we wanted the procedure to work well for any π(θ).,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Now, however, the performance depends on the similarity between p̃f (θ) and pf (θ|xn)—and by using the false posterior samples, we can estimate a p̃f (θ) that well approximates pf (θ|xn).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Additionally, we can prove that certain choices of p̃f (θ) guarantee a finite variance IS estimate.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Note that the variance of µ̂PSish is only finite if
Epf [ h(θ)2 pf (θ|xn)2
p̃f (θ)2
] ∝",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Ep [ h(θ)2
pf (θ|xn) p̃f (θ)
]",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"<∞.
To bound this, it is sufficient to show that there exists M ∈ R such that pf (θ|x
n) p̃f (θ)
< M for all θ (assuming a test function h(θ) with finite variance) (Geweke, 1989).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"To satisfy this condition, we will propose a certain parametric family p̃αf (θ).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Note that, to maintain a prior swapping procedure with O(1) cost, we want a p̃αf (θ) that can be evaluated in constant time.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"In general, a p̃αf (θ) with fewer terms will yield a faster procedure.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"With these in mind, we propose the following family of densities.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
Definition.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"For a parameter α = (α1, . . .",2.3. Prior Swapping with False Posterior Samples,[0],[0]
", αk), αj ∈",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Rp, k > 0, let density p̃αf (θ) satisfy
p̃αf (θ) ∝",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"πf (θ) k∏ j=1 p(αj |θ)n/k (8)
where p(αj |θ) denotes the model conditional PDF.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"The number of terms in p̃αf (θ) (and cost to evaluate) is determined by the parameter k. Note that this family is
inspired by the true form of the false posterior pf (θ|xn).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"However, p̃αf (θ) has constant-time evaluation, and we can estimate its parameter α using samples {θ̃t} Tf t=1 ∼ pf (θ|xn).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Furthermore, we have the following guarantees.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
Theorem 2.1.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"For any α = (α1, . . .",2.3. Prior Swapping with False Posterior Samples,[0],[0]
", αk) ⊂",2.3. Prior Swapping with False Posterior Samples,[0],[0]
Rp and k > 0,2.3. Prior Swapping with False Posterior Samples,[0],[0]
let p̃αf (θ) be defined as in Eq.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
(8).,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Then, there existsM > 0",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"such that pf (θ|x n)
p̃αf (θ) < M , for all θ ∈ Rd.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
Corollary 2.1.1.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"For {θt}Tt=1 ∼ pαs (θ) ∝ p̃αf (θ)π(θ) πf (θ) , w(θt) = pf (θt|xn) p̃αf (θt) (∑T r=1",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"pf (θr|xn) p̃αf (θr) )−1 , and test function that satisfies Varp [h(θ)]",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"< ∞, the variance of IS estimate µ̂PSish = ∑T t=1 h(θt)w(θt) is finite.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Proofs for these theorems are given in the appendix.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
Note that we do not know the normalization constant for p̃αf (θ).,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"This is not an issue for its use in prior swapping, since we only need access to a function proportional to pαs (θ) ∝",2.3. Prior Swapping with False Posterior Samples,[0],[0]
p̃αf (θ)π(θ)πf (θ)−1 in most MCMC algorithms.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"However, we still need to estimate α, which is an issue because the unknown normalization constant is a function of α.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Fortunately, we can use the method of score matching (Hyvärinen, 2005) to estimate α given a density such as p̃αf (θ) with unknown normalization constant.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Once we have found an optimal parameter α∗, we draw samples from pα ∗ s (θ) ∝ p̃α ∗ f (θ)π(θ)πf (θ) −1, compute weights for these samples (Eq. (7)), and compute the IS estimate µ̂PSish .",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"We give pseudocode for the full prior swap importance sampling procedure in Alg. 1.
Algorithm 1:",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Prior Swap Importance Sampling
Input: False posterior samples {θ̃t} Tf t=1 ∼ pf (θ|xn).
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
Output: IS estimate µ̂PSish .,2.3. Prior Swapping with False Posterior Samples,[0],[0]
1 Score matching: estimate α∗ using {θ̃t} Tf t=1.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
2,2.3. Prior Swapping with False Posterior Samples,[0],[0]
Prior swapping: sample {θt}Tt=1 ∼ pα ∗ s (θ) ∝,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"p̃α ∗ f (θ)π(θ) πf (θ) .
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"3 Importance sampling: compute µ̂PSish = ∑T t=1 h(θt)w(θt).
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
Semiparametric prior swapping.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"In the previous method, we chose a parametric form for p̃αf (θ); in general, even the optimal α will yield an inexact approximation to pf (θ|xn).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Here, we aim to incorporate methods that return an increasingly exact estimate p̃f (θ) when given more false posterior samples {θ̃t} Tf t=1.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
One idea is to use a nonparametric kernel density estimate p̃npf (θ) and plug this into p np s (θ) ∝,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"p̃ np f (θ)π(θ)πf (θ)
−1.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"However, nonparametric density estimates can yield inaccurate density tails and fare badly in high dimensions.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"To help mitigate these problems, we turn to a semiparametric estimate, which begins with a parametric estimate, and
adjusts it as samples are generated.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"In particular, we use a density estimate that can be viewed as the product of a parametric density estimate and a nonparametric correction function (Hjort & Glad, 1995).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"This density estimate is consistent as the number of samples Tf → ∞. Instead of (or in addition to) correcting prior swap samples with importance sampling, we can correct them by updating the nonparametric correction function as we continue to generate false posterior samples.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Given Tf samples {θ̃t} Tf t=1 ∼ pf (θ|xn), we write the semiparametric false posterior estimate as
p̃spf (θ) = 1
Tf Tf∑ t=1
[ 1
bd K
( ‖θ − θ̃t‖
b
) p̃αf (θ)
p̃αf (θ̃t)
] , (9)
where K denotes a probability density kernel, with bandwidth b, where b→ 0 as Tf →∞ (see (Wasserman, 2006) for details on probability density kernels and bandwidth selection).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"The semiparametric prior swap density is then
psps (θ) ∝",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"p̃spf (θ)π(θ)
πf (θ) =
1
Tf Tf∑ t=1
K ( ‖θ−θ̃t‖
b )",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"p̃αf (θ)π(θ)
p̃αf (θ̃t)πf (θ)b d
∝",2.3. Prior Swapping with False Posterior Samples,[0],[0]
[pαs (θ)]  1 Tf Tf∑ t=1,2.3. Prior Swapping with False Posterior Samples,[0],[0]
K,2.3. Prior Swapping with False Posterior Samples,[0],[0]
(,2.3. Prior Swapping with False Posterior Samples,[0],[0]
‖θ−θ̃t‖ b ) p̃αf (θ̃t)  .,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"(10) Hence, the prior swap density psps (θ) is proportional to the product of two densities: the parametric prior swap density pαs (θ), and a correction density.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"To estimate expectations with respect to psps (θ), we can follow Alg.",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"1 as before, but replace the weight function in the final IS estimate with
w(θ) ∝",2.3. Prior Swapping with False Posterior Samples,[0],[0]
p sp s (θ) pαs (θ) ∝,2.3. Prior Swapping with False Posterior Samples,[0],[0]
1,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Tf Tf∑ t=1
K ( ‖θ−θ̃t‖
b ) p̃αf (θ̃t) .",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"(11)
One advantage of this strategy is that computing the weights doesn’t require the data—it thus has constant cost with respect to data size n (though its cost does increase with the number of false posterior samples Tf ).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Additionally, as in importance sampling, we can prove that this procedure yields an exact estimate of E[h(θ)], asymptotically, as Tf → ∞ (and we can provide an explicit bound on the rate at which psps (θ) converges to p(θ|xn)).",2.3. Prior Swapping with False Posterior Samples,[0],[0]
We do this by showing that psps (θ) is consistent for p(θ|xn).,2.3. Prior Swapping with False Posterior Samples,[0],[0]
Theorem 2.2.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"Given false posterior samples {θ̃t} Tf t=1 ∼ pf (θ|xn) and b T−1/(4+d)f , the estimator psps is consistent for p(θ|xn), i.e. its mean-squared error satisfies
sup p(θ|xn)
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"E [∫
(psps (θ)− p(θ|xn))",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"2 dθ
] <
c
T 4/(4+d)",2.3. Prior Swapping with False Posterior Samples,[0],[0]
"f
for some c > 0 and 0 < b ≤ 1.
",2.3. Prior Swapping with False Posterior Samples,[0],[0]
The proof for this theorem is given in the appendix.,2.3. Prior Swapping with False Posterior Samples,[0],[0]
"We show empirical results on Bayesian generalized linear models (including linear and logistic regression) with sparsity and heavy tailed priors, and on latent factor models (including mixture models and topic models) with relational priors over factors (e.g. diversity-encouraging, agglomerate-encouraging, etc.).",3. Empirical Results,[0],[0]
"We aim to demonstrate empirically that prior swapping efficiently yields correct samples and, in some cases, allows us to apply certain inference algorithms to more-complex models than was previously possible.",3. Empirical Results,[0],[0]
"In the following experiments, we will refer to the following procedures:
• Target posterior inference: some standard inference algorithm (e.g. MCMC) run on p(θ|xn).
",3. Empirical Results,[0],[0]
"• False posterior inference: some standard inference algorithm run on pf (θ|xn).
",3. Empirical Results,[0],[0]
"• False posterior IS: IS using samples from pf (θ|xn).
",3. Empirical Results,[0],[0]
"• Prior swap exact: prior swapping with closed-form p̃f (θ) = pf (θ|xn).
",3. Empirical Results,[0],[0]
• Prior swap parametric: prior swapping with parametric p̃αf (θ) given by Eq.,3. Empirical Results,[0],[0]
"(8).
",3. Empirical Results,[0],[0]
"• Prior swap IS: correcting samples from p̃αf (θ) with IS.
",3. Empirical Results,[0],[0]
"• Prior swap semiparametric: correcting samples from p̃αf (θ) with the semiparametric estimate IS procedure.
",3. Empirical Results,[0],[0]
"To assess performance, we choose a test function h(θ), and compute the Euclidean distance between µh = Ep[h(θ)] and some estimate µ̂h returned by a procedure.",3. Empirical Results,[0],[0]
We denote this performance metric by posterior error = ‖µh − µ̂h‖2.,3. Empirical Results,[0],[0]
"Since µh is typically not available analytically, we run a single chain of MCMC on the target posterior for one million steps, and use these samples as ground truth to compute µh.",3. Empirical Results,[0],[0]
"For timing plots, to assess error of a method at a given time point, we collect samples drawn before this time point, remove the first quarter as burn in, and add the time it takes to compute any of the corrections.",3. Empirical Results,[0],[0]
Sparsity-encouraging regularizers have gained a high level of popularity over the past decade due to their ability to produce models with greater interpretability and parsimony.,3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"For example, the L1 norm has been used to induce sparsity with great effect (Tibshirani, 1996), and has been shown to be equivalent to a mean-zero independent Laplace prior (Tibshirani, 1996; Seeger, 2008).",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"In a Bayesian setting, inference given a sparsity prior can be difficult, and often requires a computationally intensive method (such as MH or
HMC) or posterior approximations (e.g. expectation propagation (Minka, 2001)) that make factorization or parametric assumptions (Seeger, 2008; Gerwinn et al., 2010).",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"We propose a cheap yet accurate solution: first get an inference result with a more-tractable prior (such as a normal prior), and then use prior swapping to quickly convert the result to the posterior given a sparsity prior.
",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"Our first set of experiments are on Bayesian linear regression models, which we can write as yi =",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"Xiθ + , ∼ N (0, σ2), θ ∼ π, i = 1,...,n.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"For π, we compute results on Laplace, Student’s t, and VerySparse (with PDF VerySparse(σ) = ∏d i=1 1 2σ exp{−|θi|
0.4/σ} (Seeger, 2008)) priors.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"Here, a normal πf is conjugate and allows for exact false posterior inference.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"Our second set of experiments are on Bayesian logistic regression models, which we write as yi ∼ Bern(pi), pi = logistic(Xiθ), θ ∼ π, i = 1,...,n.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"which we will pair with both heavy tailed priors and a hierarchical target prior π = N (0, α−1I), α ∼ Gamma(γ, 1).",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"For these experiments, we also use a normal πf .",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"However, this false prior is no longer conjugate, and so we use MCMC to sample from pf (θ|xn).
",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"For linear regression, we use the YearPredictionMSD data set*, (n = 515345, d = 90), in which regression is used to predict the year associated with a a song, and for logistic regression we use the MiniBooNE particle identification data set†, (n = 130065, d = 50), in which binary classification is used to distinguish particles.
",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"In Fig. 3, we compare prior swapping and IS methods, in order to show that the prior swapping procedures yield accurate posterior estimates, and to compare their speeds of convergence.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
We plot posterior error vs. wall time for each method’s estimate of the posterior mean Ep[h(θ)],3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"= Ep[θ] for two sparsity target priors (Laplace and VerySparse), for both linear and logistic regression.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"In linear regression (only), since the normal conjugate πf allows us to compute a closed form pf (θ|xn), we can run the prior swap exact method, where p̃f (θ) = pf (θ|xn).",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"However, we can also sample from pf (θ|xn) to compute p̃α ∗
f (θ), and therefore compare methods such as prior swap parametric and the two correction methods.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"In logistic regression, we do not have a closed form pf (θ|xn); here, we only compare the methods that make use of samples from pf (θ|xn).",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"In Fig. 3, we see that the prior swapping methods (particularly prior swap IS) quickly converge to nearly zero posterior error.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"Additionally, in linear regression, we see that prior swap parametric, using p̃f (θ) = p̃α ∗
f (θ), yields similar posterior error as prior swap exact, which uses p̃f (θ) = p(θ|xn).
",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"*https://archive.ics.uci.edu/ml/datasets/ YearPredictionMSD
†https://archive.ics.uci.edu/ml/datasets/ MiniBooNE+particle+identification
In Fig. 4, we show how prior swapping can be used for fast inference in Bayesian linear models with sparsity or heavy-tailed priors.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"We plot the time needed to first compute the false posterior (via exact inference) and then run prior swapping (via the MH procedure) on some target posterior, and compare this with the MH algorithm run directly on the target posterior.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
In (a) and (b) we show convergence plots and see that prior swapping performs faster inference (by a few orders of magnitude) than direct MH.,3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"In plot (b) we reduce the variance of the target prior; while this hurts the accuracy of false posterior IS, prior swapping still quickly converges to zero error.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"In (c) we show 1-d density marginals as we increase the prior sparsity, and in (d) we show prior swapping results for various sparsity priors.
",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"In the appendix, we also include results on logistic regression with the hierarchical target prior, as well as results for synthetic data where we are able to compare timing and posterior error as we tune n and d.",3.1. Sparsity Inducing and Heavy Tailed Priors in Bayesian Generalized Linear Models,[0],[0]
"Many latent variable models in machine learning—such as mixture models, topic models, probabilistic matrix factorization, and others—involve a set of latent factors (e.g. components or topics).",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Often, we’d like to use priors that encourage interesting behaviors among the factors.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"For example, we might want dissimilar factors through a diversity-promoting prior (Kwok & Adams, 2012; Xie et al., 2016) or for the factors to show some sort of sparsity pattern (Mayrink et al., 2013; Knowles & Ghahramani, 2011).",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Inference in such models is often computationally expensive or designed on a case-by-case basis (Xie et al., 2016; Knowles & Ghahramani, 2011).
",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"However, when conjugate priors are placed over the factor parameters, collapsed Gibbs sampling can be applied.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"In this method, the factor parameters are integrated out, leaving only a subset of variables; on these, the conditional
(a) (b)
",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Collapsed Gibbs Prior Swapping
W al
",3.2. Priors over Factors in Latent Variable Models,[0],[0]
l t,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"im
e (s
ec o
n d
s)
0
0.5
1
1.5
2
2.5
3x 10 4
1.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
southern 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
northern 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
region 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
western 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
eastern 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"south
Topic 6
Topic Model: False Posterior via Collapsed Gibbs
C lu
st er : G eo",3.2. Priors over Factors in Latent Variable Models,[0],[0]
gr,3.2. Priors over Factors in Latent Variable Models,[0],[0]
ap h y C,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"lu st er : F am il y
1.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
west 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
south 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
coast 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
north 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
east 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
western Topic 171 1.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
north 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
asia 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
south 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
western 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
southern 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
eastern,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Topic 285
1.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
father 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
family 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
brother 4. born 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
son 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
children,3.2. Priors over Factors in Latent Variable Models,[0],[0]
Topic 11 1.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
children 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
daughter 3. born 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
son 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
family 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
father Topic 243 1. born 2. died 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
father 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
years 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
family 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
lived Topic 280 1. born 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
parents 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
studied 4. moved 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
age 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
year,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Topic 306
1.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
north 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
west 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
east 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
south 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
eastern 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"western
Topic 353
Topic Model: Target Posterior via Prior Swapping
1.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
brother 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
sister 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
younger 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
older 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
youngest 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
sisters,3.2. Priors over Factors in Latent Variable Models,[0],[0]
Topic 11 1.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
husband 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
marriage 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
wife 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
death 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
marry 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
children,3.2. Priors over Factors in Latent Variable Models,[0],[0]
Topic 243 1.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
school 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
college 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
graduated 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
studies 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
university 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
fellow,3.2. Priors over Factors in Latent Variable Models,[0],[0]
Topic 306Topic 280 1.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
important 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
stayed 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
wrote 4. travelled 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
started 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"died
1.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
territory 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
region 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
regions 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
provinces 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
capital 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"territories
Topic 6
T er
ri to
ri es 1.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"bay
2.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
south 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
coast 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
area 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
land 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"sea
Topic 171
C oa
st
1.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
america 2.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
europe 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
asia 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
world 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
countries 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"africa
Topic 285
C ou
n tr
ie s 1.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"side
2.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
east 3.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
bordered 4.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
west 5.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
middle 6.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"border
Topic 353
B or
d er
Si b
li n
gs
M ar
ri ag
e
B io
gr ap
h y
Sc h
oo",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"l
Pr io
r sw
ap p
in g
fo r
di ve
rs e
to p
ic s.
= D
iv er
se (0
.5 )
",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"(c)
Relational target priors (over factors )
−3 −2 −1 0 1 2 3 4
−3
−2
−1
0
1
2
3
4
−3 −2 −1 0 1 2 3 4
−3
−2
−1
0
1
2
3
4
−3 −2 −1 0 1 2 3 4
−3
−2
−1
0
1
2
3
4
−3 −2 −1 0 1 2 3 4
−3
−2
−1
0
1
2
3
4
−3 −2 −1 0 1 2 3 4
−3
−2
−1
0
1
2
3
4
−3 −2 −1 0 1 2 3 4
−3
−2
−1
0
1
2
3
4
−3 −2 −1 0 1 2 3 4
−3
−2
−1
0
1
2
3
4
−3 −2 −1 0 1 2 3 4
−3
−2
−1
0
1
2
3
4
−3 −2 −1 0 1 2 3 4
−3
−2
−1
0
1
2
3
4 3. Chain(0.1)
7. SparseChain(0.1) 8.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Origin+Diverse(0.1)6. SparseAgglom(0.1)
",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"False-Posterior 1. Origin(0.1) 2. Agglom(0.1) 4. Diverse(0.1)
5.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"SparseOrigin(0.1)Wall time (seconds)
",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Mixture Model: False Posterior via Collapsed Gibbs, Target Posterior via Prior Swapping
Figure 5.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
Latent factor models: (a) Prior swapping results for relational target priors (defined in (b)) over components in a mixture model.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
(c) Prior swapping with a diversity-promoting target prior on an LDA topic model (Simple English Wikipedia corpus) to separate redundant topic clusters; the top 6 words per topic are shown.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"In (a, c)",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"we show wall times for the initial inference and prior swapping.
distributions can be computed analytically, which allows for Gibbs sampling over these variables.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Afterwards, samples of the collapsed factor parameters can be computed.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Hence, we propose the following strategy: first, assign a prior for the factor parameters that allows for collapsed Gibbs sampling; afterwards, reconstruct the factor samples and apply prior swapping for more complex relational priors over the factors.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"We can thus perform convenient inference in the collapsed model, yet apply more-sophisticated priors to variables in the uncollapsed model.
",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"We first show results on a Gaussian mixture model (GMM), written xi ∼ N (µzi ,Σzi), zi ∼ Dir(α), {µm}Mm=1 ∼ π, i = 1,...,n.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
Using a normal πf over {µm}Mm=1 allows for collapsed Gibbs sampling.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"We also show results on a topic model (latent Dirichlet allocation (LDA) (Blei et al., 2003)) for text data (for the form of this model, see (Blei et al., 2003; Wang & Blei, 2011)).",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Here, using a Dirichlet πf over topics allows for collapsed Gibbs sampling.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"For mixture models, we generate synthetic data from the above model (n=10,000, d=2, M=9), and for topic models, we use the Simple English Wikipedia‡ corpus (n=27,443 documents, vocab=10,192 words), and set M=400 topics.
‡https://simple.wikipedia.org/
In Fig. 5, we show results for mixture and topic models.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"In (a) we show inferred posteriors over GMM components for a number of relational target priors, which we define in (b).",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"In (c), we apply the diversity-promoting target prior to LDA, to separate redundant topics.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Here, we show two topic clusters (“geography” and “family”) in pf (θ|xn), which are separated into distinct, yet thematically-similar, topics after prior swapping.",3.2. Priors over Factors in Latent Variable Models,[0],[0]
In (a) and (c) we also show wall times of the inference methods.,3.2. Priors over Factors in Latent Variable Models,[0],[0]
"Given some false posterior inference result, and an arbitrary target prior, we have studied methods to accurately compute the associated target posterior (or expectations with respect to it), and to do this efficiently by leveraging the pre-inferred result.",4. Conclusion,[0],[0]
We have argued and shown empirically that this strategy is effective even when the false and target posteriors are quite dissimilar.,4. Conclusion,[0],[0]
"We believe that this strategy shows promise to allow a wider range of (and possibly less-costly) inference alorithms to be applied to certain models, and to allow updated or new prior information to be more-easily incorporated into models without re-incurring the full costs of standard inference algorithms.",4. Conclusion,[0],[0]
"While Bayesian methods are praised for their ability to incorporate useful prior knowledge, in practice, convenient priors that allow for computationally cheap or tractable inference are commonly used.",abstractText,[0],[0]
"In this paper, we investigate the following question: for a given model, is it possible to compute an inference result with any convenient false prior, and afterwards, given any target prior of interest, quickly transform this result into the target posterior?",abstractText,[0],[0]
A potential solution is to use importance sampling (IS).,abstractText,[0],[0]
"However, we demonstrate that IS will fail for many choices of the target prior, depending on its parametric form and similarity to the false prior.",abstractText,[0],[0]
"Instead, we propose prior swapping, a method that leverages the pre-inferred false posterior to efficiently generate accurate posterior samples under arbitrary target priors.",abstractText,[0],[0]
"Prior swapping lets us apply less-costly inference algorithms to certain models, and incorporate new or updated prior information “post-inference”.",abstractText,[0],[0]
"We give theoretical guarantees about our method, and demonstrate it empirically on a number of models and priors.",abstractText,[0],[0]
Post-Inference Prior Swapping,title,[0],[0]
"We study the design of practically useful, theoretically wellfounded, general-purpose algorithms for the contextual bandits (CBs) problem.",1. Introduction,[0],[0]
"In this setting, the learner repeatedly receives context, then selects an action, resulting in a received reward.",1. Introduction,[0],[0]
"The aim is to learn a policy, a mapping from contexts to actions, to maximize the long-term cumulative reward.",1. Introduction,[0],[0]
"For instance, a news portal must repeatedly choose articles to present to each user to maximize clicks.",1. Introduction,[0],[0]
"Here, the context is information about the user, the actions are the articles, and the reward might be indicator of a click.",1. Introduction,[0],[0]
"We refer the reader to an ICML 2017 tutorial (http://hunch.net/
˜
rwil/) for further examples.
CB algorithms can be put into two groups.",1. Introduction,[0],[0]
"Some methods (Langford & Zhang, 2008; Agarwal et al., 2014) are
1Cornell University.",1. Introduction,[0],[0]
Work performed while the author was an intern at Microsoft Research.,1. Introduction,[0],[0]
2Microsoft Research 3University of Southern California.,1. Introduction,[0],[0]
"Correspondence to: Dylan J. Foster <djf244@cornell.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
agnostic in the sense that they are provably effective for any given policy class and data distribution.,1. Introduction,[0],[0]
"In contrast, realizability-based approaches such as LinUCB and variants (Chu et al., 2011; Li et al., 2017; Filippi et al., 2010) or Thompson sampling (Thompson, 1933) assume the data is generated from a particular parametrized family of models.",1. Introduction,[0],[0]
"Computationally tractable realizability-based algorithms are only known for specific model families, such as when the conditional reward distributions come from a generalized linear model.
",1. Introduction,[0],[0]
The two groups of approaches seem to have different advantages and disadvantages.,1. Introduction,[0],[0]
"Empirically, in the contextual semibandit setting, Krishnamurthy et al. (2016) found that the realizability-based LinUCB approach outperforms all agnostic baselines using a linear policy class.",1. Introduction,[0],[0]
"However, the agnostic approaches were able to overcome this shortcoming by using a more powerful policy class.",1. Introduction,[0],[0]
"Computationally, previous realizability-based approaches have been limited by their reliance on either closed-form confidence bounds (as in LinUCB variants), or the ability to efficiently sample from and frequently update the posterior (as in Thompson sampling).",1. Introduction,[0],[0]
"Agnostic approaches, on the other hand, typically assume an oracle for cost-sensitive classification, which is computationally intractable in the worst case, but often practically feasible for many natural policy classes.
",1. Introduction,[0],[0]
"In this paper, we aim to develop techniques that combine the best of both of these approaches.",1. Introduction,[0],[0]
"To this end, in Section 3, we propose computationally efficient and practical realizability-based algorithms for arbitrary model classes.",1. Introduction,[0],[0]
"As is often done in agnostic approaches, we assume the availability of an oracle which reduces to a standard learning setting and knows how to efficiently leverage the structure of the model class.",1. Introduction,[0],[0]
"Specifically, we require access to a leastsquares regression oracle over the model class that we use for predicting rewards given contexts.",1. Introduction,[0],[0]
"Since regression can often be solved efficiently, the availability of such an oracle is a far more reasonable assumption than the cost-sensitive classification oracle usually assumed, which typically must solve NP-hard problems.",1. Introduction,[0],[0]
"In fact, for this reason, even the classification oracles are typically approximated by regression oracles in practice (see, e.g., Beygelzimer & Langford, 2009).",1. Introduction,[0],[0]
"Our main algorithmic components here are motivated by and adapted from a recent work of Krishnamurthy et al. (2017) on cost-sensitive active learning.
",1. Introduction,[0],[0]
"In Section 4, we prove that our algorithms are effective in achieving low regret under certain distributional assumptions.",1. Introduction,[0],[0]
"Specifically, we show that our methods enjoy low regret so long as certain quantities like the disagreement coefficient (Hanneke, 2014; Krishnamurthy et al., 2017) are bounded, or when some other distributional coefficients inspired by Bastani & Bayati (2015) are well-behaved.",1. Introduction,[0],[0]
"As a special consequence, we obtain nearly dimension-free results for sparse linear bandits in high dimensions.
",1. Introduction,[0],[0]
"Finally, in Section 5, we conduct a very extensive empirical evaluation of our algorithms on a number of datasets and against both realizability-based and agnostic baselines.",1. Introduction,[0],[0]
"In this test of practical effectiveness, we find that our approach gives comparable or superior results in nearly all cases, and we also validate the distributional assumptions required for low-regret guarantees on these datasets.",1. Introduction,[0],[0]
We consider the following contextual bandit protocol.,2. Preliminaries,[0],[0]
"Contexts are drawn from an arbitrary space, x ∈ X , actions are from a finite set, a ∈",2. Preliminaries,[0],[0]
"A ∶= {1, . . .",2. Preliminaries,[0],[0]
",K}, for some fixed K, and reward vectors are from a bounded set, r ∈",2. Preliminaries,[0],[0]
"[0,1]K , with component r(a) denoting the reward for action a ∈ A.",2. Preliminaries,[0],[0]
We consider an i.i.d.,2. Preliminaries,[0],[0]
"setting where there is a fixed and unknown distribution D over the context-reward pairs (x, r), with DX denoting its marginal over X .",2. Preliminaries,[0],[0]
"At each round t = 1,2, . . .",2. Preliminaries,[0],[0]
", T , nature samples (xt, rt) according to D and reveals xt to the learner.",2. Preliminaries,[0],[0]
The learner chooses an action at ∈ A and observes the reward rt(at).,2. Preliminaries,[0],[0]
The learner aims to maximize its reward and compete with strategies that model the expected reward E[r(a)  ,2. Preliminaries,[0],[0]
"x, a] via functions f ∶ X ×A → [0,1].",2. Preliminaries,[0],[0]
"We consider mappings f from a given class F , such as linear predictors or regression trees.",2. Preliminaries,[0],[0]
"The main assumption this paper follows is that the class F is rich enough to contain a predictor that perfectly predicts the expected reward of any action under any context, that is: Assumption 1 (Realizability).",2. Preliminaries,[0],[0]
There is a predictor f ∈ F such that E[r(a)  ,2. Preliminaries,[0],[0]
"x, a] = f(x, a) ∀x ∈ X , a ∈ A.",2. Preliminaries,[0],[0]
"This assumption is used by essentially all regression-based contextual bandit algorithms (Chu et al., 2011; Filippi et al., 2010; Russo & Van Roy, 2013; Li et al., 2017).",2. Preliminaries,[0],[0]
"Given a predictor f ∈ F , the associated optimal strategy ⇡f ∶ X → A, called a policy, picks the action with the highest predicted reward, i.e., ⇡f(x) ∶= argmaxa∈A f(x, a) (ties broken arbitrarily).",2. Preliminaries,[0],[0]
"Using ⇡ ∶= ⇡f to denote an optimal policy, the learner aims to minimize its regret
RegT = ∑Tt=1",2. Preliminaries,[0],[0]
"rt(⇡(xt)) −∑Tt=1 rt(at), which compares the accumulated rewards between the optimal policy and the learner’s strategy.",2. Preliminaries,[0],[0]
"The classic Exp4
algorithm (Auer et al., 2002b) achieves an optimal regret bound of order O(TK ln F ) (for any finite F), but the computational complexity is unfortunately linear in F .",2. Preliminaries,[0],[0]
"Regression Oracle To overcome the computational obstacle, our algorithms reduce the contextual bandit problem to weighted least-squares regression.",2. Preliminaries,[0],[0]
"Abstracting the computational complexity, we assume access to a weighted least-squares regression oracle over the predictor class F , which takes any set H of weighted examples (w,x, a, y) ∈ R+ ×X ×A ×",2. Preliminaries,[0],[0]
"[0,1] as input, and outputs the predictor with the smallest weighted squared loss: ORACLE(H) = argminf∈F ∑(w,x,a,y)∈H w(f(x, a)− y)2.",2. Preliminaries,[0],[0]
"As mentioned, such regression tasks are very common in machine learning practice and the availability of such oracle is thus a very mild assumption.",2. Preliminaries,[0],[0]
The high-level idea of our algorithms is the following.,3. Algorithms,[0],[0]
"As data is collected, we maintain a subset of F , referred to as the version space, that only contains f ∈ F with small squared loss on observed data.",3. Algorithms,[0],[0]
"For a new example, we construct a confidence interval for the expected reward of each action based on this version space.",3. Algorithms,[0],[0]
"Finally, with these confidence intervals, we either optimistically pick the action with the highest upper bound, similar to UCB and LinUCB, or randomize among all actions that are potentially the best.
",3. Algorithms,[0],[0]
"The challenge here is to maintain such version spaces and compute upper and lower confidence bounds efficiently, and we show that this can be done using a binary search together with a small number of regression oracle calls.
",3. Algorithms,[0],[0]
"More formally, we define the upper and lower bounds on the expected reward with respect to a subset F ′ ⊆ F as HIGHF ′(x, a) =max
f∈F ′ f(x, a), LOWF ′(x, a) = minf∈F ′ f(x, a).",3. Algorithms,[0],[0]
"Our algorithms will induce the confidence bounds by instantiating these quantities using the version space as F ′. To reduce computation, our algorithms update on a doubling epoch schedule.",3. Algorithms,[0],[0]
There are M = O(logT ) epochs and each epoch m begins at time ⌧m = 2m−1.,3. Algorithms,[0],[0]
"At epoch m our algorithms (implicitly) construct a version space Fm ⊆ F , and then select an action based on the reward ranges defined by HIGHFm(x, a) and LOWFm(x, a) for each time t that falls into epoch m. Specifically, we consider two algorithm variants: the first one uniformly at random picks from actions that are plausible to be the best (see lines 6-7 in Algorithm 1); the second one simply behaves optimistically and picks the action with the highest upper bound (see line 9 in Algorithm 2).",3. Algorithms,[0],[0]
"For technical reasons, the optimistic variant also performs pure exploration in the first few epochs to warm-start the algorithm.
",3. Algorithms,[0],[0]
Algorithm 1 REGCB.ELIMINATION 1:,3. Algorithms,[0],[0]
"Input: square-loss tolerance m 2: for epoch m = 1, . . .",3. Algorithms,[0],[0]
",M do 3:",3. Algorithms,[0],[0]
"Fm ←
 ∏a∈A Ĝm( m, a) (OPTION I)F̂m( m) (OPTION II)
4: for time t = ⌧m, . . .",3. Algorithms,[0],[0]
", ⌧m+1 − 1 do 5: Receive xt and define At as: 6: {a ∶ HIGHFm(xt, a) ≥maxa′∈A LOWFm(xt, a′)}.",3. Algorithms,[0],[0]
7: Sample at ∼ Unif (At) and receive rt(at).,3. Algorithms,[0],[0]
"8: end for 9: end for
To construct these version spaces, we further introduce the following least-squares notation for any m ≥ 2:
• R̂m(f)",3. Algorithms,[0],[0]
"= 1⌧m−1 ∑s<⌧mf(xs, as) − rs(as)2, • F̂m( ) = f ∈ F  R̂m(f) −minf∈F R̂m(f) ≤ ,
and also let F̂ 1 ( ) = F for any .",3. Algorithms,[0],[0]
"With this notation Fm is simply set to F̂( m) for some m, and HIGHFm and LOWFm recover the confidence bounds in UCB (Auer et al., 2002a) and LinUCB (Chu et al., 2011) for appropriate m.
Product Classes",3. Algorithms,[0],[0]
"Sometimes it is desirable to have a product predictor class, that is, F = GA, where G ∶ X →",3. Algorithms,[0],[0]
"[0,1] is a “base class” and each f ∈ F , described by a K-tuple(ga)a∈A where ga ∈ G, predicts according to f(x, a) = ga(x).",3. Algorithms,[0],[0]
"Similar to the general case, we define: • R̂m(g, a) = 1⌧m−1 ∑s<⌧m(g(xs)",3. Algorithms,[0],[0]
"− rs(as))21{as = a}, • Ĝm( , a) = g ∈ G  R̂m(g, a) −ming∈G R̂m(g, a) ≤ , and let Ĝ
1 ( , a) = G for any .",3. Algorithms,[0],[0]
In this case we constructFm as∏a∈A,3. Algorithms,[0],[0]
"Ĝm( m, a) for some tolerance parameter m. Our two procedures are described in Algorithms 1 and 2.",3. Algorithms,[0],[0]
Algorithms 1 and 2 hinge on the computation of the bounds HIGHFm and LOWFm .,3.1. Efficient Reward-Range Computation,[0],[0]
"This can be carried out efficiently via a small number of calls to the regression oracle.
",3.1. Efficient Reward-Range Computation,[0],[0]
"Specifically, to calculate the confidence bounds for a given pair (x, a), we augment the data set Hm with a single example (x, a, r) with a weight w.",3.1. Efficient Reward-Range Computation,[0],[0]
For the upper bound HIGHFm we use r = 2; for the lower bound r = −1,3.1. Efficient Reward-Range Computation,[0],[0]
(these values are chosen as they lie outside the reward range).,3.1. Efficient Reward-Range Computation,[0],[0]
"By changing the weight w, we trade-off the loss on this single example against that on the history Hm.",3.1. Efficient Reward-Range Computation,[0],[0]
"The binary search over w identifies—up to a given precision—the weight w at which
Algorithm 2 REGCB.OPTIMISTIC 1:",3.1. Efficient Reward-Range Computation,[0],[0]
"Input: square-loss tolerance m
number of warm-start epochs M 0
2: for time t = 1, . . .",3.1. Efficient Reward-Range Computation,[0],[0]
", ⌧M0 − 1 do 3: Receive xt, play at ∼ Unif (A), and receive rt(at).",3.1. Efficient Reward-Range Computation,[0],[0]
"4: end for 5: for epoch m =M
0 , . . .",3.1. Efficient Reward-Range Computation,[0],[0]
",M do 6: Fm ← F̂m( m).",3.1. Efficient Reward-Range Computation,[0],[0]
"7: for time t = ⌧m, . . . ,",3.1. Efficient Reward-Range Computation,[0],[0]
"⌧m+1 − 1 do 8: Receive xt. 9: Select at = argmaxa∈A HIGHFm(xt, a).
10: Receive rt(at).",3.1. Efficient Reward-Range Computation,[0],[0]
"11: end for 12: end for
the empirical regret on Hm is exactly the desired tolerance , with the corresponding prediction on x, a yielding HIGHF̂m( )(x, a) or LOWF̂m( )(x, a) (see Algorithm 3).",3.1. Efficient Reward-Range Computation,[0],[0]
In Appendix A.1 we prove that this strategy works as intended and in O(log(1↵)) iterations computes the confidence bounds up to a precision of ↵.,3.1. Efficient Reward-Range Computation,[0],[0]
Theorem 1.,3.1. Efficient Reward-Range Computation,[0],[0]
"Let Hm = {(xs, as, rs(as))}⌧m−1s=1 .",3.1. Efficient Reward-Range Computation,[0],[0]
"If the function class F is convex and closed under pointwise convergence, then the calls
zHIGH ← BINSEARCH(HIGH, (x, a),Hm, ,↵) zLOW",3.1. Efficient Reward-Range Computation,[0],[0]
"← BINSEARCH(LOW, (x, a),Hm, ,↵)
terminate after O(log(1↵))",3.1. Efficient Reward-Range Computation,[0],[0]
"oracle invocations and HIGHF̂m( )(x, a) − zHIGH ≤ ↵, LOWF̂m( )(x, a) − zLOW ≤ ↵.
",3.1. Efficient Reward-Range Computation,[0],[0]
"Compared to the procedure from Krishnamurthy et al. (2017), Algorithm 3 is much simpler and achieves an exponential improvement in terms of oracle calls, namely O(log(1↵))",3.1. Efficient Reward-Range Computation,[0],[0]
"as opposed to O(1↵), when F is convex.",3.1. Efficient Reward-Range Computation,[0],[0]
"Compared to oracles for cost-sensitive classification, convexity is not a strong assumption for regression oracles.",3.1. Efficient Reward-Range Computation,[0],[0]
"When F is not convex, reward bounds can be computed in O(1↵) oracle calls (see Krishnamurthy et al. 2017).",3.1. Efficient Reward-Range Computation,[0],[0]
In this section we provide regret guarantees for RegCB (Algorithm 1 and Algorithm 2).,4. Regret Guarantees,[0],[0]
"Note that RegCB is not minimax optimal: while it can obtain OKT logF  regret or even logarithmic regret under certain distributional assumptions, which we describe shortly, for some instances it can make as many as F  mistakes, which is suboptimal: Proposition 1.",4. Regret Guarantees,[0],[0]
"For every ✏ ∈ (0,1] and N ∈ N there exists a class of reward predictors satisfying Assumption 1 with
Algorithm 3 BINSEARCH 1: Input: bound type ∈ {LOW,HIGH}, target pair (x, a)
history H , radius > 0, precision ↵ > 0 2:",4. Regret Guarantees,[0],[0]
"Based on bound type: r←2 if HIGH and r←−1 if LOW 3: Let R(f) ∶= ∑(x′,a′,r′)∈H(f(x′, a′)",4. Regret Guarantees,[0],[0]
"− r′)2 4: Let R̃(f,w) ∶= R(f) + w
2 (f(x, a)",4. Regret Guarantees,[0],[0]
"− r)2 5: wL ← 0, wH",4. Regret Guarantees,[0],[0]
"← ↵
//",4. Regret Guarantees,[0],[0]
"Invoke oracle twice 6: fL ← argminf∈F R̃(f,wL), zL ← fL(x, a) 7: fH ← argminf∈F R̃(f,wH), zH",4. Regret Guarantees,[0],[0]
"← fH(x, a) 8:",4. Regret Guarantees,[0],[0]
"Rmin ← R(fL) 9: ← ↵ (r − zL)3
10: while zH",4. Regret Guarantees,[0],[0]
− zL >,4. Regret Guarantees,[0],[0]
↵ and wH,4. Regret Guarantees,[0],[0]
"−wL > do 11: w ← (wH +wL)2
//",4. Regret Guarantees,[0],[0]
Invoke oracle.,4. Regret Guarantees,[0],[0]
"12: f ← argmin ˜f∈F R̃( ˜f,w), z ← f(x, a) 13: if R(f) ≥",4. Regret Guarantees,[0],[0]
"Rmin + then 14: wH ← w, zH",4. Regret Guarantees,[0],[0]
"← z 15: else 16: wL ← w, zL",4. Regret Guarantees,[0],[0]
"← z 17: end if 18: end while 19: return zH.
F  = N + 1 and a distribution for which both Algorithms 1 and 2 have regret lower bounded by (1−✏) ⋅minN, ⌦̃(T ).",4. Regret Guarantees,[0],[0]
Proposition 1 is proved in Appendix A.2.,4. Regret Guarantees,[0],[0]
The proof builds on a well-known albeit rather pathological instance.,4. Regret Guarantees,[0],[0]
"In contrast, our strong empirical results in the following section show that such instances are not encountered in practice.",4. Regret Guarantees,[0],[0]
"In order to understand the typical behavior of such algorithms, prior works have considered structural assumptions such as finite eluder dimension (Russo & Van Roy, 2013) or disagreement coefficients (Hanneke, 2014; Krishnamurthy et al., 2017).",4. Regret Guarantees,[0],[0]
"In the next two subsections, we use similar ideas to analyze the regret incurred by our algorithm.",4. Regret Guarantees,[0],[0]
"We assume that HIGHFm and LOWFm are computed exactly, but extension to the approximate case is straightforward.",4. Regret Guarantees,[0],[0]
"Disagreement coefficients come from the active learning literature (Hanneke, 2014), and roughly assume that given a set of functions which fit the historical data well, the probability that these functions make differing predictions on a new example is small.",4.1. Disagreement-based Analysis,[0],[0]
"This rules out the bad case of Proposition 1, where a near-optimal predictor significantly disagrees from the others on each context.",4.1. Disagreement-based Analysis,[0],[0]
"Our development in this subsection largely follows Krishnamurthy et al. (2017), with appropriate modifications to translate from active learning to contextual bandits.",4.1. Disagreement-based Analysis,[0],[0]
"We begin with a formal definition of the disagreement coefficient.
",4.1. Disagreement-based Analysis,[0],[0]
Definition 1 (Disagreement Coefficient).,4.1. Disagreement-based Analysis,[0],[0]
"The disagreement coefficient for F (with respect to DX ) is defined as ✓ 0
∶= sup >0,"">0 "" PrDX x ∈",4.1. Disagreement-based Analysis,[0],[0]
"Dis(F("")) and
∃a ∈ AF("")(x) ∶WF("")(x, a) > .",4.1. Disagreement-based Analysis,[0],[0]
"Here F("") is the set of all predictors f whose greedy policies have regret at most "", Dis(F(""))",4.1. Disagreement-based Analysis,[0],[0]
"is the set of x’s where the greedy policies of at least two functions in F("") choose different actions, AF(x) = f∈Fargmaxa∈A",4.1. Disagreement-based Analysis,[0],[0]
"f(x, a), and WF(x, a) is the difference between the upper and lower bounds HIGHF(x, a) − LOWF(x, a).",4.1. Disagreement-based Analysis,[0],[0]
Formal definitions of these quantities can be found in Appendix A.3.,4.1. Disagreement-based Analysis,[0],[0]
"Informally, the disagreement coefficient is small if on most contexts either all f ∈ F("") choose the same action according to their greedy policies or all actions chosen by those policies have a low range of predicted rewards.
",4.1. Disagreement-based Analysis,[0],[0]
The following theorem provides regret bounds in terms of the disagreement coefficient.,4.1. Disagreement-based Analysis,[0],[0]
"In all theorems we use Õ to suppress polynomial terms in logT , logK, and log(1 ), where is the failure probability.",4.1. Disagreement-based Analysis,[0],[0]
"Moreover, all results can be improved to be logarithmic (in T ) under the standard Massart noise condition (see the appendix for the details).",4.1. Disagreement-based Analysis,[0],[0]
Theorem 2.,4.1. Disagreement-based Analysis,[0],[0]
"With m = (M−m+1)C ⌧m−1 and C = 16 log 2GKT 2 , Algorithm 1 with Option I incurs RegT = Õ T 34 (log G) 14√✓
0 K with probability at least 1 − .",4.1. Disagreement-based Analysis,[0],[0]
"See Theorem 5 in Appendix A.3 for the full version of this theorem, which applies to infinite classes and additionally obtains faster rates under the Massart noise condition.
",4.1. Disagreement-based Analysis,[0],[0]
"Discussion Theorem 2 critically uses the product class structure, specifically the fact that the set At computed by the algorithm coincides with the disagreement set AFm(xt) for t ∈ {⌧m, . . .",4.1. Disagreement-based Analysis,[0],[0]
", ⌧m+1 − 1}.",4.1. Disagreement-based Analysis,[0],[0]
"This is true for product classes, but not necessarily for general (non-product) predictor classes.",4.1. Disagreement-based Analysis,[0],[0]
"Computing the disagreement set efficiently for non-product classes is a challenge for future work.
",4.1. Disagreement-based Analysis,[0],[0]
"While bounding the disagreement coefficients a priori often requires strong assumptions on the model class and the distribution, the size of disagreement set can be easily checked empirically under the product class assumption, and we include this diagnostic in our experimental results.
",4.1. Disagreement-based Analysis,[0],[0]
"Finally, while the disagreement coefficient enables the analysis of Algorithm 1, it is not obvious how to use it to analyze Algorithm 2.",4.1. Disagreement-based Analysis,[0],[0]
"Our analysis crucially requires that any plausibly optimal action a be chosen with a reasonable probability, something which the optimistic algorithm fails to ensure.",4.1. Disagreement-based Analysis,[0],[0]
"The disagreement-based analysis of Theorem 2 is not entirely satisfying, because even for linear predictors (e.g.,
as in LinUCB, Chu et al. 2011), fairly strong assumptions on DX (e.g., log-concavity) are required to bound the disagreement coefficient ✓
0",4.2. Moment-based Analysis,[0],[0]
"(Hanneke, 2014).",4.2. Moment-based Analysis,[0],[0]
"To generalize the analysis to richer than linear classes without distributional assumptions on the contexts, prior work has used the notion of eluder dimension (Russo & Van Roy, 2013).",4.2. Moment-based Analysis,[0],[0]
"It remains challenging, however, to show examples with a small eluder dimension beyond linearly parameterized functions.",4.2. Moment-based Analysis,[0],[0]
"In addition, taking the worst-case over all histories, as in eluder dimension, is overly pessimistic for i.i.d. contextual bandits.
",4.2. Moment-based Analysis,[0],[0]
"To address the shortcomings of both the disagreement-based analysis as well as eluder dimension for i.i.d. settings, we define two new distributional properties which we will use to analyze the regret of both of our algorithms.",4.2. Moment-based Analysis,[0],[0]
Definition 2 (Surprise bound).,4.2. Moment-based Analysis,[0],[0]
"The surprise bound L
1 > 0 is the smallest constant such that for all f ∈ F , x ∈ X , and a ∈ A, the gap (f(x, a) − f(x, a))2 is at most
L 1 ⋅Ex′∼DX",4.2. Moment-based Analysis,[0],[0]
"Ea′∼Unif(A)f(x′, a′)",4.2. Moment-based Analysis,[0],[0]
"− f(x′, a′)2 .",4.2. Moment-based Analysis,[0],[0]
"The surprise bound is small if functions with a small expected squared error relative to f (under a uniform choice of actions) do not encounter a much larger squared error on any single context-action pair.
",4.2. Moment-based Analysis,[0],[0]
"The second quantity, which we call the implicit exploration coefficient (or IEC) relates the expected regression error under actions chosen by the optimal policy to the worst-case error on any other context-action pair.",4.2. Moment-based Analysis,[0],[0]
"For ∈ (0,1] define U (a) = {x  f(x, a) ≥ f(x, a′) + ∀a′ ≠ a}.",4.2. Moment-based Analysis,[0],[0]
Definition 3,4.2. Moment-based Analysis,[0],[0]
(Implicit exploration coefficient—IEC).,4.2. Moment-based Analysis,[0],[0]
"For any ∈ (0,1], the implicit exploration coefficient L
2, > 0 is the smallest constant such that for all f ∈ F , x ∈ X , and a ∈ A, the gap (f(x, a) − f(x, a))2 is at most L 2, Ex′∼DX",4.2. Moment-based Analysis,[0],[0]
"Ea′∼Unif(A)1x′ ∈ U (a′) (1) ⋅ f(x′, a′)",4.2. Moment-based Analysis,[0],[0]
"− f(x′, a′)2.",4.2. Moment-based Analysis,[0],[0]
"We now make two remarks about these definitions and their impact on the performance of Algorithms 1 and 2.
",4.2. Moment-based Analysis,[0],[0]
"• By definition, L 2, is non-decreasing in .",4.2. Moment-based Analysis,[0],[0]
"For Al-
gorithm 1 we can simply use = 0, for which L 2,0 is defined by replacing the right-hand side of (1) with L2,0K Ex∼DX",4.2. Moment-based Analysis,[0],[0]
"[(f(x,⇡(x))",4.2. Moment-based Analysis,[0],[0]
"− f(x,⇡(x)))2].",4.2. Moment-based Analysis,[0],[0]
"The analysis of Algorithm 2 requires > 0, and this must be used to tune the algorithm’s warm-start period.
",4.2. Moment-based Analysis,[0],[0]
"• We always have L 1 ≤ L 2,0, but L1 may be much
smaller.",4.2. Moment-based Analysis,[0],[0]
"L 1 appears in the regret bound of Algorithm 2, but not Algorithm 1.
",4.2. Moment-based Analysis,[0],[0]
"We now state the regret bound for Algorithm 1 with a general class F , and employ the shorthand C ′",4.2. Moment-based Analysis,[0],[0]
"= 16 log 2F T 2 .
",4.2. Moment-based Analysis,[0],[0]
Theorem 3.,4.2. Moment-based Analysis,[0],[0]
"With m = (M−m+1)C′ ⌧m−1 , Algorithm 1 with Option II incurs RegT = Õ",4.2. Moment-based Analysis,[0],[0]
"TL2,0 log F  with probability at least 1 − .",4.2. Moment-based Analysis,[0],[0]
We now move on to describe the performance guarantee for Algorithm 2.,4.2. Moment-based Analysis,[0],[0]
"Because this optimistic strategy does not explore as readily as the elimination-based strategy of Algorithm 1, the analysis requires both that (i) the IEC L
2, be invoked for some > 0 and (ii) that the algorithm use a warm-start period whose size grows as 1 2.",4.2. Moment-based Analysis,[0],[0]
Theorem 4.,4.2. Moment-based Analysis,[0],[0]
"With m = (M−m+1)C′ ⌧m−1 and M0 = 2 + log
2
 1 + (2M+3)L1C′ 2  for any ∈ (0,1), Algorithm 2
incurs RegT = Õ L1 logF  2 +TL2, log F  with probability at least 1 − .",4.2. Moment-based Analysis,[0],[0]
"As Algorithm 2 requires a warm start, the regret bounds of Theorem 4 are always worse than those of Theorem 3.",4.2. Moment-based Analysis,[0],[0]
"Appendix A.4 contains full versions of these theorems, Theorem 6 and Theorem 7, which obtain faster rates under the Massart noise condition and apply to infinite classes.
",4.2. Moment-based Analysis,[0],[0]
"Linear classes For concreteness, let us discuss the regret of both algorithms in a linear setting with a fixed feature map ∶ X ×A → Rd and F = {(x, a) w",4.2. Moment-based Analysis,[0],[0]
"(x, a) w ∈W} for some W ⊆ Rd (e.g., as in LinUCB).",4.2. Moment-based Analysis,[0],[0]
"In the basic ` 2 -bounded case, L 1 and L 2, can be bounded in terms of the minimum eigenvalues of Ex[ (x, a) (x, a)] and Ex1{x ∈ U (a)} (x, a) (x, a), respectively.",4.2. Moment-based Analysis,[0],[0]
When predictors are s-sparse we can instead obtain bounds in terms of (A) ∶= minw≠0∶ w0≤2swAw,4.2. Moment-based Analysis,[0],[0]
"ww, the minimum restricted eigenvalue for 2s-sparse predictors (Raskutti et al., 2010).",4.2. Moment-based Analysis,[0],[0]
"For Algorithm 1 this yields a near dimensionindependent bound on RegT of Õ sKT log d  Ex (x,⇡(x))",4.2. Moment-based Analysis,[0],[0]
"(x,⇡(x))",4.2. Moment-based Analysis,[0],[0]
.1,4.2. Moment-based Analysis,[0],[0]
"This improves upon the moment matrix conditions of Bastani & Bayati (2015), although our algorithm requires nonconvex optimization oracles.2 Note that without the scaling with K as in our result, a √ d dependence is unavoidable (Abbasi-Yadkori et al., 2012).",4.2. Moment-based Analysis,[0],[0]
"The result highlights the strengths of our analysis in the best case compared with eluder dimension, which does not adapt to sparsity structures.",4.2. Moment-based Analysis,[0],[0]
"On the other hand, for the standard LinUCB setting, our result is inferior by at least a factor of K.
Discussion Our analysis is influenced by the results of Bastani & Bayati (2015) for the (high-dimensional) linear setting, but extends to general classes F , and when applied to Algorithm 1 with linear classes, the assumed bound on
1See Proposition 3, Lemma 9, and Theorem 3 in the appendix.",4.2. Moment-based Analysis,[0],[0]
"2Also, since the class F is non-convex, this requires the slower
binary search algorithm of Krishnamurthy et al. (2017).
",4.2. Moment-based Analysis,[0],[0]
"L 2, is weaker than their “diversity condition”.",4.2. Moment-based Analysis,[0],[0]
"Similar assumptions have been used to analyze purely greedy linear contextual bandits (Bastani et al., 2017; Kannan et al., 2018); our assumptions are strictly weaker.",4.2. Moment-based Analysis,[0],[0]
We compared our new algorithms with existing oracle-based alternatives.,5. Experiments,[0],[0]
"In addition to showing that RegCB3 has strong empirical performance, our experiments provide a more extensive empirical study of oracle-based contextual bandit algorithms than any past works (e.g., Agarwal et al., 2014, Krishnamurthy et al., 2016).",5. Experiments,[0],[0]
"Description of the datasets, benchmark algorithms, and oracle configurations, as well as further experimental results are included in Appendix B.
Datasets We begin with 10 datasets with full reward information and simulate bandit feedback by withholding the rewards for actions not selected by the algorithm.",5. Experiments,[0],[0]
"We use two large-scale learning-to-rank datasets, Microsoft MSLRWEB30k (mslr) (Qin & Liu, 2010) and Yahoo!",5. Experiments,[0],[0]
"Learning to Rank Challenge V2.0 (yahoo) (Chapelle & Chang, 2011), which were previously used to evaluate contextual semibandits (Krishnamurthy et al., 2016).",5. Experiments,[0],[0]
"We also use eight classification datasets from the UCI repository (Lichman, 2013), summarized in Table 1 of Appendix B.1.
",5. Experiments,[0],[0]
"The ranking datasets have natural rewards (relevances), but the rewards for the classification datasets always have multiclass structure (1 for the correct action and 0 for all others).",5. Experiments,[0],[0]
"To ensure that we evaluate the full generality of the CB setting, we create eight “noisy” UCI datasets by sampling new rewards for the datasets according to a noisy reward matrix model described in Appendix B. This yields additional 8 datasets for a total of 18.",5. Experiments,[0],[0]
"On each dataset we consider several replicates obtained by randomly permuting examples and, on noisy UCI, also randomly generating rewards.",5. Experiments,[0],[0]
"All the methods are evaluated on the same set of replicates.
",5. Experiments,[0],[0]
"Algorithms We evaluate Algorithms 1 and 2 against three baselines, all based on various optimization-oracle assumptions.",5. Experiments,[0],[0]
"First two are agnostic baselines, ✏-Greedy (Langford & Zhang, 2008) and the minimax-optimal ILOVETOCONBANDITS (ILTCB) strategy of Agarwal et al. (2014).4
✏-Greedy and ILTCB both assume cost-sensitive classification oracles and come with theoretical guarantees.",5. Experiments,[0],[0]
"The third baseline is a bootstrapping-based exploration strategy of Dimakopoulou et al. (2017) (Bootstrap-TS), which uses bootstrapping to estimate confidence intervals and then performs Thompson sampling to select an action based on the intervals.",5. Experiments,[0],[0]
"This algorithm represents a computationally
3RegCB refers collectively to both Algorithms 1 and 2.",5. Experiments,[0],[0]
"4We use an implementation available at https://github.
com/akshaykr/oracle_cb, which was also used by Krishnamurthy et al. (2016).
tractable alternative to Thompson sampling as it works in the regression-oracle model we consider here, but it does not have a theoretical analysis.5
Note that the LinUCB algorithm (Chu et al., 2011; AbbasiYadkori et al., 2011), which is a natural baseline as well, coincides with our Algorithm 2 (with a linear oracle), so we only plot the performance of RegCB with a linear oracle.
",5. Experiments,[0],[0]
"All of the algorithms update on an epoch schedule with epoch lengths of 2i2, which is a theoretically rigorous choice for each algorithm.",5. Experiments,[0],[0]
"Oracles We consider two baseline predictor classes F : ` 2
- regularized linear functions (Linear) and gradient-boosted depth-5 regression trees (GB5) (Friedman, 2001).",5. Experiments,[0],[0]
"For the regularized linear class, Algorithm 2 is equivalent to LinUCB on an epoch schedule.6 See Appendix B.3 for details.
",5. Experiments,[0],[0]
"When running both RegCB variants with the GB5 oracle, we use a simple heuristic to substantially speed up the computation.",5. Experiments,[0],[0]
"At the beginning of each epoch m, we find the best regression-tree ensemble on the dataset so far (i.e., with respect to R̂m).",5. Experiments,[0],[0]
"Throughout the epoch, we keep the structure of the ensemble fixed and in each call to ORACLE(H) we only re-optimize the predictions in leaves.",5. Experiments,[0],[0]
"This can be solved in closed form, similar to LinUCB, so the full binary search procedure (Algorithm 3) does not need to be run.
",5. Experiments,[0],[0]
Parameter Tuning We evaluate each algorithm for eight exponentially spaced parameter values across five replicates.,5. Experiments,[0],[0]
"For ✏-Greedy we tune the constant ✏, and for ILTCB we tune a certain smoothing parameter (see Appendix B).",5. Experiments,[0],[0]
For Algorithms 1 and 2 we set m = for all m and tune .,5. Experiments,[0],[0]
For Algorithm 2 we use a warm start of 0.,5. Experiments,[0],[0]
"We tune a confidence parameter similar to for Bootstrap-TS.
",5. Experiments,[0],[0]
"Evaluation Each dataset is split into “training data”, for which algorithm receives one example at a time and must predict online, and a holdout validation set.",5. Experiments,[0],[0]
Validation is performed by simulating the algorithm’s predictions on examples from the holdout set without allowing the algorithm to incorporate these examples.,5. Experiments,[0],[0]
"We also plot the validation reward of a “supervised” baseline obtained by training the oracle (either Linear or GB5) on the entire training set at once (including rewards for all actions).
",5. Experiments,[0],[0]
For Algorithms 1 and 2 we show average reward at various numbers of training examples for the best fixed parameter value in each dataset.,5. Experiments,[0],[0]
"For the baselines, we take the pointwise maximum of the average reward across all parameter values for each number of examples.",5. Experiments,[0],[0]
"Thus,
5It is not known how to implement the standard formulation of Thompson sampling for contextual bandits (e.g., Russo & Van Roy 2013) with optimization oracles.
",5. Experiments,[0],[0]
"6More precisely, it is equivalent to the well-known OFUL variant of LinUCB (Abbasi-Yadkori et al., 2011).
",5. Experiments,[0],[0]
"the curves for our methods correspond to an actual run of the algorithm, while the baselines are an upper envelope aggregating multiple parameter values.
",5. Experiments,[0],[0]
"Results: Performance Figure 1 shows average reward of each algorithm on a holdout validation set for three representative datasets, letter from UCI, letter-noise (the variant with simulated rewards), and yahoo.
",5. Experiments,[0],[0]
"RegCB (both Algorithms 1 and 2) outperforms all baselines on the unmodified UCI datasets (e.g., letter in Figure 1).",5. Experiments,[0],[0]
"On the noisy variants (e.g., letter+N in Figure 1), the performance of the ILTCB and Bootstrap-TS benchmarks improves significantly, with Bootstrap-TS slightly edging out the rest of the algorithms.",5. Experiments,[0],[0]
"On the yahoo ranking dataset (Figure 1, right), the ordering of the algorithms in performance is similar to noisy UCI datasets.
",5. Experiments,[0],[0]
"Validation performance plots for all datasets are in Appendix B. Overall, RegCB methods and Bootstrap-TS generally dominate the field.",5. Experiments,[0],[0]
"While Bootstrap-TS can outperform RegCB methods when using GB5 models, the gap is typically quite small.",5. Experiments,[0],[0]
"For linear models, RegCB methods generally outperform Bootstrap-TS, hinting that the approximate binary search might be hurting RegCB with GB5 models.",5. Experiments,[0],[0]
"We also observe that when RegCB methods outperform Bootstrap-TS, the gap is often quite large.",5. Experiments,[0],[0]
"We will see further evidence of this behavior in the next set of results.
",5. Experiments,[0],[0]
"Results: Aggregate Performance To rigorously draw conclusions about overall performance, Figure 2 aggregates performance across all datasets.",5. Experiments,[0],[0]
"We compute “normalized relative loss” for each algorithm by rescaling the validation reward (computed as in Figure 1) so that, at each round, the best performing algorithm has loss 0 and the worst has loss 1.",5. Experiments,[0],[0]
"In each plot of Figure 2 we consider normalized relative losses at a specific cutoff time (1000 examples in the left plot, and all examples in the center and right), and for each method we plot the number of datasets where it achieves loss below a threshold, as a function of the threshold.",5. Experiments,[0],[0]
"Thus, curves towards top left corner correspond to methods that achieve lower relative loss on more datasets.",5. Experiments,[0],[0]
"The intercept at loss 0 is the number of datasets where an algorithm is the best, and the intercept at 0.99 is the number of datasets where the it is not the worst (so the distance from top is the number of datasets where it is the worst).",5. Experiments,[0],[0]
"Solid lines are runs with GB5 and dashed lines are with the Linear oracle.
",5. Experiments,[0],[0]
"The aggregate performance with the GB5 oracle across all datasets can be briefly summarized as follows: RegCB always beats ✏-Greedy and ILTCB, but sometimes loses out to Bootstrap-TS, and Bootstrap-TS itself sometimes underperforms relative to the other baselines, especially on the UCI datasets.",5. Experiments,[0],[0]
"Even when RegCB is not the best, it is almost always within 20% of the best.",5. Experiments,[0],[0]
"The elimination and optimistic variants of RegCB have comparable performance,
with elimination performing slightly better in aggregate.
",5. Experiments,[0],[0]
"The RegCB algorithms with the GB5 oracle also dominate the ✏-Greedy, ILTCB, and Bootstrap-TS baselines when they are equipped with Linear oracles (the dashed lines in Figure 2).",5. Experiments,[0],[0]
"When the RegCB algorithms use the Linear oracle they also dominate the baselines with the Linear oracle across all datasets, including Bootstrap-TS.7",5. Experiments,[0],[0]
"This suggests that the gap between RegCB and Bootstrap-TS for GB5 may be due to the approximation of fixing the ensemble structure in each epoch, as noted earlier.
",5. Experiments,[0],[0]
Results: Confidence Width,5. Experiments,[0],[0]
The analysis of RegCB relies on assumptions on D (disagreement coefficient or moment parameters) that are not easy to verify.,5. Experiments,[0],[0]
"The main role of these parameters is to control the rate at which confidence width WFm(xt, a) = HIGHFm(xt, a) − LOWFm(xt, a) used in RegCB shrinks, since small widths imply that the algorithm makes good decisions and thus has low regret.
",5. Experiments,[0],[0]
"To investigate whether the width indeed shrinks empirically, we compute WFm(xt, a) on each dataset for Algorithm 2 and Bootstrap-TS, where a is the “optimistic” action with highest upper confidence bound under each algorithm.",5. Experiments,[0],[0]
"Finally for both Algorithm 2 and Bootstrap-TS we compute the size of the “disagreement set” At, defined in Algorithm 1, which measures how many actions the algorithm thinks are plausibly best.8
Figure 3 shows width and disagreement for a representative sample of datasets under the GB5 oracle; the remaining datasets are in Appendix B. The figure suggests that our distributional assumptions are reasonable for real-world datasets.",5. Experiments,[0],[0]
"In particular, for our algorithm, the width decays roughly as T −13 for letter and T −12 for letter+N and yahoo.",5. Experiments,[0],[0]
"Interestingly, the best hyper-parameter setting for Bootstrap-TS on letter yields low but essentially constant (i.e., not shrinking) width, and obtains a poor validation reward in Figure 1 (left).",5. Experiments,[0],[0]
"This suggests that while the Bootstrap-TS confidence intervals are small, they may not be faithful in the sense of containing f(x, a).",5. Experiments,[0],[0]
This work serves as a starting point for what we hope will be a fruitful line of research on oracle-efficient contextual bandit algorithms in realizability-based settings.,6. Conclusion and Discussion,[0],[0]
"We have shown that the RegCB family of algorithms have strong empirical performance and enjoy nice theoretical properties.
7The aggregate plots for RegCB with the Linear oracle can be found in Appendix B along with additional aggregate plots.
8This set is well-defined for both RegCB-Opt and Bootstrap-TS even through neither algorithm instantiates it explicitly.",6. Conclusion and Discussion,[0],[0]
"For the yahoo and mslr datasets this At is technically a lower bound on the true disagreement set size AFm(xt) because our classesF do not have product structure on these datasets—see Section 4.1.
",6. Conclusion and Discussion,[0],[0]
"These results suggest several compelling future directions.
",6. Conclusion and Discussion,[0],[0]
"First, is there a regression oracle–based algorithm that achieves the optimal Õ(KT log F ) regret?",6. Conclusion and Discussion,[0],[0]
"For example, is it possible to oraclize regressor elimination of Agarwal et al. (2012)?
Second, given the competitive empirical performance of
Bootstrap-TS, are there reasonable assumptions as in Section 4 under which it can be analyzed?",6. Conclusion and Discussion,[0],[0]
"There is recent work in this direction for linear models (Lu & Van Roy, 2017).
",6. Conclusion and Discussion,[0],[0]
"Finally, randomizing uniformly or putting all the mass on the optimistic choice are two extreme cases of choosing amongst the plausibly optimal actions.",6. Conclusion and Discussion,[0],[0]
Are there better randomization schemes that lead to stronger regret guarantees?,6. Conclusion and Discussion,[0],[0]
We thank Akshay Krishnamurthy and Alberto Bietti for helpful discussions.,Acknowledgements,[0],[0]
A major challenge in contextual bandits is to design general-purpose algorithms that are both practically useful and theoretically well-founded.,abstractText,[0],[0]
We present a new technique that has the empirical and computational advantages of realizabilitybased approaches combined with the flexibility of agnostic methods.,abstractText,[0],[0]
"Our algorithms leverage the availability of a regression oracle for the valuefunction class, a more realistic and reasonable oracle than the classification oracles over policies typically assumed by agnostic methods.",abstractText,[0],[0]
Our approach generalizes both UCB and LinUCB to far more expressive possible model classes and achieves low regret under certain distributional assumptions.,abstractText,[0],[0]
"In an extensive empirical evaluation, we find that our approach typically matches or outperforms both realizability-based and agnostic baselines.",abstractText,[0],[0]
Practical Contextual Bandits with Regression Oracles,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 439–443 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"The success of automatic image captioning (Farhadi et al., 2010; Mitchell et al., 2012; Karpathy and Fei-Fei, 2015; Vinyals et al., 2015) demonstrates compellingly that end-to-end statistical models can align visual information with language.",1 Introduction,[0],[0]
"However, high-quality captions are not merely true, but also pragmatically informative in the sense that they highlight salient properties and help distinguish their inputs from similar images.",1 Introduction,[0],[0]
"Captioning systems trained on single images struggle to be pragmatic in this sense, producing either very general or hyper-specific descriptions.
",1 Introduction,[0],[0]
"In this paper, we present a neural image captioning system1 that is a pragmatic speaker as defined by the Rational Speech Acts (RSA) model (Frank and Goodman, 2012; Goodman and Stuhlmüller,
1The code is available at https://github.com/ reubenharry/Recurrent-RSA
2013).",1 Introduction,[0],[0]
"Given a set of images, of which one is the target, its objective is to generate a natural language expression which identifies the target in this context.",1 Introduction,[0],[0]
"For instance, the literal caption in Figure 1 could describe both the target and the top two distractors, whereas the pragmatic caption mentions something that is most salient of the target.",1 Introduction,[0],[0]
"Intuitively, the RSA speaker achieves this by reasoning not only about what is true but also about what it’s like to be a listener in this context trying to identify the target.
",1 Introduction,[0],[0]
"This core idea underlies much work in referring expression generation (Dale and Reiter, 1995; Monroe and Potts, 2015; Andreas and Klein, 2016; Monroe et al., 2017) and image captioning (Mao et al., 2016a; Vedantam et al., 2017), but these models do not fully confront the fact that the agents must reason about all possible utterances, which is intractable.",1 Introduction,[0],[0]
"We fully address this problem by implementing RSA at the level of characters rather than the level of utterances or words: the neural language model emits individual characters, choosing them to balance pragmatic informativeness with overall well-formedness.",1 Introduction,[0],[0]
"Thus, the agents reason not about full utterances, but rather only about all possible character choices, a very small space.",1 Introduction,[0],[0]
"The result is that the information encoded recurrently in the neural model allows us
439
to obtain global pragmatic effects from local decisions.",1 Introduction,[0],[0]
"We show that such character-level RSA speakers are more effective than literal captioning systems at the task of helping a reader identify the target image among close competitors, and outperform word-level RSA captioners in both efficiency and accuracy.",1 Introduction,[0],[0]
"In applying RSA to image captioning, we think of captioning as a kind of reference game.",2 Bayesian Pragmatics for Captioning,[0],[0]
"The speaker and listener are in a shared context consisting of a set of images W , the speaker is privately assigned a target image w⇤ 2 W , and the speaker’s goal is to produce a caption that will enable the listener to identify w⇤.",2 Bayesian Pragmatics for Captioning,[0],[0]
U is the set of possible utterances.,2 Bayesian Pragmatics for Captioning,[0],[0]
"In its simplest form, the literal speaker is a conditional distribution S0(u|w) assigning equal probability to all true utterances u 2 U and 0 to all others.",2 Bayesian Pragmatics for Captioning,[0],[0]
"The pragmatic listener L0 is then defined in terms of this literal agent and a prior P (w) over possible images:
L0(w|u) / S0(u|w) ⇤ P (w)P
w02W S0(u|w0) ⇤ P (w0) (1)
",2 Bayesian Pragmatics for Captioning,[0],[0]
"The pragmatic speaker S1 is then defined in terms of this pragmatic listener, with the addition of a rationality parameter ↵ > 0",2 Bayesian Pragmatics for Captioning,[0],[0]
governing how much it takes into account the L0 distribution when choosing utterances.,2 Bayesian Pragmatics for Captioning,[0],[0]
"P (u) is here taken to be a uniform distribution over U :
S1(u|w) / L0(w|u",2 Bayesian Pragmatics for Captioning,[0],[0]
),2 Bayesian Pragmatics for Captioning,[0],[0]
"↵ ⇤ P (u)P
u02U L0(w|u0)↵ ⇤ P (u0) (2)
",2 Bayesian Pragmatics for Captioning,[0],[0]
"As a result of this back-and-forth, the S1 speaker is reasoning not merely about what is true, but rather about a listener reasoning about a literal speaker who reasons about truth.
",2 Bayesian Pragmatics for Captioning,[0],[0]
"To illustrate, consider the pair of images 2a and 2b in Figure 2.",2 Bayesian Pragmatics for Captioning,[0],[0]
"Suppose that U = {bus, red bus}.",2 Bayesian Pragmatics for Captioning,[0],[0]
Then the literal speaker S0 is equally likely to produce bus and red bus when the left image 2a is the target.,2 Bayesian Pragmatics for Captioning,[0],[0]
"However, L0 breaks this symmetry; because red bus is false of the right bus, L0(2a|bus) = 13 and L0(2b|bus) = 23 .",2 Bayesian Pragmatics for Captioning,[0],[0]
"The S1 speaker therefore ends up favoring red bus when trying to convey 2a, so that S1(red bus|2a) = 34 and S1(bus|2a)",2 Bayesian Pragmatics for Captioning,[0],[0]
= 14 .,2 Bayesian Pragmatics for Captioning,[0],[0]
"To apply the RSA model to image captioning, we first train a neural model with a CNN-RNN architecture (Karpathy and Fei-Fei, 2015; Vinyals et al., 2015).",3 Applying Bayesian Pragmatics to a Neural Semantics,[0],[0]
The trained model can be considered an S0-style distribution P (caption|image) on top of which further listeners and speakers can be built.,3 Applying Bayesian Pragmatics to a Neural Semantics,[0],[0]
"(Unlike the idealized S0 described above, a neural S0 will assign some probability to untrue utterances.)
",3 Applying Bayesian Pragmatics to a Neural Semantics,[0],[0]
"The main challenge for this application is that the space of utterances (captions) U will be very large for any suitable captioning system, making the calculation of S1 intractable due to its normalization over all utterances.",3 Applying Bayesian Pragmatics to a Neural Semantics,[0],[0]
"The question, therefore, is how best to approximate this inference.",3 Applying Bayesian Pragmatics to a Neural Semantics,[0],[0]
"The solution employed by Monroe et al. (2017) and Andreas and Klein (2016) is to sample a small subset of probable utterances from the S0, as an approximate prior upon which exact inference can be performed.",3 Applying Bayesian Pragmatics to a Neural Semantics,[0],[0]
"While tractable, this approach has the shortcoming of only considering a small part of the true prior, which potentially decreases the extent to which pragmatic reasoning will be able to apply.",3 Applying Bayesian Pragmatics to a Neural Semantics,[0],[0]
"In particular, if a useful caption never appears in the sampled prior, it cannot appear in the posterior.",3 Applying Bayesian Pragmatics to a Neural Semantics,[0],[0]
"Inspired by the success of the “emittorsuppressor” method of Vedantam et al. (2017), we propose an incremental version of RSA.",3.1 Step-Wise Inference,[0],[0]
"Rather than performing a single inference over utterances, we perform an inference for each step of the unrolling of the utterance.
",3.1 Step-Wise Inference,[0],[0]
"We use a character-level LSTM, which defines a distribution over characters P (u|pc, image), where pc (“partial caption”) is a string of char-
acters constituting the caption so far and u is the next character of the caption.",3.1 Step-Wise Inference,[0],[0]
"This is now our S0: given a partially generated caption and an image, it returns a distribution over which character should next be added to the caption.",3.1 Step-Wise Inference,[0],[0]
"The advantage of using a character-level LSTM over a word-level one is that U is much smaller for the former (⇡30 vs. ⇡20, 000), making the ensuing RSA model much more efficient.
",3.1 Step-Wise Inference,[0],[0]
"We use this S0 to define an L0 which takes a partial caption and a new character, and returns a distribution over images.",3.1 Step-Wise Inference,[0],[0]
"The S1, in turn, given a target image w⇤, performs an inference over the set of possible characters to determine which is best with respect to the listener choosing w⇤.
",3.1 Step-Wise Inference,[0],[0]
"At timestep t of the unrolling, the listener L0 takes as its prior over images the L0 posterior from timestep (t 1).",3.1 Step-Wise Inference,[0],[0]
"The idea is that as we proceed with the unrolling, the L0 priors on which image is being referred to may change, which in turn should affect the speaker’s actions.",3.1 Step-Wise Inference,[0],[0]
"For instance, the speaker, having made the listener strongly in favor of the target image, is less compelled to continue being pragmatic.",3.1 Step-Wise Inference,[0],[0]
"In our incremental RSA, speaker models take both a target image and a partial caption pc.",3.2 Model Definition,[0],[0]
"Thus, S0 is a neurally trained conditional distribution St0(u|w, pct), where t is the current timestep of the unrolling and u is a character.
",3.2 Model Definition,[0],[0]
"We define the Lt0 in terms of the S t 0 as follows, where ip is a distribution over images representing the L0 prior:
Lt0(w|u, ipt, pct) / St0(u|w, pct) ⇤ ipt(w) (3)
",3.2 Model Definition,[0],[0]
"Given an St0 and L t 0, we define S t 1 and L t 1 as:
St1(u|w, ipt, pct) / St0(u|w, pct) ⇤ Lt0(w|u, ipt, pct)↵ (4)
Lt1(w|u, ipt, pct) / Lt0(w|u, ipt, pct) ⇤ St0(u|w, pct) (5)
",3.2 Model Definition,[0],[0]
"Unrolling To perform greedy unrolling (though in practice we use a beam search) for either S0 or S1, we initialize the state as a partial caption pc0 consisting of only the start token and a uniform prior over the images ip0.",3.2 Model Definition,[0],[0]
"Then, for t > 0, we use our incremental speaker model S0 or S1 to
generate a distribution over the subsequent character St(u|w, ipt, pct), and add the character u with highest probability density to pct, giving us pct+1.",3.2 Model Definition,[0],[0]
"We then run our listener model L1 on u, to obtain a distribution ipt+1 = L t 1(w|u, ipt, pct) over images that the L0 can use at the next timestep.",3.2 Model Definition,[0],[0]
"This incremental approach keeps the inference itself very simple, while placing the complexity of the model in the recurrent nature of the unrolling.2 While our S0 is character-level, the same incremental RSA model works for a word-level S0, giving rise to a word-level S1.",3.2 Model Definition,[0],[0]
"We compare character and word S1s in section 4.2.
",3.2 Model Definition,[0],[0]
"As well as being incremental, these definitions of St1 and L t 1 differ from the typical RSA described in section 2 in that St1 and L t 1 draw their priors from St0 and L t 0 respectively.",3.2 Model Definition,[0],[0]
This generalizes the scheme put forward for S1 by Andreas and Klein (2016).,3.2 Model Definition,[0],[0]
The motivation is to have Bayesian speakers who are somewhat constrained by the S0 language model.,3.2 Model Definition,[0],[0]
"Without this, other methods are needed to achieve English-like captions, as in Vedantam et al. (2017), where their equivalent of the S1 is combined in a weighted sum with the S0.",3.2 Model Definition,[0],[0]
"Qualitatively, Figures 1 and 2 show how the S1 captions are more informative than the S0, as a result of pragmatic considerations.",4 Evaluation,[0],[0]
"To demonstrate the effectiveness of our method quantitatively, we implement an automatic evaluation.",4 Evaluation,[0],[0]
"To evaluate the success of S1 as compared to S0, we define a listener Leval(image|caption) / PS0(caption|image), where PS0(caption|image) is the total probability of S0 incrementally generating caption given image.",4.1 Automatic Evaluation,[0],[0]
"In other words, Leval uses Bayes’ rule to obtain from S0 the posterior probability of each image w given a full caption u.
The neural S0 used in the definition of Leval must be trained on separate data to the neural S0 used for the S1 model which produces captions, since otherwise this S1 production model effectively has access to the system evaluating it.",4.1 Automatic Evaluation,[0],[0]
"As Mao et al. (2016b) note, “a model might ‘com-
2The move from standard to incremental RSA can be understood as a switching of the order of two operations; instead of unrolling a character-level distribution into a sentence level one and then applying pragmatics, we apply pragmatics and then unroll.",4.1 Automatic Evaluation,[0],[0]
"This generalizes to any recursive generation of utterances.
",4.1 Automatic Evaluation,[0],[0]
municate’ better with itself using its own language than with others”.,4.1 Automatic Evaluation,[0],[0]
"In evaluation, we therefore split the training data in half, with one part for training the S0 used in the caption generation model S1 and one part for training the S0 used in the caption evaluation model Leval.
",4.1 Automatic Evaluation,[0],[0]
"We say that the caption succeeds as a referring expression if the target has more probability mass under the distribution Leval(image|caption) than any distractor.
",4.1 Automatic Evaluation,[0],[0]
"Dataset We train our production and evaluation models on separate sets consisting of regions in the Visual Genome dataset (Krishna et al., 2017) and full images in MSCOCO (Chen et al., 2015).",4.1 Automatic Evaluation,[0],[0]
"Both datasets consist of over 100,000 images of common objects and scenes.",4.1 Automatic Evaluation,[0],[0]
"MSCOCO provides captions for whole images, while Visual Genome provides captions for regions within images.
",4.1 Automatic Evaluation,[0],[0]
Our test sets consist of clusters of 10 images.,4.1 Automatic Evaluation,[0],[0]
"For a given cluster, we set each image in it as the target, in turn.",4.1 Automatic Evaluation,[0],[0]
We use two test sets.,4.1 Automatic Evaluation,[0],[0]
"Test set 1 (TS1) consists of 100 clusters of images, 10 for each of the 10 most common objects in Visual Genome.3 Test set 2 (TS2) consists of regions in Visual Genome images whose ground truth captions have high word overlap, an indicator that they are similar.",4.1 Automatic Evaluation,[0],[0]
We again select 100 clusters of 10.,4.1 Automatic Evaluation,[0],[0]
"Both test sets have 1,000 items in total (10 potential target images for each of 100 clusters).
",4.1 Automatic Evaluation,[0],[0]
"Captioning System Our neural image captioning system is a CNN-RNN architecture4 adapted to use a character-based LSTM for the language model.
",4.1 Automatic Evaluation,[0],[0]
"Hyperparameters We use a beam search with width 10 to produce captions, and a rationality parameter of ↵ = 5.0 for the S1.",4.1 Automatic Evaluation,[0],[0]
"As shown in Table 1, the character-level S1 obtains higher accuracy (68% on TS1 and 65.9% on TS2) than the S0 (48.9% on TS1 and 47.5% on TS2), demonstrating that S1 is better than S0 at referring.
",4.2 Results,[0],[0]
"Advantage of Incremental RSA We also observe that 66% percent of the times in which the S1 caption is referentially successful and the S0
3Namely, man, person, woman, building, sign, table, bus, window, sky, and tree.
",4.2 Results,[0],[0]
"4https://github.com/yunjey/ pytorch-tutorial/tree/master/tutorials/ 03-advanced/image_captioning
caption is not, for a given image, the S1 caption is not one of the top 50 S0 captions, as generated by the beam search unrolling at S0.",4.2 Results,[0],[0]
"This means that in these cases the non-incremental RSA method of Andreas and Klein (2016) could not have generated the S1 caption, if these top 50 S0 captions were the support of the prior over utterances.
",4.2 Results,[0],[0]
Comparison to Word-Level RSA We compare the performance of our character-level model to a word-level model.5,4.2 Results,[0],[0]
"This model is incremental in precisely the way defined in section 3.2, but uses a word-level LSTM so that u 2 U are words and U is a vocabulary of English.",4.2 Results,[0],[0]
"It is evaluated with an Leval model that also operates on the word level.
",4.2 Results,[0],[0]
"Though the word S0 performs better on both test sets than the character S0, the character S1 outperforms the word S1, demonstrating the advantage of a character-level model for pragmatic behavior.",4.2 Results,[0],[0]
"We conjecture that the superiority of the characterlevel model is the result of the increased number of decisions where pragmatics can be taken into account, but leave further examination for future research.
",4.2 Results,[0],[0]
Variants of the Model We further explore the effect of two design decisions in the characterlevel model.,4.2 Results,[0],[0]
"First, we consider a variant of S1 which has a prior over utterances determined by an LSTM language model trained on the full set of captions.",4.2 Results,[0],[0]
This achieves an accuracy of 67.2% on TS1.,4.2 Results,[0],[0]
"Second, we consider our standard S1 but with unrolling such that the L0 prior is drawn uniformly at each timestep rather than determined by the L0 posterior at the previous step.",4.2 Results,[0],[0]
This achieves an accuracy of 67.4% on TS1.,4.2 Results,[0],[0]
"This suggests that neither this change of S1 nor L0 priors has a large effect on the performance of the model.
",4.2 Results,[0],[0]
"5Here, we use greedy unrolling, for reasons of efficiency due to the size of U for the word-level model, and set ↵ = 1.0 from tuning on validation data.",4.2 Results,[0],[0]
"For comparison, we note that greedy character-level S1 achieves an accuracy of 61.2% on TS1.",4.2 Results,[0],[0]
We show that incremental RSA at the level of characters improves the ability of the neural image captioner to refer to a target image.,5 Conclusion,[0],[0]
"The incremental approach is key to combining RSA with language models: as utterances become longer, it becomes exponentially slower, for a fixed n, to subsample n% of the utterance distribution and then perform inference (non-incremental approach).",5 Conclusion,[0],[0]
"Furthermore, character-level RSA yields better results than word-level RSA and is far more efficient.",5 Conclusion,[0],[0]
"Many thanks to Hiroto Udagawa and Poorvi Bhargava, who were involved in early versions of this project.",Acknowledgments,[0],[0]
This material is based in part upon work supported by the Stanford Data Science Initiative and by the NSF under Grant No. BCS-1456077.,Acknowledgments,[0],[0]
This work is also supported by a Sloan Foundation Research Fellowship to Noah Goodman.,Acknowledgments,[0],[0]
We combine a neural image captioner with a Rational Speech Acts (RSA) model to make a system that is pragmatically informative: its objective is to produce captions that are not merely true but also distinguish their inputs from similar images.,abstractText,[0],[0]
Previous attempts to combine RSA with neural image captioning require an inference which normalizes over the entire set of possible utterances.,abstractText,[0],[0]
"This poses a serious problem of efficiency, previously solved by sampling a small subset of possible utterances.",abstractText,[0],[0]
"We instead solve this problem by implementing a version of RSA which operates at the level of characters (“a”,“b”,“c”, . . . )",abstractText,[0],[0]
during the unrolling of the caption.,abstractText,[0],[0]
We find that the utterance-level effect of referential captions can be obtained with only characterlevel decisions.,abstractText,[0],[0]
"Finally, we introduce an automatic method for testing the performance of pragmatic speaker models, and show that our model outperforms a non-pragmatic baseline as well as a word-level RSA captioner.",abstractText,[0],[0]
Pragmatically Informative Image Captioning with Character-Level Inference,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 172–181 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
172",text,[0],[0]
"Coreference resolution, identifying mentions that refer to the same entities, is an important NLP problem.",1 Introduction,[0],[0]
"Resolving coreference is critical for many downstream applications, such as reading comprehension, translation, and text summarization.",1 Introduction,[0],[0]
"Identifying a mention depends not only on its lexicons but also its contexts, and requires representations of all the entities before the mention.",1 Introduction,[0],[0]
This is still a challenging task for the approaches based on the cutting-edge word2vec-like lexical representation.,1 Introduction,[0],[0]
"For example, it is hard to identify the mention “he” between two entities “Tom” and “Jerry” because they have almost the same word embeddings.
",1 Introduction,[0],[0]
"A number of datasets have been proposed to study the coreference resolution problem, such as MUC (Hirschman and Chinchor, 1997), ACE
(Doddington et al., 2004), and OntoNotes (Pradhan et al., 2012).",1 Introduction,[0],[0]
"The most popular one is OntoNotes, and recent work on coreference resolution (Clark and Manning, 2016a,b; Lee et al., 2017; Peters et al., 2018) evaluated their models on it.",1 Introduction,[0],[0]
"Other datasets were rarely studied after OntoNotes was published.
",1 Introduction,[0],[0]
"Previous work (Sadat Moosavi and Strube, 2017) suggests that the overlap between training and test sets makes significant impact on the performance of current coreference resolvers.",1 Introduction,[0],[0]
"In OntoNotes, which has relatively low training-test overlap, this impact is mixed together with the core challenges of coreference resolution.",1 Introduction,[0],[0]
"For example, consider the failure of referencing “them” to “the wounded” in “..., the wounded were carried off so fast and it was difficult to count them”.",1 Introduction,[0],[0]
It is hard to tell whether the algorithm can succeed if the currently low-frequency phrase “the wounded” has not been seen enough times in the training set.,1 Introduction,[0],[0]
"From a machine learning perspective, high overlap is needed to ensure that the training and test datasets have similar statistics.
",1 Introduction,[0],[0]
"Another limitation of OntoNotes is that it only has annotations for non-singleton mentions, while singleton mentions are not annotated.",1 Introduction,[0],[0]
"Most of the algorithms for coreference resolution have two steps: mention detection and mention clustering (Wiseman et al., 2016; Clark and Manning, 2016a,b).",1 Introduction,[0],[0]
"The lack of singleton mention annotations makes training and evaluation of mention detectors more difficult.
",1 Introduction,[0],[0]
"To address both limitations of OntoNotes, we build a new dataset, PreCo.",1 Introduction,[0],[0]
"To alleviate the negative impact of low training-test overlap, we restrict the data domain and collect a sufficient amount of data to achieve a relatively high training-test overlap.",1 Introduction,[0],[0]
"Restricting the data domain is a common way to enable better studies of unsolved NLP tasks, such as language modeling (Hill et al., 2015) and
visual question answering (Johnson et al., 2017).",1 Introduction,[0],[0]
"We select our data from English reading comprehension tests for middle and high school Chinese students, which has several advantages.",1 Introduction,[0],[0]
"On one hand, the vocabulary size is appropriate.",1 Introduction,[0],[0]
The English vocabulary of a typical Chinese high school student contains about 3000 commonly used words.,1 Introduction,[0],[0]
"This is similar to the vocabulary of a preschool English-speaking child (Wikipedia, 2018).",1 Introduction,[0],[0]
Most words from the English tests are in this limited vocabulary.,1 Introduction,[0],[0]
"On the other hand, it is practical to collect enough data of this type from the Internet.",1 Introduction,[0],[0]
"With 12.5M words, PreCo is about 10 times larger than OntoNotes.",1 Introduction,[0],[0]
"Large scale datasets, e.g. ImageNet (Deng et al., 2009), SQuAD (Rajpurkar et al., 2016), have played an important role for driving computer vision and NLP forward.
",1 Introduction,[0],[0]
We use the rate of out-of-vocabulary (OOV) words between training and test sets to measure their overlap.,1 Introduction,[0],[0]
"PreCo shows much higher trainingtest overlap than OntoNotes by having an OOV rate of 0.8%, which is about 1/3 of OntoNotes’s 2.1%.",1 Introduction,[0],[0]
"At the same time, PreCo presents a good challenge for coreference resolution research since its documents are in the open domain and have various writing styles.",1 Introduction,[0],[0]
"We test a state-of-the-art
system (Peters et al., 2018) on PreCo and get an F1 score of 81.5.",1 Introduction,[0],[0]
"However, a modest human performance (87.9, which will be described in 4.1 ) is much higher, verifying there remain challenges.
",1 Introduction,[0],[0]
"To help training and evaluation of mention detection, we annotate singleton mentions in PreCo.",1 Introduction,[0],[0]
"Besides singleton mentions, we follow most other annotation rules of OntoNotes to label the new dataset.",1 Introduction,[0],[0]
"We show that in a state-of-the-art coreference resolution system (Peters et al., 2018), we can improve the model performance from 77.3 to 81.6 F1 on a training set of 2.5K PreCo documents by using an oracle mention detector, and the remaining gap of 18.4 F1 to the perfect 100 F1 can only be reduced by improving mention clustering.",1 Introduction,[0],[0]
"This indicates that future work should concern more about mention clustering than mention detection.
",1 Introduction,[0],[0]
"The advantages of our proposed dataset over existing ones in coreference resolution can be summarized as follows:
•",1 Introduction,[0],[0]
"Its OOV rate is about 1/3 of OntoNotes.
",1 Introduction,[0],[0]
"• It has about 10 times larger corpus size than OntoNotes.
",1 Introduction,[0],[0]
• It has annotated singleton mentions.,1 Introduction,[0],[0]
Existing Datasets.,2 Related Work,[0],[0]
"The first two resources for coreference resolution study were MUC-6 and MUC-7 (Hirschman and Chinchor, 1997).",2 Related Work,[0],[0]
"The MUC datasets are too small for training and testing, containing a total of 127 documents with 65K words.",2 Related Work,[0],[0]
"The next standard dataset was ACE (Doddington et al., 2004) which has a much larger corpus of 1M words.",2 Related Work,[0],[0]
But its annotations are restricted to a small subset of entities and are less consistent.,2 Related Work,[0],[0]
"OntoNotes (Pradhan et al., 2012) was presented to overcome those limitations.",2 Related Work,[0],[0]
"Machine learning based approaches, especially deep learning based, benefitted from this well annotated and large-scale (1.3M words) dataset.",2 Related Work,[0],[0]
"Continuous research on OntoNotes over the past 6 years improved performance by 10 F1 score (Durrett and Klein, 2013; Peters et al., 2018).",2 Related Work,[0],[0]
"Datasets after OntoNotes, such as WikiCoref (Ghaddar and Langlais, 2016), are seldom studied.",2 Related Work,[0],[0]
"Therefore, we mainly compare PreCo with OntoNotes in this paper.",2 Related Work,[0],[0]
"With a much larger scale, PreCo builds on the advantages of OntoNotes.",2 Related Work,[0],[0]
"Some of these existing datasets also have corpus in other languages, but we just focus on coreference resolution in English.
",2 Related Work,[0],[0]
Out-of-domain Evaluation.,2 Related Work,[0],[0]
"(Sadat Moosavi and Strube, 2017) show that if coreference resolvers mainly rely on lexical representation, as it is the case in state-of-the-art ones, they are weak at generalizing to unseen domains.",2 Related Work,[0],[0]
"Even in the seen domains, the low degree of overlap for non-pronominal mentions between the training and test sets cause serious deterioration of coreference resolution performance.",2 Related Work,[0],[0]
"As a conclusion, (Sadat Moosavi and Strube, 2017) suggested that out-of-domain evaluation is a must in the literature.",2 Related Work,[0],[0]
"But we think the problem can be relieved by expanding the training data for the target domains to increase overlap, so that the field can pay more attention to the other challenges of coreference resolution.
",2 Related Work,[0],[0]
Data Simplification.,2 Related Work,[0],[0]
Many simplified datasets were built to enable better study on unsolved tasks.,2 Related Work,[0],[0]
Such simplifications can guide researchers to the core problems and make data collection easier.,2 Related Work,[0],[0]
"For example, (Hill et al., 2015) introduced the Children’s Book Test to distinguish the task of predicting syntactic function words from that of predicting low-frequency words for language model.",2 Related Work,[0],[0]
"The dataset helped them to develop a generalizable model with explicit memory representations.
",2 Related Work,[0],[0]
The reading comprehension dataset SQuAD,2 Related Work,[0],[0]
"(Rajpurkar et al., 2016) imposes the constraint that every answer is always a segment of the input text.",2 Related Work,[0],[0]
"This constraint benefits both labeling and evaluation of the dataset, which has significant influences in terms of benchmarks.",2 Related Work,[0],[0]
"Similarly, the reinforcement learning literature develops algorithms by studying games instead of the real world environment (Mnih et al., 2013).",2 Related Work,[0],[0]
"We hope that, with high training-test overlap, PreCo can serve as a valuable resource for research on coreference resolution.",2 Related Work,[0],[0]
We discuss the data collection and annotation in this section.,3 Dataset Creation,[0],[0]
The overview of the process is shown in Figure 2.,3 Dataset Creation,[0],[0]
We crawl English tests from several web sites.,3.1 Corpus Collection,[0],[0]
The web pages often contain the full English tests in a lot of formats.,3.1 Corpus Collection,[0],[0]
We build an annotation website and hire annotators to manually extract the relevant contents.,3.1 Corpus Collection,[0],[0]
"We have a total of 80 part-time Chinese annotators, most of whom are university students.",3.1 Corpus Collection,[0],[0]
They are required to have a minimum score in standard English tests.,3.1 Corpus Collection,[0],[0]
"During annotation training, the annotators read the annotation rules, and take several practice tasks, in which they annotate sample articles, and their results are compared with ground truth side by side for them to study.",3.1 Corpus Collection,[0],[0]
"Before formal annotation, the annotators will need to pass an assessment.
",3.1 Corpus Collection,[0],[0]
"Some data cleaning is done during annotation, such as unifying paragraph separators, etc.",3.1 Corpus Collection,[0],[0]
The questions with answers in these tests are also extracted for future research.,3.1 Corpus Collection,[0],[0]
"Finally, we use NLTK’s sentence and word tokenizer (Bird et al., 2009) to tokenize the crawled text.
",3.1 Corpus Collection,[0],[0]
"In addition to having annotators manually clean the data, we also use heuristic rules to further clean the data.",3.1 Corpus Collection,[0],[0]
"For example, in some cases the whitespaces between two words are missing.",3.1 Corpus Collection,[0],[0]
We use a spell checker to identify and correct most of these cases.,3.1 Corpus Collection,[0],[0]
"We also use heuristic rules to fix some sentence partition boundaries, e.g., to make sure opening quotes are placed at the beginning of a sentence, instead of being wrongly placed at the end of a previous sentence (closing quotes are handled similarly).
",3.1 Corpus Collection,[0],[0]
"In addition to the crawled data, we include the
documents from the RACE dataset (Lai et al., 2017).",3.1 Corpus Collection,[0],[0]
"RACE is a reading comprehension dataset from English tests for middle and high school Chinese students, which has similar types of data sources as PreCo.",3.1 Corpus Collection,[0],[0]
"About 2/3 of PreCo documents are from the RACE dataset.
",3.1 Corpus Collection,[0],[0]
"Since documents are from several data sources, we want to remove duplicated documents, and documents that are not exactly the same but have a high rate of repetitions.",3.1 Corpus Collection,[0],[0]
The similarity of two documents D1 and D2 is estimated using the bagof-words model.,3.1 Corpus Collection,[0],[0]
Assume S1 and S2 are bag-ofwords multisets to represent the two documents.,3.1 Corpus Collection,[0],[0]
"The similarity between D1 and D2 is defined as max( |S1∩S2||S1| , |S1∩S2| |S2| ).",3.1 Corpus Collection,[0],[0]
"If the similarity between two documents are larger than 0.9, we remove the shorter one.",3.1 Corpus Collection,[0],[0]
This process is referred as deduplicate in Figure 2.,3.1 Corpus Collection,[0],[0]
The dataset has a total of 38K documents.,3.2 Data Partition,[0],[0]
"We use 500 documents for the development set, 500 documents for the test set, and the rest 37K documents for the training set.",3.2 Data Partition,[0],[0]
The development and test documents were randomly selected from RACE’s development and test sets.,3.2 Data Partition,[0],[0]
We manually annotate coreferences on these documents.,3.3 Coreference Annotation and Refinement,[0],[0]
"The annotation rules are slightly different from OntoNotes (Pradhan et al., 2012).",3.3 Coreference Annotation and Refinement,[0],[0]
We modify some of the rules to make the definition of coreference more consistent and easier to be understood by the annotators.,3.3 Coreference Annotation and Refinement,[0],[0]
"The major differences
are listed in Table 1.",3.3 Coreference Annotation and Refinement,[0],[0]
"Figure 1 shows an example document in PreCo with annotations.
",3.3 Coreference Annotation and Refinement,[0],[0]
"Good quality control of annotation is essential, since the rules are complicated and coreference resolution depends on meticulous reading of the whole document over and over.",3.3 Coreference Annotation and Refinement,[0],[0]
"We found that annotators get low recall and insufficient precision mainly because of negligence, as opposed to the lack of annotation rules or other ambiguities.",3.3 Coreference Annotation and Refinement,[0],[0]
"For example, two co-referred mentions could be far apart and require careful searches, and an annotator may miss it.",3.3 Coreference Annotation and Refinement,[0],[0]
Therefore we further refine annotations as shown in Figure 3.,3.3 Coreference Annotation and Refinement,[0],[0]
"Annotators can think about the complicated inconsistent cases when merging annotations, and the voting process will fix some errors while preserving the mentions and coreferences that are found only once by individual annotators.
",3.3 Coreference Annotation and Refinement,[0],[0]
The quality of different annotation processes is shown in Table 2.,3.3 Coreference Annotation and Refinement,[0],[0]
OntoNotes took 2 individual annotations for each document and got an adjudicated version based on them.,3.3 Coreference Annotation and Refinement,[0],[0]
"Taking the adjudicated version as ground truth, the average MUC score (Vilain et al., 1995) 1 of individual annota-
1MUC score is one of the metrics to evaluate the quality of coreference resolution.
tions is 89.6, and the inter-annotator MUC score is 83.0.",3.3 Coreference Annotation and Refinement,[0],[0]
The corresponding numbers for PreCo are 85.3 and 77.5.,3.3 Coreference Annotation and Refinement,[0],[0]
The actual gap of individual annotation quality between OntoNotes and PreCo is not as large as it looks like.,3.3 Coreference Annotation and Refinement,[0],[0]
"Note that, OntoNotes’s two individual coreference annotations of each document are based on the same syntactic annotations of the document, so they could be more consistent than PreCo’s which are annotated on raw text.",3.3 Coreference Annotation and Refinement,[0],[0]
"Therefore, if we want to fairly compare PreCo with OntoNotes, we should take into account OntoNotes’s inter-annotator consistency of syntactic parsing annotations.",3.3 Coreference Annotation and Refinement,[0],[0]
"As it has a rough upper bound of 98.5 F1 score according to the reannotation of English Treebank on OntoNotes by the principal annotator a year after the original annotation (Weischedel et al., 2011), we could infer that the individual annotation quality of PreCo is quite close to OntoNotes.
",3.3 Coreference Annotation and Refinement,[0],[0]
Labeling the whole dataset is costly because each annotation from scratch or comparison takes an average of about 10 minutes.,3.3 Coreference Annotation and Refinement,[0],[0]
Prompts from an algorithm do not help since they do not speed up the annotation much but instead introduce biases.,3.3 Coreference Annotation and Refinement,[0],[0]
We observed some biases when using an algorithm to help annotation.,3.3 Coreference Annotation and Refinement,[0],[0]
"We have two models, M1 and M2, and we have a test set T which is annotated manually, and a test set T ′ which uses prompts from model M1 to help annotation.",3.3 Coreference Annotation and Refinement,[0],[0]
"While M1 and M2 have similar performance on T , M1’s performance is much higher than M2’s on T ′, which shows the biases.
",3.3 Coreference Annotation and Refinement,[0],[0]
"Because of limited annotation resources, we have only finished the refinements on the devel-
opment and test sets with the process shown in Figure 3.",3.3 Coreference Annotation and Refinement,[0],[0]
"We refine the training set annotations as follows: for each document, two annotators annotate it separately, and a third annotator compares and merges the two annotations.",3.3 Coreference Annotation and Refinement,[0],[0]
We use a training set of 2.5K documents to quantify the impact of this annotation refinement to model performance.,3.3 Coreference Annotation and Refinement,[0],[0]
"Table 3 shows the model performances of the training set that is annotated once, and the training set of the merged annotation.",3.3 Coreference Annotation and Refinement,[0],[0]
The performance difference is quite significant.,3.3 Coreference Annotation and Refinement,[0],[0]
"Furthermore, the difference is consistent with Table 2: the “AB-merge” model has a similar precision as the “Once” model, but it has a much higher recall.",3.3 Coreference Annotation and Refinement,[0],[0]
It indicates that a further refinement of the training set such as DEF-voting could be essential.,3.3 Coreference Annotation and Refinement,[0],[0]
A more interesting question is: how to make the definition of coreference more consistent and executable?,3.3 Coreference Annotation and Refinement,[0],[0]
We leave it as future work.,3.3 Coreference Annotation and Refinement,[0],[0]
Table 4 shows some properties of OntoNotes and PreCo.,3.4 Dataset Properties,[0],[0]
"As intended, PreCo has a lower OOV rate than OntoNotes.",3.4 Dataset Properties,[0],[0]
"For a training set with vocabulary V and a test set with n tokens [t1, t2, ..., tn], ignoring the tokens with non-alphabetic characters, the OOV rate is defined by:∑
i o(ti)
n ,where o(ti) = { 0 if ti ∈ V 1 if ti /∈ V
The OOV rate can be extended to the rate of lowfrequency words which also indicates the trainingtest overlap, by simply replacing V in the definition above with the non-low-frequency vocabulary of the training set.",3.4 Dataset Properties,[0],[0]
We find that the OOV rate is consistent to the rates of low-frequency words in different levels.,3.4 Dataset Properties,[0],[0]
"So we use the OOV rate for convenience.
",3.4 Dataset Properties,[0],[0]
"In PreCo, about 50.8% of the mentions are singleton mentions.",3.4 Dataset Properties,[0],[0]
Figure 4 shows the distribution of cluster sizes within non-singleton clusters.,3.4 Dataset Properties,[0],[0]
The distribution is similar between OntoNotes and PreCo.,3.4 Dataset Properties,[0],[0]
"To verify our assumption that PreCo embodies the core challenges of coreference, we evaluate a strong baseline coreference resolver on it.",4 Analysis,[0],[0]
"Specifically, we (i) estimate the room for improvement of the baseline system to show that the dataset is challenging, (ii) study the impact of training-test overlap to model performance and error analysis to show the advantages of PreCo, and (iii) quan-
titatively evaluate the mention detector to understand the bottlenecks of the coreference resolution system.",4 Analysis,[0],[0]
"We use the end-to-end neural coreference resolver, E2E-Coref (Lee et al., 2017), enhanced by the deep contextualized word representations (Peters et al., 2018) as the baseline system, and we refer to this system as EE2E-Coref.",4.1 Baseline Performance,[0],[0]
"This is the state-ofthe-art model on OntoNotes, achieving a test average F1 score of 70.4, which is the main evaluation metric for coreference resolution.",4.1 Baseline Performance,[0],[0]
"The metric is computed by averaging the F1 of MUC, B3, and CEAFφ4, which are three metrics of coreference resolution that have different focuses.
",4.1 Baseline Performance,[0],[0]
Our implementation EE2E-Coref2 gets 81.5 Avg.,4.1 Baseline Performance,[0],[0]
F1 score on PreCo.,4.1 Baseline Performance,[0],[0]
"We follow the setting of most hyperparameters on OntoNotes and do gridsearch for the decay parameter of the learning rate and the size of the hidden layers on the development set, since these two hyperparameters are relatively sensitive to the scale of the training data.",4.1 Baseline Performance,[0],[0]
"The F1 score increment from OntoNotes to PreCo is probably due to the higher overlap between the training and test sets in PreCo.
",4.1 Baseline Performance,[0],[0]
"2It gets an F1 score of 70.0±0.3 on OntoNotes, slightly lower than the F1 score reported in the original paper.
",4.1 Baseline Performance,[0],[0]
We demonstrate three typical error cases made by EE2E-Coref on PreCo in Table 5.,4.1 Baseline Performance,[0],[0]
"Coreference resolution in these cases requires good understanding of multiple sentences, which is an open problem in NLP.",4.1 Baseline Performance,[0],[0]
"A capable entity representation for “them”, “another one” or “Dr. Watson” may help to resolve these error cases.",4.1 Baseline Performance,[0],[0]
We also compare the performance of EE2E-Coref with human performance to estimate the room for improvement on PreCo.,4.1 Baseline Performance,[0],[0]
"As described in Section 3.4, human annotators get low recall mostly due to negligence.",4.1 Baseline Performance,[0],[0]
So we use the AB-merge annotation to estimate human’s ability on coreference resolution.,4.1 Baseline Performance,[0],[0]
"The gap of performance between model and human is 6.4 F1 score, from 81.5 to 87.9.",4.1 Baseline Performance,[0],[0]
"The actual gap
is larger, since AB-merge still has some missed coreference annotations due to negligence.",4.1 Baseline Performance,[0],[0]
This shows that the dataset is challenging and encourages future research.,4.1 Baseline Performance,[0],[0]
"The error cases show the challenges as well.
",4.1 Baseline Performance,[0],[0]
Note that PreCo is not a general purpose dataset.,4.1 Baseline Performance,[0],[0]
"Our motivation of designing PreCo is to make it easier to improve coreference resolution algorithms, e.g., to make error analysis easier.",4.1 Baseline Performance,[0],[0]
It is not a goal of PreCo to generalize well on corpus from other domains.,4.1 Baseline Performance,[0],[0]
"Furthermore, we find that there are a certain amount of annotation errors in the development and test sets.",4.1 Baseline Performance,[0],[0]
"We suggest that researchers working on PreCo should be careful about these errors, especially after a model gets F1 score beyond 90.0.",4.1 Baseline Performance,[0],[0]
Training-test overlap makes significant impact on error analysis.,4.2 Impact of Training-test Overlap,[0],[0]
"Consider an error case of coreference resolution, if there are low-frequency words in the related mentions, then it will be hard to tell whether the algorithm can succeed if the words has not been seen enough times in the training set.",4.2 Impact of Training-test Overlap,[0],[0]
We call an error case LFW if there are low-frequency words3 in its related mentions4.,4.2 Impact of Training-test Overlap,[0],[0]
"Therefore, the lower LFW rate a training set contains, the more precisely it may expose the drawbacks of the algorithm.
",4.2 Impact of Training-test Overlap,[0],[0]
"To study the impact of training-test overlap, actually, the training-dev overlap, we pick different subsets from the training data and evaluate the models trained on them.",4.2 Impact of Training-test Overlap,[0],[0]
"At first, we control overlap by picking different sizes of the training data randomly.",4.2 Impact of Training-test Overlap,[0],[0]
"Figure 5(a) shows that, as the training data size grows, the OOV rate, which is the overlap indicator, decreases and the F1 score of EE2ECoref increases significantly.",4.2 Impact of Training-test Overlap,[0],[0]
"Figure 5(b) shows that when training set size increases, the OOV rate and the LFW rate drop together.",4.2 Impact of Training-test Overlap,[0],[0]
"Then, to remove the impact of data size, we pick training sets which have a fixed size but different overlaps with the development set vocabulary.",4.2 Impact of Training-test Overlap,[0],[0]
The OOV rates and F1 scores of these subsets are shown in Figure 5(c).,4.2 Impact of Training-test Overlap,[0],[0]
"This experiment verifies the positive cor-
3In our experiments, a word is defined as low-frequency if it appears in the training set less than 10 times.
",4.2 Impact of Training-test Overlap,[0],[0]
"4There are 3 kinds of error cases of coreference resolution: false-new, false-link and wrong-link.",4.2 Impact of Training-test Overlap,[0],[0]
"In our experiments, the related mentions include: the current mention in all 3 kinds of cases, the nearest gold antecedent in false-new and wrong-link and the false referred antecedent in false-link and wrong-link.
relation between training-dev overlap and coreference resolution performance suggested by (Sadat Moosavi and Strube, 2017).",4.2 Impact of Training-test Overlap,[0],[0]
"Figure 5(d) shows that for training sets with the same size, the OOV rate and the LFW rate also drop together.
",4.2 Impact of Training-test Overlap,[0],[0]
We observe that the training set of 2.5K documents in Figure 5(a) has a higher model performance than all the training sets in Figure 5(c).,4.2 Impact of Training-test Overlap,[0],[0]
This is not expected.,4.2 Impact of Training-test Overlap,[0],[0]
"One hypothesis is that the lower performance in Figure 5(c) is due to the smaller diversity of these training sets, which are selected to have certain training-dev OOV rates.
",4.2 Impact of Training-test Overlap,[0],[0]
The training-dev LFW rate of OntoNotes is 34.8%.,4.2 Impact of Training-test Overlap,[0],[0]
"As a comparison, the number for PreCo is 12.3%.",4.2 Impact of Training-test Overlap,[0],[0]
A subset of PreCo with a similar token number to OntoNotes has a LFW rate of 33.0%.,4.2 Impact of Training-test Overlap,[0],[0]
This indicates that research of coreference algorithms on PreCo will be much more efficient than on OntoNotes.,4.2 Impact of Training-test Overlap,[0],[0]
"Even if we can ignore the LFW error cases, there are others related to low-frequency word senses, phrases and sentence structures, which are hard to filter out.",4.2 Impact of Training-test Overlap,[0],[0]
They will also obscure the error analysis.,4.2 Impact of Training-test Overlap,[0],[0]
"It is reasonable to believe that training-dev overlap impacts the rate
of these error cases in a similar way to impact LFW rate.",4.2 Impact of Training-test Overlap,[0],[0]
"Since most coreference systems consist of a mention detection module and a mention clustering module, an important question is: with a perfect mention detection module, what is the model performance on coreference resolution?",4.3 Mention Detection,[0],[0]
"The answer would help us understand the bottlenecks of the entire system, by quantifying the impact of the mention detection module on the final F1 score.",4.3 Mention Detection,[0],[0]
"(Lee et al., 2017) gave an answer by taking ground truth non-singleton mentions as the input of the coreference resolver for both training and evaluation, assuming that the perfect mention detector can also make perfect anaphoricity decisions, e.g., to decide whether a mention should be linked to an antecedent.",4.3 Mention Detection,[0],[0]
"But this assumption can be violated since mention detectors usually take local information but anaphoricity decisions usually need more context, nearly as much as entity identification.",4.3 Mention Detection,[0],[0]
"The anaphoricity decisions should be made in the mention clustering module.
",4.3 Mention Detection,[0],[0]
We argue that a better way to answer the question is to take all ground truth mentions (including singletons) for coreference.,4.3 Mention Detection,[0],[0]
This operation is not feasible in OntoNotes since it does not have annotations for singleton mentions.,4.3 Mention Detection,[0],[0]
We do this on PreCo and the results are shown in Table 6.,4.3 Mention Detection,[0],[0]
There is an obvious difference between the F1 scores achieved with all gold mentions and non-singleton gold mentions.,4.3 Mention Detection,[0],[0]
"Therefore, the room for improvement by better mention detection is not as enormous as suggested in (Lee et al., 2017).",4.3 Mention Detection,[0],[0]
The major challenge remained in coreference resolution is mention clustering.,4.3 Mention Detection,[0],[0]
"In this paper, we propose a large-scale coreference resolution dataset to overcome the limitations of existing ones.",5 Conclusion,[0],[0]
"Our dataset, PreCo, features higher training-test overlap, about 10 times larger scale than previous datasets, and singleton mention annotations.",5 Conclusion,[0],[0]
"By evaluating a state-of-the-art coreference resolver, we show that there is a wide gap between the model and human performance, which demonstrated challenges of the dataset.",5 Conclusion,[0],[0]
We verified the expectation that PreCo’s higher trainingtest overlap helps research on coreference resolution.,5 Conclusion,[0],[0]
"For the first time, we quantified the impact of mention detector to the entire system, thanks to our singleton mention annotations.",5 Conclusion,[0],[0]
"We make the dataset public, and hope it will stimulate further research on coreference resolution.",5 Conclusion,[0],[0]
"We introduce PreCo, a large-scale English dataset for coreference resolution.",abstractText,[0],[0]
"The dataset is designed to embody the core challenges in coreference, such as entity representation, by alleviating the challenge of low overlap between training and test sets and enabling separated analysis of mention detection and mention clustering.",abstractText,[0],[0]
"To strengthen the training-test overlap, we collect a large corpus of 38K documents and 12.5M words which are mostly from the vocabulary of Englishspeaking preschoolers.",abstractText,[0],[0]
"Experiments show that with higher training-test overlap, error analysis on PreCo is more efficient than the one on OntoNotes, a popular existing dataset.",abstractText,[0],[0]
"Furthermore, we annotate singleton mentions making it possible for the first time to quantify the influence that a mention detector makes on coreference resolution performance.",abstractText,[0],[0]
The dataset is freely available at https:// preschool-lab.github.io/PreCo/.,abstractText,[0],[0]
PreCo: A Large-scale Dataset in Preschool Vocabulary for Coreference Resolution,title,[0],[0]
"Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 11–20, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
Natural language understanding (NLU) requires analysis beyond the sentence-level.,1 Introduction,[0],[0]
"For example, an entity may be mentioned multiple times in a discourse, participating in various events, where each event may itself be referenced elsewhere in the text.",1 Introduction,[0],[0]
"Traditionally the task of coreference resolution has been defined as finding those entity mentions within a single document that co-refer, while crossdocument coreference resolution considers a wider discourse context across many documents, yet still pertains strictly to entities.
",1 Introduction,[0],[0]
"Predicate argument alignment, or entity-event cross-document coreference resolution, enlarges the set of possible co-referent elements to include the mentions of situations in which entities participate.",1 Introduction,[0],[0]
"This expanded definition drives practitioners towards a more complete model of NLU, where systems must not only consider who is mentioned, but also what happened.",1 Introduction,[0],[0]
"However, despite the drive towards an expanded notion of discourse, models typically are formulated with strong notions of localindependence: viewing a multi-document task as one limited to individual pairs of sentences.",1 Introduction,[0],[0]
"This creates a mis-match between the goals of such work – considering entire documents – with the systems – consider individual sentences.
",1 Introduction,[0],[0]
"In this work, we consider a system that takes a document level view in considering coreference for entities and predictions: the task of predicate argument linking.",1 Introduction,[0],[0]
"We treat this task as a global inference problem, leveraging multiple sources of semantic information identified at the document level.",1 Introduction,[0],[0]
"Global inference for this problem is mostly unexplored, with the exception of Lee et al. (2012) (discussed in § 8).",1 Introduction,[0],[0]
"Especially novel here is the use of document-level temporal constraints on events, representing a next step forward on the path to full understanding.
",1 Introduction,[0],[0]
Our approach avoids the pitfalls of local inference while still remaining fast and exact.,1 Introduction,[0],[0]
"We use the pairwise features of a very strong predicate argument aligner (Wolfe et al., 2013) (competitive with the state-of-the-art (Roth, 2014)), and add quadratic factors that constrain local decisions based on global document information.",1 Introduction,[0],[0]
These global factors lead to superior performance compared to the previous state-of-the-art.,1 Introduction,[0],[0]
We release both our code and data.1,1 Introduction,[0],[0]
Consider the two sentences from the document pair shown in Figure 1.,2 Model,[0],[0]
"These sentences describe the same event, although with different details.",2 Model,[0],[0]
"The source sentence has four predicates and four arguments, while the target has three predicates and three arguments.",2 Model,[0],[0]
"In this case, one of the predicates from each sentence aligns, as do three of the arguments.",2 Model,[0],[0]
We also show additional information potentially helpful to determining alignments: temporal relations between the predicates.,2 Model,[0],[0]
"The goal of predicate argument alignment is to assign these links indicating coreferent predicates and arguments across a document pair (Roth and Frank, 2012).
",2 Model,[0],[0]
"Previous work by Wolfe et al. (2013) formulated
1https://github.com/hltcoe/parma2
11
Figure 1: An example analysis and predicate argument alignment task between a source and target document.",2 Model,[0],[0]
"Predicates appear as hollow ovals, have blue mentions, and are aligned considering their arguments (dashed lines).",2 Model,[0],[0]
"Arguments, in black diamonds with green mentions, represent a document-level entity (coreference chain), and are aligned using their predicate structure and mention-level features.",2 Model,[0],[0]
The alignment choices appear in the middle in red.,2 Model,[0],[0]
"Temporal relation information is lifted into the global inference over alignments.
",2 Model,[0],[0]
"this as a binary classification problem: given a pair of arguments or predicates, construct features and score the pair, where scores above threshold indicate links.",2 Model,[0],[0]
"A binary classification framework has advantages: it’s fast since individual decisions can be made quickly, but it comes at the cost of global information across links.",2 Model,[0],[0]
The result may be links that conflict in their interpretation of the document.,2 Model,[0],[0]
"Figure 1 makes clear that jointly considering all links at once can aid individual decisions, for example, by including temporal ordering of predicates.
",2 Model,[0],[0]
The global nature of this task is similar to word alignment for machine translation (MT).,2 Model,[0],[0]
"Many systems consider alignment links between words individually, selecting the best link for each word independently of the other words in the sentence.",2 Model,[0],[0]
"Just as with an independent linking strategy in predicate argument alignment, this can lead to inconsistencies in the output.",2 Model,[0],[0]
"Lacoste-Julien et al. (2006) introduced a model that jointly resolved word alignments based on the introduction of quadratic variables, factors that depend on two alignment decisions which characterize patterns that span word-word links.",2 Model,[0],[0]
"Their approach achieved improved results even in the presence of little training data.
",2 Model,[0],[0]
We present a global predicate argument alignment model based on considering quadratic interactions between alignment variables to captures patterns we expect in coherent discourse.,2 Model,[0],[0]
"We introduce factors which are comprised of a binary variable, multiple quadratic constraints on that variable, and features that determine the cost associated with that variable in order to characterize the dependence between alignment decisions.
",2 Model,[0],[0]
"While the mathematical framework we use is similar to Lacoste-Julien et al. (2006), predicate argument alignment greatly differs from word alignment; thus our joint factors are based on different sources of regularity.",2 Model,[0],[0]
"Word alignment favors monotonicity in word order, but this effect is very weak in predicate argument alignment: aligned items can be spread throughout a document, and are often nested, gapped, or shuffled.",2 Model,[0],[0]
"Instead, we encode assumptions about consistency of temporal relations between coreferent events, coherence between predicates and arguments that appear in both documents, and fertility (to prevent over-alignment).",2 Model,[0],[0]
"We also note that our setting has much less data than typical word alignment tasks, as well as richer features that utilize semantic resources.
",2 Model,[0],[0]
"Notation An alignment between an item indexed by i in the source document and j in the target document is represented by variable zij ∈ {0, 1}, where zij = 1 indicates that items i and j are aligned.",2 Model,[0],[0]
"In some cases, we will explicitly indicate when the two items are predicates as zpij ; an argument alignment will be zaij .",2 Model,[0],[0]
"We represent all alignments for a document pair as matrix z.
For clarity, we omit any variable representing observed data when discussing feature functions; alignment variables are endowed with this information.",2 Model,[0],[0]
"For each pair of items we use “local” feature functions f(·) and corresponding parameters w, which capture the similarity between two items without the context of other alignments.
sij = w · f(zij) (1)
where sij is the score of linking items i and j. Using only local features, our system would greedily select alignments.",2 Model,[0],[0]
To capture global aspects we add joint factors that capture effects between alignment variables.,2 Model,[0],[0]
Each joint factor φ is comprised of a constrained binary variable zφ associated with features f(φ) that indicates when the factor is active.,2 Model,[0],[0]
"Together with parameters w these form additional scores sφ for the objective:
sφ = w · f(φ) (2)
The full linear scoring function on alignments sums over both local similarity and joint factors:∑
ij sijzij + ∑ φ∈Φ sφzφ.",2 Model,[0],[0]
"(3)
Lastly, it is convenient to describe the local feature functions and their corresponding alignment variable as factors with no constraints, and we will do so when describing the full score function.",2 Model,[0],[0]
"Local factors encode features based on the mention pair, which include a wide variety of similarity measures, e.g. whether two headwords appear as synonyms in WordNet, gender agreement based on possessive pronouns.",3 Local Factors,[0],[0]
"We adopt the features of Wolfe et al. (2013), a strong baseline system
which doesn’t use global inference.2 These features are built on top of a variety of semantic resources (PPDB (Ganitkevitch et al., 2013), WordNet (Miller, 1995), FrameNet (Baker et al., 1998)) and methods for comparing mentions (tree edit distance (Yao et al., 2013), string transducer (Andrews et al., 2012)).",3 Local Factors,[0],[0]
"Our goal is to develop joint factors that improve over the feature rich local factors baseline by considering global information.
",4 Joint Factors,[0],[0]
Fertility A common mistake when making independent classification decisions is to align many source items to a single target item.,4 Joint Factors,[0],[0]
"While each link looks promising on its own, they clearly cannot all be right.",4 Joint Factors,[0],[0]
"Empirically, the training set reveals that many to one alignments are uncommon; thus many to one predictions are likely errors.",4 Joint Factors,[0],[0]
"We add a fertility factor for predicates and arguments, where fertility is defined as the number of links to an item.",4 Joint Factors,[0],[0]
Higher fertilities are undesired and are thus penalized.,4 Joint Factors,[0],[0]
"Formally, for matrix z, the fertility of a row i or column j is the sum of that row or column.",4 Joint Factors,[0],[0]
"We discuss fertility in terms of rows below.
",4 Joint Factors,[0],[0]
We include two types of fertility factors.,4 Joint Factors,[0],[0]
"First, factor φfert1 distinguishes between rows with at least one link from those with none.",4 Joint Factors,[0],[0]
"For row i, we add one instance of the linear factor φfert1 with constraints
zφfert1 ≥ zij ∀j (4)
",4 Joint Factors,[0],[0]
"The cost associated with zφfert1 , which we will refer to as sfert1, will be incurred any time an item is mentioned in both documents.",4 Joint Factors,[0],[0]
"For data sets with many singletons, sfert1 more strongly penalizes nonsingleton rows, reflecting this pattern in the training data.",4 Joint Factors,[0],[0]
"We make sfert1 parametric, where the features of the φfert1 factor allow us to learn different weights for predicates and arguments, as well as the size of the row, i.e. number of items in the pairing.
",4 Joint Factors,[0],[0]
"The second fertility factory φfert2 considers items with a fertility greater than one, penalizing items for having too many links.",4 Joint Factors,[0],[0]
"Its binary variable has the
2Some features inspect the apparent predicate argument structure, based on things like dependency parses, but the model may not inspect more than one of its own decisions (joint factors) while scoring an alignment.
",4 Joint Factors,[0],[0]
"quadratic constraints:
zφfert2 ≥ zijzik ∀j < k",4 Joint Factors,[0],[0]
"(5)
",4 Joint Factors,[0],[0]
"This factor penalizes rows that have fertility of at least two, but does not distinguish beyond that.",4 Joint Factors,[0],[0]
"An alternative would be to introduce a factor for every pair of variables in a row, each with one constraint.",4 Joint Factors,[0],[0]
This would heavily penalize fertilities greater than two.,4 Joint Factors,[0],[0]
"We found that the resulting quadratic program took longer to solve and gave worse results.
",4 Joint Factors,[0],[0]
"Since documents have been processed to identify in-document coreference chains, we do not expect multiple arguments from a source document to align to a single target item.",4 Joint Factors,[0],[0]
"For this reason, we expect φfert2 for arguments to have a large negative weight.",4 Joint Factors,[0],[0]
"In contrast, since predicates do not form chains, we may have multiple source predicates for one target.
",4 Joint Factors,[0],[0]
We note an important difference between our fertility factor compared with Lacoste-Julien et al. (2006).,4 Joint Factors,[0],[0]
"We parameterize fertility for only two cases (1 and 2) whereas they consider fertility factors from 2 to D. We do not parameterize fertilities higher than two because they are not common in our dataset and come at a high computational cost.
",4 Joint Factors,[0],[0]
"The features f(φ) for both φfert1 and φfert2 are an intercept feature (which always fires), indicator features for whether this row corresponds to an argument or a predicate, and a discretized feature for how many alignments are in this row.
",4 Joint Factors,[0],[0]
Predicate Argument Structure We expect structure among links that involve a predicate and its associated arguments.,4 Joint Factors,[0],[0]
"Therefore, we add joint factors that consider a predicate and its associated alignments: the predicate argument structure.",4 Joint Factors,[0],[0]
"We determine this structure from a dependency parse, though the idea is general to any semantic binding, e.g. FrameNet or Propbank style parses.",4 Joint Factors,[0],[0]
"Given a coherent discourse, there are several expected types of patterns in the PAS; we add factors for these.
",4 Joint Factors,[0],[0]
"Predicate-centric We begin with a predicatecentric factor, which views scores an alignment between predicates based on their arguments, i.e. the two predicates share the same arguments.",4 Joint Factors,[0],[0]
"Ideally, two predicates can only align when their arguments are coreferent.",4 Joint Factors,[0],[0]
"However, in practice we may incorrectly resolve argument links, or there may be
implicit arguments that do not appear as syntactic dependencies of the predicate trigger.",4 Joint Factors,[0],[0]
"Therefore, we settle for a weaker condition, that there should be some overlap in the arguments of two coreferent predicates.
",4 Joint Factors,[0],[0]
"For every predicate alignment zpij , we add a factor φpsa whose score spsa is a penalty for having no argument overlap; predicates share arguments (psa).",4 Joint Factors,[0],[0]
"To constrain the variable of φpsa, we add a quadratic constraint that considers every possible pair of argument alignments that might overlap:
zφpsa",4 Joint Factors,[0],[0]
"≥ zpij ( 1− max
k∈args(pi) l∈args(pj)
zakl )
(6)
where args(pi) finds the indices of all arguments governed by the predicate pi.
",4 Joint Factors,[0],[0]
Entity-centric We expect similar behavior from arguments (entities).,4 Joint Factors,[0],[0]
"If an entity appears in two documents, it is likely that this entity will be mentioned in the context of a common predicate, i.e. arguments share predicates (asp).",4 Joint Factors,[0],[0]
"For a given argument alignment zaij we add quadratic constraints so that zφasp represents a penalty for two arguments not sharing a single predicate:
zφasp ≥ zaij ( 1− max
k∈preds(ai) l∈preds(aj)
zpkl )
(7)
where preds(ai) finds the indices of all predicates that govern any mention of argument ai.
",4 Joint Factors,[0],[0]
"The features f(φ) for both psa and asp are an intercept feature and a bucketed count of the size of args(pi)× args(pj) or preds(ai)×preds(aj) respectively.
",4 Joint Factors,[0],[0]
"Temporal Information Temporal ordering, in contrast to textual ordering, can indicate when predicates cannot align: we expect aligned predicates in both documents to share the same temporal relations.",4 Joint Factors,[0],[0]
"SemEval 2013 included a task on predicting temporal relations between events (UzZaman et al., 2013).",4 Joint Factors,[0],[0]
"Many systems produced partial relations of events in a document based on lexical aspect and tense, as well as discourse connectives like “during” or “after”.",4 Joint Factors,[0],[0]
"We obtain temporal relations with CAEVO, a state-of-the-art sieve-based system (Chambers et al., 2014).
",4 Joint Factors,[0],[0]
"TimeML (Pustejovsky et al., 2003), the format for specifying temporal relations, defines relations between predicates (e.g. immediately before and simultaneous), each with an inverse (e.g. immediately after and simultaneous respectively).",4 Joint Factors,[0],[0]
We will refer to a relation as R and its inverse as R−1.,4 Joint Factors,[0],[0]
"Suppose we had pa and pb in the source document, px and py in the target document, and paR1pb, pxR2py.",4 Joint Factors,[0],[0]
"Given this configuration the following alignments conflict with the in-doc relations:
zax zby zay zbx In-Doc Relations",4 Joint Factors,[0],[0]
"* * 1 1 R1 = R2 1 1 * * R1 = R−12
where 1 means there is a link and * means there is a link or no link (wildcard).",4 Joint Factors,[0],[0]
"The simplest example that fits this pattern is: ‘a before b’, ‘x before y’, ‘a corefers with y’, and ‘b corefers with x’ implies a conflict.
",4 Joint Factors,[0],[0]
We introduce a factor that penalizes these conflicting configurations.,4 Joint Factors,[0],[0]
"In every instance where the predicted temporal relation for a pair of predicate alignments matches one of the conflict patterns above, we add a factor using zφtemp :
zφtemp ≥ zayzbx if paR1pb, pxR2py, R1 = R2 zφtemp ≥ zaxzby if paR1pb, pxR2py, R1 = R−12
(8)
Thus sφtemp is the cost of disagreeing with the indoc temporal relations.",4 Joint Factors,[0],[0]
This is a general technique for incorporating relational information into coreference decisions.,4 Joint Factors,[0],[0]
"It only requires specifying when two relations are incompatible, e.g. spouseOf and siblingOf are incompatible relations (in most states).",4 Joint Factors,[0],[0]
"We leave this for future work.
",4 Joint Factors,[0],[0]
"Since CAEVO gives each relation prediction a probability, we incorporate this into the feature by indicating the probability of a conflict not arising:
f(φtemp) = log ( 1− p(R1)p(R2) + )",4 Joint Factors,[0],[0]
"(9)
avoids large negative values since CAEVO probabilities are not perfectly calibrated.",4 Joint Factors,[0],[0]
"We use = 0.1, allowing feature values of at most −2.3.",4 Joint Factors,[0],[0]
Summary The objective is a linear function over binary variables.,4 Joint Factors,[0],[0]
"There is a local similarity score
def train(alignments): w = init_weights() working_set = set() while True: xi = solve_ILP(w, working_set) c = most_violated_constraint(w, alignments) working_set.add(c) if hinge(c, w) <",4 Joint Factors,[0],[0]
"xi: break
coefficient on every alignment variable, and a joint factor similarity score on every quadratic variable.",4 Joint Factors,[0],[0]
These quadratic variables are constrained by products of the original alignment variables.,4 Joint Factors,[0],[0]
Decoding an alignment requires solving this quadratically constrained integer program; in practice is can be solved quickly without relations.,4 Joint Factors,[0],[0]
Learning We use the supervised structured SVM formulation of Joachims et al. (2009).,5 Inference,[0],[0]
"As is common in structure prediction we use margin rescaling and 1 slack variable, with the structural SVM objective:
min w ||w||22 +",5 Inference,[0],[0]
"Cξ
s.t. ξ ≥ 0
ξ +",5 Inference,[0],[0]
N∑ i=1,5 Inference,[0],[0]
w · f(zi) ≥,5 Inference,[0],[0]
N∑ i=1,5 Inference,[0],[0]
w · f(ẑi),5 Inference,[0],[0]
"+ ∆(zi, ẑi)
",5 Inference,[0],[0]
"∀ẑi ∈ Zi (10)
where Zi is the set of all possible alignments that have the same shape as zi.
",5 Inference,[0],[0]
"The score function for an alignment uses three types of terms: weights, features, and alignment variables.",5 Inference,[0],[0]
"When we decode, we take the product of the weights and the features to get the costs for the ILP (e.g. sφ = w · f(φ)).",5 Inference,[0],[0]
"When we optimize our SVM objective, we take the product of the alignment variables and the features to get modified features for the SVM:
f(z) = ∑ ij zijf(zij) + ∑ φ∈Φ zφf(φ) (11)
Since we cannot iterate over the exponentially many margin constraints, we solve for this optimization using the cutting-plane learning algorithm.",5 Inference,[0],[0]
"This algorithm repeatedly asks the “separation oracle” for the most violated SVM constraint, which finds this constraint by solving:
arg max ẑ1...ẑN ∑ i w · f(ẑi) + ∆(zi, ẑi) (12)
subject to the constraints defined by the joint factors.",5 Inference,[0],[0]
"When the separation oracle returns a constraint that is not violated or is already in the working set, then we have a guarantee that we solved the original SVM problem with exponentially many constraints.",5 Inference,[0],[0]
"This is the most time-consuming aspect of learning, but since the problem decomposes over document alignments, we cache solutions on a per document alignment basis.",5 Inference,[0],[0]
"With caching, we only call the separation oracle around 100-300 times.
",5 Inference,[0],[0]
"We implement the separation oracle using an ILP solver, CPLEX,3 due to complexity of the discrete optimization problem: there are 2m n possible alignments for and m×n alignment grid.",5 Inference,[0],[0]
"In practice this is solved very efficiently, taking less than a third of a second per document alignment on average.",5 Inference,[0],[0]
"We would like ∆ to be F1, but we need a decomposable loss to include it in a linear objective (Taskar et al., 2003).",5 Inference,[0],[0]
"Instead, we use Hamming loss as a surrogate, as in Lacoste-Julien et al. (2006).
",5 Inference,[0],[0]
"Our training data is heavily biased towards negative examples, performing poorly on F1 since precision and recall are unbalanced.",5 Inference,[0],[0]
"We use an asymmetric version of Hamming loss that incurs cFP cost for predicting an alignment for two unaligned
3http://www-01.ibm.com/software/ commerce/optimization/cplex-optimizer/
items and cFN for predicting no alignment for two aligned items.",5 Inference,[0],[0]
"We fixed cFP = 1 and tuned cFN ∈ {1, 2, 3, 4} on dev data.",5 Inference,[0],[0]
"Additionally we found it useful to tune the scale of the loss function across {12 , 1, 2, 4}.",5 Inference,[0],[0]
"Previous work, such as Joachims et al. (2009), use a hand-chosen constant for the scale of the Hamming loss, but we observe some sensitivity in this parameter and choose to optimize it.
",5 Inference,[0],[0]
"Decoding Following Wolfe et al. (2013), we tune the threshold for classification τ on dev data to maximize F1 (via linesearch).",5 Inference,[0],[0]
For SVMs τ is typically fixed at 0: this is not necessarily good practice when your training loss differs from test loss (Hamming vs F1).,5 Inference,[0],[0]
In our case this extra parameter is worth allocating a portion of training data to enable tuning.,5 Inference,[0],[0]
"Tuning τ addresses the same problem as using an asymmetric Hamming loss, but we found that doing both led to better results.4",5 Inference,[0],[0]
"Since we are using a global scoring function rather than a set of classifications, τ is implemented as a test-time unary factor on every alignment.",5 Inference,[0],[0]
Data We consider two datasets for evaluation.,6 Experiments,[0],[0]
The first is a cross-document entity and event coreference resolution dataset called the Extended Event Coref Bank (EECB) created by Lee et al. (2012) and based on a corpus from Bejan and Harabagiu (2010).,6 Experiments,[0],[0]
The dataset contains clusters of news articles taken from Google News with annotations about coreference over entities and events.,6 Experiments,[0],[0]
"Following the procedure of Wolfe et al. (2013), we select the first document in every cluster and pair it with every other document in the cluster.
",6 Experiments,[0],[0]
The second dataset (RF) comes from Roth and Frank (2012).,6 Experiments,[0],[0]
"The dataset contains pairs of news articles that describe the same news story, and are annotated for predicate links between the document pairs.",6 Experiments,[0],[0]
"Due to the lack of annotated arguments, we can only report predicate linking performance and the psa and asp factors do not apply.",6 Experiments,[0],[0]
"Lastly, the size of the RF data should be noted as it is much smaller than EECB:",6 Experiments,[0],[0]
"the test set has 60 document pairs and the dev set has 10 document pairs.
4Only tuning τ performed almost as well as tuning τ and the Hamming loss, but not tuning τ performed much worse than only tuning the Hamming loss at train time.
",6 Experiments,[0],[0]
Both datasets are annotated with parses and indocument coreference labels provided by the toolset of Napoles et al. (2012)5 and are available with our code release.,6 Experiments,[0],[0]
"Due to the small data size, we use kfold cross validation for both datasets.",6 Experiments,[0],[0]
We choose k = 10 for RF due to its very small size (more folds give more training examples) and k = 5 on EECB to save computation time (amount of training data in EECB is less of a concern).,6 Experiments,[0],[0]
Hyperparameters were chosen by hand using using cross validation on the EECB dataset using F1 as the criteria (rather than Hamming).,6 Experiments,[0],[0]
"Figures report averages across these folds.
",6 Experiments,[0],[0]
"Systems Following Roth and Frank (2012) and Wolfe et al. (2013) we include a Lemma baseline for identifying alignments which will align any two predicates or arguments that have the same lemmatized head word.6 The Local baseline uses the same features as Wolfe et al., but none of our joint factors.",6 Experiments,[0],[0]
"In addition to running our joint model with all factors, we measure the efficacy of each individual factor by evaluating each with the local features.
",6 Experiments,[0],[0]
"For evaluation we use a generous version of F1 that is defined for alignment labels composed of sure, Gs, and possible links, Gp and the system’s proposed links H (following Cohn et al. (2008), Roth and Frank (2012) and Wolfe et al. (2013)).
",6 Experiments,[0],[0]
"P = |H ∩Gp| |H| R = |H ∩Gs| |Gs| F = 2PR P +R
Note that the EECB data does not have a sure and possible distinction, so Gs = Gp, resulting in standard F1.",6 Experiments,[0],[0]
"In addition to F1, we separately measure predicate and argument F1 to demonstrate where our model makes the largest improvements.
",6 Experiments,[0],[0]
We performed a one-sided paired-bootstrap test where the null hypothesis was that the joint model was no better than the Local baseline (described in Koehn (2004)).,6 Experiments,[0],[0]
"Cases where p < 0.05 are bolded.
",6 Experiments,[0],[0]
5https://github.com/cnap/anno-pipeline 6The lemma baseline is obviously sensitive to the lemmatizer used.,6 Experiments,[0],[0]
"We used the Stanford CoreNLP lemmatizer (Manning et al., 2014) and found it yielded slightly better results than previously reported as the lemma baseline (Roth and Frank, 2012), so we used it for all systems to ensure fairness and that the baseline is as strong as it could be.",6 Experiments,[0],[0]
Results for EECB and RF are reported in Table 7.,7 Results,[0],[0]
"As previously reported, using just local factors (features on pairs) improves over lemma baselines (Wolfe et al., 2013).",7 Results,[0],[0]
The joint factors make statistically significant gains over local factors in almost all experiments.,7 Results,[0],[0]
Fertility factors provide the largest improvements from any single constraint.,7 Results,[0],[0]
"A fertility penalty actually allows the pairwise weights to be more optimistic in that they can predict more alignments for reasonable pairs, allowing the fertility penalty to ensure only the best is chosen.",7 Results,[0],[0]
"This penalty also prevents the “garbage collecting” effect that arises for instances that have rare features (Brown et al., 1993).
",7 Results,[0],[0]
"Temporal constraints are relatively sparse, appearing just 2.8 times on average.",7 Results,[0],[0]
"Nevertheless, it was very helpful across all experiments, though only statistically significantly on the RF dataset.",7 Results,[0],[0]
This is one of the first results to demonstrate benefits of temporal relations affecting an downstream task.,7 Results,[0],[0]
"Perhaps surprisingly, these improvements result from a a temporal relation system that has relatively poor absolute performance.",7 Results,[0],[0]
"Despite this, improvements are possibly due to the orthogonal nature of temporal information; no other feature captures this signal.",7 Results,[0],[0]
"This suggests that future work on temporal relation prediction may yield further improvements and deserves more attention as a useful feature for semantic tasks in NLP.
",7 Results,[0],[0]
The predicate-centric factors improved performance significantly on both datasets.,7 Results,[0],[0]
"For the predicate-centric factor, when a predicate was aligned there is a 72.3% chance that there was at least one argument aligned as well, compared to only 14.1% of case of non-aligned predicates.",7 Results,[0],[0]
"As mentioned before, the reason the former number isn’t 100% is primarily due to implicit arguments and errors in argument identification.",7 Results,[0],[0]
"The argument-centric features helped almost as much as the predicate-centric version, but the improvements were not significant on the EECB dataset.",7 Results,[0],[0]
"Running the same diagnostic as the predicate-centric feature reveals similar support: in 57.1% of the cases where an argument was aligned, at least one predicate it partook in was aligned too, compared to 7.6% of cases for non-aligned arguments.",7 Results,[0],[0]
"Both the
EECB F1 P R Arg F1 Arg P Arg R",7 Results,[0],[0]
"Pred F1 Pred P Pred R
Lemma 68.1 79.3 * 59.6 61.7 79.1 * 50.6 75.0 87.3 * 65.7",7 Results,[0],[0]
Local 73.0 75.8 70.5 67.7 76.3 60.8 78.7 81.4 76.2 +Fertility 77.1 * 83.9 * 71.3 66.6 80.9 * 56.6 82.8 * 87.4 * 78.7 * +,7 Results,[0],[0]
"Predicate-centric 74.1 * 80.7 * 68.6 67.4 81.6 * 57.3 79.7 * 85.0 * 75.1 +Argument-centric 73.7 81.2 * 67.5 66.8 83.0 * 55.9 79.3 85.1 * 74.3 +Temporal 73.7 78.2 * 69.7 67.9 80.6 * 58.7 79.0 82.1 76.1 +All Factors 77.5 * 86.3 * 70.3 65.8 83.1 * 54.5 83.7 * 89.7 * 78.4 *
RF",7 Results,[0],[0]
"Pred F1 Pred P Pred R
Lemma 52.4 47.6 58.2 * Local 58.1 63.5 53.6 +Fertility 60.0 57.4 62.4 *",7 Results,[0],[0]
+Predicate-centric NA NA NA +Argument-centric NA NA NA +Temporal 59.0 57.4 60.6 *,7 Results,[0],[0]
"+All factors 59.4 56.9 62.2 *
Figure 3: Cross validation results for EECB (above) (Lee et al., 2012) and RF (left) (Roth and Frank, 2012).",7 Results,[0],[0]
"Statistically significant improvements from Local marked * (p < 0.05 using a one-sided pairedbootstrap test) and best results are bolded.
predicate- and argument-centric improve similarly across both predicates and arguments on EECB.
",7 Results,[0],[0]
"While each of the joint factors all improve over the baselines on RF, the full model with all the joint factors does not perform as well as with some factors excluded.",7 Results,[0],[0]
"Specifically, the fertility model performs the best.",7 Results,[0],[0]
"We attribute this small gap to lack of training data (RF only contains 64 training document pairs in our experiments), as this is not a problem on the larger EECB dataset.
",7 Results,[0],[0]
"Additionally, the joint models seem to trade precision for recall on the RF dataset compared to the Local baseline.",7 Results,[0],[0]
"Note that both models are tuned to maximize F1, so this tells you more about the shape of the ROC curve as opposed to either models’ ability to achieve either high precision or recall.",7 Results,[0],[0]
"Since we don’t see this behavior on the EECB corpus, it is more likely that this is a property of the data than the model.",7 Results,[0],[0]
"The task of predicate argument linking was introduced by Roth and Frank (2012), who used a graph parameterized by a small number of semantic features to express similarities between predicates and used min-cuts to produce an alignment.",8 Related Work,[0],[0]
"This was followed by Wolfe et al. (2013), who gave a locallyindependent, feature-rich log-linear model that utilized many lexical semantic resources, similar to the
sort employed in RTE challenges.",8 Related Work,[0],[0]
Lee et al. (2012) considered a similar problem but sought to produce clusters of entities and events rather than an alignment between two documents with the goal of improving coreference resolution.,8 Related Work,[0],[0]
They used features which consider previous event and entity coreference decisions to make future coreference decisions in a greedy manner.,8 Related Work,[0],[0]
"This differs from our model which is built on non-greedy joint inference, but much of the signal indicating when two mentions corefer or are aligned is similar.
",8 Related Work,[0],[0]
"In the context of in-document coreference resolution, Recasens et al. (2013) sought to overcome the problem of opaque mentions7 by finding highprecision paraphrases of entities by pivoting off verbs mentioned in similar documents.",8 Related Work,[0],[0]
"We address the issue of opaque mentions not by building a paraphrase table, but by jointly reasoning about entities that participate in coreferent events (c.f. §4); the approaches are complementary.
",8 Related Work,[0],[0]
In this work we incorporate ordering information of events.,8 Related Work,[0],[0]
"Though we consider it an upstream task, there is a line of work trying to predict temporal relations between events (Pustejovsky et al., 2003; Mani et al., 2006; Chambers et al., 2014).",8 Related Work,[0],[0]
"Our results indicate this is a useful source of information, one of the first results to show an improvement from this
7A lexically disparate description of an entity.
type of system (Glavaš and Šnajder, 2013).",8 Related Work,[0],[0]
"We utilize an ILP to improve upon a pipelined system, similar to Roth and Yih (2004), but our work differs in that we do not use piecewise-trained classifiers.",8 Related Work,[0],[0]
Our local similarity scores are calibrated according to a global objective by propagating the gradient back from the loss to every parameter in the model.,8 Related Work,[0],[0]
"When using piecewise training, local classifiers must focus more on recall (in the spirit of Weiss and Taskar (2010)) than they would for an ordinary classification task with no global objective.",8 Related Work,[0],[0]
Our method trains classifiers jointly with a global convex objective.,8 Related Work,[0],[0]
"While our training procedure requires decoding an integer program, the parameters we learn are globally optimal.",8 Related Work,[0],[0]
"We presented a max-margin quadratic cost model for predicate argument alignment, seeking to exploit discourse level semantic features to improve on previous, locally independent approaches.",9 Conclusion,[0],[0]
"Our model includes factors that consider fertility of predicates and arguments, the predicate argument structure present in coherent discourses, and soft constraints on predicate coreference determined by a temporal relation classifier.",9 Conclusion,[0],[0]
We have shown that this model significantly improves upon prior work which uses extensive lexical resources but without the benefit of joint inference.,9 Conclusion,[0],[0]
"Additionally, this is one of the first demonstrations of the benefits of temporal relation identification.",9 Conclusion,[0],[0]
"Overall, this work demonstrates the benefits of considering global document information as part of natural language understanding.
",9 Conclusion,[0],[0]
"Future work should extend the problem formulation of predicate argument alignment to consider incremental linking: starting with a pair of documents, perform linking, and then continue to add in documents over time.",9 Conclusion,[0],[0]
"This problem formulation would capture the evolution of a breaking news story, which closely matches the type of data (news articles) considered in this work (EECB and RF datasets).",9 Conclusion,[0],[0]
"This formulation ties into existing work on news summarization, topic detection and tracking, an multi-document NLU.",9 Conclusion,[0],[0]
"This goes hand with work on better intra-document relation prediction methods, such as the temporal relation model used in this work, to lead to better joint linking decisions.",9 Conclusion,[0],[0]
We present a joint model for predicate argument alignment.,abstractText,[0],[0]
"We leverage multiple sources of semantic information, including temporal ordering constraints between events.",abstractText,[0],[0]
"These are combined in a max-margin framework to find a globally consistent view of entities and events across multiple documents, which leads to improvements over a very strong local baseline.",abstractText,[0],[0]
Predicate Argument Alignment using a Global Coherence Model,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 450–455 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
450
Because obtaining training data is often the most difficult part of an NLP or ML project, we develop methods for predicting how much data is required to achieve a desired test accuracy by extrapolating results from systems trained on a small pilot training dataset. We model how accuracy varies as a function of training size on subsets of the pilot data, and use that model to predict how much training data would be required to achieve the desired accuracy. We introduce a new performance extrapolation task to evaluate how well different extrapolations predict system accuracy on larger training sets. We show that details of hyperparameter optimisation and the extrapolation models can have dramatic effects in a document classification task. We believe this is an important first step in developing methods for estimating the resources required to meet specific engineering performance targets.",text,[0],[0]
An engineering discipline should be able to predict the cost of a project before the project is started.,1 Introduction,[0],[0]
"Because training data is often the most expensive part of an NLP or ML project, it is important to estimate how much training data required for a system to achieve a target accuracy.",1 Introduction,[0],[0]
"Unfortunately our field only offers fairly impractical advice, e.g., that more data increases accuracy (Banko and Brill, 2001); we currently have no practical methods for estimating how much data or what quality of data is required to achieve a target accuracy goal.",1 Introduction,[0],[0]
"Imagine if bridge construction was planned the way we build our systems!
",1 Introduction,[0],[0]
"Our long-term goal is to develop practical methods for designing systems that achieve target performance specifications, including identifying the amount of training data that the system will require.",1 Introduction,[0],[0]
This paper starts to address this goal by introducing an extrapolation methodology that predicts a system’s accuracy on a larger dataset from its performance on subsets of much smaller pilot data.,1 Introduction,[0],[0]
These extrapolations allow us to estimate how much training data a system will require to achieve a target accuracy.,1 Introduction,[0],[0]
"We focus on a specific task (document classification) using a specific system (the fastText classifier of Joulin et al. (2016)), and leave to future work to determine if our approach and results generalise to other tasks and systems.
",1 Introduction,[0],[0]
We introduce an accuracy extrapolation task that can be used to evaluate different extrapolation models.,1 Introduction,[0],[0]
We describe three well-known extrapolation models and evaluate them on a document classification dataset.,1 Introduction,[0],[0]
"On our development data the biased power-law method with binomial item weighting performs best, so we propose it should be a baseline for future research.",1 Introduction,[0],[0]
"We demonstrate the importance of hyperparameter optimisation on each different-sized data subset (rather than just optimising on the largest data subset) and item weighting, and show that these can have a dramatic impact on extrapolation, especially from small pilot data sets.",1 Introduction,[0],[0]
"The data and code for all experiments in this paper, including the R code for the graphics, is available from http://web.",1 Introduction,[0],[0]
science.mq.edu.au/˜mjohnson.,1 Introduction,[0],[0]
"Power analysis (Cohen, 1992) is widely-used statistical technique (e.g., in biomedical trials) for predicting the number of measurements required in an experimental design; we aim to develop sim-
ilar techniques for NLP and ML systems.",2 Related work,[0],[0]
There is a large body of research on the relationship between training data size and system performance.,2 Related work,[0],[0]
Geman et al. (1992) decompose the squared error of a model into a bias term (due to model errors) and a variance term (due to statistical noise).,2 Related work,[0],[0]
"Bias does not vary with training data size n, but the error due to variance should decrease as O(1/√n) if the training observations are independent (Domingos, 2000a,b).",2 Related work,[0],[0]
"The power-law models used in this paper have been investigated many times in prior literature (Haussler et al., 1996; Mukherjee et al., 2003; Figueroa et al., 2012; Beleites et al., 2013; Hajian-Tilaki, 2014; Cho et al., 2015).",2 Related work,[0],[0]
"Sun et al. (2017), Barone et al. (2017) and the concurrent unpublished work by Hestness et al. (2017) point out that these power-law models describe modern ML and NLP systems quite well, including complex deep-learning systems, so we expect our results to generalise to these systems.
",2 Related work,[0],[0]
This paper differs from prior work in that we explicitly focus on the task of extrapolating system performance from small pilot data.,2 Related work,[0],[0]
"We introduce a new evaluation task to compare the effectiveness of different models for this extrapolation, and demonstrate the importance of per-subset hyperparameter optimisation and item weighting, which prior work did not investigate.",2 Related work,[0],[0]
"We are given a system whose accuracy on a large dataset we wish to predict, but only a smaller pilot dataset is available.",3 Models for extrapolating pilot data,[0],[0]
"We train the system on different-sized subsets of the pilot dataset, and use the results of those training runs to estimate how the system’s accuracy varies as a function of training data size.
",3 Models for extrapolating pilot data,[0],[0]
"We focus on predicting the minimum error rate e(n) that the system can achieve on a dataset of size n after hyperparameter optimisation (where the error rate is 1−accuracy for a classifier) given a pilot dataset of size m n (in the task below, m = n/2 or m = n/10).",3 Models for extrapolating pilot data,[0],[0]
"We investigate three different extrapolation models of e(n) in this paper:
• Power law: ê(n) = bnc • Inverse square-root: ê(n) =",3 Models for extrapolating pilot data,[0],[0]
a+ bn−1/2 •,3 Models for extrapolating pilot data,[0],[0]
"Biased power law: ê(n) = a+ bnc
Here ê(n) is the estimate of e(n), and a, b and c are adjustable parameters that are estimated based on the system’s performance on the pilot dataset.
",3 Models for extrapolating pilot data,[0],[0]
"The inverse square-root curve is what one would expect if the error is distributed according to a Bias-Variance decomposition (Geman et al., 1992) with a constant bias term a and a variance term that asymptotically follows the Central Limit Theorem.",3 Models for extrapolating pilot data,[0],[0]
We fit these models using weighted least squares regression.,3 Models for extrapolating pilot data,[0],[0]
"Each data point or item in the regression is the result of a run of the system on a subset of the pilot dataset.
",3 Models for extrapolating pilot data,[0],[0]
"Assuming that the underlying system has adjustable hyperparameters, the question arises: how should the hyperparameters be set?",3 Models for extrapolating pilot data,[0],[0]
"The computationally least demanding approach is to optimise the system’s hyperparameters on the full pilot dataset, and use these hyperparameters for all the runs on subsets of the pilot dataset.",3 Models for extrapolating pilot data,[0],[0]
"An alternative, computationally more demanding approach is to optimise the system’s hyperparameters separately on each of the subsets of the pilot dataset.",3 Models for extrapolating pilot data,[0],[0]
"Figure 1 shows an example where optimising the hyperparameters just on the full pilot dataset is clearly in-
ferior to optimising the hyperparameters on each subset of the pilot dataset.",3 Models for extrapolating pilot data,[0],[0]
"We show below that the more demanding approach of optimising on each subset is superior, especially when extrapolating from small pilot datasets.
",3 Models for extrapolating pilot data,[0],[0]
We also investigate how details of the regression fit affect the regression accuracy ê(n).,3 Models for extrapolating pilot data,[0],[0]
"We experimented with several link functions (we used the default Gaussian link here), but found that these had less impact than adjusting the item weights in the regression.",3 Models for extrapolating pilot data,[0],[0]
"Runs with smaller training sets presumably have higher variance, and since our goal is to extrapolate to larger datasets, it is reasonable to place more weight on items corresponding to larger datasets.",3 Models for extrapolating pilot data,[0],[0]
"We investigated three item weighting functions in regression:
• constant weights (1), • linear weights (n), and • binomial weights (n/e(1− e))
",3 Models for extrapolating pilot data,[0],[0]
"Linear weights are motivated by the assumption that the item variance follows the Central Limit Theorem, while the binomial weights are motivated by the assumption that item variance follows a binomial distribution (see the Supplemental Materials for further discussion).",3 Models for extrapolating pilot data,[0],[0]
"As Figure 2 makes clear, linear weights and binomial weights generally produce more accurate extrapolations than constant weights, so we use binomial weights in our evaluation in Table 2.",3 Models for extrapolating pilot data,[0],[0]
We used the fastText document classifier and the document classification corpora distributed with it; see Joulin et al. (2016) for full details.,4 A performance extrapolation task,[0],[0]
FastText’s speed and evaluation scripts make it easy to do the experiments described below.,4 A performance extrapolation task,[0],[0]
We fitted our extrapolation models to the fastText document classifier results on the 8 corpora distributed with the fastText classifier.,4 A performance extrapolation task,[0],[0]
"These corpora contain labelled documents for a document classification task, and come randomised and divided into training and test sections.",4 A performance extrapolation task,[0],[0]
"All our results are on these test sections.
",4 A performance extrapolation task,[0],[0]
The corpora were divided into development and evaluation corpora (each with train and test splits) as shown in table 1.,4 A performance extrapolation task,[0],[0]
"We use the amazon review polarity, sogou news, yahoo answers and yelp review full corpora as our test set (so these are only used in the final evaluation), while the ag news, dbpedia, amazon review full and
yelp review polarity were used as development corpora.",4 A performance extrapolation task,[0],[0]
"The development and evaluation sets contain document collections of roughly similar sizes and complexities, but no attempt was made to accurately “balance” the development and evaluation corpora.
",4 A performance extrapolation task,[0],[0]
"We trained the fastText classifier on 13 differently-sized prefixes of each training set that are approximately logarithmically spaced over two orders of magnitude (i.e., varying from 1⁄100 to all of the training corpus).",4 A performance extrapolation task,[0],[0]
"To explore the effect of hyperparameter tuning on extrapolation, for each prefix of each training set we trained a classifier on each of 1,079 different hyperparameter settings, varying the n-gram length, learning rate, dimensionality of the hidden units and the loss function (the fastText classifier crashed on 17 hyperparameter combinations; we did not investigate why).",4 A performance extrapolation task,[0],[0]
"We re-ran the entire process 8 times on randomlyshuffled versions of each training corpus.
",4 A performance extrapolation task,[0],[0]
"As expected, the minimum error configuration invariably requires the full training data.",4 A performance extrapolation task,[0],[0]
When extrapolating from subsets of a smaller pilot set (we explored pilot sets consisting of 0.1 and 0.5 of the full training data) there are two plausible ways of performing hyperparameter optimisation.,4 A performance extrapolation task,[0],[0]
"Ideally, one would optimise the hyperparameters for each subset of the pilot data considered (we selected the best-performing hyperparameters using grid search).",4 A performance extrapolation task,[0],[0]
"However, if one is not working with computationally efficient algorithms like fastText, one might be tempted to only optimise the hyperparameters once on all the pilot data, and use the hyperparameters optimised on all the pilot data when calculating the error rate on subsets of that pilot data.",4 A performance extrapolation task,[0],[0]
"As figure 2 and table 2 make clear, selecting the optimal hyperparameters for each subset of the pilot data generally produces better extrapolation results.",4 A performance extrapolation task,[0],[0]
Figure 1 shows how different ways of choosing hyperparameters can affect extrapolation.,4 A performance extrapolation task,[0],[0]
"As that figure shows, hyperparameters optimised on 50% of the training data perform very badly on 1% of the training data.",4 A performance extrapolation task,[0],[0]
"As figure 2 shows, this can lead simpler extrapolation models such as the power-law to dramatically underestimate the error on the full dataset.",4 A performance extrapolation task,[0],[0]
"Interestingly, more complex extrapolation models, such as the extended power-law model, often do much better.
",4 A performance extrapolation task,[0],[0]
"Based on the development corpora results presented in Figures 1 and 2, we choose the biased power law model (ê(n) = a+ bnc) with binomial
item weights (n/e(1− e)) as the model to evaluate on the evaluation corpora.
",4 A performance extrapolation task,[0],[0]
We evaluate an extrapolation by calculating the root-mean-square (RMS) of the relative residuals ê/e,4 A performance extrapolation task,[0],[0]
"− 1, where e is the minimum error achieved by the classifier with any hyperparameter setting when trained on the full training set, and ê is the predicted error made by the extrapolation model
from the pilot dataset.1
Unsurprisingly, Table 2 shows that extrapolation is more accurate from larger pilot datasets; increasing the size of the pilot dataset 5 times re-
1We use relative residuals because the residuals themselves vary greatly from corpus to corpus, and we use RMS to penalise large extrapolation errors.",4 A performance extrapolation task,[0],[0]
"We admit that RMS relative residuals is probably not a close approximation to the extrapolation loss in real applications, and we hope future work will develop more realistic loss functions.
duces the RMS relative residuals by a factor of 10.",4 A performance extrapolation task,[0],[0]
"It also clearly shows that it valuable to perform hyperparameter optimisation on all subsets of the pilot dataset, not just on the whole pilot data.",4 A performance extrapolation task,[0],[0]
"Interestingly, Table 2 shows that the RMS difference between the two approaches to hyperparameter setting is greater when the pilot data is larger.",4 A performance extrapolation task,[0],[0]
"This makes sense; the hyperparameters that are optimal on a large pilot dataset may be far from optimal on a very small subset (this is clearly visible in Figure 1, where the items deviating most are those for the = 0.5 pilot data and hyperparameter choice).",4 A performance extrapolation task,[0],[0]
"This paper introduced an extrapolation methodology for predicting accuracy on large dataset from a small pilot dataset, applied it to a document classification system, and identified the biased powerlaw model with binomial weights as a good baseline extrapolation model.",5 Conclusions and Future Work,[0],[0]
This only scratches the surface of performance extrapolation tasks.,5 Conclusions and Future Work,[0],[0]
"We hope that teams with greater computational resources will study the extrapolation task for computationally more-demanding systems, including popular deep learning models.",5 Conclusions and Future Work,[0],[0]
"The power-law models should be considered baselines for more sophisticated extrapolation models, which might exploit more information than just accuracy on subsets of the pilot data.
",5 Conclusions and Future Work,[0],[0]
"We hope this work will spur the development of better methods for estimating the resources needed to build an NLP or ML system to meet a specification, as we believe this is essential for any mature engineering field.",5 Conclusions and Future Work,[0],[0]
We would like to thank the anonymous reviewers for their insightful comments and suggestions.,Acknowledgments,[0],[0]
"This research was supported by a Google award through the Natural Language Understanding Focused Program, and under the Australian Research Council’s Discovery Projects funding scheme (project number DP160102156).",Acknowledgments,[0],[0]
"Because obtaining training data is often the most difficult part of an NLP or ML project, we develop methods for predicting how much data is required to achieve a desired test accuracy by extrapolating results from systems trained on a small pilot training dataset.",abstractText,[0],[0]
"We model how accuracy varies as a function of training size on subsets of the pilot data, and use that model to predict how much training data would be required to achieve the desired accuracy.",abstractText,[0],[0]
We introduce a new performance extrapolation task to evaluate how well different extrapolations predict system accuracy on larger training sets.,abstractText,[0],[0]
We show that details of hyperparameter optimisation and the extrapolation models can have dramatic effects in a document classification task.,abstractText,[0],[0]
We believe this is an important first step in developing methods for estimating the resources required to meet specific engineering performance targets.,abstractText,[0],[0]
Predicting accuracy on large datasets from smaller pilot data,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 541–551 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1050",text,[0],[0]
"The influence of a speaker’s native language on learning and performance in a foreign language, also known as cross-linguistic transfer, has been studied for several decades in linguistics and psychology (Odlin, 1989; Martohardjono and Flynn, 1995; Jarvis and Pavlenko, 2008; Berkes and Flynn, 2012; Alonso, 2015).",1 Introduction,[0],[0]
"The growing availably of learner corpora has also sparked interest in cross-linguistic influence phenomena in NLP, where studies have explored the task of Native Language Identification (NLI) (Tetreault et al., 2013), as well as analysis of textual features in relation to the author’s native language (Jarvis and Crossley, 2012; Swanson and Charniak, 2013; Malmasi and Dras, 2014).",1 Introduction,[0],[0]
"Despite these advances,
1The experimental data collected in this study will be made publicly available.
",1 Introduction,[0],[0]
the extent and nature of first language influence in second language processing remains far from being established.,1 Introduction,[0],[0]
"Crucially, most prior work on this topic focused on production, while little is currently known about cross-linguistic influence in language comprehension.
",1 Introduction,[0],[0]
"In this work, we present a novel framework for studying cross-linguistic influence in language comprehension using eyetracking for reading and free-form native English text.",1 Introduction,[0],[0]
"We collect and analyze English newswire reading data from 182 participants, including 145 English as Second Language (ESL) learners from four different native language backgrounds: Chinese, Japanese, Portuguese and Spanish, as well as 37 native English speakers.",1 Introduction,[0],[0]
"Each participant reads 156 English sentences, half of which are shared across all participants, and the remaining half are individual to each participant.",1 Introduction,[0],[0]
"All the sentences are manually annotated with part-of-speech (POS) tags and syntactic dependency trees.
",1 Introduction,[0],[0]
"We then introduce the task of Native Language Identification from Reading (NLIR), which requires predicting a subject’s native language from gaze while reading text in a second language.",1 Introduction,[0],[0]
"Focusing on ESL participants and using a log-linear classifier with word fixation times normalized for reading speed as features, we obtain 71.03 NLIR accuracy in the shared sentences regime.",1 Introduction,[0],[0]
"We further demonstrate that NLIR can be generalized effectively to the individual sentences regime, in which each subject reads a different set of sentences, by grouping fixations according to linguistically motivated clustering criteria.",1 Introduction,[0],[0]
"In this regime, we obtain an NLIR accuracy of 51.03.
",1 Introduction,[0],[0]
"Further on, we provide classification and feature analyses, suggesting that the signal underlying NLIR is likely to be related to linguistic characteristics of the respective native languages.",1 Introduction,[0],[0]
"First, drawing on previous work on ESL production, we
541
observe that classifier uncertainty in NLIR correlates with global linguistic similarities across native languages.",1 Introduction,[0],[0]
"In other words, the more similar are the languages, the more similar are the reading patterns of their native speakers in English.",1 Introduction,[0],[0]
"Second, we perform feature analysis across native and non-native English speakers, and discuss structural and lexical factors that could potentially drive some of the non-native reading patterns in each of our native languages.",1 Introduction,[0],[0]
"Taken together, our results provide evidence for a systematic influence of native language properties on reading, and by extension, on online processing and comprehension in a second language.
",1 Introduction,[0],[0]
"To summarize, we introduce a novel framework for studying cross-linguistic influence in language learning by using eyetracking for reading free-form English text.",1 Introduction,[0],[0]
We demonstrate the utility of this framework in the following ways.,1 Introduction,[0],[0]
"First, we obtain the first NLIR results, addressing both the shared and the individual textual input scenarios.",1 Introduction,[0],[0]
"We further show that reading preserves linguistic similarities across native languages of ESL readers, and perform feature analysis, highlighting key distinctive reading patterns in each native language.",1 Introduction,[0],[0]
"The proposed framework complements and extends production studies, and can inform linguistic inquiry on cross-linguistic influence.
",1 Introduction,[0],[0]
This paper is structured as follows.,1 Introduction,[0],[0]
In section 2 we present the data and our experimental setup.,1 Introduction,[0],[0]
Section 3 describes our approach to NLIR and summarizes the classification results.,1 Introduction,[0],[0]
We analyze cross-linguistic influence in reading in section 4.,1 Introduction,[0],[0]
In section 4.1 we examine NLIR classification uncertainty in relation to linguistic similarities between native languages.,1 Introduction,[0],[0]
In section 4.2 we discuss several key fixation features associated with different native languages.,1 Introduction,[0],[0]
"Section 5 surveys related work, and section 6 concludes.",1 Introduction,[0],[0]
"Participants
We recruited 182 adult participants.",2 Experimental Setup,[0],[0]
"Of those, 37 are native English speakers and 145 are ESL learners from four native language backgrounds: Chinese, Japanese, Portuguese and Spanish.",2 Experimental Setup,[0],[0]
All the participants in the experiment are native speakers of only one language.,2 Experimental Setup,[0],[0]
"The ESL speakers were tested for English proficiency using the grammar and listening sections of the Michigan English test (MET), which consist of 50 multiple choice ques-
tions.",2 Experimental Setup,[0],[0]
The English proficiency score was calculated as the number of correctly answered questions on these modules.,2 Experimental Setup,[0],[0]
The majority of the participants scored in the intermediate-advanced proficiency range.,2 Experimental Setup,[0],[0]
Table 1 presents the number of participants and the mean English proficiency score for each native language group.,2 Experimental Setup,[0],[0]
"Additionally, we collected metadata on gender, age, level of education, duration of English studies and usage, time spent in English speaking countries and proficiency in any additional language spoken.
",2 Experimental Setup,[0],[0]
"Reading Materials
We utilize 14,274 randomly selected sentences from the Wall Street Journal part of the Penn Treebank (WSJ-PTB) (Marcus et al., 1993).",2 Experimental Setup,[0],[0]
"To support reading convenience and measurement precision, the maximal sentence length was set to 100 characters, leading to an average sentence length of 11.4 words.",2 Experimental Setup,[0],[0]
Word boundaries are defined as whitespaces.,2 Experimental Setup,[0],[0]
"From this sentence pool, 78 sentences (900 words) were presented to all participants (henceforth shared sentences) and the remaining 14,196 sentences were split into 182 individual batches of 78 sentences (henceforth individual sentences, averaging 880 words per batch).
",2 Experimental Setup,[0],[0]
"All the sentences include syntactic annotations from the Universal Dependency Treebank project (UDT) (McDonald et al., 2013).",2 Experimental Setup,[0],[0]
"The annotations include PTB POS tags (Santorini, 1990), Google universal POS tags (Petrov et al., 2012) and dependency trees.",2 Experimental Setup,[0],[0]
"The dependency annotations of the UDT are converted automatically from the manual phrase structure tree annotations of the WSJ-PTB.
",2 Experimental Setup,[0],[0]
"Gaze Data Collection
Each participant read 157 sentences.",2 Experimental Setup,[0],[0]
The first sentence was presented to familiarize participants with the experimental setup and was discarded during analysis.,2 Experimental Setup,[0],[0]
"The following 156 sentences consisted of 78 shared and 78 individual sen-
tences.",2 Experimental Setup,[0],[0]
The shared and the individual sentences were mixed randomly and presented to all participants in the same order.,2 Experimental Setup,[0],[0]
"The experiment was divided into three parts, consisting of 52 sentences each.",2 Experimental Setup,[0],[0]
"Participants were allowed to take a short break between experimental parts.
",2 Experimental Setup,[0],[0]
Each sentence was presented on a blank screen as a one-liner.,2 Experimental Setup,[0],[0]
"The text appeared in Times font, with font size 23.",2 Experimental Setup,[0],[0]
"To encourage attentive reading, upon completion of sentence reading participants answered a simple yes/no question about its content, and were subsequently informed if they answered the question correctly.",2 Experimental Setup,[0],[0]
"Both the sentences and the questions were triggered by a 300ms gaze on a fixation target (fixation circle for sentences and the letter “Q” for questions) which appeared on a blank screen and was co-located with the beginning of the text in the following screen.
",2 Experimental Setup,[0],[0]
"Throughout the experiment, participants held a joystick with buttons for indicating completion of sentence reading and answering the comprehension questions.",2 Experimental Setup,[0],[0]
"Eye-movement of participants’ dominant eye was recorded using a desktop mount Eyelink 1000 eyetracker, at a sampling rate of 1000Hz.",2 Experimental Setup,[0],[0]
Further details on the experimental setup are provided in appendix A.,2 Experimental Setup,[0],[0]
Our first goal is to determine whether the native language of ESL learners can be decoded from their gaze patterns while reading English text.,3 Native Language Identification from Reading,[0],[0]
"We address this question in two regimes, corresponding to our division of reading input into shared and individual sentences.",3 Native Language Identification from Reading,[0],[0]
"In the shared regime, all the participants read the same set of sentences.",3 Native Language Identification from Reading,[0],[0]
"Normalizing over the reading input, this regime facilitates focusing on differences in reading behavior across readers.",3 Native Language Identification from Reading,[0],[0]
"In the individual regime, we use the individual batches from our data to address the more challenging variant of the NLIR task in which the reading material given to each participant is different.",3 Native Language Identification from Reading,[0],[0]
"We seek to utilize features that can provide robust, simple and interpretable characterizations of reading patterns.",3.1 Features,[0],[0]
"To this end, we use speed normalized fixation duration measures over word sequences.
",3.1 Features,[0],[0]
"Fixation Measures We utilize three measures of word fixation duration:
• First Fixation duration (FF) Duration of the first fixation on a word.
",3.1 Features,[0],[0]
"• First Pass duration (FP) Time spent from first entering a word to first leaving it (including re-fixations within the word).
",3.1 Features,[0],[0]
• Total Fixation duration (TF),3.1 Features,[0],[0]
"The sum of all fixation times on a word.
",3.1 Features,[0],[0]
"We experiment with fixations over unigram, bigram and trigram sequences seqi,k = wi, ..., wi+k−1, k ∈ {1, 2, 3}, where for each metric M ∈ {FF, FP, TF} the fixation time for a sequence Mseqi,k is defined as the sum of fixations on individual tokens Mw in the sequence2.
Mseqi,k = ∑
w′∈seqi,k Mw′ (1)
",3.1 Features,[0],[0]
"Importantly, we control for variation in reading speeds across subjects by normalizing each subjects’s sequence fixation times.",3.1 Features,[0],[0]
"For each metric M and sequence seqi,k we normalize the sequence fixation time Mseqi,k relative to the subject’s sequence fixation times in the textual context of the sequence.",3.1 Features,[0],[0]
The context C is defined as the sentence in which the sequence appears for the Words in Fixed Context feature-set and the entire textual input for the Syntactic and Information clusters feature-sets (see definitions of feature-sets below).,3.1 Features,[0],[0]
"The normalization term SM,C,k is accordingly defined as the metric’s fixation time per sequence of length k in the context:
SM,C,k = 1 |C| ∑
seqk∈C Mseqk (2)
",3.1 Features,[0],[0]
"We then obtain a normalized fixation time Mnormseqi,k as:
Mnormseqi,k = Mseqi,k SM,C,k
(3)
2Note that for bigrams and trigrams, one could also measure FF and FP for interest regions spanning the sequence, instead, or in addition to summing these fixation times over individual tokens.
",3.1 Features,[0],[0]
Feature Types,3.1 Features,[0],[0]
"We use the above presented speed normalized fixation metrics to extract three feature-sets, Words in Fixed Context (WFC), Syntactic Clusters (SC) and Information Clusters (IC).",3.1 Features,[0],[0]
WFC is a token-level feature-set that presupposes a fixed textual input for all participants.,3.1 Features,[0],[0]
It is thus applicable only in the shared sentences regime.,3.1 Features,[0],[0]
SC and IC are typelevel features which provide abstractions over sequences of words.,3.1 Features,[0],[0]
"Crucially, they can also be applied when participants read different sentences.
",3.1 Features,[0],[0]
• Words in Fixed Context (WFC),3.1 Features,[0],[0]
The WFC features capture fixation times on word sequences in a specific sentence.,3.1 Features,[0],[0]
"This featureset consists of FF, FP and TF times for each of the 900 unigram, 822 bigram, and 744 trigram word sequences comprising the shared sentences.",3.1 Features,[0],[0]
The fixation times of each metric are normalized for each participant relative to their fixations on sequences of the same length in the surrounding sentence.,3.1 Features,[0],[0]
"As noted above, the WFC feature-set is not applicable in the individual regime, as it requires identical sentences for all participants.
",3.1 Features,[0],[0]
"• Syntactic Clusters (SC) CS features are average globally normalized FF, FP and TF times for word sequences clustered by our three types of syntactic labels: universal POS, PTB POS, and syntactic relation labels.",3.1 Features,[0],[0]
An example of such a feature is the average of speed-normalized TF times spent on the PTB POS bigram sequence DT NN.,3.1 Features,[0],[0]
We take into account labels that appear at least once in the reading input of all participants.,3.1 Features,[0],[0]
"On the four non-native languages, considering all three label types, we obtain 104 unigram, 636 bigram and 1,310 trigram SC features per fixation metric in the shared regime, and 56 unigram, 95 bigram and 43 trigram SC features per fixation metric in the individual regime.
",3.1 Features,[0],[0]
"• Information Clusters (IC) We also obtain average FF, FP and TF for words clustered according to their length, measured in number of characters.",3.1 Features,[0],[0]
"Word length was previously shown to be a strong predictor of information content (Piantadosi et al., 2011).",3.1 Features,[0],[0]
"As such, it provides an alternative abstraction to the syntactic clusters, combining both syntactic and lexical information.",3.1 Features,[0],[0]
"As with SC features, we take into account features that ap-
pear at least once in the textual input of all participants.",3.1 Features,[0],[0]
"For our set of non-native languages, we obtain for each fixation metric 15 unigram, 21 bigram and 23 trigram IC features in the shared regime, and 12 unigram, 18 bigram and 18 trigram IC features in the individual regime.",3.1 Features,[0],[0]
"Notably, this feature-set is very compact, and differently from the syntactic clusters, does not rely on the availability of external annotations.
",3.1 Features,[0],[0]
"In each feature-set, we perform a final preprocessing step for each individual feature, in which we derive a zero mean unit variance scaler from the training set feature values, and apply it to transform both the training and the test values of the feature to Z scores.",3.1 Features,[0],[0]
"The experiments are carried out using a log-linear model:
p(y|x; θ) = exp(θ · f(x, y))∑ y′∈Y exp(θ · f(x, y′))
(4)
where y is the reader’s native language, x is the reading input and θ are the model parameters.",3.2 Model,[0],[0]
"The classifier is trained with gradient descent using LBFGS (Byrd et al., 1995).",3.2 Model,[0],[0]
"In table 2 we report 10-fold cross-validation results on NLIR in the shared and the individual experimental regimes for native speakers of Chinese, Japanese, Portuguese and Spanish.",3.3 Experimental Results,[0],[0]
We introduce two baselines against which we compare the performance of our feature-sets.,3.3 Experimental Results,[0],[0]
The majority baseline selects the native language with the largest number of participants.,3.3 Experimental Results,[0],[0]
"The random clusters baseline clusters words into groups randomly, with the number of groups set to the number of syntactic categories in our data.
",3.3 Experimental Results,[0],[0]
"In the shared regime, WFC fixations yield the highest classification rates, substantially outperforming the cluster feature-sets and the two baselines.",3.3 Experimental Results,[0],[0]
"The strongest result using this featureset, 71.03, is obtained by combining unigram, bigram and trigram fixation times.",3.3 Experimental Results,[0],[0]
"In addition to this outcome, we note that training binary classifiers in this setup yields accuracies ranging from 68.49 for the language pair Portuguese and Spanish, to 93.15 for Spanish and Japanese.",3.3 Experimental Results,[0],[0]
"These results confirm the effectiveness of the shared input
regime for performing reliable NLIR, and suggest a strong native language signal in non-native reading fixation times.
SC features yield accuracies of 45.52 to 58.62 on the shared sentences, while IC features exhibit weaker performance in this regime, with accuracies of 41.38 to 46.21.",3.3 Experimental Results,[0],[0]
"Both results are well above chance, but lower than WFC fixations due to the information loss imposed by the clustering step.",3.3 Experimental Results,[0],[0]
"Crucially, both feature-sets remain effective in the individual input regime, with 43.45 to 48.97 accuracy for SC features and 32.41 to 38.62 accuracy for IC features.",3.3 Experimental Results,[0],[0]
"The strongest result in the individual regime is 51.03, obtained by concatenating IC and SC features over unigrams.",3.3 Experimental Results,[0],[0]
"We also note that using this setup in a binary classification scheme yields results ranging from chance level 49.31 for Portuguese versus Spanish, to 84.93 on Spanish versus Japanese.
",3.3 Experimental Results,[0],[0]
"Generally, we observe that adding bigram and trigram fixations in the shared regime leads to performance improvements compared to using unigram features only.",3.3 Experimental Results,[0],[0]
"This trend does not hold for the individual sentences, presumably due to a combination of feature sparsity and context variation in this regime.",3.3 Experimental Results,[0],[0]
"We also note that IC and SC features tend to perform better together than in separation, suggesting that the information encoded using these feature-sets is to some extent complementary.
",3.3 Experimental Results,[0],[0]
The generalization power of our cluster based feature-sets has both practical and theoretical consequences.,3.3 Experimental Results,[0],[0]
"Practically, they provide useful abstractions for performing NLIR over arbitrary textual input.",3.3 Experimental Results,[0],[0]
"That is, they enable performing this task using any textual input during both training and testing phases.",3.3 Experimental Results,[0],[0]
"Theoretically, the effectiveness of linguistically motivated features in discerning native languages suggests that linguistic factors
play an important role in the ESL reading process.",3.3 Experimental Results,[0],[0]
The analysis presented in the following sections will further explore this hypothesis.,3.3 Experimental Results,[0],[0]
"As mentioned in the previous section, the ability to perform NLIR in general, and the effectiveness of linguistically motivated features in particular, suggest that linguistic factors in the native and second languages are pertinent to ESL reading.",4 Analysis of Cross-Linguistic Influence in ESL Reading,[0],[0]
"In this section we explore this hypothesis further, by analyzing classifier uncertainty and the features learned in the NLIR task.",4 Analysis of Cross-Linguistic Influence in ESL Reading,[0],[0]
"Previous work in NLP suggested a link between textual patterns in ESL production and linguistic similarities of the respective native languages (Nagata and Whittaker, 2013; Nagata, 2014; Berzak et al., 2014, 2015).",4.1 Preservation of Linguistic Similarity,[0],[0]
"In particular, Berzak et al. (2014) has demonstrated that NLI classification uncertainty correlates with similarities between languages with respect to their typological features.",4.1 Preservation of Linguistic Similarity,[0],[0]
"Here, we extend this framework and examine if preservation of native language similarities in ESL production is paralleled in reading.
",4.1 Preservation of Linguistic Similarity,[0],[0]
Similarly to Berzak et al.,4.1 Preservation of Linguistic Similarity,[0],[0]
"(2014) we define the classification uncertainty for a pair of native languages y and y′ in our data collection D, as the average probability assigned by the NLIR classifier to one language given the other being the true native language.",4.1 Preservation of Linguistic Similarity,[0],[0]
This approach provides a robust measure of classification confusion that does not rely on the actual performance of the classifier.,4.1 Preservation of Linguistic Similarity,[0],[0]
"We interpret the classifier uncertainty as a similarity measure between the respective languages and de-
note it as English Reading Similarity ERS.
ERSy,y′",4.1 Preservation of Linguistic Similarity,[0],[0]
"=
∑ (x,y)∈Dy p(y′|x;θ)+ ∑ (x,y′)∈Dy′ p(y|x;θ)
|Dy |+|Dy′ | (5)
We compare these reading similarities to the linguistic similarities between our native languages.",4.1 Preservation of Linguistic Similarity,[0],[0]
"To approximate these similarities, we utilize feature vectors from the URIEL Typological Compendium (Littel et al., 2016) extracted using the lang2vec tool (Littell et al., 2017).",4.1 Preservation of Linguistic Similarity,[0],[0]
"URIEL aggregates, fuses and normalizes typological, phylogenetic and geographical information about the world’s languages.
",4.1 Preservation of Linguistic Similarity,[0],[0]
"We obtain all the 103 available morphosyntactic features in URIEL, which are derived from the World Atlas of Language Structures (WALS) (Dryer and Haspelmath, 2013), Syntactic Structures of the World’s Languages (SSWL) (Collins and Kayne, 2009) and Ethnologue (Lewis et al., 2015).",4.1 Preservation of Linguistic Similarity,[0],[0]
Missing feature values are completed with a KNN classifier.,4.1 Preservation of Linguistic Similarity,[0],[0]
"We also extract URIEL’s 3,718 language family features derived from Glottolog (Hammarström et al., 2015).",4.1 Preservation of Linguistic Similarity,[0],[0]
Each of these features represents membership in a branch of Glottolog’s world language tree.,4.1 Preservation of Linguistic Similarity,[0],[0]
"Truncating features with the same value for all our languages, we remain with 76 features, consisting of 49 syntactic features and 27 family tree features.",4.1 Preservation of Linguistic Similarity,[0],[0]
"The linguistic similarity LS between a pair of languages y and y′ is then determined by the cosine similarity of their URIEL feature vectors.
",4.1 Preservation of Linguistic Similarity,[0],[0]
"LSy,y′ =",4.1 Preservation of Linguistic Similarity,[0],[0]
"vy · vy′ ‖vy‖‖vy′‖
(6)
",4.1 Preservation of Linguistic Similarity,[0],[0]
Figure 1 presents the URIEL based linguistic similarities for our set of non-native languages against the average NLIR classification uncertainties on the cross-validation test samples.,4.1 Preservation of Linguistic Similarity,[0],[0]
The results presented in this figure are based on the unigram IC+SC feature-set in the individual sentences regime.,4.1 Preservation of Linguistic Similarity,[0],[0]
"We also provide a graphical illustration of the language similarities for each measure, using the Ward clustering algorithm (Ward Jr, 1963).",4.1 Preservation of Linguistic Similarity,[0],[0]
We observe a correlation between the two measures which is also reflected in similar hierarchies in the two language trees.,4.1 Preservation of Linguistic Similarity,[0],[0]
"Thus, linguistically motived features in English reveal linguistic similarities across native languages.",4.1 Preservation of Linguistic Similarity,[0],[0]
"This outcome supports the hypothesis that English
reading differences across native languages are related to linguistic factors.
",4.1 Preservation of Linguistic Similarity,[0],[0]
"We note that while comparable results are obtained for the IC and SC feature-sets, together and in separation in the shared regime, WFC features in the shared regime do not exhibit a clear uncertainty distinction when comparing across the pairs Japanese and Spanish, Japanese and Portuguese, Chinese and Spanish, and Chinese and Portuguese.",4.1 Preservation of Linguistic Similarity,[0],[0]
"Instead, this feature-set yields very low uncertainty, and correspondingly very high performance ranging from 90.41 to 93.15, for all four language pairs.",4.1 Preservation of Linguistic Similarity,[0],[0]
"Our framework enables not only native language classification, but also exploratory analysis of native language specific reading patterns in English.",4.2 Feature Analysis,[0],[0]
The basic question that we examine in this respect is on which features do readers of different native language groups spend more versus less time.,4.2 Feature Analysis,[0],[0]
We also discuss several potential relations of the observed reading time differences to usage patterns and grammatical errors committed by speakers of our four native languages in production.,4.2 Feature Analysis,[0],[0]
"We obtain this information by extracting grammatical error counts from the CLC FCE corpus (Yannakoudakis et al., 2011), and from the ngram frequency analysis in Nagata and Whittaker (2013).
",4.2 Feature Analysis,[0],[0]
"In order to obtain a common benchmark for reading time comparisons across non-native speakers, in this analysis we also consider our group of native English speakers.",4.2 Feature Analysis,[0],[0]
"In this context, we train four binary classifiers that discern each of the non-native groups from native English speakers based on TF times over unigram PTB POS tags in the shared regime.",4.2 Feature Analysis,[0],[0]
The features with the strongest positive and negative weights learned by these classifiers are presented in table 3.,4.2 Feature Analysis,[0],[0]
"These features serve as a reference point for selecting the case studies discussed below.
",4.2 Feature Analysis,[0],[0]
"Interestingly, some of the reading features that are most predictive of each native language lend themselves to linguistic interpretation with respect to structural factors.",4.2 Feature Analysis,[0],[0]
"For example, in Japanese and Chinese we observe shorter reading times for determiners (DT), which do not exist in these languages.",4.2 Feature Analysis,[0],[0]
"Figure 2a presents the mean TF times for determiners in all five native languages, suggesting that native speakers of Portuguese and Spanish, which do have determiners, do not exhibit reduced reading times on this structure compared to natives.",4.2 Feature Analysis,[0],[0]
"In ESL production, missing determiner errors are the most frequent error for native speakers of Japanese and third most common error for native speakers of Chinese.
",4.2 Feature Analysis,[0],[0]
"In figure 2b we present the mean TF reading times for pronouns (PRP), where we also see shorter reading times by natives of Japanese and Chinese as compared to English natives.",4.2 Feature Analysis,[0],[0]
In both languages pronouns can be omitted both in object and subject positions.,4.2 Feature Analysis,[0],[0]
"Portuguese and Spanish, in which pronoun omission is restricted to the subject position present similar albeit weaker tendency.
",4.2 Feature Analysis,[0],[0]
"In figure 2c we further observe that differently from natives of Chinese and Japanese, native speakers of Portuguese and Spanish spend more time on NN+POS in head final possessives such as “the public’s confidence”.",4.2 Feature Analysis,[0],[0]
"While similar constructions exist in Chinese and Japanese, the NN+POS combination is expressed in Portuguese and Spanish as a head initial NN of NN.",4.2 Feature Analysis,[0],[0]
"This form exists in English (e.g. “the confidence of the public”) and is preferred by speakers of these languages in ESL writing (Nagata and Whittaker, 2013).",4.2 Feature Analysis,[0],[0]
"As an additional baseline for this construction, we provide the TF times for NN in figure 2d.",4.2 Feature Analysis,[0],[0]
"There, relative to English natives, we observe longer reading times for Japanese and Chinese and comparable times for Portuguese and Spanish.
",4.2 Feature Analysis,[0],[0]
"The reading times of NN in figure 2d also give
rise to a second, potentially competing interpretation of differences in ESL reading times, which highlights lexical rather than structural factors.",4.2 Feature Analysis,[0],[0]
"According to this interpretation, increased reading times of nouns are the result of substantially smaller lexical sharing with English by Chinese and Japanese as compared to Spanish and Portuguese.",4.2 Feature Analysis,[0],[0]
"Given the utilized speed normalization, lexical effects on nouns could in principle account for reduced reading times on determiners and pronouns.",4.2 Feature Analysis,[0],[0]
"Conversely, structural influence leading to reduced reading times on determiners and pronouns could explain longer dwelling on nouns.",4.2 Feature Analysis,[0],[0]
A third possibility consistent with the observed reading patterns would allow for both structural and lexical effects to impact second language reading.,4.2 Feature Analysis,[0],[0]
"Importantly, in each of these scenarios, ESL reading patterns are related to linguistic factors of the reader’s native language.
",4.2 Feature Analysis,[0],[0]
"We note that the presented analysis is preliminary in nature, and warrants further study in future research.",4.2 Feature Analysis,[0],[0]
"In particular, reading times and classifier learned features may in some cases differ between the shared and the individual regimes.",4.2 Feature Analysis,[0],[0]
"In the examples presented above, similar results are obtained in the individual sentences regime for DT, PRP and NN.",4.2 Feature Analysis,[0],[0]
"The trend for the NN+POS construction, however, diminishes in that setup with similar reading times for all languages.",4.2 Feature Analysis,[0],[0]
"On the other hand, one of the strongest features for predicting Portuguese and Spanish in the individual regime are longer reading times for prepositions (IN), an outcome that holds in the shared regime only relative to Chinese and Japanese, but not relative to native speakers of English.
",4.2 Feature Analysis,[0],[0]
"Despite these caveats, our results suggest that reading patterns can potentially be related to linguistic factors of the reader’s native language.",4.2 Feature Analysis,[0],[0]
"This analysis can be extended in various ways, such as inclusion of additional feature types and fixation metrics, as well as utilization of other comparative methodologies.",4.2 Feature Analysis,[0],[0]
"Combined with evidence from language production, this line of investigation can be instrumental for informing linguistic theory of cross-linguistic influence.",4.2 Feature Analysis,[0],[0]
"Eyetracking and second language reading Second language reading has been studied using eyetracking, with much of the work focusing on processing of syntactic ambiguities and analysis
of specific target word classes such as cognates (Dussias, 2010; Roberts and Siyanova-Chanturia, 2013).",5 Related Work,[0],[0]
"In contrast to our work, such studies typically use controlled, rather than free-form sentences.",5 Related Work,[0],[0]
Investigation of global metrics in freeform second language reading was introduced only recently by Cop et al. (2015).,5 Related Work,[0],[0]
"This study compared ESL and native reading of a novel by native speakers of Dutch, observing longer sentence reading times, more fixations and shorter saccades in ESL reading.",5 Related Work,[0],[0]
"Differently from this study, our work focuses on comparison of reading patterns between different native languages.",5 Related Work,[0],[0]
"We also analyze a related, but different metric, namely speed normalized fixation durations on word sequences.
",5 Related Work,[0],[0]
Eyetracking for NLP tasks Recent work in NLP has demonstrated that reading gaze can serve as a valuable supervision signal for standard NLP tasks.,5 Related Work,[0],[0]
"Prominent examples of such work include POS tagging (Barrett and Søgaard, 2015a; Barrett et al., 2016), syntactic parsing (Barrett and Søgaard, 2015b) and sentence compression (Klerke et al., 2016).",5 Related Work,[0],[0]
"Our work also tackles a traditional NLP task with free-form text, but differs from this line of research in that it addresses this task only in comprehension.",5 Related Work,[0],[0]
"Furthermore, while these studies use gaze recordings of native readers, our work focuses on non-native readers.
",5 Related Work,[0],[0]
"NLI in production NLI was first introduced in Koppel et al. (2005) and has been drawing considerable attention in NLP, including a recent shared-task challenge with 29 participating teams (Tetreault et al., 2013).",5 Related Work,[0],[0]
"NLI has also been driving much of the work on identification of native language related features in writing (Tsur and Rappoport, 2007; Jarvis and Crossley, 2012; Brooke and Hirst, 2012; Tetreault et al., 2012; Swanson and Charniak, 2013, 2014; Malmasi and Dras, 2014; Bykh and Meurers, 2016).",5 Related Work,[0],[0]
"Several studies have also linked usage patterns and grammatical errors in production to linguistic properties of the writer’s native language (Nagata and Whittaker, 2013; Nagata, 2014; Berzak et al., 2014, 2015).",5 Related Work,[0],[0]
Our work departs from NLI in writing and introduces NLI and related feature analysis in reading.,5 Related Work,[0],[0]
"We present a novel framework for studying crosslinguistic influence in multilingualism by measuring gaze fixations during reading of free-form En-
glish text.",6 Conclusion and Outlook,[0],[0]
We demonstrate for the first time that this signal can be used to determine a reader’s native language.,6 Conclusion and Outlook,[0],[0]
The effectiveness of linguistically motivated criteria for fixation clustering and our subsequent analysis suggest that the ESL reading process is affected by linguistic factors.,6 Conclusion and Outlook,[0],[0]
"Specifically, we show that linguistic similarities between native languages are reflected in similarities in ESL reading.",6 Conclusion and Outlook,[0],[0]
"We also identify several key features that characterize reading in different native languages, and discuss their potential connection to structural and lexical properties of the native langauge.",6 Conclusion and Outlook,[0],[0]
"The presented results demonstrate that eyetracking data can be instrumental for developing predictive and explanatory models of second language reading.
",6 Conclusion and Outlook,[0],[0]
"While this work is focused on NLIR from fixations, our general framework can be used to address additional aspects of reading, such as analysis of saccades and gaze trajectories.",6 Conclusion and Outlook,[0],[0]
"In future work, we also plan to explore the role of native and second language writing system characteristics in second language reading.",6 Conclusion and Outlook,[0],[0]
"More broadly, our methodology introduces parallels with production studies in NLP, creating new opportunities for integration of data, methodologies and tasks between production and comprehension.",6 Conclusion and Outlook,[0],[0]
"Furthermore, it holds promise for formulating language learning theory that is supported by empirical findings in naturalistic setups across language processing domains.",6 Conclusion and Outlook,[0],[0]
"We thank Amelia Smith, Emily Weng, Run Chen and Lila Jansen for contributions to stimuli preparation and data collection.",Acknowledgements,[0],[0]
"We also thank Andrei Barbu, Guy Ben-Yosef, Yen-Ling Kuo, Roger Levy, Jonathan Malmaud, Karthik Narasimhan and the anonymous reviewers for valuable feedback on this work.",Acknowledgements,[0],[0]
"This material is based upon work supported by the Center for Brains, Minds, and Machines (CBMM), funded by NSF STC award CCF-1231216.",Acknowledgements,[0],[0]
"Eyetracking Setup We use a 44.5x30cm screen with 1024x768px resolution to present the reading materials, and a desktop mount Eyelink 1000 eyetracker (1000Hz) to record gaze.",A Supplemental Material,[0],[0]
"The screen, eyetracker camera and chinrest are horizontally aligned on a table surface.",A Supplemental Material,[0],[0]
"The screen center (x=512, y=384) is 79cm away from the center of
the forehead bar, and 13cm below it.",A Supplemental Material,[0],[0]
The eyetracker camera knob is 65cm away from forehead bar.,A Supplemental Material,[0],[0]
"Throughout the experiment participants hold a joystick with a button for indicating sentence completion, and two buttons for answering yes/no questions.",A Supplemental Material,[0],[0]
"We record gaze of the participant’s dominant eye.
",A Supplemental Material,[0],[0]
"Text Parameters All the textual material in the experiment is presented using Times font, normal style, with font size 23.",A Supplemental Material,[0],[0]
"In our setup, this corresponds to 0.36 degrees (11.3px) average lower case letter width, and 0.49 degrees (15.7px) average upper case letter width.",A Supplemental Material,[0],[0]
"We chose a nonmonospace font, as such fonts are generally more common in reading.",A Supplemental Material,[0],[0]
"They are also more compact compared to monospace fonts, allowing to substantially increase the upper limit for sentence length.
",A Supplemental Material,[0],[0]
"Calibration We use 3H line calibration with point repetition on the central horizontal line (y=384), using 16px outer circle, 6px inner circle, fixation points.",A Supplemental Material,[0],[0]
"At least three calibrations are performed during the experiment, one at the beginning of each experimental section.",A Supplemental Material,[0],[0]
We also recalibrate upon failure to produce a 300ms fixation on any fixation trigger preceding a sentence or a question within 4 seconds after its appearance.,A Supplemental Material,[0],[0]
The mean validation error for calibrations across subjects is 0.146 degrees (std 0.038).,A Supplemental Material,[0],[0]
A fundamental question in language learning concerns the role of a speaker’s first language in second language acquisition.,abstractText,[0],[0]
We present a novel methodology for studying this question: analysis of eye-movement patterns in second language reading of free-form text.,abstractText,[0],[0]
"Using this methodology, we demonstrate for the first time that the native language of English learners can be predicted from their gaze fixations when reading English.",abstractText,[0],[0]
"We provide analysis of classifier uncertainty and learned features, which indicates that differences in English reading are likely to be rooted in linguistic divergences across native languages.",abstractText,[0],[0]
The presented framework complements production studies and offers new ground for advancing research on multilingualism.1,abstractText,[0],[0]
Predicting Native Language from Gaze,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 659–664 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
659",text,[0],[0]
"The data generated from online news consumption constitutes a rich resource, which allows us to explore the relation between news content and user opinions and behaviors.",1 Introduction,[0],[0]
"In order to stay in business, newspapers need to pay attention to this information.",1 Introduction,[0],[0]
"For example, what headlines do users click on, and why?",1 Introduction,[0],[0]
"With the volume of news being consumed online today, there is great interest in addressing this problem algorithmically.",1 Introduction,[0],[0]
"We collaborate with a large Danish newspaper, who gave us access to several years’ worth of headlines, and the number of clicks generated by readers.
",1 Introduction,[0],[0]
"We aggregate the viewing logs to classify headlines as popular or unpopular, and build models to predict those classifications.",1 Introduction,[0],[0]
We use an expanded version of the dataset investigated by Hardt and Rambow (2017).,1 Introduction,[0],[0]
"That work found that bag-ofword models based on headlines did indeed have predictive value concerning viewing behavior, although models based on the article body were more accurate.",1 Introduction,[0],[0]
"As Hardt and Rambow noted, this is somewhat paradoxical: how can a model based
on the article text be better at predicting clicks?",1 Introduction,[0],[0]
"After all, the choice to click on an article must be based on the headline alone – the article is only seen after the clicking decision is made.",1 Introduction,[0],[0]
"Hardt and Rambow speculate that “it is possible that the headline on its own gives readers a lot of semantic information which we are not capturing with our features, but which the whole article does provide.",1 Introduction,[0],[0]
So human readers can “imagine” the article before they read it and implicitly base their behavior on their expectation.”,1 Introduction,[0],[0]
"(Hardt and Rambow, 2017)
",1 Introduction,[0],[0]
"In other words, readers are able to anticipate the contents of an article in advance from a headline, because of the linguistic and world knowledge that they bring to bear when assessing the headline.",1 Introduction,[0],[0]
"If we can incorporate this “future” knowledge into a prediction model, we are likely to improve performance.
",1 Introduction,[0],[0]
"We test this hypothesis by defining ways to model aspects of the lexical, structural, and topical knowledge of human news readers:
• Lexical – Word Embeddings: we provide our models with pretrained word embeddings from large datasets.",1 Introduction,[0],[0]
"This models aspects of the rich lexical information and association that human readers bring to bear in reading a headline.
",1 Introduction,[0],[0]
"• Structural – POS Tagging: part of speech information is a basic component of structural linguistic knowledge, reflected in the structure of common headline templates such as “Can X do Y?” or “You will not believe what happened when X”.
",1 Introduction,[0],[0]
"• Topical – Section Prediction: Each article is labeled with a section (sports, politics, etc).",1 Introduction,[0],[0]
We include a task which predicts the section of a headline.,1 Introduction,[0],[0]
"This models the ability of a news reader to understand the most salient
and interesting topical material in a headline text.
",1 Introduction,[0],[0]
"We use a multi-task learning (MTL) setup (Caruana, 1993), which provides a natural framework to test the above hypotheses: one of the first uses of MTL was to include the outcome of future diagnostic tests into a prediction task (Caruana et al., 1996).
",1 Introduction,[0],[0]
"We explore the effect of pretrained word embeddings, and the effects of auxiliary tasks involving POS tagging and section prediction.",1 Introduction,[0],[0]
"We find that the combination of all of these factors results in substantial improvements over the baseline and the previous work, which used a single-task system.",1 Introduction,[0],[0]
"We also build logistic regression models, both for word and character n-grams.",1 Introduction,[0],[0]
"The wordbased models have the advantage that the predictiveness of individual words can be examined.
",1 Introduction,[0],[0]
"While the word n-gram models have performance comparable to the baseline neural net, the character n-gram model has higher performance, competing with the best MTL result.",1 Introduction,[0],[0]
"This finding is in line with the results from Zhang et al. (2015).
",1 Introduction,[0],[0]
Our results indicate that MTL can indeed provide the tools to implement prediction processes that involve expectations about the future.,1 Introduction,[0],[0]
"Given the successful integration of two auxiliary tasks, we see this as a promising starting point for future research.",1 Introduction,[0],[0]
"However, the performance parity with the character model underscores the fact that simple model architectures still have a place.",1 Introduction,[0],[0]
"Our findings, in line with other current work (Benton et al., 2017), shine light on the question of auxiliary task selection and their interaction, and highlight that MTL results should be rigorously tested.
",1 Introduction,[0],[0]
"A good predictive model is a powerful diagnostic tool for editors, allowing them to select proposed headlines.",1 Introduction,[0],[0]
"However, journalism is a creative production process, so detection is only part of the application.",1 Introduction,[0],[0]
We also want to be able to give strategic advice to headline writers.,1 Introduction,[0],[0]
"To this end, we report an analysis of common n-gram features in the word-based logistic regression model, that provide some insights into successful headline patterns.
",1 Introduction,[0],[0]
Contributions We explore an MTL architecture with two auxiliary tasks for headline popularity prediction.,1 Introduction,[0],[0]
"We show how aspects of lexical, structural, and topical knowledge are all relevant for headline popularity.",1 Introduction,[0],[0]
The positive results reported here provide a fruitful basis for further development of MTL models for news data.,1 Introduction,[0],[0]
"We also ana-
lyze lexical features that are predictive of headline popularity.",1 Introduction,[0],[0]
News Data,2 Data,[0],[0]
The present work is based on a significantly expanded and cleaned version of the dataset used by Hardt and Rambow (2017).,2 Data,[0],[0]
This dataset includes Jyllands-Posten articles and logs.,2 Data,[0],[0]
Jyllands-Posten is a major Danish newspaper (and became known to an international audience over the cartoon controversy).,2 Data,[0],[0]
The data covers a period from July 2015 through July 2017.,2 Data,[0],[0]
"We removed any articles from before July 2015, when the viewing logs began, since these older articles have unreliable numbers of clicks.",2 Data,[0],[0]
"The resulting dataset consists of 82,532 articles and a total of 281,005,390 user views.",2 Data,[0],[0]
"We furthermore extracted the news section each article belongs to (sports, politics, etc.) from the URL.
",2 Data,[0],[0]
"We bin the articles by numbers of clicks into 2 bins, thus defining a classification task: is the article in the top 50% of clicks or not?",2 Data,[0],[0]
"The data is divided into 80% training, and 10% each development and test data.
",2 Data,[0],[0]
"Figure 1 shows the top headline on the JyllandsPosten web site for August 27, 2018.",2 Data,[0],[0]
"Our data does not include information such as the position of a headline on the page, and possible associated graphical material.
",2 Data,[0],[0]
Additional Data,2 Data,[0],[0]
"In addition to the news data from JP, we obtained a corpus of 100 million words of Danish text from the Society for Danish Language and Literature, or DSL (Jørg Asmussen, 2018).",2 Data,[0],[0]
"This corpus was collected from diverse
sources over a period from 1990 to 2010.",2 Data,[0],[0]
"The corpus has been automatically annotated for part of speech and lemmatization, and we use this for our POS tagging task.",2 Data,[0],[0]
"We also downloaded the Danish Wikipedia, which consists of approximately 49 million words of Danish text.",2 Data,[0],[0]
"We use these corpora in conjunction with the JP article texts to induce pre-trained Danish word-embeddings.
",2 Data,[0],[0]
Data Statement A. CURATION,2 Data,[0],[0]
RATIONALE,2 Data,[0],[0]
"The dataset is collected by Jyllands-Posten as part of a general strategy to understand user behavior and preferences with respect to the news content on the site.
",2 Data,[0],[0]
B. LANGUAGE VARIETY,2 Data,[0],[0]
"The data is Danish (da-DK).
",2 Data,[0],[0]
"C. SPEAKER DEMOGRAPHIC The text is produced by professional journalists.
",2 Data,[0],[0]
"D. ANNOTATOR DEMOGRAPHIC There is no manual annotation of the text.
",2 Data,[0],[0]
E. SPEECH SITUATION,2 Data,[0],[0]
"The texts were produced from July 2015 until July 2017; the intended audience is Danish news consumers.
",2 Data,[0],[0]
F. TEXT CHARACTERISTICS,2 Data,[0],[0]
"The text is standard, mainstream Danish journalism.",2 Data,[0],[0]
"Our task is to predict which articles get the most user clicks, based on the headline alone.",3 Models,[0],[0]
"We report results using logistic regression and a neural network, using MTL.
Logistic Regression We define the following features for logistic regression models:
1. n",3 Models,[0],[0]
"-chars: sequences of n characters, with n ranging from 2 to 6 in all experiments.
",3 Models,[0],[0]
"2. word unigrams: tfidf scores for all word unigrams
3.",3 Models,[0],[0]
"word bigrams: tfidf scores for all word bigrams
GRU Neural Network While the task is classification, which could be done with a feed-forward model, we want a sequential architecture, so that we can incorporate POS tagging as an auxiliary task, adding POS output at each time step.
",3 Models,[0],[0]
"Based on good results in recent work (Lee and Dernoncourt, 2016), (Liu et al., 2016), we choose a Recurrent Neural Network architecture and after
a series of experiments on the training and validation set, we obtained the best results using GRU (Gated Recurrent Unit) units.
",3 Models,[0],[0]
"Each layer k consists of two sets of units, labeled fw and bw that process the sequence forwards and backwards respectively, so that information from the whole sequence is available on every timestep t.",3 Models,[0],[0]
The two directions’ activations are concatenated and fed to a fully-connected softmax (for multi-class classification) or sigmoid layer (for binary classification) to get the output probability ykt of the task associated with layer k.,3 Models,[0],[0]
"So that higher level tasks can benefit, we embed the output probabilities using the fully connected label embedding LE layer, a technique used on similar scenarios (Rønning et al., 2018).",3 Models,[0],[0]
"The embedded label gets concatenated with the GRU output to get the activation akt that gets fed in the next layer, or the final fully connected prediction layer, as presented in figure 2.
",3 Models,[0],[0]
"In the sequential auxiliary task, i.e. POS tagging, this is done for every timestep, while for the classification tasks the prediction is made on the final timestep.
",3 Models,[0],[0]
"For regularization, we apply dropout on every layer of our network.
",3 Models,[0],[0]
"Auxiliary Tasks In our setup, we use two auxiliary tasks:
1.",3 Models,[0],[0]
"POS tagging: we include POS tagging using the DSL dataset on the first recurrent layer of the GRU.
2.",3 Models,[0],[0]
"Section prediction: we include classification into one of the 227 sections of the Jyllands-
Posten website.",3 Models,[0],[0]
"The output for this task is based on the penultimate recurrent layer.
",3 Models,[0],[0]
"Hyper-parameters and Training We perform a grid search to find the best hyper-parameters for a single-task model (i.e., without any auxiliary tasks) and then keep those settings for all our experiments.",3 Models,[0],[0]
"We settle on a model with hidden size H = 112 and Nk = 3 layers, respectively.",3 Models,[0],[0]
"The dropout probability p = 0.3 gave best results for both models.
",3 Models,[0],[0]
"We train the model for 10 epochs using Adam optimizer with the default parameters, clipping the gradient updates so that their norm is not higher than 5.",3 Models,[0],[0]
"We train the different tasks sequentially for each epoch, with the lower level (POS tagging) first and the popularity prediction last.",3 Models,[0],[0]
"Additionally, we decay the learning rate by a factor of 0.9 after each epoch.",3 Models,[0],[0]
"While this is not common with adaptive methods such as Adam, it performed better.",3 Models,[0],[0]
We stop training if the accuracy on the development set stops improving.,3 Models,[0],[0]
Tables 1 and 2 report accuracy for logistic regression and neural classifiers.,4 Results,[0],[0]
"We also give the best score from Hardt and Rambow (2017) for comparison purposes (note, though, that the data sets are not identical and can therefore not be directly compared).",4 Results,[0],[0]
We observe a substantial improvement over the baseline GRU when incorporating the pre-trained embeddings and both auxiliary tasks.,4 Results,[0],[0]
"It seems that pretrained embeddings and MTL act at least partly as regularizers, as these models trained for more epochs without overfitting.",4 Results,[0],[0]
"Interestingly, we observe a similar improvement over the word-based logistic regression models with a character n-gram model.",4 Results,[0],[0]
"Our main focus in this paper is on MTL as a framework to explore the lexical, structural and topical knowledge involved in users’ selection of headlines.",5 Analysis and Discussion,[0],[0]
"However, recognizing a popular headline and giving advice on how to write one are not the same: we want to provide editors and journalists with insights as to what constructions are likely to attract more eyeballs.
",5 Analysis and Discussion,[0],[0]
One way to explore this is to examine individual words and their contribution to predictiveness.,5 Analysis and Discussion,[0],[0]
"Table 3 displays the top 20 unigrams based on their
coefficients in the logistic regression model.",5 Analysis and Discussion,[0],[0]
For each unigram we provide a translation (if needed) and a comment.,5 Analysis and Discussion,[0],[0]
We classify several unigrams as Deictic-reference.,5 Analysis and Discussion,[0],[0]
"This follows Blom and Hansen (2015), who suggest that headline ”clickbait” often relies on forward-looking expressions, such as ”This”, as in, e.g., ”This is how you should eat an avocado”.",5 Analysis and Discussion,[0],[0]
"Here, ”this” is a referring expression, but the reader understands that the antecedent will be found in the article body.",5 Analysis and Discussion,[0],[0]
Several of these top unigrams are names that are of specific topical interest in areas such as sports and politics.,5 Analysis and Discussion,[0],[0]
"Others mention topics of more general interest (Researchers, dead, found).",5 Analysis and Discussion,[0],[0]
"The second person pronoun is also on the list – in general, it was found that second person pronouns are far more predictive of popularity than first or third person pronouns.",5 Analysis and Discussion,[0],[0]
"Finally, several unigrams identify sections of the newspaper of particular interest (car, weather, analysis, and satire).",5 Analysis and Discussion,[0],[0]
"Prediction of news headline popularity is an increasingly important problem, as news consumption has moved online.",6 Related Work,[0],[0]
"The insights and models described here might well be applicable to related problems of interest: for example, Balakrishnan and Parekh (2014) and Jaidka et al. (2018) study the problem of predicting clicks on email subject lines.
",6 Related Work,[0],[0]
Subramanian et al. (2018) show that a regression-based multitask approach can increase performance for the classification prediction of popularity.,6 Related Work,[0],[0]
"Their work looks at the popularity of online petitions, but the methodology applies to our subject as well, and ties in with the approaches taken in this project.
",6 Related Work,[0],[0]
"Benton et al. (2017) caution that in order to evaluate MTL results properly, we need to take the number of parameters into account.",6 Related Work,[0],[0]
"Our results to some extent support this finding, by showing that a simpler linear model can fare equally well on the task.
",6 Related Work,[0],[0]
"The choice of auxiliary tasks greatly influences the performance of MTL architectures, prompting several recent investigations into the selection process (Alonso and Plank, 2017; Bingel and Søgaard, 2017).",6 Related Work,[0],[0]
"However, it is still unclear whether these tasks serve as mere regularizers, or whether they can also impart some additional information.",6 Related Work,[0],[0]
We presented an exploratory approach to predicting newspaper article popularity from headlines alone.,7 Conclusion,[0],[0]
"Using pre-trained embeddings and a MTL setup, we are able to incorporate rich structural and semantic knowledge into the task and substantially improve performance.",7 Conclusion,[0],[0]
"While the results are encouraging and allow the exploration of further auxiliary tasks (for example article word prediction), we find that a simple character-based n-
gram model performs competitively.",7 Conclusion,[0],[0]
"These findings highlight two aspects: 1) For any application of MTL, this is a strong case for comparing the results to non-deep models.",7 Conclusion,[0],[0]
"While it is comparatively easy to show an improvement over the basic STL model, there might be other simple models that are competitive.",7 Conclusion,[0],[0]
2),7 Conclusion,[0],[0]
"The selection of auxiliary tasks greatly influences the performance, even beyond simple regularization, and in a non-linear way.",7 Conclusion,[0],[0]
"It does, however, provide us with a tool to test human intuitions about task interactions and the importance of certain problem aspects.",7 Conclusion,[0],[0]
Thanks to A. Michele Colombo for help with the data and experiments.,Acknowledgments,[0],[0]
"We also thank JyllandsPosten for giving us access to the data, and to DSL for data for embeddings and POS annotations.",Acknowledgments,[0],[0]
"Newspapers need to attract readers with headlines, anticipating their readers’ preferences.",abstractText,[0],[0]
"These preferences rely on topical, structural, and lexical factors.",abstractText,[0],[0]
We model each of these factors in a multi-task GRU network to predict headline popularity.,abstractText,[0],[0]
"We find that pre-trained word embeddings provide significant improvements over untrained embeddings, as do the combination of two auxiliary tasks, newssection prediction and part-of-speech tagging.",abstractText,[0],[0]
"However, we also find that performance is very similar to that of a simple Logistic Regression model over character n-grams.",abstractText,[0],[0]
"Feature analysis reveals structural patterns of headline popularity, including the use of forward-looking deictic expressions and second person pronouns.",abstractText,[0],[0]
Predicting News Headline Popularity with Syntactic and Semantic Knowledge Using Multi-Task Learning,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 130–139, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
130",text,[0],[0]
"Co-located, face-to-face spoken dialogue is the primary and basic setting where humans learn their first language (Fillmore, 1981) partly because dialogue participants (i.e., caregiver and child) can denote objects in their shared environment which is an important developmental step in child language acquisition (McCune, 2008).",1 Introduction,[0],[0]
"This setting motivates human-robot interaction tasks where robots acquire semantic meanings of words, and where part of the semantic representation of those words is grounded (Harnad, 1990) somehow in the physical world (e.g., the semantics of the word red is grounded in perception of color vision).",1 Introduction,[0],[0]
"Language grounding for robots has received increased attention (Bansal et al., 2017) and language learning is an essential aspect to robots that learn about their environment and how to interact naturally with humans.
",1 Introduction,[0],[0]
"However, humans who interact with robots often assign anthropomorphic characteristics to
robots depending on how they perceive those robots; for example stereotypical gender (Eyssel and Hegel, 2012), social categorizations (Eyssel and Kuchenbrandt, 2012) stereotypical roles (Tay et al., 2014), as well as intelligence, interpretability, and sympathy (Novikova et al., 2017).",1 Introduction,[0],[0]
"This has implications for the kinds of tasks that we ask our robots to do and the settings in which robots perform those tasks, including tasks where language grounding and acquisition is either a direct or indirect goal.",1 Introduction,[0],[0]
"It is important not to assume that humans will perceive the robot in the “correct” way; rather, the age and academic level appropriateness needs to be monitored, particularly in a grounding and first-language acquisition task.",1 Introduction,[0],[0]
The obvious follow-up question here is: Do robots need to acquire language as human children do?,1 Introduction,[0],[0]
"Certainly, enough functional systems exist that show how language can be acquired in many ways.",1 Introduction,[0],[0]
"The motivation here, however, is that those systems could be missing something in the language acquisition process that children receive because of the way they are perceived by human dialogue partners.",1 Introduction,[0],[0]
"We cannot tell until we have a robot that is shown as being perceived as a child (current work) and use that robot for language learning tasks (future work).
",1 Introduction,[0],[0]
"We hypothesize in this paper that how a robot looks and acts will not only affect how humans perceive that robot’s intelligence, but it will also affect how humans perceive that robot’s age and academic level.",1 Introduction,[0],[0]
"In particular, we explore how humans perceive three different systems: two embodied robots, and one a spoken dialogue system (explained in Section 3).",1 Introduction,[0],[0]
"We show through an experiment that human perception of robots, particularly in how they perceive the robots’ intelligence, age, and academic level, is due to how the robot appears, but also due to how the robot uses speech to interact.",1 Introduction,[0],[0]
"Several areas of research play into this work including seminal (Roy and Reiter, 2005) and recent work in grounded semantic learning in various tasks and settings, notably learning descriptions of the immediate environment (Walter et al., 2014); navigation (Kollar et al., 2010); nouns, adjectives, and relational spatial descriptions (Kennington and Schlangen, 2015); spatial operations (Bisk et al., 2018), and verbs (She and Chai, 2016).",2 Related Work,[0],[0]
"Previous work has also focused on multimodal aspects of human-robot interaction, including grounded semantics (Thomason et al., 2016), engagement (Bohus and Horvitz, 2009), and establishing common ground (Chai et al., 2014).",2 Related Work,[0],[0]
"Others have explored how robots are perceived differently by different human age groups such as the elderly (Kiela et al., 2015), whereas we are focused on the perceived age of the robot by human dialogue partners.",2 Related Work,[0],[0]
"Moreover, though we do not design our robots for deliberate affective grounding (i.e., the coordination effect of building common understanding of what behaviors can be exhibited, and how beahvior is interpreted emotionally) as in Jung (2017), we hypothesize that how our robots behave effects how they are perceived.
",2 Related Work,[0],[0]
"Kiela et al. (2015) compared tutoring sequences in parent-child and human-robot interactions with varying verbal and demonstrative behaviors, and Lyon et al. (2016) brought together several areas of research relating to language acquisition in robotics.",2 Related Work,[0],[0]
"We differ from this previous work in that we do not explcitely tell our participants to interact with the robots as they would a child, effectively removing the assumption that participants will treat robots in an age-appropriate way.",2 Related Work,[0],[0]
"Another important difference to their work is that we opted not to use an anthropomorphically realistic child robot because such robots often make people feel uncomfortable (Eberle, 2009).",2 Related Work,[0],[0]
"Our work is similar in some ways to, but different from work in paralinguistics where recognition of age given linguistic features is a common task (Schuller et al., 2013) in that we are make use of exra-linguistic features.",2 Related Work,[0],[0]
Our work primarily builds off of Novikova et al. (2017) who used multimodal features derived from the human participants to predict perceived likability and intelligence of a robot.,2 Related Work,[0],[0]
We use similar multimodal features to predict the perceived age and academic level.,2 Related Work,[0],[0]
"An important difference to their work is that we designed
the experiment with three robots to vary the appearance and two language settings to vary the behavior and linguistic factors of the robots.",2 Related Work,[0],[0]
The primary goal of our experiment is to determine what factors play into how humans perceive a robot’s age and academic level.,3 Experiment,[0],[0]
"We used the three following robotic systems in our experiment:
• Kobuki Base Robot with a Microsoft Kinect on top (denoted as KOBUKI)
",3 Experiment,[0],[0]
"• Anki Cozmo robot (denoted as COZMO)
• Non-physical “robot” (i.e., a non-embodied spoken dialogue system) which was just a camera and speaker (denoted as SDS)
Robot Appearance The COZMO has a head and animated eyes and is noticeably smaller than the KOBUKI.",3 Experiment,[0],[0]
"The robots did not move during the experiments, though they were clearly activated (e.g., the KOBUKI had a small light and COZMO’s eyes were visible and moved at random intervals, which is the default setting).",3 Experiment,[0],[0]
Figure 1 shows the KOBUKI and COZMO robots as seen by the participants.,3 Experiment,[0],[0]
"We chose these three robots because they were available to us and we assume that, based solely on appearance, participants would perceive the robots differently.",3 Experiment,[0],[0]
"We chose a spoken dialogue system (SDS) as one of the “robots” because we wanted to explore how participants perceive a system that is unembodied in direct comparison to embodied systems.
",3 Experiment,[0],[0]
Robot Behavior The COZMO robot has a builtin speaker with a young-sounding synthetic voice.,3 Experiment,[0],[0]
We used two adult voices for the KOBUKI and SDS robots from the Amazon Polly system (the Joey and Joanna voices) which we played on a small speaker.1 We vary the language setting of the robots by assigning each robot one of two possible settings: high and low.,3 Experiment,[0],[0]
"In the high setting,
1https://aws.amazon.com/polly/
the following responses were possible: sure; okay;",3 Experiment,[0],[0]
yeah;,3 Experiment,[0],[0]
"oh; I see; uh huh; (where the robot repeats a word spoken by the participant) and any combination of those responses in a single uttered response; and for the low setting, the following responses were possible: yes; okay; uh; (where the robot repeats a word spoken by the participant).",3 Experiment,[0],[0]
"In the high setting, the robot would produce responses more often than in the low setting.",3 Experiment,[0],[0]
"These responses are characteristic of different levels of feedback; the high setting contains feedback strategies that signaled understanding to the participant, whereas the low setting only signaled phonetic receipt.",3 Experiment,[0],[0]
"This corresponds to previous work (Stubbe, 1998) which investigated various feedback strategies employed in human-human dialogue termed neutral minimal responses (corresponding to our low setting) and supportive minimal responses (corresponding to our high setting).
",3 Experiment,[0],[0]
"With this setup, there are 6 possible settings: high and low for each of the three robots.",3 Experiment,[0],[0]
"Our hypothesis is that participants will perceive KOBUKI as older and more intelligent than COZMO overall (in both high and low settings) despite being less anthropomorphic, perceive COZMO as very young in the low setting, and that SDS will be perceived as older than COZMO in the high setting, but similar to COZMO in the low setting.",3 Experiment,[0],[0]
The experimenter gave each participant consent and instruction forms to complete before the experiment.,3.1 Task and Participants,[0],[0]
"The participant was then given three colored pentomino puzzle tiles and a sheet of paper with three goal shapes (example in Figure 2), each composed from the corresponding tiles.",3.1 Task and Participants,[0],[0]
The experimenter instructed the participant to sit at a table where they would see a robot.,3.1 Task and Participants,[0],[0]
Their task was to explain to the robot how to use the tiles to construct the three goal shapes and tell the robot the name of each shape.,3.1 Task and Participants,[0],[0]
"The experimenter did
not specify how to accomplish this task or give examples of the kinds of things that the robot might understand.",3.1 Task and Participants,[0],[0]
"The experimenter then left the room, leaving the participant with the robot to complete the task.",3.1 Task and Participants,[0],[0]
"The robots only responded verbally in the low/high setting as explained above and their responses were controlled by the experimenter (i.e., in a Wizard-of-Oz paradigm).",3.1 Task and Participants,[0],[0]
The robots produced no physical movement.,3.1 Task and Participants,[0],[0]
"When the participant completed each task, they uttered a keyword (i.e., done), then the experimenter returned and administered a questionnaire.",3.1 Task and Participants,[0],[0]
"This process was followed for each of the three robots.
",3.1 Task and Participants,[0],[0]
"The following aspects of the experiment were randomly assigned to each participant: the order of robot presentation, the puzzle tiles and corresponding goal shapes for each robot, the language setting (i.e., high or low) which remained the same for all three robot interactions for each participant, and for KOBUKI and SDS the adult voice (either Joey or Joanna).",3.1 Task and Participants,[0],[0]
"We recruited 21 Englishspeaking participants (10 Female, 11 Male), most of whom were students of Boise State University.",3.1 Task and Participants,[0],[0]
The interaction generally took about 30 minutes; participants received $5 for their participation.,3.1 Task and Participants,[0],[0]
We recorded the interactions with a camera that captured the face and a microphone that captured the speech of each participant.,3.2 Data Collection,[0],[0]
"We automatically transcribed the speech using the Google Speech API (we manually checked an accented female
voice which achieved an estimated WER of 30.0) and segmented transcriptions into sentences after 1 second of detected silence, which is a longer pause duration than the average pause duration for adult-adult conversation (though adults tend to take longer pauses when interacting with children (DePaulo and Coleman, 1986)).",3.2 Data Collection,[0],[0]
"This resulted in video, audio, and transcriptions for each participant, for each robot interaction.",3.2 Data Collection,[0],[0]
"We also collected 58 questionnaires (we had to remove several because they were missing data; i.e., some participants did not answer some of the questionnaire questions), one for each robot interaction, from each participant.",3.2 Data Collection,[0],[0]
"Using the data collected from the experiment, we derived subjective measures from the questionnaires and we derived a number of objective measures from the video, audio, and transcriptions.",4 Data Analysis,[0],[0]
"In this section, we explain what methods we used to derive and analyze those measures.
",4 Data Analysis,[0],[0]
"Emotion Features Using the video feed of the participants, we extracted an image of the participants’ faces every 5 seconds.",4 Data Analysis,[0],[0]
"We used the Microsoft Emotion API for processing these images to calculate an average distribution over 8 possible emotion categories for each image: happiness, sadness, surprise, anger, fear, contempt, disgust, and neutral.",4 Data Analysis,[0],[0]
"Figure 4 shows an example of face snapshots taken from the video in the task setting and the corresponding distributions over the emotions as produced by the API.
",4 Data Analysis,[0],[0]
"Prosodic Features From the audio, we calculated the average fundamental frequency of speech (F0) of the participant over the entire interaction
between the participant and the robot for each robot setting.
",4 Data Analysis,[0],[0]
"Linguistic Features Using the automatically transcribed text, we follow directly from Novikova et al. (2017) to derive several linguistic measures, with the exception that we did not derive dialoguerelated features because, though our robots were engaging in a kind of dialogue with the participants, they weren’t taking the floor in a dialogue turn; i.e., our robots were only providing feedback to signal either phonetic receipt or semantic understanding (low and high settings, respectively).",4 Data Analysis,[0],[0]
"We used the Lexical Complexity Analyser (Lu, 2009, 2012), which yields several measures, two of which we leverage here: lexical diversity (LD) and the mean segmented type-token ratio (MSTTR), both of which measure diversity of tokens; the latter averaging the diversity over segments of a given length (for all measures, higher values denote more respective diversity and sophistication in the measured text).",4 Data Analysis,[0],[0]
"The Complexity Analyser also produces a lexical sophistication (LS) measure, also known as lexical rareness which is the proportion of lexical word types that are not common (i.e., not the 2,000 most frequent words in the British National Corpus).
",4 Data Analysis,[0],[0]
"For syntactic variation, we applied the D-Level Analyser (Lu, 2009) using the D-Level scale (Lu, 2014).",4 Data Analysis,[0],[0]
"This tool builds off of the Stanford Partof-Speech Tagger (Toutanova and Manning, 2000) and the Collins Parser (Collins, 2003) and produces a scaled analysis.",4 Data Analysis,[0],[0]
"The D-Level scale counts utterances belonging to one of 8 levels (Levels 0- 7), where lower levels such as 0-1 include simple or incomplete sentences; the higher the level, the more complex the syntactic structure.",4 Data Analysis,[0],[0]
"We report each of these levels along with a mean level.
",4 Data Analysis,[0],[0]
"Godspeed Questionnaire We used the Godspeed Questionnaire (Bartneck et al., 2009) which consists of 21 pairs of contrasting characteristics in areas of anthropomorphism (e.g., artificial vs. lifelike), likability (e.g., unfriendly vs. friendly), intelligence (e.g., incompetent vs. competent), and interpretabilitiy (e.g., confusing vs. clear) each with a 5-point scaling between them.",4 Data Analysis,[0],[0]
"In addition to those questions, we included the following:
• Have you ever interacted with a robot before participating in this study?
",4 Data Analysis,[0],[0]
"• If you could give the robot you interacted
with a human age, how old would you say it was?
• What level of education would be appropriate for the robot you interacted with?
",4 Data Analysis,[0],[0]
"For the question asking about human age, answers could be selected from a set of binned ranges (under 2 years, 2-5, 6-12, 13-17, 18-24, 25- 34, 35 and older), and for the education question, answers could be selected from preschool, kindergarten, 1-12 (each grade could be selected), undergraduate, graduate, post-graduate.",4 Data Analysis,[0],[0]
"In this section, we analyze the results of the data for the emotional, prosodic, and linguistic measures.",4.1 Analysis,[0],[0]
We also provide correlations between those measures and the Godspeed Questionnaire.,4.1 Analysis,[0],[0]
"At the end of this section, we provide a discussion of the overall analysis.
",4.1 Analysis,[0],[0]
"Emotion Analysis The most common emotional response as produced by the MS Emotions API was neutral for all settings, ranging from 73- 87% (avg 81%).",4.1 Analysis,[0],[0]
"The next most common emotions were happiness (avg 11.1%), sadness (avg 3.7%), surprise (2%), and contempt (avg 1%).",4.1 Analysis,[0],[0]
We show in Figure 5 the average distribution over those four emotions for all of our settings.,4.1 Analysis,[0],[0]
"All other emotions were negligible.
",4.1 Analysis,[0],[0]
Prosodic Analysis Table 1 shows the the average F0 scores for each setting.,4.1 Analysis,[0],[0]
"In general, in the low linguistic setting participants averaged a higher F0 across all robots.",4.1 Analysis,[0],[0]
This was the case also for individual robots.,4.1 Analysis,[0],[0]
"By a wide margin, COZMO
averaged a higher F0 than the other two robots under both low and high settings.
",4.1 Analysis,[0],[0]
Linguistic Analysis Table 2 shows the results of the linguistic analysis.,4.1 Analysis,[0],[0]
"The LD (lexical diversity) scores show that, on average, participants used more LD in the high settings.",4.1 Analysis,[0],[0]
Figure 6 shows the results of the D-Level analysis.,4.1 Analysis,[0],[0]
"Level0 (i.e., short utterances) was by far the most common level which accounted for 66% of all utterances for all participants.",4.1 Analysis,[0],[0]
"The second most common was Level7, the level representing the most complex types of utterances.",4.1 Analysis,[0],[0]
"This is no surprise, as Level7 accounts for longer utterances above some threshold; i.e., all utterances of a certain length and complexity or higher fit under Level7.",4.1 Analysis,[0],[0]
"The low setting had a Level7 value of 17%, and the high setting had a Level7 value of 11%.",4.1 Analysis,[0],[0]
"This may seem surprising, but it follows previous research which has shown that, when a speaker receives fewer responses, they draw out their turns, which result longer utterances (Stubbe, 1998).
",4.1 Analysis,[0],[0]
"Questionnaire Analysis We calculated (Spearman) correlations between the prosodic, emotional, and linguistic features, and the questionnaire responses with the low/high settings and the robot settings.",4.1 Analysis,[0],[0]
Table 3 shows the results where the correlation had a strength of 0.5 or higher.,4.1 Analysis,[0],[0]
"Fig-
ures 7 and 8 respectively show the age groups and academic years that the participants perceived for each robot in each setting.",4.1 Analysis,[0],[0]
"Overall, participants assigned low age and academic level to all robots when they produced feedback that did not signal semantic understanding (i.e., the low setting).",4.1 Analysis,[0],[0]
"They also assigned a lower age and academic level to COZMO for all settings (with the exception of one 10th grade assignment).
",4.1 Analysis,[0],[0]
Our results confirm the Novikova et al. (2017) result which showed a strong correlation between F0 and knowledgeable.,4.1 Analysis,[0],[0]
"Interestingly, F0 only correlated knowledge with the physical robots and the SDS robot in the low setting.",4.1 Analysis,[0],[0]
"There is more to the F0 correlations: F0 in the low setting correlates with conscious, in the high setting correlates with natural and human-like, and in the COZMO robot setting with lifelike.",4.1 Analysis,[0],[0]
"There were some correlations with age and academic level: LS in the high setting correlated with the robot being perceived as age 18-24 and when interacting with COZMO, a higher F0 correlated with a perception of COZMO being 6-12 years old and in the 4th grade.",4.1 Analysis,[0],[0]
"Lexical diversity correlates with sadness and contempt, which indicates that participants use more diverse language (i.e., they continue speaking) when they are frustrated with the interaction (Stubbe, 1998); particularly in the high setting when they expect more from the robots.",4.1 Analysis,[0],[0]
"However, they increase their LS also in the high setting because they perceive the robot as more intelligent.
",4.1 Analysis,[0],[0]
"Discussion Taken together, the emotional, prosodic, and linguistic analyses show that participants treated the low setting with a higher average F0, less linguistic complexity, and a greater display of happiness in their facial emotions.",4.1 Analysis,[0],[0]
"This is useful knowledge: the way a robot
speaks has an impact on the perception of that robot by the human users, regardless of whether or not that robot is embodied.",4.1 Analysis,[0],[0]
"Moreover, despite the fact that the robots only produced feedback as the only system behavior, the participants tended to assign a younger age and academic level to the COZMO robot.",4.1 Analysis,[0],[0]
There were subtle differences in how the participants perceived the KOBUKI and SDS robots.,4.1 Analysis,[0],[0]
"In general, the participants seemed to perceive the SDS as being older and as having a higher academic level in the emotion, prosodic, and linguistic modalities, though those differences were small.",4.1 Analysis,[0],[0]
This leads us to postulate that anthropomorphic physical features do not automatically denote intelligence in the same way as perceived ability to comprehend language.,4.1 Analysis,[0],[0]
"In general, participants assigned younger ages and lower academic levels for the low setting, and higher ones for the high setting.",4.1 Analysis,[0],[0]
"Moreover, participants generally assigned COZMO lower ages, including the most for Under 2 years.",4.1 Analysis,[0],[0]
Of note is that no participant assigned COZMO an age of above 6-12 years for either of the low/high settings.,4.1 Analysis,[0],[0]
"The highest assigned academic level was undergrad, which was never assigned to COZMO.",4.1 Analysis,[0],[0]
The KOBUKI and SDS robots were both variously assigned comparable older ages and average academic levels under all settings.,4.1 Analysis,[0],[0]
"Using the measures we derived from the collected data, we attempted to determine if we could predict the perceived age and academic level of the robots.",5 Prediction Tasks,[0],[0]
"We used the emotional features (happiness, sadness, surprise, anger, fear, contempt, disgust, and neutral), the prosody (F0 average), and the linguistic features (LS, LD, MSTTR) to predict
both the age and the academic level as separate classification tasks.",5 Prediction Tasks,[0],[0]
"We also predict intelligence, likability, and interpretability in order to compare to previous work.",5 Prediction Tasks,[0],[0]
"Data & Task For predicting both age and academic level, we used the 58 data points from the participants for each interaction with each robot and applied those points to a 5-fold cross validation.",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
We used a logistic regression classifier to perform the classification using the Python scikitlearn library.,5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"We report accuracy for our metric.
Age We ran the cross validation for two different settings when predicting age.",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"In particular, we varied the labels that could be classified.",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"We conducted a first task which treated all of the 7 possible outcomes for age as individual labels (i.e., under 2 years, 2-5, 6-12, 13-17, 18-24, 25-34, 35 and older) and a second task splitting at age 18 (i.e., younger than 18 is one label; 18 & older is the other label).",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"The respective random baselines are 14% and 50%.
",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"Academic Levels Similar to age, we ran the cross validation for two different settings when predicting for perceived academic level.",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"The first task treated all of the 14 possible outcomes for academic level as individual labels (preschool, kindergarten, 1-11, undergraduate; we leave out graduate and post-graduate because they were never selected in the questionnaires, nor was 12th grade), the second task treated treated preschool and beyond preschool as a binary classification task.",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"The respective random baselines are 7% and 50%.
",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
Results The results of this prediction task are in Table 4.,5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"As might be expected, when attempting to predict using many labels, the classification task is challenging with so little data.",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"However, the classifiers beat their respective random baselines.",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"When classifying for age, the best performing task was a binary task splitting on 18 years at 87%, effectively making it a classifier that can determine if a human user perceives the robot as an adult or as a minor.",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
The best performing task for the academic level classification was treating preschool and above preschool as a binary classifier.,5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"Though the data is sparse, these classifiers give us useful information: a robot can use these classifiers to determine if they are perceived as an adult by human dialogue partners, and, more importantly for our purposes, as a preschool aged child, which is the age range in which we are interested for language acquisition tasks.",5.1 Predicting the Perceived Age & Academic Level of Robots,[0],[0]
"Data & Task To directly compare with Novikova et al. (2017), we also predicted perceived intelligence, likability, and interpretability using a ridge regression classifier (which is optimized to reduced standard error) while considering only certain subsets of out our feature set.","5.2 Predicting Intelligence, Likability, and Interpretability",[0],[0]
"We evaluated when only considering emo-
tional features, prosody, non-linguistic (in our case, emotions and prosody), linguistic, and all combined features.","5.2 Predicting Intelligence, Likability, and Interpretability",[0],[0]
Our metric was root mean square error (RMSE).,"5.2 Predicting Intelligence, Likability, and Interpretability",[0],[0]
"We average the RMSE over a 5-fold cross-validation.
","5.2 Predicting Intelligence, Likability, and Interpretability",[0],[0]
Results Table 5 shows the results of this prediction task.,"5.2 Predicting Intelligence, Likability, and Interpretability",[0],[0]
"We found that likability is predicted best by prosody, perceived intelligence is predicted best by linguistic features, and interpretability is predicted best by also using linguistic features.","5.2 Predicting Intelligence, Likability, and Interpretability",[0],[0]
"One big difference between our experiment data and that of previous work is that we did not consider dialogue features (e.g., number of turns, speech duration, number of self-repetitions, etc.), which they termed as non-linguistic features.","5.2 Predicting Intelligence, Likability, and Interpretability",[0],[0]
"Those features were important in predicting perceived intelligence and interpretability in their work; here, linguistic and prosodic features were the most effective in predicting all three human perceptions of the robots.","5.2 Predicting Intelligence, Likability, and Interpretability",[0],[0]
This confirms the work of Novikova et al. (2017) that linguistic features are a good predictor of interpretability.,"5.2 Predicting Intelligence, Likability, and Interpretability",[0],[0]
"In this paper, we have investigated how human dialogue partners perceive the age and academic level of three robotic systems, two of which were embodied (albeit not particularly anthropomorphically), and one unembodied spoken dialogue system.",6 Discussion & Conclusion,[0],[0]
"We collected data from participants as they interacted with the three robotic systems then derived prosodic, emotional, and linguistic features from that participant data, and found that those features correlate with certain age and academic perceptions of those robots, as well as a number of other subjective measures from the Godspeed Questionnaire.",6 Discussion & Conclusion,[0],[0]
"This work confirms what previous work has shown: that humans tend to perceive robots differently depending on different factors; in our case, varying the look and spo-
ken reposes determined how the human participants perceived the age and academic levels, as well as intelligence, likability, and interpretability of those robots.",6 Discussion & Conclusion,[0],[0]
"We were then able to use these features to automatically predict perceived age (i.e., adult or minor), perceived academic level (i.e., preschool or above) and perceived intelligence, likability, and interpretabilitiy.",6 Discussion & Conclusion,[0],[0]
"One important result of our experiment was that human dialogue partners perceive the unembodied robot (i.e., SDS) in similar ways to embodied robots; that is, the way a robot or system speaks (i.e., in our case, produces feedback by signaling either phonetic receipt or semantic understanding) is as important to human perceptions of intelligence and likability as visual characteristics.
",6 Discussion & Conclusion,[0],[0]
"We cannot not simply assume that human dialogue partners would treat a robot as they would a child, which is an important aspect of tasks with realistic first-language acquisition settings.",6 Discussion & Conclusion,[0],[0]
The work presented here shows that those interacting with a robot like COZMO will more likely treat COZMO as a learning child instead of as an adult.,6 Discussion & Conclusion,[0],[0]
"This is an important result because for future work we plan on using the COZMO robot as a platform for first language acquisition research, where the setting will be more similar to first language acquisition in humans than common language grounding tasks.",6 Discussion & Conclusion,[0],[0]
"The COZMO robot is an afforable way for reseachers to couple spoken dialogue systems with a robotic system; it has a Python SDK which allows researchers to access its sensors (including a color camera) and control its wheel and arm movements, as well as its speech and animated face.",6 Discussion & Conclusion,[0],[0]
"Our results show that human users generally like COZMO, find COZMO lifelike, competent, and intelligent; i.e., COZMO may be treated as a child, but it has potential to learn.
",6 Discussion & Conclusion,[0],[0]
"In future work, we will apply a model of grounded semantics in a co-located dialogue setting where COZMO can learn the semantics of words as it interacts with human dialogue partners.
",6 Discussion & Conclusion,[0],[0]
Acknowledgements This work was supported in part by the Boise State University HERC program.,6 Discussion & Conclusion,[0],[0]
"We would like to thank the anonymous reviewers for their comments, Hoda Mehrpouyan for use of her Kobuki robot, and the Mary Ellen Ryder Linguistics Lab at Boise State University for use of their lab for the data collection.",6 Discussion & Conclusion,[0],[0]
This work was approved by Boise State University IRB 131-SB17-043.,6 Discussion & Conclusion,[0],[0]
"When interacting with robots in a situated spoken dialogue setting, human dialogue partners tend to assign anthropomorphic and social characteristics to those robots.",abstractText,[0],[0]
"In this paper, we explore the age and educational level that human dialogue partners assign to three different robotic systems, including an un-embodied spoken dialogue system.",abstractText,[0],[0]
We found that how a robot speaks is as important to human perceptions as the way the robot looks.,abstractText,[0],[0]
"Using the data from our experiment, we derived prosodic, emotional, and linguistic features from the participants to train and evaluate a classifier that predicts perceived intelligence, age, and education level.",abstractText,[0],[0]
Predicting Perceived Age: Both Language Ability and Appearance are Important,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1741–1751 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1741",text,[0],[0]
"Semantic graphs, such as WordNet (Fellbaum, 1998), encode the structural qualities of language as a representation of human knowledge.",1 Introduction,[0],[0]
"On the local level, they describe connections between specific semantic concepts, or synsets, through individual edges representing relations such as hypernymy (‘is-a’) or meronymy (‘is-part-of’); on the global level, they encode emergent regular properties in the induced relation graphs.",1 Introduction,[0],[0]
"Local properties have been subject to extensive study in recent years via the task of relation prediction, where individual edges are found based mostly on
distributional methods that embed synsets and relations into a vector space (e.g. Socher et al., 2013; Bordes et al., 2013; Toutanova and Chen, 2015; Neelakantan et al., 2015).",1 Introduction,[0],[0]
"In contrast, while the structural regularity and significance of global aspects of semantic graphs is well-attested (Sigman and Cecchi, 2002), global properties have rarely been used in prediction settings.",1 Introduction,[0],[0]
"In this paper, we show how global semantic graph features can facilitate in local tasks such as relation prediction.
",1 Introduction,[0],[0]
"To motivate this approach, consider the hypothetical hypernym graph fragments in Figure 1: in (a), the semantic concept (synset) ‘catamaran’ has
a single hypernym, ‘boat’.",1 Introduction,[0],[0]
This is a typical property across a standard hypernym graph.,1 Introduction,[0],[0]
"In (b), the synset ‘cat’ has two hypernyms, an unlikely event.",1 Introduction,[0],[0]
"While a local relation prediction model might mistake the relation between ‘cat’ and ‘boat’ to be plausible, for whatever reason, a high-order graphstructure-aware model should be able to discard it based on the knowledge that a synset should not have more than one hypernym.",1 Introduction,[0],[0]
"In (c), an impossible situation arises: a cycle in the hypernym graph leads each of the participating synsets to be predicted by transitivity as its own hypernym, contrary to the relation’s definition.",1 Introduction,[0],[0]
"However, a purely local model has no explicit mechanism for rejecting such an outcome.
",1 Introduction,[0],[0]
"In this paper, we examine the effect of global graph properties on the link structure via the WordNet relation prediction task.",1 Introduction,[0],[0]
"Our hypothesis is that features extracted from the entire graph can help constrain local predictions to structurally sound ones (Guo et al., 2007).",1 Introduction,[0],[0]
"Such features are often manifested as aggregate counts of small subgraph structures, known as motifs, such as the number of nodes with two or more outgoing edges, or the number of cycles of length 3.",1 Introduction,[0],[0]
"Returning to the example in Figure 1, each of these features will be affected when graphs (b) and (c) are evaluated, respectively.
",1 Introduction,[0],[0]
"To estimate weights on local and global graph features, we build on the Exponential Random Graph Model (ERGM), a log-linear model over networks utilizing global graph features (Holland and Leinhardt, 1981).",1 Introduction,[0],[0]
"In ERGMs, the likelihood of a graph is computed by exponentiating a weighted sum of the features, and then normalizing over all possible graphs.",1 Introduction,[0],[0]
"This normalization term grows exponentially in the number of nodes, and in general cannot be decomposed into smaller parts.",1 Introduction,[0],[0]
"Approximations are therefore necessary to fit ERGMs on graphs with even a few dozen nodes, and the largest known ERGMs scale only to thousands of nodes (Schmid and Desmarais, 2017).",1 Introduction,[0],[0]
"This is insufficient for WordNet, which has an order of 105 nodes.
",1 Introduction,[0],[0]
We extend the ERGM framework in several ways.,1 Introduction,[0],[0]
"First, we replace the maximum likelihood objective with a margin-based objective, which compares the observed network against alternative networks; we call the resulting model the MaxMargin Markov Graph Model (M3GM), drawing on ideas from structured prediction (Taskar
et al., 2004).",1 Introduction,[0],[0]
"The gradient of this loss is approximated by importance sampling over candidate negative edges, using a local relational model as a proposal distribution.",1 Introduction,[0],[0]
"The complexity of each epoch of estimation is thus linear in the number of edges, making it possible to scale up to the 105 nodes in WordNet.1 Second, we address the multi-relational nature of semantic graphs, by incorporating a combinatorial set of labeled motifs.",1 Introduction,[0],[0]
"Finally, we link graph-level relational features with distributional information, by combining the M3GM with a dyad-level model over word sense embeddings.
",1 Introduction,[0],[0]
"We train M3GM as a re-ranker, which we apply to a a strong local-feature baseline on the WN18RR dataset (Dettmers et al., 2018).",1 Introduction,[0],[0]
This yields absolute improvements of 3-4 points on all commonly-used metrics.,1 Introduction,[0],[0]
"Model inspection reveals that M3GM assigns importance to features from all relations, and captures some interesting inter-relational properties that lend insight into the overall structure of WordNet.2",1 Introduction,[0],[0]
Relational prediction in semantic graphs.,2 Related Work,[0],[0]
Recent approaches to relation prediction in semantic graphs generally start by embedding the semantic concepts into a shared space and modeling relations by some operator that induces a score for an embedding pair input.,2 Related Work,[0],[0]
"We use several of these techniques as base models (Nickel et al., 2011; Bordes et al., 2013; Yang et al., 2014); detailed description of these methods is postponed to Section 3.2.",2 Related Work,[0],[0]
Socher et al. (2013) generalize over the approach of Nickel et al. (2011) by using a bilinear tensor which assigns multiple parameters for each relation; Shi and Weninger (2017) project the node embeddings in a translational model similar to that of Bordes et al. (2013); Dettmers et al. (2018) apply a convolutional neural network by reshaping synset embeddings to 2-dimensional matrices.,2 Related Work,[0],[0]
"None of these embedding-based approaches incorporate structural information; in general, improvements in embedding-based methods are expected to be complementary to our approach.
",2 Related Work,[0],[0]
"1Although in principle the number of edges could grow quadratically with the number of nodes, Steyvers and Tenenbaum (2005) show that semantic graphs like WordNet tend to be very sparse, so that the number of observed edges grows roughly linearly with the number of nodes.
",2 Related Work,[0],[0]
2Our code is available at http://www.github.,2 Related Work,[0],[0]
"com/yuvalpinter/m3gm.
",2 Related Work,[0],[0]
"Some recent works compose single edges into more intricate motifs, such as Guu et al. (2015), who define a task of path prediction and compose various functions to solve it.",2 Related Work,[0],[0]
They find that compositionalized bilinear models perform best on WordNet.,2 Related Work,[0],[0]
Minervini et al. (2017) train link-prediction models against an adversary that produces examples which violate structural constraints such as symmetry and transitivity.,2 Related Work,[0],[0]
"Another line of work builds on local neighborhoods of relation interactions and automatic detection of relations from syntactically parsed text (Riedel et al., 2013; Toutanova et al., 2015).",2 Related Work,[0],[0]
Schlichtkrull et al. (2017) use Graph Convolutional Networks to predict relations while considering high-order neighborhood properties of the nodes in question.,2 Related Work,[0],[0]
"In general, these methods aggregate information over local neighborhoods, but do not explicitly model structural motifs.
",2 Related Work,[0],[0]
"Our model introduces interaction features between relations (e.g., hypernyms and meronyms) for the goal of relation prediction.",2 Related Work,[0],[0]
"To our knowledge, this is the first time that relation interaction is explicitly modeled into a relation prediction task.",2 Related Work,[0],[0]
"Within the ERGM framework, Lu et al. (2010) train a limited set of combinatory path features for social network link prediction.
",2 Related Work,[0],[0]
Scaling exponential random graph models.,2 Related Work,[0],[0]
The problem of approximating the denominator of the ERGM probability has been an active research topic for several decades.,2 Related Work,[0],[0]
Two common approximation methods exist in the literature.,2 Related Work,[0],[0]
"In Maximum Pseudolikelihood Estimation (MPLE; Strauss and Ikeda, 1990), a graph’s probability is decomposed into a product of the probability for each edge, which in turn is computed based on the ERGM feature difference between the graph excluding the edge and the full graph.",2 Related Work,[0],[0]
"Monte Carlo Maximum Likelihood Estimation (MCMLE; Snijders, 2002) follows a sampling logic, where a large number of graphs is randomly generated from the overall space under the intuition that the sum of their scores would give a good approximation for the total score mass.",2 Related Work,[0],[0]
"The probability for the observed graph is then estimated following normalization conditioned on the sampling distribution, and its precision increases as more samples are gathered.",2 Related Work,[0],[0]
"Recent work found that applying a parametric bootstrap can increase the reliability of MPLE, while retaining its superiority in training speed (Schmid
and Desmarais, 2017).",2 Related Work,[0],[0]
"Despite this result, we opted for an MCMLE-based approach for M3GM, mainly due to the ability to keep the number of edges constant in each sampled graph.",2 Related Work,[0],[0]
"This property is important in our setup, since local edge scores added or removed to the overall graph score can occasionally dominate the objective function, giving unintended importance to the overall edge count.",2 Related Work,[0],[0]
"Consider a graph G = (V,E), where V is a set of vertices and E = {(si, ti)}|E|i=1 is a set of directed edges.",3 Max-Margin Markov Graph Models,[0],[0]
"The ERGM scoring function defines a probability over G|V |, the set of all graphs with |V | nodes.",3 Max-Margin Markov Graph Models,[0],[0]
"This probability is defined as a loglinear function,
PERGM(G) ∝",3 Max-Margin Markov Graph Models,[0],[0]
ψERGM(G),3 Max-Margin Markov Graph Models,[0],[0]
"= exp ( θT f(G) ) , (1)
where f is a feature function, from graphs to a vector of feature counts.",3 Max-Margin Markov Graph Models,[0],[0]
Features are typically counts of motifs — small subgraph structures — as described in the introduction.,3 Max-Margin Markov Graph Models,[0],[0]
"The vector θ is the parameter to estimate.
",3 Max-Margin Markov Graph Models,[0],[0]
"In this section we discuss our adaptation of this model to the domain of semantic graphs, leveraging their idiosyncratic properties.",3 Max-Margin Markov Graph Models,[0],[0]
"Semantic graphs are composed of multiple relation types, which the feature space needs to accommodate; their nodes are linguistic constructs (semantic concepts) associated with complex interpretations, which can benefit the graph representation through incorporating their embeddings in Rd into a new scoring model.",3 Max-Margin Markov Graph Models,[0],[0]
We then present our M3GM framework to perform reliable and efficient parameter estimation on the new model.,3 Max-Margin Markov Graph Models,[0],[0]
"Based on common practice in ERGM feature extraction (e.g., Morris et al., 2008), we select the following graph features as a basis:
• Total edge count;
• Number of cycles of length k, for k ∈ {2, 3};
• Number of nodes with exactly k outgoing (incoming) edges, for k ∈ {1, 2, 3};
• Number of nodes with at least k outgoing (incoming) edges, for k ∈ {1, 2, 3};
• Number of paths of length 2;
• Transitivity: the proportion of length-2 paths u → v → w where an edge u → w also exists.
",3.1 Graph Motifs as Features,[0],[0]
"Semantic graphs are multigraphs, where multiple relationships (hypernymy, meronymy, derivation, etc.) are overlaid atop a common set of nodes.",3.1 Graph Motifs as Features,[0],[0]
"For each relation r in the relation inventory R, we denote its edge set as Er, and redefine E = ⋃ r∈REr, the union of all labeled edges.",3.1 Graph Motifs as Features,[0],[0]
"Some relations do not produce a connected graph, while others may coincide with each other frequently, possibly in regular but intricate patterns: for example, derivation relations tend to occur between synsets in the higher, more abstract levels of the hypernym graph.",3.1 Graph Motifs as Features,[0],[0]
We represent this complexity by expanding the feature space to include relation-sensitive combinatory motifs.,3.1 Graph Motifs as Features,[0],[0]
"For each feature template from the basis list above, we extract features for all possible combinations of relation types existing in the graph.",3.1 Graph Motifs as Features,[0],[0]
"Depending on the feature type, these could be relation singletons, pairs, or triples; they may be order-sensitive or order-insensitive.",3.1 Graph Motifs as Features,[0],[0]
"For example:
• A combinatory ‘transitivity’ feature will be extracted for the proportion of paths
u hypernym−−−−−−→ v meronym−−−−−−→ w where an edge u has part−−−−−→ w also exists.
",3.1 Graph Motifs as Features,[0],[0]
"• A combinatory ‘2-outgoing’ feature will be extracted for the number of nodes with exactly one derivation and one has part.
",3.1 Graph Motifs as Features,[0],[0]
"The number of features thus scales in O(|R|K) for a feature basis which involves up to K edges in any feature, and so our 17 basis features (with K = 3) generate a combinatory feature set with roughly 3,000 features for the 11-relation version of WordNet used in our experiments (see Section 4.1).",3.1 Graph Motifs as Features,[0],[0]
"In classical ERGM application domains such as social media or biological networks, nodes tend to have little intrinsic distinction, or at least little meaningful intrinsic information that may be extracted prior to applying the model.",3.2 Local Score Component,[0],[0]
"In semantic graphs, however, the nodes represent synsets, which are associated with information that is both valuable to predicting the graph structure and approximable using unsupervised techniques such as embedding into a common d-dimensional vector
space based on copious amounts of available data.",3.2 Local Score Component,[0],[0]
We thus modify the traditional scoring function from eq.,3.2 Local Score Component,[0],[0]
"(1) to include node-specific information, by introducing a relation-specific association operator A(r) : V × V → R:
ψERGM+(G) =
= exp θT f(G) +∑ r∈R ∑ (s,t)∈Er A(r)(s, t)  .",3.2 Local Score Component,[0],[0]
"(2)
The association operator generalizes various models from the relation prediction literature:
TransE (Bordes et al., 2013) embeds each relation r into a vector in the shared space, representing a ‘difference’ between sources and targets, to compute the association score under a translational objective,
A(r)TRANSE(s, t) =",3.2 Local Score Component,[0],[0]
−‖es,3.2 Local Score Component,[0],[0]
"+ er − et‖.
BiLin (Nickel et al., 2011) embeds relations into full-rank matrices, computing the score by a bilinear multiplication,
A(r)BILIN(s, t) = e T s Wret.
",3.2 Local Score Component,[0],[0]
"DistMult (Yang et al., 2014) is a special case of BiLin where the relation matrices are diagonal, reducing the computation to a ternary dot product,
A(r)DISTMULT(s, t) = 〈es, er, et〉 = d∑
i=1
esi eri eti .",3.2 Local Score Component,[0],[0]
"The probabilistic formulation of ERGM requires the computation of a normalization term that sums over all possible graphs with a given number of nodes, GN .",3.3 Parameter Estimation,[0],[0]
"The set of such graphs grows at a rate that is super-exponential in the number of nodes, making exact computation intractable even for networks that are orders of magnitude smaller than semantic graphs like WordNet.",3.3 Parameter Estimation,[0],[0]
"One solution is to approximate probability using a variant of the Monte Carlo Maximum Likelihood Estimation (MCMLE) produce,
logP (G)",3.3 Parameter Estimation,[0],[0]
≈ logψ(G)− log |G|V ||,3.3 Parameter Estimation,[0],[0]
"M M∑ G̃∼G|V | ψ(G̃),
(3)
where M is the number of networks G̃ sampled from G|V |, the space of all (multirelational) edge sets on nodes V .",3.3 Parameter Estimation,[0],[0]
"Each G̃ is referred to as a negative sample, and the goal of estimation is to assign low scores to these samples, in comparison with the score assigned to the observed network G.
Network samples can be obtained using edgewise negative sampling.",3.3 Parameter Estimation,[0],[0]
"For each edge s r−→ t in the training network G, we remove it temporarily and consider T alternative edges, keeping the source s and relation r constant, and sampling a target t̃ from a proposal distribution Q. Every such substitution produces a new graph G̃,
G̃ =G ∪ {s r−→ t̃} \ {s r−→ t}.",3.3 Parameter Estimation,[0],[0]
"(4)
Large-margin objective.",3.3 Parameter Estimation,[0],[0]
"Rather than approximating the log probability, as in MCMLE estimation, we propose a margin loss objective: the log score for each negative sample G̃ should be below the log score for G by a margin of at least 1.",3.3 Parameter Estimation,[0],[0]
"This motivates the hinge loss,
L(Θ, G̃;G) =",3.3 Parameter Estimation,[0],[0]
"( 1− logψERGM+(G)
",3.3 Parameter Estimation,[0],[0]
+ logψERGM+(G̃) ),3.3 Parameter Estimation,[0],[0]
"+ , (5)
where (x)+ = max(0, x).",3.3 Parameter Estimation,[0],[0]
Recall that the scoring function ψERGM+ includes both the local association score for the alternative edge and the global graph features for the resulting graph.,3.3 Parameter Estimation,[0],[0]
"However, it is not necessary to recompute all association scores; we need only subtract the association score for the deleted edge s r−→ t, and add the association score for the sampled edge s r−→ t̃.
The overall loss function is the sum over N = |E|×T negative samples, {G̃(i)}Ni=1, plus an L2 regularizer on the model parameters,
L(Θ;G) = λ||Θ||22+ N∑ i=1",3.3 Parameter Estimation,[0],[0]
"L(Θ, G̃(i)).",3.3 Parameter Estimation,[0],[0]
"(6)
Proposal distribution.",3.3 Parameter Estimation,[0],[0]
"The proposal distribution Q used to sample negative edges is defined to be proportional to the local association scores of edges not present in the training graph:
Q(t̃ | s, r,G) ∝
{ 0 s
r−→ t̃ ∈ G A(r)(s, t̃) s r−→ t̃ /∈ G .",3.3 Parameter Estimation,[0],[0]
"(7)
By preferring edges that have high association scores, the negative sampler helps push the M3GM parameters away from likely false positives.",3.3 Parameter Estimation,[0],[0]
"We evaluate M3GM on the relation graph edge prediction task.3 Data for this task consists of a set of labeled edges, i.e. tuples of the form (s, r, t), where s and t denote source and target entities, respectively.",4 Relation Prediction,[0],[0]
"Given an edge from an evaluation set, two prediction instances are created by hiding the source and target side, in turn.",4 Relation Prediction,[0],[0]
"The predictor is then evaluated on its ability to predict the hidden entity, given the other entity and the relation type.4",4 Relation Prediction,[0],[0]
"A popular relation prediction dataset for WordNet is the subset curated as WN18 (Bordes et al., 2013, 2014), containing 18 relations for about 41,000 synsets extracted from WordNet 3.0.",4.1 WN18RR Dataset,[0],[0]
"It has been noted that this dataset suffers from considerable leakage: edges from reciprocal relations such as hypernym / hyponym appear in one direction in the training set and in the opposite direction in dev / test (Socher et al., 2013; Dettmers et al., 2018).",4.1 WN18RR Dataset,[0],[0]
This allows trivial rule-based baselines to achieve high performance.,4.1 WN18RR Dataset,[0],[0]
"To alleviate this concern, Dettmers et al. (2018) released the WN18RR set, removing seven relations altogether.",4.1 WN18RR Dataset,[0],[0]
"However, even this dataset retains four symmetric relation types: also see, derivationally related form, similar to, and verb group.",4.1 WN18RR Dataset,[0],[0]
These symmetric relations can be exploited by defaulting to a simple rulebased predictor.,4.1 WN18RR Dataset,[0],[0]
"We report the following metrics, common in ranking tasks and in relation prediction in particular: MR, the Mean Rank of the desired entity; MRR, Mean Reciprocal Rank, the main evaluation metric; and H@k, the proportion of Hits (true entities) found in the top k of the lists, for k ∈ {1, 10}.",4.2 Metrics,[0],[0]
"Unlike some prior work, we do not type-restrict the possible relation predictions (so, e.g., a verb group link may select a noun, and that would count against the model).",4.2 Metrics,[0],[0]
"We evaluate a single-rule baseline, three association models, and two variants of the M3GM re-
3Sometimes referred to as Knowledge Base Completion, e.g. in Socher et al. (2013).
",4.3 Systems,[0],[0]
"4We follow prior work in excluding the following from the ranked lists: the known entity (no self loops); entities from the training set which fit the instance; other entities in the evaluation set.
",4.3 Systems,[0],[0]
ranker trained on top of the best-performing association baseline.,4.3 Systems,[0],[0]
We include a single-rule baseline that predicts a relation between s and t in the evaluation set if the same relation was encountered between t and s in the training set.,4.3.1 RULE,[0],[0]
All other models revert to this baseline for the four symmetric relations.,4.3.1 RULE,[0],[0]
The next group of systems compute local scores for entity-relation triplets.,4.3.2 Association Models,[0],[0]
"They all encode entities into embeddings e. Each of these systems, in addition to being evaluated as a baseline, is also used for computing association scores in M3GM, both in the proposal distribution (see Section 3.3) and for creating lists to be re-ranked (see below): TRANSE, BILIN, DISTMULT.",4.3.2 Association Models,[0],[0]
"For detailed descriptions, see Section 3.2.",4.3.2 Association Models,[0],[0]
The M3GM is applied as a re-ranker.,4.3.3 Max-Margin Markov Graph Model,[0],[0]
"For each relation and source (target), the top K candidate targets (sources) are retrieved based on the local association scores.",4.3.3 Max-Margin Markov Graph Model,[0],[0]
"Each candidate edge is introduced into the graph, and the score ψERGM+(G) is used to re-rank the top-K list.
",4.3.3 Max-Margin Markov Graph Model,[0],[0]
"We add a variant to this protocol where the graph score and association score are weighted by α and 1 − α, repsectively, before being summed.",4.3.3 Max-Margin Markov Graph Model,[0],[0]
"We tune a separate αr for each relation type, using the development set’s mean reciprocal rank (MRR).",4.3.3 Max-Margin Markov Graph Model,[0],[0]
"These hyperparameter values offer further insight into where the M3GM signal benefits relation prediction most (see Section 6).
",4.3.3 Max-Margin Markov Graph Model,[0],[0]
"Since we do not apply the model to the symmetric relations (scored by the RULE baseline), they are excluded from the sampling protocol described in eq.",4.3.3 Max-Margin Markov Graph Model,[0],[0]
"(5), although their edges do contribute to the combinatory graph feature vector f .
",4.3.3 Max-Margin Markov Graph Model,[0],[0]
Our default setting backpropagates loss into only the graph weight vector θ.,4.3.3 Max-Margin Markov Graph Model,[0],[0]
We experiment with a model variant which backpropagates into the association model and synset embeddings as well.,4.3.3 Max-Margin Markov Graph Model,[0],[0]
"For the association component of our model, we require embedding representations for WordNet synsets.",4.4 Synset Embeddings,[0],[0]
"While unsupervised word embedding techniques go a long way in representing wordforms (Collobert et al., 2011; Mikolov et al., 2013;
Pennington et al., 2014), they are not immediately applicable to the semantically-precise domain of synsets.",4.4 Synset Embeddings,[0],[0]
"We explore two methods of transforming pre-trained word embeddings into synset embeddings.
",4.4 Synset Embeddings,[0],[0]
Averaging.,4.4 Synset Embeddings,[0],[0]
"A straightforward way of using word embeddings to create synset embeddings is to collect the words representing the synset as surface form within the WordNet dataset and average their embeddings (Socher et al., 2013).",4.4 Synset Embeddings,[0],[0]
"We apply this method to pre-trained GloVe embeddings (Pennington et al., 2014) and pre-trained FastText embeddings (Bojanowski et al., 2017), averaging over the set of all wordforms in all lemmas for each synset, and performing a caseinsensitive query on the embedding dictionary.",4.4 Synset Embeddings,[0],[0]
"For example, the synset ‘determine.v.01’ lists the following lemmas: ‘determine’, ‘find’, ‘find out’, ‘ascertain’.",4.4 Synset Embeddings,[0],[0]
"Its vector is initialized as
1 5 (edetermine + 2 · efind + eout + eascertain).
",4.4 Synset Embeddings,[0],[0]
AutoExtend retrofitting + Mimick.,4.4 Synset Embeddings,[0],[0]
"AutoExtend is a method developed specifically for embedding WordNet synsets (Rothe and Schütze, 2015), in which pre-trained word embeddings are retrofitted to the tripartite relation graph connecting wordforms, lemmas, and synsets.",4.4 Synset Embeddings,[0.951505594485291],"['We tested logistic regression, decision tree, naive Bayes, and neural networks as classifiers to compute the p(Rk, oi) for each (referring expression, candidate) pair for the ranking-based model.']"
The resulting synset embeddings occupy the same space as the word embeddings.,4.4 Synset Embeddings,[0],[0]
"However, some WordNet senses are not represented in the underlying set of pre-trained word embeddings.5 To handle these cases, we trained a character-based model called MIMICK, which learns to predict embeddings for out-of-vocabulary items based on their spellings (Pinter et al., 2017).",4.4 Synset Embeddings,[0],[0]
"We do not modify the spelling conventions of WordNet synsets before passing them to Mimick, so e.g. ‘mask.n.02’ (the second synset corresponding to ‘mask’ as a noun) acts as the input character sequence as is.
",4.4 Synset Embeddings,[0],[0]
Random initialization.,4.4 Synset Embeddings,[0],[0]
"In preliminary experiments, we attempted training the association models using randomly-initialized embeddings.",4.4 Synset Embeddings,[0],[0]
These proved to be substantially weaker than distributionally-informed embeddings and we do not report their performance in the results section.,4.4 Synset Embeddings,[0],[0]
"We view this finding as strong evidence to support the necessity of a distributional signal in a typelevel semantic setup.
",4.4 Synset Embeddings,[0],[0]
5We use the out-of-the-box vectors supplied in http:// www.cis.lmu.de/˜sascha/AutoExtend.,4.4 Synset Embeddings,[0],[0]
"Following tuning experiments, we train the association models on synset embeddings with d = 300, using a negative log-likelihood loss function over 10 negative samples and iterating over symmetric relations once every five epochs.",4.5 Setup,[0],[0]
"We optimize the loss using AdaGrad with η = 0.01, and perform early stopping based on the development set mean reciprocal rank.",4.5 Setup,[0],[0]
M3GM is trained in four epochs using AdaGrad with η = 0.1.,4.5 Setup,[0],[0]
"We set M3GM’s rerank list size K = 100 and, following tuning, the regularization parameter λ = 0.01 and negative sample count per edge T = 10.",4.5 Setup,[0],[0]
"Our models are all implemented in DyNet (Neubig et al., 2017).",4.5 Setup,[0],[0]
Table 1 presents the results on the development set.,5 Results,[0],[0]
"Lines 1-3 depict the results for local models using averaged FastText embedding initialization, showing that the best performance in terms of MRR and top-rank hits is achieved by TRANSE.",5 Results,[0],[0]
"Mean Rank does not align with the other metrics; this is an interpretable tradeoff, as both BILIN and DISTMULT have an inherent preference for correlated synset embeddings, giving a stronger fallback for cases where the relation embedding is completely off, but allowing less freedom for separating strong cases from correlated false positives, compared to a translational objective.
",5 Results,[0],[0]
Effect of global score.,5 Results,[0],[0]
There is a clear advantage to re-ranking the top local candidates using the score signal from the M3GM model (line 4).,5 Results,[0],[0]
These results are further improved when the graph score is weighted against the association component per relation (line 5).,5 Results,[0],[0]
"We obtain similar improvements when re-ranking the predictions from DISTMULT and BILIN.
",5 Results,[0],[0]
"The M3GM training procedure is not useful in fine-tuning the association model via backpropagation: this degrades the association scores for true edges in the evaluation set, dragging the reranked results along with them to about a 2-point drop relative to the untuned variant.
",5 Results,[0],[0]
"Table 2 shows that our main results transfer onto the test set, with even a slightly larger margin.",5 Results,[0],[0]
"This could be the result of the greater edge density of the combined training and dev graphs, which enhance the global coherence of the graph structure captured by M3GM features.",5 Results,[0],[0]
"To support this theory, we tested the M3GM model trained on only the training set, and its test set performance was roughly one point worse on all metrics, as compared with the model trained on the training+dev data.
",5 Results,[0],[0]
Synset embedding initialization.,5 Results,[0],[0]
We trained association models initialized on AutoExtend+Mimick vectors (see Section 4.4).,5 Results,[0],[0]
"Their performance, inferior to averaged FastText vectors by about 1-2 MRR points on the dev set, is somewhat at odds with findings from previous experiments on WordNet (Guu et al., 2015).",5 Results,[0],[0]
"We believe the decisive factor in our result is the size of the training corpus used to create FastText embeddings, along with the increase in resulting vocabulary coverage.",5 Results,[0],[0]
"Out of 124,819 lemma tokens participating in 41,105 synsets, 118,051 had embeddings available (94.6%; type-level coverage 88.1%).",5 Results,[0],[0]
Only 530 synsets (1.3%) finished this initialization process with no embedding and were assigned random vectors.,5 Results,[0],[0]
"AutoExtend, fit for embeddings from Mikolov et al. (2013) which were trained on a smaller corpus, offers a weaker signal: 13,377 synsets (32%) had no vector and needed Mimick initialization.",5 Results,[0],[0]
"As a consequence of the empirical experiment, we aim to find out what M3GM has learned about WordNet.",6 Graph Analysis,[0],[0]
Table 3 presents a sample of topweighted motifs.,6 Graph Analysis,[0],[0]
"Lines 1 and 2 demonstrate that the model prefers a broad scattering of targets for the member meronym and has part relations6, which are flat and top-downwards hierarchical, respectively, while line 4 shows that a multitude of unique hypernyms is undesired, as expected from a bottom-upwards hierarchical relation.",6 Graph Analysis,[0],[0]
"Line 5 enforces the asymmetry of the hypernym relation.
",6 Graph Analysis,[0],[0]
"Lines 3, 6, and 7 hint at deeper interactions between the different relation types.",6 Graph Analysis,[0],[0]
"Line 3 shows that the model assigns positive weights to hypernyms which have derivationally-related forms, suggesting that the derivational equivalence classes in the graph tend to exist in the higher, more abstract levels of the hypernym hierarchy, as noted in Section 3.1.",6 Graph Analysis,[0],[0]
"Line 6 captures a semantic conflict: synsets located in the lower, specific levels of the graph can be specified either as instances of abstract concepts7, or as members of less specific concrete classes, but not as both.",6 Graph Analysis,[0],[0]
"Line 7 may have captured a nodal property – since part of is a relation which holds between nouns, and verb group holds between verbs, this negative weight assignment may be the manifestation of a part-of-speech uniqueness constraint.",6 Graph Analysis,[0],[0]
"In addition, in features 3 and 7 we see the importance of symmetric relations (here derivationally related form
6Example edges: ‘America’ → ‘American’, ‘face’ → ‘mouth’, respectively.
",6 Graph Analysis,[0],[0]
"7Example instance hypernym edge: ‘Rome’→ ‘national capital’.
and verb group, respectively), which manage to be represented in the graph model despite not being directly trained on.
",6 Graph Analysis,[0],[0]
Table 4 presents examples of relation targets successfully re-ranked thanks to these features.,6 Graph Analysis,[0],[0]
"The first false connection created a new unique hypernym, ‘garden lettuce’, downgraded by the graph score through incrementing the count of negatively-weighted feature 4.",6 Graph Analysis,[0],[0]
"In the second case, ‘vienna’ was brought from rank 10 to rank 1 since it incremented the count for the positivelyweighted feature 2, whereas all targets ranked above it by the local model were already has parts, mostly of ‘europe’.
",6 Graph Analysis,[0],[0]
"The αr values weighing the importance of M3GM scores in the overall function, found per relation through grid search over the development set, are presented in Table 5.",6 Graph Analysis,[0],[0]
"It appears that for all but two relations, the best-performing model preferred the signal from the graph features to that from the association model (αr > 0.5).",6 Graph Analysis,[0],[0]
"Based on the surface properties of the different relation graphs, the decisive factor seems to be that synset domain topic of and has part pertain mostly to very common concepts, offering good local signal from the synset embeddings, whereas the rest include many long-tail, low-frequency synsets that require help from global features to detect regularity.",6 Graph Analysis,[0],[0]
"This paper presents a novel method for reasoning about semantic graphs like WordNet, combining the distributional coherence between individual entity pairs with the structural coherence of network motifs.",7 Conclusion,[0],[0]
"Applied as a re-ranker, this method substantially improves performance on link prediction.",7 Conclusion,[0],[0]
"Our analysis of results from Table 3, lines 6 and 7, suggests that adding graph motifs which qualify their adjacent nodes in terms of syntactic function or semantic category may prove useful.
",7 Conclusion,[0],[0]
"From a broader perspective, M3GM can do more as a probabilistic model than predict individual edges.",7 Conclusion,[0],[0]
"For example, consider the problem of linking a new entity into a semantic graph, given only the vector embedding.",7 Conclusion,[0],[0]
"This task involves adding multiple edges simultaneously, while maintaining structural coherence.",7 Conclusion,[0],[0]
"Our model is capable of scoring bundles of new edges, and in future work, we plan to explore the possibility of combining M3GM with a search algorithm, to automatically extend existing knowledge graphs by linking in one or more new entities.
",7 Conclusion,[0],[0]
We also plan to explore multilingual applications.,7 Conclusion,[0],[0]
"To some extent, the structural parameters estimated by M3GM are not specific to English: for example, hypernymy cannot be symmetric in any language.",7 Conclusion,[0],[0]
"If the structural parameters estimated from English WordNet are transferable to other languages, then the combination of M3GM and multilingual word embeddings could facilitate the creation and extension of large-scale semantic resources across many languages (Fellbaum and Vossen, 2012; Bond and Foster, 2013; Lafourcade, 2007).",7 Conclusion,[0],[0]
We would like to thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
"We discussed fast motif-counting algorithms with Polo Chau and Oded Green, and received early feedback from Jordan Boyd-Graber, Erica Briscoe, Martin Hyatt, Bryan Leslie Lee, Martha Palmer, and Oren Tsur.",Acknowledgments,[0],[0]
This research was funded by the Defense Threat Research Agency under award HDTRA115-1-0019.,Acknowledgments,[0],[0]
"Semantic graphs, such as WordNet, are resources which curate natural language on two distinguishable layers.",abstractText,[0],[0]
"On the local level, individual relations between synsets (semantic building blocks) such as hypernymy and meronymy enhance our understanding of the words used to express their meanings.",abstractText,[0],[0]
"Globally, analysis of graph-theoretic properties of the entire net sheds light on the structure of human language as a whole.",abstractText,[0],[0]
"In this paper, we combine global and local properties of semantic graphs through the framework of Max-Margin Markov Graph Models (M3GM), a novel extension of Exponential Random Graph Model (ERGM) that scales to large multi-relational graphs.",abstractText,[0],[0]
"We demonstrate how such global modeling improves performance on the local task of predicting semantic relations between synsets, yielding new state-ofthe-art results on the WN18RR dataset, a challenging version of WordNet link prediction in which “easy” reciprocal cases are removed.",abstractText,[0],[0]
"In addition, the M3GM model identifies multirelational motifs that are characteristic of wellformed lexical semantic ontologies.",abstractText,[0],[0]
Predicting Semantic Relations using Global Graph Properties,title,[0],[0]
The problem of learning dynamics – where an agent learns a model of how its actions will affect its state and that of its environment – is a key open problem in robotics and reinforcement learning.,1. Introduction,[0],[0]
"An agent equipped with a dynamics model can leverage model-predictive control or modelbased reinforcement learning (RL) to perform a wide variety of tasks, whose exact nature need not be known in advance, and without additional access to the environment.
",1. Introduction,[0],[0]
"In contrast with model-free RL, which seeks to directly learn a policy (mapping from states to actions) in order to accomplish a specific task, learning dynamics has the advantage that dynamics models can be learned without taskspecific supervision.",1. Introduction,[0],[0]
"Since dynamics models are decoupled from any particular task, they can be reused across different
1University of California, Berkeley 2OpenAI.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Nikhil Mishra <nmishra@berkeley.edu>.
Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
tasks in the same environment.",1. Introduction,[0],[0]
"Additionally, learning differentiable dynamics models (such as those based on neural networks) enables the use of end-to-end backpropagationbased methods for policy and trajectory optimization that are much more efficient than model-free methods.
",1. Introduction,[0],[0]
"Typical approaches to dynamics learning build a one-step model of the dynamics, predicting the next state as a function of the current state and the current action.",1. Introduction,[0],[0]
"However, when chained successively for many timesteps into the future, the predictions from a one-step model tend to diverge from the true dynamics, either due to the accumulation of small errors or deviation from the regime represented by the data the model was trained on.",1. Introduction,[0],[0]
"Any learned dynamics model is only valid under the distribution of states and actions represented by its training data, and one-step models make no attempt to deal with the fact that they cannot make accurate predictions far outside this distribution.
",1. Introduction,[0],[0]
"When the true dynamics are stochastic, or the sensory measurements noisy or unreliable, these problems are only exacerbated.",1. Introduction,[0],[0]
"Moreover, the dynamics may be inherently difficult to learn: bifurcations such as collisions induce sharp changes in state that are hard to model with certainty when looking at a single timestep.",1. Introduction,[0],[0]
"There may also be hysteresis effects such as gear backlash in robots, or high-order dynamics in hydraulic robot actuators and human muscles that require looking at a history of past states.
",1. Introduction,[0],[0]
We present a novel approach to learning dynamics based on a deep generative model over temporal segments: we wish to model the distribution over possible future state trajectories conditioned on planned future actions and a history of past states and actions.,1. Introduction,[0],[0]
"By considering an entire segment of future states, our approach can model both uncertainty and complex interactions (like collisions) holistically over a segment, even if it makes small errors at individual timesteps.",1. Introduction,[0],[0]
"We also model a prior over action segments using a similar generative model, which can be used to ensure that the action distribution explored during planning is the same as the one the model was trained on.",1. Introduction,[0],[0]
"We show that that our method makes better predictions over long horizons than one-step models, is robust to stochastic dynamics and measurements, and can be used in a variety of control settings while only considering actions from the regime where the model is valid.",1. Introduction,[0],[0]
"A number of options are available for representation of learned dynamics models, including linear functions (Mordatch et al., 2016; Yip & Camarillo, 2014), Gaussian processes (Boedecker et al., 2014; Ko & Fox, 2009; Deisenroth & Rasmussen, 2011), predictive state representations (PSRs) (Littman et al., 2002; Rosencrantz et al., 2004), and deep neural networks (Punjani & Abbeel, 2015; Fragkiadaki et al., 2015; Agrawal et al., 2016).",2. Related Work,[0],[0]
"Linear functions are efficient to evaluate and solve controls for, but have limited expressive power.",2. Related Work,[0],[0]
"Gaussian processes (Williams & Rasmussen, 1996) provide uncertainty estimates, but scaling them to large datasets remains a challenge (Shen et al.; Lawrence et al., 2003).",2. Related Work,[0],[0]
"PSRs and variants make multi-step predictions, but suffer from the same scalability challenges as Gaussian processes.",2. Related Work,[0],[0]
"Our method combines the expressiveness and scalability of neural networks with the ability to provide sampling and uncertainty estimates, modeling entire segments to improve stability and robustness.
",2. Related Work,[0],[0]
"An alternative is to learn dynamics models in an online fashion, constantly adapting the model based on an incoming stream of observed states and actions (Fu et al., 2016; Mordatch et al., 2016; Yip & Camarillo, 2014; Lenz et al., 2015).",2. Related Work,[0],[0]
"However, such approaches are slow to adapt to rapidly-changing dynamics modes (such as those arising when making or breaking contact) and may be problematic when applied on robots performing rapid motions.
",2. Related Work,[0],[0]
Several approaches exist to improve the stability of models that make sequential predictions.,2. Related Work,[0],[0]
Abbeel & Ng (2004) and Venkatraman et al. (2015) consider alternative loss functions that improve robustness over long prediction horizons.,2. Related Work,[0],[0]
Bengio et al. (2015) and Venkatraman et al. (2016) also use simple curricula for a similar effect.,2. Related Work,[0],[0]
"While they all consider multi-step prediction losses, they only do so in the context of training models that are intrinsically one-step.
",2. Related Work,[0],[0]
"Existing methods for video prediction (Finn & Levine, 2016; Oh et al., 2015) look at a history of previous states and actions to predict the next frame; we take this a step further by modeling a distribution over an entire segment of future states that is also conditioned on future actions.",2. Related Work,[0],[0]
"In this work, we focus on demonstrating the benefits of a probabilistic segment-based approach; these methods could easily be incorporated with ours to learn dynamics from images, but we leave this to future work.
",2. Related Work,[0],[0]
Watter et al. (2015) and Johnson et al. (2016) use variational autoencoders to learn a low-dimensional latent-space representation of image observations.,2. Related Work,[0],[0]
"Finn et al. (2016) takes a similar approach, but without the variational aspect.",2. Related Work,[0],[0]
"These works utilized autoencoders as a means of dimensionality reduction (rather than for temporal coherence like we do) to enable the use of existing control algorithms based on locally-linear one-step dynamics models.
",2. Related Work,[0],[0]
"Temporally-extended actions were shown to be effective in reinforcement learning, such as the options framework (Sutton et al., 1999b) or sequencing of sub-plans (Vezhnevets et al., 2016).",2. Related Work,[0],[0]
Considering entire trajectories as opposed to single timesteps can also lead to simpler control policies.,2. Related Work,[0],[0]
"For example, there are effective and simple manually-designed control laws (Raibert, 1986), (Pratt et al., 2006) that formulate optimal actions as a function of the entire future trajectory rather than a single future state.",2. Related Work,[0],[0]
Suppose we have a non-linear dynamical system with states xt and actions ut.,3. Segment-Based Dynamics Model,[0],[0]
"The conventional approach to learning dynamics is to learn a function xt+1 = f(xt, ut) using an approximator such as a neural network (possibly recurrent).
",3. Segment-Based Dynamics Model,[0],[0]
"We consider a more general formulation of the problem, which is depicted in Figure 1: given segments (of lengthH) of past states X− = {xt−H , . . .",3. Segment-Based Dynamics Model,[0],[0]
", xt−1} and actions U− = {ut−H , . . .",3. Segment-Based Dynamics Model,[0],[0]
", ut−1}, we wish to predict the entire segment of future states X+ = {xt, . . .",3. Segment-Based Dynamics Model,[0],[0]
", xt+H} that would result from taking actions U+ = {ut, . . .",3. Segment-Based Dynamics Model,[0],[0]
", ut+H−1}.",3. Segment-Based Dynamics Model,[0],[0]
"Treating these four temporal segments as random variables, then we wish to learn the conditional distribution P (X+|X−, U−, U+).",3. Segment-Based Dynamics Model,[0],[0]
"We introduce dependency on past actions U− to support dynamics with delayed or filtered actions.
",3. Segment-Based Dynamics Model,[0],[0]
"With this in mind, we propose the use of a deep conditional variational autoencoder (Kingma & Welling, 2014): our encoder will learn the distribution Q(x)(Z|X+, X−, U−, U+) over latent codes Z, and our decoder will learn to reconstruct X+ from X−, U−, U+ and a sample from Z, modeling the distribution P (x)(X+|X−, U−, U+, Z).",3. Segment-Based Dynamics Model,[0],[0]
"Note that the random variable Z is a vector that describes an entire segment of states, X+.",3. Segment-Based Dynamics Model,[0],[0]
"After training is complete, we can discard the
encoder, and the decoder will allow us to predict the future state trajectory X̂+ using X−, U−, U+, as desired, sampling latent codes from an enforced prior P (Z) = N (0, I).",3. Segment-Based Dynamics Model,[0],[0]
"Empirically, we observe that having the encoder model Q(x)(Z|X+) instead of Q(x)(Z|X+, X−, U−, U+) gives equivalent performance, and so we take this approach in all of our experiments for simplicity.",3. Segment-Based Dynamics Model,[0],[0]
In the previous section we discussed a conditional variational autoencoder whose generative path serves as a stochastic dynamics model.,3.1. Model Architecture and Training,[0],[0]
Here we will expand on some of the architectural details.,3.1. Model Architecture and Training,[0],[0]
A diagram of the entire training setup is shown in Figure 2.,3.1. Model Architecture and Training,[0],[0]
"For more details of the architectures used in our experiments, see Appendix A.
The encoder network Q(x) explicitly parametrizes a Gaussian distribution over latent codes Z with diagonal covariance.",3.1. Model Architecture and Training,[0],[0]
"It consists of a stack of 1D-convolutional layers, whose output is flattened and projected into a single vector containing a mean µZ and variance σ2Z .",3.1. Model Architecture and Training,[0],[0]
We then sample z ∼ N,3.1. Model Architecture and Training,[0],[0]
"(µZ , σ2Z) in a differentiable manner using the reparametrization trick (Kingma & Welling, 2014).
",3.1. Model Architecture and Training,[0],[0]
The decoder network P (x) seeks to model a distribution over a segment of states P (X+),3.1. Model Architecture and Training,[0],[0]
"= P (xt, . . .",3.1. Model Architecture and Training,[0],[0]
", xt+H).",3.1. Model Architecture and Training,[0],[0]
"The causal nature of this segment (a particular timestep is only
affected by the ones that occur before it)",3.1. Model Architecture and Training,[0],[0]
"suggests that an autoregressive model with dilated convolutions is appropriate, similar to architectures previously used for modeling audio (van den Oord et al., 2016a) and image (van den Oord et al., 2016b) data.",3.1. Model Architecture and Training,[0],[0]
"Like these works, we use layers with the following activation function:
tanh(Wf,k ∗ s+ V Tf,kz) σ(Wg,k ∗",3.1. Model Architecture and Training,[0],[0]
"s+ V Tg,kz) (1)
where ∗ denotes convolution, denotes elementwise multiplication, σ(·) is the sigmoid function, s is the input to the layer, z is a latent code sampled from the output of the decoder, and W,V are network weights to be learned.",3.1. Model Architecture and Training,[0],[0]
"We found that residual layers and skip connections between layers give slightly better performance but are not essential.
",3.1. Model Architecture and Training,[0],[0]
"We train the model parameters end-to-end, minimizing the l2-loss between X+ and its reconstruction X̂+, along with the KL-divergence of the latent codeZ ∼ N (µZ , σ2Z) from N (0, I) similarly to Kingma & Welling (2014).",3.1. Model Architecture and Training,[0],[0]
"Once we have learned a dynamics model, we want to utilize it in order to accomplish different tasks, each of which can be expressed as reward function r(xt, ut).",4. Control with Segment-Based Models,[0],[0]
"Trajectory optimization and policy optimization are two settings where a dynamics model would commonly be used, and provide meaningful ways with which to evaluate a dynamics model.",4. Control with Segment-Based Models,[0],[0]
"In trajectory optimization, we wish to find a sequence of actions that can be applied to accomplish a particular instance of a task.",4.1. Trajectory Optimization,[0],[0]
"Specifically, given a reward function r, we want to maximize the sum of rewards along the trajectory that results from applying the actions u1, . . .",4.1. Trajectory Optimization,[0],[0]
", uT , beginning from an initial state x0.",4.1. Trajectory Optimization,[0],[0]
"This can be summarized by the following optimization problem:
max u1,...,uT E",4.1. Trajectory Optimization,[0],[0]
"[ T∑ t=1 r(xt, ut) ] with xt ∼ P (x)(xt|x0:t−1, u1:t)
(2)
where r(xt, ut) is the reward received at time t, and X = {x1, . . .",4.1. Trajectory Optimization,[0],[0]
", xT } is the sequence of states that would result from taking actions U = {u1, . . .",4.1. Trajectory Optimization,[0],[0]
", uT } from initial state x0, under dynamics model P (x).",4.1. Trajectory Optimization,[0],[0]
The expectation is taken over state trajectories sampled from the model.,4.1. Trajectory Optimization,[0],[0]
"If we attempt to solve the optimization problem as posed in (2), the solution will often attempt to apply action sequences outside the manifold where the dynamics model
is valid: these actions come from a very different distribution than the action distribution of the training data.",4.2. Latent Action Priors,[0],[0]
"This can be problematic: the optimization may find actions that achieve high rewards under the model (by exploiting it in a regime where it is invalid) but that do not accomplish the goal when they are executed in the real environment.
",4.2. Latent Action Priors,[0],[0]
"To mitigate this problem, we propose the use of another conditional variational autoencoder, this one over segments of actions.",4.2. Latent Action Priors,[0],[0]
"In particular, given sequences of past actions U− = {ut−H , . . .",4.2. Latent Action Priors,[0],[0]
", ut−1}, and future actions U+ = {ut, . . .",4.2. Latent Action Priors,[0],[0]
", ut+H}, we wish to model the the conditional distribution P (U+|U−).",4.2. Latent Action Priors,[0],[0]
"The encoder learnsQ(u)(Z|U+) and the decoder learns P (u)(U+|Z,U−).",4.2. Latent Action Priors,[0],[0]
We condition on U− to support temporal coherence in the generated action sequence.,4.2. Latent Action Priors,[0],[0]
"Like the dynamics model introduced in Section 3.1, the encoder uses 1D-convolutional layers, and the decoder is autoregressive, with dilated causal convolutions.",4.2. Latent Action Priors,[0],[0]
"The latent space that this autoencoder learns describes a prior over actions that can be used when planning with a dynamics model; hence we refer to this autoencoder over action sequences as a latent action prior.
",4.2. Latent Action Priors,[0],[0]
"To incorporate a latent action prior, we divide an action sequence U = {u1, . . .",4.2. Latent Action Priors,[0],[0]
", uT } into segments U1, . . .",4.2. Latent Action Priors,[0],[0]
"UK of length H (where K is determined such that T = HK, and U0 = 0).",4.2. Latent Action Priors,[0],[0]
"Then we can generate action sequences that are similar to the ones in our training set by sampling different latent codes z1, . . .",4.2. Latent Action Priors,[0],[0]
", zK and using the decoder to sample from P (u)(Uk|Uk−1, zk),∀k = 1, . . .",4.2. Latent Action Priors,[0],[0]
",K. The optimization problem posed in (2) can then be expressed as:
max z1,...,zK E",4.2. Latent Action Priors,[0],[0]
"[ T∑ t=1 r(xt, ut) ] with xt ∼ P (x)(xt|x0:t−1, u1:t)
",4.2. Latent Action Priors,[0],[0]
"ut ∼ P (u)(ut|u1:t−1, z1:K)
(3)
where the actions u1, . . .",4.2. Latent Action Priors,[0],[0]
", uT and states x1, . . .",4.2. Latent Action Priors,[0],[0]
", xT are generated by the latent action prior and dynamics model (see Figure 3 for an illustration).",4.2. Latent Action Priors,[0],[0]
"Since the dynamics model is differentiable, the above optimization problem can be solved end-to-end with backpropagation.",4.2. Latent Action Priors,[0],[0]
"While it is still nonconvex, we are optimizing over fewer variables, and the possible action sequences that are explored will be from the same distribution as the model’s training data.",4.2. Latent Action Priors,[0],[0]
"Moreover, the gradients of the rewards with respect to the latent codes are likely to have stronger signal than those with respect to a single action.",4.2. Latent Action Priors,[0],[0]
"We used Adam (Kingma & Ba, 2015) with step size 0.01 to perform this optimization and found that it generally converged in around 100 iterations.",4.2. Latent Action Priors,[0],[0]
"Trajectory optimization enables an agent to accomplish a single instance of a task, but more often, we are interested
in policy optimization, where the agent learns a policy that dictates optimal behavior in order to accomplish the task in the general case.",4.3. Policy Optimization,[0],[0]
"In particular, a policy is a learned function (with parameters θ) that defines a conditional distribution over actions given states, denoted πθ(u|x).",4.3. Policy Optimization,[0],[0]
"The value of a policy is defined as the expected sum of discounted rewards when acting under the policy, and can be expressed as:
η(θ) =",4.3. Policy Optimization,[0],[0]
"E [ ∞∑ t=1 γt · r(xt, ut) ]
(4)
where the actions are sampled from πθ(ut|xt), and γ is a discount factor.",4.3. Policy Optimization,[0],[0]
"The goal of policy optimization is to maximize the value of the policy with respect to its parameters.
",4.3. Policy Optimization,[0],[0]
"The class of algorithms known as policy gradient methods (Sutton et al., 1999a; Peters & Schaal, 2006) attempt to solve this optimization problem without considering a dynamics model.",4.3. Policy Optimization,[0],[0]
"They execute a policy πθ to get samples x1, u1, r1, . . .",4.3. Policy Optimization,[0],[0]
", xT , uT , rT from the environment, and then update θ to get an improved policy, relying on likelihood ratio methods (Williams, 1992) to estimate the gradient ∂η∂θ because they cannot directly compute the derivatives of the rewards r(xt, ut) with respect to the actions u1, . . .",4.3. Policy Optimization,[0],[0]
", ut.
Model-based policy optimization can be more efficient than traditional policy-gradient methods, because the gradient ∂η ∂θ can be computed directly by backpropagation through a differentiable model.",4.3. Policy Optimization,[0],[0]
"However, its success hinges on the
accuracy of the dynamics model, as the optimization can exploit flaws in the model in the same way as discussed in Section 4.2.",4.3. Policy Optimization,[0],[0]
Heess et al. (2015) use a model-based approach where a one-step dynamics model is learned jointly with a policy in an online manner.,4.3. Policy Optimization,[0],[0]
"To evaluate the robustness of our models, we experiment with learning policies offline, where the dynamics model is learned through unsupervised exploration of the environment, and no environment interaction is allowed beyond this exploration.
",4.3. Policy Optimization,[0],[0]
"Instead of a one-step policy of the form πθ(ut|xt), we also explored using a segment-based policy πθ(Z|X−, U−) that generates actions using latent action priorP (u) as follows:
X−, U− = {xt−H , . . .",4.3. Policy Optimization,[0],[0]
", xt−1}, {ut−H , . . .",4.3. Policy Optimization,[0],[0]
", ut−1} sample Z ∼ πθ(Z|X−, U−)
{ut, . . .",4.3. Policy Optimization,[0],[0]
", ut+H} = U+ ∼ P (u)(U+|Z,U−) and then acts according to action ut.",4.3. Policy Optimization,[0],[0]
The resulting policy will learn to accomplish the task while only considering actions for which the dynamics model is valid.,4.3. Policy Optimization,[0],[0]
"In terms of the options framework (Sutton et al., 1999b), we can think of this policy as considering a continuous spectrum of options, all of which are consistent with both past observed states and actions, and the data distribution under which the dynamics model makes good predictions.",4.3. Policy Optimization,[0],[0]
Our experiments investigate the following questions: (i) How well do segment-based models predict dynamics?,5. Experiments,[0],[0]
(ii) How does prediction accuracy transfer to control applications?,5. Experiments,[0],[0]
How does this scale with the difficulty of the task and stochasticity in the dynamics?,5. Experiments,[0],[0]
(iii) How is this affected by the use of latent action priors?,5. Experiments,[0],[0]
(iv) Is there any meaning or structure encoded by the latent space learned by the dynamics model?,5. Experiments,[0],[0]
"In order for a dynamics model to be versatile enough for use in control settings, the training data needs to contain a variety of actions that explore a diverse subset of the state space.",5.1. Environments,[0],[0]
Efficient exploration strategies are an open problem in reinforcement learning and are not the focus of this work.,5.1. Environments,[0],[0]
"With this in mind, we base our experiments on a simulated 2-DOF arm moving in a plane (as implemented in the Reacher environment in OpenAI Gym), because performing random actions in this environment results in sufficient exploration.",5.1. Environments,[0],[0]
We consider the following environments throughout our experiments (illustrated in Figure 4): (i),5.1. Environments,[0],[0]
"The basic, unmodified Reacher environment.",5.1. Environments,[0],[0]
"(ii) A version containing an obstacle that the arm can collide with: the obstacle cannot move, but its position is randomly chosen at the start of each episode.",5.1. Environments,[0],[0]
"(iii) A version in which the arm can push a damped cylin-
drical object around the arena.
",5.1. Environments,[0],[0]
"While the segment length and dimensionality of the latent space could be varied, we found that these values were reasonable choices for these environments.",5.1. Environments,[0],[0]
"As the segment length approaches 1, the model degenerates into a one-step model, and for longer segments, its performance plateaus because the states towards the end of the segment become independent of those at the beginning.",5.1. Environments,[0],[0]
"Likewise, we observed that this latent-space dimensionality was a good trade-off between expressiveness and information density.",5.1. Environments,[0],[0]
"We compare our method against the following baselines: (i) A one-step model: a learned function xt+1 = f(xt, ut), where f is a fully-connected neural network.",5.2. Baselines,[0],[0]
"It is trained using a one-step-prediction l2-loss on tuples (xt, ut, xt+1).",5.2. Baselines,[0],[0]
(ii) A one-step model that is rolled out several timesteps at training time.,5.2. Baselines,[0],[0]
"The model is still a learned function xt+1 = f(xt, ut), but it is trained with a multi-step prediction loss, over a horizon of length 2H .",5.2. Baselines,[0],[0]
"While this does not increase the model’s expressive power, we expect it to be more robust to the accumulation of small errors (e.g., Venkatraman et al. (2015); Abbeel & Ng (2004)).",5.2. Baselines,[0],[0]
"(iii) An LSTM model, which can store information about the past in a hidden state ht: xt+1, ht+1 = f(xt, ut, ht), and is trained with the same multi-step prediction loss (also over a horizon of 2H).",5.2. Baselines,[0],[0]
"We expect that the LSTM can learn fairly complex dynamics, but the hidden state dependencies can make trajectory and policy optimization more difficult.",5.2. Baselines,[0],[0]
"After learning a dynamics model, we evaluate it on a test set of held-out trajectories by computing the average loglikelihood of the test data under the model.
",5.3.1. DYNAMICS PREDICTION,[0],[0]
"For our method, we do this by obtaining samples from the model, fitting a Gaussian to the samples, and determining the log-likelihood of the true trajectory under the fitted Gaussian.",5.3.1. DYNAMICS PREDICTION,[0],[0]
"Since the baseline methods do not express uncertainty, but are trained using l2-loss, we interpret their predictions as the mean of a Gaussian distribution whose variance is constant across all state dimensions and timesteps (since minimizing l2-loss is equivalent to maximizing this log-likelihood).",5.3.1. DYNAMICS PREDICTION,[0],[0]
"We then fit the value of the variance constant to maximize the log-likelihood on the test set.
",5.3.1. DYNAMICS PREDICTION,[0],[0]
Figure 5 compares our method to the baselines in each environment.,5.3.1. DYNAMICS PREDICTION,[0],[0]
"The values reported are log-likelihoods per timestep, averaged over a test set of 1000 trajectories.",5.3.1. DYNAMICS PREDICTION,[0],[0]
"Our model and the LSTM are competitive in the basic environment (and both substantially better than the one-step models), but the LSTM’s performance degrades on more challenging environments with collisions.
",5.3.1. DYNAMICS PREDICTION,[0],[0]
"Basic Pushing Object With Obstacle
Environment
32.16
26.55
17.95
28.44
16.42
11.96
18.49
13.02 11.36
19.93
13.98 12.55
Ours LSTM One Step One Step, rolled out
Figure 5.",5.3.1. DYNAMICS PREDICTION,[0],[0]
Prediction quality of our method compared to several baselines in a range of environments.,5.3.1. DYNAMICS PREDICTION,[0],[0]
The reported values are the average log-likelihood per timestep on a test set (higher is better).,5.3.1. DYNAMICS PREDICTION,[0],[0]
"Our method significantly outperforms the baseline methods, even in environments with complex dynamics such as collisions.",5.3.1. DYNAMICS PREDICTION,[0],[0]
"Next, we compare our method to the baselines on trajectory and policy optimization.",5.3.2. CONTROL1,[0],[0]
"Of interest is both the actual reward achieved in the environment, and the difference between the true reward and the expected reward under the model.",5.3.2. CONTROL1,[0],[0]
"If a control algorithm exploits the model to predict unrealistic behavior, then the latter will be large.
",5.3.2. CONTROL1,[0],[0]
We consider two tasks: (i),5.3.2. CONTROL1,[0],[0]
Reaching Task: the arm must move its end effector to a desired position.,5.3.2. CONTROL1,[0],[0]
"The reward function is the negative distance between the end effector and the target position, minus a quadratic penalty on applying large torques.
1 Videos of our experimental results can be seen here: https://sites.google.com/site/temporalsegmentmodels/.
(ii) Pushing Task: the arm must push a cylindrical object to the desired position.",5.3.2. CONTROL1,[0],[0]
"Like in the reaching task, the reward function is the negative distance between the object and the target, again minus a penalty on large torques.
",5.3.2. CONTROL1,[0],[0]
The trajectory-optimization results are summarized in Figure 6.,5.3.2. CONTROL1,[0],[0]
"For each task and dynamics model, we sampled 100 target positions uniformly at random, solved the optimization problem as described in (2) or (3), and then executed the action sequences in the environment in open loop.",5.3.2. CONTROL1,[0],[0]
"Under each model, the optimization finds actions that achieve similar model-predicted rewards, but the baselines suffer from large discrepancies between model prediction and the true dynamics.",5.3.2. CONTROL1,[0],[0]
"Qualitatively, we notice that, on the pushing task, the optimization exploits the LSTM and onestep models to predict unrealistic state trajectories, such as the object moving without being touched or the arm passing through the object instead of colliding with it.",5.3.2. CONTROL1,[0],[0]
"Our model consistently performs better, and, with a latent action prior, the true execution closely matches the model’s prediction.",5.3.2. CONTROL1,[0],[0]
"When it makes inaccurate predictions, it respects physical invariants, such as objects staying still unless they are touched, or not penetrating each other when they collide.
",5.3.2. CONTROL1,[0],[0]
"Reaching Pushing
7.23 7.917.38
12.15
8.15
16.06
8.69
19.65
7.89
19.01
Negative Reward in Environment
Reaching Pushing
0.21 0.131.01
4.30 1.65
8.44
2.27
11.71
1.58
11.47
Discrepancy between Model and Environment
Ours, with latent prior Ours, without latent prior LSTM
One Step One Step, rolled out
Figure 6.",5.3.2. CONTROL1,[0],[0]
Trajectory optimization on the reaching and pushing tasks.,5.3.2. CONTROL1,[0],[0]
"The top plot reports the negative reward from open-loop execution of the returned action sequences (lower is better, averaged over 100 trials), and the bottom shows the difference between true reward and model-predicted reward.",5.3.2. CONTROL1,[0],[0]
"Our model, with a latent action prior, achieves both the best in-environment performance and the smallest discrepancy between environment and model.
",5.3.2. CONTROL1,[0],[0]
Figure 7 depicts the results from policy-optimization (Section 4.3) in the form of learning curves for each task and dynamics model.,5.3.2. CONTROL1,[0],[0]
See Appendix A for model architectures and hyperparameters.,5.3.2. CONTROL1,[0],[0]
"For comparison, we also plot the performance of a traditional policy gradient method.",5.3.2. CONTROL1,[0],[0]
"Although this method and ours eventually achieve similar performance, ours does so much more efficiently, learning the policy offline with fewer samples from the model than the traditional method needed from the environment.",5.3.2. CONTROL1,[0],[0]
"To explore the effects of stochastic dynamics and delayed actions, we consider two more modifications of the Reacher environment, one in which there is considerable Gaussian noise in the state observations (σ = 0.25 on data in the range [−1,+1]), and one in which actions are delayed: they do not take effect for τ = 5 timesteps after they are applied.",5.3.3. SENSORY NOISE AND DELAYED ACTIONS,[0],[0]
"These challenges commonly arise in realworld robotics applications (Atkeson et al., 2016), and so it is important to be able to learn a useful dynamics model in either setting.",5.3.3. SENSORY NOISE AND DELAYED ACTIONS,[0],[0]
"For both the noisy-state and delayedaction environments, we learn a dynamics model with each method, and then use it to learn a policy for the reaching task.",5.3.3. SENSORY NOISE AND DELAYED ACTIONS,[0],[0]
Figure 8 displays the resulting learning curves.,5.3.3. SENSORY NOISE AND DELAYED ACTIONS,[0],[0]
"Our dynamics model performs much better than the baselines, both with and without an action prior.",5.3.3. SENSORY NOISE AND DELAYED ACTIONS,[0],[0]
"Notably, using the LSTM model results in a substantially worse policy than ours even though its prediction accuracy is only slightly lower.",5.3.3. SENSORY NOISE AND DELAYED ACTIONS,[0],[0]
"Because our model operates over segments, it implicitly learns to filter noisy observations.",5.3.3. SENSORY NOISE AND DELAYED ACTIONS,[0],[0]
"This removes the need to explicitly apply and tune a filtering process, as is traditionally done.",5.3.3. SENSORY NOISE AND DELAYED ACTIONS,[0],[0]
"Variational autoencoders are known for learning lossy latent codes that preserve high-level semantics of the data, leaving the decoder to determine the low-level details.",5.3.4. ANALYSIS OF LATENT SPACE,[0],[0]
"As a result, we are curious to see whether our dynamics model learns a latent space that possesses similar properties.
",5.3.4. ANALYSIS OF LATENT SPACE,[0],[0]
"Applied to dynamics data, one might expect a latent code to provide an overall description of what happens in the state trajectory X+ it encodes.",5.3.4. ANALYSIS OF LATENT SPACE,[0],[0]
"Alternatively, per the argument made by Chen et al. (2016), it is also conceivable that the decoder would ignore the latent code entirely, because the segments X−, U−, U+ provide better information than Z about X+.",5.3.4. ANALYSIS OF LATENT SPACE,[0],[0]
"However, we observe that our model does learn a meaningful latent space: one that encodes uncertainty about the future.",5.3.4. ANALYSIS OF LATENT SPACE,[0],[0]
"A particular latent code corresponds to a particular future within the space of possible ones consistent with the given X−, U−, U+.
",5.3.4. ANALYSIS OF LATENT SPACE,[0],[0]
"When the dynamics are simple and deterministic (such as in the original Reacher environment), the model does express certainty by ignoring the latent code.",5.3.4. ANALYSIS OF LATENT SPACE,[0],[0]
"With stochas-
ticity (such as in the previous section), it provides a spread of reasonable state trajectories.",5.3.4. ANALYSIS OF LATENT SPACE,[0],[0]
"Interestingly, when the dynamics are deterministic but complex, the model also uses the latent codes to express uncertainty.",5.3.4. ANALYSIS OF LATENT SPACE,[0],[0]
"This can occur regarding the orientations and velocities of objects immediately following a collision, as illustrated in Figure 9.",5.3.4. ANALYSIS OF LATENT SPACE,[0],[0]
"Our earlier experiments demonstrated the benefits of a latent action prior: by only considering actions for which the dynamics model is valid, the discrepancy between the model and the true dynamics is minimized, resulting in higher rewards achieved in the actual environment.
",5.3.5. EFFECT OF LATENT ACTION PRIOR,[0],[0]
"In this section, we qualitatively examine how the actions returned by control algorithms differ as a consequence of the latent action prior.",5.3.5. EFFECT OF LATENT ACTION PRIOR,[0],[0]
An example is illustrated in Figure 10.,5.3.5. EFFECT OF LATENT ACTION PRIOR,[0],[0]
"In the training data, the actions that the agent takes are smooth, random torques, and we observe that when we use an action prior, solutions from trajectory optimization look similar.",5.3.5. EFFECT OF LATENT ACTION PRIOR,[0],[0]
"We contrast this with the solutions from optimizing directly over actions, which are sharp and discontinuous, unlike anything the dynamics model has seen before.",5.3.5. EFFECT OF LATENT ACTION PRIOR,[0],[0]
"This lets us infer that the baselines perform poorly on the pushing task (as shown in Figure 6) because of large discrepancies between the model prediction and the true execution.
0",5.3.5. EFFECT OF LATENT ACTION PRIOR,[0],[0]
"20 40 60 80 100
Timestep
Sample of Actions from Training Data",5.3.5. EFFECT OF LATENT ACTION PRIOR,[0],[0]
"We presented a novel approach to dynamics learning based on temporal segments, using a variational autoencoder to learn the distribution over future state trajectories conditioned on past states, past actions, and planned future actions.",6. Conclusion and Future Work,[0],[0]
"We also introduced the latent action prior, a variational autoencoder that models a prior over action segments, and showed how it can be used to perform control using actions from the same distribution as a dynamics model’s training data.",6. Conclusion and Future Work,[0],[0]
"Finally, through experiments involving trajectory optimization and model-based policy optimization, we showed that the resulting method can model complex phenomena such as collisions, is robust to sensory noise and action delays, and learns a meaningful latent space that expresses uncertainty about the future.
",6. Conclusion and Future Work,[0],[0]
"The most prominent direction for future work that we plan to explore, is the data collection procedure.",6. Conclusion and Future Work,[0],[0]
"In our experiments, correlated random actions resulted in sufficient exploration for the tasks we considered and allowed us to demonstrate the benefits of a segment-based approach.",6. Conclusion and Future Work,[0],[0]
"However, incorporating a more sophisticated exploration strategy to gather data (in an iterative procedure, potentially using the model’s predictions to guide exploration) would allow us to tackle a more diverse set of environments, both simulated and real-world.",6. Conclusion and Future Work,[0],[0]
The action prior and segmentbased policy could be used as a starting point for hierarchical reinforcement-learning algorithms.,6. Conclusion and Future Work,[0],[0]
Leveraging existing work on few-shot learning could help finetune a dynamics model during the policy learning process.,6. Conclusion and Future Work,[0],[0]
"Such approaches could yield significant advances in reinforcement learning, improving both sample efficiency and knowledge transfer between related tasks.",6. Conclusion and Future Work,[0],[0]
Work done at Berkeley was supported in part by an ONR PECASE award.,Acknowledgements,[0],[0]
We introduce a method for learning the dynamics of complex nonlinear systems based on deep generative models over temporal segments of states and actions.,abstractText,[0],[0]
"Unlike dynamics models that operate over individual discrete timesteps, we learn the distribution over future state trajectories conditioned on past state, past action, and planned future action trajectories, as well as a latent prior over action trajectories.",abstractText,[0],[0]
Our approach is based on convolutional autoregressive models and variational autoencoders.,abstractText,[0],[0]
"It makes stable and accurate predictions over long horizons for complex, stochastic systems, effectively expressing uncertainty and modeling the effects of collisions, sensory noise, and action delays.",abstractText,[0],[0]
"The learned dynamics model and action prior can be used for end-to-end, fully differentiable trajectory optimization and model-based policy optimization, which we use to evaluate the performance and sample-efficiency of our method.",abstractText,[0],[0]
Prediction and Control with Temporal Segment Models,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 193–199 New Orleans, Louisiana, June 1 - 6, 2018. c©2017 Association for Computational Linguistics",text,[0],[0]
"In the last decades, media and news business underwent a fundamental shift, from one-directional to bi-directional communication between users on the one side and journalists on the other.",1 Exploding Comment Threads,[0],[0]
"The use of social media, blogs, and the possibility to immediately share, like, and comment digital content transformed readers into active and powerful agents in the media business.",1 Exploding Comment Threads,[0],[0]
"This shift from passive “consumers” to active “agents” deeply impacts both media and communication science and has many positive aspects.
",1 Exploding Comment Threads,[0],[0]
"However, the possibilities and powers can also be misused.",1 Exploding Comment Threads,[0],[0]
"Pressure groups, lobbyists, trolls, and others are effectively trying to influence discussions according to their (very different) interests.",1 Exploding Comment Threads,[0],[0]
An easy approach consists in burying unwanted arguments or simply destroying a discussion by blowing it up.,1 Exploding Comment Threads,[0],[0]
"After such an attack, readers have to crawl through hundreds of nonsense and meaningless comments to extract meaningful and interesting arguments.",1 Exploding Comment Threads,[0],[0]
"Blowing up a thread can be
achieved by injecting provocative (but not necessarily off-topic) arguments into discussions.",1 Exploding Comment Threads,[0],[0]
"Bystanders are completing the goal of the destroyers, and they do so often unknowingly: with each — often well-intentioned — reaction to the provocation, they make it more difficult for others to follow the actual argumentation path and/or tree.
",1 Exploding Comment Threads,[0],[0]
"It is costly in terms of working power and time to keep the discussion area of a news site clean from attacks like that, and to watch the compliance of users (“netiquette”).",1 Exploding Comment Threads,[0],[0]
"As a reaction, many large online media sites worldwide closed their discussion areas or downsized them significantly (prominent examples of the last years are the Internet Movie Database, Bloomberg or the USAmerican National Public Radio).",1 Exploding Comment Threads,[0],[0]
"Other news provider and media sites, including us, take a different approach: A team of editors reads and filters comments on a 24/7-basis.",1 Exploding Comment Threads,[0],[0]
This results in a huge workload with several thousand reader comments published each day.,1 Exploding Comment Threads,[0],[0]
"In its lifetime, an article receives between less than ten and more than 1500 comments; typical are about 100 to 150 comments.",1 Exploding Comment Threads,[0],[0]
"The number of published comments
193
presumably depends to a large extent on time, weather, and season as well as for each article on subject, length, style of writing, and author, among others.
Being able to predict which articles will receive high comment volume would be beneficial at two positions in the newsroom:
1.",1 Exploding Comment Threads,[0],[0]
"for the news director to schedule the publication of news stories, and
2.",1 Exploding Comment Threads,[0],[0]
"for scheduling team sizes and guiding the focus of the comment moderators and editors.
",1 Exploding Comment Threads,[0],[0]
Figure 1 gives an overview of how comment volume prediction can be integrated into the workflow of a modern online news site.,1 Exploding Comment Threads,[0],[0]
The incoming news articles are ranked based on the estimated number of comments they will attract.,1 Exploding Comment Threads,[0],[0]
The news director takes these numbers into account in the decision process when to schedule which article for publication.,1 Exploding Comment Threads,[0],[0]
"This can balance the distribution of highly controversial topics across a day, giving not only readers and commenters the possibility to engage in each single one, but also distribute the moderation workload for comment editors evenly.",1 Exploding Comment Threads,[0],[0]
"Further, knowing which articles will receive many comments can help in the moderation process.",1 Exploding Comment Threads,[0],[0]
"Guiding the main focus of attention of moderators towards controversial topics not only facilitates efficient moderation, but also improves the quality of a comment thread.",1 Exploding Comment Threads,[0],[0]
"Our experience has shown that moderators entering the online discussion at an early stage can help keeping the discussion focused and fruitful.
",1 Exploding Comment Threads,[0],[0]
"In this paper, we study the task of identifying the weekly top 10% articles with the highest comment volume.",1 Exploding Comment Threads,[0],[0]
We consider a new real-world dataset of 7 million news comments collected over more than nine years.,1 Exploding Comment Threads,[0],[0]
"In order to enrich our dataset and increase its meaningfulness, we propose to transfer a classifier trained on the Englishlanguage Yahoo News Annotated Comments Corpus (Napoles et al., 2017b) to our Germanlanguage dataset and leverage the additional class labels for comments in a post-publication prediction scenario.",1 Exploding Comment Threads,[0],[0]
"Experiments show that our logistic regression model based on article metadata, linguistic, and topical features outperforms state-ofthe-art approaches significantly.",1 Exploding Comment Threads,[0],[0]
"Our contributions are summarized as (1) a transfer learning approach to learn early comments’ characteristics, (2) an analysis of a new 7-million-comment dataset and
(3) an improvement of F1-score by 81% compared to state-of-the-art in predicting most commented articles.",1 Exploding Comment Threads,[0],[0]
Related work on newsroom assistants focuses on comment volume prediction for pre-publication and post-publication scenarios.,2 Related Work,[0],[0]
"By the nature of news articles, the attention span after article publication is short and in practice post-publication prediction is valuable only within a short time frame.",2 Related Work,[0],[0]
Tsagkias et al. (2009) classify online newspaper articles using random forests.,2 Related Work,[0],[0]
"First, they classify whether an article will receive any comments at all.",2 Related Work,[0],[0]
"Second, they classify articles as receiving a high or low amount of comments.",2 Related Work,[0],[0]
The authors find that the second task is much harder and that predicting the actual number of comments is practically infeasible.,2 Related Work,[0],[0]
"Badari et al. (2012) conclude the same, analyzing Twitter activity as a popularity indicator for news:",2 Related Work,[0],[0]
Predicting popularity as a regression task results in large errors.,2 Related Work,[0],[0]
"Therefore, the authors predict classes of popularity by binning the absolute numbers (1-20, 20-100, 100-2400 received tweets).",2 Related Work,[0],[0]
"However, predicting the number of received tweets includes modeling both, the user behavior and the platform, which is problematic.",2 Related Work,[0],[0]
"It is part of a platform’s business secrets how content is internally ranked and distributed to users, making it hard to distinguish cause and effect from the outside.",2 Related Work,[0],[0]
"In our scenario, we even see no benefit in predicting the exact number of comments.",2 Related Work,[0],[0]
"Instead, we predict which articles belong to the weekly top 10% articles with the highest comment volume, which is one of the tasks defined by Tsagkias et al. (2009).
",2 Related Work,[0],[0]
"In a post-publication scenario, Tsagkias et al. (2010) consider the comments received within the first ten hours after article publication.",2 Related Work,[0],[0]
"Based on this feature, they propose a linear model to predict the final number of comments.",2 Related Work,[0],[0]
"Comparing comment behavior at eight online news platforms, they observe seasonal trends.",2 Related Work,[0],[0]
Tatar et al. (2011) consider the shorter time frame of five hours after article publication to predict article popularity.,2 Related Work,[0],[0]
They also use a linear model and find that neither adding publication time and article category to the feature set nor extending the dataset from three months to two years improves prediction results.,2 Related Work,[0],[0]
"Their survey on popularity prediction for web content summarizes features with good predictive capabilities
and lists fields of application for popularity prediction (Tatar et al., 2012).
",2 Related Work,[0],[0]
Rizos et al. (2016) focus on user comments to predict a discussion’s controversiality.,2 Related Work,[0],[0]
"They extract a comment tree and a user graph from the discussion and investigate for example comment count, number of users, and vote score.",2 Related Work,[0],[0]
"The demonstrated improvement of popularity prediction with this limited, focused features motivates us to further explore content-based features of comments in our work.
",2 Related Work,[0],[0]
"Recently, research on deep learning (Nobata et al., 2016; Pavlopoulos et al., 2017) addresses (semi-) automation of the entire moderation task, but we see several issues that prevent us from putting these approaches into practice.",2 Related Work,[0],[0]
"First, the accuracy of these methods is not high enough.",2 Related Work,[0],[0]
"For example, reported recall (0.79) and precision (0.77) at the task of abusive language detection (Nobata et al., 2016) are not sufficient for use in production.",2 Related Work,[0],[0]
"With this recall, an algorithm would let pass every fifth inappropriate comment (containing hate speech, derogatory statements, or profanity), which is not acceptable.",2 Related Work,[0],[0]
Pavlopoulos et al. (2017) address this problem by letting human moderators review comments that an algorithm could not classify with high confidence.,2 Related Work,[0],[0]
"Second, acceptance of these kind of black-box solutions is still limited in the community and the models lack comprehensibility.",2 Related Work,[0],[0]
"A compromise can be (ensemble) decision trees, because they achieve comparable results and can give reasons for their decisions (Kennedy et al., 2017).",2 Related Work,[0],[0]
"Still, moderators and users do not feel comfortable with machines deciding which comments are allowed to be published – not least because of fear of concealed censorship or bias.",2 Related Work,[0],[0]
"For each news article, we want to predict whether it belongs to the weekly top 10% articles with the highest comment volume.",3 Predicting High Comment Volume,[0],[0]
We chose this relative amount to account for seasonal fluctuations and also to even out periods with low news worthiness.,3 Predicting High Comment Volume,[0],[0]
"This traditional classification setting enables us to use established methods, such as logistic regression, to solve the task and provide explanations on why a particular article will receive many comments or not.
",3 Predicting High Comment Volume,[0],[0]
"As a baseline to compare against, we implemented a random forest model with features from
Tsagkias et al. (2009).",3 Predicting High Comment Volume,[0],[0]
For our approach we extend this feature set and categorize the features into five groups.,3 Predicting High Comment Volume,[0],[0]
"Our metadata features consist of article publication time, day of the week, and whether the article is promoted on our Facebook page.",3 Predicting High Comment Volume,[0],[0]
We consider temperature and humidity during the hour of publication1 and the number of “competing articles” as context features.,3 Predicting High Comment Volume,[0],[0]
Competing articles is the number of similar articles and the total number of articles published by our newspaper in the same hour.,3 Predicting High Comment Volume,[0],[0]
These articles compete for readers and user comments.,3 Predicting High Comment Volume,[0],[0]
Figure 2 visualizes how the number of received comments is not affected by the significantly higher number of published articles on Thursdays.,3 Predicting High Comment Volume,[0],[0]
The publication peek on Thursdays is caused by articles that are published in our weekly printed edition and at the same time published online one-to-one.,3 Predicting High Comment Volume,[0],[0]
"Further, we incorporate publisher information, such as genre, department, and which news agency served as a source for the article.",3 Predicting High Comment Volume,[0],[0]
"We include these features in order to study their impact and performance at comment volume prediction tasks and not in order to focus on engineering complex features.
",3 Predicting High Comment Volume,[0],[0]
"In addition, we propose to leverage the article content itself.",3 Predicting High Comment Volume,[0],[0]
"Starting with headline features, we use ngrams of length one to three as well as author provided keywords for the article.",3 Predicting High Comment Volume,[0],[0]
"To capture topical information in the body, we rely on topic modeling and document embedding besides traditional bag-of-word (BOW) features.",3 Predicting High Comment Volume,[0],[0]
These guarantee that we also grasp some semantic representations of the articles.,3 Predicting High Comment Volume,[0],[0]
"To this end, topic distributions, document embeddings, and word n-grams serve as semantic representa-
1as obtained for three large German cities, Berlin, Hamburg, and Frankfurt from http://www.dwd.de/
tions of articles.",3 Predicting High Comment Volume,[0],[0]
"In order to model topics of news article bodies, we apply standard latent Dirichlet allocation (Blei et al., 2003).",3 Predicting High Comment Volume,[0],[0]
"For the document embedding, we use a Doc2Vec implementation that downsamples higher-frequency words for the composition (Mikolov et al., 2013).",3 Predicting High Comment Volume,[0],[0]
"We choose the vector length, number of topics, and window size based on F1-score evaluation on a validation set.
",3 Predicting High Comment Volume,[0],[0]
"Despite recent advances of deep neural networks for natural language processing, there is a reason to focus on other models: For the application in newsrooms and the integration in semiautomatic processes, comprehensibility of the prediction results is very important.",3 Predicting High Comment Volume,[0],[0]
A black-box model — even if it achieved better performance — is not helpful in this scenario.,3 Predicting High Comment Volume,[0],[0]
Human moderators need to understand why the number of comments is predicted to be high or low.,3 Predicting High Comment Volume,[0],[0]
"This comprehensibility issue justifies the application of decision trees and regression models, which allow to trace back predictions to their decisive factors.",3 Predicting High Comment Volume,[0],[0]
"Table 1 lists precision, recall, and F1-score for the prediction of weekly top 10% articles with the highest comment volume.",3 Predicting High Comment Volume,[0],[0]
"Especially the bag-of-words (BOW) and the topics of the article body, but also headline keywords and publisher metadata achieve
higher F1-score than the metadata features.",3 Predicting High Comment Volume,[0],[0]
"The highest precision is achieved with the binary feature whether an article is promoted on Facebook, whereas author and competing articles achieve the highest recall.",3 Predicting High Comment Volume,[0],[0]
Whether the first comment is a provocative question in disagreement with the article or an offtopic statement influences the route of further conversation.,3.1 Automatic Translation of Comments,[0],[0]
"We assume that this assumption holds not only for social networks (Berry and Taylor, 2017), but also for comment sections at news websites.",3.1 Automatic Translation of Comments,[0],[0]
"Therefore, we consider the tone and sentiment of the first comments received shortly after article publication as an additional feature.",3.1 Automatic Translation of Comments,[0],[0]
Typical layouts of news websites (including ours) list comments in chronological order and show only the first few comments to readers below an article.,3.1 Automatic Translation of Comments,[0],[0]
Pagination hides later received comments and most users do not click through dozens of pages to read through all comments.,3.1 Automatic Translation of Comments,[0],[0]
"As a consequence, early comments attract a lot more attention and, with their tone and sentiment, influence comment volume to a larger extent.",3.1 Automatic Translation of Comments,[0],[0]
"Presumably, articles that receive controversial comments in the first few minutes after publication are more likely to receive a high number of comments in total.
",3.1 Automatic Translation of Comments,[0],[0]
"To classify comments as controversial or engaging, we need to train a supervised classification algorithm, which takes thousands of annotated comments.",3.1 Automatic Translation of Comments,[0],[0]
"Such training corpora exist, if at all, mostly for English comments, while our comments are written in German.",3.1 Automatic Translation of Comments,[0],[0]
We propose to apply machine translation to overcome this language barrier:,3.1 Automatic Translation of Comments,[0],[0]
"Given a German comment, we automatically translate it into English.",3.1 Automatic Translation of Comments,[0],[0]
"From a classifier that has been trained on an annotated English dataset, we can derive automatic annotations for the translated comment.",3.1 Automatic Translation of Comments,[0],[0]
"The derived annotations serve as another feature for our actual task of comment volume prediction.
",3.1 Automatic Translation of Comments,[0],[0]
We reimplemented the classifier by Napoles et al. (2017a) and train on their English dataset.,3.1 Automatic Translation of Comments,[0],[0]
"The considered annotations consist of 12 binary labels: addressed audience (reply to a particular user or broadcast message to a general audience), agreement/disagreement with previous comment, informative, mean, controversial, persuasive, off-topic regarding the corresponding news article, neutral, positive, negative, and mixed sentiment.",3.1 Automatic Translation of Comments,[0],[0]
"We au-
tomatically translate all comments in our German dataset into English using the DeepL translation service2.",3.1 Automatic Translation of Comments,[0],[0]
"For the translated comments, we automatically generate annotations based on Napoles et al.’s classifier.",3.1 Automatic Translation of Comments,[0],[0]
"Thereby, we transfer the knowledge that the classifier learned on English training data to our German dataset despite its different language.",3.1 Automatic Translation of Comments,[0],[0]
"This approach builds on the similar content style of both corpora, which is described in the next section.",3.1 Automatic Translation of Comments,[0],[0]
We consider two datasets that both contain user comments received by news articles with similar topics.,4 Dataset,[0],[0]
"First, our German 7-million-comment dataset, which we call Zeit Online Comment Corpus (ZOCC)3 and second, the English 10kcomment Yahoo News Annotated Comments Corpus (YNACC) (Napoles et al., 2017b).",4 Dataset,[0],[0]
"ZOCC consists of roughly 200,000 online news articles published between 2008 and 2017 and 7 million associated user comments in German.",4 Dataset,[0],[0]
"Out of 174,699 users in total, 60% posted more than one comment, 23% more than 10 comments and 7% more than 100 comments.",4 Dataset,[0],[0]
"For both, articles and comments, extensive metadata is available, such as author list, department, publication date, and tags (for articles) and user name, parent comment (if posted in response), and number of recommendations by other users (for comments).",4 Dataset,[0],[0]
"Not surprisingly, ZOCC is following a popularity growth with an increasing number of articles and comments over time.",4 Dataset,[0],[0]
"While our newspaper published roughly 1,300 articles per month in 2010 and each article received roughly 20 comments on average, we nowadays publish roughly 1,500 articles per month, each receiving 110 comments on average.",4 Dataset,[0],[0]
"As both corpora’s articles and comments cover a similar time span of several years and many different departments, they deal with a broad range of topics.",4 Dataset,[0],[0]
"While the majority of articles in YNACC is
2https://deepl.com 3http://www.zeit.de/
about economy, ZOCC’s major department is politics.",4 Dataset,[0],[0]
"More than 50% of the comments in ZOCC are posted in response to articles in the politics department, whereas in YNACC culture, society, and economy share an almost equal amount of around 20% each and politics on forth rank with 12%.",4 Dataset,[0],[0]
"On average, an article in ZOCC receives 90% of its comments within 48 hours, while it takes 61 hours for an article in YNACC.",4 Dataset,[0],[0]
"Despite their slight differences, both corpora cover most popular departments, which motivates the idea to transfer a classifier trained on YNACC to ZOCC.",4 Dataset,[0],[0]
"For YNACC, Napoles et al. propose a machine learning approach to automatically identify engaging, respectful, and informative conversations (2017a).",4 Dataset,[0],[0]
"By identifying weekly top 10% articles with the highest comment volume, we focus on a different task.",4 Dataset,[0],[0]
"Nonetheless, both corpora, ZOCC and YNACC, have similar properties: both corpora contain user comments posted in reaction to news articles across similar time span and similar topics.",4 Dataset,[0],[0]
"However, only the much smaller YNACC provides detailed annotations regarding, for example, comments’ tone and sentiment.",4 Dataset,[0],[0]
"We compare to the approach by Tsagkias et al. and evaluate on the same task (Tsagkias et al., 2009, 2010).",5 Evaluation,[0],[0]
"Therefore, we consider a binary classification task, which is to identify the weekly top 10% articles with the largest comment volume.",5 Evaluation,[0],[0]
Table 3 lists our final evaluation results on the hold-out test set.,5 Evaluation,[0],[0]
"We choose F1-score as our evaluation metric, since precision and recall are equally relevant in our scenario.",5 Evaluation,[0],[0]
"On the one hand, we want to achieve high recall so that no important article and its discussion is overlooked.",5 Evaluation,[0],[0]
"On the other hand, we have limited resources and cannot afford to moderate each and every discussion.",5 Evaluation,[0],[0]
A high precision is crucial so that our moderators focus only on articles that need their attention.,5 Evaluation,[0],[0]
"All experiments are conducted using time-wise split with years 2014 to 2016 for training, January 2017 to March 2017 for validation, and April 2017 for testing.",5 Evaluation,[0],[0]
"We find that our additional article and metadata features, but also the automatically annotated first comments outperform the baseline.",5 Evaluation,[0],[0]
"Due to the diversity of the different features, their combination further improves the prediction results.",5 Evaluation,[0],[0]
"In comparison to the approach by Tsagkias et al., we finally achieve an 81% larger F1-score.",5 Evaluation,[0],[0]
"With another experiment, we study the classification error introduced by translation.",5.1 Automatically Translated Comments,[0],[0]
"Therefore, we train two classifiers with the approach by Napoles et al.:",5.1 Automatically Translated Comments,[0],[0]
"First, we train and test a classifier on the original, English YNACC.",5.1 Automatically Translated Comments,[0],[0]
"Second, we automatically translate all comments in YNACC from English into German and use this translated data for training and testing of the second classifier.",5.1 Automatically Translated Comments,[0],[0]
"Comparing these two classifiers, we find that both precision and recall slightly decrease after translation, as shown in Table 4.",5.1 Automatically Translated Comments,[0],[0]
"Based on this result, we can assume that the translation of German comments into English introduces only a small error.",5.1 Automatically Translated Comments,[0],[0]
"Although YNACC and ZOCC differ in language, we can transfer a classifier that has been trained on YNACC to ZOCC.",5.1 Automatically Translated Comments,[0],[0]
"For each article, we use the labels assigned to the first four comments, which are visible on the first comment page below an article.",5.1 Automatically Translated Comments,[0],[0]
The first four comments are typically received within very few minutes after article publication.,5.1 Automatically Translated Comments,[0],[0]
"As a baseline feature for comparison, we use the number of comments4 received in a short time span after article publication.",5.2 Number of Early Comments,[0],[0]
"Annotated first page comments, but also article and metadata features significantly outperform the baseline until 32 minutes after article publication.",5.2 Number of Early Comments,[0],[0]
"After 32 minutes, the number of received comments outperforms every single feature (but not the combination of all our features).",5.2 Number of Early Comments,[0],[0]
This is because the difference between final number of comments and so far received comments converges over time.,5.2 Number of Early Comments,[0],[0]
"In this paper, we studied the task of predicting the weekly top 10% articles with the highest comment volume.",6 Conclusions,[0],[0]
This prediction helps to schedule the publication of news stories and supports moderation teams in focusing on article discussions that require most likely their attention.,6 Conclusions,[0],[0]
"Our supervised classification approach is based on a combination of metadata and content-based features, such as article body and topics.",6 Conclusions,[0],[0]
"Further, we automatically translate German comments into English to make use of a classifier pre-trained on English data: We classify the tone and sentiment of comments received in the first minutes after article publication, which improves prediction even further.",6 Conclusions,[0],[0]
On a 7-million-comment real-world dataset our approach outperforms the current state-of-theart by over 81% larger F1-score.,6 Conclusions,[0],[0]
"We hope that our prediction will help to reduce the number of cases where newspapers have no other choice but to close down a discussion section because of limited moderation resources.
",6 Conclusions,[0],[0]
"4To allow for non-linear correlations, we pass the number of comments as an absolute count and a squared count.",6 Conclusions,[0],[0]
The overwhelming success of the Web and mobile technologies has enabled millions to share their opinions publicly at any time.,abstractText,[0],[0]
But the same success also endangers this freedom of speech due to closing down of participatory sites misused by individuals or interest groups.,abstractText,[0],[0]
We propose to support manual moderation by proactively drawing the attention of our moderators to article discussions that most likely need their intervention.,abstractText,[0],[0]
"To this end, we predict which articles will receive a high number of comments.",abstractText,[0],[0]
"In contrast to existing work, we enrich the article with metadata, extract semantic and linguistic features, and exploit annotated data from a foreign language corpus.",abstractText,[0],[0]
Our logistic regression model improves F1-scores by over 80% in comparison to state-of-the-art approaches.,abstractText,[0],[0]
"1 Exploding Comment Threads In the last decades, media and news business underwent a fundamental shift, from one-directional to bi-directional communication between users on the one side and journalists on the other.",abstractText,[0],[0]
"The use of social media, blogs, and the possibility to immediately share, like, and comment digital content transformed readers into active and powerful agents in the media business.",abstractText,[0],[0]
This shift from passive “consumers” to active “agents” deeply impacts both media and communication science and has many positive aspects.,abstractText,[0],[0]
"However, the possibilities and powers can also be misused.",abstractText,[0],[0]
"Pressure groups, lobbyists, trolls, and others are effectively trying to influence discussions according to their (very different) interests.",abstractText,[0],[0]
An easy approach consists in burying unwanted arguments or simply destroying a discussion by blowing it up.,abstractText,[0],[0]
"After such an attack, readers have to crawl through hundreds of nonsense and meaningless comments to extract meaningful and interesting arguments.",abstractText,[0],[0]
Blowing up a thread can be 1.,abstractText,[0],[0]
Prediction for the Newsroom: Which Articles Will Get the Most Comments?,title,[0],[0]
Shape constraints like monotonicity and convexity arise naturally in many real-world regression and classification tasks.,1. Introduction,[0],[0]
"For example, holding all other variables fixed, a practitioner might assume that the price of a house is a decreasing function of neighborhood crime rate, that an individual’s utility function is concave in income level, or that phenotypes such as height or the likelihood of contracting a disease are monotonic in certain genetic effects.
",1. Introduction,[0],[0]
Parametric models like linear regression implicity impose monotonicity constraints at the cost of strong assumptions on the true underlying function.,1. Introduction,[0],[0]
"On the other hand, nonparametric techniques like kernel regression impose weak assumptions, but do not guarantee monotonicity or convexity in their predictions.",1. Introduction,[0],[0]
"Shape-constrained nonparametric regression methods attempt to offer the best of both worlds, allowing practitioners to dispense with parametric assumptions while retaining many of their appealing properties.
",1. Introduction,[0],[0]
"However, classical approaches to nonparametric regression under shape constraints suffer from the curse of dimensionality (Han & Wellner, 2016; Han et al., 2017).",1. Introduction,[0],[0]
"Some methods have been developed to mitigate this issue under assumptions like additivity, where the true function f is assumed to have the form f(x) = ∑ j fj(xj) + c, where a subset of the component fj’s are shapeconstrained (Chen & Samworth, 2016; Pya & Wood, 2015; Xu et al., 2016).",1. Introduction,[0],[0]
"But in many real-world settings, the lack of interaction terms among the predictors can be too restrictive.
",1. Introduction,[0],[0]
"Approaches from the machine learning community like random forests, gradient boosted trees, and deep learning methods have been shown to exhibit outstanding empirical performance on highdimensional tasks.",1. Introduction,[0],[0]
"But these methods do not guarantee monotonicity or convexity.
∗Department of Statistics, The University of Chicago †Department of Statistics, University of Illinois at Urbana-Champaign ‡Department of Statistics and Data Science, Yale University
ar X
iv :1
80 5.
",1. Introduction,[0],[0]
"06 43
9v 1
[ st
at .M
L ]
1 6
M ay
2 01
8
In this paper, we propose two methods for high-dimensional shape-constrained regression and classification.",1. Introduction,[0],[0]
"These methods blend the performance of machine learning methods with the classical least-squares approach to nonparametric shape-constrained regression.
",1. Introduction,[0],[0]
"In Section (2.1), we describe black box reshaping, which takes any pre-trained prediction rule and reshapes it on a set of test inputs to enforce shape constraints.",1. Introduction,[0],[0]
"In the case of monotonicity constraints, we develop an efficient algorithm to compute the estimator.",1. Introduction,[0],[0]
"Section (2.2) presents a second method designed specifically to reshape random forests (Breiman, 2001).",1. Introduction,[0],[0]
This approach reshapes each individual decision tree based on its split rules and estimated leaf values.,1. Introduction,[0],[0]
"Again, in the case of monotonicity constraints, we present another efficient reshaping algorithm.",1. Introduction,[0],[0]
We apply our methods to four datasets in Section (3) and show that they enforce the pre-specified shape constraints without sacrificing accuracy.,1. Introduction,[0],[0]
"In the context of monotonicity constraints, the black box reshaping method is related to the method of rearrangements (Chernozhukov et al., 2009, 2010).",1.1. Related Work,[0],[0]
The rearrangement operation takes a pretrained prediction rule and sorts its predictions to enforce monotonicity.,1.1. Related Work,[0],[0]
"In higher dimensions, the rearranged estimator is the average of one-dimensional rearrangements.",1.1. Related Work,[0],[0]
"In contrast, this paper focuses on isotonization of prediction values, jointly reshaping multiple dimensions in tandem.",1.1. Related Work,[0],[0]
"It would be interesting to explore adaptive procedures that average rearranged and isotonized predictions in future work.
",1.1. Related Work,[0],[0]
Monotonic decision trees have previously been studied in the context of classification.,1.1. Related Work,[0],[0]
"Several methods require that the training data satisfy monotonicity constraints (Makino et al., 1996; Potharst & Feelders, 2002), a relatively strong assumption in the presence of noise.",1.1. Related Work,[0],[0]
"The methods we propose here do not place any restrictions on the training data.
",1.1. Related Work,[0],[0]
"Another class of methods augment the score function for each split to incorporate the degree of non-monotonicity introduced by that split (Ben-David, 1995; González et al., 2015).",1.1. Related Work,[0],[0]
"However, this approach does not guarantee monotonicity.",1.1. Related Work,[0],[0]
Feelders & Pardoel (2003) apply pruning algorithms to non-monotonic trees as a post-processing step in order to enforce monotonicity.,1.1. Related Work,[0],[0]
"For a comprehensive survey of estimating monotonic functions, see Gupta et al. (2016) .
",1.1. Related Work,[0],[0]
"A line of recent work has led to a method for learning deep monotonic models by alternating different types of monotone layers (You et al., 2017).",1.1. Related Work,[0],[0]
"Amos et al. (2017) propose a method for fitting neural networks whose predictions are convex with respect to a subset of predictors.
",1.1. Related Work,[0],[0]
Our methods differ from this work in several ways.,1.1. Related Work,[0],[0]
"First, our techniques can be used to enforce both monotonic and convex/concave relationships.",1.1. Related Work,[0],[0]
"Unlike pruning methods, neither approach presented here changes the structure of the original tree.",1.1. Related Work,[0],[0]
"Black box reshaping, described in Section (2.1), can be applied to any pre-trained prediction rule, giving practitioners the flexibility of picking the method of their choice.",1.1. Related Work,[0],[0]
And both methods guarantee that the intended shape constraints are satisfied on test data.,1.1. Related Work,[0],[0]
"In what follows, we say that a function f : Rd → R is monotone with respect to variables R ⊆",2. Prediction Rule Reshaping,[0],[0]
"[d] = {1, . . .",2. Prediction Rule Reshaping,[0],[0]
", d} if f(x) ≤ f(y) when xi ≤ yi for i ∈ R, and xi = yi otherwise.
",2. Prediction Rule Reshaping,[0],[0]
"Similarly, a function f is convex in R if for all x, y ∈ Rd and α ∈",2. Prediction Rule Reshaping,[0],[0]
"[0, 1], f(αx + (1 − α)y) ≤ αf(x) + (1− α)f(y) when xi = yi ∀i /∈",2. Prediction Rule Reshaping,[0],[0]
R.,2. Prediction Rule Reshaping,[0],[0]
Let f̂ : Rd → R denote an arbitrary prediction rule fit on a training set and assume we have a candidate set of shape constraints with respect to variablesR ⊆,2.1. Black Box Reshaping,[0],[0]
[d].,2.1. Black Box Reshaping,[0],[0]
"For example, we might require that the function be monotone increasing in each variable v ∈ R.
Let F denote the class of functions that satisfy the desired shape constraints on each predictor variable v ∈ R.",2.1. Black Box Reshaping,[0],[0]
"We aim to find a function f ∗ ∈ F that is close to f̂ in the L2 norm:
f ∗ = arg min f∈F ‖f",2.1. Black Box Reshaping,[0],[0]
"− f̂‖2 (2.1)
where the L2 norm is with respect to the uniform measure on a compact set containing the data.",2.1. Black Box Reshaping,[0],[0]
"We simplify this infinite-dimensional problem by only considering values of f̂ on certain fixed test points.
",2.1. Black Box Reshaping,[0],[0]
"Suppose we take a sequence t1, t2, . . .",2.1. Black Box Reshaping,[0],[0]
", tn of test points, each in Rd, that differ only in their v-th coordinate so that tik = t i′
k for all k 6=",2.1. Black Box Reshaping,[0],[0]
"v. These points can be ordered by their v-th coordinate, allowing us to consider shape constraints on the vector (f(t1), f(t2), ..., f(tn)) ∈",2.1. Black Box Reshaping,[0],[0]
Rn.,2.1. Black Box Reshaping,[0],[0]
"For instance, under a monotone-increasing constraint with respect to v, if t1v ≤ t2v ≤ · · · ≤ tnv , then we consider functions f such that (f(t1), f(t2), ..., f(tn)) is a monotone sequence.
",2.1. Black Box Reshaping,[0],[0]
"There is now the question of choosing a test point t as well as a sequence of values t1v, ..., t n v to plug into its v-th coordinate.",2.1. Black Box Reshaping,[0],[0]
"A natural choice is to use the observed data values as both test points and coordinate values.
",2.1. Black Box Reshaping,[0],[0]
"Denote Dn = {(x1, y1), . . .",2.1. Black Box Reshaping,[0],[0]
", (xn, yn)} as a set of observed values where yi is the response and xi ∈ Rd are the predictors.",2.1. Black Box Reshaping,[0],[0]
"From each xi, we construct a sequence of test points that can be ordered according to their v-th coordinate in the following way.",2.1. Black Box Reshaping,[0],[0]
"Let xi,k,v denote the observed vector xi with its v-th coordinate replaced by the v-th coordinate of xk, so that
xi,k,v = (xi1, x i 2, . . .",2.1. Black Box Reshaping,[0],[0]
", x i v−1, x k v , x i v+1, . . .",2.1. Black Box Reshaping,[0],[0]
", x i d).",2.1. Black Box Reshaping,[0],[0]
"(2.2)
",2.1. Black Box Reshaping,[0],[0]
"This process yields n points from xi that can be ordered by their v-th coordinate, xi,1,v, xi,2,v, . . .",2.1. Black Box Reshaping,[0],[0]
", xi,n,v. We then require (f(xi,1,v), f(xi,2,v), . . .",2.1. Black Box Reshaping,[0],[0]
", f(xi,n,v)) ∈",2.1. Black Box Reshaping,[0],[0]
"Sv where Sv ⊂ Rd is the appropriate convex cone that enforces the shape constraint for variable v ∈ R, for example the cone of monotone increasing or convex sequences.
",2.1. Black Box Reshaping,[0],[0]
"To summarize, for each coordinate v ∈ R and for each i ∈",2.1. Black Box Reshaping,[0],[0]
"[n], we:
1.",2.1. Black Box Reshaping,[0],[0]
Take the i-th observed data point xi as a test point.,2.1. Black Box Reshaping,[0],[0]
"2. Replace its v-th coordinate with the n observed v-th coordinates x1v, ...x n",2.1. Black Box Reshaping,[0],[0]
"v to produce
xi,1,v, xi,2,v, . . .",2.1. Black Box Reshaping,[0],[0]
", xi,n,v. 3.",2.1. Black Box Reshaping,[0],[0]
"Enforce the appropriate shape constraint on the vector of evaluated function values,
(f(xi,1,v), f(xi,2,v), . . .",2.1. Black Box Reshaping,[0],[0]
", f(xi,n,v)) ∈",2.1. Black Box Reshaping,[0],[0]
"Sv.
",2.1. Black Box Reshaping,[0],[0]
See Figure (1) for an illustration.,2.1. Black Box Reshaping,[0],[0]
"This leads to the following relaxation of (2.1):
f ∗ = arg min f∈Fn ‖f − f̂‖2 (2.3)
where Fn is the class of functions f such that (f(xi,1,v), f(xi,2,v), . . .",2.1. Black Box Reshaping,[0],[0]
", f(xi,n,v))",2.1. Black Box Reshaping,[0],[0]
∈,2.1. Black Box Reshaping,[0],[0]
Sv ⊂,2.1. Black Box Reshaping,[0],[0]
Rn for each v ∈ R and each,2.1. Black Box Reshaping,[0],[0]
i ∈,2.1. Black Box Reshaping,[0],[0]
[n].,2.1. Black Box Reshaping,[0],[0]
"In other words, we have relaxed the shape constraints on the function f , requiring the constraints to hold relative to the selected test points.",2.1. Black Box Reshaping,[0],[0]
"However, this optimization is still infinite dimensional.
",2.1. Black Box Reshaping,[0],[0]
We make the final transition to finite dimensions by changing the objective function to only consider values of f on the test points.,2.1. Black Box Reshaping,[0],[0]
"Letting Fi,k,v denote the value of f evaluated on test point xi,k,v, we relax (2.3) to obtain the solution F ∗ =",2.1. Black Box Reshaping,[0],[0]
"(F ∗i,k,v)v∈R,i∈[n],k∈[n] of the optimization:
arg min F
∑ i,k,v (Fi,k,v − f̂(xi,k,v))2
subject to (Fi,1,v, ..., Fi,n,v) ∈ (Sv)v∈R, ∀",2.1. Black Box Reshaping,[0],[0]
i ∈,2.1. Black Box Reshaping,[0],[0]
"[n] (2.4)
However, this leads to ill-defined predictions on the original data points x1, ..., xn, since for each
v, xi,i,v = xi, but we may obtain different values F ∗i,i,v for various v ∈ R.
We avoid this issue by adding a consistency constraint (2.7) to obtain our final black box reshaping optimization (BBOPT):
arg min F
∑ i,k,v (Fi,k,v − f̂(xi,k,v))2 (2.5)
subject to (Fi,1,v, ..., Fi,n,v) ∈",2.1. Black Box Reshaping,[0],[0]
"(Sv)v∈R, ∀",2.1. Black Box Reshaping,[0],[0]
i ∈,2.1. Black Box Reshaping,[0],[0]
"[n] (2.6) and Fi,i,v = Fi,i,w ∀ v, w ∈",2.1. Black Box Reshaping,[0],[0]
"R,∀",2.1. Black Box Reshaping,[0],[0]
i ∈,2.1. Black Box Reshaping,[0],[0]
"[n] (2.7)
We then take the reshaped predictions to be
f ∗(xi)",2.1. Black Box Reshaping,[0],[0]
"= F ∗i,i,v
for any v ∈ R.",2.1. Black Box Reshaping,[0],[0]
"Since the constraints depend on each xi independently, BBOPT decomposes into n optimization problems, one for each observed value.",2.1. Black Box Reshaping,[0],[0]
Note that the true response values yi are not used when reshaping.,2.1. Black Box Reshaping,[0],[0]
We could select optimal shape constraints on a held-out test set.,2.1. Black Box Reshaping,[0],[0]
"In this section, we present an efficient algorithm for solving BBOPT for the case when each Sv imposes monotonicity constraints.",2.1.1. Intersecting Isotonic Regression,[0],[0]
"Let R = |R| denote the number of monotonicity constraints.
",2.1.1. Intersecting Isotonic Regression,[0],[0]
"When reshaping with respect to only one predictor (R = 1), the consistency constraints (2.7) vanish, so the optimization decomposes into n isotonic regression problems.",2.1.1. Intersecting Isotonic Regression,[0],[0]
Each problem is efficiently solved in Θ(n) time with the pool adjacent violators algorithm (PAVA),2.1.1. Intersecting Isotonic Regression,[0],[0]
"(Ayer et al., 1955).
",2.1.1. Intersecting Isotonic Regression,[0],[0]
"For R > 1 monotonicity constraints, BBOPT gives rise to n independent intersecting isotonic regression problems.",2.1.1. Intersecting Isotonic Regression,[0],[0]
"The k-th problem corresponds to the k-th observed value xk; the “intersection"" is implied by the consistency constraints (2.7).",2.1.1. Intersecting Isotonic Regression,[0],[0]
"For each independent problem, our algorithm takes O(m logR) time, where m = n×R is the number of variables in each problem.
",2.1.1. Intersecting Isotonic Regression,[0],[0]
We first state the general problem.,2.1.1. Intersecting Isotonic Regression,[0],[0]
"Assume v1, v2, . . .",2.1.1. Intersecting Isotonic Regression,[0],[0]
", vK are each real-valued vectors with dimensions d1, d2, . . .",2.1.1. Intersecting Isotonic Regression,[0],[0]
", dK , respectively.",2.1.1. Intersecting Isotonic Regression,[0],[0]
Let ij ∈,2.1.1. Intersecting Isotonic Regression,[0],[0]
"{1, . . .",2.1.1. Intersecting Isotonic Regression,[0],[0]
", dj} denote an index in the j-th vector vj .",2.1.1. Intersecting Isotonic Regression,[0],[0]
"The intersecting isotonic regression problem (IISO) is:
minimize (v̂k)Kk=1 K∑ k=1 ‖v̂k",2.1.1. Intersecting Isotonic Regression,[0],[0]
− vk‖2 subject to v̂k1 ≤ v̂k2 ≤ · · ·,2.1.1. Intersecting Isotonic Regression,[0],[0]
"≤ v̂kdk , ∀ k ∈",2.1.1. Intersecting Isotonic Regression,[0],[0]
"[K] and v̂1i1 = v̂ 2 i2 = · · · = v̂KiK
(2.8)
",2.1.1. Intersecting Isotonic Regression,[0],[0]
First consider the simpler constrained isotonic regression problem with a single sequence v ∈,2.1.1. Intersecting Isotonic Regression,[0],[0]
"Rd,
Algorithm 1 IISO Algorithm 1.",2.1.1. Intersecting Isotonic Regression,[0],[0]
Apply PAVA to each of the 2K tails.,2.1.1. Intersecting Isotonic Regression,[0],[0]
2.,2.1.1. Intersecting Isotonic Regression,[0],[0]
Combine and sort the left and right tails separately.,2.1.1. Intersecting Isotonic Regression,[0],[0]
3.,2.1.1. Intersecting Isotonic Regression,[0],[0]
Find segment s∗ in between tail values where the derivative g′(η) changes sign.,2.1.1. Intersecting Isotonic Regression,[0],[0]
4.,2.1.1. Intersecting Isotonic Regression,[0],[0]
"Compute c∗, the minimizer of g(c) in segment s∗.
index",2.1.1. Intersecting Isotonic Regression,[0],[0]
i ∈,2.1.1. Intersecting Isotonic Regression,[0],[0]
"[d], and fixed value c ∈ R
minimize v̂ ‖v̂ − v‖2 subject to v̂1 ≤",2.1.1. Intersecting Isotonic Regression,[0],[0]
"v̂2 ≤ · · · ≤ v̂d and v̂i = c
(2.9)
",2.1.1. Intersecting Isotonic Regression,[0],[0]
Lemma 2.1.,2.1.1. Intersecting Isotonic Regression,[0],[0]
"The solution v∗ to (2.9) can be computed by using index i as a pivot and splitting v into its left and right tails, so that ` = (v1, v2, . . .",2.1.1. Intersecting Isotonic Regression,[0],[0]
", vi−1) and r = (vi+1, . . .",2.1.1. Intersecting Isotonic Regression,[0],[0]
", vd), then applying PAVA to obtain monotone tails ̂̀and",2.1.1. Intersecting Isotonic Regression,[0],[0]
"r̂. v∗ is obtained by setting elements of ̂̀and r̂ to
`∗k = min(̂̀k, c) r∗k",2.1.1. Intersecting Isotonic Regression,[0],[0]
"= max(r̂k, c)
(2.10)
and concatenating the resulting tails so that v∗ = (`∗, c, r∗) ∈ Rd.
",2.1.1. Intersecting Isotonic Regression,[0],[0]
We now explain the IISO Algorithm presented in Algorithm (1).,2.1.1. Intersecting Isotonic Regression,[0],[0]
"First divide each vector vj into two tails, the left tail `j and the right tail rj , using the intersection index ij as a pivot,
vj = (vj1, v j 2, . . .",2.1.1. Intersecting Isotonic Regression,[0],[0]
", v j (ij−1)︸ ︷︷ ︸
`j
, vjij , v j (ij+1) , vj(ij+2), . . .",2.1.1. Intersecting Isotonic Regression,[0],[0]
", v j dj︸ ︷︷ ︸
rj
).
resulting in 2K tails {`1, . . .",2.1.1. Intersecting Isotonic Regression,[0],[0]
", `K , r1, . . .",2.1.1. Intersecting Isotonic Regression,[0],[0]
", rK}.
",2.1.1. Intersecting Isotonic Regression,[0],[0]
"Step 1 of Algorithm (1) performs an unconstrained isotonic regression on each tail using PAVA to obtain 2K monotone tails {̂̀1, . . .",2.1.1. Intersecting Isotonic Regression,[0],[0]
", ̂̀K , r̂1, . . .",2.1.1. Intersecting Isotonic Regression,[0],[0]
", r̂K}.",2.1.1. Intersecting Isotonic Regression,[0],[0]
"This can be done in Θ(n) time, where n is the total number of elements across all vectors so that n = ∑K i=1",2.1.1. Intersecting Isotonic Regression,[0],[0]
"di.
",2.1.1. Intersecting Isotonic Regression,[0],[0]
"Given the monotone tails, we can write a closed-form expression for the IISO objective function in terms of the value at the point of intersection.
",2.1.1. Intersecting Isotonic Regression,[0],[0]
Let c be the value of the vectors at the point of intersection so that c = v̂1i1 = v̂ 2 i2 = · · ·,2.1.1. Intersecting Isotonic Regression,[0],[0]
= v̂KiK .,2.1.1. Intersecting Isotonic Regression,[0],[0]
"For a fixed c, we can solve IISO by applying Lemma (2.1) to each sequence separately.",2.1.1. Intersecting Isotonic Regression,[0],[0]
"This yields the following expression for the squared error as a function of c:
g(c) = K∑ k=1 (c− vkik) 2 + K∑ k=1 ik−1∑ i=1",2.1.1. Intersecting Isotonic Regression,[0],[0]
"(`ki −min(̂̀ki , c))2 + K∑ l=1 dl∑ j=il+1 (rlj −max(r̂lj, c))2 (2.11)
which is piecewise quadratic with knots at each ̂̀ki and r̂lj .",2.1.1. Intersecting Isotonic Regression,[0],[0]
Our goal is to find c? = minc g(c).,2.1.1. Intersecting Isotonic Regression,[0],[0]
"Note that g(c) is convex and differentiable.
",2.1.1. Intersecting Isotonic Regression,[0],[0]
"We proceed by computing the derivative of g at each knot, from smallest to largest, and finding the segment in which the sign of the derivative changes from negative to positive.",2.1.1. Intersecting Isotonic Regression,[0],[0]
"The minimizer c∗ will live in this segment.
",2.1.1. Intersecting Isotonic Regression,[0],[0]
Step 2 of Algorithm (1) merges the left and right sorted tails into two sorted lists.,2.1.1. Intersecting Isotonic Regression,[0],[0]
This can be done in O(n logK) time with a heap data structure.,2.1.1. Intersecting Isotonic Regression,[0],[0]
"Step 3 computes the derivative of the objective function g at each knot, from smallest to largest, searching for the segment in which the derivative changes sign.",2.1.1. Intersecting Isotonic Regression,[0],[0]
Step 4 computes the minimizer of g in the corresponding segment.,2.1.1. Intersecting Isotonic Regression,[0],[0]
"By updating the derivative incrementally and storing relevant side information, Steps 3 and 4 can be done in linear time.
",2.1.1. Intersecting Isotonic Regression,[0],[0]
The total time complexity is therefore O(n log(K)).,2.1.1. Intersecting Isotonic Regression,[0],[0]
"In this section, we describe a framework for reshaping a random forest to ensure monotonicity of its predictions in a subset of its predictor variables.",2.2. Reshaping Random Forests,[0],[0]
A similar method can be applied to ensure convexity.,2.2. Reshaping Random Forests,[0],[0]
"For both regression and probability trees (Malley et al., 2012), the prediction of the forest is an average of the prediction of each tree; it is therefore sufficient to ensure monotonicity or convexity of the trees.",2.2. Reshaping Random Forests,[0],[0]
"For the rest of this section, we focus on reshaping individual trees to enforce monotonicity.
",2.2. Reshaping Random Forests,[0],[0]
Our method is a two-step procedure.,2.2. Reshaping Random Forests,[0],[0]
The first step is to grow a tree in the usual way.,2.2. Reshaping Random Forests,[0],[0]
The second step is to reshape the leaf values to enforce monotonicity.,2.2. Reshaping Random Forests,[0],[0]
"We hope to explore the implications of combining these steps in future work.
",2.2. Reshaping Random Forests,[0],[0]
Let T (x) be a regression tree and R ⊆,2.2. Reshaping Random Forests,[0],[0]
[d] a set of predictor variables to be reshaped.,2.2. Reshaping Random Forests,[0],[0]
Let x ∈ Rd be an input point and denote the k-th coordinate of x as xk.,2.2. Reshaping Random Forests,[0],[0]
Assume v ∈,2.2. Reshaping Random Forests,[0],[0]
R is a predictor variable to be reshaped.,2.2. Reshaping Random Forests,[0],[0]
"The following thought experiment, illustrated in Figure (2), will motivate
our approach.
",2.2. Reshaping Random Forests,[0],[0]
"Imagine dropping x down T until it falls in its corresponding leaf, `1.",2.2. Reshaping Random Forests,[0],[0]
Let p1 be the closest ancestor node to `1 that splits on v and assume it has split rule {xv ≤ t1}.,2.2. Reshaping Random Forests,[0],[0]
"Holding all other coordinates constant, increasing xv until it is greater than t1 would create a new point that drops down to a different leaf `2 in the right subtree of p1.
",2.2. Reshaping Random Forests,[0],[0]
"If `1 and `2 both share another ancestor p2 farther up the tree with split rule {xv ≤ t2}, increasing xv beyond t2 would yield another leaf `3.",2.2. Reshaping Random Forests,[0],[0]
"Assume these leaves have no other shared ancestors that split on v. Denoting the value of leaf ` as µ`, in order to ensure monotonicity in v for this point x, we require µ`1 ≤ µ`2 ≤ µ`3 .
",2.2. Reshaping Random Forests,[0],[0]
We use this line of thinking to propose a framework for estimating monotonic random forests and describe two estimators that fall under this framework.,2.2. Reshaping Random Forests,[0],[0]
"Each leaf ` in a decision tree is a cell (or hyperrectangle) C` which is an intersection of intervals
C` = d⋂ j=1 {x : xj ∈ I`j}
When we split on a shape-constrained variable v with split-value t, each cell in the left subtree
is of the form Cl = C̄l ∩ {x : xv ≤ t} and each cell in the right subtree is of the form Cr = C̄r ∩ {x : xv > t}.
",2.2.1. Exact Estimator,[0],[0]
"For cells l in the left subtree and r in the right subtree, our goal is to constrain the corresponding leaf values µl ≤ µr only when C̄l ∩ C̄r 6= ∅.",2.2.1. Exact Estimator,[0],[0]
See Figure (3) for an illustration.,2.2.1. Exact Estimator,[0],[0]
"We must devise an algorithm to find the intersecting cells (l, r), and add each to a constraint set E. This can be done efficiently with an interval tree data structure.
",2.2.1. Exact Estimator,[0],[0]
"Assume there are n unique leaves appearing in E. The exact estimator is obtained by solving the following optimization:
min (µ̂`) n",2.2.1. Exact Estimator,[0],[0]
"`=1
n∑ `=1 (µ` − µ̂`)2
subject to µ̂i ≤ µ̂j ∀",2.2.1. Exact Estimator,[0],[0]
"(i, j) ∈ E (2.12)
where µ` is the original value of leaf `.
",2.2.1. Exact Estimator,[0],[0]
"This is an instance of L2 isotonic regression on a directed acyclic graph where each leaf value µ` is a node, and each constraint in E is an edge.",2.2.1. Exact Estimator,[0],[0]
"With n vertices and m edges, the fastest known exact algorithm for this problem has time complexity Θ(n4) (Spouge et al., 2003), and the fastest known δ-approximate algorithm has complexity O(m1.5 log2 n log n
δ ) (Kyng et al., 2015).
",2.2.1. Exact Estimator,[0],[0]
"With a corresponding change to the constraints in Equation (2.12), this approach extends naturally to convex regression trees.",2.2.1. Exact Estimator,[0],[0]
It can also be applied directly to probability trees for binary classification by reshaping the estimated probabilities in each leaf.,2.2.1. Exact Estimator,[0],[0]
"In this section, we propose an alternative estimator that can be more efficient to compute, depending on the tree structure.",2.2.2. Over-constrained Estimator,[0],[0]
"In our experiments below, we find that computing this estimator is always faster.
",2.2.2. Over-constrained Estimator,[0],[0]
Let Ep denote the set of constraints that arise between leaf values under a shape-constrained split node p.,2.2.2. Over-constrained Estimator,[0],[0]
"By adding additional constraints to Ep, we can solve (2.12) exactly for each shapeconstrained split node in O(np log np) time, where np is the number of leaves under p.
",2.2.2. Over-constrained Estimator,[0],[0]
"In this setting, each shape-constrained split node gives rise to an independent optimization involving its leaves.",2.2.2. Over-constrained Estimator,[0],[0]
"Due to transitivity, we can solve these optimizations sequentially in reverse (bottom-up) level-order on the tree.
",2.2.2. Over-constrained Estimator,[0],[0]
Let np denote the number of leaves under node p.,2.2.2. Over-constrained Estimator,[0],[0]
"For each node p that is split on a shapeconstrained variable, the over-constrained estimator solves the following max-min problem:
min (µ̂`) np `=1
np∑ `=1 (µ` − µ̂`)2
subject to max `∈left(p) µ̂` ≤ min r∈right(p) µ̂r
(2.13)
where left(p) denotes all leaves in the left subtree of p and right(p) denotes all leaves in the right subtree.
",2.2.2. Over-constrained Estimator,[0],[0]
"This is equivalent to adding an edge (`, r) toE for every pair of leaves such that ` is in left(p) and r is in right(p).",2.2.2. Over-constrained Estimator,[0],[0]
All such pairs do not necessarily exist in E for the exact estimator; see Figure (3).,2.2.2. Over-constrained Estimator,[0],[0]
"For each shape-constrained split, (2.13) is an instance of L2 isotonic regression on a complete directed bipartite graph.
",2.2.2. Over-constrained Estimator,[0],[0]
"For a given shape-constrained split node p, let ` = (`1, `2, . . .",2.2.2. Over-constrained Estimator,[0],[0]
", `n1) be the values of the leaves in its left subtree, and r = (r1, r2, . . .",2.2.2. Over-constrained Estimator,[0],[0]
", rn2) be the values of the leaves in its right subtree, indexed so that `1 ≤ · · · ≤ `n1 and r1 ≤ · · · ≤ rn2 .",2.2.2. Over-constrained Estimator,[0],[0]
"Then the max-min problem (2.13) is equivalent to:
min˜̀,r̃ n1∑ i=1",2.2.2. Over-constrained Estimator,[0],[0]
(`i − ˜̀i)2 + n2∑ i=1,2.2.2. Over-constrained Estimator,[0],[0]
"(ri − r̃i)2
subject to ˜̀1 ≤ ˜̀2 ≤ ...",2.2.2. Over-constrained Estimator,[0],[0]
"≤ ˜̀n1 ≤ r̃1 ≤ · · · ≤ r̃n2 (2.14)
",2.2.2. Over-constrained Estimator,[0],[0]
"The solution to this optimization is of the form ˜̀i = min(c, `i) and r̃i = max(c, ri), for some constant c.",2.2.2. Over-constrained Estimator,[0],[0]
"Given the two sorted vectors ` and r, the optimization becomes:
min c n1∑ i=1",2.2.2. Over-constrained Estimator,[0],[0]
"(`i −min(c, `i))2 + n2∑ i=1",2.2.2. Over-constrained Estimator,[0],[0]
"(ri −max(c, ri))2
This objective is convex and differentiable in c. Similar to the black box reshaping method, we can compute the derivatives at the values of the data and find where it flips sign, then compute the minimizer in the corresponding segment.",2.2.2. Over-constrained Estimator,[0],[0]
"This takes O(n) time where n = n1 + n2, the number of leaves under the shape-constrained split.",2.2.2. Over-constrained Estimator,[0],[0]
"With sorting, the over-constrained estimator can be computed in O(n log n) time for each shape-constrained split node.
",2.2.2. Over-constrained Estimator,[0],[0]
"We apply this procedure sequentially on the leaves of every shape-constrained node in reverse level-order on the tree.
3.",2.2.2. Over-constrained Estimator,[0],[0]
"Experiments
We apply the reshaping methods described above to two regression tasks and two binary classification tasks.",2.2.2. Over-constrained Estimator,[0],[0]
We show that reshaping allows us to enforce shape constraints without compromising predictive accuracy.,2.2.2. Over-constrained Estimator,[0],[0]
"For convenience, we use the acronyms in Table (1) to refer to each method.
",2.2.2. Over-constrained Estimator,[0],[0]
"The BB method was implemented in R, and the OC and EX methods were implemented in R and C++, extending the R package ranger (Wright & Ziegler, 2017).",2.2.2. Over-constrained Estimator,[0],[0]
"The exact estimator from Section (2.2.1) is computed using the MOSEK C++ package (ApS, 2017).
",2.2.2. Over-constrained Estimator,[0],[0]
"For binary classification, we use the probability tree implementation found in ranger, enforcing monotonicity of the probability of a positive classification with respect to the chosen predictors.",2.2.2. Over-constrained Estimator,[0],[0]
"For the purposes of these experiments, black box reshaping is applied to a traditional random forest.",2.2.2. Over-constrained Estimator,[0],[0]
"The random forest was fit with the default settings found in ranger.
",2.2.2. Over-constrained Estimator,[0],[0]
We apply 5-fold cross validation on all four tasks and present the results under the relevant performance metrics in Table (2).,2.2.2. Over-constrained Estimator,[0],[0]
"The diabetes dataset (Efron et al., 2004) consists of ten physiological baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements, for each of 442 patients.",3.1. Diabetes Dataset,[0],[0]
"The response is a quantitative measure of disease progression measured one year after baseline.
",3.1. Diabetes Dataset,[0],[0]
"Holding all other variables constant, we might expect disease progression to be monotonically increasing in body mass index (Ganz et al., 2014).",3.1. Diabetes Dataset,[0],[0]
"We estimate a random forest and apply our reshaping techniques, then make predictions for a random test subject as we vary the body mass index predictor variable.",3.1. Diabetes Dataset,[0],[0]
"The results shown in Figure (4a) illustrate the effect of reshaping on the predictions.
",3.1. Diabetes Dataset,[0],[0]
We use mean squared error to measure accuracy.,3.1. Diabetes Dataset,[0],[0]
The results in Table (2) indicate that the prediction accuracy of all four estimators is approximately the same.,3.1. Diabetes Dataset,[0],[0]
"In this section, the regression task is to predict real estate sales prices using property information.",3.2. Zillow Dataset,[0],[0]
"The data were obtained from Zillow, an online real estate database company.",3.2. Zillow Dataset,[0],[0]
"For each of 206,820 properties, we are given the list price, number of bedrooms and bathrooms, square footage, build decade, sale year, major renovation year (if any), city, and metropolitan area.",3.2. Zillow Dataset,[0],[0]
"The response is the actual sale price of the home.
",3.2. Zillow Dataset,[0],[0]
We reshape to enforce monotonicity of the sale price with respect to the list price.,3.2. Zillow Dataset,[0],[0]
"Due to the size of the constraint set, this problem becomes intractable for MOSEK; the results for the EX method are omitted.",3.2. Zillow Dataset,[0],[0]
"An interesting direction for future work is to investigate more efficient algorithms for this method.
",3.2. Zillow Dataset,[0],[0]
"Following reported results from Zillow, we use mean absolute percent error (MAPE) as our measure of accuracy.",3.2. Zillow Dataset,[0],[0]
"For an estimate ŷ of the true value y, the APE is |ŷ − y|/y.
",3.2. Zillow Dataset,[0],[0]
The results in Table (2) show that the performance across all estimators is indistinguishable.,3.2. Zillow Dataset,[0],[0]
We apply the reshaping techniques to the binary classification task found in the Adult dataset Lichman (2013).,3.3. Adult Dataset,[0],[0]
"The task is to predict whether an individual’s income is less than or greater than $50,000.",3.3. Adult Dataset,[0],[0]
"Following the experiments performed in Milani Fard et al. (2016) and You et al. (2017), we apply monotonic reshaping to four variables: capital gain, weekly hours of work, education
level, and the gender wage gap.
",3.3. Adult Dataset,[0],[0]
We illustrate the effect of reshaping on the predictions in Figure (4b).,3.3. Adult Dataset,[0],[0]
The results in Table (2) show that we achieve similar test set accuracy before and after reshaping the random forest.,3.3. Adult Dataset,[0],[0]
"Finally, we apply reshaping to classify whether an email is spam or not.",3.4. Spambase Dataset,[0],[0]
"The Spambase dataset (Lichman, 2013) contains 4,601 emails each with 57 predictors.",3.4. Spambase Dataset,[0],[0]
"There are 48 word frequency predictors, 6 character frequency predictors, and 3 predictors related to the number of capital letters appearing in the email.
",3.4. Spambase Dataset,[0],[0]
That data were collected by Hewlett-Packard labs and donated by George Forman.,3.4. Spambase Dataset,[0],[0]
"One of the predictors is the frequency of the word “george"", typically assumed to be an indicator of non-spam for this dataset.",3.4. Spambase Dataset,[0],[0]
"We reshape the predictions to enforce the probability of being classified as spam to be monotonically decreasing in the frequency of words “george"" and “hp"".
",3.4. Spambase Dataset,[0],[0]
The results in Table (2) again show similar performance across all methods.,3.4. Spambase Dataset,[0],[0]
We presented two strategies for prediction rule reshaping.,4. Discussion,[0],[0]
"We developed efficient algorithms to compute the reshaped estimators, and illustrated their properties on four datasets.",4. Discussion,[0],[0]
"Both approaches can be viewed as frameworks for developing more sophisticated reshaping techniques.
",4. Discussion,[0],[0]
There are several ways that this work can be extended.,4. Discussion,[0],[0]
"Extensions to the black box method include adaptively combining rearrangements and isotonization (Chernozhukov et al., 2009), and considering a weighted objective function to account for the distance between test points.
",4. Discussion,[0],[0]
"In general, the random forest reshaping method can be viewed as operating on pre-trained parameters of a specific model.",4. Discussion,[0],[0]
"Applying this line of thinking to gradient boosted trees, deep learning methods, and other machine learning techniques could yield useful variants of this approach.
",4. Discussion,[0],[0]
"And finally, while practitioners might require certain shape-constraints on their predictions, many scientific applications also require inferential quantities, such as confidence intervals and confidence bands.",4. Discussion,[0],[0]
"Developing inferential procedures for reshaped predictions, similar to Chernozhukov et al. (2010) for rearrangements and Athey et al. (2018) for random forests, would yield interpretable predictions along with useful measures of uncertainty.",4. Discussion,[0],[0]
"Research supported in part by ONR grant N00014-12-1-0762, NSF grants DMS-1513594 and DMS-1654076, and an Alfred P. Sloan fellowship.",5. Acknowledgments,[0],[0]
Two methods are proposed for high-dimensional shape-constrained regression and classification.,abstractText,[0],[0]
These methods reshape pre-trained prediction rules to satisfy shape constraints like monotonicity and convexity.,abstractText,[0],[0]
"The first method can be applied to any pre-trained prediction rule, while the second method deals specifically with random forests.",abstractText,[0],[0]
"In both cases, efficient algorithms are developed for computing the estimators, and experiments are performed to demonstrate their performance on four datasets.",abstractText,[0],[0]
We find that reshaping methods enforce shape constraints without compromising predictive accuracy.,abstractText,[0],[0]
Prediction Rule Reshaping,title,[0],[0]
"Sparse Spectrum Gaussian Processes (SSGPs) are a powerful tool for scaling Gaussian processes (GPs) to large datasets. Existing SSGP algorithms for regression assume deterministic inputs, precluding their use in many real-world robotics and engineering applications where accounting for input uncertainty is crucial. We address this problem by proposing two analytic moment-based approaches with closed-form expressions for SSGP regression with uncertain inputs. Our methods are more general and scalable than their standard GP counterparts, and are naturally applicable to multi-step prediction or uncertainty propagation. We show that efficient algorithms for Bayesian filtering and stochastic model predictive control can use these methods, and we evaluate our algorithms with comparative analyses and both real-world and simulated experiments.",text,[0],[0]
"The problem of prediction under uncertainty, appears in many fields of science and engineering that involve sequential prediction including state estimation (Ko & Fox, 2009; Deisenroth et al., 2012), time series prediction (Girard et al., 2003), stochastic process approximation (Archambeau et al., 2007), and planning and control (Deisenroth et al., 2015; Pan et al., 2015).",1. Introduction,[0],[0]
"In these problems, uncertainty can be found in both the predictive models and the model’s inputs.",1. Introduction,[0],[0]
"Formally, we are often interested in finding the probability density of a prediction y, given a distribution p(x) and a probabilistic model p(y|x).",1. Introduction,[0],[0]
"By marginal-
1Georgia Institute of Technology, Atlanta, Georgia, USA 2School of Aerospace Engineering 3School of Interactive Computing.",1. Introduction,[0],[0]
"Correspondence to: Yunpeng Pan <ypan37@gatech.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
ization,
p(y) = ∫",1. Introduction,[0],[0]
p(y|x)p(x) dx.,1. Introduction,[0],[0]
"(1)
Unfortunately, computing this integral exactly is often intractable.",1. Introduction,[0],[0]
"In this paper, we tackle a subfamily of (1) where: 1) the probabilistic model is learned from data and specified by a sparse spectrum representation of a Gaussian process (SSGP); and 2) the input x is normally distributed.",1. Introduction,[0],[0]
We show that analytic expressions of the moments of p(y) can be derived and that these are directly applicable to sequential prediction problems like filtering and control.,1. Introduction,[0],[0]
"Gaussian Process (GP) regression with uncertain inputs has been addressed by Candela et al. (2003); Girard et al. (2003), and extended to the multivariate outputs by Kuss (2006).",1.1. Related work,[0],[0]
"These methods have led to the development of many algorithms in reinforcement learning (Rasmussen & Kuss, 2004; Deisenroth et al., 2015), Bayesian filtering (Ko & Fox, 2009; Deisenroth et al., 2009), and smoothing (Deisenroth et al., 2012).",1.1. Related work,[0],[0]
"However, these approaches have two major limitations: 1) they are not directly applicable to large datasets, due to the polynomial time complexity for exact inference (Williams & Rasmussen, 2006); and 2) analytic moment expressions, when used, are restricted to squared exponential (SE) kernels (Kuss, 2006) and cannot be generalized to other kernels in a straightforward way.
",1.1. Related work,[0],[0]
"A common method for approximating large-scale kernel machines is through random Fourier features (Rahimi & Recht, 2007).",1.1. Related work,[0],[0]
The key idea is to map the input to a lowdimensional feature space yielding fast linear methods.,1.1. Related work,[0],[0]
"In the context of GP regression (GPR), this idea leads to the sparse spectrum GPR (SSGPR) algorithm (Lázaro-Gredilla et al., 2010).",1.1. Related work,[0],[0]
"SSGP has been extended in a number of ways for, e.g. incremental model learning (Gijsberts & Metta, 2013), and large-scale GPR (Dai et al., 2014; Yan et al., 2015).",1.1. Related work,[0],[0]
"However, to the best of our knowledge, prediction under uncertainty for SSGPs has not been explored.",1.1. Related work,[0],[0]
"Although there are several alternative approximations to exact GP inference including approximating the posterior distribution using inducing points, e.g., (Snelson & Ghahramani, 2006; Titsias, 2009; Cheng & Boots, 2016), comparing different GP approximations is not the focus of this paper.",1.1. Related work,[0],[0]
"We consider two key problems that are widely encountered in robotics and engineering: Bayesian filtering and stochastic model predictive control.
",1.2. Applications,[0],[0]
The goal of Bayesian filtering is to infer a hidden system state through the recursive application of Bayes’ rule.,1.2. Applications,[0],[0]
"Well-known frameworks for Bayesian filtering include unscented Kalman Filtering (UKF), particle filtering (PF), extended Kalman filtering (EKF), and assumed density filtering (ADF).",1.2. Applications,[0],[0]
"GP-based Bayesian filtering with SE kernels has been developed for these frameworks by (Ko & Fox, 2009; Deisenroth et al., 2009).",1.2. Applications,[0],[0]
"We extend this work with highly efficient SSGP-based EKF and ADF algorithms.
",1.2. Applications,[0],[0]
The goal of stochastic model predictive control (MPC) is to find finite horizon optimal control at each time instant.,1.2. Applications,[0],[0]
"Due to the high computational cost of GP inference and real-time optimization requirements in MPC, most GPbased control methods (Deisenroth et al., 2015; Pan & Theodorou, 2014; Kupcsik et al., 2014) are restricted to episodic reinforcement learning tasks.",1.2. Applications,[0],[0]
"To cope with this challenge, we present an SSGP-based MPC algorithm that is fast enough to perform probabilistic trajectory optimization and model adaptation on-the-fly.",1.2. Applications,[0],[0]
"• We propose two approaches to prediction under un-
certainty in SSGPs with closed-form expressions for the predictive distribution.",1.3. Our contributions,[0],[0]
"Compared to previous GP counterparts, our methods: 1) are more scalable, and 2) can be generalized to any continuous shift-invariant kernels with a Fourier feature representation.
",1.3. Our contributions,[0],[0]
"• We demonstrate successful applications of the proposed approaches by presenting scalable algorithms for 1) recursive Bayesian filtering and 2) stochastic model predictive control via probabilistic trajectory optimization.
",1.3. Our contributions,[0],[0]
The rest of the paper is organized as follows.,1.3. Our contributions,[0],[0]
"In §2, we give an introduction to SSGPs, which serves as our probabilistic model.",1.3. Our contributions,[0],[0]
Derivation and expressions of the two proposed prediction methods are detailed in §3.,1.3. Our contributions,[0],[0]
"Applications to filtering and control, and experimental results are presented in §4 and §5 respectively.",1.3. Our contributions,[0],[0]
Finally §6 concludes the paper.,1.3. Our contributions,[0],[0]
"Consider the task of learning the function f : Rd → R, given IID data D = {xi, yi}ni=1, with each pair related by
y = f(x) + , ∼ N (0, σ2n), (2)
where is IID additive Gaussian noise.",2. Sparse Spectral Representation of GPs,[0],[0]
"Gaussian process regression (GPR) is a principled way of performing Bayesian inference in function space, assuming that function f has a prior distribution f ∼ GP(m, k), with mean
function m : Rd → R and kernel",2. Sparse Spectral Representation of GPs,[0],[0]
k :,2. Sparse Spectral Representation of GPs,[0],[0]
"Rd × Rd → R. Without loss of generality, we assume m(x) = 0.",2. Sparse Spectral Representation of GPs,[0],[0]
"Exact GPR is challenging for large datasets due to its O(n3) time andO(n2) space complexity (Williams & Rasmussen, 2006), which is a direct consequence of having to store and invert an n× n Gram matrix.
",2. Sparse Spectral Representation of GPs,[0],[0]
"Random features can be used to form an unbiased approximation of continuous shift-invariant kernel functions, and are proposed as a general mechanism to accelerate largescale kernel machines (Rahimi & Recht, 2007), via explicitly mapping inputs to low-dimensional feature space.",2. Sparse Spectral Representation of GPs,[0],[0]
"Based on Bochner’s theorem, the Fourier transform of a continuous shift-invariant positive definite kernel k(x, x′) is a proper probability distribution p(ω), assuming k(x, x′) is properly scaled (Rahimi & Recht, 2007):
k(x, x′) = ∫",2. Sparse Spectral Representation of GPs,[0],[0]
p(ω)ejω T (x−x′),2. Sparse Spectral Representation of GPs,[0],[0]
"dω
= E(φω(x)φω(x ′)∗), ω ∼ p(ω),
(3)
where φω(x) = ejω T x, and we can see that k(x, x′) only depends on the lag vector separating x and x′:",2. Sparse Spectral Representation of GPs,[0],[0]
"x−x′. Equation (3) leads to an unbiased finite sample approximation of k: k(x, x′)",2. Sparse Spectral Representation of GPs,[0],[0]
"≈ 1m ∑ φωi(x)φωi(x
′)∗, where random frequencies {ωi}mi=1 are drawn IID from p(ω).",2. Sparse Spectral Representation of GPs,[0],[0]
"Utilizing the fact that φω can be replaced by sinusoidal functions since both p(ω) and k(x, x′) are reals, and",2. Sparse Spectral Representation of GPs,[0],[0]
"concatenating features {φωi}mi=1 into a succinct vector form, an approximation for k(x, x′) is expressed as
k(x, x′)",2. Sparse Spectral Representation of GPs,[0],[0]
"≈ φ(x)Tφ(x′), φ(x)",2. Sparse Spectral Representation of GPs,[0],[0]
=,2. Sparse Spectral Representation of GPs,[0],[0]
"[ φc(x) φs(x) ] , (4)
φci (x) = σk cos(ω T i x), φ s i (x) =",2. Sparse Spectral Representation of GPs,[0],[0]
"σk sin(ω T i x), ωi ∼ p(ω),
where σk is a scaling coefficient.",2. Sparse Spectral Representation of GPs,[0],[0]
"For the commonly used Squared Exponential (SE) kernel: k(x, x′) = σ2f exp(− 12‖x",2. Sparse Spectral Representation of GPs,[0],[0]
"− x ′‖2Λ−1), p(ω) = N (0,Λ −1) and σk = σf√ m
, where the coefficient σf and the diagonal matrix Λ are the hyperparameters, examples of kernels and corresponding spectral densities can be found in Table 1.
",2. Sparse Spectral Representation of GPs,[0],[0]
"In accordance with this feature map (4), Sparse Spectrum GPs are defined as follows
Definition 1.",2. Sparse Spectral Representation of GPs,[0],[0]
"Sparse Spectrum GPs (SSGPs) are GPs with kernels defined on the finite-dimensional and randomized feature map φ (4):
k(x, x′) = φ(x)Tφ(x′) + σ2nδ(x− x′), (5)
where the function δ is the Kronecker delta function.
",2. Sparse Spectral Representation of GPs,[0],[0]
"The second term in (5) accounts for the additive zero mean Gaussian noise in (2), if the goal is to learn the correlation between x and y directly as in our case of learning the probabilistic model p(y|x), instead of learning the latent function f .
",2. Sparse Spectral Representation of GPs,[0],[0]
"Because of the explicit finite-dimensional feature map (4), each SSGP is equivalent to a Gaussian distribution over the weights of features w ∈ R2m. Assuming that prior distribution of weights w is N (0, I) 1 and the feature map is fixed, after conditioning on the data D = {xi, yi}ni=1, the posterior distribution of w is 2
w ∼ N (α, σ2nA−1), (6) α = A−1ΦY, A = ΦΦT + σ2nI,
which can be derived through Bayesian linear regression.",2. Sparse Spectral Representation of GPs,[0],[0]
"In (6), the column vector Y and the matrix Φ are specified by the data D: Y =",2. Sparse Spectral Representation of GPs,[0],[0]
[ y1 . . .,2. Sparse Spectral Representation of GPs,[0],[0]
"yn ]T , Φ =[
φ(x1) . . .",2. Sparse Spectral Representation of GPs,[0],[0]
φ(xn) ] .,2. Sparse Spectral Representation of GPs,[0],[0]
"Consequently, the posterior distribution over the output y in (2) at a test point x is exactly Gaussian, in which the posterior variance explicitly captures the model uncertainty in prediction with input x:
p(y|x)",2. Sparse Spectral Representation of GPs,[0],[0]
"= N (αTφ(x), σ2n + σ2n‖φ(x)‖2A−1).",2. Sparse Spectral Representation of GPs,[0],[0]
"(7)
This Bayesian linear regression method for SSGP is proposed in Lázaro-Gredilla et al. (2010).",2. Sparse Spectral Representation of GPs,[0],[0]
"Its time complexity is O(nm2 +m3), which is significantly more efficient than standard GPR’s O(n3)",2. Sparse Spectral Representation of GPs,[0],[0]
"when m n.
Remark It’s worth noting that the methods proposed in this paper are not tied to specific algorithms for SSGP regression such as Bayesian linear regression (LázaroGredilla et al., 2010), but able to account for any SSGP with specified feature weights distribution (6), where posterior α and A can be computed by any means.",2. Sparse Spectral Representation of GPs,[0],[0]
"Variations on A include sparse approximations by a low rank plus diagonal matrix, or iterative solutions by optimization methods like doubly stochastic gradient descent (Dai et al., 2014).",2. Sparse Spectral Representation of GPs,[0],[0]
"Two methods for prediction under uncertainty are presented under two conditions: 1) the uncertain input is normally distributed: x ∼ N (µ,Σ), and 2) probabilistic models are in the form of (7) specified by SSGPs.",3. Prediction under Uncertainty,[0],[0]
"Despite these conditions, evaluating the integral in (1) is still intractable.",3. Prediction under Uncertainty,[0],[0]
"In this work, we approximate the true predictive distribution p(y) by a Gaussian distribution with moments that are analytically computed through: 1) exact moment matching, and 2) linearization of posterior mean function.",3. Prediction under Uncertainty,[0],[0]
"Closed-form expressions for predictive mean, variance, covariance, and input-prediction cross-covariance are derived.",3. Prediction under Uncertainty,[0],[0]
"We consider multivariate outputs by utilizing con-
1I is the identity matrix with proper size.",3. Prediction under Uncertainty,[0],[0]
The prior covariance is identity since E (f(x)f(x)),3. Prediction under Uncertainty,[0],[0]
= E ( φ(x)TwwTφ(x′) ),3. Prediction under Uncertainty,[0],[0]
"= φ(x)T E(wwT )φ(x′), and E (f(x)f(x′))",3. Prediction under Uncertainty,[0],[0]
"= φ(x)Tφ(x′) (see §2.2 in Rasmussen & Kuss (2004) for details.)
",3. Prediction under Uncertainty,[0],[0]
"2Conditioning on data D is omitted, e.g., in w|D, for simplicity in notation.
ditionally independent scalar models for each output dimension, i.e., assuming for outputs in different dimension ya and yb, p(ya, yb|x)",3. Prediction under Uncertainty,[0],[0]
= p(ya|x)p(yb|x).,3. Prediction under Uncertainty,[0],[0]
Discussions on this assumption can be found in Appendix §6.1.,3. Prediction under Uncertainty,[0],[0]
"For notational simplicity, we suppress the dependency of φ(x) on x, and treat y as a scalar by default.",3. Prediction under Uncertainty,[0],[0]
"We derive the closed-form expressions for exact moments: 1) the predictive mean E y, 2) the predictive variance Var y and covariance Cov(ya, yb), which in the multivariate case correspond to the diagonal and off-diagonal entries of the predictive covariance matrix, and 3) the cross-covariance between input and prediction Cov(x, y).
",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Using the expressions for SSGP (4), (7), and the law of total expectation, the predictive mean becomes
E y = EE(y|x)",3.1. Exact moment matching (SSGP-EMM),[0],[0]
= E ( αTφ ),3.1. Exact moment matching (SSGP-EMM),[0],[0]
"= αT E
[ φc
φs
] , (8)
Eφci = σk E cos(ω T",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"i x),",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Eφ s i = σk E sin(ω T i x),
where i = 1, . . .",3.1. Exact moment matching (SSGP-EMM),[0],[0]
",m, and in the nested expectation EE(y|x), the outer expectation is over the input distribution p(x)",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"= N (µ,Σ), and the inner expectation is over the conditional distribution p(y|x) (7).
",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"By observing (8), we see that the expectation of sinusoids under the Gaussian distribution is the key to computing the predictive mean.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Thus, we state the following proposition: Proposition 1.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"The expectation of sinusoids over multivariate Gaussian distributions: x ∼ N (µ,Σ), x ∈ Rd, i.e., p(x) = (2π)− d 2 (det Σ)−
1 2 exp(− 12‖x",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"− µ‖ 2 Σ−1), can
be computed analytically:
E cos(ωTx) = exp(−1 2 ‖ω‖2Σ) cos(ωTµ), E sin(ωTx) = exp(−1 2 ‖ω‖2Σ) sin(ωTµ).
",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"To prove it, we invoke Euler’s formula to transform the lefthand-side to complex domain, apply identities involving quadratic exponentials, and then convert back to real numbers (see Appendix §3.2 for details).",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"In Proposition 1, the expectations depend on the mean and variance of the input Gaussian distribution.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Intuitively, after passing a Gaussian distributed input through a sinusoidal function, the expectation of the output is equal to passing the mean of the input through the sinusoid, and then scaling it by a constant exp(− 12‖ω‖ 2 Σ), which depends on the variance of the input.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Expectations are smaller with larger input variance due to the periodicity of sinusoids.
",3.1. Exact moment matching (SSGP-EMM),[0],[0]
The exact moments are then derived using Proposition 1.,3.1. Exact moment matching (SSGP-EMM),[0],[0]
"By the law of total variance, the predictive variance is
Var y = EVar(y|x) + VarE(y|x)",3.1. Exact moment matching (SSGP-EMM),[0],[0]
= σ2n,3.1. Exact moment matching (SSGP-EMM),[0],[0]
+ σ 2 nTr ( A−1Ψ ) +,3.1. Exact moment matching (SSGP-EMM),[0],[0]
"αTΨα− (E y)2, (9)
where Ψ is defined as the expectation of the outer product of feature vectors over input distribution p(x).",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Specifically, we compute Ψ by applying the product-to-sum trigonometric identities:
E ( φφT ) =",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Ψ =
[ Ψcc Ψcs
Ψsc Ψss
] ,
Ψccij = σ2k 2
( E ( cos(ωi + ωj)",3.1. Exact moment matching (SSGP-EMM),[0],[0]
Tx ) +,3.1. Exact moment matching (SSGP-EMM),[0],[0]
E,3.1. Exact moment matching (SSGP-EMM),[0],[0]
"( cos(ωi − ωj)Tx )) ,
Ψssij = σ2k 2
( E ( cos(ωi − ωj)Tx )",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"−E ( cos(ωi + ωj) Tx )) ,
Ψcsij = σ2k 2
( E ( sin(ωi + ωj) Tx )",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"−E ( sin(ωi − ωj)Tx )) ,
where Ψcc,Ψss,Ψcs are m × m matrices, and i, j = 1, . . .",3.1. Exact moment matching (SSGP-EMM),[0],[0]
",m, on whose terms Proposition 1 can be directly applied.
",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Next, we derive the covariance for different output dimensions for multivariate prediction.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
These correspond to the off-diagonal entries of the predictive covariance matrix.,3.1. Exact moment matching (SSGP-EMM),[0],[0]
"We show that, despite the conditional independence assumption for different outputs given a deterministic input, outputs become coupled with uncertain inputs.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Using the law of total covariance, the covariance is
Cov(ya, yb) =",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Cov (E(ya|x),E(yb|x))",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"= E (E(ya|x),E(yb|x))−(E ya)(E yb) = αTaΨabαb",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"− (αTa Eφa)(αTb Eφb), (10)
where matrix Ψab is the expectation of the outer product of feature vectors corresponding to different feature maps φa, φb for outputs ya, yb, computed similarly as in (3.1) with corresponding random frequencies {ωi}, and the scaling coefficient σk (4).",3.1. Exact moment matching (SSGP-EMM),[0],[0]
Vectors αa and αb are the corresponding weight vectors for ya and yb (7).,3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Compared to the expression for the variance of a single output in (9), the term E (Cov(ya|x)Cov(yb|x)) that is included in the law of total covariance is neglected due to the assumption of conditional independence of different outputs (§2), so (10) does not have the corresponding first two terms in (9).
",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Finally, we compute the cross-covariance between input and each output dimension.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Invoking the law of total covariance:
Cov(x, y) = Cov(x,E(y|x))",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"= E (xE(y|x))− (Ex)(E y) = Υα− (E y)µ,
(11)
where matrix Υ is the expectation of the outer product of the input x and the feature vector φ(x) over input distribution x ∼ N (µ,Σ): E(xφT ) =",3.1. Exact moment matching (SSGP-EMM),[0],[0]
Υ = [ Υc1 . . .,3.1. Exact moment matching (SSGP-EMM),[0],[0]
Υ,3.1. Exact moment matching (SSGP-EMM),[0],[0]
c m Υ s 1 . . .,3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Υ s m ] ,
Υci = σk E",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"( cos(ωTi x)x ) , Υsi = σk E ( cos(ωTi x)x ) ,
where r = √ 2ν‖x−x′‖2
` , Kν is a modified Bessel function,
and h = 2 dπ
d 2 Γ(ν+ d2 )(2ν) ν
Γ(ν)`2ν .
",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"where i = 1, . .",3.1. Exact moment matching (SSGP-EMM),[0],[0]
.,3.1. Exact moment matching (SSGP-EMM),[0],[0]
",m. We state the following proposition to compute each column in Υ consisting of expectations of the product sinusoidal functions and inputs.
",3.1. Exact moment matching (SSGP-EMM),[0],[0]
Proposition 2.,3.1. Exact moment matching (SSGP-EMM),[0],[0]
"The expectation of the multiplication of sinusoids and linear functions over multivariate Gaussian distributions: x ∼ N (µ,Σ), can be computed analytically:
E ( cos(ωTx)x )",3.1. Exact moment matching (SSGP-EMM),[0],[0]
=,3.1. Exact moment matching (SSGP-EMM),[0],[0]
( E cos(ωTx) ),3.1. Exact moment matching (SSGP-EMM),[0],[0]
"µ− (E(sin(ωTx))Σω,
E ( sin(ωTx)x )",3.1. Exact moment matching (SSGP-EMM),[0],[0]
=,3.1. Exact moment matching (SSGP-EMM),[0],[0]
( E sin(ωTx) ),3.1. Exact moment matching (SSGP-EMM),[0],[0]
µ+ ( E cos(ωTx) ),3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Σω,
where the right-hand-side expectations have analytical expressions (Proposition 1).",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"To prove it, we find an expression for E ( aTx cos(ωTx) ) , for any a, through the complex domain trick used to prove Proposition 1.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Next, the result is extended to E ( x cos(ωTx) ) , by setting a to consist of indicator vectors (see Appendix §3.3 for details).",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Applying Proposition 1 and 2, we complete the derivation of Cov(x, y) in (11).
",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Remark In summary, SSGP-EMM computes the exact posterior moments.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"This is equivalent to expectation propagation (Minka, 2001) by minimizing the Kullback-Leibler divergence between the true distribution and its Gaussian approximation with respect to the natural parameters.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"SSGP-EMM’s computation complexity is O ( m2k2d2 ) , where m is the number of features, k is the output dimension, and d is the input dimension.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"The most computationally demanding part is constructing matrices Ψab (10) for each output pair, where each requires O ( m2d2 ) .
",3.1. Exact moment matching (SSGP-EMM),[0],[0]
"Compared to the multivariate moment-matching approach for GPs (GP-EMM) (Girard et al., 2003; Kuss, 2006) with O ( n2k2d2 ) time complexity, SSGP-EMM is more efficient when m n. Moreover, our approach is applicable to any positive-definite continuous shift-invariant kernel with different spectral densities (see examples in Table 1), while previous approaches like GP-EMM (Kuss, 2006) are only derived for squared exponential (SE) or polynomial kernels.",3.1. Exact moment matching (SSGP-EMM),[0],[0]
Next we introduce a more computationally efficient but less accurate approach that avoids the computation of Ψab’s.,3.1. Exact moment matching (SSGP-EMM),[0],[0]
"An alternative approach to computing the exact moments of the predictive distribution is based on the linearization of the posterior mean function in (7) at the input mean µ:
m(x) = αTφ(x)",3.2. Linearization (SSGP-Lin),[0],[0]
"≈ m(µ) + αT Dφ(µ)︸ ︷︷ ︸ M (x− µ), (12)
where Dφ(µ) denotes taking the derivative of function φ at µ. Given the definition of φ in (4), Dφ can be found by chain rule: Dφci (x) = −σk",3.2. Linearization (SSGP-Lin),[0],[0]
sin(ωTi,3.2. Linearization (SSGP-Lin),[0],[0]
"x)ωTi , Dφsi (x) = σk cos(ω T",3.2. Linearization (SSGP-Lin),[0],[0]
i x)ω,3.2. Linearization (SSGP-Lin),[0],[0]
"T i .
",3.2. Linearization (SSGP-Lin),[0],[0]
"Utilizing the linearized posterior mean function (12), the predictive moments can be approximated.",3.2. Linearization (SSGP-Lin),[0],[0]
"The predictive mean approximation is
E y = EE(y|x)",3.2. Linearization (SSGP-Lin),[0],[0]
"≈ m(µ), (13)
and the predictive variance approximation is Var y = EVar(y|x)",3.2. Linearization (SSGP-Lin),[0],[0]
"+ VarE(y|x)
",3.2. Linearization (SSGP-Lin),[0],[0]
≈ Var(y|µ),3.2. Linearization (SSGP-Lin),[0],[0]
+ Var(αTMx),3.2. Linearization (SSGP-Lin),[0],[0]
= σ2n + σ,3.2. Linearization (SSGP-Lin),[0],[0]
"2 n‖φ(µ)‖2A−1 + α TMΣMTα.
(14)
and the approximate covariance between output dimension a and b is Cov(ya, yb) =",3.2. Linearization (SSGP-Lin),[0],[0]
"Cov (E(ya|x),E(yb|x))
",3.2. Linearization (SSGP-Lin),[0],[0]
= E ( αTaMa(x− µ)(x− µ)TMTb αb ),3.2. Linearization (SSGP-Lin),[0],[0]
"≈ αTaMaΣMTb αb, (15)
where Ma and Mb are defined as M in (12), except that they correspond to feature maps φa and φb.",3.2. Linearization (SSGP-Lin),[0],[0]
"Notice that the assumption of conditional independence between different outputs is invoked here again, cf., (10).
",3.2. Linearization (SSGP-Lin),[0],[0]
"Finally, the cross-covariance between the input and output can be approximated as
Cov(x, y) = Cov(x,E(y|x))",3.2. Linearization (SSGP-Lin),[0],[0]
≈ E ( (x− µ)(αTM(x− µ)) ),3.2. Linearization (SSGP-Lin),[0],[0]
"= αTMΣ
(16)
",3.2. Linearization (SSGP-Lin),[0],[0]
"Unlike SSGP-EMM, which computes exact moments (§3.1), this linearization-based approach SSGP-Lin computes an approximation of the predictive moments.",3.2. Linearization (SSGP-Lin),[0],[0]
"In contrast to SSGP-EMM’s O ( m2k2d ) computational complexity, the computation time of SSGP-Lin is reduced to O ( m2kd ) , as a direct consequence of avoiding the construction of Ψ (3.1) in SSGP-EMM (10), which makes SSGP-Lin more efficient than SSGP-EMM, especially when the output dimension is high.
",3.2. Linearization (SSGP-Lin),[0],[0]
Both SSGP-EMM and SSGP-Lin are applicable to a general family of kernels.,3.2. Linearization (SSGP-Lin),[0],[0]
"See Table 2 for a comparison between our methods and GP-EMM (Girard et al., 2003; Kuss, 2006).",3.2. Linearization (SSGP-Lin),[0],[0]
"In the next section, we compare these approaches in applications of filtering and control.",3.2. Linearization (SSGP-Lin),[0],[0]
We focus on the application of the proposed methods to Bayesian filtering and predictive control.,4. Applications,[0],[0]
"We begin by introducing Gauss-Markov models, which can be expressed by the following discrete-time nonlinear dynamical system:
xt+1 = f(xt, ut) + x t ,
x t ∼ N",4. Applications,[0],[0]
"(0,Σ x), (17)
yt = g(xt) + y t ,
",4. Applications,[0],[0]
"y t ∼ N (0,Σ y ), (18)
where xt ∈ Rd is state, ut ∈",4. Applications,[0],[0]
"Rr is control, yt ∈",4. Applications,[0],[0]
"Rk is observation or measurement, xt ∈ Rd is IID process noise,",4. Applications,[0],[0]
yt ∈,4. Applications,[0],[0]
"Rk is IID measurement noise, and subscript t denotes discrete time index.",4. Applications,[0],[0]
"We call the probabilistic models (17) and (18) the dynamics and observation models, and the corresponding deterministic functions f and g the dynamics and observation functions.
",4. Applications,[0],[0]
We consider scenarios where f and g are unknown but a dataset D =,4. Applications,[0],[0]
"( {(xt, ut), xt+1}n−1t=1 , {xt, yt}nt=1 ) is provided.",4. Applications,[0],[0]
"The probabilistic models specified by SSGPs can be learned from the dataset, and then used to model the dynamics and observation (17) (18).",4. Applications,[0],[0]
"More concretely, the dynamics model p(xt+1|xt, ut) is learned using state transition pairs {(xt, ut), xt+1}n−1t=1 , and the observation model p(yt|xt) is learned separately from state-observation pairs {xt, yt}nt=1.",4. Applications,[0],[0]
"The task of Bayesian filtering is to infer the posterior distribution of the current state of a dynamical system based on the current and past noisy observations, i.e., finding p(xt|t), where the notation xt|s denotes the random variable xt|y0, . . .",4.1. Bayesian filtering,[0],[0]
", ys.",4.1. Bayesian filtering,[0],[0]
"Due to the Markov property of the process x, i.e., xt|x0, . . .",4.1. Bayesian filtering,[0],[0]
", xt−1 = xt|xt−1, in Gauss-Markov models, p(xt|t) can be computed recursively through alternating prediction step and correction step.
4.1.1.",4.1. Bayesian filtering,[0],[0]
PREDICTION STEP (xt−1|t−1 → xt|t−1),4.1. Bayesian filtering,[0],[0]
"In the prediction step, xt−1|t−1 is propagated through the dynamics model p(xt|xt−1, ut−1):
p(xt|t−1) = ∫",4.1. Bayesian filtering,[0],[0]
"p(xt|xt−1, ut−1)p(xt−1|t−1) dxt−1,
which can be viewed as prediction under uncertainty (1).",4.1. Bayesian filtering,[0],[0]
"Suppose that p(xt−1|t−1) = N (µ̂t−1|t−1, Σ̂t−1|t−1), with learned SSGP representation for the dynamics, Gaussian approximations of the output: p(xt|t−1)",4.1. Bayesian filtering,[0],[0]
"≈ N (µ̂t|t−1, Σ̂t|t−1) can be obtained by either SSGP-EMM
(§3.1) using (8), (9) and (10), or SSGP-Lin (§3.2) using (13), (14) and (15).
",4.1. Bayesian filtering,[0],[0]
4.1.2.,4.1. Bayesian filtering,[0],[0]
CORRECTION STEP,4.1. Bayesian filtering,[0],[0]
(xt|t−1 → xt|t),4.1. Bayesian filtering,[0],[0]
"The correction step conditions xt|t−1 on the current observation yt using Bayes’ rule:
p(xt|t) = p(yt|xt|t−1)p(xt|t−1)∫ p(yt|xt|t−1)p(xt|t−1) dxt .",4.1. Bayesian filtering,[0],[0]
"(19)
In the preceding prediction step, we obtain p(xt|t−1)",4.1. Bayesian filtering,[0],[0]
"≈ N (µ̂t|t−1, Σ̂t−1|t−1), which serves as a prior on xt in this correction step.",4.1. Bayesian filtering,[0],[0]
"Due to the intractability of the integral in the denominator, to apply Bayes’ rule we first seek Gaussian approximations for the joint distribution, as in the previous work on Bayesian filtering relying on GPs (Deisenroth et al., 2009; Ko & Fox, 2009):",4.1. Bayesian filtering,[0],[0]
"[
xt|t−1 yt|t−1
] ∼ N ([ µ̂t|t−1 µ̂y ] , [ Σ̂t|t−1 Σ̂xy Σ̂Txy Σ̂y ]) , (20)
Invoking p(yt|t−1) = ∫ p(yt|xt|t−1)p(xt|t−1) dxt, the moments µ̂y , Σ̂y , and Σ̂xy in the joint Gaussian approximation can be computed as the predictive mean, predictive covariance, and input-prediction cross-covariance, for the observation model p(yt|xt) with input p(xt|t−1), using SSGPEMM or SSGP-Lin.",4.1. Bayesian filtering,[0],[0]
"Having all terms in (20) determined, we condition xt|t−1 exactly on current observation yt:
µ̂t|t = µ̂t|t−1 + Σ̂xyΣ̂ −1 y",4.1. Bayesian filtering,[0],[0]
"(y − µ̂y), Σ̂t|t = Σ̂t|t−1 − Σ̂xyΣ̂−1y Σ̂xy.",4.1. Bayesian filtering,[0],[0]
"(21)
This Gaussian approximation p(xt|t)",4.1. Bayesian filtering,[0],[0]
"≈ N (µ̂t|t, Σ̂t|t) is then used as input to the prediction step.",4.1. Bayesian filtering,[0],[0]
"Thus, we have shown that starting from p(x0) = N (µ0,Σ0), by consecutively applying prediction and correction steps presented above, we recursively obtain state estimates for xt|t−1 and xt|t.",4.1. Bayesian filtering,[0],[0]
"Rather than using a finite sample-based approximation such as in the GP-UKF (Ko & Fox, 2009), the Gaussian approximations of the full densities p(xt|t) and p(xt|t−1) are propagated.
",4.1. Bayesian filtering,[0],[0]
"Algorithm 1 SSGP-ADF and SSGP-EKF 1: Model learning: collect dataset D, and learn SSGP dy-
namics and observations models (§2.)",4.1. Bayesian filtering,[0],[0]
2: Initialization: set prior p(x0).,4.1. Bayesian filtering,[0],[0]
"3: for t = 1, . . .",4.1. Bayesian filtering,[0],[0]
do 4: Prediction: compute µ̂t|t−1 and Σ̂t|t−1 .,4.1. Bayesian filtering,[0],[0]
by either SSGP-EMM (§3.1) or SSGP-Lin (§3.2).,4.1. Bayesian filtering,[0],[0]
5: Measurement: make an observation yt.,4.1. Bayesian filtering,[0],[0]
6: Correction: compute µ̂t|t and Σ̂t|t according to (21) by either SSGP-EMM (§3.1) or SSGP-Lin (§3.2).,4.1. Bayesian filtering,[0],[0]
"7: end for
We summarize the resulting filtering algorithm SSGPADF (assumed density filtering) and SSGP-EKF (extended Kalman filtering), based on SSGP-EMM and SSGP-Lin, respectively, in Algorithm 1.",4.1. Bayesian filtering,[0],[0]
"These are analogs of GP-ADF (Deisenroth et al., 2009) and GP-EKF (Ko & Fox, 2009).",4.1. Bayesian filtering,[0],[0]
"The stochastic model predictive control (MPC) problem is to choose a control sequence that minimizes the expected cost, provided p(xt):
u?t+1:t+T = argmin ut+1:t+T
E ( h(xt+T ) +",4.2. Stochastic Model Predictive Control,[0],[0]
"i+T∑ i l(xt+i, ut+i) ) ,
at each time step, subject to stochastic system dynamics (17), where function h : Rd → R and l : Rd ×Rr",4.2. Stochastic Model Predictive Control,[0],[0]
→ R are the final and running cost respectively.,4.2. Stochastic Model Predictive Control,[0],[0]
"There are two main challenges to applying MPC in practice: 1) MPC requires an accurate dynamics model for multi-step prediction, and 2) online optimization is very computationally expensive.",4.2. Stochastic Model Predictive Control,[0],[0]
"For clarity in presentation, we will assume that the state is fully observable henceforth.
",4.2. Stochastic Model Predictive Control,[0],[0]
"Algorithm 2 MPC via probabilistic trajectory optimization (1-3: offline optimization, 4-8: online optimization)
1: Model learning: collect dataset D, and learn SSGP dynamics model (§2).",4.2. Stochastic Model Predictive Control,[0],[0]
"2: Initialization: set t = 0, and estimate p(x0).",4.2. Stochastic Model Predictive Control,[0],[0]
"3: Trajectory optimization: perform trajectory optimiza-
tion in belief space, obtain u?t+1:t+T .",4.2. Stochastic Model Predictive Control,[0],[0]
"4: repeat 5: Policy execution: apply one-step control u?t+1 to the system and move one step forward, update t = t+1.",4.2. Stochastic Model Predictive Control,[0],[0]
6: Model adaptation: incorporate new data and update SSGP dynamics model.,4.2. Stochastic Model Predictive Control,[0],[0]
"7: Trajectory optimization: perform re-optimization
with the updated model.",4.2. Stochastic Model Predictive Control,[0],[0]
"Initialize with the previously optimized trajectory and obtain new u?t+1:t+T .
8: until Task terminated",4.2. Stochastic Model Predictive Control,[0],[0]
We address the aforementioned challenges by employing a combination of prediction under uncertainty and trajectory optimization.,4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"More precisely, we use SSGP-EMM or SSGP-Lin to efficiently obtain approximate Gaussian distribution over trajectory of states and perform trajectory optimization in the resultant Gaussian belief space based on differential dynamic programming (DDP) (Abbeel et al., 2007; Tassa et al., 2007).",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
Note that DDP-related methods require computation of first and second order derivatives of the dynamics and cost.,4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
Our analytic moment expressions provide a robust and efficient way to compute these derivatives.,4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"Details are omitted due to space limit, but they can be found in Appendix §4.
",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"Within the SSGP framework, we may incrementally update the posterior distribution over the feature weights w (6) given a new sample without storing or inverting the matrix A explicitly, Instead we keep track of its upper triangular Cholesky factor A = RTR (Gijsberts & Metta, 2013).",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"Given a new sample, a rank-1 update is applied to
the Cholesky factor R, which requires O(m2) time.",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"To cope with time-varying systems and to make the method more adaptive, we employ a forgetting factor λ ∈ (0, 1), such that the impact of the previous samples decays exponentially in time (Ljung, 1998).
",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"Our proposed MPC algorithm, summarized in Algorithm 2, is related to several algorithms and differs in both model and controller learning.",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"First, SSGPs are more robust to modeling error than Locally Weighted Projection Regression (LWPR) used in iLQG-LD (Mitrovic et al., 2010).",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"See a numerical comparison in (Gijsberts & Metta, 2013).",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"Second, we efficiently propagate uncertainty in multi-step prediction which is crucial in MPC.",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"In contrast, AGP-iLQR (Boedecker et al., 2014) drops the input uncertainty and uses subset of regressors (SoR-GP) which lacks a principled way to select reference points.",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"In addition, PDDP (Pan & Theodorou, 2014) uses GPs which are computationally expensive for online optimization.",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"Two deep neural networks are used for modeling in (Yamaguchi & Atkeson, 2016), which make it difficult to perform online incremental learning, as we do here.",4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION,[0],[0]
"We consider a synthetic dynamical system with groundtruth dynamics f(x) = 12x+ 25x 1+x2 and observation g(x) = 6 sin(2x) with Σ x = 1.52 and Σ y = 1 in (17,18), in a similar setting to Deisenroth et al. (2009).",5.1.1. 1D ONE-STEP FILTERING,[0],[0]
"We compare the performance of four filters, SSGP-ADF, SSGP-EKF, GPADF (Deisenroth et al., 2009) and GP-EKF (Ko & Fox, 2009).",5.1.1. 1D ONE-STEP FILTERING,[0],[0]
All models are trained using 800 samples.,5.1.1. 1D ONE-STEP FILTERING,[0],[0]
"However, for SSGP models, only 10 random Fourier features of a SE kernel are used.",5.1.1. 1D ONE-STEP FILTERING,[0],[0]
Figure 1 illustrates the comparison of filtered state distribution of a typical realization.,5.1.1. 1D ONE-STEP FILTERING,[0],[0]
We evaluate the methods by computing NLx (the negative log-likelihood of the ground truth samples in the filtered distribution) and RMSE (root-mean-square error between filtered mean and ground truth samples).,5.1.1. 1D ONE-STEP FILTERING,[0],[0]
See Table 3 for a detailed comparison.,5.1.1. 1D ONE-STEP FILTERING,[0],[0]
Our methods SSGP-ADF and SSGPEKF are able to offer close performance with their full GP counterparts but with greatly reduced computational cost.,5.1.1. 1D ONE-STEP FILTERING,[0],[0]
See Appendix §6.2 for further discussions on the comparison between SSGP-ADF and SSGP-EKF.,5.1.1. 1D ONE-STEP FILTERING,[0],[0]
We next consider a state estimation task in high-speed autonomous driving on a dirt track (Figure 2a).,5.1.2. RECURSIVE FILTERING,[0],[0]
The goal is to recursively estimate the state of an autonomous rallycar given noisy measurements.,5.1.2. RECURSIVE FILTERING,[0],[0]
"The vehicle state consists of linear velocities (x and y), heading rate, and roll angle, in body frame.",5.1.2. RECURSIVE FILTERING,[0],[0]
Controls are steering and throttle.,5.1.2. RECURSIVE FILTERING,[0],[0]
Measurements are collected by wheel speed sensors.,5.1.2. RECURSIVE FILTERING,[0],[0]
This filtering task is challenging because of the complex nonlinear dynamics and the amount of noise in the measurements.,5.1.2. RECURSIVE FILTERING,[0],[0]
"We do not use any prior model of the car, but learn the model from ground truth estimates of vehicle state generated by integrating GPS and IMU data via iSAM2 (Kaess et al., 2012).",5.1.2. RECURSIVE FILTERING,[0],[0]
"50,000 samples are collected from wheel speed sensors and ground truth state estimates from iSAM2 for training.",5.1.2. RECURSIVE FILTERING,[0],[0]
"Because of the sample size, it is too computationally expensive to use GP-based filter such as GP-ADF (Deisenroth et al., 2009).",5.1.2. RECURSIVE FILTERING,[0],[0]
"Instead, we use SSGP-ADF to perform 1,200 recursive filtering steps which correspond to 30 seconds of high-speed driving.",5.1.2. RECURSIVE FILTERING,[0],[0]
"Filtered distributions using 80 features are shown in Figure 2b, and Figure 2c shows the mean and twice the standard deviation of NLx over six 30 seconds driving with different number of features.",5.1.2. RECURSIVE FILTERING,[0],[0]
"Surprisingly, only need a small number of features is necessary for satisfactory results.",5.1.2. RECURSIVE FILTERING,[0],[0]
We consider the Puma-560 robotic arm and quadrotor systems with dynamics model specified by SSGPs.,5.2.1. TRACKING A MOVING TARGET,[0],[0]
For both tasks the goal is to track a moving target.,5.2.1. TRACKING A MOVING TARGET,[0],[0]
"In addition, the true system dynamics vary online, which necessitates both online optimization and model update, as we do here.",5.2.1. TRACKING A MOVING TARGET,[0],[0]
See Appendix §5.2 for detailed task descriptions.,5.2.1. TRACKING A MOVING TARGET,[0],[0]
"Results in terms of cost l(xt, ut) are shown in Figure 4.",5.2.1. TRACKING A MOVING TARGET,[0],[0]
"Figure 4a shows that our methods outperform iLQG-LD (Mitrovic et al., 2010) and AGP-iLQR (Boedecker et al., 2014).",5.2.1. TRACKING A MOVING TARGET,[0],[0]
The similarities and differences between these methods have been discussed in §4.2.,5.2.1. TRACKING A MOVING TARGET,[0],[0]
Figure 4b shows that model update is necessary and more features could improve performance.,5.2.1. TRACKING A MOVING TARGET,[0],[0]
We study the control of an autonomous car during extreme operating conditions (powerslide).,5.2.2. AUTONOMOUS DRIFTING,[0],[0]
The task is to stabilize the vehicle to a specified steady-state using purely longitudinal control during high-speed cornering.,5.2.2. AUTONOMOUS DRIFTING,[0],[0]
This problem has been studied in Velenis et al. (2010) where the authors developed a LQR control scheme based on a physics-based dynamics model.,5.2.2. AUTONOMOUS DRIFTING,[0],[0]
"We apply our MPC algorithm to this task without any prior model knowledge and 2,500 data points generated by the model in Velenis et al. (2010).",5.2.2. AUTONOMOUS DRIFTING,[0],[0]
SSGP-Lin is used for multi-step prediction.,5.2.2. AUTONOMOUS DRIFTING,[0],[0]
"Results and comparison to Velenis et al. (2010) are illustrated in Figure 3.
0",5.2.2. AUTONOMOUS DRIFTING,[0],[0]
"100 200 300 400 500
0 100 200 300 400 500
0 100 200 300 400 500",5.2.2. AUTONOMOUS DRIFTING,[0],[0]
We introduced two analytic moment-based approaches to prediction under uncertainty in sparse spectrum Gaussian processes (SSGPs).,6. Discussion and Conclusion,[0],[0]
"Compared to their full GP counterparts, our methods are more general: they are applicable to any continuous shift-invariant kernel.",6. Discussion and Conclusion,[0],[0]
"They also scale to larger datasets by leveraging random features with frequencies sampled from the spectral density of a given kernel (see Table 1, 2).",6. Discussion and Conclusion,[0],[0]
"Although we adopt the name SSGP, our proposed methods are not tied to specific model learning methods such as linear Bayesian regression (LázaroGredilla et al., 2010).",6. Discussion and Conclusion,[0],[0]
"They can be applied to any SSGP with a specified feature weight distribution (6), and α and A can be computed via different approaches.",6. Discussion and Conclusion,[0],[0]
"For example, A can be iteratively computed by methods like doubly stochastic gradient descent (Dai et al., 2014).",6. Discussion and Conclusion,[0],[0]
We studied the application of the proposed methods to Bayesian filtering and model predictive control.,6. Discussion and Conclusion,[0],[0]
Our methods directly address the challenging aspects of these problems: model uncertainty and real-time execution constraints.,6. Discussion and Conclusion,[0],[0]
We evaluated our algorithms on real-world and simulated examples and showed that SSGP-EMM (§3.1) and SSGP-Lin (§3.2) are accurate alternatives to their full GP counterparts when learning from large amounts of data.,6. Discussion and Conclusion,[0],[0]
This work was supported by NSF NRI awards 1637758 and 1426945.,Acknowledgements,[0],[0]
Sparse Spectrum Gaussian Processes (SSGPs) are a powerful tool for scaling Gaussian processes (GPs) to large datasets.,abstractText,[0],[0]
"Existing SSGP algorithms for regression assume deterministic inputs, precluding their use in many real-world robotics and engineering applications where accounting for input uncertainty is crucial.",abstractText,[0],[0]
We address this problem by proposing two analytic moment-based approaches with closed-form expressions for SSGP regression with uncertain inputs.,abstractText,[0],[0]
"Our methods are more general and scalable than their standard GP counterparts, and are naturally applicable to multi-step prediction or uncertainty propagation.",abstractText,[0],[0]
"We show that efficient algorithms for Bayesian filtering and stochastic model predictive control can use these methods, and we evaluate our algorithms with comparative analyses and both real-world and simulated experiments.",abstractText,[0],[0]
Prediction under Uncertainty in Sparse Spectrum Gaussian Processes  with Applications to Filtering and Control,title,[0],[0]
"Let f : X → R be a black-box function defined on a hypercube X = ∏D d=1[ad, bd] where D ≥ 2.",1. Introduction,[0],[0]
Without loss of generality we assume that 0 ∈ X .,1. Introduction,[0],[0]
"The objective is to find a global minimizer
x∗ = argmin x∈X f(x).",1. Introduction,[0],[0]
"(1)
We assume, as in Preferential Bayesian Optimization (PBO, González et al., 2017), that f is not directly accessible.",1. Introduction,[0],[0]
"In PBO, queries to f can done in pairs of points x,x′ ∈ X , and the binary feedback indicates whether f(x) > f(x′).",1. Introduction,[0],[0]
"In contrast, in our work we assume that queries to f are be done
1Helsinki Institute for Information Technology HIIT, Department of Computer Science, Aalto University, Espoo, Finland 2Department of Applied Physics, Aalto University, Espoo, Finland 3The University of Manchester, UK.",1. Introduction,[0],[0]
"Correspondence to: Petrus Mikkola <petrus.mikkola@aalto.fi>, Samuel Kaski <samuel.kaski@aalto.fi>.
Proceedings of the 37 th International Conference on Machine Learning, Online, PMLR 119, 2020.",1. Introduction,[0],[0]
"Copyright 2020 by the author(s).
",1. Introduction,[0],[0]
Figure 1.,1. Introduction,[0],[0]
An illustration of a projective preferential query on molecular properties: in which rotation is the molecule most likely to bind to the surface.,1. Introduction,[0],[0]
"Here, x ∈ X describes the location and orientation of a molecule as a vector x = (X,Y, Z, a, b, c).",1. Introduction,[0],[0]
"In the figure, the projective preferential query (ξ,x) finds the optimal rotation along the horizontal plane, defined by the coordinate b.",1. Introduction,[0],[0]
"This corresponds to setting ξi = 0 to all coordinates i except the one corresponding to b, and by rotating the molecule the expert then gives the optimal value α∗ that corresponds to the optimal value for coordinate b.",1. Introduction,[0],[0]
"The other coordinates are kept fixed (these are determined by x).
over the projection onto a projection vector ξ ∈ Ξ ⊂ X .",1. Introduction,[0],[0]
"The feedback is the optimal scalar projection, that is, the length α∗ of the projection in the direction ξ.",1. Introduction,[0],[0]
"We assume that there are zero coordinates in ξ, and these coordinates are set to fixed values described by a reference vector x ∈ X .",1. Introduction,[0],[0]
"Formally, given a query (ξ,x), the feedback is obtained as a minimizer over the possible scalar projections,
α∗ = argmin α∈Iξ f(αξ + x), (2)
where Iξ ≡ {α ∈ R|αξ + x ∈ X}.
",1. Introduction,[0],[0]
What are then natural use cases for such projective preferential queries?,1. Introduction,[0],[0]
The main motivation comes from humans serving as the oracles.,1. Introduction,[0],[0]
"The form of the query enables efficient learning of user preferences over choice sets in which each choice has multiple attributes, and in particular over continuous choice sets.",1. Introduction,[0],[0]
"An important application is knowledge elicitation from trained professionals (doctors, physi-
ar X
iv :2
00 2.
03 11
3v 4
[ st
at .M
L ]
1 4
A ug
2 02
0
cists, etc.).",1. Introduction,[0],[0]
"For example, we may learn a material scientists preferences, that is, insight based on prior knowledge and experience, over molecular translations and orientations as a molecule adsorbs to a surface.",1. Introduction,[0],[0]
"In this case, a projective preferential query could correspond to finding an optimal rotation (see Figure 1), which the scientists can easily give by rotating the molecule in a visual interface.
",1. Introduction,[0],[0]
"Probabilistic preference learning is a relatively new topic in machine learning research but has a longer history in econometrics and psychometrics (McFadden, 1981; 2001; Stern, 1990; Thurstone, 1927).",1. Introduction,[0],[0]
"A wide range of applications of these models exists, for instance in computer graphics (Brochu et al., 2010), expert knowledge elicitation (Soufiani et al., 2013), revenue management systems of airlines (Carrier & Weatherford, 2015), rating systems, and almost any application that contains users’ preference modeling.",1. Introduction,[0],[0]
"An established probabilistic model is Thurstone-Mosteller (TM) model that measures a process of pairwise comparisons (Thurstone, 1927; Mosteller, 1951).",1. Introduction,[0],[0]
"In the preference learning context, the models based on the TM-model can be applied to learning preferences from pairwise comparison feedback (e.g. Chu & Ghahramani, 2005).",1. Introduction,[0],[0]
"An extension of this research into the interactive learning setting is studied by, among others, Brochu et al. (2008) and González et al. (2017).",1. Introduction,[0],[0]
All these approaches resort to pairwise feedbacks.,1. Introduction,[0],[0]
Koyama et al. (2017) proposed an extension of Bayesian optimization for learning optimal parameter values for visual design tasks by letting a user give feedback as a slider manipulation.,1. Introduction,[0],[0]
"They considered only two pairwise comparisons per slider since they tested to “included more sampling points” but they “did not observe any significant improvement in the optimization behavior”.
",1. Introduction,[0],[0]
A drawback of most preference learning frameworks is their incapability to handle high-dimensional input spaces.,1. Introduction,[0],[0]
"The underlying reason is a combinatorial explosion in the number of possible comparisons with respect to the number of dimensions D, O(K2D), given K grid-points per dimension.",1. Introduction,[0],[0]
This implies that a single pairwise comparison has low information content in high-dimensional spaces.,1. Introduction,[0],[0]
This problem was mitigated by González et al. (2017) by capturing the correlations among pairs of queries (duels).,1. Introduction,[0],[0]
"However, it is still difficult to scale that method to high-dimensional spaces, say higher than 2-dimensional (see Section 4).",1. Introduction,[0],[0]
"Furthermore, the numerical computations become infeasible in a high-dimensional setting, especially the optimization of an acquisition function or finding a Condorcet winner.
",1. Introduction,[0],[0]
"In this paper, we introduce a Bayesian framework, which we call Projective Preferential Bayesian Optimization (PPBO), that scales to high-dimensional input spaces.",1. Introduction,[0],[0]
A main reason is that the information content of a projective preferential query is much higher than that of a pairwise preferential query.,1. Introduction,[0],[0]
"A projective preferential query is equiv-
alent to infinite pairwise comparisons along a projection.",1. Introduction,[0],[0]
"An important consequence is that with projective preferential queries, the user’s workload in answering the queries will be considerably reduced.",1. Introduction,[0],[0]
Source code is available at https://github.com/AaltoPML/PPBO.,1. Introduction,[0],[0]
In this section we introduce a Bayesian framework capable of dealing with projective preferential data.,2. Learning preferences from projective preferential feedback,[0],[0]
"A central idea is to model the user’s utility function, that is f , as a Gaussian process as first proposed by Chu & Ghahramani (2005).",2. Learning preferences from projective preferential feedback,[0],[0]
"We extend this line of study to allow projective preferential queries, by deriving a tractable likelihood, proposing a method to approximate it, and introducing four acquisition criteria for enabling interactive learning in this setting.
",2. Learning preferences from projective preferential feedback,[0],[0]
"In this paper, for convenience, we will formulate the method for maximization instead of minimization as in (2), without loss of generality.",2. Learning preferences from projective preferential feedback,[0],[0]
"Our probabilistic model of user preferences is built upon the Thurstone’s law of comparative judgement (Thurstone, 1927).",2.1. Likelihood,[0],[0]
"A straightforward way to formalize this would be to assume pairwise comparisons are corrupted by Gaussian noise: x x′, if and only if f(x) + ε > f(x′) + ε′, where the latent function f is a utility function that characterizes user preferences described by the preference relation .",2.1. Likelihood,[0],[0]
The standard assumption is that ε and ε′ are identically and independently distributed Gaussians.,2.1. Likelihood,[0],[0]
"Here, we deviate slightly from this assumption:",2.1. Likelihood,[0],[0]
"Given two alternatives (αξ + x), (βξ+x) ∈ X , we assume that αξ+x βξ+x, if and only if f(αξ + x) +W (α) > f(βξ + x) +W (β), where W is a Gaussian white noise process with zeromean and autocorrelation E(W (t)W (t+ τ))",2.1. Likelihood,[0],[0]
"= σ2 if τ = 0, and zero otherwise.
",2.1. Likelihood,[0],[0]
"We would like to find the likelihood for an observation (α, (ξ,x)) that corresponds to uncountably infinite pairwise comparisons: αξ+x βξ+x for β 6= α.",2.1. Likelihood,[0],[0]
"For each comparison we condition on W (α) (more details in Supplementary material),
P (αξ + x βξ + x |W (α) = w) = 1− Φ ( f(βξ + x)−",2.1. Likelihood,[0],[0]
f(αξ,2.1. Likelihood,[0],[0]
"+ x)− w
σ
) ,
where Φ is the cumulative distribution function of the standard normal distribution.",2.1. Likelihood,[0],[0]
"For a single comparison we have
P (αξ + x βξ + x) = 1−",2.1. Likelihood,[0],[0]
"[Φ ∗ φ] ( f(βξ + x)− f(αξ + x)
σ
) ,
where φ is the probability density of the standard normal distribution and ∗ is the convolution operator.",2.1. Likelihood,[0],[0]
"For infinite comparisons, we first consider a finite number of comparisons m. By their independence, we have
P (αξ + x β1ξ",2.1. Likelihood,[0],[0]
+,2.1. Likelihood,[0],[0]
"x, ..., αξ + x βmξ + x)
= m∏ j=1 ( 1− [Φ ∗ φ] ( f(βjξ + x)− f(αξ + x) σ )) .
",2.1. Likelihood,[0],[0]
"By letting the number of points m in an increasing sequence β1, ..., βm of the partition of the interval Iξ\{α} to approach infinity, we can interpret this as a Volterra (product) integral
exp",2.1. Likelihood,[0],[0]
( − ∫ Iξ,2.1. Likelihood,[0],[0]
[Φ ∗ φ] (f(βξ + x)− f(αξ + x) σ ),2.1. Likelihood,[0],[0]
"dβ ) .
",2.1. Likelihood,[0],[0]
"The joint log-likelihood of a dataset D, denoted as L(D|f), takes the form
− N∑ i=1",2.1. Likelihood,[0],[0]
∫,2.1. Likelihood,[0],[0]
Iξi,2.1. Likelihood,[0],[0]
[Φ ∗ φ] (f(βξi + xi)−,2.1. Likelihood,[0],[0]
f(αiξi + xi) σ ),2.1. Likelihood,[0],[0]
dβ.,2.1. Likelihood,[0],[0]
"First, we introduce notation.",2.2. Prior,[0],[0]
"Assume that N projective preferential queries have been performed and gathered into a dataset D = {(αi, (ξi,xi))}Ni=1.",2.2. Prior,[0],[0]
"For every data instance (αi, (ξi,xi)), we also consider a sequence of pseudoobservations {(βijξ
i,xi)}mj=1.",2.2. Prior,[0],[0]
"Technically, the pseudoobservations are Monte-Carlo samples needed for integrating the likelihood.",2.2. Prior,[0],[0]
"The latent function values evaluated on those points are gathered into a vector,
f (i) ≡",2.2. Prior,[0],[0]
"( f(αiξi + xi), {f(βijξ i + xi)}mj=1 ) .
",2.2. Prior,[0],[0]
The latent function vector over all points is formed by concatenating over f ≡,2.2. Prior,[0],[0]
"(f (i))Ni=1.
",2.2. Prior,[0],[0]
"The user’s utility function f is modelled as a Gaussian process (Rasmussen & Williams, 2005).",2.2. Prior,[0],[0]
"GP model fits ideally to this objective, since it is flexible (non-parametric) and can conveniently handle uncertainty (predictive distributions can be derived analytically).",2.2. Prior,[0],[0]
"In particular, it allows us to have insight into those regions of the space X in which either we are uncertain about user preferences due to lack of data, or because the user gives inconsistent feedback.",2.2. Prior,[0],[0]
"A possible reason for the latter is that one of the preference axioms, transitivity or completeness, is violated in those regions.",2.2. Prior,[0],[0]
"A weak preference relation is complete if for all x,y ∈ X , either x y or y x holds.",2.2. Prior,[0],[0]
"That is, a user is able to reveal their preferences over all possible pairwise comparisons.",2.2. Prior,[0],[0]
"Similarly, is transitive if for any x,y, z ∈ X",2.2. Prior,[0],[0]
the following holds: (x y and y z) implies that,2.2. Prior,[0],[0]
x z.,2.2. Prior,[0],[0]
"That is, a user has consistent preferences.",2.2. Prior,[0],[0]
"This together
with the continuity of guarantees the existence of a realvalued continuous utility function that represents (Debreu, 1954).
",2.2. Prior,[0],[0]
"Thus, we assume as Chu & Ghahramani (2005), that the prior of the utility function follows a zero-mean Gaussian process,
p(f)",2.2. Prior,[0],[0]
"= 1
(2π) N 2 |Σ| 12 exp(−1 2 f>Σ−1f),
where the ijth-element of the covariance matrix is determined by a kernel k as Σij = k(xi,xj).",2.2. Prior,[0],[0]
"Throughout the paper, we assume the squared exponential kernel k(x,x) = σ2f exp( 1 −2l ‖x− x
′‖2), where the σf and l are hyperparameters.",2.2. Prior,[0],[0]
"For the sake of simplicity, we use the Laplace approximation for the posterior distribution.",2.3. Posterior,[0],[0]
"A maximum a posteriori (MAP) estimate is needed for that,
argmax f P(f |D) = argmax f (P(f)L(D|f))",2.3. Posterior,[0],[0]
= argmax f T,2.3. Posterior,[0],[0]
"(f),
where we denote the functional (log-scaled posterior)
T (f) ≡ −1",2.3. Posterior,[0],[0]
"2 f>Σ−1f
− N∑ i=1",2.3. Posterior,[0],[0]
∫,2.3. Posterior,[0],[0]
Iξi,2.3. Posterior,[0],[0]
[Φ ∗ φ] (f(βξi + xi)−,2.3. Posterior,[0],[0]
f(αiξi + xi) σ ),2.3. Posterior,[0],[0]
"dβ.
",2.3. Posterior,[0],[0]
The convolution Φ ∗ φ can be efficiently approximated by Gauss-Hermite quadrature.,2.3. Posterior,[0],[0]
"The outer integral is approximated as a Monte-Carlo integral,∫ Iξ",2.3. Posterior,[0],[0]
[Φ ∗ φ] (f(βξ + x)− f(αξ + x) σ ),2.3. Posterior,[0],[0]
"dβ
≈ `(Iξ) m m∑ j=1",2.3. Posterior,[0],[0]
"[Φ ∗ φ] (f(βjξ + x)− f(αξ + x) σ ) ,
where the pseudo-observations (βjξ)mj for j = 1, ...,m are sampled from a suitable distribution.",2.3. Posterior,[0],[0]
"Our choice is to use a family of truncated generalized normal (TGN) distributions, since it provides a continuous transformation from the uniform distribution to the truncated normal distribution, such that the locations of distributions can be specified.",2.3. Posterior,[0],[0]
The idea is to concentrate pseudo-observations more densely around the optimal value αξ as the number of queries increases.,2.3. Posterior,[0],[0]
"For more details, see Supplementary material.
",2.3. Posterior,[0],[0]
"For notational convenience, define
∆i,j(f) ≡",2.3. Posterior,[0],[0]
f(βijξ,2.3. Posterior,[0],[0]
i + xi)−,2.3. Posterior,[0],[0]
"f(αiξi + xi) σ .
",2.3. Posterior,[0],[0]
"If the domain is normalized to X = ∏D d=1[0, 1], and the projections are normalized to ξ = ξ‖ξ‖∞ , then `(Iξ) = 1.",2.3. Posterior,[0],[0]
"Hence, under this normalization, the functional T can be approximated as
T (f)",2.3. Posterior,[0],[0]
≈ −1 2 f>Σ−1f,2.3. Posterior,[0],[0]
− 1 m N∑ i=1,2.3. Posterior,[0],[0]
m∑ j=1,2.3. Posterior,[0],[0]
"[Φ ∗ φ] ( ∆i,j(f) ) .
",2.3. Posterior,[0],[0]
"The MAP estimate can be efficiently solved by a secondorder iterative optimization algorithm, since the gradient and the Hessian can be easily derived for T .
",2.3. Posterior,[0],[0]
The Laplace approximation of the posterior amounts to the second-order Taylor approximation of the log posterior around the MAP estimate.,2.3. Posterior,[0],[0]
"In the ordinary (non-log) scale, this reads P(f |D)",2.3. Posterior,[0],[0]
"≈ P(fMAP|D) exp ( − 1
2 (f − fMAP)>H(f − fMAP)
) ,
where the matrix H is the negative Hessian of the log-posterior at the MAP estimate, H ≡ −∇∇ log P(f |D)|f=fMAP =",2.3. Posterior,[0],[0]
Σ−1,2.3. Posterior,[0],[0]
"+ Λ.1 In other words, the posterior distribution is approximated as a multivariate normal distribution with mean fMAP and the covariance matrix (Σ−1 + Λ)−1.",2.3. Posterior,[0],[0]
"Based on the well-known properties of the multivariate Gaussian distribution, the predictive distribution of f is also Gaussian.",2.4. Predictive distribution,[0],[0]
"Given test locations (y(1), ...,y(M)), consider the N by M matrix K ≡",2.4. Predictive distribution,[0],[0]
"[k(y(j),x(i))]ij .",2.4. Predictive distribution,[0],[0]
"The predictive mean and the predictive covariance at test locations are (for more details see (Rasmussen & Williams, 2005) or (Chu & Ghahramani, 2005))
µpred = K >Σ−1fMAP Σpred = Σ ′ −K>(Σ + Λ−1)−1K,
where Σ′ is the covariance matrix of the test locations.",2.4. Predictive distribution,[0],[0]
"In this section, we discuss how to select the next projective preferential query (ξ,x).",3. Sequential learning by projective preferential query,[0],[0]
"We will choose the next query as a maximizer of an acquisition function α(ξ,x), for instance, we will consider a modified version of the expected
1We denote the partial derivatives matrix evaluated at MAP estimate as
Λ ≡ ∂ 2 ∂f∂f> 1 m N∑ i=1",3. Sequential learning by projective preferential query,[0],[0]
m∑ j=1,3. Sequential learning by projective preferential query,[0],[0]
"[Φ ∗ φ] ( ∆i,j(f) )∣∣∣∣ f=fMAP .
",3. Sequential learning by projective preferential query,[0],[0]
"improvement acquisition function (Jones et al., 1998).",3. Sequential learning by projective preferential query,[0],[0]
"The optimization (ξ,x)next = argmax(ξ,x) α(ξ,x) is carried out by using Bayesian optimization (more details in Supplementary material).
",3. Sequential learning by projective preferential query,[0],[0]
"If the oracle is a human, this allows us to learn user preferences in an iterative loop, making PPBO interactive.",3. Sequential learning by projective preferential query,[0],[0]
"However, this interesting special case, where f is a utility function of a human, also brings forth issues due to bounded rationality.",3. Sequential learning by projective preferential query,[0],[0]
"We apply here the following narrow definition of this more general concept (see Simon, 1990):",3. Sequential learning by projective preferential query,[0],[0]
"Bounded rationality is the idea that users give feedback that reflects their preferences, but within the limits of the information available to them and their mental capabilities.",3. Sequential learning by projective preferential query,[0],[0]
"If the oracle is a human, it is important to realize that the optimal next (ξ,x) is not solely the one which optimally balances the exploration-exploitation trade-off – as it is for a perfect oracle – but the optimal (ξ,x) takes also into account human cognitive capabilities and limitations.",3.1. The effects of bounded rationality on the optimal next query,[0],[0]
"For instance, the more there are non-zero coordinates in ξ, the greater the “cognitive burden” to a human user, and the harder it becomes to give useful feedback.",3.1. The effects of bounded rationality on the optimal next query,[0],[0]
"Thus, if there is a human in the loop, the choice of ξ should take into account both the optimization needs and what types of queries are convenient for the user.
",3.1. The effects of bounded rationality on the optimal next query,[0],[0]
"The projective preferential feedback (2) may not be singlevalued or even well-defined for all ξ ∈ Ξ, if the oracle is a human.",3.1. The effects of bounded rationality on the optimal next query,[0],[0]
"For instance, the user may not be able to explicate their preferences with respect to the dth attribute, that is, the preferences do not satisfy the completeness axiom.",3.1. The effects of bounded rationality on the optimal next query,[0],[0]
"Formally, this means that if ξ = ed (the dth-standard unit vector), then for some x ∈ X it holds that argmaxα∈Iξ f(αξ + x) is multi-valued, a random variable or not well-defined – depending on how we interpret the scenario in which the user should say “I do not know” but instead gives an arbitrary feedback.",3.1. The effects of bounded rationality on the optimal next query,[0],[0]
"Fortunately, this incompleteness can be easily handled when a GP is used for modelling f ; it just implies that the posterior variance is high along the dimension d.
A possible solution would be to allow the answer “I do not know”, and to design an acquisition function that is capable of discovering and avoiding those regions in the space X where the user gives inconsistent feedback due to any source of bounded rationality.",3.1. The effects of bounded rationality on the optimal next query,[0],[0]
This challenge is left for future research.,3.1. The effects of bounded rationality on the optimal next query,[0],[0]
"It is noteworthy that the acquisition function we introduce next, performed well in the user experiment covered in Section 5.",3.1. The effects of bounded rationality on the optimal next query,[0],[0]
"We define the expected improvement by projective preferential query at the nth-iteration by
EIn(ξ,x) ≡",3.2. Expected improvement by projective preferential query,[0],[0]
"En ( max {
max α∈Iξ
f(αξ + x)− µ∗n, 0 }) , (3)
where µ∗n denotes the highest value of the predictive posterior mean, and the expectation is conditioned on the data up to the nth-iteration.",3.2. Expected improvement by projective preferential query,[0],[0]
"The maximum over α models the anticipated feedback.
",3.2. Expected improvement by projective preferential query,[0],[0]
"EIn can be approximated as a Monte-Carlo integral (up to a multiplicative constant that does not depend on (ξ,x)),
1
K K∑ k=1 max { max α∈Iξ f̃k(αξ + x)− µ∗n, 0 } , (4)
where maxα∈Iξ f̃k(αξ + x) is approximated by using discrete2 Thompson sampling as described in (HernándezLobato et al., 2014).",3.2. Expected improvement by projective preferential query,[0],[0]
"Discrete Thompson sampling draws a finite sample from the GP posterior distribution, and then returns the maximum over the sample.",3.2. Expected improvement by projective preferential query,[0],[0]
"The steps needed to approximate EIn are summarized in Algorithm 1.
",3.2. Expected improvement by projective preferential query,[0],[0]
"Algorithm 1 Approximate EIn(ξ,x) input (ξ,x) and K ≥ 1, J ≥ 1
1.",3.2. Expected improvement by projective preferential query,[0],[0]
"Compute (Σ + Λ−1)−1 for k = 1, 2, ...,K do 2.",3.2. Expected improvement by projective preferential query,[0],[0]
Draw (βj)Jj=1 3.,3.2. Expected improvement by projective preferential query,[0],[0]
Draw ( f̃(βjξ +x) ),3.2. Expected improvement by projective preferential query,[0],[0]
"J j=1
from the predictive distribution N ( µpred,Σpred ) 4.",3.2. Expected improvement by projective preferential query,[0],[0]
zk ← maxj {( f̃(βjξ + x) ),3.2. Expected improvement by projective preferential query,[0],[0]
"J j=1
} end for
output 1K ∑K k=1 max {",3.2. Expected improvement by projective preferential query,[0],[0]
"zk − µ∗n, 0 }",3.2. Expected improvement by projective preferential query,[0],[0]
The bottlenecks are the first and the third steps.,3.2. Expected improvement by projective preferential query,[0],[0]
"In the third step, a predictive covariance matrix of size J×J needs to be computed, and then a sample from the multivariate normal distribution needs to be drawn.",3.2. Expected improvement by projective preferential query,[0],[0]
"Hence, the time complexity of Algorithm 1 is O(N3m3 +KN2m2J +KNmJ2 + KJ3), where the terms come from a matrix inversion (the first step), two matrix multiplications, and a Cholesky decomposition, respectively.",3.2. Expected improvement by projective preferential query,[0],[0]
"Recall that N,m,K and J refer to the number of observations, pseudo-observations, MonteCarlo samples, and grid points, respectively.
2Another alternative is to consider continuous Thompson sampling to draw a continuous sample path from the GP model, and then maximize it.",3.2. Expected improvement by projective preferential query,[0],[0]
The method is based on Bochner’s theorem and the equivalence between a Bayesian linear model with random features and a Gaussian process.,3.2. Expected improvement by projective preferential query,[0],[0]
"For more details see (HernándezLobato et al., 2014).",3.2. Expected improvement by projective preferential query,[0],[0]
In the experiments we use pure exploration and exploitation as baselines.,3.3. Pure exploitation and exploration,[0],[0]
"A natural interpretation of pure exploitation in our context is to select the next query (ξ,x) such that ξ + x = x∗ ≡ argmaxx′∈X µn(x′), where µn(x′) is the posterior mean of the GP model at location x′, given all the data so far Dn.
",3.3. Pure exploitation and exploration,[0],[0]
"We interpret pure exploration as maximization of the GP variance on a query (ξ,x) given the anticipated feedback.",3.3. Pure exploitation and exploration,[0],[0]
"That is, the pure explorative acquisition strategy maximizes the following acquisition function
Explore(ξ,x) ≡",3.3. Pure exploitation and exploration,[0],[0]
"Vn (
max α∈Iξ
f(αξ + x) ) .",3.3. Pure exploitation and exploration,[0],[0]
"(5)
In practice, (5) is approximated by Monte-Carlo integration and discrete Thompson sampling in the same vein as in Algorithm 1.",3.3. Pure exploitation and exploration,[0],[0]
"The fourth acquisition strategy corresponds to the interesting special case where ξ = ed (the dth-standard unit vector), and the coordinates d are rotated in a cyclical order for each query.",3.4. Preferential coordinate descent (PCD),[0],[0]
"The reference vector x = (x1, ..., xd−1, 0, xd+1, ..., xD) can be chosen in several ways, but it is natural to consider an exploitative strategy in which x is set to x∗ except for the dth-coordinate which is set to zero.",3.4. Preferential coordinate descent (PCD),[0],[0]
"We call this acquisition strategy Preferential Coordinate Descent (PCD), since PPBO with PCD acquisition is closely related to a coordinate descent algorithm that successively minimizes an objective function along coordinate directions.",3.4. Preferential coordinate descent (PCD),[0],[0]
"The PPBO method with PCD acquisition (PPBO-PCD) differs from the classical coordinate descent in two ways: First, PPBO-PCD assumes that direct function evaluations are not possible but instead projective preferential queries are.",3.4. Preferential coordinate descent (PCD),[0],[0]
"Second, it models the black-box function f (as a GP) whereas the classical coordinate descent does not.",3.4. Preferential coordinate descent (PCD),[0],[0]
"This makes PPBO-PCD able to take advantage of past queries from every one-dimensional optimization.
",3.4. Preferential coordinate descent (PCD),[0],[0]
"When comparing to other acquisition strategies, we show that PCD performs well in numerical experiments (when f is not a utility function but a numerical test function).",3.4. Preferential coordinate descent (PCD),[0],[0]
"This agrees with the results in the optimization literature; for instance: if f is pseudoconvex with continuous gradient, and X is compact and convex with “nice boundary”, then the coordinate descent algorithm converges to a global minimum (Spall, 2012, Corollary 3.1).",3.4. Preferential coordinate descent (PCD),[0],[0]
"However, PCD may not perform so well in high-dimensional spaces, since it cannot query in between the dimensions.",3.4. Preferential coordinate descent (PCD),[0],[0]
"For instance, the expected improvement by projective preferential query outperformed PCD on a 20D test function (see Section 4), since it allows to query arbitrary projections.",3.4. Preferential coordinate descent (PCD),[0],[0]
"In this section we demonstrate the efficiency of the PPBO method in high-dimensional spaces, and experiment with various acquisition strategies in numerical experiments on simulated functions.
",4. Numerical experiments,[0],[0]
The goal is to find a global minimum of a black-box function f by querying it either through (i) pairwise comparisons or (ii) projective preferential queries.,4. Numerical experiments,[0],[0]
"For (i) we use the PBO method of González et al. (2017), which is state of the art among Gaussian process preference learning frameworks that are based on pairwise comparisons.",4. Numerical experiments,[0],[0]
For (ii) we use the PPBO method as introduced in this paper.,4. Numerical experiments,[0],[0]
"The four different acquisition strategies introduced in Section 3 are compared against the baseline that samples a random (ξ,x).",4. Numerical experiments,[0],[0]
"For the PBO method, we consider a random and a duelingThompson sampling acquisition strategies.",4. Numerical experiments,[0],[0]
"In total seven different methods are compared: the expected improvement by projective preferential query (PPBO-EI), pure exploitation (PPBO-EXT), pure exploration (PPBO-EXR), preferential coordinate descent (PPBO-PCD), random (PPBO-RAND), and for the PBO; random (PBO-RAND) and a variant of dueling-Thompson sampling (PBO-DTS).",4. Numerical experiments,[0],[0]
"For more details, see Supplementary material.
",4. Numerical experiments,[0],[0]
"For f we consider four different test functions: Six-humpcamel2D, Hartmann6D, Levy10D and Ackley20D.3 We add a small Gaussian error term to the test function outputs.",4. Numerical experiments,[0],[0]
There are as many initial queries as there are dimensions in a test function.,4. Numerical experiments,[0],[0]
"The ith-initial query corresponds to ξ = ei, that is, to the ith-coordinate projection, and the reference vector x is uniformly random.",4. Numerical experiments,[0],[0]
We consider a total budget of 100 queries.,4. Numerical experiments,[0],[0]
"The results are depicted in Figure 2.4
PPBO-PCD obtained the best performance on three of the four test functions.",4. Numerical experiments,[0],[0]
"On the high-dimensional test function Ackley20D, PPBO-EI performed best.",4. Numerical experiments,[0],[0]
"Unsurprisingly, all PPBO variants clearly outperformed all PBO variants.",4. Numerical experiments,[0],[0]
"Since the performance gap between PPBO-RAND and PBO-RAND is so high, we conclude that from the optimization perspective; whenever a projective preferential query is possible, a PPBO-type of approach should be preferred to an approach that is based on pairwise comparisons.",4. Numerical experiments,[0],[0]
"However, we note that it is better to think of PPBO as a complement, not as a substitute for PBO.",4. Numerical experiments,[0],[0]
"In the applications, pairwise comparisons may be preferred, for instance, if they are more convenient to a user, and the underlying choice space is low-dimensional.
",4. Numerical experiments,[0],[0]
"To illustrate the low information content of pairwise comparisons, we ran a test on the Six-hump-camel2D function.
",4. Numerical experiments,[0],[0]
3https://www.sfu.ca/∼ssurjano/optimization.html 4All experiments of each test function were run on a computing infrastructure of 24x Xeon Gold 6148 2.40GHz cores and 72GB RAM.,4. Numerical experiments,[0],[0]
"The longest experiment (Ackley20D) took in total 24h.
",4. Numerical experiments,[0],[0]
"We trained a GP classifier with 2000 random queries (duels), and found a Condorcet winner (see González et al., 2017) by maximizing the soft-Copeland score (33 × 33 MC-samples used for the integration) by using Bayesian optimization (500 iterations with 10 optimization restarts).",4. Numerical experiments,[0],[0]
"This took 41 minutes on the 8th-gen Intel i5-CPU, and the distance to a true global minimizer was ‖xc − xtrue‖ = ‖(0.1770,−0.0488)− (0.0898,−0.7126)‖ ≈ 0.67, and the corresponding function value was 0.1052 compared to a true global minimum value −1.0316.",4. Numerical experiments,[0],[0]
"In contrast, PPBORAND reached this level of accuracy at the first queries, as seen from Figure 2.",4. Numerical experiments,[0],[0]
"In this section we demonstrate the capability of PPBO to correctly and efficiently encode user preferences from projective preferential feedback.
",5. User experiment,[0],[0]
We consider a material science problem of a single organic molecule adsorbing to an inorganic surface.,5. User experiment,[0],[0]
"This is a key step in understanding the structure at the interface between organic and inorganic films inside electronic devices, coatings, solar cells and other materials of technological relevance.",5. User experiment,[0],[0]
"The molecule can bind in different adsorption configurations, altering the electronic properties at the interface and affecting device performance.",5. User experiment,[0],[0]
Exploring the structure and property phase space of materials with accurate but costly computer simulations is a difficult task.,5. User experiment,[0],[0]
Our objective is to find the most stable surface adsorption configuration through human intuition and subsequent computer simulations.,5. User experiment,[0],[0]
"The optimal configuration is the one that minimises the computed adsorption energy.
",5. User experiment,[0],[0]
"Our test case is the adsorption of a non-symmetric, bulky molecule camphor on the flat surface of (111)-plane terminated Cu slab.",5. User experiment,[0],[0]
Some understanding of chemical bonding is required to infer correct adsorption configurations.,5. User experiment,[0],[0]
The user is asked to consider the adsorption structure as a function of molecular orientation and translation near the surface.,5. User experiment,[0],[0]
"These are represented with 6 physical variables: angles α, β, γ of molecular rotation around the X, Y, Z Cartesian axes (in the range",5. User experiment,[0],[0]
"[0, 360] deg.), and distances x, y, z of translation above the surface (with lattice vectors following the translational symmetry of the surface).",5. User experiment,[0],[0]
The internal structures of the molecule and surface were kept fixed since little structural deformation is expected with adsorption.,5. User experiment,[0],[0]
"A similar organic/inorganic model system and experiment scenario was previously employed to detect the most stable surface structures with autonomous BO, given the energies of sampled configurations (Todorović et al., 2019).
",5. User experiment,[0],[0]
"In this interactive experiment, the users encode their preferred adsorption geometry as a location in the 6- dimensional phase space.",5. User experiment,[0],[0]
"We employ the quantum-
mechanical atomistic simulation code FHI-aims (Blum et al., 2009) to i) compute the adsorption energy E of this preferred choice, and ii) optimise the structure from this initial position to find the nearest local energy minimum in phase space, E*.",5. User experiment,[0],[0]
"We also consider the number of optimization steps N needed to reach the nearest minimum as a measure of quality of the initial location.
",5. User experiment,[0],[0]
"There are four different test users: two materials science experts (human: a PhD student and an experienced researcher, both of them know the optimal solution), a non-expert (human), and a random bot (computer).",5. User experiment,[0],[0]
The hypothesis is that: the materials science experts should obtain structures associated with lower energy minimum points.,5. User experiment,[0],[0]
"We consider only coordinate projections, that is ξ ∈ {e1, ..., e6}.",5. User experiment,[0],[0]
"In other words, we let the user choose the optimal value for one dimension at a time.
",5. User experiment,[0],[0]
"The total number of queries was 24, of which 6 were initial queries.",5. User experiment,[0],[0]
"The ith-initial query corresponded to ξ = ei, that is, to the ith-coordinate projection.",5. User experiment,[0],[0]
The initial values for the reference coordinate vector x were fixed to the same value across all user sessions.,5. User experiment,[0],[0]
"For acquisition, we used the expected improvement by projective preferential query.",5. User experiment,[0],[0]
"Since we allowed only coordinate projections for ξ, we first selected ξn+1 =",5. User experiment,[0],[0]
"argmaxξ∈{e1,...,e6} ∫ EIn(ξ,x)dx,
and then, either xn+1",5. User experiment,[0],[0]
"= argmaxx µn(x) (EI-EXT), or the next xn+1 was drawn uniformly at random (EI-RAND).",5. User experiment,[0],[0]
"The computer bot gave random values to the queries; to provide some consistency to the bot, xn+1 was selected by maximizing a standard expected improvement function (EI-EI).",5. User experiment,[0],[0]
"The results are summarized in Table 1.
",5. User experiment,[0],[0]
Our first observation is that PPBO can distinguish between the choices made by a human and a computer bot.,5. User experiment,[0],[0]
"Human choices pinpoint atomic arrangements that are close to nearby local minima (small N), while the random bot’s choices are far less reasonable and require much subsequent computation to optimise structures.",5. User experiment,[0],[0]
"For all human users, the preferred molecular structures were placed somewhat high above the surface, which led to relatively high E values.",5. User experiment,[0],[0]
"With this query arrangement, it appears the z variable was the most difficult one to estimate visually.",5. User experiment,[0],[0]
"Human-preferred molecular orientations were favourable, so the structures were optimised quickly (few N steps).
",5. User experiment,[0],[0]
"The quality of user preference is best judged by the depth of the nearest energy basin, denoted by E*.",5. User experiment,[0],[0]
It describes the energy of the structure preferred by a user.,5. User experiment,[0],[0]
"Here, there is a marked divide by expertise.",5. User experiment,[0],[0]
"The structures refined from the choices of the bot and non-expert are local minima of adsorption, characterised by weak dispersive interactions.
",5. User experiment,[0],[0]
"The expert’s choice led to two low-energy structure types that compete for the global minimum, and feature strong chemical bonding of the O atom to the Cu surface.",5. User experiment,[0],[0]
"Thus, the data (Table 1, column E*: rows 1-4 versus rows 5-10) supports our hypothesis: the materials science experts do obtain structures associated with lower energy minimum points.
",5. User experiment,[0],[0]
The findings above demonstrate that the PPBO framework was able to encode the expert knowledge described via preferences.,5. User experiment,[0],[0]
"However, since there are only 10 samples, further work will be needed to validate the results.",5. User experiment,[0],[0]
"In this paper we have introduced a new Bayesian framework, PPBO, for learning user preferences from a special kind of feedback, which we call projective preferential feedback.",6. Conclusions,[0],[0]
The feedback is equivalent to a minimizer along a projection.,6. Conclusions,[0],[0]
Its form is especially applicable in a human-in-the-loop context.,6. Conclusions,[0],[0]
We demonstrated this in a user experiment in which the user gives the feedback as an optimal position or orientation of a molecule adsorbing to a surface.,6. Conclusions,[0],[0]
"PPBO was capable of encoding user preferences in this case.
",6. Conclusions,[0],[0]
"We demonstrated that PPBO can deal with high-dimensional spaces where existing preferential Bayesian optimization frameworks that are based on pairwise comparisons, such as IBO (Brochu, 2010) or PBO (González et al., 2017), have difficulties to operate.",6. Conclusions,[0],[0]
"In the numerical experiments, the performance gap between PPBO and PBO was so high that we conclude: whenever a projective preferential query is possible, a PPBO-type of approach is preferable from the optimization perspective.",6. Conclusions,[0],[0]
"However, we note that it is better to think of PPBO as a complement, not as a substitute for
PBO.",6. Conclusions,[0],[0]
"In the applications, pairwise comparisons may be preferred, for instance, if they are more convenient to a user.
",6. Conclusions,[0],[0]
"In summary, if it is possible to query a projective preferential query, then PPBO provides an efficient way for preference learning in high-dimensional problems.",6. Conclusions,[0],[0]
"In particular, PPBO can be used for efficient expert knowledge elicitation in highdimensional settings which are important in many fields.",6. Conclusions,[0],[0]
"This research was supported by the Academy of Finland (Flagship programme: Finnish Center for Artificial Intelligence FCAI; and grants 320181, 319264, 313195, 292334 and 316601).",Acknowledgements,[0],[0]
"Computational resources were provided by the CSC IT Center for Science, and the Aalto Science-IT Project.",Acknowledgements,[0],[0]
Bayesian optimization is an effective method for finding extrema of a black-box function.,abstractText,[0],[0]
We propose a new type of Bayesian optimization for learning user preferences in high-dimensional spaces.,abstractText,[0],[0]
"The central assumption is that the underlying objective function cannot be evaluated directly, but instead a minimizer along a projection can be queried, which we call a projective preferential query.",abstractText,[0],[0]
"The form of the query allows for feedback that is natural for a human to give, and which enables interaction.",abstractText,[0],[0]
This is demonstrated in a user experiment in which the user feedback comes in the form of optimal position and orientation of a molecule adsorbing to a surface.,abstractText,[0],[0]
"We demonstrate that our framework is able to find a global minimum of a high-dimensional black-box function, which is an infeasible task for existing preferential Bayesian optimization frameworks that are based on pairwise comparisons.",abstractText,[0],[0]
Projective Preferential Bayesian Optimization,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1160–1170 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1160",text,[0],[0]
"Greibach normal form (GNF; Greibach, 1965) is an important construction in formal language theory which allows every context-free grammar (CFG) to be rewritten so that the first character of each rule is a terminal symbol.",1 Introduction,[0],[0]
"A grammar in GNF is said to be prefix lexicalized, because the prefix of every production is a lexical item.",1 Introduction,[0],[0]
"GNF has a variety of theoretical and practical applications, including for example the proofs of the famous theorems due to Shamir and Chomsky-Schützenberger (Shamir, 1967; Chomsky and Schützenberger, 1963; Autebert et al., 1997).",1 Introduction,[0],[0]
"Other applications of prefix lexicalization include proving coverage of parsing algorithms (Gray and Harrison, 1972) and decidability of equivalence problems (Christensen et al., 1995).
",1 Introduction,[0],[0]
"By using prefix lexicalized synchronous context-free grammars (SCFGs), Watanabe et al. (2006) and Siahbani et al. (2013) obtain asymptotic and empirical speed improvements on a machine translation task.",1 Introduction,[0],[0]
"Using a prefix lexicalized grammar ensures that target sentences can be generated from left to right, which allows the use of beam search to constrain their decoder’s search space as it performs a left-to-right traversal of translation hypotheses.",1 Introduction,[0],[0]
"To achieve these results,
new grammars had to be heuristically constrained to include only prefix lexicalized productions, as there is at present no way to automatically convert an existing SCFG to a prefix lexicalized form.
",1 Introduction,[0],[0]
"This work investigates the formal properties of prefix lexicalized synchronous grammars as employed by Watanabe et al. (2006) and Siahbani et al. (2013), which have received little theoretical attention compared to non-synchronous prefix lexicalized grammars.",1 Introduction,[0],[0]
"To this end, we first prove that SCFG is not closed under prefix lexicalization.",1 Introduction,[0],[0]
"Our main result is that there is a method for prefix lexicalizing an SCFG by converting it to an equivalent grammar in a different formalism, namely synchronous tree-adjoining grammar (STAG) in regular form.",1 Introduction,[0],[0]
"Like the GNF transformation for CFGs, our method at most cubes the grammar size, but we show empirically that the size increase is only quadratic for grammars used in existing NLP tasks.",1 Introduction,[0],[0]
"The rank is at most doubled, and we maintain O(n3k) parsing complexity for grammars of rank k.",1 Introduction,[0],[0]
"We conclude that although SCFG does not have a prefix lexicalized normal form like GNF, our conversion to prefix lexicalized STAG offers a practical alternative.",1 Introduction,[0],[0]
"An SCFG is a tuple G = (N,Σ, P, S) where N is a finite nonterminal alphabet, Σ is a finite terminal alphabet, S ∈ N is a distinguished nonterminal called the start symbol, and P is a finite set of synchronous rules of the form
(1) 〈A1 → α1, A2 → α2〉
for some A1, A2 ∈ N and strings α1, α2 ∈ (N ∪ Σ)∗.1",2.1 SCFG,[0],[0]
"Every nonterminal which appears in α1
1A variant formalism exists which requires thatA1 = A2; this is called syntax-directed transduction grammar (Lewis and Stearns, 1968) or syntax-directed translation schemata (Aho and Ullman, 1969).",2.1 SCFG,[0],[0]
"This variant is weakly equivalent to SCFG, but SCFG has greater strong generative capacity (Crescenzi et al., 2015).
",2.1 SCFG,[0],[0]
"A 1
A↓ 2a
B 2
B↓ 1b
A
cA∗
B d 〈",2.1 SCFG,[0],[0]
"〉 〈 〉
〈 A A
a A ↓ 1
c ,
B 1
b B
d 〉
Figure 1: An example of synchronous rewriting in an STAG (left) and the resulting tree pair (right).
must be linked to exactly one nonterminal in α2, and vice versa.",2.1 SCFG,[0],[0]
"We write these links using numerical annotations, as in (2).
",2.1 SCFG,[0],[0]
"(2) 〈A→ A 1 B 2 , B → B 2 A 1 〉
An SCFG has rank k if no rule in the grammar contains more than k pairs of linked nodes.
",2.1 SCFG,[0],[0]
"In every step of an SCFG derivation, we rewrite one pair of linked nonterminals with a rule from P , in essentially the same way we would rewrite a single nonterminal in a non-synchronous CFG.",2.1 SCFG,[0],[0]
"For example, (3) shows linked A and B nodes being rewritten using (2): (3) 〈X 1",2.1 SCFG,[0],[0]
"A 2 , B 2 Y 1 〉 ⇒ 〈X 1 A 2 B 3 , B 3 A 2 Y 1 〉
Note how the 1 and 2 in rule (2) are renumbered to 2 and 3 during rewriting, to avoid an ambiguity with the 1 already present in the derivation.
",2.1 SCFG,[0],[0]
An SCFG derivation is complete when it contains no more nonterminals to rewrite.,2.1 SCFG,[0],[0]
A completed derivation represents a string pair generated by the grammar.,2.1 SCFG,[0],[0]
"An STAG (Shieber, 1994) is a tuple G = (N,Σ, T, S) where N is a finite nonterminal alphabet, Σ is a finite terminal alphabet, S ∈ N is a distinguished nonterminal called the start symbol, and T is a finite set of synchronous tree pairs of the form
(4) 〈t1, t2〉
where t1 and t2 are elementary trees as defined in Joshi et al. (1975).",2.2 STAG,[0],[0]
A substitution site is a leaf node marked by ↓ which may be rewritten by another tree; a foot node is a leaf marked by ∗ that may be used to rewrite a tree-internal node.,2.2 STAG,[0],[0]
"Every substitution site in t1 must be linked to exactly one nonterminal in t2, and vice versa.",2.2 STAG,[0],[0]
"As in SCFG, we write these links using numbered annotations; rank is defined for STAG the same way as for SCFG.
",2.2 STAG,[0],[0]
"In every step of an STAG derivation, we rewrite one pair of linked nonterminals with a tree pair from T , using the same substitution and adjunction operations defined for non-synchronous TAG.",2.2 STAG,[0],[0]
"For example, Figure 1 shows linked A and B nodes being rewritten and the tree pair resulting from this operation.",2.2 STAG,[0],[0]
See Joshi et al. (1975) for details about the underlying TAG formalism.,2.2 STAG,[0],[0]
"We use synchronous production as a cover term for either a synchronous rule in an SCFG or a synchronous tree pair in an STAG.
",2.3 Terminology,[0],[0]
"Following Siahbani et al. (2013), we refer to the left half of a synchronous production as the source side, and the right half as the target side; this terminology captures the intuition that synchronous grammars model translational equivalence between a source phrase and its translation into a target language.",2.3 Terminology,[0],[0]
"Other authors refer to the two halves as the left and right components (Crescenzi et al., 2015) or, viewing the grammar as a transducer, the input and the output (Engelfriet et al., 2017).
",2.3 Terminology,[0],[0]
We call a grammar ε-free if it contains no productions whose source or target side produces only the empty string ε.,2.3 Terminology,[0],[0]
"Previous work (Watanabe et al., 2006; Siahbani et al., 2013) has shown that it is useful for the target side of a synchronous grammar to start with a terminal symbol.",2.4 Synchronous Prefix Lexicalization,[0],[0]
"For this reason, we define a synchronous grammar to be prefix lexicalized when the leftmost character of the target side2 of every synchronous production in that grammar is a terminal symbol.
",2.4 Synchronous Prefix Lexicalization,[0],[0]
"Formally, this means that every synchronous rule in a prefix lexicalized SCFG (PL-SCFG) is
2All of the proofs in this work admit a symmetrical variant which prefix lexicalizes the source side instead of the target.",2.4 Synchronous Prefix Lexicalization,[0],[0]
"We are not aware of any applications in NLP where sourceside prefix lexicalization is useful, so we do not address this case.
of the form
(5) 〈A1 → α1, A2 → aα2〉
whereA1, A2 ∈ N , α1, α2 ∈ (N∪Σ)∗ and a ∈ Σ.",2.4 Synchronous Prefix Lexicalization,[0],[0]
"Every synchronous tree pair in a prefix lexicalized STAG (PL-STAG) is of the form
(6)
",2.4 Synchronous Prefix Lexicalization,[0],[0]
"〈 A1
α1
, A2
aα2 〉 whereA1, A2 ∈ N , α1, α2 ∈",2.4 Synchronous Prefix Lexicalization,[0],[0]
(N∪Σ)∗ and a ∈ Σ.,2.4 Synchronous Prefix Lexicalization,[0],[0]
"We now prove that the class SCFG is not closed under prefix lexicalization.
",3 Closure under Prefix Lexicalization,[0],[0]
Theorem 1.,3 Closure under Prefix Lexicalization,[0],[0]
"There exists an SCFG which cannot be converted to an equivalent PL-SCFG.
",3 Closure under Prefix Lexicalization,[0],[0]
Proof.,3 Closure under Prefix Lexicalization,[0],[0]
"The SCFG in (7) generates the language L = {〈aibjci, bjai〉| i ≥ 0, j ≥ 1}, but this language cannot be generated by any PL-SCFG:
(7)
〈S → A 1 , S → A 1 〉 〈A→ aA 1 c, A→ A 1 a〉 〈A→ bB 1 , A→ bB 1 〉 〈A→ b, A→ b〉 〈B → bB 1 , B → bB 1 〉 〈B → b, B → b〉
Suppose, for the purpose of contradiction, that some PL-SCFG does generate L; call this grammar G. Then the following derivations must all be possible in G for some nontermials U, V,X, Y :
i)",3 Closure under Prefix Lexicalization,[0],[0]
"〈U 1 , V 1 〉 ⇒∗ 〈bkU 1 bm, bnV 1 bp〉, where k +m = n+ p and n ≥ 1
ii) 〈X 1 , Y 1 〉 ⇒∗ 〈aqX 1 cq, arY 1 as〉, where q = r + s and r ≥ 1
iii) 〈S 1 , S 1 〉 ⇒∗ 〈α1X 1 α2, bα3Y 1 α4〉, where α1, ..., α4 ∈ (N ∪ Σ)∗
iv) 〈X 1 , Y 1 〉 ⇒∗ 〈α5U 1 α6, α7V 1 α8〉, where α5, α6, α8 ∈",3 Closure under Prefix Lexicalization,[0],[0]
"(N ∪ Σ)∗, α7 ∈ Σ(N ∪ Σ)∗
i and ii follow from the same arguments used in the pumping lemma for (non-synchronous) context free languages (Bar-Hillel et al., 1961): strings in L can contain arbitrarily many as, bs, and cs, so there must exist some pumpable cycles
which generate these characters.",3 Closure under Prefix Lexicalization,[0],[0]
"In i, k + m = n + p because the final derived strings must contain an equal number of bs, and n ≥ 1 because G is prefix lexicalized; in ii the constraints on q, r and s follow likewise from L. iii follows from the fact that, in order to pump on the cycle in ii, this cycle must be reachable from the start symbol.",3 Closure under Prefix Lexicalization,[0],[0]
iv follows from the fact that a context-free production cannot generate a discontinuous span.,3 Closure under Prefix Lexicalization,[0],[0]
"Once the cycle in i has generated a b, it is impossible for ii to generate an a on one side of the b and a c on the other.",3 Closure under Prefix Lexicalization,[0],[0]
"Therefore i must always be derived strictly later than ii, as shown in iv.
",3 Closure under Prefix Lexicalization,[0],[0]
Now we obtain a contradiction.,3 Closure under Prefix Lexicalization,[0],[0]
"Given that G can derive all of i through iv, the following derivation is also possible: (8)
〈S 1 , S 1 〉 ⇒∗ 〈α1X 1 α2, bα3Y 1 α4〉 ⇒∗ 〈α1aqX 1 cqα2, bα3arY 1 asα4〉 ⇒∗ 〈α1aqα5U 1 α6cqα2, bα3arα7V 1 α8asα4〉 ⇒∗ 〈α1aqα5bkU 1 bmα6cqα2,
bα3a rα7b nV 1 bpα8a sα4〉
But since n, r ≥ 1, the target string derived this way contains an a before a b and does not belong to L.
This is a contradiction: if G is a PL-SCFG then it must generate i through iv, but if so then it also generates strings which do not belong to L. Thus no PL-SCFG can generate L, and SCFG must not be closed under prefix lexicalization.
",3 Closure under Prefix Lexicalization,[0],[0]
There also exist grammars which cannot be prefix lexicalized because they contain cyclic chain rules.,3 Closure under Prefix Lexicalization,[0],[0]
"If an SCFG can derive something of the form 〈X 1 , Y 1 〉 ⇒∗ 〈xX 1 , Y 1 〉, then it can generate arbitrarily many symbols in the source string without adding anything to the target string.",3 Closure under Prefix Lexicalization,[0],[0]
"Prefix lexicalizing the grammar would force it to generate some terminal symbol in the target string at each step of the derivation, making it unable to generate the original language where a source string may be unboundedly longer than its corresponding target.",3 Closure under Prefix Lexicalization,[0],[0]
We call an SCFG chain-free if it does not contain a cycle of chain rules of this form.,3 Closure under Prefix Lexicalization,[0],[0]
"The remainder of this paper focuses on chain-free grammars, like (7), which cannot be converted to PL-SCFG despite containing no such cycles.",3 Closure under Prefix Lexicalization,[0],[0]
"We now present a method for prefix lexicalizing an SCFG by converting it to an STAG.
",4 Prefix Lexicalization using STAG,[0],[0]
"SXA
〉
〈 SXA
SXA
〉
Theorem 2.",4 Prefix Lexicalization using STAG,[0],[0]
"Given a rank-k SCFG G which is εfree and chain-free, an STAGH exists such thatH is prefix lexicalized and L(G) = L(H).",4 Prefix Lexicalization using STAG,[0],[0]
"The rank of H is at most 2k, and |H| = O(|G|3).
",4 Prefix Lexicalization using STAG,[0],[0]
Proof.,4 Prefix Lexicalization using STAG,[0],[0]
"Let G = (N,Σ, P, S) be an ε-free, chainfree SCFG.",4 Prefix Lexicalization using STAG,[0],[0]
"We provide a constructive method for prefix lexicalizing the target side of G.
We begin by constructing an intermediate grammar GXA for each pair of nonterminals X,A ∈ N \",4 Prefix Lexicalization using STAG,[0],[0]
{S}.,4 Prefix Lexicalization using STAG,[0],[0]
"For each pair X,A ∈ N",4 Prefix Lexicalization using STAG,[0],[0]
\,4 Prefix Lexicalization using STAG,[0],[0]
"{S}, GXA will be constructed to generate the language of sentential forms derivable from 〈X 1 , A 1 〉 via a target-side terminal leftmost derivation (TTLD).",4 Prefix Lexicalization using STAG,[0],[0]
"A TTLD is a derivation of the form in Figure 2, where the leftmost nonterminal in the target string is expanded until it produces a terminal symbol as the first character.",4 Prefix Lexicalization using STAG,[0],[0]
"We write 〈X 1 , A 1 〉 ⇒∗TTLD 〈u, v〉 to mean that 〈X 1 , A 1 〉 derives 〈u, v〉 by way of a TTLD; in this notation, LXA = {〈u, v〉|〈X 1 , A 1 〉 ⇒∗TTLD 〈u, v〉} is the language of sentential forms derivable from 〈X 1 , A 1 〉 via a TTLD.
",4 Prefix Lexicalization using STAG,[0],[0]
"Given X,A ∈ N \",4 Prefix Lexicalization using STAG,[0],[0]
"{S} we formally define GXA as an STAG over the terminal alphabet ΣXA = N ∪ Σ and nonterminal alphabet NXA = {YXA|Y ∈ N}, with start symbol SXA.",4 Prefix Lexicalization using STAG,[0],[0]
"NXA contains nonterminals indexed by XA to ensure that two intermediate grammars GXA and GY B do not interact as long as 〈X,",4 Prefix Lexicalization using STAG,[0],[0]
"A〉 6= 〈Y,B〉.
",4 Prefix Lexicalization using STAG,[0],[0]
"GXA contains four kinds of tree pairs: 3
• For each rule in G of the form 〈X → α1, A→ aα2〉, a ∈ Σ, αi ∈ (N∪Σ)∗, we add a tree pair of the form in Figure 3(a).
",4 Prefix Lexicalization using STAG,[0],[0]
"• For each rule in G of the form 〈Y → α1, B → aα2〉, a ∈ Σ, αi ∈ (N∪Σ)∗, Y,B ∈ N",4 Prefix Lexicalization using STAG,[0],[0]
\,4 Prefix Lexicalization using STAG,[0],[0]
"{S}, we add a tree pair of the form in Figure 3(b).
",4 Prefix Lexicalization using STAG,[0],[0]
"• For each rule in G of the form 〈Y → α1Z 1 β1, B → C 1 α2〉, Y, Z,B,C ∈ N",4 Prefix Lexicalization using STAG,[0],[0]
\,4 Prefix Lexicalization using STAG,[0],[0]
"{S}, αi, βi ∈ (N ∪ Σ)∗, we add a tree pair of the form in Figure 3(c).
",4 Prefix Lexicalization using STAG,[0],[0]
"As a special case, if Y = Z we collapse the root node and adjunction site to produce a tree pair of the following form:
(9)
〈 ZXA 1
α1ZXA ∗ β1
, CXA
α2BXA ↓ 1 〉 • For each rule in G of the form 〈X → α1Y 1 β1, A→ C 1 α2〉, Y,C ∈ N , αi, βi ∈ (N ∪ Σ)∗, we add a tree pair of the form in Figure 3(d).
",4 Prefix Lexicalization using STAG,[0],[0]
"3In all cases, we assume that symbols inN (notNXA) retain any links they bore in the original grammar, even though they belong to the terminal alphabet in GXA and therefore do not participate in rewriting operations.",4 Prefix Lexicalization using STAG,[0],[0]
"In the final constructed grammar, these symbols will belong to the nonterminal alphabet again, and the links will function normally.
",4 Prefix Lexicalization using STAG,[0],[0]
"Figure 4 gives a concrete example of constructing an intermediate grammar tree pair on the basis of an SCFG rule.
",4 Prefix Lexicalization using STAG,[0],[0]
Lemma 1.,4 Prefix Lexicalization using STAG,[0],[0]
"GXA generates the language LXA.
Proof.",4 Prefix Lexicalization using STAG,[0],[0]
This can be shown by induction over derivations of increasing length.,4 Prefix Lexicalization using STAG,[0],[0]
"The proof is straightforward but very long, so we provide only a sketch; the complete proof is provided in the supplementary material.
",4 Prefix Lexicalization using STAG,[0],[0]
"As a base case, observe that a tree of the shape in Figure 3(a) corresponds straightforwardly to the derivation
(10) 〈X 1 , A 1 〉 ⇒ 〈α1, aα2〉
which is a TTLD starting from 〈X,A〉.",4 Prefix Lexicalization using STAG,[0],[0]
"By construction, therefore, every TTLD of the shape in (10) corresponds to some tree in GXA of shape 3(a); likewise every derivation inGXA comprising a single tree of shape 3(a) corresponds to a TTLD of the shape in (10).
",4 Prefix Lexicalization using STAG,[0],[0]
"As a second base case, note that a tree of the shape in Figure 3(b) corresponds to the last step of a TTLD like (11):
(11) 〈X 1 , A 1 〉 ⇒∗TTLD 〈uY 1 v,B 1 w〉 ⇒ 〈uα1v, aα2w〉
In the other direction, the last step of any TTLD of the shape in (11) will involve some rule of the shape 〈Y → α1, B → aα2〉; by construction GXA must contain a corresponding tree pair of shape 3(b).
",4 Prefix Lexicalization using STAG,[0],[0]
"Together, these base cases establish a one-toone correspondence between single-tree derivations in GXA and the last step of a TTLD starting from 〈X,A〉.
",4 Prefix Lexicalization using STAG,[0],[0]
"Now, assume that the last n steps of every TTLD starting from 〈X,A〉 correspond to some derivation over n trees in GXA, and vice versa.",4 Prefix Lexicalization using STAG,[0],[0]
"Then the last n + 1 steps of that TTLD will also correspond to some n+ 1 tree derivation in GXA, and vice versa.
",4 Prefix Lexicalization using STAG,[0],[0]
"To see this, consider the step n+ 1 steps before the end of the TTLD.",4 Prefix Lexicalization using STAG,[0],[0]
"This step may be in the middle of the derivation, or it may be the first step of the derivation.",4 Prefix Lexicalization using STAG,[0],[0]
"If it is in the middle, then this step must involve a rule of the shape
(12) 〈Y → α1Z 1 β1, B → C 1 α2〉
The existence of such a rule in G implies the existence of a corresponding tree in GXA of the shape in Figure 3(c).",4 Prefix Lexicalization using STAG,[0],[0]
Adding this tree to the existing n-tree derivation yields a new n + 1 tree derivation corresponding to the last n + 1 steps of the TTLD.4,4 Prefix Lexicalization using STAG,[0],[0]
"In the other direction, if the n+ 1th tree5 of a derivation in GXA is of the shape in Figure 3(c), then this implies the existence of a production in G of the shape in (12).",4 Prefix Lexicalization using STAG,[0],[0]
"By assumption the first n trees of the derivation in GXA correspond to some TTLD in G; by prepending the rule from (12) to this TTLD we obtain a new TTLD of length n + 1 which corresponds to the entire n + 1 tree derivation in GXA.
",4 Prefix Lexicalization using STAG,[0],[0]
"Finally, consider the case where the TTLD is only n + 1 steps long.",4 Prefix Lexicalization using STAG,[0],[0]
"The first step must involve a rule of the form
(13) 〈X → α1Y 1 β1, A→ C 1 α2〉
The existence of such a rule implies the existence of a corresponding tree in GXA of the shape in Figure 3(d).",4 Prefix Lexicalization using STAG,[0],[0]
Adding this tree to the derivation which corresponds to the last n steps of the TTLD yields a new n+1 tree derivation corresponding to the entire n+ 1 step TTLD.,4 Prefix Lexicalization using STAG,[0],[0]
"In the other direction, if the last tree of an n + 1 tree derivation in GA is of the shape in Figure 3(d), then this implies the
4It is easy to verify by inspection of Figure 3 that whenever one rule from G can be applied to the output of another rule, then the tree pairs in GXA which correspond to these rules can compose with one another.",4 Prefix Lexicalization using STAG,[0],[0]
"Thus we can add the new tree to the existing derivation and be assured that it will compose with one of the trees that is already present.
",4 Prefix Lexicalization using STAG,[0],[0]
"5Although trees in GXA may contain symbols from the nonterminal alphabet of G, these symbols belong to the terminal alphabet in GXA.",4 Prefix Lexicalization using STAG,[0],[0]
"Only nonterminals in NXA will be involved in this derivation, and by construction there is at most one such nonterminal per tree.",4 Prefix Lexicalization using STAG,[0],[0]
"Thus a well-formed derivation structure in GXA will never branch, and we can refer to the n+ 1th tree pair as the one which is at depth n in the derivation structure.
existence of a production inG of the shape in (13).",4 Prefix Lexicalization using STAG,[0],[0]
"By assumption the first n trees of the derivation in GXA correspond to some TTLD inG; by prepending the rule from (13) to this TTLD we obtain a new TTLD of length n + 1 which corresponds to the entire n+ 1 tree derivation in GXA.
",4 Prefix Lexicalization using STAG,[0],[0]
"Taken together, these cases establish a one-toone correspondence between derivations in GXA and TTLDs which start from 〈X,A〉; in turn they confirm that GXA generates the desired language LXA.
",4 Prefix Lexicalization using STAG,[0],[0]
"Once we have constructed an intermediate grammar GXA for each X,A ∈ N \ {S}, we obtain the final STAG H as follows:
1.",4 Prefix Lexicalization using STAG,[0],[0]
Convert the input SCFG G to an equivalent STAG.,4 Prefix Lexicalization using STAG,[0],[0]
"For each rule 〈A1 → α1, A2 → α2〉, where Ai ∈ N , αi ∈ (N ∪ Σ)∗, create a tree pair of the form
(14)
〈 A1
α1
, A2
α2 〉 where each pair of linked nonterminals in the original rule become a pair of linked substitution sites in the tree pair.",4 Prefix Lexicalization using STAG,[0],[0]
The terminal and nonterminal alphabets and start symbol are unchanged.,4 Prefix Lexicalization using STAG,[0],[0]
"Call the resulting STAG H .
2.",4 Prefix Lexicalization using STAG,[0],[0]
"For all X,A ∈ N \ {S}, add all of the tree pairs from the intermediate grammar GXA to the new grammar H .",4 Prefix Lexicalization using STAG,[0],[0]
"Expand N to include the new nonterminal symbols in NXA.
3.",4 Prefix Lexicalization using STAG,[0],[0]
"For every X,A ∈ N , in all tree pairs where the target tree’s leftmost leaf is labeled with A and this node is linked to anX , replace this occurrence of A with SXA.",4 Prefix Lexicalization using STAG,[0],[0]
"Also replace the linked node in the source tree.
4.",4 Prefix Lexicalization using STAG,[0],[0]
"For every X,A ∈ N , let RXA be the set of all tree pairs rooted in SXA, and let TXA be the set of all tree pairs whose target tree’s leftmost leaf is labeled with SXA.",4 Prefix Lexicalization using STAG,[0],[0]
"For every 〈s, t〉 ∈ TXA and every 〈s′, t′〉 ∈ RXA, substitute or adjoin s′ and t′ into the linked SXA nodes in s and t, respectively.",4 Prefix Lexicalization using STAG,[0],[0]
"Add the derived trees to H .
5.",4 Prefix Lexicalization using STAG,[0],[0]
"For all X,A ∈ N , let TXA be defined as above.",4 Prefix Lexicalization using STAG,[0],[0]
"Remove all tree pairs in TXA from H .
6.",4 Prefix Lexicalization using STAG,[0],[0]
"For all X,A ∈ N , let RXA be defined as above.",4 Prefix Lexicalization using STAG,[0],[0]
"Remove all tree pairs in RXA from H .
",4 Prefix Lexicalization using STAG,[0],[0]
"We now claim that H generates the same language as the original grammar G, and all of the target trees in H are prefix lexicalized.
",4 Prefix Lexicalization using STAG,[0],[0]
The first claim follows directly from the construction.,4 Prefix Lexicalization using STAG,[0],[0]
Step 1 merely rewrites the grammar in a new formalism.,4 Prefix Lexicalization using STAG,[0],[0]
"From Lemma 1 it is clear that steps 2–3 do not change the generated language: the set of string pairs generable from a pair of SXA nodes is identical to the set generable from 〈X,A〉 in the original grammar.",4 Prefix Lexicalization using STAG,[0],[0]
"Step 4 replaces some nonterminals by all possible alternatives; steps 5– 6 then remove the trees which were used in step 4, but since all possible combinations of these trees have already been added to the grammar, removing them will not alter the language.
",4 Prefix Lexicalization using STAG,[0],[0]
The second claim follows from inspection of the tree pairs generated in Figure 3.,4 Prefix Lexicalization using STAG,[0],[0]
"Observe that, by construction, for all X,A ∈ N every target tree rooted in SXA is prefix lexicalized.",4 Prefix Lexicalization using STAG,[0],[0]
"Thus the trees created in step 4 are all prefix lexicalized variants of non-lexicalized tree pairs; steps 5–6 then remove the non-lexicalized trees from the grammar.
",4 Prefix Lexicalization using STAG,[0],[0]
Figure 5 gives an example of this transformation applied to a small grammar.,4 Prefix Lexicalization using STAG,[0],[0]
"Note how A nodes at the left edge of the target trees end up rewritten as SAA nodes, as per step 4 of the transformation.",4 Prefix Lexicalization using STAG,[0],[0]
"Our conversion generates a subset of the class of prefix lexicalized STAGs in regular form, which we abbreviate to PL-RSTAG (regular form for TAG is defined in Rogers 1994).",5 Complexity & Formal Properties,[0],[0]
"This section discusses some formal properties of PL-RSTAG.
",5 Complexity & Formal Properties,[0],[0]
"Generative Capacity PL-RSTAG is weakly equivalent to the class of ε-free, chain-free SCFGs: this follows immediately from the proof that our transformation does not change the language generated by the input SCFG.",5 Complexity & Formal Properties,[0],[0]
"Note that every TAG in regular form generates a context-free language (Rogers, 1994).
",5 Complexity & Formal Properties,[0],[0]
Alignments and Reordering PL-RSTAG generates the same set of reorderings (alignments) as SCFG.,5 Complexity & Formal Properties,[0],[0]
"Observe that our transformation does not cause nonterminals which were linked in the original grammar to become unlinked, as noted for example in Figure 4.",5 Complexity & Formal Properties,[0],[0]
"Thus subtrees which are gener-
〈S → B 2 cA 1 , S → A 1 cB 2 〉 〈A→ B 2 cA 1 , A→ A 1 cB 2 〉 〈A→ a, A→ a〉 〈B → b, B → b〉
〈 S B ↓",5 Complexity & Formal Properties,[0],[0]
"1 c SAA
a
,
S
SAA
a
c B ↓",5 Complexity & Formal Properties,[0],[0]
"1
〉 〈 A B ↓ 1 c SAA
AAA 2
a
,
A
SAA
a AAA ↓ 2
c B ↓ 1 〉 〈 S
B ↓ 1 c SAA
AAA 2
a
,
S
SAA
a AAA ↓ 2
c B ↓ 1 〉 〈 A B ↓ 1 c SAA
a
,
A
SAA
a
c B ↓ 1
〉 〈 AAA 1
B ↓",5 Complexity & Formal Properties,[0],[0]
"2 c AAA∗
, AAA
c B ↓ 2 AAA ↓ 1 〉 〈
AAA
B ↓",5 Complexity & Formal Properties,[0],[0]
"1 c AAA∗
, AAA
c B ↓ 1
〉 〈 B
b
, B
b
〉 〈 A
a
, A
a 〉
Figure 5: An SCFG and the STAG which prefix lexicalizes it.",5 Complexity & Formal Properties,[0],[0]
"Non-productive trees have been omitted.
",5 Complexity & Formal Properties,[0],[0]
"Grammar |G| |H| % of G prefix lexicalized log|G|(|H|) Siahbani and Sarkar (2014a) (Zh-En) 18.5M 23.6T 63% 1.84 Example (7) 6 14 66% 1.47 ITG (10000 translation pairs) 10,003 170,000 99.97% 1.31
Table 1: Grammar sizes before and after prefix lexicalization, showing O(n2) size increase instead of the worst case O(n3).",5 Complexity & Formal Properties,[0],[0]
|G| and |H| give the grammar size before and after prefix lexicalization; log|G| |H| is the increase as a power of the initial size.,5 Complexity & Formal Properties,[0],[0]
"We also show the percentage of productions which are already prefix lexicalized in G.
ated by linked nonterminals in the original grammar will still be generated by linked nonterminals in the final grammar, so no reordering information is lost or added.6 This result holds despite the fact that our transformation is only applicable to chainfree grammars: chain rules cannot introduce any reorderings, since by definition they involve only a single pair of linked nonterminals.
",5 Complexity & Formal Properties,[0],[0]
Grammar Rank,5 Complexity & Formal Properties,[0],[0]
"If the input SCFG G has rank k,",5 Complexity & Formal Properties,[0],[0]
then the STAG H produced by our transformation has rank at most 2k.,5 Complexity & Formal Properties,[0],[0]
"To see this, observe that the construction of the intermediate grammars increases the rank by at most 1 (see Figure 3(b)).",5 Complexity & Formal Properties,[0],[0]
"When a prefix lexicalized tree is substituted at the left edge of a non-lexicalized tree, the link on the substitution site will be consumed, but up to k+ 1 new links will be introduced by the substituting tree, so that the final tree will have rank at most 2k.
",5 Complexity & Formal Properties,[0],[0]
"In the general case, rank-k STAG is more powerful than rank-k SCFG; for example, a rank-4 SCFG is required to generate the reordering in 〈S → A 1 B 2 C 3 D 4 , S → C 3 A 1 D 4 B 2 〉 (Wu, 1997), but this reordering is captured by the
6Although we consume one link whenever we substitute a prefix lexicalized tree at the left edge of an unlexicalized tree, that link can still be remembered and used to reconstruct the reorderings which occurred between the two sentences.
",5 Complexity & Formal Properties,[0],[0]
"following rank-3 STAG:〈 S X
A ↓ 1 X 2
C ↓ 3
, S
C ↓ 3",5 Complexity & Formal Properties,[0],[0]
"A ↓ 1 X ↓ 2 〉 〈
X
B ↓",5 Complexity & Formal Properties,[0],[0]
"1 X∗ D ↓ 2
, X
D ↓ 2 B ↓ 1 〉 For this reason, we speculate that it is possible to further transform the grammars produced by our lexicalization in order to reduce their rank, but the details of this transformation remain as future work.
",5 Complexity & Formal Properties,[0],[0]
This potentially poses a solution to an issue raised by Siahbani and Sarkar (2014b).,5 Complexity & Formal Properties,[0],[0]
"On a Chinese-English translation task, they find that sentences like (15) involve reorderings which cannot be captured by a rank-2 prefix lexicalized SCFG: (15) Tā bǔchōng shuō ,",5 Complexity & Formal Properties,[0],[0]
liánhé zhèngfǔ,5 Complexity & Formal Properties,[0],[0]
"mùqián zhuàngkuàng wěndı̀ng ...
",5 Complexity & Formal Properties,[0],[0]
"He added that the coalition government is now in stable condition ...
",5 Complexity & Formal Properties,[0],[0]
"If rank-k PL-RSTAG is more powerful than rank-k
SCFG, using a PL-RSTAG here would permit capturing more reorderings without using grammars of higher rank.
",5 Complexity & Formal Properties,[0],[0]
"Parse Complexity Because the grammar produced is in regular form, each side can be parsed in time O(n3) (Rogers, 1994), for an overall parse complexity of O(n3k), where n is sentence length and k is the grammar rank.
",5 Complexity & Formal Properties,[0],[0]
Grammar Size and Experiments,5 Complexity & Formal Properties,[0],[0]
"If H is the PL-RSTAG produced by applying our transformation to an SCFG G, then H contains O(|G|3) elementary tree pairs, where |G| is the number of synchronous productions in G. When the set of nonterminalsN is small compared to |G|, a tighter bound is given by O(|G|2|N |2).
",5 Complexity & Formal Properties,[0],[0]
"Table 1 shows the actual size increase on a variety of grammars: here |G| is the size of the initial grammar, |H| is the size after applying our transformation, and the increase is expressed as a power of the original grammar size.",5 Complexity & Formal Properties,[0],[0]
"We apply our transformation to the grammar from Siahbani and Sarkar (2014a), which was created for a ChineseEnglish translation task known to involve complex reorderings that cannot be captured by PL-SCFG (Siahbani and Sarkar, 2014b).",5 Complexity & Formal Properties,[0],[0]
"We also consider the grammar in (7) and an ITG (Wu, 1997) containing 10,000 translation pairs, which is a grammar of the sort that has previously been used for word alignment tasks (cf Zhang and Gildea 2005).",5 Complexity & Formal Properties,[0],[0]
"We always observe an increase within O(|G|2) rather than the worst-case O(|G|3), because |N | is small relative to |G| in most grammars used for NLP tasks.
",5 Complexity & Formal Properties,[0],[0]
We also investigated how the proportion of prefix lexicalized rules in the original grammar affects the overall size increase.,5 Complexity & Formal Properties,[0],[0]
We sampled grammars with varying proportions of prefix lexicalized rules from the grammar in Siahbani and Sarkar (2014a); Table 2 shows the result of lexicalizing these samples.,5 Complexity & Formal Properties,[0],[0]
We find that the worst case size increase occurs when 50% of the original grammar is already prefix lexicalized.,5 Complexity & Formal Properties,[0],[0]
This is because the size increase depends on both the number of prefix lexicalized trees in the intermediate grammars (which grows with the proportion of lexicalized rules) and the number of productions which need to be lexicalized (which shrinks as the proportion of prefix lexicalized rules increases).,5 Complexity & Formal Properties,[0],[0]
"At 50%, both factors contribute appreciably to the grammar size, analogous to how the function f(x) = x(1− x) takes
its maximum at x = 0.5.",5 Complexity & Formal Properties,[0],[0]
The LR decoding algorithm from Watanabe et al. (2006) relies on prefix lexicalized rules to generate a prefix of the target sentence during machine translation.,6 Applications,[0],[0]
"At each step, a translation hypothesis is expanded by rewriting the leftmost nonterminal in its target string using some grammar rule; the prefix of this rule is appended to the existing translation and the remainder of the rule is pushed onto a stack, in reverse order, to be processed later.",6 Applications,[0],[0]
"Translation hypotheses are stored in stacks according to the length of their translated prefix, and beam search is used to traverse these hypotheses and find a complete translation.",6 Applications,[0],[0]
"During decoding, the source side is processed by an Earley-style parser, with the dot moving around to process nonterminals in the order they appear on the target side.
",6 Applications,[0],[0]
"Since the trees on the target side of our transformed grammar are all of depth 1, and none of these trees can compose via the adjunction operation, they can be treated like context-free rules and used as-is in this decoding algorithm.",6 Applications,[0],[0]
"The only change required to adapt LR decoding to use a PL-RSTAG is to make the source side use a TAG parser instead of a CFG parser; an Earley-style parser for TAG already exists (Joshi and Schabes, 1997), so this is a minor adjustment.
",6 Applications,[0],[0]
"Combined with the transformation in Section 4, this suggests a method for using LR decoding without sacrificing translation quality.",6 Applications,[0],[0]
"Previously, LR decoding required the use of heuristically generated PL-SCFGs, which cannot model some reorderings (Siahbani and Sarkar, 2014a).",6 Applications,[0],[0]
"Now, an SCFG tailored for a translation task can be transformed directly to PL-RSTAG and used for decod-
ing; unlike a heuristically induced PL-SCFG, the transformed PL-RSTAG will generate the same language as the original SCFG which is known to handle more reorderings.
",6 Applications,[0],[0]
"Note that, since applying our transformation may double the rank of a grammar, this method may prove prohibitively slow.",6 Applications,[0],[0]
This highlights the need for future work to examine the generative power of rank-k PL-RSTAG relative to rankk SCFG in the interest of reducing the rank of the transformed grammar.,6 Applications,[0],[0]
Our work continues the study of TAGs and lexicalization (e.g. Joshi et al. 1975; Schabes and Waters 1993).,7 Related Work,[0],[0]
"Schabes and Waters (1995) show that TAG can strongly lexicalize CFG, whereas CFG only weakly lexicalizes itself; we show a similar result for SCFGs.",7 Related Work,[0],[0]
"Kuhlmann and Satta (2012) show that TAG is not closed under strong lexicalization, and Maletti and Engelfriet (2012) show how to strongly lexicalize TAG using simple context-free tree grammars (CFTGs).
",7 Related Work,[0],[0]
"Other extensions of GNF to new grammar formalisms include Dymetman (1992) for definite clause grammars, Fernau and Stiebe (2002) for CF valence grammars, and Engelfriet et al. (2017) for multiple CFTGs.",7 Related Work,[0],[0]
"Although multiple CFTG subsumes SCFG (and STAG), Engelfriet et al.’s result appears to guarantee only that some side of every synchronous production will be lexicalized, whereas our result guarantees that it is always the target side that will be prefix lexicalized.
",7 Related Work,[0],[0]
"Lexicalization of synchronous grammars was addressed by Zhang and Gildea (2005), but they consider lexicalization rather than prefix lexicalization, and they only consider SCFGs of rank 2.",7 Related Work,[0],[0]
"They motivate their results using a word alignment task, which may be another possible application for our lexicalization.
",7 Related Work,[0],[0]
"Analogous to our closure result, Aho and Ullman (1969) prove that SCFG does not admit a normal form with bounded rank like Chomsky normal form.
",7 Related Work,[0],[0]
Blum and Koch (1999) use intermediate grammars like our GXAs to transform a CFG to GNF.,7 Related Work,[0],[0]
"Another GNF transformation (Rosenkrantz, 1967) is used by Schabes and Waters (1995) to define Tree Insertion Grammars (which are also weakly equivalent to CFG).
",7 Related Work,[0],[0]
"We rely on Rogers (1994) for the claim that
our transformed grammars generate context-free languages despite allowing wrapping adjunction; an alternative proof could employ the results of Swanson et al. (2013), who develop their own context-free TAG variant known as osTAG.
",7 Related Work,[0],[0]
Kaeshammer (2013) introduces the class of synchronous linear context-free rewriting systems to model reorderings which cannot be captured by a rank-2 SCFG.,7 Related Work,[0],[0]
"In the event that rank-k PL-RSTAG is more powerful than rank-k SCFG, our work can be seen as an alternative approach to the same problem.
",7 Related Work,[0],[0]
"Finally, Nesson et al. (2008) present an algorithm for reducing the rank of an STAG on-the-fly during parsing; this presents a promising avenue for proving a smaller upper bound on the rank increase caused by our transformation.",7 Related Work,[0],[0]
We have demonstrated a method for prefix lexicalizing an SCFG by converting it to an equivalent STAG.,8 Conclusion and Future Work,[0],[0]
This process is applicable to any SCFG which is ε- and chain-free.,8 Conclusion and Future Work,[0],[0]
"Like the original GNF transformation for CFGs our construction at most cubes the grammar size, though when applied to the kinds of synchronous grammars used in machine translation the size is merely squared.",8 Conclusion and Future Work,[0],[0]
"Our transformation preserves all of the alignments generated by SCFG, and retains properties such as O(n3k) parsing complexity for grammars of",8 Conclusion and Future Work,[0],[0]
rank k.,8 Conclusion and Future Work,[0],[0]
"We plan to verify whether rank-k PL-RSTAG is more powerful than rank-k SCFG in future work, and to reduce the rank of the transformed grammar if possible.",8 Conclusion and Future Work,[0],[0]
We further plan to empirically evaluate our lexicalization on an alignment task and to offer a comparison against the lexicalization due to Zhang and Gildea (2005).,8 Conclusion and Future Work,[0],[0]
The authors wish to thank the anonymous reviewers for their helpful comments.,Acknowledgements,[0],[0]
The research was also partially supported by the Natural Sciences and Engineering Research Council of Canada (NSERC RGPIN-2018-06437 and RGPAS-2018-522574) to the second author.,Acknowledgements,[0],[0]
We dedicate this paper to the memory of Prof. Aravind Joshi; a short hallway conversation with him at ACL 2014 was the seed for this paper.,Acknowledgements,[0],[0]
"We show that an ε-free, chain-free synchronous context-free grammar (SCFG) can be converted into a weakly equivalent synchronous tree-adjoining grammar (STAG) which is prefix lexicalized.",abstractText,[0],[0]
"This transformation at most doubles the grammar’s rank and cubes its size, but we show that in practice the size increase is only quadratic.",abstractText,[0],[0]
"Our results extend Greibach normal form from CFGs to SCFGs and prove new formal properties about SCFG, a formalism with many applications in natural language processing.",abstractText,[0],[0]
Prefix Lexicalization of Synchronous CFGs using Synchronous TAG,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 764–770 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
764",text,[0],[0]
"Sentiment classification is a task to predict a sentiment label, such as positive/negative, for a given text and has been applied to many domains such as movie/product reviews, customer surveys, news comments, and social media.",1 Introduction,[0],[0]
"A common problem of this task is the lack of labeled training data due to costly annotation work, especially for social media without explicit sentiment feedback such as review scores.
",1 Introduction,[0],[0]
"To overcome this problem, Dai and Le (2015) recently proposed a semi-supervised sequence learning framework, where a sentiment classifier based on recurrent neural networks (RNNs) is trained with labeled data after initializing it with the parameters of an RNN-based language model pretrained with a large amount of unlabeled data.
",1 Introduction,[0],[0]
"The concept of their framework is simple but effective, and their work yielded many related studies of semi-supervised training based on sequence modeling, as described in Section 4.
",1 Introduction,[0],[0]
"In this paper, we take their concept a step further by using a conditional language model with unlabeled dialog data (i.e., tweet-reply pairs) instead of a language model with unpaired data1.",1 Introduction,[0],[0]
An important observation of the dialog data that underpins our strategy is that the sentiment or mood in a message often affects messages in reply to it.,1 Introduction,[0],[0]
"People tend to write angry responses to angry messages, empathetic replies to sad remarks, or congratulatory phrases to good news.
",1 Introduction,[0],[0]
"Our contributions are listed as follows.
",1 Introduction,[0],[0]
• We propose a pretraining strategy with unlabeled dialog data (tweet-reply pairs) via an encoder-decoder model for sentiment classifiers (Section 2).,1 Introduction,[0],[0]
"To the best of our knowledge, our proposal is the first such proposal, as clarified in Section 4.
",1 Introduction,[0],[0]
"• We report on a case study based on a costly labeled sentiment dataset of 99.5K items and a large-scale unlabeled dialog dataset of 22.3M, which were provided from a tweet analysis service (Section 3.1).
",1 Introduction,[0],[0]
"• Experimental results of sentiment classification show that our method outperforms the current semi-supervised methods based on a language model, autoencoder, and distant supervision, as well as linear classifiers (Section 3.4).",1 Introduction,[0],[0]
"Our pretraining strategy simply consists of the following two steps:
1We use the term “conditional language model” in a narrow sense only for a model trained with explicit source-target pairs, although both RNN-based language and autoencoder models can generate a text from a real-valued context vector.
1.",2 Proposed Method,[0],[0]
"Training a dialog (encoder-decoder) model using unlabeled dialog data (tweet-reply pairs) as pretraining.
2.",2 Proposed Method,[0],[0]
"Training a sentiment classifier (encoderlabeler) model using labeled sentiment data (tweet-label pairs) after initializing its encoder part with the encoder parameters of the encoder-decoder model.
",2 Proposed Method,[0],[0]
"The encoder-decoder model is a conditional language model that predicts a correct output sequence from an input sequence (Sutskever et al., 2014).",2 Proposed Method,[0],[0]
This model consists of two RNNs: an encoder and decoder.,2 Proposed Method,[0],[0]
"The encoder extracts a context of the input sequence as a real-valued vector, and the decoder predicts the output sequences from the context individually.
",2 Proposed Method,[0],[0]
"Our classifier forms an encoder-labeler structure, which consists of the above encoder and a labeler that predicts a sentiment label from the context.",2 Proposed Method,[0],[0]
"Note that the encoder of the classifier is finetuned with labeled data, as in (Dai and Le, 2015).",2 Proposed Method,[0],[0]
"The main difference between their approach and ours is that we examine paired (dialog) data for pretraining, while they only showed the usefulness of pretraining with unpaired data.",2 Proposed Method,[0],[0]
"We used two datasets, a dialog dataset for pretraining the encoder-decoder model and a sentiment dataset for training (fine-tuning) the sentiment classifier, as shown in Table 1.",3.1 Datasets,[0],[0]
"Those datasets were provided by Yahoo! JAPAN, which is the largest portal site in Japan.
",3.1 Datasets,[0],[0]
The dialog dataset contains about 22.3 million tweet-reply pairs extracted from Twitter Firehose data.,3.1 Datasets,[0],[0]
"In its preprocessing, we filtered out spam and bot posts by using user-level signals such as the follower count, the friend count, the favorite count, and whether a profile image is set or not.",3.1 Datasets,[0],[0]
"Also, we replaced all the URLs in the text with “[u]” and all the user mentions with “[m]”, considering them as noise.",3.1 Datasets,[0],[0]
"The rest of the text was used
as it was.",3.1 Datasets,[0],[0]
"On average, source and target (or reply) tweets after preprocessing were 31.5 and 27.8 characters long, respectively.",3.1 Datasets,[0],[0]
"While redistribution of tweets is prohibited, we are planning to publicize tweet IDs of this dataset for reproducibility.2
The sentiment dataset includes about 100K tweets with manually annotated three-class sentiment labels: positive, negative, and neutral.",3.1 Datasets,[0],[0]
"The breakdown of positive, negative, and neutral in the training set was 15.0, 18.6, and 66.4%, respectively.",3.1 Datasets,[0],[0]
Note that the tweets were sampled separately from those of the dialog dataset.,3.1 Datasets,[0],[0]
The procedure for text preprocessing was the same with that of the dialog dataset.,3.1 Datasets,[0],[0]
The average length of the tweets after preprocessing was 17 characters.,3.1 Datasets,[0],[0]
Each tweet was judged by a majority vote of three experienced editors in the company providing the sentiment-analysis service.,3.1 Datasets,[0],[0]
The inter-annotator agreement ratio assessed with Fleiss’ κ was 0.495.,3.1 Datasets,[0],[0]
The overall annotation work took roughly 300 person-days.,3.1 Datasets,[0],[0]
"This means that the cost is at least 24K dollars, 8 hours × 300 days × legal minimum wage in Japan 10 dollars/hour.",3.1 Datasets,[0],[0]
"Considering that the in-house annotators are well-educated, skilled proper employees, the actual cost would be much higher than this rough estimate and much more costly than collecting unlabeled dialog data.",3.1 Datasets,[0],[0]
"In addition, the annotators had gone through a few days of training to become able to appropriately judge the sentiment before they got down to actual annotation work, but the number, 300 person-days, does not include the time for this training.",3.1 Datasets,[0],[0]
The settings of the dialog (encoder-decoder) model are as follows.,3.2 Model and Training,[0],[0]
"In both the encoder and decoder, the size of the word-embedding layer is 256 and that of the LSTM-RNN hidden layer is 1024.",3.2 Model and Training,[0],[0]
"The size of the output layer is 4000, which is the same as the (character-based) vocabulary size.3.",3.2 Model and Training,[0],[0]
"The encoder and decoder share these hyperparameters as well as the parameters themselves (that is, with regard to the embedding layer and
2The tweet IDs will be provided from https://researchlab.yahoo.co.jp/en/software/ .
",3.2 Model and Training,[0],[0]
3We used a character-based model since it performed better than word-based models in our preliminary experiments.,3.2 Model and Training,[0],[0]
"Existing morphological analyzers needed for wordbased models have usually been trained by formal text such as that of newspapers and seem not suitable to highly colloquial text seen in tweets, which often includes emoticons and emoji.
recurrent layer).",3.2 Model and Training,[0],[0]
"The total number of parameters is 8.9 million.
",3.2 Model and Training,[0],[0]
The settings of the sentiment classifier (encoder-labeler) model are as follows.,3.2 Model and Training,[0],[0]
"The encoder part has the same structure and hyperparameters as that of the dialog model, making them compatible for transferring learned parameters.",3.2 Model and Training,[0],[0]
We reused the dialog model’s dictionaries in the classifier model so that the two models could process tweet texts consistently.,3.2 Model and Training,[0],[0]
"The labeler consists of a fully connected layer and soft max nonlinearity.
",3.2 Model and Training,[0],[0]
"The models were trained with ADADELTA (Zeiler, 2012) with a mini-batch size of 64.",3.2 Model and Training,[0],[0]
"The dialog model was trained in five epochs, and the classifier model was tuned with the early-stopping strategy, which stops training when the validation accuracy drops.",3.2 Model and Training,[0],[0]
"For ADADELTA’s parameters, we fixed the learning rate to 1.0, decay rate ρ to 0.95, and smoothing constant ϵ to 10−6 for all training sessions.",3.2 Model and Training,[0],[0]
We evaluated validation costs ten times per epoch and selected the model with the lowest validation cost.,3.2 Model and Training,[0],[0]
The training took 15.9 days on 1 GPU with 7 TFLOPS computational power.,3.2 Model and Training,[0],[0]
"We compared the following eight models: nonpretrained (Default), proposed dialog pretraining (Dial), current pretraining with unpaired data (Lang, SeqAE) and pseudo labeled data (Emo2M, Emo6M), and classical linear learners (LogReg, LinSVM).",3.3 Compared Models,[0],[0]
"The details of these models are given below.
",3.3 Compared Models,[0],[0]
"• Default: Trained without pretraining by executing only Step 2 in Section 2.
",3.3 Compared Models,[0],[0]
"• Dial: Pretrained with the dialog model described in Section 2.
",3.3 Compared Models,[0],[0]
"• Lang, SeqAE: Pretrained with the language model and autoencoder model proposed in (Dai and Le, 2015).",3.3 Compared Models,[0],[0]
"The language model is the decoder part of the encoder-decoder model using a zero vector as the initial hidden layer value, and the autoencoder model is the same structure of the encoder-decoder model, where input and output are the same.",3.3 Compared Models,[0],[0]
"To make the comparison as fair as possible, we used the reply-side of the dialog dataset for pretraining Lang and SeqAE so that the same supervision information on the
basis of the same tweet-reply pairs would be applied to Lang, SeqAE, and Dial.",3.3 Compared Models,[0],[0]
"The number of their pretraining epochs was also equal to that of Dial.
",3.3 Compared Models,[0],[0]
"• Emo2M, Emo6M: Pretrained with pseudo labeled data (2M, 6M) based on manually collected emoticons, which consist of 120 positive emoticons and 116 negative ones.",3.3 Compared Models,[0],[0]
This technique is also known as distant-supervision.,3.3 Compared Models,[0],[0]
These pseudo labels were annotated by extracting tweets including one of those emoticons from our dialog data and another 92M tweets.,3.3 Compared Models,[0],[0]
"Pretraining was conducted via a two-class sentiment classifier, which is a similar model to Default, since uncertain tweets without emoticons are not always neutral.",3.3 Compared Models,[0],[0]
We confirmed that this two-class classifier can reach more than 90% test accuracy on the emoticonbased test dataset.,3.3 Compared Models,[0],[0]
"After pretraining, the parameters of the encoder part were transfered to the final classifier model.
",3.3 Compared Models,[0],[0]
"• LogReg, LinSVM:",3.3 Compared Models,[0],[0]
"Logistic regression and linear support vector machine (SVM) models of LIBLINEAR (Fan et al., 2008) with bag-ofwords features, which consist of 50K unigrams (w/o stopwords), 50K bigrams, and 233 emoticons.",3.3 Compared Models,[0],[0]
"These features are based on a state-ofthe-art system (Mohammad et al., 2013) that performed best in the SEMEVAL competition (Nakov et al., 2013) and was actually used in the tweet analysis service of the data-providing company.",3.3 Compared Models,[0],[0]
The best parameters were found through a grid-search on the validation set.,3.3 Compared Models,[0],[0]
Table 2 shows the macro-average F-measure results of the compared models in Section 3.3 on the sentiment classification task when varying data size (5K to 80K).,3.4 Results,[0],[0]
"Each value is the average of five trials with different random seeds for each setting, and a value of a trial is the macro-average of F-measure values of three sentiment classes.",3.4 Results,[0],[0]
The first row (Default) shows the default sentiment classifier model without pretraining.,3.4 Results,[0],[0]
"The second row block (Dial to Emo6M) shows the results of the same training as Default after pretraining via different models, while the third block shows those of linear classifiers (non-RNN models).",3.4 Results,[0],[0]
"The supplemental materials also include the results measured by accuracy.
",3.4 Results,[0],[0]
"Comparing Dial with the other models, we can see that our pretraining strategy with dialog data consistently outperformed all the other models: state-of-the-art pretraining strategies with unpaired unlabeled data (Lang, SeqAE) and pseudo labeled data (Emo2M, Emo6M), as well as linear learners (LogReg, LinSVM).",3.4 Results,[0],[0]
"This indicates that unlabeled dialog data (tweet-reply pairs) have useful information for sentiment classifiers, as expected in Section 1.",3.4 Results,[0],[0]
"In fact, we observed that the pretrained encoder-decoder model seems to generate an appropriate reply, on which the sentiment on the input tweet is well reflected.",3.4 Results,[0],[0]
"For example, the reply “:(” was generated for the input tweet “I’m sorry to hear that” (see supplementary material for more examples).",3.4 Results,[0],[0]
Lang also outperformed well but did not overtake Dial.,3.4 Results,[0],[0]
The differences between Dial and Lang are statistically significant4 for all five training dataset sizes.,3.4 Results,[0],[0]
"Interestingly, SeqAE was not so effective like Dial, despite their model structures are basically the same.",3.4 Results,[0],[0]
"This implies that it is practically important to find appropriate data for pretraining, such as dialog data for sentiment classification.
",3.4 Results,[0],[0]
"As for the results of distant supervision with emoticons, both Emo2M and Emo6M performed worse than Default, and increasing the dataset size did not change the situation.",3.4 Results,[0],[0]
"The reason why these models did not perform as well as other pretraining-based models is considered to be noisy labels, especially in negative ones.",3.4 Results,[0],[0]
"We illustrate two instances in the Emo2M training data that include an emoticon that is usually negative emoti-
4Under the significance level of 0.05 with two-tailed t-test assuming unequal variances.
con but can be considered positive:
• 美人すぎるよ可愛い（; ;）, “She is so beautiful, cute (crying emoticon)”
• うらやましいです。おめでとうございます orz, “I envy you.",3.4 Results,[0],[0]
"Congratulations (bow-theknee emoticon)”
Comparing Default with LogReg and LinSVM, we can see that the linear models performed better than the default RNN model without pretraining, when the labeled data size is less than or equal to 20K. However, looking at the results of Dial, our method improved Default even for these cases (5K to 20K), and Dial clearly outperformed the linear models.",3.4 Results,[0],[0]
This means that pretraining is useful especially on the situation where the labeled data size is limited.,3.4 Results,[0],[0]
"After Dai and Le (2015) proposed the framework of semi-supervised sequence learning, there have been several attempts to extend sequence learning models for different tasks to semi-supervised settings.",4 Related Work,[0],[0]
"Cheng et al. (2016) and Ramachandran et al. (2017) studied semi-supervised training of machine translation models via an autoencoder model and language model, respectively.",4 Related Work,[0],[0]
"They also used paired data (parallel corpora), but unsupervised training was conducted with reasonable monolingual corpora to compensate for costly parallel corpora, which is opposite to our setting.",4 Related Work,[0],[0]
"Zhou et al. (2016a,b) proposed to use parallel corpora for adapting the sentiment resources in a resource-rich language to a resource-poor language.",4 Related Work,[0],[0]
"Their purpose was completely different from ours, since making parallel corpora is also costly.",4 Related Work,[0],[0]
"The other studies include semi-supervised extensions for predicting the property values of Wikipedia (Hewlett et al., 2017), detecting medical conditions from heart rate data (Ballinger et al., 2018), and morphological reinflection of inflected words (e.g., “playing” to “played”).",4 Related Work,[0],[0]
"They did not use paired-text data to leverage their tasks.
",4 Related Work,[0],[0]
Our method can be regarded as a general version of distant supervision since we assume that a reply includes the label information of the corresponding tweet.,4 Related Work,[0],[0]
"There have been many studies about distant supervision for sentiment analysis (Read, 2005; Go et al., 2009; Davidov et al., 2010; Purver and Battersby, 2012; Mohammad et al., 2013; Tang et al., 2014; dos Santos and Gatti,
2014; Severyn and Moschitti, 2015; Deriu et al., 2016; Müller et al., 2017), but they basically focused on how to use emoticons and hashtags to leverage performance.",4 Related Work,[0],[0]
"One exception is the study by (Pool and Nissim, 2016), in which Facebook reactions were used for distant supervision.",4 Related Work,[0],[0]
"Their approach is similar to ours using tweet-reply pairs, but our method is more general since they only used six reply categories (i.e., like, love, haha, wow, sad, and angry), not text replies.
",4 Related Work,[0],[0]
"There have been a few studies on sentiment classification in dialogue data (Bertero and Fung, 2016; Bertero et al., 2016).",4 Related Work,[0],[0]
"These studies involved sentiment classification based on dialog contexts, which means that they used labeled dialog data, while we used unlabeled dialog data.",4 Related Work,[0],[0]
"For tweet data, several studies used reply-features for sentiment classification of tweets (Barbosa and Feng, 2010; Jiang et al., 2011; Vanzo et al., 2014; Bamman and Smith, 2015; Ren et al., 2016; Castellucci et al., 2016).",4 Related Work,[0],[0]
"However, they used replies as labeled data for sentiment classification, not unlabeled data for pretraining.",4 Related Work,[0],[0]
We proposed a pretraining strategy with dialog data for sentiment classifiers.,5 Conclusion,[0],[0]
"The experimental results showed that our strategy clearly outperformed the existing pretraining with unpaired unlabeled data via language modeling and pseudo labeled data via distant supervision, as well as linear classifiers.",5 Conclusion,[0],[0]
"In the future, we will investigate whether or not we can use other paired data for pretraining of classification tasks.",5 Conclusion,[0],[0]
"For example, we expect that news article-comment pairs are useful for predicting fake news detection and that question-answer pairs of Q&A sites are useful for recommending questions for answering.",5 Conclusion,[0],[0]
The huge cost of creating labeled training data is a common problem for supervised learning tasks such as sentiment classification.,abstractText,[0],[0]
Recent studies showed that pretraining with unlabeled data via a language model can improve the performance of classification models.,abstractText,[0],[0]
"In this paper, we take the concept a step further by using a conditional language model, instead of a language model.",abstractText,[0],[0]
"Specifically, we address a sentiment classification task for a tweet analysis service as a case study and propose a pretraining strategy with unlabeled dialog data (tweet-reply pairs) via an encoder-decoder model.",abstractText,[0],[0]
Experimental results show that our strategy can improve the performance of sentiment classifiers and outperform several state-of-theart strategies including language model pretraining.,abstractText,[0],[0]
Pretraining Sentiment Classifiers with Unlabeled Dialog Data,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 764–770 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
764",text,[0],[0]
"Sentiment classification is a task to predict a sentiment label, such as positive/negative, for a given text and has been applied to many domains such as movie/product reviews, customer surveys, news comments, and social media.",1 Introduction,[0],[0]
"A common problem of this task is the lack of labeled training data due to costly annotation work, especially for social media without explicit sentiment feedback such as review scores.
",1 Introduction,[0],[0]
"To overcome this problem, Dai and Le (2015) recently proposed a semi-supervised sequence learning framework, where a sentiment classifier based on recurrent neural networks (RNNs) is trained with labeled data after initializing it with the parameters of an RNN-based language model pretrained with a large amount of unlabeled data.
",1 Introduction,[0],[0]
"The concept of their framework is simple but effective, and their work yielded many related studies of semi-supervised training based on sequence modeling, as described in Section 4.
",1 Introduction,[0],[0]
"In this paper, we take their concept a step further by using a conditional language model with unlabeled dialog data (i.e., tweet-reply pairs) instead of a language model with unpaired data1.",1 Introduction,[0],[0]
An important observation of the dialog data that underpins our strategy is that the sentiment or mood in a message often affects messages in reply to it.,1 Introduction,[0],[0]
"People tend to write angry responses to angry messages, empathetic replies to sad remarks, or congratulatory phrases to good news.
",1 Introduction,[0],[0]
"Our contributions are listed as follows.
",1 Introduction,[0],[0]
• We propose a pretraining strategy with unlabeled dialog data (tweet-reply pairs) via an encoder-decoder model for sentiment classifiers (Section 2).,1 Introduction,[0],[0]
"To the best of our knowledge, our proposal is the first such proposal, as clarified in Section 4.
",1 Introduction,[0],[0]
"• We report on a case study based on a costly labeled sentiment dataset of 99.5K items and a large-scale unlabeled dialog dataset of 22.3M, which were provided from a tweet analysis service (Section 3.1).
",1 Introduction,[0],[0]
"• Experimental results of sentiment classification show that our method outperforms the current semi-supervised methods based on a language model, autoencoder, and distant supervision, as well as linear classifiers (Section 3.4).",1 Introduction,[0],[0]
"Our pretraining strategy simply consists of the following two steps:
1We use the term “conditional language model” in a narrow sense only for a model trained with explicit source-target pairs, although both RNN-based language and autoencoder models can generate a text from a real-valued context vector.
1.",2 Proposed Method,[0],[0]
"Training a dialog (encoder-decoder) model using unlabeled dialog data (tweet-reply pairs) as pretraining.
2.",2 Proposed Method,[0],[0]
"Training a sentiment classifier (encoderlabeler) model using labeled sentiment data (tweet-label pairs) after initializing its encoder part with the encoder parameters of the encoder-decoder model.
",2 Proposed Method,[0],[0]
"The encoder-decoder model is a conditional language model that predicts a correct output sequence from an input sequence (Sutskever et al., 2014).",2 Proposed Method,[0],[0]
This model consists of two RNNs: an encoder and decoder.,2 Proposed Method,[0],[0]
"The encoder extracts a context of the input sequence as a real-valued vector, and the decoder predicts the output sequences from the context individually.
",2 Proposed Method,[0],[0]
"Our classifier forms an encoder-labeler structure, which consists of the above encoder and a labeler that predicts a sentiment label from the context.",2 Proposed Method,[0],[0]
"Note that the encoder of the classifier is finetuned with labeled data, as in (Dai and Le, 2015).",2 Proposed Method,[0],[0]
"The main difference between their approach and ours is that we examine paired (dialog) data for pretraining, while they only showed the usefulness of pretraining with unpaired data.",2 Proposed Method,[0],[0]
"We used two datasets, a dialog dataset for pretraining the encoder-decoder model and a sentiment dataset for training (fine-tuning) the sentiment classifier, as shown in Table 1.",3.1 Datasets,[0],[0]
"Those datasets were provided by Yahoo! JAPAN, which is the largest portal site in Japan.
",3.1 Datasets,[0],[0]
The dialog dataset contains about 22.3 million tweet-reply pairs extracted from Twitter Firehose data.,3.1 Datasets,[0],[0]
"In its preprocessing, we filtered out spam and bot posts by using user-level signals such as the follower count, the friend count, the favorite count, and whether a profile image is set or not.",3.1 Datasets,[0],[0]
"Also, we replaced all the URLs in the text with “[u]” and all the user mentions with “[m]”, considering them as noise.",3.1 Datasets,[0],[0]
"The rest of the text was used
as it was.",3.1 Datasets,[0],[0]
"On average, source and target (or reply) tweets after preprocessing were 31.5 and 27.8 characters long, respectively.",3.1 Datasets,[0],[0]
"While redistribution of tweets is prohibited, we are planning to publicize tweet IDs of this dataset for reproducibility.2
The sentiment dataset includes about 100K tweets with manually annotated three-class sentiment labels: positive, negative, and neutral.",3.1 Datasets,[0],[0]
"The breakdown of positive, negative, and neutral in the training set was 15.0, 18.6, and 66.4%, respectively.",3.1 Datasets,[0],[0]
Note that the tweets were sampled separately from those of the dialog dataset.,3.1 Datasets,[0],[0]
The procedure for text preprocessing was the same with that of the dialog dataset.,3.1 Datasets,[0],[0]
The average length of the tweets after preprocessing was 17 characters.,3.1 Datasets,[0],[0]
Each tweet was judged by a majority vote of three experienced editors in the company providing the sentiment-analysis service.,3.1 Datasets,[0],[0]
The inter-annotator agreement ratio assessed with Fleiss’ κ was 0.495.,3.1 Datasets,[0],[0]
The overall annotation work took roughly 300 person-days.,3.1 Datasets,[0],[0]
"This means that the cost is at least 24K dollars, 8 hours × 300 days × legal minimum wage in Japan 10 dollars/hour.",3.1 Datasets,[0],[0]
"Considering that the in-house annotators are well-educated, skilled proper employees, the actual cost would be much higher than this rough estimate and much more costly than collecting unlabeled dialog data.",3.1 Datasets,[0],[0]
"In addition, the annotators had gone through a few days of training to become able to appropriately judge the sentiment before they got down to actual annotation work, but the number, 300 person-days, does not include the time for this training.",3.1 Datasets,[0],[0]
The settings of the dialog (encoder-decoder) model are as follows.,3.2 Model and Training,[0],[0]
"In both the encoder and decoder, the size of the word-embedding layer is 256 and that of the LSTM-RNN hidden layer is 1024.",3.2 Model and Training,[0],[0]
"The size of the output layer is 4000, which is the same as the (character-based) vocabulary size.3.",3.2 Model and Training,[0],[0]
"The encoder and decoder share these hyperparameters as well as the parameters themselves (that is, with regard to the embedding layer and
2The tweet IDs will be provided from https://researchlab.yahoo.co.jp/en/software/ .
",3.2 Model and Training,[0],[0]
3We used a character-based model since it performed better than word-based models in our preliminary experiments.,3.2 Model and Training,[0],[0]
"Existing morphological analyzers needed for wordbased models have usually been trained by formal text such as that of newspapers and seem not suitable to highly colloquial text seen in tweets, which often includes emoticons and emoji.
recurrent layer).",3.2 Model and Training,[0],[0]
"The total number of parameters is 8.9 million.
",3.2 Model and Training,[0],[0]
The settings of the sentiment classifier (encoder-labeler) model are as follows.,3.2 Model and Training,[0],[0]
"The encoder part has the same structure and hyperparameters as that of the dialog model, making them compatible for transferring learned parameters.",3.2 Model and Training,[0],[0]
We reused the dialog model’s dictionaries in the classifier model so that the two models could process tweet texts consistently.,3.2 Model and Training,[0],[0]
"The labeler consists of a fully connected layer and soft max nonlinearity.
",3.2 Model and Training,[0],[0]
"The models were trained with ADADELTA (Zeiler, 2012) with a mini-batch size of 64.",3.2 Model and Training,[0],[0]
"The dialog model was trained in five epochs, and the classifier model was tuned with the early-stopping strategy, which stops training when the validation accuracy drops.",3.2 Model and Training,[0],[0]
"For ADADELTA’s parameters, we fixed the learning rate to 1.0, decay rate ρ to 0.95, and smoothing constant ϵ to 10−6 for all training sessions.",3.2 Model and Training,[0],[0]
We evaluated validation costs ten times per epoch and selected the model with the lowest validation cost.,3.2 Model and Training,[0],[0]
The training took 15.9 days on 1 GPU with 7 TFLOPS computational power.,3.2 Model and Training,[0],[0]
"We compared the following eight models: nonpretrained (Default), proposed dialog pretraining (Dial), current pretraining with unpaired data (Lang, SeqAE) and pseudo labeled data (Emo2M, Emo6M), and classical linear learners (LogReg, LinSVM).",3.3 Compared Models,[0],[0]
"The details of these models are given below.
",3.3 Compared Models,[0],[0]
"• Default: Trained without pretraining by executing only Step 2 in Section 2.
",3.3 Compared Models,[0],[0]
"• Dial: Pretrained with the dialog model described in Section 2.
",3.3 Compared Models,[0],[0]
"• Lang, SeqAE: Pretrained with the language model and autoencoder model proposed in (Dai and Le, 2015).",3.3 Compared Models,[0],[0]
"The language model is the decoder part of the encoder-decoder model using a zero vector as the initial hidden layer value, and the autoencoder model is the same structure of the encoder-decoder model, where input and output are the same.",3.3 Compared Models,[0],[0]
"To make the comparison as fair as possible, we used the reply-side of the dialog dataset for pretraining Lang and SeqAE so that the same supervision information on the
basis of the same tweet-reply pairs would be applied to Lang, SeqAE, and Dial.",3.3 Compared Models,[0],[0]
"The number of their pretraining epochs was also equal to that of Dial.
",3.3 Compared Models,[0],[0]
"• Emo2M, Emo6M: Pretrained with pseudo labeled data (2M, 6M) based on manually collected emoticons, which consist of 120 positive emoticons and 116 negative ones.",3.3 Compared Models,[0],[0]
This technique is also known as distant-supervision.,3.3 Compared Models,[0],[0]
These pseudo labels were annotated by extracting tweets including one of those emoticons from our dialog data and another 92M tweets.,3.3 Compared Models,[0],[0]
"Pretraining was conducted via a two-class sentiment classifier, which is a similar model to Default, since uncertain tweets without emoticons are not always neutral.",3.3 Compared Models,[0],[0]
We confirmed that this two-class classifier can reach more than 90% test accuracy on the emoticonbased test dataset.,3.3 Compared Models,[0],[0]
"After pretraining, the parameters of the encoder part were transfered to the final classifier model.
",3.3 Compared Models,[0],[0]
"• LogReg, LinSVM:",3.3 Compared Models,[0],[0]
"Logistic regression and linear support vector machine (SVM) models of LIBLINEAR (Fan et al., 2008) with bag-ofwords features, which consist of 50K unigrams (w/o stopwords), 50K bigrams, and 233 emoticons.",3.3 Compared Models,[0],[0]
"These features are based on a state-ofthe-art system (Mohammad et al., 2013) that performed best in the SEMEVAL competition (Nakov et al., 2013) and was actually used in the tweet analysis service of the data-providing company.",3.3 Compared Models,[0],[0]
The best parameters were found through a grid-search on the validation set.,3.3 Compared Models,[0],[0]
Table 2 shows the macro-average F-measure results of the compared models in Section 3.3 on the sentiment classification task when varying data size (5K to 80K).,3.4 Results,[0],[0]
"Each value is the average of five trials with different random seeds for each setting, and a value of a trial is the macro-average of F-measure values of three sentiment classes.",3.4 Results,[0],[0]
The first row (Default) shows the default sentiment classifier model without pretraining.,3.4 Results,[0],[0]
"The second row block (Dial to Emo6M) shows the results of the same training as Default after pretraining via different models, while the third block shows those of linear classifiers (non-RNN models).",3.4 Results,[0],[0]
"The supplemental materials also include the results measured by accuracy.
",3.4 Results,[0],[0]
"Comparing Dial with the other models, we can see that our pretraining strategy with dialog data consistently outperformed all the other models: state-of-the-art pretraining strategies with unpaired unlabeled data (Lang, SeqAE) and pseudo labeled data (Emo2M, Emo6M), as well as linear learners (LogReg, LinSVM).",3.4 Results,[0],[0]
"This indicates that unlabeled dialog data (tweet-reply pairs) have useful information for sentiment classifiers, as expected in Section 1.",3.4 Results,[0],[0]
"In fact, we observed that the pretrained encoder-decoder model seems to generate an appropriate reply, on which the sentiment on the input tweet is well reflected.",3.4 Results,[0],[0]
"For example, the reply “:(” was generated for the input tweet “I’m sorry to hear that” (see supplementary material for more examples).",3.4 Results,[0],[0]
Lang also outperformed well but did not overtake Dial.,3.4 Results,[0],[0]
The differences between Dial and Lang are statistically significant4 for all five training dataset sizes.,3.4 Results,[0],[0]
"Interestingly, SeqAE was not so effective like Dial, despite their model structures are basically the same.",3.4 Results,[0],[0]
"This implies that it is practically important to find appropriate data for pretraining, such as dialog data for sentiment classification.
",3.4 Results,[0],[0]
"As for the results of distant supervision with emoticons, both Emo2M and Emo6M performed worse than Default, and increasing the dataset size did not change the situation.",3.4 Results,[0],[0]
"The reason why these models did not perform as well as other pretraining-based models is considered to be noisy labels, especially in negative ones.",3.4 Results,[0],[0]
"We illustrate two instances in the Emo2M training data that include an emoticon that is usually negative emoti-
4Under the significance level of 0.05 with two-tailed t-test assuming unequal variances.
con but can be considered positive:
• 美人すぎるよ可愛い（; ;）, “She is so beautiful, cute (crying emoticon)”
• うらやましいです。おめでとうございます orz, “I envy you.",3.4 Results,[0],[0]
"Congratulations (bow-theknee emoticon)”
Comparing Default with LogReg and LinSVM, we can see that the linear models performed better than the default RNN model without pretraining, when the labeled data size is less than or equal to 20K. However, looking at the results of Dial, our method improved Default even for these cases (5K to 20K), and Dial clearly outperformed the linear models.",3.4 Results,[0],[0]
This means that pretraining is useful especially on the situation where the labeled data size is limited.,3.4 Results,[0],[0]
"After Dai and Le (2015) proposed the framework of semi-supervised sequence learning, there have been several attempts to extend sequence learning models for different tasks to semi-supervised settings.",4 Related Work,[0],[0]
"Cheng et al. (2016) and Ramachandran et al. (2017) studied semi-supervised training of machine translation models via an autoencoder model and language model, respectively.",4 Related Work,[0],[0]
"They also used paired data (parallel corpora), but unsupervised training was conducted with reasonable monolingual corpora to compensate for costly parallel corpora, which is opposite to our setting.",4 Related Work,[0],[0]
"Zhou et al. (2016a,b) proposed to use parallel corpora for adapting the sentiment resources in a resource-rich language to a resource-poor language.",4 Related Work,[0],[0]
"Their purpose was completely different from ours, since making parallel corpora is also costly.",4 Related Work,[0],[0]
"The other studies include semi-supervised extensions for predicting the property values of Wikipedia (Hewlett et al., 2017), detecting medical conditions from heart rate data (Ballinger et al., 2018), and morphological reinflection of inflected words (e.g., “playing” to “played”).",4 Related Work,[0],[0]
"They did not use paired-text data to leverage their tasks.
",4 Related Work,[0],[0]
Our method can be regarded as a general version of distant supervision since we assume that a reply includes the label information of the corresponding tweet.,4 Related Work,[0],[0]
"There have been many studies about distant supervision for sentiment analysis (Read, 2005; Go et al., 2009; Davidov et al., 2010; Purver and Battersby, 2012; Mohammad et al., 2013; Tang et al., 2014; dos Santos and Gatti,
2014; Severyn and Moschitti, 2015; Deriu et al., 2016; Müller et al., 2017), but they basically focused on how to use emoticons and hashtags to leverage performance.",4 Related Work,[0],[0]
"One exception is the study by (Pool and Nissim, 2016), in which Facebook reactions were used for distant supervision.",4 Related Work,[0],[0]
"Their approach is similar to ours using tweet-reply pairs, but our method is more general since they only used six reply categories (i.e., like, love, haha, wow, sad, and angry), not text replies.
",4 Related Work,[0],[0]
"There have been a few studies on sentiment classification in dialogue data (Bertero and Fung, 2016; Bertero et al., 2016).",4 Related Work,[0],[0]
"These studies involved sentiment classification based on dialog contexts, which means that they used labeled dialog data, while we used unlabeled dialog data.",4 Related Work,[0],[0]
"For tweet data, several studies used reply-features for sentiment classification of tweets (Barbosa and Feng, 2010; Jiang et al., 2011; Vanzo et al., 2014; Bamman and Smith, 2015; Ren et al., 2016; Castellucci et al., 2016).",4 Related Work,[0],[0]
"However, they used replies as labeled data for sentiment classification, not unlabeled data for pretraining.",4 Related Work,[0],[0]
We proposed a pretraining strategy with dialog data for sentiment classifiers.,5 Conclusion,[0],[0]
"The experimental results showed that our strategy clearly outperformed the existing pretraining with unpaired unlabeled data via language modeling and pseudo labeled data via distant supervision, as well as linear classifiers.",5 Conclusion,[0],[0]
"In the future, we will investigate whether or not we can use other paired data for pretraining of classification tasks.",5 Conclusion,[0],[0]
"For example, we expect that news article-comment pairs are useful for predicting fake news detection and that question-answer pairs of Q&A sites are useful for recommending questions for answering.",5 Conclusion,[0],[0]
The huge cost of creating labeled training data is a common problem for supervised learning tasks such as sentiment classification.,abstractText,[0],[0]
Recent studies showed that pretraining with unlabeled data via a language model can improve the performance of classification models.,abstractText,[0],[0]
"In this paper, we take the concept a step further by using a conditional language model, instead of a language model.",abstractText,[0],[0]
"Specifically, we address a sentiment classification task for a tweet analysis service as a case study and propose a pretraining strategy with unlabeled dialog data (tweet-reply pairs) via an encoder-decoder model.",abstractText,[0],[0]
Experimental results show that our strategy can improve the performance of sentiment classifiers and outperform several state-of-theart strategies including language model pretraining.,abstractText,[0],[0]
Pretraining Sentiment Classifiers with Unlabeled Dialog Data,title,[0],[0]
Matrix decomposition methods such as factor analysis are a widely used class of models for unsupervised learning.,1. Introduction,[0],[0]
"Typically, they operate on two-way matrices with rows thought of as objects and columns thought of as properties.",1. Introduction,[0],[0]
"The decomposition amounts to computing two low-rank matrices, one that contains prototypes of properties (loadings)
1Department of Statistics, University of Oxford, UK 2The Alan Turing Institute, London, UK 3Centre for Computational Biology, Institute of Cancer and Genomic Sciences, University of Birmingham, UK.",1. Introduction,[0],[0]
"Correspondence to: Tammo Rukat <tammo.rukat@stats.ox.ac.uk>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
2 https://github.com/TammoR/LogicalFactorisationMachines
and one that denotes a compressed representation of each object as a combination of the prototypes (factors).",1. Introduction,[0],[0]
"However, these methods are ill-suited for data with higher arity such as ternary interactions.",1. Introduction,[0],[0]
"Examples include network interactions at different time-points, gene-gene interactions for different individuals or any two-way data under different experimental conditions.",1. Introduction,[0],[0]
"Such data requires methods that specifically account for the higher-order relationship and that are commonly referred to as tensor decomposition.
",1. Introduction,[0],[0]
"Boolean tensor decomposition factorises a K-way binary tensor X ∈ {0, 1}N1×...×NK , into K binary factor matrices",1. Introduction,[0],[0]
"Fk ∈ {0, 1}Nk×L, using the Boolean algebra such that
x[n]",1. Introduction,[0],[0]
"≈ L∨
l=1  ∧ n∈[n] fnl  .",1. Introduction,[0],[0]
"(1) Here, x[n] is a single tensor entry and [n] denotes a tuple of indices [n1, . . .",1. Introduction,[0],[0]
", nK ].",1. Introduction,[0],[0]
We call k = 1 . . .K,1. Introduction,[0],[0]
"the modes of the tensor, ∨ and ∧ denote the logical OR and the logical AND operation, respectively.",1. Introduction,[0],[0]
"In plain English, eq. (1) says that an observation is 1, if and only if there exist one or more latent dimensions in which all corresponding factors are 1.",1. Introduction,[0],[0]
"This leads to easily interpretable factor matrices, Fk, where each latent dimension denotes a subset of entries along mode k, for instance subsets of objects, properties and conditions that occur jointly in the data.",1. Introduction,[0],[0]
"This can be thought of as a particular type of canonical polyadic (CP) decomposition, as illustrated in Fig. 1.",1. Introduction,[0],[0]
A different graphical intuition starts from the factor rows and considers the 3-way Boolean tensor product as a three-stage template assignment procedure.,1. Introduction,[0],[0]
Rows of a factor matrix F1 are one-dimensional binary templates of size of the first tensor mode.,1. Introduction,[0],[0]
"Rows
of the second factor matrix F2 indicates possible patterns of appearance of these templates along the second tensor dimensions.",1. Introduction,[0],[0]
"In the same manner, the third factor matrix, F3, indicates which disjunction of these 2D patterns appears in each slice of the tensor, and so forth.
",1. Introduction,[0],[0]
"We present the first probabilistic approach to Boolean tensor decomposition, the TensOrMachine, featuring distinctly improved accuracy compared to the previous state-of-the-art methods.",1. Introduction,[0],[0]
"We develop scalable, sampling-based posterior inference and infer distributions over factor matrices which enables full quantification of uncertainty.",1. Introduction,[0],[0]
"In contrast to previous approaches, the probabilistic framework readily treats missing data, allows for tensor completion and integration of prior information.",1. Introduction,[0],[0]
"Importantly, the latent representations are amenable to informative and intuitive interpretation.",1. Introduction,[0],[0]
Tensor decomposition methods are widely used in many domains of application as reviewed by Kolda & Bader (2009).,2. Related Work,[0],[0]
"Boolean Tensor decomposition was first introduced in the Psychometric literature by Leenen et al. (1999) and has received lasting attention, following the formal study by Miettinen (2011).",2. Related Work,[0],[0]
The author shows that computing the optimal decomposition is NP-hard and proposes an alternating least squares heuristics as approximate strategy.,2. Related Work,[0],[0]
A different approach based on a random-walk procedure is described by Erdos & Miettinen (2013b) and trades accuracy in the factors for computational scalability.,2. Related Work,[0],[0]
"More recently a distributed Apache Spark implementation of the alternating least squares approach has been brought forward (Park et al., 2017).",2. Related Work,[0],[0]
It demonstrates that alternating leasts squares is the state-of-the-art for computing accurate decompositions and serves as baseline method for our experiments.,2. Related Work,[0],[0]
"Boolean Matrix Factorisation (Miettinen et al., 2006) shares the logical structure of Boolean tensor decomposition.",2. Related Work,[0],[0]
"It has many real-world applications such as collaborative filtering (Su & Khoshgoftaar, 2009) and computer vision (Lázaro-Gredilla et al., 2016) and has previously been approached under a probabilistic perspective (Ravanbakhsh et al., 2016; Rukat et al., 2017).",2. Related Work,[0],[0]
"Despite the sustained theoretical interest, there have been only few practical applications of Boolean tensor decomposition, as for instance for information extraction (Erdos & Miettinen, 2013a) and clustering (Metzler & Miettinen, 2015).",2. Related Work,[0],[0]
"One of the contributions of this work is the presentation of Boolean Tensor decomposition as an interpretable, versatile and scalable analysis method.",2. Related Work,[0],[0]
We propose a probabilistic generative process for the model described in eq.,3.1. Model Description,[0],[0]
(1).,3.1. Model Description,[0],[0]
"Each tensor entry, x[n] = x[n1,...,nK ], is
a Bernoulli random variable that equals 1 with a probability greater 12 if the following holds true
∃ l : fnl = 1 ∀ n ∈",3.1. Model Description,[0],[0]
"[n1, . . .",3.1. Model Description,[0],[0]
", nK ].",3.1. Model Description,[0],[0]
"(2)
The logistic sigmoid σ(x) =",3.1. Model Description,[0],[0]
"(1+e−x)−1 has the convenient property σ(−x) = 1− σ(x) and lets us readily parametrise the corresponding likelihood
p(x[n]|.)",3.1. Model Description,[0],[0]
= σ λx̃[n],3.1. Model Description,[0],[0]
"1− 2∏
l 1− ∏ n∈[n] fnl  .",3.1. Model Description,[0],[0]
"(3)
The term inside parenthesis evaluates to 1 if the condition in eq.",3.1. Model Description,[0],[0]
"(2) is met and to -1, otherwise.",3.1. Model Description,[0],[0]
"Throughout this work, we use a tilde to denote the mapping from {0, 1} to {−1, 1} such that x̃ = 2x−1.",3.1. Model Description,[0],[0]
"The noise is parametrised by λ ∈ R+, such that for λ→ 0 the likelihood is constant, independent of the factors and for λ→∞ all probability mass is put on the deterministic Boolean tensor product following eq.",3.1. Model Description,[0],[0]
(1).,3.1. Model Description,[0],[0]
We can specify Bernoulli priors on the observations x[n] or choose more structured prior distributions.,3.1. Model Description,[0],[0]
A beta-prior on σ(λ) is a computationally convenient choice as we discuss in the following section.,3.1. Model Description,[0],[0]
"However, in the relevant regime of thousand and more data-points such priors are easily outweighed by the observed data.",3.1. Model Description,[0],[0]
We therefore assume constant prior distributions in the following derivations and experiments.,3.1. Model Description,[0],[0]
"Boolean decomposition models have an interesting relation to the noisy-OR, a canonical model for multi-causal interactions, which makes the assumption of independence between the inhibition of latent causes (Pearl, 1988).",3.2. Relation to Noisy-OR Models,[0],[0]
TensOrM violates this assumption with inhibition occurring on the event-level rather than on the cause-level.,3.2. Relation to Noisy-OR Models,[0],[0]
"As an example, in analogy to the data presented in Section.",3.2. Relation to Noisy-OR Models,[0],[0]
"5.2, consider the event of a students attending a lecture.",3.2. Relation to Noisy-OR Models,[0],[0]
We assume that this has two possible causes.,3.2. Relation to Noisy-OR Models,[0],[0]
They may (i) use the opportunity to meet fellow students (ii) have a particular question that they wish to clarify in class.,3.2. Relation to Noisy-OR Models,[0],[0]
An inhibition on the level of causes may occur if they found a satisfying answer to their question in a textbook.,3.2. Relation to Noisy-OR Models,[0],[0]
"Then, the desire to meet their friends still contributes to the likelihood of attending class.",3.2. Relation to Noisy-OR Models,[0],[0]
This naturally modelled by the noisy-OR.,3.2. Relation to Noisy-OR Models,[0],[0]
"In contrast, inhibition on the event-level may occur if a traffic disruption makes it impossible to get to campus.",3.2. Relation to Noisy-OR Models,[0],[0]
"This is naturally described by a Boolean factor model, where any additional causes to attend the lecture will not contribute to the likelihood.",3.2. Relation to Noisy-OR Models,[0],[0]
We argue that for many practical purposes the latter is an interesting alternative.,3.2. Relation to Noisy-OR Models,[0],[0]
"Even if we were to believe in the independent inhibition of latent causes, usually only one latent cause triggers an event.",3.2. Relation to Noisy-OR Models,[0],[0]
"Compared to the noisy-OR, TensOrM acts as an Occam’s razor and enforces sparse and
simple explanations, aiming to associate exactly one hidden cause with every event.",3.2. Relation to Noisy-OR Models,[0],[0]
"We condition any entry of a factor matrix, fnkl, on the state of all other parameters which yields the full conditional probability for Gibbs sampling:
p(fnkl|.)",3.3. Posterior Inference,[0],[0]
= σ,3.3. Posterior Inference,[0],[0]
"( λf̃nkl ∑ [n]
nkfixed
x̃[n]M(nk,l)→[n]
) .",3.3. Posterior Inference,[0],[0]
"(4)
We give a formal derivation in the Supplementary Information A and provide an intuitive explanation in the following.",3.3. Posterior Inference,[0],[0]
"The sigmoid maps from the real line to the interval of [0, 1].",3.3. Posterior Inference,[0],[0]
The sum in its argument is taken over all observations x[n] whose likelihood may depend on fnkl.,3.3. Posterior Inference,[0],[0]
These observations are given by the (K−1)–way sub-tensor of X with dimension nk fixed and correspond to all children of fnkl in a graphical model representation.,3.3. Posterior Inference,[0],[0]
"For each of them, the term inside the sigmoid contributes values in {−λ, 0, λ}.",3.3. Posterior Inference,[0],[0]
"This depends on whether or not f̃ and x̃ are aligned and an another indicator variable M(nk,l)→[n] that take values in {0, 1} and denotes whether the state of fnkl has any relevance for the likelihood of x[n].",3.3. Posterior Inference,[0],[0]
"It takes the form
M(nk,l)→[n] = ( ∏ n∈[n]/nk fnl )∏ l′ 6=l ( 1− ∏ n∈[n] fnl′ ) .",3.3. Posterior Inference,[0],[0]
"(5)
",3.3. Posterior Inference,[0],[0]
This variable is again composed of two indicators.,3.3. Posterior Inference,[0],[0]
"The first term is a product over the state of all co-parents of fnkl to observation x[n] in the same latent dimension l. Following the rules of the Boolean product, all these co-parents need to be one in order for fnkl to contribute to the likelihood of x[n].",3.3. Posterior Inference,[0],[0]
This corresponds to the AND-operation in eq.,3.3. Posterior Inference,[0],[0]
(1) that evaluates to zero if any its arguments are zero.,3.3. Posterior Inference,[0],[0]
The second term is a product of the co-parents in all other latent dimensions and evaluates to zero if any of them explains away observation x[n].,3.3. Posterior Inference,[0],[0]
"Following the rules of the Boolean product, a single latent dimension is sufficient to explain an observation and makes its likelihood independent of the state of fnkl.",3.3. Posterior Inference,[0],[0]
This corresponds to the OR-operation in eq. (1) that evaluates to one if any of its arguments is one.,3.3. Posterior Inference,[0],[0]
It is crucial for the speed of our implementation that eq.,3.3. Posterior Inference,[0],[0]
"(5), and thus eq.",3.3. Posterior Inference,[0],[0]
"(4), can be rapidly evaluated.",3.3. Posterior Inference,[0],[0]
"In particular, discovering a zero in any of the two terms of eq.",3.3. Posterior Inference,[0],[0]
(5) suffices for the whole expression to be zero and avoids the necessity of considering the remainder of the Markov blanket.,3.3. Posterior Inference,[0],[0]
Pseudocode for the computational procedure is given in Algorithm 1.,3.3. Posterior Inference,[0],[0]
Note that updates of fnkl can trivially be computed in parallel across nk for a fixed tensor-mode k.,3.3. Posterior Inference,[0],[0]
"The computation time scales linearly in each tensor dimension and sub-linear in the latent dimension.
",3.3. Posterior Inference,[0],[0]
Algorithm 1 Computation of the full conditional of fnkl m = 0 //,3.3. Posterior Inference,[0],[0]
initialise integer count for the sum in eq.,3.3. Posterior Inference,[0],[0]
"(4) for [n] in all tensor indices with slice nk fixed do
// check relevance of fnkl for x[n].",3.3. Posterior Inference,[0],[0]
"for n in [n] do
if fnl = 0 then // fnkl has no relevance for x[n].",3.3. Posterior Inference,[0],[0]
"continue with next [n]
end if end for // check for explaining away.",3.3. Posterior Inference,[0],[0]
"for l′ in 1, . . .",3.3. Posterior Inference,[0],[0]
", L except l do
for n in",3.3. Posterior Inference,[0],[0]
[n] do if fnl′ = 0,3.3. Posterior Inference,[0],[0]
"then
continue with next l’ end if // x[n] is explained away.",3.3. Posterior Inference,[0],[0]
"continue (next [n])
end for end for m = m + x̃nd
end for p(fnkl|.)",3.3. Posterior Inference,[0],[0]
"= ( 1 + exp ( −λ · f̃nkl ·m ))−1
",3.3. Posterior Inference,[0],[0]
"After a sampling all factor entries from their full conditional, we set the noise-parameter, λ, to its conditional MAP estimate and repeat until convergence before drawing posterior samples.",3.3. Posterior Inference,[0],[0]
The conditional MLE of λ is available in closed form and given by the logit of the fraction of datapoints that are correctly reconstructed by the deterministic Boolean product of the current state of the factors.,3.3. Posterior Inference,[0],[0]
"As a prior for σ(λ), it is natural to employ a Beta-distribution, p(σ(λ))",3.3. Posterior Inference,[0],[0]
"= Beta(σ(λ)|α, β).",3.3. Posterior Inference,[0],[0]
"This intuitively affects the MAP estimate, adding α correctly predicted data points and β incorrectly predicted data points, such that
σ(λMAP) =
α+ ∑ [n] I ( x[n]",3.3. Posterior Inference,[0],[0]
= ∨,3.3. Posterior Inference,[0],[0]
l [ ∧ n∈[n] fnl ]),3.3. Posterior Inference,[0],[0]
"α+ β +
K∏ k=1",3.3. Posterior Inference,[0],[0]
"Nk
.",3.3. Posterior Inference,[0],[0]
"(6)
Here, the indicator I evaluates to 1 if its arguments is true and to 0 otherwise.",3.3. Posterior Inference,[0],[0]
"We see that a uniform prior, p(σ(λ))",3.3. Posterior Inference,[0],[0]
"= Beta(α=1, β=1), corresponds to applying Laplace’s rule of succession to the maximum likelihood estimate.",3.3. Posterior Inference,[0],[0]
"An important application of latent variable models is the prediction of missing observations, e.g. in collaborative filtering or data imputation problems (Su & Khoshgoftaar, 2009).",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
Our probabilistic construction allows us to deal with missing data in a unified way.,3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"When computing updates
for the latent factors, we can marginalise over any missing observations.",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"Practically, this is equivalent to setting any missing entries x̃[n] to 0, such that they do not contribute to the conditional probability in eq. (4) and contribute a factor of 12 to the likelihood in eq.",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
(3).,3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"Thus, encoding observed data as {−1, 1} and unobserved data as 0 is the most convenient choice for any practical implementation.",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"For MAP updates of λ, following eq. (6), unobserved datapoints points are simply excluded.
",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"For a direct comparison of predictions to previous methods that only provide a point estimate of the factors, we can reconstruct the data based on the Boolean product of the factor MAP estimates.",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"We use the marginal MAP of each factor entry, fnkl ∈",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"[0, 1] and find no relevant difference to using the joint MAP.",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"If instead we want to use the full posterior, we can determine the reconstruction of X by rounding the posterior predictive,
1
S M∑ s=1 p(x[n]|F (s) 1 , . . .",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
", F (s) K ) , (7)
to the closest binary value.",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"Here, (F (s)1 , . . .",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
", F (s) K ) is a posterior sample.",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"Yet another alternative is to compute the estimate from the factor matrix mean, thus taking posterior uncertainty but no higher-order correlations into account.",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"Denoting the posterior mean of a factor entry as f̂ , we have p(x[n] = 1|.)",3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
≈ 1,3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
− ∏ l(1 − ∏ n∈[n] f̂nl).,3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
The predictive accuracy of this computationally cheap approximation is on par with the more expensive posterior predictive estimate as we show empirically in the next section and in Fig. 2(b).,3.4. Tensor Reconstruction Methods and Missing Data,[0],[0]
"We first demonstrate the capabilities of TensOrM on simulated data and compare to the state-of-the-art method distributed boolean tensor factorisation (dbtf) (Park et al., 2017).",4.1. Random Tensor Decomposition,[0],[0]
"We simulate random 3-way tensors, X , of size 20×20×20 and vary rank L, expected density E(X) and noise-level.",4.1. Random Tensor Decomposition,[0],[0]
"To this end, we take the Boolean product between binary i.i.d. random matrices, Fk, of size 20×L, such that the expected tensor density is given by E(X)",4.1. Random Tensor Decomposition,[0],[0]
= 1−,4.1. Random Tensor Decomposition,[0],[0]
[ 1− (E(Fk))3 ]L .,4.1. Random Tensor Decomposition,[0],[0]
We introduce noise by flipping each entry in the tensor with a given probability.,4.1. Random Tensor Decomposition,[0],[0]
"Posterior samples of the factors are drawn, following the procedure described in Section 3.3 with λ initialised to 0.5 and the initial factors drawn i.i.d.",4.1. Random Tensor Decomposition,[0],[0]
Bern(0.5).,4.1. Random Tensor Decomposition,[0],[0]
The reconstruction of X is determined based on the posterior predictive following eq.,4.1. Random Tensor Decomposition,[0],[0]
(7).,4.1. Random Tensor Decomposition,[0],[0]
The reconstruction accuracy is computed as the fraction of correctly reconstructed entries in the noise-free tensor and is shown across a variety of conditions in Fig. 2(a).,4.1. Random Tensor Decomposition,[0],[0]
Our method achieves distinctly higher accuracies throughout all conditions.,4.1. Random Tensor Decomposition,[0],[0]
"The margin becomes bigger for very noisy data,
as well as for higher tensor ranks and for particularly dense or particularly sparse data.
",4.1. Random Tensor Decomposition,[0],[0]
Can the superior reconstruction performance be explained by implicit model averaging when computing the posterior predictive following eq.,4.1. Random Tensor Decomposition,[0],[0]
(7)?,4.1. Random Tensor Decomposition,[0],[0]
"In order to address this conjecture, Fig. 2(b) compares the reconstruction accuracies of the posterior predictive compared to the reconstruction based solely on the MAP estimates of each factor.",4.1. Random Tensor Decomposition,[0],[0]
"We can see, that posterior averaging plays an important role only in scenarios with high noise levels.",4.1. Random Tensor Decomposition,[0],[0]
"The main performance gain, however, is simply due to a more accurate decomposition.",4.1. Random Tensor Decomposition,[0],[0]
"In the practically relevant regime of moderate noise levels below 30%, posterior averaging has virtually no impact.",4.1. Random Tensor Decomposition,[0],[0]
"We further note in Fig. 2(a), that dbtf features a similar or higher reconstruction accuracy with respect to the noisy training data.",4.1. Random Tensor Decomposition,[0],[0]
This indicates over-fitting and becomes particularly apparent for large noise levels and large tensor ranks.,4.1. Random Tensor Decomposition,[0],[0]
What distinguishes the decompositions of dbtf and TensOrM in this regime?,4.1. Random Tensor Decomposition,[0],[0]
In Fig. 2(c) we show the training performance under random perturbations of the inferred factors for a noise level of 40% and a expected density of 10%.,4.1. Random Tensor Decomposition,[0],[0]
Our method has a lower training accuracy but is more stable towards random perturbations of the parameters whereas the training accuracy of dbtf decreases rapidly.,4.1. Random Tensor Decomposition,[0],[0]
This shows that TensOrM converges to solutions of larger point-wise density in the parameter space that have better generalisation properties.,4.1. Random Tensor Decomposition,[0],[0]
"Recently, this phenomenon has been studied in order to improve the generalisation of deep neural networks (Chaudhari et al., 2016).",4.1. Random Tensor Decomposition,[0],[0]
"Estimating posterior distributions, Bayesian techniques naturally assign more probability to such solutions.",4.1. Random Tensor Decomposition,[0],[0]
A notorious challenge for latent variable models is the choice of dimensionality.,4.2. Model Selection,[0],[0]
"Previously, Erdos & Miettinen (2013b) have used the Minimum description length (MDL) principle for this task in Boolean Tensor Decomposition.",4.2. Model Selection,[0],[0]
We follow their derivation and compare to two approaches that our Bayesian treatment offers readily.,4.2. Model Selection,[0],[0]
"For the Bayesian Occam’s razor, we start our inference procedure with a large latent dimensionality.",4.2. Model Selection,[0],[0]
"After convergence of the Markov chain, we remove all latent dimensions that do not contribute to the likelihood.",4.2. Model Selection,[0],[0]
In these dimensions one of the factors is usually all zeros and the other factors are uniformly random.,4.2. Model Selection,[0],[0]
After removal we restart the burn-in procedure and repeat until only contributing dimensions remain.,4.2. Model Selection,[0],[0]
"In the second approach, cross validation, we treat 20% of the data as unobserved during training and choose the model dimensionality that achieves the highest posterior predictive accuracy on the held-out data.",4.2. Model Selection,[0],[0]
"Results on random matrices for different noise levels are shown in Fig.3, following the previously described simulation procedure.",4.2. Model Selection,[0],[0]
We find that both approaches clearly outperform MDL.,4.2. Model Selection,[0],[0]
"In the case of
(a) Random tensor reconstruction accuracy under variation of the noise level (top), the expected tensor density (centre) and the underlying tensor rank (bottom).",4.2. Model Selection,[0],[0]
Averages are taken across all shown combinations of the other two parameters and across ten random tensors for each such configuration.,4.2. Model Selection,[0],[0]
"Test accuracy on noise-free data is shown in solid colours, training accuracy on noisy data in faint colours.",4.2. Model Selection,[0],[0]
"Compare to Fig. 8 by Park et al. (2017).
",4.2. Model Selection,[0],[0]
"(b) Comparison of reconstruction methods – We compare predictions based on TensOrM posterior predictive, the factor matrix MAP, and mean as described in Section 3.4 to the the dbtf baseline.",4.2. Model Selection,[0],[0]
"M1 indicates the performance margin that is due to finding more accurate factor matrices, M2 denotes the margin that is due to posterior averaging.",4.2. Model Selection,[0],[0]
The underlying tensors are of rank 10.,4.2. Model Selection,[0],[0]
"The results are averaged across tensor densities and 10 random repetitions.
",4.2. Model Selection,[0],[0]
(c) Robustness of training performance under random perturbations – We show reconstruction accuracy on the noisy training data based on the factor matrix MAP estimate under random flips of the factor entries.,4.2. Model Selection,[0],[0]
The underlying tensor has a noise level of 40% and a expected density of 10%.,4.2. Model Selection,[0],[0]
We perform 10 random repetitions but standard deviations are too small to be visible.,4.2. Model Selection,[0],[0]
"TensOrM recovers exactly the expected reconstruction accuracy of 60%, while dbtf overfits to the training data.",4.2. Model Selection,[0],[0]
"Its reconstruction accuracy deteriorates rapidly under random perturbations, indicating that it has converged to a comparatively narrow mode of the posterior.
",4.2. Model Selection,[0],[0]
Figure 2:,4.2. Model Selection,[0],[0]
"The TensOrMachine is compared to the previous state-of-the-art method, distributed Boolean tensor decompositions (dbtf), and properties of its solutions are investigated.",4.2. Model Selection,[0],[0]
All examples are based on 20×20×20 tensors generated from the Boolean product of i.i.d Bernoulli random matrices.,4.2. Model Selection,[0],[0]
Noise is introduced by flipping every entry in the tensor with a given probability.,4.2. Model Selection,[0],[0]
The reconstruction accuracy indicates the fraction of correctly reconstructed entries in the noise-free test data or in the noisy training data.,4.2. Model Selection,[0],[0]
Reconstructions are based on rounding the posterior predictive to the closest value if not mentioned otherwise.,4.2. Model Selection,[0],[0]
"All plots indicate means and standard deviations (some are too small to be visible).
noise-free observations the Bayesian Occam’s razor features virtually perfect accuracy.",4.2. Model Selection,[0],[0]
For the more realistic scenario of moderate noise levels cross validation is superior.,4.2. Model Selection,[0],[0]
"Here we demonstrate the ability of TensOrM to infer meaningful, interpretable representations from real-world 3-way datasets of temporal interaction networks and temporal object×property–relations.",5. Real-world Applications,[0],[0]
"With these moderately sized datasets of less than 100,000 data-points, sampling until convergence and drawing 50 samples takes only few seconds on a single core.",5. Real-world Applications,[0],[0]
"Eventually, we turn to a large-scale biological example, analysing networks of relative geneexpression in cancer patients with more than 10 billion data points.",5. Real-world Applications,[0],[0]
"Here, the inference procedure takes around 10 hours.",5. Real-world Applications,[0],[0]
"Records of contact between pairs of individuals in a university hospital have originally been acquired to investigate transmission routes of infectious diseases (Vanhems et al., 2013).",5.1. Hospital Ward Interaction Networks,[0],[0]
Proximity sensor measurements were taken for 75 individuals in 20 second time windows across 5 days.,5.1. Hospital Ward Interaction Networks,[0],[0]
"In order to examine daily patterns, we group the time-points into 13 time-of-day windows.",5.1. Hospital Ward Interaction Networks,[0],[0]
This leaves us with a binary 13×75×75 time-adjacency tensor.,5.1. Hospital Ward Interaction Networks,[0],[0]
"We compute the decomposition, choosing 8 latent dimensions based on crossvalidation as described in Section 3.3.",5.1. Hospital Ward Interaction Networks,[0],[0]
The predictive accuracy on the held-out test data is approximately 91%.,5.1. Hospital Ward Interaction Networks,[0],[0]
Fig. 4(a) shows posterior means of the time-specific and (one of the two equivalent) individual-specific factor matrices.,5.1. Hospital Ward Interaction Networks,[0],[0]
"Individuals are labelled as either administrative staff (ADM), medical doctors (MED), nurses (NUR) or patients (PAT).",5.1. Hospital Ward Interaction Networks,[0],[0]
"Using this proximity data alone, we were able to recapitulate information about the work patterns of staff groups.",5.1. Hospital Ward Interaction Networks,[0],[0]
"For example, 10am-12pm and 3pm-5pm represent the main morning and afternoon clinic hours when all administrative, medical and nursing staff came into interaction, shown in latent dimensions 1 and 3.",5.1. Hospital Ward Interaction Networks,[0],[0]
"Whilst medical doctors are closely interacting throughout typical work hours, 9am-7pm, their
network does not include any nurses or patients as found in dimension 0.",5.1. Hospital Ward Interaction Networks,[0],[0]
"This can be explained by frequent interaction in the doctor’s room but also hints to a lack of interaction with the nursing staff, a phenomenon frequently discussed in the literature (see e.g. Manias & Street, 2001).",5.1. Hospital Ward Interaction Networks,[0],[0]
"2pm-3pm indicates a period in which nurses and administrative staff are heavily interacting without participation of medical doctors, presumably indicating an afternoon break or daily joint meeting, see latent dimension 3.",5.1. Hospital Ward Interaction Networks,[0],[0]
"Nurses, however, were active throughout the day including being the main staffing body at night as dimension 7 shows.",5.1. Hospital Ward Interaction Networks,[0],[0]
"In comparison, dbtf finds only 2 latent dimensions (0 and 5 in our analysis).",5.1. Hospital Ward Interaction Networks,[0],[0]
Our second example is part of the student-life dataset introduced by Harari et al. (2017) and given by records of the seating positions of students throughout a 9-week Android programming course.,5.2. Student Seating Position,[0],[0]
We partition the time-points into weeks of the course and the seating positions into six regions front/back - left/centre/right.,5.2. Student Seating Position,[0],[0]
"An additional seating category is labelled with a question mark, where the seating coordinates were not provided but the students appeared in class.",5.2. Student Seating Position,[0],[0]
This yields a 9×7×42 week-seat-student tensor.,5.2. Student Seating Position,[0],[0]
"We choose seven latent dimensions, again, by optimising for the test-set likelihood with a reconstruction accuracy of approximately 92% on the held out data.",5.2. Student Seating Position,[0],[0]
"The decomposition is shown in Fig. 4(b) and, once more, open to straightforward interpretation.",5.2. Student Seating Position,[0],[0]
"The majority of students shows up to class in the first week of the course and sits scattered throughout the lecture hall, as can be seen in dimensions 0 and 1.",5.2. Student Seating Position,[0],[0]
"The group of students that attends lectures most consistently, dimension 4, sits in the front-centre.",5.2. Student Seating Position,[0],[0]
"The remaining groups describe subsets of students, each corresponding to exactly one of the four front/back left/right seating regions.",5.2. Student Seating Position,[0],[0]
The formation of some of these groups starts only in week 2 of the course and they all eventually stop to appear in class after 6-7 weeks.,5.2. Student Seating Position,[0],[0]
The input tensor confirms that only two students attend class in weeks 8 and 9.,5.2. Student Seating Position,[0],[0]
"Similar solutions are found by dbtf and shown in the SI (E) but lack the ability to characterise uncertainty around the inferred mode.
",5.2. Student Seating Position,[0],[0]
(a) Dynamic hospital interaction networks – Decomposition on the 13×75×75 time-adjacency-tensor of interactions in a hospital ward.,5.2. Student Seating Position,[0],[0]
We only show one of the two equivalent individual-specific factors.,5.2. Student Seating Position,[0],[0]
"(b) Student dynamic seating throughout course – Decomposition of the 9×7×42 week-seat-student tensor indicating seating positions for a 9-week university course on Android programming.
",5.2. Student Seating Position,[0],[0]
"(c) Representations of cancer patients – Each column corresponds to one out of approximately 8,000 cancer patients and indicates which of the latent properties of relative expression among approximately 2,000 genes they exhibit.",5.2. Student Seating Position,[0],[0]
Patients are ordered by type of cancer.,5.2. Student Seating Position,[0],[0]
"See Figure 1 in the Supplementary Material for the corresponding representation from PCA on the continuous expression data, as well as for a legend of the disease types.
",5.2. Student Seating Position,[0],[0]
Figure 4: Real-world example of factors of TensOrMachine decomposition.,5.2. Student Seating Position,[0],[0]
Colours indicate posterior means.,5.2. Student Seating Position,[0],[0]
"Gene expression profiling has been used extensively in cancer research, e.g. for the characterisation of cancer subtypes, for the stratification of patients or for the identification of therapeutic targets.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
Correlations in gene expression are at the basis of protein interaction in cellular pathways and latent variable models are frequently applied to extract biologically meaningful information from such data.,5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
We propose a novel way of analysing gene expression data that can be applied to any continuous measurement with object×attribute structure (here patient×gene).,5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"The publicly available TCGA dataset (Weinstein et al., 2013) contains gene expression measurements of a large variety of cancer patients across different types of cancer.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"After preprocessing, we are left with approximately 8,000 patients and 1,100 genes.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
We normalise the expression values for each gene across all patients to allow for comparison between genes.,5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"Then the data is transformed into a 3-way tensor using the relational encoding
(patient, genei, genej) =  1; if expri > exprj 0; if expri < exprj unobserved; else .
",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"(8)
This provides an entirely new view of the data in terms of networks of relative expression.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"For every latent dimension, the two gene specific factors indicate a subset of genes, where genes in the first subset are likely to be more expressed than genes in the second subset.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"The patient factor indicates which of these relational expression properties
each patient exhibits.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"Importantly, the factors are amenable to distinct and intuitive interpretation with immediate biological relevance.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
We show the patient-specific factor in Fig. 4(c) with patients ordered by cancer-type.,5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
We observe a remarkable disease specificity with many latent expression networks being exclusively present in virtually all cancers of certain types.,5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"In addition, some latent properties are scattered throughout cancers of various types, highlighting the heterogeneity of the disease.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"Application of a traditional method, principal component analysis (PCA) on the continuous patient×gene array, is shown in the Supplementary Material C. It lacks both, the interpretability and the degree of disease-type specificity.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
We use the representations of both methods as features for random forest classifiers.,5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"The predictive accuracy of the disease type is approximately 91% for the binary TensOrM features, 86% for continuous features from PCA and 81% for binary dbtf features, shown in see SI (C, D).
",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
The corresponding gene-specific factors characterise latent gene-networks but are more difficult to analyse for a nonspecialist.,5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"In particular, the richness of the relational latent encoding can only partially be captured by traditional pathway analyses.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"Nevertheless, we investigate the biological plausibility of the inferred gene sets by running a gene set enrichment analysis of the genes in each factor dimension against the KEGG pathway database (Kanehisa et al., 2017).",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
Results are indicated in Tab. 1 and highlight the biological plausibility and significance of our analysis.,5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
We underline a few examples in the following.,5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"Firstly, Hippo signalling has been shown to be active in LUAD, LUSC, COAD, OV and LIHC (Harvey et al., 2013), all recovered by Dims. 4, 5.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"Secondly, aberrant Wnt signalling is observed in many cancers but most prominently in COAD (Polakis, 2012) which is found in Dim. 5.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"Next, PRAD progression is known to be controlled by focal adhesion (Figel & Gelman, 2011) as found in Dim. 15 as well as by the AGE-RAGE signalling pathway recovered in Dim. 7 (Bao et al., 2015).",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
"Finally, Ras signalling is aberrant in most tumours, but most significantly in PAAD (Downward, 2003) as confirmed in dims. 18, 24.",5.3. Networks of Relative Gene Expression in Cancer,[0],[0]
We have introduced the first probabilistic approach to Boolean tensor decomposition.,6. Conclusion,[0],[0]
It reaches state-of-the-art performance and can readily deal with missing data which is ubiquitous in large datasets.,6. Conclusion,[0],[0]
"Due to the particular combinatorial structure of the factor matrix posterior, sampling based inference scales to large datasets and enables the inference of posterior distributions over factor matrices, providing full uncertainty quantification.",6. Conclusion,[0],[0]
We further show that Boolean tensor decomposition leads to insightful latent representations and provides a novel view on the molecular basis of cancer by relationally encoding continuous expression data.,6. Conclusion,[0],[0]
This work was supported by The Alan Turing Institute under the EPSRC grant EP/N510129/1.,Acknowledgements,[0],[0]
TR is funded by EPSRC grant EP/G037280/1 and thanks Taha Ceritli for helpful comments.,Acknowledgements,[0],[0]
CY is supported by MRC grant MR/P02646X/1.,Acknowledgements,[0],[0]
"CH gratefully acknowledges the following for supporting his research: the EPSRC, iLike programme grant (EP/K014463/1); the MRC, through a programme leaders award; The Li Ka Shing foundation.",Acknowledgements,[0],[0]
"Boolean tensor decomposition approximates data of multi-way binary relationships as product of interpretable low-rank binary factors, following the rules of Boolean algebra.",abstractText,[0],[0]
"Here, we present its first probabilistic treatment.",abstractText,[0],[0]
We facilitate scalable sampling-based posterior inference by exploitation of the combinatorial structure of the factor conditionals.,abstractText,[0],[0]
Maximum a posteriori decompositions feature higher accuracies than existing techniques throughout a wide range of simulated conditions.,abstractText,[0],[0]
"Moreover, the probabilistic approach facilitates the treatment of missing data and enables model selection with much greater accuracy.",abstractText,[0],[0]
We investigate three real-world data-sets.,abstractText,[0],[0]
"First, temporal interaction networks in a hospital ward and behavioural data of university students demonstrate the inference of instructive latent patterns.",abstractText,[0],[0]
"Next, we decompose a tensor with more than 10 billion data points, indicating relations of gene expression in cancer patients.",abstractText,[0],[0]
"Not only does this demonstrate scalability, it also provides an entirely novel perspective on relational properties of continuous data and, in the present example, on the molecular heterogeneity of cancer.",abstractText,[0],[0]
Our implementation is available on GitHub2.,abstractText,[0],[0]
Probabilistic Boolean Tensor Decomposition,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1–11 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1",text,[0],[0]
Word embeddings are foundational to natural language processing.,1 Introduction,[0],[0]
"In order to model language, we need word representations to contain as much semantic information as possible.",1 Introduction,[0],[0]
"Most research has focused on vector word embeddings, such as WORD2VEC (Mikolov et al., 2013a), where words with similar meanings are mapped to nearby points in a vector space.",1 Introduction,[0],[0]
"Following the
∗Work done partly during internship at Amazon.
seminal work of Mikolov et al. (2013a), there have been numerous works looking to learn efficient word embeddings.
",1 Introduction,[0],[0]
One shortcoming with the above approaches to word embedding that are based on a predefined dictionary (termed as dictionary-based embeddings) is their inability to learn representations of rare words.,1 Introduction,[0],[0]
"To overcome this limitation, character-level word embeddings have been proposed.",1 Introduction,[0],[0]
"FASTTEXT (Bojanowski et al., 2016) is the state-of-the-art character-level approach to embeddings.",1 Introduction,[0],[0]
"In FASTTEXT, each word is modeled by a sum of vectors, with each vector representing an n-gram.",1 Introduction,[0],[0]
The benefit of this approach is that the training process can then share strength across words composed of common roots.,1 Introduction,[0],[0]
"For example, with individual representations for “circum” and “navigation”, we can construct an informative representation for “circumnavigation”, which would otherwise appear too infrequently to learn a dictionary-level embedding.",1 Introduction,[0],[0]
"In addition to effectively modelling rare words, character-level embeddings can also represent slang or misspelled words, such as “dogz”, and can share strength across different languages that share roots, e.g. Romance languages share latent roots.
",1 Introduction,[0],[0]
"A different promising direction involves representing words with probability distributions, instead of point vectors.",1 Introduction,[0],[0]
"For example, Vilnis and McCallum (2014) represents words with Gaussian distributions, which can capture uncertainty information.",1 Introduction,[0],[0]
"Athiwaratkun and Wilson (2017) generalizes this approach to multimodal probability distributions, which can naturally represent words with different meanings.",1 Introduction,[0],[0]
"For example, the distribution for “rock” could have mass near the word “jazz” and “pop”, but also “stone” and “basalt”.",1 Introduction,[0],[0]
"Athiwaratkun and Wilson (2018) further developed this approach to learn hierarchical word representations: for example, the word “music” can
2 be learned to have a broad distribution, which encapsulates the distributions for “jazz” and “rock”.",1 Introduction,[0],[0]
"In this paper, we propose Probabilistic FastText (PFT), which provides probabilistic characterlevel representations of words.",1 Introduction,[0],[0]
"The resulting word embeddings are highly expressive, yet straightforward and interpretable, with simple, efficient, and intuitive training procedures.",1 Introduction,[0],[0]
"PFT can model rare words, uncertainty information, hierarchical representations, and multiple word senses.",1 Introduction,[0],[0]
"In particular, we represent each word with a Gaussian or a Gaussian mixture density, which we name PFT-G and PFT-GM respectively.",1 Introduction,[0],[0]
"Each component of the mixture can represent different word senses, and the mean vectors of each component decompose into vectors of n-grams, to capture character-level information.",1 Introduction,[0],[0]
We also derive an efficient energybased max-margin training procedure for PFT.,1 Introduction,[0],[0]
We perform comparison with FASTTEXT as well as existing density word embeddings W2G (Gaussian) and W2GM (Gaussian mixture).,1 Introduction,[0],[0]
"Our models extract high-quality semantics based on multiple word-similarity benchmarks, including the rare word dataset.",1 Introduction,[0],[0]
"We obtain an average weighted improvement of 3.7% over FASTTEXT (Bojanowski et al., 2016) and 3.1% over the dictionary-level density-based models.",1 Introduction,[0],[0]
"We also observe meaningful nearest neighbors, particularly in the multimodal density case, where each mode captures a distinct meaning.",1 Introduction,[0],[0]
"Our models are also directly portable to foreign languages without any hyperparameter modification, where we observe strong performance, outperforming FASTTEXT on many foreign word similarity datasets.",1 Introduction,[0],[0]
"Our multimodal word representation can also disentangle meanings, and is able to separate different senses in foreign polysemies.",1 Introduction,[0],[0]
"In particular, our models attain state-of-the-art performance on SCWS, a benchmark to measure the ability to separate different word meanings, achieving 1.0% improvement over a recent density embedding model W2GM (Athiwaratkun and Wilson, 2017).",1 Introduction,[0],[0]
"To the best of our knowledge, we are the first to develop multi-sense embeddings with high semantic quality for rare words.",1 Introduction,[0],[0]
Our code and embeddings are publicly available.,1 Introduction,[0],[0]
1,1 Introduction,[0],[0]
"Early word embeddings which capture semantic information include Bengio et al. (2003), Col1https://github.com/benathi/multisense-prob-fasttext lobert and Weston (2008), and Mikolov et al. (2011).",2 Related Work,[0],[0]
"Later, Mikolov et al. (2013a) developed the popular WORD2VEC method, which proposes a log-linear model and negative sampling approach that efficiently extracts rich semantics from text.",2 Related Work,[0],[0]
"Another popular approach GLOVE learns word embeddings by factorizing co-occurrence matrices (Pennington et al., 2014).",2 Related Work,[0],[0]
Recently there has been a surge of interest in making dictionary-based word embeddings more flexible.,2 Related Work,[0],[0]
"This flexibility has valuable applications in many end-tasks such as language modeling (Kim et al., 2016), named entity recognition (Kuru et al., 2016), and machine translation (Zhao and Zhang, 2016; Lee et al., 2017), where unseen words are frequent and proper handling of these words can greatly improve the performance.",2 Related Work,[0],[0]
These works focus on modeling subword information in neural networks for tasks such as language modeling.,2 Related Work,[0],[0]
"Besides vector embeddings, there is recent work on multi-prototype embeddings where each word is represented by multiple vectors.",2 Related Work,[0],[0]
"The learning approach involves using a cluster centroid of context vectors (Huang et al., 2012), or adapting the skip-gram model to learn multiple latent representations (Tian et al., 2014).",2 Related Work,[0],[0]
Neelakantan et al. (2014) furthers adapts skip-gram with a non-parametric approach to learn the embeddings with an arbitrary number of senses per word.,2 Related Work,[0],[0]
Chen et al. (2014) incorporates an external dataset WORDNET to learn sense vectors.,2 Related Work,[0],[0]
We compare these models with our multimodal embeddings in Section 4.,2 Related Work,[0],[0]
"We introduce Probabilistic FastText, which combines a probabilistic word representation with the ability to capture subword structure.",3 Probabilistic FastText,[0],[0]
We describe the probabilistic subword representation in Section 3.1.,3 Probabilistic FastText,[0],[0]
We then describe the similarity measure and the loss function used to train the embeddings in Sections 3.2 and 3.3.,3 Probabilistic FastText,[0],[0]
"We conclude by briefly presenting a simplified version of the energy function for isotropic Gaussian representations (Section 3.4), and the negative sampling scheme we use in training (Section 3.5).",3 Probabilistic FastText,[0],[0]
We represent each word with a Gaussian mixture with K Gaussian components.,3.1 Probabilistic Subword Representation,[0],[0]
"That is, a word
3
w is associated with a density function f(x) =∑K i=1",3.1 Probabilistic Subword Representation,[0],[0]
"pw,iN (x; ~µw,i,Σw,i) where {µw,i}Kk=1 are the mean vectors and {Σw,i} are the covariance matrices, and {pw,i}Kk=1 are the component probabilities which sum to 1.
",3.1 Probabilistic Subword Representation,[0],[0]
The mean vectors of Gaussian components hold much of the semantic information in density embeddings.,3.1 Probabilistic Subword Representation,[0],[0]
"While these models are successful based on word similarity and entailment benchmarks (Vilnis and McCallum, 2014; Athiwaratkun and Wilson, 2017), the mean vectors are often dictionary-level, which can lead to poor semantic estimates for rare words, or the inability to handle words outside the training corpus.",3.1 Probabilistic Subword Representation,[0],[0]
We propose using subword structures to estimate the mean vectors.,3.1 Probabilistic Subword Representation,[0],[0]
"We outline the formulation below.
",3.1 Probabilistic Subword Representation,[0],[0]
"For word w, we estimate the mean vector µw with the average over n-gram vectors and its dictionary-level vector.",3.1 Probabilistic Subword Representation,[0],[0]
"That is,
µw = 1
|NGw|+ 1 vw + ∑",3.1 Probabilistic Subword Representation,[0],[0]
"g∈NGw zg  (1) where zg is a vector associated with an n-gram g, vw is the dictionary representation of word w, and NGw is a set of n-grams of word w. Examples of 3,4-grams for a word “beautiful”, including the
beginning-of-word character ‘〈’ and end-of-word character ‘〉’, are:
• 3-grams: 〈be, bea, eau, aut, uti, tif, ful, ul〉
• 4-grams: 〈bea, beau .., iful ,ful〉
This structure is similar to that of FASTTEXT (Bojanowski et al., 2016); however, we note that FASTTEXT uses single-prototype deterministic embeddings as well as a training approach that maximizes the negative log-likelihood, whereas we use a multi-prototype probabilistic embedding and for training we maximize the similarity between the words’ probability densities, as described in Sections 3.2 and 3.3
Figure 1a depicts the subword structure for the mean vector.",3.1 Probabilistic Subword Representation,[0],[0]
"Figure 1b and 1c depict our models, Gaussian probabilistic FASTTEXT (PFTG) and Gaussian mixture probabilistic FASTTEXT (PFT-GM).",3.1 Probabilistic Subword Representation,[0],[0]
"In the Gaussian case, we represent each mean vector with a subword estimation.",3.1 Probabilistic Subword Representation,[0],[0]
"For the Gaussian mixture case, we represent one Gaussian component’s mean vector with the subword structure whereas other components’ mean vectors are dictionary-based.",3.1 Probabilistic Subword Representation,[0],[0]
This model choice to use dictionary-based mean vectors for other components is to reduce to constraint imposed by the subword structure and promote independence for meaning discovery.,3.1 Probabilistic Subword Representation,[0],[0]
"Traditionally, if words are represented by vectors, a common similarity metric is a dot product.",3.2 Similarity Measure between Words,[0],[0]
"In the case where words are represented by distribution functions, we use the generalized dot product in Hilbert space 〈·, ·〉L2 , which is called the expected likelihood kernel (Jebara et al., 2004).",3.2 Similarity Measure between Words,[0],[0]
"We define the energy E(f, g) between two words f and g to be E(f, g) = log〈f, g〉L2 = log ∫ f(x)g(x) dx.",3.2 Similarity Measure between Words,[0],[0]
"With Gaussian
mixtures f(x) = ∑K
i=1 piN (x; ~µf,i,Σf,i) and g(x) = ∑K i=1",3.2 Similarity Measure between Words,[0],[0]
"qiN (x; ~µg,i,Σg,i), ∑K i=1",3.2 Similarity Measure between Words,[0],[0]
"pi = 1,
and ∑K
i=1 qi = 1, the energy has a closed form:
E(f, g) = log K∑ j=1 K∑ i=1",3.2 Similarity Measure between Words,[0],[0]
"piqje ξi,j (2)
where ξj,j is the partial energy which corresponds to the similarity between component i of the first
4
word f and component j of the second word g.2 ξi,j ≡ logN (0; ~µf,i − ~µg,j ,Σf,i + Σg,j) = −1 2 log det(Σf,i + Σg,j)− D 2 log(2π) −1 2 (~µf,i − ~µg,j)>(Σf,i + Σg,j)−1(~µf,i − ~µg,j) (3) Figure 2 demonstrates the partial energies among the Gaussian components of two words.",3.2 Similarity Measure between Words,[0],[0]
Interaction between GM components rock:0 pop:0,3.2 Similarity Measure between Words,[0],[0]
"pop:1rock:1 ⇠0,1 ⇠0,0 ⇠1,1 ⇠1,0 bang, crack, snap basalt, boulder, sand jazz, punk, indie funk, pop-rock, band
Figure 2:",3.2 Similarity Measure between Words,[0],[0]
The interactions among Gaussian components of word rock and word pop.,3.2 Similarity Measure between Words,[0],[0]
"The partial energy is the highest for the pair rock:0 (the zeroth component of rock) and pop:1 (the first component of pop), reflecting the similarity in meanings.",3.2 Similarity Measure between Words,[0],[0]
"The model parameters that we seek to learn are vw for each word w and zg for each n-gram g. We train the model by pushing the energy of a true context pair w and c to be higher than the negative context pair w and n by a margin m. We use Adagrad (Duchi et al., 2011) to minimize the following loss to achieve this outcome: L(f, g) = max [0,m− E(f, g) + E(f, n)] .",3.3 Loss Function,[0],[0]
(4) We describe how to sample words as well as its positive and negative contexts in Section 3.5.,3.3 Loss Function,[0],[0]
This loss function together with the Gaussian mixture model with K > 1 has the ability to extract multiple senses of words.,3.3 Loss Function,[0],[0]
"That is, for a word with multiple meanings, we can observe each mode to represent a distinct meaning.",3.3 Loss Function,[0],[0]
"For instance, one density mode of “star” is close to the densities of “celebrity” and “hollywood” whereas another mode of “star” is near the densities of “constellation” and “galaxy”.",3.3 Loss Function,[0],[0]
2The orderings of indices of the components for each word are arbitrary.,3.3 Loss Function,[0],[0]
"In theory, it can be beneficial to have covariance matrices as learnable parameters.",3.4 Energy Simplification,[0],[0]
"In practice, Athiwaratkun and Wilson (2017) observe that spherical covariances often perform on par with diagonal covariances with much less computational resources.",3.4 Energy Simplification,[0],[0]
"Using spherical covariances for each component, we can further simplify the energy function as follows: ξi,j =",3.4 Energy Simplification,[0],[0]
"− α 2 · ||µf,i − µg,j ||2 , (5) where the hyperparameter α is the scale of the inverse covariance term in Equation 3.",3.4 Energy Simplification,[0],[0]
We note that Equation 5 is equivalent to Equation 3 up to an additive constant given that the covariance matrices are spherical and the same for all components.,3.4 Energy Simplification,[0],[0]
"To generate a context word c of a given word w, we pick a nearby word within a context window of a fixed length `.",3.5 Word Sampling,[0],[0]
We also use a word sampling technique similar to Mikolov et al. (2013b).,3.5 Word Sampling,[0],[0]
This subsampling procedure selects words for training with lower probabilities if they appear frequently.,3.5 Word Sampling,[0],[0]
"This technique has an effect of reducing the importance of words such as ‘the’, ‘a’, ‘to’ which can be predominant in a text corpus but are not as meaningful as other less frequent words such as ‘city’, ‘capital’, ‘animal’, etc.",3.5 Word Sampling,[0],[0]
"In particular, word w has probability P (w) = 1− √ t/f(w) where f(w) is the frequency of word w in the corpus and t is the frequency threshold.",3.5 Word Sampling,[0],[0]
A negative context word is selected using a distribution Pn(w) ∝,3.5 Word Sampling,[0],[0]
U(w)3/4 where U(w) is a unigram probability of word,3.5 Word Sampling,[0],[0]
w.,3.5 Word Sampling,[0],[0]
The exponent 3/4 also diminishes the importance of frequent words and shifts the training focus to other less frequent words.,3.5 Word Sampling,[0],[0]
We have proposed a probabilistic FASTTEXT model which combines the flexibility of subword structure with the density embedding approach.,4 Experiments,[0],[0]
"In this section, we show that our probabilistic representation with subword mean vectors with the simplified energy function outperforms many word similarity baselines and provides disentangled meanings for polysemies.",4 Experiments,[0],[0]
"First, we describe the training details in Section 4.1.",4 Experiments,[0],[0]
"We provide qualitative evaluation in Section
5 4.2, showing meaningful nearest neighbors for the Gaussian embeddings, as well as the ability to capture multiple meanings by Gaussian mixtures.",4 Experiments,[0],[0]
"Our quantitative evaluation in Section 4.3 demonstrates strong performance against the baseline models FASTTEXT (Bojanowski et al., 2016) and the dictionary-level Gaussian (W2G) (Vilnis and McCallum, 2014) and Gaussian mixture embeddings (Athiwaratkun and Wilson, 2017) (W2GM).",4 Experiments,[0],[0]
We train our models on foreign language corpuses and show competitive results on foreign word similarity benchmarks in Section 4.4.,4 Experiments,[0],[0]
"Finally, we explain the importance of the n-gram structures for semantic sharing in Section 4.5.",4 Experiments,[0],[0]
We train our models on both English and foreign language datasets.,4.1 Training Details,[0],[0]
"For English, we use the concatenation of UKWAC and WACKYPEDIA (Baroni et al., 2009) which consists of 3.376 billion words.",4.1 Training Details,[0],[0]
"We filter out word types that occur fewer than 5 times which results in a vocabulary size of 2,677,466.",4.1 Training Details,[0],[0]
"For foreign languages, we demonstrate the training of our model on French, German, and Italian text corpuses.",4.1 Training Details,[0],[0]
We note that our model should be applicable for other languages as well.,4.1 Training Details,[0],[0]
"We use FRWAC (French), DEWAC (German), ITWAC (Italian) datasets (Baroni et al., 2009) for text corpuses, consisting of 1.634, 1.716 and 1.955 billion words respectively.",4.1 Training Details,[0],[0]
"We use the same threshold, filtering out words that occur less than 5 times in each corpus.",4.1 Training Details,[0],[0]
"We have dictionary sizes of 1.3, 2.7, and 1.4 million words for FRWAC, DEWAC, and ITWAC.",4.1 Training Details,[0],[0]
We adjust the hyperparameters on the English corpus and use them for foreign languages.,4.1 Training Details,[0],[0]
Note that the adjustable parameters for our models are the loss margin m in Equation 4 and the scale α in Equation 5.,4.1 Training Details,[0],[0]
"We search for the optimal hyperparameters in a grid m ∈ {0.01, 0.1, 1, 10, 100} and α ∈ { 1 5×10−3 , 1 10−3 , 1 2×10−4 , 1 1×10−4 } on our English corpus.",4.1 Training Details,[0],[0]
"The hyperpameter α affects the scale of the loss function; therefore, we adjust the learning rate appropriately for each α.",4.1 Training Details,[0],[0]
"In particular, the learning rates used are γ = {10−4, 10−5, 10−6} for the respective α values.",4.1 Training Details,[0],[0]
"Other fixed hyperparameters include the number of Gaussian components K = 2, the context window length ` = 10 and the subsampling threshold t = 10−5.",4.1 Training Details,[0],[0]
"Similar to the setup in FASTTEXT, we use n-grams where n = 3, 4, 5, 6 to estimate the mean vectors.",4.1 Training Details,[0],[0]
We show that our embeddings learn the word semantics well by demonstrating meaningful nearest neighbors.,4.2 Qualitative Evaluation - Nearest neighbors,[0],[0]
"Table 1 shows examples of polysemous words such as rock, star, and cell.",4.2 Qualitative Evaluation - Nearest neighbors,[0],[0]
Table 1 shows the nearest neighbors of polysemous words.,4.2 Qualitative Evaluation - Nearest neighbors,[0],[0]
We note that subword embeddings prefer words with overlapping characters as nearest neighbors.,4.2 Qualitative Evaluation - Nearest neighbors,[0],[0]
"For instance, “rock-y”, “rockn”, and “rock” are both close to the word “rock”.",4.2 Qualitative Evaluation - Nearest neighbors,[0],[0]
"For the purpose of demonstration, we only show words with meaningful variations and omit words with small character-based variations previously mentioned.",4.2 Qualitative Evaluation - Nearest neighbors,[0],[0]
"However, all words shown are in the top100 nearest words.",4.2 Qualitative Evaluation - Nearest neighbors,[0],[0]
"We observe the separation in meanings for the multi-component case; for instance, one component of the word “bank” corresponds to a financial bank whereas the other component corresponds to a river bank.",4.2 Qualitative Evaluation - Nearest neighbors,[0],[0]
The single-component case also has interesting behavior.,4.2 Qualitative Evaluation - Nearest neighbors,[0],[0]
We observe that the subword embeddings of polysemous words can represent both meanings.,4.2 Qualitative Evaluation - Nearest neighbors,[0],[0]
"For instance, both “lava-rock” and “rock-pop” are among the closest words to “rock”.",4.2 Qualitative Evaluation - Nearest neighbors,[0],[0]
"We evaluate our embeddings on several standard word similarity datasets, namely, SL-999 (Hill et al., 2014), WS-353 (Finkelstein et al., 2002), MEN-3k (Bruni et al., 2014), MC-30 (Miller and Charles, 1991), RG-65 (Rubenstein and Goodenough, 1965), YP-130 (Yang and Powers, 2006), MTurk(-287,-771) (Radinsky et al., 2011; Halawi et al., 2012), and RW-2k (Luong et al., 2013).",4.3 Word Similarity Evaluation,[0],[0]
Each dataset contains a list of word pairs with a human score of how related or similar the two words are.,4.3 Word Similarity Evaluation,[0],[0]
We use the notation DATASET-NUM to denote the number of word pairs NUM in each evaluation set.,4.3 Word Similarity Evaluation,[0],[0]
We note that the dataset RW focuses more on infrequent words and SimLex-999 focuses on the similarity of words rather than relatedness.,4.3 Word Similarity Evaluation,[0],[0]
"We also compare PFT-GM with other multi-prototype embeddings in the literature using SCWS (Huang et al., 2012), a word similarity dataset that is aimed to measure the ability of embeddings to discern multiple meanings.",4.3 Word Similarity Evaluation,[0],[0]
"We calculate the Spearman correlation (Spearman, 1904) between the labels and our scores gen-
6
erated by the embeddings.",4.3 Word Similarity Evaluation,[0],[0]
The Spearman correlation is a rank-based correlation measure that assesses how well the scores describe the true labels.,4.3 Word Similarity Evaluation,[0],[0]
The scores we use are cosine-similarity scores between the mean vectors.,4.3 Word Similarity Evaluation,[0],[0]
"In the case of Gaussian mixtures, we use the pairwise maximum score: s(f, g) = max i∈1,...,K max j∈1,...,K µf,i · µg,j ||µf,i|| · ||µg,j || .",4.3 Word Similarity Evaluation,[0],[0]
"(6) The pair (i, j) that achieves the maximum cosine similarity corresponds to the Gaussian component pair that is the closest in meanings.",4.3 Word Similarity Evaluation,[0],[0]
"Therefore, this similarity score yields the most related senses of a given word pair.",4.3 Word Similarity Evaluation,[0],[0]
This score reduces to a cosine similarity in the Gaussian case (K = 1).,4.3 Word Similarity Evaluation,[0],[0]
"Density Embeddings and FASTTEXT We compare our models against the dictionarylevel Gaussian and Gaussian mixture embeddings in Table 2, with 50-dimensional and 300- dimensional mean vectors.",4.3.1 Comparison Against Dictionary-Level,[0],[0]
The 50-dimensional results for W2G and W2GM are obtained directly from Athiwaratkun and Wilson (2017).,4.3.1 Comparison Against Dictionary-Level,[0],[0]
"For comparison, we use the public code3 to train the 300- dimensional W2G and W2GM models and the publicly available FASTTEXT model4.",4.3.1 Comparison Against Dictionary-Level,[0],[0]
We calculate Spearman’s correlations for each of the word similarity datasets.,4.3.1 Comparison Against Dictionary-Level,[0],[0]
"These datasets vary greatly in the number of word pairs; therefore, we mark each dataset with its size for visibil3https://github.com/benathi/word2gm 4https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.",4.3.1 Comparison Against Dictionary-Level,[0],[0]
"en.zip
7 ity.",4.3.1 Comparison Against Dictionary-Level,[0],[0]
"For a fair and objective comparison, we calculate a weighted average of the correlation scores for each model.",4.3.1 Comparison Against Dictionary-Level,[0],[0]
"Our PFT-GM achieves the highest average score among all competing models, outperforming both FASTTEXT and the dictionary-level embeddings W2G and W2GM.",4.3.1 Comparison Against Dictionary-Level,[0],[0]
Our unimodal model PFT-G also outperforms the dictionary-level counterpart W2G and FASTTEXT.,4.3.1 Comparison Against Dictionary-Level,[0],[0]
"We note that the model W2GM appears quite strong according to Table 2, beating PFT-GM on many word similarity datasets.",4.3.1 Comparison Against Dictionary-Level,[0],[0]
"However, the datasets that W2GM performs better than PFT-GM often have small sizes such as MC-30 or RG-65, where the Spearman’s correlations are more subject to noise.",4.3.1 Comparison Against Dictionary-Level,[0],[0]
"Overall, PFT-GM outperforms W2GM by 3.1% and 8.7% in 300 and 50 dimensional models.",4.3.1 Comparison Against Dictionary-Level,[0],[0]
"In addition, PFT-G and PFT-GM also outperform FASTTEXT by 1.2% and 3.7% respectively.",4.3.1 Comparison Against Dictionary-Level,[0],[0]
"In Table 3, we compare 50 and 300 dimensional PFT-GM models against the multi-prototype embeddings described in Section 2 and the existing multimodal density embeddings W2GM.",4.3.2 Comparison Against Multi-Prototype Models,[0],[0]
"We use the word similarity dataset SCWS (Huang et al., 2012) which contains words with potentially many meanings, and is a benchmark for distinguishing senses.",4.3.2 Comparison Against Multi-Prototype Models,[0],[0]
"We use the maximum similarity score (Equation 6), denoted as MAXSIM.",4.3.2 Comparison Against Multi-Prototype Models,[0],[0]
"AVESIM denotes the average of the similarity scores, rather than the maximum.",4.3.2 Comparison Against Multi-Prototype Models,[0],[0]
"We outperform the dictionary-based density embeddings W2GM in both 50 and 300 dimensions, demonstrating the benefits of subword information.",4.3.2 Comparison Against Multi-Prototype Models,[0],[0]
"Our model achieves state-of-the-art results, similar to that of Neelakantan et al. (2014).",4.3.2 Comparison Against Multi-Prototype Models,[0],[0]
We evaluate the foreign-language embeddings on word similarity datasets in respective languages.,4.4 Evaluation on Foreign Language Embeddings,[0],[0]
"We use Italian WORDSIM353 and Italian SIMLEX-999 (Leviant and Reichart, 2015) for Italian models, GUR350 and GUR65 (Gurevych, 2005) for German models, and French WORDSIM353 (Finkelstein et al., 2002) for French models.",4.4 Evaluation on Foreign Language Embeddings,[0],[0]
"For datasets GUR350 and GUR65, we use the results reported in the FASTTEXT publication (Bojanowski et al., 2016).",4.4 Evaluation on Foreign Language Embeddings,[0],[0]
"For other datasets, we train FASTTEXT models for comparison using the
public code5 on our text corpuses.",4.4 Evaluation on Foreign Language Embeddings,[0],[0]
"We also train dictionary-level models W2G, and W2GM for comparison.",4.4 Evaluation on Foreign Language Embeddings,[0],[0]
Table 4 shows the Spearman’s correlation results of our models.,4.4 Evaluation on Foreign Language Embeddings,[0],[0]
We outperform FASTTEXT on many word similarity benchmarks.,4.4 Evaluation on Foreign Language Embeddings,[0],[0]
"Our results are also significantly better than the dictionary-based models, W2G and W2GM.",4.4 Evaluation on Foreign Language Embeddings,[0],[0]
We hypothesize that W2G and W2GM can perform better than the current reported results given proper pre-processing of words due to special characters such as accents.,4.4 Evaluation on Foreign Language Embeddings,[0],[0]
We investigate the nearest neighbors of polysemies in foreign languages and also observe clear sense separation.,4.4 Evaluation on Foreign Language Embeddings,[0],[0]
"For example, piano in Italian can mean “floor” or “slow”.",4.4 Evaluation on Foreign Language Embeddings,[0],[0]
"These two meanings are reflected in the nearest neighbors where one component is close to piano-piano, pianod which mean “slowly” whereas the other component is close to piani (floors), istrutturazione (renovation) or infrastruttre (infrastructure).",4.4 Evaluation on Foreign Language Embeddings,[0],[0]
"Table 5 shows additional results, demonstrating that the disentangled semantics can be observed in multiple languages.",4.4 Evaluation on Foreign Language Embeddings,[0],[0]
One of the motivations for using subword information is the ability to handle out-of-vocabulary words.,4.5 Qualitative Evaluation - Subword Decomposition,[0],[0]
Another benefit is the ability to help improve the semantics of rare words via subword sharing.,4.5 Qualitative Evaluation - Subword Decomposition,[0],[0]
"Due to an observation that text corpuses follow Zipf’s power law (Zipf, 1949), words at the tail of the occurrence distribution appears much 5https://github.com/facebookresearch/fastText.git
8
less frequently.",4.5 Qualitative Evaluation - Subword Decomposition,[0],[0]
Training these words to have a good semantic representation is challenging if done at the word level alone.,4.5 Qualitative Evaluation - Subword Decomposition,[0],[0]
"However, an ngram such as ‘abnorm’ is trained during both occurrences of “abnormal” and “abnormality” in the corpus, hence further augments both words’s semantics.",4.5 Qualitative Evaluation - Subword Decomposition,[0],[0]
Figure 3 shows the contribution of n-grams to the final representation.,4.5 Qualitative Evaluation - Subword Decomposition,[0],[0]
We filter out to show only the n-grams with the top-5 and bottom-5 similarity scores.,4.5 Qualitative Evaluation - Subword Decomposition,[0],[0]
"We observe that the final representations of both words align with n-grams “abno”, “bnor”, “abnorm”, “anbnor”, “<abn”.",4.5 Qualitative Evaluation - Subword Decomposition,[0],[0]
"In fact, both “abnormal” and “abnormality” share the same top-5 n-grams.",4.5 Qualitative Evaluation - Subword Decomposition,[0],[0]
"Due to the fact that many rare words such as “autobiographer”, “circumnavigations”, or “hypersensitivity” are composed from many common sub-words, the n-gram structure can help improve the representation quality.",4.5 Qualitative Evaluation - Subword Decomposition,[0],[0]
"It is possible to train our approach with K > 2 mixture components; however, Athiwaratkun and Wilson (2017) observe that dictionary-level Gaussian mixtures with K = 3 do not overall improve word similarity results, even though these mixtures can discover 3 distinct senses for certain words.",5 Numbers of Components,[0],[0]
"Indeed, while K > 2 in principle allows for greater flexibility than K = 2, most words can be very flexibly modelled with a mixture of two
Gaussians, leading to K = 2 representing a good balance between flexibility and Occam’s razor.",5 Numbers of Components,[0],[0]
"Even for words with single meanings, our PFT model with K = 2 often learns richer representations than a K = 1 model.",5 Numbers of Components,[0],[0]
"For example, the two mixture components can learn to cluster to-
9 gether to form a more heavy tailed unimodal distribution which captures a word with one dominant meaning but with close relationships to a wide range of other words.",5 Numbers of Components,[0],[0]
"In addition, we observe that our model with K components can capture more than K meanings.",5 Numbers of Components,[0],[0]
"For instance, in K = 1 model, the word pairs (“cell”, “jail”) and (“cell”, “biology”) and (“cell”, “phone”) will all have positive similarity scores based on K = 1 model.",5 Numbers of Components,[0],[0]
"In general, if a word has multiple meanings, these meanings are usually compressed into the linear substructure of the embeddings (Arora et al., 2016).",5 Numbers of Components,[0],[0]
"However, the pairs of non-dominant words often have lower similarity scores, which might not accurately reflect their true similarities.",5 Numbers of Components,[0],[0]
"We have proposed models for probabilistic word representations equipped with flexible sub-word structures, suitable for rare and out-of-vocabulary words.",6 Conclusion and Future Work,[0],[0]
The proposed probabilistic formulation incorporates uncertainty information and naturally allows one to uncover multiple meanings with multimodal density representations.,6 Conclusion and Future Work,[0],[0]
"Our models offer better semantic quality, outperforming competing models on word similarity benchmarks.",6 Conclusion and Future Work,[0],[0]
"Moreover, our multimodal density models can provide interpretable and disentangled representations, and are the first multi-prototype embeddings that can handle rare words.",6 Conclusion and Future Work,[0],[0]
"Future work includes an investigation into the trade-off between learning full covariance matrices for each word distribution, computational complexity, and performance.",6 Conclusion and Future Work,[0],[0]
"This direction can potentially have a great impact on tasks where the variance information is crucial, such as for hierarchical modeling with probability distributions (Athiwaratkun and Wilson, 2018).",6 Conclusion and Future Work,[0],[0]
Other future work involves co-training PFT on many languages.,6 Conclusion and Future Work,[0],[0]
"Currently, existing work on multi-lingual embeddings align the word semantics on pre-trained vectors (Smith et al., 2017), which can be suboptimal due to polysemies.",6 Conclusion and Future Work,[0],[0]
We envision that the multi-prototype nature can help disambiguate words with multiple meanings and facilitate semantic alignment.,6 Conclusion and Future Work,[0],[0]
"We introduce Probabilistic FastText, a new model for word embeddings that can capture multiple word senses, sub-word structure, and uncertainty information.",abstractText,[0],[0]
"In particular, we represent each word with a Gaussian mixture density, where the mean of a mixture component is given by the sum of n-grams.",abstractText,[0],[0]
"This representation allows the model to share statistical strength across sub-word structures (e.g. Latin roots), producing accurate representations of rare, misspelt, or even unseen words.",abstractText,[0],[0]
"Moreover, each component of the mixture can capture a different word sense.",abstractText,[0],[0]
"Probabilistic FastText outperforms both FASTTEXT, which has no probabilistic model, and dictionary-level probabilistic embeddings, which do not incorporate subword structures, on several word-similarity benchmarks, including English RareWord and foreign language datasets.",abstractText,[0],[0]
We also achieve state-ofart performance on benchmarks that measure ability to discern different meanings.,abstractText,[0],[0]
"Thus, the proposed model is the first to achieve multi-sense representations while having enriched semantics on rare words.",abstractText,[0],[0]
Probabilistic FastText for Multi-Sense Word Embeddings,title,[0],[0]
"Hamiltonian Monte Carlo is a powerful sampling algorithm which has been shown to outperform many existing MCMC algorithms, especially in problems with highdimensional and correlated distributions (Duane et al., 1987; Neal, 2011).",1. Introduction,[0],[0]
The algorithm mimics the movement of a body balancing potential and kinetic energy by extending the state space to include auxiliary momentum variables and using Hamiltonian dynamics.,1. Introduction,[0],[0]
"By traversing long isoprobability contours in this extended state space, HMC is able to move long distances in state space in a single up-
*Equal contribution 1Program in Computational Biology, Fred Hutchison Cancer Research Center, Seattle, WA, USA 2Department of Statistics, University of Washington, Seattle, WA, USA.",1. Introduction,[0],[0]
"Correspondence to: Frederick, A. Matsen IV <matsen@fredhutch.org>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
date step, and thus has proved to be more effective than standard MCMC methods in a variety of applications.",1. Introduction,[0],[0]
"The method has gained a lot of interest from the scientific community and since then has been extended to tackle the problem of sampling on various geometric structures such as constrained spaces (Lan et al., 2014; Brubaker et al., 2012; Hartmann and Schütte, 2005), on general Hilbert space (Beskos et al., 2011) and on Riemannian manifolds (Girolami and Calderhead, 2011; Wang et al., 2013).
",1. Introduction,[0],[0]
"However, these extensions are not yet sufficient to apply to all sampling problems, such as in phylogenetics, the inference of evolutionary trees.",1. Introduction,[0],[0]
Phylogenetics is the study of the evolutionary history and relationships among individuals or groups of organisms.,1. Introduction,[0],[0]
In its statistical formulation it is an inference problem on hypotheses of shared history based on observed heritable traits under a model of evolution.,1. Introduction,[0],[0]
Phylogenetics is an essential tool for understanding biological systems and is an important discipline of computational biology.,1. Introduction,[0],[0]
"The Bayesian paradigm is now commonly used to assess support for inferred tree structures or to test hypotheses that can be expressed in phylogenetic terms (Huelsenbeck et al., 2001).
",1. Introduction,[0],[0]
"Although the last several decades have seen an explosion of advanced methods for sampling from Bayesian posterior distributions, including HMC, phylogenetics still uses relatively classical Markov chain Monte Carlo (MCMC) based methods.",1. Introduction,[0],[0]
This is in part because the number of possible tree topologies (the labeled graphs describing the branching structure of the evolutionary history) explodes combinatorially as the number of species increases.,1. Introduction,[0],[0]
"Also, to represent the phylogenetic relation among a fixed number of species, one needs to specify both the tree topology (a discrete object) and the branch lengths (continuous distances).",1. Introduction,[0],[0]
This composite structure has thus far limited sampling methods to relatively classical Markov chain Monte Carlo (MCMC) based methods.,1. Introduction,[0],[0]
"One path forward is to use a construction of the set of phylogenetic trees as a single connected space composed of Euclidean spaces glued together in a combinatorial fashion (Kim, 2000; Moulton and Steel, 2004; Billera et al., 2001; Gavryushkin and Drummond, 2016) and try to define an HMC-like algorithm thereupon.
",1. Introduction,[0],[0]
"Experts in HMC are acutely aware of the need to extend HMC to such spaces with intricate combinatorial structure: Betancourt (2017) describes the extension of HMC to dis-
crete and tree spaces as a major outstanding challenge for the area.",1. Introduction,[0],[0]
"However, there are several challenges to defining a continuous dynamics-based sampling methods on such spaces.",1. Introduction,[0],[0]
"These tree spaces are composed of Euclidean components, one for each discrete tree topology, which are glued together in a way that respects natural similarities between trees.",1. Introduction,[0],[0]
These similarities dictate that more than two such Euclidean spaces should get glued together along a common lower-dimensional boundary.,1. Introduction,[0],[0]
"The resulting lack of manifold structure poses a problem to the construction of an HMC sampling method on tree space, since up to now, HMC has just been defined on spaces with differential geometry.",1. Introduction,[0],[0]
"Similarly, while the posterior function is smooth within each topology, the function’s behavior may be very
different between topologies.",1. Introduction,[0],[0]
"In fact, there is no general notion of differentiability of the posterior function on the whole tree space and any scheme to approximate Hamiltonian dynamics needs to take this issue into account.
",1. Introduction,[0],[0]
"In this paper, we develop Probabilistic Path Hamiltonian Monte Carlo (PPHMC) as a first step to sampling distributions on spaces with intricate combinatorial structure (Figure 1).",1. Introduction,[0],[0]
"After reviewing how the ensemble of phylogenetic trees is naturally described as a geometric structure we identify as an orthant complex (Billera et al., 2001), we define PPHMC for sampling posteriors on orthant complexes along with a probabilistic version of the leapfrog algorithm.",1. Introduction,[0],[0]
"This algorithm generalizes previous HMC algorithms by doing classical HMC on the Euclidean components of the orthant complex, but making random choices between alternative paths available at a boundary.",1. Introduction,[0],[0]
"We establish that the integrator retains the good theoretical properties of Hamiltonian dynamics in classical settings, namely probabilistic equivalents of time-reversibility, volume preservation, and accessibility, which combined together result in a proof of ergodicity for the resulting Markov chain.",1. Introduction,[0],[0]
"Although a direct application of the integrator to the phylogenetic posterior does work, we obtain significantly better performance by using a surrogate function near the boundary between topologies to control approximation error.",1. Introduction,[0],[0]
"This approach also addresses a general problem in using Reflective HMC (RHMC; Afshar and Domke, 2015) for energy functions with discontinuous derivatives (for which the accuracy of RHMC is of order O( ), instead of the standard local error O( 3) of HMC on Rn).",1. Introduction,[0],[0]
"We provide, validate, and benchmark two independent implementations in open-source software.",1. Introduction,[0],[0]
"A phylogenetic tree (τ, q) is a tree graph τ with N leaves, each of which has a label, and such that each edge e is associated with a non-negative number qe.",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
Trees will be assumed to be bifurcating (internal nodes of degree 3) unless otherwise specified.,2.1. Bayesian learning on phylogenetic tree space,[0],[0]
We denote the number of edges of such a tree by n = 2N − 3.,2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"Any edge incident to a leaf is called a pendant edge, and any other edge is called an internal edge.",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
Let TN be the set of all N -leaf phylogenetic trees for which the lengths of pendant edges are bounded from below by some constant e0 > 0.,2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"(This lower bound on branch lengths is a technical condition for theoretical development and can be relaxed in practice.)
",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"We will use nearest neighbor interchange (NNI) moves (Robinson, 1971) to formalize what tree topologies that are “near” to each other.",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"An NNI move is a transformation that collapses an internal edge to zero and then expands
the resulting degree 4 vertex into an edge and two degree 3 vertices in a new way (Figure 1a).",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"Two tree topologies τ1 and τ2 are called adjacent topologies if there exists a single NNI move that transforms τ1 into τ2.
",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"We will parameterize TN as Billera-Holmes-Vogtmann (BHV) space (Billera et al., 2001), which we describe as follows.",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
An orthant of dimension n is simply Rn≥0; each n-dimensional orthant is bounded by a collection of lower dimensional orthant faces.,2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"An orthant complex is a geometric object X obtained by gluing various orthants of the same dimension n, indexed by a countable set Γ, such that: (i) the intersection of any two orthants is a face of both orthants, and (ii) each x ∈ X belongs to a finite number of orthants.",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"Each state of X is thus represented by a pair (τ, q), where τ ∈ Γ and q ∈ Rn≥0.",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"Generalizing the definitions from phylogenetics, we refer to τ as its topology and to q as the vector of attributes.",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"The topology of a point in an orthant complex indexes discrete structure, while the attributes formalize the continuous components of the space.
",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"For phylogenetics, the complex is constructed by taking one n-dimensional orthant for each of the (2n − 3)!!",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"possible tree topologies, and gluing them together along their common faces.",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
The geometry can also be summarized as follows.,2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"In BHV space, each of these orthants parameterizes the set of branch lengths for a single topology (as a technical point, because we are bounding pendant branch lengths below by e0, we can take the corresponding entries in the orthant to parameterize the amount of branch length above e0).",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"Top-dimensional orthants of the complex sharing a facet, i.e. a codimension 1 face, correspond to (NNI) adjacent topologies.
",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"For a fixed phylogenetic tree (τ, q), the phylogenetic likelihood is defined as follows and will be denoted by L(τ, p) (see Kenney and Gu, 2012, for a full exposition).",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
Let ψ =,2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"(ψ1, ψ2, ..., ψS) ∈ ΩN×S be the observed sequences (with characters in Ω) of length S over N leaves.",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"The likelihood of observing ψ given the tree has the form
L(τ, q) = S∏ s=1 ∑ as η(asρ)",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"∏ (u,v)∈E(τ,q) Puvasuasv (quv)
where ρ is any internal node of the tree, as ranges over all extensions of ψs to the internal nodes of the tree, asu denotes the assigned state of node u by as, E(τ, q) denotes the set of tree edges, Pij(t) denotes the transition probability from character i to character j across an edge of length t defined by a given evolutionary model and η is the stationary distribution of this evolutionary model.",2.1. Bayesian learning on phylogenetic tree space,[0.9505982696295486],"['For a given referring expression Rk and its candidate referent list Ck = {o1, o2, ..., oNk}, in which each oi is an object identified as a candidate referent, we compute the probability of each candidate oi being the true referent of Rk, p(Rk, oi) = f(Rk, oi), where f is the classification function.']"
"For this paper we will assume the simplest Jukes and Cantor (1969) model of a homogeneous continuous-time Markov chain on Ω with equal transition rates, noting that inferring parameters of complex substitution models is a vibrant yet separate subject of research (e.g. Zhao et al., 2016).
",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"Given a proper prior distribution with density π0 imposed on the branch lengths and on tree topologies, the posterior distribution can be computed as P(τ, q) ∝",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"L(τ, q)π0(τ, q).",2.1. Bayesian learning on phylogenetic tree space,[0],[0]
"With the motivation of phylogenetics in mind, we now describe how the phylogenetic problem sits as a specific case of a more general problem of Bayesian learning on orthant complexes, and distill the criteria needed to enable PPHMC on these spaces.",2.2. Bayesian learning on orthant complexes,[0],[0]
This generality will also enable applications of Bayesian learning on similar spaces in other settings.,2.2. Bayesian learning on orthant complexes,[0],[0]
"For example in robotics, the state complex can be described by a cubical complexes whose vertices are the states, whose edges correspond to allowable moves, and whose cubes correspond to collections of moves which can be performed simultaneously (Ardila et al., 2014).",2.2. Bayesian learning on orthant complexes,[0],[0]
"Similarly, in learning on spaces of treelike shapes, the attributes are open curves translated to start at the origin, described by a fixed number of landmark points (Feragen et al., 2010).
",2.2. Bayesian learning on orthant complexes,[0],[0]
"An orthant complex, being a union of Euclidean orthants, naturally inherits the Lebesgue measure which we will denote hereafter by µ. Orthant complexes are typically not manifolds, thus to ensure consistency in movements across orthants, we assume that local coordinates of the orthants are defined in such a way that there is a natural one-to-one correspondence between the sets of attributes of any two orthants sharing a common face.
",2.2. Bayesian learning on orthant complexes,[0],[0]
Assumption 2.1 (Consistency of local coordinates).,2.2. Bayesian learning on orthant complexes,[0],[0]
"Given two topologies τ, τ ′ ∈ Γ and state x = (τ, qτ ) = (τ ′, qτ ′) on the boundary of the orthants for τ and τ ′, then qτ = qτ ′ .
",2.2. Bayesian learning on orthant complexes,[0],[0]
We show that BHV tree space can be given such coordinates in the Appendix.,2.2. Bayesian learning on orthant complexes,[0],[0]
"For the rest of the paper, we define for each state (τ, q) ∈ X the setN (τ, q) of all neighboring topologies τ ′",2.2. Bayesian learning on orthant complexes,[0],[0]
such that τ ′,2.2. Bayesian learning on orthant complexes,[0],[0]
"orthant contains (τ, q).",2.2. Bayesian learning on orthant complexes,[0],[0]
"Note that N (τ, q) always includes τ , and if all coordinates of q are positive,N (τ, q) is exactly {τ}.",2.2. Bayesian learning on orthant complexes,[0],[0]
"Moreover, if τ ′ ∈ N",2.2. Bayesian learning on orthant complexes,[0],[0]
"(τ, q) and τ ′",2.2. Bayesian learning on orthant complexes,[0],[0]
"6= τ , we say that τ",2.2. Bayesian learning on orthant complexes,[0],[0]
"and τ ′ are joined by (τ, q).",2.2. Bayesian learning on orthant complexes,[0],[0]
"If the intersection of orthants for two topologies is a facet of each, we say that the two topologies are adjacent.
",2.2. Bayesian learning on orthant complexes,[0],[0]
"Finally, let G be the adjacency graph of the orthant complex X , that is, the graph with vertices representing the topologies and edges connecting adjacent topologies.",2.2. Bayesian learning on orthant complexes,[0],[0]
"Recalling that the diameter of a graph is the maximum value of the graph distance between any two vertices, we assume that
Assumption 2.2.",2.2. Bayesian learning on orthant complexes,[0],[0]
"The adjacency graph G of X has finite diameter, hereafter denoted by k.
For phylogenetics, k is of order O(N logN)",2.2. Bayesian learning on orthant complexes,[0],[0]
"(Li et al., 1996).
",2.2. Bayesian learning on orthant complexes,[0],[0]
"We seek to sample from a posterior distribution P(τ, q) on X .",2.2. Bayesian learning on orthant complexes,[0],[0]
"Assume that the negative logarithm of the posterior dis-
tribution U(τ, q) := − logP (τ, q) satisfies: Assumption 2.3.",2.2. Bayesian learning on orthant complexes,[0],[0]
"U(τ, q) is a continuous function on X , and is smooth up to the boundary of each orthant τ ∈",2.2. Bayesian learning on orthant complexes,[0],[0]
"Γ.
",2.2. Bayesian learning on orthant complexes,[0],[0]
"In the Appendix, we prove that if the logarithm of the phylogenetic prior distribution π0(τ, q) satisfies Assumption 2.3, then so does the phylogenetic posterior distribution.",2.2. Bayesian learning on orthant complexes,[0],[0]
"It is also worth noting that while U(τ, q) is smooth within each orthant, the function’s behavior may be very different between orthants and we do not assume any notion of differentiability of the posterior function on the whole space.",2.2. Bayesian learning on orthant complexes,[0],[0]
The HMC state space includes auxiliary momentum variables in addition to the usual state variables.,2.3. Hamiltonian dynamics on orthant complexes,[0],[0]
"In our framework, the augmented state of this system is represented by the position (τ, q) and the momentum p, an n-dimensional vector.",2.3. Hamiltonian dynamics on orthant complexes,[0],[0]
"We will denote the set of all possible augmented state (τ, q, p) of the system by T.
The Hamiltonian is defined as in the traditional HMC setting: H(τ, q, p) = U(τ, q) +K(p), where K(p) = 12‖p‖
2.",2.3. Hamiltonian dynamics on orthant complexes,[0],[0]
"We will refer to U(τ, q) and K(p) as the potential energy function and the kinetic energy function of the system at the state (τ, q, p), respectively.
",2.3. Hamiltonian dynamics on orthant complexes,[0],[0]
"Our stochastic Hamiltonian-type system of equations is:
dpi dt =− ∂U ∂qi (τ, q) if qi > 0
pi ← −pi; τ ∼ Z(N (τ, q))",2.3. Hamiltonian dynamics on orthant complexes,[0],[0]
"if qi = 0 dqi dt = pi
(2.1)
where Z(A) denotes the uniform distribution on the set A.
If all coordinates of q are positive, the system behaves as in the traditional Hamiltonian setting on Rn.",2.3. Hamiltonian dynamics on orthant complexes,[0],[0]
"When some attributes hit zero, however, the new orthant is picked randomly from the orthants of neighboring topologies (including the current one), and the momenta corresponding to non-positive attributes are negated.
",2.3. Hamiltonian dynamics on orthant complexes,[0],[0]
"Assumption 2.3 implies that despite the non-differentiable changes in the governing equation across orthants, the Hamiltonian of the system along any path is constant:
Lemma 2.1.",2.3. Hamiltonian dynamics on orthant complexes,[0],[0]
H is conserved along any system dynamics.,2.3. Hamiltonian dynamics on orthant complexes,[0],[0]
"In practice, we approximate Hamiltonian dynamics by the following integrator with step size , which we call “leapprog” as a probabilistic analog of the usual leapfrog algorithm.",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"This extends previous work of (Afshar and Domke, 2015) on RHMC where particles can reflect against planar surfaces of Rn≥0.
",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"In the RHMC formulation, one breaks the step size into smaller sub-steps, each of which correspond to an event when some of the coordinates cross zero.",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
We adapt this idea to HMC on orthant complexes as follows.,2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"Every time such an event happens, we reevaluate the values of the position and the momentum vectors, update the topology (uniformly at random from the set of neighboring topologies), reverse the momentum of crossing coordinates and continue the process until a total step size is achieved (Algorithm 1).",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"We note that several topologies might be visited in one leap-prog step.
",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"If there are no topological changes in the trajectory to time , this procedure is equivalent to classical HMC.",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"Moreover, since the algorithm only re-evaluates the gradient of the energy function at the end of the step when the final position has been fixed, changes in topology on the path have no effect on the changes of position and momentum.",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"Thus, the projection of the particles (in a single leap-prog step) to the (q, p) space is identical to a leapfrog step of RHMC on Rn≥0.
",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
Algorithm 1 Leap-prog algorithm with step size .,2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"p← p− ∇U(τ, q)/2 if FirstUpdateEvent(τ, q, p, ) = ∅ then q ← q + p
else t← 0",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"while FirstUpdateEvent(τ, q, p, − t) 6= ∅",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"do
(q, e, I)← FirstUpdateEvent(τ, q, p, − t) t←",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
t+ e τ ∼ Z(N,2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"(τ, q)) pI",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"← −pI
end while q ← q +",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"( − t)p
end if p← p− ∇U(τ, q)/2
Here FirstUpdateEvent(τ, q, p, t) returns",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"x, the position of the first event for which the line segment [q, q+ tp] crosses zero; e, the time when this event happens; and I , the indices of the coordinates crossing zero during this event.",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"If qi and pi are both zero before FirstUpdateEvent is called, i is not considered as a crossing coordinate.",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"If no such an event exists, ∅ is returned.",2.4. A probabilistic “leap-prog” algorithm,[0],[0]
"Probabilistic Path Hamiltonian Monte Carlo (PPHMC) with leap-prog dynamics iterates three steps, similar to that of classical HMC.",3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
"First, new values for the momentum variables are randomly drawn from their Gaussian distribution, independently of the current values of the posi-
tion variables.",3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
"Second, starting with the current augmented state, s = (τ, q, p), the Hamiltonian dynamics is run for a fixed number of steps T using the leap-prog algorithm with fixed step size .",3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
"The momentum at the end of this trajectory is then negated, giving a proposed augmented state s∗ = (τ∗, q∗, p∗).",3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
"Finally, this proposed augmented state is accepted as the next augmented state of the Markov chain with probability r(s, s∗)",3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
"= min (1, exp(H(s)−H(s∗))).
",3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
"PPHMC has two natural advantages over MCMC methods for phylogenetic inference: jumps between topologies are guided by the potential surface, and many jumps can be combined into a single proposal with high acceptance probability.",3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
"Indeed, rather than completely random jumps as used for MCMC, the topological modifications of HMC are guided by the gradient of the potential.",3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
"This is important because there are an enormous number of phylogenetic trees, namely (2n − 3)!!",3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
trees with n leaves.,3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
"Secondly, HMC can combine a great number of tree modifications into a single step, allowing for large jumps in tree space with high acceptance probability.",3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
These two characteristics are analogs of why HMC is superior to conventional MCMC in continuous settings and what we aimed to extend to our problem.,3. Hamiltonian Monte Carlo on orthant complexes,[0],[0]
"To support the use of this leap-prog integrator for MCMC sampling, we establish that integrator retains analogs of the good theoretical properties of Hamiltonian dynamics in classical settings, namely, time-reversibility, volume preservation and accessibility (proofs in Appendix).
",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"We formulate probabilistic reversibility as:
Lemma 3.1 (Reversibility).",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"For a fixed finite time horizon T , we denote by P (s, s′) the probability that the integrator moves s to s′ in a single update step.",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"We have
P ((τ, q, p), (τ ′, q′, p′))",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"= P ((τ ′, q′,−p′), (τ, q,−p)).
",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"for any augmented states (τ ′, q′, p′) and (τ, q, p) ∈ T.
The central part of proving the detailed balance condition of PPHMC is to verify that Hamiltonian dynamics preserves volume.",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"Unlike the traditional HMC setting where the proposal distribution is a single point mass, in our probabilistic setting, if we start at one augmented state s, we may end up at countably many end points due to stochastic HMC integration.",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"The equation describing volume preservation in this case needs to be generalized to the form of Equation (3.1), where the summations account for the discreteness of the proposal distribution.
",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
Lemma 3.2 (Volume preservation).,3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"For every pair of measurable sets A,B ⊂ T and elements s, s′ ∈ T, we denote by P (s, s′) the probability that the integrator moves s to s′
in a single update step and define
B(s) = {s′ ∈ B : P (s, s′) > 0}
and A(s′) =",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
{s ∈,3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"A : P (s, s′) > 0}.
",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"Then∫ A ∑ s′∈B(s) P (s, s′)",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"ds = ∫ B ∑ s∈A(s′) P (s′, s) ds′. (3.1)
",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"If we restrict to the case of trajectories staying in a single topology, A(s) and B(s′) are singletons and we get back the traditional equation of volume preservation.",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"We also note that the measure ds in Equation (3.1) is the Lebesgue measure: when there is no randomness in the Hamiltonian paths, (3.1) becomes the standard volume preservation condition, where volumes are expressed by the Lebesgue measure.
",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"Typically, accessibility poses no major problem in various settings of HMC since it is usually clear that one can go between any two positions in a single HMC step.",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"In the case of PPHMC, however, the composition of discrete and continuous structure, along with the possible non-differentiability of the potential energy across orthants, make it challenging to verify this condition.",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"Here we show instead that the PPHMC algorithm can go between any two states with k steps, where k denotes the diameter of adjacency graph G the space X and each PPHMC step consists of T leap-prog steps of size .
",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
Lemma 3.3 (k-accessibility).,3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"For a fixed starting state (τ (0), q(0)), any state (τ ′, q′) ∈ X can be reached from (τ (0), q(0)) by running k steps of PPHMC.
",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"The proof of this Lemma is based on Assumption 2.2, which asserts that the adjacency graph G of X has finite diameter, and that classical HMC allows the particles to move freely in each orthant by a single HMC step.
",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"To show that Markov chains generated by PPHMC are ergodic, we also need to prove that the integrator can reach any subset of positive measure of the augmented state space with positive probability.",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"To enable such a result, we show:
Lemma 3.4.",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"For every sequence of topologies ω = {τ (0), τ (1), . . .",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
", τ (nω)} and every set with positive measure B ⊂ X , let Bω be the set of all (τ ′, q′) ∈ B such that (τ ′, q′) can be reached from (τ (0), q(0)) in k PPHMC steps and such that the sequence of topologies crossed by the trajectory is ω.",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"We denote by IB,ω the set of all sequences of initial momenta for each PPHMC step {p(0), . . .",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
", p(k)} that make such a path possible.
",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"Then, if µ(IB,ω) = 0, then µ(Bω) = 0.
We also need certain sets to be countable.",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
Lemma 3.5.,3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"Given s ∈ T, we denote by R(s) the set of all augmented states s′ such that there is a finite-size leapprog step with path γ connecting s and s′, and by K(s) the set of all such leap-prog paths γ connecting s and s′ ∈ R(s).",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
Then R(s) and K(s) are countable.,3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"Moreover, the probability P∞(s, s′) of moving from s to s′ via paths with infinite number of topological changes is zero.",3.1. Theoretical properties of the leap-prog integrator,[0],[0]
"In this section, we establish that a Markov chain generated by PPHMC is ergodic with stationary distribution π(τ, q) ∝",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"exp(−U(τ, q)).",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"To do so, we need to verify that the Markov chain generated by PPHMC is aperiodic, because we have shown k-accessibility of the integrator rather than 1-accessibility.",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"Throughout this section, we will use the notation P ((τ, q, p), ·) to denote the one-step proposal distribution of PPHMC starting at augmented state (τ, q, p), and P ((τ, q), ·) to denote the one-step proposal distribution of PPHMC starting at position (τ, q) and with a momentum vector drawn from a Gaussian as described above.
",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
We first note that: Lemma 3.6.,3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"PPHMC preserves the target distribution π.
",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"Given probabilistic volume preservation (3.2), the proof is standard and is given in the Appendix.",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
Theorem 3.1 (Ergodic).,3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"The Markov chain generated by PPHMC is ergodic.
",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
Proof of Theorem 3.1.,3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"For every sequence of topologies ω = {τ (0), τ (1), . . .",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
", τ (nω)} (finite by Lemma 3.5) and every set with positive measure B ⊂ X , we define Bω and IB,ω as in the previous section.",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"By Lemma 3.3, we have
B =",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
⋃ ω,3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"Bω.
Assume that µ(IB,ω) = 0 for all ω.",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"From Lemma 3.4, we deduce that µ(Bω) = 0 for all ω.",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"This makes µ(B) = 0, which is a contradiction.",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"Hence µ(IB,ω)",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
> 0,3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
for some ω and Pnω,3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"((τ (0), q(0)), B) is at least the positive quantity
1
Z ∫ p∈IB,ω",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"Pnω ((τ (0), q(0), p), B) exp(−K(p))dp
where Z is the normalizing constant.",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"This holds for all sets with positive measure B ⊂ X , so PPHMC is irreducible.
",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
Now assume that a Markov chain generated by the leapfrog algorithm is periodic.,3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
The reversibility of Hamiltonian dynamics implies that the period d must be equal to 2.,3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"In other words, there exist two disjoint subsets X1, X2 of X such that π(X1) > 0, and
P (x,X2) = 1 ∀x ∈ X1, and P (x,X1) = 1 ∀x ∈ X2.
",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
Consider x ∈ X1 with all positive attributes.,3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
There exists a neighborhood Ux around x such that any y ∈ Ux is reachable from x by Hamiltonian dynamics.,3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"Since X1, X2 are disjoint, we deduce that µ(Ux ∩X1) = 0.",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"Since the neighborhood Ux exists for almost every x ∈ X1, this implies that µ(X1) = 0, and hence, that π(X1) = 0, which is a contradiction.",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"We conclude that any Markov chain generated by the leapfrog algorithm is aperiodic.
",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
Lemma 3.6 shows that PPHMC preserves the target distribution π.,3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
"This, along with π-irreducibility and aperiodicity, completes the proof (Roberts and Rosenthal, 2004).",3.2. Ergodicity of Probabilistic Path HMC,[0],[0]
One major advantage of HMC methods over traditional approaches is that HMC-proposed states may be distant from the current state but nevertheless have a high probability of acceptance.,3.3. An efficient surrogate smoothing strategy,[0],[0]
"This partially relies on the fact that the leapfrog algorithm with smooth energy functions has a local approximation error of order O( 3) (which leads to global errorO(T 3), where T is the number of leapfrog steps in a Hamiltonian path).
",3.3. An efficient surrogate smoothing strategy,[0],[0]
"However, when the potential energy function U(τ, q) is not differentiable on the whole space this low approximation error can break down.",3.3. An efficient surrogate smoothing strategy,[0],[0]
"Indeed, although PPHMC inherits many nice properties from vanilla HMC and RHMC (Afshar and Domke, 2015), this discontinuity of the derivatives of the potential energy across orthants may result in non-negligible loss of accuracy during numerical simulations of the Hamiltonian dynamics.",3.3. An efficient surrogate smoothing strategy,[0],[0]
"A careful analysis of the local approximation error of RHMC for potential energy functions with discontinuous first derivatives reveals that it only has an local error rate of order at least Ω( ) (see proof in Appendix):
Proposition 3.1.",3.3. An efficient surrogate smoothing strategy,[0],[0]
"Given a potential function V , we denote by V + and V − the restrictions of V on the half-spaces {x1 ≥ 0} and {x1 ≤ 0} and assume that V + and V − are smooth up to the boundary of their domains.",3.3. An efficient surrogate smoothing strategy,[0],[0]
"If the first derivative with respect to the first component of the potential energy V (q) are discontinuous across the hyperplane {x1 = 0} (i.e., (∂V +)/(∂q1) and (∂V −)/(∂q1) are not identical on this set), then RHMC on this hyper-plane has a local error of order at least Ω( ).
Since PPHMC uses RHMC, when the first derivatives of the potential energy are discontinuous, it also has a global error of orderO(C +T 3), which depends on the number of critical events C along a Hamiltonian path (that is, the number of reflection/refraction events).",3.3. An efficient surrogate smoothing strategy,[0],[0]
"This makes it difficult to tune the step size for optimal acceptance rate, and requires small , limiting topology exploration.
",3.3. An efficient surrogate smoothing strategy,[0],[0]
"To alleviate this issue, we propose the use of a surrogate induced Hamiltonian dynamics (Strathmann et al., 2015;
Zhang et al., 2016) with the Hamiltonian H̃(τ, q, p) = Ũ(τ, q) +K(p), where the surrogate potential energy is
Ũ(τ, q) = U(τ,G(q)), G(q) = (g(q1), . . .",3.3. An efficient surrogate smoothing strategy,[0],[0]
", g(qn))
and g(x) is some positive and smooth approximation of |x| with vanishing gradient at x = 0.",3.3. An efficient surrogate smoothing strategy,[0],[0]
"One simple example which will be used for the rest of this paper is
gδ(x) =",3.3. An efficient surrogate smoothing strategy,[0],[0]
"{ x, x ≥ δ 1 2δ",3.3. An efficient surrogate smoothing strategy,[0],[0]
"(x 2 + δ2), 0 ≤",3.3. An efficient surrogate smoothing strategy,[0],[0]
"x < δ
where δ will be called the smoothing threshold.
",3.3. An efficient surrogate smoothing strategy,[0],[0]
"Due to the vanishing gradient of g, Ũ now has continuous derivatives across orthants.",3.3. An efficient surrogate smoothing strategy,[0],[0]
"However, Ũ is no longer continuous across orthants since g(0) 6= 0",3.3. An efficient surrogate smoothing strategy,[0],[0]
and we thus employ the refraction technique introduced in Afshar and Domke (2015) (see Algorithm 2 for more details).,3.3. An efficient surrogate smoothing strategy,[0],[0]
"The proposed state s∗δ = (τ ∗ δ , q ∗ δ , p ∗ δ) at the end of the trajectory is accepted with probability according to the original Hamiltonian, that is, min(1, exp(H(s)−H(s∗δ))).
",3.3. An efficient surrogate smoothing strategy,[0],[0]
"By following the same framework proposed in previous sections, we can prove that the resulting sampler still samples from the exact posterior distribution P(τ, q).",3.3. An efficient surrogate smoothing strategy,[0],[0]
"A complete treatment, however, requires more technical adjustments and is beyond the scope of the paper.",3.3. An efficient surrogate smoothing strategy,[0],[0]
"We will leave this as a subject of future work.
",3.3. An efficient surrogate smoothing strategy,[0],[0]
"Algorithm 2 Refractive Leap-prog with surrogate p← p− ∇Ũ(τ, q)/2 if FirstUpdateEvent(τ, q, p, ) = ∅ then q ← q + p
else t← 0",3.3. An efficient surrogate smoothing strategy,[0],[0]
"while FirstUpdateEvent(q, p, − t)",3.3. An efficient surrogate smoothing strategy,[0],[0]
6=,3.3. An efficient surrogate smoothing strategy,[0],[0]
∅,3.3. An efficient surrogate smoothing strategy,[0],[0]
"do
(q, e, I)← FirstUpdateEvent(τ, q, p, − t) t←",3.3. An efficient surrogate smoothing strategy,[0],[0]
t+ e τ ′,3.3. An efficient surrogate smoothing strategy,[0],[0]
"∼ Z(N (τ, q))",3.3. An efficient surrogate smoothing strategy,[0],[0]
"∆E ← Ũ(τ ′, q)− Ũ(τ, q)",3.3. An efficient surrogate smoothing strategy,[0],[0]
"if ‖pI‖2 > 2∆E then pI ← √ ‖pI‖2 − 2∆E ·
−pI ‖pI‖
τ",3.3. An efficient surrogate smoothing strategy,[0],[0]
← τ ′,3.3. An efficient surrogate smoothing strategy,[0],[0]
else pI,3.3. An efficient surrogate smoothing strategy,[0],[0]
"← −pI
end if end while q ← q +",3.3. An efficient surrogate smoothing strategy,[0],[0]
"( − t)p
end if p← p− ∇Ũ(τ, q)/2
As we will illustrate later, compared to the exact potential energy, the continuity of the derivative of the surrogate potential across orthants dramatically reduces the discretiza-
tion error and allows for high acceptance probability with relatively large step size.",3.3. An efficient surrogate smoothing strategy,[0],[0]
"In this section, we demonstrate the validity and efficiency of our PPHMC method by an application to Bayesian phylogenetic inference.",4. Experiments,[0],[0]
"We compared our PPHMC implementations to industry-standard MrBayes 3.2.5, which uses MCMC to sample phylogenetic trees (Ronquist et al., 2012).",4. Experiments,[0],[0]
"We concentrated on the most challenging part: sampling jointly for the branch lengths and tree topologies, and assumed other parameters (e.g., substitution model, hyper-parameters for the priors) are fixed.",4. Experiments,[0],[0]
"More specifically, for all of our experiments we continued to assume the Jukes-Cantor model of DNA substitution and placed a uniform prior on the tree topology τ ∼ Z (TN ) with branch lengths i.i.d.",4. Experiments,[0],[0]
"qi ∼ Exponential (λ = 10), as done by others when measuring the performance of MCMC algorithms for Bayesian phylogenetics (e.g., Whidden and Matsen, 2015).",4. Experiments,[0],[0]
"As mentioned earlier, although in the theoretical development we assumed that the lengths of the pendant edges are bounded from below by a positive constant e0 to ensure that the likelihood stays positive on the whole tree space, this condition is not necessary in practice since the Hamiltonian dynamics guide the particles away from regions with zero likelihood (i.e., the region with U =∞).",4. Experiments,[0],[0]
"We validate the algorithm through two independent implementations in open-source software:
1.",4. Experiments,[0],[0]
"a Scala version available at https://github.com/ armanbilge/phyloHMC that uses the Phylogenetic Likelihood Library1 (Flouri et al., 2015), and
2.",4. Experiments,[0],[0]
a Python version available at https://github.,4. Experiments,[0],[0]
"com/zcrabbit/PhyloInfer that uses the ETE toolkit (Huerta-Cepas et al., 2016) and Biopython (Cock et al., 2009).",4. Experiments,[0],[0]
"As a proof of concept, we first tested our PPHMC method on a simulated data set.",4.1. Simulated data,[0],[0]
We used a random unrooted tree with N = 50 leaves sampled from the aforementioned prior.,4.1. Simulated data,[0],[0]
1000 nucleotide observations for each leaf were then generated by simulating the continuous-time Markov model along the tree.,4.1. Simulated data,[0],[0]
"This moderate data set provided enough information for model inference while allowing for a relatively rich posterior distribution to sample from.
",4.1. Simulated data,[0],[0]
"We ran MrBayes for 107 iterations and sampled every 1000 iterations after a burn-in period of the first 25% iterations to establish a ground truth for the posterior distribution.
1https://github.com/xflouris/libpll
For PPHMC, we set the step size = 0.0015 and smoothing threshold δ = 0.003 to give an overall acceptance rate of about α = 0.68 and set the number of leap-prog steps T = 200.",4.1. Simulated data,[0],[0]
"We then ran PPHMC for 10, 000 iterations with a burn-in of 25%.",4.1. Simulated data,[0],[0]
We saw that PPHMC indeed samples from the correct posterior distribution (see Figure S1 in the Appendix).,4.1. Simulated data,[0],[0]
We also analyzed an empirical data set labeled DS4 by Whidden and Matsen (2015) that has become a standard benchmark for MCMC algorithms for Bayesian phylogenetics since Lakner et al. (2008).,4.2. Empirical data,[0],[0]
DS4 consists of 1137 nucleotide observations per leaf from N = 41 leaves representing different species of fungi.,4.2. Empirical data,[0],[0]
"Notably, only 554 of these observations are complete; the remaining 583 are missing a character for one or more leaves so the likelihood is marginalized over all possible characters.",4.2. Empirical data,[0],[0]
"Whidden and Matsen (2015) observed that the posterior distribution for DS4 features high-probability trees separated by paths through low-probability trees and thus denoted it a “peaky” data set that was difficult to sample from using MrBayes.
To find the optimal choice of tuning parameters for DS4, we did a grid search on the space of step size and the smoothing threshold–step size ratio δ/ .",4.2. Empirical data,[0],[0]
The number of leap-prog steps T was adjusted to keep the total simulation time T fixed.,4.2. Empirical data,[0],[0]
"For each choice of parameters, we estimated the expected acceptance rate α by averaging over 20 proposals from the PPHMC transition kernel per state for 100 states sampled from the posterior in a previous, well-mixed run.",4.2. Empirical data,[0],[0]
"This strategy enabled us to obtain an accurate estimate of the average acceptance rate without needing to account for the different mixing rates in a full PPHMC run due to the various settings for the tuning parameters.
",4.2. Empirical data,[0],[0]
The results suggest that choosing δ,4.2. Empirical data,[0],[0]
≈ 2 maximizes the acceptance probability (Figure 2b).,4.2. Empirical data,[0],[0]
"Furthermore, when aiming for the optimal acceptance rate of α = 0.65 (Neal, 2011), the use of the surrogate function enables a choice of step size nearly 10 times greater than otherwise.",4.2. Empirical data,[0],[0]
"In practice, this means that an equivalent proposal requires less leap-prog steps and gives a more efficient sampling algorithm.
",4.2. Empirical data,[0],[0]
"To see the difference this makes in practice, we ran long trajectories for exact and surrogate-smoothed PPHMC with a relatively large step size = 0.0008.",4.2. Empirical data,[0],[0]
"Indeed, we found that the surrogate enables very long trajectories and large number of topology transformations (Figure 2a,c).",4.2. Empirical data,[0],[0]
"Sophisticated techniques for sampling posteriors using HMC have thus far been restricted to manifolds with
boundary.",5. Conclusion,[0],[0]
"To address this limitation, we have developed “PPHMC,” which is the first extension of HMC to a space with intricate combinatorial structure.",5. Conclusion,[0],[0]
The corresponding integrator makes a random choice among alternatives when encountering a boundary.,5. Conclusion,[0],[0]
"To prove ergodicity, we extend familiar elements of HMC proofs to this probabilistic path setting.",5. Conclusion,[0],[0]
We develop a smoothing surrogate function that enables long HMC paths with many boundary transitions across which the posterior is not differentiable.,5. Conclusion,[0],[0]
"Our surrogate method enables high acceptance probability for RHMC (Afshar and Domke, 2015) in the case of potential functions with discontinuous derivatives; this aspect of our work is independent of the probabilistic nature of PPHMC.",5. Conclusion,[0],[0]
Our implementation shows good performance on both simulated and real data.,5. Conclusion,[0],[0]
"There are many opportunities for future development, including extending the theory to other classes of combinatorially-described spaces and surrogate functions, developing adaptive path length algorithms, as well as extending our implementation for phylogenetics to sample other mutation model and demographic parameters along with topologies.",5. Conclusion,[0],[0]
"This work supported by National Science Foundation grants DMS-1223057, DMS-1341325, and CISE-1564137.",Acknowledgements,[0],[0]
The research of Frederick Matsen was supported in part by a Faculty Scholar grant from the Howard Hughes Medical Institute and the Simons Foundation.,Acknowledgements,[0],[0]
The authors are grateful to Alex Gavryushkin for helpful discussions about this work.,Acknowledgements,[0],[0]
"Hamiltonian Monte Carlo (HMC) is an efficient and effective means of sampling posterior distributions on Euclidean space, which has been extended to manifolds with boundary.",abstractText,[0],[0]
"However, some applications require an extension to more general spaces.",abstractText,[0],[0]
"For example, phylogenetic (evolutionary) trees are defined in terms of both a discrete graph and associated continuous parameters; although one can represent these aspects using a single connected space, this rather complex space is not suitable for existing HMC algorithms.",abstractText,[0],[0]
"In this paper, we develop Probabilistic Path HMC (PPHMC) as a first step to sampling distributions on spaces with intricate combinatorial structure.",abstractText,[0],[0]
"We define PPHMC on orthant complexes, show that the resulting Markov chain is ergodic, and provide a promising implementation for the case of phylogenetic trees in opensource software.",abstractText,[0],[0]
We also show that a surrogate function to ease the transition across a boundary on which the log-posterior has discontinuous derivatives can greatly improve efficiency.,abstractText,[0],[0]
Probabilistic Path Hamiltonian Monte Carlo,title,[0],[0]
"System identification, i.e. learning dynamics models from data (Ljung, 2010), is key in model-based control design (Aström & Murray, 2010; Camacho & Alba, 2013) and model-based reinforcement learning (RL) (Deisenroth & Rasmussen, 2011; Doerr et al., 2017b).",1. Introduction,[0],[0]
"State-space models (SSMs) are one popular class of representations for model learning (Billings, 2013), which describe a system with input ut, output yt, and a latent Markovian state xt.",1. Introduction,[0],[0]
"The transition model f , observation model g, process, and measurement noise t and γt form a discrete-time SSM
xt+1 = f(xt,ut) + t ,
yt = g(xt) +",1. Introduction,[0],[0]
γt .,1. Introduction,[0],[0]
"(1)
1Bosch Center for Artificial Intelligence, Renningen, Germany.",1. Introduction,[0],[0]
"2Max Planck Institute for Intelligent Systems, Stuttgart/Tübingen, Germany.",1. Introduction,[0],[0]
"3University of Southern California, Los Angeles, USA.",1. Introduction,[0],[0]
"4Machine Learning and Robotics Lab, University of Stuttgart, Germany.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
Andreas Doerr <,1. Introduction,[0],[0]
"andreasdoerr@gmx.net>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"In real systems, the latent state xt can typically not be measured directly, but has to be inferred from a series of noisy output observations.",1. Introduction,[0],[0]
"Efficient methods exist for linear models (Van Overschee & De Moor, 2012) and non-linear, deterministic models (Hochreiter & Schmidhuber, 1997).
",1. Introduction,[0],[0]
"Probabilistic models enable safe RL and alleviate model bias (Deisenroth & Rasmussen, 2011).",1. Introduction,[0],[0]
"Placing a Gaussian process (GP) prior on the unknown transition function f and potentially on the observation model g allows for Bayesian model learning, resulting in GP-SSMs.",1. Introduction,[0],[0]
"Robust training of these probabilistic, non-linear SSMs is a challenging and only partially solved problem, especially for higher dimensional systems (Frigola et al., 2013; Bayer & Osendorfer, 2014; Krishnan et al., 2015; Fraccaro et al., 2016; Eleftheriadis et al., 2017; Svensson & Schön, 2017).",1. Introduction,[0],[0]
This paper proposes the probabilistic recurrent state-space model1 (PRSSM2).,1. Introduction,[0],[0]
PR-SSM takes inspiration from RNN model learning.,1. Introduction,[0],[0]
"In particular, the transition model is unrolled over time, therefore accounting for temporal correlations whilst simultaneously allowing for learning by backpropagation through time.",1. Introduction,[0],[0]
"The proposed method enables probabilistic model predictions, inferring complex latent state distributions, and principled model complexity regularization.",1. Introduction,[0],[0]
"We propose an adapted form of a recognition model for the initial state, which facilitates scalability through batch learning and learning of slow or unstable system dynamics (cf. Sec. 5).
",1. Introduction,[0],[0]
"In summary, the key contributions of this paper are: •",1. Introduction,[0],[0]
"Combining gradient-based and sample-based inference
for efficient learning of nonlinear Gaussian process state-space models; • Tractable variational approximation, maintaining the true latent state posterior and temporal correlations;",1. Introduction,[0],[0]
"• Doubly stochastic inference scheme for scalability; • Recognition model, which allows for initializing the
latent state distribution and thus for robust training and prediction.
",1. Introduction,[0],[0]
"Together, these contributions allow for efficient and robust learning of the PR-SSM.",1. Introduction,[0],[0]
"The proposed framework is evaluated on a set of real-world system identification datasets and benchmarked against a range of state-of-the art methods.
",1. Introduction,[0],[0]
"1Code available at: https://github.com/ boschresearch/PR-SSM .
",1. Introduction,[0],[0]
2Pronounced prism.,1. Introduction,[0],[0]
Modeling the behavior of systems with only partially observable states has been an active field of research for many years and several schools of thought have emerged.,2. Related Work,[0],[0]
"Representations range from SSMs (Van Overschee & De Moor, 2012) over Predictive State Representations (PSRs) (Littman & Sutton, 2002; Singh et al., 2003; Rudary & Singh, 2004) to autoregressive models (Murray-Smith & Girard, 2001; Girard et al., 2003; Likar & Kocijan, 2007; Billings, 2013), as well as hybrid versions combining these approaches (Mattos et al., 2015; 2016; Doerr et al., 2017a).
",2. Related Work,[0],[0]
"Autoregressive (history-based) methods avoid the complex inference of a latent state and instead directly learn a mapping from a history of h past inputs and observations to the next observation, i.e. yt+1 = f(yt:t−h,ut:t−h).",2. Related Work,[0],[0]
These models face the issue of learning from noise corrupted input data.,2. Related Work,[0],[0]
"Recent work addresses this problem by either actively accounting for input noise (McHutchon & Rasmussen, 2011) or reverting to a hybrid, autoregressive formulation in a latent, but noise free state (Mattos et al., 2016; Doerr et al., 2017a).",2. Related Work,[0],[0]
"Such models can be made deep and trained in a recurrent manner (Mattos et al., 2015).
",2. Related Work,[0],[0]
"In contrast, SSMs are based on a compact, Markovian state representation.",2. Related Work,[0],[0]
"Furthermore, they allow for the direct application of many existing control algorithms, which rely on the explicit representation of the latent state.",2. Related Work,[0],[0]
"Exact solutions for state inference and model learning for linear Gaussian SSMs are given by the well known Kalman filter/smoother (Kalman, 1960) and subspace identification (Van Overschee & De Moor, 2012).",2. Related Work,[0],[0]
"In the case of non-linear latent state transition dynamics, both deterministic and probabilistic variants are active fields of research.
",2. Related Work,[0],[0]
"Deterministic variants such as Long Short-Term Memory (LSTM) models have been shown to be powerful representations for tasks such as natural language processing (Venugopalan et al., 2014) or text understanding (Sutskever et al., 2011).",2. Related Work,[0],[0]
"However, for the purpose of system identification and control, probabilistic predictions are often preferred to make model errors explicit (Deisenroth & Rasmussen, 2011).",2. Related Work,[0],[0]
"A variety of stochastic deep recurrent models has been presented based on Stochastic Gradient Variational Bayes (SGVB) (Bayer & Osendorfer, 2014; Krishnan et al., 2015; Watter et al., 2015; Chung et al., 2015; Archer et al., 2015; Karl et al., 2016; Fraccaro et al., 2016; Gemici et al., 2017).",2. Related Work,[0],[0]
The PR-SSM inference is inspired by the learning procedure in these deep recurrent models while employing GPs as a principled way of model regularization.,2. Related Work,[0],[0]
Both procedures share the explicit unrolling of transition and observation model.,2. Related Work,[0],[0]
Errors between the predicted and the observed system output are propagated back over time.,2. Related Work,[0],[0]
"Therefore, the transition dynamics has to be inferred, but the latent state (distribution) is given implicitly.",2. Related Work,[0],[0]
"This way, the challenging
initialization and optimization of latent state variables is prevented.",2. Related Work,[0],[0]
"In contrast to deep recurrent models, the PR-SSM loss and model regularization is automatically obtained from the GP assumption.",2. Related Work,[0],[0]
"Furthermore, PR-SSMs obtain predictive distributions and the proposed initial state recognition model facilitates learning on shorter sub-trajectories and unstable systems, which is not possible in deep recurrent models.
",2. Related Work,[0],[0]
"GP-SSMs are a popular class of probabilistic SSMs (Wang et al., 2008; Ko & Fox, 2009; Turner et al., 2010; Frigola et al., 2013; 2014; Eleftheriadis et al., 2017).",2. Related Work,[0],[0]
"The use of GPs allows for a fully Bayesian treatment of the modeling problem resulting in an automatic complexity trade-off, which regularizes the learning problem.",2. Related Work,[0],[0]
"Filtering and smoothing in GP-SSMs has already been covered extensively: deterministic (e.g. linearization) as well as stochastic (e.g. particles) methods are presented in (Ko & Fox, 2009; Deisenroth et al., 2012).",2. Related Work,[0],[0]
"These methods, however, assume an established system model, which is generally not available without prior knowledge.",2. Related Work,[0],[0]
"In this work, the latent state smoothing distribution is given implicitly and optimized jointly during model learning.
",2. Related Work,[0],[0]
Approaches to probabilistic GP-SSMs mainly differ in their approximations to the model’s joint distribution (e.g. when solving for the smoothing distribution or for the observation likelihood).,2. Related Work,[0],[0]
"One class of approaches aims to solve for the true distribution, which requires sample-based methods, e.g. Particle Markov Chain Monte Carlo (PMCMC), as in (Frigola et al., 2013; 2014).",2. Related Work,[0],[0]
These methods are close to exact and thus are able to represent temporal correlations.,2. Related Work,[0],[0]
"However, they are computationally inefficient and intractable for higher latent state dimensions or larger datasets.",2. Related Work,[0],[0]
"A second class of approaches is based on variational inference and mean field approximations in the latent state (Mattos et al., 2015; Föll et al., 2017).",2. Related Work,[0],[0]
"These methods, however, operate on latent autoregressive models, which can be initialized by the observed output time series, such that the learned latent representation acts as a smoothed version of the observations.",2. Related Work,[0],[0]
"In Markovian latent spaces, no such prior information is available and therefore initialization is non-trivial.",2. Related Work,[0],[0]
Model optimization based on mean field approximations empirically leads to highly suboptimal local solutions.,2. Related Work,[0],[0]
"Bridging the gap between both classes, recent methods strive to recover (temporal) latent state structure.",2. Related Work,[0],[0]
"In (Eleftheriadis et al., 2017), a linear, time-varying latent state structure is enforced as a tractable compromise between the true non-linear dependencies and no dependencies as in mean field variational inference.",2. Related Work,[0],[0]
"However, to facilitate learning, a more complex recognition model over the linear time-varying dynamics is required.",2. Related Work,[0],[0]
"In contrast, the proposed PR-SSM can efficiently incorporate the true dynamics by combining sampling- and gradient-based learning.",2. Related Work,[0],[0]
This section presents the general model background for GPSSMs.,3. Gaussian Process State-Space Model,[0],[0]
"Following a short recap of GPs in Sec. 3.1 and a specific sparse GP prior in Sec. 3.2, PR-SSM as one particular GP-SSM is introduced in Sec. 3.3.",3. Gaussian Process State-Space Model,[0],[0]
Inference on this model is detailed in Sec. 4.,3. Gaussian Process State-Space Model,[0],[0]
"A GP (Williams & Rasmussen, 2005) is a distribution over functions f :",3.1. Gaussian Process,[0],[0]
"RD → R that is fully defined by a mean function m(·) and covariance function k(·, ·).",3.1. Gaussian Process,[0],[0]
For each finite set of points X =,3.1. Gaussian Process,[0],[0]
"[x1, . . .",3.1. Gaussian Process,[0],[0]
",xN ] from the function’s domain, the corresponding function evaluations f =",3.1. Gaussian Process,[0],[0]
"[f(x1), . . .",3.1. Gaussian Process,[0],[0]
", f(xN )] are jointly Gaussian as given by
p(f |X)",3.1. Gaussian Process,[0],[0]
"= N (f |mX ,KX,X) , (2)
with mean vector mX having elements mi = m(xi) and covariance matrix KX,X with entries Kij = k(xi,xj).",3.1. Gaussian Process,[0],[0]
"Given observed function values f at input locationsX , the GP predictive distribution at a new input location x∗ is obtained as the conditional distribution
p(f∗ | x∗,f ,X) = N (f∗ | µ, σ2), (3)
with posterior mean and variance
µ = mx∗ +",3.1. Gaussian Process,[0],[0]
"kx∗,XK −1",3.1. Gaussian Process,[0],[0]
"X,X(f −mX) , (4) σ2 = kx∗,x∗ − kx∗,XK−1X,XkX,x∗ , (5)
where kA,B denotes the scalar or vector of covariances for each pair of elements inA andB. In this work, the squared exponential kernel with Automatic Relevance Determination (ARD) (Williams & Rasmussen, 2005) with hyperparameters θGP is employed.",3.1. Gaussian Process,[0],[0]
"Due to the proposed samplingbased inference scheme (cf. Sec. 4), any other differentiable kernel might be incorporated instead.",3.1. Gaussian Process,[0],[0]
"Commonly, the GP prediction in (3) is obtained by conditioning on all training data X , y. To alleviate the computational cost, several sparse approximations have been presented (Snelson & Ghahramani, 2006).",3.2. GP Sparsification,[0],[0]
By introducing P inducing GP targets z =,3.2. GP Sparsification,[0],[0]
"[z1, . . .",3.2. GP Sparsification,[0],[0]
", zP ]",3.2. GP Sparsification,[0],[0]
at pseudo input points ζ,3.2. GP Sparsification,[0],[0]
=,3.2. GP Sparsification,[0],[0]
"[ζ1, . . .",3.2. GP Sparsification,[0],[0]
", ζP ], which are jointly Gaussian with the latent function f , the true GP predictive distribution is approximated by conditioning only on this set of inducing points,
p(f∗ | x∗,f ,X)",3.2. GP Sparsification,[0],[0]
≈ p(f∗,3.2. GP Sparsification,[0],[0]
"| x∗, z, ζ) , (6) p(z)",3.2. GP Sparsification,[0],[0]
"= N (z |mζ ,Kζ,ζ) .",3.2. GP Sparsification,[0],[0]
"(7)
The predicted function values consequently become mutually independent given the inducing points.",3.2. GP Sparsification,[0],[0]
The PR-SSM is built upon a GP prior on the transition function f(·) and a parametric observation model g(·).,3.3. PR-SSM Model Definition,[0],[0]
"This is a common model structure, which can be assumed without loss of generality over (1), since any observation model can be absorbed into a sufficiently large latent state (FrigolaAlcade, 2015).",3.3. PR-SSM Model Definition,[0],[0]
"Eliminating the non-parametric observation model, however, mitigates the problem of ‘severe nonidentifiability’ between transition model f(·) and observation model g(·) (Frigola et al., 2014).",3.3. PR-SSM Model Definition,[0],[0]
"Independent GP priors are employed for each latent state dimension d given individual inducing points ζd and zd.
",3.3. PR-SSM Model Definition,[0],[0]
"In the following derivations, the system’s latent state, input and output at time t are denoted by xt ∈ RDx , ut ∈ RDu , and yt ∈ RDy , respectively.",3.3. PR-SSM Model Definition,[0],[0]
"The shorthand x̂t = (xt,ut) denotes the transition model’s input at time t. The output of the transition model is denoted by ft+1 = f(x̂t).",3.3. PR-SSM Model Definition,[0],[0]
"A time series of observations from time a to time b (including) is abbreviated by ya:b (analogously for the other model variables).
",3.3. PR-SSM Model Definition,[0],[0]
"The joint distribution of all PR-SSM random variables is given by
p(y1:T ,x1:T ,f2:T , z) =",3.3. PR-SSM Model Definition,[0],[0]
"[ T∏ t=1 p(yt | xt) ] p(x1)p(z) (8)[
T∏ t=2 p(xt | ft)p(ft | x̂t−1, z)
] ,
where p(ft | x̂t−1, z) = ∏Dx d=1 p(ft,d | x̂t−1, zd) and z ≡",3.3. PR-SSM Model Definition,[0],[0]
"[z1, . . .",3.3. PR-SSM Model Definition,[0],[0]
zDx ].,3.3. PR-SSM Model Definition,[0],[0]
"A graphical model of the resulting PRSSM is shown in Fig. 1.
",3.3. PR-SSM Model Definition,[0],[0]
"The individual contributions to (8) are given by the observation model and the transition model, which are now described in detail.",3.3. PR-SSM Model Definition,[0],[0]
"The observation model is governed by
p(yt | xt) = N (yt | g(xt), diag(σ2y,1, . . .",3.3. PR-SSM Model Definition,[0],[0]
", σ2y,Dy )), (9)
",3.3. PR-SSM Model Definition,[0],[0]
"In particular, in our experiments, we employed a parametric observation model
g(xt) = Cxt .",3.3. PR-SSM Model Definition,[0],[0]
"(10)
",3.3. PR-SSM Model Definition,[0],[0]
"The matrixC is chosen to select theDy first entries of xt by defining C := [I,0] ∈ RDy×Dx with I being the identity matrix.",3.3. PR-SSM Model Definition,[0],[0]
"This model is suitable for observation spaces that are low-dimensional compared to the latent state dimensionality, i.e. Dy < Dx, which is often the case for physical systems with a restricted number of sensors.",3.3. PR-SSM Model Definition,[0],[0]
The first Dy latent state dimensions can therefore be interpreted as noise free sensor measurements.,3.3. PR-SSM Model Definition,[0],[0]
"For high-dimensional observation spaces (e.g. images), a more involved, given observation model (e.g. a pretrained neural network) may be seamlessly
incorporated into the presented framework as long as g(·) is differentiable.
",3.3. PR-SSM Model Definition,[0],[0]
"Process noise is modeled as
p(xt | ft) = N (xt | ft, diag(σ2x,1, . . .",3.3. PR-SSM Model Definition,[0],[0]
", σ2x,Dx)) .",3.3. PR-SSM Model Definition,[0],[0]
"(11)
",3.3. PR-SSM Model Definition,[0],[0]
"The transition dynamics is described independently for each latent state dimension d by p(ft,d | x̂t−1, zd)p(zd).",3.3. PR-SSM Model Definition,[0],[0]
"This probability is given by the sparse GP prior (7) and predictive distribution (6), where x∗ = x̂t and f∗ = ft,d.",3.3. PR-SSM Model Definition,[0],[0]
The initial system state distribution p(x1) is unknown and has to be estimated.,3.3. PR-SSM Model Definition,[0],[0]
Computing the log likelihood or a posterior based on (8) is generally intractable due to the nonlinear GP dynamics model in the latent state.,4. PR-SSM Inference,[0],[0]
"However, the log marginal likelihood log p(y1:T ) (evidence) can be bounded from below by the Evidence Lower BOound (ELBO)",4. PR-SSM Inference,[0],[0]
"(Blei et al., 2017).",4. PR-SSM Inference,[0],[0]
"This ELBO is derived via Jensen’s inequality by introducing a computationally simpler, variational distribution q(x1:T ,f2:T , z) to approximate the model’s true posterior distribution p(x1:T ,f2:T , z",4. PR-SSM Inference,[0],[0]
| y1:T ) (cf. eq.,4. PR-SSM Inference,[0],[0]
(8)).,4. PR-SSM Inference,[0],[0]
"In contrast to previous work (Frigola et al., 2014; Mattos et al., 2015; Eleftheriadis et al., 2017), the proposed approximation explicitly incorporates the true temporal correlations in the latent state, whilst being scalable to large datasets.",4. PR-SSM Inference,[0],[0]
"Previous work based on sequential Monte Carlo methods (Frigola et al., 2013; Svensson & Schön, 2017) already allowed for temporal correlations but required computationally challenging resampling in each timestep.",4. PR-SSM Inference,[0],[0]
"The inference scheme is inspired by doubly stochastic variational inference for deep GPs as presented in (Salimbeni & Deisenroth, 2017).",4. PR-SSM Inference,[0],[0]
"PR-SSM employs a variational sparse GP (Titsias, 2009) based on a variational distribution q(z) on the GP’s inducing outputs as previously used in (Frigola et al., 2014; Eleftheriadis et al., 2017).",4.1. Variational Sparse GP,[0],[0]
"Eliminating the inducing outputs, however, results in dependencies between inducing outputs and data which, in turn, leads to a complexity of O(NP 2), where
N is the number of data points and P the number of inducing points (Titsias, 2009).",4.1. Variational Sparse GP,[0],[0]
"Unfortunately, this complexity is still prohibitive for large datasets.",4.1. Variational Sparse GP,[0],[0]
"Therefore, we resort to an explicit representation of the variational distribution over inducing outputs as previously proposed in (Hensman et al., 2013).",4.1. Variational Sparse GP,[0],[0]
This explicit representation enables scalability by utilizing stochastic gradient-based optimization since individual GP predictions become independent given the explicit inducing points.,4.1. Variational Sparse GP,[0],[0]
"Following a mean-field variational approximation the inducing output distribution is given as q(z) = ∏Dx d=1N (zd | µd,Σd) for each latent state dimension d with diagonal variance Σd.",4.1. Variational Sparse GP,[0],[0]
"Marginalizing out the inducing outputs, the GP predictive distribution is obtained as Gaussian with mean and variance given by
µ = mx̂t +α(x̂t)(µd −mζd) , σ2 = kx̂t,x̂t −α(x̂t)(Kζd,ζd − Σd)α(x̂t)T ,
α(x̂t)",4.1. Variational Sparse GP,[0],[0]
":= kx̂t,ζdK −1 ζd,ζd .
(12)",4.1. Variational Sparse GP,[0],[0]
"In previous work (Mattos et al., 2015), a factorized variational distribution is considered based on a mean-field approximation for the latent states x1:T .",4.2. Variational Approximation,[0],[0]
"Their variational distribution is given by
q(x1:T ,f2:T , z) =[ Dx∏ d=1 q(zd)",4.2. Variational Approximation,[0],[0]
"[ T∏ t=2 p(ft,d | x̂t−1, zd) ]][ T∏ t=1 q(xt) ] .
",4.2. Variational Approximation,[0],[0]
"This choice, however, leads to several caveats: (i) The number of model parameters grows linearly with the length of the time series since each latent state is parametrized by its individual distribution q(xt) for every time step.",4.2. Variational Approximation,[0],[0]
(ii),4.2. Variational Approximation,[0],[0]
"Initializing the latent state is non-trivial since the true, underlying observation mapping is generally unknown and non-bijective.",4.2. Variational Approximation,[0],[0]
(iii),4.2. Variational Approximation,[0],[0]
The model design does not represent correlations between time steps.,4.2. Variational Approximation,[0],[0]
"Instead, these correlations are only introduced by enforcing pairwise couplings during the optimization process.",4.2. Variational Approximation,[0],[0]
"The first two problems have been addressed in (Mattos et al., 2015; Eleftheriadis et al., 2017) by introducing a recognition model, e.g. a Bi-RNN3, which acts as a smoother which can be learned through backpropagation and which allows to obtain the latent states given the input/output sequence.
",4.2. Variational Approximation,[0],[0]
"The issue of representing correlations between time steps, however, is currently an open problem which we aim to address with our proposed model structure.",4.2. Variational Approximation,[0],[0]
"Properly representing these correlations is a crucial step in making the
3A bi-directional RNN operates on a sequence from left to right and vice versa to obtain predictions based on past and future inputs.
",4.2. Variational Approximation,[0],[0]
"optimization problem tractable in order to learn GP-SSMs for complex systems.
",4.2. Variational Approximation,[0],[0]
"For PR-SSM, the variational distribution is given by
q(x1:T ,f2:T , z) = (13) T∏ t=2",4.2. Variational Approximation,[0],[0]
"[ p(xt | ft) Dx∏ d=1 [p(ft,d | x̂t−1, zd)q(zd)]",4.2. Variational Approximation,[0],[0]
"] q(x1) ,
with
q(x1)=N (x1 | µx1 ,Σx1) , q(zd)=N (zd | µd,Σd) .
",4.2. Variational Approximation,[0],[0]
"In contrast to previous work, the proposed variational distribution does not factorize over the latent state but takes into account the true transition model, based on the sparse GP approximation from (8).",4.2. Variational Approximation,[0],[0]
"In previous work, stronger approximations have been required to achieve an analytically tractable ELBO.",4.2. Variational Approximation,[0],[0]
"This work, however, deals with the more complex distribution by combining sampling and gradientbased methods.
",4.2. Variational Approximation,[0],[0]
"In (Frigola et al., 2014), the variational distribution over inducing outputs has been optimally eliminated.",4.2. Variational Approximation,[0],[0]
"This leads to a smoothing problem in a second system requiring computationally expensive, e.g. sample-based, smoothing methods.",4.2. Variational Approximation,[0],[0]
"Instead, we approximate the distribution by a Gaussian, which is the optimal solution in case of sparse GP regression (cf. (Titsias, 2009)).
",4.2. Variational Approximation,[0],[0]
"The PR-SSM model parameters include the variational parameters for the initial state and inducing outputs and hyperparameters, such as inducing inputs, noise parameters and GP kernel parameters: θPR-SSM = (µx1 ,Σx1 ,µ1:Dx ,Σ1:Dx , ζ1:",4.2. Variational Approximation,[0],[0]
"Dx , σ 2 x,1:",4.2. Variational Approximation,[0],[0]
"Dx , σ 2 y,1:Dy , θGP,1:Dx).",4.2. Variational Approximation,[0],[0]
"Note that in the PR-SSM, the number of parameters grows only with the number of latent dimensions, but not with the length of the time series.",4.2. Variational Approximation,[0],[0]
"Following standard variational inference techniques (Blei et al., 2017), the ELBO is given by
log p(y1:T )≥Eq(x1:T ,f2:T ,z) [ log p(y1:T ,x1:T ,f2:T ,z)
q(x1:T ,f2:T , z) ]",4.3. Variational Evidence Lower Bound,[0],[0]
=: LPR-SSM .,4.3. Variational Evidence Lower Bound,[0],[0]
"(14)
Maximizing the ELBO is equivalent to minimizing KL(q(x1:T ,f2:T , z) ‖",4.3. Variational Evidence Lower Bound,[0],[0]
"p(x1:T ,f2:T , z | y1:T ))",4.3. Variational Evidence Lower Bound,[0],[0]
"(Blei et al., 2017), therefore this is a way to optimize the approximated model parameter distribution with respect to the intractable, true model parameter posterior.
",4.3. Variational Evidence Lower Bound,[0],[0]
"Based on (8) and (13) and using standard variational calcu-
lus, the ELBO (14) can be transformed into
LPR-SSM = T∑ t=1 Eq(xt)[log p(yt | xt)]
",4.3. Variational Evidence Lower Bound,[0],[0]
− Dx∑ d=1 KL(q(zd) ‖,4.3. Variational Evidence Lower Bound,[0],[0]
"p(zd; ζd)) , (15)
with q(xt) defined in Sec. 4.4.",4.3. Variational Evidence Lower Bound,[0],[0]
The first part is the expected log-likelihood of the observed system outputs y based on the observation model and the variational latent state distribution q(xt).,4.3. Variational Evidence Lower Bound,[0],[0]
This term captures the capability of the learned latent state model to explain the observed system behavior.,4.3. Variational Evidence Lower Bound,[0],[0]
The second term is a regularizer on the inducing output distribution that penalizes deviations from the GP prior.,4.3. Variational Evidence Lower Bound,[0],[0]
"Due to this term, PR-SSM automatically trades off data fit against model complexity.",4.3. Variational Evidence Lower Bound,[0],[0]
A detailed derivation of the ELBO can be found in the supplementary material.,4.3. Variational Evidence Lower Bound,[0],[0]
Training the proposed PR-SSM requires maximizing the ELBO in (15) with respect to the model parameters θPR-SSM.,4.4. Stochastic Gradient ELBO Optimization,[0],[0]
"While the second term, as KL between two Gaussian distributions, can be easily computed, the first term requires evaluation of an expectation with respect to the latent state distribution q(xt), given by
q(xt) = ∫",4.4. Stochastic Gradient ELBO Optimization,[0],[0]
t∏ τ=2,4.4. Stochastic Gradient ELBO Optimization,[0],[0]
"[p(xτ | fτ )p(fτ | x̂τ−1, z)]
q(x1)q(z)dx1:t−1df2:tdz .",4.4. Stochastic Gradient ELBO Optimization,[0],[0]
"(16)
Since the true non-linear, latent dynamics is maintained in the variational approximation (13), analytic evaluation of (16) is still intractable.",4.4. Stochastic Gradient ELBO Optimization,[0],[0]
"Because of the latent state’s Markovian structure, the marginal latent state distribution q(xt) at time t is conditionally independent of past time steps, given the previous state distribution q(xt−1) and the explicit representation of GP inducing points.",4.4. Stochastic Gradient ELBO Optimization,[0],[0]
"This enables a differentiable, sampling-based estimation of the expectation term.",4.4. Stochastic Gradient ELBO Optimization,[0],[0]
"Samples x̃t from (16) can be obtained by recursively drawing from the sparse GP posterior in (12) for t = 1, . . .",4.4. Stochastic Gradient ELBO Optimization,[0],[0]
", T .",4.4. Stochastic Gradient ELBO Optimization,[0],[0]
"Drawing samples from a Gaussian distribution can be made differentiable with respect to its parameters µd, σ2d using the re-parametrisation trick (Kingma & Welling, 2013).",4.4. Stochastic Gradient ELBO Optimization,[0],[0]
The gradient can be propagated back through time due to this re-paramatrization and unrolling of the latent state.,4.4. Stochastic Gradient ELBO Optimization,[0],[0]
"An unbiased estimator of the first term in the ELBO in (15) is given by
Eq(xt)[log(yt | xt)]",4.4. Stochastic Gradient ELBO Optimization,[0],[0]
"≈ 1
N N∑ i=1",4.4. Stochastic Gradient ELBO Optimization,[0],[0]
log p(yt | x̃(i)t ) .,4.4. Stochastic Gradient ELBO Optimization,[0],[0]
"(17)
Based on the stochastic ELBO evaluation, analytic gradients of (15) can be derived to facilitate stochastic gradientdescent-based model optimization.",4.4. Stochastic Gradient ELBO Optimization,[0],[0]
"After model optimization based on the ELBO (15), model predictions for a new input sequence u1:T and initial latent state x1 can be obtained based on the approximate, variational posterior distribution in (13).",4.5. Model Predictions,[0],[0]
"In contrast to (Mattos et al., 2015), no approximations such as moment matching are required for model predictions.",4.5. Model Predictions,[0],[0]
"Instead, the complex latent state distribution is approximated based on samples from (16).",4.5. Model Predictions,[0],[0]
The predicted observation distribution can then be computed from the latent distribution according to the observation model in (9).,4.5. Model Predictions,[0],[0]
"Instead of a fixed, uninformative initial latent state, a learned recognition model (cf. Sec. 5 for details) can be utilized to find a more informative model initialization.",4.5. Model Predictions,[0],[0]
Optimizing the ELBO (15) based on the full gradient is prohibitive for large datasets and long trajectories.,5. Extensions for Large Datasets,[0],[0]
"Instead, a stochastic optimization scheme based on mini-batches of sub-trajectories is introduced.
",5. Extensions for Large Datasets,[0],[0]
Directly optimizing the initial latent state distribution q(x1) for each sub-trajectory would lead to a full parametrization of the latent state which is undesirable as described in Sec. 4.2.,5. Extensions for Large Datasets,[0],[0]
"Instead, we propose a parametric recognition model, which initializes the latent state q(x1).",5. Extensions for Large Datasets,[0],[0]
"In recent work on SSMs (Mattos et al., 2015; Eleftheriadis et al., 2017), a recognition model is introduced to parametrize the smoothing distribution p(x1:T | y1:T ,u1:T ).",5. Extensions for Large Datasets,[0],[0]
"We propose a
similar approach, but only to model the initial latent state
q(x1) = N",5. Extensions for Large Datasets,[0],[0]
"(x1 | µ1,Σ1) ≈ q(x1 | y1:L,u1:L) , (18) µ1,Σ1 = h(y1:L,u1:L; θrecog) .",5. Extensions for Large Datasets,[0],[0]
"(19)
The initial latent state distribution is approximated by a Gaussian, where mean and variance are modeled by a recognition model h.",5. Extensions for Large Datasets,[0],[0]
"The recognition model acts as a smoother, operating on the first L elements of the system input/output data to infer the first latent state.",5. Extensions for Large Datasets,[0],[0]
"Instead of directly optimizing q(x1) during training, errors are propagated back into the recognition model h, which is parametrized by θrecog.
",5. Extensions for Large Datasets,[0],[0]
"Additionally, the proposed recognition model can also be used to predict behavior on test data, where the initial latent state is not known.",5. Extensions for Large Datasets,[0],[0]
"In the following, we present insights into the PR-SSM optimization schemes, comparisons to state-of-the-art model learning methods and a large scale experiment.",6. Experimental Evaluation,[0],[0]
"For small datasets (i.e. short training trajectory lengths), the model can be trained based on the full gradient of the ELBO in (15).",6.1. PR-SSM Learning,[0],[0]
"A comparison of the model predictions before and after training with the full ELBO gradient is shown in Fig. 2.
",6.1. PR-SSM Learning,[0],[0]
"Empirically, three major shortcomings of the full gradientbased optimization schemes are observed: (i) Computing the full gradient for long trajectories is expensive and prone
to the well-known problems of exploding and vanishing gradients (Pascanu et al., 2013).",6.1. PR-SSM Learning,[0],[0]
(ii) An uninformative initial state is prohibitive for unstable systems or systems with slowly decaying initial state transients.,6.1. PR-SSM Learning,[0],[0]
"(iii) Momentumbased optimizers (e.g. Adam) exhibit fragile optimization performance and are prone to overfitting.
",6.1. PR-SSM Learning,[0],[0]
The proposed method addresses these problems by employing the stochastic ELBO gradient based on minibatches of sub-trajectories and the initial state recognition model (cf. Sec. 5).,6.1. PR-SSM Learning,[0],[0]
"Fig. 3 visualizes the initial state distribution q(x1) and the corresponding predictive output distribution p(y1) for the fully trained model based on the full gradient (top row), as well as for the model based on the stochastic gradient and recognition model (bottom row).",6.1. PR-SSM Learning,[0],[0]
The transient dynamics and the associated model uncertainty is clearly visible for the first 15 time steps until the initial transient decays and approaches the true system behavior.,6.1. PR-SSM Learning,[0],[0]
"In contrast, the learned recognition model almost perfectly initializes the latent state, leading to much smaller deviations in the predicted observations and far less predictive uncertainty.",6.1. PR-SSM Learning,[0],[0]
"Notice how the recognition model is most certain about the distribution of the first latent state dimension (orange), which is directly coupled to the observation through the parametric observation model (cf. (9)).",6.1. PR-SSM Learning,[0],[0]
"The uncertainty for the remaining, latent states, in contrast, is slightly higher.
",6.1. PR-SSM Learning,[0],[0]
"Comparing the full ELBO gradient-based model learning and the stochastic version with the recognition model, the stochastic model learning is far more robust and counteracts the overfitting tendencies in the full gradient-based model learning.",6.1. PR-SSM Learning,[0],[0]
A comparison of the model learning progress for both methods is depicted in the supplementary material.,6.1. PR-SSM Learning,[0],[0]
"Due to the improved optimization robustness and the applicability to larger datasets, the stochastic, recognition-modelbased optimization scheme is employed for the model learning benchmark presented in the next section.",6.1. PR-SSM Learning,[0],[0]
"Empirically, the cost of the proposed sampling scheme is much lower
compared to methods employing SMC for sampling the full model posterior.",6.1. PR-SSM Learning,[0],[0]
"In the experiments, 50 latent state samples were employed (details in the supplementary material).",6.1. PR-SSM Learning,[0],[0]
"The performance of PR-SSM is assessed in comparison to state-of-the-art model learning methods on several realworld datasets as previously utilized by (Mattos et al., 2015).",6.2. Model Learning Benchmark,[0],[0]
"The suite of reference methods is composed of: One-step ahead autoregressive GP models: GP-FITC (Snelson & Ghahramani, 2006) and NIGP (McHutchon & Rasmussen, 2011).",6.2. Model Learning Benchmark,[0],[0]
"Multi-step-ahead autoregressive and recurrent GP models in latent space: REVARB based on 1, respectively 2, hidden layers (Mattos et al., 2015) and MSGP (Doerr et al., 2017a).",6.2. Model Learning Benchmark,[0],[0]
"GP-SSMs, based on a full Markovian state: SS-GP-SSM (Svensson & Schön, 2017) and the proposed PR-SSM.",6.2. Model Learning Benchmark,[0],[0]
"Currently, no published and runnable code exists for the model learning frameworks presented in (Turner et al., 2010; Frigola et al., 2013; 2014; Eleftheriadis et al., 2017).",6.2. Model Learning Benchmark,[0],[0]
"To enable a fair comparison of the methods’ performance and robustness, whitened data, a default configuration across tasks and a predefined amount of input/output data for initialization is employed.",6.2. Model Learning Benchmark,[0],[0]
"The presented results are therefore not directly comparable to previous work, where different data pre/postprocessing or method configurations are employed.",6.2. Model Learning Benchmark,[0],[0]
"A more thorough evaluation, which matches the published results from previous work, as well as experimental details are given in the supplementary material.
",6.2. Model Learning Benchmark,[0],[0]
The benchmark results are summarized in Tab. 1.,6.2. Model Learning Benchmark,[0],[0]
A detailed visualization of the resulting model predictions on the Drives dataset is shown in Fig. 4.,6.2. Model Learning Benchmark,[0],[0]
"For the one-step-ahead models (GP-NARX, NIGP), two variants are used to obtain long-term predictive distributions: Propagating the mean (no uncertainty propagation) and approximating the true posterior by a Gaussian using exact moment matching (Girard et al., 2003).",6.2. Model Learning Benchmark,[0],[0]
"The results show that PR-SSM consistently
outperforms the SS-GP-SSM learning method.",6.2. Model Learning Benchmark,[0],[0]
"Similarly, performance is improved in comparison to baseline methods (GP-NARX and NIGP).",6.2. Model Learning Benchmark,[0],[0]
"In the ensemble of models based on long-term optimized autoregressive structure (REVARB, MSGP), no method is clearly superior.",6.2. Model Learning Benchmark,[0],[0]
"However, the performance of PR-SSM is consistently strong.",6.2. Model Learning Benchmark,[0],[0]
"The probabilistic methods results are competitive or improve over the performance of deterministic RNN/LSTM models, as shown in (Mattos et al., 2015).",6.2. Model Learning Benchmark,[0],[0]
Note that PR-SSM demonstrates robust model learning performance across all datasets.,6.2. Model Learning Benchmark,[0],[0]
"To evaluate the scalability, results are provided for the forward dynamics model of the SARCOS 7 degree of freedom robotic arm.",6.3. Large Scale Experiment,[0],[0]
"The task is characterized by 60 experiments of length 337 (≈ 20.000 datapoints), 7 input, and 7 output
dimensions.",6.3. Large Scale Experiment,[0],[0]
PR-SSM is set up with a latent state dimensionality Dx = 14.,6.3. Large Scale Experiment,[0],[0]
"From the set of reference methods, only GP-NARX can be adapted to run efficiently on this dataset without major effort (details are given in the supplementary material).",6.3. Large Scale Experiment,[0],[0]
A visualization of the model predictions is shown in Fig 5 and prediction RMSEs are listed in Tab. 1.,6.3. Large Scale Experiment,[0],[0]
The results show that PR-SSM is able to learn robustly and accurately for all system outputs from all experimental data.,6.3. Large Scale Experiment,[0],[0]
"In contrast, the GP-NARX baseline achieves worse predictions and fails to predict the remaining five joints (not shown).",6.3. Large Scale Experiment,[0],[0]
"In this work, we presented Probabilistic Recurrent StateSpace Models (PR-SSM) as a novel model structure and efficient inference scheme for learning probabilistic, Markovian state-space models.",7. Conclusion,[0],[0]
"Based on GP priors and doubly stochastic variational inference, a novel model optimization criterion is derived, which is closely related to the one of powerful, but deterministic, RNNs or LSTMs.",7. Conclusion,[0],[0]
"By maintaining the true latent state distribution and thereby enabling long-term gradients, efficient inference in latent space becomes feasible.",7. Conclusion,[0],[0]
"Furthermore, a novel recognition model enables learning of unstable or slow dynamics as well as scalability to large datasets.",7. Conclusion,[0],[0]
"Robustness, scalability and high performance in model learning is demonstrated on realworld datasets in comparison to state-of-the-art methods.
",7. Conclusion,[0],[0]
A limitation of PR-SSM is its dependency on an a-priori fixed latent state dimensionality.,7. Conclusion,[0],[0]
"This shortcoming could potentially be resolved by a sparsity enforcing latent state prior, which would suppress unnecessary latent state dimensions.",7. Conclusion,[0],[0]
"This research was supported in part by National Science Foundation grants IIS-1205249, IIS-1017134, EECS0926052, the Office of Naval Research, the Okawa Foundation, the Max-Planck-Society, and the Cyber Valley initiative.",Acknowledgements,[0],[0]
State-space models (SSMs) are a highly expressive model class for learning patterns in time series data and for system identification.,abstractText,[0],[0]
"Deterministic versions of SSMs (e.g., LSTMs) proved extremely successful in modeling complex time series data.",abstractText,[0],[0]
"Fully probabilistic SSMs, however, are often found hard to train, even for smaller problems.",abstractText,[0],[0]
We propose a novel model formulation and a scalable training algorithm based on doubly stochastic variational inference and Gaussian processes.,abstractText,[0],[0]
"This combination allows efficient incorporation of latent state temporal correlations, which we found to be key to robust training.",abstractText,[0],[0]
The effectiveness of the proposed PR-SSM is evaluated on a set of real-world benchmark datasets in comparison to state-of-the-art probabilistic model learning methods.,abstractText,[0],[0]
Scalability and robustness are demonstrated on a high dimensional problem.,abstractText,[0],[0]
Probabilistic Recurrent State-Space Models,title,[0],[0]
"1 e2 ) approximation ratio for general mono-
tone submodular functions and general matroid constraints. We demonstrate the effectiveness of our approach on several real-world applications where running the maximization problem on the reduced ground set leads to two orders of magnitude speed-up while incurring almost no loss.",text,[0],[0]
"Motivated by applications in data summarization (Lin & Bilmes, 2011; Wei et al., 2013; Mirzasoleiman et al., 2016d) and recommender systems (El-Arini et al., 2009; Yue & Guestrin, 2011; Mirzasoleiman et al., 2016a), we tackle the challenge of efficiently solving many statistically related submodular maximization problems.",1. Introduction,[0],[0]
"In these applications, submodularity arises in the form of user-specific
1Yale University, New Haven, Connecticut, USA 2Google Research, New York, NY 10011, USA 3ETH Zurich, Zurich, Switzerland.",1. Introduction,[0],[0]
"Correspondence to: Amin Karbasi <amin.karbasi@yale.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
utility functions for valuating sets of items, and a prototypical problem is to find sets of say k items with nearmaximal value (Krause & Golovin, 2012; Mirzasoleiman et al., 2016b).",1. Introduction,[0],[0]
"Even though efficient greedy algorithms exist for submodular maximization, those become infeasible when serving many users and optimizing over large item collections.",1. Introduction,[0],[0]
"To this end, given training examples of (users and their utility) functions drawn from some unknown distribution, we seek to reduce the ground set to a small (ideally sublinear) size.",1. Introduction,[0],[0]
"The hope is that optimizing new functions drawn from the same distribution will incur little loss when optimized on the reduced set compared to optimizing over the full set.
",1. Introduction,[0],[0]
"Optimizing the empirical objective is an instance of twostage submodular maximization, a problem recently considered by Balkanski et al. (2016) who provide a 0.316 approximation guarantee for the case of coverage functions (more about it in the related work).",1. Introduction,[0],[0]
"One of our key technical contributions is a computationally efficient novel local-search based algorithm, called ReplacementGreedy, for two-stage submodular maximization, that provides a constant-factor 0.432 approximation guarantee for the general case of monotone submodular functions.",1. Introduction,[0],[0]
"Our approach also generalizes to arbitrary matroid constraints, and empirically compares favorably to prior work.",1. Introduction,[0],[0]
"We further analyze conditions under which our approach provably enables approximate submodular optimization based on substantially reduced ground sets, resulting the first viable approach towards sublinear-time submodular maximization.
",1. Introduction,[0],[0]
"Lastly, we demonstrate the effectiveness of our approach on recommender systems for which we compare the utility value and running time of maximizing a submodular function over the full data set and its reduced version returned by our algorithm.",1. Introduction,[0],[0]
"We consistently observe that the loss we incur is negligible (around 1%) while the speed up is enormous (about two orders of magnitude).
",1. Introduction,[0],[0]
"Related work Submodular maximization has found many applications in machine learning, ranging from feature/variable selection (Krause & Guestrin, 2005) to dictionary learning (Das & Kempe, 2011) to data summarization (Wei et al., 2014b; Lin & Bilmes, 2011; Tschiatschek et al., 2014) to recommender systems (Yue & Guestrin,
2011; El-Arini et al., 2009).",1. Introduction,[0],[0]
A seminal result of Nemhauser et al. (1978) proves that a simple greedy algorithm provides an optimal constant factor (1 − 1/e) approximation guarantee.,1. Introduction,[0],[0]
"Given the size of modern data sets, much work has focused on solving submodular maximization at scale.",1. Introduction,[0],[0]
"This work ranges from accelerating the greedy algorithm itself (Minoux, 1978; Mirzasoleiman et al., 2015; 2016a; Badanidiyuru & Jan, 2014; Buchbinder et al., 2014) to distributed (Kumar et al., 2013; Mirzasoleiman et al., 2013) and streaming (Krause & Gomes, 2010; Badanidiyuru et al., 2014) approaches, as well as algorithms based on filtering the ground set in multiple stages (Wei et al., 2014a; Feldman et al., 2017).",1. Introduction,[0],[0]
"All of these approaches aim to solve a single fixed problem instance, and have computational cost at least linear in the ground set size.",1. Introduction,[0],[0]
"In contrast, we seek to solve multiple related problems with sublinear effort.
",1. Introduction,[0],[0]
"Solving multiple submodular problems arises in online submodular optimization (Streeter & Golovin, 2008; Hazan & Kale, 2009; Jegelka & Bilmes, 2011).",1. Introduction,[0],[0]
In this setting the goal is to design algorithms that perform well in hindsight (minimize some form of regret).,1. Introduction,[0],[0]
The computational complexity of these algorithms is typically (super)-linear in the ground set size.,1. Introduction,[0],[0]
"Studying online variants of our problem is an interesting direction for future work.
",1. Introduction,[0],[0]
Closest to our work is the approach of Balkanski et al. (2016) that we build on and compare within this paper.,1. Introduction,[0],[0]
"For general submodular objectives, they propose two algorithms: one based on continuous optimization (with prohibitive computational complexity in terms of the size of the ground set n), which provides constant factor approximation guarantees only for large values of k (i.e., cardinality constraint), as well as one that has exponential complexity in terms of k. To circumvent the large computational complexity of the above algorithms, they also proposed a heuristic local search method that offers a 12 (1− 1 e ) approximation for the special case of coverage functions.",1. Introduction,[0],[0]
The query complexity of this algorithm is O(km`n2 log n) where ` is the size of the summary and m is the number of considered submodular functions in the two-stage optimization.,1. Introduction,[0],[0]
One of our key contributions is a novel and computationally efficient algorithm for the two-stage problem.,1. Introduction,[0],[0]
"More specifically, our method ReplacementGreedy provides a 12 (1 − e
−2) approximation guarantee for general monotone submodular functions subject to a general matroid constraint with only O(rm`n) query complexity (here r denotes the rank of the matroid).",1. Introduction,[0],[0]
"As argued by Balkanski et al. (2016), two-stage submodular maximization can be seen as a discrete analogue of representation learning problems like dictionary learning.",1. Introduction,[0],[0]
"It is important to note that the two-stage submodular maximization problem is fractionally subadditive (XOS) (Feige, 2009).",1. Introduction,[0],[0]
"Although it is tempting to use the XOS property of our two-
stage function especially given the positive results for social welfare XOS maximization, there are several obstacles preventing us from doing so.",1. Introduction,[0],[0]
"First, evaluating the two stage function is NP-hard, so we cannot have access to oracle value queries.",1. Introduction,[0],[0]
"Second, as shown by Singer (2010); Shahar Dobzinski & Schapira (2005); Ashwinkumar Badanidiyuru (2012), any n1/2− approximation of a XOS requires exponentially many oracle value queries.",1. Introduction,[0],[0]
Therefore the XOS property itself is not sufficient to get any positive algorithmic result for our problem.,1. Introduction,[0],[0]
"Nevertheless, we can still provide constant factor approximation with computationally efficient algorithms.
",1. Introduction,[0],[0]
"Repeatedly optimizing related classes of submodular functions is a key subroutine in many applications, such as structured prediction (Lin & Bilmes, 2012) or linear submodular bandits (Yue & Guestrin, 2011).",1. Introduction,[0],[0]
"In both of these problems, one needs to repeatedly maximize weighted combinations of submodular functions, for changing weights.",1. Introduction,[0],[0]
Our work can be viewed as providing an approach towards accelerating this central subroutine.,1. Introduction,[0],[0]
"In this paper, we consider the problem of frequently optimizing monotone submodular functions f : 2Ω → R+ that are drawn from some unknown probability distribution D. Hereby, Ω denotes the ground set of size n over which the submodular functions are defined.",2. Problem Setup,[0],[0]
W.l.o.g.,2. Problem Setup,[0],[0]
we assume that the maximum value of any function f drawn from D does not exceed 1.,2. Problem Setup,[0],[0]
"This setting arises in many applications, such as recommender systems, where the random function f = fu refers to the (predicted) valuation over sets of items for a particular user u, which may vary depending on their features (c.f., Yue & Guestrin (2011)).",2. Problem Setup,[0],[0]
"These applications typically dictate some constraints, i.e., one seeks to solve
T ∗ = arg max f(T ) s.t. T ∈",2. Problem Setup,[0],[0]
"I,
where I ⊆ 2Ω is a collection of feasible sets.",2. Problem Setup,[0],[0]
"In this paper we primarily consider cardinality constraints, i.e., I = {T ⊆ Ω :",2. Problem Setup,[0],[0]
|T | ≤ k}.,2. Problem Setup,[0],[0]
"Our results will hold also in the more general setting where I is the collection of independent sets in some matroid (Calinescu et al., 2011).",2. Problem Setup,[0],[0]
Throughout the paper r denotes the rank of the matroid.,2. Problem Setup,[0],[0]
"In the special case of cardinality constraint, the rank is r = k.
While NP-hard, good approximation algorithms are known for submodular maximization.",2. Problem Setup,[0],[0]
"For example, the classical greedy algorithm of Nemhauser et al. (1978) or its accelerated variants (Minoux, 1978; Mirzasoleiman et al., 2015; 2016a; Badanidiyuru & Jan, 2014; Buchbinder et al., 2014) provide an optimal constant factor (1−1/e) approximation for maximization under cardinality constraints.",2. Problem Setup,[0],[0]
"In modern applications, however, the system may face a large number of users, and large collections of items",2. Problem Setup,[0],[0]
Ω.,2. Problem Setup,[0],[0]
"Hence the
naive strategy of even greedily optimizing fu for each user separately may be too costly.
",2. Problem Setup,[0],[0]
"To remedy this situation, in this paper we consider the following approach:",2. Problem Setup,[0],[0]
"Given training data (i.e., a sample collection of functions f1, . . .",2. Problem Setup,[0],[0]
", fm), we invest computation once to obtain a reduced ground set S of size ` n = |Ω|.",2. Problem Setup,[0],[0]
"The hope is that optimizing new functions arising at test time will provide almost as much value when restricting the choice to items in S, than when considering arbitrary items in Ω, while being substantially more computationally efficient.
",2. Problem Setup,[0],[0]
"More formally, the expected performance when using the candidate reduced ground set S is
G(S) = Ef∼D max T∈I(S) f(T ), (1)
where we use I(S)",2. Problem Setup,[0],[0]
≡,2. Problem Setup,[0],[0]
{T ∈,2. Problem Setup,[0],[0]
I and T ⊆ S} to refer to the collection of feasible sets restricted to those containing only elements from S. The optimum achievable performance would be G(Ω).,2. Problem Setup,[0],[0]
"Our goal will be to pick a set S of small size ` to maximize G(S), or equivalently make |G(Ω)−G(S)| small.
",2. Problem Setup,[0],[0]
Special cases.,2. Problem Setup,[0],[0]
Some observations are in order.,2. Problem Setup,[0],[0]
"If D is deterministic, i.e., puts all mass on a single function f , then we simply recover classical constrained submodular maximization, since G(S) = f(S) for sets up to size k.",2. Problem Setup,[0],[0]
"If D is known to be the uniform distribution over m functions, G(S) becomes
Gm(S)",2. Problem Setup,[0],[0]
"= 1
m m∑ i=1",2. Problem Setup,[0],[0]
max T∈I(S) fi(T ).,2. Problem Setup,[0],[0]
"(2)
Gm(S) is not generally submodular, but Balkanski et al. (2016) have developed approximation algorithms for maximizing Gm under the constraint that |S| ≤",2. Problem Setup,[0],[0]
"`,1 i.e., for the problem:
Sm,` = arg max S⊂Ω,|S|≤`
1
m m∑ i=1",2. Problem Setup,[0],[0]
max T∈I(S) fi(T ).,2. Problem Setup,[0],[0]
"(3)
The general case.",2. Problem Setup,[0],[0]
"In this paper, we consider the problem of maximizing G(S) for general distributions D. I.e., we seek to solve:
S∗` = arg max S⊂Ω,|S|≤` G(S).",2. Problem Setup,[0],[0]
(4),2. Problem Setup,[0],[0]
"Since the distribution D is unknown, we cannot find S∗` or its corresponding optimum value, G(S∗` ).",3. Probabilistic Submodular Maximization,[0],[0]
"Instead, we
1Balkanski et al. (2016) only consider cardinality constraints.
",3. Probabilistic Submodular Maximization,[0],[0]
"can sample functions from D and construct the empirical average, similar to Problem (2), and try to optimize it by finding Sm,`.",3. Probabilistic Submodular Maximization,[0],[0]
"Hence, the total generalization error we incur in this process is bounded by
error = |G(Ω)−G(Sm,`)| ≤ |G(Ω)−G(S∗` )",3. Probabilistic Submodular Maximization,[0],[0]
"|
compression error + |G(S∗` )−G(Sm,`)| approximation error .(5)
",3. Probabilistic Submodular Maximization,[0],[0]
Note that once we have error ≤ for some small > 0,3. Probabilistic Submodular Maximization,[0],[0]
"then maximizing over Sm,` is almost as good as maximizing over Ω (but possibly much faster).",3. Probabilistic Submodular Maximization,[0],[0]
To that end we need to bound both compression error and approximation error.,3. Probabilistic Submodular Maximization,[0],[0]
"In fact we can prove the following result for the required number of samples to ensure small approximation error.
",3. Probabilistic Submodular Maximization,[0],[0]
Theorem 1.,3. Probabilistic Submodular Maximization,[0],[0]
"For any , δ > 0, and any set S of size at most ` we can ensure that
Pr max S⊂Ω |S|≤` |G(S)−Gm(S)| >  < δ as long as m = O((` log(n) + log(1/δ))/ 2).
",3. Probabilistic Submodular Maximization,[0],[0]
"In contrast, the compression error cannot be made arbitrarily small in general as the following example shows.
",3. Probabilistic Submodular Maximization,[0],[0]
Bad Example.,3. Probabilistic Submodular Maximization,[0],[0]
Suppose Ω =,3. Probabilistic Submodular Maximization,[0],[0]
"[n], m = n and D is the uniform distribution over the functions f1, . .",3. Probabilistic Submodular Maximization,[0],[0]
.,3. Probabilistic Submodular Maximization,[0],[0]
", fn, where fi(S) is 1 if i ∈ S, 0 otherwise.",3. Probabilistic Submodular Maximization,[0],[0]
Each fi is in fact modular.,3. Probabilistic Submodular Maximization,[0],[0]
Let k = 1.,3. Probabilistic Submodular Maximization,[0],[0]
It is easy to see that G(S) = |S|/n.,3. Probabilistic Submodular Maximization,[0],[0]
"Hence to achieve compression error less than , |S| must be greater than (1 − )",3. Probabilistic Submodular Maximization,[0],[0]
n.,3. Probabilistic Submodular Maximization,[0],[0]
"In particular for < 1/n, S must be equal to the full set.
",3. Probabilistic Submodular Maximization,[0],[0]
Sufficient conditions for sublinear `.,3. Probabilistic Submodular Maximization,[0],[0]
The above example shows that one needs additional structural assumptions.,3. Probabilistic Submodular Maximization,[0],[0]
"One simple special case arises when the union of the optimal sets for all functions in the support of D is of size ` < n, i.e.,∣∣{T ∗ :",3. Probabilistic Submodular Maximization,[0],[0]
"T ∗ = arg max
T∈I f(T ) for some f ∈ supp(D)} ∣∣ = `.",3. Probabilistic Submodular Maximization,[0],[0]
"I.e., if D is any distribution over at most m functions, clearly ` ≥ km suffices.
",3. Probabilistic Submodular Maximization,[0],[0]
"This assumption might be too strong in practice, however.",3. Probabilistic Submodular Maximization,[0],[0]
"Instead, we will consider another set of assumptions that allow bounding the compression error in the case of cardinality constraints.",3. Probabilistic Submodular Maximization,[0],[0]
"We assume Ω is endowed with a metric d. This metric is extended to sets of equal size so that for any sets T, T ′ of equal size, d(T, T ′) is the weight of a minimal matching of elements in T to elements in T ′, where the weight of (v, v′) for v ∈ T and v′ ∈ T ′ is d(v, v′).",3. Probabilistic Submodular Maximization,[0],[0]
We will assume that any function f ∼ D is L-Lipschitz continuous w.r.t.,3. Probabilistic Submodular Maximization,[0],[0]
"d, i.e., |f(T )−f(T ′)|",3. Probabilistic Submodular Maximization,[0],[0]
"≤ Ld(T, T ′) for some constant
L for all sets T and T ′ of size k. Many natural submodular functions arising in data summarization tasks satisfy this condition, such as exemplar-based clustering and certain log-determinants, see, e.g., (Mirzasoleiman et al., 2016c).
",3. Probabilistic Submodular Maximization,[0],[0]
Theorem 2.,3. Probabilistic Submodular Maximization,[0],[0]
"Suppose each function f ∼ D is L-Lipschitz continuous in (Ω, d).",3. Probabilistic Submodular Maximization,[0],[0]
"Then, for any > 0, the compression error is bounded by as long as ` ≥ kn /2kL, where nδ is the δ-covering number of (Ω, d).
",3. Probabilistic Submodular Maximization,[0],[0]
The proofs of Theorems 1 and 2 are given in the appendix.,3. Probabilistic Submodular Maximization,[0],[0]
"From the discussions in the previous section, we concluded that under appropriate statistical conditions, we can ensure that the error in Eq. 5 can be made small if we have enough samples dictated by Theorem 1.",4. Algorithm,[0],[0]
"However, our conclusion heavily relied on the fact that we can find the set Sm,` in Problem 3.",4. Algorithm,[0],[0]
"As we noted earlier, the objective function in Problem 3 is not submodular in general (Balkanski et al., 2016), thus the classical greedy algorithm may not provide any approximation guarantees.
",4. Algorithm,[0],[0]
Our proposed algorithm ReplacementGreedy works in ` rounds where in each round it tries to augment the solution in a particular greedy fashion.,4. Algorithm,[0],[0]
"It starts out with an empty set S = ∅, and checks (in each round) whether a new element can be added without violating the matroid constraint (i.e., stay an independent set) or otherwise it can be replaced with an element in the current solution while increasing the value of the objective function.",4. Algorithm,[0],[0]
To describe how these decisions are made we need a few definitions.,4. Algorithm,[0],[0]
"Let
∆i(x,A) = fi({x} ∪A)− fi(A)
denote the marginal gain of adding x to the set A if we consider function fi.",4. Algorithm,[0],[0]
"Similarly, we can define the gain of removing an element y and replacing it with x as ∇i(x, y,A) = fi({x} ∪ A \ {y})",4. Algorithm,[0],[0]
− fi(A),4. Algorithm,[0],[0]
.,4. Algorithm,[0],[0]
"Since fi is monotone we know that ∆i(x,A) ≥ 0.",4. Algorithm,[0],[0]
"However, ∇i(x, y,A) may or may not be positive.",4. Algorithm,[0],[0]
"Let us consider I(x,A) = {y ∈",4. Algorithm,[0],[0]
A : A ∪ {x} \ {y} ∈ I}.,4. Algorithm,[0],[0]
This is the set of all elements in A such that if we replace them with x we will not violate the matroid constraint.,4. Algorithm,[0],[0]
"Then, we define the replacement gain of x w.r.t.",4. Algorithm,[0],[0]
"a set A as follows:
∇i(x,A) =",4. Algorithm,[0],[0]
"{ ∆i(x,A) if A ∪ {x} ∈",4. Algorithm,[0],[0]
"I, max{0,maxy∈I(x,A)∇i(x, y,A)} o.w.
",4. Algorithm,[0],[0]
"In words,∇i(x,A) denotes how much we can increase the value of fi(A) by either inserting x into A or replacing x with one element of A while keeping A an independent set.",4. Algorithm,[0],[0]
"Finally, let Repi(x,A) be the element that should be replaced by x to maximize the gain and stay independent.
",4. Algorithm,[0],[0]
"Formally,
Repi(x,A) = { ∅ if A ∪ {x} ∈",4. Algorithm,[0],[0]
"I, arg maxy∈I(x,A)∇i(x, y,A) o.w.
",4. Algorithm,[0],[0]
With the above definitions it is easy to explain how ReplacementGreedy works.,4. Algorithm,[0],[0]
"At all times, it maintains a solution S and a collection of feasible solutions Ti ⊆ S for each function fi",4. Algorithm,[0],[0]
(all initialized to the empty set in the beginning).,4. Algorithm,[0],[0]
"In each iteration, it picks the top element x∗ from the ground set Ω, based on its total contribution to fi’s, i.e, ∑m i=1∇i(x, Ti), and updates S. Then ReplacementGreedy checks whether any of Ti’s can be augmented.",4. Algorithm,[0],[0]
This is done either by simply adding x∗ (without violating the matroid constraint) or replacing it with an element from Ti.,4. Algorithm,[0],[0]
"The condition ∇i(x∗, Ti) > 0 ensures that such replacement is executed only if the gain is positive.
",4. Algorithm,[0],[0]
Why does ReplacementGreedy work?,4. Algorithm,[0],[0]
Note that solving maxT∈I(S) fi(T ) is an NP-hard problem.,4. Algorithm,[0],[0]
"However, ReplacementGreedy finds and maintains independent sets Ti ⊆ S throughout the course of the algorithm.",4. Algorithm,[0],[0]
"In fact, the collection {S, T1, . . .",4. Algorithm,[0],[0]
", Tm} lower bounds Gm(S) by 1m ∑m i=1",4. Algorithm,[0],[0]
fi(Ti).,4. Algorithm,[0],[0]
"Moreover, each iteration increases the
aggregate value ∑m i=1",4. Algorithm,[0],[0]
"fi(Ti) by ∑m i=1∇i(x∗, Ti).",4. Algorithm,[0],[0]
"What we show in the following theorem is that after ` iterations, the accumulation of those gains reaches a constant factor approximation to the optimum value.
",4. Algorithm,[0],[0]
Theorem 3.,4. Algorithm,[0],[0]
"In only O(`mnr) function evaluations ReplacementGreedy returns a set S of size at most ` along with independent sets Ti ∈ I(S) such that
Gm(S) ≥ 1
2
( 1− 1
e2
)",4. Algorithm,[0],[0]
"Gm(S m,`).
",4. Algorithm,[0],[0]
A few comments are in order.,4. Algorithm,[0],[0]
Balkanski et al. (2016) proposed an algorithm with (1− 1/e)/2-approximation guarantee for the case where fi’s are coverage functions and the constraint is a uniform matroid.,4. Algorithm,[0],[0]
This is achieved by solving (potentially large) linear programs while maintaining O(k`mn2 log n) function evaluations.,4. Algorithm,[0],[0]
"In contrast, our result holds for any collection of monotone submodular functions and any matroid constraint.",4. Algorithm,[0],[0]
Our approximation guarantee (1 − e−2)/2 is better than (1 − 1/e)/2.,4. Algorithm,[0],[0]
"Finally, our algorithm is arguably faster in terms of both running time (as it simply runs a modified greedy method) and query complexity (as it is linear in all the parameters).",4. Algorithm,[0],[0]
"In this section, we describe our experimental setting.",5. Experiments,[0],[0]
We offer details on the datasets we used and the baselines we ran ReplacementGreedy against.,5. Experiments,[0],[0]
"We first show that ReplacementGreedy is highly efficient (i.e., high utility,
Algorithm 1 ReplacementGreedy S ← ∅, Ti ← ∅ (∀1 ≤",5. Experiments,[0],[0]
i ≤ m) for 1 ≤ j ≤,5. Experiments,[0],[0]
"` do x∗ ← arg maxx∈Ω ∑m i=1∇i(x, Ti)
S ← S ∪ {x∗} for all 1 ≤ i ≤ m do
if ∇i(x∗, Ti) > 0",5. Experiments,[0],[0]
"then Ti ← Ti ∪ {x∗}\Repi(x∗, Ti)
end if end for
end for Return sets S and T1, T2, · · · , Tm
low running time) when solving the two-stage submodular maximization problem on two concrete summarization applications: article summarization and image summarization.",5. Experiments,[0],[0]
We then demonstrate sublinear submodular maximization by showing that ReplacementGreedy can efficiently reduce the dataset while incurring minimum loss.,5. Experiments,[0],[0]
We test the performance of ReplacementGreedy on a movie dataset where movies should be recommended to users with user-specific utility functions.,5. Experiments,[0],[0]
LocalSearch.,5.1. Baselines,[0],[0]
This is the main algorithm described in Balkanski et al. (2016)2.,5.1. Baselines,[0],[0]
"In our experiments, we use = 0.2.",5.1. Baselines,[0],[0]
"We initialize S by incrementally picking ` elements such that at each step we maximize the sum of marginal gains for the m functions fi.
GreedySum.",5.1. Baselines,[0],[0]
It greedily selects ` elements while maximizing the submodular function F̂ (S) = ∑m i=1 fi(S).,5.1. Baselines,[0],[0]
"To find k elements for each fi it runs another greedy algorithm.
GreedyMerge.",5.1. Baselines,[0],[0]
"It ideally serves as an upper bound for the objective value, by greedily selecting k elements for each function fi and returning their union.",5.1. Baselines,[0],[0]
GreedyMerge can easily violate the cardinality constraint ` as its solution can have as many as mk elements.,5.1. Baselines,[0],[0]
Objective value.,5.2. Metrics,[0],[0]
"We compare algorithms’ solutions S according to the scores Gm(S) for the two-stage (empirical) problem, and G(S) for the sublinear maximization problem.
",5.2. Metrics,[0],[0]
Loss.,5.2. Metrics,[0],[0]
"For the sublinear maximization problem, we measure the relative loss in performance when using the summary, compared to the full ground set, i.e., report 1−G(S)/G(Ω).
",5.2. Metrics,[0],[0]
"2We thank the authors for providing us with their implementation.
",5.2. Metrics,[0],[0]
Running time.,5.2. Metrics,[0],[0]
We also compare the algorithms based on their wall-clock running time.,5.2. Metrics,[0],[0]
The experiments were ran in a Python 2.7 environment on a OSX 10.12.13 machine.,5.2. Metrics,[0],[0]
The processor was a 2.5 GHz Intel Core i7 with 16 GB 1600 MHz DDR3 memory.,5.2. Metrics,[0],[0]
Article summarization on Wikipedia.,5.3. Two-Stage Submodular Maximization,[0],[0]
"The aim is to select a small, highly relevant subset of wikipedia articles from a larger corpus.",5.3. Two-Stage Submodular Maximization,[0],[0]
"For this task, we reproduce the experiment from Balkanski et al. (2016) on Wikipedia articles for Machine Learning.",5.3. Two-Stage Submodular Maximization,[0],[0]
"The dataset contains n = 407 articles divided into m = 22 categories, where each category represents a subtopic from Machine Learning.",5.3. Two-Stage Submodular Maximization,[0],[0]
The relevance of a set S with respect to a category i is measured by the submodular function fi that counts the number of pages that belong to category i with a link to at least one page in S. These submodular functions are L-Lipschitz with L = 1 by considering the distance between two articles as the fraction of all pages that have a link to exactly one of these two articles.,5.3. Two-Stage Submodular Maximization,[0],[0]
Fig.,5.3. Two-Stage Submodular Maximization,[0],[0]
1a and 1b show the objective values for a fix k = 5 (and varying `) and a fixed ` = 20 (and varying k).,5.3. Two-Stage Submodular Maximization,[0],[0]
We find that ReplacementGreedy and LocalSearch perform the same while GreedySum falls off somewhat for larger values of `.,5.3. Two-Stage Submodular Maximization,[0],[0]
"However, if we look at the running times (log scale) in Fig. 1e and 1f we observe that ReplacementGreedy is considerably faster than LocalSearch and close to GreedySum.
",5.3. Two-Stage Submodular Maximization,[0],[0]
Image summarization on VOC2012.,5.3. Two-Stage Submodular Maximization,[0],[0]
"For this application we use a subset of the VOC2012 dataset (Everingham et al., 2014) where we consider n = 150 withm = 20 categories.",5.3. Two-Stage Submodular Maximization,[0],[0]
"Each category indicates a certain visual queue appearing in the image such as chair, bird, hand, etc.",5.3. Two-Stage Submodular Maximization,[0],[0]
We wish to obtain a subset of these images that are relevant to all the categories.,5.3. Two-Stage Submodular Maximization,[0],[0]
"To that end we use Exemplar Based Clustering (c.f., Mirzasoleiman et al. (2013)).",5.3. Two-Stage Submodular Maximization,[0],[0]
Let Ωi be the portion of the ground set associated to category i.,5.3. Two-Stage Submodular Maximization,[0],[0]
For any set S we also let Si = Ωi ∩ S denote its subset that is part of category i.,5.3. Two-Stage Submodular Maximization,[0],[0]
"We define fi(S) = Li({e0}) − Li(S ∪ {e0}) where Li(S) =
1 |Ωi| ∑ x∈Ωi miny∈Si d(x, y).",5.3. Two-Stage Submodular Maximization,[0],[0]
"Here, d measures
the distance between images (e.g., `2 norm), and e0 is an auxiliary element.",5.3. Two-Stage Submodular Maximization,[0],[0]
"With respect to distance d, our submodular functions are L-Lipschitz with L = 1.",5.3. Two-Stage Submodular Maximization,[0],[0]
"Also, images are represented by feature vectors obtained from categories.",5.3. Two-Stage Submodular Maximization,[0],[0]
"For example, if there were two categories a and b, and an image had features [a, a, b], its feature vector would be (2, 1).",5.3. Two-Stage Submodular Maximization,[0],[0]
Again if we look at Fig.,5.3. Two-Stage Submodular Maximization,[0],[0]
1c (for fixed k = 5 and varying `) and Fig.,5.3. Two-Stage Submodular Maximization,[0],[0]
1d (for ` = 20 and varying k) we see that ReplacementGreedy and LocalSearch achieve the same objective value.,5.3. Two-Stage Submodular Maximization,[0],[0]
"However, Fig. 1g and 1h show that LocalSearch is significantly slower than ReplacementGreedy.",5.3. Two-Stage Submodular Maximization,[0],[0]
"In this part, we experimentally show how ReplacementGreedy can reduce the size of the dataset to ` nwithout incurring too much loss in the process.",5.4. Sublinear Summarization,[0],[0]
"To do so, we consider a movie recommendation application.
",5.4. Sublinear Summarization,[0],[0]
Movie recommendation with missing ratings.,5.4. Sublinear Summarization,[0],[0]
"The dataset consists of user ratings on a scale of 1 to 5, along with some movie information.",5.4. Sublinear Summarization,[0],[0]
"There are 20 genres (Animation, Comedy, Thriller, etc) and each movie can have one or more of these genres assigned to it.",5.4. Sublinear Summarization,[0],[0]
"The goal is to find a small set S of movies with the property that each user will be able to find k enjoyable movies from S.
In our setting we consider the top 2000 highest rated movies (that were rated by at least 20 users) alongside the top 200 users ordered by number of movies they rated from this set.",5.4. Sublinear Summarization,[0],[0]
We assign a user-specific utility function fi to each user i as follows.,5.4. Sublinear Summarization,[0],[0]
Let Ai be the subset of A which user i rated.,5.4. Sublinear Summarization,[0],[0]
Let g be the number of movie genres.,5.4. Sublinear Summarization,[0],[0]
"Furthermore, we letR(i, A, j) represent the highest rating given by user i to a movie from the set A with genre j. We also define wi,j to be the proportion of movies in genre j that user i rated out of all the movie-genre ratings she provided.",5.4. Sublinear Summarization,[0],[0]
"Sowi,j will be higher for the genres that the user provided more feed-
back on, indicating that she might like these genres better.",5.4. Sublinear Summarization,[0],[0]
"Then, the valuation function by user i is as follows:
fi(A) = g∑ j=1 wi,jR(i, A, j).
",5.4. Sublinear Summarization,[0],[0]
"In words, the way a user evaluates a set A is by picking the highest rated movie from each genre (contained in A) and then take a weighted average.",5.4. Sublinear Summarization,[0],[0]
"If we define the distance between two movies to be the maximum difference of ratings they received from the same user, the submodular functions fi will be L-Lipschitz with L = 1.
",5.4. Sublinear Summarization,[0],[0]
"For the experiment, we split the users in half.",5.4. Sublinear Summarization,[0],[0]
We use the first 100 of them as a training set for the algorithms to built up their reduced ground set S of size `.,5.4. Sublinear Summarization,[0],[0]
"We then compare submodular maximization with cardinality constraint k = 3 on the reduced sets S (returned by the baselines) and that of the whole ground set Ω. To this end, we sample 20 users from the test group and compute their average values.",5.4. Sublinear Summarization,[0],[0]
"Given the size of this experiment, we were unable to run LocalSearch alongside ReplacementGreedy and GreedySum.",5.4. Sublinear Summarization,[0],[0]
"In its place, we introduce the random baseline that simply returns a set of size ` at random.",5.4. Sublinear Summarization,[0],[0]
"Fig 3a shows what fraction of the utility is preserved if we reduce the ground set by ReplacementGreedy, GreedySum,
and RandomSelection.",5.4. Sublinear Summarization,[0],[0]
"Clearly, RandomSelection performs poorly.",5.4. Sublinear Summarization,[0],[0]
"ReplacementGreedy has the highest utility, starting from 80% and practically closing the gap by reducing the ground set to only 60 movies.",5.4. Sublinear Summarization,[0],[0]
GreedySum also closely follows ReplacementGreedy.,5.4. Sublinear Summarization,[0],[0]
Fig.,5.4. Sublinear Summarization,[0],[0]
"3b, 3c, 3d show the loss versus the running time for ` = 10, ` = 30, and ` = 60.",5.4. Sublinear Summarization,[0],[0]
"Of course, if we use use the whole ground set Ω, the loss will be zero.",5.4. Sublinear Summarization,[0],[0]
This is shown by GreedyMerge.,5.4. Sublinear Summarization,[0],[0]
"However, this comes at the cost of maximizing the utility of each user on 2000 movies.",5.4. Sublinear Summarization,[0],[0]
"Instead, by using ReplacementGreedy, we see that the loss is negligible (even for ` = 30) while the running time suddenly improves by two orders of magnitude.
",5.4. Sublinear Summarization,[0],[0]
Complete matrix movie recommendation.,5.4. Sublinear Summarization,[0],[0]
"The previous experiment suffers from the potential issue that values are estimated conservatively: i.e., a user derives value only if we happen to select movies that she actually rated in the data.",5.4. Sublinear Summarization,[0],[0]
"To explore this potential bias, we repeat the same experiment, this time by first completing the matrix of (movie, rating) using standard techniques (Candés & Recht, 2008).",5.4. Sublinear Summarization,[0],[0]
We again consider 200 users and divide them into training and test sets.,5.4. Sublinear Summarization,[0],[0]
"The results are shown in Fig. 3e, 3f, 3g, 3h.",5.4. Sublinear Summarization,[0],[0]
We observe exactly the same trends.,5.4. Sublinear Summarization,[0],[0]
"Basically, a dataset with size 60 is approximately as good as a data set of size 2000 if the reduced ground set is carefully selected by ReplacementGreedy.",5.4. Sublinear Summarization,[0],[0]
"In this section, we prove that Algorithm ReplacementGreedy returns a valid solution S of at most ` elements along with independent sets Ti for all different categories
such that the aggregate value 1m ∑m i=1",6. Analysis,[0],[0]
fi(Ti) is at least 1 2 (1 − 1 e2 ),6. Analysis,[0],[0]
"> 0.43 fraction of the optimum solution’s objective value, namely Gm(Sm,`).",6. Analysis,[0],[0]
"We note that the objective value of ReplacementGreedy’s solution, Gm(S), is at least 1m ∑m i=1 fi(Ti), and therefore Algorithm ReplacementGreedy is a 12 (1 − 1 e2 )-approximation algorithm for our two stage submodular maximization problem.
",6. Analysis,[0],[0]
Proof of Theorem 3.,6. Analysis,[0],[0]
"Since Algorithm ReplacementGreedy runs in ` iterations, and adds an element to S in each iteration, the final output size, |S|, will not be more than `.",6. Analysis,[0],[0]
Each set Ti is initialized with ∅ at the beginning which is an independent set.,6. Analysis,[0],[0]
"Also whenever ReplacementGreedy adds an element x∗ to Ti, it removes Repi(x ∗, Ti).",6. Analysis,[0],[0]
"By definition, either Repi(x ∗, Ti) is equal to some element y ∈ Ti such that set {x∗}∪Ti \ {y} is an independent set or Repi(x
∗, Ti) is the empty set and {x} ∪ Ti is an independent set.",6. Analysis,[0],[0]
"In either case, set Ti after the update will remain an independent set.",6. Analysis,[0],[0]
"Therefore the output of ReplacementGreedy consists of independent sets Ti ∈ I(S) for every category i. It remains to lower bound the aggregate values of these m sets.
",6. Analysis,[0],[0]
We lower bound the aggregate increments of values incurred by adding each element we add to S in terms of the gap between the current objective value 1m ∑m i=1,6. Analysis,[0],[0]
"fi(Ti) and the optimum objective value Gm(Sm,`).",6. Analysis,[0],[0]
"This way, we can show that for each of the ` elements added to S, the current objective value is incremented enough that in total we reach at least 12 (1− 1 e2 ) fraction of the optimum value.",6. Analysis,[0],[0]
"By definition of∇ and the update operations of Algorithm ReplacementGreedy, addition of element x to S, increases the summation ∑m i=1",6. Analysis,[0],[0]
"fi(Ti) by ∑m i=1∇i(x, Ti).",6. Analysis,[0],[0]
"We also
note that the selected element x∗ maximizes this aggregate increment.",6. Analysis,[0],[0]
"We prove a lower bound benchmark according to the potential increments of values by elements in Sm,` if we add them instead of x∗.",6. Analysis,[0],[0]
"In particular, we know that:
m∑ i=1",6. Analysis,[0],[0]
"∇i(x∗, Ti) ≥",6. Analysis,[0],[0]
"1 |Sm,`| ∑ x∈Sm,` m∑ i=1 ∇i(x, Ti)
",6. Analysis,[0],[0]
"This equation holds because the rightmost side is the average increments of values of optimum elements if we add them instead of x∗, and we know that x∗ is the maximizer of the total value increments.",6. Analysis,[0],[0]
"Let Sm,`i be the independent subset of Sm,` with maximum fi value, i.e. Sm,`i = arg maxA∈I(Sm,`) fi(A).",6. Analysis,[0],[0]
"Since the ∇ values are all non-negative, we can narrow down the rightmost side of above equation, and imply that:
m∑ i=1",6. Analysis,[0],[0]
"∇i(x∗, Ti) ≥ 1 |Sm,`|",6. Analysis,[0],[0]
m∑ i=1,6. Analysis,[0],[0]
"∑ x∈Sm,`i ∇i(x, Ti) (6)
We can apply exchange properties of matroids to lower bound the total ∇ values (the rightmost side) for each category.",6. Analysis,[0],[0]
"By Corollary 39.12a of (Schrijver, 2003), we know that there exists a mapping π that maps every element of Sm,`i \Ti to either the empty set or an element of Ti \S m,` i such that:
• for every x ∈ Sm,`i",6. Analysis,[0],[0]
\,6. Analysis,[0],[0]
"Ti, the set {x} ∪ Ti \ {π(x)} is an independent set, and
• for every x1, x2 ∈",6. Analysis,[0],[0]
"Sm,`i",6. Analysis,[0],[0]
\,6. Analysis,[0],[0]
"Ti, we either have π(x1) 6= π(x2) or both of π(x1) and π(x2) are equal to the empty set.
",6. Analysis,[0],[0]
"We note that Corollary 39.12a of (Schrijver, 2003) is stated for equal size sets (e.g. |Ti| = |Sm,`i",6. Analysis,[0],[0]
|),6. Analysis,[0],[0]
"which can be easily adapted to non-equal size sets and achieve the above mapping by applying the exchange property of matroids iteratively, and making these two sets equal size.",6. Analysis,[0],[0]
"Given the mapping π, the next step is to lower bound each ∇i(x, Ti) by how much we can increase the value of Ti by replacing π(x) with x in set Ti.",6. Analysis,[0],[0]
"Since {x} ∪ Ti \ {π(x)} is an independent set, we have
∇i(x, Ti) ≥ fi({x} ∪ Ti \ {π(x)})− fi(Ti) =",6. Analysis,[0],[0]
"∆i(x, Ti)−∆i(π(x), Ti ∪ {x} \ {π(x)}) ≥ ∆i(x, Ti)−∆i(π(x), Ti \ {π(x)})
where the equality holds by definition of ∆i values, and the last inequality holds by submodularity of fi.",6. Analysis,[0],[0]
"Combining this lower bound on∇ with Equation 6 implies that in each step, adding element x∗ to set S increases the total value of the current solution by at least:
1
|Sm,`| m∑ i=1",6. Analysis,[0],[0]
∑,6. Analysis,[0],[0]
"x∈Sm,`i \Ti ∆i(x, Ti)−∆i(π(x), Ti \ {π(x)})
",6. Analysis,[0],[0]
"It is well-known (see Lemma 5 of (Bateni et al., 2010))",6. Analysis,[0],[0]
"that submodularity of fi implies ∑ x∈Sm,`i \Ti
∆i(x, Ti) ≥ fi(S m,` i )−fi(Ti).",6. Analysis,[0],[0]
"We also have ∑ x∈Sm,`i \Ti
∆i(π(x), Ti\ {π(x)}) ≤ ∑ y∈Ti ∆i(y, Ti \ {y}) because range of mapping π is a subset of Ti, and no two elements are mapped to the same y ∈ Ti.",6. Analysis,[0],[0]
"By submodularity of fi, the latter term∑ y∈Ti ∆i(y, Ti \ {y}) is upper bounded by fi(Ti).",6. Analysis,[0],[0]
"We conclude that in each step the total value is increased by at least 1`m ∑m i=1 fi(S m,` i )",6. Analysis,[0],[0]
"− 2f(Ti) (we assume |Sm,`| = ` since objective function Gm is monotone increasing).",6. Analysis,[0],[0]
"In other words, in each iteration 1 ≤ t ≤",6. Analysis,[0],[0]
"`, the increment Xt",6. Analysis,[0],[0]
"− Xt−1 is at least 1`Gm(S
m,`)",6. Analysis,[0],[0]
− 2`Xt−1 where Xt is defined to be the total value 1m ∑m i=1,6. Analysis,[0],[0]
fi(Ti),6. Analysis,[0],[0]
"at the end of iteration t. Solving this recurrence equation inductively yields Xt ≥ 12 (1 − (1 − 1 ` ) 2t)Gm(S m,`).",6. Analysis,[0],[0]
We note that X0 = 0 denotes the total value before the algorithm starts.,6. Analysis,[0],[0]
"The induction step is proved as follows:
Xt+1",6. Analysis,[0],[0]
−Xt ≥,6. Analysis,[0],[0]
"Gm(S
m,`)
` − 2Xt `
=⇒ Xt+1",6. Analysis,[0],[0]
≥,6. Analysis,[0],[0]
"Gm(S
m,`)
` + (1− 2 ` )",6. Analysis,[0],[0]
"Xt
≥ Gm(S m,`) ` + (1− 2 ` ) 1 2 (1− (1− 1 ` )2t)Gm(S m,`) ≥ 1 2 (1− (1− 1 ` )2t+2)Gm(S m,`)
At the end of Algorithm ReplacementGreedy, the total value X` is at least 12 (1 − (1 − 1 ` ) 2`)Gm(S m,`)",6. Analysis,[0],[0]
"≥ 12 (1 −
1 e2 )Gm(S m,`) which completes the proof.",6. Analysis,[0],[0]
"In this paper, we have studied the novel problem of sublinear time probabilistic submodular maximization: By investing computational effort once to reduce the ground set based on training instances, faster optimization is achieved on test instances.",7. Conclusions,[0],[0]
"Our key technical contribution is ReplacementGreedy, a novel algorithm for two-stage submodular maximization (the empirical variant of our problem).",7. Conclusions,[0],[0]
"Compared to prior approaches, ReplacementGreedy provides constant factor approximation guarantees while applying to general submodular objectives, handling arbitrary matroid constraints and scaling linearly in all relevant parameters.
Acknowledgments.",7. Conclusions,[0],[0]
"This work was supported by DARPA Young Faculty Award (D16AP00046), Simons-Berkeley fellowship, and ERC StG 307036.",7. Conclusions,[0],[0]
This work was done in part while Amin Karbasi and Andreas Krause were visiting Simons Institute for the Theory of Computing.,7. Conclusions,[0],[0]
"In this paper, we consider optimizing submodular functions that are drawn from some unknown distribution.",abstractText,[0],[0]
"This setting arises, e.g., in recommender systems, where the utility of a subset of items may depend on a user-specific submodular utility function.",abstractText,[0],[0]
"In modern applications, the ground set of items is often so large that even the widely used (lazy) greedy algorithm is not efficient enough.",abstractText,[0],[0]
"As a remedy, we introduce the problem of sublinear time probabilistic submodular maximization:",abstractText,[0],[0]
"Given training examples of functions (e.g., via user feature vectors), we seek to reduce the ground set so that optimizing new functions drawn from the same distribution will provide almost as much value when restricted to the reduced ground set as when using the full set.",abstractText,[0],[0]
We cast this problem as a two-stage submodular maximization and develop a novel efficient algorithm for this problem which offers a 1 2 (1− 1 e2 ) approximation ratio for general monotone submodular functions and general matroid constraints.,abstractText,[0],[0]
We demonstrate the effectiveness of our approach on several real-world applications where running the maximization problem on the reduced ground set leads to two orders of magnitude speed-up while incurring almost no loss.,abstractText,[0],[0]
Probabilistic Submodular Maximization in Sub-Linear Time,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1182–1192 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1109",text,[0],[0]
"Human languages exhibit a wide range of phenomena, within some limits.",1 Introduction,[0],[0]
"However, some structures seem to occur or co-occur more frequently than others.",1 Introduction,[0],[0]
"Linguistic typology attempts to describe the range of natural variation and seeks to organize and quantify linguistic universals, such as patterns of co-occurrence.",1 Introduction,[0],[0]
Perhaps one of the simplest typological questions comes from phonology: which vowels tend to occur and co-occur within the phoneme inventories of different languages?,1 Introduction,[0],[0]
"Drawing inspiration from the linguistic literature, we propose models of the probability distribution from which the attested vowel inventories have been drawn.
",1 Introduction,[0],[0]
"It is a typological universal that every language contains both vowels and consonants (Velupillai, 2012).",1 Introduction,[0],[0]
"But which vowels a language contains is guided by softer constraints, in that certain configurations are more widely attested than others.",1 Introduction,[0],[0]
"For instance, in a typical phoneme inventory, there tend to be far fewer vowels than consonants.",1 Introduction,[0],[0]
"Likewise, all languages contrast vowels based on height, although which contrast is made is language-dependent (Ladefoged and Maddieson, 1996).",1 Introduction,[0],[0]
"Moreover, while over 600 unique vowel
phonemes have been attested cross-linguistically (Moran et al., 2014), certain regions of acoustic space are used much more often than others, e.g., the regions conventionally transcribed as [a], [i], and [u].",1 Introduction,[0],[0]
Human language also seems to prefer inventories where phonologically distinct vowels are spread out in acoustic space (“dispersion”) so that they can be easily distinguished by a listener.,1 Introduction,[0],[0]
"We depict the acoustic space for English in Figure 2.
",1 Introduction,[0],[0]
"In this work, we regard the proper goal of linguistic typology as the construction of a universal prior distribution from which linguistic systems are drawn.",1 Introduction,[0],[0]
"For vowel system typology, we propose three formal probability models based on stochastic point processes.",1 Introduction,[0],[0]
We estimate the parameters of the model on one set of languages and evaluate performance on a held-out set.,1 Introduction,[0],[0]
We explore three questions: (i) How well do the properties of our proposed probability models line up experimentally with linguistic theory?,1 Introduction,[0],[0]
(ii) How well can our models predict held-out vowel systems?,1 Introduction,[0],[0]
"(iii) Do our models benefit from a “deep” transformation from formant space to metric space?
1182",1 Introduction,[0],[0]
Vowel inventories are a simple entry point into the study of linguistic typology.,2 Vowel Inventories and their Typology,[0],[0]
"Every spoken language chooses a discrete set of vowels, and the number of vowel phonemes ranges from 3 to 46, with a mean of 8.7 (Gordon, 2016).",2 Vowel Inventories and their Typology,[0],[0]
"Nevertheless, the empirical distribution over vowel inventories is remarkably peaked.",2 Vowel Inventories and their Typology,[0],[0]
"The majority of languages have 5–7 vowels, and there are only a handful of distinct 4-vowel systems attested despite many possibilities.",2 Vowel Inventories and their Typology,[0],[0]
"Reigning linguistic theory (BeckerKristal, 2010) has proposed that vowel inventories are shaped by the principles discussed below.",2 Vowel Inventories and their Typology,[0],[0]
One way to describe the sound of a vowel is through its acoustic energy at different frequencies.,2.1 Acoustic Phonetics,[0],[0]
A spectrogram (Figure 3) is a visualization of the energy at various frequencies over time.,2.1 Acoustic Phonetics,[0],[0]
Consider the “peak” frequencies F0 < F1 < F2 < . . .,2.1 Acoustic Phonetics,[0],[0]
that have a greater energy than their neighboring frequencies.,2.1 Acoustic Phonetics,[0],[0]
F0 is called the fundamental frequency or pitch.,2.1 Acoustic Phonetics,[0],[0]
"The other qualities of the vowel are largely determined by F1, F2, . .",2.1 Acoustic Phonetics,[0],[0]
"., which are known as formants (Ladefoged and Johnson, 2014).",2.1 Acoustic Phonetics,[0],[0]
"In many languages, the first two formants F1 and F2 contain enough information to identify a vowel: Figure 3 shows how these differ across three English vowels.",2.1 Acoustic Phonetics,[0],[0]
"We consider each vowel listed in the International Phonetic Alphabet (IPA) to be cross-linguistically characterized by some (F1, F2) pair.",2.1 Acoustic Phonetics,[0],[0]
"The dispersion criterion (Liljencrants and Lindblom, 1972; Lindblom, 1986) states that the phonemes of a language must be “spread out” so that they are easily discriminated by a listener.",2.2 Dispersion,[0],[0]
"A
0",2.2 Dispersion,[0],[0]
"Hz
1000 Hz
2000 Hz
3000 Hz
4000 Hz
5000 Hz /i/ /u/ /ɑ/
",2.2 Dispersion,[0],[0]
Figure 3: Example spectrogram of the three English vowels:,2.2 Dispersion,[0],[0]
"[i], [u] and [A].",2.2 Dispersion,[0],[0]
The x-axis is time and y-axis is frequency.,2.2 Dispersion,[0],[0]
The first two formants F1 and F2 are marked in with colored arrows for each vowel.,2.2 Dispersion,[0],[0]
"We used the Praat toolkit to generate the spectrogram and find the formants (Boersma et al., 2002).
language seeks phonemes that are sufficiently “distant” from one another to avoid confusion.",2.2 Dispersion,[0],[0]
Distances between phonemes are defined in some latent “metric space.”,2.2 Dispersion,[0],[0]
"We use this term rather than “perceptual space” because the confusability of two vowels may reflect not just their perceptual similarity, but also their common distortions by imprecise articulation or background noise.1",2.2 Dispersion,[0],[0]
The dispersion criterion alone does not seem to capture the whole story.,2.3 Focalization,[0],[0]
Certain vowels are simply more popular cross-linguistically.,2.3 Focalization,[0],[0]
"A commonly accepted explanation is the quantal theory of speech (Stevens, 1972, 1989).",2.3 Focalization,[0],[0]
The quantal theory states that certain sounds are easier to articulate and to perceive than others.,2.3 Focalization,[0],[0]
These vowels may be characterized as those where F1 and F2 have frequencies that are close to one another.,2.3 Focalization,[0],[0]
"On the production side, these vowels are easier to pronounce since they allow for greater articulatory imprecision.",2.3 Focalization,[0],[0]
"On the perception side, they are more salient since the two spectral peaks aggregate and act as one, larger peak to a certain degree.",2.3 Focalization,[0],[0]
"In general, languages will prefer these vowels.",2.3 Focalization,[0],[0]
The dispersion-focalization theory (DFT) combines both of the above notions.,2.4 Dispersion-Focalization Theory,[0],[0]
"A good vowel system now consists of vowels that contrast with each other and are individually desirable (Schwartz et al., 1997).",2.4 Dispersion-Focalization Theory,[0],[0]
"This paper provides the first probabilistic treatment of DFT, and new evaluation metrics for future probabilistic and non-probabilistic treatments of vowel inventory typology.
",2.4 Dispersion-Focalization Theory,[0],[0]
1We assume in this paper that the metric space is universal—although it would not be unreasonable to suppose that each language’s vowel system has adapted to avoid confusion in the specific communicative environment of its speakers.,2.4 Dispersion-Focalization Theory,[0],[0]
"Given a base set V , a point process is a distribution over its subsets.2 In this paper, we take V to be the set of all IPA symbols corresponding to vowels.",3 Point Process Models,[0],[0]
"Thus a draw from a point process is a vowel inventory V ⊆ V , and the point process itself is a distribution over such inventories.",3 Point Process Models,[0],[0]
"We will consider three basic point process models for vowel systems: the Bernoulli Point Process, the Markov Point Process and the Determinantal Point Process.",3 Point Process Models,[0],[0]
"In this section, we review the relevant theory of point processes, highlighting aspects related to §2.",3 Point Process Models,[0],[0]
"Taking V = {v1, . . .",3.1 Bernoulli Point Processes,[0],[0]
", vN}, a Bernoulli point process (BPP) makes an independent decision about whether to include each vowel in the subset.",3.1 Bernoulli Point Processes,[0],[0]
"The probability of a vowel system V ⊆ V is thus
p(V ) ∝",3.1 Bernoulli Point Processes,[0],[0]
"∏
vi∈V φ(vi), (1)
where φ is a unary potential function, i.e., φ(vi) ≥ 0.",3.1 Bernoulli Point Processes,[0],[0]
"Qualitatively, this means that φ(vi) should be large if the ith vowel is good in the sense of §2.3.",3.1 Bernoulli Point Processes,[0],[0]
Marginal inference in a BPP is computationally trivial.,3.1 Bernoulli Point Processes,[0],[0]
"The probability that the inventory V contains vi is φ(vi)/(1 + φ(vi)), independent of the other vowels in V .",3.1 Bernoulli Point Processes,[0],[0]
"Since a BPP predicts each vowel independently, it only models focalization.",3.1 Bernoulli Point Processes,[0],[0]
"Thus, the model provides an appropriate baseline that will let us measure the importance of the dispersion principle—how far can we get with just focalization?",3.1 Bernoulli Point Processes,[0],[0]
"A BPP may still tend to generate well-dispersed sets if it defines φ to be large only on certain vowels in V and these are well-dispersed (e.g., [i], [u], [a]).",3.1 Bernoulli Point Processes,[0],[0]
"More precisely, it can define φ so that φ(vi)φ(vj) is small whenever vi, vj are similar.3 But it cannot actively encourage dispersion:
2A point process is a specific kind of stochastic process, which is the technical term for a distribution over functions.",3.1 Bernoulli Point Processes,[0],[0]
"Under this view, drawing some subset of V from the point process is regarded as drawing some indicator function on V .
",3.1 Bernoulli Point Processes,[0],[0]
3We point out that such a scheme would break down if we extended our work to cover fine-grained phonetic modeling of the vowel inventory.,3.1 Bernoulli Point Processes,[0],[0]
"In that setting, we ask not just whether the inventory includes /i/ but exactly which pronunciation of /i/",3.1 Bernoulli Point Processes,[0],[0]
it contains.,3.1 Bernoulli Point Processes,[0],[0]
"In the limit, φ becomes a function over a continuous vowel space V = R2, turning the BPP into an inhomogeneous spatial Poisson process.",3.1 Bernoulli Point Processes,[0],[0]
A continuous φ function implies that the model places similar probability on similar vowels.,3.1 Bernoulli Point Processes,[0],[0]
"Then if most vowel inventories contain some version of /i/, then many of them will contain several closely related variants of /i/ (independently chosen).",3.1 Bernoulli Point Processes,[0],[0]
"By contrast, the other methods in this paper do extend nicely to fine-grained phonetic modeling.
including vi does not lower the probability of also including vj .",3.1 Bernoulli Point Processes,[0],[0]
"A Markov Point Process (MPP) (Van Lieshout, 2000)—also known as a Boltzmann machine (Ackley et al., 1985; Hinton and Sejnowski, 1986)— generalizes the BPP by adding pairwise interactions between vowels.",3.2 Markov Point Processes,[0],[0]
"The probability of a vowel system V ⊆ V is now
p(V ) ∝",3.2 Markov Point Processes,[0],[0]
"∏
vi∈V φ(vi)
∏
vi,vj∈V ψ(vi, vj), (2)
where each φ(vi) ≥ 0 is, again, a unary potential that scores the quality of the ith vowel, and each ψ(vi, vj) ≥ 0 is a binary potential that scores the combination of the ith and jth vowels.",3.2 Markov Point Processes,[0],[0]
"Roughly speaking, the potential ψ(vi, vj) should be large if the ith and jth vowel often co-occur.",3.2 Markov Point Processes,[0],[0]
"Recall that under the principle of dispersion, the vowels that often co-occur are easily distinguishable.",3.2 Markov Point Processes,[0],[0]
"Thus, confusable vowel pairs should tend to have potential ψ(vi, vj) < 1.
",3.2 Markov Point Processes,[0],[0]
"Unlike the BPP, the MPP can capture both focalization and dispersion.",3.2 Markov Point Processes,[0],[0]
"In this work, we will consider a fully connected MPP, i.e., there is a potential function for each pair of vowels in V .",3.2 Markov Point Processes,[0],[0]
"MPPs closely resemble Ising models (Ising, 1925), but with the difference that Ising models are typically lattice-structured, rather than fully connected.
",3.2 Markov Point Processes,[0],[0]
Inference in MPPs.,3.2 Markov Point Processes,[0],[0]
"Inference in fully connected MPPs, just as in general Markov Random Fields (MRFs), is intractable (Cooper, 1990) and we must rely on approximation.",3.2 Markov Point Processes,[0],[0]
"In this work, we estimate any needed properties of the MPP distribution by (approximately) drawing vowel inventories from it via Gibbs sampling (Geman and Geman, 1984; Robert and Casella, 2005).",3.2 Markov Point Processes,[0],[0]
Gibbs sampling simulates a discrete-time Markov chain whose stationary distribution is the desired MPP distribution.,3.2 Markov Point Processes,[0],[0]
"At each time step, for some random vi ∈ V , it stochastically decides whether to replace the current inventory V with V̄ , where V̄ is a copy of V with vi added (if vi /∈ V ) or removed (if vi ∈ V ).",3.2 Markov Point Processes,[0],[0]
"The probability of replacement is p(V̄ )
p(V )+p(V̄ ) .",3.2 Markov Point Processes,[0],[0]
"A determinantal point process (DPP) (Macchi, 1975) provides an elegant alternative to an MPP, and one that is directly suited to modeling both focalization and dispersion.",3.3 Determinantal Point Processes,[0],[0]
"Inference requires only
a few matrix computations and runs tractably in O(|V|3) time, even though the model may encode a rich set of multi-way interactions.",3.3 Determinantal Point Processes,[0],[0]
"We focus on the L-ensemble parameterization of the DPP, due to Borodin and Rains (2005).4 This type of DPP defines the probability of an inventory V ⊆ V as
p(V ) ∝",3.3 Determinantal Point Processes,[0],[0]
"detLV , (3)
where",3.3 Determinantal Point Processes,[0],[0]
"L ∈ RN×N (for N = |V|) is a symmetric positive semidefinite matrix, and LV refers to the submatrix of L with only those rows and columns corresponding to those elements in the subset V .
",3.3 Determinantal Point Processes,[0],[0]
"Although MAP inference remains NP-hard in DPPs (just as in MPPs), marginal inference becomes tractable.",3.3 Determinantal Point Processes,[0],[0]
"We may compute the normalizing constant in closed form as follows:
∑
V ∈2V detLV = det",3.3 Determinantal Point Processes,[0],[0]
(L+ I) .,3.3 Determinantal Point Processes,[0],[0]
"(4)
How does a DPP ensure focalization and dispersion?",3.3 Determinantal Point Processes,[0],[0]
L is positive semidefinite iff it can be written as E>E for some matrix E ∈ RN×N .,3.3 Determinantal Point Processes,[0],[0]
"It is possible to express p(V ) in terms of the column vectors of E, which we call e1, . . .",3.3 Determinantal Point Processes,[0],[0]
", eN :
• For inventories of size 2, p({vi, vj}) ∝",3.3 Determinantal Point Processes,[0],[0]
"(φ(vi)φ(vj) sin θ)
2, where φ(vi), φ(vj) represent the quality of vowels vi, vj (as in the BPP) while sin θ ∈",3.3 Determinantal Point Processes,[0],[0]
"[0, 1] represents their dissimilarity.",3.3 Determinantal Point Processes,[0],[0]
"More precisely, φ(vi), φ(vj) are the lengths of vectors ei, ej while θ is the angle between them.",3.3 Determinantal Point Processes,[0],[0]
"Thus, we should choose the columns of E so that focal vowels get long vectors and similar vowels get vectors of similar direction.",3.3 Determinantal Point Processes,[0],[0]
•,3.3 Determinantal Point Processes,[0],[0]
"Generalizing beyond inventories of size 2, p(V ) is proportional to the square of the volume of the parallelepiped whose sides are given by {ei : vi ∈ V }.",3.3 Determinantal Point Processes,[0],[0]
"This volume can be regarded as
∏ vi∈V φ(vi) times a term that
ranges from 1 for an orthogonal set of vowels to 0 for a linearly dependent set of vowels.",3.3 Determinantal Point Processes,[0],[0]
•,3.3 Determinantal Point Processes,[0],[0]
"The events vi ∈ V and vj ∈ V are anti-
correlated (when not independent).",3.3 Determinantal Point Processes,[0],[0]
"That is, while both vowels may individually have high probabilities (focalization), having either one in the inventory lowers the probability of the other (dispersion).
",3.3 Determinantal Point Processes,[0],[0]
"4Most DPPs are L-ensembles (Kulesza and Taskar, 2012).",3.3 Determinantal Point Processes,[0],[0]
At this point it is helpful to introduce the empirical dataset we will model.,4 Dataset,[0],[0]
"For each of 223 languages,5 Becker-Kristal (2010) provides the vowel inventory as a set of IPA symbols, listing the first 5 formants for each vowel (or fewer when not available in the original source).",4 Dataset,[0],[0]
"Some corpus statistics are shown in Figs. 4 and 5.6 For the present paper, we take V to be the set of all 53 IPA symbols that appear in the corpus.",4 Dataset,[0],[0]
"We treat these IPA labels as meaningful, in that we consider two vowels in different languages to be the same vowel in V if (for example)",4 Dataset,[0],[0]
they are both annotated as [O].,4 Dataset,[0],[0]
"We characterize that vowel by its average formant vector across all languages in the corpus that contain the vowel: e.g., (F1, F2, . . .)",4 Dataset,[0],[0]
"= (500, 700, . . .)",4 Dataset,[0],[0]
for [O].,4 Dataset,[0],[0]
"In future work, we plan to relax this idealization (see footnote 3), allowing us to investigate natural questions such as whether [u] is pronounced higher (smaller F1) in languages that also contain [o] (to achieve better dispersion).",4 Dataset,[0],[0]
"The BPP, MPP, and DPP models (§3) require us to specify parameters for each vowel in V .",5 Model Parameterization,[0],[0]
"In §5.1, we will accomplish this by deriving the parameters for each vowel vi from a possibly high-dimensional embedding of that vowel, e(vi) ∈",5 Model Parameterization,[0],[0]
"Rr.
",5 Model Parameterization,[0],[0]
"In §5.2, e(vi) ∈",5 Model Parameterization,[0],[0]
"Rr will in turn be defined as some learned function of f(vi) ∈ Rk, where f : V 7→ Rk is the function that maps a vowel to a k-vector of its measurable acoustic properties.",5 Model Parameterization,[0],[0]
"This approach allows us to determine reasonable parameters even for rare vowels, based on their measurable properties.",5 Model Parameterization,[0],[0]
"It will even enable us in
5Becker-Kristal lists some languages multiple times with different measurements.",5 Model Parameterization,[0],[0]
"When a language had multiple listings, we selected one randomly for our experiments.
",5 Model Parameterization,[0],[0]
6Caveat:,5 Model Parameterization,[0],[0]
The corpus is a curation of information from various phonetics papers into a common electronic format.,5 Model Parameterization,[0],[0]
"No standard procedure was followed across all languages: it was up to individual phoneticists to determine the size of each vowel inventory, the choice of IPA symbols to describe it, and the procedure for measuring the formants.",5 Model Parameterization,[0],[0]
"Moreover, it is an idealization to provide a single vector of formants for each vowel type in the language.",5 Model Parameterization,[0],[0]
"In real speech, different tokens of the same vowel are pronounced differently, because of coarticulation with the vowel context, allophony, interspeaker variation, and stochastic intraspeaker variation.",5 Model Parameterization,[0],[0]
"Even within a token, the formants change during the duration of the vowel.",5 Model Parameterization,[0],[0]
"Thus, one might do better to represent a vowel’s pronunciation not by a formant vector, but by a conditional probability distribution over its formant trajectories given its context, or by a parameter vector that characterizes such a conditional distribution.",5 Model Parameterization,[0],[0]
"This setting would require richer data than we present here.
future to generalize to vowels that were unseen in the training set, letting us scale to very large or infinite V (footnote 3).",5 Model Parameterization,[0],[0]
"We consider deep versions of all three processes.
",5.1 Deep Point Processes,[0],[0]
Deep Bernoulli Point Process.,5.1 Deep Point Processes,[0],[0]
"We define
φ(vi) =",5.1 Deep Point Processes,[0],[0]
||e(vi)|| ≥ 0,5.1 Deep Point Processes,[0],[0]
(5) Deep Markov Point Process.,5.1 Deep Point Processes,[0],[0]
"The MPP employs the same unary potential as the BPP, as well as the binary potential
ψ(vi, vj) = exp− 1
T · ||e(vi)−e(vj)||2 < 1 (6)
where the learned temperature T > 0 controls the relative strength of the unary and binary potentials.
",5.1 Deep Point Processes,[0],[0]
This formula is inspired by Coulomb’s law for describing the repulsion of static electrically charged particles.,5.1 Deep Point Processes,[0],[0]
"Just as the repulsive force between two particles approaches∞ as they approach each other, the probability of finding two vowels in the same inventory approaches exp−∞",5.1 Deep Point Processes,[0],[0]
= 0,5.1 Deep Point Processes,[0],[0]
as they approach each other.,5.1 Deep Point Processes,[0],[0]
"The formula is also reminiscent of Shepard (1987)’s “universal law of generalization,” which says here that the probability of responding to vi as if it were vj should fall off exponentially with their distance in some “psychological space” (here, embedding space).
",5.1 Deep Point Processes,[0],[0]
Deep Determinantal Point Process.,5.1 Deep Point Processes,[0],[0]
"For the DPP, we simply define the vector ei to be e(vi), and proceed as before.
",5.1 Deep Point Processes,[0],[0]
Summary.,5.1 Deep Point Processes,[0],[0]
"In the deep BPP, the probability of a set of vowels is proportional to the product of the lengths of their embedding vectors.",5.1 Deep Point Processes,[0],[0]
"The deep MPP modifies this by multiplying in pairwise repulsion terms in (0, 1) that increase as the vectors’ endpoints move apart in Euclidean space (or as T → ∞).",5.1 Deep Point Processes,[0],[0]
"The deep DPP instead modifies it by multiplying in a single setwise repulsion term in (0, 1) that increases as the embedding vectors become more mutually orthogonal.",5.1 Deep Point Processes,[0],[0]
"In the limit, then, the MPP and DPP both approach the BPP.",5.1 Deep Point Processes,[0],[0]
"Throughout this work, we simply have f extract the first k = 2 formants, since our dataset does not provide higher formants for all languages.7 For
7In lieu of higher formants, we could have extended the vector f(vi) to encode the binary distinctive features of the IPA vowel vi: round, tense, long, nasal, creaky, etc.
example, we have f([O]) =",5.2 Embeddings,[0],[0]
"(500, 700).",5.2 Embeddings,[0],[0]
We now describe three possible methods for mapping f(vi) to an embedding e(vi).,5.2 Embeddings,[0],[0]
"Each of these maps has learnable parameters.
",5.2 Embeddings,[0],[0]
Neural Embedding.,5.2 Embeddings,[0],[0]
We first consider directly embedding each vowel vi into a vector space Rr.,5.2 Embeddings,[0],[0]
"We achieve this through a feed-forward neural net
e(vi) = W1 tanh (W0f(vi) + b0) +",5.2 Embeddings,[0],[0]
"b1, (7)
Equation (7) gives an architecture with 1 layer of nonlinearity; in general we consider stacking d ≥ 0 layers.",5.2 Embeddings,[0],[0]
"Here W0 ∈ Rr×k,W1 ∈ Rr×r, . .",5.2 Embeddings,[0],[0]
.Wd,5.2 Embeddings,[0],[0]
∈,5.2 Embeddings,[0],[0]
"Rr×r are weight matrices, b0, . .",5.2 Embeddings,[0],[0]
.bd,5.2 Embeddings,[0],[0]
∈,5.2 Embeddings,[0],[0]
"Rr are bias vectors, and tanh could be replaced by any pointwise nonlinearity.",5.2 Embeddings,[0],[0]
"We treat both the depth d and the embedding size r as hyperparameters, and select the optimal values on a development set.
",5.2 Embeddings,[0],[0]
Interpretable Neural Embedding.,5.2 Embeddings,[0],[0]
We are interested in the special case of neural embeddings when r = k since then (for any d) the mapping f(vi) 7→ e(vi) is a diffeomorphism:8 a smooth invertible function of Rk.,5.2 Embeddings,[0],[0]
"An example of such a diffeomorphism is shown in Figure 1.
",5.2 Embeddings,[0],[0]
There is a long history in cognitive psychology of mapping stimuli into some psychological space.,5.2 Embeddings,[0],[0]
"The distances in this psychological space may be predictive of generalization (Shepard, 1987) or of perception.",5.2 Embeddings,[0],[0]
"Due to the anatomy of the ear, the mapping of vowels from acoustic space to perceptual space is often presumed to be nonlinear (Rosner and Pickering, 1994; Nearey and Kiefte, 2003), and there are many perceptually-oriented phonetic scales, e.g., Bark and Mel, that carry out such nonlinear transformations while preserving the dimensionality k, as we do here.",5.2 Embeddings,[0],[0]
"As discussed in §2.2, vowel system typology is similarly believed to be influenced by distances between the vowels in a latent metric space.",5.2 Embeddings,[0],[0]
"We are interested in whether a constrained k-dimensional model of these distances can do well in our experiments.
",5.2 Embeddings,[0],[0]
Prototype-Based Embedding.,5.2 Embeddings,[0],[0]
"Unfortunately, our interpretable neural embedding is unfortunately incompatible with the DPP.",5.2 Embeddings,[0],[0]
The DPP assigns probability 0 to any vowel inventory V whose e vectors are linearly dependent.,5.2 Embeddings,[0],[0]
"If the vectors are in Rk, then this means that p(V )",5.2 Embeddings,[0],[0]
= 0,5.2 Embeddings,[0],[0]
whenever |V,5.2 Embeddings,[0],[0]
| > k.,5.2 Embeddings,[0],[0]
"In our setting, this would limit vowel inventories to size 2.
",5.2 Embeddings,[0],[0]
"8Provided that our nonlinearity in (7) is a differentiable invertible function like tanh rather than relu.
",5.2 Embeddings,[0],[0]
"Our solution to this problem is to still construct our interpretable metric space Rk, but then map that nonlinearly to Rr for some large r.",5.2 Embeddings,[0],[0]
This latter map is constrained.,5.2 Embeddings,[0],[0]
"Specifically, we choose “prototype” points µ1, . . .",5.2 Embeddings,[0],[0]
",µr ∈ Rk.",5.2 Embeddings,[0],[0]
These prototype points are parameters of the model: their coordinates are learned and do not necessarily correspond to any actual vowel.,5.2 Embeddings,[0],[0]
We then construct e(vi) ∈,5.2 Embeddings,[0],[0]
Rr as a “response vector” of similarities of our vowel vi to these prototypes.,5.2 Embeddings,[0],[0]
"Crucially, the responses depend on distances measured in the interpretable metric space Rk.",5.2 Embeddings,[0],[0]
"We use a Gaussian-density response function, where x(vi) denotes the representation of our vowel vi in the interpretable space:
e(vi)` = w` p(x(vi);µ`, σ 2I) (8)
= w` (2πσ 2)−( k 2 ) exp (−||x− µ`||2 2σ2 ) .
for ` = 1, 2, . . .",5.2 Embeddings,[0],[0]
", r. We additionally impose the constraints that each w` ≥ 0 and ∑r `=1w` = 1.
",5.2 Embeddings,[0],[0]
"Notice that the sum ∑r
`=1 e(vi) may be viewed as the density at x(vi) under a Gaussian mixture model.",5.2 Embeddings,[0],[0]
"We use this fact to construct a prototypebased MPP as well: we redefine φ(vi) to equal this positive density, while still defining ψ via equation (6).",5.2 Embeddings,[0],[0]
"The idea is that dispersion is measured in the interpretable space Rk, and focalization is defined by certain “good” regions in that space that are centered at the r prototypes.",5.2 Embeddings,[0],[0]
"Fundamentally, we are interested in whether our model has abstracted the core principles of what makes a good vowel system.",6 Evaluation Metrics,[0],[0]
Our choice of a probabilistic model provides a natural test: how surprised is our model by held-out languages?,6 Evaluation Metrics,[0],[0]
"In other words, how likely does our model think unobserved, but attested vowel systems are?",6 Evaluation Metrics,[0],[0]
"While this is a natural evaluation paradigm in NLP, it has not—to the best of our knowledge—been applied to a quantitative investigation of linguistic typology.
",6 Evaluation Metrics,[0],[0]
"As a second evaluation, we introduce a vowel system cloze task that could also be used to evaluate non-probabilistic models.",6 Evaluation Metrics,[0],[0]
"This task is defined by analogy to the traditional semantic cloze task (Taylor, 1953), where the reader is asked to fill in a missing word in the sentence from the context.",6 Evaluation Metrics,[0],[0]
"In our vowel system cloze task, we present a learner with a subset of the vowels in a held-out vowel system and ask them to predict the remaining vowels.",6 Evaluation Metrics,[0],[0]
"Consider, as a concrete example, the
general American English vowel system (excluding long vowels) {",6 Evaluation Metrics,[0],[0]
"[i], [I], [u], [U], [E], [æ], [O], [A], [@]}.",6 Evaluation Metrics,[0],[0]
"One potential cloze task would be to predict {[i],",6 Evaluation Metrics,[0],[0]
"[u]} given {[I], [U], [E], [æ], [O], [A], [@]} and the fact that two vowels are missing from the inventory.",6 Evaluation Metrics,[0],[0]
"Within the cloze task, we report accuracy, i.e., did we guess the missing vowel right?",6 Evaluation Metrics,[0],[0]
We consider three versions of the cloze tasks.,6 Evaluation Metrics,[0],[0]
"First, we predict one missing vowel in a setting where exactly one vowel was deleted.",6 Evaluation Metrics,[0],[0]
"Second, we predict up to one missing vowel where a vowel may have been deleted.",6 Evaluation Metrics,[0],[0]
"Third, we predict up to two missing vowels, where one or two vowels may be deleted.",6 Evaluation Metrics,[0],[0]
We evaluate our models using 10-fold crossvalidation over the 223 languages.,7 Experiments,[0],[0]
We report the mean performance over the 10 folds.,7 Experiments,[0],[0]
"The performance on each fold (“test”) was obtained by training many models on 8 of the other 9 folds (“train”), selecting the model that obtained the best task-specific performance on the remaining fold (“development”), and assessing it on the test fold.",7 Experiments,[0],[0]
"Minimization of the parameters is performed with the L-BFGS algorithm (Liu and Nocedal, 1989).",7 Experiments,[0],[0]
"As a preprocessing step, the first two formants values F1 and F2 are centered around zero and scaled down by a factor of 1000 since the formant values themselves may be quite large.
",7 Experiments,[0],[0]
"Specifically, we use the development fold to select among the following combinations of hyperparameters.",7 Experiments,[0],[0]
"For neural embeddings, we tried r ∈ {2, 10, 50, 100, 150, 200}.",7 Experiments,[0],[0]
"For prototype embeddings, we took the number of components r ∈ {20, 30, 40, 50}.",7 Experiments,[0],[0]
"We tried network depths d ∈ {0, 1, 2, 3}.",7 Experiments,[0],[0]
We sweep the coefficient for an L2 regularizer on the neural network parameters.,7 Experiments,[0],[0]
Figure 1 visualizes the diffeomorphism from formant space to metric space for one of our DPP models (depth d = 3 with r = 20 prototypes).,7.1 Results and Discussion,[0],[0]
"Similar figures can be generated for all of the interpretable models.
",7.1 Results and Discussion,[0],[0]
"We report results for cross-entropy and the cloze evaluation in Table 1.9 Under both metrics, we see that the DPP is slightly better than the MPP; both are better than the BPP.",7.1 Results and Discussion,[0],[0]
"This ranking holds for
9Computing cross-entropy exactly is intractable with the MPP, so we resort to an unbiased importance sampling scheme where we draw samples from the BPP and reweight according to the MPP (Liu et al., 2015).
",7.1 Results and Discussion,[0],[0]
each of the 3 embedding schemes.,7.1 Results and Discussion,[0],[0]
"The embedding schemes themselves are compared in the caption.
",7.1 Results and Discussion,[0],[0]
"Within each embedding scheme, the BPP performs several points worse on the cloze tasks, confirming that dispersion is needed to model vowel inventories well.",7.1 Results and Discussion,[0],[0]
"Still, the BPP’s respectable performance shows that much of the structure can be capture by focalization.",7.1 Results and Discussion,[0],[0]
"As §3 noted, the BPP may generate well-dispersed sets, as the common vowels tend to be dispersed already (see Figure 4).",7.1 Results and Discussion,[0],[0]
"In this capacity, however, the BPP is not explanatory as it cannot actually tell us why these vowels should be frequent.
",7.1 Results and Discussion,[0],[0]
"We mention that depth in the neural network is helpful, with deeper embedding networks performing slightly better than depth d = 0.
",7.1 Results and Discussion,[0],[0]
"Finally, we identified each model’s favorite complete vowel system of size n",7.1 Results and Discussion,[0],[0]
(Table 2).,7.1 Results and Discussion,[0],[0]
"For the BPP, this is simply the n most probable vowels.",7.1 Results and Discussion,[0],[0]
"Decoding the DPP and MPP is NP-hard, but we found the best system by brute force (for small n).",7.1 Results and Discussion,[0],[0]
The dispersion in these models predicts different systems than the BPP.,7.1 Results and Discussion,[0],[0]
Typology as Density Estimation?,8 Discussion: Probabilistic Typology,[0],[0]
Our goal is to define a universal distribution over all possible vowel inventories.,8 Discussion: Probabilistic Typology,[0],[0]
Is this appropriate?,8 Discussion: Probabilistic Typology,[0],[0]
"We regard this as a natural approach to typology, because it directly describes which kinds of linguistic systems are more or less common.",8 Discussion: Probabilistic Typology,[0],[0]
"Traditional implicational universals (“all languages with vi have vj”) are softened, in our approach, into conditional probabilities such as “p(vj ∈ V | vi ∈ V )",8 Discussion: Probabilistic Typology,[0],[0]
≈ 0.9.”,8 Discussion: Probabilistic Typology,[0],[0]
"Here the 0.9 is not merely an empirical ratio, but a smoothed
probability derived from the complete estimated distribution.",8 Discussion: Probabilistic Typology,[0],[0]
"It is meant to make predictions about unseen languages.
",8 Discussion: Probabilistic Typology,[0],[0]
Whether human language learners exploit any properties of this distribution10 is a separate question that goes beyond typology.,8 Discussion: Probabilistic Typology,[0],[0]
"Jakobson (1941) did find that children acquired phoneme inventories in an order that reflected principles similar to dispersion (“maximum contrast”) and focalization.
",8 Discussion: Probabilistic Typology,[0],[0]
"At any rate, we estimate the distribution given some set of attested systems that are assumed to have been drawn IID from it.",8 Discussion: Probabilistic Typology,[0],[0]
"One might object that this IID assumption ignores evolutionary relationships among the attested systems, causing our estimated distribution to favor systems that are coincidentally frequent among current human languages, rather than being natural in some timeless sense.",8 Discussion: Probabilistic Typology,[0],[0]
"We reply that our approach is then appropriate when the goal of typology is to estimate the distribution of actual human languages—a distribution that can be utilized in principle (and also in practice, as we show) to predict properties of actual languages from outside the training set.
",8 Discussion: Probabilistic Typology,[0],[0]
A different possible goal of typology is a theory of natural human languages.,8 Discussion: Probabilistic Typology,[0],[0]
This goal would require a more complex approach.,8 Discussion: Probabilistic Typology,[0],[0]
"One should not imagine that natural languages are drawn in a vacuum from some single, stationary distribution.",8 Discussion: Probabilistic Typology,[0],[0]
"Rather, each language is drawn conditionally on its parent language.",8 Discussion: Probabilistic Typology,[0],[0]
"Thus, one should estimate a stochastic model of the evolution of linguistic systems through time, and identify “naturalness” with
10This could happen because learners have evolved to expect the languages (the Baldwin effect), or because the languages have evolved to be easily learned (universal grammar).
",8 Discussion: Probabilistic Typology,[0],[0]
"the directions in which this system tends to evolve.
",8 Discussion: Probabilistic Typology,[0],[0]
Energy Minimization Approaches.,8 Discussion: Probabilistic Typology,[0],[0]
"The traditional energy-based approach (Liljencrants and Lindblom, 1972) to vowel simulation minimizes the following objective (written in our notation):
E(m) = ∑
1≤i<j≤m
1
||e(vi)− e(vj)||2 , (9)
where the vectors e(vi) ∈",8 Discussion: Probabilistic Typology,[0],[0]
"Rr are not spit out of a deep network, as in our case, but rather directly optimized.",8 Discussion: Probabilistic Typology,[0],[0]
Liljencrants and Lindblom (1972) propose a coordinate descent algorithm to optimize E(m).,8 Discussion: Probabilistic Typology,[0],[0]
"While this is not in itself a probabilistic model, they generate diverse vowel systems through random restarts that find different local optima (a kind of deterministic evolutionary mechanism).",8 Discussion: Probabilistic Typology,[0],[0]
"We note that equation (9) assumes that the number of vowels m is given, and only encodes a notion of dispersion.",8 Discussion: Probabilistic Typology,[0],[0]
"Roark (2001) subsequently extended equation (9) to include the notion of focalization.
Vowel Inventory Size.",8 Discussion: Probabilistic Typology,[0],[0]
A fatal flaw of the traditional energy minimization paradigm is that it has no clear way to compare vowel inventories of different sizes.,8 Discussion: Probabilistic Typology,[0],[0]
"The problem is quite crippling since, in general, inventories with fewer vowels will have lower energy.",8 Discussion: Probabilistic Typology,[0],[0]
This does not match reality—the empirical distribution over inventory sizes (shown in Figure 5) shows that the mode is actually 5 and small inventories are uncommon: no 1-vowel inventory is attested and only one 2-vowel inventory is known.,8 Discussion: Probabilistic Typology,[0],[0]
A probabilistic model over all vowel systems must implicitly model the size of the system.,8 Discussion: Probabilistic Typology,[0],[0]
"Indeed, our models pit all potential inventories against each other, bestowing the extra burden to match the empirical distribution over size.
Frequency of Inventories.",8 Discussion: Probabilistic Typology,[0],[0]
Another problem is the inability to model frequency.,8 Discussion: Probabilistic Typology,[0],[0]
"While for inventories of a modest size (3-5 vowels) there are very few unique attested systems, there is a plethora of
attested larger vowel systems.",8 Discussion: Probabilistic Typology,[0],[0]
The energy minimization paradigm has no principled manner to tell the scientist how likely a novel system may be.,8 Discussion: Probabilistic Typology,[0],[0]
"Appealing again to the empirical distribution over attested vowel systems, we consider the relative diversity of systems of each size.",8 Discussion: Probabilistic Typology,[0],[0]
We graph this in Figure 5.,8 Discussion: Probabilistic Typology,[0],[0]
Consider all vowel systems of size 7.,8 Discussion: Probabilistic Typology,[0],[0]
"There are (|V| 7 ) potential inventories, yet the empirical distribution is remarkably peaked.",8 Discussion: Probabilistic Typology,[0],[0]
"Our probabilistic models have the advantage in this context as well, as they naturally quantify the likelihood of an individual inventory.
",8 Discussion: Probabilistic Typology,[0],[0]
Typology is a Small-Data Problem.,8 Discussion: Probabilistic Typology,[0],[0]
"In contrast to many common problems in applied NLP, e.g., part-of-speech tagging, parsing and machine translation, the modeling of linguistic typology is fundamentally a “small-data” problem.",8 Discussion: Probabilistic Typology,[0],[0]
"Out of the 7105 languages on earth, we only have linguistic annotation for 2600 of them (Comrie et al., 2013).",8 Discussion: Probabilistic Typology,[0],[0]
"Moreover, we only have phonetic and phonological annotation for a much smaller set of languages— between 300-500 (Maddieson, 2013).",8 Discussion: Probabilistic Typology,[0],[0]
"Given the paucity of data, overfitting on only those attested languages is a dangerous possibility—just because a certain inventory has never been attested, it is probably wrong to conclude that it is impossible— or even improbable—on that basis alone.",8 Discussion: Probabilistic Typology,[0],[0]
"By analogy to language modeling, almost all sentences observed in practice are novel with respect to the training data, but we still must employ a principled manner to discriminate high-probability sentences (which are syntactically and semantically coherent) from low-probability ones.",8 Discussion: Probabilistic Typology,[0],[0]
"Probabilistic modeling provides a natural paradigm for this sort of investigation—machine learning has developed well-understood smoothing techniques, e.g., regularization with tuning on a held-out dev set, to avoid overfitting in a small-data scenario.
",8 Discussion: Probabilistic Typology,[0],[0]
Related Work in NLP.,8 Discussion: Probabilistic Typology,[0],[0]
"Various point processes have been previously applied to potpourri of tasks
in NLP.",8 Discussion: Probabilistic Typology,[0],[0]
Determinantal point processes have found a home in the literature in tasks that require diversity.,8 Discussion: Probabilistic Typology,[0],[0]
"E.g., DPPs have achieved state-of-the-art results on multi-document document summarization (Kulesza and Taskar, 2011), news article selection (Affandi et al., 2012) recommender systems (Gartrell et al., 2017), joint clustering of verbal lexical semantic properties (Reichart and Korhonen, 2013), inter alia.",8 Discussion: Probabilistic Typology,[0],[0]
"Poisson point processes have also been applied to NLP problems: Yee et al. (2015) model the emerging topic on social media using a homogeneous point process and Lukasik et al. (2015) apply a log-Gaussian point process, a variant of the Poisson point process, to rumor detection in Twitter.",8 Discussion: Probabilistic Typology,[0],[0]
"We are unaware of previous attempts to probabilistically model vowel inventory typology.
",8 Discussion: Probabilistic Typology,[0],[0]
Future Work.,8 Discussion: Probabilistic Typology,[0],[0]
This work lends itself to several technical extensions.,8 Discussion: Probabilistic Typology,[0],[0]
"One could expand the function f to more completely characterize each vowel’s acoustic properties, perceptual properties, or distinctive features (footnote 7).",8 Discussion: Probabilistic Typology,[0],[0]
One could generalize our point process models to sample finite subsets from the continuous space of vowels (footnote 3).,8 Discussion: Probabilistic Typology,[0],[0]
One could consider augmenting the MPP with a new factor that explicitly controls the size of the vowel inventory.,8 Discussion: Probabilistic Typology,[0],[0]
Richer families of point processes might also be worth exploring.,8 Discussion: Probabilistic Typology,[0],[0]
"For example, perhaps the vowel inventory is generated by some temporal mechanism with latent intermediate steps, such as sequential selection of the vowels or evolutionary drift of the inventory.",8 Discussion: Probabilistic Typology,[0],[0]
"Another possibility is that vowel systems tend to reuse distinctive features or even follow factorial designs, so that an inventory with creaky front vowels also tends to have creaky back vowels.",8 Discussion: Probabilistic Typology,[0],[0]
We have presented a series of point process models for the modeling of vowel system inventory typology with the goal of a mathematical grounding for research in phonological typology.,9 Conclusions,[0],[0]
All models were additionally given a deep parameterization to learn representations similar to perceptual space in cognitive science.,9 Conclusions,[0],[0]
"Also, we motivated our preference for probabilistic modeling in linguistic typology over previously proposed computational approaches and argued it is a more natural research paradigm.",9 Conclusions,[0],[0]
"Additionally, we have introduced several novel evaluation metrics for research in vowelsystem typology, which we hope will spark further interest in the area.",9 Conclusions,[0],[0]
"Their performance was empirically validated on the Becker-Kristal corpus, which includes data from over 200 languages.",9 Conclusions,[0],[0]
"The first author was funded by an NDSEG graduate fellowship, and the second author by NSF grant IIS1423276.",Acknowledgments,[0],[0]
We would like to thank Tim Vieira and Huda Khayrallah for helpful initial feedback.,Acknowledgments,[0],[0]
Linguistic typology studies the range of structures present in human language.,abstractText,[0],[0]
"The main goal of the field is to discover which sets of possible phenomena are universal, and which are merely frequent.",abstractText,[0],[0]
"For example, all languages have vowels, while most—but not all—languages have an [u] sound.",abstractText,[0],[0]
In this paper we present the first probabilistic treatment of a basic question in phonological typology: What makes a natural vowel inventory?,abstractText,[0],[0]
"We introduce a series of deep stochastic point processes, and contrast them with previous computational, simulation-based approaches.",abstractText,[0],[0]
We provide a comprehensive suite of experiments on over 200 distinct languages.,abstractText,[0],[0]
Probabilistic Typology: Deep Generative Models of Vowel Inventories,title,[0],[0]
Machine learning is increasingly used to make consequential classification decisions about individuals.,1. Introduction,[0],[0]
"Examples range from predicting whether a user will enjoy a particular article, to estimating a felon’s recidivism risk, to determining whether a patient is a good candidate for a medical treatment.",1. Introduction,[0],[0]
"Automated classification comes with great benefits, but it also raises substantial societal concerns (cf. (O’Neil, 2016) for a recent perspective).",1. Introduction,[0],[0]
One prominent concern is that these algorithms might discriminate against individuals or groups in a way that violates laws or social and ethical norms.,1. Introduction,[0],[0]
"This might happen due to biases in the training data
*Equal contribution 1Weizmann Institute of Science, Rehovot, Israel.",1. Introduction,[0],[0]
"Correspondence to: Guy N. Rothblum <rothblum@alum.mit.edu>, Gal Yona <gal.yona@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
or due to biases introduced by the algorithm.",1. Introduction,[0],[0]
"To address these concerns, and to truly unleash the full potential of automated classification, there is a growing need for frameworks and tools to mitigate the risks of algorithmic discrimination.",1. Introduction,[0],[0]
"A growing literature attempts to tackle these challenges by exploring different fairness criteria.
",1. Introduction,[0],[0]
Discrimination can take many guises.,1. Introduction,[0],[0]
It can be difficult to spot and difficult to define.,1. Introduction,[0],[0]
"Imagine a protected minority population P (defined by race, gender identity, etc).",1. Introduction,[0],[0]
A natural approach for protecting the members of P from discrimination is to make sure that they are not mistreated on average.,1. Introduction,[0],[0]
"For example, that on average members of P and individuals outside of P are classified in any particular way with roughly the same probability.",1. Introduction,[0],[0]
"This is a “group-level” fairness notion, sometimes referred to as statistical parity.
",1. Introduction,[0],[0]
"Pointing out several weakness of group-level notions of fairness, the seminal work of (Dwork et al., 2012) introduced a notion of individual fairness.",1. Introduction,[0],[0]
"Their notion relies on a task-specific similarity metric that specifies, for every two individuals, how similar they are with respect to the specific classification task at hand.",1. Introduction,[0],[0]
"Given such a metric, similar individuals should be treated similarly, i.e. assigned similar classification distributions (their focus was on probabilistic classifiers, as will be ours).",1. Introduction,[0],[0]
"In this work, we refer to their fairness notion as perfect metric-fairness.
",1. Introduction,[0],[0]
"Given a good metric, perfect metric-fairness provides powerful protections from discrimination.",1. Introduction,[0],[0]
"Furthermore, the metric provides a vehicle for specifying social norms, cultural awareness, and task-specific knowledge.",1. Introduction,[0],[0]
"While coming up with a good metric can be challenging, metrics arise naturally in prominent existing examples (such as credit scores and insurance risk scores), and in natural scenarios (a metric specified by an external regulator).",1. Introduction,[0],[0]
"Dwork et al. studied the goal of finding a (probabilistic) classifier that minimizes utility loss (or maximizes accuracy), subject to satisfying the perfect metric-fairness constraint.",1. Introduction,[0],[0]
They showed how to phrase and solve this optimization problem for a given collection of individuals.,1. Introduction,[0],[0]
"Building on these foundations, we study metric-fair machine learning.",1.1. This Work,[0],[0]
"Consider a learner that is given a similarity metric and a training set of labeled examples, drawn from
an underlying population distribution.",1.1. This Work,[0],[0]
"The learner should output a fair classifier that (to the extent possible) accurately classifies the underlying population.
",1.1. This Work,[0],[0]
"This goal departs from the scenario studied in (Dwork et al., 2012), where the focus was on guaranteeing metric-fairness and utility for the dataset at hand.",1.1. This Work,[0],[0]
"Generalization of the fairness guarantee is a key difference: we focus on guaranteeing fairness not just for the (training) data set at hand, but also for the underlying population from which it was drawn.",1.1. This Work,[0],[0]
"We note that perfect metric-fairness does not, as a rule, generalize from a training set to the underlying population.",1.1. This Work,[0],[0]
This presents computational difficulties for constructing learning algorithms that are perfectly metric-fair for the underlying population.,1.1. This Work,[0],[0]
"Indeed, we exhibit a simple learning task that, while easy to learn without fairness constraints, becomes computationally infeasible under the perfect metric-fairness constraint (given a particular metric).1 See below and in Section 6 for further details.
",1.1. This Work,[0],[0]
"We develop a relaxed approximate metric-fairness framework for machine learning, where fairness does generalize from the sample to the underlying population, and present polynomial-time fair learning algorithms in this framework.",1.1. This Work,[0],[0]
"We proceed to describe our setting and contributions.
",1.1. This Work,[0],[0]
Problem setting.,1.1. This Work,[0],[0]
"A metric-fair learning problem is defined by a domain X and a similarity metric d. A metric-fair learning algorithm gets as input the metric d and a sample of labeled examples, drawn i.i.d.",1.1. This Work,[0],[0]
"from a distribution D over labeled examples from (X × ±1), and outputs a classifier h. To accommodate fairness, we focus on probabilistic classifiers h :",1.1. This Work,[0],[0]
X,1.1. This Work,[0],[0]
"→ [0, 1], where we interpret h(x) as the probability of label 1 (the probability of −1 is thus (1 − h(x))).",1.1. This Work,[0],[0]
"We refer to these probabilistic classifiers as predictors.
",1.1. This Work,[0],[0]
Approximate Metric-Fairness.,1.1. This Work,[0],[0]
"Taking inspiration from Valiant’s celebrated PAC learning model (Valiant, 1984), we allow a small fairness error, which opens the door to generalization.",1.1. This Work,[0],[0]
"We require that for two individuals sampled from the underlying population, with all but a small probability, if they are similar then they should be treated similarly.",1.1. This Work,[0],[0]
Similarity is measured by the statistical distance between the classification distributions given to the two individuals (we also allow a small additive slack in the similarity measure).,1.1. This Work,[0],[0]
We refer to this condition as approximate metric-fairness (MF).,1.1. This Work,[0],[0]
"Similarly to PAC learning, we also allow a small probability of a complete fairness failure.
",1.1. This Work,[0],[0]
"Given a well-designed metric, approximate metric-fairness guarantees that almost every individual gets fair treatment
1We remark that perfect metric-fairness can always be obtained trivially by outputting a constant classifier that treats all individuals identically, the challenge is achieving metric-fairness together with non-trivial accuracy.
",1.1. This Work,[0],[0]
compared to almost every other individual.,1.1. This Work,[0],[0]
"In particular, it provides discrimination-protections to every group P that is not too small.",1.1. This Work,[0],[0]
"However, this guarantee also has limitations: particular individuals and even small groups might encounter bias and discrimination.",1.1. This Work,[0],[0]
"There are certainly settings in which this is problematic, but in other settings protecting all groups that are not too small is an appealing guarantee.",1.1. This Work,[0],[0]
"The relaxation is well-motivated because approximate fairness opens the door to fairness-generalization bounds, as well as efficient learning algorithms for a rich collection of problems (see below).",1.1. This Work,[0],[0]
"We elaborate on these choices in Section 2.
",1.1. This Work,[0],[0]
Competitive accuracy.,1.1. This Work,[0],[0]
"Turning our attention to the accuracy objective, we follow (Dwork et al., 2012) in considering fairness to be a hard constraint (e.g. imposed by a regulator).",1.1. This Work,[0],[0]
"Given the fairness constraint, what is a reasonable accuracy objective?",1.1. This Work,[0],[0]
"Ideally, we would like the predictor’s accuracy to approach (as the sample size grows) that of the most accurate approximately MF predictor.",1.1. This Work,[0],[0]
"This is analogous to the accuracy guarantee pioneered in (Dwork et al., 2012).",1.1. This Work,[0],[0]
A probably approximately correct and fair (PACF) learning algorithm guarantees both approximate MF and “best-possible” accuracy.,1.1. This Work,[0],[0]
A more relaxed accuracy benchmark is approaching the accuracy of the best classifier that is approximately MF for a tighter (more restrictive) fairnesserror.,1.1. This Work,[0],[0]
"We refer this as a relaxed PACF learning algorithm (looking ahead, our efficient algorithms achieve this relaxed accuracy guarantee).",1.1. This Work,[0],[0]
We note that even relaxed PACF guarantees that the classifier is (at the very least) competitive with the best perfectly metric-fair classifier.,1.1. This Work,[0],[0]
"We elaborate in Section 3.
",1.1. This Work,[0],[0]
Generalization bounds.,1.1. This Work,[0],[0]
A key issue in learning theory is that of generalization: to what extent is a classifier that is accurate on a finite sample S ∼ Dm also guaranteed to be accurate w.r.t the underlying distribution?,1.1. This Work,[0],[0]
"We develop strong generalization bounds for approximate metricfairness, showing that for any class of predictors with bounded Rademacher complexity, approximate MF on the sample S implies approximate MF on the underlying distribution (w.h.p.",1.1. This Work,[0],[0]
over the choice of sample S).,1.1. This Work,[0],[0]
The use of Rademacher complexity guarantees fairness-generalization for finite classes and also for many infinite classes.,1.1. This Work,[0],[0]
Proving that approximate metric-fairness generalizes well is a crucial component in our analysis: it opens the door to polynomial-time algorithms that can focus on guaranteeing fairness (and accuracy) on the sample.,1.1. This Work,[0],[0]
"Generalization also implies information-theoretic sample-complexity bounds for PACF learning, similar to those known for PAC learning (without fairness constraints).",1.1. This Work,[0],[0]
"We elaborate in Section 4.
Efficient algorithms.",1.1. This Work,[0],[0]
We construct polynomial-time (relaxed) PACF algorithms for linear and logistic regression.,1.1. This Work,[0],[0]
"Recall that (for fairness) we focus on regression problems:
learning predictors that assign a probability in [0, 1] to each example.",1.1. This Work,[0],[0]
"For linear predictors, the probability is a linear function of an example’s distance from a hyperplane.",1.1. This Work,[0],[0]
Logistic predictors compose a linear function with a sigmoidal transfer function.,1.1. This Work,[0],[0]
This allows logistic predictors to exhibit sharper transitions from low predictions to high predictions.,1.1. This Work,[0],[0]
"In particular, a logistic predictor can better approximate a classifier that labels examples that are below a hyperplane by −1, and examples that are above the hyperplane by 1.",1.1. This Work,[0],[0]
"Linear and logistic predictors can be more powerful than they first seem: by embedding a learning problem into a higher-dimensional space, linear functions (over the expanded space) can capture the power of many of the function classes that are known to be PAC learnable (Hellerstein & Servedio, 2007).",1.1. This Work,[0],[0]
We overview these results in Section 5.,1.1. This Work,[0],[0]
We note that a key challenge in efficient metric-fair learning is that the fairness constraints are neither Lipschitz nor convex (even when the predictor is linear).,1.1. This Work,[0],[0]
"This is also a challenge for proving generalization and sample complexity bounds.
",1.1. This Work,[0],[0]
Perfect metric-fairness is hard.,1.1. This Work,[0],[0]
"Under mild cryptographic assumptions, we exhibit a learning problem and a similarity metric where: (i) there exists a perfectly fair and perfectly accurate simple (linear) predictor, but (ii) any polynomialtime perfectly metric-fair learner can only find a trivial predictor, whose error approaches 1/2.",1.1. This Work,[0],[0]
"In contrast, (iii) there does exist a polynomial-time (relaxed) PACF learning algorithm for this task.",1.1. This Work,[0],[0]
This is an important motivation for our study of approximate MF.,1.1. This Work,[0],[0]
"We elaborate in Section 6.
Organization.",1.1. This Work,[0],[0]
"In the remainder of this paper, we go on to provide a detailed overview of our contributions.",1.1. This Work,[0],[0]
In Section 1.2 we review related work.,1.1. This Work,[0],[0]
Section 2 details and discusses the definition of approximate metric-fairness.,1.1. This Work,[0],[0]
Accurate and fair (PACF) learning is discussed in Section 3.,1.1. This Work,[0],[0]
We state and prove fairness-generalization bounds in Section 4.,1.1. This Work,[0],[0]
Our polynomial-time PACF learning algorithms for linear and logistic regression are in Section 5.,1.1. This Work,[0],[0]
Section 6 elaborates on the hardness of perfectly metric-fair learning.,1.1. This Work,[0],[0]
There is a growing body of work attempting to study the question of algorithmic discrimination.,1.2. Related Work,[0],[0]
"This literature is characterized by an abundance of definitions, each capturing different discrimination concerns and notions of fairness.",1.2. Related Work,[0],[0]
"One high-level distinction can be drawn between group and individual notions of fairness.
",1.2. Related Work,[0],[0]
"Group fairness notions assume the existence of a protected attribute (e.g gender, race), which induces a partition of the instance space into some small number of groups.",1.2. Related Work,[0],[0]
A fair classifier is one that achieves parity of some statistical measure across these groups.,1.2. Related Work,[0],[0]
"Some prominent measures include classification rates (statistical parity, see e.g (Feldman et al., 2015)), calibration, and false positive or negative
rates (Kleinberg et al., 2016; Chouldechova, 2017; Hardt et al., 2016).",1.2. Related Work,[0],[0]
"It has been established that some of these notions are inherently incompatible with each other, in all but trivial cases (Kleinberg et al., 2016; Chouldechova, 2017).",1.2. Related Work,[0],[0]
"The work of (Woodworth et al., 2017) takes a step towards incorporating the fairness notion of (Hardt et al., 2016) into a statistical and computational theory of learning, and considers a relaxation of the fairness definition to overcome the computational intractability of the learning objective.",1.2. Related Work,[0],[0]
"The work of (Dwork et al., 2017) proposes an efficient framework for learning different classifiers for different groups in a fair manner.
",1.2. Related Work,[0],[0]
"Individual fairness (Dwork et al., 2012) posits that “similar individuals should be treated similarly”.",1.2. Related Work,[0],[0]
This powerful guarantee is formalized via a Lipschitz condition (with respect to an existing task-specific similarity metric) on the classifier mapping individuals to distributions over outcomes.,1.2. Related Work,[0],[0]
"Recent works (see e.g (Joseph et al.)) study different individuallevel fairness in the contexts of reinforcement and online learning.
",1.2. Related Work,[0],[0]
Our notion of approximate metric-fairness can be interpreted as staking a middle-ground between individual- and group-fairness.,1.2. Related Work,[0],[0]
"In this sense, it is similar to recent works that protect large collections of sufficiently-large groups (Hébert-Johnson et al., 2017; Kearns et al., 2017; Kim et al., 2018).",1.2. Related Work,[0],[0]
"A distinction from these works is in protecting every sufficiently-large group, rather than a large collection of groups that is fixed a priori.",1.2. Related Work,[0],[0]
"(Kim et al., 2018) consider a (computational) relaxation of individual fairness, focusing on settings where the metric itself is not fully known.
",1.2. Related Work,[0],[0]
"Finally, several works have studied fair regression (Kamishima et al., 2012; Calders et al., 2013; Zafar et al., 2017; Berk et al., 2017).",1.2. Related Work,[0],[0]
"The main differences in our work are a focus on metric-based fairness, a strong rigorous fairness guarantee, and proofs of competitive accuracy (both stated with respect to the underlying distribution).",1.2. Related Work,[0],[0]
We require that metric-fairness holds for all but a small α fraction of pairs of individuals.,2. Approximate Metric-Fairness,[0],[0]
"That is, with all but α probability over a choice of two individuals from the underlying distribution, if the two individuals are similar then they get similar classification distributions.",2. Approximate Metric-Fairness,[0],[0]
We think of α ∈,2. Approximate Metric-Fairness,[0],[0]
"[0, 1) as a small constant, and note that setting α = 0 recovers the definition of perfect metric-fairness (thus, setting α to be a small constant larger than 0 is indeed a relaxation).",2. Approximate Metric-Fairness,[0],[0]
"Similarity is measured by the statistical distance between the classification distributions given to the two individuals, where we also allow a small additive slack γ in the similarity measure.",2. Approximate Metric-Fairness,[0],[0]
"The larger γ is, the more “differently” similar individuals might be treated.",2. Approximate Metric-Fairness,[0],[0]
"We think of γ as a small
constant, close to 0.
",2. Approximate Metric-Fairness,[0],[0]
Definition 2.1,2. Approximate Metric-Fairness,[0],[0]
"A predictor h is (α, γ) approximately metricfair (MF) with respect to a similarity metric d and a data distribution D if:
LFγ def = Pr x,x′∼D",2. Approximate Metric-Fairness,[0],[0]
"[|h(x)− h(x′)| > d(x, x′) +",2. Approximate Metric-Fairness,[0],[0]
"γ] ≤ α (1)
Similarly to the PAC learning model, we also allow a small δ probability of failure.",2. Approximate Metric-Fairness,[0],[0]
This probability is taken over the choice of the training set and over the learner’s coins.,2. Approximate Metric-Fairness,[0],[0]
"For example, δ bounds the probability that the randomly sampled training set is not representative of the underlying population.",2. Approximate Metric-Fairness,[0],[0]
We think of δ as very small or even negligible.,2. Approximate Metric-Fairness,[0],[0]
"A learning algorithm is probably approximately metric-fair if with all but δ probability over the sample (and the learner’s coins), it outputs a classifier that is (α, γ)-approximately MF.",2. Approximate Metric-Fairness,[0],[0]
"Further details are in Appendix A.2 in the full version (see supplementary material).
",2. Approximate Metric-Fairness,[0],[0]
"Given a well-designed metric, approximate metric-fairness (for sufficiently small α, γ) guarantees that almost every individual gets fair treatment compared to almost every other individual (see Appendix A.3 for a quantitative discussion).",2. Approximate Metric-Fairness,[0],[0]
"Every protected group P of fractional size significantly larger than α is protected in the sense that, on average, members of P are treated similarly to similar individuals outside of P .",2. Approximate Metric-Fairness,[0],[0]
"We note, however, that this guarantee does not protect single individuals or small groups (see the discussion in Section 1.1).",2. Approximate Metric-Fairness,[0],[0]
"Our goal is to obtain learning algorithms that are probably approximately metric-fair, and that simultaneously guarantee non-trivial accuracy.",3. Accurate and Fair Learning,[0],[0]
"Recall that fairness, on its own, can always be obtained by outputting a constant classifier that ignores its input and treats all individuals identically.",3. Accurate and Fair Learning,[0],[0]
It is the combination of the fairness and the accuracy objectives that makes for an interesting task.,3. Accurate and Fair Learning,[0],[0]
"As discussed above, we follow (Dwork et al., 2012) in focusing on finding a classifier that maximizes accuracy, subject to the approximate metric-fairness constraint.",3. Accurate and Fair Learning,[0],[0]
"This is a natural formulation, as we think of fairness as a hard requirement (imposed, for example, by a regulator), and thus fairness cannot be traded off for better accuracy.
",3. Accurate and Fair Learning,[0],[0]
"As discussed above, we focus on the setting of binary classification.",3. Accurate and Fair Learning,[0],[0]
A learning problem is defined by an instance domain X and a classH of predictors (probabilistic classifiers) h,3. Accurate and Fair Learning,[0],[0]
: X,3. Accurate and Fair Learning,[0],[0]
"→ [0, 1].",3. Accurate and Fair Learning,[0],[0]
A fair learning problem also includes a similarity metric d : X 2,3. Accurate and Fair Learning,[0],[0]
"→ [0, 1].",3. Accurate and Fair Learning,[0],[0]
"The learning algorithm gets as input the metric d and a sample of labeled examples, drawn i.i.d.",3. Accurate and Fair Learning,[0],[0]
"from a distribution D over labeled examples from (X × ±1), and its goal is to output a predictor that
is both fair and as accurate as possible.",3. Accurate and Fair Learning,[0],[0]
"A proper learner outputs a predictor in the class H, whereas an improper learner’s output is unconstrained (butH is used as a benchmark for accuracy).",3. Accurate and Fair Learning,[0],[0]
"For a learned (real-valued) predictor h, we use errD(h) to denote the expected `1 error of h (the absolute loss) on a random sample from D.2
Accuracy guarantee: PACF learning.",3. Accurate and Fair Learning,[0],[0]
"As discussed above, the goal in metric-fair and accurate learning is optimizing the predictor’s accuracy subject to the fairness constraint.",3. Accurate and Fair Learning,[0],[0]
"Ideally, we aim to approach (as the sample size grows) the error rate of the most accurate classifier that satisfies the fairness constraints.",3. Accurate and Fair Learning,[0],[0]
"A more relaxed benchmark is guaranteeing (α, γ)-approximate metric-fairness, while approaching the accuracy of the best classifier that is (α′, γ′)-approximately metric-fair, for α′ ∈",3. Accurate and Fair Learning,[0],[0]
"[0, α] and γ′ ∈",3. Accurate and Fair Learning,[0],[0]
"[0, γ].",3. Accurate and Fair Learning,[0],[0]
Our efficient learning algorithms will achieve this more relaxed accuracy goal (see below).,3. Accurate and Fair Learning,[0],[0]
"We note that even relaxed competitiveness means that the classifier is (at the very least) competitive with the best perfectly metric-fair classifier.
",3. Accurate and Fair Learning,[0],[0]
These goals are captured in the following definition of probably approximately correct and fair (PACF) learning.,3. Accurate and Fair Learning,[0],[0]
"Crucially, both fairness and accuracy goals are stated with respect to the (unknown) underlying distribution.
",3. Accurate and Fair Learning,[0],[0]
Definition 3.1 (PACF Learning),3. Accurate and Fair Learning,[0],[0]
"A learning algorithm A PACF-learns a hypothesis classH if for every metric d and population distribution D, every required fairness parameters α, γ ∈",3. Accurate and Fair Learning,[0],[0]
"[0, 1), every failure probability δ ∈ (0, 1), and every error parameters , α, γ ∈ (0, 1), there exists a sample complexity m = poly ( log |X |·log(1/δ) α·γ· · α· γ ) and constants α′, γ′ ∈",3. Accurate and Fair Learning,[0],[0]
"[0, 1) (specified below), such that with all but δ probability over an i.i.d. sample of size m and A’s coin tosses, the output predictor h satisfies the following two conditions:
1.",3. Accurate and Fair Learning,[0],[0]
"Fairness: h is (α, γ)-approximately metric-fair w.r.t.",3. Accurate and Fair Learning,[0],[0]
"the metric d and the distribution D.
2.",3. Accurate and Fair Learning,[0],[0]
"Accuracy: LetH′F be the subclass of hypotheses inH that are (α′ − α, γ′",3. Accurate and Fair Learning,[0],[0]
"− γ)-approximately MF, then:
errD(h) ≤ min h′∈H′F errD(h ′)",3. Accurate and Fair Learning,[0],[0]
"+
We say that A is efficient if it runs in time poly(m).",3. Accurate and Fair Learning,[0],[0]
If accuracy holds for α′ = α and γ′,3. Accurate and Fair Learning,[0],[0]
"= γ, then we stay that A is a strong PACF learning algorithm.",3. Accurate and Fair Learning,[0],[0]
"Otherwise, we say that A is a relaxed PACF learning algorithm.
",3. Accurate and Fair Learning,[0],[0]
See Appendix B and Definitions B.2 and B.3 for a full treatment.,3. Accurate and Fair Learning,[0],[0]
"Note that the accuracy guarantee is agnostic: we
2All results also translate to `2 error (the squared loss).
make no assumptions about the way the training labels are generated.",3. Accurate and Fair Learning,[0],[0]
"Agnostic learning is particularly well suited to our setting: since we make no assumptions about the metric d, even if the labels are generated by h ∈ H, it might be the case that d does not allow for accurate predictions, in which case a fair learner cannot compete with h’s accuracy.",3. Accurate and Fair Learning,[0],[0]
Generalization is a key issue in learning theory.,4. Generalization,[0],[0]
"We develop strong generalization bounds for approximate metricfairness, showing that with high probability, guaranteeing empirical approximate MF on a training set also guarantees approximate MF on the underlying distribution (w.h.p.",4. Generalization,[0],[0]
over the choice of sample S).,4. Generalization,[0],[0]
"This generalization bound opens the door to polynomial-time algorithms that can focus on guaranteeing fairness (and accuracy) on the sample and effectively rules out the possibility of creating a “false facade” of fairness (i.e, a classifier that appears fair on a random sample, but is not fair w.r.t new individuals).
",4. Generalization,[0],[0]
"Towards proving generalization, we define the empirical fairness loss on a sample S (a training set).",4. Generalization,[0],[0]
"Fixing a fairness parameter γ, a predictor h and a pair of individuals x, x′ in the training set, consider the MF loss on the “edge” between x and x′ (recall that the MF loss is 1 if the “internal” inequality of Equation (1) holds, and 0 otherwise).",4. Generalization,[0],[0]
"Observe that the losses on the (|S| 2 ) edges are not independent random variables (over the choice of S), because each individual x ∈ S affects many edges.",4. Generalization,[0],[0]
"Thus, rather than count the empirical MF loss over all edges, we restrict ourselves to a “matching” M(S) in the complete graph whose vertices are S: a collection of edges, where each individual is involved in exactly one edge.",4. Generalization,[0],[0]
"The empirical MF loss of h on S is defined as the average MF loss over edges in M(S).3 Note that, since we restricted our attention to a matching, the MF losses on these edges are now independent random variables (over the choice of S).",4. Generalization,[0],[0]
"A classifier is empirically (α, γ)-approximately MF if its empirical MF loss is at most α.",4. Generalization,[0],[0]
"We are now ready to state our generalization bound:
Theorem 4.1 LetH be a hypothesis class with Rademacher complexity Rm(H) =",4. Generalization,[0],[0]
(r/ √ m).,4. Generalization,[0],[0]
"For every δ ∈ (0, 1) and every α, γ ∈ (0, 1), there exists a sample complexity m = O ( r2·ln(1/δ)",4. Generalization,[0],[0]
"2α· 2γ ) , such that with probability at least 1−δ over an i.i.d sample S ∼ Dm, simultaneously for every h ∈ H: if h is (α, γ)-approximately metric-fair on the sample S, then h is also (α + α, γ + γ)-approximately metric-fair on the underlying distribution D.
3The choice of which matching is used does not affect any of the results.",4. Generalization,[0],[0]
"Note that we could also choose to average over all the edges in the graph induced by S. Generalization bounds still follow, but the rate of convergence is not faster.
",4. Generalization,[0],[0]
See Appendix A.4 and Theorem A.9 for a full statement and discussion (and see Definition A.8 for a definition of Rademacher complexity).,4. Generalization,[0],[0]
"Rademacher complexity differs from the celebrated VC-dimension in several respects: first, it is defined for any class of real-valued functions (making it suitable for our setting of learning probabilistic classifiers); second, it is data-dependent and can be measured from finite samples (indeed, Theorem 4.1 can be stated w.r.t.",4. Generalization,[0],[0]
"the empirical Rademacher complexity on a given sample); third, it often results in tighter uniform convergence bounds (see, e.g, (Koltchinskii & Panchenko, 2002)).",4. Generalization,[0],[0]
"We note that for every finite hypothesis class H whose range is [0, 1], the Rademacher complexity is bounded by O( √ log |H|/m).
",4. Generalization,[0],[0]
Technical Overview of Theorem 4.1.,4. Generalization,[0],[0]
"For any class of (bounded) real-valued functions F , the maximal difference (over all functions f ∈ F ) between the function’s empirical average on a randomly drawn sample, and the function’s true expectation over the underlying distribution, can be bounded in terms of the Rademacher complexity of the class (as well as the sample size and desired confidence).",4. Generalization,[0],[0]
"For a hypothesis class H and a loss function `, applying this result for the class L(H) = {`h}h∈H yields a bound on the maximal difference (over all hypotheses h ∈ H) between the true loss and the empirical loss, in terms of the Rademacher complexity of the composed class L(H).",4. Generalization,[0],[0]
"If the loss function ` is G-Lipschitz, this can be converted to a bound in terms of the Rademacher complexity ofH using the fact that R (L(H))",4. Generalization,[0],[0]
≤,4. Generalization,[0],[0]
"G ·R (H).
",4. Generalization,[0],[0]
"Turning our attention to generalization of the fairness guarantee, we are faced with the problem that our “0-1” MF loss function is not Lipschitz.",4. Generalization,[0],[0]
We resolve this by defining an approximation `′ to the MF loss that is a piece-wise linear and G-Lipschitz function.,4. Generalization,[0],[0]
"The approximation `′ does generalize, and so we conclude that the empirical MF loss is close to the empirical value of `′, which is close to the true value of `′, which in turn is close to the true MF loss.",4. Generalization,[0],[0]
The approximation incurs a 1/G additive slack in the fairness guarantee.,4. Generalization,[0],[0]
"The larger G is, the more accurately `′ approximates the MF loss, but this comes at the price of increasing the Lipschitz constant (which hurts generalization).",4. Generalization,[0],[0]
The generalization theorem statement above reflects a choice of G that trades off these conflicting concerns.,4. Generalization,[0],[0]
"The fairness-generalization result of Theorem 4.1 implies that, from a sample-complexity perspective, any hypothesis class is strongly PACF learnable, with sample complexity comparable to that of standard PAC learning.
",4.1. Information-Theoretic Sample Complexity,[0],[0]
Theorem 4.2 LetH be a hypothesis class with Rademacher complexity Rm(H) =,4.1. Information-Theoretic Sample Complexity,[0],[0]
(r/ √ m).,4.1. Information-Theoretic Sample Complexity,[0],[0]
"Then H is informationtheoretically strongly PACF learnable with sample complex-
ity m = O ( r2 ln(1/δ)
( ′)2
) , for ′ = min { , α, γ} .",4.1. Information-Theoretic Sample Complexity,[0],[0]
One of our primary contributions is the construction of polynomial-time relaxed-PACF learning algorithms for expressive hypothesis classes.,5. Efficient Fair Learning,[0],[0]
"We focus on linear classification tasks, where the labels are determined by a separating hyperplane.",5. Efficient Fair Learning,[0],[0]
"Learning linear classifiers, also referred to as halfspaces or linear threshold functions, is a central tool in machine learning.",5. Efficient Fair Learning,[0],[0]
"By embedding a learning problem into a higher-dimensional space, linear classifiers (over the expanded space) can capture surprisingly strong classes, such as polynomial threshold functions (see, for example, the discussion in (Hellerstein & Servedio, 2007)).",5. Efficient Fair Learning,[0],[0]
"The “kernel trick” (see, e.g, (Shalev-Shwartz & Ben-David, 2014)) can allow for efficient solutions even over very high (or infinite) dimensional embeddings.",5. Efficient Fair Learning,[0],[0]
"Many of the known (distributionfree) PAC learning algorithms can be derived by learning linear threshold functions (Hellerstein & Servedio, 2007).
",5. Efficient Fair Learning,[0],[0]
"Recall that in metric-fair learning, we aim to learn a probabilistic classifier, or a predictor, that outputs a real value in [0, 1].",5. Efficient Fair Learning,[0],[0]
We interpret the output as the probability of assigning the label 1.,5. Efficient Fair Learning,[0],[0]
We are thus in the setting of regression.,5. Efficient Fair Learning,[0],[0]
We show polynomial-time relaxed-PACF learning algorithms for linear regression and for logistic regression.,5. Efficient Fair Learning,[0],[0]
See Appendix D.2 for full and formal details.,5. Efficient Fair Learning,[0],[0]
"Linear regression, the task of learning linear predictors, is an important and well-studied problem in the machine learning literature.",5.1. Linear Regression,[0],[0]
"In terms of accuracy, this is an appealing class when we expect a linear relationship between the probability of the label being 1 and the distance from a hyperplane.",5.1. Linear Regression,[0],[0]
"Taking the domain X to be the unit ball, we define the class of linear predictors as:
Hlin def = {x 7→ (1 + 〈w,x〉)/2 :",5.1. Linear Regression,[0],[0]
"‖w‖ ≤ 1} .
",5.1. Linear Regression,[0],[0]
"We restrict w to the unit ball to guarantee that 〈w,x〉 ∈",5.1. Linear Regression,[0],[0]
"[−1, 1].",5.1. Linear Regression,[0],[0]
"We then invoke a linear transformation so that the final prediction is in [0, 1], as required.",5.1. Linear Regression,[0],[0]
"Restricting the predictor’s output to the range [0, 1] is important.",5.1. Linear Regression,[0],[0]
"In particular, it means that a linear predictor must be (1/2)-Lipschitz, which might not be appropriate for certain classification tasks (see the discussion of logistic regression below).
",5.1. Linear Regression,[0],[0]
"We show a relaxed PACF learning algorithm for Hlin :
Theorem 5.1 Hlin is relaxed PACF learnable with sample and time complexities of poly( 1 γ , 1 α , 1 , log 1 δ ).",5.1. Linear Regression,[0],[0]
For every γ′ ∈,5.1. Linear Regression,[0],[0]
"[0, 1) and α′ =",5.1. Linear Regression,[0],[0]
"(α · γ − γ′), the accuracy of the learned predictor approaches (or beats) the most accurate (α′, γ′)-approximately MF predictor.
",5.1. Linear Regression,[0],[0]
Algorithm overview.,5.1. Linear Regression,[0],[0]
"Since the Rademacher complexity of (bounded) linear functions is small (Kakade et al., 2009), Theorem 4.1 implies that empirical approximate metricfairness on the training set generalizes to the underlying population.",5.1. Linear Regression,[0],[0]
"Thus, given the metric and a training set, our task is to find a linear predictor that is as accurate as possible, conditioned on the empirical fairness constraint.",5.1. Linear Regression,[0],[0]
We use H = Hlin to denote the class of linear predictors defined above.,5.1. Linear Regression,[0],[0]
"Fixing desired fairness parameters α, γ ∈ (0, 1), let Ĥα,γ ⊆ H be the subset of linear functions that are also (α, γ)-approximately MF on the training set.",5.1. Linear Regression,[0],[0]
"Given a training set S of m labeled examples, we would like to solve the following optimization problem:
argmin h∈H
errS(h) subject to h ∈ Ĥα,γ
Observe, however, that Ĥα,γ is not a convex set.",5.1. Linear Regression,[0],[0]
This is a consequence of the “0/1” metric-fairness loss.,5.1. Linear Regression,[0],[0]
"Thus, we do not know how to solve the above optimization problem efficiently.",5.1. Linear Regression,[0],[0]
"Instead, we will further constrain the predictor h by bounding its `1 MF loss.",5.1. Linear Regression,[0],[0]
"For a predictor h let its (empirical) `1 MF violation ξS(h) be given by:
ξS(h) = ∑
(x,x′)∈M(S)
max (0, |h(x)− h(x′)| − d(x, x′)) .
",5.1. Linear Regression,[0],[0]
For τ ∈,5.1. Linear Regression,[0],[0]
"[0, 1], we take Ĥτ`1 ⊂ H to be the set of linear predictors h s.t. ξS(h) ≤ τ .",5.1. Linear Regression,[0],[0]
"For any fixed τ , this is a convex set, and we can find the most (empirically) accurate predictor in Ĥτ`1 in polynomial time.",5.1. Linear Regression,[0],[0]
"For fairness, we show that small `1 fairness loss also implies the standard notion of approximate metric-fairness (with related parameters α, γ).",5.1. Linear Regression,[0],[0]
"For accuracy, we also show that approximate metric-fairness (with smaller fairness parameters) implies small `1 loss.",5.1. Linear Regression,[0],[0]
"Thus, optimizing over predictors whose `1 loss is bounded gives a predictor that is competitive with (a certain class of) approximately MF predictors.",5.1. Linear Regression,[0],[0]
"In particular for τ, σ ∈",5.1. Linear Regression,[0],[0]
"[0, 1) we have: Ĥτ−σ,σ ⊆ Ĥτ`1 ⊆ Ĥ τ",5.1. Linear Regression,[0],[0]
"γ ,γ .",5.1. Linear Regression,[0],[0]
"Thus, by picking τ = α · γ we guarantee (empirical) (α, γ)-approximate metric-fairness.",5.1. Linear Regression,[0],[0]
"Moreover, for any choice of σ, the set over which we optimize contains all of the predictors that are ((αγ − σ), σ)-approximately MF.",5.1. Linear Regression,[0],[0]
"Thus, our (empirical) accuracy is competitive with all such predictors, and we obtain a relaxed PACF algorithm.",5.1. Linear Regression,[0],[0]
The empirical fairness and accuracy guarantees generalize beyond the training set by Theorem 4.1 (fairness-generalization) and a standard uniform convergence argument for accuracy.,5.1. Linear Regression,[0],[0]
Logistic regression is another appealing class.,5.2. Logistic Regression,[0],[0]
"Here, the prediction need not a be a linear function of the distance from a hyperplane.",5.2. Logistic Regression,[0],[0]
"Rather, we allow the use of a sigmoid function φ` : [−1, 1]→",5.2. Logistic Regression,[0],[0]
"[0, 1] defined as φ`(z) = 11+exp(−4`·z)
(which is continuous and `-Lipschitz).",5.2. Logistic Regression,[0],[0]
"The class of logistic predictors is formed by composing a linear function with a sigmoidal transfer function:
Hφ,L def = {x 7→ φ` (〈w,x〉) :",5.2. Logistic Regression,[0],[0]
"‖w‖ ≤ 1, ` ∈",5.2. Logistic Regression,[0],[0]
"[0, L]} (2)
The sigmoidal transfer function gives the predictor the power to exhibit sharper transitions from low predictions to high predictions around a certain distance (or decision) threshold.",5.2. Logistic Regression,[0],[0]
"For example, suppose a distance from the hyperplane provides a quality score for candidates with respect to a certain task.",5.2. Logistic Regression,[0],[0]
Suppose also that an employer wants to hire candidates whose quality scores are above some threshold η ∈,5.2. Logistic Regression,[0],[0]
"[−1,+1].",5.2. Logistic Regression,[0],[0]
"The class Hφ,L can give probabilities close to 0 to candidates whose quality scores are under η − 1/L, and probabilities close to 1 to candidates whose quality scores are over η + 1/L. Linear predictors, on the other hand, need to be (1/2)-Lipschitz (since we restrict their output to be in [0, 1], see Section 5.1).",5.2. Logistic Regression,[0],[0]
Logistic predictors seem considerably better-suited to this type of scenario.,5.2. Logistic Regression,[0],[0]
"Indeed, the class Hφ,L can achieve good accuracy on linearly separable data whose margin (i.e. the expected distance from the hyperplane) is larger than 1/L. Moreover, similarly to linear threshold functions, logistic regression can be applied after embedding the learning problem into a higher-dimensional space.",5.2. Logistic Regression,[0],[0]
"For example, in the “quality score” example above, the score could be computed by a low-degree polynomial.
",5.2. Logistic Regression,[0],[0]
"Our primary technical contribution is a polynomial-time relaxed PACF learner for Hφ,L where L is constant.
",5.2. Logistic Regression,[0],[0]
"Theorem 5.2 For every constant L > 0, Hφ,L is relaxed PACF learnable with sample and time complexities of poly( 1 γ , 1 α , 1 , log 1 δ ).",5.2. Logistic Regression,[0],[0]
"For every γ
′ ∈",5.2. Logistic Regression,[0],[0]
"[0, 1) and α′ =",5.2. Logistic Regression,[0],[0]
"(α · γ − γ′), the learned predictor’s accuracy approaches the best (α′, γ′)-approximately MF predictor.
",5.2. Logistic Regression,[0],[0]
"More generally, our algorithm is exponential in the parameter L. Recall that we expect to have good accuracy on linearly separable data whose margins are larger than (1/L).",5.2. Logistic Regression,[0],[0]
"Thus, one can interpret the algorithm as having runtime that is exponential in the reciprocal of the (expected) margin.
",5.2. Logistic Regression,[0],[0]
Algorithm overview.,5.2. Logistic Regression,[0],[0]
We note that fair learning of logistic predictors is considerably more challenging than the linear case because the sigmoidal transfer function specifies nonconvex fairness constraints.,5.2. Logistic Regression,[0],[0]
"In standard logistic regression, polynomial-time learning is achieved by replacing the standard loss with a convex logistic loss.",5.2. Logistic Regression,[0],[0]
"In metric-fair learning, however, it not clear how to replace the sigmoidal transfer function by a convex surrogate.
",5.2. Logistic Regression,[0],[0]
"To overcome these barriers, we use improper learning.",5.2. Logistic Regression,[0],[0]
"We embed the linear problem at hand into a higher-dimensional space, where logistic predictors and their fairness constraints can be approximated by convex expressions.",5.2. Logistic Regression,[0],[0]
"To do so, we
use a beautiful result of Shalev-Schwartz et al. (ShalevShwartz et al., 2011) that presents a particular infinitedimensional kernel space where our fairness constraints can be made convex.
",5.2. Logistic Regression,[0],[0]
"In particular, we replace the problem of PACF learningHφ,L with the problem of PACF learning HB , a class of linear predictors with norm bounded by B in a RHKS defined by Vovk’s infinite-dimension polynomial kernel, k(x, x′) =",5.2. Logistic Regression,[0],[0]
"(1− 〈x, x′〉)−1.",5.2. Logistic Regression,[0],[0]
We learn the linear predictor in this RHKS using the result of Theorem 5.1 to obtain a relaxed PACF algorithm for HB .,5.2. Logistic Regression,[0],[0]
"We use the kernel trick to argue that the sample complexity is m = O(B/( ′)2), where ′ = min( , α, γ), and the time complexity is poly(m).
",5.2. Logistic Regression,[0],[0]
"For every B ≥ 0, we can thus learn a linear predictor (in the above RHKS) that is (empirically) sufficiently fair, and whose (empirical) accuracy is competitive with all the linear predictors with norm bounded by B that are ((αγ − σ) , σ)approximately MF, for any choice of σ.",5.2. Logistic Regression,[0],[0]
"To prove PACF learnability of Hφ,L, we build on the polynomial approximation result of Shalev-Schwartz et al. (Shalev-Shwartz et al., 2011) to show that taking B to be sufficiently large ensures that the accuracy of the set of (α, γ)-AMF predictors in Hφ,L is comparable to the accuracy of the set of (α, γ)-AMF predictors in HB .",5.2. Logistic Regression,[0],[0]
"This requires a choice of B that is exp(O(L · ln(L/ ′)), which is where the exponential dependence on L comes in.",5.2. Logistic Regression,[0],[0]
"As discussed above, perfect metric-fairness does not generalize from a training set to the underlying population.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"For example, consider a very small subset of the population that isn’t represented in the training set.",6. Hardness of Perfect Metric-Fairness,[0],[0]
A classifier that discriminates against this small subset might be perfectly metric-fair on the training set.,6. Hardness of Perfect Metric-Fairness,[0],[0]
The failure of generalization poses serious challenges to constructing learning algorithms.,6. Hardness of Perfect Metric-Fairness,[0],[0]
"Indeed, we show that perfect metric-fairness can make simple learning tasks computationally intractable (with respect to a particular metric).
",6. Hardness of Perfect Metric-Fairness,[0],[0]
"We present a natural learning problem and a metric where, even though a perfectly fair and perfectly accurate simple (linear) classifier exists, it cannot be found by any polynomial-time learning algorithm that is perfectly metricfair.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"Indeed, any such algorithm can only find trivial classifiers with error rate approaching 1/2 (not much better than random guessing).",6. Hardness of Perfect Metric-Fairness,[0],[0]
The learner can tell that a particular (linear) classifier is empirically perfectly fair (and perfectly accurate).,6. Hardness of Perfect Metric-Fairness,[0],[0]
"However, even though the classifier is perfectly fair on the underlying distribution, the (polynomial-time) learner cannot certify that this is the case, and thus it has to settle for outputting a trivial classifier.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"We note that there does exist an exponential-time perfectly metric-fair learning
algorithm with a competitive accuracy guarantee (see footnote 5 in the full version).",6. Hardness of Perfect Metric-Fairness,[0],[0]
The issue is the computational complexity of this task.,6. Hardness of Perfect Metric-Fairness,[0],[0]
"In contrast, the relaxed notion of approximate metric-fairness does allow for polynomial-time relaxed-PACF learning algorithms that obtain competitive accuracy for this task (as it does for a rich class of learning problems, see Section 5).
",6. Hardness of Perfect Metric-Fairness,[0],[0]
We present an overview of the hard learning task and discuss its consequences below.,6. Hardness of Perfect Metric-Fairness,[0],[0]
See Appendix E and Theorem E.1 for a more formal description.,6. Hardness of Perfect Metric-Fairness,[0],[0]
"Since we want to argue about computational intractability, we need to make computational assumptions (in particular, if P = NP , then perfectly metric-fair learning would be tractable).",6. Hardness of Perfect Metric-Fairness,[0],[0]
"We will make the minimal cryptographic hardness assumption that one-way functions exist (see, e.g, (Goldreich, 2001)).
",6. Hardness of Perfect Metric-Fairness,[0],[0]
Simplified construction.,6. Hardness of Perfect Metric-Fairness,[0],[0]
"For this sketch, we take a uniform distribution D over a domain X = {±1}n.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"For an item (or individual) x ∈ X , its label will be given by the linear classifier w(x) = x1.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"Note that the linear classifier w indeed is perfectly accurate.4
To argue that fair learning is intractable, we construct two metrics dU and dV that are computationally indistinguishable: no polynomial-time algorithm can tell them apart (even given the explicit description of the metric).5",6. Hardness of Perfect Metric-Fairness,[0],[0]
"We construct these metrics so that dU does not allow any nontrivial accuracy, whereas dV essentially imposes no fairness constraints.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"Thus, w is a perfectly fair and perfectly accurate classifier w.r.t.",6. Hardness of Perfect Metric-Fairness,[0],[0]
dV .,6. Hardness of Perfect Metric-Fairness,[0],[0]
"Now, since a polynomial-time learning algorithm",6. Hardness of Perfect Metric-Fairness,[0],[0]
"A cannot tell dU and dV apart, it has to output the same (distribution on) classifiers given either of these two metrics.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"If A, given dU , outputs a classifier with non-trivial accuracy, then it violates perfect metric-fairness.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"Thus, when given dU ,Amust (with high probability) output a classifier with error close to 1/2.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"This remains the case even when A is given the metric dV (by indistinguishability), despite the fact perfect metric-fairness under dV allows for perfect accuracy.
",6. Hardness of Perfect Metric-Fairness,[0],[0]
We construct the metrics as follows.,6. Hardness of Perfect Metric-Fairness,[0],[0]
"The metric dV gives every pair of individuals x, x′ ∈ X distance 1.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"The metric dU , on the other hand, partitions the items in X into disjoint pairs (x, x′) where the label of x is 1, the label of x′ is −1, but the distance between x and x′ is 0.6 Thus, the 4Note that the expected margin in this distribution is small compared to the norms of the examples.",6. Hardness of Perfect Metric-Fairness,[0],[0]
This is for simplicity and readability.,6. Hardness of Perfect Metric-Fairness,[0],[0]
The full hardness result is shown (in a very similar manner) for data where the margins are large.,6. Hardness of Perfect Metric-Fairness,[0],[0]
"In particular, this means that the class of predictors Hφ,L can achieve good accuracy with constant L. See Appendix E.
5More formally, we construct two distribution on metrics, such that no polynomial-time algorithm can tell whether a given metric was sampled from the first distribution or from the second.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"For readability, we mostly ignore this distinction in this sketch.
",6. Hardness of Perfect Metric-Fairness,[0],[0]
"6Formally, dU is a pseudometric, since it has distinct items at
metric dU assigns to each item",6. Hardness of Perfect Metric-Fairness,[0],[0]
"x ∈ X a “hidden counterpart” x′ that is identical to x, but has the opposite label.",6. Hardness of Perfect Metric-Fairness,[0],[0]
The distance between any two distinct elements that are not “hidden counterparts” is 1 (as in dV ).,6. Hardness of Perfect Metric-Fairness,[0],[0]
"The metric dU specifies that hidden counterparts (x, x′) are identical, and thus any perfectly metric-fair classifier h must treat them identically.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"Since x and x′ have opposing labels, h’s average error on the pair must be 1/2.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"The support of D is partitioned into disjoint hidden counterparts, and thus we conclude that errD(h) = 1/2.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"Note that this is true regardless of h’s complexity (in particular, it also rules out improper learning).",6. Hardness of Perfect Metric-Fairness,[0],[0]
"We construct the metrics using a cryptographic pseudorandom generator (PRG), which specifies the hidden counterparts (in dU ) or their absence (in dV ).",6. Hardness of Perfect Metric-Fairness,[0],[0]
"See the full version for details.
",6. Hardness of Perfect Metric-Fairness,[0],[0]
Discussion.,6. Hardness of Perfect Metric-Fairness,[0],[0]
We make several remarks about the above result.,6. Hardness of Perfect Metric-Fairness,[0],[0]
"First, note that the data distribution is fixed, and the optimal classifier is linear and simple: it only considers a single coordinate.",6. Hardness of Perfect Metric-Fairness,[0],[0]
"This makes the hardness result sharper: without fairness, the learning task is trivial (indeed, since the classifier is fixed there is nothing to learn).",6. Hardness of Perfect Metric-Fairness,[0],[0]
It is the fairness constraint (and only the fairness constraint) that leads to intractability.,6. Hardness of Perfect Metric-Fairness,[0],[0]
The computational hardness of perfectly fair learning applies also to improper learning.,6. Hardness of Perfect Metric-Fairness,[0],[0]
"Finally, the metrics for which we show hardness are arguably contrived (though we note they do obey the triangle inequality).",6. Hardness of Perfect Metric-Fairness,[0],[0]
This rules out perfectly metric-fair learners that work for any given metric.,6. Hardness of Perfect Metric-Fairness,[0],[0]
"A natural direction for future work is restricting the choice of metric, which may make perfectly metric-fair learning feasible.
distance 0.",6. Hardness of Perfect Metric-Fairness,[0],[0]
We can make dU be a true metric by replacing the distance 0 with an arbitrarily small positive quantity.,6. Hardness of Perfect Metric-Fairness,[0],[0]
The hardness result is essentially unchanged.,6. Hardness of Perfect Metric-Fairness,[0],[0]
We thank Cynthia Dwork and Omer Reingold for invaluable and illuminating conversations.,Acknowledgements,[0],[0]
This work was supported by the ISRAEL SCIENCE FOUNDATION (grant No. 5219/17).,Acknowledgements,[0],[0]
"The seminal work of Dwork et al. [ITCS 2012] introduced a metric-based notion of individual fairness: given a task-specific similarity metric, their notion required that every pair of similar individuals should be treated similarly.",abstractText,[0],[0]
"In the context of machine learning, however, individual fairness does not generalize from a training set to the underlying population.",abstractText,[0],[0]
We show that this can lead to computational intractability even for simple fair-learning tasks.,abstractText,[0],[0]
"With this motivation in mind, we introduce and study a relaxed notion of approximate metric-fairness: for a random pair of individuals sampled from the population, with all but a small probability of error, if they are similar then they should be treated similarly.",abstractText,[0],[0]
We formalize the goal of achieving approximate metric-fairness simultaneously with best-possible accuracy as Probably Approximately Correct and Fair (PACF) Learning.,abstractText,[0],[0]
"We show that approximate metric-fairness does generalize, and leverage these generalization guarantees to construct polynomial-time PACF learning algorithms for the classes of linear and logistic predictors.",abstractText,[0],[0]
Probably Approximately Metric-Fair Learning,title,[0],[0]
The goal of text simplification is to rewrite complex text into simpler language that is easier to understand.,1 Introduction,[0],[0]
Research into this topic has many potential practical applications.,1 Introduction,[0],[0]
"For instance, it can provide reading aids for people with disabilities (Carroll et al., 1999; Canning et al., 2000; Inui et al., 2003), low-literacy (Watanabe et al., 2009; De Belder and Moens, 2010), non-native backgrounds (Petersen and Ostendorf, 2007; Allen, 2009) or non-expert knowledge (Elhadad and Sutaria, 2007; Siddharthan and Katsos, 2010).",1 Introduction,[0],[0]
"Text simplification may also help improve the performance of many natural language processing (NLP) tasks, such as parsing (Chandrasekar et al., 1996), summarization (Siddharthan et al., 2004; Klebanov et al., 2004; Vanderwende et al., 2007; Xu and Grishman, 2009), semantic role labeling (Vickrey and Koller, 2008), information extraction (Miwa et al., 2010) and machine translation (Gerber and Hovy, 1998; Chen et al., 2012), by
transforming long, complex sentences into ones that are more easily processed.
",1 Introduction,[0],[0]
"The Parallel Wikipedia Simplification (PWKP) corpus prepared by Zhu et al. (2010), has become the benchmark dataset for training and evaluating automatic text simplification systems.",1 Introduction,[0],[0]
An associated test set of 100 sentences from Wikipedia has been used for comparing the state-of-the-art approaches.,1 Introduction,[0],[0]
The collection of simple-complex parallel sentences sparked a major advance for machine translationbased approaches to simplification.,1 Introduction,[0],[0]
"However, we will show that this dataset is deficient and should be considered obsolete.
",1 Introduction,[0],[0]
"In this opinion paper, we argue that Wikipedia as a simplification data resource is suboptimal for several reasons: 1) It is prone to automatic sentence alignment errors; 2) It contains a large proportion of inadequate simplifications; 3) It generalizes poorly to other text genres.",1 Introduction,[0],[0]
These problems are largely due to the fact that Simple Wikipedia is an encyclopedia spontaneously and collaboratively created for “children and adults who are learning English language” without more specific guidelines.,1 Introduction,[0],[0]
"We quantitatively illustrate the seriousness of these problems through manual inspection and statistical analysis.
",1 Introduction,[0],[0]
Our manual inspection reveals that about 50% of the sentence pairs in the PWKP corpus are not simplifications.,1 Introduction,[0],[0]
We also introduce a new comparative approach to simplification corpus analysis.,1 Introduction,[0],[0]
"In particular, we assemble a new simplification corpus of news articles,1 re-written by professional editors to meet the readability standards for children at multi-
1This Newsela corpus can be requested following the instructions at: https://newsela.com/data/
283
Transactions of the Association for Computational Linguistics, vol. 3, pp. 283–297, 2015.",1 Introduction,[0],[0]
Action Editor: Rada Mihalcea.,1 Introduction,[0],[0]
"Submission batch: 12/2014; Revision batch 4/2015; Published 5/2015.
",1 Introduction,[0],[0]
c©2015 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY-NC-SA 4.0 license.
ple grade levels.",1 Introduction,[0],[0]
This parallel corpus is higher quality and its size is comparable to the PWKP dataset.,1 Introduction,[0],[0]
"It helps us to showcase the limitations of Wikipedia data in comparison and it provides potential remedies that may improve simplification research.
",1 Introduction,[0],[0]
We are not the only researchers to notice problems with Simple Wikipedia.,1 Introduction,[0],[0]
"There are many hints in past publications that reflect the inadequacy of this resource, which we piece together in this paper to support our arguments.",1 Introduction,[0],[0]
"Several different simplification datasets have been proposed (Bach et al., 2011; Woodsend and Lapata, 2011a; Coster and Kauchak, 2011; Woodsend and Lapata, 2011b), but most of these are derived from Wikipedia and not thoroughly analyzed.",1 Introduction,[0],[0]
Siddharthan (2014)’s excellent survey of text simplification research states that one of the most important questions that needs to be addressed is “how good is the quality of Simple English Wikipedia”.,1 Introduction,[0],[0]
"To the best of our knowledge, we are the first to systematically quantify the quality of Simple English Wikipedia and directly answer this question.
",1 Introduction,[0],[0]
"We make our argument not as a criticism of others or ourselves, but as an effort to refocus research directions in the future (Eisenstein, 2013).",1 Introduction,[0],[0]
"We hope to
inspire the creation of higher quality simplification datasets, and to encourage researchers to think critically about existing resources and evaluation methods.",1 Introduction,[0],[0]
We believe this will lead to breakthroughs in text simplification research.,1 Introduction,[0],[0]
"The Parallel Wikipedia Simplification (PWKP) corpus (Zhu et al., 2010) contains approximately 108,000 automatically aligned sentence pairs from cross-linked articles between Simple and Normal English Wikipedia.",2 Simple Wikipedia is not that simple,[0],[0]
"It has become a benchmark dataset for simplification largely because of its size and availability, and because follow-up papers (Woodsend and Lapata, 2011a; Coster and Kauchak, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Siddharthan and Angrosh, 2014; Angrosh et al., 2014) often compare with Zhu et al.’s system outputs to demonstrate further improvements.
",2 Simple Wikipedia is not that simple,[0],[0]
The large quantity of parallel text from Wikipedia made it possible to build simplification systems using statistical machine translation (SMT) technology.,2 Simple Wikipedia is not that simple,[0],[0]
"But after the initial success of these firstgeneration systems, we started to suffer from the
inadequacy of the parallel Wikipedia simplification datasets.",2 Simple Wikipedia is not that simple,[0],[0]
There is scattered evidence in the literature.,2 Simple Wikipedia is not that simple,[0],[0]
"Bach et al. (2011) mentioned they have attempted to use parallel Wikipedia data, but opted to construct their own corpus of 854 sentences (25% from New York Times and 75% are from Wikipedia) with one manual simplification per sentence.",2 Simple Wikipedia is not that simple,[0],[0]
Woodsend and Lapata (2011a) showed that rewriting rules learned from Simple Wikipedia revision histories produce better output compared to the “unavoidably noisy” aligned sentences from SimpleNormal Wikipedia.,2 Simple Wikipedia is not that simple,[0],[0]
"The Woodsend and Lapata (2011b) model, that used quasi-synchronous grammars learned from Wikipedia revision history, left 22% sentences unchanged in the test set.",2 Simple Wikipedia is not that simple,[0],[0]
"Wubben et al. (2012) found that a phrase-based machine translation model trained on the PWKP dataset often left the input unchanged, since “much of training data consists of partially equal input and output strings”.",2 Simple Wikipedia is not that simple,[0],[0]
Coster and Kauchak (2011) constructed another parallel Wikipedia dataset using a more sophisticated sentence alignment algorithm with an additional step that first aligns paragraphs.,2 Simple Wikipedia is not that simple,[0],[0]
"They noticed that 27% aligned sentences are identical between simple and normal, and retained them in the dataset “since not all sentences need to be simplified and it is important for any simplification algorithm to be able to handle this case”.",2 Simple Wikipedia is not that simple,[0],[0]
"However, we will show that many sentences that need to be simplified are not simplified in the Simple Wikipedia.
",2 Simple Wikipedia is not that simple,[0],[0]
We manually examined the Parallel Wikipedia Simplification (PWKP) corpus and found that it is noisy and half of its sentence pairs are not simplifications (Table 1).,2 Simple Wikipedia is not that simple,[0],[0]
"We randomly sampled 200 one-toone sentence pairs from the PWKP dataset (one-tomany sentence splitting cases consist of only 6.1% of the dataset), and classify each sentence pair into one of the three categories:
Not Aligned (17%) - Two sentences have different meanings, or only have partial content overlap.",2 Simple Wikipedia is not that simple,[0],[0]
"Not Simpler (33%)- The SIMP sentence has the same meaning as the NORM sentence, but is not simpler.",2 Simple Wikipedia is not that simple,[0],[0]
"Real Simplification (50%)- The SIMP sentence has the same meaning as the NORM sentence, and is simpler.",2 Simple Wikipedia is not that simple,[0],[0]
"We fur-
ther breakdown into whether the simplification is due to deletion or paraphrasing.
",2 Simple Wikipedia is not that simple,[0],[0]
Table 1 shows a detailed breakdown and representative examples for each category.,2 Simple Wikipedia is not that simple,[0],[0]
"Although Zhu et al. (2010) and Coster and Kauchak (2011) have provided a simple analysis on the accuracy of sentence alignment, there are some important facts that cannot be revealed without in-depth manual inspection.",2 Simple Wikipedia is not that simple,[0],[0]
The “non-simplification” noise in the parallel Simple-Normal Wikipedia data is a much more serious problem than we all thought.,2 Simple Wikipedia is not that simple,[0],[0]
"The quality of “real simplifications” also varies: some sentences are simpler by only one word while the rest of sentence is still complex.
",2 Simple Wikipedia is not that simple,[0],[0]
The main causes of non-simplifications and partial-simplifications in the parallel Wikipedia corpus include: 1),2 Simple Wikipedia is not that simple,[0],[0]
"The Simple Wikipedia was created by volunteer contributors with no specific objective; 2) Very rarely are the simple articles complete re-writes of the regular articles in Wikipedia (Coster and Kauchak, 2011), which makes automatic sentence alignment errors worse; 3)",2 Simple Wikipedia is not that simple,[0],[0]
"As an encyclopedia, Wikipedia contains many difficult sentences with complex terminology.",2 Simple Wikipedia is not that simple,[0],[0]
The difficulty of sentence alignment between Normal-Simple Wikipedia is highlighted by a recent study by Hwang et al. (2015) that achieves state-of-the-art performance of 0.712 maximum F1 score (over the precisionrecall curve) by combining Wiktionary-based and dependency-parse-based sentence similarities.,2 Simple Wikipedia is not that simple,[0],[0]
"And in fact, even the simple side of the PWKP corpus contains an extensive English vocabulary of 78,009 unique words.",2 Simple Wikipedia is not that simple,[0],[0]
"6,669 of these words do not exist in the normal side (Table 2).",2 Simple Wikipedia is not that simple,[0],[0]
"Below is a sentence from an article entitled “Photolithography"" in Simple Wikipedia:
Microphototolithography is the use of photolithography to transfer geometric shapes on a photomask to the surface of a semiconductor wafer for making integrated circuits.
",2 Simple Wikipedia is not that simple,[0],[0]
We should use the PWKP corpus with caution and consider other alternative parallel simplification corpora.,2 Simple Wikipedia is not that simple,[0],[0]
"Alternatives could come from Wikipedia (but better aligned and selected) or from manual simplification of other domains, such as newswire.",2 Simple Wikipedia is not that simple,[0],[0]
"In the
next section, we will present a corpus of news articles simplified by professional editors, called the Newsela corpus.",2 Simple Wikipedia is not that simple,[0],[0]
We perform a comparative corpus analysis of the Newsela corpus versus the PWKP corpus to further illustrate concerns about PWKP’s quality.,2 Simple Wikipedia is not that simple,[0],[0]
"To study how professional editors conduct text simplification, we have assembled a new simplification dataset that consists of 1,130 news articles.",3 What the Newsela corpus teaches us,[0],[0]
"Each article has been re-written 4 times for children at different grade levels by editors at Newsela2, a company that produces reading materials for pre-college classroom use.",3 What the Newsela corpus teaches us,[0],[0]
We use Simp-4 to denote the most simplified level and Simp-1 to denote the least simplified level.,3 What the Newsela corpus teaches us,[0],[0]
"This data forms a parallel corpus, where we can align sentences at different reading levels, as shown in Table 3.
",3 What the Newsela corpus teaches us,[0],[0]
"Unlike Simple Wikipedia, which was created without a well-defined objective, Newsela is meant to help teachers prepare curricula that match the English language skills required at each grade level.",3 What the Newsela corpus teaches us,[0],[0]
"It is motivated by the Common Core Standards (Porter et al., 2011) in the United States.",3 What the Newsela corpus teaches us,[0],[0]
"All the Newsela articles are grounded in the Lexile3 readability score, which is widely used to measure text complexity and assess students’ reading ability.",3 What the Newsela corpus teaches us,[0],[0]
We conducted a manual examination of the Newsela data similar to the one for Wikipedia data in Table 1.,3.1 Manual examination of Newsela corpus,[0],[0]
"The breakdown of aligned sentence pairs between different versions in Newsela is shown in Figure 1.
2https://newsela.com/",3.1 Manual examination of Newsela corpus,[0],[0]
"3http://en.wikipedia.org/wiki/Lexile
It is based on 50 randomly selected sentence pairs and shows much more reliable simplification than the Wikipedia data.
",3.1 Manual examination of Newsela corpus,[0],[0]
"We designed a sentence alignment algorithm for the Newsela corpus based on Jaccard similarity (Jaccard, 1912).",3.1 Manual examination of Newsela corpus,[0],[0]
We first align each sentence in the simpler version (e.g. s1 in Simp-3) to the sentence in the immediate more complex version (e.g. s2 in Simp2) of the highest similarity score.,3.1 Manual examination of Newsela corpus,[0],[0]
"We compute the similarity based on overlapping word lemmas:4
Sim(s1, s2) = |Lemmas(s1) ∩ Lemmas(s2)| |Lemmas(s1) ∪ Lemmas(s2)|
(1) We then align sentences into groups across all 5 versions for each article.",3.1 Manual examination of Newsela corpus,[0],[0]
"For cases where no sentence splitting is involved, we discard any sentence pairs with a similarity smaller than 0.40.",3.1 Manual examination of Newsela corpus,[0],[0]
"If splitting occurs, we set the similarity threshold to 0.20 instead.
",3.1 Manual examination of Newsela corpus,[0],[0]
Newsela’s professional editors produce simplifications with noticeably higher quality than Wikipedia’s simplifications.,3.1 Manual examination of Newsela corpus,[0],[0]
"Compared to sentence alignment for Normal-Simple Wikipedia, automatically aligning Newsela is more straightforward and reliable.",3.1 Manual examination of Newsela corpus,[0],[0]
"The better correspondence between the simplified and complex articles and the availability of multiple simplified versions in the Newsela data also contribute to the accuracy of sentence alignment.
",3.1 Manual examination of Newsela corpus,[0],[0]
4We use the WordNet lemmatization in the NLTK package: http://www.nltk.org/,3.1 Manual examination of Newsela corpus,[0],[0]
Table 4 shows the basic statistics of the Newsela corpus and the PWKP corpus.,3.2 Vocabulary statistics,[0],[0]
They are clearly different.,3.2 Vocabulary statistics,[0],[0]
"Compared to the Newsela data, the Wikipedia corpus contains remarkably longer (more complex) words and the difference of sentence length before and after simplification is much smaller.",3.2 Vocabulary statistics,[0],[0]
"We use the Penn Treebank tokenizer in the Moses package.5
Tables 2 and 5 show the vocabulary statistics and the vocabulary difference matrix of the PWKP and Newsela corpus.",3.2 Vocabulary statistics,[0],[0]
"While the vocabulary size of the PWKP corpus drops only 18% from 95,111 unique words to 78,009, the vocabulary size of the Newsela corpus is reduced dramatically by 50.8% from 39,046 to 19,197 words at its most simplified level (Simp-4).",3.2 Vocabulary statistics,[0],[0]
"Moreover, in the Newsela data, only several hundred words that occur in the simpler version do not occur in the more complex version.",3.2 Vocabulary statistics,[0],[0]
"The words introduced are often abbreviations (“National Hurricane Center” → “NHC”), less formal words (“unscrupulous”→ “crooked”) and shortened words (“chimpanzee” → “chimp”).",3.2 Vocabulary statistics,[0],[0]
This implies a more complete and precise degree of simplification in the Newsela than the PWKP dataset.,3.2 Vocabulary statistics,[0],[0]
"In this section, we visualize the differences in the topics and degree of simplification between the Simple Wikipedia and the Newsela corpus.",3.3 Log-odds-ratio analysis of words,[0],[0]
"To do this, we employ the log-odds-ratio informative Dirichlet prior method of Monroe et al. (2008) to find words and punctuation marks that are statistically overrepresented in the simplified text compared to the original text.",3.3 Log-odds-ratio analysis of words,[0],[0]
"The method measures each token by the z-score of its log-odds-ratio as:
δ (i−j) t√
σ2(δ (i−j) t )
(2)
It uses a background corpus when calculating the log-odds-ratio δt for token t, and controls for its variance σ2.",3.3 Log-odds-ratio analysis of words,[0],[0]
Therefore it is capable of detecting differences even in very frequent tokens.,3.3 Log-odds-ratio analysis of words,[0],[0]
"Other methods used to discover word associations, such as mu-
5https://github.com/moses-smt/ mosesdecoder/blob/master/scripts/ tokenizer/tokenizer.perl
tual information, log likelihood ratio, t-test and chisquare, often have problems with frequent words (Jurafsky et al., 2014).",3.3 Log-odds-ratio analysis of words,[0],[0]
"We choose the Monroe et al. (2008) method because many function words and punctuations are very frequent and play important roles in text simplification.
",3.3 Log-odds-ratio analysis of words,[0],[0]
"The log-odds-ratio δ(i−j)t for token t estimates the difference of the frequency of token t between two text sets i and j as:
δ (i−j) t = log( yit + αt ni + α0 − (yit + αt) )
",3.3 Log-odds-ratio analysis of words,[0],[0]
"− log( y j t + αt
nj + α0 − (yjt + αt) )
(3)
where ni is the size of corpus i, nj is the size of corpus j, yit is the count of token t in corpus i, y j t is the count of token t in corpus j, α0 is the size of the background corpus, and αt is the count of token t in the background corpus.",3.3 Log-odds-ratio analysis of words,[0],[0]
"We use the combination of both simple and complex sides in the corpus as the background.
",3.3 Log-odds-ratio analysis of words,[0],[0]
"And the variance of the log-odds-ratio is estimated by:
σ2(δ (i−j) t )",3.3 Log-odds-ratio analysis of words,[0],[0]
"≈
1
yit + αt +
1
yjt + αt (4)
Table 6 lists the top 50 words and punctuation marks that are the most strongly associated with the complex text.",3.3 Log-odds-ratio analysis of words,[0],[0]
Both corpora significantly reduce function words and punctuation.,3.3 Log-odds-ratio analysis of words,[0],[0]
The content words show the differences of the topics and subject matters between the two corpora.,3.3 Log-odds-ratio analysis of words,[0],[0]
Table 7 lists the top 50 words that are the most strongly associated with the simplified text.,3.3 Log-odds-ratio analysis of words,[0],[0]
"The two corpora are more agreeable on what the simple words are than what complex words need to be simplified.
",3.3 Log-odds-ratio analysis of words,[0],[0]
Table 8 shows the frequency and odds ratio of example words from the top 50 complex words.,3.3 Log-odds-ratio analysis of words,[0],[0]
"The odds ratio of token t between two texts sets i and j is defined as:
r (i−j) t =
yit/y j t ni/nj (5)
",3.3 Log-odds-ratio analysis of words,[0],[0]
It reflects the difference of topics and degree of simplification between the Wikipedia and the Newsela data.,3.3 Log-odds-ratio analysis of words,[0],[0]
"The high proportion of clause-related function words, such as “which” and “where”,
that are retained in Simple Wikipedia indicates the incompleteness of simplification in the Simple Wikipedia.",3.3 Log-odds-ratio analysis of words,[0],[0]
The dramatic frequency decrease of words like “which” and “advocates” in Newsela shows the consistent quality from professional simplifications.,3.3 Log-odds-ratio analysis of words,[0],[0]
"Wikipedia has good coverage on certain words, such as “approximately”, because of its large volume.",3.3 Log-odds-ratio analysis of words,[0],[0]
We can also reveal the syntax patterns that are most strongly associated with simple text versus complex text using the log-odds-ratio technique.,3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
"Table 9 shows syntax patterns that represent “parent node (head word) → children node(s)"" structures from a constituency parse tree.",3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
"To extract theses patterns we parsed our corpus with the Stanford Parser (Klein and Manning, 2002) and applied its built-in head word identifier from Collins (2003).",3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
Both the Newsela and Wikipedia corpora exhibit syntactic differences that are intuitive and interesting.,3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
"However, as with word frequency (Table 8),
complex syntactic patterns are retained more often in Wikipedia’s simplifications than in Newsela’s.
",3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
"In order to show interesting syntax patterns in the Wikipedia parallel data for Table 9, we first had to discard 3613 sentences in PWKP that contain both ""is a commune"" and ""France"".",3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
"As the word-level analysis in Tables 6 and 7 hints, there is an exceeding number of sentences about communes in France in the PWKP corpus, such as the sentence pair below:
[NORM]",3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
"La Couture is a commune in the Pas-de-Calais department in the Nord-Pas-de-Calais region of France .
",3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
"[SIMP] La Couture, Pas-de-Calais is a commune.",3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
"It is found in the region Nord-Pas-de-Calais in the Pas-de-Calais department in the north of France.
",3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
This is a template sentence from a stub geographic article and its deterministic simplification.,3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
"The influence of this template sentence is more over-
whelming in the syntax-level analysis than in the word-level analysis —- about 1/3 of the top 30 syntax patterns would be related to these sentence pairs if they were not discarded.",3.4 Log-odds-ratio analysis of syntax patterns,[0],[0]
"There are few publicly accessible document-level parallel simplification corpora (Barzilay and Lapata, 2008).",3.5 Document-level compression,[0],[0]
"The Newsela corpus will enable more research on document-level simplification, such as anaphora choice (Siddharthan and Copestake, 2002), content selection (Woodsend and Lapata, 2011b), and discourse relation preservation (Siddharthan, 2003).
",3.5 Document-level compression,[0],[0]
Simple Wikipedia is rarely used to study document-level simplification.,3.5 Document-level compression,[0],[0]
Woodsend and Lapata (2011b) developed a model that simplifies Wikipedia articles while selecting their most important content.,3.5 Document-level compression,[0],[0]
"However, they could only use Simple Wikipedia in very limited ways.",3.5 Document-level compression,[0],[0]
"They noted that Simple Wikipedia is “less mature” with many articles that are just “stubs, comprising a single paragraph of just one or two sentences”.",3.5 Document-level compression,[0],[0]
"We quantify their observation in Figure 2, plotting the documentlevel compression ratio of Simple vs. Normal Wikipedia articles.",3.5 Document-level compression,[0],[0]
The compression ratio is the ratio of the number of characters between each simple-complex article pair.,3.5 Document-level compression,[0],[0]
"In the plot, we use all 60 thousand article pairs from the Simple-Normal Wikipedia collected by Kauchak (2013) in May 2011.",3.5 Document-level compression,[0],[0]
The overall compression ratio is skewed towards almost 0.,3.5 Document-level compression,[0],[0]
"For comparison, we also plot the ratio between the simplest version (Simp-4) and the original version (Original) of the news articles in the Newsela corpus.",3.5 Document-level compression,[0],[0]
The Newsela corpus has a much more reasonable compression ratio and is therefore likely to be more suitable for studying documentlevel simplification.,3.5 Document-level compression,[0],[0]
"Although discourse is known to affect readability, the relation between discourse and text simplification is still under-studied with the use of statistical methods (Williams et al., 2003; Siddharthan, 2006; Siddharthan and Katsos, 2010).",3.6 Analysis of discourse connectives,[0],[0]
"Text simplification often involves splitting one sentence into multiple sentences, which is likely to require discourse-level changes such as introducing explicit rhetorical rela-
tions.",3.6 Analysis of discourse connectives,[0],[0]
"However, previous research that uses SimpleNormal Wikipedia largely focuses on sentence-level transformation, without taking large discourse structure into account.
",3.6 Analysis of discourse connectives,[0],[0]
"To preserve the rhetorical structure, Siddharthan (2003, 2006) proposed to introduce cue words when simplifying various conjoined clauses.",3.6 Analysis of discourse connectives,[0],[0]
We perform an analysis on discourse connectives that are relevant to readability as suggested by Siddharthan (2003).,3.6 Analysis of discourse connectives,[0],[0]
Figure 3 presents the odds ratios of simple cue words and complex conjunction connectives.,3.6 Analysis of discourse connectives,[0],[0]
"The odds radios are computed for Newsela between the Original and Simp-4 versions, and for Wikipedia between Normal and Simple documents collected by Kauchak (2013).",3.6 Analysis of discourse connectives,[0],[0]
"It suggests that Newsela exhibits a more complete degree of simplification than Wikipedia, and that it may be able to enable more computational studies of the role of discourse in text simplification in the future.
",3.6 Analysis of discourse connectives,[0],[0]
"Newsela
Wikipedia",3.6 Analysis of discourse connectives,[0],[0]
"Overall, we have shown that the professional simplification of Newsela is more rigorous and more consistent than Simple English Wikipedia.",3.7 Newsela’s quality is better than Wikipedia,[0],[0]
The language and content also differ between the encyclopedia and news domains.,3.7 Newsela’s quality is better than Wikipedia,[0],[0]
They are not exchangeable in developing nor in evaluating simplification systems.,3.7 Newsela’s quality is better than Wikipedia,[0],[0]
"In the next section, we will review the evaluation methodology used in recent research, discuss its shortcomings and propose alternative evaluations.",3.7 Newsela’s quality is better than Wikipedia,[0],[0]
"With the popularity of parallel Wikipedia data in simplification research, most state-of-the-art systems evaluate on simplifying sentences from Wikipedia.",4 Evaluation of simplification systems,[0],[0]
"All simplification systems published in the ACL, NAACL, EACL, COLING and EMNLP main conferences since Zhu’s 2010 work compared solely on the same test set that consists of only 100 sentences from Wikipedia, except one paper that additionally experimented with 5 short news summaries.",4 Evaluation of simplification systems,[0],[0]
"The most widely practiced evaluation methodology is to have human judges rate on grammaticality (or fluency), simplicity, and adequacy (or meaning preservation) on a 5-point Likert scale.
",4 Evaluation of simplification systems,[0],[0]
"Such evaluation is insufficient to measure 1) the practical value of a system to a specific target reader population and 2) the performance of individual simplification components: sentence splitting, dele-
tion and paraphrasing.",4 Evaluation of simplification systems,[0],[0]
"Although the inadequacy of text simplification evaluations has been discussed before (Siddharthan, 2014), we focus on these two common deficiencies and suggest two future directions.",4 Evaluation of simplification systems,[0],[0]
"Simplification has many subtleties, since what constitutes simplification for one type of user may not be appropriate for another.",4.1 Targeting specific audiences,[0],[0]
Many researchers have studied simplification in the context of different audiences.,4.1 Targeting specific audiences,[0],[0]
"However, most recent automatic simplification systems are developed and evaluated with little consideration of target reader population.",4.1 Targeting specific audiences,[0],[0]
There is one attempt by Angrosh et al. (2014) who evaluate their system by asking non-native speakers comprehension questions.,4.1 Targeting specific audiences,[0],[0]
"They conducted an English vocabulary size test to categorize the users into different levels of language skills.
",4.1 Targeting specific audiences,[0],[0]
The Newsela corpus allows us to target children at different grade levels.,4.1 Targeting specific audiences,[0],[0]
"From the application point of view, making knowledge accessible to all children is an important yet challenging part of education (Scarton et al., 2010; Moraes et al., 2014).",4.1 Targeting specific audiences,[0],[0]
"From the technical point of view, reading grade level is a clearly defined objective for both simplification systems and human annotators.",4.1 Targeting specific audiences,[0],[0]
"Once there is a well-defined objective, with constraints such as vocabulary size and sentence length, it is easier to fairly compare different systems.",4.1 Targeting specific audiences,[0],[0]
"Newsela provides human simplification
at different grade levels and reading comprehension quizzes alongside each article.
",4.1 Targeting specific audiences,[0],[0]
"In addition, readability is widely studied and can be automatically estimated (Kincaid et al., 1975; Pitler and Nenkova, 2008; Petersen and Ostendorf, 2009).",4.1 Targeting specific audiences,[0],[0]
"Although existing readability metrics assume text is well-formed, they can potentially be used in combination with text quality metrics (Post, 2011; Louis and Nenkova, 2013) to evaluate simplifications.",4.1 Targeting specific audiences,[0],[0]
They can also be used to aid humans in the creation of reference simplifications.,4.1 Targeting specific audiences,[0],[0]
"It is widely accepted that sentence simplification involves three different elements: splitting, deletion and paraphrasing (Feng, 2008; Narayan and Gardent, 2014).",4.2 Evaluating sub-tasks separately,[0],[0]
Splitting breaks a long sentence into a few short sentences to achieve better readability.,4.2 Evaluating sub-tasks separately,[0],[0]
Deletion reduces the complexity by removing unimportant parts of a sentence.,4.2 Evaluating sub-tasks separately,[0],[0]
"Paraphrasing rewrites text into a simpler version via reordering, substitution and occasionally expansion.
",4.2 Evaluating sub-tasks separately,[0],[0]
Most state-of-the-art systems consist of all or a subset of these three components.,4.2 Evaluating sub-tasks separately,[0],[0]
"However, the popular human evaluation criteria (grammaticality, simplicity and adequacy) do not explain which components in a system are good or bad.",4.2 Evaluating sub-tasks separately,[0],[0]
"More importantly, deletion may be unfairly penalized since shorter output tends to result in lower adequacy judgements (Napoles et al., 2011).
",4.2 Evaluating sub-tasks separately,[0],[0]
We therefore advocate for a more informative evaluation that separates out each sub-task.,4.2 Evaluating sub-tasks separately,[0],[0]
We believe this will lead to more easily quantifiable metrics and possibly the development of automatic metrics.,4.2 Evaluating sub-tasks separately,[0],[0]
"For example, early work shows potential use of precision and recall to evaluate splitting (Siddharthan, 2006; Gasperin et al., 2009) and deletion (Riezler et al., 2003; Filippova and Strube, 2008).",4.2 Evaluating sub-tasks separately,[0],[0]
"Several studies also have investigated various metrics for evaluating sentence paraphrasing (CallisonBurch et al., 2008; Chen and Dolan, 2011; Ganitkevitch et al., 2011; Xu et al., 2012, 2013; Weese et al., 2014).",4.2 Evaluating sub-tasks separately,[0],[0]
"In this paper, we presented the first systematic analysis of the quality of Simple Wikipedia as a simpli-
fication data resource.",5 Summary and recommendations,[0],[0]
"We conducted a qualitative manual examination and several statistical analyses (including vocabulary change matrices, compression ratio histograms, log-odds-ratio calculations, etc.).",5 Summary and recommendations,[0],[0]
"We introduced a new, high-quality corpus of professionally simplified news articles, Newsela, as an alternative resource, that allowed us to demonstrate Simple Wikipedia’s inadequacies in comparison.",5 Summary and recommendations,[0],[0]
"We further discussed problems with current simplification evaluation methodology and proposed potential improvements.
",5 Summary and recommendations,[0],[0]
Our goal for this opinion paper is to stimulate progress in text simplification research.,5 Summary and recommendations,[0],[0]
Simple English Wikipedia played a vital role in inspiring simplification approaches based on statistical machine translation.,5 Summary and recommendations,[0],[0]
"However, it has so many drawbacks that we recommend the community to drop it as the standard benchmark set for simplification.",5 Summary and recommendations,[0],[0]
"Other resources like the Newsela corpus are superior, since they provide a more consistent level of quality, target a particular audience, and approach the size of parallel Simple-Normal English Wikipedia.",5 Summary and recommendations,[0],[0]
We believe that simplification is an important area of research that has the potential for broader impact beyond NLP research.,5 Summary and recommendations,[0],[0]
"But we must first adopt appropriate data sets and research methodologies.
",5 Summary and recommendations,[0],[0]
Researchers can request the Newsela data following the instructions at: https://newsela. com/data/,5 Summary and recommendations,[0],[0]
"The authors would like to thank Dan Cogan-Drew, Jennifer Coogan, and Kieran Sobel from Newsela for creating their data and generously sharing it with us.",Acknowledgments,[0],[0]
"We also thank action editor Rada Mihalcea and three anonymous reviewers for their thoughtful comments, and Ani Nenkova, Alan Ritter and Maxine Eskenazi for valuable discussions.
",Acknowledgments,[0],[0]
This material is based on research sponsored by the NSF under grant IIS-1430651.,Acknowledgments,[0],[0]
The views and conclusions contained in this publication are those of the authors and should not be interpreted as representing official policies or endorsements of the NSF or the U.S. Government.,Acknowledgments,[0],[0]
Simple Wikipedia has dominated simplification research in the past 5 years.,abstractText,[0],[0]
"In this opinion paper, we argue that focusing on Wikipedia limits simplification research.",abstractText,[0],[0]
We back up our arguments with corpus analysis and by highlighting statements that other researchers have made in the simplification literature.,abstractText,[0],[0]
"We introduce a new simplification dataset that is a significant improvement over Simple Wikipedia, and present a novel quantitative-comparative approach to study the quality of simplification data resources.",abstractText,[0],[0]
Problems in Current Text Simplification Research: New Data Can Help,title,[0],[0]
Behaving intelligently often requires mathematical reasoning.,1 Introduction,[0],[0]
"Shopkeepers calculate change, tax, and sale prices; agriculturists calculate the proper amounts of fertilizers, pesticides, and water for their crops; and managers analyze productivity.",1 Introduction,[0],[0]
"Even determining whether you have enough money to pay for a list of items requires applying addition, multiplication, and comparison.",1 Introduction,[0],[0]
"Solving these tasks is challenging as it involves recognizing how goals, entities, and quantities in the real-world map onto a mathematical formalization, computing the solution, and mapping the solution back onto the world.",1 Introduction,[0],[0]
"As a proxy for the richness of the real world, a series of papers have
used natural language specifications of algebraic word problems, and solved these by either learning to fill in templates that can be solved with equation solvers (Hosseini et al., 2014; Kushman et al., 2014) or inferring and modeling operation sequences (programs) that lead to the final answer (Roy and Roth, 2015).
",1 Introduction,[0],[0]
"In this paper, we learn to solve algebraic word problems by inducing and modeling programs that generate not only the answer, but an answer rationale, a natural language explanation interspersed with algebraic expressions justifying the overall solution.",1 Introduction,[0],[0]
Such rationales are what examiners require from students in order to demonstrate understanding of the problem solution; they play the very same role in our task.,1 Introduction,[0],[0]
"Not only do natural language rationales enhance model interpretability, but they provide a coarse guide to the structure of the arithmetic programs that must be executed.",1 Introduction,[0],[0]
"In fact the learner we propose (which relies on a heuristic search; §4) fails to solve this task without modeling the rationales—the search space is too unconstrained.
",1 Introduction,[0],[0]
"This work is thus related to models that can explain or rationalize their decisions (Hendricks et al., 2016; Harrison et al., 2017).",1 Introduction,[0],[0]
"However, the use of rationales in this work is quite different from the role they play in most prior work, where interpretation models are trained to generate plausible sounding (but not necessarily accurate) posthoc descriptions of the decision making process they used.",1 Introduction,[0],[0]
"In this work, the rationale is generated as a latent variable that gives rise to the answer—it is thus a more faithful representation of the steps used in computing the answer.
",1 Introduction,[0],[0]
This paper makes three contributions.,1 Introduction,[0],[0]
"First, we have created a new dataset with more than 100,000 algebraic word problems that includes both answers and natural language answer rationales (§2).",1 Introduction,[0],[0]
"Figure 1 illustrates three representative instances
ar X
iv :1
70 5.
04 14
6v 3
[ cs
.A",1 Introduction,[0],[0]
"I]
2 3
O ct
2 01
7
from the dataset.",1 Introduction,[0],[0]
"Second, we propose a sequence to sequence model that generates a sequence of instructions that, when executed, generates the rationale; only after this is the answer chosen (§3).",1 Introduction,[0],[0]
"Since the target program is not given in the training data (most obviously, its specific form will depend on the operations that are supported by the program interpreter); the third contribution is thus a technique for inferring programs that generate a rationale and, ultimately, the answer.",1 Introduction,[0],[0]
"Even constrained by a text rationale, the search space of possible programs is quite large, and we employ a heuristic search to find plausible next steps to guide the search for programs (§4).",1 Introduction,[0],[0]
"Empirically, we are able to show that state-of-the-art sequence to sequence models are unable to perform above chance on this task, but that our model doubles the accuracy of the baseline (§6).",1 Introduction,[0],[0]
"We built a dataset1 with 100,000 problems with the annotations shown in Figure 1.",2 Dataset,[0],[0]
"Each question is decomposed in four parts, two inputs and two outputs: the description of the problem, which we will denote as the question, and the possible (multiple choice) answer options, denoted as options.",2 Dataset,[0],[0]
"Our goal is to generate the description of the rationale used to reach the correct answer, denoted as rationale and the correct option label.",2 Dataset,[0],[0]
"Problem 1 illustrates an example of an algebra problem, which must be translated into an expression (i.e., (27x + 17y)/(x + y) = 23) and then the desired quantity (x/y) solved for.",2 Dataset,[0],[0]
"Problem 2 is an example that could be solved by multi-step arithmetic operations proposed in (Roy and Roth, 2015).",2 Dataset,[0],[0]
"Finally, Problem 3 describes a problem that is solved by testing each of the options, which has not been addressed in the past.",2 Dataset,[0],[0]
"We first collect a set of 34,202 seed problems that consist of multiple option math questions covering a broad range of topics and difficulty levels.",2.1 Construction,[0],[0]
Examples of exams with such problems include the GMAT (Graduate Management Admission Test) and GRE (General Test).,2.1 Construction,[0],[0]
"Many websites contain example math questions in such exams, where the answer is supported by a rationale.
",2.1 Construction,[0],[0]
"Next, we turned to crowdsourcing to generate new questions.",2.1 Construction,[0],[0]
We create a task where users are presented with a set of 5 questions from our seed dataset.,2.1 Construction,[0],[0]
"Then, we ask the Turker to choose one of the questions and write a similar question.",2.1 Construction,[0],[0]
We also force the answers and rationale to differ from the original question in order to avoid paraphrases of the original question.,2.1 Construction,[0],[0]
"Once again, we manually check a subset of the jobs for each Turker for quality control.",2.1 Construction,[0],[0]
The type of questions generated using this method vary.,2.1 Construction,[0],[0]
"Some turkers propose small changes in the values of the questions (e.g., changing the equality p(a)",2.1 Construction,[0],[0]
− p(b) =,2.1 Construction,[0],[0]
"p(a − b) in Problem 3 to a different equality is a valid question, as long as the rationale and options are rewritten to reflect the change).",2.1 Construction,[0],[0]
We designate these as replica problems as the natural language used in the question and rationales tend to be only minimally unaltered.,2.1 Construction,[0],[0]
"Others propose new problems in the same topic where the generated questions tend to dif-
1Available at https://github.com/deepmind/ AQuA
fer more radically from existing ones.",2.1 Construction,[0],[0]
"Some Turkers also copy math problems available on the web, and we define in the instructions that this is not allowed, as it will generate multiple copies of the same problem in the dataset if two or more Turkers copy from the same resource.",2.1 Construction,[0],[0]
These Turkers can be detected by checking the nearest neighbours within the collected datasets as problems obtained from online resources are frequently submitted by more than one Turker.,2.1 Construction,[0],[0]
"Using this method, we obtained 70,318 additional questions.",2.1 Construction,[0],[0]
Descriptive statistics of the dataset is shown in Figure 1.,2.2 Statistics,[0],[0]
"In total, we collected 104,519 problems (34,202 seed problems and 70,318 crowdsourced problems).",2.2 Statistics,[0],[0]
We removed 500 problems as heldout set (250 for development and 250 for testing).,2.2 Statistics,[0],[0]
"As replicas of the heldout problems may be present in the training set, these were removed manually by listing for each heldout instance the closest problems in the training set in terms of character-based Levenstein distance.",2.2 Statistics,[0],[0]
"After filtering, 100,949 problems remained in the training set.
",2.2 Statistics,[0],[0]
"We also show the average number of tokens (total number of tokens in the question, options and rationale) and the vocabulary size of the questions and rationales.",2.2 Statistics,[0],[0]
"Finally, we provide the same statistics exclusively for tokens that are numeric values and tokens that are not.
",2.2 Statistics,[0],[0]
Figure 2 shows the distribution of examples based on the total number of tokens.,2.2 Statistics,[0],[0]
"We can see that most examples consist of 30 to 500 tokens, but there are also extremely long examples with more than 1000 tokens in our dataset.",2.2 Statistics,[0],[0]
"Generating rationales for math problems is challenging as it requires models that learn to perform math operations at a finer granularity as
each step within the solution must be explained.",3 Model,[0],[0]
"For instance, in Problem 1, the equation (27x + 17y)/(x + y) = 23 must be solved to obtain the answer.",3 Model,[0],[0]
"In previous work (Kushman et al., 2014), this could be done by feeding the equation into an expression solver to obtain x/y = 3/2.",3 Model,[0],[0]
"However, this would skip the intermediate steps 27x+17y = 23x+23y and 4x = 6y, which must also be generated in our problem.",3 Model,[0],[0]
"We propose a model that jointly learns to generate the text in the rationale, and to perform the math operations required to solve the problem.",3 Model,[0],[0]
"This is done by generating a program, containing both instructions that generate output and instructions that simply generate intermediate values used by following instructions.",3 Model,[0],[0]
"In traditional sequence to sequence models (Sutskever et al., 2014; Bahdanau et al., 2014), the goal is to predict the output sequence y = y1, . . .",3.1 Problem Definition,[0],[0]
", y|y| from the input sequence x = x1, . . .",3.1 Problem Definition,[0],[0]
", x|x|, with lengths |y| and |x|.
",3.1 Problem Definition,[0],[0]
"In our particular problem, we are given the problem and the set of options, and wish to predict the rationale and the correct option.",3.1 Problem Definition,[0],[0]
"We set x as the sequence of words in the problem, concatenated with words in each of the options separated by a special tag.",3.1 Problem Definition,[0],[0]
Note that knowledge about the possible options is required as some problems are solved by the process of elimination or by testing each of the options (e.g. Problem 3).,3.1 Problem Definition,[0],[0]
"We wish to generate y, which is the sequence of words in the rationale.",3.1 Problem Definition,[0],[0]
"We also append the correct option as the last word in y, which is interpreted as the chosen option.",3.1 Problem Definition,[0],[0]
"For example, y in Problem 1 is “Let the . . .",3.1 Problem Definition,[0],[0]
= 3/2 .,3.1 Problem Definition,[0],[0]
"〈EOR〉 B 〈EOS〉”, whereas in Problem 2 it is “Let s be . . .",3.1 Problem Definition,[0],[0]
"Answer is C 〈EOR〉 C 〈EOS〉”, where “〈EOS〉” is the end of sentence symbol and
“〈EOR〉” is the end of rationale symbol.",3.1 Problem Definition,[0],[0]
"We wish to generate a latent sequence of program instructions, z = z1, . . .",3.2 Generating Programs to Generate Rationales,[0],[0]
", z|z|, with length |z|, that will generate y when executed.
",3.2 Generating Programs to Generate Rationales,[0],[0]
"We express z as a program that can access x, y, and the memory buffer m. Upon finishing execution we expect that the sequence of output tokens to be placed in the output vector y.
Table 2 illustrates an example of a sequence of instructions that would generate an excerpt from Problem 2, where columns x, z, v, and r denote the input sequence, the instruction sequence (program), the values of executing the instruction, and where each value vi is written (i.e., either to the output or to the memory).",3.2 Generating Programs to Generate Rationales,[0],[0]
"In this example, instructions from indexes 1 to 14 simply fill each position with the observed output y1, . . .",3.2 Generating Programs to Generate Rationales,[0],[0]
", y14 with a string,
where the Id operation simply returns its parameter without applying any operation.",3.2 Generating Programs to Generate Rationales,[0],[0]
"As such, running this operation is analogous to generating a word by sampling from a softmax over a vocabulary.",3.2 Generating Programs to Generate Rationales,[0],[0]
"However, instruction z15 reads the input word x5, 52, and applies the operation Str to Float, which converts the word 52 into a floating point number, and the same is done for instruction z20, which reads a previously generated output word y17.",3.2 Generating Programs to Generate Rationales,[0],[0]
"Unlike, instructions z1, . . .",3.2 Generating Programs to Generate Rationales,[0],[0]
", z14, these operations write to the external memory m, which stores intermediate values.",3.2 Generating Programs to Generate Rationales,[0],[0]
"A more sophisticated instruction—which shows some of the power of our model—is z21 = Choose(m1,m2) → m3 which evaluates ( m1 m2 ) and stores the result in m3.",3.2 Generating Programs to Generate Rationales,[0],[0]
This process repeats until the model generates the end-of-sentence symbol.,3.2 Generating Programs to Generate Rationales,[0],[0]
"The last token of the program as said previously must generate the correct option value, from “A” to “E”.
",3.2 Generating Programs to Generate Rationales,[0],[0]
"By training a model to generate instructions that can manipulate existing tokens, the model benefits from the additional expressiveness needed to solve math problems within the generation process.",3.2 Generating Programs to Generate Rationales,[0],[0]
"In total we define 22 different operations, 13 of which are frequently used operations when solving math problems.",3.2 Generating Programs to Generate Rationales,[0],[0]
"These are: Id, Add, Subtract, Multiply, Divide, Power, Log, Sqrt, Sine, Cosine, Tangent, Factorial, and Choose (number of combinations).",3.2 Generating Programs to Generate Rationales,[0],[0]
"We also provide 2 operations to convert between Radians and Degrees, as these are needed for the sine, cosine and tangent operations.",3.2 Generating Programs to Generate Rationales,[0],[0]
There are 6 operations that convert floating point numbers into strings and vice-versa.,3.2 Generating Programs to Generate Rationales,[0],[0]
"These include the Str to Float and Float to Str operations described previously, as well as operations which convert between floating point numbers and fractions, since in many math problems the answers are in the form “3/4”.",3.2 Generating Programs to Generate Rationales,[0],[0]
"For the same reason, an operation to convert between a floating point number and number grouped in thousands is also used (e.g. 1000000 to “1,000,000” or “1.000.000”).",3.2 Generating Programs to Generate Rationales,[0],[0]
"Finally, we define an operation (Check) that given the input string, searches through the list of options and returns a string with the option index in {“A”, “B”, “C”, “D”, “E”}.",3.2 Generating Programs to Generate Rationales,[0],[0]
"If the input value does not match any of the options, or more than one option contains that value, it cannot be applied.",3.2 Generating Programs to Generate Rationales,[0],[0]
"For instance, in Problem 2, once the correct probability “1/221” is generated, by applying the check operation to this number we can
obtain correct option “C”.",3.2 Generating Programs to Generate Rationales,[0],[0]
"In our model, programs consist of sequences of instructions, z. We turn now to how we model each zi, conditional on the text program specification, and the program’s history.",3.3 Generating and Executing Instructions,[0],[0]
"The instruction zi is a tuple consisting of an operation (oi), an ordered sequence of its arguments (ai), and a decision about where its results will be placed (ri) (is it appended in the output y or in a memory buffer m?), and the result of applying the operation to its arguments (vi).",3.3 Generating and Executing Instructions,[0],[0]
"That is, zi = (oi, ri,ai, vi).
",3.3 Generating and Executing Instructions,[0],[0]
"Formally, oi is an element of the pre-specified set of operations O, which contains, for example add, div, Str to Float, etc.",3.3 Generating and Executing Instructions,[0],[0]
"The number of arguments required by oi is given by argc(oi), e.g., argc(add)",3.3 Generating and Executing Instructions,[0],[0]
= 2 and argc(log),3.3 Generating and Executing Instructions,[0],[0]
= 1.,3.3 Generating and Executing Instructions,[0],[0]
"The arguments are ai = ai,1, . . .",3.3 Generating and Executing Instructions,[0],[0]
", ai,argc(oi).",3.3 Generating and Executing Instructions,[0],[0]
"An instruction will generate a return value vi upon execution, which will either be placed in the output y or hidden.",3.3 Generating and Executing Instructions,[0],[0]
This decision is controlled by ri.,3.3 Generating and Executing Instructions,[0],[0]
"We define the instruction probability as:
p(oi,ai, ri,vi | z<i,x,y,m) = p(oi | z<i,x)× p(ri |",3.3 Generating and Executing Instructions,[0],[0]
"z<i,x, oi)×
argc(oi)∏ j=1 p(ai,j | z<i,x, oi,m,y)×
[vi = apply(oi,a)],
where [p] evaluates to 1 if p is true and 0 otherwise, and apply(f,x) evaluates the operation f with arguments",3.3 Generating and Executing Instructions,[0],[0]
"x. Note that the apply function is not learned, but pre-defined.
",3.3 Generating and Executing Instructions,[0],[0]
The network used to generate an instruction at a given timestamp i is illustrated in Figure 3.,3.3 Generating and Executing Instructions,[0],[0]
"We
first use the recurrent state hi to generate p(oi | z<i,x) = softmax
",3.3 Generating and Executing Instructions,[0],[0]
"oi∈O (hi), using a softmax over the
set of available operations O.",3.3 Generating and Executing Instructions,[0],[0]
"In order to predict ri, we generate a new hidden state ri, which is a function of the current program context hi, and an embedding of the current predicted operation, oi.",3.3 Generating and Executing Instructions,[0],[0]
"As the output can either be placed in the memory m or the output y, we compute the probability p(ri =",3.3 Generating and Executing Instructions,[0],[0]
"OUTPUT | z<i,x, oi) = σ(ri · wr + br), where σ is the logistic sigmoid function.",3.3 Generating and Executing Instructions,[0],[0]
"If ri = OUTPUT, vi is appended to the output y; otherwise it is appended to the memory m.
Once we generate ri, we must predict ai, the argc(oi)-length sequence of arguments that operation oi requires.",3.3 Generating and Executing Instructions,[0],[0]
"The jth argument ai,j can be either generated from a softmax over the vocabulary, copied from the input vector x, or copied from previously generated values in the output y or memory m. This decision is modeled using a latent predictor network (Ling et al., 2016), where the control over which method used to generate ai,j is governed by a latent variable qi,j ∈ {SOFTMAX, COPY-INPUT, COPY-OUTPUT}.",3.3 Generating and Executing Instructions,[0],[0]
"Similar to when predicting ri, in order to make this choice, we also generate a new hidden state for each argument slot j, denoted by qi,j with an LSTM, feeding the previous argument in at each time step, and initializing it with ri and by reading the predicted value of the output ri.
•",3.3 Generating and Executing Instructions,[0],[0]
"If qi,j = SOFTMAX, ai,j is generated by sampling from a softmax over the vocabulary Y ,
p(ai,j | qi,j = SOFTMAX) = softmax ai,j∈Y (qi,j).
",3.3 Generating and Executing Instructions,[0],[0]
This corresponds to a case where a string is used as argument (e.g. y1=“Let”).,3.3 Generating and Executing Instructions,[0],[0]
"• If qi,j = COPY-INPUT, ai,j is obtained by copy-
ing an element from the input vector with a pointer network (Vinyals et al., 2015) over input words x1, . . .",3.3 Generating and Executing Instructions,[0],[0]
", x|x|, represented by their encoder LSTM state u1, . . .",3.3 Generating and Executing Instructions,[0],[0]
",u|x|.",3.3 Generating and Executing Instructions,[0],[0]
"As such, we compute the probability distribution over input words as:
p(ai,j | qi,j =COPY-INPUT) =",3.3 Generating and Executing Instructions,[0],[0]
"(1) softmax
ai,j∈x1,...,x|x|
( f(uai,j ,qi,j) )",3.3 Generating and Executing Instructions,[0],[0]
"Function f computes the affinity of each token xai,j and the current output context qi,j .",3.3 Generating and Executing Instructions,[0],[0]
"A common implementation of f , which we follow, is to apply a linear projection from [uai,j ;qi,j ]
into a fixed size vector (where [u;v] is vector concatenation), followed by a tanh and a linear projection into a single value.",3.3 Generating and Executing Instructions,[0],[0]
"• If qi,j = COPY-OUTPUT, the model copies from
either the output y or the memory m. This is equivalent to finding the instruction zi, where the value was generated.",3.3 Generating and Executing Instructions,[0],[0]
"Once again, we define a pointer network that points to the output instructions and define the distribution over previously generated instructions as:
p(ai,j | qi,j =COPY-OUTPUT) = softmax
ai,j∈z1,...,zi−1
( f(hai,j ,qi,j) )",3.3 Generating and Executing Instructions,[0],[0]
"Here, the affinity is computed using the decoder state hai,j and the current state qi,j .
",3.3 Generating and Executing Instructions,[0],[0]
"Finally, we embed the argument ai,j2 and the state qi,j to generate the next state qi,j+1.",3.3 Generating and Executing Instructions,[0],[0]
"Once all arguments for oi are generated, the operation is executed to obtain vi.",3.3 Generating and Executing Instructions,[0],[0]
"Then, the embedding of vi, the final state of the instruction qi,|ai| and the previous state hi are used to generate the state at the next timestamp hi+1.",3.3 Generating and Executing Instructions,[0],[0]
The set of instructions z that will generate y is unobserved.,4 Inducing Programs while Learning,[0],[0]
"Thus, given x we optimize the marginal probability function: p(y | x) = ∑ z∈Z p(y | z)p(z | x) = ∑ z∈Z(y)",4 Inducing Programs while Learning,[0],[0]
"p(z | x),
where p(y | z) is the Kronecker delta function δe(z),y, which is 1 if the execution of z, denoted as e(z), generates y and 0 otherwise.",4 Inducing Programs while Learning,[0],[0]
"Thus, we can redefine p(y|x), the marginal over all programsZ , as a marginal over programs that would generate y, defined as Z(y).",4 Inducing Programs while Learning,[0],[0]
"As marginalizing over z ∈ Z(y) is intractable, we approximate the marginal by generating samples from our model.",4 Inducing Programs while Learning,[0],[0]
Denote the set of samples that are generated by Ẑ(y).,4 Inducing Programs while Learning,[0],[0]
"We maximize ∑ z ∈ Ẑ(y)p(z|x).
",4 Inducing Programs while Learning,[0],[0]
"However, generating programs that generate y is not trivial, as randomly sampling from the RNN distribution over instructions at each timestamp is unlikely to generate a sequence z ∈ Z(y).
",4 Inducing Programs while Learning,[0],[0]
"2 The embeddings of a given argument ai,j and the return value vi are obtained with a lookup table embedding and two flags indicating whether it is a string and whether it is a float.",4 Inducing Programs while Learning,[0],[0]
"Furthermore, if the the value is a float we also add its numeric value as a feature.
",4 Inducing Programs while Learning,[0],[0]
"This is analogous to the question answering work in Liang et al. (2016), where the query that generates the correct answer must be found during inference, and training proved to be difficult without supervision.",4 Inducing Programs while Learning,[0],[0]
"In Roy and Roth (2015) this problem is also addressed by adding prior knowledge to constrain the exponential space.
",4 Inducing Programs while Learning,[0],[0]
"In our work, we leverage the fact that we are generating rationales, where there is a sense of progression within the rationale.",4 Inducing Programs while Learning,[0],[0]
"That is, we assume that the rationale solves the problem step by step.",4 Inducing Programs while Learning,[0],[0]
"For instance, in Problem 2, the rationale first describes the number of combinations of two cards in a deck of 52 cards, then describes the number of combinations of two kings, and finally computes the probability of drawing two kings.",4 Inducing Programs while Learning,[0],[0]
"Thus, while generating the final answer without the rationale requires a long sequence of latent instructions, generating each of the tokens of the rationale requires far less operations.
",4 Inducing Programs while Learning,[0],[0]
"More formally, given the sequence z1, . . .",4 Inducing Programs while Learning,[0],[0]
", zi−1 generated so far, and the possible values for zi given by the network, denotedZi, we wish to filter Zi to Zi(yk), which denotes a set of possible options that contain at least one path capable of generating the next token at index k. Finding the set Zi(yk) is achieved by testing all combinations of instructions that are possible with at most one level of indirection, and keeping those that can generate yk.",4 Inducing Programs while Learning,[0],[0]
"This means that the model can only generate one intermediate value in memory (not including the operations that convert strings into floating point values and vice-versa).
",4 Inducing Programs while Learning,[0],[0]
Decoding.,4 Inducing Programs while Learning,[0],[0]
"During decoding we find the most likely sequence of instructions z given x, which can be performed with a stack-based decoder.",4 Inducing Programs while Learning,[0],[0]
"However, it is important to refer that each generated instruction zi = (oi, ri, ai,1, . . .",4 Inducing Programs while Learning,[0],[0]
", ai,|ai|, vi) must be executed to obtain vi.",4 Inducing Programs while Learning,[0],[0]
"To avoid generating unexecutable code—e.g., log(0)—each hypothesis instruction is executed and removed if an error occurs.",4 Inducing Programs while Learning,[0],[0]
"Finally, once the “〈EOR〉” tag is generated, we only allow instructions that would generate one of the option “A” to “E” to be generated, which guarantees that one of the options is chosen.",4 Inducing Programs while Learning,[0],[0]
"As it is shown in Figure 2, math rationales with more than 200 tokens are not uncommon, and with additional intermediate instructions, the size z can easily exceed 400.",5 Staged Back-propagation,[0],[0]
"This poses a practical challenge
for training the model.",5 Staged Back-propagation,[0],[0]
"For both the attention and copy mechanisms, for each instruction zi, the model needs to compute the probability distribution between all the attendable units c conditioned on the previous state hi−1.",5 Staged Back-propagation,[0],[0]
"For the attention model and input copy mechanisms, c = x0,i−1 and for the output copy mechanism",5 Staged Back-propagation,[0],[0]
c = z.,5 Staged Back-propagation,[0],[0]
These operations generally involve an exponential number of matrix multiplications as the size of c and z grows.,5 Staged Back-propagation,[0],[0]
"For instance, during the computation of the probabilities for the input copy mechanism in Equation 1, the affinity function f between the current context q and a given input uk is generally implemented by projecting u and q into a single vector followed by a non-linearity, which is projected into a single affinity value.",5 Staged Back-propagation,[0],[0]
"Thus, for each possible input u, 3 matrix multiplications must be performed.",5 Staged Back-propagation,[0],[0]
"Furthermore, for RNN unrolling, parameters and intermediate outputs for these operations must be replicated for each timestamp.",5 Staged Back-propagation,[0],[0]
"Thus, as z becomes larger the attention and copy mechanisms quickly become a memory bottleneck as the computation graph becomes too large to fit on the GPU.",5 Staged Back-propagation,[0],[0]
"In contrast, the sequence-to-sequence model proposed in (Sutskever et al., 2014), does not suffer from these issues as each timestamp is dependent only on the previous state hi−1.
",5 Staged Back-propagation,[0],[0]
"To deal with this, we use a training method we call staged back-propagation which saves memory by considering slices of K tokens in z, rather than the full sequence.",5 Staged Back-propagation,[0],[0]
"That is, to train on a minibatch where |z| = 300 with K = 100, we would actually train on 3 mini-batches, where the first batch would optimize for the first z1:100, the second for z101:200 and the third for z201:300.",5 Staged Back-propagation,[0],[0]
"The advantage of this method is that memory intensive operations, such as attention and the copy mechanism, only need to be unrolled for K steps, and K can be adjusted so that the computation graph fits in memory.
",5 Staged Back-propagation,[0],[0]
"However, unlike truncated back-propagation for language modeling, where context outside the scope of K is ignored, sequence-to-sequence models require global context.",5 Staged Back-propagation,[0],[0]
"Thus, the sequence of states h is still built for the whole sequence z. Afterwards, we obtain a slice hj:j+K , and compute the attention vector.3 Finally, the prediction of the instruction is conditioned on the LSTM state
3This modeling strategy is sometimes known as late fusion, as the attention vector is not used for state propagation, it is incorporated “later”.
and the attention vector.",5 Staged Back-propagation,[0],[0]
"We apply our model to the task of generating rationales for solutions to math problems, evaluating it on both the quality of the rationale and the ability of the model to obtain correct answers.",6 Experiments,[0],[0]
"As the baseline we use the attention-based sequence to sequence model proposed by Bahdanau et al. (2014), and proposed augmentations, allowing it to copy from the input (Ling et al., 2016) and from the output (Merity et al., 2016).",6.1 Baselines,[0],[0]
"We used a two-layer LSTM with a hidden size of H = 200, and word embeddings with size 200.",6.2 Hyperparameters,[0],[0]
The number of levels that the graph G is expanded during sampling D is set to 5.,6.2 Hyperparameters,[0],[0]
Decoding is performed with a beam of 200.,6.2 Hyperparameters,[0],[0]
"As for the vocabulary of the softmax and embeddings, we keep the most frequent 20,000 word types, and replace the rest of the words with an unknown token.",6.2 Hyperparameters,[0],[0]
"During training, the model only learns to predict a word as an unknown token, when there is no other alternative to generate the word.",6.2 Hyperparameters,[0],[0]
"The evaluation of the rationales is performed with average sentence level perplexity and BLEU4 (Papineni et al., 2002).",6.3 Evaluation Metrics,[0],[0]
"When a model cannot generate a token for perplexity computation, we predict unknown token.",6.3 Evaluation Metrics,[0],[0]
This benefits the baselines as they are less expressive.,6.3 Evaluation Metrics,[0],[0]
"As the perplexity of our model is dependent on the latent program that is generated, we force decode our model to generate the rationale, while maximizing the probability of the program.",6.3 Evaluation Metrics,[0],[0]
"This is analogous to the method used to obtain sample programs described in Section 4, but we choose the most likely instructions at each timestamp instead of sampling.",6.3 Evaluation Metrics,[0],[0]
"Finally, the correctness of the answer is evaluated by computing the percentage of the questions, where the chosen option matches the correct one.",6.3 Evaluation Metrics,[0],[0]
"The test set results, evaluated on perplexity, BLEU, and accuracy, are presented in Table 3.
Perplexity.",6.4 Results,[0],[0]
"In terms of perplexity, we observe that the regular sequence to sequence model fares poorly on this dataset, as the model requires the generation of many values that tend to be sparse.",6.4 Results,[0],[0]
Adding an input copy mechanism greatly improves the perplexity as it allows the generation process to use values that were mentioned in the question.,6.4 Results,[0],[0]
"The output copying mechanism improves perplexity slightly over the input copy mechanism, as many values are repeated after their first occurrence.",6.4 Results,[0],[0]
"For instance, in Problem 2, the value “1326” is used twice, so even though the model cannot generate it easily in the first occurrence, the second one can simply be generated by copying the first one.",6.4 Results,[0],[0]
"We can observe that our model yields significant improvements over the baselines, demonstrating that the ability to generate new values by algebraic manipulation is essential in this task.",6.4 Results,[0],[0]
An example of a program that is inferred is shown in Figure 4.,6.4 Results,[0],[0]
The graph was generated by finding the most likely program z that generates y.,6.4 Results,[0],[0]
"Each node isolates a value in x, m, or y, where arrows indicate an operation executed with the outgoing nodes as arguments and incoming node as the return of the operation.",6.4 Results,[0],[0]
"For simplicity, operations that copy or convert values (e.g. from string to float) were not included, but nodes that were copied/converted share the same color.",6.4 Results,[0],[0]
"Examples of tokens where our model can obtain the perplexity reduction are the values “0.025”, “0.023”, “0.002” and finally the answer “E” , as these cannot be copied from the input or output.
",6.4 Results,[0],[0]
BLEU.,6.4 Results,[0],[0]
We observe that the regular sequence to sequence model achieves a low BLEU score.,6.4 Results,[0],[0]
"In fact, due to the high perplexities the model generates very short rationales, which frequently consist of segments similar to “Answer should be D”, as most rationales end with similar statements.",6.4 Results,[0],[0]
"By applying the copy mechanism the BLEU score improves substantially, as the model can define the variables that are used in the rationale.",6.4 Results,[0],[0]
"In-
terestingly, the output copy mechanism adds no further improvement in the perplexity evaluation.",6.4 Results,[0],[0]
This is because during decoding all values that can be copied from the output are values that could have been generated by the model either from the softmax or the input copy mechanism.,6.4 Results,[0],[0]
"As such, adding an output copying mechanism adds little to the expressiveness of the model during decoding.
",6.4 Results,[0],[0]
"Finally, our model can achieve the highest BLEU score as it has the mechanism to generate the intermediate and final values in the rationale.
Accuracy.",6.4 Results,[0],[0]
"In terms of accuracy, we see that all baseline models obtain values close to chance (20%), indicating that they are completely unable to solve the problem.",6.4 Results,[0],[0]
"In contrast, we see that our model can solve problems at a rate that is significantly higher than chance, demonstrating the value of our program-driven approach, and its ability to learn to generate programs.
",6.4 Results,[0],[0]
"In general, the problems we solve correctly correspond to simple problems that can be solved in one or two operations.",6.4 Results,[0],[0]
"Examples include questions such as “Billy cut up each cake into 10 slices, and ended up with 120 slices altogether.",6.4 Results,[0],[0]
How many cakes did she cut up?,6.4 Results,[0],[0]
"A) 9 B) 7 C) 12 D) 14 E) 16”, which can be solved in a single step.",6.4 Results,[0],[0]
"In this case, our model predicts “120 / 10 = 12 cakes.",6.4 Results,[0],[0]
"Answer is C” as the rationale, which is reasonable.",6.4 Results,[0],[0]
"While we show that our model can outperform the models built up to date, generating complex rationales as those shown in Figure 1 correctly is still an unsolved problem, as each additional step adds complexity to the problem both during inference and decoding.",6.5 Discussion.,[0],[0]
"Yet, this is the first result showing that it is possible to solve math problems in such a manner, and we believe this modeling approach and dataset will drive work on this problem.",6.5 Discussion.,[0],[0]
"Extensive efforts have been made in the domain of math problem solving (Hosseini et al., 2014; Kushman et al., 2014; Roy and Roth, 2015), which aim at obtaining the correct answer to a given math problem.",7 Related Work,[0],[0]
"Other work has focused on learning to map math expressions into formal languages (Roy et al., 2016).",7 Related Work,[0],[0]
"We aim to generate natural language rationales, where the bindings between variables and the problem solving approach are mixed into
a single generative model that attempts to solve the problem while explaining the approach taken.
",7 Related Work,[0],[0]
"Our approach is strongly tied with the work on sequence to sequence transduction using the encoder-decoder paradigm (Sutskever et al., 2014; Bahdanau et al., 2014; Kalchbrenner and Blunsom, 2013), and inherits ideas from the extensive literature on semantic parsing (Jones et al., 2012; Berant et al., 2013; Andreas et al., 2013; Quirk et al., 2015; Liang et al., 2016; Neelakantan et al., 2016) and program generation (Reed and de Freitas, 2016; Graves et al., 2016), namely, the usage of an external memory, the application of different operators over values in the memory and the copying of stored values into the output sequence.
",7 Related Work,[0],[0]
"Providing textual explanations for classification decisions has begun to receive attention, as part of increased interest in creating models whose decisions can be interpreted.",7 Related Work,[0],[0]
"Lei et al. (2016), jointly modeled both a classification decision, and the selection of the most relevant subsection of a document for making the classification decision.",7 Related Work,[0],[0]
"Hendricks et al. (2016) generate textual explanations for visual classification problems, but in contrast
to our model, they first generate an answer, and then, conditional on the answer, generate an explanation.",7 Related Work,[0],[0]
This effectively creates a post-hoc justification for a classification decision rather than a program for deducing an answer.,7 Related Work,[0],[0]
"These papers, like ours, have jointly modeled rationales and answer predictions; however, we are the first to use rationales to guide program induction.",7 Related Work,[0],[0]
"In this work, we addressed the problem of generating rationales for math problems, where the task is to not only obtain the correct answer of the problem, but also generate a description of the method used to solve the problem.",8 Conclusion,[0],[0]
"To this end, we collect 100,000 question and rationale pairs, and propose a model that can generate natural language and perform arithmetic operations in the same decoding process.",8 Conclusion,[0],[0]
"Experiments show that our method outperforms existing neural models, in both the fluency of the rationales that are generated and the ability to solve the problem.",8 Conclusion,[0],[0]
Solving algebraic word problems requires executing a series of arithmetic operations—a program—to obtain a final answer.,abstractText,[0],[0]
"However, since programs can be arbitrarily complicated, inducing them directly from question-answer pairs is a formidable challenge.",abstractText,[0],[0]
"To make this task more feasible, we solve these problems by generating answer rationales, sequences of natural language and human-readable mathematical expressions that derive the final answer through a series of small steps.",abstractText,[0],[0]
"Although rationales do not explicitly specify programs, they provide a scaffolding for their structure via intermediate milestones.",abstractText,[0],[0]
"To evaluate our approach, we have created a new 100,000-sample dataset of questions, answers and rationales.",abstractText,[0],[0]
Experimental results show that indirect supervision of program learning via answer rationales is a promising strategy for inducing arithmetic programs.,abstractText,[0],[0]
Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems,title,[0],[0]
A central goal of Artificial Intelligence is the creation of machines that learn as effectively from human instruction as they do from data.,1. Introduction,[0],[0]
"A recent and important step towards this goal is the invention of neural architectures that learn to perform algorithms akin to traditional computers, using primitives such as memory access and stack manipulation (Graves et al., 2014; Joulin & Mikolov, 2015; Grefenstette et al., 2015; Kaiser & Sutskever, 2015; Kurach et al., 2016; Graves et al., 2016).",1. Introduction,[0],[0]
"These architectures can be trained through standard gradient descent methods, and enable machines to learn complex behaviour from input-output pairs or program traces.",1. Introduction,[0],[0]
"In this context, the role of the human programmer is often limited to providing training data.",1. Introduction,[0],[0]
"However, training data is a scarce resource for many tasks.",1. Introduction,[0],[0]
"In these cases, the programmer may have
1Department of Computer Science, University College London, London, UK 2Department of Computer Science, University of Oxford, Oxford, UK 3Department of Theoretical and Applied Linguistics, University of Cambridge, Cambridge, UK.",1. Introduction,[0],[0]
"Correspondence to: Matko Bošnjak <m.bosnjak@cs.ucl.ac.uk>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"partial procedural background knowledge: one may know the rough structure of the program, or how to implement several subroutines that are likely necessary to solve the task.",1. Introduction,[0],[0]
"For example, in programming by demonstration (Lau et al., 2001) or query language programming (Neelakantan et al., 2015a) a user establishes a larger set of conditions on the data, and the model needs to set out the details.",1. Introduction,[0],[0]
"In all these scenarios, the question then becomes how to exploit various types of prior knowledge when learning algorithms.
",1. Introduction,[0],[0]
To address the above question we present an approach that enables programmers to inject their procedural background knowledge into a neural network.,1. Introduction,[0],[0]
"In this approach, the programmer specifies a program sketch (Solar-Lezama et al., 2005) in a traditional programming language.",1. Introduction,[0],[0]
This sketch defines one part of the neural network behaviour.,1. Introduction,[0],[0]
The other part is learned using training data.,1. Introduction,[0],[0]
The core insight that enables this approach is the fact that most programming languages can be formulated in terms of an abstract machine that executes the commands of the language.,1. Introduction,[0],[0]
"We implement these machines as neural networks, constraining parts of the networks to follow the sketched behaviour.",1. Introduction,[0],[0]
"The resulting neural programs are consistent with our prior knowledge and optimised with respect to the training data.
",1. Introduction,[0],[0]
"In this paper, we focus on the programming language Forth (Brodie, 1980), a simple yet powerful stack-based language that facilitates factoring and abstraction.",1. Introduction,[0],[0]
Underlying Forth’s semantics is a simple abstract machine.,1. Introduction,[0],[0]
"We introduce ∂4, an implementation of this machine that is differentiable with respect to the transition it executes at each time step, as well as distributed input representations.",1. Introduction,[0],[0]
"Sketches that users write define underspecified behaviour which can then be trained with backpropagation.
",1. Introduction,[0],[0]
"For two neural programming tasks introduced in previous work (Reed & de Freitas, 2015) we present Forth sketches that capture different degrees of prior knowledge.",1. Introduction,[0],[0]
"For example, we define only the general recursive structure of a sorting problem.",1. Introduction,[0],[0]
"We show that given only input-output pairs, ∂4 can learn to fill the sketch and generalise well to problems of unseen size.",1. Introduction,[0],[0]
"In addition, we apply ∂4 to the task of solving word algebra problems.",1. Introduction,[0],[0]
"We show that when provided with basic algorithmic scaffolding and trained jointly with an upstream LSTM (Hochreiter & Schmidhuber, 1997), ∂4 is able to learn to read natural
ar X
iv :1
60 5.
06 64
0v 3
[ cs
.N",1. Introduction,[0],[0]
"E
] 2
3 Ju
l 2 01
7
language narratives, extract important numerical quantities, and reason with these, ultimately answering corresponding mathematical questions without the need for explicit intermediate representations used in previous work.
",1. Introduction,[0],[0]
The contributions of our work are as follows: i),1. Introduction,[0],[0]
"We present a neural implementation of a dual stack machine underlying Forth, ii) we introduce Forth sketches for programming with partial procedural background knowledge, iii) we apply Forth sketches as a procedural prior on learning algorithms from data, iv) we introduce program code optimisations based on symbolic execution that can speed up neural execution, and v) using Forth sketches we obtain state-of-the-art for end-to-end reasoning about quantities expressed in natural language narratives.",1. Introduction,[0],[0]
"Forth is a simple Turing-complete stack-based programming language (ANSI, 1994; Brodie, 1980).",2. The Forth Abstract Machine,[0],[0]
We chose Forth as the host language of our work because i),2. The Forth Abstract Machine,[0],[0]
"it is an established, general-purpose high-level language relatively close to machine code, ii) it promotes highly modular programs through use of branching, loops and function calls, thus bringing out a good balance between assembly and higher level languages, and importantly iii) its abstract machine is simple enough for a straightforward creation of its continuous approximation.",2. The Forth Abstract Machine,[0],[0]
"Forth’s underlying abstract machine is represented by a state S = (D,R,H,c), which contains two stacks: a data evaluation pushdown stack D (data stack) holds values for manipulation, and a return address pushdown stackR (return stack) assists with return pointers and subroutine calls.",2. The Forth Abstract Machine,[0],[0]
"These are accompanied by a heap or random memory access bufferH , and a program counter c.
A Forth program P is a sequence1 of Forth words (i.e. commands)P =w1...wn.",2. The Forth Abstract Machine,[0],[0]
"The role of a word varies, encompassing language keywords, primitives, and user-defined subroutines (e.g. DROP discards the top element of the data stack, or DUP duplicates the top element of the data stack).2 Each wordwi defines a transition function between machine states wi : S → S. Therefore, a program P itself defines a transition function by simply applying the word at the current program counter to the current state.",2. The Forth Abstract Machine,[0],[0]
"Although usually considered as a part of the heap H , we consider Forth programs P separately to ease the analysis.
",2. The Forth Abstract Machine,[0],[0]
An example of a Bubble sort algorithm implemented in Forth is shown in Listing 1 in everything except lines 3b-4c.,2. The Forth Abstract Machine,[0],[0]
The execution starts from line 12 where literals are pushed on the data stack and the SORT is called.,2. The Forth Abstract Machine,[0],[0]
Line 10 executes the main loop over the sequence.,2. The Forth Abstract Machine,[0],[0]
"Lines 2-7
1Forth is a concatenative language.",2. The Forth Abstract Machine,[0],[0]
"2In this work, we restrict ourselves to a subset of all Forth
words, detailed in Appendix A.
1 : BUBBLE ( a1 ... an n-1 -- one pass ) 2 DUP IF >R
3a OVER OVER < IF SWAP THEN 4a R> SWAP >R 1- BUBBLE R> 3b { observe D0 D-1 -> permute D-1 D0 R0} 4b 1- BUBBLE R> 3c { observe D0 D-1 -> choose NOP SWAP } 4c R> SWAP >R 1- BUBBLE R> 5 ELSE 6 DROP 7 THEN 8 ; 9 : SORT ( a1 .. an n -- sorted ) 10 1-",2. The Forth Abstract Machine,[0],[0]
DUP 0,2. The Forth Abstract Machine,[0],[0]
"DO >R R@ BUBBLE R> LOOP DROP 11 ; 12 2 4 2 7 4 SORT \ Example call
Listing 1: Three code alternatives (white lines are common to all, coloured/lettered lines are alternative-specific): i)",2. The Forth Abstract Machine,[0],[0]
"Bubble sort in Forth (a lines – green), ii) PERMUTE sketch (b lines – blue), and iii) COMPARE sketch (c lines – yellow).
",2. The Forth Abstract Machine,[0],[0]
"denote the BUBBLE procedure – comparison of top two stack numbers (line 3a), and the recursive call to itself (line 4a).",2. The Forth Abstract Machine,[0],[0]
"A detailed description of how this program is executed by the Forth abstract machine is provided in Appendix B. Notice that while Forth provides common control structures such as looping and branching, these can always be reduced to low-level code that uses jumps and conditional jumps (using the words BRANCH and BRANCH0, respectively).",2. The Forth Abstract Machine,[0],[0]
"Likewise, we can think of sub-routine definitions as labelled code blocks, and their invocation amounts to jumping to the code block with the respective label.",2. The Forth Abstract Machine,[0],[0]
"When a programmer writes a Forth program, they define a sequence of Forth words, i.e., a sequence of known state transition functions.",3. ∂4: Differentiable Abstract Machine,[0],[0]
"In other words, the programmer knows exactly how computation should proceed.",3. ∂4: Differentiable Abstract Machine,[0],[0]
"To accommodate for cases when the developer’s procedural background knowledge is incomplete, we extend Forth to support the definition of a program sketch.",3. ∂4: Differentiable Abstract Machine,[0],[0]
"As is the case with Forth programs, sketches are sequences of transition functions.",3. ∂4: Differentiable Abstract Machine,[0],[0]
"However, a sketch may contain transition functions whose behaviour is learned from data.
",3. ∂4: Differentiable Abstract Machine,[0],[0]
To learn the behaviour of transition functions within a program we would like the machine output to be differentiable with respect to these functions (and possibly representations of inputs to the program).,3. ∂4: Differentiable Abstract Machine,[0],[0]
"This enables us to choose parameterised transition functions such as neural networks.
",3. ∂4: Differentiable Abstract Machine,[0],[0]
"To this end, we introduce ∂4, a TensorFlow (Abadi et al., 2015) implementation of a differentiable abstract machine with continuous state representations, differentiable words and sketches.",3. ∂4: Differentiable Abstract Machine,[0],[0]
"Program execution in ∂4 is modelled by a recurrent neural network (RNN), parameterised by the transition functions at each time step.",3. ∂4: Differentiable Abstract Machine,[0],[0]
"We map the symbolic machine state S = (D, R, H, c) to a continuous representation S = (D, R, H, c) into two differentiable stacks (with pointers), the data stack D= (D,d) and the return stackR= (R,r), a heap H, and an attention vector c indicating which word of the sketchPθ is being executed at the current time step.",3.1. Machine State Encoding,[0],[0]
Figure 1 depicts the machine together with its elements.,3.1. Machine State Encoding,[0],[0]
"All three memory structures, the data stack, the return stack and the heap, are based on differentiable flat memory buffersM∈{D,R,H}, where D,R,H∈Rl×v , for a stack size l and a value size v.",3.1. Machine State Encoding,[0],[0]
"Each has a differentiable read operation
readM(a)=aTM
and write operation
writeM(x,a) :M←M−(a1T )",3.1. Machine State Encoding,[0],[0]
"M+xaT
akin to the Neural Turing Machine (NTM) memory (Graves et al., 2014), where is the element-wise multiplication, and a is the address",3.1. Machine State Encoding,[0],[0]
pointer.3,3.1. Machine State Encoding,[0],[0]
"In addition to the memory buffers D and R, the data stack and the return stack contain pointers to the current top-of-the-stack (TOS) element d,r∈Rl, respectively.",3.1. Machine State Encoding,[0],[0]
"This allows us to implement pushing as writing a value x into M and incrementing the TOS pointer as:
pushM(x) :writeM(x,p) (side-effect: p← inc(p))
where p∈{d,r}, inc(p)=pTR1+, dec(p)=pTR−, and R1+ and R1− are increment and decrement matrices (left and right circular shift matrices).
3The equal widths ofH andD allow us to directly move vector representations of values between the heap and the stack.
",3.1. Machine State Encoding,[0],[0]
"Popping is realized by multiplying the TOS pointer and the memory buffer, and decreasing the TOS pointer:
popM( )= readM(p) (side-effect: p←dec(p))
",3.1. Machine State Encoding,[0],[0]
"Finally, the program counter c ∈",3.1. Machine State Encoding,[0],[0]
"Rp is a vector that, when one-hot, points to a single word in a program of length p, and is equivalent to the c vector of the symbolic state machine.4 We use S to denote the space of all continuous representations S.
Neural Forth",3.1. Machine State Encoding,[0],[0]
Words,3.1. Machine State Encoding,[0],[0]
"It is straightforward to convert Forth words, defined as functions on discrete machine states, to functions operating on the continuous space S.",3.1. Machine State Encoding,[0],[0]
"For example, consider the word DUP, which duplicates the top of the data stack.",3.1. Machine State Encoding,[0],[0]
"A differentiable version of DUP first calculates the value e on the TOS address ofD, as e=dTD.",3.1. Machine State Encoding,[0],[0]
"It then shifts the stack pointer via d← inc(d), and writes e to D using writeD(e,d).",3.1. Machine State Encoding,[0],[0]
The complete description of implemented Forth Words and their differentiable counterparts can be found in Appendix A.,3.1. Machine State Encoding,[0],[0]
We define a Forth sketch Pθ as a sequence of continuous transition functions P = w1 ...wn.,3.2. Forth Sketches,[0],[0]
"Here, wi ∈ S → S either corresponds to a neural Forth word or a trainable transition function (neural networks in our case).",3.2. Forth Sketches,[0],[0]
"We will call these trainable functions slots, as they correspond to underspecified “slots” in the program code that need to be filled by learned behaviour.
",3.2. Forth Sketches,[0],[0]
We allow users to define a slot w by specifying a pair of a state encoder wenc and a decoder wdec.,3.2. Forth Sketches,[0],[0]
"The encoder
4During training c can become distributed and is considered as attention over the program code.
",3.2. Forth Sketches,[0],[0]
"produces a latent representation h of the current machine state using a multi-layer perceptron, and the decoder consumes this representation to produce the next machine state.",3.2. Forth Sketches,[0],[0]
We hence have w=wdec ◦wenc.,3.2. Forth Sketches,[0],[0]
"To use slots within Forth program code, we introduce a notation that reflects this decomposition.",3.2. Forth Sketches,[0],[0]
"In particular, slots are defined by the syntax { encoder -> decoder } where encoder and decoder are specifications of the corresponding slot parts as described below.
",3.2. Forth Sketches,[0],[0]
"Encoders We provide the following options for encoders:
static produces a static representation, independent of the actual machine state.",3.2. Forth Sketches,[0],[0]
observe e1 ...,3.2. Forth Sketches,[0],[0]
em: concatenates the elements e1 ...,3.2. Forth Sketches,[0],[0]
em of the machine state.,3.2. Forth Sketches,[0],[0]
An element can be a stack item Di at relative index,3.2. Forth Sketches,[0],[0]
"i, a return stack item Ri, etc. linear N, sigmoid, tanh represent chained transformations, which enable the multilayer perceptron architecture.",3.2. Forth Sketches,[0],[0]
"Linear N projects to N dimensions, and sigmoid and tanh apply same-named functions elementwise.
",3.2. Forth Sketches,[0],[0]
"Decoders Users can specify the following decoders:
choose w1...wm: chooses from the Forth wordsw1...wm.",3.2. Forth Sketches,[0],[0]
Takes an input vector h of length m to produce a weighted combination of machine states ∑m i hiwi(S).,3.2. Forth Sketches,[0],[0]
manipulate e1 ...,3.2. Forth Sketches,[0],[0]
em: directly manipulates the machine state elements e1 ...,3.2. Forth Sketches,[0],[0]
em by writing the appropriately reshaped and softmaxed output of the encoder over the machine state elements with writeM. permute e1 ...,3.2. Forth Sketches,[0],[0]
em: permutes the machine state elements e1...,3.2. Forth Sketches,[0],[0]
em via a linear combination ofm!,3.2. Forth Sketches,[0],[0]
state vectors.,3.2. Forth Sketches,[0],[0]
We model execution using an RNN which produces a state Sn+1 conditioned on a previous state Sn.,3.3. The Execution RNN,[0],[0]
"It does so by first passing the current state to each function wi in the program, and then weighing each of the produced next states by the component of the program counter vector ci that corresponds to program index i, effectively using c as an attention vector over code.",3.3. The Execution RNN,[0],[0]
"Formally we have:
Sn+1=RNN(Sn,Pθ)= |P |∑ i=1",3.3. The Execution RNN,[0],[0]
"ciwi(Sn)
",3.3. The Execution RNN,[0],[0]
"Clearly, this recursion, and its final state, are differentiable with respect to the program codePθ, and its inputs.",3.3. The Execution RNN,[0],[0]
"Furthermore, for differentiable Forth programs the final state of this RNN will correspond to the final state of a symbolic execution (when no slots are present, and one-hot values are used).",3.3. The Execution RNN,[0],[0]
The ∂4 RNN requires one-time step per transition.,3.4. Program Code Optimisations,[0],[0]
"After each time step, the program counter is either incremented, decremented, explicitly set or popped from the stack.",3.4. Program Code Optimisations,[0],[0]
"In turn, a new machine state is calculated by executing all words in the program and then weighting the result states by the program counter.",3.4. Program Code Optimisations,[0],[0]
"As this is expensive, it is advisable to avoid full RNN steps wherever possible.",3.4. Program Code Optimisations,[0],[0]
"We use two strategies to avoid full RNN steps and significantly speed-up ∂4: symbolic execution and interpolation of if-branches.
",3.4. Program Code Optimisations,[0],[0]
Symbolic Execution,3.4. Program Code Optimisations,[0],[0]
"Whenever we have a sequence of Forth words that contains no branch entry or exit points, we can collapse this sequence into a single transition instead of naively interpreting words one-by-one.",3.4. Program Code Optimisations,[0],[0]
"We symbolically execute (King, 1976) a sequence of Forth words to calculate a new machine state.",3.4. Program Code Optimisations,[0],[0]
We then use the difference between the new and the initial state to derive the transition function of the sequence.,3.4. Program Code Optimisations,[0],[0]
"For example, the sequenceR> SWAP >R that swaps top elements of the data and the return stack yields the symbolic state D= r1d2",3.4. Program Code Optimisations,[0],[0]
...dl. and R= d1r2 ...rl.,3.4. Program Code Optimisations,[0],[0]
"Comparing it to the initial state, we derive a single neural transition that only needs to swap the top elements of D and R.
Interpolation of If-Branches We cannot apply symbolic execution to code with branching points as the branching behaviour depends on the current machine state, and we cannot resolve it symbolically.",3.4. Program Code Optimisations,[0],[0]
"However, we can still collapse if-branches that involve no function calls or loops by executing both branches in parallel and weighing their output states by the value of the condition.",3.4. Program Code Optimisations,[0],[0]
"If the if-branch does contain function calls or loops, we simply fall back to execution of all words weighted by the program counter.",3.4. Program Code Optimisations,[0],[0]
"Our training procedure assumes input-output pairs of machine start and end states (xi,yi) only.",3.5. Training,[0],[0]
The output yi defines a target memory YDi and a target pointer y d,3.5. Training,[0],[0]
"i on the data stack D. Additionally, we have a mask Ki that indicates which components of the stack should be included in the loss (e.g. we do not care about values above the stack depth).",3.5. Training,[0],[0]
"We use DT (θ,xi) and dT (θ,xi) to denote the final state of D and d after T steps of execution RNN and using an initial state xi.",3.5. Training,[0],[0]
"We define the loss function as
L(θ)=H(Ki DT (θ,xi),Ki YDi )",3.5. Training,[0],[0]
"+H(Ki dT (θ,xi),Ki ydi )
where H(x, y) = −x log y is the cross-entropy loss, and θ are parameters of slots in the program P .",3.5. Training,[0],[0]
We can use backpropagation and any variant of gradient descent to optimise this loss function.,3.5. Training,[0],[0]
"Note that at this point it would be possible to include supervision of the intermediate states (trace-level), as done by the Neural Program Interpreter (Reed & de Freitas, 2015).",3.5. Training,[0],[0]
We evaluate ∂4 on three tasks.,4. Experiments,[0],[0]
"Two of these are simple transduction tasks, sorting and addition as presented in (Reed & de Freitas, 2015), with varying levels of program structure.",4. Experiments,[0],[0]
"For each problem, we introduce two sketches.
",4. Experiments,[0],[0]
We also test ∂4 on the more difficult task of answering word algebra problems.,4. Experiments,[0],[0]
"We show that not only can ∂4 act as a standalone solver for such problems, bypassing the intermediary task of producing formula templates which must then be executed, but it can also outperform previous work when trained on the same data.",4. Experiments,[0],[0]
"Specific to the transduction tasks, we discretise memory elements during testing.",4.1. Experimental Setup,[0],[0]
This effectively allows the trained model to generalise to any sequence length if the correct sketch behaviour has been learned.,4.1. Experimental Setup,[0],[0]
"We also compare against a Seq2Seq (Sutskever et al., 2014) baseline.",4.1. Experimental Setup,[0],[0]
Full details of the experimental setup can be found in Appendix E.,4.1. Experimental Setup,[0],[0]
"Sorting sequences of digits is a hard task for RNNs, as they fail to generalise to sequences even marginally longer than the ones they have been trained on (Reed & de Freitas, 2015).",4.2. Sorting,[0],[0]
"We investigate several strong priors based on Bubble sort for this transduction task and present two ∂4 sketches in Listing 1 that enable us to learn sorting from only a few hundred training examples (see Appendix C.1 for more detail):
In both sketches, the outer loop can be specified in ∂4 (Listing 1, line 10), which repeatedly calls a functionBUBBLE.",4.2. Sorting,[0],[0]
"In doing so, it defines sufficient structure so that the behaviour of the network is invariant to the input sequence length.
Results on Bubble sort A quantitative comparison of our models on the Bubble sort task is provided in Table 1.",4.2. Sorting,[0],[0]
"For a given test sequence length, we vary the training set lengths to illustrate the model’s ability to generalise to sequences longer than those it observed during training.",4.2. Sorting,[0],[0]
"We find that ∂4 quickly learns the correct sketch behaviour, and it is able to generalise perfectly to sort sequences of 64 elements after observing only sequences of length two and three during training.",4.2. Sorting,[0],[0]
"In comparison, the Seq2Seq baseline falters when attempting similar generalisations, and performs close to chance when tested on longer sequences.",4.2. Sorting,[0],[0]
"Both ∂4 sketches perform flawlessly when trained on short sequence lengths, but under-perform when trained on sequences of length 4 due to arising computational difficulties (COMPARE sketch performs better due to more structure it imposes).",4.2. Sorting,[0],[0]
We discuss this issue further in Section 5.,4.2. Sorting,[0],[0]
"Next, we applied ∂4 to the problem of learning to add two n-digit numbers.",4.3. Addition,[0],[0]
"We rely on the standard elementary school addition algorithm, where the goal is to iterate over pairs of aligned digits, calculating the sum of each to yield the resulting sum.",4.3. Addition,[0],[0]
"The key complication arises when two digits sum to a two-digit number, requiring that the correct extra digit (a carry) be carried over to the subsequent column.
1 : ADD-DIGITS ( a1 b1...an bn carry n -- r1 r2...r_{n+1} ) 2 DUP 0 =",4.3. Addition,[0],[0]
IF 3 DROP 4 ELSE 5,4.3. Addition,[0],[0]
">R \ put n on R
6a { observe D0 D-1 D-2 -> tanh -> linear 70 -> manipulate D-1 D-2 } 7a DROP",4.3. Addition,[0],[0]
"6b { observe D0 D-1 D-2 -> tanh -> linear 10 -> choose 0 1 } 7b { observe D-1 D-2 D-3 -> tanh -> linear 50
-> choose 0 1 2 3 4 5 6 7 8 9 }",4.3. Addition,[0],[0]
">R SWAP DROP SWAP DROP SWAP DROP R>
8 R> 1- SWAP >R \ new_carry n-1",4.3. Addition,[0],[0]
"9 ADD-DIGITS \ call add-digits on n-1 subseq.
10 R> \",4.3. Addition,[0],[0]
"put remembered results back on the stack 11 THEN 12 ;
Listing 2: Manipulate sketch (a lines – green) and the choose sketch (b lines – blue) for Elementary Addition.",4.3. Addition,[0],[0]
"Input data is used to fill data stack externally
We assume aligned pairs of digits as input, with a carry for the least significant digit (potentially 0), and the length of the respective numbers.",4.3. Addition,[0],[0]
"The sketches define the high-level operations through recursion, leaving the core addition to be learned from data.
",4.3. Addition,[0],[0]
"The specified high-level behaviour includes the recursive call template and the halting condition of the recursion (no remaining digits, line 2-3).",4.3. Addition,[0],[0]
"The underspecified addition operation must take three digits from the previous call, the two digits to sum and a previous carry, and produce a single digit (the sum) and the resultant carry (lines 6a, 6b and 7a, 7b).",4.3. Addition,[0],[0]
"We introduce two sketches for inducing this behaviour:
MANIPULATE.",4.3. Addition,[0],[0]
"This sketch provides little prior procedural knowledge as it directly manipulates the ∂4 machine state, filling in a carry and the result digits, based on the top three elements on the data stack (two digits and the carry).",4.3. Addition,[0],[0]
"Depicted in Listing 2 in green.
CHOOSE.",4.3. Addition,[0],[0]
"Incorporating additional prior information, CHOOSE exactly specifies the results of the computation, namely the output of the first slot (line 6b) is the carry, and the output of the second one (line 7b) is the result digit, both conditioned on the two digits and the carry on the data stack.",4.3. Addition,[0],[0]
"Depicted in Listing 2 in blue.
",4.3. Addition,[0],[0]
"The rest of the sketch code reduces the problem size by one and returns the solution by popping it from the return stack.
",4.3. Addition,[0],[0]
"Quantitative Evaluation on Addition In a set of experiments analogous to those in our evaluation on Bubble sort, we demonstrate the performance of ∂4 on the addition task by examining test set sequence lengths of 8 and 64 while varying the lengths of the training set instances (Table 2).",4.3. Addition,[0],[0]
"The Seq2Seq model again fails to generalise
to longer sequences than those observed during training.",4.3. Addition,[0],[0]
"In comparison, both the CHOOSE sketch and the less structured MANIPULATE sketch learn the correct sketch behaviour and generalise to all test sequence lengths (with an exception of MANIPULATE which required more data to train perfectly).",4.3. Addition,[0],[0]
"In additional experiments, we were able to successfully train both the CHOOSE and the MANIPULATE sketches from sequences of input length 24, and we tested them up to the sequence length of 128, confirming their perfect training and generalisation capabilities.",4.3. Addition,[0],[0]
Word algebra problems (WAPs) are often used to assess the numerical reasoning abilities of schoolchildren.,4.4. Word Algebra Problems,[0],[0]
"Questions are short narratives which focus on numerical quantities, culminating with a question.",4.4. Word Algebra Problems,[0],[0]
For example:,4.4. Word Algebra Problems,[0],[0]
"Answering such questions requires both the understanding of language and of algebra — one must know which numeric operations correspond to which phrase and how to execute these operations.
","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"Previous work cast WAPs as a transduction task by mapping a question to a template of a mathematical formula, thus requiring manuall labelled formulas.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"For instance, one formula that can be used to correctly answer the question in the example above is (50 - 15) + 21 = 56.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"In previous work, local classifiers (Roy & Roth, 2015; Roy et al., 2015), hand-crafted grammars (Koncel-Kedziorski et al., 2015), and recurrent neural models (Bouchard et al., 2016) have been used to perform this task.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"Predicted formula templates may be marginalised during training (Kushman et al., 2014), or evaluated directly to produce an answer.
","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"In contrast to these approaches, ∂4 is able to learn both, a soft mapping from text to algebraic operations and their execution, without the need for manually labelled equations and no explicit symbolic representation of a formula.
","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"Model description Our model is a fully end-to-end differentiable structure, consisting of a ∂4 interpreter, a
\ first copy data from H: vectors to R and numbers to D 1 { observe R0 R-1 R-2 R-3 -> permute D0 D-1 D-2 } 2 { observe R0 R-1 R-2 R-3 -> choose","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
+ - * / } 3 { observe R0 R-1 R-2 R-3 -> choose SWAP NOP } 4 { observe R0 R-1 R-2 R-3 -> choose,"A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"+ - * / } \ lastly, empty out the return stack
Listing 3: Core of the Word Algebra Problem sketch.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"The full sketch can be found in the Appendix.
sketch, and a Bidirectional LSTM (BiLSTM) reader.
","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"The BiLSTM reader reads the text of the problem and produces a vector representation (word vectors) for each word, concatenated from the forward and the backward pass of the BiLSTM network.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"We use the resulting word vectors corresponding only to numbers in the text, numerical values of those numbers (encoded as one-hot vectors), and a vector representation of the whole problem (concatenation of the last and the first vector of the opposite passes) to initialise the ∂4 heap H. This is done in an end-to-end fashion, enabling gradient propagation through the BiLSTM to the vector representations.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"The process is depicted in Figure 1.
","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"The sketch, depicted in Listing 3 dictates the differentiable computation.5 First, it copies values from the heap H – word vectors to the return stack R, and numbers (as one-hot vectors) on the data stack D. Second, it contains four slots that define the space of all possible operations of four operators on three operands, all conditioned on the vector representations on the return stack.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"These slots are i) permutation of the elements on the data stack, ii) choosing the first operator, iii) possibly swapping the intermediate result and the last operand, and iv) the choice of the second operator.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"The final set of commands simply empties out the return stack R. These slots define the space of possible operations, however, the model needs to learn how to utilise these operations in order to calculate the correct result.
","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"Results We evaluate the model on the Common Core (CC) dataset, introduced by Roy & Roth (2015).","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"CC is notable for having the most diverse set of equation patterns, consisting of four operators (+, -,×,÷), with up to three operands.
","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"We compare against three baseline systems: (1) a local classifier with hand-crafted features (Roy & Roth, 2015), (2) a Seq2Seq baseline, and (3) the same model with a data generation component (GeNeRe) Bouchard et al. (2016).","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"All baselines are trained to predict the best equation, which is executed outside of the model to obtain the answer.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"In contrast, ∂4 is trained end-to-end from input-output pairs and predicts the answer directly without the need for an intermediate symbolic representation of a formula.
","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
Results are shown in Table 3.,"A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"All RNN-based methods 5Due to space constraints, we present the core of the sketch here.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"For the full sketch, please refer to Listing 4 in the Appendix.
(bottom three) outperform the classifier-based approach.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
"Our method slightly outperforms a Seq2Seq baseline, achieving the highest reported result on this dataset without data augmentation.","A florist had 50 roses. If she sold 15 of them and then later picked 21 more, how many roses would she have?",[0],[0]
∂4 bridges the gap between a traditional programming language and a modern machine learning architecture.,5. Discussion,[0],[0]
"However, as we have seen in our evaluation experiments, faithfully simulating the underlying abstract machine architecture introduces its own unique set of challenges.
",5. Discussion,[0],[0]
One such challenge is the additional complexity of performing even simple tasks when they are viewed in terms of operations on the underlying machine state.,5. Discussion,[0],[0]
"As illustrated in Table 1, ∂4 sketches can be effectively trained from small training sets (see Appendix C.1), and generalise perfectly to sequences of any length.",5. Discussion,[0],[0]
"However, difficulty arises when training from sequences of modest lengths.",5. Discussion,[0],[0]
"Even when dealing with relatively short training length sequences, and with the program code optimisations employed, the underlying machine can unroll into a problematically large number states.",5. Discussion,[0],[0]
"For problems whose machine execution is quadratic, like the sorting task (which at input sequences of length 4 has 120 machine states), we observe significant instabilities during training from backpropagating through such long RNN sequences, and consequent failures to train.",5. Discussion,[0],[0]
"In comparison, the addition problem was easier to train due to a comparatively shorter underlying execution RNNs.
",5. Discussion,[0],[0]
The higher degree of prior knowledge provided played an important role in successful learning.,5. Discussion,[0],[0]
"For example, the COMPARE sketch, which provides more structure, achieves higher accuracies when trained on longer sequences.",5. Discussion,[0],[0]
"Similarly, employing softmax on the directly manipulated memory elements enabled perfect training for the MANIPULATE sketch for addition.",5. Discussion,[0],[0]
"Furthermore, it is encouraging to see that ∂4 can be trained jointly with an upstream LSTM to provide strong procedural prior knowledge for solving a real-world NLP task.",5. Discussion,[0],[0]
"Program Synthesis The idea of program synthesis is as old as Artificial Intelligence, and has a long history in computer science (Manna & Waldinger, 1971).",6. Related Work,[0],[0]
"Whereas a large body of work has focused on using genetic programming (Koza, 1992) to induce programs from the given inputoutput specification (Nordin, 1997), there are also various Inductive Programming approaches (Kitzelmann, 2009) aimed at inducing programs from incomplete specifications of the code to be implemented (Albarghouthi et al., 2013; Solar-Lezama et al., 2006).",6. Related Work,[0],[0]
"We tackle the same problem of sketching, but in our case, we fill the sketches with neural networks able to learn the slot behaviour.
",6. Related Work,[0],[0]
"Probabilistic and Bayesian Programming Our work is closely related to probabilistic programming languages such as Church (Goodman et al., 2008).",6. Related Work,[0],[0]
They allow users to inject random choice primitives into programs as a way to define generative distributions over possible execution traces.,6. Related Work,[0],[0]
"In a sense, the random choice primitives in such languages correspond to the slots in our sketches.",6. Related Work,[0],[0]
"A core difference lies in the way we train the behaviour of slots: instead of calculating their posteriors using probabilistic inference, we estimate their parameters using backpropagation and gradient descent.",6. Related Work,[0],[0]
"This is similar in-kind to TerpreT’s FMGD algorithm (Gaunt et al., 2016), which is employed for code induction via backpropagation.",6. Related Work,[0],[0]
"In comparison, our model which optimises slots of neural networks surrounded by continuous approximations of code, enables the combination of procedural behaviour and neural networks.",6. Related Work,[0],[0]
"In addition, the underlying programming and probabilistic paradigm in these programming languages is often functional and declarative, whereas our approach focuses on a procedural and discriminative view.",6. Related Work,[0],[0]
"By using an end-to-end differentiable architecture, it is easy to seamlessly connect our sketches to further neural input and output modules, such as an LSTM that feeds into the machine heap.
",6. Related Work,[0],[0]
"Neural approaches Recently, there has been a surge of research in program synthesis, and execution in deep learning, with increasingly elaborate deep models.",6. Related Work,[0],[0]
"Many of these models were based on differentiable versions of abstract data structures (Joulin & Mikolov, 2015; Grefenstette et al., 2015; Kurach et al., 2016), and a few abstract machines, such as the NTM (Graves et al., 2014), Differentiable Neural Computers (Graves et al., 2016), and Neural GPUs (Kaiser & Sutskever, 2015).",6. Related Work,[0],[0]
All these models are able to induce algorithmic behaviour from training data.,6. Related Work,[0],[0]
"Our work differs in that our differentiable abstract machine allows us to seemingly integrate code and neural networks, and train the neural networks specified by slots via backpropagation.",6. Related Work,[0],[0]
"Related to our efforts is also the Autograd (Maclaurin et al., 2015), which enables automatic gradient computation in
pure Python code, but does not define nor use differentiable access to its underlying abstract machine.
",6. Related Work,[0],[0]
The work in neural approximations to abstract structures and machines naturally leads to more elaborate machinery able to induce and call code or code-like behaviour.,6. Related Work,[0],[0]
Neelakantan et al. (2015a) learned simple SQL-like behaviour–—querying tables from the natural language with simple arithmetic operations.,6. Related Work,[0],[0]
"Although sharing similarities on a high level, the primary goal of our model is not induction of (fully expressive) code but its injection.",6. Related Work,[0],[0]
"(Andreas et al., 2016) learn to compose neural modules to produce the desired behaviour for a visual QA task.",6. Related Work,[0],[0]
"Neural Programmer-Interpreters (Reed & de Freitas, 2015) learn to represent and execute programs, operating on different modes of an environment, and are able to incorporate decisions better captured in a neural network than in many lines of code (e.g. using an image as an input).",6. Related Work,[0],[0]
Users inject prior procedural knowledge by training on program traces and hence require full procedural knowledge.,6. Related Work,[0],[0]
"In contrast, we enable users to use their partial knowledge in sketches.
",6. Related Work,[0],[0]
"Neural approaches to language compilation have also been researched, from compiling a language into neural networks (Siegelmann, 1994), over building neural compilers (Gruau et al., 1995) to adaptive compilation (Bunel et al., 2016).",6. Related Work,[0],[0]
"However, that line of research did not perceive neural interpreters and compilers as a means of injecting procedural knowledge as we did.",6. Related Work,[0],[0]
"To the best of our knowledge, ∂4 is the first working neural implementation of an abstract machine for an actual programming language, and this enables us to inject such priors in a straightforward manner.",6. Related Work,[0],[0]
"We have presented ∂4, a differentiable abstract machine for the Forth programming language, and showed how it can be used to complement programmers’ prior knowledge through the learning of unspecified behaviour in Forth sketches.",7. Conclusion and Future Work,[0],[0]
"The ∂4 RNN successfully learns to sort and add, and solve word algebra problems, using only program sketches and program input-output pairs.",7. Conclusion and Future Work,[0],[0]
"We believe ∂4, and the larger paradigm it helps establish, will be useful for addressing complex problems where low-level representations of the input are necessary, but higher-level reasoning is difficult to learn and potentially easier to specify.
",7. Conclusion and Future Work,[0],[0]
"In future work, we plan to apply ∂4 to other problems in the NLP domain, like machine reading and knowledge base inference.",7. Conclusion and Future Work,[0],[0]
"In the long-term, we see the integration of non-differentiable transitions (such as those arising when interacting with a real environment), as an exciting future direction which sits at the intersection of reinforcement learning and probabilistic programming.",7. Conclusion and Future Work,[0],[0]
"We thank Guillaume Bouchard, Danny Tarlow, Dirk Weissenborn, Johannes Welbl and the anonymous reviewers for fruitful discussions and helpful comments on previous drafts of this paper.",ACKNOWLEDGMENTS,[0],[0]
"This work was supported by a Microsoft Research PhD Scholarship, an Allen Distinguished Investigator Award, and a Marie Curie Career Integration Award.",ACKNOWLEDGMENTS,[0],[0]
We implemented a small subset of available Forth words in ∂4.,A. Forth Words and their implementation,[0],[0]
"The table of these words, together with their descriptions is given in Table 4, and their implementation is given in Table 5.",A. Forth Words and their implementation,[0],[0]
The commands are roughly divided into 7 groups.,A. Forth Words and their implementation,[0],[0]
"These groups, line-separated in the table, are:
Data stack operations {num}, 1+, 1-, DUP, SWAP, OVER, DROP, +, -, *, / Heap operations @, !",A. Forth Words and their implementation,[0],[0]
"Comparators >, <, = Return stack operations >R, R>, @R Control statements IF..ELSE..THEN, BEGIN..WHILE..REPEAT, DO..LOOP Subroutine control :, {sub}, ;, MACRO Variable creation VARIABLE, CREATE..ALLOT",A. Forth Words and their implementation,[0],[0]
An example of a Forth program that implements the Bubble sort algorithm is shown in Listing 1.,B. Bubble sort algorithm description,[0],[0]
"We provide a description of how the first iteration of this algorithm is executed by the Forth abstract machine:
",B. Bubble sort algorithm description,[0],[0]
"The program begins at line 11, putting the sequence [2 4 2 7] on the data stackD, followed by the sequence length 4.6 It then calls the SORTword.
",B. Bubble sort algorithm description,[0],[0]
D R c comment 1,B. Bubble sort algorithm description,[0],[0]
[] [] 11 execution start 2 [2 4 2 7 4],B. Bubble sort algorithm description,[0],[0]
"[] 8 pushing sequence to D, calling
SORT subroutine puts ASORT toR
For a sequence of length 4, SORT performs a do-loop in line 9 that calls the BUBBLE sub-routine 3 times.",B. Bubble sort algorithm description,[0],[0]
It does so by decrementing the top ofD with the 1-word to 3.,B. Bubble sort algorithm description,[0],[0]
"Subsequently, 3 is duplicated onD by using DUP, and 0 is pushed ontoD.
3 [2 4 2 7 3]",B. Bubble sort algorithm description,[0],[0]
[ASORT] 9 1- 4 [2 4 2 7 3 3],B. Bubble sort algorithm description,[0],[0]
[ASORT] 9 DUP 6 [2 4 2 7 3 3 0],B. Bubble sort algorithm description,[0],[0]
"[ASORT] 9 0
DO consumes the top two stack elements 3 and 0 as the limit and starting point of the loop, leaving the stack D to be [2,4,2,7,3].",B. Bubble sort algorithm description,[0],[0]
"We use the return stackR as a temporary variable buffer and push 3 onto it using the word >R. This drops 3 from D, which we copy fromRwith R@
7 [2 4 2 7 3]",B. Bubble sort algorithm description,[0],[0]
[AddrSORT] 9 DO 8 [2 4 2 7] [AddrSORT 3] 9 >R 9 [2 4 2 7 3],B. Bubble sort algorithm description,[0],[0]
"[AddrSORT 3] 9 @R
Next, we call BUBBLE to perform one iteration of the bubble pass, (calling BUBBLE 3 times internally), and consuming 3.",B. Bubble sort algorithm description,[0],[0]
"Notice that this call puts the current program counter ontoR, to be used for the program counter cwhen exiting BUBBLE.
",B. Bubble sort algorithm description,[0],[0]
"Inside the BUBBLE subroutine, DUP duplicates 3 onR.",B. Bubble sort algorithm description,[0],[0]
IF consumes the duplicated 3 and interprets is as TRUE.,B. Bubble sort algorithm description,[0],[0]
>,B. Bubble sort algorithm description,[0],[0]
"R puts 3 onR.
10 [2 4 2 7 3]",B. Bubble sort algorithm description,[0],[0]
[ASORT 3 ABUBBLE] 0 calling BUBBLE subroutine puts ABUBBLE toR 11,B. Bubble sort algorithm description,[0],[0]
[2 4 2 7 3 3],B. Bubble sort algorithm description,[0],[0]
[ASORT 3 ABUBBLE] 1 DUP 12 [2 4 2 7 3],B. Bubble sort algorithm description,[0],[0]
[ASORT 3 ABUBBLE] 1,B. Bubble sort algorithm description,[0],[0]
IF 13 [2 4 2 7],B. Bubble sort algorithm description,[0],[0]
"[ASORT 3 ABUBBLE 3] 1 >R
Calling OVER twice duplicates the top two elements of the stack, to test them with <, which tests whether 2< 7.",B. Bubble sort algorithm description,[0],[0]
"IF tests if the result is TRUE (0), which it is, so it executes SWAP.
14",B. Bubble sort algorithm description,[0],[0]
[2 4 2 7 2 7],B. Bubble sort algorithm description,[0],[0]
[ASORT 3 ABUBBLE 3] 2 OVER OVER 15 [2 4 2 7 1],B. Bubble sort algorithm description,[0],[0]
[ASORT 3 ABUBBLE 3] 2 < 16,B. Bubble sort algorithm description,[0],[0]
[2 4 2 7],B. Bubble sort algorithm description,[0],[0]
[ASORT 3 ABUBBLE 3] 2 IF 17 [2 4 7 2],B. Bubble sort algorithm description,[0],[0]
"[ASORT 3 ABUBBLE 3] 2 SWAP
To prepare for the next call to BUBBLEwe move 3 back from the return stackR to the data stackD via R>, SWAP it with the next element, put it back toRwith >R, decrease the TOS with 1- and invoke BUBBLE again.",B. Bubble sort algorithm description,[0],[0]
"Notice thatRwill accumulate the analysed part of the sequence, which will be recursively taken back.
",B. Bubble sort algorithm description,[0],[0]
18 [2 4 7 2 3],B. Bubble sort algorithm description,[0],[0]
[ASORT 3 ABUBBLE] 3 R> 19,B. Bubble sort algorithm description,[0],[0]
[2 4 7 3 2],B. Bubble sort algorithm description,[0],[0]
[ASORT 3 ABUBBLE] 3 SWAP 20 [2 4 7 3],B. Bubble sort algorithm description,[0],[0]
[ASORT 3 ABUBBLE 2] 3 >R 21 [2 4 7 2],B. Bubble sort algorithm description,[0],[0]
[ASORT 3 ABUBBLE 2] 3 1- 22,B. Bubble sort algorithm description,[0],[0]
[2 4 7 2],B. Bubble sort algorithm description,[0],[0]
"[ASORT 3 ABUBBLE 2] 0 ...BUBBLE
When we reach the loop limit we drop the length of the sequence and exit SORT using the ; word, which takes the return address fromR. At the final point, the stack should contain the ordered sequence [7 4 2 2].
6Note that Forth uses Reverse Polish Notation and that the top of the data stack is 4 in this example.",B. Bubble sort algorithm description,[0],[0]
C.1.,C. Learning and Run Time Efficiency,[0],[0]
"Accuracy per training examples
Sorter When measuring the performance of the model as the number of training instances varies, we can observe the benefit of additional prior knowledge to the optimisation process.",C. Learning and Run Time Efficiency,[0],[0]
"We find that when stronger prior knowledge is provided (COMPARE), the model quickly maximises the training accuracy.",C. Learning and Run Time Efficiency,[0],[0]
"Providing less structure (PERMUTE) results in lower testing accuracy initially, however, both sketches learn the correct behaviour and generalise equally well after seeing 256 training instances.",C. Learning and Run Time Efficiency,[0],[0]
"Additionally, it is worth noting that the PERMUTE sketch was not always able to converge into a result of the correct length, and both sketches are not trivial to train.
",C. Learning and Run Time Efficiency,[0],[0]
"In comparison, Seq2Seq baseline is able to generalise only to the sequence it was trained on (Seq2Seq trained and tested on sequence length 3).",C. Learning and Run Time Efficiency,[0],[0]
"When training it on sequence length 3, and testing it on a much longer sequence length of 8, Seq2Seq baseline is not able to achieve more than 45% accuracy.
",C. Learning and Run Time Efficiency,[0],[0]
Adder We tested the models to train on datasets of increasing size on the addition task.,C. Learning and Run Time Efficiency,[0],[0]
"The results, depicted in Table 4 show that both the choose and the manipulate sketch are able to perfectly generalise from 256 examples, trained on sequence lengths of 8, tested on 16.",C. Learning and Run Time Efficiency,[0],[0]
"In comparison, the Seq2Seq baseline achieves 98% when trained on 16384 examples, but only when tested on the input of the same length, 8.",C. Learning and Run Time Efficiency,[0],[0]
"If we test Seq2Seq as we tested the sketches, it is unable to achieve more 19.7%.
",C. Learning and Run Time Efficiency,[0],[0]
C.2.,C. Learning and Run Time Efficiency,[0],[0]
"Program Code Optimisations
We measure the runtime of Bubble sort on sequences of varying length with and without the optimisations described in Section 3.4.",C. Learning and Run Time Efficiency,[0],[0]
The results of ten repeated runs are shown in Figure 5 and demonstrate large relative improvements for symbolic execution and interpolation of if-branches compared to non-optimised ∂4 code.,C. Learning and Run Time Efficiency,[0],[0]
Listing 1 (lines 3b and 4b – in blue) defines the BUBBLE word as a sketch capturing several types of prior knowledge.,D. ∂4 execution of a Bubble sort sketch,[0],[0]
"In this section, we describe the PERMUTE sketch.",D. ∂4 execution of a Bubble sort sketch,[0],[0]
"In it, we assume BUBBLE involves a recursive call, that terminates at length 1, and that the next BUBBLE call takes as input some function of the current length and the top two stack elements.
",D. ∂4 execution of a Bubble sort sketch,[0],[0]
"The input to this sketch are the sequence to be sorted and its length decremented by one, n−1 (line 1).",D. ∂4 execution of a Bubble sort sketch,[0],[0]
"These inputs
are expected on the data stack.",D. ∂4 execution of a Bubble sort sketch,[0],[0]
"After the length (n − 1) is duplicated for further use with DUP, the machine tests whether it is non-zero (using IF, which consumes the TOS during the check).",D. ∂4 execution of a Bubble sort sketch,[0],[0]
"If n−1>0, it is stored on theR stack for future use (line 2).
",D. ∂4 execution of a Bubble sort sketch,[0],[0]
"At this point (line 3b) the programmer only knows that a decision must be made based on the top two data stack elements D0 and D-1 (comparison elements), and the top return stack,R0 (length decremented by 1).",D. ∂4 execution of a Bubble sort sketch,[0],[0]
"Here the precise nature of this decision is unknown but is limited to variants of permutation of these elements, the output of which produce the input state to the decrement -1 and the recursive BUBBLE call (line 4b).",D. ∂4 execution of a Bubble sort sketch,[0],[0]
"At the culmination of the call, R0, the output of the learned slot behaviour, is moved onto the data stack usingR>, and execution proceeds to the next step.
",D. ∂4 execution of a Bubble sort sketch,[0],[0]
Figure 2 illustrates how portions of this sketch are executed on the ∂4 RNN.,D. ∂4 execution of a Bubble sort sketch,[0],[0]
"The program counter initially resides at >R (line 3 in P), as indicated by the vector c, next to program P. Both data and return stacks are partially filled (R has 1 element, D has 4), and we show the content both through horizontal one-hot vectors and their corresponding integer values (colour coded).",D. ∂4 execution of a Bubble sort sketch,[0],[0]
"The vectors d and r point to the top of both stacks, and are in a one-hot state as well.",D. ∂4 execution of a Bubble sort sketch,[0],[0]
"In this execution trace, the slot at line 4 is already showing optimal behaviour: it remembers the element on the return stack (4) is larger and executes BUBBLE on the remaining sequence with the counter n subtracted by one, to 1.",D. ∂4 execution of a Bubble sort sketch,[0],[0]
"The parameters of each sketch are trained using Adam (Kingma & Ba, 2015), with gradient clipping (set to 1.0) and gradient noise (Neelakantan et al., 2015b).",E. Experimental details,[0],[0]
"We tuned the learning rate, batch size, and the parameters of the gradient noise in a random search on a development variant of each task.
",E. Experimental details,[0],[0]
E.1.,E. Experimental details,[0],[0]
"Seq2Seq baseline
The Seq2Seq baseline models are single-layer networks with LSTM cells of 50 dimensions.
",E. Experimental details,[0],[0]
"The training procedure for these models consists of 500 epochs of Adam optimisation, with a batch size of 128, a learning rate of 0.01, and gradient clipping when the L2 norm of the model parameters exceeded 5.0.",E. Experimental details,[0],[0]
"We vary the size of training and test data (Fig. 3), but observe no indication of the models failing to reach convergence under these training conditions.
",E. Experimental details,[0],[0]
E.2.,E. Experimental details,[0],[0]
"Sorting
The Permute and Compare sketches in Table 1 were trained on a randomly generated train, development and test set
containing 256, 32 and 32 instances, respectively.",E. Experimental details,[0],[0]
"Note that the low number of dev and test instances was due to the computational complexity of the sketch.
",E. Experimental details,[0],[0]
"The batch size was set to a value between 64 and 16, depending on the problem size, and we used an initial learning rate of 1.0.
E.3.",E. Experimental details,[0],[0]
"Addition
We trained the addition Choose and Manipulate sketches presented in Table 2 on a randomly generated train, development and test sets of sizes 512, 256, and 1024 respectively.",E. Experimental details,[0],[0]
"The batch size was set to 16, and we used an initial learning rate of 0.05
E.4.",E. Experimental details,[0],[0]
"Word Algebra Problem
The Common Core (CC) dataset (Roy & Roth, 2015) is partitioned into a train, dev, and test set containing 300, 100, and 200 questions, respectively.",E. Experimental details,[0],[0]
"The batch size was set to 50, and we used an initial learning rate of0.02.",E. Experimental details,[0],[0]
The BiLSTM word vectors were initialised randomly to vectors of length 75.,E. Experimental details,[0],[0]
The stack width was set to 150 and the stack size to 5.,E. Experimental details,[0],[0]
In Figure 6 we visualise the program counter traces.,F. Qualitative Analysis on BubbleSort of PC traces,[0],[0]
"The trace follows a single example from start, to middle, and the end of the training process.",F. Qualitative Analysis on BubbleSort of PC traces,[0],[0]
"In the beginning of training, the program counter starts to deviate from the one-hot representation in the first 20 steps (not observed in the figure due to unobservable changes), and after two iterations ofSORT, ∂4 fails to correctly determine the next word.",F. Qualitative Analysis on BubbleSort of PC traces,[0],[0]
After a few training epochs ∂4 learns better permutations which enable the algorithm to take crisp decisions and halt in the correct state.,F. Qualitative Analysis on BubbleSort of PC traces,[0],[0]
The Word Algebra Problem (WAP) sketch described in Listing 3 is the core of the model that we use for WAP problems.,G. The complete Word Algebra Problem sketch,[0],[0]
"However, there were additional words before and after the core which took care of copying the data from the heap to data and return stacks, and finally emptying out the return stack.
",G. The complete Word Algebra Problem sketch,[0],[0]
The full WAP sketch is given in Listing 4.,G. The complete Word Algebra Problem sketch,[0],[0]
We define a QUESTION variable which will denote the address of the question vector on the heap.,G. The complete Word Algebra Problem sketch,[0],[0]
"Lines 4 and 5 create REPR BUFFER and NUM BUFFER variables and denote that they will occupy four sequential memory slots on the heap, where we will store the representation vectors and numbers, respectively.",G. The complete Word Algebra Problem sketch,[0],[0]
Lines 7 and 8 create variables REPR and NUM which will denote addresses to current representations and numbers on the heap.,G. The complete Word Algebra Problem sketch,[0],[0]
"Lines 10 and 11 store REPR BUFFER to REPR and NUM BUFFER to NUM, essentially setting the values of variables REPR and NUM to starting addresses allotted in lines 4 and 5.",G. The complete Word Algebra Problem sketch,[0],[0]
Lines 14-16 and 19-20 create macro functions STEP NUM and STEP REPR which increment the NUM and REPR values on call.,G. The complete Word Algebra Problem sketch,[0],[0]
These macro functions will be used to iterate through the heap space.,G. The complete Word Algebra Problem sketch,[0],[0]
"Lines 24-25 define macro functions CURRENT NUM for fetching the current number, and CURRENT REPR for fetching representation values.",G. The complete Word Algebra Problem sketch,[0],[0]
Lines 28-32 essentially copy values of numbers from the heap to the data stack by using the CURRENT NUM and STEP NUM macros.,G. The complete Word Algebra Problem sketch,[0],[0]
"After that line 35 pushes the question vector, and lines 36-40 push the word representations of numbers on the return stack.
",G. The complete Word Algebra Problem sketch,[0],[0]
"Following that, we define the core operations of the sketch.",G. The complete Word Algebra Problem sketch,[0],[0]
Line 43 permutes the elements on the data stack (numbers) as a function of the elements on the return stack (vector representations of the question and numbers).,G. The complete Word Algebra Problem sketch,[0],[0]
"Line 45 chooses an operator to execute over the TOS and NOS elements of the data stack (again, conditioned on elements on the return stack).",G. The complete Word Algebra Problem sketch,[0],[0]
Line 47 executes a possible swap of the two elements on the data stack (the intermediate result and the last operand) conditioned on the return stack.,G. The complete Word Algebra Problem sketch,[0],[0]
"Finally, line 49 chooses the last operator to execute on the data stack, conditioned on the return stack.
",G. The complete Word Algebra Problem sketch,[0],[0]
"The sketch ends with lines 52-55 which empty out the return stack.
",G. The complete Word Algebra Problem sketch,[0],[0]
1 \ address of the question on H 2 VARIABLE QUESTION 3 \ allotting H for representations and numbers 4 CREATE REPR_BUFFER 4,G. The complete Word Algebra Problem sketch,[0],[0]
ALLOT 5 CREATE NUM_BUFFER 4,G. The complete Word Algebra Problem sketch,[0],[0]
"ALLOT 6 \ addresses of the first representation and number 7 VARIABLE REPR 8 VARIABLE NUM
10 REPR_BUFFER REPR !",G. The complete Word Algebra Problem sketch,[0],[0]
"11 NUM_BUFFER NUM !
13 \ macro function for incrementing the pointer to numbers in H 14 MACRO:",G. The complete Word Algebra Problem sketch,[0],[0]
"STEP_NUM 15 NUM @ 1+ NUM ! 16 ;
18 \ macro function for incrementing the pointer to representations in H 19 MACRO: STEP_REPR 20 REPR @ 1+ REPR !",G. The complete Word Algebra Problem sketch,[0],[0]
"21 ;
23 \ macro functions for fetching current numbers and representations 24 MACRO: CURRENT_NUM NUM @ @ ; 25 MACRO: CURRENT_REPR",G. The complete Word Algebra Problem sketch,[0],[0]
"REPR @ @ ;
27 \ copy numbers to D 28",G. The complete Word Algebra Problem sketch,[0],[0]
"CURRENT_NUM 29 STEP_NUM 30 CURRENT_NUM 31 STEP_NUM 32 CURRENT_NUM
34 \ copy question vector, and representations of numbers to R 35 QUESTION @ >R 36 CURRENT_REPR >",G. The complete Word Algebra Problem sketch,[0],[0]
R 37 STEP_REPR 38 CURRENT_REPR,G. The complete Word Algebra Problem sketch,[0],[0]
>,G. The complete Word Algebra Problem sketch,[0],[0]
R 39 STEP_REPR 40 CURRENT_REPR,G. The complete Word Algebra Problem sketch,[0],[0]
>,G. The complete Word Algebra Problem sketch,[0],[0]
"R
42 \ permute stack elements, based on the question and number representations 43 { observe R0 R-1 R-2 R-3 -> permute D0 D-1 D-2 } 44 \ choose the first operation 45 { observe R0 R-1 R-2 R-3 -> choose",G. The complete Word Algebra Problem sketch,[0],[0]
+ - * / } 46 \ choose whether to swap intermediate result and the bottom number 47 { observe R0 R-1 R-2 R-3 -> choose SWAP NOP } 48 \ choose the second operation 49 { observe R0 R-1 R-2 R-3 -> choose,G. The complete Word Algebra Problem sketch,[0],[0]
"+ - * / }
51 \ empty out R 52 R> DROP 53 R> DROP",G. The complete Word Algebra Problem sketch,[0],[0]
"54 R> DROP 55 R> DROP
Listing 4: The complete Word Algebra Problem sketch",G. The complete Word Algebra Problem sketch,[0],[0]
"Given that in practice training data is scarce for all but a small set of problems, a core question is how to incorporate prior knowledge into a model.",abstractText,[0],[0]
"In this paper, we consider the case of prior procedural knowledge for neural networks, such as knowing how a program should traverse a sequence, but not what local actions should be performed at each step.",abstractText,[0],[0]
"To this end, we present an end-to-end differentiable interpreter for the programming language Forth which enables programmers to write program sketches with slots that can be filled with behaviour trained from program input-output data.",abstractText,[0],[0]
"We can optimise this behaviour directly through gradient descent techniques on user-specified objectives, and also integrate the program into any larger neural computation graph.",abstractText,[0],[0]
We show empirically that our interpreter is able to effectively leverage different levels of prior program structure and learn complex behaviours such as sequence sorting and addition.,abstractText,[0],[0]
"When connected to outputs of an LSTM and trained jointly, our interpreter achieves state-of-the-art accuracy for end-to-end reasoning about quantities expressed in natural language stories.",abstractText,[0],[0]
Programming with a Differentiable Forth Interpreter,title,[0],[0]
"The conditional gradient algorithm (Frank & Wolfe, 1956) (also known as Frank-Wolfe) is historically the earliest algorithm for solving general constrained convex optimization problems.",1. Introduction,[0],[0]
"Due to its projection-free property and ability to handle structural constraints, it has regained a significant amount of interest in recent years.",1. Introduction,[0],[0]
"Different properties concerning the algorithm, such as the sparsity property (Clarkson, 2010) and the primal-dual convergence rate (Jaggi, 2013), have been analyzed in details.",1. Introduction,[0],[0]
"Many different algorithm variants, such as the composite variant (Harchaoui et al., 2015), the online and stochastic vari-
1Department of Computer Science and Technology, Tsinghua University, Beijing, China 2Artificial Intelligence Department, Ant Financial Services Group, Hangzhou, China 3School of Information Systems, Singapore Management University, Singapore 4Tencent AI Lab, Shenzhen, China.",1. Introduction,[0],[0]
"Correspondence to: Wenwu Zhu <wwzhu@tsinghua.edu.cn>, Wenpeng Zhang <zhangwenpeng0@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"ants (Hazan & Kale, 2012) (Hazan, 2016) (Hazan & Luo, 2016), faster variants over special types of convex domains, i.e. spectrahedron (Garber, 2016) and polytope (Garber & Hazan, 2016), have also been proposed.
",1. Introduction,[0],[0]
"However, despite this great flourish of research on conditional gradient, its distributed online variant over networks has rarely been investigated.",1. Introduction,[0],[0]
"In comparison to this situation is the popularity of the variants of its gradient descent and dual averaging counterparts—distributed online gradient descent (D-OGD) (Ram et al., 2010) (Yan et al., 2013) and distributed online dual averaging (D-ODA) (Duchi et al., 2012) (Hosseini et al., 2013) (Lee et al., 2015), which have been successfully applied in handling large-scale streaming data in decentralized computational architectures (e.g., sensor networks and smart phones).",1. Introduction,[0],[0]
"Despite the success of these algorithms, the projection operation required in them still limits their further applicability in many settings of practical interests.",1. Introduction,[0],[0]
"For example, in matrix learning (Dudı́k et al., 2012), multiclass classification (Hazan & Luo, 2016) and many other related problems, where the convex domain is the set of all matrices with bounded nuclear norm, the projection operation amounts to computing the full singular value decomposition (SVD) of a matrix, too expensive an operation that does not meet the need of locally light computation in distributed online learning.",1. Introduction,[0],[0]
"To avoid this kind of expensive operation, the distributed online variant of conditional gradient is desired since it is expected to be able to eschew the projection operation by using a linear minimization step instead.",1. Introduction,[0],[0]
"In the aforementioned case, the linear step amounts to finding the top singular vector of a matrix, which is at least one order of magnitude simpler.",1. Introduction,[0],[0]
"However, how to design and analyze this variant remains an open problem.
",1. Introduction,[0],[0]
"To fill this gap, in this work, we present the distributed online conditional gradient (D-OCG) algorithm as the desired variant.",1. Introduction,[0],[0]
"This algorithm is a novel extension of the previous online variant (Hazan, 2016), in which each local learner communicates its dual variables with its neighbors to cooperate with each other.",1. Introduction,[0],[0]
"We present highly non-trivial analysis of the regret bound for the proposed algorithm, which can capture the intuition that the algorithm’s regret bound should be larger on graphs with more nodes and should be smaller on ”well-connected” graphs (e.g., complete graphs) than on ”poorly connected” graphs (e.g., cycle graphs).",1. Introduction,[0],[0]
"We
evaluate the performance of the D-OCG algorithm on two large-scale real-world datasets for a multiclass classification task.",1. Introduction,[0],[0]
The experimental results show that D-OCG runs significantly faster than both D-OGD and D-ODA.,1. Introduction,[0],[0]
"This illustrates that although the regret bound for D-OCG is in higher order O(T 3/4) than those in order O(T 1/2) for DOGD and D-ODA, its lower computational cost per iteration outweighs the increased number of iterations, making it overall a faster algorithm.",1. Introduction,[0],[0]
The theoretical results regarding the algorithm’s regret bound for different graphs are also well confirmed.,1. Introduction,[0],[0]
"In this section, we first give a formal definition of the distributed online convex optimization problem, and then review the two algorithms that our algorithm are built upon.",2. Preliminaries,[0],[0]
"Let G = (V,E) denote an undirected graph with vertex set V = {1, · · · , n} and edge set E ⊂ V × V .",2.1. Distributed Online Convex Optimization,[0],[0]
"In distributed online convex optimization defined overG (see the book (Sayed et al., 2014) and the survey (Hazan, 2016) for more details), each node i ∈ V is associated with a separate agent or learner.",2.1. Distributed Online Convex Optimization,[0],[0]
"At each round t = 1, · · · , T , each learner i ∈ V is required to generate a decision point xi(t) from a convex compact set K ⊆ Rm.",2.1. Distributed Online Convex Optimization,[0],[0]
"Then the adversary replies each learner’s decision with a convex loss function ft,i : K → R and each learner suffers the loss ft,i(xi(t)).",2.1. Distributed Online Convex Optimization,[0],[0]
The communication between learners is specified by the graph G: learner,2.1. Distributed Online Convex Optimization,[0],[0]
i can only communicate directly with its immediate neighbors N(i) =,2.1. Distributed Online Convex Optimization,[0],[0]
"{j ∈ V |(i, j) ∈ E}.",2.1. Distributed Online Convex Optimization,[0],[0]
"The goal of the learners is to generate a sequence of decision points xi(t), i ∈ V so that the regret with respect to each learner",2.1. Distributed Online Convex Optimization,[0],[0]
"i regarding any fixed decision x ∈ K in hindsight,
RT (xi,x) = n∑ j=1 T∑ t=1",2.1. Distributed Online Convex Optimization,[0],[0]
"(ft,j(xi(t))− ft,j(x)),
is sublinear in T .
",2.1. Distributed Online Convex Optimization,[0],[0]
"We make the following assumptions: (1) each function ft,i(x) is L-Lipschitz with respect to the L2 norm ‖·‖ on K, i.e. ∀ x,y ∈ K, |ft,i(x)− ft,i(y)| ≤",2.1. Distributed Online Convex Optimization,[0],[0]
L ‖x− y‖ .,2.1. Distributed Online Convex Optimization,[0],[0]
"Note that the Lipschitz condition implies that for any x ∈ K and any∇ft,i(x) ∈ ∂ft,i(x), we have ‖∇ft,i(x)‖ ≤",2.1. Distributed Online Convex Optimization,[0],[0]
"L. (2) the Euclidean diameter of K is bounded by D, i.e. ∀x,y ∈ K, ‖x− y‖ ≤ D.
Two definitions are important for deriving useful properties.",2.1. Distributed Online Convex Optimization,[0],[0]
"We say that a function f is β-smooth if ∀x,y ∈ K, we have
f(y) ≤ f(x) + 〈∇f(x) , y",2.1. Distributed Online Convex Optimization,[0],[0]
− x〉+ β 2 ‖y,2.1. Distributed Online Convex Optimization,[0],[0]
"− x‖2.
We say that a function f is σ-strongly convex if ∀x,y ∈ K, we have
f(y) ≥ f(x) +",2.1. Distributed Online Convex Optimization,[0],[0]
"〈∇f(x) , y − x〉+ σ",2.1. Distributed Online Convex Optimization,[0],[0]
2 ‖y,2.1. Distributed Online Convex Optimization,[0],[0]
"− x‖2.
",2.1. Distributed Online Convex Optimization,[0],[0]
"A σ-strongly convex function f has a very important property: if x∗ = arg minx∈Kf(x), then for any x ∈ K, we have
f(x)− f(x∗)",2.1. Distributed Online Convex Optimization,[0],[0]
≥ σ 2 ‖x− x∗‖2.,2.1. Distributed Online Convex Optimization,[0],[0]
"In the distributed online dual averaging algorithm (Duchi et al., 2012) (Hosseini et al., 2013), each learner i ∈ V maintains a sequence of iterates xi(t) and a sequence of dual variables zi(t).",2.2. Distributed Online Dual Averaging,[0],[0]
"At each round t = 1, · · · , T , each learner i first computes the new dual variable zi(t + 1) from a weighted combination of its new subgradient gi(t) and other dual variables {zj(t), j ∈ N(i)} received from its neighbors, then updates the iterate xi(t + 1) via a proximal projection ∏ψ K(zi(t + 1), αi(t)), where αi(t) is a positive number from a non-increasing sequence, ψ(x) :",2.2. Distributed Online Dual Averaging,[0],[0]
"K → R is a proximal function and∏ψ K(z, α) = arg minx∈K { 〈z , x〉+ 1αψ(x) } denotes the projection onto K operator specified by z, α and ψ(x) (see (Nesterov, 2009) (Xiao, 2010) for more details).",2.2. Distributed Online Dual Averaging,[0],[0]
"The communication between learners is modeled by a doubly stochastic symmetric matrix P , which satisfies (",2.2. Distributed Online Dual Averaging,[0],[0]
"1) Pij > 0 only if (i, j) ∈ E (i 6= j) or i = j; (2) ∀",2.2. Distributed Online Dual Averaging,[0],[0]
"i ∈ V , ∑n j=1 Pij = ∑ j∈N(i) Pij = 1 and ∀ j ∈ V ,∑n
i=1",2.2. Distributed Online Dual Averaging,[0],[0]
"Pij = ∑ i∈N(j) Pij = 1.
",2.2. Distributed Online Dual Averaging,[0],[0]
"Algorithm 1 Distributed Online Dual Averaging (D-ODA) 1: Input: convex set K, maximum round number T , 2: parameters {αi(t)}, ∀",2.2. Distributed Online Dual Averaging,[0],[0]
"i ∈ V 3: Initialize: xi(1) ∈ K, zi(1) = 0, ∀",2.2. Distributed Online Dual Averaging,[0],[0]
"i ∈ V 4: for t = 1, · · · , T do 5:",2.2. Distributed Online Dual Averaging,[0],[0]
"The adversary reveals ft,i, ∀",2.2. Distributed Online Dual Averaging,[0],[0]
"i ∈ V 6: Compute subgradients gi(t) ∈ ∂ft,i(xi(t)), ∀",2.2. Distributed Online Dual Averaging,[0],[0]
"i ∈ V 7: for Each Learner i ∈ V do 8: zi(t+ 1) = ∑ j∈N(i) pijzj(t)+gi(t)
9: xi(t+ 1) = ∏ψ K(zi(t+ 1), αi(t))
10: end for 11: end for",2.2. Distributed Online Dual Averaging,[0],[0]
"The standard online conditional gradient algorithm (Hazan & Kale, 2012) (Hazan, 2016) eschews the computational expensive projection operation by using a simple linear optimization step instead and is thus much more efficient for many computationally intensive tasks.
",2.3. Online Conditional Gradient,[0],[0]
"Algorithm 2 Online Conditional Gradient (OCG) 1: Input: convex set K, maximum round number T , 2: parameters η and {σt} 3: Initialize: x1 ∈ K 4: for t = 1, · · · , T do 5:",2.3. Online Conditional Gradient,[0],[0]
The adversary reveals ft 6: Compute a subgradient gt ∈ ∂ft(xt) 7: Ft(x) = η ∑t−1 i=1,2.3. Online Conditional Gradient,[0],[0]
"〈gi , x〉+",2.3. Online Conditional Gradient,[0],[0]
"‖x− x1‖ 2
8: vt = arg minx∈K {〈∇Ft(xt) , x〉} 9: xt+1 = xt + σt(vt − xt)
10: end for",2.3. Online Conditional Gradient,[0],[0]
"In this section, we first present the proposed distributed online conditional gradient algorithm, and then give the theoretical analysis of its regret bound.",3. Distributed Online Conditional Gradient,[0],[0]
"Algorithm 3 Distributed Online Conditional Gradient (DOCG)
1: Input: convex set K, maximum round number T , 2: parameters {ηi} and{σt,i}, ∀ i ∈ V 3: Initialize: xi(1) ∈ K, zi(1) = 0, ∀",3.1. Algorithm,[0],[0]
"i ∈ V 4: for t = 1, · · · , T do 5:",3.1. Algorithm,[0],[0]
"The adversary reveals ft,i, ∀",3.1. Algorithm,[0],[0]
"i ∈ V 6: Compute subgradients gi(t) ∈ ∂ft,i(xi(t)), ∀",3.1. Algorithm,[0],[0]
"i ∈ V 7: for Each Learner i ∈ V do 8: Ft,i(x) = ηi 〈zi(t) , x〉+ ‖x− x1(1)‖2 9: vi(t) = arg minx∈K {〈∇Ft,i(xi(t)) , x〉}
10: xi(t+ 1) = xi(t) + σt,i(vi(t)− xi(t)) 11: zi(t+ 1) = ∑ j∈N(i) pijzj(t)+gi(t) 12: end for 13: end for",3.1. Algorithm,[0],[0]
Theorem 1.,3.2. Analysis,[0],[0]
The D-OCG algorithm with parameters ηi = (1−σ2(P )),3.2. Analysis,[0],[0]
D 2( √ n+1+( √ n−1)σ2(P )),3.2. Analysis,[0],[0]
"LT 3/4
and σt,i = 1√t for any i ∈ V and any t = 1, · · · , T attains the following regret bound
RT (xi,x) ≤ 8nLDT 3/4
+ 6 √ n+ 1− σ2(P )
4( √ n+ 1 + ( √ n− 1)σ2(P ))",3.2. Analysis,[0],[0]
"LDT 1/4
+ 2( √ n+ 1 + ( √ n− 1)σ2(P ))
1− σ2(P ) LDT 3/4,
where σ2(P ) denotes the second largest eigenvalue of matrix P and 1 − σ2(P ) denotes the corresponding spectral gap value.
",3.2. Analysis,[0],[0]
Remark.,3.2. Analysis,[0],[0]
"(1) The regret bound for D-OCG is in the similar order O(T 3/4) to that of its centralized variant
OCG (Hazan, 2016).",3.2. Analysis,[0],[0]
"(2) Since the connectivity of a graph is captured by its spectral gap value 1−σ2(P ) (Duchi et al., 2012) (Colin et al., 2016): the better the connectivity of a graph is, the larger the spectral gap value will be, it is easy to verify that this theorem captures the intuition that the D-OCG’s regret bound will be larger on larger graphs (the regret bound will be larger when the node size n is larger for all T ) and will be smaller on ”well-connected” graphs than on ”poorly connected” graphs (the regret bound will be smaller when the spectral gap value is larger for certain large T ).
",3.2. Analysis,[0],[0]
"To analyze the regret bound for D-OCG, we first establish its connection to D-ODA.",3.2. Analysis,[0],[0]
"To this end, we consider the following points
x∗i (t) = arg min x∈K",3.2. Analysis,[0],[0]
"Ft,i(x),
where Ft,i(x) are the functions defined in line 8 in D-OCG.",3.2. Analysis,[0],[0]
"Actually, these points are exactly the iterates of D-ODA with regularization ψ(x) =",3.2. Analysis,[0],[0]
"‖x− x1(1)‖2 applied to the following loss functions
f̃t,i(x) = ft,i(x + (xi(t)− x∗i (t))).
",3.2. Analysis,[0],[0]
"Note that these loss functions are not the same as the original ft,i(x) in D-OCG.",3.2. Analysis,[0],[0]
"The reason is that the subgradients used in the aforementioned D-ODA are ∂ft,i(xi(t)) rather than ∂ft,i(x∗i (t)).",3.2. Analysis,[0],[0]
"Indeed, in this algorithm, the subgradients are evaluated at the points x∗i (t), thus the corresponding loss functions f̃t,i(x) should satisfy
∂f̃t,i(x ∗ i (t))",3.2. Analysis,[0],[0]
"= ∂ft,i(xi(t)).
",3.2. Analysis,[0],[0]
"This clearly holds by definition of f̃t,i(x).
",3.2. Analysis,[0],[0]
"Based on the above preparation, we can now present the following lemma.
",3.2. Analysis,[0],[0]
Lemma 1.,3.2. Analysis,[0],[0]
"For any fixed i ∈ V , the following bound holds for any j ∈ V and any x ∈ K T∑ t=1",3.2. Analysis,[0],[0]
"(ft,j(x ∗ i (t))− ft,j(x))
≤",3.2. Analysis,[0],[0]
2L T∑ t=1 ∥∥xj(t)− x∗j (t)∥∥+ T∑ t=1,3.2. Analysis,[0],[0]
"(f̃t,j(x ∗ i (t))− f̃t,j(x)).
",3.2. Analysis,[0],[0]
Proof.,3.2. Analysis,[0],[0]
"By definition of f̃t,j(x) and the Lipschitz-ness of ft,j(x), for any x ∈ K, we have∣∣∣f̃t,j(x)− ft,j(x)∣∣∣ ≤",3.2. Analysis,[0],[0]
L∥∥xj(t)− x∗j (t)∥∥ .,3.2. Analysis,[0],[0]
"Then by plugging in two auxiliary terms in each difference
ft,j(x ∗ i (t))− ft,j(x), we obtain T∑ t=1",3.2. Analysis,[0],[0]
"(ft,j(x ∗ i (t))− ft,j(x))
= T∑ t=1 (ft,j(x ∗ i (t))− f̃t,j(x∗i (t))",3.2. Analysis,[0],[0]
"+ f̃t,j(x)− ft,j(x)
+ f̃t,j(x ∗ i (t))− f̃t,j(x))
≤ T∑ t=1 ∣∣∣ft,j(x∗i (t))− f̃t,j(x∗i (t))∣∣∣ +
T∑ t=1 ∣∣∣f̃t,j(x)− ft,j(x)∣∣∣ +
T∑ t=1",3.2. Analysis,[0],[0]
"(f̃t,j(x ∗ i (t))− f̃t,j(x))
≤",3.2. Analysis,[0],[0]
2L T∑ t=1 ∥∥xj(t)− x∗j (t)∥∥+ T∑ t=1,3.2. Analysis,[0],[0]
"(f̃t,j(x ∗ i (t))− f̃t,j(x)).
",3.2. Analysis,[0],[0]
"Notice that the last summation in the above bound is exactly the part of the regret of D-ODA incurred by learner j with respect to learner i. Thus, to proceed, we require lemmas that allow us to relate the iterates xi(t) to the iterates x∗i (t).",3.2. Analysis,[0],[0]
"Let ht,i(x) = Ft,i(x)",3.2. Analysis,[0],[0]
"− Ft,i(x∗i (t))",3.2. Analysis,[0],[0]
"and ht,i = ht,i(xi(t)).",3.2. Analysis,[0],[0]
"In the following, we first present a lemma that establishes the recursion between ht+1,i and ht,i.
Lemma 2.",3.2. Analysis,[0],[0]
"The following recursion between ht+1,i and ht,i holds for any i ∈ V and any t = 1, · · · , T
ht+1,i ≤ (1− σt,i)ht,i + σ2t,iD2",3.2. Analysis,[0],[0]
+ ηi ‖zi(t+,3.2. Analysis,[0],[0]
1)−,3.2. Analysis,[0],[0]
"zi(t)‖ √ ht+1,i,
where zi(t) denotes the dual variable defined in D-OCG.
",3.2. Analysis,[0],[0]
Proof.,3.2. Analysis,[0],[0]
"Using the definitions of ht,i(x) and xi(t + 1), the fact that Ft,i(x) are 2-smooth and the boundedness of K, we obtain
ht,i(xi(t+ 1))",3.2. Analysis,[0],[0]
"= Ft,i(xi(t) + σt,i(vi(t)− xi(t)))",3.2. Analysis,[0],[0]
"− Ft,i(x∗i (t)) ≤",3.2. Analysis,[0],[0]
"Ft,i(xi(t))− Ft,i(x∗i (t))
+ σt,i 〈∇Ft,i(xi(t)) , vi(t)− xi(t)〉
+ σ2t,i ‖vi(t)− xi(t)‖ 2
≤",3.2. Analysis,[0],[0]
"Ft,i(xi(t))− Ft,i(x∗i (t))",3.2. Analysis,[0],[0]
"+ σt,i 〈∇Ft,i(xi(t)) , vi(t)− xi(t)〉 + σ2t,iD 2.
",3.2. Analysis,[0],[0]
"By the optimality of vi(t), we have
〈∇Ft,i(xi(t)) , vi(t)〉 ≤ 〈∇Ft,i(xi(t)) , x∗i (t)〉 .
",3.2. Analysis,[0],[0]
"By the convexity of Ft,i(x), we have
〈∇Ft,i(xi(t)) , x∗i (t)− xi(t)〉 ≤ Ft,i(x∗i (t))−Ft,i(xi(t)).
",3.2. Analysis,[0],[0]
"Putting the above three inequalities together, we obtain
ht,i(xi(t+ 1))",3.2. Analysis,[0],[0]
≤,3.2. Analysis,[0],[0]
"Ft,i(xi(t))− Ft,i(x∗i (t))",3.2. Analysis,[0],[0]
"+ σt,i(Ft,i(x ∗ i (t))− Ft,i(xi(t)))
",3.2. Analysis,[0],[0]
"+ σ2t,iD 2
= (1− σt,i)(Ft,i(xi(t))− Ft,i(x∗i (t)))",3.2. Analysis,[0],[0]
"+ σ2t,iD 2 = (1− σt,i)ht,i + σ2t,iD2.
",3.2. Analysis,[0],[0]
"Next, by definition of ht+1,i and the optimality of x∗i (t), we have
ht+1,i = Ft+1,i(xi(t+ 1))− Ft+1,i(x∗i (t+ 1))",3.2. Analysis,[0],[0]
"= Ft,i(xi(t+ 1))− Ft,i(x∗i (t+ 1))
+ (Ft+1,i(xi(t+ 1))− Ft,i(xi(t+ 1)))",3.2. Analysis,[0],[0]
"− (Ft+1,i(x∗i (t+ 1))− Ft,i(x∗i (t+ 1)))",3.2. Analysis,[0],[0]
≤,3.2. Analysis,[0],[0]
"Ft,i(xi(t+ 1))− Ft,i(x∗i (t))
",3.2. Analysis,[0],[0]
"+ (Ft+1,i(xi(t+ 1))− Ft,i(xi(t+ 1)))",3.2. Analysis,[0],[0]
"− (Ft+1,i(x∗i (t+ 1))− Ft,i(x∗i (t+ 1))).
",3.2. Analysis,[0],[0]
"Then, by definition of Ft+1,i(x) and Ft,i(x), we have
Ft+1,i(x)− Ft,i(x) = ηi 〈zi(t+ 1)− zi(t),x〉 .
",3.2. Analysis,[0],[0]
"Thus,
ht+1,i ≤ ht,i(xi(t+ 1))",3.2. Analysis,[0],[0]
"+ ηi 〈zi(t+ 1)− zi(t),xi(t+ 1)〉 − ηi 〈zi(t+ 1)− zi(t),x∗i",3.2. Analysis,[0],[0]
(,3.2. Analysis,[0],[0]
"t+ 1)〉
= ht,i(xi(t+ 1))
",3.2. Analysis,[0],[0]
+ ηi 〈,3.2. Analysis,[0],[0]
"zi(t+ 1)− zi(t),xi(t+",3.2. Analysis,[0],[0]
"1)− x∗i (t+ 1)〉 ≤ ht,i(xi(t+ 1))
",3.2. Analysis,[0],[0]
+ ηi ‖zi(t+,3.2. Analysis,[0],[0]
"1)− zi(t)‖ ‖xi(t+ 1)− x∗i (t+ 1)‖ .
",3.2. Analysis,[0],[0]
"The last inequality follows from the Cauchy-Schwarz inequality.
",3.2. Analysis,[0],[0]
"Now, we derive the bound for ‖xi(t+ 1)− x∗i (t+ 1)‖. By definition, Ft,i(x) are 2-strongly convex and x∗i (t) = arg minx∈K",3.2. Analysis,[0],[0]
"Ft,i(x).",3.2. Analysis,[0],[0]
"Thus, using the property of strongly convex functions, for any x ∈ K, we have
‖x− x∗i (t)‖ 2 ≤",3.2. Analysis,[0],[0]
"Ft,i(x)− Ft,i(x∗i (t)).
",3.2. Analysis,[0],[0]
"Analogously, it is easy to deduce that
‖xi(t+ 1)− x∗i (t+ 1)‖ ≤ √ ht+1,i.
",3.2. Analysis,[0],[0]
"Combining this bound and the above two bounds for ht+1,i and ht,i(xi(t+ 1)) yields the stated recursion.
",3.2. Analysis,[0],[0]
"To make the above recursion more concrete, it remains to bound the deviation term ‖zi(t+ 1)− zi(t)‖, which measures the stability of local dual variables over each node.
",3.2. Analysis,[0],[0]
Lemma 3.,3.2. Analysis,[0],[0]
"For any i ∈ V and any t = 1, · · · , T , the dual variables zi(t) and zi(t + 1) specified in D-OCG satisfy the following bound
‖zi(t+ 1)− zi(t)‖ ≤ 1 + σ2(P ) 1−",3.2. Analysis,[0],[0]
"σ2(P ) √ nL+ L.
Proof.",3.2. Analysis,[0],[0]
"Let P r denote the r-th power of matrix P and P rij denote the j-th entry of the i-th row of P r. Then, via a bit of algebra, we can get the following generalized recursion
zi(t+ 1) = n∑",3.2. Analysis,[0],[0]
j=1 P,3.2. Analysis,[0],[0]
t+1−sij zj(s),3.2. Analysis,[0],[0]
"+ t−1∑ r=s n∑ j=1 P t−rij gj(r)
+ gi(t).
",3.2. Analysis,[0],[0]
"Clearly, this recursion reduces to the standard dual variable update in D-OCG when s = t. Next, since zj(1) = 0, by setting s = 1, we can obtain
zi(t+ 1) = t−1∑ r=1 n∑ j=1 P t−rij gj(r) + gi(t).
",3.2. Analysis,[0],[0]
"Then by assuming P 0 to be the identity matrix In, we have zi(t+1)−zi(t) = t−1∑ r=1 n∑ j=1 (P t−rij",3.2. Analysis,[0],[0]
"− P t−r−1 ij )gj(r)+gi(t).
",3.2. Analysis,[0],[0]
"Using the fact that ‖gi(t)‖ ≤ L, the properties of norm functions and the symmetry of matrix P , we obtain
‖zi(t+",3.2. Analysis,[0],[0]
"1)− zi(t)‖
= ∥∥∥∥∥∥ t−1∑ r=1 n∑ j=1 (P t−rij",3.2. Analysis,[0],[0]
− P t−r−1 ij )gj(r),3.2. Analysis,[0],[0]
+ gi(t) ∥∥∥∥∥∥,3.2. Analysis,[0],[0]
"≤
t−1∑ r=1 n∑ j=1 ∣∣P t−rij",3.2. Analysis,[0],[0]
− P t−r−1ij ∣∣ ∥∥gj(r)∥∥+,3.2. Analysis,[0],[0]
"‖gi(t)‖ ≤ L
t−1∑ r=1 ∥∥P",3.2. Analysis,[0],[0]
"t−ri − P t−r−1i ∥∥1 + L, where P ri denotes the i-th column of matrix P r.
Now we try to bound the L1 norm sum in the above inequality.",3.2. Analysis,[0],[0]
"By plugging in an all-ones column vector and then using the properties of norm functions, we obtain
t−1∑ r=1 ∥∥P",3.2. Analysis,[0],[0]
"t−ri − P t−r−1i ∥∥1 =
t−1∑ r=1 ∥∥(P t−ri",3.2. Analysis,[0],[0]
"− 1/n)− (P t−r−1i − 1/n)∥∥1 ≤
t−1∑ r=1 ( ∥∥P t−ri − 1/n∥∥1 + ∥∥P t−r−1i − 1/n∥∥1).
",3.2. Analysis,[0],[0]
"To proceed, we introduce a useful property of stochastic matrices (Duchi et al., 2012).",3.2. Analysis,[0],[0]
"Let ∆n = {x ∈ Rn |x 0, ∑n i=1",3.2. Analysis,[0],[0]
xi = 1} denote the n-dimensional probability simplex.,3.2. Analysis,[0],[0]
"Then for any positive integer s = 1, · · · and any x ∈ ∆n, the following inequality holds
‖P sx− 1/n‖1 ≤ σ2(P ) s √ n.
Taking x to be the i-th canonical basis vector ei in Rn, we have
‖P sei − 1/n‖1 ≤ σ2(P ) s √ n.
Note that this inequality also holds for s = 0 since∥∥P 0ei",3.2. Analysis,[0],[0]
"− 1/n∥∥1 = 2(n− 1)n ≤ √n, for any n = 1, · · · .",3.2. Analysis,[0],[0]
"In addition, it is easy to verify that
‖P si − 1/n‖1 = ‖P sei − 1/n‖1.
",3.2. Analysis,[0],[0]
"Thus, we have
t−1∑ r=1 ( ∥∥P t−ri",3.2. Analysis,[0],[0]
"− 1/n∥∥1 + ∥∥P t−r−1i − 1/n∥∥1)
≤ t−1∑ r=1 (σ2(P ) t−r + σ2(P ) t−r−1)",3.2. Analysis,[0],[0]
"√ n
= 1 + σ2(P )
1− σ2(P ) (1− σ2(P )t−1)
",3.2. Analysis,[0],[0]
"√ n
≤ 1 + σ2(P ) 1− σ2(P ) √ n.
The above equation and the last inequality follow respectively from the summation formula of geometric series and the fact that σ2(P ) < 1 when P is a doubly stochastic matrix (Berman & Plemmons, 1979).
",3.2. Analysis,[0],[0]
"Combining the above together yields the stated bound.
",3.2. Analysis,[0],[0]
"Combining the results in Lemma 2 and Lemma 3, we can obtain a more concrete recursion between ht+1,i and ht,i, and then deduce the bound for ht,i.
Lemma 4.",3.2. Analysis,[0],[0]
"Assume that the parameters ηi and σt,i in DOCG are chosen such that ηi(
1+σ2(P ) 1−σ2(P )
",3.2. Analysis,[0],[0]
"√ n+1)L √ ht+1,i ≤
σ2t,iD 2.",3.2. Analysis,[0],[0]
"Then the following bound for ht,i holds for any i ∈ V and any t = 1, · · · , T
ht,i ≤ 4D2σt,i.
",3.2. Analysis,[0],[0]
This lemma can be easily proved using mathematical induction and we place its detailed proof in the Appendix.,3.2. Analysis,[0],[0]
Now we can deduce the bound for the deviation between xi(t) and x∗i (t).,3.2. Analysis,[0],[0]
Lemma 5.,3.2. Analysis,[0],[0]
"For any fixed i ∈ V , the iterates xi(t) and x∗i (t) satisfy the following bound
T∑ t=1",3.2. Analysis,[0],[0]
‖xi(t)−,3.2. Analysis,[0],[0]
x∗i,3.2. Analysis,[0],[0]
"(t)‖ ≤ 8 3 DT 3/4.
Proof.",3.2. Analysis,[0],[0]
"As is given in the proof of Lemma 2, for any x ∈ K, we have
‖x− x∗i (t)‖ 2 ≤",3.2. Analysis,[0],[0]
"Ft,i(x)− Ft,i(x∗i (t)).
",3.2. Analysis,[0],[0]
"It then follows that ‖xi(t)− x∗i (t)‖ ≤ √ Ft,i(xi(t))− Ft,i(x∗i (t))
=",3.2. Analysis,[0],[0]
"√ ht,i ≤ 2D√σt,i = 2Dt−1/4.
",3.2. Analysis,[0],[0]
"The last inequality follows from the bound in Lemma 4 and the last equation follows from the definition of σt,i. Thus, summing over t = 1, · · · , T , we obtain
T∑ t=1 ‖xi(t)− x∗i (t)‖ ≤ 2D T∑ t=1 t−1/4
≤ 2D(1 + ∫ T 1 t−1/4dt)
= 2D(1 + 4
3 t3/4 ∣∣∣∣T 1 )
≤ 2D(4 3 T 3/4",3.2. Analysis,[0],[0]
"− 1 3 ) = 8
3 DT 3/4.
",3.2. Analysis,[0],[0]
"Before proceeding with the final proof of Theorem 1, we present the regret bound of the D-ODA algorithm applied to the loss functions f̃t,j(x).",3.2. Analysis,[0],[0]
"To this end, we first introduce an auxiliary sequence which are composed of the centralized averages of dual variables over all nodes at each iteration
z̄(t)",3.2. Analysis,[0],[0]
"= 1
n n∑ i=1 zi(t).
",3.2. Analysis,[0],[0]
Note that the dual variables used in the above definition are exactly those specified in D-OCG.,3.2. Analysis,[0],[0]
"Then, as for the deviation between the local dual variable zi(t) and the global dual variable z̄(t), we have the following lemma.",3.2. Analysis,[0],[0]
Lemma 6.,3.2. Analysis,[0],[0]
"For any i ∈ V and any t = 1, · · · , T , the dual variable zi(t) defined in D-OCG and their averages z̄(t) over all nodes satisfy the following bound
‖zi(t)− z̄(t)‖ ≤ √ nL
1− σ2(P ) .
",3.2. Analysis,[0],[0]
"Two similar bounds for ‖zi(t)− z̄(t)‖ in D-ODA are reported in (Duchi et al., 2012) (Hosseini et al., 2013)1 .",3.2. Analysis,[0],[0]
Our bound is tighter than both of them.,3.2. Analysis,[0],[0]
"The proof is a little bit similar to that in Lemma 3 and is presented in detail in the Appendix.
",3.2. Analysis,[0],[0]
We can now give the regret bound for the D-ODA algorithm in the following lemma.,3.2. Analysis,[0],[0]
Lemma 7.,3.2. Analysis,[0],[0]
The D-ODA algorithm with regularization ψ(x) =,3.2. Analysis,[0],[0]
"‖x− x1(1)‖2 and parameters αi(t) = η, ∀",3.2. Analysis,[0],[0]
"i ∈ V , applied to the loss functions f̃t,j(x) attains the following regret bound
RaT (xi,x) ≤ 6 √ n+ 1− σ2(P )
2(1− σ2(P ))",3.2. Analysis,[0],[0]
"ηL2T +
1 η D2.
",3.2. Analysis,[0],[0]
"Using our tighter bound for ‖zi(t)− z̄(t)‖, this lemma can be easily deduced from the general regret bound for the DODA algorithm (Hosseini et al., 2013).",3.2. Analysis,[0],[0]
"The detailed proof is presented in the Appendix.
",3.2. Analysis,[0],[0]
"Now, we are ready to prove our theorem.
",3.2. Analysis,[0],[0]
Proof of Theorem 1.,3.2. Analysis,[0],[0]
"By plugging in two auxiliary terms in each difference ft,j(xi(t))− ft,j(x), we have T∑ t=1 (ft,j(xi(t))− ft,j(x))
= T∑ t=1 (ft,j(xi(t))− ft,j(x∗i (t))",3.2. Analysis,[0],[0]
"+ ft,j(x∗i (t))− ft,j(x))
≤ T∑ t=1 |ft,j(xi(t))− ft,j(x∗i (t))|
+ T∑ t=1 (ft,j(x ∗ i (t))− ft,j(x)).
",3.2. Analysis,[0],[0]
"Using the Lipschitz-ness of ft,j(x), we can obtain the following bound for the first summation T∑ t=1 |ft,j(xi(t))− ft,j(x∗i (t))| ≤ L T∑ t=1 ‖xi(t)− x∗i (t)‖ .
",3.2. Analysis,[0],[0]
"1Strictly, the norm utilized in them is the general dual norm.
",3.2. Analysis,[0],[0]
Recall that Lemma 1 provides the bound for the second summation.,3.2. Analysis,[0],[0]
"Combining these two bounds together, we have T∑ t=1 (ft,j(xi(t))− ft,j(x))
≤",3.2. Analysis,[0],[0]
L T∑ t=1 ‖xi(t)− x∗i,3.2. Analysis,[0],[0]
(t)‖+ 2L T∑ t=1 ∥∥xj(t)−,3.2. Analysis,[0],[0]
"x∗j (t)∥∥ +
T∑ t=1",3.2. Analysis,[0],[0]
"(f̃t,j(x ∗ i (t))− f̃t,j(x)).
",3.2. Analysis,[0],[0]
"Hence,
RT (xi,x) = n∑ j=1 T∑ t=1",3.2. Analysis,[0],[0]
"(ft,j(xi(t))− ft,j(x))
≤ nL T∑ t=1 ‖xi(t)− x∗i (t)‖
+ 2L n∑ j=1 T∑ t=1 ∥∥xj(t)−",3.2. Analysis,[0],[0]
"x∗j (t)∥∥ +
n∑ j=1 T∑ t=1",3.2. Analysis,[0],[0]
"(f̃t,j(x ∗ i (t))− f̃t,j(x)).
",3.2. Analysis,[0],[0]
"Note that, as the parameters are set to be η1 = · · · = ηn = η, the last term in the right side is exactly the regret of the D-ODA algorithm applied to f̃t,j(x).",3.2. Analysis,[0],[0]
"In addition, using the results in Lemma 5, the sum of the first and the second terms is further bounded by 8nLDT 3/4.",3.2. Analysis,[0],[0]
"Thus, we have
RT (xi,x) ≤ 8nLDT 3/4",3.2. Analysis,[0],[0]
"+RaT (xi,x)
≤ 8nLDT 3/4 + 6 √ n+ 1− σ2(P )
2(1− σ2(P )) ηL2T
+ 1
η D2.
",3.2. Analysis,[0],[0]
Let η = (1−σ2(P )),3.2. Analysis,[0],[0]
D 2( √ n+1+( √ n−1)σ2(P )),3.2. Analysis,[0],[0]
"LT 3/4
.",3.2. Analysis,[0],[0]
"Then via a bit of analysis, we can verify that the choice of ηi satisfies the constraint required in Lemma 4
ηi( 1 + σ2(P ) 1− σ2(P )",3.2. Analysis,[0],[0]
"√ n+ 1)L
√ ht+1,i ≤ σ2t,iD2.
",3.2. Analysis,[0],[0]
"The detailed verification is presented in the Appendix.
",3.2. Analysis,[0],[0]
"We thus finally obtain
RT (xi,x) ≤ 8nLDT 3/4
+ 6 √ n+ 1− σ2(P )
4( √ n+ 1 + ( √ n− 1)σ2(P ))",3.2. Analysis,[0],[0]
"LDT 1/4
+ 2( √ n+ 1 + ( √ n− 1)σ2(P ))
1− σ2(P ) LDT 3/4.",3.2. Analysis,[0],[0]
"To evaluate the performance of the proposed D-OCG algorithm, we conduct simulation experiments for a popular machine learning problem: multiclass classification.",4. Experiments,[0],[0]
"Multiclass Classification In the distributed online learning setting, the problem is as follows.",4.1. Experimental Setup,[0],[0]
"At each round t = 1, · · · , T , each learner i is presented with a data example ei(t) ∈ Rk which belongs to one of the classes C = {1, · · · , h} and is required to generate a decision matrix Xi(t) =",4.1. Experimental Setup,[0],[0]
[xT1 ; · · · ;xTh ] ∈ Rh×k that predicts the class label with arg max`∈C xT` ei(t).,4.1. Experimental Setup,[0],[0]
"Then the adversary reveals the true class labels yi(t) and each learner i suffers a convex multivariate logistic loss
ft,i(Xi(t))",4.1. Experimental Setup,[0],[0]
"= log ( 1+ ∑
` 6=yi(t)
exp(xT` ei(t)− xTyi(t)ei(t)) ) .
",4.1. Experimental Setup,[0],[0]
"The convex domain of the decision matrices is K = {X ∈ Rh×k| ‖X‖tr ≤ τ}, where ‖·‖tr denotes the nuclear norm of matrices.",4.1. Experimental Setup,[0],[0]
"In this case, the linear minimization required in each iteration of D-OCG amounts to compute a matrix’s top singular vector, an operation that can be done in time near linear to the number of non-zeros in the matrix, whereas the projection onto K operation needed in traditional distributed online algorithms amounts to performing a full SVD, an O(hkmin(h, k)) time operation that is much more expensive.
",4.1. Experimental Setup,[0],[0]
"Datasets We use two multiclass datasets selected from the LIBSVM2 repository with relatively large number of instances, which is summarized in Table 1.
",4.1. Experimental Setup,[0],[0]
"Network Topology To investigate the influence of network topology, we conduct our experiments on three types of graphs, which represent different levels of connectivity.
",4.1. Experimental Setup,[0],[0]
• Complete graph.,4.1. Experimental Setup,[0],[0]
"This represents the highest level of connectivity in our experiments: all nodes are connected to each other.
",4.1. Experimental Setup,[0],[0]
• Cycle graph.,4.1. Experimental Setup,[0],[0]
"This represents the lowest level of connectivity in our experiments: each node has only two immediate neighbors.
",4.1. Experimental Setup,[0],[0]
• Watts-Strogatz.,4.1. Experimental Setup,[0],[0]
"This random graph generation technique (Watts & Strogatz, 1998) has two tunable pa-
2https://www.csie.ntu.edu.tw/ cjlin/libsvmtools/datasets/
rameters: the average degree of the graph k and the rewiring probability p.",4.1. Experimental Setup,[0],[0]
"In general, the higher the rewiring probability, the better the connectivity of the graph (Colin et al., 2016).",4.1. Experimental Setup,[0],[0]
"We tune the parameters k = 4 and p = 0.3 to achieve an intermediate level of connectivity in our experiments.
",4.1. Experimental Setup,[0],[0]
"Compared Algorithms To evaluate the performance benefit of D-OCG over its counterparts with projection operation, we compare it with two classic algorithms: DOGD (Yan et al., 2013) and D-ODA (Hosseini et al., 2013).",4.1. Experimental Setup,[0],[0]
"To verify that performing online conditional gradient in the distributed setting does not lose much quality compared with that in the centralized setting, we also compare DOCG with OCG, i.e. D-OCG with 1 node.
",4.1. Experimental Setup,[0],[0]
Parameter Settings,4.1. Experimental Setup,[0],[0]
We set most of the parameters in these algorithms as what their corresponding theories suggest.,4.1. Experimental Setup,[0],[0]
"For instance, the parameters σt,i in D-OCG are strictly set to be 1√
t and the learning rates in D-OGD are
set to be the typical decaying sequence 1√ t .",4.1. Experimental Setup,[0],[0]
"We use the method utilized in (Duchi et al., 2012) to generate the doubly stochastic matrices and fix the nuclear norm bound τ to 50 throughout.",4.1. Experimental Setup,[0],[0]
"We measure the running time of the D-OGD, D-ODA and D-OCG algorithms run on a complete graph with 9 nodes and see how fast the average losses decrease.",4.2. Experimental Results,[0],[0]
"From the results shown in Figure 1, we can clearly observe that DOCG is significantly faster than both D-OGD and D-ODA, which illustrates the necessity and usefulness of using conditional gradient in distributed online learning.
",4.2. Experimental Results,[0],[0]
We then investigate how the number of nodes affects the performance of D-OCG by running experiments on complete graphs with varying number of nodes.,4.2. Experimental Results,[0],[0]
"From the results shown in Figure 2(a), we can make the following two main observations.",4.2. Experimental Results,[0],[0]
"First, the average losses decrease
more slowly on larger graphs than on smaller graphs, which nicely confirms our theoretical results.",4.2. Experimental Results,[0],[0]
"Second, D-OCG is able to yield comparable results to the centralized OCG.
",4.2. Experimental Results,[0],[0]
We finally test the influence of network topology on the algorithm’s performance.,4.2. Experimental Results,[0],[0]
We run experiments on the aforementioned three types of graphs with 16 nodes using the aloi dataset.,4.2. Experimental Results,[0],[0]
"As shown in Figure 2(b), graphs with better connectivity lead to slightly faster convergence, which illustrates good agreement of empirical results with our theoretical predictions.",4.2. Experimental Results,[0],[0]
"In this paper, we propose the distributed online conditional gradient algorithm for projection-free distributed online learning in networks.",5. Conclusion,[0],[0]
"We give detailed analysis of the regret bound for the proposed algorithm, which depends on both the network size and the network topology.",5. Conclusion,[0],[0]
We evaluate the efficacy of the proposed algorithm on two real-world datasets for a multiclass classification task and find that it runs significantly faster than the counterpart algorithms with projection.,5. Conclusion,[0],[0]
The theoretical results regarding the regret bound for different graphs have also been verified.,5. Conclusion,[0],[0]
This work is supported by National Program on Key Basic Research Project No. 2015CB352300 and National Natural Science Foundation of China Major Project No. U1611461.,Acknowledgements,[0],[0]
"It is also supported by the National Research Foundation, Prime Ministers Office, Singapore under its International Research Centres in Singapore Funding Initiative.",Acknowledgements,[0],[0]
We thank Zheng Xiong for helping constructing the networks and thank Wei Liu for his kind help in preparing the submission and the rebuttal.,Acknowledgements,[0],[0]
We finally acknowledge anonymous reviewers for their insightful comments on comparison and explanation of the regret bound.,Acknowledgements,[0],[0]
The conditional gradient algorithm has regained a surge of research interest in recent years due to its high efficiency in handling large-scale machine learning problems.,abstractText,[0],[0]
"However, none of existing studies has explored it in the distributed online learning setting, where locally light computation is assumed.",abstractText,[0],[0]
"In this paper, we fill this gap by proposing the distributed online conditional gradient algorithm, which eschews the expensive projection operation needed in its counterpart algorithms by exploiting much simpler linear optimization steps.",abstractText,[0],[0]
"We give a regret bound for the proposed algorithm as a function of the network size and topology, which will be smaller on smaller graphs or ”well-connected” graphs.",abstractText,[0],[0]
Experiments on two large-scale real-world datasets for a multiclass classification task confirm the computational benefit of the proposed algorithm and also verify the theoretical regret bound.,abstractText,[0],[0]
Projection-free Distributed Online Learning in Networks,title,[0],[0]
"Online optimization has been a successful framework for solving large-scale problems under computational constraints and partial information. Current methods for online convex optimization require either a projection or exact gradient computation at each step, both of which can be prohibitively expensive for large-scale applications. At the same time, there is a growing trend of nonconvex optimization in machine learning community and a need for online methods. Continuous DR-submodular functions, which exhibit a natural diminishing returns condition, have recently been proposed as a broad class of non-convex functions which may be efficiently optimized. Although online methods have been introduced, they suffer from similar problems. In this work, we propose Meta-Frank-Wolfe, the first online projectionfree algorithm that uses stochastic gradient estimates. The algorithm relies on a careful sampling of gradients in each round and achieves the optimal O( √ T ) adversarial regret bounds for convex and continuous submodular optimization. We also propose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single stochastic gradient estimate in each round and achieves an O(T 2/3) stochastic regret bound for convex and continuous submodular optimization. We apply our methods to develop a novel “lifting” framework for the online discrete submodular maximization and also see that they outperform current state-of-the-art techniques on various experiments.
1Yale Institute for Network Science, Yale University, New Haven, CT, USA 2Department of Electrical Engineering, Yale University 3Department of Computer Science, Yale University 4Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA. Correspondence to: Lin Chen <lin.chen@yale.edu>.",text,[0],[0]
"As the amount of collected data becomes massive in both size and complexity, algorithm designers are faced with unprecedented challenges in statistics, machine learning, and control.",1. Introduction,[0],[0]
"In the past decade, online optimization has provided a successful computational framework for tackling a wide variety of challenging problems, ranging from non-parametric regression to portfolio management (Calandriello et al., 2017; Agarwal et al., 2006).",1. Introduction,[0],[0]
"In online optimization, a large or complex optimization problem is broken down into a sequence of smaller optimization problems, each of which must be solved with limited information.",1. Introduction,[0],[0]
This framework captures many real-world scenarios in which standard optimization theory does not apply.,1. Introduction,[0],[0]
"For instance, a machine learning application cannot feasibly process terabytes of data at a single time; rather, subsets of data may be handled in a sequential fashion.",1. Introduction,[0],[0]
"Another example is when the true objective function is the expectation of an unknown distribution of functions, and may only be accessible via samples, as is the case for problems in online learning and control theory (Xiao, 2010; Wang & Boyd, 2008).
",1. Introduction,[0],[0]
"Online convex optimization, a branch of online optimization that considers sequentially minimizing convex functions, has proved particularly useful for statistical and machine learning applications.",1. Introduction,[0],[0]
Online convex optimization has enjoyed much success in these areas because most offline machine learning techniques utilize the existing theory of convex optimization.,1. Introduction,[0],[0]
"As in the offline setting, gradient methods are a popular class of algorithms for online convex optimization due to their simplicity; however, they require projections onto the constraint set, which involve solving a quadratic program in the general case.",1. Introduction,[0],[0]
"These projections are infeasible for large scale applications with complicated constraints such as matrix completion, network routing problems, and maximum matchings.",1. Introduction,[0],[0]
"Online projection-free methods have been proposed and are much more efficient , replacing a projection onto the constraint set with a linear optimization over the constraint set at each iteration (Hazan & Kale, 2012; Garber & Hazan, 2013).",1. Introduction,[0],[0]
"However, these projection-free methods require exact gradient computations, which may be prohibitively expensive for even moderately sized data sets and intractable when a ar X iv :1 80 2.
08 18
3v 4
[ st
at .M
L ]
1 4
Ju n
20 18
closed form does not exist.",1. Introduction,[0],[0]
"Thus, there is a huge need for online convex optimization routines that are projection-free and also robust to stochastic gradient estimates.
",1. Introduction,[0],[0]
"While convex programs may be efficiently solved (at least in theory), there is a growing number of non-convex problems arising in machine learning and statistics.",1. Introduction,[0],[0]
"Notable examples include nonnegative principle component analysis, low-rank matrix recovery, sigmoid loss functions for binary classification, and the training of deep neural networks, to name a few.",1. Introduction,[0],[0]
Understanding which types of non-convex functions may be efficiently optimized and developing techniques for doing so is a pressing research question for both theory and practice.,1. Introduction,[0],[0]
"Recently, continuous DR-submodular functions have been proposed as a broad class of non-convex functions which admit efficient approximate maximization routines, even though exact maximization is NP-Hard (Bian et al., 2017).",1. Introduction,[0],[0]
"These functions capture many real-life applications, such as optimal experiment design, non-definite quadratic programming, coverage and diversity functions, and continuous relaxation of discrete submodular functions.",1. Introduction,[0],[0]
"Recent works (Chen et al., 2018) have proposed methods for online continuous DR-submodular optimization; however, these too require either expensive projections or exact gradient computations.
",1. Introduction,[0],[0]
"Our contributions In this paper, we present a suite of projection-free algorithms for online optimization that use stochastic estimates of the gradient and leverage the averaging technique (Mokhtari et al., 2018a;b) to reduce their variance.",1. Introduction,[0],[0]
"This includes
• Meta-Frank-Wolfe, the first projection-free algorithm for adversarial online optimization which requires only stochastic gradient estimates.",1. Introduction,[0],[0]
"The algorithm relies on a careful sampling of gradients in each round and achieves optimal O( √ T ) regret and (1− 1/e)-regret
bounds for convex and submodular optimization, respectively.
",1. Introduction,[0],[0]
"• One-Shot Frank-Wolfe, a simpler projection-free algorithm for stochastic online optimization which requires only a single stochastic gradient estimate in each round.",1. Introduction,[0],[0]
"This simpler algorithm achieves O(T 2/3) regret and (1 − 1/e)-regret bounds for the convex and submodular case, respectively.
•",1. Introduction,[0],[0]
"A novel class of algorithms for online discrete submodular optimization which are based on lifting discrete functions to the continuous domain, applying our methods with an extremely efficient sampling technique, and using rounding schemes to produce a discrete solution.
",1. Introduction,[0],[0]
"Finally, to demonstrate the effectiveness of our algorithms,
we tested their performance on an extensive set of experiments and measured against common baselines.",1. Introduction,[0],[0]
"The Frank-Wolfe algorithm, also known as the conditional gradient descent, was originally proposed for the offline setting in (Frank & Wolfe, 1956).",2. Related Work,[0],[0]
"The framework of online convex optimization was introduced by Zinkevich (2003), in which the online projected gradient descent was proposed and proved to achieve an O( √ T ) regret bound.",2. Related Work,[0],[0]
"However, the projections required for such an algorithm are too expensive for many large-scale online problems.",2. Related Work,[0],[0]
"The online conditional gradient descent was the first projection-free online algorithm, originally proposed in (Hazan & Kale, 2012).",2. Related Work,[0],[0]
"An improved conditional gradient algorithm was later designed for smooth and strongly convex optimization which achieves the optimal O( √ T ) adversarial regret bound (Garber & Hazan, 2013).",2. Related Work,[0],[0]
"However, both of these algorithms can perform arbitrarily poorly if supplied with stochastic gradient estimates.",2. Related Work,[0],[0]
Lafond et al. (2015) proposed an online Frank-Wolfe variant for the any-time stochastic online setting that converges to a stationary point for nonconvex expected functions .,2. Related Work,[0],[0]
"While convergence is an important property of the any-time methods, arbitrary stationary points do not yield approximation guarantees for general non-convex functions.
",2. Related Work,[0],[0]
Johnson & Zhang (2013) introduced the variance reduction technique for accelerating stochastic gradient descent.,2. Related Work,[0],[0]
It was independently discovered by Mahdavi et al. (2013).,2. Related Work,[0],[0]
Allen-Zhu & Hazan (2016) applied this technique to nonconvex optimization.,2. Related Work,[0],[0]
Hazan & Luo (2016) devised a projection-free stochastic convex optimization algorithm based on this technique.,2. Related Work,[0],[0]
Mokhtari et al. (2018a;b) proposed the first sample-efficient variance reduction technique for projection-free algorithms that does not require increasing batch sizes.,2. Related Work,[0],[0]
Their method achieves the tight (1 − 1/e) approximation guarantee for monotone and continuous DRsubmodular functions.,2. Related Work,[0],[0]
"Although these variance reduction techniques have enjoyed success in the offline setting, they have yet to be as extensively applied in the online setting that we consider in this paper.
",2. Related Work,[0],[0]
"In the discrete domain, Streeter & Golovin (2009) studied the online maximization problem of monotone submodular set functions subject to a knapsack constraint and introduced the meta-action technique.",2. Related Work,[0],[0]
"In a celebrated work, Calinescu et al. (2011) proposed an (offline) method for maximizing monotone submodular set functions subject to a matroid constraint by working in the continuous domain via the multilinear extension, then rounding the fractional solution.",2. Related Work,[0],[0]
"By combining the meta-action and lifting techniques, Golovin et al. (2014) presented an algorithm whose (1− 1/e)-regret is bounded by O( √ T ).",2. Related Work,[0],[0]
"The lifting method therein relies
on an expensive sampling procedure that does not scale favorably to large applications.
",2. Related Work,[0],[0]
Bach (2015) demonstrated connections between continuous submodular functions and convex functions in the context of minimization.,2. Related Work,[0],[0]
"Building upon the continuous greedy algorithm of (Calinescu et al., 2011), Bian et al. (2017) proposed an algorithm that achieves a (1− 1/e)-approximation guarantee for maximizing monotone continuous DR-submodular functions subject to down-closed convex constraints.",2. Related Work,[0],[0]
"Projected gradient methods were investigated in (Hassani et al., 2017) and were shown to attain a 1/2-approximation ratio for monotone continuous DR-submodular functions.",2. Related Work,[0],[0]
"Very recently, Chen et al. (2018) borrowed the idea of metaaction (Streeter & Golovin, 2009) and proposed several online algorithms for maximizing monotone continuous DR-submodular functions.",2. Related Work,[0],[0]
"However, each of these methods either requires an expensive projection step at each iteration or cannot handle stochastic gradient estimates.",2. Related Work,[0],[0]
"In this work, we are interested in optimizing two classes of functions, namely convex and continuous DR-submodular.",3. Preliminaries,[0],[0]
"To begin defining continuous submodular functions, we first recall the definition of a submodular set function.",3. Preliminaries,[0],[0]
"A real-valued set function f : 2Ω → R+ is submodular if
f(A) + f(B) ≥ f(A ∪B) + f(A ∩B)
for all A,B ⊂",3. Preliminaries,[0],[0]
Ω.,3. Preliminaries,[0],[0]
"The notion of submodularity has been extended to continuous domains (Wolsey, 1982; Vondrák, 2007; Bach, 2015).",3. Preliminaries,[0],[0]
Consider a function f :,3. Preliminaries,[0],[0]
X → R+ where the domain is of the form X = ∏n i=1,3. Preliminaries,[0],[0]
Xi and each Xi is a compact subset of R+.,3. Preliminaries,[0],[0]
"We say that f is continuous submodular if f is continuous and for all x,y ∈ X , we have f(x) + f(y) ≥ f(x ∨ y) + f(x ∧ y) where x ∨ y and x ∧ y are component-wise maximum and minimum, respectively.",3. Preliminaries,[0],[0]
Note that we have defined both discrete and continuous functions to be nonnegative on their respective domains.,3. Preliminaries,[0],[0]
"For efficient maximization, we also require that these functions satisfy a diminishing returns condition (Bian et al., 2017).",3. Preliminaries,[0],[0]
"We say that f is continuous DR-submodular if f is differentiable and
∇f(x) ≥ ∇f(y)
for all x ≤ y.",3. Preliminaries,[0],[0]
"The main attraction of continuous DRsubmodular functions is that they are concave in positive directions; that is, for all x ≤ y,
f(y) ≤ f(x) +",3. Preliminaries,[0],[0]
"〈∇f(x),y − x〉
(Calinescu et al., 2011; Bian et al., 2017).",3. Preliminaries,[0],[0]
A function f is monotone if f(x) ≤ f(y) for all x ≤ y.,3. Preliminaries,[0],[0]
A function f is L-smooth if ‖∇f(x)−∇f(y)‖≤,3. Preliminaries,[0],[0]
"L‖x− y‖ for all x,y.
We now provide a brief introduction to online optimization, referring the interested reader to the excellent survey of (Hazan et al., 2016).",3. Preliminaries,[0],[0]
"In the online setting, a player seeks to iteratively optimize a sequence of functions f1, . . .",3. Preliminaries,[0],[0]
fT over T rounds.,3. Preliminaries,[0],[0]
"In each round, a player must first choose a point xt from the constraint set K. After playing xt, the value of ft(xt) is revealed to the player, along with access to the gradient∇f .",3. Preliminaries,[0],[0]
"Although the player does not know the function ft while choosing xt, they may use information of previously seen functions to guide their choice.",3. Preliminaries,[0],[0]
"The situation where an arbitrary sequence of functions f1, . . .",3. Preliminaries,[0],[0]
", fT is presented is known as the adversarial online setting.",3. Preliminaries,[0],[0]
"In the adversarial setting, the goal of the player is to minimize adversarial regret, which is defined as
RT , T∑
t =1
ft(xt)− inf x ∈K T∑ t =1 ft(x)
for minimization problems and analogously defined for maximization problems.",3. Preliminaries,[0],[0]
"Intuitively, a player’s regret is low if the accumulated value of their actions over the T rounds is close to that of the single best action in hindsight.",3. Preliminaries,[0],[0]
"Indeed, this is a natural framework for data-intensive applications where the entire data may not fit onto a single disk and thus needs to be processed in T batches.",3. Preliminaries,[0],[0]
"The algorithm designer would like to devise a scheme to process the T batches separately in a way that is competitive with the best single disk solution.
",3. Preliminaries,[0],[0]
A slightly different formulation known as stochastic online setting is when the functions are chosen i.i.d.,3. Preliminaries,[0],[0]
from some unknown distribution ft ∼ D.,3. Preliminaries,[0],[0]
"In this case, the player seeks to minimize stochastic regret, which is defined as
SRT , T∑
t =1
f(xt)− T · inf x ∈K f(x)
where f(x) = Eft∼D[ft(x)] denotes the expected function.",3. Preliminaries,[0],[0]
"This is a natural framework for many statistical and machine learning applications, such as empirical risk minimization, where the true objective is unknown but pairs of data points and labels are sampled.",3. Preliminaries,[0],[0]
"While the stochastic setting appears “easier” than the adversarial setting (in the sense that any strategy for the adversarial settings applies to stochastic settings and obtains a potentially lower regret), the strategies designed for the stochastic setting may be much simpler and more computationally efficient.",3. Preliminaries,[0],[0]
"For both adversarial and stochastic settings, a strategy that achieves a regret that is sublinear in T is considered good andO( √ T ) regret bounds are optimal for convex functions in both settings.",3. Preliminaries,[0],[0]
"Although convex programs can be efficiently solved to high accuracy, general non-convex programs cannot be efficiently exactly optimized, thus necessitating another definition of regret.
",3. Preliminaries,[0],[0]
"The α-regret is defined as
α-RT , α sup x ∈K",3. Preliminaries,[0],[0]
T∑,3. Preliminaries,[0],[0]
"t =1 ft(x)− T∑ t =1 ft(xt)
for adversarial maximization problems, and may be analogously extended to other scenarios.",3. Preliminaries,[0],[0]
"Intuitively, α-regret compares a player’s actions with the best α-approximation to the optimal solution in hindsight.",3. Preliminaries,[0],[0]
"This is appropriate when the objective functions do not admit efficient optimization routines, but do admit constant-factor approximations, as is the case with continuous DR-submodular functions.
",3. Preliminaries,[0],[0]
"Nearly all optimization methods for both offline and online settings use first order information of the objective function; however, exact gradient computations can be costly, especially when the objective function is only readily expressed as a large sum of individual functions or is itself an expectation over an unknown distribution.",3. Preliminaries,[0],[0]
"In this case, stochastic estimates are usually much more computationally efficient to obtain via sampling or simulation.",3. Preliminaries,[0],[0]
"In this work, we assume that once a function ft is revealed, the player gains oracle access to unbiased stochastic estimates of the gradient, rather than the exact gradient.",3. Preliminaries,[0],[0]
"More precisely, the player may query the oracle to obtain a random linear function ∇̃f(x) such that E[∇f(x)−∇̃f(x)] = 0 for all x. This computational model captures commonly used mini-batch methods for estimating gradients, among other examples.",3. Preliminaries,[0],[0]
"In this work, we make a few main assumptions that allow our algorithms to be analyzed.
",3. Preliminaries,[0],[0]
Assumption 1.,3. Preliminaries,[0],[0]
"The constraint setK is convex and compact, with diameter D = supx,y∈K‖x − y‖ and radius R = supx∈K‖x‖.
Assumption 2.",3. Preliminaries,[0],[0]
"In the adversarial setting, each function ft is L-smooth and in the stochastic setting, the expected function f is L-smooth.
",3. Preliminaries,[0],[0]
Assumption 3.,3. Preliminaries,[0],[0]
"In the adversarial setting, the gradient oracle is unbiased E[∇ft(x)−∇̃ft(x)]",3. Preliminaries,[0],[0]
= 0 and has a bounded variance E[‖∇ft(x)−∇̃ft(x)‖2] ≤ σ2 for all points x and functions ft.,3. Preliminaries,[0],[0]
"In the stochastic setting, the gradient oracle is unbiased E[∇f(x)",3. Preliminaries,[0],[0]
"− ∇̃ft(x)] = 0 and has a bounded variance E[‖∇f(x)− ∇̃ft(x)‖2] ≤ σ2 for all points x and functions ft.
",3. Preliminaries,[0],[0]
"We remark that in the stochastic setting and under mild regularity conditions, unbiasedness of the gradients E[∇ft(x)− ∇̃ft(x)] = 0 implies unbiasedness E[∇f(x)−∇̃ft(x)]",3. Preliminaries,[0],[0]
= 0 in Assumption 3 because f(x) = Eft∼D[ft(x)],3. Preliminaries,[0],[0]
"Moreover, upper bounds on the variance terms E[‖∇f(x)",3. Preliminaries,[0],[0]
− ∇ft(x)‖2] ≤ σ2a and E[‖∇ft(x)− ∇̃ft(x)‖2] ≤ σ2b yield a variance bound of E[‖∇f(x),3. Preliminaries,[0],[0]
"− ∇̃ft(x)‖2] ≤ σ2a + σ2b , by the triangle inequality.",3. Preliminaries,[0],[0]
We now present two algorithms for online optimization of convex and continuous DR-submodular functions in the adversarial and stochastic settings.,4. Main Results,[0],[0]
"Unlike previous work, these methods are projection-free and require only stochastic estimates of the gradients, rather than exact gradient computations.",4. Main Results,[0],[0]
"In both algorithms, the main computational primitive is linear optimization over a compact convex set.",4. Main Results,[0],[0]
"In addition, we remark that both algorithms can be converted into an anytime algorithm that does not require the knowledge of the horizon T via the doubling trick; see Section 2.3.1 of (Shalev-Shwartz et al., 2012).",4. Main Results,[0],[0]
"Algorithm 1 combines the recent variance reduction technique of (Mokhtari et al., 2018a) along with the use of online linear optimization oracles to minimize the regret in each round.",4.1. Adversarial Online Setting,[0],[0]
"An online linear optimization oracle is an instance of an online linear optimization (minimization/maximization in the convex/DR-submodular setting, respectively) algorithm that optimizes linear objectives in a sequential manner.",4.1. Adversarial Online Setting,[0],[0]
"Both the variance reduction in the stochastic gradient estimates and the online linear oracles are crucial in the algorithm, as just one technique is not enough to get sublinear regret bounds in the adversarial setting.",4.1. Adversarial Online Setting,[0],[0]
"At a high level, our algorithm produces iterates xt by running K steps of a Frank-Wolfe procedure, using an average of previous gradient estimates and linear online optimization oracles in place of exact optimization of the true gradient.",4.1. Adversarial Online Setting,[0],[0]
"After a point xt is played in round t, our algorithm queries the gradient oracle ∇̃ft at K points.",4.1. Adversarial Online Setting,[0],[0]
"Then, the gradient estimates are averaged with those from previous rounds and fed as objective functions into K linear online optimization oracles.",4.1. Adversarial Online Setting,[0],[0]
The K points chosen by the oracles are used as iterates in a full K-step Frank-Wolfe subroutine to obtain the next point xt+1.,4.1. Adversarial Online Setting,[0],[0]
"A formal description is provided in Algorithm 1.
",4.1. Adversarial Online Setting,[0],[0]
There are only a few differences in Algorithm 1 for convex and submodular optimization.,4.1. Adversarial Online Setting,[0],[0]
"First, the online oracles should be minimizing in the case of convex optimization and maximizing in the case of submodular optimization.",4.1. Adversarial Online Setting,[0],[0]
"Second, the initial point x1 may be any point in K for convex problems but should be set to 0 for submodular problems (even if K is not down-closed).",4.1. Adversarial Online Setting,[0],[0]
"Finally, the update rule is
x (k+1) t ← (1− ηk)x (k) t + ηkv (k) t
for convex problems and
x (k+1) t ← x (k) t + ηkv (k) t
for submodular problems.",4.1. Adversarial Online Setting,[0],[0]
"We now provide a formal regret bound.
",4.1. Adversarial Online Setting,[0],[0]
"Algorithm 1 Meta-Frank-Wolfe Input: convex set K, time horizon T , linear optimization
oracles E(1) . . .",4.1. Adversarial Online Setting,[0],[0]
"E(K), step sizes ρk ∈ (0, 1) and ηk ∈ (0, 1), and initial point x1 Output: {xt : 1 ≤ t ≤ T} 1: Initialize online linear optimization oracles E(1) . . .",4.1. Adversarial Online Setting,[0],[0]
"E(K)
2: Initialize d(0)t = 0",4.1. Adversarial Online Setting,[0],[0]
"and x (1) t = x1 3: for t← 1, 2, 3, . . .",4.1. Adversarial Online Setting,[0],[0]
", T do 4: v(k)t ← output of oracle E(k) in round t− 1 5: x(k+1)t ← update(x (k) t ,v (k) t , ηk) for k = 1 . .",4.1. Adversarial Online Setting,[0],[0]
.K,4.1. Adversarial Online Setting,[0],[0]
"6: Play xt = x (K+1) t , then obtain value ft(xt) and unbiased oracle access to∇ft 7: d(k)t ← (1 − ρk)d (k−1) t + ρk∇̃ft(x (k) t ) for k = 1 . .",4.1. Adversarial Online Setting,[0],[0]
.K,4.1. Adversarial Online Setting,[0],[0]
8,4.1. Adversarial Online Setting,[0],[0]
:,4.1. Adversarial Online Setting,[0],[0]
"Feedback 〈v(k)t ,d (k) t 〉 to E(k) for k = 1 . .",4.1. Adversarial Online Setting,[0],[0]
.K,4.1. Adversarial Online Setting,[0],[0]
"9: end for
Theorem 1 (Proof in Appendices B and C).",4.1. Adversarial Online Setting,[0],[0]
"Suppose Assumptions 1 - 3 hold, the online linear optimization oracles have regret at most RET , and the averaging parameters are chosen as ρk = 2(k+3)2/3 .",4.1. Adversarial Online Setting,[0],[0]
"Then for convex functions f1, . . .",4.1. Adversarial Online Setting,[0],[0]
", fT and step sizes ηk = 1k+3 , the adversarial regret of Algorithm 1 is at most
4TDQ1/2
K1/3",4.1. Adversarial Online Setting,[0],[0]
"+
4T
K
( M + LD2
3 log(K + 1)
) +",4.1. Adversarial Online Setting,[0],[0]
"4
3 RET
in expectation, where M = max1≤t≤T [ft(x1)− ft(x∗)] and Q , max{42/3 max1≤t≤T ‖∇ft(x1)‖2, 4σ2 + 3(LD)2/2}.",4.1. Adversarial Online Setting,[0],[0]
"For monotone continuous DR-submodular functions f1, . . .",4.1. Adversarial Online Setting,[0],[0]
", fT and step sizes ηk = 1K , the adversarial (1− 1/e)-regret of Algorithm 1 is at most
3TDQ1/2 2K1/3 + LD2T 2K +RET
in expectation, where Q , max{max1≤t≤T ‖∇ft(x1)‖242/3, 4σ2 + 6L2R2}.
",4.1. Adversarial Online Setting,[0],[0]
"From Theorem 1, we observe that by setting K = T 3/2 and choosing a projection-free online linear optimization oracle with RET = O( √ T ), such as Follow the Perturbed Leader (Cohen & Hazan, 2015), both regrets are bounded above by O( √ T ).",4.1. Adversarial Online Setting,[0],[0]
We remark that the expectation in Theorem 1 is with respect to the stochastic gradient estimates.,4.1. Adversarial Online Setting,[0],[0]
"In the stochastic online setting, where functions are sampled i.i.d.",4.2. Stochastic Online Setting,[0],[0]
"ft ∼ D, we can develop much simpler algorithms that still achieve sublinear regret.",4.2. Stochastic Online Setting,[0],[0]
"Algorithm 2 works without
instantiating any online linear optimization oracles and requires only a single stochastic estimate of the gradient at each round.",4.2. Stochastic Online Setting,[0],[0]
"Indeed, because the functions are not arbitrarily chosen, variance reduction along with one Frank-Wolfe step suffices to achieve a sublinear regret bound.
",4.2. Stochastic Online Setting,[0],[0]
"Algorithm 2 One-Shot Frank-Wolfe Input: convex set K, time horizon T , step sizes ρt ∈ (0, 1)
and ηt ∈ (0, 1), and initial point x1 Output: {xt : 1 ≤ t ≤ T}
1: d0 ← 0 2: for t← 1, 2, 3, . . .",4.2. Stochastic Online Setting,[0],[0]
", T do 3: Play xt, then obtain value ft(xt) and unbiased oracle access to ∇ft 4: dt ← (1− ρt)dt−1 + ρt∇̃ft(xt) 5: vt ← arg maxv∈K〈dt,v〉 6: xt+1",4.2. Stochastic Online Setting,[0],[0]
"← update(xt,vt, ηt) 7: end for
The differences in Algorithm 2 for convex and submodular optimization are similar to those in Algorithm 1.",4.2. Stochastic Online Setting,[0],[0]
"Namely, the update rules are the same and the initial point x1 may be arbitrarily chosen from K for convex optimization, and set to 0 for submodular optimization.
",4.2. Stochastic Online Setting,[0],[0]
Theorem 2 (Proof in Appendices D and E).,4.2. Stochastic Online Setting,[0],[0]
Suppose Assumptions 1 - 3 hold and the averaging parameters are chosen as ρt = 2(t+3)2/3 .,4.2. Stochastic Online Setting,[0],[0]
"Then for a convex expected function f and step sizes ηt = 1t+3 , the stochastic regret of Algorithm 1 is at most
4M log(T + 1) + 6Q1/2DT 2/3 + 4
3 LD2 log2(T + 3)
in expectation, where M = f(x1) − f(x∗) and Q , max{42/3‖∇F (x1)‖2, 4σ2 + 3(LD)2/2}.",4.2. Stochastic Online Setting,[0],[0]
"For expected functions f which are monotone continuous DR-submodular and step sizes ηk = 1K , the stochastic (1 − 1/e)-regret of Algorithm 2 is at most
(1− 1/e)M + 3DQ 1/2
10 (3T 2/3 + 2T−1)",4.2. Stochastic Online Setting,[0],[0]
"+
LD2
2 .
",4.2. Stochastic Online Setting,[0],[0]
"in expectation, where M = f(x∗)",4.2. Stochastic Online Setting,[0],[0]
"− f(0) and Q , max{‖∇f(0)‖242/3, 4σ2 + 6L2R2}",4.2. Stochastic Online Setting,[0],[0]
One exciting application of our online continuous DRsubmodular optimization algorithms is a new approach for online discrete submodular optimization.,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"While previous methods could only handle knapsack constraints (Streeter & Golovin, 2009) or required expensive sampling procedures (Golovin et al., 2014), our continuous methods can
be applied to the discrete setting to handle general matroid constraints and computationally cheap sampling procedures.
",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"Suppose f1, . . .",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"fT are nonnegative monotone submodular set functions on a ground set Ω with matroid constraint I and f̄1, . . .",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
f̄T are corresponding multi-linear extensions with matroid polytope K ⊂,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"[0, 1]n.",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"A discrete procedure that uses our continuous algorithm is as follows: at each round t, the online continuous algorithm produces a fractional solution xt ∈ K, which is then rounded to a set",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
Xt ∈,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
I and played as the discrete solution.,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
The value ft(Xt) is revealed and the player is granted access to the discrete function ft.,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"Then, the player supplies the continuous algorithm with a stochastic gradient estimate ∇̃f̂t obtained by a single function evaluation, as
∂ft(x)
∂xi = E[f(R ∪ {i})− f(R)], ∀i ∈",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"[n], (1)
where R is random subset of [n]",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
\ {i} such that for every j ∈,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"[n] \ {i}, the event j ∈ R happens with an independent probability of xj .",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"Because a lossless rounding scheme is used, the discrete player enjoys a regret that is no worse than that of the continuous solution.",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"Provably lossless rounding schemes include the pipage rounding (Ageev & Sviridenko, 2004; Calinescu et al., 2011) and contention resolution (Vondrák et al., 2011).
",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
Most discrete submodular maximization algorithms that go through the multi-linear extension require a gradient estimate with high accuracy.,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"In order to do this, they appeal to a concentration bound, which requires O(n2) evaluations of the discrete function for independently chosen samples.",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"In stark contrast, our algorithms can handle stochastic gradient estimates and thus require only a single function evaluation, finally making continuous methods a reality for large-scale online discrete optimization problems.",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"The framework of the one-sampling lifting method is illustrated in Fig. 1.
",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"As an example, we present in Algorithm 3 how to use Meta-Frank-Wolfe as an online maximization algorithm of submodular set functions.",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"According to Theorem 1, the (1− 1/e)-regret of Algorithm 3 is bounded by 3TDQ 1/2
K1/3",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"+
LD2T 2K +R E T , whereRET is the regret of E(k) up to horizon T .",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"If one sets E(k) to an online linear maximization algo-
rithm with regret bound O( √ T ) and sets K = T 3/2, the (1− 1/e)-regret is at most O( √ T ).
",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"Algorithm 3 Meta-Frank-Wolfe for online discrete submodular maximization Input: matroid constraint I, time horizon T , linear opti-
mization oracles E(1) . . .",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"E(K), step sizes ρk ∈ (0, 1) and ηk ∈ (0, 1), and initial point x1 Output: {Xt : 1 ≤ t ≤ T} 1: Initialize online linear optimization oracles E(1)...E(K),
setting the constraint set to the matroid polytope of I 2: Initialize d(0)t = 0",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"and x (1) t = x1 3: for t← 1, 2, 3, . . .",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
", T do 4: v(k)t ← output of oracle E(k) in round t− 1 5: x(k+1)t ← update(x (k) t ,v (k) t , ηk) for k = 1 . .",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
.K,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"6: xt ← x(K+1)t 7: play Xt ← round(xt), obtain value ft(Xt) and observe the function ft 8: Sample ∇̃f̄t(x(k)t ) for k = 0, . . .",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
",K − 1 9: d(k)t ← (1 − ρk)d (k−1) t + ρk∇̃ft(x (k) t ) for k =
1 . .",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
.K,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
10:,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"Feedback 〈v(k)t ,d (k) t 〉 to E(k) for k = 1 . .",4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
.K,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
11: end for,4.3. Lifting Methods for Discrete Online Optimization,[0],[0]
"In this section, we test our online algorithms for monotone continuous DR-submodular and convex optimization on both real-world and synthetic data sets.",5. Experiment,[0],[0]
"We find that our algorithms outperform most baselines, including projected gradient descent, when supplied with stochastic gradient estimates.",5. Experiment,[0],[0]
All code was written in the Julia programming language and tested on a Macintosh desktop with an Intel Processor i7 with 16 GB of RAM.,5. Experiment,[0],[0]
No parts of the code were optimized past basic Julia usage.,5. Experiment,[0],[0]
"A list of all algorithms to be compared in this section is presented below.
",5. Experiment,[0],[0]
• Meta-Frank-Wolfe is Algorithm 1.,5. Experiment,[0],[0]
"We compare the variance-reduced meta-Frank-Wolfe algorithm and the analogue without variance reduction, denoted MetaFW w/ VR and Meta-FW w/o VR, respectively.
",5. Experiment,[0],[0]
• One-shot Frank-Wolfe is Algorithm 2.,5. Experiment,[0],[0]
"We compare the One-shot online Frank-Wolfe algorithm with and without variance reduction, denoted OS-FW w/ VR OS-FW w/o NVR, respectively.
",5. Experiment,[0],[0]
"• Regularized online Frank-Wolfe is referred to as the online conditional gradient algorithm in (Hazan et al., 2016).",5. Experiment,[0],[0]
It has a regularizer term when computing the gradient.,5. Experiment,[0],[0]
"Thus we term it the regularized online FrankWolfe algorithm and denote it as Regularized-OFW.
",5. Experiment,[0],[0]
• Online projected gradient ascent (OGA) follows the direction of the projected gradient.,5. Experiment,[0],[0]
"Its 1/2-regret is at most O( √ T ) for online monotone continuous DR-
submodular maximization if the step size is set to Θ(1/ √ t) on the t-th iteration (Chen et al., 2018).",5. Experiment,[0],[0]
Note that OGA is not a projection-free algorithm.,5. Experiment,[0],[0]
"In the setting of convex minimization, we use online projected gradient descent instead (denoted by OGD).
",5. Experiment,[0],[0]
"• When we perform experiments on discrete submodular maximization problems using our lifting method, we also compare the above algorithms with the Online Greedy algorithm (Streeter & Golovin, 2009).",5. Experiment,[0],[0]
"In order to test the performance of algorithms for online maximization of monotone continuous DR-submodular functions with stochastic gradient estimates, we conducted three sets of experiments on real-world datasets.",5.1. Online DR-Submodular Maximization,[0],[0]
"We approximate the (1− 1/e)-regret by running an offline Frank Wolfe maximization to produce a solution that is a (1−1/e) approximation to the optimum.
",5.1. Online DR-Submodular Maximization,[0],[0]
"Joke Recommendations (Continuous) The first set of experiments is to optimize a sequence of continuous facility location objectives on the Jester dataset (Goldberg et al., 2001).",5.1. Online DR-Submodular Maximization,[0],[0]
"It contains ratings of 100 jokes from 73,421 users and the rating range is [−10, 10].",5.1. Online DR-Submodular Maximization,[0],[0]
"We re-scale the rating range into [0, 20] so that all ratings are nonnegative.",5.1. Online DR-Submodular Maximization,[0],[0]
"Let Ruj be user u’s rating of joke j. All users are splitted into disjoint batches B1, B2, . . .",5.1. Online DR-Submodular Maximization,[0],[0]
", BT , each containing B users.",5.1. Online DR-Submodular Maximization,[0],[0]
The facility location objective is defined as ft(X),5.1. Online DR-Submodular Maximization,[0],[0]
=,5.1. Online DR-Submodular Maximization,[0],[0]
∑ u∈Bt maxj∈X,5.1. Online DR-Submodular Maximization,[0],[0]
"Ruj , ∀X ⊆",5.1. Online DR-Submodular Maximization,[0],[0]
"[J ], where J = 100 is the total number of jokes and [J ] = {1, 2, 3, . . .",5.1. Online DR-Submodular Maximization,[0],[0]
", J}.",5.1. Online DR-Submodular Maximization,[0],[0]
Its multilinear extension is given by f̄t(x) = ∑ u∈Bt ∑J l=1Rujluxjlu ∏l−1,5.1. Online DR-Submodular Maximization,[0],[0]
"m=1(1 − xjmu ), ∀x ∈",5.1. Online DR-Submodular Maximization,[0],[0]
"[0, 1]J , where j1u, j 2 u, . . .",5.1. Online DR-Submodular Maximization,[0],[0]
", j J u is a permutation of 1, 2, . . .",5.1. Online DR-Submodular Maximization,[0],[0]
", J such that Ruj1u ≥ Ruj2u ≥ . . .",5.1. Online DR-Submodular Maximization,[0],[0]
≥,5.1. Online DR-Submodular Maximization,[0],[0]
"RujJu (Iyer et al., 2014).",5.1. Online DR-Submodular Maximization,[0],[0]
"In this experiment, the sequence of objective functions to be optimized is {f̄1, f̄2, . . .",5.1. Online DR-Submodular Maximization,[0],[0]
", f̄T }.",5.1. Online DR-Submodular Maximization,[0],[0]
The stochastic gradient is obtained by the sampling method given in Eq.,5.1. Online DR-Submodular Maximization,[0],[0]
(1) with only one sample for each coordinate of the gradient.,5.1. Online DR-Submodular Maximization,[0],[0]
We set the constraint set to {x ∈,5.1. Online DR-Submodular Maximization,[0],[0]
"[0, 1]J : 1>x ≤ 1} and choose B = 5.",5.1. Online DR-Submodular Maximization,[0],[0]
We present the results in Fig. 2(a).,5.1. Online DR-Submodular Maximization,[0],[0]
Meta-FW w/ VR attains the smallest regret.,5.1. Online DR-Submodular Maximization,[0],[0]
The counterpart without variance reduction Meta-FW w/o VR is inferior to Meta-FW w/ VR in terms of the regret.,5.1. Online DR-Submodular Maximization,[0],[0]
"OS-FW w/ VR outperforms OSFW w/o NVR, which suggests that the variance reduction technique improves the performance of the algorithms.
",5.1. Online DR-Submodular Maximization,[0],[0]
Joke Recommendations (Discrete),5.1. Online DR-Submodular Maximization,[0],[0]
"In the second set experiments, we consider online maximization of discrete submodular functions.",5.1. Online DR-Submodular Maximization,[0],[0]
"The problem set up is the same
as before, but instead of evaluating regret of the multilinear extensions, we round solutions using pipage rounding and evaluate the regret on the discrete submodular functions.",5.1. Online DR-Submodular Maximization,[0],[0]
We set the batch size B to 40 and we recommend 10 jokes for users.,5.1. Online DR-Submodular Maximization,[0],[0]
The results are illustrated in Fig. 2(b).,5.1. Online DR-Submodular Maximization,[0],[0]
We observe that Meta-FW w/ VR outperforms all other algorithms again.,5.1. Online DR-Submodular Maximization,[0],[0]
The projected algorithm OGA is second to Meta-FW w/ VR.,5.1. Online DR-Submodular Maximization,[0],[0]
Online Greedy appears only better than Regularized-OFW.,5.1. Online DR-Submodular Maximization,[0],[0]
"The experiment result show that the continuous algorithms designed under the framework of the lifting method perform better than the discrete algorithms.
",5.1. Online DR-Submodular Maximization,[0],[0]
"Topic Summarization We consider the problem of selecting news documents in order to maximize the probabilistic coverage of news topics (El-Arini et al., 2009; Yue & Guestrin, 2011).",5.1. Online DR-Submodular Maximization,[0],[0]
"We applied the latent Dirichlet allocation to the corpus of Reuters-21578, Distribution 1.0, set the number of topics to 10, and extracted the topic distribution of each news document.",5.1. Online DR-Submodular Maximization,[0],[0]
"We sample T batches of news documents from the corpus and denote them by B1, B2, . . .",5.1. Online DR-Submodular Maximization,[0],[0]
", BT , where each batch contains 50 randomly sampled documents.",5.1. Online DR-Submodular Maximization,[0],[0]
"For each batch Bi, we define the probabilistic coverage function as follows fi(X) = 1 10 ∑10 j=1[1",5.1. Online DR-Submodular Maximization,[0],[0]
− ∏ a∈X(1,5.1. Online DR-Submodular Maximization,[0],[0]
− pa(j)),5.1. Online DR-Submodular Maximization,[0],[0]
"], ∀X ⊆ Bi, where pa(·) is the topic distribution of news document",5.1. Online DR-Submodular Maximization,[0],[0]
a.,5.1. Online DR-Submodular Maximization,[0],[0]
"Its multilinear extension is f̄i(x) = 110 ∑10 j=1[1− ∏ a∈X(1− pa(j)xa)], ∀x ∈",5.1. Online DR-Submodular Maximization,[0],[0]
"[0, 1]50, see (Iyer et al., 2014).",5.1. Online DR-Submodular Maximization,[0],[0]
"The sequence of objective functions that the algorithms are expected to maximize is f̄1, f̄2, . . .",5.1. Online DR-Submodular Maximization,[0],[0]
", f̄T .",5.1. Online DR-Submodular Maximization,[0],[0]
"As in the experiments on joke recommendations, the stochastic gradient is obtained by the sampling method given in Eq.",5.1. Online DR-Submodular Maximization,[0],[0]
(1) with only one sample for each coordinate of the gradient.,5.1. Online DR-Submodular Maximization,[0],[0]
The constraint set is {x ∈,5.1. Online DR-Submodular Maximization,[0],[0]
"[0, 1]50 : 1>x ≤ 45}.",5.1. Online DR-Submodular Maximization,[0],[0]
We show the (1−1/e)-regret of the algorithms in Fig. 2(c).,5.1. Online DR-Submodular Maximization,[0],[0]
"Again, MetaFW w/ VR exhibits the lowest regret than any other algorithm.",5.1. Online DR-Submodular Maximization,[0],[0]
Its non-variance-reduced counterpart Meta-FW w/o VR is second to it.,5.1. Online DR-Submodular Maximization,[0],[0]
"OS-FW w/ VR outperforms OS-FW w/o NVR, which confirms the improvement brought by the variance reduction technique.",5.1. Online DR-Submodular Maximization,[0],[0]
The next two sets of experiments test the performance of the algorithms for online minimization of convex functions with stochastic gradient estimates.,5.2. Online Convex Minimization,[0],[0]
"For these experiments, the regret is computed by obtaining the offline solutions with a Frank-Wolfe solver.
",5.2. Online Convex Minimization,[0],[0]
Stochastic Cost Network Flow The fourth set of experiments is a minimum stochastic cost flow in a directed network.,5.2. Online Convex Minimization,[0],[0]
"A directed graph G = (V,E) with source s ∈ V , sink v ∈ V , and edge capacities",5.2. Online Convex Minimization,[0],[0]
c : E → R+ is known to the player.,5.2. Online Convex Minimization,[0],[0]
"A flow is a function x : R|E|+ → R+ that satisfies the capacities on each edge 0 ≤ x(e) ≤ c(e) and obeys the
0
1000
2000
3000
4000
0 25 50 75 100 Iteration index
1 −
1 e −r
eg re
t
Meta−FW w/ VR Meta−FW w/o VR OGA OS−FW w/ VR OS−FW w/o VR Regularized−OFW
Meta-FW w/ VR
Meta-FW w/o VR
OGA
Regularized-OFW
OS-FW w/ VR OS-FW w/o VR
(a) Continuous facility location on Jester dataset
0
500
1000
1500
2000
0 100 200 300 400 Iteration index
1 −
1 e −r
eg re
t
Meta−FW w/ VR Meta−FW w/o VR OGA Regularized−OFW Online greedy
Meta-FW w/ VR
Meta-FW w/o VR OGA
Online greedy
Regularized-OFW
(b) Discrete facility location on Jester dataset
0
100
200
300
400
0 250 500 750 1000 Iteration index
1 −
1 e −r
eg re
t
Meta−FW w/ VR Meta−FW w/o VR OGA OS−FW w/ VR OS−FW w/o VR Regularized−OFW
Meta-FW w/ VR Meta-FW w/o VR
OGA
Regularized-OFW
OS-FW w/ VR
OS-FW w/o VR
(c) News recommendation in Reuters corpus
conservation laws for all vertices z,
∑ {z,r}∈E x(r) =  a z = s −a z = v 0 otherwise
for some fixed a ≥ 0.",5.2. Online Convex Minimization,[0],[0]
"In each round t, a convex cost function on the flow ft : R|E| → R+ is drawn from a distribution, unknown to the player.",5.2. Online Convex Minimization,[0],[0]
The goal is to minimize the stochastic regret of the flows chosen.,5.2. Online Convex Minimization,[0],[0]
Linear optimizations for this problem may be implemented as combinatorial network flow algorithms.,5.2. Online Convex Minimization,[0],[0]
"We used the directed Zachary Karate network with 34 nodes and 78 arcs (Zachary, 1977).",5.2. Online Convex Minimization,[0],[0]
"We set all edge capacities to 1 and cost functions are of the form f(x) = ∑ e∈E wex(e)
2 where we ∼ Unif[100, 120].",5.2. Online Convex Minimization,[0],[0]
The results are presented in Fig. 2(d).,5.2. Online Convex Minimization,[0],[0]
Meta-FW w/ VR attains the lowest regret among all baselines.,5.2. Online Convex Minimization,[0],[0]
"Again, the regret of Meta-FW w/o VR is larger than the variance-reduced MetaFW w/ VR.",5.2. Online Convex Minimization,[0],[0]
"Similarly, OS-FW w/ VR also outperforms OS-FW w/o NVR.
Matrix Completion In the online convex matrix completion problem, one would like to construct a low rank matrix X ∈ Rm×n that well-approximates a given matrix
M ∈",5.2. Online Convex Minimization,[0],[0]
Rm×n on observed entries OB ⊆,5.2. Online Convex Minimization,[0],[0]
[m]× [n].,5.2. Online Convex Minimization,[0],[0]
"The convex relaxation is minTrace(X)≤k ∑ (i,j)∈OB(Xi,j−Mi,j)2.",5.2. Online Convex Minimization,[0],[0]
"In the online setting, observed entries of the matrix arrive in T batches, OB1, OB2, . . .",5.2. Online Convex Minimization,[0],[0]
"OBT , each of size B.",5.2. Online Convex Minimization,[0],[0]
"In each round, we construct a low-rank matrix to minimize the total regret over the T rounds.",5.2. Online Convex Minimization,[0],[0]
"Although projection involves a full singular value decomposition, linear optimization here is simply a calculation of the largest singular vectors of (X − M)OB , see Chapter 7 of (Hazan et al., 2016).",5.2. Online Convex Minimization,[0],[0]
"In our experiment, M is a rank 10 matrix with m = n = 50, and B = 100.",5.2. Online Convex Minimization,[0],[0]
We illustrate the results in Fig. 2(e) and the computational time is shown in Fig. 2(f).,5.2. Online Convex Minimization,[0],[0]
Meta-FW w/ VR is only second to OGD.,5.2. Online Convex Minimization,[0],[0]
"However, OGD is the slowest algorithm due to the computationally expensive projection operations and its computational time is five times that of Meta-FW w/ VR.",5.2. Online Convex Minimization,[0],[0]
The non-variance-reduced Meta-FW w/o VR is inferior to Meta-FW w/ VR in terms of regret.,5.2. Online Convex Minimization,[0],[0]
AK was supported by AFOSR YIP (FA9550-18-1-0160).,Acknowledgments,[0],[0]
CH was supported in part by NSF GRFP (DGE1122492) and by ONR Award N00014-16-1-2374.,Acknowledgments,[0],[0]
"We begin by examining the sequence of iterates x(1)t ,x (2) t , . . .",B. Proof of Theorem 1: Convex Case,[0],[0]
",x (K+1) t produced in Algorithm 1 for a fixed t. By definition of the update and because ft is L-smooth, we have
ft(x",B. Proof of Theorem 1: Convex Case,[0],[0]
(k+1) t ),B. Proof of Theorem 1: Convex Case,[0],[0]
− ft(x∗) = ft(x,B. Proof of Theorem 1: Convex Case,[0],[0]
(k) t + ηk(v (k) t,B. Proof of Theorem 1: Convex Case,[0],[0]
− x (k) t )),B. Proof of Theorem 1: Convex Case,[0],[0]
"− ft(x∗)
≤ ft(x(k)t )− ft(x∗) + ηk〈∇ft(x",B. Proof of Theorem 1: Convex Case,[0],[0]
"(k) t ),v (k) t",B. Proof of Theorem 1: Convex Case,[0],[0]
− x (k) t 〉,B. Proof of Theorem 1: Convex Case,[0],[0]
"+ η2k
L 2 ‖v(k)t",B. Proof of Theorem 1: Convex Case,[0],[0]
"− x (k) t ‖2
≤ ft(x(k)t )− ft(x∗) + ηk〈∇ft(x",B. Proof of Theorem 1: Convex Case,[0],[0]
"(k) t ),v (k) t",B. Proof of Theorem 1: Convex Case,[0],[0]
− x (k) t 〉,B. Proof of Theorem 1: Convex Case,[0],[0]
"+ η2k
LD2
2 .
",B. Proof of Theorem 1: Convex Case,[0],[0]
"Now, observe that the dual pairing may be decomposed as
〈∇ft(x(k)t ),v (k) t − x (k) t 〉 = 〈∇ft(x (k) t )",B. Proof of Theorem 1: Convex Case,[0],[0]
"− d (k) t ,v (k) t",B. Proof of Theorem 1: Convex Case,[0],[0]
"− x∗〉+ 〈∇ft(x (k) t ),x ∗",B. Proof of Theorem 1: Convex Case,[0],[0]
"− x(k)t 〉+ 〈d (k) t ,v (k) t − x∗〉.
",B. Proof of Theorem 1: Convex Case,[0],[0]
"We can bound the first term using Young’s Inequality to get
〈∇ft(x(k)t )",B. Proof of Theorem 1: Convex Case,[0],[0]
"− d (k) t ,v (k) t",B. Proof of Theorem 1: Convex Case,[0],[0]
"− x∗〉 ≤
1
2βk ‖ft(x(k)t )",B. Proof of Theorem 1: Convex Case,[0],[0]
− d (k) t ‖2 + 2βk‖v (k) t,B. Proof of Theorem 1: Convex Case,[0],[0]
"− x∗‖2
≤ 1 2βk ‖ft(x(k)t )",B. Proof of Theorem 1: Convex Case,[0],[0]
"− d (k) t ‖2 + 2βkD2
for any βk > 0, which will be chosen later in the proof.",B. Proof of Theorem 1: Convex Case,[0],[0]
"We may also bound the second term in the decomposition of the dual pairing using convexity of ft, i.e. 〈∇ft(x(k)t ),x∗",B. Proof of Theorem 1: Convex Case,[0],[0]
− x (k) t 〉 ≤ ft(x∗)− ft(x (k) t ).,B. Proof of Theorem 1: Convex Case,[0],[0]
"Using these upper bounds, we get that
〈∇ft(x(k)t ),v (k) t − x (k) t 〉 ≤
1
2βk ‖ft(x(k)t )",B. Proof of Theorem 1: Convex Case,[0],[0]
− d (k) t ‖2 + 2βkD2 + ft(x∗)− ft(x (k) t ) +,B. Proof of Theorem 1: Convex Case,[0],[0]
"〈d (k) t ,v (k) t − x∗〉.
",B. Proof of Theorem 1: Convex Case,[0],[0]
"Using this upper bound on the dual pairing in the first inequality, we get that
ft(x (k+1) t )",B. Proof of Theorem 1: Convex Case,[0],[0]
"− ft(x∗)≤ (1−ηk)(ft(x (k) t )−ft(x∗))+ηk
[ 1
2βk ‖ft(x(k)t )−d (k) t ‖2 +2βkD2 +〈d (k) t ,v (k) t −x∗〉+ηk
LD2
2
] .
",B. Proof of Theorem 1: Convex Case,[0],[0]
Now we will apply the variance reduction technique.,B. Proof of Theorem 1: Convex Case,[0],[0]
"Note that
‖∇ft(x(k+1)t",B. Proof of Theorem 1: Convex Case,[0],[0]
−∇ft(x (k) t )‖≤ L‖x,B. Proof of Theorem 1: Convex Case,[0],[0]
(k+1) t − x (k) t,B. Proof of Theorem 1: Convex Case,[0],[0]
"‖≤ Lηk‖x (k) t − v (k) t ‖≤
LD
k + 3
Where we have used that ft is L-smooth, the convex update, and that the step size is ηk = 1k+3 .",B. Proof of Theorem 1: Convex Case,[0],[0]
"Now, using Theorem 3 with G = LD and s = 3, we have that
E[‖ft(x(k)t )",B. Proof of Theorem 1: Convex Case,[0],[0]
− d (k) t ‖2] ≤,B. Proof of Theorem 1: Convex Case,[0],[0]
"Qt (k + 4)2/3 ≤ Q (k + 4)2/3 .
",B. Proof of Theorem 1: Convex Case,[0],[0]
Where,B. Proof of Theorem 1: Convex Case,[0],[0]
"Qt , max{‖∇ft(x1)‖242/3, 4σ2 + 3(LD)2/2} and Q , max{42/3 max1≤t≤T",B. Proof of Theorem 1: Convex Case,[0],[0]
‖∇ft(x1)‖2,B. Proof of Theorem 1: Convex Case,[0],[0]
", 4σ2 + 3(LD)2/2} Thus, taking expectation of both sides of the optimality gap and setting βk = Q 1/2
2D(k+4)1/3 yields
E[ft(x(k+1)t )",B. Proof of Theorem 1: Convex Case,[0],[0]
],B. Proof of Theorem 1: Convex Case,[0],[0]
− ft(x∗) ≤,B. Proof of Theorem 1: Convex Case,[0],[0]
(1− ηk)(E[ft(x (k) t )],B. Proof of Theorem 1: Convex Case,[0],[0]
"− ft(x∗)) + ηk
[ 2Q1/2D
(k + 4)1/3 + 〈d(k)t ,v (k) t",B. Proof of Theorem 1: Convex Case,[0],[0]
"− x∗〉+ ηk
LD2
2
] .
",B. Proof of Theorem 1: Convex Case,[0],[0]
Now we have obtained an upper bound on the expected optimality gap E[ft(x(k+1)t )],B. Proof of Theorem 1: Convex Case,[0],[0]
− ft(x∗) in terms of the expected optimality gap E[ft(x(k)t )],B. Proof of Theorem 1: Convex Case,[0],[0]
− ft(x∗) in the previous iteration.,B. Proof of Theorem 1: Convex Case,[0],[0]
"By induction on k, we get that the final iterate in the sequence, xt , x (K+1) t , satisfies the following expected optimality gap E[ft(xt)]− ft(x∗) ≤ K∏
k=1
(1− ηk)",B. Proof of Theorem 1: Convex Case,[0],[0]
[ft(x1)− ft(x∗)],B. Proof of Theorem 1: Convex Case,[0],[0]
"+ K∑
k=1
ηk K∏ j=k+1 (1− ηj) [ 2Q1/2D (k + 4)1/3 + 〈d(k)t ,v (k) t −x∗〉+ ηk LD2 2 ] (2)
Recall that the Frank Wolfe step sizes are ηk = 1k+3 .",B. Proof of Theorem 1: Convex Case,[0],[0]
"We may obtain upper bounds on product of the form ∏K k=r(1− ηk) by
K∏ k =r (1− ηk) = K∏ k=r ( 1− 1 k + 3 ) ≤ exp",B. Proof of Theorem 1: Convex Case,[0],[0]
( − K∑ k=r 1 x+ 3 ) ≤ exp,B. Proof of Theorem 1: Convex Case,[0],[0]
( − ∫ K+1 x=r 1 x+ 3 dx ) =,B. Proof of Theorem 1: Convex Case,[0],[0]
"r + 3 K + 4 ≤ r + 3 K
Substituting step sizes ηk = 1k+3 into Eq (2) and using this upper bound yields
(3)E[ft(xt)]− ft(x∗) ≤",B. Proof of Theorem 1: Convex Case,[0],[0]
"4
K",B. Proof of Theorem 1: Convex Case,[0],[0]
[ft(x1)− ft(x∗)],B. Proof of Theorem 1: Convex Case,[0],[0]
+ K∑ k=1,B. Proof of Theorem 1: Convex Case,[0],[0]
( 1 k + 3 · k + 4 K ),B. Proof of Theorem 1: Convex Case,[0],[0]
"[ 2Q1/2D (k + 4)1/3 + 〈d(k)t ,v (k) t",B. Proof of Theorem 1: Convex Case,[0],[0]
"− x∗〉+ LD2 2(k + 3) ]
Which may be further simplified by using (
1 k+3 · k+4 K ) ≤ 43K to obtain
E[ft(xt)]− ft(x∗) ≤ 4
K",B. Proof of Theorem 1: Convex Case,[0],[0]
[ft(x1)− ft(x∗)],B. Proof of Theorem 1: Convex Case,[0],[0]
"+
",B. Proof of Theorem 1: Convex Case,[0],[0]
"4
3K K∑ k=1",B. Proof of Theorem 1: Convex Case,[0],[0]
"[ 2Q1/2D (k + 3)1/3 + 〈d(k)t ,v (k) t",B. Proof of Theorem 1: Convex Case,[0],[0]
"− x∗〉+ LD2 2(k + 3) ] ,
As before, we can obtain the following upper bounds using integral methods:
K∑ k",B. Proof of Theorem 1: Convex Case,[0],[0]
"=1 1 k + 3 ≤ log ( K + 3 3 ) ≤ log(K + 1) and K∑ k =1
1 (k + 3)1/3 ≤",B. Proof of Theorem 1: Convex Case,[0],[0]
"3 2
( (K + 3)2/3",B. Proof of Theorem 1: Convex Case,[0],[0]
− 32/3 ),B. Proof of Theorem 1: Convex Case,[0],[0]
"≤ 3
2 K2/3
Substituting these bounds into Eq (3) yields
E[ft(xt)]− ft(x∗) ≤",B. Proof of Theorem 1: Convex Case,[0],[0]
"4
K",B. Proof of Theorem 1: Convex Case,[0],[0]
[ft(x1)− ft(x∗)],B. Proof of Theorem 1: Convex Case,[0],[0]
"+
4Q1/2D
K1/3",B. Proof of Theorem 1: Convex Case,[0],[0]
"+
4LD2 log(K + 1)
3K +
4
3K K∑ k=1 〈d(k)t ,v (k) t − x∗〉.
",B. Proof of Theorem 1: Convex Case,[0],[0]
"Now, we can begin to bound regret by summing over all t = 1 . . .",B. Proof of Theorem 1: Convex Case,[0],[0]
"T to obtain
T∑ t =1 E[ft(xt)]−",B. Proof of Theorem 1: Convex Case,[0],[0]
T∑ t =1 ft(x ∗) ≤ 4 K T∑ t=1,B. Proof of Theorem 1: Convex Case,[0],[0]
[ft(x1)− ft(x∗)],B. Proof of Theorem 1: Convex Case,[0],[0]
"+ 4TQ1/2D K1/3
+ 4TLD2 log(K + 1)
3K +
4
3K T∑ t=1 K∑ k=1 〈d(k)t ,v (k) t − x∗〉
Recall that for a fixed k, the sequence {v(k)t }Tt=1 is produced by a online linear minimization oracle with regretRET so that
T∑ t =1 〈d(k)t ,v (k) t − x∗〉 ≤",B. Proof of Theorem 1: Convex Case,[0],[0]
"T∑ t=1 〈d(k)t ,v (k) t 〉 −min",B. Proof of Theorem 1: Convex Case,[0],[0]
x∈K,B. Proof of Theorem 1: Convex Case,[0],[0]
"T∑ t=1 〈d(k)t ,x〉 ≤ RET .
",B. Proof of Theorem 1: Convex Case,[0],[0]
Substituting this into the upper bound and using M = max1≤t≤T,B. Proof of Theorem 1: Convex Case,[0],[0]
"[ft(x1)− ft(x∗)] yields
T∑ t =1 E[ft(xt)]− T∑ t =1 ft(x ∗) ≤",B. Proof of Theorem 1: Convex Case,[0],[0]
4TDQ 1/2 K1/3 + 4T K ( M + LD2 3 log(K + 1) ),B. Proof of Theorem 1: Convex Case,[0],[0]
"+ 4 3 RET
Now, setting K = T 3/2 and using a linear oracle withRET =",B. Proof of Theorem 1: Convex Case,[0],[0]
"O( √ T ) yields
T∑ t",B. Proof of Theorem 1: Convex Case,[0],[0]
=1 E[ft(xt)]−,B. Proof of Theorem 1: Convex Case,[0],[0]
T∑ t =1 ft(x ∗) ≤ 4 √ TDQ1/2 +,B. Proof of Theorem 1: Convex Case,[0],[0]
4√ T ( M + LD2 3 (log T 3/2 + 1) ),B. Proof of Theorem 1: Convex Case,[0],[0]
"+ 4 3 RET
= O( √ T ).",B. Proof of Theorem 1: Convex Case,[0],[0]
"Using the smoothness of ft and recalling x (k+1) t − x (k) t = 1 Kv (k) t , we have
(4)
ft(x",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
(k+1) t ),C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
≥ ft(x (k) t ) +,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"〈∇ft(x (k) t ),x (k+1) t − x (k) t 〉 −
L 2 ‖x(k+1)t",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− x (k) t ‖2
= ft(x",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
(k) t ) +,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"〈
1
K ∇ft(x(k)t ),v (k) t 〉 −
L
2K2 ‖v(k)t ‖2
≥ ft(x(k)t ) + 1
K 〈∇ft(x(k)t ),v (k) t 〉 −
LD2 2K2 .
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"We can re-write the term 〈∇ft(x(k)t ),v (k) t 〉 as
(5) 〈∇ft(x(k)t ),v (k) t 〉 = 〈∇ft(x (k) t )",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ,v (k) t 〉+ 〈d (k) t ,v (k) t 〉
= 〈∇ft(x(k)t )",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ,v (k) t 〉+ 〈d (k) t ,x ∗〉+ 〈d(k)t ,v (k) t − x∗〉 = 〈∇ft(x(k)t )",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ,v (k) t",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− x∗〉+ 〈∇ft(x (k) t ),x ∗〉+ 〈d(k)t ,v (k) t − x∗〉.
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"We claim 〈∇ft(x(k)t ),x∗〉 ≥ ft(x∗) − ft(x",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
(k) t ).,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"Indeed, using monotonicity of ft and concavity along non-negative directions, we have
(6) ft(x
∗)− ft(x(k)t ) ≤",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
ft(x∗ ∨ x (k) t ),C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− ft(x (k) t )
≤ 〈∇ft(x(k)t ),x∗ ∨ x (k) t",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− x (k) t 〉 = 〈∇ft(x(k)t ), (x∗ − x (k) t ) ∨ 0〉 ≤ 〈∇ft(x(k)t ),x∗〉.
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
Plugging Eq.,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"(6) into Eq. (5), we obtain
(7)〈∇ft(x(k)t ),v (k) t 〉 ≥ 〈∇ft(x (k) t )",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ,v (k) t",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− x∗〉+ 〈d (k) t ,v (k) t",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− x∗〉+ (ft(x∗)− ft(x (k) t )).
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"Using Young’s inequality, we can show that
(8)〈∇ft(x (k) t )",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ,v (k) t",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− x∗〉 ≥ −
1
2β(k) ‖∇ft(x(k)t )",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ‖2 −
β(k)
2 ‖v(k)t",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− x∗‖2
≥ − 1 2β(k) ‖∇ft(x(k)t )",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ‖2 − β(k)D2/2
Then we plug Eqs.",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"(7) and (8) into Eq. (4), we deduce
ft(x (k+1) t )≥ ft(x",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
(k) t ),C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"+
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"1
K
[ − 1
2β(k) ‖∇ft(x(k)t )−d (k) t ‖2−β(k)D2/2+〈d",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"(k) t ,v (k) t −x∗〉+(ft(x∗)−ft(x (k) t ))
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
],C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− LD 2
2K2 .
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"Equivalently, we have
(9)ft(x ∗)− ft(x(k+1)t ) ≤ (1− 1/K)[ft(x∗)− ft(x",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"(k) t )]
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− 1 K
[ − 1
2β(k) ‖∇ft(x(k)t )",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ‖2 − β(k)D2/2 + 〈d (k) t ,v (k) t − x∗〉
] + LD2
2K2 .
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
Applying Eq.,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"(9) recursively for 1 ≤ k ≤ K immediately yields
ft(x ∗)− ft(x(k+1)t ) ≤ (1− 1/K)K [ft(x∗)− ft(x (1) t )]
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"+ 1
K K∑ k=1",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
[ 1 2β(k) ‖∇ft(x(k)t ),C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ‖2 + β(k)D2/2 + 〈d (k) t ,x ∗",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− v(k)t 〉 ] + LD2 2K .
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"Recall that the point played in round t is xt , x (K+1) t , the first iterate in the sequence is x (1) t = 0, and that (1− 1/K)K ≤ 1/e for all K ≥ 1",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"so that
ft(x ∗)− ft(xt) ≤
1 e [ft(x ∗)− ft(0)]",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
+ 1 K K∑ k=1,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
[ 1 2β(k) ‖∇ft(x(k)t ),C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ‖2 + β(k)D2/2 + 〈d (k) t ,x ∗",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− v(k)t 〉 ] + LD2 2K .
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"Since ft(0) ≥ 0, we obtain
(10)(1− 1/e)ft(x∗)− ft(xt) ≤ 1
K K∑ k=1",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
[ 1 2β(k) ‖∇ft(x(k)t ),C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ‖2 + β(k)D2/2 + 〈d (k) t ,x ∗",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− v(k)t 〉 ] + LD2 2K .
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
If we sum Eq.,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"(10) over t = 1, 2, 3, . . .",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
", T , we obtain
(1− 1/e) T∑
t=1
ft(x ∗)
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− T∑
t=1
ft(xt) ≤ 1
K K∑",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"k=1
[ 1
2β(k)",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
T∑ t=1 ‖∇ft(x(k)t ),C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ‖2 + β(k)D2T/2 + T∑ t=1 〈d(k)t ,x∗",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− v (k) t 〉
] + LD2T
2K .
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"By the definition of the regret, we have T∑
t =1
〈d(k)t ,x∗ − v (k) t 〉 ≤ RET .
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"Therefore, we deduce
(1− 1/e) T∑
t=1
ft(x ∗)− T∑ t=1 ft(xt)
≤ 1 K K∑ k=1
[ 1
2β(k) T∑ t=1 ‖∇ft(x(k)t )",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ‖2 + β(k)D2T/2
] + LD2T
2K +RET .
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"Taking the expectation in both sides, we obtain
(11) (1− 1/e) T∑ t=1",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"E[ft(x∗)]− T∑ t=1 E[ft(xt)]
≤ 1 K K∑",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"k=1
[ 1
2β(k)",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
T∑ t=1 E[‖∇ft(x(k)t ),C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"− d (k) t ‖2] + β(k)D2T/2
] + LD2T
2K +RET .
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
Notice that ‖∇ft(x(k)t ),C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
−∇ft(x (k−1) t )‖ ≤,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
L‖v (k) t ‖/T ≤ LR/T ≤ 2LR/(k+ 3).,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"By Theorem 3, if we set ρk = 2(k+3)2/3 , we have
(12)E[‖∇ft(x (k) t )",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
− d (k) t ‖2] ≤,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"Qt (k + 4)2/3
≤ Q (k + 4)2/3 ,
where Qt , max{‖∇ft(0)‖242/3, 4σ2 + 6L2R2} and Q , max{max1≤t≤T ‖∇ft(x1)‖242/3, 4σ2 + 6L2R2}.
",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
Plugging Eq. (12) into Eq.,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
(11) and setting β(k) =,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"(Q1/2)/(D(k + 3)1/3), we deduce
(1− 1/e) T∑
t=1
E[ft(x∗)]− T∑
t=1
E[ft(xt)]",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"≤ TDQ1/2
K
K∑ k=1
1 (k + 4)1/3 + LD2T 2K +RET
Since ∑K
k=1 1 (k+4)1/3 ≤ ∫K 0 dx (x+4)1/3 = 32",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
"[(K + 4) 2/3 − 92/3] ≤ 32K 2/3, we have
(1− 1/e) T∑
t=1
E[ft(x∗)]− T∑
t=1
E[ft(xt)] ≤",C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
3TDQ1/2 2K1/3 + LD2T 2K +RET .,C. Proof of Theorem 1: DR-Submodular Case,[0],[0]
Let f(x) = Eft∼D[ft(x)] denote the expected function.,D. Proof of Theorem 2: Convex Case,[0],[0]
"Because f is L-smooth and convex, we have
f(xt+1)− f(x∗) = f(xt + ηt(vt",D. Proof of Theorem 2: Convex Case,[0],[0]
"− xt))− f(x∗)
≤",D. Proof of Theorem 2: Convex Case,[0],[0]
"f(xt)− f(x∗) + ηt〈∇f(xt),vt",D. Proof of Theorem 2: Convex Case,[0],[0]
"− xt〉+ η2t L
2 ‖vt − xt‖2
≤ f(xt)− ft(x∗) + ηt〈∇f(xt),vt − xt〉+ η2t LD2
2 .
",D. Proof of Theorem 2: Convex Case,[0],[0]
"As before, the dual pairing may be decomposed as
〈∇f(xt),vt − xt〉 = 〈∇f(xt)− dt,vt − x∗〉+ 〈∇f(xt),x∗ − xt〉+ 〈dt,vt − x∗〉.
",D. Proof of Theorem 2: Convex Case,[0],[0]
"We can bound the first term using Young’s Inequality to get
〈∇f(xt)− dt,vt − x∗〉 ≤ 1
2β ‖f(xt)−",D. Proof of Theorem 2: Convex Case,[0],[0]
dt‖2 + 2β‖vt,D. Proof of Theorem 2: Convex Case,[0],[0]
"− x∗‖2
≤ 1 2β ‖f(xt)−",D. Proof of Theorem 2: Convex Case,[0],[0]
"dt‖2 + 2βD2.
",D. Proof of Theorem 2: Convex Case,[0],[0]
"for any β > 0, which will be chosen later in the proof.",D. Proof of Theorem 2: Convex Case,[0],[0]
"We may also bound the second term in the decomposition of the dual pairing using convexity of f , i.e. 〈∇f(xt),x∗ − xt〉 ≤ ft(x∗)− f(xt).",D. Proof of Theorem 2: Convex Case,[0],[0]
"Finally, the third term is nonpositive, by the choice of vt, namely vt = arg minv∈K〈dt,v〉.",D. Proof of Theorem 2: Convex Case,[0],[0]
"Using these inequalities, we now have that
f(xt+1)− f(x∗) ≤ (1− ηt) (f(xt)− f(x∗))",D. Proof of Theorem 2: Convex Case,[0],[0]
"+ ηt ( 1
2β ‖f(xt)−",D. Proof of Theorem 2: Convex Case,[0],[0]
"dt‖2 + 2βD2
) + η2t LD2
2 .
",D. Proof of Theorem 2: Convex Case,[0],[0]
"Taking expectation over the randomness in the iterates (i.e. the stochastic gradient estimates), we have that
(13)E[f(xt+1)]− f(x∗) ≤ (1− ηt) (E[f(xt)]− f(x∗))",D. Proof of Theorem 2: Convex Case,[0],[0]
"+ ηt ( 1
2β E[‖f(xt)− dt‖2] + 2βD2
) + η2t LD2
2 .
",D. Proof of Theorem 2: Convex Case,[0],[0]
Now we will apply the variance reduction technique.,D. Proof of Theorem 2: Convex Case,[0],[0]
"Note that
‖∇f(xt+1)−∇f(xt)‖≤ L‖xt+1 − xt‖≤ Lηt‖xt − vt‖≤ LηtD
where we have used that f is L-smooth, the convex update, and the diameter.",D. Proof of Theorem 2: Convex Case,[0],[0]
"Now, using Theorem 3 with G = LD and s = 3, we have that
E[‖f(xt)− dt‖2] ≤ Q
(t+ 4)2/3 ,
where Q , max{42/3‖∇f(x1)‖2, 4σ2 + 3(LD)2/2}.",D. Proof of Theorem 2: Convex Case,[0],[0]
"Using this bound in Eq (13) and setting β = Q 1/2
2D(t+4)1/3 yields
E[f(xt+1)]− f(x∗) ≤ (1− ηt) (E[f(xt)]− f(x∗))",D. Proof of Theorem 2: Convex Case,[0],[0]
"+ ηt 2Q1/2D
(t+ 4)1/3 + η2t
LD2
2 .
",D. Proof of Theorem 2: Convex Case,[0],[0]
"By induction, we have
E[f(xt+1)]− f(x∗) ≤",D. Proof of Theorem 2: Convex Case,[0],[0]
"t∏
k=1
(1− ηk)M + t∑
k=1
ηk t∏ j=k+1 (1− ηj) ( 2Q1/2D (k + 4)1/3 + ηk LD2 2 ) ,
where M = f(x1)− f(x∗).",D. Proof of Theorem 2: Convex Case,[0],[0]
Recall that the step size is set to be ηt = 1t+3 .,D. Proof of Theorem 2: Convex Case,[0],[0]
"As in Appendix B, we can obtain the bounds∏t k=1(1 − ηk) = ∏t k=1(1 − 1 k+3 ) ≤ exp(−",D. Proof of Theorem 2: Convex Case,[0],[0]
∑t,D. Proof of Theorem 2: Convex Case,[0],[0]
k=1 1 k+3 ) ≤ exp(− ∫ t+1 1 dx x+3 ),D. Proof of Theorem 2: Convex Case,[0],[0]
"= 4/(t + 4) and similarly ∏t j=k+1(1 −
1 j+3 )",D. Proof of Theorem 2: Convex Case,[0],[0]
≤,D. Proof of Theorem 2: Convex Case,[0],[0]
k+4 t+4 .,D. Proof of Theorem 2: Convex Case,[0],[0]
"Using these bounds as well as the choice of step size ηt = 1 t+3 in the above yields
E[f(xt+1)]− f(x∗) ≤ 4M
t+ 4 + t∑ k=1",D. Proof of Theorem 2: Convex Case,[0],[0]
"( 1 k + 3 · k + 4 t+ 4 )( 2Q1/2D (k + 4)1/3 + 1 k + 3 LD2 2 )
",D. Proof of Theorem 2: Convex Case,[0],[0]
"= 4M
t+ 4 +
4
3(t+ 4)",D. Proof of Theorem 2: Convex Case,[0],[0]
"t∑ k=1 ( 2Q1/2D (k + 4)1/3 + 1 k + 3 LD2 2 )
where the second inequality used (
1 k+3 · k+4 (t+4) )",D. Proof of Theorem 2: Convex Case,[0],[0]
< 43(t+4) .,D. Proof of Theorem 2: Convex Case,[0],[0]
"As before in Section B, using the inequalities ∑t k=1 1 k+3 ≤
log(t+ 1) and ∑t
k=1 1 (k+3)1/3 ≤ 32 t 2/3 in the above yields
E[f(xt+1)]− f(x∗) ≤ 4M
t+ 4 + 4Q1/2D
t2/3
t+ 4 +
4 3 LD2 log(t+ 1) t+ 4 . (14)
To obtain a regret bound, we sum over rounds t = 1, . . .",D. Proof of Theorem 2: Convex Case,[0],[0]
"T to obtain
T∑ t=1",D. Proof of Theorem 2: Convex Case,[0],[0]
"E[f(xt)]− Tf(x∗) ≤ 4M
( T∑
t=1
1
t+ 4
)",D. Proof of Theorem 2: Convex Case,[0],[0]
"+ 4Q1/2D ( T∑
t=1
t2/3
t+ 4
)",D. Proof of Theorem 2: Convex Case,[0],[0]
"+ 4
3 LD2
( T∑
t=1
log(t+ 1)
t+ 4
)
Using the integral trick again, we obtain the upper bounds ∑T
t=1 1 t+4 ≤",D. Proof of Theorem 2: Convex Case,[0],[0]
log(T,D. Proof of Theorem 2: Convex Case,[0],[0]
"+ 1), ∑T t=1 t2/3 t+4 ≤",D. Proof of Theorem 2: Convex Case,[0],[0]
"3 2T
2/3, and∑T t=1 log(t+3) t+4 ≤ log 2(T + 3).",D. Proof of Theorem 2: Convex Case,[0],[0]
"Substituting these bounds in the regret bound above yields
T∑ t=1",D. Proof of Theorem 2: Convex Case,[0],[0]
E[f(xt)]− Tf(x∗) ≤ 4M log(T + 1) +,D. Proof of Theorem 2: Convex Case,[0],[0]
6Q1/2DT 2/3 + 4 3 LD2 log2(T + 3) =,D. Proof of Theorem 2: Convex Case,[0],[0]
O ( T 2/3 ),D. Proof of Theorem 2: Convex Case,[0],[0]
"Since f is L-smooth, we obtain
f(xt+1) ≥ f(xt) +",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"〈∇f(xt), 1
T vt〉 −
L 2 ‖ 1 T vt‖2
≥ f(xt)",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"+ 1
T 〈∇f(xt),vt〉 −
LD2
2T 2
= f(xt)",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"+ 1
T 〈dt,vt〉+
1 T 〈∇f(xt)− dt,vt〉 −
LD2
2T 2
≥ f(xt)",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"+ 1
T 〈dt,x∗〉+
1 T 〈∇f(xt)− dt,vt〉 −
LD2
2T 2
= f(xt)",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"+ 1
T 〈∇f(xt)− dt,vt − x∗〉+
1 T 〈f(xt),x∗〉 −
LD2 2T 2 .
",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"In the last inequality, we used the fact that vt = arg maxv∈K〈dt,v〉.",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
Similar to Eq.,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"(6) in Appendix C, we have 〈f(xt),x∗〉 ≥ f(x∗)− f(xt).",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"Again, Young’s inequality gives 〈∇f(xt)− dt,vt − x∗〉 ≥ −12 (βt‖vt − x
∗‖2 + ‖f(xt)−",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
dt‖2/βt).,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"Therefore, we deduce
f(xt+1) ≥ f(xt)− 1
2T (βt‖vt",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
− x∗‖2 + ‖f(xt)−,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"dt‖2/βt) +
1 T (f(x∗)− f(xt))−
LD2
2T 2
≥ f(xt)− 1
2T (βtD
2 + ‖f(xt)−",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"dt‖2/βt) + 1
T (f(x∗)− f(xt))−
LD2 2T 2 .
",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"Re-arrangement of the terms yields
f(x∗)− f(xt+1) ≤ (1− 1/T )(f(x∗)− f(xt))",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"+ 1
2T (βtD
2 + ‖f(xt)−",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"dt‖2/βt) + LD2
2T 2 .
",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"Recalling that (1− 1/T )T ≤ 1/e and f(x1) = f(0) ≥ 0, we have
f(x∗)− f(xt+1) ≤ (1− 1/T )t(f(x∗)− f(x1))",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"+ 1
2T t∑ i=1",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
(βiD 2 + ‖f(xi)−,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"di‖2/βi) + LD2 2T
≤",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
1,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
e f(x∗),E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
+ 1 2T t∑ i=1,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
(βiD 2 + ‖f(xi)−,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
di‖2/βi) +,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"LD2 2T ,
which in turn yields
(1− 1/e)f(x∗)− f(xt+1) ≤ 1
2T t∑ i=1",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
(βiD 2 + ‖f(xi)−,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
di‖2/βi) +,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"LD2 2T .
",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"Taking expectation in both sides gives
(1− 1/e)E[f(x∗)]− E[f(xt+1)]",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"≤ 1
2T t∑ i=1",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"(βiD 2 + E[‖f(xi)− di‖2]/βi) + LD2 2T .
",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
Notice that ‖∇f(xt)−∇f(xt−1)‖ ≤,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
L‖vt‖/K ≤ LR/K ≤ 2LR/(k + 3).,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"By Theorem 3, if we set ρi = 2(i+3)2/3 , we have
E[‖f(xi)− di‖2] ≤ Q
(i+ 4)2/3
for every i ≤ T and Q = max{‖∇f(0)‖242/3, 4σ2 + 6L2R2}.",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"If we set βi = Q 1/2
D(i+4)1/3 , we have
(1− 1/e)E[f(x∗)]− E[f(xt+1)]",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"≤ t∑
i=1
DQ1/2 (i+ 4)1/3T + LD2 2T ≤ 3DQ 1/2t2/3 2T + LD2 2T
since ∑t
i=1 1 (i+4)1/3 ≤ ∫ t 0 1",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
(x+4)1/3 dx = 32,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
[(x+ 4) 2/3]t0 ≤ 32,E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"[x 2/3]t0 = 3 2 t 2/3.
",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"Therefore we have
(1− 1/e)TE[f(x∗)]− T∑
t=1
E[f(xt)]
= (1− 1/e)E[f(x∗)]− f(0) + T−1∑ t=1",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"[(1− 1/e)E[f(x∗)]− E[f(xt)]]
≤ (1− 1/e)E[f(x∗)]− f(0) + T−1∑ t=1",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"[ 3DQ1/2t2/3 2T + LD2 2T ] .
",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"Since ∑T−1
t=1 t 2/3 = 1 + ∑T−1 t=2 t 2/3 ≤ 1 + ∫ T 1 t2/3dt = 35T 5/3 + 25 , we conclude
(1− 1/e)TE[f(x∗)]− T∑
t=1
E[f(xt)] ≤ (1− 1/e)E[f(x∗)]− f(0) + 3DQ1/2
10 (3T 2/3 + 2T−1)",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
"+
LD2
2 = O(T 2/3).",E. Proof of Theorem 2: DR-Submodular Case,[0],[0]
Online optimization has been a successful framework for solving large-scale problems under computational constraints and partial information.,abstractText,[0],[0]
"Current methods for online convex optimization require either a projection or exact gradient computation at each step, both of which can be prohibitively expensive for large-scale applications.",abstractText,[0],[0]
"At the same time, there is a growing trend of nonconvex optimization in machine learning community and a need for online methods.",abstractText,[0],[0]
"Continuous DR-submodular functions, which exhibit a natural diminishing returns condition, have recently been proposed as a broad class of non-convex functions which may be efficiently optimized.",abstractText,[0],[0]
"Although online methods have been introduced, they suffer from similar problems.",abstractText,[0],[0]
"In this work, we propose Meta-Frank-Wolfe, the first online projectionfree algorithm that uses stochastic gradient estimates.",abstractText,[0],[0]
The algorithm relies on a careful sampling of gradients in each round and achieves the optimal O( √ T ) adversarial regret bounds for convex and continuous submodular optimization.,abstractText,[0],[0]
"We also propose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single stochastic gradient estimate in each round and achieves an O(T ) stochastic regret bound for convex and continuous submodular optimization.",abstractText,[0],[0]
We apply our methods to develop a novel “lifting” framework for the online discrete submodular maximization and also see that they outperform current state-of-the-art techniques on various experiments.,abstractText,[0],[0]
"Yale Institute for Network Science, Yale University, New Haven, CT, USA Department of Electrical Engineering, Yale University Department of Computer Science, Yale University Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA.",abstractText,[0],[0]
Correspondence to: Lin Chen <lin.chen@yale.edu>.,abstractText,[0],[0]
Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity,title,[0],[0]
Generalized bipartite matching or bipartite b-matching is one of the fundamental problems in computer science.,1. Introduction,[0],[0]
"Canonical applications include resource allocation problems such as ad allocation in online advertising, job/server allocation in cloud computing, organ/donor matching, and product recommendation under resource constraints.",1. Introduction,[0],[0]
"It has also been utilized as an algorithmic tool in a variety of do-
*Equal contribution 1Columbia University, New York, NY 2Google Research.",1. Introduction,[0],[0]
"Correspondence to: Shipra Agrawal <sa3305@columbia.edu>, Vahab Mirrokni <mirrokni@google.com>, Morteza Zadimoghaddam <zadim@google.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
mains, including computer vision (Belongie et al., 2002), estimating text similarity (Pang et al., 2016), string matching for protein structure alignment (Krissinel & Henrick, 2004), document clustering (Dhillon, 2001); and as a subroutine in several machine learning tasks (Huang & Jebara, 2007; Jebara & Shchogolev, 2006).
",1. Introduction,[0],[0]
The focus of this paper is on large-scale matching problems such as those arising in online advertising.,1. Introduction,[0],[0]
"In online advertising settings, a set of advertisers A provide their targeting domains to determine what subset of impressions I they are interested in.",1. Introduction,[0],[0]
"This can be modeled as a bipartite graph G(A, I,E).",1. Introduction,[0],[0]
"The advertisers also set capacity/targeting constraints on the number of impressions they want their ads to be shown to, referred to as capacity (or budget) constraints.",1. Introduction,[0],[0]
It is assumed that each advertiser a has a capacity constraint Ca.,1. Introduction,[0],[0]
The matching task is to assign each impression to at most one eligible advertiser based on the targeting information while respecting the capacity constraints.,1. Introduction,[0],[0]
"Typically, the goal is to maximize either the number of matched impressions, or the sum of values of the assignments if we are awarded different values for the assignment of every pair of impressions and advertisers.
",1. Introduction,[0],[0]
The rapid growth in Internet advertising has introduced many large scale matching problems for assigning billions of impressions to advertisers on a daily basis.,1. Introduction,[0],[0]
Classic centralized approaches to solve these problems may be irrelevant due to their computational and memory limitations.,1. Introduction,[0],[0]
"In online advertising, the number of impressions are usually much higher than the number of advertisers.",1. Introduction,[0],[0]
Such bipartite graphs are called lopsided bipartite graphs.,1. Introduction,[0],[0]
"The number of impressions is often so large that these matching instances do not fit in the memory of a single machine, and there is a dire need of designing simple and scalable matching algorithms.",1. Introduction,[0],[0]
"This is true even if we treat similar impressions as identical copies because each impression type is “the Cartesian product of several features (such as geographic location, time of day/week), domains of which have sizes typically ranging from thousands to millions” (Bateni et al., 2017).",1. Introduction,[0],[0]
"Similar lopsided bipartite matching problems arise in many other domains, for example in product recommendation, where the number of users is typically much higher than the number of products, or document-word clustering, where
the number of words is typically much larger compared to the number of documents (Dhillon, 2001).
",1. Introduction,[0],[0]
All the above motivate the problem of designing simple and scalable algorithms for lopsided bipartite matching in practice.,1. Introduction,[0],[0]
"One such natural algorithm that has been used in practice is the proportional allocation algorithm: consider the bipartite matching problem on graph G(A, I,E) with given capacity constraints Ca for a ∈ A. Proportional allocation algorithm is as follows: Maintain a priority score βa for each a ∈ A, initialized as βa = 1.",1. Introduction,[0],[0]
Iteratively allocate each node i ∈,1. Introduction,[0],[0]
I to an eligible node a ∈,1. Introduction,[0],[0]
A in proportion of its score βa.,1. Introduction,[0],[0]
"After each round, increase or decrease βa based on over- or under- allocation of node a, for each a ∈ A. Repeat until this algorithm converges to a stable solution.",1. Introduction,[0],[0]
"This is a natural and easy to implement algorithm, used in practice to compute b-matching in a distributed fashion for large-scale problems.",1. Introduction,[0],[0]
"This is especially useful when the graph is lop-sided, so that the number of advertisers, and hence, the number of priority scores to be maintained and communicated are relatively small.
",1. Introduction,[0],[0]
Our first result is that this simple iterative algorithm converges to a (1 − )-approximate fractional b-matching solution in O( logn 2 ) rounds.,1. Introduction,[0],[0]
"To this end, we first present a combinatorial proof of our result for the unweighted case.",1. Introduction,[0],[0]
"Then, we present a primal-dual interpretation via convex programing duality.",1. Introduction,[0],[0]
"We formulate a convex program for the problem of maximizing the cardinality/weight of matching in a bipartite graph, with the entropy of the matching as a regularizer in the objective.",1. Introduction,[0],[0]
"Interestingly, it turns out that the priority scores in the proportional allocation algorithm correspond to the dual variables of this convex program.",1. Introduction,[0],[0]
"And, the proportional allocation rule corresponds to the complimentary primal solution, for any given values of the dual variables.",1. Introduction,[0],[0]
"This formulation helps us extend the proportional allocation algorithm and convergence results to edge-weighted graphs.
",1. Introduction,[0],[0]
"More importantly, an implication of this formulation is that the proportional allocation algorithm naturally produces high entropy matchings.",1. Introduction,[0],[0]
"In fact, we formally demonstrate that we can set certain parameters of the algorithm to ensure convergence to an almost optimal matching with high entropy.",1. Introduction,[0],[0]
"High entropy, in turn, implies additional desirable properties of this matching.",1. Introduction,[0],[0]
"First of all, by maximizing entropy, the allocation achieves higher diversity both from the advertisers’ point of view and from the users’ perspective.",1. Introduction,[0],[0]
"From advertisers’ perspective, they see a more diverse set of impressions which translates to reaching out to a more diverse demographics.",1. Introduction,[0],[0]
"From impressions’ perspective, each user will also see a more diverse set of ads.",1. Introduction,[0],[0]
"The connection between entropy and various diversity measures has been confirmed by several papers (Qin & Zhu, 2013; Ahmed et al., 2017; Noia et al., 2017).",1. Introduction,[0],[0]
"Besides achieving higher di-
versity, high entropy allocations are also believed to be more fair (e.g., (Venkatasubramanian, 2010) and (Lan et al., 2010) propose high entropy as an important fairness criteria).
",1. Introduction,[0],[0]
"Furthermore, one can argue that the proportional allocation algorithm achieves better fairness due to its symmetry and anonymity properties (Lan et al., 2010).",1. Introduction,[0],[0]
It is also likely to be more robust to changes in demand patterns (due to its increased randomized allocation criteria).,1. Introduction,[0],[0]
"Below, we further discuss the merits of proportional allocation in comparison to other related online and distributed algorithms for bipartite matching.",1. Introduction,[0],[0]
Graph matching and assignment problems are some of the most well studied problems in combinatorial optimization.,1.1. Related work,[0],[0]
"There is considerable work on fast exact algorithms, as well as faster approximate algorithms, for matching problems.",1.1. Related work,[0],[0]
"Notable examples include (1− ) approximation in O(m log(1/ )) time by (Duan & Pettie, 2014) for weighted graphs, where m is the number of edges in the graph.",1.1. Related work,[0],[0]
"For maximum cardinality matching, many classic algorithms (e.g., (Hopcroft & Karp, 1971) ) can achieve this.
",1.1. Related work,[0],[0]
"Motivated by the large-scale applications of matching in advertising and other e-commerce applications, recently there has been a focus on distributed algorithms.",1.1. Related work,[0],[0]
"In these applications, it is desirable to have algorithms which run in potentially logarithmic rounds or phases, with each phase involving simple computations that can be distributed1 and/or parallelized.",1.1. Related work,[0],[0]
"Some recent literature includes the work by (Bahmani et al., 2014) in the MapReduce framework, which improves upon previous work of (Ahn & Guha, 2013) and (Bahmani et al., 2012).",1.1. Related work,[0],[0]
"The proportional allocation algorithm provides a much simpler alternative approach for such distributed large-scale settings, especially in case of large lop-sided bipartite graphs.",1.1. Related work,[0],[0]
"Arguably, this heuristic is comparable in its simplicity and ease of implementation to the greedy heuristic, which only allows a 2-factor approximation.",1.1. Related work,[0],[0]
"In contrast, as proven in this paper, the proportional allocation converges to optimal solution in logarithmic number of rounds.
",1.1. Related work,[0],[0]
Another closely related work is by Charles et al. (2010) on fast streaming algorithms for bipartite matching in lopsided graphs.,1.1. Related work,[0],[0]
"Proportional allocation has several significant benefits over the method proposed there, including high entropy matching, amenability to distributed implementation, and simple concise representation through priority scores of advertisers (i.e., one score for each node on the smaller side in the lop sided graphs) only.
",1.1. Related work,[0],[0]
"We also note that iterative approximation algorithms have been developed for the more general problem class of pack-
1i.e., allow the graph to be stored in a distributed manner
ing and covering (Plotkin et al., 1995; Awerbuch & Khandekar, 2009; Garg & Konemann, 2007).",1.1. Related work,[0],[0]
"In fact, many of these algorithms belong to the class of multiplicative weight update (MWU) methods(Arora",1.1. Related work,[0],[0]
"et al., 2012)",1.1. Related work,[0],[0]
.,1.1. Related work,[0],[0]
"The MWU methods operate by maintaining weights wa for each advertiser, similar to our priority scores.",1.1. Related work,[0],[0]
These weights are updated in a multiplicative manner based on the amount of over-allocation or under-allocation in every round.,1.1. Related work,[0],[0]
"The weights are then used as Lagrangian dual variables to combine the packing (capacity) constraints, so that the packing problem reduces to a knapsack problem.",1.1. Related work,[0],[0]
"The impression allocation then roughly reduces to greedily selecting impression-advertiser mappings with highest ratio ri,a/wa.",1.1. Related work,[0],[0]
"Besides having a simpler score update rule (constant factor updates) and a simpler, distributed assignment rule (proportional allocation), the proportional allocation algorithm is naturally designed to yield higher entropy solutions compared to these methods.",1.1. Related work,[0],[0]
"Intuitively, this is because proportional allocation rule essentially does a softmax over (ri,a − βa): imagine the case when weights ri,a are distinct but infinitesimally close to each other, then the abovementioned greedy approach will select the top Ca impressions for every advertiser, where as the softmax will give almost uniform distribution.",1.1. Related work,[0],[0]
"In fact, we formally show that softmax is the optimal form of primal decision for maximizing entropy along with weight of the matching.
",1.1. Related work,[0],[0]
"Extensions of such primal-dual approaches have also been proposed for online packing problems motivated by the Display Ads Allocation (DA) problem (Gupta & Molinaro, 2016; Agrawal & Devanur, 2015; Devanur et al., 2011; Agrawal et al., 2009; Feldman et al., 2009; 2010; Vee et al., 2010), and the Budgeted Allocation (AdWords) problem (Mehta et al., 2007; Devanur & Hayes, 2009).",1.1. Related work,[0],[0]
"In the online setting, the impressions arrive one by one in sequential time steps, and should either be immediately assigned to one of the advertisers with remaining budget, or discarded.",1.1. Related work,[0],[0]
"In these algorithms, the dual variables or advertiser weights are updated periodically over time either by solving an LP (Agrawal et al., 2009; Feldman et al., 2009; 2010; Devanur & Hayes, 2009), or by multiplicative weight updates (Gupta & Molinaro, 2016; Agrawal & Devanur, 2015; Devanur et al., 2011).",1.1. Related work,[0],[0]
These weights are then used as thresholds for making assignments of impressions arriving online.,1.1. Related work,[0],[0]
"Besides the concerns mentioned above for MWU methods, the weight updates in these online algorithms must be performed sequentially, and therefore are not amenable to parallel implementations.",1.1. Related work,[0],[0]
"In Section 2, we formulate the generalized bipartite matching problems considered in this paper.",1.2. Organization of the paper.,[0],[0]
"In Section 3, we present the proportional allocation algorithm for the maximum cardinality case, as well as its simple extension to the problem of finding maximum weighted matching with high-
entropy.",1.2. Organization of the paper.,[0],[0]
"In Section 4, we prove our main results (Theorem 1 and Theorem 2) regarding efficient convergence of both these versions of the proportional allocation algorithm.",1.2. Organization of the paper.,[0],[0]
The proof of Theorem 2 also provides an interesting primal-dual interpretation of the proportional allocation algorithm.,1.2. Organization of the paper.,[0],[0]
"Here, we formulate the generalized bipartite matching problems, aka bipartite b-matching problems, considered in this paper.",2. Problem Formulation,[0],[0]
"Throughout the paper, we use the terminology from online advertising, with the two sides of the bipartite graph being ‘impressions’ and ‘advertisers’.
",2. Problem Formulation,[0],[0]
Maximum cardinality matching.,2. Problem Formulation,[0],[0]
A set A of advertisers and a set I of impressions are given.,2. Problem Formulation,[0],[0]
"For each advertiser a ∈ A, there is a set of impressions Na ⊆",2. Problem Formulation,[0],[0]
I that can be potentially assigned to a. Similarly for any,2. Problem Formulation,[0],[0]
i ∈,2. Problem Formulation,[0],[0]
"I, we define Ni ⊆ A to be the set of advertisers that impression i can be matched to.",2. Problem Formulation,[0],[0]
"These connections can be represented with a bipartite graph G of edge set E = {(i, a) :",2. Problem Formulation,[0],[0]
i ∈,2. Problem Formulation,[0],[0]
"I, a ∈ Ni} = {(i, a) : a ∈ A, i ∈ Na}.",2. Problem Formulation,[0],[0]
"Each advertiser a has capacity Ca denoting maximum number of impressions she is interested to be matched to.
",2. Problem Formulation,[0],[0]
"The goal is to find a subset of edges M ⊆ E such that: • Each impression is incident to at most one edge in M .
",2. Problem Formulation,[0],[0]
This property ensures that each impression is assigned to at most one advertiser.,2. Problem Formulation,[0],[0]
• Each advertiser a is incident to at most,2. Problem Formulation,[0],[0]
"Ca edges in M respecting its capacity.
",2. Problem Formulation,[0],[0]
while maximizing the cardinality of M .,2. Problem Formulation,[0],[0]
"Such an edge set M is referred to as a maximum cardinality matching.
",2. Problem Formulation,[0],[0]
"A maximum cardinality fractional matching is defined as an assignment {xi,a} ∈",2. Problem Formulation,[0],[0]
"[0, 1]E that maximizes ∑",2. Problem Formulation,[0],[0]
"(i,a)∈E xi,a while satisfying capacity constraints, i.e.,∑ i∈I
xi,a ≤",2. Problem Formulation,[0],[0]
"Ca, ∀a ∈ A, (1)∑ a∈A",2. Problem Formulation,[0],[0]
"xi,a ≤ 1, ∀i ∈ I (2)
",2. Problem Formulation,[0],[0]
Maximum weighted matching.,2. Problem Formulation,[0],[0]
We also consider the more general problem of maximum weighted matching.,2. Problem Formulation,[0],[0]
"Here, for each edge e = (i, a) ∈ E, a weight ri,a has been specified.",2. Problem Formulation,[0],[0]
"The goal is to find a subset of edges M ⊆ E such that the capacity constraints for each advertiser and impression are satisfied, while maximizing total weight ∑ (i,a)∈M ri,a of the matching.",2. Problem Formulation,[0],[0]
"For fractional matching {xi,a}(i,a)∈E, similarly the goal is to maximize∑ (i,a)∈E xi,ari,a, while satisfying constraints in (1) and (2).
",2. Problem Formulation,[0],[0]
High entropy matching.,2. Problem Formulation,[0],[0]
"The proportional allocation algorithm proposed in this paper naturally gives a high en-
Algorithm 1 PropAlloc : A proportional allocation algorithm for maximum cardinality matching Input: G = (A, I,E), {Ca}a∈A; parameter ∈ (0, 1),
number of rounds R. Initialization: Set βa = 1, for all a ∈ A.
for rounds ` = 1, 2, . . .",2. Problem Formulation,[0],[0]
", R do Step 1: For each impression i, set assignment
xi,a = βa∑
a′∈Ni βa′",2. Problem Formulation,[0],[0]
",∀a ∈ Ni
Step 2: For each advertiser a, update βa as follows:
Alloca ≤",2. Problem Formulation,[0],[0]
"Ca
(1 + )",2. Problem Formulation,[0],[0]
"=⇒ βa := (1 + )βa
Alloca ≥ (1 + )",2. Problem Formulation,[0],[0]
"Ca =⇒ βa := βa
(1 + ) where Alloca := ∑ i∈Na xi,a.
end for for each a with Alloca >",2. Problem Formulation,[0],[0]
"Ca do
Set xi,a := CaAlloca xi,a,∀i ∈ Na end for
tropy fractional matching, while also maximizing cardinality/weight of the matching.",2. Problem Formulation,[0],[0]
"To formally study this property of the algorithm, we consider an alternate objective of maximizing a combination of weight and entropy of the matching.",2. Problem Formulation,[0],[0]
"Specifically, given a parameter λ ≥ 0, the goal here is to find a fractional matching {xi,a}(i,a)∈E that maximizes∑
(i,a)∈E
ri,axi,a + λ ∑
(i,a)∈E
xi,a log(1/xi,a) (3)
while satisfying capacity constraints in (1) and (2).",2. Problem Formulation,[0],[0]
"The second term in the above is the entropy of assignment {xi,a}.",2. Problem Formulation,[0],[0]
"We propose the multi round distributed algorithm PropAlloc that finds an almost optimum fractional matching, and then prove how the fractional matching can be transformed into an (integral) matching without much loss if the capacities of advertisers are large.
",3. Proportional allocation algorithm,[0],[0]
Algorithm PropAlloc intends to find priority score βa for each advertiser a ∈,3. Proportional allocation algorithm,[0],[0]
"A such that if the impressions are assigned proportional to these priorities, we achieve an almost optimum allocation.",3. Proportional allocation algorithm,[0],[0]
"Formally, impression i will be assigned to advertiser a ∈ Ni with probability βa∑
a′∈Ni βa′
.",3. Proportional allocation algorithm,[0],[0]
"Algorithm
PropAlloc then computes the expected number of impressions each advertiser a receives as follows.
",3. Proportional allocation algorithm,[0],[0]
"Alloca = ∑ i∈Na βa∑ a′∈Ni βa′
(4)
Algorithm 2 PropAlloc + : A proportional allocation algorithm for high-entropy maximum weight matching Input: G = (A, I,E), {Ca}a∈A, weights {ri,a}(i,a)∈E, pa-
rameter λ; parameter ∈ (0, 1), number of rounds R. Initialization: Set βa = (1 + )−R, for all a ∈ A.
for rounds ` = 1, 2, . . .",3. Proportional allocation algorithm,[0],[0]
", R do Step 1: For each impression i, set assignment
xi,a =
{ βaDi,a,λ if ∑ a′∈Ni βa′Di,a′,λ ≤ 1
βaDi,a,λ∑ a′∈Ni βa′Di,a′,λ otherwise
whereDi,a,λ = e ri,a λ −1",3. Proportional allocation algorithm,[0],[0]
Step 2:,3. Proportional allocation algorithm,[0],[0]
"For each advertiser a, update βa as follows:
Alloca ≤",3. Proportional allocation algorithm,[0],[0]
"Ca
(1 + )",3. Proportional allocation algorithm,[0],[0]
"=⇒ βa := (1 + )βa
Alloca ≥ (1 + )",3. Proportional allocation algorithm,[0],[0]
"Ca =⇒ βa := βa
(1 + ) where Alloca := ∑ i∈Na xi,a.
end for for each a with Alloca >",3. Proportional allocation algorithm,[0],[0]
"Ca do
Reduce xi,a for impressions",3. Proportional allocation algorithm,[0],[0]
"i ∈ Na with xi,a ≥ Ca|Na| , until ∑ i∈Na xi,a ≤",3. Proportional allocation algorithm,[0],[0]
"Ca.
end for
Intuitively, if the expected allocation Alloca exceeds the capacity Ca, it means advertiser a has been over-allocated, so the overflow of impressions Alloca",3. Proportional allocation algorithm,[0],[0]
− Ca are going to be discarded without contributing anything to the objective function.,3. Proportional allocation algorithm,[0],[0]
"On the other hand, if the expected allocation Alloca does not reach the capacity Ca, it means advertiser a has been under-allocated, so the there is a Ca−Alloca extra capacity left to be potentially exploited.",3. Proportional allocation algorithm,[0],[0]
Both of the above situations introduce some room for improving the priority variables.,3. Proportional allocation algorithm,[0],[0]
"Algorithm PropAlloc initializes all βa variables to the same value (for instance 1), and then updates βa for each a ∈ A in each round as follows.
",3. Proportional allocation algorithm,[0],[0]
•,3. Proportional allocation algorithm,[0],[0]
If Alloca ≤ Ca(1+ ) =⇒ βa := (1 + )βa.,3. Proportional allocation algorithm,[0],[0]
In other words increase priority of a by a multiplicative factor of 1 + .,3. Proportional allocation algorithm,[0],[0]
•,3. Proportional allocation algorithm,[0],[0]
If Alloca ≥ (1 + ),3. Proportional allocation algorithm,[0],[0]
"Ca =⇒ βa := βa 1+ .
",3. Proportional allocation algorithm,[0],[0]
"In other words decrease priority of a by a multiplicative factor of 1 + .
",3. Proportional allocation algorithm,[0],[0]
"• Otherwise, do not change the priority of a.
Algorithm PropAlloc consists of R rounds of computing Alloc variables based on the priorities, {βa}a∈A, and then updating the priorities with above rules.",3. Proportional allocation algorithm,[0],[0]
"After all these rounds, PropAlloc computes the fractional matching respecting all capacity constraints as follows.",3. Proportional allocation algorithm,[0],[0]
For every impression i ∈,3. Proportional allocation algorithm,[0],[0]
"I and each advertiser a ∈ Ni, we set the
assignment xi,a to be the probability that i is assigned to a based on the current priority values.",3. Proportional allocation algorithm,[0],[0]
"That is,
xi,a = βa∑
a′∈Ni βa′
These assignments always respect the constraints (1) on impressions, since the total assignment of each impression i ∈",3. Proportional allocation algorithm,[0],[0]
"I, given by ∑ a∈Ni xi,a, is equal to 1.",3. Proportional allocation algorithm,[0],[0]
"But, there might be advertisers that receive more total assignment than their capacities.",3. Proportional allocation algorithm,[0],[0]
"To adjust for these over-allocations, at the end of R rounds, the assignments to these advertisers can be reduced in any manner.",3. Proportional allocation algorithm,[0],[0]
"For each advertiser, a ∈ A with Alloca >",3. Proportional allocation algorithm,[0],[0]
"Ca, we can scale down the assignments of all edges incident on a by a factor of AllocaCa to make sure that the capacity constraints are all respected.",3. Proportional allocation algorithm,[0],[0]
"Therefore, the total weight of the fractional matching is equal to MatchWeight = ∑ a∈A min{Alloca,Ca}.
",3. Proportional allocation algorithm,[0],[0]
The proportional allocation algorithm is summarized in Algorithm 1.,3. Proportional allocation algorithm,[0],[0]
"We show that a logarithmic number of rounds suffices to converge to an almost optimum fractional allocation, and then find an integral assignment based on that.",3. Proportional allocation algorithm,[0],[0]
"Further, among the maximum cardinality matching, the proportional allocation algorithm naturally finds matchings with high entropy.",3. Proportional allocation algorithm,[0],[0]
"To formalize this observation, below we give a simple extension of the algorithm for the joint objective of maximizing entropy and weight of the matching, combined with a parameter λ.",3. Proportional allocation algorithm,[0],[0]
"In fact Algorithm 1 will be a special case of the new algorithm for λ ≈ 0, ri,a = 1,∀i, a.
Algorithm for high-entropy weighted matching.",3. Proportional allocation algorithm,[0],[0]
"Given weights {ri,a}(i,a)∈E, and a parameter λ > 0, a simple extension of the proportional allocation algorithm computes maximum weight matching with high entropy.",3. Proportional allocation algorithm,[0],[0]
This algorithm maintains and updates priority scores {βa} in a similar manner to Algorithm 1.,3. Proportional allocation algorithm,[0],[0]
"However, to account for weights and entropy parameter λ, given the priority scores, the assignments xi,a are now computed as follows: let Di,a,λ := e ri,a λ −1, then,
xi,a =
{ βaDi,a,λ if ∑ a′∈Ni βa′Di,a′,λ ≤ 1
βaDi,a,λ∑ a′∈Ni βa′Di,a′,λ otherwise
The new algorithm is summarized in Algorithm 2.",3. Proportional allocation algorithm,[0],[0]
Note that the main change is in Step 2.,3. Proportional allocation algorithm,[0],[0]
"Further, at the end of R rounds, earlier in Algorithm 1 we could allow any kind of adjustment to assignments of over-allocated advertisers.",3. Proportional allocation algorithm,[0],[0]
"But, since entropy is of consideration here, in Algorithm 2 we make a slightly more careful adjustment: we only remove impressions with large assignment value, i.e., impressions i ∈ Na with xi,a ≥ Ca|Na| .
",3. Proportional allocation algorithm,[0],[0]
"Note that these modifications keeps the simple distributed structure of the algorithm intact: given priority scores of
advertisers, the impressions can be allocated in a distributed manner in proprtion of these scores.",3. Proportional allocation algorithm,[0],[0]
"First, we show that after enough number of rounds, the fractional matching achieved by PropAlloc (refer to Algorithm 1 is almost optimal.
",4.1. Main results,[0],[0]
Theorem 1.,4.1. Main results,[0],[0]
"For any δ ∈ (0, 1], there exists2 an > 0",4.1. Main results,[0],[0]
such that algorithm PropAlloc with parameter returns a (1−δ)approximate fractional matching after R = O( log(n/δ)δ2 ) rounds.,4.1. Main results,[0],[0]
"Here, n is the number of advertisers.
",4.1. Main results,[0],[0]
"Further, we provide a primal-dual interpretation of the proportional allocation algorithm to show that PropAlloc + (refer to Algorithm 2) can achieve any desired tradeoff between weight of the matching and entropy of the matching.
",4.1. Main results,[0],[0]
Theorem 2.,4.1. Main results,[0],[0]
"For any δ ∈ (0, 1], λ > 0, there exists an > 0 such that algorithm PropAlloc + with parameter returns a fractional matching that achieves (1 − δ)approximation for the weight-entropy objective in (3), after R = O",4.1. Main results,[0],[0]
"( rmax rmin (1+λ log N̄))2 λδ ) rounds.
",4.1. Main results,[0],[0]
"Here, rmax = max(i,a)∈E ri,a, rmin = min(i,a)∈E ri,a, N̄ = maxa∈A
|Na| Ca .
",4.1. Main results,[0],[0]
Remark 1.,4.1. Main results,[0],[0]
Any feasible fractional allocation can be adapted as a randomized allocation algorithm since the sum of edge weights per impression does not exceed 1 and they can be interpreted as allocation probabilities.,4.1. Main results,[0],[0]
"In expectation, this gives a feasible integral allocation.",4.1. Main results,[0],[0]
"Further, using concentration bounds (e.g., Lemma 13 of (Bansal & Sviridenko, 2006)), with high probability, the capacity constraints will not be violated by more than a factor of Õ(1 + 1√Ca
) for any advertiser a. Therefore, if advertisers have large enough capacities, the fractional matching can be rounded to an integral solution with negligible loss.
4.2.",4.1. Main results,[0],[0]
"A combinatorial analysis of PropAlloc (Proof of Theorem 1)
",4.1. Main results,[0],[0]
We focus on the β variables when the algorithm terminates (after the end of round R).,4.1. Main results,[0],[0]
The minimum value the priority variables can take after R rounds is βmin,4.1. Main results,[0],[0]
"= 1 (1+ )R
, and any a ∈ A can take one of the following 2R + 1 potential priority values:
βa ∈ {βmin, (1 + )βmin, · · · , (1 + )2Rβmin}
For each 0 ≤ k ≤ 2R, let Lk be the set of advertisers with priority value (1 + )",4.1. Main results,[0],[0]
"kβmin, i.e.",4.1. Main results,[0],[0]
Lk := {a|βa = (1 + )kβmin}.,4.1. Main results,[0],[0]
"Since these sets form a hierarchy of priority
2It suffices to set = δ/5.
values, we call them level sets.",4.1. Main results,[0],[0]
We note that some of these sets may be empty.,4.1. Main results,[0],[0]
"There are two main sources of possible suboptimality in the fractional matching that PropAlloc finds:
• Over-allocation: If Alloca is greater than Ca, Alloca− Ca matched impressions will not be counted towards the objective.",4.1. Main results,[0],[0]
•,4.1. Main results,[0],[0]
"Under-allocation: If Alloca is less than Ca, an extra capacity of Ca − Alloca is left to be exploited for advertiser a.
In the following, we show that for advertisers in most of the level sets, both of the above over-allocation and underallocation losses are negligible.
",4.1. Main results,[0],[0]
Lemma 1.,4.1. Main results,[0],[0]
For any a ∈ ∪2R−1k=0,4.1. Main results,[0],[0]
"Lk, the under-allocation Ca−Alloca is at most 3 Ca.",4.1. Main results,[0],[0]
"Similarly for any a ∈ ∪2Rk=1Lk, the over-allocation Alloca − Ca is at most 3 Ca.
",4.1. Main results,[0],[0]
Proof.,4.1. Main results,[0],[0]
"Due to the symmetry of the two claims, we only prove the former.",4.1. Main results,[0],[0]
"Since a is not in level set L2R, there was a time that we did not increase βa.",4.1. Main results,[0],[0]
Let t be the last round that βa was not increased.,4.1. Main results,[0],[0]
"At this point, Alloca Ca was at least 1 (1+ ) .",4.1. Main results,[0],[0]
"For t = R, this completes the proof.",4.1. Main results,[0],[0]
"Otherwise, we focus on round t+ 1 ≤ R. Recall, Alloca = ∑ i∈Na βa∑ a′∈Ni βa′ .
",4.1. Main results,[0],[0]
"If βa is unchanged at round t, the numerator of each term also remains unchanged.",4.1. Main results,[0],[0]
The denominator terms are increased at most by a factor of (1 + ).,4.1. Main results,[0],[0]
"So in total, Alloca is not decreased by more than a factor of (1 + ) yielding the lower bound AllocaCa ≥ 1 (1+ )2 at round t+ 1.",4.1. Main results,[0],[0]
"In the other case, βa is decreased at round t, so the numerator of each term is also reduced by a factor of (1 + ).",4.1. Main results,[0],[0]
"In total, the ratio Alloca
Ca is decreased by a factor of at most 1 (1+ )2 at round t + 1.",4.1. Main results,[0],[0]
"Note that the reduction of βa at round t means the ratio AllocaCa was at least 1 + , and therefore at least 1 1+ at round t+ 1.",4.1. Main results,[0],[0]
"So independent of whether βa was reduced or not, AllocaCa will be at least 1 (1+ )2 at round t+ 1.
",4.1. Main results,[0],[0]
"By definition of t, βa is increased in all rounds after t. With a similar argument, we know that AllocaCa does not decrease at any of these rounds.",4.1. Main results,[0],[0]
"So the ratio AllocaCa remains at least
1 (1+ )2 ≥ 1 + 3 for ≤ 1 till the last round.
",4.1. Main results,[0],[0]
"Lemma 1 shows that every advertiser is either changed in one direction (reducing or increasing β) in all rounds, or its fractional allocation will be almost equal to its capacity.",4.1. Main results,[0],[0]
"The latter helps us prove optimality, and the former only contains advertisers in level sets L0 and L2R. Next, we prove two main claims: on lower bounding the weight of the fractional matching, MatchWeight = ∑ a∈A min{Alloca,Ca}, and on upper bounding the optimum value in terms of the level sets.",4.1. Main results,[0],[0]
"These are stated as Claim 1.
",4.1. Main results,[0],[0]
Claim 1.,4.1. Main results,[0],[0]
For any two indices 1 ≤ ` and `+ log(n/ )/ ≤,4.1. Main results,[0],[0]
"`′ ≤ 2R, we have:
• MatchWeight, is at least:
(1− 4 ) (∑`
k=0 ∑",4.1. Main results,[0],[0]
a∈Lk Ca + |N(∪,4.1. Main results,[0],[0]
"2R k′=`′+1Lk′)| ) (5)
where N(S) for any subset S of advertisers is the union of their neighborhoods ∪a∈SNa.",4.1. Main results,[0],[0]
"• The weight of the optimum fractional matching does not exceed:(∑`′
k=0 ∑",4.1. Main results,[0],[0]
a∈Lk Ca + |N(∪,4.1. Main results,[0],[0]
"2R k′=`′+1Lk′)| ) (6)
Proof.",4.1. Main results,[0],[0]
The proof of the second statement is very similar to folklore graph theoretic results like Konig’s Theorem (Ahmadi & Hall).,4.1. Main results,[0],[0]
"The number of matched impressions in the optimum allocation consists of two main classes: those matched to advertisers in ∪`′k=0Lk, and those assigned to advertisers in ∪2Rk=`′+1Lk.",4.1. Main results,[0],[0]
The former cannot be more than the sum of capacities of the associated advertisers which is the first term in the upper bound.,4.1. Main results,[0],[0]
"The latter is a subset of all neighbors of advertisers in ∪2Rk=`′+1Lk and therefore at most |N(∪2Rk′=`′+1Lk′)|.
",4.1. Main results,[0],[0]
"To prove the first statement of the Claim, we categorize assigned impressions in MatchWeight into two categories.",4.1. Main results,[0],[0]
"Using Lemma 1, the impressions assigned to advertisers in L0, L1, · · · , L` almost fill up their capacities and therefore sum up to at least (1−3 ) ∑` k=0 ∑ a∈Lk Ca which is larger than the first term of the lower bound.
",4.1. Main results,[0],[0]
"The second term represents all neighbors of advertisers in L`′+1, · · · , L2R. To avoid double counting, we show that any impression that has a neighbor in ∪2Rk′=`′+1Lk′ will not be assigned to any advertiser in ∪`k=0Lk w.h.p.",4.1. Main results,[0],[0]
"(≥ 1− ).
Consider impression i that is a neighbor of a′ ∈ Lk′ for some k′ ≥",4.1. Main results,[0],[0]
`′,4.1. Main results,[0],[0]
+ 1.,4.1. Main results,[0],[0]
"Because `′ is at least `+ log(n/ )/ , we have βa′ ≥ n βa for any a ∈",4.1. Main results,[0],[0]
Lk with k ≤,4.1. Main results,[0],[0]
`.,4.1. Main results,[0],[0]
Therefore the probability of i being assigned to a is at most /n times the probability it being assigned to a′.,4.1. Main results,[0],[0]
"Since there could be potentially at most n candidates like a, the probability of i being assigned to any advertiser in ∪`k=0Lk is at most .",4.1. Main results,[0],[0]
So every impression in N(∪2Rk=`′+1Lk) will be assigned to some advertiser in∪2Rk=`+1Lk with probability at least 1− .,4.1. Main results,[0],[0]
"Using Lemma 1, at least 1− 3 fraction of every such impression will be counted towards MatchWeight.",4.1. Main results,[0],[0]
"So in total, we get at least 1−4 for each impression in N(∪2Rk′=`′+1Lk′) which concludes the proof of the Claim.
",4.1. Main results,[0],[0]
Proof of Theorem 1.,4.1. Main results,[0],[0]
"Given Claim 1, there are two main gaps between the lower bound of (5) and the upper bound of (6): the 1 − 4 factor and the sum ∑`′ k=`+1 ∑ a∈Lk Ca.",4.1. Main results,[0],[0]
We show that the latter gap is small for some value of ` and `′ =,4.1. Main results,[0],[0]
"`+ log(n/ )/ .
",4.1. Main results,[0],[0]
Summing this gap over different values of ` yields∑2R−log(n/ )/ `=0 ∑`+log(n/ )/ k=`+1 ∑ a∈Lk,4.1. Main results,[0],[0]
"Ca
≤ (log(n/ )/ ) ∑2R k=1",4.1. Main results,[0],[0]
"∑ a∈Lk Ca
Therefore there exists an 0 ≤ `",4.1. Main results,[0],[0]
≤ 2R − log(n/ )/ such that its associated gap ∑`+log(n/ )/ k=`+1 ∑,4.1. Main results,[0],[0]
"a∈Lk Ca is at most
log(n/ )/",4.1. Main results,[0],[0]
2R−log(n/ )/,4.1. Main results,[0],[0]
+1 ∑2R k=1 ∑ a∈Lk Ca ≤ ∑2R k=1 ∑ a∈Lk,4.1. Main results,[0],[0]
"Ca where the last inequality holds when R is at least log(n/ )/ 2.
",4.1. Main results,[0],[0]
"Using Lemma 1, for every a ∈ ∪2Rk=1Lk, the over-allocation Alloca − Ca is at most 3 Ca.",4.1. Main results,[0],[0]
Therefore MatchWeight is at least (1 − 3 ) ∑2R k=1 ∑ a∈Lk Ca.,4.1. Main results,[0],[0]
This means the gap associated for some ` is at most MatchWeight/(1 − 3 ).,4.1. Main results,[0],[0]
"Using Claim 1, we have MatchWeight ≥ (1− 4 )(OPT − MatchWeight/(1 − 3 )) yielding a final approximation factor of at least 1 − 5 .",4.1. Main results,[0],[0]
"Then, the theorem statement can be obtained by setting δ = /5, R = log(n/ )/ 2 = O(log(n/δ)/δ2).",4.1. Main results,[0],[0]
"Consider the matching problem with weights {ri,a}(i,a)∈E. Given any λ > 0, let OPTλ denote the optimal value of the following convex optimization problem that maximizes a combination of weight of matching and entropy:
maximize ∑ (i,a)∈E ri,axi,a+ λ ∑ i,a xi,a log(1/xi,a)
subject to ∑ a∈Ni xi,a ≤ 1, i ∈ I∑",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"i∈Na xi,a ≤",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Ca, a ∈ A
xi,a ≥ 0 ∀(i, a) ∈ E (7)
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"We show that in R = rmaxrmin (1+λ log(N̄))2 δλ iterations, where N̄ = maxa |Na|",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Ca , the proportional allocation algorithm with
≤ rmin rmax
1
8(2 + λ log(N̄))",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"δ,
finds an assignment {xi,a}i,a satisfying: OPTλ ≤ (1 + δ) ∑",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"i,a ri,axi,a + λ ∑ i,a xi,a log(1/xi,a)
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
Following upper bound on OPTλ can be obtained using Lagrangian duality for the convex program (7).,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"This also provides a dual-based interpretation of the decision xi,a with priority scores {βa} emerging as an exponential function of the corresponding dual variables for the advertisers’ capacity constraints.
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
Lemma 2.,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Given any {γa ≥ 0}a, let
x∗i,a =  e −γa λ",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Di,a,λ∑ a′∈Ni e −γ a′ λ Di,a′,λ , ∑ a′∈Ni e −γ a′ λ Di,a′,λ ≥ 1
e −γa λ Di,a,λ otherwise.
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"(8)
(recallDi,a,λ = e ri,a λ −1).",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Then,
OPTλ ≤ ∑
(i,a)∈E
ri,ax∗i,a − λx∗i,a log(x∗i,a)
+ ∑ a∈A γa(Ca − ∑ i∈Na x∗i,a) (9)
Proof.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Using Lagrangian duality for (7)
OPTλ = min γ≥0,z≥0 max x≥0 L(x, γ, z)
where
L(x, γ, z) :=  ∑i,a ri,axi,a − λxi,a log(xi,a)+∑i zi(1−∑a∈Ni xi,a) + ∑ a γa(Ca − ∑ i∈Na xi,a)  Also, for any {γa ≥ 0, zi ≥ 0}
OPTλ ≤ maxx≥0 L(x, γ, z)
Now, ∂
∂xi,a L(x, γ, z) = ri,a − λ− λ log(xi,a)− zi",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"− γa
so for any zi ≥ 0, γa ≥ 0,
x∗i,a = e −γa/λ−zi/λe
ri,a λ −1
satisfies x∗i,a ≥ 0, ∂∂xi,aL(x, γ, z) = 0, and therefore it is a maximizer of L(x, γ, z), and from above we have OPTλ ≤",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"L(x∗, γ, z).",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Now, set zi as follows: IF∑",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"a∈Ni e −γa/λDi,a,λ ≥ 1, set e zi λ = ∑ a∈Ni e −γa λ",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Di,a,λ where Di,a,λ = e ri,a λ −1.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Otherwise, set zi = 0.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Then, substituting zi, x∗i,a is as given in (8).",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Further, for all i, zi( ∑ a∈Ni x ∗",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"i,a − 1) = 0, substituting which we get
L(x∗, γ, z) = ∑ i,a rax∗i,a − λx∗i,a log(x∗i,a)
+ ∑ a γa(Ca − ∑ i∈Na x∗i,a)
and therefore, using OPTλ ≤",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"L(x∗, γ, z)",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"we obtain the upper bound in (9).
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
Corollary 1.,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Let {xRi,a}(i,a)∈E be the assignments and {βRa }a∈A be the priority scores at the end of R iterations of Algorithm 2, then
OPTλ ≤ ∑
(i,a)∈E
ri,axRi,a − λxRi,a log(xRi,a)
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
− ∑ a∈A λ log(βRa ),4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"(Ca − ∑ i∈Na xRi,a) (10)
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
Proof.,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"We can observe this using Lemma 2, by substituting γa = λ log(1/β R a ).",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Since initial value of βa is (1 + )
−R, and there is a increase of at most (1 + )R factor, we have that βa ≤ 1, so that γa = λ log(1/β R",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
a,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
),4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
≥ λ log(1) = 0.,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Therefore, it is a valid assignment of γa.
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
Primal-dual interpretation of PropAlloc,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
+ .,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"From the above discussion, observe that there is a one-to-one mapping between the priority scores βa and dual variables γa.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
On setting βa = e −γa,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
λ,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
",",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"we obtained that the assignments made by our algorithm are same as complimentary solution {x∗i,a} given by (8).",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
This provides a primal dual interpretation of the proportional allocation algorithm.,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"The proportional allocation algorithm is essentially updating the dual variables based on the feasibility (over-allocation/under-allocation) of the primal complimentary solution.
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Now, using observations similar to those made in Lemma 1 in the previous section, it is easy to see that algorithm PropAlloc + satisfies the following property.
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
Lemma 3.,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"For any a ∈ A, unless βa was increased in all iterations or decreased in all iterations, at the end of R iterations of Algorithm 2, Alloca := ∑ i∈Na xi,a ∈",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"[(1 +
)−2Ca, (1 + )2Ca].
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
We are now ready to prove Theorem 2.,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Here we provide an outline, with detailed proof in the supplementary material.
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
Proof of Theorem 2 (Sketch).,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Without loss of generality, let’s assume that rmax is 1.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"This can be obtained by dividing all ri,a by rmin. rmin in the processed instance is then in fact the ratio of rmin and rmax of the original instance.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Let xRi,a and β R a denote the value of assignments and priority scores at the end of R iterations of Algorithm 2 (before the processing in the last step was done to handle over-allocated advertisers).",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"And, let xMi,a denote the feasible assignments obtained after the processing in the last step of the algorithm.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Let weight(M) := ∑ i,a∈E ri,ax M i,a denote the weight of this feasible fractional matching M .
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Initially, βa = (1 + ) −R.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"From Lemma 3, for every a, either ∑ i∈Na x R i,a ∈",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"[(1 + )−2Ca, (1 + )2Ca], i.e., the advertiser budget constraint is approximately satisfied; or, we will have that βa was continuously increased/decreased by (1+ ) factor for allR iterations, so that βRa is either 1 or (1 + )",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
−2R.,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
Let us call the first set of advertisers where the budget constraint is approximately satisfied as E .,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"For these advertisers, |Ca− ∑ i∈Na xi,a| ≤ 3",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
Ca for any ≤ 1.,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Also, βRa ≥ (1 + )−2R.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Among the second set, let O be the set of advertisers a ∈ A with βRa = (1 + )−2R.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Here, βa was continuously decreased in order to decrease the allocation, and these advertisers will be over-allocated in the end.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"For the remaining a /∈ E , a /∈",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"O, we have βRa = 1.
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Using the upper bound from (10), and substituting the value of βRa ,
OPTλ ≤ ∑",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"i,a ri,axRi,a + ∑ a∈O 2R λ(Ca",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"− ∑ i∈Na xRi,a)
+ ∑ a∈E 2R λ(3 Ca)−",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
λ ∑,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"i,a xRi,a log(x R i,a)
The terms for a /∈",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"O, a /∈ E do not appear in above because log(1/βRa ) = log(1) = 0 for those a. Next, we relate the above upper bound to the weight and entropy of the feasible fractional matching M .",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"First, we substitute R as:
R = 12 λ ( 1 + λ log(N̄) ) , (11)
(where N̄ = maxa Ca|Na| ) to decompose the above upper bound on OPTλ as:
OPTλ ≤ ∑",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"i,a ri,axRi,a + ∑ a∈O (Ca − ∑ i∈Na xRi,a) (12)
+λ log(N̄) ∑ a∈O (Ca − ∑ i∈Na xRi,a)− λ ∑ i,a xRi,",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"a log x R i,a(13)
+ ∑ a∈E 3 ( 1 + λ log(N̄) )",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Ca (14)
Now, matching M was created by removing ∑ i∈Na x R i,a − Ca edges from {xRi,a} for every over-allocated advertiser a ∈ O. Therefore, the second term in (12) accounts for the weight (since rmax = 1) of all edges removed, except for those in a ∈ E .",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
Since a ∈ E can be over-allocated by at most 3,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Ca, we can show that for small , almost all the decrease in the weight is accounted for, and (12) is close to weight(M):
(12) ≤",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"(1 + δ2 )weight(M), when
= rmin
8(2 + λ log(N̄))",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"δ, (15)
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Similarly, we show that the first term in (13) accounts for any increase in entropy due to removal of edges from xRi,a, so that
(13) ≤ λEntropy(xMi,a) := λ ∑ i,a x R i,a log(1/xRi,a)
Here, we utilize the fact that in Algorithm 2 does not decrease very small assignments: it only decreases assignment of edges while xRi,a ≥ Ca/|Na|.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Finally, for small , the last part (14) is negligible compared to weight(M).",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Specifically, for the choice of in (15),
(14) ≤ δ2 weight(M).
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Combining these observations,
OPTλ ≤ (1 + δ)weight(M) + λEntropy(M)
",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Finally, from (11), substituting value of from (15), we have the number of iterations
R = 1
2 λ
( 1 + λ log(N̄) )",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"≤ 8
rmin (1 + λ",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
log(N̄))2,4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"λδ
Then, the theorem statement is obtained on substituting back rmin/rmax for rmin.",4.3. Primal-dual interpretation: Proof of Theorem 2,[0],[0]
"Inspired by many applications of bipartite matching in online advertising and machine learning, we study a simple and natural iterative proportional allocation algorithm:",abstractText,[0],[0]
Maintain a priority score βa for each node a ∈,abstractText,[0],[0]
"A on one side of the bipartition, initialized as βa = 1.",abstractText,[0],[0]
Iteratively allocate the nodes i ∈,abstractText,[0],[0]
I on the other side to eligible nodes in A in proportion of their priority scores.,abstractText,[0],[0]
"After each round, for each node a ∈ A, decrease or increase the score βa based on whether it is overor underallocated.",abstractText,[0],[0]
"Our first result is that this simple, distributed algorithm converges to a (1 − )-approximate fractional b-matching solution in O( logn 2 ) rounds.",abstractText,[0],[0]
"We also extend the proportional allocation algorithm and convergence results to the maximum weighted matching problem, and show that the algorithm can be naturally tuned to produce maximum matching with high entropy.",abstractText,[0],[0]
"High entropy, in turn, implies additional desirable properties of this matching, e.g., it satisfies certain diversity and fairness (aka anonymity) properties that are desirable in a variety of applications in online advertising and machine learning.",abstractText,[0],[0]
"Proportional Allocation:  Simple, Distributed, and Diverse Matching with High Entropy ",title,[0],[0]
"Real-time and accurate prediction on resource-constrained devices is critical for several Machine Learning (ML) do-
1Microsoft Research, India 2Carnegie Mellon University, Pittsburgh 3University of Michigan, Ann Arbor 4IIT Delhi, India.",1. Introduction,[0],[0]
"Correspondence to: Arun Sai Suggala <asuggala@andrew.cmu.edu>, Prateek Jain <prajain@microsoft.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
mains.",1. Introduction,[0],[0]
Internet-of-things (IoT) is one such rapidly growing domain.,1. Introduction,[0],[0]
"IoT devices have the potential to provide realtime, local, sensor-based solutions for a variety of areas like housing, factories, farming, even everyday utilities like toothbrushes and spoons.",1. Introduction,[0],[0]
The ability to use machine learning on data collected from IoT sensors opens up a myriad of possibilities.,1. Introduction,[0],[0]
"For example, smart factories measure temperature, noise and various other parameters of their machines.",1. Introduction,[0],[0]
"ML based anomaly detection models can then be applied on this sensor data to preemptively schedule maintenance of a machine and avoid failure.
",1. Introduction,[0],[0]
"However, machine learning in IoT scenarios is so far limited to cloud-based predictions where large deep learning models are deployed to provide accurate predictions.",1. Introduction,[0],[0]
The sensors/embedded devices have limited compute/storage abilities and are tasked only with sensing and transmitting data to the cloud.,1. Introduction,[0],[0]
"Such a solution does not take into account several practical concerns like privacy, bandwidth, latency and battery issues.",1. Introduction,[0],[0]
"For example, consider the energy costs of communication if each IoT device on each machine in a smart factory has to continuously send data and receive predictions from the cloud.
Consider a typical IoT device that has ≤ 32kB RAM and a 16MHz processor.",1. Introduction,[0],[0]
Most existing ML models cannot be deployed on such tiny devices.,1. Introduction,[0],[0]
"Recently, several methods (Han et al., 2016; Nan et al., 2015; Kusner et al., 2014) have been proposed to produce models that are compressed compared to large DNN/kernel-SVM/decision-tree based classifiers.",1. Introduction,[0],[0]
"However, none of these methods work well at the scale of IoT devices.",1. Introduction,[0],[0]
"Moreover, they do not offer natural extensions to supervised learning problems other than the ones they were initially designed for.
",1. Introduction,[0],[0]
"In this paper, we propose a novel kNN based algorithm (ProtoNN) that can be deployed on the tiniest of devices, can handle general supervised learning problems, and can produce state-of-the-art accuracies with just ≈16kB of model size on many benchmark datasets.",1. Introduction,[0],[0]
"A key reason for selecting kNN as the algorithm of choice is due to its generality, ease of implementation on tiny devices, and small number of parameters to avoid overfitting.",1. Introduction,[0],[0]
"However, kNN suffers from three issues which limit its applicability in
practice, especially in the small devices setting: a) Poor accuracy: kNN is an ill-specified algorithm as it is not a priori clear which distance metric one should use to compare a given set of points.",1. Introduction,[0],[0]
"Standard metrics like Euclidean distance, `1 distance etc. are not task-specific and lead to poor accuracies.",1. Introduction,[0],[0]
"b) Model size: kNN requires the entire training data for prediction, so its model size is too large for the IoT setting.",1. Introduction,[0],[0]
c),1. Introduction,[0],[0]
Prediction time: kNN requires computing the distance of a given test point w.r.t.,1. Introduction,[0],[0]
"each training point, making it prohibitive for prediction in real-time.
",1. Introduction,[0],[0]
Several methods have been proposed to address some of these concerns.,1. Introduction,[0],[0]
"For example, metric learning (Weinberger & Saul, 2009) learns a task-specific metric that provides better accuracies but ends up increasing model-size and prediction time.",1. Introduction,[0],[0]
"KD-trees (Bentley, 1975) can decrease the prediction time, but they increase the model size and lead to loss in accuracy.",1. Introduction,[0],[0]
"Finally, recent methods like Stochastic Neighborhood Compression (SNC) (Kusner et al., 2014) can decrease model size and prediction time by learning a small number of prototypes to represent the entire training dataset.",1. Introduction,[0],[0]
"However, as our experiments show, their predictions are relatively inaccurate, especially in the tiny modelsize regime.",1. Introduction,[0],[0]
"Moreover, their formulations limit applicability to binary and multi-class classification problems (see Section 2 for a detailed comparison to SNC).
",1. Introduction,[0],[0]
"In contrast, ProtoNN is able to address the abovementioned concerns by using three key ideas:
a) Sparse low-d projection: we project the entire data in low-d using a sparse projection matrix that is jointly learned to provide good accuracy in the projected space.
",1. Introduction,[0],[0]
b) Prototypes: we learn prototypes to represent the entire training dataset.,1. Introduction,[0],[0]
"Moreover, we learn labels for each prototype to further boost accuracy.",1. Introduction,[0],[0]
"This provides additional flexibility, and allows us to seamlessly generalize ProtoNN for multi-label or ranking problems.
",1. Introduction,[0],[0]
c) Joint optimization: we learn the projection matrix jointly with the prototypes and their labels.,1. Introduction,[0],[0]
"Explicit sparsity constraints are imposed on our parameters during the optimization itself so that we can obtain an optimal model within the given model size de-facto, instead of post-facto pruning to force the model to fit in memory.
",1. Introduction,[0],[0]
"Unfortunately, our optimization problem is non-convex with hard `0 constraints.",1. Introduction,[0],[0]
"Yet, we show that simple stochastic gradient descent (SGD) with iterative hard-thresholding (IHT) works well for optimization.",1. Introduction,[0],[0]
"ProtoNN can be implemented efficiently, can handle datasets with millions of points, and obtains state-of-the-art accuracies.
",1. Introduction,[0],[0]
"We analyze ProtoNN in a simple binary classification setting where the data is sampled from a mixture of two wellseparated Gaussians, each Gaussian representing one class.
",1. Introduction,[0],[0]
"We show that if we fix the projection matrix and prototype labels, the prototypes themselves can be learned optimally in polynomial time with at least a constant probability.",1. Introduction,[0],[0]
"Moreover, assuming a strong initialization condition we observe that our SGD+IHT method when supplied a small number of samples, proportional to the sparsity of means, converges to the global optima.",1. Introduction,[0],[0]
"Although the data model is simple, it nicely captures the main idea behind our problem formulation.",1. Introduction,[0],[0]
"Further, our analysis is the first such analysis for any method in this regime that tries to learn a compressed non-linear model for binary classification.
",1. Introduction,[0],[0]
"Finally, we conduct extensive experiments to benchmark ProtoNN against existing state-of-the-art methods for various learning tasks.",1. Introduction,[0],[0]
"First, we show that on several binary (multi-class) problems, ProtoNN with a 2kB (16kB) memory budget significantly outperforms all the existing methods in this regime.",1. Introduction,[0],[0]
"Moreover, in the binary classification case, we show that ProtoNN",1. Introduction,[0],[0]
"with just ≈ 16kB of model-size, provides nearly the same accuracy as most popular methods like GBDT, RBF-SVM, 1-hidden layer NN, etc, which might require up to 1GB of RAM on the same datasets.",1. Introduction,[0],[0]
"Similarly, on multilabel datasets, ProtoNN can give 100× compression with ≤ 1% loss in accuracy.",1. Introduction,[0],[0]
"Finally, we demonstrate that ProtoNN can be deployed on a tiny Arduino Uno device1 and leads to better accuracies than existing methods while incurring significantly lesser energy and prediction time costs.",1. Introduction,[0],[0]
We have implemented ProtoNN,1. Introduction,[0],[0]
as part of an open source embedded device ML library and it can be downloaded online2.,1. Introduction,[0],[0]
"kNN is a popular ML algorithm owing to its simplicity, generality, and interpretability (Cover & Hart, 2006).",2. Related Works,[0],[0]
"In particular, kNN can learn complex decision boundaries and has only one hyperparameter k.",2. Related Works,[0],[0]
"However, vanilla kNN suffers from several issues as mentioned in the previous section.",2. Related Works,[0],[0]
"A number of methods, which try to address these issues, exist in the literature.",2. Related Works,[0],[0]
"Broadly, these methods can be divided into three sub-categories.
",2. Related Works,[0],[0]
Several existing methods reduce prediction time of kNN using fast nearest neighbor retrieval.,2. Related Works,[0],[0]
For example Bentley (1975); Beygelzimer et al. (2006) use tree data structures and Gionis et al. (1999); Weiss et al. (2008); Kulis & Darrell (2009); Norouzi et al. (2012); Liu et al. (2012) learn binary embeddings for fast nearest neighbor operations.,2. Related Works,[0],[0]
"These methods, although helpful in reducing the prediction time, lead to loss in accuracy and require the entire training data to be in memory leading to large model sizes that cannot be deployed on tiny IoT devices.
",2. Related Works,[0],[0]
"1https://www.arduino.cc/en/Main/ArduinoBoardUno 2https://github.com/Microsoft/ELL
Another class of methods improve accuracy of kNN by learning a better metric to compare, given a pair of points (Goldberger et al., 2004; Davis et al., 2007).",2. Related Works,[0],[0]
"For example, (Weinberger & Saul, 2009) proposed a Large Margin Nearest Neighbor (LMNN) classifier which transforms the input space such that in the transformed space points from same class are closer compared to points from disparate classes.",2. Related Works,[0],[0]
"LMNN’s transformation matrix can map data into lower dimensions and reduce overall model size compared to kNN, but it is still too large for most resource-scarce devices.
",2. Related Works,[0],[0]
"Finally, another class of methods constructs a set of prototypes to represent the entire training data.",2. Related Works,[0],[0]
"In some approaches (Angiulli, 2005; Devi & Murty, 2002), the prototypes are chosen from the original training data, while some other approaches (Mollineda et al., 2002) construct artificial points for prototypes.",2. Related Works,[0],[0]
"Of these approaches, SNC, Deep SNC (DSNC) (Wang et al., 2016), Binary Neighbor Compression (BNC) (Zhong et al., 2017) are the current state-of-the-art.
",2. Related Works,[0],[0]
SNC learns artificial prototypes such that the likelihood of a particular class probability model is maximized.,2. Related Works,[0],[0]
"Thus, SNC applies only to multi-class problems and its extension to multilabel/ranking problems is non-trivial.",2. Related Works,[0],[0]
"In contrast, we have a more direct discriminative formulation that can be applied to arbitrary supervised learning problems.",2. Related Works,[0],[0]
"To decrease the model size, SNC introduces a pre-processing step of low-d projection of the data via LMNN based projection matrix and then learns prototypes in the projected space.",2. Related Works,[0],[0]
"The SNC parameters (projection matrix, prototypes) might have to be hard-thresholded post-facto to fit within the memory budget.",2. Related Works,[0],[0]
"In contrast, ProtoNN’s parameters are de-facto learnt jointly with model size constraints imposed during optimization.",2. Related Works,[0],[0]
"This leads to significant improvements over SNC and other state-of-the-art methods in the small model-size regime; see Figure 1, 3.
DSNC is a non-linear extension of SNC in that it learns a non-linear low-d transformation jointly with the prototypes.",2. Related Works,[0],[0]
"It has similar drawbacks as SNC: a) it only applies to multi-class problems and b) model size of DSNC can be significantly larger than SNC as it uses a feedforward network to learn the non-linear transformation.
",2. Related Works,[0],[0]
"BNC is a binary embedding technique, which jointly learns a binary embedding and a set of artificial binary prototypes.",2. Related Works,[0],[0]
"Although BNC learns binary embeddings, its dimensionality can be significantly higher, so it need not result in significant model compression.",2. Related Works,[0],[0]
"Moreover, the optimization in BNC is difficult because of the discrete optimization space.",2. Related Works,[0],[0]
Given n data points X =,3. Problem Formulation,[0],[0]
"[x1,x2, . . .xn]T",3. Problem Formulation,[0],[0]
and the corresponding target output Y =,3. Problem Formulation,[0],[0]
"[y1,y2 . .",3. Problem Formulation,[0],[0]
".yn]T , where xi ∈
Rd, yi ∈ Y , our goal is to learn a model that accurately predicts the desired output of a given test point.",3. Problem Formulation,[0],[0]
"In addition, we also want our model to have small size.",3. Problem Formulation,[0],[0]
"For both multilabel/multi-class problems with L labels, yi ∈ {0, 1}L but in multi-class ‖yi‖ = 1.",3. Problem Formulation,[0],[0]
"Similarly, for ranking problems, the output yi is a permutation.
",3. Problem Formulation,[0],[0]
"Let’s consider a smooth version of kNN prediction function for the above given general supervised learning problem
ŷ = ρ(ŝ) = ρ ( n∑ i=1 σ(yi)K(x,xi) ) , (1)
where ŷ is the predicted output for a given input x, ŝ =∑n i=1",3. Problem Formulation,[0],[0]
"σ(yi)K(x,xi) is the score vector for x. σ",3. Problem Formulation,[0],[0]
: Y → RL maps a given output into a score vector and ρ : RL → Y maps the score function back to the output space.,3. Problem Formulation,[0],[0]
"For example, in the multi-class classification, σ is the identity function while ρ = Top1, where [Top1(s)]j = 1 if sj is the largest element and 0 otherwise.",3. Problem Formulation,[0],[0]
K :,3. Problem Formulation,[0],[0]
"Rd × Rd → R is the similarity function, i.e., K(xi,xj) computes similarity between xi and xj .",3. Problem Formulation,[0],[0]
"For example, standard kNN uses K(x,xi) = I[xi ∈ Nk(x)] where Nk(x) is the set of k nearest neighbors of x in X .
",3. Problem Formulation,[0],[0]
"Note that kNN requires entire X to be stored in memory for prediction, so its model size and prediction time are prohibitive for resource constrained devices.",3. Problem Formulation,[0],[0]
"So, to bring down model and prediction complexity of kNN, we propose using prototypes that represent the entire training data.",3. Problem Formulation,[0],[0]
"That is, we learn prototypes B =",3. Problem Formulation,[0],[0]
"[b1, . . .",3. Problem Formulation,[0],[0]
",bm] and the corresponding score vectors Z =",3. Problem Formulation,[0],[0]
"[z1, . . .",3. Problem Formulation,[0],[0]
", zm] ∈ RL×m, so that the decision function is given by: ŷ",3. Problem Formulation,[0],[0]
= ρ,3. Problem Formulation,[0],[0]
"(∑m j=1 zjK(x,bj) ) .
",3. Problem Formulation,[0],[0]
"Existing prototype based approaches like SNC, DSNC have a specific probabilistic model for multi-class problems with the prototypes as the model parameters.",3. Problem Formulation,[0],[0]
"In contrast, we take a more direct discriminative learning approach that allows us to obtain better accuracies in several settings along with generalization to any supervised learning problem, e.g., multi-label classification, regression, ranking, etc.
",3. Problem Formulation,[0],[0]
"However, K is a fixed similarity function like RBF kernel which is not tuned for the task at hand and can lead to inaccurate results.",3. Problem Formulation,[0],[0]
We propose to solve this issue by learning a low-dimensional matrix W ∈ Rd̂×d that further brings down model/prediction complexity as well as transforms data into a space where prediction is more accurate.,3. Problem Formulation,[0],[0]
"That is, our proposed algorithm ProtoNN uses the following prediction function that is based on three sets of learned parameters W ∈ Rd̂×d, B =",3. Problem Formulation,[0],[0]
"[b1, . . .",3. Problem Formulation,[0],[0]
",bm] ∈ Rd̂×m, and Z =",3. Problem Formulation,[0],[0]
"[z1, . . .",3. Problem Formulation,[0],[0]
", zm] ∈ RL×m: ŷ = ρ (∑m j=1 zjK(Wx,bj) ) .
",3. Problem Formulation,[0],[0]
"To further reduce the model/prediction complexity, we learn sparse set of Z,B,W .",3. Problem Formulation,[0],[0]
"Selecting the correct simi-
larity function K is crucial to the performance of the algorithm.",3. Problem Formulation,[0],[0]
"In this work we choose K to be the Gaussian kernel: Kγ(x, y) = exp{−γ2‖x − y‖22}, which is a popular choice in many non-parametric methods (including regression, classification, density estimation).
",3. Problem Formulation,[0],[0]
"Note that if m = n, and W = Id×d, then our prediction function reduces to the standard RBF kernel-SVM’s decision function for binary classification.",3. Problem Formulation,[0],[0]
"That is, our function class is universal: we can learn any arbitrary function given enough data and model complexity.",3. Problem Formulation,[0],[0]
"We observe a similar trend in our experiments, where even with reasonably small amount of model complexity, ProotNN nearly matches RBF-SVM’s prediction error.
",3. Problem Formulation,[0],[0]
"Training Objective: We now provide the formal optimization problem to learn parameters Z,B,W .",3. Problem Formulation,[0],[0]
"Let L(ŝ,y) be the loss (or) risk of predicting score vector ŝ for a point with label vector y.",3. Problem Formulation,[0],[0]
"For example, the loss function can be standard hinge-loss for binary classification, or NDCG loss function for ranking problems.
",3. Problem Formulation,[0],[0]
"Now, define the empirical risk associated with Z,B,W as
Remp(Z,B,W ) = 1
n n∑ i=1",3. Problem Formulation,[0],[0]
"L yi, m∑ j=1 zjKγ(bj ,Wxi)  .",3. Problem Formulation,[0],[0]
"In the sequel, to simplify the notation, we denote the risk at ith data point by Li(Z,B,W ) i.e., Li(Z,B,W ) =",3. Problem Formulation,[0],[0]
"L ( yi, ∑m j=1 zjKγ(bj ,Wxi) ) .",3. Problem Formulation,[0],[0]
"To jointly learn Z,B,W , we minimize the empirical risk with explicit sparsity constraints:
min Z:‖Z‖0≤sZ ,B:‖B‖0≤sB ,W :‖W‖0≤sW
Remp(Z,B,W ), (2)
where ‖Z‖0 is equal to the number of non-zero entries in Z. For all our expeirments (multi-class/multi-label), we used the squared `2 loss function as it helps us write down the gradients easily and allows our algorithm to converge faster and in a robust manner.",3. Problem Formulation,[0],[0]
"That is, Remp(Z,B,W ) = 1 n",3. Problem Formulation,[0],[0]
∑n i=1 ‖yi,3. Problem Formulation,[0],[0]
"− ∑m j=1 zjKγ(bj ,Wxi)‖22.",3. Problem Formulation,[0],[0]
Note that the sparsity constraints in the above objective gives us explicit control over the model size.,3. Problem Formulation,[0],[0]
"Furthermore, as we show in our experiments, jointly optimizing all the three parameters, Z,B,W , leads to better accuracies than optimizing only a subset of parameters.",3. Problem Formulation,[0],[0]
We now present our algorithm for optimization of (2).,4. Algorithm,[0],[0]
Note that the objective in (2) is non-convex and is difficult to optimize.,4. Algorithm,[0],[0]
"However, we present a simple alternating minimization technique for its optimization.",4. Algorithm,[0],[0]
"In this technique, we alternately minimizeZ,B,W while fixing the other two parameters.",4. Algorithm,[0],[0]
"Note that the resulting optimization problem
Algorithm 1 ProtoNN: Train Algorithm Input: data (X,Y ), sparsities (sZ , sB , sW ), kernel parameter γ, projection dimension d̂, no. of prototypes m, iterations T , SGD epochs e. Initialize Z,B,W for t",4. Algorithm,[0],[0]
"= 1 to T do {alternating minimization}
repeat {minimization of Z} randomly sample S ⊆",4. Algorithm,[0],[0]
"[1, . .",4. Algorithm,[0],[0]
.,4. Algorithm,[0],[0]
n,4. Algorithm,[0],[0]
],4. Algorithm,[0],[0]
"Z ← HTsZ ( Z − ηr ∑ i∈S ∇ZLi(Z,B,W ) )",4. Algorithm,[0],[0]
"until e epochs repeat {minimization of B}
randomly sample S ⊆ [1, . . .",4. Algorithm,[0],[0]
n,4. Algorithm,[0],[0]
],4. Algorithm,[0],[0]
B ← HTsB,4. Algorithm,[0],[0]
"( B − ηr ∑ i∈S ∇BLi(Z,B,W ) )",4. Algorithm,[0],[0]
"until e epochs repeat {minimization of W}
randomly sample S ⊆ [1, . . .",4. Algorithm,[0],[0]
n,4. Algorithm,[0],[0]
],4. Algorithm,[0],[0]
"W ← HTsW ( W − ηr ∑ i∈S ∇WLi(Z,B,W ) )",4. Algorithm,[0],[0]
"until e epochs
end for Output: Z,B,W
in each of the alternating steps is still non-convex.",4. Algorithm,[0],[0]
"To optimize these sub-problems we use projected Stochastic Gradient Descent (SGD) for large datasets and projected Gradient Descent (GD) for small datasets.
",4. Algorithm,[0],[0]
"Suppose we want to minimize the objective w.r.t Z by fixing B,W .",4. Algorithm,[0],[0]
Then in each iteration of SGD we randomly sample a mini-batch S ⊆,4. Algorithm,[0],[0]
"[1, . .",4. Algorithm,[0],[0]
.,4. Algorithm,[0],[0]
n],4. Algorithm,[0],[0]
"and update Z as: Z ← HTsZ ( Z − η ∑ i∈S ∇ZLi(Z,B,W ) ) , where HTsZ (A) is the hard thresholding operator that thresholds the smallest L ×m − sZ entries (in magnitude) of A and ∇ZLi(Z,B,W ) denotes the partial derivative of Li w.r.t Z. Note that GD procedure is just SGD with batch size |S| =",4. Algorithm,[0],[0]
n. Algorithm,4. Algorithm,[0],[0]
"1 presents pseudo-code for our entire training procedure.
",4. Algorithm,[0],[0]
"Step-size: Setting correct step-size is critical to convergence of SGD methods, especially for non-convex optimization problems.",4. Algorithm,[0],[0]
"For our algorithm, we select the initial step size using Armijo rule.",4. Algorithm,[0],[0]
"Subsequent step sizes are selected as ηt = η0/t where η0 is the initial step-size.
",4. Algorithm,[0],[0]
"Initialization: Since our objective function (2) is nonconvex, good initialization for Z,B,W is critical in converging efficiently to a good local optima.",4. Algorithm,[0],[0]
We used a randomly sampled Gaussian matrix to initialize W for binary and small multi-class benchmarks.,4. Algorithm,[0],[0]
"However, for large multi class datasets (aloi) we use LMNN based initialization of W. Similarly, for multi-label datasets we use SLEEC (Bhatia et al., 2015) for initialization of W ; SLEEC is an embedding technique for large multi-label problems.
",4. Algorithm,[0],[0]
"For initialization of prototypes, we experimented with two different approaches.",4. Algorithm,[0],[0]
"In one, we randomly sample training
data points in the transformed space and assign them as the prototypes; this is a useful technique for multilabel problems.",4. Algorithm,[0],[0]
"In the other approach, we run k-means clustering in the transformed space on data points belonging to each class and pick the cluster centers as our prototypes.",4. Algorithm,[0],[0]
"We use this approach for binary and multi-class problems.
",4. Algorithm,[0],[0]
Convergence:,4. Algorithm,[0],[0]
"Although Algorithm 1 optimizes an `0 constrained optimization problem, we can still show that it converges to a local minimum due to smoothness of objective function (Blumensath & Davies, 2008).",4. Algorithm,[0],[0]
"Moreover, if the objective function satisfies strong convexity in a small ball around optima, then appropriate initialization leads to convergence to that optima (Jain et al., 2014).",4. Algorithm,[0],[0]
"In fact, our next section presents such a strong convexity result (wrtB) if the data is generated from a mixture of well-separated Gaussians.",4. Algorithm,[0],[0]
"Finally, our empirical results (Section 6) indicate that the objective function indeed converges at a fast rate to a good local optimum leading to accurate models.",4. Algorithm,[0],[0]
"In this section, we present an analysis of our approach for when data is generated from the following generative model: let each point xi be sampled from a mixture of two Gaussians, i.e., xi
i.i.d∼ 0.5·N",5. Analysis,[0],[0]
"(µ+, I)+0.5·N (µ−, I) ∈ Rd and the corresponding label yi be the indicator of the Gaussian from which xi is sampled.",5. Analysis,[0],[0]
"Now, it is easy to see that if the Gaussians are well-separated then one can design 2 prototypes b+∗, b−∗ such that the error of our method with W = I and fixed Z =",5. Analysis,[0],[0]
"[e1, e2] will lead to nearly Bayes’ optimal classifier; ei is the i-th canonical basis vector.
",5. Analysis,[0],[0]
The goal of this section is to show that our method that optimizes the squared `2 loss objective (2) w.r.t.,5. Analysis,[0],[0]
"prototypes B, converges at a linear rate to a solution that is in a small ball around the global optima, and hence leads to nearly optimal classification accuracy.
",5. Analysis,[0],[0]
We would like to stress that the goal of our analysis is to justify our proposed approach in a simple and easy to study setting.,5. Analysis,[0],[0]
We do not claim new bounds for the mixture of Gaussians problem; it is a well-studied problem with several solid solutions.,5. Analysis,[0],[0]
"Our goal is to show that our method in this simple setting indeed converges to a nearly optimal solution at linear rate, thus providing some intuition for its success in practice.",5. Analysis,[0],[0]
"Also, our current analysis only studies optimization w.r.t.",5. Analysis,[0],[0]
the prototypes B while fixing projection matrix W and prototype label vectors Z.,5. Analysis,[0],[0]
Studying the problem w.r.t.,5. Analysis,[0],[0]
"all the three parameters is significantly more challenging, and is beyond the scope of this paper.
",5. Analysis,[0],[0]
"Despite the simplicity of our model, ours is one of the first rigorous studies of a classification method that is designed for resource constrained problems.",5. Analysis,[0],[0]
"Typically, the proposed methods in this regime are only validated using empirical
results as theoretical study is quite challenging owing to the obtained non-convex optimization surface and complicated modeling assumptions.
",5. Analysis,[0],[0]
"For our first result, we ignore sparsity ofB, i.e., sB = 2 ·d. We consider the RBF-kernel for K with γ2 = 12 .",5. Analysis,[0],[0]
Theorem 1.,5. Analysis,[0],[0]
Let X =,5. Analysis,[0],[0]
"[x1, . . .",5. Analysis,[0],[0]
",xn] and Y =",5. Analysis,[0],[0]
"[y1, . . .",5. Analysis,[0],[0]
",yn] be generated from the above mentioned generative model.",5. Analysis,[0],[0]
SetW =,5. Analysis,[0],[0]
"I , Z =",5. Analysis,[0],[0]
"[e1, e2] and let b+,b− be the prototypes.",5. Analysis,[0],[0]
"Let n → ∞, µ̄ := µ+ − µ−. Also, let ∆+ := b+ − µ+, ∆− := b+ − µ−, and let ∆+T",5. Analysis,[0],[0]
µ̄ ≥,5. Analysis,[0],[0]
"− (1−δ)2 ‖µ̄‖
2 for some fixed constant δ > 0, and d ≥ 8(α",5. Analysis,[0],[0]
− δ)‖µ̄‖2 for some constant α > 0.,5. Analysis,[0],[0]
"Then, the following holds for the gradient descent step b+
′ =",5. Analysis,[0],[0]
"b+ − η∇b+R where R = E[Remp], and η ≥ 0 is appropriately chosen:
‖b+′−µ+‖2 ≤ ‖b+−µ+‖2",5. Analysis,[0],[0]
"( 1− 0.01 exp { −α‖µ̄‖ 2
4
}) ,
if ‖∆+‖ ≥ 8‖µ̄‖ exp { −α‖µ̄‖ 2
4
} .
",5. Analysis,[0],[0]
See Appendix 8 for a detailed proof of this as well as the below given theorem.,5. Analysis,[0],[0]
"The above theorem shows that if the Gaussians are well-separated and the starting b+ is closer to µ+ than µ−, then the gradient descent step decreases the distance between b+ and µ+ geometrically until b+ converges to a small ball around µ+, the radius of the ball is exponentially small in ‖µ+−µ−‖. Note that our initialization method indeed satisfies the above mentioned assumption with at least a constant probability.
",5. Analysis,[0],[0]
"It is easy to see that in this setting, the loss function decomposes over independent terms from b+ and b−, and hence an identical result can be obtained for b−. For simplicity, we present the result for n → ∞ (hence, expected value).",5. Analysis,[0],[0]
Extension to finite samples should be fairly straightforward using standard tail bounds.,5. Analysis,[0],[0]
"The tail bounds will also lead to a similar result for SGD but with an added variance term.
",5. Analysis,[0],[0]
"Next, we show that if the b+ is even closer to µ+, then the objective function becomes strongly convex in b+,b−. Theorem 2.",5. Analysis,[0],[0]
"Let X,Y, µ̄,∆+,∆− be as given in Theorem 1.",5. Analysis,[0],[0]
"Also, let ∆+T",5. Analysis,[0],[0]
µ̄ ≥,5. Analysis,[0],[0]
"− (1−δ)2 ‖µ̄‖
2, for some small constant δ > 0, ‖µ̄‖2 ≥ 4(ln 0.1)δ , and ‖∆+‖
2 ≤ 0.5.",5. Analysis,[0],[0]
"Then, R with W = I and Z =",5. Analysis,[0],[0]
"[e1, e2] is a strongly convex function of B with condition number bounded by 20.
",5. Analysis,[0],[0]
"Note that the initialization assumptions are much more strict here, but strong convexity with bounded condition number provides significantly faster convergence to optima.",5. Analysis,[0],[0]
"Moreover, this theorem also justifies our IHT based method.",5. Analysis,[0],[0]
"Using standard tail bounds, it is easy to show that if n grows linearly with sB rather than d, the condition number bound still holds over sparse set of vectors, i.e., for sparse µ+, µ− and sparse b+,b−. Using this restricted strong convexity with (Jain et al., 2014) guarantees
that with just O(sB log d) samples, our method will converge to a small ball around sparse µ+ in polynomial time.",5. Analysis,[0],[0]
We skip these standard details as they are orthogonal to the main point of this analysis section.,5. Analysis,[0],[0]
"In this section we present the performance of ProtoNN on various benchmark binary, multiclass and multilabel datasets with a goal to demonstrate the following aspects:
a)",6. Experiments,[0],[0]
"In severely resource constrained settings where we require model sizes to be less than 2kB (which occur routinely for IoT devices like Arduino Uno), we outperform all state-of-the art compressed methods.",6. Experiments,[0],[0]
b),6. Experiments,[0],[0]
"For model sizes in the range 16 − 32 kB, we achieve comparable accuracies to the best uncompressed methods.",6. Experiments,[0],[0]
c),6. Experiments,[0],[0]
"In multiclass and multilabel problems we achieve near state-of-the-art accuracies with an order of magnitude reduction in model size, thus showing our approach is flexible and general enough to handle a wide variety of problems.
",6. Experiments,[0],[0]
"Experimental Settings: Datasets: Table 3 in Appendix 9.1 lists the binary, multiclass and multilabel datasets used in our experiments.",6. Experiments,[0],[0]
"For binary and multiclass datasets, we standardize each feature in the data to zero-mean and unit-variance.",6. Experiments,[0],[0]
"For multilabel datasets, we normalize the feature vector of each data point by projecting it onto a unit norm ball which preserves data sparsity.",6. Experiments,[0],[0]
Hyperparameters:,6. Experiments,[0],[0]
"In all our experiments, we fix the no. of alternating minimization iterations(T) to 150.",6. Experiments,[0],[0]
"Each such iteration does e-many epochs each over the 3 parameters, W , B, and Z. For small binary and multiclass datasets we do GD with e set to 20.",6. Experiments,[0],[0]
"For multilabel and large multiclass (aloi) datasets, we do SGD with e set to 5, batch size to 512.",6. Experiments,[0],[0]
"Kernel parameter γ is computed after initializing B,W as 2.5median(D) , where D is the set of distances between prototypes and training points in the transformed space and
is defined as D = {‖bj −Wxi‖2}i∈[n],j∈[m].
",6. Experiments,[0],[0]
ProtoNN,6. Experiments,[0],[0]
"vs. Uncompressed Baselines: In this experiment we compare the performance of ProtoNN with uncompressed baselines and demonstrate that even with compression, ProtoNN achieves near state-of-the-art accuracies.",6. Experiments,[0],[0]
We restrict the model size of ProtoNN to 16kB for binary datasets and to 64kB for multiclass datasets and don’t place any constraints on the model sizes of baselines.,6. Experiments,[0],[0]
We compare ProtoNN,6. Experiments,[0],[0]
"with: GBDT, RBF-SVM, 1-Hidden Layer Neural Network (1-hidden NN), kNN, BNC and SNC.",6. Experiments,[0],[0]
For baselines the optimal hyper-parameters are selected through cross-validation.,6. Experiments,[0],[0]
"For SNC, BNC we set projection dimensions to 100, 1280 respectively and compression ratios to 16%, 1%.",6. Experiments,[0],[0]
"For ProtoNN, hyper-parameters are set based on the following heuristics which ensure that the model size constraints are satisfied:",6. Experiments,[0],[0]
"Binary: d̂ = 10, sZ = sB = 0.8. m = 40 if sW = 1.0 gives model larger than 16kB. Else, sW = 1.0 and m is increased to reach 16 kB model.",6. Experiments,[0],[0]
"Multiclass: d̂ = 15, sZ = sB = 0.8. m",6. Experiments,[0],[0]
= 5/class if sW = 1.0 gives model larger than 64kb.,6. Experiments,[0],[0]
"Else, m is increased to reach 64 kB model.",6. Experiments,[0],[0]
"CUReT which has 61 classes, requires smaller sZ to satisfy model size constraints.",6. Experiments,[0],[0]
"We use the above parameter settings for all binary, multiclass datasets except for binary versions of usps, character and eye which require 5-fold cross validation.",6. Experiments,[0],[0]
Table 1 presents the results on binary datasets and Table 2 presents the results on multiclass datasets.,6. Experiments,[0],[0]
"For most of the datasets, ProtoNN gets to within 1−2% accuracy of the best uncompressed baseline with 1− 2 orders of magnitude reduction in model size.",6. Experiments,[0],[0]
"For example on character recognition, ProtoNN is 0.5% more accurate than the best method (RBFSVM) while getting ≈ 400× compression in model size.",6. Experiments,[0],[0]
"Similarly, on letter-26, our method is within 0.5% accuracy of RBF-SVM while getting ≈ 9× compression.",6. Experiments,[0],[0]
"Also note that ProtoNN with 16kB models is still able to outperform BNC, SNC on most of the datasets.
",6. Experiments,[0],[0]
ProtoNN,6. Experiments,[0],[0]
vs. Compressed Baselines:,6. Experiments,[0],[0]
"In this experiment we compare the performance of ProtoNN with other stateof-the-art compressed methods in the 2-16kB model size regime: BudgetRF (Nan et al., 2015), Decision Jungle (Shotton et al., 2013), LDKL (Jose et al., 2013), Tree Pruning (Dekel et al., 2016), GBDT (Friedman, 1999), Budget Prune (Nan et al., 2016), SNC and NeuralNet Pruning (Han et al., 2016).",6. Experiments,[0],[0]
All baselines plots are obtained via cross-validation.,6. Experiments,[0],[0]
Figure 1 presents the memory vs. accuracy plots.,6. Experiments,[0],[0]
Hyper-parameters of ProtoNN are set as follows:,6. Experiments,[0],[0]
Binary: sB = sZ = 0.8.,6. Experiments,[0],[0]
"For [2, 4, 8, 16] kB, d̂ =",6. Experiments,[0],[0]
"[5, 5, 10, 15].",6. Experiments,[0],[0]
"sW , m are set using the same heuristic mentioned in the previous paragraph.",6. Experiments,[0],[0]
Multiclass: sB = 0.8.,6. Experiments,[0],[0]
"For [16, 32, 64, 128] kB, d̂ = [10, 15, 15, 20].",6. Experiments,[0],[0]
"sW , sZ , m are set as defined in the previous paragraph.",6. Experiments,[0],[0]
ProtoNN,6. Experiments,[0],[0]
"values obtained with the above hyper-parameters
are reported for all datasets, except usps and character recognition which require 5-fold cross validation.",6. Experiments,[0],[0]
ProtoNN performs significantly better than the baselines on all the datasets.,6. Experiments,[0],[0]
"This is especially true in the 2kB regime, where ProtoNN is ≥ 5% more accurate on most of the datasets.
",6. Experiments,[0],[0]
ProtoNN on Multilabel and Large Multiclass Datasets: We now present the performance of ProtoNN on larger datasets.,6. Experiments,[0],[0]
"Here, we experimented with the following datasets: aloi dataset which is a relatively large multiclass dataset , mediamill, delicious, eurlex which are smallmedium sized multilabel datasets.",6. Experiments,[0],[0]
We set the hyper-parameters of ProtoNN as follows.,6. Experiments,[0],[0]
"d̂ is set to 30 for all datasets, except for eurlex for which we set it to 100.",6. Experiments,[0],[0]
"Other parameters are set as follows: sW = 1, sB = 1, sZ = 5/L for aloi and sZ = 2(avg.",6. Experiments,[0],[0]
"number of labels per training point)/L for multilabel datasets, m = 2 · L for multilabel datasets.",6. Experiments,[0],[0]
"For aloi, we compare ProtoNN",6. Experiments,[0],[0]
"with the following baselines: 1vsA L2 Logistic Regression (1vsA-Logi), RBFSVM, FastXML: a large-scale multilabel method (Prabhu & Varma, 2014), Recall Tree: a scalable method for large multiclass problems (Daume III et al., 2016).",6. Experiments,[0],[0]
"For 1vsALogi, Recall Tree we perform cross validation to pick the best tuning parameter.",6. Experiments,[0],[0]
For FastXML we use the default parameters.,6. Experiments,[0],[0]
"For RBF-SVM we set γ to the default value 1/d
and do a limited tuning of the regularization parameter.",6. Experiments,[0],[0]
Left table of Figure 2 shows that ProtoNN,6. Experiments,[0],[0]
(with m = 5000) gets to within 1% of the accuracy of RBF-SVM with just (1/50)th of its model size and 50 times fewer floating point computations per prediction.,6. Experiments,[0],[0]
"For a better comparison of ProtoNN with FastXML, we set the number of prototypes (m = 1500) such that computations/prediction of both the methods are almost the same.",6. Experiments,[0],[0]
We can see that ProtoNN gets similar accuracy as FastXML,6. Experiments,[0],[0]
but with a model size 2 orders of magnitude smaller than FastXML.,6. Experiments,[0],[0]
"Finally, our method has almost same prediction cost as Recall-Tree but with 10% higher accuracy and 4× smaller model size.",6. Experiments,[0],[0]
Right table of Figure 2 presents preliminary results on multilabel datasets.,6. Experiments,[0],[0]
"Here, we compare ProtoNN with SLEEC, FastXML and DiSMEC (Babbar & Shölkopf, 2016), which learns a 1vsA linear-SVM in a distributed fashion.",6. Experiments,[0],[0]
ProtoNN,6. Experiments,[0],[0]
almost matches the performance of all baselines with huge reduction in model size.,6. Experiments,[0],[0]
These results show that ProtoNN is very flexible and can handle a wide variety of problems very efficiently.,6. Experiments,[0],[0]
SNC doesn’t have such flexibility.,6. Experiments,[0],[0]
"For example, it can’t be naturally extended to handle multilabel classification problems.
",6. Experiments,[0],[0]
ProtoNN,6. Experiments,[0],[0]
"vs. BNC, SNC:",6. Experiments,[0],[0]
"In this experiment, we do a thorough performance comparison of ProtoNN with BNC and SNC.",6. Experiments,[0],[0]
"To show that ProtoNN learns better prototypes than BNC, SNC, we fix the projection dimension d̂ of all the methods and vary the number of prototypes m. To show that ProtoNN learns a better embedding, we fix m and vary d̂.",6. Experiments,[0],[0]
"For BNC, which learns a binary embedding, d̂ is chosen such that the #parameters in its transformation matrix is 32 times the #parameters in transformation matrices of ProtoNN, SNC.",6. Experiments,[0],[0]
m is chosen similarly.,6. Experiments,[0],[0]
Figure 3 presents the results from this experiment on mnist binary dataset.,6. Experiments,[0],[0]
"We use the following hyper parameters for ProtoNN: sW = 0.1, sZ = sB = 1.0.",6. Experiments,[0],[0]
"For SNC, we hard threshold the input transformation matrix so that it has sparsity 0.1.",6. Experiments,[0],[0]
"Note that for small d̂ our method is as much as
Figure 2.",6. Experiments,[0],[0]
Left Table: ProtoNN vs baselines on aloi dataset.,6. Experiments,[0],[0]
For Recall Tree we couldn’t compute the avg.,6. Experiments,[0],[0]
"number of computations needed per prediction, instead we report the prediction time w.r.t 1vsA-Logi.",6. Experiments,[0],[0]
Right Table: ProtoNN vs baselines on multilabel datasets.,6. Experiments,[0],[0]
For SLEEC and FastXML we use the default parameters from the respective papers.,6. Experiments,[0],[0]
"Both the tables show that our method achieves similar accuracies as the baselines, but often with 1− 2 orders of magnitude compression in model size.",6. Experiments,[0],[0]
"On aloi our method is at most 2 slower than 1-vs-all while RBF-SVM is 115× slower.
20% more accurate than SNC, 5% more accurate than BNC and reaches nearly optimal accuracy for small d̂ or m.
Remark 1.",6. Experiments,[0],[0]
Before we conclude the section we provide some practical guidelines for hyper-parameter selection in ProtoNN.,6. Experiments,[0],[0]
Consider the following two cases: a) Small L (L / 0.1d):,6. Experiments,[0],[0]
"In this case, parameters d̂ and sW govern the model size.",6. Experiments,[0],[0]
"Given a model size constraint, fixing one parameter fixes the other, so that we effectively have one hyper-parameter to cross-validate.",6. Experiments,[0],[0]
Choosing m such that 10 ≤ m/L ≤ 20 typically gives good accuracies.,6. Experiments,[0],[0]
b) Large L (L ' 0.1d):,6. Experiments,[0],[0]
"In this case, sZ also governs the model size.",6. Experiments,[0],[0]
"sZ , sW and d̂ can be selected through crossvalidation.",6. Experiments,[0],[0]
"If the model size allows it, increasing d̂ typically helps.",6. Experiments,[0],[0]
"Fixing m/L to a reasonable value such as 3-10 for medium L, 1-2 for large L typically gives good accuracies.",6. Experiments,[0],[0]
"In the previous section, we showed that ProtoNN gets better accuracies than other compressed baselines at low model size regimes.",7. Experiments on tiny IoT devices,[0],[0]
"For small devices, it is also critical to study other aspects like energy consumption, which severely impact the effectiveness of a method in practice.",7. Experiments on tiny IoT devices,[0],[0]
"In this section, we study the energy consumption and prediction time of ProtoNN model of size 2kB when deployed on an Arduino Uno.",7. Experiments on tiny IoT devices,[0],[0]
"The Arduino Uno has an 8 bit, 16 MHz Atmega328P microcontroller, with 2kB of SRAM and 32kB
of read-only flash.",7. Experiments on tiny IoT devices,[0],[0]
We compare ProtoNN,7. Experiments on tiny IoT devices,[0],[0]
"with 3 baselines (LDKL-L1, NeuralNet Pruning, L1 Logistic) on 4 binary datasets.",7. Experiments on tiny IoT devices,[0],[0]
Figure 4 presents the results from this experiment.,7. Experiments on tiny IoT devices,[0],[0]
ProtoNN shows almost the same characteristics as a simple linear model (L1-logistic) in most cases while providing significantly more accurate predictions.,7. Experiments on tiny IoT devices,[0],[0]
"Further optimization: The Atmega328P microcontroller supports native integer arithmetic at ≈0.1µs/operation, software-based floating point arithmetic at≈6µs/operation; exponentials are a further order slower.",7. Experiments on tiny IoT devices,[0],[0]
It is thus desirable to perform prediction only using integers.,7. Experiments on tiny IoT devices,[0],[0]
We implemented an integer version of ProtoNN to leverage this.,7. Experiments on tiny IoT devices,[0],[0]
We factor out a common float value from the parameters and round the residuals by 1-byte integers.,7. Experiments on tiny IoT devices,[0],[0]
"To avoid computing the exponentials, we store a pre-computed table of approximate exponential values.",7. Experiments on tiny IoT devices,[0],[0]
"As can be seen in Figure 4, this optimized version of ProtoNN loses only a little accuracy, but obtains ≈ 2× reduction in energy and prediction cost.",7. Experiments on tiny IoT devices,[0],[0]
Several real-world applications require real-time prediction on resource-scarce devices such as an Internet of Things (IoT) sensor.,abstractText,[0],[0]
Such applications demand prediction models with small storage and computational complexity that do not compromise significantly on accuracy.,abstractText,[0],[0]
"In this work, we propose ProtoNN, a novel algorithm that addresses the problem of real-time and accurate prediction on resource-scarce devices.",abstractText,[0],[0]
ProtoNN is inspired by k-Nearest Neighbor (KNN) but has several orders lower storage and prediction complexity.,abstractText,[0],[0]
ProtoNN models can be deployed even on devices with puny storage and computational power (e.g. an Arduino UNO with 2kB RAM) to get excellent prediction accuracy.,abstractText,[0],[0]
"ProtoNN derives its strength from three key ideas: a) learning a small number of prototypes to represent the entire training set, b) sparse low dimensional projection of data, c) joint discriminative learning of the projection and prototypes with explicit model size constraint.",abstractText,[0],[0]
"We conduct systematic empirical evaluation of ProtoNN on a variety of supervised learning tasks (binary, multi-class, multi-label classification) and show that it gives nearly state-of-the-art prediction accuracy on resource-scarce devices while consuming several orders lower storage, and using minimal working memory.",abstractText,[0],[0]
ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices,title,[0],[0]
"For retailers, brick-and-mortar stores and internet-based stores, various recommendation methods are proposed in an attempt to sell products.",1. Introduction,[0],[0]
The recommendation model is usually updated in a timely manner or it includes new valuable features of products which are not previously available.,1. Introduction,[0],[0]
"For example, during the Apple WWDC 2018 keynote, Apple has introduced new features of their platforms to fight “fingerprinting”, a technique which tracks users based on identifying computers.",1. Introduction,[0],[0]
"With the available of new features, a feature selection model is employed to determine whether the new features will drive sales of products in the future
1Cornell University, New York, NY 10021, USA. 2Rutgers University, Piscataway, NJ 08854, USA.",1. Introduction,[0],[0]
"3Baidu Research, Bellevue, WA 98004, USA.",1. Introduction,[0],[0]
"Jing Wang <jiw2026@med.cornell.edu>, Ping Li <pingli98@gmail.com>.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Jie Shen <js2007@rutgers.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
and only related features will be included in the recommendation model.,1. Introduction,[0],[0]
"Hence, in real-world applications, features are usually revealed in a continuous stream.",1. Introduction,[0],[0]
It is necessary to evaluate new features immediately and output intermediate result.,1. Introduction,[0],[0]
"The feature evaluation process in a stream is called online feature selection (Perkins & Theiler, 2003; Zhou et al., 2005; Wu et al., 2010).",1. Introduction,[0],[0]
"We first formulate this problem.
",1. Introduction,[0],[0]
Suppose that there are n samples but initially we do not observe all of the features.,1. Introduction,[0],[0]
"We call the sequence a1,a2, · · · ∈",1. Introduction,[0],[0]
"Rn is a feature stream, with each ai ∈",1. Introduction,[0],[0]
"Rn being the ith feature, or the ith covariate of n samples.",1. Introduction,[0],[0]
"Note that in our setting, the feature ai is revealed at time stamp i.",1. Introduction,[0],[0]
"If ai is selected, we update the observation matrixA as follows:
A←",1. Introduction,[0],[0]
[A θiai] .,1. Introduction,[0],[0]
"(1.1)
where the parameter θi 6= 0 is chosen in an online manner.
",1. Introduction,[0],[0]
"In the literature, a large number of online methods have been proposed based on statistical measurements or optimization techniques (Perkins & Theiler, 2003; Zhou et al., 2005; Wang et al., 2015).",1. Introduction,[0],[0]
"For example, Perkins & Theiler (2003) added a new feature which contributes to a predictor learning and optimization analysis into the model.",1. Introduction,[0],[0]
Zhou et al. (2005) proposed an adaptive complexity penalty method to evaluate a new feature based on its p-value.,1. Introduction,[0],[0]
Wu et al. (2010) utilized the Markov blanket to measure the relationship between a new feature and the selected feature subset.,1. Introduction,[0],[0]
"Yet successful, most of the results in this line of research are empirical in nature.
",1. Introduction,[0],[0]
"On the other hand, feature selection method can be categorized into either supervised or unsupervised.",1. Introduction,[0],[0]
"For instance, Shen & Li (2017) recently proposed a non-convex supervised approach for variable selection with favorable iteration complexity.",1. Introduction,[0],[0]
"Unsupervised methods, however, are with great practical importance to many areas such as Cardiology, as annotated data is usually precious and limited due to genetic privacy issue and the medical background requirement for annotators.
",1. Introduction,[0],[0]
Summary of Contributions.,1. Introduction,[0],[0]
"In this paper, we consider the high-dimensional regime that the number of features is much larger than the sample size, and the features are revealed in an online manner.",1. Introduction,[0],[0]
"We propose an unsupervised algorithm termed Online leverage scores for Feature Selection
(OFS).",1. Introduction,[0],[0]
"Our main technique is to approximately compute the broadly used leverage score in each iteration, and determine the importance of each feature in real time.",1. Introduction,[0],[0]
We prove that the reduced feature space is a good approximation to the original one in some sense to be clarified.,1. Introduction,[0],[0]
"Furthermore, we apply k-means clustering on the set of selected features, and show that the clustering performance does not degrade a lot.",1. Introduction,[0],[0]
"Computationally, our algorithm enjoys low time complexity and little memory usage, which makes it a perfect fit for big data analytics.",1. Introduction,[0],[0]
Feature selection is a primary technique in machine learning to address “the curse of dimensionality”.,2. Related Work,[0],[0]
"In the last decades, a number of methods have been proposed (Guyon & Elisseeff, 2003; Donoho & Jin, 2008).",2. Related Work,[0],[0]
"In this section, we give a brief review of existing approaches in terms of batch situation and online situation.
",2. Related Work,[0],[0]
Batch Methods.,2. Related Work,[0],[0]
"Existing batch feature selection methods can be roughly divided to unsupervised, supervised and semi-supervised approaches.",2. Related Work,[0],[0]
"The supervised methods utilize the target variable to guide the feature evaluation process, such as Fisher score, Least Absolute Shrinkage and Selection Operator (Lasso) (Tibshirani, 1996) and minimum Redundancy Maximum Relevance (Peng et al., 2005).",2. Related Work,[0],[0]
"Unsupervised feature selection methods mainly depend on latent data distribution analysis (He et al., 2005), such as spectral analysis (Zhao & Liu, 2007; Cai et al., 2010) and Kullback-Leibler Divergence between neighborhood distributions (Wei & Philip, 2016).",2. Related Work,[0],[0]
"The semi-supervised feature selection algorithms make benefits of both aforementioned approaches, such as combining Gaussian Field and Harmonic functions (Kong & Yu, 2010; Zhu et al., 2003).
",2. Related Work,[0],[0]
"Feature selection methods are also characterized as wrapper, embedded and filter model.",2. Related Work,[0],[0]
"The wrapper model evaluates feature subsets by their performance on a specific algorithm, such as SVM or Naive Bayes for classification tasks (Forman, 2003) and k-means for clustering tasks (Guyon et al., 2002; Xu et al., 2014).",2. Related Work,[0],[0]
"The embedded model seeks the desired feature subset by solving a regularized optimization objective function with certain constraints (Zhang, 2009; Yang & Xu, 2013).",2. Related Work,[0],[0]
"Examples of this approach include Least Angle Regression (Efron et al., 2004) and group Lasso (Zhang et al., 2016).",2. Related Work,[0],[0]
The optimization process forces most coefficients small or exact zero.,2. Related Work,[0],[0]
"The features corresponding to nonzero coefficients are selected.
",2. Related Work,[0],[0]
"The filter model utilizes certain statistical measurements, such as the Hilbert-Schmidt Independence Criterion (HSIC), leverage score (Boutsidis et al., 2009) and kernel-based measures of independence (Chen et al., 2017).",2. Related Work,[0],[0]
"Specifically, the statistical leverage score is an important measurement
for unsupervised feature selection.",2. Related Work,[0],[0]
It characterizes the outstanding features that have more affect towards the result of a statistical procedure.,2. Related Work,[0],[0]
"There are multiple variants of the statistical leverage score, such as the normalized leverage score (Boutsidis et al., 2009), the truncated version of leverage score (Gittens & Mahoney, 2013) and the kernel ridge leverage score (Alaoui & Mahoney, 2015).",2. Related Work,[0],[0]
"The ridge leverage score is used to select features for k-means clustering (Boutsidis et al., 2009) and has proved to attain (2 + )- approximate partition.",2. Related Work,[0],[0]
"Specifically, the ridge leverage score of the ith column of data matrix A ∈ Rn×d is defined as (Alaoui & Mahoney, 2015),
li = a > i (AA > + λI)−1ai, (2.1)
where λ > 0 is a parameter, I ∈ Rn×n is the identity matrix.",2. Related Work,[0],[0]
"However, it is expensive as it requires O ( n3 + n2d ) running time and O (nd) memory storage.",2. Related Work,[0],[0]
"A number of recent papers focus on sampling some columns of A and approximate the linear kernel ofA (Li et al., 2013; Alaoui & Mahoney, 2015; Cohen et al., 2016; Musco & Musco, 2017).",2. Related Work,[0],[0]
"However, none of these techniques have been applied for feature selection of streaming features.
",2. Related Work,[0],[0]
Online Methods.,2. Related Work,[0],[0]
"Motivated by the fact that features are available in a stream in real-world applications, online feature selection has attracted a lot of attention (Perkins & Theiler, 2003; Zhou et al., 2005; Wu et al., 2010; Wang et al., 2013).",2. Related Work,[0],[0]
The batch-mode algorithms cannot handle this situation well as the global feature space is required in advance.,2. Related Work,[0],[0]
"Examples of online feature selection approaches either utilize statistical measurements, such as alpha-investing (Zhou et al., 2005) and mutual information (Wu et al., 2010) or rely on optimization techniques, such as stochastic gradient grafting (Perkins & Theiler, 2003; Wang et al., 2015).",2. Related Work,[0],[0]
All existing mentioned methods come with no theoretical guarantees of the selected feature subset for clustering task.,2. Related Work,[0],[0]
"We use bold lower-case letters, e.g. v ∈ Rd to denote a column vector.",2.1. Notation,[0],[0]
‖v‖2 is used to denote the `2-norm of the vector.,2.1. Notation,[0],[0]
"Capital letters such asX are used to denote matrices, and its transpose is denoted byX>.",2.1. Notation,[0],[0]
The capital letter In×n is reserved for the identity matrix where n indicates its size.,2.1. Notation,[0],[0]
"For an invertible matrix X , we write its inverse as X−1.",2.1. Notation,[0],[0]
"Otherwise, we use X† for the pseudoinverse.",2.1. Notation,[0],[0]
"For a square matrix X , we write its trace as Tr (X), which is the sum of its diagonal elements.",2.1. Notation,[0],[0]
"The ith column and jth row of the matrix X are denoted by xi and (xj)>, respectively.",2.1. Notation,[0],[0]
"Suppose that the rank of matrixX ∈ Rn×m is k ≤ min{m,n}.",2.1. Notation,[0],[0]
"The singular value decomposition of X
is given by
X = [ u1, · · · ,uk ] σ1 . . .",2.1. Notation,[0],[0]
"σk  v > 1 ... v>k  where the singular values in descending order σ1 ≥ · · · ≥ σk > 0, U =",2.1. Notation,[0],[0]
"[u1, · · · ,uk] ∈ Rn×k contains the left singular vectors and V = [v1, · · · ,vk] contains the right singular vectors.",2.1. Notation,[0],[0]
"In this paper, we will use the Frobe-
nius norm",2.1. Notation,[0],[0]
‖X‖F := √∑k i=1 σ 2,2.1. Notation,[0],[0]
"i and the spectral norm ‖X‖2 := max1≤i≤k σi = σ1.
",2.1. Notation,[0],[0]
"For a sequence of random variablesX1,X2, . . .",2.1. Notation,[0],[0]
", we write Ej−1",2.1. Notation,[0],[0]
"[Xj ] for the expectation of Xj conditioning on {X1, . .",2.1. Notation,[0],[0]
.,2.1. Notation,[0],[0]
",Xj−1}.",2.1. Notation,[0],[0]
"In this section, we propose an online algorithm for feature selection, where the goal is to approximate the original data with much fewer attributes in some sense.",3. Main Results,[0],[0]
"To the end, we make use of the leverage score that, from a high level, reflects the importance of each feature.
",3. Main Results,[0],[0]
"Suppose that the data matrix isA ∈ Rn×d, i.e., n samples lying in a d-dimensional ambient space.",3. Main Results,[0],[0]
"The statistical leverage score of the ith column (i.e., feature) of A is defined as
l∗i =",3. Main Results,[0],[0]
a > i (AA >)†ai.,3. Main Results,[0],[0]
"(3.1)
It is well known that sampling an n×O ( −2n log n ) matrix
Ã with probabilities proportional to the respective leverage scores yields a (1 + )-spectral approximation toA (Spielman & Srivastava, 2011), in the sense",3. Main Results,[0],[0]
that for all x∥∥∥Ã>x∥∥∥ 2,3. Main Results,[0],[0]
"≈ ∥∥∥A>x∥∥∥ 2 , or more precisely (1− )",3. Main Results,[0],[0]
x>AA>x ≤ x>ÃÃ>x ≤ (1 + ),3. Main Results,[0],[0]
"x>AA>x, or
(1− )AA> ÃÃ>",3. Main Results,[0],[0]
"(1 + )AA>.
",3. Main Results,[0],[0]
"In the online setting, however, we are not able to access all the data to compute the leverage score.",3. Main Results,[0],[0]
"The key idea of our algorithm is that when a new feature arrives, we approximate its leverage score based on the obtained features, which can further be used to guide the selection process.
",3. Main Results,[0],[0]
"To be more concrete, at time stamp i, suppose the observed data matrix is Ãi−1 and the new feature ai is revealed, we need to determine whether ai is kept or discarded.",3. Main Results,[0],[0]
"A natural way for the sake is to compute the approximate leverage score of ai as follows:
li =",3. Main Results,[0],[0]
a > i (Ãi−1Ã > i−1) †ai.,3. Main Results,[0],[0]
"(3.2)
Algorithm 1 Online Feature Selection Require: Initial data matrix Ã0, sampling rate c =
8 −2 log n, approximation parameter ∈ (0, 1).",3. Main Results,[0],[0]
"1: for i = 1, · · · do 2: Reveal the ith feature ai.",3. Main Results,[0],[0]
"3: Compute the online leverage score
l̃i = min((1 + )",3. Main Results,[0],[0]
"a > i (Ãi−1Ã > i−1) †ai, 1).
",3. Main Results,[0],[0]
"4: Compute the probability,
pi = min(cl̃i, 1).
5: With probability pi, update
Ãi =",3. Main Results,[0],[0]
"[Ãi−1 ai/ √ pi].
",3. Main Results,[0],[0]
"Otherwise,
Ãi = Ãi−1.
6: end for
Intuitively, if Ãi−1 is a good approximation to A, li indicates the importance of ai as l∗i does.",3. Main Results,[0],[0]
"And what we will show is that, it is the case after we reveal a few attributes.
",3. Main Results,[0],[0]
"It is known that if the entire feature space is available, each leverage score is upper bounded by 1.",3. Main Results,[0],[0]
"However the estimates based on Ãi−1 can be arbitrary because Ãi−1 is a submatrix of A which leads to Ãi−1Ã > i−1 AA
>.",3. Main Results,[0],[0]
"For our analysis, we technically require that each li is not larger than 1.",3. Main Results,[0],[0]
"Hence, we will make use of a modified quantity
l̃i = min ( (1 + )",3. Main Results,[0],[0]
"a>i (Ãi−1Ã > i−1) †ai, 1 ) .",3. Main Results,[0],[0]
"(3.3)
Note that > 0 is some pre-defined accuracy parameter, and the above suggests we are using a conservative estimate of the leverage score.",3. Main Results,[0],[0]
"To see this, consider Ãi−1 = A, then l̃i ≥ l∗i .",3. Main Results,[0],[0]
"It is essential in the online setting in that we may lose many important features with an aggressive strategy.
",3. Main Results,[0],[0]
"Then, the sampling probability is computed as pi = min ( 8 −2 log n · l̃i, 1 ) .",3. Main Results,[0],[0]
"(3.4)
With the scaling factor of l̃i above, it is not hard to see that for a small approximation error , one has to select the current feature with high probability, which conforms the intuition – an exact estimation of A requires selecting all the features.",3. Main Results,[0],[0]
We summarize our method in Algorithm 1.,3. Main Results,[0],[0]
"We first show that with high probability, the data matrix produced by our algorithm is a good approximation toA.
Theorem 1.",3.1. Analysis,[0],[0]
Consider Algorithm 1.,3.1. Analysis,[0],[0]
Let Ã be the output when it terminates.,3.1. Analysis,[0],[0]
"It holds with high probability that
(1− )AA> ÃÃ> (1 + )AA>.
",3.1. Analysis,[0],[0]
Proof.,3.1. Analysis,[0],[0]
Let Ai = (a1 a2 . . .ai).,3.1. Analysis,[0],[0]
Define Y 0,3.1. Analysis,[0],[0]
"as the zero matrix and for all i ≥ 1, let
Y i−1 = (AA >)†/2(Ãi−1Ã > i−1−Ai−1A >",3.1. Analysis,[0],[0]
"i−1)(AA >)†/2.
",3.1. Analysis,[0],[0]
Let ui = (AA>)†/2ai.,3.1. Analysis,[0],[0]
"If ‖Y i−1‖2 ≥ , we set Xi = 0.",3.1. Analysis,[0],[0]
"Otherwise, set
Xi = { (1/pi − 1)uiu>",3.1. Analysis,[0],[0]
"i , if ai is sampled in Ã, −uiu>i , otherwise.
",3.1. Analysis,[0],[0]
"Thus,Xi = Y i − Y i−1.
Consider the case ‖Y i−1‖2 < .",3.1. Analysis,[0],[0]
"We get
l̃i = min((1 + )",3.1. Analysis,[0],[0]
"a > i (ÃiÃ > i ) †ai, 1)
≥ min((1 + )",3.1. Analysis,[0],[0]
"a>i (AiA > i + AA >)†ai, 1) ≥ min((1 + )",3.1. Analysis,[0],[0]
"a>i ((1 + )(AA >))†ai, 1) = a>i (AA >)†ai",3.1. Analysis,[0],[0]
"= u>i ui.
",3.1. Analysis,[0],[0]
"Thus, pi ≥ min(cu>i ui, 1).",3.1. Analysis,[0],[0]
"If pi = 1, then Xi = 0.",3.1. Analysis,[0],[0]
"Otherwise, we have pi ≥ cu",3.1. Analysis,[0],[0]
>i ui.,3.1. Analysis,[0],[0]
"Moreover, we get
‖Xi‖2 ≤ 1/c
and
",3.1. Analysis,[0],[0]
Ei−1,3.1. Analysis,[0],[0]
"[ X2i ]
pi · (1/pi − 1)2(uiu>i )2 + (1− pi) · (uiu>i )2
= (uiu > i ) 2/pi
uiu>i /c.
",3.1. Analysis,[0],[0]
LetW i = ∑i k=1 Ek−1 [ X2k ] .,3.1. Analysis,[0],[0]
"We have
‖W i‖2 ≤ ∥∥∥∥∥",3.1. Analysis,[0],[0]
"i∑
k=1
uiu > i /c ∥∥∥∥∥",3.1. Analysis,[0],[0]
"2 ≤ 1/c.
Applying Lemma 4 gives Pr(‖Y n‖2 ≥ ) ≤ n ·",3.1. Analysis,[0],[0]
exp ( − 2/2 1/c+ /(3c) ),3.1. Analysis,[0],[0]
"≤ n · exp(−c 2/4) = 1/n.
",3.1. Analysis,[0],[0]
"This implies that with high probability∥∥∥(AA>)†/2(ÃÃ>)(AA>)†/2 − I∥∥∥ 2 ≤ .
",3.1. Analysis,[0],[0]
"We thus have
(1− )AA> ÃÃ > (1 + )AA>,
completing the theorem.
",3.1. Analysis,[0],[0]
Now we turn to control the number of features selected by Algorithm 1.,3.1. Analysis,[0],[0]
"We will use the result in (Cohen et al., 2015) shown below.
",3.1. Analysis,[0],[0]
Lemma 1.,3.1. Analysis,[0],[0]
"Let A be an n × d matrix, ∈ (0, 1), c = 1/ , l̃1, · · · , l̃d be over-estimated leverage scores, i.e., l̃i ≥",3.1. Analysis,[0],[0]
"a>i (AA
>)†ai for all 1 ≤",3.1. Analysis,[0],[0]
i ≤ d.,3.1. Analysis,[0],[0]
"Let pi = min{cl̃i, 1}.",3.1. Analysis,[0],[0]
"Construct Ã by independently sampling each column ai of A with probability pi and rescale it by 1/ √ pi if it is included in Ã. Then, with high probability, Ã is the (1+ )- spectral approximation ofA and the number of columns in Ã is O ( −2 ∑d i=1",3.1. Analysis,[0],[0]
"l̃i log n ) .
",3.1. Analysis,[0],[0]
"By Lemma 1, in order to control the number of selected features, we need to bound the sum of online leverage scores.
",3.1. Analysis,[0],[0]
Lemma 2.,3.1. Analysis,[0],[0]
"After running Algorithm 1, it holds with high probability that
d∑ i=1",3.1. Analysis,[0],[0]
l̃i = O,3.1. Analysis,[0],[0]
"(n log(‖A‖2)) .
",3.1. Analysis,[0],[0]
Proof.,3.1. Analysis,[0],[0]
"We define
δi = log",3.1. Analysis,[0],[0]
det(ÃiÃ >,3.1. Analysis,[0],[0]
i ),3.1. Analysis,[0],[0]
"− log det(Ãi−1Ã > i−1).
",3.1. Analysis,[0],[0]
The sum of δi can be bounded by the logarithm of the ratio of the determinants of ÃÃ > .,3.1. Analysis,[0],[0]
"By the matrix determinant lemma, we have
Ei−1",3.1. Analysis,[0],[0]
[ exp(l̃i/8− δi) ],3.1. Analysis,[0],[0]
= pi · eli/8(1 +,3.1. Analysis,[0],[0]
"a>i (Ãi−1Ã > i−1) −1ai/pi) −1
+",3.1. Analysis,[0],[0]
(1− pi) ·,3.1. Analysis,[0],[0]
"eli/8
≤ (1 + li/4) · (pi(1 + a>i (Ãi−1Ã > i−1) −1ai/pi) −1
+ 1− pi).
",3.1. Analysis,[0],[0]
"If cl̃i < 1, we have pi = cl̃i and Ei−1",3.1. Analysis,[0],[0]
[ exp(l̃i/8− δi) ],3.1. Analysis,[0],[0]
≤ cl̃i · (1 + li/4)(1 + 1/((1 + ),3.1. Analysis,[0],[0]
"c))−1 + (1− cl̃i)· (1 + li/4)
= (1 + li/4)(cli(1 + 1/((1 + )c)) −1",3.1. Analysis,[0],[0]
"+ 1− cli)
≤ (1 + li/4)(1 + cli(1− 1/(4c)− 1))",3.1. Analysis,[0],[0]
"= (1 + li/4)(1− li/4) ≤ 1.
",3.1. Analysis,[0],[0]
"Otherwise, pi = 1 and we have
Ei−1",3.1. Analysis,[0],[0]
[ exp(l̃i/8− δi) ],3.1. Analysis,[0],[0]
≤ (1 + li/4)(1,3.1. Analysis,[0],[0]
+A>i (Ã > i−1Ãi−1 + λI) −1Ai) −1 ≤,3.1. Analysis,[0],[0]
(1 + li/4)(1,3.1. Analysis,[0],[0]
"+ li)−1 ≤ 1.
",3.1. Analysis,[0],[0]
We now analyze the expected product of exp(l̃i/8−δi) over the first k steps.,3.1. Analysis,[0],[0]
"For k ≥ 1 we have
E [ exp ( k∑ i=1",3.1. Analysis,[0],[0]
l̃i/8− δi )],3.1. Analysis,[0],[0]
≤ E [ exp ( k−1∑ i=1,3.1. Analysis,[0],[0]
"l̃i/8− δi )] ,
and so by induction on k,
E [ exp ( d∑ i=1",3.1. Analysis,[0],[0]
"l̃i/8− δi )] ≤ 1.
",3.1. Analysis,[0],[0]
"Hence by Markov’s inequality,
Pr ( d∑ i=1",3.1. Analysis,[0],[0]
l̃i > 8n+ 8 d∑ i=1,3.1. Analysis,[0],[0]
δi ),3.1. Analysis,[0],[0]
"≤ e−n.
Using Theorem 1, with high probability, we have
ÃÃ >",3.1. Analysis,[0],[0]
"(1 + )AA>,
implying that
det(ÃÃ > )",3.1. Analysis,[0],[0]
"≤ (1 + )n(‖A‖22) n,
log det(ÃÃ > )",3.1. Analysis,[0],[0]
≤,3.1. Analysis,[0],[0]
"n(1 + log(‖A‖22)).
",3.1. Analysis,[0],[0]
"By the definition of δi, it holds with high probability that
d∑ i=1",3.1. Analysis,[0],[0]
"δi = log det(Ã > Ã+ λI)− n
≤ n(1 + log(‖A‖22)− 1) = n(log(‖A‖22)).
",3.1. Analysis,[0],[0]
"And with high probability,
d∑ i=1",3.1. Analysis,[0],[0]
l̃i ≤,3.1. Analysis,[0],[0]
8n+ 8 d∑ i=1,3.1. Analysis,[0],[0]
"δi
≤ 8n+ 8n log(‖A‖22) =",3.1. Analysis,[0],[0]
O ( n log(‖A‖22) ),3.1. Analysis,[0],[0]
"= O (n log(‖A‖2)) .
",3.1. Analysis,[0],[0]
"The proof is complete.
",3.1. Analysis,[0],[0]
"Thus Lemma 1 and 2 imply that Algorithm 1 selects O ( −2n log d log(‖A‖2) ) features with high probability.
",3.1. Analysis,[0],[0]
Time Complexity.,3.1. Analysis,[0],[0]
"The running time of Algorithm 1 is dominated by the online leverage score computation in Step 3, which is O ( n3 ) .",3.1. Analysis,[0],[0]
"In the case that Ãi−1 is a Laplacian
matrix, Step 3 can be implemented inO",3.1. Analysis,[0],[0]
"( d log2 n ) time by a fast graph Laplacian solver with the Johnson-Lindenstrauss lemma, as stated in (Koutis et al., 2016).
",3.1. Analysis,[0],[0]
Memory Cost.,3.1. Analysis,[0],[0]
The memory cost for leverage score computation is significantly reduced from O (nd) to O ( n2 log n ),3.1. Analysis,[0],[0]
(storage of Ãi).,3.1. Analysis,[0],[0]
"This follows from the analysis of Lemma 2 which states that when the algorithm terminates, only O ( −2n log n log(‖A‖2) ) features will be selected.",3.1. Analysis,[0],[0]
"Note that this paper considers the regime where n d, such as the number of patients with rare diseases n and the length of their gene expressions d, or the batch size in neural networks n and the corresponding dimension of feature space d.",3.1. Analysis,[0],[0]
Hence our online implementation is order of magnitude more efficient.,3.1. Analysis,[0],[0]
"It leads to practical values of our algorithm for learning tasks, such as clustering.
3.2.",3.1. Analysis,[0],[0]
"Application to k-Means Clustering
We explore the performance of matrix Ã returned by Algorithm 1 when it is used for k-means clustering.",3.1. Analysis,[0],[0]
"We first recall the k-means clustering problem.
",3.1. Analysis,[0],[0]
"Formally, k-means clustering seeks to partition the data matrix A ∈ Rn×d into k clusters {C1, · · · , Ck} to minimize the distance between data points and its closest center {µ1, · · · ,µk} (Awasthi et al., 2010):
min µ1,...,µk k∑ i=1",3.1. Analysis,[0],[0]
∑ j∈Ci ∥∥aj,3.1. Analysis,[0],[0]
"− µi∥∥22 , (3.5) where µi be the center of data points in Ci.",3.1. Analysis,[0],[0]
"It is known that k-means clustering is an instance of low-rank approximation (Boutsidis et al., 2009).",3.1. Analysis,[0],[0]
"To see this, we construct an n× k matrix X as the cluster indicator matrix.",3.1. Analysis,[0],[0]
"Then for each solution {µi}ki=1 of (3.5), we will assign a cluster label, say xj ∈ {1, 2, . . .",3.1. Analysis,[0],[0]
", k}, to each sample aj .",3.1. Analysis,[0],[0]
We set Xij = 1/ √,3.1. Analysis,[0],[0]
"|Cj | if ai belongs to Cj , and 0 otherwise.",3.1. Analysis,[0],[0]
"In this way, the ith row ofXX>",3.1. Analysis,[0],[0]
"A is actually the average of the points with label i, i.e., the center µi of the ith class.",3.1. Analysis,[0],[0]
"Hence, from the discussion, we may rewrite (3.5) as follows:
min X k∑ i=1",3.1. Analysis,[0],[0]
∑ j∈Ci ∥∥∥aj,3.1. Analysis,[0],[0]
"− (XX>A)i∥∥∥2 2 .
",3.1. Analysis,[0],[0]
"More compactly, we aim to solve
min X ∥∥∥A−XX>A∥∥∥2",3.1. Analysis,[0],[0]
"F .
",3.1. Analysis,[0],[0]
"See (Ostrovsky et al., 2006) for a more detailed discussion.
",3.1. Analysis,[0],[0]
Let the indicator matrix X∗ ∈,3.1. Analysis,[0],[0]
"Rn×k denote the optimal partition onA, i.e.,
X∗ = argmin X ∥∥∥A−XX>A∥∥∥2",3.1. Analysis,[0],[0]
F .,3.1. Analysis,[0],[0]
"(3.6)
We first investigate how the cluster indicator matrixX over Ã is deviated from the optimum.",3.1. Analysis,[0],[0]
"The following lemma provides the bound of the k-means objective function value on Ã.
Lemma 3.",3.1. Analysis,[0],[0]
"Suppose that Ã is the matrix returned by Algorithm 1, then
(1− ) ∥∥∥A−XX",3.1. Analysis,[0],[0]
>A∥∥∥2,3.1. Analysis,[0],[0]
"F ≤ ∥∥∥Ã−XX>Ã∥∥∥2 F
≤ (1 + ) ∥∥∥A−XX",3.1. Analysis,[0],[0]
">A∥∥∥2
F ,
when is the parameter of Algorithm 1.
",3.1. Analysis,[0],[0]
Proof.,3.1. Analysis,[0],[0]
"Using the notation Y = I −XX>, we can rewrite the objective function of k-means based on the data matrices A and Ã as∥∥∥A−XX>A∥∥∥2
F = ‖Y A‖2F =",3.1. Analysis,[0],[0]
"Tr
( Y AA>Y ) ,∥∥∥Ã−XX>Ã∥∥∥2 F = ∥∥∥Y Ã∥∥∥2",3.1. Analysis,[0],[0]
"F = Tr ( Y ÃÃ > Y ) .
",3.1. Analysis,[0],[0]
"Note that
Tr ( Y ÃÃ > Y ) =",3.1. Analysis,[0],[0]
Tr ( n∑ i=1,3.1. Analysis,[0],[0]
y,3.1. Analysis,[0],[0]
>,3.1. Analysis,[0],[0]
i,3.1. Analysis,[0],[0]
"ÃÃ > yi ) ,
where yi is the ith column of Y .",3.1. Analysis,[0],[0]
"Then by the spectral bound onAA> in Theorem 1, we immediately get
(1− )",3.1. Analysis,[0],[0]
Tr ( Y AA>Y ) ≤,3.1. Analysis,[0],[0]
"Tr ( Y ÃÃ > Y )
≤ (1 + )",3.1. Analysis,[0],[0]
"Tr ( Y AA>Y ) .
",3.1. Analysis,[0],[0]
"Plugging Y = I −XX> into the above inequalities completes the proof.
",3.1. Analysis,[0],[0]
"Now we show that Ã is also a good approximation toA.
Theorem 2.",3.1. Analysis,[0],[0]
Suppose that Ã is returned by Algorithm 1.,3.1. Analysis,[0],[0]
"Let X̃∗ = argmin ∥∥∥Ã−XX>Ã∥∥∥2
F .",3.1. Analysis,[0],[0]
"Then given ∈ (0, 1),
we can get∥∥∥A− X̃∗X̃>∗ A∥∥∥2",3.1. Analysis,[0],[0]
F ≤ 1 + 1− · ∥∥∥A−X∗X>∗ A∥∥∥2,3.1. Analysis,[0],[0]
"F .
",3.1. Analysis,[0],[0]
Proof.,3.1. Analysis,[0],[0]
"Using Lemma 3, we have (1− ) ∥∥∥A− X̃∗X̃>∗ A∥∥∥2",3.1. Analysis,[0],[0]
"F ≤ ∥∥∥Ã− X̃∗X̃>∗ Ã∥∥∥2
F ,∥∥∥Ã−X∗X>∗ Ã∥∥∥2
F ≤",3.1. Analysis,[0],[0]
(1 + ) ∥∥∥A−X∗X>∗ A∥∥∥2,3.1. Analysis,[0],[0]
"F .
",3.1. Analysis,[0],[0]
"On the other hand, by the optimality of X̃∗ for Ã, we have∥∥∥Ã− X̃∗X̃>∗ Ã∥∥∥2 F ≤ ∥∥∥Ã−X∗X>∗ Ã∥∥∥2 F .
",3.1. Analysis,[0],[0]
"Combining the above inequalities, we have∥∥∥A− X̃∗X̃>∗ A∥∥∥2",3.1. Analysis,[0],[0]
F ≤ 1 + 1− · ∥∥∥A−X∗X>∗ A∥∥∥2,3.1. Analysis,[0],[0]
"F .
",3.1. Analysis,[0],[0]
"The proof is complete.
",3.1. Analysis,[0],[0]
"Theorem 2 implies that if X̃∗ is an optimal solution for Ã, then it also preserves an (1 + )-approximation",3.1. Analysis,[0],[0]
forA. We compare our algorithm with existing dimension reduction methods for k-means clustering as shown in Table 1.,3.1. Analysis,[0],[0]
This section describes an empirical study of the efficacy and efficiency of our algorithm.,4. Experiments,[0],[0]
"We first elaborate the experimental settings.
",4. Experiments,[0],[0]
Data Sets.,4. Experiments,[0],[0]
"We perform the experiments on 6 realistic data sets, including USPS1, AR2, COIL203, CIFAR-104, MNIST5 and ORL6.",4. Experiments,[0],[0]
"The summary of them is shown in Table 2.
",4. Experiments,[0],[0]
Comparative Methods.,4. Experiments,[0],[0]
"We compare our algorithm with state-of-the-art feature selection approaches, including supervised model, for instance, alpha-investing (Alpha) (Zhou et al., 2005), as well as unsupervised model, e.g., λ-ridge leverage score (LevS) (Alaoui & Mahoney, 2015) and Laplacian score (LapS) (He et al., 2005).",4. Experiments,[0],[0]
"We also compare to sparse random projection (SEC) (Liu et al., 2017) which is particularly designed for k-means clustering.
Pipeline.",4. Experiments,[0],[0]
"After running our method and the baselines above, we obtain a reduced set of features.",4. Experiments,[0],[0]
Then we feed it to the standard k-means clustering that is available in Matlab.,4. Experiments,[0],[0]
"We also report the clustering result based on the original set of features, and we simply denote it by k-means.
Results.",4. Experiments,[0],[0]
We report the clustering accuracy against the number of selected features in Figure 1.,4. Experiments,[0],[0]
We can see that our algorithm achieves competitive performance with other batch methods.,4. Experiments,[0],[0]
"For example, our algorithm outperforms all the
1https://archive.ics.uci.edu/ml/datasets.",4. Experiments,[0],[0]
"html
2http://www2.ece.ohio-state.edu/˜aleix/ ARdatabase.html
3http://www.cs.columbia.edu/CAVE/ software/softlib/coil-20.php
4https://www.cs.toronto.edu/˜kriz/cifar.",4. Experiments,[0],[0]
"html
5http://yann.lecun.com/exdb/mnist/ 6http://www.cl.cam.ac.uk/research/dtg/
attarchive/facedatabase.html
baseline methods on COIL20, CIFAR-10 and ORL when the number of selected features varies from 10 to 500.",4. Experiments,[0],[0]
"The clustering performance on our selected subset even outperforms the one with all available features.
",4. Experiments,[0],[0]
Computational Efficiency.,4. Experiments,[0],[0]
We illustrate the running time in Table 3.,4. Experiments,[0],[0]
"In terms of efficiency, our algorithm outperforms most of the comparative methods.",4. Experiments,[0],[0]
"This is not surprising in that for batch methods, they often update the model with all the data while we process them one by one.",4. Experiments,[0],[0]
"For example, on the CIFAR-10 data set, Laplacian score requires 2 minutes
for feature selection because the computation of the graph matrix based on global feature space is expensive.",4. Experiments,[0],[0]
"Our algorithm, in contrast, only requires a few seconds.",4. Experiments,[0],[0]
"The reason is that in each iteration, we operate with a skinny matrix Ã instead of the whole data matrixA.",4. Experiments,[0],[0]
"In this paper, we have proposed an online feature selection for k-means clustering.",5. Conclusion,[0],[0]
"For features in a stream, we approx-
imate its leverage score in an online manner and perform feature selection based on such an inexact score.",5. Conclusion,[0],[0]
We provide theoretical guarantee that our unsupervised approach produces an accurate estimation based on the original space.,5. Conclusion,[0],[0]
"Moreover, in the high-dimensional regime the algorithm is computationally efficient and consumes little memory.",5. Conclusion,[0],[0]
"Perhaps more importantly, our algorithm is capable of addressing streaming data which makes it a perfect fit for large-scale learning systems.",5. Conclusion,[0],[0]
"In addition, we extend the analysis to the k-means clustering problem, and provably show that with the set of features reduced by our approach, we are still able to obtain a near-optimal solution to the original k-means problem.",5. Conclusion,[0],[0]
The extensive empirical study matches perfectly our analysis.,5. Conclusion,[0],[0]
"Jing Wang, Jie Shen and Ping Li are supported by NSFBigdata-1419210 and NSF-III-1360971.",Acknowledgements,[0],[0]
Jing Wang is supported by grants from the Dalio Foundation.,Acknowledgements,[0],[0]
The work was done when Jing Wang was a postdoc at Rutgers University.,Acknowledgements,[0],[0]
"We provide a technical lemma which is due to (Tropp et al., 2011).
",A. Technical Lemmas,[0],[0]
Lemma 4.,A. Technical Lemmas,[0],[0]
"Let Y 0,Y 1, . . .",A. Technical Lemmas,[0],[0]
",Y n be a matrix martingale that are self-adjoint matrices with dimension d, and let X1, . . .",A. Technical Lemmas,[0],[0]
",Xn be such that Xk = Y k",A. Technical Lemmas,[0],[0]
− Y k−1 for all 1 ≤ k ≤,A. Technical Lemmas,[0],[0]
"n. Assume
‖Xk‖2",A. Technical Lemmas,[0],[0]
"≤ R, almost surely for all k.
Define the predictable quadratic variation process
W k",A. Technical Lemmas,[0],[0]
":= k∑ j=1 Ej−1 [ X2j ] for all k,
where Ej−1 [ X2j ]
denotes the expectation ofX2j conditioning onX1, · · · ,Xj−1.",A. Technical Lemmas,[0],[0]
"Then, for all > 0 and σ2 > 0,
Pr ( ‖Y n‖2 ≥ and ‖W n‖2 ≤",A. Technical Lemmas,[0],[0]
"σ 2 )
≤",A. Technical Lemmas,[0],[0]
"d · exp ( − 2/2
σ2 +R /3
) .",A. Technical Lemmas,[0],[0]
"In large-scale machine learning applications and high-dimensional statistics, it is ubiquitous to address a considerable number of features among which many are redundant.",abstractText,[0],[0]
"As a remedy, online feature selection has attracted increasing attention in recent years.",abstractText,[0],[0]
It sequentially reveals features and evaluates the importance of them.,abstractText,[0],[0]
"Though online feature selection has proven an elegant methodology, it is usually challenging to carry out a rigorous theoretical characterization.",abstractText,[0],[0]
"In this work, we propose a provable online feature selection algorithm that utilizes the online leverage score.",abstractText,[0],[0]
"The selected features are then fed to k-means clustering, making the clustering step memory and computationally efficient.",abstractText,[0],[0]
"We prove that with high probability, performing k-means clustering based on the selected feature space does not deviate far from the optimal clustering using the original data.",abstractText,[0],[0]
The empirical results on realworld data sets demonstrate the effectiveness of our algorithm.,abstractText,[0],[0]
Provable Variable Selection for Streaming Features,title,[0],[0]
"We consider the following optimization problem
min z∈RM g(z)",1. Introduction,[0],[0]
":= N∑ i=1 fi(z), (1)
where each fi, i ∈ {1, · · · , N} := [N ] is a nonconvex cost function, and we assume that it is smooth and has Lipschitz continuous gradient.
",1. Introduction,[0],[0]
"Such a finite sum problem plays a central role in machine learning and signal/information processing (Cevher et al., 2014; Hong et al., 2016).",1. Introduction,[0],[0]
"In particular, in the class of empirical risk minimization (ERM) problem, z represents the feature vectors to be learned, and each fi can represent: 1) a mini-batch of (possibly nonconvex) loss functions modeling data fidelity (Antoniadis et al., 2009); 2) nonconvex activation functions of neural networks (Allen-Zhu & Hazan,
1Department of Industrial and Manufacturing Systems Engineering, Iowa State University, Ames, IA, USA 2College of Information Science and Electronic Engineering, Zhejiang University, China.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Mingyi Hong <mingyi@iastate.edu>, Davood Hajinezhad <dhaji@iastate.edu>, Ming-Min Zhao <zmmblack@zju.edu.cn>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
2016); 3) nonconvex utility functions used in applications such as resource allocation (Bjornson & Jorswieck, 2013).",1. Introduction,[0],[0]
"Recently, a number of works in machine learning community have been focused on designing fast algorithms for solving problem (1) in centralized setting; e.g., SAG (Defazio et al., 2014), SAGA (Schmidt et al., 2013), and SVRG (Johnson & Zhang, 2013) for convex problems, and (Reddi et al., 2016; Allen-Zhu & Hazan, 2016; Hajinezhad et al., 2016b; Rahimpour et al., 2016) for nonconvex problems.
",1. Introduction,[0],[0]
"In this work, we are interested in designing algorithms that solve problem (1) in a distributed manner.",1. Introduction,[0],[0]
"In particular, we focus on the scenario where each fi (or equivalently, each subset of data points in the ERM problem) is available locally at a given computing node i ∈",1. Introduction,[0],[0]
"[N ], and the nodes are connected via a network.",1. Introduction,[0],[0]
"Clearly, such distributed optimization and learning scenario is important for machine learning, because in contemporary applications such as document topic modeling and/or social network data analysis, oftentimes data corporas are stored in geographically distributed locations without any central controller managing the entire network of nodes; see (Forero et al., 2010; Yan et al., 2013; Rahmani & Atia, 2015; Aybat & Hamedani, 2016).
",1. Introduction,[0],[0]
Related Works.,1. Introduction,[0],[0]
Distributed convex optimization and learning has been thoroughly investigated in the literature.,1. Introduction,[0],[0]
"In (Nedic & Ozdaglar, 2009b), the authors propose a distributed subgradient algorithm (DSG), which allows the agents to jointly optimize problem (1).",1. Introduction,[0],[0]
"Subsequently, many variants of DSG have been proposed, either with special assumptions on the underlying graph, or having additional structures of the problem; see, e.g., (Lobel & Ozdaglar, 2011; Lobel et al., 2011; Nedic & Olshevsky, 2015).",1. Introduction,[0],[0]
The rate of convergence for DSG is O(log(r)/ √ r) under certain diminishing stepsize rules.,1. Introduction,[0],[0]
"Recently, a number of algorithms such as the exact first-order algorithm (EXTRA) (Shi et al., 2014) and DLM (Ling et al., 2015) have been proposed, which use constant stepsize and achieve faster O(1/r) rate for convex problems.",1. Introduction,[0],[0]
"Recent works that apply distributed optimization algorithms to machine learning applications include (Scardapane et al., 2016; Aybat & Hamedani, 2016; Scardapane & Lorenzo, 2016).
",1. Introduction,[0],[0]
"On the other hand, there has been little work for dis-
tributed optimization and learning when the objective function involves nonconvex problems.",1. Introduction,[0],[0]
"A dual subgradient method has been proposed in (Zhu & Martinez, 2010), which relaxes the exact consensus constraint.",1. Introduction,[0],[0]
"In (Bianchi & Jakubowicz, 2013) a stochastic projection algorithm using diminishing stepsizes has been proposed.",1. Introduction,[0],[0]
"An ADMM based algorithm has been presented in (Hong et al., 2014; Hajinezhad & Hong, 2015) for a special type of problem called global consensus, where all distributed nodes are directly connected to a central controller.",1. Introduction,[0],[0]
"Utilizing certain convexification decomposition technique the authors of (Lorenzo & Scutari, 2016) designed an algorithm named NEXT, which converges to the set of stationary solutions when using diminishing stepsizes.",1. Introduction,[0],[0]
"To the best of our knowledge, no multi agent distributed algorithm is able to guarantee global sublinear convergence rate for problem (1).
",1. Introduction,[0],[0]
Our Contributions.,1. Introduction,[0],[0]
"In this work, we propose a proximal primal-dual algorithm (Prox-PDA) for problem (1) over an undirected connected network.",1. Introduction,[0],[0]
We show that Prox-PDA converges to the set of stationary solutions of problem (1) (satisfying the first-order optimality condition) in a globally sublinear manner.,1. Introduction,[0],[0]
We also show that Prox-PDA can be extended in several directions to improve its practical performance.,1. Introduction,[0],[0]
"To the best of our knowledge, this is the first algorithm that is capable of achieving global sublinear convergence rate for distributed non-convex optimization.
",1. Introduction,[0],[0]
"Further, our work reveals an interesting connection between the primal-dual based algorithm Prox-PDA and the primal-only fast distributed algorithms such as EXTRA (Shi et al., 2014).",1. Introduction,[0],[0]
Such new insight of the connection between primal-dual and primal-only algorithms could be of independent interest for the optimization community.,1. Introduction,[0],[0]
"Finally, we generalize the theory for Prox-PDA based algorithms to a challenging distributed matrix factorization problem.",1. Introduction,[0],[0]
"Define a graph G := {V, E}, where V and E are the node and edge sets; Let |V| = N and |E| = E.",2. System Model,[0],[0]
"Each node v ∈ V represents an agent in the network, and each edge eij =",2. System Model,[0],[0]
"(i, j) ∈ E indicates that node i and j are neighbors; see Fig.1(Left).",2. System Model,[0],[0]
"Assume that each node i can only communicate with its immediate neighbors, defined as Ni := {j | (i, j) ∈ V}, with |Ni| = di.",2. System Model,[0],[0]
"The distributed version of problem (1) is given as below
min xi∈RM f(x) := N∑ i=1 fi(xi), s.t. xi = xj , ∀ (i, j) ∈ E .",2. System Model,[0],[0]
"(2)
Clearly the above problem is equivalent to (1) as long as G is connected.",2. System Model,[0],[0]
"For notational simplicity, define x := {xi} ∈ RNM×1, and Q := N ×M .
To proceed, let us introduce a few useful quantities related to graph G.
• The incidence matrix Ã ∈ RE×N is a matrix with entires Ã(k, i) = 1 and Ã(k, j) = −1",2. System Model,[0],[0]
"if k = (i, j) ∈ E with j >",2. System Model,[0],[0]
"i, and all the rest of the entries being zero.",2. System Model,[0],[0]
"For example, for the network in Fig.1 (Left); the incidence matrix is given in Fig.1 (Right).",2. System Model,[0],[0]
"Define the extended incidence matrix as
A := Ã⊗ IM ∈ REM×Q, (3)
where ⊗ denotes the Kronecker product.
",2. System Model,[0],[0]
•,2. System Model,[0],[0]
"The Degree matrix D̃ ∈ RN×N is given by D̃ := diag[d1, · · · , dN ]; Let D := D̃ ⊗ IM ∈ RQ×Q.
• The signed and the signless Laplacian matrices (denoted as L− and L+ respectively), are given below
L− := A>A ∈ RQ×Q, L+ := 2D −A>A ∈ RQ×Q.",2. System Model,[0],[0]
"(4)
Using the above notations, one can verify that problem (2) can be written in the following compact form
min x∈RQ f(x), s.t.",2. System Model,[0],[0]
Ax = 0. (5),2. System Model,[0],[0]
"The proposed algorithm builds upon the classical augmented Lagrangian (AL) method (Bertsekas, 1982; Powell, 1969).",3. The Prox-PDA Algorithm,[0],[0]
"Let us define the AL function for (5) as
Lβ(x, µ) = f(x) +",3. The Prox-PDA Algorithm,[0],[0]
"〈µ,Ax〉+ β
2 ‖Ax‖2, (6)
where µ ∈ RQ is the dual variable; β > 0 is a penalty parameter.",3. The Prox-PDA Algorithm,[0],[0]
Let B ∈ RQ×Q be some arbitrary matrix to be determined shortly.,3. The Prox-PDA Algorithm,[0],[0]
Then the proposed algorithm is given in the table below (Algorithm 1).,3. The Prox-PDA Algorithm,[0],[0]
"In Prox-PDA, the primal iteration (7a) minimizes the augmented Lagrangian plus a proximal term β2 ‖x",3. The Prox-PDA Algorithm,[0],[0]
"− x
r‖2BTB .",3. The Prox-PDA Algorithm,[0],[0]
We emphasize that the proximal term is critical in both the algorithm implementation and the analysis.,3. The Prox-PDA Algorithm,[0],[0]
It is used to ensure the following key properties: (1).,3. The Prox-PDA Algorithm,[0],[0]
The primal problem is strongly convex; (2).,3. The Prox-PDA Algorithm,[0],[0]
"The primal problem is decomposable over different network nodes, hence distributedly implementable.",3. The Prox-PDA Algorithm,[0],[0]
"To see the first point, suppose BTB is chosen such that ATA + BTB IQ, and that f(x) has Lipschitz gradient.",3. The Prox-PDA Algorithm,[0],[0]
"Then by a result in (Zlobec, 2005)[Theorem 2.1], we know
Algorithm 1",3. The Prox-PDA Algorithm,[0],[0]
"The Prox-PDA Algorithm
1: At iteration 0, initialize µ0 = 0 and x0 ∈ RQ.",3. The Prox-PDA Algorithm,[0],[0]
"2: At each iteration r + 1, update variables by:
xr+1 = arg min x∈RQ f(x) +",3. The Prox-PDA Algorithm,[0],[0]
"〈µr, Ax〉+ β 2 ‖Ax‖2
+ β
2 ‖x− xr‖2BTB ; (7a)
µr+1 = µr + βAxr+1.",3. The Prox-PDA Algorithm,[0],[0]
"(7b)
that there exists β > 0",3. The Prox-PDA Algorithm,[0],[0]
large enough such that the objective function of (7a) is strongly convex.,3. The Prox-PDA Algorithm,[0],[0]
"To see the second point, Let B := |A|, where the absolute value is taken for each component of A. It can be verified that BTB = L+, and step (7a) becomes
xr+1 = argmin x N∑ i=1 fi(xi)",3. The Prox-PDA Algorithm,[0],[0]
"+ 〈µr, Ax〉
+",3. The Prox-PDA Algorithm,[0],[0]
β,3. The Prox-PDA Algorithm,[0],[0]
2,3. The Prox-PDA Algorithm,[0],[0]
"xTL−x+ β 2 (x− xr)TL+(x− xr)
= argmin x N∑ i=1 fi(xi)",3. The Prox-PDA Algorithm,[0],[0]
"+ 〈µr, Ax〉+ βxTDx− βxTL+xr.
",3. The Prox-PDA Algorithm,[0],[0]
"Clearly this problem is separable over the nodes, therefore it can be solved completely distributedly.",3. The Prox-PDA Algorithm,[0],[0]
In this section we provide convergence analysis for Algorithm 1.,4. The Convergence Analysis,[0],[0]
"The key in the analysis is the construction of a novel potential function, which decreases at every iteration of the algorithm.",4. The Convergence Analysis,[0],[0]
"In particular, the constructed potential function is a conic combination of the AL function and the size of the violation of the consensus constraint, therefore it measures the progress of both the primal and dual updates.
",4. The Convergence Analysis,[0],[0]
"We first state our main assumptions below.
",4. The Convergence Analysis,[0],[0]
[A1.],4. The Convergence Analysis,[0],[0]
"The function f(x) is differentiable and has Lipschitz continuous gradient, i.e.,
‖∇f(x)−∇f(x)‖ ≤",4. The Convergence Analysis,[0],[0]
"L‖x− y‖, ∀ x, y ∈ RQ.
",4. The Convergence Analysis,[0],[0]
"Further assume that ATA+BTB IQ.
",4. The Convergence Analysis,[0],[0]
[A2.],4. The Convergence Analysis,[0],[0]
There exists a constant δ > 0,4. The Convergence Analysis,[0],[0]
"such that
∃ f > −∞, s.t. f(x) + δ 2 ‖Ax‖2 ≥ f, ∀ x ∈ RQ.
",4. The Convergence Analysis,[0],[0]
Without loss of generality we will assume that f = 0.,4. The Convergence Analysis,[0],[0]
"Below we provide a few nonconvex smooth functions that satisfy our assumptions, all of which are commonly used as activation functions for neural networks.
",4. The Convergence Analysis,[0],[0]
•,4. The Convergence Analysis,[0],[0]
The sigmoid function sigmoid(x) = 11+e−x .,4. The Convergence Analysis,[0],[0]
• The arctan and tanh function.,4. The Convergence Analysis,[0],[0]
•,4. The Convergence Analysis,[0],[0]
"The logit function logit(x) = e x
ex+1 .",4. The Convergence Analysis,[0],[0]
Below we provide the analysis of Prox-PDA.,4.1. The Analysis Steps,[0],[0]
First we provide a bound on the size of the constraint violation using a quantity related to the primal iterates.,4.1. The Analysis Steps,[0],[0]
"Let σmin denotes the smallest non-zero eigenvalue of ATA, and we define wr := (xr+1−xr)−(xr−xr−1) for notational simplicity.",4.1. The Analysis Steps,[0],[0]
We have the following result.,4.1. The Analysis Steps,[0],[0]
Lemma 1 Suppose Assumptions [A1] and [A2] are satisfied.,4.1. The Analysis Steps,[0],[0]
"Then the following is true for Prox-PDA
1 β ‖µr+1",4.1. The Analysis Steps,[0],[0]
"− µr‖2
≤ 2L 2
βσmin ∥∥xr",4.1. The Analysis Steps,[0],[0]
− xr+1∥∥2 + 2β,4.1. The Analysis Steps,[0],[0]
σmin ‖BTBwr‖2.,4.1. The Analysis Steps,[0],[0]
"(8)
Then we bound the descent of the AL function.",4.1. The Analysis Steps,[0],[0]
Lemma 2 Suppose Assumptions [A1] and [A2] are satisfied.,4.1. The Analysis Steps,[0],[0]
"Then the following is true for Algorithm 1
Lβ(x r+1, µr+1)− Lβ(xr, µr) ≤ 2β‖BTB‖ σmin ‖wr‖2BTB
− ( β − L
2 − 2L
2
βσmin
) ‖xr+1",4.1. The Analysis Steps,[0],[0]
"− xr‖2. (9)
",4.1. The Analysis Steps,[0],[0]
"A key observation from Lemma 2 is that no matter how large β is, the rhs of (9) cannot be made negative.",4.1. The Analysis Steps,[0],[0]
"This observation suggests that in contrast to (Hong et al., 2014; Hajinezhad et al., 2016a) the augmented Lagrangian alone cannot serve as the potential function for Prox-PDA.",4.1. The Analysis Steps,[0],[0]
"In search for an appropriate potential function, we need a new object that is decreasing in the order of β ‖wr‖2BTB .",4.1. The Analysis Steps,[0],[0]
"The following lemma shows that the descent of the sum of the constraint violation and the proximal term has the desired property.
",4.1. The Analysis Steps,[0],[0]
Lemma 3 Suppose Assumption,4.1. The Analysis Steps,[0],[0]
[A1] is satisfied.,4.1. The Analysis Steps,[0],[0]
"Then the following is true
β
2
( ‖Axr+1‖2 + ‖xr+1",4.1. The Analysis Steps,[0],[0]
− xr‖2BTB ),4.1. The Analysis Steps,[0],[0]
≤,4.1. The Analysis Steps,[0],[0]
L‖xr+1,4.1. The Analysis Steps,[0],[0]
"− xr‖2 + β
2
( ‖Axr‖2 + ‖xr − xr−1‖2BTB )",4.1. The Analysis Steps,[0],[0]
"− β
2
( ‖wr‖2BTB + ‖A(x r+1 − xr)‖2 ) .",4.1. The Analysis Steps,[0],[0]
"(10)
It is interesting to observe that the new object, β/2",4.1. The Analysis Steps,[0],[0]
( ‖Axr+1‖2 + ‖xr+1,4.1. The Analysis Steps,[0],[0]
"− xr‖2BTB ) , increases in L‖xr+1 − xr‖2 and decreases in β/2‖wr‖2BTB , while the AL behaves in an opposite manner (cf. Lemma 2).",4.1. The Analysis Steps,[0],[0]
"More importantly, in our new object, the constant in front of ‖xr+1",4.1. The Analysis Steps,[0],[0]
− xr‖2 is independent of β.,4.1. The Analysis Steps,[0],[0]
"Although neither of these two objects decreases by itself, quite surprisingly, a proper conic combination of these two objects decreases at every iteration of Prox-PDA.",4.1. The Analysis Steps,[0],[0]
"To precisely state the claim, let us define the potential function for Algorithm 1 as
Pc,β(x r+1, xr, µr+1) := Lβ(x r+1, µr+1)
+ cβ
2
( ‖Axr+1‖2 + ‖xr+1",4.1. The Analysis Steps,[0],[0]
"− xr‖2BTB ) , (11)
",4.1. The Analysis Steps,[0],[0]
where c > 0 is some constant to be determined later.,4.1. The Analysis Steps,[0],[0]
"We have the following result.
",4.1. The Analysis Steps,[0],[0]
Lemma 4 Suppose the assumptions made in Lemmas 1 – 3 are satisfied.,4.1. The Analysis Steps,[0],[0]
"Then we have the following
Pc,β(x r+1, xr, µr+1) ≤",4.1. The Analysis Steps,[0],[0]
"Pc,β(xr, xr−1, µr) − ( β − L
2 − 2L
2
βσmin − cL
) ‖xr+1",4.1. The Analysis Steps,[0],[0]
"− xr‖2
− ( cβ
2 − 2β‖B TB‖F σmin
) ‖wr‖2BTB .",4.1. The Analysis Steps,[0],[0]
"(12)
From the above analysis, it is easy to see that as long as c and β are sufficiently large, the potential function decreases at each iteration of Prox-PDA.",4.1. The Analysis Steps,[0],[0]
Below we derive the precise bounds for c and β.,4.1. The Analysis Steps,[0],[0]
"First, a sufficient condition for c is given below (note, that δ",4.1. The Analysis Steps,[0],[0]
"> 0 is defined in Assumption [A2])
",4.1. The Analysis Steps,[0],[0]
"c ≥ max { δ
L , 4‖BTB‖F σmin
} .",4.1. The Analysis Steps,[0],[0]
"(13)
",4.1. The Analysis Steps,[0],[0]
"Second, for any given c, we need β to satisfy β−L2",4.1. The Analysis Steps,[0],[0]
"− 2L2
βσmin − cL > 0, which implies the following
β > L
2 2c+ 1 +√(2c+ 1)2 + 16L2 σmin  .",4.1. The Analysis Steps,[0],[0]
"(14) We conclude that if both (13) and (14) are satisfied, then the potential function Pc,β(xr+1, xr, µr+1) decreases at every iteration.
",4.1. The Analysis Steps,[0],[0]
"Our next step shows that by using the particular choices of c and β in (13) and (14), the constructed potential function is lower bounded.
",4.1. The Analysis Steps,[0],[0]
"Lemma 5 Suppose [A1] - [A2] are satisfied, and (c, β) are chosen according to (13) and (14).",4.1. The Analysis Steps,[0],[0]
"Then the following statement holds true
∃ P > −∞ s.t.",4.1. The Analysis Steps,[0],[0]
"Pc,β(xr+1, xr, µr+1) ≥ P , ∀ r > 0.",4.1. The Analysis Steps,[0],[0]
Now we are ready to present the main result of this section.,4.1. The Analysis Steps,[0],[0]
"To this end, define Q(xr+1, µr) as the optimality gap of problem (5), given by
Q(xr+1, µr) := ‖∇xLβ(xr+1, µr)‖2 + ‖Axr+1‖2. (15)
",4.1. The Analysis Steps,[0],[0]
"It is easy to see that Q(xr+1, µr) → 0 implies that any limit point (x∗, µ∗), if it exists, is a KKT point of (5) that satisfies the following conditions
0 = ∇f(x∗) +ATµ∗, Ax∗ = 0.",4.1. The Analysis Steps,[0],[0]
"(16)
In the following we show that the gap Q(·) not only decreases to zero, but does so in a sublinear manner.
",4.1. The Analysis Steps,[0],[0]
Theorem 1 Suppose Assumption A and the conditions (13) and (14) are satisfied.,4.1. The Analysis Steps,[0],[0]
"Then we have • Eventual Consensus:
lim r→∞ µr+1 − µr → 0, lim r→∞ Axr → 0.
• Convergence to Stationary Points: Every limit point of the iterates {xr, µr} generated by Algorithm 1 converges to a KKT point of problem (5).",4.1. The Analysis Steps,[0],[0]
"Further, Q(xr+1, µr)→ 0.",4.1. The Analysis Steps,[0],[0]
•,4.1. The Analysis Steps,[0],[0]
"Sublinear Convergence Rate: For any given ϕ > 0, let us define T to be the first time that the optimality gap reaches below ϕ, i.e.,
T := arg min r Q(xr+1, µr) ≤",4.1. The Analysis Steps,[0],[0]
"ϕ.
",4.1. The Analysis Steps,[0],[0]
"Then for some ν > 0, we have ϕ ≤ νT−1 .",4.1. The Analysis Steps,[0],[0]
"That is, the optimality gap Q(xr+1, µr) converges sublinearly.",4.1. The Analysis Steps,[0],[0]
"In this section, we discuss two important extensions of the Prox-PDA, one allows the x-problem (7a) to be solved inexactly, while the second allows the use of increasing penalty parameter β.",5. Variants of Prox-PDA,[0],[0]
"In many practical applications, exactly minimizing the augmented Lagrangian may not be easy.",5. Variants of Prox-PDA,[0],[0]
"Therefore, we propose the proximal gradient primaldual algorithm (Prox-GPDA), whose main steps are given below
xr+1 = arg min x∈RQ 〈∇f(xr), x− xr〉+ 〈µr, Ax〉
+ β 2 ‖Ax‖2 + β 2 ‖x− xr‖2BTB ; (17) µr+1 = µr + βAxr+1.",5. Variants of Prox-PDA,[0],[0]
"(18)
",5. Variants of Prox-PDA,[0],[0]
The analysis of this algorithm follows similar steps as that for Prox-PDA.,5. Variants of Prox-PDA,[0],[0]
"For detailed discussion see (Hong, 2016).
",5. Variants of Prox-PDA,[0],[0]
Our second variant do not require to explicitly compute the bound for β given in (14).,5. Variants of Prox-PDA,[0],[0]
"Indeed, the bounds on β derived in the previous sections are the worst case bounds, and algorithms that use stepsizes that strictly satisfy such bounds may be slow at the beginning.",5. Variants of Prox-PDA,[0],[0]
"In practice, one may prefer to start with a small penalty parameter and gradually increase it.",5. Variants of Prox-PDA,[0],[0]
"We denote this algorithm by Prox-PDA-IP, whose main steps are given below
xr+1 = arg min x∈RQ f(x) +",5. Variants of Prox-PDA,[0],[0]
"〈µr, Ax〉
+ βr+1 2 ‖Ax‖2 + β r+1 2 ‖x− xr‖2BTB ; (19)
µr+1 = µr + βr+1Axr+1. (20)
",5. Variants of Prox-PDA,[0],[0]
"Note that one can also replace f(x) in (19) by 〈∇f(xr), x− xr〉 to obtain a similar variant for Prox-GPDA denoted by Prox-GPDA-IP.",5. Variants of Prox-PDA,[0],[0]
"Throughout this section we will still as-
sume that Assumption A holds true.",5. Variants of Prox-PDA,[0],[0]
"Further, we will assume that βr satisfies the following conditions
1
βr → 0, ∞∑ r=1 1 βr =∞, βr+1 ≥ βr,
max r
(βr+1 − βr) < κ, for some finite κ > 0.",5. Variants of Prox-PDA,[0],[0]
"(21)
Also without loss of generality we will assume that
BTB 0, and ‖BTB‖F > 1.",5. Variants of Prox-PDA,[0],[0]
"(22)
Note that this is always possible, by adding an identity matrix to BTB if necessary.
",5. Variants of Prox-PDA,[0],[0]
"The analysis for Prox-PDA-IP is long and technical, therefore we refer the readers to (Hong, 2016).",5. Variants of Prox-PDA,[0],[0]
"The key step is to construct a new potential function, given below
Pβr+1,c(x r+1, xr, µr+1) = Lβr+1(x r+1, µr+1)
+",5. Variants of Prox-PDA,[0],[0]
cβr+1βr 2,5. Variants of Prox-PDA,[0],[0]
"‖Axr+1‖2 + cβ r+1βr 2 ‖xr − xr+1‖2BTB .
",5. Variants of Prox-PDA,[0],[0]
"The insight here is that in order to achieve the desired descent, in the potential function the coefficients for ‖xr+1− xr‖2BTB and ‖Ax
r+1‖2 should be proportional to O ( (βr)2 ) .",5. Variants of Prox-PDA,[0],[0]
"We have the following theorem regarding to the convergence of Prox-PDA-IP.
",5. Variants of Prox-PDA,[0],[0]
Theorem 2 Suppose Assumption A and (21) are satisfied.,5. Variants of Prox-PDA,[0],[0]
Suppose that B is selected such that (22) holds true.,5. Variants of Prox-PDA,[0],[0]
"Then the following hold for Prox-PDA-IP
• Eventual Consensus: lim r→∞ µr+1 − µr → 0, lim r→∞",5. Variants of Prox-PDA,[0],[0]
"Axr → 0.
",5. Variants of Prox-PDA,[0],[0]
"• Convergence to KKT Points: Every limit point of the iterates {xr, µr} generated by Prox-PDA-IP converges to a KKT point of problem (5).",5. Variants of Prox-PDA,[0],[0]
"Further, Q(xr+1, µr)→ 0.",5. Variants of Prox-PDA,[0],[0]
"In this section we present an interesting observation which establishes links between the so-called EXTRA algorithm (Shi et al., 2014) (developed for distributed, but convex optimization) and the Prox-GPDA.
",6. Connections and Discussions,[0],[0]
"Specifically, the optimality condition of the x-update step (17) is given by
∇f(xr) +AT (µr + βAxr+1) + β(BTB(xr+1",6. Connections and Discussions,[0],[0]
− xr)),6. Connections and Discussions,[0],[0]
"= 0.
Utilizing the fact that ATA = L−, BTB = L+ and L+ + L− = 2D, we have
∇f(xr) +ATµr + 2βDxr+1",6. Connections and Discussions,[0],[0]
"− βL+xr = 0.
",6. Connections and Discussions,[0],[0]
"Subtracting the same equation evaluated at the previous iteration, we obtain
∇f(xr)−∇f(xr−1) + βL−xr + 2βD(xr+1 − xr) − βL+(xr − xr−1) = 0,
where we have used the fact that AT (µr − µr−1) = βATAxr",6. Connections and Discussions,[0],[0]
= βL−xr.,6. Connections and Discussions,[0],[0]
"Rearranging terms, we have
xr+1 = xr",6. Connections and Discussions,[0],[0]
"− 1 2β D−1
( ∇f(xr)−∇f(xr−1) )",6. Connections and Discussions,[0],[0]
"+ 1
2 D−1(L+ − L−)xr",6. Connections and Discussions,[0],[0]
"− 1 2 D−1L+xr−1
= xr",6. Connections and Discussions,[0],[0]
"− 1 2β D−1
( ∇f(xr)−∇f(xr−1) )",6. Connections and Discussions,[0],[0]
"+Wxr
− 1 2 (I +W )xr−1, (23)
where in the last equality we have defined the weight matrix W := 12D
−1(L+ − L−), which is a row stochastic matrix.
",6. Connections and Discussions,[0],[0]
"Iteration (23) has the same form as the EXTRA algorithm given in (Shi et al., 2014), therefore we can conclude that EXTRA is a special case of Prox-GPDA.",6. Connections and Discussions,[0],[0]
"Moreover, by appealing to our analysis in Section 5, it readily follows that EXTRA works for the nonconvex distributed optimization problem as well.
",6. Connections and Discussions,[0],[0]
"We remark that each node i can distributedly implement iteration (23) by performing the following
xr+1i = x r",6. Connections and Discussions,[0],[0]
"i −
1
2βdi
( ∇fi(xri )",6. Connections and Discussions,[0],[0]
−∇fi(xr−1i ) ),6. Connections and Discussions,[0],[0]
"+ ∑
j∈N (i)
1 di xrj",6. Connections and Discussions,[0],[0]
− 1 2  ∑ j∈N (i) 1,6. Connections and Discussions,[0],[0]
di xr−1j + x,6. Connections and Discussions,[0],[0]
r−1 i  .,6. Connections and Discussions,[0],[0]
"(24) Clearly, at iteration r + 1, besides the local gradient information, node i only needs the aggregated information from its neighbors, ∑ j∈N (i) x",6. Connections and Discussions,[0],[0]
r j .,6. Connections and Discussions,[0],[0]
Therefore the algorithm is distributedly implementable.,6. Connections and Discussions,[0],[0]
"In this section we study a variant of the Prox-PDA/ProxPDA-IP for the following distributed matrix factorization problem (Ling et al., 2012)
min X,Y
1 2 ‖XY",7. Distributed Matrix Factorization,[0],[0]
"− Z‖2F + η‖X‖2F + h(Y ) (25)
=",7. Distributed Matrix Factorization,[0],[0]
"N∑ i=1 1 2 ‖Xyi − zi‖2 + γ‖X‖2F + hi(yi),
s.t. ‖yi‖2 ≤ τ, ∀",7. Distributed Matrix Factorization,[0],[0]
"i
where X ∈ RM×K , Y ∈ RK×N ; for each i, yi ∈ RK consists of one column of Y ; Z ∈",7. Distributed Matrix Factorization,[0],[0]
"RM×N is some known matrix; h(Y ) := ∑N i=1 hi(yi) is some convex but possibly nonsmooth penalization term; η > 0 is some given constant; for notation simplicity we have defined γ := 1/Nη.
",7. Distributed Matrix Factorization,[0],[0]
"It is easy to extend the above formulation to the case where Y and Z both have NP columns, and each yi and zi consists of P columns of Y and Z respectively.
",7. Distributed Matrix Factorization,[0],[0]
We assume that h(Y ) is lower bounded over dom (h).,7. Distributed Matrix Factorization,[0],[0]
"One application of problem (25) is the distributed sparse dictionary learning problem where X is the dictionary to be learned, each zi is a training data sample, and each yi is the sparse coefficient corresponding to the particular training sample zi.",7. Distributed Matrix Factorization,[0],[0]
"The constraint ‖yi‖2 ≤ τ simply says that the size of the coefficient must be bounded.
",7. Distributed Matrix Factorization,[0],[0]
"Consider a distributed scenario where N agents form a graph {V, E}, each having a column of Y .",7. Distributed Matrix Factorization,[0],[0]
"We reformulate problem (25) as
min {Xi},{yi} N∑ i=1",7. Distributed Matrix Factorization,[0],[0]
( 1 2 ‖Xiyi,7. Distributed Matrix Factorization,[0],[0]
− zi‖2 + hi(yi),7. Distributed Matrix Factorization,[0],[0]
"+ γ‖Xi‖2F ) s.t. ‖yi‖2 ≤ τ, ∀",7. Distributed Matrix Factorization,[0],[0]
"i Xi = Xj , ∀",7. Distributed Matrix Factorization,[0],[0]
"(i, j) ∈ E .
",7. Distributed Matrix Factorization,[0],[0]
"Let us stack all the variables Xi, and define X :=",7. Distributed Matrix Factorization,[0],[0]
[X1;X2; · · · ;XN ] ∈ RNM×K .,7. Distributed Matrix Factorization,[0],[0]
"Define the block signed incidence matrix as A = Ã ⊗ IM ∈ REM×NM , where A is the standard graph incidence matrix.",7. Distributed Matrix Factorization,[0],[0]
Define the block signless incidence matrix B ∈ REM×NM similarly.,7. Distributed Matrix Factorization,[0],[0]
"If the graph is connected, then the condition AX = 0 implies network-wide consensus.",7. Distributed Matrix Factorization,[0],[0]
"We formulate the distributed matrix factorization problem as
min {Xi},{yi} f(X, Y ) + h(Y )
:= N∑ i=1",7. Distributed Matrix Factorization,[0],[0]
( 1 2 ‖Xiyi,7. Distributed Matrix Factorization,[0],[0]
"− zi‖2 + γ‖Xi‖2F + hi(yi) ) s.t. ‖yi‖2 ≤ τ, ∀",7. Distributed Matrix Factorization,[0],[0]
i AX = 0.,7. Distributed Matrix Factorization,[0],[0]
"(26)
Clearly the above problem does not satisfy Assumption A, because the objective function is not smooth, and neither ∇Xf(X, Y ) nor ∇Y f(X, Y ) is Lipschitz continuous.",7. Distributed Matrix Factorization,[0],[0]
The latter fact poses significant difficulty in algorithm development and analysis.,7. Distributed Matrix Factorization,[0],[0]
"Define the block-signed/signless Laplacians as
L− = ATA, L+ = BTB.",7. Distributed Matrix Factorization,[0],[0]
"(27)
",7. Distributed Matrix Factorization,[0],[0]
"The AL function for the above problem is given by
Lβ(X, Y,Ω) = N∑ i=1",7. Distributed Matrix Factorization,[0],[0]
( 1 2 ‖Xiyi,7. Distributed Matrix Factorization,[0],[0]
− zi‖2 + γ‖Xi‖2F + hi(yi) ),7. Distributed Matrix Factorization,[0],[0]
+,7. Distributed Matrix Factorization,[0],[0]
"〈Ω,AX〉+ β
2 〈AX,AX〉, (28)
",7. Distributed Matrix Factorization,[0],[0]
"where Ω := {Ωe} ∈ REM×K is the matrix of the dual variable, with Ωe ∈ RM×K being the dual variable for the consensus constraint on link e, i.e, Xi = Xj , e = (i, j).
",7. Distributed Matrix Factorization,[0],[0]
Let us generalize Algorithm 1 for distributed matrix factorization given in Algorithm 2.,7. Distributed Matrix Factorization,[0],[0]
"In Algorithm 2 we have introduced a sequence {θri ≥ 0} which measures the size
Algorithm 2 Prox-PDA for Distr.",7. Distributed Matrix Factorization,[0],[0]
"Matrix Factorization
1: At iteration 0, initialize Ω0 = 0, and X0, y0 2:",7. Distributed Matrix Factorization,[0],[0]
"At each iteration r + 1, update variables by:
θri = ‖Xri yri − zi‖2, ∀",7. Distributed Matrix Factorization,[0],[0]
"i; (29a)
yr+1i = arg min ‖yi‖2≤τ
1 2 ‖Xri yi",7. Distributed Matrix Factorization,[0],[0]
"− zi‖2 + hi(yi)
+ θri 2 ‖yi − yri ‖2, ∀ i; (29b)
Xr+1 = argmin X f(X, Y r+1) +",7. Distributed Matrix Factorization,[0],[0]
"〈Ωr,AX〉 (29c)
+ β 2 〈AX,AX〉+ β 2 〈B(X −Xr),B(X −Xr)〉;
Ωr+1 = Ωr + βAXr+1.",7. Distributed Matrix Factorization,[0],[0]
"(29d)
of the local factorization error.",7. Distributed Matrix Factorization,[0],[0]
"We note that including the proximal term θ r i
2 ‖yi − y r i ‖2 is the key to achieve conver-
gence for Algorithm 2.
Let us comment on the distributed implementation of the algorithm.",7. Distributed Matrix Factorization,[0],[0]
"First note that the y subproblem (29b) is naturally distributed to each node, that is, only local information is needed to perform the update.",7. Distributed Matrix Factorization,[0],[0]
"Second, the X subproblem (29c) can also be decomposed into N subproblems, one for each node.",7. Distributed Matrix Factorization,[0],[0]
"To be more precise, let us examine the terms in (29c) one by one.",7. Distributed Matrix Factorization,[0],[0]
"First, the term f(X, Y r+1) =∑N i=1",7. Distributed Matrix Factorization,[0],[0]
( 1 2‖Xiy r+1 i − zi‖2 + hi(y r+1 i ),7. Distributed Matrix Factorization,[0],[0]
"+ γ‖Xi‖2F ) , hence it is decomposable.",7. Distributed Matrix Factorization,[0],[0]
"Second, the term 〈Ωr,AX〉 can be expressed as
〈Ωr,AX〉 = N∑ i=1 ∑ e∈U(i) 〈Ωre, Xi〉 − ∑ e∈H(i) 〈Ωre, Xi〉
where the sets U(i) and H(i) are defined as U(i) := {e | e =",7. Distributed Matrix Factorization,[0],[0]
"(i, j) ∈ E , i ≥ j}, H(i) :",7. Distributed Matrix Factorization,[0],[0]
"= {e | e = (i, j) ∈ E , j ≥ i}.
",7. Distributed Matrix Factorization,[0],[0]
"Similarly, we have 〈BXr,BX〉 = N∑ i=1
〈 Xi, diX r i + ∑ j∈N(i)",7. Distributed Matrix Factorization,[0],[0]
"Xrj 〉 β 2 (〈AX,AX〉+ 〈BX,BX〉)
= β〈DX,X〉 = β N∑ i=1",7. Distributed Matrix Factorization,[0],[0]
"di‖Xi‖2F ,
where D := D̃ ⊗ IM ∈ RNM×NM with D̃ being the degree matrix.",7. Distributed Matrix Factorization,[0],[0]
It is easy to see that the X subproblem (29c) is separable over the distributed agents.,7. Distributed Matrix Factorization,[0],[0]
"Finally, one can verify that the Ω update step (29d) can be implemented by each edge e ∈ E as follows
Ωr+1e",7. Distributed Matrix Factorization,[0],[0]
=,7. Distributed Matrix Factorization,[0],[0]
Ω r e + β,7. Distributed Matrix Factorization,[0],[0]
"( Xr+1i −X r+1 j ) , e = (i, j), i ≥ j.
To show convergence rate of the algorithm, we need the following definition Q(Xr+1, Y r+1,Ωr) := β‖AXr+1‖2 + ‖[Zr+11 ;Z r+1 2 ]‖ 2,
where we have defined Zr+11 := ∇XLβ(X r+1, Y r+1,Ωr);",7. Distributed Matrix Factorization,[0],[0]
"Zr+12 := Y r+1
− proxh+ι(Y) [ Y r+1 −∇Y",7. Distributed Matrix Factorization,[0],[0]
"( Lβ(X r+1, Y r+1,Ωr)− h(Y ) )] .
",7. Distributed Matrix Factorization,[0],[0]
"In the above expression, we have used Y :=⋃ i { ‖yi‖2 ≤ τ } to denote the feasible set of Y , and used ι(Y) to denote the indicator function of such set.",7. Distributed Matrix Factorization,[0],[0]
"Similarly as in Section 4, we can show that Q(Xr+1, Y r+1,Ωr) → 0 implies that every limit point of (Xr+1, Y r+1,Ωr) is a KKT point of problem (26).
",7. Distributed Matrix Factorization,[0],[0]
Next we present the main convergence analysis for Algorithm 2.,7. Distributed Matrix Factorization,[0],[0]
"The proof is long and technical, therefore we refer the readers to (Hong, 2016).
",7. Distributed Matrix Factorization,[0],[0]
Theorem 3 Consider using Algorithm 2 to solve the distributed matrix factorization problem (26).,7. Distributed Matrix Factorization,[0],[0]
"Suppose that h(Y ) is lower bounded over dom h(x), and that the penalty parameter β, together with two positive constants c and d, satisfies the following conditions
β + 2γ 2 − 8(τ
2 + 4γ2)
βσmin",7. Distributed Matrix Factorization,[0],[0]
"− cd 2 > 0,
1 2 − 8 σminβ − c d > 0, 1 2 − 8τ σminβ − cτ d > 0,
cβ 2 − 2β‖B TB‖ σmin > 0.
(30)
",7. Distributed Matrix Factorization,[0],[0]
"Then in the limit, consensus will be achieved, i.e.,
lim r→∞
‖Xri −Xrj ‖ = 0, ∀ (i, j) ∈ E .
",7. Distributed Matrix Factorization,[0],[0]
"Further, the sequences {Xr+1} and {Ωr+1} are both bounded, and every limit point generated by Algorithm 2 is a KKT point of problem (25).
",7. Distributed Matrix Factorization,[0],[0]
"Additionally, Algorithm 2 converges sublinearly.",7. Distributed Matrix Factorization,[0],[0]
"Specifically, for any given ϕ > 0, define T to be the first time that the optimality gap reaches below ϕ, i.e.,
T := argmin r
Q(Xr+1, Y r+1,Ωr) ≤",7. Distributed Matrix Factorization,[0],[0]
"ϕ.
",7. Distributed Matrix Factorization,[0],[0]
Then for some constant ν > 0,7. Distributed Matrix Factorization,[0],[0]
we have ϕ ≤ νT−1 .,7. Distributed Matrix Factorization,[0],[0]
"We can see that it is always possible to find the tuple {β, c, d > 0} that satisfies (30): c can be solely determined by the last inequality; for fixed c, the constant d needs to be chosen large enough such that 1/2 − cd > 0 and",7. Distributed Matrix Factorization,[0],[0]
1/2 − cτd > 0 are satisfied.,7. Distributed Matrix Factorization,[0],[0]
"After c and d are fixed, one can always choose β large enough to satisfy the first three conditions.",7. Distributed Matrix Factorization,[0],[0]
"In practice, we typically prefer to choose β as small as possible to improve the convergence speed.",7. Distributed Matrix Factorization,[0],[0]
"Therefore empirically one can start with (for some small ν > 0): c = 4‖B
TB‖ σmin + ν, d = max{4, 2cτ}, and then
gradually increase d to find an appropriate β that satisfies the first three conditions.
",7. Distributed Matrix Factorization,[0],[0]
We remark that Algorithm 2 can be extended to the case with increasing penalty.,7. Distributed Matrix Factorization,[0],[0]
Due to the space limitation we omit the details here.,7. Distributed Matrix Factorization,[0],[0]
"In this section, we demonstrate the performance of the proposed algorithms.",8. Numerical Results,[0],[0]
All experiments are performed in Matlab (2016b) on a desktop with an Intel Core(TM) i5-4690 CPU (3.50 GHz) and 8GB RAM running Windows 7.,8. Numerical Results,[0],[0]
"In this subsection, we study the problem of binary classification using nonconvex regularizers in the mini-bach setup i.e. each node stores b (batch size) data points, and each component function is given by
fi(xi)",8.1. Distributed Binary Classification,[0],[0]
"= 1
Nb [ b∑ j=1 log(1 + exp(−yijxTi vij))",8.1. Distributed Binary Classification,[0],[0]
+ M∑,8.1. Distributed Binary Classification,[0],[0]
k=1,8.1. Distributed Binary Classification,[0],[0]
"λαx2i,k 1 + αx2i,k ]
where vij ∈ RM and yij ∈ {1,−1} are the feature vector and the label for the jth date point in ith agent (Antoniadis et al., 2009).",8.1. Distributed Binary Classification,[0],[0]
"We use the parameter settings of λ = 0.001, α = 1 and M = 10.",8.1. Distributed Binary Classification,[0],[0]
"We randomly generated 100, 000 data points and distribute them into N = 20 nodes (i.e. b = 5000).",8.1. Distributed Binary Classification,[0],[0]
"We use the optimality gap (opt-gap) and constraint violation (con-vio), displayed below, to measure the quality of the solution generated by different algorithms
opt-gap := ∥∥∥∥ N∑ i=1",8.1. Distributed Binary Classification,[0],[0]
∇fi(zi),8.1. Distributed Binary Classification,[0],[0]
"∥∥∥∥2 + ‖Ax‖2, con-vio = ‖Ax‖2.
",8.1. Distributed Binary Classification,[0],[0]
"We compare the the Prox-GPDA, and Prox-GPDA-IP with the distributed subgradient (DSG) method (Nedic & Ozdaglar, 2009a;b) (which is only known to work for convex cases) and the Push-sum algorithm (Tatarenko & Touri, 2015).",8.1. Distributed Binary Classification,[0],[0]
The performance of all three algorithms in terms of the consensus error and the optimality gap (averaged over 30 problem instances) are presented in Fig. 2.,8.1. Distributed Binary Classification,[0],[0]
"The penalty parameter for Prox-GPDA is chosen such that satisfy (14), and βr for Prox-GPDA-IP is set as 0.05 log(r), the stepsizes of the DSG algorithm and the Push-sum algorithm are chosen as 1/0.05 log(r) and 1/r, respectively.",8.1. Distributed Binary Classification,[0],[0]
Note that these parameters are tuned for each algorithm to achieve the best results.,8.1. Distributed Binary Classification,[0],[0]
All Algorithms will stop after 1000 iterations.,8.1. Distributed Binary Classification,[0],[0]
It can be observed that the Prox-GPDA with constant stepsize outperforms other algorithms.,8.1. Distributed Binary Classification,[0],[0]
"The Push-sum algorithm does not seem to converge within 1000 iterations.
",8.1. Distributed Binary Classification,[0],[0]
"To see more results, we compare different algorithms with different number of agents in the network (N ).",8.1. Distributed Binary Classification,[0],[0]
The problem and the algorithms setup are set as the previous case.,8.1. Distributed Binary Classification,[0],[0]
We measure the optimality gap as well as the constraint violation and the results are respectively reported in Table 1 and Table 2.,8.1. Distributed Binary Classification,[0],[0]
"In the tables Alg1, Alg2, Alg3, Alg4
denote Prox-GPDA, Prox-GPDA-IP, DGS, and Push-sum algorithms respectively.",8.1. Distributed Binary Classification,[0],[0]
"As seen, the performance of the proposed algorithms (Alg1, Alg2) are significantly better than DGS and Push-Sum.",8.1. Distributed Binary Classification,[0],[0]
In this section we consider the distributed matrix factorization problem (25).,8.2. Distributed Matrix Factorization,[0],[0]
"The training data is constructed
by randomly extracting 300 overlapping patches from the 512 × 512 image of barbara.png, each with size 16 × 16 pixels.",8.2. Distributed Matrix Factorization,[0],[0]
"Each of the extracted patch is vectorized, resulting a training data set Z of size 256 × 300.",8.2. Distributed Matrix Factorization,[0],[0]
"We consider a network of N = 10 agents, and the columns of Z are evenly distributed among the agents (each having P = 30 columns).",8.2. Distributed Matrix Factorization,[0],[0]
"We compare Prox-PDA-IP with the EXTRAAO algorithm proposed in (H.-T. Wai & Scaglione, 2015).",8.2. Distributed Matrix Factorization,[0],[0]
Note that the EXTRA-AO is also designed for a similar distributed matrix factorization problem and it works well in practice.,8.2. Distributed Matrix Factorization,[0],[0]
"However, it does not have formal convergence proof.",8.2. Distributed Matrix Factorization,[0],[0]
We initialize both algorithms with X being the 2D discrete cosine transform (DCT) matrix.,8.2. Distributed Matrix Factorization,[0],[0]
"We set γ = 0.05, τ = 105 and β = 0.001r, and the results are averaged over 30 problem instances.",8.2. Distributed Matrix Factorization,[0],[0]
The stepsizes of the EXTRAAO is set as αAO = 0.03 and βAO = 0.002.,8.2. Distributed Matrix Factorization,[0],[0]
"In Fig. 3, we compare the performance of the proposed Prox-PDAIP and the EXTRA-AO.",8.2. Distributed Matrix Factorization,[0],[0]
It can be observed that our proposed algorithm converges faster than the EXTRA-AO.,8.2. Distributed Matrix Factorization,[0],[0]
"We have observed that the EXTRA-AO does have reasonably good practical performance, however it lacks formal convergence proof.",8.2. Distributed Matrix Factorization,[0],[0]
The authors supported by National Natural Science Foundation (Grant No. CCF-1526078).,Acknowledgment,[0],[0]
In this paper we consider nonconvex optimization and learning over a network of distributed nodes.,abstractText,[0],[0]
"We develop a Proximal Primal-Dual Algorithm (Prox-PDA), which enables the network nodes to distributedly and collectively compute the set of first-order stationary solutions in a global sublinear manner",abstractText,[0],[0]
"[with a rate of O(1/r), where r is the iteration counter].",abstractText,[0],[0]
"To the best of our knowledge, this is the first algorithm that enables distributed nonconvex optimization with global sublinear rate guarantees.",abstractText,[0],[0]
Our numerical experiments also demonstrate the effectiveness of the proposed algorithm.,abstractText,[0],[0]
Prox-PDA: The Proximal Primal-Dual Algorithm for Fast Distributed Nonconvex Optimization and Learning Over Networks,title,[0],[0]
"Translation quality estimation is a task of growing importance in NLP, due to its potential to reduce post-editing human effort in disruptive ways. However, this potential is currently limited by the relatively low accuracy of existing systems. In this paper, we achieve remarkable improvements by exploiting synergies between the related tasks of word-level quality estimation and automatic post-editing. First, we stack a new, carefully engineered, neural model into a rich feature-based wordlevel quality estimation system. Then, we use the output of an automatic post-editing system as an extra feature, obtaining striking results on WMT16: a word-level F MULT1 score of 57.47% (an absolute gain of +7.95% over the current state of the art), and a Pearson correlation score of 65.56% for sentence-level HTER prediction (an absolute gain of +13.36%).",text,[0],[0]
"The goal of quality estimation (QE) is to evaluate a translation system’s quality without access to reference translations (Blatz et al., 2004; Specia et al., 2013).",1 Introduction,[0],[0]
"This has many potential usages: informing an end user about the reliability of translated content; deciding if a translation is ready for publishing or if it requires human post-editing; highlighting
the words that need to be changed.",1 Introduction,[0],[0]
"QE systems are particularly appealing for crowd-sourced and professional translation services, due to their potential to dramatically reduce post-editing times and to save labor costs (Specia, 2011).",1 Introduction,[0],[0]
"The increasing interest in this problem from an industrial angle comes as no surprise (Turchi et al., 2014; de Souza et al., 2015; Martins et al., 2016; Kozlova et al., 2016).
",1 Introduction,[0],[0]
"In this paper, we tackle word-level QE, whose goal is to assign a label of OK or BAD to each word in the translation (Figure 1).",1 Introduction,[0],[0]
"Past approaches to this problem include linear classifiers with handcrafted features (Ueffing and Ney, 2007; Biçici, 2013; Shah et al., 2013; Luong et al., 2014), often combined with feature selection (Avramidis, 2012; Beck et al., 2013), recurrent neural networks (de Souza et al., 2014; Kim and Lee, 2016), and systems that combine linear and neural models (Kreutzer et al., 2015; Martins et al., 2016).",1 Introduction,[0],[0]
"We start by proposing a “pure” QE system (§3) consisting of a new, carefully engineered neural model (NEURALQE), stacked into a linear feature-rich classifier (LINEARQE).",1 Introduction,[0],[0]
"Along the way, we provide a rigorous empirical analysis to better understand the contribution of the several groups of features and to justify the architecture of the neural system.
",1 Introduction,[0],[0]
"A second contribution of this paper is bringing in the related task of automatic post-editing (APE; Simard et al. (2007)), which aims to au-
205
Transactions of the Association for Computational Linguistics, vol. 5, pp.",1 Introduction,[0],[0]
"205–218, 2017.",1 Introduction,[0],[0]
Action Editor: Stefan Riezler.,1 Introduction,[0],[0]
"Submission batch: 12/2016; Revision batch: 2/2017; Published 7/2017.
",1 Introduction,[0],[0]
c©2017 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
tomatically correct the output of machine translation (MT).",1 Introduction,[0],[0]
"We show that a variant of the APE system of Junczys-Dowmunt and Grundkiewicz (2016), trained on a large amount of artificial “roundtrip translations,” is extremely effective when adapted to predict word-level quality labels (yielding APEQE, §4).",1 Introduction,[0],[0]
"We further show that the pure and the APEbased QE system are highly complementary (§5): a stacked combination of LINEARQE, NEURALQE, and APEQE boosts the scores even further, leading to a new state of the art on the WMT15 and WMT16 datasets.",1 Introduction,[0],[0]
"For the latter, we achieve an F MULT1 score of 57.47%, which represents an absolute improvement of +7.95% over the previous best system.
",1 Introduction,[0],[0]
"Finally, we provide a simple word-to-sentence conversion to adapt our system to sentence-level QE.",1 Introduction,[0],[0]
"This results in a new state of the art for humantargeted translation error rate (HTER) prediction, where we obtain a Pearson’s r correlation score of 65.56% (+13.36% absolute gain), and for sentence ranking, which achieves a Spearman’s ρ correlation score of 65.92% (+17.62%).",1 Introduction,[0],[0]
We complement our findings with error analysis that highlights the synergies between pure and APE-based QE systems.,1 Introduction,[0],[0]
Datasets.,2 Datasets and System Architecture,[0],[0]
"For developing and evaluating our systems, we use the datasets listed in Table 1.",2 Datasets and System Architecture,[0],[0]
"These datasets have been used in the QE and APE tasks in WMT 2015–2016 (Bojar et al., 2015, 2016).1 They span two language pairs (English-Spanish and English-German) and two different domains (news translations and information technology).",2 Datasets and System Architecture,[0],[0]
"We used the standard train, development and test splits.",2 Datasets and System Architecture,[0],[0]
"Each split contains the source and automatically translated sentences (which we use as inputs), the manu-
1Publicly available at http://www.statmt.org/ wmt15 and http://www.statmt.org/wmt16.
ally post-edited sentences (output for the APE task), and a sequence of OK/BAD quality labels, one per each translated word (output for the word-level QE task); see Figure 1.",2 Datasets and System Architecture,[0],[0]
"Besides these datasets, for training the APE system we make use of artificial roundtrip translations; this will be detailed in §4.",2 Datasets and System Architecture,[0],[0]
Evaluation.,2 Datasets and System Architecture,[0],[0]
"For all experiments, we report the official evaluation metrics of each dataset’s year.",2 Datasets and System Architecture,[0],[0]
"For WMT15, the official metric for the word-level QE task is the F1 score of the BAD labels (F BAD1 ).",2 Datasets and System Architecture,[0],[0]
"For WMT16, it is the product of the F1 scores for the OK and BAD labels (denoted F MULT1 ).",2 Datasets and System Architecture,[0],[0]
"For sentencelevel QE, we report the Pearson’s r correlation for HTER prediction and the Spearman’s ρ correlation score for sentence ranking (Graham, 2015).
",2 Datasets and System Architecture,[0],[0]
From post-edited sentences to quality labels.,2 Datasets and System Architecture,[0],[0]
"In the datasets above, the word quality labels are obtained automatically by aligning the translated and the post-edited sentence with the TERCOM software tool (Snover et al., 2006)2, with the default settings (tokenized, case insensitive, exact matching only, shifts disabled).",2 Datasets and System Architecture,[0],[0]
This tool computes the HTER (the normalized edit distance) between the translated and post-edited sentence.,2 Datasets and System Architecture,[0],[0]
"As a by-product, it aligns the words in the two sentences, identifying substitution errors, word deletions (i.e. words omitted by the translation system), and insertions (redundant words in the translation).",2 Datasets and System Architecture,[0],[0]
"Words in the MT output that need to be edited are marked by the BAD quality labels.
",2 Datasets and System Architecture,[0],[0]
"The fact that the quality labels are automatically obtained from the post-edited sentences is not just an artifact of these datasets, but a procedure that is highly convenient for developing QE systems in an industrial setting.",2 Datasets and System Architecture,[0],[0]
"Manually annotating word-level quality labels is time-consuming and expensive; on the other hand, post-editing translated sentences is
2http://www.cs.umd.edu/˜snover/tercom.
",2 Datasets and System Architecture,[0],[0]
commonly part of the workflow of crowd-sourced and professional translation services.,2 Datasets and System Architecture,[0],[0]
"Thus, getting quality labels for free from sentences that have already been post-edited is a much more realistic and sustainable process.",2 Datasets and System Architecture,[0],[0]
"This observation suggests that we can tackle word-level QE in two ways:
1.",2 Datasets and System Architecture,[0],[0]
"Pure QE: run the TER alignment tool (i.e. TERCOM) on the post-edited data, and then train a QE system directly on the generated quality labels;
2.",2 Datasets and System Architecture,[0],[0]
"APE-based QE: train an APE system on the original post-edited data, and at runtime use the TER aligment tool to convert the automatically post-edited sentences to quality labels.
",2 Datasets and System Architecture,[0],[0]
"From a machine learning pespective, QE is a sequence labeling problem (i.e., whose output sequence has a fixed length and a small number of labels), while APE is a sequence-to-sequence problem (where the output is of variable length and spans a large vocabulary).",2 Datasets and System Architecture,[0],[0]
"Therefore, we can regard APE-based QE as a “projection” of a more complex and fine-grained output (APE) into a simpler output space (QE).",2 Datasets and System Architecture,[0],[0]
APE-based QE systems have the potential for being more powerful since they are trained with this finer-grained information (provided there is enough training data to make them generalize well).,2 Datasets and System Architecture,[0],[0]
"We report results in §4 confirming this hypothesis.
",2 Datasets and System Architecture,[0],[0]
"Our system architecture, described in full detail in the following sections, consists of state of the art pure QE and APE-based QE systems, which are then combined to yield a new, more powerful, QE system.",2 Datasets and System Architecture,[0],[0]
"The best performing system in the WMT16 wordlevel QE task was developed by the Unbabel team
(Martins et al., 2016).",3 Pure Quality Estimation,[0],[0]
"It is a pure but rather complex QE system, ensembling a linear feature-based classifier with three different neural networks with different configurations.",3 Pure Quality Estimation,[0],[0]
"In this section, we provide a simpler version of their system, by replacing the three ensembled neural components by a single one, which we engineer in a principled way.",3 Pure Quality Estimation,[0],[0]
"We evaluate the resulting system on additional data (WMT15 in addition to WMT16), covering a new language pair and a new content type.",3 Pure Quality Estimation,[0],[0]
"Overall, we obtain a slightly higher accuracy with a much simpler system.
",3 Pure Quality Estimation,[0],[0]
"In this section, we describe the linear (§3.1) and neural (§3.2) components of our system, as well as their combination (§3.3).",3 Pure Quality Estimation,[0],[0]
"We start with the linear component of our model, a discriminative feature-based sequential model (called LINEARQE), based on Martins et al. (2016).",3.1 Linear Sequential Model,[0],[0]
"The system receives as input a tuple 〈s, t,A〉, where s = s1 . . .",3.1 Linear Sequential Model,[0],[0]
"sM is the source sentence, t = t1 . . .",3.1 Linear Sequential Model,[0],[0]
"tN is the translated sentence, and A ⊆ {(m,n)",3.1 Linear Sequential Model,[0],[0]
"| 1 ≤ m ≤ M, 1 ≤ n ≤",3.1 Linear Sequential Model,[0],[0]
N} is a set of word alignments.,3.1 Linear Sequential Model,[0],[0]
It predicts as output a sequence ŷ = y1 . . .,3.1 Linear Sequential Model,[0],[0]
"yN , with each yi ∈ {BAD, OK}.",3.1 Linear Sequential Model,[0],[0]
"This is done as follows:
ŷ",3.1 Linear Sequential Model,[0],[0]
=,3.1 Linear Sequential Model,[0],[0]
argmax,3.1 Linear Sequential Model,[0],[0]
"y
N∑
i=1
w>φu(s, t,A, yi)
+ N+1∑
i=1
",3.1 Linear Sequential Model,[0],[0]
"w>φb(s, t,A, yi, yi−1).",3.1 Linear Sequential Model,[0],[0]
"(1)
Above, w is a vector of weights, φu(s, t,A, yi) are unigram features (depending only on a single output label), φb(s, t,A, yi, yi−1) are bigram features (depending on consecutive output labels), and y0 and yN+1 are special start/stop symbols.
",3.1 Linear Sequential Model,[0],[0]
Features.,3.1 Linear Sequential Model,[0],[0]
Table 2 shows the unigram and bigram features used in the LINEARQE system.,3.1 Linear Sequential Model,[0],[0]
"Like the baseline systems provided in WMT15/16, we include features that depend on the target word and its aligned source word, as well as the context surrounding them.3",3.1 Linear Sequential Model,[0],[0]
"A distinctive aspect of our system is the inclusion of syntactic features, which will
3Features involving the aligned source word are replaced by NIL if the target word is unaligned.",3.1 Linear Sequential Model,[0],[0]
"If there are multiple aligned source words, they are concatenated into a single feature.
show to be useful to detect grammatically incorrect",3.1 Linear Sequential Model,[0],[0]
"constructions.4 We use features that involve the dependency relation, the head word, and secondorder sibling and grandparent structures.",3.1 Linear Sequential Model,[0],[0]
"Features involving part-of-speech (POS) tags and syntactic information are obtained with TurboTagger and TurboParser (Martins et al., 2013).5
Training.",3.1 Linear Sequential Model,[0],[0]
"The feature weights are learned by running 50 epochs of the max-loss MIRA algorithm (Crammer et al., 2006), with regularization constant C ∈ {10−k}4k=1 and a Hamming cost function placing a higher penalty on false positives than on false negatives (cFP ∈ {0.5, 0.55, . . .",3.1 Linear Sequential Model,[0],[0]
", 0.95}, cFN = 1 − cFP), to account for the existence of fewer BAD labels than OK labels in the data.",3.1 Linear Sequential Model,[0],[0]
"These values are tuned on the development set.
",3.1 Linear Sequential Model,[0],[0]
Results and feature contribution.,3.1 Linear Sequential Model,[0],[0]
Table 3 shows the performance of the LINEARQE system.,3.1 Linear Sequential Model,[0],[0]
"To help understand the contribution of each group of features, we evaluated different variants of the LINEARQE system on the development sets of WMT15/16.",3.1 Linear Sequential Model,[0],[0]
"As expected, the use of bigrams improves the simple unigram model, and the syntac-
4While syntactic features have been used previously in sentence-level QE (Rubino et al., 2012), they have never been applied to the finer-grained word-level variant tackled here.
",3.1 Linear Sequential Model,[0],[0]
"5http://www.cs.cmu.edu/˜ark/TurboParser.
1 for
WMT16.
tic features help even further.",3.1 Linear Sequential Model,[0],[0]
"The impact of these features is more prominent in WMT16: the rich bigram features lead to scores about 3 points above a sequential model with a single indicator bigram feature, and the syntactic features contribute another 2.5 points.",3.1 Linear Sequential Model,[0],[0]
The net improvement exceeds 6 points over the unigram model.,3.1 Linear Sequential Model,[0],[0]
"Next, we describe the neural component of our pure QE system, which we call NEURALQE.",3.2 Neural System,[0],[0]
"In WMT15 and WMT16, the neural QUETCH system (Kreutzer et al., 2015) and its ensemble with other neural models (Martins et al., 2016) were components of the winning systems.",3.2 Neural System,[0],[0]
"However, none of these neural models managed to outperform a linear model when
considered in isolation—for example, QUETCH obtained a F BAD1 of 35.27% in the WMT15 test set, far below the 40.84% score of the linear system built by the same team.",3.2 Neural System,[0],[0]
"By contrast, our carefully engineered NEURALQE model attains a performance superior to that of the linear system, as we shall see.
",3.2 Neural System,[0],[0]
Architecture.,3.2 Neural System,[0],[0]
The architecture of NEURALQE is depicted in Figure 2.,3.2 Neural System,[0],[0]
"We used Keras (Chollet, 2015) to implement our model.",3.2 Neural System,[0],[0]
"The system receives as input the source and target sentences s and t, their word-level alignments A, and their corresponding POS tags obtained from TurboTagger.",3.2 Neural System,[0],[0]
"The input layer follows a similar architecture as QUETCH, with the addition of POS features.",3.2 Neural System,[0],[0]
A vector representing each target word is obtained by concatenating the embedding of that word with those of the aligned word in the source.6 The immediate left and right contexts for source and target words are also concatenated.,3.2 Neural System,[0],[0]
"We use the pre-trained 64- dimensional Polyglot word embeddings (Al-Rfou et al., 2013) for English, German, and Spanish, and refine them during training.",3.2 Neural System,[0],[0]
"In addition to this, POS tags for each source and target word are also embedded and concatenated.",3.2 Neural System,[0],[0]
POS embeddings have size 50 and are initialized as described by Glorot and Bengio (2010).,3.2 Neural System,[0],[0]
"A dropout probability of 0.5 is applied to the resulting vector representations.
",3.2 Neural System,[0],[0]
"The following layers are then applied in sequence:
1.",3.2 Neural System,[0],[0]
Two feed-forward layers of size 400 with rectified linear units (ReLU; Nair and Hinton (2010));,3.2 Neural System,[0],[0]
"6For the cases in which there are multiple source words aligned to the same target word, the embeddings are averaged.
2.",3.2 Neural System,[0],[0]
"A layer with bidirectional gated recurrent units (BiGRU, Cho et al. (2014)) of size 200, where forward and backward vectors are concatenated, trained with layer normalization (Ba et al., 2016);
3.",3.2 Neural System,[0],[0]
"Two feed-forward ReLU layers of size 200;
4.",3.2 Neural System,[0],[0]
"A BiGRU layer of size 100 with identical configuration to the previous BiGRU;
5.",3.2 Neural System,[0],[0]
"Two more feed-forward ReLU layers of sizes 100 and 50, respectively.
",3.2 Neural System,[0],[0]
"As the output layer, a softmax transformation over the OK/BAD labels is applied.",3.2 Neural System,[0],[0]
"The choice for this architecture was dictated by experiments on the WMT16 development data, as we explain next.
",3.2 Neural System,[0],[0]
Training.,3.2 Neural System,[0],[0]
"We train the model with the RMSProp algorithm (Tieleman and Hinton, 2012) by minimizing the cross-entropy with a linear penalty for BAD word predictions, as in Kreutzer et al. (2015).",3.2 Neural System,[0],[0]
We set the BAD weight factor to 3.0.,3.2 Neural System,[0],[0]
All hyperparameters are adjusted based on the development set.,3.2 Neural System,[0],[0]
"Target sentences are bucketed by length and then processed in batches (without any padding or truncation).
",3.2 Neural System,[0],[0]
Results and architectural choices.,3.2 Neural System,[0],[0]
The final results are shown in Table 4.,3.2 Neural System,[0],[0]
"Overall, the final NEURALQE model achieves an F MULT1 score of 46.80% on the WMT16 development set, compared with the 46.11% obtained with the LINEARQE system (cf. Table 3).",3.2 Neural System,[0],[0]
"This contrasts with previous neural systems, such as QUETCH (Kreutzer et al., 2015) and any of the three neural systems developed by Martins et al. (2016), which could not outperform a rich feature linear classifier.
",3.2 Neural System,[0],[0]
"To justify the most relevant choices regarding the architecture of NEURALQE, we also evaluated several variations of it on the WMT16 development set.",3.2 Neural System,[0],[0]
"The use of recurrent layers yields the largest contribution to the performance of NEURALQE, as the scores drop sharply (by more than 4 points) if they are replaced by feed-forward layers (which would correspond to a mere deeper QUETCH model).",3.2 Neural System,[0],[0]
"The first BiGRU is particulary effective, as scores drop more than 2 points if it is removed.",3.2 Neural System,[0],[0]
The use of layer normalization on the recurrent layers also contributes positively (+1.20) to the final score.,3.2 Neural System,[0],[0]
"As expected, the use of POS tags adds another large improvement: everything staying the same, the model
without POS tags as input performs almost 2.5 points worse.",3.2 Neural System,[0],[0]
"Finally, varying the size of the hidden layers and the depth of the network hurts the final model’s performance, albeit more slightly.",3.2 Neural System,[0],[0]
"We now stack the NEURALQE system (§3.2) into the LINEARQE system (§3.1) as an ensemble strategy; we call the resulting system STACKEDQE.
",3.3 Stacking Neural and Linear Models,[0],[0]
"Stacking architectures (Wolpert, 1992; Breiman, 1996) have proved effective in structured NLP problems (Cohen and de Carvalho, 2005; Martins et al., 2008).",3.3 Stacking Neural and Linear Models,[0],[0]
The underlying idea is to combine two systems by letting the prediction of the first system be used as an input feature for the second system.,3.3 Stacking Neural and Linear Models,[0],[0]
"During training, it is necessary to jackknife the first system’s predictions to avoid overfitting the training set.",3.3 Stacking Neural and Linear Models,[0],[0]
"This is done by splitting the training set in K folds (we set K = 10) and training K different instances of the first system, where each instance is trained on K − 1 folds and makes predictions for the left-out fold.",3.3 Stacking Neural and Linear Models,[0],[0]
"The concatenation of all the predictions yields an unbiased training set for the second classifier.
",3.3 Stacking Neural and Linear Models,[0],[0]
Neural intra-ensembles.,3.3 Stacking Neural and Linear Models,[0],[0]
We also evaluate the performance of intra-ensembled neural systems.,3.3 Stacking Neural and Linear Models,[0],[0]
"We train independent instances of NEURALQE with different random initializations and different data shuffles, following the approach of Jean et al. (2015) in neural MT.",3.3 Stacking Neural and Linear Models,[0],[0]
"In Tables 5–6, we report the performance on the WMT15 and WMT16 datasets of systems ensembling 5 and 15 of these instances, called respectively NEURALQE-5 and NEURALQE-15.",3.3 Stacking Neural and Linear Models,[0],[0]
"The in-
stances are ensembled by taking the averaged probability of each word being BAD.",3.3 Stacking Neural and Linear Models,[0],[0]
"We see consistent benefits (both for WMT15 and WMT16) in ensembling 5 neural systems and (somewhat surprisingly) some degradation with ensembles of 15.
",3.3 Stacking Neural and Linear Models,[0],[0]
Stacking architecture.,3.3 Stacking Neural and Linear Models,[0],[0]
"The individual instances of the neural systems are incorporated in the stacking architecture as different features, yielding STACKEDQE.",3.3 Stacking Neural and Linear Models,[0],[0]
"In total, we have 15 predictions (probability values given by each NEURALQE system) for every word in the training, development and test datasets.",3.3 Stacking Neural and Linear Models,[0],[0]
These predictions are plugged as additional features in the LINEARQE model.,3.3 Stacking Neural and Linear Models,[0],[0]
"As unigram features, we used one real-valued feature for every model prediction at each position, conjoined with the label.",3.3 Stacking Neural and Linear Models,[0],[0]
"As bigram features, we used two realvalued features for every model prediction at the two positions, conjoined with the label pair.
",3.3 Stacking Neural and Linear Models,[0],[0]
The results obtained with this stacked architecture on the WMT15 and WMT16 datasets are shown respectively in Tables 5 and 6.,3.3 Stacking Neural and Linear Models,[0],[0]
"In WMT15, it is unclear if stacking helps over the best intra-ensembled neural system, with a slight improvement in the development set, but a degradation in the test set.",3.3 Stacking Neural and Linear Models,[0],[0]
"In WMT16, however, stacking is clearly beneficial, with a boost of about 2 points over the best intraensembled neural system and 3–4 points above the linear system, both in the development and test partitions.",3.3 Stacking Neural and Linear Models,[0],[0]
"For the remainder of this paper, we will take STACKEDQE as our pure QE system.",3.3 Stacking Neural and Linear Models,[0],[0]
"Now that we have described a pure QE system, we move on to an APE-based QE system (APEQE).
",4 APE-Based Quality Estimation,[0],[0]
"Our starting point is the system submitted by the Adam Mickiewicz University (AMU) team to the APE task of WMT16 (Junczys-Dowmunt and Grundkiewicz, 2016).",4 APE-Based Quality Estimation,[0],[0]
"They explored the application of neural translation models to the APE problem and achieved good results by treating different models as components in a log-linear model, allowing for multiple inputs (the source s and the translated sentence t) that were decoded to the same target language (post-edited translation p).",4 APE-Based Quality Estimation,[0],[0]
"Two systems were considered, one using s as the input (s → p) and another using t as the input (t → p).",4 APE-Based Quality Estimation,[0],[0]
A simple string-matching penalty integrated within the loglinear model was used to control for higher faithfulness with regard to the raw MT output.,4 APE-Based Quality Estimation,[0],[0]
"The penalty fires if the APE system proposes a word in its output that has not been seen in t.
To overcome the problem of too little training data, Junczys-Dowmunt and Grundkiewicz (2016) generated large amounts of artificial data via roundtrip translations: a large corpus of monolingual sentences is first gathered for the target language in the domain of interest (each sentence is regarded as an artificial post-edited sentence p); then an MT system is ran to translate these sentences to the source language (which are regarded as the source sentences s), and another MT system in the reverse direction translates the latter back to the target language (playing the role of the translations t).",4 APE-Based Quality Estimation,[0],[0]
"The artificial data is filtered to match the HTER statistics of the training and development data for the shared
task.7 Their submission improved over the uncorrected baseline on the unseen WMT16 test set by - 3.2% TER and +5.5% BLEU and outperformed any other system submitted to the shared-task by a large margin.",4 APE-Based Quality Estimation,[0],[0]
"We reproduce the experiments from JunczysDowmunt and Grundkiewicz (2016) using Nematus (Sennrich et al., 2016) for training and AmuNMT (Junczys-Dowmunt et al., 2016) for decoding.
",4.1 Training the APE System,[0],[0]
"As stated in §3.3, jackknifing is required to avoid overfitting during the training procedure of the stacked classifiers (§5), therefore we start by preparing four jackknifed models.",4.1 Training the APE System,[0],[0]
"We perform the following steps:
• We divide the original WMT16 training set into four equally sized parts, maintaining correspondences between different languages.",4.1 Training the APE System,[0],[0]
"Four new training sets are created by leaving out one part and concatenating the remaining three parts.
",4.1 Training the APE System,[0],[0]
"• For each of the four new training sets, we train one APE model on a concatenation of a smaller set of artificial data (denoted as “round-trip.n1” in Junczys-Dowmunt and Grundkiewicz (2016), consisting of 531,839 sentence triples) and a 20- fold oversampled new training set.",4.1 Training the APE System,[0],[0]
"Each of these newly created four APE models has not seen a different part of the quartered original training data.
",4.1 Training the APE System,[0],[0]
"• To avoid overfitting, we use scaling dropout8 over GRU steps and input embeddings, with dropout probabilities 0.2, and over source and target words with probabilities 0.1 (Sennrich et al., 2016).
",4.1 Training the APE System,[0],[0]
"• We use Adam (Kingma and Ba, 2014) instead of Adadelta (Zeiler, 2012).
",4.1 Training the APE System,[0],[0]
"• We train both models (s → p and t → p) until convergence up to 20 epochs, saving model checkpoints every 10,000 mini-batches.
",4.1 Training the APE System,[0],[0]
"7The artificial filtered data has been made available by the authors at https://github.com/emjotde/amunmt/ wiki/AmuNMT-for-Automatic-Post-Editing.
",4.1 Training the APE System,[0],[0]
"8Currently available in the MRT branch of Nematus at https://github.com/rsennrich/nematus
•",4.1 Training the APE System,[0],[0]
"The last four model checkpoints of each training run are averaged element-wise (JunczysDowmunt et al., 2016) resulting in new single models with generally improved performance.
",4.1 Training the APE System,[0],[0]
"To verify the quality of the APE system, we ensemble the 8 resulting models (4 times s→ p and 4 times t → p) and add the APE penalty described in Junczys-Dowmunt and Grundkiewicz (2016).",4.1 Training the APE System,[0],[0]
This large ensemble across folds is only used during test time.,4.1 Training the APE System,[0],[0]
"For creating the jackknifed training data, only the models from the corresponding fold are used.",4.1 Training the APE System,[0],[0]
"Since we combine models of different types, we tune weights on the development set with MERT9 (Och, 2003) towards TER, yielding the model denoted as “APE TER-tuned”.",4.1 Training the APE System,[0],[0]
Results are listed in Table 7 for the APE shared task (WMT 16).,4.1 Training the APE System,[0],[0]
"For the purely s → p and t → p ensembles, models are weighted equally.",4.1 Training the APE System,[0],[0]
"We achieve slightly better results in terms of TER, the main task metric, than the original system, using less data.
",4.1 Training the APE System,[0],[0]
"For completeness, we also apply this procedure to WMT15 data, generating a similar resource of 500K artificial English-Spanish-Spanish postediting triplets via roundtrip translation.10 The training, jackknifing and ensembling methods are the same as for the WMT16 setting.",4.1 Training the APE System,[0],[0]
"For the WMT15 APE shared task, results are less persuasive than for WMT16: none of the shared task participants was able to beat the uncorrected baseline and our system fails at this as well.",4.1 Training the APE System,[0],[0]
"However, we produced the
9We found MERT to work better when tuning towards TER than kb-MIRA which has been used in the original paper.
",4.1 Training the APE System,[0],[0]
10Our artificially created data might suffer from a higher mismatch between training and development data.,4.1 Training the APE System,[0],[0]
"While we were able to match the TER statistics of the dev set, BLEU scores are several points lower.",4.1 Training the APE System,[0],[0]
"The artificial WMT16 data we created in Junczys-Dowmunt and Grundkiewicz (2016) matches both, TER and BLEU scores, of the respective development set.
second strongest system for case-sensitive TER (Table 7, WMT15) and the strongest for case-insensitve TER (22.49 vs. 22.54).",4.1 Training the APE System,[0],[0]
"As described in §2, APE outputs can be turned into word quality labels using TER-based word alignments.",4.2 Adaptation to QE and Task-Specific Tuning,[0],[0]
"Somewhat surprisingly, among the APE systems introduced above, we observe in Table 9 that the s→ p APE system is the so-far strongest standalone QE system for the WMT16 task in this work.",4.2 Adaptation to QE and Task-Specific Tuning,[0],[0]
This system is essentially a retrained neural MT component without any additional features.11 The t → p system and the TER-tuned APE ensemble are much weaker in terms of F MULT1 .,4.2 Adaptation to QE and Task-Specific Tuning,[0],[0]
"This is less surprising in the case of the full ensemble, as it has been tuned towards TER for the APE task specifically.",4.2 Adaptation to QE and Task-Specific Tuning,[0],[0]
"However, we can obtain even better APEbased QE systems for both shared task settings by tuning the full APE ensembles towards F MULT1 , the official WMT16 QE metric, and towards F BAD1 for WMT15.12 With this approach, we produce our new best stand-alone QE-systems for both shared tasks, which we denote as APEQE.
11Note that this system resembles other QE approaches which use pseudo-reference features (Albrecht and Hwa, 2008; Soricut and Narsale, 2012; Shah et al., 2013), since the s → p is essentially an “alternative” MT system.
",4.2 Adaptation to QE and Task-Specific Tuning,[0],[0]
12Using again MERT and executing 7 iterations on the official development set with an n-best list size of 12.,4.2 Adaptation to QE and Task-Specific Tuning,[0],[0]
"Finally, we consider a larger stacked system where we stack both NEURALQE and APEQE into LINEARQE.",5 Full Stacked System,[0],[0]
This will mix pure QE with APE-based QE systems; we call the result FULLSTACKEDQE.,5 Full Stacked System,[0],[0]
"The procedure is analogous to that described in §3.3, with one extra binary feature for the APE-based word quality label predictions.",5 Full Stacked System,[0],[0]
"For training, we used jackknifing as described in §3.3.",5 Full Stacked System,[0],[0]
The performance of the FULLSTACKEDQE system on the WMT15 and WMT16 datasets are shown in Tables 10–11.,5.1 Word-Level QE,[0],[0]
"We compare with the other systems introduced in this paper, and with the best participating systems at WMT15–16 (Esplà-Gomis et al., 2015; Martins et al., 2016).
",5.1 Word-Level QE,[0],[0]
"We can see that the APE-based and the pure QE systems are complementary: the full combination of the linear, neural, and APE-based systems improves the scores with respect to the best individual system (APEQE) by about 1 point in WMT15 and 2 points in WMT16.",5.1 Word-Level QE,[0],[0]
"Overall, we obtain for WMT16 an F MULT1 score of 57.47%, a new state of the art, and an absolute gain of +7.95% over Martins et al. (2016).",5.1 Word-Level QE,[0],[0]
This is a remarkable improvement that can pave the way for a wider adoption of word-level QE systems in industrial settings.,5.1 Word-Level QE,[0],[0]
"For WMT15, we also obtain a new state of the art, with a less impressive gain of +3.96% over the best previous system.",5.1 Word-Level QE,[0],[0]
In §6 we analyze the errors made by the pure and the APE-based QE systems to better understand how they complement each other.,5.1 Word-Level QE,[0],[0]
"Encouraged by the strong results obtained with the FULLSTACKEDQE system in word-level QE, we investigate how we can adapt this system for HTER prediction at sentence level.",5.2 Sentence-Level QE,[0],[0]
"Prior work (de Souza et al., 2014) incorporated word-level quality predictions as features in a sentence-level QE system, training a feature-based linear classifier.",5.2 Sentence-Level QE,[0],[0]
"Here, we show that a very simple conversion, which requires no training or tuning, is enough to obtain a substantial improvement over the state of the art.
",5.2 Sentence-Level QE,[0],[0]
"For the APE system, it is easy to obtain a prediction for HTER: we can simply measure the HTER between the translated sentence t and the predicted corrected sentence p̂. For a pure QE system, we apply the following word-to-sentence conversion technique: (i) run a QE system to obtain a sequence of OK and BAD word quality labels; (ii) use the fraction of BAD labels as an estimate for HTER.",5.2 Sentence-Level QE,[0],[0]
"Note that this procedure, while not requiring any training, is far from perfect.",5.2 Sentence-Level QE,[0],[0]
"Words that are not in the translated sentence but exist in the reference post-edited sentence do not originate BAD labels, and therefore will not contribute to the HTER estimate.",5.2 Sentence-Level QE,[0],[0]
"Yet, as we will see, this procedure applied to the STACKEDQE system (i.e. without the APEQE component) is already sufficient to obtain state of the art results.",5.2 Sentence-Level QE,[0],[0]
"Finally, to combine the APE and pure QE systems toward sentence-level QE, we simply take the average of the two HTER predictions above.
",5.2 Sentence-Level QE,[0],[0]
"Table 12 shows the results obtained with our pure QE system (STACKEDQE), with our APEbased system (APEQE), and with the combination of the two (FULLSTACKEDQE).",5.2 Sentence-Level QE,[0],[0]
"As baselines, we
report the performance of the two best systems in the sentence-level QE tasks at WMT15 and WMT16 (Bicici et al., 2015; Langlois, 2015; Kozlova et al., 2016; Kim and Lee, 2016).
",5.2 Sentence-Level QE,[0],[0]
"The results are striking: for WMT16, even our weakest system (STACKEDQE) with the simple conversion procedure above is already sufficient to obtain state of the art results, outperforming Kozlova et al. (2016) and Kim and Lee (2016) by a considerable margin.",5.2 Sentence-Level QE,[0],[0]
"The APEQE system gives a very large boost over these scores, which are further increased by the combined FULLSTACKEDQE system.",5.2 Sentence-Level QE,[0],[0]
"Overall, we obtain absolute gains of +13.36% in Pearson’s r correlation score for HTER prediction, and +17.62% in Spearman’s ρ correlation for sentence ranking, a considerable advance over the previous state of the art.",5.2 Sentence-Level QE,[0],[0]
"For WMT15, we also obtain a new state of the art, with less sharp (but still significant) improvements: +5.08% in Pearson’s r correlation score, and +5.81% in Spearman’s ρ correlation.",5.2 Sentence-Level QE,[0],[0]
Performance over sentence length.,6 Error Analysis,[0],[0]
"To better understand the differences in performance between the pure QE system (STACKEDQE) and the APE-based system (APEQE), we analyze how the two systems, as well as their combination (FULLSTACKEDQE), perform as a function of the sentence length.
",6 Error Analysis,[0],[0]
"Figure 3 shows the averaged number of BAD predictions made by the three systems for different sentences lengths, in the WMT16 development set.",6 Error Analysis,[0],[0]
"For
comparison, we show also the true average number of BAD words in the gold standard.",6 Error Analysis,[0],[0]
"We observe that, for short sentences (less than 5 words), the pure QE system tends to be too optimistic (i.e., it underpredicts BAD words) and the APE-based system too pessimistic (overpredicting them).",6 Error Analysis,[0],[0]
"In the range of 5-10 words, the pure QE system matches the proportion of BAD words more accurately than the APE-based system.",6 Error Analysis,[0],[0]
"For medium/long sentences, we observe the opposite behavior (this is particularly clear in the 20-25 word range), with the APE-based system being generally better.",6 Error Analysis,[0],[0]
"On the other hand, the combination of the two systems (FULLSTACKEDQE) manages to find a good balance between these two biases, being much closer to the true proportion of BAD labels for both shorter and longer sentences than any of the individual systems.",6 Error Analysis,[0],[0]
"This shows that the two systems complement each other well in the combination.
",6 Error Analysis,[0],[0]
Illustrative examples.,6 Error Analysis,[0],[0]
Table 13 shows concrete examples of quality predictions on the WMT16 development data.,6 Error Analysis,[0],[0]
"In the top example, we can see that the APE system correctly replaced Angleichungsfarbe by Mischfarbe, but is under-corrective in other parts.",6 Error Analysis,[0],[0]
"The APEQE system therefore misses several BAD words, but manages to get the correct label (OK) for den.",6 Error Analysis,[0],[0]
"By contrast, the pure QE system erroneously flags this word as incorrect, but it makes the right decision on Farbton and zu erstellen, being more accurate than APEQE.",6 Error Analysis,[0],[0]
"The combination of the two systems (pure QE and APEQE) leads to
the correct sequential prediction.",6 Error Analysis,[0],[0]
"In the bottom example, the pure QE system assigns the correct label to Zusatzmodul, while the APE system mistranslates this word to Dialogfeld, leading to a wrong prediction by the APEQE system.",6 Error Analysis,[0],[0]
"On the other hand, pure QE misclassifies unterstützt RGB- as BAD words, while the APEQE gets them right.",6 Error Analysis,[0],[0]
"Overall, the APEQE is more accurate in this example.",6 Error Analysis,[0],[0]
"Again,
these decisions complement each other well, as can be seen by the combined QE system which outputs the correct word labels for the entire sentence.",6 Error Analysis,[0],[0]
"We have presented new state of the art systems for word-level and sentence-level QE that are considerably more accurate than previous systems on the WMT15 and WMT16 datasets.
",7 Conclusions,[0],[0]
"First, we proposed a new pure QE system which stacks a linear and a neural system, and is simpler and slighly more accurate than the currently best word-level system.",7 Conclusions,[0],[0]
"Then, by relating the tasks of APE and word-level QE, we derived a new APEbased QE system, which leverages additional artificial roundtrip translation data, achieving a larger improvement.",7 Conclusions,[0],[0]
"Finally, we combined the two systems via a full stacking architecture, boosting the scores even further.",7 Conclusions,[0],[0]
Error analysis shows that the pure and APE-based systems are highly complementary.,7 Conclusions,[0],[0]
"The full system was extended to sentence-level QE by virtue of a simple word-to-sentence conversion, re-
quiring no further training or tuning.",7 Conclusions,[0],[0]
We thank the reviewers and the action editor for their insightful comments.,Acknowledgments,[0],[0]
This work was partially supported by the the EXPERT project (EU Marie Curie ITN,Acknowledgments,[0],[0]
"No. 317471), and by Fundação para a Ciência e Tecnologia (FCT), through contracts UID/EEA/50008/2013 and UID/CEC/50021/2013, the LearnBig project (PTDC/EEI-SII/7092/2014), the GoLocal project (grant CMUPERI/TIC/0046/2014), and the Amazon Academic Research Awards program.",Acknowledgments,[0],[0]
"Translation quality estimation is a task of growing importance in NLP, due to its potential to reduce post-editing human effort in disruptive ways.",abstractText,[0],[0]
"However, this potential is currently limited by the relatively low accuracy of existing systems.",abstractText,[0],[0]
"In this paper, we achieve remarkable improvements by exploiting synergies between the related tasks of word-level quality estimation and automatic post-editing.",abstractText,[0],[0]
"First, we stack a new, carefully engineered, neural model into a rich feature-based wordlevel quality estimation system.",abstractText,[0],[0]
"Then, we use the output of an automatic post-editing system as an extra feature, obtaining striking results on WMT16: a word-level F MULT 1 score of 57.47% (an absolute gain of +7.95% over the current state of the art), and a Pearson correlation score of 65.56% for sentence-level HTER prediction (an absolute gain of +13.36%).",abstractText,[0],[0]
Pushing the Limits of Translation Quality Estimation,title,[0],[0]
"Reinforcement learning (RL) holds considerable promise to help address a variety of cooperative multi-agent problems, such as coordination of robot swarms (Hüttenrauch et al., 2017) and autonomous cars (Cao et al., 2012).
",1. Introduction,[0],[0]
"*Equal contribution 1University of Oxford, Oxford, United Kingdom 2Russian-Armenian University, Yerevan, Armenia.",1. Introduction,[0],[0]
"Correspondence to: Tabish Rashid <tabish.rashid@cs.ox.ac.uk>, Mikayel Samvelyan <mikayel@samvelyan.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"In many such settings, partial observability and/or communication constraints necessitate the learning of decentralised policies, which condition only on the local actionobservation history of each agent.",1. Introduction,[0],[0]
"Decentralised policies also naturally attenuate the problem that joint action spaces grow exponentially with the number of agents, often rendering the application of traditional single-agent RL methods impractical.
",1. Introduction,[0],[0]
"Fortunately, decentralised policies can often be learned in a centralised fashion in a simulated or laboratory setting.",1. Introduction,[0],[0]
"This often grants access to additional state information, otherwise hidden from agents, and removes inter-agent communication constraints.",1. Introduction,[0],[0]
"The paradigm of centralised training with decentralised execution (Oliehoek et al., 2008; Kraemer & Banerjee, 2016) has recently attracted attention in the RL community (Jorge et al., 2016; Foerster et al., 2018).",1. Introduction,[0],[0]
"However, many challenges surrounding how to best exploit centralised training remain open.
",1. Introduction,[0],[0]
One of these challenges is how to represent and use the action-value function that most RL methods learn.,1. Introduction,[0],[0]
"On the one hand, properly capturing the effects of the agents’ actions requires a centralised action-value function Qtot that conditions on the global state and the joint action.",1. Introduction,[0],[0]
"On the other hand, such a function is difficult to learn when there are many agents and, even if it can be learned, offers no obvious way to extract decentralised policies that allow each agent to select only an individual action based on an individual observation.
",1. Introduction,[0],[0]
"The simplest option is to forgo a centralised action-value function and let each agent a learn an individual action-value function Qa independently, as in independent Q-learning (IQL) (Tan, 1993).",1. Introduction,[0],[0]
"However, this approach cannot explicitly represent interactions between the agents and may not converge, as each agent’s learning is confounded by the learning and exploration of others.
",1. Introduction,[0],[0]
"At the other extreme, we can learn a fully centralised stateaction value function Qtot and then use it to guide the optimisation of decentralised policies in an actor-critic framework, an approach taken by counterfactual multi-agent (COMA) policy gradients (Foerster et al., 2018), as well as work by Gupta et al. (2017).",1. Introduction,[0],[0]
"However, this requires onpolicy learning, which can be sample-inefficient, and training the fully centralised critic becomes impractical when there are more than a handful of agents.
",1. Introduction,[0],[0]
"In between these two extremes, we can learn a centralised but factored Qtot, an approach taken by value decomposition networks (VDN) (Sunehag et al., 2017).",1. Introduction,[0],[0]
"By representing Qtot as a sum of individual value functions Qa that condition only on individual observations and actions, a decentralised policy arises simply from each agent selecting actions greedily with respect to its Qa.",1. Introduction,[0],[0]
"However, VDN severely limits the complexity of centralised action-value functions that can be represented and ignores any extra state information available during training.
",1. Introduction,[0],[0]
"In this paper, we propose a new approach called QMIX which, like VDN, lies between the extremes of IQL and COMA, but can represent a much richer class of actionvalue functions.",1. Introduction,[0],[0]
Key to our method is the insight that the full factorisation of VDN is not necessary to extract decentralised policies.,1. Introduction,[0],[0]
"Instead, we only need to ensure that a global argmax performed on Qtot yields the same result as a set of individual argmax operations performed on each Qa.",1. Introduction,[0],[0]
"To this end, it suffices to enforce a monotonicity constraint on the relationship between Qtot and each Qa:
∂Qtot ∂Qa ≥ 0, ∀a.",1. Introduction,[0],[0]
"(1)
QMIX consists of agent networks representing each Qa, and a mixing network that combines them into Qtot, not as a simple sum as in VDN, but in a complex non-linear way that ensures consistency between the centralised and decentralised policies.",1. Introduction,[0],[0]
"At the same time, it enforces the constraint of (1) by restricting the mixing network to have positive weights.",1. Introduction,[0],[0]
"As a result, QMIX can represent complex centralised action-value functions with a factored representation that scales well in the number of agents and allows decentralised policies to be easily extracted via linear-time individual argmax operations.
",1. Introduction,[0],[0]
"We evaluate QMIX on a range of unit micromanagement
tasks built in StarCraft II1.",1. Introduction,[0],[0]
"(Vinyals et al., 2017).",1. Introduction,[0],[0]
"Our experiments show that QMIX outperforms IQL and VDN, both in terms of absolute performance and learning speed.",1. Introduction,[0],[0]
"In particular, our method shows considerable performance gains on a task with heterogeneous agents.",1. Introduction,[0],[0]
"Moreover, our ablations show both the necessity of conditioning on the state information and the non-linear mixing of agent Q-values in order to achieve consistent performance across tasks.",1. Introduction,[0],[0]
"Recent work in multi-agent RL has started moving from tabular methods (Yang & Gu, 2004; Busoniu et al., 2008) to deep learning methods that can tackle high-dimensional state and action spaces (Tampuu et al., 2017; Foerster et al., 2018; Peng et al., 2017).",2. Related Work,[0],[0]
"In this paper, we focus on cooperative settings.
",2. Related Work,[0],[0]
"On the one hand, a natural approach to finding policies for a multi-agent system is to directly learn decentralised value functions or policies.",2. Related Work,[0],[0]
"Independent Q-learning (Tan, 1993) trains independent action-value functions for each agent using Q-learning (Watkins, 1989).",2. Related Work,[0],[0]
"(Tampuu et al., 2017) extend this approach to deep neural networks using DQN (Mnih et al., 2015).",2. Related Work,[0],[0]
"While trivially achieving decentralisation, these approaches are prone to instability arising from the non-stationarity of the environment induced by simultaneously learning and exploring agents.",2. Related Work,[0],[0]
"Omidshafiei et al. (2017) and Foerster et al. (2017) address learning stabilisation to some extent, but still learn decentralised value functions and do not allow for the inclusion of extra state information during training.
",2. Related Work,[0],[0]
"On the other hand, centralised learning of joint actions can naturally handle coordination problems and avoids nonstationarity, but is hard to scale, as the joint action space grows exponentially in the number of agents.",2. Related Work,[0],[0]
"Classical approaches to scalable centralised learning include coordination graphs (Guestrin et al., 2002), which exploit conditional independencies between agents by decomposing a global reward function into a sum of agent-local terms.",2. Related Work,[0],[0]
"Sparse cooperative Q-learning (Kok & Vlassis, 2006) is a tabular Q-learning algorithm that learns to coordinate the actions of a group of cooperative agents only in the states in which such coordination is necessary, encoding those dependencies in a coordination graph.",2. Related Work,[0],[0]
"These methods require the dependencies between agents to be pre-supplied, whereas we do not require such prior knowledge.",2. Related Work,[0],[0]
"Instead, we assume that each agent always contributes to the global reward, and learns the magnitude of its contribution in each state.
",2. Related Work,[0],[0]
More recent approaches for centralised learning require even more communication during execution:,2. Related Work,[0],[0]
"CommNet
1StarCraft and StarCraft II are trademarks of Blizzard EntertainmentTM.
",2. Related Work,[0],[0]
"(Sukhbaatar et al., 2016) uses a centralised network architecture to exchange information between agents.",2. Related Work,[0],[0]
"BicNet (Peng et al., 2017) uses bidirectional RNNs to exchange information between agents in an actor-critic setting.",2. Related Work,[0],[0]
"This approach additionally requires estimating individual agent rewards.
",2. Related Work,[0],[0]
Some work has developed hybrid approaches that exploit the setting of centralised learning with fully decentralised execution.,2. Related Work,[0],[0]
"COMA (Foerster et al., 2018) uses a centralised critic to train decentralised actors, estimating a counterfactual advantage function for each agent in order to address multi-agent credit assignment.",2. Related Work,[0],[0]
"Similarly, Gupta et al. (2017) present a centralised actor-critic algorithm with per-agent critics, which scales better with the number of agents but mitigates the advantages of centralisation.",2. Related Work,[0],[0]
Lowe et al. (2017) learn a centralised critic for each agent and apply this to competitive games with continuous action spaces.,2. Related Work,[0],[0]
"These approaches use on-policy policy gradient learning, which can have poor sample efficiency and is prone to getting stuck in sub-optimal local minima.
Sunehag et al. (2017) propose value decomposition networks (VDN), which allow for centralised value-function learning with decentralised execution.",2. Related Work,[0],[0]
Their algorithm decomposes a central state-action value function into a sum of individual agent terms.,2. Related Work,[0],[0]
This corresponds to the use of a degenerate fully disconnected coordination graph.,2. Related Work,[0],[0]
"VDN does not make use of additional state information during training and can represent only a limited class of centralised action-value functions.
",2. Related Work,[0],[0]
A number of papers have established unit micromanagement in StarCraft as a benchmark for deep multi-agent RL.,2. Related Work,[0],[0]
Usunier et al. (2017) present an algorithm using a centralised greedy MDP and first-order optimisation.,2. Related Work,[0],[0]
Peng et al. (2017) also evaluate their methods on StarCraft.,2. Related Work,[0],[0]
"However, neither requires decentralised execution.",2. Related Work,[0],[0]
"Similar to our setup is the work of Foerster et al. (2017), who evaluate replay stabilisation methods for IQL on combat scenarios with up to five agents.",2. Related Work,[0],[0]
Foerster et al. (2018) also uses this setting.,2. Related Work,[0],[0]
"In this paper, we construct unit micromanagement tasks in the StarCraft II Learning Environment (SC2LE) (Vinyals et al., 2017) as opposed to StarCraft, because it is actively supported by the game developers and SC2LE offers a more stable testing environment.
",2. Related Work,[0],[0]
"QMIX relies on a neural network to transform the centralised state into the weights of another neural network, in a manner reminiscent of hypernetworks (Ha et al., 2017).",2. Related Work,[0],[0]
This second neural network is constrained to be monotonic with respect to its inputs by keeping its weights positive.,2. Related Work,[0],[0]
Dugas et al. (2009) investigate such functional restrictions for neural networks.,2. Related Work,[0],[0]
"A fully cooperative multi-agent task can be described as a Dec-POMDP (Oliehoek & Amato, 2016) consisting of a tuple G = 〈S,U, P, r, Z,O, n, γ〉. s ∈ S describes the true state of the environment.",3. Background,[0],[0]
"At each time step, each agent a ∈",3. Background,[0],[0]
"A ≡ {1, ..., n} chooses an action ua ∈ U , forming a joint action u ∈ U ≡ Un.",3. Background,[0],[0]
"This causes a transition on the environment according to the state transition function P (s′|s,u) :",3. Background,[0],[0]
"S×U×S → [0, 1].",3. Background,[0],[0]
All agents share the same reward function,3. Background,[0],[0]
"r(s,u) : S ×U → R and γ ∈",3. Background,[0],[0]
"[0, 1) is a discount factor.
",3. Background,[0],[0]
"We consider a partially observable scenario in which each agent draws individual observations z ∈ Z according to observation function O(s, a) :",3. Background,[0],[0]
S × A → Z. Each agent has an action-observation history τa ∈ T ≡,3. Background,[0],[0]
"(Z × U)∗, on which it conditions a stochastic policy πa(ua|τa) :",3. Background,[0],[0]
T × U →,3. Background,[0],[0]
"[0, 1].",3. Background,[0],[0]
"The joint policy π has a joint action-value function: Qπ(st,ut) = Est+1:∞,ut+1:∞",3. Background,[0],[0]
"[Rt|st,ut], where Rt = ∑∞ i=0",3. Background,[0],[0]
"γ irt+i is the discounted return.
",3. Background,[0],[0]
"Although training is centralised, execution is decentralised, i.e., the learning algorithm has access to all local actionobservation histories τ and global state s, but each agent’s learnt policy can condition only on its own actionobservation history τa.
3.1.",3. Background,[0],[0]
"Deep Q-Learning
Deep Q-learning represents the action-value function with a deep neural network parameterised by θ.",3. Background,[0],[0]
"Deep Q-networks (DQNs) (Mnih et al., 2015) use a replay memory to store the transition tuple 〈s, u, r, s′〉, where the state s′ is observed after taking the action u in state s and receiving reward r. θ is learnt by sampling batches of b transitions from the replay memory and minimising the squared TD error:
L(θ) = b∑ i=1",3. Background,[0],[0]
"[( yDQNi −Q(s, u; θ) )2] , (2)
where yDQN",3. Background,[0],[0]
"= r + γmaxu′ Q(s′, u′; θ−).",3. Background,[0],[0]
"θ− are the parameters of a target network that are periodically copied from θ and kept constant for a number of iterations.
",3. Background,[0],[0]
3.2.,3. Background,[0],[0]
"Deep Recurrent Q-Learning
In partially observable settings, agents can benefit from conditioning on their entire action-observation history.",3. Background,[0],[0]
Hausknecht & Stone (2015) propose Deep Recurrent Qnetworks (DRQN) that make use of recurrent neural networks.,3. Background,[0],[0]
"Typically, gated architectures such as LSTM (Hochreiter & Schmidhuber, 1997) or GRU (Chung et al., 2014) are used to facilitate learning over longer timescales.
3.3.",3. Background,[0],[0]
"Independent Q-Learning
Perhaps the most commonly applied method in multi-agent learning is independent Q-learning (IQL) (Tan, 1993), which decomposes a multi-agent problem into a collection of simultaneous single-agent problems that share the same environment.",3. Background,[0],[0]
"This approach does not address the nonstationarity introduced due to the changing policies of the learning agents, and thus, unlike Q-learning, has no convergence guarantees even in the limit of infinite exploration.",3. Background,[0],[0]
"In practice, nevertheless, IQL commonly serves as a surprisingly strong benchmark even in mixed and competitive games (Tampuu et al., 2017; Leibo et al., 2017).",3. Background,[0],[0]
"By contrast, value decomposition networks (VDNs) (Sunehag et al., 2017) aim to learn a joint action-value function Qtot(τ ,u), where τ ∈ T ≡ T n is a joint actionobservation history and u is a joint action.",3.4. Value Decomposition Networks,[0],[0]
"It represents Qtot as a sum of individual value functions Qa(τa, ua; θa), one for each agent a, that condition only on individual action-observation histories:
Qtot(τ ,u) = n∑ i=1",3.4. Value Decomposition Networks,[0],[0]
Qi(τ,3.4. Value Decomposition Networks,[0],[0]
"i, ui; θi).",3.4. Value Decomposition Networks,[0],[0]
"(3)
Strictly speaking, each Qa is a utility function (Guestrin et al., 2002) and not a value function since by itself it does not estimate an expected return.",3.4. Value Decomposition Networks,[0],[0]
"However, for terminological simplicity we refer to both Qtot and Qa as value functions.
",3.4. Value Decomposition Networks,[0],[0]
"The loss function for VDN is equivalent to (2), where Q is replaced by Qtot.",3.4. Value Decomposition Networks,[0],[0]
An advantage of this representation is that a decentralised policy arises simply from each agent performing greedy action selection with respect to its Qa.,3.4. Value Decomposition Networks,[0],[0]
"In this section, we propose a new approach called QMIX which, like VDN, lies between the extremes of IQL and centralised Q-learning, but can represent a much richer class of action-value functions.
",4. QMIX,[0],[0]
Key to our method is the insight that the full factorisation of VDN is not necessary in order to be able to extract decentralised policies that are fully consistent with their centralised counterpart.,4. QMIX,[0],[0]
"Instead, for consistency we only need to ensure that a global argmax performed on Qtot yields the same result as a set of individual argmax operations performed on each Qa:
argmax u",4. QMIX,[0],[0]
"Qtot(τ ,u) =
 argmaxu1 Q1(τ 1, u1)
...",4. QMIX,[0],[0]
"argmaxun Qn(τ n, un)
 .",4. QMIX,[0],[0]
"(4)
This allows each agent a to participate in a decentralised execution solely by choosing greedy actions with respect to its Qa.",4. QMIX,[0],[0]
"As a side effect, if (4) is satisfied, then taking the argmax of Qtot, required by off-policy learning updates, is trivially tractable.
",4. QMIX,[0],[0]
VDN’s representation is sufficient to satisfy (4).,4. QMIX,[0],[0]
"However, QMIX is based on the observation that this representation can be generalised to the larger family of monotonic functions that are also sufficient but not necessary to satisfy (4).",4. QMIX,[0],[0]
"Monotonicity can be enforced through a constraint on the relationship between Qtot and each Qa:
∂Qtot ∂Qa ≥ 0, ∀a ∈ A. (5)
To enforce (5), QMIX represents Qtot using an architecture consisting of agent networks, a mixing network, and a set of hypernetworks (Ha et al., 2017).",4. QMIX,[0],[0]
"Figure 2 illustrates the overall setup.
",4. QMIX,[0],[0]
"For each agent a, there is one agent network that represents its individual value functionQa(τa, ua).",4. QMIX,[0],[0]
"We represent agent networks as DRQNs that receive the current individual observation oat and the last action u a t−1 as input at each time step, as shown in Figure 2c.
",4. QMIX,[0],[0]
"The mixing network is a feed-forward neural network that takes the agent network outputs as input and mixes them monotonically, producing the values of Qtot, as shown in Figure 2a.",4. QMIX,[0],[0]
"To enforce the monotonicity constraint of (5), the weights (but not the biases) of the mixing network are restricted to be non-negative.",4. QMIX,[0],[0]
"This allows the mixing network to approximate any monotonic function arbitrarily closely (Dugas et al., 2009).
",4. QMIX,[0],[0]
The weights of the mixing network are produced by separate hypernetworks.,4. QMIX,[0],[0]
Each hypernetwork takes the state s as input and generates the weights of one layer of the mixing network.,4. QMIX,[0],[0]
"Each hypernetwork consists of a single linear layer, followed by an absolute activation function, to ensure that the mixing network weights are non-negative.",4. QMIX,[0],[0]
"The output of the hypernetwork is then a vector, which is reshaped into a matrix of appropriate size.",4. QMIX,[0],[0]
The biases are produced in the same manner but are not restricted to being non-negative.,4. QMIX,[0],[0]
The final bias is produced by a 2 layer hypernetwork with a ReLU non-linearity.,4. QMIX,[0],[0]
"Figure 2a illustrates the mixing network and the hypernetworks.
",4. QMIX,[0],[0]
The state is used by the hypernetworks rather than being passed directly into the mixing network because Qtot is allowed to depend on the extra state information in nonmonotonic ways.,4. QMIX,[0],[0]
"Thus, it would be overly constraining to pass some function of s through the monotonic network alongside the per-agent values.",4. QMIX,[0],[0]
"Instead, the use of hypernetworks makes it possible to condition the weights of the monotonic network on s in an arbitrary way, thus integrating the full state s into the joint action-value estimates as
flexibly as possible.
",4. QMIX,[0],[0]
"QMIX is trained end-to-end to minimise the following loss:
L(θ) = b∑ i=1",4. QMIX,[0],[0]
"[( ytoti −Qtot(τ ,u, s; θ) )2] , (6)
where b is the batch size of transitions sampled from the replay buffer, ytot = r + γmaxu′",4. QMIX,[0],[0]
"Qtot(τ ′,u′, s′; θ−) and θ− are the parameters of a target network as in DQN.",4. QMIX,[0],[0]
(6) is analogous to the standard DQN loss of (2).,4. QMIX,[0],[0]
"Since (4) holds, we can perform the maximisation of Qtot in time linear in the number of agents (as opposed to scaling exponentially in the worst case).",4. QMIX,[0],[0]
The value function class representable with QMIX includes any value function that can be factored into a non-linear monotonic combination of the agents’ individual value functions in the fully observable setting.,4.1. Representational Complexity,[0],[0]
This expands upon the linear monotonic value functions that are representable by VDN.,4.1. Representational Complexity,[0],[0]
"However, the constraint in (5) prevents QMIX from representing value functions that do not factorise in such a manner.
",4.1. Representational Complexity,[0],[0]
"Intuitively, any value function for which an agent’s best action depends on the actions of the other agents at the same time step will not factorise appropriately, and hence cannot be represented perfectly by QMIX.",4.1. Representational Complexity,[0],[0]
"However, QMIX can approximate such value functions more accurately than VDN.",4.1. Representational Complexity,[0],[0]
"Furthermore, it can take advantage of the extra state information available during training, which we show empirically.",4.1. Representational Complexity,[0],[0]
A more detailed discussion on the representation complexity is available in the supplementary materials.,4.1. Representational Complexity,[0],[0]
"To illustrate the effects of representational complexity of VDN and QMIX, we devise a simple two-step cooperative matrix game for two agents.
",5. Two-Step Game,[0],[0]
"At the first step, Agent 1 chooses which of the two matrix games to play in the next timestep.",5. Two-Step Game,[0],[0]
"For the first time step, the actions of Agent 2 have no effect.",5. Two-Step Game,[0],[0]
"In the second step, both agents choose an action and receive a global reward according to the payoff matrices depicted in Table 1.
",5. Two-Step Game,[0],[0]
We train VDN and QMIX on this task for 5000 episodes and examine the final learned value functions in the limit of full exploration ( = 1).,5. Two-Step Game,[0],[0]
"Full exploration ensures that each method is guaranteed to eventually explore all available game states, such that the representational capacity of the state-action value function approximation remains the only limitation.",5. Two-Step Game,[0],[0]
"The full details of the architecture and hyperparameters used are provided in the supplementary material.
",5. Two-Step Game,[0],[0]
"Table 2, which shows the learned values for Qtot, demonstrates that QMIX’s higher representational capacity allows
it to accurately represent the joint-action value function whereas VDN cannot.",5. Two-Step Game,[0],[0]
"This directly translates into VDN learning the suboptimal strategy of selecting Action A at the first step and receiving a reward of 7, whereas QMIX recovers the optimal strategy from its learnt joint-action values and receives a reward of 8.",5. Two-Step Game,[0],[0]
"In this section, we describe the decentralised StarCraft II micromanagement problems to which we apply QMIX and the ablations we consider.",6. Experimental Setup,[0],[0]
Real-time strategy (RTS) games have recently emerged as challenging benchmarks for the RL community.,6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"StarCraft, in particular, offers a great opportunity to tackle competitive and cooperative multi-agent problems.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
Units in StarCraft have a rich set of complex micro-actions that allow the learning of complex interactions between collaborating agents.,6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"Previous work (Usunier et al., 2017; Foerster et al., 2018; Peng et al., 2017) applied RL to the original version of StarCraft: BW, which made use of the standard API or related wrappers (Synnaeve et al., 2016).",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"We perform our experiments on the StarCraft II Learning Environment (SC2LE) (Vinyals et al., 2017), which is based on the second version of the game.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"Because it is supported by the developers of the game, SC2LE mitigates many of the practical difficulties in using StarCraft as an RL platform, such as the dependence on complicated APIs and external emulation software.
",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"In this work, we focus on the decentralised micromanagement problem in StarCraft II, in which each of the learning agents controls an individual army unit.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
We consider combat scenarios where two groups of identical units are placed symmetrically on the map.,6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"The units of the first, allied, group are controlled by the decentralised agents.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"The enemy units are controlled by a built-in StarCraft II AI, which makes use of handcrafted heuristics.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
The initial placement of units within the groups varies across episodes.,6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"The difficulty of the computer AI controlling the enemy units is set
to medium.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"At the beginning of each episode, the enemy units are ordered to attack the allies.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"We compare our results on a set of maps where each unit group consists of 3 Marines (3m), 5 Marines (5m), 8 Marines (8m), 2 Stalkers and 3 Zealots (2s 3z), 3 Stalkers and 5 Zealots (3s 5z), or 1 Colossus, 3 Stalkers and 5 Zealots (1c 3s 5z).
",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"Similar to the work of Foerster et al. (2018), the action space of agents consists of the following set of discrete actions: move[direction], attack[enemy id], stop, and noop.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"Agents can only move in four directions: north, south, east, or west.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
A unit is allowed to perform the attack[enemy id] action only if the enemy is within its shooting range.,6.1. Decentralised StarCraft II Micromanagement,[0],[0]
This facilitates the decentralisation of the problem and prohibits the usage of the attack-move macroactions that are integrated into the game.,6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"Furthermore, we disable the following unit behaviour when idle: responding to enemy fire and attacking enemies if they are in range.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"By doing so, we force the agents to explore in order to find the optimal combat strategy themselves, rather than relying on built-in StarCraft II utilities.
",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"Partial observability is achieved by the introduction of unit sight range, which restricts the agents from receiving information about allied or enemy units that are out of range.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"Moreover, agents can only observe others if they are alive and cannot distinguish between units that are dead or out of range.
",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"At each time step, the agents receive a joint reward equal to the total damage dealt on the enemy units.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"In addition, agents receive a bonus of 10 points after killing each opponent, and 200 points after killing all opponents.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"These rewards are all normalised to ensure the maximum cumulative reward achievable in an episode is 20.
",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"The full details of the environmental setup, architecture and training are available in the supplementary material.",6.1. Decentralised StarCraft II Micromanagement,[0],[0]
"We perform ablation experiments in order to investigate the influence of the inclusion of extra state information and the necessity of non-linear transformations in the mixing network.
",6.2. Ablations,[0],[0]
"First, we analyse the significance of extra state information on the mixing network by comparing against QMIX without hypernetworks.",6.2. Ablations,[0],[0]
"Thus, the weights and biases of the mixing network are learned in the standard way, without conditioning on the state.",6.2. Ablations,[0],[0]
We refer to this method as QMIX-NS.,6.2. Ablations,[0],[0]
"We take the absolute value of the weights in order to enforce the monotonicity constraint.
",6.2. Ablations,[0],[0]
"Second, we investigate the necessity of non-linear mixing by removing the hidden layer of the mixing network.",6.2. Ablations,[0],[0]
"This method can be thought of as an extension of VDN that uses
the state s to perform a weighted sum over Qa values.",6.2. Ablations,[0],[0]
"We call this method QMIX-Lin.
",6.2. Ablations,[0],[0]
"Third, we investigate the significance of utilising the state s in comparison to the non-linear mixing.",6.2. Ablations,[0],[0]
To do this we extend VDN by adding a state-dependent term to the sum of the agent’sQ-Values.,6.2. Ablations,[0],[0]
"This state-dependent term is produced by a network with a single hidden layer of 32 units and a ReLU non-linearity, taking in the state s as input (the same as the hypernetwork producing the final bias in QMIX).",6.2. Ablations,[0],[0]
"We refer to this method as VDN-S.
We also show the performance of a non-learning heuristicbased algorithm with full observability, where each agent attacks the closest enemy and continues attacking the same target until the unit dies.",6.2. Ablations,[0],[0]
"Afterwards, the agent starts attacking the nearest enemy and so forth.",6.2. Ablations,[0],[0]
"In order to evaluate each method’s performance, we adopt the following evaluation procedure: for each run of a method, we pause training every 100 episodes and run 20 independent episodes with each agent performing greedy decentralised action selection.",7. Results,[0],[0]
"The percentage of these episodes in which the method defeats all enemy units within the time limit is referred to as the test win rate.
",7. Results,[0],[0]
"Figures 3 and 4 plot the mean test win rate across 20 runs for each method on selected maps, together with 95% confidence intervals.",7. Results,[0],[0]
The graphs for all methods on all maps are available in the supplementary material.,7. Results,[0],[0]
"In all scenarios, IQL fails to learn a policy that consistently defeats the enemy.",7.1. Main Results,[0],[0]
"In addition, the training is highly unstable due to the non-stationarity of the environment which arises due to the other agents changing their behaviour during training.
",7.1. Main Results,[0],[0]
The benefits of learning the joint action-value function can be demonstrated by VDN’s superior performance over IQL in all scenarios.,7.1. Main Results,[0],[0]
"VDN is able to more consistently learn basic coordinated behaviour, in the form of focus firing which allows it to win the majority of its encounters on the 5m and 8m maps.",7.1. Main Results,[0],[0]
"On the 8m map, this simple strategy is sufficient for good performance, as evidenced by the extremely high win rate of the heuristic-based algorithm, and explains the performance parity with QMIX.",7.1. Main Results,[0],[0]
"However, on the 3m task, which requires more fine-grained control, it is unable to learn to consistently defeat the enemy.
",7.1. Main Results,[0],[0]
"QMIX is noticeably the strongest performer on all of the maps, in particular on the maps with hetergenous agent types.",7.1. Main Results,[0],[0]
"The largest performance gap can be seen in the
3s 5z and 1c 3s 5z maps, where VDN is unable to reach the performance of the simple heuristic.",7.1. Main Results,[0],[0]
The superior representational capacity of QMIX combined with the state information presents a clear benefit over a more restricted linear decomposition.,7.1. Main Results,[0],[0]
"Our additional ablation experiments reveal that QMIX outperforms, or is competitive with, all of its ablations discussed in Section 6.2.",7.2. Ablation Results,[0],[0]
Figure 4a shows that non-linear value function factorisation is not always required on a map with homogeneous agent types.,7.2. Ablation Results,[0],[0]
"However, the additional complexity introduced through the extra hidden layer does not slow down learning.",7.2. Ablation Results,[0],[0]
"In contrast, Figures 4b and 4c show that on a map with heterogeneous agent types a combination of both central state information and non-linear value function factorisation is required to achieve good performance.",7.2. Ablation Results,[0],[0]
"QMIX-NS performs on par or slightly better than VDN in both scenarios, which suggests that a non-linear decomposition is not always beneficial when not conditioning on the central state in complex scenarios.",7.2. Ablation Results,[0],[0]
"Additionally, the performance of VDN-S compared to QMIX-Lin shows the necessity of allowing a non-linear mixing in order to fully leverage central state information.",7.2. Ablation Results,[0],[0]
We examine the learned behaviours of the policies in order to better understand the differences between the strategies learnt by the different methods.,7.3. Learned Policies,[0],[0]
"On the 8m scenario, both QMIX and VDN learn the particularly sophisticated strategy of first positioning the units into a semicircle in order to fire at the incoming enemy units from the sides (as opposed to just head on).",7.3. Learned Policies,[0],[0]
"On the 2s 3z scenario, VDN first runs left and then attacks the enemy once they are in range with no regards to positioning or unit match-ups.",7.3. Learned Policies,[0],[0]
"QMIX, on the other hand learns to position the Stalkers so that the enemy Zealots cannot attack them.",7.3. Learned Policies,[0],[0]
This is especially important since Zealots counter Stalkers.,7.3. Learned Policies,[0],[0]
"QMIX achieves
this by having the allied Zealots first block off and then attack the enemy Zealots (whilst the Stalkers fire from a safe distance), before moving on to the enemy Stalkers.",7.3. Learned Policies,[0],[0]
The same behaviour is observed in the 3s 5z scenario for QMIX.,7.3. Learned Policies,[0],[0]
"VDN-S does not learn to protect the Stalkers from the Zealots, and first positions the units around their starting location and then attacks the enemy as they move in.
",7.3. Learned Policies,[0],[0]
The initial hump in the performance of both VDN and IQL is due to both methods initially learning the simple strategy of just attacking the first visible enemy (which is quite successful as shown by the heuristic).,7.3. Learned Policies,[0],[0]
"However, due to exploratory learning behaviour, they also attempt to move around (instead of just firing), which results in the rapid decline in performance.",7.3. Learned Policies,[0],[0]
"IQL is unable to then recover the initial strategy, whereas VDN learns how to combine small movements and firing together.",7.3. Learned Policies,[0],[0]
"This paper presented QMIX, a deep multi-agent RL method that allows end-to-end learning of decentralised policies in a centralised setting and makes efficient use of extra state information.",8. Conclusion,[0],[0]
"QMIX allows the learning of a rich joint actionvalue function, which admits tractable decompositions into per-agent action-value functions.",8. Conclusion,[0],[0]
"This is achieved by imposing a monotonicity constraint on the mixing network.
",8. Conclusion,[0],[0]
"Our results in decentralised unit micromanagement tasks in StarCraft II show that QMIX improves the final performance over other value-based multi-agent methods that employ less sophisticated joint state-value function factorisation, as well as independent Q-learning.
",8. Conclusion,[0],[0]
"In the near future, we aim to conduct additional experiments to compare the methods across tasks with a larger number and greater diversity of units.",8. Conclusion,[0],[0]
"In the longer term, we aim to complement QMIX with more coordinated exploration schemes for settings with many learning agents.",8. Conclusion,[0],[0]
This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement number 637713).,Acknowledgements,[0],[0]
"It was also supported by the OxfordGoogle DeepMind Graduate Scholarship, the UK EPSRC CDT in Autonomous Intelligent Machines and Systems, Chevening Scholarship, Luys Scholarship and an EPSRC grant (EP/M508111/1, EP/N509711/1).",Acknowledgements,[0],[0]
This work is linked to and partly funded by the project Free the Drones (FreeD) under the Innovation Fund Denmark and Microsoft.,Acknowledgements,[0],[0]
"The experiments were made possible by a generous equipment grant from NVIDIA.
",Acknowledgements,[0],[0]
We would like to thank Frans Oliehoek and Wendelin Boehmer for helpful comments and discussion.,Acknowledgements,[0],[0]
"We also thank Oriol Vinyals, Kevin Calderone, and the rest of the SC2LE team at DeepMind and Blizzard for their work on the interface.",Acknowledgements,[0],[0]
"In many real-world settings, a team of agents must coordinate their behaviour while acting in a decentralised way.",abstractText,[0],[0]
"At the same time, it is often possible to train the agents in a centralised fashion in a simulated or laboratory setting, where global state information is available and communication constraints are lifted.",abstractText,[0],[0]
"Learning joint actionvalues conditioned on extra state information is an attractive way to exploit centralised learning, but the best strategy for then extracting decentralised policies is unclear.",abstractText,[0],[0]
"Our solution is QMIX, a novel value-based method that can train decentralised policies in a centralised end-to-end fashion.",abstractText,[0],[0]
QMIX employs a network that estimates joint action-values as a complex non-linear combination of per-agent values that condition only on local observations.,abstractText,[0],[0]
"We structurally enforce that the joint-action value is monotonic in the per-agent values, which allows tractable maximisation of the joint action-value in off-policy learning, and guarantees consistency between the centralised and decentralised policies.",abstractText,[0],[0]
"We evaluate QMIX on a challenging set of StarCraft II micromanagement tasks, and show that QMIX significantly outperforms existing value-based multi-agent reinforcement learning methods.",abstractText,[0],[0]
QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 587–593 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
587",text,[0],[0]
"In the last decade, the distributed word representation (a.k.a word embedding) has attracted tremendous attention in the field of natural language processing (NLP).",1 Introduction,[0],[0]
"Instead of large vectors, such as the one-hot representation, the distributed word representation embeds semantic and syntactic characteristics of words into a low-dimensional space, which makes it popular in NLP applications.
",1 Introduction,[0],[0]
"The main idea of most word embedding models follows the distributional hypothesis (Harris, 1954), i.e., the embedding of each word may be inferred using its context.",1 Introduction,[0],[0]
"An important model family for distributional word representation learning is built based on the global matrix factorization approach (Deerwester et al., 1990; Lee and Seung, 2001; Srebro et al., 2005; Mnih and Hinton, 2007; Li et al., 2015; Wang and Cohen, 2016), in which a dimensionality reduction over a sparse matrix is performed to capture the statistical information about a corpus in low-dimensional vectors.",1 Introduction,[0],[0]
"Another model family is neural word embeddings (Levy and Goldberg, 2014b), some attempts include the famous Neural Probabilistic Language Model (Bengio et al., 2003), SGNS and
CBOW (Mikolov et al., 2013a,b), GloVe (Pennington et al., 2014) and their variants (Shazeer et al., 2016; Kenter et al., 2016; Ling et al., 2017; Patel et al., 2017).
",1 Introduction,[0],[0]
Most of these models capture the context information of each word using the co-occurrence matrix.,1 Introduction,[0],[0]
"However, the co-occurrence matrix only represents relatively local information, i.e., it describes context associations based on word pairs’ co-occurrence counts without considering global context perspective.",1 Introduction,[0],[0]
"Besides, the co-occurrence matrix is only an estimation of a corpus, which is only a sample of a language.",1 Introduction,[0],[0]
"A mass of related word pairs may not be observed in the corpus, and the latent relations between unobserved word pairs may not be modeled well due to the missing knowledge.
",1 Introduction,[0],[0]
Few attempts are carried out to indirectly deal with unobserved co-occurrence for dense neural word embeddings.,1 Introduction,[0],[0]
"SGNS (Mikolov et al., 2013a,b) indirectly addresses this problem through negative sampling.",1 Introduction,[0],[0]
"Swivel (Shazeer et al., 2016) improves GloVe by using a “soft hinge” loss to prevent from over-estimating zero co-occurrences.",1 Introduction,[0],[0]
"However, the latent relations between unobserved word pairs are not explicitly represented.",1 Introduction,[0],[0]
"There are also some works around semantic composition and distributional inference (Mitchell and Lapata, 2008; Erk and Padó, 2008, 2010; Reisinger and Mooney, 2010; Thater et al., 2011; Kartsaklis et al., 2013; Kober et al., 2016) that are explored to address the sparseness problem, but they are not designed for training neural word embeddings.
",1 Introduction,[0],[0]
"In this paper, we explore an approach that utilizes context overlap information to dig up more effective co-occurrence relations and propose extensions for GloVe and Swivel to validate the positive impact of introducing context overlap.",1 Introduction,[0],[0]
"In this work, we explore quantifying context overlap based on the observation that to a certain extent the overlap of Point-wise Mutual Information (PMI) (Church and Hanks, 1990) reflects context overlap.
",2 Quantify Context Overlap,[0],[0]
"As shown in Figure 1, two separate words may exhibit a particular aspect of interest or be semantically related when the overlap area between their PMI is relatively large.
",2 Quantify Context Overlap,[0],[0]
The calculation of complete PMI-weighted context overlap may be time-consuming when the number of words is large.,2 Quantify Context Overlap,[0],[0]
"To make the time complexity affordable, only the context words that have strong lexical association with a target word i are considered:
Si = {k ∈ V |PMI(i, k) > hPMI} (1)
in which V is the vocabulary, hPMI is a threshold which acts as a magnitude to shift PMI, and Si denotes the set that consists of the context words that have enough large PMI values with the target word i.",2 Quantify Context Overlap,[0],[0]
It is expected that most context information associated with the word i can be captured by its PMI values over Si.,2 Quantify Context Overlap,[0],[0]
"Then, we measure the degree of context overlap (CO) between two target words i, j as a function of their PMI values over the intersection of Si and Sj , i.e.,
CO(i, j) = ∑
k∈Si∩Sj
min(f(PMI(i, k)), f(PMI(j, k)))
(2) where f is a monotonic mapping function to rectify the data characteristics for certain objective function in word embedding training.
",2 Quantify Context Overlap,[0],[0]
"Compared to identity function f(x) = x, we find exponential function f(x) = exp(x) works much better in our experiments.",2 Quantify Context Overlap,[0],[0]
"For the quantized context overlap, the exponential mapping function results in a similar data distribution as the cooccurrence counts, i.e., few word pairs have extremely large values while most word pairs’ values are distributed in a relatively small range.",2 Quantify Context Overlap,[0],[0]
"We consider the original co-occurrence matrix as a description of first order co-occurrence relations, while the quantized context overlap as a description of second order co-occurrence relations (Schütze, 1998), i.e., co-co-occurrences, which is represented by “non-logarithmic PMI-weighted
context overlap” in this work.",3 Extend to Existing Models,[0],[0]
The context overlap between two words can be inferred even when they never co-occur in the corpus.,3 Extend to Existing Models,[0],[0]
"According to our statistics, more than 84% word pairs in the second order co-occurrence matrix are not included in the first order co-occurrence matrix.",3 Extend to Existing Models,[0],[0]
We expect introducing second order co-occurrence relations may enhance the quality of the word embedding that is originally trained on first order co-occurrence relations.,3 Extend to Existing Models,[0],[0]
"GloVe (Pennington et al., 2014) and Swivel (Shazeer et al., 2016) are extended by joint training with context overlap information in this paper.
",3 Extend to Existing Models,[0],[0]
GloVe,3 Extend to Existing Models,[0],[0]
"The logarithmic co-occurrence matrix is factorized in GloVe with bias terms, and a weighted least squares loss function is optimized:
JGloV e = ∑ i,j",3 Extend to Existing Models,[0],[0]
"λij(w T i w̃j+bi+b̃j−logXij)2 (3)
where Xij denotes the word-context cooccurrence count between a target word i and a context word j.",3 Extend to Existing Models,[0],[0]
"The model parameters to be learned include wi ∈ Rd, w̃j ∈ Rd, bi and b̃j , which correspond to target word vector, context word vector, bias terms associated with the target word and the context word, respectively.",3 Extend to Existing Models,[0],[0]
"λij is a weight whose value equals to (min(Xij , xmax)/xmax)
α.",3 Extend to Existing Models,[0],[0]
"To extend GloVe, two tasks are trained in parallel during the training process: One is the main task that follows the original GloVe training pro-
cess as above; Another one is an auxiliary task that tunes word embeddings using context overlap.",3 Extend to Existing Models,[0],[0]
"The parameters of word embeddings are shared in both tasks.
",3 Extend to Existing Models,[0],[0]
"Following GloVe-style loss function, in the auxiliary task, the dot products of word vectors are pushed to estimate logarithmic second order cooccurrence.",3 Extend to Existing Models,[0],[0]
"J (2)GloV e = ∑ i,j λ (2) ij",3 Extend to Existing Models,[0],[0]
(Aw T i wj+b (2) i +b (2) j −logX,3 Extend to Existing Models,[0],[0]
(2) ij ) 2 (4) where the superscripts (2) are used to differentiate with the terms in the original GloVe.,3 Extend to Existing Models,[0],[0]
"X(2)ij = CO(i, j) represents context overlap, a word independent learnable scale A is adopted to relieve the potential inconformity between first order and second order co-occurrences.",3 Extend to Existing Models,[0],[0]
"The weight λ(2)ij is similar to the original λij , but using a different hyperparameter x(2)max.
",3 Extend to Existing Models,[0],[0]
"The multi-task (Ruder, 2017) loss function is the weighted sum of the two tasks, i.e., J = JGloV e+β ·J (2)",3 Extend to Existing Models,[0],[0]
"GloV e, where the weight β is a hyperparameter.
",3 Extend to Existing Models,[0],[0]
"Swivel As pointed out by (Levy et al., 2015) , if the bias terms in GloVe are fixed to the logarithmic count of the corresponding word, the dot products of target word vectors and context word vectors are almost equivalent to the approximation of logarithmic PMI matrix with a shift of log ∑ i,j Xij .",3 Extend to Existing Models,[0],[0]
Submatrix-wise Vector Embedding Learner (Swivel) directly reconstructs the PMI matrix by dot product between target vectors and context vectors and deals with unobserved co-occurrences using a “soft hinge” loss function.,3 Extend to Existing Models,[0],[0]
"(Shazeer et al., 2016) details its loss functions and training process.",3 Extend to Existing Models,[0],[0]
"In our extended version, we add a supplementary loss function to handle second order co-occurrences.",3 Extend to Existing Models,[0],[0]
"When the second order cooccurrence X(2)ij is more than zero, the PMI of context overlap is approximated.
1 2 λ (2) ij",3 Extend to Existing Models,[0],[0]
(Aw T i wj,3 Extend to Existing Models,[0],[0]
"+B − PMI(2)(i, j))2 (5)
in which A, B are word independent learnable scale parameters, and PMI(2)(i, j) is the Pointwise Mutual Information computed on the second order co-occurrence matrix",3 Extend to Existing Models,[0],[0]
[X(2)ij ].,3 Extend to Existing Models,[0],[0]
"Corpus The training dataset contains 6 billion tokens collected from diversified corpora, including the News Crawl corpus (Chelba et al., 2013), the April 2010 Wikipedia dump (Shaoul, 2010; Lee and Chen, 2017), and a year-2012 subset of the Reddit comment datasets 1.
",4.1 Setup,[0],[0]
"Preprocessing Following (Lee and Chen, 2017), the Stanford tokenizer is used to process the training corpus, which are split into sentences with characters converted to lower cases.",4.1 Setup,[0],[0]
"Punctuations are removed.
",4.1 Setup,[0],[0]
Parameter Configuration,4.1 Setup,[0],[0]
The vocabularies are limited to the 200K most frequent words.,4.1 Setup,[0],[0]
"Following (Pennington et al., 2014), a decreasing weighting function is adopted to construct the cooccurrence matrix.",4.1 Setup,[0],[0]
"We use symmetric context window of five words to the left and five words to the right.
",4.1 Setup,[0],[0]
"For GloVe, recommended parameters in (Pennington et al., 2014) are used.",4.1 Setup,[0],[0]
"Specifically, we set α = 34 , xmax = 100, initial learning rate as 0.05, 100 iterations.",4.1 Setup,[0],[0]
"For Swivel, recommended parameters in (Shazeer et al., 2016) are used.",4.1 Setup,[0],[0]
"The weighting function is 0.1 + 0.25x0.5ij , each shard is sampled about 100 times.",4.1 Setup,[0],[0]
"But we set the block size as 4000 so that the vocabulary size can be divided exactly.
",4.1 Setup,[0],[0]
"For the auxiliary tasks, we tune the hyperparameters on the small News Crawl corpus.",4.1 Setup,[0],[0]
"And we find that in an appropriate range, the threshold hPMI is not sensitive to the performance.",4.1 Setup,[0],[0]
"In this paper, hPMI , x (2) max and β are set to log 100, 10000 and 0.2 respectively.",4.1 Setup,[0],[0]
"Since there is no difference between target vectors and context vectors (except random initialization), in order to keep symmetry, we not only approximate context overlap between target vectors, but also approximate context overlap between context vectors simultaneously.",4.1 Setup,[0],[0]
Final vectors are the sum of w and w̃ in both GloVe and Swivel.,4.1 Setup,[0],[0]
Table 1 shows the evaluation results of word similarity tasks and word analogy tasks.,4.2 Intrinsic Evaluation,[0],[0]
Word similarity is measured as the Spearman’s rank correlation ρ between human-judged similarity and cosine distance of word vectors.,4.2 Intrinsic Evaluation,[0],[0]
"In word analogy
1Available at https://files.pushshift.io/ reddit/comments/
task, the questions are answered over the whole vocabulary through 3CosMul (Levy and Goldberg, 2014a).",4.2 Intrinsic Evaluation,[0],[0]
"In addition to GloVe and Swivel, the evaluations of SGNS are also reported for reference.",4.2 Intrinsic Evaluation,[0],[0]
"We train SGNS with the word2vec tool, using symmetric context window of five words to the left and five words to the right, and 5 negative samples.
",4.2 Intrinsic Evaluation,[0],[0]
"As can be seen from the table, the context overlap information enhanced word embeddings perform better in most word similarity tasks and get higher analogy accuracy in semantic aspect at the cost of syntactic score.",4.2 Intrinsic Evaluation,[0],[0]
"The improved semantics performance, to a certain extent, reflects second order co-occurrence relations are more semantic.",4.2 Intrinsic Evaluation,[0],[0]
"Text classification tasks are conducted on five shared benchmark datasets from (Kim, 2014) including binary classification tasks CR (Hu and Liu, 2004), MR (Pang and Lee, 2005), Subj (Pang and Lee, 2004) and multiple classification tasks TREC (Li and Roth, 2002), SST1 (Socher et al., 2013).",4.3 Text Classification,[0],[0]
Texts are preprocessed following the description of Section 4.1.,4.3 Text Classification,[0],[0]
"We train Convolutional Neural Networks (CNN) on top of our static pretrained word vectors following (Kim, 2014).",4.3 Text Classification,[0],[0]
"To avoid the high-risk of single-run estimate being false (Melis et al., 2017; Reimers and Gurevych, 2017), average classification accuracies of 20 runs are reported as the final scores.",4.3 Text Classification,[0],[0]
The results are shown in Table 2.,4.3 Text Classification,[0],[0]
As can be seen from the results that the enhanced word embeddings outperform the baselines.,4.3 Text Classification,[0],[0]
"As it is known to all, word frequency plays an important role in the computation of word embeddings (Gittens et al., 2017).",5 Model Analysis,[0],[0]
"Inspired from
the graph in (Shazeer et al., 2016), relations between word analogy accuracy and the log mean frequency of the words in analogy questions and answers are plotted on Figure 2.",5 Model Analysis,[0],[0]
"The word embeddings trained by GloVe with or without context overlap information are used here.
",5 Model Analysis,[0],[0]
An obvious semantic performance improvement is observed in the range of low frequency.,5 Model Analysis,[0],[0]
Our observation of second order co-occurrences may explain this fact.,5 Model Analysis,[0],[0]
"We randomly sample 1 million word pairs, and rank these word pairs in descending order by their quantized context overlap.",5 Model Analysis,[0],[0]
"In all the word pairs, average word frequency is 13934.4.",5 Model Analysis,[0],[0]
"However, it is only 1676.1 in the top 0.1% word pairs, it is 3984.8 in the top 1%, and it is 7904.9 in the top 10%.",5 Model Analysis,[0],[0]
"This may be caused by PMI’s bias towards infrequent words, but it illustrates infrequent words carry more information in second order co-occurrence relations.",5 Model Analysis,[0],[0]
"In this paper, we propose an empirical metric to enhance the word embeddings through estimating second order co-occurrence relations using con-
text overlap.",6 Conclusion,[0],[0]
"Instead of only local statistical information, context overlap leverages global association distribution to measure word pairs correlation.
",6 Conclusion,[0],[0]
"The proposed method is easy to extend to existing models, such as GloVe and Swivel, by an auxiliary objective function.",6 Conclusion,[0],[0]
"The improvement in experimental results helps to validate the positive impact of introducing quantized context overlap.
",6 Conclusion,[0],[0]
We have considered the feasibility of enriching SGNS and CBOW with information from contextoverlap.,6 Conclusion,[0],[0]
"However, because of their training mode, we can’t remake them in a straightforward way following their “original spirit”.",6 Conclusion,[0],[0]
"When training SGNS and CBOW, the program scans the training text.",6 Conclusion,[0],[0]
The target and context words are chosen using a slide window and negative sampling is used.,6 Conclusion,[0],[0]
"In this process, no co-occurrence matrix is explicitly computed, and we fail to extend it in a united form as we extend GloVe and Swivel.",6 Conclusion,[0],[0]
The extensions for GloVe and Swivel can also be used for reference for extending other word embedding approaches that are trained on co-occurrence matrix.,6 Conclusion,[0],[0]
The exploration for second order co-occurrence can be traced back to 1990s.,6 Conclusion,[0],[0]
"We think it is helpful to revive the classical method in a modern, embedding driven way.",6 Conclusion,[0],[0]
"How to integrate second order co-occurrence information for approaches like SGNS, CBOW should be an interesting future work.
",6 Conclusion,[0],[0]
"As future works, we suggest further investigating the characteristics of context overlap in diversified ways.",6 Conclusion,[0],[0]
"Most models for learning word embeddings are trained based on the context information of words, more precisely first order cooccurrence relations.",abstractText,[0],[0]
"In this paper, a metric is designed to estimate second order cooccurrence relations based on context overlap.",abstractText,[0],[0]
The estimated values are further used as the augmented data to enhance the learning of word embeddings by joint training with existing neural word embedding models.,abstractText,[0],[0]
Experimental results show that better word vectors can be obtained for word similarity tasks and some downstream NLP tasks by the enhanced approach.,abstractText,[0],[0]
Quantifying Context Overlap for Training Word Embeddings,title,[0],[0]
"Change detection, namely the problem of analyzing a data stream to detect changes in the data-generating distribution, is very relevant in machine-learning and is typically addressed in an unsupervised manner.",1. Introduction,[0],[0]
"This approach is generally dictated by many practical aspects, which include the unpredictability of the change and the fact that the training set often contains only stationary data.",1. Introduction,[0],[0]
"As a matter of fact,
1Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy.",1. Introduction,[0],[0]
"2Institute of Intelligent Systems for Automation, National Research Council, Genova, Italy.",1. Introduction,[0],[0]
"Correspondence to: Diego Carrera <diego.carrera@polimi.it>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
most change-detection tests in the literature (Basseville & Nikiforov, 1993; Lung-Yut-Fong et al., 2011; Ross et al., 2011; Kuncheva, 2013) consist of three major ingredients: i) a model describing the distribution of stationary data, φ0, that is typically learned from a training set, ii) a test statistic T used to assess the conformance of test data with the learned model, and iii) a decision rule that monitors T to detect changes in φ0.",1. Introduction,[0],[0]
"Needless to say, all these have to be wisely designed and combined to yield a sound test that can provide prompt detections as well as a controlled False Positive Rate (FPR), which is one of the primary concerns in change detection.",1. Introduction,[0],[0]
"Unfortunately, when it comes to monitoring multivariate data, it is difficult to find good density models and test statistics that do not depend on φ0: this represents a severe limitation for real-world monitoring problems, where the stream distribution is unknown.",1. Introduction,[0],[0]
"Our work presents an efficient change-detection test for multivariate data that overcomes this limitation.
",1. Introduction,[0],[0]
"The first change-detection tests were developed to monitor univariate data streams in the statistical process control literature (Basseville & Nikiforov, 1993).",1. Introduction,[0],[0]
"In classification problems, changes in the data stream are known as concept drift (Gama et al., 2014) and are detected by monitoring the sequence of classification errors on supervised data (Harel et al., 2014; Alippi et al., 2013; Bifet & Gavalda, 2007).",1. Introduction,[0],[0]
"Many change-detection tests are parametric, i.e., they assume that φ0 belongs to a known family, e.g., (Page, 1954), or are based on ad-hoc statistics that detect specific changes, e.g., the Hotelling statistic (Lehmann & Romano, 2006).",1. Introduction,[0],[0]
"Most nonparametric statistics are instead based on ranking, e.g., the Kolmogorov-Smirnov (Ross & Adams, 2012) and Lepage (Ross et al., 2011) statistics, and can be applied exclusively to univariate data.
",1. Introduction,[0],[0]
"There exist a few multivariate tests able to detect any distribution change (Lung-Yut-Fong et al., 2011; Justel et al., 1997).",1. Introduction,[0],[0]
"Two popular approaches consists either in reducing the data dimension by PCA (Kuncheva, 2013; Qahtan et al., 2015) or computing the likelihood with respect to a model fitted on a training set, e.g., a Gaussian mixture (Kuncheva, 2013; Alippi et al., 2016), a Gaussian process (Saatçi et al., 2010) or a kernel density estimator (Krempl, 2011).",1. Introduction,[0],[0]
In the latter case the change-detection problem boils down to monitoring a univariate stream.,1. Introduction,[0],[0]
"Unfortunately, in these cases, T often depends on φ0, and detection rules be-
come heuristic in nature (Kuncheva, 2013; Ditzler & Polikar, 2011) preventing a proper control over the FPR.",1. Introduction,[0],[0]
"Histograms, which are perhaps the most natural candidates for describing densities, enable a different form of monitoring that is based on a comparison among distributions (Ditzler & Polikar, 2011; Boracchi et al., 2017).",1. Introduction,[0],[0]
"However, they are often implemented over regular grids and require a number of bins that grows exponentially with the data dimension.",1. Introduction,[0],[0]
"Only a few change-detection solutions (Dasu et al., 2006; Boracchi et al., 2017) adopt alternative partitioning schemes that scale well in high dimensions.",1. Introduction,[0],[0]
"In particular, kqd-trees (Dasu et al., 2006) were introduced as a variant of kd-trees (Bentley, 1975) to guarantee that all the leaves contain a minimum number of training samples and have a minimum size.",1. Introduction,[0],[0]
"In (Boracchi et al., 2017)",1. Introduction,[0],[0]
"it is shown that histograms built on uniform-density partitions rather than regular grids provide superior detection performance.
",1. Introduction,[0],[0]
"Our main contribution is QuantTree, a recursive binary splitting scheme that defines histograms for changedetection purposes.",1. Introduction,[0],[0]
The most prominent advantage of using QuantTree is that the distribution of any statistic defined over the resulting histograms does not depend on φ0.,1. Introduction,[0],[0]
"This implies that decision rules to be used in multivariate change-detection problems do not depend on the data, and can be numerically computed from synthetically generated univariate sequences.",1. Introduction,[0],[0]
"Moreover, histograms defined by QuantTree can have a pre-assigned number of bins and can be represented as a tree, thus enabling a very efficient computation of test statistics.
",1. Introduction,[0],[0]
"QuantTree (Section 3) iteratively divides the input space by means of binary splits on a single covariate, where the cutting points are defined by the quantiles of the marginal distributions.",1. Introduction,[0],[0]
"This splitting strategy is similar to the one adopted by kd-trees (Bentley, 1975), where the split is performed w.r.t.",1. Introduction,[0],[0]
the median value of the marginal.,1. Introduction,[0],[0]
"Such a simple construction scheme can be handled analytically, as it is possible to prove (Section 4) that the distribution of each bin probability does not depend on φ0.",1. Introduction,[0],[0]
Our experiments (Section 5) show that QuantTree enables good detection performance in high dimensional streams.,1. Introduction,[0],[0]
"Moreover, when testing few samples, QuantTree guarantees a better FPR control than the Pearson goodness-of-fit test and tests based on empirical thresholds computed through bootstrap.",1. Introduction,[0],[0]
We also show that histograms constructed with a few bins gathering the same density under φ0 achieve higher power than monitoring schemes based on different histograms.,1. Introduction,[0],[0]
"Before the change, namely in stationary conditions, data in the monitored stream x ∈ Rd are independent and identically distributed (i.i.d.)",2. Problem Formulation,[0],[0]
"realizations of a continuous random vector X0 having an unknown probability density function
(pdf) φ0, whose support is X ⊆ Rd.",2. Problem Formulation,[0],[0]
"We assume that a training set TR = {xi ∈ X , i = 1, . . .",2. Problem Formulation,[0],[0]
", N} containing N stationary data (i.e., xi ∼ φ0) is provided.
",2. Problem Formulation,[0],[0]
"Histograms: we define a histogram as:
h = {(Sk, π̂k)}k=1,...,K , (1) where the K subsets Sk ⊆ X form a partition of Rd, i.e.,⋃K k=1 Sk = Rd and Sj ∩ Si = ∅, for j 6=",2. Problem Formulation,[0],[0]
"i, and each π̂k ∈",2. Problem Formulation,[0],[0]
"[0, 1] corresponds to the probability for data generated from φ0 to fall inside Sk.",2. Problem Formulation,[0],[0]
"Both the subsets {Sk}k and probabilities {π̂k}k can be adaptively defined from training data TR, and in particular π̂k is typically estimated as π̂k = Lk/N , i.e. the number of training samples LK belonging to Sk over the number of points in TR.
Batch-wise monitoring: for the sake of simplicity, we analyze the incoming data in batches W = {x1, . . .",2. Problem Formulation,[0],[0]
",xν} of ν samples.",2. Problem Formulation,[0],[0]
We detect changes by an hypothesis test (HT) which assesses whether data in W are consistent with a reference histogram h learned from TR.,2. Problem Formulation,[0],[0]
"In particular, this hypothesis test can be stated as follows:
",2. Problem Formulation,[0],[0]
H0 :W ∼ φ0 vs H1 :W ∼ φ1 6= φ0 (2) where φ1 represents the unknown post-change distribution.,2. Problem Formulation,[0],[0]
"We focus on HTs that are based on a test statistic Th defined over the histogram h, like for instance the Pearson statistic (Lehmann & Romano, 2006).",2. Problem Formulation,[0],[0]
"Thus, Th uniquely depends on {yk}k=1,...,K , where yk denotes the number of samples in W falling in Sk.",2. Problem Formulation,[0],[0]
"We detect a change in the incoming W when
Th(W ) = Th(y1, . . .",2. Problem Formulation,[0],[0]
", yK)",2. Problem Formulation,[0],[0]
>,2. Problem Formulation,[0],[0]
"τ, (3) where τ ∈ R is a threshold that controls the FPR, namely the proportion of type I errors (Lehmann & Romano, 2006).
",2. Problem Formulation,[0],[0]
"Goal: our goal is two-fold, i) learn a histogram h from TR to be used for change-detection purposes and ii) for each given test statistic Th and reference FPR value α, define a threshold τ such that
Pφ0(Th(W )",2. Problem Formulation,[0],[0]
> τ) ≤,2. Problem Formulation,[0],[0]
"α, (4) where Pφ0 denotes the probability under the null hypothesis that W contains samples generated from φ0.
",2. Problem Formulation,[0],[0]
There are two important comments.,2. Problem Formulation,[0],[0]
"First, while (3) might seem an oversimplified monitoring scheme, this is enough to demonstrate that when histograms are built through QuantTree, the monitoring can be performed independently of φ0.",2. Problem Formulation,[0],[0]
"As a consequence, test statistics Th can be potentially employed in sequential monitoring schemes like (Ross & Adams, 2012).",2. Problem Formulation,[0],[0]
"Second, we focus on generalpurpose tests, which are able to detect any distribution change φ0 → φ1 as well as on histograms that can model densities in high dimensions, i.e., d 1.
",2. Problem Formulation,[0],[0]
Algorithm 1,2. Problem Formulation,[0],[0]
QuantTree Input: Training set TR containing N stationary points in X ; number of bins K; target probabilities {πk}k.,2. Problem Formulation,[0],[0]
Output:,2. Problem Formulation,[0],[0]
"The histogram h = {(Sk, π̂k)}k.",2. Problem Formulation,[0],[0]
"1: Set N0 = N , L0 = 0.",2. Problem Formulation,[0],[0]
"2: for k = 1, . . .",2. Problem Formulation,[0],[0]
",K do 3: Set Nk = Nk−1",2. Problem Formulation,[0],[0]
"− Lk−1, Xk = X \",2. Problem Formulation,[0],[0]
"⋃ j<k Sj , and
Lk = round(πkN).",2. Problem Formulation,[0],[0]
"4: Choose a random component i ∈ {1, . . .",2. Problem Formulation,[0],[0]
", d}.",2. Problem Formulation,[0],[0]
5: Define zn =,2. Problem Formulation,[0],[0]
[xn]i for each xn ∈ Xk. 6: Sort {zn}: z(1) ≤ z(2) ≤ . . .,2. Problem Formulation,[0],[0]
z(Nk),2. Problem Formulation,[0],[0]
.,2. Problem Formulation,[0],[0]
"7: Draw γ ∈ {0, 1} from a Bernoulli(0.5).",2. Problem Formulation,[0],[0]
8: if γ = 0 then 9: Define Sk = {x ∈,2. Problem Formulation,[0],[0]
Xk,2. Problem Formulation,[0],[0]
"[x]i ≤ z(Lk)}.
",2. Problem Formulation,[0],[0]
10: else 11: Define Sk = {x ∈,2. Problem Formulation,[0],[0]
Xk [x]i ≥ z(Nk−Lk+1)}.,2. Problem Formulation,[0],[0]
12: end if 13: Set π̂k = Lk/N .,2. Problem Formulation,[0],[0]
14: end for,2. Problem Formulation,[0],[0]
"Here we describe QuantTree1, an algorithm to define histograms h through a recursive binary splitting of the input space X .",3. The QuantTree Algorithm,[0],[0]
"This algorithm takes as input a training set TR containing N stationary points, the number of bins K in the histogram, and the target probabilities on each bin {πk}k=1,...,K , and returns a histogram h = {(Sk, π̂k)}k=1,...,K , where each π̂k represents an estimate of the probability for a sample drawn from φ0 to fall in Sk.
",3. The QuantTree Algorithm,[0],[0]
"Algorithm 1 presents in detail the iterative formulation of QuantTree, which constructs a new bin of h at each step",3. The QuantTree Algorithm,[0],[0]
k.,3. The QuantTree Algorithm,[0],[0]
"We denote by Xk ⊆ X the subset of the input space that still has to be partitioned (i.e., Xk = X \",3. The QuantTree Algorithm,[0],[0]
⋃ j<k Sk) and by Nk the number of points of TR belonging to Xk.,3. The QuantTree Algorithm,[0],[0]
We compute (line 3) the number of training points that has to fall inside Sk as Lk = round(πkN).,3. The QuantTree Algorithm,[0],[0]
"The subset Sk is then defined by splitting Xk along a component i ∈ {1, . . .",3. The QuantTree Algorithm,[0],[0]
", d} that is randomly chosen with uniform probability (line 4).",3. The QuantTree Algorithm,[0],[0]
The splitting point is defined by sorting zn =,3. The QuantTree Algorithm,[0],[0]
"[xn]i, i.e., the values of the i-th component for each xn ∈ Xk (lines 5).",3. The QuantTree Algorithm,[0],[0]
We thus obtain z(1) ≤ z(2) ≤ · · · ≤ z(Nk) (line 6) and we define Sk by splitting Xk w.r.t. z(Lk) or z(Nk−Lk+1) (lines 7-11).,3. The QuantTree Algorithm,[0],[0]
"In both cases Sk contains Lk points among the N in X , thus the estimated probability of Sk is π̂k = Lk/N (line 13).",3. The QuantTree Algorithm,[0],[0]
"This procedure is iterated until K subsets are extracted.
",3. The QuantTree Algorithm,[0],[0]
"QuantTree divides X in a given number of subsets, where each Sk has an estimated probability π̂k ' πk, and the
1The implementation of QuantTree is available at http:// home.deib.polimi.it/boracchi/Projects
Algorithm 2 Numerical procedure to compute thresholds Input: Test statistic Th; arbitrarily chosen ψ0; the number
B of datasets and batches to compute the threshold; the number of points ν in each batch; N ,K, and π̂k as in Algorithm 1; the desired FPR α.",3. The QuantTree Algorithm,[0],[0]
"Output: The value τ of the threshold 1: for b = 1, . . .",3. The QuantTree Algorithm,[0],[0]
", B do 2: Draw from ψ0 a training set TRb of N samples.",3. The QuantTree Algorithm,[0],[0]
"3: Use QuantTree to compute the histogram hb with K bins and target probabilities {πk}k over TR.
4: Draw a batch Wb containing ν points from φ0.",3. The QuantTree Algorithm,[0],[0]
5: Compute the value tb = Th(W ).,3. The QuantTree Algorithm,[0],[0]
"6: end for 7: Compute the threshold τ as in (5).
",3. The QuantTree Algorithm,[0],[0]
equality holds when πkN is integer.,3. The QuantTree Algorithm,[0],[0]
"Since the probabilities πk are set a priori, in what follows we use πk in place of π̂k.",3. The QuantTree Algorithm,[0],[0]
Indexes i and parameter γ are randomly chosen to add variability to the histogram construction.,3. The QuantTree Algorithm,[0],[0]
"Figure 1(a) shows a tree obtained from a bivariate Gaussian training set, defined by K = 4 bins, each having probability πk = N/4.",3. The QuantTree Algorithm,[0],[0]
A key feature of a histogram computed by QuantTree is that any statistic Th built over it has a distribution that is independent from φ0.,3.1. Computation of Distribution-Free Test Statistics,[0],[0]
"This result follows from Theorem 1, that is proved in Section 4.
",3.1. Computation of Distribution-Free Test Statistics,[0],[0]
Theorem 1.,3.1. Computation of Distribution-Free Test Statistics,[0],[0]
Let Th(·) be defined as in (3) over the histogram h computed by QuantTree.,3.1. Computation of Distribution-Free Test Statistics,[0],[0]
"When W ∼ φ0, the distribution of Th(W ) depends only on ν, N and {πk}k.
",3.1. Computation of Distribution-Free Test Statistics,[0],[0]
"Theorem 1 implies that we can numerically compute the thresholds for any statistic Th defined on histograms, provided ν, N and {πk}, thus disregarding φ0 and the data dimension d. To this end, we synthetically generate data from a conveniently chosen distribution ψ0, and we follow the procedure outlined in Algorithm 2 to estimate the threshold τ for HT in (2) yielding a desired FPR α.",3.1. Computation of Distribution-Free Test Statistics,[0],[0]
"At first we generate B training sets {TRb}b=1,...,B , sampling N points from ψ0 and, for each training set, we build a histogram hb using QuantTree (lines 2-3).",3.1. Computation of Distribution-Free Test Statistics,[0],[0]
"Then, for each hb we generate a batch Wb of ν points drawn from ψ0, and compute the value of the statistic tb = Th(Wb) (lines 4-5).",3.1. Computation of Distribution-Free Test Statistics,[0],[0]
"Finally, we estimate τ (line 7) from the set TB = {t1, . . .",3.1. Computation of Distribution-Free Test Statistics,[0],[0]
", tB} as the 1 − α quantile of the empirical distribution of Th over the generated batches, i.e.
τ = min { t ∈ TB : #{v ∈ TB : v > t} ≤ αB } , (5)
where #A denotes the cardinality of a set A.
To take full advantage of the distribution-free nature of the procedure, we set ψ0 to a univariate uniform distribution
U(0, 1).",3.1. Computation of Distribution-Free Test Statistics,[0],[0]
"This allows to obtain high accuracy on the estimation of the thresholds, since we can use very large values of B with limited computational cost.",3.1. Computation of Distribution-Free Test Statistics,[0],[0]
"We consider two meaningful examples of statistics Th that can be employed for batch-wise monitoring through histograms: the Pearson statistic and the total variation (Lehmann & Romano, 2006).",3.2. Considered Statistics,[0],[0]
"The Pearson statistic is defined as
T Ph (W ) =",3.2. Considered Statistics,[0],[0]
K∑ k=1,3.2. Considered Statistics,[0],[0]
"(yk − νπk)2 νπk , (6)
while the total variation is defined as
T TVh (W ) = 1
2 K∑ k=1 |yk",3.2. Considered Statistics,[0],[0]
− νπk| .,3.2. Considered Statistics,[0],[0]
"(7)
It is well known that, when {πk}k are the true probabilities of the bins {Sk}k, under the null hypothesis the statistic T Ph (W ) is asymptotically distributed as a χ2K−1.",3.2. Considered Statistics,[0],[0]
"However, when the πk are estimated, the threshold obtained from the χ2K−1 distribution does not allow to properly control the FPR, and this effect is more evident when yk is small.",3.2. Considered Statistics,[0],[0]
"In contrast, thresholds defined by Algorithm 2 hold also in case of limited sample size, since they are not based on an asymptotic result.
",3.2. Considered Statistics,[0],[0]
"These two statistics will be used for our experiments in Section 5, using thresholds reported in Table 1 for different values of N , K, ν and choosing πk = 1/K, k = 1, . . .",3.2. Considered Statistics,[0],[0]
",K. These values have been computed applying the procedure described in Algorithm 2 with B = 2.5 · 106.",3.2. Considered Statistics,[0],[0]
"We note that both statistics T Ph and T TVh assume only discrete values, therefore it is not always possible to set the threshold τ yielding the FPR exactly equal to α, but only to ensure that the FPR does not exceed α.",3.2. Considered Statistics,[0],[0]
"We remark that since the histogram h computed by QuantTree is exclusively defined on the marginal probabilities of single components, the dimensionality of the input data d does not impact the overall computational cost.",3.3. Computational Remarks,[0],[0]
"In fact, the computational cost of building a QuantTree is dominated by sorting the covariates (Algorithm 1 line 6), which is performed K times on an progressively smaller number of samples at each iteration.",3.3. Computational Remarks,[0],[0]
"Therefore, the overall complexity of constructing a QuantTree is O(KN logN).",3.3. Computational Remarks,[0],[0]
"In case of univariate distribution (i.e., d = 1), the complexity is reduced toO(N logN), since the partition {Sk}k can be defined through a single sorting operation.
",3.3. Computational Remarks,[0],[0]
"Since any histogram h computed by QuantTree can be represented as a tree structure, it is very efficient to identify
the bin where any testing point belongs to.",3.3. Computational Remarks,[0],[0]
"In fact, during monitoring, at most K IF-THEN operations (that reduces to logK when d = 1) have to be performed for each input sample x.",3.3. Computational Remarks,[0],[0]
"Moreover, in contrast with histograms based on regular grids, the number of binsK is here a priori defined, and does not need to grow exponentially with d.",3.3. Computational Remarks,[0],[0]
We prove Theorem 1 showing that the distribution of any test statistic Th defined over an histogram h computed by QuantTree does not depend on φ0.,4. Theoretical Analysis,[0],[0]
"To this end, we first prove some preliminary propositions to characterize the distribution of the true probability of each bin Sk under φ0:
pk = Pφ0(Sk), (8)
which is also a random variable as it depends on the training data TR.
For the sake of simplicity, we assume that QuantTree always splits with respect to the left tail, i.e., γ = 0 in line 8 of Algorithm 1 (proofs hold when γ ∼ Bernoulli(0.5)) and, to simplify the notation, we will omit the subscript φ0 from Pφ0 , thus P denotes the probability computed w.r.t. φ0.",4. Theoretical Analysis,[0],[0]
"The following proposition will be used to derive the distributions of pk.
Proposition 1.",4. Theoretical Analysis,[0],[0]
"Let x1, . . .",4. Theoretical Analysis,[0],[0]
",xM",4. Theoretical Analysis,[0],[0]
be i.i.d.,4. Theoretical Analysis,[0],[0]
realizations of a continuous random vector X defined over D ⊆ Rd.,4. Theoretical Analysis,[0],[0]
Let us define the i-th component of x as z =,4. Theoretical Analysis,[0],[0]
"[x]i, and denote with z(1) ≤ z(2) ≤ · · · ≤ z(M) the M sorted components of x1, . . .",4. Theoretical Analysis,[0],[0]
",xM .",4. Theoretical Analysis,[0],[0]
"For any L ∈ {1, . . .",4. Theoretical Analysis,[0],[0]
",M} we define the set
Qi,L := {x ∈ D :",4. Theoretical Analysis,[0],[0]
[x]i ≤ z(L)}.,4. Theoretical Analysis,[0],[0]
"(9) Then, for each i ∈ {1, . . .",4. Theoretical Analysis,[0],[0]
", d}, the random variable p = PX(Qi,L) is distributed as a Beta(L,M − L+ 1).
",4. Theoretical Analysis,[0],[0]
Proof.,4. Theoretical Analysis,[0],[0]
"The proof consists of showing that p is an order statistic of the uniform distribution, which in turns follows a Beta distribution.",4. Theoretical Analysis,[0],[0]
"For this purpose, we consider X defined over Rd and PX(Rd\D) = 0, thus p can be expressed as
p = PX(Qi,L) =",4. Theoretical Analysis,[0],[0]
PX(x ∈,4. Theoretical Analysis,[0],[0]
Rd :,4. Theoretical Analysis,[0],[0]
[x]i ≤ z(L)),4. Theoretical Analysis,[0],[0]
"= = PZ(z ∈ R : z ≤ z(L)), (10)
where PZ denotes the marginal probability of Z =",4. Theoretical Analysis,[0],[0]
"[X]i, namely the marginal of X w.r.t.",4. Theoretical Analysis,[0],[0]
the component i.,4. Theoretical Analysis,[0],[0]
We denote with FZ the cumulative distribution of Z and define U = F−1Z (Z) and un = F −1,4. Theoretical Analysis,[0],[0]
Z,4. Theoretical Analysis,[0],[0]
"(zn), n = 1, . . .",4. Theoretical Analysis,[0],[0]
",M , where F−1Z (z) = inf{t ∈ R : FZ(t) > z}.",4. Theoretical Analysis,[0],[0]
(11),4. Theoretical Analysis,[0],[0]
"The function F−1Z (·) is monotonically nondecreasing, thus it preserves the order and the L-th sorted value of {un} can be computed as u(L) = F −1 Z (z(L)).",4. Theoretical Analysis,[0],[0]
"Then, (10) becomes
p = PZ(z ∈ R :",4. Theoretical Analysis,[0],[0]
z ≤ z(L)),4. Theoretical Analysis,[0],[0]
= (12) =,4. Theoretical Analysis,[0],[0]
PU (u ∈,4. Theoretical Analysis,[0],[0]
"[0, 1] : u ≤ u(L))",4. Theoretical Analysis,[0],[0]
= FU (u(L)),4. Theoretical Analysis,[0],[0]
"= u(L).
",4. Theoretical Analysis,[0],[0]
"Since U follows a uniform distribution over [0, 1], it follows that p is the L-th order statistic of the uniform distribution, that is a distributed as a Beta(L,M − L + 1) (Balakrishnan & Rao, 1998).
",4. Theoretical Analysis,[0],[0]
"Thus, p1 in (8), namely the probability of S1 under φ0, is distributed as a Beta(L1, N − L1 + 1).",4. Theoretical Analysis,[0],[0]
"To derive the distribution of the remaining pk, k ≥ 2, we define the conditional probability
PS1(x ∈ A)",4. Theoretical Analysis,[0],[0]
= Pφ0(x ∈,4. Theoretical Analysis,[0],[0]
A | x /∈,4. Theoretical Analysis,[0],[0]
"S1), (13) where A is any Borel subset of X .",4. Theoretical Analysis,[0],[0]
"Then, from the definition of conditional probability and the fact that x1, . . .",4. Theoretical Analysis,[0],[0]
",xN are i.i.d.",4. Theoretical Analysis,[0],[0]
"according to φ0, it can be easily proved that the N − L1 points that do not belong to S1 are i.i.d.",4. Theoretical Analysis,[0],[0]
according to PS1 .,4. Theoretical Analysis,[0],[0]
"Therefore, we can apply Proposition 1 to the subset of the N − L1 points that do not fall in S1 by setting D = Rd \ S1 and considering PS1 in place of PX.",4. Theoretical Analysis,[0],[0]
"Thus, the random variable p̃2 = PS1(S2) is distributed as Beta(L2, N2 − L2, 1), where N2 = N −N1.",4. Theoretical Analysis,[0],[0]
"Iterating the above procedure, we obtain that all the random variables p̃k, k = 1, . . .",4. Theoretical Analysis,[0],[0]
",K, defined as2
p̃k = P⋃k−1 j=1 Sj (Sk), (14)
are distributed as Beta(Lk, Nk − Lk + 1), where Nk = N − ∑k−1 j=1 Nj .
",4. Theoretical Analysis,[0],[0]
We remark the different roles of pk and p̃k.,4. Theoretical Analysis,[0],[0]
"While pk in 2We adopt the following conventions: an empty union of sets is the empty set, an empty sum is zero, and an empty product is 1.
(8) the measure of the bin Sk under φ0, p̃k in (14) is the ratio between pk and the measure under φ0 of Xk = Rd \⋃k−1 j Sj , namely the space that remains to be partitioned at step k.",4. Theoretical Analysis,[0],[0]
"As an example, for a tree with K = 3 leaves, if we set target probabilities π1 = π2 = π3 = 1/3, we obtain p̃1 = 1/3, p̃2 = 1/2 and p̃3 = 1.",4. Theoretical Analysis,[0],[0]
"To prove Theorem 1 we need to derive the distribution of pk, that are expressed in terms of p̃k by the following proposition.
",4. Theoretical Analysis,[0],[0]
Proposition 2.,4. Theoretical Analysis,[0],[0]
"In case of histograms defined by QuantTree, the following relation holds between pk and p̃k:
pk = p̃k · (1− k−1∑ j=1 pj) = p̃k k−1∏ j=1 (1− p̃j).",4. Theoretical Analysis,[0],[0]
"(15)
Proof.",4. Theoretical Analysis,[0],[0]
"From the law of total probability we have that
pk = Pφ0(x ∈",4. Theoretical Analysis,[0],[0]
Sk) = = Pφ0 ( x ∈,4. Theoretical Analysis,[0],[0]
Sk | x /∈ ∪k−1j=1Sj ) · Pφ0 ( x /∈ ∪k−1j=1Sj ),4. Theoretical Analysis,[0],[0]
"+
+ Pφ0 ( x ∈",4. Theoretical Analysis,[0],[0]
"Sk | x ∈ ∪k−1j=1Sj ) · Pφ0 ( x ∈ ∪k−1j=1Sj ) .
",4. Theoretical Analysis,[0],[0]
"(16) Since sets {Sk} defined by QuantTree are disjoint, it follows that",4. Theoretical Analysis,[0],[0]
Sk and ⋃k−1 j=1,4. Theoretical Analysis,[0],[0]
"Sj are also disjoint, thus the second term in the sum in (16) is equal to 0.",4. Theoretical Analysis,[0],[0]
The first equality in (15) follows from the definition of p̃k = Pφ0(x ∈,4. Theoretical Analysis,[0],[0]
Sk | x /∈ ⋃k−1,4. Theoretical Analysis,[0],[0]
j=1 Sj) and the fact that Pφ0(x /∈ ⋃k−1,4. Theoretical Analysis,[0],[0]
"j=1 Sj) =
1 − ∑k−1 j=1 pj .",4. Theoretical Analysis,[0],[0]
"The second equality in (15) can be proved by induction over j.
The following proposition allows us to express pj as a product of independent Beta distributions.
",4. Theoretical Analysis,[0],[0]
Proposition 3.,4. Theoretical Analysis,[0],[0]
"The random variables p̃k defined over histograms computed by QuantTree are independent.
",4. Theoretical Analysis,[0],[0]
Proof.,4. Theoretical Analysis,[0],[0]
"To prove the independence of the p̃k, k = 1, . . .",4. Theoretical Analysis,[0],[0]
",K, we show that p̃k is independent from p̃j , j = 1, . . .",4. Theoretical Analysis,[0],[0]
", k",4. Theoretical Analysis,[0],[0]
− 1.,4. Theoretical Analysis,[0],[0]
"In particular, we prove that
Pφ0(p̃k ≤",4. Theoretical Analysis,[0],[0]
"tk | p̃j = tj , j = 1, . . .",4. Theoretical Analysis,[0],[0]
", k−1) = Pφ0(p̃k ≤ tk).",4. Theoretical Analysis,[0],[0]
"(17) To this end, we follow the proof of Proposition 1, and express p̃k as an order statistic of the uniform distribution.
",4. Theoretical Analysis,[0],[0]
"At iteration k, QuantTree randomly selects a dimension ik and performs a split w.r.t.",4. Theoretical Analysis,[0],[0]
the Lk-th order statistic of the ik components over the remaining Nk points (line 9 of Algorithm 1).,4. Theoretical Analysis,[0],[0]
Let L̃k be the position of this splitting point in {zn =,4. Theoretical Analysis,[0],[0]
"[xn]ik , n = 1, . . .",4. Theoretical Analysis,[0],[0]
", N}, namely the sequence of ordered ik components of all the points in TR.",4. Theoretical Analysis,[0],[0]
"The value of L̃k ∈ N depends on realizations x1, . . .",4. Theoretical Analysis,[0],[0]
",xN , and is a random variable ranging in {Lk, . . .",4. Theoretical Analysis,[0],[0]
",Mk}, where Mk = ∑k j=1 Lj .",4. Theoretical Analysis,[0],[0]
"Obviously, at the first iteration L1 = L̃1 but then the two may differ, as shown in Figure 1.",4. Theoretical Analysis,[0],[0]
"Let us now consider the splitting point with respect to L̃k, i.e., z(L̃k).",4. Theoretical Analysis,[0],[0]
"From the definition of p̃k we have that
p̃k = P⋃k−1 j=1 Sj (Sk) = P⋃k−1 j=1",4. Theoretical Analysis,[0],[0]
Sj (z ≤ z(L̃k)).,4. Theoretical Analysis,[0],[0]
"(18)
",4. Theoretical Analysis,[0],[0]
"As in the proof of Proposition 1, we denote with FZ the cdf of Z =",4. Theoretical Analysis,[0],[0]
"[X]ik , and define U = F −1 Z (Z), that has a uniform distribution on [0, 1].",4. Theoretical Analysis,[0],[0]
"Therefore it holds that
p̃k = P⋃k−1 j=1",4. Theoretical Analysis,[0],[0]
Sj (z ≤ z(L̃k)),4. Theoretical Analysis,[0],[0]
= P⋃k−1j=1 Sj (u ≤ u(L̃k)),4. Theoretical Analysis,[0],[0]
= = FU (u(L̃k)),4. Theoretical Analysis,[0],[0]
= u(L̃k).,4. Theoretical Analysis,[0],[0]
"(19)
We use the law of total probability w.r.t.",4. Theoretical Analysis,[0],[0]
"the events {L̃k = a}, a ∈ {Lk, . . .",4. Theoretical Analysis,[0],[0]
",Mk}, to decompose the left hand side in (17) as (for simpler notation we omit the expression j = 1, . . .",4. Theoretical Analysis,[0],[0]
", k",4. Theoretical Analysis,[0],[0]
− 1 in what follows): Pφ0(p̃k ≤ tk,4. Theoretical Analysis,[0],[0]
"| p̃j = tj) = Pφ0(u(L̃k) ≤ tk | p̃j = tj) =
= Mk∑ a=Lk Pφ0(u(L̃k) ≤ tk",4. Theoretical Analysis,[0],[0]
"| L̃k = a, p̃j = tj) ·",4. Theoretical Analysis,[0],[0]
"Pφ0(L̃k = a)
= Mk∑ a=Lk Pφ0(u(a) ≤ tk | p̃j = tj) ·",4. Theoretical Analysis,[0],[0]
Pφ0(L̃k = a).,4. Theoretical Analysis,[0],[0]
"(20)
Since the distribution of u(a) does not depend on p̃j , we have that Pφ0(u(a) ≤ tk",4. Theoretical Analysis,[0],[0]
"| p̃j = tj) = Pφ0(u(a) ≤ tk), therefore it follows
Pφ0(p̃k",4. Theoretical Analysis,[0],[0]
"≤ tk | p̃j = tj) =
= Mk∑ a=Lk Pφ0(u(a) ≤ tk) ·",4. Theoretical Analysis,[0],[0]
"Pφ0(L̃k = a)
= Mk∑ a=Lk Pφ0(u(L̃k) ≤ tk",4. Theoretical Analysis,[0],[0]
| L̃k = a) ·,4. Theoretical Analysis,[0],[0]
"Pφ0(L̃k = a) =
= Pφ0(u(L̃k) ≤ tk) = Pφ0(p̃k ≤ tk), (21) and (17) is proved.
",4. Theoretical Analysis,[0],[0]
"The proof of Theorem 1 follows from Proposition 3.
",4. Theoretical Analysis,[0],[0]
Proof of Theorem 1.,4. Theoretical Analysis,[0],[0]
"For any stationary distribution φ0, the random vector [y1, . . .",4. Theoretical Analysis,[0],[0]
", yK ] conditioned on p1, . . .",4. Theoretical Analysis,[0],[0]
", pK follows a Multinomial distribution with parameters (ν, p1, . . .",4. Theoretical Analysis,[0],[0]
", pK) (White et al., 2009).",4. Theoretical Analysis,[0],[0]
"From Proposition 3 each pk is a product of independent Beta distributions, thus depends only on {Lk} and it is independent from φ0.
",4. Theoretical Analysis,[0],[0]
"Therefore any statistic Th that is a function of {yk} depends only on ν, and onN and {πk}which determines {Lk}.",4. Theoretical Analysis,[0],[0]
We quantitatively assess the advantages of changedetection tests based on QuantTree w.r.t.,5. Experiments,[0],[0]
other generalpurpose tests able to detect any distribution change φ0 → φ1.,5. Experiments,[0],[0]
"In particular, we show that: i) thresholds provided by Algorithm 2 can better control the FPR w.r.t.",5. Experiments,[0],[0]
alternatives based on asymptotic results or bootstrap ii) HT based on histograms provided by QuantTree yielding a uniformdensity partition of Rd achieve higher power than other partitioning schemes.,5. Experiments,[0],[0]
"We employ both synthetic and real-world datasets: Synthetic datasets are generated by choosing, for each dimension d ∈ {2, 8, 32, 64}, 250 pairs (φ0, φ1) of Gaussians, where φ0 has a randomly defined covariance, and φ1 = φ0(Q · +v) is a roto-transalation of φ0 such that the symmetric Kullback-Leibler divergence sKL(φ0, φ1) = 1.",5.1. Datasets and Change Models,[0],[0]
"We control sKL(φ0, φ1) by the CCM framework (Carrera & Boracchi, 2017), which guarantees all the changes to have the same magnitude.",5.1. Datasets and Change Models,[0],[0]
"This is required when comparing detection performance in different dimensions.
",5.1. Datasets and Change Models,[0],[0]
"We also employ four real-world high-dimensional sets: MiniBooNE particle identification (“particle”, d = 50), Physicochemical Properties of Protein Tertiary Structure (“protein”, d = 9), Sensorless Drive Diagnosis (“sensorless”, d = 48) from the UCI Machine Learning Repository (Lichman, 2013), and Credit Card Fraud Detection (“credit”, d = 29) from (Dal Pozzolo et al., 2015).",5.1. Datasets and Change Models,[0],[0]
"We standardize these datasets and add to each component of the “particle” and “sensorless” an imperceivable amount of noise η ∼ N(0, 0.001) to scramble the many repeated values, which harms histogram construction.",5.1. Datasets and Change Models,[0],[0]
For each dataset we simulate 150 changes φ0 → φ1 by randomly selecting TR and defining a random shift drawn from a normal distribution.,5.1. Datasets and Change Models,[0],[0]
"Four of the considered methods rely on the same histogram computed through QuantTree (Algorithm 1) to provide a uniform density partition of Rd, i.e. the target probabilities are πk = 1/K, ∀k.",5.2. Change Detection Methods,[0],[0]
"These methods differ only for the threshold adopted and have been considered mainly to investigate the control over false positives.
",5.2. Change Detection Methods,[0],[0]
"Pearson Distribution Free / TV Distribution Free: thresholds are computed by Algorithm 2 for the Pearson T Ph (6) and the total variation T TVh statistics (7), respectively.",5.2. Change Detection Methods,[0],[0]
"The adopted thresholds are reported in Table 1.
",5.2. Change Detection Methods,[0],[0]
"Pearson Asymptotic: thresholds for T Ph are provided from the classic χ2 goodness-of-fit test (Lehmann & Romano, 2006), which provides an asymptotic control over the FPR.
TV Bootstrap: thresholds for T TVh are computed empirically by bootstrapping TR.
",5.2. Change Detection Methods,[0],[0]
"Three other methods built on different density models have been considered to assess the advantages – also in terms of HT power – of histograms providing uniform density.
",5.2. Change Detection Methods,[0],[0]
"Voronoi: a histogram where the {Sk}k are defined as Voronoi cells around K randomly chosen centers in TR.
",5.2. Change Detection Methods,[0],[0]
"Here we compute T TVh and use thresholds estimated by bootstrapping over TR.
Density Tree: A binary tree aiming at approximating φ0, where splits are defined by a maximum information-gain criterion, in a similar fashion to random density trees like (Criminisi et al., 2011).",5.2. Change Detection Methods,[0],[0]
"We use T TVh with thresholds empirically computed by bootstrap over TR.
Parametric: in the synthetic experiments we consider also an HT based on a parametric density model.",5.2. Change Detection Methods,[0],[0]
"In particular, we fit a Gaussian density on TR, compute the loglikelihood (Song et al., 2007; Kuncheva, 2013) of each incoming batchW , and detect changes by means of the t-test.",5.2. Change Detection Methods,[0],[0]
"Since this method exploits the true density model, it has to be considered as an ideal reference.
",5.2. Change Detection Methods,[0],[0]
All the methods are configured and tested on the same TR and tested on the same batches W .,5.2. Change Detection Methods,[0],[0]
"We perform a PCA transformation, estimated from TR, to all the methods based on trees as density models.",5.2. Change Detection Methods,[0],[0]
"We have in fact experienced that this improves the change-detection performance, since it aligns the coordinate axes – along which splits are performed – with the principal components that become parallel to the bin boundaries.",5.2. Change Detection Methods,[0],[0]
"We consider a small TR configuration, where N = 4096 and ν = 64, and a large TR configuration, where N = 16384 and ν = 256.",5.3. Test Design and Performance Measures,[0],[0]
"Both configurations have been tested with a number of bins K = 32 and K = 128, leading to 4 different combinations (N, ν,K).",5.3. Test Design and Performance Measures,[0],[0]
"In all our experiments, the target FPR has been set to α = 0.05.
",5.3. Test Design and Performance Measures,[0],[0]
"We empirically compute the FPR as the ratio of detections over 100 stationary batches W ∼ φ0, for each considered φ0.",5.3. Test Design and Performance Measures,[0],[0]
"Similarly, for each change φ0 → φ1, we estimate the test power over 100 batches W ∼ φ1.",5.3. Test Design and Performance Measures,[0],[0]
The average FPR and power computed over the whole datasets are reported as dots in Figure 2.,5.3. Test Design and Performance Measures,[0],[0]
To illustrate the distribution of the FPR and power we report their boxplots.,5.3. Test Design and Performance Measures,[0],[0]
Figure 2 shows the FPR and the power of all the methods in the small TR configuration.,5.4. Results and Discussion,[0],[0]
"Figures 2(a-b),(e-f) confirm that QuantTree effectively controls the FPR, for both the Pearson and total variation statistics, which is very important in change-detection.",5.4. Results and Discussion,[0],[0]
The peculiar QuantTree construction and Algorithm 2 provide very accurate thresholds resulting in FPR below the reference value α = 0.05.,5.4. Results and Discussion,[0],[0]
"Moreover, even if histograms defined by QuantTree feature a small number of bins, they are able to effectively monitor high-dimensional datastreams.
",5.4. Results and Discussion,[0],[0]
"The FPRs of the total variation statistic are typically lower
than others: this is due to the discrete nature of the statistics, which affects both testing and quantile estimation.",5.4. Results and Discussion,[0],[0]
"The same problem occurs, but to a lesser extent, in the Pearson statistic, since the expression (6) contains a square that allows this statistic to assume a larger number of distinct values.",5.4. Results and Discussion,[0],[0]
"Clearly, increasing K attenuates this problem, bringing the FPR closer to α.",5.4. Results and Discussion,[0],[0]
"Thresholds used in the traditional Pearson test achieve larger FPR values, as the number of training samples in each bin is too low for the asymptotic approximation to hold: in the large TR configuration, the problem attenuates (plots and tables of average values are reported in the Appendix).",5.4. Results and Discussion,[0],[0]
"Since the likelihood values do not follow a Gaussian distribution, the FPR are not properly controlled in the t-test of the Parametric method either.",5.4. Results and Discussion,[0],[0]
"In all these tests, smaller values of K provide a better control over FPR, since the number of samples in each bin is larger.
",5.4. Results and Discussion,[0],[0]
"Concerning the power, Figures 2(c-d) show a clear decay when d increases: this is consistent with the Detectability loss problem, which has been analytically studied in (Alippi et al., 2016) when monitoring the log-likelihood (as the Parametric).",5.4. Results and Discussion,[0],[0]
"In general, all the methods on Synthetic datasets achieve satisfactory performance, and uniform histograms obtained through the QuantTree appear a better choice than Density Tree and Voronoi.",5.4. Results and Discussion,[0],[0]
There are minor differences among methods based on QuantTree which are nevertheless consistent with the FPR in Figure 2(a-b).,5.4. Results and Discussion,[0],[0]
"Uniform density histograms outperforms others on real world datasets, see Figure 2(g-h), indicating that their partitioning scheme is better at detecting changes.",5.4. Results and Discussion,[0],[0]
"Obviously, increasing N and ν provides superior performance (see the results reported in the supplementary materials).",5.4. Results and Discussion,[0],[0]
"In this paper we have presented QuantTree, an algorithm to build histograms for change detection through a recursive binary splitting of the input space.",6. Conclusions,[0],[0]
Our theoretical analysis allows a characterization of the probability of each bin defined by QuantTree and shows that this probability is independent from the distribution φ0 of stationary data.,6. Conclusions,[0],[0]
This implies that statistics defined over such histograms are non parametric and thresholds can be estimated through numerical simulation on synthetically generated data.,6. Conclusions,[0],[0]
"Experiments show that our thresholds (estimated using samples drawn from a univariate uniform distribution) enable a better control of the FPR than asymptotic ones or those estimated by bootstrap, which is no longer necessary when using such histograms.",6. Conclusions,[0],[0]
"Ongoing work investigates how to mitigate the impact of test statistics assuming a limited number of discrete values, asymptotic results for histograms generated by QuantTree, and extensions to sequential monitoring schemes.",6. Conclusions,[0],[0]
We address the problem of detecting distribution changes in multivariate data streams by means of histograms.,abstractText,[0],[0]
"Histograms are very general and flexible models, which have been relatively ignored in the change-detection literature as they often require a number of bins that grows unfeasibly with the data dimension.",abstractText,[0],[0]
"We present QuantTree, a recursive binary splitting scheme that adaptively defines the histogram bins to ease the detection of any distribution change.",abstractText,[0],[0]
Our design scheme implies that i) we can easily control the overall number of bins and ii) the bin probabilities do not depend on the distribution of stationary data.,abstractText,[0],[0]
"This latter is a very relevant aspect in change detection, since thresholds of tests statistics based on these histograms (e.g., the Pearson statistic or the total variation) can be numerically computed from univariate and synthetically generated data, yet guaranteeing a controlled false positive rate.",abstractText,[0],[0]
"Our experiments show that the proposed histograms are very effective in detecting changes in high dimensional data streams, and that the resulting thresholds can effectively control the false positive rate, even when the number of training samples is relatively small.",abstractText,[0],[0]
QuantTree: Histograms for Change Detection in Multivariate Data Streams,title,[0],[0]
"In many situations in machine learning and statistics, we encounter objective functions which are expectations over continuous distributions.",1. Introduction,[0],[0]
"Among other examples, this situation occurs in reinforcement learning (Sutton and Barto, 1998) and variational inference (Jordan et al., 1999).",1. Introduction,[0],[0]
"If the expectation cannot be computed in closed form, an approximation can often be obtained via Monte Carlo (mc) sampling from the underlying distribution.",1. Introduction,[0],[0]
"As most optimization pro-
*Equal contribution 1ENSAE-CREST, Paris 2TU Kaiserslautern, Germany 3Disney Research, Los Angeles, USA.",1. Introduction,[0],[0]
"Correspondence to: Alexander Buchholz <alexander.buchholz@ensae.fr>, Florian Wenzel <wenzelfl@huberlin.de>, Stephan Mandt <stephan.mandt@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
cedures rely on the gradient of the objective, a mc gradient estimator has to be built by sampling from this distribution.",1. Introduction,[0],[0]
The finite number of mc samples per gradient step introduces noise.,1. Introduction,[0],[0]
"When averaging over multiple samples, the error in approximating the gradient can be decreased, and thus its variance reduced.",1. Introduction,[0],[0]
"This guarantees stability and fast convergence of stochastic gradient descent (sgd).
",1. Introduction,[0],[0]
Certain objective functions require a large number of mc samples per stochastic gradient step.,1. Introduction,[0],[0]
"As a consequence, the algorithm gets slow.",1. Introduction,[0],[0]
It is therefore desirable to obtain the same degree of variance reduction with fewer samples.,1. Introduction,[0],[0]
This paper proposes the idea of using Quasi-Monte Carlo (qmc) samples instead of i.i.d.,1. Introduction,[0],[0]
"samples to achieve this goal.
",1. Introduction,[0],[0]
"A qmc sequence is a deterministic sequence which covers a hypercube [0, 1]d more regularly than random samples.",1. Introduction,[0],[0]
"When using a qmc sequence for Monte Carlo integration, the mean squared error (MSE) decreases asymptotically with the number of samples N as O(N−2(log N)2d−2) (Leobacher and Pillichshammer, 2014).",1. Introduction,[0],[0]
"In contrast, the naive mc integration error decreases as O(N−1).",1. Introduction,[0],[0]
"Since the cost of generating N qmc samples is O(N log N), this implies that a much smaller number of operations per gradient step is required in order to achieve the same precision (provided that N is large enough).",1. Introduction,[0],[0]
"Alternatively, we can achieve a larger variance reduction with the same number of samples, allowing for larger gradient steps and therefore also faster convergence.",1. Introduction,[0],[0]
"This paper investigates the benefits of this approach both experimentally and theoretically.
",1. Introduction,[0],[0]
"Our ideas apply in the context of Monte Carlo variational inference (mcvi), a set of methods which make approximate Bayesian inference scalable and easy to use.",1. Introduction,[0],[0]
Variance reduction is an active area of research in this field.,1. Introduction,[0],[0]
"Our algorithm has the advantage of being very general; it can be easily implemented in existing software packages such as STAN and Edward (Carpenter et al., 2017; Tran et al., 2016).",1. Introduction,[0],[0]
"In Appendix D we show how our approach can be easily implemented in your existing code.
",1. Introduction,[0],[0]
"The main contributions are as follows:
• We investigate the idea of using qmc sequences for Monte Carlo variational inference.",1. Introduction,[0],[0]
"While the usage of qmc for vi has been suggested in the outlook section of Ranganath et al. (2014), to our knowledge, we are the first to actually investigate this approach both
theoretically and experimentally.
",1. Introduction,[0],[0]
"• We show that when using a randomized version of qmc (rqmc), the resulting stochastic gradient is unbiased and its variance is asymptotically reduced.",1. Introduction,[0],[0]
"We also show that when operating sgd with a constant learning rate, the stationary variance of the iterates is reduced by a factor of N, allowing us to get closer to the optimum.
",1. Introduction,[0],[0]
"• We propose an algorithm which operates at a constant learning rate, but increases the number of rqmc samples over iterations.",1. Introduction,[0],[0]
"We prove that this algorithm has a better asymptotic convergence rate than sgd.
•",1. Introduction,[0],[0]
"Based on three different experiments and for two popular types of gradient estimators we illustrate that our method allows us to train complex models several orders of magnitude faster than with standard mcvi.
",1. Introduction,[0],[0]
Our paper is structured as follows.,1. Introduction,[0],[0]
Section 2 reviews related work.,1. Introduction,[0],[0]
Section 3 explains our method and exhibits our theoretical results.,1. Introduction,[0],[0]
In Section 4 we describe our experiments and show comparisons to other existing approaches.,1. Introduction,[0],[0]
"Finally, Section 5 concludes and lays out future research directions.",1. Introduction,[0],[0]
Monte Carlo Variational Inference (MCVI),2. Related Work,[0],[0]
"Since the introduction of the score function (or REINFORCE) gradient estimator for variational inference (Paisley et al., 2012; Ranganath et al., 2014), Monte Carlo variational inference has received an ever-growing attention, see Zhang et al. (2017a) for a recent review.",2. Related Work,[0],[0]
The introduction of the gradient estimator made vi applicable to non-conjugate models but highly depends on the variance of the gradient estimator.,2. Related Work,[0],[0]
"Therefore various variance reduction techniques have been introduced; for example Rao-Blackwellization and control variates, see Ranganath et al. (2014) and importance sampling, see Ruiz et al. (2016a); Burda et al. (2016).
",2. Related Work,[0],[0]
"At the same time the work of Kingma and Welling (2014); Rezende et al. (2014) introduced reparameterization gradients for mcvi, which typically exhibits lower variance but are restricted to models where the variational family can be reparametrized via a differentiable mapping.",2. Related Work,[0],[0]
In this sense mcvi based on score function gradient estimators is more general but training the algorithm is more difficult.,2. Related Work,[0],[0]
A unifying view is provided by Ruiz et al. (2016b).,2. Related Work,[0],[0]
"Miller et al. (2017) introduce a modification of the reparametrized version, but relies itself on assumptions on the underlying variational family.",2. Related Work,[0],[0]
Roeder et al. (2017) propose a lower variance gradient estimator by omitting a term of the elbo.,2. Related Work,[0],[0]
"The idea of using qmc in order to reduce the variance has been suggested by Ranganath et al. (2014) and Ruiz et al. (2016a) and used for a specific model by Tran et al. (2017), but without
a focus on analyzing or benchmarking the method.
",2. Related Work,[0],[0]
"Quasi-Monte Carlo and Stochastic Optimization Besides the generation of random samples for approximating posterior distributions (Robert and Casella, 2013), Monte Carlo methods are used for calculating expectations of intractable integrals via the law of large numbers.",2. Related Work,[0],[0]
The error of the integration with random samples goes to zero at a rate of O(N−1) in terms of the MSE.,2. Related Work,[0],[0]
For practical application this rate can be too slow.,2. Related Work,[0],[0]
"Faster rates of convergence in reasonable dimensions can be obtained by replacing the randomness by a deterministic sequence, also called QuasiMonte Carlo.
",2. Related Work,[0],[0]
"Compared to Monte Carlo and for sufficiently regular functions, qmc reaches a faster rate of convergence of the approximation error of an integral.",2. Related Work,[0],[0]
Niederreiter (1992); L’Ecuyer and Lemieux (2005); Leobacher and Pillichshammer (2014); Dick et al. (2013) provide excellent reviews on this topic.,2. Related Work,[0],[0]
"From a theoretical point of view, the benefits of qmc vanish in very high dimensions.",2. Related Work,[0],[0]
"Nevertheless, the error bounds are often too pessimistic and in practice, gains are observed up to dimension 150, see Glasserman (2013).
",2. Related Work,[0],[0]
"qmc has frequently been used in financial applications (Glasserman, 2013; Joy et al., 1996; Lemieux and L’Ecuyer, 2001).",2. Related Work,[0],[0]
"In statistics, some applications include particle filtering (Gerber and Chopin, 2015), approximate Bayesian computation (Buchholz and Chopin, 2017), control functionals (Oates and Girolami, 2016) and Bayesian optimal design (Drovandi and Tran, 2018).",2. Related Work,[0],[0]
"Yang et al. (2014) used qmc in the context of large scale kernel methods.
",2. Related Work,[0],[0]
Stochastic optimization has been pioneered by the work of Robbins and Monro (1951).,2. Related Work,[0],[0]
"As stochastic gradient descent suffers from noisy gradients, various approaches for reducing the variance and adapting the step size have been introduced (Johnson and Zhang, 2013; Kingma and Ba, 2015; Defazio et al., 2014; Duchi et al., 2011; Zhang et al., 2017b).",2. Related Work,[0],[0]
Extensive theoretical results on the convergence of stochastic gradients algorithms are provided by Moulines and Bach (2011).,2. Related Work,[0],[0]
Mandt et al. (2017) interpreted stochastic gradient descent with constant learning rates as approximate Bayesian inference.,2. Related Work,[0],[0]
Some recent reviews are for example Bottou et al. (2016); Nesterov (2013).,2. Related Work,[0],[0]
"Naturally, concepts from qmc can be beneficial to stochastic optimization.",2. Related Work,[0],[0]
Contributions on exploiting this idea are e.g. Gerber and Bornn (2017) and Drew and Homem-de Mello (2006).,2. Related Work,[0],[0]
"In this Section, we introduce Quasi-Monte Carlo Variational Inference (qmcvi), using randomized qmc (rqmc) for variational inference.",3. Quasi-Monte Carlo Variational Inference,[0],[0]
We review mcvi in Section 3.1.,3. Quasi-Monte Carlo Variational Inference,[0],[0]
"rqmc
and the details of our algorithm are exposed in Section 3.2.",3. Quasi-Monte Carlo Variational Inference,[0],[0]
Theoretical results are given in Section 3.3.,3. Quasi-Monte Carlo Variational Inference,[0],[0]
"Variational inference (vi) is key to modern probabilistic modeling and Bayesian deep learning (Jordan et al., 1999; Blei et al., 2017; Zhang et al., 2017a).",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"In Bayesian inference, the object of interest is a posterior distribution of latent variables z given observations x. vi approximates Bayesian inference by an optimization problem which we can solve by (stochastic) gradient ascent (Jordan et al., 1999; Hoffman et al., 2013).
",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"In more detail, vi builds a tractable approximation of the posterior p(z|x) by minimizing the KL-divergence between a variational family q(z|λ), parametrized by free parameters λ ∈ Rd, and p(z|x).",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"This is equivalent to maximizing the so-called evidence lower bound (elbo):
L(λ) = Eq(z|λ)[log p(x, z)",3.1. Background: Monte Carlo Variational Inference,[0],[0]
− log q(z|λ)].,3.1. Background: Monte Carlo Variational Inference,[0],[0]
"(1)
In classical variational inference, the expectations involved in (1) are carried out analytically (Jordan et al., 1999).",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"However, this is only possible for the fairly restricted class of so-called conditionally conjugate exponential family models (Hoffman et al., 2013).",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"More recently, black-box variational methods have gained momentum, which make the analytical evaluation of these expectation redundant, and which shall be considered in this paper.
",3.1. Background: Monte Carlo Variational Inference,[0],[0]
Maximizing the objective (1) is often based on a gradient ascent scheme.,3.1. Background: Monte Carlo Variational Inference,[0],[0]
"However, a direct differentiation of the objective (1) with respect to λ is not possible, as the measure of the expectation depends on this parameter.",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"The two major approaches for overcoming this issue are the score function estimator and the reparameterization estimator.
",3.1. Background: Monte Carlo Variational Inference,[0],[0]
Score Function Gradient,3.1. Background: Monte Carlo Variational Inference,[0],[0]
"The score function gradient (also called REINFORCE gradient) (Ranganath et al., 2014) expresses the gradient as expectation with respect to q(z|λ) and is given by
∇λL(λ) =",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"Eq(z|λ)[∇λ log q(z|λ) ( log p(x, z) − log q(z|λ))",3.1. Background: Monte Carlo Variational Inference,[0],[0]
].,3.1. Background: Monte Carlo Variational Inference,[0],[0]
"(2)
The gradient estimator is obtained by approximating the expectation with independent samples from the variational distribution q(z|λ).",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"This estimator applies to continuous and discrete variational distributions.
",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"Reparameterization Gradient The second approach is based on the reparametrization trick (Kingma and Welling, 2014), where the distribution over z is expressed as a deterministic transformation of another distribution over a noise
variable ε, hence z = gλ(ε) where ε ∼ p(ε).",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"Using the reparameterization trick, the elbo is expressed as expectation with respect to p(ε) and the derivative is moved inside the expectation:
∇λL(λ) = Ep(ε)[∇λ log p(x, gλ(ε))",3.1. Background: Monte Carlo Variational Inference,[0],[0]
− ∇λ log q(gλ(ε)|λ)].,3.1. Background: Monte Carlo Variational Inference,[0],[0]
"(3)
The expectation is approximated using a mc sum of independent samples from p(ε).",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"In its basic form, the estimator is restricted to distributions over continuous variables.
",3.1. Background: Monte Carlo Variational Inference,[0],[0]
MCVI,3.1. Background: Monte Carlo Variational Inference,[0],[0]
"In the general setup of mcvi considered here, the gradient of the elbo is represented as an expectation ∇λL(λ) = E[gz̃(λ)] over a random variable z̃.",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"For the score function estimator we choose g according to Equation (2) with z̃ = z and for the reparameterization gradient according to Equation (3) with z̃ = ε, respectively.",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"This allows us to obtain a stochastic estimator of the gradient by an average over a finite sample {z̃1, · · · , z̃N} as ĝN(λt) = (1/N) ∑N i=1",3.1. Background: Monte Carlo Variational Inference,[0],[0]
gz̃i,3.1. Background: Monte Carlo Variational Inference,[0],[0]
"(λt).This way, the elbo can be optimized by stochastic optimization.",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"This is achieved by iterating the sgd updates with decreasing step sizes αt:
λt+1 = λt + αtĝN(λt).",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"(4)
The convergence of the gradient ascent scheme in (4) tends to be slow when gradient estimators have a high variance.",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"Therefore, various approaches for reducing the variance of both gradient estimators exist; e.g. control variates (cv), Rao-Blackwellization and importance sampling.",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"However these variance reduction techniques do not improve the O(N−1) rate of the MSE of the estimator, except under some restrictive conditions (Oates et al., 2017).",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"Moreover, the variance reduction schemes must often be tailored to the problem at hand.",3.1. Background: Monte Carlo Variational Inference,[0],[0]
"Quasi Monte Carlo Low discrepancy sequences, also called qmc sequences, are used for integrating a function ψ over the [0, 1]d hypercube.",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
When using standard i.i.d.,3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"samples on [0, 1]d, the error of the approximation is O(N−1).",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"qmc achieves a rate of convergence in terms of the MSE of O ( N−2(log N)2d−2 ) if ψ is sufficiently regular (Leobacher and Pillichshammer, 2014).",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"This is achieved by a deterministic sequence that covers [0, 1]d more evenly.
",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"On a high level, qmc sequences are constructed such that the number of points that fall in a rectangular volume is proportional to the volume.",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
This idea is closely linked to stratification.,3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"Halton sequences e.g. are constructed using coprime numbers (Halton, 1964).",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"Sobol sequences are based on the reflected binary code (Antonov and Saleev, 1979).",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"The exact construction of qmc sequences is quite involved and we refer to Niederreiter (1992); Leobacher
and Pillichshammer (2014); Dick et al. (2013) for more details.
",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"The approximation error of qmc increases with the dimension, and it is difficult to quantify.",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
Carefully reintroducing randomness while preserving the structure of the sequence leads to randomized qmc.,3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
rqmc sequences are unbiased and the error can be assessed by repeated simulation.,3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"Moreover, under slightly stronger regularity conditions on F we can achieve rates of convergence of O(N−2)",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"(Gerber, 2015).",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"For illustration purposes, we show different sequences in Figure 1.",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"In Appendix A we provide more technical details.
qmc or rqmc can be used for integration with respect to arbitrary distributions by transforming the initial sequence on [0, 1]d via a transformation Γ to the distribution of interest.",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"Constructing the sequence typically costs O(N log N) (Gerber and Chopin, 2015).
QMC and VI We suggest to replace N independent mc samples for computing ĝN(λt) by an rqmc sequence of the same length.",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"With our approach, the variance of the gradient estimators becomes O(N−2), and the costs for creating the sequence is O(N log N).",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"The incorporation of rqmc in vi is straightforward: instead of sampling z̃ as independent mc samples, we generate a uniform rqmc sequence u1, · · · , uN and transform this sequence via a mapping Γ to the original random variable z̃ = Γ(u).",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"Using this transformation we obtain the rqmc gradient estimator
ĝN(λt) =",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"(1/N) N∑
i=1
gΓ(ui)(λ).",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"(5)
From a theoretical perspective, the function u 7→ gΓ(u)(λ) has to be sufficiently smooth for all λ.",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
For commonly used variational families this transformation is readily available.,3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"Although evaluating these transforms adds computational overhead, we found this cost negligible in practice.",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"For example, in order to sample from a multivariate Gaussian zn ∼ N(µ,Σ), we generate an rqmc squence un and apply the transformation zn = Φ−1(un)Σ1/2",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"+ µ, where Σ1/2 is the Cholesky decomposition of Σ and Φ−1 is the componentwise inverse cdf of a standard normal distribution.",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"Similar
procedures are easily obtained for exponential, Gamma, and other distributions that belong to the exponential family.",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"Algorithm 1 summarizes the procedure.
",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"Algorithm 1: Quasi-Monte Carlo Variational Inference Input: Data x, model p(x, z), variational family q(z|λ)",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"Result: Variational parameters λ∗
1 while not converged do 2 Generate uniform rqmc sequence u1:N 3 Transform the sequence via Γ 4 Estimate the gradient ĝN(λt)",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
= 1N ∑N i=1,3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
gΓ(ui)(λt) 5,3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"Update λt+1 = λt + αt ĝN(λt)
rqmc samples can be generated via standard packages such as randtoolbox (Christophe and Petr, 2015), available in R. Existing mcvi algorithms are adapted by replacing the random variable sampler by an rqmc version.",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
Our approach reduces the variance in mcvi and applies in particular to the reparametrization gradient estimator and the score function estimator.,3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
"rqmc can in principle be combined with additional variance reduction techniques such as cv, but care must be taken as the optimal cv for rqmc are not the same as for mc (Hickernell et al., 2005).",3.2. Quasi-Monte Carlo Variational Inference,[0],[0]
In what follows we give a theoretical analysis of using rqmc in stochastic optimization.,3.3. Theoretical Properties of QMCVI,[0],[0]
"Our results apply in particular to vi but are more general.
",3.3. Theoretical Properties of QMCVI,[0],[0]
"qmcvi leads to faster convergence in combination with Adam (Kingma and Ba, 2015) or Adagrad (Duchi et al., 2011), as we will show empirically in Section 4.",3.3. Theoretical Properties of QMCVI,[0],[0]
"Our analysis, presented in this section, underlines this statement for the simple case of sgd with fixed step size in the Lipschitz continuous (Theorem 1) and strongly convex case (Theorem 2).",3.3. Theoretical Properties of QMCVI,[0],[0]
"We show that for N sufficiently large, sgd with rqmc samples reaches regions closer to the true optimizer of the elbo.",3.3. Theoretical Properties of QMCVI,[0],[0]
"Moreover, we obtain a faster convergence rate than sgd when using a fixed step size and increasing the sample size over iterations (Theorem 3).
",3.3. Theoretical Properties of QMCVI,[0],[0]
RQMC for Optimizing Monte Carlo Objectives We step back from black box variational inference and consider the more general setup of optimizing Monte Carlo objectives.,3.3. Theoretical Properties of QMCVI,[0],[0]
"Our goal is to minimize a function F(λ), where the optimizer has only access to a noisy, unbiased version F̂N(λ), with E[F̂N(λ)]",3.3. Theoretical Properties of QMCVI,[0],[0]
"= F(λ) and access to an unbiased noisy estimator of the gradients ĝN(λ), with E[ĝN(λ)]",3.3. Theoretical Properties of QMCVI,[0],[0]
= ∇F(λ).,3.3. Theoretical Properties of QMCVI,[0],[0]
"The optimum of F(λ) is λ?.
",3.3. Theoretical Properties of QMCVI,[0],[0]
"We furthermore assume that the gradient estimator ĝN(λ) has the form as in Eq. 5, where Γ is a reparameterization function that converts uniform samples from the hypercube
into samples from the target distribution.",3.3. Theoretical Properties of QMCVI,[0],[0]
"In this paper, u1, · · · ,uN is an rqmc sequence.",3.3. Theoretical Properties of QMCVI,[0],[0]
"In the following theoretical analysis, we focus on sgd with a constant learning rate α.",3.3. Theoretical Properties of QMCVI,[0],[0]
"The optimal value λ? is approximated by sgd using the update rule
λt+1 =",3.3. Theoretical Properties of QMCVI,[0],[0]
λt − αĝN(λt).,3.3. Theoretical Properties of QMCVI,[0],[0]
"(6)
Starting from λ1 the procedure is iterated until |F̂N(λt)",3.3. Theoretical Properties of QMCVI,[0],[0]
"− F̂N(λt+1)| ≤ , for a small threshold .",3.3. Theoretical Properties of QMCVI,[0],[0]
The quality of the approximation λT,3.3. Theoretical Properties of QMCVI,[0],[0]
"≈ λ? crucially depends on the variance of the estimator ĝN (Johnson and Zhang, 2013).
",3.3. Theoretical Properties of QMCVI,[0],[0]
"Intuitively, the variance of ĝN(λ) based on an rqmc sequence will be O(N−2) and thus for N large enough, the variance will be smaller than for the mc counterpart, that is O(N−1).",3.3. Theoretical Properties of QMCVI,[0],[0]
This will be beneficial to the optimization procedure defined in (6).,3.3. Theoretical Properties of QMCVI,[0],[0]
"Our following theoretical results are based on standard proof techniques for stochastic approximation, see e.g. Bottou et al. (2016).
",3.3. Theoretical Properties of QMCVI,[0],[0]
Stochastic Gradient Descent with Fixed Step Size,3.3. Theoretical Properties of QMCVI,[0],[0]
"In the case of functions with Lipschitz continuous derivatives, we obtain the following upper bound on the norm of the gradients.
",3.3. Theoretical Properties of QMCVI,[0],[0]
"Theorem 1 Let F be a function with Lipschitz continuous derivatives, i.e. there exists L > 0",3.3. Theoretical Properties of QMCVI,[0],[0]
"s.t. ∀λ, λ ‖∇F(λ)",3.3. Theoretical Properties of QMCVI,[0],[0]
"− ∇F(λ)‖22 ≤ L‖λ − λ‖22, let UN = {u1, · · · ,uN} be an rqmc sequence and let ∀λ, G : u 7→ gΓ(u)(λ) has cross partial derivatives of up to order d. Let the constant learning rate α < 2/L and let µ = 1 − αL/2.",3.3. Theoretical Properties of QMCVI,[0],[0]
"Then ∀λ, tr VarUN [ĝN(λ)]",3.3. Theoretical Properties of QMCVI,[0],[0]
"≤ MV × r(N), where MV < ∞ and r(N) = O ( N−2 ) and
∑T t=1",3.3. Theoretical Properties of QMCVI,[0],[0]
"E‖∇F(λt)‖22
T
≤ 1 2µ αLMVr(N) + F(λ1)",3.3. Theoretical Properties of QMCVI,[0],[0]
"− F(λ?) αµT ,
where λt is iteratively defined in (6).",3.3. Theoretical Properties of QMCVI,[0],[0]
"Consequently,
lim T→∞
∑T t=1",3.3. Theoretical Properties of QMCVI,[0],[0]
"E‖∇F(λt)‖22
T ≤ 1 2µ αLMVr(N).",3.3. Theoretical Properties of QMCVI,[0],[0]
"(7)
Equation (7) underlines the dependence of the sum of the norm of the gradients on the variance of the gradients.",3.3. Theoretical Properties of QMCVI,[0],[0]
"The better the gradients are estimated, the closer one gets to the optimum where the gradient vanishes.",3.3. Theoretical Properties of QMCVI,[0],[0]
"As the dependence on the sample size becomes O ( N−2 ) for an rqmc sequence instead of 1/N for a mc sequence, the gradient is more precisely estimated for N large enough.
",3.3. Theoretical Properties of QMCVI,[0],[0]
We now study the impact of a reduced variance on sgd with a fixed step size and strongly convex functions.,3.3. Theoretical Properties of QMCVI,[0],[0]
"We obtain an improved upper bound on the optimality gap.
",3.3. Theoretical Properties of QMCVI,[0],[0]
Theorem 2,3.3. Theoretical Properties of QMCVI,[0],[0]
"Let F have Lipschitz continuous derivatives and be a strongly convex function, i.e. there exists a constant c > 0 s.t. ∀λ, λ F(λ) ≥ F(λ)",3.3. Theoretical Properties of QMCVI,[0],[0]
+ ∇F(λ)T (λ − λ) + 12 c‖λ,3.3. Theoretical Properties of QMCVI,[0],[0]
"− λ‖22, let UN = {u1, · · · , uN} be an rqmc sequence and let ∀λ,G : u 7→ gΓ(u)(λ) be as in Theorem 1.",3.3. Theoretical Properties of QMCVI,[0],[0]
Let the constant learning rate α < 12c and α < 2 L .,3.3. Theoretical Properties of QMCVI,[0],[0]
"Then the expected optimality gap satisfies, ∀t ≥ 0,
E[F(λt+1)",3.3. Theoretical Properties of QMCVI,[0],[0]
− F(λ?)],3.3. Theoretical Properties of QMCVI,[0],[0]
≤,3.3. Theoretical Properties of QMCVI,[0],[0]
"[( α2L
2 − α
) 2c + 1 ] × E[FN(λt)",3.3. Theoretical Properties of QMCVI,[0],[0]
"− F(λ?)]
+ 1 2 Lα2 [MVr(N)] .
Consequently,
lim T→∞
E[F(λT )",3.3. Theoretical Properties of QMCVI,[0],[0]
− F(λ?)],3.3. Theoretical Properties of QMCVI,[0],[0]
"≤ αL
4c − αLc",3.3. Theoretical Properties of QMCVI,[0],[0]
"[MVr(N)] .
",3.3. Theoretical Properties of QMCVI,[0],[0]
The previous result has the following interpretation.,3.3. Theoretical Properties of QMCVI,[0],[0]
The expected optimality gap between the last iteration λT and the true minimizer λ? is upper bounded by the magnitude of the variance.,3.3. Theoretical Properties of QMCVI,[0],[0]
"The smaller this variance, the closer we get to λ?.",3.3. Theoretical Properties of QMCVI,[0],[0]
"Using rqmc we gain a factor 1/N in the bound.
",3.3. Theoretical Properties of QMCVI,[0],[0]
"Increasing Sample Size Over Iterations While sgd with a fixed step size and a fixed number of samples per gradient step does not converge, convergence can be achieved when increasing the number of samples used for estimating the gradient over iterations.",3.3. Theoretical Properties of QMCVI,[0],[0]
"As an extension of Theorem 2, we show that a linear convergence is obtained while increasing the sample size at a slower rate than for mc sampling.
",3.3. Theoretical Properties of QMCVI,[0],[0]
"Theorem 3 Assume the conditions of Theorem 2 with the modification α ≤ min{1/c, 1/L}.",3.3. Theoretical Properties of QMCVI,[0],[0]
"Let 1−αc/2 < ξ2 = 1
τ2 < 1.
",3.3. Theoretical Properties of QMCVI,[0],[0]
"Use an increasing sample size Nt = N + dτte, where N < ∞ is defined in Appendix B.3.",3.3. Theoretical Properties of QMCVI,[0],[0]
"Then ∀t ∈ N,∃M̂V < ∞,
tr VarUN [ĝNt (λ)]",3.3. Theoretical Properties of QMCVI,[0],[0]
≤,3.3. Theoretical Properties of QMCVI,[0],[0]
"M̂V × 1 τ2t
and E[F(λt+1)",3.3. Theoretical Properties of QMCVI,[0],[0]
− F(λ?)],3.3. Theoretical Properties of QMCVI,[0],[0]
"≤ ωξ2t,
where ω = max{αLM̂V/c, F(λ1)",3.3. Theoretical Properties of QMCVI,[0],[0]
"− F(λ?)}.
",3.3. Theoretical Properties of QMCVI,[0],[0]
"This result compares favorably with a standard result on the linear convergence of sgd with fixed step size and strongly convex functions (Bottou et al., 2016).",3.3. Theoretical Properties of QMCVI,[0],[0]
For mc sampling one obtains a different constant ω̃ and an upper bound with ξt and not ξ2t.,3.3. Theoretical Properties of QMCVI,[0],[0]
"Thus, besides the constant factor, rqmc samples allow us to close the optimality gap faster for the same geometric increase in the sample size τt or to use τt/2 to obtain the same linear rate of convergence as mc based estimators.
",3.3. Theoretical Properties of QMCVI,[0],[0]
Other Remarks The reduced variance in the estimation of the gradients should allow us to make larger moves in the parameter space.,3.3. Theoretical Properties of QMCVI,[0],[0]
"This is for example achieved by using adaptive step size algorithms as Adam (Kingma and Ba, 2015), or Adagrad (Duchi et al., 2011).",3.3. Theoretical Properties of QMCVI,[0],[0]
"However, the theoretical analysis of these algorithms is beyond the scope of this paper.
",3.3. Theoretical Properties of QMCVI,[0],[0]
"Also, note that it is possible to relax the smoothness assumptions on G while supposing only square integrability.",3.3. Theoretical Properties of QMCVI,[0],[0]
Then one obtains rates in o(N−1).,3.3. Theoretical Properties of QMCVI,[0],[0]
"Thus, rqmc yields always a faster rate than mc, regardless of the smoothness.",3.3. Theoretical Properties of QMCVI,[0],[0]
"See Appendix A for more details.
",3.3. Theoretical Properties of QMCVI,[0],[0]
"In the previous analysis, we have assumed that the entire randomness in the gradient estimator comes from the sampling of the variational distribution.",3.3. Theoretical Properties of QMCVI,[0],[0]
"In practice, additional randomness is introduced in the gradient via mini batch sampling.",3.3. Theoretical Properties of QMCVI,[0],[0]
"This leads to a dominating term in the variance of O(K−1) for mini batches of size K. Still, the part of the variance related to the variational family itself is reduced and so is the variance of the gradient estimator as a whole.",3.3. Theoretical Properties of QMCVI,[0],[0]
"We study the effectiveness of our method in three different settings: a hierarchical linear regression, a multi-level Poisson generalized linear model (GLM) and a Bayesian neural network (BNN).",4. Experiments,[0],[0]
"Finally, we confirm the result of Theorem 3, which proposes to increase the sample size over iterations in qmcvi for faster asymptotic convergence.
",4. Experiments,[0],[0]
"Setup In the first three experiments we optimize the elbo using the Adam optimizer (Kingma and Ba, 2015) with the initial step size set to 0.1, unless otherwise stated.",4. Experiments,[0],[0]
"The rqmc sequences are generated through a python interface to the R package randtoolbox (Christophe and Petr, 2015).",4. Experiments,[0],[0]
In particular we use scrambled Sobol sequences.,4. Experiments,[0],[0]
The gradients are calculated using an automatic differentiation toolbox.,4. Experiments,[0],[0]
"The elbo values are computed by using 10, 000 mc samples, the variance of the gradient estimators is estimated by resampling the gradient 1000 times in each optimization step and computing the empirical variance.
",4. Experiments,[0],[0]
Benchmarks The first benchmark is the vanilla mcvi algorithm based on ordinary mc sampling.,4. Experiments,[0],[0]
"Our method qmcvi replaces the mc samples by rqmc sequences and comes at almost no computational overhead (Section 3).
",4. Experiments,[0],[0]
"Our second benchmark in the second and third experiment is the control variate (cv) approach of Miller et al. (2017), where we use the code provided with the publication.",4. Experiments,[0],[0]
"In the first experiment, this comparison is omitted since the method of Miller et al. (2017) does not apply in this setting due to the non-Gaussian variational distribution.
",4. Experiments,[0],[0]
Main Results We find that our approach generally leads to a faster convergence compared to our baselines due to a decreased gradient variance.,4. Experiments,[0],[0]
"For the multi-level Poisson GLM experiment, we also find that our rqmc algorithm converges to a better local optimum of the elbo.",4. Experiments,[0],[0]
"As proposed in Theorem 3, we find that increasing the sample size over iteration in qmcvi leads to a better asymptotic convergence rate than in mcvi.",4. Experiments,[0],[0]
We begin the experiments with a toy model of hierarchical linear regression with simulated data.,4.1. Hierarchical Linear Regression,[0],[0]
The sampling process for the outputs yi is yi ∼,4.1. Hierarchical Linear Regression,[0],[0]
N(x,4.1. Hierarchical Linear Regression,[0],[0]
">i bi, ), bi ∼ N(µβ, σβ).",4.1. Hierarchical Linear Regression,[0],[0]
We place lognormal hyper priors on the variance of the intercepts σβ and on the noise ; and a Gaussian hyper prior on µβ.,4.1. Hierarchical Linear Regression,[0],[0]
Details on the model are provided in Appendix C.1.,4.1. Hierarchical Linear Regression,[0],[0]
We set the dimension of the data points to be 10 and simulated 100 data points from the model.,4.1. Hierarchical Linear Regression,[0],[0]
"This results in a 1012-
1Using only 10 samples for the mc based score function estimator leads to divergence and the elbo values are out of the scope of the plot.
dimensional posterior, which we approximate by a variational distribution that mirrors the prior distributions.
",4.1. Hierarchical Linear Regression,[0],[0]
"We optimize the elbo using Adam (Kingma and Ba, 2015) based on the score function as well as the reparameterization gradient estimator.",4.1. Hierarchical Linear Regression,[0],[0]
"We compare the standard mc based approach using 10 and 100 samples with our rqmc based approach using 10 samples, respectively.",4.1. Hierarchical Linear Regression,[0],[0]
The cv based estimator cannot be used in this setting since it only supports Gaussian variational distributions and the variational family includes a lognormal distribution.,4.1. Hierarchical Linear Regression,[0],[0]
"For the score function estimator, we set the initial step size of Adam to 0.01.
",4.1. Hierarchical Linear Regression,[0],[0]
The results are shown in Figure 2.,4.1. Hierarchical Linear Regression,[0],[0]
We find that using rqmc samples decreases the variance of the gradient estimator substantially.,4.1. Hierarchical Linear Regression,[0],[0]
This applies both to the score function and the reparameterization gradient estimator.,4.1. Hierarchical Linear Regression,[0],[0]
Our approach substantially improves the standard score function estimator in terms of convergence speed and leads to a decreased gradient variance of up to three orders of magnitude.,4.1. Hierarchical Linear Regression,[0],[0]
"Our approach is also beneficial in the case of the reparameterization gradient estimator, as it allows for reducing the sample size from 100 mc samples to 10 rqmc samples, yielding a similar gradient variance and optimization speed.",4.1. Hierarchical Linear Regression,[0],[0]
"We use a multi-level Poisson generalized linear model (GLM), as introduced in (Gelman and Hill, 2006) as an example of multi-level modeling.",4.2. Multi-level Poisson GLM,[0],[0]
"This model has a 37-dim posterior, resulting from its hierarchical structure.
",4.2. Multi-level Poisson GLM,[0],[0]
"As in (Miller et al., 2017), we apply this model to the frisk data set (Gelman et al., 2006) that contains information on the number of stop-and-frisk events within different ethnicity groups.",4.2. Multi-level Poisson GLM,[0],[0]
The generative process of the model is described in Appendix C.2.,4.2. Multi-level Poisson GLM,[0],[0]
"We approximate the posterior by a diagonal Gaussian variational distribution.
",4.2. Multi-level Poisson GLM,[0],[0]
The results are shown in Figure 3.,4.2. Multi-level Poisson GLM,[0],[0]
"When using a small number of samples (N = 10), all three methods have comparable convergence speed and attain a similar optimum.",4.2. Multi-level Poisson GLM,[0],[0]
"In this setting, the cv based method has lowest gradient variance.",4.2. Multi-level Poisson GLM,[0],[0]
"When increasing the sample size to 50, our proposed rqmc approach leads to substantially decreased gradient variance and allows Adam to convergence closer to the optimum than the baselines.",4.2. Multi-level Poisson GLM,[0],[0]
This agrees with the fact that rqmc improves over mc for sufficiently large sample sizes.,4.2. Multi-level Poisson GLM,[0],[0]
"As a third example, we study qmcvi and its baselines in the context of a Bayesian neural network.",4.3. Bayesian Neural Network,[0],[0]
The network consists of a 50-unit hidden layer with ReLU activations.,4.3. Bayesian Neural Network,[0],[0]
"We place a normal prior over each weight, and each weight prior has an inverse Gamma hyper prior.",4.3. Bayesian Neural Network,[0],[0]
We also place an inverse Gamma prior over the observation variance.,4.3. Bayesian Neural Network,[0],[0]
The model exhibits a posterior of dimension d = 653 and is applied to a 100-row subsample of the wine dataset from the UCI repository2.,4.3. Bayesian Neural Network,[0],[0]
The generative process is described in Appendix C.3.,4.3. Bayesian Neural Network,[0],[0]
"We approximate the posterior by a variational diagonal Gaussian.
",4.3. Bayesian Neural Network,[0],[0]
The results are shown in Figure 4.,4.3. Bayesian Neural Network,[0],[0]
"For N = 10, both the rqmc and the cv version converge to a comparable value of the elbo, whereas the ordinary mc approach converges to a lower value.",4.3. Bayesian Neural Network,[0],[0]
"For N = 50, all three algorithms reach approximately the same value of the elbo, but our rqmc method converges much faster.",4.3. Bayesian Neural Network,[0],[0]
"In both settings, the variance of the rqmc gradient estimator is one to three orders of magnitude lower than the variance of the baselines.",4.3. Bayesian Neural Network,[0],[0]
"Along with our new Monte Carlo variational inference approach qmcvi, Theorem 3 gives rise to a new stochastic optimization algorithm for Monte Carlo objectives.",4.4. Increasing the Sample Size Over Iterations,[0],[0]
"Here, we investigate this algorithm empirically, using a constant learning rate and an (exponentially) increasing sample size schedule.",4.4. Increasing the Sample Size Over Iterations,[0],[0]
"We show that, for strongly convex objective functions and some mild regularity assumptions, our rqmc based gradient estimator leads to a faster asymptotic convergence rate than using the ordinary mc based gradient estimator.
",4.4. Increasing the Sample Size Over Iterations,[0],[0]
"In our experiment, we consider a two-dimensional factorizing normal target distribution with zero mean and standard deviation one.",4.4. Increasing the Sample Size Over Iterations,[0],[0]
"Our variational distribution is also a normal distribution with fixed standard deviation of 1, and with a variational mean parameter, i.e., we only optimize the mean parameter.",4.4. Increasing the Sample Size Over Iterations,[0],[0]
"In this simple setting, the elbo is strongly convex and the variational family includes the target distribution.",4.4. Increasing the Sample Size Over Iterations,[0],[0]
"We optimize the elbo with an increasing sample size, using the sgd algorithm described in Theorem 3.",4.4. Increasing the Sample Size Over Iterations,[0],[0]
"We initialize the variational parameter to (0.1, 0.1).",4.4. Increasing the Sample Size Over Iterations,[0],[0]
"Results are shown in Figure 5.
",4.4. Increasing the Sample Size Over Iterations,[0],[0]
We considered both rqmc (red) and mc (blue) based gradient estimators.,4.4. Increasing the Sample Size Over Iterations,[0],[0]
We plot the difference between the optimal elbo value and the optimization trace in logarithmic scale.,4.4. Increasing the Sample Size Over Iterations,[0],[0]
The experiment confirms the theoretical result of Theorem 3 as our rqmc based method attains a faster asymptotic convergence rate than the ordinary mc based approach.,4.4. Increasing the Sample Size Over Iterations,[0],[0]
"This means that, in the absence of additional noise due to data
2https://archive.ics.uci.edu/ml/datasets/Wine+ Quality
subsampling, optimizing Monte Carlo objectives with rqmc can drastically outperform sgd.",4.4. Increasing the Sample Size Over Iterations,[0],[0]
We investigated randomized Quasi-Monte Carlo (rqmc) for stochastic optimization of Monte Carlo objectives.,5. Conclusion,[0],[0]
"We termed our method Quasi-Monte Carlo Variational Inference (qmcvi), currently focusing on variational inference applications.",5. Conclusion,[0],[0]
"Using our method, we showed that we can achieve faster convergence due to variance reduction.
qmcvi has strong theoretical guarantees and provably gets us closer to the optimum of the stochastic objective.",5. Conclusion,[0],[0]
"Furthermore, in absence of additional sources of noise such as data subsampling noise, qmcvi converges at a faster rate than sgd when increasing the sample size over iterations.
qmcvi can be easily integrated into automated inference packages.",5. Conclusion,[0],[0]
"All one needs to do is replace a sequence of uniform random numbers over the hypercube by an rqmc sequence, and perform the necessary reparameterizations to sample from the target distributions.
",5. Conclusion,[0],[0]
"An open question remains as to which degree qmcvi can be combined with control variates, as rqmc may introduce additional unwanted correlations between the gradient and the cv.",5. Conclusion,[0],[0]
We will leave this aspect for future studies.,5. Conclusion,[0],[0]
"We see particular potential for qmcvi in the context of reinforcement learning, which we consider to investigate.",5. Conclusion,[0],[0]
"We would like to thank Pierre E. Jacob, Nicolas Chopin, Rajesh Ranganath, Jaan Altosaar and Marius Kloft for their valuable feedback on our manuscript.",Acknowledgements,[0],[0]
This work was partly funded by the German Research Foundation (DFG) award KL 2698/2-1 and a GENES doctoral research scholarship.,Acknowledgements,[0],[0]
Many machine learning problems involve Monte Carlo gradient estimators.,abstractText,[0],[0]
"As a prominent example, we focus on Monte Carlo variational inference (mcvi) in this paper.",abstractText,[0],[0]
The performance of mcvi crucially depends on the variance of its stochastic gradients.,abstractText,[0],[0]
We propose variance reduction by means of Quasi-Monte Carlo (qmc) sampling.,abstractText,[0],[0]
qmc replaces N i.i.d.,abstractText,[0],[0]
samples from a uniform probability distribution by a deterministic sequence of samples of length N.,abstractText,[0],[0]
This sequence covers the underlying random variable space more evenly than i.i.d.,abstractText,[0],[0]
"draws, reducing the variance of the gradient estimator.",abstractText,[0],[0]
"With our novel approach, both the score function and the reparameterization gradient estimators lead to much faster convergence.",abstractText,[0],[0]
"We also propose a new algorithm for Monte Carlo objectives, where we operate with a constant learning rate and increase the number of qmc samples per iteration.",abstractText,[0],[0]
"We prove that this way, our algorithm can converge asymptotically at a faster rate than sgd.",abstractText,[0],[0]
"We furthermore provide theoretical guarantees on qmc for Monte Carlo objectives that go beyond mcvi, and support our findings by several experiments on large-scale data sets from various domains.",abstractText,[0],[0]
Quasi-Monte Carlo Variational Inference,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 24–34 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Previous work showed that treating semantic dependency parsing as the search for Maximum Subgraphs is not only elegant in theory but also effective in practice (Kuhlmann and Jonsson, 2015; Cao et al., 2017).",1 Introduction,[0],[0]
"In particular, our previous work showed that 1-endpoint-crossing, pagenumber-2 (1EC/P2) graphs are an appropriate graph class for modelling semantic dependency structures (Cao et al., 2017).",1 Introduction,[0],[0]
"On the one hand, it is highly expressive to cover a majority of semantic analysis.",1 Introduction,[0],[0]
"On the other hand, the corresponding Maximum Subgraph problem with an arc-factored disambiguation model can be solved in low-degree polynomial time.
",1 Introduction,[0],[0]
Defining disambiguation models on wider contexts than individual bi-lexical dependencies improves various syntactic parsers in different architectures.,1 Introduction,[0],[0]
This paper studies exact algorithms for second-order parsing for 1EC/P2 graphs.,1 Introduction,[0],[0]
"The existing algorithm, viz.",1 Introduction,[0],[0]
"our previous algorithm
(GCHSW, hereafter), has two properties that make it hard to incorporate higher-order features in a principled way.",1 Introduction,[0],[0]
"First, GCHSW does not explicitly consider the construction of noncrossing arcs.",1 Introduction,[0],[0]
We will show that incorporiating higher-order factors containing crossing arcs without increasing time and space complexity is extremely hard.,1 Introduction,[0],[0]
"An effective strategy is to only include higher-order factors containing only noncrossing arcs (Pitler, 2014).",1 Introduction,[0],[0]
But this crossing-sensitive strategy is incompatible with GCHSW.,1 Introduction,[0],[0]
"Second, all existing higherorder parsing algorithms for projective trees, including (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010), require that which arcs are created in a construction step be deterministic.",1 Introduction,[0],[0]
This design is also incompatible with GCHSW.,1 Introduction,[0],[0]
"In summary, it is not convenient to extend GCHSW to incorporate higher-order features while keeping the same time complexity.
",1 Introduction,[0],[0]
"In this paper, we introduce an alternative Maximum Subgraph algorithm for first-order parsing to 1EC/P2 graphs.",1 Introduction,[0],[0]
"while keeping the same time and space complexity to GCHSW, our new algorithm has two characteristics that make it relatively easy to be extended to incorporate crossingsensitive, second-order features: (1) it separates the construction for noncrossing edges and possible crossing edges; (2) whether an edge is created is deterministic in each construction rule.",1 Introduction,[0],[0]
We then introduce a new algorithm to perform secondorder parsing.,1 Introduction,[0],[0]
"When all second-order scores are greater than or equal to 0, it exactly solves the corresponding optimization problem.
",1 Introduction,[0],[0]
"We implement a practical parser with a statistical disambiguation model and evaluate it on four data sets: those used in SemEval 2014 Task 8 (Oepen et al., 2014), and the dependency graphs extracted from CCGbank (Hockenmaier and Steedman, 2007).",1 Introduction,[0],[0]
"On all data sets, we find that our second-order parsing models are more ac-
24
curate than the first-order baseline.",1 Introduction,[0],[0]
"If we do not use features derived from syntactic trees, we get an absolute unlabeled F-score improvement of 1.3 on average.",1 Introduction,[0],[0]
"When syntactic analysis is used, we get an improvement of 0.4 on average.",1 Introduction,[0],[0]
Semantic dependency parsing can be formulated as the search for Maximum Subgraph for graph class G:,2.1 Maximum Subgraph Parsing,[0],[0]
"Given a graph G = (V,A), find a subset A′ ⊆",2.1 Maximum Subgraph Parsing,[0],[0]
"A with maximum total score such that the induced subgraph G′ = (V,A′) belongs to G. Formally, we have the following optimization problem:
arg max G∗∈G(s,G) ∑ p in G∗",2.1 Maximum Subgraph Parsing,[0],[0]
"spart(s, p)
G(s, G) denotes the set of all graphs that belong to G and are compatible with s and G. G is usually a complete digraph.",2.1 Maximum Subgraph Parsing,[0],[0]
"spart(s, p) evaluates the event that part p (from a candidate graph G∗) is good.",2.1 Maximum Subgraph Parsing,[0],[0]
"We define the order of p according to the number of arcs it contains, in analogy with tree parsing in terminology.",2.1 Maximum Subgraph Parsing,[0],[0]
"Previous work only discussed the first-order case:
arg max G∗∈G(G) ∑ d∈ARC(G∗) sarc(d)
",2.1 Maximum Subgraph Parsing,[0],[0]
"If G is the set of noncrossing or 1EC/P2 graphs, the above optimization problem can be solved in cubic-time (Kuhlmann and Jonsson, 2015) and quintic-time (Cao et al., 2017) respectively.",2.1 Maximum Subgraph Parsing,[0],[0]
"Furthermore, ignoring one linguistically-rare structure in 1EC/P2 graphs descreases the complexity to O(n4).",2.1 Maximum Subgraph Parsing,[0],[0]
"This paper is concerned with secondorder parsing, with a special focus on the following factorizations:
And the objective function turns to be:∑ d∈ARC(G∗) sarc(d) +",2.1 Maximum Subgraph Parsing,[0],[0]
"∑ s∈SIB(G∗) ssib(s)
Sun et al. (2017) introduced a dynamic programming algorithm for second-order planar parsing.",2.1 Maximum Subgraph Parsing,[0],[0]
Their empirical evaluation showed that secondorder features are effective to improve parsing accuracy.,2.1 Maximum Subgraph Parsing,[0],[0]
It is still unknown how to incorporate such features for 1EC/P2 parsing.,2.1 Maximum Subgraph Parsing,[0],[0]
"The formal description of the 1-endpoint-crossing property is adopted from (Pitler et al., 2013).
","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
Definition 1.,"2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"Edges e1 and e2 cross if e1 and e2 have distinct endpoints and exactly one of the endpoints of e1 lies between the endpoints of e2.
","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
Definition 2.,"2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"A dependency graph is 1-EndpointCrossing if for any edge e, all edges that cross e share an endpoint p named pencil point.
","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"Given a sentence s = w0w1 · · ·wn−1 of length n, the vertices, i.e. words, are indexed with integers, an arc from wi to wj as a(i,j), and the common endpoint, namely pencil point, of all edges crossed with a(i,j) or a(j,i) as pt(i, j).","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"We denote an edge as e(i,j), if we do not consider its direction.","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"Figure 1 is an example.
","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
Definition 3.,"2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"A pagenumber-k graph means it consists at most k half-planes, and arcs on each half-plane are noncrossing.
","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"These half-planes may be thought of as the pages of a book, with the vertex line corresponding to the books spine, and the embedding of a graph into such a structure is known as a book embedding.","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"Figure 2 is an example.
","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"(Pitler et al., 2013) proved that 1-endpointcrossing trees are a subclass of graphs whose pagenumber is at most 2.","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"In Cao et al. (2017), we studied graphs that are constrained to be both 1-endpoint-crossing and pagenumber-2.","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"In this paper, we ignored a complex and linguistic-rare
structure and studied a subset of 1EC/P2 graphs.","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"The complex structure is named as C structures in our previous paper, and Figure 3 is the prototype of C structures.","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"In this paper, we present new algorithms for finding optimal 1EC/P2, C-free graphs.","2.2 1-Endpoint-Crossing, Pagenumber-2 Graphs",[0],[0]
"Cao et al. (2017) designed a polynomial time Maximum Subgraph algorithm, viz.",2.3 The GCHSWAlgorithm,[0],[0]
"GCHSW, for 1EC/P2 graphs by exploring the following property: Every subgraph of a 1EC/P2 graph is also a 1EC/P2 graph.",2.3 The GCHSWAlgorithm,[0],[0]
GCHSW defines a number of prototype backbones for decomposing a 1EC/P2 graph in a principled way.,2.3 The GCHSWAlgorithm,[0],[0]
"In each decomposition step, GCHSW focuses on the edges that can be created without violating either the 1EC nor P2 restriction.",2.3 The GCHSWAlgorithm,[0],[0]
"Sometimes, multiple edges can be created simultaneously in one single step.",2.3 The GCHSWAlgorithm,[0],[0]
"Figure 4 is an example.
",2.3 The GCHSWAlgorithm,[0],[0]
"There is an important difference between GCHSW and Eisner-style Maximum Spanning Tree algorithms (MST; Eisner, 1996; McDonald and Pereira, 2006; Koo and Collins, 2010).",2.3 The GCHSWAlgorithm,[0],[0]
"In each construction step, GCHSW allows multiple arcs to be constructed, but whether or not such arcs are added to the target graph depends on their arc-weights.",2.3 The GCHSWAlgorithm,[0],[0]
"If all arcs are assigned scores that are greater than 0, the output of our algorithm includes the most complicated 1EC/P2 graphs.",2.3 The GCHSWAlgorithm,[0],[0]
"For the higher-order MST algorithms, in a single construction step, it is clear whether adding a new arc, and which one.",2.3 The GCHSWAlgorithm,[0],[0]
There is no local search.,2.3 The GCHSWAlgorithm,[0],[0]
This deterministic strategy is also followed by Kuhlmann and Jonsson’s Maximum Subgraph algorithm for noncrossing graphs.,2.3 The GCHSWAlgorithm,[0],[0]
Higher-order MST models associate higher-order score functions with the construction of individual dependencies.,2.3 The GCHSWAlgorithm,[0],[0]
Therefore the deterministic strategy is a prerequisite to incorporate higher-order features.,2.3 The GCHSWAlgorithm,[0],[0]
The design of GCHSW is incompatible with this strategy.,2.3 The GCHSWAlgorithm,[0],[0]
It is very difficult to enumerate all high-order features for crossing arcs.,2.4 Challenge of Second-Order Decoding,[0],[0]
Figure 5 illustrates the idea.,2.4 Challenge of Second-Order Decoding,[0],[0]
"There is a pair of corssing arcs, viz. e(x,k) and e(i,j).",2.4 Challenge of Second-Order Decoding,[0],[0]
"The key strategy to develop a dynamic programming algorithm to generate such crossing structure is to treat parts of this structures as intervals/spans together with an external vertex (Pitler et al., 2013; Cao et al., 2017).",2.4 Challenge of Second-Order Decoding,[0],[0]
"Without loss of generality, we assume [i, j] makes up such an interval and x is the corresponding external vertex.",2.4 Challenge of Second-Order Decoding,[0],[0]
"When we consider e(i,j), its neighboring edges can be e(i,ri) and e(lj ,j), and therefore we need to consider searching the best positions of both ri and lj .",2.4 Challenge of Second-Order Decoding,[0],[0]
"Because we have already taken into account three vertices, viz.",2.4 Challenge of Second-Order Decoding,[0],[0]
"x, i and j, the two new positions increase the time complexity to be at least quintic.
",2.4 Challenge of Second-Order Decoding,[0],[0]
"Now consider e(x,k).",2.4 Challenge of Second-Order Decoding,[0],[0]
When we decompose the whole graph into inverval,2.4 Challenge of Second-Order Decoding,[0],[0]
"[i, j] plus x and remaining part, we will factor out e(x,k) in a successive decomposition for resolving [i, j] plus x.",2.4 Challenge of Second-Order Decoding,[0],[0]
"We cannot capture the second features associated to e(x,k) and e(x,rx), because they are in different intervals, and when these intervals are combined, we have already hidden the position information of k. Explicitly encoding k increases the time complexity to be at least quintic too.
",2.4 Challenge of Second-Order Decoding,[0],[0]
Pitler (2014) showed that it is still possible to build accurate tree parsers by considering only higher-order features of noncrossing arcs.,2.4 Challenge of Second-Order Decoding,[0],[0]
This is in part because only a tiny fraction of neighboring arcs involve crossing arcs.,2.4 Challenge of Second-Order Decoding,[0],[0]
"However, this strategy is not easy to by applied to GCHSW, because GCHSW does not explicitly analyze sub-graphs of noncrossing arcs.",2.4 Challenge of Second-Order Decoding,[0],[0]
"Based on the discussion of Section 2.3 and 2.4, we can see that it is not easy to extend the existing algorithm, viz.",3 A New Maximum Subgraph Algorithm,[0],[0]
"GCHSW, to handle second-order features.",3 A New Maximum Subgraph Algorithm,[0],[0]
"In this paper, we propose an alternative first-order dynamic programming algorithm.",3 A New Maximum Subgraph Algorithm,[0],[0]
"Because ignoring one linguistically-rare structure associated with the C problem in GCHSW descreases the complexity, we exclude this structure in our algorithm.",3 A New Maximum Subgraph Algorithm,[0],[0]
"Formally, we introduce a new algorithm
IntO(i, j)← max IntO(i + 1, j) IntC(i, j) IntC(i, k) + IntO(k, j) RC(i, k, x) + IntO(k, x) +",3 A New Maximum Subgraph Algorithm,[0],[0]
"LO(x, j, k) +",3 A New Maximum Subgraph Algorithm,[0],[0]
"sarc(i, k) LR(i, k, x) + IntO(k, x) +",3 A New Maximum Subgraph Algorithm,[0],[0]
"IntO(x, j, k) +",3 A New Maximum Subgraph Algorithm,[0],[0]
"sarc(i, k) IntO[i, x] +",3 A New Maximum Subgraph Algorithm,[0],[0]
LC,3 A New Maximum Subgraph Algorithm,[0],[0]
"[x, k, i] + NO[k, j, x] +",3 A New Maximum Subgraph Algorithm,[0],[0]
"sarc(i, k) RO[i, x, k] + IntO[x, k] + LO[k, j, x] +",3 A New Maximum Subgraph Algorithm,[0],[0]
"sarc(i, k)
IntC(i, j)← sarc(i, j) +",3 A New Maximum Subgraph Algorithm,[0],[0]
"max IntO(i + 1, j) IntC(i, k) + IntO(k, j) RC(i, k, x) + IntO(k, x) +",3 A New Maximum Subgraph Algorithm,[0],[0]
"LO(x, j, k) +",3 A New Maximum Subgraph Algorithm,[0],[0]
"sarc(i, k) LR(i, k, x) + IntO(k, x) +",3 A New Maximum Subgraph Algorithm,[0],[0]
"IntO(x, j, k) +",3 A New Maximum Subgraph Algorithm,[0],[0]
"sarc(i, k) IntO[i, x] +",3 A New Maximum Subgraph Algorithm,[0],[0]
LC,3 A New Maximum Subgraph Algorithm,[0],[0]
"[x, k, i] + NO[k, j, x] +",3 A New Maximum Subgraph Algorithm,[0],[0]
"sarc(i, k) RO[i, x, k] + IntO[x, k] + LO[k, j, x] + sarc(i, k)
to solve the following optimization problem:
arg max G∗∈G(G) ∑ d∈ARC(G∗) sarc(d)
where G means 1EC/P2, C-free graphs.",3 A New Maximum Subgraph Algorithm,[0],[0]
Our algorithm has the same time and space complexity to the degenerated version of GCHSW.,3 A New Maximum Subgraph Algorithm,[0],[0]
We represent our algorithm using undirected graphs.,3 A New Maximum Subgraph Algorithm,[0],[0]
"Following GCHSW, we consider five sub-problems when we construct a maximum dependency graph on a given interval",3.1 Sub-problems,[0],[0]
"[i, k].",3.1 Sub-problems,[0],[0]
"Though the subproblems introduced by GCHSW and us handle similar structures, their definitions are quite different.",3.1 Sub-problems,[0],[0]
"The sub-problems are explained as follows:
Int Int[i, j] represents an interval from i to j inclusively.",3.1 Sub-problems,[0],[0]
"And there is no edge e(i′,j′) such that i′ ∈",3.1 Sub-problems,[0],[0]
"[i, j] and j′ /∈",3.1 Sub-problems,[0],[0]
"[i, j].",3.1 Sub-problems,[0],[0]
"We distinguish two sub-types for Int. IntO[i, j] may or may not contain e(i,j), while IntC [i, j] contains e(i,j).
LR LR[i, j, x] represents an interval from i to j inclusively and an external vertex",3.1 Sub-problems,[0],[0]
"x. ∀p ∈
",3.1 Sub-problems,[0],[0]
"[i, j], pt(x, p) = i or j. LR[i, j, x] implies the existence of e(i,j), but does not contain e(i,j).",3.1 Sub-problems,[0],[0]
"When LR[i, j, x] is combined with other DP sub-structures, e(i,j) is immediately created.",3.1 Sub-problems,[0],[0]
"LR[i, j, x] disallows neither e(x,i) nor e(x,j).
",3.1 Sub-problems,[0],[0]
N N,3.1 Sub-problems,[0],[0]
"[i, j, x] represents an interval from i to j inclusively and an external vertex",3.1 Sub-problems,[0],[0]
x. ∀p ∈,3.1 Sub-problems,[0],[0]
"[i, j], pt(x, p) /∈",3.1 Sub-problems,[0],[0]
"[i, j].",3.1 Sub-problems,[0],[0]
N,3.1 Sub-problems,[0],[0]
"[i, j, x] could contain e(i,j) but disallows e(x,i).",3.1 Sub-problems,[0],[0]
We distinguish two sub-types.,3.1 Sub-problems,[0],[0]
"NO[i, j, x] may or may not contain e(x,j).",3.1 Sub-problems,[0],[0]
NC,3.1 Sub-problems,[0],[0]
"[i, j, x] implies the existence of but does not contain e(x,j).",3.1 Sub-problems,[0],[0]
When N,3.1 Sub-problems,[0],[0]
"[i, j, x] is combined with others, e(x,j) is immediately created.
",3.1 Sub-problems,[0],[0]
"L L[i, j, x] represents an interval from i to j inclusively as well as an external vertex",3.1 Sub-problems,[0],[0]
x. ∀p ∈,3.1 Sub-problems,[0],[0]
"[i, j], pt(x, p) = i. L[i, j, x] could contain e(i,j) but disallows e(x,i).",3.1 Sub-problems,[0],[0]
"We distinguish sub-two types for L. LO[i, j, x] may or may not contain e(x,j).",3.1 Sub-problems,[0],[0]
LC,3.1 Sub-problems,[0],[0]
"[i, j, x] implies the existence of but does not contain e(x,j).",3.1 Sub-problems,[0],[0]
"When it is combined with others, e(x,j) is immediately created.
",3.1 Sub-problems,[0],[0]
"R R[i, j, x] represents an interval from i to j inclusively as well as an external vertex",3.1 Sub-problems,[0],[0]
x. ∀p ∈,3.1 Sub-problems,[0],[0]
"[i, j], pt(x, p) = j. R[i, j, x] disallows e(x,j) and e(x,i).",3.1 Sub-problems,[0],[0]
"We distinguish two sub-types for R. RO[i, j, x] may or may not contain e(i,j).",3.1 Sub-problems,[0],[0]
RC,3.1 Sub-problems,[0],[0]
"[i, j, x] implies the existence of but does not contain e(i,j).",3.1 Sub-problems,[0],[0]
"When it is combined with others, e(i,j) is immediately created.",3.1 Sub-problems,[0],[0]
Figure 7 gives a sketch of our dynamic programming algorithm.,3.2 Decomposing Sub-problems,[0],[0]
"We give a detailed illustration for Int, a rough idea for L and LR, and omit other sub-problems.",3.2 Decomposing Sub-problems,[0],[0]
More details about the whole algorithm can be found in the supplementary note.,3.2 Decomposing Sub-problems,[0],[0]
"Consider IntO[i, j] and IntC",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"[i, j] sub-problem.",3.2.1 Decomposing an Int Sub-problem,[0],[0]
Because the decomposition for IntC,3.2.1 Decomposing an Int Sub-problem,[0],[0]
"[i, j] is very similar to IntO[i, j] and needs to be modified by our second-order parsing algorithm, we only show the decomposition of IntC",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"[i, j].",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"Assume that k(k ∈ (i, j)) is the farthest vertex that is adjacent to i, and x = pt(i, k).",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"If there is no such k (i.e. there no arc from i to some other node in this interval), then we denote k as ∅.",3.2.1 Decomposing an Int Sub-problem,[0],[0]
So it is to x.,3.2.1 Decomposing an Int Sub-problem,[0],[0]
"We illustrate different cases as following and give a graphical representation in Figure 8.
",3.2.1 Decomposing an Int Sub-problem,[0],[0]
Case a: k = ∅.,3.2.1 Decomposing an Int Sub-problem,[0],[0]
We can directly consider interval,3.2.1 Decomposing an Int Sub-problem,[0],[0]
"[i + 1, j].",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"Because there is no edge from i to any node in [i + 1, j], [i + 1, j] is an IntO.
Case b: x = ∅. x = ∅ means that e(i,k) does not cross other arcs.",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"So [i, k] and",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"[k, j] are Int.
",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"Case c: x ∈ (k, j].",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"e(i,k) is taken as a possible crossing edge.",3.2.1 Decomposing an Int Sub-problem,[0],[0]
k and x divide the interval,3.2.1 Decomposing an Int Sub-problem,[0],[0]
"[i, j] into three parts: [i, k], [k, x], [x, j].",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"Because x may be j, interval",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"[x, j] may only contain j and become an empty interval.",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"We define x′ as the pencil point of all edges from (i, k) to x, and distinguish two sub-problems as follows.
c.1",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"Assume that there exists an edge from k to some node r in (x, j], so x′ can only be k and pencil point of edges from k to (x, j] is x.",3.2.1 Decomposing an Int Sub-problem,[0],[0]
Thus interval,3.2.1 Decomposing an Int Sub-problem,[0],[0]
"[i, k, x] is an R. Due to the existence of e(i,k), its sub-type is RC.",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"The e(i,k) is created in this construction and thus not contained by RC [i, k, x].",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"An edge from within [k, x] to outside violates the 1EC restriction, so",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"[k, x] is an Int.",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"Since x is endpoint of edge
from k to [x, r], interval [k, j] is an LO with external vertex k.
c.2",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"We assume no edge from k to any node in [x, j], x′ thus can be i or k.",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"As a result, [x, j] is an Int and [i, k,",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"x] is an LR.
",3.2.1 Decomposing an Int Sub-problem,[0],[0]
Case d: x ∈,3.2.1 Decomposing an Int Sub-problem,[0],[0]
"(i, k).
d.1 Assume that there exist edges from i to (x, k), so the pencil point of edges from x to (k, j] is",3.2.1 Decomposing an Int Sub-problem,[0],[0]
i. Therefore,3.2.1 Decomposing an Int Sub-problem,[0],[0]
"[k, j] is an N. Because x is pencil point of edges from i to (x, k], [x, k] is an L. Furthmore, it is an LC because we generate e(i,k) in this step.",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"It is obvious that [i, x] is an Int.
d.2",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"Assume that there exists edges from k to (i, x), and the pencil point of edges from x to (k, j] is thus k. Similar to the above analysis, we reach RO[i, x, k]+IntO[x, k]+ LO[k, j, x] + e(i,k) + e(i,j).
",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"For IntO[i, j], because there may be e(i,j), we add one more rule: IntO[i, j] = IntC",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"[i, j].",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"And we do not need to create e(i,j) in all cases.",3.2.1 Decomposing an Int Sub-problem,[0],[0]
"Without loss of generality, we show the decomposition of LO[i, j, x] as follows.",3.2.2 Decomposing an L Sub-problem,[0],[0]
"For LC [i, j, x], we ignore Case b but follow the others.
",3.2.2 Decomposing an L Sub-problem,[0],[0]
Case a.,3.2.2 Decomposing an L Sub-problem,[0],[0]
"If there is no more edge from x to (i, j], then it will degenerate to IntO[i, j].
",3.2.2 Decomposing an L Sub-problem,[0],[0]
Case b.,3.2.2 Decomposing an L Sub-problem,[0],[0]
"If there exists e(x,j), then it will degenerate to LC",3.2.2 Decomposing an L Sub-problem,[0],[0]
"[i, j, x] + e(x,j).
",3.2.2 Decomposing an L Sub-problem,[0],[0]
"Case c. Assume that there are edges from x to (i, j) and e(x,k) is the farthest one.",3.2.2 Decomposing an L Sub-problem,[0],[0]
"It divides [i, j] into [i, k] and",3.2.2 Decomposing an L Sub-problem,[0],[0]
"[k, j].
c.1",3.2.2 Decomposing an L Sub-problem,[0],[0]
"If there is an edge from x to (i, k),",3.2.2 Decomposing an L Sub-problem,[0],[0]
"[i, k] and [k, j] are LC [i, k, x] and NO[k, j, i].
c.2",3.2.2 Decomposing an L Sub-problem,[0],[0]
"If there is no edge from x to (i, k),",3.2.2 Decomposing an L Sub-problem,[0],[0]
"[i, k] and [k, j] are IntO[i, k] and LO[k, j, i].
",3.2.2 Decomposing an L Sub-problem,[0],[0]
Figure 8 is a graphical representation.,3.2.2 Decomposing an L Sub-problem,[0],[0]
"LR[i, j, x] means i or j is the pencil point of edges from x to (i, j).",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"We show the decomposition of LR[i, j, x] as follows:
",3.2.3 Decomposing an LR Sub-problem,[0],[0]
Case a.,3.2.3 Decomposing an LR Sub-problem,[0],[0]
"If there is a vertex k within (i, j), which divides [i, j] into [i, k] and",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"[k, j].",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"And it guarantees no edge from [i, k) to (k, j].",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"i is the pencil point of edges from x to (i, k] because no edge from j to (i, k) can cross these edges.",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"Similarly j has to be the pencil point of edges from x to (k, j).",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"Obviously, [i, k] is an LO and [k, j] is an RO with external x.",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"Thus the problem is decomposed as LO[i, k, x] + RO[k, j, x].
",3.2.3 Decomposing an LR Sub-problem,[0],[0]
Case b.,3.2.3 Decomposing an LR Sub-problem,[0],[0]
"If there is no such vertex k, there must be edges from [i, k′) to (k′, j] for every k′ in (i, j) without considering e(i,j).",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"For i + 1, we assume e(i,a1) is the farthest edge that goes from i.",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"For a1, we assume e(b1,b2) is the farthest edge from b1 where b1 is in (i, a1) and b2 is in (a1, j).",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"For b2, we assume e(a1,a3) is the farthest edge from a1 where a3 is in (b2, j) and a1 is the pencil point.",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"We then get the series {a1, a2, a3...an} and {b1, b2...",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"bm}which guarantees bi < ai , ai < bi+1 and max(an, bm) =",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"j.
If bm = j, we will get a graph like Figure 10.",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"If e(x,b1) exists, this LR subproblem degenerates to an L subproblem.",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"If e(x,an) exists, this subproblem degenerates to an R subproblem.
",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"If am = j, we will get a graph like Figure 11.",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"If there exists only e(x,b1) or e(x,bm), we can solve it like bm = j.",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"If both exist, this is a typical C-
structure like Figure 3 and we cannot get it through other decompostion.
",3.2.3 Decomposing an LR Sub-problem,[0],[0]
The above discussion gives the rough idea of the correctness of the following conclusion.,3.2.3 Decomposing an LR Sub-problem,[0],[0]
Theorem 1.,3.2.3 Decomposing an LR Sub-problem,[0],[0]
"Our new algorithm is sound and complete with respect to 1EC/P2, C-free graphs.",3.2.3 Decomposing an LR Sub-problem,[0],[0]
"An LR, L, R or N sub-problem allows to build crossing arcs, but does not necessarily create crossing arcs.",3.3 Spurious Ambiguity,[0],[0]
"For example, LC [i, j, x] allows e(i,j) to cross with e(x,y) (y ∈ (i, j)).",3.3 Spurious Ambiguity,[0],[0]
"Because every subgraph of a 1EC/P2 graph is also a 1EC/P2 graph, we allow an LC [i, j, x] to be directly degenerated to IO[i, j].",3.3 Spurious Ambiguity,[0],[0]
"In this way, we can make sure that all subgraphs can be constructed by our algorithm.",3.3 Spurious Ambiguity,[0],[0]
Figure 12 shows the rough idea.,3.3 Spurious Ambiguity,[0],[0]
"To generate the same graph, we have different derivations.",3.3 Spurious Ambiguity,[0],[0]
"The spurious ambiguity in our algorithm does not affect the correctness of first-order parsing, because scores are assigned to individual dependencies, rather than derivation processes.",3.3 Spurious Ambiguity,[0],[0]
There is no need to distinguish one special derivation here.,3.3 Spurious Ambiguity,[0],[0]
We propose a second-order extension of our new algorithm.,4 Quasi-Second-Order Extension,[0],[0]
We focus on factorizations introduced in Section 2.1.,4 Quasi-Second-Order Extension,[0],[0]
"Especially, the two arcs in a factor should not cross other arcs.",4 Quasi-Second-Order Extension,[0],[0]
"Formally, we introduce a new algorithm to solve the optimization problem with the following objective:∑
d∈ARC(G∗) sarc(d) + ∑ s∈SIB(G∗) max(ssib(s), 0)
",4 Quasi-Second-Order Extension,[0],[0]
"In the first-order algorithm, all noncrossing edges can be constructed as the frontier edge of an IntC.
So we can develop an exact decoding algorithm by modifying the composition for IntC while keeping intact the decomposition for LR, N, L, R.
4.1 New Decomposition for IntC",4 Quasi-Second-Order Extension,[0],[0]
"In order to capture the second-order features from noncrossing neighbors, we need to find the rightmost node adjacent to i, denoted as ri, and the leftmost node adjacent to j, denoted as lj ,while i < ri ≤",4 Quasi-Second-Order Extension,[0],[0]
"lj < j. To do this, we split IntC",4 Quasi-Second-Order Extension,[0],[0]
"[i, j] into at most three parts to capture the sibling factors.",4 Quasi-Second-Order Extension,[0],[0]
"Denote the score of adjacent edges e(i,j1) and e(i,j2) as s2(i, j1, j2).",4 Quasi-Second-Order Extension,[0],[0]
"When j is the inner most node adjacent to i, we denote the score as s2(i, ∅, j).",4 Quasi-Second-Order Extension,[0],[0]
We give a sketch of the decomposition in Figure 14 and a graphical representation in Figure 13.,4 Quasi-Second-Order Extension,[0],[0]
"The following is a rough illustration.
",4 Quasi-Second-Order Extension,[0],[0]
"Case a: ri = ∅. We further distinguish three sub-problems:
a.1",4 Quasi-Second-Order Extension,[0],[0]
"If lj = ∅ too, both sides are the inner most second-order factor.
a.2",4 Quasi-Second-Order Extension,[0],[0]
"There is a crossing arc from j. This case is handled in the same way as the first-order algorithm.
a.3",4 Quasi-Second-Order Extension,[0],[0]
lj 6= ∅.,4 Quasi-Second-Order Extension,[0],[0]
"We introduce a new decomposition rule.
",4 Quasi-Second-Order Extension,[0],[0]
"Case b: There is a crossing arc from i.
b.1",4 Quasi-Second-Order Extension,[0],[0]
lj = ∅. Similar case to (a.2).,4 Quasi-Second-Order Extension,[0],[0]
b.2,4 Quasi-Second-Order Extension,[0],[0]
"There is a crossing arc from j. Similar case
to (a.2).
b.3",4 Quasi-Second-Order Extension,[0],[0]
"There is a noncrossing arc from j. We introduce a new rule to calculate SIB(j, lj , i).
",4 Quasi-Second-Order Extension,[0],[0]
Case c:,4 Quasi-Second-Order Extension,[0],[0]
"There is a noncrossing arc from i.
c.1",4 Quasi-Second-Order Extension,[0],[0]
"lj = ∅. Similar to (a.3).
",4 Quasi-Second-Order Extension,[0],[0]
c.2,4 Quasi-Second-Order Extension,[0],[0]
"There is a crossing arc from j. Similar to (b.3).
",4 Quasi-Second-Order Extension,[0],[0]
c.3,4 Quasi-Second-Order Extension,[0],[0]
There is a noncrossing arc from j too.,4 Quasi-Second-Order Extension,[0],[0]
"We introduce a new rule to calculate SIB(i, ri, j) and SIB(j, lj , i).",4 Quasi-Second-Order Extension,[0],[0]
The complexity of both first- and second-order algorithms can be analyzed in the same way.,4.2 Complexity,[0],[0]
"The sub-problem Int is of size O(n2), with a calculating time of order O(n2) at most.",4.2 Complexity,[0],[0]
"For sub-problems L, R, LR, and N, each has O(n3) elements, with a unit calculating time O(n).",4.2 Complexity,[0],[0]
Therefore both algorithms run in time of O(n4) with a space requirement of O(n3).,4.2 Complexity,[0],[0]
"A traditional second-order model takes as the objective function ∑ s∈SIB(G∗) ssib(s).
",4.3 Discussion,[0],[0]
"Our model instead tries to optimize∑ s∈SIB(G∗) max(ssib(s), 0).",4.3 Discussion,[0],[0]
This model is somehow inadequate given that the second-order score function cannot penalize a bad factor.,4.3 Discussion,[0],[0]
"When a negative score is assigned to a second-order factor, it will be taken as 0 by our algorithm.
",4.3 Discussion,[0],[0]
This inadequacy is due to the spurious ambiguity problem that is illustrated in Section 3.3.,4.3 Discussion,[0],[0]
Take the two derivations in Figure 12 for example.,4.3 Discussion,[0],[0]
"The derivation that starts from IntC [a, e]⇒ IntC [a, c]+IntO[c, e] incorporates the second-order score ssib(a, c, e).",4.3 Discussion,[0],[0]
"This is different when we consider the derivation that starts from IntC [a, e] ⇒ LR[a, c, d] + IntO[k, d] + LO[d, e, c].",4.3 Discussion,[0],[0]
"Because we assume temporarily that e(a,c) crosses others, we do not consider ssib(a, c, e).",4.3 Discussion,[0],[0]
"We can see from this example that second-order scores not only depend on the derived graphs but also sensitive to the derivation processes.
",4.3 Discussion,[0],[0]
"If a second-order score is greater than 0, our algorithm selects the derivation that takes it into account since it increases the total score.",4.3 Discussion,[0],[0]
"If a secondorder score is negative, our algorithm avoids including it by selecting other paths.",4.3 Discussion,[0],[0]
"In other words, our algorithm treats this score as 0.",4.3 Discussion,[0],[0]
We extend our quartic-time parsing algorithm into a practical parser.,5.1 Derivation-Sensitive Training,[0],[0]
"In the context of data-driven parsing, this requires an extra disambiguation model.",5.1 Derivation-Sensitive Training,[0],[0]
"As with many other parsers, we employ a global linear model.",5.1 Derivation-Sensitive Training,[0],[0]
"Following Zhang et al. (2016)’s experience, we define rich features extracted from word, POS-tags and pseudo trees.",5.1 Derivation-Sensitive Training,[0],[0]
"To estimate parameters, we utilize the averaged perceptron algorithm (Collins, 2002).
",5.1 Derivation-Sensitive Training,[0],[0]
Our training proceudre is sensitive to derivation rather then derived graphs.,5.1 Derivation-Sensitive Training,[0],[0]
"For each sentence, we first apply our algorithm to find the optimal prediction derivation.",5.1 Derivation-Sensitive Training,[0],[0]
The we collect all first- and second-order factors from this derivation to update parameters.,5.1 Derivation-Sensitive Training,[0],[0]
"To train a first-order model, because our algorithm includes all factors, viz.",5.1 Derivation-Sensitive Training,[0],[0]
"depencies, there is no difference between our derivationbased method and a traditional derived structurebased method.",5.1 Derivation-Sensitive Training,[0],[0]
"For the second-order model, our method increases the second-order scores somehow.",5.1 Derivation-Sensitive Training,[0],[0]
"We evaluate first- and second-order models on four representative data sets: CCGBank (Hockenmaier and Steedman, 2007), DeepBank (Flickinger et al., 2012), Enju HPSGBank (Miyao et al., 2005) and Prague Dependency TreeBank (Hajic et al., 2012).",5.2 Data and Preprocessing,[0],[0]
"We use “standard” training, validation, and test splits to facilitate comparisons.
",5.2 Data and Preprocessing,[0],[0]
"• Following previous experimental setup for English CCG parsing, we use section 02-21 as training data, section 00 as the development data, and section 23 for testing.
",5.2 Data and Preprocessing,[0],[0]
"• The DeepBank, Enju HPSGBank and Prague Dependency TreeBank are from SemEval 2014 Task 8 (Oepen et al., 2014), and the data splitting policy follows the shared task.
",5.2 Data and Preprocessing,[0],[0]
"Experiments for CCG-grounded analysis were performed using automatically assigned POS-tags that are generated by a symbol-refined HMM tagger (Huang et al., 2010).",5.2 Data and Preprocessing,[0],[0]
Experiments for the other three data sets used POS-tags provided by the shared task.,5.2 Data and Preprocessing,[0],[0]
We also use features extracted from pseudo trees.,5.2 Data and Preprocessing,[0],[0]
"We utilize the Mate parser (Bohnet, 2010) to generate pseudo trees.",5.2 Data and Preprocessing,[0],[0]
All experimental results consider directed dependencies in a standard way.,5.2 Data and Preprocessing,[0],[0]
"We report Unlabeled Precision (UP), Recall (UR) and F-score (UF), which are calculated using the official evaluation tool provided by SDP2014 shared task.",5.2 Data and Preprocessing,[0],[0]
Table 1 lists the accuracy of our system.,5.3 Accuracy,[0],[0]
The output of our parser was evaluated against each dependency in the corpus.,5.3 Accuracy,[0],[0]
"We can see that the firstorder parser obtains a considerably good accuracy, with rich syntactic features.",5.3 Accuracy,[0],[0]
"Furthermore, we can see that the introduction of higher-order features improves parsing substantially for all data sets, as expected.",5.3 Accuracy,[0],[0]
"When syntactic trees are utilized, the
improvement is smaller but still significant on the three SemEval data sets.
",5.3 Accuracy,[0],[0]
Table 2 lists the parsing results on the test data together with the result obtained by Sun et al. (SJW; 2017)’s system.,5.3 Accuracy,[0],[0]
"The building architectures of both systems are comparable.
",5.3 Accuracy,[0],[0]
1.,5.3 Accuracy,[0],[0]
Both systems have explicit control of the output structures.,5.3 Accuracy,[0],[0]
"While Sun et al.’s system constrain the output graph to be P2 only, our system adds an additional 1EC restriction.
",5.3 Accuracy,[0],[0]
2.,5.3 Accuracy,[0],[0]
"Their system’s second-order features also includes both-side neighboring features.
3.",5.3 Accuracy,[0],[0]
"Their system uses beam search and dual decomposition and therefore approximate, while ours perform exact decoding.
",5.3 Accuracy,[0],[0]
We can see that while our purely Maximum Subgraph parser obtains better results on DeepBank and CCGBank; while the book embedding parser is better on the other two data sets.,5.3 Accuracy,[0],[0]
Our algorithm is sensitive to the derivation process and may exclude a couple of negative secondorder scores by selecting misleading derivations.,5.4 Analysis,[0],[0]
"Neverthess, our algorithm works in an exact way to include all positive second-order scores.",5.4 Analysis,[0],[0]
Table 3 shows the coverage of all second-order factors.,5.4 Analysis,[0],[0]
"On average, 99.67% second-order factors are calculated by our algorithm.",5.4 Analysis,[0],[0]
This relatively satisfactory coverage suggests that our algorithm is very effective to include second-order features.,5.4 Analysis,[0],[0]
Only a very small portion is dropped.,5.4 Analysis,[0],[0]
"This paper proposed two exact, graph-based algorithms for 1EC/P2 parsing with first-order and quasi-second-order scores.",6 Conclusion,[0],[0]
The resulting parser has the same asymptotic run time as Cao et al. (2017)’s algorithm.,6 Conclusion,[0],[0]
An exploration of other factorizations that facilitate semantic dependency parsing may be an interesting avenue for future work.,6 Conclusion,[0],[0]
"Recent work has investigated faster decoding for higher-order graph-based projective parsing e.g. vine pruning (Rush and Petrov, 2012) and cube pruning (Zhang and McDonald, 2012).",6 Conclusion,[0],[0]
It would be interesting to extend these lines of work to decrease the complexity of our quartic algorithm.,6 Conclusion,[0],[0]
"This work was supported by 863 Program of China (2015AA015403), NSFC (61331011), and Key Laboratory of Science, Technology and Standard in Press Industry (Key Laboratory of Intelligent Press Media Technology).",Acknowledgments,[0],[0]
Weiwei Sun is the corresponding author.,Acknowledgments,[0],[0]
"We propose a new Maximum Subgraph algorithm for first-order parsing to 1endpoint-crossing, pagenumber-2 graphs.",abstractText,[0],[0]
"Our algorithm has two characteristics: (1) it separates the construction for noncrossing edges and crossing edges; (2) in a single construction step, whether to create a new arc is deterministic.",abstractText,[0],[0]
These two characteristics make our algorithm relatively easy to be extended to incorporiate crossing-sensitive second-order features.,abstractText,[0],[0]
We then introduce a new algorithm for quasi-second-order parsing.,abstractText,[0],[0]
Experiments demonstrate that second-order features are helpful for Maximum Subgraph parsing.,abstractText,[0],[0]
"Quasi-Second-Order Parsing for 1-Endpoint-Crossing, Pagenumber-2 Graphs",title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 643–653, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Semantic role labeling (SRL) is the widely studied challenge of recovering predicate-argument structure for natural language words, typically verbs.",1 Introduction,[0],[0]
"The goal is to determine “who does what to whom,” “when,” and “where,” etc.",1 Introduction,[0],[0]
"(Palmer et al., 2010; Johansson and Nugues, 2008).",1 Introduction,[0],[0]
"However, this intuition is difficult to formalize and fundamental aspects of the task vary across efforts, for example FrameNet (Baker et al., 1998) models a large set of interpretable thematic roles (AGENT, PATIENT, etc.) while PropBank (Palmer et al., 2005) uses a small set of verb-specific roles
(ARG0, ARG1, etc.).",1 Introduction,[0],[0]
"Existing task definitions can be complex and require significant linguistic expertise to understand,1 causing challenges for data annotation and use in many target applications.
",1 Introduction,[0],[0]
"In this paper, we introduce a new questionanswer driven SRL task formulation (QA-SRL), which uses question-answer pairs to label verbal predicate-argument structure.",1 Introduction,[0],[0]
"For example, for the sentence in Figure 1, we can ask a short question containing a verb, e.g. “Who finished something?”, and whose answer is a phrase from the original sentence, in this case “UCD.”",1 Introduction,[0],[0]
"The answer tells us that “UCD” is an argument of “finished,” while the question provides an indirect label on the role that “UCD” plays.",1 Introduction,[0],[0]
"Enumerating all such pairs, as we will see later, provides a relatively complete representation of the original verb’s arguments and modifiers.
",1 Introduction,[0],[0]
The QA-SRL task formulation has a number of advantages.,1 Introduction,[0],[0]
It can be easily explained to nonexpert annotators with a short tutorial and a few examples.,1 Introduction,[0],[0]
"Moreover, the formulation does not depend on any pre-defined inventory of semantic roles or frames, or build on any existing gram-
1The PropBank annotation guide is 89 pages (Bonial et al., 2010), and the FrameNet guide is 119 pages (Ruppenhofer et al., 2006).",1 Introduction,[0],[0]
"Our QA-driven annotation instructions are 5 pages.
643
mar formalisms.",1 Introduction,[0],[0]
"Nonetheless, as we will show, it still represents the argument and modifier attachment decisions that have motivated previous SRL definitions, and which are of crucial importance for semantic understanding in a range of NLP tasks, such as machine translation (Liu and Gildea, 2010) and coreference resolution (Ponzetto and Strube, 2006).",1 Introduction,[0],[0]
"The annotations also, perhaps surprisingly, capture other implicit arguments that cannot be read directly off of the syntax, as was required for previous SRL approaches.",1 Introduction,[0],[0]
"For example, in “It was his mother’s birthday, so he was going to play her favorite tune”, annotators created the QA pair “When would someone play something?",1 Introduction,[0],[0]
His mother’s birthday” which describes an implicit temporal relation.,1 Introduction,[0],[0]
"Finally, QA-SRL data can be easily examined, proofread, and improved by anyone who speaks the language and understands the sentence; we use natural language to label the structure of natural language.
",1 Introduction,[0],[0]
We present a scalable approach for QA-SRL annotation and baseline models for predicting QA pairs.,1 Introduction,[0],[0]
"Given a sentence and target word (the verb), we ask annotators to provide as many questionanswer pairs as possible, where the question comes from a templated space of wh-questions2 and the answer is a phrase from the original sentence.",1 Introduction,[0],[0]
This approach guides annotators to quickly construct high quality questions within a very large space of possibilities.,1 Introduction,[0],[0]
"Given a corpus of QASRL annotated sentences, we also train baseline classifiers for both predicting a set of questions to ask, and what their answers should be.",1 Introduction,[0],[0]
"The question generation aspect of QA-SRL is unique to our formulation, and corresponds roughly to identifying what semantic role labels are present in previous formulations of the task.",1 Introduction,[0],[0]
"For example, the question “Who finished something” in Figure 1 corresponds to the AGENT role in FrameNet.",1 Introduction,[0],[0]
Table 1 also shows examples of similar correspondences for PropBank roles.,1 Introduction,[0],[0]
"Instead of pre-defining the labels, as done in previous work, the questions themselves define the set of possibilities.
",1 Introduction,[0],[0]
Experiments demonstrate high quality data annotation with very little annotator training and establish baseline performance levels for the task.,1 Introduction,[0],[0]
"We hired non-expert, part-time annotators on Upwork (previously oDesk) to label over 3,000 sentences (nearly 8,000 verbs) across two domains
2Questions starting with a wh-word, such as who, what, when, how, etc.
(newswire and Wikipedia) at a cost of approximately $0.50 per verb.",1 Introduction,[0],[0]
"We show that the data is high quality, rivaling PropBank in many aspects including coverage, and easily gathered in nonnewswire",1 Introduction,[0],[0]
domains.3,1 Introduction,[0],[0]
"The baseline performance levels for question generation and answering reinforce the quality of the data and highlight the potential for future work on this task.
",1 Introduction,[0],[0]
"In summary, our contributions are:
• We introduce the task of question-answer driven semantic role labeling (QA-SRL), by using question-answer pairs to specify verbal arguments and the roles they play, without predefining an inventory of frames or semantic roles.
",1 Introduction,[0],[0]
"• We present a novel, lightweight templatebased scheme (Section 3) that enables the high quality QA-SRL data annotation with very little training and no linguistic expertise.
",1 Introduction,[0],[0]
"• We define two new QA-SRL sub-tasks, question generation and answer identification, and present baseline learning approaches for both (Sections 4 and 5).",1 Introduction,[0],[0]
The results demonstrate that our data is high-quality and supports the study of better learning algorithms.,1 Introduction,[0],[0]
"The success of syntactic annotation projects such as the Penn Treebank (Marcus et al., 1993) has led to numerous efforts to create semantic annotations for large corpora.",2 Related Work,[0],[0]
"The major distinguishing features of our approach are that it is not tied to any linguistic theory and that it can be annotated by non-experts with minimal training.
",2 Related Work,[0],[0]
Existing SRL task formulations are closely related to our work.,2 Related Work,[0],[0]
"FrameNet (Baker et al., 1998) contains a detailed lexicon of verb senses and thematic roles.",2 Related Work,[0],[0]
"However, this complexity increases the difficulty of annotation.",2 Related Work,[0],[0]
"While the FrameNet project is decades old, the largest fully annotated corpus contains about 3,000 sentences (Chen et al., 2010).",2 Related Work,[0],[0]
"We were able to annotate over 3,000 sentences within weeks.",2 Related Work,[0],[0]
"PropBank (Kingsbury and Palmer, 2002), NomBank (Meyers et al., 2004) and OntoNotes (Hovy et al., 2006) circumvent the need for a large lexicon of roles, by defin-
3Our hope is that this approach will generalize not only across different domains in English, as we show in this paper, but also to other languages.",2 Related Work,[0],[0]
"We will leave those explorations to future work.
",2 Related Work,[0],[0]
ing the core semantic roles in a predicate-specific manner.,2 Related Work,[0],[0]
"This means that frames need to be created for every verb, and it requires experts to distinguish between different senses and different roles.
",2 Related Work,[0],[0]
"Our work is also related to recent, more general semantic annotation efforts.",2 Related Work,[0],[0]
"Abstract Meaning Representation (Banarescu et al., 2013) can be viewed as an extension of PropBank with additional semantic information.",2 Related Work,[0],[0]
"Sentences take 8- 13 minutes to annotate—which is slower than ours, but the annotations are more detailed.",2 Related Work,[0],[0]
"Universal Cognitive Conceptual Annotation (UCCA) (Abend and Rappoport, 2013) is an attempt to create a linguistically universal annotation scheme by using general labels such as argument or scene.",2 Related Work,[0],[0]
"The UCCA foundational layer does not distinguish semantic roles, so Frogs eat herons and Herons eat frogs will receive identical annotation — thereby discarding information which is potentially useful for translation or question answering.",2 Related Work,[0],[0]
"They report similar agreement with Prop-
Bank to our approach (roughly 90%), but annotator training time was an order-of-magnitude higher (30-40 hours).",2 Related Work,[0],[0]
"The Groningen Meaning Bank (Basile et al., 2012) project annotates text by manually correcting the output of existing semantic parsers.",2 Related Work,[0],[0]
"They show that some annotation can be crowdsourced using “games with a purpose” — however, this does not include its predicateargument structure, which requires expert knowledge of their syntactic and semantic formalisms.",2 Related Work,[0],[0]
"Finally, Reisinger et al. (2015) study crowdsourcing semantic role labels based on Dowty’s protoroles, given gold predicate and argument mentions.",2 Related Work,[0],[0]
"This work directly complements our focus on labeling predicate-argument structure.
",2 Related Work,[0],[0]
"The idea of expressing the meaning of natural language in terms of natural language is related to natural logic (MacCartney and Manning, 2007), in which they use natural language for logical inference.",2 Related Work,[0],[0]
"Similarly, we model predicate-argument structure of a sentence with a set of question-
answer pairs.",2 Related Work,[0],[0]
"While existing work on natural logic has relied on small entailment datasets for training, our method allows practical large-scale annotation of training data.
",2 Related Work,[0],[0]
"Parser evaluation using textual entailment (Yuret et al., 2010) is a method for evaluating syntactic parsers based on entailment examples.",2 Related Work,[0],[0]
"In a similar spirit to our work, they abstract away from linguistic formalisms by using natural language inference.",2 Related Work,[0],[0]
"We focus on semantic rather than syntactic annotation, and introduce a scalable method for gathering data that allows both training and evaluation.",2 Related Work,[0],[0]
Stern and Dagan (2014) applied textual entailment to recognize implicit predicate-argument structure that are not explicitly expressed in syntactic structure.,2 Related Work,[0],[0]
"This section describes our annotation process in more detail, and discusses agreement between our annotations and PropBank.",3 QA-based Semantic Dataset,[0],[0]
Table 1 shows examples provided by non-expert annotators.4,3 QA-based Semantic Dataset,[0],[0]
We annotate verbs with pairs of questions and answers that provide information about predicateargument structure.,3.1 Annotation Task Design,[0],[0]
"Given a sentence s and a verbal predicate v in the sentence, annotators must produce a set of wh-questions that contain v and whose answers are phrases in s.
4Our dataset is freely available at: https://dada.cs.washington.edu/qasrl .
",3.1 Annotation Task Design,[0],[0]
"To speed annotation and simplify downstream processing, we define a small grammar over possible questions.",3.1 Annotation Task Design,[0],[0]
"The questions are constrained with a template with seven fields, q ∈ WH × AUX × SBJ × TRG × OBJ1 × PP × OBJ2, each associated with a list of possible options.",3.1 Annotation Task Design,[0],[0]
Descriptions for each field are shown in Table 2.,3.1 Annotation Task Design,[0],[0]
"The grammar is sufficiently general to capture a wide-range of questions about predicate-argument structure— some examples are given in Table 3.
",3.1 Annotation Task Design,[0],[0]
"The precise form of the question template is a function of the verb v and sentence s, for two of the fields.",3.1 Annotation Task Design,[0],[0]
"For the TRG field, we generate a list of inflections forms of v using the Wiktionary dictionary.",3.1 Annotation Task Design,[0],[0]
"For the PP field, the candidates are all the prepositions that occurred in the sentence s, and some frequently-used prepositions - by, to, for, with, and about.",3.1 Annotation Task Design,[0],[0]
"We also include preposition bigrams (e.g., out for) from s.
Answers are constrained to be a subset of the words in the sentence but do not necessarily have to be contiguous spans.",3.1 Annotation Task Design,[0],[0]
"We also allow questions to have multiple answers, which is useful for annotating graph structured dependencies such as those in examples 3 and 6 in Table 1.",3.1 Annotation Task Design,[0],[0]
"We annotated over 3000 sentences (nearly 8,000 verbs) in total across two domains: newswire (PropBank) and Wikipedia.",3.2 Data Preparation,[0],[0]
Table 4 shows the full data statistics.,3.2 Data Preparation,[0],[0]
"In the newswire domain, we sampled sentences from the English training data of CoNLL-2009 shared task (Hajič et al.,
2009), excluding questions and sentences with fewer than 10 words.",3.2 Data Preparation,[0],[0]
"For the Wikipedia domain, we randomly sampled sentences from the English Wikipedia, excluding questions and sentences with fewer than 10 or more than 60 words.
",3.2 Data Preparation,[0],[0]
"In each sentence, we need to first identify the candidates for verbal predicates.",3.2 Data Preparation,[0],[0]
"In principle, a separate stage of annotation could identify verbs—but for simplicity, we instead used POS-tags.",3.2 Data Preparation,[0],[0]
"We used gold POS-tags for newswire, and predicted POS-tags (using Stanford tagger (Toutanova et al., 2003)) in Wikipedia.",3.2 Data Preparation,[0],[0]
Annotators can choose to skip a candidate verb if they are unable to write questions for it.,3.2 Data Preparation,[0],[0]
Annotators skipped 136 verbs (3%) in Wikipedia data and 50 verbs (1.5%) in PropBank data.,3.2 Data Preparation,[0],[0]
"For annotation, we hired 10 part-time, non-expert annotators from Upwork (previously oDesk) and paid $10 per hour for their work.",3.3 Annotation Process,[0],[0]
The average cost was $0.58 per verb ($1.57 per sentence) for newswire text and $0.45 per verb ($1.01 per sentence) on the Wikipedia domain.,3.3 Annotation Process,[0],[0]
The annotators are given a short tutorial and a small set of sample annotations (about 10 sentences).,3.3 Annotation Process,[0],[0]
Annotators were hired if they showed good understanding of English and our task.,3.3 Annotation Process,[0],[0]
"The entire screening process usually took less than 2 hours.
",3.3 Annotation Process,[0],[0]
"Writing QA pairs for each sentence takes 6 minutes on average for Wikipedia and 9 minutes on newswire, depending on the length and complexity of the sentence and the domain of the text.
",3.3 Annotation Process,[0],[0]
"3.4 Agreement with Gold PropBank Data (CoNLL-2009)
",3.3 Annotation Process,[0],[0]
PropBank is the most widely used annotation of predicate-argument structure.,3.3 Annotation Process,[0],[0]
"While our annotation captures different information from PropBank, it is closely related.",3.3 Annotation Process,[0],[0]
"To investigate the similarity between the annotation schemes, we measured the overlap between the newswire domain
(1241 sentences) of our QA-SRL dataset and the PropBank dataset.
",3.3 Annotation Process,[0],[0]
"For each PropBank predicate that we have annotated with our scheme, we compute the agreement between the PropBank arguments and the QA-SRL answers.",3.3 Annotation Process,[0],[0]
"We ignore modality, reference, discourse and negation roles, as they are outside the scope of our current annotation.",3.3 Annotation Process,[0],[0]
"An annotated answer is judged to match the PropBank argument if either (1) the gold argument head is within the annotated answer span, or (2) the gold argument head is a preposition and at least one of its children is within the answer span.
",3.3 Annotation Process,[0],[0]
"We measure the macro-averaged precision and recall of our annotation against PropBank, with the proportion of our QA-pairs that are match a PropBank relation, and the proportion of PropBank relations covered by our annotation.",3.3 Annotation Process,[0],[0]
"The results are shown in Table 5, and demonstrate high overall agreement with PropBank.",3.3 Annotation Process,[0],[0]
"Agreement for core arguments 5 is especially strong, showing much of the expert linguist annotation in PropBank can be recovered with our simple scheme.",3.3 Annotation Process,[0],[0]
"Agreement for adjuncts is lower, because the annotated QAs often contain inferred roles, especially for why, when and where questions (See examples 4, 7 and 8 in Table 1).",3.3 Annotation Process,[0],[0]
"These inferred roles are typically correct, but outside of the scope of PropBank annotations; they point to exciting opportunities for future work with QA-SRL data.",3.3 Annotation Process,[0],[0]
"On the other hand, the adverbial arguments in PropBank are sometimes neglected by annotators, thus becoming a major source of recall loss.
",3.3 Annotation Process,[0],[0]
Table 6 shows the overlap between our annotated question words and PropBank argument labels.,3.3 Annotation Process,[0],[0]
"There are many unsurprising correlations— who questions are strongly associated with Prop-
5In PropBank, A0-A5 are the core arguments.",3.3 Annotation Process,[0],[0]
"In QASRL, the core arguments include QA pairs with a question that starts with Who or What.
Bank agents (A0), and where and when questions correspond to PropBank temporal and locative roles, respectively.",3.3 Annotation Process,[0],[0]
"Some types of questions are divided much more evenly among PropBank roles, such as How much.",3.3 Annotation Process,[0],[0]
"These cases show how our questions can produce a more easily interpretable annotation than PropBank labels, which are predicate-specific and can be difficult to understand without reference to the frame files.
",3.3 Annotation Process,[0],[0]
"Together, these results suggest that non-experts can annotate much of the information contained in PropBank, and produce a more easily interpretable annotation.",3.3 Annotation Process,[0],[0]
"To judge the reliability of the data, we measured agreement on a portion of the data (100 sentences in the newswire domain and 108 sentences in the
Wikipedia domain) annotated by five annotators.",3.5 Inter-Annotator Agreement,[0],[0]
"Measuring agreement is complicated by the fact that the same question can be asked in multiple ways—for example “Who resigned?” and “Who resigned from something?”—and annotators may choose different, although usually highly overlapping, answer spans.",3.5 Inter-Annotator Agreement,[0],[0]
We consider two QA pairs to be equivalent if (1) they have the same wh-word and (2) they have overlapping answer spans.,3.5 Inter-Annotator Agreement,[0],[0]
"In this analysis, Who and What are considered to be the same wh-word.
",3.5 Inter-Annotator Agreement,[0],[0]
Figure 2 shows how the number of different QA pairs (both overall and agreed) increases with number of annotations.,3.5 Inter-Annotator Agreement,[0],[0]
A QA pair is considered to be agreed upon if it is proposed by at least two of the five annotators.,3.5 Inter-Annotator Agreement,[0],[0]
"After five annotators, the number of agreed QA pairs starts to asymptote.",3.5 Inter-Annotator Agreement,[0],[0]
"A single annotator finds roughly 80% of the agreed QA pairs that are found by five annotators, suggesting that high recall can be achieved with a single stage of annotation.",3.5 Inter-Annotator Agreement,[0],[0]
"To further improve precision, future work should explore a second stage of annotation where annotators check each other’s work, for example by answering each other’s questions.",3.5 Inter-Annotator Agreement,[0],[0]
"Given a sentence s and a target verb v, we want to automatically generate a set of questions containing v that are answerable with phrases from s. This task is important because generating answerable questions requires understanding the predicate-argument structure of the sentence.",4 Question Generation,[0],[0]
"In
essence, questions play the part of semantic roles in our approach.6
We present a baseline that breaks down question generation into two steps: (1) we first use a classifier to predict a set of roles for verb v that are likely present in the sentence, from a small, heuristically defined set of possibilities and then (2) generate one question for each predicted role, using templates extracted from the training set.
",4 Question Generation,[0],[0]
"Mapping Question Fields to Semantic Roles To generate questions, we first have to decide the primary role we want to target; each question’s answer is associated with a specific semantic role.",4 Question Generation,[0],[0]
"For example, given the sentence UCD finished the 2006 championship and target verb finished, we could ask either: (Q1) Who finished something?",4 Question Generation,[0],[0]
or (Q2),4 Question Generation,[0],[0]
What did someone finish?.,4 Question Generation,[0],[0]
"Q1 targets the role associated with the person doing the finishing, while Q2 focuses on the thing being finished.",4 Question Generation,[0],[0]
"To generate high quality questions, it is also often necessary to refer to roles other than the primary role, with pronouns.",4 Question Generation,[0],[0]
"For example, Q2 uses “someone” to refer to the finisher.
",4 Question Generation,[0],[0]
"Although it is difficult to know a priori the ideal set of possible roles, our baseline uses a simple discrete set, and introduces heuristics for identifying the roles a question refers to.",4 Question Generation,[0],[0]
"The roles R include:
R ={R0,R1,R2,R2[p], w, w[p]} w ∈{Where,When,Why,How,HowMuch} p ∈Prepositions
We then normalize the annotated questions by mapping its fields WH, SBJ, OBJ1 and OBJ2 to the roles r ∈ R, using a small set of rules listed in Table 7.",4 Question Generation,[0],[0]
"In our example, the WH field of the Q1 (Who) and the SBJ of Q2 (someone) are both mapped to role R0.",4 Question Generation,[0],[0]
The WH of Q2 (What) and the OBJ1 of Q1 (something) are mapped to role R1.,4 Question Generation,[0],[0]
Some roles can be subclassed with prepositions.,4 Question Generation,[0],[0]
"For example, the WH field of the question What did something rise from? is mapped to R2[from].
",4 Question Generation,[0],[0]
"In most cases, R0 is related to the A0/AGENT roles in PropBank/FrameNet, and R1/R2 are related to A1/PATIENT roles.",4 Question Generation,[0],[0]
"Since our questions are defined in a templated space, we are able to do
6The task also has applications to semi-automatic annotation of sentences with our scheme, if we could generate questions with high enough recall and only require annotators to provide all the answers.",4 Question Generation,[0],[0]
"We leave this important direction to future work.
",4 Question Generation,[0],[0]
this mapping heuristically with reasonable accuracy.,4 Question Generation,[0],[0]
"In the future, we might try to induce the set of possible roles given each target verb, following the semantic role induction work of Titov and Klementiev (2012) and Lang and Lapata (2011), or use crowdsourcing to label proto-roles, following Reisinger et al. (2015).
",4 Question Generation,[0],[0]
"Predicting Question Roles Given this space of possible roles, our first step in generation is to determine which roles are present in a sentence, and select the pronouns that could be used to refer to them in the resulting questions.",4 Question Generation,[0],[0]
We formulate this task as a supervised multi-label learning problem.,4 Question Generation,[0],[0]
"We define the set of possible labels L by combining the roles inR with different pronoun values:
L ={role:val | role ∈ R} val ∈{φ, someone, something, do something,
doing something}
",4 Question Generation,[0],[0]
"For example, to support the generation of the questions Who finished something?",4 Question Generation,[0],[0]
"and What did someone finish?, we need to first predict the labels R0:someone and R1:something.",4 Question Generation,[0],[0]
"Adjunct roles, such as When and How, always take an empty pronoun value.
",4 Question Generation,[0],[0]
"For each sentence s and verb v, the set of positive training samples corresponds to the set of labels in the annotated questions, and the negative samples are all the other labels in Ltrain, the subset of labels appeared in training data.7",4 Question Generation,[0],[0]
"We train a binary classifier for every label in Ltrain using L2regularized logistic regression by Liblinear (Fan et al., 2008), with hyper-parameter C = 0.1.",4 Question Generation,[0],[0]
Features of the binary classifiers are listed in Table 10.,4 Question Generation,[0],[0]
"For each sentence s and verb v in the test data, we take the k highest-scoring labels, and generate questions from these.
",4 Question Generation,[0],[0]
"Question Generation After predicting the set of labels for a verb, we generate a question to query each role.",4 Question Generation,[0],[0]
"First, we define the concept of an abstract question, which provides a template that specifies the role to be queried, other roles to include in the question, and the voice of the verb.",4 Question Generation,[0],[0]
"Abstract questions can be read directly from our training data.
",4 Question Generation,[0],[0]
We can map an abstract question to a surface realization by substituting the slots with the pronoun values of the predicted labels.,4 Question Generation,[0],[0]
"Table 8 shows the abstract questions we could use to query roles R0 and R1; and the generated questions, based on the set of predicted labels {R0:someone,R1:something}.
",4 Question Generation,[0],[0]
"Therefore, to generate a question to query a role r ∈ R, we simply return the most frequent abstract question that occurred in training data that matches the role being queried, and the set of other predicted labels.
",4 Question Generation,[0],[0]
Experiments Native English speakers manually evaluated 500 automatically generated questions (5 questions per verb).,4 Question Generation,[0],[0]
"Annotators judged whether the questions were grammatical 8 and answerable from the sentence.
",4 Question Generation,[0],[0]
"We evaluated the top k questions produced by
7We pruned the negative samples that contain prepositions that are not in the sentence or in the set of frequently-used prepositions (by, to, for, with, about).
",4 Question Generation,[0],[0]
"8Some automatically generated questions are ungrammatical because of label prediction errors, such as Who sneezed someone?, where the label R1:someone shouldn’t be predicted.
",4 Question Generation,[0],[0]
our baseline technique.,4 Question Generation,[0],[0]
The results in Table 9 show that our system is able to produce questions which are both grammatical and answerable.,4 Question Generation,[0],[0]
"The average number of QA pairs per verb collected by human annotator is roughly 2.5, demonstrating significant room for improving these results.",4 Question Generation,[0],[0]
"The goal of the answer identification task is to predict an answer a given sentence s, target verb v and a question q.",5 Answer Identification,[0],[0]
"Our annotated answers can be a series of spans, so the space of all possible answers is 2|s|.",5 Answer Identification,[0],[0]
"To simplify the problem, we transform our span-based answer annotation to answer head words, thus reducing the answer space to |s|.",5 Answer Identification,[0],[0]
"We model whether a word is the head of an answer as a binary classification problem.
",5 Answer Identification,[0],[0]
"Each training sample is a tuple 〈s, v, q, a,±1〉.",5 Answer Identification,[0],[0]
The answer head a is extracted from the k-best dependency parses and the annotated answer span.,5 Answer Identification,[0],[0]
"Given a dependency tree, if any word in the annotated answer span has a parent coming from outside the span, then it is considered an answer head.",5 Answer Identification,[0],[0]
"Therefore, a gold question-answer pair can be transformed into multiple positive training samples.",5 Answer Identification,[0],[0]
The negative samples come from all the words in the sentence that are not an answer head.,5 Answer Identification,[0],[0]
"For learning, we train a binary classifier for every word in the sentence (except for the verb v).
",5 Answer Identification,[0],[0]
"Experiments We use L2-regularized logistic regression by Liblinear (Fan et al., 2008) for binary classification.",5 Answer Identification,[0],[0]
"Features are listed in Table 10.
",5 Answer Identification,[0],[0]
The performance of our answer identification approach is measured by accuracy.,5 Answer Identification,[0],[0]
"For evaluation, given each test sentence s, verb v and question q, we output the word with highest predicted score using the binary classifier.",5 Answer Identification,[0],[0]
"If the predicted word is contained inside the annotated answer span, it is considered a correct prediction.",5 Answer Identification,[0],[0]
"We also use the
baseline method that predicts a random syntactic child from the 1-best parse for each question.
",5 Answer Identification,[0],[0]
"In each of the two domains, we train the binary classifiers on the training set of that domain (See Table 4 for dataset size).",5 Answer Identification,[0],[0]
Table 11 shows experiment results for answer identification.,5 Answer Identification,[0],[0]
"Our classifier-based method outputs a correct answer head for 80% of the test questions, establishing a useful baseline for future work on this task.",5 Answer Identification,[0],[0]
"We introduced the task of QA-SRL, where question-answer pairs are used to specify predicate-argument structure.",6 Discussion and Future Work,[0],[0]
"We also presented a scalable annotation approach with high coverage, as compared to existing SRL resources, and introduced baselines for two core QA-SRL subtasks: question generation and answering.
",6 Discussion and Future Work,[0],[0]
Our annotation scheme has a number of advantages.,6 Discussion and Future Work,[0],[0]
"It is low cost, easily interpretable, and can be performed with very little training and no linguistic expertise.",6 Discussion and Future Work,[0],[0]
"These advantages come, in large part, from the relatively open nature of the QASRL task, which does not depend on any linguistic theory of meaning or make use of any frame or role ontologies.",6 Discussion and Future Work,[0],[0]
"We are simply using natural language to annotate natural language.
",6 Discussion and Future Work,[0],[0]
"Although we studied verbal predicate-argument structure, there are significant opportunities for future work to investigate annotating nominal and adjectival predicates.",6 Discussion and Future Work,[0],[0]
"We have also made few language-specific assumptions, and believe the annotation can be generalized to other languages— a major advantage over alternative annotation
schemes that require new lexicons to be created for each language.
",6 Discussion and Future Work,[0],[0]
The biggest challenge in annotating sentences with our scheme is choosing the questions.,6 Discussion and Future Work,[0],[0]
"We introduced a method for generating candidate questions automatically, which has the potential to enable very large-scale annotation by only asking the annotators to provide answers.",6 Discussion and Future Work,[0],[0]
"This will only be possible if performance can be improved to the point where we achieve high recall question with acceptable levels of precision.
",6 Discussion and Future Work,[0],[0]
"Finally, future work will also explore applications of our annotation.",6 Discussion and Future Work,[0],[0]
"Most obviously, the annotation can be used for training question-answering systems, as it directly encodes question-answer pairs.",6 Discussion and Future Work,[0],[0]
"More ambitiously, the annotation has the potential to be used for training parsers.",6 Discussion and Future Work,[0],[0]
"A joint syntactic and semantic parser, such as that of Lewis et al. (2015), could be trained directly on the annotations to improve both the syntactic and semantic models, for example in domain transfer settings.",6 Discussion and Future Work,[0],[0]
"Alternatively, the annotation could be used for active learning: we envisage a scheme where parsers, when faced with ambiguous attachment decisions, can generate a human-readable question whose answer will resolve the attachment.",6 Discussion and Future Work,[0],[0]
"This research was supported in part by the NSF (IIS-1252835), DARPA under the DEFT program through the AFRL (FA8750-13-2-0019), an Allen Distinguished Investigator Award, and a gift from Google.",Acknowledgments,[0],[0]
"We are grateful to Kenton Lee and Mark Yatskar for evaluating the question generation task, and Eunsol Choi, Yejin Choi, Chloé Kiddon, Victoria Lin, and Swabha Swayamdipta for their helpful comments on the paper.",Acknowledgments,[0],[0]
We would also like to thank our freelance workers on oDesk/Upwork for their annotation and the anonymous reviewers for their valuable feedback.,Acknowledgments,[0],[0]
"This paper introduces the task of questionanswer driven semantic role labeling (QA-SRL), where question-answer pairs are used to represent predicate-argument structure.",abstractText,[0],[0]
"For example, the verb “introduce” in the previous sentence would be labeled with the questions “What is introduced?”, and “What introduces something?”, each paired with the phrase from the sentence that gives the correct answer.",abstractText,[0],[0]
"Posing the problem this way allows the questions themselves to define the set of possible roles, without the need for predefined frame or thematic role ontologies.",abstractText,[0],[0]
It also allows for scalable data collection by annotators with very little training and no linguistic expertise.,abstractText,[0],[0]
"We gather data in two domains, newswire text and Wikipedia articles, and introduce simple classifierbased models for predicting which questions to ask and what their answers should be.",abstractText,[0],[0]
"Our results show that non-expert annotators can produce high quality QA-SRL data, and also establish baseline performance levels for future work on this task.",abstractText,[0],[0]
Question-Answer Driven Semantic Role Labeling: Using Natural Language to Annotate Natural Language,title,[0],[0]
"The recent “reproducibility crisis” (Baker, 2016) in various scientific fields (particularly Psychology and Social Sciences) indicates that some introspection is needed in all fields, particularly those that are experimental by nature.",1 Introduction,[0],[0]
"The efforts of Collberg’s repeatability studies highlight the state of affairs within the computer systems research community (Moraila et al., 2014; Collberg et al., 2015).1 Other fields have also begun to push for more stringent presentation of
1http://reproducibility.cs.arizona.edu
results, for example, the information retrieval community has been aware for some time of the issues surrounding weak baselines (Armstrong et al., 2009) and more recently reproducibility (Arguello et al., 2016; Lin et al., 2016).
",1 Introduction,[0],[0]
"The issue of reproducibility in the deep-learning community has also started to become a growing concern, with the need for replicable and reproducible results being included in a list of challenges for the ACL (Nivre, 2017).",1 Introduction,[0],[0]
"In reinforcement learning, Henderson et al. (2017) showed that there are a number of effects that would change the results obtained by published authors and call for more rigorous testing, and reporting, of state-of-the-art methods.",1 Introduction,[0],[0]
"There is also an ongoing project by OpenAI to provide baselines in reinforcement learning that are reproduced from published descriptions, but even they admit that their scores are only “roughly on par with the scores in published papers.”2",1 Introduction,[0],[0]
"Reimers and Gurevych (2017) investigated over 50,000 combinations of hyper-parameter settings, such as word embedding sources and the optimizer across five different NLP tasks and found that these settings have a significant impact on both the variability, and the relative effectiveness of models.
",1 Introduction,[0],[0]
"In this paper we present a number of controllable environment settings that often go unreported, and illustrate that these are factors that can cause irreproducibility of results as presented in the literature.",1 Introduction,[0],[0]
"These environmental factors have an effect on the effectiveness of neural networks due to the nonconvexity of the optimization surface, meaning that
2https://blog.openai.com/openaibaselines-dqn/
241
Transactions of the Association for Computational Linguistics, vol. 6, pp. 241–252, 2018.",1 Introduction,[0],[0]
Action Editor: Brian Roark.,1 Introduction,[0],[0]
"Submission batch: 9/2017; Revision batch: 12/2017; Published 4/2018.
",1 Introduction,[0],[0]
c©2018 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
",1 Introduction,[0],[0]
even minor changes in computation can lead the network to fall into one of a multitude of local minima.,1 Introduction,[0],[0]
"Because these effect sizes are comparable to the largest incremental improvements that have been reported brings into question those improvements, and associated claims of progress.",1 Introduction,[0],[0]
"In order to limit the scope of this paper, we specifically focus our efforts on a single natural language processing task—answer selection within question answering—elaborated upon in Section 2.1.",2 Experimental Setup,[0],[0]
"We also further limit our discussion to look at how these environmental effects manifest in a single implementation of a single model, described in Section 2.2.",2 Experimental Setup,[0],[0]
"These restrictions, however, do not mean that our results are only applicable to this model on this task, rather our discussion generalizes to all neural network based research.
",2 Experimental Setup,[0],[0]
"To isolate the effect that each environmental factor has all other settings related to the network are fixed; that is, the hyper-parameters are static across all experiments, and only the environmental variable of interest is manipulated.",2 Experimental Setup,[0],[0]
"Along with each of the presented factors we include suggestions on how to respond to these in order to best ensure that the work, as presented, is reproducible.",2 Experimental Setup,[0],[0]
Answer selection is one important aspect of opendomain question answering.,2.1 Exemplar Task,[0],[0]
"Given a question, q, and a set of candidate sentences, A, the answer selection task is to rank the sentences contained in A such that those candidates that answer the question are ranked at the top of the list.",2.1 Exemplar Task,[0],[0]
"From this ranked list and assessments of whether the candidate contains an answer to the question, common information retrieval metrics average precision (AP) and reciprocal rank (RR) can be calculated to assess the effectiveness of the system.",2.1 Exemplar Task,[0],[0]
"These metrics are the de facto metrics to evaluate answer selection, and as such the metrics are reported within this paper.",2.1 Exemplar Task,[0],[0]
"Descriptions of these metrics are easily found in the literature.
",2.1 Exemplar Task,[0],[0]
"Worryingly, in the literature, it is becoming increasingly common to not conduct statistical significance testing, rather a higher metric value is taken as evidence that the model performs better.",2.1 Exemplar Task,[0],[0]
"Due to
the nature of this paper, we only perform significance testing between results in the same condition, and not across conditions.",2.1 Exemplar Task,[0],[0]
Within each condition we identify a “baseline”/default setting to compare against.,2.1 Exemplar Task,[0],[0]
"Conducting this many significance tests would normally call for a correction method to be applied, but we do not do so, as we only wish to indicate that selecting the higher number may result in an absolute difference, but not necessarily a statistically significantly one.",2.1 Exemplar Task,[0],[0]
To calculate significance we use a paired Wilcoxon signed rank test.,2.1 Exemplar Task,[0],[0]
"To perform our experiments we utilize the model released by Sequiera et al. (2017), a simplified PyTorch implementation of the model proposed by Severyn and Moschitti (2015).",2.2 Exemplar Model,[0],[0]
"The model was chosen because of its simplicity, it is quick to train which supports a fast iteration of experiments, and it has also been reimplemented with similar effectiveness additional times (Rao et al., 2017).",2.2 Exemplar Model,[0],[0]
"Figure 1 shows a diagram of the model, which adopts a “Siamese” structure with two sub-networks to process the question and candidate sentence.
",2.2 Exemplar Model,[0],[0]
We emphasize that this model was only selected to serve as an exemplar; the effects that are observed in relative performance will also be present in other models.,2.2 Exemplar Model,[0],[0]
"Indeed, because of the simplicity of this model, it is likely that the environmental effects described will have a more substantial impact on the network effectiveness of more complicated models.",2.2 Exemplar Model,[0],[0]
"The experiments reported in this paper are all performed against the TrecQA dataset that was first released by Wang et al. (2007) and further elab-
orated upon by Yao et al. (2013), as well as the WikiQA dataset released by Yang et al. (2015).",2.3 Datasets,[0],[0]
"Both datasets consists of pre-determined training, development and test sets.",2.3 Datasets,[0],[0]
"For each question, each candidate answer is labelled positive if it contains the answer to the question, otherwise negative.",2.3 Datasets,[0],[0]
"The ratios of these labels and size of the splits for both datasets are shown in Table 1.
",2.3 Datasets,[0],[0]
"The TrecQA dataset has further diverged into two versions, named RAW and CLEAN.",2.3 Datasets,[0],[0]
The CLEAN version has removed those questions that had no positive labelled answers.,2.3 Datasets,[0],[0]
"Results on these two variants are not directly comparable to each other (Rao et al., 2017), and experiments in this paper are performed against the RAW variant.",2.3 Datasets,[0],[0]
"Similar manipulation of the WikiQA dataset has also been performed, although no analysis of the comparability of the results has been conducted.",2.3 Datasets,[0],[0]
"As observed by Armstrong et al. (2009) in the information retrieval field, the use of weak baselines is a factor that should be considered when discussing results as using a weak baseline shows a greater improvement than could otherwise be claimed.",3 Weak Baselines,[0],[0]
"Table 2 shows the state-of-the-art results in answer selection, as replicated from the ACL Wiki, Table 3 likewise shows the (potentially incomplete) state-ofthe-art results on the WikiQA dataset, sourced by inspection of relevant papers.",3 Weak Baselines,[0],[0]
"The TrecQA dataset contains an additional row that presents a simple baseline—the sum of IDF weights for terms in both
the question and candidate sentence—that performs no learning of any sort.
",3 Weak Baselines,[0],[0]
"Sq,a = ∑
t∈q∩a log
|D| |{d ∈ D",3 Weak Baselines,[0],[0]
:,3 Weak Baselines,[0],[0]
"t ∈ d}| (1)
",3 Weak Baselines,[0],[0]
"Equation 1 shows the function that produces these results, where D is the document collection, d is a document from this collection, q is the query, a is the candidate sentence, and t is a term.",3 Weak Baselines,[0],[0]
This calculation is done after removal of stopwords.3 This baseline outperforms a number of the older stateof-the-art methods.,3 Weak Baselines,[0],[0]
"Therefore these older results, and some results afterwards are comparing against a weak baseline.",3 Weak Baselines,[0],[0]
"In fairness, this baseline was first reported in the literature by Yih et al. (2013), but is
3The stopword list contains 127 English words, sourced from the nltk",3 Weak Baselines,[0],[0]
"Python Library.
",3 Weak Baselines,[0],[0]
a result that is frequently overlooked in the literature that followed.,3 Weak Baselines,[0],[0]
"However, we also note that the results for this simple baseline differ between our reported value and that of Yih et al. (2013), which is substantially lower—0.6531 AP, 0.7071 RR.",3 Weak Baselines,[0],[0]
For these reasons we repeat this result here.,3 Weak Baselines,[0],[0]
"In this section we document a number of confounding variables that often go unreported in the literature, and can have a substantial effect on whether a result would be considered state-of-the-art or not, and the reproducibility of that result.",4 Confounding Variables,[0],[0]
"These range from controllable factors, to factors that are not controllable, but need to be reported.",4 Confounding Variables,[0],[0]
"To aid discussion, the state-of-the-art tables have been recreated and annotated with the change in AP and RR over the then state-of-the-art result (Table 2 and Table 3).
",4 Confounding Variables,[0],[0]
"Unless otherwise stated, all experiments are performed using Docker containers that are derived from common, shared, base images.",4 Confounding Variables,[0],[0]
This substantially eases the fixing of all environment and versioning issues that can be observed when running under a native environment.,4 Confounding Variables,[0],[0]
All the data that is required to reproduce the results in this paper is publicly available.,4 Confounding Variables,[0],[0]
"Including Docker images, scripts to create and use those images, and",4 Confounding Variables,[0],[0]
"resulting pretrained model files.4
4https://github.com/snapbug/ questionable-qa",4 Confounding Variables,[0],[0]
There are numerous points of software in which the version of the software being used can impact the end results substantially.,4.1 Software Versions,[0],[0]
"These are the model definitions, they framework software and the libraries that the framework uses.",4.1 Software Versions,[0],[0]
We refer to the code that is used to define the model and to run the experiments as the model definition.,4.1.1 Model Definition,[0],[0]
"These are changing artifacts, and when the software is made available to researchers, then it must be accompanied by the version of that software being used.",4.1.1 Model Definition,[0],[0]
A cursory glance of the commit history of some of these repositories shows a non-zero amount of bug fixing commits.,4.1.1 Model Definition,[0],[0]
"Because of the nature of deep learning, these bugs may actually improve effectiveness, as anecdotal evidence suggests.5
Whether the commits fix bugs or add features, the models being compared are inherently different and can result in different outcomes.",4.1.1 Model Definition,[0],[0]
Authors should specify which version of the code is being run to obtain the results presented.,4.1.1 Model Definition,[0],[0]
"Table 4 shows the effect
5https://twitter.com/soumithchintala/ status/910339781019791360
of changing the version of the code on the model’s effectiveness.",4.1.1 Model Definition,[0],[0]
"As can be seen, there is a reasonable shift in results, and until authors specify the exact version of the model that is used for experimentation their results are non-reproducible.",4.1.1 Model Definition,[0],[0]
The version used for all further experiments in this paper is cf0e269.,4.1.1 Model Definition,[0],[0]
Specifying the framework that is being used would be an important first step.,4.1.2 Framework Version,[0],[0]
Different framework versions could give different results for the same model code.,4.1.2 Framework Version,[0],[0]
"To illustrate this we ran the sample model over a range of different versions of PyTorch.
",4.1.2 Framework Version,[0],[0]
Table 5 shows the impact of changing the version of PyTorch used in the training of the sample model.,4.1.2 Framework Version,[0],[0]
"It shows that newer (0.2.0) is not necessarily better, although this depends on the dataset.",4.1.2 Framework Version,[0],[0]
"The version used throughout the rest of the paper is 0.1.12, as this is the version that was used in prior work for this model.",4.1.2 Framework Version,[0],[0]
Version 0.1.8 and earlier would not run the sample model due to use of features introduced in 0.1.9.,4.1.2 Framework Version,[0],[0]
The results are stable for 0.1.x versions across datasets.,4.1.2 Framework Version,[0],[0]
One possible cause could be that the underlying libraries PyTorch relies on were pinned to specific versions across PyTorch versions.,4.1.2 Framework Version,[0],[0]
"Alternatively, the model code may not be using features of PyTorch that were changing across these versions.",4.1.2 Framework Version,[0],[0]
"While fixing the framework version is a good step, these frameworks often themselves rely on other libraries.",4.1.3 Framework Dependencies,[0],[0]
"Of particular interest to the neural network
community is the math library that underpins all the matrix and vector operations.",4.1.3 Framework Dependencies,[0],[0]
By default PyTorch installs a version of the library that is linked against Intel’s Math Kernel Library (MKL).,4.1.3 Framework Dependencies,[0],[0]
"When running the sample model on different hardware, we identify the effectiveness of the model changes.
",4.1.3 Framework Dependencies,[0],[0]
"Table 6 shows the results of running the MKLbacked version on Intel and AMD hardware, compared to an OpenBLAS, which results in the same answers regardless of hardware.",4.1.3 Framework Dependencies,[0],[0]
"Intel also notes that the results of the same floating point calculation may be different across their own hardware.6 It should not surprise the reader that Intel’s math library gives different results on different architectures; after all, Intel knows with great detail the architecture of Intel chipsets and is not necessarily inclined to produce optimal code for competing platforms.",4.1.3 Framework Dependencies,[0],[0]
The sensitivity of the network to the backing math library is dependent on the dataset.,4.1.3 Framework Dependencies,[0],[0]
"This difference in effectiveness is likely due to the relative non-convexity of the optimization surface for the two datasets, where the TrecQA surface has a large number of local minima.
",4.1.3 Framework Dependencies,[0],[0]
"Changing the library, or even the backend, within the same library, in which the model is implemented can substantially change the effectiveness of the model.",4.1.3 Framework Dependencies,[0],[0]
"For example Simon (2017) observed a 16% increase of test accuracy for the same model (from 0.5438 to 0.6197) by changing the computation backend from Tensorflow to MXNet.
6http://intel.ly/1b8Qrq6",4.1.3 Framework Dependencies,[0],[0]
"Threading introduces a number of possibilities for non-reproducible results, as results from threads can be returned in differing orders.",4.2 Threads,[0],[0]
"This is because floating point arithmetic is non-associative as well as non-commutative; however, these effects can be controlled by using the appropriate functions and settings in the library.",4.2 Threads,[0],[0]
"Training the sample model repeatedly achieves the same results, suggesting that these settings are being utilized inside the PyTorch library, although we implore readers to discover this for their library of choice.
",4.2 Threads,[0],[0]
"However, while threading itself does not impact the results within PyTorch, the number of threads used does.",4.2 Threads,[0],[0]
"Other than by never varying the number of threads used, this effect cannot be controlled for.",4.2 Threads,[0],[0]
The reason for this is related to the non-associativity of floating point maths.,4.2 Threads,[0],[0]
"For example, given the mathematical relations a + b = e, and c + d = f , the floating point specification does not ensure that the mathematical equality a + b + c + d = e + f holds.",4.2 Threads,[0],[0]
"A result calculated on two threads may perform the e+ f calculation, while on four threads the a+b+c+d calculation may be performed, resulting in potential differences.
",4.2 Threads,[0],[0]
For these experiments we use PyTorch v0.1.12 with Intel’s MKL library on an Intel i7-6800K processor.,4.2 Threads,[0],[0]
"Using the OMP_NUM_THREADS and MKL_NUM_THREADS environment variables, as well as the set_num_threads function in PyTorch, we can control the number of threads used in training.",4.2 Threads,[0],[0]
"We range this from 1–6 on our machine, as this is the number of hardware cores on the CPU, and therefore the maximum number of threads that
OpenMP will spawn.",4.2 Threads,[0],[0]
Table 7 shows the results of this experiment.,4.2 Threads,[0],[0]
"Interestingly the results are consistent within datasets when using an odd number of threads, although this is most likely coincidental.",4.2 Threads,[0],[0]
"The range of differences is small, but is, again, larger than some of the incremental improvements reported in the literature.",4.2 Threads,[0],[0]
"The exact environment variables, or code settings, that need to be modified will depend on the framework being used.
",4.2 Threads,[0],[0]
There is no solution to this given the nonassociative nature of the floating-point and the splitting of workload among differing numbers of threads.,4.2 Threads,[0],[0]
"The only recommendation is that authors report the number of threads used for training, although we do suggest a smaller number to err on the side of caution, as OpenMP will not create more threads than there are hardware cores.",4.2 Threads,[0],[0]
The variation of GPUs available for deep learning research is arguably larger than that of CPUs.,4.3 GPU Computation,[0],[0]
"There are many models, and each manufacturer is free to deviate from the reference models provided by nVidia or AMD, although it is unclear just how many choose to do so.",4.3 GPU Computation,[0],[0]
"There are also more uncontrollable factors, for instance, the number of threads that are used by the GPU is uncontrollable meaning that results are unlikely to be the same across different GPUs, unlike CPU training.
",4.3 GPU Computation,[0],[0]
Table 8 shows the results of enabling GPU computation on the sample model.,4.3 GPU Computation,[0],[0]
"We report on both enabling the cuDNN backend, as this is the default, as well as disabling it globally.",4.3 GPU Computation,[0],[0]
"The cuDNN backend is known to contain some non-deterministic kernels.7 In addition, nVidia provides a white-paper that describes some of the implementation details and compliance issues of the IEEE 754 floating point specification and their impact on nVidia GPUs (Whitehead and Fit-Florea, 2011).",4.3 GPU Computation,[0],[0]
"The paper also presents examples where compiling for a 32-bit x86 architecture and a 64-bit x86-64 architecture can yield different results.
",4.3 GPU Computation,[0],[0]
"In addition to running the experiment on our own GPU, an Asus branded nVidia GeForce 1080GTX (revision a1)",4.3 GPU Computation,[0],[0]
"we also repeated the experiment on
7http://docs.nvidia.com/deeplearning/sdk/ cudnn-developer-guide/#reproducibility
an Amazon EC2 p2.xlarge instance.",4.3 GPU Computation,[0],[0]
This instance comes equipped with a single nVidia Tesla K80 GPU.,4.3 GPU Computation,[0],[0]
"Other instances come equipped with multiple GPUs, but as the model is both small and does not take advantage of multiple GPUs experiments were not performed on these instances.",4.3 GPU Computation,[0],[0]
"Of note is the presence or absence of the cuDNN library has no effect on the K80, but does on the 1080GTX GPU.",4.3 GPU Computation,[0],[0]
"We suspect that the reason for this is that the K80 is designed as a compute card, while the 1080GTX is primarily designed for graphics processing.",4.3 GPU Computation,[0],[0]
"This design difference could manifest itself in different instructions that can be taken advantage of by cuDNN kernels.
",4.3 GPU Computation,[0],[0]
"Even with just two GPUs and using the cuDNN backend, there is already evidence that the performance of the network depends on both the dataset and the underlying hardware.",4.3 GPU Computation,[0],[0]
There is a clear dependence on the dataset for the relative performance.,4.3 GPU Computation,[0],[0]
Further results reported on the GPU are reported on the GeForce 1080GTX with cuDNN disabled.,4.3 GPU Computation,[0],[0]
Although this is not the default it maximizes reproducibility by avoiding non-reproducible kernels.,4.3 GPU Computation,[0],[0]
Perhaps the most obvious feature of machine learning that can impact the effectiveness is the random seed.,4.4 Random Seed,[0],[0]
"Thus far the experiments in this paper have used a fixed seed, and like most prior research this was only implied rather than explicitly stated.",4.4 Random Seed,[0],[0]
"The seed in question was 1234.
",4.4 Random Seed,[0],[0]
Randomness is a crucial part of machine learning and values from the random generator are widely used.,4.4 Random Seed,[0],[0]
"For example, random values are used for the
initial values of weights, for selecting which nodes to drop in drop-out layers, and for selecting set embeddings for terms that have no associated embeddings.",4.4 Random Seed,[0],[0]
"As Goldberg (2017, Section 5.3.2 p59) rightly makes note of—“When debugging, and for reproducibility of results [emphasis added], it is advised to used a fixed random seed.”",4.4 Random Seed,[0],[0]
"Figure 2 shows the variance in AP and RR when specifying different seeds, for 200 randomly chosen seeds (selected using the bash (version 4.3.48(1))",4.4 Random Seed,[0],[0]
"RANDOM built-in, itself initialized/seeded to 1234 prior to performing runs).
",4.4 Random Seed,[0],[0]
"Noting the generator of the random numbers is important, as different languages and libraries may use different generators.",4.4 Random Seed,[0],[0]
"Most languages default to a pseudo-random generator for performance reasons, which carries the additional benefit that sequences can be reconstructed from a given start state, commonly referred to as a seed.",4.4 Random Seed,[0],[0]
"For example, the bash version used to generate the seeds for Figure 2 uses a linear congruential generator (Park and Miller, 1988).",4.4 Random Seed,[0],[0]
"A more commonly used generator is MT19937, a Mersenne Twister based on the Mersenne prime 219937",4.4 Random Seed,[0],[0]
"− 1, the standard implementation that uses a 32-bit word length.",4.4 Random Seed,[0],[0]
"Another implementation, MT19937-64, uses a 64-bit word length and generates a different sequence.",4.4 Random Seed,[0],[0]
To specify the generator used it is often enough to specify the language version and platform being used.,4.4 Random Seed,[0],[0]
"PyTorch and dependent libraries use the aforementioned MT19937 generator.
",4.4 Random Seed,[0],[0]
"The spread of results shows that the results are either marginally worse than prior work (which would likely mean the result from this model would not be
published), or better than work that was reported on afterward (meaning these latter results may not have been published).",4.4 Random Seed,[0],[0]
"Significance testing across these models was not performed.
",4.4 Random Seed,[0],[0]
"Table 9 shows the agreements, calculated using Kendall’s τ and Spearman’s ρ, on rankings for each of the datasets, comparing the two metrics, and two computational backends used, all results shown are statistically significant at the p < 0.01 level.
",4.4 Random Seed,[0],[0]
"On the TrecQA dataset, these variations in AP and RR show only moderate agreement in rankings of the model when the same training computational backend is used, and only weak agreement across computation backend.",4.4 Random Seed,[0],[0]
"For the TrecQA dataset, the CPU results covered a range of 0.0393 for AP, and 0.0599 for RR, while the GPU covered 0.0379 AP, and 0.0492 RR respectively.
",4.4 Random Seed,[0],[0]
"The WikiQA dataset exhibits stronger agreements about model rankings on the same computation
backend, but similarly weak agreements when comparing across computational backends.",4.4 Random Seed,[0],[0]
"The range of AP and RR values on this dataset are even larger, covering 0.0712 AP, and 0.0727 RR on GPU; and 0.0705 AP and 0.0755 RR on the CPU.
",4.4 Random Seed,[0],[0]
"These ranges in AP and RR values are greater than a large proportion of incremental improvements reported in prior answer selection research (see Table 2 and Table 3), and indeed are an order of magnitude larger than a typically reported improvement in either metric on the WikiQA datasets.",4.4 Random Seed,[0],[0]
"In these cases the model was trained to target AP, another setting that is not commonly reported.",4.4 Random Seed,[0],[0]
"While some software for models made available specifies a seed, this detail is often omitted from the paper, making replication-from-paper efforts nigh on impossible.
",4.4 Random Seed,[0],[0]
"Reagen et al. (2017, Chapter 4) discuss this variance in results from seeding, calling it Iso-Training Noise.",4.4 Random Seed,[0],[0]
"They use this concept to frame discus-
sion over whether optimizations, such as using fixed point arithmetic over floating point, are safe to perform.",4.4 Random Seed,[0],[0]
"They define an optimization as safe if the results are within one standard deviation of the mean of the results observed from multiple seeded runs.
",4.4 Random Seed,[0],[0]
"We suggest that specifying the random seed used in training is the bare minimum, necessary step that should be taken, although given the potential for different pseudo-random generators, and differences in implementation, this may not be enough.",4.4 Random Seed,[0],[0]
"Indeed, the best approach is to stop reporting single-value results, and instead report the distribution of results from a range of seeds.",4.4 Random Seed,[0],[0]
"Doing so allows for a fairer comparison across models, by discarding potential comparisons of lucky and unlucky seeds.",4.4 Random Seed,[0],[0]
"In addition, these result populations can be statistically compared for significance, allowing for stronger claims on improvement.",4.4 Random Seed,[0],[0]
Thus far this paper has presented a number of effects that can affect the results of a neural network.,4.5 Interactions,[0],[0]
"Each of these has been presented in isolation, after fixing
the prior effects.",4.5 Interactions,[0],[0]
These effects clearly have potential for interaction and the interaction is unpredictable.,4.5 Interactions,[0],[0]
"In this section we briefly examine one of these interactions, namely the seed selection combined with either CPU or GPU training.
",4.5 Interactions,[0],[0]
The results presented in Table 8 show that for a given seed the models exhibit different effectiveness based on the hardware used for training.,4.5 Interactions,[0],[0]
In Section 4.4 it was shown that the seed has a significant impact on the relative effectiveness of the model regardless of this computational backend.,4.5 Interactions,[0],[0]
"The correlation coefficients across devices presented in Table 9 leads us to suspect that there can be substantial changes in effectiveness when switching the backend from CPU to GPU and vice versa.
",4.5 Interactions,[0],[0]
"Figure 3 shows the effect of changing from CPU training to GPU training, using the same 200 seeds that were used in Section 4.4.",4.5 Interactions,[0],[0]
"The relationship observed in Figure 2 between AP and RR is still present, but there is no telling, given a fixed seed, whether training on GPU or CPU would result in better effectiveness.",4.5 Interactions,[0],[0]
"In addition, these deltas can be larger than a substantial number of incremental improvements reported.",4.5 Interactions,[0],[0]
"For example, a middling result on the CPU may be transformed to either a top or bottom result if switching to GPU training, with everything else fixed.
",4.5 Interactions,[0],[0]
"By reporting results as single numbers the variation due to the hardware on which the training is performed is hidden, and this could lead authors to conclude that their model is a substantial improvement on state-of-the-art.",4.5 Interactions,[0],[0]
The changes in AP and RR that are observed are representative of even the larger improvements in state-of-the-art.,4.5 Interactions,[0],[0]
"However, when comparing the distributions of the scores across the backends by visual inspection of Figure 2 there is clearly not any difference in the populations.",4.5 Interactions,[0],[0]
"Statistical significance testing (p ≫ 0.05 in a paired t-test, both two- and single-tailed) bears out this intuition.",4.5 Interactions,[0],[0]
Using these population based results would then lead authors to a different conclusion than if the seed was “lucky” for the training hardware.,4.5 Interactions,[0],[0]
This is a concrete example of the differences between reporting result distributions compared with single values.,4.5 Interactions,[0],[0]
The final aspect of result reporting that is controllable for is the rounding of results.,4.6 Reporting Rounding,[0],[0]
"For example,
when using the default install options of the sample model, and fixing the other versions and settings, our sample model gives two observed separate results with CPU training—on the TrecQA dataset either an AP of 0.7485 or 0.7487 is obtained.",4.6 Reporting Rounding,[0],[0]
"While this difference of 0.0002 is small, there is a newer trend (present in the latter three papers in Table 2) of reporting results to three decimal points.",4.6 Reporting Rounding,[0],[0]
"In this case even such a minor difference can result in state-ofthe-art or not, statistical significance notwithstanding.",4.6 Reporting Rounding,[0],[0]
"For example a result of 0.7484 would round down, while 0.7486 would round up, overemphasizing the difference by a factor of 5.",4.6 Reporting Rounding,[0],[0]
"We concede, however, that the same argument can be applied regardless of which decimal point cut-off is used, although we observe that trec_eval, the de facto tool used to calculate AP and RR, reports to four.
",4.6 Reporting Rounding,[0],[0]
"We recommend that reviewers be skeptical of such minor improvements on state-of-the-art when single results are reported, the recommendation here follows that of Section 4.4, in that ideally multiple seeds are used, and testing is performed on the population of results to determine improvement.",4.6 Reporting Rounding,[0],[0]
In this paper we have demonstrated a number of factors that are present during training of a model and affect the results of said model.,5 Conclusions,[0],[0]
"These parameters, and their settings, often go unreported in the literature.",5 Conclusions,[0],[0]
The result is that a large amount of prior work in answer selection is inherently irreproducible.,5 Conclusions,[0],[0]
"Furthermore, the differences in results illustrated by these effects can be much larger than the majority
of improvements reported as gains in the literature.",5 Conclusions,[0],[0]
The effects that we presented are not stand-alone effects.,5 Conclusions,[0],[0]
"Interaction between effects also has an additional impact, one of which was discussed in Section 4.5.",5 Conclusions,[0],[0]
Other results presented in this paper do not consider this interaction.,5 Conclusions,[0],[0]
"For example Table 6 suggested that a model trained using OpenBLAS produces worse results for the TrecQA dataset than one trained using Intel’s MKL library, which is true. . .",5 Conclusions,[0],[0]
"for that version of the model code, for that version of the framework, for that random seed, when trained on a single thread on that CPU, for that dataset.",5 Conclusions,[0],[0]
"We reserve investigating the interaction effects of these individual effects for future work.
",5 Conclusions,[0],[0]
"It is simply no longer adequate to report a single value when evaluating results from neural networks, especially without the presence of statistical testing on those results.",5 Conclusions,[0],[0]
By far the largest source of variability in the experiments presented in this paper was when the network was seeded with different random starting points.,5 Conclusions,[0],[0]
"The range of results produced cover ranges of results that can be an order of magnitude larger than typically imported improvements.
",5 Conclusions,[0],[0]
"As well as repeating experiments for multiple seeds, the specifications of the hardware on which the experiments were performed should be reported alongside the results, as changing the hardware can change the results by an order of magnitude.",5 Conclusions,[0],[0]
"Additionally, the number of threads and the math library used impact on the results and should be reported.
",5 Conclusions,[0],[0]
"Finally, beyond the hardware effects, the software that is used to both run the model, and define the model, has an impact.",5 Conclusions,[0],[0]
"For this reason both the model
definition and library versions, as well as all the required dependencies, should be pinned to a specified version.",5 Conclusions,[0],[0]
"These issues are easily avoidable by the use of common packaging tools such as Docker, which also provides opportunities to fix most of the nonversioning environmental issues as well.
",5 Conclusions,[0],[0]
"In cases where authors are unable to provide a Docker image, or equivalent, then making the trained models available is one alternative.",5 Conclusions,[0],[0]
Loading pre-trained models is an action that is supported by a number of frameworks.,5 Conclusions,[0],[0]
"PyTorch, for example, provides functions to load a model from a URL.",5 Conclusions,[0],[0]
"The pre-trained models appear to provide consistent results even when the inference pass is performed using settings that would have provided different results in training.
",5 Conclusions,[0],[0]
A sentence is all that it takes to describe the environment used for training.,5 Conclusions,[0],[0]
"For example: “our model was written against PyTorch v0.1.12, and training was conducted on an Intel i7-6800K using a single thread and Intel’s Math Kernel Library”.",5 Conclusions,[0],[0]
Beyond this we implore reviewers to be wary of such minor reported improvements in the light of these issues.,5 Conclusions,[0],[0]
"The author wishes to acknowledge the input and advice of (in alphabetical order) Gaurav Baruah, Jimmy Lin, Adam Roegiest, Royal Sequiera, and Michael Tu.",Acknowledgements,[0],[0]
Finally thanks to the reviewers and editors for their comments and suggestions to improve the paper.,Acknowledgements,[0],[0]
"“Based on theoretical reasoning it has been suggested that the reliability of findings published in the scientific literature decreases with the popularity of a research field” (Pfeiffer and Hoffmann, 2009).",abstractText,[0],[0]
"As we know, deep learning is very popular and the ability to reproduce results is an important part of science.",abstractText,[0],[0]
There is growing concern within the deep learning community about the reproducibility of results that are presented.,abstractText,[0],[0]
"In this paper we present a number of controllable, yet unreported, effects that can substantially change the effectiveness of a sample model, and thusly the reproducibility of those results.",abstractText,[0],[0]
Through these environmental effects we show that the commonly held belief that distribution of source code is all that is needed for reproducibility is not enough.,abstractText,[0],[0]
Source code without a reproducible environment does not mean anything at all.,abstractText,[0],[0]
In addition the range of results produced from these effects can be larger than the majority of incremental improvement reported.,abstractText,[0],[0]
Questionable Answers in Question Answering Research: Reproducibility and Variability of Published Results,title,[0],[0]
"Quick Shift (Vedaldi & Soatto, 2008) is a mode-seeking based clustering algorithm that has a growing popularity in computer vision.",1. Introduction,[0],[0]
"It proceeds by repeatedly moving each sample to its closest sample point that has higher empirical density if one exists within a τ -radius ball, otherwise we stop.",1. Introduction,[0],[0]
Thus each path ends at a point which can be viewed as a local mode of the empirical density.,1. Introduction,[0],[0]
"Then, points that end up at the same mode are assigned to the same cluster.",1. Introduction,[0],[0]
The most popular choice of empirical density function is the Kernel Density Estimator (KDE) with Gaussian Kernel.,1. Introduction,[0],[0]
"The algorithm also appears in Rodriguez & Laio (2014).
",1. Introduction,[0],[0]
"Quick Shift was designed as a faster alternative to the wellknown Mean Shift algorithm (Cheng, 1995; Comaniciu & Meer, 2002).",1. Introduction,[0],[0]
"Mean Shift is equivalent to performing a gradient ascent of the KDE starting at each sample until convergence (Arias-Castro et al., 2016).",1. Introduction,[0],[0]
Samples that correspond to the same points of convergence are in the same cluster and the points of convergence are taken to be the estimates of the modes.,1. Introduction,[0],[0]
"Thus, both procedures hill-climb to the local modes of the empirical density function and cluster based on these modes.",1. Introduction,[0],[0]
"The key differences are that Quick Shift restricts the steps to sample points (and thus is a sample-based version of Mean Shift) and has the extra τ parameter which allows it to merge close segments together.
",1. Introduction,[0],[0]
"1Google Research, Mountain View, CA 2Uber Inc, San Francisco, CA 3Princeton University, Princeton, NJ.",1. Introduction,[0],[0]
"Correspondence to: Heinrich Jiang <heinrich.jiang@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"One of the drawbacks of these two procedures, as well as many mode-seeking based clustering algorithms, is that the point-modes of the density functions are often poor representations of the clusters.",1. Introduction,[0],[0]
"This will happen when the high-density regions within a cluster are of arbitrary shape and have some variations causing the underlying density function to have possibly many apparent, but not so salient modes.",1. Introduction,[0],[0]
"In this case, such procedures asymptotically recover all of the modes separately, leading to over-segmentation.",1. Introduction,[0],[0]
"To combat this effect, practitioners often increase the kernel bandwidth, which makes the density estimate more smooth.",1. Introduction,[0],[0]
"However, this can cause the density estimate to deviate too far from the original density we are intending to cluster based on.1 Thus, practitioners may not wish to identify the clusters based on the point-modes of the density function, but rather identify them based on locally high density regions of the dataset (See Figure 1).2
We propose modeling these locally high-density regions as cluster-cores (to be precisely defined later), which can be of arbitrary shape, size, and density level, and are thus better suited at capturing the possibly complex topological properties of clusters that can arise in practice.",1. Introduction,[0],[0]
"In other words, these cluster-cores are better at expressing the clusters and are more stable as they are less sensitive to the small fluctuations that can arise in the empirical density function.",1. Introduction,[0],[0]
We parameterize the cluster-core by β where 0,1. Introduction,[0],[0]
"< β < 1, which determines how much the density is allowed to vary within the cluster-core.",1. Introduction,[0],[0]
"We estimate them from a finite sample using a minor modification of the MCores algorithm of Jiang & Kpotufe (2017).
",1. Introduction,[0],[0]
"We introduce Quickshift++, which first estimates these cluster-cores, and then runs the Quick Shift based hillclimbing procedure on each remaining sample until it reaches a cluster-core.",1. Introduction,[0],[0]
"Samples that end up in the same cluster-core are assigned to the same cluster; thus,
1KDE with Gaussian kernel and bandwidth h approximates the underlying density convolved with a Gaussian with mean 0 and covariance h2I. Thus, the higher h is, the more the KDE deviates from the original density.
",1. Introduction,[0],[0]
"2Over-segmentation is also dealt with in Quick Shift via the τ parameter, but a threshold for the distance between two modes which should be clustered together is hard to determine in practice.",1. Introduction,[0],[0]
"Moreover, there may not even be a good setting of τ which works everywhere in the input space.
",1. Introduction,[0],[0]
the cluster-cores can be seen as representing the highconfidence regions within each cluster.,1. Introduction,[0],[0]
"We utilize the k-NN density estimator as our empirical density.
",1. Introduction,[0],[0]
"Despite the simplicity of our approach, we show that Quickshift++ considerably outperforms the popular density-based clustering algorithms, while being efficient.",1. Introduction,[0],[0]
Another desirable property of Quickshift++ is that it is simple to tune its two hyperparameters β and k.3,1. Introduction,[0],[0]
"We show that a few settings of β turn out to work for a wide range of applications and that the procedure is stable in choices of k.
We then give a novel statistical consistency analysis for Quickshift++ which provides guarantees that points within a cluster-core’s attraction regions (to be described later) are correctly assigned.",1. Introduction,[0],[0]
"We also show promising results on image segmentation, which further validates the desirability of using cluster-cores on real-data applications.",1. Introduction,[0],[0]
"We show that Quickshift++ is a new and powerful addition to the family of clustering procedures known as densitybased clustering, which most notably includes DBSCAN (Ester et al., 1996) and Mean Shift (Cheng, 1995).",2. Related Works and Contributions,[0],[0]
Such procedures operate on the estimated density function based on a finite sample to recover structures in the density function that ultimately correspond to the clusters.,2. Related Works and Contributions,[0],[0]
There are several advantages of density-based clustering over classical objective-based procedures such as k-means and spectral clustering.,2. Related Works and Contributions,[0],[0]
"Density-based procedures can automatically detect the number of clusters, while objective-based procedures typically require this as an input.",2. Related Works and Contributions,[0],[0]
"Density-based clustering algorithms also make little assumptions on the shapes of the clusters as well as their relative positions.
",2. Related Works and Contributions,[0],[0]
"Density-based clustering procedures can roughly be classified into two categories: hill-climbing based approaches (discussed earlier, which includes both Mean Shift and
3The τ parameter from Quick Shift is unnecessary here because we climb until we reach a cluster-core as our stopping condition.
",2. Related Works and Contributions,[0],[0]
Quick Shift) and density-level set based approaches.,2. Related Works and Contributions,[0],[0]
"We now discuss the latter approach, which takes the connected components of the density-level set defined by {x : f(x) ≥ λ} for some density level λ as the clusters.",2. Related Works and Contributions,[0],[0]
This statistical notion of clustering traces back to Hartigan (1975).,2. Related Works and Contributions,[0],[0]
"Since then, there has been extensive work done, e.g. Tsybakov et al. (1997); Cadre (2006); Rigollet et al. (2009); Singh et al. (2009); Chaudhuri & Dasgupta (2010); Rinaldo & Wasserman (2010); Kpotufe & von Luxburg (2011); Balakrishnan et al. (2013); Chaudhuri et al. (2014); Chen et al. (2017).",2. Related Works and Contributions,[0],[0]
"More recently, Sriperumbudur & Steinwart (2012); Jiang (2017a) show that the popular DBSCAN algorithm turns out to converge to these clusters.",2. Related Works and Contributions,[0],[0]
"However, one of the main drawbacks of this approach is that the density-level λ is fixed and thus such methods perform poorly when the clusters are at different density-levels.",2. Related Works and Contributions,[0],[0]
"Moreover, the question of how to choose λ remains (e.g. Steinwart (2011)).
",2. Related Works and Contributions,[0],[0]
"Jiang & Kpotufe (2017) provide an alternative notion of clusters, called modal-sets, which are regions of flat density which are local maximas of the density.",2. Related Works and Contributions,[0],[0]
"They can be of arbitrary shape, dimension, or density.",2. Related Works and Contributions,[0],[0]
"They provide a procedure, MCores, which estimates these with consistency guarantees.",2. Related Works and Contributions,[0],[0]
"Our notion of cluster-core is similar to modalsets, but the density within a cluster-core is allowed to vary by a substantial amount in order to capture such variations seen in real data as a the flat density of modal-sets may be too restrictive in practice.",2. Related Works and Contributions,[0],[0]
It turns out that a small modification of MCores allows us to estimate these cluster-cores.,2. Related Works and Contributions,[0],[0]
"Thus Quickshift++ has the advantage over DBSCAN in that clusters can be at any density level and that furthermore, the density levels are chosen adaptively.
",2. Related Works and Contributions,[0],[0]
"Mcores however consists of an over-simplistic final clustering: it simply assigns each point to its closest modal-set, while in practice, clusters tend not to follow the geometry induced by the Euclidean metric.",2. Related Works and Contributions,[0],[0]
"Quickshift++ on the other hand clusters the remaining points by a hill-climbing method which we show is far better in practice.
",2. Related Works and Contributions,[0],[0]
"Thus, Quickshift++ combines the strengths of both densitybased clustering approaches while avoiding many of their weaknesses.",2. Related Works and Contributions,[0],[0]
"In addition to the general advantages of densitybased clustering algorithms shared by both approaches, it is also able to both (1) recover clusters at varying density levels and (2) not suffer from the over-segmentation issue described in Figure 1.",2. Related Works and Contributions,[0],[0]
"To our knowledge, no other procedure has been shown to have this property.
",2. Related Works and Contributions,[0],[0]
"For our theoretical analysis, we give guarantees about Quickshift++’s ability to recover the clusters based on attraction regions defined by the gradient flows.",2. Related Works and Contributions,[0],[0]
Wasserman et al. (2014); Arias-Castro et al. (2016) showed that Mean Shift’s iterates approximate the gradient flows.,2. Related Works and Contributions,[0],[0]
"Some progress has been made in understanding Quick Shift (Jiang, 2017b; Verdinelli & Wasserman, 2018).",2. Related Works and Contributions,[0],[0]
"There are also related lines
of work in mode clustering e.g. (Li et al., 2007; Chacón, 2012; Genovese et al., 2016; Chen et al., 2016).",2. Related Works and Contributions,[0],[0]
"In this paper, we show that Quickshift++ recovers the interior of its attraction region, thus adding to our statistical understanding of hill-climbing based clustering procedures.",2. Related Works and Contributions,[0],[0]
"Let X[n] = {x1, ..., xn} be n i.i.d.",3.1. Basic Definitions,[0],[0]
"samples drawn from an unknown density f , defined over the Lebesgue measure on Rd.",3.1. Basic Definitions,[0],[0]
"Suppose that f has compact support X .
",3.1. Basic Definitions,[0],[0]
"Our procedure will operate on the k-NN density estimator:
Definition 1.",3.1. Basic Definitions,[0],[0]
"Let rk(x) := inf{r > 0 : |B(x, r)∩X[n]| ≥ k}, i.e., the distance from x to its k-th nearest neighbor.",3.1. Basic Definitions,[0],[0]
"Define the k-NN density estimator as
fk(x) := k
n · vd · rk(x)d ,
where vd is the volume of a unit ball in Rd.",3.1. Basic Definitions,[0],[0]
"We define the cluster core with respect to fixed fluctuation parameter β as follows.
",3.2. Cluster-Cores,[0],[0]
Definition 2.,3.2. Cluster-Cores,[0],[0]
Let 0,3.2. Cluster-Cores,[0],[0]
< β < 1.,3.2. Cluster-Cores,[0],[0]
"Closed and connected set M ⊂ X is a cluster-core if M is a connected component (CC) of {x ∈ X : f(x) ≥ (1− β) ·maxx′∈M f(x′)}.
",3.2. Cluster-Cores,[0],[0]
"Note that when β → 0, then the cluster-cores become the modes or local-maximas of f .",3.2. Cluster-Cores,[0],[0]
"When β → 1, then the cluster-core becomes the entire support X .",3.2. Cluster-Cores,[0],[0]
"We next give a very basic fact about cluster-cores, that they do not overlap.
",3.2. Cluster-Cores,[0],[0]
Lemma 1.,3.2. Cluster-Cores,[0],[0]
"Suppose that M1, M2 are distinct cluster-cores of f .",3.2. Cluster-Cores,[0],[0]
"Then M1 ∩M2 = ∅.
Proof.",3.2. Cluster-Cores,[0],[0]
Suppose otherwise.,3.2. Cluster-Cores,[0],[0]
"We have that M1 and M2 are CCs of {x ∈ X : f(x) ≥ λ1} and {x ∈ X : f(x) ≥ λ2}, respectively for some λ1, λ2.",3.2. Cluster-Cores,[0],[0]
"Clearly, if λ1 = λ2, then it follows that M1 =M2.",3.2. Cluster-Cores,[0],[0]
"Then, without loss of generality, let λ1 < λ2.",3.2. Cluster-Cores,[0],[0]
"Then since the CCs of {x ∈ X : f(x) ≥ λ2} are nested in the CCs of {x ∈ X : f(x) ≥ λ1}, then it follows that M2 ⊆M1.",3.2. Cluster-Cores,[0],[0]
"Then, λ2 = (1− β) supx∈M2 f(x) ≤ (1− β) supx∈M1 f(x) = λ1, a contradiction.",3.2. Cluster-Cores,[0],[0]
"As desired.
",3.2. Cluster-Cores,[0],[0]
Algorithm 1 is a simple modification of MCores by Jiang & Kpotufe (2017).,3.2. Cluster-Cores,[0],[0]
"The difference is that we use a multiplicative fluctuation parameter β, while Jiang & Kpotufe (2017) uses an additive one.",3.2. Cluster-Cores,[0],[0]
"The latter requires knowledge of the scale of the density function, which is difficult to determine in practice.",3.2. Cluster-Cores,[0],[0]
"Moreover, the multiplicative fluctuation adapts to clusters at varying density levels more reasonably than
a fixed additive fluctuation.",3.2. Cluster-Cores,[0],[0]
"It uses the levels of the mutual k-NN graph of the sample points, defined below.",3.2. Cluster-Cores,[0],[0]
Definition 3.,3.2. Cluster-Cores,[0],[0]
"Let G(λ) denote the λ-level of the mutual k-NN graph with vertices {x ∈ X[n] : fk(x) ≥ λ} and an edge between x and x′ iff ||x− x′|| ≤ min{rk(x), rk(x′)}.
",3.2. Cluster-Cores,[0],[0]
"It is known that G(λ) approximates the CCs of the λ-level sets of the true density, defined as {x ∈ X : f(x) ≥ λ} see e.g. (Chaudhuri & Dasgupta, 2010).",3.2. Cluster-Cores,[0],[0]
"Moreover, it can be seen that the CCs of G(λ) forms a hierarchical nesting structure as λ decreases.
",3.2. Cluster-Cores,[0],[0]
"Algorithm 1 proceeds by performing a top-down sweep of the levels of the mutual k-NN graph, G(λ).",3.2. Cluster-Cores,[0],[0]
"As λ decreases, it is clear that more nodes appear and that connectivity increases.",3.2. Cluster-Cores,[0],[0]
"In other words, as we scan top-down, the CCs of G(λ) become larger, some CCs can merge, or new CCs can appear.",3.2. Cluster-Cores,[0],[0]
"When a new CC appears at level λ, then intuitively, it should correspond to a local maxima of f , which appears at a density level approximately λ.",3.2. Cluster-Cores,[0],[0]
This follows from the fact that the CCs of G(λ) approximates the CCs of {x ∈ X : f(x) ≥ λ}.,3.2. Cluster-Cores,[0],[0]
"Thus, the idea is that when a new CC appears in G(λ), then we can take the corresponding CC in G(λ− βλ) (which is the density level (1− β) times that of the highest point in the CC) to estimate the cluster-core.
",3.2. Cluster-Cores,[0],[0]
Algorithm 1 MCores (estimating cluster-cores),3.2. Cluster-Cores,[0],[0]
"Parameters k, β Initialize M̂ :=",3.2. Cluster-Cores,[0],[0]
∅. Sort the xi’s in decreasing order of fk values (i.e. fk(xi) ≥ fk(xi+1)).,3.2. Cluster-Cores,[0],[0]
"for i = 1 to n do
Define λ := fk(xi).",3.2. Cluster-Cores,[0],[0]
Let A be the CC of G(λ− βλ) containing xi.,3.2. Cluster-Cores,[0],[0]
"if A is disjoint from all cluster-cores in M̂ then
Add A to M̂. end if
end for return M̂.
Algorithm 2 Quickshift++
Let M̂ be the cluster-cores obtained by running Algorithm 1.",3.2. Cluster-Cores,[0],[0]
"Initialize directed graph G with vertices {x1, ..., xn} and no edges.",3.2. Cluster-Cores,[0],[0]
"for i = 1 to n do
If xi is not in any cluster-core, then add to G an edge from xi to its closest sample x ∈ X[n] such that fk(x) > fk(xi).",3.2. Cluster-Cores,[0],[0]
"end for For each cluster-core M ∈ M̂, let ĈM be the points x ∈ X[n] such that the directed path in G starting at x ends in M .",3.2. Cluster-Cores,[0],[0]
return {ĈM :M ∈ M̂}.,3.2. Cluster-Cores,[0],[0]
"Quickshift++ (Algorithm 2) proceeds by first running Algorithm 1 to obtain the cluster-cores, and then moving each sample point to its nearest neighbor that has higher k-NN density until it reaches some cluster-core.",3.3. Quickshift++,[0],[0]
All samples that end up in the same cluster-core after the hill-climbing are assigned to the same cluster.,3.3. Quickshift++,[0],[0]
"Note that since the highest empirical density sample point is contained in a cluster-core, it follows that each sample point not in a cluster-core will eventually be assigned to a unique cluster-core.",3.3. Quickshift++,[0],[0]
"Thus, Quickshift++ provides a clustering assignment of every sample point.",3.3. Quickshift++,[0],[0]
Remark 1.,3.3. Quickshift++,[0],[0]
"Although it seems a similar procedure could have been constructed by using Mean Shift in place of Quick Shift, Mean Shift could have convergence outside of the estimated cluster-cores, while Quick Shift guarantees that each sample outside of a cluster-core get assigned to some cluster-core.",3.3. Quickshift++,[0],[0]
The implementation details for the MCores modification can be inferred from Jiang & Kpotufe (2017).,3.4. Implementation,[0],[0]
"This step runs in O(nk · α(n)) where α is the Inverse Ackermann function (Cormen, 2009), in addition to the time it takes to compute the k-NN sets for the n sample points.",3.4. Implementation,[0],[0]
"To cluster the remaining points, for each sample not in a cluster-core, we must find its nearest sample of higher k-NN density.",3.4. Implementation,[0],[0]
"Although this is worst-case O(n) time for each sample point, fortunately we see that in practice (as long as k is not too small) for the vast majority of cases, the nearest sample with higher density is within the k-nearest neighbor set so it only takes O(k) in most cases.",3.4. Implementation,[0],[0]
It is an open problem whether there the nearest sample with higher empirical density is often in its k-NN set.,3.4. Implementation,[0],[0]
Code release is at https://github.com/google/quickshift.,3.4. Implementation,[0],[0]
"For the theoretical analysis, we make first the following regularity assumption, that the density is continuously differentiable and lower bounded on X .",4. Theoretical Analysis,[0],[0]
Assumption 1.,4. Theoretical Analysis,[0],[0]
f is continuously differentiable on X and there exists λ0 > 0,4. Theoretical Analysis,[0],[0]
"such that infx∈X f(x) ≥ λ0.
",4. Theoretical Analysis,[0],[0]
"Let M1, ...,MC be the cluster-cores of f .",4. Theoretical Analysis,[0],[0]
Then we can define the following notion of attraction region for each cluster-core based on the gradient ascent curve or flow.,4. Theoretical Analysis,[0],[0]
"This is similar to notions of attraction regions for some previous analyses of mode-based clustering, such as Wasserman et al. (2014); Arias-Castro et al. (2016), where the intuition is that attraction regions are defined based by following the direction of the gradient of the underlying density.",4. Theoretical Analysis,[0],[0]
"In our situation, instead of an attraction region defined as all points
which flow towards a particular point-mode, the attraction region is defined around a cluster-core.
",4. Theoretical Analysis,[0],[0]
Definition 4 (Attraction Regions).,4. Theoretical Analysis,[0],[0]
"Let path πx : R→ Rd satisfy πx(0) = x, π′x(t) = ∇f(πx(t)).",4. Theoretical Analysis,[0],[0]
"For cluster-core Mi, its attraction region Ai is the set of points x ∈ X that satisfy limt→∞ πx(t) ∈Mi.
",4. Theoretical Analysis,[0],[0]
It is clear that these attraction regions are well-defined.,4. Theoretical Analysis,[0],[0]
"The flow path is well-defined since the density is differentiable and since each cluster-core is defined as a CC of a level set, the density must decay around its boundaries.",4. Theoretical Analysis,[0],[0]
"In other words, once an ascent path reaches a cluster-core, it cannot leave the cluster-core.
",4. Theoretical Analysis,[0],[0]
"However, it is in general not the case that the space can be partitioned into attraction regions.",4. Theoretical Analysis,[0],[0]
"For example, if a flow reaches a saddle point, it will get stuck there and thus any point whose flow ends up at a saddle point will not belong to any attraction region.",4. Theoretical Analysis,[0],[0]
"In this paper, we only give guarantees about the clustering of points which are in an attraction region.
",4. Theoretical Analysis,[0],[0]
"The next regularity assumption we make is that the clustercores are on the interior of the attraction region (to avoid situations such as when the cluster-cores intersect with the boundary of the input space).
",4. Theoretical Analysis,[0],[0]
Assumption 2.,4. Theoretical Analysis,[0],[0]
"There exists R0 > 0 such that Mi + B(0, R0) ⊆ Ai for i = 1, ..., C, where M + B(0, r) denotes {x : infy∈M ||x− y|| ≤ r}.",4. Theoretical Analysis,[0],[0]
Definition 5 (Level Set).,4. Theoretical Analysis,[0],[0]
"The λ level set of f is defined as Lf (λ) := {x ∈ X : f(x) ≥ λ}.
",4. Theoretical Analysis,[0],[0]
The next assumption says that the level sets are continuous w.r.t.,4. Theoretical Analysis,[0],[0]
"the level in the following sense where we denote the -interior of A as A := {x ∈ A, infy∈∂A ||x − y|| ≥ } (∂A is the boundary of A):
Assumption 3 (Uniform Continuity of Level Sets).",4. Theoretical Analysis,[0],[0]
"For each > 0, there exists δ > 0",4. Theoretical Analysis,[0],[0]
such that for 0 < λ ≤ λ′ ≤ ||f ||∞ with |λ−,4. Theoretical Analysis,[0],[0]
"λ′| < δ, then Lf (λ) ⊆ Lf (λ′).
",4. Theoretical Analysis,[0],[0]
This ensures that there are no approximately flat areas in which the procedure may get stuck at.,4. Theoretical Analysis,[0],[0]
"The assumption is borrowed from (Jiang, 2017b).",4. Theoretical Analysis,[0],[0]
"Finally, we need the following regularity condition which ensures that level sets away from cluster-cores do not get arbitrarily thin.",4. Theoretical Analysis,[0],[0]
"This is adapted from standard analyses of level-set estimation (e.g. Assumption B of Singh et al. (2009)).
",4. Theoretical Analysis,[0],[0]
Assumption 4.,4. Theoretical Analysis,[0],[0]
Let µ denote the Lebesgue measure on Rd.,4. Theoretical Analysis,[0],[0]
"For any r > 0, there exists σ > 0",4. Theoretical Analysis,[0],[0]
"such that the following holds for any connected component A of any level-set of f which is not contained inMi for any i: µ(B(x, r)∩A) ≥ σ for all x ∈ A.
For our consistency results, we prove that Quickshift++ can cluster the sample points in the (R, ρ)-interior of an attrac-
tion region (defined below) for each cluster-core properly where R, ρ > 0 are fixed and can be chosen arbitrarily small.
",4. Theoretical Analysis,[0],[0]
"Definition 6 ((R, ρ)-interior of Attraction Regions).",4. Theoretical Analysis,[0],[0]
"Define the (R, ρ)-interior of Ai, denoted as A(R,ρ)i , as the set of points x0 ∈",4. Theoretical Analysis,[0],[0]
"Ai such that each path P from x0 to any point y ∈ ∂Ai satisfies the following.
",4. Theoretical Analysis,[0],[0]
"sup x∈P inf x′∈B(x,R) f(x′)",4. Theoretical Analysis,[0],[0]
"≥ sup x′∈B(y,R) f(x′) + ρ.
",4. Theoretical Analysis,[0],[0]
"In other words, points in the interior satisfy the property that any path leaving its attraction region must sufficiently decrease in density at some point.",4. Theoretical Analysis,[0],[0]
"This decrease threshold is parameterized by R and ρ.
",4. Theoretical Analysis,[0],[0]
"We first give a guarantee on the first step of MCores recovers, that the cluster-cores are reasonably recovered.",4. Theoretical Analysis,[0],[0]
"The proof follows from the analysis of Jiang & Kpotufe (2017) by replacing modal-sets with cluster-cores, and the results match up to constant factors.",4. Theoretical Analysis,[0],[0]
"The proof is omitted here.
",4. Theoretical Analysis,[0],[0]
Theorem 1.,4. Theoretical Analysis,[0],[0]
"[Adapted from Theorem 3, 4 of Jiang & Kpotufe (2017)]",4. Theoretical Analysis,[0],[0]
"Suppose that Assumptions 1, 3, and 4 hold.",4. Theoretical Analysis,[0],[0]
Let 0,4. Theoretical Analysis,[0],[0]
"< β < 1, , δ > 0",4. Theoretical Analysis,[0],[0]
and suppose that k ≡ k(n) is chosen such that log2 n/k → 0 and n4/(4+d)/k → 0.,4. Theoretical Analysis,[0],[0]
"Let M1, ...,MC be the cluster-cores of f .",4. Theoretical Analysis,[0],[0]
"Then for n sufficiently large depending on f , δ, , and β, with probability at least 1− δ, MCores returns C cluster-core estimates M̂1, ..., M̂C such that Mi ∩X[n] ⊆ M̂i ⊆Mi+B(0, ) for i ∈ 1, ..., C. Remark 2.",4. Theoretical Analysis,[0],[0]
The original result from Jiang & Kpotufe (2017) is about -approximate modal-set which are defined as levelsets whose density has range .,4. Theoretical Analysis,[0],[0]
"Our notion of cluster-core is similar, but the range is a β-proportion of the highest density level within the level-set.",4. Theoretical Analysis,[0],[0]
"Using a proportion is more interpretable and thus more useful, as the scale of the density function is difficult to determine in practice.
",4. Theoretical Analysis,[0],[0]
"In other words, with high probability, MCores estimates each cluster-core bijectively and that for each cluster-core, MCores’ estimate contains all of the sample points and that the estimate does not over-estimate by much.
",4. Theoretical Analysis,[0],[0]
"We now state the main result, which says that as long as the cluster-cores are sufficiently well estimated (up to a certain Hausdorff error) by MCores (via previous theorem), then Quickshift++ will correctly cluster the (R, ρ)-interiors of the attraction regions with high probability.
",4. Theoretical Analysis,[0],[0]
Theorem 2.,4. Theoretical Analysis,[0],[0]
"Suppose that Assumptions 1, 2, 3, and 4 hold.",4. Theoretical Analysis,[0],[0]
Let 0,4. Theoretical Analysis,[0],[0]
<,4. Theoretical Analysis,[0],[0]
"R < R0 and ρ, δ > 0.",4. Theoretical Analysis,[0],[0]
Suppose that k ≡ k(n) is chosen such that log2 n/k → 0 and n4/(4+d)/k → 0.,4. Theoretical Analysis,[0],[0]
"Suppose that M̂1, ..., M̂C are the cluster-cores returned by Algorithm 1 and satisfyMi∩X[n] ⊆ M̂i ⊆Mi+B(0, R/4) for i = 1, ..., C. Then for n sufficiently large depending on f , ρ, δ and R, the following holds with probably at least 1 − 2δ uniformly in x ∈ A(R,ρ)i ∩X[n] and i ∈",4. Theoretical Analysis,[0],[0]
[C]: Quickshift++ clusters x to the cluster corresponding to Mi.,4. Theoretical Analysis,[0],[0]
"We require the following uniform bound on k-NN density estimator, which follows from Dasgupta & Kpotufe (2014).
",4.1. Proof of Theorem 2,[0],[0]
Lemma 2.,4.1. Proof of Theorem 2,[0],[0]
Let δ > 0.,4.1. Proof of Theorem 2,[0],[0]
"Suppose that f is Lipschitz continuous with compact support X (e.g. there exists L such that |f(x)−f(x′)| ≤ L|x−x′| for all x, x′ ∈ X ) and f satsifies Assumption 1.",4.1. Proof of Theorem 2,[0],[0]
"Then exists constant C depending on f such that the following holds if n ≥ C2δ,n with probability at least 1− δ.
",4.1. Proof of Theorem 2,[0],[0]
sup,4.1. Proof of Theorem 2,[0],[0]
x∈X |fk(x)− f(x)| ≤ C,4.1. Proof of Theorem 2,[0],[0]
"( Cδ,n√ k + ( k n )1/d) .
",4.1. Proof of Theorem 2,[0],[0]
"where Cδ,n := 16 log(2/δ)",4.1. Proof of Theorem 2,[0],[0]
"√ d log n.
We next need the following uniform concentration bound on balls intersected with level-sets, which says that if such a set has large enough probability mass, then it will contain a sample point with high probability.
",4.1. Proof of Theorem 2,[0],[0]
Lemma 3.,4.1. Proof of Theorem 2,[0],[0]
"Let E := {B(x, r) ∩",4.1. Proof of Theorem 2,[0],[0]
"Lf (λ) : x ∈ Rd, r > 0, λ > 0}.",4.1. Proof of Theorem 2,[0],[0]
"Then the following holds with probability at least 1− δ uniformly for all E ∈ E
F(E) ≥",4.1. Proof of Theorem 2,[0],[0]
"Cδ,n √ d log n
n ⇒ E ∩Xn 6=",4.1. Proof of Theorem 2,[0],[0]
"∅.
Proof.",4.1. Proof of Theorem 2,[0],[0]
"The indicator functions 1[B(x, f) ∩",4.1. Proof of Theorem 2,[0],[0]
"Lf (λ)] for x ∈ Rd, λ > 0 have VC-dimension d+ 1.",4.1. Proof of Theorem 2,[0],[0]
"This is because the balls over Rd have VC-dimension d+ 1 and the level-sets Lf (λ) has VC-dimension 1 and thus their intersection has VC-dimension d+ 1 (Van Der Vaart & Wellner, 2009).",4.1. Proof of Theorem 2,[0],[0]
"The result follows by applying Theorem 15 of Chaudhuri & Dasgupta (2010).
",4.1. Proof of Theorem 2,[0],[0]
Proof of Theorem 2.,4.1. Proof of Theorem 2,[0],[0]
"Suppose that x0 ∈ A(R,ρ)i ∩X[n] and Quickshift++ gives directed path x0 → x1 → · · · → xL where x1, ..., xL−1 are outside of cluster-cores and xL is in a cluster-core but",4.1. Proof of Theorem 2,[0],[0]
"xL 6∈ Ai.
",4.1. Proof of Theorem 2,[0],[0]
"We first show that ||xi − xi+1|| ≤ R/2 for i = 0, ..., L− 1.",4.1. Proof of Theorem 2,[0],[0]
"By Assumption 3 and 4, we have that there exists τ > 0",4.1. Proof of Theorem 2,[0],[0]
"and σ > 0 such that the following holds uniformly for i = 0, ..., L− 1:
µ ( B(xi, R/2) ∩",4.1. Proof of Theorem 2,[0],[0]
Lf (f(xi) + τ) ),4.1. Proof of Theorem 2,[0],[0]
"≥ σ.
",4.1. Proof of Theorem 2,[0],[0]
"Hence, since the density is uniformly lower bounded by λ0, we have
F ( B(xi, R/2) ∩",4.1. Proof of Theorem 2,[0],[0]
Lf (f(xi) + τ) ),4.1. Proof of Theorem 2,[0],[0]
"≥ σλ0.
",4.1. Proof of Theorem 2,[0],[0]
"Then by Lemma 3, for n suffiicently large such that σλ0 > Cδ,n",4.1. Proof of Theorem 2,[0],[0]
"√ d logn n , then with probability at least 1− δ there exists sample point x′i in B(xi, R/2) ∩",4.1. Proof of Theorem 2,[0],[0]
"Lf (f(xi) + τ) for i = 0, ..., L− 1.
",4.1. Proof of Theorem 2,[0],[0]
"Next, choose n sufficiently large such that by Lemma 2, we have with probability at least 1− δ",4.1. Proof of Theorem 2,[0],[0]
"that
sup",4.1. Proof of Theorem 2,[0],[0]
"x∈X |fk(x)− f(x)| ≤ min{τ, ρ}/3.
",4.1. Proof of Theorem 2,[0],[0]
"Thus, we have
fk(x ′",4.1. Proof of Theorem 2,[0],[0]
i) ≥ f(x′i)− τ/3 ≥ f(xi) + 2τ/3 ≥ fk(xi) + τ/3,4.1. Proof of Theorem 2,[0],[0]
"> fk(xi).
",4.1. Proof of Theorem 2,[0],[0]
"Moreover ||xi − x′i|| ≤ R/2 and x′i ∈ X[n], it follows that ||xi − xi+1|| ≤ R/2 for i = 0, ..., L− 1.
",4.1. Proof of Theorem 2,[0],[0]
"Let π : [0, 1]→ Rd be the piecewise linear path defined by π(j/L) = xj for j = 0, ..., L. Let t2 = min{t ∈",4.1. Proof of Theorem 2,[0],[0]
"[0, 1] : π(t) ∈ ∂Ai}.",4.1. Proof of Theorem 2,[0],[0]
"Then, by definition of A(R,ρ)i , there exists 0 ≤",4.1. Proof of Theorem 2,[0],[0]
t1 < t2 such that x := π(t1) and y := π(t2) satisfies y ∈,4.1. Proof of Theorem 2,[0],[0]
∂Ai,4.1. Proof of Theorem 2,[0],[0]
"and
inf x′∈B(x,R) f(x′)",4.1. Proof of Theorem 2,[0],[0]
"≥ sup x′∈B(y,R) f(x′) + ρ.
",4.1. Proof of Theorem 2,[0],[0]
"Thus, there exists indices p, q ∈ {0, ..., L − 1} such that p ≤ q, |xp",4.1. Proof of Theorem 2,[0],[0]
− x| ≤,4.1. Proof of Theorem 2,[0],[0]
"R, and |xq",4.1. Proof of Theorem 2,[0],[0]
− y| ≤,4.1. Proof of Theorem 2,[0],[0]
"R. Thus, we have f(xp) ≥ f(xq) + ρ, but fk(xp) ≤ fk(xq).",4.1. Proof of Theorem 2,[0],[0]
"However, we have
fk(xp) ≥ f(xp)− ρ/3 ≥ f(xq) + 2ρ/3 ≥ fk(xq) + ρ/3 > fk(xq),
a contradiction, as desired.",4.1. Proof of Theorem 2,[0],[0]
Figure 3 provides simple verification that Quickshift++ provides reasonable clusterings in a wide variety of situations where other density-based procedures are known to fail.,5. Simulations,[0],[0]
"For instance, in the two rings dataset (first row), we
see that Mean Shift and Quick Shift suffer from the oversegmentation issue coupled with the oversized bandwidth which causes them to recover clusters that have points from both the rings even though the rings are separated.",5. Simulations,[0],[0]
"In the three Gaussians dataset (third row), we see that DBSCAN fails because the three clusters are of different density levels and thus no matter which density-level we set, DBSCAN will not be able to recover the three clusters.",5. Simulations,[0],[0]
"In order to apply clustering to image segmentation, we use the following standard approach (see e.g. Felzenszwalb & Huttenlocher (2004)): we transform each pixel into a 5-dimensional vector where two coordinates correspond to the location of the pixel and three correspond to each of the RGB color channels.",6. Image Segmentation,[0],[0]
"Then segmentation is done by clustering this 5-dimensional dataset.
",6. Image Segmentation,[0],[0]
"We observed that for Quickshift++, setting β = 0.9 is reasonable across a wide range of images, β was fixed to this value for segmentation here.",6. Image Segmentation,[0],[0]
"We compare Quickshift++ to Quick Shift, as the latter is often used for segmentation.",6. Image Segmentation,[0],[0]
Quick Shift often over-segments in some areas and undersegments in other areas under any hyperparameter setting and we showed the settings which provided a reasonable trade-off.,6. Image Segmentation,[0],[0]
"On the other hand Quickshift++ gives us reason-
able segmentations in many cases and can capture segments that may be problematic for other procedures.
",6. Image Segmentation,[0],[0]
"As shown in the figures, it moreover has the interesting property of being able to recover segments of widely varying shapes and sizes in the same image, which suggests that modelling the dense regions of the segments as cluster-cores instead of point-modes may be useful as we compare to Quick Shift.",6. Image Segmentation,[0],[0]
"Although this is only qualitative, it further suggests that Quickshift++ is a versatile algorithm and begins to show its potential application in many more areas.",6. Image Segmentation,[0],[0]
"We ran Quickshift++ against other clustering algorithms on the various real datasets and scored against the groundtruth using the adjusted rand index and the adjusted mutual information scores.
",7. Clustering Experiments,[0],[0]
Datasets Used: Summary of the datasets can be found in Figure 8.,7. Clustering Experiments,[0],[0]
"Seeds, glass, and iris are standard UCI datasets (Lichman, 2013) used for clustering.",7. Clustering Experiments,[0],[0]
"Banknote is another UCI dataset which involves identifying whether a banknote is forged or not, based on various statistics of an image of the banknote.",7. Clustering Experiments,[0],[0]
"Page Blocks is a UCI dataset which involves determining the type of a portion of a page (e.g. text, image, etc) based on various statistics of an image of the portion.",7. Clustering Experiments,[0],[0]
"Phonemes (Friedman et al., 2001) is a dataset which involves the log periodograms of spoken phonemes.",7. Clustering Experiments,[0],[0]
"Images is a UCI dataset called Statlog, based on features extracted from various images, and letters is the UCI letter recognition dataset.",7. Clustering Experiments,[0],[0]
"We also used a small subset of MNIST (LeCun et al., 2010) for our experiments.
",7. Clustering Experiments,[0],[0]
"We evaluate performance under the Adjusted Mutual Information and Rand Index scores (Vinh et al., 2010) which are metrics to compare clusterings.",7. Clustering Experiments,[0],[0]
"Not only do we show that Quickshift++ considerably outperforms the popular densitybased clustering procedures under optimal tuning (Figure 9), but that it is also robust in its hyperparameter k (Figure 7), all while fixing β = 0.3 for all but one of the datasets.",7. Clustering Experiments,[0],[0]
Such robustness to its tuning parameters is highly desirable since optimal tuning is usually not available in practice.,7. Clustering Experiments,[0],[0]
"We presented Quickshift++, a new density-based clustering procedure that first estimates the cluster-cores of the density, which are locally high-density regions.",8. Conclusion,[0],[0]
Then remaining points are assigned to its appropriate cluster-core using a hill-climbing procedure based on Quick Shift.,8. Conclusion,[0],[0]
Such clustercores turn out to be more stable and expressive representations of the possibly complex clusters than point-modes.,8. Conclusion,[0],[0]
"As a result, Quickshift++ enjoys the advantages of the popular density-based clustering algorithms while avoiding many of their respective weaknesses.",8. Conclusion,[0],[0]
We then gave guarantees for cluster recovery.,8. Conclusion,[0],[0]
"Finally, we showed that the algorithm has strong and robust performance on real datasets and has promising applications to image segmentation.",8. Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful feedback.,Acknowledgements,[0],[0]
"We provide initial seedings to the Quick Shift clustering algorithm, which approximate the locally high-density regions of the data.",abstractText,[0],[0]
Such seedings act as more stable and expressive cluster-cores than the singleton modes found by Quick Shift.,abstractText,[0],[0]
We establish statistical consistency guarantees for this modification.,abstractText,[0],[0]
We then show strong clustering performance on real datasets as well as promising applications to image segmentation.,abstractText,[0],[0]
Quickshift++: Provably Good Initializations for Sample-Based Mean Shift,title,[0],[0]
"Given their impressive performance on machine learning and pattern recognition tasks, Deep Neural Networks (DNNs) have recently attracted a considerable deal of attention in several applied domains such as computer vision and natural language processing; see, e.g., LeCun et al. (2015) and references therein.",1. Introduction,[0],[0]
"Deep Gaussian Processes (DGPs; Damianou & Lawrence, 2013) alleviate the outstanding issue characterizing DNNs of having to specify the number of units in hidden layers by implicitly working with infinite representations at each layer.",1. Introduction,[0],[0]
"From a generative perspective, DGPs transform the inputs using a cascade of Gaussian Processes (GPs; Rasmussen & Williams,
1Department of Data Science, EURECOM, France 2School of Computer Science and Engineering, University of New South Wales, Australia.",1. Introduction,[0],[0]
"Correspondence to: Kurt Cutajar <kurt.cutajar@eurecom.fr>, Pietro Michiardi <pietro.michiardi@eurecom.fr>, Edwin V. Bonilla",1. Introduction,[0],[0]
Cutajar <e.bonilla@unsw.edu.au,1. Introduction,[0],[0]
">, Maurizio Filippone <maurizio.filippone@eurecom.fr>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
2006) such that the output of each layer of GPs forms the input to the GPs at the next layer, effectively implementing a deep probabilistic nonparametric model for compositions of functions (Neal, 1996; Duvenaud et al., 2014).
",1. Introduction,[0],[0]
"Because of their probabilistic formulation, it is natural to approach the learning of DGPs through Bayesian inference techniques; however, the application of such techniques to learn DGPs leads to various forms of intractability.",1. Introduction,[0],[0]
"A number of contributions have been proposed to recover tractability, extending or building upon the literature on approximate methods for GPs.",1. Introduction,[0],[0]
"Nevertheless, only few works leverage one of the key features that arguably make DNNs so successful, that is being scalable through the use of minibatch-based learning (Hensman & Lawrence, 2014; Dai et al., 2016; Bui et al., 2016).",1. Introduction,[0],[0]
"Even among these works, there does not seem to be an approach that is truly applicable to large-scale problems, and practical beyond only a few hidden layers.
",1. Introduction,[0],[0]
"In this paper, we develop a practical learning framework for DGP models that significantly improves the state-of-the-art on those aspects.",1. Introduction,[0],[0]
"In particular, our proposal introduces two sources of approximation to recover tractability, while (i) scaling to large-scale problems, (ii) being able to work with moderately deep architectures, and (iii) being able to accurately quantify uncertainty.",1. Introduction,[0],[0]
"The first is a model approximation, whereby the GPs at all layers are approximated using random feature expansions (Rahimi & Recht, 2008); the second approximation relies upon stochastic variational inference to retain a probabilistic and scalable treatment of the approximate DGP model.
",1. Introduction,[0],[0]
"We show that random feature expansions for DGP models yield Bayesian DNNs with low-rank weight matrices, and the expansion of different covariance functions results in different DNN activation functions, namely trigonometric for the Radial Basis Function (RBF) covariance, and Rectified Linear Unit (ReLU) functions for the ARC-COSINE covariance.",1. Introduction,[0],[0]
"In order to retain a probabilistic treatment of the model we adapt the work on variational inference for DNNs and variational autoencoders (Graves, 2011; Kingma & Welling, 2014) using mini-batch-based stochastic gradient optimization, which can exploit GPU and distributed computing.",1. Introduction,[0],[0]
"In this respect, we can view the probabilistic treatment of DGPs approximated through random feature
expansions as a means to specify sensible and interpretable priors for probabilistic DNNs.",1. Introduction,[0],[0]
"Furthermore, unlike popular inducing points-based approximations for DGPs, the resulting learning framework does not involve any matrix decompositions in the size of the number of inducing points, but only matrix products.",1. Introduction,[0],[0]
"We implement our model in TensorFlow (Abadi et al., 2015), which allows us to rely on automatic differentiation to apply stochastic variational inference.
",1. Introduction,[0],[0]
"Although having to select the appropriate number of random features goes against the nonparametric formulation favored in GP models, the level of approximation can be tuned based on constraints on running time or hardware.",1. Introduction,[0],[0]
"Most importantly, the random feature approximation enables us to develop a learning framework for DGPs which significantly advances the state-of-the-art.",1. Introduction,[0],[0]
We extensively demonstrate the effectiveness of our proposal on a variety of regression and classification problems by comparing it with DNNs and other state-of-the-art approaches to infer DGPs.,1. Introduction,[0],[0]
"The results indicate that for a given DGP architecture, our proposal is consistently faster at achieving better generalization compared to the competitors.",1. Introduction,[0],[0]
"Another key observation is that the proposed DGP outperforms DNNs trained with dropout when quantifying uncertainty.
",1. Introduction,[0],[0]
"We focus part of the experiments on large-scale problems, such as MNIST8M digit classification and the AIRLINE dataset, which contain over 8 and 5 million observations, respectively.",1. Introduction,[0],[0]
"Only very recently there have been attempts to demonstrate performance of GP models on such large data sets (Wilson et al., 2016; Krauth et al., 2016), and our proposal is on par with these latest GP methods.",1. Introduction,[0],[0]
"Furthermore, we obtain impressive results when employing our learning framework to DGPs with moderate depth (few tens of layers) on the AIRLINE dataset.",1. Introduction,[0],[0]
We are not aware of any other DGP models having such depth that can achieve comparable performance when applied to datasets with millions of observations.,1. Introduction,[0],[0]
"Crucially, we obtain all these results by running our algorithm on a single machine without GPUs, but our proposal is designed to be able to exploit GPU and distributed computing to significantly accelerate our deep probabilistic learning framework (see supplement for experiments in distributed mode).
",1. Introduction,[0],[0]
"In summary, the most significant contributions of this work are as follows: (i) we propose a novel approximation of DGPs based on random feature expansions that we study in connection with DNNs; (ii) we demonstrate the ability of our proposal to systematically outperform state-of-theart methods to carry out inference in DGP models, especially for large-scale problems and moderately deep architectures; (iii) we validate the superior quantification of uncertainty offered by DGPs compared to DNNs.",1. Introduction,[0],[0]
"Following the original proposal of DGP models in Damianou & Lawrence (2013), there have been several attempts to extend GP inference techniques to DGPs.",1.1. Related work,[0],[0]
"Notable examples include the extension of inducing point approximations (Hensman & Lawrence, 2014; Dai et al., 2016) and Expectation Propagation (Bui et al., 2016).",1.1. Related work,[0],[0]
Sequential inference for training DGPs has also been investigated in Wang et al. (2016).,1.1. Related work,[0],[0]
A recent example of a DGP “natively” formulated as a variational model appears in Tran et al. (2016).,1.1. Related work,[0],[0]
Our work is the first to employ random feature expansions to approximate DGPs as DNNs.,1.1. Related work,[0],[0]
"The expansion of the squared exponential covariance for DGPs leads to trigonometric DNNs, whose properties were studied in Sopena et al. (1999).",1.1. Related work,[0],[0]
"Meanwhile, the expansion of the arccosine covariance is inspired by Cho & Saul (2009), and it allows us to show that DGPs with such covariance can be approximated with DNNs having ReLU activations.
",1.1. Related work,[0],[0]
"The connection between DGPs and DNNs has been pointed out in several papers, such as Neal (1996) and Duvenaud et al. (2014), where pathologies with deep nets are investigated.",1.1. Related work,[0],[0]
"The approximate DGP model described in our work becomes a DNN with low-rank weight matrices, which have been used in, e.g., Novikov et al. (2015); Sainath et al. (2013); Denil et al. (2013) as a regularization mechanism.",1.1. Related work,[0],[0]
"Dropout is another technique to speed-up training and improve generalization of DNNs that has recently been linked to variational inference (Gal & Ghahramani, 2016).
",1.1. Related work,[0],[0]
"Random Fourier features for large scale kernel machines were proposed in Rahimi & Recht (2008), and their application to GPs appears in Lázaro-Gredilla et al. (2010).",1.1. Related work,[0],[0]
"In the case of squared exponential covariances, variational learning of the posterior over the frequencies was proposed in Gal & Turner (2015) to avoid potential overfitting caused by optimizing these variables.",1.1. Related work,[0],[0]
"These approaches are special cases of our DGP model when using no hidden layers.
",1.1. Related work,[0],[0]
"In our work, we learn the proposed approximate DGP model using stochastic variational inference.",1.1. Related work,[0],[0]
"Variational learning for DNNs was first proposed in Graves (2011), and later extended to include the reparameterization trick to clamp randomness in the computation of the gradient with respect to the posterior over the weights (Kingma & Welling, 2014; Rezende et al., 2014), and to include a Gaussian mixture prior over the weights (Blundell et al., 2015).",1.1. Related work,[0],[0]
Consider a supervised learning scenario where a set of input vectors X =,2. Preliminaries,[0],[0]
"[x1, . . .",2. Preliminaries,[0],[0]
",xn]⊤ is associated with a set of (possibly multivariate) labels Y =",2. Preliminaries,[0],[0]
"[y1, . . .",2. Preliminaries,[0],[0]
",yn]⊤, where xi ∈ RDin and yi ∈ RDout .",2. Preliminaries,[0],[0]
"We assume that there is an underlying function fo(xi) characterizing a mapping from the
inputs to a latent representation, and that the labels are a realization of some probabilistic process p(yio|fo(xi)) which is based on this latent representation.
",2. Preliminaries,[0],[0]
"In this work, we consider modeling the latent functions using Deep Gaussian Processes (DGPs; Damianou & Lawrence, 2013).",2. Preliminaries,[0],[0]
Let variables in layer l be denoted by the (l) superscript.,2. Preliminaries,[0],[0]
"In DGP models, the mapping between inputs and labels is expressed as a composition of functions
f(x) =",2. Preliminaries,[0],[0]
( f (Nh−1) ◦ . . .,2. Preliminaries,[0],[0]
◦,2. Preliminaries,[0],[0]
f (0) ),2. Preliminaries,[0],[0]
"(x),
where each of the Nh layers is composed of a (possibly transformed) multivariate Gaussian process (GP).",2. Preliminaries,[0],[0]
"Formally, a GP is a collection of random variables such that any subset of these are jointly Gaussian distributed (Rasmussen & Williams, 2006).",2. Preliminaries,[0],[0]
"In GPs, the covariance between variables at different inputs is modeled using the so-called covariance function.
",2. Preliminaries,[0],[0]
"Given the relationship between GPs and single-layered neural networks with an infinite number of hidden units (Neal, 1996), the DGP model has an obvious connection with DNNs.",2. Preliminaries,[0],[0]
"In contrast to DNNs, where each of the hidden layers implements a parametric function of its inputs, in DGPs these functions are assigned a GP prior, and are therefore nonparametric.",2. Preliminaries,[0],[0]
"Furthermore, because of their probabilistic formulation, it is natural to approach the learning of DGPs through Bayesian inference techniques that lead to principled approaches for both determining the optimal settings of architecture-dependent parameters, such as the number of hidden layers, and quantification of uncertainty.
",2. Preliminaries,[0],[0]
"While DGPs are attractive from a theoretical standpoint, inference is extremely challenging.",2. Preliminaries,[0],[0]
Denote by F (l) the set of latent variables with entries f,2. Preliminaries,[0],[0]
"(l)io = f (l) o (xi), and let p(Y |F (Nh)) be the conditional likelihood.",2. Preliminaries,[0],[0]
Learning and making predictions with DGPs requires solving integrals that are generally intractable.,2. Preliminaries,[0],[0]
"For example, computing the marginal likelihood to optimize covariance parameters θ(l) at all layers entails solving
p(Y |X,θ)",2. Preliminaries,[0],[0]
= ∫ p,2. Preliminaries,[0],[0]
"( Y |F (Nh) ) p ( F (Nh)|F (Nh−1),θ(Nh−1) )",2. Preliminaries,[0],[0]
× . .,2. Preliminaries,[0],[0]
.×,2. Preliminaries,[0],[0]
p,2. Preliminaries,[0],[0]
"( F (1)|X,θ(0) ) dF (Nh) . . .",2. Preliminaries,[0],[0]
"dF (1).
",2. Preliminaries,[0],[0]
In the following section we use random feature approximations to the covariance function in order to develop a scalable algorithm for inference in DGPs.,2. Preliminaries,[0],[0]
We start by describing how random feature expansions can be used to approximate the covariance of a single GP model.,2.1. Random Feature Expansions for GPs,[0],[0]
"Such approximations have been considered previously, for example by Rahimi & Recht (2008) in the context of non-probabilistic kernel machines.",2.1. Random Feature Expansions for GPs,[0],[0]
"Here we focus
on random feature expansions for the radial basis function (RBF) covariance and the ARC-COSINE covariance, which we will use in our experiments.
",2.1. Random Feature Expansions for GPs,[0],[0]
"For the sake of clarity, we will present the covariances without any explicit scaling of the features or the covariance itself.",2.1. Random Feature Expansions for GPs,[0],[0]
"After explaining the random feature expansion associated with each covariance, we will generalize these results in the context of DGPs to include scaling the covariance by a factor σ2, and scaling the features for Automatic Relevance Determination (ARD) (Mackay, 1994).",2.1. Random Feature Expansions for GPs,[0],[0]
"A popular example of a covariance function, which we consider here, is the Radial Basis Function (RBF) covariance
krbf(x,x ′)",2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
= exp [ −1 2 ∥x− x′∥⊤ ] .,2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
"(1)
Appealing to Bochner’s theorem, any continuous shiftinvariant normalized covariance function k(xi,xj) = k(xi−xj) is positive definite if and only if it can be rewritten as the Fourier transform of a non-negative measure p(ω) (Rahimi & Recht, 2008).",2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
"Denoting the spectral frequencies by ω, while assigning ι = √ −1",2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
"and δ = xi−xj , in the case of the RBF covariance in equation (1), this yields:
krbf(δ) =
∫ p(ω) exp ( ιδ⊤ω ) dω, (2)
with a corresponding non-negative measure p(ω) = N (0, I).",2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
"Because the covariance function and the nonnegative measures are real, we can drop the unnecessary complex part of the argument of the expectation, keeping cos(δ⊤ω) =",2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
cos((xi − xj)⊤ω) that can be rewritten as cos(x⊤i ω),2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
cos(x ⊤ j ω),2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
+ sin(x ⊤ i ω),2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
"sin(x ⊤ j ω).
",2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
The importance of the expansion above is that it allows us to interpret the covariance function as an expectation that can be estimated using Monte Carlo.,2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
Defining z(x|ω) =,2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
"[cos(x⊤ω), sin(x⊤ω)]⊤, the covariance function can be therefore unbiasedly approximated as
krbf(xi,xj)",2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
"≈ 1
NRF NRF∑ r=1 z(xi|ω̃r)⊤z(xj |ω̃r), (3)
with ω̃r ∼ p(ω).",2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
"This has an important practical implication, as it provides the means to access an approximate explicit representation of the mapping induced by the covariance function that, in the RBF case, is infinite dimensional (Shawe-Taylor & Cristianini, 2004).",2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
"Various results have been established on the accuracy of the random Fourier feature approximation; see, e.g., Rahimi & Recht (2008).",2.1.1. RADIAL BASIS FUNCTION COVARIANCE,[0],[0]
"We also consider the ARC-COSINE covariance of order p
k(p)arc (x,x ′) =
1 π (∥x∥ ∥x′∥)p Jp
( cos−1 ( x⊤x′
∥x∥∥x′∥
)) ,
(4) where we have defined
Jp(α) =",2.1.2. ARC-COSINE COVARIANCE,[0],[0]
"(−1)p(sinα)2p+1 ( 1
sinα
∂
∂α )p ( π − α sinα ) .
",2.1.2. ARC-COSINE COVARIANCE,[0],[0]
Let H(·) be the Heaviside function.,2.1.2. ARC-COSINE COVARIANCE,[0],[0]
"Following Cho & Saul (2009), an integral representation of this covariance is:
k(p)arc (x,x ′) = 2
∫ H(ω⊤x) ( ω⊤x )p H(ω⊤x′) ( ω⊤x′ )",2.1.2. ARC-COSINE COVARIANCE,[0],[0]
"p ×N (ω|0, I)dω.",2.1.2. ARC-COSINE COVARIANCE,[0],[0]
"(5)
This integral formulation immediately suggests a random feature approximation for the ARC-COSINE covariance in equation (4), noting that it can be seen as an expectation of the product of the same function applied to the inputs to the covariance.",2.1.2. ARC-COSINE COVARIANCE,[0],[0]
"As before, this provides an approximate explicit representation of the mapping induced by the covariance function.",2.1.2. ARC-COSINE COVARIANCE,[0],[0]
"Interestingly, for the ARC-COSINE covariance of order p = 1, this yields an approximation based on popular Rectified Linear Unit (ReLU) functions.",2.1.2. ARC-COSINE COVARIANCE,[0],[0]
We note that when p = 0,2.1.2. ARC-COSINE COVARIANCE,[0],[0]
"the resulting Heaviside activations are unsuitable for our inference scheme, given that they yield systematically zero gradients.",2.1.2. ARC-COSINE COVARIANCE,[0],[0]
"In this section, we present our approximate formulation of DGPs which, as we illustrate in the experiments, leads to a practical learning algorithm for these deep probabilistic
nonparametric models.",3. Random Feature Expansions for DGPs,[0],[0]
"We propose to employ the random feature expansion at each layer, and by doing so we obtain an approximation to the original DGP model as a DNN (Figure 1).
",3. Random Feature Expansions for DGPs,[0],[0]
"Assume that the GPs have zero mean, and define F (0) := X .",3. Random Feature Expansions for DGPs,[0],[0]
"Also, assume that the GP covariances at each layer are parameterized through a set of parameters θ(l).",3. Random Feature Expansions for DGPs,[0],[0]
"The parameter set θ(l) comprises the layer-wise GP marginal variances (σ2)(l) and lengthscale parameters Λ(l) = diag((ℓ21)
(l), . . .",3. Random Feature Expansions for DGPs,[0],[0]
", (ℓ2 D
(l) F
)(l)).
",3. Random Feature Expansions for DGPs,[0],[0]
"Considering a DGP with RBF covariances, taking a “weightspace view” of the GPs at each layer, and extending the results in the previous section, we have that
Φ (l) rbf =
√ (σ2)(l)
N (l) RF
[ cos ( F (l)Ω(l) ) , sin ( F (l)Ω(l) )] ,
(6) and F (l+1) = Φ(l)rbfW",3. Random Feature Expansions for DGPs,[0],[0]
(l).,3. Random Feature Expansions for DGPs,[0],[0]
"At each layer, the priors over the
weights are p ( Ω
(l) ·j
)",3. Random Feature Expansions for DGPs,[0],[0]
"= N ( 0, ( Λ(l) )−1)",3. Random Feature Expansions for DGPs,[0],[0]
"and p ( W
(l) ·i
) =
N (0, I).",3. Random Feature Expansions for DGPs,[0],[0]
Each matrix Ω(l) has dimensions DF (l) × N (l) RF.,3. Random Feature Expansions for DGPs,[0],[0]
"On the other hand, the weight matrices W (l) have dimensions 2N (l)RF × DF (l+1) (weighting of sine and cosine random features), with the constraint that DF (Nh) = Dout.
Similarly, considering a DGP with ARC-COSINE covariances of order p = 1, the application of the random feature approximation leads to DNNs with ReLU activations:
Φ(l)arc =
√ 2(σ2)(l)
N (l) RF
max ( 0, F (l)Ω(l) ) , (7)
with Ω(l)·j ∼ N ( 0, ( Λ(l) )−1) , which are cheaper to evaluate and differentiate than the trigonometric functions required in the RBF case.",3. Random Feature Expansions for DGPs,[0],[0]
"As in the RBF case, we allowed the covariance and the features to be scaled by (σ2)(l) and Λ(l), respectively.",3. Random Feature Expansions for DGPs,[0],[0]
"The dimensions of the weight matrices Ω(l) are the same as in the RBF case, but the dimensions of the W (l) matrices are N (l)RF ×DF",3. Random Feature Expansions for DGPs,[0],[0]
(l+1) .,3. Random Feature Expansions for DGPs,[0],[0]
Our formulation of an approximate DGP using random feature expansions reveals a close connection with DNNs.,3.1. Low-rank weights in the resulting DNN,[0],[0]
"In our formulation, the design matrices at each layer are Φ(l+1)",3.1. Low-rank weights in the resulting DNN,[0],[0]
"= γ ( Φ(l)W (l)Ω(l+1) ) , where γ(·) denotes the element-wise application of covariance-dependent functions, i.e., sine and cosine for the RBF covariance and ReLU for the ARC-COSINE covariance.",3.1. Low-rank weights in the resulting DNN,[0],[0]
"Instead, for the DNN case, the design matrices are computed as Φ(l+1) = g(Φ(l)Ω(l)), where g(·) is a so-called activation function.",3.1. Low-rank weights in the resulting DNN,[0],[0]
"In light of this, we can view our approximate DGP model as a DNN.",3.1. Low-rank weights in the resulting DNN,[0],[0]
"From a probabilistic standpoint, we can interpret our approximate
DGP model as a DNN with specific Gaussian priors over the Ω(l) weights controlled by the covariance parameters θ(l), and standard Gaussian priors over the W (l) weights.",3.1. Low-rank weights in the resulting DNN,[0],[0]
"Covariance parameters act as hyper-priors over the weights Ω(l), and the objective is to optimize these during training.
",3.1. Low-rank weights in the resulting DNN,[0],[0]
"Another observation about the resulting DGP approximation is that, for a given layer l, the transformations given by W (l) and Ω(l+1) are both linear.",3.1. Low-rank weights in the resulting DNN,[0],[0]
"If we collapsed the two transformations into a single one, by introducing weights Ξ(l) = W (l)Ω(l+1), we would have to learn O ( N
(l) RF ×N (l+1) RF
) weights at each layer, which is con-
siderably more than learning the two separate sets of weights.",3.1. Low-rank weights in the resulting DNN,[0],[0]
"As a result, we can view the proposed approximate DGP model as a way to impose a low-rank structure on the weights of DNNs, which is a form of regularization proposed in the literature of DNNs (Novikov et al., 2015; Sainath et al., 2013; Denil et al., 2013).",3.1. Low-rank weights in the resulting DNN,[0],[0]
"In order to keep the notation uncluttered, let Θ be the collection of all covariance parameters θ(l) at all layers.",3.2. Variational inference,[0],[0]
"Also, consider the case of a DGP with fixed spectral frequencies Ω(l) collected into Ω, and let W be the collection of the weight matrices W (l) at all layers.",3.2. Variational inference,[0],[0]
For W we have a product of standard normal priors stemming from the approximation of the GPs at each layer p(W) =,3.2. Variational inference,[0],[0]
"∏Nh−1 l=0 p(W
(l)), and we propose to treat W using variational inference following Kingma & Welling (2014) and Graves (2011), and optimize all covariance parameters Θ. We will consider Ω to be fixed here, but we will discuss alternative ways to treat Ω in the next section.",3.2. Variational inference,[0],[0]
"In the supplement we also assess the quality of the variational approximation over W, with Ω and Θ fixed, by comparing it with MCMC techniques.
",3.2. Variational inference,[0],[0]
"The marginal likelihood p(Y |X,Ω,Θ) involves intractable integrals, but we can obtain a tractable lower bound using variational inference.",3.2. Variational inference,[0],[0]
"Defining L = log [p(Y |X,Ω,Θ)] and E = Eq(W) (log [p (Y |X,W,Ω,Θ)]), we obtain
L ≥ E −DKL",3.2. Variational inference,[0],[0]
"[q(W)∥p (W)] , (8)
where q(W) acts as an approximation to the posterior over all the weights p(W|Y,X,Ω,Θ).
",3.2. Variational inference,[0],[0]
"We are interested in optimizing q(W), i.e. finding an optimal approximate distribution over the parameters according to the bound above.",3.2. Variational inference,[0],[0]
"The first term can be interpreted as a model fitting term, whereas the second as a regularization term.",3.2. Variational inference,[0],[0]
"In the case of a Gaussian distribution q(W) and a Gaussian prior p(W), it is possible to compute the DKL term analytically (see supplementary material), whereas the remaining term needs to be estimated.",3.2. Variational inference,[0],[0]
"Assume a Gaussian approximating distribution that factorizes across layers
and weights:
q(W) = ∏ ijl q",3.2. Variational inference,[0],[0]
( W (l) ij ),3.2. Variational inference,[0],[0]
"= ∏ ijl N ( m (l) ij , (s 2) (l) ij ) .",3.2. Variational inference,[0],[0]
"(9)
",3.2. Variational inference,[0],[0]
"The variational parameters are the mean and the variance of each of the approximating factors m(l)ij , (s 2) (l) ij , and we aim to optimize the lower bound with respect to these as well as all covariance parameters Θ.
In the case of a likelihood that factorizes across observations, an interesting feature of the expression of the lower bound is that it is amenable to fast stochastic optimization.",3.2. Variational inference,[0],[0]
"In particular, we derive a doubly-stochastic approximation of the expectation in the lower bound as follows.",3.2. Variational inference,[0],[0]
"First, E can be rewritten as a sum over the input points, which allows us to estimate it in an unbiased fashion using minibatches, selecting m points indexed by Im:
E",3.2. Variational inference,[0],[0]
"≈ n m ∑ k∈Im Eq(W)(log[p(yk|xk,W,Ω,Θ)]).",3.2. Variational inference,[0],[0]
"(10)
Second, each of the elements of the sum can be estimated using NMC Monte Carlo samples, yielding:
E ≈ n m ∑ k∈Im 1 NMC NMC∑ r=1",3.2. Variational inference,[0],[0]
"log[p(yk|xk,W̃r,Ω,Θ)], (11)
",3.2. Variational inference,[0],[0]
with W̃r ∼ q(W).,3.2. Variational inference,[0],[0]
"In order to facilitate the optimization, we reparameterize the weights as follows:
(W̃ (l)r )ij = s (l) ij ϵ",3.2. Variational inference,[0],[0]
(l) rij,3.2. Variational inference,[0],[0]
+m (l) ij .,3.2. Variational inference,[0],[0]
"(12)
",3.2. Variational inference,[0],[0]
"By differentiating the lower bound with respect to Θ and the mean and variance of the approximate posterior over W, we obtain an unbiased estimate of the gradient for the lower bound.",3.2. Variational inference,[0],[0]
"The reparameterization trick ensures that the randomness in the computation of the expectation is fixed when applying stochastic gradient ascent moves to the parameters of q(W) and Θ (Kingma & Welling, 2014).",3.2. Variational inference,[0],[0]
"Automatic differentiation tools enabled us to compute stochastic gradients automatically, which is why we opted to implement our model in TensorFlow (Abadi et al., 2015).",3.2. Variational inference,[0],[0]
"So far, we have assumed the spectral frequencies Ω to be sampled from the prior and fixed throughout, whereby we employ the reparameterization trick to obtain Ω(l)ij = (β2) (l) ij ε",3.3. Treatment of the spectral frequencies Ω,[0],[0]
(l) rij + µ,3.3. Treatment of the spectral frequencies Ω,[0],[0]
"(l) ij , with (β 2) (l) ij and µ (l) ij determined by the
prior p ( Ω
(l) ·j
)",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"= N ( 0, ( Λ(l) )−1) .",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"We then draw the
ε (l) rij’s and fix them from the outset, such that covariance parameters Θ can be optimized along with q(W).",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"We refer to this variant as PRIOR-FIXED.
",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"Inspired by previous work on random feature expansions for GPs, we can think of alternative ways to treat these parameters, e.g., Lázaro-Gredilla et al. (2010); Gal & Turner (2015).",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"In particular, we study a variational treatment of Ω; we refer the reader to the supplementary material for details on the derivation of the lower bound in this case.",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"When being variational about Ω, we introduce an approximate posterior q(Ω) which also has a factorized form.",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"We use the reparameterization trick once again, but Ω are now sampled from the posterior, which in general has different mean and variances to the prior.",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"We report two variations of this treatment, namely VAR-FIXED and VAR-RESAMPLED.",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"In VAR-FIXED, we fix ε(l)rij in computing Ω throughout the learning of the model, whereas in VAR-RESAMPLED we resample these at each iteration.",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"We note that one can also be variational about Θ, but we leave this for future work.
",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"In Figure 2, we illustrate the differences between the strategies discussed in this section; we report the accuracy of the proposed one-layer DGP with RBF covariances with respect to the number of random features on one of the datasets that we consider in the experiment section (EEG dataset).",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"For PRIOR-FIXED, more random features result in a better approximation of the GP priors at each layer, and this results in better generalization.",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"When we resample Ω from the approximate posterior (VAR-RESAMPLED), we notice that the model quickly struggles with the optimization when increasing the number of random features.",3.3. Treatment of the spectral frequencies Ω,[0],[0]
We attribute this to the fact that the factorized form of the posterior over Ω and W is unable to capture posterior correlations between the coefficients for the random features and the weights of the corresponding linearized model.,3.3. Treatment of the spectral frequencies Ω,[0],[0]
"Being deterministic about the way spectral frequencies are computed (VARFIXED) offers the best performance among the three learning strategies, and this is what we employ throughout the rest of this paper.",3.3. Treatment of the spectral frequencies Ω,[0],[0]
"When estimating the lower bound, there are two main operations performed at each layer, that is F (l)Ω(l) and Φ(l)W (l).",3.4. Computational complexity,[0],[0]
"Recalling that this matrix product is done for
samples from the posterior over W (and Ω when treated variationally) and given the mini-batch formulation, the former costs O ( mD
(l) F N (l) RFNMC
) , while the latter costs
O ( mN
(l) RFD (l) F NMC
) .
",3.4. Computational complexity,[0],[0]
"Because of feature expansions and stochastic variational inference, the resulting algorithm does not involve any Cholesky decompositions.",3.4. Computational complexity,[0],[0]
"This is in sharp contrast with stochastic variational inference using inducing-point approximations (see e.g. Dai et al., 2016; Bui et al., 2016), where such operations could significantly limit the number of inducing points that can be employed.",3.4. Computational complexity,[0],[0]
"We evaluate our model by comparing it against relevant alternatives for both regression and classification, and assess its performance when applied to large-scale datasets.",4. Experiments,[0],[0]
We also investigate the extent to which such deep compositions continue to yield good performance when the number of layers is significantly increased.,4. Experiments,[0],[0]
"We primarily compare our model to the state-of-the-art DGP inference method presented in the literature, namely DGPs using expectation propagation (DGP-EP; Bui et al., 2016).",4.1. Model Comparison,[0],[0]
"We originally intended to include results for the variational auto-encoded DGP (Damianou & Lawrence, 2013); however, the results obtained using the available code were not competitive with DGP-EP and we thus decided to exclude them from the figures.",4.1. Model Comparison,[0],[0]
"We also omitted DGP training using sequential inference (Wang et al., 2016) given that we could not find an implementation of the method and, in any case, the performance reported in the paper is inferior to more recent approaches.",4.1. Model Comparison,[0],[0]
"We also compare against DNNs in order to present the results in a wider context, and demonstrate that DGPs lead to better quantification of uncertainty.",4.1. Model Comparison,[0],[0]
"Finally, to substantiate the benefits of using a deep model, we compare against the shallow sparse variational GP (Hensman et al., 2015b) implemented in GPflow (Matthews et al., 2016).
",4.1. Model Comparison,[0],[0]
"We use the same experimental set-up for both regression and classification tasks using datasets from the UCI repository (Asuncion & Newman, 2007), for models having one hidden layer.",4.1. Model Comparison,[0],[0]
The results for architectures with two hidden layers are included in the supplementary material.,4.1. Model Comparison,[0],[0]
"The specific configurations for each model are detailed below:
DGP-RBF, DGP-ARC :",4.1. Model Comparison,[0],[0]
"In the proposed DGP with an RBF kernel, we use 100 random features at every hidden layer to construct a multivariate GP with D(l)F = 3, and set the batch size to m = 200.",4.1. Model Comparison,[0],[0]
"We initially only use a single
Monte Carlo sample, and halfway through the allocated optimization time, this is then increased to 100 samples.",4.1. Model Comparison,[0],[0]
"We employ the Adam optimizer (Kingma & Ba, 2015) with a learning rate of 0.01, and in order to stabilize the optimization procedure, we fix the parameters Θ for 12, 000 iterations, before jointly optimizing all parameters.",4.1. Model Comparison,[0],[0]
"As discussed in Section 3.3, Ω are optimized variationally with fixed randomness.",4.1. Model Comparison,[0],[0]
"The same set-up is used for DGP-ARC, the variation of our model using the ARC-COSINE kernel;
DGP-EP 1: For this technique, we use the same architecture and optimizer as for DGP-RBF and DGP-ARC, a batch size of 200 and 100 inducing points at each hidden layer.",4.1. Model Comparison,[0],[0]
"For the classification case, we use 100 samples for approximating the Softmax likelihood;
DNN : We construct a DNN configured with a dropout rate of 0.5 at each hidden layer in order to provide regularization during training.",4.1. Model Comparison,[0],[0]
"In order to preserve a degree of fairness, we set the number of hidden units in such a way as to ensure that the number of weights to be optimized match those in the DGP-RBF and DGP-ARC models when the random features are taken to be fixed.
",4.1. Model Comparison,[0],[0]
We assess the performance of each model using the error rate (RMSE in the regression case) and mean negative loglikelihood (MNLL) on withheld test data.,4.1. Model Comparison,[0],[0]
The results are averaged over 3 folds for every dataset.,4.1. Model Comparison,[0],[0]
"The experiments were launched on single nodes of a cluster of Intel Xeon E5-2630 CPUs having 32 cores and 128GB RAM.
",4.1. Model Comparison,[0],[0]
Figure 3 shows that DGP-RBF and DGP-ARC consistently outperform competing techniques both in terms of convergence speed and predictive accuracy.,4.1. Model Comparison,[0],[0]
"This is particu-
1Code obtained from: github.com/thangbui/deepGP_approxEP
larly significant for larger datasets where other techniques take considerably longer to converge to a reasonable error rate, although DGP-EP converges to superior MNLL for the PROTEIN dataset.",4.1. Model Comparison,[0],[0]
The results are also competitive (and sometimes superior) to those obtained by the variational GP (VAR-GP) in Hensman et al. (2015b).,4.1. Model Comparison,[0],[0]
"It is striking to see how inferior uncertainty quantification provided by the DNN (which is inherently limited to the classification case, so no MNLL reported on regression datasets) is compared to DGPs, despite the error rate being comparable.
",4.1. Model Comparison,[0],[0]
"By virtue of its higher dimensionality, larger configurations were used for MNIST.",4.1. Model Comparison,[0],[0]
"For DGP-RBF and DGP-ARC, we use 500 random features, 50 GPs in the hidden layers, batch size of 1000, and Adam with a 0.001 learning rate.",4.1. Model Comparison,[0],[0]
"Similarly for DGP-EP, we use 500 inducing points, with the only difference being a slightly smaller batch size to cater for issues with memory requirements.",4.1. Model Comparison,[0],[0]
"Following Simard et al. (2003), we employ 800 hidden units at each layer of the DNN.",4.1. Model Comparison,[0],[0]
The DGP-RBF peaks at 98.04% and 97.93% for 1 and 2 hidden layers respectively.,4.1. Model Comparison,[0],[0]
It was observed that the model performance degrades noticeably when more than 2 hidden layers are used (without feeding forward the inputs).,4.1. Model Comparison,[0],[0]
"This is in line with what is reported in the literature on DNNs (Neal, 1996; Duvenaud et al., 2014).",4.1. Model Comparison,[0],[0]
"By simply re-introducing the original inputs in the hidden layer, the accuracy improves to 98.2% for the one hidden layer case.
",4.1. Model Comparison,[0],[0]
"Recent experiments on MNIST using a variational GP with MCMC report overall accuracy of 98.04% (Hensman et al., 2015a), while the AutoGP architecture has been shown to give 98.45% accuracy (Krauth et al., 2016).",4.1. Model Comparison,[0],[0]
"Using a finer-tuned configuration, DNNs were also shown to obtain 98.5% accuracy (Simard et al., 2003), whereas 98.6% has been reported for SVMs (Schölkopf, 1997).",4.1. Model Comparison,[0],[0]
"In view of this wider scope of inference techniques, it can be confirmed
that the results obtained using the proposed architecture are comparable to the state-of-the-art, even if further extensions may be required for obtaining a proper edge.",4.1. Model Comparison,[0],[0]
"Note that this comparison focuses on approaches without preprocessing, and excludes convolutional neural nets.",4.1. Model Comparison,[0],[0]
One of the defining characteristics of our model is the ability to scale up to large datasets without compromising on performance and accuracy in quantifying uncertainty.,4.2. Large-scale Datasets,[0],[0]
"As a demonstrative example, we evaluate our model on two large-scale problems which go beyond the scale of datasets to which GPs and especially DGPs are typically applied.
",4.2. Large-scale Datasets,[0],[0]
"We first consider MNIST8M, which artificially extends the original MNIST dataset to 8+ million observations.",4.2. Large-scale Datasets,[0],[0]
"We trained this model using the same configuration described for standard MNIST, and we obtained 99.14% accuracy on the test set using one hidden layer.",4.2. Large-scale Datasets,[0],[0]
"Given the size of this dataset, there are only few reported results for other GP models.",4.2. Large-scale Datasets,[0],[0]
"Most notably, Krauth et al. (2016) recently obtained 99.11% accuracy with the AutoGP framework, which is comparable to the result obtained by our model.
",4.2. Large-scale Datasets,[0],[0]
"Meanwhile, the AIRLINE dataset contains flight information for 5+ million US flights.",4.2. Large-scale Datasets,[0],[0]
"Following the procedure described in Hensman et al. (2013) and Wilson et al. (2016), we use this 8-dimensional dataset for classification, where the task is to determine whether a flight has been delayed or not.",4.2. Large-scale Datasets,[0],[0]
"We construct the test set using the scripts provided in Wilson et al. (2016), where 100, 000 data points are heldout for testing.",4.2. Large-scale Datasets,[0],[0]
"We construct our DGP models using 100 random features at each layer, and set the dimensionality to DF (l) = 3.",4.2. Large-scale Datasets,[0],[0]
"As shown in Table 1, our model works significantly better when using the RBF kernel.",4.2. Large-scale Datasets,[0],[0]
"In addition, the results are also directly comparable to those obtained by Wilson et al. (2016), which reports accuracy and MNLL of 78.1% and 0.457, respectively.",4.2. Large-scale Datasets,[0],[0]
"Finally, we assess the scalability of our model with respect to additional hidden layers in the constructed model.",4.3. Model Depth,[0],[0]
"In particular, we re-consider the AIRLINE dataset and evaluate the performance of DGP-RBF models constructed using up to 30 layers.",4.3. Model Depth,[0],[0]
"In order to cater for the increased depth in the
model, we feed-forward the original input to each hidden layer, as suggested in Duvenaud et al. (2014).
",4.3. Model Depth,[0],[0]
"Figure 4 reports the progression of error rate and MNLL over time for different number of hidden layers, using the results obtained in Wilson et al. (2016) as a baseline (reportedly obtained in about 3 hours).",4.3. Model Depth,[0],[0]
"As expected, the model takes longer to train as the number of layers increases.",4.3. Model Depth,[0],[0]
"However, the model converges to an optimal state in every case in less than a couple of hours, with an improvement being noted in the case of 10 and 20 layers over the shallower 2-layer model.",4.3. Model Depth,[0],[0]
The box plot within the same figure indicates that the negative lower bound is a suitable objective function for carrying out model selection.,4.3. Model Depth,[0],[0]
"In this work, we have proposed a novel formulation of DGPs which exploits the approximation of covariance functions using random features, as well as stochastic variational inference for preserving the probabilistic representation of a regular GP.",5. Conclusions,[0],[0]
"We demonstrated how inference using this model is not only faster, but also frequently superior to other state-of-the-art methods, with particular emphasis on competing DGP models.",5. Conclusions,[0],[0]
The results obtained for both the AIRLINE dataset and the MNIST8M digit recognition problem are particularly impressive since such large datasets have been generally considered to be beyond the computational scope of DGPs.,5. Conclusions,[0],[0]
"We perceive this to be a considerable step forward in the direction of scaling and accelerating DGPs.
",5. Conclusions,[0],[0]
"The results obtained on higher-dimensional datasets strongly suggest that approximations such as Fastfood (Le et al., 2013) could be instrumental in the interest of using more random features.",5. Conclusions,[0],[0]
We are also currently investigating ways to mitigate the decline in performance observed when optimizing Ω variationally with resampling.,5. Conclusions,[0],[0]
The obtained results also encourage the extension of our model to include convolutional layers suitable for computer vision applications.,5. Conclusions,[0],[0]
MF gratefully acknowledges support from the AXA Research Fund.,ACKNOWLEDGEMENTS,[0],[0]
PM was partially supported by the EU project H2020-644182,ACKNOWLEDGEMENTS,[0],[0]
“IOStack”.,ACKNOWLEDGEMENTS,[0],[0]
The composition of multiple Gaussian Processes as a Deep Gaussian Process (DGP) enables a deep probabilistic nonparametric approach to flexibly tackle complex machine learning problems with sound quantification of uncertainty.,abstractText,[0],[0]
Existing inference approaches for DGP models have limited scalability and are notoriously cumbersome to construct.,abstractText,[0],[0]
In this work we introduce a novel formulation of DGPs based on random feature expansions that we train using stochastic variational inference.,abstractText,[0],[0]
"This yields a practical learning framework which significantly advances the state-of-the-art in inference for DGPs, and enables accurate quantification of uncertainty.",abstractText,[0],[0]
"We extensively showcase the scalability and performance of our proposal on several datasets with up to 8 million observations, and various DGP architectures with up to 30 hidden layers.",abstractText,[0],[0]
Random Feature Expansions for Deep Gaussian Processes,title,[0],[0]
Kernel methods constitute a powerful paradigm for devising non-parametric modeling techniques for a wide range of problems in machine learning.,1. Introduction,[0],[0]
One of the most elementary is Kernel Ridge Regression (KRR).,1. Introduction,[0],[0]
"Given training data (x
1 , y 1 ), . . .",1. Introduction,[0],[0]
", (x n , y n ) 2 X ⇥Y , where X ✓ Rd is an input domain and Y ✓ R is an output domain, a positive definite kernel function",1. Introduction,[0],[0]
k : X ⇥ X !,1. Introduction,[0],[0]
"R, and a regularization parameter > 0, the response for a given input x is estimated as:
¯f(x) ⌘ nX
j=1
k(x j ,x)↵ j
where ↵ = (↵ 1 · · ·↵ n )",1. Introduction,[0],[0]
"T is the solution of the equation
(K+ I n )",1. Introduction,[0],[0]
"↵ = y. (1) *Equal contribution 1School of Mathematical Sciences, Tel Aviv University, Israel 2School of Computer and Communication Sciences, EPFL, Switzerland 3Computer Science and Artificial Intelligence Laboratory, MIT, USA.",1. Introduction,[0],[0]
"Correspondence to: Haim Avron <haimav@post.tau.ac.il>, Michael Kapralov <michael.kapralov@epfl.ch>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"In the above, K 2 Rn⇥n is the kernel matrix or Gram matrix defined by K
ij ⌘",1. Introduction,[0],[0]
"k(x i ,x j ) and y",1. Introduction,[0],[0]
⌘,1. Introduction,[0],[0]
[y 1 · · · y n ],1. Introduction,[0],[0]
T is the vector of responses.,1. Introduction,[0],[0]
"The KRR estimator can be derived by minimizing a regularized square loss objective function over a hypothesis space defined by the reproducing kernel Hilbert space associated with k(·, ·); however, the details are not important for this paper.
",1. Introduction,[0],[0]
"While simple, KRR is a powerful technique that is well understood statistically and capable of achieving impressive empirical results.",1. Introduction,[0],[0]
"Nevertheless, the method has a key weakness: computing the KRR estimator can be prohibitively expensive for large datasets.",1. Introduction,[0],[0]
Solving (1) generally requires ⇥(n3) time and ⇥(n2) memory.,1. Introduction,[0],[0]
"Thus, the design of scalable methods for KRR (and other kernel based methods) has been the focus of intensive research in recent years (Zhang et al., 2015; Alaoui & Mahoney, 2015; Musco & Musco, 2016; Avron et al., 2016).
",1. Introduction,[0],[0]
"One of the most popular approaches to scaling up kernel based methods is random Fourier features sampling, originally proposed by Rahimi & Recht (2007).",1. Introduction,[0],[0]
"For shiftinvariant kernels (e.g. the Gaussian kernel), Rahimi & Recht (2007) presented a distribution D on functions from X to Cs (s is a parameter) such that for every x, z 2 Rd
k(x, z) = E '⇠D ['(x)⇤'(z)] .
",1. Introduction,[0],[0]
"The idea is to sample ' from D and use ˜k(x, z) ⌘ '(x)⇤'(y) as a surrogate kernel.",1. Introduction,[0],[0]
"The resulting approximate KRR estimator can be computed in O(ns2) time and O(ns) memory (see §2.2 for details), giving substantial computational savings if s",1. Introduction,[0],[0]
⌧ n.,1. Introduction,[0],[0]
This approach naturally raises the question: how large should s be to ensure a high quality estimator?,1. Introduction,[0],[0]
"Or, using the exact KRR estimator as a natural baseline: how large should s be for the random Fourier features estimator to be almost as good as the exact KRR estimator?",1. Introduction,[0],[0]
"Answering this question can help us determine when random Fourier features can be useful, whether the method needs to be improved, and how to go about improving it.
",1. Introduction,[0],[0]
"The original random Fourier features analysis (Rahimi & Recht, 2007) bounds the point-wise distance between
k(·, ·) and ˜k(·, ·) (for other approaches for analyzing random Fourier features, see §2.3).",1. Introduction,[0],[0]
"However, the bounds do not naturally lead to an answer to the aforementioned question.",1. Introduction,[0],[0]
"In contrast, spectral approximation bounds on the entire kernel matrix, i.e. of the form
(1 )(K+ I n )",1. Introduction,[0],[0]
˜K+,1. Introduction,[0],[0]
"I n (1+ )(K+ I n
) , (2)
naturally have statistical and algorithmic implications.",1. Introduction,[0],[0]
"Indeed, in §3 we show that when (2) holds we can bound the excess risk introduced by the random Fourier features estimator when compared to the KRR estimator.",1. Introduction,[0],[0]
"We also show that ˜K+ I
n can be used as an effective preconditioner for the solution of (1).",1. Introduction,[0],[0]
"This motivates the study of how large s should be as a function of for (2) to hold.
",1. Introduction,[0],[0]
In this paper we rigorously analyze the relation between the number of random Fourier features and the spectral approximation bound (2).,1. Introduction,[0],[0]
"Our main results are the following:
We give an upper bound on the number of random features needed to achieve (2) (Theorem 7).",1. Introduction,[0],[0]
"This bound, in conjunction with the results in §3, positively shows that random Fourier features can give guarantees for KRR under reasonable assumptions.",1. Introduction,[0],[0]
We give a lower bound showing that our upper bound is tight for the Gaussian kernel (Theorem 8).,1. Introduction,[0],[0]
We show that the upper bound can be improved dramatically by modifying the sampling distribution used in classical random Fourier features (§4).,1. Introduction,[0],[0]
"Our sampling distribution is based on an appropriately defined leverage function of the kernel, closely related to so-called leverage scores frequently encountered in the analysis of sampling based methods for linear regression.",1. Introduction,[0],[0]
"Unfortunately, it is unclear how to efficiently sample using the leverage function.",1. Introduction,[0],[0]
"To address the lack of an efficient way to sample using the leverage function, we propose a novel, easy-tosample distribution for the Gaussian kernel which approximates the true leverage function distribution and allows random Fourier features to achieve a significantly improved upper bound (Theorem 10).",1. Introduction,[0],[0]
"The bound has an exponential dependence on the data dimension, so it is only applicable to low dimensional datasets.",1. Introduction,[0],[0]
"Nevertheless, it demonstrate that classic random Fourier features can be improved for spectral approximation and motivates further study.",1. Introduction,[0],[0]
"As an application, our improved understanding of the leverage function yields a novel asymptotic bound on the statistical dimension of Gaussian kernel matrices over bounded datasets, which may be of independent interest (Corollary 15).",1. Introduction,[0],[0]
The complex conjugate of x 2 C is denoted by x⇤.,2.1. Setup and Notation,[0],[0]
"For a vector x or a matrix A, x⇤ or A⇤ denotes the Hermitian transpose.",2.1. Setup and Notation,[0],[0]
The l ⇥,2.1. Setup and Notation,[0],[0]
"l identity matrix is denoted I
l .",2.1. Setup and Notation,[0],[0]
"We use the convention that vectors are column-vectors.
",2.1. Setup and Notation,[0],[0]
A Hermitian matrix A is positive semidefinite (PSD),2.1. Setup and Notation,[0],[0]
if x ⇤ Ax 0 for every vector x.,2.1. Setup and Notation,[0],[0]
"It is positive definite (PD) if
x",2.1. Setup and Notation,[0],[0]
⇤ Ax > 0 for every vector x 6= 0.,2.1. Setup and Notation,[0],[0]
"For any two Hermitian matrices A and B of the same size, A B means that B A is PSD.",2.1. Setup and Notation,[0],[0]
"We use L
2 (d⇢)",2.1. Setup and Notation,[0],[0]
=,2.1. Setup and Notation,[0],[0]
"L 2 (Rd, d⇢) to denote the space of complex-valued square-integrable functions with respect to some measure ⇢(·).",2.1. Setup and Notation,[0],[0]
"L
2 (d⇢) is a Hilbert space equipped with the inner product
hf, gi L
2
(d⇢)
",2.1. Setup and Notation,[0],[0]
"=
Z
Rd f(⌘)g(⌘)",2.1. Setup and Notation,[0],[0]
"⇤d⇢(⌘)
=
Z
Rd f(⌘)g(⌘)⇤p ⇢ (⌘)d⌘ .
",2.1. Setup and Notation,[0],[0]
"In the above, p ⇢ (·) is the density associated with ⇢(·).",2.1. Setup and Notation,[0],[0]
"We denote the training set by (x
1 , y 1 ), . . .",2.1. Setup and Notation,[0],[0]
", (x n , y n ) 2 X ⇥",2.1. Setup and Notation,[0],[0]
Y,2.1. Setup and Notation,[0],[0]
✓ Rd ⇥,2.1. Setup and Notation,[0],[0]
"R. Note that n denotes the number of training examples, and d their dimension.",2.1. Setup and Notation,[0],[0]
"We denote the kernel, which is a function from X ⇥ X to R, by k.",2.1. Setup and Notation,[0],[0]
"We denote the kernel matrix by K, with K
ij ⌘ k(x",2.1. Setup and Notation,[0],[0]
"i ,x j
).",2.1. Setup and Notation,[0],[0]
"The associated reproducing kernel Hilbert space (RKHS) is denoted by H
k , and the associated inner product by (·, ·)Hk .",2.1. Setup and Notation,[0],[0]
"Some results are stated for the Gaussian kernel k(x, z) = exp( kx zk2
2 /2 2) for some bandwidth parameter .
",2.1. Setup and Notation,[0],[0]
We use = n to denote the ridge regularization parameter.,2.1. Setup and Notation,[0],[0]
"While for brevity we omit the n subscript, the choice of regularization parameter generally depends on n. Typically,
n = !",2.1. Setup and Notation,[0],[0]
(1) and n = o(n).,2.1. Setup and Notation,[0],[0]
"See Caponnetto & De Vito (2007) and Bach (2013) for discussion on the asymptotic behavior of
n , noting that in our notation, is scaled by an n factor as compared to those works.",2.1. Setup and Notation,[0],[0]
"As the ratio between n and will be an important quantity in our bounds, we denote it as n
⌘ n/ .",2.1. Setup and Notation,[0],[0]
The statistical dimension or effective degrees of freedom is denoted by s (K) ⌘,2.1. Setup and Notation,[0],[0]
Tr (K+ I n ) 1 K .,2.1. Setup and Notation,[0],[0]
"Random Fourier features (Rahimi & Recht, 2007) is an approach to scaling up kernel methods for shift-invariant kernels.",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"A shift-invariant kernel is a kernel of the form k(x, z) =",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"k(x z) where k(·) is a positive definite func-
tion (we abuse notation by using k to denote both the kernel and the defining positive definite function).
",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
The underlying observation behind random Fourier features is a simple consequence of Bochner’s Theorem: for every shift-invariant kernel for which k(0),2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"= 1 there is a probability measure µ
k (·) and a corresponding probability density function p
k
(·), both on Rd, such that
k(x, z) =
Z
Rd e 2⇡i⌘
T (x z)dµ
k
(⌘)
=
Z
Rd e 2⇡i⌘
T (x z)p
k
(⌘)d⌘ .",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"(3)
In other words, the inverse Fourier transform of the kernel k(·) is a probability density function, p
k (·).",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"For simplicity we typically drop the k subscript, writing µ(·) = µ
k (·) and p(·) = p
k (·), with the associated kernel function clear from context.
",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"If ⌘ 1 , . . .",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
",⌘ s are drawn according to p(·), and we define '(x) ⌘",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"1p
s
⇣ e 2⇡i⌘ T 1 x, · · · , e 2⇡i⌘Ts x ⌘⇤
, then it is not hard to see that
k(x, z) = E '",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"['(x)⇤'(z)] .
",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"The idea of the Random Fourier features method is then to define
˜k(x, z) ⌘ '(x)⇤'(z)",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"= 1 s
sX
l=1
e 2⇡i⌘",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"T l (x z) (4)
as a substitute kernel.
",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"Now suppose that Z 2 Cn⇥s is the matrix whose jth row is '(x
j
)",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"⇤, and let ˜K = ZZ⇤.",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"˜K is the kernel matrix corresponding to ˜k(·, ·).",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
The resulting random Fourier features KRR estimator is ˜f(x) ⌘,2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"Pn
j=1
˜k(x j ,x)↵̃ j where ↵̃ is the solution of ( ˜K+ I
n )",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"↵̃ = y. Typically, s < n",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"and we can represent ˜f(·) more efficiently as:
˜f(x) = '(x)⇤w
where w =",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
(Z ⇤ Z+,2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"I
s
) 1 Z ⇤ y
We can compute w in O(ns2) time, making random Fourier features computationally attractive if s < n.",2.2.1. CLASSICAL RANDOM FOURIER FEATURES,[0],[0]
"While it seems to be a natural choice, there is no fundamental reason that we must sample the frequencies ⌘
1 , . . .",2.2.2. MODIFIED RANDOM FOURIER FEATURES,[0],[0]
",⌘ s
using the Fourier transform density function p(·).",2.2.2. MODIFIED RANDOM FOURIER FEATURES,[0],[0]
"In fact, our results show that it is advantageous to use a different sampling distribution based on the kernel leverage function (defined later).
",2.2.2. MODIFIED RANDOM FOURIER FEATURES,[0],[0]
Let q(·) be any probability density function whose support includes that of p(·).,2.2.2. MODIFIED RANDOM FOURIER FEATURES,[0],[0]
"If we sample ⌘
1 , . . .",2.2.2. MODIFIED RANDOM FOURIER FEATURES,[0],[0]
",⌘ s using q(·), and define
'(x) ⌘",2.2.2. MODIFIED RANDOM FOURIER FEATURES,[0],[0]
"1p s
s p(⌘
1
)
q(⌘ 1 )
e 2⇡i⌘ T 1 x, · · · , s p(⌘ s )
q(⌘ s )
e 2⇡i⌘ T s x
!",2.2.2. MODIFIED RANDOM FOURIER FEATURES,[0],[0]
"⇤
we still have k(x, z) = E '",2.2.2. MODIFIED RANDOM FOURIER FEATURES,[0],[0]
['(x)⇤'(z)].,2.2.2. MODIFIED RANDOM FOURIER FEATURES,[0],[0]
We refer to this method as modified random Fourier features and remark that it can be viewed as a form of importance sampling.,2.2.2. MODIFIED RANDOM FOURIER FEATURES,[0],[0]
"Now that we have defined (modified) random Fourier features, we can introduce some additional notation and identities that shall prove useful in the rest of the paper.
",2.2.3. ADDITIONAL NOTATIONS AND IDENTITIES,[0],[0]
"The (j, l) entry of Z is given by
Z
jl
= 1p s e 2⇡ix
T j⌘l p p(⌘
l )/q",2.2.3. ADDITIONAL NOTATIONS AND IDENTITIES,[0],[0]
(⌘ l ).,2.2.3. ADDITIONAL NOTATIONS AND IDENTITIES,[0],[0]
"(5)
Let z : Rd !",2.2.3. ADDITIONAL NOTATIONS AND IDENTITIES,[0],[0]
"Cn be defined by
z(⌘) j
= e 2⇡ix T j⌘ .
",2.2.3. ADDITIONAL NOTATIONS AND IDENTITIES,[0],[0]
"Note that column l of Z from the previous section is exactly z(⌘
l
)",2.2.3. ADDITIONAL NOTATIONS AND IDENTITIES,[0],[0]
"p p(⌘
l )/[s",2.2.3. ADDITIONAL NOTATIONS AND IDENTITIES,[0],[0]
· q(⌘ l )].,2.2.3. ADDITIONAL NOTATIONS AND IDENTITIES,[0],[0]
"So we have:
ZZ ⇤ = 1
s
sX
l=1
p(⌘ l ) q(⌘ l ) z",2.2.3. ADDITIONAL NOTATIONS AND IDENTITIES,[0],[0]
"(⌘ l )z(⌘ l ) ⇤.
",2.2.3. ADDITIONAL NOTATIONS AND IDENTITIES,[0],[0]
"Finally, by (3) we have E [ZZ⇤] = K since
K =
Z
Rd z(⌘)z(⌘)⇤dµ(⌘) =
Z
Rd z(⌘)z(⌘)⇤p(⌘)d⌘ .",2.2.3. ADDITIONAL NOTATIONS AND IDENTITIES,[0],[0]
"Rahimi & Recht (2007)’s original analysis of random Fourier features bounded the point-wise distance between k(·, ·) and ˜k(·, ·) .",2.3. Related Work,[0],[0]
"In follow-up work, they give learning rate bounds for a broad class of estimators using random Fourier features.",2.3. Related Work,[0],[0]
"However, their results do not apply to classic KRR (Rahimi & Recht, 2008).",2.3. Related Work,[0],[0]
"Their main bound becomes relevant only when the number of sampled features is on order of the training set size.
",2.3. Related Work,[0],[0]
"Rudi et al. (2016) prove generalization properties for KRR with random features, under somewhat difficult to verify technical assumptions, some of which can be seen as constraining the leverage function distribution that we study.",2.3. Related Work,[0],[0]
They leave open improving their bounds via a more refined sampling approach.,2.3. Related Work,[0],[0]
Bach (2017) analyzes random Fourier features from a function approximation point of view.,2.3. Related Work,[0],[0]
"He defines a similar leverage function distribution to the one that we consider, but leaves open establishing
bounds on and effectively sampling from this distribution, both of which we address in this work.",2.3. Related Work,[0],[0]
"Finally, Tropp (2015) analyzes the distance between the kernel matrix and its approximation in terms of the spectral norm, kK ˜Kk
2 , which can be a significantly weaker error metric than (2).
",2.3. Related Work,[0],[0]
"Outside of work on random Fourier features, risk inflation bounds for approximate KRR and leverage score sampling have been used to analyze and improve the Nyström method for kernel approximation (Bach, 2013; Alaoui & Mahoney, 2015; Rudi et al., 2015; Musco & Musco, 2016).",2.3. Related Work,[0],[0]
"We apply a number of techniques from this line of work.
",2.3. Related Work,[0],[0]
"Spectral approximation bounds, such as (2), are quite popular in the sketching literature; see Woodruff (2014).",2.3. Related Work,[0],[0]
"Most closely related to our work is analysis of spectral approximation bounds without regularization (i.e. = 0) for the polynomial kernel (Avron et al., 2014).",2.3. Related Work,[0],[0]
Improved bounds with regularization (still for the polynomial kernel) were recently proved by Avron et al. (2016).,2.3. Related Work,[0],[0]
"Given a feature transformation, like random Fourier features, how do we analyze it and relate its use to nonapproximate methods?",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"A common approach, taken for example in the original paper on random Fourier features (Rahimi & Recht, 2007), is to bound the difference between the true kernel k(·, ·) and the approximate kernel ˜k(·, ·).",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"However, it is unclear how such bounds translate to downstream guarantees on statistical learning methods, such as KRR.",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"In this paper we advocate and focus on spectral approximation bounds on the regularized kernel matrix, specifically, bounds of the form
(1 )(K+ I n )",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"ZZ⇤+ I n (1+ )(K+ I n ) (6)
for some < 1.",3. Spectral Bounds and Statistical Guarantees,[0],[0]
Definition 1.,3. Spectral Bounds and Statistical Guarantees,[0],[0]
"We say that a matrix A is a -spectral approximation of another matrix B, if (1 )B A (1 + )",3. Spectral Bounds and Statistical Guarantees,[0],[0]
B. Remark 1.,3. Spectral Bounds and Statistical Guarantees,[0],[0]
"When = 0, bounds of the form of (6) can be viewed as a low-distortion subspace embedding bounds.",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"Indeed, when = 0",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"it follows from (6) that Sp (k(x
1 , ·), . . .",3. Spectral Bounds and Statistical Guarantees,[0],[0]
", k(x n , ·))",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"✓ H k
can be embedded with -distortion in Sp ('(x
1 ), . . .",3. Spectral Bounds and Statistical Guarantees,[0],[0]
",'(x n ))",3. Spectral Bounds and Statistical Guarantees,[0],[0]
✓ Rs.,3. Spectral Bounds and Statistical Guarantees,[0],[0]
"The main mathematical question we seek to address in this paper is: when using random Fourier features, how large should s be in order to guarantee that ZZ⇤ +",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"I
n is a - spectral approximation of K+ I
n ?",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"To motivate this question, in the following two subsections we show that such bounds can be used to derive risk inflation bounds for approximate kernel ridge regression.",3. Spectral Bounds and Statistical Guarantees,[0],[0]
We also show that such bounds can be used to analyze the use of ZZ⇤ +,3. Spectral Bounds and Statistical Guarantees,[0],[0]
"I
n",3. Spectral Bounds and Statistical Guarantees,[0],[0]
as a preconditioner for K+,3. Spectral Bounds and Statistical Guarantees,[0],[0]
"I
n
.
",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"While this paper focuses on KRR for conciseness, we remark that in the sketching literature, spectral approximation bounds also form the basis for analyzing sketching based methods for tasks like low-rank approximation, kmeans and more.",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"In the kernel setting, such bounds where analyzed, without regularization, for the polynomial kernel (Avron et al., 2014).",3. Spectral Bounds and Statistical Guarantees,[0],[0]
Cohen et al. (2017) recently showed that (6) along with a trace condition on ZZ⇤ (which holds for all sampling approaches we consider) yields a so called “projection-cost preservation” condition for the kernel approximation.,3. Spectral Bounds and Statistical Guarantees,[0],[0]
"With chosen appropriately, this condition ensures that ZZ⇤ can be used in place of K for approximately solving kernel k-means clustering and for certain versions of kernel PCA and kernel CCA.",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"See Musco & Musco (2016) for details, where this analysis is carried out for the Nyström method.",3. Spectral Bounds and Statistical Guarantees,[0],[0]
"One way to analyze estimators is via risk bounds; several recent papers on approximate KRR employ such an analysis (Bach, 2013; Alaoui & Mahoney, 2015; Musco & Musco, 2016).",3.1. Risk Bounds,[0],[0]
"In particular, these papers consider the fixed design setting and seek to bound the expected in-sample predication error of the KRR estimator ¯f , viewing it as an empirical estimate of the statistical risk.",3.1. Risk Bounds,[0],[0]
"More specifically, the underlying assumption is that y
i
satisfies
y i = f?(x i )",3.1. Risk Bounds,[0],[0]
+ ⌫,3.1. Risk Bounds,[0],[0]
"i
(7)
for some f? : X !",3.1. Risk Bounds,[0],[0]
R.,3.1. Risk Bounds,[0],[0]
"The {⌫ i }’s are i.i.d noise terms, distributed as normal variables with variance 2
⌫ .",3.1. Risk Bounds,[0],[0]
"The empirical risk of an estimator f , which can be viewed as a measure of the quality of the estimator, is
R(f) ⌘",3.1. Risk Bounds,[0],[0]
"E{⌫i} 2
4 1 n
nX
j=1
(f(x i )",3.1. Risk Bounds,[0],[0]
f?(x i )),3.1. Risk Bounds,[0],[0]
"2
3
5
(note that f itself might be a function of {⌫ i }).",3.1. Risk Bounds,[0],[0]
"Let f 2 Rn be the vector whose jth entry is f?(x
j ).",3.1. Risk Bounds,[0],[0]
"It is quite straightforward to show that for the KRR estimator ¯f we have (Bach, 2013; Alaoui & Mahoney, 2015):
R( ¯f) = n 1 2fT(K+ I n )",3.1. Risk Bounds,[0],[0]
"2 f
+ n 1 2 ⌫ Tr K 2 (K+ I n ) 2 .
",3.1. Risk Bounds,[0],[0]
Since 2fT(K,3.1. Risk Bounds,[0],[0]
+ I n ),3.1. Risk Bounds,[0],[0]
2 f  fT(K,3.1. Risk Bounds,[0],[0]
+ I n ),3.1. Risk Bounds,[0],[0]
"1 f and
Tr K
2
(K+ I n )",3.1. Risk Bounds,[0],[0]
2  Tr K(K+ I n ),3.1. Risk Bounds,[0],[0]
"1 = s
(K), we define
bR K (f) ⌘ n 1 fT(K+ I n )",3.1. Risk Bounds,[0],[0]
"1 f + n 1 2
⌫
s (K)
and note that R( ¯f)  bR K
(f).",3.1. Risk Bounds,[0],[0]
"The first term in the above expressions for R( ¯f) and bR
K (f) is frequently referred to as the bias term, while the second is the variance term.
",3.1. Risk Bounds,[0],[0]
Lemma 2.,3.1. Risk Bounds,[0],[0]
"Suppose that (7) holds, and let f 2 Rn be the vector whose jth entry is f?(x
j ).",3.1. Risk Bounds,[0],[0]
"Let ¯f be the KRR estimator, and let ˜f be KRR estimator obtained using some other kernel ˜k(·, ·) whose kernel matrix is ˜K. Suppose that ˜",3.1. Risk Bounds,[0],[0]
K,3.1. Risk Bounds,[0],[0]
+ I n is a -spectral approximation to K +,3.1. Risk Bounds,[0],[0]
"I n
for some < 1, and that kKk
2 1.",3.1. Risk Bounds,[0],[0]
"The following bound holds:
R( ˜f)  (1 ) 1 bR K (f) +
(1 + )
· rank( ˜ K) n · 2 ⌫
(8)
The proof appears in the supplementary material (Appendix B).
",3.1. Risk Bounds,[0],[0]
"In short, Lemma 2 bounds the risk of the approximate KRR estimator as a function of both the risk upper bound bR K
(f) (8) and an additive term which is small if the rank of rank( ˜
K) and/or is small.",3.1. Risk Bounds,[0],[0]
"In particular, it is instructive to compare the additive term ( /(1+ ))n",3.1. Risk Bounds,[0],[0]
"1 2
⌫ ·rank( ˜K) to the variance term n 1 2
⌫
· s
(K).",3.1. Risk Bounds,[0],[0]
"Since approximation ˜
K is only useful computationally if rank( ˜K)",3.1. Risk Bounds,[0],[0]
⌧ n,3.1. Risk Bounds,[0],[0]
we should expect the additive term in (8) to also approach 0,3.1. Risk Bounds,[0],[0]
"an generally be small when n is large.
",3.1. Risk Bounds,[0],[0]
Remark 2.,3.1. Risk Bounds,[0],[0]
An approximation ˜K is only useful computationally if rank( ˜K),3.1. Risk Bounds,[0],[0]
⌧ n so ˜K gives a significantly compressed approximation to the original kernel matrix.,3.1. Risk Bounds,[0],[0]
Ideally we should have rank( ˜K)/n ! 0,3.1. Risk Bounds,[0],[0]
as n !,3.1. Risk Bounds,[0],[0]
1 and so the additive term in (8) will also approach 0 and generally be small when n is large.,3.1. Risk Bounds,[0],[0]
Suppose we choose to solve (K + I n ),3.2. Random Features Preconditioning,[0],[0]
↵ = y using an iterative method (e.g. CG).,3.2. Random Features Preconditioning,[0],[0]
"In this case, we can apply ZZ⇤ +",3.2. Random Features Preconditioning,[0],[0]
"I
n as a preconditioner.",3.2. Random Features Preconditioning,[0],[0]
Using standard analysis of Krylov-subspace iterative methods it is immediate that if ZZ⇤ +,3.2. Random Features Preconditioning,[0],[0]
"I
n is a -spectral approximation of K +",3.2. Random Features Preconditioning,[0],[0]
"I
n",3.2. Random Features Preconditioning,[0],[0]
then the number of iterations until convergence is O( p (1 + )/(1 ))).,3.2. Random Features Preconditioning,[0],[0]
"Thus, if ZZ⇤ +",3.2. Random Features Preconditioning,[0],[0]
"I
n is, say, a 1/2-spectral approximation of K+ I
n , then the number of iterations is bounded by a constant.",3.2. Random Features Preconditioning,[0],[0]
"The preconditioner can be efficiently applied (after preprocessing) via the Woodbury formula, giving cost per iteration (if s  n) of O(n2).",3.2. Random Features Preconditioning,[0],[0]
The overall cost of computing the KRR estimator is therefore O(ns2+n2).,3.2. Random Features Preconditioning,[0],[0]
"Thus, as long as s = o(n) this approach gives an advantage over direct methods which cost O(n3).",3.2. Random Features Preconditioning,[0],[0]
For small s it also beats non-preconditioned iterative methods cost O(n2 p (K)).,3.2. Random Features Preconditioning,[0],[0]
We reach again the question that was poised earlier: how big should s be so that ZZ⇤ +,3.2. Random Features Preconditioning,[0],[0]
"I n is a 1/2-spectral approximation of K+ I n ?
",3.2. Random Features Preconditioning,[0],[0]
See Cutajar et al. (2016) and Avron et al. (2016) for more details and discussion on random features preconditioning.,3.2. Random Features Preconditioning,[0],[0]
In this section we present upper bounds on the number of random Fourier features needed to guarantee that ZZ ⇤ +,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"I
n is a -spectral approximation to K+ I n .",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Our bounds are applicable to any shift-invariant kernel, and a wide range of feature sampling distributions (and, in particular, for classical random Fourier features).
",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
Our analysis is based on relating the sampling density to an appropriately defined ridge leverage function.,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"This function is a continuous generalization of the popular leverage scores (Mahoney & Drineas, 2009) and ridge leverage scores (Alaoui & Mahoney, 2015; Cohen et al., 2017) used in the analysis of linear methods.",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
Bach (2017) defined the leverage function of the integral operator given by the kernel function and the data distribution.,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"For our purposes, a more appropriate definition is with respect to a fixed input dataset:
Definition 3.",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"For given x 1 , . . .",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
",x n and shift-invariant kernel k(·, ·), define the ridge leverage function as
⌧ (⌘) ⌘",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
p(⌘)z(⌘),4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"⇤(K+ I) 1z(⌘) .
",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"In the above, K is the kernel matrix and p(·) is the distribution associated with k(·, ·).",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Proposition 4.
p(⌘)n/(n+ )  ",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"⌧ (⌘)  p(⌘)n/ Z
Rd ⌧ (⌘)d⌘ = s (K)
The (simple) proof of the proposition is given in the supplementary material (Appendix C).
",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Recall that we denote the ratio n/ , which appears frequently in our analysis, by n
= n/ .",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"As discussed, theoretical bounds generally set = !",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
(1) (as a function of n),4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"so n
= o(n).",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"However we remark that in practice, it may frequently be the case that is very small and n
n. Corollary 5.",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"For any K, s (K)  n .
",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"For any shift-invariant kernel with k(x,x) = 1 and k(x, z) ! 0",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"as kx zk
2 ! 1 (e.g., the Gaussian kernel) if we allow points to be arbitrarily spread out, the kernel matrix converges to the identity matrix, and s (I
n
) =
n/(1+ ) = ⌦(n )",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
if = ⌦(1) so the above bound is tight.,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"However, this requires datasets of increasingly large diameter (as n grows).",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"In contrast, the usual assumption in statistical learning is that the data is sampled from a bounded domain X .",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"In §7.2 we show via a leverage function upper bound that for the important Gaussian kernel, for bounded datasets we have s (K) = o(n ).
",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
In the matrix sketching literature it is well known that spectral approximation bounds similar to (6) can be constructed by sampling columns relative to upper bounds on the leverage scores.,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"In the following, we generalize this for the case of sampling Fourier features from a continuous domain.",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
Lemma 6.,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
Let ⌧̃ : Rd !,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"R be a measurable function such that ⌧̃(⌘) ⌧
(⌘) for all ⌘ 2 Rd, and furthermore assume that
s ⌧̃
⌘ Z
Rd ⌧̃(⌘)d⌘
is finite.",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
Denote p ⌧̃ (⌘) = ⌧̃(⌘)/s,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
⌧̃ .,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Let  1/2 and ⇢ 2 (0, 1).",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Assume that kKk
2 .",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Suppose we take s 8
3
2s ⌧̃ ln(16s (K)/⇢) samples ⌘ 1 , . . .",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
",⌘ s from the distribution associated with the density p
⌧̃ (·) and the construct the matrix Z according to (5) with q = p
⌧̃ .",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
Then ZZ ⇤ +,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"I
n is -spectral approximation of K +",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
I n with probability of at least 1 ⇢.,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"The proof is based on matrix concentration inequalities, and appears in the supplementary material (Appendix D).
",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Lemma 6 shows that if we could sample using the ridge leverage function, then O(s (K) log(s
(K)))",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
samples suffice for spectral approximation of K (for a fixed and failure probability).,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"While there is no straightforward way to perform this sampling, we can consider how well the classic random Fourier features sampling distribution approximates the leverage function, obtaining a bound on its performance (the proof is in Appendix D as well): Theorem 7.",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Let  1/2 and 2 (0, 1).",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Assume that kKk
2
.",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"If we use s 8 3
2n ln(16s (K)/⇢) random Fourier features (i.e., sampled according to p(·)), then ZZ ⇤ +",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"I
n is -spectral approximation of K +",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
I n with probability of at least 1 ⇢.,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
Theorem 7 establishes that if = !,4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"(log(n)) and is fixed, o(n)",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"random Fourier features suffice for spectral approximation, and so the method can provably speed up KRR.",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Nevertheless, the bound depends on n instead of s
(K), as is possible with true leverage function sampling (see Lemma 6).",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"This gap arises from our use of the simple, often loose, ridge leverage function upper bound given by Proposition 4.
",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Unfortunately, as the next section shows, the bound in Theorem 7 cannot be improved since the classic random Fourier features sampling distribution can be far enough from the ridge leverage distribution that ⌦(n
) features may be needed even when s (K) = o(n ).",4. Ridge Leverage Function Sampling and Random Fourier Features,[0],[0]
"Our lower bound shows that the upper bound of Theorem 7 on the number of samples required by classic random Fourier features to obtain a spectral approximation to K+
I n is essentially best possible.",5. Lower Bound,[0],[0]
The full proof is given in the supplementary material (Appendix I).,5. Lower Bound,[0],[0]
Theorem 8.,5. Lower Bound,[0],[0]
"Consider the Gaussian kernel with = (2⇡) 1 (so p(⌘) = 1p
2⇡
e ⌘ 2 /2).",5. Lower Bound,[0],[0]
"Suppose n 17 is an odd integer, satisfies 10
n <  n 2
, and R satisfies 3000 log 1.5 (n
)  ",5. Lower Bound,[0],[0]
R  n 500 p log(n ) .,5. Lower Bound,[0],[0]
"Then, there exists a
dataset of n points {x j }n j=1 ✓ [ R,R] such that if s random Fourier features (i.e., sampled according to p(·)) are used for some s  n
400 , then with probability at least 1/2, there exists a vector ↵ 2 Rn such that
↵T(K+ I n )",5. Lower Bound,[0],[0]
"↵ < 2
3
↵T(ZZ⇤ +",5. Lower Bound,[0],[0]
"I n )↵. (9)
",5. Lower Bound,[0],[0]
"Furthermore, for the said dataset we have s (K) = O(R · poly (log n )).
Thus, the number of samples s required for ZZ⇤ + I n
to be a 1/2-spectral approximation to K+ I
n for a bounded dataset of points must either depend exponentially on the radius of the point set, or at least linearly on n
, and there is an asymptotic gap between what is achieved with classical random Fourier features and what is achieved by modified random Fourier features using leverage function sampling.
",5. Lower Bound,[0],[0]
"We note that the above lower bound is proven for a onedimensional point set, which makes it only stronger: even at low dimensions, and for the common Gaussian kernel, there is a large gap between the performance of classic random Fourier features and leverage function sampling.
",5. Lower Bound,[0],[0]
"The bound applies for datasets bounded on the range [ R,R] for R = ⌦ log1.5 n .",5. Lower Bound,[0],[0]
"As we will see in §7, the key idea behind the proof is to show that for such a dataset, the ridge leverage function is large on a range of low frequencies.",5. Lower Bound,[0],[0]
"In contrast, the classic random Fourier features distribution is very small at the edges of this frequency range, and so significantly undersamples some frequencies and does not achieve spectral approximation.
",5. Lower Bound,[0],[0]
"We remark that it would be preferable if Theorem 8 applied to bounded datasets (i.e. with R fixed), as the usual assumption in statistical learning theory is that data is sampled from a bounded domain.",5. Lower Bound,[0],[0]
"However, our current techniques are unable to address this scenario.",5. Lower Bound,[0],[0]
"Nevertheless, our analysis allows R to grow very slowly with n and we conjecture that the upper bound is tight even for bounded domains.",5. Lower Bound,[0],[0]
"Contrasting with the lower bound of Theorem 8, we now give a modified Fourier feature sampling distribution that does perform well for the Gaussian kernel on bounded input sets.",6. Improved Sampling (Gaussian Kernel),[0],[0]
"Furthermore, unlike the true ridge leverage function, this distribution is simple and efficient to sample from.
",6. Improved Sampling (Gaussian Kernel),[0],[0]
"To reduce clutter, we state the result for a fixed bandwidth = (2⇡) 1.",6. Improved Sampling (Gaussian Kernel),[0],[0]
"This is without loss of generality since we can rescale the points and adjust the bounding interval.
",6. Improved Sampling (Gaussian Kernel),[0],[0]
Our modified distribution essentially corrects the classic distribution by “capping” the probability of sampling low frequencies near the origin.,6. Improved Sampling (Gaussian Kernel),[0],[0]
"This allows it to allocate more samples to higher frequencies, which are undersampled by classical random Fourier features.",6. Improved Sampling (Gaussian Kernel),[0],[0]
"For simplicity, we focus on the one-dimensional setting.",6. Improved Sampling (Gaussian Kernel),[0],[0]
"Our results extend to higher dimensions, albeit with an exponential in the dimension loss.",6. Improved Sampling (Gaussian Kernel),[0],[0]
Definition 9 (Improved Fourier Feature Distribution for the Gaussian Kernel).,6. Improved Sampling (Gaussian Kernel),[0],[0]
"Define the function
⌧̄ R
(⌘) ⌘ ⇢ 25max(R, 3000 log1.5 n )",6. Improved Sampling (Gaussian Kernel),[0],[0]
"|⌘|  10plog(n )
p(⌘)n
o.w.
Let s ⌧̄R = R R ⌧̄R(⌘)d⌘ and define the probability density function p̄ R (⌘) = ⌧̄ R (⌘)/s ⌧̄R .
",6. Improved Sampling (Gaussian Kernel),[0],[0]
"Note that p̄ R (⌘) is just the uniform distribution for low frequencies with |⌘|  10plog(n
), and the classic Fourier features distribution, appropriately scaled, outside this range.",6. Improved Sampling (Gaussian Kernel),[0],[0]
"As we show in §7, ⌧̄
R (⌘) upper bounds the true ridge leverage function ⌧
(⌘) for all ⌘.",6. Improved Sampling (Gaussian Kernel),[0],[0]
"Hence, simply applying Lemma 6: Theorem 10.",6. Improved Sampling (Gaussian Kernel),[0],[0]
"For any integer n and parameter 0 <  n
2 , consider the one dimensional Gaussian kernel with = (2⇡) 1 (so p(⌘) = 1p
2⇡
e ⌘ 2 /2) and any dataset of n points {x
j }n j=1 ✓ [ R,R] with any radius R > 0.",6. Improved Sampling (Gaussian Kernel),[0],[0]
"If we sample s 8
3
2s ⌧̄R ln(16s⌧̄R/⇢)",6. Improved Sampling (Gaussian Kernel),[0],[0]
"random Fourier features ac-
cording to p̄ R (·) and construct Z according to (5), then with probability at least 1 ⇢, ZZ⇤ +",6. Improved Sampling (Gaussian Kernel),[0],[0]
"I
n is -spectral approximation of K+ I
n for any  1/2 and ⇢ 2 (0, 1).",6. Improved Sampling (Gaussian Kernel),[0],[0]
"Furthermore, s ⌧̄R = O(R p log(n ) + log 2 n ) and p̄ R
(·) can be sampled from in O(1) time.
",6. Improved Sampling (Gaussian Kernel),[0],[0]
Theorem 10 represents a possibly exponential improvement over the bound obtainable by classic random Fourier features.,6. Improved Sampling (Gaussian Kernel),[0],[0]
"For R log1.5(n
)",6. Improved Sampling (Gaussian Kernel),[0],[0]
our modified distribution requires O(R p,6. Improved Sampling (Gaussian Kernel),[0],[0]
"log(n
))",6. Improved Sampling (Gaussian Kernel),[0],[0]
"samples, as compared to the lower bound of n
400
given by Theorem 8.",6. Improved Sampling (Gaussian Kernel),[0],[0]
"We conclude by discussing our approach to bounding the ridge leverage function of the Gaussian kernel, which leads to Theorems 8 and 10.",7. Bounding the Ridge Leverage Function,[0],[0]
The key idea is to reformulate the leverage function as the solution of two dual optimization problems.,7. Bounding the Ridge Leverage Function,[0],[0]
"By exhibiting suitable test functions for these optimization problems, we are able to give both upper and lower bounds on the ridge leverage function, and correspondingly on the sampling performance of classic and modified Fourier feature sampling.",7. Bounding the Ridge Leverage Function,[0],[0]
"In this section we prove two alternative characterizations of the ridge leverage function: one as a minimization, and the other as a maximization.",7.1. Primal-Dual Characterization,[0],[0]
"These characterization are useful for bounding the leverage function, as we exhibit in the next subsection for the Gaussian kernel.
",7.1. Primal-Dual Characterization,[0],[0]
Define the operator : L 2 (dµ) !,7.1. Primal-Dual Characterization,[0],[0]
"Cn by
y ⌘ Z
Rd z(⇠)y(⇠)dµ(⇠).",7.1. Primal-Dual Characterization,[0],[0]
"(10)
The following two lemmas constitute the main result of this subsection.",7.1. Primal-Dual Characterization,[0],[0]
The proofs can be found in the supplementary material (Appendix E).,7.1. Primal-Dual Characterization,[0],[0]
Lemma 11.,7.1. Primal-Dual Characterization,[0],[0]
"The ridge leverage function can alternatively be defined as follows:
⌧ (⌘) =",7.1. Primal-Dual Characterization,[0],[0]
"min y2L
2
(dµ)
1k y p p(⌘)z(⌘)k2
2 + kyk2 L
2
(dµ)
(11) Lemma 12.",7.1. Primal-Dual Characterization,[0],[0]
"The ridge leverage function can alternatively be defined as follows:
⌧ (⌘) = max ↵2Cn p(⌘) ·",7.1. Primal-Dual Characterization,[0],[0]
|↵⇤z(⌘)|2,7.1. Primal-Dual Characterization,[0],[0]
"k ⇤↵k2
L
2
(dµ)
+ k↵k2 2
(12)
Similar results are well known for the finite dimensional case.",7.1. Primal-Dual Characterization,[0],[0]
Here we extend these results to an infinite dimensional case.,7.1. Primal-Dual Characterization,[0],[0]
"Lemma 11 allows us to upper bound the leverage function at any point ⌘ 2 Rd by exhibiting a carefully constructed function y(·) and upper bounding the ratio in (11), while Lemma 12 allows us to lower bound it in a similar fashion.",7.1. Primal-Dual Characterization,[0],[0]
In this section we prove nearly matching bounds on the leverage score function for the one-dimensional Gaussian kernel on bounded datasets.,7.2. Leverage Function: the Gaussian Case,[0],[0]
For simplicity of presentation we focus on the one-dimensional setting.,7.2. Leverage Function: the Gaussian Case,[0],[0]
"Our results extend to higher dimensions, albeit with an exponential in the dimension loss in the gap between upper and lower bounds.
",7.2. Leverage Function: the Gaussian Case,[0],[0]
"Our bounds are parameterized by the width of the point set, which we denote by R. To reduce clutter, we present all results for fixed = (2⇡) 1.",7.2. Leverage Function: the Gaussian Case,[0],[0]
This is without loss of generality since we can rescale the points.,7.2. Leverage Function: the Gaussian Case,[0],[0]
All the proofs appear in the supplementary material (Appendices F–H).,7.2. Leverage Function: the Gaussian Case,[0],[0]
Theorem 13.,7.2. Leverage Function: the Gaussian Case,[0],[0]
Consider the one dimensional Gaussian kernel with = (2⇡) 1.,7.2. Leverage Function: the Gaussian Case,[0],[0]
"For any integer n and parameter 0 <  n
2
, and any radius R > 0, if x 1 , ..., x n 2 [ R,R], for every |⌘|  10plog n",7.2. Leverage Function: the Gaussian Case,[0],[0]
":
⌧ (⌘)  25max(R, 3000 log1.5 n ) .
",7.2. Leverage Function: the Gaussian Case,[0],[0]
Theorem 14.,7.2. Leverage Function: the Gaussian Case,[0],[0]
Consider the one dimensional Gaussian kernel with = (2⇡) 1.,7.2. Leverage Function: the Gaussian Case,[0],[0]
"For any integer n 17, any parameter 10
n   n 16 , and every radius 1000 log1.5 n  R  n
500 p log(n ) , there exist x 1 , ..., x n 2 [ R,R] such that for every ⌘ 2 [ 100plog n ,+100 p log n ]",7.2. Leverage Function: the Gaussian Case,[0],[0]
"we have:
⌧ (⌘) R 150
✓ p(⌘)
p(⌘) + 2Rn 1
◆ .
",7.2. Leverage Function: the Gaussian Case,[0],[0]
"The last two theorems lead to a tight bound on the statistical dimension matrices corresponding to bounded points sets:
Corollary 15.",7.2. Leverage Function: the Gaussian Case,[0],[0]
Consider the Gaussian kernel with = (2⇡) 1.,7.2. Leverage Function: the Gaussian Case,[0],[0]
"For any integer n and parameter 0 <  n
2 , and any R > 0, if x
1 , ..., x n
2 [ R,R] then we have:
s (K)  500 ·max(R, 3000 log1.5 n )",7.2. Leverage Function: the Gaussian Case,[0],[0]
"p log n + 1
= O(R p log n + log 2 n )
",7.2. Leverage Function: the Gaussian Case,[0],[0]
"Furthermore, if 1000 log1.5 n  R  n 500 p log(n ) there exists a set of points x 1 , . . .",7.2. Leverage Function: the Gaussian Case,[0],[0]
", x n ✓ [ R,R] such that:
s (K) = ⌦ ⇣ R p log(n /R)",7.2. Leverage Function: the Gaussian Case,[0],[0]
"⌘ .
",7.2. Leverage Function: the Gaussian Case,[0],[0]
The bounds above match up to constant factors if 1000 log 1.5 n  R  n0.99 .,7.2. Leverage Function: the Gaussian Case,[0],[0]
"For any 1000 log1.5 n
 R  n
500 p log(n )
they match up to a p log n factor.",7.2. Leverage Function: the Gaussian Case,[0],[0]
Lemma 11 allows us to bound ⌧ (⌘) simply by exhibiting any y(·) which makes the cost function small.,7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"One simple attempt might be y(s)
⌘",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
(⇠) = (⌘ ⇠) where (·) is the Dirac delta function.,7.3. Theorems 13 and 14: Proof Outline,[0],[0]
This choice zeros out the first term.,7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"However the delta function is not square integrable, y(s) ⌘ 62 L 2
(dµ), so the lemma cannot be used.",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"Another trivial attempt is y(0)(⇠) = 0, which zeros out the second term and recovers the trivial bound ⌧ (⌘)  p(⌘)n
.",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"Nevertheless, a smarter test functions y(·) can yield improved bounds, yielding results on the leverage score function that are parameterized by the diameter of the point set.
",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"At a high level, our approach is to replace the spike function at ⌘ with a ‘soft spike’ whose Fourier transform still looks approximately like a cosine wave on [ R,R], yet is still square integrable.",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"The smaller R is, the more spread out this function will be able to be, and hence the smaller its `
2 norm, and the better the leverage score bound.",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"A natural candidate for a ‘soft spike’ is a Gaussian of appropriate variance, but this choice does not suffice to obtain tight bounds, due to two difficulties.",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"First, for the upper bound a simple Gaussian does not result in a function that is close enough to a pure frequency in time domain (first
term of the objective function in Lemma 11) unless we settle for an upper bound of O(R · poly (n
))",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
as opposed to the tight O(R) on the leverage score density function.,7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"Second, the lower bound on the leverage score function resulting from using a Gaussian pulse would only be of the form ⌦(R/ p log n
), leading to a weak lower bound on the statistical dimension, namely ⌦(R) as opposed to ⌦(R · plog n
), thereby missing entirely the effect of the regularization parameter on the statistical dimension!
",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
The remedy to the issues above turns out to be the convolution of a (modulated) Gaussian with a rectangular pulse in time domain (product of a shifted Gaussian with the sinc function in frequency domain).,7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"Specifically, our bounds are based on variants of a flattened Gaussian spike function
y ⌘,b,v
(⇠) ⌘",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
e (⇠ ⌘)2b2/4 · v · sinc (v(⇠ ⌘)) .,7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"(13)
for some b > 0, v > 0 and ⌘ 2 R. It turns out that with a proper setting of parameters (where one should think of b as large, i.e. the spike y is rather narrow) the function",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"y
⌘,b,v
satisfies
( y ⌘,b,v )(x) ⇡ p(⌘) · exp(2⇡i⌘x) R x+ v2 x v
2
1p 2⇡b e t 2 /2b 2 dt.
",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"An illustration of this function in y is given in Fig. 1, (left) and the function y in Fig. 1, (right).",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"Note that if the parameter v is chosen to be large, then for x not too large we have R x+ v 2
x v 2 1p 2⇡b e t 2 /2b 2 dt ⇡ R +1 1",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"1p 2⇡b e t 2 /2b 2
dt, i.e. the second multiplier is essentially constant, i.e. flat as a function of x (hence the term ‘flattened Gaussian spike’).",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
"This means that y
⌘,b,v is essentially the kernel density evaluated at ⌘ times a pure harmonic term exp(2⇡i⌘x), which is exactly what one needs to minimize the first term on the rhs of (11) in Lemma 11, up to a factor of p p(⌘) – see Appendix F. One can also see that setting v to be not too large results in a good function to use in the maximization problem in (12) in Lemma 12 – see Appendix G. Obtaining tight bounds and in particular achieving the right dependence on p log n
requires several modifications to the function y above, but the intuition we just described works!",7.3. Theorems 13 and 14: Proof Outline,[0],[0]
The authors thank Arturs Backurs helpful discussions at early stages of this project.,Acknowledgements,[0],[0]
"Haim Avron acknowledges the support from the XDATA program of the Defense Advanced Research Projects Agency (DARPA), administered through Air Force Research Laboratory contract FA875012-C-0323 and an IBM Faculty Award.",Acknowledgements,[0],[0]
"Cameron Musco acknowledges the support by NSF Graduate Research Fellowship, AFOSR grant FA9550-13-1-0042 and the NSF Center for Science of Information.",Acknowledgements,[0],[0]
"Random Fourier features is one of the most popular techniques for scaling up kernel methods, such as kernel ridge regression.",abstractText,[0],[0]
"However, despite impressive empirical results, the statistical properties of random Fourier features are still not well understood.",abstractText,[0],[0]
In this paper we take steps toward filling this gap.,abstractText,[0],[0]
"Specifically, we approach random Fourier features from a spectral matrix approximation point of view, give tight bounds on the number of Fourier features required to achieve a spectral approximation, and show how spectral matrix approximation bounds imply statistical guarantees for kernel ridge regression.",abstractText,[0],[0]
Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees,title,[0],[0]
"Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 42–52, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
Parsing accuracy is greatly impacted by the quality of preprocessing steps such as tagging and word segmentation.,1 Introduction,[0],[0]
Li et al. (2011) report that the difference between using the gold POS tags and using the automatic counterparts reaches about 6% in dependency accuracy.,1 Introduction,[0],[0]
"Prior research has demonstrated that joint prediction alleviates error propagation inherent in pipeline architectures, where mistakes cascade from one task to the next (Bohnet et
1The source code is available at https://github. com/yuanzh/SegParser.
al., 2013; Tratz, 2013; Hatori et al., 2012; Zhang et al., 2014a).",1 Introduction,[0],[0]
"However, jointly modeling all the processing tasks inevitably increases inference complexity.",1 Introduction,[0],[0]
"Prior work addressed this challenge by introducing constraints on scoring functions to keep inference tractable (Qian and Liu, 2012).
",1 Introduction,[0],[0]
"In this paper, we propose a method for joint prediction that imposes no constraints on the scoring function.",1 Introduction,[0],[0]
"The method is able to handle high-order and global features for each individual task (e.g., parsing), as well as features that capture interactions between tasks.",1 Introduction,[0],[0]
"The algorithm achieves this flexibility by operating over full assignments that specify segmentation, POS tags and dependency tree, moving from one complete configuration to another.
",1 Introduction,[0],[0]
"Our approach is based on the randomized greedy algorithm from our earlier dependency parsing system (Zhang et al., 2014b).",1 Introduction,[0],[0]
We extend this algorithm to jointly predict the segmentation and the POS tags in addition to the dependency parse.,1 Introduction,[0],[0]
The search space for the algorithm is a combination of parse trees and lattices that encode alternative morphological and POS analyses.,1 Introduction,[0],[0]
"The inference algorithm greedily searches over this space, iteratively making local modifications to POS tags and dependency trees.",1 Introduction,[0],[0]
"To overcome local optima, we employ multiple restarts.
",1 Introduction,[0],[0]
"This simple, yet powerful approach can be easily applied to a range of joint prediction tasks.",1 Introduction,[0],[0]
"In prior work, joint models have been designed for a specific language.",1 Introduction,[0],[0]
"For instance, joint models for Chinese are designed with word segmentation in mind (Hatori et al., 2012), while algorithms for processing Semitic languages are tailored for morpho-
42
logical analysis (Tratz, 2013; Goldberg and Elhadad, 2011).",1 Introduction,[0],[0]
"In contrast, we show that our algorithm can be effortlessly applied to all these distinct languages.",1 Introduction,[0],[0]
"Language-specific characteristics drive the lattice construction and the feature selection, while the learning and inference methods are languageagnostic.
",1 Introduction,[0],[0]
"We evaluate our model on three datasets: SPMRL (Modern Standard Arabic), classical Arabic and CTB5 (Chinese).",1 Introduction,[0],[0]
Our model consistently outperforms state-of-the-art systems designed for these languages.,1 Introduction,[0],[0]
"We obtain a 2.1% TedEval gain against the best published results in the 2013 SPMRL shared task (Seddah et al., 2013).",1 Introduction,[0],[0]
"The joint model results in significant gains against its pipeline counterpart, yielding 2.4% absolute F-score increase in dependency parsing on the same dataset.",1 Introduction,[0],[0]
Our analysis reveals that most of this gain comes from the improved prediction on OOV words.,1 Introduction,[0],[0]
"Joint Segmentation, POS tagging and Syntactic Parsing",2 Related Work,[0],[0]
"It has been widely recognized that joint prediction is an appealing alternative for pipeline architectures (Goldberg and Tsarfaty, 2008; Hatori et al., 2012; Habash and Rambow, 2005; GahbicheBraham et al., 2012; Zhang and Clark, 2008; Bohnet and Nivre, 2012).",2 Related Work,[0],[0]
"These approaches have been particularly prominent for languages with difficult preprocessing, such as morphologically rich languages (e.g., Arabic and Hebrew) and languages that require word segmentation (e.g., Chinese).",2 Related Work,[0],[0]
"For the former, joint prediction models typically rely on a lattice structure to represent alternative morphological analyses (Goldberg and Tsarfaty, 2008; Tratz, 2013; Cohen and Smith, 2007).",2 Related Work,[0],[0]
"For instance, transitionbased models intertwine operations on the lattice with operations on a dependency tree.",2 Related Work,[0],[0]
"Other joint architectures are more decoupled: in Goldberg and Tsarfaty (2008), a lattice is used to derive the best morphological analysis for each part-of-speech alternative, which is in turn provided to the parsing algorithm.",2 Related Work,[0],[0]
"In both cases, tractable inference is achieved by limiting the representation power of the scoring function.",2 Related Work,[0],[0]
Our model also uses a lattice to encode alternative analyses.,2 Related Work,[0],[0]
"However, we employ this structure in a different way.",2 Related Work,[0],[0]
"The model samples
the full path from the lattice, which corresponds to a valid segmentation and POS tagging assignment.",2 Related Work,[0],[0]
Then the model improves the path and the corresponding tree via a hill-climbing strategy.,2 Related Work,[0],[0]
"This architecture allows us to incorporate arbitrary features for segmentation, POS tagging and parsing.
",2 Related Work,[0],[0]
"In joint prediction models for Chinese, lattice structures are not typically used.",2 Related Work,[0],[0]
"Commonly these models are formulated in a transition-based framework at the character level (Zhang and Clark, 2008; Zhang et al., 2014a; Wang and Xue, 2014).",2 Related Work,[0],[0]
"While this formulation can handle a large space of possible word segmentations, it can only capture features that are instantiated based on the stack and queue status.",2 Related Work,[0],[0]
"Our approach offers two advantages over prior work: (1) we can incorporate arbitrary features for word segmentation and parsing; (2) we demonstrate that a lattice-based approach commonly used for other languages can be effectively utilized for Chinese.
",2 Related Work,[0],[0]
"Randomized Greedy Inference Our prior work has demonstrated that a simple randomized greedy approach delivers near optimal dependency parsing (Zhang et al., 2014b).",2 Related Work,[0],[0]
Our analysis explains this performance with the particular properties of the search space in dependency parsing.,2 Related Work,[0],[0]
We show how to apply this strategy to a more challenging inference task and demonstrate that a randomized greedy algorithm achieves excellent performance in a significantly larger search space.,2 Related Work,[0],[0]
"In this section, we introduce our model for joint morphological segmentation, tagging and parsing.",3 Randomized Greedy System for Joint Prediction,[0],[0]
"Our description will first assume that word boundaries are provided (e.g., the case of Arabic).",3 Randomized Greedy System for Joint Prediction,[0],[0]
"Later, we will describe how this model can be applied to a joint prediction task that involves word segmentation (e.g., Chinese).",3 Randomized Greedy System for Joint Prediction,[0],[0]
Let x = {xi}|x|i=1 be a sentence of length |x| that consists of tokens xi.,3.1 Notation,[0],[0]
"We use s = {si}|x|i=1 to denote a segmentation of all the tokens in sentence x, and si = {si,j}|si|j=1 to denote a segmentation of the token xi, where si,j is the jth morpheme of the token xi.",3.1 Notation,[0],[0]
"Similarly, we use t, ti and ti,j for the POS
w/PRT
w/C
kAn/V
w/C k/P
An/N
An/C
ti,1 2 Ti,1 = {C, PRT}
ti,2 2 Ti,2 = {V }
Si
Ti = Ti,1 ⇥",3.1 Notation,[0],[0]
"Ti,2
1
si = w+ kAn xi = wkAn
si,1 = w ti,1ti,1 2 Ti,1 = {C, PRT}
ti,2 2 Ti,2 = {V }
Si
Ti = Ti,1 ⇥",3.1 Notation,[0],[0]
"Ti,2
1
ti,1 2 Ti,1 = {C, PRT}
ti,2 2 Ti,2 = {V }
Si
Ti = Ti,1 ⇥",3.1 Notation,[0],[0]
"Ti,2
1
Figure 1: Example lattice structures for the Arabic token “wkAn”.",3.1 Notation,[0],[0]
It has two candidate segmentations: w+kAn or w+k+An.,3.1 Notation,[0],[0]
The first segmentation consists of two morphemes.,3.1 Notation,[0],[0]
"The first morpheme w has two candidate POS.
tags for each sentence, token and morpheme.",3.1 Notation,[0],[0]
"We use y to denote a dependency tree over morphemes, and yi,j to denote the head of morpheme si,j .",3.1 Notation,[0],[0]
"During training, the algorithm is provided with tuples that specify ground truth values for all the variables D = {(x, ŝ, t̂, ŷ)}.
",3.1 Notation,[0],[0]
We also assume access to a morphological analyzer and a POS tagger that provide candidate analyses.,3.1 Notation,[0],[0]
"Specifically, for each token xi, the algorithm is provided with candidate segmentations Si, and candidate POS tags Ti and Ti,j .",3.1 Notation,[0],[0]
These alternative analyses are captured in the lattice structure (see Figure 1 for an example).,3.1 Notation,[0],[0]
"Finally, we use Y to denote the set of all valid dependency trees defined over morphemes.",3.1 Notation,[0],[0]
"We parameterize the scoring function as
score(x, s, t, y) = θ · f(x, s, t, y) (1)
where θ is the parameter vector and f(x, s, t, y) is the feature vector associated with the sentence and all variables.
",3.2 Decoding,[0],[0]
"The goal of decoding is to find a set of valid values for (s, t, y) ∈ S × T × Y that maximizes the score defined in Eq. 1.",3.2 Decoding,[0],[0]
"Our randomized greedy algorithm finds a high scoring assignment for (s, t, y) via a hill-climbing process with multiple random restarts.",3.2 Decoding,[0],[0]
"(Section 3.3 describes how the parameters θ are learned.)
",3.2 Decoding,[0],[0]
Figure 2 shows the framework of our randomized greedy algorithm.,3.2 Decoding,[0],[0]
"First, we draw a full path from the lattice structure in two steps: (1) sampling a morphological segmentation s from S; (2) sampling POS tags t for each morpheme.",3.2 Decoding,[0],[0]
"Next, we
sample a dependency tree y from the parse space.",3.2 Decoding,[0],[0]
"Based on this random starting point, we iteratively hill-climb t and y in a bottom-up order.2 In our earlier work (Zhang et al., 2014b), we showed this strategy guarantees that we can climb to any target tree in a finite number of steps.",3.2 Decoding,[0],[0]
We repeat the sampling and the hill-climbing processes above until we do not find a better solution for K iterations.,3.2 Decoding,[0],[0]
"We introduce the details of this process below.
SampleSeg and SamplePOS:",3.2 Decoding,[0],[0]
"Given a sentence x, we first draw segmentations s and POS tags t(0) from the first-order distribution using the current learned parameter values.",3.2 Decoding,[0],[0]
"For segmentation, firstorder features only depend on each token xi and its morphemes si,j .",3.2 Decoding,[0],[0]
"Similarly, for POS, first-order features are defined based on si,j and ti,j .",3.2 Decoding,[0],[0]
"The sampling process is straightforward due to the fact that the candidate sets |Si| and |Ti,j | are both small.",3.2 Decoding,[0],[0]
"We can enumerate and compute the probabilities proportional to the exponential of the first-order scores as follows.3
p(si) ∝",3.2 Decoding,[0],[0]
"exp{θ · f(x, si)} p(ti,j) ∝",3.2 Decoding,[0],[0]
"exp{θ · f(x, si, ti,j)}
(2)
SampleTree:",3.2 Decoding,[0],[0]
"Given a random sample of the segmentations s and the POS tags t(0), we draw a random tree y(0) from the first-order distribution using Wilson’s algorithm (Wilson, 1996).4
HillClimbPOS:",3.2 Decoding,[0],[0]
"After sampling the initial values s, t(0) and y(0), the hill-climbing algorithm improves the solution via locally greedy changes.",3.2 Decoding,[0],[0]
The hillclimbing algorithm iterates between improving the POS tags and the dependency tree.,3.2 Decoding,[0],[0]
"For POS tagging, it updates each ti,j in a bottom-up order as follows
ti,j ← arg max ti,j∈Ti,j score(x, s, ti,j , t−(i,j), y) (3)
where t−(i,j) are the rest of the POS tags when we update ti,j .
",3.2 Decoding,[0],[0]
"2We do not hill-climb segmentation, or else we have to jointly find the optimal t and y, and the resulting computational cost is too high.
",3.2 Decoding,[0],[0]
3We notice that the distribution becomes significantly sharper after training for several epochs.,3.2 Decoding,[0],[0]
"Therefore, we also smooth the distribution by multiplying the score with a scaling factor.
",3.2 Decoding,[0],[0]
"4We also smooth the distribution in the same way as in segmentation and POS tagging.
HillClimbTree",3.2 Decoding,[0],[0]
:,3.2 Decoding,[0],[0]
We improve the dependency tree y via a similar hill-climbing process.,3.2 Decoding,[0],[0]
"Specifically, we greedily update the head yi,j of each morpheme in a bottom-up order as follows
yi,j ← arg max yi,j∈Yi,j score(x, s, t, yi,j , y−(i,j))",3.2 Decoding,[0],[0]
"(4)
where Yi,j is the set of candidate heads such that changing yi,j to any candidate does not violate the tree constraint.",3.2 Decoding,[0],[0]
"We learn the parameters θ in a max-margin framework, using on-line updates.",3.3 Training,[0],[0]
"For each update, we need to compute the segmentations, POS tags and the tree that maximize the cost-augmented score:
(s̃, t̃, ỹ) = arg max s∈S,t∈T ,y∈Y {θ·f(x, s, t, y)+Err(s, t, y)} (5) whereErr(s, t, y) is the number of errors of (s, t, y) against the ground truth (ŝ, t̂, ŷ).",3.3 Training,[0],[0]
The parameters are then updated to guide the selection against the violation.,3.3 Training,[0],[0]
"This is done via standard passive-aggressive updates (Crammer et al., 2006).",3.3 Training,[0],[0]
"In this section we describe how the proposed model can be adapted to languages that do not delineate
words with spaces, and thus require word segmentation.",3.4 Adapting to Chinese Joint Prediction,[0],[0]
The main difference lies in the construction of the lattice structure.,3.4 Adapting to Chinese Joint Prediction,[0],[0]
We employ a state-of-the-art word segmenter to produce candidate word boundaries.,3.4 Adapting to Chinese Joint Prediction,[0],[0]
We consider boundaries common across all the top-k candidates as true word boundaries.,3.4 Adapting to Chinese Joint Prediction,[0],[0]
"The remaining tokens (i.e., strings between these boundaries) are treated as words to be further segmented and labeled with POS tags.",3.4 Adapting to Chinese Joint Prediction,[0],[0]
Figure 3 shows an example of the Chinese word lattice structure we construct.,3.4 Adapting to Chinese Joint Prediction,[0],[0]
"Once the lattice is constructed, the joint prediction model is applied as described above.",3.4 Adapting to Chinese Joint Prediction,[0],[0]
"Segmentation Features For both Arabic and Chinese, each segmentation is represented by its score from the preprocessing system, and by the corresponding morphemes (or words in Chinese).",4 Features,[0],[0]
"Following previous work (Zhang and Clark, 2010), we also add character-based features for Chinese word segmentation, including the first and the last characters in the word, and the length of the word.
",4 Features,[0],[0]
POS Tag Features Table 1 summarizes the POS tag features employed by the model.,4 Features,[0],[0]
"First, we use the feature templates proposed in our previous work on Arabic joint parsing and POS correction (Zhang et al., 2014c).",4 Features,[0],[0]
"In addition, we incorporate character-based features specifically designed for Chinese.",4 Features,[0],[0]
"These features are mainly inspired by previous transition-based models on Chinese joint POS tagging and word segmentation (Zhang and Clark, 2010).
",4 Features,[0],[0]
Dependency Parsing Features,4 Features,[0],[0]
"The feature templates for dependency parsing are mainly drawn from our previous work (Zhang et al., 2014b).",4 Features,[0],[0]
"Fig-
ure 4 shows the first- to third-order feature templates that we use in our model.",4 Features,[0],[0]
"We also use global features to capture the adjacent conjuncts agreement in a coordination structure, and the valency patterns for each POS category.",4 Features,[0],[0]
Note that most dependency features are implicitly cross-task in that they include POS tag and segmentation information.,4 Features,[0],[0]
"For example, the standard feature involves the POS tags of the words on both ends of the arc.",4 Features,[0],[0]
We evaluate our model on two Arabic datasets and one Chinese dataset.,5.1 Datasets,[0],[0]
"For the first Arabic dataset, we use the dataset used in the Statistical Parsing of
Morphologically Rich Languages (SPMRL) Shared Task 2013 (Seddah et al., 2013).5 We follow the official split for training, development and testing set.",5.1 Datasets,[0],[0]
We use the core set of 12 POS categories provided by Marton et al. (2013).,5.1 Datasets,[0],[0]
"In the second Arabic dataset, the training set is a dependency conversion of the Arabic Treebank, which primarily includes Modern Standard Arabic (MSA) text.",5.1 Datasets,[0],[0]
"However, we test on a new corpus, which consists of classical Arabic text obtained from the Comprehensive Islamic Library (CIS).6 A native Arabic speaker with background in computational linguistics annotated the morphological segmentation and POS tags.",5.1 Datasets,[0],[0]
"This corpus is an excellent testbed for a joint model because classical Arabic may use rather different vocabulary from MSA, while their syntactic grammars are very similar to each other.",5.1 Datasets,[0],[0]
Therefore incorporating syntactic information should be particularly beneficial to morphological segmentation and POS tagging.,5.1 Datasets,[0],[0]
"For Chinese, we use the Chinese Penn Treebank 5.0 (CTB5) and follow the split in previous work (Zhang and Clark, 2010).
",5.1 Datasets,[0],[0]
Table 2 summarizes the statistics of the datasets.,5.1 Datasets,[0],[0]
"For the SPMRL test set, we follow the common practice which limits the sentence lengths up to 70 (Seddah et al., 2013).",5.1 Datasets,[0],[0]
"For classical Arabic and Chinese, we evaluate on all the test sentences.",5.1 Datasets,[0],[0]
"In this section we introduce the methodology for constructing candidate sets for segmentation and
5This dataset is originally provided by the LDC (Maamouri et al., 2004), specifically its SPMRL 2013 dependency instance, derived from the Columbia Catib Treebank (Habash and Roth, 2009; Habash et al., 2009) and extended according to the SPMRL 2013 extension scheme (Seddah et al., 2013).
",5.2 Generating Lattice Structures,[0],[0]
"6This classical Arabic dataset is publicly available at http: //farasa.qcri.org/
POS tagging.",5.2 Generating Lattice Structures,[0],[0]
"Table 3 provides statistics on the generated candidate sets.
",5.2 Generating Lattice Structures,[0],[0]
SPMRL 2013,5.2 Generating Lattice Structures,[0],[0]
"Following Marton et al. (2013), we use the MADA system to generate candidate morphological analyses and POS tags.",5.2 Generating Lattice Structures,[0],[0]
"For each token in the sentence, MADA provides a list of possible morphological analyses and POS tags, each associated with a score.",5.2 Generating Lattice Structures,[0],[0]
The score of each segmentation or POS tag equals the highest score of the MADA analysis in which it appears.,5.2 Generating Lattice Structures,[0],[0]
"In addition, we associate each segmentation with MADA analyses on gender, number and person.",5.2 Generating Lattice Structures,[0],[0]
"Figure 5 shows an example of MADA output for the token Emlyp and the corresponding lattice structure.
",5.2 Generating Lattice Structures,[0],[0]
Classical Arabic We construct the lattice for this corpus in a similar fashion to the SPMRL dataset with two main departures.,5.2 Generating Lattice Structures,[0],[0]
"First, we use the Arabic morphological analyzer developed by Darwish et al. (2014) because MADA is primarily trained for MSA and performs poorly on classical Arabic.",5.2 Generating Lattice Structures,[0],[0]
"Second, we implement a CRF-based morpheme-level POS tagger and generate the POS tag candidates for each morpheme based on their marginal probabilities, truncated by a probability threshold.
",5.2 Generating Lattice Structures,[0],[0]
CTB5,5.2 Generating Lattice Structures,[0],[0]
"We first re-train the Stanford Chinese word segmenter on CTB5 and generate a top-10 list for each sentence.7 We treat the word boundaries shared across all the 10 candidates as the confident ones,
7We use 10-fold cross validation to avoid overfitting on the training set.
and construct the lattice as described in Section 3.4.",5.2 Generating Lattice Structures,[0],[0]
Our model then focuses on disambiguating the rest of the word boundaries in the candidates.,5.2 Generating Lattice Structures,[0],[0]
"To generate POS candidates, we apply a CRF-based tagger with Chinese-specific features used in previous work (Hatori et al., 2011).",5.2 Generating Lattice Structures,[0],[0]
"Following standard practice in previous work (Hatori et al., 2012; Zhang et al., 2014a), we use Fscore as the evaluation metric for segmentation, POS tagging and dependency parsing.",5.3 Evaluation Measures,[0],[0]
We report the morpheme-level F-score for Arabic and the wordlevel F-score for Chinese.,5.3 Evaluation Measures,[0],[0]
"In addition, we use TedEval (Tsarfaty et al., 2012) to evaluate the joint prediction on the SPMRL dataset, because TedEval score is the only evaluation metric used in the official report.",5.3 Evaluation Measures,[0],[0]
We directly use the evaluation tools provided on the SPMRL official website.8,5.3 Evaluation Measures,[0],[0]
"State-of-the-Art Systems For the SPMRL dataset, we directly compare with Björkelund et al. (2013).",5.4 Baselines,[0],[0]
This system achieves the best TedEval score in the track of dependency parsing with predicted information and we directly republish the official result.,5.4 Baselines,[0],[0]
We also compute the F-score of this system on each task using our own evaluation script.9,5.4 Baselines,[0],[0]
"For the CTB5 dataset, we directly compare to the arc-eager system by Zhang et al. (2014a), which slightly outperforms the arc-standard system by Hatori et al. (2012).
8http://www.spmrl.org/spmrl2013-sharedtask.html 9F-score evaluation for Arabic is not straightforward due to the stem changes in the morphological analysis.",5.4 Baselines,[0],[0]
"Therefore, the comparison of F-scores is only approximate.
",5.4 Baselines,[0],[0]
System Variants We also compare against a pipeline variation of our model.,5.4 Baselines,[0],[0]
"In our pipeline model, we predict segmentations and POS tags by the same system that we use to generate candidates.",5.4 Baselines,[0],[0]
The subsequent standard parsing model then operates on the predicted segmentations and POS tags.,5.4 Baselines,[0],[0]
"Following our earlier work (Zhang et al., 2014b), we train a first-order classifier to prune the dependency tree space.10 Following common practice, we average parameters over all iterations after training with passive-aggressive online learning algorithm (Crammer et al., 2006; Collins, 2002).",5.5 Experimental Details,[0],[0]
"We use the same adaptive random restart strategy as in our earlier work (Zhang et al., 2014b) and set K = 300.",5.5 Experimental Details,[0],[0]
"In addition, we also apply an aggressive early-stop strategy during training for efficiency.",5.5 Experimental Details,[0],[0]
"If we have found a violation against the ground truth during the first 50 iterations, we immediately stop and update the
10We set the probability threshold to 0.05 and limit the number of candidate heads up to 20, which gives a 99.5% pruning recall on both the SPMRL and the CTB5 development sets.
parameters based on the current violation.",5.5 Experimental Details,[0],[0]
"The reasoning behind this early-stop strategy is that weaker violations for some training sentences are already sufficient for separable training sets (Huang et al., 2012).",5.5 Experimental Details,[0],[0]
"Comparison to State-of-the-art Systems Table 4 summarizes the performance of our model and the best published results for the SPMRL and the CTB5 datasets.11 On both datasets, our system outperforms the baselines.",6 Results,[0],[0]
"On the SPMRL 2013 shared task, our approach yields a 2.1% TedEval score gain over the top performing system (Björkelund et al., 2013).",6 Results,[0],[0]
We also improve the segmentation and dependency F-scores by 3.1% and 4.8% respectively.,6 Results,[0],[0]
Note that the POS F-scores are not directly comparable because Björkelund et al. (2013) use a different POS tagset from us.,6 Results,[0],[0]
"On the CTB5 dataset, we outperform the state-of-the-art with respect to all
11We are not aware of any published results on the Classical Arabic Dataset.
tasks: segmentation (0.3%), tagging (0.1%), and dependency parsing (0.3%).12
Impact of the Joint Prediction As Table 4 shows, our joint prediction model consistently outperforms the corresponding pipeline model in all three tasks.",6 Results,[0],[0]
"This observation is consistent with findings in previous work (Hatori et al., 2012; Tratz, 2013).",6 Results,[0],[0]
"We also observe that gains are higher (2%) on the classical Arabic dataset, which demonstrates that joint prediction is particularly helpful in bridging the gap between MSA and classical Arabic.
",6 Results,[0],[0]
12Zhang et al. (2014a) improve the dependency F-score to 82.14% by adding manually annotated intra-word dependency information.,6 Results,[0],[0]
"Even without such gold word structure annotations, our model still achieves a comparable result.
",6 Results,[0],[0]
Figure 6 shows the break of the improvement based on seen and out-of-vocabulary (OOV) words.,6 Results,[0],[0]
"As expected, across all languages OOV words benefit more from the joint prediction, as they constitute a common source of error propagation in a pipeline model.",6 Results,[0],[0]
The extent of improvement depends on the underlying accuracy of the preprocessing for segmentation and POS tagging on OOV words.,6 Results,[0],[0]
"For instance, we observe a higher gain (7%) on Chinese OOV words which have a 61.5% accuracy when processed by the original stand-along POS tagger.",6 Results,[0],[0]
"On the SPMRL dataset, the gain on OOV words is lower (3%), while preprocessing accuracy is higher (82%).",6 Results,[0],[0]
Their error reductions on OOV words are nevertheless close to each other.,6 Results,[0],[0]
"Table 5 summarizes the results on F-score error reduction.
",6 Results,[0],[0]
We also observe that the error reductions of OOV words/morphemes on the Chinese and the Classical Arabic dataset are larger than that of the invocabulary counterparts (e.g. 26% vs. 20% on Chinese word segmentation).,6 Results,[0],[0]
"However, we have the opposite observation on the segmentation and POS tagging on the SPMRL dataset (28% vs. 48%).",6 Results,[0],[0]
This can be explained by analyzing the oracle performance in which we select the best solution from possible candidates.,6 Results,[0],[0]
"The oracle error reduction of OOV morphemes in the SPMRL dataset is relatively low (44%), compared to the 61% oracle error reduction of OOV morphemes in the Classical Arabic dataset.
",6 Results,[0],[0]
"Impact of the Number of Alternative Analyses In Figure 7, we plot the performance on the SPMRL dataset as a function of the number k of MADA analyses that we use to construct the candidate sets.",6 Results,[0],[0]
"For low k, increasing the number of analyses improves performance across all evaluation metrics.",6 Results,[0],[0]
"However, the performance converges at around k = 15.
",6 Results,[0],[0]
"Convergence Properties To assess the quality of the approximation obtained by the randomized greedy inference, we would like to compare it against the optimal solution.",6 Results,[0],[0]
"Following our earlier work (Zhang et al., 2014b), we use the highest score among 3,000 restarts for each sentence as a proxy for the optimal solution.",6 Results,[0],[0]
Figure 8 shows the normalized score of the retrieved solution as a function of the number of restarts.,6 Results,[0],[0]
We observe that most sentences converge quickly.13,6 Results,[0],[0]
"Specifically, more than 97% of the sentences converge within first 300 restarts.",6 Results,[0],[0]
"Since for the vast majority of cases our system converges fast, we achieve a comparable speed to that of other state-of-the-art joint systems.",6 Results,[0],[0]
"For example, our model achieves high performance on Chinese at about 0.5 sentences per second.",6 Results,[0],[0]
"The speed is about the same as that of the transition-based system (Hatori et al., 2012) with beam size 64, the setting that achieved best accuracy in their work.
",6 Results,[0],[0]
Quality of Local Optima Figure 9 shows the cumulative distribution function (CDF) for the number of local optima versus the score of these local optima obtained from each restart.,6 Results,[0],[0]
"More specifically, the score captures the difference between a local optimum and the maximal score among 3,000 restarts.",6 Results,[0],[0]
"We can see that most of the local optima reached by hill-climbing have scores close to
13As expected, we also observe that convergence is slower when comparing to standard dependency parsing with a similar randomized greedy algorithm (Zhang et al., 2014b), because joint prediction results in a harder inference problem.
",6 Results,[0],[0]
the maximum.,6 Results,[0],[0]
"For instance, about 30% of the local optima are identical to the best solution, namely scoremax − scorelocal = 0.",6 Results,[0],[0]
"In this paper, we propose a general randomized greedy algorithm for joint segmentation, POS tagging and dependency parsing.",7 Conclusions,[0],[0]
"On both Arabic and Chinese, our model achieves improvement on the three tasks over state-of-the-art systems and pipeline variants of our system.",7 Conclusions,[0],[0]
"In particular, we demonstrate that OOV words benefits more from the power of joint prediction.",7 Conclusions,[0],[0]
"Finally, our experimental results show that increasing candidate sizes improves performance across all evaluation metrics.",7 Conclusions,[0],[0]
This research is developed in a collaboration of MIT with the Arabic Language Technologies (ALT) group at Qatar Computing Research Institute (QCRI) within the Interactive sYstems for Answer Search (IYAS) project.,Acknowledgments,[0],[0]
"The authors acknowledge the support of the U.S. Army Research Office under grant number W911NF-10-1-0533, and of the DARPA BOLT program.",Acknowledgments,[0],[0]
We thank Meishan Zhang and Anders Björkelund for answering questions and sharing the outputs of their systems.,Acknowledgments,[0],[0]
We also thank the MIT NLP group and the ACL reviewers for their comments.,Acknowledgments,[0],[0]
"Any opinions, findings, conclusions, or recommendations expressed in this paper are those of the authors, and do not necessarily reflect the views of the funding organizations.",Acknowledgments,[0],[0]
"In this paper, we introduce a new approach for joint segmentation, POS tagging and dependency parsing.",abstractText,[0],[0]
"While joint modeling of these tasks addresses the issue of error propagation inherent in traditional pipeline architectures, it also complicates the inference task.",abstractText,[0],[0]
Past research has addressed this challenge by placing constraints on the scoring function.,abstractText,[0],[0]
"In contrast, we propose an approach that can handle arbitrarily complex scoring functions.",abstractText,[0],[0]
"Specifically, we employ a randomized greedy algorithm that jointly predicts segmentations, POS tags and dependency trees.",abstractText,[0],[0]
"Moreover, this architecture readily handles different segmentation tasks, such as morphological segmentation for Arabic and word segmentation for Chinese.",abstractText,[0],[0]
"The joint model outperforms the state-of-the-art systems on three datasets, obtaining 2.1% TedEval absolute gain against the best published results in the 2013 SPMRL shared task.1",abstractText,[0],[0]
"Randomized Greedy Inference for Joint Segmentation, POS Tagging and Dependency Parsing",title,[0],[0]
"data, i.e., a new family of probability distributions on permutations. Our model is inspired by the idea of a data-generating process in the form of a noisy sorting procedure, in which deterministic comparisons between pairs of items are replaced by Bernoulli trials. The probability of producing a certain ranking as a result then essentially depends on the Bernoulli parameters, which can be interpreted as pairwise preferences. We show that our model can be written in closed form if insertion sort is used as sorting algorithm and can be characterized recursively if quick sort is used, and propose a maximum likelihood approach for parameter estimation. We also introduce a generalization of the model, in which the constraints on pairwise preferences are relaxed, and for which maximum likelihood estimation can be carried out based on a variation of the generalized iterative scaling algorithm. Experimentally, we show that the models perform very well in terms of goodness of fit, compared to existing models for ranking data.",text,[0],[0]
"The analysis of ranking data has a long tradition in statistics, and corresponding methods have been used in various fields of application, such as psychology and the social sciences (Marden, 1996).",1. Introduction,[0],[0]
"More recently, applications in information retrieval (Liu, 2009) and machine learning (F¨urnkranz & H¨ullermeier, 2010) have caused a renewed interest in the analysis of rankings and related statistical tools, such as probability distributions on rankings.
",1. Introduction,[0],[0]
"In contrast to probability distributions on the reals, the number of parametric distributions on rankings (permutations
1
Heinz Nixdorf Institute and Department of Computer Science,
Paderborn University, Germany
2
Yahoo Research, New York, USA.
Correspondence to: Adil El Mesaoudi-Paul <adil.paul@upb.de>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
of a fixed size) is rather limited.",1. Introduction,[0],[0]
"The most popular models are Mallows (Mallows, 1957) and Plackett-Luce (Plackett, 1975; Luce, 1959), and to a lesser extent Babington Smith (Babington-Smith, 1950).",1. Introduction,[0],[0]
"In this paper, we add another class of probability distributions to this repertoire.
",1. Introduction,[0],[0]
"Our model is inspired by the idea of a data-generating process in the form of a noisy sorting procedure (Biernacki & Jacques, 2013), that is, the idea that a ranking is produced as the result of a sorting process, in which comparisons are not deterministic but dependant on chance.",1. Introduction,[0],[0]
"More specifically, comparisons between pairs of items are modelled as Bernoulli trials, with the Bernoulli parameters representing pairwise preferences.",1. Introduction,[0],[0]
"While these preferences obey certain consistency constraints for our basic model, we also introduce a generalization for which these constraints are relaxed.",1. Introduction,[0],[0]
"For two sorting algorithms, insertion sort and quick sort, we show that the former model can be written in closed form, and that the latter has a recursive characterization.
",1. Introduction,[0],[0]
"In addition to proposing the models themselves, we address the problem of parameter estimation based on sample data.",1. Introduction,[0],[0]
"More specifically, we devise procedures for efficient maximum likelihood estimation.",1. Introduction,[0],[0]
"In an experimental study, we assess the performance of our models in terms of goodness of fit on a large number of real-world data sets.
",1. Introduction,[0],[0]
The rest of the paper is organized as follows.,1. Introduction,[0],[0]
"In the next section, we introduce notation and recall the basic families of probability distributions on rankings.",1. Introduction,[0],[0]
"Our new model classes are introduced in Section 3, their instantiation for specific sorting algorithms is discussed in Section 4, and the problem of parameter estimation is addressed in Section 5.",1. Introduction,[0],[0]
"Experimental results are presented in Section 6, prior to concluding the paper in Section 7.",1. Introduction,[0],[0]
"Consider a fixed set O = {o1, . . .",2. Probability Distributions on Rankings,[0],[0]
", oK} of K choice alternatives (objects/options/items).",2. Probability Distributions on Rankings,[0],[0]
"We identify a ranking over O with a permutation ⇡ 2 SK , where SK denotes the collection of permutations on [K] = {1, . . .",2. Probability Distributions on Rankings,[0],[0]
",K}.",2. Probability Distributions on Rankings,[0],[0]
"Thus, each ⇡ is a mapping [K] !",2. Probability Distributions on Rankings,[0],[0]
"[K], such that ⇡(k) denotes the position of the kth item ok in the associated ranking.",2. Probability Distributions on Rankings,[0],[0]
"With each ranking ⇡, we associate an ordering ⇡ 1, where ⇡ 1(j) is the index of the item on position j. To simplify notation, we
shall denote by ⇡ both a ranking and the associated ordering, writing the former in brackets and the latter in parentheses.",2. Probability Distributions on Rankings,[0],[0]
"For example, ⇡ = [2, 3, 1], ⇡ = (3, 1, 2), as well as the function ⇡ defined by ⇡(1) = 2,⇡(2) = 1,⇡(3) = 1, all denote the ranking in which o3 is at the top, o1 in the middle, and o2 on the last position.",2. Probability Distributions on Rankings,[0],[0]
"The Mallows model (MM) (Mallows, 1957) belongs to the exponential family of distributions and is parametrized by a reference ranking ⌧ and a dispersion parameter :
P⌧, (⇡) = 1
C( ) exp
D(⇡, ⌧) ,
where D(⇡, ⌧) is the Kendall distance (the number of pairwise inversions between ⇡ and ⌧ ) and C( ) a normalization constant.",2.1. Mallows Distribution and Extensions,[0],[0]
"Thus, Mallows is a distance-based model: the probability of a ranking ⇡ decreases with increasing distance from ⌧ , which is the mode of the distribution.
",2.1. Mallows Distribution and Extensions,[0],[0]
"The generalized Mallows model (GMM) (Fligner & Verducci, 1986) is an extension of the MM model, which has K 1 dispersion parameters 1, . . .",2.1. Mallows Distribution and Extensions,[0],[0]
", K 1.",2.1. Mallows Distribution and Extensions,[0],[0]
"Each of the latter affects one specific position in the ranking, thereby allowing permutations at the same distance from the reference ranking to have different probabilities.",2.1. Mallows Distribution and Extensions,[0],[0]
"The probability of a ranking ⇡ according to the GMM model is given by
P⌧, (⇡) = 1
C( ) exp
0 @ K 1X
j=1
jVj(⇡)
1 A ,
where",2.1. Mallows Distribution and Extensions,[0],[0]
"Vj(⇡) = P
i>j
q ⇡ 1(i) < ⇡ 1(j) y is the number
of inversions for item oj in ⇡ with respect to the identity permutation 1 .",2.1. Mallows Distribution and Extensions,[0],[0]
"As such, the GMM model uses an insertion procedure in its generative process, in which a ranking is generated by iteratively inserting elements according to the reference ranking into a list.",2.1. Mallows Distribution and Extensions,[0],[0]
"The probability of inserting an element into a specific position is controlled by the inversion distance and the -parameters.
",2.1. Mallows Distribution and Extensions,[0],[0]
"Meek & Meila (2014) further extend the GMM to the recursive inversion model (RIM), which is able to capture a hierarchical structure on the items.",2.1. Mallows Distribution and Extensions,[0],[0]
"Instead of inserting single items, complete subsequences are merged in a recursive manner, preserving the order within each subsequence.",2.1. Mallows Distribution and Extensions,[0],[0]
"The model is specified by a binary recursive decomposition of the items represented by a structure ⌧ , and the number of inversions is controlled by a parameter ✓i associated with each merge operation.",2.1. Mallows Distribution and Extensions,[0],[0]
"By representing a RIM as a binary tree, where the leaves correspond to the items and the internal vertices I to the parameters",2.1. Mallows Distribution and Extensions,[0],[0]
"✓i, the probability of a 1J·K maps true predictaes to 1 and false predicates to 0.
ranking ⌧(✓) becomes proportional to Y
i2I exp
✓ivi(⇡,⇡⌧ ) ,
where vi(⇡,⇡⌧ ) is the number of inversions at vertex i of ⌧(✓) for the ranking ⇡.",2.1. Mallows Distribution and Extensions,[0],[0]
"The Plackett-Luce (PL) model (Plackett, 1975; Luce, 1959) is parametrized by a vector ✓ = (✓1, ✓2, . . .",2.2. Plackett-Luce Distribution,[0],[0]
", ✓K) 2 RK+ .",2.2. Plackett-Luce Distribution,[0],[0]
Each ✓i can be interpreted as the weight or “strength” of the option oi.,2.2. Plackett-Luce Distribution,[0],[0]
"The probability assigned by the PL model to a ranking represented by a permutation ⇡ 2 SK is given by
P✓(⇡) = KY
i=1
✓⇡ 1(i) ✓⇡ 1(i) +",2.2. Plackett-Luce Distribution,[0],[0]
✓⇡ 1(i+1) + . .,2.2. Plackett-Luce Distribution,[0],[0]
.+,2.2. Plackett-Luce Distribution,[0],[0]
"✓⇡ 1(K) (1)
",2.2. Plackett-Luce Distribution,[0],[0]
"The product on the right-hand side of (1) is the probability of producing the ranking ⇡ in a stagewise process: First, the item on the first position is selected, then the item on the second position, and so forth.",2.2. Plackett-Luce Distribution,[0],[0]
"In each step, the probability of an item to be chosen next is proportional to its weight.",2.2. Plackett-Luce Distribution,[0],[0]
"Consequently, items with a higher weight tend to occupy higher positions.",2.2. Plackett-Luce Distribution,[0],[0]
"In particular, the most probable ranking (i.e., the mode of the PL distribution) is simply obtained by sorting the items in decreasing order of their weight:
⌧ = argmax ⇡2SK P✓(⇡) = argsort k2[K] {✓1, . . .",2.2. Plackett-Luce Distribution,[0],[0]
", ✓K} (2)",2.2. Plackett-Luce Distribution,[0],[0]
"The Babington Smith (BS) model is defined as follows (Babington-Smith, 1950):
P✓(⇡) = 1
C(✓)
Y
1i<jK p⇡ 1(i),⇡ 1(j) , (3)
where pi,j is the probability to observe a preference oi",2.3. Babington Smith Distribution,[0],[0]
"oj in a direct comparison between oi and oj , and C(✓) is a normalization constant.",2.3. Babington Smith Distribution,[0],[0]
"Thus, the parametrization ✓ of the BS model consists of all pairwise probabilities pi,j = 1 pj,i, 1  i < j  K.
The BS distribution results from the following “trial and error” data-generating process: First, the order of each pair of objects oi",2.3. Babington Smith Distribution,[0],[0]
"and oj is determined independently at random (as a result of a Bernoulli trial, i.e., by flipping a coin with bias pi,j).",2.3. Babington Smith Distribution,[0],[0]
"Then, in case all pairwise comparisons form a consistent ranking, this ranking is adopted, otherwise the first step is repeated.",2.3. Babington Smith Distribution,[0],[0]
The previous models can naturally be distinguished in terms of their parametrization.,2.4. Comparison,[0],[0]
The Mallows model is quite restricted and not very flexible.,2.4. Comparison,[0],[0]
"It has one degree of freedom
to determine the location of the distribution (the reference ranking), and another parameter to determine the spread (comparable, for example, to the normal distribution on the reals).",2.4. Comparison,[0],[0]
"The PL model is more flexible (for example, see (Cheng et al., 2012) for a comparison of the expressivity of Mallows and PL), with a number of parameters that is linear in the number of items.",2.4. Comparison,[0],[0]
"BS has an even richter parametrization, the size of which grows quadratically with the number of items.
",2.4. Comparison,[0],[0]
"From a preference modeling point of view, the parametrizations of PL and BS are both quite natural: PL specifies the strength of each option individually, whereas BS takes pairwise comparisons as a point of departure.",2.4. Comparison,[0],[0]
"Thus, while PL implies relatively strong consistency properties, such as strong stochastic transitivity, BS principally allows for preferential cycles.",2.4. Comparison,[0],[0]
"PL and BS can both be interpreted in terms of an underlying data-generating process, in which a ranking is produced as the result of a specific stochastic process.",3. Ranking Distributions based on Sorting,[0],[0]
"However, especially in the case of BS, the “cognitive plausibility” of the process is questionable: It is difficult to imagine that a ranking of items is indeed produced by repeating the full set of stochastic pairwise comparisons, independently of each other, till reaching consistency (especially since most of such repetitions will be futile).
",3. Ranking Distributions based on Sorting,[0],[0]
"As an arguably more plausible assumption, one could imagine that a ranking is the result of a (noisy) sorting procedure.",3. Ranking Distributions based on Sorting,[0],[0]
"Indeed, when people produce a ranking, they often apply some kind of sorting process, in which items are compared only if necessary.",3. Ranking Distributions based on Sorting,[0],[0]
"This idea has recently been put forward by Biernacki and Jacques (Biernacki & Jacques, 2013), and provides the main point of departure for our contribution.
",3. Ranking Distributions based on Sorting,[0],[0]
"A sorting algorithm puts objects stored in a list in a certain order, based on pairwise comparisons between these objects.",3. Ranking Distributions based on Sorting,[0],[0]
"Most often, the objects to be sorted are numbers, and the pairwise comparison is determined based on some binary relation, for example, the  relation for increasing and relation for decreasing order.",3. Ranking Distributions based on Sorting,[0],[0]
"Note that the list submitted as input to a (deterministic) sorting algorithm does not affect its output, but it does have an influence on its time complexity, and on the pairs of items that are compared.",3. Ranking Distributions based on Sorting,[0],[0]
"Therefore, the time complexity of sorting algorithms is often analyzed under the assumption of a uniform distribution over the possible inputs (average time complexity analysis).",3. Ranking Distributions based on Sorting,[0],[0]
"The model by Biernacki and Jacques (Biernacki & Jacques, 2013), called Insertion Sort Rank data (ISR) model, is specified by a reference ranking ⌧ and real parameter p, very
much like the Mallows model.",3.1. Insertion Sort Rank Data Model,[0],[0]
"The former corresponds to the “correct” ranking, i.e., the mode of the distribution, and p 2 [0.5, 1] is the noise parameter that controls the peakedness of the distribution.",3.1. Insertion Sort Rank Data Model,[0],[0]
"More specifically, the following assumption is made: A sorting algorithm (insertion sort) is run on an initial ordering ⇡, and whenever two items oi",3.1. Insertion Sort Rank Data Model,[0],[0]
"and oj are compared, the “right” outcome (consistent with ⌧ ) is produced with probability p (hence the “wrong” outcome with probability 1 p).
",3.1. Insertion Sort Rank Data Model,[0],[0]
"The algorithm’s probability to terminate with a ranking obviously depends on the initial ordering ⇡, which is a latent variable of the model.",3.1. Insertion Sort Rank Data Model,[0],[0]
"To get rid of this influence, the initialization is “averaged out”, i.e., an expectation is taken over all initial rankings.",3.1. Insertion Sort Rank Data Model,[0],[0]
"Assuming a uniform distribution for ⇡, we thus obtain
P( | ⌧, p) = 1 K!
X
⇡2SK P( |⇡, ⌧, p) .",3.1. Insertion Sort Rank Data Model,[0],[0]
"(4)
This model can also be written as follows:
P( |P) = 1 C 0(P)
",3.1. Insertion Sort Rank Data Model,[0],[0]
"X
⇡2SK P( |⇡,P) ,
=
1
C 0(P)
",3.1. Insertion Sort Rank Data Model,[0],[0]
"X
⇡2SK
KY
i=1
Y j 6=i pi,j d ,⇡i,j , (5)
where P is a K ⇥K matrix P =",3.1. Insertion Sort Rank Data Model,[0],[0]
"[pi,j ]1i,jK with entries
pi,j = pi,j(⌧, p) =
⇢ p if ⌧(oi) < ⌧(oj)
1 p if ⌧(oi) >",3.1. Insertion Sort Rank Data Model,[0],[0]
⌧(oj) .,3.1. Insertion Sort Rank Data Model,[0],[0]
"(6)
That is, the matrix P is uniquely determined by ⌧ and p (and vice versa).",3.1. Insertion Sort Rank Data Model,[0],[0]
"Moreover, for rankings ,⇡ 2 SK ,
D ,⇡ = ⇥",3.1. Insertion Sort Rank Data Model,[0],[0]
"d ,⇡i,j ⇤ 1i,jK
is a binary matrix with entries d ,⇡i,j = 1 if the sorting algorithm, given ⇡ as initial ordering and producing as output, has compared oi to oj with a win for oi, and to 0 otherwise.",3.1. Insertion Sort Rank Data Model,[0],[0]
"Finally,
C 0(P)",3.1. Insertion Sort Rank Data Model,[0],[0]
"= X
2SK
X
⇡2SK
KY
i=1
Y j 6=i pi,j d ,⇡i,j
is the normalization constant.
",3.1. Insertion Sort Rank Data Model,[0],[0]
"Biernacki and Jacques tackle the problem of estimating the parameters of the model, ⌧ and p, using the maximum likelihood principle.",3.1. Insertion Sort Rank Data Model,[0],[0]
"To this end, they adopt a latent variable interpretation of the model and propose an EM algorithm.",3.1. Insertion Sort Rank Data Model,[0],[0]
"Our model is a modification of (5), which looks very similar at first sight: Instead of averaging out the influence of the
initial ranking ⇡ in an additive way, by aggregating the probabilities P( |⇡, ⌧, p) with an arithmetic mean, we apply the product as an aggregation function:
PA( | ⌧, p) / Y
⇡2SK PA( |⇡, ⌧, p) ,
where A is the underlying sorting algorithm.",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"As for the latter, one may of course consider algorithms other than insertion sort.",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"Indeed, any pairwise-comparison-based sorting algorithm can in principle be extended to a noisy sorting model by using stochastic pairwise comparisons (Braverman & Mossel, 2008; 2009).",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"In Section 4, we will instantiate our model for two algorithms, insertion sort and quick sort.
",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
There are different motivations for the above modification.,3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"First, as will be seen, the multiplicative variant has appealing mathematical properties and can be handled a bit more easily.",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"Second, the model can also be motivated intuitively.",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"The product is a conjunctive aggregation function (Grabisch et al., 2009), and combining probabilities in a conjunctive way is in agreement with standard (deterministic) sorting, where the “correct” output ordering is obtained regardless of the initial ordering ⇡, that is, as a result for all initial orderings ⇡.",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"Therefore, we call our model the Conjunctive Noisy Sorting (CNS) model.
",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"Recall the definition of the matrix P with entries (6), which is in one-to-one relationship with the model parameters ⌧ and p.",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"With this notation, the CNS model can also be written as follows:
PA( |P) = 1
C(P)
Y
⇡2SK P( |⇡,P) ,
=
1
C(P)
Y
⇡2SK
KY
i=1
Y j 6=i pi,j d ,⇡i,j , (7)
where C(P) =",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
P 2SK Q ⇡2SK QK i=1,3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"Q j 6=i pi,j d ,⇡i,j .",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"To simplify this representation, we introduce
D = ⇥",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
d,3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"i,j ⇤ 1i,jK , d i,j =
X
⇡2SK d ,⇡i,j .
",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"With this notation, the model becomes
PA( |P) = 1
C(P)
KY
i=1
Y j 6=i pi,j d i,j , (8)
where
C(P) = X
2SK
KY
i=1
Y j 6=i pi,j d i,j .",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"(9)
In Section 4, explicit expressions for the exponents d i,j will be provided for two instantiations of the model (insertion sort and quick sort).",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"Note that, since pi,j = p or pi,j = 1 p
in (9), the normalization constant can be written as a power series in p:
C(p) =
e(K)X
j=0
↵(K)j · p",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"j
The degree e(K) and the coefficients ↵(K)j are specific to K but can be precomputed.",3.2. The Conjunctive Noisy Sorting Model,[0],[0]
"CNS is a relatively simple model, comparable to Mallows and ISR in terms of its parametrization.",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"The distribution has a single mode at ⌧ , and all pairwise preferences are consistent with this reference.",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Here, we consider a more general model, which subsumes the CNS model as a special case, and in which these assumptions are relaxed.",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"More specifically, like in the BS model, pairwise preferences pi,j are allowed to be defined independently for each pair of objects oi",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"and oj , and are not assumed to obey any consistency conditions.",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Thus, we assume a noisy sorting procedure in which, whenever the comparison of objects oi and oj is required, a coin with success probability pi,j is flipped, and the outcome of this Bernoulli experiment determines the order of the two elements: oi is preferred to oj if the outcome is 1, and oj is preferred to oi otherwise.",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"We furthermore assume that all pairwise comparisons are independent of each other, and that pi,j = 1 pj,i for all i, j 2",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
[K].,3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"We summarize the probabilities pi,j in the matrix P 2",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"[0, 1]K⇥K , which constitutes the parametrization of the model, referred to as Generalized Conjunctive Noisy Sorting (GCNS) model.",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Together with a sorting algorithm A and an initial ordering ⇡, GCNS defines a distribution PA(· |⇡,P) over SK .",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Thus, for each ranking 2 SK , PA( |⇡,P) is the probability to end up with when applying A to the input ⇡, and comparing items oi and oj according to pi,j .",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Again, we eliminate the latent variable ⇡ via conjunctive aggregation:
PA( |P) / Y
⇡2SK PA( |⇡,P)
To obtain a more compact representation, we introduce binary matrices D ,⇡ = ⇥",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"d ,⇡i,j ⇤ 1i,jK for rankings ,⇡ 2 SK , where the entry d ,⇡i,j in D ,⇡ is set to 1 if the sorting algorithm A, given ⇡ as initial ordering and producing as output, has compared oi to oj with a win for oi, and to 0 otherwise, and the matrices
D = ⇥",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
d,3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"i,j ⇤ 1i,jK , d i,j =
X
⇡2SK d ,⇡i,j .",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"(10)
We shall consider only such sorting algorithms for which all these matrices are well-defined (which means that, given and ⇡, it is clear whether and how oi and oj have been compared); this includes insertion sort and quick sort, amongst
others.",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Using this notation, the GCNS model can be written as follows:
PA( |P) = 1
C(P)
KY
i=1
Y j 6=i p d",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"i,j i,j , (11)
where
C(P) = X
2SK
KY
i=1
Y j 6=i p d",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"i,j i,j .",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"(12)
",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Based on (11), one can see that GCNS is a special case of the log-linear model over the symmetric group, because the log of the probabilities can be written as a linear function of the logarithm of the parameters.",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Note that the key quantity in the model is D , which we shall compute in a closed form when insertion sort is used as sorting algorithm, and characterize recursively when quick sort is used.",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Extreme probabilities pi,j 2 {0, 1} may cause problems in the case of inconsistencies, such as preferential cycles p1,2 = p2,3 = p3,1 = 1, which are not excluded in our general model.",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Applying a sorting algorithm A to some P 2 {0, 1}K⇥K , an initial ordering ⇡ will be turned into an ordering with probability 1, i.e., PA( |⇡,P) = 1 and PA( 0 |⇡,P) = 0 for all 0 6= .",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Then, unless the same is produced for all initial orderings ⇡, which is unlikely in the case of inconsistencies, the product Q ⇡ PA( |⇡,P) will vanish for all , which means that (11) is no longer well-defined.",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Therefore, we subsequently exclude extreme probabilities and assume 0 < pi,j < 1 for all i, j 2",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
[K].,3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
Observation 1.,3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
"Assuming that pi,j > 0 for all i, j 2 [K], the model (11) is well-defined in the sense that C(P) > 0; moreover, PA( |P) > 0 for all 2 SK .",3.3. The Generalized Conjunctive Noisy Sorting Model,[0],[0]
Our model has an interesting connection to BS.,3.4. Connection to BS,[0],[0]
"The latter is parametrized by the same probability matrix P, specifying probabilities pi,j = 1 pj,i for each pair of objects oi, oj .",3.4. Connection to BS,[0],[0]
"Moreover, with a normalizing constant C 00(P), it can be written as follows:
P( |P) = 1 C 00(P)
",3.4. Connection to BS,[0],[0]
"KY
i=1
Y j 6=i p d i,j i,j ,
where d i,j = 1 if (i) <",3.4. Connection to BS,[0],[0]
(j) and = 0 otherwise.,3.4. Connection to BS,[0],[0]
"Comparing this expression with (11), it can be seen that BS has exactly the same structure as our model.",3.4. Connection to BS,[0],[0]
"The key difference concerns the values d i,j , which can be seen as weights specifying the importance of the comparison between oi and oj .",3.4. Connection to BS,[0],[0]
"In BS, d i,j 2 {0, 1} and d i,j + d j,i ⌘ 1, which means that each pair has the same importance.",3.4. Connection to BS,[0],[0]
"In our model, where a pair (oi, oj) can be more or less relevant when producing a ranking with a sorting algorithms A, more general (integer) values are possible.
",3.4. Connection to BS,[0],[0]
"Interestingly, if the BS model is restricted such that pi,j = p if ⌧(i) <",3.4. Connection to BS,[0],[0]
"⌧(j) and pi,j = 1 p if ⌧(i) >",3.4. Connection to BS,[0],[0]
"⌧(j), for a fixed ⌧ 2 SK and probability p, it reduces to the Mallows model (Mallows, 1957).",3.4. Connection to BS,[0],[0]
"For exactly the same restriction, GCNS reduces to CNS.",3.4. Connection to BS,[0],[0]
"Roughly speaking, Mallows is to BS what CNS is to GCNS.",3.4. Connection to BS,[0],[0]
"Moreover, since GCNS can be seen as a “sorting variant” of BS, CNS can also be seen as a “sorting variant” of Mallows.",3.4. Connection to BS,[0],[0]
This is another strong motivation of our model.,3.4. Connection to BS,[0],[0]
"To make the definition of our models complete, we make use of two sorting algorithms A: insertion sort, denoted by I, and quick sort, denoted by Q. For insertion sort algorithm, we show that (8) and (11) can be written in closed form, and for quick sort algorithm, we show that they can be characterized in a recursive way.",4. Instantiations of the Ranking Model,[0],[0]
"In (stochastic) insertion sort, we start with an empty ordering, in which all K objects are inserted one by one, in the order determined by the initial ranking ⇡.",4.1. Insertion Sort,[0],[0]
"In the lth iteration, we are given a partial ordering (oi(1), . . .",4.1. Insertion Sort,[0],[0]
", oi(l))",4.1. Insertion Sort,[0],[0]
of l < K objects and insert another object o.,4.1. Insertion Sort,[0],[0]
"To this end, o is first compared with oi(1), then with oi(2), and so forth.",4.1. Insertion Sort,[0],[0]
"It is inserted as position j if oi(j) is the first item that looses its comparison with o; in case o is beaten by all l items, it is put on position l + 1.
",4.1. Insertion Sort,[0],[0]
"Thus, in stochastic insertion sort, we produce an output ranking from an initial ranking ⇡ by comparing only a subset of all possible pairs of items.",4.1. Insertion Sort,[0],[0]
Note that the output of the noisy sorting procesure is a random ordering that depends on the success probabilities P =,4.1. Insertion Sort,[0],[0]
"[pi,j ], and also on the initial ordering ⇡, i.e., the order in which items are inserted.",4.1. Insertion Sort,[0],[0]
The following example elaborates on this dependence.,4.1. Insertion Sort,[0],[0]
Example 1.,4.1. Insertion Sort,[0],[0]
"Consider insertion sort with two different initial orderings ⇡ = (o1, o2, o3) and ⇡0 = (o3, o2, o1).",4.1. Insertion Sort,[0],[0]
"Let the pairwise probabilities be p1,2 = 1/4, and p1,3 = p2,3 = 1/2.",4.1. Insertion Sort,[0],[0]
"Now let us compute the probability of observing = (o1, o2, o3).",4.1. Insertion Sort,[0],[0]
"Starting from ⇡, we first insert o1, then o2, and finally o3.",4.1. Insertion Sort,[0],[0]
"Ending with is thus only possible if o1 has beaten o2 in the first comparison, o1 has also beaten o3, and o2 has beaten o3.",4.1. Insertion Sort,[0],[0]
"Therefore, the probability of observing is proportional to p1,2p1,3p2,3 = 0.0625.",4.1. Insertion Sort,[0],[0]
"Starting from ⇡0, is produced with fewer comparisons, and the same probability is proportional to p1,2p2,3 = 0.125.",4.1. Insertion Sort,[0],[0]
"Now, we are going to focus on D = P
⇡2SK D ,⇡ , where
the sum is elmentwise.",4.1. Insertion Sort,[0],[0]
The following observation allows us to compute D in a concise way.,4.1. Insertion Sort,[0],[0]
Lemma 1.,4.1. Insertion Sort,[0],[0]
"Assume that id = (o1, . . .",4.1. Insertion Sort,[0],[0]
", oK).",4.1. Insertion Sort,[0],[0]
"Then, for
insertion sort, the matrix D id is given by
d idi,j =
8 < :
K! 2 if i < j K
bi,j+2
(K bi,j 2)!",4.1. Insertion Sort,[0],[0]
"bi,j !",4.1. Insertion Sort,[0],[0]
if j < i 0,4.1. Insertion Sort,[0],[0]
"otherwise ,
where bi,j = i j 1.",4.1. Insertion Sort,[0],[0]
"Furthermore, for any 2 SK , we have D = B D idB | , where B is the permutation matrix that corresponds to .
",4.1. Insertion Sort,[0],[0]
Proof.,4.1. Insertion Sort,[0],[0]
"The first case is easy to verify, since insertion sort with an initial ordering ⇡ compares two objects only in case they are concordant (in the same order) in
id and ⇡.",4.1. Insertion Sort,[0],[0]
"The number of such orderings is
K! 2 .
",4.1. Insertion Sort,[0],[0]
"The second case is more involved, since one needs to calculate all initial orders ⇡ 2 SK in which a pair of objects, say oi and oj , are discordant and compared to each other in the course of the sorting procedure.",4.1. Insertion Sort,[0],[0]
"Assume that insertion sort is run with ⇡ as initial order, and the output is id .",4.1. Insertion Sort,[0],[0]
It is easy to see that object oi,4.1. Insertion Sort,[0],[0]
"and oj are not compared if there is a third object ok, which is between oj and oi with respect to
id , and also between oj and oi in ⇡; Figure 1 illustrates such a configuration of objects.",4.1. Insertion Sort,[0],[0]
"Therefore, the number of orderings for which oi",4.1. Insertion Sort,[0],[0]
"and oj are compared is equal to
K bi,j+2 (K bi,j 2)!, because oi and oj and the
items between them have to be ordered such that oi is the first, oj is the second, and all items between oj and oi with respect to
id preceed them in ⇡.",4.1. Insertion Sort,[0],[0]
"In addition, the items between oi and oj can be permuted arbitrarily in the initial order, which results in the term bi,j !.
",4.1. Insertion Sort,[0],[0]
The last claim can be verified based on the fact that the argument above holds for an arbitrary permutation of objects.,4.1. Insertion Sort,[0],[0]
This concludes the proof.,4.1. Insertion Sort,[0],[0]
The quick sort algorithm is inherently random due to the random choice of the pivot item.,4.2. Quick Sort,[0],[0]
"We make use of a derandomized version by taking as pivot the item in the middle of the initial ordering (i.e., the item on position dK/2e for an ordering with K items).
",4.2. Quick Sort,[0],[0]
"In noisy quick sort, we start by picking a pivot element op from the elements {o1, . . .",4.2. Quick Sort,[0],[0]
", oK} to be ordered.",4.2. Quick Sort,[0],[0]
"We then
proceed with the partition operation, in which we construct two sub-orderings, one collecting the items that lost and the other one the items that won the pairwise comparison with the pivot element.",4.2. Quick Sort,[0],[0]
"The same process is repeated with each of the two sub-orderings (unless a sub-ordering reduces to a single item), eventually producing a complete ordering of the items.",4.2. Quick Sort,[0],[0]
"Again, we note that the output of the noisy sorting model based on quick sort depends on the pairwise probabilities P and the initial ordering ⇡.",4.2. Quick Sort,[0],[0]
This dependence is illustrated in the following example.,4.2. Quick Sort,[0],[0]
Example 2.,4.2. Quick Sort,[0],[0]
"Consider the quick sort algorithm with two different initial orderings ⇡ = (o1, o2, o3) and ⇡0 = (o2, o1, o3).",4.2. Quick Sort,[0],[0]
Let the pairwise probabilities be given as in Example 1.,4.2. Quick Sort,[0],[0]
"It is easy to see that the probability of observing = (o1, o2, o3) starting from ⇡ is proportional to p1,2p2,3 = 0.125.",4.2. Quick Sort,[0],[0]
"When starting with ⇡0, this probability is proportional to p1,2p1,3p2,3 = 0.0625.
",4.2. Quick Sort,[0],[0]
The following lemma gives a recursive expression of D for the case of quick sort as a sorting algorithm.,4.2. Quick Sort,[0],[0]
Lemma 2.,4.2. Quick Sort,[0],[0]
"Assume that id = (o1, . . .",4.2. Quick Sort,[0],[0]
", oK).",4.2. Quick Sort,[0],[0]
"Then, for quick sort, the matrix D id is given by
d idij = (K 1)!
2 4 iX
k=1
Q(k,K, i, j) + KX
k=j
Q(1, k, i, j)
3 5 ,
where
Q(`, u, i, j) =
8 >>",4.2. Quick Sort,[0],[0]
<,4.2. Quick Sort,[0],[0]
>,4.2. Quick Sort,[0],[0]
>,4.2. Quick Sort,[0],[0]
":
0",4.2. Quick Sort,[0],[0]
"if i < p = d i+j2 e < j 2 if p = i or p = j
Q(1, p 1, i, j) if j < p Q(p+ 1, u, i, j) if i > p
Furthermore, for any 2 SK , we have D = B D idB |
, where B is the permutation matrix that corresponds to .
",4.2. Quick Sort,[0],[0]
Proof.,4.2. Quick Sort,[0],[0]
"The first case of the recursion Q(`, u, i, j) follows from the fact that neither oi nor oj is chosen as pivot, in which case they will not be compared any more.",4.2. Quick Sort,[0],[0]
"In the second case, either oi or oj is chosen as pivot, in which case they will be compared.",4.2. Quick Sort,[0],[0]
"Otherwise, the recursion corresponds to the quick sort recursion.",4.2. Quick Sort,[0],[0]
"In this section, we address the problem of parameter estimation, i.e., the question of how to fit our models to a given sample D = { 1, . . .",5. Parameter Estimation,[0],[0]
", n} ⇢ SK using the principle of maximum likelihood (ML) estimation.",5. Parameter Estimation,[0],[0]
"Given a set of observations { 1, . . .",5.1. The CNS Model,[0],[0]
", n}, the ML estimation consists of solving the following constrained optimiza-
tion problem:
max
P⌧
nX
`=1
KX
i=1
X j 6=i d `,⌧i,j log p ⌧ i,j n logC(P⌧ ) (13)
s. t. p⌧i,j =
⇢ p if ⌧(i) <",5.1. The CNS Model,[0],[0]
"⌧(j)
1 p if ⌧(i) >",5.1. The CNS Model,[0],[0]
"⌧(j) 8i, j 2",5.1. The CNS Model,[0],[0]
"[K], i 6=",5.1. The CNS Model,[0],[0]
"j
Recall that P⌧ is equivalently represented by the reference order ⌧ and the probability p, i.e., the maximization in the above problem is over these two parameters.
",5.1. The CNS Model,[0],[0]
"We tackle the problem with simple hill-climbing search for ⌧ in the discrete space SK , initialized with the Borda ranking (i.e., sorting items according to their average rank in the data).",5.1. The CNS Model,[0],[0]
The neighborhood of an ordering is defined as the set of all orderings that can be obtained by a swap of two adjacent items.,5.1. The CNS Model,[0],[0]
"For a fixed ⌧ , the optimization problem (13) reduces to a simple one-dimensional problem:
max
p
nX
`=1
2 4 X
⌧(i)<⌧(j)
d",5.1. The CNS Model,[0],[0]
"`,⌧i,j log p+ X
⌧(i)>⌧(j)
d",5.1. The CNS Model,[0],[0]
"`,⌧i,j log(1 p)
3 5
n logC(P⌧ ) s. t. p 2 [0.5, 1]
(14)
",5.1. The CNS Model,[0],[0]
"This problem is convex (the distribution belongs to the exponential family) and can be solved numerically, for example by means of the golden section method.
",5.1. The CNS Model,[0],[0]
"In each iteration of the algorithm, the best candidate solution (⌧, p) in the neighborhood of the current best solution is adopted, and the search stops if no improvement is possible anymore.",5.1. The CNS Model,[0],[0]
"The GCNS model (11) is parametrized by P. Here, the maximum likelihood (ML) principle cannot be applied directly, because the normalizing factor C(P) in (12) cannot be written in a closed form in terms of the model parameters.",5.2. The GCNS Model,[0],[0]
"Therefore, we opt for using the generalized iterative scaling (GIS) procedure (Darroch & Ratcliff, 1972), an iterative method for estimating the probabilities in a log-linear model.",5.2. The GCNS Model,[0],[0]
"Given a set of observations { 1, . . .",5.2. The GCNS Model,[0],[0]
", n}, ML estimation amounts to solving the following constrained optimization problem:
max
P
nX
`=1
KX
i=1
X j 6=i d",5.2. The GCNS Model,[0],[0]
"`i,j log pi,j n logC(P)
s. t. pi,j + pj,i = 1, 8i, j 2",5.2. The GCNS Model,[0],[0]
"[K], i 6= j .
(15)
Let #j denote the jth ranking according to some fixed ordering over SK (e.g. Lehmer code).",5.2. The GCNS Model,[0],[0]
"With fj = #{i 2 [n] : i = #j}, the empirical frequencies corresponding
to the probabilities of all possible permutations, the GIS procedure seeks to find a parameter estimate P0 for which
K!X
`=1
p0` d #` i,j =
K!X
`=1
bp` d #` i,j (16)
for all i 6= j, where p0` = PA( #` |P0).
",5.2. The GCNS Model,[0],[0]
"Observe that the GIS procedure can be adapted to produce the parameters of the log-linear model instead of the probabilities pi,j (Malouf, 2002).",5.2. The GCNS Model,[0],[0]
"In addition, we note that GIS requires the computation of a vector of length K!, a very costly operation that will be tackled based on a Monte Carlobased approximation technique.",5.2. The GCNS Model,[0],[0]
"Further, based on Lemma 1 and 2, it is easy to see that the sum of exponents is constant for every ordering in case of both insertion and quick sort, that is PK i=1",5.2. The GCNS Model,[0],[0]
"P i 6=j d i,j = BK for all 2 SK .",5.2. The GCNS Model,[0],[0]
"According to (Darroch & Ratcliff, 1972), P0 in (16) is the (unconstrained)",5.2. The GCNS Model,[0],[0]
"ML estimate for P. In our case, however, the constraints pi,j + pj,i = 1 in (15) need to be taken into account.",5.2. The GCNS Model,[0],[0]
"Therefore, we accompany each update step in the GIS procedure with a projection step, which ensures that the estimated parameters satisfy the constraints.",5.2. The GCNS Model,[0],[0]
"One update step of the iterative procedure for the parameter estimation thus can be written as
p(n+1)i,",5.2. The GCNS Model,[0],[0]
"j = ⇧ ⇣ p(n)i,j + (n) ⌘ ,
where
(n) = log
PK! `=1 bpld #` i,j
PK! `=1 p (n)",5.2. The GCNS Model,[0],[0]
"l d #` i,j
!",5.2. The GCNS Model,[0],[0]
"1 BK
,
and ⇧(x) denotes the least-squares projection of x = (xi,j , xj,i), given by
argmin y2R2+ ||x y||2 s. t. yi,j + yj,i = 1 ,
(17)
which can be determined analytically.",5.2. The GCNS Model,[0],[0]
"The model (11) can be sampled by using MCMC based on the fact that one can compute the acceptance ratio as
log PA( |P) PA( 0|P) =
KX
i=1
X j 6=i (d i,j d 0",5.3. Sampling,[0],[0]
"i,j) log pi,j .
",5.3. Sampling,[0],[0]
This allows us to make use of the Metropolis-Hastings (MH) algorithm.,5.3. Sampling,[0],[0]
"We use Mallows (Mallows, 1957) as proposal distribution.",5.3. Sampling,[0],[0]
The pseudo-code of the sampling is given in Algorithm 1.,5.3. Sampling,[0],[0]
"The reference ranking of the Mallows model P(· | , ), denoted by , is always set to the current ranking i 1 (see line 5).",5.3. Sampling,[0],[0]
"In this case, it is easy to verify that the stationary distribution of the Markov chain is indeed
PA( |P), because the Mallows model is symmetric in the sense that P( | , 0) = P( 0 | , ), and assigns positive probability to every ranking when > 0.",5.3. Sampling,[0],[0]
"Therefore, the detailed balance condition is satisfied, and the ergodicity of the chain is also ensured.
",5.3. Sampling,[0],[0]
"Algorithm 1 Metropolis-Hastings with Mallows proposal 1: procedure MH(T, ) 2: Select initial ordering 0 3: D = ; 4: for i = 1!",5.3. Sampling,[0],[0]
"T do 5: i ⇠ P(· | , i 1) .",5.3. Sampling,[0],[0]
Proposal from Mallows 6: qi PK i=1,5.3. Sampling,[0],[0]
"PK j 6=i(d i i,j d",5.3. Sampling,[0],[0]
i 1,5.3. Sampling,[0],[0]
"i,j ) log pi,j
7: Accept i with probability min (1, exp(qi)) 8: D = D",5.3. Sampling,[0],[0]
[ { i} 9: return D,5.3. Sampling,[0],[0]
"To investigate the performance of our new model and the effectiveness of parameter estimation, we conducted experiments on 213 real-world data sets from the PrefLib repository (http://www.preflib.org).",6. Experiments,[0],[0]
"These data sets originate from different domains, ranging from actual elections over movie rankings to competitor rankings from various sporting competitions.",6. Experiments,[0],[0]
"The number of items varies between 3 and 10 (details are summarized in the supplementary material).
",6. Experiments,[0],[0]
"All models are fit using maximum likelihood estimation, and Kullback-Leibler (KL) divergence between an empirical distribution and its estimation is used as a measure of the goodness of fit.",6. Experiments,[0],[0]
"In a first setting, we fit the models to the entire data, while in a second setting, we only fit to half of the data and determine divergence on the other half (averaging over 20 random splits).
",6. Experiments,[0],[0]
"In a first experiment, we compare ISR with our new variant CNS, with both insertion and quick sort as underlying sorting algorithms, using MM as an additional baseline.",6. Experiments,[0],[0]
"The ISR, CNS, and MM models are comparable in terms of their parametrization.",6. Experiments,[0],[0]
A summary of the results in terms of win/tie/loss statistics is given in Table 1 (while the complete results can be found in the supplementary material).,6. Experiments,[0],[0]
"As can be seen, CNS shows a very strong performance, especially with insertion sort as a sorting algorithm.
",6. Experiments,[0],[0]
"In a second experiment, we compare CNS with its generalization GCNS, again with insertion and quick sort as underlying sorting algorithms in both models.",6. Experiments,[0],[0]
The results in Table 1 clearly show that GCNS leads to better approximations.,6. Experiments,[0],[0]
"This is hardly surprising, given that GCNS has more parameters and therefore allows for fitting distributions in a more flexible way.",6. Experiments,[0],[0]
"Again, an instantiation with insertion sort seems to be preferable to the use of quick sort.",6. Experiments,[0],[0]
"Adopting the idea of a data-generating process in the form of a noisy sorting procedure, we proposed a variant of a parametrized probability distribution on rankings as recently proposed by Biernacki and Jacques (Biernacki & Jacques, 2013), as well as a generalization that is more flexible and makes less stringent coherence assumptions.",7. Conclusion and Future Work,[0],[0]
"Our models have an intuitive interpretation, exhibit convenient mathematical properties, and seem to fit empirical data very well.",7. Conclusion and Future Work,[0],[0]
"For two sorting algorithms, insertion sort and quick sort, we developed parameter estimation techniques based on a closed-form expression of the likelihood function for the former, and a recursive characterization of it for the latter.",7. Conclusion and Future Work,[0],[0]
"Experimentally, insertion sort leads to better performance.
",7. Conclusion and Future Work,[0],[0]
"In future work, we plan to consider other sorting algorithms, such as merge sort and heap sort.",7. Conclusion and Future Work,[0],[0]
"Another direction worth to investigate is the analysis of algebraic properties of our models using tools from computational algebraic geometry (Geiger et al., 2006); such properties may simplify the handling of the model and help to further improve efficiency of parameter estimation.",7. Conclusion and Future Work,[0],[0]
"Last but not least, we are also interested in using the model for other machine learning problems, in which distributions on rankings are needed, such as learning to rank (Ailon et al., 2005; Ailon, 2008; Cao et al., 2007) and multi-armed bandits (Busa-Fekete & H¨ullermeier, 2014; Sz¨or´enyi et al., 2015).",7. Conclusion and Future Work,[0],[0]
The authors gratefully acknowledge financial support by the Germany Research Foundation (DFG).,Acknowledgements,[0],[0]
"We propose a new statistical model for ranking data, i.e., a new family of probability distributions on permutations.",abstractText,[0],[0]
"Our model is inspired by the idea of a data-generating process in the form of a noisy sorting procedure, in which deterministic comparisons between pairs of items are replaced by Bernoulli trials.",abstractText,[0],[0]
"The probability of producing a certain ranking as a result then essentially depends on the Bernoulli parameters, which can be interpreted as pairwise preferences.",abstractText,[0],[0]
"We show that our model can be written in closed form if insertion sort is used as sorting algorithm and can be characterized recursively if quick sort is used, and propose a maximum likelihood approach for parameter estimation.",abstractText,[0],[0]
"We also introduce a generalization of the model, in which the constraints on pairwise preferences are relaxed, and for which maximum likelihood estimation can be carried out based on a variation of the generalized iterative scaling algorithm.",abstractText,[0],[0]
"Experimentally, we show that the models perform very well in terms of goodness of fit, compared to existing models for ranking data.",abstractText,[0],[0]
Ranking Distributions based on Noisy Sorting,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 565–569 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
565",text,[0],[0]
"With the introduction of large scale machine comprehension datasets, machine comprehension models that are highly accurate and efficient in answering questions given raw texts have been proposed recently (Seo et al., 2016; Xiong et al., 2016; Wang et al., 2017c).",1 Introduction,[0],[0]
"While conventional machine comprehension models were given a paragraph that always contains an answer to a question, some researchers have extended the models to an open-domain setting where relevant documents have to be searched from an extremely large knowledge source such as Wikipedia (Chen et al., 2017; Wang et al., 2017a).",1 Introduction,[0],[0]
"However, most of the open-domain QA pipelines depend on traditional information retrieval systems
∗Corresponding author
which use TF-IDF rankings (Chen et al., 2017; Wang et al., 2017b).",1 Introduction,[0],[0]
"Despite the efficiency of the traditional retrieval systems, the documents retrieved and ranked at the top by such systems often do not contain answers to questions.",1 Introduction,[0],[0]
"However, simply increasing the number of top ranked documents to find answers also increases the number of irrelevant documents.",1 Introduction,[0],[0]
"The tradeoff between reading more documents and minimizing noise is frequently observed in previous works that defined the N number of top documents as a hyperparameter to find (Wang et al., 2017a).
",1 Introduction,[0],[0]
"In this paper, we tackle the problem of ranking the paragraphs of retrieved documents for improving the answer recall of the paragraphs while filtering irrelevant paragraphs.",1 Introduction,[0],[0]
"By using our simple but efficient Paragraph Ranker, our QA pipeline considers more documents for a high answer recall, and ranks paragraphs to read only the most relevant ones.",1 Introduction,[0],[0]
The work closest to ours is that of Wang et al. (2017a).,1 Introduction,[0],[0]
"However, whereas their main focus is on re-ranking retrieved sentences to maximize the rewards of correctly answering the questions, our focus is to increase the answer recall of paragraphs with less noise.",1 Introduction,[0],[0]
"Thus, our work is complementary to the work of Wang et al. (2017a).
",1 Introduction,[0],[0]
"Our work is largely inspired by the field of information retrieval called Learning to Rank (Liu et al., 2009; Severyn and Moschitti, 2015).",1 Introduction,[0],[0]
Most learning to rank models consist of two parts: encoding networks and ranking functions.,1 Introduction,[0],[0]
"We use bidirectional long short term memory (Bi-LSTM) as our encoding network, and apply various ranking functions proposed by previous works (Severyn and Moschitti, 2015; Tu et al., 2017).",1 Introduction,[0],[0]
"Also, as the time and space complexities of ranking paragraphs are much larger than those of ranking sentences (Severyn and Moschitti, 2015), we resort to negative sampling (Mikolov et al., 2013) for an efficient training of our Paragraph Ranker.
",1 Introduction,[0],[0]
Our pipeline with Paragraph Ranker improves the exact match scores on the four open-domain QA datasets by 7.8% on average.,1 Introduction,[0],[0]
"Even though we did not further customize Document Reader of DrQA (Chen et al., 2017), the large improvement in the exact match scores shows that future researches would benefit from ranking and reading the more relevant paragraphs.",1 Introduction,[0],[0]
"By a qualitative analysis of ranked paragraphs, we provide additional evidence supporting our findings.",1 Introduction,[0],[0]
Most open-domain QA systems are constructed as pipelines that include a retrieval system and a reader model.,2 Open-Domain QA Pipeline,[0],[0]
We additionally built Paragraph Ranker that assists our QA pipeline for a better paragraph selection.,2 Open-Domain QA Pipeline,[0],[0]
"For the retrieval system and the reader model, we used Document Retriever and Document Reader of Chen et al. (2017).1 The overview of our pipeline is illustrated in Figure 1.",2 Open-Domain QA Pipeline,[0],[0]
"Given N number of documents retrieved from Document Retriever, we assume that each document contains K number of paragraphs on average.",2.1 Paragraph Ranker,[0],[0]
"Instead of feeding all NK number of paragraphs to Document Reader, we select only M number of paragraphs using Paragraph Ranker.",2.1 Paragraph Ranker,[0],[0]
"Utilizing Paragraph Ranker, we safely increase N for a higher answer recall, and reduce the number of paragraphs to read by selecting only top ranked paragraphs.
",2.1 Paragraph Ranker,[0],[0]
"Given the retrieved paragraphs Pi where i ranges from 1 to NK, and a question Q, we en-
1https://github.com/facebookresearch/DrQA
code each paragraph and the question using two separate RNNs such as Bi-LSTM.",2.1 Paragraph Ranker,[0],[0]
"Representations of each paragraph and the question are calculated as follows:
pih = BiLSTMp(E(Pi))",2.1 Paragraph Ranker,[0],[0]
"qh = BiLSTMq(E(Q))
where BiLSTM(·) returns the concatenation of the last hidden state of forward LSTM and the first hidden state of backward LSTM.",2.1 Paragraph Ranker,[0],[0]
E(·) converts tokens in a paragraph or a question into pretrained word embeddings.,2.1 Paragraph Ranker,[0],[0]
"We use GloVe (Pennington et al., 2014) for the pretrained word embeddings.
",2.1 Paragraph Ranker,[0],[0]
"Once each paragraph and the question are represented as pih and qh, we calculate the probability of each paragraph to contain an answer of the question as follows:
p(Pi|Q)",2.1 Paragraph Ranker,[0],[0]
"= 1
1 + e−s(p",2.1 Paragraph Ranker,[0],[0]
"i h,qh)
where we have used similarity function s(·, ·) to measure the probability of containing answer to the question Q in the paragraph Pi.",2.1 Paragraph Ranker,[0],[0]
"While Wang and Jiang (2015) adopted high capacity models such as Match-LSTM for measuring the similarity between paragraphs and questions, we use much simpler scoring functions to calculate the similarity more efficiently.",2.1 Paragraph Ranker,[0],[0]
"We tested three different scoring functions: 1) the dot product of pih and qh, 2) the bilinear form pih T Wqh, and 3) a multilayer perceptron (MLP) (Severyn and Moschitti, 2015).",2.1 Paragraph Ranker,[0],[0]
"While utilizing MLP takes much more time than the other two functions, recall of MLP was similar to that of the dot product.",2.1 Paragraph Ranker,[0],[0]
"Also, as recall of the bilinear form was worse than that of the dot product, we use the dot product as our scoring function.
",2.1 Paragraph Ranker,[0],[0]
"Due to the large size of NK, it is difficult to train Paragraph Ranker on all the retrieved paragraphs.2 To efficiently train our model, we use a negative sampling of irrelevant paragraphs (Mikolov et al., 2013).",2.1 Paragraph Ranker,[0],[0]
"Hence, the loss function of our model is as follows:
J(Θ)",2.1 Paragraph Ranker,[0],[0]
=− log p(Pi|Q),2.1 Paragraph Ranker,[0],[0]
− Ek∼pn [log(1− p(Pk|Q)),2.1 Paragraph Ranker,[0],[0]
"]
where k indicates indexes of negative samples that do not contain the answer, and Θ denotes trainable parameters of Paragraph Ranker.",2.1 Paragraph Ranker,[0],[0]
The distribution of negative samples are defined as pn.,2.1 Paragraph Ranker,[0],[0]
"We use the distribution of all the Stanford Question Answering Dataset (SQuAD) (Rajpurkar et al., 2016) training paragraphs as pn .
",2.1 Paragraph Ranker,[0],[0]
"Based on the rank of each paragraph from Paragraph Ranker and the rank of source document from Document Retriever, we collect top M paragraphs to read.",2.1 Paragraph Ranker,[0],[0]
We combine the ranks by the multiplication of probabilities p(Pi|Q) and p̃(Di|Q) to find most relevant paragraphs where p̃(Di|Q) denotes TF-IDF score of a source document Di.,2.1 Paragraph Ranker,[0],[0]
We feed M paragraphs to Document Reader to extract M answers.,2.2 Answer Aggregation,[0],[0]
"While Paragraph Ranker increases the probability of including answers in the topM ranked paragraphs, aggregation step should determine the most probable answer among theM extracted answers.",2.2 Answer Aggregation,[0],[0]
Chen et al. (2017) and Clark et al. (2017) used the unnormalized answer probability from the reader.,2.2 Answer Aggregation,[0],[0]
"However, as the unnormalized answer probability is very sensitive to noisy answers, Wang et al. (2017b) proposed a more sophisticated aggregation methods such as coveragebased and strength-based re-rankings.
",2.2 Answer Aggregation,[0],[0]
"In our QA pipeline, we incorporate the coverage-based method by Wang et al. (2017b) with paragraph scores from Paragraph Ranker.",2.2 Answer Aggregation,[0],[0]
"Although strength-based answer re-ranking showed good performances on some datasets, it is too complex to efficiently re-rank M answers.",2.2 Answer Aggregation,[0],[0]
"Given the M candidate answers [A1, ..., AM ] from each paragraph, we aggregate answers as follows:
Â = arg max Ai
p(Ai|Q)
= arg max Ai
p̃(Ai|Pi, Q)αp(Pi|Q)β p̃(Di|Q)γ
(1)
2NK ≈ 350 when N = 5 in SQuAD",2.2 Answer Aggregation,[0],[0]
"QA pairs.
where p̃(Ai|Pi, Q) denotes the unnormalized answer probability from a reader given the paragraph Pi and the question Q. Importance of each score is determined by the hyperparamters α, β, and γ.",2.2 Answer Aggregation,[0],[0]
"Also, we add up all the probabilities of the duplicate candidate answers for the coverage-based aggregation.",2.2 Answer Aggregation,[0],[0]
We evaluate our pipeline with Paragraph Ranker on the four open-domain QA datasets.,3.1 Datasets,[0],[0]
"Wang et al. (2017a) termed SQuAD without relevant paragraphs for the open-domain QA as SQuADOPEN, and we use the same term to denote the opendomain setting SQuAD.",3.1 Datasets,[0],[0]
"CuratedTrec (Baudiš and Šedivỳ, 2015) was created for TREC opendomain QA tasks.",3.1 Datasets,[0],[0]
"WebQuestions (Berant et al., 2013) contains questions from Google Suggest API.",3.1 Datasets,[0],[0]
"WikiMovies (Miller et al., 2016) contains questions regarding movies collected from OMDb and the MovieLens database.",3.1 Datasets,[0],[0]
We pretrain Document Reader and Paragraph Ranker on the SQuAD training set.3,3.1 Datasets,[0],[0]
Paragraph Ranker uses 3-layer Bi-LSTM networks with 128 hidden units.,3.2 Implementation Details,[0],[0]
"On SQuADOPEN and CuratedTrec, we set α, β, and γ of Paragraph Ranker to 1.",3.2 Implementation Details,[0],[0]
"Due to the different characteristics of questions in WebQuestion and WikiMovies, we find α, β, and γ based on the validation QA pairs of the two datasets.",3.2 Implementation Details,[0],[0]
We use N = 20 for the number of documents to retrieve and M = 200 for the number of paragraphs to read for all the four datasets.,3.2 Implementation Details,[0],[0]
"We use Adamax (Kingma and Ba, 2014) as the optimization algorithm.",3.2 Implementation Details,[0],[0]
Dropout is applied to LSTMs and embeddings with p = 0.4.,3.2 Implementation Details,[0],[0]
"In our experiments, Paragraph Ranker ranks only paragraphs, and answers are determined by unnormalized scores of the answers.",3.3 Results,[0],[0]
Paragraph Ranker + Answer Agg.,3.3 Results,[0],[0]
"sums up the unnormalized probabilities of duplicate answers (i.e., β = γ = 0).",3.3 Results,[0],[0]
Paragraph Ranker + Full Agg.,3.3 Results,[0],[0]
"aggregates answers using Equation 1 with the coveragebased aggregation.
",3.3 Results,[0],[0]
"3On SQuAD development set, pretrained Document Reader achieves 69.1% EM, and pretrained Paragraph Ranker achieves 96.7% recall on the top 5 paragraph .
",3.3 Results,[0],[0]
"In Table 1, we summarize the performance and recall of each model on open-domain QA datasets.",3.3 Results,[0],[0]
We define recall as the probability of read paragraphs containing answers.,3.3 Results,[0],[0]
"While Reinforced Reader-Ranker (R3) (Wang et al., 2017a) performs better than DrQA on the three datasets (SQuADOPEN, CuratedTrec, WikiMovies), Paragraph Ranker + Full Agg.",3.3 Results,[0],[0]
outperforms both DrQA and R3.,3.3 Results,[0],[0]
"Paragraph Ranker + Full Agg. achieved 3.78%, 24.65%, 2.05%, 0.77% relative improvements in terms of EM on SQuADOPEN, CuratedTrec, WebQuestion, and WikiMovies, respectively (7.8% on average).",3.3 Results,[0],[0]
It is noticeable that our pipeline with Paragraph Ranker + Full Agg. greatly outperforms DrQA + Multitask in SQuADOPEN and CuratedTrec.,3.3 Results,[0],[0]
"In Table 2, we show 3 random paragraphs of the top document returned by Document Retriever, and the top 3 paragraphs ranked by Paragraph Ranker from the top 40 documents.",3.4 Analysis,[0],[0]
"As Document Retriever largely depends on matching of query tokens with document tokens, the top ranked document is usually the document with most tokens
matching the query.",3.4 Analysis,[0],[0]
"However, Question 1 includes the polysemy of the word “play” which makes it more difficult for Document Retriever to perform effectively.",3.4 Analysis,[0],[0]
Our Paragraph Ranker well understands that the question is about a sports player not a musician.,3.4 Analysis,[0],[0]
"The top 1-3 paragraphs for the second question came from the 30th, 7th, and 6th documents, respectively, ranked by Document Retriever.",3.4 Analysis,[0],[0]
This shows that increasing number of documents to rank helps Paragraph Ranker find more relevant paragraphs.,3.4 Analysis,[0],[0]
"In this paper, we present an open-domain question answering pipeline and proposed Paragraph Ranker.",4 Conclusion,[0],[0]
"By using Paragraph Ranker, the QA pipeline benefits from increased answer recall from paragraphs to read, and filters irrelevant documents or paragraphs.",4 Conclusion,[0],[0]
"With our simple Paragraph Ranker, we achieve state-of-the-art performances on the four open-domain QA datasets with large margins.",4 Conclusion,[0],[0]
"As future works, we plan to further improve Paragraph Ranker based on the researches on learning to rank.",4 Conclusion,[0],[0]
"This research was supported by National Research Foundation of Korea (NRF-2017R1A2A1A17069645, NRF2017M3C4A7065887), and the Korean MSIT (Ministry of Science and ICT) under the National Program for Excellence in SW (2015-0-00936) supervised by the IITP (Institute for Information & communications Technology Promotion)",Acknowledgement,[0],[0]
"Recently, open-domain question answering (QA) has been combined with machine comprehension models to find answers in a large knowledge source.",abstractText,[0],[0]
"As open-domain QA requires retrieving relevant documents from text corpora to answer questions, its performance largely depends on the performance of document retrievers.",abstractText,[0],[0]
"However, since traditional information retrieval systems are not effective in obtaining documents with a high probability of containing answers, they lower the performance of QA systems.",abstractText,[0],[0]
"Simply extracting more documents increases the number of irrelevant documents, which also degrades the performance of QA systems.",abstractText,[0],[0]
"In this paper, we introduce Paragraph Ranker which ranks paragraphs of retrieved documents for a higher answer recall with less noise.",abstractText,[0],[0]
We show that ranking paragraphs and aggregating answers using Paragraph Ranker improves performance of open-domain QA pipeline on the four opendomain QA datasets by 7.8% on average.,abstractText,[0],[0]
Ranking Paragraphs for Improving Answer Recall in Open-Domain Question Answering,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 875–880 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
875",text,[0],[0]
"When disaster strikes, news and social media are invaluable sources of information, allowing humanitarian organizations to rapidly mitigate crisis situations and save lives (Vieweg et al., 2010; Neubig et al., 2011; Starbird et al., 2012).",1 Introduction,[0],[0]
"However, language barriers looms large over these efforts, especially when disasters occur in parts of the world that use less common languages.",1 Introduction,[0],[0]
"In these cases, machine translation (MT) technology can be a valuable tool, with one widely-heralded success story being the deployment of Haitian Creoleto-English translation systems during the earthquakes in Haiti (Lewis, 2010; Munro, 2010).
",1 Introduction,[0],[0]
"However, data-driven MT systems, particularly neural machine translation (NMT; Kalchbrenner
1Code to reproduce experiments at https://github. com/neubig/rapid-adaptation
and Blunsom (2013); Bahdanau et al. (2015)), require large amounts of training data, and creating high-quality systems in low-resource languages (LRLs) is a difficult challenge where research efforts have just begun (Gu et al., 2018).",1 Introduction,[0],[0]
"Another hurdle, which to our knowledge has not been covered in previous research, is the time it takes to create such a system.",1 Introduction,[0],[0]
"In a crisis situation, time is of the essence, and systems that require days or weeks of training will not be desirable or even feasible.
",1 Introduction,[0],[0]
"In this paper we focus on the question: how can we create MT systems for new language pairs as accurately as possible, and as quickly as possible?",1 Introduction,[0],[0]
"To examine this question we propose NMT methods at the intersection of cross-lingual transfer learning (Zoph et al., 2016) and multilingual training (Johnson et al., 2016), two paradigms that, to our knowledge, have not been used together in previous work.",1 Introduction,[0],[0]
"Our methods, laid out in §2 follow the process of training a seed model on a large number of languages, then fine-tuning the model to improve its performance on the language of interest.",1 Introduction,[0],[0]
"We propose a novel method of similar-language regularization (SLR) where training data from a second similar languages is used to help prevent over-fitting to the small LRL dataset.
",1 Introduction,[0],[0]
"In the experiments in §3, we attempt to answer two questions: (1) Which method of creating multilingual systems and adapting them to an LRL is the most effective way to increase accuracy?",1 Introduction,[0],[0]
(2) How can we create the strongest system possible with a bare minimum of training time?,1 Introduction,[0],[0]
The results are sometimes surprising – we first find that a single monolithic model trained on 57 languages can achieve BLEU scores as high as 15.5 with no training data in the new source language whatsoever.,1 Introduction,[0],[0]
"In addition, the proposed method starting with a universal model then fine-tuning with the SLR proves most effective, achieving gains of 1.7
BLEU points averaged over several language pairs compared to previous methods adapting to only the LRL.",1 Introduction,[0],[0]
"In this paper, we consider the setting where we have a source LRL of interest, and we want to translate into English.2 All of our adaptation methods are based on first training on larger data including other languages, then fine-tuning the model to be specifically tailored to the LRL.",2 Training Paradigms,[0],[0]
"We first discuss a few multilingual training paradigms from previous literature (§2.1), then discuss our proposed adaptation methods (§2.2).",2 Training Paradigms,[0],[0]
"We use three varieties of multilingual training: Single-source modeling (“Sing.”) is the first method, using only parallel data between the LRL of interest and English.",2.1 Multilingual Modeling Methods,[0],[0]
"This method is straightforward and the resulting model will be most highly tailored to the final test language pair, but the method also has the obvious disadvantage that training data is very sparse.",2.1 Multilingual Modeling Methods,[0],[0]
"Bi-source modeling (“Bi”) trains an MT system with two source languages: one LRL that we would like to translate from, and a second highly related high-resource language (HRL): the helper source language.3",2.1 Multilingual Modeling Methods,[0],[0]
"This method is inspired by Johnson et al. (2016), who examine multilingual translation models to/from English and two highly related languages such as Spanish/Portuguese or Japanese/Korean.",2.1 Multilingual Modeling Methods,[0],[0]
"The advantage of this method is that it allows the LRL to learn from a highly similar helper, potentially increasing accuracy.",2.1 Multilingual Modeling Methods,[0],[0]
"All-source modeling (“All”) trains not only on a couple source languages, but instead creates a universal model on all of the languages that we have at our disposal.",2.1 Multilingual Modeling Methods,[0],[0]
"In our experiments (§3.1) this entails training systems on 58 source languages, to our knowledge the largest reported in NMT experiments.4",2.1 Multilingual Modeling Methods,[0],[0]
"This paradigm allows us to train a single
2Translation into LRLs, is a challenging and interesting problem in it’s own right, but beyond the scope of the paper.
",2.1 Multilingual Modeling Methods,[0],[0]
3“Related” could mean different things: typologically related or having high lexical overlap.,2.1 Multilingual Modeling Methods,[0],[0]
"In our experiments our LRLs are all selected to have an helper that is highly similar in both aspects, but choosing an appropriate helper when this is not the case is an interesting problem for future work.
",2.1 Multilingual Modeling Methods,[0],[0]
"4In contrast to Gu et al. (2018), who train on 10 languages.",2.1 Multilingual Modeling Methods,[0],[0]
"Malaviya et al. (2017); Tiedemann (2018) train NMT on over 1,000 languages, but only as a feature extractor for downstream tasks; MT accuracy itself is not evaluated.
model that has wide coverage of vocabulary and syntax of a large number of languages, but also has the drawback in that a single model must be able to express information about all the languages in the training set within its limited parameter budget.",2.1 Multilingual Modeling Methods,[0],[0]
"Thus, it is reasonable to expect that this model may achieve worse accuracy than a model created specifically to handle a particular source language.
",2.1 Multilingual Modeling Methods,[0],[0]
"In the following, we will consider adaptation methods that focus on tailoring a more general model (i.e. bi-source or universal) to a more specific model (i.e. single-source or bi-source).",2.1 Multilingual Modeling Methods,[0],[0]
"As noted in the introduction, there are two major requirements: the accuracy of the system is important and the training time required from when we learn of a need for translation to when we can first start producing adequate results.",2.2 Adaptation to New Languages,[0],[0]
"Throughout the discussion, we will compare various adaptation paradigms with respect to these two aspects.",2.2 Adaptation to New Languages,[0],[0]
"Our first adaptation method, inspired by Zoph et al. (2016) is based on fine-tuning to the source language of interest.",2.2.1 Adaptation by Fine-tuning,[0],[0]
"Within our experiments, we will test this setting, but also make two distinctions between the types of adaptation: Seed Model Variety: Zoph et al. (2016) performed experiments taking a bilingual system trained on a different language (e.g. French) and adapting it to a new LRL (e.g. Uzbek).",2.2.1 Adaptation by Fine-tuning,[0],[0]
"We can also take universal model and adapt it to the new language, a setting that we examine (to our knowledge, for the first time) in this work.",2.2.1 Adaptation by Fine-tuning,[0],[0]
Warm vs. Cold Start:,2.2.1 Adaptation by Fine-tuning,[0],[0]
"Another contrast is whether we have training data for the LRL of interest while training the original system, or whether we only receive training data after the original model has already been trained.",2.2.1 Adaptation by Fine-tuning,[0],[0]
"We call the former warm start, and the latter cold start.",2.2.1 Adaptation by Fine-tuning,[0],[0]
"Intuitively, we expect warm-start training to perform better, as having access to the LRL of interest during the training of the original model will ensure that it can handle the LRL to some extent.",2.2.1 Adaptation by Fine-tuning,[0],[0]
"However, the cold-start scenario is also of interest: we may want to spend large amounts of time training a strong model, then quickly adapt to a new language that we have never seen before in our training data as data becomes available.",2.2.1 Adaptation by Fine-tuning,[0],[0]
"For the cold-start models, we start with a model that is only trained on the HRL similar to the LRL (Bi−), or a model trained
on all languages but the LRL (All−).",2.2.1 Adaptation by Fine-tuning,[0],[0]
One problem with adapting to a small amount of data in the target language is that it will be very easy for the model to over-fit to the small training set.,2.2.2 Similar-Language Regularization,[0],[0]
"To alleviate this problem, we propose a method of similar language regularization: while training to adapt to the language of interest, we also add some data from another similar HRL that has sufficient resources to help prevent overfitting.",2.2.2 Similar-Language Regularization,[0],[0]
"We do this in two ways: Corpus Concatenation: Simply concatenate the data from the two corpora, so that we have a small amount of data in the LRL, and a large amount of data in the similar HRL.",2.2.2 Similar-Language Regularization,[0],[0]
"Balanced Sampling: Every time we select a minibatch to do training, we either sample it from the LRL, or from the HRL according to a fixed ratio.",2.2.2 Similar-Language Regularization,[0],[0]
"We try different sampling strategies, including sampling with a 1-to-1 ratio, 1-to-2 ratio, and 1-to-4 ratio for the LRL and HRL respectively.",2.2.2 Similar-Language Regularization,[0],[0]
"We perform experiments on the 58-language-toEnglish TED corpus (Qi et al., 2018), which is ideal for our purposes because it has a wide variety of languages over several language families, some high-resourced and some low-resourced.",3.1 Experimental Setup,[0],[0]
"Like Qi et al. (2018), we experiment with Azerbaijani (aze), Belarusian (bel), and Galician (glg) to English, and also additionally add Slovak (slk), a slightly higher resourced language, for contrast.",3.1 Experimental Setup,[0],[0]
"These languages are all paired with a similar HRL: Turkish (tur), Russian (rus), Portuguese (por), and Czech (ces) respectively.",3.1 Experimental Setup,[0],[0]
"Data sizes are shown in Table 1.
",3.1 Experimental Setup,[0],[0]
"Models are implemented using xnmt (Neubig et al., 2018), commit 8173b1f, and start with the recipe for training on IWSLT TED5.",3.1 Experimental Setup,[0],[0]
"The model consists of an attentional neural machine translation model (Bahdanau et al., 2015), using bi-directional LSTM encoders, 128-dimensional
5Found in examples/stanford-iwslt/
word embeddings, 512-dimensional hidden states, and a standard LSTM-based decoder.
",3.1 Experimental Setup,[0],[0]
"Following standard practice (Sennrich et al., 2016; Denkowski and Neubig, 2017), we break low-frequency words into subwords using the sentencepiece toolkit.6 There are two alternatives for creating subword units: jointly learning subwords over all source language, or separately learning subwords for each source language, then taking the union of all the subword vocabularies as the vocabulary for the multilingual model.",3.1 Experimental Setup,[0],[0]
"Previous work on multilingual training has preferred the former (Nguyen and Chiang, 2017), but in this paper we use the latter for two reasons: (1) because data in the LRL will not affect the subword units from the other languages, in the cold-start scenario we can postpone creation of subword units for the LRL until directly before we start training on the LRL itself, and (2) we need not be concerned with the LRL being “overwhelmed” by the higher-resourced languages when calculating statistics used in the creation of subword units, because all languages get an equal share.7",3.1 Experimental Setup,[0],[0]
"In the experiments, we use a subword vocabulary of 8,000 for each language.
",3.1 Experimental Setup,[0],[0]
"We also compare with two additional baselines: phrase-based MT implemented in Moses,8 and unsupervised NMT implemented in undreamt.9 Moses is trained on the bilingual data only (training multilingually reduced average accuracy), and undreamt is trained on all monolingual data available for the LRL and English.",3.1 Experimental Setup,[0],[0]
"Table 2 shows our main translation results, with warm-start scenarios in the upper half and coldstart scenarios in the lower half.
",3.2 Experimental Results,[0],[0]
Does Multilingual Training Help?,3.2 Experimental Results,[0],[0]
"To answer this question, we can compare the warm-start Sing., Bi, and All settings, and find that the answer is a resounding yes, gains of 7-13 BLEU points are obtained by going from single-source to bi-source or all-source training, corroborating previous work (Gu et al., 2018).",3.2 Experimental Results,[0],[0]
"Bi-source models tend to perform slightly better than all-source models, indicating that given identical parameter
6https://github.com/google/ sentencepiece, using the unigram training setting.
",3.2 Experimental Results,[0],[0]
"7 Preliminary experiments found both comparable: with scores of 20.1 and 19.4 for separate and joint respectively.
8http://statmt.org/moses 9https://github.com/artetxem/undreamt
capacity, training on a highly resourced language is effective.",3.2 Experimental Results,[0],[0]
"Comparing with the phrase-based baseline, as noted by Koehn and Knowles (2017) NMT tends to underperform on low-resource settings when trained only on the data available for these languages.",3.2 Experimental Results,[0],[0]
"However, multilingual training of any variety quickly remedies this issue; all outperform phrase-based handily.
",3.2 Experimental Results,[0],[0]
"More interestingly, examining the cold-start results, we can see that even systems with no data in the target language are able to achieve nontrivial accuracies, up to 15.5 BLEU on glg-eng.",3.2 Experimental Results,[0],[0]
"Interestingly, in the cold-start scenario, the All− model bests the Bi− model, indicating that massively multilingual training is more useful in this setting.",3.2 Experimental Results,[0],[0]
"In contrast, the unsupervised NMT model struggles, achieving a BLEU score of around 0 for all language pairs – this is because unsupervised NMT requires high-quality monolingual embeddings from the same distribution, which can be trained easily in English, but are not available in the low-resource languages we are considering.
",3.2 Experimental Results,[0],[0]
Does Adaptation Help?,3.2 Experimental Results,[0],[0]
"Regarding adaptation, we can first observe that regardless of the original model and method for adaptation, adaptation is helpful, particularly (and unsurprisingly) in the cold-start case.",3.2 Experimental Results,[0],[0]
"When adapting directly to only the target language (“→Sing.”), adapting from the massively multilingual model performs better, indicating that information about all input languages is better than just a single language.",3.2 Experimental Results,[0],[0]
"Next, comparing with our proposed method of adding similar
language regularization (“→Bi”), we can see that this helps significantly over adapting directly to the LRL, particularly in the cold-start case where we can observe gains of up to 1.7 BLEU points.",3.2 Experimental Results,[0],[0]
"Finally, in our data setting, corpus concatenation outperforms balanced sampling in both the coldstart and warm-start scenarios.",3.2 Experimental Results,[0],[0]
How Can We Adapt Most Efficiently?,3.2 Experimental Results,[0],[0]
"Finally, we revisit adapting to new languages efficiently, with Figure 1 showing BLEU vs. hours training for the aze/tur and bel/rus source language pairs (others were similar).",3.2 Experimental Results,[0],[0]
We can see that in all cases the cold-start models (All− →) either outperform or are comparable in final accuracy to the fromscratch single-source and bi-source models.,3.2 Experimental Results,[0],[0]
"In addition, all of the adapted models converge faster than the bi-source from-scratch trained models, indicating that adapting from seed models is a good strategy for rapid construction of MT systems in new languages.",3.2 Experimental Results,[0],[0]
"Comparing the cold-start adaptation strategies, we can see that in general, the higher the density of target language training data, the faster the training converges to a solution, but the worse the final solution is.",3.2 Experimental Results,[0],[0]
This suggests that there is a speed/accuracy tradeoff in the amount of similar language regularization we apply during fine-tuning.,3.2 Experimental Results,[0],[0]
"While adapting MT systems to new languages is a long-standing challenge (Schultz and Black, 2006; Jabaian et al., 2013), multilingual NMT is highly promising in its ability to abstract across
language boundaries (Firat et al., 2016; Ha et al., 2016; Johnson et al., 2016).",4 Related Work,[0],[0]
"Results on multilingual training for low-resource translation (Gu et al., 2018; Qi et al., 2018) further demonstrates this potential, although these works do not consider adaptation to new languages, the main focus of our work.",4 Related Work,[0],[0]
"Notably, we did not examine partial freezing of parameters, another method proven useful for cross-lingual adaptation (Zoph et al., 2016); this is orthogonal to our multi-lingual training approach but the two methods could potentially be combined.",4 Related Work,[0],[0]
"Finally, unsupervised NMT approaches (Artetxe et al., 2017; Lample et al., 2018, 2017) require no parallel data, but rest on strong assumptions about high-quality comparable monolingual data.",4 Related Work,[0],[0]
"As we show, when this assumption breaks down these methods fail to function, while our cold-start methods achieve non-trivial accuracies even with no monolingual data.",4 Related Work,[0],[0]
This paper examined methods to rapidly adapt MT systems to new languages by fine-tuning.,5 Conclusion,[0],[0]
"In both warm-start and cold-start scenarios, the best results were obtained by adapting a pre-trained universal model to the low-resource language while regularizing with similar languages.",5 Conclusion,[0],[0]
"The authors thank Jaime Carbonell, Xinyi Wang, Rebecca Knowles, Arya McCarthy, and anonymous reviewers for their constructive comments on this paper.
",Acknowledgements,[0],[0]
This work is sponsored by Defense Advanced Research Projects Agency Information Innovation Office (I2O).,Acknowledgements,[0],[0]
Program: Low Resource Languages for Emergent Incidents (LORELEI).,Acknowledgements,[0],[0]
Issued by DARPA/I2O under Contract No. HR0011-15C0114.,Acknowledgements,[0],[0]
"The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Government.",Acknowledgements,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on.,Acknowledgements,[0],[0]
"This paper examines the problem of adapting neural machine translation systems to new, low-resourced languages (LRLs) as effectively and rapidly as possible.",abstractText,[0],[0]
"We propose methods based on starting with massively multilingual “seed models”, which can be trained ahead-of-time, and then continuing training on data related to the LRL.",abstractText,[0],[0]
"We contrast a number of strategies, leading to a novel, simple, yet effective method of “similar-language regularization”, where we jointly train on both a LRL of interest and a similar high-resourced language to prevent over-fitting to small LRL data.",abstractText,[0],[0]
"Experiments demonstrate that massively multilingual models, even without any explicit adaptation, are surprisingly effective, achieving BLEU scores of up to 15.5 with no data from the LRL, and that the proposed similarlanguage regularization method improves over other adaptation methods by 1.7 BLEU points average over 4 LRL settings.1",abstractText,[0],[0]
Rapid Adaptation of Neural Machine Translation to New Languages,title,[0],[0]
"1The Fuqua School of Business, Duke University, Durham, NC, USA.. Correspondence to: J. Xu <jiaming.xu868@duke.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).
approximations of the graphon function f .",text,[0],[0]
Many modern systems and datasets can be represented as networks with vertices denoting the objects and edges (possibly weighted or labelled) encoding their interactions.,1. Introduction,[0],[0]
"Examples include online social networks such as Facebook friendship network, biological networks such as protein-protein interaction networks, and recommender systems such as movie rating datasets.",1. Introduction,[0],[0]
"A key task in network analysis is to estimate the underlying network generating mechanism, i.e., how the edges are formed in a network.",1. Introduction,[0],[0]
"It is useful for many important applications such as studying network evolution over time (Pensky, 2016), predicting missing links in networks (Miller et al., 2009; Airoldi et al., 2013; Gao et al., 2016), learning hidden user prefererences in recommender systems (Song et al., 2016), and correcting errors in crowdsourcing systems (Lee & Shah, 2017).",1. Introduction,[0],[0]
"However, in practice we usually observe only a very small fraction of edge connections in these networks, which obscures the underlying network generating mechanism.",1. Introduction,[0],[0]
"For example, around 80% of the molecular interactions in cells of Yeast (Yu et al., 2008) are unknown.",1. Introduction,[0],[0]
"In Netflix movie dataset, about 99% of movie ratings are missing and the observed ratings are noisy.
",1. Introduction,[0],[0]
"In this paper, we are interested in understanding when and how the underlying network generating mechanism can be efficiently inferred from a partial observation of a network.",1. Introduction,[0],[0]
"We assume the network is generated according to the graphon model (Lovász & Szegedy, 2006).",1. Introduction,[0],[0]
"Concretely, given n vertices, the edges are generated independently, connecting each pair of two distinct vertices i and j with a probability
Mij = f(xi, xj), (1)
where xi ∈ X is the latent feature vector of vertex i that captures various characteristics of vertex i; f :",1. Introduction,[0],[0]
X × X →,1. Introduction,[0],[0]
"[0, 1] is a symmetric function called graphon.",1. Introduction,[0],[0]
We assume no self loop and setMii = 0 for 1 ≤,1. Introduction,[0],[0]
i ≤,1. Introduction,[0],[0]
n.,1. Introduction,[0],[0]
We further assume the feature vectors xi’s are drawn i.i.d.,1. Introduction,[0],[0]
"from a measurable space X according to a probability distribution µ.
Graphon model captures a key characteristic of real networks, that is, the edge connections are dependent on latent
features of vertices rather than specific vertex identities.",1. Introduction,[0],[0]
"Graphon model was originally developed as a limit of a sequence of graphs with growing sizes (Lovász, 2012), and has been applied to various network analysis problems ranging from testing graph properties to counting homomorphisms to charactering distances between two graphs (Lovász, 2012; Borgs et al., 2008; 2012) to detecting communities (Bickel & Chen, 2009).",1. Introduction,[0],[0]
Graphon model encompasses many existing network models as special cases.,1. Introduction,[0],[0]
"Setting f to be a constant p, it gives rise to Erdős-Rényi random graphs, where each edge is formed independently with probability p.",1. Introduction,[0],[0]
"In the case where f is a step function or X is a discrete set, the model specializes to the stochastic block model (Holland et al., 1983), where each vertex belongs to a community, and the edge probability between i and j depends only on which communities they are in.",1. Introduction,[0],[0]
"If X is a Euclidean space of dimension d and f(xi, xj) is a function of the Euclidean distance ‖xi−xj‖, then the grahon model reduces to the latent space model (Hoff et al., 2002; Handcock et al., 2007).
",1. Introduction,[0],[0]
"To capture a partial observation of the network, we assume every edge is observed independently with probability ρ ∈",1. Introduction,[0],[0]
"[0, 1], where ρ = ρn may converge to 0 as n → ∞. Given the resulting observed graph, the problem of interest is to estimate the underlying network generating mechanism – the graphon f .",1. Introduction,[0],[0]
"However, without observing xi’s, there is no way to uniquely identify f. To overcome this identifiability issue, we follow the prior work (Gao et al., 2015) and consider estimating f under the expected empirical loss1:
1
n2 E  ∑ i,j∈[n]",1. Introduction,[0],[0]
"( f̂(xi, xj)− f(xi, xj) )2 .",1. Introduction,[0],[0]
"This is equivalent to estimating the edge probability matrix M under the mean squared error (Gao et al., 2015):
MSE(M̂) , 1 n2 E [∥∥∥M̂ −M∥∥∥2 F ] , (2)
",1. Introduction,[0],[0]
"where M̂ij = f̂(xi, xj).",1. Introduction,[0],[0]
"The fundamental estimation limits are phrased in terms of the minimax mean-squared error:
R∗n , inf M̂ sup f∈F sup µ∈P MSE(M̂),
where F denotes a set of admissible graphon functions f , and P denotes the set of all possible probability measures
1 By the definition of the expected empirical loss, we only need to estimate the edge probabilities {f(xi, xj)}.",1. Introduction,[0],[0]
"An alternative way to overcome the identifiablity issue is to consider estimating f up to weak isometry under the expected integral loss (Wolfe & Olhede, 2013).",1. Introduction,[0],[0]
"As shown in (Klopp et al., 2015)[Section 3], the results of estimating f under the expected empirical loss can be readily extended to estimating f up to weak isometry under the expected integral loss by including an extra agnostic error term due to the discretization of X by xi’s.
on X .",1. Introduction,[0],[0]
"The minimax estimation error depends on the smoothness of graphon f , the structure of latent space (X , µ), and the observation probability ρ.
",1. Introduction,[0],[0]
There is a recent surge of interest in graphon estimation.,1. Introduction,[0],[0]
"Various procedures have been proposed and analyzed (Gao et al., 2015; Klopp et al., 2015; Gao et al., 2016; Wolfe & Olhede, 2013; Airoldi et al., 2013; Yang et al., 2014; Chan & Airoldi, 2014; Cai et al., 2014; Zhang et al., 2015; Borgs et al., 2015a; Klopp & Verzelen, 2017; Borgs et al., 2017).",1. Introduction,[0],[0]
"A recent line of work (Gao et al., 2015; Klopp et al., 2015; Gao et al., 2016) has characterized the minimax error rate in certain special cases.",1. Introduction,[0],[0]
"In particular, for stochastic block model with k blocks, it is shown that the minimax error rate is k 2
n2ρ + log k nρ .",1. Introduction,[0],[0]
For fully observed graphons with f being Hölder smooth on X =,1. Introduction,[0],[0]
"[0, 1] and ρ = 1, the minimax error rate turns out be n−1 log k + n−2α/(α+1), where α is the smoothness index of f .",1. Introduction,[0],[0]
"This result was extended by (Klopp et al., 2015; Gao et al., 2016) to sparse regimes where ρ→ 0 as n→∞.
From a computational perspective, the problem appears to be much harder and far less well-understood.",1. Introduction,[0],[0]
In the special case where f is α-Hölder smooth on X =,1. Introduction,[0],[0]
"[0, 1], a universal singular value thresholding (USVT) algorithm is shown in (Chatterjee, 2015) to achieve an error rate of n−1/3ρ−1/2.",1. Introduction,[0],[0]
"However, this performance guarantee is far from the minimax optimal rate log(nρ)/(nρ).",1. Introduction,[0],[0]
"A similar spectral method is shown in (Xu et al., 2014) to achieve a vanishing MSE when nρ log n",1. Introduction,[0],[0]
but without an explicit characterization of the rate of the convergence.,1. Introduction,[0],[0]
"The nearestneighbor based approach is analyzed in (Song et al., 2016) under a stringent assumption nρ √ n.",1. Introduction,[0],[0]
"A simple degree sorting algorithm (Borgs et al., 2015b) is shown to achieve an error rate of (log(nρ)/(nρ))α/(4α+d) for α ∈ (0, 1] under the restrictive assumption that ∫ 1 0 f(x, y)dy is strictly monotone in x.
",1. Introduction,[0],[0]
"In summary, despite the recent significant effort devoted to developing fundamental limits and efficient algorithms for graphon estimation, an understanding of the statistical and computational aspects of graphon estimation is still lacking.",1. Introduction,[0],[0]
"In particular, there is a wide gap between the known performance bounds of polynomial-time estimator and the minimax optimal estimation rate.",1. Introduction,[0],[0]
"This raises a fundamental question:
Is there a polynomial-time estimator that is guaranteed to achieve the minimax optimal rate?
",1. Introduction,[0],[0]
"In this paper, we provide a partial answer to this question by analyzing the universal singular value thresholding (USVT) algorithm proposed by Chatterjee (Chatterjee, 2015).",1. Introduction,[0],[0]
"The universal singular value thresholding is a simple and versatile method for structured matrix estimation and has been applied to a variety of different problems such as rank-
ing (Shah et al., 2016).",1. Introduction,[0],[0]
It truncates the singular values of A at a threshold slightly above the spectral norm ‖A−E,1. Introduction,[0],[0]
"[A] ‖, and estimates M by a properly rescaled A after truncation.",1. Introduction,[0],[0]
"It is computationally efficient, however, its performance guarantee established in (Chatterjee, 2015) requires the total number of observed edges to be much larger than n(2d+2)/(d+2) to attain a vanishing MSE.",1. Introduction,[0],[0]
"In contrast, our improved performance bound shows that the total number of observed edges only needs to be a constant factor larger than n log n, irrespective of the latent space dimension d.
More formally, by assuming the average vertex degree is at least logarithmic in n, i.e., nρ = Ω(log n), and X is a compact subset in Rd, the mean-squared error rate of USVT is shown to be upper bounded by (nρ)−2α/(2α+d), when f belongs to either α-smooth Hölder function class H(α,L) or α-smooth Sobolev space S(α,L).",1. Introduction,[0],[0]
"This convergence rate of USVT is approaching the minimax optimal rate log(nρ)/(nρ) provided in (Gao et al., 2015) for d = 1, as f becomes smoother, i.e., α increases.",1. Introduction,[0],[0]
"In fact, we show that if f is analytic with infinitely many times differentiability2, then the error rate is upper bounded by logd(nρ)/(nρ).
",1. Introduction,[0],[0]
"In the special case where f is a step fuction or X is a discrete set, then the graphon model specializes to the stochastic block model with k blocks for some k.",1. Introduction,[0],[0]
"In this case, the error rate of USVT is shown to be k/(nρ), which is larger than the optimal minimax rate by at most a multiplicative factor k/ log k.",1. Introduction,[0],[0]
"This factor coincides with the ratio of the Kesten-Stigum threshold and information-theoretic threshold in community detection (Banks et al., 2016; Abbe & Sandon, 2015; Banks et al., 2018).",1. Introduction,[0],[0]
"Based on compelling but non-rigorous statistical physics arguments, it is believed that no polynomial-time algorithms are able to detect the communities between the KS-threshold and IT-threshold (Moore, 2017).",1. Introduction,[0],[0]
"This coincidence indicates that k/(nρ) may be the optimal estimation rate among all polynomial-time algorithms, and the minimax optimal rate may not be attainable in polynomial-time.",1. Introduction,[0],[0]
"During the preparation of this manuscript, we became aware of an earlier arXiv preprint (Klopp & Verzelen, 2017)[Proposition 4] which also derives the error rate of k/(nρ).
",1. Introduction,[0],[0]
Our proof incorporates three interesting ingredients.,1. Introduction,[0],[0]
"One is a characterization of the estimation error of USVT in terms of the tail of eigenvalues of M , and the spectral norm of the noise perturbation ‖A",1. Introduction,[0],[0]
"− E [A|M ] ‖, see e.g., (Shah et al., 2016)[Lemma 3].",1. Introduction,[0],[0]
The second one is a high-probability upper bound on ‖A− E,1. Introduction,[0],[0]
"[M |A] ‖ obtained from matrix concentration inequalities initially developed by (Feige & Ofek, 2005).",1. Introduction,[0],[0]
"The last but most important one is a characterization
2The minimax lower bound in (Gao et al., 2015)[Appendix A.1] is only established for the α-smooth Hölder function class for any fixed α and d = 1.",1. Introduction,[0],[0]
"It is an open question whether the error rate of logd(nρ)/(nρ) is minimax-optimal for analytic graphons.
",1. Introduction,[0],[0]
"Algorithm 1 Universal Singular Value Thresholding (USVT) (Chatterjee, 2015)
1: Input: A ∈ Rn×n, ρ ∈",1. Introduction,[0],[0]
"[0, 1] and a threshold τ > 0.",1. Introduction,[0],[0]
2: Let A = ∑n i=1,1. Introduction,[0],[0]
siuiv,1. Introduction,[0],[0]
>,1. Introduction,[0],[0]
"i be its singular value decompo-
sition with s1 ≥ s2 ≥ · · ·",1. Introduction,[0],[0]
≥ sn. 3: Let S be the set of “thresholded” singular values: S = {i : si ≥ τ}.,1. Introduction,[0],[0]
"4: Let Â =
∑ i∈S siuiv >",1. Introduction,[0],[0]
"i
and M̃ = Â/ρ.",1. Introduction,[0],[0]
5: Output a matrix M̂ ∈,1. Introduction,[0],[0]
"[0, 1]n×n such that M̂ii = 0 for
all i ∈",1. Introduction,[0],[0]
"[n], and for 1 ≤ i < j ≤ n, M̂ij = M̂ji and
M̂ij =  ",1. Introduction,[0],[0]
"M̃ij , if M̃ij ∈",1. Introduction,[0],[0]
"[0, 1] 1, if M̃ij > 1 0, if M̃ij < 0.
of the tail of eigenvalues of M using piecewise polynomial approximations of f , which were originally used to study the spectrum of integral operators defined by f (Birman & Solomyak, 1967; 1977).",1. Introduction,[0],[0]
"The piecewise constant approximations of f have appeared in the previous work on graphon estimation (Chatterjee, 2015; Gao et al., 2015; Klopp et al., 2015), and are sufficient for the purpose of deriving minimax estimation rates because the smoothness of f beyond α = 1 does not improve the rates.",1. Introduction,[0],[0]
"However, piecewise degree-bαc polynomial approximations are needed for showing USVT to achieve a faster converging rate as α increases.
",1. Introduction,[0],[0]
"Notation For a vector x ∈ Rd, let ‖x‖2 denote its `2 norm and ‖x‖∞ = max1≤i≤d |xi| denote its `-infinity norm.",1. Introduction,[0],[0]
"For any matrix M , let ‖M‖ denote its spectral norm and ‖M‖F denote its Frobenius norm.",1. Introduction,[0],[0]
"For any positive integer n, let [n] = {1, . . .",1. Introduction,[0],[0]
", n}.",1. Introduction,[0],[0]
"For any positive constant α, let bαc denotes the largest integer strictly smaller than α.",1. Introduction,[0],[0]
"For two real numbers α and β, let α ∧ β = min{α, β} and α ∨ β = max{α, β}.",1. Introduction,[0],[0]
"If κ = (κ1, . . .",1. Introduction,[0],[0]
", κd) is a multi-index with κi ∈ N, then |κ| = ∑d i=1",1. Introduction,[0],[0]
"κi, κ! =",1. Introduction,[0],[0]
∏d i=1,1. Introduction,[0],[0]
"κi!, and
xκ = ∏d i=1",1. Introduction,[0],[0]
x κi i for a vector x ∈ Rd.,1. Introduction,[0],[0]
Let A denote the adjacency matrix of the observed graph with Aii = 0 by convention.,2. Main results,[0],[0]
"Then conditional on x = (x1, . . .",2. Main results,[0],[0]
", xn), for 1 ≤",2. Main results,[0],[0]
"i < j ≤ n, Aij = Aji are independently distributed as Bern (ρMij).",2. Main results,[0],[0]
"In particular, E [A|M ] = ρM .
",2. Main results,[0],[0]
"To describe our main results, we first recall the universal singular value thresholding (USVT) algorithm (Chatterjee,
2015) as stated in Algorithm 1.",2. Main results,[0],[0]
"Note that according to the graphon model (1), the edge probability matrix M may not be of low-rank.",2. Main results,[0],[0]
"Nevertheless, it is possible that the singular values of M , or equivalently magnitudes of eigenvalues, drop off fast enough and as a consequence M is approximately low-rank.",2. Main results,[0],[0]
"If this is indeed the case, then a natural idea to estimate M is via low-rank approximations of A. In particular, USVT truncates the singular values of A at a proper threshold τ , and estimates M by the rescaled A after truncation.
",2. Main results,[0],[0]
"Note that Algorithm 1 applies hard-thresholding to the singular values of A. Alternatively, we can use softthresholding (Koltchinskii et al., 2011) and let Â =∑ i∈S(si",2. Main results,[0],[0]
− τ)uiv>i .,2. Main results,[0],[0]
Our main results with the hardthresholding also apply to the soft-thresholding.,2. Main results,[0],[0]
"As argued in (Chatterjee, 2015), the cut-off threshold τ is chosen to be slightly above ‖A − E [A|M ] ‖, so that noise is suppressed and signals corresponding to large singular values of E [A|M ] are maintained.",2. Main results,[0],[0]
"Since conditional on M , A is a random matrix with independent entries bounded in [0, 1] of variance at most ρ, it is expected that ‖A − E [A|M ] ‖ .",2. Main results,[0],[0]
"√nρ with high probability, in view of standard matrix concentration inequalities.",2. Main results,[0],[0]
"This turns out to be true if the observed graph is not too sparse, i.e., there exists a positive constant C such that
nρ ≥ C log n. (3)
",2. Main results,[0],[0]
"However, when the observed graph is sparse with nρ = o(log n), due to the existence of high-degree vertices, ‖A− E [A|M ] ‖ √nρ with high probability (Krivelevich & Sudakov, 2003).
",2. Main results,[0],[0]
"Motivated by the discussion above, we focus on the relatively sparse regime where (3) holds, and set τ = c0 √ nρ for a positive large constant c0, whose value depends on the constant C in (3).",2. Main results,[0],[0]
"It is known that with high probability,
‖A− E",2. Main results,[0],[0]
"[A|M ] ‖ ≤ κ√nρ,
where
κ =
{ 4 + o(1) nρ = ω(log n)
2 + o(1)",2. Main results,[0],[0]
"nρ = ω(log4 n) , (4)
see, e.g., (Hajek et al., 2016)[Lemma 30].",2. Main results,[0],[0]
"Hence, the constant c0 can be set to be a universal constant strictly larger than 4 in the case of nρ log(n) and 2 in the case of nρ log4(n).",2. Main results,[0],[0]
"Notably, in these cases, the cutoff threshold τ is universal, independent of the underlying graphon f .
",2. Main results,[0],[0]
"Next, we present our main results without proofs.",2. Main results,[0],[0]
"The excluded details can be found in the full paper (Xu, 2017).",2. Main results,[0],[0]
Our first result provides an upper bound to the estimation error of USVT.,2. Main results,[0],[0]
"A similar result without explicit constants is proved
in (Shah et al., 2016)[Lemma 3], which improves on the previous result in (Chatterjee, 2015)[Lemma 3.5].",2. Main results,[0],[0]
"Another similar result with slightly different constants is proved in (Koltchinskii et al., 2011)[Theorem 1] for soft singular value thresholding and in (Klopp et al., 2011)[Theorem 2] for hard singular value thresholding.
",2. Main results,[0],[0]
Theorem 1.,2. Main results,[0],[0]
Consider the relatively sparse regime where (3) holds.,2. Main results,[0],[0]
"For all c > 0 there exists a positive constant κ such that if τ = (1 + δ)κ √ nρ for a fixed constant δ > 0, then conditional on M , with probability at least 1− n−c,
1
n2 ‖M̂ −M‖2F
≤",2. Main results,[0],[0]
16(1 + δ)2,2. Main results,[0],[0]
min 0≤r≤n κ2r nρ + 1 n2δ2 ∑ i≥r+1 λ2i (M)  .,2. Main results,[0],[0]
"It further follows that MSE(M̂) is bounded by the same error term as above plus the failing probability n−c.
",2. Main results,[0],[0]
Theorem 1 gives an upper bound to the estimation error of USVT in terms of the tail of eigenvalues of M and the observation probability ρ.,2. Main results,[0],[0]
The upper bound invovles minimization of a sum of two terms over integers 0 ≤,2. Main results,[0],[0]
r ≤ n:,2. Main results,[0],[0]
the first term r/(nρ) can be viewed as the estimation error for a rank-r matrix; the second term n−2 ∑ i≥r+1 λ 2 i (M) is the tail of eigenvalues of M and charaterizes the approximation error of M by the best rank-r matrix.,2. Main results,[0],[0]
The optimal r is chosen to achieve the best trade-off between the estimation error and the approximaiton error.,2. Main results,[0],[0]
"Moreover, a lighter tail of eigenvalues of M implies a faster convergence rate of the estimation error.",2. Main results,[0],[0]
"To characterize different tails of eigenvalues of M , we introduce the following definitions of polynomial and super-polynomial decays.
",2. Main results,[0],[0]
Definition 1 (Polynomial decay).,2. Main results,[0],[0]
We say the eigenvalues of M asymptotically satisfy a polynomial decay with rate β > 0,2. Main results,[0],[0]
if for all integers 0 ≤,2. Main results,[0],[0]
"r ≤ n− 1,
1
n2 ∑ i≥r+1 E [ λ2i (M) ] ≤ c0r−β +",2. Main results,[0],[0]
"c1n−1,
where c0 and c1 are two constants independent of n and r.
Definition 2 (Super-polynomial decay).",2. Main results,[0],[0]
We say the eigenvalues of M asymptotically satisfy a super-polynomial decay with rate α > 0,2. Main results,[0],[0]
if for all integers 0 ≤,2. Main results,[0],[0]
"r ≤ n− 1,
1
n2 ∑ i≥r+1 E [ λ2i (M) ] ≤",2. Main results,[0],[0]
"c0e−c2r α + c1n −1,
where c0, c1, c2 are constants independent of n and r.
We remark that in the above two definitions, we allow for a residual term c1n−1, which is responsible for the contribution of diagonal entries of M .",2. Main results,[0],[0]
"According to Theorem 1,
this residual term only induces an additional n−1 error in the upper bound to MSE and will not affect our main results.",2. Main results,[0],[0]
"The following corollary readily follows from Theorem 1 by choosing the optimal r according to the decay rates of eigenvalues of M .
",2. Main results,[0],[0]
Corollary 1.,2. Main results,[0],[0]
Consider the relatively sparse regime where (3) holds and suppose the eigenvalues of M satisfy a polynomial decay with rate β > 0.,2. Main results,[0],[0]
Then there exists a positive constant κ > 0,2. Main results,[0],[0]
"such that if τ = (1 + δ)κ √ nρ for a fixed constant δ > 0,
MSE(M̂) ≤ c′(nρ)− β β+1 .
If instead the eigenvalues of M satisfy a super-polynomial decay with rates α > 0, then
MSE(M̂) ≤ c′ (log(nρ)) 1/α
nρ ,
where c′ is a positive constant independent of n.
Proof.",2. Main results,[0],[0]
"The first conclusion follows from Theorem 1 by choosing c = 1 and r = b(nρ)1/(β+1)c and the second one follows by choosing c = 1 and r = b(log(nρ)/c2)1/αc.
",2. Main results,[0],[0]
Next we specialize our general results in different settings by deriving the decay rates of eigenvalues of M.,2. Main results,[0],[0]
"We first present results on the rate of convergence in the stochastic block model setting, where xi ∈ {1, 2, . . .",2.1. Stochastic block model,[0],[0]
", k} indicating which community that vertex i belongs to.",2.1. Stochastic block model,[0],[0]
"In this case, Mij only depends on the communities of vertex i and vertex j, and M has rank at most k.
Theorem 2.",2.1. Stochastic block model,[0],[0]
Assume (3) holds under the stochastic block model with k blocks.,2.1. Stochastic block model,[0],[0]
There exists a positive constant κ > 0,2.1. Stochastic block model,[0],[0]
"such that if τ = (1+δ)κ √ nρ for some fixed constant δ > 0, then
MSE(M̂) ≤ c′′",2.1. Stochastic block model,[0],[0]
"[ k nρ ∧ 1 ] .
where c′′ is a positive constant depending on κ and δ.
",2.1. Stochastic block model,[0],[0]
Proof.,2.1. Stochastic block model,[0],[0]
"Under the stochastic block model, M is of rank at most k.",2.1. Stochastic block model,[0],[0]
Thus λi(M) = 0 for all i ≥ k+ 1.,2.1. Stochastic block model,[0],[0]
"Moreover, since Mij ∈ [0, 1], it follows that ∑k i=1",2.1. Stochastic block model,[0],[0]
λ 2,2.1. Stochastic block model,[0],[0]
i (M) = ‖M‖2F ≤ n2.,2.1. Stochastic block model,[0],[0]
"Applying Theorem 1 with r = 0 and r = k yields the desired result.
",2.1. Stochastic block model,[0],[0]
"Theorem 2 shows that the convergence rate of MSE of USVT is at most knρ ∧ 1, while the previous result in (Chatterjee, 2015) establishes that the convergence rate is at most
√ k/n for ρ = 1.",2.1. Stochastic block model,[0],[0]
"During the preparation of this manuscript, we became aware of an earlier arXiv preprint (Klopp & Verzelen, 2017)[Proposition 4] which also proves the error rate of k/(nρ).
",2.1. Stochastic block model,[0],[0]
"The minimax optimal rate derived in (Klopp et al., 2015; Gao et al., 2016) is ( k2
n2ρ + log k nρ
) ∧ 1.",2.1. Stochastic block model,[0],[0]
"Hence, the error
rate of USVT is larger than the minimax optimal rate by at most a multiplicative factor of k/ log k, which resembles the computational gap observed in community detection (Banks et al., 2016; Abbe & Sandon, 2015) and the related high-dimensional statistical inference problems discussed in (Banks et al., 2018).",2.1. Stochastic block model,[0],[0]
"In particular, it is shown in (Banks et al., 2016; Abbe & Sandon, 2015) that estimation better than randomly guessing is attainable efficiently by spectral methods when above the Kesten-Stigum threshold, while it is information-theoretically possible even strictly below the KS threshold by a multiplicative factor k/ log k for large k.",2.1. Stochastic block model,[0],[0]
"In between the KS threshold and informationtheoretic threshold, non-trivial estimation is informationtheoretically possible but believed to require exponential time.",2.1. Stochastic block model,[0],[0]
"The same conclusion also holds for exact community recovery as shown in (Chen & Xu, 2014).",2.1. Stochastic block model,[0],[0]
"Due to this coincidence, it is tempting to believe that knρ ∧ 1 might be the optimal estimation rate among all polynomial-time algorithms; however, we do not have a proof.",2.1. Stochastic block model,[0],[0]
Next we proceed to the smooth graphon setting.,2.2. Smooth graphon,[0],[0]
We assume X =,2.2. Smooth graphon,[0],[0]
"[0, 1)d for simplicity.",2.2. Smooth graphon,[0],[0]
3.,2.2. Smooth graphon,[0],[0]
There are various notions to characterize the smoothness of graphon.,2.2. Smooth graphon,[0],[0]
"In this paper, we focus on the following two notions, which are widely adopted in the non-parametric regression literature (Tsybakov, 2008).",2.2. Smooth graphon,[0],[0]
"Given a function g : X → R and a multi-index κ, let
∇κg(x) = ∂|κ|g(x)
(∂x)κ (5)
denote its partial derivative whenever it exists.
",2.2. Smooth graphon,[0],[0]
Definition 3 (Hölder class).,2.2. Smooth graphon,[0],[0]
Let α and L be two positive numbers.,2.2. Smooth graphon,[0],[0]
"The Hölder class H(α,L) on X is defined as the set of functions g : X → R whose partial derivatives satisfy4∑ κ:|κ|=bαc 1 κ! |∇κg(x)−∇κg(x′)| ≤",2.2. Smooth graphon,[0],[0]
"L‖x− x′‖α−bαc∞ .
",2.2. Smooth graphon,[0],[0]
"(6)
3If X is a compact set in Rd, then there exists a positive constant a such that X ⊂",2.2. Smooth graphon,[0],[0]
"[−a, a)d.",2.2. Smooth graphon,[0],[0]
"Hence, the general compact set case can be reduced to X =",2.2. Smooth graphon,[0],[0]
"[0, 1)d by a proper scaling.
",2.2. Smooth graphon,[0],[0]
"4 Changing the infinity-norm to a different norm (e.g. `2 norm) only changes L (by a factor may depending on d and α) and thus will not affect rates of convergence.
",2.2. Smooth graphon,[0],[0]
"Note that if α ∈ (0, 1], then (6) is equivalent to the Lip-α condition:
|g(x)−",2.2. Smooth graphon,[0],[0]
g(x′)| ≤,2.2. Smooth graphon,[0],[0]
"L‖x− x′‖α∞. (7)
One can also measure the smoothness with respect to the underlying measure µ.",2.2. Smooth graphon,[0],[0]
"This leads to the consideration of Sobolev space (Leoni, 2009).",2.2. Smooth graphon,[0],[0]
"For ease of exposition, we assume µ is the Lebesgue measure.",2.2. Smooth graphon,[0],[0]
"The main results can be extended to more general Borel measures.
",2.2. Smooth graphon,[0],[0]
Definition 4 (Sobolev space).,2.2. Smooth graphon,[0],[0]
Let α and L be two positive numbers.,2.2. Smooth graphon,[0],[0]
"The Sobolev space S(α,L) on (X , µ) is defined as the set of functions g : X → R",2.2. Smooth graphon,[0],[0]
"whose partial derivatives5 satsify∑
κ:|κ|=α
∫ X ‖∇κg(x)‖22 dx ≤ L2, for integral α,
and for non-integral α,
∑ κ:|κ|=bαc ∫ X×X",2.2. Smooth graphon,[0],[0]
"‖∇κg(x)−∇κg(y)‖22 ‖x− y‖2(α−bαc)+d2 dxdy ≤ L2.
",2.2. Smooth graphon,[0],[0]
"Note that the graphon f(x, y) is a bi-variate function.",2.2. Smooth graphon,[0],[0]
"We treat it as a function of x for every fixed y, and introduce the following two conditions on f .
",2.2. Smooth graphon,[0],[0]
Condition 1 (Hölder condition on f ).,2.2. Smooth graphon,[0],[0]
"There exist two positive numbers α and L such that f(·, y) ∈ H(α,L) for every y ∈ X .",2.2. Smooth graphon,[0],[0]
Condition 2 (Sobolev condition on f ).,2.2. Smooth graphon,[0],[0]
"There exist two positive numbers α and L such that f(·, y) ∈ S(α,L(y)) for every y, where L(y) : X → R satisfies that ∫ X L
2(y)dy ≤ L2.
",2.2. Smooth graphon,[0],[0]
"The following key result shows that the eigenvalues of M drop off to zero in a polynomial rate depending on the smoothness index α of f.
Proposition 1.",2.2. Smooth graphon,[0],[0]
Suppose that f satisfies either Condition 1 or Condition 2.,2.2. Smooth graphon,[0],[0]
"Then there exists a constantC = C(α,L, d) only depending on α, L, and d such that for all integers 0 ≤",2.2. Smooth graphon,[0],[0]
"r ≤ n− 1,
1
n2 ∑ i≥r+1 E [ λ2i (M) ] ≤ C(α,L, d) ( n−1 + r−2α/d ) .
",2.2. Smooth graphon,[0],[0]
Remark 1.,2.2. Smooth graphon,[0],[0]
"In the special case where f is Hölder smooth with α = 1, Proposition 1 has been proved in (Chatterjee, 2015).",2.2. Smooth graphon,[0],[0]
"In particular, it is shown in (Chatterjee, 2015) that f can be well-approximated by a piecewise constant function.",2.2. Smooth graphon,[0],[0]
"As a consequence, M can be approximated by a rank-r
5More generally, the Sobolev space is defined when only weak derivatives exist (Leoni, 2009).
block matrix with r2 blocks, and the entry-wise approximation error in the squared Frobenius norm is shown to be approximately r−2α/d.",2.2. Smooth graphon,[0],[0]
The same idea can be readily extended to the case α ∈,2.2. Smooth graphon,[0],[0]
"[0, 1].",2.2. Smooth graphon,[0],[0]
"However, piecewise constant approximations of f no longer suffice for α > 1, because Hölder smoothness condition (6) no longer implies Lip-α condition (7).",2.2. Smooth graphon,[0],[0]
"In fact (7) with α > 1 will imply that f ≡ C for some constant C. Instead, we show that f can be well approximated by piecewise polynomials of degree bαc.
",2.2. Smooth graphon,[0],[0]
"By combining Proposition 1 with Corollary 1, we immediately get the following result on the convergence rate of the estimation error of USVT.
",2.2. Smooth graphon,[0],[0]
Theorem 3.,2.2. Smooth graphon,[0],[0]
"Under the graphon estimation model, assume (3) holds, and f satisfies either Condition 1 or Condition 2.",2.2. Smooth graphon,[0],[0]
"There exists a positive constant κ such that if τ = (1 + δ)κ √ nρ for some fixed constant δ > 0, then
MSE(M̂) ≤ c′′(nρ)− 2α 2α+d ,
where c′′ is a positive constant independent of n.
Theorem 3 implies that if f is infinitely many times differentiable, then the MSE of USVT converges to zero faster than (nρ)−1+ for an arbitrarily small constant > 0.",2.2. Smooth graphon,[0],[0]
"In fact, we can prove a sharper result when f is analytic, i.e., f is infinitely differentiable and its Taylor series expansion around any point in its domain converges to the function in some neighborhood of the point.",2.2. Smooth graphon,[0],[0]
"One concerete example of analytic function which appears in the study of matrix completion is f(x, y) = 1/(1+exp(−〈x, y〉))",2.2. Smooth graphon,[0],[0]
"(Ganti et al., 2015).
",2.2. Smooth graphon,[0],[0]
Theorem 4.,2.2. Smooth graphon,[0],[0]
"Under the graphon estimation model, suppose there there exists positive constants a and b such that for all multi-indices κ and all y ∈ X
sup x∈X
∂|κ|f(x, y)
",2.2. Smooth graphon,[0],[0]
(∂x)κ ≤ ba|κ|κ!.,2.2. Smooth graphon,[0],[0]
"(8)
There exists positive constants c0 and c1 only depending on a, b, d such that for all integers 0 ≤",2.2. Smooth graphon,[0],[0]
"r ≤ n− 1,
1
n2 ∑ i≥r+1 λ2i (M) ≤ c1 ( n−1 + exp ( −c0r1/d )) .",2.2. Smooth graphon,[0],[0]
"(9)
Moreover, assume (3) holds.",2.2. Smooth graphon,[0],[0]
"Then there exists positive constants c′, c′′ such that if τ = c′′ √ nρ,
MSE(M̂) ≤ c′ log d (nρ)
nρ .
",2.2. Smooth graphon,[0],[0]
"We remark that for a fixed y ∈ X , (8) is a sufficient and necessary condition for f(·, y) being analytic (Komatsu, 1960).",2.2. Smooth graphon,[0],[0]
Note that (9) implies the eigenvalues of M has a super-polynomial decay with rate α = 1/d.,2.2. Smooth graphon,[0],[0]
"Its proof is
based on approximating f(·, y) using its Taylor series truncated at degree ` r1/d. When d = 1, the eigenvalues of M decays to zero exponentially fast in r; such an exponential decay can be also proved via Chebyshev polynomial approximation of f as shown in (Little & Reade, 1984).",2.2. Smooth graphon,[0],[0]
We compare the rates of convergence of USVT for estimating Hölder smooth graphons to the minimax optimal rates when the dimension of latent feature space d = 1,2.2.1. COMPARISON TO MINIMAX OPTIMAL RATES,[0],[0]
"(Gao et al., 2015; Klopp et al., 2015; Gao et al., 2016):
R∗n  1, nρ = O(1) log(nρ) nρ , ω(1) ≤",2.2.1. COMPARISON TO MINIMAX OPTIMAL RATES,[0],[0]
"nρ ≤ n α(log n)α+1
(n2ρ)− α α+1 , nρ ≥",2.2.1. COMPARISON TO MINIMAX OPTIMAL RATES,[0],[0]
"nα(log n)α+1
.
(10)
",2.2.1. COMPARISON TO MINIMAX OPTIMAL RATES,[0],[0]
"Thus, as graphon gets smoother, i.e., α increases, the upper bound to the rate of convergence of USVT (nρ)−2α/(2α+1) approaches the minimax optimal rate log(nρ)/(nρ).",2.2.1. COMPARISON TO MINIMAX OPTIMAL RATES,[0],[0]
"We state a useful result, connecting the eigenvalues of M to the spectrum of an integral operator defined in terms of f. This allows us to translate existing results on the decay rates of eigenvalues of integral operators to those of M. Define an operator T : L2(X , µ)→ L2(X , µ) as
(T g) (x) , ∫ X f(x, y)g(y)µ(dy), ∀g ∈ L2(X , µ), (11)
where f acts as a kernal function.",2.3. Connections to spectrum of integral operators,[0],[0]
"Hence, M can be also viewed as a kernal matrix.",2.3. Connections to spectrum of integral operators,[0],[0]
"We assume that the graphon f is square-integrable, i.e., ∫ X×X",2.3. Connections to spectrum of integral operators,[0],[0]
"f
2(x, y)µ(dx)µ(dy) <",2.3. Connections to spectrum of integral operators,[0],[0]
"∞. In this case, the operator T is known as Hilbert-Schmidt integral operator, which is compact.",2.3. Connections to spectrum of integral operators,[0],[0]
"Therefore it admits a discrete spectrum with finite multiplicity of all of its nonzero eigenvalues (see e.g. (Kato, 1966; Koltchinskii, 1998; von Luxburg et al., 2005)).",2.3. Connections to spectrum of integral operators,[0],[0]
"Moreover, any of its eigenfunctions is continuous onX .",2.3. Connections to spectrum of integral operators,[0],[0]
Denote the eigenvalues of operator T sorted in decreasing order by |λ1(T )| ≥ |λ2(T ),2.3. Connections to spectrum of integral operators,[0],[0]
"| ≥ · · · and its corresponding eigenfunctions with unit L2(X , µ) norm by φ1, φ2, · · · .",2.3. Connections to spectrum of integral operators,[0],[0]
"By the definition of λk and φk, we have∫ X×X",2.3. Connections to spectrum of integral operators,[0],[0]
"( f(x, y)− m∑ k=1 λk(T )φk(x)φk(y) )2 µ(dx)µ(dy)
→ 0, as m→∞ (12)
see, e.g., (Kato, 1966)[Chapter Five, Section 2.4].
",2.3. Connections to spectrum of integral operators,[0],[0]
The following theorem upper bounds the tail of eigenvalues of M in expectation using the tail of eigenvalues of T .,2.3. Connections to spectrum of integral operators,[0],[0]
"Previous results in (Koltchinskii & Giné, 2000) provide
similar upper bounds to the `2 distance between the ordered eigenvalues of M and those of T .",2.3. Connections to spectrum of integral operators,[0],[0]
Theorem 5.,2.3. Connections to spectrum of integral operators,[0],[0]
"For any integer r ≥ 0,
1
n2 ∑ k>r E [ λ2k(M) ] ≤ ∞∑ k>r λ2k(T ) + 1 n r∑ k,`=1 λk(T )λ`(T )E [ φ2k(x1)φ 2 `(x1) ] .
(13)
The second term on the right hand side of (13) is responsible for the contribution of the diagonal entries of M .",2.3. Connections to spectrum of integral operators,[0],[0]
When E [ φ2k(x1)φ 2 `(x1) ] is bounded and ∑∞,2.3. Connections to spectrum of integral operators,[0],[0]
"k=1 λk(T ) <∞, this second term is on the order of n−1.
",2.3. Connections to spectrum of integral operators,[0],[0]
"It is well known that if the kernel function f is smoother, the eigenvalues of T drops to zero faster.",2.3. Connections to spectrum of integral operators,[0],[0]
"There is vast literature on estimating the decay rates of the eigenvalues of T in terms of the smoothness conditions of f , see, e.g., (Krein, 1965; Birman & Solomyak, 1977; König, 2013; Delgado & Ruzhansky, 2014).",2.3. Connections to spectrum of integral operators,[0],[0]
"Theorem 5 allows us to translate those existing results on the decay rates of eigenvalues of T to those of M , as illustrated by examples in Section 3.",2.3. Connections to spectrum of integral operators,[0],[0]
"We provide numerical results on synthetic datasets, which corroborate our theoretical results.",3. Numerical examples,[0],[0]
"Additional numerical results on stochastic block models can be found in the full paper (Xu, 2017).",3. Numerical examples,[0],[0]
We assume the sparsity level ρ is known and set the threshold τ = 2.01 √ nρ throughout the experiments.,3. Numerical examples,[0],[0]
"In the case where ρ is unknown, one can apply cross-validation procedure to adaptively choose the sparsity level ρ as shown in (Gao et al., 2016).",3. Numerical examples,[0],[0]
"We first apply USVT with input (A, τ, ρ), and then output the estimator M̂ , and finally calculate the MSE error MSE(M̂).",3. Numerical examples,[0],[0]
"For some a > 0, let h :",3.1. Translation invariant graphon,[0],[0]
"[−a, a] → R denote an even function, i.e., h(x) = h(−x).",3.1. Translation invariant graphon,[0],[0]
Let us extends its domain to the real line by the periodic extension such that h(x + 2ka) = h(x) for all x ∈,3.1. Translation invariant graphon,[0],[0]
"[−a, a] and integers k ∈ Z.",3.1. Translation invariant graphon,[0],[0]
By construction h has a period 2a.,3.1. Translation invariant graphon,[0],[0]
"Using this function, we can define a translation-invariant graphon on the product space [−a, a]× [−a, a] via f(x, y) = h(x− y).",3.1. Translation invariant graphon,[0],[0]
"Since h is even, it follows that f is symmetric.",3.1. Translation invariant graphon,[0],[0]
Then the integral operator T defined in (11) reduces to: for all x ∈,3.1. Translation invariant graphon,[0],[0]
"[−a, a],
(T g) (x) = 1 2a ∫ a −a h(x− y)g(y)dy = 1 2a (h ∗ g) (x),
where ∗ denotes the convolution.",3.1. Translation invariant graphon,[0],[0]
"Hence, we can explicitly determine the eigenvalues of T via Fourier analysis.",3.1. Translation invariant graphon,[0],[0]
"In
particular, let ĥ[k] denote the Fourier coefficients:
ĥ[k] = 1
2a ∫ a −a h(x)e−jπkx/adx,
where throughout this section j denotes the imaginary part such that j2 = −1, Since h is even, it follows that ĥ[k]’s are real and ĥ[k] = ĥ[−k].",3.1. Translation invariant graphon,[0],[0]
"Fourier analysis entails a one-toone correspondence between eigenvalues of T and Fourier coefficients of h: λk(T ) = ĥ[k].
",3.1. Translation invariant graphon,[0],[0]
We specify h :,3.1. Translation invariant graphon,[0],[0]
"[−1, 1]→ R as h(x) = |x|",3.1. Translation invariant graphon,[0],[0]
"and simulate the graphon model with f(x, y) = h(x− y) for x, y ∈",3.1. Translation invariant graphon,[0],[0]
"[−1, 1] and the underlying measure µ being uniform over [−1, 1].",3.1. Translation invariant graphon,[0],[0]
"Since h(x) = |x|, the Fourier coefficients can be explicitly computed as λk(T )",3.1. Translation invariant graphon,[0],[0]
= ĥ[k] = 2 sin2(πk/2)/(π2k2) with eigenfunctions given by {cos(πkx)}∞k=0 and sin(πkx)}∞k=1.,3.1. Translation invariant graphon,[0],[0]
"It follows from Theorem 5 that the eigenvalues of M satisfy
1
n2 ∑ i≥r+1 E [ λ2i (M) ] ≤ O(n−1) +O(r−3) (14)
uniformly over all integers r ≥ 0.",3.1. Translation invariant graphon,[0],[0]
"Therefore, our theory predicts that the MSE of USVT converges to zero at least in a rate of (nρ)−3/4.",3.1. Translation invariant graphon,[0],[0]
The simulation results for varying observation probabilities are depicted in Fig. 1.,3.1. Translation invariant graphon,[0],[0]
Panel (a) shows the MSE converges to 0 as the number of vertices n increases.,3.1. Translation invariant graphon,[0],[0]
"In Panel (b), we rescale the x-axis to log(nρ) and the y-axis to the log of MSE.",3.1. Translation invariant graphon,[0],[0]
"The curves for different ρ align well with each other after the rescaling and decrease linearly with a slope of approximately 0.8, which is close to 3/4 as predicted by our theory.",3.1. Translation invariant graphon,[0],[0]
"In this section, we simulate the graphon model with X =",3.2. Sobolev graphon,[0],[0]
"[0, 1] and µ being the uniform measure and f(x, y) = min{x, y}.",3.2. Sobolev graphon,[0],[0]
"Then ∇xf(x, y) = 1{x≤y} and ∇yf(x, y) = 1{y≤x}.",3.2. Sobolev graphon,[0],[0]
"Moreover, |f(x, y)−f(x′, y′)| ≤ |x−x′|+|y−y′|.
",3.2. Sobolev graphon,[0],[0]
"However, the second-order weak derivatives of f do not exist.",3.2. Sobolev graphon,[0],[0]
"Therefore, f is Sobolev smooth with α = 1.",3.2. Sobolev graphon,[0],[0]
"In this case, one can get a bound on the eigenvalue decay rate tighter than Proposition 1 by directly computing λk(T ) and invoking Theorem 5.",3.2. Sobolev graphon,[0],[0]
"Note that
(T g) (x) = ∫ x 0 yg(y)dy + x ∫ 1 x g(y)dy.
",3.2. Sobolev graphon,[0],[0]
Suppose φ is an eigenfunction of T with eigenvalue λ.,3.2. Sobolev graphon,[0],[0]
Then∫ x 0 yφ(y)dy + x ∫,3.2. Sobolev graphon,[0],[0]
"1 x φ(y)dy = λφ(x).
",3.2. Sobolev graphon,[0],[0]
It follows that φ(0) = 1 and λφ′(x) = ∫ 1 x φ(y)dy.,3.2. Sobolev graphon,[0],[0]
It further implies that φ′(1) = 0,3.2. Sobolev graphon,[0],[0]
and λφ′′ + φ = 0.,3.2. Sobolev graphon,[0],[0]
"Therefore, the eigenfunction and eigenvalue pairs are given by
φk(x) = sin (2k − 1)πx
2 , and λk(T ) =
( 2
(2k − 1)π
)2 .
",3.2. Sobolev graphon,[0],[0]
It follows from Theorem 5 that the eigenvalues of M satisfy (14) uniformly over all integers r ≥ 0.,3.2. Sobolev graphon,[0],[0]
"Therefore, our theory predicts that the MSE of USVT converges to zero in a rate of (nρ)−3/4.",3.2. Sobolev graphon,[0],[0]
The simulation results for varying observation probabilities are depicted in Fig. 2.,3.2. Sobolev graphon,[0],[0]
"The curves in Panel (b) for different ρ align well with each other after the rescaling and decrease linearly with a slope of approximately 0.7, which is close to 3/4 as predicted by our theory.",3.2. Sobolev graphon,[0],[0]
"In this paper, we establish upper bounds to the graphon estimation error of USVT when the average vertex degree is at least logarithmic in n. Our results can be extended to the case of bounded average degrees by first trimming the highdegree vertices (Feige & Ofek, 2005) and then applying USVT.",4. Conclusions and future work,[0],[0]
We leave this extension as future work.,4. Conclusions and future work,[0],[0]
Another fundamental and open question is whether the minimax optimal rate can be achieved in polynomial-time.,4. Conclusions and future work,[0],[0]
This paper studies the problem of estimating the graphon function – a generative mechanism for a class of random graphs that are useful approximations to real networks.,abstractText,[0],[0]
"Specifically, a graph of n vertices is generated such that each pair of two vertices i and j are connected independently with probability ρn × f(xi, xj), where xi is the unknown d-dimensional label of vertex i, f is an unknown symmetric function, and ρn, assumed to be Ω(log n/n), is a scaling parameter characterizing the graph sparsity.",abstractText,[0],[0]
The task is to estimate graphon f given the graph.,abstractText,[0],[0]
Recent studies have identified the minimax optimal estimation error rate for d = 1.,abstractText,[0],[0]
"However, there exists a wide gap between the known error rates of polynomialtime estimators and the minimax optimal error rate.",abstractText,[0],[0]
"We improve on the previously known error rates of polynomial-time estimators, by analyzing a spectral method, namely universal singular value thresholding (USVT) algorithm.",abstractText,[0],[0]
"When f belongs to either Hölder or Sobolev space with smoothness index α, we show the error rates of USVT are at most (nρ)−2α/(2α+d).",abstractText,[0],[0]
"These error rates approach the minimax optimal error rate log(nρ)/(nρ) proved in prior work for d = 1, as α increases, i.e., f becomes smoother.",abstractText,[0],[0]
"Furthermore, when f is analytic with infinitely many times differentiability, we show the error rate of USVT is at most log(nρ)/(nρ).",abstractText,[0],[0]
"When f is a step function which corresponds to the stochastic block model with k blocks for some k, the error rate of USVT is at most k/(nρ), which is larger than the minimax optimal error rate by at most a multiplicative factor k/ log k.",abstractText,[0],[0]
This coincides with the computational gap observed in community detection.,abstractText,[0],[0]
"A key ingredient of our analysis is to derive the eigenvalue decaying rate of the edge probability matrix using piecewise polynomial The Fuqua School of Business, Duke University, Durham, NC, USA..",abstractText,[0],[0]
Correspondence to: J. Xu <jiaming.xu868@duke.edu>.,abstractText,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",abstractText,[0],[0]
Copyright 2018 by the author(s).,abstractText,[0],[0]
approximations of the graphon function f .,abstractText,[0],[0]
Rates of Convergence of Spectral Methods for Graphon Estimation,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 107–117, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
Many recent advances in NLP problems have come from formulating and training expressive and elaborate neural models.,1 Introduction,[0],[0]
"This includes models for sentiment classification, parsing, and machine translation among many others.",1 Introduction,[0],[0]
"The gains in accuracy have, however, come at the cost of interpretability since complex neural models offer little transparency concerning their inner workings.",1 Introduction,[0],[0]
"In many applications, such as medicine, predictions are used to drive critical decisions, including treatment options.",1 Introduction,[0],[0]
"It is necessary in such cases to be able to verify and under-
1Our code and data are available at https://github.",1 Introduction,[0],[0]
"com/taolei87/rcnn.
stand the underlying basis for the decisions.",1 Introduction,[0],[0]
"Ideally, complex neural models would not only yield improved performance but would also offer interpretable justifications – rationales – for their predictions.
",1 Introduction,[0],[0]
"In this paper, we propose a novel approach to incorporating rationale generation as an integral part of the overall learning problem.",1 Introduction,[0],[0]
We limit ourselves to extractive (as opposed to abstractive) rationales.,1 Introduction,[0],[0]
"From this perspective, our rationales are simply subsets of the words from the input text that satisfy two key properties.",1 Introduction,[0],[0]
"First, the selected words represent short and coherent pieces of text (e.g., phrases) and, second, the selected words must alone suffice for prediction as a substitute of the original text.",1 Introduction,[0],[0]
"More concretely, consider the task of multi-aspect sentiment analysis.",1 Introduction,[0],[0]
Figure 1 illustrates a product review along with user rating in terms of two categories or aspects.,1 Introduction,[0],[0]
"If the model in this case predicts five star rating for color, it should also identify the phrase ”a very pleasant ruby red-amber color” as the rationale underlying this decision.
",1 Introduction,[0],[0]
"In most practical applications, rationale genera-
107
tion must be learned entirely in an unsupervised manner.",1 Introduction,[0],[0]
"We therefore assume that our model with rationales is trained on the same data as the original neural models, without access to additional rationale annotations.",1 Introduction,[0],[0]
"In other words, target rationales are never provided during training; the intermediate step of rationale generation is guided only by the two desiderata discussed above.",1 Introduction,[0],[0]
Our model is composed of two modular components that we call the generator and the encoder.,1 Introduction,[0],[0]
Our generator specifies a distribution over possible rationales (extracted text) and the encoder maps any such text to task specific target values.,1 Introduction,[0],[0]
"They are trained jointly to minimize a cost function that favors short, concise rationales while enforcing that the rationales alone suffice for accurate prediction.
",1 Introduction,[0],[0]
The notion of what counts as a rationale may be ambiguous in some contexts and the task of selecting rationales may therefore be challenging to evaluate.,1 Introduction,[0],[0]
We focus on two domains where ambiguity is minimal (or can be minimized).,1 Introduction,[0],[0]
"The first scenario concerns with multi-aspect sentiment analysis exemplified by the beer review corpus (McAuley et al., 2012).",1 Introduction,[0],[0]
"A smaller test set in this corpus identifies, for each aspect, the sentence(s) that relate to this aspect.",1 Introduction,[0],[0]
"We can therefore directly evaluate our predictions on the sentence level with the caveat that our model makes selections on a finer level, in terms of words, not complete sentences.",1 Introduction,[0],[0]
The second scenario concerns with the problem of retrieving similar questions.,1 Introduction,[0],[0]
The extracted rationales should capture the main purpose of the questions.,1 Introduction,[0],[0]
We can therefore evaluate the quality of rationales as a compressed proxy for the full text in terms of retrieval performance.,1 Introduction,[0],[0]
Our model achieves high performance on both tasks.,1 Introduction,[0],[0]
"For instance, on the sentiment prediction task, our model achieves extraction accuracy of 96%, as compared to 38% and 81% obtained by the bigram SVM and a neural attention baseline.",1 Introduction,[0],[0]
"Developing sparse interpretable models is of considerable interest to the broader research community(Letham et al., 2015; Kim et al., 2015).",2 Related Work,[0],[0]
The need for interpretability is even more pronounced with recent neural models.,2 Related Work,[0],[0]
"Efforts in this area include analyzing and visualizing state activation (Hermans
and Schrauwen, 2013; Karpathy et al., 2015; Li et al., 2016), learning sparse interpretable word vectors (Faruqui et al., 2015b), and linking word vectors to semantic lexicons or word properties (Faruqui et al., 2015a; Herbelot and Vecchi, 2015).
",2 Related Work,[0],[0]
"Beyond learning to understand or further constrain the network to be directly interpretable, one can estimate interpretable proxies that approximate the network.",2 Related Work,[0],[0]
"Examples include extracting “if-then” rules (Thrun, 1995) and decision trees (Craven and Shavlik, 1996) from trained networks.",2 Related Work,[0],[0]
"More recently, Ribeiro et al. (2016) propose a modelagnostic framework where the proxy model is learned only for the target sample (and its neighborhood) thus ensuring locally valid approximations.",2 Related Work,[0],[0]
Our work differs from these both in terms of what is meant by an explanation and how they are derived.,2 Related Work,[0],[0]
"In our case, an explanation consists of a concise yet sufficient portion of the text where the mechanism of selection is learned jointly with the predictor.
",2 Related Work,[0],[0]
"Attention based models offer another means to explicate the inner workings of neural models (Bahdanau et al., 2015; Cheng et al., 2016; Martins and Astudillo, 2016; Chen et al., 2015; Xu and Saenko, 2015; Yang et al., 2015).",2 Related Work,[0],[0]
"Such models have been successfully applied to many NLP problems, improving both prediction accuracy as well as visualization and interpretability (Rush et al., 2015; Rocktäschel et al., 2016; Hermann et al., 2015).",2 Related Work,[0],[0]
Xu et al. (2015) introduced a stochastic attention mechanism together with a more standard soft attention on image captioning task.,2 Related Work,[0],[0]
Our rationale extraction can be understood as a type of stochastic attention although architectures and objectives differ.,2 Related Work,[0],[0]
"Moreover, we compartmentalize rationale generation from downstream encoding so as to expose knobs to directly control types of rationales that are acceptable, and to facilitate broader modular use in other applications.
",2 Related Work,[0],[0]
"Finally, we contrast our work with rationale-based classification (Zaidan et al., 2007; Marshall et al., 2015; Zhang et al., 2016) which seek to improve prediction by relying on richer annotations in the form of human-provided rationales.",2 Related Work,[0],[0]
"In our work, rationales are never given during training.",2 Related Work,[0],[0]
The goal is to learn to generate them.,2 Related Work,[0],[0]
We formalize here the task of extractive rationale generation and illustrate it in the context of neural models.,3 Extractive Rationale Generation,[0],[0]
"To this end, consider a typical NLP task where we are provided with a sequence of words as input, namely x = {x1, · · · , xl}, where each xt ∈ Rd denotes the vector representation of the ith word.",3 Extractive Rationale Generation,[0],[0]
The learning problem is to map the input sequence x to a target vector in Rm.,3 Extractive Rationale Generation,[0],[0]
"For example, in multi-aspect sentiment analysis each coordinate of the target vector represents the response or rating pertaining to the associated aspect.",3 Extractive Rationale Generation,[0],[0]
"In text retrieval, on the other hand, the target vectors are used to induce similarity assessments between input sequences.",3 Extractive Rationale Generation,[0],[0]
"Broadly speaking, we can solve the associated learning problem by estimating a complex parameterized mapping enc(x) from input sequences to target vectors.",3 Extractive Rationale Generation,[0],[0]
We call this mapping an encoder.,3 Extractive Rationale Generation,[0],[0]
"The training signal for these vectors is obtained either directly (e.g., multi-sentiment analysis) or via similarities (e.g., text retrieval).",3 Extractive Rationale Generation,[0],[0]
"The challenge is that a complex neural encoder enc(x) reveals little about its internal workings and thus offers little in the way of justification for why a particular prediction was made.
",3 Extractive Rationale Generation,[0],[0]
"In extractive rationale generation, our goal is to select a subset of the input sequence as a rationale.",3 Extractive Rationale Generation,[0],[0]
In order for the subset to qualify as a rationale it should satisfy two criteria: 1) the selected words should be interpretable and 2) they ought to suffice to reach nearly the same prediction (target vector) as the original input.,3 Extractive Rationale Generation,[0],[0]
"In other words, a rationale must be short and sufficient.",3 Extractive Rationale Generation,[0],[0]
"We will assume that a short selection is interpretable and focus on optimizing sufficiency under cardinality constraints.
",3 Extractive Rationale Generation,[0],[0]
We encapsulate the selection of words as a rationale generator which is another parameterized mapping gen(x) from input sequences to shorter sequences of words.,3 Extractive Rationale Generation,[0],[0]
Thus gen(x) must include only a few words and enc(gen(x)) should result in nearly the same target vector as the original input passed through the encoder or enc(x).,3 Extractive Rationale Generation,[0],[0]
We can think of the generator as a tagging model where each word in the input receives a binary tag pertaining to whether it is selected to be included in the rationale.,3 Extractive Rationale Generation,[0],[0]
"In our case, the generator is probabilistic and specifies a distribution over possible selections.
",3 Extractive Rationale Generation,[0],[0]
The rationale generation task is entirely unsupervised in the sense that we assume no explicit annotations about which words should be included in the rationale.,3 Extractive Rationale Generation,[0],[0]
"Put another way, the rationale is introduced as a latent variable, a constraint that guides how to interpret the input sequence.",3 Extractive Rationale Generation,[0],[0]
"The encoder and generator are trained jointly, in an end-to-end fashion so as to function well together.",3 Extractive Rationale Generation,[0],[0]
We use multi-aspect sentiment prediction as a guiding example to instantiate the two key components – the encoder and the generator.,4 Encoder and Generator,[0],[0]
"The framework itself generalizes to other tasks.
",4 Encoder and Generator,[0],[0]
"Encoder enc(·): Given a training instance (x,y) where x = {xt}lt=1 is the input text sequence of length l and y ∈",4 Encoder and Generator,[0],[0]
"[0, 1]m is the target m-dimensional sentiment vector, the neural encoder predicts ỹ = enc(x).",4 Encoder and Generator,[0],[0]
"If trained on its own, the encoder would aim to minimize the discrepancy between the predicted sentiment vector ỹ and the gold target vector y. We will use the squared error (i.e. L2 distance) as the sentiment loss function,
L(x,y) = ‖ỹ",4 Encoder and Generator,[0],[0]
− y‖22 = ‖enc(x)− y‖22 The encoder could be realized in many ways such as a recurrent neural network.,4 Encoder and Generator,[0],[0]
"For example, let ht = fe(xt,ht−1) denote a parameterized recurrent unit mapping input word xt and previous state ht−1 to next state ht.",4 Encoder and Generator,[0],[0]
The target vector is then generated on the basis of the final state reached by the recurrent unit after processing all the words in the input sequence.,4 Encoder and Generator,[0],[0]
"Specifically,
ht = fe(xt,ht−1), t = 1, . . .",4 Encoder and Generator,[0],[0]
", l
ỹ = σe(W ehl + b e)
Generator gen(·): The rationale generator extracts a subset of text from the original input x to function as an interpretable summary.",4 Encoder and Generator,[0],[0]
"Thus the rationale for a given sequence x can be equivalently defined in terms of binary variables {z1, · · · , zl} where each zt ∈ 0, 1 indicates whether word xt is selected or not.",4 Encoder and Generator,[0],[0]
"From here on, we will use z to specify the binary selections and thus (z,x) is the actual rationale generated (selections, input).",4 Encoder and Generator,[0],[0]
"We will use generator gen(x) as synonymous with a
probability distribution over binary selections, i.e., z ∼ gen(x) ≡ p(z|x) where the length of z varies with the input x.
In a simple generator, the probability that the tth word is selected can be assumed to be conditionally independent from other selections given the input x. That is, the joint probability p(z|x) factors according to
p(z|x) = l∏
t=1
p(zt|x) (independent selection)
",4 Encoder and Generator,[0],[0]
The component distributions p(zt|x) can be modeled using a shared bi-directional recurrent neural network.,4 Encoder and Generator,[0],[0]
"Specifically, let −→ f () and ←− f () be the forward and backward recurrent unit, respectively, then
−→ ht = −→ f (xt, −−→ ht−1) ←−",4 Encoder and Generator,[0],[0]
"ht = ←− f (xt, ←−− ht+1)
p(zt|x) = σz(Wz",4 Encoder and Generator,[0],[0]
"[ −→ ht; ←− ht] + b z)
",4 Encoder and Generator,[0],[0]
Independent but context dependent selection of words is often sufficient.,4 Encoder and Generator,[0],[0]
"However, the model is unable to select phrases or refrain from selecting the same word again if already chosen.",4 Encoder and Generator,[0],[0]
"To this end, we also introduce a dependent selection of words,
p(z|x) = l∏
t=1
p(zt|x, z1 · · · zt−1)
which can be also expressed as a recurrent neural network.",4 Encoder and Generator,[0],[0]
"To this end, we introduce another hidden state st whose role is to couple the selections.",4 Encoder and Generator,[0],[0]
"For example,
p(zt|x, z1,t−1) = σz(Wz",4 Encoder and Generator,[0],[0]
"[ −→ ht; ←− ht; st−1] + bz)
st = fz([ −→ ht; ←− ht; zt], st−1)
Joint objective: A rationale in our definition corresponds to the selected words, i.e., {xk|zk = 1}.",4 Encoder and Generator,[0],[0]
"We will use (z,x) as the shorthand for this rationale and, thus, enc(z,x) refers to the target vector obtained by applying the encoder to the rationale as the input.",4 Encoder and Generator,[0],[0]
Our goal here is to formalize how the rationale can be made short and meaningful yet function well in conjunction with the encoder.,4 Encoder and Generator,[0],[0]
"Our generator and encoder are learned jointly to interact well but they are treated as independent units for modularity.
",4 Encoder and Generator,[0],[0]
The generator is guided in two ways during learning.,4 Encoder and Generator,[0],[0]
"First, the rationale that it produces must suffice as a replacement for the input text.",4 Encoder and Generator,[0],[0]
"In other words, the target vector (sentiment) arising from the rationale should be close to the gold sentiment.",4 Encoder and Generator,[0],[0]
"The corresponding loss function is given by
L(z,x,y) = ‖enc(z,x)− y‖22 Note that the loss function depends directly (parametrically) on the encoder but only indirectly on the generator via the sampled selection.
",4 Encoder and Generator,[0],[0]
"Second, we must guide the generator to realize short and coherent rationales.",4 Encoder and Generator,[0],[0]
"It should select only a few words and those selections should form phrases (consecutive words) rather than represent isolated, disconnected words.",4 Encoder and Generator,[0],[0]
"We therefore introduce an additional regularizer over the selections
Ω(z) = λ1‖z‖+ λ2 ∑
t
|zt",4 Encoder and Generator,[0],[0]
"− zt−1|
where the first term penalizes the number of selections while the second one discourages transitions (encourages continuity of selections).",4 Encoder and Generator,[0],[0]
Note that this regularizer also depends on the generator only indirectly via the selected rationale.,4 Encoder and Generator,[0],[0]
"This is because it is easier to assess the rationale once produced rather than directly guide how it is obtained.
",4 Encoder and Generator,[0],[0]
"Our final cost function is the combination of the two, cost(z,x,y) = L(z,x,y) + Ω(z).",4 Encoder and Generator,[0],[0]
"Since the selections are not provided during training, we minimize the expected cost:
min θe,θg
∑
(x,y)∈D Ez∼gen(x)",4 Encoder and Generator,[0],[0]
"[cost(z,x,y)]
where θe and θg denote the set of parameters of the encoder and generator, respectively, and D is the collection of training instances.",4 Encoder and Generator,[0],[0]
"Our joint objective encourages the generator to compress the input text into coherent summaries that work well with the associated encoder it is trained with.
",4 Encoder and Generator,[0],[0]
Minimizing the expected cost is challenging since it involves summing over all the possible choices of rationales,4 Encoder and Generator,[0],[0]
z.,4 Encoder and Generator,[0],[0]
This summation could potentially be made feasible with additional restrictive assumptions about the generator and encoder.,4 Encoder and Generator,[0],[0]
"However, we assume only that it is possible to efficiently sample from the generator.
",4 Encoder and Generator,[0],[0]
Doubly stochastic gradient We now derive a sampled approximation to the gradient of the expected cost objective.,4 Encoder and Generator,[0],[0]
This sampled approximation is obtained separately for each input text x so as to work well with an overall stochastic gradient method.,4 Encoder and Generator,[0],[0]
"Consider therefore a training pair (x,y).",4 Encoder and Generator,[0],[0]
"For the parameters of the generator θg,
∂Ez∼gen(x)",4 Encoder and Generator,[0],[0]
"[cost(z,x,y)]",4 Encoder and Generator,[0],[0]
"∂θg
= ∑
z
cost(z,x,y) · ∂p(z|x) ∂θg
= ∑
z
cost(z,x,y) · ∂p(z|x) ∂θg · p(z|x) p(z|x)
",4 Encoder and Generator,[0],[0]
"Using the fact (log f(θ))′ = f ′(θ)/f(θ), we get
∑
z
cost(z,x,y) · ∂p(z|x) ∂θg · p(z|x) p(z|x)
= ∑
z
cost(z,x,y) · ∂ log p(z|x) ∂θg · p(z|x)
",4 Encoder and Generator,[0],[0]
"= Ez∼gen(x) [ cost(z,x,y) ∂ log p(z|x)
∂θg
]
The last term is the expected gradient where the expectation is taken with respect to the generator distribution over rationales",4 Encoder and Generator,[0],[0]
"z. Therefore, we can simply sample a few rationales z from the generator gen(x) and use the resulting average gradient in an overall stochastic gradient method.",4 Encoder and Generator,[0],[0]
"A sampled approximation to the gradient with respect to the encoder parameters θe can be derived similarly,
∂Ez∼gen(x)",4 Encoder and Generator,[0],[0]
"[cost(z,x,y)] ∂θe
= ∑
z
∂cost(z,x,y) ∂θe · p(z|x)
= Ez∼gen(x)",4 Encoder and Generator,[0],[0]
"[ ∂cost(z,x,y)
∂θe
]
Choice of recurrent unit We employ recurrent convolution (RCNN), a refinement of local-ngram based convolution.",4 Encoder and Generator,[0],[0]
"RCNN attempts to learn n-gram features that are not necessarily consecutive, and average features in a dynamic (recurrent) fashion.",4 Encoder and Generator,[0],[0]
"Specifically, for bigrams (filter width n = 2) RCNN computes ht = f(xt,ht−1) as follows
λt = σ(W λxt +",4 Encoder and Generator,[0],[0]
"U λht−1 + b λ)
c (1) t = λt c(1)t−1 + (1− λt) (W1xt) c (2) t =",4 Encoder and Generator,[0],[0]
λt c(2)t−1,4 Encoder and Generator,[0],[0]
"+ (1− λt) (c (1) t−1 + W2xt)
ht = tanh(c (2) t + b)
RCNN has been shown to work remarkably in classification and retrieval applications (Lei et al., 2015; Lei et al., 2016) compared to other alternatives such CNNs and LSTMs.",4 Encoder and Generator,[0],[0]
We use it for all the recurrent units introduced in our model.,4 Encoder and Generator,[0],[0]
We evaluate the proposed joint model on two NLP applications: (1) multi-aspect sentiment analysis on product reviews and (2) similar text retrieval on AskUbuntu question answering forum.,5 Experiments,[0],[0]
"Dataset We use the BeerAdvocate2 review dataset used in prior work (McAuley et al., 2012).3 This dataset contains 1.5 million reviews written by the website users.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"The reviews are naturally multiaspect – each of them contains multiple sentences describing the overall impression or one particular aspect of a beer, including appearance, smell (aroma), palate and the taste.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"In addition to the written text, the reviewer provides the ratings (on a scale of 0 to 5 stars) for each aspect as well as an overall rating.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"The ratings can be fractional (e.g. 3.5 stars), so we normalize the scores to [0, 1] and use them as the (only) supervision for regression.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"McAuley et al. (2012) also provided sentencelevel annotations on around 1,000 reviews.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"Each sentence is annotated with one (or multiple) aspect label, indicating what aspect this sentence covers.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"2www.beeradvocate.com 3http://snap.stanford.edu/data/
web-BeerAdvocate.html
We use this set as our test set to evaluate the precision of words in the extracted rationales.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
Table 1 shows several statistics of the beer review dataset.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"The sentiment correlation between any pair of aspects (and the overall score) is quite high, getting 63.5% on average and a maximum of 79.1% (between the taste and overall score).",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"If directly training the model on this set, the model can be confused due to such strong correlation.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"We therefore perform a preprocessing step, picking “less correlated” examples from the dataset.4 This gives us a de-correlated subset for each aspect, each containing about 80k to 90k reviews.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
We use 10k as the development set.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"We focus on three aspects since the fourth aspect taste still gets > 50% correlation with the overall sentiment.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"Sentiment Prediction Before training the joint model, it is worth assessing the neural encoder separately to check how accurately the neural network predicts the sentiment.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"To this end, we compare neural encoders with bigram SVM model, training medium and large SVM models using 260k and all
4Specifically, for each aspect we train a simple linear regression model to predict the rating of this aspect given the ratings of the other four aspects.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"We then keep picking reviews with largest prediction error until the sentiment correlation in the selected subset increases dramatically.
1580k reviews respectively.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"As shown in Table 3, the recurrent neural network models outperform the SVM model for sentiment prediction and also require less training data to achieve the performance.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"The LSTM and RCNN units obtain similar test error, getting 0.0094 and 0.0087 mean squared error respectively.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
The RCNN unit performs slightly better and uses less parameters.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"Based on the results, we choose the RCNN encoder network with 2 stacking layers and 200 hidden states.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"To train the joint model, we also use RCNN unit with 200 states as the forward and backward recurrent unit for the generator gen().",5.1 Multi-aspect Sentiment Analysis,[0],[0]
The dependent generator has one additional recurrent layer.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
For this layer we use 30 states so the dependent version still has a number of parameters comparable to the independent version.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"The two versions of the generator have 358k and 323k parameters respectively.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
Figure 2 shows the performance of our joint dependent model when trained to predict the sentiment of all aspects.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
We vary the regularization λ1 and λ2 to show various runs that extract different amount of text as rationales.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"Our joint model gets performance close to the best encoder run (with full text) when few words are extracted.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"a beer that is not sold in my neck of the woods , but managed to get while on a roadtrip .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
poured into an imperial pint glass with a generous head that sustained life throughout .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"nothing out of the ordinary here , but a good brew s9ll .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"body was kind of heavy , but not thick .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
the hop smell was excellent and en9cing .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"very drinkable
very dark beer .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
pours a nice finger and a half of creamy foam and stays throughout the beer .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
smells of coffee and roasted malt .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
has a major coffee-like taste with hints of chocolate .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"if you like black coffee , you will love this porter .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
creamy smooth mouthfeel,5.1 Multi-aspect Sentiment Analysis,[0],[0]
and definitely gets smoother on the palate once it warms .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
it 's an ok porter,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"but i feel there are much beAer one 's out there .
poured into a sniBer .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
produces a small coffee head that reduces quickly .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
black as night .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
preAy,5.1 Multi-aspect Sentiment Analysis,[0],[0]
typical imp .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
roasted malts hit on the nose .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
a liAle sweet chocolate follows .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
big toasty character on the taste .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
in between i 'm geDng plenty of dark chocolate and some biAer espresso .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
it finishes with hop biAerness .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
nice smooth mouthfeel with perfect carbona9on for the style .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"overall a nice stout i would love to have again , maybe with some age on it .
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
i really did not like this .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
it just seemed extremely watery .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
i dont ' think this had any carbona9on whatsoever .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"maybe it was flat , who knows ?",5.1 Multi-aspect Sentiment Analysis,[0],[0]
but even if i got a bad brew i do n't see how this would possibly be something i 'd get 9me and 9me again .,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"i could taste the hops towards the middle , but the beer got preAy nasty towards the boAom .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"i would never drink this again , unless it was free .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"i 'm kind of upset i bought this .
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"a : poured a nice dark brown with a tan colored head about half an inch thick , nice red/garnet accents when held to the light .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"liAle clumps of lacing all around the glass , not too shabby .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"not terribly impressive though s : smells like a more guinness-y guinness really , there are some roasted malts there , signature guinness smells , less burnt though , a liAle bit of chocolate … …",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"m : rela9vely thick , it is n't an export stout or imperial stout , but s9ll is preAy heBy in the mouth , very smooth , not much carbona9on .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"not too shabby d : not quite as drinkable as the draught , but s9ll not too bad .",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"i could easily see drinking a few of these .
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
Figure 3:,5.1 Multi-aspect Sentiment Analysis,[0],[0]
Examples of extracted rationales indicating the sentiments of various aspects.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"The extracted texts for appearance, smell and palate are shown in red, blue and green color respectively.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"The last example is shortened for space.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"SVM Attention Gen (independent) Gen (recurrent)
1 73.9 1 89.1 6 97.4 12 96.5 3 55.9 3 88.1 13 94.9 14 96.3 5 48.5 5 86.4 16 92.9 16 91.2 7 44.7 7 84.1
9 42.2 9 82.3 11 41.2 11 79.8 13 38.3 13 77.1 15 36.7 15 74.4 17 35.1 17 71.6
30
48
65
83
100
5 7 9 11 13 15 17
SVM Attention Gen (independent) Gen (recurrent)
Figure 4: Precision (y-axis) when various percentages of text are extracted as rationales (x-axis) for the appearance aspect.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"Rationale Selection To evaluate the supporting rationales for each aspect, we train the joint encodergenerator model on each de-correlated subset.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"We set the cardinality regularization λ1 between values {2e − 4, 3e",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"− 4, 4e",5.1 Multi-aspect Sentiment Analysis,[0],[0]
− 4} so the extracted rationale texts are neither too long nor too short.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"For simplicity, we set λ2 = 2λ1 to encourage local coherency of the extraction.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
For comparison we use the bigram SVM model and implement an attention-based neural network model.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
The SVM model successively extracts unigram or bigram (from the test reviews) with the highest feature.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"The attention-based model learns a normalized attention vector of the input tokens (using similarly the forward and backward RNNs), then the model averages over the encoder states accordingly to the attention, and feed the averaged vector to the output layer.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"Similar to the SVM model, the attention-based model can selects words based on their attention weights.
0",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"50 100
0.03
0.04
0.05
0.06
Gen (recurrent) Gen (independent)
0.2
0.4
0.6
0.8
1.0
Figure 5:",5.1 Multi-aspect Sentiment Analysis,[0],[0]
Learning curves of the optimized cost function on the development set and the precision of rationales on the test set.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"The smell (aroma) aspect is the target aspect.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
Table 2 presents the precision of the extracted rationales calculated based on sentence-level aspect annotations.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
The λ1 regularization hyper-parameter is tuned so the two versions of our model extract similar number of words as rationales.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
The SVM and attention-based model are constrained similarly for comparison.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
Figure 4 further shows the precision when different amounts of text are extracted.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"Again, for our model this corresponds to changing the λ1 regularization.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"As shown in the table and the figure, our encoder-generator networks extract text pieces describing the target aspect with high precision, ranging from 80% to 96% across the three aspects appearance, smell and palate.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"The SVM baseline performs poorly, achieving around 30% accuracy.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"The attention-based model achieves reasonable but worse performance than the rationale generator, suggesting the potential of directly modeling rationales as explicit extraction.
113
Figure 5 shows the learning curves of our model for the smell aspect.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"In the early training epochs, both the independent and (recurrent) dependent selection models fail to produce good rationales, getting low precision as a result.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"After a few epochs of exploration however, the models start to achieve high accuracy.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
"We observe that the dependent version learns more quickly in general, but both versions obtain close results in the end.
",5.1 Multi-aspect Sentiment Analysis,[0],[0]
Finally we conduct a qualitative case study on the extracted rationales.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"Figure 3 presents several reviews, with highlighted rationales predicted by the model.",5.1 Multi-aspect Sentiment Analysis,[0],[0]
Our rationale generator identifies key phrases or adjectives that indicate the sentiment of a particular aspect.,5.1 Multi-aspect Sentiment Analysis,[0],[0]
"Dataset For our second application, we use the real-world AskUbuntu5 dataset used in recent work (dos Santos et al., 2015; Lei et al., 2016).",5.2 Similar Text Retrieval on QA Forum,[0],[0]
This set contains a set of 167k unique questions (each consisting a question title and a body) and 16k useridentified similar question pairs.,5.2 Similar Text Retrieval on QA Forum,[0],[0]
"Following previous work, this data is used to train the neural encoder that learns the vector representation of the input question, optimizing the cosine distance (i.e. cosine similarity) between similar questions against random non-similar ones.",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"We use the “one-versusall” hinge loss (i.e. positive versus other negatives) for the encoder, similar to (Lei et al., 2016).",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"During development and testing, the model is used to score 20 candidate questions given each query question, and a total of 400×20 query-candidate question pairs are annotated for evaluation6.
Task/Evaluation Setup The question descriptions are often long and fraught with irrelevant details.",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"In this set-up, a fraction of the original question text should be sufficient to represent its content, and be used for retrieving similar questions.",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"Therefore, we will evaluate rationales based on the accuracy of the question retrieval task, assuming that better rationales achieve higher performance.",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"To put this performance in context, we also report the accuracy when full body of a question is used, as well as titles alone.",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"The latter constitutes an upper bound on
5askubuntu.com 6https://github.com/taolei87/askubuntu
Gen (independent) Gen (recurrent)
0.052 47.08 0.063 50.54 0.058 52.36 0.067 49.48 0.059 46.02 0.07 51.96 0.062 49.76 0.078 51.54 0.064 47.94 0.086 52.55 0.068 48.93 0.095 53.59
0.07 49.5 0.108 53.15 0.081 52.18 0.112 51.48 0.081 51.84 0.116 54.62 0.094 51.24 0.121 52.12 0.094 52.21 0.137 53 0.097 53.61 0.163 53.2 0.098 54.11 0.179 54.13 0.122 49.03 0.193 52.11 0.133 54.19 0.262 52.32 0.135 50.21 0.277 50.87 0.136 48.22 0.328 53.21 0.145 50.96 0.328 55.61 0.155 52.91 0.347 51 0.173 52.74 0.378 54.93 0.197 52.6
the model performance as in this dataset titles provide short, informative summaries of the question content.",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"We evaluate the rationales using the mean average precision (MAP) of retrieval.
",5.2 Similar Text Retrieval on QA Forum,[0],[0]
Results Table 4 presents the results of our rationale model.,5.2 Similar Text Retrieval on QA Forum,[0],[0]
We explore a range of hyper-parameter values7.,5.2 Similar Text Retrieval on QA Forum,[0],[0]
We include two runs for each version.,5.2 Similar Text Retrieval on QA Forum,[0],[0]
"The first one achieves the highest MAP on the development set, The second run is selected to compare the models when they use roughly 10% of question text (7 words on average).",5.2 Similar Text Retrieval on QA Forum,[0],[0]
We also show the results of different runs in Figure 6.,5.2 Similar Text Retrieval on QA Forum,[0],[0]
"The rationales achieve the MAP up to 56.5%, getting close to using the titles.",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"The models also outperform the baseline of using the noisy question bodies, indicating the the models’ capacity of extracting short but important fragments.
",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"Figure 7 shows the rationales for several questions in the AskUbuntu domain, using the recurrent version with around 10% extraction.",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"Interestingly, the model does not always select words from the question title.",5.2 Similar Text Retrieval on QA Forum,[0],[0]
The reasons are that the question body can contain the same or even complementary information useful for retrieval.,5.2 Similar Text Retrieval on QA Forum,[0],[0]
"Indeed, some rationale fragments shown in the figure are error messages,
7λ1 ∈ {.008, .01, .012, .015}, λ2 = {0, λ1, 2λ1}, dropout ∈ {0.1, 0.2}
114
i accidentally removed the ubuntu soBware centre , when i was actually trying to remove my ubuntu one applica9ons .",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"although i do n't remember directly uninstalling the centre , i think dele9ng one of those packages might have triggered it .",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"i can not look at history of applica9on changes , as the soBware centre is missing .",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"please advise on how to install , or rather reinstall , ubuntu soBware centre on my computer .",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"how do i install ubuntu soBware centre applica9on ?
",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"i know this will be an odd ques9on , but i was wondering if anyone knew how to install the ubuntu installer package in an ubuntu installa9on .",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"to clarify , when you boot up to an ubuntu livecd , it 's got the installer program available so that you can install ubuntu to a drive .",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"naturally , this program is not present in the installed ubuntu .",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"is there , though , a way to download and install it like other packages ?",5.2 Similar Text Retrieval on QA Forum,[0],[0]
"invariably , someone will ask what i 'm trying to do , and the answer … install installer package on an installed system ?
which are typically not in the titles but very useful to identify similar questions.",5.2 Similar Text Retrieval on QA Forum,[0],[0]
We proposed a novel modular neural framework to automatically generate concise yet sufficient text fragments to justify predictions made by neural networks.,6 Discussion,[0],[0]
"We demonstrated that our encoder-generator framework, trained in an end-to-end manner, gives rise to quality rationales in the absence of any explicit rationale annotations.",6 Discussion,[0],[0]
"The approach could be modified or ext nded in various ways to other applications or types of data.
",6 Discussion,[0],[0]
Choices of enc(·) and gen(·).,6 Discussion,[0],[0]
The encoder and generator can be realized in numerous ways without changing the broader algorithm.,6 Discussion,[0],[0]
"For instance, we could use a convolutional network (Kim, 2014; Kalchbrenner et al., 2014), deep averaging network (Iyyer et al., 2015; Joulin et al., 2016) or a boosting classifier as the encoder.",6 Discussion,[0],[0]
"When rationales can be expected to conform to repeated stereotypical patterns in the text, a simpler encoder consistent with this bias can work better.",6 Discussion,[0],[0]
"We emphasize that, in this paper, rationales are flexible explanations that may vary substantially from instance to another.",6 Discussion,[0],[0]
"On the generator side, many additional constraints could be imposed to further guide acceptable rationales.
",6 Discussion,[0],[0]
Dealing with Search Space.,6 Discussion,[0],[0]
"Our training method employs a REINFORCE-style algorithm (Williams, 1992) where the gradient with respect to the parameters is estimated by sampling possible rationales.
",6 Discussion,[0],[0]
Additional constraints on the generator output can be helpful in alleviating problems of exploring potentially a large space of possible rationales in terms of their interaction with the encoder.,6 Discussion,[0],[0]
We could also apply variance reduction techniques to increase stability of stochastic training (cf.,6 Discussion,[0],[0]
"(Weaver and Tao, 2001; Mni et al., 2014; Ba et al., 2015; Xu et al., 2015)).",6 Discussion,[0],[0]
We thank Prof. Julian McAuley for sharing the review dat s t and annotations.,7 Acknowledgments,[0],[0]
We also th nk MIT NLP group and the reviewers for their helpful comments.,7 Acknowledgments,[0],[0]
The work is supported by the Arabic Language Technologies (ALT) group at Qatar Computing Research Institute (QCRI) within the IYAS project.,7 Acknowledgments,[0],[0]
"Any opinions, findings, conclusions, or recommendations expressed in this paper are those of the authors, and do not necessarily reflect the views of the funding organizations.",7 Acknowledgments,[0],[0]
Prediction without justification has limited applicability.,abstractText,[0],[0]
"As a remedy, we learn to extract pieces of input text as justifications – rationales – that are tailored to be short and coherent, yet sufficient for making the same prediction.",abstractText,[0],[0]
"Our approach combines two modular components, generator and encoder, which are trained to operate well together.",abstractText,[0],[0]
The generator specifies a distribution over text fragments as candidate rationales and these are passed through the encoder for prediction.,abstractText,[0],[0]
Rationales are never given during training.,abstractText,[0],[0]
"Instead, the model is regularized by desiderata for rationales.",abstractText,[0],[0]
We evaluate the approach on multi-aspect sentiment analysis against manually annotated test cases.,abstractText,[0],[0]
Our approach outperforms attention-based baseline by a significant margin.,abstractText,[0],[0]
We also successfully illustrate the method on the question retrieval task.1,abstractText,[0],[0]
Rationalizing Neural Predictions,title,[0],[0]
"Given a dataset, similarity relationship between examples can be represented by a graph in which each example is represented by a vertex.",1. Introduction,[0],[0]
"While pairwise relationship between two vertices can be represented by an edge in a normal graph, a higher order relationship involving multiple vertices can be captured by a hyperedge, which means that all the corresponding examples are similar to one another.",1. Introduction,[0],[0]
"Hypergraphs have been used in several learning applications such as clustering of categorical data (Gibson et al., 1998), multi-label classification (Sun et al., 2008), Laplacian sparse coding (Gao et al., 2013), image classification (Yu et al., 2012), image retrieval (Huang et al., 2010), mapping users across different social networks (Tan et al., 2014) and predicting edge labels in hypernode graphs (Ricatte et al., 2014).
",1. Introduction,[0],[0]
"*Equal contribution 1University of Hong Kong, Hong Kong.",1. Introduction,[0],[0]
2This research was partially supported by the Hong Kong RGC under the grant 17200214.,1. Introduction,[0],[0]
"Correspondence to: T-H. Hubert Chan <hubert@cs.hku.hk>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"In this paper, we consider semi-supervised learning on an edge-weighted hypergraph H = (V,E,w), with a set L of labeled vertices, whose labels are given by f∗L ∈ {−1,+1}L. The task is to predict the labels of the unlabeled vertices N , with the working principle that vertices contained in a hyperedge e ∈ E are more similar to one another if the edge weight we is larger.",1. Introduction,[0],[0]
"This problem is also known as transductive inference and has been studied in (Zhou et al., 2006) and (Hein et al., 2013).
",1. Introduction,[0],[0]
"However, the methods in (Zhou et al., 2006) have been criticized by (Agarwal et al., 2006), because essentially a hypergraph is converted into a normal graph.",1. Introduction,[0],[0]
"For instance, given a hyperedge e containing vertices S, either (i) a clique is added between the vertices in S, or (ii) a star is formed by adding a new vertex ve connecting every vertex in S to ve.",1. Introduction,[0],[0]
"Then, a standard convex program using a regularization potential function for normal graphs can be applied (Zhu et al., 2003).",1. Introduction,[0],[0]
"By choosing appropriate edge weights, it was shown in (Agarwal et al., 2006) that the two approaches are equivalent to the following convex program relaxation:
min Φold(f) := 1
2 ∑ e∈E we ∑
{u,v}∈(e2)
(fu − fv)2
subject to fu ∈",1. Introduction,[0],[0]
"[−1, 1], ∀u ∈ V fu = f ∗ u , ∀u ∈",1. Introduction,[0],[0]
"L.
On the other hand, it was proposed in (Hein et al., 2013) that the following regularization function is more suitable to capture hyperedge expansion:
Φnew(f) := 1
2 ∑ e∈E we · (max u∈e fu −min v∈e fv) 2.
",1. Introduction,[0],[0]
"Indeed, it was shown in (Hein et al., 2013) that their approach outperforms (Zhou et al., 2006) on several datasets from the UCI Machine Learning Repository (Lichman, 2013).
",1. Introduction,[0],[0]
Loss Function.,1. Introduction,[0],[0]
"In (Hein et al., 2013), a squared loss function was added by considering the convex program with objective function Φnew(f) + µ ‖f − f∗‖22 on f ∈",1. Introduction,[0],[0]
"[−1, 1]V , where µ > 0 is a parameter to be tuned, f∗L is given by the labeled vertices L, and for the unlabeled vertices f∗N = 0.
",1. Introduction,[0],[0]
"The loss function allows errors in the labeled vertices, and also ensures that the minimizer is unique.",1. Introduction,[0],[0]
"However, as a result, unlabeled vertices have a tendency to acquire f values close to 0.",1. Introduction,[0],[0]
"This might remove useful information as illustrated in the following example.
",1. Introduction,[0],[0]
Example.,1. Introduction,[0],[0]
"In Figure 1.1, vertices a, b ∈ L are labeled as +1 and c ∈ L is labeled as −1.",1. Introduction,[0],[0]
"Vertices x, y ∈ N are unlabeled.",1. Introduction,[0],[0]
"There are three (undirected) edges: {a, x}, {b, x} and {x, y, c}, each with unit weight.
",1. Introduction,[0],[0]
"By choosing µ = 12 for squared loss function, the unique minimizer gives fx = 15 and fy = 0.",1. Introduction,[0],[0]
"Hence, this solution gives no useful information regarding the label for vertex y.
On the other hand, if we just use the objective function Φnew(f) with the constraints fL = f∗L, then in an optimal solution, fx = 13 , but fy could be anywhere in the confidence interval",1. Introduction,[0],[0]
"[−1, 13 ].",1. Introduction,[0],[0]
"Hence, in this case, we could use the average value − 13 to predict −1 for vertex y.
Our Contributions.",1. Introduction,[0],[0]
"In this paper, we revisit the approach used in (Hein et al., 2013) and consider several extensions and simplifications.",1. Introduction,[0],[0]
"We summarize our results and give an outline of the paper as follows.
1.",1. Introduction,[0],[0]
Unified Framework for Directed Hypergraphs.,1. Introduction,[0],[0]
"Inspired also from the recent result on Laplacians for directed normal graphs (Yoshida, 2016), we introduce a semisupervised learning framework using directed hypergraphs that can capture higher order causal relationships.",1. Introduction,[0],[0]
"This notion of directed hypergraph was first introduced in (Gallo et al., 1993), who considered applications in propositional logic, analyzing dependency in relational database, and traffic analysis.",1. Introduction,[0],[0]
"On a high level, a directed hyperedge e consists of a tail set Te pointing to a head set He such that a vertex in Te labeled +1 implies that a vertex in He is more likely to be labeled +1.",1. Introduction,[0],[0]
"(Equivalently in terms of its contrapositive, a vertex in He labeled −1 implies that a vertex in Te is more likely to be labeled −1.)",1. Introduction,[0],[0]
"In Section 2, we formally define the model and the corresponding potential function Φ. An additional advantage of our potential function is that there is no need to tune any parameters.
2.",1. Introduction,[0],[0]
Confidence Interval for Unlabeled Vertices.,1. Introduction,[0],[0]
Observe that the minimizer for our convex program might not be unique.,1. Introduction,[0],[0]
"In Section 3, we introduce the concept of confidence interval for each unlabeled vertex that can be useful for predicting its label.",1. Introduction,[0],[0]
"Furthermore, we provide an algorithm to calculate the confidence interval given an optimal solution.
3.",1. Introduction,[0],[0]
Simpler Subgradient Method.,1. Introduction,[0],[0]
"Since the new potential function is not everywhere differentiable but still convex, we use the subgradient method (Shor et al., 1985) to obtain an estimated minimizer for label prediction.",1. Introduction,[0],[0]
"Inspired by the diffusion processes used for defining Laplacians in hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), in Section 4, we define a simple Markov operator that returns a subgradient for Φ, which is used to solve the underlying convex program.",1. Introduction,[0],[0]
"We remark that our framework is very easy to understand, because it is a variation on the well-known gradient descent.
",1. Introduction,[0],[0]
"In contrast, the primal-dual approach in (Hein et al., 2013) considers the convex conjugate of the primal objective and involves complicated update operations on the primal and dual variables.",1. Introduction,[0],[0]
"The subgradient used in our approach gives the update direction, and we can actually solve exactly the same convex program with a much simpler method.",1. Introduction,[0],[0]
"Section 5, we revisit some datasets in the UCI Machine Learning Repository (Lichman, 2013), and experiments confirm that our prediction model based on confidence interval gives better accuracy than that in (Hein et al., 2013).",4. Experimental Results on Real-World Datasets. In,[0],[0]
"Our simpler subgradient method takes more iterations than the primal-dual method (Hein et al., 2013), but each iteration is much faster.",4. Experimental Results on Real-World Datasets. In,[0],[0]
"Experiments show that overall both methods have similar running times, and the subgradient method has an advantage when the number of vertices is much larger than the number of edges.
",4. Experimental Results on Real-World Datasets. In,[0],[0]
"Moreover, using the DBLP dataset (Ley, 2009), our experiments also support that using directed hypergraphs to capture causal relationships can improve the prediction accuracy.",4. Experimental Results on Real-World Datasets. In,[0],[0]
The experiments for directed hypergraphs are described in the full version.,4. Experimental Results on Real-World Datasets. In,[0],[0]
"We consider an edge-weighted directed hypergraph H = (V,E,w) with vertex set V (with n = |V |), edge set E and weight function",2. Preliminaries,[0],[0]
w : E → R+.,2. Preliminaries,[0],[0]
Each hyperedge e ∈ E consists of a tail set Te ⊆ V and a head set He ⊆ V (which are not necessarily disjoint); we use the convention that the direction is from tail to head.,2. Preliminaries,[0],[0]
"For x ∈ R, we denote [x]+ := max{x, 0}.
",2. Preliminaries,[0],[0]
"In our application, each vertex v ∈ V is supposed to have a label in {−1,+1}.",2. Preliminaries,[0],[0]
"Intuitively, the directed hypergraph attempts to capture the rule that for each edge e ∈ E, if there is a vertex in Te having label +1, then it is more likely for vertices in He to receive label +1.",2. Preliminaries,[0],[0]
"In terms of its contrapositive, if there is a vertex in He having label −1, then it is more likely for vertices in Te to receive label −1.
",2. Preliminaries,[0],[0]
"We use f ∈ RV to denote a vector, where the coordi-
nates are labeled by vertices in V .",2. Preliminaries,[0],[0]
"For U ⊆ V , we use fU ∈ RU to denote the vector restricting f to coordinates inU .",2. Preliminaries,[0],[0]
"In semi-supervised learning, we consider a setL ⊆ V of labeled vertices, which have labels f∗L ∈",2. Preliminaries,[0],[0]
"{−1,+1}L. Typically, |L| |V | and the task is to assign a label in {−1,+1} to each unlabeled vertex in N := V \ L, using information from the directed hypergraph H .
",2. Preliminaries,[0],[0]
"By relaxing labels to be in the interval [−1, 1], we consider the following regularization potential function Φ : RV → R:
Φ(f)",2. Preliminaries,[0],[0]
"= 1
2 ∑ e∈E we · ([∆e(f)]+)2,
where ∆e(f) := max(u,v)∈Te×He(fu − fv) = maxu∈Te fu −minv∈He fv .
",2. Preliminaries,[0],[0]
"In particular, there is a penalty due to edge e only if some vertex in Te receives a label larger than that of some vertex in He.",2. Preliminaries,[0],[0]
"The convexity of Φ is proved in the full version.
",2. Preliminaries,[0],[0]
Our approach is to consider the following convex program to obtain an estimated minimizer f ∈,2. Preliminaries,[0],[0]
"[−1, 1]V , which can be rounded to an integer solution for labeling all vertices.
min Φ(f) (CP1) subject to fu ∈",2. Preliminaries,[0],[0]
"[−1, 1], ∀u ∈ V
fu = f ∗ u , ∀u",2. Preliminaries,[0],[0]
"∈ L
Since the f values for the labeled vertices L are fixed in (CP1), we also view Φ : RN → R as a function on the f values of unlabeled vertices N .",2. Preliminaries,[0],[0]
"We use OPT ⊂ RV to denote the set of optimal solutions to (CP1).
",2. Preliminaries,[0],[0]
Trivial Edges.,2. Preliminaries,[0],[0]
An edge e ∈ E is trivial if there exist vertices u ∈ Te ∩ L and v ∈,2. Preliminaries,[0],[0]
He ∩ L such that f∗u = +1 and f∗v = −1.,2. Preliminaries,[0],[0]
"As trivial edges contribute constant towards the objective function Φ, we shall assume that there are no trivial edges in the convex program (CP1).
",2. Preliminaries,[0],[0]
Special Cases.,2. Preliminaries,[0],[0]
"Our directed hypergraph model can capture other graph models as follows.
1.",2. Preliminaries,[0],[0]
Undirected Hypergraphs.,2. Preliminaries,[0],[0]
"For each hyperedge e, we can set Te = He to the corresponding subset of vertices.",2. Preliminaries,[0],[0]
2.,2. Preliminaries,[0],[0]
Undirected Normal Graphs.,2. Preliminaries,[0],[0]
"For each edge e = {u, v}, we can set Te = He = e. Observe that in this case, the potential function becomes Φ(f) =∑
(u,v)∈E wuv(fu− fv)2, which is differentiable, and hence, (CP1) can be solved by standard techniques like gradient descent.
",2. Preliminaries,[0],[0]
Soft Constraints.,2. Preliminaries,[0],[0]
"In (Hein et al., 2013), each labeled vertex u ∈ L can also have some weight µu ∈ R+, which can, for instance, indicate how trustworthy the label
f∗u ∈ {−1,+1} is.",2. Preliminaries,[0],[0]
"The following relaxation is considered.
",2. Preliminaries,[0],[0]
"min Φ̂(f) := Φ(f) + 1
2 ∑ u∈L µu(fu",2. Preliminaries,[0],[0]
"− f∗u)2 (CP2)
subject to fu ∈",2. Preliminaries,[0],[0]
"[−1, 1],∀u ∈ V.
Observe that (CP2) can also be expressed in the framework of (CP1).",2. Preliminaries,[0],[0]
"We simply consider an augmented hypergraph Ĥ such that all vertices V are treated as unlabeled, and for each u ∈ L, we add a new vertex û with label f∗u and a new undirected edge {u, û} with weight µu.",2. Preliminaries,[0],[0]
"Then, it follows that the convex program (CP1) for the augmented instance for Ĥ is exactly the same as (CP2).
",2. Preliminaries,[0],[0]
Challenges Ahead.,2. Preliminaries,[0],[0]
"We next outline how we resolve the encountered challenges when we use (CP1) for semisupervised learning.
",2. Preliminaries,[0],[0]
"• Unlike the case for normal graphs, the set OPT can contain more than one optimal solution for (CP1).",2. Preliminaries,[0],[0]
"In Section 3, we prove some structural properties of the convex program, and illustrate that each u ∈ N has some confidence interval from which we can predict its label.",2. Preliminaries,[0],[0]
• The function Φ is not everywhere differentiable.,2. Preliminaries,[0],[0]
"Hence, we use the subgradient method (Shor et al., 1985).",2. Preliminaries,[0],[0]
"In Section 4, we give a method to generate a subgradient, which is inspired by the continuous diffusion processes for hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), and our method can in fact be viewed as a discretized version.",2. Preliminaries,[0],[0]
"In general, a minimizer for (CP1) might not be unique.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Hence, we introduce the concept of confidence interval.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Definition 3.1 (Confidence Interval),3. Confidence Interval for Semi-supervised Learning,[0],[0]
"For each u ∈ V , we define its confidence interval to be [mu,Mu], where mu := minf∈OPT fu and Mu := maxf∈OPT fu.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"The confidence intervals induce the lower and the upper confidence vectors, ~m and ~M ∈ RV , respectively.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"In Section 3.1, we give the proof of the following lemma, which states that the confidence vectors ~m and ~M are optimal solutions, and so are their convex combinations.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Lemma 3.1 (Confidence Vectors Give Optimal Solutions),3. Confidence Interval for Semi-supervised Learning,[0],[0]
For any λ ∈,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1], the convex combination λ~m + (1− λ) ~M",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"∈ OPT is optimal for (CP1).
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Semi-supervised Learning via Confidence Interval.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
Lemma 3.1 suggests what one can do when (CP1) has more than one optimal solution.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Specifically, in Algorithm 1, the
average vector 12 (~m + ~M) ∈ OPT can be used for label prediction.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"We show that the confidence vectors ~m and ~M can be recovered from any optimal solution f ∈ OPT, which in turn can be estimated by the subgradient method described in Section 4.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Algorithm 1 Semi-Supervised Learning
1: Input: Directed hypergraph H = (V,E,w), labels f∗L for labeled vertices L 2: Compute (estimated) confidence vectors (~m, ~M) ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"RN × RN , either by Algorithm 2 or 3.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
3: Compute average vector fN ← 12 (~m+ ~M).,3. Confidence Interval for Semi-supervised Learning,[0],[0]
4: Compute threshold θ ← 1|N | ∑ u∈N fu.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"5: for each u ∈ N do 6: if fu ≥ θ then 7: f̂u ← +1; 8: else 9: f̂u ← −1;
10: end if 11: end for 12: return f̂N
Fine-Tuning Parameters.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"In view of Lemma 3.1, one could further optimize the choice of λ ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1] in defining fN ← λ~m+ (1−λ) ~M in Line 3.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Similarly, one could pick the threshold θ to be the ϑ-percentile of the sorted coordinates of fN , for some choice of ϑ ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1].",3. Confidence Interval for Semi-supervised Learning,[0],[0]
The parameters λ and ϑ can be tuned using standard techniques like cross-validation.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"However, to illustrate our concepts, we keep the description simple without introducing too many free parameters.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
We derive some properties of the confidence vectors to prove Lemma 3.1.,3.1. Properties of Confidence Vectors,[0],[0]
"The full proofs of Lemma 3.2 and 3.3 are given in the full version.
",3.1. Properties of Confidence Vectors,[0],[0]
"Given a feasible solution f ∈ RV to (CP1), we define the following:
1. Se(f) := arg maxu∈Te fu ⊆ Te and Ie(f) := arg minv∈He fv ⊆ He.",3.1. Properties of Confidence Vectors,[0],[0]
2. f(Se),3.1. Properties of Confidence Vectors,[0],[0]
:= maxu∈Te fu and f(Ie) := minv∈He fv .,3.1. Properties of Confidence Vectors,[0],[0]
"Hence, we have ∆e(f) = f(Se)− f(Ie).",3.1. Properties of Confidence Vectors,[0],[0]
3.,3.1. Properties of Confidence Vectors,[0],[0]
"The set of active edges with respect to f is E(f) := {e ∈ E : ∆e(f) > 0}.
",3.1. Properties of Confidence Vectors,[0],[0]
"The following lemma states even though a minimizer for (CP1) might not be unique, there are still some structural properties for any optimal solution.
",3.1. Properties of Confidence Vectors,[0],[0]
Lemma 3.2 (Active Edges in an Optimal Solution) Suppose f and g are optimal solutions to (CP1).,3.1. Properties of Confidence Vectors,[0],[0]
"Then, for all e ∈ E, [∆e(f)]+ = [∆e(g)]+.",3.1. Properties of Confidence Vectors,[0],[0]
"In particular, this implies that the set of active edges E∗",3.1. Properties of Confidence Vectors,[0],[0]
":= E(f) = E(g) in any op-
timal solution is uniquely determined.",3.1. Properties of Confidence Vectors,[0],[0]
"Hence, for e ∈ E∗, we can define the corresponding ∆∗e = ∆e(f).
",3.1. Properties of Confidence Vectors,[0],[0]
"Definition 3.2 (Pinned Vertex) An unlabeled vertex u is pinned in a solution f ∈ RV if there exist active edges e and e′ ∈ E(f) such that u ∈ Se(f)∩ Ie′(f), in which case we say that the edges e and e′ pin the vertex u under f .
",3.1. Properties of Confidence Vectors,[0],[0]
Lemma 3.3 (Extending an Active Edge),3.1. Properties of Confidence Vectors,[0],[0]
Suppose edge e ∈ E(f) is active in an optimal solution f .,3.1. Properties of Confidence Vectors,[0],[0]
"If He does not contain a vertex labeled with −1, then there exist u ∈ Ie(f) and another active edge e′ ∈ E(f) such that the following holds.
",3.1. Properties of Confidence Vectors,[0],[0]
(a) The edges e and e′,3.1. Properties of Confidence Vectors,[0],[0]
"pin u under f , i.e., u ∈ Se′(f).",3.1. Properties of Confidence Vectors,[0],[0]
(b),3.1. Properties of Confidence Vectors,[0],[0]
"If g is an optimal solution, then Ie(f) ∩ Se′(f) =
Ie(g) ∩ Se′(g) and fu = gu.",3.1. Properties of Confidence Vectors,[0],[0]
vertex labeled with +1.,An analogous result holds when Te does not contain any,[0],[0]
∗(Ie),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
":= minu∈He fu are uniquely determined by any optimal solution f .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Corollary 3.1 (Pinned Vertices),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"In any optimal solution, the set of pinned vertices is uniquely determined.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
We use L∗ to denote the set of labeled or pinned vertices in an optimal solution.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Then, for each u ∈ L∗, its value f∗u in any optimal solution is also uniquely determined.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"From Corollary 3.1, the confidence interval for any u ∈ L∗ contains exactly one value, namely the unique value f∗u in any optimal solution.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The following lemma gives a characterization of an optimal solution.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Lemma 3.4 Characterization of Optimal Solutions,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"A solution f to (CP1) is optimal iff the following conditions hold.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"(a) For each u ∈ L∗, fu = f∗u .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"(b) For each active edge e ∈ E∗, both the maximum
maxu∈Te fu and the minimum minv∈He fv are attained by vertices in L∗. (c) For each inactive edge e /∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"E∗,","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
for all u ∈ Te and v ∈,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He, fu ≤ fv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Proof: We first observe that Corollary 3.1 states that the values of the vertices in L∗ are uniquely determined in any optimal solution.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, any optimal solution must satisfy the three conditions.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We next show that the three conditions implies that the objective value is optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Once the values for vertices in L∗ are fixed, Lemma 3.3 and condition (b) implies that the contribution of all active edges E∗ are determined and are the same as any optimal solution.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Finally, condition (c) implies that edges not in E∗ do not have any contribution towards the objective function.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, any solution satisfying the three conditions must be optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Deriving Confidence Vectors.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"To prove Lemma 3.5, we define a procedure that returns a vector ~m ∈ V R such that for any optimal f ∈ OPT, we have f ≥ ~m.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, we shall show that ~m ∈ OPT and hence ~m is the lower confidence vector.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The argument for the upper confidence vector ~M is similar.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For the special case of undirected hypergraphs, the procedure can be simplified to Algorithm 2 in Section 3.2.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Lemma 3.5 (Confidence Vectors are Optimal: Proof of Lemma 3.1),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The confidence vectors ~m and ~M defined in Definition 3.1 are optimal solutions to (CP1).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This implies that any of their convex combination is also optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Proof: We give a procedure that returns a vector ~m such that at any moment during the procedure, the following invariant is maintained: for any f ∈ OPT, f ≥ ~m.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The following steps correspond to maintaining the conditions in Lemma 3.4.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0.9571284270432672],['The arrows link referring expressions in the situated dialogue to their referents in the environment.']
(a) Initialization.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For v ∈ L∗, set mv := f∗v ; for v /∈ L∗, set mv := −1.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This satisfies the invariant, because for any f ∈ OPT and any v ∈ L∗, fv = f∗v .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(b) Preserving Active Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For each v /∈ L∗, set mv ← max{mv,maxe∈E∗:v∈He f∗(Ie)}.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Observe that Lemma 3.4(b) implies that for any optimal f ∈ OPT, any e ∈ E∗ and any v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He, fv ≥ f∗(Ie).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, the invariant is maintained.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(c) Preserving Inactive Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
While there is an inactive edge e /∈ E∗,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"such that u ∈ Te, v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He and mu > mv , set mv ← mu.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
We argue why each such update preserves the invariant.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Consider any optimal f ∈ OPT.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Before this update, the invariant holds.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, we have mu ≤ fu.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, Lemma 3.4 implies that fu ≤ fv .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Therefore, after setting mv ← mu, we still have mv ≤ fv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Finally, observe that after step (b), the coordinates of ~m can take at most n distinct values.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, after each update in step (c), one coordinate of ~m must increase strictly.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, this procedure will terminate.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We next argue that ~m is an optimal solution by checking that it satisfies the conditions in Lemma 3.4.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Condition (a).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Observe that for each v ∈ L∗, mv is initialized to f∗v .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Afterwards the value mv could only be increased.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"However, because the invariant holds when the procedure terminates, it must be the case that mv = f∗v at the end.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Condition (b).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The procedure makes sure that at the end of
step (b), for every active edge e ∈ E∗, minv∈He mv can be attained by some vertex in L∗. Since only mv for v /∈ L∗ can be increased in step (c), it follows that in the end, the minimum can still be attained by some vertex in L∗.
Next, consider u ∈ Te, where e ∈ E∗. For any optimal solution f , Lemma 3.3 implies that fu ≤ f∗(Se).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, the invariant implies thatmu ≤ fu ≤ f∗(Se).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Since condition (a) holds, this means that maxv∈Te mv can be attained by some vertex in L∗.
Condition (c).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This is clearly satisfied because of the while-termination condition.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Therefore, we have ~m ∈ OPT, as required.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The proof for the upper confidence vector ~M is similar.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We omit the detailed proof and just give the corresponding procedure to return ~M .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(a) Initialization.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For v ∈ L∗, set Mv := f∗v ; for v /∈ L∗, set Mv := +1.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(b) Preserving Active Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For each v /∈ L∗, set Mv ← min{Mv,mine∈E∗:v∈Te f∗(Se)}.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(c) Preserving Inactive Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
While there is an inactive edge e /∈ E∗,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"such that u ∈ Te, v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He and Mu > Mv , set Mu ←Mv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The same argument can show that for any optimal f ∈ OPT, we have f ≤ ~M .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, we also have ~M ∈ OPT.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"As mentioned before, the proof of Lemma 3.5 implicitly gives a procedure to compute the confidence vectors from any optimal solution.",3.2. Computing the Confidence Interval,[0],[0]
"For the special case of undirected hypergraphs, a simplified version of the procedure is given in Algorithm 2.
",3.2. Computing the Confidence Interval,[0],[0]
"Alternatively, we can try to solve the convex program (CP1), for example using Algorithm 5 in Section 4, from two initial feasible solutions to heuristically estimate the confidence vectors.",3.2. Computing the Confidence Interval,[0],[0]
"In Algorithm 3, one instance approaches an optimal solution from high f values and the other from low f values.",3.2. Computing the Confidence Interval,[0],[0]
Resolving Ties.,4. Subgradient Method via Markov Operator,[0],[0]
Observe that Φ : RN → R is differentiable at fN ∈ RN that has distinct coordinates.,4. Subgradient Method via Markov Operator,[0],[0]
"For the purpose of computing a subgradient, we assume that there is some global ordering π on V to resolve ties among coordinates with the same value.",4. Subgradient Method via Markov Operator,[0],[0]
"In particular, the vertices in L having label +1 are the highest, and those in L labeled −1 are the lowest.",4. Subgradient Method via Markov Operator,[0],[0]
"Hence, in this section, we may assume that any arg max or arg min operator over a subset of vertices
Algorithm 2 Confidence Intervals for Undirected Hypergraphs
1: Input: Undirected hypergraph H = (V,E,w), label vector f∗L and tolerance ≥ 0.",4. Subgradient Method via Markov Operator,[0],[0]
"2: Let f be a solution of (CP1), either by Algorithm 5 or by PDHG method (Hein et al., 2013) 3: For all v ∈ V , set p(v)← v, mv ← −1, Mv ← +1.",4. Subgradient Method via Markov Operator,[0],[0]
"4: Ê := {e ∈ E : ∆e(f) ≤ } 5: while ∃e1 6= e2 ∈ Ê, e1 ∩ e2 6= ∅",4. Subgradient Method via Markov Operator,[0],[0]
"do 6: Ê ← (Ê \ {e1, e2}) ∪ {e1 ∪ e2} 7: end while 8: for each e ∈ Ê do 9: x← an arbitrary vertex in e
10: for each vertex v ∈ e do 11: p(v)← p(x) 12: end for 13: end for 14: for each vertex v ∈ L do 15: mp(v) ← f∗v , Mp(v) ← f∗v 16: end for 17: for each edge e ∈ E such that ∆e(f) >",4. Subgradient Method via Markov Operator,[0],[0]
do 18: for each vertex v ∈,4. Subgradient Method via Markov Operator,[0],[0]
e,4. Subgradient Method via Markov Operator,[0],[0]
"do 19: mp(v) ← max{mp(v), f(Ie)} 20: Mp(v) ← min{Mp(v), f(Se)} 21: end for 22: end for 23: for each vertex v ∈ V do 24: mv ← mp(v), Mv ←Mp(v) 25: end for 26: return vectors (~m, ~M)
will return a unique vertex.
",4. Subgradient Method via Markov Operator,[0],[0]
"We next define a Markov operator that is inspired from the diffusion processes on hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016) in the context of defining Laplacians.",4. Subgradient Method via Markov Operator,[0],[0]
"We denote the projection operator ΠN : RV → RN that takes f ∈ RV and returns the restricted vector fN ∈ RN .
",4. Subgradient Method via Markov Operator,[0],[0]
Lemma 4.1 For f ∈,4. Subgradient Method via Markov Operator,[0],[0]
"[−1, 1]V that is feasible in (CP1), the Markov operator Mf given in Algorithm 4 returns a subgradient of Φ : RN → R at fN .
",4. Subgradient Method via Markov Operator,[0],[0]
"Proof: (Sketch) Observe that if fN ∈ RN has distinct coordinates, then Φ is differentiable at fN , and Mf gives exactly the gradient (which is the only possible subgradient in this case).",4. Subgradient Method via Markov Operator,[0],[0]
"Observe that in our subgradient method application, we could imagine that at every iteration, infinitesimal perturbation is performed on the current solution to ensure that all coordinates are distinct, and ties are resolved according to our global ordering π.
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 3 Estimate confidence interval 1: Input: Directed hypergraph H = (V,E,w), labels f∗L
for labeled vertices L 2: Construct feasible f (0,+)N ← +1 ∈ RN with all entries
being +1; 3: Construct feasible f (0,−)N ← −1 ∈",4. Subgradient Method via Markov Operator,[0],[0]
"RN with all entries
being −1; 4: ~M ← SGM(f (0,+)N ); 5: ~m← SGM(f (0,−)N ); 6: return the vectors (~m, ~M)
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 4 Markov Operator M : RV → RN
1: Input: Directed hypergraph H = (V,E,w), feasible f ∈ RV for (CP1) 2: Construct symmetric matrix A ∈ RV×V ; set A← 0.",4. Subgradient Method via Markov Operator,[0],[0]
3: for each e ∈ E such that ∆e(f) > 0,4. Subgradient Method via Markov Operator,[0],[0]
do 4: u← arg maxu∈Te fu; 5: v ← arg minv∈He fv; 6: Auv ← Auv + we; 7: (The same is done forAvu becauseA is symmetric.),4. Subgradient Method via Markov Operator,[0],[0]
"8: end for 9: Construct diagonal matrix W ∈ RN×N ; set W ← 0.
10: for each u ∈ N",4. Subgradient Method via Markov Operator,[0],[0]
do 11:,4. Subgradient Method via Markov Operator,[0],[0]
"Wuu ← ∑ v∈V Auv; 12: end for 13: return (WΠN −ΠNA)f
Hence, as the magnitude of the perturbation tends to zero, if the global ordering π is preserved, then the gradient remains the same, which implies that the gradient is also the subgradient when the perturbation reaches 0.
",4. Subgradient Method via Markov Operator,[0],[0]
"Using the Markov operator M as a subroutine to generate a subgradient, we have the following subgradient method (SGM) (Shor et al., 1985).
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 5 Subgradient Method SGM(f (0)N ∈ RN ) 1: Input: Directed hypergraph H = (V,E,w) with la-
bels f∗L for labeled vertices L, initial feasible solution f (0) N ∈",4. Subgradient Method via Markov Operator,[0],[0]
"RN , step size {ηt := 1 t }t≥1
2: t← 1; 3: (Throughout the algorithm, f (t)L = f ∗ L is given by the
labeled vertices.)",4. Subgradient Method via Markov Operator,[0],[0]
4: while Solution f (t)N has not “stabilized” do 5: g(t)N ← Mf (t−1) ∈ RN ; 6: f (t)N = f (t−1) N,4. Subgradient Method via Markov Operator,[0],[0]
"− ηt ·
g (t)",4. Subgradient Method via Markov Operator,[0],[0]
"N∥∥∥g(t)N ∥∥∥
2
;
7: t← t+ 1; 8: end while 9: return f (t)
",4. Subgradient Method via Markov Operator,[0],[0]
Stabilizing Condition.,4. Subgradient Method via Markov Operator,[0],[0]
"Our experiments in Section 5 suggest that it suffices to run the solver for a short time, after which a better feasible solution f does not improve the prediction accuracy.",4. Subgradient Method via Markov Operator,[0],[0]
Our experiments are run on a standard PC.,5. Experimental Results,[0],[0]
"In our graphs, each point refers to a sample mean, and the height of the vertical bar is the standard error of the mean.",5. Experimental Results,[0],[0]
"We show that our treatment of hypergraphs performs better than the previously best method in (Hein et al., 2013).
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Hypergraph Model.,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We use three datasets from the UCI Machine Learning Repository (Lichman, 2013): mushroom, covertype45 and covertype67.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"As in (Hein et al., 2013), each dataset fits into the hypergraph learning model in the following way.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Each entry in the dataset corresponds to a vertex, which is labeled either +1 or −1.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Moreover, each entry has some categorical attributes.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each attribute and each realized value for that attribute, we form a unit-weight hyperedge containing all the vertices corresponding to entries having that attribute value.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"To summarize, below are the properties of the resulting hypergraphs.
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Dataset mushroom covertype45 covertype67
n = |V",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"| 8124 12240 37877 m = |E| 112 104 123 k =∑
e∈E |e| m
1523 1412 3695
Semi-supervised Learning Framework.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We compare our semi-supervised learning framework with that in (Hein et al., 2013), which was previously the best (compared to (Zhou et al., 2006), for instance).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Specifically, we compare the prediction accuracy of the following two prediction algorithms.
1.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Confidence Interval (CI).,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We use hard constraints (CP1) and confidence intervals for prediction, as described in Algorithm 1 in Section 3. 2.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Hein et al. We implement the method described in (Hein et al., 2013), which uses soft constraints (regularized version), plus 5-fold cross validation to determine the regularization parameter.
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Testing Methodology.,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Since we focus on prediction accuracy, using either subgradient method or PDHG (Hein et al., 2013) for solving the underlying convex programs in each algorithm produces the same results.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each algorithm candidate, we try different sizes of labeled vertices L, where l = |L| ranges from 20 to 200.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each size l
of labeled vertices, we randomly pick l vertices from the dataset to form the set L and treat the rest as unlabeled vertices; we re-sample if only one label (+1 or −1) appears in L. For each size",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"l, we perform 100 trials to report the average error rate together with its standard error.
Results.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Our experiment can recover the results reported in (Hein et al., 2013).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"The test error for the two algorithms on the three datasets is presented in Figure 5.1, which shows that our CI method consistently has lower test error than the one in (Hein et al., 2013).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Different Solvers.,5.2. Comparing Running Times of Solvers,[0],[0]
"We compare the running times of the following two convex program solvers:
• Subgradient Method (SG), proposed by us.",5.2. Comparing Running Times of Solvers,[0],[0]
"Empirically, the step size ηt := 1
(t+1) min( 0.16t 105 ,1)
gives good
performance.",5.2. Comparing Running Times of Solvers,[0],[0]
"For large t, ηt grows like 1t and so the method converges; however, for small t, we would like a larger step size to speed up convergence.",5.2. Comparing Running Times of Solvers,[0],[0]
"• Primal-Dual Hybrid Gradient (PDHG), proposed in (Hein et al., 2013).",5.2. Comparing Running Times of Solvers,[0],[0]
"We choose σ = τ = 1√
1+d ,
where d is the maximum degree.
",5.2. Comparing Running Times of Solvers,[0],[0]
Theoretical Analysis.,5.2. Comparing Running Times of Solvers,[0],[0]
"Given a hypergraph with n vertices and m edges, where the average size of an edge is k, each vertex on average appears in mkn edges.",5.2. Comparing Running Times of Solvers,[0],[0]
"For SG, we use a heap-based data structure to maintain the vertices within a hyperedge.",5.2. Comparing Running Times of Solvers,[0],[0]
"Vertices attaining the maximum and the minimum value within a hyperedge can be retrieved in O(1) time, and a value update takes O(log k) time.",5.2. Comparing Running Times of Solvers,[0],[0]
"In each iteration, at most 2m vertices will have their values updated.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, in each iteration, SG takes time 2m·mkn ·O(log k) = O(m
2k n log k).",5.2. Comparing Running Times of Solvers,[0],[0]
"In the description of PDHG in (Hein et al., 2013), each iteration takesO(mk log k) time.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, when n m, each iteration of SG will be significantly faster, although in general, the number of iterations required by the subgradient method can be larger than that for PDHG.
",5.2. Comparing Running Times of Solvers,[0],[0]
Testing Methodology.,5.2. Comparing Running Times of Solvers,[0],[0]
"In each experiment, we consider the hypergraph from one of the above three datasets.",5.2. Comparing Running Times of Solvers,[0],[0]
"We pick l = 160 vertices at random as the labeled vertices L, and form the corresponding convex program (CP1) for the two solvers, where the initial values for unlabeled vertices are chosen independently to be uniformly at random from [−1, 1].",5.2. Comparing Running Times of Solvers,[0],[0]
"To compare the performance, we run the two solvers on the same convex program, and record each trajectory of the objective value versus the time duration.",5.2. Comparing Running Times of Solvers,[0],[0]
"According to experience, 100 seconds is good enough for either solver to reach an almost optimal solution, and we use the minimum value achieved by the two solvers after 100 seconds as an estimate for the true optimal value OPT.",5.2. Comparing Running Times of Solvers,[0],[0]
"Then, we scan each trajectory, and for each relative gap
∈ {10−i : i = 1, 2, . . .",5.2. Comparing Running Times of Solvers,[0],[0]
", 6}, we find the smallest time T ( ) after which the objective value is at most OPT away from the estimate OPT.",5.2. Comparing Running Times of Solvers,[0],[0]
Each instance of the experiment is repeated 100 times (with different sets of labeled vertices) to obtain an average of those T ( )’s and their standard error.,5.2. Comparing Running Times of Solvers,[0],[0]
"For each relative gap , we also report the test error for using a feasible solution that is OPT away from the presumed optimal value OPT.
Results.",5.2. Comparing Running Times of Solvers,[0],[0]
Both solvers have similar performance.,5.2. Comparing Running Times of Solvers,[0],[0]
"As predicted by our theoretical analysis, we see in Figure 5.2 that SG has an advantage when the number n of vertices is much larger than the number m of edges, which is the case for the the last dataset covertype67.",5.2. Comparing Running Times of Solvers,[0],[0]
"Moreover, in Figure 5.3, we see that achieving a relative gap smaller than 10−4 has almost no effect on improving the prediction accuracy.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, we can conclude that for either solver, it takes roughly 10 to 20 seconds to produce a solution for the underlying convex program that can give good predic-
tion accuracy.",5.2. Comparing Running Times of Solvers,[0],[0]
DBLP Dataset.,5.3. Directed Hypergraph: More Powerful,[0],[0]
"We use the DBLP (Ley, 2009) dataset.",5.3. Directed Hypergraph: More Powerful,[0],[0]
Each paper is represented by a vertex.,5.3. Directed Hypergraph: More Powerful,[0],[0]
"We include papers from year 2000 to 2015 from conferences belonging to the following research areas to conduct our experiments:
• 7049 papers from machine learning (ML): NIPS, ICML • 2539 papers from theoretical computer science (TCS): STOC, FOCS • 3374 papers from database (DB): VLDB, SIGMOD
We perform the following prediction tasks: (a) ML (+1) vs TCS (-1), and (b) ML (+1) vs DB (-1).
",5.3. Directed Hypergraph: More Powerful,[0],[0]
The details of the experiment setup and the results are given in the full version.,5.3. Directed Hypergraph: More Powerful,[0],[0]
We revisit semi-supervised learning on hypergraphs.,abstractText,[0],[0]
"Same as previous approaches, our method uses a convex program whose objective function is not everywhere differentiable.",abstractText,[0],[0]
"We exploit the non-uniqueness of the optimal solutions, and consider confidence intervals which give the exact ranges that unlabeled vertices take in any optimal solution.",abstractText,[0],[0]
"Moreover, we give a much simpler approach for solving the convex program based on the subgradient method.",abstractText,[0],[0]
"Our experiments on real-world datasets confirm that our confidence interval approach on hypergraphs outperforms existing methods, and our sub-gradient method gives faster running times when the number of vertices is much larger than the number of edges.",abstractText,[0],[0]
Re-revisiting Learning on Hypergraphs:  Confidence Interval and Subgradient Method,title,[0],[0]
"Our algorithm typically produces files 2.5 times smaller than JPEG and JPEG 2000, 2 times smaller than WebP, and 1.7 times smaller than BPG on datasets of generic images across all quality levels. At the same time, our codec is designed to be lightweight and deployable: for example, it can encode or decode the Kodak dataset in around 10ms per image on GPU.
Our architecture is an autoencoder featuring pyramidal analysis, an adaptive coding module, and regularization of the expected codelength. We also supplement our approach with adversarial training specialized towards use in a compression setting: this enables us to produce visually pleasing reconstructions for very low bitrates.",text,[0],[0]
"Streaming of digital media makes 70% of internet traffic, and is projected to reach 80% by 2020 (CIS, 2015).",1. Introduction,[0],[0]
"However, it has been challenging for existing commercial compression algorithms to adapt to the growing demand and the changing landscape of requirements and applications.",1. Introduction,[0],[0]
"While digital media are transmitted in a wide variety of settings, the available codecs are “one-size-fits-all”: they are hard-coded, and cannot be customized to particular use cases beyond high-level hyperparameter tuning.
",1. Introduction,[0],[0]
"In the last few years, deep learning has revolutionized many tasks such as machine translation, speech recognition, face recognition, and photo-realistic image generation.",1. Introduction,[0],[0]
"Even though the world of compression seems a natural domain for machine learning approaches, it has not yet benefited from these advancements, for two main reasons.",1. Introduction,[0],[0]
"First,
*Equal contribution 1WaveOne Inc., Mountain View, CA, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Oren Rippel <oren@wave.one>, Lubomir Bourdev <lubomir@wave.one>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, 2017.",1. Introduction,[0],[0]
JMLR: W&CP.,1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"our deep learning primitives, in their raw forms, are not well-suited to construct representations sufficiently compact.",1. Introduction,[0],[0]
"Recently, there have been a number of important efforts by Toderici et al. (2015; 2016), Theis et al. (2016), Ballé et al. (2016), and Johnston et al. (2017) towards alleviating this: see Section 2.2.",1. Introduction,[0],[0]
"Second, it is difficult to develop a deep learning compression approach sufficiently efficient for deployment in environments constrained by computation power, memory footprint and battery life.
",1. Introduction,[0],[0]
"In this work, we present progress on both performance and computational feasibility of ML-based image compression.
",1. Introduction,[0],[0]
"Our algorithm outperforms all existing image compression approaches, both traditional and ML-based: it typically produces files 2.5 times smaller than JPEG and JPEG 2000 (JP2), 2 times smaller than WebP, and 1.7 times smaller than BPG on the Kodak PhotoCD",1. Introduction,[0],[0]
and RAISE-1k 512×768 datasets across all of quality levels.,1. Introduction,[0],[0]
"At the same time, we designed our approach to be lightweight and efficiently deployable.",1. Introduction,[0],[0]
"On a GTX 980 Ti GPU, it takes around 9ms to encode and 10ms to decode an image from these datasets: for JPEG, encode/decode times are 18ms/12ms, for JP2 350ms/80ms and for WebP 70ms/80ms.",1. Introduction,[0],[0]
"Results for a representative quality level are presented in Table 1.
",1. Introduction,[0],[0]
"To our knowledge, this is the first ML-based approach to surpass all commercial image compression techniques, and moreover run in real-time.
",1. Introduction,[0],[0]
We additionally supplement our algorithm with adversarial training specialized towards use in a compression setting.,1. Introduction,[0],[0]
"This enables us to produce convincing reconstructions for very low bitrates.
",1. Introduction,[0],[0]
"ar X
iv :1
70 5.
05 82
3v 1
[ st
at .M
L ]
1 6
M ay
2 01
7",1. Introduction,[0],[0]
"Compression, in general, is very closely related to pattern recognition.",2.1. Traditional compression techniques,[0],[0]
"If we are able to discover structure in our input, we can eliminate this redundancy to represent it more succinctly.",2.1. Traditional compression techniques,[0],[0]
"In traditional codecs such as JPEG and JP2, this is achieved via a pipeline which roughly breaks down into 3 modules: transformation, quantization, and encoding (Wallace (1992) and Rabbani & Joshi (2002) provide great overviews of the JPEG standards).
",2.1. Traditional compression techniques,[0],[0]
"In traditional codecs, since all components are hard-coded, they are heavily engineered to fit together.",2.1. Traditional compression techniques,[0],[0]
"For example, the coding scheme is custom-tailored to match the distribution of the outputs of the preceding transformation.",2.1. Traditional compression techniques,[0],[0]
"JPEG, for instance, employs 8 × 8 block DCT transforms, followed by run-length encoding which exploits the sparsity pattern of the resultant frequency coefficients.",2.1. Traditional compression techniques,[0],[0]
"JP2 employs an adaptive arithmetic coder to capture the distribution of coefficient magnitudes produced by the preceding multiresolution wavelet transform.
",2.1. Traditional compression techniques,[0],[0]
"However, despite the careful construction and assembly of
these pipelines, there still remains significant room for improvement of compression efficiency.",2.1. Traditional compression techniques,[0],[0]
"For example, the transformation is fixed in place irrespective of the distribution of the inputs, and is not adapted to their statistics in any way.",2.1. Traditional compression techniques,[0],[0]
"In addition, hard-coded approaches often compartmentalize the loss of information within the quantization step.",2.1. Traditional compression techniques,[0],[0]
"As such, the transformation module is chosen to be bijective: however, this limits the ability to reduce redundancy prior to coding.",2.1. Traditional compression techniques,[0],[0]
"Moreover, the encode-decode pipeline cannot be optimized for a particular metric beyond manual tweaking: even if we had the perfect metric for image quality assessment, traditional approaches cannot directly optimize their reconstructions for it.",2.1. Traditional compression techniques,[0],[0]
"In approaches based on machine learning, structure is automatically discovered, rather than manually engineered.
",2.2. ML-based lossy image compression,[0],[0]
"One of the first such efforts by Bottou et al. (1998), for example, introduced the DjVu format for document image compression, which employs techniques such as segmentation and K-means clustering separate foreground from background, and analyze the document’s contents.
",2.2. ML-based lossy image compression,[0],[0]
"At a high level, one natural approach to implement the encoder-decoder image compression pipeline is to use an autoencoder to map the target through a bitrate bottleneck, and train the model to minimize a loss function penalizing it from its reconstruction.",2.2. ML-based lossy image compression,[0],[0]
"This requires carefully constructing a feature extractor and synthesizer for the encoder and decoder, selecting an appropriate objective, and possibly introducing a coding scheme to further compress the fixedsize representation to attain variable-length codes.
",2.2. ML-based lossy image compression,[0],[0]
Many of the existing ML-based image compression approaches (including ours) follow this general strategy.,2.2. ML-based lossy image compression,[0],[0]
Toderici et al. (2015; 2016) explored various transformations for binary feature extraction based on different types of recurrent neural networks; the binary representations were then entropy-coded.,2.2. ML-based lossy image compression,[0],[0]
"Johnston et al. (2017) enabled another considerable leap in performance by introducing a loss weighted with SSIM (Wang et al., 2004), and spatiallyadaptive bit allocation.",2.2. ML-based lossy image compression,[0],[0]
"Theis et al. (2016) and Ballé et al. (2016) quantize rather than binarize, and propose strategies to approximate the entropy of the quantized representation: this provides them with a proxy to penalize it.",2.2. ML-based lossy image compression,[0],[0]
"Finally, Pied Piper has recently claimed to employ ML techniques in its Middle-Out algorithm (Judge et al., 2016), although their nature is shrouded in mystery.",2.2. ML-based lossy image compression,[0],[0]
"One of the most exciting innovations in machine learning in the last few years is the idea of Generative Adversarial Networks (GANs) (Goodfellow et al., 2014).",2.3. Generative Adversarial Networks,[0],[0]
"The idea is to construct a generator network GΦ(·) whose goal is to synthesize outputs according to a target distribution ptrue, and a discriminator network DΘ(·) whose goal is to distinguish between examples sampled from the ground truth distribution, and ones produced by the generator.",2.3. Generative Adversarial Networks,[0],[0]
"This can be expressed concretely in terms of the minimax problem:
min Φ max Θ
Ex∼ptrue logDΘ(x) + Ez∼pz log [1−DΘ(GΦ(z))] .
",2.3. Generative Adversarial Networks,[0],[0]
"This idea has enabled significant progress in photo-realistic image generation (Denton et al., 2015; Radford et al., 2015; Salimans et al., 2016), single-image super-resolution
(Ledig et al., 2016), image-to-image conditional translation (Isola et al., 2016), and various other important problems.
",2.3. Generative Adversarial Networks,[0],[0]
The adversarial training framework is particularly relevant to the compression world.,2.3. Generative Adversarial Networks,[0],[0]
"In traditional codecs, distortions often take the form of blurriness, pixelation, and so on.",2.3. Generative Adversarial Networks,[0],[0]
"These artifacts are unappealing, but are increasingly noticeable as the bitrate is lowered.",2.3. Generative Adversarial Networks,[0],[0]
"We propose a multiscale adversarial training model to encourage reconstructions to match the statistics of their ground truth counterparts, resulting in sharp and visually pleasing results even for very low bitrates.",2.3. Generative Adversarial Networks,[0],[0]
"As far as we know, we are the first to propose using GANs for image compression.",2.3. Generative Adversarial Networks,[0],[0]
"Our model architecture is shown in Figure 2, and comprises a number of components which we briefly outline below.",3. Model,[0],[0]
"In this section, we limit our focus to operations performed by the encoder: since the decoder simply performs the counterpart inverse operations, we only address exceptions which require particular attention.
",3. Model,[0],[0]
Feature extraction.,3. Model,[0],[0]
"Images feature a number of different types of structure: across input channels, within individual scales, and across scales.",3. Model,[0],[0]
We design our feature extraction architecture to recognize these.,3. Model,[0],[0]
"It consists of a pyramidal decomposition which analyzes individual scales, followed by an interscale alignment procedure which exploits structure shared across scales.
",3. Model,[0],[0]
Code computation and regularization.,3. Model,[0],[0]
This module is responsible for further compressing the extracted features.,3. Model,[0],[0]
"It quantizes the features, and encodes them via an adaptive arithmetic coding scheme applied on their binary expansions.",3. Model,[0],[0]
"An adaptive codelength regularization is introduced to penalize the entropy of the features, which the coding scheme exploits to achieve better compression.
",3. Model,[0],[0]
Discriminator loss.,3. Model,[0],[0]
We employ adversarial training to pursue realistic reconstructions.,3. Model,[0],[0]
We dedicate Section 4 to describing our GAN formulation.,3. Model,[0],[0]
"Our pyramidal decomposition encoder is loosely inspired by the use of wavelets for multiresolution analysis, in which an input is analyzed recursively via feature extraction and downsampling operators (Mallat, 1989).",3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
"The JPEG 2000 standard, for example, employs discrete wavelet transforms with the Daubechies 9/7 kernels (Antonini et al., 1992; Rabbani & Joshi, 2002).",3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
"This transform is in fact a linear operator, which can be entirely expressed via compositions of convolutions with only two hard-coded and separable 9×9 filters applied irrespective of scale, and independently for each channel.
",3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
"The idea of a pyramidal decomposition has been employed in machine learning: for instance, Mathieu et al. (2015) uses a pyramidal composition for next frame prediction, and Denton et al. (2015) uses it for image generation.",3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
"The spectral representations of CNN activations have also been investigated by Rippel et al. (2015) to enable processing across a spectrum of scales, but this approach does not enable FIR processing as does wavelet analysis.
",3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
"We generalize the wavelet decomposition idea to learn optimal, nonlinear extractors individually for each scale.",3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
"Let us assume an input x to the model, and a total of M scales.",3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
We perform recursive analysis: let us denote xm as the input to scale m; we set the input to the first scale x1 = x as the input to the model.,3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
"For each scale m, we perform two operations: first, we extract coefficients cm = fm(xm) ∈",3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
"RCm×Hm×Wm via some parametrized function fm(·) for output channels Cm, height Hm and width Wm.",3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
"Second, we compute the input to the next scale as xm+1 = Dm(xm) where Dm(·) is some downsampling operator (either fixed or learned).
",3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
Our pyramidal decomposition architecture is illustrated in Figure 3.,3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
"In practice, we extract across a total of M =
6 scales.",3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
The feature extractors for the individual scales are composed of a sequence of convolutions with kernels 3 × 3 or 1 × 1 and ReLUs with a leak of 0.2.,3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
We learn all downsamplers as 4× 4 convolutions with a stride of 2.,3.1.1. PYRAMIDAL DECOMPOSITION,[0],[0]
Interscale alignment is designed to leverage information shared across different scales — a benefit not offered by the classic wavelet analysis.,3.1.2. INTERSCALE ALIGNMENT,[0],[0]
It takes in as input the set of coefficients extracted from the different scales {cm}Mm=1 ⊂,3.1.2. INTERSCALE ALIGNMENT,[0],[0]
"RCm×Hm×Wm , and produces a single tensor of a target output dimensionality C ×H ×W .
",3.1.2. INTERSCALE ALIGNMENT,[0],[0]
"To do this, we first map each input tensor cm to the target dimensionality via some parametrized function gm(·).",3.1.2. INTERSCALE ALIGNMENT,[0],[0]
"This involves ensuring that this function spatially resamples cm to the appropriate output map sizeH×W , and outputs the appropriate number of channels C. We then sum gm(cm),m = 1, . . .",3.1.2. INTERSCALE ALIGNMENT,[0],[0]
",M , and apply another parametrized non-linear transformation g(·) for joint processing.
",3.1.2. INTERSCALE ALIGNMENT,[0],[0]
The interscale alignment module can be seen in Figure 3.,3.1.2. INTERSCALE ALIGNMENT,[0],[0]
We denote its output as y.,3.1.2. INTERSCALE ALIGNMENT,[0],[0]
"In practice, we choose each gm(·) as a convolution or a deconvolution with an appropriate stride to produce the target spatial map size H ×W ; see Section 5.1 for a more detailed discussion.",3.1.2. INTERSCALE ALIGNMENT,[0],[0]
We choose g(·) simply as a sequence of 3× 3 convolutions.,3.1.2. INTERSCALE ALIGNMENT,[0],[0]
"Given the extracted tensor y ∈ RC×H×W , we proceed to quantize it and encode it.",3.2. Code computation and regularization,[0],[0]
"This pipeline involves a number of components which we overview here and describe in detail throughout this section.
",3.2. Code computation and regularization,[0],[0]
Quantization.,3.2. Code computation and regularization,[0],[0]
"The tensor y is quantized to bit precision B:
ŷ",3.2. Code computation and regularization,[0],[0]
":= QUANTIZEB(y) .
",3.2. Code computation and regularization,[0],[0]
Bitplane decomposition.,3.2. Code computation and regularization,[0],[0]
"The quantized tensor ŷ is transformed into a binary tensor suitable for encoding via a lossless bitplane decomposition:
b := BITPLANEDECOMPOSEB(ŷ) ∈ {0, 1}B×C×H×W .
",3.2. Code computation and regularization,[0],[0]
Adaptive arithmetic coding.,3.2. Code computation and regularization,[0],[0]
The adaptive arithmetic coder (AAC) is trained to leverage the structure remaining in the data.,3.2. Code computation and regularization,[0],[0]
"It encodes b into its final variable-length binary sequence s of length `(s):
s := AACENCODE(b) ∈ {0, 1}`(s) .
",3.2. Code computation and regularization,[0],[0]
Adaptive codelength regularization.,3.2. Code computation and regularization,[0],[0]
"The adaptive codelength regularization (ACR) modulates the distribution of the quantized representation ŷ to achieve a target
expected bit count across inputs:
Ex[`(s)]",3.2. Code computation and regularization,[0],[0]
−→ `target .,3.2. Code computation and regularization,[0],[0]
"Given a desired precision ofB bits, we quantize our feature tensor y into 2B equal-sized bins as
ŷchw := QUANTIZEB(ychw)",3.2.1. QUANTIZATION,[0],[0]
"= 1 2B−1 ⌈ 2B−1ychw ⌉ .
",3.2.1. QUANTIZATION,[0],[0]
"For the special case B = 1, this reduces exactly to a binary quantization scheme.",3.2.1. QUANTIZATION,[0],[0]
"While some ML-based approaches to compression employ such thresholding, we found better performance with the smoother quantization described.",3.2.1. QUANTIZATION,[0],[0]
We quantize with B = 6 for all models in this paper.,3.2.1. QUANTIZATION,[0],[0]
We decompose ŷ into bitplanes.,3.2.2. BITPLANE DECOMPOSITION,[0],[0]
This transformation maps each value ŷchw into its binary expansion ofB bits.,3.2.2. BITPLANE DECOMPOSITION,[0],[0]
"Hence, each of the C spatial maps ŷc ∈ RH×W of ŷ expands intoB binary bitplanes.",3.2.2. BITPLANE DECOMPOSITION,[0],[0]
"We illustrate this transformation in Figure 4, and denote its output as b ∈ {0, 1}B×C×H×W .",3.2.2. BITPLANE DECOMPOSITION,[0],[0]
"This transformation is lossless.
",3.2.2. BITPLANE DECOMPOSITION,[0],[0]
"As described in Section 3.2.3, this decomposition will enable our entropy coder to exploit structure in the distribution of the activations in y to achieve a compact representation.",3.2.2. BITPLANE DECOMPOSITION,[0],[0]
"In Section 3.2.4, we introduce a strategy to encourage such exploitable structure to be featured.",3.2.2. BITPLANE DECOMPOSITION,[0],[0]
"The output b of the bitplane decomposition is a binary tensor, which contains significant structure: for example, higher bitplanes are sparser, and spatially neighboring bits often have the same value (in Section 3.2.4 we propose a technique to guarantee presence of these properties).",3.2.3. ADAPTIVE ARITHMETIC CODING,[0],[0]
"We exploit this low entropy by lossless compression via adaptive arithmetic coding.
",3.2.3. ADAPTIVE ARITHMETIC CODING,[0],[0]
"Namely, we associate each bit location in b with a context, which comprises a set of features indicative of the bit value.",3.2.3. ADAPTIVE ARITHMETIC CODING,[0],[0]
These are based on the position of the bit as well as the values of neighboring bits.,3.2.3. ADAPTIVE ARITHMETIC CODING,[0],[0]
"We train a classifier to predict the value of each bit from its context features, and then use these probabilities to compress b via arithmetic coding.
",3.2.3. ADAPTIVE ARITHMETIC CODING,[0],[0]
"During decoding, we decompress the code by performing the inverse operation.",3.2.3. ADAPTIVE ARITHMETIC CODING,[0],[0]
"Namely, we interleave between computing the context of a particular bit using the values of previously decoded bits, and using this context to retrieve the activation probability of the bit and decode it.",3.2.3. ADAPTIVE ARITHMETIC CODING,[0],[0]
We note that this constrains the context of each bit to only include features composed of bits already decoded.,3.2.3. ADAPTIVE ARITHMETIC CODING,[0],[0]
One problem with classic autoencoder architectures is that their bottleneck has fixed capacity.,3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"The bottleneck may be too small to represent complex patterns well, which affects quality, and it may be too large for simple patterns, which results in inefficient compression.",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"What we need is a model capable of generating long representations for complex patterns and short for simple ones, while maintaining an expected codelength target over large number of examples.",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"To achieve this, the AAC is necessary, but not sufficient.
",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"We extend the architecture by increasing the dimensionality of b — but at the same time controlling its information content, thereby resulting in shorter compressed code s = AACENCODE(b) ∈ {0, 1}.",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"Specifically, we introduce the adaptive codelength regularization (ACR), which enables us to regulate the expected codelength Ex[`(s)] to a target value `target.",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
This penalty is designed to encourage structure exactly where the AAC is able to exploit it.,3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"Namely, we regularize our quantized tensor ŷ with
P(ŷ) =",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"αt
CHW ∑ chw { log2 |ŷchw|
+ ∑
(x,y)∈S
log2 ∣∣ŷchw − ŷc(h−y)(w−x)∣∣ } ,
for iteration t and difference index set S = {(0, 1), (1, 0), (1, 1), (−1, 1)}.",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"The first term penalizes the magnitude of each tensor element, and the second penalizes deviations between spatial neighbors.",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"These enable better prediction by the AAC.
",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"As we train our model, we continuously modulate the scalar coefficient αt to pursue our target codelength.",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
We do this via a feedback loop.,3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
We use the AAC to monitor the mean number of effective bits.,3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"If it is too high, we increase αt; if too low, we decrease it.",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"In practice, the model reaches an equilibrium in a few hundred iterations, and is able to maintain it throughout training.
",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"Hence, we get a knob to tune: the ratio of total bits, namely the BCHW bits available in b, to the target number of effective bits `target.",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"This allows exploring the trade-off of increasing the number of channels or spatial map size of
b at the cost of increasing sparsity.",3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
We find that a totalto-target ratio of BCHW/`target = 4 works well across all architectures we have explored.,3.2.4. ADAPTIVE CODELENGTH REGULARIZATION,[0],[0]
"In our compression approach, we take the generator as the encoder-decoder pipeline, to which we append a discriminator — albeit with a few key differences from existing GAN formulations.
",4.1. Discriminator design,[0],[0]
"In many GAN approaches featuring both a reconstruction and a discrimination loss, the target and the reconstruction are treated independently: each is separately assigned a label indicating whether it is real or fake.",4.1. Discriminator design,[0],[0]
"In our formulation, we consider the target and its reconstruction jointly as a single example: we compare the two by asking which of the two images is the real one.
",4.1. Discriminator design,[0],[0]
"To do this, we first swap between the target and reconstruction in each input pair to the discriminator with uniform probability.",4.1. Discriminator design,[0],[0]
"Following the random swap, we propagate each set of examples through the network.",4.1. Discriminator design,[0],[0]
"However, instead of producing an output for classification at the
very last layer of the pipeline, we accumulate scalar outputs along branches constructed along it at different depths.",4.1. Discriminator design,[0],[0]
We average these to attain the final value provided to the terminal sigmoid function.,4.1. Discriminator design,[0],[0]
"This multiscale architecture allows aggregating information across different scales, and is motivated by the observation that undesirable artifacts vary as function of the scale in which they are exhibited.",4.1. Discriminator design,[0],[0]
"For example, high-frequency artifacts such as noise and blurriness are discovered by earlier scales, whereas more abstract discrepancies are found in deeper scales.
",4.1. Discriminator design,[0],[0]
"We apply our discriminator DΘ on the aggregate sum across scales, and proceed to formulate our objectives as described in Section 2.3.",4.1. Discriminator design,[0],[0]
The complete discriminator architecture is illustrated in Figure 10.,4.1. Discriminator design,[0],[0]
Training a GAN system can be tricky due to optimization instability.,4.2. Adversarial training,[0],[0]
"In our case, we were able to address this by designing a training scheme adaptive in two ways.",4.2. Adversarial training,[0],[0]
"First, the reconstructor is trained by both the confusion signal gradient as well as the reconstruction loss gradient: we balance the two as function of their gradient magnitudes.",4.2. Adversarial training,[0],[0]
"Second, at any point during training, we either train the discriminator or propagate confusion signal through the reconstructor, as function of the prediction accuracy of the discriminator.
More concretely, given lower and upper accuracy bounds L,U ∈",4.2. Adversarial training,[0],[0]
"[0, 1] and discriminator accuracy a(DΘ), we apply the following procedure:
•",4.2. Adversarial training,[0],[0]
"If a < L: freeze propagation of confusion signal through the reconstructor, and train the discriminator.
",4.2. Adversarial training,[0],[0]
•,4.2. Adversarial training,[0],[0]
"If L ≤ a < U : alternate between propagating confusion signal and training the disciminator.
• If U ≤ a: propagate confusion signal through the reconstructor, and freeze the discriminator.
",4.2. Adversarial training,[0],[0]
"In practice we used L = 0.8, U = 0.95.",4.2. Adversarial training,[0],[0]
We compute the accuracy a as a running average over mini-batches with a momentum of 0.8.,4.2. Adversarial training,[0],[0]
Similarity metric.,5.1. Experimental setup,[0],[0]
"We trained and tested all models on the Multi-Scale Structural Similarity Index Metric (MSSSIM) (Wang et al., 2003).",5.1. Experimental setup,[0],[0]
"This metric has been specifically designed to match the human visual system, and has been established to be significantly more representative than losses in the `p family and variants such as PSNR.
Color space.",5.1. Experimental setup,[0],[0]
"Since the human visual system is much more sensitive to variations in brightness than color, most codecs represent colors in the YCbCr color space to devote more bandwidth towards encoding luma rather than chroma.",5.1. Experimental setup,[0],[0]
"In quantifying image similarity, then, it is common to assign the Y, Cb, Cr components weights 6/8, 1/8, 1/8.",5.1. Experimental setup,[0],[0]
"While many ML-based compression papers evaluate similarity in the RGB space with equal color weights, this does not allow fair comparison with standard codecs such as JPEG, JPEG 2000 and WebP, since they have not been designed to perform optimally in this domain.",5.1. Experimental setup,[0],[0]
"In this work, we provide comparisons with both traditional and ML-based codecs, and present results in both the RGB domain with equal color weights, as well as in YCbCr with weights as above.
",5.1. Experimental setup,[0],[0]
Reported performance metrics.,5.1. Experimental setup,[0],[0]
"We present both compression performance of our algorithm, but also its runtime.",5.1. Experimental setup,[0],[0]
"While the requirement of running the approach in real-time severely constrains the capacity of the model, it must be met to enable feasible deployment in real-life applications.
",5.1. Experimental setup,[0],[0]
Training and deployment procedure.,5.1. Experimental setup,[0],[0]
We trained and tested all models on a GeForce GTX 980 Ti GPU and a custom codebase.,5.1. Experimental setup,[0],[0]
"We trained all models on 128× 128 patches sampled at random from the Yahoo Flickr Creative Com-
mons 100 Million dataset (Thomee et al., 2016).
",5.1. Experimental setup,[0],[0]
"We optimized all models with Adam (Kingma & Ba, 2014).",5.1. Experimental setup,[0],[0]
"We used an initial learning rate of 3 × 10−4, and reduced it twice by a factor of 5 during training.",5.1. Experimental setup,[0],[0]
"We chose a batch size of 16 and trained each model for a total of 400,000 iterations.",5.1. Experimental setup,[0],[0]
We initialized the ACR coefficient as α0 = 1.,5.1. Experimental setup,[0],[0]
During runtime we deployed the model on arbitrarily-sized images in a fully-convolutional way.,5.1. Experimental setup,[0],[0]
"To attain the ratedistortion (RD)curves presented in Section 5.2, we trained models for a range of target bitrates `target.",5.1. Experimental setup,[0],[0]
"We present several types of results:
1.",5.2. Performance,[0],[0]
"Average MS-SSIM as function of the BPP fixed for each image, found in Figures 5 and 6, and Table 1.
2.",5.2. Performance,[0],[0]
"Average compressed file sizes relative to ours as function of the MS-SSIM fixed for each image, found in Figures 5 and 6, and Table 1.
3.",5.2. Performance,[0],[0]
"Encode and decode timings as function of MS-SSIM, found in Figure 7, in the appendix, and Table 1.
4.",5.2. Performance,[0],[0]
"Visual examples of reconstructions of different compression approaches for the same BPP, found in Figure 1 and in the appendix.
",5.2. Performance,[0],[0]
Test sets.,5.2. Performance,[0],[0]
"To enable comparison with other approaches, we first present performance on the Kodak PhotoCD dataset1.",5.2. Performance,[0],[0]
"While the Kodak dataset is very popular for testing compression performance, it contains only 24 images, and hence is susceptible to overfitting and does not necessarily fully capture broader statistics of natural images.",5.2. Performance,[0],[0]
"As such, we additionally present performance on the RAISE-1k dataset (Dang-Nguyen et al., 2015) which contains 1,000 raw images.",5.2. Performance,[0],[0]
"We resized each image to size 512× 768 (backwards if vertical): we intend to release our preparation code to enable reproduction of the dataset used.
",5.2. Performance,[0],[0]
"We remark it is important to use a dataset of raw, rather than previously compressed, images for codec evaluation.
",5.2. Performance,[0],[0]
"1The Kodak PhotoCD dataset can be found at http:// r0k.us/graphics/kodak.
2The results of Toderici et al. (2016) on the Kodak RGB dataset are available at http://github.com/ tensorflow/models/tree/master/compression.
",5.2. Performance,[0],[0]
"3We have no access to reconstructions by Theis et al. (2016) and Johnston et al. (2017), so we carefully transcribed their results, only available in RGB, from the graphs in their paper.
4Reconstructions by Ballé et al. (2016) of images in the Kodak dataset can be found at http://www.cns.nyu.edu/ ˜lcv/iclr2017/ for both RGB and YCbCr and across a spectrum of BPPs.",5.2. Performance,[0],[0]
"We use these to compute RD curves by the procedure described in this section.
5An implementation of the BPG codec is available at http: //bellard.org/bpg.
",5.2. Performance,[0],[0]
"Compressing an image introduces artifacts with a bias particular to the codec used, which results in a more favorable RD curve if it compressed again with the same codec.",5.2. Performance,[0],[0]
"See Figure 9 for a plot demonstrating this effect.
",5.2. Performance,[0],[0]
Codecs.,5.2. Performance,[0],[0]
"We compare against commercial compression techniques JPEG, JPEG 2000, WebP, as well as recent MLbased compression work by Toderici et al. (2016)2, Theis et al. (2016)3, Ballé et al. (2016)4, and Johnston et al. (2017)3 in all settings in which results are available.",5.2. Performance,[0],[0]
"We also compare to BPG5 (4:2:0 and 4:4:4) which, while not widely used, surpassed all other codecs in the past.",5.2. Performance,[0],[0]
"We use the best-performing configuration we can find of JPEG, JPEG 2000, WebP, and BPG, and reduce their bitrates by their respective header lengths for fair comparison.
",5.2. Performance,[0],[0]
Performance evaluation.,5.2. Performance,[0],[0]
"For each image in each test set, each compression approach, each color space, and for the selection of available compression rates, we recorded (1) the BPP, (2) the MS-SSIM (with components weighted appropriately for the color space), and (3) the computation times for encoding and decoding.
",5.2. Performance,[0],[0]
It is important to take great care in the design of the performance evaluation procedure.,5.2. Performance,[0],[0]
"Each image has a separate RD curve computed from all available compression rates for a given codec: as Ballé et al. (2016) discusses in detail, different summaries of these RD curves lead to disparate results.",5.2. Performance,[0],[0]
"In our evaluations, to compute a given curve, we sweep across values of the independent variable (such as bitrate).",5.2. Performance,[0],[0]
"We interpolate each individual RD curve at this independent variable value, and average all the results.",5.2. Performance,[0],[0]
"To ensure accurate interpolation, we sample densely across rates for each codec.
",5.2. Performance,[0],[0]
"Acknowledgements We are grateful to Trevor Darrell, Sven Strohband, Michael Gelbart, Robert Nishihara, Albert Azout, and Vinod Khosla for meaningful discussions and input.",5.2. Performance,[0],[0]
"Streaming of digital media makes 70% of internet traffic, and is projected to reach 80% by 2020 (CIS, 2015).",abstractText,[0],[0]
"However, it has been challenging for existing commercial compression algorithms to adapt to the growing demand and the changing landscape of requirements and applications.",abstractText,[0],[0]
"While digital media are transmitted in a wide variety of settings, the available codecs are “one-size-fits-all”: they are hard-coded, and cannot be customized to particular use cases beyond high-level hyperparameter tuning.",abstractText,[0],[0]
Real-Time Adaptive Image Compression,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 57–66 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
57",text,[0],[0]
"Procedural text is ubiquitous (e.g., scientific protocols, news articles, how-to guides, recipes), but is challenging to comprehend because of the dynamic nature of the world being described.",1 Introduction,[0],[0]
"Comprehending such text requires a model of the actions described in the text and the state changes they produce, so that questions about the states of entities at different timepoints can be answered (Bosselut et al., 2018).
",1 Introduction,[0],[0]
"Despite these challenges, substantial progress has been made recently in this task.",1 Introduction,[0],[0]
"Recent work – such as EntNet (Henaff et al., 2017), QRN (Seo et al., 2017b), ProLocal/ProGlobal (Dalvi et al.,
∗*Niket Tandon and Bhavana Dalvi Mishra contributed equally to this work.
",1 Introduction,[0],[0]
Procedural Text: How hydroelectric electricity is generated: 1 Water flows downwards thanks to gravity.,1 Introduction,[0],[0]
2 The moving water spins the turbines in the power plant.,1 Introduction,[0],[0]
3 The turbines turn the generators.,1 Introduction,[0],[0]
4,1 Introduction,[0],[0]
"The generators spin, and produce electricity.
",1 Introduction,[0],[0]
"Prior Neural Model’s Predictions:
2018), and NPN (Bosselut et al., 2018) – has focused on learning to predict individual entity states at various points in the text, thereby approximating the underlying dynamics of the world.",1 Introduction,[0],[0]
"However, while these models can learn to make local predictions with fair accuracy, their results are often globally unlikely or inconsistent.",1 Introduction,[0],[0]
"For example, in Figure 1, the neural ProGlobal model from Dalvi et al. (2018) learns to predict the impossible action of an object moving from itself (1), and the unlikely action of a turbine changing location (2).",1 Introduction,[0],[0]
"We observe similar mistakes in other neural models, indicating that these models have little notion of global consistency.",1 Introduction,[0],[0]
"Unsurprisingly, mistakes in local predictions compound as the process becomes longer, further reducing the plausibility of the overall result.
",1 Introduction,[0],[0]
"To address this challenge, we treat process comprehension as a structured prediction task and apply hard and soft constraints during reading.",1 Introduction,[0],[0]
"During training, our model, called ProStruct, learns to search for the most likely action sequence that is consistent with global constraints (e.g., entities cannot be destroyed after they have already been destroyed) and priors from background knowledge (e.g., turbines rarely change location).",1 Introduction,[0],[0]
"The model is trained end-to-end, with gradients backpropagating through the search path.",1 Introduction,[0],[0]
"We find that this approach significantly outperforms existing approaches on a benchmark dataset for process comprehension, mainly by avoiding the nonsensical predictions that earlier systems make.
",1 Introduction,[0],[0]
Our contributions are twofold.,1 Introduction,[0],[0]
"First, we reformulate procedural text comprehension in a novel way: as a (neural) structured prediction task.",1 Introduction,[0],[0]
This lets hard and soft constraints steer the model away from unlikely and nonsensical predictions.,1 Introduction,[0],[0]
"Second, we present a novel, end-to-end model that integrates these constraints and achieves state-of-the-art performance on an existing process comprehension dataset (Dalvi et al., 2018).",1 Introduction,[0],[0]
Our work builds off a recent body of work that focuses on using neural networks to explicitly track the states of entities while reading long texts.,2 Related Work,[0],[0]
"These works have focused on answering simple commonsense questions (Henaff et al., 2017), tracking entity states in scientific processes (Dalvi et al., 2018; Clark et al., 2018), tracking ingredients in cooking recipes (Bosselut et al., 2018), and tracking the emotional reactions and motivations of characters in simple stories (Rashkin et al., 2018).",2 Related Work,[0],[0]
"Our work extends these methods and addresses their most common issues by using background knowledge about entities to prune the set of state changes they can experience as the model reads new text.
",2 Related Work,[0],[0]
"Prior to these neural approaches, some earlier systems for process comprehension did make use of world knowledge, and motivated this work.",2 Related Work,[0],[0]
"Like us, the system ProRead (Berant et al., 2014; Scaria et al., 2013) also treated process comprehension as structure prediction, using an Integer Linear Programming (ILP) formalism to enforce global constraints (e.g., if the result of event1 is the agent of event2, then event1 must enable event2).",2 Related Work,[0],[0]
"Similarly, Kiddon et al. (2015) used corpus-based priors to guide extraction of an “action graph” from recipes.
",2 Related Work,[0],[0]
"Our work here can viewed as incorporating these approaches within the neural paradigm.
",2 Related Work,[0],[0]
"Neural methods for structure prediction have been used extensively in other areas of NLP, and we leverage these methods here.",2 Related Work,[0],[0]
"In particular we use a neural encoder-decoder architecture with beam search decoding, representative of several current state-of-the-art systems (Bahdanau et al., 2014; Wiseman and Rush, 2016; Vinyals et al., 2015).",2 Related Work,[0],[0]
"As our model’s only supervision signal comes from the final prediction (of state changes), our work is similar to previous work in semantic parsing that extracts structured outputs from text with no intermediate supervision (Krishnamurthy et al., 2017).
",2 Related Work,[0],[0]
"State tracking also appears in other areas of AI, such as dialog.",2 Related Work,[0],[0]
"A typical dialog state tracking task (e.g., the DSTC competitions) involves gradually uncovering the user’s state (e.g., their constraints, preferences, and goals for booking a restaurant), until an answer can be provided.",2 Related Work,[0],[0]
"Although this context is somewhat different (the primary goal being state discovery from weak dialog evidence), state tracking techniques originally designed for procedural text have been successfully applied in this context also (Liu and Perez, 2017).
",2 Related Work,[0],[0]
"Finally, our model learns to search over the best candidate structures using hard constraints and soft KB priors.",2 Related Work,[0],[0]
"Previous work in Neural Machine Translation (NMT) has used sets of example-specific lexical constraints in beam search decoding to only produce translations that satisfy every constraint in the set (Hokamp and Liu, 2017).",2 Related Work,[0],[0]
"In contrast, our work uses a set of global example-free constraints to prune the set of possible paths the search algorithm can explore.",2 Related Work,[0],[0]
"Simultaneously, a recent body of work has explored encoding soft constraints as an additional loss term in the training objective for dialogue (Wen et al., 2015), machine translation (Tu et al., 2016), and recipe generation (Kiddon et al., 2016).",2 Related Work,[0],[0]
Our work instead uses soft constraints to re-rank candidate structures and is not directly encoded in the loss function.,2 Related Work,[0],[0]
"We first define the general task that we are addressing, before presenting our approach.",3 Problem Definition,[0],[0]
We define the task as follows.,3.1 General Formulation,[0],[0]
"Given:
• A paragraph of procedural text S = an ordered set of sentences {s1, ..., sT } describing
a sequence of actions1 about a given topic (a word or phrase).",3.1 General Formulation,[0],[0]
"• A set of entities E = {e j} representing the en-
tities mentioned in the procedure or process.",3.1 General Formulation,[0],[0]
"Each entity e j is denoted by the set of its mentions in the paragraph, e.g., {leaf, leaves} • A set of properties P = {pk} of entities to be
tracked (e.g., location, existence)
predict:
• The state of each entity e j after each sentence sk, where an entity’s state is the values of all its properties {pk}.",3.1 General Formulation,[0],[0]
"For example, in Figure 2, the state of the water after step 2 is {location(water) = turbine; exists(water) = true}.
",3.1 General Formulation,[0],[0]
This task definition covers the tasks used in earlier procedural text comprehension datasets.,3.1 General Formulation,[0],[0]
"In bAbI tasks 1-3, a single propert (location) was tracked for a single entity throughout a paragraph (Weston et al., 2015).",3.1 General Formulation,[0],[0]
"In the state tracking task of Bosselut et al. (2018), six properties (temperature, shape, etc.) were tracked for each ingredient in the recipe.",3.1 General Formulation,[0],[0]
"In our work, we use the ProPara dataset (Dalvi et al., 2018) for both illustration and evalution.",3.2 Data,[0],[0]
"ProPara contains 488 paragraphs (3100 sentences) of a particular genre of procedural text, namely science processes (e.g., how hydroelectricity is generated).",3.2 Data,[0],[0]
"The dataset tracks two entity properties, existence and location, for all entities involved in each process, resulting in 81,000 annotations in the
1We use a broad definition of action to mean any event that changes the state of the world (including non-volitional events such as roots absorbing water).
dataset.",3.2 Data,[0],[0]
"Figure 2 gives a (simplified) example of the data, visualized as an (entity x sentence) grid, where each column tracks a different entity (time progressing vertically downwards), and each row denotes the entities’ state (existence and location) after each sentence.",3.2 Data,[0],[0]
"To evaluate the predictions, a set of templated questions whose answers can be computed from the predictions is posed (e.g., “What was destroyed, when and where?”).",3.2 Data,[0],[0]
"We now describe our model, called ProStruct.",4 Model,[0],[0]
"We approach the task by predicting the state changes that occur at each step of the text, using a vocabulary (size K) of the possible state change types that can occur given the domain and properties being modeled.",4.1 Overview,[0],[0]
"For example, for the ProPara dataset, we model K = 4 types of state change: move, create, destroy, and none.",4.1 Overview,[0],[0]
"move changes an entity’s location from one place to another, create from non-existence to a location, and destroy from a location to non-existence.",4.1 Overview,[0],[0]
"State changes can be parameterized by text spans in the paragraph, e.g., move takes a before and after location parameter.",4.1 Overview,[0],[0]
"If a parameterized state change is predicted, then the model also must predict its parameter values from the paragraph.
",4.1 Overview,[0],[0]
"Previous models for process comprehension make a sequence of local predictions about the entities’ states, one sentence at a time, maintaining a (typically neural) state at each sentence.",4.1 Overview,[0],[0]
"However, none have the ability to reverse earlier predictions should an inconsistency arise later in the sequence.",4.1 Overview,[0],[0]
ProStruct overcomes this limitation by reformulating the task as structured prediction.,4.1 Overview,[0],[0]
"To do this, it uses a neural encoder-decoder from the semantic parsing literature (Krishnamurthy et al., 2017; Yin and Neubig, 2017) combined with a search procedure that integrates soft and hard constraints for finding the best candidate structure.
",4.1 Overview,[0],[0]
"For each sentence and entity, the encoder first uses a bidirectional LSTM to encode the sentence and indicator variables identifying which entity is currently being considered (Figure 3).",4.1 Overview,[0],[0]
It then produces a (distributed) representation of the action that the sentence describes as being applied to that entity.,4.1 Overview,[0],[0]
"During decoding, the model decodes each action embedding into a distribution over possible state changes that might result, then performs
a search over the space of possible state change sequences.",4.1 Overview,[0],[0]
"Each node in the space is a partial sequence of state changes, and each edge is a prediction of the next state changes to add to the sequence (Figure 4).
",4.1 Overview,[0],[0]
"During training, the model only follows the path along the gold sequence, and optimizes a loss function that drives up the likelihood of predictions along that path (thus driving down the probabilities for alternative, incorrect paths).",4.1 Overview,[0],[0]
"At test time, the model does not have access to the gold path, and instead performs a beam search of the space to find the best candidate sequence.
",4.1 Overview,[0],[0]
"Most importantly, by mapping the state change prediction problem to structured prediction, we can perform a search over the set of candidate paths that allows us to introduce hard and soft constraints that capture commonsense knowledge.",4.1 Overview,[0],[0]
"Hard constraints are used to prune the search space (Equation 4 later), and soft constraints bias the search away from unlikely state changes via an additional term in the scoring function (Equations 5 and 6).",4.1 Overview,[0],[0]
"The encoder operates over every (st, e j) ∈ S × E pair to create an encoded representation ct j of the action described by sentence st, as applied to entity e j. In other words, we can consider the overall
action to be represented by |E| embeddings, one for each of the entities in E, encoding the action’s effects on each.",4.2 Encoder,[0],[0]
This novel feature allows us to model different effects on different entities by the same action.,4.2 Encoder,[0],[0]
"For example, a conversion action may simultaneously destroy one entity and create another.",4.2 Encoder,[0],[0]
"Figure 3 shows the encoder operating on s4: “The generator spins, and produces electricity” and e3: electricity from Figure 1.
",4.2 Encoder,[0],[0]
"Without loss of generality, we define an arbitrary sentence in S as st = {w0, ...,wI}.",4.2 Encoder,[0],[0]
Each word wi in the input sentence is encoded as a vector xi =,4.2 Encoder,[0],[0]
"[vw : ve : vv], which is the concatenation of a pre-trained word embedding vw for wi, an indicator variable ve for whether wi is a reference to the specified entity e j, and an indicator variable vv for whether wi is a verb.",4.2 Encoder,[0],[0]
"We use GloVe vectors as pre-trained embeddings (Pennington et al., 2014) and a POS tagger to extract verbs (Spacy, 2018).
",4.2 Encoder,[0],[0]
"Then, a BiLSTM is used to encode the word representations extracted above, yielding a contextualized vector hi for each embedded word xi that is the concatenated output of the backward and forward hidden states produced by the BiLSTM for word wi.",4.2 Encoder,[0],[0]
"An attention over the contextualized embeddings hi is performed to predict a distribution of weights over the sentence:
ai = hi ∗ B ∗",4.2 Encoder,[0],[0]
"hev + b (1)
ct j = I∑
i=1
ai ∗",4.2 Encoder,[0],[0]
"hi (2)
where ai is the attention weight for each contextualized embedding, ct j is the vector encoding the action for the sentence-entity pair (st, e j), B and b are learned parameters, and hev is the concatenation of the contextual embeddings of the hidden states where the entity he and verb hv are mentioned:
hev",4.2 Encoder,[0],[0]
"= [µ({hi : xi[ve] = 1}); µ({hi : xi[vv] = 1}] (3) where µ is an average function, and xi[ve] and xi[vv] correspond to the entity indicator and verb indicator variables defined above for any word wi, respectively.",4.2 Encoder,[0],[0]
The output vector ct j encodes the action at step st on entity e j.,4.2 Encoder,[0],[0]
"This vector is computed for all steps and entities, populating a grid of the actions on each entity at each step (Figure 3).",4.2 Encoder,[0],[0]
"To decode the action vectors ct j into their resulting state changes they imply, each is passed through a
feedforward layer to generate logit(π jt ), a set of logistic activations over the K possible state changes π
j t for entity e j in sentence st.",4.3 Decoder,[0],[0]
"(For ProPara, there are K = 4 possible state changes: move, create, destroy, none).",4.3 Decoder,[0],[0]
These logits denote how likely each state change π jt is for entity e j at sentence st.,4.3 Decoder,[0],[0]
"The decoder then explores the search space of possible state change sequences for the whole paragraph (Figure 4), using these likelihoods to score each visited sequence (Equation 6).
",4.3 Decoder,[0],[0]
"Let πt be the set of state changes for all entities at time t, i.e., πt = {π jt } j=1..|E|, and let Πt be the sequence of state changes from time 1 to t, i.e., Πt = [π1, ..., πt].",4.3 Decoder,[0],[0]
"Each node in the search space is a Πt, and each edge adds a πt+1 to it so that it becomes Πt+1:
",4.3 Decoder,[0],[0]
"Πt πt+1−−→ Πt+1
",4.3 Decoder,[0],[0]
"Given there are K possible values for π jt , the number of possible configurations for πt at time t (i.e., the branching factor during search) is exponential:",4.3 Decoder,[0],[0]
"K |E|, where |E| is the number of entities in the paragraph.
",4.3 Decoder,[0],[0]
"To explore this exponential number of paths, after every sentence st, we prune branches Πt → Πt+1 where Πt+1 is impossible according to background knowledge (described in Section 5.1).",4.3 Decoder,[0],[0]
"We define the boolean function over state change sequences:
allowable(Π) = 1 if hard constraints satisfied
= 0 otherwise (4) and prune paths Πt+1 where allowable(Πt+1) = 0.",4.3 Decoder,[0],[0]
"For example for ProPara, a state transition such as DESTROY → MOVE is not allowed because a hard constraint prohibits non-existent entities from being moved (Section 5.1).
",4.3 Decoder,[0],[0]
"While hard constraints remove impossible state change predictions, there may also be other state changes that are implausible with respect to background knowledge.",4.3 Decoder,[0],[0]
"For example, commonsense dictates that it is unlikely (but not impossible) for plants to be destroyed during photosynthesis.",4.3 Decoder,[0],[0]
"Accordingly, our inference procedure should discourage (but not prohibit) predicting plant destruction when reading about photosynthesis.",4.3 Decoder,[0],[0]
"To discourage unlikely state changes, we make use of soft constraints that estimate the likelihood of a particular state change associated with an entity, denoted as: P(π j|e j, topic) (5) In Section 5.2, we describe how these likelihoods can be estimated from large-scale corpora.",4.3 Decoder,[0],[0]
"We add this bias as an additional term (the second term below) when scoring the addition of πt+1 to the
sequence so far Πt: φ′(πt+1) =",4.3 Decoder,[0],[0]
"|E|∑ j=1 ( λ logit(π jt+1)
+ (1 − λ) log P(π jt+1|e j, topic) )
(6) where λ is a learned parameter controlling the degree of bias.
",4.3 Decoder,[0],[0]
"During search, when making a transition along a path from Πt to a valid Πt+1, Πt+1 is scored by accumulating normalized scores along the path:
φ(Πt+1) = φ(Πt) + φ′(πt+1)∑
",4.3 Decoder,[0],[0]
"π′t+1∈Πt+1 φ ′(π′t+1)
(7)
Continuing state transitions in this manner, when we reach the finished state (i.e., last sentence), our objective is to maximize the score of the state changes produced when reading each sentence.",4.3 Decoder,[0],[0]
"During training, we only materialize a valid node when Πt ∈ Π∗t where Π∗t is the set of nodes along the gold path.
",4.3 Decoder,[0],[0]
We use this constrained decoding to predict the state change sequence.,4.3 Decoder,[0],[0]
"For state changes that take additional parameters, e.g., in the ProPara model a move is parameterized by the before and after
locations, we also predict those parameter values during decoding.",4.3 Decoder,[0],[0]
"This is done using standard span prediction layers (inspired by BiDAF, Seo et al. (2017a)) on top of the encoded input.
",4.3 Decoder,[0],[0]
The model is trained to minimize the joint loss of predicting the correct state changes and correct state change parameters for every sentence in the paragraph:,4.3 Decoder,[0],[0]
"L = − T∑
t=1
( log P(πt)+ |E|∑ j=1 ∑ p∈param(π jt ) log P(vp jt|π jt ) )
(8) where param(π jt ) are the parameters of state change π
j t , and vp jt are the values of those parameters.",4.3 Decoder,[0],[0]
"For example, move is parameterized by before/after locations, and the 2nd loss term refers to the predicted values of those locations.
",4.3 Decoder,[0],[0]
"At test time, instead of following the gold state change path, we use beam search.",4.3 Decoder,[0],[0]
"After reading any sentence, we explore the top-k states sorted by the score φ′(πt) that satisfy hard constraints.",4.3 Decoder,[0],[0]
"This way, we predict a sequence of state changes that have maximum score while being sensible w.r.t.",4.3 Decoder,[0],[0]
hard constraints.,4.3 Decoder,[0],[0]
"By formulating procedural text comprehension as a structured prediction task, we can introduce commonsense knowledge as hard and soft constraints into the model, allowing nonsensical and unlikely predictions to be avoided, and allowing the system to recover from early mistakes.",5 Incorporating Commonsense Knowledge,[0],[0]
"Hard constraints are introduced by defining the (boolean) function over a candidate sequence of state changes:
allowable(Π) used in Equation 4.
",5.1 Hard Constraints,[0],[0]
"While this function can be defined in any way, for the ProPara application we use six constraints.",5.1 Hard Constraints,[0],[0]
"The first three below are based on basic “laws of physics” or commonsense (CS) and are universally applicable:
CS-1: An entity must exist before it can be moved or destroyed CS-2: An entity cannot be created if it already exists CS-3: An entity cannot change until it is mentioned
in the paragraph
The next three constraints are observed in the training data:
D-1:",5.1 Hard Constraints,[0],[0]
Maximum number of toggles for an entity between Exists and not Exist ≤ fmax_toggles D-2: Max fraction of entities that are changed per sentence ≤ fentities_per_sentence D-3: Max fraction of sentences in which an entity changes ≤,5.1 Hard Constraints,[0],[0]
"fsentences_per_entity
The thresholds used in D-1, D-2 and D-3 are hyperparameters that can be tuned on the dev set.",5.1 Hard Constraints,[0],[0]
"Soft constraints are introduced by defining the prior probabilities used in Equation 6: P(π j|e j, topic) that entity e j undergoes state change π j in a sentence of text about topic.",5.2 Soft Constraints,[0],[0]
"These probabilities are used to re-rank the candidate event sequences during decoding (see Equation 6).
",5.2 Soft Constraints,[0],[0]
"While any method can be used to estimate these probabilities, we describe our corpus-based approach here.",5.2 Soft Constraints,[0],[0]
"Although it was designed for ProPara, it generalizes easily to other domains, and is itself a contribution of this work.",5.2 Soft Constraints,[0],[0]
"For a given state change π j, entity e j, and topic, we first gather a corpus of Web sentences mentioning that topic (using Bing search APIs), then count the number of times x that the entity is described as undergoing that state change (e.g., that water is said to MOVE).",5.2 Soft Constraints,[0],[0]
"To determine this frequency, we first convert the sentences into a set of SRL frames (verb + roleargument pairs) using an off-the-shelf SRL labeler.",5.2 Soft Constraints,[0],[0]
"We then use an existing rulebase, derived from VerbNet, that contains rules that map SRL frames to state changes, e.g., e1/ARG0 “absorbs”/VERB e2/ARG1 =⇒ e2 MOVES (Clark et al., 2018).",5.2 Soft Constraints,[0],[0]
"Although the rules and SRL labels are incomplete and noisy, redundancy in the corpus provides some robustness when estimating the frequency x.",5.2 Soft Constraints,[0],[0]
"Finally, the observed frequency x is converted to a likelihood using a logistic transformation:
P(π j|e j, topic) = 1
1 + exp−(x−x0) (9)
where, x0 is a hyperparameter tuned on the dev set.",5.2 Soft Constraints,[0],[0]
"The commonsense constraints we have used for ProPara are general, covering the large variety of topics contain in ProPara (e.g., electricity, photosynthesis, earthquakes).",5.3 Commonsense Constraints for New Domains,[0],[0]
"However, if one wants to
apply ProStruct to other genres of procedural text (e.g., fictional text, newswire articles), or broaden the state change vocabulary, different commonsense constraints may be needed.",5.3 Commonsense Constraints for New Domains,[0],[0]
Note that our model architecture itself is agnostic to the source and quantity of hard and soft constraints.,5.3 Commonsense Constraints for New Domains,[0],[0]
"For example, one might leverage commonsense rules from existing ontologies such as SUMO (Niles and Pease, 2001) or Cyc (Lenat et al., 1985) to identify new hard constraints; and our corpus-based method could be extended to cover new state change types should the state change vocabulary be extended.",5.3 Commonsense Constraints for New Domains,[0],[0]
"We evaluate our model using the ProPara dataset, and compare against several strong baselines published with the original dataset (Dalvi et al., 2018).",6 Evaluation,[0],[0]
"Given a paragraph and set of entities as input, the task is to answer four templated questions, whose answers are deterministically computed from the state change sequence: Q1.",6.1 Evaluation setup,[0],[0]
What are the inputs to the process?,6.1 Evaluation setup,[0],[0]
Q2.,6.1 Evaluation setup,[0],[0]
What are the outputs of the process?,6.1 Evaluation setup,[0],[0]
Q3.,6.1 Evaluation setup,[0],[0]
"What conversions occur, when and where?",6.1 Evaluation setup,[0],[0]
Q4.,6.1 Evaluation setup,[0],[0]
"What movements occur, when and where?",6.1 Evaluation setup,[0],[0]
"Inputs are defined as entities that existed at the start of the process, but not at the end.",6.1 Evaluation setup,[0],[0]
"Outputs are entities that did not exist at the start, but did at the end.",6.1 Evaluation setup,[0],[0]
A conversion is when some entities are destroyed and others created.,6.1 Evaluation setup,[0],[0]
"Finally, a movement is an event where an entity changes location.
",6.1 Evaluation setup,[0],[0]
"For each process, as every question can have multiple answers, we compute a separate F1 score for each question by comparing the gold and predicted answers.",6.1 Evaluation setup,[0],[0]
"For Q1 and Q2, this is straightforward as answers are atomic (i.e., individual names of entities).",6.1 Evaluation setup,[0],[0]
"For Q3, as each answer is a 4-tuple (convert-from, convert-to, location, sentence-id), some answers may only be partially correct.",6.1 Evaluation setup,[0],[0]
"To score partial correctness, we pair gold and predicted answers by requiring the sentence-id in each to be the same, and then score each pair by the Hamming distance of their tuples.",6.1 Evaluation setup,[0],[0]
"For Q4, each answer is also a 4-tuple (entity, from-location, to-location, sentence-id), and the same procedure is applied.",6.1 Evaluation setup,[0],[0]
The four F1 scores are then macro-averaged.,6.1 Evaluation setup,[0],[0]
The total number of items to predict in the train/dev/test partitions is 7043/913/1095.,6.1 Evaluation setup,[0],[0]
"We compare results using the following process comprehension models: Recurrent Entity Networks (EntNet) (Henaff et al., 2017) are a state-of-the-art model for the bAbI tasks (Weston et al., 2015).",6.2 Baselines,[0],[0]
"The model uses a dynamic memory to maintain a representation of the world state as sentences are read, with a gated update at each step.",6.2 Baselines,[0],[0]
These states are decoded to answer questions after each sentence is read.,6.2 Baselines,[0],[0]
"Query Reduction Networks (QRN) (Seo et al., 2017b) perform a gated propagation of their hidden state across each time-step.",6.2 Baselines,[0],[0]
"Given a question, the hidden state is used to modify the query to keep pointing to the answer at each step.",6.2 Baselines,[0],[0]
"ProLocal (Dalvi et al., 2018) predicts the state changes described in individual sentences, and then uses commonsense rules of inertia to propagate state values forwards and backwards in time.",6.2 Baselines,[0],[0]
"ProGlobal (Dalvi et al., 2018) predicts states of an entity across all time steps.",6.2 Baselines,[0],[0]
"It considers the entire paragraph while predicting states for an entity, and learns to predict location spans at time-step t + 1 based on location span predictions at t.",6.2 Baselines,[0],[0]
We compare our model (which make use of world knowledge) with the four baseline systems on the ProPara dataset.,7.1 Comparison with Baselines,[0],[0]
"All models were trained on the training partition, and the best model picked based on prediction accuracy on the dev partition.",7.1 Comparison with Baselines,[0],[0]
"Table 1 shows the precision, recall, and F1 for all models on the the test partition.",7.1 Comparison with Baselines,[0],[0]
"ProStruct significantly outperforms the baselines, suggesting that world knowledge helps ProStruct avoid spurious predictions.",7.1 Comparison with Baselines,[0],[0]
"This hypothesis is supported by the fact that the ProGlobal model has the highest recall and worst precision, indicating that it is over-generating state change predictions.",7.1 Comparison with Baselines,[0],[0]
"Conversely, the ProLocal model has the highest precision, but its recall is much lower, likely because it makes predictions for individual sentences, and thus has no access to information in surrounding sentences that may suggest a state change is occurring.
",7.1 Comparison with Baselines,[0],[0]
We also examined the role of the constraint rules (both hard and soft) on efficiency.,7.1 Comparison with Baselines,[0],[0]
"With all rules disabled, the training does not complete even one epoch in more than three hours.",7.1 Comparison with Baselines,[0],[0]
"Because the number of valid states is exponential in the number of
entities, the training is particularly slow on paragraphs with many entities.",7.1 Comparison with Baselines,[0],[0]
"In contrast, with all rules enabled, training takes less than 10 minutes per epoch.",7.1 Comparison with Baselines,[0],[0]
"This illustrates that the constraints are not only contributing to the model scores, but also helping make the search efficient.",7.1 Comparison with Baselines,[0],[0]
"To explore the impact of world knowledge, we also performed two ablations on the dev set: Removing soft constraints (at both training and test time), and a partial ablation of removing hard constraints at test time only - note that hard constraints cannot be removed during training because model training time becomes prohibitively large without them, thus qualifying this second ablation.",7.2 Ablations and Analysis,[0],[0]
"Table 4 shows that F1 drops when each type of knowledge is removed, illustrating that they are helping.",7.2 Ablations and Analysis,[0],[0]
"The smaller drop for hard constraints suggests that they have primarily been incorporated into the network during training due to this ablation being partial.
",7.2 Ablations and Analysis,[0],[0]
"Qualitatively, we compared dev set examples where the predicted event sequence changed, comparing predictions made without world knowledge to those made with world knowledge.",7.2 Ablations and Analysis,[0],[0]
"For readability, we only show the event type predictions (M ,C,D, and N (shown as ""-"")) and not their fromlocation/to-location arguments.",7.2 Ablations and Analysis,[0],[0]
"If a prediction changes from X (without knowledge) to Y (with knowledge), we write this “X → Y”.",7.2 Ablations and Analysis,[0],[0]
"For cases where the prediction changed, we show incorrect predictions in red, and correct predictions in green.
",7.2 Ablations and Analysis,[0],[0]
"We first compare predictions made with and without the BK (corpus-based background knowledge, the soft constraints).",7.2 Ablations and Analysis,[0],[0]
"Table 3 shows a paragraph about the process of nuclear-powered elec-
tricity generation, in the problematic prediction of the generator moving (M) was predicted in the second to last sentence.",7.2 Ablations and Analysis,[0],[0]
"However, the background knowledge contains no examples of generators being moved.",7.2 Ablations and Analysis,[0],[0]
"As a result, it drives the probability mass away from the move (M) prediction, resulting in a no state change (N) prediction instead.
",7.2 Ablations and Analysis,[0],[0]
"Table 4 shows a second example where, without knowledge, no event was predicted for the spark entity.",7.2 Ablations and Analysis,[0],[0]
"However, BK contains many examples of sparks being created (reflecting text about this topic), shifting the probability mass towards this prediction, resulting in the correct C (create).
",7.2 Ablations and Analysis,[0],[0]
"Finally, Table 5 shows an example of a hard constraint preventing a nonsensical prediction (namely, electricity is created after it already exists).",7.2 Ablations and Analysis,[0],[0]
There are also many cases where incorrect predictions are made.,7.3 Error Analysis,[0],[0]
"The main causes are summarized below, and offer opportunities for future work.
",7.3 Error Analysis,[0],[0]
"Implicit reference is a challenge for ProStruct, where an entity affected by an event is not mentioned until a later sentence in the paragraph.",7.3 Error Analysis,[0],[0]
"For example, in the following ProPara paragraph snippet about combustion engines:
""...(3) A spark ignites fuel...(4)",7.3 Error Analysis,[0],[0]
"The pressure pushes the piston down....""
both spark and pressure are created in sentence 3, even though pressure is not mentioned until the subsequent sentence.",7.3 Error Analysis,[0],[0]
Recognizing this type of implicit mention is very hard.,7.3 Error Analysis,[0],[0]
"It is possible that BK could help in such situations, particularly if ignite were often associated with creating pressure in the context of a combustion engines, but we did not see such examples in practice.
",7.3 Error Analysis,[0],[0]
"A second challenge is coreference, in particular when different entities have similar names.",7.3 Error Analysis,[0],[0]
"For example, again for combustion, a snippet looks:
...(2) the fuel is injected... (6) the spent
fuel is ejected.",7.3 Error Analysis,[0],[0]
"(7) new fuel is injected....
",7.3 Error Analysis,[0],[0]
"Here fuel and spent fuel are the same entity, while new fuel is a different entity.",7.3 Error Analysis,[0],[0]
"Correctly tracking these references is challenging (in this case, ProStruct misidentifies (7) as describing an event on the original fuel/spent fuel).
",7.3 Error Analysis,[0],[0]
"A third, related problem is pronoun resolution.",7.3 Error Analysis,[0],[0]
"For example, in:
The sound continues to bounce off of things and produce echoes until it is totally absorbed or dissipated.
",7.3 Error Analysis,[0],[0]
"the word it confuses ProStruct, and it predicts that the echo (rather than the sound) is destroyed.",7.3 Error Analysis,[0],[0]
"We observe several such failure cases.
",7.3 Error Analysis,[0],[0]
"Finally, we observed BK retrieval failures when there was appropriate background knowledge that was expressed in a lexically different way.",7.3 Error Analysis,[0],[0]
Consider the example in Table 6 about oil formation.,7.3 Error Analysis,[0],[0]
"Without BK, the model correctly predicts that sediment is destroyed (D).",7.3 Error Analysis,[0],[0]
"However, BK has few examples of sediment being destroyed, and so biases the prediction away from this (correct) choice to an incorrect choice.",7.3 Error Analysis,[0],[0]
"Further examination of BK shows that it does in fact have knowledge about this destruction, but that is expressed using the word deposit instead (e.g., ""deposits break down"").",7.3 Error Analysis,[0],[0]
A soft (neural) means of accessing BK would help alleviate this problem.,7.3 Error Analysis,[0],[0]
"Answering questions about procedural text remains challenging, requiring models of actions and the
state changes they produce.",8 Conclusions,[0],[0]
Predictions made locally throughout the text may together be globally inconsistent or improbable.,8 Conclusions,[0],[0]
"We have shown how the predicted effects of actions can be improved by treating the task as a structured prediction problem, allowing commonsense knowledge to be injected to avoid an overall inconsistent or improbable set of predictions.",8 Conclusions,[0],[0]
"In particular, we have shown how two kinds of knowledge can be exploited: hard constraints to exclude impossible and nonsensical state changes, and soft constraints to encourage likely state changes.",8 Conclusions,[0],[0]
"The resulting system significantly outperforms previous state-of-the-art systems on a challenging dataset, and our ablations and analysis suggest that the knowledge is playing an important role.",8 Conclusions,[0],[0]
Our code is available at https://github.com/allenai/propara.,8 Conclusions,[0],[0]
We thank Oren Etzioni for his insightful feedback and encouragement for this work.,Acknowledgements,[0],[0]
We are grateful to Paul Allen whose long-term vision continues to inspire our scientific endeavors.,Acknowledgements,[0],[0]
"Comprehending procedural text, e.g., a paragraph describing photosynthesis, requires modeling actions and the state changes they produce, so that questions about entities at different timepoints can be answered.",abstractText,[0],[0]
"Although several recent systems have shown impressive progress in this task, their predictions can be globally inconsistent or highly improbable.",abstractText,[0],[0]
"In this paper, we show how the predicted effects of actions in the context of a paragraph can be improved in two ways: (1) by incorporating global, commonsense constraints (e.g., a non-existent entity cannot be destroyed), and (2) by biasing reading with preferences from large-scale corpora (e.g., trees rarely move).",abstractText,[0],[0]
"Unlike earlier methods, we treat the problem as a neural structured prediction task, allowing hard and soft constraints to steer the model away from unlikely predictions.",abstractText,[0],[0]
"We show that the new model significantly outperforms earlier systems on a benchmark dataset for procedural text comprehension (+8% relative gain), and that it also avoids some of the nonsensical predictions that earlier systems make.",abstractText,[0],[0]
Reasoning about Actions and State Changes by Injecting Commonsense Knowledge,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1173–1182, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
We present a model for describing scenes and objects by reasoning about context and listener behavior.,1 Introduction,[0],[0]
"By incorporating standard neural modules for image retrieval and language modeling into a probabilistic framework for pragmatics, our model generates rich, contextually appropriate descriptions of structured world representations.
",1 Introduction,[0],[0]
"This paper focuses on a reference game RG played between a listener L and a speaker S.
1.",1 Introduction,[0],[0]
"Reference candidates r1 and r2 are revealed to both players.
",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
"S is secretly assigned a random target t ∈ {1, 2}.
3.",1 Introduction,[0],[0]
"S produces a description d = S(t, r1, r2), which is shown to L.
4.",1 Introduction,[0],[0]
"L chooses c = L(d, r1, r2).
5.",1 Introduction,[0],[0]
"Both players win if c = t.
(RG)
Figure 1 shows an example drawn from a standard captioning dataset (Zitnick et al., 2014).
",1 Introduction,[0],[0]
"In order for the players to win, S’s description d must be pragmatic: it must be informative, fluent, concise, and must ultimately encode an understanding of L’s behavior.",1 Introduction,[0],[0]
"In Figure 1, for example, the owl is wearing a hat and the owl is sitting in the tree are both accurate descriptions of the target image, but only the second allows a human listener to succeed with high probability.",1 Introduction,[0],[0]
"RG is the focus of many papers in the computational pragmatics literature: it provides a concrete generation task while eliciting a broad range of pragmatic behaviors, including conversational implicature (Benotti and Traum, 2009) and context dependence (Smith et al., 2013).",1 Introduction,[0],[0]
"Existing computational models of pragmatics can be divided into two broad lines of work, which we term the direct and derived approaches.
",1 Introduction,[0],[0]
Direct models (see Section 2 for examples) are based on a representation of S. They learn pragmatic behavior by example.,1 Introduction,[0],[0]
"Beginning with datasets annotated for the specific task they are trying to
1173
solve (e.g. examples of humans playing RG), direct models use feature-based architectures to predict appropriate behavior without a listener representation.",1 Introduction,[0],[0]
"While quite general in principle, such models require training data annotated specifically with pragmatics in mind; such data is scarce in practice.
",1 Introduction,[0],[0]
"Derived models, by contrast, are based on a representation of L. They first instantiate a base listener L0 (intended to simulate a naı̈ve, non-pragmatic listener).",1 Introduction,[0],[0]
"They then form a reasoning speaker S1, which chooses a description that causes L0 to behave correctly.",1 Introduction,[0],[0]
Existing derived models couple hand-written grammars and hand-engineered listener models with sophisticated inference procedures.,1 Introduction,[0],[0]
"They exhibit complex behavior, but are restricted to small domains where grammar engineering is practical.
",1 Introduction,[0],[0]
The approach we present in this paper aims to capture the best aspects of both lines of work.,1 Introduction,[0],[0]
"Like direct approaches, we use machine learning to acquire a complete grounded generation model from data, without domain knowledge in the form of a hand-written grammar or hand-engineered listener model.",1 Introduction,[0],[0]
"But like derived approaches, we use this learning to construct a base model, and embed it within a higher-order model that reasons about listener responses.",1 Introduction,[0],[0]
"As will be seen, this reasoning step allows the model to make use of weaker supervision than previous data-driven approaches, while exhibiting robust behavior in a variety of contexts.
",1 Introduction,[0],[0]
Our goal is to build a derived model that scales to real-world datasets without domain engineering.,1 Introduction,[0],[0]
"Independent of the application to RG, our model also belongs to the family of neural image captioning models that have been a popular subject of recent study (Xu et al., 2015).",1 Introduction,[0],[0]
"Nevertheless, our approach appears to be:
• the first such captioning model to reason explicitly about listeners
• the first learned approach to pragmatics that requires only non-pragmatic training data
Following previous work, we evaluate our model on RG, though the general architecture could be applied to other tasks where pragmatics plays a core role.",1 Introduction,[0],[0]
"Using a large dataset of abstract scenes like the one shown in Figure 1, we run a series of games
with humans in the role of L and our system in the role of S. We find that the descriptions generated by our model result in correct interpretation 17% more often than a recent learned baseline system.",1 Introduction,[0],[0]
"We use these experiments to explore various other aspects of computational pragmatics, including tradeoffs between adequacy and fluency, and between computational efficiency and expressive power.1",1 Introduction,[0],[0]
"Direct pragmatics As an example of the direct approach mentioned in the introduction, FitzGerald et al. (2013) collect a set of human-generated referring expressions about abstract representations of sets of colored blocks.",2 Related Work,[0],[0]
"Given a set of blocks to describe, their model directly learns a maximumentropy distribution over the set of logical expressions whose denotation is the target set.",2 Related Work,[0],[0]
"Other research, focused on referring expression generation from a computer vision perspective, includes that of Mao et al. (2015) and Kazemzadeh et al. (2014).
",2 Related Work,[0],[0]
"Derived pragmatics Derived approaches, sometimes referred to as “rational speech acts” models, include those of Smith et al. (2013), Vogel et al. (2013), Golland et al. (2010), and Monroe and Potts (2015).",2 Related Work,[0],[0]
"These couple template-driven language generation with probabilistic or game-theoretic reasoning frameworks to produce contextually appropriate language: intelligent listeners reason about the behavior of reflexive speakers, and even higher-order speakers reason about these listeners.",2 Related Work,[0],[0]
"Experiments (Frank et al., 2009) show that derived approaches explain human behavior well, but both computational and representational issues restrict their application to simple reference games.",2 Related Work,[0],[0]
"They require domainspecific engineering, controlled world representations, and pragmatically annotated training data.
",2 Related Work,[0],[0]
"An extensive literature on computational pragmatics considers its application to tasks other than RG, including instruction following (Anderson et al., 1991) and discourse analysis (Jurafsky et al., 1997).
",2 Related Work,[0],[0]
"1Models, human annotations, and code to generate all tables and figures in this paper can be found at http://github.",2 Related Work,[0],[0]
"com/jacobandreas/pragma.
",2 Related Work,[0],[0]
"Representing language and the world In addition to the pragmatics literature, the approach proposed in this paper relies extensively on recently developed tools for multimodal processing of language and unstructured representations like images.",2 Related Work,[0],[0]
"These includes both image retrieval models, which select an image from a collection given a textual description (Socher et al., 2014), and neural conditional language models, which take a content representation and emit a string (Donahue et al., 2015).",2 Related Work,[0],[0]
Our goal is to produce a model that can play the role of the speaker S in RG.,3 Approach,[0],[0]
"Specifically, given a target referent (e.g. scene or object) r and a distractor r′, the model must produce a description d that uniquely identifies r. For training, we have access to a set of non-contrastively captioned referents {(ri, di)}: each training description di is generated for its associated referent ri in isolation.",3 Approach,[0],[0]
There is no guarantee that di would actually serve as a good referring expression for ri in any particular context.,3 Approach,[0],[0]
"We must thus use the training data to ground language in referent representations, but rely on reasoning to produce pragmatics.
",3 Approach,[0],[0]
Our model architecture is compositional and hierarchical.,3 Approach,[0],[0]
"We begin in Section 3.2 by describing a collection of “modules”: basic computational primitives for mapping between referents, descriptions, and reference judgments, here implemented as linear operators or small neural networks.",3 Approach,[0],[0]
"While these modules appear as substructures in neural architectures for a variety of tasks, we put them to novel use in constructing a reasoning pragmatic speaker.
",3 Approach,[0],[0]
"Section 3.3 describes how to assemble two base models: a literal speaker, which maps from referents to strings, and a literal listener, which maps from strings to reference judgments.",3 Approach,[0],[0]
"Section 3.4 describes how these base models are used to implement a top-level reasoning speaker: a learned, probabilistic, derived model of pragmatics.",3 Approach,[0],[0]
"Formally, we take a description d to consist of a sequence of words d1, d2, . . .",3.1 Preliminaries,[0],[0]
", dn, drawn from a vocabulary of known size.",3.1 Preliminaries,[0],[0]
"For encoding, we also assume access to a feature representation f(d) of the
FCFC
ngram features desc ref features referent
(a) referent encoder Er (b) description encoder Ed
sentence (for purposes of this paper, a vector of indicator features on n-grams).",3.1 Preliminaries,[0],[0]
"These two views—as a sequence of words di and a feature vector f(d)— form the basis of module interactions with language.
",3.1 Preliminaries,[0],[0]
Referent representations are similarly simple.,3.1 Preliminaries,[0],[0]
Because the model never generates referents—only conditions on them and scores them—a vectorvalued feature representation of referents suffices.,3.1 Preliminaries,[0],[0]
Our approach is completely indifferent to the nature of this representation.,3.1 Preliminaries,[0],[0]
"While the experiments in this paper use a vector of indicator features on objects and actions present in abstract scenes (Figure 1), it would be easy to instead use pre-trained convolutional representations for referring to natural images.",3.1 Preliminaries,[0],[0]
"As with descriptions, we denote this feature representation f(r) for referents.",3.1 Preliminaries,[0],[0]
"All listener and speaker models are built from a kit of simple building blocks for working with multimodal representations of images and text:
1.",3.2 Modules,[0],[0]
a referent encoder Er 2.,3.2 Modules,[0],[0]
a description encoder Ed 3.,3.2 Modules,[0],[0]
a choice ranker R 4.,3.2 Modules,[0],[0]
"a referent describer D
These are depicted in Figure 2, and specified more formally below.",3.2 Modules,[0],[0]
"All modules are parameterized by weight matrices, written with capital lettersW1,W2, etc.; we refer to the collection of weights for all modules together as W .
",3.2 Modules,[0],[0]
"Encoders The referent and description encoders produce a linear embedding of referents and descriptions in a common vector space.
",3.2 Modules,[0],[0]
"Referent encoder: Er(r) =W1f(r) (1)
Description encoder: Ed(d) =W2f(d) (2)
",3.2 Modules,[0],[0]
"Choice ranker The choice ranker takes a string encoding and a collection of referent encodings, assigns a score to each (string, referent) pair, and then transforms these scores into a distribution over referents.",3.2 Modules,[0],[0]
"We write R(ei|e−i, ed) for the probability of choosing i in contrast to the alternative; for example, R(e2|e1, ed) is the probability of answering “2” when presented with encodings e1 and e2.
",3.2 Modules,[0],[0]
"s1 = w > 3 ρ(W4e1 +W5ed) s2 = w > 3 ρ(W4e2 +W5ed)
R(ei|e−i, ed) = esi
es1 + es2 (3)
(Here ρ is a rectified linear activation function.)
",3.2 Modules,[0],[0]
Referent describer The referent describer takes an image encoding and outputs a description using a (feedforward) conditional neural language model.,3.2 Modules,[0],[0]
"We express this model as a distribution p(dn+1|dn, d<n, er), where dn is an indicator feature on the last description word generated, d<n is a vector of indicator features on all other words previously generated, and er is a referent embedding.",3.2 Modules,[0],[0]
"This is a “2-plus-skip-gram” model, with local positional history features, global position-independent history features, and features on the referent being described.",3.2 Modules,[0],[0]
"To implement this probability distribution, we first use a multilayer perceptron to compute a vector of scores s (one si for each vocabulary item): s = W6ρ(W7[dn, d<n, ei]).",3.2 Modules,[0],[0]
"We then normalize these to obtain probabilities: pi = esi/ ∑ j e
sj .",3.2 Modules,[0],[0]
"Finally, p(dn+1|dn, d<n, er) = pdn+1 .",3.2 Modules,[0],[0]
"From these building blocks, we construct a pair of base models.",3.3 Base models,[0],[0]
"The first of these is a literal listener
L0, which takes a description and a set of referents, and chooses the referent most likely to be described.",3.3 Base models,[0],[0]
This serves the same purpose as the base listener in the general derived approach described in the introduction.,3.3 Base models,[0],[0]
"We additionally construct a literal speaker S0, which takes a referent in isolation and outputs a description.",3.3 Base models,[0],[0]
"The literal speaker is used for efficient inference over the space of possible descriptions, as described in Section 3.4.",3.3 Base models,[0],[0]
"L0 is, in essence, a retrieval model, and S0 is neural captioning model.
",3.3 Base models,[0],[0]
"Both of the base models are probabilistic: L0 produces a distribution over referent choices, and S0 produces a distribution over strings.",3.3 Base models,[0],[0]
"They are depicted with shaded backgrounds in Figure 3.
",3.3 Base models,[0],[0]
Literal listener,3.3 Base models,[0],[0]
"Given a description d and a pair of candidate referents r1 and r2, the literal listener embeds both referents and passes them to the ranking module, producing a distribution over choices i.
ed = Ed(d)
e1 = Er(r1)
e2 = Er(r2)
pL0(i|d, r1, r2)",3.3 Base models,[0],[0]
"= R(ei|e−i, ed) (4)
",3.3 Base models,[0],[0]
"That is, pL0(1|d, r1, r2) = R(e1|e2, ed) and viceversa.",3.3 Base models,[0],[0]
"This model is trained contrastively, by solving the following optimization problem:
max W
∑
j
log pL0(1|dj , rj , r′) (5)
Here r′ is a random distractor chosen uniformly from the training set.",3.3 Base models,[0],[0]
"For each training example (ri, di), this objective attempts to maximize the probability that the model chooses ri as the referent of di over a random distractor.
",3.3 Base models,[0],[0]
"This contrastive objective ensures that our approach is applicable even when there is not a naturally-occurring source of target–distractor pairs, as previous work (Golland et al., 2010; Monroe and Potts, 2015) has required.",3.3 Base models,[0],[0]
"Note that this can also be viewed as a version of the loss described by Smith and Eisner (2005), where it approximates a likelihood objective that encourages L0 to prefer ri to every other possible referent simultaneously.
",3.3 Base models,[0],[0]
"Literal speaker As in the figure, the literal speaker is obtained by composing a referent encoder with a describer, as follows:
e = Er(f(r))
pS0(d|r) = Dd(d|e)
",3.3 Base models,[0],[0]
"As with the listener, the literal speaker should be understood as producing a distribution over strings.",3.3 Base models,[0],[0]
"It is trained by maximizing the conditional likelihood of captions in the training data:
max W
∑
i
log pS0(di|ri)",3.3 Base models,[0],[0]
"(6)
These base models are intended to be the minimal learned equivalents of the hand-engineered speakers and hand-written grammars employed in previous derived approaches (Golland et al., 2010).",3.3 Base models,[0],[0]
The neural encoding/decoding framework implemented by the modules in the previous subsection provides a simple way to map from referents to descriptions and descriptions to judgments without worrying too much about the details of syntax or semantics.,3.3 Base models,[0],[0]
"Past work amply demonstrates that neural conditional language models are powerful enough to generate fluent and accurate (though not necessarily pragmatic) descriptions of images or structured representations (Donahue et al., 2015).",3.3 Base models,[0],[0]
"As described in the introduction, the general derived approach to pragmatics constructs a base listener and then selects a description that makes it behave
correctly.",3.4 Reasoning model,[0],[0]
"Since the assumption that listeners will behave deterministically is often a poor one, it is common for such derived approaches to implement probabilistic base listeners, and maximize the probability of correct behavior.
",3.4 Reasoning model,[0],[0]
The neural literal listener L0 described in the preceding section is such a probabilistic listener.,3.4 Reasoning model,[0],[0]
"Given a target i and a pair of candidate referents r1 and r2, it is natural to specify the behavior of a reasoning speaker as simply:
max d pL0(i|d, r1, r2) (7)
",3.4 Reasoning model,[0],[0]
"At a first glance, the only thing necessary to implement this model is the representation of the literal listener itself.",3.4 Reasoning model,[0],[0]
"When the set of possible utterances comes from a fixed vocabulary (Vogel et al., 2013) or a grammar small enough to exhaustively enumerate (Smith et al., 2013) the operation maxd in Equation 7 is practical.
",3.4 Reasoning model,[0],[0]
"For our purposes, however, we would like the model to be capable of producing arbitrary utterances.",3.4 Reasoning model,[0],[0]
"Because the score pL0 is produced by a discriminative listener model, and does not factor along the words of the description, there is no dynamic program that enables efficient inference over the space of all strings.
",3.4 Reasoning model,[0],[0]
We instead use a sampling-based optimization procedure.,3.4 Reasoning model,[0],[0]
The key ingredient here is a good proposal distribution from which to sample sentences likely to be assigned high weight by the model listener.,3.4 Reasoning model,[0],[0]
For this we turn to the literal speaker S0 described in the previous section.,3.4 Reasoning model,[0],[0]
"Recall that this speaker produces a distribution over plausible descriptions of isolated images, while ignoring pragmatic context.",3.4 Reasoning model,[0],[0]
"We can use it as a source of candidate descriptions, to be reweighted according to the expected behavior of L0.",3.4 Reasoning model,[0],[0]
"The full specification of a sampling neural reasoning speaker is as follows:
1.",3.4 Reasoning model,[0],[0]
"Draw samples d1, . . .",3.4 Reasoning model,[0],[0]
dn ∼ pS0(·|ri).,3.4 Reasoning model,[0],[0]
2.,3.4 Reasoning model,[0],[0]
"Score samples: pk = pL0(i|dk, r1, r2).",3.4 Reasoning model,[0],[0]
3.,3.4 Reasoning model,[0],[0]
"Select dk with k = argmax pk.
While primarily to enable efficient inference, we can also use the literal speaker to serve a different purpose: “regularizing” model behavior towards choices that are adequate and fluent, rather than exploiting strange model behavior.",3.4 Reasoning model,[0],[0]
"Past work has re-
stricted the set of utterances in a way that guarantees fluency.",3.4 Reasoning model,[0],[0]
"But with an imperfect learned listener model, and a procedure that optimizes this listener’s judgments directly, the speaker model might accidentally discover the kinds of pathological optima that neural classification models are known to exhibit (Goodfellow et al., 2014)—in this case, sentences that cause exactly the right response from L0, but no longer bear any resemblance to human language use.",3.4 Reasoning model,[0],[0]
"To correct this, we allow the model to consider two questions: as before, “how likely is it that a listener would interpret this sentence correctly?”, but additionally “how likely is it that a speaker would produce it?”
",3.4 Reasoning model,[0],[0]
"Formally, we introduce a parameter λ that trades off between L0 and S0, and take the reasoning model score in step 2 above to be:
pk = pS0(dk|ri)λ · pL0(i|dk, r1, r2)1−λ (8)
This can be viewed as a weighted joint probability that a sentence is both uttered by the literal speaker and correctly interpreted by the literal listener, or alternatively in terms of Grice’s conversational maxims (Grice, 1970): L0 encodes the maxims of quality and relation, ensuring that the description contains enough information for L to make the right choice, while S0 encodes the maxim of manner, ensuring that the description conforms with patterns of human language use.",3.4 Reasoning model,[0],[0]
"Responsibility for the maxim of quantity is shared: L0 ensures that the model doesn’t say too little, and S0 ensures that the model doesn’t say too much.",3.4 Reasoning model,[0],[0]
We evaluate our model on the reference game RG described in the introduction.,4 Evaluation,[0],[0]
"In particular, we construct instances of RG using the Abstract Scenes Dataset introduced by Zitnick and Parikh (2013).",4 Evaluation,[0],[0]
Example scenes are shown in Figure 1 and Figure 4.,4 Evaluation,[0],[0]
The dataset contains pictures constructed by humans and described in natural language.,4 Evaluation,[0],[0]
"Scene representations are available both as rendered images and as feature representations containing the identity and location of each object; as noted in Section 3.1, we use this feature set to produce our referent representation f(r).",4 Evaluation,[0],[0]
"This dataset was previously used for a variety of language and vision tasks (e.g. Or-
tiz et al. (2015), Zitnick et al. (2014)).",4 Evaluation,[0],[0]
"It consists of 10,020 scenes, each annotated with up to 6 captions.
",4 Evaluation,[0],[0]
"The abstract scenes dataset provides a more challenging version of RG than anything we are aware of in the existing computational pragmatics literature, which has largely used the TUNA corpus of isolated object descriptions (Gatt et al., 2007) or small synthetic datasets (Smith et al., 2013).",4 Evaluation,[0],[0]
"By contrast, the abstract scenes data was generated by humans looking at complex images with numerous objects, and features grammatical errors, misspellings, and a vocabulary an order of magnitude larger than TUNA.",4 Evaluation,[0],[0]
"Unlike previous work, we have no prespecified indomain grammar, and no direct supervision of the relationship between scene features and lexemes.
",4 Evaluation,[0],[0]
We perform a human evaluation using Amazon Mechanical Turk.,4 Evaluation,[0],[0]
We begin by holding out a development set and a test set; each held-out set contains 1000 scenes and their accompanying descriptions.,4 Evaluation,[0],[0]
"For each held-out set, we construct two sets of 200 paired (target, distractor) scenes: All, with up to four differences between paired scenes, and Hard, with exactly one difference between paired scenes.",4 Evaluation,[0],[0]
"(We take the number of differences between scenes to be the number of objects that appear in one scene but not the other.)
",4 Evaluation,[0],[0]
We report two evaluation metrics.,4 Evaluation,[0],[0]
"Fluency is determined by showing human raters isolated sentences, and asking them to rate linguistic quality on a scale from 1–5.",4 Evaluation,[0],[0]
"Accuracy is success rate at RG: as in Figure 1, humans are shown two images and a model-generated description, and asked to select the image matching the description.
",4 Evaluation,[0],[0]
"In the remainder of this section, we measure the tradeoff between fluency and accuracy that results from different mixtures of the base models (Section 4.1), measure the number of samples needed to obtain good performance from the reasoning listener (Section 4.2), and attempt to approximate the reasoning listener with a monolithic “compiled” listener (Section 4.3).",4 Evaluation,[0],[0]
In Section 4.4 we report final accuracies for our approach and baselines.,4 Evaluation,[0],[0]
"To measure the performance of the base models, we draw 10 samples djk for a subset of 100 pairs (r1,j , r2,j) in the Dev-All set.",4.1 How good are the base models?,[0],[0]
We collect human fluency and accuracy judgments for each of the 1000 total samples.,4.1 How good are the base models?,[0],[0]
"This allows us to conduct a post-hoc search over values of λ: for a range of λ, we compute the average accuracy and fluency of the highest scoring sample.",4.1 How good are the base models?,[0],[0]
"By varying λ, we can view the tradeoff between accuracy and fluency that results from interpolating between the listener and speaker model—setting λ = 0 gives samples from pL0, and λ = 1 gives samples from pS0.
Figure 5 shows the resulting accuracy and fluency for various values of λ.",4.1 How good are the base models?,[0],[0]
It can be seen that relying entirely on the listener gives the highest accuracy but degraded fluency.,4.1 How good are the base models?,[0],[0]
"However, by adding only a very small weight to the speaker model, it is possible to achieve near-perfect fluency without a substantial decrease in accuracy.",4.1 How good are the base models?,[0],[0]
Example sentences for an individual reference game are shown in Figure 5; increasing λ causes captions to become more generic.,4.1 How good are the base models?,[0],[0]
"For the remaining experiments in this paper, we take λ = 0.02, finding that this gives excellent performance on both metrics.
",4.1 How good are the base models?,[0],[0]
"On the development set, λ = 0.02 results in an average fluency of 4.8 (compared to 4.8 for the literal speaker λ = 1).",4.1 How good are the base models?,[0],[0]
"This high fluency can be confirmed by inspection of model samples (Figure 4).
",4.1 How good are the base models?,[0],[0]
We thus focus on accuracy or the remainder of the evaluation.,4.1 How good are the base models?,[0],[0]
Next we turn to the computational efficiency of the reasoning model.,4.2 How many samples are needed?,[0],[0]
"As in all sampling-based inference, the number of samples that must be drawn from the proposal is of critical interest—if too many samples are needed, the model will be too slow to use in practice.",4.2 How many samples are needed?,[0],[0]
"Having fixed λ = 0.02 in the preceding section, we measure accuracy for versions of the reasoning model that draw 1, 10, 100, and 1000 samples.",4.2 How many samples are needed?,[0],[0]
Results are shown in Table 1.,4.2 How many samples are needed?,[0],[0]
We find that gains continue up to 100 samples.,4.2 How many samples are needed?,[0],[0]
"Because they do not require complicated inference procedures, direct approaches to pragmatics typically enjoy better computational efficiency than derived ones.",4.3 Is reasoning necessary?,[0],[0]
"Having built an accurate derived speaker, can we bootstrap a more efficient direct speaker?
",4.3 Is reasoning necessary?,[0],[0]
"To explore this, we constructed a “compiled” speaker model as follows:",4.3 Is reasoning necessary?,[0],[0]
"Given reference candidates r1 and r2 and target t, this model produces embeddings e1 and e2, concatenates them together into a “contrast embedding”",4.3 Is reasoning necessary?,[0],[0]
"[et, e−t], and then feeds this whole embedding into a string decoder module.",4.3 Is reasoning necessary?,[0],[0]
"Like S0, this model generates captions without the need for discriminative rescoring; unlike S0, the contrast embedding means this model can in principle learn to produce pragmatic captions, if given access to pragmatic training data.",4.3 Is reasoning necessary?,[0],[0]
"Since no such training data exists, we train the compiled model on
captions sampled from the reasoning speaker itself.
",4.3 Is reasoning necessary?,[0],[0]
This model is evaluated in Table 3.,4.3 Is reasoning necessary?,[0],[0]
"While the distribution of scores is quite different from that of the base model (it improves noticeably over S0 on scenes with 2–3 differences), the overall gain is negligible (the difference in mean scores is not significant).",4.3 Is reasoning necessary?,[0],[0]
The compiled model significantly underperforms the reasoning model.,4.3 Is reasoning necessary?,[0],[0]
"These results suggest either that the reasoning procedure is not easily approximated by a shallow neural network, or that example descriptions of randomly-sampled training pairs (which are usually easy to discriminate) do not provide a strong enough signal for a reflex learner to recover pragmatic behavior.",4.3 Is reasoning necessary?,[0],[0]
"Based on the following sections, we keep λ = 0.02 and use 100 samples to generate predictions.",4.4 Final evaluation,[0],[0]
"We evaluate on the test set, comparing this Reasoning model S1 to two baselines: Literal, an image captioning model trained normally on the abstract scene captions (corresponding to our L0), and Contrastive, a model trained with a soft contrastive objective, and previously used for visual referring expression generation (Mao et al., 2015).
",4.4 Final evaluation,[0],[0]
Results are shown in Table 2.,4.4 Final evaluation,[0],[0]
"Our reasoning model outperforms both the literal baseline and previous work by a substantial margin, achieving an improvement of 17% on all pairs set and 15% on hard
pairs.2 Figures 4 and 6 show various representative descriptions from the model.",4.4 Final evaluation,[0],[0]
"We have presented an approach for learning to generate pragmatic descriptions about general referents, even without training data collected in a pragmatic context.",5 Conclusion,[0],[0]
"Our approach is built from a pair of simple neural base models, a listener and a speaker, and a high-level model that reasons about their outputs in order to produce pragmatic descriptions.",5 Conclusion,[0],[0]
"In an evaluation on a standard referring expression game, our model’s descriptions produced correct behavior in human listeners significantly more often than existing baselines.
",5 Conclusion,[0],[0]
"It is generally true of existing derived approaches to pragmatics that much of the system’s behavior requires hand-engineering, and generally true of direct approaches (and neural networks in particular) that training is only possible when supervision is available for the precise target task.",5 Conclusion,[0],[0]
"By synthesizing these two approaches, we address both problems, obtaining pragmatic behavior without domain knowledge and without targeted training data.",5 Conclusion,[0],[0]
"We believe that this general strategy of using reasoning to obtain novel contextual behavior from neural decoding models might be more broadly applied.
",5 Conclusion,[0],[0]
"2 For comparison, a model with hand-engineered pragmatic behavior—trained using a feature representation with indicators on only those objects that appear in the target image but not the distractor—produces an accuracy of 78% and 69% on all and hard development pairs respectively.",5 Conclusion,[0],[0]
"In addition to performing slightly worse than our reasoning model, this alternative approach relies on the structure of scene representations and cannot be applied to more general pragmatics tasks.",5 Conclusion,[0],[0]
"We present a model for contrastively describing scenes, in which context-specific behavior results from a combination of inferencedriven pragmatics and learned semantics.",abstractText,[0],[0]
"Like previous learned approaches to language generation, our model uses a simple featuredriven architecture (here a pair of neural “listener” and “speaker” models) to ground language in the world.",abstractText,[0],[0]
"Like inference-driven approaches to pragmatics, our model actively reasons about listener behavior when selecting utterances.",abstractText,[0],[0]
"For training, our approach requires only ordinary captions, annotated without demonstration of the pragmatic behavior the model ultimately exhibits.",abstractText,[0],[0]
"In human evaluations on a referring expression game, our approach succeeds 81% of the time, compared to 69% using existing techniques.",abstractText,[0],[0]
Reasoning about Pragmatics with Neural Listeners and Speakers,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2032–2043 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Commonsense knowledge is fundamental in artificial intelligence, and has long been a key component in natural language understanding and human-like reasoning.",1 Introduction,[0],[0]
"For example, to understand the relation between sentences “Mary walked to a restaurant” and “She ordered some foods”, we need commonsense knowledge such as “Mary is a girl”, “restaurant sells food”, etc.",1 Introduction,[0],[0]
"The task of understanding natural language with commonsense knowledge is usually referred as commonsense machine comprehension, which has been a
hot topic in recent years (Richardson et al., 2013; Weston et al., 2015; Zhang et al., 2016).
",1 Introduction,[0],[0]
"Recently, RocStories (Mostafazadeh et al., 2016a), a commonsense machine comprehension task, has attached many researchers’ attention due to its significant difference from previous machine comprehension tasks.",1 Introduction,[0],[0]
"RocStories focuses on reasoning with implicit commonsense knowledge, rather than matching with explicit information in given contexts.",1 Introduction,[0],[0]
"In this task, a system requires choosing a sentence, namely hypothesis, to complete a given commonsense story, called as premise document.",1 Introduction,[0],[0]
Table 1 shows two examples.,1 Introduction,[0],[0]
RocStories proposes a challenging benchmark task for evaluating commonsensebased language understanding.,1 Introduction,[0],[0]
"As investigated by Mostafazadeh et al.(2016a), this dataset does not have any boundary cases and thus results in 100% human performance.
",1 Introduction,[0],[0]
"Commonsense machine comprehension, however, is an natural ability for human but could be very challenging for computers.",1 Introduction,[0],[0]
"In general, any world knowledge whatsoever in the reader’s mind can affect the choice of an interpretation (Dahlgren et al., 1989).",1 Introduction,[0],[0]
"That is, a person can learn any heterogeneous commonsense knowledge and make inference of given information based on all knowledge in his mind.",1 Introduction,[0],[0]
"For example, to choose the right hypothesis for the first premise document in Table 1, we needs the event narrative knowledge that “X does a thorough job” will lead to “commends X”, rather than “fire X”.",1 Introduction,[0],[0]
"Besides, people can further confirm their judgement based on the sentimental coherence between “finish super early” and “job well done”.",1 Introduction,[0],[0]
"Furthermore, in the second example, even both hypothesises are consistent with the premise document in both event and sentimental facets, we can still infer the right answer easily using the commonsense knowledge that “puppy” is a dog, meanwhile “kitten” is a cat.
2032
",1 Introduction,[0],[0]
"In recent years, many methods have been proposed for commonsense machine comprehension.",1 Introduction,[0],[0]
"However, these methods mostly either focus on matching explicit information in given texts (Weston et al., 2014; Wang and Jiang, 2016a,b; Wang et al., 2016b; Zhao et al., 2017), or paid attention to one specific kind of commonsense knowledge, such as event temporal relation (Chambers and Jurafsky, 2008; Modi and Titov, 2014; Pichotta and Mooney, 2016b; Hu et al., 2017) and event causality (Do et al., 2011; Radinsky et al., 2012; Hashimoto et al., 2015; Gui et al., 2016).",1 Introduction,[0],[0]
"As discussed above, it is obvious that commonsense machine comprehension problem is far from settled by considering only explicit or a single kind of commonsense knowledge.",1 Introduction,[0],[0]
"To achieve humanlike comprehension and reasoning, there exist two main challenges:",1 Introduction,[0],[0]
kinds of implicit knowledge that commonsense machine comprehension needs.,1) How to mine and represent different,[0],[0]
"For example, to complete the first example in Table 1, we need a system equipped with the event narrative knowledge that “commends X” can be inferred from “X does a thorough job”, as well as the sentiment coherent knowledge that “insubordination” and “finish super early” are sentimental incoherent.",1) How to mine and represent different,[0],[0]
commonsense knowledge.,2) How to reason with various kinds of,[0],[0]
"As shown above, knowledge that reasoning process needs varies for different contexts.",2) How to reason with various kinds of,[0],[0]
"For human-like commonsense machine comprehension, a system should take various kinds of knowledge into consideration, decide what knowledge will be utilized in a specific reasoning contexts, and make the final decision by taking all utilized knowledge into consideration.
",2) How to reason with various kinds of,[0],[0]
"To address the above problems, this paper proposes a new commonsense reasoning approach, which can mine and exploit heterogeneous knowledge for commonsense machine comprehension.",2) How to reason with various kinds of,[0],[0]
"Specifically, we first mine different kinds of knowledge from raw text and relevant knowl-
edge base, including event narrative knowledge, entity semantic knowledge and sentiment coherent knowledge.",2) How to reason with various kinds of,[0.9536901188815703],"['First, models should incorporate more semantic information from discourse structure and utterance understanding besides semantics from referring expressions.']"
"These heterogeneous knowledge are encoded into a uniform representation – inference rules between elements under different kinds of relations, with an inference cost for each rule.",2) How to reason with various kinds of,[0],[0]
"Then we design a rule selection model using attention mechanism, modeling which inference rules will be applied in a specific reasoning context.",2) How to reason with various kinds of,[0],[0]
"Finally, we propose a multi-knowledge reasoning model, which measures the reasoning distance from a premise document to a hypothesis as the expected cost sum of all inference rules applied in the reasoning process.
",2) How to reason with various kinds of,[0],[0]
"By modeling and exploiting heterogeneous knowledge during commonsense reasoning, our method can achieve more accurate and more robust performance than traditional methods.",2) How to reason with various kinds of,[0],[0]
"Furthermore, our method is a general framework, which can be extended to incorporate new knowledge easily.",2) How to reason with various kinds of,[0],[0]
"Experiments show that our method achieves a 13.7% accuracy improvement on the standard RocStories dataset, a significant improvement over previous work.",2) How to reason with various kinds of,[0],[0]
"As described above, various knowledge can be exploited for machine comprehension.",2 Commonsense Knowledge Acquisition for Machine Comprehension,[0],[0]
"In this section, we describe how to mine different knowledge from different sources.",2 Commonsense Knowledge Acquisition for Machine Comprehension,[0],[0]
"Specifically, we mine three types of commonly used commonsense knowledge, including: 1)Event narrative knowledge, which captures temporal and causal relations between events; 2)Entity semantic knowledge, which captures semantic relations between entities; 3)Sentiment coherent knowledge, which captures sentimental coherence between elements.
",2 Commonsense Knowledge Acquisition for Machine Comprehension,[0],[0]
"In this paper, we represent commonsense knowledge as a set of inference rules given in the form of X f−→ Y : s, which means that element Y can be inferred from element X under relation f , with an inference cost s. An element can stand
for either event, entity or sentiment, and this paper represents elements using lemmatized nouns, verbs and adjectives.",2 Commonsense Knowledge Acquisition for Machine Comprehension,[0],[0]
"The lexical element representation can also be easily extended to structural representation, like the one in (Chambers and Jurafsky, 2008), if needed.",2 Commonsense Knowledge Acquisition for Machine Comprehension,[0],[0]
"However, in auxiliary experiments we found that using structural elements results in severe sparseness and noises which in turn will hurt the reasoning performance.",2 Commonsense Knowledge Acquisition for Machine Comprehension,[0],[0]
"Therefore, we think an individual work is needed to solve it.",2 Commonsense Knowledge Acquisition for Machine Comprehension,[0],[0]
Table 2 demonstrates several examples of inference rules.,2 Commonsense Knowledge Acquisition for Machine Comprehension,[0],[0]
"In following, we describe how to mine different types of inference rules.",2 Commonsense Knowledge Acquisition for Machine Comprehension,[0],[0]
"Event narrative knowledge captures structured temporal and casual knowledge about stereotypical event sequences, which is fundamental for commonsense machine comprehension.",2.1 Mining Event Narrative Knowledge,[0],[0]
"For example, we can infer “X ordered some foods” from “X walked to a restaurant” using event narrative knowledge.",2.1 Mining Event Narrative Knowledge,[0],[0]
"Previous work (Chambers and Jurafsky, 2008; Rudinger et al., 2015) proves that event narrative knowledge can be mined from raw texts unsupervisedly.",2.1 Mining Event Narrative Knowledge,[0],[0]
"So we propose two models to encode this knowledge using inference rules.
",2.1 Mining Event Narrative Knowledge,[0],[0]
"The first one is based on ordered PMI, which is also proposed by Rudinger et al. (2015).",2.1 Mining Event Narrative Knowledge,[0],[0]
"Given two element e1 and e2, this model calculates the cost of inference rule e1
narrative−−−−−−→ e2 as: cost(e1 −→ e2) = −log",2.1 Mining Event Narrative Knowledge,[0],[0]
"C(e1, e2)
",2.1 Mining Event Narrative Knowledge,[0],[0]
"C(e1, ∗), C(∗, e2) (1)
HereC(e1, e2) is the order sensitive count that element e1 occurs before element e2 in different sentences of the same document.
",2.1 Mining Event Narrative Knowledge,[0],[0]
"The second model is a variant of the skip-gram model (Mikolov et al., 2013).",2.1 Mining Event Narrative Knowledge,[0],[0]
The goal of this model is to find element representations which can accurately predict relevant elements in sentences afterwards.,2.1 Mining Event Narrative Knowledge,[0],[0]
"Formally, given n asymmetric pairs of elements (e11, e 1 2), (e 2 1, e 2 2), ...., (e n 1 , e n 2 ) identified from training data, the objective of our model is to maximize the average log proba-
bility",2.1 Mining Event Narrative Knowledge,[0],[0]
1n,2.1 Mining Event Narrative Knowledge,[0],[0]
∑n i=1,2.1 Mining Event Narrative Knowledge,[0],[0]
logP (e i 2|ei1).,2.1 Mining Event Narrative Knowledge,[0],[0]
And the probability P (e2|e1) is defined using the softmax function: P (e2|e1) ∝ exp(v′e2,2.1 Mining Event Narrative Knowledge,[0],[0]
"T ve1) (2) where ve and v′e are “antecedent” and “consequent” vector representation of element e, respectively.",2.1 Mining Event Narrative Knowledge,[0],[0]
We use the negative inner product −v′e2Tve1 as the cost of inference rule e1 skip−gram−−−−−−−→ e2.,2.1 Mining Event Narrative Knowledge,[0],[0]
"Entities, often serving as event participants or environment variables, are important components of commonsense stories.",2.2 Mining Entity Semantic Knowledge,[0],[0]
"Intuitively, an entity in hypothesis is reasonable if we can identify semantic relations between it and some parts of premise document.",2.2 Mining Entity Semantic Knowledge,[0],[0]
"For example, if a premise document contains “Starbucks”, then “coffeehouse” and “latte” will be reasonable entities in hypothesis since “Starbucks” is a possible coreference of “coffeehouse” and it is semantically related to “latte”.
",2.2 Mining Entity Semantic Knowledge,[0],[0]
"Specifically, we identify mainly two kinds of semantic relations between entities for commonsense machine comprehension:
1) Coreference relation, which indicates that two elements refer to the same entity in environment.",2.2 Mining Entity Semantic Knowledge,[0],[0]
"In stories, besides to pronouns, an entity is often referred using its hypernyms, e.g, the second example in Table 1 uses “dog” to refer to “puppy”.",2.2 Mining Entity Semantic Knowledge,[0],[0]
"Motivated by this observation, we mine coreference knowledge between elements using Wordnet (Kilgarriff and Fellbaum, 2000): X coref−−−→",2.2 Mining Entity Semantic Knowledge,[0],[0]
"Y is an inference rule with cost 0 if X and Y are lemmas in the same Wordnet synset, or with hyponymy relation in Wordnet.",2.2 Mining Entity Semantic Knowledge,[0],[0]
"Otherwise, the cost of inference rules between this element-pair under this relation will be 1.
2) Associative relation, which captures the semantic relatedness between two entities, i.e., “starbucks” → “latte”, “restaurant” → “food”, etc.",2.2 Mining Entity Semantic Knowledge,[0],[0]
"This paper mines associative relations between entities from Wikipedia1, using the method proposed by Milne and Witten(2008).",2.2 Mining Entity Semantic Knowledge,[0],[0]
"Specifically, given two entities e1 and e2, we compute the semantic distance dist(e1, e2) between them as:
dist(e1, e2) =",2.2 Mining Entity Semantic Knowledge,[0],[0]
"log(max(|E1|, |E2|)− log(|E1⋂E2|))",2.2 Mining Entity Semantic Knowledge,[0],[0]
"log(|W |)− log(min(|E1|, |E2|))
(3)
where E1 and E2 are the sets of all entities that link to these two entities in Wikipedia respectively,
1https://www.wikipedia.org/
and W is the entire Wikipedia.",2.2 Mining Entity Semantic Knowledge,[0],[0]
"We set the cost of inference rule e1
associative−−−−−−−→ e2 as dist(e1, e2).",2.2 Mining Entity Semantic Knowledge,[0],[0]
"Sentiment is one of the central and pervasive aspects of human experience (Ortony et al., 1990).",2.3 Mining Sentiment Coherent Knowledge,[0],[0]
"It plays an important role in commonsense stories, i.e., a reasonable hypothesis should be sentimental coherent with its premise document.",2.3 Mining Sentiment Coherent Knowledge,[0],[0]
"In this paper, we mine sentiment coherence rules using SentiWordnet (Baccianella et al., 2010), in which each synset of Wordnet is assigned with three sentiment scores: positivity, negativity and objectivity.
",2.3 Mining Sentiment Coherent Knowledge,[0],[0]
"Concretely, to identify sentimental coherence rule between two element e1 and e2, we first compute the positivity, negativity and objectivity scores of every element by averaging the scores of all synsets it’s in, then we identify an element to be subjective if its objectivity score is smaller than a threshold, and the distance between its positivity and negativity score is greater than a threshold.",2.3 Mining Sentiment Coherent Knowledge,[0],[0]
"Finally, for an inference rule e1
senti−−−→ e2, we set its cost to 1 if e1 and e2 are both subjective and have opposite sentimental polarity, to -1",2.3 Mining Sentiment Coherent Knowledge,[0],[0]
"if they are both subjective and their sentimental polarity are the same, and to 0 for other cases.",2.3 Mining Sentiment Coherent Knowledge,[0],[0]
"For example, we will mine inference rules “good senti−−−→ happy : −1”, “perfect senti−−−→ sad : 1” and “young senti−−−→ happy : 0”.",2.3 Mining Sentiment Coherent Knowledge,[0],[0]
"So far, we have extracted many inference rules under different relations.",2.4 Metric Learning to Calibrate Cost Measurement,[0],[0]
"However, because we extract them from different sources and estimate their costs using different measurements, the cost metrics of these rules may not be consistent with each other.",2.4 Metric Learning to Calibrate Cost Measurement,[0],[0]
"To exploit different types of inference rules in a unified framework, we here propose a metric learning based method to calibrate their costs.
",2.4 Metric Learning to Calibrate Cost Measurement,[0],[0]
"Given an input distance function, a metric learning method constructs a new distance function which is “better” than the original one with supervision regarding an ideal distance (Kulis, 2012).",2.4 Metric Learning to Calibrate Cost Measurement,[0],[0]
"To calibrate inference rule cost, we add a nonlinear layer to the original cost sr of inference rule r under relation f :
cr = sigmoid(wfsr + bf ) (4)
",2.4 Metric Learning to Calibrate Cost Measurement,[0],[0]
"Here cr is the metric-unified inference cost of inference rule r, wf and bf are calibration parame-
ters for inference rules of relation f .",2.4 Metric Learning to Calibrate Cost Measurement,[0],[0]
We use sigmoid function in order to normalize costs into 0 to 1.,2.4 Metric Learning to Calibrate Cost Measurement,[0],[0]
Calibration parameters will be trained along with other parameters in our model.,2.4 Metric Learning to Calibrate Cost Measurement,[0],[0]
See Section 3.4 for detail.,2.4 Metric Learning to Calibrate Cost Measurement,[0],[0]
One important linguistic phenomenon needs to specifically consider is negation.,2.5 Dealing with Negation,[0],[0]
"Here we discuss how to solve negation in our model.
",2.5 Dealing with Negation,[0],[0]
We use ¬X to represent an element X modified by a negation word (the existence of negation is detected using dependency relations).,2.5 Dealing with Negation,[0],[0]
"Under event narrative relation and sentiment coherent relation, the existence of negation will reverse the conclusion.",2.5 Dealing with Negation,[0],[0]
"So we add three additional negation related inference rules for rule X f−→ Y : s under these relations, including ¬X f−→ Y : 1 − s, X
f−→ ¬Y : 1 − s and ¬X f−→ ¬Y : s. Here s is the calibrated cost of the original inference rule.",2.5 Dealing with Negation,[0],[0]
"For entity semantic relations, we just ignore the negation since it will not affect the inference under these relations.",2.5 Dealing with Negation,[0],[0]
This section describes how to leverage acquired knowledge for commonsense machine comprehension.,3 Machine Comprehension via Commonsense Reasoning,[0],[0]
We first define how to infer from a premise document to a hypothesis using inference rules.,3 Machine Comprehension via Commonsense Reasoning,[0],[0]
Then we model how to choose inference rules for a specific reasoning context.,3 Machine Comprehension via Commonsense Reasoning,[0],[0]
"Finally, we describe how to measure the reasoning distance from a premise document to a hypothesis by summarizing the costs of all possible inferences.",3 Machine Comprehension via Commonsense Reasoning,[0],[0]
"Given a premise document D = {d1, d2, ..., dm} containing m elements, a hypothesis H = {h1, h2, ..., hn} containing n elements, a valid inference R from D to H is a set of inference rules that all elements in H can be inferred from one element inD using one and only one rule inR.",3.1 Inference from Premise Document to Hypothesis,[0],[0]
"This definition means that all elements in H should be covered by consequents of inference rules in R, as well as all antecedents of inference rules in R should come from D. Figure 1 shows some inference examples, where (a), (b) and (d) are valid inferences, but (c) is not a valid inference because its rules can not cover all elements in hypothesis.
",3.1 Inference from Premise Document to Hypothesis,[0],[0]
"By the definition, the size of R and the size of H are equal.",3.1 Inference from Premise Document to Hypothesis,[0],[0]
"So we use ri to denote the inference rule in R that applied to derive element hi in H , i.e., R = {r1, r2, ..., rn}.
",3.1 Inference from Premise Document to Hypothesis,[0],[0]
"Based on the above definition, we can naturally define the cost of an inference R as the cost sum of all inference rules in R. In Figure 1, the cost for inference (a) is 0.0 + 0.1 + 0.1 = 0.2, and for inference (d) is 0.0 + 0.8 = 0.8.",3.1 Inference from Premise Document to Hypothesis,[0],[0]
"Obviously, there exist multiple valid inferences for a premise document and a hypothesis.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"For example, in Figure 1, both (a) and (b) are valid inferences for the same premise document and hypothesis.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"To identify whether a hypothesis is reasonable, we need to consider all possible inferences.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"However, in human reasoning process, not all inference rules have the same possibility to be applied, because the more reasonable inference will be proposed more likely.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"In Figure 1, inference (a) should have a higher probability than inference (b) because it is more reasonable to infer “foods” from “a restaurant” with associative relation, rather than from “walked to” with narrative relation.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"Besides, the possibility of proposing an inference should not depend on its cost, e.g., inference (d) should have high possibility to be proposed despite its high cost, because we often infer event “sleep” from another event using inference rules under narrative relation.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"As examples mentioned above, the “cost” measures the “correctness” of an inference rule.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"A rule with low cost is more likely to be “reasonable”, and a rule with high cost is more likely to be a contradiction with commonsense.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"On the other hand, the “possibility” should measure how likely a rule will be applied in a given context, which does not depend on the “cost”
but on the nature of the rule and the given context.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"Motivated by above observations, we endow each inference a probability P (R|D,H), indicating the possibility thatR is chosen to infer hypothesis H from premise document D. For simplicity, we assume that each element in hypothesis is independently inferred using individual inference rule, then P (R|D,H) can be written as:
P (R|D,H) = n∏
i=1
P (ri|D,H) (5)
",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
= n∏ i=1,3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"P (ri|D,hi) (6)
= n∏ i=1",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"m∑ j=1 P (ri, dj |D,hi) (7)
",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
Equation (7) clearly shows how an inference rule is selected given the premise document D and the element hi in hypothesis.,3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
It depends on which element dj inD will be selected and which relation f will be used to infer hi from dj .,3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"We then refactor the probability P (ri, dj |D,hi) to be:
P (ri, dj |D,hi) = {
0 , antecedent(ri) 6=",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"dj g(hi, dj , f(ri);D) , otherwise (8)
Here f(r) is the relation type of inference rule r, and g(h, d, f ;D) is defined as:
g(h, d, f ;D) = s(h, d)a(h, f)a(d, f)∑ f∈F ∑ d∈D s(h, d)a(h, f)a(d, f) (9) Here F denotes all relation types of inference rules, s(e1, e2) is a matching function between two elements e1 and e2, measuring by cosine similarity based on GoogleNews word2vec (Mikolov et al., 2013).",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"And a(e, f) is an attention function measuring how likely an element e will be involved with rules under relation f :
a(e, f) =",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"vf T tanh(Wfe + bf ) (10)
where vf ∈ RK ,",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"Wf ∈ RK×F and bf ∈ RK are attention parameters of relation f , and e ∈ RF is the feature vector of element e.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
Here K is the size of attention hidden layer and F is the dimension of feature vector.,3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"We consider three types of features, as shown in Table 3.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"Using attention mechanism, our method models the possibility that an inference rule is applied during the inference from a premise document to a hypothesis by considering the relatedness between elements and knowledge category, as well as the relatedness between two elements, which make it able to select the most reasonable inference rules to derive each part of the hypothesis.",3.2 Modeling Inference Probability using Attention Mechanism,[0],[0]
"Given a premise document, this section shows how to measure whether a hypothesis is coherent using above inference model.",3.3 Reasoning Distance Between Premise Document and Hypothesis,[0],[0]
"Given all valid inferences from D to H and the probability P (R|D,H) of selecting inference R to infer H from D, we measure the reasoning distance L(D → H) as the expected cost sum of all valid inferences:
L(D → H) = EP (R|D,H)[cost(R)]",3.3 Reasoning Distance Between Premise Document and Hypothesis,[0],[0]
"(11)
= EP (R|D,H)[ n∑
i=1
cost(ri)] (12)
Then using Equation (6) and Equation (7), we can further rewrite the equation into:
L(D → H) = ∑ R [ n∏ i=1",3.3 Reasoning Distance Between Premise Document and Hypothesis,[0],[0]
"P (ri|D,hi)] ·",3.3 Reasoning Distance Between Premise Document and Hypothesis,[0],[0]
"[ n∑ i=1 cost(ri)] (13)
= n∑ i=1",3.3 Reasoning Distance Between Premise Document and Hypothesis,[0],[0]
"P (ri|D,hi) · cost(ri) (14)
",3.3 Reasoning Distance Between Premise Document and Hypothesis,[0],[0]
= n∑ i=1,3.3 Reasoning Distance Between Premise Document and Hypothesis,[0],[0]
"m∑ j=1 P (ri, dj |D,hi) · cost(ri) (15)
",3.3 Reasoning Distance Between Premise Document and Hypothesis,[0],[0]
"Equation (15) shows that in our framework, the final cost of inferring the element hi in the hypothesis is the expected cost of all valid inference rules which can derive hi from one element in the premise document.",3.3 Reasoning Distance Between Premise Document and Hypothesis,[0],[0]
"Following Huang et al. (2013), our model measures the posterior probability of choosing hypothesis H as the answer of premise document D through a softmax function:
P (H|D) =",3.4 Model Learning,[0],[0]
"exp(−γL(D → H))∑ H′∈HD exp(−γL(D → H ′)
(16)
",3.4 Model Learning,[0],[0]
"Here HD is all candidate hypothesises for D, and γ is a positive smoothing factor.",3.4 Model Learning,[0],[0]
"We train our model by maximizing the likelihood of choosing right
hypothesis H+ for D: L(θ) = −log",3.4 Model Learning,[0],[0]
"∏
(D,H+)
P (H+|D) (17)
where θ is the parameter set of our model, including calibration parameters in Section 2.4 and attention parameters in Section 3.2.",3.4 Model Learning,[0],[0]
L(θ) is differentiable so we can estimate θ using any gradientbased optimization algorithm.,3.4 Model Learning,[0],[0]
Data Preparation.,4.1 Experimental Settings,[0],[0]
"We evaluated our approach on the Test Set Spring 2016 of RocStories, which consists of 1871 commonsense stories, with each story has two candidate story endings.",4.1 Experimental Settings,[0],[0]
"Because stories in the training set of RocStories do not contain wrong hypothesis, and our model has a compact size of parameters, we estimated the parameters of our model using the Validation Set Spring 2016 of RocStories with 1871 commonsense stories.
",4.1 Experimental Settings,[0],[0]
"We mined event narrative knowledge from the Training Set Spring 2016 of RocStories, which consists of 45502 commonsense stories.",4.1 Experimental Settings,[0],[0]
"We performed lemmatisation, part of speech annotation, named entity tagging, and dependency parsing using Stanford CoreNLP toolkits (Manning et al., 2014).",4.1 Experimental Settings,[0],[0]
"We used the Jan. 30, 2010 English version of Wikipedia and processed it according to the method described by Hu et al. (2008).
",4.1 Experimental Settings,[0],[0]
Model Training.,4.1 Experimental Settings,[0],[0]
"We used normalized initialization (Glorot and Bengio, 2010) to initialize attention parameters in our model.",4.1 Experimental Settings,[0],[0]
"For calibration parameters, we initialized all wf to 1 and bf to 0.",4.1 Experimental Settings,[0],[0]
The model parameters were trained using minibatch stochastic gradient descent algorithm.,4.1 Experimental Settings,[0],[0]
"As for hyper-parameters, we set the batch size as 32, the learning rate as 1, the dimension of attention hidden layer K as 32, and the smoothing factor γ as 0.5.
Baselines.",4.1 Experimental Settings,[0],[0]
"We compared our approach with following three baselines:
1) Narrative Event Chain (Chambers and Jurafsky, 2008), which scores hypothesis using PMI scores between events.",4.1 Experimental Settings,[0],[0]
"We used a simplified version of the original model by using only verbs as event, ignoring the dependency relation between verbs and their participants.",4.1 Experimental Settings,[0],[0]
"We found such a simplified version achieved better performance than its original one whose performance was reported in (Mostafazadeh et al., 2016a).
2)",4.1 Experimental Settings,[0],[0]
"Deep Structured Semantic Model (DSS-
M) (Huang et al., 2013), which achieved the best performance on RocStories as reported by Mostafazadeh et al.(2016a).",4.1 Experimental Settings,[0],[0]
"This model measures the reasoning score between a premise document D and a hypothesis H by calculating the cosine similarity between the overall vector representations of D and H , and do not consider any other task-relevant knowledge.",4.1 Experimental Settings,[0],[0]
"proposed by Pichotta and Mooney(2015), which transforms all events and their arguments into a sequence and predict next events and arguments using a Long Short-Term Memory network.",3) Recurrent Neural Network(RNN) Model,[0],[0]
"We used the average generating probability of all elements in H as the reasoning score, and choose the hypothesis with largest reasoning score as the system answer.",3) Recurrent Neural Network(RNN) Model,[0],[0]
Table 4 shows the results.,4.2 Overall Performance,[0],[0]
"From this table, we can see that:
1)",4.2 Overall Performance,[0],[0]
Our model outperforms all baselines significantly.,4.2 Overall Performance,[0],[0]
"Compared with baselines, the accuracy improvement on test set is at least 13.7%.",4.2 Overall Performance,[0],[0]
"This demonstrates the effectiveness of our model by mining and exploiting heteregenous knowledge.
",4.2 Overall Performance,[0],[0]
2),4.2 Overall Performance,[0],[0]
The event narrative knowledge only is insufficient for commonsense machine comprehension.,4.2 Overall Performance,[0],[0]
"Compared with Narrative Event Chain Model, our model achieves a 16.3% accuracy improvement by considering richer commonsense knowledge, rather than only narrative event knowledge.
",4.2 Overall Performance,[0],[0]
3),4.2 Overall Performance,[0],[0]
It is necessary to distinguish different kinds of commonsense relations for machine comprehension and commonsense reasoning.,4.2 Overall Performance,[0],[0]
"Compared with DSSM and RNN, which model all relations between two elements using a single semantic similarity score, our model achieves significant accuracy improvements by modeling, distinguishing and selecting different types of commonsense relations between different kinds of elements.",4.2 Overall Performance,[0],[0]
"To investigate the effect of different kinds of knowledge in our model, we conducted two groups of experiments.
",4.3 Effects of Different Knowledge,[0],[0]
The first group of experiments was conducted using only one kind of knowledge at a time in our model.,4.3 Effects of Different Knowledge,[0],[0]
Table 5 shows the results.,4.3 Effects of Different Knowledge,[0],[0]
"We can see that using a single kind of knowledge is insufficient for commonsense machine comprehension: all single-knowledge settings cannot achieve competitive performance to the all-knowledge setting.
",4.3 Effects of Different Knowledge,[0],[0]
The second group of experiments was conducted to investigate whether different knowledge can complement each other.,4.3 Effects of Different Knowledge,[0],[0]
"We conducted experiments by removing one kind of knowledge from our final model at a time, and investigate the change of accuracy.
",4.3 Effects of Different Knowledge,[0],[0]
Table 6 shows the results.,4.3 Effects of Different Knowledge,[0],[0]
We can find that removing any kind of knowledge will reduce the accuracy.,4.3 Effects of Different Knowledge,[0],[0]
"This verified that all kinds of knowledge containing unique complementary information, which cannot be covered by other types of knowledge.",4.3 Effects of Different Knowledge,[0],[0]
"This section investigates the effect of inference rule selection probability, and whether our attention mechanism can effectively model the possibility of inference rule selection.",4.4 Effect of Inference Probability,[0],[0]
"We compared our method with following two heuristic settings:
1) Minimum Cost Mechanism, which measures the reasoning distance by only selecting the inference rule with minimum cost for each hypothesis element.
2) Average Cost Mechanism, which measures the reasoning distance by setting equal probabilities to all inference rules that can infer a hypothesis element from a premise document element.
",4.4 Effect of Inference Probability,[0],[0]
Table 7 show the results.,4.4 Effect of Inference Probability,[0],[0]
"We can see that: 1) the minimum cost mechanism cannot achieve competitive performance, we believe this is because the selection of rules should not depend on the cost of them, and considering all valid inferences is critical for reasoning; 2) our attention mechanism can effectively model the inference rule selection possibility.",4.4 Effect of Inference Probability,[0],[0]
"Compared with the average cost mechanism, our method achieved a 6.36% accuracy improvement.",4.4 Effect of Inference Probability,[0],[0]
This also verified the necessity of an effective inference rule probability model.,4.4 Effect of Inference Probability,[0],[0]
This section investigates the effect of special handling of negation mentioned in Section 2.5.,4.5 Effect of Negation Rules,[0],[0]
"To investigate the necessity of negation rules proposed in our model, we conducted experiments by removing all negation rules from original system, and investigate the change of accuracy.
",4.5 Effect of Negation Rules,[0],[0]
Table 8 show the results.,4.5 Effect of Negation Rules,[0],[0]
"We can see that removing negation rules will significantly drop the system performance, which confirm the effectiveness of our proposed negation rules.",4.5 Effect of Negation Rules,[0],[0]
Endowing computers with the ability of understanding commonsense story has long a goal of natural language processing.,5 Related Work,[0],[0]
There exist two big challenges: 1)Matching explicit information in the given context; 2)Incorporating implicit commonsense knowledge into human-like reasoning process.,5 Related Work,[0],[0]
"Previous machine comprehension tasks (Richardson et al., 2013; Weston et al., 2015; Hermann et al., 2015; Rajpurkar et al.,
2016) mainly focus on the first challenge, leading their solutions focusing on semantic matching between texts (Weston et al., 2014; Kumar et al., 2015; Narasimhan and Barzilay, 2015; Smith et al., 2015; Sukhbaatar et al., 2015; Hill et al., 2015; Wang et al., 2015, 2016a; Cui et al., 2016; Trischler et al., 2016a,b; Kadlec et al., 2016; Kobayashi et al., 2016; Wang and Jiang, 2016b), but ignore the second issues.",5 Related Work,[0],[0]
"One notable task is SNLI (Bowman et al., 2015), which considers entailment between two sentences.",5 Related Work,[0],[0]
"This task, however, only provides shallow context and thus needs a few kinds of implicit knowledge (Rocktäschel et al., 2015; Wang and Jiang, 2016a; Angeli et al., 2016; Wang et al., 2016b; Parikh et al., 2016; Henderson and Popa, 2016; Zhao et al., 2017).
",5 Related Work,[0],[0]
"Realizing that story understanding needs commonsense knowledge, many researches have been proposed to learn structural event knowledge.",5 Related Work,[0],[0]
Chambers and Jurafsky (2008) first proposed an unsupervised approach to learn partially ordered sets of events from raw text.,5 Related Work,[0],[0]
"Many expansions have been introduced later, including unsupervisedly learning narrative schemas and scripts (Chambers and Jurafsky, 2009; Regneri et al., 2011), event schemas and frames (Chambers and Jurafsky, 2011; Balasubramanian et al., 2013; Sha et al., 2016; Huang et al., 2016; Mostafazadeh et al., 2016b), and some generative models to learn latent structures of event knowledge (Cheung et al., 2013; Chambers, 2013; Bamman et al., 2014; Nguyen et al., 2015).",5 Related Work,[0],[0]
"Another direction for learning event-centred knowledge is causality identification (Do et al., 2011; Radinsky et al., 2012; Berant et al., 2014; Hashimoto et al., 2015; Gui et al., 2016), which tried to identify the causality relation in text.
",5 Related Work,[0],[0]
"For reasoning over these knowledge, Jans et al. (2012) extend introduced skip-grams for collecting statistics.",5 Related Work,[0],[0]
"Further improvements include incorporating more information and more complicated models (Radinsky and Horvitz, 2013; Modi and Titov, 2014; Ahrendt and Demberg, 2016).",5 Related Work,[0],[0]
"Recent researches tried to solve event prediction problem by transforming it into an language modeling paradigm (Pichotta and Mooney, 2014, 2015, 2016a,b; Rudinger et al., 2015; Hu et al., 2017).
",5 Related Work,[0],[0]
"The principal difference between previous work and our method is that we not only take various kinds of implicit commonsense knowledge into consideration, but also provide a highly
extensible framework to exploit these kinds of knowledge for commonsense machine comprehension.",5 Related Work,[0],[0]
"We also notice the recent progress in RocStories (Mostafazadeh et al., 2017).",5 Related Work,[0],[0]
"Rather than inferring a possible ending generated from document, recent systems solve this task by discriminatively comparing two candidates.",5 Related Work,[0],[0]
"This enables very strong stylistic features being added explicitly (Schwartz et al., 2017; Bugert et al., 2017) or implicitly (Schenk and Chiarcos, 2017), which can select hypothesis without any consideration of given document.",5 Related Work,[0],[0]
"Also, some augmentation strategies are introduced to produce more training data (Roemmele and Gordon, 2017; Mihaylov and Frank, 2017; Bugert et al., 2017).",5 Related Work,[0],[0]
These methods are dataset-sensitive and are not the main concentration of our paper.,5 Related Work,[0],[0]
"This paper proposes a commonsense machine comprehension method, which performs effective commonsense reasoning by taking heterogenous knowledge into consideration.",6 Conclusions and Future Work,[0],[0]
"Specifically, we mine commonsense knowledge from heterogeneous knowledge sources and simultaneously exploit them by proposing a highly extensible multiknowledge reasoning framework.",6 Conclusions and Future Work,[0],[0]
"Experiment results shown that our method surpasses baselines by a large margin.
",6 Conclusions and Future Work,[0],[0]
"Currently, there are little labeled training instances for commonsense machine comprehension, for future work we want to address this issue by developing semi-supervised or unsupervised approaches.",6 Conclusions and Future Work,[0],[0]
"This work is supported by the National Natural Science Foundation of China under Grants no. 61433015 and 61572477, the National High Technology Development 863 Program of China under Grants no. 2015AA015405, and the Young Elite Scientists Sponsorship Program no.",Acknowledgments,[0],[0]
YESS20160177.,Acknowledgments,[0],[0]
"Moreover, we sincerely thank the reviewers for their valuable comments.",Acknowledgments,[0],[0]
Reasoning with commonsense knowledge is critical for natural language understanding.,abstractText,[0],[0]
"Traditional methods for commonsense machine comprehension mostly only focus on one specific kind of knowledge, neglecting the fact that commonsense reasoning requires simultaneously considering different kinds of commonsense knowledge.",abstractText,[0],[0]
"In this paper, we propose a multi-knowledge reasoning method, which can exploit heterogeneous knowledge for commonsense machine comprehension.",abstractText,[0],[0]
"Specifically, we first mine different kinds of knowledge (including event narrative knowledge, entity semantic knowledge and sentiment coherent knowledge) and encode them as inference rules with costs.",abstractText,[0],[0]
"Then we propose a multiknowledge reasoning model, which selects inference rules for a specific reasoning context using attention mechanism, and reasons by summarizing all valid inference rules.",abstractText,[0],[0]
Experiments on RocStories show that our method outperforms traditional models significantly.,abstractText,[0],[0]
Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1010–1020 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1010
Sarcasm is a sophisticated speech act which commonly manifests on social communities such as Twitter and Reddit. The prevalence of sarcasm on the social web is highly disruptive to opinion mining systems due to not only its tendency of polarity flipping but also usage of figurative language. Sarcasm commonly manifests with a contrastive theme either between positive-negative sentiments or between literal-figurative scenarios. In this paper, we revisit the notion of modeling contrast in order to reason with sarcasm. More specifically, we propose an attention-based neural model that looks inbetween instead of across, enabling it to explicitly model contrast and incongruity. We conduct extensive experiments on six benchmark datasets from Twitter, Reddit and the Internet Argument Corpus. Our proposed model not only achieves stateof-the-art performance on all datasets but also enjoys improved interpretability.",text,[0],[0]
"Sarcasm, commonly defined as ‘An ironical taunt used to express contempt’, is a challenging NLP problem due to its highly figurative nature.",1 Introduction,[0],[0]
"The usage of sarcasm on the social web is prevalent and can be frequently observed in reviews, microblogs (tweets) and online forums.",1 Introduction,[0],[0]
"As such, the battle against sarcasm is also regularly cited as one of the key challenges in sentiment analysis and opinion mining applications (Pang et al., 2008).",1 Introduction,[0],[0]
"Hence, it is both imperative and intuitive that effective sarcasm detectors can bring about numerous benefits to opinion mining applications.
",1 Introduction,[0],[0]
Sarcasm is often associated to several linguistic phenomena such as (1) an explicit contrast between sentiments or (2) disparity between the conveyed emotion and the author’s situation (context).,1 Introduction,[0],[0]
"Prior work has considered sarcasm to be a contrast between a positive and negative sentiment (Riloff et al., 2013).",1 Introduction,[0],[0]
"Consider the following examples:
1.",1 Introduction,[0],[0]
"I absolutely love to be ignored!
2.",1 Introduction,[0],[0]
Yay!!!,1 Introduction,[0],[0]
"The best thing to wake up to is my neighbor’s drilling.
",1 Introduction,[0],[0]
3.,1 Introduction,[0],[0]
"Perfect movie for people who can’t fall asleep.
",1 Introduction,[0],[0]
"Given the examples, we make a crucial observation - Sarcasm relies a lot on the semantic relationships (and contrast) between individual words and phrases in a sentence.",1 Introduction,[0],[0]
"For instance, the relationships between phrases {love, ignored}, {best, drilling} and {movie, asleep} (in the examples above) richly characterize the nature of sarcasm conveyed, i.e., word pairs tend to be contradictory and more often than not, express a juxtaposition of positive and negative terms.",1 Introduction,[0],[0]
"This concept is also explored in (Joshi et al., 2015) in which the authors refer to this phenomena as ‘incongruity’.",1 Introduction,[0],[0]
"Hence, it would be useful to capture the relationships between selected word pairs in a sentence, i.e., looking in-between.
",1 Introduction,[0],[0]
"State-of-the-art sarcasm detection systems mainly rely on deep and sequential neural networks (Ghosh and Veale, 2016; Zhang et al., 2016).",1 Introduction,[0],[0]
"In these works, compositional encoders such as gated recurrent units (GRU) (Cho et al., 2014) or long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) are often employed, with the input document being parsed one word at a time.",1 Introduction,[0],[0]
This has several shortcomings for the sarcasm detection task.,1 Introduction,[0],[0]
"Firstly, there is
no explicit interaction between word pairs, which hampers its ability to explicitly model contrast, incongruity or juxtaposition of situations.",1 Introduction,[0],[0]
"Secondly, it is difficult to capture long-range dependencies.",1 Introduction,[0],[0]
"In this case, contrastive situations (or sentiments) which are commonplace in sarcastic language may be hard to detect with simple sequential models.
",1 Introduction,[0],[0]
"To overcome the weaknesses of standard sequential models such as recurrent neural networks, our work is based on the intuition that modeling intra-sentence relationships can not only improve classification performance but also pave the way for more explainable neural sarcasm detection methods.",1 Introduction,[0],[0]
"In other words, our key intuition manifests itself in the form of an attention-based neural network.",1 Introduction,[0],[0]
"While the key idea of most neural attention mechanisms is to focus on relevant words and sub-phrases, it merely looks across and does not explicitly capture word-word relationships.",1 Introduction,[0],[0]
"Hence, it suffers from the same shortcomings as sequential models.
",1 Introduction,[0],[0]
"In this paper, our aim is to combine the effectiveness of state-of-the-art recurrent models while harnessing the intuition of looking in-between.",1 Introduction,[0],[0]
We propose a multi-dimensional intra-attention recurrent network that models intricate similarities between each word pair in the sentence.,1 Introduction,[0],[0]
"In other words, our novel deep learning model aims to capture ‘contrast’ (Riloff et al., 2013) and ‘incongruity’ (Joshi et al., 2015) within end-to-end neural networks.",1 Introduction,[0],[0]
"Our model can be thought of selftargeted co-attention (Xiong et al., 2016), which allows our model to not only capture word-word relationships but also long-range dependencies.",1 Introduction,[0],[0]
"Finally, we show that our model produces interpretable attention maps which aid in the explainability of model outputs.",1 Introduction,[0],[0]
"To the best of our knowledge, our model is the first attention model that can produce explainable results in the sarcasm detection task.
",1 Introduction,[0],[0]
"Briefly, the prime contributions of this work can be summarized as follows:
• We propose a new state-of-the-art method for sarcasm detection.",1 Introduction,[0],[0]
"Our proposed model, the Multi-dimensional Intra-Attention Recurrent Network (MIARN) is strongly based on the intuition of compositional learning by leveraging intra-sentence relationships.",1 Introduction,[0],[0]
"To the best of our knowledge, none of the existing state-of-the-art models considered exploiting
intra-sentence relationships, solely relying on sequential composition.
",1 Introduction,[0],[0]
"• We conduct extensive experiments on multiple benchmarks from Twitter, Reddit and the Internet Argument Corpus.",1 Introduction,[0],[0]
"Our proposed MIARN achieves highly competitive performance on all benchmarks, outperforming existing state-of-the-art models such as GRNN (Zhang et al., 2016) and CNN-LSTM-DNN (Ghosh and Veale, 2016).",1 Introduction,[0],[0]
Sarcasm is a complex linguistic phenomena that have long fascinated both linguists and NLP researchers.,2 Related Work,[0],[0]
"After all, a better computational understanding of this complicated speech act could potentially bring about numerous benefits to existing opinion mining applications.",2 Related Work,[0],[0]
"Across the rich history of research on sarcasm, several theories such as the Situational Disparity Theory (Wilson, 2006) and the Negation Theory (Giora, 1995) have emerged.",2 Related Work,[0],[0]
"In these theories, a common theme is a motif that is strongly grounded in contrast, whether in sentiment, intention, situation or context.",2 Related Work,[0],[0]
"(Riloff et al., 2013) propagates this premise forward, presenting an algorithm strongly based on the intuition that sarcasm arises from a juxtaposition of positive and negative situations.",2 Related Work,[0],[0]
"Naturally, many works in this area have treated the sarcasm detection task as a standard text classification problem.",2.1 Sarcasm Detection,[0],[0]
"An extremely comprehensive overview can be found at (Joshi et al., 2017).",2.1 Sarcasm Detection,[0],[0]
"Feature engineering approaches were highly popular, exploiting a wide diverse range of features such as syntactic patterns (Tsur et al., 2010), sentiment lexicons (González-Ibánez et al., 2011), ngram (Reyes et al., 2013), word frequency (Barbieri et al., 2014), word shape and pointedness features (Ptáček et al., 2014), readability and flips (Rajadesingan et al., 2015), etc.",2.1 Sarcasm Detection,[0],[0]
"Notably, there have been quite a reasonable number of works that propose features based on similarity and contrast.",2.1 Sarcasm Detection,[0],[0]
"(Hernández-Farı́as et al., 2015) measured the Wordnet based semantic similarity between words.",2.1 Sarcasm Detection,[0],[0]
"(Joshi et al., 2015) proposed a framework based on explicit and implicit incongruity, utilizing features based on positive-negative patterns.",2.1 Sarcasm Detection,[0],[0]
"(Joshi et al., 2016) proposed similarity features based on word embeddings.",2.1 Sarcasm Detection,[0],[0]
Deep learning based methods have recently garnered considerable interest in many areas of NLP research.,2.2 Deep Learning for Sarcasm Detection,[0],[0]
"In our problem domain, (Zhang et al., 2016) proposed a recurrent-based model with a gated pooling mechanism for sarcasm detection on Twitter.",2.2 Deep Learning for Sarcasm Detection,[0],[0]
"(Ghosh and Veale, 2016) proposed a convolutional long-short-term memory network (CNN-LSTM-DNN) that achieves state-of-the-art performance.
",2.2 Deep Learning for Sarcasm Detection,[0],[0]
"While our work focuses on document-only sarcasm detection, several notable works have proposed models that exploit personality information (Ghosh and Veale, 2017) and user context (Amir et al., 2016).",2.2 Deep Learning for Sarcasm Detection,[0],[0]
"Novel methods for sarcasm detection such as gaze / cognitive features (Mishra et al., 2016, 2017) have also been explored.",2.2 Deep Learning for Sarcasm Detection,[0],[0]
"(Peled and Reichart, 2017) proposed a novel framework based on neural machine translation to convert a sequence from sarcastic to non-sarcastic.",2.2 Deep Learning for Sarcasm Detection,[0],[0]
"(Felbo et al., 2017) proposed a layer-wise training scheme that utilizes emoji-based distant supervision for sentiment analysis and sarcasm detection tasks.",2.2 Deep Learning for Sarcasm Detection,[0],[0]
"In the context of NLP, the key idea of neural attention is to soft select a sequence of words based on their relative importance to the task at hand.",2.3 Attention Models for NLP,[0],[0]
"Early innovations in attentional paradigms mainly involve neural machine translation (Luong et al., 2015; Bahdanau et al., 2014) for aligning sequence pairs.",2.3 Attention Models for NLP,[0],[0]
"Attention is also commonplace in many NLP applications such as sentiment classification (Chen et al., 2016; Yang et al., 2016), aspect-level sentiment analysis (Tay et al., 2018s, 2017b; Chen et al., 2017) and entailment classification (Rocktäschel et al., 2015).",2.3 Attention Models for NLP,[0],[0]
"Co-attention / Bi-Attention (Xiong et al., 2016; Seo et al., 2016) is a form of pairwise attention mechanism that was proposed to model query-document pairs.",2.3 Attention Models for NLP,[0],[0]
"Intraattention can be interpreted as a self-targetted coattention and is seeing a lot promising results in many recent works (Vaswani et al., 2017; Parikh et al., 2016; Tay et al., 2017a; Shen et al., 2017).",2.3 Attention Models for NLP,[0],[0]
"The key idea is to model a sequence against itself, learning to attend while capturing long term dependencies and word-word level interactions.",2.3 Attention Models for NLP,[0],[0]
"To the best of our knowledge, our work is not only the first work that only applies intra-attention to sarcasm detection but also the first attention model for sarcasm detection.",2.3 Attention Models for NLP,[0],[0]
"In this section, we describe our proposed model.",3 Our Proposed Approach,[0],[0]
Figure 1 illustrates our overall model architecture.,3 Our Proposed Approach,[0],[0]
Our model accepts a sequence of one-hot encoded vectors as an input.,3.1 Input Encoding Layer,[0],[0]
Each one-hot encoded vector corresponds to a single word in the vocabulary.,3.1 Input Encoding Layer,[0],[0]
"In the input encoding layer, each one-hot vector is converted into a low-dimensional vector representation (word embedding).",3.1 Input Encoding Layer,[0],[0]
The word embeddings are parameterized by an embedding layer W ∈ Rn×|V |.,3.1 Input Encoding Layer,[0],[0]
"As such, the output of this layer is a sequence of word embeddings, i.e., {w1, w2, · · ·w`} where ` is a predefined maximum sequence length.",3.1 Input Encoding Layer,[0],[0]
"In this section, we describe our multi-dimensional intra-attention mechanism for sarcasm detection.",3.2 Multi-dimensional Intra-Attention,[0],[0]
We first begin by describing the standard single-dimensional intra-attention.,3.2 Multi-dimensional Intra-Attention,[0],[0]
The multidimensional adaptation will be introduced later in this section.,3.2 Multi-dimensional Intra-Attention,[0],[0]
"The key idea behind this layer is to look in-between, i.e., modeling the semantics between each word in the input sequence.",3.2 Multi-dimensional Intra-Attention,[0],[0]
We first begin by modeling the relationship of each word pair in the input sequence.,3.2 Multi-dimensional Intra-Attention,[0],[0]
"A simple way to achieve this is to use a linear1 transformation layer to project the concatenation of each word embedding pair into a scalar score as follows:
sij =Wa([wi;wj ])",3.2 Multi-dimensional Intra-Attention,[0],[0]
"+ ba (1)
",3.2 Multi-dimensional Intra-Attention,[0],[0]
where Wa ∈,3.2 Multi-dimensional Intra-Attention,[0],[0]
"R2n×1, ba ∈ R are the parameters of this layer.",3.2 Multi-dimensional Intra-Attention,[0],[0]
"[.; .] is the vector concatenation operator and sij is a scalar representing the affinity score between word pairs (wi, wj).",3.2 Multi-dimensional Intra-Attention,[0],[0]
We can easily observe that s is a symmetrical matrix of `× ` dimensions.,3.2 Multi-dimensional Intra-Attention,[0],[0]
"In order to learn attention vector a, we apply a row-wise max-pooling operator on matrix s.
a = softmax(max row s) (2)
where a ∈ R` is a vector representing the learned intra-attention weights.",3.2 Multi-dimensional Intra-Attention,[0],[0]
"Then, the vector a is employed to learn weighted representation of {w1, w2 · · ·w`} as follows:
va = ∑̀ i=1 wiai (3)
1Early experiments found that adding nonlinearity here may degrade performance.
",3.2 Multi-dimensional Intra-Attention,[0],[0]
where v ∈,3.2 Multi-dimensional Intra-Attention,[0],[0]
Rn is the intra-attentive representation of the input sequence.,3.2 Multi-dimensional Intra-Attention,[0],[0]
"While other choices of pooling operators may be also employed (e.g., mean-pooling over max-pooling), the choice of max-pooling is empirically motivated.",3.2 Multi-dimensional Intra-Attention,[0],[0]
"Intuitively, this attention layer learns to pay attention based on a word’s largest contribution to all words in the sequence.",3.2 Multi-dimensional Intra-Attention,[0],[0]
"Since our objective is to highlight words that might contribute to the contrastive theories of sarcasm, a more discriminative pooling operator is desirable.",3.2 Multi-dimensional Intra-Attention,[0],[0]
"Notably, we also mask values of s where i = j such that we do not allow the relationship scores of a word with respect to itself to influence the overall attention weights.
",3.2 Multi-dimensional Intra-Attention,[0],[0]
"Furthermore, our network can be considered as an ‘inner’ adaptation of neural attention, modeling intra-sentence relationships between the raw word representations instead of representations that have been compositionally manipulated.",3.2 Multi-dimensional Intra-Attention,[0],[0]
This allows word-to-word similarity to be modeled ‘as it is’ and not be influenced by composition.,3.2 Multi-dimensional Intra-Attention,[0],[0]
"For example, when using the outputs of a compositional encoder (e.g., LSTM), matching words n and n + 1 might not be meaningful since they would be relatively similar in terms of semantic composition.",3.2 Multi-dimensional Intra-Attention,[0],[0]
"For relatively short documents (such as tweets), it is also intuitive that attention typically focuses on the last hidden representation.
",3.2 Multi-dimensional Intra-Attention,[0],[0]
"Intuitively, the relationships between two words is often not straightforward.",3.2 Multi-dimensional Intra-Attention,[0],[0]
Words are complex and often hold more than one meanings (or word senses).,3.2 Multi-dimensional Intra-Attention,[0],[0]
"As such, it might be beneficial to model multiple views between two words.",3.2 Multi-dimensional Intra-Attention,[0],[0]
This can be modeled by representing the word pair interaction with a vector instead of a scalar.,3.2 Multi-dimensional Intra-Attention,[0],[0]
"As such, we propose a multi-dimensional adaptation of the intra-attention mechanism.",3.2 Multi-dimensional Intra-Attention,[0],[0]
"The key idea here is that each word pair is projected down to a lowdimensional vector before we compute the affinity score, which allows it to not only capture one view (one scalar) but also multiple views.",3.2 Multi-dimensional Intra-Attention,[0],[0]
"A modification to Equation (1) constitutes our MultiDimensional Intra-Attention variant.
",3.2 Multi-dimensional Intra-Attention,[0],[0]
sij,3.2 Multi-dimensional Intra-Attention,[0],[0]
"=Wp(ReLU(Wq([wi;wj ]) + bq)) + bp (4)
where Wq ∈ Rn×k,Wp ∈ Rk×1, bq ∈ Rk, bp ∈ R are the parameters of this layer.",3.2 Multi-dimensional Intra-Attention,[0],[0]
The final intraattentive representation is then learned with Equation (2) and Equation (3) which we do not repeat here for the sake of brevity.,3.2 Multi-dimensional Intra-Attention,[0],[0]
"While we are able to simply use the learned representation v for prediction, it is clear that v does not encode compositional information and may miss out on important compositional phrases such as ‘not happy’.",3.3 Long Short-Term Memory Encoder,[0],[0]
"Clearly, our intra-attention mechanism simply considers a word-by-word interaction and does not model the input document sequentially.",3.3 Long Short-Term Memory Encoder,[0],[0]
"As such, it is beneficial to use a separate compositional encoder for this purpose, i.e., learning compositional representations.",3.3 Long Short-Term Memory Encoder,[0],[0]
"To this end, we employ the standard Long Short-Term Memory (LSTM) encoder.",3.3 Long Short-Term Memory Encoder,[0],[0]
"The output of an LSTM encoder at each time-step can be briefly defined as:
hi = LSTM(w, i), ∀i ∈",3.3 Long Short-Term Memory Encoder,[0],[0]
"[1, . . .",3.3 Long Short-Term Memory Encoder,[0],[0]
"`] (5)
where ` represents the maximum length of the sequence and hi ∈ Rd is the hidden output of the LSTM encoder at time-step i. d is the size of the hidden units of the LSTM encoder.",3.3 Long Short-Term Memory Encoder,[0],[0]
LSTM encoders are parameterized by gating mechanisms learned via nonlinear transformations.,3.3 Long Short-Term Memory Encoder,[0],[0]
"Since
LSTMs are commonplace in standard NLP applications, we omit the technical details for the sake of brevity.",3.3 Long Short-Term Memory Encoder,[0],[0]
"Finally, to obtain a compositional representation of the input document, we use vc = h` which is the last hidden output of the LSTM encoder.",3.3 Long Short-Term Memory Encoder,[0],[0]
Note that the inputs to the LSTM encoder are the word embeddings right after the input encoding layer and not the output of the intraattention layer.,3.3 Long Short-Term Memory Encoder,[0],[0]
We found that applying an LSTM on the intra-attentively scaled representations do not yield any benefits.,3.3 Long Short-Term Memory Encoder,[0],[0]
"The inputs to the final prediction layer are two representations, namely (1) the intra-attentive representation (va ∈ Rn) and (2) the compositional representation (vc ∈ Rd).",3.4 Prediction Layer,[0],[0]
"This layer learns a joint representation of these two views using a nonlinear projection layer.
v = ReLU(Wz([va; vc]) + bz) (6)
where Wz ∈ R(d+n)×d and bz ∈ Rd.",3.4 Prediction Layer,[0],[0]
"Finally, we pass v into a Softmax classification layer.
ŷ",3.4 Prediction Layer,[0],[0]
"= Softmax(Wf v + bf ) (7)
where Wf ∈ Rd×2, bf ∈ R2 are the parameters of this layer.",3.4 Prediction Layer,[0],[0]
ŷ ∈ R2 is the output layer of our proposed model.,3.4 Prediction Layer,[0],[0]
"Our network is trained end-to-end, optimizing the standard binary cross-entropy loss function.
",3.5 Optimization and Learning,[0],[0]
J =,3.5 Optimization and Learning,[0],[0]
− N∑ i=1,3.5 Optimization and Learning,[0],[0]
[yi log ŷi + (1− yi) log(1− ŷi)],3.5 Optimization and Learning,[0],[0]
"+R (8)
where J is the cost function, ŷ is the output of the network, R =",3.5 Optimization and Learning,[0],[0]
||θ||L2 is the L2 regularization and λ is the weight of the regularizer.,3.5 Optimization and Learning,[0],[0]
"In this section, we describe our experimental setup and results.",4 Empirical Evaluation,[0],[0]
"Our experiments were designed to answer the following research questions (RQs).
",4 Empirical Evaluation,[0],[0]
"• RQ1 - Does our proposed approach outperform existing state-of-the-art models?
",4 Empirical Evaluation,[0],[0]
• RQ2 - What are the impacts of some of the architectural choices of our model?,4 Empirical Evaluation,[0],[0]
"How much does intra-attention contribute
to the model performance?",4 Empirical Evaluation,[0],[0]
"Is the MultiDimensional adaptation better than the Single-Dimensional adaptation?
",4 Empirical Evaluation,[0],[0]
• RQ3 - What can we interpret from the intraattention layers?,4 Empirical Evaluation,[0],[0]
Does this align with our hypothesis about looking in-between and modeling contrast?,4 Empirical Evaluation,[0],[0]
"We conduct our experiments on six publicly available benchmark datasets which span across three well-known sources.
",4.1 Datasets,[0],[0]
• Tweets - Twitter2 is a microblogging platform which allows users to post statuses of less than 140 characters.,4.1 Datasets,[0],[0]
We use two collections for sarcasm detection on tweets.,4.1 Datasets,[0],[0]
"More specifically, we use the dataset obtained from (1) (Ptáček et al., 2014) in which tweets are trained via hashtag based semisupervised learning, i.e., hashtags such as #not, #sarcasm and #irony are marked as sarcastic tweets and (2) (Riloff et al., 2013) in which Tweets are hand annotated and manually checked for sarcasm.",4.1 Datasets,[0],[0]
"For both datasets, we retrieve.",4.1 Datasets,[0],[0]
"Tweets using the Twitter API using the provided tweet IDs.
",4.1 Datasets,[0],[0]
• Reddit - Reddit3 is a highly popular social forum and community.,4.1 Datasets,[0],[0]
"Similar to Tweets, sarcastic posts are obtained via the tag ‘/s’ which are marked by the authors themselves.",4.1 Datasets,[0],[0]
We use two Reddit datasets which are obtained from the subreddits /r/movies and /r/technology respectively.,4.1 Datasets,[0],[0]
"Datasets are subsets from (Khodak et al., 2017).
",4.1 Datasets,[0],[0]
"• Debates - We use two datasets4 from the Internet Argument Corpus (IAC) (Lukin and Walker, 2017) which have been hand annotated for sarcasm.",4.1 Datasets,[0],[0]
"This dataset, unlike the first two, is mainly concerned with long text and provides a diverse comparison from the other datasets.",4.1 Datasets,[0],[0]
The IAC corpus was designed for research on political debates on online forums.,4.1 Datasets,[0],[0]
"We use the V1 and V2 versions of the sarcasm corpus which are denoted as IAC-V1 and IAC-V2 respectively.
",4.1 Datasets,[0],[0]
"The statistics of the datasets used in our experiments is reported in Table 1.
2https://twitter.com 3https://reddit.com 4https://nlds.soe.ucsc.edu/sarcasm1",4.1 Datasets,[0],[0]
"We compare our proposed model with the following algorithms.
",4.2 Compared Methods,[0],[0]
"• NBOW is a simple neural bag-of-words baseline that sums all the word embeddings and passes the summed vector into a simple logistic regression layer.
",4.2 Compared Methods,[0],[0]
• CNN is a vanilla Convolutional Neural Network with max-pooling.,4.2 Compared Methods,[0],[0]
CNNs are considered as compositional encoders that capture n-gram features by parameterized sliding windows.,4.2 Compared Methods,[0],[0]
"The filter width is 3 and number of filters f = 100.
",4.2 Compared Methods,[0],[0]
• LSTM is a vanilla Long Short-Term Memory Network.,4.2 Compared Methods,[0],[0]
"The size of the LSTM cell is set to d = 100.
",4.2 Compared Methods,[0],[0]
• ATT-LSTM (Attention-based LSTM) is a LSTM model with a neural attention mechanism applied to all the LSTM hidden outputs.,4.2 Compared Methods,[0],[0]
"We use a similar adaptation to (Yang et al., 2016), albeit only at the document-level.
• GRNN (Gated Recurrent Neural Network) is a Bidirectional Gated Recurrent Unit (GRU) model that was proposed for sarcasm detection by (Zhang et al., 2016).",4.2 Compared Methods,[0],[0]
GRNN uses a gated pooling mechanism to aggregate the hidden representations from a standard BiGRU model.,4.2 Compared Methods,[0],[0]
"Since we only compare on document-level sarcasm detection, we do not use the variant of GRNN that exploits user context.
",4.2 Compared Methods,[0],[0]
"• CNN-LSTM-DNN (Convolutional LSTM + Deep Neural Network), proposed by (Ghosh and Veale, 2016), is the state-of-theart model for sarcasm detection.",4.2 Compared Methods,[0],[0]
"This model is a combination of a CNN, LSTM and Deep Neural Network via stacking.",4.2 Compared Methods,[0],[0]
It stacks two layers of 1D convolution with 2 LSTM layers.,4.2 Compared Methods,[0],[0]
"The output passes through a deep neural network (DNN) for prediction.
",4.2 Compared Methods,[0],[0]
"Both CNN-LSTM-DNN (Ghosh and Veale, 2016) and GRNN (Zhang et al., 2016) are state-ofthe-art models for document-level sarcasm detection and have outperformed numerous neural and non-neural baselines.",4.2 Compared Methods,[0],[0]
"In particular, both works have well surpassed feature-based models (Support Vector Machines, etc.), as such we omit comparisons for the sake of brevity and focus comparisons with recent neural models instead.",4.2 Compared Methods,[0],[0]
"Moreover, since our work focuses only on document-level sarcasm detection, we do not compare against models that use external information such as user profiles, context, personality information (Ghosh and Veale, 2017) or emoji-based distant supervision (Felbo et al., 2017).
",4.2 Compared Methods,[0],[0]
"For our model, we report results on both multi-dimensional and single-dimensional intraattention.",4.2 Compared Methods,[0],[0]
The two models are named as MIARN and SIARN respectively.,4.2 Compared Methods,[0],[0]
"We adopt standard the evaluation metrics for the sarcasm detection task, i.e., macro-averaged F1 and accuracy score.",4.3 Implementation Details and Metrics,[0],[0]
"Additionally, we also report precision and recall scores.",4.3 Implementation Details and Metrics,[0],[0]
"All deep learning models are implemented using TensorFlow (Abadi et al., 2015) and optimized on a NVIDIA GTX1070 GPU.",4.3 Implementation Details and Metrics,[0],[0]
Text is preprocessed with NLTK5’s Tweet tokenizer.,4.3 Implementation Details and Metrics,[0],[0]
Words that only appear once in the entire corpus are removed and marked with the UNK token.,4.3 Implementation Details and Metrics,[0],[0]
"Document lengths are truncated at 40, 20, 80 tokens for Twitter, Reddit and Debates dataset respectively.",4.3 Implementation Details and Metrics,[0],[0]
Mentions of other users on the Twitter dataset are replaced by ‘@USER’.,4.3 Implementation Details and Metrics,[0],[0]
"Documents with URLs (i.e., containing ‘http’) are removed from the corpus.",4.3 Implementation Details and Metrics,[0],[0]
Documents with less than 5 tokens are also removed.,4.3 Implementation Details and Metrics,[0],[0]
The learning optimizer used is the RMSProp with an initial learning rate of 0.001.,4.3 Implementation Details and Metrics,[0],[0]
The L2 regularization is set to 10−8.,4.3 Implementation Details and Metrics,[0],[0]
"We initialize the word embedding layer with GloVe (Pennington et al., 2014).",4.3 Implementation Details and Metrics,[0],[0]
We use the GloVe model trained on 2B Tweets for the Tweets and Reddit dataset.,4.3 Implementation Details and Metrics,[0],[0]
The Glove model trained on Common Crawl is used for the Debates corpus.,4.3 Implementation Details and Metrics,[0],[0]
The size of the word embeddings is fixed at d = 100 and are fine-tuned during training.,4.3 Implementation Details and Metrics,[0],[0]
"In all experiments, we use a development set to select the best hyperparameters.",4.3 Implementation Details and Metrics,[0],[0]
"Each model is trained for a total of 30 epochs and the model is saved each time the performance
5https://nltk.org
on the development set is topped.",4.3 Implementation Details and Metrics,[0],[0]
"The batch size is tuned amongst {128, 256, 512} for all datasets.",4.3 Implementation Details and Metrics,[0],[0]
"The only exception is the Tweets dataset from (Riloff et al., 2013), in which a batch size of 16 is used in lieu of the much smaller dataset size.",4.3 Implementation Details and Metrics,[0],[0]
"For fair comparison, all models have the same hidden representation size and are set to 100 for both recurrent and convolutional based models (i.e., number of filters).",4.3 Implementation Details and Metrics,[0],[0]
"For MIARN, the size of intraattention hidden representation is tuned amongst {4, 8, 10, 20}.",4.3 Implementation Details and Metrics,[0],[0]
"Table 2, Table 3 and Table 4 reports a performance comparison of all benchmarked models on the Tweets, Reddit and Debates datasets respectively.",4.4 Experimental Results,[0],[0]
"We observe that our proposed SIARN and MIARN models achieve the best results across
all six datasets.",4.4 Experimental Results,[0],[0]
The relative improvement differs across domain and datasets.,4.4 Experimental Results,[0],[0]
"On the Tweets dataset from (Ptáček et al., 2014), MIARN achieves about ≈ 2% − 2.2% improvement in terms of F1 and accuracy score when compared against the best baseline.",4.4 Experimental Results,[0],[0]
"On the other Tweets dataset from (Riloff et al., 2013), the performance gain of our proposed model is larger, i.e., 3%− 5% improvement on average over most baselines.",4.4 Experimental Results,[0],[0]
"Our proposed SIARN and MIARN models achieve very competitive performance on the Reddit datasets, with an average of ≈ 2% margin improvement over the best baselines.",4.4 Experimental Results,[0],[0]
"Notably, the baselines we compare against are extremely competitive state-of-the-art neural network models.",4.4 Experimental Results,[0],[0]
This further reinforces the effectiveness of our proposed approach.,4.4 Experimental Results,[0],[0]
"Additionally, the performance improvement on Debates (long text) is significantly larger than short
text (i.e., Twitter and Reddit).",4.4 Experimental Results,[0],[0]
"For example, MIARN outperforms GRNN and CNN-LSTM-DNN by ≈ 8%− 10% on both IAC-V1 and IAC-V2.",4.4 Experimental Results,[0],[0]
"At this note, we can safely put RQ1 to rest.
",4.4 Experimental Results,[0],[0]
"Overall, the performance of MIARN is often marginally better than SIARN (with some exceptions, e.g., Tweets dataset from (Riloff et al., 2013)).",4.4 Experimental Results,[0],[0]
We believe that this is attributed to the fact that more complex word-word relationships can be learned by using multi-dimensional values instead of single-dimensional scalars.,4.4 Experimental Results,[0],[0]
The performance brought by our additional intra-attentive representations can be further observed by comparing against the vanilla LSTM model.,4.4 Experimental Results,[0],[0]
"Clearly, removing the intra-attention network reverts our model to the standard LSTM.",4.4 Experimental Results,[0],[0]
"The performance improvements are encouraging, leading to almost 10% improvement in terms of F1 and accuracy.",4.4 Experimental Results,[0],[0]
"On datasets with short text, the performance improvement is often a modest ≈ 2%",4.4 Experimental Results,[0],[0]
− 3% (RQ2).,4.4 Experimental Results,[0],[0]
"Notably, our proposed models also perform much better on long text, which can be attributed to the intra-attentive representations explicitly modeling long range dependencies.",4.4 Experimental Results,[0],[0]
"Intuitively, this is problematic for models that only capture sequential dependencies (e.g., word by word).
",4.4 Experimental Results,[0],[0]
"Finally, the relative performance of competitor methods are as expected.",4.4 Experimental Results,[0],[0]
"NBOW performs the worse, since it is just a naive bag-of-words model without any compositional or sequential information.",4.4 Experimental Results,[0],[0]
"On short text, LSTMs are overall better than CNNs.",4.4 Experimental Results,[0],[0]
"However, this trend is reversed on long text (i.e., Debates) since the LSTM model may be overburdened by overly long sequences.",4.4 Experimental Results,[0],[0]
"On short text, we also found that attention (or the gated pooling mechanism from GRNN) did not really help make any significant improvements over the vanilla LSTM model and a qualitative explanation to why this is so is deferred to the next section.",4.4 Experimental Results,[0],[0]
"However, attention helps for long text (such as debates), resulting in Attention LSTMs becoming the strongest baseline on the Debates datasets.",4.4 Experimental Results,[0],[0]
"However, our proposed intra-attentive model is both effective on short text and long text, outperforming Attention LSTMs consistently on all datasets.",4.4 Experimental Results,[0],[0]
"In this section, we present an in-depth analysis of our proposed model.",4.5 In-depth Model Analysis,[0],[0]
"More specifically, we not only aim to showcase the interpretability of
our model but also explain how representations are formed.",4.5 In-depth Model Analysis,[0],[0]
"More specifically, we test our model (trained on Tweets dataset by (Ptáček et al., 2014)) on two examples.",4.5 In-depth Model Analysis,[0],[0]
"We extract the attention maps of three models, namely MIARN, Attention LSTM (ATT-LSTM) and applying Attention mechanism directly on the word embeddings without using a LSTM encoder (ATT-RAW).",4.5 In-depth Model Analysis,[0],[0]
"Table 5 shows the visualization of the attention maps.
",4.5 In-depth Model Analysis,[0],[0]
"In the first example (true label), we notice that the attention maps of MIARN are focusing on the words ‘love’ and ‘ignored’.",4.5 In-depth Model Analysis,[0],[0]
This is in concert with our intuition about modeling contrast and incongruity.,4.5 In-depth Model Analysis,[0],[0]
"On the other hand, both ATT-LSTM and ATT-RAW learn very different attention maps.",4.5 In-depth Model Analysis,[0],[0]
"As for ATT-LSTM, the attention weight is focused completely on the last representation - the token ‘!!’.",4.5 In-depth Model Analysis,[0],[0]
"Additionally, we also observed that this is true for many examples in the Tweets and Reddit dataset.",4.5 In-depth Model Analysis,[0],[0]
"We believe that this is the reason why standard neural attention does not help as what the attention mechanism is learning is to select the last representation (i.e., vanilla LSTM).",4.5 In-depth Model Analysis,[0],[0]
"Without the LSTM encoder, the attention weights focus on ‘love’ but not ‘ignored’.",4.5 In-depth Model Analysis,[0],[0]
"This fails to capture any concept of contrast or incongruity.
",4.5 In-depth Model Analysis,[0],[0]
"Next, we consider the false labeled example.",4.5 In-depth Model Analysis,[0],[0]
"This time, the attention maps of MIARN are not as distinct as before.",4.5 In-depth Model Analysis,[0],[0]
"However, they focus on sentiment-bearing words, composing the words ‘ignored sucks’ to form the majority of the intraattentive representation.",4.5 In-depth Model Analysis,[0],[0]
"This time, passing the vector made up of ‘ignored sucks’ allows the subsequent layers to recognize that there is no contrasting situation or sentiment.",4.5 In-depth Model Analysis,[0],[0]
"Similarly, ATTLSTM focuses on the last word time which is totally non-interpretable.",4.5 In-depth Model Analysis,[0],[0]
"On the other hand, ATTRAW focuses on relatively non-meaningful words such as ‘big’.
",4.5 In-depth Model Analysis,[0],[0]
"Overall, we analyzed two cases (positive and negative labels) and found that MIARN produces
very explainable attention maps.",4.5 In-depth Model Analysis,[0],[0]
"In general, we found that MIARN is able to identify contrast and incongruity in sentences, allowing our model to better detect sarcasm.",4.5 In-depth Model Analysis,[0],[0]
This is facilitated by modeling intra-sentence relationships.,4.5 In-depth Model Analysis,[0],[0]
"Notably, the standard vanilla attention is not explainable or interpretable.",4.5 In-depth Model Analysis,[0],[0]
"Based on the intuition of intra-sentence similarity (i.e., looking in-between), we proposed a new neural network architecture for sarcasm detection.",5 Conclusion,[0],[0]
"Our network incorporates a multi-dimensional intra-attention component that learns an intraattentive representation of the sentence, enabling it to detect contrastive sentiment, situations and incongruity.",5 Conclusion,[0],[0]
Extensive experiments over six public benchmarks confirm the empirical effectiveness of our proposed model.,5 Conclusion,[0],[0]
Our proposed MIARN model outperforms strong state-of-the-art baselines such as GRNN and CNN-LSTM-DNN.,5 Conclusion,[0],[0]
"Analysis of the intra-attention scores shows that our model learns highly interpretable attention weights, paving the way for more explainable neural sarcasm detection methods.",5 Conclusion,[0],[0]
Sarcasm is a sophisticated speech act which commonly manifests on social communities such as Twitter and Reddit.,abstractText,[0],[0]
The prevalence of sarcasm on the social web is highly disruptive to opinion mining systems due to not only its tendency of polarity flipping but also usage of figurative language.,abstractText,[0],[0]
Sarcasm commonly manifests with a contrastive theme either between positive-negative sentiments or between literal-figurative scenarios.,abstractText,[0],[0]
"In this paper, we revisit the notion of modeling contrast in order to reason with sarcasm.",abstractText,[0],[0]
"More specifically, we propose an attention-based neural model that looks inbetween instead of across, enabling it to explicitly model contrast and incongruity.",abstractText,[0],[0]
"We conduct extensive experiments on six benchmark datasets from Twitter, Reddit and the Internet Argument Corpus.",abstractText,[0],[0]
Our proposed model not only achieves stateof-the-art performance on all datasets but also enjoys improved interpretability.,abstractText,[0],[0]
Reasoning with Sarcasm by Reading In-between,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1358–1368 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1358",text,[0],[0]
"There is a rich literature in natural language processing (NLP) and information retrieval on question answering (QA) (Hirschman and Gaizauskas, 2001), but recently deep learning has sparked interest in a special kind of QA, commonly referred to as reading comprehension (RC) (Vanderwende, 2007).",1 Introduction,[0],[0]
"The aim in RC research is to build intelligent systems with the abilities to read and understand natural language text and answer questions related to it (Burges, 2013).",1 Introduction,[0],[0]
"Such tests are appealing as they require joint understanding of the question and the related passage (i.e. context), and moreover, they can analyze many different types of skills in a rather objective way (Sugawara et al., 2017).
",1 Introduction,[0],[0]
"Despite the progress made in recent years, there is still a significant performance gap between humans and deep neural models in RC, and researchers are pushing forward our understanding of
the limitations and capabilities of these approaches by introducing new datasets.",1 Introduction,[0],[0]
"Existing tasks for RC mainly differ in two major respects: the questionanswer formats, e.g. cloze (fill-in-the-blank), span selection or multiple choice, and the text sources they use, such as news articles (Hermann et al., 2015; Trischler et al., 2017), fictional stories (Hill et al., 2016), Wikipedia articles (Kočiský et al., 2018; Hewlett et al., 2016; Rajpurkar et al., 2016) or other web sources (Joshi et al., 2017).",1 Introduction,[0],[0]
"A popular topic in computer vision closely related to RC is Visual Question Answering (VQA) in which context takes the form of an image in the comprehension task, where recent datasets have also been compiled, such as (Antol et al., 2015; Yu et al., 2015; Johnson et al., 2017; Goyal et al., 2017), to name a few.
",1 Introduction,[0],[0]
"More recently, research in QA has been extended to focus on the multimodal aspects of the problem where different modalities are being explored.",1 Introduction,[0],[0]
Tapaswi et al. (2016) introduced MovieQA where they concentrate on evaluating automatic story comprehension from both video and text.,1 Introduction,[0],[0]
"In COMICS, Iyyer et al. (2017) turned to comic books to test understanding of closure, transitions in the narrative from one panel to the next.",1 Introduction,[0],[0]
"In AI2D (Kembhavi et al., 2016) and FigureQA (Kahou et al., 2018), the authors addressed comprehension of scientific diagrams and graphical plots.",1 Introduction,[0],[0]
"Last but not least, Kembhavi et al. (2017) has proposed another comprehensive and challenging dataset named TQA, which comprised of middle school science lessons of diagrams and texts.
",1 Introduction,[0],[0]
"In this study, we focus on multimodal machine comprehension of cooking recipes with images and text.",1 Introduction,[0],[0]
"To this end, we introduce a new QA dataset called RecipeQA that consists of recipe instructions and related questions (see Fig. 1 for an example text cloze style question).",1 Introduction,[0],[0]
"There are a handful of reasons why understanding and reasoning about
Text Cloze Style Question Context Modalities: Images and Descriptions of Steps
Recipe: Last-Minute Lasagna
1.",1 Introduction,[0],[0]
"Heat oven to 375 degrees F. Spoon a thin layer of sauce over the bottom of a 9-by-13-inch baking dish.
",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
Cover with a single layer of ravioli.,1 Introduction,[0],[0]
3.,1 Introduction,[0],[0]
"Top with half the spinach half the mozzarella and a third
of the remaining sauce.",1 Introduction,[0],[0]
4.,1 Introduction,[0],[0]
"Repeat with another layer of ravioli and the remaining
spinach mozzarella and half the remaining sauce.",1 Introduction,[0],[0]
5.,1 Introduction,[0],[0]
"Top with another layer of ravioli and the remaining sauce
not all the ravioli may be needed.",1 Introduction,[0],[0]
"Sprinkle with the Parmesan.
6.",1 Introduction,[0],[0]
Cover with foil and bake for 30 minutes.,1 Introduction,[0],[0]
"Uncover and bake until bubbly, 5 to 10 minutes.
",1 Introduction,[0],[0]
7.,1 Introduction,[0],[0]
"Let cool 5 minutes before spooning onto individual plates.
",1 Introduction,[0],[0]
"Step 1 Step 2 Step 3 Step 4
Step 5 Step 6 Step 7
Question Choose the best text for the missing blank to correctly complete the recipe Cover. .",1 Introduction,[0],[0]
Bake.,1 Introduction,[0],[0]
"Cool, serve.
",1 Introduction,[0],[0]
"Answer A. Top, sprinkle B. Finishing touches C. Layer it up D. Ravioli bonus round
Figure 1: An illustrative text cloze style question (context, question and answer triplet).",1 Introduction,[0],[0]
The context is comprised of recipe description and images where the question is generated using the question titles.,1 Introduction,[0],[0]
"Each paragraph in the context is taken from another step, as also true for the images.",1 Introduction,[0],[0]
"Bold answer is the correct one.
",1 Introduction,[0],[0]
recipes is interesting.,1 Introduction,[0],[0]
"Recipes are written with a specific goal in mind, that is to teach others how to prepare a particular food.",1 Introduction,[0],[0]
"Hence, they contain immensely rich information about the real world.",1 Introduction,[0],[0]
"Recipes consist of instructions, wherein one needs to follow each instruction to successfully complete the recipe.",1 Introduction,[0],[0]
"As a classical example in introductory programming classes, each recipe might be seen as a particular way of solving a task and in that regard can also be considered as an algorithm.",1 Introduction,[0],[0]
"We believe that recipe comprehension is an elusive challenge and might be seen as important milestone in the long-standing goal of artificial intelligence and machine reasoning (Norvig, 1987; Bottou, 2014).
",1 Introduction,[0],[0]
"Among previous efforts towards multimodal machine comprehension (Tapaswi et al., 2016; Kembhavi et al., 2016; Iyyer et al., 2017; Kembhavi et al., 2017; Kahou et al., 2018), our study is closer to what Kembhavi et al. (2017) envisioned in TQA.",1 Introduction,[0],[0]
Our task primarily differs in utilizing substantially larger number of images – the average number of images per recipe in RecipeQA is 12 whereas TQA has only 3 images per question on average.,1 Introduction,[0],[0]
"Moreover, in our case, each image is aligned with the text of a particular step in the corresponding recipe.",1 Introduction,[0],[0]
"Another important difference is that TQA contains mostly diagrams or textbook images whereas
RecipeQA consists of natural images taken by users in unconstrained environments.
",1 Introduction,[0],[0]
"Some of the important characteristics of RecipeQA are as follows:
•",1 Introduction,[0],[0]
"There are arbitrary numbers of steps in recipes and images in steps, respectively.
",1 Introduction,[0],[0]
"• There are different question styles, each requiring a specific comprehension skill.
",1 Introduction,[0],[0]
"• There exists high lexical and syntactic divergence between contexts, questions and answers.
",1 Introduction,[0],[0]
"• Answers require understanding procedural language, in particular keeping track of entities and/or actions and their state changes.
",1 Introduction,[0],[0]
"• Answers may need information coming from multiple steps (i.e. multiple images and multiple paragraphs).
",1 Introduction,[0],[0]
"• Answers inherently involve multimodal understanding of image(s) and text.
",1 Introduction,[0],[0]
"To sum up, we believe RecipeQA is a challenging benchmark dataset which will serve as a test bed for evaluating multimodal comprehension systems.",1 Introduction,[0],[0]
"In this paper, we present several statistical analyses on RecipeQA and also obtain baseline performances for a number of multimodal comprehension tasks that we introduce for cooking recipes.",1 Introduction,[0],[0]
The Recipe Question Answering (RecipeQA) dataset is a challenging multimodal dataset that evaluates reasoning over real-life cooking recipes.,2 RecipeQA Dataset,[0],[0]
"It consists of approximately 20K recipes from 22 food categories, and over 36K questions.",2 RecipeQA Dataset,[0],[0]
Fig. 2 shows an illustrative cooking recipe from our dataset.,2 RecipeQA Dataset,[0],[0]
Each recipe includes an arbitrary number of steps containing both textual and visual elements.,2 RecipeQA Dataset,[0],[0]
"In particular, each step of a recipe is accompanied by a ‘title’, a ‘description’ and a set of illustrative ‘images’ that are aligned with the title and the description.",2 RecipeQA Dataset,[0],[0]
Each of these elements can be considered as a different modality of the data.,2 RecipeQA Dataset,[0],[0]
"The questions in RecipeQA explore the multimodal aspects of the step-by-step instructions available in the recipes through a number of specific tasks that are described in Sec. 3, namely textual cloze, visual cloze, visual coherency and visual ordering.",2 RecipeQA Dataset,[0],[0]
We consider cooking recipes as the main data source for our dataset.,2.1 Data Collection,[0],[0]
"These recipes were collected from Instructables1, which is a how-to web site where users share all kinds of instructions including but not limited to recipes.
",2.1 Data Collection,[0],[0]
We employed a set of heuristics that helped us collect high quality data in an automatic manner.,2.1 Data Collection,[0],[0]
"For instance, while collecting the recipes, we downloaded only the most popular recipes by considering the popularity as an objective measure for assessing the quality of a recipe.",2.1 Data Collection,[0],[0]
"Our assumption is that the mostly viewed recipes contain less noise and include easy-to-understand instructions with high-quality illustrative images.
",2.1 Data Collection,[0],[0]
"In total, we collected about 20K unique recipes from the food category of Instructables.",2.1 Data Collection,[0],[0]
"We filtered out non-English recipes using a language identification (Lui and Baldwin, 2012), and automatically removed the ones with unreadable contents such as the ones that only contain recipe videos.",2.1 Data Collection,[0],[0]
"Finally, as a post processing step, we normalized the description text by removing non-ASCII characters from the text.",2.1 Data Collection,[0],[0]
"For machine comprehension and reasoning, forming the questions and the answers is crucial for evaluating the ability of a model in understanding
1All materials from the instructables.com were downloaded in April 2018.
",2.2 Questions and Answers,[0],[0]
the content.,2.2 Questions and Answers,[0],[0]
"Prior studies employed natural language questions either collected via crowdsourcing platforms such as SQuAD (Rajpurkar et al., 2016) or generated synthetically as in CNN/Daily Mail (Hermann et al., 2015).",2.2 Questions and Answers,[0],[0]
"Using natural language questions is a good approach in terms of capturing human understanding, but crowdsourcing is often too costly and does not scale well as the size of the dataset grows.",2.2 Questions and Answers,[0],[0]
"Synthetic question generation is a low-cost solution, but the quality of the generated questions is subject to question.
",2.2 Questions and Answers,[0],[0]
"RecipeQA includes structured data about the cooking recipes that consists of step-by-step instructions, which helps us generate questions in a fully automatic manner without compromising the quality.",2.2 Questions and Answers,[0],[0]
Our questions test the semantics of the instructions of the recipes from different aspects through the tasks described in Sec. 3.,2.2 Questions and Answers,[0],[0]
"In particular, we generate a set of multiple choice questions (the number of choices is fixed as four) by following a simple procedure which apply to all of our tasks with slight modifications.
",2.2 Questions and Answers,[0],[0]
"In order to generate question-answer-context triplets, we first filtered out recipes that contain less than 3 steps or more than 25 steps.",2.2 Questions and Answers,[0],[0]
"We also ignored the initial step of the recipes as our preliminary analysis showed that the first step of the recipes almost always is used by the authors to provide a narrative, e.g. why they love making that particular food, or how it makes sense to prepare a food for some occasion, and often is not relevant to the recipe instructions.",2.2 Questions and Answers,[0],[0]
"In addition, we automatically removed some indicators such as step numbers that explicitly emphasize temporal order from the step titles while generating questions.
",2.2 Questions and Answers,[0],[0]
"Given a task, we first randomly select a set of steps from each recipe and construct our questions and answers from these steps according to the task at hand.",2.2 Questions and Answers,[0],[0]
"In particular, we employ the modality that the comprehension task is built upon to generate the candidate answers and use the remaining content as the necessary context for our questions.",2.2 Questions and Answers,[0],[0]
"For instance, if the step titles are used within the candidate answers, the context becomes the descriptions and the images of the steps.",2.2 Questions and Answers,[0],[0]
"As the average number of steps per recipe is larger than four, using this strategy, we can generate multiple context-questionanswer triplets from a single recipe.
",2.2 Questions and Answers,[0],[0]
Candidate answers can be generated by selecting the distractors at random from the steps of other recipes.,2.2 Questions and Answers,[0],[0]
"To make our dataset more challenging, we
employ a different strategy and select the distractors from the relevant modalities (titles, descriptions or images), which are not too far or too close from the correct answer.",2.2 Questions and Answers,[0],[0]
"Specifically, we employ the following simple heuristic.",2.2 Questions and Answers,[0],[0]
We first find k nearest neighbors (k = 100) from other recipes.,2.2 Questions and Answers,[0],[0]
We then define an adaptive neighborhood by finding the closest distance to the query and remove the candidates that are too close.,2.2 Questions and Answers,[0],[0]
The remaining candidates are similar enough to be adversarial but not too similar to semantically substitute for the groundtruth.,2.2 Questions and Answers,[0],[0]
"Finally, we randomly sample distractors from that pool.",2.2 Questions and Answers,[0],[0]
Details of the question generation procedure for each of the tasks are given in Sec. 3.,2.2 Questions and Answers,[0],[0]
RecipeQA dataset contains approximately 20K cooking recipes and over 36K question-answer pairs divided into four major question types reflecting each of the task at hand.,2.3 Dataset Statistics,[0],[0]
"The data is split into non-overlapping training, validation and test sets so that one set does not include a recipe and/or questions about that recipe which are available in other sets.",2.3 Dataset Statistics,[0],[0]
"There are 22 different food categories
across our dataset whose distribution is shown in Fig. 3.",2.3 Dataset Statistics,[0],[0]
"While splitting the recipes into sets, we take into account these categories so that all the sets have a similar distribution of recipes across all the categories.",2.3 Dataset Statistics,[0],[0]
"In Table 1, we show the detailed statistics about our RecipeQA dataset.",2.3 Dataset Statistics,[0],[0]
"Moreover, to visualize the token frequencies, we also provide the word clouds of the titles and the descriptions from the recipes in Fig. 4.",2.3 Dataset Statistics,[0],[0]
"RecipeQA includes four different types of tasks: (1) Textual cloze, (2) Visual cloze, (3) Visual coherence, and (4) Visual ordering.",3 Tasks,[0],[0]
"Each of these tasks requires different reasoning skills as discussed in (Sugawara et al., 2017), and considers different modalities in their contexts and candidate answer sets.",3 Tasks,[0],[0]
"By modalities, we refer to the following pieces of information: (i) titles of steps, (ii) descriptions of steps and (iii) illustrative images of steps.",3 Tasks,[0],[0]
"While generating the questions for these tasks, we rather employ fixed templates as will be discussed below, which helps us to automatically construct questionanswers pairs from the recipes with no human intervention.",3 Tasks,[0],[0]
"Using these tasks, we can easily evaluate complex relationships between different steps of a recipe via their titles, their descriptions and/or their illustrative images.",3 Tasks,[0],[0]
"Hence, our question-answers pairs are multimodal in nature.",3 Tasks,[0],[0]
"In the following, we provide a detailed description of each one of these tasks and discuss our strategies while selecting candidate answers.",3 Tasks,[0],[0]
Textual cloze style questions test the ability to infer missing text either in the title or in the step description by taking into account the question’s context which includes a set of illustrative images besides text.,3.1 Textual Cloze,[0],[0]
"While generating the question-answer pairs for this task, we randomly select a step from the candidate steps of a given recipe, hide its title and description, and ask for identifying this text amongst the multiple choices from the remaining modalities.",3.1 Textual Cloze,[0],[0]
"To construct the distractor answers, we use the strategy in Sec. 2.2 that depends on the WMD (Kusner et al., 2015) distance measure.",3.1 Textual Cloze,[0],[0]
"In Fig. 1, we provide a sample text cloze question from RecipeQA generated automatically in this way.",3.1 Textual Cloze,[0],[0]
Visual cloze style questions test a skill similar to that of textual cloze task with the difference that the missing information in this task reside in the visual domain.,3.2 Visual Cloze,[0],[0]
"Here, just like the textual cloze task, for a recipe we randomly select a step, hide its representative image, and ask to infer this image amongst the multiple choices.",3.2 Visual Cloze,[0],[0]
The context for this task is all textual and is in the form of a sequence of titles and descriptions.,3.2 Visual Cloze,[0],[0]
"To construct the distractor images, we use Euclidean distances of 2048-d pool5 features extracted from a ResNet-50 (He et al., 2016) pre-trained on ImageNet classification task.",3.2 Visual Cloze,[0],[0]
We show a sample visual cloze style question in Fig. 5 (second row).,3.2 Visual Cloze,[0],[0]
Visual coherence style questions test the capability to identify an incoherent image in an ordered set of images given the titles and descriptions of the corresponding recipe as the context.,3.3 Visual Coherence,[0],[0]
"Hence, to be successful at this task, a system needs to not only understand the relations between candidate steps, but also align and relate different modalities existing in the context and the answers.",3.3 Visual Coherence,[0],[0]
"While generating the answer candidates for this task, we randomly select a single representative image from a single step and replace this image with a distractor image via employing the distractor selection strategy used for visual cloze task.",3.3 Visual Coherence,[0],[0]
"In Fig. 5 (third row), we provide a sample visual coherence style question from RecipeQA.",3.3 Visual Coherence,[0],[0]
Visual ordering questions test the ability of a system in finding a correctly ordered sequence given a jumbled set of representative images of a recipe.,3.4 Visual Ordering,[0],[0]
"As in the previous visual tasks, the context of this task consists of the titles and descriptions of a recipe.",3.4 Visual Ordering,[0],[0]
"To
Context Modalities: Titles and Descriptions of Steps
Recipe: Bacon Sushi
successfully complete this task, the system needs to understand the temporal occurrence of a sequence of recipe steps and infer temporal relations between candidates, i.e. boiling the water first, putting the
spaghetti next, so that the ordered sequence of images aligns with the given recipe.",3.4 Visual Ordering,[0],[0]
"To generate answer choices, we simply use random permutations of the illustrative images in the recipe steps.",3.4 Visual Ordering,[0],[0]
"In
Fig. 5 (last row), we illustrate this visual ordering task through an example question.",3.4 Visual Ordering,[0],[0]
"Here, we should note that a similar task has been previously investigated by Agrawal et al. (2016) for visual stories where the task is to order a jumbled set of aligned image-description pairs.",3.4 Visual Ordering,[0],[0]
Ingredient Detection.,4.1 Data Preparation,[0],[0]
"We employed the method proposed in (Salvador et al., 2017) to detect recipe ingredients.",4.1 Data Preparation,[0],[0]
"To learn more effective word embeddings, we transformed the ingredients with compound words such as olive oil into single word ingredients with a proper hyphenation as olive oil.
",4.1 Data Preparation,[0],[0]
Textual Embeddings.,4.1 Data Preparation,[0],[0]
"We trained a distributed memory model, namely Doc2Vec (Le and Mikolov, 2014) and used it to learn word level and document level embeddings while encoding the semantic similarity by taking into account the word order within the provided context.",4.1 Data Preparation,[0],[0]
"In this way, we can represent each word, sentence or paragraph by a fixed sized vector.",4.1 Data Preparation,[0],[0]
"In our experiments, we employed 100-d vectors to represent all of the textual modalities (titles and descriptions).",4.1 Data Preparation,[0],[0]
"We made sure that the embeddings encode semantically useful information by exploring nearest neighbors (see Fig. 6 for some examples.)
",4.1 Data Preparation,[0],[0]
Visual Features.,4.1 Data Preparation,[0],[0]
"We used the final activation of the ResNet-50 (He et al., 2016) model trained on the ImageNet dataset (Russakovsky et al., 2015) to extract 2048-d dense visual representations.",4.1 Data Preparation,[0],[0]
"Then, we further utilized an autoencoder to decrease the dimension of the visual features to 100-d so that they become compatible in size with the text embeddings.",4.1 Data Preparation,[0],[0]
Neural Baselines.,4.2 Baseline Models,[0],[0]
"For our neural baselines, we adapted the Impatient Reader model in (Hermann et al., 2015), which was originally developed only for the cloze style text comprehension questions in the CNN/Daily Mail dataset.",4.2 Baseline Models,[0],[0]
"In our implementation, we used a uni-directional stacked LSTM architecture with 3 layers, in which we feed the context of the question to the network in a sequential manner.",4.2 Baseline Models,[0],[0]
"Particularly, we preserve the temporal order of the steps of the recipe while feeding it to the neural model, by mimicking the most common reading strategy – reading from top to bottom.",4.2 Baseline Models,[0],[0]
"For the multimodal setting, since images are represented with vectors which are of the same size with the text embeddings, we also feed the images to the network in the same order they are presented in the recipe.
",4.2 Baseline Models,[0],[0]
"In order to account for different question types, we employ a modular architecture, which requires small adjustments to be made for each task.",4.2 Baseline Models,[0],[0]
"For instance, we place the candidate answers into query for the cloze style questions or remove the candidate answer from the query for the visual coherence type questions.",4.2 Baseline Models,[0],[0]
"In training our Impatient Reader baseline model, we use a cosine similarity function and employed the hinge ranking loss (Collobert et al., 2011) as follows:
L = max{0,M − cos(q, a+) + cos(q, a−)} (1)
where M is a scalar denoting the margin, a+ represents the ground truth answer, and a− corresponds to an incorrect answer which is sampled randomly from the whole answer space.",4.2 Baseline Models,[0],[0]
"For all of our experiments, we select M as 1.5 and employ a simple heuristic to prevent overfitting by following an early stopping scheme with patience set to 10 against the validation set accuracy after the initial epoch.",4.2 Baseline Models,[0],[0]
"For the optimizer, we use ADAM and set the learning rate to 1e−3.",4.2 Baseline Models,[0],[0]
The training took around 18 to 24 hours on GTX 1080Ti on a single GPU.,4.2 Baseline Models,[0],[0]
"We did not perform any hyperparameter tuning.
",4.2 Baseline Models,[0],[0]
Simple Baselines.,4.2 Baseline Models,[0],[0]
"We adapt the Hasty Student model described in (Tapaswi et al., 2016), which does not consider the provided context and simply answers questions by only looking at the similarities or the dissimilarities between the elements in questions and the candidate answers.
",4.2 Baseline Models,[0],[0]
"For the textual close task, each candidate answer is compared against the titles or descriptions of
the steps by using WMD (Kusner et al., 2015) distance, where such distances are averaged.",4.2 Baseline Models,[0],[0]
"Then, the choice closest to all of the question steps is selected as the final answer.",4.2 Baseline Models,[0],[0]
"For the visual cloze task, a similar approach is carried out by considering images instead of text using deep visual features.",4.2 Baseline Models,[0],[0]
"For the visual coherence task, since the aim is to find the incoherent image among other images, the final answer is chosen as the most dissimilar one to the remaining images on average.",4.2 Baseline Models,[0],[0]
"Lastly, for the visual ordering task, first, the distances between each consecutive image pair in a candidate ordering of the jumbled image set is estimated.",4.2 Baseline Models,[0],[0]
"Then, each candidate ordering is scored based on the average of these pairwise distances and the choice with the minimum average distance is set as the final answer.",4.2 Baseline Models,[0],[0]
"In all these simple baseline models, we use the cosine distance to rank the candidates.",4.2 Baseline Models,[0],[0]
We report the performance of the baseline models in Table 2 which indicates the ratio of correct answers against the total questions in the test.,4.3 Baseline Results,[0],[0]
"For the textual cloze, the comparison between text-only and multimodal Impatient Reader models shows that the additional visual modality helps the model to understand the question better and to provide more accurate answers.",4.3 Baseline Results,[0],[0]
"While for the cloze style questions, the Impatient Reader outperforms the Hasty student, for the visual coherence and visual ordering style questions Hasty student gives way better results.",4.3 Baseline Results,[0],[0]
This demonstrates that better neural models are needed to be able to effectively deal with this kind of questions.,4.3 Baseline Results,[0],[0]
Some qualitative examples are provided in the supplementary material.,4.3 Baseline Results,[0],[0]
Question Answering has been studied extensively in the literature.,5 Related Work,[0],[0]
"With the success of deep learning approaches in question answering, comprehension and reasoning aspects of the task has attracted researchers to investigate QA as a medium to measure intelligence.",5 Related Work,[0],[0]
"Various datasets and methods
have been proposed for measuring different aspects of the comprehension and reasoning problem.",5 Related Work,[0],[0]
Each dataset has its own merits as well as weaknesses.,5 Related Work,[0],[0]
"Recently, a thorough analysis by (Chen et al., 2016) revealed that the required reasoning and inference level was quite simple for CNN/Daily Mail dataset (Hermann et al., 2015).",5 Related Work,[0],[0]
"To make reasoning task more realistic, new datasets such as SQuAD (Rajpurkar et al., 2016), NewsQA (Trischler et al., 2017), MSMARCO (Nguyen et al., 2016), CLEVR (Johnson et al., 2017), COMICS (Iyyer et al., 2017) and FigureQA (Kahou et al., 2018) have been proposed.
",5 Related Work,[0],[0]
"In the following, we briefly discuss the publicly available datasets that are closely related to our problem and provide an overview in Table 3.
",5 Related Work,[0],[0]
"The closest works to ours are (Iyyer et al., 2017), (Tapaswi et al., 2016) and (Kembhavi et al., 2017) where data multi-modality is the key aspect.",5 Related Work,[0],[0]
"COMICS dataset (Iyyer et al., 2017) focus on comic book narratives and explore visual cloze style questions, introducing a dataset consisting of drawings from comic books.",5 Related Work,[0],[0]
The dataset is constructed from 4K Golden Age (1938-1954) comic books from the Digital Comics Museum and contains 1.2M panels with 2.5M textboxes.,5 Related Work,[0],[0]
"Three tasks are evaluated in this context, namely text cloze, visual cloze, character coherence.",5 Related Work,[0],[0]
"MovieQA dataset (Tapaswi et al., 2016), comprises of 15K crowdsourced questions about 408 movies.",5 Related Work,[0],[0]
"It consists of movie clips, subtitles, and snapshots, is about comprehending stories about movies.",5 Related Work,[0],[0]
"TQA dataset (Kembhavi et al., 2017), have 26K questions about 1K middle school science lessons with 3.5K im-
ages, mostly of diagrams and aims at addressing middle school knowledge acquisition using both images and text.",5 Related Work,[0],[0]
"Since the audience is middle school children, it requires limited reasoning.
",5 Related Work,[0],[0]
RecipeQA substantially differentiates from the previous work in the following way.,5 Related Work,[0],[0]
"Our dataset consists of natural images that are taken by anonymous users in unconstrained environments, which is a major diversion from COMICS and TQA datasets.
",5 Related Work,[0],[0]
It should also be noted that there has been a long history of research involving cooking recipes.,5 Related Work,[0],[0]
"Recent examples include parsing of recipes (Malmaud et al., 2014; Jermsurawong and Habash, 2015), aligning instructional text to videos (Malmaud et al., 2015; Sener et al., 2015), recipe text generation (Kiddon et al., 2016), learning cross-modal embeddings (Salvador et al., 2017), tracking entities and action transformations in recipes (Bosselut et al., 2018).
",5 Related Work,[0],[0]
"Finally, to our best knowledge, there is no dataset focusing on “how-to” instructions or recipes; hence, this work will be the first to serve multimodal comprehension of recipes having an arbitrary number of steps aligned with multiple images and multiple sentences.",5 Related Work,[0],[0]
"We present RecipeQA, a dataset for multimodal comprehension of cooking recipes, which consists of roughly 20K cooking recipes with over 36K context-question-answer triplets.",6 Conclusion,[0],[0]
"To our knowledge, RecipeQA is the first machine comprehension dataset that deals with understanding procedural knowledge in a multimodal setting.",6 Conclusion,[0],[0]
Each one of the four question styles in our dataset is specifically tailored to evaluate a particular skill and requires connecting the dots between different modalities.,6 Conclusion,[0],[0]
Results of our baseline models demonstrate that RecipeQA is a challenging dataset and we plan make it publicly available for other researchers to promote the development of new methods for multimodal machine comprehension.,6 Conclusion,[0],[0]
"In the future, we also intend to extend the dataset by collecting natural language questions-answer pairs via crowdsourcing.",6 Conclusion,[0],[0]
We also hope that RecipeQA will serve other purposes for related research problems on cooking recipes as well.,6 Conclusion,[0],[0]
"We would like to thank our anonymous reviewers for their insightful comments and suggestions, which helped us improve the paper, Taha Sevim and Kenan Hagverdiyev for their help in building the RecipeQA challenge website, and NVIDIA Corporation for the donation of GPUs used in this research.",Acknowledgments,[0],[0]
This work was supported in part by a Hacettepe BAP fellowship (FBB-2016-11653) awarded to Erkut Erdem.,Acknowledgments,[0],[0]
Semih Yagcioglu was partly sponsored by STM A.Ş.,Acknowledgments,[0],[0]
Understanding and reasoning about cooking recipes is a fruitful research direction towards enabling machines to interpret procedural text.,abstractText,[0],[0]
"In this work, we introduce RecipeQA, a dataset for multimodal comprehension of cooking recipes.",abstractText,[0],[0]
"It comprises of approximately 20K instructional recipes with multiple modalities such as titles, descriptions and aligned set of images.",abstractText,[0],[0]
"With over 36K automatically generated question-answer pairs, we design a set of comprehension and reasoning tasks that require joint understanding of images and text, capturing the temporal flow of events and making sense of procedural knowledge.",abstractText,[0],[0]
Our preliminary results indicate that RecipeQA will serve as a challenging test bed and an ideal benchmark for evaluating machine comprehension systems.,abstractText,[0],[0]
The data and leaderboard are available at http://hucvl.github.io/recipeqa.,abstractText,[0],[0]
RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1224–1233, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
Recognizing implicit discourse relations is a challenging but important task in the field of Natural Language Processing. For such a complex text processing task, different from previous studies, we argue that it is necessary to repeatedly read the arguments and dynamically exploit the efficient features useful for recognizing discourse relations. To mimic the repeated reading strategy, we propose the neural networks with multi-level attention (NNMA), combining the attention mechanism and external memories to gradually fix the attention on some specific words helpful to judging the discourse relations. Experiments on the PDTB dataset show that our proposed method achieves the state-ofart results. The visualization of the attention weights also illustrates the progress that our model observes the arguments on each level and progressively locates the important words.",text,[0],[0]
"Discourse relations (e.g., contrast and causality) support a set of sentences to form a coherent text.",1 Introduction,[0],[0]
Automatically recognizing discourse relations can help many downstream tasks such as question answering and automatic summarization.,1 Introduction,[0],[0]
"Despite great progress in classifying explicit discourse relations where the discourse connectives (e.g., “because”, “but”) explicitly exist in the text, implicit discourse relation recognition remains a challenge due to the absence of discourse connectives.",1 Introduction,[0],[0]
"Previous research mainly focus on exploring various kinds of efficient features and machine learning models to classify the implicit discourse
relations (Soricut and Marcu, 2003; Baldridge and Lascarides, 2005; Subba and Di Eugenio, 2009; Hernault et al., 2010; Pitler et al., 2009; Joty et al., 2012).",1 Introduction,[0],[0]
"To some extent, these methods simulate the single-pass reading process that a person quickly skim the text through one-pass reading and directly collect important clues for understanding the text.",1 Introduction,[0],[0]
"Although single-pass reading plays a crucial role when we just want the general meaning and do not necessarily need to understand every single point of the text, it is not enough for tackling tasks that need a deep analysis of the text.",1 Introduction,[0],[0]
"In contrast with single-pass reading, repeated reading involves the process where learners repeatedly read the text in detail with specific learning aims, and has the potential to improve readers’ reading fluency and comprehension of the text (National Institute of Child Health and Human Development, 2000; LaBerge and Samuels, 1974).",1 Introduction,[0],[0]
"Therefore, for the task of discourse parsing, repeated reading is necessary, as it is difficult to generalize which words are really useful on the first try and efficient features should be dynamically exploited through several passes of reading .
",1 Introduction,[0],[0]
"Now, let us check one real example to elaborate the necessity of using repeated reading in discourse parsing.",1 Introduction,[0],[0]
"Arg-1 : the use of 900 toll numbers has been
expanding rapidly in recent years
Arg-2 : for a while, high-cost pornography lines and services that tempt children to dial (and redial) movie or music information earned the service a somewhat sleazy image
(Comparison - wsj 2100)
To identify the “Comparison” relation between
1224
the two arguments Arg-1 and Arg-2, the most crucial clues mainly lie in some content, like “expanding rapidly” in Arg-1 and “earned the service a somewhat sleazy image” in Arg-2, since there exists a contrast between the semantic meanings of these two text spans.",1 Introduction,[0],[0]
"However, it is difficult to obtain sufficient information for pinpointing these words through scanning the argument pair left to right in one pass.",1 Introduction,[0],[0]
"In such case, we follow the repeated reading strategy, where we obtain the general meaning through reading the arguments for the first time, re-read them later and gradually pay close attention to the key content.
",1 Introduction,[0],[0]
"Recently, some approaches simulating repeated reading have witnessed their success in different tasks.",1 Introduction,[0],[0]
"These models mostly combine the attention mechanism that has been originally designed to solve the alignment problem in machine translation (Bahdanau et al., 2014) and the external memory which can be read and written when processing the objects (Sukhbaatar et al., 2015).",1 Introduction,[0],[0]
"For example, Kumar et al. (2015) drew attention to specific facts of the input sequence and processed the sequence via multiple hops to generate an answer.",1 Introduction,[0],[0]
"In computation vision, Yang et al. (2015) pointed out that repeatedly giving attention to different regions of an image could gradually lead to more precise image representations.
",1 Introduction,[0],[0]
"Inspired by these recent work, for discourse parsing, we propose a model that aims to repeatedly read an argument pair and gradually focus on more fine-grained parts after grasping the global information.",1 Introduction,[0],[0]
"Specifically, we design the Neural Networks with Multi-Level Attention (NNMA) consisting of one general level and several attention levels.",1 Introduction,[0],[0]
"In the general level, we capture the general representations of each argument based on two bidirectional long short-term memory (LSTM) models.",1 Introduction,[0],[0]
"For each attention level, NNMA generates a weight vector over the argument pair to locate the important parts related to the discourse relation.",1 Introduction,[0],[0]
And an external short-term memory is designed to store the information exploited in previous levels and help update the argument representations.,1 Introduction,[0],[0]
"We stack this structure in a recurrent manner, mimicking the process of reading the arguments multiple times.",1 Introduction,[0],[0]
"Finally, we use the representation output from the highest attention level to identify the discourse
relation.",1 Introduction,[0],[0]
Experiments on the PDTB dataset show that our proposed model achieves the state-of-art results.,1 Introduction,[0],[0]
"In this section, we describe how we use the neural networks with multi-level attention to repeatedly read the argument pairs and recognize implicit discourse relations.
",2 Repeated Reading Neural Network with Multi-Level Attention,[0],[0]
"First, we get the general understanding of the arguments through skimming them.",2 Repeated Reading Neural Network with Multi-Level Attention,[0],[0]
"To implement this, we adopt the bidirectional Long-Short Term Memory Neural Network (bi-LSTM) to model each argument, as bi-LSTM is good at modeling over a sequence of words and can represent each word with consideration of more contextual information.",2 Repeated Reading Neural Network with Multi-Level Attention,[0],[0]
"Then, several attention levels are designed to simulate the subsequent multiple passes of reading.",2 Repeated Reading Neural Network with Multi-Level Attention,[0],[0]
"On each attention level, an external short-term memory is used to store what has been learned from previous passes and guide which words should be focused on.",2 Repeated Reading Neural Network with Multi-Level Attention,[0],[0]
"To pinpoint the useful parts of the arguments, the attention mechanism is used to predict a probability distribution over each word, indicating to what degree each word should be concerned.",2 Repeated Reading Neural Network with Multi-Level Attention,[0],[0]
The overall architecture of our model is shown in Figure 1.,2 Repeated Reading Neural Network with Multi-Level Attention,[0],[0]
"For clarity, we only illustrate two attention levels in the figure.",2 Repeated Reading Neural Network with Multi-Level Attention,[0],[0]
It is noted that we can easily extend our model to more attention levels.,2 Repeated Reading Neural Network with Multi-Level Attention,[0],[0]
The Long-Short Term Memory (LSTM) Neural Network is a variant of the Recurrent Neural Network which is usually used for modeling a sequence.,2.1 Representing Arguments with LSTM,[0],[0]
"In our model, we adopt two LSTM neural networks to respectively model the two arguments: the left argument Arg-1 and the right argument Arg2.
",2.1 Representing Arguments with LSTM,[0],[0]
"First of all, we associate each word w in our vocabulary with a vector representation xw ∈ RDe .",2.1 Representing Arguments with LSTM,[0],[0]
"Here we adopt the pre-trained vectors provided by GloVe (Pennington et al., 2014).",2.1 Representing Arguments with LSTM,[0],[0]
"Since an argument can be viewed as a sequence of word vectors, let x1i (x2i ) be the i-th word vector in argument Arg-1 (Arg-
2) and the two arguments can be represented as,
Arg-1 :",2.1 Representing Arguments with LSTM,[0],[0]
"[x11,x 1 2, · · · ,x1L1 ] Arg-2 :",2.1 Representing Arguments with LSTM,[0],[0]
"[x21,x 2 2, · · · ,x2L2 ]
where Arg-1 has L1 words and Arg-2 has L2 words.",2.1 Representing Arguments with LSTM,[0],[0]
"To model the two arguments, we briefly introduce the working process how the LSTM neural networks model a sequence of words.",2.1 Representing Arguments with LSTM,[0],[0]
"For the i-th time step, the model reads the i-th word xi as the input and updates the output vector hi as follows (Zaremba and Sutskever, 2014).
",2.1 Representing Arguments with LSTM,[0],[0]
"ii = sigmoid(Wi[xi,hi−1] + bi) (1)
fi = sigmoid(Wf",2.1 Representing Arguments with LSTM,[0],[0]
"[xi,hi−1] + bf )",2.1 Representing Arguments with LSTM,[0],[0]
"(2)
oi = sigmoid(Wo[xi,hi−1] + bo) (3)
c̃i = tanh(Wc[xi,hi−1] + bc) (4) ci = ii ∗ c̃i + fi",2.1 Representing Arguments with LSTM,[0],[0]
∗ ci−1 (5) hi =,2.1 Representing Arguments with LSTM,[0],[0]
"oi ∗ tanh(ci) (6)
where [ ] means the concatenation operation of several vectors.",2.1 Representing Arguments with LSTM,[0],[0]
"i,f ,o and c denote the input gate, forget gate, output gate and memory cell
respectively in the LSTM architecture.",2.1 Representing Arguments with LSTM,[0],[0]
The input gate i determines how much the input xi updates the memory cell.,2.1 Representing Arguments with LSTM,[0],[0]
The output gate o controls how much the memory cell influences the output.,2.1 Representing Arguments with LSTM,[0],[0]
The forget gate f controls how the past memory ci−1 affects the current state.,2.1 Representing Arguments with LSTM,[0],[0]
"Wi,Wf ,Wo,Wc, bi, bf , bo, bc are the network parameters.
",2.1 Representing Arguments with LSTM,[0],[0]
"Referring to the work of Wang and Nyberg (2015), we implement the bidirectional version of LSTM neural network to model the argument sequence.",2.1 Representing Arguments with LSTM,[0],[0]
"Besides processing the sequence in the forward direction, the bidirectional LSTM (biLSTM) neural network also processes it in the reverse direction.",2.1 Representing Arguments with LSTM,[0],[0]
"As shown in Figure 1, using two bi-LSTM neural networks, we can obtain h1i =",2.1 Representing Arguments with LSTM,[0],[0]
"[~h1i , ~h1i ]",2.1 Representing Arguments with LSTM,[0],[0]
for the i-th word in Arg-1 and h 2 i =,2.1 Representing Arguments with LSTM,[0],[0]
"[ ~h2i , ~h2i ] for the i-th word in Arg-2,",2.1 Representing Arguments with LSTM,[0],[0]
"where ~h1i , ~h 2",2.1 Representing Arguments with LSTM,[0],[0]
"i ∈ Rd and ~h1i , ~h 2",2.1 Representing Arguments with LSTM,[0],[0]
i ∈ Rd are the output vectors from two directions.,2.1 Representing Arguments with LSTM,[0],[0]
"Next, to get the general-level representations of the arguments, we apply a mean pooling operation over the bi-LSTM outputs, and obtain two vectors R10 and R 2 0, which can reflect the global information of the argument pair.
",2.1 Representing Arguments with LSTM,[0],[0]
"R10 = 1
L1
L1∑
i=0
h1i (7)
",2.1 Representing Arguments with LSTM,[0],[0]
"R20 = 1
L2
L2∑
i=0
h2i (8)",2.1 Representing Arguments with LSTM,[0],[0]
"After obtaining the general-level representations by treating each word equally, we simulate the repeated reading and design multiple attention levels to gradually pinpoint those words particularly useful for discourse relation recognition.",2.2 Tuning Attention via Repeated Reading,[0],[0]
"In each attention level, we adopt the attention mechanism to determine which words should be focused on.",2.2 Tuning Attention via Repeated Reading,[0],[0]
"An external short-term memory is designed to remember what has seen in the prior levels and guide the attention tuning process in current level.
",2.2 Tuning Attention via Repeated Reading,[0],[0]
"Specifically, in the first attention level, we concatenate R10, R 2 0 and R 1 0−R20 and apply a non-linear transformation over the concatenation to catch the general understanding of the argument pair.",2.2 Tuning Attention via Repeated Reading,[0],[0]
"The use of R10−R20 takes a cue from the difference between two vector representations which
has been found explainable and meaningful in many applications (Mikolov et al., 2013).",2.2 Tuning Attention via Repeated Reading,[0],[0]
"Then, we get the memory vector M1 ∈ Rdm of the first attention level as
M1 = tanh(Wm,1[R 1 0,R 2 0,R 1 0−R20]) (9)
where Wm,1 ∈ Rdm×6d is the weight matrix.",2.2 Tuning Attention via Repeated Reading,[0],[0]
"With M1 recording the general meaning of the argument pair, our model re-calculates the importance of each word.",2.2 Tuning Attention via Repeated Reading,[0],[0]
We assign each word a weight measuring to what degree our model should pay attention to it.,2.2 Tuning Attention via Repeated Reading,[0],[0]
The weights are so-called “attention” in our paper.,2.2 Tuning Attention via Repeated Reading,[0],[0]
This process is designed to simulate the process that we re-read the arguments and pay more attention to some specific words with an overall understanding derived from the first-pass reading.,2.2 Tuning Attention via Repeated Reading,[0],[0]
"Formally, for Arg-1, we use the memory vector M1 to update the representation of each word with a non-linear transformation.",2.2 Tuning Attention via Repeated Reading,[0],[0]
"According to the updated word representations o11, we get the attention vector a11.
",2.2 Tuning Attention via Repeated Reading,[0],[0]
h1 =,2.2 Tuning Attention via Repeated Reading,[0],[0]
"[h10,h 1 1, · · · ,h1L1 ] (10) o11",2.2 Tuning Attention via Repeated Reading,[0],[0]
"= tanh(W 1 a,1h
1 + W 1b,1(M1 ⊗ e))",2.2 Tuning Attention via Repeated Reading,[0],[0]
"(11) a11 = softmax(W 1 s,1o 1 1) (12)
where h1 ∈ R2d×L1 is the concatenation of all LSTM output vectors of Arg-1.",2.2 Tuning Attention via Repeated Reading,[0],[0]
e ∈ RL1 is a vector of 1s and the M1 ⊗ e operation denotes that we repeat the vector M1 L1 times and generate a dm × L1 matrix.,2.2 Tuning Attention via Repeated Reading,[0],[0]
The attention vector a11 ∈ RL1 is obtained through applying a softmax operation over o11.,2.2 Tuning Attention via Repeated Reading,[0],[0]
"Wa,1
1 ∈ R2d×2d,Wb,11 ∈ R2d×dm and Ws,1
1 ∈ R1×2d are the transformation weights.",2.2 Tuning Attention via Repeated Reading,[0],[0]
It is noted that the subscripts denote the current attention level and the superscripts denote the corresponding argument.,2.2 Tuning Attention via Repeated Reading,[0],[0]
"In the same way, we can get the attention vector a21 for Arg-2.
",2.2 Tuning Attention via Repeated Reading,[0],[0]
"Then, according to a11 and a 2 1, our model re-reads the arguments and get the new representations R11 and R21 for the first attention level.
",2.2 Tuning Attention via Repeated Reading,[0],[0]
R11 = h 1(a11) T (13),2.2 Tuning Attention via Repeated Reading,[0],[0]
"R21 = h 2(a21) T (14)
",2.2 Tuning Attention via Repeated Reading,[0],[0]
"Next, we iterate the “memory-attentionrepresentation” process and design more attention
levels, giving NNMA the ability to gradually infer more precise attention vectors.",2.2 Tuning Attention via Repeated Reading,[0],[0]
"The processing of the second or above attention levels is slightly different from that of the first level, as we update the memory vector in a recurrent way.",2.2 Tuning Attention via Repeated Reading,[0],[0]
"To formalize, for the k-th attention level (k ≥ 2), we use the following formulae for Arg-1.
",2.2 Tuning Attention via Repeated Reading,[0],[0]
"Mk = tanh(Wm,k[R 1 k−1,R2k−1,R1k−1−R2k−1,Mk−1])
(15)
o1k = tanh(W 1 a,kh 1 + W 1b,k(Mk ⊗ e)) (16) a1k = softmax(W 1 s,ko 1 k) (17)
R1k = h 1(a1k) T (18)
",2.2 Tuning Attention via Repeated Reading,[0],[0]
"In the same way, we can computer o2k,a 2 k and R 2 k for Arg-2.",2.2 Tuning Attention via Repeated Reading,[0],[0]
"Finally, we use the newest representation derived from the top attention level to recognize the discourse relations.",2.2 Tuning Attention via Repeated Reading,[0],[0]
"Suppose there are totally K attention levels and n relation types, the predicted discourse relation distribution P ∈",2.2 Tuning Attention via Repeated Reading,[0],[0]
"Rn is calculated as
P = softmax(Wp[R 1 K ,R 2 K ,R 1 K−R2K ] + bp)
(19)
where Wp ∈ Rn×6d and bp ∈ Rn are the transformation weights.",2.2 Tuning Attention via Repeated Reading,[0],[0]
"To train our model, the training objective is defined as the cross-entropy loss between the outputs of the softmax layer and the ground-truth class labels.",2.3 Model Training,[0],[0]
"We use stochastic gradient descent (SGD) with momentum to train the neural networks.
",2.3 Model Training,[0],[0]
"To avoid over-fitting, dropout operation is applied on the top feature vector before the softmax layer.",2.3 Model Training,[0],[0]
"Also, we use different learning rates λ and λe to train the neural network parameters Θ and the word embeddings",2.3 Model Training,[0],[0]
"Θe referring to (Ji and Eisenstein, 2015).",2.3 Model Training,[0],[0]
λe is set to a small value for preventing overfitting on this task.,2.3 Model Training,[0],[0]
"In the experimental part, we will introduce the setting of the hyper-parameters.",2.3 Model Training,[0],[0]
"We evaluate our model on the Penn Discourse Treebank (PDTB) (Prasad et al., 2008).",3.1 Preparation,[0],[0]
"In our work,
we experiment on the four top-level classes in this corpus as in previous work (Rutherford and Xue, 2015).",3.1 Preparation,[0],[0]
"We extract all the implicit relations of PDTB, and follow the setup of (Rutherford and Xue, 2015).",3.1 Preparation,[0],[0]
"We split the data into a training set (Sections 2- 20), development set (Sections 0-1), and test set (Section 21-22).",3.1 Preparation,[0],[0]
"Table 1 summarizes the statistics of the four PDTB discourse relations, i.e., Comparison, Contingency, Expansion and Temporal.
",3.1 Preparation,[0],[0]
We first convert the tokens in PDTB to lowercase.,3.1 Preparation,[0],[0]
"The word embeddings used for initializing the word representations are provided by GloVe (Pennington et al., 2014), and the dimension of the embeddings De is 50.",3.1 Preparation,[0],[0]
"The hyper-parameters, including the momentum δ, the two learning rates λ and λe, the dropout rate q, the dimension of LSTM output vector d, the dimension of memory vector dm are all set according to the performance on the development set Due to space limitation, we do not present the details of tuning the hyper-parameters and only give their final settings as shown in Table 2.
To evaluate our model, we adopt two kinds of experiment settings.",3.1 Preparation,[0],[0]
"The first one is the fourway classification task, and the second one is the binary classification task, where we build a onevs-other classifier for each class.",3.1 Preparation,[0],[0]
"For the second setting, to solve the problem of unbalanced classes in the training data, we follow the reweighting method of (Rutherford and Xue, 2015) to reweigh the training instances according to the size of each relation class.",3.1 Preparation,[0],[0]
We also use visualization methods to analyze how multi-level attention helps our model.,3.1 Preparation,[0],[0]
"First, we design experiments to evaluate the effectiveness of attention levels and how many attention levels are appropriate.",3.2 Results,[0],[0]
"To this end, we implement a baseline model (LSTM with no attention) which directly applies the mean pooling operation over LSTM output vectors of two arguments without any attention mechanism.",3.2 Results,[0],[0]
"Then we consider different attention levels including one-level, twolevel and three-level.",3.2 Results,[0],[0]
The detailed results are shown in Table 3.,3.2 Results,[0],[0]
"For four-way classification, macroaveraged F1 and Accuracy are used as evaluation metrics.",3.2 Results,[0],[0]
"For binary classification, F1 is adopted to evaluate the performance on each class.
",3.2 Results,[0],[0]
"From Table 3, we can see that the basic LSTM model performs the worst.",3.2 Results,[0],[0]
"With attention levels added, our NNMA model performs much better.",3.2 Results,[0],[0]
This confirms the observation above that one-pass reading is not enough for identifying the discourse relations.,3.2 Results,[0],[0]
"With respect to the four-way F1 measure, using NNMA with one-level attention produces a 4% improvement over the baseline system with no attention.",3.2 Results,[0],[0]
Adding the second attention level gives another 2.8% improvement.,3.2 Results,[0],[0]
"We perform significance test for these two improvements, and they are both significant under one-tailed t-test (p < 0.05).",3.2 Results,[0],[0]
"However, when adding the third attention level, the performance does not promote much and almost reaches its plateau.",3.2 Results,[0],[0]
We can see that threelevel NNMA experiences a decease in F1 and a slight increase in Accuracy compared to two-level NNMA.,3.2 Results,[0],[0]
"The results imply that with more attention levels considered, our model may perform slightly better, but it may incur the over-fitting problem due to adding more parameters.",3.2 Results,[0],[0]
"With respect to the binary classification F1 measures, we can see
that the “Comparison” relation needs more passes of reading compared to the other three relations.",3.2 Results,[0],[0]
"The reason may be that the identification of the “Comparison” depends more on some deep analysis such as semantic parsing, according to (Zhou et al., 2010).
",3.2 Results,[0],[0]
"Next, we compare our models with six state-ofthe-art baseline approaches, as shown in Table 4.",3.2 Results,[0],[0]
"The six baselines are introduced as follows.
",3.2 Results,[0],[0]
• P&C2012:,3.2 Results,[0],[0]
Park and Cardie (2012) designed a feature-based method and promoted the performance through optimizing the feature set.,3.2 Results,[0],[0]
•,3.2 Results,[0],[0]
"J&E2015: Ji and Eisenstein (2015) used two
recursive neural networks on the syntactic parse tree to induce the representation of the arguments and the entity spans.",3.2 Results,[0],[0]
• Zhang2015:,3.2 Results,[0],[0]
"Zhang et al. (2015) proposed
to use shallow convolutional neural networks to model two arguments respectively.",3.2 Results,[0],[0]
We replicated their model since they used a different setting in preprocessing PDTB.,3.2 Results,[0],[0]
"• R&X2014, R&X2015: Rutherford and Xue
(2014) selected lexical features, production rules, and Brown cluster pairs, and fed them into a maximum entropy classifier.",3.2 Results,[0],[0]
Rutherford and Xue (2015) further proposed to gather extra weakly labeled data based on the discourse connectives for the classifier.,3.2 Results,[0],[0]
•,3.2 Results,[0],[0]
B&D2015:,3.2 Results,[0],[0]
"Braud and Denis (2015) combined
several hand-crafted lexical features and word embeddings to train a max-entropy classifier.
",3.2 Results,[0],[0]
"• Liu2016: Liu et al. (2016) proposed to better classify the discourse relations by learning from other discourse-related tasks with a multitask neural network.
",3.2 Results,[0],[0]
• Ji2016:,3.2 Results,[0],[0]
"Ji et al. (2016) proposed a neural language model over sequences of words and used the discourse relations as latent variables to connect the adjacent sequences.
",3.2 Results,[0],[0]
It is noted that P&C2012,3.2 Results,[0],[0]
and J&E2015 merged the “EntRel” relation into the “Expansion” relation1.,3.2 Results,[0],[0]
"For a comprehensive comparison, we also experiment our model by adding a Expa.+EntRel vs Other classification.",3.2 Results,[0],[0]
Our NNMA model with two attention levels exhibits obvious advantages over the six baseline methods on the whole.,3.2 Results,[0],[0]
"It is worth noting that NNMA is even better than the R&X2015 approach which employs extra data.
",3.2 Results,[0],[0]
"As for the performance on each discourse relation, with respect to the F1 measure, we can see that our NNMA model can achieve the best results on the “Expansion”, “Expansion+EntRel” and “Temporal” relations and competitive results on the “Contingency” relation .",3.2 Results,[0],[0]
The performance of recognizing the “Comparison” relation is only worse than R&X2014 and R&X2015.,3.2 Results,[0],[0]
"As (Rutherford and Xue, 2014) stated, the “Comparison” relation is closely related to the constituent parse feature of the text, like production rules.",3.2 Results,[0],[0]
"How to represent and
1EntRel is the entity-based coherence relation which is independent of implicit and explicit relations in PDTB.",3.2 Results,[0],[0]
"However some research merges it into the implicit Expansion relation.
exploit these information in our model will be our next research focus.",3.2 Results,[0],[0]
The multiple attention levels in our model greatly boost the performance of classifying implicit discourse relations.,3.3 Analysis of Attention Levels,[0],[0]
"In this subsection, we perform both qualitative and quantitative analysis on the attention levels.
",3.3 Analysis of Attention Levels,[0],[0]
"First, we take a three-level NNMA model for example and analyze its attention distributions on different attention levels by calculating the mean Kullback-Leibler (KL) Divergence between any two levels on the training set.",3.3 Analysis of Attention Levels,[0],[0]
"In Figure 3, we use klij to denote the KL Divergence between the ith and the jthattention level and use klui to denote the KL Divergence between the uniform distribution and the ith attention level.",3.3 Analysis of Attention Levels,[0],[0]
We can see that each attention level forms different attention distributions and the difference increases in the higher levels.,3.3 Analysis of Attention Levels,[0],[0]
It can be inferred that the 2nd and 3rd levels in NNMA gradually neglect some words and pay more attention to some other words in the arguments.,3.3 Analysis of Attention Levels,[0],[0]
"One point worth mentioning is that Arg-2 tends to have more non-uniform attention weights, since klu2 and klu3 of Arg-2 are much larger than those of Arg1.",3.3 Analysis of Attention Levels,[0],[0]
"And also, the changes between attention levels are more obvious for Arg-2 through observing the values of kl12, kl13 and kl23.",3.3 Analysis of Attention Levels,[0],[0]
"The reason may be that Arg-2 contains more information related with discourse relation and some words in it tend to require focused attention, as Arg-2 is syntactically bound to the implicit connective.
",3.3 Analysis of Attention Levels,[0],[0]
"At the same time, we visualize the attention levels of some example argument pairs which are analyzed by the three-level NNMA.",3.3 Analysis of Attention Levels,[0],[0]
"To illustrate the kth attention level, we get its attention weights a1k and a2k which reflect the contribution of each word and then depict them by a row of color-shaded grids in Figure 2.
",3.3 Analysis of Attention Levels,[0],[0]
We can see that the NNMA model focuses on different words on different attention levels.,3.3 Analysis of Attention Levels,[0],[0]
"Interestingly, from Figure 2, we find that the 1st and 3rd attention levels focus on some similar words, while the 2nd level is relatively different from them.",3.3 Analysis of Attention Levels,[0],[0]
"It seems that NNMA tries to find some clues (e.g. “moscow could be suspended” in Arg-2a; “won the business” in Arg-1b; “with great aplomb he
considers not only” in Arg-2c) for recognizing the discourse relation on the 1st level, looking closely at other words (e.g. “misuse of psychiatry against dissenters” in Arg-2a; “a third party that” in Arg-1b; “and support of hitler” in Arg-2c) on the 2nd level, and then reconsider the arguments, focus on some specific words (e.g. “moscow could be suspended” in Arg-2a; “has not only hurt” in Arg-2b) and make the final decision on the last level.",3.3 Analysis of Attention Levels,[0],[0]
"The Penn Discourse Treebank (PDTB) (Prasad et al., 2008), known as the largest discourse corpus, is composed of 2159 Wall Street Journal articles.",4.1 Implicit Discourse Relation Classification,[0],[0]
"Each document is annotated with the predicate-argument structure, where the predicate is the discourse connective (e.g. while) and the arguments are two text spans around the connective.",4.1 Implicit Discourse Relation Classification,[0],[0]
The discourse connective can be either explicit or implicit.,4.1 Implicit Discourse Relation Classification,[0],[0]
"In PDTB, a hierarchy of relation tags is provided for annotation.",4.1 Implicit Discourse Relation Classification,[0],[0]
"In our study, we use the four top-level tags, including Temporal, Contingency, Comparison and Expansion.",4.1 Implicit Discourse Relation Classification,[0],[0]
"These four core relations allow us to be theory-neutral, since they are almost included in all discourse theories, sometimes with different names (Wang et al., 2012).
",4.1 Implicit Discourse Relation Classification,[0],[0]
Implicit discourse relation recognition is often treated as a classification problem.,4.1 Implicit Discourse Relation Classification,[0],[0]
"The first work to tackle this task on PDTB is (Pitler et al., 2009).",4.1 Implicit Discourse Relation Classification,[0],[0]
"They selected several surface features to train four binary classifiers, each for one of the top-level PDTB relation classes.",4.1 Implicit Discourse Relation Classification,[0],[0]
"Extending from this work, Lin et al. (2009) further identified four different feature types representing the context, the constituent parse trees, the dependency parse trees and the raw text respectively.",4.1 Implicit Discourse Relation Classification,[0],[0]
Rutherford and Xue (2014) used brown cluster to replace the word pair features for solving the sparsity problem.,4.1 Implicit Discourse Relation Classification,[0],[0]
Ji and Eisenstein (2015) adopted two recursive neural networks to exploit the representation of arguments and entity spans.,4.1 Implicit Discourse Relation Classification,[0],[0]
"Very recently, Liu et al. (2016) proposed a twodimensional convolutional neural network (CNN) to model the argument pairs and employed a multitask learning framework to boost the performance by learning from other discourse-related tasks.",4.1 Implicit Discourse Relation Classification,[0],[0]
"Ji et al. (2016) considered discourse relations as
Arg-1a
th e w",4.1 Implicit Discourse Relation Classification,[0],[0]
"or ld ps
yc hi
at ric
as so
ci at
io n vo te",4.1 Implicit Discourse Relation Classification,[0],[0]
d at an at he ns pa rle y to co nd iti on al ly re ad m it,4.1 Implicit Discourse Relation Classification,[0],[0]
th,4.1 Implicit Discourse Relation Classification,[0],[0]
e,4.1 Implicit Discourse Relation Classification,[0],[0]
"so vi et un io n
1 2 3 Attention Level
Arg-2a
m os
co w
co ul d be su
sp en
de d
if th e m isu se of ps",4.1 Implicit Discourse Relation Classification,[0],[0]
"yc hi
at ry
ag ai
ns t
di ss
en te rs is",4.1 Implicit Discourse Relation Classification,[0],[0]
di sc,4.1 Implicit Discourse Relation Classification,[0],[0]
ov,4.1 Implicit Discourse Relation Classification,[0],[0]
er ed du rin,4.1 Implicit Discourse Relation Classification,[0],[0]
"g a re vi ew w ith in a ye ar
1 2 3 Attention Level
(a) Example with Comparison relation
Arg-1b
bu t",4.1 Implicit Discourse Relation Classification,[0],[0]
ib,4.1 Implicit Discourse Relation Classification,[0],[0]
m,4.1 Implicit Discourse Relation Classification,[0],[0]
w,4.1 Implicit Discourse Relation Classification,[0],[0]
ou ld ha,4.1 Implicit Discourse Relation Classification,[0],[0]
"ve w on th e bu si
ne ss
an yw ay as a sa le to a th ird pa rt y th at w ou ld ha ve th en le as ed th e eq ui
pm en t to th e cu st om er
1 2 3 Attention Level
Arg-2b
ib m ha s no t on ly hu",4.1 Implicit Discourse Relation Classification,[0],[0]
"rt its sh or
tte rm re ve nu e ou tlo",4.1 Implicit Discourse Relation Classification,[0],[0]
"ok bu t ha s al so be en lo sin g m on ey on its le as es
1 2 3 Attention Level
(b) Example with Contingency relation
Arg-1 Arg-2 kl_12 0.00749 0.04177 kl_23 0.099784 0.502146 kl_13 0.085394 0.35212 kl_u1 0.123413 0.136228 kl_u2 0.156619 0.254844 kl_u3 0.162379 0.467976
0
0.1
0.2
0.3
0.4
0.5
0.6 Arg-1 Arg-2
l
Figure 3: KL-divergences between attention levels
latent variables connecting two token sequences and trained a discourse informed language model.",4.1 Implicit Discourse Relation Classification,[0],[0]
"Recently, neural network-based methods have gained prominence in the field of natural language processing (Kim, 2014).",4.2 Neural Networks and Attention Mechanism,[0],[0]
"Such methods are primarily based on learning a distributed representation for each word, which is also called a word embedding (Collobert et al., 2011).
",4.2 Neural Networks and Attention Mechanism,[0],[0]
"Attention mechanism was first introduced into neural models to solve the alignment problem
between different modalities.",4.2 Neural Networks and Attention Mechanism,[0],[0]
Graves (2013) designed a neural network to generate handwriting based on a text.,4.2 Neural Networks and Attention Mechanism,[0],[0]
It assigned a window on the input text at each step and generate characters based on the content within the window.,4.2 Neural Networks and Attention Mechanism,[0],[0]
"Bahdanau et al. (2014) introduced this idea into machine translation, where their model computed a probabilistic distribution over the input sequence when generating each target word.",4.2 Neural Networks and Attention Mechanism,[0],[0]
"Tan et al. (2015) proposed an attentionbased neural network to model both questions and sentences for selecting the appropriate non-factoid answers.
",4.2 Neural Networks and Attention Mechanism,[0],[0]
"In parallel, the idea of equipping the neural model with an external memory has gained increasing attention recently.",4.2 Neural Networks and Attention Mechanism,[0],[0]
A memory can remember what the model has learned and guide its subsequent actions.,4.2 Neural Networks and Attention Mechanism,[0],[0]
Weston et al. (2015) presented a neural network to read and update the external memory in a recurrent manner with the guidance of a question embedding.,4.2 Neural Networks and Attention Mechanism,[0],[0]
Kumar et al. (2015) proposed a similar model where a memory was designed to change the gate of the gated recurrent unit for each iteration.,4.2 Neural Networks and Attention Mechanism,[0],[0]
"As a complex text processing task, implicit discourse relation recognition needs a deep analysis
of the arguments.",5 Conclusion,[0],[0]
"To this end, we for the first time propose to imitate the repeated reading strategy and dynamically exploit efficient features through several passes of reading.",5 Conclusion,[0],[0]
"Following this idea, we design neural networks with multiple levels of attention (NNMA), where the general level and the attention levels represent the first and subsequent passes of reading.",5 Conclusion,[0],[0]
"With the help of external short-term memories, NNMA can gradually update the arguments representations on each attention level and fix attention on some specific words which provide effective clues to discourse relation recognition.",5 Conclusion,[0],[0]
"We conducted experiments on PDTB and the evaluation results show that our model can achieve the state-of-the-art performance on recognizing the implicit discourse relations.
",5 Conclusion,[0],[0]
"Acknowledgments
We thank all the anonymous reviewers for their insightful comments on this paper.",5 Conclusion,[0],[0]
"This work was partially supported by National Key Basic Research Program of China (2014CB340504), and National Natural Science Foundation of China (61273278 and 61572049).",5 Conclusion,[0],[0]
The correspondence author of this paper is Sujian Li.,5 Conclusion,[0],[0]
Recognizing implicit discourse relations is a challenging but important task in the field of Natural Language Processing.,abstractText,[0],[0]
"For such a complex text processing task, different from previous studies, we argue that it is necessary to repeatedly read the arguments and dynamically exploit the efficient features useful for recognizing discourse relations.",abstractText,[0],[0]
"To mimic the repeated reading strategy, we propose the neural networks with multi-level attention (NNMA), combining the attention mechanism and external memories to gradually fix the attention on some specific words helpful to judging the discourse relations.",abstractText,[0],[0]
Experiments on the PDTB dataset show that our proposed method achieves the state-ofart results.,abstractText,[0],[0]
The visualization of the attention weights also illustrates the progress that our model observes the arguments on each level and progressively locates the important words.,abstractText,[0],[0]
Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 2261–2271 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Recurrent neural networks (RNNs) are an attractive apparatus for probabilistic language modeling (Mikolov and Zweig, 2012).",1 Introduction,[0],[0]
"Recent experiments show that RNNs significantly outperform other methods in assigning high probability to held-out English text (Jozefowicz et al., 2016).
",1 Introduction,[0],[0]
"Roughly speaking, an RNN works as follows.",1 Introduction,[0],[0]
"At each time step, it consumes one input token, updates its hidden state vector, and predicts the next token by generating a probability distribution over all permissible tokens.",1 Introduction,[0],[0]
The probability of an input string is simply obtained as the product of the predictions of the tokens constituting the string followed by a terminating token.,1 Introduction,[0],[0]
"In this manner, each RNN defines a weighted language; i.e. a total function from strings to weights.",1 Introduction,[0],[0]
Siegelmann and Sontag (1995) showed that single-layer rational-weight RNNs with saturated linear activation can compute any computable function.,1 Introduction,[0],[0]
"To
this end, a specific architecture with 886 hidden units can simulate any Turing machine in real-time (i.e., each Turing machine step is simulated in a single time step).",1 Introduction,[0],[0]
"However, their RNN encodes the whole input in its internal state, performs the actual computation of the Turing machine when reading the terminating token, and then encodes the output (provided an output is produced) in a particular hidden unit.",1 Introduction,[0],[0]
"In this way, their RNN allows “thinking” time (equivalent to the computation time of the Turing machine) after the input has been encoded.
",1 Introduction,[0],[0]
We consider a different variant of RNNs that is commonly used in natural language processing applications.,1 Introduction,[0],[0]
"It uses ReLU activations, consumes an input token at each time step, and produces softmax predictions for the next token.",1 Introduction,[0],[0]
"It thus immediately halts after reading the last input token and the weight assigned to the input is simply the product of the input token predictions in each step.
",1 Introduction,[0],[0]
Other formal models that are currently used to implement probabilistic language models such as finite-state automata and context-free grammars are by now well-understood.,1 Introduction,[0],[0]
A fair share of their utility directly derives from their nice algorithmic properties.,1 Introduction,[0],[0]
"For example, the weighted languages computed by weighted finite-state automata are closed under intersection (pointwise product) and union (pointwise sum), and the corresponding unweighted languages are closed under intersection, union, difference, and complementation (Droste et al., 2013).",1 Introduction,[0],[0]
"Moreover, toolkits like OpenFST",1 Introduction,[0],[0]
"(Allauzen et al., 2007) and Carmel1 implement efficient algorithms on automata like minimization, intersection, finding the highestweighted path and the highest-weighted string.
RNN practitioners naturally face many of these same problems.",1 Introduction,[0],[0]
"For example, an RNN-
1https://www.isi.edu/licensed-sw/carmel/
2261
based machine translation system should extract the highest-weighted output string (i.e., the most likely translation) generated by an RNN, (Sutskever et al., 2014; Bahdanau et al., 2014).",1 Introduction,[0],[0]
Currently this task is solved by approximation techniques like heuristic greedy and beam searches.,1 Introduction,[0],[0]
To facilitate the deployment of large RNNs onto limited memory devices (like mobile phones) minimization techniques would be beneficial.,1 Introduction,[0],[0]
"Again currently only heuristic approaches like knowledge distillation (Kim and Rush, 2016) are available.",1 Introduction,[0],[0]
"Meanwhile, it is unclear whether we can determine if the computed weighted language is consistent; i.e., if it is a probability distribution on the set of all strings.",1 Introduction,[0],[0]
"Without a determination of the overall probability mass assigned to all finite strings, a fair comparison of language models with regard to perplexity is simply impossible.
",1 Introduction,[0],[0]
The goal of this paper is to study the above problems for the mentioned ReLU-variant of RNNs.,1 Introduction,[0],[0]
"More specifically, we ask and answer the following questions: • Consistency: Do RNNs compute consistent
weighted languages?",1 Introduction,[0],[0]
Is the consistency of the computed weighted language decidable?,1 Introduction,[0],[0]
"• Highest-weighted string: Can we (efficiently)
determine the highest-weighted string in a computed weighted language?",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Equivalence: Can we decide whether two
given RNNs compute the same weighted language?",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Minimization: Can we minimize the number
of neurons for a given RNN?",1 Introduction,[0],[0]
"Before we introduce our RNN model formally, we recall some basic notions and notation.",2 Definitions and notations,[0],[0]
"An alphabet Σ is a finite set of symbols, and we write |Σ| for the number of symbols in Σ. A string s over the alphabet Σ is a finite sequence of zero or more symbols drawn from Σ, and we write Σ∗ for the set of all strings over Σ, of which is the empty string.",2 Definitions and notations,[0],[0]
The length of the string s ∈ Σ∗ is denoted |s| and coincides with the number of symbols constituting the string.,2 Definitions and notations,[0],[0]
"As usual, we write AB for the set of functions {f | f : B → A}.",2 Definitions and notations,[0],[0]
A weighted language L is a total function L : Σ∗,2 Definitions and notations,[0],[0]
→ R from strings to real-valued weights.,2 Definitions and notations,[0],[0]
"For example, L(an) = e−n for all n ≥ 0 is such a weighted language.
",2 Definitions and notations,[0],[0]
"We restrict the weights in our RNNs to the ratio-
nal numbers Q.",2 Definitions and notations,[0],[0]
"In addition, we reserve the use of a special symbol $ to mark the start and end of an input string.",2 Definitions and notations,[0],[0]
"To this end, we assume that $ /∈",2 Definitions and notations,[0],[0]
"Σ for all considered alphabets, and we let Σ$ = Σ∪{$}.",2 Definitions and notations,[0],[0]
Definition 1.,2 Definitions and notations,[0],[0]
"A single-layer RNN R is a 7-tuple 〈Σ, N, h−1,W,W ′, E,E′〉, in which • Σ is an input alphabet, • N is a finite set of neurons, • h−1 ∈ QN is an initial activation vector, • W ∈",2 Definitions and notations,[0],[0]
"QN×N is a transition matrix, • W ′ =",2 Definitions and notations,[0],[0]
"(W ′a)a∈Σ$ is a Σ$-indexed family of
bias vectors",2 Definitions and notations,[0],[0]
"W ′a ∈ QN , • E ∈",2 Definitions and notations,[0],[0]
"QΣ$×N is a prediction matrix, and • E′ ∈ QΣ$ is a prediction bias vector.",2 Definitions and notations,[0],[0]
"Next, let us define how such an RNN works.",2 Definitions and notations,[0],[0]
We first prepare our input encoding and the effect of our activation function.,2 Definitions and notations,[0],[0]
"For an input string s = s1s2 · · · sn ∈ Σ∗ with s1, . . .",2 Definitions and notations,[0],[0]
", sn ∈ Σ, we encode this input as $s$ and thus assume that s0 = $ and sn+1 = $.",2 Definitions and notations,[0],[0]
"Our RNNs use ReLUs (Rectified Linear Units), so for every v ∈ QN we let σ〈v〉 (the ReLU activation) be the vector σ〈v〉 ∈ QN such that
σ〈v〉(n) = max ( 0, v(n) ) for every n ∈ N .
",2 Definitions and notations,[0],[0]
"In other words, the ReLUs act like identities on nonnegative inputs, but clip negative inputs to 0.",2 Definitions and notations,[0],[0]
"We use softmax-predictions, so for every vector p ∈ QΣ$ and a ∈ Σ$ we let
softmax〈p〉(a) = e p(a)
∑ a′∈Σ$ e p(a′) .
",2 Definitions and notations,[0],[0]
RNNs act in discrete time steps reading a single letter at each step.,2 Definitions and notations,[0],[0]
We now define the semantics of our RNNs.,2 Definitions and notations,[0],[0]
Definition 2.,2 Definitions and notations,[0],[0]
"Let R = 〈Σ, N, h−1,W,W ′, E,E′〉 be an RNN, s an input string of length n and 0 ≤ t ≤ n",2 Definitions and notations,[0],[0]
a time step.,2 Definitions and notations,[0],[0]
"We define • the hidden state vector hs,t ∈ QN given by
hs,t = σ〈W · hs,t−1 +W ′st〉 ,
where hs,−1 = h−1",2 Definitions and notations,[0],[0]
"and we use standard matrix product and point-wise vector addition, • the next-token prediction vector Es,t ∈ QΣ$
Es,t = E · hs,t + E′
• the next-token distribution E′s,t ∈",2 Definitions and notations,[0],[0]
"RΣ$
E′s,t = softmax〈Es,t〉 .
",2 Definitions and notations,[0],[0]
"Finally, the RNN R computes the weighted language R : Σ∗",2 Definitions and notations,[0],[0]
"→ R, which is given for every input s = s1 · · · sn as above by
R(s) = n∏
t=0
E′s,t(st+1) .
",2 Definitions and notations,[0],[0]
"In other words, each component hs,t(n) of the hidden state vector is the ReLU activation applied to a linear combination of all the components of the previous hidden state vector hs,t−1 together with a summand W ′st that depends on the t-th input letter st.",2 Definitions and notations,[0],[0]
"Thus, we often specify hs,t(n) as linear combination instead of specifying the matrix W and the vectors W ′a.",2 Definitions and notations,[0],[0]
"The semantics is then obtained by predicting the letters s1, . . .",2 Definitions and notations,[0],[0]
", sn of the input s and the final terminator $ and multiplying the probabilities of the individual predictions.
",2 Definitions and notations,[0],[0]
Let us illustrate these notions on an example.,2 Definitions and notations,[0],[0]
"We consider the RNN 〈Σ, N, h−1,W,W ′, E,E′〉 with γ ∈ Q and • Σ = {a} and N = {1, 2}, • h−1 = (−1, 0)T and
W = ( 1 0 1 0 ) and W ′$ = W ′",2 Definitions and notations,[0],[0]
"a = ( 1 0 )
",2 Definitions and notations,[0],[0]
"• E($, ·) =",2 Definitions and notations,[0],[0]
"(M + 1, −(M + 1)) and E(a, ·) = (1, −1) and • E′($) = −M and E′(a) = 0.
",2 Definitions and notations,[0],[0]
"In this case, we obtain the linear combinations
hs,t = σ 〈 hs,t−1(1) + 1 hs,t−1(1) 〉
computing the next hidden state components.",2 Definitions and notations,[0],[0]
"Given the initial activation, we thus obtain hs,t = σ〈t, t − 1〉.",2 Definitions and notations,[0],[0]
"Using this information, we obtain
Es,t($) =",2 Definitions and notations,[0],[0]
"(M + 1) · (t− σ〈t− 1〉)−M Es,t(a)",2 Definitions and notations,[0],[0]
"= t− σ〈t− 1〉 .
",2 Definitions and notations,[0],[0]
"Consequently, we assign weight e −M
1+e−M to input ε,
weight 1 1+e−M ·
e1
e1+e1 to a, and, more generally,
weight 1 1+e−M · 1 2n to a n.",2 Definitions and notations,[0],[0]
"Clearly the weight assigned by an RNN is always in the interval (0, 1), which enables a probabilistic view.",2 Definitions and notations,[0],[0]
"Similar to weighted finite-state automata or weighted context-free grammars, each RNN is a compact, finite representation of a
weighted language.",2 Definitions and notations,[0],[0]
"The softmax-operation enforces that the probability 0 is impossible as assigned weight, so each input string is principally possible.",2 Definitions and notations,[0],[0]
"In practical language modeling, smoothing methods are used to change distributions such that impossibility (probability 0) is removed.",2 Definitions and notations,[0],[0]
"Our RNNs avoid impossibility outright, so this can be considered a feature instead of a disadvantage.
",2 Definitions and notations,[0],[0]
"The hidden state hs,t of an RNN can be used as scratch space for computation.",2 Definitions and notations,[0],[0]
"For example, with a single neuron n we can count symbols in s via:
hs,t(n) =",2 Definitions and notations,[0],[0]
"σ〈hs,t−1(n)",2 Definitions and notations,[0],[0]
"+ 1〉 .
",2 Definitions and notations,[0],[0]
Here the letter-dependent summand W ′a is universally 1.,2 Definitions and notations,[0],[0]
"Similarly, for an alphabet Σ =",2 Definitions and notations,[0],[0]
{,2 Definitions and notations,[0],[0]
"a1, . . .",2 Definitions and notations,[0],[0]
", am} we can use the method of Siegelmann and Sontag (1995) to encode the complete input string s in base m+ 1 using:
hs,t(n)",2 Definitions and notations,[0],[0]
"= σ〈(m+ 1)hs,t−1(n)",2 Definitions and notations,[0],[0]
"+ c(st)〉 ,
where c : Σ$ → {0, . . .",2 Definitions and notations,[0],[0]
",m} is a bijection.",2 Definitions and notations,[0],[0]
"In principle, we can thus store the entire input string (of unbounded length) in the hidden state value hs,t(n), but our RNN model outputs weights at each step and terminates immediately once the final delimiter $ is read.",2 Definitions and notations,[0],[0]
It must assign a probability to a string incrementally using the chain rule decomposition p(s1 · · · sn) = p(s1) · . . .,2 Definitions and notations,[0],[0]
"· p(sn | s1 · · · sn−1).
",2 Definitions and notations,[0],[0]
Let us illustrate our notion of RNNs on some additional examples.,2 Definitions and notations,[0],[0]
They all use the alphabet Σ = {a} and are illustrated and formally specified in Figure 1.,2 Definitions and notations,[0],[0]
The first column shows an RNN R1 that assigns R1(an) = 2−(n+1).,2 Definitions and notations,[0],[0]
The next-token prediction matrix ensures equal values for a and $ at every time step.,2 Definitions and notations,[0],[0]
"The second column shows the RNN R2, which we already discussed.",2 Definitions and notations,[0],[0]
"In the beginning, it heavily biases the next symbol prediction towards a, but counters it starting at t = 1.",2 Definitions and notations,[0],[0]
"The third RNN R3 uses another counting mechanism with hs,t = σ〈t− 100, t− 101, t〉.",2 Definitions and notations,[0],[0]
"The first two components are ReLU-thresholded to zero until t > 101, at which point they overwhelm the bias towards a turning all future predictions to $.",2 Definitions and notations,[0],[0]
"We first investigate the consistency problem for an RNN R, which asks whether the recognized weighted language R is indeed a probability distribution.",3 Consistency,[0],[0]
"Consequently, an RNN R is consistent
n) = 2−(n+1) R2(ε)",3 Consistency,[0],[0]
≈ 0 R3(a100),3 Consistency,[0],[0]
"≈ 1
if ∑
s∈Σ∗ R(s) = 1.",3 Consistency,[0],[0]
"We first show that there is an inconsistent RNN, which together with our examples shows that consistency is a nontrivial property of RNNs.2
We immediately use a slightly more complex example, which we will later reuse.
",3 Consistency,[0],[0]
Example 3.,3 Consistency,[0],[0]
"Let us consider an arbitrary RNN
R = 〈Σ, N, h−1,W,W ′, E,E′〉
with the single-letter alphabet Σ = {a}, the neurons {1, 2, 3, n, n′} ⊆ N , initial activation h−1(i) = 0 for all i ∈ {1, 2, 3, n, n′}, and the following linear combinations:
hs,t(1) =",3 Consistency,[0],[0]
"σ〈hs,t−1(1) + hs,t−1(n)− hs,t−1(n′)〉 2",3 Consistency,[0],[0]
"For comparison, all probabilistic finite-state automata are consistent, provided no transitions exit final states.",3 Consistency,[0],[0]
Not all probabilistic context-free grammars are consistent; necessary and sufficient conditions for consistency are given by Booth and Thompson (1973).,3 Consistency,[0],[0]
"However, probabilistic context-free grammars obtained by training on a finite corpus using popular methods (such as expectation-maximization) are guaranteed to be consistent (Nederhof and Satta, 2006).
",3 Consistency,[0],[0]
"hs,t(2) =",3 Consistency,[0],[0]
"σ〈hs,t−1(2) + 1〉 hs,t(3) =",3 Consistency,[0],[0]
"σ〈hs,t−1(3)",3 Consistency,[0],[0]
"+ 3hs,t−1(1)〉
Es,t($) = hs,t(3)− hs,t(2) Es,t(a) = hs,t(2)
",3 Consistency,[0],[0]
"Now we distinguish two cases: Case 1: If hs,t(n)",3 Consistency,[0],[0]
"− hs,t(n′) = 0 for all t ∈ N, then hs,t(1) = 0 and hs,t(2) = t + 1 and hs,t(3) = 0.",3 Consistency,[0],[0]
"Hence we have Es,t($) =",3 Consistency,[0],[0]
"−(t + 1) and Es,t(a) = t + 1.",3 Consistency,[0],[0]
"In this case the termination probability
E′s,t($) = e−(t+1)
e−(t+1) +",3 Consistency,[0],[0]
"et+1 =
1
1 + e2(t+1)
(i.e., the likelihood of predicting $) shrinks rapidly towards 0, so the RNN assigns less than 15% of the probability mass to the terminating sequences (i.e., the finite strings), so the RNN is inconsistent (see Lemma 15 in the appendix).
",3 Consistency,[0],[0]
"Case 2: Suppose that there exists a time
point T ∈ N such that for all t ∈ N
hs,t(n)− hs,t(n′) = {
1 if t = T 0 otherwise.
",3 Consistency,[0],[0]
"Then hs,t(1)",3 Consistency,[0],[0]
= 0,3 Consistency,[0],[0]
"for all t ≤ T and hs,t(1)",3 Consistency,[0],[0]
= 1 otherwise.,3 Consistency,[0],[0]
"In addition, we have hs,t(2) = t + 1 and hs,t(3) = σ〈3(t−",3 Consistency,[0],[0]
T,3 Consistency,[0],[0]
− 1)〉.,3 Consistency,[0],[0]
"Hence we have
Es,t($) = σ〈3(t−",3 Consistency,[0],[0]
T,3 Consistency,[0],[0]
"− 1)〉 − (t+ 1)
= { −(t+ 1) if t ≤ T 2t− 3T",3 Consistency,[0],[0]
"− 4 otherwise
Es,t(a) = t+ 1 ,
which shows that the probability
E′s,t($) =    1 1+e2(t+1) if t ≤ T et−3T−5
1+et−3T−5 otherwise
of predicting $ increases over time and eventually (for t 3T ) far outweighs the probability of predicting a. Consequently, in this case the RNN is consistent (see Lemma 16 in the appendix).
",3 Consistency,[0],[0]
"We have seen in the previous example that consistency is not trivial for RNNs, which takes us to the consistency problem for RNNs:
Consistency: Given an RNN R, return “yes” if R is consistent and “no” otherwise.
",3 Consistency,[0],[0]
"We recall the following theorem, which, combined with our example, will prove that consistency is unfortunately undecidable for RNNs.
",3 Consistency,[0],[0]
Theorem 4 (Theorem 2 of Siegelmann and Sontag (1995)).,3 Consistency,[0],[0]
Let M be an arbitrary deterministic Turing machine.,3 Consistency,[0],[0]
"There exists an RNN
R = 〈Σ, N, h−1,W,W ′, E,E′〉
with saturated linear activation, input alphabet Σ = {a}, and 1 designated neuron n ∈ N such that for all s ∈ Σ∗ and 0 ≤ t ≤ |s| • hs,t(n) = 0",3 Consistency,[0],[0]
"if M does not halt on ε, and • if M does halt on empty input after T steps,
then
hs,t(n)",3 Consistency,[0],[0]
"= { 1 if t = T 0 otherwise.
",3 Consistency,[0],[0]
"In other words, such RNNs with saturated linear activation can semi-decide halting of an arbitrary Turing machine in the sense that a particular neuron achieves value 1 at some point during
the evolution if and only if the Turing machine halts on empty input.",3 Consistency,[0],[0]
An RNN with saturated linear activation is an RNN following our definition with the only difference that instead of our ReLU-activation σ the following saturated linear activation σ′ : QN → QN is used.,3 Consistency,[0],[0]
"For every vector v ∈ QN and n ∈ N , let
σ′〈v〉(n) =    0 if v(n) < 0",3 Consistency,[0],[0]
"v(n) if 0 ≤ v(n) ≤ 1 1 if v(n) > 1 .
",3 Consistency,[0],[0]
Since σ′〈v〉 = σ〈v〉,3 Consistency,[0],[0]
"− σ〈v−~1〉 for all v ∈ QN , and the right-hand side is a linear transformation, we can easily simulate saturated linear activation in our RNNs.",3 Consistency,[0],[0]
"To this end, each neuron n ∈ N of the original RNN R = 〈Σ, N, h−1, U, U ′, E,E′〉 is replaced by two neurons n1 and n2 in the new RNN R′ = 〈Σ, N ′, h′−1, V, V ′, F, F ′〉 such that hs,t(n)",3 Consistency,[0],[0]
"= h ′ s,t(n1)",3 Consistency,[0],[0]
"− h′s,t(n2) for all s ∈ Σ∗ and 0 ≤ t ≤ |s|, where the evaluation of h′s,t is performed in the RNNR′. More precisely, we use the transition matrix V and bias function V ′, which is given by
V (n1, n ′ 1) = V (n2, n ′ 1) = U(n, n ′) V (n1, n ′ 2) = V (n2, n ′ 2) = −U(n, n′)
V ′a(n1)",3 Consistency,[0],[0]
= U ′ a(n) V ′a(n2) =,3 Consistency,[0],[0]
"U ′ a(n)− 1
h′−1(n1) = h−1(n) h′−1(n2) = 0
for all n, n′ ∈ N and a ∈ Σ ∪ {$}, where n1 and n2 are the two neurons corresponding to n and n′1 and n ′",3 Consistency,[0],[0]
"2 are the two neurons corresponding to n′ (see Lemma 17 in the appendix).
",3 Consistency,[0],[0]
Corollary 5.,3 Consistency,[0],[0]
Let M be an arbitrary deterministic Turing machine.,3 Consistency,[0],[0]
"There exists an RNN
R = 〈Σ, N, h−1,W,W ′, E,E′〉
with input alphabet Σ = {a} and 2 designated neurons n1, n2 ∈ N such that for all s ∈ Σ∗ and 0 ≤ t ≤ |s| • hs,t(n1)",3 Consistency,[0],[0]
"− hs,t(n2) = 0",3 Consistency,[0],[0]
"if M does not halt
on ε, and • if M does halt on empty input after T steps,
then
hs,t(n1)− hs,t(n2) = {
1 if t = T 0 otherwise.
",3 Consistency,[0],[0]
We can now use this corollary together with the RNNR of Example 3 to show that the consistency problem is undecidable.,3 Consistency,[0],[0]
"To this end, we simulate a given Turing machine M and identify the two designated neurons of Corollary 5 as n and n′ in Example 3.",3 Consistency,[0],[0]
It follows that M halts if and only if R is consistent.,3 Consistency,[0],[0]
"Hence we reduced the undecidable halting problem to the consistency problem, which shows the undecidability of the consistency problem.
",3 Consistency,[0],[0]
Theorem 6.,3 Consistency,[0],[0]
"The consistency problem for RNNs is undecidable.
",3 Consistency,[0],[0]
"As mentioned in Footnote 2, probabilistic context-free grammars obtained after training on a finite corpus using the most popular methods are guaranteed to be consistent.",3 Consistency,[0],[0]
"At least for 2-layer RNNs this does not hold.
",3 Consistency,[0],[0]
Theorem 7.,3 Consistency,[0],[0]
"A two-layer RNN trained to a local optimum using Back-propagation-throughtime (BPTT) on a finite corpus is not necessarily consistent.
",3 Consistency,[0],[0]
Proof.,3 Consistency,[0],[0]
"The first layer of the RNN R with a single alphabet symbol a uses one neuron n′ and has the following behavior:
h−1(n′) = 0 hs,t(n ′) =",3 Consistency,[0],[0]
"σ〈hs,t−1(n′) + 1〉
The second layer uses neuron n and takes hs,t(n′) as input at time t:
hs,t(n) =",3 Consistency,[0],[0]
"σ〈hs,t(n′)− 2〉 Es,t(a) = hs,t(n) Es,t($) = 0
E′s,t(a) = { 1 2 if t ≤ 1 e(t−1)
1+e(t−1) otherwise.
",3 Consistency,[0],[0]
Let the training data be {a}.,3 Consistency,[0],[0]
Then the objective we wish to maximize is simply R(a).,3 Consistency,[0],[0]
"The derivative of this objective with respect to each parameter is 0, so applying gradient descent updates does not change any of the parameters and we have converged to an inconsistent RNN.
",3 Consistency,[0],[0]
It remains an open question whether there is a single-layer RNN that also exhibits this behavior.,3 Consistency,[0],[0]
Given a function f : Σ∗ → R we are often interested in the highest-weighted string.,4 Highest-weighted string,[0],[0]
"This corresponds to the most likely sentence in a language
model or the most likely translation for a decoder RNN in machine translation.
",4 Highest-weighted string,[0],[0]
"For deterministic probabilistic finite-state automata or context-free grammars only one path or derivation exists for any given string, so the identification of the highest-weighted string is the same task as the identification of the most probable path or derivation.",4 Highest-weighted string,[0],[0]
"However, for nondeterministic devices, the highest-weighted string is often harder to identify, since the weight of a string is the sum of the probabilities of all possible paths or derivations for that string.",4 Highest-weighted string,[0],[0]
"A comparison of the difficulty of identifying the most probable derivation and the highest-weighted string for various models is summarized in Table 1, in which we marked our results in bold face.
",4 Highest-weighted string,[0],[0]
We present various results concerning the difficulty of identifying the highest-weighted string in a weighted language computed by an RNN.,4 Highest-weighted string,[0],[0]
We also summarize some available algorithms.,4 Highest-weighted string,[0],[0]
"We start with the formal presentation of the three studied problems.
1.",4 Highest-weighted string,[0],[0]
"Best string: Given an RNNR and c ∈ (0, 1), does there exist s ∈ Σ∗",4 Highest-weighted string,[0],[0]
with R(s) > c? 2.,4 Highest-weighted string,[0],[0]
Consistent best string:,4 Highest-weighted string,[0],[0]
"Given a consistent RNN R and c ∈ (0, 1), does there exist s ∈ Σ∗",4 Highest-weighted string,[0],[0]
with R(s) > c? 3.,4 Highest-weighted string,[0],[0]
Consistent best string of polynomial length:,4 Highest-weighted string,[0],[0]
"Given a consistent RNN R, polynomial P with P(x) ≥ x for x ∈ N+, and c ∈ (0, 1), does there exist s ∈ Σ∗",4 Highest-weighted string,[0],[0]
with |s| ≤ P(|R|) and R(s) > c?,4 Highest-weighted string,[0],[0]
As usual the corresponding optimization problems are not significantly simpler than these decision problems.,4 Highest-weighted string,[0],[0]
"Unfortunately, the general problem is also undecidable, which can easily be shown using our example.
",4 Highest-weighted string,[0],[0]
"3Restricted to solutions of polynomial length 4Dijkstra shortest path / (Knuth, 1977)",4 Highest-weighted string,[0],[0]
"5(Casacuberta and de la Higuera, 2000) /",4 Highest-weighted string,[0],[0]
"(Simaan, 1996)
Theorem 8.",4 Highest-weighted string,[0],[0]
"The best string problem for RNNs is undecidable.
",4 Highest-weighted string,[0],[0]
Proof.,4 Highest-weighted string,[0],[0]
Let M be an arbitrary Turing machine and again consider the RNN R of Example 3 with the neurons n and n′ identified with the designated neurons of Corollary 5.,4 Highest-weighted string,[0],[0]
"We note that R(ε) = 1
1+e2 < 0.12 in both cases.",4 Highest-weighted string,[0],[0]
"If M does
not halt, then R(an) ≤ 1 1+e2(n+1) ≤ 1 1+e2
< 0.12 for all n ∈ N.",4 Highest-weighted string,[0],[0]
"On the other hand, if M halts after T steps, then
R(a3T−5)
= ( T∏
t=0
e2(t+1)
1 + e2(t+1)
) · ( 3T−6∏
t=T+1
1
1 + et−3T−5
) · 1
2
≥ 2 (−1, e−2)∞
· ( 3T−6∏
t=T+1
e3T+5−t
e3T+5−t+1
) · 1
2
≥ 2 (−1, e−2)∞ · (−1, e−1)∞ ≥ 0.25
using Lemma 14 in the appendix.",4 Highest-weighted string,[0],[0]
"Consequently, a string with weight above 0.12 exists if and only if M halts, so the best string problem is also undecidable.
",4 Highest-weighted string,[0],[0]
"If we restrict the RNNs to be consistent, then we can easily decide the best string problem by simple enumeration.
",4 Highest-weighted string,[0],[0]
Theorem 9.,4 Highest-weighted string,[0],[0]
"The consistent best string problem for RNNs is decidable.
",4 Highest-weighted string,[0],[0]
Proof.,4 Highest-weighted string,[0],[0]
"Let R be the RNN over alphabet Σ and c ∈ (0, 1) be the bound.",4 Highest-weighted string,[0],[0]
"Since Σ∗ is countable, we can enumerate it via f :",4 Highest-weighted string,[0],[0]
N,4 Highest-weighted string,[0],[0]
→ Σ∗. In the algorithm we compute Sn = ∑n i=0R(f(i)) for increasing values of n.,4 Highest-weighted string,[0],[0]
If we encounter a weight R(f(n)),4 Highest-weighted string,[0],[0]
"> c, then we stop with answer “yes.”",4 Highest-weighted string,[0],[0]
"Otherwise we continue until Sn > 1− c, at which point we stop with answer “no.”
",4 Highest-weighted string,[0],[0]
"Since R is consistent, limi→∞ Si = 1, so this algorithm is guaranteed to terminate and it obviously decides the problem.
",4 Highest-weighted string,[0],[0]
"Next, we investigate the length |wmaxR | of the shortest string wmaxR of maximal weight in the weighted language R generated by a consistent RNN R in terms of its (binary storage) size |R|.",4 Highest-weighted string,[0],[0]
"As already mentioned by Siegelmann and Sontag (1995) and evidenced here, only small precision rational numbers are needed in our constructions, so we assume that |R| ≤ c · |N |2 for a (reasonably small) constant c, where N is the set of neurons
of R. We show that no computable bound on the length of the best string can exist, so its length can surpass all reasonable bounds.
",4 Highest-weighted string,[0],[0]
Theorem 10.,4 Highest-weighted string,[0],[0]
"Let f : N+ → N be the function with
f(n) = max consistent RNN R |R|≤n |wmaxR |
for all n ∈ N+.",4 Highest-weighted string,[0],[0]
There exists no computable function g : N→ N with g(n) ≥ f(n) for all n ∈ N. Proof.,4 Highest-weighted string,[0],[0]
In the previous section (before Theorem 6) we presented an RNN RM that simulates an arbitrary (single-track) Turing machine M with n states.,4 Highest-weighted string,[0],[0]
By Siegelmann and Sontag (1995) we have |RM,4 Highest-weighted string,[0],[0]
| ≤ c · (4n + 16).,4 Highest-weighted string,[0],[0]
"Moreover, we observed that this RNN RM is consistent if and only if the Turing machine M halts on empty input.",4 Highest-weighted string,[0],[0]
"In the proof of Theorem 8 we have additionally seen that the length |wmaxR | of its best string exceeds the number TM of steps required to halt.
",4 Highest-weighted string,[0],[0]
"For every n ∈ N, let BB(n) be the n-th “Busy Beaver” number (Radó, 1962), which is
BB(n) = max normalized n-state Turing machine M with
2 tape symbols that halts on empty input
TM
It is well-known that BB : N+ → N cannot be bounded by any computable function.",4 Highest-weighted string,[0],[0]
"However,
BB(n) ≤ max normalized n-state Turing machine M with and 2 tape symbols that halts on empty input |wmaxRM |
≤ max consistent RNN R |R|≤c·(4n+16) |wmaxR |
= f(4nc+ 16c) ,
so f clearly cannot be computable and no computable function g can provide bounds for f .
",4 Highest-weighted string,[0],[0]
"Finally, we investigate the difficulty of the best string problem for consistent RNN restricted to solutions of polynomial length.
",4 Highest-weighted string,[0],[0]
Theorem 11.,4 Highest-weighted string,[0],[0]
"Identifying the best string of polynomial length in a consistent RNN is NP-complete.
",4 Highest-weighted string,[0],[0]
Proof.,4 Highest-weighted string,[0],[0]
"To show NP-hardness, we reduce from the 3-SAT problem.",4 Highest-weighted string,[0],[0]
"Let x1, . . .",4 Highest-weighted string,[0],[0]
", xm be m Boolean variables and
F = k∧
i=1
( `i1 ∨ `i2 ∨ `i3 ) ,
be a formula in conjunctive normal form, where `ij ∈ {x1, . . .",4 Highest-weighted string,[0],[0]
", xm,¬x1, . .",4 Highest-weighted string,[0],[0]
.,4 Highest-weighted string,[0],[0]
",¬xm}.",4 Highest-weighted string,[0],[0]
"3-SAT asks whether there is a setting of xis that makes F true.
",4 Highest-weighted string,[0],[0]
"We initialize h−1(n) = 0, ∀ n ∈",4 Highest-weighted string,[0],[0]
N,4 Highest-weighted string,[0],[0]
"= {x1, . . .",4 Highest-weighted string,[0],[0]
", xm, c1, . . .",4 Highest-weighted string,[0],[0]
", ck, c′1, . . .",4 Highest-weighted string,[0],[0]
", c′k, F, n1, n2, n3, ?}.",4 Highest-weighted string,[0],[0]
"Let s ∈ {0, 1}∗ be the input string.",4 Highest-weighted string,[0],[0]
Denote the value of F when xj = sj for all j ∈,4 Highest-weighted string,[0],[0]
[m] as F (s).,4 Highest-weighted string,[0],[0]
Let t ∈ N with t ≤ |s|.,4 Highest-weighted string,[0],[0]
"Set hs,t(xm) = σ〈I(st)〉, where I(0) = I($) = 0 and I(1) = 1.",4 Highest-weighted string,[0],[0]
"This stores the current input symbol in neuron xm, so hs,t(xm) = I(st).",4 Highest-weighted string,[0],[0]
"In addition, we let hs,t(xj) = σ〈hs,t−1(xj+1)〉 for all j ∈",4 Highest-weighted string,[0],[0]
[m − 1].,4 Highest-weighted string,[0],[0]
"Consequently, for all j ∈",4 Highest-weighted string,[0],[0]
"[m]
hs,t(xj) = { I(st−(m−j)) if m− j ≤ t 0",4 Highest-weighted string,[0],[0]
"otherwise.
",4 Highest-weighted string,[0],[0]
"Next, we evaluate the clauses.",4 Highest-weighted string,[0],[0]
For each i ∈,4 Highest-weighted string,[0],[0]
"[k], we use two neurons ci and c′i such that
hs,t(ci) = σ〈fs,t(`i1) + fs,t(`i2) + fs,t(`i3)〉 hs,t(c ′ i) =",4 Highest-weighted string,[0],[0]
"σ〈fs,t(`i1) + fs,t(`i2)",4 Highest-weighted string,[0],[0]
"+ fs,t(`i3)− 1〉,
where fs,t(xm) = I(st), fs,t(¬xm) = 1 − I(st), and ∀j ∈",4 Highest-weighted string,[0],[0]
"[m − 1], fs,t(xj) = hs,t−1(xj+1), fs,t(¬xj) = 1 − hs,t−1(xj+1).",4 Highest-weighted string,[0],[0]
"Note that hs,t(ci)",4 Highest-weighted string,[0],[0]
"− hs,t(c′i) contains the evaluation of the clause `i1 ∨ `i2 ∨ `i3.",4 Highest-weighted string,[0],[0]
"Let
hs,t(F ) = σ 〈 k∑
i=1
( hs,t−1(ci)−hs,t−1(c′i) )",4 Highest-weighted string,[0],[0]
"−k+1 〉 ,
so hs,t(F ) = F (s) contains the evaluation of the formula F using the values in neurons x1, . . .",4 Highest-weighted string,[0],[0]
", xm.
",4 Highest-weighted string,[0],[0]
"We use three counters n1, n2, n3 to ensure that the only relevant inputs are of length m+ 2:
hs,t(n1) = σ〈hs,t−1(n3)− (m+ 2)〉 hs,t(n2) = σ〈hs,t−1(n3)− (m+ 1)〉 hs,t(n3) = σ〈hs,t−1(n3) + 1〉 ,
which yields hs,t(n3) = t + 1, hs,t(n2) = σ〈t",4 Highest-weighted string,[0],[0]
"− (m + 1)〉, and hs,t(n1) = σ〈t− (m+ 2)〉.
",4 Highest-weighted string,[0],[0]
"Our goal neuron is ?, which we set to
hs,t(?)",4 Highest-weighted string,[0],[0]
"= σ〈hs,t−1(F )−hs,t−1(n1)+hs,t−1(n2)−1〉
so that
hs,t(?)",4 Highest-weighted string,[0],[0]
"= { hs,t−1(F ) if t = m+ 2 0 otherwise,
so hs,t(?)",4 Highest-weighted string,[0],[0]
"= 1 if and only if t = m + 2 and F (s) = 1.
Let m′",4 Highest-weighted string,[0],[0]
=,4 Highest-weighted string,[0],[0]
m+ 4.,4 Highest-weighted string,[0],[0]
"The output is set as follows:
Es,t(0)",4 Highest-weighted string,[0],[0]
"= Es,t(1)",4 Highest-weighted string,[0],[0]
"= m ′(1− 2hs,t(?) )
",4 Highest-weighted string,[0],[0]
"Es,t($) = −m′ ( 1− 2hs,t(?) ) ,
This yieldsEs,t(0) =",4 Highest-weighted string,[0],[0]
"Es,t(1) =",4 Highest-weighted string,[0],[0]
"−Es,t($) = −m′ if t = m+2 and F (s) = 1, andm′ otherwise.",4 Highest-weighted string,[0],[0]
"For a ∈ {0, 1},
E′s,t(a)=    e−m ′ 2e−m′+em′ if t=m+2 and F (s)=1 em ′
2em′+e−m′ otherwise
E′s,t($)=   
em ′
2e−m′+em′ if t=m+2 and F (s)=1
e−m ′
2em′+e−m′ otherwise.
",4 Highest-weighted string,[0],[0]
"Finally, we set the threshold ξ = 3−m ′ .",4 Highest-weighted string,[0],[0]
"When |s| 6= m + 2, sm+3 6= $, so the weight of s contains the factor e −m′
2e−m′+em′ = 1 2+e2m′ and thus is
upper-bounded by 1 2+e2m′ < ξ.",4 Highest-weighted string,[0],[0]
Hence no input of length different from m+ 2 achieves a weight that exceeds ξ.,4 Highest-weighted string,[0],[0]
"A string s of length m+ 2 achieves the weight ws given by
ws=   
em ′ 2e−m′+em′ ·∏m+2i=1 e m′ 2em′+e−m′ if F (s)=1
e−m ′ 2em′+e−m′ ·∏m+2i=1 e m′ 2em′+e−m′ otherwise.
",4 Highest-weighted string,[0],[0]
"When F (s) = 0, ws < e −m′
2em′+e−m′ < ξ, so
if F is unsatisfiable, no input string achieves a weight above the threshold ξ.",4 Highest-weighted string,[0],[0]
"When F (s) = 1, ws = em ′ 2e−m′+em′ · ( em ′ 2em′+e−m′ )m+2 > ξ.",4 Highest-weighted string,[0],[0]
An input string with weight above ξ exists if and only if F is satisfiable.,4 Highest-weighted string,[0],[0]
"Obviously, the reduction can be computed in polynomial time since all constants can be computed in logarithmic space.",4 Highest-weighted string,[0],[0]
"The constructed RNN is consistent, since the output prediction is constant after m+ 3 steps.",4 Highest-weighted string,[0],[0]
We prove that equivalence of two RNNs is undecidable.,5 Equivalence,[0],[0]
"For comparison, equivalence of two deterministic WFSAs can be tested in time O(|Σ|(|QA| + |QB|)3), where |QA|, |QB| are the number of states of the two WFSAs and |Σ| is the size of the alphabet (Cortes et al., 2007); equivalence of nondeterministic WFSAs are undecidable (Griffiths, 1968).",5 Equivalence,[0],[0]
"The decidability of language equivalence for deterministic probabilistic pushdowntown automata (PPDA) is still open (Forejt et al., 2014), although equivalence for deterministic unweighted push-downtown automata (PDA) is decidable (Sénizergues, 1997).
",5 Equivalence,[0],[0]
"The equivalence problem is formulated as follows:
Equivalence:",5 Equivalence,[0],[0]
"Given two RNNsR andR′, return “yes” if R(s) = R′(s) for all s ∈ Σ∗, and “no” otherwise.
",5 Equivalence,[0],[0]
Theorem 12.,5 Equivalence,[0],[0]
"The equivalence problem for RNNs is undecidable.
",5 Equivalence,[0],[0]
Proof.,5 Equivalence,[0],[0]
We prove by contradiction.,5 Equivalence,[0],[0]
Suppose Turing machine M decides the equivalence problem.,5 Equivalence,[0],[0]
"Given any deterministic Turing Machine M ′, construct the RNN R that simulates M ′ on input as described in Corollary 5.",5 Equivalence,[0],[0]
"Let Es,t(a) = 0",5 Equivalence,[0],[0]
"and Es,t($) = hs,t(n1)−hs,t(n2).",5 Equivalence,[0],[0]
"If M ′ does not halt on , for all t ∈ N, E′s,t(a) =",5 Equivalence,[0],[0]
"E′s,t($) = 1/2; if M ′ halts after T steps, E′s,T (a) = 1/(e + 1), Es,T ($) = e/(e + 1).",5 Equivalence,[0],[0]
"Let R′ be the trivial RNN that computes {an : P (an) = 2−(n+1), n ≥ 0}.",5 Equivalence,[0],[0]
"We run M on input 〈R,R′〉.",5 Equivalence,[0],[0]
"If M returns “no”, M ′ halts on x, else it does not halt.",5 Equivalence,[0],[0]
Therefore the Halting Problem would be decidable if equivalence is decidable.,5 Equivalence,[0],[0]
Therefore equivalence is undecidable.,5 Equivalence,[0],[0]
We look next at minimization of RNNs.,6 Minimization,[0],[0]
"For comparison, state-minimization of a deterministic PFSA is O(|E| log |Q|) where |E| is the number of transitions and |Q| is the number of states (Aho et al., 1974).",6 Minimization,[0],[0]
"Minimization of a non-deterministic PFSA is PSPACE-complete (Jiang and Ravikumar, 1993).
",6 Minimization,[0],[0]
We focus on minimizing the number of hidden neurons (|N |) in RNNs:,6 Minimization,[0],[0]
Minimization:,6 Minimization,[0],[0]
"Given RNN R and non-negative integer n, return “yes” if ∃ RNN R′ with number of hidden units |N ′| ≤ n such that R(s) = R′(s) for all s ∈ Σ∗, and “no” otherwise.
",6 Minimization,[0],[0]
Theorem 13.,6 Minimization,[0],[0]
"RNN minimization is undecidable.
",6 Minimization,[0],[0]
Proof.,6 Minimization,[0],[0]
We reduce from the Halting Problem.,6 Minimization,[0],[0]
Suppose Turing Machine M decides the minimization problem.,6 Minimization,[0],[0]
"For any Turing Machine M ′, construct the same RNN R as in Theorem 12.",6 Minimization,[0],[0]
"We run M on input 〈R, 0〉.",6 Minimization,[0],[0]
"Note that an RNN with no hidden unit can only output constant E′s,t for all t. Therefore the number of hidden units in R can be minimized to 0 if and only if it always outputs E′s,t(a) = E ′ s,t($) = 1/2.",6 Minimization,[0],[0]
"If M returns “yes”, M ′ does not halt on , else it halts.",6 Minimization,[0],[0]
"We proved the following hardness results regarding RNN as a recognizer of weighted languages:
1.",7 Conclusion,[0],[0]
Consistency: (a) Inconsistent RNNs exist.,7 Conclusion,[0],[0]
(b) Consistency of RNNs is undecidable.,7 Conclusion,[0],[0]
2.,7 Conclusion,[0],[0]
"Highest-weighted string: (a) Finding the highest-weighted string for
an arbitrary RNN is undecidable.",7 Conclusion,[0],[0]
"(b) Finding the highest-weighted string for
a consistent RNN is decidable, but the solution length can surpass all computable bounds.",7 Conclusion,[0],[0]
"(c) Restricting to solutions of polynomial length, finding the highest-weighted string is NP-complete.",7 Conclusion,[0],[0]
3.,7 Conclusion,[0],[0]
"Testing equivalence of RNNs and minimizing the number of neurons in an RNN are both undecidable.
",7 Conclusion,[0],[0]
"Although our undecidability results are upshots of the Turing-completeness of RNN (Siegelmann and Sontag, 1995), our NP-completeness result is original, and surprising, since the analogous hardness results in PFSA relies on the fact that there are multiple derivations for a single string (Casacuberta and de la Higuera, 2000).",7 Conclusion,[0],[0]
"The fact that these results hold for the relatively simple RNNs we used in this paper suggests that the case would be the same for more complicated models used in NLP, such as long short term memory networks (LSTMs; Hochreiter and Schmidhuber 1997).
",7 Conclusion,[0],[0]
Our results show the non-existence of (efficient) algorithms for interesting problems that researchers using RNN in natural language processing tasks may have hoped to find.,7 Conclusion,[0],[0]
"On the other hand, the non-existence of such efficient or exact algorithms gives evidence for the necessity of approximation, greedy or heuristic algorithms to solve those problems in practice.",7 Conclusion,[0],[0]
"In particular, since finding the highest-weighted string in RNN is the same as finding the most-likely translation in a sequence-to-sequence RNN decoder, our NPcompleteness result provides some justification for employing greedy and beam search algorithms in practice.",7 Conclusion,[0],[0]
This work was supported by DARPA (W911NF15-1-0543 and HR0011-15-C-0115).,Acknowledgments,[0],[0]
Andreas Maletti was financially supported by DFG Graduiertenkolleg 1763 (QuantLA).,Acknowledgments,[0],[0]
We investigate the computational complexity of various problems for simple recurrent neural networks (RNNs) as formal models for recognizing weighted languages.,abstractText,[0],[0]
"We focus on the single-layer, ReLU-activation, rationalweight RNNs with softmax, which are commonly used in natural language processing applications.",abstractText,[0],[0]
"We show that most problems for such RNNs are undecidable, including consistency, equivalence, minimization, and the determination of the highest-weighted string.",abstractText,[0],[0]
"However, for consistent RNNs the last problem becomes decidable, although the solution length can surpass all computable bounds.",abstractText,[0],[0]
"If additionally the string is limited to polynomial length, the problem becomes NP-complete.",abstractText,[0],[0]
"In summary, this shows that approximations and heuristic algorithms are necessary in practical applications of those RNNs.",abstractText,[0],[0]
Recurrent Neural Networks as Weighted Language Recognizers,title,[0],[0]
"Proceedings of the SIGDIAL 2015 Conference, pages 295–304, Prague, Czech Republic, 2-4 September 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
Dialogue management is the core of a spoken dialogue system.,1 Introduction,[0],[0]
"As a dialogue progresses, dialogue management usually accomplishes two missions.",1 Introduction,[0],[0]
"One mission is called dialogue state tracking (DST), which is a process to estimate the distribution of the dialogue states.",1 Introduction,[0],[0]
"Another mission is to choose semantics-level machine dialogue acts to direct the dialogue given the information of the dialogue state, referred to as dialogue decision making.",1 Introduction,[0],[0]
"Due to unpredictable user behaviours, inevitable automatic speech recognition (ASR) and spoken language understanding (SLU) errors, dialogue state tracking and decision making are difficult (Williams and Young, 2007).",1 Introduction,[0],[0]
"Consequently,
much research has been devoted to statistical dialogue management.",1 Introduction,[0],[0]
"In previous studies, dialogue state tracking and decision making are usually investigated together.",1 Introduction,[0],[0]
"In recent years, to advance the research of statistical dialogue management, the DST problem is raised out of the statistical dialogue management framework so that a bunch of models can be investigated for DST.",1 Introduction,[0],[0]
"Moreover, shared research tasks like the Dialog State Tracking Challenge (DSTC) (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) have provided a common testbed and evaluation suite to facilitate direct comparisons among DST models.
",1 Introduction,[0],[0]
"Two DST model categories are broadly known, i.e, rule-based models and statistical models.",1 Introduction,[0],[0]
"Recent studies on constrained Markov Bayesian polynomial (CMBP) framework took the first step towards bridging the gap between rule-based and statistical approaches for DST (Sun et al., 2014a; Yu et al., 2015).",1 Introduction,[0],[0]
"CMBP formulates rule-based DST in a general way and allows data-driven rules to be generated, so the performance can be improved when training data is available.",1 Introduction,[0],[0]
"This enables CMBP to achieve competitive performance to the state-of-the-art statistical approaches, while at the same time keeping most of the advantages of rule-based models.",1 Introduction,[0],[0]
"Nevertheless, adding features to CMBP is not as easy as in most other statistical approaches because additional prior knowledge is needed to be added to keep the search space tractable (Sun et al., 2014a; Yu et al., 2015).",1 Introduction,[0],[0]
"For the same reason, increasing the model complexity is difficult.",1 Introduction,[0],[0]
"To tackle the weakness of CMBP, recurrent polynomial network (RPN) (Sun et al., 2015) is proposed to further bridge the gap between rule-based and statistical approaches for DST (Sun et al., 2015).",1 Introduction,[0],[0]
RPN’s unique structure enables the framework to have all the advantages of CMBP.,1 Introduction,[0],[0]
"Additionally, RPN achieves more properties of statistical approaches than CMBP.",1 Introduction,[0],[0]
"RPN
295
uses gradient descent where CMBP uses Hillclimbing.",1 Introduction,[0],[0]
"Hence RPN can train its parameters faster and the parameter space are not limited to grid where parameters only takes values which are a multiple of a constant.
",1 Introduction,[0],[0]
SLU is usually the input module of tracker.,1 Introduction,[0],[0]
Hence its performance affect state tracking’s performance greatly.,1 Introduction,[0],[0]
"However, it is hard to design a reliable parser because of ASR errors and the difficulty of obtaining in-domain data.",1 Introduction,[0],[0]
"Further, it is a common case that SLU on a tracker’s training data is very different from SLU on a tracker’s testing data in real world end-to-end dialogue system.",1 Introduction,[0],[0]
"Thus, RPN is evaluated on SLUs with great variance and especially in the case where SLU for training mismatches SLU for testing.",1 Introduction,[0],[0]
"RPN shows consistently best results among trackers investigated on all SLUs.
",1 Introduction,[0],[0]
"The contribution of this paper is to investigate more complex RPN structures with deeper layers, multiple activation nodes and more features and to evaluate RPN’s performance in mismatched SLU condition.
",1 Introduction,[0],[0]
The rest of the paper is organized as follows.,1 Introduction,[0],[0]
Section 2 introduces rule-based models and statistical models used in DST.,1 Introduction,[0],[0]
Section 3 introduces two frameworks – CMBP and RPN bridging rulebased models and statistical models.,1 Introduction,[0],[0]
Complex RPN structures are also introduced in this section.,1 Introduction,[0],[0]
Section 4 discusses the influence of SLU on tracking and the SLU mismatch condition.,1 Introduction,[0],[0]
Section 5 evaluates RPN with different structures and features and these results are compared with state-ofthe-art trackers in DSTC-3.,1 Introduction,[0],[0]
"Rule-based models, statistical models and mixed models’ performance in cases where testing parser mismatches training parser are also compared.",1 Introduction,[0],[0]
"Finally, section 6 concludes the paper.",1 Introduction,[0],[0]
"The results of the DSTCs demonstrated the power of statistical approaches, such as Maximum Entropy (MaxEnt) (Lee and Eskenazi, 2013), Conditional Random Field (Lee, 2013), Deep Neural Network (DNN)",2 Rule-based and Statistical Models for DST,[0],[0]
"(Sun et al., 2014b), and Recurrent Neural Network (RNN) (Henderson et al., 2014d).",2 Rule-based and Statistical Models for DST,[0],[0]
"However, statistical approaches have some disadvantages.",2 Rule-based and Statistical Models for DST,[0],[0]
"For example, statistical approaches sometimes show large variation in performance and poor generalisation ability because of lack
of data (Williams, 2012).",2 Rule-based and Statistical Models for DST,[0],[0]
"Moreover, statistical models usually have a complex model structure and complex features, and thus can hardly achieve portability and interpretability.
",2 Rule-based and Statistical Models for DST,[0],[0]
"In addition to statistical approaches, rule-based approaches have also been investigated in DSTC due to their efficiency, portability and interpretability and some of them showed good performance and generalisation ability in DSTC (Zilka et al., 2013; Wang and Lemon, 2013).
",2 Rule-based and Statistical Models for DST,[0],[0]
"However, the performance of rule-based models is usually not competitive to the best statistical approaches.",2 Rule-based and Statistical Models for DST,[0],[0]
"Furthermore, a general way is lacking to design rule-based models with prior knowledge and their performance can hardly be improved when training data is available.",2 Rule-based and Statistical Models for DST,[0],[0]
There are two ways of bridging rule-based approaches and statistical approaches.,3 Bridging Rule-based models and statistical models,[0],[0]
"One starts from rule-based models and uses data-driven approaches to find a good rule, while the other one is a statistical model taking advantage of prior knowledge and constraints.",3 Bridging Rule-based models and statistical models,[0],[0]
"Constrained Markov Bayesian Polynomial (CMBP) (Sun et al., 2014a; Yu et al., 2015) takes the first way of bridging rule-based models and statistical models.
",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"Several probability features extracted from SLU results shown below are used in CMBP for each slot (Sun et al., 2014a; Yu et al., 2015):
• P+t (v): sum of scores of SLU hypotheses informing or affirming value v at turn t
• P−t (v): sum of scores of SLU hypotheses denying or negating value v at turn t
• P̃+t (v) = ∑ v′",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"/∈{v,None} P + t (v ′)
• P̃−t (v) = ∑ v′",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"/∈{v,None} P − t (v ′)
• bt(v): belief of “the value being v at turn t” • brt : probability of the value being None (the
value not mentioned) at turn t.
Because slots and values are assumed independent in CMBP.",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"To simplify the notation, these features are denoted as P+t , P − t , P̃ + t , P̃ − t , b r t , bt in the rest of this paper.
",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"With these probability features , a CMBP model is defined by
bt =P ( P+t , P − t , P̃ + t , P̃ − t , b r t−1, bt−1 ) s.t. constraints
(1)
where the P is a multivariate polynomial function defined as
P(x1, · · · , xD) = ∑
0≤k1≤···≤kn≤D gk1,··· ,kn ∏ 1≤i≤n xki
(2) where ki is an index into input variables.",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
n,3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"called order of the CMBP is the order of the polynomial, D denotes the number of inputs with x0 = 1 and g is the parameter of CMBP.
",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"In CMBP, prior knowledge or intuition is encoded by constraints in equation (1).",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"For example, intuition that goal belief should be unchanged or positively correlated with the positive scores from SLU can be written to a constraint:
∂P(P+t+1, P−t+1, P̃+t+1, P̃−t+1, brt , bt) ∂P+t+1 ≥ 0 (3)
",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"Further, these constraints are approximated to linear forms (Sun et al., 2014a; Yu et al., 2015).
",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"With a set of linear constraints, integer linear programming can be used to get the integer parameters which satisfy the relaxed constraints.",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
Then the tracking accuracy of each parameters can be evaluated and the best one is picked out.,3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"Hill-climbing can further be used to extend the best integer-coefficient CMBP to real-coefficient CMBP (Yu et al., 2015).
",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"Note that in practice order 3 (n=3) is used to balance the performance and the complexity (Sun et al., 2014a; Yu et al., 2015).",3.1 Constrained Markov Bayesian Polynomial,[0],[0]
3-order CMBP has achieved state-of-the art-performance on DSTC2/3.,3.1 Constrained Markov Bayesian Polynomial,[0],[0]
"Recurrent Polynomial network (Sun et al., 2015) takes the second way to bridge rule-based and statistical models.",3.2 Recurrent Polynomial Network,[0],[0]
"It is a computational network and a statistical framework, which takes advantage of prior knowledge by using CMBP to do initialization.
",3.2 Recurrent Polynomial Network,[0],[0]
"RPN contains two types of nodes, input node or computational node.",3.2 Recurrent Polynomial Network,[0],[0]
"Every node x has a value at every time t, denoted by u(t)x .",3.2 Recurrent Polynomial Network,[0],[0]
"The values of computational nodes at time t are evaluated using
the nodes’ values at time t and the nodes’ values at time t − 1 as inputs just like Recurrent Neural Networks (RNNs).
",3.2 Recurrent Polynomial Network,[0],[0]
Two types of edges are introduced to denote the time relation between linked nodes.,3.2 Recurrent Polynomial Network,[0],[0]
"A node at time t takes the value of a node at time t − 1 as input when they are connected by type-1 edges, while type-2 edges indicate that a node at time t takes the value of a node at time t.
Let Ix denote the set of nodes which are connected to node x by type-1 edges.",3.2 Recurrent Polynomial Network,[0],[0]
"Similarly, let Îx denote the set of nodes which are connected to node x by type-2 edges.
",3.2 Recurrent Polynomial Network,[0],[0]
"Generally, three types of computational node are used in RPN, which are sum node, product node and activation node.
",3.2 Recurrent Polynomial Network,[0],[0]
"• Sum node: For sum node x at time t, its value u (t) x is the weighted sum of its inputs:
u(t)x = ∑",3.2 Recurrent Polynomial Network,[0],[0]
"y∈Ix wx,yu (t−1) y + ∑ y∈Îx ŵx,yu (t) y (4)
where wx,y, ŵx,y ∈ R are the weights of edges.
",3.2 Recurrent Polynomial Network,[0],[0]
"• Product node: For product node x at time t, its value u(t)x is the product of its inputs.",3.2 Recurrent Polynomial Network,[0],[0]
Note that there may be multiple edges connecting from node y to node x.,3.2 Recurrent Polynomial Network,[0],[0]
Then node y’s value should be multiplied to u(t)x multiple times.,3.2 Recurrent Polynomial Network,[0],[0]
"Formally, letMx,y and M̂x,y be the multiplicity of the type-1 edge −→yx and the multiplicity of the type-2 edge −→yx respectively.",3.2 Recurrent Polynomial Network,[0],[0]
"Node x’s value u(t)x is evaluated by
u(t)x = ∏ y∈Ix u(t−1)y Mx,y ∏ y∈Îx u(t)y M̂x,y (5)
• Activation node: As the value of product nodes and sum nodes are not bounded by certain range while the output belief should lie in [0, 1], activation functions are needed to map values from R to some interval such as [0, 1].",3.2 Recurrent Polynomial Network,[0],[0]
An activation function is a univariate function.,3.2 Recurrent Polynomial Network,[0],[0]
"If node x is an activation node, there is only one type-2 edge linked to it.
",3.2 Recurrent Polynomial Network,[0],[0]
"Sun et al. (2015) investigated several activation functions and proposed an ascending, continuous function softclip mapping from R to [0, 1] which is linear on [ , 1− ] with being a small value.
",3.2 Recurrent Polynomial Network,[0],[0]
"Note that w, ŵ are the only parameters in RPN while Mx,y and M̂x,y are constant given the structure of RPN and each node can be used as output node in RPN.",3.2 Recurrent Polynomial Network,[0],[0]
"A basic 3-layer RPN shown in figure 1 is introduced here to help understand the correlation between 3-order CMBP and RPN.
",3.2.1 Basic Structure,[0],[0]
"For simplicity, (l, i) is used to denote the index of the i-th node in the l-th layer.",3.2.1 Basic Structure,[0],[0]
"Then each layer is defined as follows:
• First layer / Input layer:",3.2.1 Basic Structure,[0],[0]
"In this layer, input nodes correspond to the variables in equation (1), i.e. the value of 6 input nodes u(t)(0,0) ∼ u
(t) (0,5) are the same as variables bt−1, P + t ,
P−t , P̃ + t , P̃ − t , 1 in equation (1).
",3.2.1 Basic Structure,[0],[0]
Feature brt−1 which is belief of the value at time t − 1 being None is not used here to make the RPN structure clear and compact.,3.2.1 Basic Structure,[0],[0]
Experiments show that performance of CMBP without feature brt−1 would not degrade.,3.2.1 Basic Structure,[0],[0]
"It is not used by CMBP mentioned in the rest of paper either.
",3.2.1 Basic Structure,[0],[0]
• Second layer: Every product node x in the second layer corresponds to a monomial in equation (2).,3.2.1 Basic Structure,[0],[0]
"To express different monomials, each triple of input nodes (1, k1), (1, k2), (1, k3)(0 ≤ k1 ≤ k2 ≤ k3 ≤ 5) is enumerated to link to a product node x = (2, i) in the second layer and u(t)x = u
(t) (1,k1) u (t) (1,k2) u (t) (1,k3) .
",3.2.1 Basic Structure,[0],[0]
"• Third layer: There is only one sum node (3, 0) in the third layer corresponding to the belief value calculated by a polynomial.",3.2.1 Basic Structure,[0],[0]
"With the parameters set according to gk1,k2,k3 in equation (2), the value u(t)(3,0) is equal to bt
outputted by equation (1).",3.2.1 Basic Structure,[0],[0]
"It is the only output node in this structure.
",3.2.1 Basic Structure,[0],[0]
"From the explanation of basic structure in this section, it can be easily observed that a CMBP can be used to initialize RPN and thus RPN can achieve at least the same results with CMBP.",3.2.1 Basic Structure,[0],[0]
"So prior knowledge and constraints are used to find a suboptimum point in RPN parameter space and RPN as a statistical approach, can further optimize its parameters.",3.2.1 Basic Structure,[0],[0]
"Hence, RPN is a way of bridging rule-based models and statistical models.",3.2.1 Basic Structure,[0],[0]
It is easy to add features to RPN as a statistical model.,3.2.2 Complete Structure,[0],[0]
"In the work of Sun et al. (2015), 4 more features about user dialogue acts and machine acts are introduced.
",3.2.2 Complete Structure,[0],[0]
"A new sum node x = (3, 1) in the third layer is introduced to capture some property across turns just like belief bt.",3.2.2 Complete Structure,[0],[0]
"Like the node (3, 0) that outputs belief in the same layer, node (3, 1) takes input from every product node in the second layer and is used as input features at next time.
",3.2.2 Complete Structure,[0],[0]
"Further, to map the output belief to [0, 1], activation nodes with softclip(·) as their activation function are introduced.
",3.2.2 Complete Structure,[0],[0]
"The complete structure with the activation function, 4 more features and the new recurrent connection is shown in figure 2.
",3.2.2 Complete Structure,[0],[0]
The relation between a 3-order CMBP and the basic structure is shown in section 3.2.1.,3.2.2 Complete Structure,[0],[0]
"Similarly, the complete structure can also be initialized using CMBP by setting the weights of edges that do not appear in the basic structure to 0.",3.2.2 Complete Structure,[0],[0]
"We next exam RPN’s power of utilizing more features, multiple activation functions and a deeper
structure with two interesting explorations on RPN structure are shown in this section.",3.3 Complex RPN Structure,[0],[0]
"Although these extensions do not yield better results, this section covers these extensions to show the flexibility of the RPN approach.",3.3 Complex RPN Structure,[0],[0]
"Firstly, to express a 4-order polynomial, simply using the structure shown in figure 2 with indegree of nodes in the second layer increased to 4 would be sufficient.",3.3.1 Complex Structure,[0],[0]
"However, it can be expressed by a more compact RPN structure.",3.3.1 Complex Structure,[0],[0]
"To simplify the explanation, the example RPN expressing 1 − (1 − (bt−1)2)(1 − (P+t )2) is shown in figure 3.
",3.3.1 Complex Structure,[0],[0]
"In figure 3, the first layer is used for input, and the values of the product nodes in the second layer are equal to the products of two features such as (bt−1)2, bt−1P+t , (P + t )
2 and so on.",3.3.1 Complex Structure,[0],[0]
Every sum node in the third layer can express all the possible 2-order polynomial of features with weights set accordingly.,3.3.1 Complex Structure,[0],[0]
"In figure 3, the values of the three sum nodes are 1 − (bt−1)2, 1 − (P+t )2 and 1 respectively.",3.3.1 Complex Structure,[0],[0]
"Then similarly, with another product nodes layer and sum nodes layer, the value of the output node in the last layer equals the value of the 4-order polynomial (1− (bt−1)2)(1− (P+t )2).
",3.3.1 Complex Structure,[0],[0]
"The complete RPN structure with same features shown in figure 2, the new recurrent connection and activation nodes that expresses 4-order CMBPs can be obtained similarly.
",3.3.1 Complex Structure,[0],[0]
"With limited sum nodes in the third layer, the complexity of the model is much smaller than using a structure shown in figure 2 with product node’s in-degree increased to 4 and increasing the
number of product nodes accordingly.",3.3.1 Complex Structure,[0],[0]
"Secondly, RNN proposed by Henderson et al. (2014c) uses n-gram of ASR results and machine acts.",3.3.2 Complex Features,[0],[0]
"Similar to that, features of n-gram of ASR results and machine acts are also investigated in RPN.",3.3.2 Complex Features,[0],[0]
"Since RPN used in this paper is a binary classification model and assumes slots independent of each other, the n-gram features proposed by Henderson et al. (2014c) are modified in this paper by removing/merging some features to make the features independent of slots and values.",3.3.2 Complex Features,[0],[0]
"When tracking slot s and value v, the sum of confidence scores of ASR hypothesises of the following cases are extracted:
• V : confidence score of ASR hypothesises where value v appears
• Ṽ : confidence score of ASR hypothesises where values other than v appear
• V r: confidence score of ASR hypothesises where no value appear
Similar features for slots can be extracted.",3.3.2 Complex Features,[0],[0]
"Then by looking at both slot and value features for ASR results, we can get the combination of conditions of slots and values.
",3.3.2 Complex Features,[0],[0]
n-gram features of machine acts about the tracking slot and value are also used as features.,3.3.2 Complex Features,[0],[0]
"For example, given machine acts hello() | inform(area=center) | inform(food=Chinese) | request(name), for slot food and value Chinese, the n-gram machine act features are hello, inform, request, inform+slot, inform+value, inform+slot+value, slot, value, slot+value.",3.3.2 Complex Features,[0],[0]
"Features such as request(name) are about slot name and hence request+slot are not in the feature list.
",3.3.2 Complex Features,[0],[0]
"To combine RPN with RNN proposed by Henderson et al. (2014c), input nodes of these n-gram features are not linked to product nodes in the second layer.",3.3.2 Complex Features,[0],[0]
"Instead, a layer of sum nodes followed by a layer of activation nodes with sigmoid activation function, which are equivalent to a layer of neurons are introduced.",3.3.2 Complex Features,[0],[0]
These activation nodes are linked to sum nodes in the third layer just like product nodes in the second layer.,3.3.2 Complex Features,[0],[0]
"The structure is illustrated by figure 4 clearly.
",3.3.2 Complex Features,[0],[0]
"Experiments in section 5 show that these two structures do not yield better results when initialized randomly or initialized using 3-order CMBPs, although the model complexity increases a lot.",3.3.2 Complex Features,[0],[0]
This indicates the briefness and effectiveness of the simple structure shown in figure 2.,3.3.2 Complex Features,[0],[0]
"In an end-to-end dialogue system, there are two challenges in spoken language understanding: ASR errors and insufficient in-domain dialogue data.
",4 Uncertainty in SLU,[0],[0]
ASR errors make information contained in the user’s utterance distorted or even missed.,4 Uncertainty in SLU,[0],[0]
"Thankfully, statistical approaches to SLU, trained on labeled in-domain examples, have been shown to be relatively robust to ASR errors.",4 Uncertainty in SLU,[0],[0]
"(Mairesse et al., 2009).
",4 Uncertainty in SLU,[0],[0]
"Even with an effective way to get SLU robust to ASR errors, it is hard to implement these SLUs for a new domain due to insufficient labelled data.",4 Uncertainty in SLU,[0],[0]
"In DSTC-3, only little data of new dialogue domain is provided.
",4 Uncertainty in SLU,[0],[0]
"Following the work of Zhu et al. (2014), the following steps are used to handle the two challenges stated above:
• Data generation: with sufficient data in restaurants domain in DSTC-2, data on tourists domain using ontology of DSTC-3 can be generated.",4 Uncertainty in SLU,[0],[0]
Utterance patterns of data in the original domain are used to generate data for the new domain of DSTC-3.,4 Uncertainty in SLU,[0],[0]
"After preparing both the original data in DSTC-2 and the generated data of DSTC-3, a more
general parser for these two domains can be built.
",4 Uncertainty in SLU,[0],[0]
"• ASR error simulation: after data generation, ASR error simulation (Zhu et al., 2014) is needed to make the prepared data resemble ASR output with speech recognition errors to train a parser robust to ASR errors.",4 Uncertainty in SLU,[0],[0]
"With a simple mapping from the pattern of transcription to the corresponding patterns of ASR nbest hypotheses learned from existing data and phone-based confusion for slot-values, pseudo ASR n-best hypotheses can be obtained.",4 Uncertainty in SLU,[0],[0]
"Note that methods proposed by Zhu et al. (2014) only do ASR error simulation for generated data in domain of DSTC-3 and leave the original data in DSTC-2 as its original ASR form,which may introduce the difference in the distribution between training data and testing data on two different domains for the tracker.",4 Uncertainty in SLU,[0],[0]
"So ASR error is simulated in data on both domains instead.
",4 Uncertainty in SLU,[0],[0]
• Training:,4 Uncertainty in SLU,[0],[0]
"Using the data got from the previous steps, a statistical parser can be trained (Henderson et al., 2012).",4 Uncertainty in SLU,[0],[0]
"By varying the fraction of simulated vs. real data, and the simulated error rate, prior expectations about operating conditions can be expressed.
",4 Uncertainty in SLU,[0],[0]
"Although a semantic parser with state-of-theart techniques can achieve good performance in some degree, parsing without any error is impossible because it is typical that a semantic parser gets high performance in speech patterns existing in the training dataset, while it fails to predict the correct semantics for some utterances unseen in training dataset.",4 Uncertainty in SLU,[0],[0]
"So it is common for SLU performance to differ significantly between training and test conditions in real world end-to-end systems.
",4 Uncertainty in SLU,[0],[0]
It has been widely observed that SLU influences state tracking greatly because the confidence scores of SLU hypotheses are usually the key inputs for dialogue state tracking.,4 Uncertainty in SLU,[0],[0]
"When these confidence scores become unreliable, the performance of tracker is sure to degrade.",4 Uncertainty in SLU,[0],[0]
"Studies have shown that it is possible to improve SLU accuracy as compared to the live SLU in the DSTC data (Zhu et al., 2014; Sun et al., 2014b).",4 Uncertainty in SLU,[0],[0]
"Hence, most of the state-of-the-art results from DSTC-2 and DSTC3 used refined SLU (either explicitly rebuild a SLU component or take the ASR hypotheses into the trackers (Williams, 2014; Sun et al., 2014b;
Henderson et al., 2014d; Henderson et al., 2014c; Kadlec et al., 2014; Sun et al., 2014a)).",4 Uncertainty in SLU,[0],[0]
"Kadlec et al.(2014) gets a tracking accuracy improvement of 7.6% when they use SLU refined by themselves instead of organiser-provided live SLU.
",4 Uncertainty in SLU,[0],[0]
"In semantic parser mismatch condition, the accuracy of state tracking can degrade badly.",4 Uncertainty in SLU,[0],[0]
Mismatched SLU problem is a main challenge in DST.,4 Uncertainty in SLU,[0],[0]
Trackers under mismatched SLU conditions are investigated in this paper.,4 Uncertainty in SLU,[0],[0]
"In this section, the performance of three structures shown in this paper is compared and RPN with the simple structure is evaluated on DSTC-3 and compared with the best submitted trackers.",5.1 RPN with Different Structures,[0],[0]
Only joint goal accuracy which is the most difficult task of DSTC-3 is of interest.,5.1 RPN with Different Structures,[0],[0]
Note that the integercoefficient CMBP with the best performance on DSTC-2 is used to initialize RPN.,5.1 RPN with Different Structures,[0],[0]
"As it is stated in section 4, SLU designed in this paper focuses on domain extension, so trackers are only evaluated on DSTC-3.
",5.1 RPN with Different Structures,[0],[0]
"The RPN structures that express 3-order CMBP, 4-order CMBP without n-gram features and 4- order CMBP with n-gram features are evaluated.",5.1 RPN with Different Structures,[0],[0]
"Acc is the accuracy of tracker’s 1-best joint goal hypothesis, the larger the better.",5.1 RPN with Different Structures,[0],[0]
"L2 is the L2 norm between correct joint goal distribution and distribution tracker outputs, the smaller the better.
",5.1 RPN with Different Structures,[0],[0]
It can be seen from table 1 that the simple structure yields the best result.,5.1 RPN with Different Structures,[0],[0]
"Note that parser used here is explained in work (Zhu et al., 2014).",5.1 RPN with Different Structures,[0],[0]
"Experiments of the mismatched SLU case also use this SLU for training.
",5.1 RPN with Different Structures,[0],[0]
"For DSTC-3, it can be seen from table 2, RPN trained on DSTC-2 can achieve state-of-the-art performance on DSTC-3 without modifying tracking method, outperforming all the submitted trackers in DSTC-3 including the RNN system.
",5.1 RPN with Different Structures,[0],[0]
Note that the simple structure is used here with SLU refined described in section 4.,5.1 RPN with Different Structures,[0],[0]
"We picked the best practical one on dstc2-test among SLUs intro-
duced in the following section as the training SLU and testing SLU.",5.1 RPN with Different Structures,[0],[0]
"As section 4 stated, SLU is the input module for dialogue state tracking whose confidence score is usually directly used as probability features and hence has tremendous effect on trackers.",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"Handling mismatched semantic parsers is a main challenge to DST.
",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"In this section, different tracking methods are evaluated when there is a mismatch between training data and testing data.",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"More specifically, different tracking models are trained with the same fixed SLU and tested with different SLUs.
",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"Three main categories of tracking models are investigated: rule-based models, statistical models and mixed models.
",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"MaxEnt (Sun et al., 2014b) is a statistical model.",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"HWU baseline (Wang, 2013) is selected as a competitive rule-based model.",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"CMBP and RPN are mixed models.
",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"Four type of SLUs with different levels of performance are used:
1 Original: SLU results provided by DSTC-3 organizer.
2 Train: SLU introduced in section 4 with k(k = 25, 50) percent training data adding ASR error simulation and parsed on ASRhypotheses.
3",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"Combined: SLU combining the Original type SLU and Train type SLU using averaging.
4 Transcript: SLU introduced in section 4 with k percent training data adding ASR error simulation and parsed on transcription.",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"This setup assumes an oracle speech recognizer: it is not practical, and is included only for comparison.
",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
It has been shown that the organiser-provided live SLU can be improved upon and so it is used as the worst SLU in the following comparison.,5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"Past work has shown that trained parser gets a performance improvement when combined with the one the organiser provided (Zhu et al., 2014).",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
Using transcription for parsing gives a much more reliable SLU results than using ASR hypotheses.,5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"So generally speaking, performance of SLUs of different types is quite distinguished to each other.",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"Six different SLUs whose performance score shown in table 3 are investigated.
",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
Note that ASR error here is the percent of training data with ASR error simulation when training SLU.,5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"The Item Cross Entropy (ICE) (Thomson et al., 2008) between the N-best SLU hypotheses and the semantic label assesses the overall quality of the semantic items distribution, and is shown to give a consistent performance ranking for both the confidence scores and the overall correctness of the semantic parser (Zhu et al., 2014).",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"SLU with the lower ICE has better performance.
",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"Precision and recall are evaluated using only SLU’s 1-best hypothesis where ICE takes all hypothesises and their confidence score into consideration.
",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"In results shown in figure 5, the training dataset for tracker is fixed, while testing dataset is outputted by different SLUs.",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
The X-axis gives the SLU ICE and Y-axis gives the tracking accuracy on DSTC3-test.,5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"It can be observed that RPN achieves highest accuracy on every SLU among rule-based models, statistical models and mixed models.",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"Thus, RPN shows its robustness on mismatched semantic parsers, which demonstrates the power of using both prior knowledge and being a statistical approach.
",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"After evaluating the mismatched case, the matched case is also tested.",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"When training dataset and testing dataset are outputted by the same SLU, RPN also outperforms all other models, shown in figure 6.
",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
"It can be observed that RPN achieves the highest accuracy among RPN, CMBP, MaxEnt, and
HWU baseline whether there is a mismatch between training SLU and testing SLU or not.",5.2 RPN with Mismatched Semantic Parsers,[0],[0]
Recurrent Polynomial Network demonstrated in this paper is a recent framework to bridge rulebased and statistical models.,6 Conclusion,[0],[0]
Several networks are explored and the simple structure’s performance outperforms others.,6 Conclusion,[0],[0]
Experiments show that RPN outperforms many state-of-the-art trackers on DSTC-3 and RPN performs best on all SLUs with mismatched SLU.,6 Conclusion,[0],[0]
"This work was supported by the Program for Professor of Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher Learning, the China NSFC project No. 61222208 and the Chun-Tsung Program of SJTU.",Acknowledgments,[0],[0]
"We thank Jason Williams for reviewing and providing suggestions to this paper.
",Acknowledgments,[0],[0]
"Appendix
Activation function
An activation function softclip(·) is a combination of logistic function and clip function.",Acknowledgments,[0],[0]
"Let denote a small value such as 0.01, δ denote the offset of sigmoid function such that sigmoid ( − 0.5 + δ) = .",Acknowledgments,[0],[0]
"sigmoid function here is defined as
sigmoid(x) = 1
1 + e−x (6)
",Acknowledgments,[0],[0]
"The softclip function is defined as
softclip(x) ,  sigmoid (x− 0.5 + δ)",Acknowledgments,[0],[0]
"if x ≤ x if < x < 1− sigmoid (x− 0.5− δ)
",Acknowledgments,[0],[0]
"if x ≥ 1−
(7)
It is a non-decreasing, continuous function, which is linear on [ , 1 − ].",Acknowledgments,[0],[0]
"Its derivative is defined as follows:
∂softclip(x) ∂x ,  ∂sigmoid(x−0.5+δ) ∂x if x ≤ 1 if < x < 1− ∂sigmoid(x−0.5−δ) ∂x
if x ≥ 1− (8)
Training
Backpropagation through time (BPTT) using mini-batch is used to train the network with batch size 50.",Acknowledgments,[0],[0]
Gradients of weights are calculated and accumulated within each batch.,Acknowledgments,[0],[0]
Gradients computed for each timestep are propagated to the first timestep.,Acknowledgments,[0],[0]
"Mean squared error (MSE) is used as the criterion to measure the distance of the output belief to the correct belief distribution.
",Acknowledgments,[0],[0]
"Derivative calculation
Let δ(t)x be the partial derivative of the cost function over value of node x, i.e., δ(t)x = ∂L∂ux .",Acknowledgments,[0],[0]
"Suppose node x = (d, i) is a sum node, then when
node x passes its error, the error of child node y ∈ Îx is updated as
δ(t)y = δ",Acknowledgments,[0],[0]
(t),Acknowledgments,[0],[0]
y + ∂L ∂u (t) x,Acknowledgments,[0],[0]
∂u (t) x,Acknowledgments,[0],[0]
"∂u (t) y
= δ(t)y",Acknowledgments,[0],[0]
"+ δ (t) x ŵx,y
(9)
",Acknowledgments,[0],[0]
"Similarly, error of node y ∈ Ix is updated as
δ(t)y = δ",Acknowledgments,[0],[0]
(t),Acknowledgments,[0],[0]
y + ∂L ∂u (t) x,Acknowledgments,[0],[0]
∂u (t) x,Acknowledgments,[0],[0]
"∂u (t−1) y
= δ(t)y",Acknowledgments,[0],[0]
"+ δ (t) x wx,y
(10)
",Acknowledgments,[0],[0]
"Suppose node x = (d, i) is a product node, then when node x passes its error, error of node y ∈ Îx is updated as
δ(t)y = δ",Acknowledgments,[0],[0]
(t),Acknowledgments,[0],[0]
y + ∂L ∂u (t) x,Acknowledgments,[0],[0]
∂u (t) x,Acknowledgments,[0],[0]
"∂u (t) y
= δ(t)y",Acknowledgments,[0],[0]
"+
δ(t)x M̂x,yu (t) y",Acknowledgments,[0],[0]
"M̂x,y−1∏ z∈Îx−{y} u(t)z M̂x,z ∏ z∈Ix u(t−1)z Mx,z
(11)
",Acknowledgments,[0],[0]
"Similarly, error of node y ∈ Ix is updated as
δ(t)y = δ",Acknowledgments,[0],[0]
(t),Acknowledgments,[0],[0]
y + ∂L ∂u (t) x,Acknowledgments,[0],[0]
∂u (t) x,Acknowledgments,[0],[0]
"∂u (t−1) y
= δ(t)y",Acknowledgments,[0],[0]
"+
δ(t)x",Acknowledgments,[0],[0]
"Mx,yu (t−1) y Mx,y−1∏ z∈Îx u(t)z M̂x,z ∏ z∈Ix−{y} u(t−1)z Mx,z
(12)",Acknowledgments,[0],[0]
"Recently, constrained Markov Bayesian polynomial (CMBP) has been proposed as a data-driven rule-based model for dialog state tracking (DST).",abstractText,[0],[0]
CMBP is an approach to bridge rule-based models and statistical models.,abstractText,[0],[0]
"Recurrent Polynomial Network (RPN) is a recent statistical framework taking advantages of rulebased models and can achieve state-ofthe-art performance on the data corpora of DSTC-3, outperforming all submitted trackers in DSTC-3 including RNN.",abstractText,[0],[0]
"It is widely acknowledged that SLU’s reliability influences tracker’s performance greatly, especially in cases where the training SLU is poorly matched to the testing SLU.",abstractText,[0],[0]
"In this paper, this effect is analyzed in detail for RPN.",abstractText,[0],[0]
Experiments show that RPN’s tracking result is consistently the best compared to rule-based and statistical models investigated on different SLUs including mismatched ones and demonstrate RPN’s is very robust to mismatched semantic parsers.,abstractText,[0],[0]
Recurrent Polynomial Network for Dialogue State Tracking with Mismatched Semantic Parsers,title,[0],[0]
"We introduce Recurrent Predictive State Policy (RPSP) networks, a recurrent architecture that brings insights from predictive state representations to reinforcement learning in partially observable environments. Predictive state policy networks consist of a recursive filter, which keeps track of a belief about the state of the environment, and a reactive policy that directly maps beliefs to actions. The recursive filter leverages predictive state representations (PSRs) (Rosencrantz & Gordon, 2004; Sun et al., 2016) by modeling predictive state — a prediction of the distribution of future observations conditioned on history and future actions. This representation gives rise to a rich class of statistically consistent algorithms (Hefny et al., 2018) to initialize the recursive filter. Predictive state serves as an equivalent representation of a belief state. Therefore, the policy component of the RPSP-network can be purely reactive, simplifying training while still allowing optimal behaviour. We optimize our policy using a combination of policy gradient based on rewards (Williams, 1992) and gradient descent based on prediction error of the recursive filter. We show the efficacy of RPSP-networks under partial observability on a set of robotic control tasks from OpenAI Gym. We empirically show that RPSP-networks perform well compared with memory-preserving networks such as GRUs, as well as finite memory models, being the overall best performing method.
*Equal contribution 1Machine Learning Department, Carnegie Mellon University, Pittsburgh, USA 2Robotics Institute, Carnegie Mellon University, Pittsburgh, USA 3ISR/IT, Instituto Superior Técnico, Lisbon, Portugal 4Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, USA. Correspondence to: Ahmed Hefny <ahefny@cs.cmu.edu>, Zita Marinho <zmarinho@cmu.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).",text,[0],[0]
"Recently, there has been significant progress in deep reinforcement learning (Bojarski et al., 2016; Schulman et al., 2015; Mnih et al., 2013; Silver et al., 2016).",1. Introduction,[0],[0]
"Deep reinforcement learning combines deep networks as a representation of the policy with reinforcement learning algorithms and enables end-to-end training.
",1. Introduction,[0],[0]
"While traditional applications of deep learning rely on standard architectures with sigmoid or ReLU activations, there is an emerging trend of using composite architectures that contain parts explicitly resembling other algorithms such as Kalman filtering (Haarnoja et al., 2016) and value iteration (Tamar et al., 2016).",1. Introduction,[0],[0]
"It has been shown that such architectures can outperform standard neural networks.
",1. Introduction,[0],[0]
"In this work, we focus on partially observable environments, where the agent does not have full access to the state of the environment, but only to partial observations thereof.",1. Introduction,[0],[0]
"The agent has to maintain instead a distribution over states, i.e., a belief state, based on the entire history of observations and actions.",1. Introduction,[0],[0]
"The standard approach to this problem is to employ recurrent architectures such as Long-Short-TermMemory (LSTM) (Hochreiter & Schmidhuber, 1997) and Gated Recurrent Units (GRU) (Cho et al., 2014).",1. Introduction,[0],[0]
"Despite their success (Hausknecht & Stone, 2015), these methods are difficult to train due to non-convexity, and their hidden states lack a predefined statistical meaning.
",1. Introduction,[0],[0]
"Models based on predictive state representations (Littman et al., 2001; Singh et al., 2004; Rosencrantz & Gordon, 2004; Boots et al., 2013) offer an alternative method to construct a surrogate for belief state in a partially observable environment.",1. Introduction,[0],[0]
"These models represent state as the expectation of sufficient statistics of future observations, conditioned on history and future actions.",1. Introduction,[0],[0]
Predictive state models admit efficient learning algorithms with theoretical guarantees.,1. Introduction,[0],[0]
"Moreover, the successive application of the predictive state update procedure (i.e., filtering equations) results in a recursive computation graph that is differentiable with respect to model parameters.",1. Introduction,[0],[0]
"Therefore, we can treat predictive state models as recurrent networks and apply backpropagation through time (BPTT)",1. Introduction,[0],[0]
"(Hefny et al., 2018; Downey et al., 2017) to optimize model parameters.",1. Introduction,[0],[0]
"We use this insight to construct a Recurrent Predictive State Policy (RPSP) network, a special recurrent architecture that consists of (1) a
predictive state model acting as a recursive filter to keep track of a predictive state, and (2) a feed-forward neural network that directly maps predictive states to actions.",1. Introduction,[0],[0]
"This configuration results in a recurrent policy, where the recurrent part is implemented by a PSR instead of an LSTM or a GRU.",1. Introduction,[0],[0]
"As predictive states are a sufficient summary of the history of observations and actions, the reactive policy will have rich enough information to make its decisions, as if it had access to a true belief state.",1. Introduction,[0],[0]
"There are a number of motivations for this architecture:
• Using a PSR means we can benefit from methods in the spectral learning literature to provide an efficient and statistically consistent initialization of a core component of the policy.
",1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
Predictive states have a well defined probabilistic interpretation as conditional distribution of observed quantities.,1. Introduction,[0],[0]
"This can be utilized for optimization.
",1. Introduction,[0],[0]
"• The recursive filter in RPSP-networks is fully differentiable, meaning that once a good initialization is obtained from spectral learning methods, we can refine RPSP-nets using gradient descent.
",1. Introduction,[0],[0]
"This network can be trained end-to-end, for example using policy gradients in a reinforcement learning setting (Sutton et al., 2001) or supervised learning in an imitation learning setting (Ross et al., 2011).",1. Introduction,[0],[0]
In this work we focus on the former.,1. Introduction,[0],[0]
We discuss the predictive state model component in §3.,1. Introduction,[0],[0]
The control component is presented in §4 and the learning algorithm is presented in §5.,1. Introduction,[0],[0]
In §6 we describe the experimental setup and results on control tasks: we evaluate the performance of reinforcement learning using predictive state policy networks in multiple partially observable environments with continuous observations and actions.,1. Introduction,[0],[0]
"Throughout the rest of the paper, we will define vectors in bold notation v, matrices in capital letters W .",2. Background and Related Work,[0],[0]
"We will use ⊗ to denote vectorized outer product: x ⊗ y is xy> reshaped into a vector.
",2. Background and Related Work,[0],[0]
"We assume an agent is interacting with the environment in episodes, where each episode consists of T time steps in each of which the agent takes an action at ∈ A, and observes an observation ot ∈",2. Background and Related Work,[0],[0]
O and a reward rt ∈ R.,2. Background and Related Work,[0],[0]
"The agent chooses actions based on a stochastic policy πθ parameterized by a parameter vector θ: πθ(at | o1:t−1,a1:t−1) ≡ p(at | o1:t−1,a1:t−1,θ).",2. Background and Related Work,[0],[0]
We would like to improve the policy rewards by optimizing θ based on the agent’s experience in order to maximize the expected long term reward J(πθ) = 1 T ∑T t=1,2. Background and Related Work,[0],[0]
E,2. Background and Related Work,[0],[0]
"[ γt−1rt | πθ ] , where γ ∈",2. Background and Related Work,[0],[0]
"[0, 1] is a discount factor.
",2. Background and Related Work,[0],[0]
There are two major approaches for model-free reinforcement learning.,2. Background and Related Work,[0],[0]
"The first is the value function-based approach, where we seek to learn a function (e.g., a deep network (Mnih et al., 2013)) to evaluate the value of each action at each state (a.k.a. Q-value) under the optimal policy (Sutton & Barto, 1998).",2. Background and Related Work,[0],[0]
Given the Q function the agent can act greedily based on estimated values.,2. Background and Related Work,[0],[0]
"The second approach is direct policy optimization, where we learn a function to directly predict optimal actions (or optimal action distributions).",2. Background and Related Work,[0],[0]
"This function is optimized to maximize J(θ) using policy gradient methods (Schulman et al., 2015; Duan et al., 2016) or derivative-free methods (Szita & Lrincz, 2006).",2. Background and Related Work,[0],[0]
"We focus on the direct policy optimization approach as it is more robust to noisy continuous environments and modeling uncertainty (Sutton et al., 2001; Wierstra et al., 2010).
",2. Background and Related Work,[0],[0]
Our aim is to provide a new class of policy functions that combines recurrent reinforcement learning with recent advances in modeling partially observable environments using predictive state representations (PSRs).,2. Background and Related Work,[0],[0]
There have been previous attempts to combine predictive state models with policy learning.,2. Background and Related Work,[0],[0]
Boots et al. (2011) proposed a method for planning in partially observable environments.,2. Background and Related Work,[0],[0]
The method first learns a PSR from a set of trajectories collected using an explorative blind policy.,2. Background and Related Work,[0],[0]
The predictive states estimated by the PSR are then considered as states in a fully observable Markov Decision Process.,2. Background and Related Work,[0],[0]
"A value function is learned on these states using least squares temporal difference (Boots & Gordon, 2010) or point-based value iteration (PBVI) (Boots et al., 2011).",2. Background and Related Work,[0],[0]
"The main disadvantage of these approaches is that it assumes a one-time initialization of the PSR and does not propose a mechanism to update the model based on subsequent experience.
",2. Background and Related Work,[0],[0]
Hamilton et al. (2014) proposed an iterative method to simultaneously learn a PSR and use the predictive states to fit a Q-function.,2. Background and Related Work,[0],[0]
Azizzadenesheli et al. (2016) proposed a tensor decomposition method to estimate the parameters of a discrete partially observable Markov decision process (POMDP).,2. Background and Related Work,[0],[0]
One common limitation in the aforementioned methods is that they are restricted to discrete actions (some even assume discrete observations).,2. Background and Related Work,[0],[0]
"Also, it has been shown that PSRs can benefit greatly from local optimization after a moment-based initialization (Downey et al., 2017; Hefny et al., 2018).
",2. Background and Related Work,[0],[0]
"Venkatraman et al. (2017) proposed predictive state decoders, where an LSTM or a GRU network is trained on a mixed objective function in order to obtain high cumulative rewards while accurately predicting future observations.",2. Background and Related Work,[0],[0]
"While it has shown improvement over using standard training objective functions, it does not solve the initialization issue of the recurrent network.
",2. Background and Related Work,[0],[0]
"Our proposed RPSP networks alleviate the limitations of previous approaches: It supports continuous observations
and actions, it uses a recurrent state tracker with consistent initialization, and it supports end-to-end training after the initialization.",2. Background and Related Work,[0],[0]
"In this section, we give a brief introduction to predictive state representations, which constitute the state tracking (filtering) component of our model.1 We provide more technical details in the appendix.
",3. Predictive State Representations of Controlled Models,[0],[0]
"Given a history of observations and actions a1,o1,a2,o2, . . .",3. Predictive State Representations of Controlled Models,[0],[0]
",at−1,ot−1, a recursive filter computes a belief state",3. Predictive State Representations of Controlled Models,[0],[0]
"qt using a recursive update equation qt+1 = f(qt,at,ot).",3. Predictive State Representations of Controlled Models,[0],[0]
"Given the state qt, one can predict observations through a function g(qt,at) ≡",3. Predictive State Representations of Controlled Models,[0],[0]
E[ot,3. Predictive State Representations of Controlled Models,[0],[0]
"| qt,at].",3. Predictive State Representations of Controlled Models,[0],[0]
"In a recurrent neural network (Figure 1 (a,b)), q is latent and the function g that connects states to the output is unknown and has to be learned.",3. Predictive State Representations of Controlled Models,[0],[0]
"In this case, the output could be predicted from observations, when the RNN is used for prediction, see Figure 1 (a,b).
",3. Predictive State Representations of Controlled Models,[0],[0]
Predictive state models use a predictive representation of the state.,3. Predictive State Representations of Controlled Models,[0],[0]
"That means the qt is explicitly defined as the conditional distribution of future observations ot:t+k−1 conditioned on future actions at:t+k−1.2 (e.g., in the discrete case, qt could be a vectorized conditional probability table).
",3. Predictive State Representations of Controlled Models,[0],[0]
Predictive states are thus defined entirely in terms of observable features with no latent variables involved.,3. Predictive State Representations of Controlled Models,[0],[0]
"That means the mapping between the predictive state qt and the prediction of ot given at can be fully known or simple to learn consistently (Hefny et al., 2015b; Sun et al., 2016).",3. Predictive State Representations of Controlled Models,[0],[0]
"This is in contrast to RNNs, where this mapping is unknown and requires non-convex optimization to be learned.
",3. Predictive State Representations of Controlled Models,[0],[0]
"Similar to an RNN, a PSR employs a recursive state update that consists of the following two steps:3
• State extension: A linear map Wext is applied to qt to obtain an extended state pt.",3. Predictive State Representations of Controlled Models,[0],[0]
This state defines a conditional distribution over an extended window of k + 1 observations and actions.,3. Predictive State Representations of Controlled Models,[0],[0]
"Wext is a parameter to be learned.
",3. Predictive State Representations of Controlled Models,[0],[0]
pt = Wextqt (1) 1,3. Predictive State Representations of Controlled Models,[0],[0]
We follow the predictive state controlled model formulation in Hefny et al. (2018).,3. Predictive State Representations of Controlled Models,[0],[0]
"Alternative methods such as predictive state inference machines (Sun et al., 2016) could be contemplated.
",3. Predictive State Representations of Controlled Models,[0],[0]
2 We condition on “intervention by actions” rather than “observing actions”.,3. Predictive State Representations of Controlled Models,[0],[0]
That means qt is independent of the policy that determines the actions.,3. Predictive State Representations of Controlled Models,[0],[0]
"See (Pearl, 2009).
",3. Predictive State Representations of Controlled Models,[0],[0]
The length-k depends on the observability of the system.,3. Predictive State Representations of Controlled Models,[0],[0]
"A system is k-observable if maintaining the predictive state is equivalent to maintaining the distribution of the system’s latent state.
",3. Predictive State Representations of Controlled Models,[0],[0]
"3See the appendix Section 9 for more details.
",3. Predictive State Representations of Controlled Models,[0],[0]
•,3. Predictive State Representations of Controlled Models,[0],[0]
"Conditioning: Given at and ot, and a known conditioning function fcond:
qt+1 = fcond(pt,at,ot).",3. Predictive State Representations of Controlled Models,[0],[0]
"(2)
Figure 1 (c, d) depicts the PSR state update.",3. Predictive State Representations of Controlled Models,[0],[0]
The conditioning function fcond depends on the representation of qt and pt.,3. Predictive State Representations of Controlled Models,[0],[0]
"For example, in a discrete system, qt and pt could represent conditional probability tables and fcond amounts to applying Bayes rule.",3. Predictive State Representations of Controlled Models,[0],[0]
"In continuous systems we can use Hilbert space embedding of distributions (Boots et al., 2013), where fcond uses kernel Bayes rule (Fukumizu et al., 2013).
",3. Predictive State Representations of Controlled Models,[0],[0]
"In this work, we use the RFFPSR model proposed in (Hefny et al., 2018).",3. Predictive State Representations of Controlled Models,[0],[0]
"Observation and action features are based on random Fourier features (RFFs) of RBF kernel (Rahimi & Recht, 2008) projected into a lower dimensional subspace using randomized PCA (Halko et al., 2011).",3. Predictive State Representations of Controlled Models,[0],[0]
We use φ to denote this feature function.,3. Predictive State Representations of Controlled Models,[0],[0]
"Conditioning function fcond is kernel Bayes rule, and observation function g is a linear function of state E[ot | qt,at] = Wpred(qt ⊗ φ(at)).",3. Predictive State Representations of Controlled Models,[0],[0]
See Section 9.1 in the appendix for more details.,3. Predictive State Representations of Controlled Models,[0],[0]
"Learning PSRs is carried out in two steps: an initialization procedure using method of moments and a local optimization procedure using gradient descent.
",3.1. Learning predictive states representations,[0],[0]
"Initialization: The initialization procedure exploits the fact that qt and pt are represented in terms of observable quantities: since Wext is linear and using (1), then E[pt | ht] = WextE[qt | ht].",3.1. Learning predictive states representations,[0],[0]
"Here ht ≡ h(a1:t−1,o1:t−1) denotes a set of features extracted from previous observations and actions (typically from a fixed length window ending at t− 1).",3.1. Learning predictive states representations,[0],[0]
"Because qt and pt are not hidden states, estimating these expectations on both sides can be done by solving a supervised regression subproblem.",3.1. Learning predictive states representations,[0],[0]
"Given the predictions from this regression, solving for Wext then becomes another linear regression problem.",3.1. Learning predictive states representations,[0],[0]
"We follow this two-stage regression proposed by Hefny et al. (2018).4 Once Wext is computed, we can perform filtering to obtain the predictive states qt.",3.1. Learning predictive states representations,[0],[0]
"We then use the estimated states to learn the mapping to predicted observations Wpred, which results in another regression subproblem, see Section 9.2 in the appendix for more details.
",3.1. Learning predictive states representations,[0],[0]
"In RFFPSR, we use linear regression for all subproblems (which is a reasonable choice with kernel-based features).",3.1. Learning predictive states representations,[0],[0]
"This ensures that the two-stage regression procedure is free of local optima.
",3.1. Learning predictive states representations,[0],[0]
Local Optimization:,3.1. Learning predictive states representations,[0],[0]
"Although PSR initialization procedure is consistent, it is based on method of moments and hence is not necessarily statistically efficient.",3.1. Learning predictive states representations,[0],[0]
"Therefore it
4",3.1. Learning predictive states representations,[0],[0]
"We use the joint stage-1 regression variant for initialization.
can benefit from local optimization.",3.1. Learning predictive states representations,[0],[0]
"Downey et al. (2017) and Hefny et al. (2018) note that a PSR defines a recursive computation graph similar to that of an RNN where we have
qt+1 = fcond(Wext(qt),at,ot))
",3.1. Learning predictive states representations,[0],[0]
E[ot,3.1. Learning predictive states representations,[0],[0]
"| qt,at] = Wpred(qt ⊗ φ(at)), (3)
With a differentiable fcond, the PSR can be trained using backpropagation through time to minimize prediction error.
",3.1. Learning predictive states representations,[0],[0]
"In a nutshell, a PSR effectively constitutes a special type of a recurrent network where the state representation and update are chosen in a way that permits a consistent initialization, which is then followed by conventional backpropagation.",3.1. Learning predictive states representations,[0],[0]
"We now introduce our proposed class of policies, Recurrent Predictive State Policies (RPSPs).",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
We describe its components and in §5 we describe the learning algorithm .,4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"RPSPs consist of two fundamental components: a state tracking component, which models the state of the system, and is able to predict future observations; and a reactive policy component, that maps states to actions, shown in Figure 2.",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
The state tracking component is based on the PSR formulation described in §3.,4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"The reactive policy is a stochas-
tic non-linear policy πre(at | qt) ≡ p(at | qt;θre) which maps a predictive state to a distribution over actions and is
Algorithm 1 Recurrent Predictive State Policy network Optimization (RPSPO) 1: Input: Learning rate η. 2",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
:,4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"Sample initial trajectories: {(oit, ait)t}Mi=1 from πexp.",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"3: Initialize PSR:
θ0PSR = {q0,Wext,Wpred} via 2-stage regression in §3. 4: Initialize reactive policy θ0re randomly.",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
5: for n = 1 . . .,4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"Nmax iterations do 6: for i = 1, . . .",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
",M batch of M trajectories from πn−1: do 7: Reset episode: ai0. 8: for t = 0 . . .",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"T roll-in in each trajectory: do 9: Get observation oit and reward rit.
10: Filter qit+1 = ft(qit,ait,oit) in (Eq. 3).",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
11: Execute ait+1 ∼ πn−1re (qit+1).,4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"12: end for 13: end for 14: Update θ using D = {{oit,ait, rit,qit}Tt=1}Mi=1: θn ← UPDATE(θn−1,D, η), as in §5. 15: end for 16: Output: Return θ = (θPSR,θre).
parametrized by θre.",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"Similar to Schulman et al. (2015) we assume a Gaussian distribution N (µt,Σ), where
µ = ϕ(qt;θµ);",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"Σ = diag(exp(r)) 2 (4)
for a non-linear map ϕ parametrized by θµ (e.g. a feedforward network) , and a learnable vector r. An RPSP is thus a stochastic recurrent policy with the recurrent part corresponding to a PSR.",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"The parameters θ consist of two parts: the PSR parameters θPSR = {q0,Wext,Wpred} and the reactive policy parameters θre = {θµ, r}.",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"In the following section, we describe how these parameters are learned.",4. Recurrent Predictive State Policy (RPSP) Networks,[0],[0]
"As detailed in Algorithm 1, learning an RPSP is performed in two phases.5 In the first phase, we execute an exploration policy to collect a dataset that is used to initialize the PSR as described in §3.1.",5. Learning RPSPs,[0],[0]
It is worth noting that this initialization procedure depends on observations rather than rewards.,5. Learning RPSPs,[0],[0]
"This can be particularly useful in environments where informative reward signals are infrequent.
",5. Learning RPSPs,[0],[0]
"In the second phase, starting from the initial PSR and a random reactive policy, we iteratively collect trajectories using the current policy and use them to update the parameters of both the reactive policy θre = {θµ, r} and the predictive model θPSR = {q0,Wext,Wpred}, as depicted in Algorithm 1.",5. Learning RPSPs,[0],[0]
Let p(τ | θ) be the distribution over trajectories induced by the policy πθ .,5. Learning RPSPs,[0],[0]
"By updating parameters, we seek to minimize the objective function in (5).
L(θ) = α1`1(θ) + α2`2(θ) (5)
",5. Learning RPSPs,[0],[0]
= −α1J(πθ) + α2 T∑ t=0 Ep(τ |θ),5. Learning RPSPs,[0],[0]
"[ ‖Wpred(qt ⊗ at)− ot‖2 ] ,
5https://github.com/ahefnycmu/rpsp
which combines negative expected returns with PSR prediction error.6 Optimizing the PSR parameters to maintain low prediction error can be thought of as a regularization scheme.",5. Learning RPSPs,[0],[0]
"The hyper-parameters α1, α2 ∈ R determine the importance of the expected return and prediction error respectively.",5. Learning RPSPs,[0],[0]
They are discussed in more detail in §5.3.,5. Learning RPSPs,[0],[0]
"Noting that RPSP is a special type of a recurrent network policy, it is possible to adapt policy gradient methods (Williams, 1992) to the joint loss in (5).",5. Learning RPSPs,[0],[0]
"In the following subsections, we propose different update variants.",5. Learning RPSPs,[0],[0]
"In this variant, we use REINFORCE method (Williams, 1992) to obtain a stochastic gradient of J(π) from a batch of M trajectories.
",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
Let R(τ),5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
= ∑T t=1,5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"γ
t−1rt be the cumulative discounted reward for trajectory τ given a discount factor γ ∈",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"[0, 1].",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"REINFORCE uses the likelihood ratio trick ∇θp(τ |θ) = p(τ |θ)∇θ log p(τ |θ) to compute∇θJ(π) as
∇θJ(π) = Eτ∼p(τ |θ)[R(τ)",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
T∑ t=1,5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"∇θ log πθ(at|qt)],
In practice, we use a variance reducing variant of policy gradient (Greensmith et al., 2001) given by
∇θJ(π) = Eτ∼p(τ |θ)",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
T∑ t=0,5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"[∇θ log πθ(at|qt)(Rt(τ)− bt)],
(6)
where we replace the cumulative trajectory reward R(τ) by a reward-to-go function Rt(τ) = ∑T j=t γ
j−trj computing the cumulative reward starting from t. To further reduce variance we use a baseline bt ≡ Eθ[Rt(τ)",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"| a1:t−1,o1:t] which estimates the expected reward-to-go conditioned on the current policy.",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"In our implementation, we assume bt = w>b qt for a parameter vector wb that is estimated using linear regression.",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"Given a batch of M trajectories, a stochastic gradient of J(π) can be obtained by replacing the expectation in (6) with the empirical expectation over trajectories in the batch.",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
A stochastic gradient of the prediction error can be obtained using backpropagation through time.,5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"With an estimate of both gradients, we can compute (5) and update the parameters trough gradient descent.",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"For more details, see Algorithm 2 in the appendix.
",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"6We minimize 1-step prediction error, as opposed to general k-future prediction error recommended by (Hefny et al., 2018), to avoid biased estimates induced by non causal statistical correlations (observations correlated with future actions) when performing on-policy updates when a non-blind policy is in use.",5.1. Joint Variance Reduced Policy Gradient (VRPG),[0],[0]
"In this section, we describe a method that utilizes the recently proposed Trust Region Policy Optimization (TRPO (Schulman et al., 2015)), an alternative to the vanilla policy gradient methods that has shown superior performance in practice.",5.2. Alternating Optimization,[0],[0]
It uses a natural gradient update and enforces a constraint that encourages small changes in the policy in each TRPO step.,5.2. Alternating Optimization,[0],[0]
"This constraint results in smoother changes of policy parameters.
",5.2. Alternating Optimization,[0],[0]
"Each TRPO update is an approximate solution to the following constrained optimization problem in (7).
θn+1 = arg min θ Eτ∼p(τ |πn)",5.2. Alternating Optimization,[0],[0]
"T∑ t=0 [ πθ(at|qt) πn(at|qt) (Rt(τ)− bt) ]
s.t. Eτ∼p(τ |πn)",5.2. Alternating Optimization,[0],[0]
T∑ t=0,5.2. Alternating Optimization,[0],[0]
"[DKL (π n(.|qt) | πθ(.|qt))] ≤ , (7)
where πn is the policy induced by θn, and Rt and bt are the reward-to-go and baseline functions defined in §5.1.",5.2. Alternating Optimization,[0],[0]
"While it is possible to extend TRPO to the joint loss in (5), we observed that TRPO tends to be computationally intensive with recurrent architectures.",5.2. Alternating Optimization,[0],[0]
"Instead, we resort to the following alternating optimization:7",5.2. Alternating Optimization,[0],[0]
"In each iteration, we use TRPO to update the reactive policy parameters θre, which involve only a feedforward network.",5.2. Alternating Optimization,[0],[0]
"Then, we use a gradient step on (5), as described in §5.1, to update the PSR parameters θPSR, see Algorithm 3 in the appendix.",5.2. Alternating Optimization,[0],[0]
"It is difficult to make sense of the values of α1, α2, specially if the gradient magnitudes of their respective losses are not comparable.",5.3. Variance Normalization,[0],[0]
"For this reason, we propose a more principled approach for finding the relative weights.",5.3. Variance Normalization,[0],[0]
"We use α1 = α̃1 and α2 = a2α̃2, where a2 is a user-given value, and α̃1 and α̃2 are dynamically adjusted to maintain the property that the gradient of each loss weighted by α̃ has unit (uncentered) variance, in (8).",5.3. Variance Normalization,[0],[0]
"In doing so, we maintain the variance of the gradient of each loss through exponential averaging and use it to adjust the weights.
v (n)",5.3. Variance Normalization,[0],[0]
"i = (1− β)v (n−1) i + β ∑ θj∈θ ‖∇(n)θj `i‖ 2 (8)
α̃ (n)",5.3. Variance Normalization,[0],[0]
i = ∑ θj∈θ v (n),5.3. Variance Normalization,[0],[0]
"i,j −1/2 ,",5.3. Variance Normalization,[0],[0]
"We evaluate the RPSP-network’s performance on a collection of reinforcement learning tasks using OpenAI Gym
7 We emphasize that both VRPG and alternating optimization models optimize the joint RL/prediction loss.",6. Experiments,[0],[0]
"They differ only on how to update the reactive policy parameters (which are independent of prediction error).
",6. Experiments,[0],[0]
Mujoco environments.,6. Experiments,[0],[0]
8,6. Experiments,[0],[0]
"We consider partially observable environments: only the angles of the joints of the agent are visible to the network, without velocities.
",6. Experiments,[0],[0]
"Proposed Models: We consider an RPSP with a predictive component based on RFFPSR, as described in §3 and §4.",6. Experiments,[0],[0]
"For the RFFPSR, we use 1000 random Fourier features on observation and action sequences followed by a PCA dimensionality reduction step to d dimensions.",6. Experiments,[0],[0]
"We report the results for the best choice of d ∈ {10, 20, 30}.",6. Experiments,[0],[0]
"We initialize the RPSP with two stage regression on a batch of Mi initial trajectories (100 for Hopper, Walker and CartPole, and 50 for Swimmer) (equivalent to 10 extra iterations, or 5 for Swimmer).",6. Experiments,[0],[0]
We then experiment with both joint VRPG optimization (RPSP-VRPG) described in §5.1 and alternating optimization (RPSP-Alt) in §5.2.,6. Experiments,[0],[0]
"For RPSPVRPG, we use the gradient normalization described in §5.3.",6. Experiments,[0],[0]
"Additionally, we consider an extended variation (+obs) that concatenates the predictive state with a window w of previous observations as an extended form of predictive state q̃t =",6. Experiments,[0],[0]
"[qt,ot−w:t].",6. Experiments,[0],[0]
"If PSR learning succeeded perfectly, this extra information would be unnecessary; however we observe in practice that including observations help the model learn faster and more stably.",6. Experiments,[0],[0]
Later in the results section we report the RPSP variant that performs best.,6. Experiments,[0],[0]
"We provide a detailed comparison of all models in the appendix.
",6. Experiments,[0],[0]
Competing Models: We compare our models to a finite memory model (FM) and gated recurrent units (GRU).,6. Experiments,[0],[0]
"The finite memory models are analogous to RPSP, but replace the predictive state with a window of past observations.",6. Experiments,[0],[0]
"We tried three variants, FM1, FM2 and FM5, with window size of 1, 2 and 5 respectively (FM1 ignores that the environment is partially observable).",6. Experiments,[0],[0]
"We compare to GRUs with 16, 32, 64 and 128-dimensional hidden states.",6. Experiments,[0],[0]
"We optimize network parameters using the RLLab9 implementation of TRPO with two different learning rates (η = 10−2, 10−3).
",6. Experiments,[0],[0]
"In each model, we use a linear baseline for variance reduction where the state of the model (i.e. past observation window for FM, latent state for GRU and predictive state for RPSP) is used as the predictor variable.
",6. Experiments,[0],[0]
Evaluation Setup: We run each algorithm for a number of iterations based on the environment (see Figure 3).,6. Experiments,[0],[0]
"After each iteration, we compute the average return Riter = 1 M ∑M m=1 ∑Tm",6. Experiments,[0],[0]
"j=1 r j m on a batch of M trajectories, where Tm is the length of the mth trajectory.",6. Experiments,[0],[0]
"We repeat this process using 10 different random seeds and report the average and standard deviation of Riter for each iteration.
",6. Experiments,[0],[0]
"For each environment, we set the number of samples in the batch to 10000 and the maximum length of each episode to
8 https://gym.openai.com/envs#mujoco 9https://github.com/openai/rllab
200, 500, 1000, 1000 for Cart-Pole, Swimmer, Hopper and Walker2d respectively.10
For RPSP, we found that a step size of 10−2 performs well for both VRPG and alternating optimization in all environments.",6. Experiments,[0],[0]
The reactive policy contains one hidden layer of 16 nodes with ReLU activation.,6. Experiments,[0],[0]
"For all models, we report the results for the choice of hyper-parameters that resulted in
10For example, for a 1000 length environment we use a batch of 10 trajectories resulting in 10000 samples in the batch.
the highest mean cumulative reward (area under curve).",6. Experiments,[0],[0]
Performance over iterations:,7. Results and Discussion,[0],[0]
"Figure 3 shows the empirical average return vs. the amount of interaction with the environment (experience), measured in time steps.",7. Results and Discussion,[0],[0]
"We observe that RPSP networks (especially RPSP-Alt) perform well in every environment, competing with or outperforming the top model in terms of the learning speed and the
final reward, with the exception of Cart-Pole where the gap to GRU is larger.",7. Results and Discussion,[0],[0]
We report the cumulative reward for all environments in Table 3(h).,7. Results and Discussion,[0],[0]
"For all except Cart-Pole, come variant of RPSP is the best performing model.",7. Results and Discussion,[0],[0]
"For Swimmer our best performing model is only statistically better than FM model (t-test, p < 0.01), while for Hopper our best RPSP model performs statistically better than FM and GRU models (t-test, p < 0.01) and for Walker2d RPSP outperforms only GRU baselines (t-test, p < 0.01).",7. Results and Discussion,[0],[0]
"For Cart-Pole the top RPSP model performs better than the FM model (t-test, p < 0.01) and it is not statistically significantly different than the GRU model.",7. Results and Discussion,[0],[0]
"We also note that RPSPAlt provides similar performance to the joint optimization (RPSP-VRPG), but converges faster.
",7. Results and Discussion,[0],[0]
"Effect of proposed contributions: Our RPSP model is based on a number of components: (1) State tracking using PSR (2) Consistent initialization using two-stage regression (3) End-to-end training of state tracker and policy (4) Using observation prediction loss to regularize training.
",7. Results and Discussion,[0],[0]
"We conducted a set of experiments to verify the benefit of each component.11 In the first experiment, we test three variants of RPSP: one where the PSR is randomly initialized (random PSR), another one where the PSR is fixed at the initial value and only the reactive policy is further updated (fix PSR), and a third one where we train the RPSP network with initialization and without prediction loss regularization (i.e. we set α2 in (5)) to 0 (reactive PSR).",7. Results and Discussion,[0],[0]
"Figure 3(e) demonstrates that these variants are inferior to our model, showing the importance of two-stage initialization, end-toend training and observation prediction loss respectively.
",7. Results and Discussion,[0],[0]
"In the second experiment, we replace the PSR with a GRU that is initialized using BPTT applied on exploration data.",7. Results and Discussion,[0],[0]
"This is analogous to the predictive state decoders proposed in (Venkatraman et al., 2017), where observation prediction
11 Due to space limitation, we report results on Hopper environment.",7. Results and Discussion,[0],[0]
"We report results for other environments in the appendix.
loss is included when optimizing a GRU policy network (reg GRU).12",7. Results and Discussion,[0],[0]
"Figure 3(f-g) shows that a GRU model is inferior to a PSR model, where the initialization procedure is consistent and does not suffer from local optima.
",7. Results and Discussion,[0],[0]
Effect of observation noise: We also investigated the effect of observation noise on the RPSP model and the competitive FM baseline by applying Gaussian noise of increasing variance to observations.,7. Results and Discussion,[0],[0]
"Figure 4 shows that while FM was very competitive with RPSP in the noiseless case, RPSP has a clear advantage over FM in the case of mild noise.",7. Results and Discussion,[0],[0]
The performance gap vanishes under excessive noise.,7. Results and Discussion,[0],[0]
"We propose RPSP-networks, combining ideas from predictive state representations and recurrent networks for reinforcement learning.",8. Conclusion,[0],[0]
"We use PSR learning algorithms to provide a statistically consistent initialization of the state tracking component, and propose gradient-based methods to maximize expected return while reducing prediction error.",8. Conclusion,[0],[0]
"We compare RPSP against different baselines and empirically show the efficacy of the proposed approach in terms of speed of convergence and overall expected return.
",8. Conclusion,[0],[0]
"One direction to investigate is how to develop an online, consistent and statistically efficient method to update the RFFPSR as a predictor in continuous environments.",8. Conclusion,[0],[0]
"There has been a body of work for online learning of predictive state representations (Venkatraman et al., 2016; Boots & Gordon, 2011; Azizzadenesheli et al., 2016; Hamilton et al., 2014).",8. Conclusion,[0],[0]
"To our knowledge, none of them is able to deal with continuous actions and make use of local optimization.",8. Conclusion,[0],[0]
"We are also interested in applying off-policy methods and more elaborate exploration strategies.
",8. Conclusion,[0],[0]
"12 We report results for partially observable setting which is different from RL experiments in (Venkatraman et al., 2017).",8. Conclusion,[0],[0]
"We introduce Recurrent Predictive State Policy (RPSP) networks, a recurrent architecture that brings insights from predictive state representations to reinforcement learning in partially observable environments.",abstractText,[0],[0]
"Predictive state policy networks consist of a recursive filter, which keeps track of a belief about the state of the environment, and a reactive policy that directly maps beliefs to actions.",abstractText,[0],[0]
"The recursive filter leverages predictive state representations (PSRs) (Rosencrantz & Gordon, 2004; Sun et al., 2016) by modeling predictive state — a prediction of the distribution of future observations conditioned on history and future actions.",abstractText,[0],[0]
"This representation gives rise to a rich class of statistically consistent algorithms (Hefny et al., 2018) to initialize the recursive filter.",abstractText,[0],[0]
Predictive state serves as an equivalent representation of a belief state.,abstractText,[0],[0]
"Therefore, the policy component of the RPSP-network can be purely reactive, simplifying training while still allowing optimal behaviour.",abstractText,[0],[0]
"We optimize our policy using a combination of policy gradient based on rewards (Williams, 1992) and gradient descent based on prediction error of the recursive filter.",abstractText,[0],[0]
We show the efficacy of RPSP-networks under partial observability on a set of robotic control tasks from OpenAI Gym.,abstractText,[0],[0]
"We empirically show that RPSP-networks perform well compared with memory-preserving networks such as GRUs, as well as finite memory models, being the overall best performing method.",abstractText,[0],[0]
"Equal contribution Machine Learning Department, Carnegie Mellon University, Pittsburgh, USA Robotics Institute, Carnegie Mellon University, Pittsburgh, USA ISR/IT, Instituto Superior Técnico, Lisbon, Portugal Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, USA.",abstractText,[0],[0]
"Correspondence to: Ahmed Hefny <ahefny@cs.cmu.edu>, Zita Marinho <zmarinho@cmu.edu>.",abstractText,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",abstractText,[0],[0]
Copyright 2018 by the author(s).,abstractText,[0],[0]
Recurrent Predictive State Policy Networks,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 2171–2181 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
2171",text,[0],[0]
The problem of fine-grained opinion analysis involves extraction of opinion targets (or aspect terms) and opinion expressions (or opinion terms) from each review sentence.,1 Introduction,[0],[0]
"For example, in the sentence: “They offer good appetizers”, the aspect and opinion terms are appetizers and good correspondingly.",1 Introduction,[0],[0]
"Many supervised deep models have been proposed for this problem (Liu et al., 2015; Yin et al., 2016; Wang et al., 2017), and obtained promising results.",1 Introduction,[0],[0]
"However, these methods fail to adapt well across domains, because the aspect terms from two different domains are usually disjoint, e.g., laptop v.s. restaurant, leading to large domain shift in the feature vector space.",1 Introduction,[0],[0]
"Though unsupervised methods (Hu and Liu, 2004; Qiu et al., 2011) can
deal with data with few labels, their performance is unsatisfactory compared with supervised ones.
",1 Introduction,[0],[0]
"There have been a number of domain adaptation methods for coarse-grained sentiment classification problems across domains, where an overall sentiment polarity of a sentence or document is being predicted.",1 Introduction,[0],[0]
"Nevertheless, very few approaches exist for cross-domain fine-grained opinion analysis due to the difficulties in fine-grained adaptation, which is more challenging than coarse-grained problems.",1 Introduction,[0],[0]
"Li et al. (2012) proposed a bootstrap method based on the TrAdaBoost algorithm (Dai et al., 2007) to iteratively expand opinion and aspect lexicons in the target domain by exploiting source-domain labeled data and cross-domain common relations between aspect terms and opinion terms.",1 Introduction,[0],[0]
"However, their model requires a seed opinion lexicon in the target domain and pre-mined syntactic patterns as a bridge.",1 Introduction,[0],[0]
Ding et al. (2017) proposed to use rules to generate auxiliary supervision on top of a recurrent neural network to learn domain-invariant hidden representation for each word.,1 Introduction,[0],[0]
The performance highly depends on the quality of the manually defined rules and the prior knowledge of a sentiment lexicon.,1 Introduction,[0],[0]
"In addition, the recurrent structure fails to capture the syntactic interactions among words intrinsically for opinion extraction.",1 Introduction,[0],[0]
"The requirement for rules makes the above methods non-flexible.
",1 Introduction,[0],[0]
"In this paper, we propose a novel cross-domain Recursive Neural Network (RNN)1 for aspect and opinion terms co-extraction across domains.",1 Introduction,[0],[0]
Our motivations are twofold: 1),1 Introduction,[0],[0]
The dependency relations capture the interactions among different words.,1 Introduction,[0],[0]
"These relations are especially important for identifying aspect terms and opinion terms (Qiu et al., 2011; Wang et al., 2016), which are also domain-invariant within the same language.",1 Introduction,[0],[0]
"Therefore, they can be used as “pivot” information to
1Here, we use RNN to denote recursive neural networks, rather than recurrent neural networks.
bridge the gap between different domains.",1 Introduction,[0],[0]
"2) Inspired by the idea of structural learning (Ando and Zhang, 2005), the success of target task depends on the ability of finding good predictive structures learned from other related tasks, e.g., structural correspondence learning (SCL) (Blitzer et al., 2006) for coarse-grained cross-domain sentiment classification.",1 Introduction,[0],[0]
"Here, we aim to generate an auxiliary task on dependency relation classification.",1 Introduction,[0],[0]
"Different from previous approaches, our auxiliary task and the target extraction task are of heterogeneous label spaces.",1 Introduction,[0],[0]
"We aim to integrate this auxiliary task with distributed relation representation learning into a recursive neural network.
",1 Introduction,[0],[0]
"Specifically, we generate a dependency tree for each sentence from the dependency parser and construct a unified RNN that integrates an auxiliary task into the computation of each node.",1 Introduction,[0],[0]
The auxiliary task is to classify the dependency relation for each direct edge in the dependency tree by learning a relation feature vector.,1 Introduction,[0],[0]
"To reduce label noise brought by inaccurate parsing trees, we further propose to incorporate an autoencoder into the auxiliary task to group the relations into different clusters.",1 Introduction,[0],[0]
"Finally, to model the sequential context interaction, we develop a joint architecture that combines RNN with a sequential labeling model for aspect and opinion terms extraction.",1 Introduction,[0],[0]
Extensive experiments are conducted to demonstrate the advantage of our proposed model.,1 Introduction,[0],[0]
"Existing works for single-domain aspect/opinion terms extraction include unsupervised methods based on association rule mining (Hu and Liu, 2004), syntactic rule propagation (Qiu et al., 2011) or topic modeling (Titov and McDonald, 2008; Lu et al., 2009; Zhang et al., 2010), as well as supervised methods based on extensive feature engineering with graphical models (Jin and Ho, 2009; Li et al., 2010) or deep learning (Liu et al., 2015; Zhang et al., 2015; Wang et al., 2017; Yin et al., 2016).",2 Related Work,[0],[0]
"Among exiting deep models, improved results are obtained using dependency relations (Yin et al., 2016; Wang et al., 2016), which indicates the significance of syntactic word interactions for target term extraction.",2 Related Work,[0],[0]
"In cross-domain setting, there are very few works for aspect/opinion terms extraction including a pipelined approach (Li et al., 2012) and a recurrent neural network (Ding et al., 2017).",2 Related Work,[0],[0]
"Both of the methods require manual construction
of common and pivot syntactic patterns or rules, which are indicative of aspect or opinion words.
",2 Related Work,[0],[0]
There have been a number of domain adaptation approaches proposed for coarse-grained sentiment classification.,2 Related Work,[0],[0]
"Among existing methods, one active line focuses on projecting original feature spaces of two domains into the same low-dimensional space to reduce domain shift using pivot features as a bridge (Blitzer et al., 2007; Pan et al., 2010; Bollegala et al., 2015; Yu and Jiang, 2016).",2 Related Work,[0],[0]
"Another line learns domain-invariant features via autoencoders (Glorot et al., 2011; Chen et al., 2012; Zhou et al., 2016).",2 Related Work,[0],[0]
"Our work is more related to the first line by utilizing pivot information to transfer knowledge across domains, but we integrate the idea into a unified deep structure that can fully utilize syntactic structure for domain adaptation in fine-grained sentiment analysis.",2 Related Work,[0],[0]
Our task is to extract opinion and aspect terms within each review sentence.,3 Problem Definition & Motivation,[0],[0]
We denote a sentence by a sequence of tokens x=,3 Problem Definition & Motivation,[0],[0]
"(w1, w2, ..., wn).",3 Problem Definition & Motivation,[0],[0]
"The output is a sequence of token-level labels y=(y1, y2, ..., yn), with yi∈{BA, IA,BO, IO,N} that represents beginning of an aspect (BA), inside of an aspect (IA), beginning of an opinion (BO), inside of an opinion (IO) or none of the above (N).",3 Problem Definition & Motivation,[0],[0]
A subsequence of labels started with “BA” and followed by “IA” indicates a multi-word aspect term.,3 Problem Definition & Motivation,[0],[0]
"In unsupervised domain adaptation, we are given a set of labeled review sentences from a source domain DS={(xSi ,ySi)} nS i=1, and a set of unlabeled sentences from a target domain DT = {xTj} nT j=1.",3 Problem Definition & Motivation,[0],[0]
Our goal is to predict token-level labels on DT .,3 Problem Definition & Motivation,[0],[0]
Existing works for cross-domain aspect and/or opinion terms extraction require hand-coded rules and a sentiment lexicon in order to transfer knowledge across domains.,3 Problem Definition & Motivation,[0],[0]
"For example in Figure 1, given a review sentence “They offer good appetizers” in the source domain and “The laptop has a nice screen” in the target domain.",3 Problem Definition & Motivation,[0],[0]
"If nice has been extracted as a common sentiment word, and “OPINION-amod-ASPECT” has been identified as a common syntactic pattern from the source domain, screen could be deduced as an aspect term using the identified syntactic pattern (Li et al., 2012).",3 Problem Definition & Motivation,[0],[0]
"Similarly, Ding et al. (2017) used a set of predefined rules based on syntactic relations and a sentiment lexicon to generate auxiliary labels to learn high-level feature representations through a
recurrent neural network.",3 Problem Definition & Motivation,[0],[0]
"On one hand, these previous attempts have verified that syntactic information between words, which can be used as a bridge between domains, is crucial for domain adaptation.",3 Problem Definition & Motivation,[0],[0]
"On the other hand, dependency-tree-based RNN (Socher et al., 2010) has proven to be effective to learn high-level feature representation of each word by encoding syntactic relations between aspect terms and opinion terms (Wang et al., 2016).",3 Problem Definition & Motivation,[0],[0]
"With the above findings, we propose a novel RNN named Recursive Neural Structural Correspondence Network (RNSCN) to learn high-level representation for each word across different domains.",3 Problem Definition & Motivation,[0],[0]
Our model is built upon dependency trees generated from a dependency parser.,3 Problem Definition & Motivation,[0],[0]
"Different from previous approaches, we do not require any hand-coded rules or pre-selected pivot features to construct correspondences, but rather focus on the automatically generated dependency relations as the pivots.",3 Problem Definition & Motivation,[0],[0]
"The model associates each direct edge in the tree with a relation feature vector, which is used to predict the corresponding dependency relation as an auxiliary task.
",3 Problem Definition & Motivation,[0],[0]
Note that the relation vector is the key in the model: it associates with the two interacting words and is used to construct structural correspondences between two different domains.,3 Problem Definition & Motivation,[0],[0]
"Hence, the auxiliary task guides the learning of relation vectors, which in turn affects their correspondingly interactive words.",3 Problem Definition & Motivation,[0],[0]
"Specifically in Figure 1, the relation vector for “amod” is computed from the features of its child and parent words, and also used to produce the hidden representation of its parent.",3 Problem Definition & Motivation,[0],[0]
"For this relation path in both sentences, the auxiliary task enforces close proximity for these two relation vectors.",3 Problem Definition & Motivation,[0],[0]
"This pushes the hidden representations for their parent nodes appetizers and screen closer to each other, provided that good and nice have similar representations.",3 Problem Definition & Motivation,[0],[0]
"In a word, the auxiliary task bridges the gap between two different domains by drawing the words with similar syntactic properties closer to each other.
",3 Problem Definition & Motivation,[0],[0]
"However, the relation vectors may be sensitive to the accuracy of the dependency parser.",3 Problem Definition & Motivation,[0],[0]
"It might
harm the learning process when some noise exists for certain relations, especially for informal texts.",3 Problem Definition & Motivation,[0],[0]
"This problem of noisy labels has been addressed using perceptual consistency (Reed et al., 2015).",3 Problem Definition & Motivation,[0],[0]
"Inspired by the taxonomy of dependency relations (de Marneffe and Manning, 2008), relations with similar functionalities could be grouped together, e.g., dobj, iobj and pobj all indicate objects.",3 Problem Definition & Motivation,[0],[0]
We propose to use an auto-encoder to automatically group these relations in an unsupervised manner.,3 Problem Definition & Motivation,[0],[0]
The reconstruction loss serves as the consistency objective that reduces label noise by aligning relation features with their intrinsic relation group.,3 Problem Definition & Motivation,[0],[0]
Our model consists of two components.,4 Proposed Methodology,[0],[0]
"The first component is a Recursive Neural Structural Correspondence Network (RNSCN), and the second component is a sequence labeling classifier.",4 Proposed Methodology,[0],[0]
"In this paper, we focus on Gated Recurrent Unit (GRU) as an implementation for the sequence labeling classifier.",4 Proposed Methodology,[0],[0]
We choose GRU because it is able to deal with long-term dependencies compared to a simple Recurrent neural network and requires less parameters making it easier to train than LSTM.,4 Proposed Methodology,[0],[0]
The resultant deep learning model is denoted by RNSCN-GRU.,4 Proposed Methodology,[0],[0]
"We also implement Conditional Random Field as the sequence labeling classifier, and denote the model by RNSCN-CRF accordingly.
",4 Proposed Methodology,[0],[0]
The overall architecture of RNSCN-GRU without auto-encoder on relation denoising is shown in Figure 2.,4 Proposed Methodology,[0],[0]
"The left and right are two example sentences from the source and the target domain, respectively.",4 Proposed Methodology,[0],[0]
"In the first component, RNSCN, an auxiliary task to predict the dependency relation for each direct edge is integrated into a dependencytree-based RNN.",4 Proposed Methodology,[0],[0]
"We generate a relation vector for each direct edge from its child node to parent node, and use it to predict the relation and produce the hidden representation for the parent node in the dependency tree.",4 Proposed Methodology,[0],[0]
"To address the issues of noisy relation labels, we further incorporate an auto-encoder into RNSCN, as will be shown in Figure 3.
While RNSCN mainly focuses on syntactic interactions among the words, the second component, GRU, aims to compute linear-context interactions.",4 Proposed Methodology,[0],[0]
GRU takes the hidden representation of each word computed from RNSCN as inputs and further produces final representation of each word by taking linear contexts into consideration.,4 Proposed Methodology,[0],[0]
We describe each component in detail in the following sections.,4 Proposed Methodology,[0],[0]
"RNSCN is built on the dependency tree of each sentence, which is pre-generated from a dependency parser.",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"Specifically, each node in the tree is associated with a word wn, an input word embedding xn∈Rd and a transformed hidden representation hn∈Rd.",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"Each direct edge in the dependency tree associates with a relation feature vector rnm∈Rd and a true relation label vector yRnm∈RK , where K is the total number of dependency relations, n and m denote the indices of the parent and child word of the dependency edge, respectively.",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"Based on the dependency tree, the hidden representations are generated in a recursive manner from leaf nodes until reaching the root node.",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"Consider the sourcedomain sentence shown in Figure 2 as an illustrative example, we first compute hidden representations for leaf nodes they and good:
h1=tanh(Wxx1 + b), h3=tanh(Wxx3 + b),
where Wx ∈ Rd×d transforms word embeddings to hidden space.",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"For non-leaf node appetizer, we first generate the relation vector r43 for the dependency edge x4 (appetizers) amod−−−−→ x3 (good) by
r43 = tanh(Whh3 + Wxx4),
where Wh ∈ Rd×d transforms the hidden representation to the relation vector space.",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"We then compute the hidden representation for appetizer:
h4 = tanh(Wamodr43 + Wxx4 + b).
",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"Moreover, the relation vector r43 is used for the auxiliary task on relation prediction:
ŷR43 = softmax(WRr43 + bR),
where WR ∈ RK×d is the relation classification matrix.",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
The supervised relation classifier enforces close proximity of similar {rnm}’s in the distributed relation vector space.,4.1 Recursive Neural Structural Correspondence Network,[0],[0]
The relation features bridge the gap of word representations in different domains by incorporating them into the forward computations.,4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"In general, the hidden representation hn for a non-leaf node is produced through
hn=tanh( ∑
m∈Mn
WRnmrnm +",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"Wxxn + b), (1)
where rnm=tanh(Wh ·hm+Wx ·xn),Mn is the set of child nodes of wn, and WRnm is the relation transformation matrix tied with each relation Rnm.",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"The predicted label vector ŷRnm for rnm is
ŷRnm = softmax(WR · rnm + bR).",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"(2)
Here we adopt the the cross-entropy loss for relation classification between the predicted label vector ŷRnm and the ground-truth y R nm to encode relation side information into feature learning:
`R = K∑ k=1 −yRnm[k] log ŷ",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
R nm[k].,4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"(3)
Through the auxiliary task, similar relations enforce participating words close to each other so
that words with similar syntactic functionalities are clustered across domains.",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"On the other hand, the pre-trained word embeddings group semanticallysimilar words.",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"By taking them as input to RNN, together with the auxiliary task, our model encodes both semantic and syntactic information.",4.1 Recursive Neural Structural Correspondence Network,[0],[0]
"As discussed in Section 3, it might be hard to learn an accurate relation classifier when each class is a unique relation, because the dependency parser may generate incorrect relations as noisy labels.",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"To address it, we propose to integrate an autoencoder into RNSCN.",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"Suppose there is a set of latent groups of relations: G = {1, 2, ..., |G|}, where each relation belongs to only one group.",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"For each relation vector, rnm, an autoencoder is performed before feeding it into the auxiliary classifier (2).",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
The goal is to encode the relation vector to a probability distribution of assigning this relation to any group.,4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"As can be seen Figure 3, each relation vector rnm is first passed through the autoencoder as follows,
p(Gnm = i|rnm) = exp(r>nmWencgi)∑
j∈G exp(r>nmWencgj)
, (4)
where Gnm denotes the inherent relation group for rnm, gi∈Rd represents the feature embedding for group i, and Wenc∈Rd×d is the encoding matrix that computes bilinear interactions between relation vector rnm and relation group embedding gi.",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"Thus, p(Gnm = i|rnm) represents the probability of rnm being mapped to group i.",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"An accumulated relation group embedding is computed as:
gnm = |G|∑ i=1",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
p(Gnm,4.2 Reduce Label Noise with Auto-encoders,[0],[0]
= i|rnm)gi.,4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"(5)
For decoding, the decoder takes gnm as input and tries to reconstruct the relation feature input rnm.",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"Moreover, gnm is also used as the higher-level feature vector for rnm for predicting the relation label.",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"Therefore, the objective for the auxiliary task in (3) becomes:
`R = `R1 + α`R2 + β`R3 , (6)
where
`R1 = ‖rnm −Wdecgnm‖ 2 2 , (7)
`R2 = K∑ k=1 −yRnm[k] log ŷ",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"R nm[k], (8)
`R3 = ∥∥∥I−",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"Ḡ>Ḡ∥∥∥2
F .",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"(9)
Here `R1 is the reconstruction loss with Wdec being the decoding matrix, `R2 follows (3) with ŷRnm = softmax(WRgnm + bR) and `R3 is the regularization term on the correlations among latent groups with I being the identity matrix and Ḡ being a normalized group embedding matrix that consists of normalized gi’s as column vectors.",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
This regularization term enforces orthogonality between gi and gj for i 6=,4.2 Reduce Label Noise with Auto-encoders,[0],[0]
j. α and β are used to control the trade-off among different losses.,4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"With the auto-encoder, the auxiliary task of relation classification is conditioned on group assignment.",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
"The reconstruction loss further ensures the consistency between relation features and groupings, which is supposed to dominate classification loss when the observed labels are inaccurate.",4.2 Reduce Label Noise with Auto-encoders,[0],[0]
We denote RNSCN with auto-encoder by RNSCN+.,4.2 Reduce Label Noise with Auto-encoders,[0],[0]
RNSCN or RNSCN+ focuses on capturing and representing syntactic relations to build a bridge between domains and learn more powerful representations for tokens.,4.3 Joint Models for Sequence Labeling,[0],[0]
"However, it ignores the linearchain correlations among tokens within a sentence, which is important for aspect and opinion terms extraction.",4.3 Joint Models for Sequence Labeling,[0],[0]
"Therefore, we propose a joint model, denoted by RNSCN-GRU (RNSCN+-GRU), which integrates a GRU-based recurrent neural network on top of RNSCN (RNSCN+), i.e., the input for GRU is the hidden representations hn learned by RNSCN or RNSCN+ for the n-th token in the sentence.",4.3 Joint Models for Sequence Labeling,[0],[0]
"For simplicity in presentation, we denote the computation of GRU by using the notation fGRU .",4.3 Joint Models for Sequence Labeling,[0],[0]
"To be specific, by taking hn as input, the final feature representation h′n for each word is obtained through
h′n = fGRU",4.3 Joint Models for Sequence Labeling,[0],[0]
"(h ′ n−1,hn;Θ), (10)
where Θ is the collection of the GRU parameters.",4.3 Joint Models for Sequence Labeling,[0],[0]
"The final token-level prediction is made through
ŷn = softmax(Wl · h′n + bl), (11)
",4.3 Joint Models for Sequence Labeling,[0],[0]
"where Wl ∈ R5×d ′ transforms a d′-dimensional feature vector to class probabilities (note that we
have 5 different classes as defined in Section 3).",4.3 Joint Models for Sequence Labeling,[0],[0]
"The second joint model, namely RNSCN-CRF, combines a linear-chain CRF with RNSCN to learn the discriminative mapping from high-level features to labels.",4.3 Joint Models for Sequence Labeling,[0],[0]
The advantage of CRF is to learn sequential interactions between each pair of adjacent words as well as labels and provide structural outputs.,4.3 Joint Models for Sequence Labeling,[0],[0]
"Formally, the joint model aims to output a sequence of labels with maximum conditional probability given its input.",4.3 Joint Models for Sequence Labeling,[0],[0]
"Denote by y a sequence of labels for a sentence and by H the embedding matrix for each sentence (each column denotes a hidden feature vector of a word in the sentence learned by RNSCN), the inference is computed as:
ŷ= argmax y
p(y|H)
= argmax y
1
Z(H) ∏ c∈C",4.3 Joint Models for Sequence Labeling,[0],[0]
"exp〈Wc, g(H,yc)〉(12)
whereC indicates the set of different cliques (unary and pairwise cliques in the context of linear-chain).",4.3 Joint Models for Sequence Labeling,[0],[0]
"Wc is tied for each different yc, which indicates the labels for clique c.",4.3 Joint Models for Sequence Labeling,[0],[0]
"The operator 〈·, ·〉 is the element-wise multiplication, and g(·) produces the concatenation of {hn}’s in a context window of each word.",4.3 Joint Models for Sequence Labeling,[0],[0]
"The above two models both consider the sequential interaction of the words within each sentence, but the formalization and training are totally different.",4.3 Joint Models for Sequence Labeling,[0],[0]
We will report the results for both joint models in the experiment section.,4.3 Joint Models for Sequence Labeling,[0],[0]
"Recall that in our cross-domain setting, the labels for terms extraction are only available in the source domain, but the auxiliary relation labels can be automatically produced for both domains via the dependency parser.",4.4 Training,[0],[0]
"Besides the source domain labeled data DS = {(xSi ,ySi)} nS i=1, we denote by DR={(rj ,yRj )} nR j=1 the combined source and target domain data with auxiliary relation labels.",4.4 Training,[0],[0]
"For training, the total loss consists of token-prediction loss `S and relation-prediction loss `R:
L = ∑ DS `S(ySi , ŷSi)",4.4 Training,[0],[0]
"+ γ ∑ DR `R(rj ,y R j ), (13)
where γ is the trade-off parameter, `S is the crossentropy loss between the predicted extraction label in (11) and the ground-truth, and `R is defined in (6) for RNSCN+ or (3) for RNSCN.",4.4 Training,[0],[0]
"For RNSCNCRF, the loss becomes the negative log probability of the true label given the corresponding input:
`S(ySi , ŷSi) =",4.4 Training,[0],[0]
− log(ySi |hSi).,4.4 Training,[0],[0]
"(14)
The parameters for token-level predictions and relation-level predictions are updated jointly such that the information from the auxiliary task could be propagated to the target task to obtain better performance.",4.4 Training,[0],[0]
"This idea is in accordance with structural learning proposed by Ando and Zhang (2005), which shows that multiple related tasks are useful for finding the optimal hypothesis space.",4.4 Training,[0],[0]
"In our case, the set of multiple tasks includes the target terms extraction task and the auxiliary relation prediction task, which are closely related.",4.4 Training,[0],[0]
The parameters are all shared across domains.,4.4 Training,[0],[0]
The joint model is trained using back-propagation from the top layer of GRU or CRF to RNSCN until reaching to the input word embeddings in the bottom.,4.4 Training,[0],[0]
"The data is taken from the benchmark customer reviews in three different domains, namely restaurant, laptop and digital devices.",5.1 Data & Experimental Setup,[0],[0]
"The restaurant domain contains a combination of restaurant reviews from SemEval 2014 task 4 subtask 1 (Pontiki et al., 2014) and SemEval 2015 task 12 subtask 1 (Pontiki et al., 2015).",5.1 Data & Experimental Setup,[0],[0]
The laptop domain consists of laptop reviews from SemEval 2014 task 4 subtask 1.,5.1 Data & Experimental Setup,[0],[0]
"For digital device, we take reviews from (Hu and Liu, 2004) containing sentences from 5 digital devices.",5.1 Data & Experimental Setup,[0],[0]
The statistics for each domain are shown in Table 1.,5.1 Data & Experimental Setup,[0],[0]
"In our experiments, we randomly split the data in each domain into training set and testing set with the proportion being 3:1.",5.1 Data & Experimental Setup,[0],[0]
"To obtain more rigorous result, we make three random splits for each domain and test the learned model on each split.",5.1 Data & Experimental Setup,[0],[0]
The number of sentences for training and testing after each split is also shown in Table 1.,5.1 Data & Experimental Setup,[0],[0]
"Each sentence is labeled with aspect terms and opinion terms.
",5.1 Data & Experimental Setup,[0],[0]
"For each cross-domain task, we conduct both inductive and transductive experiments.",5.1 Data & Experimental Setup,[0],[0]
"Specifically, we train our model only on the training sets from both (labeled) source and (unlabeled) target domains.",5.1 Data & Experimental Setup,[0],[0]
"For testing, the inductive results are obtained using the test data from the target domain, and the transductive results are obtained using the (unlabeled) training data from the target domain.
",5.1 Data & Experimental Setup,[0],[0]
The evaluation metric we used is F1 score.,5.1 Data & Experimental Setup,[0],[0]
"Following the setting from existing work, only exact match could be counted as correct.
",5.1 Data & Experimental Setup,[0],[0]
"For experimental setup, we use Stanford Dependency Parser (Klein and Manning, 2003) to generate dependency trees.",5.1 Data & Experimental Setup,[0],[0]
"There are in total 43 different dependency relations, i.e. 43 classes for the auxiliary task.",5.1 Data & Experimental Setup,[0],[0]
We set the number of latent relation groups as 20.,5.1 Data & Experimental Setup,[0],[0]
"The input word features for RNSCN are pre-trained word embeddings using word2vec (Mikolov et al., 2013) which is trained on 3M reviews from the Yelp dataset2 and electronics dataset in Amazon reviews3",5.1 Data & Experimental Setup,[0],[0]
"(McAuley et al., 2015).",5.1 Data & Experimental Setup,[0],[0]
The dimension of word embeddings is 100.,5.1 Data & Experimental Setup,[0],[0]
"Because of the relatively small size of the training data compared with the number of parameters, we firstly pre-train RNSCN for 5 epochs with minibatch size 30 and rmsprop initialized at 0.01.",5.1 Data & Experimental Setup,[0],[0]
The joint model of RNSCN+-GRU is then trained with rmsprop initialized at 0.001 and mini-batch size 30.,5.1 Data & Experimental Setup,[0],[0]
"The trade-off parameter α, β and γ are set to be 1, 0.001 and 0.1, respectively.",5.1 Data & Experimental Setup,[0],[0]
"The hidden-layer dimension for GRU is 50, and the context window size is 3 for input feature vectors of GRU.",5.1 Data & Experimental Setup,[0],[0]
"For the joint model of RNSCN-CRF, we implement SGD with a decaying learning rate initialized at 0.02.",5.1 Data & Experimental Setup,[0],[0]
The context window size is also 3 in this case.,5.1 Data & Experimental Setup,[0],[0]
Both joint models are trained for 10 epochs.,5.1 Data & Experimental Setup,[0],[0]
"We compared our proposed model with several baselines and variants of the proposed model:
• RNCRF: A joint model of recursive neural network and CRF proposed by (Wang et al., 2016) for single-domain aspect and opinion terms extraction.",5.2 Comparison & Results,[0],[0]
"We make all the parameters shared across domains for target prediction.
",5.2 Comparison & Results,[0],[0]
• RNGRU: A joint model of RNN and GRU.,5.2 Comparison & Results,[0],[0]
The hidden layer of RNN is taken as input for GRU.,5.2 Comparison & Results,[0],[0]
"We share all the parameters across domains, similar to RNCRF.
",5.2 Comparison & Results,[0],[0]
• CrossCRF:,5.2 Comparison & Results,[0],[0]
"A linear-chain CRF with handengineered features that are useful for crossdomain settings (Jakob and Gurevych, 2010), e.g., POS tags, dependency relations.
",5.2 Comparison & Results,[0],[0]
• RAP:,5.2 Comparison & Results,[0],[0]
"The Relational Adaptive bootstraPping method proposed by (Li et al., 2012) that uses TrAdaBoost to expand lexicons.
",5.2 Comparison & Results,[0],[0]
"2http://www.yelp.com/dataset challenge 3http://jmcauley.ucsd.edu/data/amazon/links.html
• Hier-Joint: A recent deep model proposed by Ding et al. (2017) that achieves state-ofthe-art performance on aspect terms extraction across domains.
",5.2 Comparison & Results,[0],[0]
"• RNSCN-GRU: Our proposed joint model integrating auxiliary relation prediction task into RNN that is further combined with GRU.
•",5.2 Comparison & Results,[0],[0]
RNSCN-CRF:,5.2 Comparison & Results,[0],[0]
"The second proposed model similar to RNSCN-GRU, which replace GRU with CRF.
• RNSCN+-GRU:",5.2 Comparison & Results,[0],[0]
"Our final joint model with auto-encoders to reduce auxiliary label noise.
",5.2 Comparison & Results,[0],[0]
"Note that we do not implement other recent deep adaptation models for comparison (Chen et al., 2012; Yang and Hospedales, 2015), because HierJoint (Ding et al., 2017) has already demonstrated better performances than these models.",5.2 Comparison & Results,[0],[0]
The overall comparison results with the baselines are shown in Table 2 with average F1 scores and standard deviations over three random splits.,5.2 Comparison & Results,[0],[0]
"Clearly, the results for aspect terms (AS) transfer are much lower than opinion terms (OP) transfer, which indicate that the aspect terms are usually quite different across domains, whereas the opinion terms could be more common and similar.",5.2 Comparison & Results,[0],[0]
Hence the ability to adapt the aspect extraction from the source domain to the target domain becomes more crucial.,5.2 Comparison & Results,[0],[0]
"On this behalf, our proposed model shows clear advantage over other baselines for this more difficult transfer problem.",5.2 Comparison & Results,[0],[0]
"Specifically, we achieve 6.77%, 5.88%, 10.55% improvement over the bestperforming baselines for aspect extraction in R→L, L→D and D→L, respectively.",5.2 Comparison & Results,[0],[0]
"By comparing with RNCRF and RNGRU, we show that the structural correspondence network is indeed effective when integrated into RNN.
",5.2 Comparison & Results,[0],[0]
"To show the effect of the integration of the autoencoder, we conduct experiments over different variants of the proposed model in Table 3.",5.2 Comparison & Results,[0],[0]
"RNSCNGRU represents the model without autoencoder, which achieves much better F1 scores on most experiments compared with the baselines in Table 2.",5.2 Comparison & Results,[0],[0]
RNSCN+-GRU outperforms RNSCN-GRU in almost all experiments.,5.2 Comparison & Results,[0],[0]
"This indicates the autoencoder automatically learns data-dependent groupings, which is able to reduce unnecessary label noise.",5.2 Comparison & Results,[0],[0]
"To further verify that the autoencoder indeed reduces label noise when the parser is inaccurate, we generate new noisy parse trees by replacing some relations within each sentence with a random
relation.",5.2 Comparison & Results,[0],[0]
"Specifically, in each source domain, for each relation that connects to any aspect or opinion word, it has 0.5 probability of being replaced by any other relation.",5.2 Comparison & Results,[0],[0]
"In Table 3, We denote the model with noisy relations with (r).",5.2 Comparison & Results,[0],[0]
"Obviously, the performance of RNSCN-GRU without an autoencoder significantly deteriorates when the auxiliary labels are very noisy.",5.2 Comparison & Results,[0],[0]
"On the contrary, RNSCN+GRU (r) achieves acceptable results compared to RNSCN+-GRU.",5.2 Comparison & Results,[0],[0]
This proves that the autoencoder makes the model more robust to label noise and helps to adapt the information more accurately to the target data.,5.2 Comparison & Results,[0],[0]
Note that a large drop for L→ R in aspect extraction might be caused by a large portion of noisy replacements for this particular data which makes it too hard to train a good classifier.,5.2 Comparison & Results,[0],[0]
"This may not greatly influence opinion extraction, as shown, because the two domains usually share many common opinion terms.",5.2 Comparison & Results,[0],[0]
"However, the significant difference in aspect terms makes the learning
more dependent on common relations.",5.2 Comparison & Results,[0],[0]
"The above comparisons are made using the test data from target domains which are not available during training (i.e., the inductive setting).",5.2 Comparison & Results,[0],[0]
"For more complete comparison, we also conduct experiments in the transductive setting.",5.2 Comparison & Results,[0],[0]
"We pick our best model RNSCN+-GRU, and show the effect of different components.",5.2 Comparison & Results,[0],[0]
"To do that, we first remove the sequential structure on top, resulting in RNSCN+.",5.2 Comparison & Results,[0],[0]
"Moreover, we create another variant by removing opinion term labels to show the effect of the double propogation between aspect terms and opinion terms.",5.2 Comparison & Results,[0],[0]
The resulting model is named RNSCN+GRU*.,5.2 Comparison & Results,[0],[0]
"As shown in Table 4, we denote by OUT and IN the inductive and transductive setting, respectively.",5.2 Comparison & Results,[0],[0]
The results shown are the average F1 scores among three splits4.,5.2 Comparison & Results,[0],[0]
"In general, RNSCN+GRU shows similar performances for both inductive and transductive settings.",5.2 Comparison & Results,[0],[0]
"This indicates the
4We omit standard deviation here due to the limit of space.
robustness and the ability to learn well when test data is not presented during training.",5.2 Comparison & Results,[0],[0]
"Without opinion labels, RNSCN+-GRU* still achieves better results than Hier-Joint most of the time.",5.2 Comparison & Results,[0],[0]
"Its lower performance compared to RNSCN+-GRU also indicates that in the cross-domain setting, the dual information between aspects and opinions is beneficial to find appropriate and discriminative relation feature space.",5.2 Comparison & Results,[0],[0]
"Finally, the results for RNSCN+ by removing GRU are lower than the joint model, which proves the importance of combining syntactic tree structure with sequential modeling.
",5.2 Comparison & Results,[0],[0]
"To qualitatively show the effect of the auxiliary task with auto-encoders for clustering syntactically similar words across domains, we provide some case studies on the predicted groups of some words in Table 5.",5.2 Comparison & Results,[0],[0]
"Specifically, for each relation in the dependency tree, we use (4) to obtain the most probable group to assign the word in the child node.",5.2 Comparison & Results,[0],[0]
The left column shows the predicted group index with the right column showing the corresponding words.,5.2 Comparison & Results,[0],[0]
"Clearly, the words in the same group have similar syntactic functionalities, whereas the word types vary across groups.
",5.2 Comparison & Results,[0],[0]
"In the end, we verify the robustness and capability of the model by conducting sensitivity studies and experiments with varying number of unlabeled target data for training, respectively.",5.2 Comparison & Results,[0],[0]
"Figure 4 shows the sensitivity test for L→D, which indicates that changing of the trade-off parameter γ or the number of groups |G| does not affect the model’s performance greatly, i.e., less than 1% for aspect extraction and 2% for opinion extraction.",5.2 Comparison & Results,[0],[0]
This proves that our model is robust and stable against small variations.,5.2 Comparison & Results,[0],[0]
Figure 5 compares the results of RNSCN+-GRU with Hier-Joint when increasing the proportion of unlabeled target training data from 0 to 1.,5.2 Comparison & Results,[0],[0]
"Obviously, our model shows steady improvement with the increasing number of unlabeled target data.",5.2 Comparison & Results,[0],[0]
"This pattern proves our
model’s capability of learning from target domain for adaptation.",5.2 Comparison & Results,[0],[0]
"We propose a novel dependency-tree-based RNN, namely RNSCN (or RNSCN+), for domain adaptation.",6 Conclusion,[0],[0]
The model integrates an auxiliary task into representation learning of nodes in the dependency tree.,6 Conclusion,[0],[0]
"The adaptation takes place in a common relation feature space, which builds the structural correspondences using syntactic relations among the words in each sentence.",6 Conclusion,[0],[0]
We further develop a joint model to combine RNSCN/RNSCN+ with a sequential labeling model for terms extraction.,6 Conclusion,[0],[0]
"This work is supported by NTU Singapore Nanyang Assistant Professorship (NAP) grant M4081532.020, MOE AcRF Tier-1 grant 2016- T1-001-159, and Fuji Xerox Corporation through joint research on Multilingual Semantic Analysis.",Acknowledgements,[0],[0]
Fine-grained opinion analysis aims to extract aspect and opinion terms from each sentence for opinion summarization.,abstractText,[0],[0]
Supervised learning methods have proven to be effective for this task.,abstractText,[0],[0]
"However, in many domains, the lack of labeled data hinders the learning of a precise extraction model.",abstractText,[0],[0]
"In this case, unsupervised domain adaptation methods are desired to transfer knowledge from the source domain to any unlabeled target domain.",abstractText,[0],[0]
"In this paper, we develop a novel recursive neural network that could reduce domain shift effectively in word level through syntactic relations.",abstractText,[0],[0]
We treat these relations as invariant “pivot information” across domains to build structural correspondences and generate an auxiliary task to predict the relation between any two adjacent words in the dependency tree.,abstractText,[0],[0]
"In the end, we demonstrate state-ofthe-art results on three benchmark datasets.",abstractText,[0],[0]
Recursive Neural Structural Correspondence Network for Cross-domain Aspect and Opinion Co-Extraction,title,[0],[0]
Personalization is the problem of determining the best treatment option for a given instance.,1. Introduction,[0],[0]
"A treatment can, for example, be a movie recommendation (Zhou et al., 2008), a display ad (Goldfarb & Tucker, 2011), or a pharmacological therapy (Lesko, 2007), and an instance is usually an individual person.",1. Introduction,[0],[0]
"In this paper, we study the problem of learning how to personalize from observational data, which is an important problem in emergent contexts such as personalized medicine.",1. Introduction,[0],[0]
"In this and related contexts, experimentation can be prohibitively small-scale, costly, dangerous, and unethical in comparison to passive data collection,
1School of Operations Research and Information Engineering and Cornell Tech, Cornell University.",1. Introduction,[0],[0]
"Correspondence to: Nathan Kallus <kallus@cornell.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"which can be potentially massive as in electronic medical records (EMRs) but, at the same time, lack experimental manipulation so that isolated causal effects of specific treatments are hidden by confounding factors.",1. Introduction,[0],[0]
"We show that standard approaches that pose the problem as multiple supervised learning tasks fall short in this setting and propose new learning algorithms as well as evaluation methods used for validation, selection, and tuning.
",1. Introduction,[0],[0]
"Specifically, we consider the problem of learning how to assign the best of m treatments to an instance, given an observation of associated baseline covariates x ∈ Rd.",1. Introduction,[0],[0]
"An instance is characterized by the random variables X ∈ Rd and Y (1), . . .",1. Introduction,[0],[0]
", Y (m) ∈ R, which denote the covariates and the m potential outcomes of applying each of the treatments (Imbens & Rubin, 2015, Chs. 1-2).",1. Introduction,[0],[0]
We use the convention that smaller outcome is better.,1. Introduction,[0],[0]
A personalization model is a map τ : Rd,1. Introduction,[0],[0]
"→ [m] = {1, . . .",1. Introduction,[0],[0]
",m} that, given an observation of covariates x, prescribes a treatment τ(x).",1. Introduction,[0],[0]
Its (out-of-sample) personalization risk is its average causal effect in the population R(τ) =,1. Introduction,[0],[0]
E [Y (τ(X))],1. Introduction,[0],[0]
"(the expectation is taken with respect to the joint distribution of X,Y (1), . . .",1. Introduction,[0],[0]
", Y (m)).",1. Introduction,[0],[0]
"The Bayes optimal risk is R∗ = R(τ∗), where τ∗(x) ∈ T ∗(x) = arg mint∈[m] E",1. Introduction,[0],[0]
[Y (t),1. Introduction,[0],[0]
"| X = x] is the Bayes optimal personalization model.
",1. Introduction,[0],[0]
The learning task is to train a personalization model τ̂n(·) on n data points:,1. Introduction,[0],[0]
"Sn = {(X1, T1, Y1), . . .",1. Introduction,[0],[0]
", (Xn, Tn, Yn)} , where the observed outcome Yi = Yi(Ti) corresponds only to the treatment Ti administered.",1. Introduction,[0],[0]
This data is observational: we may not control the historic administration of treatment (as we would in a controlled experiment) and the values Yi(t) for t 6=,1. Introduction,[0],[0]
Ti are missing data.,1. Introduction,[0],[0]
"We assume the data is independent and identically distributed (iid) and let X,T, Y, Y (1), . . .",1. Introduction,[0],[0]
", Y (m) represent a generic draw.",1. Introduction,[0],[0]
"Although the data is iid, the t-treated sample {i : Ti = t} differs systematically from the sample t′-treated {i : Ti = t′} for t 6= t′, i.e., not just by chance as in a randomized controlled trial (RCT).",1. Introduction,[0],[0]
"Our second assumption about the data is unconfoundedness:
Assumption 1.",1. Introduction,[0],[0]
For each t ∈,1. Introduction,[0],[0]
"[m]: Y (t) is independent of T given X and T = t is possible for almost every X , i.e., Y (t) ⊥ T | X and P (P (T = t | X)",1. Introduction,[0],[0]
> 0),1. Introduction,[0],[0]
"= 1.
",1. Introduction,[0],[0]
"The assumption is standard in causal effect estimation
(see e.g. Kallus, 2016; 2017b) for ensuring identifiability (Rosenbaum & Rubin, 1983).",1. Introduction,[0],[0]
It says that we measured the right covariates to separate the effect of the treatment itself from the effect of assignment.,1. Introduction,[0],[0]
"In the context of personalized medicine, this assumption would be justified if the EMR contained all the patient information used by a doctor to prescribe treatment up to the vagaries and idiosyncrasies of individual doctors or hospitals.",1. Introduction,[0],[0]
"Under Asn. 1, the conditional causal effect is equal to regressing Y on X,T :
E [Y (t) | X = x] = E [Y (t) | X = x, T = t] = E",1. Introduction,[0],[0]
"[Y | X = x, T = t] .",1. Introduction,[0],[0]
"Since under Asn. 1 the optimal model τ∗ chooses a treatment by minimizing among m regression functions, one obvious approach to personalization is to estimate these regression functions, fitting each to the subset of the data that received each treatment, and then use these to predict outcomes and pick the smallest prediction.",1.1. Standard Approach: Regress and Compare,[0],[0]
"For example, in medicine, there is a vast literature on predicting patient-specific responses to treatment (Feldstein et al., 1978; Stoehlmacher et al., 2004) and picking the best by comparing (Qian & Murphy, 2011; Bertsimas et al., 2017).
",1.1. Standard Approach: Regress and Compare,[0],[0]
"The same approach is also generally taken in the contextual multi-arm bandit problem (Li et al., 2010), which is similar to our problem with the differences that we consider an offline learning problem and that bandit arm pulls are controlled interventions (a bandit problem is essentially a dynamic RCT) so the treated subpopulations are always statistically equivalent.",1.1. Standard Approach: Regress and Compare,[0],[0]
"The standard solution is to fit m regression functions, and, for a new instance, predict m outcomes and pick the smallest prediction subject to cleverly ensuring sufficient exploration by, e.g., adding confidence bounds that vanish with n.",1.1. Standard Approach: Regress and Compare,[0],[0]
"The regression, assumed linear, is done using ridge regression as in Li et al. (2010) (LinUCB), ordinary least squares (OLS) as in Goldenshluger & Zeevi (2013), or LASSO as in Bastani & Bayati (2016).
",1.1. Standard Approach: Regress and Compare,[0],[0]
"The regress and compare (R&C) approach to personalization from observational data can be summarized as:
1.",1.1. Standard Approach: Regress and Compare,[0],[0]
For each t ∈,1.1. Standard Approach: Regress and Compare,[0],[0]
"[m]: (a) Consider the t-treated subsample St,nt = {(Xi, Yi)",1.1. Standard Approach: Regress and Compare,[0],[0]
":
i ∈",1.1. Standard Approach: Regress and Compare,[0],[0]
"[n], Ti = t} of size nt = ∑n i=1",1.1. Standard Approach: Regress and Compare,[0],[0]
I,1.1. Standard Approach: Regress and Compare,[0],[0]
"[Ti = t].
(b) Fit a regression model µ̂t,nt(x) of the response Y to regressors X using training data St,nt , e.g., by OLS.",1.1. Standard Approach: Regress and Compare,[0],[0]
"1
1Note that separate OLS on each subsample St,nt is equivalent to OLS on the whole sample if we include interaction terms with dummy variables",1.1. Standard Approach: Regress and Compare,[0],[0]
I [Ti = t].,1.1. Standard Approach: Regress and Compare,[0],[0]
"At the same time, OLS on the whole sample without interaction terms provides no personalization, i.e., τ̂R&Cn (x) is constant.",1.1. Standard Approach: Regress and Compare,[0],[0]
"Similarly, separate nonparametric regressions on each subsample is equivalent to using the whole sample and endowing the T variable with a discrete topology.
",1.1. Standard Approach: Regress and Compare,[0],[0]
2.,1.1. Standard Approach: Regress and Compare,[0],[0]
"Personalize by choosing the best predicted outcome: τ̂R&Cn (x) = arg mint∈[m] µ̂t,nt(x).
",1.1. Standard Approach: Regress and Compare,[0],[0]
"Under Asn. 1, if our regression estimator is consistent then so is R&C personalization consistent as shown below.",1.1. Standard Approach: Regress and Compare,[0],[0]
"All proofs are given in the supplementary materials.
",1.1. Standard Approach: Regress and Compare,[0],[0]
Theorem 1.,1.1. Standard Approach: Regress and Compare,[0],[0]
"If Asn. 1 holds and µ̂t,nt(x) are pointwise consistent regressions, i.e., µ̂t,nt(X)",1.1. Standard Approach: Regress and Compare,[0],[0]
→ E,1.1. Standard Approach: Regress and Compare,[0],[0]
"[Y | X,T = t] almost surely (a.s.)",1.1. Standard Approach: Regress and Compare,[0],[0]
∀t ∈,1.1. Standard Approach: Regress and Compare,[0],[0]
"[m], then τ̂R&Cn (X) ∈ T ∗(X) eventually a.s.
",1.1. Standard Approach: Regress and Compare,[0],[0]
"Examples of pointwise consistent regression estimators are k-nearest neighbors (kNN) and kernel regression (Walk, 2010).",1.1. Standard Approach: Regress and Compare,[0],[0]
"If a linear model is well-specified, then OLS is also pointwise consistent.",1.1. Standard Approach: Regress and Compare,[0],[0]
"In practice, however, R&C is not effective for personalization because it attempts to learn much more than it needs to, it splits the training data into m, and in training it addresses estimation or prediction risk rather than personalization risk.",1.1. Standard Approach: Regress and Compare,[0],[0]
"In learning heterogeneous causal effects, one is concerned with the case of observational data with two treatments, t = 1 (“Control”) and t = 2 (“Treatment”), and the estimation of the relative conditional average treatment effect (CATE), δ(x) =",1.2. Other Related Problems and Approaches,[0],[0]
E [Y (2)− Y (1) | X = x].,1.2. Other Related Problems and Approaches,[0],[0]
"Under Asn. 1, CATE is the difference between two regression functions: δ(x) =",1.2. Other Related Problems and Approaches,[0],[0]
E,1.2. Other Related Problems and Approaches,[0],[0]
"[Y | X = x, T = 2]−E",1.2. Other Related Problems and Approaches,[0],[0]
"[Y | X = x, T = 1].",1.2. Other Related Problems and Approaches,[0],[0]
And so one way to estimate it is by regressing outcome in each treatment population and taking differences.,1.2. Other Related Problems and Approaches,[0],[0]
"When the conditioning variables in CATE are a proper subset of the covariates needed to satisfy Asn. 1, Abrevaya et al. (2015) propose estimates based on propensity-score weighting and kernel regression.",1.2. Other Related Problems and Approaches,[0],[0]
"Athey & Imbens (2016) develop the Causal Tree (CT), which uses recursive partitioning, as an alternative to differencing two CART regressions.
",1.2. Other Related Problems and Approaches,[0],[0]
"For personalization, learning heterogeneous effects can be used to choose between two treatments by comparing an estimate of their relative CATE to zero.",1.2. Other Related Problems and Approaches,[0],[0]
"As a learning problem, however, this addresses estimation risk rather than personalization risk and deals only with two treatments.",1.2. Other Related Problems and Approaches,[0],[0]
In Sec. 2.6 we propose one-vs-one and one-vs-all strategies for personalization using CATE estimates and show it is consistent.,1.2. Other Related Problems and Approaches,[0],[0]
"We compare to this strategy using CT in our empirical investigation.
",1.2. Other Related Problems and Approaches,[0],[0]
"In learning from logged bandit feedback (Beygelzimer & Langford, 2009; Swaminathan & Joachims, 2015a;b; Kallus, 2017a), one is concerned with learning a good policy for a contextual multi-arm bandit problem based on logged data from another, known policy, rather than online interactions.",1.2. Other Related Problems and Approaches,[0],[0]
This problem differs in that it assumes the data is experimental and the policy that generated the data is known and available.,1.2. Other Related Problems and Approaches,[0],[0]
"In Sec. 2.6, we discuss adapt-
ing these methods using imputed estimated propensities, to which we compare in our empirical investigation.",1.2. Other Related Problems and Approaches,[0],[0]
In this section we present three new algorithms that tackle personalization directly as a single learning task.,2. Recursive Partitioning for Personalization,[0],[0]
We begin by reformulating personalization risk.,2.1. Recasting the Problem,[0],[0]
"Following Hirano & Imbens (2004, Def. 2.1), we define the generalized propensity score (GPS) as Q = φ(T,X), where φ(t, x) = P (T = t | X = x).",2.1. Recasting the Problem,[0],[0]
"The GPS of subject i, Qi, is an unknown quantity given by taking the unknown φ(t, x) and plugging in the known variables Ti, Xi.",2.1. Recasting the Problem,[0],[0]
"Using the GPS we can relate the personalization risk of a personalization model τ to its accuracy as a classification model for labels T , weighted by outcome and GPS.
Theorem 2.",2.1. Recasting the Problem,[0],[0]
"Under Asn. 1,
R(τ) =",2.1. Recasting the Problem,[0],[0]
E,2.1. Recasting the Problem,[0],[0]
[I [T = τ(X)]Y/Q] .,2.1. Recasting the Problem,[0],[0]
"(1)
For m = 2 and randomized data (φ(1, x) = π constant), Zhao et al. (2012) is a special case of Thm. 2.",2.1. Recasting the Problem,[0],[0]
Thm. 2 suggests using a weighted form of empirical classification risk minimization.,2.1. Recasting the Problem,[0],[0]
"When Q is fully known as in the logged bandit setting, this approach is closely related to the approach taken by Beygelzimer & Langford (2009); Swaminathan & Joachims (2015a;b).",2.1. Recasting the Problem,[0],[0]
"In the observational setting, we explore estimating and imputing Q to use this approach in Sec. 2.6.",2.1. Recasting the Problem,[0],[0]
"However, because estimating the GPS generally either relies heavily on model specification or, in nonparametric settings, can be biased and variable, this will lead to severe instability and limited practical use.",2.1. Recasting the Problem,[0],[0]
"Moreover, it does not address the personalization problem as a single learning task, rather as two: learning a propensity model task and then a weighted classification task.",2.1. Recasting the Problem,[0],[0]
"Instead, in the following sections we present a single-task approach that does not rely on estimating propensities separately.",2.1. Recasting the Problem,[0],[0]
Classification and regression trees (CART) are predictive models based on recursive partitioning: the covariate space is recursively partitioned by axis-aligned hyperplanes (x` ≤ θ for ` ∈,2.2. An Impurity Measure for Personalization,[0],[0]
"[d] and θ ∈ R) in order to minimize a within-partition impurity measure (Breiman et al., 1984).",2.2. An Impurity Measure for Personalization,[0],[0]
Impurities for classification include entropy and Gini and for regression include sum of squared errors.,2.2. An Impurity Measure for Personalization,[0],[0]
Athey & Imbens (2016) develop impurities for estimating heterogeneous effects.,2.2. An Impurity Measure for Personalization,[0],[0]
"Motivated by Thm. 2, we develop an impurity for personalization leading to a recursive partitioning algorithm called personalization tree (PT).
",2.2. An Impurity Measure for Personalization,[0],[0]
"Note that for a subset X ⊆ Rd such that X ⊥ T | X ∈ X , we have that φ(t, x) = P",2.2. An Impurity Measure for Personalization,[0],[0]
(T = t | X ∈ X ),2.2. An Impurity Measure for Personalization,[0],[0]
whenever x ∈ X .,2.2. An Impurity Measure for Personalization,[0],[0]
"To develop the personalization impurity, we use this to establish the following as a corollary of Thm.",2.2. An Impurity Measure for Personalization,[0],[0]
"2:
Corollary 3.",2.2. An Impurity Measure for Personalization,[0],[0]
Consider a fixed partition of the covariate space: Rd = X1 ∪ · · · ∪XL where X` ∩X`′ = ∅,2.2. An Impurity Measure for Personalization,[0],[0]
"whenever ` 6= `′. Suppose that the partition is sufficiently fine so that
X ⊥ T | X ∈ X` ∀` = 1, . . .",2.2. An Impurity Measure for Personalization,[0],[0]
", L. (2)
Then, R̂n(τ) = ∑L `=1 R̂n,X`(τ) is an unbiased and consistent estimator for R(τ), where
R̂n,X (τ) = ∑n i=1 I[Xi∈X ]
",2.2. An Impurity Measure for Personalization,[0],[0]
"n
∑n i=1 I[Xi∈X ,Ti=τ(Xi)]Y∑n i′=1",2.2. An Impurity Measure for Personalization,[0],[0]
"I[Xi′∈X ,Ti′=τ(Xi)] .
Note that the conditional independence in the condition (2), which requires that leaf membership be a balancing score as defined by Rosenbaum & Rubin (1983), holds trivially when we condition on X itself.",2.2. An Impurity Measure for Personalization,[0],[0]
"Therefore, the finer the partition X1, . . .",2.2. An Impurity Measure for Personalization,[0],[0]
",XL, the more accurate this assumption.",2.2. An Impurity Measure for Personalization,[0],[0]
(while possibly not truly satisfiable by any finite partition).,2.2. An Impurity Measure for Personalization,[0],[0]
"Given a partition, we can use this risk estimate to optimize τ .",2.2. An Impurity Measure for Personalization,[0],[0]
"Letting S̃` = {(Xi, Ti, Yi) :",2.2. An Impurity Measure for Personalization,[0],[0]
"Xi ∈ X`}, we can rewrite
minτ :Rd→[m] n",2.2. An Impurity Measure for Personalization,[0],[0]
"∑L `=1 R̂n,X`(τ) = ∑L `=1 Ipers(S̃`),
where Ipers is the personalization impurity given by
Ipers({(Xi1 , Ti1 , Yi1), . . .",2.2. An Impurity Measure for Personalization,[0],[0]
", (Xik , Tik , Yik)})
= mint∈[m] k( ∑k",2.2. An Impurity Measure for Personalization,[0],[0]
j=1 I[Tij=t]Yij )∑k,2.2. An Impurity Measure for Personalization,[0],[0]
"j=1 I[Tij=t] ,
Therefore, to achieve good personalization risk we may wish to seek partitions that have minimal sum of withinpartition personalization impurities as defined by Ipers.",2.2. An Impurity Measure for Personalization,[0],[0]
The PT algorithm attempts to find a fine partition of the data to minimize the sum of within-partition personalization impurities.,2.3. Personalization Tree,[0],[0]
"It does so by partitioning the dataset along axis-aligned cuts, at each stage choosing to cut a partition into the two partitions with least sum of impurities and proceeding recursively.",2.3. Personalization Tree,[0],[0]
"In an attempt to find a fine partition
that satisfies condition (2), PT continues to recurse until a specified stopping criterion.",2.3. Personalization Tree,[0],[0]
"One criterion is that there be at least nmin-leaf ≥ 1 subjects of each treatment in the partition.2 Another criterion may be a maximum recursion depth ∆max, but this criterion is not necessary.",2.3. Personalization Tree,[0],[0]
We also allow for a limited number #features of features to be sampled as candidate cut dimensions.,2.3. Personalization Tree,[0],[0]
We summarize the PT recursive subroutine as Alg. 1.,2.3. Personalization Tree,[0],[0]
The PT algorithm is given by passing the whole dataset Sn and initial depth ∆ = 0 to Alg. 1.,2.3. Personalization Tree,[0],[0]
The PT algorithm is notable for producing an interpretable decision tree for the personalization rule (Fig. 1).,2.3. Personalization Tree,[0],[0]
"The finer the partition produced by PT,",2.4. Personalization Forest,[0],[0]
the closer we are to condition (2) and the less bias the estimate of risk has.,2.4. Personalization Forest,[0],[0]
"The coarser the partition, the less variance the estimate has.",2.4. Personalization Forest,[0],[0]
"Therefore, there is an inherent trade-off to the fineness parameters in PT.",2.4. Personalization Forest,[0],[0]
"To address this we can bag (bootstrap aggregate) many very fine PTs, which will have the effect of reducing variance without incurring too much bias as in the case of random forests (Breiman, 2001).",2.4. Personalization Forest,[0],[0]
The corresponding personalization forest (PF) algorithm is summarized in Alg. 2.,2.4. Personalization Forest,[0],[0]
"Generally, we set #features to √ d to achieve sufficient independence between trees for variance reduction.",2.4. Personalization Forest,[0],[0]
PT is a greedy algorithm for minimizing personalization impurity.,2.5. Optimal Personalization Tree,[0],[0]
"In this section we propose the optimal personalization tree (OPT) algorithm, which solves the global problem of finding partitions that minimize the sum of withinpartition personalization impurities:
min X1∪···∪XL=Rd:(∗) L∑̀",2.5. Optimal Personalization Tree,[0],[0]
"=1 Ipers({(Xi, Ti, Yi) :",2.5. Optimal Personalization Tree,[0],[0]
"Xi ∈ X`}), (3)
where (∗) is the restriction that X1, . . .",2.5. Optimal Personalization Tree,[0],[0]
",XL be disjoint regions defined by the leaves of a binary decision tree.",2.5. Optimal Personalization Tree,[0],[0]
"In the case of classification and regression, Bennett & Blue (1996); Bertsimas & Dunn (2016) attempt to find globally optimal prediction trees (while the problem is NP-hard; see Hyafil & Rivest, 1976).",2.5. Optimal Personalization Tree,[0],[0]
"For our personalization problem, motivated by Bertsimas & Dunn (2016), we propose a mixed-integer programming (MIP) approach to the optimal personalization tree problem (3).
",2.5. Optimal Personalization Tree,[0],[0]
"We consider a fixed binary tree structure on nodes 1, . . .",2.5. Optimal Personalization Tree,[0],[0]
", P .",2.5. Optimal Personalization Tree,[0],[0]
Let,2.5. Optimal Personalization Tree,[0],[0]
Ap ⊂,2.5. Optimal Personalization Tree,[0],[0]
"[P ] be the unique path from the root to node p, i.e., its ancestors.",2.5. Optimal Personalization Tree,[0],[0]
"For q ∈ Ap, let Rpq = 1 if the right branch is taken to reach p from q, otherwise −1.",2.5. Optimal Personalization Tree,[0],[0]
Let L = {p ∈,2.5. Optimal Personalization Tree,[0],[0]
[P ] : p /∈ A(q) ∀q ∈,2.5. Optimal Personalization Tree,[0],[0]
"[P ]} be the set of
2Note that Ipers(X ) is only defined when there is at least 1 subject for each treatment in the partition X .",2.5. Optimal Personalization Tree,[0],[0]
"An alternative appropriate for scarce data and large m allows for any number of subjects but chooses the best treatment only from among those with at least nmin-leaf subjects in the partition.
",2.5. Optimal Personalization Tree,[0],[0]
"Algorithm 1 PT subroutine input: Data part S̃ = { (Xi1 , Ti1 , Yi1 ), . . .",2.5. Optimal Personalization Tree,[0],[0]
", (Xik , Tik , Yik ) } , cur-
rent depth ∆, tuning parameters nmin-leaf,∆max,#features.",2.5. Optimal Personalization Tree,[0],[0]
1: for ` ∈,2.5. Optimal Personalization Tree,[0],[0]
"[d] do sort the data along x`: Xiπ(`,1),` ≤ · · · ≤ Xiπ(`,k),`.",2.5. Optimal Personalization Tree,[0],[0]
"2: Set τ̂S̃(x) = arg mint∈[m] ∑k j=1 I[Tij = t]Yij / ∑k j=1 I[Tij = t].
",2.5. Optimal Personalization Tree,[0],[0]
3: if ∆ < ∆max and mint∈[m] ∑k j=1 I[Tij = t] >,2.5. Optimal Personalization Tree,[0],[0]
nmin-leaf then 4: Set I?,2.5. Optimal Personalization Tree,[0],[0]
"=∞, `?",2.5. Optimal Personalization Tree,[0],[0]
"= 0, j? = 0. 5: Draw `1, . . .",2.5. Optimal Personalization Tree,[0],[0]
", `#features at random from [d] without replacement.",2.5. Optimal Personalization Tree,[0],[0]
"6: for ` = `1, . . .",2.5. Optimal Personalization Tree,[0],[0]
", `#features do 7: Set kL1 = · · · = k L m = 0, S L 1 = · · · = S L m = 0, k
L = 0. 8:",2.5. Optimal Personalization Tree,[0],[0]
"Set kRt = ∑k j=1 I[Tij = t], S R t = ∑k",2.5. Optimal Personalization Tree,[0],[0]
"j=1 I[Tij = t]Yij , k
R = k. 9: for j ∈",2.5. Optimal Personalization Tree,[0],[0]
"[k − 1] do
10:",2.5. Optimal Personalization Tree,[0],[0]
"Update kL+=1, kR−=1, t = Tiπ(`,j) , k L t+=1, k R t−=1, 11: SLt+=Yiπ(`,j) , S R t−=Yiπ(`,j) .",2.5. Optimal Personalization Tree,[0],[0]
12: Set I = kL mint∈[m] S L t/k L t + k R mint∈[m] S R t /k,2.5. Optimal Personalization Tree,[0],[0]
"R t , 13:",2.5. Optimal Personalization Tree,[0],[0]
"kmin = mint∈[m] min(k L t , k R t ).",2.5. Optimal Personalization Tree,[0],[0]
14: if I < I?,2.5. Optimal Personalization Tree,[0],[0]
and kmin ≥ nmin-leaf then set I? =,2.5. Optimal Personalization Tree,[0],[0]
"I , `? =",2.5. Optimal Personalization Tree,[0],[0]
"`, j? = j. 15: end for 16: end for 17: if I?",2.5. Optimal Personalization Tree,[0],[0]
"<∞ then 18: Set S̃L = {(Xiπ(`?,j) , Tiπ(`?,j) , Yiπ(`?,j) ) : 1 ≤ j ≤ j
?}, 19: S̃R = {(Xiπ(`?,j) , Tiπ(`?,j) , Yiπ(`?,j) )",2.5. Optimal Personalization Tree,[0],[0]
": j
?+1 ≤ j ≤ k}, 20: τ̂S̃L = Alg. 1(S̃ L, ∆ + 1), τ̂S̃R = Alg.",2.5. Optimal Personalization Tree,[0],[0]
"1(S̃ R, ∆ + 1), 21: θ? = 12 (Xiπ(`?,j),` +Xiπ(`?,j+1),`), 22: τ̂S̃(x) =",2.5. Optimal Personalization Tree,[0],[0]
(if x`? ≤,2.5. Optimal Personalization Tree,[0],[0]
θ ?,2.5. Optimal Personalization Tree,[0],[0]
then τ̂S̃L (x) else τ̂S̃R (x)).,2.5. Optimal Personalization Tree,[0],[0]
"23: end if 24: end if
output: τ̂S̃(x).
leaf nodes and let LC =",2.5. Optimal Personalization Tree,[0],[0]
[P ]\L be the non-leaf nodes.,2.5. Optimal Personalization Tree,[0],[0]
Let,2.5. Optimal Personalization Tree,[0],[0]
Cp ⊂,2.5. Optimal Personalization Tree,[0],[0]
"[d] × R be the finite set of potential cuts at each non-leaf node p ∈ LC , where (`, θ",2.5. Optimal Personalization Tree,[0],[0]
) ∈,2.5. Optimal Personalization Tree,[0],[0]
Cp denotes that the cut x` ≤ θ is to be considered at node p.,2.5. Optimal Personalization Tree,[0],[0]
(Usually we take θ to be the data midpoints along dimension `.),2.5. Optimal Personalization Tree,[0],[0]
Let Y i = Yi,2.5. Optimal Personalization Tree,[0],[0]
"− minj∈[n] Yj , Y max = maxi Y i, and M = Y max(maxt∈[m]",2.5. Optimal Personalization Tree,[0],[0]
∑n i=1,2.5. Optimal Personalization Tree,[0],[0]
I [Ti = t],2.5. Optimal Personalization Tree,[0],[0]
− |L|nmin-leaf).,2.5. Optimal Personalization Tree,[0],[0]
For a vector γ with index set C ⊂,2.5. Optimal Personalization Tree,[0],[0]
"[d] × R, let χi(γ, C) = ∑ (`,θ)∈C I",2.5. Optimal Personalization Tree,[0],[0]
"[Xi,` ≤ θ] γ`,θ.",2.5. Optimal Personalization Tree,[0],[0]
"For p ∈ LC , let kp = dlog2 |Cp|e and Zp ∈ {0, 1}kp×|Cp| be such that (Zp)ij = 1 if bj/2ic is odd and otherwise 0.",2.5. Optimal Personalization Tree,[0],[0]
"Our MIP formulation of the OPT problem (3) follows:
minimize ∑n
i=1 ∑ p∈L νip subject to (4a)
",2.5. Optimal Personalization Tree,[0],[0]
w ∈,2.5. Optimal Personalization Tree,[0],[0]
"[0, 1][n]×L, λ ∈ {0, 1}L×m, µ ∈ RL+, ν ∈ R",2.5. Optimal Personalization Tree,[0],[0]
[n]×L + (4b) γp ∈,2.5. Optimal Personalization Tree,[0],[0]
"[0, 1]Cp , δp ∈ {0, 1}kp , Zpγp = δp ∀p ∈",2.5. Optimal Personalization Tree,[0],[0]
"LC (4c) wip ≤ 1+Rpq2 −Rpqχi(γq, Cq) ∀i ∈",2.5. Optimal Personalization Tree,[0],[0]
"[n], p ∈ L, q ∈",2.5. Optimal Personalization Tree,[0],[0]
"Ap (4d) wip ≥ 1 + ∑ q∈Ap( 1−Rpq 2 −Rpqχi(γq, Cq))",2.5. Optimal Personalization Tree,[0],[0]
(4e) ∀i ∈,2.5. Optimal Personalization Tree,[0],[0]
"[n], p ∈ L∑",2.5. Optimal Personalization Tree,[0],[0]
"i:Ti=t
wip ≥ nmin-leaf ∀t ∈",2.5. Optimal Personalization Tree,[0],[0]
"[m] (4f) νip ≤ Y maxwip, νip ≤ µp ∀i ∈",2.5. Optimal Personalization Tree,[0],[0]
"[n], p ∈ L (4g) νip ≥ µp − Y max(1− wip) ∀i",2.5. Optimal Personalization Tree,[0],[0]
∈,2.5. Optimal Personalization Tree,[0],[0]
"[n], p ∈ L (4h)∑
t∈[m]",2.5. Optimal Personalization Tree,[0],[0]
λpt = 1 ∀p ∈ L (4i)∑,2.5. Optimal Personalization Tree,[0],[0]
"i:Ti=t
(νip − wipY i) ≤M(1− λpt) ∀p",2.5. Optimal Personalization Tree,[0],[0]
"∈ L, t ∈",2.5. Optimal Personalization Tree,[0],[0]
[m] (4j)∑ i:Ti=t (νip,2.5. Optimal Personalization Tree,[0],[0]
− wipY i) ≥M(λpt − 1) ∀p,2.5. Optimal Personalization Tree,[0],[0]
"∈ L, t ∈",2.5. Optimal Personalization Tree,[0],[0]
"[m] (4k)
Problem (4) is a MIP with |L|m + ∑ p∈LC log2 |Cp| binary variables.",2.5. Optimal Personalization Tree,[0],[0]
"The variables γp encode choice of cut at each node p and constraint (4c) ensures only one is cho-
Algorithm 2 PF input: Data Sn = {(X1, T1, Y1), . . .",2.5. Optimal Personalization Tree,[0],[0]
", (Xn, Tn, Yn)}, tuning parame-
ters T, nmin-leaf, ∆max, #features.",2.5. Optimal Personalization Tree,[0],[0]
1: for j ∈,2.5. Optimal Personalization Tree,[0],[0]
"[T ] do 2: Draw S(j)n = { (Xi1 , Ti1 , Yi1 ), . . .",2.5. Optimal Personalization Tree,[0],[0]
", (Xin , Tin , Yin ) }",2.5. Optimal Personalization Tree,[0],[0]
"at random
from Sn with replacement.",2.5. Optimal Personalization Tree,[0],[0]
3: Set τ̂(j)n = Alg.,2.5. Optimal Personalization Tree,[0],[0]
"1(S (j) n , 0, nmin-leaf, ∆max, #features).",2.5. Optimal Personalization Tree,[0],[0]
4: end for output: τ̂n(x) =,2.5. Optimal Personalization Tree,[0],[0]
"mode{τ̂(1)n (x), . . .",2.5. Optimal Personalization Tree,[0],[0]
", τ̂ (T ) n",2.5. Optimal Personalization Tree,[0],[0]
"(x)}.
",2.5. Optimal Personalization Tree,[0],[0]
"sen (see Yıldız & Vielma, 2013).",2.5. Optimal Personalization Tree,[0],[0]
The variable wip encodes membership of datapoint i to leaf p and constraints (4d4e) enforce that wip is the product of indicators of whether Xi goes in the left or right branch of the ancestor nodes.,2.5. Optimal Personalization Tree,[0],[0]
"Since these constraints are integral (Ahuja et al., 1993)",2.5. Optimal Personalization Tree,[0],[0]
we need not enfoce wip be binary.,2.5. Optimal Personalization Tree,[0],[0]
Constraint (4f) ensures at least nmin-leaf samples per leaf.,2.5. Optimal Personalization Tree,[0],[0]
"The variable µp encodes the mean outcome of the prescribed treatment in leaf p and the variable νip encodes its product with wip, as ensured by constraints (4g-4h).",2.5. Optimal Personalization Tree,[0],[0]
The variable λpt encodes the choice of treatment t in leaf p and constraint (4i) ensures only one is chosen.,2.5. Optimal Personalization Tree,[0],[0]
Constraints (4j-4k) ensure the consistency between the choice of treatment λpt and the mean outcome µp.,2.5. Optimal Personalization Tree,[0],[0]
We summarize the OPT algorithm for a complete binary tree in Alg.,2.5. Optimal Personalization Tree,[0],[0]
3.,2.5. Optimal Personalization Tree,[0],[0]
"We use Gurobi to solve MIP (4) and use PT as a heuristic warm start, randomly splitting leaf nodes at depth less than ∆.",2.5. Optimal Personalization Tree,[0],[0]
"As discussed earlier, methods that estimate CATE, notably CT (Athey & Imbens, 2016), can be used to choose between two treatments by comparing δ(x) =",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
E,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[Y | X = x, T = 2] − E",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[Y | X = x, T = 1] to zero.",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"However, such methods are directed at estimation rather than personalization and only address two treatments.",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"To address the latter, we propose one-vs-all (1vA) and one-vsone (1v1) strategies for personalization.
",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"For 1vA, for each t ∈",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
[m] we learn an estimate δ̂tvAn (x) of δtvA(x) =,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
E,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[Y | X = x, T = t]",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
− E,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[Y | X = x, T 6= t] by applying a base algorithm (e.g., CT) to the modified dataset StvAn = {(Xi, 1 +",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"I [Ti = t] , Yi) :",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
i ∈,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[n]}; then we assign the treatment that does the best compared to the rest: τ̂ 1vAn (x) ∈ arg mint∈[m] δ̂tvA(x).
",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"For 1v1, for each t 6= s we learn an estimate δ̂tvsnt+ns(x) of δ
tvs(x) =",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
E,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[Y | X = x, T = t]",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
− E,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[Y | X = x, T = s] on the modified data subset Stvsnt+ns =",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"{(Xi, 1",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
+ I,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[Ti = t] , Yi) :",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"Ti ∈ {t, s}}; then we either assign the treatment that does the best compared to the worst, τ̂ 1v1-An (x) ∈ arg mint∈[m] mins∈[m] δ̂tvsnt+ns(x), or the one that gets the most votes in one-to-one comparisons, τ̂ 1v1-Bn (x) ∈ arg maxt∈[m] ∑ s 6=t I [ δ̂tvsnt+ns(x) < 0 ] .
",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"Algorithm 3 OPT (complete binary tree) input: Data Sn = {(X1, T1, Y1), . . .",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
", (Xn, Tn, Yn)}, tuning parame-
ters nmin-leaf, ∆, #features, #cuts.",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"1: Set P = 2∆, LC =",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[2∆−1],Ap = { bp/2jc : j ∈",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[∆] } , 2: Rpq = (−1)1+bp/2 ∆−blog2(q)cc. 3: for ` ∈",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[d] do sort the data along x`: Xiπ(`,1),` ≤ · · · ≤ Xiπ(`,k),`.",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"4: for p = 1, . . .",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
", 2∆−1 do 5: DrawFp⊂",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
[d] with |Fp|= #features.,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"Set J ={1, d n−1#cuts e, . . .",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
", n−1}.",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"6: Set Cp = {(`, Xiπ(`,j),` +Xiπ(`,j+1,`) 2 ) : ` ∈ Fp, j ∈ J}.",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"7: end for 8: Find γ, λ that solve problem (4).
output: Personalization model τ̂n(x) that proceeds as follows: Set p = 1.",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
for j ∈,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[∆] do set (`, θ) = inf{c ∈",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"Cp : γp,c = 1}, p = 2p+",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
I,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
[x` > θ].,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
return inf{t ∈,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[m] : λpt = 1}.
",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"We can prove that each of our 1vA and 1v1 proposals are consistent given pointwise consistent estimates of CATE:
Theorem 4.",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
Let Asn. 1 hold.,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"Then:
1.",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
If δ̂tvAn (X) → δtvA(X) a.s.,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
∀t ∈,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"[m], then τ̂ 1vAn (X) ∈ T ∗(X) eventually a.s. 2.",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
If δ̂tvsnt+ns(X) → δ tvs(X) a.s.,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"∀t 6= s, then
τ̂ 1v1-An (X), τ̂ 1v1-B n (X) ∈ T ∗(X) eventually a.s.
",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"Note that 1vA and 1v1 with CT do not inherit trees’ interpretability because the partitions of the 1vX models may not overlap.
",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"POEM and NPOEM (Swaminathan & Joachims, 2015a;b) solve the problem of learning from logged bandit feedback, assuming access to the logging policy that generated the data.",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"To adapt these to personalizing from observational data, we propose to impute the logging policy using estimated GPS, i.e., pretend the data were generated by the policy that assigns t when context is x with probability φ̂n(t, x) where φ̂n is a probabilistic classification model fitted to the data {(Xi, Ti) :",2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
i ∈,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
[n]}.,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
We call these IPOEM and INPOEM.,2.6. Adapting Existing Methods to Personalization Using Observational Data,[0],[0]
"In this section we discuss how one can evaluate and validate personalization policies, such as the ones from the last section.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"Usually, a new policy would be evaluated using a randomized controlled trial, but these can be infeasibly costly.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
We consider how to evaluate a personalization policy using observational data.,3. Submatching for Validating Personalization using Observational Data,[0],[0]
Such a dataset can be a subset removed from the training data either for the purpose of testing or for tuning and selection by (cross-)validation.,3. Submatching for Validating Personalization using Observational Data,[0],[0]
The difficulty in using observational data is that if a policy prescribes any treatment τ(Xi) 6=,3. Submatching for Validating Personalization using Observational Data,[0],[0]
"Ti, then it is not immediately clear how to score this.
",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"For offline evaluation of contextual bandits with experimental data, Li et al. (2011) show that rejection sampling is sufficient.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"A similar solution to evaluation with obser-
vational data is a combined rejection and importance sampling approach suggested by Thm. 2.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"If we had the GPS Qi, we could omit any datapoint where τ(Xi)",3. Submatching for Validating Personalization using Observational Data,[0],[0]
6=,3. Submatching for Validating Personalization using Observational Data,[0],[0]
"Ti while giving score Yi/Qi to each datapoint where the prescription matched the data, τ(Xi) = Ti.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
Per Thm. 2,3. Submatching for Validating Personalization using Observational Data,[0],[0]
"and the law of large numbers, this will provide a consistent estimate for out-of-sample personalization risk.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"However, not only does this throw away many datapoints, but to implement this in practice we would have to estimate the GPS from data.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"Estimating the GPS generally either relies heavily on model specification or, in non-parametric settings, can be biased and variable.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"This may be acceptable for training purposes, as in imputing GPS in IPOEM and INPOEM, as it is already a black box.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"However, for evaluation, a more reliable estimate of risk is desirable for evidence of success.
",3. Submatching for Validating Personalization using Observational Data,[0],[0]
We propose the use of submatching for evaluation.,3. Submatching for Validating Personalization using Observational Data,[0],[0]
"Matching is a common tool for causal inference (Rosenbaum, 1989; Abadie & Imbens, 2006) where every subject is matched to a subject that received the opposite treatment, creating a complete matched dataset.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"In submatching, we instead seek only a subset of the data that is well-matched.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"In this subset, each subject is matched based on a metric ‖x− x′‖ to m− 1 subjects that received each of the treatments the subject did not.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
Their outcome is imputed as the counterfactual outcome of those treatments for the subject.,3. Submatching for Validating Personalization using Observational Data,[0],[0]
All matched subjects are not used for training in order to avoid in-sample bias.,3. Submatching for Validating Personalization using Observational Data,[0],[0]
"Usually, Mahalanobis distance is used: ((x− x′)Σ̂−1(x− x′))1/2 where Σ̂ is the sample covariance.",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"(Note that due to personalization on X , matching on propensity scores alone would be insufficient.)",3. Submatching for Validating Personalization using Observational Data,[0],[0]
"The simplest way to extract a matched subset of size ntest from Sn is to do so greedily: draw random i1, . . .",3.1. Greedy Submatching,[0],[0]
", intest from [n] without replacement, for each j ∈",3.1. Greedy Submatching,[0],[0]
[ntest] and t ∈,3.1. Greedy Submatching,[0],[0]
"[m], if t = Tij then set Ŷijt = Yij and if t 6=",3.1. Greedy Submatching,[0],[0]
"Tij then find i ∈ arg mini∈[n]:Ti=t ‖Xi −Xij‖ (with replacement), let Ŷijt = Yi and flag subject",3.1. Greedy Submatching,[0],[0]
"i, and finally remove all drawn and flagged subjects from training data.",3.1. Greedy Submatching,[0],[0]
The imputed value for the unknown Yij (t) is Ŷijt and our estimate for personalization risk of τ(x) is R̂(τ) = 1ntest ∑ntest j=1 Ŷijτ(Xij ).,3.1. Greedy Submatching,[0],[0]
"When matching is exact, i.e. Xi = Xij for all matches, this estimate is unbiased.
",3.1. Greedy Submatching,[0],[0]
Theorem 5.,3.1. Greedy Submatching,[0],[0]
"Under Asn. 1 and exact matching, E[R̂(τ)]=R(τ).",3.1. Greedy Submatching,[0],[0]
"The greedy method for constructing a matched dataset is simple but it can be wasteful, limiting the amount of the data available for training.",3.2. Optimal Submatching,[0],[0]
"We may be able to do better for testing and evaluation when m = 2, when the problem
reduces to average treatment effect estimation.",3.2. Optimal Submatching,[0],[0]
Consider the problem of finding the subset of the data with the closest matches.,3.2. Optimal Submatching,[0],[0]
"That is, finding i11, i12, . .",3.2. Optimal Submatching,[0],[0]
.,3.2. Optimal Submatching,[0],[0]
", inpair1, inpair2 with Tijt = t and minimal ∑npair j=1",3.2. Optimal Submatching,[0],[0]
"‖Xij1 −Xij2‖, and using the pairs for imputations.3",3.2. Optimal Submatching,[0],[0]
"This problem can be reduced to bipartite matching, which can be solved efficiently (Hopcroft & Karp, 1973).",3.2. Optimal Submatching,[0],[0]
Consider the complete bipartite graph with left nodes being subjects with Ti = 1 and right nodes being subjects with Ti = 2 along with n−npair dummy nodes.,3.2. Optimal Submatching,[0],[0]
Put weight ‖Xi−Xj‖ on edges between datapoints and weight 0 on edges to dummy nodes.,3.2. Optimal Submatching,[0],[0]
The subset of the data with the closest matches is given by the nodes incident to edges not incident to dummy nodes in the least-weight bipartite match.,3.2. Optimal Submatching,[0],[0]
"We extract these to construct a well-matched, economical test set with ntest = 2npair.",3.2. Optimal Submatching,[0],[0]
"Although this test set may be biased relative to the whole population (e.g., it may emphasize areas of treatment overlap), the corresponding risk estimate is unbiased conditioned on the test set, i.e., it corresponds to risk on an alternative population, which is often sufficient for comparison and selection.",3.2. Optimal Submatching,[0],[0]
"In prediction, the coefficient of determination R2 is a unitless quantity bounded by 1 that measures both how well data X predict outcomes Y and how well a predictive model leverages X .",3.3. Coefficient of Personalization,[0],[0]
One way to interpret out-of-sample R2 is as the percent of the way that X and the model go from a no-X-data solution (Y ’s sample average) to perfect foresight (Y ’s realized value).,3.3. Coefficient of Personalization,[0],[0]
"Using this interpretation, we construct two analogous quantities for personalization, the 1st and 2nd coefficients of personalization:
P1(τ) = 1− E[Y (τ(X))]−E[mint∈[m] Y (t)]
mint∈[m] E[Y (t)]−E[mint∈[m] Y (t)] ,
P2(τ)",3.3. Coefficient of Personalization,[0],[0]
"= 1− E[Y (τ(X))]−E[mint∈[m] Y (t)] E[Y (T )]−E[mint∈[m] Y (t)] .
",3.3. Coefficient of Personalization,[0],[0]
"These are also analogous to the coefficient of prescription for conditional stochastic optimization (Bertsimas & Kallus, 2015).",3.3. Coefficient of Personalization,[0],[0]
The first measures the improvement toward perfect (prescient) personalization relative to no personalization at all and the second does relative to current practice or standard of care (whatever determined T in the data).,3.3. Coefficient of Personalization,[0],[0]
"They are unitless, bounded by 1.",3.3. Coefficient of Personalization,[0],[0]
"Using a matched dataset, we can estimate these as:4
P̂1(τ) =",3.3. Coefficient of Personalization,[0],[0]
"1− Σ ntest j=1Ŷijτ(Xij ) −Σntestj=1 mint∈[m] Ŷijt
mint∈[m] Σ ntest j=1Ŷijt−Σ ntest j=1 mint∈[m] Ŷijt
,
P̂2(τ)",3.3. Coefficient of Personalization,[0],[0]
"= 1− Σ ntest j=1Ŷijτ(Xij ) −Σntestj=1 mint∈[m] Ŷijt
Σ ntest j=1Yij−Σ ntest j=1 mint∈[m] Ŷijt
.
3 More efficient estimates may be possible using analogues of Robins & Rotnitzky (1995); Hahn (1998) on the submatched data.
",3.3. Coefficient of Personalization,[0],[0]
4,3.3. Coefficient of Personalization,[0],[0]
This assumes that potential outcomes are conditionally independent given X .,3.3. Coefficient of Personalization,[0],[0]
"Indeed, the conditional copula of potential outcomes has no physical meaning and is unidentifiable.",3.3. Coefficient of Personalization,[0],[0]
We conclude with an empirical investigation of personalization using observational data and our new algorithms.,4. Empirical Investigation,[0],[0]
"According to the International Warfarin Pharmacogenetics Consortium, “warfarin is the most widely used oral anticoagulant agent worldwide” and finding the appropriate dose is both difficult and important “because it can vary by a factor of 10 among patients” and “incorrect doses contribute to a high rate of adverse effects” (Consortium, 2009).",4.1. Personalized Warfarin Dosing,[0],[0]
"Currently, the common practice is to start a new patient at 35 mg/week and slowly adjust the dose (Jaffer & Bragg, 2003).",4.1. Personalized Warfarin Dosing,[0],[0]
"We present an application of our methods to personalizing dosage based on data on 5410 warfarin patients collected by Consortium (2009).
",4.1. Personalized Warfarin Dosing,[0],[0]
"The baseline data collected on each patient include demographic characteristics (sex, ethnicity, age, weight, height, and smoker), reason for treatment (e.g., atrial fibrillation), current medications, co-morbidities (e.g., diabetes), genotype of two polymorphisms in CYP2C9, and genotype of seven single nucleotide polymorphisms (SNPs) in VKORC1.",4.1. Personalized Warfarin Dosing,[0],[0]
"The correct stable therapeutic dose of warfarin, determined by adjustment over a few weeks, is recorded for each patient and segmented into three dose groups: low (≤ 21 mg/week, t = 1), medium (> 21, < 49 mg/week, t = 2), and high (≥ 49 mg/week, t = 3).",4.1. Personalized Warfarin Dosing,[0],[0]
"The dataset was also studied in an online (bandit) setting in (Bastani & Bayati, 2016) where an R&C approach is analyzed.
",4.1. Personalized Warfarin Dosing,[0],[0]
"In our experiment, we let Y (t) be 1 if the dose t is incorrect and otherwise 0.",4.1. Personalized Warfarin Dosing,[0],[0]
"To generate observational data (where dosage is not revealed by experimentation), we consider T chosen based on body mass index (BMI):
P(T = t | X = x) = e (t−2)(xBMI−µBMI)/σBMI
e−(xBMI−µBMI)/σBMI +1+e(xBMI−µBMI)/σBMI ,
where µBMI and σBMI are the sample mean and standard deviation of BMI.",4.1. Personalized Warfarin Dosing,[0],[0]
"As an example, we run the PT algorithm with ∆max = 5 on the whole data, generating the tree shown in Fig. 1.",4.1. Personalized Warfarin Dosing,[0],[0]
(We use ∆max = 5 due to length constraints.),4.1. Personalized Warfarin Dosing,[0],[0]
"It is known that VKORC1 and CYP2C9 genotypes are strongly associated to warfarin dosage requirements (Li et al., 2006).",4.1. Personalized Warfarin Dosing,[0],[0]
"PT is able to learn this relationship and it provides an efficient and interpretable dosing guideline where the effect of these genotypes is clear.
",4.1. Personalized Warfarin Dosing,[0],[0]
"To assess the efficiency of various personalization algorithms, for each n = 100, 200, . . .",4.1. Personalized Warfarin Dosing,[0],[0]
", 2500, we consider 100 replications in which we randomly select n training subjects and ntest = 2500 test subjects (disjoint, without replacement).",4.1. Personalized Warfarin Dosing,[0],[0]
"In each replication, we run 12 personalization algorithms and evaluate their risk on the test set (where full counterfactuals are available).",4.1. Personalized Warfarin Dosing,[0],[0]
"We test standard R&C using four predictive models: OLS, logistic regression, CART (scikit-learn defaults), and kNN (k = b √ nc).",4.1. Personalized Warfarin Dosing,[0],[0]
"We compare these to our three direct personalization methods: PT (nmin-leaf = 20,∆max = ∞,#features = d), PF (T = 500, nmin-leaf = 10,∆max = ∞,#features = √ d), and OPT (nmin-leaf = 20,#features = d,#cuts = 10,∆ = 2 +",4.1. Personalized Warfarin Dosing,[0],[0]
I,4.1. Personalized Warfarin Dosing,[0],[0]
"[n ≥ 300], MIP solve time limited to 1 hour).",4.1. Personalized Warfarin Dosing,[0],[0]
"We also compare to our 1vA strategy using Athey & Imbens (2016)’s CT-A (adaptive) and CT-H (honest with 50-50 split) and to IPOEM and INPOEM (parameters tuned on 25% holdout validation as in Swaminathan & Joachims, 2015a;b) with GPS imputed by cross-validated `1-regularized multinomial regression using R package glmnet.",4.1. Personalized Warfarin Dosing,[0],[0]
"(Due to limited space, we focus on 1vA, which outperformed 1v1.)
",4.1. Personalized Warfarin Dosing,[0],[0]
We plot the average risk over replicates in Fig. 2 (note log scale).,4.1. Personalized Warfarin Dosing,[0],[0]
It is evident that R&C approaches make inefficient use of the available data by splitting it and learning more than is necessary.,4.1. Personalized Warfarin Dosing,[0],[0]
"While eventually reaching low risk (< 0.4), R&C using OLS and logistic regression take
much longer (n = 1300) to get there than our direct methods, which achieve low risk very quickly (n = 200) and near-optimal risk (≤ 0.36) soon after (n = 700).",4.1. Personalized Warfarin Dosing,[0],[0]
"Nonparametric R&C (CART, kNN), IPOEM, and INPOEM converge slowly.",4.1. Personalized Warfarin Dosing,[0],[0]
"1vA with CT-A and CT-H offers competitive performance for moderate n, but fails to achieve near-optimal risk even at n",4.1. Personalized Warfarin Dosing,[0],[0]
= 2500.,4.1. Personalized Warfarin Dosing,[0],[0]
"CT-A offers a small edge over CT-H, which can be attributed to CT-H’s splitting of the training data – indeed, CT-H’s primary advantage are correctly sized confidence intervals, which are not used.
",4.1. Personalized Warfarin Dosing,[0],[0]
"Among our direct methods, PF appears to work the best overall, for both small and large n, while PT achieve similar performance for n ≥ 2000.",4.1. Personalized Warfarin Dosing,[0],[0]
"For smaller n, OPT outperforms PT (and PF for n = 100) attributed to OPT’s ability to find the best simple tree to fit the scarce data.",4.1. Personalized Warfarin Dosing,[0],[0]
"For larger n, the MIP becomes so large that Gurobi is hardly able to improve the PT warm start, which has very limited depth.",4.1. Personalized Warfarin Dosing,[0],[0]
"Therefore, we see performance deteriorate.",4.1. Personalized Warfarin Dosing,[0],[0]
"We conclude OPT is best either for small datasets or for finding models that are reasonably efficient while being exceedingly simple and interpretable (depth 2–3 compared to depth 9–13 for PT at n = 2500), albeit at computational cost.",4.1. Personalized Warfarin Dosing,[0],[0]
"Our best out-of-sample risk is 0.356, which translates to P̂1 = 0.22, P̂2 = 0.47: i.e., 22% (or, 47%) of the way from no personalization (or, standard of care) to perfect personalization.",4.1. Personalized Warfarin Dosing,[0],[0]
We consider an application to personalized recommendations for a job training program.,4.2. Personalized Job Training,[0],[0]
"We use data from the National Supported Work Demonstration (LaLonde, 1986) (combining the experimental sample of 465 subjects with the 2490 PSID controls to create an observational dataset).",4.2. Personalized Job Training,[0],[0]
"The data includes 2935 individuals, 185 of which received a job training program in 1976-77 (Ti = 1).",4.2. Personalized Job Training,[0],[0]
"The data includes information about age, education level, ethnicity, marital status, earnings in years 1974-75, and earnings in 1978.",4.2. Personalized Job Training,[0],[0]
"This data is the standard benchmark in evaluation of causal methodologies for estimating an average treatment effect (Dehejia & Wahba, 2002).",4.2. Personalized Job Training,[0],[0]
"We consider an alternative setting where we give a personalized recommendation as to whether to enroll in the job training program, assuming enrollment costs $2,000.",4.2. Personalized Job Training,[0],[0]
"Therefore, we let Yi equal 1978 earnings less $2,000 if Ti = 1.
",4.2. Personalized Job Training,[0],[0]
"From the 2935, we extract an optimal matched test set of 55 pairs (ntest = 110) perfectly matched in all covariates except for a mean absolute deviation of $12 and $17 in 1974 and 1975 earnings, respectively, within pairs.",4.2. Personalized Job Training,[0],[0]
"On the remaining n = 2825 subjects, we train the same personalization models as above with the following changes: we omit logistic regression (outcomes not binary), use nmin-leaf = 10 for PT and OPT and = 1 for PF, use ∆ = 4 for OPT and let the MIP solve for 24 hours, use logistic regressions to im-
pute GPS for IPOEM and INPOEM, and include the causal forest (CF) extension (Wager & Athey, 2017) of CT as implemented by the R package gradient.forest.
",4.2. Personalized Job Training,[0],[0]
We plot the estimated average personalized net income (after enrollment costs) in Fig. 3.,4.2. Personalized Job Training,[0],[0]
"We see a clear benefit to our methods’ direct targeting of personalization and that, with only two treatments, CF and CT-A provide highly competitive performance.",4.2. Personalized Job Training,[0],[0]
"Average net income of 4200.8 due to PF translates to P̂1 = 0.22, P̂2 = 0.28: i.e., 22% (or, 28%) of the way from no personalization (or, standard of care) to perfect personalization.",4.2. Personalized Job Training,[0],[0]
We developed a new approach to the unique problem of personalization from observational data.,5. Conclusions,[0],[0]
The approach was based on a new formulation of the problem and a new impurity measure for personalization.,5. Conclusions,[0],[0]
"This lead to three recursive-partitioning-based algorithms: the personalization tree that greedily partitions the data to minimize the sum of within-partition personalization impurities, the personalization forest that bagged many personalization trees, and the optimal personalization tree that used a MIP to globally optimize the partitioning problem.",5. Conclusions,[0],[0]
We developed new submatching techniques to evaluate and validate these algorithms as well as ones adapted from existing methods.,5. Conclusions,[0],[0]
And we used these techniques to evaluate all algorithms in two example applications: personalized warfarin dosing and personalized job training.,5. Conclusions,[0],[0]
"In both examples, we demonstrated the benefits of our algorithms in terms of efficacy and interpretability.",5. Conclusions,[0],[0]
"We phrased the success of our personalization techniques in terms of the new coefficients of personalization, which quantify the benefit we achieve from personalization as a percentage of the benefit that impossibly perfect personalization can achieve relative to either no personalization or the standard of care.",5. Conclusions,[0],[0]
"We study the problem of learning to choose from m discrete treatment options (e.g., news item or medical drug) the one with best causal effect for a particular instance (e.g., user or patient) where the training data consists of passive observations of covariates, treatment, and the outcome of the treatment.",abstractText,[0],[0]
"The standard approach to this problem is regress and compare: split the training data by treatment, fit a regression model in each split, and, for a new instance, predict all m outcomes and pick the best.",abstractText,[0],[0]
"By reformulating the problem as a single learning task rather than m separate ones, we propose a new approach based on recursively partitioning the data into regimes where different treatments are optimal.",abstractText,[0],[0]
"We extend this approach to an optimal partitioning approach that finds a globally optimal partition, achieving a compact, interpretable, and impactful personalization model.",abstractText,[0],[0]
We develop new tools for validating and evaluating personalization models on observational data and use these to demonstrate the power of our novel approaches in a personalized medicine and a job training application.,abstractText,[0],[0]
Recursive Partitioning for Personalization using Observational Data,title,[0],[0]
"Imperfect-information extensive-form games model strategic multi-step scenarios between agents with hidden information, such as auctions, security interactions (both physical and virtual), negotiations, and military situations.",1. Introduction,[0],[0]
"Typically in imperfect-information games, one wishes to find a Nash equilibrium, which is a profile of strategies in which no player can improve her outcome by unilaterally changing her strategy.",1. Introduction,[0],[0]
"A linear program can find an exact Nash equilibrium in two-player zero-sum games containing fewer than about 108 nodes (Gilpin & Sandholm, 2007).",1. Introduction,[0],[0]
"For larger games, iterative algorithms are used to converge to a Nash equilibrium.",1. Introduction,[0],[0]
"There are a number of such iterative algorithms (Heinrich et al., 2015; Nesterov, 2005; Hoda et al., 2010; Pays, 2014; Kroer et al., 2015), the most popular of which is Counterfactual Regret Minimization (CFR) (Zinkevich et al., 2007).",1. Introduction,[0],[0]
CFR minimizes regret independently at each decision point in the game.,1. Introduction,[0],[0]
"CFR+, a variant of CFR,
1Computer Science Department, Carnegie Mellon University, Pittsburgh, PA, USA.",1. Introduction,[0],[0]
"Correspondence to: Noam Brown <noamb@cs.cmu.edu>, Tuomas Sandholm <sandholm@cs.cmu.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"was used to essentially solve Limit Texas Hold’em, the largest imperfect-information game ever to be essentially solved (Bowling et al., 2015).
",1. Introduction,[0],[0]
Both computation time and storage space are difficult challenges when solving large imperfect-information games.,1. Introduction,[0],[0]
"For example, solving Limit Texas Hold’em required nearly 8 million core hours and a complex, domain-specific streaming compression algorithm to store the 262 TiB of uncompressed data in only 10.9 TiB. This data had to be repeatedly decompressed from disk into memory and then compressed back to disk in order to run CFR+ (Tammelin et al., 2015).
",1. Introduction,[0],[0]
"In certain situations, pruning can be applied to speed up the traversal of the game tree in iterative algorithms (Lanctot et al., 2009; Brown & Sandholm, 2015a; Brown et al., 2017).",1. Introduction,[0],[0]
"However, these past pruning techniques do not reduce the space needed to solve a game and lack theoretical guarantees for improved performance.
",1. Introduction,[0],[0]
"In this paper we introduce Best-Response Pruning (BRP)1, a new form of pruning for iterative algorithms such as CFR in large imperfect-information games.",1. Introduction,[0],[0]
"BRP leverages the fact that in iterative algorithms we are typically interested in performance against the opponent’s average strategy over all iterations, and that the opponent’s average strategy cannot change faster than a rate of 1t , where t is the number of iterations conducted so far.",1. Introduction,[0],[0]
"Thus, if part-way through a run one of our actions has done very poorly relative to other available actions against the opponent’s average strategy, then after just a few more iterations the opponent’s average strategy cannot change sufficiently for the poorly-performing action to now be doing well against the opponent’s updated average strategy.",1. Introduction,[0],[0]
"In fact, we can bound how much an action’s performance can improve over any number of iterations against the opponent’s average strategy.",1. Introduction,[0],[0]
"So long as the upper bound on that performance is still not competitive with the other actions, then we can safely ignore the poorly-performing action.
",1. Introduction,[0],[0]
BRP provably reduces the computation time needed to solve imperfect-information games.,1. Introduction,[0],[0]
"Additionally, a primary advantage of BRP is that in addition to faster convergence,
1Earlier versions of this paper referred to Best-Response Pruning as Total Regret-Based Pruning (Total RBP)
it also reduces the space needed over time.",1. Introduction,[0],[0]
"Specifically, once pruning begins on a branch, BRP discards the memory allocated on that branch and does not reallocate the memory until pruning ends and the branch cannot immediately be pruned again.",1. Introduction,[0],[0]
"In Section 3.1, we prove that after enough iterations of CFR are completed, space for certain pruned branches will never need to be allocated again.",1. Introduction,[0],[0]
"Specifically, we prove that when using BRP it is asymptotically only necessary to store data for parts of the game that are reached with positive probability in a best response to a Nash equilibrium.",1. Introduction,[0],[0]
"This is extremely advantageous when solving large imperfect-information games, which are often constrained by space and in which the set of best response actions may be orders of magnitude smaller than the size of the game (Schmid et al., 2014).
While BRP still requires enough memory to store the entire game in the early iterations, recent work has shown that these early iterations can be skipped in CFR, and possibly other iterative algorithms, by first solving a low-memory abstraction of the game and then using its solution to warm start CFR in the full game (Brown & Sandholm, 2016).",1. Introduction,[0],[0]
"BRP’s reduction in space is also helpful to the Simultaneous Abstraction and Equilibrium Finding (SAEF) algorithm (Brown & Sandholm, 2015b), which starts CFR with a small abstraction of the game and progressively expands the abstraction while also solving the game.",1. Introduction,[0],[0]
"SAEF’s space requirements increase the longer the algorithm runs, and may eventually exceed the constraints of a system.",1. Introduction,[0],[0]
"BRP can counter this increase in space by eliminating the need to store suboptimal paths of the game tree.
",1. Introduction,[0],[0]
"BRP shares some similarities to the earlier pruning algorithm Regret-Based Pruning, which has shown empirical evidence of improving the performance of CFR.",1. Introduction,[0],[0]
"In contrast, this paper proves that CFR converges faster when using BRP, because suboptimal paths in the game tree will only need to be traversed O ( ln(T ) )",1. Introduction,[0],[0]
times over T iterations.,1. Introduction,[0],[0]
"We also prove that BRP uses asymptotically less space, while Regret-Based Pruning does not reduce the space needed to solve a game.",1. Introduction,[0],[0]
"Moreover, Best-Response Pruning easily generalizes to iterative algorithms beyond CFR such as Fictitious Play (Heinrich et al., 2015).
",1. Introduction,[0],[0]
The magnitude of the gains in speed and space that BRP provides varies depending on the game.,1. Introduction,[0],[0]
It is possible to construct games where BRP provides no benefit.,1. Introduction,[0],[0]
"However, if there are many suboptimal actions in the game—as is frequently the case in large games—BRP can speed up CFR by multiple orders of magnitude and require orders of magnitude less space.",1. Introduction,[0],[0]
"Our experiments show an order of magnitude space reduction already in medium-sized games, and a reduction factor increase with game size.",1. Introduction,[0],[0]
"In a two-player zero-sum imperfect-information extensiveform game there are two players, P = {1, 2}.",2. Background,[0],[0]
"Let H be the set of all possible histories (nodes) in the game tree, represented as a sequence of actions.",2. Background,[0],[0]
"The actions available in a history is A(h) and the player who acts at that history is P (h) ∈ P ∪ c, where c denotes chance.",2. Background,[0],[0]
Chance plays an action a ∈ A(h) with a fixed probability.,2. Background,[0],[0]
"The history h′ reached after action a in h is a child of h, represented by h · a = h′, while h is the parent of h′. More generally, h′ is an ancestor of h (and h is a descendant of h′), represented by h′ @ h, if there exists a sequence of actions from h′ to h. Z ⊆ H are terminal histories.",2. Background,[0],[0]
"For each player i ∈ P , there is a payoff function ui :",2. Background,[0],[0]
Z → < where u1 = −u2.,2. Background,[0],[0]
"Define ∆i = maxz∈Z ui(z)−minz∈Z ui(z) and ∆ = maxi ∆i.
",2. Background,[0],[0]
Imperfect information is represented by information sets for each player i ∈ P by a partition Ii of h ∈ H : P (h) = i.,2. Background,[0],[0]
"For any information set I ∈ Ii, all histories h, h′ ∈",2. Background,[0],[0]
I are indistinguishable to player,2. Background,[0],[0]
"i, so A(h) = A(h′).",2. Background,[0],[0]
I(h) is the information set I where h ∈,2. Background,[0],[0]
I .,2. Background,[0],[0]
P (I) is the player i such,2. Background,[0],[0]
that I ∈ Ii.,2. Background,[0],[0]
A(I) is the set of actions such that for all h ∈,2. Background,[0],[0]
"I , A(I) = A(h).",2. Background,[0],[0]
|Ai| = maxI∈Ii |A(I)|,2. Background,[0],[0]
and |A| = maxi |Ai|.,2. Background,[0],[0]
"Define U(I) to be the maximum payoff reachable from a history in I , and L(I) to be the minimum.",2. Background,[0],[0]
"That is, U(I) = maxz∈Z,h∈I:hvz uP (I)(z) and L(I) = minz∈Z,h∈I:hvz uP (I)(z).",2. Background,[0],[0]
Define ∆(I) = U(I),2. Background,[0],[0]
− L(I) to be the range of payoffs reachable from a history in I .,2. Background,[0],[0]
"Similarly U(I, a), L(I, a), and ∆(I, a) are the maximum, minimum, and range of payoffs (respectively) reachable from a history in I after taking action a. Define D(I, a) to be the set of information sets reachable by player P (I) after taking action",2. Background,[0],[0]
"a. Formally, I ′",2. Background,[0],[0]
"∈ D(I, a) if for some history h ∈",2. Background,[0],[0]
I and h′ ∈,2. Background,[0],[0]
"I ′, h · a v h′ and P (I) = P (I ′).
",2. Background,[0],[0]
A strategy σi(I) is a probability vector over A(I) for player i in information set I .,2. Background,[0],[0]
"The probability of a particular action a is denoted by σi(I, a).",2. Background,[0],[0]
"Since all histories in an information set belonging to player i are indistinguishable, the strategies in each of them must be identical.",2. Background,[0],[0]
"That is, for all h ∈ I , σi(h) = σi(I) and σi(h, a) = σi(I, a).",2. Background,[0],[0]
Define σi to be a probability vector for player i over all available strategies Σi in the game.,2. Background,[0],[0]
"A strategy profile σ is a tuple of strategies, one for each player.",2. Background,[0],[0]
"ui(σi, σ−i) is the expected payoff for player i if all players play according to the strategy profile 〈σi, σ−i〉.",2. Background,[0],[0]
"If a series of strategies are played over T iterations, then σ̄Ti = ∑",2. Background,[0],[0]
"t∈T σ t i T . πσ(h) = Πh′→avhσP (h′)(h ′, a) is the joint probability of reaching h if all players play according to σ.",2. Background,[0],[0]
"πσi (h) is the contribution of player i to this probability (that is, the probability of reaching h if all players other than i, and chance, always chose actions leading to h).",2. Background,[0],[0]
"πσ−i(h) is the contribution of all players other than i, and chance.",2. Background,[0],[0]
"πσ(h, h′) is the
probability of reaching h′ given that h has been reached, and 0",2. Background,[0],[0]
if h 6@ h′.,2. Background,[0],[0]
"In a perfect-recall game, ∀h, h′ ∈",2. Background,[0],[0]
"I ∈ Ii, πi(h) = πi(h
′).",2. Background,[0],[0]
In this paper we focus on perfect-recall games.,2. Background,[0],[0]
"Therefore, for i = P (I) define πi(I) = πi(h) for h ∈ I .",2. Background,[0],[0]
"Moreover, I ′ @ I if for some h′ ∈ I ′ and some h ∈ I , h′ @ h. Similarly, I ′ · a @ I if h′ · a @ h.",2. Background,[0],[0]
"The average strategy σ̄Ti (I) for an information set I is defined
as σ̄Ti (I) =",2. Background,[0],[0]
∑ t∈T,2. Background,[0],[0]
"π σti i (I)σ t i(I)∑
",2. Background,[0],[0]
"t∈T π σt i (I)
.
",2. Background,[0],[0]
A best response to σ−i is a strategy σ∗i,2. Background,[0],[0]
"such that ui(σ
∗ i , σ−i) = maxσ′i∈Σi ui(σ ′",2. Background,[0],[0]
"i, σ−i).",2. Background,[0],[0]
"A Nash equilibrium σ∗ is a strategy profile where every player plays a best response: ∀i, ui(σ∗i , σ∗−i) = maxσ′i∈Σi ui(σ ′",2. Background,[0],[0]
"i, σ ∗ −i).",2. Background,[0],[0]
A Nash equilibrium strategy for player i as a strategy σi,2. Background,[0],[0]
that is part of any Nash equilibrium.,2. Background,[0],[0]
"In two-player zero-sum games, if σi and σ−i are both Nash equilibrium strategies, then 〈σi, σ−i〉 is a Nash equilibrium.",2. Background,[0],[0]
"An -equilibrium as a strategy profile σ∗ such that ∀i, ui(σ∗i , σ∗−i) + ≥ maxσ′i∈Σi ui(σ ′",2. Background,[0],[0]
"i, σ ∗ −i).",2. Background,[0],[0]
"Counterfactual Regret Minimization (CFR) is a popular algorithm for extensive-form games in which the strategy vector for each information set is determined according to a regret-minimization algorithm (Zinkevich et al., 2007).",2.1. Counterfactual Regret Minimization,[0],[0]
"We use regret matching (RM) (Hart & Mas-Colell, 2000) as the regret-minimization algorithm, but the material presented in this paper also applies to other regret minimizing algorithms such as Hedge (Brown et al., 2017).
",2.1. Counterfactual Regret Minimization,[0],[0]
The analysis of CFR makes frequent use of counterfactual value.,2.1. Counterfactual Regret Minimization,[0],[0]
"Informally, this is the expected utility of an information set given that player i tries to reach it.",2.1. Counterfactual Regret Minimization,[0],[0]
"For player i at information set I given a strategy profile σ, this is defined as
vσ(I) = ∑ h∈I ( πσ−i(h) ∑ z∈Z ( πσ(h, z)ui(z) ))",2.1. Counterfactual Regret Minimization,[0],[0]
"(1)
The counterfactual value of an action a is vσ(I, a) = ∑ h∈I ( πσ−i(h) ∑ z∈Z ( πσ(h · a, z)ui(z) ))",2.1. Counterfactual Regret Minimization,[0],[0]
"(2)
A counterfactual best response (Moravcik et al., 2016) (CBR) is a strategy similar to a best response, except that it maximizes counterfactual value even at information sets that it does not reach due to its earlier actions.",2.1. Counterfactual Regret Minimization,[0],[0]
"Specifically, a counterfactual best response to σ−i is a strategy CBR(σ−i) such that if CBR(σ−i)(I, a) > 0",2.1. Counterfactual Regret Minimization,[0],[0]
"then v〈CBR(σ−i),σ−i〉(I, a) = maxa′ v
〈CBR(σ−i),σ−i〉(I, a′).",2.1. Counterfactual Regret Minimization,[0],[0]
"The counterfactual best response value CBV σ−i(I) is similar to counterfactual value, except that player i = P (I) plays according to a CBR to σ−i.",2.1. Counterfactual Regret Minimization,[0],[0]
"Formally, CBV σ−i(I) = v〈CBRi(σ−i),σ−i〉(I).
",2.1. Counterfactual Regret Minimization,[0],[0]
Let σt be the strategy profile used on iteration t.,2.1. Counterfactual Regret Minimization,[0],[0]
"The instantaneous regret on iteration t for action a in information set I is rt(I, a) =",2.1. Counterfactual Regret Minimization,[0],[0]
"vσ t
(I, a) − vσt(I) and the regret for action a in I on iteration T is RT (I, a) = ∑ t∈T r
t(I, a).",2.1. Counterfactual Regret Minimization,[0],[0]
"Additionally, RT+(I, a) = max{RT",2.1. Counterfactual Regret Minimization,[0],[0]
"(I, a), 0} and RT (I) =",2.1. Counterfactual Regret Minimization,[0],[0]
"maxa{RT+(I, a)}.",2.1. Counterfactual Regret Minimization,[0],[0]
Regret for player i in the entire game is RTi = maxσ′i∈Σi ∑ t∈T,2.1. Counterfactual Regret Minimization,[0],[0]
( ui(σ ′,2.1. Counterfactual Regret Minimization,[0],[0]
"i, σ t −i)− ui(σti , σt−i) ) .
",2.1. Counterfactual Regret Minimization,[0],[0]
"In regret matching, a player picks a distribution over actions in an information set in proportion to the positive regret on those actions.",2.1. Counterfactual Regret Minimization,[0],[0]
"Formally, on each iteration T + 1, player i selects actions a ∈ A(I) according to probabilities
σT+1(I, a) =  ",2.1. Counterfactual Regret Minimization,[0],[0]
"RT+(I,a)∑ a′∈A(I) R T",2.1. Counterfactual Regret Minimization,[0],[0]
"+(I,a ′) , if ∑ a′ R T +(I, a ′) > 0
1 |A(I)| , otherwise
(3)",2.1. Counterfactual Regret Minimization,[0],[0]
"If a player plays according to RM on every iteration then on iteration T , RT (I) ≤ ∆(I) √ |A(I)| √ T .
",2.1. Counterfactual Regret Minimization,[0],[0]
If a player plays according to CFR in every iteration then RTi ≤ ∑ I∈Ii R T (I).,2.1. Counterfactual Regret Minimization,[0],[0]
"So, as T → ∞, R T",2.1. Counterfactual Regret Minimization,[0],[0]
"i
T → 0.",2.1. Counterfactual Regret Minimization,[0],[0]
"In two-player zero-sum games, if both players’ average regret R T i
T ≤ , their average strategies 〈σ̄ T 1 , σ̄ T 2 〉 form a 2 -
equilibrium (Waugh et al., 2009).",2.1. Counterfactual Regret Minimization,[0],[0]
"Thus, CFR constitutes an anytime algorithm for finding an -Nash equilibrium in zero-sum games.",2.1. Counterfactual Regret Minimization,[0],[0]
This section reviews forms of pruning that allow parts of the game tree to be skipped in CFR.,2.2. Prior Approaches to Pruning,[0],[0]
"In vanilla CFR, the entire game tree is traversed separately for each player historyby-history.",2.2. Prior Approaches to Pruning,[0],[0]
"On each traversal, the regret for each action of a history’s information set is updated based on the expected value for that action on that iteration, weighed by the probability of opponents taking actions to reach the history (that is, weighed by πσ t
−i(h)).",2.2. Prior Approaches to Pruning,[0],[0]
"However, if a history h is reached on iteration t in which πσ t
−i(h) = 0, then from (1) and (2) the strategy at h contributes nothing on iteration t to the regret of I(h) (or to the information sets above it).",2.2. Prior Approaches to Pruning,[0],[0]
"Moreover, any history that would be reached beyond h would also contribute nothing to its information set’s regret because πσ t
−i(h ′) = 0 for every history h′ where h @ h′
and P (h′) = P (h).",2.2. Prior Approaches to Pruning,[0],[0]
"Thus, when traversing the game tree for player i, there is no need to traverse beyond any history h when πσ t
−i(h) = 0.",2.2. Prior Approaches to Pruning,[0],[0]
"The benefit of this form of pruning, which we refer to as partial pruning, varies depending on the game, but empirical results show a factor of 30 improvement in some games (Lanctot et al., 2009).
",2.2. Prior Approaches to Pruning,[0],[0]
"While partial pruning allows one to prune paths that an opponent reaches with zero probability, Regret-Based Pruning allows one to also prune paths that the traverser reaches
with zero probability (Brown & Sandholm, 2015a).",2.2. Prior Approaches to Pruning,[0],[0]
"However, this pruning is necessarily temporary.",2.2. Prior Approaches to Pruning,[0],[0]
"Consider an action a ∈ A(I) such that σt(I, a) = 0, and assume that it is known action a will not be played with positive probability until some far-future iteration t′ (in RM, this would be the case ifRt(I, a) 0).",2.2. Prior Approaches to Pruning,[0],[0]
"Since action a is played with zero probability on iteration t, so from (1) the strategy played and reward received following action a (that is, in D(I, a)) will not contribute to the regret for any information set preceding action a on iteration t.",2.2. Prior Approaches to Pruning,[0],[0]
"In fact, what happens in D(I, a) has no bearing on the rest of the game tree until iteration t′ is reached.",2.2. Prior Approaches to Pruning,[0],[0]
"So one could, in theory, “procrastinate” in deciding what happened beyond action a on iteration t, t+1, ..., t′−1 until iteration t′.
However, upon reaching iteration t′, rather than individually making up the t′ − t iterations over D(I, a), one can instead do a single iteration, playing against the average of the opponents’ strategies in the t′",2.2. Prior Approaches to Pruning,[0],[0]
"− t iterations that were missed, and declare that strategy was played on all the t′− t iterations.",2.2. Prior Approaches to Pruning,[0],[0]
This accomplishes the work of the t′−t iterations in a single traversal.,2.2. Prior Approaches to Pruning,[0],[0]
"Moreover, since player i never plays action a with positive probability between iterations t and t′, that means every other player can apply partial pruning on that part of the game tree for iterations t′",2.2. Prior Approaches to Pruning,[0],[0]
"− t, and skip it completely.",2.2. Prior Approaches to Pruning,[0],[0]
"This, in turn, means that player i has free rein to play whatever they want in D(I, a) without affecting the regrets of the other players.",2.2. Prior Approaches to Pruning,[0],[0]
"In light of that, and of the fact that player i gets to decide what is played in D(I, a) after knowing what the other players have played, player i might as well play a strategy that ensures zero regret for all information sets I ′ ∈ D(I, a) in the iterations t to t′. A CBR to the average of the opponent strategies on the t′",2.2. Prior Approaches to Pruning,[0],[0]
"− t iterations would qualify as such a zero-regret strategy.
",2.2. Prior Approaches to Pruning,[0],[0]
"Regret-Based Pruning only allows a player to skip traversing D(I, a) for as long as σt(I, a) = 0.",2.2. Prior Approaches to Pruning,[0],[0]
"Thus, in RM, if Rt0(I, a) < 0, we can prune the game tree beyond action a from iteration t0 until iteration t1 so long as ∑t0 t=1 v σt(I, a) + ∑t1 t=t0+1 πσ t
−i(I)U(I, a) ≤∑t1 t=1 v σt(I).",2.2. Prior Approaches to Pruning,[0],[0]
This section describes the behavior of BRP.,3. Best-Response Pruning,[0],[0]
"In particular we focus on the case where BRP is applied to the most popular family of iterative algorithms, CFR.",3. Best-Response Pruning,[0],[0]
"BRP begins pruning an action in an information set whenever playing perfectly beyond that action against the opponent’s average strategy (that is, playing a CBR) still does worse than what has been achieved in the iterations played so far (that is,∑T t=1 v
σt(I)).",3. Best-Response Pruning,[0],[0]
"Pruning continues for the minimum number of iterations it could take for the opponent’s average strategy to change sufficiently such that the pruning starting condition (that is, playing a CBR beyond the action against the
opponent’s average strategy does worse than what has been achieved in the iterations so far) no longer holds.",3. Best-Response Pruning,[0],[0]
"When pruning ends, BRP calculates a CBR in the pruned branch against the opponent’s average strategy over all iterations played so far, and sets regret in the pruned branch as if that CBR strategy were played on every iteration played in the game so far—even those that were played before pruning began.
",3. Best-Response Pruning,[0],[0]
"While using a CBR works correctly when applying BRP to CFR, it is also sound to choose a strategy that is almost a CBR (formalized later in this section), as long as that strategy ensures ∑ a∈A(I) ( RT+(I, a)
)2 ≤ (∆(I))2|A(I)|T .",3. Best-Response Pruning,[0],[0]
"In practice, this means that the strategy is close to a CBR, and approaches a CBR as T →∞.",3. Best-Response Pruning,[0],[0]
We now present the theory to show that such a near-CBR can be used.,3. Best-Response Pruning,[0],[0]
"However, in practice CFR converges much faster than the theoretical bound, so the potential function is typically far lower than the theoretical bound.",3. Best-Response Pruning,[0],[0]
"Thus, while choosing a near-CBR rather than an exact CBR may allow for slightly longer pruning according to the theory, it may actually result in worse performance.",3. Best-Response Pruning,[0],[0]
"All of the theoretical results presented in this paper, including the improved convergence bound as well as the lower space requirements, still hold if only a CBR is used, and our experiments use a CBR.",3. Best-Response Pruning,[0],[0]
"Nevertheless, clever algorithms for deciding on a near-CBR may lead to even better performance in practice.
",3. Best-Response Pruning,[0],[0]
"We define a strategy β(σ−i, T ) as a T -near counterfactual best response (T -near CBR) to σ−i if for all I belonging to player i
∑ a∈A(I) ( v〈β(σ−i,T ),σ−i〉(I, a)−v〈β(σ−i,T ),σ−i〉(I) )",3. Best-Response Pruning,[0],[0]
2 + ≤,3. Best-Response Pruning,[0],[0]
"x T I T 2 (4) where xTI can be any value in the range 0 ≤ xTI ≤( ∆(I)
)2|A(I)|T .",3. Best-Response Pruning,[0],[0]
"If xTI = 0, then a T -near CBR is always a CBR.",3. Best-Response Pruning,[0],[0]
"The set of strategies that are T -near CBRs to σ−i is represented as Σβ(σ−i, T ).",3. Best-Response Pruning,[0],[0]
"We also define the T -near counterfactual best response value as ψσ−i,T (I, a) = minσ′i∈Σβ(σ−i,T ) v
〈σ′i,σ−i〉(I, a) and ψσ−i,T (I) = minσ′i∈Σβ(σ−i,T ) v 〈σ′i,σ−i〉(I).
",3. Best-Response Pruning,[0],[0]
"When applying BRP to CFR, an action is pruned only if it would still have negative regret had a T -near CBR against the opponent’s average strategy been played on every iteration.",3. Best-Response Pruning,[0],[0]
"Specifically, on iteration T of CFR with RM, if
T ( ψσ̄ T −i,T (I, a) ) ≤",3. Best-Response Pruning,[0],[0]
T∑ t=1,3. Best-Response Pruning,[0],[0]
"vσ t (I) (5)
then D(I, a) can be pruned for
T ′",3. Best-Response Pruning,[0],[0]
"=
∑T t=1",3. Best-Response Pruning,[0],[0]
v,3. Best-Response Pruning,[0],[0]
"σt(I)− ψσ̄ T −i,T (I, a)
U(I, a)− L(I) (6)
iterations.",3. Best-Response Pruning,[0],[0]
"After those T ′ iterations are over, we calculate a T + T ′-near CBR in D(I, a) to the opponent’s average strategy and set regret as if that T + T ′-near CBR had been played on every iteration.",3. Best-Response Pruning,[0],[0]
"Specifically, for each t ≤ T + T ′",3. Best-Response Pruning,[0],[0]
"we set2 vσ t (I, a) = ψσ̄",3. Best-Response Pruning,[0],[0]
"T+T ′ −i ,T+T ′",3. Best-Response Pruning,[0],[0]
"(I, a) so that
RT+T ′",3. Best-Response Pruning,[0],[0]
"(I, a) =",3. Best-Response Pruning,[0],[0]
( T+T ′ ),3. Best-Response Pruning,[0],[0]
( ψσ̄ T+T ′,3. Best-Response Pruning,[0],[0]
−i,3. Best-Response Pruning,[0],[0]
",T+T ′",3. Best-Response Pruning,[0],[0]
"(I, a) )",3. Best-Response Pruning,[0],[0]
− T+T ′∑ t=1 vσ t (I) (7) and for every information set I ′,3. Best-Response Pruning,[0],[0]
"∈ D(I, a) we set vσ t (I ′, a′) = ψσ̄",3. Best-Response Pruning,[0],[0]
"T+T ′ −i ,T+T ′",3. Best-Response Pruning,[0],[0]
"(I ′, a′) and",3. Best-Response Pruning,[0],[0]
vσ t (I ′) = ψσ̄,3. Best-Response Pruning,[0],[0]
"T+T ′ −i ,T+T ′",3. Best-Response Pruning,[0],[0]
(I ′),3. Best-Response Pruning,[0],[0]
"so that
RT+T ′",3. Best-Response Pruning,[0],[0]
"(I ′, a′) =( T + T ′ )",3. Best-Response Pruning,[0],[0]
( ψσ̄ T+T ′,3. Best-Response Pruning,[0],[0]
−i,3. Best-Response Pruning,[0],[0]
",T+T ′",3. Best-Response Pruning,[0],[0]
"(I ′, a′)− ψσ̄",3. Best-Response Pruning,[0],[0]
"T+T ′ −i ,T+T ′",3. Best-Response Pruning,[0],[0]
"(I ′) ) (8)
Theorem 1 proves that if (5) holds for some action, then the action can be pruned for T ′ iterations, where T ′ is defined in (6).",3. Best-Response Pruning,[0],[0]
The same theorem holds if one replaces the T -near counterfactual best response values with exact counterfactual best response values.,3. Best-Response Pruning,[0],[0]
"The proof for Theorem 1 draws from recent work on warm starting CFR using only an average strategy profile (Brown & Sandholm, 2016).",3. Best-Response Pruning,[0],[0]
"Essentially, we warm start regrets in the pruned branch using only the average strategy of the opponent and knowledge of T .
",3. Best-Response Pruning,[0],[0]
Theorem 1.,3. Best-Response Pruning,[0],[0]
"Assume T iterations of CFR with RM have been played in a two-player zero-sum game and assume T ( ψσ̄ T −i,T (I, a) )",3. Best-Response Pruning,[0],[0]
≤ ∑T t=1 v σt(I) where P (I) =,3. Best-Response Pruning,[0],[0]
"i. Let
T ′",3. Best-Response Pruning,[0],[0]
=,3. Best-Response Pruning,[0],[0]
"b ∑T t=1 v
σt (I)−T ( ψ σ̄T−i,T (I,a) )",3. Best-Response Pruning,[0],[0]
"U(I,a)−L(I) c.",3. Best-Response Pruning,[0],[0]
"If both players
play according to CFR with RM for the next T ′ iterations in all information sets I ′′ 6∈ D(I, a) except that σ(I, a) is set to zero and σ(I) is renormalized, then
(T + T ′)",3. Best-Response Pruning,[0],[0]
( ψσ̄ T+T ′,3. Best-Response Pruning,[0],[0]
−i,3. Best-Response Pruning,[0],[0]
",T+T ′",3. Best-Response Pruning,[0],[0]
"(I, a) ) ≤ ∑T+T ′",3. Best-Response Pruning,[0],[0]
t=1 v σt(I).,3. Best-Response Pruning,[0],[0]
"Moreover, if one then sets vσ t (I, a) = ψσ̄",3. Best-Response Pruning,[0],[0]
"T+T ′ −i ,T+T ′",3. Best-Response Pruning,[0],[0]
"(I, a) for each t ≤ T + T ′",3. Best-Response Pruning,[0],[0]
and,3. Best-Response Pruning,[0],[0]
"vσt(I ′, a′) = ψσ̄",3. Best-Response Pruning,[0],[0]
"T+T ′ −i ,T+T ′",3. Best-Response Pruning,[0],[0]
"(I ′, a′) for each I ′ ∈ D(I, a), then after T ′′ additional iterations of CFR with RM, the bound on exploitability of σ̄T+T ′+T ′′ is no worse than having played T + T ′",3. Best-Response Pruning,[0],[0]
"+ T ′′ iterations of CFR with RM without BRP.
",3. Best-Response Pruning,[0],[0]
"In practice, rather than check whether (5) is met for an action on every iteration, one could only check actions that
2In practice, only the sums ∑T t=1 v
σt(I) and either∑T t=1 v σt(I, a) or RT (I, a) are stored.
",3. Best-Response Pruning,[0],[0]
"have very negative regret, and do a check only once every several iterations.",3. Best-Response Pruning,[0],[0]
"This would still be safe and would save some computational cost of the checks, but would lead to less pruning.
",3. Best-Response Pruning,[0],[0]
"Similar to Regret-Based Pruning, the duration of pruning in BRP can be increased by giving up knowledge beforehand of exactly how many iterations can be skipped.",3. Best-Response Pruning,[0],[0]
"From (2) and (1) we see that rT (I, a) ≤ πσt−i(I) ( U(I, a) − L(I) ) .",3. Best-Response Pruning,[0],[0]
"Thus, if πσ t
−i(I) is very low, then (5) would continue to hold for more iterations than (6) guarantees.",3. Best-Response Pruning,[0],[0]
"Specifically, we can prune D(I, a) from iteration t0 until iteration t1 as long as
t0 ( ψσ̄ t0 −i,t0(I, a) )",3. Best-Response Pruning,[0],[0]
"+ t1∑ t=t0+1 πσ t −i(I)U(I, a) ≤ t1∑ t=1",3. Best-Response Pruning,[0],[0]
"vσ t (I)
(9)",3. Best-Response Pruning,[0],[0]
A key advantage of BRP is that setting the new regrets according to (7) and (8) requires no knowledge of what the regrets were before pruning began.,3.1. Best-Response Pruning Requires Less Space,[0],[0]
"Thus, once pruning begins, all the regrets in D(I, a) can be discarded and the space that was allocated to storing the regret can be freed.",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"That space need only be re-allocated once (9) ceases to hold and we cannot immediately begin pruning again (that is, (5) does not hold).",3.1. Best-Response Pruning Requires Less Space,[0],[0]
Theorem 2 proves that for any information set I and action a ∈ A(I),3.1. Best-Response Pruning Requires Less Space,[0],[0]
"that is not part of a best response to a Nash equilibrium, there is an iteration TI,a such that for all T ≥ TI,a, action a in information set I (and its descendants) can be pruned.3 Thus, once this TI,a is reached, it will never be necessary to allocate space for regret in D(I, a) again.",3.1. Best-Response Pruning Requires Less Space,[0],[0]
Theorem 2.,3.1. Best-Response Pruning Requires Less Space,[0],[0]
"In a two-player zero-sum game, if for every opponent Nash equilibrium strategy σ∗−P (I), CBV σ ∗ −P",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"(I)(I, a) < CBV σ ∗ −P",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"(I)(I), then there exists a TI,a and δI,a > 0",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"such that after T ≥ TI,a iterations of CFR, CBV σ̄ T −i(I, a)− ∑T t=1 v σt (I)
T ≤ −δI,a.
While such a constant TI,a exists for any suboptimal action, BRP cannot determine whether or when TI,a is reached.",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"Thus, it is still necessary to check whether (5) is satisfied whenever (9) no longer holds, and to recalculate how much longer D(I, a) can safely be pruned.",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"This requires the algorithm to periodically calculate a best response (or near-best response) in D(I, a).",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"However, this (near-)best response calculation does not require knowledge of regret in D(I, a),
3If CFR converges to a particular Nash equilibrium, then this condition could be broadened to any information set I and action a ∈ A(I)",3.1. Best-Response Pruning Requires Less Space,[0],[0]
that is not a best response to that particular Nash equilibrium.,3.1. Best-Response Pruning Requires Less Space,[0],[0]
"While empirically CFR does appear to always converge to a particular Nash equilibrium, there is no known proof that it always does so.
",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"so it is still never necessary to store regret after iteration TI,a is reached.
",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"While it is possible to discard regrets in D(I, a) without penalty once pruning begins, regret is only half the space requirement of CFR.",3.1. Best-Response Pruning Requires Less Space,[0],[0]
Every information set I also stores a sum of the strategies played ∑T t=1,3.1. Best-Response Pruning Requires Less Space,[0],[0]
( πσ t i (I)σ t(I) ) which is normalized once CFR ends in order to calculate σ̄T,3.1. Best-Response Pruning Requires Less Space,[0],[0]
(I).,3.1. Best-Response Pruning Requires Less Space,[0],[0]
"Fortunately, if action a in information set I is pruned for long enough, then the stored cumulative strategy in D(I, a) can also be discarded at the cost of a small increase in the distance of the final average strategy from a Nash equilibrium.",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"Specifically, if πσ̄ T
i (I, a) ≤ C√T , where C is some constant, then setting σ̄T (I, a) = 0 and renormalizing σ̄T",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"(I), and setting σ̄T (I ′, a′) = 0 for I ′ ∈ D(I, a), can result in at most C|I|∆√
T higher exploitability for the whole strategy
σ̄T .",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"Since CFR only guarantees that σ̄T is a 2|I|∆ √ |A|√
T -
Nash equilibrium anyway, C|I|∆√ T
is only a constant factor of the bound.",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"If an action is pruned from T ′ to T , then∑T t=1 ( πσ t i (I)σ t(I, a) )",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"≤ T ′
T .",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"Thus, if an action is pruned for long enough, then eventually ∑T t=1",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"( πσ t i (I)σ t(I, a) )",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"≤ C√ T for any C, so ∑T t=1",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"( πσ t i (I)σ t(I, a) ) could be set to zero (as well as all descendants of I · a), while suffering at most a constant factor increase in exploitability.",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"As more iterations are played, this penalty will continue to decrease and eventually be negligible.",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"The constant C can be set by the user: a higher C allows the average strategy to be discarded sooner, while a lower C reduces the potential penalty in exploitability.
",3.1. Best-Response Pruning Requires Less Space,[0],[0]
We define IS as the set of information sets that are not guaranteed to be asymptotically pruned by Theorem 2.,3.1. Best-Response Pruning Requires Less Space,[0],[0]
"Specifically, I ∈ IS if I 6∈ D(I ′, a′) for some I ′ and a′ ∈ A(I ′) such that for every opponent Nash equilibrium strategy σ∗−P (I′)",3.1. Best-Response Pruning Requires Less Space,[0],[0]
", CBV σ∗−P (I′)(I ′, a′) < CBV σ ∗ −P",3.1. Best-Response Pruning Requires Less Space,[0],[0]
(I′)(I ′).,3.1. Best-Response Pruning Requires Less Space,[0],[0]
"Theorem 2 implies the following.
",3.1. Best-Response Pruning Requires Less Space,[0],[0]
Corollary 1.,3.1. Best-Response Pruning Requires Less Space,[0],[0]
"In a two-player zero-sum game with some threshold on the average strategy C√
T for C > 0, after
a finite number of iterations CFR with BRP requires only O ( |IS ||A| ) space.
",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"Using a threshold of CT rather than C√ T does not change the theoretical properties of the corollary, and may lead to faster convergence in some situations, but it may also result in a slower reduction in the space used by the algorithm (though the asymptotic space used is identical).",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"In particular, if BRP can be extended to first-order methods that converge to an -Nash equilibrium in O( 1 ) iterations rather than O( 1 2 ) iterations, such as the Excessive Gap Technique (Hoda et al., 2010; Kroer et al., 2017), then a threshold of CT may be more appropriate when those algorithms are used.",3.1. Best-Response Pruning Requires Less Space,[0],[0]
"A threshold of C T may also be preferable when using an algorithm which
empirically converges to an -Nash equilibrium in faster than O( 1 2 ) iterations, such as CFR+ on some games.",3.1. Best-Response Pruning Requires Less Space,[0],[0]
We now prove that BRP in CFR speeds up convergence to an -Nash equilibrium.,3.2. Best-Response Pruning Converges Faster,[0],[0]
Section 3 proved that CFR with BRP converges in the same number of iterations as CFR alone.,3.2. Best-Response Pruning Converges Faster,[0],[0]
"In this section, we prove that BRP allows each iteration to be traversed more quickly.",3.2. Best-Response Pruning Converges Faster,[0],[0]
"Specifically, if an action a ∈ A(I) is not a CBR to a Nash equilibrium, then D(I, a) need only be traversed O(ln(T ))",3.2. Best-Response Pruning Converges Faster,[0],[0]
times over T iterations.,3.2. Best-Response Pruning Converges Faster,[0],[0]
"Intuitively, as both players converge to a Nash equilibrium, actions that are not a counterfactual best response will eventually do worse than actions that are, so those suboptimal actions will accumulate increasing amounts of negative regret.",3.2. Best-Response Pruning Converges Faster,[0],[0]
"This negative regret allows the action to be safely pruned for increasingly longer periods of time.
",3.2. Best-Response Pruning Converges Faster,[0],[0]
"Specifically, let S ⊆ H be the set of histories where h·a ∈ S if h ∈ S and action a is part of some CBR to some Nash equilibrium.",3.2. Best-Response Pruning Converges Faster,[0],[0]
"Formally, S contains ∅ and every history h · a such that h ∈ S and CBV σ ∗ −P",3.2. Best-Response Pruning Converges Faster,[0],[0]
"(I)(I, a) = CBV σ ∗ −P",3.2. Best-Response Pruning Converges Faster,[0],[0]
"(I)(I) for some Nash equilibrium σ∗.
Theorem 3.",3.2. Best-Response Pruning Converges Faster,[0],[0]
"In a two-player zero-sum game, if both players choose strategies according to CFR with BRP, then conducting T iterations requires only O ( |S|T + |H| ln(T ) )",3.2. Best-Response Pruning Converges Faster,[0],[0]
"nodes to be traversed.
",3.2. Best-Response Pruning Converges Faster,[0],[0]
"The definition of S uses properties of the Nash equilibria of the game, and an action a ∈ A(I) not in S is only guaranteed to be pruned by BRP after some TI,a is reached, which also depends on the Nash equilibria of the game.",3.2. Best-Response Pruning Converges Faster,[0],[0]
"Since CFR converges to only an -Nash equilibrium, CFR cannot determine with certainty which nodes are in S or when TI,a is reached.",3.2. Best-Response Pruning Converges Faster,[0],[0]
"Nevertheless, both S and TI,a are fixed properties of the game.",3.2. Best-Response Pruning Converges Faster,[0],[0]
"We compare the convergence speed of BRP to Regret-Based Pruning, to only partial pruning, and to no pruning at all.",4. Experiments,[0],[0]
"We also show that BRP uses less space as as more iterations are conducted, unlike prior pruning algorithms.",4. Experiments,[0],[0]
"The experiments are conducted on Leduc Hold’em (Southey et al., 2005) and Leduc-5 (Brown & Sandholm, 2015a).",4. Experiments,[0],[0]
Leduc Hold’em is a common benchmark in imperfect-information game solving because it is small enough to be solved but still strategically complex.,4. Experiments,[0],[0]
"In Leduc Hold’em, there is a deck consisting of six cards: two each of Jack, Queen, and King.",4. Experiments,[0],[0]
There are two rounds.,4. Experiments,[0],[0]
"In the first round, each player places an ante of 1 chip in the pot and receives a single private card.",4. Experiments,[0],[0]
"A round of betting then takes place with a two-bet maximum, with Player 1 going first.",4. Experiments,[0],[0]
"A public shared card is then dealt face up and another round of betting takes place.
",4. Experiments,[0],[0]
"Again, Player 1 goes first, and there is a two-bet maximum.",4. Experiments,[0],[0]
"If one of the players has a pair with the public card, that players wins.",4. Experiments,[0],[0]
"Otherwise, the player with the higher card wins.",4. Experiments,[0],[0]
"The bet size in the first round is 2 chips, and 4 chips in the second round.",4. Experiments,[0],[0]
Leduc-5 is like Leduc Hold’em but larger: there are 5 bet sizes to choose from.,4. Experiments,[0],[0]
"In the first round a player may bet 0.5, 1, 2, 4, or 8 chips, while in the second round a player may bet 1, 2, 4, 8, or 16 chips.
",4. Experiments,[0],[0]
Nodes touched is a hardware and implementationindependent proxy for time which we use to measure performance of the various algorithms.,4. Experiments,[0],[0]
Overhead costs are counted in nodes touched.,4. Experiments,[0],[0]
"CFR+ is a variant of CFR in which a floor on regret is set at zero and each iteration is weighted linearly in the average strategy (that is, iteration t is weighted by t) rather than each iteration being weighted equally.",4. Experiments,[0],[0]
"Since Regret-Based Pruning can only prune negative-regret actions, Regret-Based Pruning modifies the definition of CFR+ so that regret can be negative, but immediately jumps up to zero as soon as regret increases.",4. Experiments,[0],[0]
BRP does not require this modification.,4. Experiments,[0],[0]
"Still, BRP also modifies the behavior of CFR+ because without pruning, CFR+ would put positive probability on an action as soon as its regret increases, while BRP waits until pruning is over.",4. Experiments,[0],[0]
"This is not, by itself, a problem.",4. Experiments,[0],[0]
"However, CFR+’s linear weighting of the average strategy is only guaranteed to converge to a Nash equilibrium if pruning does not occur.",4. Experiments,[0],[0]
"While both Regret-Based Pruning and BRP do well empirically with CFR+, the convergence is noisy.",4. Experiments,[0],[0]
"This noise can be reduced by using the lowest-exploitability average strategy profile found so far, which we do in the experiments.4 BRP does not do as well empirically with the linear-averaging component of CFR+.",4. Experiments,[0],[0]
"Thus, for BRP we only measure performance using RM+ with CFR, which is the same as CFR+ but without linear averaging.",4. Experiments,[0],[0]
"CFR+ with and without linear averaging has the same theoretical performance as CFR, but CFR+ does better empirically (particularly with linear averaging).
",4. Experiments,[0],[0]
"Figure 1 and Figure 2 show the reduction in space needed to store the average strategy and regrets for BRP—for various values of the constant threshold C, where an action’s probability is set to zero if it is reached with probability less than C√
T in the average strategy, as we explained in
Section 3.1.",4. Experiments,[0],[0]
"In both games, a threshold between 0.01 and 0.1 performed well in both space and number of iterations, with the lower thresholds converging somewhat faster and the higher thresholds reducing space faster.",4. Experiments,[0],[0]
"We also tested thresholds below 0.01, but the speed of convergence was essentially the same as when using 0.01.",4. Experiments,[0],[0]
"In Leduc, all variants resulted in a quick drop-off in space to about half the initial
4Exploitability is no harder to compute than one iteration of CFR or CFR+.",4. Experiments,[0],[0]
"Snapshots are not plotted at every iteration but only after every 10,000,000 nodes touched—except for the first few snapshots.
amount.",4. Experiments,[0],[0]
"In Leduc-5, a threshold of 0.1 resulted in about a factor of 7 reduction for both CFR with RM and CFR with RM+.",4. Experiments,[0],[0]
"This space reduction factor appears to continue to increase.
",4. Experiments,[0],[0]
"Figure 3 and Figure 4 compare the convergence rates of BRP, Regret-Based Pruning, and only partial pruning for CFR with RM, CFR with RM+, and CFR+.",4. Experiments,[0],[0]
"In Leduc, BRP and Regret-Based Pruning perform comparably when added to CFR.",4. Experiments,[0],[0]
"Regret-Based Pruning with CFR+ does significantly better, while BRP with CFR using RM+ sees no improve-
ment over BRP with CFR.",4. Experiments,[0],[0]
"In Leduc-5, which is a far larger game, BRP outperforms Regret-Based Pruning by a factor of 2 when added to CFR.",4. Experiments,[0],[0]
"BRP with CFR using RM+ also performs comparably to Regret-Based Pruning with CFR+, while retaining theoretical guarantees and not suffering from noisy convergence.",4. Experiments,[0],[0]
"We introduced BRP, a new form of pruning that provably reduces both the space needed to solve an imperfectinformation game and the time needed to reach an -Nash equilibrium.",5. Conclusions,[0],[0]
This addresses both of the major bottlenecks in solving large imperfect-information games.,5. Conclusions,[0],[0]
"Experimentally, BRP reduced the space needed to solve a game by a factor of 7, with the reduction factor increasing with game size.",5. Conclusions,[0],[0]
"While the early iterations may still be slow and require the same amount of space as CFR without BRP, these early iterations can be skipped by warm starting CFR with an abstraction of the game (Brown & Sandholm, 2016).",5. Conclusions,[0],[0]
"This paper focused on the theory of BRP when applied to CFR, the most popular algorithm for solving imperfectinformation games.",5. Conclusions,[0],[0]
"However, BRP can also be applied to Fictitious Play (Heinrich et al., 2015) and likely extends to other iterative algorithms as well (Hoda et al., 2010).",5. Conclusions,[0],[0]
This material is based on work supported by the National Science Foundation under grant IIS-1617590 and the ARO under award W911NF-17-1-0082.,6. Acknowledgments,[0],[0]
Iterative algorithms such as Counterfactual Regret Minimization (CFR) are the most popular way to solve large zero-sum imperfect-information games.,abstractText,[0],[0]
"In this paper we introduce Best-Response Pruning (BRP), an improvement to iterative algorithms such as CFR that allows poorly-performing actions to be temporarily pruned.",abstractText,[0],[0]
"We prove that when using CFR in zero-sum games, adding BRP will asymptotically prune any action that is not part of a best response to some Nash equilibrium.",abstractText,[0],[0]
This leads to provably faster convergence and lower space requirements.,abstractText,[0],[0]
"Experiments show that BRP results in a factor of 7 reduction in space, and the reduction factor increases with game size.",abstractText,[0],[0]
Reduced Space and Faster Convergence in Imperfect-Information Games via Pruning,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2799–2804 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2799",text,[0],[0]
"Automatic detection of abusive language is an important task since such language in online space can lead to personal trauma, cyber-bullying, hate crime, and discrimination.",1 Introduction,[0],[0]
"As more and more people freely express their opinions in social media, the amount of textual contents produced every day grows almost exponentially, rendering it difficult to effectively moderate user content.",1 Introduction,[0],[0]
"For this reason, using machine learning and natural language processing (NLP) systems to automatically detect abusive language is useful for many websites or social media services.
",1 Introduction,[0],[0]
"Although many works already tackled on training machine learning models to automatically detect abusive language, recent works have raised concerns about the robustness of those systems.",1 Introduction,[0],[0]
"Hosseini et al. (2017) have shown how to easily cause false predictions with adversarial examples in Google’s API, and Dixon et al. (2017) show that
classifiers can have unfair biases toward certain groups of people.
",1 Introduction,[0],[0]
We focus on the fact that the representations of abusive language learned in only supervised learning setting may not be able to generalize well enough for practical use since they tend to overfit to certain words that are neutral but occur frequently in the training samples.,1 Introduction,[0],[0]
"To such classifiers, sentences like “You are a good woman” are considered “sexist” probably because of the word “woman.”
",1 Introduction,[0],[0]
"This phenomenon, called false positive bias, has been reported by Dixon et al. (2017).",1 Introduction,[0],[0]
"They further defined this model bias as unintended, “a model contains unintended bias if it performs better for comments containing some particular identity terms than for comments containing others.”
",1 Introduction,[0],[0]
Such model bias is important but often unmeasurable in the usual experiment settings since the validation/test sets we use for evaluation are already biased.,1 Introduction,[0],[0]
"For this reason, we tackle the issue of measuring and mitigating unintended bias.",1 Introduction,[0],[0]
"Without achieving certain level of generalization ability, abusive language detection models may not be suitable for real-life situations.
",1 Introduction,[0],[0]
"In this work, we address model biases specific to gender identities (gender bias) existing in abusive language datasets by measuring them with a generated unbiased test set and propose three reduction methods: (1) debiased word embedding, (2) gender swap data augmentation, (3) fine-tuning with a larger corpus.",1 Introduction,[0],[0]
"Moreover, we compare the effects of different pre-trained word embeddings and model architectures on gender bias.",1 Introduction,[0],[0]
"So far, many efforts were put into defining and constructing abusive language datasets from different sources and labeling them through crowd-
sourcing or user moderation (Waseem and Hovy, 2016; Waseem, 2016; Founta et al., 2018; Wulczyn et al., 2017).",2 Related Work,[0],[0]
"Many deep learning approaches have been explored to train a classifier with those datasets to develop an automatic abusive language detection system (Badjatiya et al., 2017; Park and Fung, 2017; Pavlopoulos et al., 2017).",2 Related Work,[0],[0]
"However, these works do not explicitly address any model bias in their models.
",2 Related Work,[0],[0]
"Addressing biases in NLP models/systems have recently started to gain more interest in the research community, not only because fairness in AI is important but also because bias correction can improve the robustness of the models.",2 Related Work,[0],[0]
"Bolukbasi et al. (2016) is one of the first works to point out the gender stereotypes inside word2vec (Mikolov et al., 2013) and propose an algorithm to correct them.",2 Related Work,[0],[0]
Caliskan et al. (2017) also propose a method called Word Embedding Association Test (WEAT) to measure model bias inside word embeddings and finds that many of those pretrained embeddings contain problematic bias toward gender or race.,2 Related Work,[0],[0]
Dixon et al. (2017) is one of the first works that point out existing “unintended” bias in abusive language detection models.,2 Related Work,[0],[0]
"Kiritchenko and Mohammad (2018) compare 219 sentiment analysis systems participating in SemEval competition with their proposed dataset, which can be used for evaluating racial and gender bias of those systems.",2 Related Work,[0],[0]
Zhao et al. (2018) shows the effectiveness of measuring and correcting gender biases in coreference resolution tasks.,2 Related Work,[0],[0]
We later show how we extend a few of these works into ours.,2 Related Work,[0],[0]
"3.1 Sexist Tweets (st)
This dataset consists of tweets with sexist tweets collected from Twitter by searching for tweets that contain common terms pertaining to sexism such as “feminazi.”",3 Datasets,[0],[0]
The tweets were then annotated by experts based on criteria founded in critical race theory.,3 Datasets,[0],[0]
"The original dataset also contained a relatively small number of “racist” label tweets, but we only retain “sexist” samples to focus on gender biases.",3 Datasets,[0],[0]
"Waseem and Hovy (2016); Waseem (2016), the creators of the dataset, describe “sexist” and “racist” languages as specific subsets of abusive language.
",3 Datasets,[0],[0]
"3.2 Abusive Tweets (abt)
Recently, Founta et al. (2018) has published a large scale crowdsourced abusive tweet dataset with 60K tweets.",3 Datasets,[0],[0]
"Their work incrementally and iteratively investigated methods such as boosted sampling and exploratory rounds, to effectively annotate tweets through crowdsourcing.",3 Datasets,[0],[0]
"Through such systematic processes, they identify the most relevant label set in identifying abusive behaviors in Twitter as {None, Spam,Abusive,Hateful} resulting in 11% as ’Abusive,’ 7.5% as ’Hateful’, 22.5% as ’Spam’, and 59% as ’None’.",3 Datasets,[0],[0]
"We transform this dataset for a binary classification problem by concatenating ’None’/’Spam’ together, and ’Abusive’/’Hateful’ together.",3 Datasets,[0],[0]
"Gender bias cannot be measured when evaluated on the original dataset as the test sets will follow the same biased distribution, so normal evaluation set will not suffice.",4.1 Methodology,[0],[0]
"Therefore, we generate a separate unbiased test set for each gender, male and female, using the identity term template method proposed in Dixon et al. (2017).
",4.1 Methodology,[0],[0]
The intuition of this template method is that given a pair of sentences with only the identity terms different (ex.,4.1 Methodology,[0],[0]
"“He is happy” & “She is happy”), the model should be able to generalize well and output same prediction for abusive language.",4.1 Methodology,[0],[0]
This kind of evaluation has also been performed in SemEval 2018:,4.1 Methodology,[0],[0]
"Task 1 Affect In Tweets (Kiritchenko and Mohammad, 2018) to measure the gender and race bias among the competing systems for sentiment/emotion analysis.
",4.1 Methodology,[0],[0]
"Using the released code1 of Dixon et al. (2017), we generated 1,152 samples (576 pairs) by filling the templates with common gender identity pairs (ex. male/female, man/woman, etc.).",4.1 Methodology,[0],[0]
"We created templates (Table 2) that contained both neutral and offensive nouns and adjectives inside the vocabu-
1https://github.com/conversationai/ unintended-ml-bias-analysis
lary (See Table 3) to retain balance in neutral and abusive samples.
",4.1 Methodology,[0],[0]
"For the evaluation metric, we use 1) AUC scores on the original test set (Orig. AUC), 2) AUC scores on the unbiased generated test set (Gen. AUC), and 3) the false positive/negative equality differences proposed in Dixon et al. (2017) which aggregates the difference between the overall false positive/negative rate and gender-specific false positive/negative rate.",4.1 Methodology,[0],[0]
"False Positive Equality Difference (FPED) and False Negative Equality Difference (FNED) are defined as below, where T = {male, female}.
",4.1 Methodology,[0],[0]
"FPED = ∑ t∈T |FPR− FPRt|
FNED = ∑",4.1 Methodology,[0],[0]
"t∈T |FNR− FNRt|
Since the classifiers output probabilities, equal error rate thresholds are used for prediction decision.
",4.1 Methodology,[0],[0]
"While the two AUC scores show the performances of the models in terms of accuracy, the equality difference scores show them in terms of fairness, which we believe is another dimension for evaluating the model’s generalization ability.",4.1 Methodology,[0],[0]
We first measure gender biases in st and abt datasets.,4.2 Experimental Setup,[0],[0]
"We explore three neural models used in previous works on abusive language classification: Convolutional Neural Network (CNN) (Park
and Fung, 2017), Gated Recurrent Unit (GRU) (Cho et al., 2014), and Bidirectional GRU with self-attention (α-GRU) (Pavlopoulos et al., 2017), but with a simpler mechanism used in Felbo et al. (2017).",4.2 Experimental Setup,[0],[0]
Hyperparameters are found using the validation set by finding the best performing ones in terms of original AUC scores.,4.2 Experimental Setup,[0],[0]
"These are the used hyperparameters:
1.",4.2 Experimental Setup,[0],[0]
CNN:,4.2 Experimental Setup,[0],[0]
"Convolution layers with 3 filters with the size of [3,4,5], feature map size=100, Embedding Size=300, Maxpooling, Dropout=0.5
2.",4.2 Experimental Setup,[0],[0]
"GRU: hidden dimension=512, Maximum Sequence Length=100, Embedding Size=300, Dropout=0.3
3.",4.2 Experimental Setup,[0],[0]
"α-GRU: hidden dimension=256 (bidirectional, so 512 in total), Maximum Sequence Length=100, Attention Size=512, Embedding Size=300, Dropout=0.3
We also compare different pre-trained embeddings, word2vec (Mikolov et al., 2013) trained on Google News corpus, FastText (Bojanowski et al., 2017)) trained on Wikipedia corpus, and randomly initialized embeddings (random) to analyze their effects on the biases.",4.2 Experimental Setup,[0],[0]
Experiments were run 10 times and averaged.,4.2 Experimental Setup,[0],[0]
"Tables 4 and 5 show the bias measurement experiment results for st and abt, respectively.",4.3 Results & Discussions,[0],[0]
"As expected, pre-trained embeddings improved task performance.",4.3 Results & Discussions,[0],[0]
"The score on the unbiased generated test set (Gen. ROC) also improved since word embeddings can provide prior knowledge of words.
",4.3 Results & Discussions,[0],[0]
"However, the equality difference scores tended to be larger when pre-trained embeddings were
used, especially in the st dataset.",4.3 Results & Discussions,[0],[0]
This confirms the result of Bolukbasi et al. (2016).,4.3 Results & Discussions,[0],[0]
"In all experiments, direction of the gender bias was towards female identity words.",4.3 Results & Discussions,[0],[0]
"We can infer that this is due to the more frequent appearances of female identities in “sexist” tweets and lack of negative samples, similar to the reports of Dixon et al. (2017).",4.3 Results & Discussions,[0],[0]
"This is problematic since not many NLP datasets are large enough to reflect the true data distribution, more prominent in tasks like abusive language where data collection and annotation are difficult.
",4.3 Results & Discussions,[0],[0]
"On the other hand, abt dataset showed significantly better results on the two equality difference scores, of at most 0.04.",4.3 Results & Discussions,[0],[0]
Performance in the generated test set was better because the models successfully classify abusive samples regardless of the gender identity terms used.,4.3 Results & Discussions,[0],[0]
"Hence, we can assume that abt dataset is less gender-biased than the st dataset, presumably due to its larger size, balance in classes, and systematic collection method.
",4.3 Results & Discussions,[0],[0]
"Interestingly, the architecture of the models also influenced the biases.",4.3 Results & Discussions,[0],[0]
"Models that “attend” to certain words, such as CNN’s max-pooling or αGRU’s self-attention, tended to result in higher false positive equality difference scores in st dataset.",4.3 Results & Discussions,[0],[0]
"These models show effectiveness in catching not only the discriminative features for classification, but also the “unintended” ones causing the model biases.",4.3 Results & Discussions,[0],[0]
We experiment and discuss various methods to reduce gender biases identified in Section 4.3.,5 Reducing Gender Biases,[0],[0]
"Debiased Word Embeddings (DE) (Bolukbasi et al., 2016) proposed an algorithm to correct word embeddings by removing gender stereotypical information.",5.1 Methodology,[0],[0]
All the other experiments used pretrained word2vec to initialized the embedding layer,5.1 Methodology,[0],[0]
"but we substitute the pretrained word2vec with their published embeddings to verify their effectiveness in our task.
",5.1 Methodology,[0],[0]
Gender Swap (GS),5.1 Methodology,[0],[0]
We augment the training data by identifying male entities and swapping them with equivalent female entities and vice-versa.,5.1 Methodology,[0],[0]
"This simple method removes correlation between gender and classification decision and has proven to be effective for correcting gender biases in coreference resolution task (Zhao et al., 2018).
",5.1 Methodology,[0],[0]
Bias fine-tuning (FT) We propose a method to use transfer learning from a less biased corpus to reduce the bias.,5.1 Methodology,[0],[0]
"A model is initially trained with a larger, less-biased source corpus with a same or similar task, and fine-tuned with a target corpus with a larger bias.",5.1 Methodology,[0],[0]
This method is inspired by the fact that model bias mainly rises from the imbalance of labels and the limited size of data samples.,5.1 Methodology,[0],[0]
"Training the model with a larger and less biased dataset may regularize and prevent the model from over-fitting to the small, biased dataset.",5.1 Methodology,[0],[0]
"Debiased word2vec Bolukbasi et al. (2016) is compared with the original word2vec (Mikolov et al., 2013) for evaluation.",5.2 Experimental Setup,[0],[0]
"For gender swapping data augmentation, we use pairs identified through crowd-sourcing by Zhao et al. (2018).
",5.2 Experimental Setup,[0],[0]
"After identifying the degree of gender bias of each dataset, we select a source with less bias and a target with more bias.",5.2 Experimental Setup,[0],[0]
Vocabulary is extracted from training split of both sets.,5.2 Experimental Setup,[0],[0]
The model is first trained by the source dataset.,5.2 Experimental Setup,[0],[0]
We then remove final softmax layer and attach a new one initialized for training the target.,5.2 Experimental Setup,[0],[0]
The target is trained with a slower learning rate.,5.2 Experimental Setup,[0],[0]
"Early stopping is decided by the valid set of the respective dataset.
",5.2 Experimental Setup,[0],[0]
"Based on this criterion and results from Section 4.3, we choose the abt dataset as source and st dataset as target for bias fine-tuning experiments.",5.2 Experimental Setup,[0],[0]
Table 6 shows the results of experiments using the three methods proposed.,5.3 Results & Discussion,[0],[0]
The first rows are the baselines without any method applied.,5.3 Results & Discussion,[0],[0]
"We can see from the second rows of each section that debiased word embeddings alone do not effectively correct the bias of the whole system that well, while gender swapping significantly reduced both the equality difference scores.",5.3 Results & Discussion,[0],[0]
"Meanwhile, fine-tuning bias with a larger, less biased source dataset helped to decrease the equality difference scores and greatly improve the AUC scores from the generated unbiased test set.",5.3 Results & Discussion,[0],[0]
"The latter improvement shows that the model significantly reduced errors on the unbiased set in general.
",5.3 Results & Discussion,[0],[0]
"To our surprise, the most effective method was applying both debiased embedding and gender swap to GRU, which reduced the equality differences by 98% & 89% while losing only 1.5% of the original performance.",5.3 Results & Discussion,[0],[0]
We assume that this may be related to the influence of “attending” model architectures on biases as discussed in Section 4.3.,5.3 Results & Discussion,[0],[0]
"On the other hand, using the three methods together improved both generated unbiased set performance and equality differences, but had the largest decrease in the original performance.
",5.3 Results & Discussion,[0],[0]
All methods involved some performance loss when gender biases were reduced.,5.3 Results & Discussion,[0],[0]
"Especially, fine-tuning had the largest decrease in original test set performance.",5.3 Results & Discussion,[0],[0]
This could be attributed to the difference in the source and target tasks (abusive & sexist).,5.3 Results & Discussion,[0],[0]
"However, the decrease was marginal (less
than 4%), while the drop in bias was significant.",5.3 Results & Discussion,[0],[0]
We assume the performance loss happens because mitigation methods modify the data or the model in a way that sometimes deters the models from discriminating important “unbiased” features.,5.3 Results & Discussion,[0],[0]
"We discussed model biases, especially toward gender identity terms, in abusive language detection.",6 Conclusion & Future Work,[0],[0]
"We found out that pre-trained word embeddings, model architecture, and different datasets all can have influence.",6 Conclusion & Future Work,[0],[0]
"Also, we found our proposed methods can reduce gender biases up to 90-98%, improving the robustness of the models.
",6 Conclusion & Future Work,[0],[0]
"As shown in Section 4.3, some classification performance drop happens when mitigation methods.",6 Conclusion & Future Work,[0],[0]
We believe that a meaningful extension of our work can be developing bias mitigation methods that maintain (or even increase) the classification performance and reduce the bias at the same time.,6 Conclusion & Future Work,[0],[0]
"Some previous works (Beutel et al.; Zhang et al., 2018) employ adversarial training methods to make the classifiers unbiased toward certain variables.",6 Conclusion & Future Work,[0],[0]
"However, those works do not deal with natural language where features like gender and race are latent variables inside the language.",6 Conclusion & Future Work,[0],[0]
"Although those approaches are not directly comparable to our methods, it would be interesting to explore adversarial training to tackle this problem in the future.
",6 Conclusion & Future Work,[0],[0]
"Although our work is preliminary, we hope that our work can further develop the discussion of evaluating NLP systems in different directions, not merely focusing on performance metrics like accuracy or AUC.",6 Conclusion & Future Work,[0],[0]
The idea of improving models by measuring and correcting gender bias is still unfamiliar but we argue that they can be crucial in building systems that are not only ethical but also practical.,6 Conclusion & Future Work,[0],[0]
"Although this work focuses on gender terms, the methods we proposed can easily be extended to other identity problems like racial and to different tasks like sentiment analysis by following similar steps, and we hope to work on this in the future.",6 Conclusion & Future Work,[0],[0]
"This work is partially funded by ITS/319/16FP of Innovation Technology Commission, HKUST, and 16248016 of Hong Kong Research Grants Council.",Acknowledgments,[0],[0]
Abusive language detection models tend to have a problem of being biased toward identity words of a certain group of people because of imbalanced training datasets.,abstractText,[0],[0]
"For example, “You are a good woman” was considered “sexist” when trained on an existing dataset.",abstractText,[0],[0]
Such model bias is an obstacle for models to be robust enough for practical use.,abstractText,[0],[0]
"In this work, we measure gender biases on models trained with different abusive language datasets, while analyzing the effect of different pre-trained word embeddings and model architectures.",abstractText,[0],[0]
"We also experiment with three bias mitigation methods: (1) debiased word embeddings, (2) gender swap data augmentation, and (3) fine-tuning with a larger corpus.",abstractText,[0],[0]
These methods can effectively reduce gender bias by 90-98% and can be extended to correct model bias in other scenarios.,abstractText,[0],[0]
Reducing Gender Bias in Abusive Language Detection,title,[0],[0]
"Proceedings of the SIGDIAL 2017 Conference, pages 115–126, Saarbrücken, Germany, 15-17 August 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
Recent years have seen a growing interest in research on conversational agents.,1 Introduction,[0],[0]
Several strands of dialogue systems have emerged which differ in underlying goals and methods.,1 Introduction,[0],[0]
"Some systems focus on data-driven learning of models which can autonomously hold conversations with humans or one another, potentially even on open domains (Vinyals and Le, 2015; Sordoni et al., 2015; Li
∗Work performed during an internship at Google.
",1 Introduction,[0],[0]
"User: What is Malaria?
",1 Introduction,[0],[0]
"Agent: A disease caused by a plasmodium parasite, transmitted by the bite of infected mosquitoes.
",1 Introduction,[0],[0]
"User: Is it a virus?
",1 Introduction,[0],[0]
Agent: Malaria is a parasitic infection spread by Anopheles mosquitoes.,1 Introduction,[0],[0]
"The Plasmodium parasite that causes Malaria is neither a virus nor a bacterium – it is a single-celled parasite that multiplies in red blood cells of humans as well as in the mosquito intestine.
",1 Introduction,[0],[0]
Figure 1: Informational-dialogue example between a human and a conversational agent.,1 Introduction,[0],[0]
"The second agent utterance is partially redundant (the underlined text).
",1 Introduction,[0],[0]
"et al., 2016).",1 Introduction,[0],[0]
"Other works deal with task-oriented dialogues, which offer natural-language interfaces to real-world services like restaurant booking (Bordes and Weston, 2016; Dhingra et al., 2016; Crook et al., 2016).",1 Introduction,[0],[0]
"We focus in this paper on a third dialogue setting where the goal is to have a natural conversation with a user, during which the user’s information needs are satisfied in an iterative manner.",1 Introduction,[0],[0]
"Such a setting is common in question-answering experiences implemented in personal digital assistants (Sarikaya et al., 2016).
",1 Introduction,[0],[0]
We call this setting informational dialogues.,1 Introduction,[0],[0]
"They start with the user posing a fact-seeking question, e.g., to learn about current events or to explore unknown terms and concepts.",1 Introduction,[0],[0]
"Consider the example dialogue in Fig. 1, which is initiated by the user requesting a definition of a specific disease and which also features a subsequent question on the same topic.",1 Introduction,[0],[0]
Many approaches have been proposed which can produce suitable replies to such questions.,1 Introduction,[0],[0]
"Examples include techniques which find pertinent passages or short text chunks in collections of documents (Hermann et al., 2015; Miller et al., 2016; Trischler et al., 2016) or find rele-
115
vant entries in structured knowledge bases (Bordes et al., 2014, 2015; Yin et al., 2016a,b).",1 Introduction,[0],[0]
"Generation techniques can then be employed to generate well-formed natural-language utterances from the candidate replies (Wen et al., 2015, 2016a,b; Zhou et al., 2016; Dušek and Jurcicek, 2016).",1 Introduction,[0],[0]
"In the dialogue in Fig. 1, both agent replies are coherent wrt.",1 Introduction,[0],[0]
the questions.,1 Introduction,[0],[0]
"However, they sound strange when occurring together in a single dialogue context because information is partially reiterated (see the underlined part in the second agent reply).",1 Introduction,[0],[0]
"It is this very problem that we focus on in this work, i.e., the localization of redundancy in conversation.",1 Introduction,[0],[0]
"Information on the location of non-novel portions of a passage could either be fed back to the retrieval model, so that only text passages with new information would be selected, or alternatively this localized redundancy might be used as input to a summarization model (Rush et al., 2015).
",1 Introduction,[0],[0]
"The specific contributions of this work are as follows:
• We propose a new task, motivated by practical issues that dialogue applications face (Sec. 3).
",1 Introduction,[0],[0]
"• We release a new dataset with manual annotations for this task, which allows to evaluate and compare competing approaches (Sec. 4).
",1 Introduction,[0],[0]
"• Due to the insufficient amount of annotated data for training purposes, we report on a weak supervision signal over a large collection of passages with partially redundant content (Sec. 5).
",1 Introduction,[0],[0]
"• We augment a recently introduced entailment model (Parikh et al., 2016) with means for representing local similarities in passages in a unidirectional way (Sec. 6) and find that this extension outperforms the original model (Sec. 8).
",1 Introduction,[0],[0]
"• Furthermore, we briefly discuss an experiment on real-world dialogue data (Sec. 9), which gives insights on the application-relevance of the proposed task and model.",1 Introduction,[0],[0]
A lot of work has been presented on reasoning with short texts for tasks on similarity and entailment.,2 Related Work,[0],[0]
"Knowledge-rich approaches define lexical and syntactic inference rules over phrase pairs and employ decision algorithms that rely on matches of these rules in input texts (Magnini et al., 2014).",2 Related Work,[0],[0]
"Other approaches generate structured representations of
the input to enable sophisticated alignment of the texts with now available rich lexical, syntactic, and semantic information (Liang et al., 2016).",2 Related Work,[0],[0]
"The use of kernel methods for similarity tasks has also been reported (Filice et al., 2015).",2 Related Work,[0],[0]
"In contrast to these approaches, neither do we use external knowledge nor do we build explicit syntactic representations of input texts.
",2 Related Work,[0],[0]
"Sentence fusion (Barzilay and McKeown, 2005; Filippova and Strube, 2008) is a technique that is related to the overall problem setting of this paper.",2 Related Work,[0],[0]
"This technique is used in the context of abstractive multi-document summarization, where a particular challenge is to identify shared content in a cluster of sentences and to subsequently produce a single sentence that covers all information fragments.",2 Related Work,[0],[0]
"In our work, we focus on a similar but different problem formulation, in which we fix one text fragment and want to find reiterations of its content in other texts.",2 Related Work,[0],[0]
"Furthermore, we focus on identifying and localizing redundancy and leave the generation of low-redundancy text mostly as future work.
",2 Related Work,[0],[0]
"Neural approaches are common for bi-sequence classification problems (Laha and Raykar, 2016).",2 Related Work,[0],[0]
"Yin and Schütze (2015), He et al. (2015), and He and Lin (2016) use convolutional networks to represent input texts on multiple granularity levels and model the interactions of these.",2 Related Work,[0],[0]
"We also aim to find fine-granular interactions in texts, but in addition to their models, we aim to make these interactions explicit rather than latent intermediate results.",2 Related Work,[0],[0]
"Another line of research has proposed recurrent networks for modeling phrases/sentences, including various forms of neural attention (Bowman et al., 2015; Rocktäschel et al., 2015; Zhao et al., 2016).",2 Related Work,[0],[0]
"These approaches come with high computational cost during training and inference, in contrast we rely on cheaper feed-forward connections.",2 Related Work,[0],[0]
"We focus in this work on the problem of redundancy localization in a passage with respect to another text, i.e., we aim to understand when a sub-passage is redundant with what is mentioned in the context.1 Consider the following example with a context passage c and a follow-up passage p with sub-sequences s0–s3, which need to be ranked according to the extent to which their semantics are covered by c.",3 Problem Definition,[0],[0]
"In this case, one may expect the
1Note that the problem definition is not limited to the dialogue scenario used as motivation in the introduction.
order to be (s1, s2, s3, s0):
c :",3 Problem Definition,[0],[0]
"The Allianz Arena is a football stadium in Munich, Bavaria, Germany, with a seating capacity of more than 70,000.
s0 : Bayern to increase stadium capacity.
",3 Problem Definition,[0],[0]
"s1 : Bayern Munich have revealed plans to increase the capacity of Allianz Arena to 75,000,
s2 : which would make it the second largest stadium in Germany.
s3 :",3 Problem Definition,[0],[0]
"The Allianz Arena is currently the third largest stadium in Germany.
",3 Problem Definition,[0],[0]
"More formally, let p be a sequence of n tokens.",3 Problem Definition,[0],[0]
"Let S = {sk}m−1k=0 be a set of m sub-sequences of p such that for integers s0, s1, . . .",3 Problem Definition,[0],[0]
", sm with s0 = 0 <",3 Problem Definition,[0],[0]
s1 < . . .,3 Problem Definition,[0],[0]
<,3 Problem Definition,[0],[0]
"sm−1 < sm = n, each subsequence sk ∈ S is ranging from tokens sk to (sk+1 − 1), inclusive.",3 Problem Definition,[0],[0]
"Given a context sequence c, the task of redundancy localization is to produce a ranking function rank(sk) ∈ {1, . . .",3 Problem Definition,[0],[0]
",m} that induces an ordering of the subsequences sk ∈ S of p which corresponds to the degree of information in sk that is semantically covered by c. Here, a low rank corresponds to a high semantic overlap of a subsequence with c, where segments are allowed to have equal ranks.
",3 Problem Definition,[0],[0]
We formulate this task as a ranking problem instead of a more expressive yet also more complex regression setting in order to pose less restrictions on the collection of data for training and evaluation.,3 Problem Definition,[0],[0]
"The design decision to rank sub-sequences rather than individual tokens is intended to keep manual annotation feasible and cost-effective.
",3 Problem Definition,[0],[0]
Relation to Other Tasks,3 Problem Definition,[0],[0]
"The problem we pose here is related to bi-sequence problems like semantic textual similarity (STS) (Agirre et al., 2016a) and recognizing textual entailment (RTE) (Bowman et al., 2015).",3 Problem Definition,[0],[0]
"In contrast to these tasks, we are not interested in determining the overall relation between sequences, but aim to generate more finegrained sub-passage-level information.",3 Problem Definition,[0],[0]
"The task of interpretable semantic textual similarity (Agirre et al., 2016b) requires systems to provide humanunderstandable explanations for STS ratings of sentence pairs.",3 Problem Definition,[0],[0]
"Chunks from both sentences need to be paired and for each such pairing, similarity and relation type need to be assessed.",3 Problem Definition,[0],[0]
"While this type of annotation is richer than what we propose, it is also harder to produce, likely requiring speciallytrained raters, and would likely be impossible to
predict accurately using a surrogate supervision signal like we rely on.",3 Problem Definition,[0],[0]
"Besides, it does not scale well beyond single sentences, since the number of ratings per sequence pair grows proportionally to the multiple of their lengths, while the model we present can handle longer, multi-sentence passages.",3 Problem Definition,[0],[0]
"The setting proposed in the next section is more restricted, but easier to learn and directly applicable in downstream applications.",3 Problem Definition,[0],[0]
"The evaluation dataset (EVAL) is constructed from pairs of potentially redundant passages from Wikipedia, which were segmented into subpassages and presented to human raters for manual redundancy assessment.",4 A Testbed for Redundancy Localization,[0],[0]
The collection of passages was guided by a need for text pairs with various degrees of semantic overlap; we employed a passage-retrieval system for the purpose of text selection.,4 A Testbed for Redundancy Localization,[0],[0]
"Passage retrieval (Khalid and Verberne, 2008; Aktolga et al., 2011; Xu et al., 2011) is a common intermediate step in information-retrieval and question-answering settings, the goal of which is to return a passage containing the answer to a given query.",4 A Testbed for Redundancy Localization,[0],[0]
"Most systems generate a list of candidate passages, rank them by relevance and return the top one.
",4 A Testbed for Redundancy Localization,[0],[0]
We picked a random set of 1200 fact-seeking questions and retrieved corresponding passages from Wikipedia.,4 A Testbed for Redundancy Localization,[0],[0]
"The questions were then discarded, as they are not relevant to our task.",4 A Testbed for Redundancy Localization,[0],[0]
We selected the top-scoring passage as the context c and paired it with a low-scoring one from further down the result list (p).,4 A Testbed for Redundancy Localization,[0],[0]
"p was then heuristically split into chunks sk, corresponding to verb-governed phrases.",4 A Testbed for Redundancy Localization,[0],[0]
"The example shown in the last section is an instance of such a pair (c, p).
",4 A Testbed for Redundancy Localization,[0],[0]
"We asked three raters per item to select for each segment sk of p one out of three labels: NOTREDUNDANT, PARTIALLYREDUNDANT, and FULLYREDUNDANT, depending on the degree of which the content of a sub-passage is covered by the context c.",4 A Testbed for Redundancy Localization,[0],[0]
"The annotators fully/partially agreed2 on 64%/96% of examples, their annotation has an intra-class correlation of .55.",4 A Testbed for Redundancy Localization,[0],[0]
"We aggregated the rating by mapping the categorical labels to a numeric scale (0, 1, 2) and averaging the scores.",4 A Testbed for Redundancy Localization,[0],[0]
"We used 200 examples as a development
2Full: 3/3 annotators agreed on a label.",4 A Testbed for Redundancy Localization,[0],[0]
"Partial: At least 2/3 annotators agreed on a label.
",4 A Testbed for Redundancy Localization,[0],[0]
"dataset for the experiments in this paper (DEV), and the remaining 1000 items as a test dataset (TEST).",4 A Testbed for Redundancy Localization,[0],[0]
Tab. 2 reports the label distribution in both parts of the dataset.,4 A Testbed for Redundancy Localization,[0],[0]
We make the dataset publicly available at https://github.com/ kraseb/redundancy-localization.,4 A Testbed for Redundancy Localization,[0],[0]
"While the annotation required for our task is comparatively simple and can be performed by raters without special training, a workable fullysupervised model would require a very considerable amount of data and is likely to prove costly.3 Suppose, however, we were supplied with a large number of short texts with varying degrees of similarity and relatedness to one another and we had a means of assessing at the coarse level of text pairs whether or not they were similar.",5 Training with a Proxy Signal,[0],[0]
"Our hypothesis is that given appropriate model capacity and structure, a model trained to predict the passage-level similarity would learn to compare smaller units of text to make an appropriate high-level decision.
",5 Training with a Proxy Signal,[0],[0]
"We derive a proxy signal from passage-level retrieval scores which allows to bootstrap the redundancy-localization model described in Sec. 6.
3Among other things, to accurately identify redundancy the model needs to have at least some notion of paraphrasing.
",5 Training with a Proxy Signal,[0],[0]
"The model is presented with passage triples, where two passages are very closely related and the third one is on the same general topic, but less similar to the other two and hence likely contains less redundancy.",5 Training with a Proxy Signal,[0],[0]
"The model is then trained to rank the more closely related passage pairs above the less closely related ones.
",5 Training with a Proxy Signal,[0],[0]
We retrieve lists of relevant passages from the web using the same passage-retrieval system that we utilized to collect data for manual annotation.,5 Training with a Proxy Signal,[0],[0]
"Through manual inspection of a small subset of candidate passage lists, we identified a range of passage scores, where candidate passages are topically close to the top-scoring one, but sufficiently different in factual content.",5 Training with a Proxy Signal,[0],[0]
"To ensure that the topscoring passage and the lower-scoring one are on the same topic, we further require that they be extracted from the same webpage.
",5 Training with a Proxy Signal,[0],[0]
"From each of the queries’ passage lists we extract three passages, the top-scoring passage c, the second-highest ranking passage p+, and a lower-scoring passage p− from the score corridor described above.",5 Training with a Proxy Signal,[0],[0]
"The stream of passage triples (c,p+,p−) generated in this way allows to train a model with a margin-based ranking objective.",5 Training with a Proxy Signal,[0],[0]
"This objective enforces that the similarity score of the two high-scoring passages c,p+ is greater than the similarity of the low-scoring passage p− and the top-scoring one, plus a margin; see Sec. 6.3.",5 Training with a Proxy Signal,[0],[0]
"This pushes a model to find what differentiates two given text sequences, so that it can assign a higher similarity to the near-paraphrases.
",5 Training with a Proxy Signal,[0],[0]
Tab. 1 shows three example passage triples constructed with this signal.,5 Training with a Proxy Signal,[0],[0]
"Here, underlining is a means of visualizing the overlapping/disjoint content between triple elements.",5 Training with a Proxy Signal,[0],[0]
"Note that we do not
make this information available to a model during training.",5 Training with a Proxy Signal,[0],[0]
"In the interest of brevity, we selected short, single-sentence passages for this example.",5 Training with a Proxy Signal,[0],[0]
"This section first gives a brief overview of the proposed model, before going into details of its architecture and use during training and inference time.
",6 Model Design,[0],[0]
"Architecture Overview Existing models for bisequence tasks (Bahdanau et al., 2014; Rush et al., 2015; He and Lin, 2016) often learn to align texts as an intermediate step, i.e., reasoning is done with pairs of short text units, which allows to build a task-specific output for whole sequences on top of local decisions.",6 Model Design,[0],[0]
A particular example for RTE is the three-layer model of Parikh et al. (2016).,6 Model Design,[0],[0]
"The first layer produces a bi-directional alignment between input sentences, which is utilized in the second component to perform local comparisons, which in turn are fed to the top layer to make the final entailment decision.",6 Model Design,[0],[0]
"We follow the same pattern in the design of our model.
",6 Model Design,[0],[0]
We implement a multi-component neuralnetwork that takes two passages as input.,6 Model Design,[0],[0]
"It first (a) learns a uni-directional alignment between the passages, which is utilized to produce a customized representation of the context passage, specific to each token of the potentially redundant passage.
",6 Model Design,[0],[0]
"Next, (b) token-level redundancy scores are produced via local comparison operations.",6 Model Design,[0],[0]
"During training, (c) an additional layer aggregates the local scores and produces a passage-level similarity score on top of which a ranking objective is applied.",6 Model Design,[0],[0]
"At inference time, (d) the local scores from (b) serve as the basis for the ranking of the subpassage elements as described in Sec. 3.",6 Model Design,[0],[0]
Fig. 2 outlines steps (a) – (d).,6 Model Design,[0],[0]
"Input to the model are two sequences of n tokens each, p = (p0, . . .",6.1 Step (a): Alignment,[0],[0]
", pn−1) and c = (c0, . . .",6.1 Step (a): Alignment,[0],[0]
", cn−1), with shorter sequences being padded to this length.",6.1 Step (a): Alignment,[0],[0]
"The goal of this step is to generate for each pi ∈ p a fixed-length representation calignedi of c, which captures the meaning aspects of c specifically relevant for pi.
",6.1 Step (a): Alignment,[0],[0]
"The tokens pi, cj are represented via word embeddings of size dw, which are updated during model training and are stored in a matrix Ww ∈ Rdw×|V |, with V being the vocabulary.",6.1 Step (a): Alignment,[0],[0]
"For ease of notation, we use p, pi, c, ci to refer to both the original tokens and their embedding representation.
",6.1 Step (a): Alignment,[0],[0]
We create a soft alignment of c to the tokens of p via the decomposed attention mechanism described by Parikh et al. (2016).,6.1 Step (a): Alignment,[0],[0]
"At its core is the application of the attention function f1 to each token of the input sequences, which is implemented as a feed-forward neural network with hf1 layers of
df1 rectified linear units (Glorot et al., 2011, ReLu) each.",6.1 Step (a): Alignment,[0],[0]
"Using this function, unnormalized attention weights are produced:
αij = f1(pi) · f1(cj), (1) then normalized per token in p via
α′ij = exp (αij)/ ∑
k
exp (αik).",6.1 Step (a): Alignment,[0],[0]
"(2)
The customized (aligned) representation of c is then calculated as
calignedi = n−1∑ j=0",6.1 Step (a): Alignment,[0],[0]
α′ijcj .,6.1 Step (a): Alignment,[0],[0]
(3),6.1 Step (a): Alignment,[0],[0]
"Each token pi from p is compared to the corresponding representation calignedi of the context sequence via a single-layer feed-forward network f2 with a ReLu:
lsim (pi, c) := f2 ([ pi, c aligned i ]) (4) lsim (p, c) :=",6.2 Step (b): Learning Local Redundancy,[0],[0]
"[lsim (pi, c)]",6.2 Step (b): Learning Local Redundancy,[0],[0]
"n−1 i=0 (5)
with [ ] being the concatenation operator and lsim(p, c) ∈",6.2 Step (b): Learning Local Redundancy,[0],[0]
Rn.,6.2 Step (b): Learning Local Redundancy,[0],[0]
This local similarity score measures for each token the degree with which its meaning is covered by c.,6.2 Step (b): Learning Local Redundancy,[0],[0]
"As described in Sec. 5, supervised training with local redundancy labels is costly, which is why we add another layer on top which learns to calculate a coarse passage-level similarity score csim(p, c) from the local redundancy information.",6.3 Step (c): Learning to Aggregate Local Redundancy Scores,[0],[0]
"Given a passage triple (c,p+,p−) (Sec. 5), two such coarse scores are calculated and used to determine a loss which allows to train steps (a–c) of the network in Fig. 2 in a weakly supervised way.
",6.3 Step (c): Learning to Aggregate Local Redundancy Scores,[0],[0]
"The passage-level score is computed by another feed-forward network f3 with hf3 layers of df3 ReLus, followed by another hidden layer with a logistic activation function that projects to a scalar value in (0, 1):
csim (p, c) := f3 (lsim (p, c)) .",6.3 Step (c): Learning to Aggregate Local Redundancy Scores,[0],[0]
"(6)
Then, for a given passage triple (c,p+,p−), the loss is defined as:
L = max{0, 0.5− csim(p+, c) + csim(p−, c)} (7)
",6.3 Step (c): Learning to Aggregate Local Redundancy Scores,[0],[0]
This ranking criterion is similar to what has been used by Collobert et al. (2011) and Bordes et al. (2013).,6.3 Step (c): Learning to Aggregate Local Redundancy Scores,[0],[0]
"It is intended to push the model to assign a higher coarse similarity score to the more similar sequences from the triple, and in doing so, ideally forces the model to learn to detect local redundancies.",6.3 Step (c): Learning to Aggregate Local Redundancy Scores,[0],[0]
"During inference time, the goal of this model is to rank a set of given sub-sequences S of p with respect to their redundancy with c; note that during inference time the model is presented with pairs of passages in contrast to the triples it sees in the training phase.
",6.4 Step (d): Generation of Sub-sequence Redundancy Scores,[0],[0]
"We calculate a redundancy score for a subsequence sk ∈ S as follows:
ssim(sk, c) :",6.4 Step (d): Generation of Sub-sequence Redundancy Scores,[0],[0]
"= 1sk+1−sk sk+1−1∑
l=sk
(lsim(pl, c)) , (8)
where sk is the subsequence running from positions sk to sk+1 − 1 (see Sec. 3).",6.4 Step (d): Generation of Sub-sequence Redundancy Scores,[0],[0]
"A ranking of the subsequences is then given by:
rank(sk) := |{sl | ssim(sl, c) ≥",6.4 Step (d): Generation of Sub-sequence Redundancy Scores,[0],[0]
"ssim(sk, c)}| (9)
In other words, sub-passages are ranked by comparing the mean of their local redundancy scores.",6.4 Step (d): Generation of Sub-sequence Redundancy Scores,[0],[0]
"In the evaluation of Sec. 8, we refer to the model that uses this way of ranking sub-passages as UA (short for uni-directional alignment).",6.4 Step (d): Generation of Sub-sequence Redundancy Scores,[0],[0]
"We compare this against a number of other variants of processing internal activations of the model to extract information about local redundancy, see Sec. 8.",6.4 Step (d): Generation of Sub-sequence Redundancy Scores,[0],[0]
"The bi-directional alignment model (BA) of Parikh et al. (2016) can be trained in a similar fashion as our proposed model, i.e., with triples of passages and the loss from Eq. (7).",6.5 Baseline Ranking Method,[0],[0]
"Although it has not been developed with the localization of redundancy in mind, its native problem formulation (RTE) is structurally related to the problem at hand by requiring models to assess to what degree the semantic content of one passage is embedded in a second one.",6.5 Baseline Ranking Method,[0],[0]
"We believe BA constitutes a strong baseline because it has been shown to achieve state-of-the-art performance on RTE and because it has the means to decompose coarse inference decisions on two text sequences into local comparison operations,
a key requisite to successfully utilize the training signal from Sec. 5.
",6.5 Baseline Ranking Method,[0],[0]
"However, in contrast to our model, the results of comparing the aligned sequences calignedi with individual tokens from p are not directly interpretable as redundancy scores, also the architecture is designed for a bi-directional alignment of the input sequences.",6.5 Baseline Ranking Method,[0],[0]
"In order to produce lsim values for the tokens of p, we use the alignment matrices as a basis for a max-based aggregation, i.e., we take the row-wise maximum value and use this as the localized redundancy value for the corresponding token.",6.5 Baseline Ranking Method,[0],[0]
Sub-sequence similarity is then determined either via Eq.,6.5 Baseline Ranking Method,[0],[0]
(8) or alternatively via summation.,6.5 Baseline Ranking Method,[0],[0]
"We implemented both UA and BA in the TensorFlow framework (Abadi et al., 2015) and trained them with the signal from Sec. 5.","7 Experimental Setting, Model Training",[0],[0]
"As input to the passage-retrieval system we used a set of 1.5 million queries, resulting in the same amount of passage triples; 80% were used for training, 10% were used as a separate validation set for hyperparameter optimization, and the final 10% were held out and served as the basis for the smaller dataset with manually annotated labels (EVAL, Sec. 4)4.
","7 Experimental Setting, Model Training",[0],[0]
"The hyperparameters of UA (hf1, df1, hf3, df3) and BA (like our model, plus a few additional ones) were optimized separately.","7 Experimental Setting, Model Training",[0],[0]
"We also experimented with Dropout (Srivastava et al., 2014) for the feedforward networks in step (a–c) (pf1, pf2, pf3), with different initial learning rates (η) for Adagrad (Duchi et al., 2011), with different batch sizes, and with different vocabulary sizes (|V |).","7 Experimental Setting, Model Training",[0],[0]
The final settings for UA used in the reported experiments are shown in Tab. 3.,"7 Experimental Setting, Model Training",[0],[0]
"Word embeddings were initialized with pre-trained embeddings (Mikolov et al., 2013), the other model parameters were randomly initialized; out-of-vocabulary words were hashed
4We only annotated a subset of the passages in this part of the data.
into 100 buckets.","7 Experimental Setting, Model Training",[0],[0]
The models were trained for 1 million steps.,"7 Experimental Setting, Model Training",[0],[0]
"We first compare the performance of different variants of generating the redundancy scores for subpassage ranking, for both UA and BA, on DEV.",8 Evaluation on EVAL,[0],[0]
We then pick the respective best-performing model variant and compare the systems on TEST.,8 Evaluation on EVAL,[0],[0]
"The model variants we test are the following:
• UA: The uni-directional alignment model described in Sec. 6.
",8 Evaluation on EVAL,[0],[0]
• UAΣ: Summation instead of averaging in Eq.,8 Evaluation on EVAL,[0],[0]
"(8), which gives higher weight to long subsequences with redundancy.
",8 Evaluation on EVAL,[0],[0]
• UA′:,8 Evaluation on EVAL,[0],[0]
"Calculation of lsim in analogous fashion as BA (see below).
",8 Evaluation on EVAL,[0],[0]
• UA′Σ:,8 Evaluation on EVAL,[0],[0]
Combination of two variants above.,8 Evaluation on EVAL,[0],[0]
• BA′/BA′′:,8 Evaluation on EVAL,[0],[0]
"Models with bi-directional alignment
of input texts.",8 Evaluation on EVAL,[0],[0]
"lsim values for tokens of p are produced by using the first/second one of the two alignment matrices as a basis for the max-based aggregation of the normalized attention weights described in Sec. 6.5.
",8 Evaluation on EVAL,[0],[0]
"• BA′Σ / BA′′Σ: Like above, but sub-sequence similarity is determined via summation rather than calculating the mean in Eq.",8 Evaluation on EVAL,[0],[0]
"(8).
We measure performance by calculating the Spearman correlation of the raw passage scores with the gold redundancy for all segments in the respective partition of the dataset.",8 Evaluation on EVAL,[0],[0]
The top of Tab. 4 reports results of the different model variants.,8 Evaluation on EVAL,[0],[0]
"For UA, making direct use of the local redundancy scores calculated in step (b) of the model yields slightly better results than post-processing the alignments
from step (a) of the model.",8 Evaluation on EVAL,[0],[0]
"The best overall results for UA are achieved when this is combined with the strategy that represents sub-sequence redundancy as the arithmetic mean of the contained tokens’ local scores, meaning sub-sequence length needs to be taken into account.
",8 Evaluation on EVAL,[0],[0]
"For the baseline BA, exploiting the reverse alignment matrix and summing over the alignment scores without correction for sub-sequence length gives the best results.",8 Evaluation on EVAL,[0],[0]
The bottom of the table reports the results of applying both models with the respective best strategy on the test partition of the dataset.,8 Evaluation on EVAL,[0],[0]
The proposed uni-directional model clearly outperforms the bi-directional baseline.,8 Evaluation on EVAL,[0],[0]
"This indicates that the direct modeling of uni-directional redundancy during both training and inference time allows a model to better learn to compare a subsequence to another full passage, in comparison to the case where both passages are analyzed in a fine-granular way.
",8 Evaluation on EVAL,[0],[0]
"Fig. 3 depicts a scatter plot of the segments in TEST, with the x-axis corresponding to the gold redundancy scores (Sec. 4) and the y-axis showing the redundancy assessment by UA.",8 Evaluation on EVAL,[0],[0]
"While actually redundant segments tend to be handled correctly by the model, a certain amount of non-redundant segments get assigned a relatively high absolute redundancy value, which is not problematic as long as the actually redundant segments of the same passage are rated even higher.",8 Evaluation on EVAL,[0],[0]
"The next section elaborates on an experiment that looks into the quality of this internal ranking of segments for given passages, and how this ranking could potentially be utilized in an application.",8 Evaluation on EVAL,[0],[0]
"This section briefly discusses an experiment in a dialogue setting, in which redundancy information is used for the compression of passages.",9 Redundancy Localization for Passage Compression,[0.9629357031734861],"['This process is illustrated in Figure 1, which shows an excerpt from a corpus of tutorial dialogue situated in an introductory computer programming task in the Java programming language.']"
"Consider again the example from Fig. 1, where a conversational agent engages a human user in an informational dialogue whose quality suffers from repetition of information on the agent side.",9 Redundancy Localization for Passage Compression,[0],[0]
"In this experiment, we asked human raters to assess whether the removal of redundancy improves the dialogue flow.",9 Redundancy Localization for Passage Compression,[0],[0]
"Note, however, that given the small scale of the experiment, results are only indicative and not conclusive.
",9 Redundancy Localization for Passage Compression,[0],[0]
We selected 50 passage pairs from the held-out portion of the training data where the second passage consisted of at least three sentences.,9 Redundancy Localization for Passage Compression,[0],[0]
We then fed the passages to UA and removed the sentence from the second passage which had the largest semantic overlap with the context (the first passage).,9 Redundancy Localization for Passage Compression,[0],[0]
"We asked three human raters, (a) whether the two original passages are coherent at all (as the following questions assume this), (b) whether the compressed passage sounds more or less natural (due to the dropped redundant sentence), and (c) whether the modified passage is equally informative as the original passage.
",9 Redundancy Localization for Passage Compression,[0],[0]
"For comparison, we implemented a baseline which always dropped the first sentence of a passage, as well as one that removed the sentence with the highest term overlap.",9 Redundancy Localization for Passage Compression,[0],[0]
"For the following example, dropping the underlined sentence from the passage would result in a more natural and equally informative text:
c :",9 Redundancy Localization for Passage Compression,[0],[0]
"The 1966 FIFA World Cup was won by the England national football team.
",9 Redundancy Localization for Passage Compression,[0],[0]
p,9 Redundancy Localization for Passage Compression,[0],[0]
: The day England won the World Cup.,9 Redundancy Localization for Passage Compression,[0],[0]
Long-suffering fans of the England football team can always look back with nostalgia on one year: 1966.,9 Redundancy Localization for Passage Compression,[0],[0]
"This was the year Bobby Moore’s team defeated West Germany 4-2 in the World Cup final on 30 July, after a nail-biting and controversial match.
",9 Redundancy Localization for Passage Compression,[0],[0]
"Among the 50 uncompressed passage pairs, only one third was rated as being coherent (question a; independent of the model).",9 Redundancy Localization for Passage Compression,[0],[0]
"For these pairs, UA tended to produce more natural compressions (question b) compared to the baselines.",9 Redundancy Localization for Passage Compression,[0],[0]
"This might be explained by the term-overlap baseline’s restriction to only look at the level of individual words, which results in erroneously removing sentences that are essential for discourse coherence but do not
repeat facts.",9 Redundancy Localization for Passage Compression,[0],[0]
"Similarly, always dropping the first sentence can leave a passage with dangling backward references, e.g., in the case of anaphors.",9 Redundancy Localization for Passage Compression,[0],[0]
"In terms of the informativeness dimension (question c), all approaches resulted in slightly less informative compressed passages, which is expected.",9 Redundancy Localization for Passage Compression,[0],[0]
"However, UA’s score on this metric is slightly worse than the one of the baselines.",9 Redundancy Localization for Passage Compression,[0],[0]
"In this paper, we described the problem of localizing redundancy in pairs of passages.",10 Contributions and Outlook,[0],[0]
"We proposed a model based on a uni-directional alignment from one passage to the context passage, which can be efficiently trained using a novel weak supervision signal defined over the output of common passageretrieval systems.",10 Contributions and Outlook,[0],[0]
We applied this signal in a oneoff process to train our model and a reasonable baseline; from a held-out part of the retrieved passages we created a publicly available dataset which allows to compare and evaluate models on this task and enables other researchers to reproduce the evaluation setting of this work.,10 Contributions and Outlook,[0],[0]
"The conducted evaluation showed that the proposed uni-directional alignment model is indeed capable of finding the redundant sub-segments in texts.
",10 Contributions and Outlook,[0],[0]
"In future work, we would like to represent and model more facets of the naturalness and coherence of dialogues.",10 Contributions and Outlook,[0],[0]
"For instance in dialogue settings, a certain amount of redundancy between the utterances of participants may actually tie the dialogue turns together, i.e., may be beneficial in terms of discourse coherence and naturalness.",10 Contributions and Outlook,[0],[0]
Incorporating this consideration into the structure of a model can potentially improve the results of passage compression techniques in settings similar to Sec. 9.,10 Contributions and Outlook,[0],[0]
"The first author was partially supported by the German Federal Ministry of Education and Research, project ALL SIDES (contract 01IW14002).",Acknowledgments,[0],[0]
"Conversational agents offer users a naturallanguage interface to accomplish tasks, entertain themselves, or access information.",abstractText,[0],[0]
"Informational dialogue is particularly challenging in that the agent has to hold a conversation on an open topic, and to achieve a reasonable coverage it generally needs to digest and present unstructured information from textual sources.",abstractText,[0],[0]
"Making responses based on such sources sound natural and fit appropriately into the conversation context is a topic of ongoing research, one of the key issues of which is preventing the agent’s responses from sounding repetitive.",abstractText,[0],[0]
"Targeting this issue, we propose a new task, known as redundancy localization, which aims to pinpoint semantic overlap between text passages.",abstractText,[0],[0]
"To help address it systematically, we formalize the task, prepare a public dataset with fine-grained redundancy labels, and propose a model utilizing a weak training signal defined over the results of a passage-retrieval system on web texts.",abstractText,[0],[0]
The proposed model demonstrates superior performance compared to a state-of-the-art entailment model and yields encouraging results when applied to a real-world dialogue.,abstractText,[0],[0]
Redundancy Localization for the Conversationalization of Unstructured Responses,title,[0],[0]
"Proceedings of the SIGDIAL 2016 Conference, pages 329–338, Los Angeles, USA, 13-15 September 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"The content of a situated dialogue is very closely related to the environment in which it happens (Grosz and Sidner, 1986).",1 Introduction,[0],[0]
"As dialogue systems move toward assisting users in increasingly complex tasks, these systems must understand users’ language within the environment of the tasks.",1 Introduction,[0],[0]
"To achieve this goal, dialogue systems must perform reference resolution, which involves identifying the referents in the environment that the user refers to (Iida et al., 2010; Liu et al., 2014; Liu and Chai, 2015; Chai et al., 2004).",1 Introduction,[0],[0]
Imagine a dialogue system that assists a novice student in solving a programming problem.,1 Introduction,[1.0],['Imagine a dialogue system that assists a novice student in solving a programming problem.']
"To understand a question or statement the student poses, such as, “Should I use the 2 dimensional array?”, the system must link the referring expression “the 2 dimensional array” to an object1 in the environment.
",1 Introduction,[0],[0]
"1The word “object” has a technical meaning within the domain of object-oriented programming, which is the domain
This process is illustrated in Figure 1, which shows an excerpt from a corpus of tutorial dialogue situated in an introductory computer programming task in the Java programming language.",1 Introduction,[0],[0]
The arrows link referring expressions in the situated dialogue to their referents in the environment.,1 Introduction,[0],[0]
"To identify the referent of each referring expression, it is essential to capture the semantic structure of the referring expression of the object it refers to, such as “the 2 dimensional array” contains two attributes, “2 dimensional” and “array”.",1 Introduction,[0],[0]
"At the same time, the dialogue history and the history of user task actions (such as editing the code) play a key role.",1 Introduction,[0],[0]
"To disambiguate the referent of “my array”, temporal information is needed: in this case, the referent is a variable named arra, which is an array that the student has just created.
",1 Introduction,[0],[0]
Reference resolution in situated dialogue is challenging because of the ambiguity inherent within dialogue utterances and the complexity of the environment.,1 Introduction,[0],[0]
"Prior work has leveraged dialogue history and task history information to improve the accuracy of reference resolution (Iida et al., 2010; Iida et al., 2011; Funakoshi et al., 2012).",1 Introduction,[0],[0]
"However, these prior approaches have employed relatively simple semantic information from the referring expressions, such as a manually created lexicon, or have operated within an environment with a limited set of pre-defined objects.",1 Introduction,[0],[0]
"Besides reference resolution in situated dialogue, there is also a research direction in which machine learning models are used to learn the semantics of noun phrases in order to map noun phrases to objects in a related environment (Kennington and Schlangen, 2015; Liang et al., 2009; Naim et al., 2014; Kushman et al., 2014).",1 Introduction,[0],[0]
"However, these prior approaches operated at the granularity of single
of the corpus utilized in this work.",1 Introduction,[0],[0]
"However, we follow the standard usage of “object” in situated dialogue (Iida et al., 2010), which for programming is any portion of code in the environment.
329
spoken utterances not contextualized within a dialogue history, and they too focus on environments with a limited number (and a pre-defined set) of objects.",1 Introduction,[0],[0]
"As this paper demonstrates, these prior approaches do not perform well in situated dialogues for complex problem solving, in which the user creates, modifies, and removes objects from the environment in unpredictable ways.
",1 Introduction,[0],[0]
"To tackle the problem of reference resolution in this type of situated dialogue, we propose an approach that combines semantics from a conditional-random-field-based semantic parser along with salient features from dialogue history and task history.",1 Introduction,[0],[0]
"We evaluate this approach on the JavaTutor corpus, a corpus of textual tutorial dialogue collected within an online environment for computer programming.",1 Introduction,[1.0],"['We evaluate this approach on the JavaTutor corpus, a corpus of textual tutorial dialogue collected within an online environment for computer programming.']"
"The results show that our approach achieves substantial improvement over two existing state-of-the-art approaches, with existing approaches achieving 55.2% accuracy at best, and the new approach achieving 68.5% accuracy.
2Typos and syntactic errors are shown as they appear in the original corpus.",1 Introduction,[0.983585158042746],"['The results show that our approach achieves substantial improvement over two existing state-of-the-art approaches, with existing approaches achieving 55.2% accuracy at best, and the new approach achieving 68.5% accuracy.']"
The work in this paper is informed by research in coreference resolution for text as well as reference resolution in situated dialogue and multi-modal environments.,2 Related Work,[0],[0]
"This section describes related work in those areas.
",2 Related Work,[0],[0]
"The classic reference resolution problem for discourse aims to resolve coreference relationships within a given text (Martschat and Strube, 2015; McCarthy and Lehnert, 1995; Soon et al., 2001).",2 Related Work,[0],[0]
"Effective approaches for discourse cannot be directly applied to the problem of linking referring expressions to their referents in a rich situated dialogue environment, because the information embedded within the environment plays an important role in understanding the referring relationships in the situated dialogue.",2 Related Work,[0],[0]
"Our approach combines referring expressions’ semantic information along with dialogue history, task history, and a representation of the environment in which the dialogue is situated.
",2 Related Work,[0],[0]
Reference resolution in dialogue has been investigated in recent years.,2 Related Work,[0],[0]
"Some of the previous work focuses on reference resolution in a multimodal setting (Chai et al., 2004; Liu et al., 2014; Liu et al., 2013; Krishnamurthy and Kollar, 2013; Matuszek et al., 2012).",2 Related Work,[0],[0]
"For this problem re-
searchers have used multimodal information, including vision, gestures, speech, and eye gaze, to contribute to the problem of reference resolution.",2 Related Work,[0],[0]
"Given that the focus of these works is on employing rich multimodal information, the research is usually conducted on a limited number of objects, and typically uses spatial relationship between objects as constraints to solve the reference resolution problem.",2 Related Work,[0],[0]
"We conduct reference resolution in an environment with a dynamic number of referents and there is no obvious spatial relationship between the objects.
",2 Related Work,[0],[0]
"More closely related work to our own involves reference resolution in dialogue situated within a collaborative game (Iida et al., 2010; Iida et al., 2011; Funakoshi et al., 2012).",2 Related Work,[0],[0]
"To link referring expressions to one of the seven gamepiece objects, they encoded dialogue history and task history, and our proposed approach leverages these features as well.",2 Related Work,[0],[0]
"However, in contrast to our complex problem-solving domain of computer programming, their domain has a small number of possible referents, so they used a manually created lexicon to extract semantic information from referring expressions.",2 Related Work,[0],[0]
"Funakoshi et al. (2012) went further, using Bayesian networks to model the relationship between referents and words used in referring expressions.",2 Related Work,[0],[0]
That model is based on a hand-crafted concept dictionary and distribution over different referents.,2 Related Work,[0],[0]
"This approach cannot be directly applied to a dialogue with a dynamic environment because it is not possible to manually define the distribution over all possible referents beforehand, since objects in the environment are not known before they are created.",2 Related Work,[0],[0]
"So we chose Iida et al.’s work (2010) as one of the two most recent approaches to compare with.
",2 Related Work,[0],[0]
"Another closely related research direction involves reference resolution in physical environments (Kennington and Schlangen, 2015; Kushman et al., 2014; Naim et al., 2014; Liang et al., 2009).",2 Related Work,[0],[0]
"Although not within situated dialogue per se (because only one participant speaks), these lines of investigation have produced approaches that link natural language noun phrases to objects in an environment, such as a set of objects of different type and color on a table (Kennington and Schlangen, 2015) or a variable in a mathematical formula (Kushman et al., 2014).",2 Related Work,[0],[0]
"Some of these learn the mapping relationship by learning the semantics of words in the referring expressions
(Kennington and Schlangen, 2015; Liang et al., 2009) with referring expression-referent pairs as input.",2 Related Work,[0],[0]
"Most recently, Kennington and Schlangen (2015) used a word-as-classifier approach to learn word semantics to map referring expressions to a set of 36 Pentomino puzzle pieces on a table.",2 Related Work,[0],[0]
We implement their word-as-classifier approach and compare it with our novel approach.,2 Related Work,[0],[0]
This section describes a new approach to reference resolution in situated dialogue.,3 Reference Resolution Approach,[1.0],['This section describes a new approach to reference resolution in situated dialogue.']
It links each referring expression from the dialogue to a most likely referent object in the environment.,3 Reference Resolution Approach,[0],[0]
Our approach involves three main steps.,3 Reference Resolution Approach,[0],[0]
"First, referring expressions from the situated dialogue are segmented and labeled according to their semantic structure.",3 Reference Resolution Approach,[0],[0]
"Using a semantic segmentation and labeling approach we have previously developed (Li and Boyer, 2015), we use a conditional random field (CRF) for this joint segmentation and labeling task, and the values of the labeled attributes are then extracted (Section 3.1).",3 Reference Resolution Approach,[0],[0]
"The result of this step is learned semantics, which are attributes of objects expressed within each referring expression.",3 Reference Resolution Approach,[0],[0]
"Then, these learned semantics are utilized within the novel approach reported in this paper.",3 Reference Resolution Approach,[0],[0]
"As Section 3.2 describes, dialogue and task history are used to filter the objects in the environment to build a candidate list of referents, and then as Section 3.3 describes, a ranking-based classification approach is used to select the best matching referent.
",3 Reference Resolution Approach,[0],[0]
For situated dialogue we define Et as the state of the environment at time t. Et consists of all objects present in the environment.,3 Reference Resolution Approach,[0],[0]
"Importantly, the objects in the environment vary along with the dialogue: at each moment, new objects could be created (|Et| > |Et−1|), and existing objects could be removed (|Et| < |Et−1|) because of the task performed by the user.
",3 Reference Resolution Approach,[0],[0]
"Et = {oi|oi is an object in the environment at time t}
We assume that all of the objects oi are observable in the environment.",3 Reference Resolution Approach,[0],[0]
"For example, in situated dialogues about programming, we can find all of the objects and extract their attributes using a source code parser.",3 Reference Resolution Approach,[0],[0]
"Then, reference resolution is defined as finding a best-matching oi in Et for referring expression RE.",3 Reference Resolution Approach,[0],[0]
"Interpretation
In situated dialogues, a referring expression may contain rich semantic information about the referent, especially when the context of the situated dialogue is complex.",3.1 Referring Expression Semantic,[0],[0]
"Approaches such as domainspecific lexicons are limited in their ability to address this complexity, so we utilize a linear-chain CRF to parse the semantic structure of the referring expression.",3.1 Referring Expression Semantic,[0],[0]
"This more automated approach can also potentially avoid the manual labor required in creating and maintaining a lexicon.
",3.1 Referring Expression Semantic,[0],[0]
"In this approach, every object within the environment must be represented according to its attributes.",3.1 Referring Expression Semantic,[0],[0]
"We treat the set of all possible attributes of objects as a vector, and for each object oi in the environment we instantiate and populate an attribute vector Att V eci.",3.1 Referring Expression Semantic,[0],[0]
"For example, the attribute vector for a two-dimensional array in a computer program could be [CATEGORY = ‘array, DIMENSION = ‘2, LINE = ‘30, NAME = ‘table, ...].",3.1 Referring Expression Semantic,[1.0],"['For example, the attribute vector for a two-dimensional array in a computer program could be [CATEGORY = ‘array, DIMENSION = ‘2, LINE = ‘30, NAME = ‘table, ...].']"
"We ultimately represent Et = {oi} as the set of all attribute vectors Att V eci, and for a referring expression we aim to identify Att V ecj , the actual referent.
",3.1 Referring Expression Semantic,[0],[0]
"Since a referring expression describes its referents either implicitly or explicitly, the attributes expressed in it should match the attributes of its referent.",3.1 Referring Expression Semantic,[0],[0]
"We segment referring expressions and label the semantics of each segment using the CRF and the result is a set of segments, each of which represents some attribute of its referent.",3.1 Referring Expression Semantic,[0],[0]
This process is illustrated in (Figure 2 (a)).,3.1 Referring Expression Semantic,[0],[0]
"After segmenting and labeling attributes in the referring expressions, the attribute values are extracted from each semantic segment using regular expressions (Figure 2 (b)), e.g., value 2 is extracted from 2 dimensional to fill in the ARRAY DIM element in an empty Att V ec.",3.1 Referring Expression Semantic,[0],[0]
The result is an attribute vector that represents the referring expression.,3.1 Referring Expression Semantic,[0],[0]
"Once the referring expression is represented as an object attribute vector as described above, we wish to link that vector to the closest-matching object in the environment.",3.2 Generating a List of Candidate Referents,[0],[0]
"Each object is represented by its own attribute vector, and there may be a large number of objects in Et.",3.2 Generating a List of Candidate Referents,[0],[0]
"Given a referring expression Rk, we would like to trim the list to keep only those objects that are likely to be referent for Rk.
",3.2 Generating a List of Candidate Referents,[0],[0]
"There are two desired criteria for generating the
list of candidate referents.",3.2 Generating a List of Candidate Referents,[0],[0]
"First, the actual referent must be in the candidate list.",3.2 Generating a List of Candidate Referents,[0],[0]
"At the same time, the candidate list should be as short as possible.",3.2 Generating a List of Candidate Referents,[0],[0]
We can pare down the set of all objects in Et by considering focus of attention in dialogue.,3.2 Generating a List of Candidate Referents,[0],[0]
"Early approaches performed reference resolution by estimating each dialogue participant’s focus of attention (Lappin and Leass, 1994; Grosz et al., 1995).",3.2 Generating a List of Candidate Referents,[0],[0]
"According to Ariel’s accessibility theory (Ariel, 1988), people tend to use more precise descriptions such as proper names in referring expressions for referents in long term memory, and use less precise descriptions such as pronouns for referents in short term memory.",3.2 Generating a List of Candidate Referents,[0],[0]
"In a precise description, there is more semantic information, while in a more vague description like a pronoun, there is less semantic information.",3.2 Generating a List of Candidate Referents,[0],[0]
"Thus, these two sources of information, semantics and focus of attention, work together in identifying a referent.
",3.2 Generating a List of Candidate Referents,[0],[0]
"Our approach employs this idea in the process of candidate referent selection by tracking the focus of attention of the dialogue participants from the beginning of the dialogue through dialogue history and task history, as has been done in prior work we use for comparison within our experiments (Iida et al., 2010).",3.2 Generating a List of Candidate Referents,[0],[0]
"We also use the learned semantics of the referring expression (represented as the referring expression’s attribute vector) as filtering conditions to select candidates.
",3.2 Generating a List of Candidate Referents,[0],[0]
"The candidate generation process consists of three steps.
1.",3.2 Generating a List of Candidate Referents,[0],[0]
"Candidate generation from dialogue history DH .
",3.2 Generating a List of Candidate Referents,[0],[0]
"DH =< Od, Td >
Here, Od =< o1d, o 2 d, ..., o m d > is a sequence of objects that were mentioned since
the beginning of the dialogue.",3.2 Generating a List of Candidate Referents,[0],[0]
"Td =< t1d, t 2 d, ..., t m d > is a sequence of timestamps when corresponding objects were mentioned.",3.2 Generating a List of Candidate Referents,[0],[0]
"All of the objects in Et that were ever mentioned in the dialogue history, {oi|oi ∈ DH & oi ∈ Et}, will also be added into the candidate list.
2.",3.2 Generating a List of Candidate Referents,[0],[0]
Candidate generation from task history TH .,3.2 Generating a List of Candidate Referents,[0],[0]
"Similarly, TH =< Ob, Tb >, which is all of the objects in Et that were ever manipulated by the user, will be added into the candidate list.
3.",3.2 Generating a List of Candidate Referents,[0.993631542771134],"['Similarly, TH =< Ob, Tb >, which is all of the objects in Et that were ever manipulated by the user, will be added into the candidate list.']"
"Candidate generation using learned semantics, which are the referent’s attributes.",3.2 Generating a List of Candidate Referents,[0],[0]
"Given a set of attributes extracted from a referring expression, all objects in Et with one of the same attribute values will be added into the candidate list.",3.2 Generating a List of Candidate Referents,[0],[0]
The attributes are considered separately to avoid the case in which a single incorrectly extracted attribute could rule out the correct referent.,3.2 Generating a List of Candidate Referents,[0],[0]
Table 1 shows the algorithm used in this step.,3.2 Generating a List of Candidate Referents,[0],[0]
"With the list of candidate referents in hand, we employ a ranking-based classification model to identify the most likely referent.",3.3 Ranking-based classification,[0],[0]
"Ranking-based models have been shown to perform well for reference resolution problems in prior work (Denis and Baldridge, 2008; Iida et al., 2010).",3.3 Ranking-based classification,[0],[0]
"For a given referring expression Rk and its candidate referent list Ck = {o1, o2, ..., oNk}, in which each oi is an object identified as a candidate referent, we compute the probability of each candidate oi being the true referent of Rk, p(Rk, oi) = f(Rk, oi), where f is the classification function.",3.3 Ranking-based classification,[0],[0]
(Note that our approach is classifier-agnostic.,3.3 Ranking-based classification,[0],[0]
"As we describe in
Section 5, we experimented with several different models.)",3.3 Ranking-based classification,[0],[0]
"Then, the candidates are ranked by p(Rk, oi), and the object with the highest probability is taken as the referent of Rk.",3.3 Ranking-based classification,[0],[0]
Human problem solving represents a highly complex domain that poses great challenges for reference resolution.,4 Corpus,[0],[0]
"We evaluate our new reference resolution approach on a corpus of human-human textual dialogue in the domain of computer programming (Boyer et al., 2011).",4 Corpus,[0],[0]
"In each dialogue, a human tutor assisted a student remotely using typed dialogue as the student completed given programming tasks in the Java programming language.",4 Corpus,[0],[0]
"The programming tasks involved array manipulation and control flow, which are challenging for students with little programming experience.",4 Corpus,[0],[0]
Students’ and tutors’ view of the task were synchronized in real time.,4 Corpus,[0],[0]
"At the beginning of each problem-solving session students were provided a framework of code to fill in, which is around 200 lines initially.",4 Corpus,[0],[0]
"The corpus contains 45 tutoring sessions, 4857 utterances in total, 108 utterances for each session on average.",4 Corpus,[0],[0]
We manually annotated the referring expressions in the dialogue and their referents in the corresponding Java code for six dialogues from the corpus (346 referring expressions).,4 Corpus,[0],[0]
These six sessions contain 758 utterances.,4 Corpus,[0],[0]
"The dialogues focus on the details of solving the programming problems, with very little social or off-task talk.",4 Corpus,[0],[0]
Figure 1 shows an excerpt of this dialogue.,4 Corpus,[0],[0]
"To evaluate the new approach, we performed a set of experiments that compare our approach with two state-of-the-art approaches.",5 Experiments & Result,[0],[0]
The referring expressions were extracted from the tutorial dialogues and their semantic segments and labels were manually annotated.,5.1 Semantic Parsing,[0],[0]
"A linear-chain CRF was trained on that data and used to perform referring expression segmentation and labeling (Li and Boyer, 2015).",5.1 Semantic Parsing,[0],[0]
"The current paper reports the first use of that learned semantics approach for reference resolution.
",5.1 Semantic Parsing,[0],[0]
"Next, we proceeded to extract the attribute values, a step that our previous work did not address.",5.1 Semantic Parsing,[0],[0]
"For the example shown in Figure 2 (b), from the
learned semantic structure, we may know that 2 dimensional refers to the dimension of the array, the attribute ARRAY DIM.",5.1 Semantic Parsing,[0],[0]
"(In the current domain there are 14 attributes that comprise the generic attribute vector V , such as ARRAY DIM, NUM, and CATEGORY.)",5.1 Semantic Parsing,[0],[0]
"To actually extract the attribute values, we use regular expressions that capture our three types of attribute values: categorical, numeric, and strings.",5.1 Semantic Parsing,[0],[0]
"For example, the value type of CATEGORY is categorical, like method or variable.",5.1 Semantic Parsing,[0],[0]
Its values are taken from a closed set.,5.1 Semantic Parsing,[0],[0]
NAME has values that are strings.,5.1 Semantic Parsing,[0],[0]
LINE NUMBER’s value is numeric.,5.1 Semantic Parsing,[0],[0]
"For categorical attributes, we add the categorical attribute values into the semantic tag set of the CRF used for segmentation.",5.1 Semantic Parsing,[0],[0]
"In this way, the attribute values of categorical attributes will be generated by the CRF.",5.1 Semantic Parsing,[0],[0]
"For attributes with text string values, we take the whole surface string of the semantic segment as its attribute value.",5.1 Semantic Parsing,[0],[0]
The accuracy of the entire semantic parsing pipeline is 93.2% using 10-fold crossvalidation.,5.1 Semantic Parsing,[0],[0]
The accuracy is defined as the percentage of manually labeled attribute values that were successfully extracted from referring expressions.,5.1 Semantic Parsing,[0],[0]
We applied the approach described in Section 3.2 on each session to generate a list of candidate referents for each referring expression.,5.2 Candidate Referent Generation,[0],[0]
"In a program, there could be more than one appearance of the same object.",5.2 Candidate Referent Generation,[0],[0]
"We take all of the appearances of the same object to be the same, since they all refer to the same artifact in the program.",5.2 Candidate Referent Generation,[0],[0]
The average number of generated candidates for each referring expression was 44.8.,5.2 Candidate Referent Generation,[0],[0]
"The percentage of referring expressions whose actual referents were in the generated candidate list, or ’“hit rate” is 90.5%, based on manual tagging.",5.2 Candidate Referent Generation,[0],[0]
"This performance indicates that the candidate referent list generation performs well.
",5.2 Candidate Referent Generation,[0],[0]
"A referring expression could be a pronoun, such as “it” or “that”, which does not contain attribute information.",5.2 Candidate Referent Generation,[0],[0]
"In previous reference resolution research, it was shown that training separate models for different kinds of referring expressions could improve performance (Denis and Baldridge, 2008).",5.2 Candidate Referent Generation,[0],[0]
"We follow this idea and split the dataset into two groups: referring expressions containing attributes, REatt, (270 referring expressions), and referring expressions that do not contain attributes, REnon (76 referring expressions).
",5.2 Candidate Referent Generation,[0],[0]
"The candidate generation approach performed better for the referring expressions without attributes (hit rate 94.7%), compared to referring expressions with attributes (hit rate 89.3%).",5.2 Candidate Referent Generation,[0],[0]
"Since the candidate list for referring expressions without attributes relies solely on dialogue and task history, 94.7% of those referents had been mentioned in the dialogue or manipulated by the user previously.",5.2 Candidate Referent Generation,[0],[0]
"For referring expressions with attribute information, the generation of the candidate list also used learned semantic information.",5.2 Candidate Referent Generation,[0],[0]
Only 70.0% of those referents had been mentioned in the dialogue or manipulated by the user before.,5.2 Candidate Referent Generation,[0],[0]
We applied the approach described in section 3.3 to perform reference resolution on the corpus of tutorial dialogue.,5.3 Identifying Most Likely Referent,[0],[0]
The data from the six manually labeled Java tutoring sessions were split into a training set and a test set.,5.3 Identifying Most Likely Referent,[1.0],['The data from the six manually labeled Java tutoring sessions were split into a training set and a test set.']
We used leave-onedialogue-out cross validation (which leads to six folds) for the reference resolution experiments.,5.3 Identifying Most Likely Referent,[0],[0]
"In each fold, annotated referring expressions from one of the tutoring sessions were taken as the test set, and data from the other five sessions were the training set.",5.3 Identifying Most Likely Referent,[0],[0]
"We tested logistic regression, decision tree, naive Bayes, and neural networks as classifiers to compute the p(Rk, oi) for each (referring expression, candidate) pair for the ranking-based model.",5.3 Identifying Most Likely Referent,[0],[0]
"The features provided to each classifier are shown in Table 2.
",5.3 Identifying Most Likely Referent,[0],[0]
"To evaluate the performance of the new approach, we compare against two other recent approaches.",5.3 Identifying Most Likely Referent,[0],[0]
"First, we compare against a rankingbased model that uses dialogue history and task history features (Iida et al., 2010).",5.3 Identifying Most Likely Referent,[0],[0]
This model uses semantics from a domain-specific lexicon instead of a semantic parser.,5.3 Identifying Most Likely Referent,[1.0],['This model uses semantics from a domain-specific lexicon instead of a semantic parser.']
"(As described in Section 2, their work was extended by Funakoshi et al. (2012), but that work relies upon a handcrafted probability distribution of referents to concepts, which is not feasible in our domain since it has no fixed set of possible referents.)",5.3 Identifying Most Likely Referent,[0],[0]
"Therefore, we compare against their 2010 approach, implementing it in a way that creates the strongest possible baseline: we built a lexicon directly from our manually labeled semantic segments.",5.3 Identifying Most Likely Referent,[0],[0]
"First, we split all of the semantic segments into groups by their tags.",5.3 Identifying Most Likely Referent,[0],[0]
"Then, for each group of segments, any token that appeared twice or more was added into the lexi-
con.",5.3 Identifying Most Likely Referent,[0],[0]
"Although the necessary data to do this would not be available in a real application of the technique, it ensures that the lexicon for the baseline condition has good coverage and creates a high baseline for our new approach to compare against.",5.3 Identifying Most Likely Referent,[0],[0]
"Additionally, for fairness of comparison, for each
semantic feature used in our model, we extracted the same feature using the lexicon.",5.3 Identifying Most Likely Referent,[0],[0]
"There were three kinds of attribute values in the domain: categorical, string, and numeric (as described in Section 5.1).",5.3 Identifying Most Likely Referent,[0],[0]
We extracted categorical attribute values using the appearance of tokens in the lexicon.,5.3 Identifying Most Likely Referent,[0],[0]
We used regular expressions to determine whether a referring expression contains the name of a candidate referent.,5.3 Identifying Most Likely Referent,[0],[0]
"We also used regular expressions to extract attribute values from referring expressions, such as line number.",5.3 Identifying Most Likely Referent,[0],[0]
"We also provided the Iida baseline model (2010) with a feature to indicate string matching between referring expressions and candidate referents, since this feature was captured in our model as an attribute.
",5.3 Identifying Most Likely Referent,[0],[0]
"We also compared our approach against a very recent technique that leveraged a word-asclassifier approach to learn semantic compatibility between referring expressions and candidate referents (Kennington and Schlangen, 2015).",5.3 Identifying Most Likely Referent,[0],[0]
To create this comparison model we used a word-asclassifier to learn the semantics of referring expressions instead of CRF.,5.3 Identifying Most Likely Referent,[0],[0]
This weakly supervised approach relies on co-appearance between words and object’s attributes.,5.3 Identifying Most Likely Referent,[0],[0]
"We then used the resulting semantic compatibility in a ranking-based model to select the most likely referent.
",5.3 Identifying Most Likely Referent,[0],[0]
"The three conditions for our experiment are as follows.
",5.3 Identifying Most Likely Referent,[0],[0]
"• Iida Baseline Condition: Features including dialogue history, task history, and semantics from a handcrafted lexicon (Iida et al., 2010).
",5.3 Identifying Most Likely Referent,[0.9999999720020529],"['• Iida Baseline Condition: Features including dialogue history, task history, and semantics from a handcrafted lexicon (Iida et al., 2010).']"
• Kennington Baseline Condition:,5.3 Identifying Most Likely Referent,[0],[0]
"Features including dialogue history, task history, and learned semantics from a wordas-classifier model (Kennington and Schlangen, 2015).
",5.3 Identifying Most Likely Referent,[0],[0]
"• Proposed approach: Features including dialogue history, task history, and learned semantics from CRF.
",5.3 Identifying Most Likely Referent,[1.0000000267129925],"['• Proposed approach: Features including dialogue history, task history, and learned semantics from CRF.']"
"Within each of these experimental conditions, we varied the classifier used to compute p(Rk, oi), testing four classifiers: logistic regression (LR), decision tree (DT), naive Bayes (NB), and neural network (NN).",5.3 Identifying Most Likely Referent,[0],[0]
"The neural network has one hidden layer and the best-performing number of perceptrons was 100 (we experimented between 50 and 120).
",5.3 Identifying Most Likely Referent,[0],[0]
"To measure the performance of the reference resolution approaches, we analyzed accuracy, defined to be the percent of referring expressions that were successfully linked to their referents.",5.3 Identifying Most Likely Referent,[0],[0]
"We chose accuracy for our metric following standard practice (Iida et al., 2010; Kennington and Schlangen, 2015) because it provides an overall measure of the number of (Rk, oi) pairs that were correctly identified.",5.3 Identifying Most Likely Referent,[0],[0]
"For the rare cases in which one referring expression referred to multiple referents, the output referent of the algorithm was taken as correct if it selected any of the multiple referents.
",5.3 Identifying Most Likely Referent,[0],[0]
The results are shown in Table 3.,5.3 Identifying Most Likely Referent,[0],[0]
"We focus on comparing the results on referring expressions that contain attribute information, shown in the table as REFATT .",5.3 Identifying Most Likely Referent,[0],[0]
REFATT accounts for 78% of all of the cases (270 out of 346).,5.3 Identifying Most Likely Referent,[0],[0]
"Among the three approaches, our proposed approach outperformed both prior approaches.",5.3 Identifying Most Likely Referent,[0],[0]
"Compared to the Iida 2010 approach which achieved a maximum of 55.2% accuracy, our approach achieved 68.5% accuracy using a neural net classifier, and this difference is statistically significant based on the results of a Wilcoxon signed-rank test (n = 6; p = 0.046).",5.3 Identifying Most Likely Referent,[0],[0]
"Our approach outperformed the Kennington 2015 approach even more substantially, as its best performance was 46.3% accuracy (p = 0.028).",5.3 Identifying Most Likely Referent,[0],[0]
"Intuitively, the better performance of our model compared to the Iida approach is due to its ability to more accurately model referring expressions’ semantics.",5.3 Identifying Most Likely Referent,[0],[0]
"Compared to a lexicon, semantic parsing finds optimal segmentation for a referring expression, while a lexicon approach extracts different attribute information from referring expressions separately.",5.3 Identifying Most Likely Referent,[0],[0]
Note that our approach and the Iida 2010 approach achieved the same performance on REFNON referring expressions.,5.3 Identifying Most Likely Referent,[0],[0]
"Since these referring expressions do not contain attribute information, these two approaches used the same set of features.
",5.3 Identifying Most Likely Referent,[0],[0]
"Interestingly, the model using a word-asclassifier approach to learn the semantic compatibility between referring expressions and referent’s attributes performs the worst.",5.3 Identifying Most Likely Referent,[0],[0]
We believe that the reason for this poor performance is mainly from the way it performs semantic compositions.,5.3 Identifying Most Likely Referent,[0],[0]
"It cannot learn structures in referring expressions, such as that 2 dimensional is a segment, dimensional represents the type of the attribute, and 2 is the value of the attribute.",5.3 Identifying Most Likely Referent,[0],[0]
"The word-as-classifier
model cannot deal with this complex semantic composition.
",5.3 Identifying Most Likely Referent,[0],[0]
The results reported above relied on learned semantics.,5.3 Identifying Most Likely Referent,[0],[0]
"We also performed experiments using manually labeled, gold-standard semantics of referring expressions.",5.3 Identifying Most Likely Referent,[0],[0]
"The result in Table 4 shows that ranking-based models have the potential to achieve a considerably better result, 73.6%, with more accurate semantic information.",5.3 Identifying Most Likely Referent,[0],[0]
"Given the 85.3% agreement between two human annotators, the model performs very well, since the semantics of whole utterances in situated dialogue also play a very important role in identifying a given referring expression’s referent.",5.3 Identifying Most Likely Referent,[0],[0]
Dialogue systems need to move toward supporting users in increasingly complex tasks.,6 Conclusion,[0],[0]
"To do this effectively, accurate reference resolution is crucial.",6 Conclusion,[0],[0]
"We have presented a new approach that applies
learned semantics to reference resolution in situated dialogue for collaborative tasks.",6 Conclusion,[0],[0]
The experiments with human-human dialogue on a collaborative programming task showed a tremendous improvement using semantic information that was learned with a CRF-based semantic parsing approach compared to the previous state-of-art approaches.,6 Conclusion,[0],[0]
"The accuracy was improved substantially, from 55.2% to 68.5%.
",6 Conclusion,[0],[0]
There are several important future research directions in reference resolution for situated dialogues.,6 Conclusion,[1.0],['There are several important future research directions in reference resolution for situated dialogues.']
"First, models should incorporate more semantic information from discourse structure and utterance understanding besides semantics from referring expressions.",6 Conclusion,[0],[0]
This is illustrated by the observation that the reference resolution accuracy using gold-standard semantic information from referring expressions is still substantially lower than the agreement rate between human annotators.,6 Conclusion,[0],[0]
Another research direction that holds promise is to use an unsupervised approach to extract semantic information from referring expressions.,6 Conclusion,[0],[0]
It is hoped that this line of investigation will enable rich natural language dialogue interactions to support users in a wide variety of complex situated tasks.,6 Conclusion,[0],[0]
"The authors wish to thank the members of the LearnDialogue group at the University of Florida and North Carolina State University, particularly Joseph Wiggins, along with Wookhee Min and Adam Dalton for their helpful input.",Acknowledgments,[0],[0]
This work is supported in part by Google through a Capacity Research Award and by the National Science Foundation through grant CNS-1622438.,Acknowledgments,[0],[0]
"Any opinions, findings, conclusions, or recommendations expressed in this report are those of the authors, and do not necessarily represent the official views, opinions, or policy of the National Science Foundation.",Acknowledgments,[0],[0]
Understanding situated dialogue requires identifying referents in the environment to which the dialogue participants refer.,abstractText,[0],[0]
"This reference resolution problem, often in a complex environment with high ambiguity, is very challenging.",abstractText,[0],[0]
We propose an approach that addresses those challenges by combining learned semantic structure of referring expressions with dialogue history into a ranking-based model.,abstractText,[0],[0]
We evaluate the new technique on a corpus of human-human tutorial dialogues for computer programming.,abstractText,[0],[0]
The experimental results show a substantial performance improvement over two recent state-of-the-art approaches.,abstractText,[0],[0]
The proposed work makes a stride toward automated dialogue in complex problem-solving environments.,abstractText,[0],[0]
Reference Resolution in Situated Dialogue with Learned Semantics,title,[0],[0]

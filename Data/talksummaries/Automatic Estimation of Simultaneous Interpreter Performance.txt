0	15	Simultaneous Interpretation (SI) is an inherently difficult task that carries significant cognitive and attentional burdens.
1	6	The role of the simultaneous interpreter is to accurately render the source speech in a given target language in a timely and precise manner.
3	11	Unfortunately, the interpreter is pitched against the limits of human memory and stamina, and after only minutes of interpreting, the number of errors made by an interpreter begins to increase exponentially (Moser-Mercer et al., 1998).
4	28	We examine the task of estimating simultaneous interpreter performance: automatically predicting when interpreters are interpreting smoothly and when they are struggling.
6	25	CAI is quickly gaining traction in the interpreting community, with software products such as InterpretBank (Fantinouli, 2016) deployed in interpreting booths to provide live and interactive terminology support.
7	77	Figure 1(b) shows how this might work; both the interpreter and the CAI system receive the source message and the system displays assistive information in the form of terminology and informational support.
10	36	The system can minimize distraction by providing assistance only when an interpreter is struggling.
11	9	This level of support could be moderated appropriately if interpreter performance can be accurately predicted.
13	65	As a concrete method for estimating interpreter performance, we turn to existing work on QE for machine translation (MT) systems (Specia et al., 2010, 2015), which takes in the source sentence and MT-generated outputs and estimates a measure of quality.
17	4	The remainder of the paper describes methods and experiments on English-Japanese (ENJA), English-French (EN-FR), and English-Italian (EN-IT) interpretation data attempting to answer these questions.
18	46	Blatz et al. (2004) first proposed the problem of measuring the quality of MT output as a prediction task, given that existing metrics such as BLEU (Papineni et al., 2002) rely on the availability of reference translations to evaluate MT output quality, which aren’t always available.
19	43	As such, QE has since received widespread attention in the MT community and since 2012 has been included as a task in the Workshop on Statistical Machine Translation (Callison-Burch et al., 2012), using approaches ranging from linear classifiers (Ueffing and Ney, 2007; Luong et al., 2014) to neural models (Martins et al., 2016, 2017).
22	45	There are two main modules to QuEst++: a feature extractor and a learning module.
27	45	The default, out-of-the-box, sentence-level feature set for QuEst++ includes seventeen features such as number of tokens in source/target utterances, average token length, n-gram frequency, etc.
31	3	Ratio of pauses/hesitations/incomplete words: Sridhar et al. (2013) propose that interpreters regularly use pauses to gain more time to think and as a cognitive strategy to manage memory constraints.
32	73	An increased number of hesitations or incomplete words in interpreter output might indicate that an interpreter is struggling to produce accurate output.
33	25	In our particular case, both corpora we use in experiments are annotated for pauses and partial renditions of words.
34	6	Ratio of non-specific words: Interpreters often compress output by replacing or omitting common nouns to avoid specific terminology (Sridhar et al., 2013), either to prevent redundancy or to ease cognitive load.
38	25	Transliterated words in interpreted speech could represent facilitated translation by language proximity, or an attempt to produce an approximation of a word that the interpreter did not know.
47	3	Interpreter output is fundamentally different from any reference that we may use in evaluation because interpreters employ a range of economizing strategies such as segmentation, omission, generalization, and reformulation (Riccardi, 2005).
52	16	This corpus provides human transcribed SI output from three interpreters of low, intermediate and high levels of proficiency denoted B-rank, Arank and S-rank respectively, with 559 utterances from each interpreter.
57	2	As a proxy for our experiments, we generated translations of the original speech using Google Translate, which resulted in much more qualitatively reliable METEOR scores than the EPTIC translations.
59	7	As a baseline, we train QuEst++ on the out-of-the-box feature set (Section 2).
69	28	However, our proposed, interpreter-focused model out-performs in all language settings with notable gains in particular for EN-JA(A-Rank) (+0.104), achieving its highest accuracy on the EN-FR dataset.
77	23	Below is a qualitative EN-IT example with a METEOR score of 0.079 (being substantially lower than the average METEOR score across all datasets; 0.262).
78	17	The baseline model prediction of its score was 0.127, and our proposed model, 0.066: SOURCE: “Will the Parliament grant President Dilma Rousseff, on the very first occasion after her groundbaking groundbreaking election and for no sound formal reason, the kind of debate that we usually reserve for people like Mugabe?
79	129	So, I ask you to remove Brazil from the agenda of the urgencies.” INTERP: “Ehm il Parlamento... dopo le elezioni... daremdar spazio a un dibattito sul ehm sul caso per esempio del presidente Mugabe invece di mettere il Brasile all’ordine del giorno?” GLOSS: “Ehm the Parliament... after the elections... we’ll gi- will give way to a debate on the ehm on the case for example of President Mugabe instead of putting Brazil on the agenda?” Our model can better capture the issues in this example because it has many interpretation specific qualities (pauses, compression, and omission).
80	13	This is an example in which a CAI system might offer assistance to an interpreter struggling to produce an accurate rendition.
81	22	We introduce a novel and effective application of QE to evaluate interpreter output, which could be immediately applied to allow CAI systems to selectively offer assistance to struggling interpreters.
82	35	This work uses METEOR to evaluate interpreter output, but creation of fine-grained mea- sures to evaluate various aspects of interpreter performance is an interesting avenue for future work.

0,1,label2,summary_sentences
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 364–369 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
364",text,[0],[0]
"Semantic role labeling (SRL) captures predicateargument relations, such as “who did what to whom.”",1 Introduction,[0],[0]
"Recent high-performing SRL models (He et al., 2017; Marcheggiani et al., 2017; Tan et al., 2018) are BIO-taggers, labeling argument spans for a single predicate at a time (as shown in Figure 1).",1 Introduction,[0],[0]
"They are typically only evaluated with gold predicates, and must be pipelined with error-prone predicate identification models for deployment.
",1 Introduction,[0],[0]
We propose an end-to-end approach for predicting all the predicates and their argument spans in one forward pass.,1 Introduction,[0],[0]
"Our model builds on a recent coreference resolution model (Lee et al., 2017), by making central use of learned, contextualized span representations.",1 Introduction,[0],[0]
We use these representations to predict SRL graphs directly over text spans.,1 Introduction,[0],[0]
"Each edge is identified by independently predicting which role, if any, holds between every possible pair of text spans, while using aggressive beam
1Code and models: https://github.com/luheng/lsgn
pruning for efficiency.",1 Introduction,[0],[0]
"The final graph is simply the union of predicted SRL roles (edges) and their associated text spans (nodes).
",1 Introduction,[0],[0]
"Our span-graph formulation overcomes a key limitation of semi-markov and BIO-based models (Kong et al., 2016; Zhou and Xu, 2015; Yang and Mitchell, 2017; He et al., 2017; Tan et al., 2018): it can model overlapping spans across different predicates in the same output structure (see Figure 1).",1 Introduction,[0],[0]
"The span representations also generalize the token-level representations in BIObased models, letting the model dynamically decide which spans and roles to include, without using previously standard syntactic features (Punyakanok et al., 2008; FitzGerald et al., 2015).
",1 Introduction,[0],[0]
"To the best of our knowledge, this is the first span-based SRL model that does not assume that predicates are given.",1 Introduction,[0],[0]
"In this more realistic setting, where the predicate must be predicted, our model achieves state-of-the-art performance on PropBank.",1 Introduction,[0],[0]
"It also reinforces the strong performance of similar span embedding methods for coreference (Lee et al., 2017), suggesting that this style of models could be used for other span-span relation tasks, such as syntactic parsing (Stern et al., 2017), relation extraction (Miwa and Bansal, 2016), and QA-SRL (FitzGerald et al., 2018).",1 Introduction,[0],[0]
"We consider the space of possible predicates to be all the tokens in the input sentence, and the space of arguments to be all continuous spans.",2 Model,[0],[0]
"Our model decides what relation exists between each predicate-argument pair (including no relation).
",2 Model,[0],[0]
"Formally, given a sequence X = w1, . . .",2 Model,[0],[0]
", wn, we wish to predict a set of labeled predicateargument relations Y ⊆ P ×",2 Model,[0],[0]
"A × L, where P = {w1, . . .",2 Model,[0],[0]
", wn} is the set of all tokens (predicates), A = {(wi, . . .",2 Model,[0],[0]
", wj) | 1 ≤",2 Model,[0],[0]
"i ≤ j ≤ n} contains all the spans (arguments), and L is the space of semantic role labels, including a null label indicating no relation.",2 Model,[0],[0]
"The final SRL output would be all the non-empty relations {(p, a, l) ∈ Y",2 Model,[0],[0]
"| l 6= }.
",2 Model,[0],[0]
"We then define a set of random variables, where each random variable yp,a corresponds to a predicate p ∈ P and an argument a ∈ A, taking value from the discrete label space L.",2 Model,[0],[0]
"The random variables yp,a are conditionally independent of each other given the input X:
P (Y | X) = ∏
p∈P,a∈A P (yp,a | X) (1)
P (yp,a = l | X) = exp(φ(p, a, l))∑
l′∈L exp(φ(p, a, l′))
",2 Model,[0],[0]
"(2)
Where φ(p, a, l) is a scoring function for a possible (predicate, argument, label) combination.",2 Model,[0],[0]
"φ is decomposed into two unary scores on the predicate and the argument (defined in Section 3), as well as a label-specific score for the relation:
φ(p, a, l) = Φa(a) + Φp(p) +",2 Model,[0],[0]
"Φ (l) rel (a, p) (3)
",2 Model,[0],[0]
"The score for the null label is set to a constant: φ(p, a, ) = 0, similar to logistic regression.
",2 Model,[0],[0]
"Learning For each input X , we minimize the negative log likelihood of the gold structure Y ∗:
",2 Model,[0],[0]
J (X) =,2 Model,[0],[0]
"− logP (Y ∗ | X) (4)
Beam pruning As our model deals with O(n2) possible argument spans and O(n) possible predicates, it needs to consider O(n3|L|) possible relations, which is computationally impractical.",2 Model,[0],[0]
"To overcome this issue, we define two beams Ba and Bp for storing the candidate arguments and predicates, respectively.",2 Model,[0],[0]
The candidates in each beam are ranked by their unary score (Φa or Φp).,2 Model,[0],[0]
The sizes of the beams are limited by λan and λpn.,2 Model,[0],[0]
"Elements that fall out of the beam do not participate
in computing the edge factors Φ(l)rel , reducing the overall number of relational factors evaluated by the model to O(n2|L|).",2 Model,[0],[0]
"We also limit the maximum width of spans to a fixed number W (e.g. W = 30), further reducing the number of computed unary factors to O(n).",2 Model,[0],[0]
"Our model builds contextualized representations for argument spans a and predicate words p based on BiLSTM outputs (Figure 2) and uses feedforward networks to compute the factor scores in φ(p, a, l) described in Section 2 (Figure 3).
",3 Neural Architecture,[0],[0]
"Word-level contexts The bottom layer consists of pre-trained word embeddings concatenated with character-based representations, i.e. for each token wi, we have xi = [WORDEMB(wi); CHARCNN(wi)].",3 Neural Architecture,[0],[0]
"We then contextualize each xi using an m-layered bidirectional LSTM with highway connections (Zhang et al., 2016), which we denote as x̄i.
Argument and predicate representation We build contextualized representations for all candidate arguments a ∈ A and predicates p ∈ P .",3 Neural Architecture,[0],[0]
"The argument representation contains the following: end points from the BiLSTM outputs (x̄START(a), x̄END(a)), a soft head word xh(a), and embedded span width features f(a), similar to Lee et al. (2017).",3 Neural Architecture,[0],[0]
"The predicate representation is simply the BiLSTM output at the position INDEX(p).
",3 Neural Architecture,[0],[0]
"g(a) =[x̄START(a); x̄END(a); xh(a); f(a)] (5)
g(p) =x̄INDEX(p) (6)
The soft head representation xh(a) is an attention mechanism over word inputs x in the argument span, where the weights e(a) are computed via a linear layer over the BiLSTM outputs x̄.
xh(a) = xSTART(a):END(a)e(s) ᵀ (7) e(a)",3 Neural Architecture,[0],[0]
"= SOFTMAX(wᵀe x̄START(a):END(a)) (8)
xSTART(a):END(a) is a shorthand for stacking a list of vectors xt, where START(a) ≤ t ≤ END(a).
",3 Neural Architecture,[0],[0]
"Scoring The scoring functions Φ are implemented with feed-forward networks based on the predicate and argument representations g:
Φa(a) =w ᵀ a MLPa(g(a))",3 Neural Architecture,[0],[0]
(9) Φp(p),3 Neural Architecture,[0],[0]
"=w ᵀ pMLPp(g(p)) (10)
Φ (l) rel (a, p) =w (l)ᵀ r MLPr([g(a); g(p)]) (11)",3 Neural Architecture,[0],[0]
"We experiment on the CoNLL 2005 (Carreras and Màrquez, 2005) and CoNLL 2012 (OntoNotes 5.0, (Pradhan et al., 2013)) benchmarks, using two SRL setups: end-to-end and gold predicates.",4 Experiments,[0],[0]
"In the end-to-end setup, a system takes a tokenized sentence as input, and predicts all the predicates and their arguments.",4 Experiments,[0],[0]
"Systems are evaluated on the micro-averaged F1 for correctly predicting (predicate, argument span, label) tuples.",4 Experiments,[0],[0]
"For comparison with previous systems, we also report results with gold predicates, in which the complete set of predicates in the input sentence is given as well.",4 Experiments,[0],[0]
"Other experimental setups and hyperparameteres are listed in Appendix A.1.
ELMo embeddings To further improve performance, we also add ELMo word representations (Peters et al., 2018) to the BiLSTM input (in the +ELMo rows).",4 Experiments,[0],[0]
"Since the contextualized representations ELMo provides can be applied to most previous neural systems, the improvement is orthogonal to our contribution.",4 Experiments,[0],[0]
"In Table 1 and 2, we organize all the results into two categories: the comparable single model systems, and the mod-
els augmented with ELMo or ensembling (in the PoE rows).
",4 Experiments,[0],[0]
"End-to-end results As shown in Table 1,2 our joint model outperforms the previous best pipeline system (He et al., 2017) by an F1 difference of anywhere between 1.3 and 6.0 in every setting.",4 Experiments,[0],[0]
"The improvement is larger on the Brown test set, which is out-of-domain, and the CoNLL 2012 test set, which contains nominal predicates.",4 Experiments,[0],[0]
"On all datasets, our model is able to predict over 40% of the sentences completely correctly.
",4 Experiments,[0],[0]
"Results with gold predicates To compare with additional previous systems, we also conduct experiments with gold predicates by constraining our predicate beam to be gold predicates only.",4 Experiments,[0],[0]
"As shown in Table 2, our model significantly out-performs He et al. (2017), but falls short of Tan et al. (2018), a very recent attention-based (Vaswani et al., 2017)",4 Experiments,[0],[0]
BIO-tagging model that was developed concurrently with our work.,4 Experiments,[0],[0]
"By adding the contextualized ELMo representations, we are able to out-perform all previous systems, including Peters et al. (2018), which applies ELMo to the SRL model introduced in He et al. (2017).",4 Experiments,[0],[0]
Our model’s architecture differs significantly from previous BIO systems in terms of both input and decision space.,5 Analysis,[0],[0]
"To better understand our model’s strengths and weaknesses, we perform three analyses following Lee et al. (2017) and He et al. (2017), studying (1) the effectiveness of beam
2For the end-to-end setting on CoNLL 2012, we used a subset of the train/dev data from previous work due to noise in the dataset; the dev result is not directly comparable.",5 Analysis,[0],[0]
"See Appendix A.2 for detailed explanation.
",5 Analysis,[0],[0]
"pruning, (2) the ability to capture long-range dependencies, (3) agreement with syntactic spans, and (4) the ability to predict globally consistent SRL structures.",5 Analysis,[0],[0]
The analyses are performed on the development sets without using ELMo embeddings.,5 Analysis,[0],[0]
"3
Effectiveness of beam pruning Figure 4 shows the predicate and argument spans kept in the beam, sorted with their unary scores.",5 Analysis,[0],[0]
"Our model efficiently prunes unlikely argument spans and predicates, significantly reduces the number of edges it needs to consider.",5 Analysis,[0],[0]
Figure 5 shows the recall of predicate words on the CoNLL 2012 development set.,5 Analysis,[0],[0]
"By retaining λp = 0.4 predicates per word, we are able to keep over 99.7% argument-bearing predicates.",5 Analysis,[0],[0]
"Compared to having a part-of-speech tagger (POS:X in Figure 5), our joint beam pruning allowing the model to have a soft trade-off between efficiency and recall.4
Long-distance dependencies Figure 6 shows the performance breakdown by binned distance between arguments to the given predicates.",5 Analysis,[0],[0]
"Our model is better at accurately predicting arguments that are farther away from the predicates, even
3For comparability with prior work, analyses (2)-(4) are performed on the CoNLL 05 dev set with gold predicates.
",5 Analysis,[0],[0]
"4The predicate ID accuracy of our model is not comparable with that reported in He et al. (2017), since our model does not predict non-argument-bearing predicates.
",5 Analysis,[0],[0]
"compared to an ensemble model (He et al., 2017) that has a higher overall F1.",5 Analysis,[0],[0]
"This is very likely due to architectural differences; in a BIO tagger, predicate information passes through many LSTM timesteps before reaching a long-distance argument, whereas our architecture enables direct connections between all predicates-arguments pairs.
Agreement with syntax As mentioned in He et al. (2017), their BIO-based SRL system has good agreement with gold syntactic span boundaries (94.3%) but falls short of previous syntaxbased systems (Punyakanok et al., 2004).",5 Analysis,[0],[0]
"By directly modeling span information, our model achieves comparable syntactic agreement (95.0%) to Punyakanok et al. (2004) without explicitly modeling syntax.
",5 Analysis,[0],[0]
"Global consistency On the other hand, our model suffers from global consistency issues.",5 Analysis,[0],[0]
"For example, on the CoNLL 2005 test set, our model has lower complete-predicate accuracy (62.6%) than the BIO systems (He et al., 2017; Tan et al., 2018) (64.3%-66.4%).",5 Analysis,[0],[0]
"Table 3 shows its viola-
tions of global structural constraints5 compared to previous systems.",5 Analysis,[0],[0]
Our model made more constraint violations compared to previous systems.,5 Analysis,[0],[0]
"For example, our model predicts duplicate core arguments6 (shown in the U column in Table 3) more often than previous work.",5 Analysis,[0],[0]
"This is due to the fact that our model uses independent classifiers to label each predicate-argument pair, making it difficult for them to implicitly track the decisions made for several arguments with the same predicate.
",5 Analysis,[0],[0]
"The Ours+decode row in Table 3 shows SRL performance after enforcing the U-constraint using dynamic programming (Täckström et al., 2015) at decoding time.",5 Analysis,[0],[0]
"Constrained decoding at test time is effective at eliminating all the core-role inconsistencies (shown in the U-column), but did not bring significant gain on the end result (shown
5Punyakanok et al. (2008) described a list of global constraints for SRL systems, e.g., there can be at most one core argument of each type for each predicate.
6Arguments with labels ARG0,ARG1,. . .",5 Analysis,[0],[0]
",",5 Analysis,[0],[0]
"ARG5 and AA.
in SRL F1), which only evaluates the piece-wise predicate-argument structures.",5 Analysis,[0],[0]
"We proposed a new SRL model that is able to jointly predict all predicates and argument spans, generalized from a recent coreference system (Lee et al., 2017).",6 Conclusion and Future Work,[0],[0]
"Compared to previous BIO systems, our new model supports joint predicate identification and is able to incorporate span-level features.",6 Conclusion and Future Work,[0],[0]
"Empirically, the model does better at longrange dependencies and agreement with syntactic boundaries, but is weaker at global consistency, due to our strong independence assumption.
",6 Conclusion and Future Work,[0],[0]
"In the future, we could incorporate higher-order inference methods (Lee et al., 2018) to relax this assumption.",6 Conclusion and Future Work,[0],[0]
"It would also be interesting to combine our span-based architecture with the selfattention layers (Tan et al., 2018; Strubell et al., 2018) for more effective contextualization.",6 Conclusion and Future Work,[0],[0]
"This research was supported in part by the ARO (W911NF-16-1-0121), the NSF (IIS-1252835, IIS-1562364), a gift from Tencent, and an Allen Distinguished Investigator Award.",Acknowledgments,[0],[0]
"We thank Eunsol Choi, Dipanjan Das, Nicholas Fitzgerald, Ariel Holtzman, Julian Michael, Noah Smith, Swabha Swayamdipta, and our anonymous reviewers for helpful feedback.",Acknowledgments,[0],[0]
"Recent BIO-tagging-based neural semantic role labeling models are very high performing, but assume gold predicates as part of the input and cannot incorporate span-level features.",abstractText,[0],[0]
"We propose an endto-end approach for jointly predicting all predicates, arguments spans, and the relations between them.",abstractText,[0],[0]
"The model makes independent decisions about what relationship, if any, holds between every possible word-span pair, and learns contextualized span representations that provide rich, shared input features for each decision.",abstractText,[0],[0]
Experiments demonstrate that this approach sets a new state of the art on PropBank SRL without gold predicates.1,abstractText,[0],[0]
Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 401–406 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
401",text,[0],[0]
"Neural NER trains a deep neural network for the NER task and has become quite popular as they minimize the need for hand-crafted features and, learn feature representations from the training data itself.",1 Introduction,[0],[0]
"Recently, multilingual learning has been shown to benefit Neural NER in a resource-rich language setting (Gillick et al., 2016; Yang et al., 2017).",1 Introduction,[0],[0]
Multilingual learning aims to improve the NER performance on the language under consideration (primary language) by adding training data from one or more assisting languages.,1 Introduction,[0],[0]
The neural network is trained on the combined data of the primary (DP ) and the assisting languages (DA).,1 Introduction,[0],[0]
"The neural network has a combination of languagedependent and language-independent layers, and, the network learns better cross-lingual features via these language-independent layers.
∗This work began when the second author was a research scholar at IIT Bombay
Existing approaches add all training sentences from the assisting language to the primary language and train the neural network on the combined data.",1 Introduction,[0],[0]
"However, data from assisting languages can introduce a drift in the tag distribution for named entities, since the common named entities from the two languages may have vastly divergent tag distributions.",1 Introduction,[0],[0]
"For example, the entity China appears in training split of Spanish (primary) and English (assisting) (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003) with the corresponding tag frequencies, Spanish = { Loc : 20, Org : 49, Misc : 1 } and English = { Loc : 91, Org : 7 }.",1 Introduction,[0],[0]
"By adding English data to Spanish, the tag distribution of China is skewed towards Location entity in Spanish.",1 Introduction,[0],[0]
This leads to a drop in named entity recognition performance.,1 Introduction,[0],[0]
"In this work, we address this problem of drift in tag distribution owing to adding training data from a supporting language.
",1 Introduction,[0],[0]
"The problem is similar to the problem of data selection for domain adaptation of various NLP tasks, except that additional complexity is introduced due to the multilingual nature of the learning task.",1 Introduction,[0],[0]
"For domain adaptation in various NLP tasks, several approaches have been proposed to address drift in data distribution (Moore and Lewis, 2010; Axelrod et al., 2011; Ruder and Plank, 2017).",1 Introduction,[0],[0]
"For instance, in machine translation, sentences from out-of-domain data are selected based on a suitably defined metric (Moore and Lewis, 2010; Axelrod et al., 2011).",1 Introduction,[0],[0]
The metric attempts to capture similarity of the out-of-domain sentences with the in-domain data.,1 Introduction,[0],[0]
"Out-of-domain sentences most similar to the in-domain data are added.
",1 Introduction,[0],[0]
"Like the domain adaptation techniques summarized above, we propose to judiciously add sentences from the assisting language to the primary language data based on the divergence between the tag distributions of named entities in the train-
ing instances.",1 Introduction,[0],[0]
"Adding assisting language sentences with lower divergence reduces the possibility of entity drift enabling the multilingual model to learn better cross-lingual features.
",1 Introduction,[0],[0]
Following are the contributions of the paper: (a) We present a simple approach to select assisting language sentences based on symmetric KLDivergence of overlapping entities (b) We demonstrate the benefits of multilingual Neural NER on low-resource languages.,1 Introduction,[0],[0]
"We compare the proposed data selection approach with monolingual Neural NER system, and the multilingual Neural NER system trained using all assisting language sentences.",1 Introduction,[0],[0]
"To the best of our knowledge, ours is the first work for judiciously selecting a subset of sentences from an assisting language for multilingual Neural NER.",1 Introduction,[0],[0]
"For every assisting language sentence, we calculate the sentence score based on the average symmetric KL-Divergence score of overlapping entities present in that sentence.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"By overlapping entities, we mean entities whose surface form appears in both the languages’ training data.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"The symmetric KL-Divergence SKL(x), of a named entity x, is defined as follows,
SKL(x) =",2 Judicious Selection of Assisting Language Sentences,[0],[0]
[ KL( Pp(x) || Pa(x) ),2 Judicious Selection of Assisting Language Sentences,[0],[0]
+KL( Pa(x) ||,2 Judicious Selection of Assisting Language Sentences,[0],[0]
Pp(x) ) ] /2,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"(1)
where Pp(x) and Pa(x) are the probability distributions for entity x in the primary (p) and the assisting (a) languages respectively.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"KL refers to the standard KL-Divergence score between the two probability distributions.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
KL-Divergence calculates the distance between the two probability distributions.,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Lower the KLDivergence score, higher is the tag agreement for an entity in both the languages thereby, reducing the possibility of entity drift in multilingual learning.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
Assisting language sentences with the sentence score below a threshold value are added to the primary language data for multilingual learning.,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"If an assisting language sentence contains no overlapping entities, the corresponding sentence score is zero resulting in its selection.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Network Architecture
Several deep learning models (Collobert et al., 2011; Ma and Hovy, 2016; Murthy and Bhattacharyya, 2016; Lample et al., 2016; Yang et al., 2017) have been proposed for monolingual NER in the literature.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Apart from the model by Collobert et al. (2011), remaining approaches extract sub-word features using either Convolution Neural Networks (CNNs) or Bi-LSTMs.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
The proposed data selection strategy for multilingual Neural NER can be used with any of the existing models.,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"We choose the model by Murthy and Bhattacharyya (2016)1 in our experiments.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Multilingual Learning
We consider two parameter sharing configurations for multilingual learning (i) sub-word feature extractors shared across languages (Yang et al., 2017)",2 Judicious Selection of Assisting Language Sentences,[0],[0]
(Sub-word) (ii) the entire network trained in a language independent way (All).,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"As Murthy and Bhattacharyya (2016) use CNNs to extract sub-word features, only the character-level CNNs are shared for the Sub-word configuration.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
1The code is available here: https://github.com/ murthyrudra/NeuralNER,2 Judicious Selection of Assisting Language Sentences,[0],[0]
In this section we list the datasets used and the network configurations used in our experiments.,3 Experimental Setup,[0],[0]
The Table 1 lists the datasets used in our experiments along with pre-trained word embeddings used and other dataset statistics.,3.1 Datasets,[0],[0]
"For German NER, we use ep-96-04-16.conll to create train and development splits, and use ep-96-04-15.conll as test split.",3.1 Datasets,[0],[0]
"As Italian has a different tag set compared to English, Spanish and Dutch, we do not share output layer for All configuration in multilingual experiments involving Italian.",3.1 Datasets,[0],[0]
"Even though the languages considered are resource-rich languages, we consider German and Italian as primary languages due to their relatively lower number of train tokens.",3.1 Datasets,[0],[0]
"The German NER data followed IO notation and for all experiments involving German, we converted other language data to IO notation.",3.1 Datasets,[0],[0]
"Similarly, the Italian NER data followed IOBES notation and for all experiments involving Italian, we converted other language data to IOBES notation.
",3.1 Datasets,[0],[0]
"For low-resource language setup, we consider the following Indian languages: Hindi, Marathi2, Bengali, Tamil and Malayalam.",3.1 Datasets,[0],[0]
Except for Hindi all are low-resource languages.,3.1 Datasets,[0],[0]
"We consider only Person, Location and Organization tags.",3.1 Datasets,[0],[0]
"Though the scripts of these languages are different, they share the same set of phonemes making script mapping across languages easier.",3.1 Datasets,[0],[0]
"We convert Tamil, Bengali and Malayalam data to the Devanagari script using the Indic NLP li-
2Data is available here: http://www.cfilt.iitb.",3.1 Datasets,[0],[0]
"ac.in/ner/annotated_corpus/
brary3 (Kunchukuttan et al., 2015)",3.1 Datasets,[0],[0]
"thereby, allowing sharing of sub-word features across the Indian languages.",3.1 Datasets,[0],[0]
"For Indian languages, the annotated data followed the IOB format.",3.1 Datasets,[0],[0]
"With the exception of English, Spanish and Dutch, remaining language datasets did not have official train and development splits provided.",3.2 Network Hyper-parameters,[0],[0]
We randomly select 70% of the train split for training the model and remaining as development split.,3.2 Network Hyper-parameters,[0],[0]
"The threshold for sentence score SKL, is selected based on cross-validation for every language pair.",3.2 Network Hyper-parameters,[0],[0]
The dimensions of the Bi-LSTM hidden layer are 200 and 400 for the monolingual and multilingual experiments respectively.,3.2 Network Hyper-parameters,[0],[0]
"We extract 20 features per convolution filter, with width varying from 1 to 9.",3.2 Network Hyper-parameters,[0],[0]
The initial learning rate is 0.4 and multiplied by 0.7 when validation error increases.,3.2 Network Hyper-parameters,[0],[0]
The training is stopped when the learning rate drops below 0.002.,3.2 Network Hyper-parameters,[0],[0]
"We assign a weight of 0.1 to assisting language sentences and oversample primary language sentences to match the assisting language sentence count in all multilingual experiments.
",3.2 Network Hyper-parameters,[0],[0]
"For European languages, we have performed hyper-parameter tuning for both the monolingual and multilingual learning (with all assisting language sentences) configurations.",3.2 Network Hyper-parameters,[0],[0]
The best hyperparameter values for the language pair involved were observed to be within similar range.,3.2 Network Hyper-parameters,[0],[0]
"Hence, we chose the same set of hyper-parameter values for all languages.
",3.2 Network Hyper-parameters,[0],[0]
3https://github.com/anoopkunchukuttan/ indic_nlp_library,3.2 Network Hyper-parameters,[0],[0]
We now present the results on both resource-rich and resource-poor languages.,4 Results,[0],[0]
Table 2 presents the results for German and Italian NER.,4.1 Resource-Rich Languages,[0],[0]
"We consistently observe improvements for German and Italian NER using our data selection strategy, irrespective of whether only subword features are shared (Sub-word) or the entire network (All) is shared across languages.
",4.1 Resource-Rich Languages,[0],[0]
Adding all Spanish/Dutch sentences to Italian data leads to drop in Italian NER performance when all layers are shared.,4.1 Resource-Rich Languages,[0],[0]
Label drift from overlapping entities is one of the reasons for the poor results.,4.1 Resource-Rich Languages,[0],[0]
This can be observed by comparing the histograms of English and Spanish sentences ranked by the SKL scores for Italian multilingual learning (Figure 1).,4.1 Resource-Rich Languages,[0],[0]
Most English sentences have lower SKL scores indicating higher tag agreement for overlapping entities and lower drift in tag distribution.,4.1 Resource-Rich Languages,[0],[0]
"Hence, adding all English sentences improves Italian NER accuracy.",4.1 Resource-Rich Languages,[0],[0]
"In contrast, most Spanish sentences have larger SKL
scores and adding these sentences adversely impacts Italian NER performance.",4.1 Resource-Rich Languages,[0],[0]
"By judiciously selecting assisting language sentences, we eliminate sentences which are responsible for drift occurring during multilingual learning.
",4.1 Resource-Rich Languages,[0],[0]
"To understand how overlapping entities impact the NER performance, we study the statistics of overlapping named entities between ItalianEnglish and Italian-Spanish pairs.",4.1 Resource-Rich Languages,[0],[0]
911 and 916 unique entities out of 4061 unique Italian entities appear in the English and Spanish data respectively.,4.1 Resource-Rich Languages,[0],[0]
We had hypothesized that entities with divergent tag distribution are responsible for hindering the performance in multilingual learning.,4.1 Resource-Rich Languages,[0],[0]
If we sort the common entities based on their SKL divergence value.,4.1 Resource-Rich Languages,[0],[0]
We observe that 484 out of 911 common entities in English and 535 out of 916 common entities in Spanish have an SKL score greater than 1.0. 162 out of 484 common entities in English-Italian data having SKL divergence value greater than 1.0 also appear more than 10 times in the English corpus.,4.1 Resource-Rich Languages,[0],[0]
"Similarly, 123 out of 535 common entities in Spanish-Italian data having SKL divergence value greater than 1.0 also appear more than 10 times in the Spanish corpus.",4.1 Resource-Rich Languages,[0],[0]
"However, these common 162 entities have a combined frequency of 12893 in English, meanwhile the 123 common entities have a combined frequency of 34945 in Spanish.",4.1 Resource-Rich Languages,[0],[0]
"To summarize, although the number of overlapping entities is comparable in English and Spanish sentences, entities with larger SKL divergence score appears more frequently in Spanish sentences compared to English sentences.",4.1 Resource-Rich Languages,[0],[0]
"As a consequence, adding all Spanish sentences leads to significant drop in Italian NER performance which is not the case when all English sentences are added.",4.1 Resource-Rich Languages,[0],[0]
"As Indian languages exhibit high lexical overlap (Kunchukuttan and Bhattacharyya, 2016) and syntactic relatedness (V Subbãrão, 2012), we share all layers of the network across languages.",4.2 Resource-Poor Languages,[0],[0]
Table 3 presents the results.,4.2 Resource-Poor Languages,[0],[0]
"Bengali, Malayalam, and Tamil (low-resource languages) benefits from our data selection strategy.",4.2 Resource-Poor Languages,[0],[0]
"Hindi and Marathi NER performance improves when the other is used as assisting language.
",4.2 Resource-Poor Languages,[0],[0]
"Bengali, Malayalam, and Tamil have weaker baselines compared to Hindi and Marathi, and are benefited from our approach irrespective of the assisting language chosen.",4.2 Resource-Poor Languages,[0],[0]
"However, Hindi and Marathi are not benefited from multilingual learning with Bengali, Malayalam and Tamil.",4.2 Resource-Poor Languages,[0],[0]
Malayalam and Tamil being morphologically rich have low entity overlap (surface level) with Hindi and Marathi.,4.2 Resource-Poor Languages,[0],[0]
"As a result, only 2-3% of Malayalam and Tamil sentences are eliminated from our approach, leading to no gains from multilingual learning.",4.2 Resource-Poor Languages,[0],[0]
Hindi and Marathi are negatively impacted by noisy Bengali data.,4.2 Resource-Poor Languages,[0],[0]
"Bengali has less training sentences compared to other languages and, choosing a low SKL threshold results in selecting very few Bengali sentences for multilingual learning.",4.2 Resource-Poor Languages,[0],[0]
"Here, we study the influence of SKL score threshold on the NER performance.",4.3 Influence of SKL Threshold,[0],[0]
We run experiments for Italian NER by adding Spanish training sentences and sharing all layers except for output layer across languages.,4.3 Influence of SKL Threshold,[0],[0]
"We vary the threshold value from 1.0 to 9.0 in steps of 1, and select sentences with score less than the threshold.",4.3 Influence of SKL Threshold,[0],[0]
"A threshold of 0.0 indicates monolingual training and threshold greater than 9.0 indicates all assist-
ing language sentences considered.",4.3 Influence of SKL Threshold,[0],[0]
The plot of Italian test F-Score against SKL score is shown in the Figure 2.,4.3 Influence of SKL Threshold,[0],[0]
Italian test F-Score increases initially as we add more and more Spanish sentences and then drops due to influence of drift becoming significant.,4.3 Influence of SKL Threshold,[0],[0]
"Finding the right SKL threshold is important, hence we use a validation set to tune the SKL threshold.",4.3 Influence of SKL Threshold,[0],[0]
"In this paper, we address the problem of divergence in tag distribution between primary and assisting languages for multilingual Neural NER.",5 Conclusion,[0],[0]
We show that filtering out the assisting language sentences exhibiting significant divergence in the tag distribution can improve NER accuracy.,5 Conclusion,[0],[0]
We propose to use the symmetric KL-Divergence metric to measure the tag distribution divergence.,5 Conclusion,[0],[0]
We observe consistent improvements in multilingual Neural NER performance using our data selection strategy.,5 Conclusion,[0],[0]
"The strategy shows benefits for extremely low resource primary languages too.
",5 Conclusion,[0],[0]
"This problem of drift in data distribution may not be unique to multilingual NER, and we plan to study the influence of data selection for multilingual learning on other NLP tasks like sentiment analysis, question answering, neural machine translation, etc.",5 Conclusion,[0],[0]
"We also plan to explore more metrics for multilingual learning, specifically for morphologically rich languages.",5 Conclusion,[0],[0]
"We thank Gajanan Rane and Geetanjali Rane for annotating the Marathi data, which was created as part of the CLIA project.",Acknowledgements,[0],[0]
Multilingual learning for Neural Named Entity Recognition (NNER) involves jointly training a neural network for multiple languages.,abstractText,[0],[0]
"Typically, the goal is improving the NER performance of one of the languages (the primary language) using the other assisting languages.",abstractText,[0],[0]
We show that the divergence in the tag distributions of the common named entities between the primary and assisting languages can reduce the effectiveness of multilingual learning.,abstractText,[0],[0]
"To alleviate this problem, we propose a metric based on symmetric KL divergence to filter out the highly divergent training instances in the assisting language.",abstractText,[0],[0]
"We empirically show that our data selection strategy improves NER performance in many languages, including those with very limited training data.",abstractText,[0],[0]
Judicious Selection of Training Data in Assisting Language for Multilingual Neural NER,title,[0],[0]
The key challenge of drug discovery is to find target molecules with desired chemical properties.,1. Introduction,[0],[0]
"Currently, this task takes years of development and exploration by expert chemists and pharmacologists.",1. Introduction,[0],[0]
Our ultimate goal is to automate this process.,1. Introduction,[0],[0]
"From a computational perspective, we decompose the challenge into two complementary subtasks: learning to represent molecules in a continuous manner that facilitates the prediction and optimization of their properties (encoding); and learning to map an optimized continuous representation back into a molecular graph with improved properties (decoding).",1. Introduction,[0],[0]
"While deep learning has been extensively investigated for molecular graph encoding (Duvenaud et al., 2015; Kearnes et al., 2016; Gilmer et al., 2017), the harder combinatorial task of molecular graph generation from latent representation remains under-explored.
",1. Introduction,[0],[0]
1MIT Computer Science & Artificial Intelligence Lab.,1. Introduction,[0],[0]
"Correspondence to: Wengong Jin <wengong@csail.mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"Prior work on drug design formulated the graph generation task as a string generation problem (Gómez-Bombarelli et al., 2016; Kusner et al., 2017) in an attempt to side-step direct generation of graphs.",1. Introduction,[0],[0]
"Specifically, these models start by generating SMILES (Weininger, 1988), a linear string notation used in chemistry to describe molecular structures.",1. Introduction,[0],[0]
"SMILES strings can be translated into graphs via deterministic mappings (e.g., using RDKit (Landrum, 2006)).",1. Introduction,[0],[0]
"However, this design has two critical limitations.",1. Introduction,[0],[0]
"First, the SMILES representation is not designed to capture molecular similarity.",1. Introduction,[0],[0]
"For instance, two molecules with similar chemical structures may be encoded into markedly different SMILES strings (e.g., Figure 1).",1. Introduction,[0],[0]
This prevents generative models like variational autoencoders from learning smooth molecular embeddings.,1. Introduction,[0],[0]
"Second, essential chemical properties such as molecule validity are easier to express on graphs rather than linear SMILES representations.",1. Introduction,[0],[0]
"We hypothesize that operating directly on graphs improves generative modeling of valid chemical structures.
",1. Introduction,[0],[0]
Our primary contribution is a new generative model of molecular graphs.,1. Introduction,[0],[0]
While one could imagine solving the problem in a standard manner – generating graphs node by node – the approach is not ideal for molecules.,1. Introduction,[0],[0]
"This is because creating molecules atom by atom would force the model to generate chemically invalid intermediaries (see, e.g., Figure 2), delaying validation until a complete graph is generated.",1. Introduction,[0],[0]
"Instead, we propose to generate molecular graphs in two phases by exploiting valid subgraphs as components.",1. Introduction,[0],[0]
"The overall generative approach, cast as a junction tree variational autoencoder, first generates a tree structured object (a junction tree) whose role is to represent the scaffold of subgraph components and their coarse relative arrangements.",1. Introduction,[0],[0]
The components are valid chemical substructures automatically extracted from the training set using tree decomposition and are used as building blocks.,1. Introduction,[0],[0]
"In the sec-
ond phase, the subgraphs (nodes in the tree) are assembled together into a coherent molecular graph.
",1. Introduction,[0],[0]
We evaluate our model on multiple tasks ranging from molecular generation to optimization of a given molecule according to desired properties.,1. Introduction,[0],[0]
"As baselines, we utilize state-of-the-art SMILES-based generation approaches (Kusner et al., 2017; Dai et al., 2018).",1. Introduction,[0],[0]
"We demonstrate that our model produces 100% valid molecules when sampled from a prior distribution, outperforming the top performing baseline by a significant margin.",1. Introduction,[0],[0]
"In addition, we show that our model excels in discovering molecules with desired properties, yielding a 30% relative gain over the baselines.",1. Introduction,[0],[0]
"Our approach extends the variational autoencoder (Kingma & Welling, 2013) to molecular graphs by introducing a suitable encoder and a matching decoder.",2. Junction Tree Variational Autoencoder,[0],[0]
"Deviating from previous work (Gómez-Bombarelli et al., 2016; Kusner et al., 2017), we interpret each molecule as having been built from subgraphs chosen out of a vocabulary of valid components.",2. Junction Tree Variational Autoencoder,[0],[0]
These components are used as building blocks both when encoding a molecule into a vector representation as well as when decoding latent vectors back into valid molecular graphs.,2. Junction Tree Variational Autoencoder,[0],[0]
"The key advantage of this view is that the decoder can realize a valid molecule piece by piece by utilizing the collection of valid components and how they interact, rather than trying to build the molecule atom by atom through chemically invalid intermediaries (Figure 2).",2. Junction Tree Variational Autoencoder,[0],[0]
"An aromatic bond, for example, is chemically invalid on its own unless the entire aromatic ring is present.",2. Junction Tree Variational Autoencoder,[0],[0]
"It would be therefore challenging to learn to build rings atom by atom rather than by introducing rings as part of the basic vocabulary.
",2. Junction Tree Variational Autoencoder,[0],[0]
"Our vocabulary of components, such as rings, bonds and individual atoms, is chosen to be large enough so that a given molecule can be covered by overlapping components or clusters of atoms.",2. Junction Tree Variational Autoencoder,[0],[0]
"The clusters serve the role analogous to cliques in graphical models, as they are expressive enough that a molecule can be covered by overlapping clusters without forming cluster cycles.",2. Junction Tree Variational Autoencoder,[0],[0]
"In this sense, the clusters serve as cliques in a (non-optimal) triangulation of the molecular graph.",2. Junction Tree Variational Autoencoder,[0],[0]
We form a junction tree of such clusters and use it as the tree representation of the molecule.,2. Junction Tree Variational Autoencoder,[0],[0]
"Since our choice of cliques is constrained a priori, we cannot guarantee that a junction tree exists with such clusters for an arbitrary
molecule.",2. Junction Tree Variational Autoencoder,[0],[0]
"However, our clusters are built on the basis of the molecules in the training set to ensure that a corresponding junction tree can be found.",2. Junction Tree Variational Autoencoder,[0],[0]
"Empirically, our clusters cover most of the molecules in the test set.
",2. Junction Tree Variational Autoencoder,[0],[0]
The original molecular graph and its associated junction tree offer two complementary representations of a molecule.,2. Junction Tree Variational Autoencoder,[0],[0]
We therefore encode the molecule into a two-part latent representation z,2. Junction Tree Variational Autoencoder,[0],[0]
=,2. Junction Tree Variational Autoencoder,[0],[0]
"[zT , zG] where zT encodes the tree structure and what the clusters are in the tree without fully capturing how exactly the clusters are mutually connected.",2. Junction Tree Variational Autoencoder,[0],[0]
zG encodes the graph to capture the fine-grained connectivity.,2. Junction Tree Variational Autoencoder,[0],[0]
Both parts are created by tree and graph encoders q(zT |T ) and q(zG|G).,2. Junction Tree Variational Autoencoder,[0],[0]
The latent representation is then decoded back into a molecular graph in two stages.,2. Junction Tree Variational Autoencoder,[0],[0]
"As illustrated in Figure 3, we first reproduce the junction tree using a tree decoder p(T |zT )",2. Junction Tree Variational Autoencoder,[0],[0]
based on the information in zT .,2. Junction Tree Variational Autoencoder,[0],[0]
"Second, we predict the fine grain connectivity between the clusters in the junction tree using a graph decoder p(G|T , zG) to realize the full molecular graph.",2. Junction Tree Variational Autoencoder,[0],[0]
"The junction tree approach allows us to maintain chemical feasibility during generation.
",2. Junction Tree Variational Autoencoder,[0],[0]
"Notation A molecular graph is defined as G = (V,E) where V is the set of atoms (vertices) and E the set of bonds (edges).",2. Junction Tree Variational Autoencoder,[0],[0]
Let N(x) be the neighbor of x. We denote sigmoid function as σ(·) and ReLU function as τ(·).,2. Junction Tree Variational Autoencoder,[0],[0]
"We use i, j, k for nodes in the tree and u, v, w for nodes in the graph.",2. Junction Tree Variational Autoencoder,[0],[0]
A tree decomposition maps a graph G into a junction tree by contracting certain vertices into a single node so that G becomes cycle-free.,2.1. Junction Tree,[0],[0]
"Formally, given a graph G, a junction tree TG = (V, E ,X ) is a connected labeled tree whose node set is V = {C1, · · · , Cn} and edge set is E .",2.1. Junction Tree,[0],[0]
"Each node or cluster Ci = (Vi, Ei) is an induced subgraph of G, satisfying the following constraints:
1.",2.1. Junction Tree,[0],[0]
"The union of all clusters equals G. That is, ⋃ i Vi = V
and ⋃ iEi = E.
2.",2.1. Junction Tree,[0],[0]
"Running intersection: For all clusters Ci, Cj and Ck, Vi ∩ Vj ⊆ Vk if Ck is on the path from Ci to Cj .
",2.1. Junction Tree,[0],[0]
"Viewing induced subgraphs as cluster labels, junction trees are labeled trees with label vocabulary X .",2.1. Junction Tree,[0],[0]
"By our molecule tree decomposition, X contains only cycles (rings) and single edges.",2.1. Junction Tree,[0],[0]
"Thus the vocabulary size is limited (|X | = 780 for a standard dataset with 250K molecules).
",2.1. Junction Tree,[0],[0]
"Tree Decomposition of Molecules Here we present our tree decomposition algorithm tailored for molecules, which finds its root in chemistry (Rarey & Dixon, 1998).",2.1. Junction Tree,[0],[0]
Our cluster vocabulary X includes chemical structures such as bonds and rings (Figure 3).,2.1. Junction Tree,[0],[0]
"Given a graphG, we first find all its simple cycles, and its edges not belonging to any cycles.",2.1. Junction Tree,[0],[0]
"Two simple rings are merged together if they have more than two overlapping atoms, as they constitute a specific structure called bridged compounds (Clayden et al., 2001).",2.1. Junction Tree,[0],[0]
Each of those cycles or edges is considered as a cluster.,2.1. Junction Tree,[0],[0]
"Next, a cluster graph is constructed by adding edges between all intersecting clusters.",2.1. Junction Tree,[0],[0]
"Finally, we select one of its spanning trees as the junction tree of G (Figure 3).",2.1. Junction Tree,[0],[0]
"As a result of ring merging, any two clusters in the junction tree have at most two atoms in common, facilitating efficient inference in the graph decoding phase.",2.1. Junction Tree,[0],[0]
The detailed procedure is described in the supplementary.,2.1. Junction Tree,[0],[0]
"We first encode the latent representation of G by a graph message passing network (Dai et al., 2016; Gilmer et al., 2017).",2.2. Graph Encoder,[0],[0]
"Each vertex v has a feature vector xv indicating the atom type, valence, and other properties.",2.2. Graph Encoder,[0],[0]
"Similarly, each edge (u, v) ∈ E has a feature vector xuv indicating its bond type, and two hidden vectors νuv and νvu denoting the message from u to v and vice versa.",2.2. Graph Encoder,[0],[0]
"Due to the loopy structure of the graph, messages are exchanged in a loopy belief propagation fashion:
ν(t)uv = τ(W",2.2. Graph Encoder,[0],[0]
"g 1xu +W g 2xuv +W g 3 ∑ w∈N(u)\v ν(t−1)wu ) (1)
where ν(t)uv is the message computed in t-th iteration, initialized with ν(0)uv = 0.",2.2. Graph Encoder,[0],[0]
"After T steps of iteration, we aggregate
those messages as the latent vector of each vertex, which captures its local graphical structure:
hu =",2.2. Graph Encoder,[0],[0]
"τ(U g 1xu + ∑ v∈N(u) Ug2ν (T ) vu ) (2)
",2.2. Graph Encoder,[0],[0]
The final graph representation is hG = ∑ i hi/|V |.,2.2. Graph Encoder,[0],[0]
The mean µG and log variance logσG of the variational posterior approximation are computed from hG with two separate affine layers.,2.2. Graph Encoder,[0],[0]
"zG is sampled from a Gaussian N (µG,σG).",2.2. Graph Encoder,[0],[0]
We similarly encode TG with a tree message passing network.,2.3. Tree Encoder,[0],[0]
Each cluster Ci is represented by a one-hot encoding xi representing its label type.,2.3. Tree Encoder,[0],[0]
"Each edge (Ci, Cj) is associated with two message vectors mij and mji.",2.3. Tree Encoder,[0],[0]
We pick an arbitrary leaf node as the root and propagate messages in two phases.,2.3. Tree Encoder,[0],[0]
"In the first bottom-up phase, messages are initiated from the leaf nodes and propagated iteratively towards root.",2.3. Tree Encoder,[0],[0]
"In the top-down phase, messages are propagated from the root to all the leaf nodes.",2.3. Tree Encoder,[0],[0]
"Message mij is updated as:
mij = GRU(xi, {mki}k∈N(i)\j) (3)
where GRU is a Gated Recurrent Unit (Chung et al., 2014; Li et al., 2015) adapted for tree message passing:
sij = ∑
k∈N(i)\j mki (4)
",2.3. Tree Encoder,[0],[0]
zij = σ(W zxi +U zsij + b z) (5) rki = σ(W rxi +U rmki + b r),2.3. Tree Encoder,[0],[0]
"(6)
m̃ij = tanh(Wxi +U ∑
k∈N(i)\j
rki mki) (7)
mij = (1− zij) sij + zij m̃ij (8)
The message passing follows the schedule where mij is computed only when all its precursors {mki | k ∈ N(i)\j} have been computed.",2.3. Tree Encoder,[0],[0]
"This architectural design is motivated by the belief propagation algorithm over trees and is thus different from the graph encoder.
",2.3. Tree Encoder,[0],[0]
"After the message passing, we obtain the latent representation of each node hi by aggregating its inward messages:
hi = τ(W oxi + ∑ k∈N(i) Uomki) (9)
",2.3. Tree Encoder,[0],[0]
"The final tree representation is hTG = hroot, which encodes a rooted tree (T , root).",2.3. Tree Encoder,[0],[0]
"Unlike the graph encoder, we do not apply node average pooling because it confuses the tree decoder which node to generate first.",2.3. Tree Encoder,[0],[0]
zTG is sampled in a similar way as in the graph encoder.,2.3. Tree Encoder,[0],[0]
"For simplicity, we abbreviate zTG as zT from now on.
",2.3. Tree Encoder,[0],[0]
This tree encoder plays two roles in our framework.,2.3. Tree Encoder,[0],[0]
"First, it is used to compute zT , which only requires the bottom-up phase of the network.",2.3. Tree Encoder,[0],[0]
"Second, after a tree T̂ is decoded
from zT , it is used to compute messages m̂ij over the entire T̂ , to provide essential contexts of every node during graph decoding.",2.3. Tree Encoder,[0],[0]
This requires both top-down and bottom-up phases.,2.3. Tree Encoder,[0],[0]
We will elaborate this in section 2.5.,2.3. Tree Encoder,[0],[0]
We decode a junction tree T from its encoding zT with a tree structured decoder.,2.4. Tree Decoder,[0],[0]
The tree is constructed in a top-down fashion by generating one node at a time.,2.4. Tree Decoder,[0],[0]
"As illustrated in Figure 4, our tree decoder traverses the entire tree from the root, and generates nodes in their depth-first order.",2.4. Tree Decoder,[0],[0]
"For every visited node, the decoder first makes a topological prediction: whether this node has children to be generated.",2.4. Tree Decoder,[0],[0]
"When a new child node is created, we predict its label and recurse this process.",2.4. Tree Decoder,[0],[0]
Recall that cluster labels represent subgraphs in a molecule.,2.4. Tree Decoder,[0],[0]
"The decoder backtracks when a node has no more children to generate.
",2.4. Tree Decoder,[0],[0]
"At each time step, a node receives information from other nodes in the current tree for making those predictions.",2.4. Tree Decoder,[0],[0]
The information is propagated through message vectors hij when trees are incrementally constructed.,2.4. Tree Decoder,[0],[0]
"Formally, let Ẽ = {(i1, j1), · · · , (im, jm)} be the edges traversed in a depth first traversal over T = (V, E), where m = 2|E| as each edge is traversed in both directions.",2.4. Tree Decoder,[0],[0]
The model visits node it at time t. Let Ẽt be the first t edges in Ẽ .,2.4. Tree Decoder,[0],[0]
"The message hit,jt is updated through previous messages:
hit,jt = GRU(xit , {hk,it}(k,it)∈Ẽt,k 6=jt) (10)
where GRU is the same recurrent unit as in the tree encoder.
",2.4. Tree Decoder,[0],[0]
"Topological Prediction When the model visits node it, it makes a binary prediction on whether it still has children to be generated.",2.4. Tree Decoder,[0],[0]
"We compute this probability by combining
Algorithm 1 Tree decoding at sampling time Require:",2.4. Tree Decoder,[0],[0]
"Latent representation zT
1: Initialize: Tree T̂ ← ∅ 2: function SampleTree(i, t) 3:",2.4. Tree Decoder,[0],[0]
Set Xi ← all cluster labels that are chemically compatible with node i and its current neighbors.,2.4. Tree Decoder,[0],[0]
4: Set dt ← expand with probability pt. .,2.4. Tree Decoder,[0],[0]
Eq.(11) 5:,2.4. Tree Decoder,[0],[0]
if dt = expand and Xi 6= ∅,2.4. Tree Decoder,[0],[0]
then 6: Create a node j and add it to tree T̂ .,2.4. Tree Decoder,[0],[0]
"7: Sample the label of node j from Xi .. Eq.(12) 8: SampleTree(j, t+ 1) 9: end if
10: end function
zT , node features xit and inward messages hk,it via a one hidden layer network followed by a sigmoid function:
pt = σ(u d ·τ(Wd1xit+Wd2zT +Wd3 ∑ (k,it)∈Ẽt hk,it) (11)
Label Prediction When a child node j is generated from its parent i, we predict its node label with
qj = softmax(Ulτ(Wl1zT",2.4. Tree Decoder,[0],[0]
+,2.4. Tree Decoder,[0],[0]
W l 2hij)),2.4. Tree Decoder,[0],[0]
"(12)
where qj is a distribution over label vocabulary X .",2.4. Tree Decoder,[0],[0]
"When j is a root node, its parent i is a virtual node and hij = 0.
",2.4. Tree Decoder,[0],[0]
Learning The tree decoder aims to maximize the likelihood p(T |zT ).,2.4. Tree Decoder,[0],[0]
"Let p̂t ∈ {0, 1} and q̂j be the ground truth topological and label values, the decoder minimizes the following cross entropy loss:1
Lc(T ) =",2.4. Tree Decoder,[0],[0]
"∑
t Ld(pt, p̂t)",2.4. Tree Decoder,[0],[0]
"+ ∑ j Ll(qj , q̂j) (13)
",2.4. Tree Decoder,[0],[0]
"Similar to sequence generation, during training we perform teacher forcing: after topological and label prediction at each step, we replace them with their ground truth so that the model makes predictions given correct histories.
",2.4. Tree Decoder,[0],[0]
Decoding & Feasibility Check Algorithm 1 shows how a tree is sampled from zT .,2.4. Tree Decoder,[0],[0]
The tree is constructed recursively guided by topological predictions without any external guidance used in training.,2.4. Tree Decoder,[0],[0]
"To ensure the sampled tree could be realized into a valid molecule, we define set Xi to be cluster labels that are chemically compatible with node i and its current neighbors.",2.4. Tree Decoder,[0],[0]
"When a child node j is generated from node i, we sample its label from Xi with a renormalized distribution qj over Xi by masking out invalid labels.",2.4. Tree Decoder,[0],[0]
"The final step of our model is to reproduce a molecular graph G that underlies the predicted junction tree T̂ = (V̂, Ê).
",2.5. Graph Decoder,[0],[0]
1The node ordering is not unique as the order within sibling nodes is ambiguous.,2.5. Graph Decoder,[0],[0]
"In this paper we train our model with one ordering and leave this issue for future work.
",2.5. Graph Decoder,[0],[0]
Note that this step is not deterministic since there are potentially many molecules that correspond to the same junction tree.,2.5. Graph Decoder,[0],[0]
The underlying degree of freedom pertains to how neighboring clusters Ci and Cj are attached to each other as subgraphs.,2.5. Graph Decoder,[0],[0]
"Our goal here is to assemble the subgraphs (nodes in the tree) together into the correct molecular graph.
",2.5. Graph Decoder,[0],[0]
Let G(T ) be the set of graphs whose junction tree is T .,2.5. Graph Decoder,[0],[0]
"Decoding graph Ĝ from T̂ = (V̂, Ê) is a structured prediction:
Ĝ = arg max G′∈G(T̂ )
",2.5. Graph Decoder,[0],[0]
"fa(G′) (14)
where fa is a scoring function over candidate graphs.",2.5. Graph Decoder,[0],[0]
We only consider scoring functions that decompose across the clusters and their neighbors.,2.5. Graph Decoder,[0],[0]
"In other words, each term in the scoring function depends only on how a cluster Ci is attached to its neighboring clusters",2.5. Graph Decoder,[0],[0]
"Cj , j ∈ NT̂ (i) in the tree T̂ .",2.5. Graph Decoder,[0],[0]
The problem of finding the highest scoring graph Ĝ – the assembly task – could be cast as a graphical model inference task in a model induced by the junction tree.,2.5. Graph Decoder,[0],[0]
"However, for efficiency reasons, we will assemble the molecular graph one neighborhood at a time, following the order in which the tree itself was decoded.",2.5. Graph Decoder,[0],[0]
"In other words, we start by sampling the assembly of the root and its neighbors according to their
scores.",2.5. Graph Decoder,[0],[0]
"Then we proceed to assemble the neighbors and their associated clusters (removing the degrees of freedom set by the root assembly), and so on.
",2.5. Graph Decoder,[0],[0]
It remains to be specified how each neighborhood realization is scored.,2.5. Graph Decoder,[0],[0]
"Let Gi be the subgraph resulting from a particular merging of cluster Ci in the tree with its neighbors Cj , j ∈ NT̂ (i).",2.5. Graph Decoder,[0],[0]
We score Gi as a candidate subgraph by first deriving a vector representation hGi and then using fai (Gi) = hGi · zG as the subgraph score.,2.5. Graph Decoder,[0],[0]
"To this end, let u, v specify atoms in the candidate subgraph Gi and let αv = i",2.5. Graph Decoder,[0],[0]
if v ∈ Ci and αv = j if v ∈,2.5. Graph Decoder,[0],[0]
Cj \ Ci.,2.5. Graph Decoder,[0],[0]
"The indices αv are used to mark the position of the atoms in the junction tree, and to retrieve messages m̂i,j summarizing the subtree under i along the edge (i, j) obtained by running the tree encoding algorithm.",2.5. Graph Decoder,[0],[0]
"The neural messages pertaining to the atoms and bonds in subgraph Gi are obtained and aggregated into hGi , similarly to the encoding step, but with different (learned) parameters:
µ(t)uv = τ(W a 1xu +W a 2xuv +W a 3µ̃ (t−1) uv ) (15)
µ̃(t−1)uv =
{∑ w∈N(u)\v µ (t−1) wu",2.5. Graph Decoder,[0],[0]
"αu = αv
m̂αu,αv + ∑ w∈N(u)\v µ",2.5. Graph Decoder,[0],[0]
(t−1) wu,2.5. Graph Decoder,[0],[0]
"αu 6= αv
The major difference from Eq.",2.5. Graph Decoder,[0],[0]
"(1) is that we augment the model with tree messages m̂αu,αv derived by running the tree encoder over the predicted tree T̂ .",2.5. Graph Decoder,[0],[0]
"m̂αu,αv provides a tree dependent positional context for bond (u, v) (illustrated as subtree A in Figure 5).
",2.5. Graph Decoder,[0],[0]
"Learning The graph decoder parameters are learned to maximize the log-likelihood of predicting correct subgraphs Gi of the ground true graph G at each tree node:
Lg(G)",2.5. Graph Decoder,[0],[0]
= ∑ i fa(Gi)− log ∑ G′i∈Gi exp(fa(G′i))  ,2.5. Graph Decoder,[0],[0]
"(16) where Gi is the set of possible candidate subgraphs at tree node i. During training, we again apply teacher forcing, i.e. we feed the graph decoder with ground truth trees as input.
",2.5. Graph Decoder,[0],[0]
Complexity,2.5. Graph Decoder,[0],[0]
"By our tree decomposition, any two clusters share at most two atoms, so we only need to merge at most two atoms or one bond.",2.5. Graph Decoder,[0],[0]
"By pruning chemically invalid subgraphs and merging isomorphic graphs, |Gi| ≈ 4 on average when tested on a standard ZINC drug dataset.",2.5. Graph Decoder,[0],[0]
"The computational complexity of JT-VAE is therefore linear in the number of clusters, scaling nicely to large graphs.",2.5. Graph Decoder,[0],[0]
Our evaluation efforts measure various aspects of molecular generation.,3. Experiments,[0],[0]
"The first two evaluations follow previously proposed tasks (Kusner et al., 2017).",3. Experiments,[0],[0]
"We also introduce a third task — constrained molecule optimization.
",3. Experiments,[0],[0]
"• Molecule reconstruction and validity We test the VAE models on the task of reconstructing input molecules from their latent representations, and decoding valid molecules when sampling from prior distribution.",3. Experiments,[0],[0]
(Section 3.1) •,3. Experiments,[0],[0]
"Bayesian optimization Moving beyond generating valid
molecules, we test how the model can produce novel molecules with desired properties.",3. Experiments,[0],[0]
"To this end, we perform Bayesian optimization in the latent space to search molecules with specified properties.",3. Experiments,[0],[0]
"(Section 3.2)
• Constrained molecule optimization The task is to modify given molecules to improve specified properties, while constraining the degree of deviation from the original molecule.",3. Experiments,[0],[0]
"This is a more realistic scenario in drug discovery, where development of new drugs usually starts with known molecules such as existing drugs (Besnard et al., 2012).",3. Experiments,[0],[0]
"Since it is a new task, we cannot compare to any existing baselines.",3. Experiments,[0],[0]
"(Section 3.3)
",3. Experiments,[0],[0]
"Below we describe the data, baselines and model configuration that are shared across the tasks.",3. Experiments,[0],[0]
"Additional setup details are provided in the task-specific sections.
",3. Experiments,[0],[0]
"Data We use the ZINC molecule dataset from Kusner et al. (2017) for our experiments, with the same training/testing split.",3. Experiments,[0],[0]
"It contains about 250K drug molecules extracted from the ZINC database (Sterling & Irwin, 2015).
",3. Experiments,[0],[0]
"Baselines We compare our approach with SMILES-based baselines: 1) Character VAE (CVAE) (Gómez-Bombarelli et al., 2016) which generates SMILES strings character by character; 2) Grammar VAE (GVAE) (Kusner et al., 2017) that generates SMILES following syntactic constraints given
by a context-free grammar; 3) Syntax-directed VAE (SDVAE) (Dai et al., 2018) that incorporates both syntactic and semantic constraints of SMILES via attribute grammar.",3. Experiments,[0],[0]
"For molecule generation task, we also compare with GraphVAE (Simonovsky & Komodakis, 2018) that directly generates atom labels and adjacency matrices of graphs.
",3. Experiments,[0],[0]
"Model Configuration To be comparable with the above baselines, we set the latent space dimension as 56, i.e., the tree and graph representation hT and hG have 28 dimensions each.",3. Experiments,[0],[0]
Full training details and model configurations are provided in the appendix.,3. Experiments,[0],[0]
Setup The first task is to reconstruct and sample molecules from latent space.,3.1. Molecule Reconstruction and Validity,[0],[0]
"Since both encoding and decoding process are stochastic, we estimate reconstruction accuracy by Monte Carlo method used in (Kusner et al., 2017):",3.1. Molecule Reconstruction and Validity,[0],[0]
Each molecule is encoded 10 times and each encoding is decoded 10 times.,3.1. Molecule Reconstruction and Validity,[0],[0]
"We report the portion of the 100 decoded molecules that are identical to the input molecule.
",3.1. Molecule Reconstruction and Validity,[0],[0]
"To compute validity, we sample 1000 latent vectors from the prior distribution N (0, I), and decode each of these vectors 100 times.",3.1. Molecule Reconstruction and Validity,[0],[0]
We report the percentage of decoded molecules that are chemically valid (checked by RDKit).,3.1. Molecule Reconstruction and Validity,[0],[0]
"For ablation study, we also report the validity of our model without validity check in decoding phase.
",3.1. Molecule Reconstruction and Validity,[0],[0]
"Results Table 1 shows that JT-VAE outperforms previous models in molecule reconstruction, and always pro-
duces valid molecules when sampled from prior distribution.",3.1. Molecule Reconstruction and Validity,[0],[0]
"When validity check is removed, our model could still generates 93.5% valid molecules.",3.1. Molecule Reconstruction and Validity,[0],[0]
This shows our method does not heavily rely on prior knowledge.,3.1. Molecule Reconstruction and Validity,[0],[0]
"As shown in Figure 6, the sampled molecules have non-trivial structures such as simple chains.",3.1. Molecule Reconstruction and Validity,[0],[0]
We further sampled 5000 molecules from prior and found they are all distinct from the training set.,3.1. Molecule Reconstruction and Validity,[0],[0]
"Thus our model is not a simple memorization.
",3.1. Molecule Reconstruction and Validity,[0],[0]
Analysis We qualitatively examine the latent space of JTVAE by visualizing the neighborhood of molecules.,3.1. Molecule Reconstruction and Validity,[0],[0]
"Given a molecule, we follow the method in Kusner et al. (2017) to construct a grid visualization of its neighborhood.",3.1. Molecule Reconstruction and Validity,[0],[0]
Figure 6 shows the local neighborhood of the same molecule visualized in Dai et al. (2018).,3.1. Molecule Reconstruction and Validity,[0],[0]
"In comparison, our neighborhood does not contain molecules with huge rings (with more than 7 atoms), which rarely occur in the dataset.",3.1. Molecule Reconstruction and Validity,[0],[0]
We also highlight two groups of closely resembling molecules that have identical tree structures but vary only in how clusters are attached together.,3.1. Molecule Reconstruction and Validity,[0],[0]
This demonstrates the smoothness of learned molecular embeddings.,3.1. Molecule Reconstruction and Validity,[0],[0]
Setup The second task is to produce novel molecules with desired properties.,3.2. Bayesian Optimization,[0],[0]
"Following (Kusner et al., 2017), our target chemical property y(·) is octanol-water partition coefficients (logP) penalized by the synthetic accessibility (SA) score and number of long cycles.2 To perform Bayesian optimization (BO), we first train a VAE and associate each molecule with a latent vector, given by the mean of the variational encoding distribution.",3.2. Bayesian Optimization,[0],[0]
"After the VAE is learned, we train a sparse Gaussian process (SGP) to predict y(m) given its latent representation.",3.2. Bayesian Optimization,[0],[0]
"Then we perform five iterations of batched BO using the expected improvement heuristic.
",3.2. Bayesian Optimization,[0],[0]
"For comparison, we report 1) the predictive performance of SGP trained on latent encodings learned by different VAEs, measured by log-likelihood (LL) and root mean square error (RMSE) with 10-fold cross validation.",3.2. Bayesian Optimization,[0],[0]
"2) The top-3 molecules found by BO under different models.
2y(m) = logP (m) − SA(m)",3.2. Bayesian Optimization,[0],[0]
"− cycle(m) where cycle(m) counts the number of rings that have more than six atoms.
",3.2. Bayesian Optimization,[0],[0]
"Results As shown in Table 2, JT-VAE finds molecules with significantly better scores than previous methods.",3.2. Bayesian Optimization,[0],[0]
Figure 7 lists the top-3 best molecules found by JT-VAE.,3.2. Bayesian Optimization,[0],[0]
"In fact, JT-VAE finds over 50 molecules with scores over 3.50 (the second best molecule proposed by SD-VAE).",3.2. Bayesian Optimization,[0],[0]
"Moreover, the SGP yields better predictive performance when trained on JT-VAE embeddings (Table 3).",3.2. Bayesian Optimization,[0],[0]
Setup The third task is to perform molecule optimization in a constrained scenario.,3.3. Constrained Optimization,[0],[0]
"Given a molecule m, the task is to find a different molecule m′ that has the highest property value with the molecular similarity sim(m,m′)",3.3. Constrained Optimization,[0],[0]
≥ δ for some threshold δ.,3.3. Constrained Optimization,[0],[0]
"We use Tanimoto similarity with Morgan fingerprint (Rogers & Hahn, 2010) as the similarity metric, and penalized logP coefficient as our target chemical property.",3.3. Constrained Optimization,[0],[0]
"For this task, we jointly train a property predictor F (parameterized by a feed-forward network) with JT-VAE to predict y(m) from the latent embedding of m. To optimize a molecule m, we start from its latent representation, and apply gradient ascent in the latent space to improve the predicted score F (·), similar to (Mueller et al., 2017).",3.3. Constrained Optimization,[0],[0]
"After applying K = 80 gradient steps, K molecules are decoded from resulting latent trajectories, and we report the molecule with the highest F (·) that satisfies the similarity constraint.",3.3. Constrained Optimization,[0],[0]
"A modification succeeds if one of the decoded molecules satisfies the constraint and is distinct from the original.
",3.3. Constrained Optimization,[0],[0]
"To provide the greatest challenge, we selected 800 molecules with the lowest property score y(·) from the test set.",3.3. Constrained Optimization,[0],[0]
"We report the success rate (how often a modification succeeds), and among success cases the average improvement y(m′)− y(m) and molecular similarity sim(m,m′) between the original and modified molecules m and m′.
Results Our results are summarized in Table 4.",3.3. Constrained Optimization,[0],[0]
"The unconstrained scenario (δ = 0) has the best average improvement, but often proposes dissimilar molecules.",3.3. Constrained Optimization,[0],[0]
"When we tighten the constraint to δ = 0.4, about 80% of the time our model finds similar molecules, with an average improvement 0.84.",3.3. Constrained Optimization,[0],[0]
This also demonstrates the smoothness of the learned latent space.,3.3. Constrained Optimization,[0],[0]
Figure 8 illustrates an effective modification resulting in a similar molecule with great improvement.,3.3. Constrained Optimization,[0],[0]
Molecule Generation Previous work on molecule generation mostly operates on SMILES strings.,4. Related Work,[0],[0]
GómezBombarelli,4. Related Work,[0],[0]
et al. (2016); Segler et al. (2017) built generative models of SMILES strings with recurrent decoders.,4. Related Work,[0],[0]
"Unfortunately, these models could generate invalid SMILES that do not result in any molecules.",4. Related Work,[0],[0]
"To remedy this issue, Kusner et al. (2017); Dai et al. (2018) complemented the decoder with syntactic and semantic constraints of SMILES by context free and attribute grammars, but these grammars do not fully capture chemical validity.",4. Related Work,[0],[0]
"Other techniques such as active learning (Janz et al., 2017) and reinforcement learning (Guimaraes et al., 2017) encourage the model to generate valid SMILES through additional training signal.",4. Related Work,[0],[0]
"Very recently, Simonovsky & Komodakis (2018) proposed to generate molecular graphs by predicting their adjacency matrices, and Li et al. (2018) generated molecules node by node.",4. Related Work,[0],[0]
"In comparison, our method enforces chemical validity and is more efficient due to the coarse-to-fine generation.
",4. Related Work,[0],[0]
Graph-structured Encoders,4. Related Work,[0],[0]
"The neural network formulation on graphs was first proposed by Gori et al. (2005); Scarselli et al. (2009), and later enhanced by Li et al. (2015) with gated recurrent units.",4. Related Work,[0],[0]
"For recurrent architectures over
graphs, Lei et al. (2017) designed Weisfeiler-Lehman kernel network inspired by graph kernels.",4. Related Work,[0],[0]
"Dai et al. (2016) considered a different architecture where graphs were viewed as latent variable graphical models, and derived their model from message passing algorithms.",4. Related Work,[0],[0]
"Our tree and graph encoder are closely related to this graphical model perspective, and to neural message passing networks (Gilmer et al., 2017).",4. Related Work,[0],[0]
"For convolutional architectures, Duvenaud et al. (2015) introduced a convolution-like propagation on molecular graphs, which was generalized to other domains by Niepert et al. (2016).",4. Related Work,[0],[0]
Bruna et al. (2013); Henaff et al. (2015) developed graph convolution in spectral domain via graph Laplacian.,4. Related Work,[0],[0]
"For applications, graph neural networks are used in semisupervised classification (Kipf & Welling, 2016), computer vision (Monti et al., 2016), and chemical domains (Kearnes et al., 2016; Schütt et al., 2017; Jin et al., 2017).
",4. Related Work,[0],[0]
Tree-structured Models,4. Related Work,[0],[0]
"Our tree encoder is related to recursive neural networks and tree-LSTM (Socher et al., 2013; Tai et al., 2015; Zhu et al., 2015).",4. Related Work,[0],[0]
These models encode tree structures where nodes in the tree are bottom-up transformed into vector representations.,4. Related Work,[0],[0]
"In contrast, our model propagates information both bottom-up and top-down.
",4. Related Work,[0],[0]
"On the decoding side, tree generation naturally arises in natural language parsing (Dyer et al., 2016; Kiperwasser & Goldberg, 2016).",4. Related Work,[0],[0]
"Different from our approach, natural language parsers have access to input words and only predict the topology of the tree.",4. Related Work,[0],[0]
"For general purpose tree generation, Vinyals et al. (2015); Aharoni & Goldberg (2017) applied recurrent networks to generate linearized version of trees, but their architectures were entirely sequence-based.",4. Related Work,[0],[0]
Dong & Lapata (2016); Alvarez-Melis & Jaakkola (2016) proposed tree-based architectures that construct trees top-down from the root.,4. Related Work,[0],[0]
"Our model is most closely related to Alvarez-Melis & Jaakkola (2016) that disentangles topological prediction from label prediction, but we generate nodes in a depth-first order and have additional steps that propagate information bottom-up.",4. Related Work,[0],[0]
"This forward-backward propagation also appears in Parisotto et al. (2016), but their model is node based whereas ours is based on message passing.",4. Related Work,[0],[0]
In this paper we present a junction tree variational autoencoder for generating molecular graphs.,5. Conclusion,[0],[0]
Our method significantly outperforms previous work in molecule generation and optimization.,5. Conclusion,[0],[0]
"For future work, we attempt to generalize our method for general low-treewidth graphs.",5. Conclusion,[0],[0]
"We thank Jonas Mueller, Chengtao Li, Tao Lei and MIT NLP Group for their helpful comments.",Acknowledgement,[0],[0]
This work was supported by the DARPA Make-It program under contract ARO W911NF-16-2-0023.,Acknowledgement,[0],[0]
We seek to automate the design of molecules based on specific chemical properties.,abstractText,[0],[0]
"In computational terms, this task involves continuous embedding and generation of molecular graphs.",abstractText,[0],[0]
"Our primary contribution is the direct realization of molecular graphs, a task previously approached by generating linear SMILES strings instead of graphs.",abstractText,[0],[0]
"Our junction tree variational autoencoder generates molecular graphs in two phases, by first generating a tree-structured scaffold over chemical substructures, and then combining them into a molecule with a graph message passing network.",abstractText,[0],[0]
This approach allows us to incrementally expand molecules while maintaining chemical validity at every step.,abstractText,[0],[0]
We evaluate our model on multiple tasks ranging from molecular generation to optimization.,abstractText,[0],[0]
"Across these tasks, our model outperforms previous state-of-the-art baselines by a significant margin.",abstractText,[0],[0]
Junction Tree Variational Autoencoder for Molecular Graph Generation,title,[0],[0]
"by using adaptively chosen pairwise comparisons. Our goal is to recover the ranking accurately but to sample the comparisons sparingly. If all comparison outcomes are consistent with the ranking, the optimal solution is to use an efficient sorting algorithm, such as Quicksort. But how do sorting algorithms behave if some comparison outcomes are inconsistent with the ranking? We give favorable guarantees for Quicksort for the popular Bradley–Terry model, under natural assumptions on the parameters. Furthermore, we empirically demonstrate that sorting algorithms lead to a very simple and effective active learning strategy: repeatedly sort the items. This strategy performs as well as state-of-the-art methods (and much better than random sampling) at a minuscule fraction of the computational cost.",text,[0],[0]
"The problem of recovering a ranking over n items from noisy outcomes of pairwise comparisons has attracted, in the last century, much research interest, driven by applications in sports (Elo, 1978), social sciences (Thurstone, 1927; Salganik & Levy, 2015) and—more recently—recommender systems (Houlsby et al., 2012).",1 Introduction,[0],[0]
"Whereas pairwise comparison models and related inference algorithms have been extensively studied, the issue of which pairwise comparisons to sample, also known as active learning, has received significantly less attention.",1 Introduction,[0],[0]
"To understand the potential benefits of adaptively selecting samples, consider the case where comparison outcomes are noiseless, i.e., consistent with a linear order on a set of n items.",1 Introduction,[0],[0]
"If pairs of items are selected at random, it is necessary to collect Ω(n2) comparisons to recover the ranking (Alon et al., 1994).",1 Introduction,[0],[0]
"In contrast, by using an efficient sorting algorithm, O(n log n) adaptively
1School of Computer and Communication Sciences, EPFL, Lausanne, Switzerland.",1 Introduction,[0],[0]
"Correspondence to: Lucas Maystre <lucas.maystre@epfl.ch>.
",1 Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1 Introduction,[0],[0]
"Copyright 2017 by the author(s).
chosen comparisons are sufficient.",1 Introduction,[0],[0]
"In this work, we demonstrate that sorting algorithms can also be helpful in the noisy setting, where some comparison outcomes are inconsistent with the ranking: despite errors, sorting algorithms tend to select informative samples.",1 Introduction,[0],[0]
"We focus on the Bradley–Terry (BT) model, a widely-used probabilistic model of comparison outcomes.",1 Introduction,[0],[0]
"In this model, each item is associated with a parameter on the real line, and the probability of observing an incorrect outcome decreases as the distance between the items’ parameters increases.
",1 Introduction,[0],[0]
"First, we study the output of a single execution of Quicksort when comparison outcomes are generated from a BT model, under the assumption that the distance between adjacent parameters is (stochastically) uniform across the ranking.",1 Introduction,[0],[0]
"We measure the quality of a ranking estimate by its displacement with respect to the ground truth, i.e., the sum of rank differences.",1 Introduction,[0],[0]
We show that Quicksort’s output is a good approximation to the ground-truth ranking: no method comparing every pair of items at most once can do better (up to constant factors).,1 Introduction,[0],[0]
"Furthermore, we show that by aggregating O(log5 n) independent runs of Quicksort, it is possible to recover the exact rank for all but a vanishing fraction of the items.",1 Introduction,[0],[0]
"These theoretical results suggest that adaptive sampling is able to bring a substantial acceleration to the learning process.
",1 Introduction,[0],[0]
"Second, we propose a practical active-learning (AL) strategy that consists of repeatedly sorting the items.",1 Introduction,[0],[0]
We evaluate our sorting-based method on three datasets and compare it to existing AL methods.,1 Introduction,[0],[0]
We observe that all the strategies that we consider lead to better ranking estimates noticeably faster than random sampling.,1 Introduction,[0],[0]
"However, most strategies are challenging to operate and computationally expensive, thus hindering wider adoption (Schein & Ungar, 2007).",1 Introduction,[0],[0]
"In this regard, sorting-based AL stands out, as a) it is computationally-speaking as inexpensive as random sampling, b) it is trivial to implement, and c)",1 Introduction,[0],[0]
it requires no tuning of hyperparameters.,1 Introduction,[0],[0]
"We consider n items that are represented by consecutive integers [n] = {1, . . .",1.1 Preliminaries and Notation,[0],[0]
", n}.",1.1 Preliminaries and Notation,[0],[0]
"Without loss of generality, we
assume that the items are ranked by increasing preference1, i.e., i < j means that j is (in expectation) preferred to i.",1.1 Preliminaries and Notation,[0],[0]
"When j is preferred to i as a result of a pairwise comparison, we denote the observation by i ≺ j.",1.1 Preliminaries and Notation,[0],[0]
"If i < j, we say that i ≺ j is a consistent outcome and j ≺ i an inconsistent (incorrect) outcome.",1.1 Preliminaries and Notation,[0],[0]
"In most of the paper, pairwise comparison outcomes follow a Bradley–Terry model with parameters θ = [ θ1 · · · θn ]
∈ Rn, denoted BT(θ).",1.1 Preliminaries and Notation,[0],[0]
"The parameters θ1 < · · · < θn represent the utilities of items 1, . . .",1.1 Preliminaries and Notation,[0],[0]
",",1.1 Preliminaries and Notation,[0],[0]
"n, and the probability of observing the outcome",1.1 Preliminaries and Notation,[0],[0]
"i ≺ j is
p(i ≺ j | θ) = 1
1 + exp[−(θj − θi)] .
",1.1 Preliminaries and Notation,[0],[0]
The probability of observing an inconsistent comparison decreases with the distance between the items.,1.1 Preliminaries and Notation,[0],[0]
"This captures the intuitive notion that some pairs of items are easy to compare and some are more difficult (Zermelo, 1928; Bradley & Terry, 1952).
",1.1 Preliminaries and Notation,[0],[0]
"A ranking σ is a function that maps an item to its rank, i.e., σ(i) = rank of item i.",1.1 Preliminaries and Notation,[0],[0]
"The (ground-truth) identity ranking is denoted by id, i.e. id(i) = i. To measure the quality of a ranking σ with respect to the ground-truth, we consider the displacement
∆(σ) =
n ∑
i=1
|σ(i)− i|,
also known as Spearman’s footrule distance.",1.1 Preliminaries and Notation,[0],[0]
"Another metric widely used in practice is the Kendall–Tau distance, defined as K(σ) =",1.1 Preliminaries and Notation,[0],[0]
"∑
i<j 1 {σ(i) > σ(j)}.",1.1 Preliminaries and Notation,[0],[0]
"Both metrics are equiv-
alent up to a factor of two2, such that bounds on ∆(σ) also hold for K(σ) up to constant factors.
",1.1 Preliminaries and Notation,[0],[0]
"Finally, we say that an event A holds with high probability if P [A] → 1 as n → ∞. For a random variable X and a sequence of numbers an, we say that X = O(an) with high probability if P",1.1 Preliminaries and Notation,[0],[0]
[|X| ≤ can]→,1.1 Preliminaries and Notation,[0],[0]
"1 as n→∞ for some constant c that does not depend on n.
Outline of the paper.",1.1 Preliminaries and Notation,[0],[0]
We begin by briefly reviewing related literature in Section 2.,1.1 Preliminaries and Notation,[0],[0]
"Next, in Section 3, we study the displacement of Quicksort’s output under noisy comparisons.",1.1 Preliminaries and Notation,[0],[0]
"In Section 4, we empirically evaluate several AL strategies on three datasets.",1.1 Preliminaries and Notation,[0],[0]
"Finally, we conclude in Section 5.",1.1 Preliminaries and Notation,[0],[0]
Passive setting.,2 Related Work,[0],[0]
"Recently, there have been a number of results on the sample complexity of the BT model, based on
1 This convention greatly simplifies the notation throughout the paper, but differs from that used in most of the preference learning literature.",2 Related Work,[0],[0]
"In our paper, the item with rank 1 is the worst.
2∆(σ)/2 ≤ K(σ)",2 Related Work,[0],[0]
"≤ ∆(σ) (Diaconis & Graham, 1977).
",2 Related Work,[0],[0]
"the assumption that all pairs of items are chosen before any comparison outcome is revealed (Negahban et al., 2012; Hajek et al., 2014; Rajkumar & Agarwal, 2014; Vojnovic & Yun, 2016).",2 Related Work,[0],[0]
"In general, these results reveal that choosing pairs of items uniformly at random is essentially optimal.",2 Related Work,[0],[0]
"Furthermore, they suggest that the ranking induced by the BT model cannot be recovered with less than Ω(n2) comparisons.",2 Related Work,[0],[0]
"Our work shows that by adaptively selecting pairs based on observed outcomes, we observe substantial gains.
",2 Related Work,[0],[0]
Active preference learning.,2 Related Work,[0],[0]
AL approaches for learning a ranking based on noisy comparison outcomes have been studied under various assumptions.,2 Related Work,[0],[0]
"Braverman & Mossel (2008) examine a model where outcomes of pairwise comparisons are flipped with a small, constant probability.",2 Related Work,[0],[0]
"Ailon (2012) considers an adversarial setting (comparison outcomes can be arbitrary) and investigates AL in the context of finding a ranking that minimizes the number of inconsistent outcomes, also known as the minimum feedback-arc set problem on tournaments (MFAST).",2 Related Work,[0],[0]
"These theoretical studies imply, in their respective settings, that O(n logk n) comparison outcomes are enough to recover a near-optimal ranking.",2 Related Work,[0],[0]
"Jamieson & Nowak (2011) propose an efficient active-ranking algorithm that is applicable if items can be embedded in Rd (e.g., using d features) and assuming that admissible rankings satisfy some geometric constraints.",2 Related Work,[0],[0]
Wang et al. (2014) study a collaborative preference-learning problem and show that a variant of uncertainty sampling (a well-known AL strategy) works well for their problem.,2 Related Work,[0],[0]
"In this work, we assume that we do not have access to item features and that comparison outcomes follow a single BT model.
",2 Related Work,[0],[0]
Bayesian methods.,2 Related Work,[0],[0]
"From a practical standpoint, Bayesian methods provide an effective way to select informative samples (MacKay, 1992).",2 Related Work,[0],[0]
"However, they can be difficult to scale if the number of items is large.",2 Related Work,[0],[0]
"Work on Bayesian active preference learning includes Chu & Ghahramani (2005), Houlsby et al. (2012), Salimans et al. (2012) and Chen et al. (2013).",2 Related Work,[0],[0]
"We compare our AL strategy to these methods in Section 4.
",2 Related Work,[0],[0]
Multi-armed bandit.,2 Related Work,[0],[0]
"The dueling bandit problem (Yue et al., 2009) is somewhat related to our work.",2 Related Work,[0],[0]
"In this problem, the goal is to identify the best item based on noisy comparison outcomes, using as few adaptively chosen samples as possible.",2 Related Work,[0],[0]
Two recent papers also extend the problem to that of recovering the entire ranking (instead of only the top element).,2 Related Work,[0],[0]
"The work of Szörényi et al. (2015) is the closest to ours, as it also uses the BT model.",2 Related Work,[0],[0]
"One of their results is similar to our Theorem 2: They show that a quasi-linear number of comparisons is sufficient to recover the true ranking, under some conditions on θ.",2 Related Work,[0],[0]
Heckel et al. (2016) investigate a non-parametric model and develop some theoretical guarantees.,2 Related Work,[0],[0]
"In contrast to these works, our paper studies practical
Algorithm 1 Quicksort
Require: set of items V 1: if |V | < 2 then return list(V ) ⊲",2 Related Work,[0],[0]
Terminating case.,2 Related Work,[0],[0]
"2: L← ∅, R← ∅ 3: p← element of V selected uniformly at random 4: for i ∈ V \ {p} do 5: if i ≺ p then ⊲",2 Related Work,[0],[0]
Pairwise comparison.,2 Related Work,[0],[0]
"6: L← L ∪ {i} 7: else
8: R← R ∪ {i}
9: return Quicksort(L) · p · Quicksort(R)
comparison budgets: we give theoretical guarantees for the output obtained from a single call to Quicksort, and in our experiments we never exceed ≈ 10 calls.
",2 Related Work,[0],[0]
Quicksort.,2 Related Work,[0],[0]
"The Quicksort algorithm (Hoare, 1962) is one of the most widely studied sorting procedures.",2 Related Work,[0],[0]
Quicksort has been shown to produce useful rankings beyond classic sorting problems.,2 Related Work,[0],[0]
"For example, Ailon et al. (2008) show that Quicksort produces (in expectation) a 3-approximation to the MFAST problem.",2 Related Work,[0],[0]
"Quicksort combined with BT comparison outcomes has also been proposed as a probabilistic ranking model (Ailon, 2008).",2 Related Work,[0],[0]
We take advantage of some of the properties of this ranking model in order to derive the theoretical results of Section 3.,2 Related Work,[0],[0]
"In this section, we begin by studying the behavior and output of Quicksort under inconsistent comparison outcomes, without any assumptions on the noise generating process.",3 Theoretical Results,[0],[0]
"Then, starting in Section 3.1, we focus on comparison outcomes generated by the BT model.",3 Theoretical Results,[0],[0]
"Due to limited space, most full proofs are deferred to the supplementary material (Section A).
",3 Theoretical Results,[0],[0]
Quicksort (Algorithm 1) is best described as a recursive procedure.,3 Theoretical Results,[0],[0]
"At each step of the recursion, a pivot item p is chosen uniformly at random (line 3).",3 Theoretical Results,[0],[0]
"Then, during the partition operation (lines 4–8), every other item is compared to p and added to the set L or R, depending on the outcome.",3 Theoretical Results,[0],[0]
"If all comparison outcomes are consistent, it is well-known that Quicksort terminates after sampling O(n log n) comparisons with high probability.",3 Theoretical Results,[0],[0]
What happens if we drop the consistency assumption?,3 Theoretical Results,[0],[0]
"The following two lemmas state that these key properties remain valid, no matter which (and how many) comparison outcomes are inconsistent.
",3 Theoretical Results,[0],[0]
Lemma 1.,3 Theoretical Results,[0],[0]
"Quicksort always terminates and samples each of the n(n−1)/2 possible comparisons at most once.
",3 Theoretical Results,[0],[0]
Proof.,3 Theoretical Results,[0],[0]
The proof is identical to the consistent setting.,3 Theoretical Results,[0],[0]
"Consider the state of L and R at the end of a partition operation.
",3 Theoretical Results,[0],[0]
"Because |L|+ |R| = |V |−1, the recursive calls are made on sets of items of strictly decreasing cardinality, and the algorithm terminates after a finite number of steps.",3 Theoretical Results,[0],[0]
"Furthermore, suppose that Quicksort samples an outcome for the pair (i, j).",3 Theoretical Results,[0],[0]
Then either i or j is the pivot in a partition operation.,3 Theoretical Results,[0],[0]
"In either case, the pivot is not included in the recursive calls, which ensures that (i, j) cannot be compared again.
",3 Theoretical Results,[0],[0]
Lemma 2.,3 Theoretical Results,[0],[0]
"Quicksort samples O(n log n) comparisons w.h.p.
",3 Theoretical Results,[0],[0]
Proof (sketch).,3 Theoretical Results,[0],[0]
"We follow a standard analysis of Quicksort (see, e.g., Dubhashi & Panconesi, 2009, Section 3.3.3).",3 Theoretical Results,[0],[0]
"With high probability, we choose a “good” pivot (i.e., one that results in a balanced partition) a constant fraction of the time.",3 Theoretical Results,[0],[0]
"In this case, the depth of the call tree is O(log n).",3 Theoretical Results,[0],[0]
"As there are at most n comparisons at each level of the call tree, we conclude that Quicksort uses O(n log n) comparisons in total.",3 Theoretical Results,[0],[0]
"With respect to the standard proof, we need some additional work to formalize the notion of “good” pivot to the setting where comparison outcomes are not consistent with a linear order.
",3 Theoretical Results,[0],[0]
"Lemma 2 complements Theorem 3 in Ailon & Mohri (2010), which states that Quicksort samples O(n log n) in expectation.",3 Theoretical Results,[0],[0]
These results might suggest that all properties of Quicksort carry over to the noisy setting.,3 Theoretical Results,[0],[0]
This is not the case.,3 Theoretical Results,[0],[0]
"For example, although Quicksort uses approximately 2n lnn comparisons on average in the noiseless setting (Sedgewick & Wayne, 2011), this number can be distinctly different with inconsistent comparison outcomes3.
Quicksort (and efficient sorting algorithms in general) infer most pairs of items’ relative position by transitivity and thus rely heavily on the consistency of comparison outcomes.",3 Theoretical Results,[0],[0]
"In the noisy case, it is therefore important to precisely understand the effect of an inconsistent outcome on the output of the algorithm; this effect extends beyond the pair of items whose comparison outcome was inconsistent.",3 Theoretical Results,[0],[0]
"For this purpose, the next Lemma bounds the displacement of Quicksort’s output as a function of the inconsistent outcomes.
",3 Theoretical Results,[0],[0]
Lemma 3.,3 Theoretical Results,[0],[0]
Let E be the set of pairs sampled by Quicksort and whose outcome is inconsistent with id. Let σ be the output.,3 Theoretical Results,[0],[0]
"Then,
∆(σ) ≤ 2 ∑
(i,j)∈E
|i− j|
Proof (sketch).",3 Theoretical Results,[0],[0]
"Consider the first partition operation, with pivot p, resulting in partitions L and R. Denote the errors
3E.g., if comparison outcomes are uniformly random, all items are “good” pivots w.h.p., and the average number of comparisons will be closer to n log
2 n on average, for large n.
made during this partition operation by E1.",3 Theoretical Results,[0],[0]
"We can show that the displacement is bounded by
∆(σ) ≤ ∆L(σ) + ∆R(σ) + 2 ∑
(i,j)∈E1
|i− j|,
where ∆L(σ) and ∆R(σ) represent the displacement of the ordering induced by σ on L and R, respectively.",3 Theoretical Results,[0],[0]
"In other words, the total displacement can be decomposed into a term that represents the “local” displacement due to the partition operation and into two terms that account for errors in the recursive calls.",3 Theoretical Results,[0],[0]
"We obtain the desired result by recursively bounding ∆L(σ) and ∆R(σ).
",3 Theoretical Results,[0],[0]
"Informally, Lemma 3 states that the displacement can be bounded by a sum of “local shifts” due to the inconsistent outcomes and that the price to pay for any information inferred by transitivity is bounded by a factor two.",3 Theoretical Results,[0],[0]
"Lemma 3 is a crucial component of our subsequent analysis of BT noise, and we believe that it can be useful in order to investigate Quicksort under a wide variety of other noise generating processes.",3 Theoretical Results,[0],[0]
"From here on, we assume that comparison outcomes are generated from BT(θ).",3.1 Displacement in the Poisson Model,[0],[0]
"Clearly, any results on the displacement of a ranking estimated from samples of a BT model will depend on θ; it is easy to construct a model instance for which it is arbitrarily hard to recover the ranking, by choosing parameters sufficiently close to each other.",3.1 Displacement in the Poisson Model,[0],[0]
Our approach is as follows.,3.1 Displacement in the Poisson Model,[0],[0]
"We postulate a family of distributions over θ, and we give bounds on the displacement that hold with high probability.
",3.1 Displacement in the Poisson Model,[0],[0]
"We suppose that comparison outcomes are (in expectation) uniformly noisy across the ranking: i.e., comparing two elements at the bottom is (a priori) as difficult as comparing two elements at the top or in the middle.",3.1 Displacement in the Poisson Model,[0],[0]
"This means that the probability distribution over parameters θ1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", θn results in (random) distances |θi+k−θi| that depend only on k. One such distribution arises if the parameters are drawn from a Poisson point process of rate λ.",3.1 Displacement in the Poisson Model,[0],[0]
"That is,
i.i.d.",3.1 Displacement in the Poisson Model,[0],[0]
"x1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", xn−1 ∼ Exp(λ), θi =
i−1 ∑
k=1
xk.",3.1 Displacement in the Poisson Model,[0],[0]
"(1)
The average distance between two items separated by k positions in the ordering is E",3.1 Displacement in the Poisson Model,[0],[0]
[θi+k,3.1 Displacement in the Poisson Model,[0],[0]
− θi] = k/λ.,3.1 Displacement in the Poisson Model,[0],[0]
"Although the distance between adjacent items is constant in expectation, we allow some parameters to be arbitrarily close4.",3.1 Displacement in the Poisson Model,[0],[0]
"The parameter λ controls the expected level of noise; a large λ is
4 In particular, the expected minimum distance between two items (i.e., the min of n exponential r.v.s) decreases as (nλ)−1 as n increases.
likely to result in a larger number of inconsistent outcomes.",3.1 Displacement in the Poisson Model,[0],[0]
"Although the precise choice of this Poisson model is driven by tractability concerns, in Section 3.2 we argue that it is essentially equivalent to choosing the parameters independently and uniformly at random in the interval",3.1 Displacement in the Poisson Model,[0],[0]
"[0, (n+1)/λ], when λ is fixed and n is large.",3.1 Displacement in the Poisson Model,[0],[0]
"We are now ready to state our main result.
",3.1 Displacement in the Poisson Model,[0],[0]
Theorem 1.,3.1 Displacement in the Poisson Model,[0],[0]
Let θ be sampled from a Poisson point process of rate λ.,3.1 Displacement in the Poisson Model,[0],[0]
Let σ be the output of Quicksort using comparison outcomes sampled from BT(θ).,3.1 Displacement in the Poisson Model,[0],[0]
"Then, w.h.p.,
∆(σ) = O(λ2n), (2)
max i |σ(i)− i| = O(λ log n).",3.1 Displacement in the Poisson Model,[0],[0]
"(3)
Proof (sketch).",3.1 Displacement in the Poisson Model,[0],[0]
"Let zij be the indicator random variable of the event “the comparison between i and j results in an error”, and let dij = |θi",3.1 Displacement in the Poisson Model,[0],[0]
− θj |.,3.1 Displacement in the Poisson Model,[0],[0]
"The distance dij is a sum of |i − j| exponential random variables, i.e., dij ∼ Gamma(|i− j|, λ), and we can show that
E",3.1 Displacement in the Poisson Model,[0],[0]
"[zij ] = E
[
1
1 + exp(dij)
]
≤ E",3.1 Displacement in the Poisson Model,[0],[0]
[exp(−dij)],3.1 Displacement in the Poisson Model,[0],[0]
"= (1 + 1/λ) −|i−j|.
Using Lemma 3 and the fact that every pair of items is compared at most once, we find
E [∆] ≤ 2 ∑
i<j
|i−",3.1 Displacement in the Poisson Model,[0],[0]
j|E,3.1 Displacement in the Poisson Model,[0],[0]
"[zij ]
≤ 2n
∞ ∑
k=0
k(1 + 1/λ)−k = 2nλ(λ+ 1).
",3.1 Displacement in the Poisson Model,[0],[0]
"The random variables {zij} are not unconditionally independent (they are independent when conditioned on θ) but, with some more work, we can show that Var [∆] = O(n).",3.1 Displacement in the Poisson Model,[0],[0]
"By using a Chebyshev bound, (2) follows.
",3.1 Displacement in the Poisson Model,[0],[0]
"In order to prove (3), we take advantage of a theorem due to Ailon (2008) which states that
P",3.1 Displacement in the Poisson Model,[0],[0]
[σ(i) < σ(j),3.1 Displacement in the Poisson Model,[0],[0]
"| θ] = p(i ≺ j | θ),
even if i and j were not directly compared with each other.",3.1 Displacement in the Poisson Model,[0],[0]
We use a Chernoff bound on dij to show that the relative order between any two items separated by at least O(λ log n) positions is correct with high probability.,3.1 Displacement in the Poisson Model,[0],[0]
"The second part of the claim follows easily.
",3.1 Displacement in the Poisson Model,[0],[0]
"Note that any method that compares each pair of items at most once results in a ranking estimate τ with displacement ∆(τ) = Ω(n) with high probability: As there is only a single (possibly inconsistent) comparison outcome between each pair of adjacent items, it is likely that a constant fraction of the items will be ranked incorrectly, resulting in a
Algorithm 2 Multisort
Require: set of items V , number of iterations m",3.1 Displacement in the Poisson Model,[0],[0]
"1: S ← ∅ 2: for k = 1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
",m do 3: σ ← Quicksort(V ) 4: S ← S ∪ {σ}
5: return Copeland aggregation of S
displacement that grows linearly in n. Hence, our bound on ∆(σ) shows that Quicksort is order-optimal (in n).
",3.1 Displacement in the Poisson Model,[0],[0]
"In light of Theorem 1, a natural question to ask is as follows.",3.1 Displacement in the Poisson Model,[0],[0]
How many comparisons are needed in order to find the correct ranking?,3.1 Displacement in the Poisson Model,[0],[0]
"Clearly, finding the exact ranking is difficult: in fact, Ω(n) comparison outcomes are necessary to discriminate the closest pair of items reliably (see supplementary material, Section B).",3.1 Displacement in the Poisson Model,[0],[0]
"As such, we will focus on finding a ranking that matches the ground truth everywhere, except at a vanishing fraction of the items.
",3.1 Displacement in the Poisson Model,[0],[0]
"Multiple runs of Quicksort likely produce different outputs, because of the noisy comparison outcomes and because the algorithm itself is randomized (the pivot selection is random).",3.1 Displacement in the Poisson Model,[0],[0]
"By aggregating m independent outputs of Quicksort, is it possible to produce a better ranking estimate?",3.1 Displacement in the Poisson Model,[0],[0]
"Similarly to Szörényi et al. (2015), we combine the m outputs σ1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", σm into an aggregate ranking σ̂ using Copeland’s method.",3.1 Displacement in the Poisson Model,[0],[0]
"The method assigns, to each item, a score that corresponds to the number of items that it beats in a majority of the rankings, and it then ranks the items by increasing score (Copeland, 1951).",3.1 Displacement in the Poisson Model,[0],[0]
"We call the procedure Multisort and describe it in Algorithm 2.
Theorem 2.",3.1 Displacement in the Poisson Model,[0],[0]
Let θ be sampled from a Poisson point process of rate λ.,3.1 Displacement in the Poisson Model,[0],[0]
Let σ̂ be the output of Multisort using m = O(λ2 log5 n) and comparison outcomes sampled from BT(θ).,3.1 Displacement in the Poisson Model,[0],[0]
"Then, w.h.p.,
∆(σ̂) = o(λn).
",3.1 Displacement in the Poisson Model,[0],[0]
Proof (sketch).,3.1 Displacement in the Poisson Model,[0],[0]
"We use results on the order statistics of the distances x1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", xn−1 between successive items, as defined in (1), to partition the items into two disjoint subsets B and G. The set B contains a vanishing (1/ log2 n)-fraction of “bad” items that are difficult to order.",3.1 Displacement in the Poisson Model,[0],[0]
The set G is such that the smallest distance dij from any item,3.1 Displacement in the Poisson Model,[0],[0]
i ∈ G to any other item j ∈,3.1 Displacement in the Poisson Model,[0],[0]
[n] is bounded from below by c/(λ log2 n).,3.1 Displacement in the Poisson Model,[0],[0]
"We can show that with m = O(λ2 log5 n), for any i ∈ G and j ∈",3.1 Displacement in the Poisson Model,[0],[0]
[n] we have i < j ⇐⇒ σ(i) < σ(j) in a majority of the Quicksort outputs (with high probability).,3.1 Displacement in the Poisson Model,[0],[0]
This implies that σ̂(i),3.1 Displacement in the Poisson Model,[0],[0]
= i for all i ∈ G with high probability.,3.1 Displacement in the Poisson Model,[0],[0]
"Using (3) for items in B, we have
∆(σ̂) = |B| ·O(λ log n) = O(λn/ log n)
with high probability.
",3.1 Displacement in the Poisson Model,[0],[0]
Theorem 2 states that all but a vanishing fraction of items are correctly ranked using O(λ2n log6 n) comparisons.,3.1 Displacement in the Poisson Model,[0],[0]
"This result should be compared to the Ω(n2) comparisons needed if samples are selected uniformly at random.
",3.1 Displacement in the Poisson Model,[0],[0]
Empirical validation.,3.1 Displacement in the Poisson Model,[0],[0]
"In Figure 1, we illustrate the results of Theorems 1 and 2 by running simulations for increasing n and different values of λ.",3.1 Displacement in the Poisson Model,[0],[0]
"The bound on ∆(σ) is tight in n, but the dependence on λ appears to be linear rather than quadratic.",3.1 Displacement in the Poisson Model,[0],[0]
The bound on maxi|σ(i)− i| appears to be tight in n and λ.,3.1 Displacement in the Poisson Model,[0],[0]
"Finally, we compare the Copeland aggregation of m outputs of Quicksort with the ranking induced by the maximum-likelihood (ML) estimate, inferred from the outcomes of all the pairwise comparisons sampled by the m runs.",3.1 Displacement in the Poisson Model,[0],[0]
"Although the ranking induced by the ML estimate does not benefit from the guarantees of Theorem 2, it performs better in practice.",3.1 Displacement in the Poisson Model,[0],[0]
We will make use of this observation in Section 4.,3.1 Displacement in the Poisson Model,[0],[0]
A different (perhaps more natural) assumption on the parameters θ is to consider that they are drawn independently and uniformly at random over some interval.,3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"That is,
i.i.d. θ̄1, . . .",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
", θ̄n ∼ U(0, (n+ 1)/λ),
with θ1, . . .",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
", θn the order statistics of θ̄, i.e., the random variables arranged in increasing order.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"From some elementary results on the joint distribution of order statistics (see, e.g., Arnold et al., 2008), we see that
|θi+k",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"− θi| ∼ (n+ 1)/λ · Beta(k, n− k + 1),
i.e., a Beta random variable rescaled between 0 and (n + 1)/λ.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"Letting fk,n(x) be the probability density of |θi+k",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"− θi|, we have, for any fixed k and λ,
fk,n(x) ∝",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"x k−1
[
1− λx
n+ 1
]n−k n→∞ −−−−→ xk−1e−λx.
",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"We recognize the functional form of the density of a Gamma(k, λ) distribution.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"Hence, the Poisson model and the i.i.d. uniform model are essentially equivalent for fixed λ and large n, and we can expect the results developed in Section 3.1 to hold under this distribution as well.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"In practice, the comparison budget for estimating a ranking from noisy data might typically be larger than that for a single call to Quicksort, and it might not exactly match the number of comparisons required to run a given number of calls to Quicksort to completion.",4 Experimental Results,[0],[0]
"Building upon the observations made at the end of Section 3.1, we suggest the following practical active-learning strategy: for a budget of
c pairwise comparisons, run the sorting procedure repeatedly until the budget is depleted (the last call might have to be truncated).",4 Experimental Results,[0],[0]
"Then, retain only the set of c comparison pairs and their outcomes and discard the rankings produced by the sorting procedure.",4 Experimental Results,[0],[0]
"The final ranking estimate is then induced from the ML estimate over the set of c comparison outcomes.
",4 Experimental Results,[0],[0]
"In this section, we demonstrate the effectiveness of this sampling strategy on synthetic and real-world data.",4 Experimental Results,[0],[0]
"In particular, we show that it is comparable to existing AL strategies at a minuscule fraction of the computational cost.",4 Experimental Results,[0],[0]
"To assess the relative merits of our sorting-based strategy, we consider three strategies that we believe are representative of the state of the art in active preference learning.
",4.1 Competing Sampling Strategies,[0],[0]
Uncertainty sampling.,4.1 Competing Sampling Strategies,[0],[0]
"Developed in the context of classification tasks, this popular active-learning heuristic suggests to greedily sample the point that lies closest to the decision boundary (Settles, 2012).",4.1 Competing Sampling Strategies,[0],[0]
"In the context of a ranking task, this corresponds to sampling the pair of items whose relative order is most uncertain.",4.1 Competing Sampling Strategies,[0],[0]
"After t observations, given an estimate of model parameters θt, the strategy selects the (t+1)-st pair uniformly at random in
argmin i 6=j
|θti − θ t j |.
",4.1 Competing Sampling Strategies,[0],[0]
This set can be computed in time O(n log n) by sorting the parameters.,4.1 Competing Sampling Strategies,[0],[0]
"The parameters themselves need to be estimated, e.g., using (penalized) ML inference that in practice can be the dominating cost.
",4.1 Competing Sampling Strategies,[0],[0]
Bayesian methods.,4.1 Competing Sampling Strategies,[0],[0]
"If we have access to a full posterior distribution qt(θ) instead of a point estimate θt, we can take advantage of the extra information on the uncertainty of the parameters to improve the selection strategy.",4.1 Competing Sampling Strategies,[0],[0]
"A principled approach to AL consists of sampling the point that
maximizes the expected information gain (MacKay, 1992).",4.1 Competing Sampling Strategies,[0],[0]
"That is, the pair of items at iteration t+ 1 is selected in
argmax i 6=j
H(qt)−E",4.1 Competing Sampling Strategies,[0],[0]
"[ H(qt+1) ] , (4)
where H(·) denotes the entropy function.",4.1 Competing Sampling Strategies,[0],[0]
A conceptually similar but slightly different selection strategy is given by Chen et al. (2013).,4.1 Competing Sampling Strategies,[0],[0]
"Letting qij be the marginal distribution of (θi, θj), the pair is selected in
argmax i 6=j
E",4.1 Competing Sampling Strategies,[0],[0]
"[ KL(qt+1ij ‖q t ij) ] , (5)
where KL(·) denotes the Kullback–Leibler divergence.",4.1 Competing Sampling Strategies,[0],[0]
"Computing the exact posterior is not analytically tractable for the BT model, but a Gaussian approximation can be found in time O(n3).",4.1 Competing Sampling Strategies,[0],[0]
Criteria (4) and (5) can be computed in constant time for each pair of items.,4.1 Competing Sampling Strategies,[0],[0]
"The dominating cost is again that of estimating θ (or, in this case, q(θ)).
",4.1 Competing Sampling Strategies,[0],[0]
"In addition to these existing AL strategies, we also include in our experiments a variation of our sorting-based strategy that uses Mergesort instead of Quicksort.",4.1 Competing Sampling Strategies,[0],[0]
"In the noiseless setting, Mergesort is known to use on average≈ 39 % fewer comparisons than Quicksort per run (Knuth, 1998), but it does not benefit from the theoretical guarantees developed in Section 3.",4.1 Competing Sampling Strategies,[0],[0]
"In this section, we briefly discuss the running time of the methods.",4.2 Running Time,[0],[0]
We implement ML and Bayesian approximate inference algorithms for the BT model as a Python library5.,4.2 Running Time,[0],[0]
"For ML inference, we find that the fastest running time is achieved by a truncated Newton algorithm (even for large n).",4.2 Running Time,[0],[0]
"For approximate Bayesian inference, we use a variant of the expectation-propagation algorithm outlined by Chu & Ghahramani (2005).",4.2 Running Time,[0],[0]
"All experiments are performed on
5See: http://lucas.maystre.ch/choix.
a server with a 12-core Xeon X5670 processor running at 2.93 GHz.",4.2 Running Time,[0],[0]
"Numerical computations take advantage of the Intel Math Kernel Library.
",4.2 Running Time,[0],[0]
We illustrate the running time of AL strategies as follows.,4.2 Running Time,[0],[0]
"For n ∈ {102, 103, 104}, we generate outcomes for n comparisons pairs chosen uniformly at random among n items.",4.2 Running Time,[0],[0]
"For each strategy, we then measure the time it takes to select the (n+1)-st pair of items adaptively.",4.2 Running Time,[0],[0]
The results are presented in Table 1.,4.2 Running Time,[0],[0]
"Note that these numbers are intended to be considered as orders of magnitude, rather than exact values, as they depend on the particular combination of software and hardware that we use.",4.2 Running Time,[0],[0]
The running time of the Bayesian AL strategies exceed 10 hours for n = 104 and the calls were stopped ahead of completion.,4.2 Running Time,[0],[0]
"Our sorting-based methods, like random sampling, are the only AL strategies whose running time is constant for increasing n",4.2 Running Time,[0],[0]
(and for increasing c).,4.2 Running Time,[0],[0]
"In fact, their running time is negligible in comparison to the other strategies, including uncertainty sampling.",4.2 Running Time,[0],[0]
"We now investigate three datasets and measure the displacement of rankings estimated from adaptively-chosen samples, as a function of the budget c. Note that in order to use uncertainty sampling and Bayesian methods, it is necessary to choose a regularization strength or prior variance in the inference step.",4.3 Empirical Evaluation,[0],[0]
"Different values can result in drastically different outcomes (in particular for uncertainty sampling) and, in practice, choosing a good value can be a significant challenge6.",4.3 Empirical Evaluation,[0],[0]
"In the following, we report results for the values that worked best a posteriori.
",4.3 Empirical Evaluation,[0],[0]
Synthetic dataset.,4.3 Empirical Evaluation,[0],[0]
We generate n i.i.d.,4.3 Empirical Evaluation,[0],[0]
"parameters θ1, . .",4.3 Empirical Evaluation,[0],[0]
.,4.3 Empirical Evaluation,[0],[0]
", θn uniformly in [0, (n + 1)/λ] and draw samples from BT(θ).",4.3 Empirical Evaluation,[0],[0]
The ground-truth ranking is the one induced by the parameters.,4.3 Empirical Evaluation,[0],[0]
Figure 2 presents results for n = 200 and λ,4.3 Empirical Evaluation,[0],[0]
"= 5 (plots for different values of λ are presented in the supplementary material, Section C, and are qualitatively
6Observe that our sorting-based approach is entirely parameterfree and is therefore not affected by this issue.
similar).",4.3 Empirical Evaluation,[0],[0]
"In comparison to random sampling, AL is very effective and results in significantly better ranking estimates for any given number of comparisons.",4.3 Empirical Evaluation,[0],[0]
"The two Bayesian methods, though being the most computationally expensive, perform the best for all values of c, but are nearly indistinguishable from uncertainty sampling.",4.3 Empirical Evaluation,[0],[0]
The two sorting-based strategies perform similarly (with a small edge for Mergesort).,4.3 Empirical Evaluation,[0],[0]
"They are slightly worse than the Bayesian methods but are still able to reap most of the benefits of active learning.
",4.3 Empirical Evaluation,[0],[0]
Sushi dataset.,4.3 Empirical Evaluation,[0],[0]
"Next, we consider a dataset of Sushi preferences (Kamishima & Akaho, 2009).",4.3 Empirical Evaluation,[0],[0]
"In this dataset, 5000 respondents give a strict ordering over 10 different types of sushi.",4.3 Empirical Evaluation,[0],[0]
These 10 sushi are chosen among a larger set of n = 100 items.,4.3 Empirical Evaluation,[0],[0]
"To suit our purposes, we decompose each 10-way partial ranking into pairwise comparisons, resulting in 225 000 comparison outcomes.",4.3 Empirical Evaluation,[0],[0]
"We use all comparisons to fit a BT model that induces a ground-truth ranking7.
",4.3 Empirical Evaluation,[0],[0]
"The comparisons are dense, and there is at least one comparison outcome for almost all pairs.",4.3 Empirical Evaluation,[0],[0]
"When an outcome for pair (i, j) is requested, we sample uniformly at random over all outcomes observed for this pair.",4.3 Empirical Evaluation,[0],[0]
"In the rare case where no outcome is available, we return i ≺ j with probability 1/2.",4.3 Empirical Evaluation,[0],[0]
"This enables us to compare sampling strategies in a realistic setting, where the assumptions of the BT model do not necessarily hold anymore.
",4.3 Empirical Evaluation,[0],[0]
Results are shown in Figure 3 (left).,4.3 Empirical Evaluation,[0],[0]
"Once again, active learning performs noticeably better than random sampling.",4.3 Empirical Evaluation,[0],[0]
"On this real-world dataset, the performance of our sorting-based strategies is indistinguishable from that of the Bayesian
7 The BT-induced ranking is almost the same as that obtained using the Copeland score.",4.3 Empirical Evaluation,[0],[0]
"The results are very similar if the Copeland aggregation is used as ground truth.
methods, after completing one entire call to the sorting procedure (slightly less than 1000 comparisons).",4.3 Empirical Evaluation,[0],[0]
"This result should be interpreted in light of the time needed to select all 104 pairs: a fraction of a second for sorting-based strategies, and several hours for the Bayesian methods.",4.3 Empirical Evaluation,[0],[0]
"Finally, we observe that the performance of uncertainty sampling progressively degrades as c increases.",4.3 Empirical Evaluation,[0],[0]
"A detailed analysis reveals that uncertainty sampling increasingly focuses on a small set of hard-to-discriminate pairs, symptomatic of a well-known issue (Settles, 2012).
GIFGIF dataset.",4.3 Empirical Evaluation,[0],[0]
GIFGIF8 is a project of the MIT Media Lab that aims at explaining the emotions communicated by a collection of animated GIF images.,4.3 Empirical Evaluation,[0],[0]
"Users of the website are shown a prompt with two images and a question, “Which better expresses x?” where x is one of 17 emotions.",4.3 Empirical Evaluation,[0],[0]
"The users can click on either image, or use a third option, neither.",4.3 Empirical Evaluation,[0],[0]
"To date, over three million comparison outcomes have been collected.",4.3 Empirical Evaluation,[0],[0]
"For the purpose of our experiment, we restrict ourselves to a single emotion, happiness; and we ignore outcomes that resulted in neither.",4.3 Empirical Evaluation,[0],[0]
"We consider 106 887 comparison outcomes over n = 6120 items—a significant increase in scale compared to the Sushi dataset.
",4.3 Empirical Evaluation,[0],[0]
"As the data, despite a relatively large number of comparisons, remains sparse (less than 20 comparisons per item on average), we proceed as follows.",4.3 Empirical Evaluation,[0],[0]
We fit a BT model by using all the available comparisons and use the induced ranking as ground truth.,4.3 Empirical Evaluation,[0],[0]
"We then generate new, synthetic comparison outcomes from the BT model.",4.3 Empirical Evaluation,[0],[0]
"In this sense, the experiment enables us to compare sampling strategies by using a large BT model with realistic parameters.",4.3 Empirical Evaluation,[0],[0]
"The large number of items makes uncertainty sampling and the two Bayesian
8See http://www.gif.gf/.",4.3 Empirical Evaluation,[0],[0]
"Data available at http:// lucas.maystre.ch/gifgif-data.
methods prohibitively expensive.",4.3 Empirical Evaluation,[0],[0]
"We try a simplified, computationally less expensive version of uncertainty sampling where, at every iteration, each item is compared to its two closest neighbors, but this heuristic fails spectacularly: The resulting displacement is over 5× larger than random sampling for c = 106, and is therefore not reported here (see supplementary material, Section C).
",4.3 Empirical Evaluation,[0],[0]
Figure 3 (right) compares the displacement of random sampling to that of the two sorting-based sampling strategies for increasing c.,4.3 Empirical Evaluation,[0],[0]
The adaptive sampling approaches perform systematically better.,4.3 Empirical Evaluation,[0],[0]
"After 106 comparisons, the displacement of random sampling is 14 % and 23 % larger than that of Quicksort and Mergesort, respectively.",4.3 Empirical Evaluation,[0],[0]
"Conversely, in order to reach any target displacement, Mergesort requires approximately 2× fewer comparisons than random sampling.",4.3 Empirical Evaluation,[0],[0]
"In this work, we demonstrate that active learning can substantively speed up the task of learning a ranking from noisy comparisons gains—both in theory and in practice.",5 Conclusion,[0],[0]
"With the advent of large-scale crowdsourced ranking surveys, exemplified by GIFGIF and wiki surveys (Salganik & Levy, 2015), there is a clear need for practical AL strategies.",5 Conclusion,[0],[0]
"However, existing methods are complex and computationally expensive to operate even for a reasonable number of items (a few thousands).",5 Conclusion,[0],[0]
"We show that a deceptively simple idea—repeatedly sorting the items—is able to bring in all the benefits of active learning, is trivial to implement, and is computationally no more expensive that random sampling.",5 Conclusion,[0],[0]
"Therefore, we believe that our method can be broadly useful for machine-learning practitioners interested in ranking problems.",5 Conclusion,[0],[0]
"We thank Holly Cogliati-Bauereis, Ksenia Konyushkova, Brunella Spinelli and the anonymous reviewers for careful proofreading and helpful comments.",Acknowledgments,[0],[0]
We address the problem of learning a ranking by using adaptively chosen pairwise comparisons.,abstractText,[0],[0]
Our goal is to recover the ranking accurately but to sample the comparisons sparingly.,abstractText,[0],[0]
"If all comparison outcomes are consistent with the ranking, the optimal solution is to use an efficient sorting algorithm, such as Quicksort.",abstractText,[0],[0]
But how do sorting algorithms behave if some comparison outcomes are inconsistent with the ranking?,abstractText,[0],[0]
"We give favorable guarantees for Quicksort for the popular Bradley–Terry model, under natural assumptions on the parameters.",abstractText,[0],[0]
"Furthermore, we empirically demonstrate that sorting algorithms lead to a very simple and effective active learning strategy: repeatedly sort the items.",abstractText,[0],[0]
This strategy performs as well as state-of-the-art methods (and much better than random sampling) at a minuscule fraction of the computational cost.,abstractText,[0],[0]
Just Sort It! A Simple and Effective Approach to Active Preference Learning,title,[0],[0]
K-means clustering is a classical clustering problems and has been studied for several decades.,1. Introduction,[0],[0]
The goal of K-Means clustering is to find a set of k cluster centers for a dataset such that the sum of squared distances of each point to its closest cluster center is minimized.,1. Introduction,[0],[0]
"While it is known that k-means clustering is an NP hard optimization problem even for k = 2 (Dasgupta, 2008), in practice a local search heuristic due to Lloyd (Lloyd, 1982) is widely used for solving K-means clustering problem.",1. Introduction,[0],[0]
"Lloyd’s iterative
1Department of Electrical Engineering & Computer Science, Wichita State University, KS, USA.",1. Introduction,[0],[0]
"Correspondence to: Kaushik Sinha <kaushik.sinha@wichita.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
algorithm begins with k arbitrary “cluster centers”, and in each iteration, each point is assigned to the nearest cluster center, and each cluster center is recomputed as the center of mass of all points assigned to it.",1. Introduction,[0],[0]
These last two steps are repeated until the process stabilizes.,1. Introduction,[0],[0]
"Lloyd’s algorithm for k-means clustering is known to be one of the top ten data mining tools of the last fifty years (Wu, 2008).
",1. Introduction,[0],[0]
"K-means clustering is typically performed on a data matrix A ∈ Rn×d, consisting of n data points each having d attributes/features and per iteration computational cost of Lloyd’s algorithm is O(nkd).",1. Introduction,[0],[0]
In recent years there has been a series of work towards reducing this computational cost and speeding up k-means clustering computation.,1. Introduction,[0],[0]
Most of these works can broadly be classified into three categories.,1. Introduction,[0],[0]
"In the first category, K-means clustering algorithm is accelerated by avoiding unnecessary distance calculations by applying various forms of triangular inequality and by keeping track of lower and upper bounds for distances between points and cluster centers (Elkan, 2003; Hamerly, 2010; Drake & Hamerly, 2012; Ding et al., 2015; Newling & Fleuret, 2016; Bottesch et al., 2016).",1. Introduction,[0],[0]
All these algorithms ensure the exact same clustering result that would have been obtained had one applied Lloyd’s heuristic from the same set of initial cluster centers without applying any distance inequality bounds.,1. Introduction,[0],[0]
"In the second category, various dimension reduction techniques are applied to data matrix A to reduce data dimensionality from d to d′ (d′ d), where d′ is independent of n and d, so that optimal k-means clustering solution of dimensionality reduced dataset A′ ∈",1. Introduction,[0],[0]
"Rn×d′ ensures an approximately optimal k-means clustering objective function of A. Most prominent among these is the random projection based dimensionality reduction technique that reduces data dimensionality from d to Ω(k/ 2) resulting in (1 + ) approximation of the optimal k-means objective function (Boutsidis et al., 2010; 2015; Cohen et al., 2015) and also from d to O(log(k)/ 2) resulting in (9 + ) approximation of the optimal k-means objective function (Cohen et al., 2015).",1. Introduction,[0],[0]
"Recently, (Liu et al., 2017) demonstrated the the random projection step can be performed by multiplying with a sparse matrix that yields the same (1 + ) approximation guarantee.",1. Introduction,[0],[0]
"Additionally, random feature selection method reduces data dimensionality from d to Ω(k log k/ 2) resulting in (1 + ) approximation of the optimal k-means objective function (Boutsidis et al.,
2015; Cohen et al., 2015).",1. Introduction,[0],[0]
"In the third category, a smaller subset of n data points called coresets, are constructed so that optimal weighted k-means clustering objective function performed on this coreset is (1 + ) approximation of the optimal k-means objective function performed on the original dataset (Feldman & Langberg, 2011; Feldman et al., 2013).",1. Introduction,[0],[0]
"In k-means clustering using Lloyd’s heuristic, a major computational bottleneck arises from Euclidean distance computation between each data point and k cluster centers in every iteration.",1. Introduction,[0],[0]
"For a data point a ∈ Rd and a cluster center µ ∈ Rd, the Euclidean distance can be represented as, ‖a",1. Introduction,[0],[0]
− µ‖2 = ‖a‖2 + ‖µ‖2,1. Introduction,[0],[0]
"− 2a>µ. Note that ‖a‖2 needs be computed for each data point only once over all iterations of Lloyd’s heuristics (and can be done off-line), ‖µ‖2 needs be computed once for each cluster center in each iteration, while the dot product needs to be computed for every possible data point, cluster center pair in every single iteration.",1. Introduction,[0],[0]
"In fact, the dot product between a cluster center µ and all n data points can be computed by a simple matrix-vector multiplication:",1. Introduction,[0],[0]
Aµ.,1. Introduction,[0],[0]
"If the data matrix A is significantly sparse (i.e., number of non-zero entries is reasonable small) the above matrix vector multiplication can be performed reasonably fast.",1. Introduction,[0],[0]
"A key question that is not addressed in the literature is, To what extent the data matrix A can be made sparse without significantly affecting optimal k-means clustering objective?",1. Introduction,[0],[0]
"In this paper we show that under mild conditions, we can randomly sparsify data matrix A to obtain a sparse data matrix Ã such that optimal k-means clustering solution of Ã yields an approximately optimal k-means clustering objective of A with high probability.",1. Introduction,[0],[0]
Note that such a sparsification scheme can be extremely useful in practice.,1. Introduction,[0],[0]
"If the original data matrix is reasonably dense, then such sparsification results in fast matrix-vector multiplication, thereby speeding up k-means clustering.",1. Introduction,[0],[0]
"However, it may seem at first that for many real world high dimensional datasets that are very sparse to begin with, such as text datasets represented in “bag of word” format, such sparsification scheme may not be useful.",1. Introduction,[0],[0]
"But, note that instead of directly working with high dimensional data, typically a random projection step is often applied first to reduce data dimensionality since it is known that optimal k-means clustering solution of this randomly projected dataset results in approximately optimal k-means clustering objective of the original high dimensional dataset (Boutsidis et al., 2010; 2015; Cohen et al., 2015; Liu et al., 2017).",1. Introduction,[0],[0]
"Unfortunately, such a random projection step results in a dense projected data matrix.",1. Introduction,[0],[0]
"Interestingly, our sparsification method can now be applied on this projected dense data matrix to reap further computational benefit in addition to the computational benefit already achieved by random projection step (see Figure 1).
",1. Introduction,[0],[0]
"To quantify the approximation factor as well as the level of sparsity of our proposed method, we use ideas from
(Achlioptas & Mcsherry, 2007) which establishes that random matrix sparsification approximately preserves low rank matrix structure with high probability and also ideas from (Cohen et al., 2015) which establishes to what extent an approximately optimal low rank matrix serves as a projection cost preserving sketch.",1. Introduction,[0],[0]
"To the best of our knowledge, this is the first result that quantifies how random matrix sparsification affects k-means clustering.",1. Introduction,[0],[0]
"In particular, we make the following contributions in this paper.
",1. Introduction,[0],[0]
"• We show that for any ∈ (0, 1), a dense data matrix A ∈ Rn×d can be randomly sparsified to yield a data matrix Ã ∈",1. Introduction,[0],[0]
"Rn×d, such that, Ã contains O(nk/ 9 + d log4 n) non-zero entries in expectation, and optimal k-means clustering solution of Ã results in (1 + ) approximation of optimal k-means objective of A with high probability.
",1. Introduction,[0],[0]
"• We show that for any ∈ (0, 1), a dense data matrix A ∈ Rn×d can be randomly sparsified to yield a data matrix Ã ∈",1. Introduction,[0],[0]
"Rn×d, such that, Ã contains O(nk/ 9 + d log4 n) non-zero entries in expectation, and any approximately optimal k-means clustering solution of Ã, having (1 + ) approximation of optimal k-means objective of Ã, results in (1 +O( )) approximation of optimal k-means objective of A with high probability.
",1. Introduction,[0],[0]
"• We present experimental results on three real world datasets to demonstrate effect of our proposed random sparsification scheme on k-means clustering solution.
",1. Introduction,[0],[0]
The rest of the paper is organized as follows.,1. Introduction,[0],[0]
In section 2 we present k-means clustering problem in matrix notation and introduce uniform and non-uniform sampling strategies for random matrix sparsification.,1. Introduction,[0],[0]
We propose an algorithm for k-means clustering using random matrix sparsification in section 3 and present its analysis in section 4.,1. Introduction,[0],[0]
Empirical evaluations are presented in section 5.,1. Introduction,[0],[0]
"Finally, we conclude and point out a few open questions in section 6.",1. Introduction,[0],[0]
We use bold lower case letters to denote vectors and bold upper case letters to denote matrices.,2.1. Notation and linear algebra basics,[0],[0]
"For any n and d, consider a matrix A ∈ Rn×d with rank r = rank(A).",2.1. Notation and linear algebra basics,[0],[0]
"Using singular value decomposition A can be written as A = UΣV>, where U ∈ Rn×r contains r left singular vectors u1,u2, . . .",2.1. Notation and linear algebra basics,[0],[0]
",ur ∈ Rn, V contains r right singular vectors v1,v2, . . .",2.1. Notation and linear algebra basics,[0],[0]
",vr ∈ Rd, and Σ ∈",2.1. Notation and linear algebra basics,[0],[0]
Rr×r is a positive diagonal matrix containing the singular values of A : σ1(A),2.1. Notation and linear algebra basics,[0],[0]
≥ σ2(A),2.1. Notation and linear algebra basics,[0],[0]
≥ · · · ≥ σr(A).,2.1. Notation and linear algebra basics,[0],[0]
A can also be written as A = ∑r i=1,2.1. Notation and linear algebra basics,[0],[0]
σi(A)uiv >,2.1. Notation and linear algebra basics,[0],[0]
i .,2.1. Notation and linear algebra basics,[0],[0]
"For any k ≤ r,
Ak = ∑k i=1",2.1. Notation and linear algebra basics,[0],[0]
σi(A)uiv >,2.1. Notation and linear algebra basics,[0],[0]
"i is the best rank k approximation to A for any unitarily invariant norm, including Frobenious
and spectral norm (Mirsky, 1960).",2.1. Notation and linear algebra basics,[0],[0]
Note that,2.1. Notation and linear algebra basics,[0],[0]
A = Ak + Ar−k,2.1. Notation and linear algebra basics,[0],[0]
where Ar−k =,2.1. Notation and linear algebra basics,[0],[0]
∑r,2.1. Notation and linear algebra basics,[0],[0]
i=k+1 σi(A)uiv >,2.1. Notation and linear algebra basics,[0],[0]
i .,2.1. Notation and linear algebra basics,[0],[0]
"Therefore, Ar−k = A−Ak.",2.1. Notation and linear algebra basics,[0],[0]
"Square Frobenious norm of A is given by ‖A‖2F = ∑ i,jA(i, j) 2 = trace(AA>)",2.1. Notation and linear algebra basics,[0],[0]
= ∑,2.1. Notation and linear algebra basics,[0],[0]
i σ 2,2.1. Notation and linear algebra basics,[0],[0]
i (A).,2.1. Notation and linear algebra basics,[0],[0]
The spectral norm of A is given by ‖A‖2 = σ1(A).,2.1. Notation and linear algebra basics,[0],[0]
Ak satisfies ‖A −Ak‖F =,2.1. Notation and linear algebra basics,[0],[0]
"minB,rank(B)=k ‖A",2.1. Notation and linear algebra basics,[0],[0]
"− B‖F and ‖A−Ak‖2 = minB,rank(B)=k ‖A−B‖2.",2.1. Notation and linear algebra basics,[0],[0]
"The objective of k-means clustering is to partition n data points in Rd, {a1, . . .",2.2. K-means clustering,[0],[0]
",an}, into k non-overlapping clusters C = {C1, . . .",2.2. K-means clustering,[0],[0]
", Ck} such that points that are close to each other belong to the same cluster and points that are far from each other belong to to different clusters.",2.2. K-means clustering,[0],[0]
"Let µi be the centroid of cluster Ci and for any data point ai, let C(ai) be the index of the cluster to which ai is assigned to.",2.2. K-means clustering,[0],[0]
"The goal of k-means clustering is to minimize the objective function
k∑ i=1",2.2. K-means clustering,[0],[0]
∑ aj∈Ci ‖aj −µi‖22,2.2. K-means clustering,[0],[0]
"= n∑ j=1 ‖aj −µC(aj)‖ 2 2 (1)
",2.2. K-means clustering,[0],[0]
"Let A ∈ Rn×d be a data matrix containing the n data points {a1, . . .",2.2. K-means clustering,[0],[0]
",an} as rows and for any clustering C, let XC ∈ Rn×k be the cluster indicator matrix, with XC(i, j) = 1/ √",2.2. K-means clustering,[0],[0]
"|Cj | if ai is assigned to Cj and XC(i, j) = 0",2.2. K-means clustering,[0],[0]
otherwise.,2.2. K-means clustering,[0],[0]
"The k-means objective function given in equation 1 can now be represented in the matrix notation as,
",2.2. K-means clustering,[0],[0]
"‖A−XCX>CA‖2F = n∑ j=1 ‖aj −µC(aj)‖ 2 2 (2)
",2.2. K-means clustering,[0],[0]
"By construction, the columns of XC have disjoint support and are orthonormal vectors and XCX>C is an orthogonal projection matrix of rank k.",2.2. K-means clustering,[0],[0]
Let S be the set of all possible rank k cluster projection matrices of the form,2.2. K-means clustering,[0],[0]
XCX>C .,2.2. K-means clustering,[0],[0]
"The objective of k-means clustering is to find an optimal clustering of A that minimizes the objective function in equation
2, that is, to find XCopt such that,
XCopt = argmin XCX>C ∈S
‖A−XCX>CA‖2F
As mentioned earlier, finding XCopt is an NP-hard problem.",2.2. K-means clustering,[0],[0]
"Any cluster indicator matrix Xγ is called an γapproximation for the k-means clustering problem (γ ≥ 1) for data matrix A if it satisfies,
‖A−XγX>γA‖2F ≤",2.2. K-means clustering,[0],[0]
γ min,2.2. K-means clustering,[0],[0]
XCX>C ∈S,2.2. K-means clustering,[0],[0]
"‖A−XCX>CA‖2F
= γ‖A−XCoptX>CoptA‖ 2 F",2.2. K-means clustering,[0],[0]
"Given a data matrix A ∈ Rn×d, the basic idea of random matrix sparsification is to randomly sparsify the entries of A to get a matrix Ã ∈ Rn×d such that Ã contains fewer nonzero entries compared to A. Such a sparse matrix Ã speeds up matrix-vector multiplication by decreasing the number of arithmetic operations.",2.3. Random matrix sparsification,[0],[0]
"Let us write Ã = A+N, where N ∈ Rn×d.",2.3. Random matrix sparsification,[0],[0]
"A fundamental result of random matrix theory is that, as long as N is a random matrix whose entries are zero mean, independent random variables with bounded variance, no low dimensional subspace accommodates N well, i.e., ‖Nm‖2 and ‖Nm‖F are small for small m. In fact, optimal rank m approximation to Ã approximates A nearly as well as Am as long as ‖Am‖ ‖Nm‖ (for both Frobenious and spectral norm) and the quantity ‖Nm‖ bounds the influence that N may exert on the optimal rank m approximation to Ã.",2.3. Random matrix sparsification,[0],[0]
"Next we describe a simple random uniform sampling scheme as well as a simple non-uniform sampling scheme for generating sparse Ã that were proposed in (Achlioptas & Mcsherry, 2007) along with bounds on ‖Nm‖.",2.3. Random matrix sparsification,[0],[0]
"In the following, we set b to be b = max(i,j) |A(i, j)|.",2.3. Random matrix sparsification,[0],[0]
"In random matrix sparsificaion using uniform sampling scheme, p fraction of entries of A are set to zero to obtain a sparse Ã.",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"In particular,
Ã(i, j) = { A(i, j)/p with probability p 0 otherwise
(3)
It was shown in (Achlioptas & Mcsherry, 2007) that as long as p is bounded from below, with high probability, ‖Nm‖ is bounded as shown below (a simplified version of a result from (Achlioptas & Mcsherry, 2007)).
",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
Theorem 1.,2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"[Theorem 2 of (Achlioptas & Mcsherry, 2007)]",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"For p ≥ (8 log n)4/n, let Ã be the random sparse matrix obtained by applying uniform sampling scheme (equation 3).",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"Then with probability at least (1 − 1/n19 log3 n), for any m ≤ min{n, d}, N satisfies ‖Nm‖2 ≤",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"4b √ n/p and
‖Nm‖F ≤",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
4b,2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
√ mn/p.,2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
Random sparsification using uniform sampling can be improved by retaining entries with probability that depends on their magnitude.,2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"For any p > 0 define τij = p(A(i, j)/b)2
and let pij = max { τij , √ τij × (8 log n)4/n } .",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"Then a
sparse Ã can be obtained from A using the following nonuniform sampling scheme.
",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"Ã(i, j) = { A(i, j)/pij with probability pij 0",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"otherwise (4)
Such non-uniform sampling scheme yields greater sparsification when entry magnitudes vary, without increasing error bound of Theorem 1.
",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
Theorem 2.,2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"[Theorem 3 of (Achlioptas & Mcsherry, 2007)] Let Ã be the random sparse matrix obtained by applying non-uniform sampling scheme (equation 4).",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"Then with probability at least (1− 1/n19 log3 n), for any m ≤ min{n, d}, N satisfies ‖Nm‖2 ≤",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
4b √ n/p and ‖Nm‖F ≤ 4b √ mn/p.,2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
most p(‖A‖F /b)2,"In addition, expected number of non-zero entries in Ã is at",[0],[0]
"+ d(8 log n)4.
","In addition, expected number of non-zero entries in Ã is at",[0],[0]
"For any s > 0, setting p = s(b/‖A‖F )2 in the above Theorem ensures that expected number of non-zero entries in Ã is at most s+ d(8 log n)4.","In addition, expected number of non-zero entries in Ã is at",[0],[0]
"While the goal of k-means clustering is to well approximate each row of A with its cluster center, as can be seen from equation 1, an equivalent formulation in equation 2 shows that the problem actually amounts to finding an optimal rank
Algorithm 1 K-means clustering using random sparsification Input : Data matrix A ∈ Rn×d, number of clusters k, a positive scalar p and a γ-approximation k-means algorithm.",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"Output : Cluster indicator matrix Xγ̃ determining a k partition of the rows of A.
1: Compute Ã using non-uniform sampling scheme (equation 4).",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
2: Run the γ-approximation k-means algorithm on Ã to obtain Xγ̃ .,3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"3: Return Xγ̃ .
",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"k subspace for approximating the columns of A. Moreover, the choice of subspace is constrained because it must be spanned by the columns of a cluster indicator matrix.",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"The random sampling schemes presented in the previous section yields a sparse Ã whose optimal rank m approximation Ãm approximates Am reasonably well for small m. For appropriate choice of m, if such Am approximates optimal rank k subspace for approximating the columns of A well, then a reasonable strategy for k-means clustering that will reduce number of arithmetic operations is to perform kmeans clustering on Ã, instead of A, and hope that optimal k-means clustering solution of Ã will be close to optimal kmeans clustering solution of A. We propose such a strategy in Algorithm 1.",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
In the next section we present an analysis of this algorithm and prove that an optimal k-means clustering solution of Ã indeed results in an approximately optimal k-means objective of A.,3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
In this section we present an analysis of Algorithm 1.,4. Analysis of algorithm,[0],[0]
For all our results we have assumed that n,4. Analysis of algorithm,[0],[0]
≥,4. Analysis of algorithm,[0],[0]
d.,4. Analysis of algorithm,[0],[0]
"The main intuition for the technical part of the proof is that even though A and Ã look very different because of the enforced sparse structure, if their appropriate low-rank structures are similar, that is enough to argue that optimal k-means solution of Ã is close to optimal k-means solution of A. We use the notion of projection cost preserving sketch1 as a useful mathematical object for our proof.",4. Analysis of algorithm,[0],[0]
"If B is a rank k projection-cost preserving sketch for A with error 1, then it implies (can be easily shown) that optimal k-means solution of B is (1 + 1) optimal k-means solution of A (Cohen et al., 2015).",4. Analysis of algorithm,[0],[0]
"It turns out that for appropriate choice of m = m(k, 1), the best rankm approximation of A, namely Am, constructed by the m largest SVD structure form a rank k projection-cost preserving sketch for A with error 1.
1B ∈ Rn×d ′
is a rank k projection-cost preserving sketch of A ∈ Rn×d, with error 0 ≤ ≤ 1 if, for all rank k orthogonal projection matrices P ∈ Rn×n it holds",4. Analysis of algorithm,[0],[0]
that (1− )‖A−PA‖2F ≤,4. Analysis of algorithm,[0],[0]
‖B − PB‖2F + c ≤ (1 + ),4. Analysis of algorithm,[0],[0]
‖A,4. Analysis of algorithm,[0],[0]
"− PA‖2F for some fixed nonnegative constant c that may depend on A and B but is independent of P.
Similarly, Ãm is a rank k projection-cost preserving sketch for Ã.",4. Analysis of algorithm,[0],[0]
"We show that optimal k-means solution of Ã is close to optimal k-mean solution of A in two steps.
1.",4. Analysis of algorithm,[0],[0]
"First, we show the reverse direction of the implication of rank k projection-cost preserving sketch also holds.",4. Analysis of algorithm,[0],[0]
"In particular, we show that an optimal k-means solution of Ã is also (1 +O( 1)) optimal for Ãm.
2.",4. Analysis of algorithm,[0],[0]
Then we show that Ãm is also rank k projection-cost preserving sketch for A with a different error 2.,4. Analysis of algorithm,[0],[0]
"(this is where we quantify amount of sparsity to k-means error)
",4. Analysis of algorithm,[0],[0]
"Combining these two facts and properly choosing 1 and 2, we conclude that optimal k-means solution of Ã is (1 + )",4. Analysis of algorithm,[0],[0]
optimal k-means solution of A. We lay out the necessary details in the following subsections.,4. Analysis of algorithm,[0],[0]
"Ã and Ãm
We first show that close to optimal cluster indicator matrix obtained by solving k-means clustering problem on Ã yields a close to optimal k-means objective of Ãm.
",4.1. Relation between clustering objective functions of,[0],[0]
Lemma 1.,4.1. Relation between clustering objective functions of,[0],[0]
"For any 0 < ≤ 1/2, let m = dk/ e.",4.1. Relation between clustering objective functions of,[0],[0]
For any Ã ∈ Rn×d with rank r ≥ dk/,4.1. Relation between clustering objective functions of,[0],[0]
"e + k, let Ãm be its best rank m approximation.",4.1. Relation between clustering objective functions of,[0],[0]
"For any set S of rank k cluster projection matrices, let P̃∗ = argminP∈S ‖Ã",4.1. Relation between clustering objective functions of,[0],[0]
− PÃ‖2F and P̃∗m = argminP∈S ‖Ãm−PÃm‖2F .,4.1. Relation between clustering objective functions of,[0],[0]
"For any γ ≥ 1, if ‖Ã− P̂Ã‖2F ≤ γ‖Ã− P̃∗Ã‖2F , then, ‖Ãm− P̂Ãm‖2F ≤ γ‖Ãm",4.1. Relation between clustering objective functions of,[0],[0]
− P̃∗mÃm‖2F,4.1. Relation between clustering objective functions of,[0],[0]
+ (γ − 1)‖Ã − Ãm‖2F + ‖P̂(Ã − Ãm)‖2F .,4.1. Relation between clustering objective functions of,[0],[0]
"In particular, the following holds.
",4.1. Relation between clustering objective functions of,[0],[0]
(i),4.1. Relation between clustering objective functions of,[0],[0]
"If γ = 1, then, ‖Ãm − P̃∗Ãm‖2F ≤ (1 + 2 )‖Ãm",4.1. Relation between clustering objective functions of,[0],[0]
− P̃∗mÃm‖2.,4.1. Relation between clustering objective functions of,[0],[0]
(ii),4.1. Relation between clustering objective functions of,[0],[0]
"If γ = 1 + 1, for any 0 < 1 < 1 satisfying 1 ∑r i=m+1 σ 2 i (Ã) ≤ ∑m+k",4.1. Relation between clustering objective functions of,[0],[0]
"i=m+1 σ 2 i (Ã), then, ‖Ãm",4.1. Relation between clustering objective functions of,[0],[0]
− P̂Ãm‖2F ≤ (1 + 1 + 4 ),4.1. Relation between clustering objective functions of,[0],[0]
‖Ãm,4.1. Relation between clustering objective functions of,[0],[0]
"− P̃∗mÃm‖2.
",4.1. Relation between clustering objective functions of,[0],[0]
"Proof of the above lemma, which follows from repeated applications of linear algebra basics, choice of m, definition of P̂ and optimality of P̃∗, is long and technical and is differed to the supplementary material for better readability.",4.1. Relation between clustering objective functions of,[0],[0]
"Note that on the left hand side of the first inequality above (for γ = 1), we have used P̃∗ instead of P̂ since P̂ and P̃∗ are identical for γ",4.1. Relation between clustering objective functions of,[0],[0]
= 1.,4.1. Relation between clustering objective functions of,[0],[0]
Now we show that optimal cluster indicator matrix obtained by solving k-means clustering problem on Ãm results in close to optimal k-means objective of A. Let P∗,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"=
argminP∈S",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
‖A − PA‖2F and P̃∗m =,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
argminP∈S,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
‖Ãm,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
− PÃm‖2F .,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Our goal is to show that ‖A−P̃∗mA‖2F is close to ‖A−P∗A‖2F .,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"In fact, we prove a stronger result showing that Ãm is a rank k projection cost preserving sketch2 of A.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
We do this in multiple steps.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"First we show that for small k, Ãm is approximately best rank m subspace of A. Next, we show that such an Ãm is a rank k projection cost preserving sketch for A, which in turn ensures the required guarantee.
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
We start with the following lemma which is a consequence of Theorem 2.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Lemma 2.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Fix any m ≥ 1 and let 0 < 2,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
< 1/,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"√ m. Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = 16nb 2
22‖A‖2F .",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Then Ã contains O ( n 22 + d(log n)4 ) non-zero entries in expectation and with probability at least (1− 1/n19 log3 n),
‖A− Ãm‖F ≤ ‖A−Am‖F + 3 √ 2m 1/4‖A‖F
We tailor the above result to show that under mild conditions Ãm approximates Am reasonably well.
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Lemma 3.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Fix any 3, where 0 < 3 < 1.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Let rank of A be ρ.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Fix any k that satisfies ∑k/ 3 i=1 σ,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
2 i (A) ≤ 12,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
∑ρ i=1,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
σ 2,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"i (A), and let m = dk/ 3e.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = O ( nb2k
93‖A‖2F
) .",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Then Ã contains
O ( nk 93 + d(log n)4 ) non-zero entries in expectation and with probability at least (1− 1/n19 log3 n),
‖A− Ãm‖F ≤ (1 + 23)‖A−Am‖F
Next, we use a result from (Cohen et al., 2015) to show that if Ãm is close to best rank approximation of A, then Ãm is rank k projection cost preserving sketch for A.
Theorem 3.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"[Theorem 9 of (Cohen et al., 2015)] Let m = dk/ 3e.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"For any A ∈ Rn×d, 0 ≤ 4 ≤ 1 and any B ∈ Rn×d with rank(B) = m satisfying ‖A",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"− B‖2F ≤ (1 + 24)‖A−Am‖2F , the sketch B is a projection cost preserving sketch for A. Specifically, for all rank k orthogonal projections P,
(1− 2 4)‖A−PA‖2F ≤",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
‖B−PB‖2F,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
+ c ≤,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"(1 + 2 3 + 5 4)‖A−PA‖2F
where c is a non-negative scalar.
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"From Lemma 3 we see that with high probability, ‖A − Ãm‖2F ≤ (1 + 2 23 + 43)‖A −Am‖2F = (1 + 3 23)‖A −
2If B is a rank k projection cost preserving sketch of A, then optimal k-means clustering solution of B results in approximately optimal k-means clustering objective of A (Cohen et al., 2015).
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Am‖2F .,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Setting 4 = √
3 3 and B = Ãm, it follows from Theorem 3 that Ãm is a rank k projection cost preserving sketch of A.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
We combine these results from previous two subsections to present the main result of this paper.,4.3. Main result,[0],[0]
Theorem 4.,4.3. Main result,[0],[0]
"Fix any , where 0 < < 1/4.",4.3. Main result,[0],[0]
Let rank of A be ρ.,4.3. Main result,[0],[0]
For any k that satisfies ∑k/ i=1,4.3. Main result,[0],[0]
σ,4.3. Main result,[0],[0]
2,4.3. Main result,[0],[0]
i (A) ≤ 1 2 ∑ρ i=1,4.3. Main result,[0],[0]
σ 2,4.3. Main result,[0],[0]
"i (A), and let m = dk/ e. Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = O ( nb2k
9‖A‖2F
) .",4.3. Main result,[0],[0]
"For any
set S of rank k cluster projection matrices, let P∗",4.3. Main result,[0],[0]
= argminP∈S,4.3. Main result,[0],[0]
"‖A−PA‖2F , P̃∗ = argminP∈S ‖Ã−PÃ‖2F and P̃∗m = argminP∈S",4.3. Main result,[0],[0]
‖Ãm,4.3. Main result,[0],[0]
− PÃm‖2F .,4.3. Main result,[0],[0]
"For any γ ≥ 1, if ‖Ã − P̂Ã‖2F ≤ γ‖Ã",4.3. Main result,[0],[0]
"− P̃∗Ã‖2F , then Ã contains O ( nk 9 + d(log n) 4 )
non-zero entries in expectation and with probability at least (1 − 1/n19 log3 n)",4.3. Main result,[0],[0]
"the following holds,
(i)",4.3. Main result,[0],[0]
"If γ = 1, then ‖A−P̂A‖2F ≤ (1+2 )(1+11 ) 1−4 ‖A−P ∗A‖2
(ii) If γ = 1 + 1, for any 0 < 1 < 1 satisfying 1 ∑r i=m+1 σ 2 i (Ã) ≤ ∑m+k",4.3. Main result,[0],[0]
"i=m+1 σ 2 i (Ã), then ‖A − P̂A‖2F ≤ (1+ 1+4 )(1+11 ) 1−4 ‖A−P ∗A‖2
Proof.",4.3. Main result,[0],[0]
Set 3 = .,4.3. Main result,[0],[0]
"Then from Lemma 3 we get, ‖A − Ãm‖2F ≤ (1 + 3 2)‖A −Am‖2F .",4.3. Main result,[0],[0]
"Now setting B = Ãm and 4 = √ 3 in Theorem 3, for any rank k orthogonal projection P we get, (1− 2 √
3 )‖A−PA‖2F ≤",4.3. Main result,[0],[0]
‖Ãm −PÃm‖2F + c ≤,4.3. Main result,[0],[0]
"(1 + 2 + 5 √ 3 )‖A−PA‖2F
or simplifying,
(1− 4 )‖A−PA‖2F ≤",4.3. Main result,[0],[0]
‖Ãm −PÃm‖2F + c ≤,4.3. Main result,[0],[0]
(1 + 11 )‖A−PA‖2F,4.3. Main result,[0],[0]
"(5)
Let γ1 = (1 + 2 ) if γ = 1 and γ1 = (1 + 1 + 4 ) if γ ≥ 1.",4.3. Main result,[0],[0]
Then from lemma 1 we get ‖Ãm,4.3. Main result,[0],[0]
− P̂Ãm‖2F ≤ γ1‖Ãm,4.3. Main result,[0],[0]
− P̃∗mÃm‖2.,4.3. Main result,[0],[0]
"Using this result and repeated application of Equation 5 we get,
‖A− P̂A‖2F
≤ 1 1− 4
{",4.3. Main result,[0],[0]
"‖Ãm − P̂Ãm‖2F + c } ≤ 1
1− 4
{ γ1‖Ãm − P̃∗mÃm‖2F + c } ≤ 1
1− 4
{ γ1‖Ãm −P∗Ãm‖2F + c } ≤ 1
1− 4 { γ1",4.3. Main result,[0],[0]
[ (1 + 11 ),4.3. Main result,[0],[0]
‖A−P∗A‖2F,4.3. Main result,[0],[0]
− c ],4.3. Main result,[0],[0]
"+ c }
≤",4.3. Main result,[0],[0]
γ1(1 + 11 ),4.3. Main result,[0],[0]
"1− 4 ‖A−P∗A‖2F
Substituting appropriate value of γ1 yields the result.
",4.3. Main result,[0],[0]
The above result (Theorem 4) is obtained by stitching together many intermediate results.,4.3. Main result,[0],[0]
"To make sure that everything works at the end, we have different ranges for in Lemma 1 and Theorem 4.
",4.3. Main result,[0],[0]
A simple consequence of the above theorem is the following result which ensures (1 + ′) approximation for any 0,4.3. Main result,[0],[0]
< ′,4.3. Main result,[0],[0]
"< 1.
",4.3. Main result,[0],[0]
Corollary 1.,4.3. Main result,[0],[0]
"Fix any ′, where 0 < ′",4.3. Main result,[0],[0]
< 1.,4.3. Main result,[0],[0]
Let rank of A be ρ.,4.3. Main result,[0],[0]
Let m = O(k/ ′) and fix any k that satisfies∑m i=1 σ,4.3. Main result,[0],[0]
2,4.3. Main result,[0],[0]
i (A) ≤ 12,4.3. Main result,[0],[0]
∑ρ i=1,4.3. Main result,[0],[0]
σ 2,4.3. Main result,[0],[0]
i (A).,4.3. Main result,[0],[0]
"Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = O ( nb2k
( ′)9‖A‖2F
) .",4.3. Main result,[0],[0]
"For any set S of rank
k cluster projection matrices, let P∗",4.3. Main result,[0],[0]
= argminP∈S ‖A− PA‖2F and P̃∗ = argminP∈S ‖Ã,4.3. Main result,[0],[0]
− PÃ‖2F .,4.3. Main result,[0],[0]
For any 1 ≤ γ ≤ 2 satisfying (γ − 1) ∑r,4.3. Main result,[0],[0]
"i=m+1 σ
2 i (Ã) ≤∑m+k
i=m+1 σ 2 i (Ã), if ‖Ã− P̂Ã‖2F ≤ γ‖Ã−",4.3. Main result,[0],[0]
"P̃∗Ã‖2F , then Ã contains O (
nk ( ′)9 + d(log n)
4 )
non-zero entries in ex-
pectation and with probability at least (1−1/n19 log3 n)",4.3. Main result,[0],[0]
"the following holds,
‖A− P̂A‖2F ≤",4.3. Main result,[0],[0]
γ(1 + ′)‖A−P∗A‖2,4.3. Main result,[0],[0]
"In this section we present empirical evaluation of our proposed algorithm on three real world datasets: USPS, RCV1 and TDT2.",5. Empirical evaluations,[0],[0]
"The USPS dataset (Hull, 1994) contains 9298 handwritten digit images, where each 16 × 16 image is represented by a feature vector of length 256.",5. Empirical evaluations,[0],[0]
"We seek to find k = 10 clusters, one for each of the ten digits.",5. Empirical evaluations,[0],[0]
"The RCV1 dataset (Lewis et al., 2004) is an archive of over 800, 000 manually categorized news articles recently made available by Reuters.",5. Empirical evaluations,[0],[0]
"We use a smaller subset of this dataset available from LIBSVM webpage (LIB) containing 15, 564 news articles from 53 categories.",5. Empirical evaluations,[0],[0]
"Each such news article is represented by a feature vector of length 47, 236.",5. Empirical evaluations,[0],[0]
"We seek to find k = 53 clusters, one for each news article category.",5. Empirical evaluations,[0],[0]
"The TDT2 dataset (Cieri et al., 1999) consists of 11201 text documents which are classified into 96 semantic categories.",5. Empirical evaluations,[0],[0]
"We use a smaller subset of this dataset available from Deng Cai’s webpage3 where those documents appearing in two or more categories are removed, and only the largest 30 categories are kept, resulting in 9, 394 documents in total.",5. Empirical evaluations,[0],[0]
"Each such document is represented by a feature vector of length 36, 771.",5. Empirical evaluations,[0],[0]
"We seek to find k = 30 clusters, one for each news article category.",5. Empirical evaluations,[0],[0]
"For USPS dataset, all (100%) data matrix entries are non-zero.",5. Empirical evaluations,[0],[0]
"However, for TDT2 dataset, only 0.35% entries of the 9394 × 36771 data matrix are
3http://www.cad.zju.edu.cn/home/dengcai/Data/TextData.html
non-zero, while for RCV1 dataset, only 0.14% entries of the 15564 × 47236 data matrix are non-zero.",5. Empirical evaluations,[0],[0]
Since these two later datasets are already very sparse we reduce data dimensionality to 1000 using random projection in both cases by multiplying original data matrices with a random projection matrix (of appropriate size) whose entries are standard i.i.d.,5. Empirical evaluations,[0],[0]
normals4.,5. Empirical evaluations,[0],[0]
"After this random projection step, resulting projected data matrices become dense matrices, each containing 100% non-zero entries.",5. Empirical evaluations,[0],[0]
"As we will demonstrate next, for these two dense projected matrices our proposed sparsification method finds k-means clustering solution without severely affecting cluster quality.
",5. Empirical evaluations,[0],[0]
"To apply Lloyd’s heuristic for k-means clustering we use Matlab’s kmeans function which, by default, uses kmeans++ algorithm (Arthur & Vassilvitskii, 2007) for cluster center initialization.",5. Empirical evaluations,[0],[0]
"We repeat this clustering 30 times, each time initializing cluster center using k-means++ and selecting the final clustering as the one with lowest k-means objective.",5. Empirical evaluations,[0],[0]
"We demonstrate the effect of random sparsification obtained by uniform and non-uniform sampling on k-means clustering by reporting the following quantities, (a) the ratio h1(q) = ‖A−XqX>q",5. Empirical evaluations,[0],[0]
A‖2F /‖A−XX,5. Empirical evaluations,[0],[0]
">A‖2F , (b) cluster quality h2(q), measured by normalized mutual information (with respect to ground truth cluster labels of A) of a sparse data matrix Ã whose q fracation of entries are non-zero, and (c) normalized objective function h3(q) =",5. Empirical evaluations,[0],[0]
‖A − XqX>q A‖2F /‖A‖2F,5. Empirical evaluations,[0],[0]
",",5. Empirical evaluations,[0],[0]
as we vary q.,5. Empirical evaluations,[0],[0]
"In the above description, Xq is the cluster indicator matrix obtained by running k-means on sparse data matrix Ã whose q fraction of entries are non-zero and X is the cluster indicator matrix obtained by running k-means on A.
For uniform sampling, p simply indicates that p fraction
4It has been shown (Cohen et al., 2015) that such dimensionality reduction introduces (1 + ) relative error to optimal k-means objective.",5. Empirical evaluations,[0],[0]
"We chose projected dimension to be 1000 since increasing it further did not increase normalized mutual information significantly.
of entries of Ã are non-zero (in expectation, when A is dense matrix).",5. Empirical evaluations,[0],[0]
"For non-uniform sampling, number of nonzero entries in Ã can only be guaranteed by Theorem 2, which typically holds for large n.",5. Empirical evaluations,[0],[0]
In our empirical evaluation we use a slightly different strategy for non-uniform sampling than what is presented in section 2.3.2.,5. Empirical evaluations,[0],[0]
"However, this modified strategy, in principle, is still similar to what is presented in section 2.3.2.",5. Empirical evaluations,[0],[0]
"For any fixed value of p, note that τij = p(A(i, j)/b)
2.",5. Empirical evaluations,[0],[0]
"Now, instead of using pij in terms of τij as given in section 2.3.2, we use,
pij = { τij if τij ≥ p× f√ τij × p× f",5. Empirical evaluations,[0],[0]
"otherwise
where, f > 1, is to be chosen later.",5. Empirical evaluations,[0],[0]
"Therefore, for τij < p×f , pij = √ τij × p× f = p×(|A(i, j)|/b)× √ f .",5. Empirical evaluations,[0],[0]
"The basic idea is still same as before, i.e., when τij is small, instead of setting pij ∝",5. Empirical evaluations,[0],[0]
"(A(i, j))2, we set pij ∝",5. Empirical evaluations,[0],[0]
"|A(i, j)|.",5. Empirical evaluations,[0],[0]
"Now consider the case when τij < p× f , for all i, j.",5. Empirical evaluations,[0],[0]
"The expected number of non-zero entries is ∑ i,j p ×",5. Empirical evaluations,[0],[0]
√ f ×,5. Empirical evaluations,[0],[0]
"(|A(i, j)|/b) = pnd×",5. Empirical evaluations,[0],[0]
"√ f×Avg(|A(i, j)|/b).",5. Empirical evaluations,[0],[0]
"Therefore, if we choose5 f = 1/(Avg(|A(i, j)|/b))2, expected number of non-zero entries in Ã is pnd.",5. Empirical evaluations,[0],[0]
"In general, when the condition τij < p× f does not hold for all i, j, the expected fraction will be even less since pij < p, for τij ≥ p× f .",5. Empirical evaluations,[0],[0]
"In our experimental setting, we set f = 1/(Avg(|A(i, j)|/b))2.",5. Empirical evaluations,[0],[0]
"This ensures for any p, non-uniform sampling results in at most p fraction of non-zero entries in Ã. In our experiments, we vary p from 0.01 to 1.0 in steps of 0.01 and for each value of p, the number of of non-zero entries in Ã obtained due to non-uniform sampling is denoted by q and is plotted in Figure 2 for all three datasets.",5. Empirical evaluations,[0],[0]
"Observe that for all values of p, q = p for uniform sampling and q ≤ p for non-uniform sampling.
",5. Empirical evaluations,[0],[0]
"Next, in Figure 3 we show how random sparsification affects k-means clustering quality with increasing q.",5. Empirical evaluations,[0],[0]
"As can be seen from Figure 3, with increasing q, h1(q) and h3(q) decrease, while h2(q) increases as one would expect.",5. Empirical evaluations,[0],[0]
"In fact, h1(q) decreases quickly towards its optimal value 1 and corresponding h2(q) value quickly increases towards optimal k-means normalized mutual information of A. The normalized k-means objective h3(q)",5. Empirical evaluations,[0],[0]
"also shows steady decrease with increasing q. As can be seen from Figure 3, for all three datasets, non-uniform sampling yields better k-means clustering performance compared to uniform sampling.",5. Empirical evaluations,[0],[0]
"This makes perfect sense since non-uniform sampling, unlike uniform sampling, enforces sparsity by retaining entries with probability that depends on their magnitude.",5. Empirical evaluations,[0],[0]
"In fact, for TDT2 and RCV1 datasets, non-uniform sampling results in significant improvement in k-means clustering performance compared to uniform sampling.
",5. Empirical evaluations,[0],[0]
"5Avg(|A(i, j)|) represents average over all entries |A(i, j)|.
USPS
TDT2
RCV1",5. Empirical evaluations,[0],[0]
In this paper we proposed a simple algorithm for k-means clustering using random matrix sparsification and presented its analysis.,6. Conclusion,[0],[0]
"We proved that under mild condition, for any ∈ (0, 1), a dense data matrix A ∈ Rn×d can be randomly sparsified to yield a data matrix Ã ∈ Rn×d containing O(nk/ 9 + d log4 n) non-zero entries in expectation, such that an (1+ )-approximate k-mean clustering solution of Ã results in (1 +O( ))-approximate clustering solution of A with high probability.",6. Conclusion,[0],[0]
"Empirical results on three real world datasets demonstrated that k-means clustering solution of Ã was indeed very close to k-means clustering solution of A. Moreover, sparsification obtained by non-uniform sampling resulted in better cluster quality compared to uniform sampling.",6. Conclusion,[0],[0]
Empirical results also seem to suggest that the O(1/ 9) dependence on the number of non-zero entries in Ã is possibly a bit loose.,6. Conclusion,[0],[0]
We conclude this paper with two possible open questions: (a) Is it possible to analytically provide a better estimate (by improving dependence on 1/ ) of the number of non-zero entries in the sparse matrix Ã that ensures (1 + ) approximation guarantee?,6. Conclusion,[0],[0]
"and, (b) Using different proof technique, is it possible to show that γ-approximate clustering solution of Ã will result in γ(1 + )-approximate solution of A as shown in Corollary 1, even for γ > 2?",6. Conclusion,[0],[0]
"In other words, is the restriction on γ
in Corollary 1 a limitation of the proof technique or does it indicate computational hardness of the problem?",6. Conclusion,[0],[0]
K-means clustering algorithm using Lloyd’s heuristic is one of the most commonly used tools in data mining and machine learning that shows promising performance.,abstractText,[0],[0]
"However, it suffers from a high computational cost resulting from pairwise Euclidean distance computations between data points and cluster centers in each iteration of Lloyd’s heuristic.",abstractText,[0],[0]
"Main contributing factor of this computational bottle neck is a matrix-vector multiplication step, where the matrix contains all the data points and the vector is a cluster center.",abstractText,[0],[0]
In this paper we show that we can randomly sparsify the original data matrix resulting in a sparse data matrix which can significantly speed up the above mentioned matrix vector multiplication step without significantly affecting cluster quality.,abstractText,[0],[0]
"In particular, we show that optimal k-means clustering solution of the sparse data matrix, obtained by applying random matrix sparsification, results in an approximately optimal k-means clustering objective of the original data matrix.",abstractText,[0],[0]
Our empirical studies on three real world datasets corroborate our theoretical findings and demonstrate that our proposed sparsification method can indeed achieve satisfactory clustering performance.,abstractText,[0],[0]
K-means clustering using random matrix sparsification,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1470–1480 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics
We introduce KBGAN, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models. Because knowledge graphs typically only contain positive facts, sampling useful negative training examples is a nontrivial task. Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training. Inspired by generative adversarial networks (GANs), we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in GANs. This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks. In experiments, we adversarially train two translation-based models, TRANSE and TRANSD, each with assistance from one of the two probability-based models, DISTMULT and COMPLEX. We evaluate the performances of KBGAN on the link prediction task, using three knowledge base completion datasets: FB15k-237, WN18 and WN18RR. Experimental results show that adversarial training substantially improves the performances of target embedding models under various settings.",text,[0],[0]
"Knowledge graph (Dong et al., 2014) is a powerful graph structure that can provide direct access of knowledge to users via various applications such as structured search, question answering, and intelligent virtual assistant.",1 Introduction,[0],[0]
"A common representation of knowledge graph beliefs is in the
form of a discrete relational triple such as LocatedIn(NewOrleans,Louisiana).
",1 Introduction,[0],[0]
A main challenge for using discrete representation of knowledge graph is the lack of capability of accessing the similarities among different entities and relations.,1 Introduction,[0],[0]
"Knowledge graph embedding (KGE) techniques (e.g., RESCAL (Nickel et al., 2011), TRANSE (Bordes et al., 2013), DISTMULT (Yang et al., 2015), and COMPLEX (Trouillon et al., 2016)) have been proposed in recent years to deal with the issue.",1 Introduction,[0],[0]
"The main idea is to represent the entities and relations in a vector space, and one can use machine learning technique to learn the continuous representation of the knowledge graph in the latent space.
",1 Introduction,[0],[0]
"However, even steady progress has been made in developing novel algorithms for knowledge graph embedding, there is still a common challenge in this line of research.",1 Introduction,[0],[0]
"For space efficiency, common knowledge graphs such as Freebase (Bollacker et al., 2008), Yago (Suchanek et al., 2007), and NELL (Mitchell et al., 2015) by default only stores beliefs, rather than disbeliefs.",1 Introduction,[0],[0]
"Therefore, when training the embedding models, there is only the natural presence of the positive examples.",1 Introduction,[0],[0]
"To use negative examples, a common method is to remove the correct tail entity, and randomly sample from a uniform distribution (Bordes et al., 2013).",1 Introduction,[0],[0]
"Unfortunately, this approach is not ideal, because the sampled entity could be completely unrelated to the head and the target relation, and thus the quality of randomly generated negative examples is often poor (e.g, LocatedIn(NewOrleans,BarackObama)).",1 Introduction,[0],[0]
"Other approach might leverage external ontological constraints such as entity types (Krompaß et al., 2015) to generate negative examples, but such resource does not always exist or accessible.
",1 Introduction,[0],[0]
"In this work, we provide a generic solution to improve the training of a wide range of knowl-
1470
edge graph embedding models.",1 Introduction,[0],[0]
"Inspired by the recent advances of generative adversarial deep models (Goodfellow et al., 2014), we propose a novel adversarial learning framework, namely, KBGAN, for generating better negative examples to train knowledge graph embedding models.",1 Introduction,[0],[0]
"More specifically, we consider probabilitybased, log-loss embedding models as the generator to supply better quality negative examples, and use distance-based, margin-loss embedding models as the discriminator to generate the final knowledge graph embeddings.",1 Introduction,[0],[0]
"Since the generator has a discrete generation step, we cannot directly use the gradient-based approach to backpropagate the errors.",1 Introduction,[0],[0]
"We then consider a onestep reinforcement learning setting, and use a variance-reduction REINFORCE method to achieve this goal.",1 Introduction,[0],[0]
"Empirically, we perform experiments on three common KGE datasets (FB15K-237, WN18 and WN18RR), and verify the adversarial learning approach with a set of KGE models.",1 Introduction,[0],[0]
"Our experiments show that across various settings, this adversarial learning mechanism can significantly improve the performance of some of the most commonly used translation based KGE methods.",1 Introduction,[0],[0]
"Our contributions are three-fold:
•",1 Introduction,[0],[0]
"We are the first to consider adversarial learning to generate useful negative training examples to improve knowledge graph embedding.
",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"This adversarial learning framework applies to a wide range of KGE models, without the need of external ontologies constraints.
",1 Introduction,[0],[0]
• Our method shows consistent performance gains on three commonly used KGE datasets.,1 Introduction,[0],[0]
"A large number of knowledge graph embedding models, which represent entities and relations in a knowledge graph with vectors or matrices, have been proposed in recent years.",2.1 Knowledge Graph Embeddings,[0],[0]
"RESCAL (Nickel et al., 2011) is one of the earliest studies on matrix factorization based knowledge graph embedding models, using a bilinear form as score function.",2.1 Knowledge Graph Embeddings,[0],[0]
"TRANSE (Bordes et al., 2013) is the first model to introduce translation-based embedding.",2.1 Knowledge Graph Embeddings,[0],[0]
"Later variants, such as TRANSH (Wang et al., 2014), TRANSR (Lin et al., 2015) and TRANSD (Ji et al., 2015), extend TRANSE by projecting the embedding vectors of entities into various spaces.",2.1 Knowledge Graph Embeddings,[0],[0]
"DISTMULT (Yang et al., 2015) simplifies RESCAL by only using a diagonal matrix, and COMPLEX (Trouillon et al., 2016) extends DISTMULT into the complex number field.",2.1 Knowledge Graph Embeddings,[0],[0]
"(Nickel et al., 2015) is a comprehensive survey on these models.
",2.1 Knowledge Graph Embeddings,[0],[0]
Some of the more recent models achieve strong performances.,2.1 Knowledge Graph Embeddings,[0],[0]
"MANIFOLDE (Xiao et al., 2016) embeds a triple as a manifold rather than a point.",2.1 Knowledge Graph Embeddings,[0],[0]
"HOLE (Nickel et al., 2016) employs circular correlation to combine the two entities in a triple.",2.1 Knowledge Graph Embeddings,[0],[0]
"CONVE (Dettmers et al., 2017) uses a convolutional neural network as the score function.",2.1 Knowledge Graph Embeddings,[0],[0]
"However, most of these studies use uniform sampling to generate negative training examples (Bordes et al., 2013).",2.1 Knowledge Graph Embeddings,[0],[0]
"Because our framework is independent of the concrete form of models, all these models can be potentially incorporated into our framework, regardless of the complexity.",2.1 Knowledge Graph Embeddings,[0],[0]
"As a proof of principle, our work focuses on simpler models.",2.1 Knowledge Graph Embeddings,[0],[0]
Table 1 summarizes the score functions and dimensions of all models mentioned above.,2.1 Knowledge Graph Embeddings,[0],[0]
"Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) was originally proposed for generating samples in a continuous space such as images.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"A GAN consists of two parts, the generator and the discriminator.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
The generator accepts a noise input and outputs an image.,2.2 Generative Adversarial Networks and its Variants,[0],[0]
The discriminator is a classifier which classifies images as “true” (from the ground truth set) or “fake” (generated by the generator).,2.2 Generative Adversarial Networks and its Variants,[0],[0]
"When training a GAN, the generator and the discriminator play a minimax game, in which the generator tries to generate “real” images to deceive the discriminator, and the discriminator tries to tell them apart from ground truth images.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"GANs are also capable of generating samples satisfying certain requirements, such as conditional GAN (Mirza and Osindero, 2014).
",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"It is not possible to use GANs in its original form for generating discrete samples like natural language sentences or knowledge graph triples, because the discrete sampling step prevents gradients from propagating back to the generator.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"SEQGAN (Yu et al., 2017) is one of the first successful solutions to this problem by using reinforcement learning—It trains the generator using policy gradient and other tricks.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"IRGAN (Wang et al., 2017) is a recent work which combines two categories of information retrieval models into a discrete GAN framework.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"Likewise, our framework relies on policy gradient to train the generator which provides discrete negative triples.
",2.2 Generative Adversarial Networks and its Variants,[0],[0]
The discriminator in a GAN is not necessarily a classifier.,2.2 Generative Adversarial Networks and its Variants,[0],[0]
"Wasserstein GAN or WGAN (Arjovsky et al., 2017) uses a regressor with clipped parameters as its discriminator, based on solid analysis about the mathematical nature of GANs.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"GOGAN (Juefei-Xu et al., 2017) further replaces the loss function in WGAN with marginal loss.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"Although originating from very different fields, the form of loss function in our framework turns out to be more closely related to the one in GOGAN.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"In this section, we first define two types of training objectives in knowledge graph embedding models to show how KBGAN can be applied.",3 Our Approaches,[0],[0]
"Then, we demonstrate a long overlooked problem about negative sampling which motivates us to propose KBGAN to address the problem.",3 Our Approaches,[0],[0]
"Finally, we dive into the mathematical, and algorithmic details of
KBGAN.",3 Our Approaches,[0],[0]
"For a given knowledge graph, let E be the set of entities, R be the set of relations, and T be the set of ground truth triples.",3.1 Types of Training Objectives,[0],[0]
"In general, a knowledge graph embedding (KGE) model can be formulated as a score function f(h, r, t), h, t ∈ E , r ∈ R which assigns a score to every possible triple in the knowledge graph.",3.1 Types of Training Objectives,[0],[0]
"The estimated likelihood of a triple to be true depends only on its score given by the score function.
",3.1 Types of Training Objectives,[0],[0]
"Different models formulate their score function based on different designs, and therefore interpret scores differently, which further lead to various training objectives.",3.1 Types of Training Objectives,[0],[0]
"Two common forms of training objectives are particularly of our interest: Marginal loss function is commonly used by a large group of models called translation-based models, whose score function models distance between points or vectors, such as TRANSE, TRANSH, TRANSR, TRANSD and so on.",3.1 Types of Training Objectives,[0],[0]
"In these models, smaller distance indicates a higher likelihood of truth, but only qualitatively.",3.1 Types of Training Objectives,[0],[0]
"The marginal loss function takes the following form:
Lm = ∑
(h,r,t)∈T [f(h, r, t)− f(h′, r, t′) +",3.1 Types of Training Objectives,[0],[0]
"γ]+ (1)
where γ is the margin, [·]+ = max(0, ·) is the hinge function, and (h′, r, t′) is a negative triple.",3.1 Types of Training Objectives,[0],[0]
"The negative triple is generated by replacing the head entity or the tail entity of a positive triple with a random entity in the knowledge graph, or formally (h′, r, t′) ∈ {(h′, r, t)|h′ ∈ E} ∪ {(h, r, t′)|t′ ∈ E}.",3.1 Types of Training Objectives,[0],[0]
Log-softmax loss function is commonly used by models whose score function has probabilistic interpretation.,3.1 Types of Training Objectives,[0],[0]
"Some notable examples are RESCAL, DISTMULT, COMPLEX.",3.1 Types of Training Objectives,[0],[0]
"Applying the softmax function on scores of a given set of triples gives the probability of a triple to be the best one among them: p(h, r, t) = exp f(h,r,t)∑
(h′,r,t′) exp f(h ′,r,t′) .",3.1 Types of Training Objectives,[0],[0]
"The loss
function is the negative log-likelihood of this probabilistic model:
",3.1 Types of Training Objectives,[0],[0]
"Ll = ∑
(h,r,t)∈T − log exp f(h, r, t)∑ exp f(h′, r, t′)
(h′, r, t′) ∈ {(h, r, t)} ∪Neg(h, r, t) (2) where Neg(h, r, t) ⊂ {(h′, r, t)|h′ ∈ E} ∪ {(h, r, t′)|t′ ∈ E} is a set of sampled corrupted triples.
",3.1 Types of Training Objectives,[0],[0]
"Other forms of loss functions exist, for example CONVE uses a triple-wise logistic function to model how likely the triple is true, but by far the two described above are the most common.",3.1 Types of Training Objectives,[0],[0]
"Also, softmax function gives an probabilistic distribution over a set of triples, which is necessary for a generator to sample from them.",3.1 Types of Training Objectives,[0],[0]
"Most previous KGE models use uniform negative sampling for generating negative triples, that is, replacing the head or tail entity of a positive triple with any of the entities in E , all with equal probability.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Most of the negative triples generated in this way contribute little to learning an effective embedding, because they are too obviously false.
",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"To demonstrate this issue, let us consider the following example.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Suppose we have a ground truth triple LocatedIn(NewOrleans,Louisiana), and corrupt it by replacing its tail entity.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"First, we remove the tail entity, leaving LocatedIn(NewOrleans,?).",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Because the relation LocatedIn constraints types of its entities, “?” must be a geographical region.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"If we fill “?” with a random entity e ∈ E , the probability of e having a wrong type is very high, resulting in ridiculous triples like LocatedIn(NewOrleans,BarackObama) or LocatedIn(NewOrleans,StarTrek).",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Such triples are considered “too easy”, because they can be eliminated solely by types.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"In contrast, LocatedIn(NewOrleans,Florida) is a very useful negative triple, because it satisfies type constraints, but it cannot be proved wrong without detailed knowl-
edge of American geography.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"If a KGE model is fed with mostly “too easy” negative examples, it would probably only learn to represent types, not the underlying semantics.
",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"The problem is less severe to models using logsoftmax loss function, because they typically samples tens or hundreds of negative triples for one positive triple in each iteration, and it is likely to have a few useful negatives among them.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"For instance, (Trouillon et al., 2016) found that a 100:1 negative-to-positive ratio results in the best performance for COMPLEX.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"However, for marginal loss function, whose negative-to-positive ratio is always 1:1, the low quality of uniformly sampled negatives can seriously damage their performance.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Inspired by GANs, we propose an adversarial training framework named KBGAN which uses a KGE model with softmax probabilities to provide high-quality negative samples for the training of a KGE model whose training objective is marginal loss function.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"This framework is independent of the score functions of these two models, and therefore possesses some extent of universality.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Figure 1 illustrates the overall structure of KBGAN.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In parallel to terminologies used in GAN literature, we will simply call these two models generator and discriminator respectively in the rest of this paper.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"We use softmax probabilistic models as the generator because they can adequately model the “sampling from a probability distribu-
Algorithm 1: The KBGAN algorithm Data: training set of positive fact triples T = {(h, r, t)}",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Input: Pre-trained generator G with parameters θG and score function fG(h, r, t), and pre-trained discriminator D with
parameters θD and score function fD(h, r, t)",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Output: Adversarially trained discriminator
1 b←− 0; // baseline for policy gradient 2 repeat 3 Sample a mini-batch of data Tbatch from T ; 4 GG ←− 0, GD ←− 0; // gradients of parameters of G and D 5 rsum ←− 0; // for calculating the baseline 6 for (h, r, t) ∈",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Tbatch do 7 Uniformly randomly sample Ns negative triples Neg(h, r, t) =",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"{(h′i, r, t′i)}i=1...",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
Ns ; 8 Obtain their probability of being generated: pi = exp fG(h ′,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"i,r,t ′",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
i)∑Ns,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"j=1 exp fG(h ′ j ,r,t ′ j)
;
9 Sample one negative triple (h′s, r, t′s) from Neg(h, r, t) according to {pi}i=1...",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
Ns .,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Assume its probability to be ps;
10 GD ←− GD +∇θD",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"[fD(h, r, t)− fD(h′s, r, t′s) + γ]+; // accumulate gradients for D 11 r ←− −fD(h′s, r, t′s), rsum ←− rsum + r; // r is the reward 12 GG ←− GG",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
+ (r − b)∇θG log ps; // accumulate gradients for G 13 end 14 θG ←−,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
θG,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"+ ηGGG,",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"θD ←− θD − ηDGD; // update parameters 15 b← rsum/|Tbatch|; // update baseline 16 until convergence;
tion” process of discrete GANs, and we aim at improving discriminators based on marginal loss because they can benefit more from high-quality negative samples.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Note that a major difference between GAN and our work is that, the ultimate goal of our framework is to produce a good discriminator, whereas GANS are aimed at training a good generator.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In addition, the discriminator here is not a classifier as it would be in most GANs.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Intuitively, the discriminator should assign a relatively small distance to a high-quality negative sample.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In order to encourage the generator to generate useful negative samples, the objective of the generator is to minimize the distance given by discriminator for its generated triples.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"And just like the ordinary training process, the objective of the discriminator is to minimize the marginal loss between the positive triple and the generated negative triple.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In an adversarial training setting, the generator and the discriminator are alternatively trained towards their respective objectives.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Suppose that the generator produces a probability distribution on negative triples pG(h
′, r, t′|h, r, t) given a positive triple (h, r, t), and generates negative triples (h′, r, t′) by sampling from this distribution.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Let fD(h, r, t) be the score function of the discriminator.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The objective of the discriminator can be formulated as
minimizing the following marginal loss function:
LD = ∑
(h,r,t)∈T [fD(h, r, t)− fD(h′, r, t′) + γ]+
(h′, r, t′) ∼ pG(h′, r, t′|h, r, t) (3)
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The only difference between this loss function and Equation 1 is that it uses negative samples from the generator.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The objective of the generator can be formulated as maximizing the following expectation of negative distances:
RG = ∑
(h,r,t)∈T E[−fD(h′, r, t′)]
(h′, r, t′) ∼ pG(h′, r, t′|h, r, t) (4)
RG involves a discrete sampling step, so we cannot find its gradient with simple differentiation.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"We use a simple special case of Policy Gradient Theorem1 (Sutton et al., 2000) to obtain the gradient of RG with respect to parameters of the generator:
∇GRG = ∑
(h,r,t)∈T E(h′,r,t′)∼pG(h′,r,t′|h,r,t)
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"[−fD(h′, r, t′)∇G log pG(h′, r, t′|h, r, t)]
' ∑
(h,r,t)∈T
1
N
∑
(h′i,r,t ′",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"i)∼pG(h′,r,t′|h,r,t),i=1...",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"N
[−fD(h′, r, t′)∇G log pG(h′, r, t′|h, r, t)]",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"(5) 1A proof can be found in the supplementary material
where the second approximate equality means we approximate the expectation with sampling in practice.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Now we can calculate the gradient of RG and optimize it with gradient-based algorithms.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Policy Gradient Theorem arises from reinforcement learning (RL), so we would like to draw an analogy between our model and an RL model.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
The generator can be viewed as an agent which interacts with the environment by performing actions and improves itself by maximizing the reward returned from the environment in response of its actions.,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Correspondingly, the discriminator can be viewed as the environment.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Using RL terminologies, (h, r, t) is the state (which determines what actions the actor can take), pG(h′, r, t′|h, r, t) is the policy (how the actor choose actions), (h′, r, t′) is the action, and −fD(h′, r, t′) is the reward.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The method of optimizing RG described above is called REINFORCE (Williams, 1992) algorithm in RL.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Our model is a simple special case of RL, called one-step RL.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In a typical RL setting, each action performed by the agent will change its state, and the agent will perform a series of actions (called an epoch) until it reaches certain states or the number of actions reaches a certain limit.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"However, in the analogy above, actions does not affect the state, and after each action we restart with another unrelated state, so each epoch consists of only one action.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To reduce the variance of REINFORCE algorithm, it is common to subtract a baseline from the reward, which is an arbitrary number that only depends on the state, with-
out affecting the expectation of gradients.2 In our case, we replace −fD(h′, r, t′) with −fD(h′, r, t′)",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"− b(h, r, t) in the equation above to introduce the baseline.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To avoid introducing new parameters, we simply let b be a constant, the average reward of the whole training set: b =∑
(h,r,t)∈T E(h′,r,t′)∼pG(h′,r,t′|h,r,t)[−fD(h′, r, t′)].",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In practice, b is approximated by the mean of rewards of recently generated negative triples.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Let the generator’s score function to be fG(h, r, t), given a set of candidate negative triples Neg(h, r, t) ⊂ {(h′, r, t)|h′ ∈ E}∪{(h, r, t′)|t′ ∈ E}, the probability distribution pG is modeled as:
pG(h ′, r, t′|h, r, t)",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"= exp fG(h ′, r, t′)∑ exp fG(h∗, r, t∗) (h∗, r, t∗) ∈ Neg(h, r, t) (6) Ideally, Neg(h, r, t) should contain all possible negatives.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"However, knowledge graphs are usually highly incomplete, so the ”hardest” negative triples are very likely to be false negatives (true facts).",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To address this issue, we instead generate Neg(h, r, t) by uniformly sampling of Ns entities (a small number compared to the number of all possible negatives) from E to replace h or t. Because in real-world knowledge graphs, true negatives are usually far more than false negatives, such set would be unlikely to contain any false negative, and the negative selected by the generator would likely be a true negative.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Using a small Neg(h, r, t) can also significantly reduce computational complexity.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Besides, we adopt the “bern” sampling technique (Wang et al., 2014) which replaces the “1” side in “1-to-N” and “N-to-1” relations with higher probability to further reduce false negatives.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
Algorithm 1 summarizes the whole adversarial training process.,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Both the generator and the dis-
2A proof of such fact can also be found in the supplementary material
criminator require pre-training, which is the same as conventionally training a single KBE model with uniform negative sampling.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Formally speaking, one can pre-train the generator by minimizing the loss function defined in Equation (1), and pre-train the discriminator by minimizing the loss function defined in Equation (2).",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Line 14 in the algorithm assumes that we are using the vanilla gradient descent as the optimization method, but obviously one can substitute it with any gradientbased optimization algorithm.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To evaluate our proposed framework, we test its performance for the link prediction task with different generators and discriminators.",4 Experiments,[0],[0]
"For the generator, we choose two classical probability-based KGE model, DISTMULT and COMPLEX, and for the discriminator, we also choose two classical translation-based KGE model, TRANSE and TRANSD, resulting in four possible combinations of generator and discriminator in total.",4 Experiments,[0],[0]
See Table 1 for a brief summary of these models.,4 Experiments,[0],[0]
"We use three common knowledge base completion datasets for our experiment: FB15k-237, WN18 and WN18RR. FB15k-237 is a subset of FB15k introduced by (Toutanova and Chen, 2015), which removed redundant relations in FB15k and greatly reduced the number of relations.",4.1.1 Datasets,[0],[0]
"Likewise, WN18RR is a subset of WN18 introduced by (Dettmers et al., 2017) which removes reversing relations and dramatically increases the difficulty of reasoning.",4.1.1 Datasets,[0],[0]
"Both FB15k and WN18 are first introduced by (Bordes et al., 2013) and have been commonly used in knowledge graph researches.",4.1.1 Datasets,[0],[0]
Statistics of datasets we used are shown in Table 3.,4.1.1 Datasets,[0],[0]
"Following previous works like (Yang et al., 2015) and (Trouillon et al., 2016), for each run, we report two common metrics, mean reciprocal ranking (MRR) and hits at 10 (H@10).",4.1.2 Evaluation Protocols,[0],[0]
"We only report scores under the filtered setting (Bordes et al., 2013), which removes all triples appeared in training, validating, and testing sets from candidate triples before obtaining the rank of the ground truth triple.",4.1.2 Evaluation Protocols,[0],[0]
"3 In the pre-training stage, we train every model to convergence for 1000 epochs, and divide every epoch into 100 mini-batches.",4.1.3 Implementation Details,[0],[0]
"To avoid overfitting, we adopt early stopping by evaluating MRR on the validation set every 50 epochs.",4.1.3 Implementation Details,[0],[0]
"We tried γ = 0.5, 1, 2, 3, 4, 5 and L1, L2 distances for TRANSE and TRANSD, and λ = 0.01, 0.1, 1, 10 for DISTMULT and COMPLEX, and determined the best hyperparameters listed on table 2, based on their performances on the validation set after pre-training.",4.1.3 Implementation Details,[0],[0]
"Due to limited computation resources, we deliberately limit the dimensions of embeddings to k = 50, similar to the one used in earlier works, to save time.",4.1.3 Implementation Details,[0],[0]
"We also apply certain constraints or regularizations to these models, which are mostly the same as those described in their original publications, and also listed on table 2.
",4.1.3 Implementation Details,[0],[0]
"In the adversarial training stage, we keep all the hyperparamters determined in the pre-training stage unchanged.",4.1.3 Implementation Details,[0],[0]
"The number of candidate negative triples, Ns, is set to 20 in all cases, which is proven to be optimal among the candidate set of {5, 10, 20, 30, 50}.",4.1.3 Implementation Details,[0],[0]
"We train for 5000 epochs, with 100 mini-batches for each epoch.",4.1.3 Implementation Details,[0],[0]
"We also use early stopping in adversarial training by evaluating MRR on the validation set every 100 epochs.
",4.1.3 Implementation Details,[0],[0]
"We use the self-adaptive optimization method Adam (Kingma and Ba, 2015) for all trainings, and always use the recommended default setting α = 0.001, β1 = 0.9, β2 = 0.999, = 10 −8.",4.1.3 Implementation Details,[0],[0]
Results of our experiments as well as baselines are shown in Table 4.,4.2 Results,[0],[0]
"All settings of adversarial training bring a pronounced improvement to the model, which indicates that our method is consistently effective in various cases.",4.2 Results,[0],[0]
"TRANSE performs slightly worse than TRANSD on FB15k-237 and WN18, but better on WN18RR.",4.2 Results,[0],[0]
"Using DISTMULT or COMPLEX as the generator does not affect performance greatly.
",4.2 Results,[0],[0]
"TRANSE and TRANSD enhanced by KBGAN can significantly beat their corresponding baseline implementations, and outperform stronger baselines in some cases.",4.2 Results,[0],[0]
"As a prototypical and proofof-principle experiment, we have never expected state-of-the-art results.",4.2 Results,[0],[0]
"Being simple models pro-
3The KBGAN source code is available at https:// github.com/cai-lw/KBGAN
posed several years ago, TRANSE and TRANSD has their limitations in expressiveness that are unlikely to be fully compensated by better training technique.",4.2 Results,[0],[0]
"In future researches, people may try employing more advanced models into KBGAN, and we believe it has the potential to become stateof-the-art.
",4.2 Results,[0],[0]
"To illustrate our training progress, we plot performances of the discriminator on validation set over epochs, which are displayed in Figure 2.",4.2 Results,[0],[0]
"As all these graphs show, our performances are always in increasing trends, converging to its max-
imum as training proceeds, which indicates that KBGAN is a robust GAN that can converge to good results in various settings, although GANs are wellknown for difficulty in convergence.",4.2 Results,[0],[0]
"Fluctuations in these graphs may seem more prominent than other KGE models, but is considered normal for an adversially trained model.",4.2 Results,[0],[0]
Note that in some cases the curve still tends to rise after 5000 epochs.,4.2 Results,[0],[0]
"We do not have sufficient computation resource to train for more epochs, but we believe that they will also eventually converge.",4.2 Results,[0],[0]
"To demonstrate that our approach does generate better negative samples, we list some examples of them in Table 5, using the KBGAN (TRANSE + DISTMULT) model and the WN18 dataset.",4.3 Case study,[0],[0]
"All hyperparameters are the same as those described in Section 4.1.3.
",4.3 Case study,[0],[0]
"Compared to uniform random negatives which are almost always totally unrelated, the generator generates more semantically related negative samples, which is different from type relatedness we used as example in Section 3.2, but also helps training.",4.3 Case study,[0],[0]
"In the first example, two of the five terms are physically related to the process of distilling liquids.",4.3 Case study,[0],[0]
"In the second example, three of the five entities are geographical objects.",4.3 Case study,[0],[0]
"In the third example, two of the five entities express the concept of “gather”.
",4.3 Case study,[0],[0]
"Because we deliberately limited the strength of generated negatives by using a small Ns as described in Section 3.3, the semantic relation is pretty weak, and there are still many unrelated entities.",4.3 Case study,[0],[0]
"However, empirical results (when selecting the optimal Ns) shows that such situation is more beneficial for training the discriminator than generating even stronger negatives.",4.3 Case study,[0],[0]
We propose a novel adversarial learning method for improving a wide range of knowledge graph embedding models—We designed a generatordiscriminator framework with dual KGE components.,5 Conclusions,[0],[0]
"Unlike random uniform sampling, the generator model generates higher quality negative examples, which allow the discriminator model to learn better.",5 Conclusions,[0],[0]
"To enable backpropagation of error, we introduced a one-step REINFORCE method to seamlessly integrate the two modules.",5 Conclusions,[0],[0]
"Experimentally, we tested the proposed ideas with four commonly used KGE models on three datasets, and the results showed that the adversarial learning framework brought consistent improvements to various KGE models under different settings.",5 Conclusions,[0],[0]
"We introduce KBGAN, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models.",abstractText,[0],[0]
"Because knowledge graphs typically only contain positive facts, sampling useful negative training examples is a nontrivial task.",abstractText,[0],[0]
"Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training.",abstractText,[0],[0]
"Inspired by generative adversarial networks (GANs), we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in GANs.",abstractText,[0],[0]
"This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks.",abstractText,[0],[0]
"In experiments, we adversarially train two translation-based models, TRANSE and TRANSD, each with assistance from one of the two probability-based models, DISTMULT and COMPLEX.",abstractText,[0],[0]
"We evaluate the performances of KBGAN on the link prediction task, using three knowledge base completion datasets: FB15k-237, WN18 and WN18RR.",abstractText,[0],[0]
Experimental results show that adversarial training substantially improves the performances of target embedding models under various settings.,abstractText,[0],[0]
KBGAN: Adversarial Learning for Knowledge Graph Embeddings,title,[0],[0]
"Inference of parameters in a probabilistic model is an essential ingredient in model-based statistical approaches, both in the frequentist and Bayesian paradigms.",1. Introduction,[0],[0]
"Given a probabilistic model P (y|θ), which is a conditional distribution of observations y given a parameter θ, the aim is to make inference about the parameter θ∗ that generated an observed data y∗.",1. Introduction,[0],[0]
"When the model P (y|θ) admits a conditional density `(y|θ), such an inference can be made on the basis of evaluations of `(y∗|θ); this is the likelihood of y∗ as a function of θ.",1. Introduction,[0],[0]
"However, in modern scientific and engineering problems in which the model P (y|θ) is required to be sophisticated and complex, the likelihood function `(y∗|θ) might no longer be available.",1. Introduction,[0],[0]
"This may be because the density form of P (y|θ) is elusive, or the evaluation of the likelihood `(y∗|θ) is computationally very expensive.",1. Introduction,[0],[0]
"Such situations, in which `(y|θ) (or P (y|θ)) are referred to as intractable likelihood, make the inference problem quite challenging and are commonly found in the literature on
1NEC Corporation 2National Institute of Advanced Industrial Science and Technology 3Max Planck Institute for Intelligent Systems 4The Institute of Statistical Mathematics.",1. Introduction,[0],[0]
"Correspondence to: Takafumi Kajihara <t-kajihara@ct.jp.nec.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"population genetics (Pritchard et al., 1999) and dynamical systems (Toni et al., 2009), to name just two.
",1. Introduction,[0],[0]
"Approximate Bayesian Computation (ABC) is a class of computational methods for Bayesian inference with intractable likelihood (Tavaré et al., 1997; Pritchard et al., 1999; Beaumont et al., 2002) that is applicable as long as sampling from the model P (y|θ) is possible.",1. Introduction,[0],[0]
"Given a prior π(θ) on the parameter space, the basic ABC constructs a Monte Carlo approximation to the posterior Py∗(θ) ∝",1. Introduction,[0],[0]
"P (y∗|θ)π(θ) in the following way: i) sample pairs (yi, θi) of pseudo data yi and parameter θi from the joint distribution P (y|θ)π(θ), where i = 1, . . .",1. Introduction,[0],[0]
", n for some n ∈ N, ii) maintain only those parameters θi associated with yi that are “close enough” to the observed data y∗, and iii) regard them as samples from the posterior Py∗(θ).",1. Introduction,[0],[0]
"ABC has been extensively studied in statistics and machine learning; see, e.g., Del Moral et al. (2012); Fukumizu et al. (2013); Meeds and Welling (2014); Park et al. (2016); Mitrovic et al. (2016).
",1. Introduction,[0],[0]
"In this paper, we rather take the frequentist perspective, and deal with the problem of maximum likelihood estimation (MLE) with intractable likelihood.",1. Introduction,[0],[0]
"That is, we consider situations in which one believes that there is a “true” parameter θ∗ that generated the data y∗ and wishes to obtain a point estimate for it.",1. Introduction,[0],[0]
"This problem is also motivated by the following situations encountered in practice: 1) Consider a situation in which the model is computationally expensive (e.g., a state-space model) and one wants to perform prediction based on it.",1. Introduction,[0],[0]
"In this case fully Bayesian prediction would require simulation from each of sampled parameters, which might be quite costly.",1. Introduction,[0],[0]
"If one has a point estimate of the true parameter θ∗, then the computational cost can be drastically reduced.",1. Introduction,[0],[0]
2) Consider a situation in which one only has limited knowledge w.r.t. model parameters.,1. Introduction,[0],[0]
"In this case, it is generally difficult to specify an appropriate prior distribution over the parameter space, and thus the resulting posterior may not be reliable.1 Methods for point estimation with intractable likelihood have been reported in the literature, including the method of simulated-moments (McFadden, 1989), indirect inference (Gourieroux et al.,
1For point estimation, one may think of using the maximum a posterior (MAP) estimate, but it may again be unreliable (as for the posterior distribution itself), if the prior distribution cannot be specified appropriately.
1993), ABC-based MAP estimation (Rubio et al., 2013), noisy ABC-MLE (Dean et al., 2014; Yıldırım et al., 2015), an approach based on Bayesian optimization (Gutmann and Corander, 2016), and data-cloning ABC (Picchini and Anderson, 2017).",1. Introduction,[0],[0]
"We will discuss these existing approaches in Sec. 4.
",1. Introduction,[0],[0]
"Our contribution is in proposing a novel approach to point estimation with intractable likelihood on the basis of kernel mean embedding of distributions (Muandet et al., 2017), a framework for statistical inference using reproducing kernel Hilbert spaces.",1. Introduction,[0],[0]
"Specifically, our approach extends kernel ABC (Fukumizu et al., 2013; Nakagome et al., 2013), a method for ABC using kernel embedding of conditional distributions (Song et al., 2009; 2013), to point estimation with intractable likelihood.",1. Introduction,[0],[0]
"The novelty lies in combining kernel ABC with kernel herding (Chen et al., 2010), a deterministic sampling method similar to quasi-Monte Carlo (Dick et al., 2013), and in applying these two methods iteratively to the same observed data in a recursive way.",1. Introduction,[0],[0]
We term this approach kernel recursive ABC.,1. Introduction,[0],[0]
"A theoretical explanation will be provided for this approach, discussing how such recursion yields a point estimate for the true parameter.",1. Introduction,[0],[0]
"We also discuss that the combination of kernel ABC and kernel herding leads to robustness against misspecification of a prior for the true parameter; this is an advantage over existing methods, and will be demonstrated experimentally.
",1. Introduction,[0],[0]
This paper is organized as follows.,1. Introduction,[0],[0]
We briefly review kernel ABC and kernel herding in Sec. 2 and propose kernel recursive ABC in Sec. 3.,1. Introduction,[0],[0]
We report experimental results of comparisons with existing methods in Sec. 4.,1. Introduction,[0],[0]
"The experiments include parameter estimation for a real-world pedestrian flow simulator (Yamashita et al., 2010), which may be of independent interest as application.",1. Introduction,[0],[0]
"Kernel ABC is an algorithm that executes ABC in a reproducing kernel Hilbert space (RKHS) and produces a reliable solution even in moderately large dimensional problems (Fukumizu et al., 2013; Nakagome et al., 2013).",2.1. Kernel ABC,[0],[0]
"It is based on the framework of kernel mean embeddings, in which all probability measures are represented as elements in an RKHS (see Muandet et al. (2017) for a recent survey of this field).",2.1. Kernel ABC,[0],[0]
"Let Θ be a measurable space, k : Θ × Θ → R be a measurable positive definite kernel, and H be its RKHS.",2.1. Kernel ABC,[0],[0]
"In this framework, any probability measure P on Θ will be represented as a Bochner integral
µP",2.1. Kernel ABC,[0],[0]
":= ∫ Θ k(·, θ)dP (θ) ∈ H, (1)
which is called the kernel mean of P .",2.1. Kernel ABC,[0],[0]
"If the mapping P → µP is injective, in which case µP preserves all the
information in P , the kernel k is referred to as being characteristic (Fukumizu et al., 2008).",2.1. Kernel ABC,[0],[0]
"Characteristic kernels on Θ = Rd, for example, include Gaussian and Matérn kernels (Sriperumbudur et al., 2010).
",2.1. Kernel ABC,[0],[0]
Let Y be another measurable space and assume that an observed data y∗ ∈ Y is provided.,2.1. Kernel ABC,[0],[0]
(y∗ is often a set of sample points.),2.1. Kernel ABC,[0],[0]
"Given a conditional probability P (y|θ) and a prior π(θ), we wish to obtain the posterior distribution Py∗(θ) ∝",2.1. Kernel ABC,[0],[0]
P,2.1. Kernel ABC,[0],[0]
"(y∗|θ)π(θ).2 As in a standard ABC, kernel ABC achieves this by first generating pairs of pseudo data and parameter {(yi, θi)}ni=1 from the joint distribution P (y|θ)π(θ).",2.1. Kernel ABC,[0],[0]
"It then estimates the kernel mean of the posterior Py∗ , which we denote by
µPy∗ := ∫",2.1. Kernel ABC,[0],[0]
"Θ k(·, θ)dPy∗(θ) ∈ H.
",2.1. Kernel ABC,[0],[0]
"Given a measurable positive definite kernel kY on Y , the estimator is given by
µ̂Py∗ = n∑ i=1 wik(·, θi) ∈ H, (2)
",2.1. Kernel ABC,[0],[0]
"w := (w1, . . .",2.1. Kernel ABC,[0],[0]
", wn) T := (G+ nδI)−1k(y∗), (3)
where k(y∗)",2.1. Kernel ABC,[0],[0]
":= (kY(y1, y∗), . . .",2.1. Kernel ABC,[0],[0]
", kY(yn, y∗))T ∈",2.1. Kernel ABC,[0],[0]
"Rn, G := (kY(yi, yj)) n",2.1. Kernel ABC,[0],[0]
"i,j=1 ∈ Rn×n, δ > 0 is a regularization constant, and I ∈ Rn×n is an identity matrix.",2.1. Kernel ABC,[0],[0]
"The estimator (2) is essentially an (RKHS-valued) kernel ridge regression (Grünewälder et al., 2012):",2.1. Kernel ABC,[0],[0]
"Given training data {(yi, k(·, θi))}ni=1, the weights (3) provide an estimator for the mapping y∗ ⇒",2.1. Kernel ABC,[0],[0]
"k(·, θ∗).",2.1. Kernel ABC,[0],[0]
"For consistency and convergence results, which require δ → 0 as n→∞, we re refer to Fukumizu et al. (2013) and Muandet et al. (2017).",2.1. Kernel ABC,[0],[0]
"Kernel herding is a deterministic sampling technique based on the kernel mean representation of a distribution (Chen et al., 2010) and can be seen as a greedy approach to quasiMonte Carlo (Dick et al., 2013).",2.2. Kernel herding,[0],[0]
"Consider sampling from P using the kernel mean µP (1), and assume that one is able to evaluate function values of µP .",2.2. Kernel herding,[0],[0]
"Kernel herding greedily obtains sample points θ1, θ2, . . .",2.2. Kernel herding,[0],[0]
", θn by iterating the following steps: Defining h0 := µP ,
θt+1 = argmax θ∈Θ ht(θ), (4) ht+1 = ht + µP",2.2. Kernel herding,[0],[0]
"− k(·, θt+1) ∈ H, (5)
where t = 0, . . .",2.2. Kernel herding,[0],[0]
", n− 1.",2.2. Kernel herding,[0],[0]
"Chen et al. (2010) has shown that, if there exists a constant C > 0",2.2. Kernel herding,[0],[0]
"such that k(θ, θ) = C for all θ ∈ Θ, this procedure will be identical to the greedy
2There is abuse of notation here, as P (y|θ) does not denote a conditional density but a conditional distribution.
",2.2. Kernel herding,[0],[0]
Algorithm 1 Kernel Recursive ABC Input:,2.2. Kernel herding,[0],[0]
"A prior distribution π, an observed data y∗, a data generator P (y|θ), the number Niter of iterations, the number n of simulated pairs, a kernel k on Θ, a kernel kY on Y , and a regularization constant δ > 0",2.2. Kernel herding,[0],[0]
"Output: A point estimate θ́. for N = 1, ..., Niter do
if N = 1 then for i = 1, ..., n do
Sample θ1,i ∼ π(θ) i.i.d. end for
end if for i = 1, ..., n do
Generate yN,i ∼ P (·|θN,i) end for Compute G := (kY(yN,i, yN,i))ni,j=1 ∈ Rn×n and k(y) := (kY(yN,i, y
∗))ni=1 ∈",2.2. Kernel herding,[0],[0]
Rn.,2.2. Kernel herding,[0],[0]
"Calculate w = (w1, . . .",2.2. Kernel herding,[0],[0]
", wn)T ∈",2.2. Kernel herding,[0],[0]
Rn by Eq.(3).,2.2. Kernel herding,[0],[0]
"Construct a kernel mean estimate of the powered posterior µ̂PN := ∑n i=1 wik(·, θN,i)",2.2. Kernel herding,[0],[0]
"Sample {θN+1,t}nt=1 by performing kernel herding Eqs.(4) (5) with µP := µ̂PN .
",2.2. Kernel herding,[0],[0]
"end for Obtain a point estimate θ́ := θNiter+1,1
minimization of the maximum mean discrepancy (MMD) (Gretton et al., 2007; 2012):
n",2.2. Kernel herding,[0],[0]
:= ∥∥∥∥∥µP,2.2. Kernel herding,[0],[0]
"− 1n n∑ t=1 k(·, θt) ∥∥∥∥∥",2.2. Kernel herding,[0],[0]
"H , (6)
where ‖ · ‖H denotes the norm of H. That is, the points θ1, . . .",2.2. Kernel herding,[0],[0]
", θn are obtained so as to (greedily) minimize the distance εn between µP and the empirical kernel mean 1 n ∑n t=1",2.2. Kernel herding,[0],[0]
k,2.2. Kernel herding,[0],[0]
"(·, θt).",2.2. Kernel herding,[0],[0]
"The generated points θ1, . .",2.2. Kernel herding,[0],[0]
.,2.2. Kernel herding,[0],[0]
", θn are also called super-samples because they are more informative than those from random sampling; this is in the sense that error decreases at the rate n = O(n−1) if the RKHS is finite-dimensional (Bach et al., 2012), which is faster than the rate n = O(n−1/2) of random sampling (Smola et al., 2007).",2.2. Kernel herding,[0],[0]
"Convergence guarantees are also provided even when the optimization problem in (4) is solved approximately (Lacoste-Julien et al., 2015) and when the kernel mean µP is replaced by an empirical estimate µ̂P of the form (2) (Kanagawa et al., 2016b).",2.2. Kernel herding,[0],[0]
Note that the decay n → 0 of the error (6) as n→∞ implies the convergence of expectation 1 n,2.2. Kernel herding,[0],[0]
"∑n t=1 f(θt) → ∫ f(x)dP (x) for all functions f in the RKHSH and for functions f that can be approximated well by the RKHS functions (Kanagawa et al., 2016a).",2.2. Kernel herding,[0],[0]
"Our idea is to recursively apply Bayes’ rule to the same
observed data y∗ by using the posterior obtained in one iteration as a prior for the next iteration.",3. Proposed method,[0],[0]
"For this, let `(θ) := `(y∗|θ) be a likelihood function and π(θ) be a prior density, where θ ∈ Θ, with Θ being a measurable space.",3. Proposed method,[0],[0]
Consider the population setting in which no estimation procedure is involved.,3. Proposed method,[0],[0]
"After theN -th recursion, the posterior distribution becomes
pN (θ) :",3. Proposed method,[0],[0]
"= C −1 N π(θ)(`(θ)) N , (7)
where CN := ∫
Θ π(θ) (`(θ))
",3. Proposed method,[0],[0]
"N dθ is a normalization con-
stant.",3. Proposed method,[0],[0]
We refer here to this as a powered posterior.,3. Proposed method,[0],[0]
"If ` has a unique global maximum at θ∞ ∈ Θ and the support of π contains θ∞, one can show that pN converges weakly to the Dirac distribution δθ∞ at θ∞ under certain conditions (Lele et al., 2010).",3. Proposed method,[0],[0]
"In other words, the effect of the prior diminishes as the recursion proceeds, and the powered posterior degenerates at the maximum likelihood point, providing a method for MLE.",3. Proposed method,[0],[0]
"A similar idea has been discussed by Doucet et al. (2002); Lele et al. (2010) in the context of data augmentation and data cloning, in which one replicates the observed data y∗ multiple times and applies Bayes’ rule once; our approach is different, as we employ recursive applications of Bayes’ rule multiple times (this turns out to be beneficial in our approach, as is shown below).
",3. Proposed method,[0],[0]
"Based on the above idea, we propose to recursively applying kernel ABC (Sec. 2.1) and kernel herding (Sec. 2.2).",3. Proposed method,[0],[0]
"Specifically, the proposed method (Algorithm 1) iterates the following procedures: (i) At the N -th iteration, the kernel mean µPN := ∫ k(·, θ)pN (θ)dθ of the powered posterior (7) is estimated using simulated pairs {(θN,i, yN,i)}ni=1 via kernel ABC; (ii) from the estimate µ̂PN of µPN given in (i), new parameters {θN+1,i}ni=1 are generated via kernel herding, and new pseudo-data {yN+1,i}ni=1 are generated from the simulator P (yN+1,i|θN+1,i) in the N + 1-th iteration.",3. Proposed method,[0],[0]
"After iterating these procedures Niter times, point estimate θ́ for the true parameter is given as the first point θNiter+1,1 from kernel herding at the last iteration.
",3. Proposed method,[0],[0]
Auto-correction mechanism.,3. Proposed method,[0],[0]
"An interesting feature of the proposed approach is that, as experimentally indicated in Sec. 4.2, it is equipped with an auto-correction mechanism: If the parameters θN,1, . . .",3. Proposed method,[0],[0]
", θN,n",3. Proposed method,[0],[0]
at theN -th,3. Proposed method,[0],[0]
iteration,3. Proposed method,[0],[0]
"are far apart from the true parameter θ∗, then Algorithm 1 searches for the parameters θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,n at the next iteration, so as to explore the parameter space Θ.",3. Proposed method,[0],[0]
"For instance, if the prior π(θ) is misspecified, meaning that the true parameter θ∗ is not contained in the support of π(θ), then the initial parameters θ1,1, . . .",3. Proposed method,[0],[0]
", θ1,n from π(θ) are likely to be apart from the true parameter θ∗.",3. Proposed method,[0],[0]
"The auto-correction mechanism makes the proposed method robust to such misspecification and makes it suitable for use in situations in which one lacks appropriate prior knowledge about the true parameter.
",3. Proposed method,[0],[0]
"To explain how this works, let us explicitly write down the procedure (4) (5) of kernel herding as used in Algorithm 1.
",3. Proposed method,[0],[0]
"Given that t (< n) points θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,t have already been generated, the next point θN+1,t+1 is obtained as
θN+1,t+1 := (8)
argmax θ∈Θ n∑ i=1",3. Proposed method,[0],[0]
"wik(θ, θN,i)− 1 t+ 1",3. Proposed method,[0],[0]
t∑ i=1,3. Proposed method,[0],[0]
"k(θ, θN+1,i),
where the weights w1, . . .",3. Proposed method,[0],[0]
", wn are given as (3).",3. Proposed method,[0],[0]
"Assume that all the simulated parameters θN,1, . . .",3. Proposed method,[0],[0]
", θN,n at the N -th iteration are far apart from the true parameter θ∗:",3. Proposed method,[0],[0]
"If N = 1, these are the parameters sampled from the prior π(θ).",3. Proposed method,[0],[0]
"Then it is likely the resulting simulated data yN,1, . . .",3. Proposed method,[0],[0]
", yN,n are dissimilar to the observed data y∗.",3. Proposed method,[0],[0]
"In this case, each component of the vector k(y) := (kY(yN,i, y∗))ni=1 ∈",3. Proposed method,[0],[0]
"Rn becomes nearly 0, since kY(yN,i, y∗) quantifies the similarity between y∗ and yN,i. As a result, each of the weights w1, . .",3. Proposed method,[0],[0]
.,3. Proposed method,[0],[0]
", wn given by kernel ABC (3) also become nearly 0, and thus the first term on the right side in (8) will be ignorable.",3. Proposed method,[0],[0]
"The point θN+1,t+1 is then obtained so as to roughly maximize the second term − 1t+1 ∑t i=1",3. Proposed method,[0],[0]
"k(θN+1,t+1, θN+1,i), or, equivalently, so as
to minimize ∑t i=1",3. Proposed method,[0],[0]
"k(θN+1,t+1, θN+1,i).",3. Proposed method,[0],[0]
"Since the kernel k(θN+1,t+1, θN+1,i) measures the similarity between θN+1,t+1 and θN+1,i, the new point θN+1,t+1 is located apart from the points θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,t generated so far.",3. Proposed method,[0],[0]
"In this way, the parameters θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,n at theN+1th iteration are made to explore the parameter space Θ if parameters θN,1, . . .",3. Proposed method,[0],[0]
", θN,n at the N -th iteration are far apart from the true parameter θ∗.",3. Proposed method,[0],[0]
We provide here a theoretical basis for the proposed recursive approach.,3.1. Theoretical analysis,[0],[0]
"Since the consistency of kernel ABC and kernel herding have already been established in the literature (Fukumizu et al., 2013; Bach et al., 2012), we focus on convergence analysis in the population setting, that is, convergence analysis for the kernel mean of the powered posterior (7) and for the resulting point estimate.",3.1. Theoretical analysis,[0],[0]
We nevertheless note that convergence analysis of the overall procedure of Algorithm 1 remains an important topic for future research.,3.1. Theoretical analysis,[0],[0]
"All the proofs can be found in the Supplementary Materials.
",3.1. Theoretical analysis,[0],[0]
"Below, we let Θ be a Borel measurable set in Rd.",3.1. Theoretical analysis,[0],[0]
"Denote by PN the probability measure induced by the powered posterior density pN (7), and let µPN := ∫ k(·, θ)dPN (θ) ∈ H be its kernel mean, where k is a kernel on Θ and H is its RKHS.",3.1. Theoretical analysis,[0],[0]
We require the following assumption for the likelihood function ` and the prior π for theoretical analysis.,3.1. Theoretical analysis,[0],[0]
Assumption 1.,3.1. Theoretical analysis,[0],[0]
"(i) ` has a unique global maximum at θ∞ ∈ Θ, and π(θ∞) > 0; (ii) π is continuous at θ∞, ` has continuous second derivatives in the neighborhood of θ∞, and the Hessian of ` at θ∞ is strictly negative-definite.
",3.1. Theoretical analysis,[0],[0]
"Our first result below shows that, under Assumption 1, the
powered posterior PN (7) converges to the Dirac distribution δθ∞ in the RKHSH as N →∞; this provides a theoretical basis for recursively applying the kernel ABC.
",3.1. Theoretical analysis,[0],[0]
Proposition 1.,3.1. Theoretical analysis,[0],[0]
Let Θ ⊂ Rd be a Borel measurable set and k : Θ × Θ → R be a continuous bounded kernel.,3.1. Theoretical analysis,[0],[0]
"Under Assumption 1, we have limN→∞ ‖µPN",3.1. Theoretical analysis,[0],[0]
"− k(·, θ∞)‖H = 0.
Proposition 2 below provides a justification for the use of the first point of kernel herding (here this is θN",3.1. Theoretical analysis,[0],[0]
:= argminθ̃∈Θ ‖µPN,3.1. Theoretical analysis,[0],[0]
"− k(·, θ̃)‖H; see Sec. 2.2) as a point estimate of θ∞. To this end, we introduce the following assumption on the kernel, which is satisfied by, for example, Gaussian and Matérn kernels.
",3.1. Theoretical analysis,[0],[0]
Assumption 2.,3.1. Theoretical analysis,[0],[0]
(i),3.1. Theoretical analysis,[0],[0]
"There exists a constant C > 0 such that k(θ, θ) = C for all θ ∈ Θ. (ii)",3.1. Theoretical analysis,[0],[0]
"It holds that k(θ, θ′) < C for all θ, θ′ ∈ Θ with θ 6= θ′. Proposition 2.",3.1. Theoretical analysis,[0],[0]
"Let Θ ⊂ Rd be a compact set, and k : Θ × Θ → R be a continuous, bounded kernel.",3.1. Theoretical analysis,[0],[0]
Let θN,3.1. Theoretical analysis,[0],[0]
:,3.1. Theoretical analysis,[0],[0]
"= argminθ̃∈Θ
∥∥∥µPN − k(·, θ̃)∥∥∥H. If Assumptions 1 and 2 hold, then we have θN → θ∞ as N →∞.
We make a few remarks regarding Assumption 1.",3.1. Theoretical analysis,[0],[0]
"The assumption that ` has a unique global maximum is not satisfied if the model is singular, an example being mixture models: In this case there are multiple global maximums.",3.1. Theoretical analysis,[0],[0]
"However, our experiment in Sec. 4.5 shows that even for mixture models, the proposed method works reasonably well.",3.1. Theoretical analysis,[0],[0]
"This suggests that, in an empirical setting, a point estimate may converge to one of the global maximums.",3.1. Theoretical analysis,[0],[0]
"The assumption π(θ∞) > 0 will also not be satisfied if the support π does not contain θ∞, but the proposed method performs well even in this case (as shown in 4.2), possibly thanks to the auto-correction mechanism explained above.",3.1. Theoretical analysis,[0],[0]
We reserve further analysis of these properties for future work.,3.1. Theoretical analysis,[0],[0]
We have conducted a variety of experiments comparing the proposed method with existing approaches.,4. Experiments,[0],[0]
"We begin with a quick review of these approaches (Sec. 4.1), and report experimental results on point estimation with a misspecified prior (Sec. 4.2), population dynamics of the blowfly (Sec. 4.3), alpha stable distributions (Sec. 4.4), Gaussian mixture models with redundant components (Sec. 4.5), and a real-world pedestrian simulator (Sec. 4.6).",4. Experiments,[0],[0]
"K2-ABC (Park et al., 2016) is an ABC method that represents the empirical distributions of simulated and test observations as kernel means in an RKHS.",4.1. Existing approaches and experimental settings,[0],[0]
"For each of simulated parameters, the associated weight is calculated by using the RKHS distance between the kernel means (i.e., MMD), and the resulting weighted sample is treated as a posterior
distribution.",4.1. Existing approaches and experimental settings,[0],[0]
"Adaptive SMC-ABC (Del Moral et al., 2012) is a rejection-based approach based on sequential Monte Carlo, which sequentially updates the tolerance level and the associated proposal distribution in an adaptive manner.",4.1. Existing approaches and experimental settings,[0],[0]
This method is a state-of-the-art ABC approach.,4.1. Existing approaches and experimental settings,[0],[0]
"The approach by Gutmann and Corander (2016), which we refer to as Bayesian Optimization for simplicity, is a method for MLE with intractable likelihood based on Bayesian optimization (Brochu et al., 2010).",4.1. Existing approaches and experimental settings,[0],[0]
This method optimizes the parameters in a intractable model so as to minimize the discrepancy between the simulated and test observations.,4.1. Existing approaches and experimental settings,[0],[0]
"Note that comparison with this method in terms of computation time may not make sense (although we report them for purposes of completeness), as we used publicly available code3 for implementation.",4.1. Existing approaches and experimental settings,[0],[0]
"The method of simulated moments (MSM) (McFadden, 1989) optimizes the parameter in the model so that the resulting moments of simulated data match those of observe data.",4.1. Existing approaches and experimental settings,[0],[0]
"MSM may be seen a special case of indirect inference (Gourieroux et al., 1993), an approach studied in econometrics.4 Data-cloning ABC (ABC-DC) (Picchini and Anderson, 2017) is an approach combining ABC-MCMC (Marjoram et al., 2003) and Data Cloning (Lele et al., 2010), replicating observed data multiple times to achieve MLE with intractable likelihood.
",4.1. Existing approaches and experimental settings,[0],[0]
Experimental settings.,4.1. Existing approaches and experimental settings,[0],[0]
"Unless otherwise specified, the following settings were applied in the experiments.",4.1. Existing approaches and experimental settings,[0],[0]
"For all the methods that employed kernels, we used Gaussian kernels.",4.1. Existing approaches and experimental settings,[0],[0]
"The discrepancy between the simulated and observed data was measured by the energy distance (Székely and Rizzo, 2013), which is a standard metric for distributions in statistics and can be computed only from pairwise Euclidean distances between data points.",4.1. Existing approaches and experimental settings,[0],[0]
"Since the usual quadratic time estimator was too costly, we used a linear time estimator for computing the energy distance (see the Supplementary Materials for details).
",4.1. Existing approaches and experimental settings,[0],[0]
"For each method, unless otherwise specified, we determined the hyper-parameters on the basis of the cross-validationlike approach described in Park et al. (2016, Sec. 4).",4.1. Existing approaches and experimental settings,[0],[0]
"That is, to evaluate one configuration of hyper-parameters, we first used 75% of the observed data for point estimation and then computed the discrepancy between the rest of the observed data and the ones simulated from point estimates; after applying this procedure to all candidate configurations, the one with the lowest discrepancy was finally selected.",4.1. Existing approaches and experimental settings,[0],[0]
"The bandwidth of a Gaussian kernel was selected from candidate values, each of which is the median (of pairwise distances) multiplied by logarithmically equally spaced values between 2−4 and 24 (Takeuchi et al., 2006, Sec. 5.1.1).",4.1. Existing approaches and experimental settings,[0],[0]
"Regularization constants for the proposed method and kernel ABC, as well as the soft threshold for K2-ABC, were selected
3https://sheffieldml.github.io/GPyOpt/ 4MSM is a special case of indirect inference because the mo-
ments can be regarded as the parameters of an auxiliary model.
from logarithmically spaced values between 10−4 and 1.",4.1. Existing approaches and experimental settings,[0],[0]
"To compute MMD for K2-ABC, a linear time estimator (Gretton et al., 2012, Sec. 6) was used to reduce computational time, as the usual quadratic time estimator was too costly.",4.1. Existing approaches and experimental settings,[0],[0]
"For Adaptive SMC-ABC, the initial tolerance level was set as the median of pairwise distances between the observed and simulated data.",4.1. Existing approaches and experimental settings,[0],[0]
"For Bayesian Optimization, we used Expected Improvement as an acquisition function, and all the hyper-parameters were marginalized out following the approach of Snoek et al. (2012, Sec. 3.2).",4.1. Existing approaches and experimental settings,[0],[0]
"For MSM, the number of moments were selected from a range up to 30 by the cross-validation like approach.",4.1. Existing approaches and experimental settings,[0],[0]
"For ABC-DC, we employed, in particular, dynamic ABC-DC, which automatically adjusts its associated parameters.",4.1. Existing approaches and experimental settings,[0],[0]
"To obtain point estimates with kernel ABC and K2-ABC, we computed the means of the resulting posterior distributions.",4.1. Existing approaches and experimental settings,[0],[0]
"For Adaptive SMC-ABC, point estimates were obtained as posterior means as well as MAP estimates by applying the mean shift algorithm to posterior weighted samples (Fukunaga and Hostetler, 1975), the latter essentially being an approach suggested by Rubio et al. (2013).
",4.1. Existing approaches and experimental settings,[0],[0]
"The following abbreviations may be used for the sake of simplicity; kernel recursive ABC is referred to as KR-ABC, kernel ABC as K-ABC, adaptive SMC-ABC as SMC-ABC, Bayesian Optimization as BO, and Dynamic ABC-DC as ABC-DC.",4.1. Existing approaches and experimental settings,[0],[0]
"For our method, we also report results based on a half number of iterations, which we call KR-ABC (less).",4.1. Existing approaches and experimental settings,[0],[0]
"As a proof of concept regarding the auto-correction mechanism of the proposed method described in Sec.3, we have performed an experiment for when the prior distribution is severely misspecified (see the Supplementary Materials for an illustration).",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"The task is to estimate the mean vector of a 20-dimensional Gaussian distribution Normal(µ,Σ), where the true mean vector is µ := (10, 50, 90, 130, 180, 280, 390, 430, 520, 630, 1010, 1050, 1090, 1130, 1180, 1280, 1390, 1430, 1520, 1630)T ∈ R20.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
The covariance matrix Σ ∈ R20×20 is assumed to be known and is a diagonal matrix with all diagonal elements being 40.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
Test data y∗ consisted of 100 i.i.d.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
observations from this Gaussian distribution.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"As a prior for the mean vector µ, we used the uniform distribution on [9× 106, 107]20, which is extremely misspecified.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For Bayesian optimization, the space to be explored was set as [0, 107]20.
",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"In this experiment, each pseudo data was made from 100 observations simulated with one parameter configuration.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
K2-ABC and K-ABC used 3000 pairs of a parameter and pseudo-data.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For the proposed method and SMC-ABC, we generated 100 pairs of a parameter and pseudo-data for the initial iteration, and then the iterations were repeated 30
times, resulting in a total of 3000 simulations.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For the proposed method, the bandwidth of the kernel kY on observed data was recomputed for each iteration, using the median heuristic.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For SMC-ABC, the parameter α ∈ (0, 1), which controls the trade-off between the speed of convergence and the accuracy of posterior approximation, was set to be 0.3, as we found this value to be the best in terms of the trade-off.
",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For each method, we ran 30 independent trials, and the results in averages and standard deviations are shown in Table 1, where the parameter error is the mean (over 20 dimensions) of the absolute difference between the estimated and the true parameter values divided by the true value, and the data error is the energy distance between the true data and pseudo data simulated with the estimated parameter.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"Surprisingly, the proposed method successfully approached the true parameter even when the prior was severely misspecified.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"As discussed in Sec 3 and demonstrated in the Supplementary Materials, this would appear to be because of the use of kernel herding, which automatically widens the space to explore when simulated data is far apart from test data.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"As expected, other methods were unable to approach the true parameter.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"Following Park et al. (2016), we performed an experiment on parameter estimation with a dynamical system of blowfly populations (Wood, 2010), which is defined as
Nt+1 = PNt−τ exp (−Nt−τ/N0) et + Nt exp(−δ t),
where t = 1, . . .",4.3. Ecological dynamic systems: blowfly,[0],[0]
", T are time indices, Nt is the population at time t, et ∼ Gam( 1σ2pσ 2 p) and t ∼ Gam( 1σ2d , σ 2 d) are independent Gamma-distributed noise, and θ := (P ∈ N, N0 ∈ N,",4.3. Ecological dynamic systems: blowfly,[0],[0]
"σd ∈ R+, σp ∈",4.3. Ecological dynamic systems: blowfly,[0],[0]
"R+, τ",4.3. Ecological dynamic systems: blowfly,[0],[0]
"∈ N, δ ∈",4.3. Ecological dynamic systems: blowfly,[0],[0]
R+) are the parameters of the system.,4.3. Ecological dynamic systems: blowfly,[0],[0]
"The task is to estimate θ from observed values of N1, . . .",4.3. Ecological dynamic systems: blowfly,[0],[0]
", NT .",4.3. Ecological dynamic systems: blowfly,[0],[0]
"We set the true parameters as θ = (29, 260, 0.6, 0.3, 7, 0.2), and the time-length T for both the observed and pseudo data as T = 1000.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"Following Park et al. (2016, Sec. 4), for each parameter we defined a Gaussian prior on its logarithm (see the Supplementary Materials for a definition).",4.3. Ecological dynamic systems: blowfly,[0],[0]
"In this experiment, for all methods we converted the observed and pseudo-data into histograms
with 1000 bins (i.e., we treated each data as a 1000 dim.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"vector), as this produced better results.",4.3. Ecological dynamic systems: blowfly,[0],[0]
K2-ABC and K-ABC used 1300 pairs of a parameter and a pseudo-data item.,4.3. Ecological dynamic systems: blowfly,[0],[0]
"For the proposed method and SMC-ABC, we generated 100 pairs of a parameter and pseudo-data for the initial iteration, and the iterations were then repeated 13 times, resulting in total 1300 simulations.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"For SMC-ABC, we set the parameter α ∈ (0, 1) to be 0.3, as in Sec. 4.2.
",4.3. Ecological dynamic systems: blowfly,[0],[0]
"For each method we performed 30 independent trials, and the results are summarized in Table 2.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"The proposed method performed the best, even when the number of simulations was halved (i.e., KR-ABC (less)).",4.3. Ecological dynamic systems: blowfly,[0],[0]
"In addition to the competitive methods described earlier, we performed a comparison with the method called noisy ABC-MLE (Yıldırım et al., 2015).",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"This method assumes that sampling from the intractable model can be realized by deterministic mapping applied to a simple random variable, and that the gradient of the deterministic mapping is available.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"This method can, then, only be applied to a limited class of generative models, though for such models it can perform well.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"Although the main scope of this paper is on simulation models in which such gradient information is unavailable, we performed this experiment in order to see how the proposed method compared with this method without relying on the gradient information.
",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"We also considered parameter estimation with multivariate elliptically contoured alpha stable distributions (Nolan, 2013), which subsume heavy-tailed and skewed distributions and are popular for modeling financial data.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"This family of distributions in general does not admit closedform expressions for density functions, which means they are “intractable” in the sense that the standard procedure for parameter estimation cannot be employed.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"However, sampling of a random vector X ∈ Rd from this family is possible in the following way:
X := A1/2G + δ ∈ Rd, G ∼ Normal(0, Q),",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"A := τθ(U1, U2) ∈ R,
U1 ∼ Unif(−π/2, π/2), U2 ∼ Exp(1),
where Q ∈ Rd×d is positive definite, δ ∈ Rd, θ := (α, β, µ, σ) ∈ (0, 2] ×",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"[−1, 1] × R ×",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"[0,∞), τθ is a deterministic mapping whose concrete form is described in the Supplementary Materials, and Unif and Exp denote uniform and exponential distributions, respectively.
",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"We dealt with estimation of α := 1.3 and Q, while fixing the other parameters as δ := 0, β := 1, µ := 0, and σ",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
:= 1.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
We restricted Q to be a positive definite matrix such that all diagonal elements are the same and so are the off-diagonal elements.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
We defined true Q to be a matrix whose diagonal elements are 1.0 and off-diagonals are 0.2.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"Therefore the task was to estimate these three values (i.e., 1.3 for α, and 1.0 and 0.2 for Q).",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"We used Unif[0, 2] as a prior for α, and Unif[0, 5] as a prior for each of the diagonal and offdiagonal values of Q.
Figure 1 shows results for the averages of mean square errors in parameter estimation over 30 independent trials, with variation in the dimensionality d from 2 to 16.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"For each method we sampled a total of 1400 pairs of a parameter and a pseudo-data item, and for iterative methods we used 100 pairs in each iteration.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
Each pseudo-data (and observed-data) was made up of 1000 points.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"The noisy ABC-MLE exploited the gradient information in τθ, while the other methods did not.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
The proposed method was competitive with BO and outperformed the other methods with the exception of the noisy ABC-MLE.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"Although the noisy ABC-MLE was accurate for lower-dimensionality (as expected), it exhibited a steep increase in errors for higher dimensionality.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"In contrast, the performance degradation of the proposed method was mild for higher dimensionality.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
We consider here a parametric model in which there exist redundant parameters for expressing given data.,4.5. Gaussian mixture with redundant components,[0],[0]
"We are interested in whether point estimation with the proposed method results in elimination of the redundant parameters
when applied to such a model.",4.5. Gaussian mixture with redundant components,[0],[0]
"This was motivated by Yamazaki and Kaji (2013), who argued that, for mixture models, the use of a Dirichlet prior with a sufficiently small concentration parameter leads to elimination of unnecessary components.",4.5. Gaussian mixture with redundant components,[0],[0]
"We therefore focus on mixture models with redundant components.
",4.5. Gaussian mixture with redundant components,[0],[0]
"Specifically, we considered Gaussian mixture models.",4.5. Gaussian mixture with redundant components,[0],[0]
"We defined the true model as a two-component Gaussian mixture ∑2 i=1 φiNormal(µi, 20) of equal variances.",4.5. Gaussian mixture with redundant components,[0],[0]
"The task was to estimate the mixture coefficients (φ1, φ2, ) := (0.7, 0.3) and the associate means (µ1, µ2) := (110, 70), provided 3000 i.i.d. sample points from the model as observed data y∗. We employed an over-parametrized model for point estimation (i.e., no method used the knowledge that the truth consisted of 2 components), which is a fourcomponent Gaussian mixture ∑4 i=1 φiNormal(µi, 20).",4.5. Gaussian mixture with redundant components,[0],[0]
"We used a 4-dimensional Dirichlet distribution with equal concentration parameters 0.01 as a prior for the coefficients (φ1, . . .",4.5. Gaussian mixture with redundant components,[0],[0]
", φ4), and Normal(0, 100) as a prior for each of µ1, . . .",4.5. Gaussian mixture with redundant components,[0],[0]
", µ4.
",4.5. Gaussian mixture with redundant components,[0],[0]
"For each method, we generated a total of 1000 pairs of a parameter and pseudo-data, and for iterative methods, we made use of 100 pairs in each iteration, resulting in 10 iterations.",4.5. Gaussian mixture with redundant components,[0],[0]
Each pseudo-data consisted of 3000 simulated observations.,4.5. Gaussian mixture with redundant components,[0],[0]
"For all the methods, we converted each data item into a histogram of 300 bins and treated it as a 300 dim.",4.5. Gaussian mixture with redundant components,[0],[0]
vector since this resulted in better performances.,4.5. Gaussian mixture with redundant components,[0],[0]
"We set the parameter α ∈ (0, 1) of SMC-ABC to be 0.2, as this performed well in this experiment.
",4.5. Gaussian mixture with redundant components,[0],[0]
"We ran each algorithm 30 times, and the resulting average errors and standard deviations are shown in Table 3, where the φ error and µ error denote the errors for the coefficients and the means, respectively, as measured in terms of Euclidean distance.",4.5. Gaussian mixture with redundant components,[0],[0]
"More precisely, since any permutation of component labels will result in the same model, we first sorted the estimated parameters {(φi, µi)} so that φ1 ≥ · · · ≥ φ4, and we then measured the errors w.r.t.",4.5. Gaussian mixture with redundant components,[0],[0]
"the ground truth φ := (0.7, 0.3, 0, 0) and µ := (110, 70).",4.5. Gaussian mixture with redundant components,[0],[0]
"For the µ error, we computed the errors only for the estimated means µ1, µ2 associated with the two largest coefficients since there was no ground truth for the redundant components µ3, µ4.",4.5. Gaussian mixture with redundant components,[0],[0]
"Results show that the proposed KR-ABC performed best, indicating that the dominant components were successfully estimated.",4.5. Gaussian mixture with redundant components,[0],[0]
"Our final experiment was parameter estimation with CrowdWalk, a publicly available real-world simulator5 for the movements of pedestrians in a commercial district (Yamashita et al., 2010).",4.6. Real-world pedestrian simulator,[0],[0]
"It has been used to gain insights into pedestrian behavior at a variety of events and occurrences, such as fireworks festivals and evacuations after earthquakes.",4.6. Real-world pedestrian simulator,[0],[0]
"As this simulator is complicated and also computationally expensive, its likelihood function is intractable.
",4.6. Real-world pedestrian simulator,[0],[0]
"Using CrowdWalk, we simulated the movements of pedestrians in Ginza, a commercial district in Tokyo (see Supplementary Materials for an illustration).",4.6. Real-world pedestrian simulator,[0],[0]
"Specifically, we modeled pedestrians as a mixture of multiple groups, each of which has the following 6 parameters (below i denotes the index of a group): (1) θ(N)i ∈ N: the number of pedestrians in the group; (2) θ(T )",4.6. Real-world pedestrian simulator,[0],[0]
i ∈,4.6. Real-world pedestrian simulator,[0],[0]
R+:,4.6. Real-world pedestrian simulator,[0],[0]
"the time when the group starts to move; (3) θ(S)i ∈ R2: the starting location of the group (e.g., stations); (4) θ(G)i ∈ R2: the goal location of the group; (5) θ(P )",4.6. Real-world pedestrian simulator,[0],[0]
"i ∈ R2: the intermediate location(s) that the pedestrians in the group visit (e.g., stores); and (6) θ
(R)",4.6. Real-world pedestrian simulator,[0],[0]
i ∈,4.6. Real-world pedestrian simulator,[0],[0]
"R+: the time duration(s) of the pedestrians’ visit(s)
at the intermediate location(s).
",4.6. Real-world pedestrian simulator,[0],[0]
"In this experiment, we focused on estimation of the first two parameters θ(N)i , θ (T )",4.6. Real-world pedestrian simulator,[0],[0]
"i , and fixed the other parameters.",4.6. Real-world pedestrian simulator,[0],[0]
"We defined the true model as a mixture of 5 pedestrian groups, and set their parameters as (θ∗(N)1 , . . .",4.6. Real-world pedestrian simulator,[0],[0]
", θ ∗(N) 5 ) := (100, 100, 100, 100, 100) and (θ ∗(T ) 1 , . .",4.6. Real-world pedestrian simulator,[0],[0]
.,4.6. Real-world pedestrian simulator,[0],[0]
", θ ∗(T ) 5 ) := (30, 60, 90, 120, 150).",4.6. Real-world pedestrian simulator,[0],[0]
"As in Sec. 4.5, we used a redundant model of a mixture of 10 groups for parameter estimation.",4.6. Real-world pedestrian simulator,[0],[0]
"The goal was to detect the active 5 groups of the true model, without knowing that the truth consists of 5 groups.",4.6. Real-world pedestrian simulator,[0],[0]
"For simplicity, 5 (unknown) groups among the 10 candidate groups included the parameters of the true model other than θ∗(N)i , θ ∗(T ) i ; see the Supplementary Materials for details.
",4.6. Real-world pedestrian simulator,[0],[0]
We defined prior distributions as follows.,4.6. Real-world pedestrian simulator,[0],[0]
First we assumed the total number 500 of pedestrians to be known.,4.6. Real-world pedestrian simulator,[0],[0]
"The mixing coefficients of the mixture of 10 groups are given by (φ1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", φ10) =",4.6. Real-world pedestrian simulator,[0],[0]
"(θ (N) 1 , . . .",4.6. Real-world pedestrian simulator,[0],[0]
", θ (N) 10 )/500.",4.6. Real-world pedestrian simulator,[0],[0]
"Thus, rather than directly putting a prior on (θ(N)1 , . .",4.6. Real-world pedestrian simulator,[0],[0]
.,4.6. Real-world pedestrian simulator,[0],[0]
", θ (N) 10 ), we defined a prior on the mixing coefficients (φ1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", φ10).",4.6. Real-world pedestrian simulator,[0],[0]
"Specifically, we used a Dirichlet prior with a small concentration parameter, as in Sec. 4.5, in order to eliminate 5 redundant components:
(φ1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", φ10)",4.6. Real-world pedestrian simulator,[0],[0]
"∼ Dirichlet(α1, ..., α10), θ
(N)",4.6. Real-world pedestrian simulator,[0],[0]
"i := φi ∗ 500, (i = 1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", 10)
where α1 = · · · = α10 = 0.01 denote the concentration 5https://github.com/crest-cassia/CrowdWalk
parameters.",4.6. Real-world pedestrian simulator,[0],[0]
"For each of θ(T )1 , . . .",4.6. Real-world pedestrian simulator,[0],[0]
", θ (T ) 10 , we defined a broad uniform prior θ(T )i ∼ Unif(0, 480).
",4.6. Real-world pedestrian simulator,[0],[0]
"From the true model, we simulated 4200 time steps of pedestrian flow as observed data.",4.6. Real-world pedestrian simulator,[0],[0]
We made 5× 5 = 25 grids in a map of Ginza and computed a histogram of the corresponding 25 bins for each time step.,4.6. Real-world pedestrian simulator,[0],[0]
"Thus, observed data was made up of 4200 vectors in R25.",4.6. Real-world pedestrian simulator,[0],[0]
"In the same way, each method generated a total of 4200 vectors, and each iterative method made use of 200 vectors in each iteration, running 21 iterations in total.",4.6. Real-world pedestrian simulator,[0],[0]
"For SMC-ABC, we set the parameter α ∈ (0, 1) to be 0.2, as in the previous experiment.
",4.6. Real-world pedestrian simulator,[0],[0]
"We ran each method 20 times, and the resulting averages and standard deviations for errors are summarized in Table 4, where “θ(N) error” and “θ(T ) error” denote the errors of the corresponding estimated parameters, as measured in terms of Euclidean distance.",4.6. Real-world pedestrian simulator,[0],[0]
"These errors were computed in the same way as in Sec. 4.5 (e.g., the estimated parameters were sorted according to the magnitudes of the mixing coefficients).",4.6. Real-world pedestrian simulator,[0],[0]
"Results show that our method performed the best, confirming its effectiveness.",4.6. Real-world pedestrian simulator,[0],[0]
"In the Supplementary Materials, we also report the point estimates made using the proposed method, showing that the true parameters were estimated reasonably accurately.",4.6. Real-world pedestrian simulator,[0],[0]
We have proposed kernel recursive ABC for point estimation with intractable likelihood and have empirically investigated the effectiveness of this approach.,5. Summary and future work,[0],[0]
"While we have also provided theoretical analysis to a certain extent, there remain important theoretical topics, as discussed in Sec. 3.1, that we wish to reserve for future research.",5. Summary and future work,[0],[0]
"We thank the anonymous reviewers as well as Itaru Nishioka, Itsuki Noda, Takashi Washio, Shinji Ito, Wittawat Jitkrittum, and Marie Oshima for their helpful comments and support.",Acknowledgements,[0],[0]
We also thank Shuhei Mano for providing his code.,Acknowledgements,[0],[0]
MK has been supported by the European Research Council (StG Project PANAMA).,Acknowledgements,[0],[0]
KF has been supported by JSPS KAKENHI 26280009.,Acknowledgements,[0],[0]
We propose a novel approach to parameter estimation for simulator-based statistical models with intractable likelihood.,abstractText,[0],[0]
Our proposed method involves recursive application of kernel ABC and kernel herding to the same observed data.,abstractText,[0],[0]
"We provide a theoretical explanation regarding why the approach works, showing (for the population setting) that, under a certain assumption, point estimates obtained with this method converge to the true parameter, as recursion proceeds.",abstractText,[0],[0]
"We have conducted a variety of numerical experiments, including parameter estimation for a realworld pedestrian flow simulator, and show that in most cases our method outperforms existing approaches.",abstractText,[0],[0]
Kernel Recursive ABC: Point Estimation with Intractable Likelihood,title,[0],[0]
"1 Kernelized Support Tensor Train Machines Cong Chen, Kim Batselier, Wenjian Yu, Senior Member, IEEE, Ngai Wong, Senior Member, IEEE
Abstract—Tensor, a multi-dimensional data structure, has been exploited recently in the machine learning community. Traditional machine learning approaches are vector- or matrixbased, and cannot handle tensorial data directly. In this paper, we propose a tensor train (TT)-based kernel technique for the first time, and apply it to the conventional support vector machine (SVM) for image classification. Specifically, we propose a kernelized support tensor train machine that accepts tensorial input and preserves the intrinsic kernel property. The main contributions are threefold. First, we propose a TT-based feature mapping procedure that maintains the TT structure in the feature space. Second, we demonstrate two ways to construct the TTbased kernel function while considering consistency with the TT inner product and preservation of information. Third, we show that it is possible to apply different kernel functions on different data modes. In principle, our method tensorizes the standard SVM on its input structure and kernel mapping scheme. Extensive experiments are performed on real-world tensor data, which demonstrates the superiority of the proposed scheme under few-sample high-dimensional inputs.
I. INTRODUCTION
Many real-world data appear in matrix or tensor format. For example, a grayscale picture is a 2-way tensor (i.e. a matrix), a color image or a grayscale video is naturally a 3-way tensor, and a color video can be regarded as a 4- way tensor. In such circumstances, extending the vector-based machine learning algorithms to their tensorial format has recently attracted significant interest in the machine learning and data mining communities.For example, neighborhood preserving embedding (NPE) was extended to tensor neighborhood preserving embedding (TNPE) in [1], principal component analysis to multilinear principal component analysis (MPCA) in [2], support vector machines (SVMs) [3] to support tensor machines (STMs) in [4], and restricted Boltzmann machines to their tensorial formats in [5].
By reformulating the aforementioned machine learning algorithms into the tensorial framework, a huge performance improvement has been achieved. The main reasons for this improvement can be summarized as follows. Firstly, these tensorized algorithms can naturally utilize the multi-way structure of the original tensor data, which is believed to be useful in
This work is partially supported by the Hong Kong Research Grants Council under Project 17246416, the University Research Committee of The University of Hong Kong, Tsinghua University Initiative Scientific Research Program, and NSFC under grant No. 61872206.
Cong Chen is with the Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong. Email: chencong@eee.hku.hk.
Kim Batselier is with the Delft Center for Systems and Control, Delft University of Technology, Delft, Netherlands. Email: k.batselier@tudelft.nl.
Wenjian Yu is with BNRist, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China. Email: yuwj@tsinghua.edu.cn.
Ngai Wong is with the Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong. Email: nwong@eee.hku.hk.
many machine learning applications such as pattern recognition [6], image completion [7] and anomaly detection [8]. Secondly, vectorizing tensor data leads to high-dimensional vectors, which may cause overfitting especially when the training sample size is relatively small [9]. On the contrary, tensor-based approaches usually derive a more structural and robust model that commonly involves much fewer model parameters, which not only alleviates the overfitting problem, but also saves a lot of storage and computation resources [10], [11].
In this paper, we propose a kernelized support tensor train machine (K-STTM) to address few-sample image classification problems due to the fact that collecting labeled pictures is very expensive and time-consuming in many research areas. Specifically, we first employ the tensor train (TT) decomposition [12] to decompose the given tensor data so that a more compact and informative representation of it can be derived. Secondly, we define a TT-based feature mapping strategy to derive a high-dimensional TT in the feature space. This strategy enables us to apply different feature mappings on different data modes, which naturally provides a way to leverage the multi-modal nature of tensor structured data. Thirdly, we propose two ways to build the kernel matrix with the consideration of the consistency with the TT inner product and preservation of information. The constructed kernel matrix is then used by kernel machines to solve the image classification problems.
There are two main advantages from the proposed methods. On the one hand, the proposed methods are naturally nonlinear classifiers. It is common that real-life data are not linearly separable. However, most existing supervised tensor learning methods which employ tensor input are often based on a linear model and cannot deal with nonlinear classification problems. In that case, our proposed methods can handle nonlinear learning problems on tensor data better. On the other hand, conventional tensor-based kernel methods focus on flatting tensor data into matrices [13], [14], and thus can only preserve one-mode relationships within the tensor itself. However, our proposed approaches can capture and exploit multi-mode relationships, which commonly leads to more powerful and accurate models.
The superiority of our methods is validated through extensive experiments. It is observed that our methods achieve a much better performance than the linear supervised tensor learning methods, which indicates the importance of introducing kernel trick. Furthermore, our methods achieve a better classification performance when the input data are truly highdimensional. Applying different kernel functions on different data modes is also investigated and shows an obvious improvement compared with the baseline.
The rest of this paper is organized as follows. In Section II,
ar X
iv :2
00 1.
00 36
0v 1
[ cs
.L G
] 2
J an
2 02
0
2 we briefly review some related works in supervised tensor learning. Some useful notations and tensor arithmetic are further introduced in Section III. In Section IV, we formulate the proposed kernelized support tensor train machine (K-
STTM). Experiments are shown in Section V to validate the superiority of our methods. Lastly, we draw conclusions and propose some possible extended works in Section VI.",text,[0],[0]
"As one of the most typical supervised learning algorithms, SVM [3] has achieved an enormous success in pattern classification by minimizing the Vapnik-Chervonenkis dimensions and structural risk.",II. RELATED WORKS,[0],[0]
"However, a standard SVM can not deal with tensorial input directly.",II. RELATED WORKS,[0],[0]
The first work that extends SVM to handle tensorial input is [4].,II. RELATED WORKS,[0],[0]
"More precisely, a supervised tensor learning (STL) scheme was proposed to train a support tensor machine (STM), where the hyperplane parameters are modeled as a rank-1 tensor instead of a vector.",II. RELATED WORKS,[0],[0]
"For the parameter training, they employed the alternating projection optimization method.
",II. RELATED WORKS,[0],[0]
"Although STM is capable to classify tensorial data directly, the expressive power of a rank-1 weight tensor is limited, which often leads to a poor classification accuracy.",II. RELATED WORKS,[0],[0]
"To increase the model expression capacity, several works were proposed recently based on the STL scheme.",II. RELATED WORKS,[0],[0]
Ref.,II. RELATED WORKS,[0],[0]
"[15] employs a more general tensor structure, i.e., the canonical polyadic (CP) format, to replace the rank-1 weight tensor in STM.",II. RELATED WORKS,[0],[0]
"However, it is an NP-complete problem to determine the CP-rank.",II. RELATED WORKS,[0],[0]
"In [16], the STM is generalized to a support Tucker machine (STuM) by representing the weight parameter as a Tucker tensor.",II. RELATED WORKS,[0],[0]
"Nevertheless, the number of model parameters in STuM is exponentially large, which often leads to a large amount of storage and computation consumption.",II. RELATED WORKS,[0],[0]
"To overcome this, Ref.",II. RELATED WORKS,[0],[0]
"[17] proposed a support tensor train machine (STTM), which assumes the potential weight tensor format is a TT.",II. RELATED WORKS,[0],[0]
"By doing so, the corresponding optimization problem is more scalable and can be solved efficiently.",II. RELATED WORKS,[0],[0]
The aforementioned work are all based on the assumption that the given tensorial data are linearly separable.,II. RELATED WORKS,[0],[0]
"However, this is not the case in most real-world data.",II. RELATED WORKS,[0],[0]
"It is worth noting that though STTM sounds like the linear case of the proposed K-STTM, they are totally different when the linear kernel is applied on K-STTM.",II. RELATED WORKS,[0],[0]
"Specifically, K-STTM and STTM use two totally different schemes to train the corresponding model.",II. RELATED WORKS,[0],[0]
"For KSTTM, it first constructs the kernel matrix with the proposed TT-based kernel function, and then solves the standard SVM problem.",II. RELATED WORKS,[0],[0]
"However, in STTM, it assumes the parameter in the classification hyperplane can be modeled as a TT, and only updates one TT-core at a time by reformulating the training data.
",II. RELATED WORKS,[0],[0]
"To extend the linear tensorial classifiers to the nonlinear case, the authors in [18] proposed a nonlinear supervised learning scheme called dual structure-preserving kernels (DuSK).",II. RELATED WORKS,[0],[0]
"Specifically, based on the CP tensor structure, they define a corresponding kernel trick to map the CP format data into a higher-dimensional feature space.",II. RELATED WORKS,[0],[0]
"Through the introduction of the kernel trick, DuSK can achieve a higher classification
a a A A
Fig. 1: Graphical representation of a scalar a, vector a, matrix A, and third-order tensor A.
I1
I2 I4
I3 I5A B
Fig. 2: Index contraction between two 3-way tensors A and B.
accuracy.",II. RELATED WORKS,[0],[0]
"However, since DuSK is based on the CP decomposition, the NP-complete problem on the rank determination still exists.",II. RELATED WORKS,[0],[0]
"Moreover, through introducing a kernelized CP tensor factorization technique, the same research group in [18] further proposed the Multi-way Multi-level Kernel model [19] and kernelized support tensor machine model [20].",II. RELATED WORKS,[0],[0]
"Nevertheless, the CP-rank determination issue still exists since they are all based on the CP decomposition.
",II. RELATED WORKS,[0],[0]
"To avoid the above issues, we propose the K-STTM, which not only introduces the customized kernel function to handle nonlinear classification problems, but also achieves an efficient model training since the scalable TT format is employed.",II. RELATED WORKS,[0],[0]
"In this Section, we review some basic tensor notations and operations, together with the related tensor train decomposition method.",III. PRELIMINARIES,[0],[0]
Tensors in this paper are multi-dimensional arrays that generalize vectors (first-order tensors) and matrices (secondorder tensors) to higher orders.,A. Tensor basics,[0],[0]
"A dth-order or d-way tensor is denoted as A ∈ RI1×I2×···×Id and the element of A by A(i1, i2 . . .",A. Tensor basics,[0],[0]
", id), where 1≤ ik ≤ Ik, k = 1, 2, . . .",A. Tensor basics,[0],[0]
", d. The numbers I1, I2, . .",A. Tensor basics,[0],[0]
.,A. Tensor basics,[0],[0]
", Id are called the dimensions of the tensor A.",A. Tensor basics,[0],[0]
"We use boldface capital calligraphic letters A, B, . . .",A. Tensor basics,[0],[0]
"to denote tensors, boldface capital letters A, B, . . .",A. Tensor basics,[0],[0]
"to denote matrices, boldface letters a, b, . . .",A. Tensor basics,[0],[0]
"to denote vectors, and roman letters a, b, . . .",A. Tensor basics,[0],[0]
to denote scalars.,A. Tensor basics,[0],[0]
"An intuitive and useful graphical representation of scalars, vectors, matrices and tensors is depicted in Figure 1.",A. Tensor basics,[0],[0]
"The unconnected edges, also called free legs, are the indices of the tensor.",A. Tensor basics,[0],[0]
"Therefore scalars have no free legs, while a matrix has 2 free legs.",A. Tensor basics,[0],[0]
We will employ these graphical representations to visualize the tensor networks and operations in the following sections whenever possible and refer to [21] for more details.,A. Tensor basics,[0],[0]
"We now briefly introduce some important tensor operations.
",A. Tensor basics,[0],[0]
"Definition 1: (Tensor index contraction): A tensor index contraction is the sum over all possible values of the repeated indices in a set of tensors.
3 A(1) A(2) A(d)...",A. Tensor basics,[0],[0]
"R1 R2 R3 Rd Rd+1
I1 I2 Id
Fig. 3: Tensor train decomposition of a d-way tensor A into d 3-way tensors A(1),A(2) . . .",A. Tensor basics,[0],[0]
",A(d).
",A. Tensor basics,[0],[0]
"For example, the following contraction of two 3-way tensors A and B
C(i1, i2, i4, i5) = I3∑ i3=1 A(i1, i2, i3)B(i3, i4, i5),
over the i3 index produces a four-way tensor C. We also present the graphical representation of this contraction in Figure 2, where the summation over i3 is indicated by the connected edge.",A. Tensor basics,[0],[0]
"After this contraction, the tensor diagram contains four free legs indexed by i1, i2, i4, i5, respectively.
",A. Tensor basics,[0],[0]
"Definition 2: (Tensor inner product): For two tensors A,B ∈ RI1×I2×···×Id , their inner product 〈A,B〉 is defined as
〈A,B〉 = I1∑ i1=1 I2∑ i2=1 · · · Id∑ id=1 ai1,i2,··· ,idbi1,i2,··· ,id .
",A. Tensor basics,[0],[0]
"Definition 3: (Tensor Frobenius norm): The Frobenius norm of a tensor A ∈ RI1×I2×···×Id is defined as ||A||F =√ 〈A,A〉.",A. Tensor basics,[0],[0]
Here we briefly introduce the tensor train (TT) decomposition that will be utilized in the proposed K-STTM.,B. Tensor train decomposition,[0],[0]
"A TT decomposition [12] represents a d-way tensor A as d 3-way tensors A(1), A(2), . . .",B. Tensor train decomposition,[0],[0]
", A(d) such that a particular entry of A is written as the matrix product
A(i1, . . .",B. Tensor train decomposition,[0],[0]
", id) = A(1)(:, i1, :) · · ·A(d)(:, id, :), (1)
where A(k)(:, ik, :) is naturally a matrix since we fix the second index.",B. Tensor train decomposition,[0],[0]
"Each tensor A(k), k = 1, . . .",B. Tensor train decomposition,[0],[0]
", d, is called a TT-core and has dimensions Rk × Ik ×Rk+1.",B. Tensor train decomposition,[0],[0]
"Storage of a tensor as a TT therefore reduces from
∏d i=1",B. Tensor train decomposition,[0],[0]
Ri down,B. Tensor train decomposition,[0],[0]
"to∑d
i=1 RiIiRi+1.",B. Tensor train decomposition,[0],[0]
In order for the left-hand-side of (1) to be a scalar we require that R1 = Rd+1 = 1.,B. Tensor train decomposition,[0],[0]
The remaining Rk values are called the TT-ranks.,B. Tensor train decomposition,[0],[0]
"Figure 3 demonstrates how TT-decomposition decomposes a d-way tensor A, where the edges connecting the different circles indicate the matrixmatrix products of (1).",B. Tensor train decomposition,[0],[0]
"To simplify the statement, we define the notation TT (·), which means perform TT decomposition on a d-way tensor.",B. Tensor train decomposition,[0],[0]
"For example, TT (A) is the resulting TT after doing TT decomposition on the full tensor A, namely, A(1), A(2), · · · , A(d) are derived.
",B. Tensor train decomposition,[0],[0]
"Definition 4: (TT inner product): The inner product between two tensor trains TT (A) and TT (B) is denoted as 〈TT (A), TT (B)〉.",B. Tensor train decomposition,[0],[0]
The tensor network diagram of the inner product of two TTs is shown in Figure 4.,B. Tensor train decomposition,[0],[0]
"The lack of unconnected edges in Figure 4 implies that 〈TT (A), TT (B)〉 is a scalar.
A(1) A(2) A(d)
B(1) B(2) B(d)
...
...
",B. Tensor train decomposition,[0],[0]
Fig. 4: The inner product between two d-way tensor trains.,B. Tensor train decomposition,[0],[0]
"Since this work is based on traditional SVM, we therefore briefly review the main idea of an SVM.",C. Support vector machines,[0],[0]
"Assume we have a dataset D={xi, yi}Mi=1 of M labeled samples, where xi ∈ Rn are the vectorized data samples with labels yi ∈ {−1, 1}.",C. Support vector machines,[0],[0]
"The goal of an SVM is to find a discriminant hyperplane
f(x) = wTx + b (2)
that maximizes the margin between the two classes where w and b are the weight vector and bias, respectively.",C. Support vector machines,[0],[0]
"However, an SVM is very sensitive to noise since it requires all the training samples to meet the hard margin constraint.",C. Support vector machines,[0],[0]
"In that case, the trained model tends to overfit.",C. Support vector machines,[0],[0]
"To solve this, slack variables ξ1, . . .",C. Support vector machines,[0],[0]
", ξM are introduced to allow some certain samples to be misclassified, thus enhancing the robustness of the trained model.",C. Support vector machines,[0],[0]
"We can express the learning problem as a quadratic optimization problem
min w,b,ξ
1 2 ||w||2F + C M∑ i=1",C. Support vector machines,[0],[0]
"ξi
subject to yi(wTxi + b) ≥ 1− ξi, ξi ≥ 0, i = 1, . . .",C. Support vector machines,[0],[0]
",M. (3)
",C. Support vector machines,[0],[0]
The parameter C controls the trade-off between the size of the weight vector w and the size of the slack variables.,C. Support vector machines,[0],[0]
"It is more common to solve the dual problem of (3), especially when the feature size n is larger than the sample size M .",C. Support vector machines,[0],[0]
"The dual problem format of (3) is
min α1,α2,··· ,αM M∑ i=1",C. Support vector machines,[0],[0]
αi− 1 2 M∑,C. Support vector machines,[0],[0]
"i,j=1 αiαjyiyj〈xi,xj〉
subject to M∑ i=1",C. Support vector machines,[0],[0]
αiyi,C. Support vector machines,[0],[0]
"= 0,
0 ≤ αi ≤ C, i = 1, . . .",C. Support vector machines,[0],[0]
",M, (4)
where 〈xi,xj〉 represents the inner product between vector xi and xj and αi (i = 1, . . .",C. Support vector machines,[0],[0]
",M) are the Lagrange multipliers.
",C. Support vector machines,[0],[0]
"To solve a nonlinear classification problem with SVM, researchers further introduced the kernel trick that projects the original vectorial data onto a much higher-dimensional feature space through a nonlinear mapping function φ.",C. Support vector machines,[0],[0]
"In the feature space, the data generally become more (linearly) separable.",C. Support vector machines,[0],[0]
"By doing so, the optimization in (4) is transformed into
min α1,α2,··· ,αM M∑ i=1",C. Support vector machines,[0],[0]
αi− 1 2 M∑,C. Support vector machines,[0],[0]
"i,j=1 αiαjyiyj〈φ(xi), φ(xj)〉 (5)
4 with the same constraints as in (4).",C. Support vector machines,[0],[0]
"It turns out that it is possible to make the computation easier by replacing the inner product term 〈φ(xi), φ(xj)〉 with a kernel function k(xi,xj).",C. Support vector machines,[0],[0]
"In that case, the inner product in the high-dimensional feature space can be computed without the need to explicitly compute the mappings φ(xi), φ(xj).",C. Support vector machines,[0],[0]
"In this section, we first demonstrate the tensor-based kernel learning problem and then introduce the proposed K-STTM.",IV. KERNELIZED SUPPORT TENSOR TRAIN MACHINES,[0],[0]
"Given M tensorial training data and their labels, i.e., dataset D = {X i, yi}Mi=1, where X",A. Problem statement,[0],[0]
i ∈,A. Problem statement,[0],[0]
"RI1×I2×···×Id and yi ∈ {−1, 1}, we want to find a hyperplane
f(X ) = 〈W ,X 〉+ b",A. Problem statement,[0],[0]
(6) that separates the tensorial data into two classes.,A. Problem statement,[0],[0]
W is the hyperplane weight tensor with the same dimensions as X i and b is the bias.,A. Problem statement,[0],[0]
"Similar to the primal problem in SVM, we can derive the corresponding primal optimization problem for (6)
min W,b,ξ
1 2 ||W ||2F + C M∑ i=1",A. Problem statement,[0],[0]
"ξi
subject to yi(〈W ,X i〉+ b) ≥ 1− ξi, ξi ≥ 0, i = 1, . .",A. Problem statement,[0],[0]
.,A. Problem statement,[0],[0]
",M. (7)
",A. Problem statement,[0],[0]
"Following the scheme of the kernel trick for conventional SVMs, we introduce a nonlinear feature mapping function Φ(·).",A. Problem statement,[0],[0]
"Then, given a tensor X ∈ RI1×I2×···×Id , we assume it is mapped into the Hilbert space H by
Φ : X → Φ(X ) ∈ RH1×H2×···×Hd .",A. Problem statement,[0],[0]
(8) We need to mention that the dimension of projected tensor Φ(X ) can be infinite depending on the feature mapping function Φ(·).,A. Problem statement,[0],[0]
"The resulting Hilbert space is then called the tensor feature space and we can further develop the following model
min W,b,ξ
1 2 ||W ||2F + C M∑ i=1",A. Problem statement,[0],[0]
"ξi
subject to yi(〈W ,Φ(X i)〉+ b) ≥ 1− ξi, ξi ≥ 0, i = 1, . . .",A. Problem statement,[0],[0]
",M, (9)
with parameter tensor W ∈ RH1×H2×···×Hd .",A. Problem statement,[0],[0]
This model is naturally a linear classifier on the tensor feature space.,A. Problem statement,[0],[0]
"However, when we map the classifier back to the original data space, it is a nonlinear classifier.",A. Problem statement,[0],[0]
"To obtain the tensor-based kernel optimization model, we need to transfer model (9) into its dual, namely
min α1,α2,··· ,αM M∑ i=1",A. Problem statement,[0],[0]
αi− 1 2 M∑,A. Problem statement,[0],[0]
"i,j=1 αiαjyiyj〈Φ(X i),Φ(X j)〉
subject to M∑ i=1",A. Problem statement,[0],[0]
αiyi,A. Problem statement,[0],[0]
"= 0,
0 ≤ αi ≤ C, i = 1, . .",A. Problem statement,[0],[0]
.,A. Problem statement,[0],[0]
",M, (10)
where αi are the Lagrange multipliers.",A. Problem statement,[0],[0]
The key task we need to solve is to define a tensorial kernel function,A. Problem statement,[0],[0]
"K(X i,X j) that computes the inner product 〈Φ(X i),Φ(X j)〉 in the original data space instead of the feature space.",A. Problem statement,[0],[0]
"Although tensor is a natural structure for representing realworld data, there is no guarantee that such a representation works well for kernel learning.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Instead of the full tensor, here we employ a TT for data representation due to the following reasons:
1) Real-life data often contain redundant information, which is not useful for kernel learning.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
The TT decomposition has proven to be efficient for removing the redundant information in the original data and provides a more compact data representation.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
2),B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Compared to the Tucker decomposition whose storage scales exponentially with the core tensor, a TT is more scalable (parameter number grows linearly with the tensor order d), which reduces the computation during kernel learning.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"3) Unlike the CP decomposition, determining the TT-rank is easily achieved through a series of singular value decompositions (TT-SVD [12] ).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
This naturally leads to a faster data transformation to the TT format.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
4),B. Customized kernel mapping schemes for TT-based data,[0],[0]
It is convenient to implement different operations on different tensor modes when data is in the TT format.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Since a TT decomposition decomposes the original data into many TT cores, it is possible to apply different kernel functions on different TT cores for a better classification performance.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Furthermore, we can emphasize the importance of different tensor modes by putting different weights on those TT cores during the kernel mapping.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"For example, a color image is a 3-way (pixel-pixel-color) tensor.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"The color mode can be treated differently with the two pixel modes since they contain different kinds of information, as will be exemplified later.
",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"In the following, we demonstrate the proposed TT-based feature mapping approach.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Specifically, we map all fibers in each TT-core to the feature space, namely
Φ : X (i)(ri, :, ri+1)→ Φ(X (i)(ri, :, ri+1))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"∈ RHi
1 ≤",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"ri ≤ Ri, i = 1, . . .",B. Customized kernel mapping schemes for TT-based data,[0],[0]
", d, (11)
where X (i) and Ri are the i-th TT-core and TT-rank of TT (X ), respectively.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"The fibers of each TT-core are naturally vectors, so the feature mapping works in the same way as for the conventional SVM.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"We then represent the resulting high-dimensional TT, which is in the tensor feature space, as Φ(TT (X ))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
∈ RH1×H2×···×Hd .,B. Customized kernel mapping schemes for TT-based data,[0],[0]
We stress that Φ(TT (X )) is still in a TT format with the same TT-ranks as TT (X ).,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"In this sense, the TT format data structure is preserved after the feature mapping.
",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"After mapping the TT format data into the TT-based highdimensional feature space, we then demonstrate the two proposed approaches for computing the inner product between two mapped TT format data using kernel function.
5 1) K-STTM-Prod:",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"The first method is called K-STTM-Prod since we implement consecutive multiplication operations on d fiber inner products, which is consistent with the result of an inner product between two TTs.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
Assuming Φ(TT (X )),B. Customized kernel mapping schemes for TT-based data,[0],[0]
and,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Φ(TT (Y)) ∈ RH1×H2×···×Hd with TT-ranks Ri and R̂i, i = 1, 2, . . .",B. Customized kernel mapping schemes for TT-based data,[0],[0]
", d, respectively, their inner product can be computed from
〈Φ(TT (X )),Φ(TT (Y))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"〉 = R1∑ r1=1 · · · Rd∑ rd=1 R̂1∑ r̂1=1 · · · R̂d∑ r̂d=1
( d∏ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"〈Φ(X (i)(ri, :, ri+1)),Φ(Y(i)(r̂i, :, r̂i+1))〉).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"(12)
We remark that (12) derives the exact same result as Figure 4 (assuming X = A and Y = B) when an identity feature mapping function Φ(·) is used, namely Φ(TT (X ))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
=TT (X ).,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"What is more, since each fiber of a mapped TT-core is naturally a vector, we have
〈Φ(X (i)(ri, :, ri+1)),Φ(Y(i)(r̂i, :, r̂i+1))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"〉 = K(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1)), (13)
where K(·) can be any kernel function used for a standard SVM, such as a Gaussian RBF kernel, polynomial kernel, linear kernel etc.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Combining (12) and (13), we obtain the corresponding TT-based kernel function
K(TT (X ), TT (Y))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"= R1∑ r1=1 · · · Rd∑ rd=1 R̂1∑ r̂1=1 · · · R̂d∑ r̂d=1
( d∏ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"K(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1))).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"(14)
As mentioned before, different kernel functions can be applied on different tensor modes i = 1, 2, . . .",B. Customized kernel mapping schemes for TT-based data,[0],[0]
", d. Therefore, the second line in (14) can be generalized to
( d∏ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Ki(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1))).
",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"One possible application is in color image classification, where one could apply Gaussian RBF kernels K1 and K2 on its first two spatial modes, while choosing a linear or polynomial kernel K3 for the color mode.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"This will be investigated in the experiments.
2) K-STTM-Sum: The second method we propose to construct a TT kernel function is called K-STTM-Sum.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Instead of implementing consecutive multiplication operations on d fiber inner products like in K-STTM-Prod, K-STTM-Sum performs consecutive addition operations on them.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
This idea is inspired by [22] which argues that the product of inner products can lead to the loss/misinterpretation of information.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Take the linear kernel as an example, the inner product between two fibers of the same mode could be negative, which indicates a low similarity between those two fibers.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"However, by implementing consecutive multiplication operations on d fiber inner products, highly negative values could result in a large positive value.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"In that case, the overall similarity is high which is clearly unwanted.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"This situation also appears
when employing Gaussian RBF kernels.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"A nearly zero value would be assigned to two non-similar fibers, which could influence the final result significantly.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"To this end, we propose the K-STTM-Sum.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Similar to K-STTM-Prod, we can obtain the corresponding kernel function as
K(TT (X ), TT (Y))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"= R1∑ r1=1 · · · Rd∑ rd=1 R̂1∑ r̂1=1 · · · R̂d∑ r̂d=1
( d∑ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Ki(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1))).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
(15),B. Customized kernel mapping schemes for TT-based data,[0],[0]
"After defining the TT-based kernel function, we can then replace the term 〈Φ(X i),Φ(X j)〉 in (10) with (14) or (15), and derive our final kernel optimization problem based on the TT structure, namely,
min α1,α2,··· ,αM M∑ i=1",C. Kernel optimization problem,[0],[0]
αi− 1 2 M∑,C. Kernel optimization problem,[0],[0]
"i,j=1 αiαjyiyjK(TT",C. Kernel optimization problem,[0],[0]
"(X i), TT (X j))
subject to M∑ i=1",C. Kernel optimization problem,[0],[0]
αiyi,C. Kernel optimization problem,[0],[0]
"= 0,
0 ≤ αi ≤ C, i = 1, . . .",C. Kernel optimization problem,[0],[0]
",M. (16)
",C. Kernel optimization problem,[0],[0]
"After solving (16), we can get the unknown model parameters α1, α2, . . .",C. Kernel optimization problem,[0],[0]
", αM and the resulting decision function is then represented as
f(X )",C. Kernel optimization problem,[0],[0]
= sign( M∑ i=1,C. Kernel optimization problem,[0],[0]
αiyiK(TT,C. Kernel optimization problem,[0],[0]
"(X i), TT (X ))",C. Kernel optimization problem,[0],[0]
+ b).,C. Kernel optimization problem,[0],[0]
"(17)
Here we take the Gaussian RBF kernel as an example and summarize the training algorithm of the K-STTM-Prod/Sum as pseudo-code in Algorithm 1.",C. Kernel optimization problem,[0],[0]
An alternative for doing a grid search to find optimal hyperparameters would be crossvalidation.,C. Kernel optimization problem,[0],[0]
"Generalizing the binary classification to multiclassification can be easily achieved by utilizing a one-vs-one or one-vs-all strategy, namely, we can build several binary classifiers to do multi-class classification.",C. Kernel optimization problem,[0],[0]
"A key property of kernel function in standard SVM is that the resulting kernel matrix is positive semi-definite, which guarantees the mapped high-dimensional feature space is truly an inner product space.",D. Kernel validity,[0],[0]
"Therefore, we provide Theorem 1 to show the validity of K-STTM-Prod and K-STTM-Sum.
Theorem 1: Kernel functions K-STTM-Prod and K-STTMSum produce positive semi-definite kernel matrices.
",D. Kernel validity,[0],[0]
We provide the proof here.,D. Kernel validity,[0],[0]
1) Validity of K-STTM-Prod:,D. Kernel validity,[0],[0]
We first demonstrate the kernel function validity of K-STTM-Prod.,D. Kernel validity,[0],[0]
The goal is to show that the final kernel matrix constructed by (14) is positive semidefinite.,D. Kernel validity,[0],[0]
"In the actual implementation, it is extremely inefficient to use TT decomposition to decompose each tensorial sample one by one.",D. Kernel validity,[0],[0]
"The way we did it is by first stacking all
6 Algorithm 1 K-STTM-Prod/Sum Algorithm
Input: Training dataset {X i ∈ RI1×···×Id , yi ∈ {−1, 1}}Mi=1; Validation dataset {X j ∈ RI1×···×Id , yj ∈ {−1, 1}}Nj=1; The pre-set TT-ranks R1, R2, . . .",D. Kernel validity,[0],[0]
", Rd+1; The range of the performance trade-off parameter C and kernel width parameter σ, namely [Cmin, Cmax], and [σmin, σmax].",D. Kernel validity,[0],[0]
"Output: The Lagrange multipliers α1, α2, . . .",D. Kernel validity,[0],[0]
", αM ; The bias b.
1: Compute the TT approximation of training samples {X i}Mi=1 and validation set {X j}Nj=1 with the given TTranks using TT-SVD.",D. Kernel validity,[0],[0]
2: for C from Cmin to Cmax do 3: for σ from σmin to σmax do 4:,D. Kernel validity,[0],[0]
"Apply Gaussian RBF kernel on all the tensor modes,
and construct the kernel matrix according to (14) or (15), which are corresponding to K-STTM-Prod and K-STTM-Sum, respectively.
5: Solve (16) using the resulting kernel matrix.",D. Kernel validity,[0],[0]
6: Compute the classification accuracy on validation set.,D. Kernel validity,[0],[0]
"7: end for 8: end for 9: Find the best C and σ according to the classification
accuracy on validation set.",D. Kernel validity,[0],[0]
"10: Train the K-STTM with the best C and σ by imple-
menting step 4 and 5.",D. Kernel validity,[0],[0]
"Thus the the Lagrange multipliers α1, α2, . . .",D. Kernel validity,[0],[0]
", αM and the bias b are obtained.
",D. Kernel validity,[0],[0]
the d-way samples and then compute a TT decomposition on the resulting (d+ 1)-way tensor directly.,D. Kernel validity,[0],[0]
"By doing so, all TTbased training samples have the same TT-ranks.",D. Kernel validity,[0],[0]
"Also in the case where we compute the TT decomposition separately for each sample, we can still set the TT-ranks of all samples to be identical.",D. Kernel validity,[0],[0]
"That means Ri is equal to R̂i, i = 1, 2, . . .",D. Kernel validity,[0],[0]
", d for all the TT-based training samples.",D. Kernel validity,[0],[0]
We can then compute the final kernel matrix by doing R21×. .,D. Kernel validity,[0],[0]
.×R2d,D. Kernel validity,[0],[0]
"matrix summations, while each matrix in the summation procedure is computed by d times matrix Hadamard product.",D. Kernel validity,[0],[0]
"The matrix factors in the d times Hadamard product are valid kernel matrices since they are computed using the standard kernel function.
",D. Kernel validity,[0],[0]
"Through the above analysis, the goal now transforms into proving that the summation or Hadamard product between two positive semi-definite matrices A and B ∈ Rn×n still results in a positive semi-definite matrix.
",D. Kernel validity,[0],[0]
"For the summation case, we have{ uTAu ≥ 0, uTBu ≥ 0.
(18)
for every non-zero column vector u ∈ Rn.",D. Kernel validity,[0],[0]
"Obviously we can conclude that
uT (A+B)u ≥ 0, (19)
namely A + B is still positive semi-definite.",D. Kernel validity,[0],[0]
"For the Hadamard product case, we refer to the the Schur product theorem [23] and we can easily obtain
uT (A B)u ≥ 0, (20)
for every non-zero column vector u ∈",D. Kernel validity,[0],[0]
"Rn, where is the Hadamard product.",D. Kernel validity,[0],[0]
"Thus A B is still positive semi-definite.
",D. Kernel validity,[0],[0]
"Through the above analysis, we can conclude that by constraining the TT-based training samples to have identical TT-ranks, we can get a valid kernel matrix using K-STTMProd.
2) Validity of K-STTM-Sum: The proof for the validity of K-STTM-Sum is similar as it for K-STTM-Prod.",D. Kernel validity,[0],[0]
The difference between kernel functions (14) and (15) is that (15) only replaces the product with a summation.,D. Kernel validity,[0],[0]
"In that case, for K-STTM-Sum, the final kernel matrix is produced by the summation of a set of valid positive semi-definite matrices.",D. Kernel validity,[0],[0]
"Namely, we can still get a valid kernel matrix using K-STTMSum.",D. Kernel validity,[0],[0]
"Here we demonstrate the convergence analysis of our proposed methods and compare the storage and computation complexity with the standard SVM.
",E. Convergence and complexity,[0],[0]
"For the convergence analysis, it is same as it in standard SVM problem.",E. Convergence and complexity,[0],[0]
We already show the kernel validity of (14) and (15) in Theorem 1.,E. Convergence and complexity,[0],[0]
"With a valid kernel matrix, we can solve a quadratic programming problem to get the Lagrange multipliers αi and bias b, which is same as the procedure in standard SVM.",E. Convergence and complexity,[0],[0]
"Consequently, the convergence analysis is exactly same as it in standard SVM.
",E. Convergence and complexity,[0],[0]
"For the storage complexity analysis, the original tensorial sample storage is O(MId), where I is the maximum value of Ii, i = 1, 2, . . .",E. Convergence and complexity,[0],[0]
", d.",E. Convergence and complexity,[0],[0]
"After representing the original tensorial data as TTs, the data storage becomes to O(MdIR2), where R is the maximum TT-rank.",E. Convergence and complexity,[0],[0]
"This shows a great reduction especially when the data order d is large.
",E. Convergence and complexity,[0],[0]
"For the computation complexity, the overall result of KSTTM-Prod is the same as the result of K-STTM-Sum if we neglect those low-order polynomial terms.",E. Convergence and complexity,[0],[0]
This can be observed from (14) and (15).,E. Convergence and complexity,[0],[0]
The main computation costs are similar in those two equations.,E. Convergence and complexity,[0],[0]
Therefore we just analyze the K-STTM-Prod method.,E. Convergence and complexity,[0],[0]
"The computational complexity of constructing the kernel matrix in standard SVM is O(M2Id), where n is the maximum dimension of Ii, i = 1, 2, ...",E. Convergence and complexity,[0],[0]
"d. When applying the accelerating implementation of K-STTMProd, its kernel matrix computation complexity is O(dI2R4 + M2IdR 2 d), where I and R are the maximum values of Ii and Ri, i = 1, 2, ...",E. Convergence and complexity,[0],[0]
d,E. Convergence and complexity,[0],[0]
"− 1, respectively.",E. Convergence and complexity,[0],[0]
"Real-world data is commonly low-rank, so the TT-ranks Ri are generally small.",E. Convergence and complexity,[0],[0]
"Moreover, their dimensions Ii are very high.",E. Convergence and complexity,[0],[0]
That indicates our proposed method is more efficient than its vector counterpart since the computation complexity is reduced from exponential to polynomial.,E. Convergence and complexity,[0],[0]
"We evaluate the effectiveness of the two proposed schemes, K-STTM-Prod and K-STTM-Sum, on real-world tensorial datasets and contrast our methods with the following seven methods as a baseline.",V. EXPERIMENTS,[0],[0]
"• SVM: SVM [3] is one of the most widely used vector-
based method for classification.",V. EXPERIMENTS,[0],[0]
"What is more, the proposed K-STTM is a tensorial extension of SVM, so SVM
7 is selected as a baseline.",V. EXPERIMENTS,[0],[0]
"We employ the widely used convex optimization solver CVX∗ to solve the quadratic programming problem.
",V. EXPERIMENTS,[0],[0]
"• STM: STM [4] is the first method which extends SVM to the tensorial format, which employs alternating optimization scheme to update the weight tensors and outperforms kernel SVM in some tasks.",V. EXPERIMENTS,[0],[0]
• STuM:,V. EXPERIMENTS,[0],[0]
It is a kind of support tensor machine which is based on the Tucker decomposition [16].,V. EXPERIMENTS,[0],[0]
The training procedure is similar as the one in STM. •,V. EXPERIMENTS,[0],[0]
"STTM: STTM [17] assumes the weight tensor is a scalable tensor train, which enables STTM to deal with high-dimensional data classification.",V. EXPERIMENTS,[0],[0]
"STM, STuM, and STTM are all tensor-based linear classifiers.",V. EXPERIMENTS,[0],[0]
"In very small sample size problem, sometimes linear classifier are observed to achieve a better classification accuracy than nonlinear classifier [18] since a linear classifier is commonly less complex and more stable and can be better trained than nonlinear classifiers.",V. EXPERIMENTS,[0],[0]
• DuSK: DuSK is a kernelized support tensor machine using the CP decomposition [18].,V. EXPERIMENTS,[0],[0]
"Through introducing the kernel trick, it can deal with nonlinear classification tasks.",V. EXPERIMENTS,[0],[0]
• 3D CNN:,V. EXPERIMENTS,[0],[0]
CNN is one of the most powerful structure for image classification.,V. EXPERIMENTS,[0],[0]
The 3D CNN we employ here is an extension of the 2D version in [24].,V. EXPERIMENTS,[0],[0]
We replace the 2D convolutional kernels with 3D ones and keep other settings the same.,V. EXPERIMENTS,[0],[0]
"Though 3D CNN is a relatively simple CNN model, it has an advantage in dealing with small sample size problems since it can be trained better than the complicated CNN model.",V. EXPERIMENTS,[0],[0]
• TT Classifier:,V. EXPERIMENTS,[0],[0]
"As an updated tensor classification method, TT classifier [25] trains a TT as a polynomial classifier and achieves good results on tensorial image classification tasks.
",V. EXPERIMENTS,[0],[0]
"For simplicity, all of the kernel based methods, i.e., SVM, DuSK, and K-STTM, employ the Gaussian RBF kernel.",V. EXPERIMENTS,[0],[0]
"The optimal parameters, namely the performance trade-off parameter C, RBF kernel parameter σ, hidden layer size in 3D CNN, plus the corresponding tensor rank in STuM, STTM, DuSK, TT classifier and K-STTM, are determined through a grid search.",V. EXPERIMENTS,[0],[0]
The detail of the hyperparameter search schemes of all methods in all experiments are demonstrated in Appendix.,V. EXPERIMENTS,[0],[0]
"First, our proposed methods are compared with the above methods on the well-known MNIST dataset [26], which has a training set of 60k samples and a testing set of 10k samples.",A. MNIST,[0],[0]
"Each sample is a 28 × 28 grayscale image of a handwritten digit {0, . . .",A. MNIST,[0],[0]
", 9}.",A. MNIST,[0],[0]
"Although there are total 60k training samples, we care more about the small sample size problem.",A. MNIST,[0],[0]
"Thus for each class, we randomly choose 50 samples for model training and another 50 for validation.",A. MNIST,[0],[0]
All test samples in each class are used for checking the classification performance of each trained model.,A. MNIST,[0],[0]
"Since an SVM is naturally a binary classifier,
∗http://cvxr.com/cvx/
we randomly choose 10 digit pairs out of 45 to check the classification accuracy.
",A. MNIST,[0],[0]
Table I shows the classification results on different digit pairs.,A. MNIST,[0],[0]
"DuSK achieves the lowest accuracy among all the methods , which may be caused by the CP-rank searching: Finding a good CP-rank is an NP-complete problem, so DuSK may perform poorly if it fails to do so.",A. MNIST,[0],[0]
"Due to the naturally linearity of STM, STuM and STTM, they also can not achieve a good classification accuracy on real-world data.",A. MNIST,[0],[0]
"TT classifier even achieves a very poor classification performance on some digit pairs since it is naturally a polynomial classifier, whose classification power is limited.",A. MNIST,[0],[0]
We notice that the two proposed approaches K-STTM-Prod and K-STTM-Sum only achieve a slightly better accuracy than SVM and 3D CNN on some digit pairs.,A. MNIST,[0],[0]
The main reason that SVM and 3D CNN perform very well also is that MNIST is a relatively small dataset.,A. MNIST,[0],[0]
"The data dimension is 784 only, thus conventional SVM and 3D CNN do not encounter the curse of dimensionality and no overfitting occurs.",A. MNIST,[0],[0]
The advantage of tensorial methods are expected to be more apparent when the problem is truly high-dimensional.,A. MNIST,[0],[0]
"We therefore consider in the second experiment fMRI image data, whose dimensions are higher than 32k.
",A. MNIST,[0],[0]
We also investigate the influence of the TT-rank on the classification accuracy.,A. MNIST,[0],[0]
Figure 5 shows how the classification accuracy of K-STTM-Prod and K-STTM-Sum changes along with increasing TT-rank on two randomly selected digit pairs.,A. MNIST,[0],[0]
"We can observe that K-STTM with a small TT-rank can achieve a similar classification performance when it with high TT-rank, and the highest accuracies are all achieved when TTrank is around 5, which means we can select a relatively small TT-rank R to reduce the cost of kernel computation, while at the same time keep the classification performance.",A. MNIST,[0],[0]
This validates the computation complexity analysis in Section IV-E since the R and Rd in O(dI2R4 +M2IdR2d) are often small.,A. MNIST,[0],[0]
"As we mentioned in experiment V-A, tensorial method shows more apparent advantages on high-dimensional dataset.",B. fMRI datasets,[0],[0]
"Thus we consider two high-dimensional fMRI datasets, namely the StarPlus fMRI dataset† and the CMU Science 2008 fMRI dataset (CMU2008)",B. fMRI datasets,[0],[0]
[27] to evaluate the classification performance of different models.,B. fMRI datasets,[0],[0]
An fMRI image is essentially a 3-way tensor.,B. fMRI datasets,[0],[0]
"Figure 6 from [18] illustrates the tensorial structure of the fMRI image.
1) StarPlus fMRI dataset:",B. fMRI datasets,[0],[0]
"The fMRI images in StarPlus dataset are with dimensions 64 × 64 × 8 that contains 25 to 30 anatomically defined regions (called“Regions of Interest”, or ROIs).",B. fMRI datasets,[0],[0]
"To achieve a better classification accuracy, we only consider the following ROIs: ‘CALC’ ‘LIPL’ ‘LT’ ‘LTRIA’ ‘LOPER’ ‘LIPS’ ‘LDLPFC’.",B. fMRI datasets,[0],[0]
"After extracting those ROIs, we further normalize the data of each subject.",B. fMRI datasets,[0],[0]
StarPlus fMRI dataset contains the brain images of 6 human subjects.,B. fMRI datasets,[0],[0]
"The data of each human subject is partitioned into trials, and each subject has 40 effective trials.",B. fMRI datasets,[0],[0]
"Here we only use the first 4 seconds of each trial since the subject was shown one kind of
†http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-81/www/
8
TABLE",B. fMRI datasets,[0],[0]
I:,B. fMRI datasets,[0],[0]
"Classification accuracy of different methods for different MNIST digit pairs.
",B. fMRI datasets,[0],[0]
Digit pair SVM STM STuM STTM DuSK,B. fMRI datasets,[0],[0]
"3D CNN TT classiifer K-STTM-Prod K-STTM-Sum
{‘1’,‘2’} 98.15% 94.09% 97.96% 97.69% 89.16% 98.20% 73.93% 99.22% 99.27% {‘1’,‘7’} 97.73% 96.62% 97.87% 97.83% 80.95% 98.19% 96.99% 98.34% 98.20% {‘1’,‘8’} 96.49% 93.78% 95.92% 96.30% 87.63% 97.24% 84.48% 97.97% 98.06% {‘2’,‘4’} 98.36% 96.32% 97.46% 97.52% 77.26% 96.27% 93.45% 99.01% 98.61% {‘2’,‘7’} 96.41% 94.46% 95.58% 95.58% 81.26% 94.22% 94.22% 97.09% 96.95% {‘4’,‘6’} 97.16% 97.57% 97.47% 97.42% 78.66% 96.18% 93.71% 98.30% 97.74% {‘4’,‘9’} 89.50% 86.53% 90.65% 90.86% 68.46% 91.91% 59.12% 93.27% 91.77% {‘5’,‘6’} 96.00% 95.29% 95.24% 94.92% 75.78% 92.75% 88.16% 96.49% 96.76% {‘5’,‘8’} 86.92% 78.18% 91.47% 88.10% 70.69% 90.46% 63.56% 94.32% 91.59% {‘7’,‘8’} 94.46% 92.30% 95.85% 95.40% 75.97% 94.30% 94.46% 96.76% 96.16%
TABLE II:",B. fMRI datasets,[0],[0]
"Classification accuracy of different methods for different subjects in StarPlus fMRI datasets.
",B. fMRI datasets,[0],[0]
"Subject SVM STM STuM STTM DuSK 3D CNN TT classifier K-STTM-Prod K-STTM-Sum
04799 50.00%∗ 36.67% 35.83% 39.61% 47.50% 51.67% 57.50% 68.33% 66.67% 04820 50.00%∗ 43.33% 35.00% 45.83% 46.67% 44.16% 54.17% 70.00% 62.50% 04847 50.00%∗ 38.33% 17.50% 47.50% 53.33% 55.00% 61.67% 65.00% 65.00% 05675",B. fMRI datasets,[0],[0]
"50.00%∗ 37.50% 30.83% 35.00% 55.00% 47.50% 55.00% 60.00% 60.00% 05680 50.00%∗ 38.33% 39.17% 40.00% 64.17% 68.33% 60.83% 73.33% 75.00% 05710 50.00%∗ 40.00% 30.00% 43.33% 54.16% 47.50% 53.33% 59.17% 58.33% ∗ SVM classifies all test samples into one class since no good hyperparameter setting can be found by grid search.
",B. fMRI datasets,[0],[0]
Fig. 5: Classification accuracy of K-STTM-Prod and K-STTM-Sum with different TT-rank on two randomly selected digit pairs.,B. fMRI datasets,[0],[0]
"Top figure: digit pair ‘1’,‘2’; bottom figure: digit pair ‘5’,‘6’.
stimulus (sentence or picture) during the whole period.",B. fMRI datasets,[0],[0]
"The fMRI images were collected every 500 msec, thus we can utilize 8 fMRI images in each trial.",B. fMRI datasets,[0],[0]
"Overall, we have 320 fMRI images: one half of them were collected when the subject was shown a picture, the other half were collected when the subject was shown a sentence, while we randomly select 140 images for training, 60 for validation and the left for testing.
",B. fMRI datasets,[0],[0]
The classification results are listed in Table II.,B. fMRI datasets,[0],[0]
"Due to the very high-dimensional and sparse data, SVM fails to find a good hyperparameter setting thus can not do classification.",B. fMRI datasets,[0],[0]
"Since fMRI data are very complicated, those linear classifiers, namely STM, STuM and STTM, can not achieve an acceptable performance, and the classification accuracies of them are all
Fig. 6: fMRI images from [18].",B. fMRI datasets,[0],[0]
"(a) An illustration of a 3-way tensor (fMRI image), (b) Visualization of an fMRI image.
lower than 50%.",B. fMRI datasets,[0],[0]
The classification result of TT classifier is poor on several subjects.,B. fMRI datasets,[0],[0]
DuSK also performs poor on subjects ‘04799’ and ‘04820’.,B. fMRI datasets,[0],[0]
"Due to the small number of training samples and high-dimensional data size, the 3D CNN overfits and can not be well trained, while our proposed two methods still achieve the highest classification accuracy on all human subjects.
",B. fMRI datasets,[0],[0]
2) CMU2008:,B. fMRI datasets,[0],[0]
The second fMRI dataset we consider is CMU2008.,B. fMRI datasets,[0],[0]
It shows the brain activities associated with the meanings of nouns.,B. fMRI datasets,[0],[0]
"During the data collection period, the subjects were asked to view 60 different word-picture from 12 semantic categories.",B. fMRI datasets,[0],[0]
There are 5 pictures in each categories and each images is shown to the subject for 6 times.,B. fMRI datasets,[0],[0]
"Therefore, we can get 30 fMRI images for each semantic category, and each fMRI image is with dimensions 51 × 61 × 23.",B. fMRI datasets,[0],[0]
"In this experiment, we consider all the ROIs thus the classified fMRI images are relatively denser than the images we classified in the StarPlus example.",B. fMRI datasets,[0],[0]
"Considering the extremely small number of samples in each category, we therefore follow the experiment settings in [28] , which combines two similar categories into an integrated class.",B. fMRI datasets,[0],[0]
"Specifically, we combine categories
9
animal and insect as class Animals, and categories tool and furniture as class Tools.",B. fMRI datasets,[0],[0]
"By doing so, we have 60 samples in both Animals and Tools classes.",B. fMRI datasets,[0],[0]
"We separate the total 120 fMRI images as training, validation and testing sets, with 50, 20 and 50 images respectively.
",B. fMRI datasets,[0],[0]
Table III shows the binary classification results of different models.,B. fMRI datasets,[0],[0]
"We notice that SVM can perform classification on this dataset since we include all ROIs, which facilitates the hyperparameter searching procedure.",B. fMRI datasets,[0],[0]
"However, its classification accuracies on four subjects are lower than 50%.",B. fMRI datasets,[0],[0]
"The linear and polynomial model, namely STM, STuM, STTM, and TT classiifer, can only achieve an acceptable performance on a few subjects.",B. fMRI datasets,[0],[0]
"Due to the high-dimensional data size, DuSK fails to find a good CP-rank in acceptable time and can not achieve a good classification accuracy.",B. fMRI datasets,[0],[0]
3D CNN still performs poor due to the very few training samples and high-dimensional feature size.,B. fMRI datasets,[0],[0]
Our proposed two methods still achieve the best classification results on all subjects.,B. fMRI datasets,[0],[0]
"In this experiment, we use the CIFAR-10 dataset [29] to investigate the fourth claim in Section IV-B, namely, we can perform different kernel functions on different tensor modes.",C. CIFAR-10,[0],[0]
Here we demonstrate the effect on K-STTM-Prod only.,C. CIFAR-10,[0],[0]
We also randomly select ten class pairs to do binary classification.,C. CIFAR-10,[0],[0]
"Without overlap, 50 samples from the training set of each class are picked randomly for model training and validation respectively, while all the test samples of each class are used for testing.",C. CIFAR-10,[0],[0]
"Since each color image is naturally a threeway tensor (pixel-pixel-color), and the first two tensor modes are related to pixel intensity, we therefore utilize the same Gaussian RBF kernel for the first two tensor modes and try a different kernel (linear or polynomial) for the third mode.",C. CIFAR-10,[0],[0]
"The parameters c, d in the polynomial kernel k(x,y) = (xTy+c)d
were empirically set to c = 1 and d = 2.",C. CIFAR-10,[0],[0]
"The baseline case is when the Gaussian RBF kernel is applied to all tensor modes.
",C. CIFAR-10,[0],[0]
Table IV lists the classification results.,C. CIFAR-10,[0],[0]
We can observe that K-STTM-Prod still achieves the best accuracy on all class pairs.,C. CIFAR-10,[0],[0]
"And by applying a linear or polynomial kernel on the color mode, the classification accuracy of K-STTMProd outperforms the baseline case (RBF-RBF-RBF) on nine class pairs, which indicates the potential benefit of employing different kernel functions on different tensor modes when they contain different kind of information.",C. CIFAR-10,[0],[0]
"Since the data size of CIFAR-10 is also relatively small, we get a similar observation as the MNIST experiment, namely our method only achieves slightly better classification performance than SVM and 3D CNN on some class pairs.",C. CIFAR-10,[0],[0]
"Due to the constrained rank-one model setting, STM can not achieve an acceptable performance.",C. CIFAR-10,[0],[0]
"The other two linear classifiers, namely STuM and STTM still perform poor on most of the class pairs.",C. CIFAR-10,[0],[0]
The TT classifier has a similar performance as the STM in this experiment.,C. CIFAR-10,[0],[0]
This paper has proposed a tensor train (TT)-based kernel trick for the first time and devised a kernelized support tensor train machine (K-STTM).,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Assuming a low-rank TT as the prior structure of multi-dimensional data, we first define a corresponding feature mapping scheme that keeps the TT structure in the feature space.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Furthermore, two kernel function construction schemes are proposed with consideration of consistency with the TT inner product and the preservation of information, respectively.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
The feasibility of applying different kernel mappings on the tensor modes with different characteristics is also investigated.,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Experiments have demonstrated the superiority of K-STTM over conventional approaches for tensorial data in few-sample size problems.
",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"10
We further envision two future research directions based on the K-STTM framework.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Firstly, instead of constructing a kernel matrix in the K-STTM formula, we will consider building a kernel tensor.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
We believe that the kernel matrix constructed for each mode can contain different information.,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
Simply multiplying or adding this information may not be the best solution.,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Subsequently, we propose to stack this information into a 3-way kernel tensor and develop a better way to exploit information in each of the modes.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Secondly, we will embed the proposed kernel mapping trick into other kernel-based methods such as LSSVM [30], kernel PCA [31] etc., such that these methods can directly deal with tensorial data and achieve potentially better performance.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Tensor, a multi-dimensional data structure, has been exploited recently in the machine learning community.",abstractText,[0],[0]
"Traditional machine learning approaches are vectoror matrixbased, and cannot handle tensorial data directly.",abstractText,[0],[0]
"In this paper, we propose a tensor train (TT)-based kernel technique for the first time, and apply it to the conventional support vector machine (SVM) for image classification.",abstractText,[0],[0]
"Specifically, we propose a kernelized support tensor train machine that accepts tensorial input and preserves the intrinsic kernel property.",abstractText,[0],[0]
The main contributions are threefold.,abstractText,[0],[0]
"First, we propose a TT-based feature mapping procedure that maintains the TT structure in the feature space.",abstractText,[0],[0]
"Second, we demonstrate two ways to construct the TTbased kernel function while considering consistency with the TT inner product and preservation of information.",abstractText,[0],[0]
"Third, we show that it is possible to apply different kernel functions on different data modes.",abstractText,[0],[0]
"In principle, our method tensorizes the standard SVM on its input structure and kernel mapping scheme.",abstractText,[0],[0]
"Extensive experiments are performed on real-world tensor data, which demonstrates the superiority of the proposed scheme under few-sample high-dimensional inputs.",abstractText,[0],[0]
Kernelized Support Tensor Train Machines,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1400–1409, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
Directly reading documents and being able to answer questions from them is an unsolved challenge. To avoid its inherent difficulty, question answering (QA) has been directed towards using Knowledge Bases (KBs) instead, which has proven effective. Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g. Wikipedia contains much more information than Freebase. In this work we introduce a new method, Key-Value Memory Networks, that makes reading documents more viable by utilizing different encodings in the addressing and output stages of the memory read operation. To compare using KBs, information extraction or Wikipedia documents directly in a single framework we construct an analysis tool, WIKIMOVIES, a QA dataset that contains raw text alongside a preprocessed KB, in the domain of movies. Our method reduces the gap between all three settings. It also achieves state-of-the-art results on the existing WIKIQA benchmark.",text,[0],[0]
"Question answering (QA) has been a long standing research problem in natural language processing, with the first systems attempting to answer questions by directly reading documents (Voorhees and Tice, 2000).",1 Introduction,[0],[0]
"The development of large-scale Knowledge Bases (KBs) such as Freebase (Bollacker et al., 2008) helped organize information into structured forms, prompting recent progress to focus on answering questions by converting them into logical forms that
can be used to query such databases (Berant et al., 2013; Kwiatkowski et al., 2013; Fader et al., 2014).
",1 Introduction,[0],[0]
"Unfortunately, KBs have intrinsic limitations such as their inevitable incompleteness and fixed schemas that cannot support all varieties of answers.",1 Introduction,[0],[0]
"Since information extraction (IE) (Craven et al., 2000), intended to fill in missing information in KBs, is neither accurate nor reliable enough, collections of raw textual resources and documents such as Wikipedia will always contain more information.",1 Introduction,[0],[0]
"As a result, even if KBs can be satisfactory for closed-domain problems, they are unlikely to scale up to answer general questions on any topic.",1 Introduction,[0],[0]
"Starting from this observation, in this work we study the problem of answering by directly reading documents.
",1 Introduction,[0],[0]
"Retrieving answers directly from text is harder than from KBs because information is far less structured, is indirectly and ambiguously expressed, and is usually scattered across multiple documents.",1 Introduction,[0],[0]
This explains why using a satisfactory KB—typically only available in closed domains—is preferred over raw text.,1 Introduction,[0],[0]
"We postulate that before trying to provide answers that are not in KBs, document-based QA systems should first reach KB-based systems’ performance in such closed domains, where clear comparison and evaluation is possible.",1 Introduction,[0],[0]
"To this end, this paper introduces WIKIMOVIES, a new analysis tool that allows for measuring the performance of QA systems when the knowledge source is switched from a KB to unstructured documents.",1 Introduction,[0],[0]
"WIKIMOVIES contains ∼100k questions in the movie domain, and was designed to be answerable by using either a perfect KB (based on OMDb1), Wikipedia pages or an imper-
1http://www.omdbapi.com
1400
fect KB obtained through running an engineered IE pipeline on those pages.
",1 Introduction,[0],[0]
"To bridge the gap between using a KB and reading documents directly, we still lack appropriate machine learning algorithms.",1 Introduction,[0],[0]
"In this work we propose the Key-Value Memory Network (KV-MemNN), a new neural network architecture that generalizes the original Memory Network (Sukhbaatar et al., 2015) and can work with either knowledge source.",1 Introduction,[0],[0]
The KV-MemNN performs QA by first storing facts in a key-value structured memory before reasoning on them in order to predict an answer.,1 Introduction,[0],[0]
"The memory is designed so that the model learns to use keys to address relevant memories with respect to the question, whose corresponding values are subsequently returned.",1 Introduction,[0],[0]
"This structure allows the model to encode prior knowledge for the considered task and to leverage possibly complex transforms between keys and values, while still being trained using standard backpropagation via stochastic gradient descent.
",1 Introduction,[0],[0]
"Our experiments on WIKIMOVIES indicate that, thanks to its key-value memory, the KV-MemNN consistently outperforms the original Memory Network, and reduces the gap between answering from a human-annotated KB, from an automatically extracted KB or from directly reading Wikipedia.",1 Introduction,[0],[0]
"We confirm our findings on WIKIQA (Yang et al., 2015), another Wikipedia-based QA benchmark where no KB is available, where we demonstrate that KV-MemNN can reach state-of-the-art results— surpassing the most recent attention-based neural network models.",1 Introduction,[0],[0]
"Early QA systems were based on information retrieval and were designed to return snippets of text containing an answer (Voorhees and Tice, 2000; Banko et al., 2002), with limitations in terms of question complexity and response coverage.",2 Related Work,[0],[0]
"The creation of large-scale KBs (Auer et al., 2007; Bollacker et al., 2008) have led to the development of a new class of QA methods based on semantic parsing (Berant et al., 2013; Kwiatkowski et al., 2013; Fader et al., 2014; Yih et al., 2015) that can return precise answers to complicated compositional questions.",2 Related Work,[0],[0]
"Due to the sparsity of KB data, however, the main challenge shifts from finding answers to developing efficient information extraction methods to populate KBs auto-
matically (Craven et al., 2000; Carlson et al., 2010)— not an easy problem.
",2 Related Work,[0],[0]
"For this reason, recent initiatives are returning to the original setting of directly answering from text using datasets like TRECQA (Wang et al., 2007), which is based on classical TREC resources (Voorhees et al., 1999), and WIKIQA (Yang et al., 2015), which is extracted from Wikipedia.",2 Related Work,[0],[0]
"Both benchmarks are organized around the task of answer sentence selection, where a system must identify the sentence containing the correct answer in a collection of documents, but need not return the actual answer as a KB-based system would do.",2 Related Work,[0],[0]
"Unfortunately, these datasets are very small (hundreds of examples) and, because of their answer selection setting, do not offer the option to directly compare answering from a KB against answering from pure text.",2 Related Work,[0],[0]
"Using similar resources as the dialog dataset of Dodge et al. (2016), our new benchmark WIKIMOVIES addresses both deficiencies by providing a substantial corpus of questionanswer pairs that can be answered by either using a KB or a corresponding set of documents.
",2 Related Work,[0],[0]
"Even though standard pipeline QA systems like AskMR (Banko et al., 2002) have been recently revisited (Tsai et al., 2015), the best published results on TRECQA and WIKIQA have been obtained by either convolutional neural networks (Santos et al., 2016; Yin and Schütze, 2015; Wang et al., 2016) or recurrent neural networks (Miao et al., 2015)— both usually with attention mechanisms inspired by (Bahdanau et al., 2015).",2 Related Work,[0],[0]
"In this work, we introduce KV-MemNNs, a Memory Network model that operates a symbolic memory structured as (key, value) pairs.",2 Related Work,[0],[0]
Such structured memory is not employed in any existing attention-based neural network architecture for QA.,2 Related Work,[0],[0]
"As we will show, it gives the model greater flexibility for encoding knowledge sources and helps shrink the gap between directly reading documents and answering from a KB.",2 Related Work,[0],[0]
"The Key-Value Memory Network model is based on the Memory Network (MemNNs) model (Weston et al., 2015; Sukhbaatar et al., 2015) which has proven useful for a variety of document reading and question answering tasks: for reading children’s books and answering questions about them (Hill et al., 2016), for complex reasoning over sim-
ulated stories (Weston et al., 2016) and for utilizing KBs to answer questions (Bordes et al., 2015).
",3 Key-Value Memory Networks,[0],[0]
Key-value paired memories are a generalization of the way context (e.g. knowledge bases or documents to be read) are stored in memory.,3 Key-Value Memory Networks,[0],[0]
The lookup (addressing) stage is based on the key memory while the reading stage (giving the returned result) uses the value memory.,3 Key-Value Memory Networks,[0],[0]
This gives both (i) greater flexibility for the practitioner to encode prior knowledge about their task; and (ii) more effective power in the model via nontrivial transforms between key and value.,3 Key-Value Memory Networks,[0],[0]
"The key should be designed with features to help match it to the question, while the value should be designed with features to help match it to the response (answer).",3 Key-Value Memory Networks,[0],[0]
An important property of the model is that the entire model can be trained with key-value transforms while still using standard backpropagation via stochastic gradient descent.,3 Key-Value Memory Networks,[0],[0]
Our model is based on the end-to-end Memory Network architecture of Sukhbaatar et al. (2015).,3.1 Model Description,[0],[0]
"A high-level view of both models is as follows: one defines a memory, which is a possibly very large array of slots which can encode both long-term and short-term context.",3.1 Model Description,[0],[0]
"At test time one is given a query (e.g. the question in QA tasks), which is used to iteratively address and read from the memory (these iterations are also referred to as “hops”) looking for relevant information to answer the question.",3.1 Model Description,[0],[0]
"At each step, the collected information from the memory is cumulatively added to the original query to build context for the next round.",3.1 Model Description,[0],[0]
"At the last iteration, the final
retrieved context and the most recent query are combined as features to predict a response from a list of candidates.
",3.1 Model Description,[0],[0]
"Figure 1 illustrates the KV-MemNN model architecture.
",3.1 Model Description,[0],[0]
"In KV-MemNNs we define the memory slots as pairs of vectors (k1, v1) . . .",3.1 Model Description,[0],[0]
", (kM , vM ) and denote the question x.",3.1 Model Description,[0],[0]
"The addressing and reading of the memory involves three steps:
• Key Hashing: the question can be used to preselect a small subset of the possibly large array.",3.1 Model Description,[0],[0]
"This is done using an inverted index that finds a subset (kh1 , vh1), . . .",3.1 Model Description,[0],[0]
", (khN , vhN ) of memories of size N where the key shares at least one word with the question with frequency < F = 1000 (to ignore stop words), following Dodge et al. (2016).",3.1 Model Description,[0],[0]
"More sophisticated retrieval schemes could be used here, see e.g. Manning et al. (2008),
• Key Addressing: during addressing, each candidate memory is assigned a relevance probability by comparing the question to each key:
phi = Softmax(AΦX(x) ·AΦK(khi))
where Φ· are feature maps of dimension D, A is a d×D matrix and Softmax(zi) = ezi/ ∑ j e
zj .",3.1 Model Description,[0],[0]
"We discuss choices of feature map in Sec. 3.2.
",3.1 Model Description,[0],[0]
"• Value Reading: in the final reading step, the values of the memories are read by taking their weighted sum using the addressing probabilities,
and the vector o is returned:
o = ∑
i
phiAΦV (vhi) .
",3.1 Model Description,[0],[0]
The memory access process is conducted by the “controller” neural network using q = AΦX(x) as the query.,3.1 Model Description,[0],[0]
"After receiving the result o, the query is updated with q2 = R1(q + o) where R is a d × d matrix.",3.1 Model Description,[0],[0]
"The memory access is then repeated (specifically, only the addressing and reading steps, but not the hashing), using a different matrix",3.1 Model Description,[0],[0]
"Rj on each hop, j. The key addressing equation is transformed accordingly to use the updated query:
phi = Softmax(q > j+1AΦK(khi)) .
",3.1 Model Description,[0],[0]
The motivation for this is that new evidence can be combined into the query to focus on and retrieve more pertinent information in subsequent accesses.,3.1 Model Description,[0],[0]
"Finally, after a fixed number H hops, the resulting state of the controller is used to compute a final prediction over the possible outputs:
â = argmaxi=1,...,CSoftmax(q > H+1BΦY (yi))
where yi are the possible candidate outputs, e.g. all the entities in the KB, or all possible candidate answer sentences in the case of a dataset like WIKIQA (see Sec. 5.2).",3.1 Model Description,[0],[0]
The d×D matrix B can also be constrained to be identical to A.,3.1 Model Description,[0],[0]
"The whole network is trained end-to-end, and the model learns to perform the iterative accesses to output the desired target a by minimizing a standard cross-entropy loss between â and the correct answer a. Backpropagation and stochastic gradient descent are thus used to learn the matrices A,B and R1, . . .",3.1 Model Description,[0],[0]
", RH .
To obtain the standard End-To-End Memory Network of Sukhbaatar et al. (2015) one can simply set the key and value to be the same for all memories.",3.1 Model Description,[0],[0]
"Hashing was not used in that paper, but is important for computational efficiency for large memory sizes, as already shown in Dodge et al. (2016).",3.1 Model Description,[0],[0]
We will now go on to describe specific applications of key-value memories for the task of reading KBs or documents.,3.1 Model Description,[0],[0]
There are a variety of ways to employ key-value memories that can have important effects on overall performance.,3.2 Key-Value Memories,[0],[0]
"The ability to encode prior knowledge in
this way is an important component of KV-MemNNs, and we are free to define ΦX ,ΦY ,ΦK and ΦV for the query, answer, keys and values respectively.",3.2 Key-Value Memories,[0],[0]
"We now describe several possible variants of ΦK and ΦV that we tried in our experiments, for simplicity we kept ΦX and ΦY fixed as bag-of-words representations.
",3.2 Key-Value Memories,[0],[0]
KB Triple Knowledge base entries have a structure of triple “subject relation object” (see Table 1 for examples).,3.2 Key-Value Memories,[0],[0]
"The representation we consider is simple: the key is composed of the left-hand side entity (subject) and the relation, and the value is the right-hand side entity (object).",3.2 Key-Value Memories,[0],[0]
We double the KB and consider the reversed relation as well (e.g. we now have two triples “Blade Runner directed_by Ridley Scott” and “Ridley Scott !,3.2 Key-Value Memories,[0],[0]
directed_by Blade Runner” where !,3.2 Key-Value Memories,[0],[0]
directed_by is a different entry in the dictionary than directed_by).,3.2 Key-Value Memories,[0],[0]
Having the entry both ways round is important for answering different kinds of questions (“Who directed Blade Runner?” vs. “What did Ridley Scott direct?”).,3.2 Key-Value Memories,[0],[0]
"For a standard MemNN that does not have key-value pairs the whole triple has to be encoded into the same memory slot.
",3.2 Key-Value Memories,[0],[0]
Sentence Level,3.2 Key-Value Memories,[0],[0]
"For representing a document, one can split it up into sentences, with each memory slot encoding one sentence.",3.2 Key-Value Memories,[0],[0]
Both the key and the value encode the entire sentence as a bag-of-words.,3.2 Key-Value Memories,[0],[0]
"As the key and value are the same in this case, this is identical to a standard MemNN and this approach has been used in several papers (Weston et al., 2016; Dodge et al., 2016).
",3.2 Key-Value Memories,[0],[0]
Window Level Documents are split up into windows of W words; in our tasks we only include windows where the center word is an entity.,3.2 Key-Value Memories,[0],[0]
Windows are represented using bag-of-words.,3.2 Key-Value Memories,[0],[0]
"Window representations for MemNNs have been shown to work well previously (Hill et al., 2016).",3.2 Key-Value Memories,[0],[0]
"However, in Key-Value MemNNs we encode the key as the entire window, and the value as only the center word, which is not possible in the MemNN architecture.",3.2 Key-Value Memories,[0],[0]
"This makes sense because the entire window is more likely to be pertinent as a match for the question (as the key), whereas the entity at the center is more pertinent as a match for the answer (as the value).",3.2 Key-Value Memories,[0],[0]
"We will compare these approaches in our experiments.
",3.2 Key-Value Memories,[0],[0]
"Window + Center Encoding Instead of representing the window as a pure bag-of-words, thus mixing
the window center with the rest of the window, we can also encode them with different features.",3.2 Key-Value Memories,[0],[0]
"Here, we double the size, D, of the dictionary and encode the center of the window and the value using the second dictionary.",3.2 Key-Value Memories,[0],[0]
"This should help the model pick out the relevance of the window center (more related to the answer) as compared to the words either side of it (more related to the question).
",3.2 Key-Value Memories,[0],[0]
Window + Title,3.2 Key-Value Memories,[0],[0]
The title of a document is commonly the answer to a question that relates to the text it contains.,3.2 Key-Value Memories,[0],[0]
For example “What did Harrison Ford star in?” can be (partially) answered by the Wikipedia document with the title “Blade Runner”.,3.2 Key-Value Memories,[0],[0]
"For this reason, we also consider a representation where the key is the word window as before, but the value is the document title.",3.2 Key-Value Memories,[0],[0]
"We also keep all the standard (window, center) key-value pairs from the window-level representation as well, thus doubling the number of memory slots in comparison.",3.2 Key-Value Memories,[0],[0]
"To differentiate the two keys with different values we add an extra feature “_window_” or “_title_” to the key, depending on the value.",3.2 Key-Value Memories,[0],[0]
The “_title_” version also includes the actual movie title in the key.,3.2 Key-Value Memories,[0],[0]
This representation can be combined with center encoding.,3.2 Key-Value Memories,[0],[0]
Note that this representation is inherently specific to datasets in which there is an apparent or meaningful title for each document.,3.2 Key-Value Memories,[0],[0]
The WIKIMOVIES benchmark consists of questionanswer pairs in the domain of movies.,4 The WikiMovies Benchmark,[0],[0]
It was built with the following goals in mind: (i) machine learning techniques should have ample training examples for learning; and (ii) one can analyze easily the performance of different representations of knowledge and break down the results by question type.,4 The WikiMovies Benchmark,[0],[0]
The dataset can be downloaded from http://fb.ai/babi.,4 The WikiMovies Benchmark,[0],[0]
We construct three forms of knowledge representation: (i),4.1 Knowledge Representations,[0],[0]
Doc: raw Wikipedia documents consisting of the pages of the movies mentioned; (ii) KB: a classical graph-based KB consisting of entities and relations created from the Open Movie Database (OMDb) and MovieLens; and (iii) IE: information extraction performed on the Wikipedia pages to build a KB in a similar form as (ii).,4.1 Knowledge Representations,[0],[0]
"We take care to construct
QA pairs such that they are all potentially answerable from either the KB from (ii) or the original Wikipedia documents from (i) to eliminate data sparsity issues.",4.1 Knowledge Representations,[0],[0]
"However, it should be noted that the advantage of working from raw documents in real applications is that data sparsity is less of a concern than for a KB, while on the other hand the KB has the information already parsed in a form amenable to manipulation by machines.",4.1 Knowledge Representations,[0],[0]
"This dataset can help analyze what methods we need to close the gap between all three settings, and in particular what are the best methods for reading documents when a KB is not available.",4.1 Knowledge Representations,[0],[0]
"A sample of the dataset is shown in Table 1.
",4.1 Knowledge Representations,[0],[0]
Doc We selected a set of Wikipedia articles about movies by identifying a set of movies from OMDb2 that had an associated article by title match.,4.1 Knowledge Representations,[0],[0]
We keep the title and the first section (before the contents box) for each article.,4.1 Knowledge Representations,[0],[0]
"This gives∼17k documents (movies) which comprise the set of documents our models will read from in order to answer questions.
2 http://beforethecode.com/projects/omdb/download.aspx
KB",4.1 Knowledge Representations,[0],[0]
Our set of movies were also matched to the MovieLens dataset3.,4.1 Knowledge Representations,[0],[0]
"We built a KB using OMDb and MovieLens metadata with entries for each movie and nine different relation types: director, writer, actor, release year, language, genre, tags, IMDb rating and IMDb votes, with ∼10k related actors, ∼6k directors and∼43k entities in total.",4.1 Knowledge Representations,[0],[0]
The KB is stored as triples; see Table 1 for examples.,4.1 Knowledge Representations,[0],[0]
"IMDb ratings and votes are originally real-valued but are binned and converted to text (“unheard of”, “unknown”, “well known”, “highly watched”, “famous”).",4.1 Knowledge Representations,[0],[0]
"We finally only retain KB triples where the entities also appear in the Wikipedia articles4 to try to guarantee that all QA pairs will be equally answerable by either the KB or Wikipedia document sources.
",4.1 Knowledge Representations,[0],[0]
IE,4.1 Knowledge Representations,[0],[0]
"As an alternative to directly reading documents, we explore leveraging information extraction techniques to transform documents into a KB format.",4.1 Knowledge Representations,[0],[0]
An IE-KB representation has attractive properties such as more precise and compact expressions of facts and logical key-value pairings based on subjectverb-object groupings.,4.1 Knowledge Representations,[0],[0]
This can come at the cost of lower recall due to malformed or completely missing triplets.,4.1 Knowledge Representations,[0],[0]
For IE we use standard open-source software followed by some task-specific engineering to improve the results.,4.1 Knowledge Representations,[0],[0]
"We first employ coreference resolution via the Stanford NLP Toolkit (Manning et al., 2014) to reduce ambiguity by replacing pronominal (“he”, “it”) and nominal (“the film”) references with their representative entities.",4.1 Knowledge Representations,[0],[0]
"Next we use the SENNA semantic role labeling tool (Collobert et al., 2011) to uncover the grammatical structure of each sentence and pair verbs with their arguments.",4.1 Knowledge Representations,[0],[0]
"Each triplet is cleaned of words that are not recognized entities, and lemmatization is done to collapse different inflections of important task-specific verbs to one form (e.g. stars, starring, star→ starred).",4.1 Knowledge Representations,[0],[0]
"Finally, we append the movie title to each triple similar to the “Window + Title” representation of Sec. 3.2, which improved results.",4.1 Knowledge Representations,[0],[0]
"Within the dataset’s more than 100,000 questionanswer pairs, we distinguish 13 classes of question
3 http://grouplens.org/datasets/movielens/
4The dataset also includes the slightly larger version without this constraint.
",4.2 Question-Answer Pairs,[0],[0]
corresponding to different kinds of edges in our KB.,4.2 Question-Answer Pairs,[0],[0]
"They range in scope from specific—such as actor to movie: “What movies did Harrison Ford star in?” and movie to actors: “Who starred in Blade Runner?”—to more general, such as tag to movie: “Which films can be described by dystopian?”; see Table 4 for the full list.",4.2 Question-Answer Pairs,[0],[0]
"For some question there can be multiple correct answers.
",4.2 Question-Answer Pairs,[0],[0]
"Using SimpleQuestions (Bordes et al., 2015), an existing open-domain question answering dataset based on Freebase, we identified the subset of questions posed by human annotators that covered our question types.",4.2 Question-Answer Pairs,[0],[0]
We created our question set by substituting the entities in those questions with entities from all of our KB triples.,4.2 Question-Answer Pairs,[0],[0]
"For example, if the original question written by an annotator was “What movies did Harrison Ford star in?”, we created a pattern “What movies did [@actor] star in?”, which we substitute for any other actors in our set, and repeat this for all annotations.",4.2 Question-Answer Pairs,[0],[0]
"We split the questions into disjoint training, development and test sets with ∼96k, 10k and 10k examples, respectively.",4.2 Question-Answer Pairs,[0],[0]
The same question (even worded differently) cannot appear in both train and test sets.,4.2 Question-Answer Pairs,[0],[0]
"Note that this is much larger than most existing datasets; for example, the WIKIQA dataset (Yang et al., 2015) for which we also conduct experiments in Sec.",4.2 Question-Answer Pairs,[0],[0]
5.2 has only ∼1000 training pairs.,4.2 Question-Answer Pairs,[0],[0]
This section describes our experiments on WIKIMOVIES and WIKIQA.,5 Experiments,[0],[0]
We conducted experiments on the WIKIMOVIES dataset described in Sec. 4.,5.1 WikiMovies,[0],[0]
"Our main goal is to compare the performance of KB, IE and Wikipedia (Doc) sources when trying varying learning methods.",5.1 WikiMovies,[0],[0]
"We compare four approaches: (i) the QA system of Bordes et al. (2014) that performs well on existing datasets WebQuestions (Berant et al., 2013) and SimpleQuestions (Bordes et al., 2015) that use KBs only; (ii) supervised embeddings that do not make use of a KB at all but learn question-to-answer embeddings directly and hence act as a sanity check (Dodge et al., 2016); (iii) Memory Networks; and (iv) Key-Value Memory Networks.",5.1 WikiMovies,[0],[0]
"Performance is reported using the accuracy of the top hit (single answer) over all possible answers (all entities), i.e. the hits@1 metric measured in percent.",5.1 WikiMovies,[0],[0]
"In all cases hyperparameters are optimized on the development set, including the memory representations of Sec. 3.2 for MemNNs and KV-MemNNs.",5.1 WikiMovies,[0],[0]
"As MemNNs do not support key-value pairs, we concatenate key and value together when they differ instead.
",5.1 WikiMovies,[0],[0]
The main results are given in Table 2.,5.1 WikiMovies,[0],[0]
"The QA system of Bordes et al. (2014) outperforms Supervised Embeddings and Memory Networks for KB and IE-based KB representations, but is designed to work with a KB, not with documents (hence the N/A in that column).",5.1 WikiMovies,[0],[0]
"However, Key-Value Memory Networks outperform all other methods on all three data source types.",5.1 WikiMovies,[0],[0]
"Reading from Wikipedia documents directly (Doc) outperforms an IE-based KB (IE), which is an encouraging result towards automated machine reading though a gap to a humanannotated KB still remains (93.9 vs. 76.2).",5.1 WikiMovies,[0],[0]
The best memory representation for directly reading documents uses “Window-level + Center Encoding + Title” (W = 7 and H = 2); see Table 3 for a comparison of results for different representation types.,5.1 WikiMovies,[0],[0]
"Both center encoding and title features help the windowlevel representation, while sentence-level is inferior.
",5.1 WikiMovies,[0],[0]
QA Breakdown A breakdown by question type comparing the different data sources for KVMemNNs is given in Table 4.,5.1 WikiMovies,[0],[0]
"IE loses out especially
to Doc (and KB) on Writer, Director and Actor to Movie, perhaps because coreference is difficult in these cases – although it has other losses elsewhere too.",5.1 WikiMovies,[0],[0]
"Note that only 56% of subject-object pairs in IE match the triples in the original KB, so losses are expected.",5.1 WikiMovies,[0],[0]
"Doc loses out to KB particularly on Tag to Movie, Movie to Tags, Movie to Writer and Movie to Actors.",5.1 WikiMovies,[0],[0]
Tag questions are hard because they can reference more or less any word in the entire Wikipedia document; see Table 1.,5.1 WikiMovies,[0],[0]
"Movie to Writer/Actor are hard because there is likely only one or a few references to the answer across all documents, whereas for Writer/Actor to Movie there are more possible answers to find.
",5.1 WikiMovies,[0],[0]
"KB vs. Synthetic Document Analysis To further understand the difference between using a KB versus reading documents directly, we conducted an experiment where we constructed synthetic documents using the KB.",5.1 WikiMovies,[0],[0]
"For a given movie, we use a simple grammar to construct a synthetic “Wikipedia” doc-
ument based on the KB triples: for each relation type we have a set of template phrases (100 in total) used to generate the fact, e.g. “Blade Runner came out in 1982” for the entry BLADE RUNNER RELEASE_YEAR 1982.",5.1 WikiMovies,[0],[0]
"We can then parameterize the complexity of our synthetic documents: (i) using one template, or all of them; (ii) using conjunctions to combine facts into single sentences or not; and (iii) using coreference between sentences where we replace the movie name with “it”.5 The purpose of this experiment is to find which aspects are responsible for the gap in performance to a KB.",5.1 WikiMovies,[0],[0]
The results are given in Table 5.,5.1 WikiMovies,[0],[0]
"They indicate that some of the loss (93.9% for KB to 82.9% for One Template Sentence) in performance is due directly to representing in sentence form, making the subject, relation and object harder to extract.",5.1 WikiMovies,[0],[0]
Moving to a larger number of templates does not deteriorate performance much (80%).,5.1 WikiMovies,[0],[0]
The remaining performance drop seems to be split roughly equally between conjunctions (74%) and coreference (76%).,5.1 WikiMovies,[0],[0]
The hardest synthetic dataset combines these (All Templates + Conj.,5.1 WikiMovies,[0],[0]
+ Coref.),5.1 WikiMovies,[0],[0]
and is actually harder than using the real Wikipedia documents (72.5% vs. 76.2%).,5.1 WikiMovies,[0],[0]
"This is possibly because the amount of conjunctions and coreferences we make are artificially too high (50% and 80% of the time, respectively).",5.1 WikiMovies,[0],[0]
"WIKIQA (Yang et al., 2015) is an existing dataset for answer sentence selection using Wikipedia as the knowledge source.",5.2 WikiQA,[0],[0]
"The task is, given a question, to select the sentence coming from a Wikipedia document that best answers the question, where performance is measured using mean average preci-
5This data is also part of the WIKIMOVIES benchmark.
",5.2 WikiQA,[0],[0]
sion (MAP) and mean reciprocal rank (MRR) of the ranked set of answers.,5.2 WikiQA,[0],[0]
"The dataset uses a pre-built information retrieval step and hence provides a fixed set of candidate sentences per question, so systems do not have to consider ranking all of Wikipedia.",5.2 WikiQA,[0],[0]
"In contrast to WIKIMOVIES, the training set size is small (∼1000 examples) while the topic is much more broad (all of Wikipedia, rather than just movies) and the questions can only be answered by reading the documents, so no comparison to the use of KBs can be performed.",5.2 WikiQA,[0],[0]
"However, a wide range of methods have already been tried on WIKIQA, thus providing a useful benchmark to test if the same results found on WIKIMOVIES carry across to WIKIQA, in particular the performance of Key-Value Memory Networks.
",5.2 WikiQA,[0],[0]
"Due to the size of the training set, following many other works (Yang et al., 2015; Santos et al., 2016; Miao et al., 2015) we pre-trained the word vectors (matrices A and B which are constrained to be identical) before training KV-MemNNs.",5.2 WikiQA,[0],[0]
"We employed Supervised Embeddings (Dodge et al., 2016) for that goal, training on all of Wikipedia while treating the input as a random sentence and the target as the subsequent sentence.",5.2 WikiQA,[0],[0]
"We then trained KV-MemNNs with dropout regularization: we sample words from the question, memory representations and the answers, choosing the dropout rate using the development set.",5.2 WikiQA,[0],[0]
"Finally, again following other successful methods (Yin and Schütze, 2015), we combine our approach with exact matching word features between question and answers.",5.2 WikiQA,[0],[0]
Key hashing was not used as candidates were already pre-selected.,5.2 WikiQA,[0],[0]
"To represent the memories, we used the Window-Level representation (the best choice on the dev set was W = 7) as the key and the whole sentence as the value, as the value should match the answer which in this case is a sentence.",5.2 WikiQA,[0],[0]
"Additionally, in the representation all numbers in the text and the phrase “how many” in the question were replaced with the feature “_number_”.",5.2 WikiQA,[0],[0]
"The best choice of hops was also H = 2 for KV-MemNNs.
",5.2 WikiQA,[0],[0]
The results are given in Table 6.,5.2 WikiQA,[0],[0]
"Key-Value Memory Networks outperform a large set of other methods, although the results of the L.D.C. method of (Wang et al., 2016) are very similar.",5.2 WikiQA,[0],[0]
"Memory Networks, which cannot easily pair windows to sentences, perform much worse, highlighting the importance of key-value memories.",5.2 WikiQA,[0],[0]
"We studied the problem of directly reading documents in order to answer questions, concentrating our analysis on the gap between such direct methods and using human-annotated or automatically constructed KBs.",6 Conclusion,[0],[0]
"We presented a new model, Key-Value Memory Networks, which helps bridge this gap, outperforming several other methods across two datasets, WIKIMOVIES and WIKIQA.",6 Conclusion,[0],[0]
"However, some gap in performance still remains.",6 Conclusion,[0],[0]
WIKIMOVIES serves as an analysis tool to shed some light on the causes.,6 Conclusion,[0],[0]
"Future work should try to close this gap further.
",6 Conclusion,[0],[0]
Key-Value Memory Networks are versatile models for reading documents or KBs and answering questions about them—allowing to encode prior knowledge about the task at hand in the key and value memories.,6 Conclusion,[0],[0]
"These models could be applied to storing and reading memories for other tasks as well, and future work should try them in other domains, such as in a full dialog setting.",6 Conclusion,[0],[0]
Directly reading documents and being able to answer questions from them is an unsolved challenge.,abstractText,[0],[0]
"To avoid its inherent difficulty, question answering (QA) has been directed towards using Knowledge Bases (KBs) instead, which has proven effective.",abstractText,[0],[0]
"Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g. Wikipedia contains much more information than Freebase.",abstractText,[0],[0]
"In this work we introduce a new method, Key-Value Memory Networks, that makes reading documents more viable by utilizing different encodings in the addressing and output stages of the memory read operation.",abstractText,[0],[0]
"To compare using KBs, information extraction or Wikipedia documents directly in a single framework we construct an analysis tool, WIKIMOVIES, a QA dataset that contains raw text alongside a preprocessed KB, in the domain of movies.",abstractText,[0],[0]
Our method reduces the gap between all three settings.,abstractText,[0],[0]
It also achieves state-of-the-art results on the existing WIKIQA benchmark.,abstractText,[0],[0]
Key-Value Memory Networks for Directly Reading Documents,title,[0],[0]
"Proceedings of the SIGDIAL 2017 Conference, pages 37–49, Saarbrücken, Germany, 15-17 August 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"With the success of new speech-based humancomputer interfaces, there is a great need for effective task-oriented dialogue agents that can handle everyday tasks such as scheduling events and booking hotels.",1 Introduction,[0],[0]
Current commercial dialogue agents are often brittle pattern-matching systems which are unable to maintain the kind of flexible conversations that people desire.,1 Introduction,[0],[0]
"Neural dialogue agents present one of the most promising avenues for leveraging dialogue corpora to build statistical models directly from data by using powerful distributed representations (Bordes and Weston, 2016; Wen et al., 2016b; Dhingra et al., 2016).
",1 Introduction,[0],[0]
"While this work has been somewhat successful, these task-oriented neural dialogue models suffer from a number of problems: 1) They struggle to effectively reason over and incorporate knowledge base information while still preserving their endto-end trainability and 2)",1 Introduction,[0],[0]
"They often require explicitly modelling user dialogues with belief trackers and dialogue state information, which necessitates additional data annotation and also breaks differentiability.
",1 Introduction,[0],[0]
"To address some of the modelling issues in previous neural dialogue agents, we introduce a new architecture called the Key-Value Retrieval Network.",1 Introduction,[0],[0]
"This model augments existing recurrent network architectures with an attention-based key-value retrieval mechanism over the entries of a knowledge base, which is inspired by recent work on key-value memory networks (Miller et al., 2016).",1 Introduction,[0],[0]
"By doing so, it is able to learn how to extract useful information from a knowledge base directly from data in an end-to-end fashion, with-
37
out the need for explicit training of belief or intent trackers as is done in traditional task-oriented dialogue systems.",1 Introduction,[0],[0]
"The architecture has no dependence on the specifics of the data domain, learning how to appropriately incorporate world knowledge into its dialogue utterances via attention over the key-value entries of the underlying knowledge base.
",1 Introduction,[0],[0]
"In addition, we introduce and make publicly available a new corpus of 3,031 dialogues spanning three different domain types in the incar personal assistant space: calendar scheduling, weather information retrieval, and point-ofinterest navigation.",1 Introduction,[0],[0]
The dialogues are grounded through knowledge bases.,1 Introduction,[0],[0]
This makes them ideal for building dialogue architectures that seamlessly reason over world knowledge.,1 Introduction,[0],[0]
"The multi-domain nature of the dialogues in the corpus also makes this dataset an apt test bed for generalizability of modelling architectures.1
The main contributions of our work are therefore two-fold: 1) We introduce the Key-Value Retrieval Network, a highly performant neural taskoriented dialogue agent that is able to smoothly incorporate information from underlying knowledge bases through a novel key-value retrieval mechanism.",1 Introduction,[0],[0]
"Unlike other dialogue agents which only rely on prior dialogue history for generation (Kannan et al., 2016; Eric and Manning, 2017), our architecture is able to access and use database-style information, while still retaining the text generation advantages of recent neural models.",1 Introduction,[0],[0]
"By doing so, our model outperforms a competitive rulebased system and other baseline neural models on a number of automatic metrics as well as human evaluation.",1 Introduction,[0],[0]
2),1 Introduction,[0],[0]
We release a new publicly-available dialogue corpus across three distinct domains in the in-car personal assistant space that we hope will help further work on task-oriented dialogue agents.,1 Introduction,[0],[0]
"While recent neural dialogue models have explicitly modelled dialogue state through belief and user intent trackers (Wen et al., 2016b; Dhingra et al., 2016; Henderson et al., 2014b), we choose instead to rely on learned neural representations for implicit modelling of dialogue state, forming
1The data is available for download at https://nlp.stanford.edu/blog/a-new-multi-turn-multidomain-task-oriented-dialogue-dataset/
a truly end-to-end trainable system.",2 Key-Value Retrieval Networks,[0],[0]
Our model starts with an encoder-decoder sequence architecture and is further augmented with an attentionbased retrieval mechanism that effectively reasons over a key-value representation of the underlying knowledge base.,2 Key-Value Retrieval Networks,[0],[0]
We describe each component of our model in the subsequent sections.,2 Key-Value Retrieval Networks,[0],[0]
"Given a dialogue between a user (u) and a system (s), we represent the dialogue utterances as {(u1, s1), (u2, s2), . . .",2.1 Encoder,[0],[0]
", (uk, sk)} where k denotes the number of turns in the dialogue.",2.1 Encoder,[0],[0]
"At the ith turn of the dialogue, we encode the aggregated dialogue context composed of the tokens of (u1, s1, . . .",2.1 Encoder,[0],[0]
", si−1, ui).",2.1 Encoder,[0],[0]
"Letting x1, . . .",2.1 Encoder,[0],[0]
", xm denote these tokens, we first embed these tokens using a trained embedding function φemb that maps each token to a fixed-dimensional vector.",2.1 Encoder,[0],[0]
"These mappings are fed into the encoder to produce contextsensitive hidden representations h1, . . .",2.1 Encoder,[0],[0]
", hm, by repeatedly applying the recurrence:
hi = LSTM(φemb(xi), hi−1) (1)
where the recurrence uses a long-short-term memory unit, as described by (Hochreiter and Schmidhuber, 1997).",2.1 Encoder,[0],[0]
The vanilla sequence-to-sequence decoder predicts the tokens of the ith system response si by first computing decoder hidden states via the recurrent unit.,2.2 Decoder,[0],[0]
"We denote h̃1, . . .",2.2 Decoder,[0],[0]
", h̃n as the hidden states of the decoder and y1, . . .",2.2 Decoder,[0],[0]
", yn as the output tokens.",2.2 Decoder,[0],[0]
"We extend this decoder with an attentionbased model (Bahdanau et al., 2015; Luong et al., 2015a), where, at every time step t of the decoding, an attention score ati is computed for each hidden state hi of the encoder, using the attention mechanism of (Vinyals et al., 2015).",2.2 Decoder,[0],[0]
"Formally this attention can be described by the following equations:
uti = w T tanh(W2 tanh(W1[hi, h̃t])))",2.2 Decoder,[0],[0]
"(2) ati = Softmax(u t i) (3)
h̃′t = m∑
i=1
atihi (4)
",2.2 Decoder,[0],[0]
"ot = U [h̃t, h̃′t] (5) yt = Softmax(ot) (6)
where U , W1, W2, and w are trainable parameters of the model and ot represents the logits over the tokens of the output vocabulary V .",2.2 Decoder,[0],[0]
"In (2) above, the attention logit on hi is computed via a twolayer MLP function with a tanh nonlinearity at the intermediate layers.",2.2 Decoder,[0],[0]
"During training, the next token yt is predicted so as to maximize the loglikelihood of the correct output sequence given the input sequence.",2.2 Decoder,[0],[0]
"Recently, some neural task-oriented dialogue agents that query underlying knowledge bases (KBs) and extract relevant entities either do the following: 1) create and execute well-formatted API calls to the KB, operations which require intermediate supervision in the form of training slot trackers and which break differentiability (Wen et al., 2016b), or 2) softly attend to the KB and combine this probability distribution with belief trackers as state input for a reinforcement learning policy (Dhingra et al., 2016).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"We choose to build off the latter approach as it fits nicely into the end-to-end trainable framework of sequenceto-sequence modelling, though we are in a supervised learning setting and we do away with explicit representations of belief trackers or dialogue state.
",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For storing the KB of a given dialogue, we take inspiration from the work of (Miller et al., 2016) which found that a key-value structured memory allowed for efficient machine reading of documents.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"We store every entry of our KB using a (subject, relation, object) representation.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In our representation a KB entry from the dialogue in Figure 1 such as (event=dinner, time=8pm, date=the 13th, party=Ana, agenda=“-”) would be normalized into four separate triples of the form (dinner, time, 8pm).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
Every KB has at most 230 normalized triples.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"This formalism is similar to a neo-Davidsonian or RDF-style representation of events.
",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Recent literature has shown that incorporating a copying mechanism into neural architectures improves performance on various sequenceto-sequence tasks (Jia and Liang, 2016; Gu et al., 2016; Ling et al., 2016; Gulcehre et al., 2016; Eric and Manning, 2017).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"We build off this intuition in the following way: at every timestep of decoding, we take the decoder hidden state and compute an attention score with the key of each normalized
KB entry.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For our purposes, the key of an entry corresponds to the sum of the word embeddings of the subject (meeting) and relation (time).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
The attention logits then become the logits of the value for that KB entry.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For our KB attentions, we replace the embedding of the value with a canonicalized token representation.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For example, the value 5pm is replaced with the canonicalized representation meeting time.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"At runtime, if we decode this canonicalized representation token, we convert it into the actual value of the KB entry (5pm in our running example) through a KB lookup.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
Note that this means we are expanding our original output vocabulary to |V,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
| + n,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"where n is the number of separate canonical key representation KB entries.
",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In particular, let kj denote the word embedding of the key of our j th normalized KB entry.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
We can now formalize the decoding for our KB attentionbased retrieval.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Assume that we have m distinct triples in our KB and that we are in the tth timestep of decoding:
utj = r T",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
tanh(W ′2,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
tanh(W ′,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"1[kj , h̃t])))",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"(7) ot = U [h̃t, h̃′t] + v̄ t (8) yt = Softmax(ot) (9)
where r, W ′1, and W ′2 are trainable parameters.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In (8) above, v̄t is a sparse vector with length |V",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
| + n.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Within v̄t, the entry for the value embedding vj corresponding to the key kj is equal to the logit score utj on kj .",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Hence, the m entries of v̄t corresponding to the values in the KB are non-zero, whereas the remaining entries corresponding to the original vocabulary tokens are 0.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
This sparse vector contains our aggregated KB logit scores which we combine with the original logits to get a modified ot.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
We then select the argmax token as input to the next timestep.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"This description seeks to capture the intuition that in response to the query What time is my meeting, we want the model to put a high attention weight on the key representation for the (meeting, time, 5pm)",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"KB triple, which should then lead the model to favor outputting the value token at the given timestep.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
We provide a visualization of the KeyValue Retrieval Network in Figure 2.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In an effort to further work in multi-domain dialogue agents, we built a corpus of multi-turn
dialogues in three distinct domains: calendar scheduling, weather information retrieval, and point-of-interest navigation.","3 A Multi-Turn, Multi-Domain Dialogue Dataset",[0],[0]
"While these domains are different, they are all relevant to the overarching theme of tasks that users would expect of a sophisticated in-car personal assistant.","3 A Multi-Turn, Multi-Domain Dialogue Dataset",[0],[0]
"The data for the multi-turn dialogues was collected using a Wizard-of-Oz scheme inspired by that of (Wen et al., 2016b).",3.1 Data Collection,[0],[0]
"In our scheme, users had two potential modes they could play: Driver and Car Assistant.",3.1 Data Collection,[0],[0]
"In the Driver mode, users were presented with a task that listed certain information they were trying to extract from the Car Assistant as well as the dialogue history exchanged between Driver and Car Assistant up to that point.",3.1 Data Collection,[0],[0]
An example task presented could be: You want to find what the temperature is like in San Mateo over the next two days.,3.1 Data Collection,[0],[0]
"The Driver was then only responsible for contributing a single line of dialogue that appropriately continued the discourse given the prior dialogue history and the task definition.
",3.1 Data Collection,[0],[0]
"Tasks were randomly specified by selecting values (5pm, Saturday, San Francisco, etc.)",3.1 Data Collection,[0],[0]
"for three to five slots (time, date, location, etc.), de-
pending on the domain type.",3.1 Data Collection,[0],[0]
"Values specified for the slots were chosen according to a uniform distribution from a per-domain candidate set.
",3.1 Data Collection,[0],[0]
"In the Car Assistant mode, users were presented with the dialogue history exchanged up to that point in the running dialogue and a private knowledge base known only to the Car Assistant with information that could be useful for satisfying the Driver query.",3.1 Data Collection,[0],[0]
"Examples of knowledge bases could include a calendar of event information, a collection of weekly forecasts for nearby cities, or a collection of nearby points-of-interest with relevant information.",3.1 Data Collection,[0],[0]
The Car Assistant was then responsible for using this private information to provide a single utterance that progressed the user-directed dialogues.,3.1 Data Collection,[0],[0]
"The Car Assistant was also asked to fill in dialogue state information for mentioned slots and values in the dialogue history up to that point.
",3.1 Data Collection,[0],[0]
Each private knowledge base had six to seven distinct rows and five to seven attribute types.,3.1 Data Collection,[0],[0]
"The private knowledge bases used were generated by uniformly selecting a value for a given attribute type, where each attribute type had a variable number of candidate values.",3.1 Data Collection,[0],[0]
"Some knowledge bases intentionally lacked attributes to encourage diversity in discourse.
",3.1 Data Collection,[0],[0]
"During data collection, some of the dialogues
in the calendar scheduling domain did not explicitly require the use of a KB.",3.1 Data Collection,[0],[0]
"For example, in a task such as Set a meeting reminder at 3pm, we hoped to encourage dialogues that required the Car Assistant to execute a task while asking for Driver clarification on underspecified information.",3.1 Data Collection,[0],[0]
"Roughly half of the scheduling dialogues fell into this category.
",3.1 Data Collection,[0],[0]
"While specifying the attribute types and values in each task presented to the Driver allowed us to ground the subject of each dialogue with our desired entities, it would occasionally result in more mechanical discourse exchanges.",3.1 Data Collection,[0],[0]
"To encourage more naturalistic, unbiased utterances, we had users record themselves saying commands in response to underspecified visual depictions of an action a car assistant could perform.",3.1 Data Collection,[0],[0]
These commands were transcribed and then inserted as the first exchange in a given dialogue on behalf of the Driver.,3.1 Data Collection,[0],[0]
"Roughly ∼1,500 of the dialogues employed this transcribed audio command firstutterance technique.
",3.1 Data Collection,[0],[0]
241 unique workers from Amazon Mechanical Turk were anonymously recruited to use the interface we built over a period of about six days.,3.1 Data Collection,[0],[0]
Data statistics are provided in Table 1 and slot types and values are provided in Table 2.,3.1 Data Collection,[0],[0]
"A screenshot of the user-facing interfaces for the data collection, as well as a visual used to prompt user recorded commands, are provided in the supplementary material.",3.1 Data Collection,[0],[0]
Task-oriented agents for spoken dialogue systems have been the subject of extensive research effort.,4 Related Work,[0],[0]
"One line of work by (Young et al., 2013) has tackled the problem using partially observable Markov decision processes and reinforcement learning with carefully designed action spaces, though the number of distinct action states makes this approach often brittle and computationally intractable.
",4 Related Work,[0],[0]
"The recent successes of neural architectures on a number of traditional natural language processing subtasks (Bahdanau et al., 2015; Sutskever et al., 2014; Vinyals et al., 2015) have motivated investigation into dialogue agents that can effectively make use of distributed neural representations for dialogue state management, belief tracking, and response generation.",4 Related Work,[0],[0]
"Recent work by (Wen et al., 2016b) has built systems with modularly-connected representation, belief state, and generation components.",4 Related Work,[0],[0]
"These models learn to explicitly represent user intent through intermediate supervision, which breaks end-to-end trainability.",4 Related Work,[0],[0]
"Other work by (Bordes and Weston, 2016; Liu and Perez, 2016) stores dialogue context in a memory module and repeatedly queries and reasons about this context to select an adequate system response from a set of all candidate responses.
",4 Related Work,[0],[0]
"Another line of recent work has developed taskoriented models which are amenable to both supervised learning and reinforcement learning and are able to incorporate domain-specific knowledge via explicitly-provided features and model-output restrictions (Williams et al., 2017).",4 Related Work,[0],[0]
"Our model contrasts with these works in that training is done in a strictly supervised fashion via a per utterance token generative process, and the model does not need dialogue state trackers, relying instead on latent neural embeddings for accurate system response generation.
",4 Related Work,[0],[0]
"Research in task-oriented dialogue often struggles with a lack of standard, publicly available datasets.",4 Related Work,[0],[0]
"Several classical corpora have consisted of moderately-sized collections of dialogues related to travel-booking (Hemphill et al., 1990;
Bennett and Rudnicky, 2002).",4 Related Work,[0],[0]
"Another wellknown corpus is derived from a series of competitions on the task of dialogue-state tracking (Williams et al., 2013).",4 Related Work,[0],[0]
"While the competitions were designed to test systems for state tracking, recent work has chosen to repurpose this data by only using the transcripts of dialogues without state annotation for developing systems (Bordes and Weston, 2016; Williams et al., 2017).",4 Related Work,[0],[0]
"More recently, Maluuba has released a dataset of hotel and travel-booking dialogues collected in a Wizard-ofOz Scheme with elaborate semantic frames annotated (Asri et al., 2017).",4 Related Work,[0],[0]
This dataset aims to encourage research in non-linear decision-making processes that are present in task-oriented dialogues.,4 Related Work,[0],[0]
In this section we first introduce the details of the experiments and then present results from both automatic and human evaluation.,5 Experiments,[0],[0]
"For our experiments, we divided the dialogues into train/validation/test sets using a 0.8/0.1/0.1 data split and ensured that each domain type was equally represented in each of the splits.
",5.1 Details,[0],[0]
"To reduce lexical variability, in a pre-processing step, we map the variant surface expression of entities to a canonical form using named entity recognition and linking.",5.1 Details,[0],[0]
"For example, the surface form 20 Main Street is mapped to Pizza My Heart address.",5.1 Details,[0],[0]
"During inference, our model outputs the canonical forms of the entities, and so we realize their surface forms by running the system output through an inverse lexicon.",5.1 Details,[0],[0]
The inverse lexicon converts the entities back to their surface forms by sampling from a multinomial distribution with parameters of the distribution equal to the frequency count of a given surface form for an entity as observed in the training and validation data.,5.1 Details,[0],[0]
"Note that for the purposes of computing our evaluation metrics, we operate on the canonicalized forms, so that any non-deterministic variability in surface form realization does not affect the computed metrics.",5.1 Details,[0],[0]
"We trained using a cross-entropy loss and the Adam optimizer (Kingma and Ba, 2015) with learning rates sampled from the interval
[10−4, 10−3].",5.2 Hyperparameters,[0],[0]
"We applied dropout (Hinton et al., 2012) as a regularizer to the input and output of the LSTM.",5.2 Hyperparameters,[0],[0]
We also added an l2 regularization penalty on the weights of the model.,5.2 Hyperparameters,[0],[0]
"We identified hyperparameters by random search, evaluating on the held-out validation subset of the data.",5.2 Hyperparameters,[0],[0]
"Dropout keep rates were sampled from [0.8, 0.9] and the l2 coefficient was sampled from [3 · 10−6, 10−5].",5.2 Hyperparameters,[0],[0]
"We used word embeddings, hidden layer, and cell sizes with size 200.",5.2 Hyperparameters,[0],[0]
We applied gradient clipping with a clip-value of 10 to avoid gradient explosions during training.,5.2 Hyperparameters,[0],[0]
"The attention, output parameters, word embeddings, and LSTM weights were randomly initialized from a uniform unit-scaled distribution in the style of (Sussillo and Abbott, 2015).",5.2 Hyperparameters,[0],[0]
"We also added a bias of 1 to the LSTM cell forget gate in the style of (Pham et al., 2014).",5.2 Hyperparameters,[0],[0]
"We provide several baseline models for comparing performance of the Key-Value Retrieval Network:
• Rule-Based Model:",5.3 Baseline Models,[0],[0]
"This model is a traditional rule-based system with modular dialogue state trackers, KB query, and natural language generation components.",5.3 Baseline Models,[0],[0]
It first does an extensive domain-dependent keyword search in the user utterances to detect intent.,5.3 Baseline Models,[0],[0]
The user utterances are also provided to a lexicon to extract any entities mentioned.,5.3 Baseline Models,[0],[0]
"Collectively, this information forms the dialogue state up to a given point in the dialogue.",5.3 Baseline Models,[0],[0]
"This dialogue state is used to query the KB as appropriate, and the returned KB values are used to fill in predefined template system responses.
",5.3 Baseline Models,[0],[0]
"• Copy-Augmented Sequence-to-Sequence Network: This model is derived from the work of (Eric and Manning, 2017).",5.3 Baseline Models,[0],[0]
"It augments a sequence-to-sequence architecture with encoder attention, with an additional attention-based hard-copy mechanism over the KB entities mentioned in the encoder context.",5.3 Baseline Models,[0],[0]
This model does not explicitly incorporate information from the underlying KB and instead relies solely on dialogue history for system response generation.,5.3 Baseline Models,[0],[0]
"Unlike the best performing model of (Eric and Manning, 2017), we do not enhance the inputs to the encoder with additional entity type features, as we found that the
model performed worse on our data with this added mechanism.",5.3 Baseline Models,[0],[0]
"We choose this model for comparison as it is also end-to-end trainable and implicitly models dialogue state through learned neural representations, putting it in the same class of dialogue models as our key-value retrieval net.",5.3 Baseline Models,[0],[0]
This model has also been shown to be a competitive task-oriented dialogue baseline that can accurately interpret user input and act on this input through latent distributed representation.,5.3 Baseline Models,[0],[0]
We refer to this model as Copy Net in the results tables.,5.3 Baseline Models,[0],[0]
"Though prior work has shown that automatic evaluation metrics often correlate poorly with human assessments of dialogue agents (Liu et al., 2016), we report a number of automatic metrics in Table 3.",5.4.1 Metrics,[0],[0]
"These metrics are provided for coarse-grained evaluation of dialogue response quality:
• BLEU:",5.4.1 Metrics,[0],[0]
"We use the BLEU metric, commonly employed in evaluating machine translation systems (Papineni et al., 2002), which has also been used in past literature for evaluating dialogue systems both of the chatbot and task-oriented variety (Ritter et al., 2011; Li et al., 2016; Wen et al., 2016b).",5.4.1 Metrics,[0],[0]
"While work by (Liu et al., 2016) has demonstrated that ngram based evaluation metrics such as BLEU and METEOR do not correlate well with human performance on non-task-oriented dialogue datasets, recently (Sharma et al., 2017) have shown that these metrics can show comparatively stronger correlation with human assessment on task-oriented datasets.",5.4.1 Metrics,[0],[0]
"We, therefore, calculate average BLEU score over all responses generated by the system, and primarily report these scores to gauge our
model’s ability to accurately generate the language patterns seen in our data.
",5.4.1 Metrics,[0],[0]
• Entity F1: Each human Turker’s Car Assistant response in the test data defines a gold set of entities.,5.4.1 Metrics,[0],[0]
"To compute an entity F1, we micro-average over the entire set of system dialogue responses and use the entities in their canonicalized forms.",5.4.1 Metrics,[0],[0]
This metric evaluates the model’s ability to generate relevant entities from the underlying knowledge base and to capture the semantics of the userinitiated dialogue flow.,5.4.1 Metrics,[0],[0]
"Given that our test set contains dialogues from all three domains, we compute a per-domain entity F1 as well as an aggregated dataset entity F1.",5.4.1 Metrics,[0],[0]
"We note that other work on task-oriented dialogue by (Wen et al., 2016b; Henderson et al., 2014a) have reported the slot-tracking accuracy of their systems, which is a similar but perhaps more informative and fine-grained notion of a system’s ability to capture user semantics.",5.4.1 Metrics,[0],[0]
"Because our model does not have provisions for slot-tracking by design, we are unable to report such a metric and hence report our entity F1.",5.4.1 Metrics,[0],[0]
"We see that of our baseline models, Copy Net has the lowest aggregate entity F1 performance.",5.4.2 Results,[0],[0]
"Though it has the highest model entity F1 for the weather domain dialogues, it performs very poorly in the other domains, indicating its inability to generalize well to multiple dialogue domains and to accurately integrate relevant entities into its responses.",5.4.2 Results,[0],[0]
"Copy Net does, however, have the second highest BLEU score, which is not surprising given that the model is a powerful extension to the sequence-to-sequence modelling class, which is known to have very robust language modelling capabilities.
",5.4.2 Results,[0],[0]
"Our rule-based model has the lowest BLEU score, which is a consequence of the fact that the naturalness of the system output is very limited by the number of diverse and distinct response templates we manually provided.",5.4.2 Results,[0],[0]
This is a common issue with heuristic dialogue agents and one that could be partially alleviated through a larger collection of lexically rich response templates.,5.4.2 Results,[0],[0]
"However, the rule-based system has a very competitive aggregate entity F1.",5.4.2 Results,[0],[0]
"This is because it was designed to accurately parse the semantics of user utterances and query the underlying KB of the dialogue, through manually-provided heuristics.
",5.4.2 Results,[0],[0]
"As precursors to our key-value retrieval net, we first report results of a model that does not compute an attention over the KB (referred to as Attn.",5.4.2 Results,[0],[0]
Seq2Seq),5.4.2 Results,[0],[0]
"and show that without computing attention over the KB, the model performs poorly in entity F1 as its output is agnostic to the world state represented in the KB.",5.4.2 Results,[0],[0]
Note that this model is effectively a sequence-to-sequence model with encoder attention.,5.4.2 Results,[0],[0]
If we include an attention over the KB but do not compute an encoder attention (referred to as KV Retrieval Net no enc.,5.4.2 Results,[0],[0]
"attn.), the entity F1 increases drastically, showing that the model is able to incorporate relevant entities from the KB.",5.4.2 Results,[0],[0]
"Finally, we combine these two attention mechanisms to get our final key-value retrieval net.",5.4.2 Results,[0],[0]
"Our proposed key-value retrieval net has the highest modelling performance in BLEU, aggregate entity F1, and entity F1 for the scheduling and navigation domains.",5.4.2 Results,[0],[0]
It outperforms the rule-based aggregate entity F1 by 4.2% and outperforms the Copy Net BLEU score by 2.2 points as well as its entity F1 by 11%.,5.4.2 Results,[0],[0]
"These salient gains are noteworthy because our model is able to achieve them by learning its latent representationts directly from data, without the need for heuristics or manual labelling.
",5.4.2 Results,[0],[0]
We also report human performance on the provided metrics.,5.4.2 Results,[0],[0]
These scores were computed by taking the dialogues of the test set and having a second distinct batch of Amazon Mechanical Turk workers provide system responses given prior dialogue context.,5.4.2 Results,[0],[0]
"This, in effect, functions as an interannotator agreement score and sets a human upper bound on model performance.",5.4.2 Results,[0],[0]
"We see that there is a sizable gap between human performance on entity F1 and that of our key-value retrieval net (∼ 12.7%), though our model is on par with human performance in BLEU score.",5.4.2 Results,[0],[0]
"We randomly generated 120 distinct scenarios across the three dialogue domains, where a scenario is defined by an underlying KB as well as a user goal for the dialogue (e.g. find the nearest gas station, avoiding heavy traffic).",5.5 Human Evaluation,[0],[0]
"We then paired Amazon Mechanical Turkers with one of our systems in a real-time chat environment, where each Turker played the role of the Driver.",5.5 Human Evaluation,[0],[0]
"We evaluated the rule-based model, Copy Net, and key-value retrieval network on each of the 120 scenarios.",5.5 Human Evaluation,[0],[0]
"We also paired a Turker with another Turker for each of the scenarios, in order to get evaluations of human performance.",5.5 Human Evaluation,[0],[0]
"At the end of the chat, the Turker was asked to judge the quality of their partner according to fluency, cooperativeness, and humanlikeness on a scale from 1 to 5.",5.5 Human Evaluation,[0],[0]
The average scores per pairing are reported in Table 4.,5.5 Human Evaluation,[0],[0]
"In a separate experiment, we also had Turkers evaluate the outputs of the systems on 80 randomly selected dialogues from the test split of our dataset.",5.5 Human Evaluation,[0],[0]
"Those outputs were evaluated according to correctness, appropriateness, and humanlikeness of the responses, and the scores are reported in Table 5.
",5.5 Human Evaluation,[0],[0]
"We see that on real-time dialogues the key-value retrieval network outperforms the baseline models on all of the metrics, with especially sizeable performance gains over the Copy Net which is the only other recurrent neural model evaluated.",5.5 Human Evaluation,[0],[0]
"We also see that human performance on this assessment sets the upper bound on scores, as expected.",5.5 Human Evaluation,[0],[0]
"The results on human evaluation of test outputs show that the rule-based model provides the most correct system responses, the KV network provides the most appropriate responses, and the Copy Net gives the most humanlike responses by small margins.",5.5 Human Evaluation,[0],[0]
"We should note, however, that the second regime for human evaluation is more unrealistic because it involves providing a dialogue context that is directly sampled from our dataset, whereas the first regime of real-time dialogues measures the models’ abilities to adapt to new and noisier user input.",5.5 Human Evaluation,[0],[0]
"This suggests that the first set of results are more meaningful and representative for assessing overall model efficacy.
",5.5 Human Evaluation,[0],[0]
Examples of dialogues conducted between our model and Turkers are included in Figure 3.,5.5 Human Evaluation,[0],[0]
"Particularly noteworthy is our model’s ability to seamlessly integrate world information from the underlying KBs in the respective dialogues, while
still producing very naturalistic utterances.",5.5 Human Evaluation,[0],[0]
The model is able to do this effectively across multiple domains.,5.5 Human Evaluation,[0],[0]
"In this work, we have presented a novel neural task-oriented dialogue model that is able to sustain grounded discourse across a variety of domains by retrieving world knowledge represented in knowledge bases.",6 Conclusion and Future Work,[0],[0]
"It smoothly incorporates
this world knowledge into natural-sounding system responses in an end-to-end trainable fashion, without the need to explicitly model dialogue state.",6 Conclusion and Future Work,[0],[0]
Our model outperforms competitive heuristic and neural baselines on both automatic and human evaluation metrics.,6 Conclusion and Future Work,[0],[0]
"In addition, we have introduced a publicly available dialogue dataset across three domains in the in-car personal assistant space that we hope will help the data scarcity issue present in task-oriented dialogue research.
",6 Conclusion and Future Work,[0],[0]
Future work will address closing the margin between the Key-Value Retrieval Network and human performance on the various metrics.,6 Conclusion and Future Work,[0],[0]
This will include developing new methods for robust handling of joint KB attributes as well as usage of the KB that requires more pragmatic understanding of the world via notions such as temporal reasoning.,6 Conclusion and Future Work,[0],[0]
"The authors wish to thank He He, Peng Qi, Urvashi Khandelwal, and Reid Pryzant for their valuable feedback and insights.",Acknowledgments,[0],[0]
"We gratefully acknowledge the funding of the Ford Research and Innovation Center, under Grant No. 124344.",Acknowledgments,[0],[0]
Neural task-oriented dialogue systems often struggle to smoothly interface with a knowledge base.,abstractText,[0],[0]
"In this work, we seek to address this problem by proposing a new neural dialogue agent that is able to effectively sustain grounded, multi-domain discourse through a novel key-value retrieval mechanism.",abstractText,[0],[0]
The model is end-to-end differentiable and does not need to explicitly model dialogue state or belief trackers.,abstractText,[0],[0]
"We also release a new dataset of 3,031 dialogues that are grounded through underlying knowledge bases and span three distinct tasks in the in-car personal assistant space: calendar scheduling, weather information retrieval, and point-of-interest navigation.",abstractText,[0],[0]
Our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rulebased system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics.,abstractText,[0],[0]
Key-Value Retrieval Networks for Task-Oriented Dialogue,title,[0],[0]
Reasoning is a key concept in artificial intelligence.,1. Introduction,[0],[0]
"A host of applications such as search engines, question-answering systems, conversational dialogue systems, and social networks require reasoning over underlying structured knowledge.",1. Introduction,[0],[0]
Effective representation and learning over such knowledge has come to the fore as a very important task.,1. Introduction,[0],[0]
"In particular, Knowledge Graphs have gained much attention as an important model for studying complex multi-relational settings.",1. Introduction,[0],[0]
"Traditionally, knowledge graphs are considered to be static snapshot of multi-relational data.",1. Introduction,[0],[0]
"However, recent availability of large amount of event based interaction data that exhibits complex temporal dynamics in addition to its multi-relational nature has created the need for approaches that can characterize and reason over tempo-
1College of Computing, Georgia Institute of Technology.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Rakshit Trivedi <rstrivedi@gatech.edu>, Le Song <lsong@cc.gatech.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
rally evolving systems.",1. Introduction,[0],[0]
"For instance, GDELT (Leetaru & Schrodt, 2013) and ICEWS (Boschee et al., 2017) are two popular event based data repository that contains evolving knowledge about entity interactions across the globe.
",1. Introduction,[0],[0]
"Thus traditional knowledge graphs need to be augmented into Temporal Knowledge Graphs, where facts occur, recur or evolve over time in these graphs, and each edge in the graphs have temporal information associated with it.",1. Introduction,[0],[0]
Figure 1 shows a subgraph snapshot of such temporal knowledge graph.,1. Introduction,[0],[0]
Static knowledge graphs suffer from incompleteness resulting in their limited reasoning ability.,1. Introduction,[0],[0]
Most work on static graphs have therefore focussed on advancing entity-relationship representation learning to infer missing facts based on available knowledge.,1. Introduction,[0],[0]
"But these methods lack ability to use rich temporal dynamics available in underlying data represented by temporal knowledge graphs.
",1. Introduction,[0],[0]
Effectively capturing temporal dependencies across facts in addition to the relational (structural) dependencies can help improve the understanding on behavior of entities and how they contribute to generation of facts over time.,1. Introduction,[0],[0]
"For example, one can precisely answer questions like:
• Object prediction.",1. Introduction,[0],[0]
"(Who) will Donald Trump mention next?
",1. Introduction,[0],[0]
• Subject prediction.,1. Introduction,[0],[0]
"(Which country) will provide material support to US next month?
",1. Introduction,[0],[0]
• Time prediction.,1. Introduction,[0],[0]
"(When) will Bob visit Burger King?
”People (entities) change over time and so do relationships.”",1. Introduction,[0],[0]
"When two entities forge a relationship, the newly formed edge drives their preferences and behavior.",1. Introduction,[0],[0]
"This change is effected by combination of their own historical factors (temporal evolution) and their compatibility with the historical factors of the other entity (mutual evolution).
",1. Introduction,[0],[0]
"For instance, if two countries have tense relationships, they are more likely to engage in conflicts.",1. Introduction,[0],[0]
"On the other hand, two countries forging an alliance are most likely to take confrontational stands against enemies of each other.",1. Introduction,[0],[0]
"Finally, time plays a vital role in this process.",1. Introduction,[0],[0]
A country that was once peaceful may not have same characteristics 10 years in future due to various facts (events) that may occur during that period.,1. Introduction,[0],[0]
Being able to capture this temporal and evolutionary effects can help us reason better about future relationship of an entity.,1. Introduction,[0],[0]
"We term this combined phenomenon of evolving entities and their dynamically changing relationships over time as “knowledge evolution”.
",1. Introduction,[0],[0]
"In this paper, we propose an elegant framework to model knowledge evolution and reason over complex non-linear interactions between entities in a multi-relational setting.",1. Introduction,[0],[0]
The key idea of our work is to model the occurrence of a fact as multidimensional temporal point process whose conditional intensity function is modulated by the relationship score for that fact.,1. Introduction,[0],[0]
The relationship score further depends on the dynamically evolving entity embeddings.,1. Introduction,[0],[0]
"Specifically, our work makes the following contributions:
• We propose a novel deep learning architecture that evolves over time based on availability of new facts.",1. Introduction,[0],[0]
"The dynamically evolving network will ingest the incoming new facts, learn from them and update the embeddings of involved entities based on their recent relationships and temporal behavior.",1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
"Besides predicting the occurrence of a fact, our architecture has ability to predict time when the fact may potentially occur which is not possible by any prior relational learning approaches to the best of our knowledge.",1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
Our model supports Open World Assumption as missing links are not considered to be false and may potentially occur in future.,1. Introduction,[0],[0]
It further supports prediction over unseen entities due to its novel dynamic embedding process.,1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
The large-scale experiments on two real world datasets show that our framework has consistently and significantly better performance for link prediction than stateof-arts that do not account for temporal and evolving non-linear dynamics.,1. Introduction,[0],[0]
• Our work aims to introduce the use of powerful mathematical tool of temporal point process framework for temporal reasoning over dynamically evolving knowledge graphs.,1. Introduction,[0],[0]
It has potential to open a new research direction in reasoning over time for various multi-relational settings with underlying spatio-temporal dynamics.,1. Introduction,[0],[0]
"A temporal point process (Cox & Lewis, 2006) is a random process whose realization consists of a list of events localized in time, {ti} with ti ∈ R+.",2.1. Temporal Point Process,[0],[0]
"Equivalently, a given temporal point process can be represented as a counting process, N(t), which records the number of events before time t.
An important way to characterize temporal point processes is via the conditional intensity function λ(t), a stochastic model for the time of the next event given all the previous events.",2.1. Temporal Point Process,[0],[0]
"Formally, λ(t)dt is the conditional probability of observing an event in a small window [t, t+ dt) given the history T (t) := {tk|tk < t} up to t, i.e.,
λ(t)dt := P {event in [t, t+ dt)|T (t)} = E[dN(t)|T (t)]
(1)
where one typically assumes that only one event can happen in a small window of size dt, i.e., dN(t) ∈ {0, 1}.
",2.1. Temporal Point Process,[0],[0]
"From the survival analysis theory (Aalen et al., 2008), given the history T = {t1, . . .",2.1. Temporal Point Process,[0],[0]
", tn}, for any t > tn, we characterize the conditional probability that no event happens during [tn, t) as S(t|T ) =",2.1. Temporal Point Process,[0],[0]
exp ( − ∫ t tn λ(τ) dτ ) .,2.1. Temporal Point Process,[0],[0]
"Moreover, the conditional density that an event occurs at time t is defined as : f(t) = λ(t)S(t) (2)
The functional form of the intensity λ(t) is often designed to capture the phenomena of interests.",2.1. Temporal Point Process,[0],[0]
"Some Common forms include: Poisson Process, Hawkes processes (Hawkes, 1971), Self-Correcting Process (Isham & Westcott, 1979), Power Law and Rayleigh Process.
",2.1. Temporal Point Process,[0],[0]
"Rayleigh Process is a non-monotonic process and is welladapted to modeling fads, where event likelihood drops rapidly after rising to a peak.",2.1. Temporal Point Process,[0],[0]
"Its intensity function is λ(t) = α · (t), where α > 0 is the weight parameter, and the log survival function is logS(t|α) = −α · (t)2/2.",2.1. Temporal Point Process,[0],[0]
We define a Temporal Knowledge Graph (TKG) as a multirelational directed graph with timestamped edges between any pair of nodes.,2.2. Temporal Knowledge Graph representation,[0],[0]
"In a TKG, each edge between two nodes represent an event in the real world and edge type (relationship) represent the corresponding event type.",2.2. Temporal Knowledge Graph representation,[0],[0]
Further an edge may be available multiple times (recurrence).,2.2. Temporal Knowledge Graph representation,[0],[0]
We do not allow duplicate edges and self-loops in graph.,2.2. Temporal Knowledge Graph representation,[0],[0]
"Hence, all recurrent edges will have different time points and every edge will have distinct subject and object entities.
",2.2. Temporal Knowledge Graph representation,[0],[0]
"Given ne entities and nr relationships, we extend traditional triplet representation for knowledge graphs to introduce time dimension and represent each fact in TKG as a quadruplet (es, r, eo, t), where es, eo ∈ {1, . . .",2.2. Temporal Knowledge Graph representation,[0],[0]
", ne}, es 6= eo,
r ∈ {1, . . .",2.2. Temporal Knowledge Graph representation,[0],[0]
", nr}, t ∈",2.2. Temporal Knowledge Graph representation,[0],[0]
R+.,2.2. Temporal Knowledge Graph representation,[0],[0]
"It represents the creation of relationship edge r between subject entity es, and object entity eo at time t. The complete TKG can therefore be represented as an ne × ne",2.2. Temporal Knowledge Graph representation,[0],[0]
× nr × T - dimensional tensor where T is the total number of available time points.,2.2. Temporal Knowledge Graph representation,[0],[0]
"Consider a TKG comprising of N edges and denote the globally ordered set of corresponding N observed events as D = {(es, r, eo, t)n}Nn=1, where 0 ≤ t1 ≤ t2 . . .",2.2. Temporal Knowledge Graph representation,[0],[0]
≤ T .,2.2. Temporal Knowledge Graph representation,[0],[0]
We present our unified knowledge evolution framework (Know-Evolve) for reasoning over temporal knowledge graphs.,3. Evolutionary Knowledge Network,[0],[0]
"The reasoning power of Know-Evolve stems from the following three major components:
1.",3. Evolutionary Knowledge Network,[0],[0]
"A powerful mathematical tool of temporal point process that models occurrence of a fact.
2.",3. Evolutionary Knowledge Network,[0],[0]
"A bilinear relationship score that captures multirelational interactions between entities and modulates the intensity function of above point process.
",3. Evolutionary Knowledge Network,[0],[0]
3.,3. Evolutionary Knowledge Network,[0],[0]
A novel deep recurrent network that learns non-linearly and mutually evolving latent representations of entities based on their interactions with other entities in multirelational space over time.,3. Evolutionary Knowledge Network,[0],[0]
Large scale temporal knowledge graphs exhibit highly heterogeneous temporal patterns of events between entities.,3.1. Temporal Process,[0],[0]
Discrete epoch based methods to model such temporal behavior fail to capture the underlying intricate temporal dependencies.,3.1. Temporal Process,[0],[0]
"We therefore model time as a random variable and use temporal point process to model occurrence of fact.
",3.1. Temporal Process,[0],[0]
"More concretely, given a set of observed events O corresponding to a TKG, we construct a relationship-modulated multidimensional point process to model occurrence of these events.",3.1. Temporal Process,[0],[0]
"We characterize this point process with the following conditional intensity function:
λe s,eo r (t|t̄) = f(ge",3.1. Temporal Process,[0],[0]
"s,eo r (t̄))",3.1. Temporal Process,[0],[0]
"∗ (t− t̄) (3)
where t > t̄, t is the time of the current event and t̄ = max(te
s−, teo−) is the most recent time point when either subject or object entity was involved in an event before time t. Thus, λe s,eo
r (t|t̄) represents intensity of event involving triplet (es, r, ej) at time t given previous time point t̄ when either es or eo was involved in an event.",3.1. Temporal Process,[0],[0]
This modulates the intensity of current event based on most recent activity on either entities’ timeline and allows to capture scenarios like non-periodic events and previously unseen events.,3.1. Temporal Process,[0],[0]
f(·) = exp(·) ensures that intensity is positive and well defined.,3.1. Temporal Process,[0],[0]
"The first term in (3) modulates the intensity function by the relational compatibility score between the involved enti-
ties in that specific relationship.",3.2. Relational Score Function,[0],[0]
"Specifically, for an event (es, r, eo, t) ∈ D occurring at time t, the score term ges,eor is computed using a bilinear formulation as follows:
ge s,eo r (t) =",3.2. Relational Score Function,[0],[0]
v,3.2. Relational Score Function,[0],[0]
es(t−)T,3.2. Relational Score Function,[0],[0]
·,3.2. Relational Score Function,[0],[0]
"Rr · ve o (t−) (4)
where ve s , ve s ∈ Rd represent latent feature embeddings of entities appearing in subject and object position respectively.",3.2. Relational Score Function,[0],[0]
Rr ∈ Rd×d represents relationship weight matrix which attempts to capture interaction between two entities in the specific relationship space r.,3.2. Relational Score Function,[0],[0]
This matrix is unique for each relation in dataset and is learned during training.,3.2. Relational Score Function,[0],[0]
"t is time of current event and t− represent time point just before time t. ve s
(t−) and veo(t−), therefore represent most recently updated vector embeddings of subject and object entities respectively before time t. As these entity embeddings evolve and update over time, ge s,eo
r (t) is able to capture cumulative knowledge learned about the entities over the history of events that have affected their embeddings.",3.2. Relational Score Function,[0],[0]
We represent latent feature embedding of an entity e at time t with a low-dimensional vector ve(t).,3.3. Dynamically Evolving Entity Representations,[0],[0]
We add superscript s and o as shown in Eq.,3.3. Dynamically Evolving Entity Representations,[0],[0]
(4) to indicate if the embedding corresponds to entity in subject or object position respectively.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"We also use relationship-specific low-dimensional representation for each relation type.
",3.3. Dynamically Evolving Entity Representations,[0],[0]
The latent representations of entities change over time as entities forge relationships with each other.,3.3. Dynamically Evolving Entity Representations,[0],[0]
We design novel deep recurrent neural network based update functions to capture mutually evolving and nonlinear dynamics of entities in their vector space representations.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"We consider an event m = (es, r, eo, t)m ∈ D occurring at time t. Also, consider that event m is entity es’s p-th event while it is entity eo’s q-th event.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"As entities participate in events in a heterogeneous pattern, it is less likely that p = q",3.3. Dynamically Evolving Entity Representations,[0],[0]
although not impossible.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Having observed this event, we update the embeddings of two involved entities as follows:
Subject Embedding:
ve s
(tp) = σ(W s t(tp − tp−1) +",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Whh · he
s
(tp−))",3.3. Dynamically Evolving Entity Representations,[0],[0]
"he s (tp−) = σ(Wh · [ve s (tp−1)⊕ ve o (tp−)⊕ re s p−1])
(5)
Object Embedding:
ve o
(tq) = σ(W o t (tq − tq−1) +",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Whh · he
o
(tq−))",3.3. Dynamically Evolving Entity Representations,[0],[0]
"he o (tq−) = σ(Wh · [ve o (tq−1)⊕ ve s (tq−)⊕ re o q−1])
(6)
where, ve s , ve o ∈ Rd.",3.3. Dynamically Evolving Entity Representations,[0],[0]
tp = tq = tm is the time of observed event.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"For subject embedding update in Eq. (5), tp−1 is the time point of the previous event in which entity es was
involved.",3.3. Dynamically Evolving Entity Representations,[0],[0]
tp− is the timepoint just before time tp.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Hence, ve s
(tp−1) represents latest embedding for entity es that was updated after (p − 1)-th event for that entity.",3.3. Dynamically Evolving Entity Representations,[0],[0]
veo(tp−) represents latest embedding for entity eo that was updated any time just before tp = tm.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"This accounts for the fact that entity eo may have been involved in some other event during the interval between current (p) and previous (p− 1) event of entity es. re s
p−1 ∈ Rc represent relationship embedding that corresponds to relationship type of the (p− 1)-th event of entity es.",3.3. Dynamically Evolving Entity Representations,[0],[0]
Note that the relationship vectors are static and do not evolve over time.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"he s
(tp−)",3.3. Dynamically Evolving Entity Representations,[0],[0]
∈ Rd is the hidden layer.,3.3. Dynamically Evolving Entity Representations,[0],[0]
The semantics of notations apply similarly to object embedding update in Eq.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"(6).
",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Wst,W o t ∈ Rd×1, Whh ∈ Rd×l and Wh ∈ Rl×(2d+c) are weight parameters in network learned during training.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Wst,W o t captures variation in temporal drift for subject and object respectively.",3.3. Dynamically Evolving Entity Representations,[0],[0]
Whh is shared parameter that captures recurrent participation effect for each entity.,3.3. Dynamically Evolving Entity Representations,[0],[0]
Wh is a shared projection matrix applied to consider the compatibility of entities in their previous relationships.,3.3. Dynamically Evolving Entity Representations,[0],[0]
⊕ represent simple concatenation operator.,3.3. Dynamically Evolving Entity Representations,[0],[0]
σ(·) denotes nonlinear activation function (tanh in our case).,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Our formulations use simple RNN units but it can be replaced with more expressive
units like LSTM or GRU in straightforward manner.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"In our experiments, we choose d = l and d 6= c",3.3. Dynamically Evolving Entity Representations,[0],[0]
but they can be chosen differently.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Below we explain the rationales of our deep recurrent architecture that captures nonlinear evolutionary dynamics of entities over time.
",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Reasoning Based on Structural Dependency: The hidden layer (he s
) reasons for an event by capturing the compatibility of most recent subject embedding with most recent object embedding in previous relationship of subject entity.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"This accounts for the behavior that within a short period of time, entities tend to form relationships with other entities that have similar recent actions and goals.",3.3. Dynamically Evolving Entity Representations,[0],[0]
This layer thereby uses historical information of the two nodes involved in current event and the edges they both created before this event.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"This holds symmetrically for hidden layer (he o ).
",3.3. Dynamically Evolving Entity Representations,[0],[0]
Reasoning based on Temporal Dependency: The recurrent layer uses hidden layer information to model the intertwined evolution of entity embeddings over time.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Specifically this layer has two main components:
• Drift over time:",3.3. Dynamically Evolving Entity Representations,[0],[0]
The first term captures the temporal difference between consecutive events on respective dimension of each entity.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"This captures the external influences
that entities may have experienced between events and allows to smoothly drift their features over time.",3.3. Dynamically Evolving Entity Representations,[0],[0]
This term will not contribute anything in case when multiple events happen for an entity at same time point (e.g. within a day in our dataset).,3.3. Dynamically Evolving Entity Representations,[0],[0]
"While tp − tp−1 may exhibit high variation, the corresponding weight parameter will capture these variations and along with the second recurrent term, it will prevent ve s (tp) to collapse.
",3.3. Dynamically Evolving Entity Representations,[0],[0]
• Relation-specific Mutual Evolution: The latent features of both subject and object entities influence each other.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"In multi-relational setting, this is further affected by the relationship they form.",3.3. Dynamically Evolving Entity Representations,[0],[0]
Recurrent update to entity embedding with the information from the hidden layer allows to capture the intricate non-linear and evolutionary dynamics of an entity with respect to itself and the other entity in a specific relationship space.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Figure (2) and Figure (3) shows the architecture of knowledge evolution framework and one step of our model.
",3.4. Understanding Unified View of Know-Evolve,[0],[0]
The updates to the entity representations in Eq. (5) and (6) are driven by the events involving those entities which makes the embeddings piecewise constant i.e. an entity embedding remains unchanged in the duration between two events involving that entity and updates only when an event happens on its dimension.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
This is justifiable as an entity’s features may update only when it forges a relationship with other entity within the graph.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
"Note that the first term in Eq. (5) and (6) already accounts for any external influences.
",3.4. Understanding Unified View of Know-Evolve,[0],[0]
"Having observed an event at time t, Know-Evolve considers it as an incoming fact that brings new knowledge about the entities involved in that event.",3.4. Understanding Unified View of Know-Evolve,[0],[0]
It computes the intensity of that event in Eq.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
(3) which is based on relational compatibility score in Eq. (4) between most recent latent embeddings of involved entities.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
"As these embeddings are piecewise constant, we use time interval term (t− t̄) in Eq.",3.4. Understanding Unified View of Know-Evolve,[0],[0]
(3) to make the overall intensity piecewise linear which is standard mathematical choice for efficient computation in point process framework.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
This formulation naturally leads to Rayleigh distribution which models time interval between current event and most recent event on either entities’ dimension.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
Rayleigh distribution has an added benefit of having a simple analytic form of likelihood which can be further used to find entity for which the likelihood reaches maximum value and thereby make precise entity predictions.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
"The complete parameter space for the above model is: Ω = {{Ve}e=1:ne , {Rr}r=1:nr ,We,Wst,Wot ,Wh, Whh,Wr}.",4. Efficient Training Procedure,[0],[0]
"Although Know-Evolve gains expressive power from deep architecture, Table 4 (Appendix D) shows that the memory footprint of our model is comparable to
simpler relational models.",4. Efficient Training Procedure,[0],[0]
The intensity function in (3) allows to use maximum likelihood estimation over all the facts as our objective function.,4. Efficient Training Procedure,[0],[0]
"Concretely, given a collection of facts recorded in a temporal window [0, T ), we learn the model by minimizing the joint negative log likelihood of intensity function (Daley & Vere-Jones, 2007) written as:
L =",4. Efficient Training Procedure,[0],[0]
"− N∑ p=1 log ( λe s,eo r (tp|t̄p) )
︸ ︷︷ ︸ happened events
+ nr∑ r=1",4. Efficient Training Procedure,[0],[0]
"ne∑ es=1 ne∑ eo=1 ∫ T 0 λe s,eo
r (τ |τ̄) dτ︸ ︷︷ ︸ survival term
(7)
",4. Efficient Training Procedure,[0],[0]
The first term maximizes the probability of specific type of event between two entities; the second term penalizes non-presence of all possible types of events between all possible entity pairs in a given observation window.,4. Efficient Training Procedure,[0],[0]
We use Back Propagation Through Time (BPTT) algorithm to train our model.,4. Efficient Training Procedure,[0],[0]
"Previous techniques (Du et al., 2016; Hidasi et al., 2016) that use BPTT algorithm decompose data into independent sequences and train on mini-batches of those sequences.",4. Efficient Training Procedure,[0],[0]
But there exists intricate relational and temporal dependencies between data points in our setting which limits our ability to efficiently train by decomposing events into independent sequences.,4. Efficient Training Procedure,[0],[0]
"To address this challenge, we design an efficient Global BPTT algorithm (Algorithm 2, Appendix A) that creates mini-batches of events over global timeline in sliding window fashion and allows to capture dependencies across batches while retaining efficiency.
",4. Efficient Training Procedure,[0],[0]
Intractable Survival Term.,4. Efficient Training Procedure,[0],[0]
"To compute the second survival term in (7), since our intensity function is modulated by relation-specific parameter, for each relationship we need to compute survival probability over all pairs of entities.",4. Efficient Training Procedure,[0],[0]
"Next, given a relation r and entity pair (es, eo), we denote P(es,eo) as total number of events of type r involving either es or eo in window",4. Efficient Training Procedure,[0],[0]
"[T0, T ).",4. Efficient Training Procedure,[0],[0]
"As our intensity function is piecewise-linear, we can decompose the integration term − ∫ T T0 λe s,eo
r (τ |τ̄)dτ into multiple time intervals where intensity is constant:∫ T
T0
λe s,eo
r (τ |τ̄)dτ
= P(es,eo)−1∑ p=1 ∫ tp+1 tp λe s,eo r (τ |τ̄)dτ
= P(es,eo)−1∑ p=1 (t2p+1 − t2p) · exp(ve s (tp) T ·Rr · ve o (tp))
(8)
The integral calculations in (8) for all possible triplets requiresO(n2r) computations (n is number of entities and r is the number of relations).",4. Efficient Training Procedure,[0],[0]
"This is computationally intractable
Algorithm 1 Survival Loss Computation in mini-batch Input: Minibatch E , size s, Batch Entity List bl loss = 0.0 for p = 0 to s− 1 do
subj feat = Ep → ve s
(t−) obj feat = Ep → ve o
(t−) rel weight =",4. Efficient Training Procedure,[0],[0]
Ep → Rr t end =,4. Efficient Training Procedure,[0],[0]
"Ep → t subj surv = 0, obj surv = 0, total surv = 0 for i = 0 to bl.size do
obj other = bl[i] if obj other == Ep → es then
continue end if t̄ = max(te
s−, teo−) subj surv",4. Efficient Training Procedure,[0],[0]
+= (t end2 − t̄2) · exp(subj featT · rel weight ·,4. Efficient Training Procedure,[0],[0]
"obj other feat)
end for for j = 0 to bl.size do
subj other = bl[i] if subj other == Ep → eo then
continue end if t̄ = max(te
s−, teo−)",4. Efficient Training Procedure,[0],[0]
obj surv += (t end2,4. Efficient Training Procedure,[0],[0]
"− t̄2) · exp(subj other featT · rel weight · obj feat)
end for loss += subj",4. Efficient Training Procedure,[0],[0]
"surv + obj surv
end for
and also unnecessary.",4. Efficient Training Procedure,[0],[0]
Knowledge tensors are inherently sparse and hence it is plausible to approximate the survival loss in a stochastic setting.,4. Efficient Training Procedure,[0],[0]
"We take inspiration from techniques like noise contrastive (Gutmann & Hyvärinen, 2012) estimation and adopt a random sampling strategy to compute survival loss:",4. Efficient Training Procedure,[0],[0]
"Given a mini-batch of events, for each relation in the mini-batch, we compute dyadic survival term across all entities in that batch.",4. Efficient Training Procedure,[0],[0]
Algorithm 1 presents the survival loss computation procedure.,4. Efficient Training Procedure,[0],[0]
"While this procedure may randomly avoid penalizing some dimensions in a relationship, it still includes all dimensions that had events on them.",4. Efficient Training Procedure,[0],[0]
The computational complexity for this procedure will be O(2n′r′m) where m is size of mini-batch and n′ and r′ represent number of entities and relations in the mini-batch.,4. Efficient Training Procedure,[0],[0]
"We use two datasets: Global Database of Events, Language, and Tone (GDELT) (Leetaru & Schrodt, 2013) and Integrated Crisis Early Warning System (ICEWS) (Boschee et al., 2017) which has recently gained attention in learning community (Schein et al., 2016) as useful temporal KGs.",5.1. Temporal Knowledge Graph Data,[0],[0]
"GDELT data is collected from April 1, 2015 to Mar 31,
2016 (temporal granularity of 15 mins).",5.1. Temporal Knowledge Graph Data,[0],[0]
"ICEWS dataset is collected from Jan 1, 2014 to Dec 31, 2014 (temporal granularity of 24 hrs).",5.1. Temporal Knowledge Graph Data,[0],[0]
"Both datasets contain records of events that include two actors, action type and timestamp of event.",5.1. Temporal Knowledge Graph Data,[0],[0]
We use different hierarchy of actions in two datasets - (top level 20 relations for GDELT while last level 260 relations for ICEWS) - to test on variety of knowledge tensor configurations.,5.1. Temporal Knowledge Graph Data,[0],[0]
Note that this does not filter any record from the dataset.,5.1. Temporal Knowledge Graph Data,[0],[0]
"We process both datasets to remove any duplicate quadruples, any mono-actor events (i.e., we use only dyadic events), and self-loops.",5.1. Temporal Knowledge Graph Data,[0],[0]
We report our main results on full versions of each dataset.,5.1. Temporal Knowledge Graph Data,[0],[0]
We create smaller version of both datasets for exploration purposes.,5.1. Temporal Knowledge Graph Data,[0],[0]
Table 1 (Appendix B) provide statistics about the data and Table 2 (Appendix B) demonstrates the sparsity of knowledge tensor.,5.1. Temporal Knowledge Graph Data,[0],[0]
"We compare the performance of our method with following relational learning methods: RESCAL, Neural Tensor Network (NTN), Multiway Neural Network (ER-MLP), TransE and TransR.",5.2. Competitors,[0],[0]
"To the best of our knowledge, there are no existing relational learning approaches that can predict time for a new fact.",5.2. Competitors,[0],[0]
"Hence we devised two baseline methods for evaluating time prediction performance — (i) Multi-dimensional Hawkes process (MHP): We model dyadic entity interactions as multi-dimensional Hawkes process similar to (Du et al., 2015).",5.2. Competitors,[0],[0]
"Here, an entity pair constitutes a dimension and for each pair we collect sequence of events on its dimension and train and test on that sequence.",5.2. Competitors,[0],[0]
Relationship is not modeled in this setup.,5.2. Competitors,[0],[0]
"(ii) Recurrent Temporal Point Process (RTPP): We implement a simplified version of RMTPP (Du et al., 2016) where we do not predict the marker.",5.2. Competitors,[0],[0]
"For training, we concatenate static entity and relationship embeddings and augment the resulting vector with temporal feature.",5.2. Competitors,[0],[0]
This augmented unit is used as input to global RNN which produces output vector ht.,5.2. Competitors,[0],[0]
"During test time, for a given triplet, we use this vector ht to compute conditional intensity of the event given history which is further used to predict next event time.",5.2. Competitors,[0],[0]
Appendix C provides implementation details of our method and competitors.,5.2. Competitors,[0],[0]
"We report experimental results on two tasks: Link prediction and Time prediction.
",5.3. Evaluation Protocol,[0],[0]
Link prediction:,5.3. Evaluation Protocol,[0],[0]
"Given a test quadruplet (es, r, eo, t), we replace eo with all the entities in the dataset and compute the conditional density de s,eo
r = λ es,eo r (t)S es,eo
r (t) for the resulting quadruplets including the ground truth.",5.3. Evaluation Protocol,[0],[0]
We then sort all the quadruplets in the descending order of this density to rank the correct entity for object position.,5.3. Evaluation Protocol,[0],[0]
"We also conduct testing after applying the filtering techniques described in (Bordes et al., 2013) -",5.3. Evaluation Protocol,[0],[0]
"we only rank against the entities that do not generate a true triplet (seen in train) when it replaces
ground truth object.",5.3. Evaluation Protocol,[0],[0]
"We report Mean Absolute Rank (MAR), Standard Deviation for MAR and HITS@10 (correct entity in top 10 predictions) for both Raw and Filtered Versions.
",5.3. Evaluation Protocol,[0],[0]
"Time prediction: Give a test triplet (es, r, eo), we predict the expected value of next time the fact (es, r, eo) can occur.",5.3. Evaluation Protocol,[0],[0]
"This expectation is defined by: Ees,eor (t) =√
π
2 exp(ge s,eo r (t)) , where ge
s,eo
r (t) is computed using equa-
tion (4).",5.3. Evaluation Protocol,[0],[0]
"We report Mean Absolute Error (MAE) between the predicted time and true time in hours.
",5.3. Evaluation Protocol,[0],[0]
Sliding Window Evaluation.,5.3. Evaluation Protocol,[0],[0]
"As our work concentrates on temporal knowledge graphs, it is more interesting to see the performance of methods over time span of test set as compared to single rank value.",5.3. Evaluation Protocol,[0],[0]
This evaluation method can help to realize the effect of modeling temporal and evolutionary knowledge.,5.3. Evaluation Protocol,[0],[0]
We therefore partition our test set in 12 different slides and report results in each window.,5.3. Evaluation Protocol,[0],[0]
"For both datasets, each slide included 2 weeks of time.",5.3. Evaluation Protocol,[0],[0]
Link Prediction Results.,5.4. Quantitative Analysis,[0],[0]
"Figure (4, 5, 6) demonstrate link prediction performance comparison on both datasets.",5.4. Quantitative Analysis,[0],[0]
"Know-Evolve significantly and consistently outperforms all competitors in terms of prediction rank without any dete-
rioration over time.",5.4. Quantitative Analysis,[0],[0]
Neural Tensor Network’s second best performance compared to other baselines demonstrate its rich expressive power but it fails to capture the evolving dynamics of intricate dependencies over time.,5.4. Quantitative Analysis,[0],[0]
"This is further substantiated by its decreasing performance as we move test window further in time.
",5.4. Quantitative Analysis,[0],[0]
The second row represents deviation error for MAR across samples in a given test window.,5.4. Quantitative Analysis,[0],[0]
Our method achieves significantly low deviation error compared to competitors making it most stable.,5.4. Quantitative Analysis,[0],[0]
"Finally, high performance on HITS@10 metric demonstrates extensive discriminative ability of KnowEvolve.",5.4. Quantitative Analysis,[0],[0]
"For instance, GDELT has only 20 relations but 32M events where many entities interact with each other in multiple relationships.",5.4. Quantitative Analysis,[0],[0]
"In this complex setting, other methods depend only on static entity embeddings to perform prediction unlike our method which does effectively infers new knowledge using powerful evolutionary network and provides accurate prediction results.
",5.4. Quantitative Analysis,[0],[0]
Time Prediction Results.,5.4. Quantitative Analysis,[0],[0]
Figure 7 demonstrates that Know-Evolve performs significantly better than other point process based methods for predicting time.,5.4. Quantitative Analysis,[0],[0]
MHP uses a specific parametric form of the intensity function which limits its expressiveness.,5.4. Quantitative Analysis,[0],[0]
"Further, each entity pair interaction is modeled as an independent dimension and does not take
into account relational feature which fails to capture the intricate influence of different entities on each other.",5.4. Quantitative Analysis,[0],[0]
"On the other hand, RTPP uses relational features as part of input, but it sees all events globally and cannot model the intricate evolutionary dependencies on past events.",5.4. Quantitative Analysis,[0],[0]
"We observe that our method effectively captures such non-linear relational and temporal dynamics.
",5.4. Quantitative Analysis,[0],[0]
"In addition to the superior quantitative performance, we demonstrate the effectiveness of our method by providing extensive exploratory analysis in Appendix E.",5.4. Quantitative Analysis,[0],[0]
"In this section, we discuss relevant works in relational learning and temporal modeling techniques.",6. Related Work,[0],[0]
"Among various relational learning techniques, neural embedding models that focus on learning low-dimensional representations of entities and relations have shown stateof-the-art performance.",6.1. Relational Learning,[0],[0]
These methods compute a score for the fact based on different operations on these latent representations.,6.1. Relational Learning,[0],[0]
"Such models can be mainly categorized into two variants:
Compositional Models.",6.1. Relational Learning,[0],[0]
"RESCAL (Nickel et al., 2011) uses a relation specific weight matrix to explain triplets via pairwise interactions of latent features.",6.1. Relational Learning,[0],[0]
"Neural Tensor Network (NTN) (Socher et al., 2013) is more expressive model as it combines a standard NN layer with a bilinear tensor layer.",6.1. Relational Learning,[0],[0]
"(Dong et al., 2014) employs a concatenationprojection method to project entities and relations to lower dimensional space.",6.1. Relational Learning,[0],[0]
"Other sophisticated models include Holographic Embeddings (HoLE) (Nickel et al., 2016b) that employs circular correlation on entity embeddings and Neural Association Models (NAM) (Liu et al., 2016), a deep network used for probabilistic reasoning.
",6.1. Relational Learning,[0],[0]
Translation Based Models.,6.1. Relational Learning,[0],[0]
"(Bordes et al., 2011) uses two relation-specific matrices to project subject and object entities and computes L1 distance to score a fact between two entity vectors.",6.1. Relational Learning,[0],[0]
"(Bordes et al., 2013) proposed TransE model that computes score as a distance between relation-specific translations of entity embeddings.",6.1. Relational Learning,[0],[0]
"(Wang et al., 2014) improved",6.1. Relational Learning,[0],[0]
"TransE by allowing entities to have distributed representations on relation specific hyperplane where distance
between them is computed.",6.1. Relational Learning,[0],[0]
TransR,6.1. Relational Learning,[0],[0]
"(Lin et al., 2015) extends this model to use separate semantic spaces for entities and relations and does translation in the relationship space.
",6.1. Relational Learning,[0],[0]
"(Nickel et al., 2016a) and (Yang et al., 2015; Toutanova & Chen, 2015) contains comprehensive reviews and empirical comparison of relational learning techniques respectively.",6.1. Relational Learning,[0],[0]
All these methods consider knowledge graphs as static models and lack ability to capture temporally evolving dynamics.,6.1. Relational Learning,[0],[0]
"Temporal point processes have been shown as very effective tool to model various intricate temporal behaviors in networks (Yang & Zha, 2013; Farajtabar et al., 2014; 2015; Du et al., 2015; 2016; Wang et al., 2016a;b;c; 2017a;b).",6.2. Temporal Modeling,[0],[0]
"Recently, (Wang et al., 2016a; Dai et al., 2016b) proposed novel co-evolutionary feature embedding process that captures self-evolution and co-evolution dynamics of users and items interacting in a recommendation system.",6.2. Temporal Modeling,[0],[0]
"In relational setting, (Loglisci et al., 2015) proposed relational mining approach to discover changes in structure of dynamic network over time.",6.2. Temporal Modeling,[0],[0]
"(Loglisci & Malerba, 2017) proposes method to capture temporal autocorrelation in data to improve predictive performance.",6.2. Temporal Modeling,[0],[0]
"(Sharan & Neville, 2008) proposes summarization techniques to model evolving relational-temporal domains.",6.2. Temporal Modeling,[0],[0]
"Recently, (Esteban et al., 2016) proposed multiway neural network architecture for modeling event based relational graph.",6.2. Temporal Modeling,[0],[0]
The authors draw a synergistic relation between a static knowledge graph and an event set wherein the knowledge graph provide information about entities participating in events and new events in turn contribute to enhancement of knowledge graph.,6.2. Temporal Modeling,[0],[0]
They do not capture the evolving dynamics of entities and model time as discrete points which limits its capacity to model complex temporal dynamics.,6.2. Temporal Modeling,[0],[0]
"(Jiang et al., 2016) models dependence of relationship on time to facilitate time-aware link prediction but do not capture evolving entity dynamics.",6.2. Temporal Modeling,[0],[0]
We propose a novel deep evolutionary knowledge network that efficiently learns non-linearly evolving entity representations over time in multi-relational setting.,7. Conclusion,[0],[0]
Evolutionary dynamics of both subject and object entities are captured by deep recurrent architecture that models historical evolution of entity embeddings in a specific relationship space.,7. Conclusion,[0],[0]
The occurrence of a fact is then modeled by multivariate point process that captures temporal dependencies across facts.,7. Conclusion,[0],[0]
The superior performance and high scalability of our method on large real-world temporal knowledge graphs demonstrate the importance of supporting temporal reasoning in dynamically evolving relational systems.,7. Conclusion,[0],[0]
Our work establishes previously unexplored connection between relational processes and temporal point processes with a potential to open a new direction of research on reasoning over time.,7. Conclusion,[0],[0]
"This project was supported in part by NSF IIS-1218749, NIH BIGDATA 1R01GM108341, NSF CAREER IIS1350983,",Acknowledgement,[0],[0]
"NSF IIS-1639792 EAGER, ONR N00014-15-12340, NVIDIA, Intel and Amazon AWS.",Acknowledgement,[0],[0]
The availability of large scale event data with time stamps has given rise to dynamically evolving knowledge graphs that contain temporal information for each edge.,abstractText,[0],[0]
Reasoning over time in such dynamic knowledge graphs is not yet well understood.,abstractText,[0],[0]
"To this end, we present Know-Evolve, a novel deep evolutionary knowledge network that learns non-linearly evolving entity representations over time.",abstractText,[0],[0]
The occurrence of a fact (edge) is modeled as a multivariate point process whose intensity function is modulated by the score for that fact computed based on the learned entity embeddings.,abstractText,[0],[0]
We demonstrate significantly improved performance over various relational learning approaches on two large scale real-world datasets.,abstractText,[0],[0]
"Further, our method effectively predicts occurrence or recurrence time of a fact which is novel compared to prior reasoning approaches in multirelational setting.",abstractText,[0],[0]
Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2038–2043, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Large-scale knowledge bases (KB) like Freebase (Bollacker et al., 2008), Yago (Suchanek et al., 2007), NELL (Mitchell et al., 2015) can be useful in a variety of applications like natural language question answering, semantic search engines, etc.",1 Introduction,[0],[0]
These knowledge bases consist of millions of real world entities and relationships between them which are stored in the form of a directed graph where links represent relations and nodes represent the entities.,1 Introduction,[0],[0]
"Although such KBs contain millions of entities, they are still very sparse, i.e., they are missing a large number of relations between existing entities (West et al., 2014).
",1 Introduction,[0],[0]
Performing inference over the knowledge graph for predicting relations between two entities is one way of densifying the KB graph.,1 Introduction,[0],[0]
"For example,
from (Germany, playsinTournament, FIFA) and (FIFA, tournamentofSport, Soccer), we can infer (Germany, playsSport, Soccer).",1 Introduction,[0],[0]
"The Path Ranking Algorithm (PRA) (Lao and Cohen, 2010), (Lao et al., 2011) performs such an inference by learning inference rules over the knowledge graph.
",1 Introduction,[0],[0]
"If the knowledge graph is sparse, i.e., if there are a very few or no paths between source and target entities, then PRA is unable to predict the existence of a relation.",1 Introduction,[0],[0]
"To address this shortcoming, (Lao et al., 2012) augmented the knowledge graph with paths obtained from an external corpus.",1 Introduction,[0],[0]
The added paths consisted of unlexicalized dependency labels obtained from a dependency parsed external corpus.,1 Introduction,[0],[0]
"To improve the expressivity of the added paths, instead of the unlexicalized labels, (Gardner et al., 2013) augmented the KB graph with verbs (surface relations) from a corpus containing over 600 million Subject-Verb-Object (SVO) triples.",1 Introduction,[0],[0]
"These verbs act as edges that connect previously unconnected entities thereby increasing the connectivity of the KB graph which can potentially improve PRA performance.
",1 Introduction,[0],[0]
"However, naı̈vely adding these edges increases the feature sparsity which degrades the discriminative ability of the logistic regression classifier
2038
used in PRA.",1 Introduction,[0],[0]
"This can be addressed by adding latent relations obtained by clustering the surface relations, instead of directly adding the surface relations.",1 Introduction,[0],[0]
"This reduces feature sparsity and has been shown to improve PRA inference (Gardner et al., 2013) , (Gardner et al., 2014).
",1 Introduction,[0],[0]
In this article we propose a scheme for augmenting the KB using paths obtained by mining noun phrases that connect two SVO triples from an external corpus.,1 Introduction,[0],[0]
We term these noun phrases as bridging entities since they bridge two KB relations to form a path.,1 Introduction,[0],[0]
"This is different from the scheme in (Gardner et al., 2013) and (Gardner et al., 2014), which adds edges between KB nodes by mining surface relations from an external corpus.",1 Introduction,[0],[0]
"We search for such bridging entities in the corpus by performing a limited depth DFS (depth first search) on the corpus graph in an on-demand fashion.
",1 Introduction,[0],[0]
"We term this procedure as On-Demand Augmentation (ODA), because the search can be performed during test time in an on-demand manner.",1 Introduction,[0],[0]
"In contrast, the previous approaches of adding edges or embeddings to the KB (Gardner et al., 2013), and vector space random walk PRA (Gardner et al., 2014) are batch procedures.",1 Introduction,[0],[0]
"As we shall see in Section 4, due to a limited search space, on-demand augmentation is much faster compared to algorithms in (Gardner et al., 2013; Gardner et al., 2014).",1 Introduction,[0],[0]
"Furthermore, since edges are not added blindly, on-demand augmentation does not increase feature sparsity which is responsible for performance degradation.",1 Introduction,[0],[0]
"Our experiments suggest that ODA provides better performance than (Gardner et al., 2013) and nearly the same prediction performance as provided by (Gardner et al., 2014), but in both cases with the added advantage of faster running time and greater flexibility due to its online and on-demand nature.",1 Introduction,[0],[0]
The code along with the results can be obtained at https://github.com/malllabiisc/pra-oda.,1 Introduction,[0],[0]
"Using surface level relations and noun phrases for extracting meaningful relational facts is not a new idea (Hearst, 1992),(Brin, 1999), (Etzioni et al., 2004).",2 Related Work,[0],[0]
"However, none of them make use of Knowledge Bases for improving information extraction.
",2 Related Work,[0],[0]
"The Path Ranking Algorithm (PRA) first proposed in (Lao and Cohen, 2010) was used for per-
forming inference over a KB in (Lao et al., 2011).",2 Related Work,[0],[0]
"It was extended by (Lao et al., 2012), to improve the inference by augmenting the KB with syntactic information obtained from a dependency parsed corpus.",2 Related Work,[0],[0]
"Augmenting the KB for improving PRA inference using surface relations mined from an external corpus and using latent edge labels obtained by performing PCA on the surface relations was explored in (Gardner et al., 2013).",2 Related Work,[0],[0]
"Instead of hard mapping of surface relations to latent embeddings, (Gardner et al., 2014) perform a ‘soft’ mapping using vector space random walks.",2 Related Work,[0],[0]
"This allows the random walker to traverse an edge semantically similar to the current edge type more frequently than other edges.
",2 Related Work,[0],[0]
"Although, like others, we too use an external corpus to augment the KB, the crucial difference in our approach is that apart from adding surface relations, we also add bridging entities that enable us to create new paths in the KB.",2 Related Work,[0],[0]
"Furthermore, the procedure is targeted so that only paths that play a part in inferring the relations that are of interest are added.",2 Related Work,[0],[0]
"Thus, the number of paths added in this manner is much lower than the number of surface relations added using the procedure in (Gardner et al., 2013).",2 Related Work,[0],[0]
"As we shall see in Section 4, this results in a more effective algorithm with faster runtime.",2 Related Work,[0],[0]
"We first present a brief overview of the Path Ranking Algorithm (PRA) (Lao and Cohen, 2010).",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
The PRA uses paths as features for a logistic regression classifier which predicts if the given relation exists between a pair of entities.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"For a given pair of entities s and t, the path type connecting s to t form the feature vector.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
A path types π is an ordered set of relations.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
Paths with the same ordered relations but different intermediate or terminal entities belong to the same path type.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"For example, s1
v0−→ x1 v1−→ t1 and s2 v0−→ x2 v1−→ t2 belong to path type v0−→ v1−→.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"The value of a feature, is taken to be P (s → t;π), where P (s → t;π) is the probability of reaching t from s by traversing paths of type π.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
PRA approximates these probabilities by running a random walk (RW) on the KB graph.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"Let F = {π1, π2, ..., πk} be the set of all path types.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"For predicting the existence of relation r between entities s and t, the logistic regression classifier outputs a score which is a measure of the
confidence that r exists between s and t. It does so by first assigning weights to the features in the training phase.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"The score is given by
S(s, t, r) = ∑ π∈F P (s→ t;π)× θrπ (1)
where θrπ is the weight learned by the logistic regression classifier during training specially for relation r and path type π.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"During the test phase, since targets are not available, the PRA gathers candidate targets by performing a random walk and then computes feature vectors and the score.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"PRA-SVO and PRA-VS are the systems proposed in (Gardner et al., 2013) and (Gardner et al., 2014) respectively, where the KB graph is augmented with edges mined from a large subject-verb-object (SVO) triple corpus.",3.2 PRA-SVO and PRA-VS,[0],[0]
"In these two systems, only new edges are added over the fixed set of nodes, and the augmentation happens in a batch, offline setting.",3.2 PRA-SVO and PRA-VS,[0],[0]
"In contrast, PRA-ODA, the method proposed in the paper, also expands the set of nodes through bridging entities, and performs the augmentation in an on-demand manner.",3.2 PRA-SVO and PRA-VS,[0],[0]
Training: Let s and t be any two KB entities and let s(n) and t(n) be their corresponding noun phrase representations or aliases.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We search for bridging entities x1, x2, ..xn by performing limited depth first search (DFS) starting with sn such that we obtain a path s ALIAS−→ s(n) v0−→ x1 v1−→ ...
vn−1−→",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
xn vn−→ t(n) ALIAS−→,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"t, where vi are verbs present in the corpus graph.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"This is done for all n ≤ dmax− 1, where dmax is the maximum depth of DFS.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
We add an ‘ALIAS’ edge between the KB entity and its noun phase representation.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"The usefulness of bridging entities is illustrated in Fig. 1.
",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We mine bridging entities from a corpus containing over 600 million SVO triples which were obtained from the ClueWeb09 corpus (Callan et
al., 2009)",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"parsed using the MALT parser (Nivre et al., 2007).",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
We use Mongo DB to store the triples as an adjacency list.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"During training time, for any relation that is being inferred, both the source and its corresponding target entities are known.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
A limited depth DFS is performed for all depths less then dmax on the SVO graph with the aliases of subject entity acting as the starting points.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
Such aliases are available for the NELL and Freebase knowledge bases.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
The DFS is said to discover a path if the terminating entity of the path matches any alias of the target entity.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We choose to use aliases to perform string match, since it is easy to change the softness of the match by simply adding more aliases.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
This is done for all training sourcetarget pairs.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"A few examples of added paths are shown in Table 1.
",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
The SVO graph is noisy since it is obtained by parsing the ClueWeb corpus which was obtained by scraping the web.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"To reduce noise, we add the top K most frequent discovered SVO path types, whereK is a tunable parameter.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
By SVO path type we refer to a set of ordered verbs mined from the SVO corpus.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"There is a possibility that the bridging entities, extracted from the corpus, may be present in the KB.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"If the bridging entity matches any alias, then it is treated as an alias to an existing KB entity.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"If not, then the bridging entity is added to the KB as a new entity.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
To avoid overfitting we add negative data to the training set.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Furthermore, only high quality expressive bridging entities result in meaningful and discriminative paths.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Although the quality of bridging entities depend on the corpus, low quality bridging entities can be filtered out by adding negative training data.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Low quality bridging entities connect source target pairs from both positive and negative training sets, and hence are eliminated by the sparse logistic regression classifier.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"The negative dataset is generated using the closed world assumption by performing a random walk.
",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"After augmenting the KB, we run the training phase of the PRA algorithm to obtain the feature (path) weights computed by the logistic regression
classifier.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
Query Time:,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
The set of target entities corresponding to a source entity and the relation being predicted is not available during query (test) time.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
We use all the entities included in the range of the relation being predicted as candidate target entities.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"For example, if the relation is riverFlowsThroughCity, the candidate target set would include entities in the KB that are cities.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"The DFS is now performed starting from source entities as during training, but this time only restricting to paths with positive weights learned during training.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Any path (along with bridging entities) found during this search are added to the KB, and the PRA algorithm is now run over this augmented graph.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We used the implementation of PRA provided by the authors of (Gardner et al., 2014).",4 Experiments,[0],[0]
"For our experiments, we used the same 10 NELL relation data as used in (Gardner et al., 2014).",4 Experiments,[0],[0]
"The augmentation resulted in the addition of 1086 paths during training and 1430 paths during test time.
",4 Experiments,[0],[0]
"We split the NELL data into 60% training data, 15 % development data and 25% test data.",4 Experiments,[0],[0]
"Values for dmax, and K, the most frequent paths, were obtained by tuning on a development set for 4 relations (athleteplaysforsport,actorstarredinmovie,citylocatedincountry
and journalistwritesforpublication).",4 Experiments,[0],[0]
"The hyperparameter values dmax = 2, K = 10 reported the highest MRR and were used for the rest of the relations.",4 Experiments,[0],[0]
"For the L1 and L2 regularization parameters in the logistic regression classifier, we used the same values as used in (Gardner et al., 2013; Gardner et al., 2014), viz., L1 = 0.005, and L2 = 1.0.",4 Experiments,[0],[0]
"This is because the parameters were reported to be robust, and seemed to work well even when the knowledge base was augmented.
",4 Experiments,[0],[0]
"We compare the results (PRA-ODA) with the PRA algorithm executed on the NELL KB, NELL KB augmented with surface relations (PRA-SVO) (Gardner et al., 2013) and vector space random walk PRA (PRA-VS) (Gardner et al., 2014).",4 Experiments,[0],[0]
"The run times, i.e, the time taken to perform an entire experiment for PRA-SVO and PRA-VS includes the time taken to augment NELL KB with SVO edges.",4 Experiments,[0],[0]
The PRA-VS runtime also includes the time taken for generating embeddings to perform the vector space random walk.,4 Experiments,[0],[0]
"As can be seen from Table 2 and Table 3, our scheme, PRA-ODA, provides performance equivalent to PRA-VS with faster running time (speed up of 1.8).",4 Experiments,[0],[0]
"In addition to the time taken for the full SVO augmentation, PRA-VS takes additional time to generate embeddings (13 minutes) from the added verbs.",4 Experiments,[0],[0]
"We note that the batch augmentation in case of PRA-SVO and PRA-VS, and embedding computation in case of PRA-VS are all specific to the relations in the evaluation set, and hence can’t be ignored as a one-time offline cost.",4 Experiments,[0],[0]
"In other words, these costs are likely to increase as more relations (and their instances) are included during training and testing.",4 Experiments,[0],[0]
"Runtime gains with PRA-ODA are likely to be even more pronounced in such settings.
",4 Experiments,[0],[0]
An additional advantage of the proposed algorithm is that it can also be run on the top of any PRA based algorithm such as the PRA-SVO and PRA-VS.,4 Experiments,[0],[0]
"In this paper, we investigated the usefulness of adding paths to a Knowledge Base for improving its connectivity by mining bridging entities from an external corpus.",5 Conclusion,[0],[0]
"While previous KB augmentation methods focused only on augmentation using mined surface verbs while keeping the node set fixed, we extended these approaches by also adding bridging entities in an online fashion.",5 Conclusion,[0],[0]
We used a large corpus of 500 million web text corpus to mine these additional edges and bridging entities.,5 Conclusion,[0],[0]
"Through experiments on real-world datasets, we demonstrate that the proposed approach is not only comparable or better than other state-of-theart baselines, but more importantly provides faster overall runtime compared with the alternatives.",5 Conclusion,[0],[0]
This work is supported in part by a gift from Google.,Acknowledgment,[0],[0]
"Large-scale Knowledge Bases (such as NELL, Yago, Freebase, etc.) are often sparse, i.e., a large number of valid relations between existing entities are missing.",abstractText,[0],[0]
"Recent research have addressed this problem by augmenting the KB graph with additional edges mined from a large text corpus while keeping the set of nodes fixed, and then using the Path Ranking Algorithm (PRA) to perform KB inference over this augmented graph.",abstractText,[0],[0]
"In this paper, we extend this line of work by augmenting the KB graph not only with edges, but also with bridging entities, where both the edges and bridging entities are mined from a 500 million web text corpus.",abstractText,[0],[0]
"Through experiments on real-world datasets, we demonstrate the value of bridging entities in improving the performance and running time of PRA in the KB inference task.",abstractText,[0],[0]
Knowledge Base Inference using Bridging Entities,title,[0],[0]
"We consider the problem of completing a partial knowledge base (KB) containing facts about gener-
∗This work was done while the author was affiliated with the Allen Institute for Artificial Intelligence.
ics or common nouns, represented as a third-order tensor of (source, relation, target) triples, such as (butterfly, pollinate, flower) and (thermometer, measure, temperature).",1 Introduction,[0],[0]
Such facts capture common knowledge that humans have about the world.,1 Introduction,[0],[0]
They are arguably essential for intelligent agents with human-like conversational abilities as well as for specific applications such as question answering.,1 Introduction,[0],[0]
"We demonstrate that state-of-the-art KB completion methods perform poorly when faced with generics, while our strategies for incorporating external knowledge as well as obtaining additional annotations for rare entities provide the first successful solution to this challenging new task.
",1 Introduction,[0],[0]
"Since generics represent classes of similar individuals, the truth value yi of a generics triple xi = (s, r, t) depends on the quantification semantics one associates with s and t. Indeed, the semantics of generics statements can be ambiguous, even selfcontradictory, due to cultural norms.",1 Introduction,[0],[0]
"As Leslie (2008) points out, ‘ducks lay eggs’ is generally considered true while ‘ducks are female’, which is true for a broader set of ducks than the former statement, is generally considered false.
",1 Introduction,[0],[0]
"To avoid deep philosophical issues, we fix a particular mathematical semantics that is especially relevant for noisy facts derived automatically from text: associate s with a categorical quantification from {all, some, none} and associate t (implicitly) with some.",1 Introduction,[0],[0]
"For instance, “all butterflies pollinate (some) flower” and “some animals live in (some) forest”.",1 Introduction,[0],[0]
"When presenting such triples to humans, they are phrased as: is it true that all butterflies pollinate some flower?",1 Introduction,[0],[0]
"As a notational shortcut, we treat the quantification of s as the categorical label yi for the triple xi.",1 Introduction,[0],[0]
"For example, (butterfly, pollinate, flower)
197
Transactions of the Association for Computational Linguistics, vol. 6, pp.",1 Introduction,[0],[0]
"197–210, 2018.",1 Introduction,[0],[0]
Action Editor: Hinrich Schütze.,1 Introduction,[0],[0]
"Submission batch: 6/2017; Revision batch: 9/2017; Published 4/2018.
",1 Introduction,[0],[0]
c©2018 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
is labeled all while (animal, live in, forest) is labeled some.",1 Introduction,[0],[0]
"Given a noisy KB of such labeled triples, the task is to infer more triples.
",1 Introduction,[0],[0]
"Tensor factorization and graph based methods have both been found to be very effective for expanding knowledge bases, but have focused on named entity KBs such as Freebase (Bollacker et al., 2008) involving relations with clear semantics such as liveIn and isACityIn, and disambiguated entities such as Barack Obama or Hawaii.",1 Introduction,[0],[0]
"Completing KBs that involve facts about generics, however, brings up new challenges, as evidenced by our empirical results when using existing methods.
",1 Introduction,[0],[0]
It has been observed that Horn clauses often reliably connect predicates in the named-entity setting.,1 Introduction,[0],[0]
"For instance, for any person x, city y, and country z, (x, liveIn, y) & (y, isACityIn, z) ⇒",1 Introduction,[0],[0]
"(x, liveIn, z).",1 Introduction,[0],[0]
"With generics, however, clear patterns or reliable first-order logic rules are rare, in part due to each generic representing a collection of individuals that often have similarities with respect to some relations and differences with respect to others.",1 Introduction,[0],[0]
"For instance, (x, liveIn, mountain) is true for many cats and caribou, but there is little tangible similarity between the two animals and it is unclear what, if anything, can be carried over from one to the other.",1 Introduction,[0],[0]
"On the other hand, if we take two animals that share a ‘parent’ in some taxonomy (e.g., reindeer and deer), then the likelihood of knowledge transfer increases.
",1 Introduction,[0],[0]
"We propose to make use of additional rich background knowledge complementing the information present in the KB itself, such as a taxonomic hierarchy of entities (available from sources such as WordNet (Miller, 1995)) and the corresponding entity types and relation schema.",1 Introduction,[0],[0]
"Our key insight is that, if used appropriately, taxonomic and schema information can be surprisingly effective in making tensor factorization methods vastly more effective for generics for deriving high precision facts.
",1 Introduction,[0],[0]
"Intuitively, for generics, many properties of interest are themselves generic (e.g., living in forests, as opposed to living in a specific forest) and tend to be shared by siblings in a taxonomy (e.g., finch, oriole, and hummingbird).",1 Introduction,[0],[0]
"In contrast, siblings of named entities (e.g., various people) often differ substantially in the properties we typically care about and model (e.g., who they are married to, where they live, etc.).",1 Introduction,[0],[0]
"Methods that use type information are
thus more promising for generics than for classical NLP tasks involving named entities.",1 Introduction,[0],[0]
"We propose three ways of using this information and empirically demonstrate the effectiveness of each on two variants of a KB of elementary level science facts (Dalvi et al., 2017).1
First, we observe that simply imposing schema consistency (Section 3.1) on derived facts can significantly boost state-of-the-art methods such as Holographic Embeddings (HolE) (Nickel et al., 2016b) from nearly no new facts at 80% precision to over 10,000 new facts, starting with a generics KB of a similar size.",1 Introduction,[0],[0]
"Other embedding methods, such as TransE (Bordes et al., 2013), RESCAL (Nickel et al., 2011), and SICTF (Nimishakavi et al., 2016) (which uses schema information as well), also produced no new facts at 80% precision.",1 Introduction,[0],[0]
"Graph-based completion methods did not scale to our densely connected tensors.2
Second, one can further boost performance by transferring knowledge up and down the taxonomic hierarchy, using the quantification semantics of generics (Section 3.2).",1 Introduction,[0],[0]
"We show that expanding the starting tensor this way before applying tensor factorization is complementary and results in a statistically significantly higher precision (86.4% as opposed to 82%) over new facts at the same yield.
",1 Introduction,[0],[0]
"Finally, we propose a novel limited-budget taxonomy guided active learning method to address the challenge of significant incompleteness in generics KBs, by quantifying uncertainty via siblings (Section 4).",1 Introduction,[0],[0]
"Dalvi et al. (2017) have observed that, when using information extraction methods, it is much harder to derive reliable facts about generics than about named entities.",1 Introduction,[0],[0]
"This makes generics KBs vastly incomplete, with no or very little information about certain entities such as caribou or oriole.
",1 Introduction,[0],[0]
1We are unaware of other large generics KBs.,1 Introduction,[0],[0]
"Our method does not employ rules or choices specific to this dataset and is expected to generalize to other generics KBs, as and when they become available.
2On the smaller Animals tensor (to be described later),",1 Introduction,[0],[0]
"PRA (Lao et al., 2011) generated very few high-precision facts after 30 hours.",1 Introduction,[0],[0]
"SFE (Gardner and Mitchell, 2015) was unable to finish training a classifier for any relation after a day, in part due to the high connectivity of generics like animal.",1 Introduction,[0],[0]
"On the other hand, HolE is trained in a couple of minutes even on the larger Science tensor, and can be made even faster using the method of Hayashi and Shimbo (2017).
",1 Introduction,[0],[0]
"Our active learning approach addresses the following question: Given a new entity3 ẽ and a budget B, what is a good set Q of B queries about ẽ to annotate (via humans) such that expanding the original tensor with Q helps a KB completion method infer many more high precision facts about ẽ?
We propose to define a correlation based measure of the uncertainty of each unannotated triple (i.e., a potential query) involving ẽ, based on how frequently the corresponding triple is true for ẽ’s siblings in the taxonomic hierarchy (Section 4.1).",1 Introduction,[0],[0]
"We then develop a submodular objective function, and a corresponding greedy (1 − 1/e)-approximation, to search for a small subset of triples to annotate that optimally balances diversity with coverage (Section 4.2).",1 Introduction,[0],[0]
We demonstrate that annotating this balanced subset makes tensor factorization derive substantially more new and interesting facts compared to several active learning baselines.,1 Introduction,[0],[0]
"For example, with a budget to annotate 100 queries about a new entity oriole, random queries lead to no new true facts at all (via annotation followed by tensor factorization), imposing schema consistency results in 83 new facts, and our proposed method ends up with 483 new facts.",1 Introduction,[0],[0]
"This demonstrates that well-designed intelligent queries can be substantially more effective in gathering facts about the new entity.
",1 Introduction,[0],[0]
"In summary, this work tackles, for the first time, the challenging task of knowledge completion for generics, by imposing consistency with external knowledge.",1 Introduction,[0],[0]
"Our efficient sibling-guided active learning approach addresses the paucity of facts about certain entities, successfully inferring a substantial number of new facts about them.",1 Introduction,[0],[0]
KB completion approaches fall into two main classes: graph-based methods and those employing low-dimensional embeddings via matrix or tensor factorization.,1.1 Related Work,[0],[0]
"The former uses graph traversal techniques to complete the KB, by learning which types of paths or transitions are indicative of which relation between the start and end points (Lao et al., 2011; Gardner and Mitchell, 2015).",1.1 Related Work,[0],[0]
"This class of solutions, unfortunately, does not scale well to
3Unless otherwise stated, we will henceforth use entity to refer to a singular common noun that represents a class or group of individuals, such as animal, hummingbird, forest, etc.
our setting (cf. Footnote 2).",1.1 Related Work,[0],[0]
"This appears due, at least in part, to different connectivity characteristics of generics tensors compared to named entity ones such as FB15k (Bordes et al., 2013).",1.1 Related Work,[0],[0]
"Advances in the latter set of methods have led to several embedding-based methods that are highly successful at KB completion for named entities (Nickel et al., 2011; Riedel et al., 2013; Dong et al., 2014; Trouillon et al., 2016; Nickel et al., 2016a).",1.1 Related Work,[0],[0]
"We compare against many of these, including variants of HolE, TransE, and RESCAL.
",1.1 Related Work,[0],[0]
"Recent work on incorporating entity type and relation schema in tensor factorization (Krompaß et al., 2014; Krompaß et al., 2015; Xie et al., 2016b) has focused on factual databases about named entities, which, as discussed earlier, have very different characteristics than generics tensors.",1.1 Related Work,[0],[0]
Nimishakavi et al. (2016) use entity type information as a matrix in the context of non-negative RESCAL for schema induction on medical research documents.,1.1 Related Work,[0],[0]
"As a byproduct, they complete missing entries in the tensor in a schema-compatible manner.",1.1 Related Work,[0],[0]
"We show that our proposal performs better on generics tensors than their method, SICTF.",1.1 Related Work,[0],[0]
"SICTF, in turn, is meant to be an improvement over the TRESCAL system of Chang et al. (2014), which also incorporates types in RESCAL in a similar manner.",1.1 Related Work,[0],[0]
"Recently, Schütze et al. (2017) proposed a neural model for fine-grained entity typing and for robustly using type information to improve relation extraction, but this is targeted for Freebase style named entities.
",1.1 Related Work,[0],[0]
"For schema-aware discriminative training of embeddings, Xie et al. (2016b) use a flexible ratio of negative samples from both schema consistent and schema inconsistent triples.",1.1 Related Work,[0],[0]
"Their combined ideas, however, do not improve upon vanilla HolE (one of our baselines) on the standard FB15k (Bordes et al., 2013) dataset.",1.1 Related Work,[0],[0]
"They also consider imposing hierarchical types for Freebase, as entities may have different meanings when they have different types— an issue that typically does not apply to generics KBs.",1.1 Related Work,[0],[0]
Komninos and Manandhar (2017) use type information along with additional textual evidence for knowledge base completion on the FB15k237 dataset.,1.1 Related Work,[0],[0]
"They learn embeddings for types, along with entities and relations, and show that this way of incorporating type information has a (small) contribution towards improving performance.",1.1 Related Work,[0],[0]
"Incorpo-
rating given first order logic rules has been explored for the simpler case of matrix factorization (Rocktaschel et al., 2015; Demeester et al., 2016).",1.1 Related Work,[0],[0]
"Existing first order logic rule extraction methods, however, struggle to find meaningful rules for generics, making this approach not yet viable in our setting.
",1.1 Related Work,[0],[0]
Xie et al. (2016a) consider inferring facts about a new entity ẽ given a ‘description’ of that entity.,1.1 Related Work,[0],[0]
"They use Convolutional Neural Networks (CNNs) to encode the description, deriving an embedding for ẽ. Such a description in our context would correspond to knowing some factual triples about ẽ, which is a restricted version of our active learning setting.
Krishnamurthy and Singh (2013) consider active learning for a particular kind of tensor decomposition, namely CP or Candecomp/Parafac decomposition into a low dimensional space.",1.1 Related Work,[0],[0]
They start with an empty tensor and look for the most informative slices and columns to fill completely to achieve optimal sample complexity.,1.1 Related Work,[0],[0]
"Their framework builds upon the incoherence assumption on the column space, which does not apply to generics KB.
Hegde and Talukdar (2015) use an entity-centric information extraction (IE) approach for obtaining new facts about entities of interest.",1.1 Related Work,[0],[0]
Narasimhan et al. (2016) use a reinforcement learning approach to issue search queries to acquire additional evidence for a candidate fact.,1.1 Related Work,[0],[0]
"Both of these works, and others along similar lines, are advanced IE techniques that operate via a search for new documents and extraction of facts from them.",1.1 Related Work,[0],[0]
"This is different from the KB completion task, where the only source of information is the starting KB and possibly some details about the involved entities and relations.",1.1 Related Work,[0],[0]
"We consider knowledge expressed in terms of (source, relation, target) triples, abbreviated as (s, r, t).",2 Tensors of Generics,[0],[0]
"Such a triple may refer to (subject, predicate, object) style facts commonly used in information extraction.",2 Tensors of Generics,[0],[0]
"Each source and target is an entity that is a generic noun, e.g., animals, habitats, or food items.",2 Tensors of Generics,[0],[0]
"Examples of relations include foundIn, eat, etc.",2 Tensors of Generics,[0],[0]
"As mentioned earlier, with each generics triple (s, r, t), we associate a categorical truth value q ∈",2 Tensors of Generics,[0],[0]
"{all, some, none}, defining the quantification semantics “q s r (some) t”.",2 Tensors of Generics,[0],[0]
"For instance, “some an-
imals live in (some) forest” and “all dogs eat (some) bone”.",2 Tensors of Generics,[0],[0]
"Given a set K of such triples with annotated truth values, the task is to predict additional triples K ′",2 Tensors of Generics,[0],[0]
"that are also likely to be true.
",2 Tensors of Generics,[0],[0]
"In addition to a list of triples, we assume access to background information in the form of entity types and the corresponding relation schema, as well as a taxonomic hierarchy.4 Let ET denote the set of possible entity types.",2 Tensors of Generics,[0],[0]
"For each relation r, the relation schema imposes a type constraint on the entities that may appear as its source or target.",2 Tensors of Generics,[0],[0]
"Specifically, using [`] to denote the set {1, 2, . . .",2 Tensors of Generics,[0],[0]
", `}, the schema for r is a collection Sr = {(D(i)r ,R(i)r ) ⊆ ET × ET",2 Tensors of Generics,[0],[0]
| i ∈,2 Tensors of Generics,[0],[0]
"[`]} of domain-range pairs with the following property: the truth value of (s, r, t) is none whenever for every",2 Tensors of Generics,[0],[0]
i ∈,2 Tensors of Generics,[0],[0]
[`] it is the case that s /∈,2 Tensors of Generics,[0],[0]
D(i)r or t /∈,2 Tensors of Generics,[0],[0]
R(i)r .,2 Tensors of Generics,[0],[0]
"For example, the relation foundIn may be associated with the schema SfoundIn = {(animal, location), (insect, animal), (plant, habitat), . . .",2 Tensors of Generics,[0],[0]
}.,2 Tensors of Generics,[0],[0]
"Similarly, the taxonomic hierarchy defines a partial order H over all entities that captures the “isa” relation, with direct links such as isa(dog, mammal) or isa(gerbil, rodent).",2 Tensors of Generics,[0],[0]
"We use this information to extract “siblings” of a given entity, i.e., entities that share a common parent (this may be easily generalized to any common ancestor).",2 Tensors of Generics,[0],[0]
We begin with an overview of tensor factorization for KB completion for generics.,3 Guided Knowledge Completion,[0],[0]
"Let (s, r, t) be a generics triple associated with a categorical quantification label q ∈ {all, some, none}.",3 Guided Knowledge Completion,[0],[0]
"For example, ((cat, havePart, whiskers), all), ((cat, liveIn, homes), some), and ((cat, eat, bear), none).",3 Guided Knowledge Completion,[0],[0]
Predicting such labels is thus a multi-class classification problem.,3 Guided Knowledge Completion,[0],[0]
"Given a set K of labeled triples, the goal of tensor factorization is to learn a low-dimensional embedding h for each entity and relation such that some function f of h best captures the given labels.",3 Guided Knowledge Completion,[0],[0]
"Given a new triple, we can then use f and the learned h to predict the probability of each label for it.",3 Guided Knowledge Completion,[0],[0]
"K often contains only “positive” triples, i.e., those with label all or some.",3 Guided Knowledge Completion,[0],[0]
"A common step in discriminative training for h is thus negative sampling, i.e., generating additional triples that (are expected to) have
4We do not assume that the schema or taxonomy is perfect, and instead rely on these only for heuristic guidance.
",3 Guided Knowledge Completion,[0],[0]
label none.,3 Guided Knowledge Completion,[0],[0]
"With [m] denoting the set {1, 2, . . .",3 Guided Knowledge Completion,[0],[0]
",m} as before, let K = {(xi, yi),",3 Guided Knowledge Completion,[0],[0]
i ∈,3 Guided Knowledge Completion,[0],[0]
[m]} be a set of triples,3 Guided Knowledge Completion,[0],[0]
"xi = (si, ri, ti) and corresponding labels",3 Guided Knowledge Completion,[0],[0]
"yi ∈ {1, 2, 3} equivalent to categorical quantification label qi ∈ {all, some, none}.",3 Guided Knowledge Completion,[0],[0]
"We learn entity and relation embeddings Θ that minimize the multinomial logistic loss defined as:
min Θ
m∑
i=1
3∑
k=1
−1{yi = k} log Pr(yi = k | xi,Θ)
=",3 Guided Knowledge Completion,[0],[0]
"min Θ
m∑
i=1
3∑
k=1
−1{yi = k} log σ(yi f(hr, hs, ht))
(1)
where hr, hs, ht ∈ Rd denote the learned embeddings (latent vectors) for s, r, t, respectively, and σ(·) is the sigmoid function defined as σ(z) =
1 1+exp(−z) .
",3 Guided Knowledge Completion,[0],[0]
"If the all categorical label for generics is unavailable,5 we can simplify the label space to {some, none}, modeled as yi ∈ {±1}, and reduce the model to binary classification:
min Θ
m∑
i=1
log [1 + exp",3 Guided Knowledge Completion,[0],[0]
"[−yi f(hr, hs, ht)]] .",3 Guided Knowledge Completion,[0],[0]
"(2)
We remark that while this generics task with only two labels appears superficially similar to the standard KB completion task for named entities, the underlying challenges and solutions are different.",3 Guided Knowledge Completion,[0],[0]
"For instance, the approach of using taxonomic information (as opposed to just entity types) as a guide is uniquely suited to generics KBs; the reason being that a generic entity refers to a set of individuals, with a natural subset/superset relation forming a taxonomy, whereas in standard KBs an entity refers to one specific individual.",3 Guided Knowledge Completion,[0],[0]
"This prevents taxonomy based rules from providing useful information for standard KBs, while our results demonstrate their high value when reasoning with generics.",3 Guided Knowledge Completion,[0],[0]
"Differences like this lead to differences in what is successful in each setting and what is not.
",3 Guided Knowledge Completion,[0],[0]
"5This happens to be the case for current generics KBs, but is expected to change with increasing interest in the research community.",3 Guided Knowledge Completion,[0],[0]
"A step in this direction is a recent version of the Aristo Tuple KB, http://allenai.org/data/aristo-tuple-kb, which includes most as a quantification label, in addition to some.
",3 Guided Knowledge Completion,[0],[0]
"While all our proposed schemes are embedding oblivious, for concreteness, we describe and evaluate them for the Holographic Embedding or HolE (Nickel et al., 2016b) which models the label probability as:
f(hr, hs, ht) = h > r",3 Guided Knowledge Completion,[0],[0]
"(hs ◦ ht) (3)
where ◦ : Rd × Rd → Rd denotes circular correlation defined as:
[a ◦ b]k = d−1∑
i=0
aib(i+k) mod d .",3 Guided Knowledge Completion,[0],[0]
"(4)
Intuitively, the k-th dimension of circular correlation captures how related a is to b when the dimensions of the latter are shifted (circularly, via the mod operation) by k.",3 Guided Knowledge Completion,[0],[0]
In particular [a ◦ b]0 is simply the dot product of a and b.,3 Guided Knowledge Completion,[0],[0]
As can be deduced from Eqns.,3 Guided Knowledge Completion,[0],[0]
"(3)-(4), this model resembles circular convolution, but can capture, to some extent, relations that are asymmetric among the source and target entities.",3 Guided Knowledge Completion,[0],[0]
This is because [a ◦ b] is not the same as [b ◦a] but is rather “flipped” ([a◦b]k = [b◦a]d−k).,3 Guided Knowledge Completion,[0],[0]
"If we consider the d × d matrix Mab of element-wise relationships between a and b, the HolE embedding of a relation r between a and b defines a weighted sum of circular anti-diagonals of Mab.
",3 Guided Knowledge Completion,[0],[0]
"Circular correlation can be computed using the fast Fourier transform (FFT), making HolE quite efficient in practice.",3 Guided Knowledge Completion,[0],[0]
"Hayashi and Shimbo (2017) recently showed that HolE and complex embeddings (Trouillon et al., 2016), which is another stateof-the-art method for KB completion, are equivalent and differ only in terms of constraints on initial values.",3 Guided Knowledge Completion,[0],[0]
"Further, they proposed a linear time computation for HolE by staying fully within the frequency domain of FFT.",3 Guided Knowledge Completion,[0],[0]
"As described earlier, relation schema Sr imposes a restriction on sources and targets that may occur with a relation r.",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
We can incorporate this knowledge both at training and at test times.,3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
Doing this at test time simply translates to relabeling schemainconsistent predicted triples as none.,3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"Incorporating this knowledge at training time can be done as a constraint on the random negative samples that
the method generates to complement the given, typically positive, triples for training.
",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"In general, the ratio of random negative samples from the entire tensor T and random negative samples from the schema consistent portion T ′ of T is a parameter that should be tuned such that the resulting negative samples mimic the true distribution of labels.",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
It is worth noting that whether the locally closed world assumption (LCWA) holds or not plays an important role in determining this ratio.,3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"However, the idea of mixing the two kinds of negative samples has been used in the literature without considering the nature of the dataset, resulting in some seemingly contradicting empirical results on the optimal ratio (Li et al., 2016; Xie et al., 2016b; Shi and Weninger, 2017; Xie et al., 2017).",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"As discussed later, we found sampling from T to work best on our datasets.",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"It is challenging to come up with complex Horn or first order logic rules for generics, as each entity represents a class of individuals that may not all behave identically.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"However, we can derive simple yet highly effective rules based on categorical quantification labels, leveraging the fact that entities come from different levels in a taxonomy hierarchy.
",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
Let p be the parent entity for entity set {ci}.,3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"Note that ci itself is a generic, that is, a class of individuals rather than a single individual.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"This allows one to make meaningful existential statements such as: if a property holds for all or most members of even one class ci, then it holds for some (reasonable number of) members of its parent class p.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"We use the following rules:6
((p, rj , tj), all)⇒ ∀i ((ci, rj , tj), all) ∀i ((ci, rj , tj), all)⇒ ((p, ej , tj), all) ∃i",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"((ci, rj , tj), all)⇒ ((p, ej , tj), some)
∃i",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"((ci, rj , tj), some)⇒ ((p, ej , tj), some)
",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"We apply these rules to address sparsity of generics tensors, making tensor factorization more robust.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"Specifically, given initial triples K, we use applicable rules to derive additional triples K ′, perform
6The last rule may not be appropriate for KBs where some may refer to the extreme case of a single individual.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"This is not the case for the KBs we use for our evaluation.
tensor factorization on K ∪K ′, and then revisit the triples in K ′ using their predicted label probabilities.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"Note that this approach allows us to be robust to taxonomic errors: instead of assuming each triple in K ′ is true, we use this only as a prior and let tensor factorization determine the final prediction based on global patterns it finds.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"To address the incomplete nature of generics KBs, we consider rare entities for which we have very few facts, or new entities which are present in the taxonomy but for which we have no facts in the KB.",4 Active Learning for New or Rare Entities,[0],[0]
"The goal is to use tensor factorization to generate high quality facts about such entities.
",4 Active Learning for New or Rare Entities,[0],[0]
"For instance, consider the task of inferring facts about oriole, where all we know is that it is a bird.",4 Active Learning for New or Rare Entities,[0],[0]
"We assume a restricted budget on the number of facts we can query (for human annotation) about oriole, using which we would like to predict many more high-quality facts about it.
",4 Active Learning for New or Rare Entities,[0],[0]
"Given a fixed query budget B, what is the optimal set of queries we should generate for human annotation about a new or rare entity ẽ for this task?",4 Active Learning for New or Rare Entities,[0],[0]
We view this as an active learning problem and propose a two-step algorithm.,4 Active Learning for New or Rare Entities,[0],[0]
"First, we use taxonomy guided uncertainty sampling to propose a list L to potentially query.",4 Active Learning for New or Rare Entities,[0],[0]
"Next, we describe a submodular objective function and a corresponding linear time algorithm to choose an optimal subset L̂ ⊆ L satisfying |L̂| = B. We then use L̂ for human annotation, append the result to the original KB, and perform tensor factorization to predict additional new facts about ẽ. For notational simplicity and without loss of generality, throughout this section, we consider the case where ẽ appears as the source entity in the triple; the ideas apply equally when ẽ appears as the target entity in the triple.",4 Active Learning for New or Rare Entities,[0],[0]
We now discuss the active learning and specifically uncertainty sampling method we use to propose a list of triples to query.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Uncertainty sampling considers the uncertainty for each possible triple (ẽ, ri, ei), defined as how far away from 0.5 the conditional probability is of this fact, given the facts we already
know from the KB (Settles, 2012).",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
The question is how to model this conditional probability.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"A simple baseline is to consider Random queries, i.e., r, e are selected randomly from the list of relations and entities in the tensor, respectively.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"To infer information about ẽ, we propose the following approximation for the conditional probability of a new fact about ẽ given the KB.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Let Ẽẽ = {e | corr(ẽ, e) > 0} be the set of entities that are correlated with ẽ, Ω = {((ei, ri, e′i), yi)",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"| ei ∈ Ẽẽ} be the set of known facts about such entities, and yi be the label for the triple (ei, ri, e′i).",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"We have:
Pr(f(hri , hẽ, he′i)) ' 1 |Ω| ∑
ei∈Ẽẽ
corr(ẽ, ei) yi.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(5)
However, in practice, we cannot measure corr(ẽ, ei) for every entry in the KB as we do not have complete information about ẽ. One simple idea is to consider that every entity is correlated with ẽ: corr(ẽ, ei) = 1 ∀ei ∈ E.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"We will refer to this as Schema Consistent query proposal as this relates to summing over all possible (hence schema consistent) facts.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Since we have access to taxonomy information, we can do a more precise, Sibling Guided, approximation.7",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"We propose the following approximation for corr(ẽ, ei) for ei ∈ E:
corr(ẽ, ei) =",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
{ 1 if ei ∈ sibling(ẽ) 0,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
otherwise .,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(6)
Eqns.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(5) and (6) can be used to infer uncertain triples: if every sibling of ẽ has relationship r with an entity e′, we can infer for “free” that this is the case for ẽ as well.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"On the other hand, when siblings disagree in this respect, there is more uncertainty about (ẽ, r, e′)",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(according to (5) and (6)), making this triple a good candidate to query.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"In our example of oriole, the siblings are the birds that exist in the tensor, e.g., hummingbird, finch, woodpecker, etc.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"All of them (eat, insect) and hence we infer this for oriole.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"But there is no agreement on (appearIn, farm) and hence this is added to the query list.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
7One may also define corr based on entity similarity in a distributional space.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
One challenge here is that such similarity generally doesn’t preserve types.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"For example, dog may cooccur more often with and thus be “closer” to bone or barking in a distributional space, than to siblings such as cat or other pet animals, which are more helpful in our setting.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Algorithm 1: Active Learning for Query Proposal
input new entity ẽ, KB, taxonomy, lower bound κM on agreement, lower bound τL on uncertainty, upper bound τU on uncertainty
1: extract list Sẽ of sibling(ẽ) using taxonomy 2: for each ei ∈ Sẽ, add all facts about ei to Ω 3: for (ẽ, ri, e′i) ∈ Ω do 4: use (5)-(6) to estimate Pr(f(hri , hẽ, he′i)) 5",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
: if p ≥ κM,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"then add (ẽ, ri, e′i) to M 6: if τL ≤ p ≤ τU then add (ẽ, ri, e′i) to L
output L, M
Algorithm 1 formalizes this process.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Setting some upper (τU ) and lower (τL) bounds on the conditional probability (Eqn. (5)) which quantifies the uncertainty, we reach a set L = {(ẽ, ri, ei), i ∈",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
I} of triples to query.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
Using another high threshold κM,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"> τU , we also infer the set M = {(ẽ, rj , ej), j ∈ J} of triples that a large majority of siblings agree upon, and hence ẽ is expected to agree with as well.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
Triples whose conditional probability estimate is between κM and τU are considered neither certain enough to include in M nor uncertain enough to justify adding to L for human annotation in hopes of learning from it.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Similarly, triples with a conditional probability estimate lower than τL are discarded.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
The output of Algorithm 1 is the list L to query and the list M to add directly to the knowledge base.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Given the list L as above (Algorithm 1), which we can write in short as L = {(ri, ei), i ∈",4.2 Efficient Subset Selection,[0],[0]
"I}, the problem is to find the “best” subset L̂. A baseline for such a selection is to choose the top k queries.",4.2 Efficient Subset Selection,[0],[0]
"We will refer to this as TK subset selection.
",4.2 Efficient Subset Selection,[0],[0]
"Viewing subset selection as a combinatorial problem, we devise an objective F that models several natural properties of this subset.",4.2 Efficient Subset Selection,[0],[0]
"We then prove that F is submodular, that is, the marginal gain inF(L) obtained by adding one more item to L decreases as L grows.8",4.2 Efficient Subset Selection,[0],[0]
"Importantly, this implies that there is a simple known greedy algorithm that can efficiently compute a worst-case (1 − 1/e)-approximation of
8Formally, for L′′ ⊆ L′",4.2 Efficient Subset Selection,[0],[0]
"⊆ L and for l = (rl, el) ∈",4.2 Efficient Subset Selection,[0],[0]
"L \ L′, we have F(L′′ ∪ l)−F(L′′) ≥ F(L′ ∪ l)−F(L′).
",4.2 Efficient Subset Selection,[0],[0]
"the global optimum of F (Nemhauser et al., 1978).",4.2 Efficient Subset Selection,[0],[0]
"We refer to this as SM subset selection.
",4.2 Efficient Subset Selection,[0],[0]
"Since queried samples will eventually be fed into tensor factorization, we would like L̂ to cover entities (for the other argument of the triple) and relations as much as possible.",4.2 Efficient Subset Selection,[0],[0]
"In addition, we would like L̂ to be diverse, i.e., prioritize relations and entities that are more varied.9",4.2 Efficient Subset Selection,[0],[0]
"At the same time, we would also want to minimize redundancy, i.e., avoid choosing relations (entities) that are too similar.",4.2 Efficient Subset Selection,[0],[0]
"Let F(L̂, R
L̂ , E L̂ ) denote our objective, where R L̂ , E L̂
is the set of relations and entities in L̂, respectively.",4.2 Efficient Subset Selection,[0],[0]
"We decompose it as:
F(L̂, R L̂ , E L̂ ) = wCC(L̂, RL̂, EL̂) (7)
+ wDD(L̂, RL̂, EL̂)− wRR(L̂, RL̂, EL̂)
where the terms in RHS correspond to coverage, diversity, and redundancy, respectively, and wC , wD, wR are the corresponding non-negative weights.",4.2 Efficient Subset Selection,[0],[0]
"Next, we propose functional forms for these terms.",4.2 Efficient Subset Selection,[0],[0]
"Note that any function that captures the described properties can be used instead, as long as the objective remains submodular.
",4.2 Efficient Subset Selection,[0],[0]
"Let R and E denote the set of relations and entities in the KB, respectively.",4.2 Efficient Subset Selection,[0],[0]
"The coverage simply captures the fraction of entity and relations that we have included in L̂:
C(L̂, R L̂ , E L̂ ) = |R",4.2 Efficient Subset Selection,[0],[0]
L̂ | |R| + |E,4.2 Efficient Subset Selection,[0],[0]
"L̂ | |E| .
",4.2 Efficient Subset Selection,[0],[0]
"The diversity for L̂ is the sum of the diversity measure of the entities and relations included in the set:
D(L̂, R L̂ , E L̂ ) =
∑
(r,e)∈L̂
",4.2 Efficient Subset Selection,[0],[0]
"[Vr + Ve] ,
Vr = |ESr |+",4.2 Efficient Subset Selection,[0],[0]
|ETr,4.2 Efficient Subset Selection,[0],[0]
"| |E| , Ve = |Re|+ |ESe | |R|+ |E| .
",4.2 Efficient Subset Selection,[0],[0]
"Here Vr and Ve represent the diversity measure of relation r and entity e, respectively.",4.2 Efficient Subset Selection,[0],[0]
"We use ESr , ETr to denote the set of sources and targets that appear
9This agrees with the sampling method of Chen et al. (2014) for factorizing coherent matrices with missing values, which chooses samples with probability proportional to their local coherence.
",4.2 Efficient Subset Selection,[0],[0]
Algorithm 2:,4.2 Efficient Subset Selection,[0],[0]
"Query Subset Selection input KB, budget B, query list L from Alg. 1.
1: ∀(r, e) ∈ L, compute the diversity measure Vr, Ve 2: L̂← ∅ 3: for j = 1 to B do 4: ∀l ∈ L \ L̂ : G(l) = F(L̂ ∪ l)−F(L̂), for F in (7) 5:",4.2 Efficient Subset Selection,[0],[0]
"Select l∗ = arg max
L\L̂ G(l) 6: Add l∗ to L̂
output L̂
for relation r in the KB, Re as the set of relations in the KB that have e as their target, and ESe as the set of entities that appear as the first entity when e is the second entity of the triple in the KB.",4.2 Efficient Subset Selection,[0],[0]
"The diversity measure for each relation r is defined as the ratio of the number of entities that appear in the KB as its source or target, over the total number of entities.",4.2 Efficient Subset Selection,[0],[0]
"Similarly, for an entity e, its diversity is defined as the ratio of the number of relations involving e plus the number of source entities that co-occur with e in a relation, over the total number of relations and entities.",4.2 Efficient Subset Selection,[0],[0]
"Note that the diversity measure is an intrinsic characteristic of each entity and relationship, dictated by the KB and independent of the set L, and can thus be computed in advance.
",4.2 Efficient Subset Selection,[0],[0]
"As described above, redundancy is a measure of similarity between relations(entities) in L̂. Tensor factorization yields an embedding for each relation(entity) given the facts they participated in.",4.2 Efficient Subset Selection,[0],[0]
"Therefore, the learned embeddings are one of the best options for capturing similarities.",4.2 Efficient Subset Selection,[0],[0]
"Let he (and hr) denote the learned embedding for entity e (and relation r, resp.).",4.2 Efficient Subset Selection,[0],[0]
"We define
R(L̂, R L̂ , E L̂ ) =
∑
r1,r2∈L̂
‖hr1",4.2 Efficient Subset Selection,[0],[0]
"− hr2‖
+ ∑
e1,e2∈L̂
‖he1 − he2‖.
This completes the definition of all pieces of our objective function, F , from Eqn.",4.2 Efficient Subset Selection,[0],[0]
(7).,4.2 Efficient Subset Selection,[0],[0]
"In Algorithm 2, we present our efficient greedy method to select a subset of L that approximately optimizes F .
",4.2 Efficient Subset Selection,[0],[0]
"Despite being a greedy approach that simply adds the currently most valuable single query to L̂ and
repeats, the submodular nature of F , which we will prove shortly, guarantees that Algorithm 2 provides an approximation that, even in the worse case, is no worse than a factor of 1 − 1/e from the (unknown) true optimum of F .",4.2 Efficient Subset Selection,[0],[0]
This is formalized in the following theorem.,4.2 Efficient Subset Selection,[0],[0]
"Since addition preserves submodularity and the weights wC , wD, wR are non-negative, we will show that each of the three terms in F is submodular.
",4.2 Efficient Subset Selection,[0],[0]
Theorem 1.,4.2 Efficient Subset Selection,[0],[0]
"Given a tensor KB, a budget B, and a candidate query list L, the quality F(L̂, R
L̂ , E L̂ )
of the output L̂ of Algorithm 2 is a (1 − 1/e)approximation of the global optimum of F .",4.2 Efficient Subset Selection,[0],[0]
Proof.,4.2 Efficient Subset Selection,[0],[0]
"In order to prove the result, it suffices to show that F(L̂, R
L̂ , E L̂ ) in Equation (7) is submod-
ular (Nemhauser et al., 1978).",4.2 Efficient Subset Selection,[0],[0]
"To this end, we show that for L′′ ⊆ L′ ⊆ L and for l = (rl, el) ∈",4.2 Efficient Subset Selection,[0],[0]
"L \ L′,
F(L′′ ∪ l)−F(L′′) ≥ F(L′ ∪ l)−F(L′).
",4.2 Efficient Subset Selection,[0],[0]
"Since addition preserves submodularity and the weights wC , wD, wR are non-negative, it suffices to show that each term in F is submodular.
",4.2 Efficient Subset Selection,[0],[0]
"First, consider the coverage term, C(L̂, R L̂ , E L̂ ).
",4.2 Efficient Subset Selection,[0],[0]
"In order to prove that it is submodular, we verify:
(|RL′′∪l| − |RL′′ |)",4.2 Efficient Subset Selection,[0],[0]
|R| ≥ (|RL′∪l| − |RL′ |),4.2 Efficient Subset Selection,[0],[0]
"|R| , (|EL′′∪l| − |EL′′",4.2 Efficient Subset Selection,[0],[0]
|),4.2 Efficient Subset Selection,[0],[0]
"|E| ≥ (|EL′∪l| − |EL′ |) |E| .
",4.2 Efficient Subset Selection,[0],[0]
"Note that for the numerators of each of the above lines, the difference can be either +1 or 0.",4.2 Efficient Subset Selection,[0],[0]
"Since L′′ ⊂ L′, LHS is, by definition, never less than RHS and the inequalities holds.
",4.2 Efficient Subset Selection,[0],[0]
"Next, consider the diversity term, D(L̂, R L̂ , E L̂ ).",4.2 Efficient Subset Selection,[0],[0]
The above argument directly applies here as well.,4.2 Efficient Subset Selection,[0],[0]
"Finally, consider the redundancy term.",4.2 Efficient Subset Selection,[0],[0]
"In order to show that −R(L̂, R L̂ , E L̂ ) is submodular, note that when taking the difference between R(L′′ ∪ l) and R(L′′) the terms that correspond to both entities (or both relations) being in L′′ cancel out.",4.2 Efficient Subset Selection,[0],[0]
The same holds forR(L′ ∪ l)−R(L′).,4.2 Efficient Subset Selection,[0],[0]
"We thus have: R(L′′ ∪ l)−R(L′′) =
∑
rl∈l,r2∈L′′ ‖hr1",4.2 Efficient Subset Selection,[0],[0]
"− hr2‖+
∑
el∈l,e2∈L′′ ‖he1",4.2 Efficient Subset Selection,[0],[0]
"− he2‖
R(L′ ∪ l)−R(L′) = ∑
rl∈l,r2∈L′",4.2 Efficient Subset Selection,[0],[0]
‖hr1,4.2 Efficient Subset Selection,[0],[0]
"− hr2‖+
∑
el∈l,e2∈L′ ‖he1 − he2‖.
Since L′′ ⊆ L′ and norms are non-negative,
R(L′′ ∪ l)−R(L′′) ≤ R(L′ ∪ l)−R(L′).
",4.2 Efficient Subset Selection,[0],[0]
"The reverse inequality holds for the negation of both sides, proving that −R(L̂, R
L̂ , E L̂ ) is submodular.
",4.2 Efficient Subset Selection,[0],[0]
Combining the three items concludes the proof.,4.2 Efficient Subset Selection,[0],[0]
We will complement this theoretical guarantee in the experiments section (cf. Table 3) by empirically comparing the performance of our query proposal and subset selection methods with baselines.,4.2 Efficient Subset Selection,[0],[0]
"We begin with a description of the datasets and the general setup, then evaluate the effectiveness of our guided KB completion approach, and end with an evaluation of our active learning method.10",5 Experiments,[0],[0]
"To assess the quality of our guided KB completion method, we consider the only large existing knowledge bases about generics that we are aware of:
1.",5.1 Dataset and Setup,[0],[0]
"A Science tensor containing facts about various scientific activities, entities (e.g., animals, instruments, body parts), units, locations, occupations, etc.",5.1 Dataset and Setup,[0],[0]
"(Dalvi et al., 2017).11",5.1 Dataset and Setup,[0],[0]
This starting tensor has a precision of about 80% and acts as a valuable resource for challenging tasks such as question answering.,5.1 Dataset and Setup,[0],[0]
"Our goal is to start with this tensor and infer more scientific facts at a similar or higher level of precision.
",5.1 Dataset and Setup,[0],[0]
2.,5.1 Dataset and Setup,[0],[0]
An Animals sub,5.1 Dataset and Setup,[0],[0]
"-tensor of the Science tensor, which focuses on facts about animals and also has a similar starting precision.",5.1 Dataset and Setup,[0],[0]
"Again, the goal is to infer more facts about animals.
",5.1 Dataset and Setup,[0],[0]
The mainstream approach for KB completion is to focus on entities that are mentioned sufficiently often.,5.1 Dataset and Setup,[0],[0]
"For instance, the commonly used FB15K dataset guarantees that every entity appears at least 100 times.",5.1 Dataset and Setup,[0],[0]
"As a milder version of this, we focus on the subset of the starting tensors where every entity appears at least 20 times.",5.1 Dataset and Setup,[0],[0]
"The resulting statistics of the tensors we use here are shown in Table 1.
10Data and code available from the authors.",5.1 Dataset and Setup,[0],[0]
"11Aristo Tuple KB v0, http://allenai.org/data/aristo-tuple-kb.
",5.1 Dataset and Setup,[0],[0]
"This data, which is the only one we are aware of with generics, does not include ((s, r, t), all) style triples.",5.1 Dataset and Setup,[0],[0]
We therefore use the objective function in Eqn.,5.1 Dataset and Setup,[0],[0]
(2) rather than the multi-class one in Eqn. (1).,5.1 Dataset and Setup,[0],[0]
"Despite this limitation of the dataset and its superficial similarity to the binary classification task underlying standard (non-generics) KB completion, our results reveal that extending a generics KB is surprisingly difficult for existing methods.
",5.1 Dataset and Setup,[0],[0]
"Dalvi et al. (2017) use a pipeline consisting of Open IE (Banko et al., 2007) extractions, aggregation, and clean up via crowd-sourcing to generate the Science tensor.",5.1 Dataset and Setup,[0],[0]
"These facts come with a relevant WordNet (Miller, 1995) based taxonomy, entity types (derived from WordNet ‘synsets’), and relation schema.",5.1 Dataset and Setup,[0],[0]
"Our method capitalizes on this additional information12 to perform high quality knowledge completion.
",5.1 Dataset and Setup,[0],[0]
Our evaluation metric is the accuracy of the top k triples generated by various KB completion methods.,5.1 Dataset and Setup,[0],[0]
"We also visualize entire precision-recall curves, where possible.",5.1 Dataset and Setup,[0],[0]
"While this metric requires human annotation and is thus more cumbersome than fullyautomatic metrics, it is arguably more suitable for evaluating generative tasks with a massive output space, such as KB completion.",5.1 Dataset and Setup,[0],[0]
"In this setting, evaluation against a relatively small held out test set can be misleading—a method may be highly accurate at generating thousands of valid and useful triples even if it does not necessarily classify specific held out instances accurately.",5.1 Dataset and Setup,[0],[0]
"While measures such MAP and MRR have been used in the past to alleviate this, they provide only a partial solution to the inherent difficulty of evaluating generative systems.",5.1 Dataset and Setup,[0],[0]
"Annotation-efficient evaluation methods have recently been proposed to address this challenge (Sabharwal and Sedghi, 2017).
",5.1 Dataset and Setup,[0],[0]
"12In order to limit potential error propagation, we collapse the taxonomy to the top two levels in our experiments.",5.1 Dataset and Setup,[0],[0]
"We first compare our method (Section 3) with existing KB completion techniques on the Animals tensor, and then demonstrate that its effectiveness carries over scalably to the larger Science tensor as well.",5.2 Guided KB Completion,[0],[0]
"In what follows, T denotes the tensor under consideration.
",5.2 Guided KB Completion,[0],[0]
"We examine two alternatives for generating negative samples: given a triple (s, r, t) ∈ T , replace s with (1) any entity s′ or (2) an entity s′ of the same type as s.",5.2 Guided KB Completion,[0],[0]
"The resulting perturbed triple (s′, r, t) is then treated as a negative sample if it is not present in T .",5.2 Guided KB Completion,[0],[0]
"We also considered a weighted combination of (1) and (2), and found random sampling to be the most reliable on our datasets.",5.2 Guided KB Completion,[0],[0]
"This complies with the commonly used LCWA assumption not being applicable to these tensors.
",5.2 Guided KB Completion,[0],[0]
"As baselines, we consider extensions of three state-of-the-art embedding-based KB completion methods: HolE, TransE, and RESCAL.",5.2 Guided KB Completion,[0],[0]
"As mentioned earlier, two leading graph-based methods, SFE and PRA, did not scale well.",5.2 Guided KB Completion,[0],[0]
Both vanilla TransE and RESCAL resulted in poor performance; we thus report numbers only for their extensions.,5.2 Guided KB Completion,[0],[0]
"Specifically, we consider 3 baselines: (1) HolE, (2) TransE+Schema, and (3) SICTF which extends
RESCAL and incorporates schema.",5.2 Guided KB Completion,[0],[0]
Figure 1 shows the resulting precision-yield curves for the predictions made by each method on the Animals dataset containing 10.6K facts.,5.2 Guided KB Completion,[0],[0]
"Specifically, for each method, we rank the predictions based on the method’s assigned score and compute the precision of the top k predictions for varying k.",5.2 Guided KB Completion,[0],[0]
"As expected, we observe a generally decreasing trend as k increases.",5.2 Guided KB Completion,[0],[0]
TransE+ITRS gave a precision of only around 10% and is omitted from the plot.,5.2 Guided KB Completion,[0],[0]
"We make two observations:
First, deriving new facts for these generics tensors at a high precision is challenging!",5.2 Guided KB Completion,[0],[0]
"Specifically, none of the baseline methods (black and pink curves), which represent state of the art for named-entity tensors, achieve a yield of more than 10% of T (i.e., 1K predictions) even at a precision of just 60%.
",5.2 Guided KB Completion,[0],[0]
"Second, external information, if used appropriately, can be surprisingly powerful in this setting.",5.2 Guided KB Completion,[0],[0]
"Specifically, simply incorporating relation schema (ITRS, blue curve) allows HolE-based completion to double the size of the starting tensor T by producing over 10K new triples at a precision of 82%.",5.2 Guided KB Completion,[0],[0]
"Further, incorporating entity taxonomy (IET, green
curve) to address tensor sparsity results in the same yield at a statistically significantly higher precision of 86.4%.
",5.2 Guided KB Completion,[0],[0]
"It turns out that not only does our method result in substantially improved PR curves, it also generates qualitatively more interesting and useful generic facts about the world than previous methods.",5.2 Guided KB Completion,[0],[0]
"We illustrate this in Table 2, which lists the top 20 predictions made by various approaches.",5.2 Guided KB Completion,[0],[0]
"The triples shown in red are false predictions (e.g., (penguin, has part, tooth), (grass, graze in, man), (caterpillar, turn into, bird)) or uninteresting ones (e.g., (water, is known as, water)).",5.2 Guided KB Completion,[0],[0]
"As we see, a vast majority of the top 20 predictions made by both vanilla HolE and SICTF fall into these categories.",5.2 Guided KB Completion,[0],[0]
"On the other hand, our method, HolE+ITRS+IET, predicts 19 true tripes out of the top 20, including interesting scientific facts that were evidently missing from the starting tensor, such as (salmon, thrive in, water), (fish, swim in, ocean) and (insect, destroy, tree).
",5.2 Guided KB Completion,[0],[0]
"Finally, we evaluate our proposal on the entire Science dataset with 66.6K facts.",5.2 Guided KB Completion,[0],[0]
"Since graph-based methods did not scale well to the much smaller Animals dataset and other methods performed substan-
tially worse there, we focus here on the scalability and prediction quality of our method.",5.2 Guided KB Completion,[0],[0]
"We found that HolE+ITRS+IET scales well to this high dimension, doubling the number of facts by adding 66K new facts at 74% precision.",5.2 Guided KB Completion,[0],[0]
"Although the Science tensor is 1,000 times larger than the Animals tensor, the method took only 10x longer to run (3 minutes on Animals tensor vs. 56 minutes on Science tensor, using a 2.8GHz, 16GB Macbook Pro).",5.2 Guided KB Completion,[0],[0]
"With additional improvements such as parallelization, it is easily possible to further scale the method up to substantially larger tensors.",5.2 Guided KB Completion,[0],[0]
"To assess the quality of our active learning mechanism (Section 4), we consider predicting facts about a new entity ẽ that is not in the Animals tensor.",5.3 Active Learning for New Entities,[0],[0]
"For illustration, we choose ẽ from the Science tensor vocabulary while ensuring that it is present in the WordNet taxonomy.
",5.3 Active Learning for New Entities,[0],[0]
The setup is as follows.,5.3 Active Learning for New Entities,[0],[0]
"We first use a query generation mechanism (Random, Schema Consistent, or Sibling Guided; cf. Section 4.1) to propose an ordered list L of facts about ẽ to annotate.",5.3 Active Learning for New Entities,[0],[0]
"Next, we perform subset selection (Top k or TK, Submodular or SM; cf. Section 4.2) on L to identify a subset L̂ of up to 100 most promising queries.",5.3 Active Learning for New Entities,[0],[0]
"These are then annotated and the true ones fed into tensor factorization as additional input to infer further new facts about ẽ.
In Table 3, we assess the quality of L̂ in two ways, when |L̂| = 100: how many true facts does L̂ have and how many overall new facts does this annotation produce about ẽ. Figure 2 provides a complementary view, focusing on the overall number of new facts inferred as |L̂| increases.",5.3 Active Learning for New Entities,[0],[0]
"While these illus-
trative numbers are for a representative new entity, reindeer, the overall trend and order of numbers remained the same for other new entities we experimented with.
",5.3 Active Learning for New Entities,[0],[0]
We mention some highlights from Table 3.,5.3 Active Learning for New Entities,[0],[0]
"First, not surprisingly, randomly choosing triples about ẽ to annotate is ineffective.",5.3 Active Learning for New Entities,[0],[0]
"Second, choosing schema consistent triples results in 73 true triples (out of 100) but these facts help tensor factorization very little, resulting in only 10 additional new triples about ẽ.",5.3 Active Learning for New Entities,[0],[0]
"Our proposed sibling guided querying mechanism results not only in nearly all 100 facts being true along with 17 true facts inferred from sibling agreement (set M in Alg. 1), but also, combined with submodular subset selection for balancing diversity with coverage (Alg. 2), ultimately results in 483 new
facts about ẽ. These facts cover interesting new information such as (reindeer, eat, fruit), (wolf, chase, reindeer), and (reindeer, provide, fur).
",5.3 Active Learning for New Entities,[0],[0]
"Finally, the plot in Figure 2 demonstrates that the qualitative trends remain the same, irrespective of the number |L̂| of queries annotated.",5.3 Active Learning for New Entities,[0],[0]
"Overall, our sibling guided queries with submodular subset selection (green triangles, top-most curve) ultimately results in 5.8 times more new facts about ẽ than a non-trivial, uncertainly based, schema consistent baseline (black stars, 3rd curve from the top).",5.3 Active Learning for New Entities,[0],[0]
This attests to the efficacy of the method on this challenging problem and dataset.,5.3 Active Learning for New Entities,[0],[0]
"This work explores KB completion for a new class of problems, namely completing generics KBs, which is an essential step for including general world knowledge in intelligent machines.",6 Conclusion,[0],[0]
The differences between generics and much studied named entity KBs make existing techniques either not scale well or produce facts at an undesirably low precision out of the box.,6 Conclusion,[0],[0]
We demonstrate that incorporating entity taxonomy and relation schema appropriately can be highly effective for generics KBs.,6 Conclusion,[0],[0]
"Further, to address scarcity of facts about certain entities in such KBs, we present a novel active learning approach using sibling guided uncertainty estimation along with submodular subset selection.",6 Conclusion,[0],[0]
"The proposed techniques substantially outperform various baselines, setting a new state of the art for this challenging class of completion problems.
",6 Conclusion,[0],[0]
Our method is applicable to KBs that have an associated entity taxonomy and relation schema.,6 Conclusion,[0],[0]
It is expected to be successful when information from siblings can be used to guide what is likely to be true and what is a good candidate to query for a given entity.,6 Conclusion,[0],[0]
"We focus on KBs of generics where such information is available and—as we show—is highly valuable for effective KB completion.
",6 Conclusion,[0],[0]
Why does our use of types work substantially better in our setting than the use of types in various baselines?,6 Conclusion,[0],[0]
One hypothesis is the following.,6 Conclusion,[0],[0]
The use of complicated models requires substantial data and information.,6 Conclusion,[0],[0]
"In our KB, the information appears so sparse and incomplete that using types in complicated ways is not productive.",6 Conclusion,[0],[0]
"Our proposal instead
attempts to use type information only to gently enhance the signal and reduce noise, before performing tensor decomposition.",6 Conclusion,[0],[0]
"We hope this work will trigger further exploration of knowledge bases with generics, a key aspect of machine intelligence.",6 Conclusion,[0],[0]
"The authors would like to thank Peter Clark for fruitful discussions, valuable feedback, and crowdsourcing annotations; Matt Gardner for constructive comments and assessing graph-based completion methods on our datasets; and Udai Saini and Partha Talukdar for evaluating their CNTF approach on our datasets.",Acknowledgments,[0],[0]
"Given a knowledge base or KB containing (noisy) facts about common nouns or generics, such as “all trees produce oxygen” or “some animals live in forests”, we consider the problem of inferring additional such facts at a precision similar to that of the starting KB.",abstractText,[0],[0]
"Such KBs capture general knowledge about the world, and are crucial for various applications such as question answering.",abstractText,[0],[0]
"Different from commonly studied named entity KBs such as Freebase, generics KBs involve quantification, have more complex underlying regularities, tend to be more incomplete, and violate the commonly used locally closed world assumption (LCWA).",abstractText,[0],[0]
"We show that existing KB completion methods struggle with this new task, and present the first approach that is successful.",abstractText,[0],[0]
"Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting.",abstractText,[0],[0]
"First, our simple yet effective knowledge guided tensor factorization approach achieves state-of-the-art results on two generics KBs (80% precise) for science, doubling their size at 74%-86% precision.",abstractText,[0],[0]
"Second, our novel taxonomy guided, submodular, active learning method for collecting annotations about rare entities (e.g., oriole, a bird) is 6x more effective at inferring further new facts about them than multiple active learning baselines.",abstractText,[0],[0]
Knowledge Completion for Generics using Guided Tensor Factorization,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3198–3207 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3198",text,[0],[0]
"Knowledge Graphs (KGs) are extremely useful resources for many AI-related applications, such as question answering, information retrieval and query expansion.",1 Introduction,[0],[0]
"Indeed, KGs are multi-relational directed graphs composed of entities as nodes and relations as edges.",1 Introduction,[0],[0]
"They represent information about real-world entities and relations in the form of knowledge triples, which is denoted as (h, r, t), where h and t correspond to the head and tail entities and r denotes the relation between them, e.g., (Donald Trump, presidentOf, USA).",1 Introduction,[0],[0]
"Large
scale, collaboratively created KGs , such as Freebase (Bollacker et al., 2008), WordNet (Miller, 1994), Yago (Suchanek et al., 2007), Gene Ontology (Sherlock, 2009), NELL (Carlson et al., 2010) and Google’s KG1, have recently become available.",1 Introduction,[0],[0]
"However, despite the impressively large sizes, the coverage of most existing KGs are far from complete.",1 Introduction,[0],[0]
"This has motivated research in knowledge base completion task, which includes KGE methods aiming to embed entities and relations in KGs into low-dimensional embeddings.
",1 Introduction,[0],[0]
"In the literature, there are a number of studies about KGE models.",1 Introduction,[0],[0]
"These models embed entities and relations into latent vectors and complete KGs based on these vectors, such as TransE (Bordes et al., 2013), TransH (Wang et al., 2014) and TransR",1 Introduction,[0],[0]
"(Lin et al., 2015b).",1 Introduction,[0],[0]
"However, most of the existing works simply embed relations into vectors.",1 Introduction,[0],[0]
Less efforts have been made for investigating the rich information from the relation structure.,1 Introduction,[0],[0]
"Indeed, in this research, we define a three-layer hierarchical relation structure (HRS), which can be conformed by relation clusters, relations and subrelations in KGs.
",1 Introduction,[0],[0]
• Relation clusters: Semantically similar relations are often observed in Large-scales KGs.,1 Introduction,[0],[0]
"For example, the relation ’producerOf’ and ’directorOf’ may be semantically related if both of them describe a relation between a person and a film.",1 Introduction,[0],[0]
These semantically similar relations can make up relation clusters.,1 Introduction,[0],[0]
"We believe the information from semantically similar relations is of great value, and relations in the same group can be trained in a collective way to facilitate the knowledge sharing when learning the embeddings of related relations.
",1 Introduction,[0],[0]
"• Relations: A relation connects the head and 1https://www.google.com/intl/es419/insidesearch/features/ search/knowledge.html
tail entities in a knowledge triple, denoted as (h, r, t), where h and t correspond to the head and tail entities and r denotes the relation between them.
",1 Introduction,[0],[0]
• Sub-relations: There are relations that have multiple semantic meanings and can be split into several sub-relations.,1 Introduction,[0],[0]
"For example, the relation partOf has at least two semantics: location-related as (New Y ork, partOf , USA) and composition-related as (monitor, partOf , television).",1 Introduction,[0],[0]
"We believe the subrelations can give fine-grained descriptions for each relation.
",1 Introduction,[0],[0]
"The relation clusters, relations and sub-relations correspond to the top, middle and bottom layer of the three-layer HRS.
",1 Introduction,[0],[0]
"In this paper, we extend state-of-the-art models TransE (Bordes et al., 2013), TransH (Wang et al., 2014) and DistMult (Yang et al., 2015) to learn knowledge representations by leveraging the rich information from the HRS.",1 Introduction,[0],[0]
"Moreover, the same technique can easily be used to extend other stateof-the-art models and utilize the HRS information.",1 Introduction,[0],[0]
"In the proposed models, for each knowledge triple (h, r, t), the embedding of r is the sum of three embedding vectors, which correspond to the three layers of the HRS respectively and therefore, the information from the HRS is leveraged.",1 Introduction,[0],[0]
"Particularly, instead of using additional information like text or paths, our model simply use the knowledge triples in KGs and the rich information from the HRS.",1 Introduction,[0],[0]
"Extensive experiments on popular benchmark data sets demonstrate the effectiveness of our models.
",1 Introduction,[0],[0]
"In summary, we highlight our key contributions as follows,
1.",1 Introduction,[0],[0]
"We propose a technique by making use of the HRS information to conduct the KGE task, and extend three state-of-the-art models to utilize this technique.",1 Introduction,[0],[0]
"The technique can be easily applied to other KGE models.
",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
"Our proposed models don’t use additional information like text or paths, instead, we only use the knowledge triples in KGs and take advantage of the rich information from the HRS.
3.",1 Introduction,[0],[0]
"We evaluate our models on popular benchmark data sets, and the results show that our
extended models achieve substantial improvements against the original models as well as other state-of-the-art baselines.",1 Introduction,[0],[0]
We extend three popular KGE models by leveraging the HRS information in this study.,2 Preliminaries and Related Work,[0],[0]
"Therefore, in this section, we first introduce the three existing models TransE (Bordes et al., 2013), TransH (Wang et al., 2014) and DistMult (Yang et al., 2015) in detail.",2 Preliminaries and Related Work,[0],[0]
"Then, we further summarize other state-of-the-art models on the topic of KGE.",2 Preliminaries and Related Work,[0],[0]
"Recently, a number of KGE models have been proposed.","2.1 TransE, TransH and DistMult",[0],[0]
"These methods learn low-dimensional vector representations for entities and relations (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015b).
","2.1 TransE, TransH and DistMult",[0],[0]
"TransE (Bordes et al., 2013) is one of the most widely used model, which views relations as translations from a head entity to a tail entity on the same low-dimensional hyperplane, i.e, h + r","2.1 TransE, TransH and DistMult",[0],[0]
"≈ t when (h, r, t) holds.","2.1 TransE, TransH and DistMult",[0],[0]
This indicates that t should be the nearest neighbor of h+ r.,"2.1 TransE, TransH and DistMult",[0],[0]
"In this case, the score function of TransE is defined as
fr(h, t) = ‖h+ r− t‖Ln , (1)
which can be measured by L1 or L2 norm.","2.1 TransE, TransH and DistMult",[0],[0]
"Positive triples are supposed to have lower scores than negative ones.
","2.1 TransE, TransH and DistMult",[0],[0]
"TransH (Wang et al., 2014) introduces a mechanism of projecting entities into relation-specific hyperplanes that enables different roles of an entity in different relations.","2.1 TransE, TransH and DistMult",[0],[0]
TransH models the relation as a vector r on a hyperplane wr and assumes that h⊥ +,"2.1 TransE, TransH and DistMult",[0],[0]
"r ≈ t⊥ when (h, r, t) holds, where h⊥ and t⊥ are the projection of h and t in the relationspecific hyperplane.","2.1 TransE, TransH and DistMult",[0],[0]
"The score function of TransH is defined as
fr(h, t) = ‖h⊥ + r− t⊥‖22 , (2)
","2.1 TransE, TransH and DistMult",[0],[0]
"where h⊥ = h−w>r hwr, t⊥ = t−w>r twr and ‖wr‖2 = 1.","2.1 TransE, TransH and DistMult",[0],[0]
"Like triples in TransE, positive triples in TransH should have lower scores than negative ones.
","2.1 TransE, TransH and DistMult",[0],[0]
"DistMult (Yang et al., 2015) adopts a bilinear score function to compute the scores given (h, r, t) triples.","2.1 TransE, TransH and DistMult",[0],[0]
"The score function is defined as
fr(h, t) =","2.1 TransE, TransH and DistMult",[0],[0]
"hMrt, (3)
where Mr is a relation-specific diagonal matrix, which represents the characteristics of a relation.","2.1 TransE, TransH and DistMult",[0],[0]
"Different from TransE and TransH, positive triples should have larger scores than negative ones.","2.1 TransE, TransH and DistMult",[0],[0]
"Besides TransE, TransH and DistMult, there are also many models on the topic of KGE. TransR",2.2 Other KGE Models,[0],[0]
"(Lin et al., 2015b) embeds entities and relations into separate entity space and relationspecific spaces.",2.2 Other KGE Models,[0],[0]
"ComplEx (Welbl et al., 2016) extends DistMult to embed entities and relations into complex vectors instead of real-valued ones.",2.2 Other KGE Models,[0],[0]
"HolE (Nickel et al., 2016) employs circular correlations to create compositional representations.",2.2 Other KGE Models,[0],[0]
"ProjE (Shi and Weninger, 2017) adopts a twolayer network to embed entities and relations.",2.2 Other KGE Models,[0],[0]
"Other KGE models also try to embeds entities and relations in various ways, such as Unstructured Model (Bordes et al., 2012a, 2014), Structured Embedding (Bordes et al., 2012b), Single Layer Model (Socher et al., 2013), Semantic Matching Energy (Bordes et al., 2012a, 2014), NTN Model (Socher et al., 2013), etc.
",2.2 Other KGE Models,[0],[0]
Many efforts have been devoted to building models using additional information like paths or text.,2.2 Other KGE Models,[0],[0]
"For instance, PTransE (Lin et al., 2015a) and R-GCN (Schlichtkrull et al., 2017) use paths as additional information, while DKRL (Xie et al., 2016) and SSP (Xiao et al., 2017) adopt text to assist the embedding task.
",2.2 Other KGE Models,[0],[0]
Some KGE works focus on making use of the information from relations.,2.2 Other KGE Models,[0],[0]
"CTransR (Lin et al., 2015b), TransD",2.2 Other KGE Models,[0],[0]
"(Ji et al., 2015) and TransG",2.2 Other KGE Models,[0],[0]
"(Xiao et al., 2016) try to find fine-grained representations for each relation.",2.2 Other KGE Models,[0],[0]
"However, these works didn’t utilize the information from semantically similar relations and the HRS is also not exploited.",2.2 Other KGE Models,[0],[0]
"Different from the above studies, we believe semantically similar relations can make up relation clusters, and some relations may have multiple semantic meanings and can be split into fine-grained subrelations.",2.2 Other KGE Models,[0],[0]
"In this paper, we take advantage of the three-layer HRS and conduct the KGE task by extending three widely used models.",2.2 Other KGE Models,[0],[0]
"In this section, we provide the technical details of how to extend existing KGE models by leveraging the HRS information.",3 Methodology,[0],[0]
We first formally define the HRS and its integration with existing models.,3 Methodology,[0],[0]
"Then
we introduce the new loss functions of extended models TransE-HRS, TransH-HRS and DistMultHRS.",3 Methodology,[0],[0]
"Finally, two variants of the HRS models and implementation details are provided.",3 Methodology,[0],[0]
"Given a KG G = {(h, r, t)} ⊆ E × R× E , where E and R are the entity (node) set and relation (edge) set respectively.",3.1 Hierarchical Relation Structure,[0],[0]
We believe the relations in KGs can make up relation clusters as well as be split into fine-grained sub-relations.,3.1 Hierarchical Relation Structure,[0],[0]
"On the one hand, large scale KGs always have semantically related relations.",3.1 Hierarchical Relation Structure,[0],[0]
The information from semantically similar relations is of great value and these relations should be trained in a collective way.,3.1 Hierarchical Relation Structure,[0],[0]
"In this way, meaningful associations among related relations can be utilized and less frequent relations can be enriched with more training data.",3.1 Hierarchical Relation Structure,[0],[0]
"On the other hand, some relations may have multiple semantic meanings and can be split into several subrelations, which can provide fine-grained descriptions for each relation.",3.1 Hierarchical Relation Structure,[0],[0]
"In general, relations in KGs conform to a three-layer HRS, as shown in Figure 1.",3.1 Hierarchical Relation Structure,[0],[0]
"The HRS include a relation cluster layer, a relation layer and a sub-relation layer, which are denoted in yellow, green and blue in Figure 1 respectively.
",3.1 Hierarchical Relation Structure,[0],[0]
"For a triple (h, r, t) in the HRS model, the embedding of r is comprised of three parts: the relation cluster embedding rc, relation-specific embedding r′ and sub-relation embedding rs, which is denotes as
r = rc + r ′ + rs.",3.1 Hierarchical Relation Structure,[0],[0]
"(4)
",3.1 Hierarchical Relation Structure,[0],[0]
"According to the above equation, the embedding of each relation can leverage the information from the three-layer HRS.",3.1 Hierarchical Relation Structure,[0],[0]
"The relation clusters and subrelations are determined by k-means algorithm based on the results of TransE:
• Relation clusters.",3.1 Hierarchical Relation Structure,[0],[0]
"We first run TransE on a given data set and obtain the embeddings of relations r1, r2, r3, ..., r|R|, where |R| is the number of relations.",3.1 Hierarchical Relation Structure,[0],[0]
"Then, the k-means algorithm is applied on these embeddings.",3.1 Hierarchical Relation Structure,[0],[0]
"In this way, we get relation clusters C1, C2, C3, ..., C|C|, where C is the set of relation clusters.",3.1 Hierarchical Relation Structure,[0],[0]
"Previous studies have shown that the embeddings of semantically similar relations locate near each other in the latent space (Yang et al., 2015).",3.1 Hierarchical Relation Structure,[0],[0]
"In this way, we are able to find relation clusters composed of semantically related relations.
",3.1 Hierarchical Relation Structure,[0],[0]
• Sub-relations.,3.1 Hierarchical Relation Structure,[0],[0]
TransE assumes that t − h,3.1 Hierarchical Relation Structure,[0],[0]
"≈ r when (h, r, t) holds.",3.1 Hierarchical Relation Structure,[0],[0]
"For each triple (h, r, t), we define that r̂ = t−h, where h and t are obtained from the results of TransE. For each relation, we collect all the r̂ and adopt the k-means algorithm to cluster these vectors into several groups Sr1 , Sr2 , Sr3 , ..., Srnr , where nr is the number of subrelations for",3.1 Hierarchical Relation Structure,[0],[0]
relation r.,3.1 Hierarchical Relation Structure,[0],[0]
Each group corresponds to a fine-grained sub-relation.,3.1 Hierarchical Relation Structure,[0],[0]
"The loss of the extended HRS model is comprised of two parts, as is shown in Equation (5),
LTotal =",3.2 Loss Function,[0],[0]
"LOrig + LHRS , (5)
where LOrig is the loss function of the original model, while LHRS is the loss function for the HRS information.
",3.2 Loss Function,[0],[0]
"We know that TransE, TransH and DistMult all adopt a margin-based ranking loss.",3.2 Loss Function,[0],[0]
"Taking TransE as an example, the loss function of TransE for the first part LOrig is shown as Equation (6),
LOrig = |C|∑ c=1 ∑ r∈Cc ∑ (h,r,t)∈4r ∑ (h′,r,t′)∈4′r",3.2 Loss Function,[0],[0]
"[γ + fr(h, t)
",3.2 Loss Function,[0],[0]
"− fr(h′, t′)]+, (6)
where [x]+ = max(0, x), 4r denotes the set of positive triples for relation r and 4′r = {(h′, r, t)|h′ ∈ E}∪{(h, r, t′)|t′ ∈ E} is the set of negative ones for relation r. γ is the margin separating the positive triples from the negative ones.",3.2 Loss Function,[0],[0]
"fr(h, t) is the score function as shown in Equation (7),
fr(h, t) = ∥∥h+",3.2 Loss Function,[0],[0]
rc + r′ + rs,3.2 Loss Function,[0],[0]
"− t∥∥Ln , (7)
which can be measured by L1 or L2 norm.",3.2 Loss Function,[0],[0]
"Positive triples are supposed to have lower scores than negative ones.
",3.2 Loss Function,[0],[0]
"The second part, LHRS , is composed of three regularized terms, which is shown in Equation (8),
LHRS = λ1 ∑ rc∈C ‖rc‖22 + λ2 ∑ r′∈R ∥∥r′∥∥2 2
+ λ3 ∑ rs∈S ‖rs‖22 , (8)
where C = {C1, C2, ..., C|C|} is the set of relation clusters, S = {Sr1 , Sr2 , Sr3 , ..., Srnr |r ∈ R} is the set of fine-grained sub-relations, nr is the number of sub-relations for relation r. λ1, λ2 and λ3 are trade-off parameters.",3.2 Loss Function,[0],[0]
"Large value of λ1 will result in the separate training of each relation, while large value of λ2 will lead to all relations in the same relation cluster sharing the same embedding vector.",3.2 Loss Function,[0],[0]
"λ3 should be larger than λ1 and λ2 to restrict rs to be a small value, i.e., the sub-relations from the same relation should be close.",3.2 Loss Function,[0],[0]
"Additionally, we introduce two variants of the HRS model: the top-middle model and the middle-bottom model.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
The top-middle model only uses the HRS by leveraging the information from the top to the middle layer.,3.3 Variants of the HRS Model and Implementation details,[0],[0]
"For this model, the relation embedding and the loss for HRS is defined as Equation (9) and (10).
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"r = rc + r ′, (9)
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
LHRS = λ1 ∑ rc∈C ‖rc‖22 + λ2 ∑ r′∈R ∥∥r′∥∥2 2 .,3.3 Variants of the HRS Model and Implementation details,[0],[0]
"(10)
While the middle-bottom model only utilizes the information from the middle to the bottom layer.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"The relation embedding and HRS loss are defined as Equation (11) and (12).
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"r = r′ + rs, (11)
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
LHRS = λ2 ∑ r′∈R ∥∥r′∥∥2 2 + λ3 ∑ rs∈S ‖rs‖22 .,3.3 Variants of the HRS Model and Implementation details,[0],[0]
"(12)
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"The learning process of the extended models is carried out by using the Adam (Kingma and Ba, 2014) optimizer.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"For the extended models of TransE, all the entity and relation embedding parameters are initialized with a uniform distribution U [ − 6√
k , 6√ k
] following TransE, where k
is the dimension of the embedding space.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"For the extended models of TransH and DistMult, we initialize these parameters with the results of TransE. For the relation cluster embeddings and sub-relation embeddings, we initialize all the parameters with the value of zero.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"In this research, we evaluate the performances of our extended models on popular benchmarks FB15k (Bordes et al., 2013), FB15k237 (Toutanova and Chen, 2015), FB13(Socher et al., 2013), WN18 (Bordes et al., 2013) and WN11 (Socher et al., 2013).",4.1 Data Sets,[0],[0]
"FB15k, FB15k237 and FB13 are extracted from Freebase (Bollacker et al., 2008), which provides general facts of the world.",4.1 Data Sets,[0],[0]
"WN18 and WN11 are obtained from WordNet (Miller, 1994), which provides semantic knowledge of words.",4.1 Data Sets,[0],[0]
"FB15k-237 and WN18 are used for the task of link prediction, FB13 and WN11 are used for the triple classification task, while FB15k is used for both tasks.",4.1 Data Sets,[0],[0]
The statistics of the five data sets are summarized in Table 1.,4.1 Data Sets,[0],[0]
"To demonstrate the effectiveness of our models, we compare results with the following baselines.
",4.2 Baselines,[0],[0]
•,4.2 Baselines,[0],[0]
"TransE (Bordes et al., 2013): one of the most widely used KGE models.
",4.2 Baselines,[0],[0]
"• TransH (Wang et al., 2014): a KGE model which adopts relation-specific hyperplanes to lay entities and relations.
",4.2 Baselines,[0],[0]
"• DistMult (Yang et al., 2015): a state of the art model which uses a bilinear score function to compute scores of knowledge triples.
",4.2 Baselines,[0],[0]
"• CTransR (Lin et al., 2015b): a pioneering KGE model which exploits fine-grained sub-relations for each relation.
• TransD",4.2 Baselines,[0],[0]
"(Ji et al., 2015): an improvement of CTransR, which embeds KGs using dynamic mapping matrices.
• TransG",4.2 Baselines,[0],[0]
"(Xiao et al., 2016): the first generative KGE model that uses a non-parametric bayesian model to embed KGs.",4.2 Baselines,[0],[0]
"Link prediction, a.k.a. knowledge graph completion, aims to fill the missing values into incomplete knowledge triples.",4.3 Link Prediction,[0],[0]
"More formally, the goal of link prediction is to predict either the head entity in a given query (?, r, t) or the tail entity in a given query (h, r, ?).",4.3 Link Prediction,[0],[0]
All the parameters are set by some preliminary test.,4.3.1 Experimental Settings,[0],[0]
"For TransE-HRS, TransE-top-middle and TransE-middle-bottom, λ1, λ2, λ3 and the margin γ are set as λ1 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 4, λ3 = 1e−3, γ = 2.",4.3.1 Experimental Settings,[0],[0]
"For the extended models of TransH, we set the parameters as λ1 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ3 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 3, γ = 1.",4.3.1 Experimental Settings,[0],[0]
"For the extended models of DistMult, the parameters are set as λ1 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 4, λ3 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 3, γ = 1.",4.3.1 Experimental Settings,[0],[0]
"For all the above models, the learning rate ς , batch size b and embedding size k are set as ς = 1e",4.3.1 Experimental Settings,[0],[0]
"− 3, b = 4096, k = 100.",4.3.1 Experimental Settings,[0],[0]
The L1 norm is adopted by the score function of TransE and its extended models.,4.3.1 Experimental Settings,[0],[0]
"The number of relation clusters are set as 300, 120 and 10 for FB15k, FB15k-237 and WN18 respectively.",4.3.1 Experimental Settings,[0],[0]
"For all the data sets, we generate 3 subrelations for relations that have more than 500 occurrences in the training set.",4.3.1 Experimental Settings,[0],[0]
"For all the extended models and baselines, we produce negative triples following the “bern” sampling strategy which was introduced in TransH (Wang et al., 2014).",4.3.1 Experimental Settings,[0],[0]
"For baselines TransE, TransH and DistMult, the embedding parameters of entities and relations are initialized the same way as the extended models for a fair comparison.
",4.3.1 Experimental Settings,[0],[0]
"In the test phase, we replace the head and tail entities with all the entities in KG in turn for each triple in the test set.",4.3.1 Experimental Settings,[0],[0]
Then we compute a score for each corrupted triple.,4.3.1 Experimental Settings,[0],[0]
"Note that for each corrupted
triple (h′, r, t′), the sub-relation is determined by t′ − h′, i.e., the k-means model is adopted to assign t′−h′ to a specific sub-relation of r. We rank all the candidate entities according to the scores.",4.3.1 Experimental Settings,[0],[0]
"Specifically, positive candidates are supposed to precede negative ones.",4.3.1 Experimental Settings,[0],[0]
"Finally, the rank of the correct entity is stored.",4.3.1 Experimental Settings,[0],[0]
"We compare our models with baselines using the following metrics: (1) Mean Rank (MR, the mean of all the predicted ranks); (2) Mean Reciprocal Rank (MRR, the mean of all the reciprocals of predicted ranks); (3) Hits@n",4.3.1 Experimental Settings,[0],[0]
"(Hn, the proportion of ranks not larger than n).",4.3.1 Experimental Settings,[0],[0]
Lower values of MR and larger values of MRR and Hn indicate better performance.,4.3.1 Experimental Settings,[0],[0]
"All the results are reported in the “filtered” setting (Bordes et al., 2013).",4.3.1 Experimental Settings,[0],[0]
Evaluation results are shown in Table 2.,4.3.2 Experimental Results,[0],[0]
We divide all the results into 4 groups.,4.3.2 Experimental Results,[0],[0]
"The second, third and forth group are results of TransE, TransH, DistMult and their extended models respectively, while the first group are results of other state-ofthe-art competitors.",4.3.2 Experimental Results,[0],[0]
Results in bold font are the best results in the group and the underlined results denote the best results in the column.,4.3.2 Experimental Results,[0],[0]
"From Table 1, we have the following findings: (1) Our extended models outperform the original models, which indicates that the information learned from the HRS is valuable; (2) For WN18, the results from ‘top-middle’ models of TransE, TransH and DistMult are worse than the original models, and HRS models can’t outperform middle-bottom ones.",4.3.2 Experimental Results,[0],[0]
We conjecture the reason lies as follows: WN18 has only 18 relations and the semantic correlation among relations is small.,4.3.2 Experimental Results,[0],[0]
"In this case, the information learned from the top to the middle layer of the HRS may lead to worse results since for each relation, even though the information learned from semantically similar relations are useful, the information learned from unrelated relations may damage the results.",4.3.2 Experimental Results,[0],[0]
"The results indicate that HRS models are especially useful for KGs with dense semantic distributions over relations; (3) For WN18, TransE-middle-bottom and DistMult-middle-bottom achieve the best results on MRR, Hits@10, Hits@3 and Hits@1 while failing to get the best results on MR in the same group.",4.3.2 Experimental Results,[0],[0]
"Further analysis shows that in the results of TransE-middle-bottom, 56 test triples get ranks more than 10000, leading to more than 110 MR loss.",4.3.2 Experimental Results,[0],[0]
"While in the results of DistMult-middle-
bottom, there exist 37 test triples whose ranks are more than 7000, which would lead to about 50 MR loss.",4.3.2 Experimental Results,[0],[0]
"Indeed, MR is sensitive to these high ranks, which lead to worse results on the metric of MR; (4) From all the results, based on the good basic model DistMult, the extended models of DistMult can achieve the best performance compared with other state-of-the-art baselines CTransR, TransD and TransG.
We also provide some case studies on relation clusters and sub-relations.",4.3.2 Experimental Results,[0],[0]
Table 3 shows some relation clusters of FB15k.,4.3.2 Experimental Results,[0],[0]
"Cluster 1 to 3 are Olympics-related, basketball-related and software-related relations respectively.",4.3.2 Experimental Results,[0],[0]
From Table 3 we can see that semantically related relations can join the same cluster.,4.3.2 Experimental Results,[0],[0]
"Table 4 shows some (head, tail) pairs for the sub-relations of ‘/educational institution/education/degree’.",4.3.2 Experimental Results,[0],[0]
"Sub-relation 1 to 3 are about the degree of Doctor, Master and Bachelor respectively.",4.3.2 Experimental Results,[0],[0]
"Table 5 gives some (head, tail) pairs for the sub-relations of ’/music/artist/genre’.",4.3.2 Experimental Results,[0],[0]
Sub-relation 1 and 2 are about rock music and pop music respectively while subcluster 3 is about other kinds of music.,4.3.2 Experimental Results,[0],[0]
"From Table 4 and 5, we can see that different sub-relations give fine-grained descriptions for each relation.",4.3.2 Experimental Results,[0],[0]
"In this section, we study the performance affected by the number of relation clusters N1 as well as the number of sub-relations for each relation N2.",4.3.3 Parameter Study,[0],[0]
The results in Figure 2 and 3 clearly show that there exists an optimal value of N1 and N2 for each dataset.,4.3.3 Parameter Study,[0],[0]
All three models keep achieving better results as we increase the number of clusters from 0 to the optimal value.,4.3.3 Parameter Study,[0],[0]
"Then, after N1 and N2 exceed the optimal point, the performance starts falling down.",4.3.3 Parameter Study,[0],[0]
The reason lies as: (1) Smaller value of N1 leads to large-sized relation clusters.,4.3.3 Parameter Study,[0],[0]
Some unrelated relations may join in the same large-sized cluster and degrade the performance of our models.,4.3.3 Parameter Study,[0],[0]
"Larger value of N1 leads to small-sized relation clusters, thus less information can be leveraged by each relation, leading to the unsatisfying performance; (2) Smaller value of N2 can’t provide sufficient representations for each relation and degrade the performance of our models.",4.3.3 Parameter Study,[0],[0]
Larger value ofN2 may lead to lacking of training data for each sub-relation and also result in the unsatisfying performance.,4.3.3 Parameter Study,[0],[0]
"In order to testify the discriminative capability of our models, we conduct a triple classification task aiming to predict the label (True or False) of a given triple (h, r, t).",4.4 Triple Classification,[0],[0]
"In this paper, we use three datasets WN11, FB13 and FB15k to evaluate our models.",4.4.1 Experimental Settings,[0],[0]
"The data sets WN11 and FB13 released by NTN (Socher et al., 2013) already have negative triples.",4.4.1 Experimental Settings,[0],[0]
"The test set of FB15k only contains correct triples, which re-
quires us to construct negative triples.",4.4.1 Experimental Settings,[0],[0]
"In this study, we construct negative triples following the same setting used for FB13 (Socher et al., 2013).",4.4.1 Experimental Settings,[0],[0]
"For the extended models of TransE, λ1, λ2, λ3 and γ are set as λ1 = 1e−5, λ2 = 1e−5, λ3 = 1e−3 and γ = 4.",4.4.1 Experimental Settings,[0],[0]
"For the extended models of TransH, we set λ1 = 1e",4.4.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.4.1 Experimental Settings,[0],[0]
"− 4, λ3 = 1e",4.4.1 Experimental Settings,[0],[0]
− 3 and γ = 5.,4.4.1 Experimental Settings,[0],[0]
"While for the extended models of DistMult, parameters are set as λ1 = 1e",4.4.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e− 4, λ3 = 1e− 2 and γ = 4.",4.4.1 Experimental Settings,[0],[0]
"For WN11 and FB13, we generate 2 sub-relations for each relation.",4.4.1 Experimental Settings,[0],[0]
"For FB15k, we generate 3 sub-relations for
relations that have more than 500 occurrences in the training set.",4.4.1 Experimental Settings,[0],[0]
Other parameters are set as introduced in Section 4.3.1.,4.4.1 Experimental Settings,[0],[0]
"We follow the same decision process as NTN (Socher et al., 2013): for TransE and TransH, a triple is predicted to be positive if fr(h, t) is below a threshold, while for DistMult, a triple is regarded as a positive one if fr(h, t) is above a threshold; otherwise negative.",4.4.1 Experimental Settings,[0],[0]
The thresholds are determined on the validation set.,4.4.1 Experimental Settings,[0],[0]
We adopt accuracy as our evaluation metric.,4.4.1 Experimental Settings,[0],[0]
"Finally, the evaluation results in Table 6 lead to the following findings: (1) Our models outperform other baselines on WN11 and FB15k, and obtain comparable results with baselines on FB13, which validate the effectiveness of our models; (2) The extended models TransE-HRS, TransH-HRS and DistMult-HRS achieve substantial improvements against the original models.",4.4.2 Experimental Results,[0],[0]
"On WN11, TransE-
HRS outperforms TransE with a margin as large as 10.9%.",4.4.2 Experimental Results,[0],[0]
These improvements indicates the technique of utilizing the HRS information is capable to be extended to different KGE models.,4.4.2 Experimental Results,[0],[0]
"Figure 4
shows the classification accuracy of different relations on WN11.",4.4.2 Experimental Results,[0],[0]
"We can see that extended models significantly improve the original models in each relation classification task, which again validate the effectiveness of our models.",4.4.2 Experimental Results,[0],[0]
"In this paper, we found that relations in KGs conform to a three-layer HRS.",5 Conclusion,[0],[0]
"This HRS model provides a critical capacity for embedding entities and relations, and along this line we extended three state-of-the-art models to leverage the HRS information.",5 Conclusion,[0],[0]
The technique we used can be easily applied to extend other KGE models.,5 Conclusion,[0],[0]
"Moreover, our proposed models don’t need additional information like text or paths, instead, we made full use of the knowledge triples in KGs and the rich information from the HRS.",5 Conclusion,[0],[0]
We evaluate our model on the link prediction task and triple classification task.,5 Conclusion,[0],[0]
"The results show that our extended models achieve substantial improvements against the original models as well as other baseline competitors.
",5 Conclusion,[0],[0]
"In the future, we will utilize more sophisticated models to leverage the HRS information, e.g, (1) utilize the embeddings of the three layers in a more sophisticated way instead of sum them together;
(2) determine the number of relation clusters and sub-relations automatically instead of manually.",5 Conclusion,[0],[0]
"The research work is supported by the National Key Research and Development Program of China under Grant No. 2018YFB1004300, the National Natural Science Foundation of China under Grant No. 61773361, 61473273, 91546122, Guangdong provincial science and technology plan projects under Grant No. 2015 B010109005, the Project of Youth Innovation Promotion Association CAS under Grant No. 2017146.",Acknowledgements,[0],[0]
This work is also partly supported by the funding of WeChat cooperation project.,Acknowledgements,[0],[0]
"We thank Bo Chen, Leyu Lin, Cheng Niu, Xiaohu Cheng for their constructive advices.",Acknowledgements,[0],[0]
"The rapid development of knowledge graphs (KGs), such as Freebase and WordNet, has changed the paradigm for AI-related applications.",abstractText,[0],[0]
"However, even though these KGs are impressively large, most of them are suffering from incompleteness, which leads to performance degradation of AI applications.",abstractText,[0],[0]
Most existing researches are focusing on knowledge graph embedding (KGE) models.,abstractText,[0],[0]
"Nevertheless, those models simply embed entities and relations into latent vectors without leveraging the rich information from the relation structure.",abstractText,[0],[0]
"Indeed, relations in KGs conform to a three-layer hierarchical relation structure (HRS), i.e., semantically similar relations can make up relation clusters and some relations can be further split into several fine-grained sub-relations.",abstractText,[0],[0]
"Relation clusters, relations and sub-relations can fit in the top, the middle and the bottom layer of three-layer HRS respectively.",abstractText,[0],[0]
"To this end, in this paper, we extend existing KGE models TransE, TransH and DistMult, to learn knowledge representations by leveraging the information from the HRS.",abstractText,[0],[0]
"Particularly, our approach is capable to extend other KGE models.",abstractText,[0],[0]
"Finally, the experiment results clearly validate the effectiveness of the proposed approach against baselines.",abstractText,[0],[0]
Knowledge Graph Embedding with Hierarchical Relation Structure,title,[0],[0]
"Proceedings of the SIGDIAL 2015 Conference, pages 12–21, Prague, Czech Republic, 2-4 September 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
"Partially observable Markov decision processes (POMDP) (Young et al., 2013) are a popular framework to model dialogue management as a reinforcement learning (RL) problem.",1 Introduction,[0],[0]
"In a POMDP, a state tracker (Thomson and Young, 2010)(Williams, 2014) maintains a distribution over possible user goals (states), called the belief state, and RL methods (Sutton and Barto,
1998) are used to optimize a metric called cumulative reward, a score that combines dialogue success rate and dialogue length.",1 Introduction,[0],[0]
"However, existing model-based RL approaches become intractable for real world sized dialogue systems (Williams and Young, 2007), and model-free approaches often need a large number of dialogues to converge to the optimal policy (Jurčı́ček et al., 2012).
",1 Introduction,[0],[0]
"Recently, Gaussian process (GP) based RL (Engel et al., 2005) has been proposed for dialogue policy optimization, reducing the number of interactions needed to converge to the optimal policy by an order of magnitude with respect to other POMDP models, allowing the policy to be learned directly from real users interactions (Gašić et al., 2013 a).",1 Introduction,[0],[0]
"In addition, using transfer learning methods (Taylor and Stone, 2009) to initialise the policy with data gathered from dialogue systems in different domains has increased the learning speed of the policy further (Gašić et al., 2013 b), and provided an acceptable system performance when there is no domain specific data available.",1 Introduction,[0],[0]
"In the case of dialogue managers personalised for a single speaker, data gathered from other “source” speakers can be used to pre-train the policy, but if the dynamics of the other speakers are very different, this data will have a different distribution than the data of the current “target” speaker, and therefore, using this data to train the policy model does not have any benefit.",1 Introduction,[0],[0]
"In the context of speaker specific acoustic models for users with dysarthria (a speech impairment), Christensen et al. (2014) demonstrated that using a speaker similarity metric to select the data to train the acoustic models improves ASR performance.",1 Introduction,[0],[0]
"Taking this idea into dialogue management, if a similarity metric is defined between different speakers, this metric can be used to select which data from the source speakers is used to train the model, and even to weight the influence of the data from each speaker in the model.",1 Introduction,[0],[0]
"As GP-RL is a non-parametric
12
method, a straightforward way to transfer knowledge is to directly initialise the GP model for the target speaker using data from source speakers, and update the GP with the data from the target speaker as this is gathered through interaction.",1 Introduction,[0],[0]
"But GP-RL soon becomes intractable as the data amount increases, limiting the amount of data that can be transferred.",1 Introduction,[0],[0]
"Gašić et al. (2013 a) proposes to transfer knowledge between domains by using the source data to train a prior GP, whose posterior is used as prior mean in the new GP.",1 Introduction,[0],[0]
"Another option is to use a GP approximation method (Quiñonero and Rasmussen, 2005) which permits data selection, use the speaker similarity metric to select the source data to initialise the policy, and then discard source data points as data points from the target speaker become available, keeping the number of data points up to a maximum.
",1 Introduction,[0],[0]
"This paper investigates knowledge transfer between speakers in the context of a spoken environmental control system personalised for speakers with dysarthria (Christensen et al., 2013), where the ASR is adapted as speaker specific data is gathered (Christensen et al., 2012), thus improving the ASR performance with usage.",1 Introduction,[0],[0]
The paper is organised as follows: Section 2 gives the background of GP-RL and defines the methods to select and weight the transferred data.,1 Introduction,[0],[0]
"Section 3 presents the experimental setup of the environmental control system and the different dysarthric simulated users, as well as the different features used to define the speaker similarities.",1 Introduction,[0],[0]
In Section 4 the results of the experiments are presented and explained and Section 5 concludes the paper.,1 Introduction,[0],[0]
"The objective of a POMDP based dialogue manager is to find the policy π(b) = a that maximizes the expected cumulative reward ci defined as the sum of immediate rewards from time step i until the dialogue is finished, where a ∈ A is the action taken by the manager, and the belief state b is a probability distribution over a discrete set of states S .",2 GPs for reinforcement learning,[0],[0]
"The Q-function defines the expected cumulative reward when the dialogue is in belief state bi and action ai is taken, following policy π:
Q(bi, ai) = Eπ[ci] ; where ci = N∑ n=i γn−irn (1)
where N is the time step at which the terminal action is taken (end of the dialogue), ri is the immediate reward given by the reward function, and
0 ≤",2 GPs for reinforcement learning,[0],[0]
"γ ≤ 1 is the discount factor, which weights future rewards.",2 GPs for reinforcement learning,[0],[0]
"If ci is considered to be a random variable, it can be modelled as a mean plus a residual, ci = Q(bi, ai) +",2 GPs for reinforcement learning,[0],[0]
"∆Q(bi, ai).",2 GPs for reinforcement learning,[0],[0]
"Then the immediate reward ri can be written recursively as the temporal difference (TD) between Q at time i and i+ 1:
ri = Q(bi, ai) + ∆Q(bi, ai) −γiQ(bi+1, ai+1)− γi∆Q(bi+1, ai+1)(2)
where γi = 0",2 GPs for reinforcement learning,[0],[0]
"if ai is a terminal action1, and the discount factor γ otherwise.",2 GPs for reinforcement learning,[0],[0]
"Given a set of observed belief-action points (bi, ai), with their respective ri values, the set of linear equations can be represented in matrix form as:
rt−1 = Htqt + Ht∆qt (3)
where qt=[Q(b1, a1), Q(b2, a2), ..., Q(bt, at)]",2 GPs for reinforcement learning,[0],[0]
">, ∆qt=[∆Q(b1, a1),∆Q(b2, a2), ...,∆Q(bt, at)]",2 GPs for reinforcement learning,[0],[0]
"> , rt−1 = [r1, r2, ..., rt−1]> and
Ht =  1 −γ1 . . .",2 GPs for reinforcement learning,[0],[0]
0 0 0 1 . . .,2 GPs for reinforcement learning,[0],[0]
0 0 ... . . .,2 GPs for reinforcement learning,[0],[0]
. .,2 GPs for reinforcement learning,[0],[0]
.,2 GPs for reinforcement learning,[0],[0]
"...
... 0 0 . . .",2 GPs for reinforcement learning,[0],[0]
1 −γt−1  ,2 GPs for reinforcement learning,[0],[0]
"If the random variables qt are assumed to have a joint Gaussian distribution with zero mean and ∆Q(bi, ai) ∼ N (0, σ2), the system can be modelled as a GP (Rasmussen and Williams, 2005), with the covariance matrix determined by a kernel function defined independently over the belief and the action space (Engel et al., 2005):
ki,j = k((bi, ai), (bj , aj))",2 GPs for reinforcement learning,[0],[0]
"= kb(bi,bj)ka(ai, aj) (4) To simplify the notation, from now on xi = (bi, ai) will be defined as each belief-action point, and KY,Y ′",2 GPs for reinforcement learning,[0],[0]
"as the matrix of size |Y| × |Y′| whose elements are computed by the kernel function (eq. 4) between any set of points Y and Y′. For a new belief-action point x∗ = (b∗, a∗), the posterior of the expected cumulative reward can be computed:
Q(x∗)|Xt, rt−1 ∼ N (Q̄(x∗), Q̂(x∗))",2 GPs for reinforcement learning,[0],[0]
"Q̄(x∗) = K∗,XH>t (HtKX,XH > t + Σt)
",2 GPs for reinforcement learning,[0],[0]
"−1rt−1 Q̂(x∗) = k(x∗,x∗)
−K∗,XH>t (HtKX,XH>t + Σt)−1HtKX,∗ (5)
1As dialogue management is an episodic RL problem, the temporal difference relationship between 2 consecutive belief-action points only happens if the points belong to the same dialogue.
",2 GPs for reinforcement learning,[0],[0]
"where Xt is the set of size t of all the previously visited (bi, ai) points, ∗ denotes the set of size 1 composed by the new belief-action point to be evaluated and Σt = σ2HtH>t .",2 GPs for reinforcement learning,[0],[0]
Q̄ and,2 GPs for reinforcement learning,[0],[0]
"Q̂ represent the mean and the variance of Q respectively.
",2 GPs for reinforcement learning,[0],[0]
To further simplify the notation it is possible to redefine eq. 5 by defining a kernel in the temporal difference space instead of in the belief-action space.,2 GPs for reinforcement learning,[0],[0]
"If the set of belief-action points Xt is redefined2 as Zt where zi = (bi, ai,bi+1, ai+1), with bi+1 and ai+1 set to any default values if ai is a terminal action, a kernel function between 2 temporal difference points can be defined as:
ktdi,j = k td(zi, zj)
= ktd((bi, ai,bi+1, ai+1), (bj , aj ,bj+1, aj+1))",2 GPs for reinforcement learning,[0],[0]
"= (ki,j + γiγjki+1,j+1 − γiki+1,j − γjki,j+1)
(6) where ki,j is the kernel function in the beliefaction space (eq. 4) and γi = 0 and γj = 0",2 GPs for reinforcement learning,[0],[0]
"if ai and aj are terminal actions respectively, or the discount factor γ otherwise (as in eq. 2).",2 GPs for reinforcement learning,[0],[0]
"When ai is a terminal action, the value of ai+1 and bi+1 in zi is irrelevant, as it will be multiplied by γi = 0.",2 GPs for reinforcement learning,[0],[0]
"In the same way, when this kernel is used to compute the covariance vector between a new test point and the set Zt, as the new point x∗ = (b∗, a∗) lies in the belief-action space, it is redefined as z∗ = (b∗, a∗,b∗+1, a∗+1) with b∗+1 and a∗+1 set to default values.",2 GPs for reinforcement learning,[0],[0]
"Then, a∗ is considered a terminal action, so b∗+1 and a∗+1 won’t affect the value of ktdi∗ due to γ∗ = 0.",2 GPs for reinforcement learning,[0],[0]
"A more detailed derivation of the temporal difference kernel is given in appendix A. Using the temporal difference kernel defined in eq. 6, eq. 5 can be rewritten as:
Q(z∗)|Zt, rt−1 ∼ N (Q̄(z∗), Q̂(z∗))",2 GPs for reinforcement learning,[0],[0]
Q̄(z∗),2 GPs for reinforcement learning,[0],[0]
"= Ktd∗,Z(K td Z,Z + Σt)
−1rt−1 Q̂(z∗) =",2 GPs for reinforcement learning,[0],[0]
"ktd(z∗, z∗)−Ktd∗,Z(KtdZ,Z + Σt)−1KtdZ,∗ (7) where KtdY,Y ′ is the covariance matrix computed with the temporal difference kernel between any set of TD points Y and Y′. With this notation, the shape of the equation for the posterior of Q is equivalent to classic GP regression models.",2 GPs for reinforcement learning,[0],[0]
"Thus, it is straightforward to apply a wide range of well studied GP techniques, such as sparse methods.",2 GPs for reinforcement learning,[0],[0]
"Redefining the belief-action set of points Xt as the set of temporal difference points Zt also simplifies the selection of data points (e.g. to select inducing
2Take into account that |Zt| = |Xt| − 1
points in sparse models), because the dependency between consecutive points is well defined.
",2 GPs for reinforcement learning,[0],[0]
"The GP literature proposes various sparse methods which select a subset of inducing points U of size m < t from the set of training points Z (Quiñonero and Rasmussen, 2005).",2 GPs for reinforcement learning,[0],[0]
In this paper the deterministic training conditional (DTC) method is used.,2 GPs for reinforcement learning,[0],[0]
"Once the subset of points has been selected and assuming ∆Q(bi, ai)",2 GPs for reinforcement learning,[0],[0]
"− γi∆Q(bi+1, ai+1) ∼ N (0, σ2) as in (Engel et al., 2003), the GP posterior can be approximated in O(t ·m2) with the DTC method as: Qdtc(z∗)|Zt, rt−1 ∼ N (Q̄dtc(z∗), Q̂dtc(z∗))",2 GPs for reinforcement learning,[0],[0]
"Q̄dtc(z∗) = σ−2Ktd∗,UΛK td U,Zrt−1
Q̂dtc(z∗) = ktd(z∗, z∗)−Φ + Ktd∗,UΛKtdU,∗ (8)
where Λ = (σ−2KtdU,ZK td Z,U +K td U,U ) −1",2 GPs for reinforcement learning,[0],[0]
"and Φ = Ktd∗,U (K td U,U )
−1KtdU,∗.",2 GPs for reinforcement learning,[0],[0]
"Once the posterior for any new belief-action point can be computed with eq. 7 or eq. 8, the policy π(b) = a can be computed as the action a that maximizes the Q-function from the current belief state b∗, but in order to avoid getting stuck in a local optimum, an exploration-exploitation approach should be taken.",2 GPs for reinforcement learning,[0],[0]
"One of the advantages of GPs is that they compute the uncertainty of the expected cumulative reward in form of a variance, which can be used as a metric for active exploration (Geist and Pietquin, 2011) to speed up the learning of the policy with an -greedy approach:
π(b∗) = { arg max a∈A Q̄(b∗, a) with prob.",2 GPs for reinforcement learning,[0],[0]
"(1− )
arg max a∈A Q̂(b∗, a) with prob.
(9) where controls the exploration rate.",2 GPs for reinforcement learning,[0],[0]
"The policy optimization loop is performed following the Episodic GP-Sarsa algorithm defined by (Gašić and Young, 2014).",2 GPs for reinforcement learning,[0],[0]
"The scenario where a statistical model for a specific “target” task must be trained, but only data from different but related “source” tasks is available, is known as transfer learning (Pan and Yang, 2010).",2.1 Transfer learning with GP-RL,[0],[0]
"In the context of this paper the different tasks will be dialogues with different speakers, and three points of transfer learning will be addressed:
• How to transfer the knowledge
•",2.1 Transfer learning with GP-RL,[0],[0]
"In the case of multiple source speakers, which data to transfer, and
• How to weight data from different sources.
",2.1 Transfer learning with GP-RL,[0],[0]
"In the context of reinforcement learning (Taylor and Stone, 2009) and dialogue policy optimization (Gašić et al., 2013 a), transfer learning has been shown to increase the performance of the system in the initial stages of use and to speed up the policy learning, requiring a smaller amount of target data to reach the optimal policy.",2.1 Transfer learning with GP-RL,[0],[0]
The most straightforward way to transfer the data in GP-RL is to initialise the set of temporal difference points,2.1.1 Knowledge transfer,[0],[0]
Zt of the GP with the source points and then continue updating it with target data points as they are gathered through interaction.,2.1.1 Knowledge transfer,[0],[0]
"However, this approach has a few shortcomings.",2.1.1 Knowledge transfer,[0],[0]
"First, as GP-RLs complexity increases with the number of data points, the model might quickly become intractable if it is initialised with too many source points.",2.1.1 Knowledge transfer,[0],[0]
"Also, when data points from the target speaker are gathered through interaction, the source points may not improve the performance of the system, while increasing the model complexity.",2.1.1 Knowledge transfer,[0],[0]
"Second, as the computation of the variance for a new point depends on the number of close points already visited, the variance of the new belief-action points will be reduced by the effect of the source points close in the belief-action space.",2.1.1 Knowledge transfer,[0],[0]
"If the distribution of the source data points is unbalanced, the effectiveness of the policy of eq. 9 will be affected.",2.1.1 Knowledge transfer,[0],[0]
Gašić,2.1.1 Knowledge transfer,[0],[0]
"et al. (2013 a) proposes to use the source points to train a prior GP, and use its posterior as mean function for the GP trained with the target points.",2.1.1 Knowledge transfer,[0],[0]
"With this approach, the mean of the posterior in eq. 7 will be modified as:
Q̄(z∗)",2.1.1 Knowledge transfer,[0],[0]
=,2.1.1 Knowledge transfer,[0],[0]
"m(z∗)+Ktd∗,Z(K td Z,Z+Σ)",2.1.1 Knowledge transfer,[0],[0]
−1(rt−1−mt) (10) where m(z∗) is the mean of the posterior of the Q-function given by the prior GP and mt =,2.1.1 Knowledge transfer,[0],[0]
"[m(z0), ...,m(zt)]",2.1.1 Knowledge transfer,[0],[0]
>.,2.1.1 Knowledge transfer,[0],[0]
"If the DTC approach (eq. 8) is taken, the posterior Q-function mean becomes:
Q̄dtc(z∗) =",2.1.1 Knowledge transfer,[0],[0]
"m(z∗)+σ−2Ktd∗,UΛK td U,Z(rt−1−mt)
(11)",2.1.1 Knowledge transfer,[0],[0]
"This approach has the advantage of being computationally cheaper than the former method while modelling the uncertainty for new target points more accurately, but at the cost of not taking into account the correlation between source and target points, which might reduce the performance when there is a small amount of target data.
",2.1.1 Knowledge transfer,[0],[0]
"A third approach combines the two previous methods, using a portion of the transfer points to train a GP for the prior mean function, while the rest is used to initialise the set Zt of the GP that will be updated with target points.",2.1.1 Knowledge transfer,[0],[0]
This method will be computationally cheaper than the first one while increasing the performance of the second method with a small amount of target data.,2.1.1 Knowledge transfer,[0],[0]
"As non-parametric models, the complexity of GPs will increase with the number of data points, limiting the amount of source data that can be transferred.",2.1.2 Transfer data selection,[0],[0]
"Additionally, if the points come from multiple sources, it is possible that the data distribution from some sources is more similar to the target speaker than others, hence transferring data from these sources will increase performance.",2.1.2 Transfer data selection,[0],[0]
"We propose to extract a speaker feature vector s from each speaker and define a similarity function f(s, s′) between speakers (see sec. 3.4).",2.1.2 Transfer data selection,[0],[0]
"The data can be selected by choosing the points from the source speakers more similar to the target.
",2.1.2 Transfer data selection,[0],[0]
"With the DTC approach (eq. 8), a subset of inducing points Um must be selected.",2.1.2 Transfer data selection,[0],[0]
The most straightforward way is to select the most similar points to the speaker from the transferred points.,2.1.2 Transfer data selection,[0],[0]
"As the user interacts with the system and target data points are gathered, these points may be used as inducing points.",2.1.2 Transfer data selection,[0],[0]
"This approach acts like another layer of data selection; the reduced complexity will allow for the transfer of more source points, while using the target points as inducing points will mean that only the source points that lie in the same part of the belief-action space as the target points have influence on the model.",2.1.2 Transfer data selection,[0],[0]
"When transferring data from multiple sources, the similarity between each source and the target speaker might be different.",2.1.3 Transfer data weighting,[0],[0]
Thus the data from a source more similar to the target should have more influence in the model than less similar ones.,2.1.3 Transfer data weighting,[0],[0]
"As a GP is defined by computing covariances between data points through a kernel function, one way to weight the data from different sources is to extend the belief-action vector used to compute the covariance with the speaker feature vector s explained in the previous section as xi = (bi, ai, si), and then extend the kernel (eq. 4) by multiplying it by a new kernel in the speaker space ks as:
kexti,j = k((bi, ai, si), (bj , aj , sj))
",2.1.3 Transfer data weighting,[0],[0]
"= kb(bi,bj)ka(ai, aj)ks(si, sj) (12)
",2.1.3 Transfer data weighting,[0],[0]
"By adding this extra space to the data points, the covariance between points will not only depend on the similarity between points in the belief-action space, but also in the speaker space, reducing the covariance between two points that lie in different parts of the speaker space.",2.1.3 Transfer data weighting,[0],[0]
This approach will also help to partially deal with the variance computing problem of the first model in sec.,2.1.3 Transfer data weighting,[0],[0]
"2.1.1, as the source points will lie on a different part of the speaker space than the new target points, thus having less influence in the variance computation.",2.1.3 Transfer data weighting,[0],[0]
"3 Experimental setup To test the system in a scenario with high variability between the dynamics of the speakers, the experiments are performed within the context of a voice-enabled control system designed to help speakers with dysarthria to interact with their home devices (TV, radio, lamps...), where the speakers have different severities of dysarthria (this is an instance of the homeService application (Christensen et al., 2013)).",2.1.3 Transfer data weighting,[0],[0]
"The system has a vocabulary of 36 commands and is organised in a tree setup where each node in the tree represents either a device (e.g. “TV”), a property of that device (e.g. “channel”), or actions that trigger some change in one of the devices (e.g. “one”, child of “channel”, will change the TV to channel one).",2.1.3 Transfer data weighting,[0],[0]
"When the system transitions to one of the terminal nodes that trigger an action, the action associated with this node is performed, and subsequently the system returns to the root node.",2.1.3 Transfer data weighting,[0],[0]
In the following experiments a dialogue will be considered finished when one of the terminal node actions is carried out.,2.1.3 Transfer data weighting,[0],[0]
"In the non-terminal nodes, the user may either speak one of the commands available in that node (defined by its children nodes) to transition to them, or say the meta-command “back” to return to its parent node.",2.1.3 Transfer data weighting,[0],[0]
"The ASR is configured to recognise single words, so there is no need for a language understanding system, as the concepts are just a direct mapping from the ASR output.",2.1.3 Transfer data weighting,[0],[0]
"A more detailed explanation of the system is given in (Casanueva et al., 2014) and two example dialogues are presented in Appendix B.",2.1.3 Transfer data weighting,[0],[0]
"In the homeService application, each system is personalised for a single speaker by adapting the
ASR system’s acoustic model as more data is gathered through interaction, thus increasing the accuracy of the ASR over time.",3.1 Simulated dysarthric users,[0],[0]
"In the following experiments, the system is tested by interacting with a set of simulated users with dysarthria, where each user interacts with a set of different ASR simulators, arising from the different amounts of data used to adapt the ASR.",3.1 Simulated dysarthric users,[0],[0]
"To train the ASR simulator for these users, data from a dysarthric speech database (UASpeech database (Kim et al., 2008)) has been used.",3.1 Simulated dysarthric users,[0],[0]
"Table 1 shows the characteristics of the 15 speakers of the database, and the ASR accuracy for each speaker in the 36 word vocabulary of the system without adaptation and adapted with 500 words from that speaker.",3.1 Simulated dysarthric users,[0],[0]
"Additionally, an intelligibility measure assessment is presented for each speaker as the percentage of words spoken by each speaker which are understood by unfamiliar speakers; these are shown in the second column in table 1.
",3.1 Simulated dysarthric users,[0],[0]
The system is tested with 6 different simulated users trained with data from low and medium intelligibility3 speakers.,3.1 Simulated dysarthric users,[0],[0]
"Each user interacts with 4 different ASRs, adapted with 0, 150, 300 and 500 words respectively.",3.1 Simulated dysarthric users,[0],[0]
"For a more detailed explanation of the simulated users configuration, the reader may refer to (Casanueva et al., 2014).",3.1 Simulated dysarthric users,[0],[0]
"Each non-terminal node in the tree is modelled as an independent POMDP where the state set S is the set of possible goals of the node and the action setA is the set of actions associated with each goal plus an “ask” action, which requests the user to repeat his last command.",3.2 POMDP setup,[0],[0]
"The reward function for all the POMDPs is -1 for the “ask” action, and +10 for each other action if it corresponds to the user goal, or -10 otherwise, and γ = 0.95.",3.2 POMDP setup,[0],[0]
"The state tracker is a logistic regression classifier (Pedregosa et al., 2011), where classes are the set of states",3.2 POMDP setup,[0],[0]
S.,3.2 POMDP setup,[0],[0]
The belief state b is computed as the posterior over the states given the last 5 observations (N-best lists with normalised confidence scores).,3.2 POMDP setup,[0],[0]
"For each speaker, the state tracker has been trained with data from the other 14 speakers.
",3.2 POMDP setup,[0],[0]
"3In (Casanueva et al., 2014)",3.2 POMDP setup,[0],[0]
"it was shown that, with a 36 command setup, statistical DM is most useful for low and medium intelligibility speakers.",3.2 POMDP setup,[0],[0]
"For high intelligibility speakers, the ASR accuracy is close to 100% so the improvement obtained from DM is small, and for very low intelligibility speakers, the absolute performance is not high enough to make the system useful.",3.2 POMDP setup,[0],[0]
The DTC approach (eq. 8) is used to compute the Q-function for the policy (eq. 9) with Gaussian noise variance σ2 = 5.,3.3 Policy models,[0],[0]
"The kernel over the belief space is a radial basis function kernel (RBF):
kb(bi,bj) = σ2k exp ( − ||bi − bj || 2
2l2k
) (13)
with variance σ2k = 25 and lengthscale l 2 k = 0.5.",3.3 Policy models,[0],[0]
"The delta kernel is used over the action space:
ka(ai, aj) = δ(ai, aj) =",3.3 Policy models,[0],[0]
"{
1 if ai = aj 0",3.3 Policy models,[0],[0]
"otherwise
(14)
and the kernels over the speaker space are defined in section 3.4.",3.3 Policy models,[0],[0]
The size of the inducing set Um is 500 and the maximum size of the TD points set Zt is 2000.,3.3 Policy models,[0],[0]
"Whenever a new data point is observed from the target speaker, it is added to the set of inducing points Um, and the first point of the set Um (which, due to the ordering done by data selection, corresponds to the least similar source point or to the oldest target point) is discarded from the inducing set.",3.3 Policy models,[0],[0]
"Whenever a new data point is observed and the size of the set of temporal difference points |Zt| = 2000, the first point of this set is discarded.",3.3 Policy models,[0],[0]
"Three variations of the DTC approach are used:
• DTC:",3.3 Policy models,[0],[0]
"Equation 8 is used to compute the Q posterior for the policy (eq. 9) and the set of temporal difference points Zt is initialised with the source points.
",3.3 Policy models,[0],[0]
"• Prior: Equation 11 is used to compute the Q posterior for the policy (eq. 9) and the prior GP is trained with the source points.
",3.3 Policy models,[0],[0]
•,3.3 Policy models,[0],[0]
Hybrid:,3.3 Policy models,[0],[0]
"Equation 11 is used to compute the Q posterior for the policy (eq. 9), the prior GP is trained with half of the source points and the set of temporal difference points Zt is initialised with the other half.",3.3 Policy models,[0],[0]
To compute the similarities between speakers a vector of speaker features s must be extracted.,3.4 Speaker similarities,[0],[0]
"Different kinds of features may be extracted, such
as meta-data based features, acoustic features, features related to the ASR performance, etc.",3.4 Speaker similarities,[0],[0]
"In this paper, we explore 3 different methods to extract s;
• Intelligibility assessment: The intelligibility assessment for each speaker in the UASpeech database (table 1) can be used as a single dimensional feature.
",3.4 Speaker similarities,[0],[0]
"• I-vectors: Martı́nez et al. (2013) showed that i-vectors (Dehak et al., 2011) can be used to predict the intelligibility of a dysarthric speaker.",3.4 Speaker similarities,[0],[0]
"For each speaker, s is defined as a 400 dimensional vector corresponding to the mean i-vector extracted from each utterance from that speaker.",3.4 Speaker similarities,[0],[0]
"For more information on the i-vector extraction and characteristics, refer to (Martı́nez et al., 2014).
",3.4 Speaker similarities,[0],[0]
• ASR accuracy:,3.4 Speaker similarities,[0],[0]
The performance statistics of the ASR (e.g. accuracy) can be used as speaker features.,3.4 Speaker similarities,[0],[0]
"In this paper we use the accuracy per word (command), defining s as a 36 dimensional vector where each element is the ASR accuracy for each of the 36 commands.
",3.4 Speaker similarities,[0],[0]
"The kernel over the speaker space ks (eq. 12), is defined as an RBF kernel (eq. 13).",3.4 Speaker similarities,[0],[0]
"This kernel is used both to compute the similarity between speakers in order to select data (section 2.1.2), and to weight the data from each source speaker (section 2.1.3).",3.4 Speaker similarities,[0],[0]
ks has variance σ2k = 1 and the lengthscale l2k varies depending on the features.,3.4 Speaker similarities,[0],[0]
"For intelligibility features l2k = 0.5, for i-vectors l2k = 8.0 and for ASR accuracy features",3.4 Speaker similarities,[0],[0]
l 2 k = 4.0,3.4 Speaker similarities,[0],[0]
"In the following experiments the reward is computed as -1 for each dialogue turn, +20 if the dialogue was successful4.",4 Results,[0],[0]
"The system has been tested
4Because of the variable depth tree structure of the spoken dialogue system, the sum or average of cumulative rewards obtained in each sub-dialogue is not a good measure of the overall system performance.",4 Results,[0],[0]
"If the dialogue gets stuck in a loop going back and forth between two sub-dialogues, the extra amount of turns spent in this loop would not be reflected in the average of rewards
with the 24 speaker-ASR pairs explained in section 3.1, and in the following figures, each plotted line is the average results for these 24 speakerASR pairs.",4 Results,[0],[0]
"As the behaviour of the simulated user and some data selection methods partially depend on random variables, each experiment has been initialised with four different seeds and all the results presented are the average of the four seeds tested over 500 dialogues.",4 Results,[0],[0]
"In all the experiments the data to initialise each POMDP is transferred from a pool of 4200 points corresponding to 300 points from each speaker in table 1 except the speaker being tested, where each data pool is different for each seed.
",4 Results,[0],[0]
Figure 1 compares the different policy models presented in section 3.3 using the intelligibility measure based similarity to select and weight the data.,4 Results,[0],[0]
The dotted line named DTC-conv shows the performance of the DTC policy when trained until convergence with the target speaker by simulating 1200 sub-dialogues in each node.,4 Results,[0],[0]
DTC-1000 and DTC-2000 show the performance of the basic DTC approach when 1000 and 2000 source points are transferred respectively.,4 Results,[0],[0]
"It can be observed that, transferring more points boosts the performance, but at the cost of increasing the complexity.",4 Results,[0],[0]
pri-1000 and pri-2000 show the performance of the prior policy with 1000 and 2000 transfer points respectively.,4 Results,[0],[0]
The success rate is above the DTC policy but the learning rate for the reward is slower.,4 Results,[0],[0]
This might be because the small amount of target data points make the predictions of the Q-function given by the GP unreliable.,4 Results,[0],[0]
"Hyb-1000 and hyb-2000 show the performance of the hybrid model, showing the best behaviour on success rate after 100 dialogues, and for hyb-2000 even outperforming DTC-2000 in reward after 400 dialogues.
",4 Results,[0],[0]
"In figure 2 the different approaches to compute the speaker similarities for data selection
and weighting presented in section 3.4 are compared, using the DTC model with 1000 transfer points (named DTC-1000 in the previous figure).",4 Results,[0],[0]
"DTC-int uses the intelligibility measure based features, DTC-iv the i-vector features and DTC-acc the ASR accuracy based features.",4 Results,[0],[0]
"DTC-iv outperforms the other two features, followed closely by DTC-acc.",4 Results,[0],[0]
"The performance of DTC-int is way below the other two metrics, suggesting that the information given by intelligibility assessments is a weak feature for source speaker selection (as it is done by humans, it might be very noisy).",4 Results,[0],[0]
"As DTC-acc uses information about the ASR statistics (which is the input for the dialogue manager), it might be expected that it will outperform the rest, but in this case a purely acoustic based measure such as the DTC-iv works better.",4 Results,[0],[0]
"The reason for this might be that these features are not correlated to the ASR performance, so hidden variables are used to better organise the data.",4 Results,[0],[0]
"To investigate the usefulness of similarity based data selection, two different data selection methods which do not weight the transferred data have been tried.",4 Results,[0],[0]
"DTC-randspk selects the ordering of the speakers from whom the data is transferred at random, and has a much worse performance than the similarity based method, but DTC-allspk selects the 1000 source points from all the speakers, selecting 1000 points at random from the pool of 4200 points and, as it can be seen, the reward obtained by this method is slightly better than with DTC-iv, even if the success rate is lower.",4 Results,[0],[0]
"This suggests that transferring points from more speakers rather than from just the closest ones is a better strategy, probably because points selected by this method are distributed more uniformly over the belief-action space.",4 Results,[0],[0]
"A method which does a trade-off between filling the belief-action space while selecting the most similar points could be a better option.
",4 Results,[0],[0]
"To further investigate the effect of selection and weighting of the data, figure 3 plots the results for the DTC policy model using the i-vector based similarity to weight the data but different data selection methods.",4 Results,[0],[0]
"iv-clo selects the closest speakers with respect to the i-vector metric, iv-randspk orders the speakers at random, and iv-allspk selects the 1000 transfer points from all the speakers but the tested one.",4 Results,[0],[0]
"As in the previous figure, selecting speakers by similarity works better than selecting speakers at random, but selecting the points from all the speakers and weighting them with the ivector metric outperforms all the previous meth-
ods.",4 Results,[0],[0]
"This might be because weighting the data does a kind of data selection, as the data points from source speakers closer to the target will have more influence than the further ones, while transferring points from all the speakers covers a bigger part of the belief-action space.",4 Results,[0],[0]
"acc-allspk and allspk-uw show the results of weighting the data with the ASR accuracy metric and not weighting the data respectively, when selecting the data from all speakers.",4 Results,[0],[0]
"The accuracy metric performs worse than the i-vector metric once again, but it still outperforms not weighting the data, suggesting that data weighting works for different metrics.",4 Results,[0],[0]
Finally iv-allspk-hyb plots the performance of the hybrid model when selecting the data from all the speakers and weighting it with the i-vector based similarity.,4 Results,[0],[0]
"Even if it is computationally cheaper, it outperforms iv-allspk after 100 dialogues, suggesting that with a good similarity metric and data selection method, the hybrid model in section 3.3 is the best option to take.",4 Results,[0],[0]
"When transferring knowledge between speakers in a GP-RL based policy, weighting the data by using a similarity metric between speakers, and to a lesser extent, selecting the data using this similarity, improves the performance of the dialogue manager.",5 Conclusions,[0],[0]
"By defining a kernel between temporal difference points and interpreting the Q-function as a GP regression problem where data points are in the TD space, sparse methods that allow the selection of the subset of inducing points such as DTC can be applied.",5 Conclusions,[0],[0]
"In a transfer learning scenario, DTC permits a larger number of data points to be transferred and the selection of points collected from the target speaker as inducing points.
",5 Conclusions,[0],[0]
"We showed that using part of the transferred data to train a prior GP for the mean function,
and the rest to initialize the set of points of the GP, improves the performance of each of these approaches.",5 Conclusions,[0],[0]
"Transferring data points from a larger number of speakers outperformed selecting the data points only from the more similar ones, probably because the belief-action space is covered better.",5 Conclusions,[0],[0]
This suggests that more complex data selection algorithms that trade-off between selecting the data points by similarity and covering more uniformly the belief-action space should be used.,5 Conclusions,[0],[0]
"Also, increasing the amount of data transferred increased the performance, but the complexity increase of GP-RL limits the amount of data that can be transferred.",5 Conclusions,[0],[0]
"More computationally efficient ways to transfer the data could be studied.
",5 Conclusions,[0],[0]
"Of the three metrics based on speaker features tested (speaker intelligibility, i-vectors and ASR accuracy), i-vectors outperformed the rest.",5 Conclusions,[0],[0]
This suggest that i-vectors are a potentially good feature for speaker specific dialogue management and could be used in other tasks such as state tracking.,5 Conclusions,[0],[0]
"ASR accuracy based metrics also outperformed the intelligibility based one, and as ASR accuracy and i-vector are uncorrelated features, a combination of them could give further improvement.
",5 Conclusions,[0],[0]
"Finally, as the models were tested with simulated users in a hierarchically structured dialogue system (following the structure of the homeService application), future work directions include evaluating the policy models in a mixed initiative dialogue system and testing them with real users.",5 Conclusions,[0],[0]
The research leading to these results was supported by the University of Sheffield studentship network PIPIN and EPSRC Programme Grant EP/I031022/1 (Natural Speech Technology).,Acknowledgements,[0],[0]
The authors would like to thank David Martı́nez for providing the i-vectors used in this paper.,Acknowledgements,[0],[0]
"In equation 5, a linear transformation from the belief-action space to the temporal difference space is applied to the to the covariance vector K∗,X and to the covariance matrix KX,X by multiplying them by the matrix Ht.",Appendix A. Temporal difference kernel,[0],[0]
"Deriving the term HtKX,XH>t we obtain the matrix in eq. 15 (page bottom), where ki,j is the kernel function between two belief-action points xi = (bi, ai) and xj = (bj , aj), defined in eq. 4.",Appendix A. Temporal difference kernel,[0],[0]
"The transformed matrix (eq. 15) has the form of a covariance matrix where each element is a sum of kernel functions ki,j between belief-action points on time i or i + 1 weighted by the discount factors.",Appendix A. Temporal difference kernel,[0],[0]
"So each element of this matrix can be defined as a function of 2 temporal differences between belief-action points (TD points),",Appendix A. Temporal difference kernel,[0],[0]
"zi = (bi, ai,bi+1, ai+1) and zj = (bj , aj ,bj+1, aj+1) in the form of (eq. 6):
ktdi,j = (ki,j + γiγjki+1,j+1− γiki+1,j − γjki,j+1) (16) where γi and γj will be 0 if ai and aj are terminal actions respectively.",Appendix A. Temporal difference kernel,[0],[0]
"Deriving the term K∗,XH>t (and HtKX,∗)",Appendix A. Temporal difference kernel,[0],[0]
"we obtain:
K∗,XH>t =[ (k1,∗
−γ1k2,∗) (k2,∗ −γ2k3,∗) . . .",Appendix A. Temporal difference kernel,[0],[0]
"(kt−1,∗ −γt−1kt,∗) ] (17)
which is a vector with ktdi,∗ = (ki,∗ − γiki+1,∗) for each term.",Appendix A. Temporal difference kernel,[0],[0]
"This is equivalent to equation 16 if the action of the new point a∗ is considered a terminal action, thus γ∗ = 0.",Appendix A. Temporal difference kernel,[0],[0]
"Then, redefining the set of belief-action points Xt as the set of beliefaction temporal difference points denoted as Zt, and defining Ktd as the covariance matrix computed with the kernel function between two temporal difference points (eq. 6), eq. 7 can be derived from eq. 5 by doing the following substitutions: K∗,XH>t = Ktd∗,Z , HtKX,∗ = K td Z,∗ and HtKX,XH>t = KtdZ,Z .",Appendix A. Temporal difference kernel,[0],[0]
"For a more detailed description of the hierarchical structure of the homeService environment, this appendix presents two example dialogues between an user and the system.",Appendix B. Example homeService dialogues,[0],[0]
"The second column represents the actions taken either by the user (commands) or by the system (actions)
",Appendix B. Example homeService dialogues,[0],[0]
"Dialogue 1: Goal = {TV, Channel, One} Dialogue starts in node “Devices” Sub-dialogue “Devices”
User TV ( Speaks the command “TV”) System Ask (Requests to repeat last command) User TV (Repeats his last command) System TV (Dialogue transitions to node “TV”)
",Appendix B. Example homeService dialogues,[0],[0]
Sub-dialogue “TV” User Chan.,Appendix B. Example homeService dialogues,[0],[0]
(Command “Channel”) System Chan.,Appendix B. Example homeService dialogues,[0],[0]
"(Transitions to node “Channel”)
",Appendix B. Example homeService dialogues,[0],[0]
Sub-dialogue “Channel” User One (Command “One”) System One (Performs action TV-Channel-One),Appendix B. Example homeService dialogues,[0],[0]
"As an action has been taken in a terminal node, the dialogue ends.
",Appendix B. Example homeService dialogues,[0],[0]
"Dialogue 2: Goal = {Hi-fi, On} Dialogue starts in node “Devices” Sub-dialogue “Devices”
User Hi-fi (Command “Hi-fi”) System Light (transitions to node Light)
",Appendix B. Example homeService dialogues,[0],[0]
"Sub-dialogue “Light” User Back (Requests to go to previous node) System Back (transitions to node Devices)
Sub-dialogue “Devices” User Hi-fi (Command “Hi-fi”)",Appendix B. Example homeService dialogues,[0],[0]
"System Hi-fi (transitions to node Hi-fi)
Sub-dialogue “Hi-fi” User On (Command “On”) System Off (Performs action Hifi-Off)",Appendix B. Example homeService dialogues,[0],[0]
"As the action taken in the terminal node does not match the goal, it is a failed dialogue.",Appendix B. Example homeService dialogues,[0],[0]
"Model-free reinforcement learning has been shown to be a promising data driven approach for automatic dialogue policy optimization, but a relatively large amount of dialogue interactions is needed before the system reaches reasonable performance.",abstractText,[0],[0]
"Recently, Gaussian process based reinforcement learning methods have been shown to reduce the number of dialogues needed to reach optimal performance, and pre-training the policy with data gathered from different dialogue systems has further reduced this amount.",abstractText,[0],[0]
"Following this idea, a dialogue system designed for a single speaker can be initialised with data from other speakers, but if the dynamics of the speakers are very different the model will have a poor performance.",abstractText,[0],[0]
"When data gathered from different speakers is available, selecting the data from the most similar ones might improve the performance.",abstractText,[0],[0]
"We propose a method which automatically selects the data to transfer by defining a similarity measure between speakers, and uses this measure to weight the influence of the data from each speaker in the policy model.",abstractText,[0],[0]
The methods are tested by simulating users with different severities of dysarthria interacting with a voice enabled environmental control system.,abstractText,[0],[0]
Knowledge transfer between speakers for personalised dialogue management,title,[0],[0]
"Proceedings of NAACL-HLT 2013, pages 1206–1215, Atlanta, Georgia, 9–14 June 2013. c©2013 Association for Computational Linguistics",text,[0],[0]
"Despite morphological phenomena’s salience in most human languages, many NLP systems treat fully inflected forms as the atomic units of language.",1 Introduction,[0],[0]
"By assuming independence of lexical stems’ various surface forms, this avoidance approach exacerbates the problem of data sparseness.",1 Introduction,[0],[0]
"If it is employed at all, morphological analysis of text tends to be treated as a preprocessing step to other NLP modules.",1 Introduction,[0],[0]
"While this latter disambiguation approach helps address data sparsity concerns, it has substantial drawbacks: it requires supervised learning from expert-annotated corpora, and determining the optimal morphological granularity is labor-intensive (Habash and Sadat, 2006).
",1 Introduction,[0],[0]
"Neither approach fully exploits the finite-state transducer (FST) technology that has been so successful for modeling the mapping between surface
forms and their morphological analyses (Karttunen and Beesley, 2005), and the mature collections of high quality transducers that already exist for many languages (e.g., Turkish, Russian, Arabic).",1 Introduction,[0],[0]
"Much linguistic knowledge is encoded in such FSTs.
",1 Introduction,[0],[0]
"In this paper, we develop morphology-aware nonparametric Bayesian language models that bring together hand-written FSTs with statistical modeling and require no token-level annotation.",1 Introduction,[0],[0]
The sparsity issue discussed above is addressed by hierarchical priors that share statistical strength across different inflections of the same stem by backing off to word formation models that piece together morphemes using FSTs.,1 Introduction,[0],[0]
"Furthermore, because of the nonparametric formulation of our models, the regular morphological patterns found in the long tail of word types will rely more heavily on deeper analysis, while frequent and idiosyncratically behaved forms are modeled opaquely.
",1 Introduction,[0],[0]
"Our prior can be used in virtually any generative model of language as a replacement for multinomial distributions over words, bringing morphological awareness to numerous applications.",1 Introduction,[0],[0]
"For various morphologically rich languages, we show that:
• our model can provide rudimentary unsupervised disambiguation for a highly ambiguous analyzer;
• integrating morphology into n-gram language models allows better generalization to unseen words and can improve the performance of applications that are truly open vocabulary; and
• bilingual word alignment models also benefit greatly from sharing translation information
1206
across stems.
",1 Introduction,[0],[0]
"We are particularly interested in low-resource scenarios, where one has to make the most of the small quantity of available data, and overcoming data sparseness is crucial.",1 Introduction,[0],[0]
"If analyzers exist in such settings, they tend to be highly ambiguous, and annotated data for learning to disambiguate are also likely to be scarce or non-existent.",1 Introduction,[0],[0]
"Therefore, in our experiments with Russian, we compare two analyzers: a rapidly-developed guesser, which models regular inflectional paradigms but contains no lexicon or irregular forms, and a high-quality analyzer.",1 Introduction,[0],[0]
"In this section, we describe a generative model of word formation based on Pitman-Yor processes that generates word types using a finite-state morphological generator.",2 Word Models with Morphology,[0],[0]
"At a high level, the process first produces lexicons of stems and inflectional patterns; then it generates a lexicon of inflected forms using the finite-state generator.",2 Word Models with Morphology,[0],[0]
"Finally, the inflected forms are used to generate observed data.",2 Word Models with Morphology,[0],[0]
"Different independence assumptions can be made at each of these levels to encode beliefs about where stems, inflections, and surface forms should share statistical strength.",2 Word Models with Morphology,[0],[0]
"Our work relies extensively on Pitman-Yor processes, which provide a flexible framework for expressing backoff and interpolation relationships and extending standard models with richer word distributions (Pitman and Yor, 1997).",2.1 Pitman-Yor Processes,[0],[0]
"They have been shown to match the performance of state-of-the-art language models and to give estimates that follow appropriate power laws (Teh, 2006).
",2.1 Pitman-Yor Processes,[0],[0]
"A draw from a Pitman-Yor process (PYP), denoted G ∼ PY(d, θ,G0), is a discrete distribution over a (possibly infinite) set of events, which we denote abstractly E .",2.1 Pitman-Yor Processes,[0],[0]
The process is parameterized by a discount parameter 0 ≤,2.1 Pitman-Yor Processes,[0],[0]
"d < 1, a strength parameter θ > −d, and a base distribution G0 over the event space E .
",2.1 Pitman-Yor Processes,[0],[0]
"In this work, our focus is on the base distribution G0.",2.1 Pitman-Yor Processes,[0],[0]
"We place vague priors on the hyperparameters d ∼ U([0, 1]) and (θ + d) ∼ Gamma(1, 1).",2.1 Pitman-Yor Processes,[0],[0]
Inference in PYPs is discussed below.,2.1 Pitman-Yor Processes,[0],[0]
The most basic expression of our model is a unigram model of text.,2.2 Unigram Morphology Model,[0],[0]
"So far, we only assume that each word can be analyzed into a stem and a sequence of morphemes forming an inflection pattern.",2.2 Unigram Morphology Model,[0],[0]
"LetGs be a distribution over stems,Gp be a distribution over inflectional patterns, and let GENERATE be a deterministic mapping from 〈stem, pattern〉 pairs to inflected word forms.1 An inflected word type is generated with the following process, which we designate MP(Gs, Gd,GENERATE):
stem ∼ Gs pattern ∼ Gp
word = GENERATE(stem, pattern)
",2.2 Unigram Morphology Model,[0],[0]
"For example, in Russian, we might sample stem = прочий,2 pattern = STEM+Adj+Pl+Dat, and obtain word = прочим.
",2.2 Unigram Morphology Model,[0],[0]
This model could be used directly to generate observed tokens.,2.2 Unigram Morphology Model,[0],[0]
"However, we have said nothing about Gs and Gp, and the assumption that stems and patterns are independent is clearly unsatisfying.",2.2 Unigram Morphology Model,[0],[0]
"We therefore assume that both the stem and the pattern distributions are generated from PY processes, and that MP(Gs, Gp,GENERATE) is itself the base distribution of a PYP.
",2.2 Unigram Morphology Model,[0],[0]
"Gs ∼ PY(ds, θs, G0s) Gp ∼ PY(dp, θp, G0p)",2.2 Unigram Morphology Model,[0],[0]
"Gw ∼ PY(d, θ,MP(Gs, Gp,GENERATE))
",2.2 Unigram Morphology Model,[0],[0]
"A draw Gw from this PYP is a unigram distribution over tokens.
",2.2 Unigram Morphology Model,[0],[0]
"2.3 Base Stem Model G0s In general there are an unbounded number of stems possible in any language, so we set G0s to be character trigram model, which we statically estimate, with Kneser-Ney smoothing, from a large corpus of word types in the language being modeled.",2.2 Unigram Morphology Model,[0],[0]
"While using fixed parameters estimated to maximize likelihood is
1The assumption of determinism is only inappropriate in cases of inflectional spelling variants (e.g., modeled vs. modelled) or pronunciation variants (e.g., reduced forms in certain environments).
2прочий (pronounced [pr5tCij]) = other
questionable from the perspective of Bayesian learning, it is tremendously beneficial for computational reasons.",2.2 Unigram Morphology Model,[0],[0]
"For some applications (e.g., word alignment), the set of possible stems for a corpus S can be precomputed, so we will also experiment with using a uniform stem distribution based on this set.
",2.2 Unigram Morphology Model,[0],[0]
2.4 Base Pattern Model G0p,2.2 Unigram Morphology Model,[0],[0]
"Several choices are possible for the base pattern distribution:
MP0 We can assume a uniformG0p when the number of patterns is small.
",2.2 Unigram Morphology Model,[0],[0]
"MP1 To be able to generalize to new patterns, we can draw the length of the pattern from a Poisson distribution and generate morphemes one by one from a uniform distribution.
",2.2 Unigram Morphology Model,[0],[0]
"MP2 A more informative prior is a Markov chain of morphemes, where each morpheme is generated conditional on the preceding morpheme.
",2.2 Unigram Morphology Model,[0],[0]
"The choice of the base pattern distribution could depend on the complexity of the inflectional patterns produced by the morphological analyzer, reflecting the type of morphological phenomena present in a given language.",2.2 Unigram Morphology Model,[0],[0]
"For example, the number of possible patterns can practically be considered finite in Russian, but this assumption is not valid for languages with more extensive derivational morphology like Turkish.",2.2 Unigram Morphology Model,[0],[0]
"For most applications, rather than directly generating from a model using the processes outlined above, we seek to infer posterior distributions over latent parameters and structures, given a sample of data.
",2.5 Posterior Inference,[0],[0]
"Although there is no known analytic form of the PYP density, it is possible to marginalize the draws from it and to work directly with observations.",2.5 Posterior Inference,[0],[0]
"This marginalization produces the classical Chinese restaurant process representation (Teh, 2006).",2.5 Posterior Inference,[0],[0]
"When working with the morphology models we are proposing, we also need to marginalize the different latent forms (stems s and patterns p) that may have given rise to a given word",2.5 Posterior Inference,[0],[0]
"w. Thus, we require that the inverse relation of GENERATE is
available to compute the marginal base word distribution:
p(w | G0w) =",2.5 Posterior Inference,[0],[0]
"∑
GENERATE(s,p)=w
p(s | Gs) p(p",2.5 Posterior Inference,[0],[0]
"| Gp)
Since our approach encodes morphology using FSTs, which are invertible, this poses no problem.
",2.5 Posterior Inference,[0],[0]
"To illustrate, consider the Russian word прочим, which may be analyzed in several ways:
прочий +Adj +Sg +Neut +Instr прочий +Adj +Sg +Masc +Instr прочий +Adj +Pl +Dat
прочить +Verb +Pl +1P прочее +Pro +Sg +Ins
Because the set of possible analyses is in general small, marginalization is fast and complex",2.5 Posterior Inference,[0],[0]
"blocked sampling is not necessary.
",2.5 Posterior Inference,[0],[0]
"Finally, to infer hyperparameter values (d, θ, . . .)",2.5 Posterior Inference,[0],[0]
", a Metropolis-Hastings update is interleaved with Gibbs sampling steps for the rest of the hidden variables.3
Having described a model for generating words, we now show its usage in several contexts.",2.5 Posterior Inference,[0],[0]
"Given a rule-based morphological analyzer encoded as an unweighted FST and a corpus on which the analyzer has been run – possibly generating multiple analyses for each token – we can use our unigram model to learn a probabilistic model of disambiguation in an unsupervised setting (i.e., without annotated examples).",3 Unsupervised Morphological Disambiguation,[0],[0]
The corpus is assumed to be generated from the unigram distribution,3 Unsupervised Morphological Disambiguation,[0],[0]
"Gw, and the base stem model is set to a fixed character trigram",3 Unsupervised Morphological Disambiguation,[0],[0]
model.4,3 Unsupervised Morphological Disambiguation,[0],[0]
"After learning the parameters of the model, we can find for each word in the vocabulary its most likely analysis and use this as a crude disambiguation step.
",3 Unsupervised Morphological Disambiguation,[0],[0]
"3The proposal distribution for Metropolis-Hastings is a Beta distribution (d) or a Gamma distribution (θ+d) centered on the previous parameter values.
",3 Unsupervised Morphological Disambiguation,[0],[0]
4Experiments suggest that this is important to constrain the model to realistic stems.,3 Unsupervised Morphological Disambiguation,[0],[0]
"Finite-state morphological analyzers are usually specified in three parts: a stem lexicon, which defines the words in the language and classifies them into several categories according to their grammatical function and their morphological properties; a set of prefixes and suffixes that can be applied to each category to form surface words; and possibly alternation rules that can encode exceptions and spelling variations.",3.1 Morphological Guessers,[0],[0]
The combination of these parts provides a powerful framework for defining a generative model of words.,3.1 Morphological Guessers,[0],[0]
Such models can be reversed to obtain an analyzer.,3.1 Morphological Guessers,[0],[0]
"However, while the two latter parts can be relatively easy to specify, enumerating a comprehensive stem lexicon is a time consuming and necessarily incomplete process, as some categories are truly open-class.
",3.1 Morphological Guessers,[0],[0]
"To allow unknown words to be analyzed, one can use a guesser that attempts to analyze words missing in the lexicon.",3.1 Morphological Guessers,[0],[0]
Can we eliminate the stem lexicon completely and use only the guesser?,3.1 Morphological Guessers,[0],[0]
This is what we try to do by designing a lexicon-free analyzer for Russian.,3.1 Morphological Guessers,[0],[0]
"A guesser was developed in three hours; it is prone to over-generation and produces ambiguous analyses for most words but covers a large number of morphological phenomena (gender, case, tense, etc.).",3.1 Morphological Guessers,[0],[0]
"For example, the word иврите5 can be correctly analyzed as иврит+Noun+Masc+Prep+Sg but also as the incorrect forms: иврить+Verb+Pres+2P+Pl, иврита+Noun+Fem+Dat+Sg, ивритя+Noun+Fem+Prep+Sg, and more.",3.1 Morphological Guessers,[0],[0]
"We train the unigram model on a 1.7M-word corpus of TED talks transcriptions translated into Russian (Cettolo et al., 2012) and evaluate our analyzer against a test set consisting of 1,500 goldstandard analyses obtained from the morphology disambiguation task of the DIALOG 2010 conference (Lyaševskaya et al., 2010).6
Each analysis is composed of a lemma (иврит), a part of speech (Noun), and a sequence of additional functional morphemes (Masc,Prep,Sg).",3.2 Disambiguation Experiments,[0],[0]
"We consider only open-class categories: nouns, ad-
5иврите = Hebrew (masculine noun, prepositional case) 6http://ru-eval.ru
jectives, adverbs and verbs, and evaluate the output of our model with three metrics: the lemma accuracy, the part-of-speech accuracy, and the morphology F -measure.7
As a baseline, we consider picking a random analysis from output of the analyzer or choosing the most frequent lemma and the most frequent morphological pattern.8",3.2 Disambiguation Experiments,[0],[0]
"Then, we use our model with each of the three versions of the pattern model described in §2.2.",3.2 Disambiguation Experiments,[0],[0]
"Finally, as an upper bound, we use the gold standard to select one of the analyses produced by the guesser.
",3.2 Disambiguation Experiments,[0],[0]
"Since our evaluation is not directly comparable to the standard for this task, we use for reference a high-quality analyzer from Xerox9 disambiguated with the MP0 model (all of the models have very close accuracy in this case).
",3.2 Disambiguation Experiments,[0],[0]
"Considering the amount of effort put in developing the guesser, the baseline POS tagging accuracy is relatively good.",3.2 Disambiguation Experiments,[0],[0]
"However, the disambiguation is largely improved by using our unigram model with respect to all the evaluation categories.",3.2 Disambiguation Experiments,[0],[0]
"We are still far from the performance of a high-quality analyzer but, in absence of such a resource, our technique might be a sensible option.",3.2 Disambiguation Experiments,[0],[0]
"We also note that there is no clear winner in terms of pattern model, and conclude that this choice is task-specific.
",3.2 Disambiguation Experiments,[0],[0]
"7F -measure computed for the set of additional morphemes and averaged over the words in the corpus.
8We estimate these frequencies by assuming each analysis of each token is uniformly likely, then summing fractional counts.
",3.2 Disambiguation Experiments,[0],[0]
9http://open.xerox.com/Services/ fst-nlp-tools/Pages/morphology,3.2 Disambiguation Experiments,[0],[0]
We now integrate our unigram model in a hierarchical Pitman-Yor n-gram language model (Fig. 1).,4 Open Vocabulary Language Models,[0],[0]
"The training corpus words are assumed to be generated from a distribution Gnw drawn from PY(dn, θn, G n−1 w ), where G n−1 w is defined recursively down to the base model G0w.",4 Open Vocabulary Language Models,[0],[0]
"Previous work Teh (2006) simply used G0w = U(V ) where V is the word vocabulary, but in our case G0w is the MP defined in §2.2.
",4 Open Vocabulary Language Models,[0],[0]
We are interested in evaluating our model in an open vocabulary scenario where the ability to explain new unseen words matters.,4 Open Vocabulary Language Models,[0],[0]
"We expect our model to be able to generalize better thanks to the combination of a morphological analyzer and a stem distribution which is less sparse than the word distribution (for example, for the 1.6M word Turkish corpus, |V",4 Open Vocabulary Language Models,[0],[0]
"| ≈ 3.5|S| ≈ 140k).
",4 Open Vocabulary Language Models,[0],[0]
"To integrate out-of-vocabulary words in our evaluation, we use infinite base distributions: G0w (in the baseline model) or G0s (in the MP) are character trigram models.",4 Open Vocabulary Language Models,[0],[0]
"We define perplexity of a held-out test corpus in the standard way:
ppl = exp ( − 1 N N∑ i=1",4 Open Vocabulary Language Models,[0],[0]
"log p (wi | wi−n+1 · · ·wi−1) )
",4 Open Vocabulary Language Models,[0],[0]
"but compared to the common practice, we do not need to discount OOVs from this sum since the model vocabulary is infinite.",4 Open Vocabulary Language Models,[0],[0]
Note that we also marginalize by summing over all the possible analyses for a given word when computing its base probability according to the MP.,4 Open Vocabulary Language Models,[0],[0]
We train several trigram models on the Russian TED talks corpus used in the previous section.,4.1 Language Modeling Experiments,[0],[0]
Our baseline is a hierarchical PY trigram model with a trigram character model as the base word distribution.,4.1 Language Modeling Experiments,[0],[0]
We compare it with our model using the same character model for the base stem distribution.,4.1 Language Modeling Experiments,[0],[0]
Both of the morphological analyzers described in the previous section help obtaining perplexity reductions (Table 2).,4.1 Language Modeling Experiments,[0],[0]
"We ran a similar experiment on the Turkish version of this corpus (1.6M words) with a highquality analyzer (Oflazer, 1994) and obtain even larger gains (Table 3).
",4.1 Language Modeling Experiments,[0],[0]
These results can partly be attributed to the high OOV rate in these conditions: 4% for the Russian corpus and 6% for the Turkish corpus.,4.1 Language Modeling Experiments,[0],[0]
"It is difficult to know whether a decrease in perplexity, as measured in the previous section, will result in a performance improvement in downstream applications.",4.2 Predictive Text Input,[0],[0]
"As a confirmation that correctly modeling new words matters, we consider a predictive task with a truly open vocabulary and that requires only a language model: predictive text input.
",4.2 Predictive Text Input,[0],[0]
"Given some text, we encode it using a lossy deterministic character mapping, and try to recover the original content by computing the most likely word sequence.",4.2 Predictive Text Input,[0],[0]
This task is inspired by predictive text input systems available on cellphones with a 9-key keypad.,4.2 Predictive Text Input,[0],[0]
"For example, the string gave me a cup is encoded as 4283 63 2 287, which could also be decoded as: hate of a bus.
",4.2 Predictive Text Input,[0],[0]
"Silfverberg et al. (2012) describe a system designed for this task in Finnish, which is composed of a weighted finite-state morphological analyzer trained on IRC logs.",4.2 Predictive Text Input,[0],[0]
"However, their system is restricted to words that are encoded in the analyzer’s lexicon and does not use context for disambiguation.
",4.2 Predictive Text Input,[0],[0]
"In our experiments, we use the same Turkish TED talks corpus as the previous section.",4.2 Predictive Text Input,[0],[0]
"As a baseline, we use a trigram character language model.",4.2 Predictive Text Input,[0],[0]
We produce a character lattice which encodes all the possible interpretations for a word and compose it with a finite-state representation of the character LM using OpenFST,4.2 Predictive Text Input,[0],[0]
"(Allauzen et al., 2007).",4.2 Predictive Text Input,[0],[0]
"Alternatively, we can use a unigram word model to decode this lattice, backing off to the character language model if no solution is found.",4.2 Predictive Text Input,[0],[0]
"Finally, to be able to make use of word context, we can extract the k most likely paths according to the character LM and produce a word lattice, which is in turn decoded with a language model defined over the extracted vocabulary.
",4.2 Predictive Text Input,[0],[0]
"We measure word and character error rate (WER, CER) on the predicted word sequence and observe large improvements in both of these metrics by modeling morphology, both at the unigram level and when context is used (Table 4).
",4.2 Predictive Text Input,[0],[0]
"Preliminary experiments with a corpus of 1.6M Turkish tweets, an arguably more appropriate domain this task, show smaller but consistent improving: the trigram word error rate is reduced from 26% to 24% when our model is used.",4.2 Predictive Text Input,[0],[0]
"While our model is an important step forward in practical modeling of OOVs using morphological processes, we have made the linguistically naive assumption that morphology applies inside the language’s lexicon but has no effect on the process that put inflected lexemes together into sentences.",4.3 Limitations,[0],[0]
"In this
regard, our model is a minor variant on traditional ngram models that work with “opaque” word forms.",4.3 Limitations,[0],[0]
How to best relax this assumption in a computationally tractable way is an important open question left for future work.,4.3 Limitations,[0],[0]
Monolingual models of language are not the only models that can benefit from taking into account morphology.,5 Word Alignment Model,[0],[0]
"In fact, alignment models are a good candidate for using richer word distributions: they assume a target word distribution conditioned on each source word.",5 Word Alignment Model,[0],[0]
"When the target language is morphologically rich, classic independence assumptions produce very weak models unless some kind of preprocessing is applied to one side of the corpus.",5 Word Alignment Model,[0],[0]
"An alternative is to use our unigram model as a word translation distribution for each source word in the corpus.
",5 Word Alignment Model,[0],[0]
"Our alignment model is based on a simple variant of IBM Model 2 where the alignment distribution is only controlled by two parameters, λ and p0 (Dyer et al., 2013).",5 Word Alignment Model,[0],[0]
p0 is the probability of the null alignment.,5 Word Alignment Model,[0],[0]
"For a source sentence f of length n, a target sentence e of lengthm and a latent alignment a, we define the following alignment link probabilities (j 6= 0):
p(ai = j | n,m) ∝",5 Word Alignment Model,[0],[0]
(1− p0) exp ( −λ ∣∣∣∣,5 Word Alignment Model,[0],[0]
"im − jn ∣∣∣∣) λ controls the flatness of this distribution: larger values make the probabilities more peaked around the diagonal of the alignment matrix.
",5 Word Alignment Model,[0],[0]
"Each target word is then generated given a source word and a latent alignment link from the word translation distribution p(ei | fai , Gw).",5 Word Alignment Model,[0],[0]
"Note that this is effectively a unigram distribution over target words, albeit conditioned on the source word fj .",5 Word Alignment Model,[0],[0]
Here is where our model differs from classic alignment models: the unigram distribution Gw is assumed be generated from a PY process.,5 Word Alignment Model,[0],[0]
"There are two choices for the base word distribution:
• As a baseline, we use a uniform base distribution over the target vocabulary: G0w = U(V ).
",5 Word Alignment Model,[0],[0]
"• We define a stem distribution Gs[f ] for each source word f , a shared pattern distributionGp, and set G0w[f ] = MP(Gs[f ], Gp).",5 Word Alignment Model,[0],[0]
"In this case,
we obtain the model depicted in Fig. 2.",5 Word Alignment Model,[0],[0]
"The stem and the pattern models are also given PY priors with uniform base distribution (G0s = U(S)).
",5 Word Alignment Model,[0],[0]
"Finally, we put uninformative priors on the alignment distribution parameters: p0 ∼ Beta(α, β) is collapsed and λ ∼ Gamma(k, θ) is inferred using Metropolis-Hastings.
",5 Word Alignment Model,[0],[0]
Experiments We evaluate the alignment error rate of our models for two language pairs with rich morphology on the target side.,5 Word Alignment Model,[0],[0]
"We compare to alignments inferred using IBM Model 4 trained with EM (Brown et al., 1993),10 a version of our baseline model (described above) without PY priors (learned using EM), and the PY-based baseline.",5 Word Alignment Model,[0],[0]
"We consider two language pairs.
",5 Word Alignment Model,[0],[0]
"English-Turkish We use a 2.8M word cleaned version of the South-East European Times corpus (Tyers and Alperen, 2010) and gold-standard alignments from Çakmak et al. (2012).",5 Word Alignment Model,[0],[0]
"Our morphological analyzer is identical to the one used in the previous sections.
",5 Word Alignment Model,[0],[0]
"English-Czech We use the 1.3M word News Commentary corpus and gold-standard alignments
10We use the default GIZA++ stage training scheme:",5 Word Alignment Model,[0],[0]
"Model 1 + HMM + Model 3 + Model 4.
from Bojar and Prokopová (2006).",5 Word Alignment Model,[0],[0]
"The morphological analyzer is provided by Xerox.
",5 Word Alignment Model,[0],[0]
Results Results are shown in Table 5.,5 Word Alignment Model,[0],[0]
Our lightly parameterized model performs much better than IBM Model 4 in these small-data conditions.,5 Word Alignment Model,[0],[0]
"With an identical model, we find PY priors outperform traditional multinomial distributions.",5 Word Alignment Model,[0],[0]
"Adding morphology further reduced the alignment error rate, for both languages.
",5 Word Alignment Model,[0],[0]
"As an example of how our model generalizes better, consider the sentence pair in Fig. 3, taken from the evaluation data.",5 Word Alignment Model,[0],[0]
"The two words composing the Turkish sentence are not found elsewhere in the corpus, but several related inflections occur.11",5 Word Alignment Model,[0],[0]
"It is therefore trivial for the stem-base model to find the correct alignment (marked in black), while all the other models have no evidence for it and choose an arbitrary alignment (gray points).",5 Word Alignment Model,[0],[0]
"Computational morphology has received considerable attention in NLP since the early work on twolevel morphology (Koskenniemi, 1984; Kaplan and
11ödevinin, ödevini, ödevleri; bitmez, bitirileceğinden, bitmesiyle, ...
Kay, 1994).",6 Related Work,[0],[0]
"It is now widely accepted that finitestate transducers have sufficient power to express nearly all morphological phenomena, and the XFST toolkit (Beesley and Karttunen, 2003) has contributed to the practical adoption of this modeling approach.",6 Related Work,[0],[0]
"Recently, open-source tools have been released: in this paper, we used Foma (Hulden, 2009) to develop the Russian guesser.
",6 Related Work,[0],[0]
"Since some inflected forms have several possible analyses, there has been a great deal of work on selecting the intended one in context (Hakkani-Tür et al., 2000; Hajič et al., 2001; Habash and Rambow, 2005; Smith et al., 2005; Habash et al., 2009).",6 Related Work,[0],[0]
"Our disambiguation model is closely related to generative models used for this purpose (Hakkani-Tür et al., 2000).
",6 Related Work,[0],[0]
"Rule-based analysis is not the only approach to modeling morphology, and many unsupervised models have been proposed.12 Heuristic segmentation approaches based on the minimum description length principle (Goldsmith, 2001; Creutz and Lagus, 2007; de Marcken, 1996; Brent et al., 1995) have been shown to be effective, and Bayesian model-based versions have been proposed as well (Goldwater et al., 2011; Snyder and Barzilay, 2008; Snover and Brent, 2001).",6 Related Work,[0],[0]
"In §3, we suggested a third way between rule-based approaches and fully unsupervised learning that combines the best of both worlds.
",6 Related Work,[0],[0]
"Morphological analysis or segmentation is crucial to the performance of several applications: machine translation (Goldwater and McClosky, 2005; AlHaj and Lavie, 2010; Oflazer and El-Kahlout, 2007; Minkov et al., 2007; Habash and Sadat, 2006, inter alia), automatic speech recognition (Creutz et al., 2007), and syntactic parsing (Tsarfaty et al., 2010).",6 Related Work,[0],[0]
"Several methods have been proposed to integrate morphology into n-gram language models, including factored language models (Bilmes and Kirchhoff, 2003), discriminative language modeling (Arısoy et al., 2008), and more heuristic approaches (Monz, 2011).
",6 Related Work,[0],[0]
"Despite the fundamentally open nature of the lexicon (Heaps, 1978), there has been distressingly lit-
12Developing a high-coverage analyzer can be a timeconsuming process even with the simplicity of modern toolkits, and unsupervised morphology learning is an attractive problem for computational cognitive science.
",6 Related Work,[0],[0]
tle attention to the general problem of open vocabulary language modeling problem (most applications make a closed-vocabulary assumption).,6 Related Work,[0],[0]
"The classic exploration of open vocabulary language modeling is Brown et al. (1992), which proposed the strategy of interpolating between word- and character-based models.",6 Related Work,[0],[0]
Character-based language models are reviewed by Carpenter (2005).,6 Related Work,[0],[0]
"So-called hybrid models that model both words and sublexical units have become popular in speech recognition (Shaik et al., 2012; Parada et al., 2011; Bazzi, 2002).",6 Related Work,[0],[0]
"Openvocabulary language language modeling has also recently been explored in the context of assistive technologies (Roark, 2009).
",6 Related Work,[0],[0]
"Finally, Pitman-Yor processes (PYPs) have become widespread in natural language processing since they are natural power-law generators.",6 Related Work,[0],[0]
"It has been shown that the widely used modified KneserNey estimator (Chen and Goodman, 1998) for ngram language models is an approximation of the posterior predictive distribution of a language model with hierarchical PYP priors (Goldwater et al., 2011; Teh, 2006).",6 Related Work,[0],[0]
We described a generative model which makes use of morphological analyzers to produce richer word distributions through sharing of statistical strength between stems.,7 Conclusion,[0],[0]
We have shown how it can be integrated into several models central to NLP applications and have empirically validated the effectiveness of these changes.,7 Conclusion,[0],[0]
"Although this paper mostly focused on languages that are well studied and for which high-quality analyzers are available, our models are especially relevant in low-resource scenarios because they do not require disambiguated analyses.",7 Conclusion,[0],[0]
"In future work, we plan to apply these techniques to languages such as Kinyarwanda, a resource-poor but morphologically rich language spoken in Rwanda.",7 Conclusion,[0],[0]
It is our belief that knowledge-rich models can help bridge the gap between low- and high-resource languages.,7 Conclusion,[0],[0]
"We thank Kemal Oflazer for making his Turkish language morphological analyzer available to us and Brendan O’Connor for gathering the Turkish tweets used in
the predictive text experiments.",Acknowledgments,[0],[0]
This work was sponsored by the U. S. Army Research Laboratory and the U. S. Army Research Office under contract/grant number W911NF-10-1-0533.,Acknowledgments,[0],[0]
We present a morphology-aware nonparametric Bayesian model of language whose prior distribution uses manually constructed finitestate transducers to capture the word formation processes of particular languages.,abstractText,[0],[0]
"This relaxes the word independence assumption and enables sharing of statistical strength across, for example, stems or inflectional paradigms in different contexts.",abstractText,[0],[0]
Our model can be used in virtually any scenario where multinomial distributions over words would be used.,abstractText,[0],[0]
"We obtain state-of-the-art results in language modeling, word alignment, and unsupervised morphological disambiguation for a variety of morphologically rich languages.",abstractText,[0],[0]
Knowledge-Rich Morphological Priors for Bayesian Language Models,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 821–832 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
821",text,[0],[0]
"Reading comprehension (RC) is a language understanding task similar to question answering, where a system is expected to read a given passage of text and answer questions about it.",1 Introduction,[0],[0]
"Cloze-style reading comprehension is a task setting where the question is formed by replacing a token in a sentence of the story with a placeholder (left part of Figure 1).
",1 Introduction,[0],[0]
"In contrast to many previous complex models (Weston et al., 2015; Dhingra et al., 2017; Cui et al., 2017; Munkhdalai and Yu, 2016; Sordoni et al., 2016) that perform multi-turn reading of a story and a question before inferring the correct answer, we aim to tackle the cloze-style RC task in a way that resembles how humans solve it: using, in addition, background knowledge.",1 Introduction,[0],[0]
"We develop
a neural model for RC that can successfully deal with tasks where most of the information to infer answers from is given in the document (story), but where additional information is needed to predict the answer, which can be retrieved from a knowledge base and added to the context representations explicitly.1",1 Introduction,[0],[0]
"An illustration is given in Figure 1.
",1 Introduction,[0],[0]
"Such knowledge may be commonsense knowledge or factual background knowledge about entities and events that is not explicitly expressed but can be found in a knowledge base such as ConceptNet (Speer et al., 2017), BabelNet (Navigli and Ponzetto, 2012), Freebase (Tanon et al., 2016) or domain-specific KBs collected with Information Extraction approaches (Fader et al., 2011; Mausam et al., 2012; Bhutani et al., 2016).",1 Introduction,[0],[0]
"Thus, we aim to define a neural model that encodes preselected knowledge in a memory, and that learns to include the available knowledge as an enrichment to the context representation.
",1 Introduction,[0],[0]
"The main difference of our model to prior state-of-the-art is that instead of relying only on document-to-question interaction or discrete features while performing multiple hops over the document, our model (i) attends to relevant selected
1‘Context representation’ refers to a vector representation computed from textual information only (i.e., document (story) or question).
",1 Introduction,[0],[0]
"external knowledge and (ii) combines this knowledge with the context representation before inferring the answer, in a single hop.",1 Introduction,[0],[0]
"This allows the model to explicitly imply knowledge that is not stated in the text, but is relevant for inferring the answer, and that can be found in an external knowledge source.",1 Introduction,[0],[0]
"Moreover, by including knowledge explicitly, our model provides evidence and insight about the used knowledge in the RC.
",1 Introduction,[0],[0]
"Our main contributions are: (i) We develop a method for integrating knowledge in a simple but effective reading comprehension model (AS Reader, Kadlec et al. (2016)) and improve its results significantly whereas other models employ features or multiple hops.",1 Introduction,[0],[0]
"(ii) We examine two sources of common knowledge: WordNet (Miller et al., 1990) and ConceptNet (Speer et al., 2017) and show that this type of knowledge is important for answering common nouns questions and also improves slightly the performance for named entities.
",1 Introduction,[0],[0]
"(iii) We show that knowledge facts can be added directly to the text-only representation, enriching the neural context encoding.",1 Introduction,[0],[0]
(iv) We demonstrate the effectiveness of the injected knowledge by case studies and data statistics in a qualitative evaluation study.,1 Introduction,[0],[0]
"In this work, we examine the impact of using external knowledge as supporting information for the task of cloze style reading comprehension.
",2 Reading Comprehension with Background Knowledge Sources,[0],[0]
We build a system with two modules.,2 Reading Comprehension with Background Knowledge Sources,[0],[0]
"The first, Knowledge Retrieval, performs fact retrieval and selects a number of facts f1, ..., fp that might be relevant for connecting story, question and candidate answers.",2 Reading Comprehension with Background Knowledge Sources,[0],[0]
"The second, main module, the Knowledgeable Reader, is a knowledge-enhanced neural module.",2 Reading Comprehension with Background Knowledge Sources,[0],[0]
"It uses the input of the story context tokens d1..m, the question tokens q1..n, the set of answer candidates a1..k and a set of ‘relevant’ background knowledge facts f1..p in order to select the right answer.",2 Reading Comprehension with Background Knowledge Sources,[0],[0]
"To include external knowledge for the RC task, we encode each fact f1..p and use attention to select the most relevant among them for each token in the story and question.",2 Reading Comprehension with Background Knowledge Sources,[0],[0]
We expect that enriching the text with additional knowledge about the mentioned concepts will improve the prediction of correct answers in a strong single-pass system.,2 Reading Comprehension with Background Knowledge Sources,[0],[0]
See Figure 1 for illustration.,2 Reading Comprehension with Background Knowledge Sources,[0],[0]
"In our experiments we use knowledge from the Open Mind Common Sense (OMCS, Singh et al. (2002)) part of ConceptNet, a crowd-sourced resource of commonsense knowledge with a total of ∼630k facts.",2.1 Knowledge Retrieval,[0],[0]
"Each fact fi is represented as a triple fi=(subject, relation, object), where subject and object can be multi-word expressions and relation is a relation type.",2.1 Knowledge Retrieval,[0],[0]
"An example is: ([bow]subj , [IsUsedFor]rel, [hunt, animals]obj)
",2.1 Knowledge Retrieval,[0],[0]
"We experiment with three set-ups: using (i) all facts from OMCS that pertain to ConceptNet, referred to as CN5All, (ii) using all facts from CN5All excluding some WordNet relations referred to as CN5Sel(ected) (see Section 3), and using (iii) facts from OMCS that have source set to WordNet (CN5WN3).
",2.1 Knowledge Retrieval,[0],[0]
Retrieving relevant knowledge.,2.1 Knowledge Retrieval,[0],[0]
"For each instance (D, Q, A1..10) we retrieve relevant commonsense background facts.",2.1 Knowledge Retrieval,[0],[0]
"We first retrieve facts that contain lemmas that can be looked up via tokens contained in any D(ocument), Q(uestion) or A(nswer candidates).",2.1 Knowledge Retrieval,[0],[0]
"We add a weight value for each node: 4, if it contains a lemma of a candidate token from A; 3, if it contains a lemma from the tokens of Q; and 2 if it contains a lemma from the tokens of D. The selected weights are chosen heuristically such that they model relative fact importance in different interactions as A+A > A+Q",2.1 Knowledge Retrieval,[0],[0]
> A+D,2.1 Knowledge Retrieval,[0],[0]
>D+Q>,2.1 Knowledge Retrieval,[0],[0]
"D+D. We weight the fact triples that contain these lemmas as nodes, by summing the weights of the subject and object arguments.",2.1 Knowledge Retrieval,[0],[0]
"Next, we sort the knowledge triples by this overall weight value.",2.1 Knowledge Retrieval,[0],[0]
"To limit the memory of our model, we run experiments with different sizes of the top number of facts (P ) selected from all instance fact candidates, P ∈ {50, 100, 200}.",2.1 Knowledge Retrieval,[0],[0]
"As additional retrieval limitation, we force the number of facts per answer candidate to be the same, in order to avoid a frequency bias for an answer candidate that appears more often in the knowledge source.",2.1 Knowledge Retrieval,[0],[0]
"Thus, if we select the maximum 100 facts for each task instance and we have 10 answer candidates ai=1..10, we retrieve the top 10 facts for each candidate ai that has either a subject or an object lemma for a token in ai.",2.1 Knowledge Retrieval,[0],[0]
"If the same fact contains lemmas of two candidates ai and aj (j > i), we add the fact once for ai and do not add the same fact again for aj .",2.1 Knowledge Retrieval,[0],[0]
"If several facts have the same weight, we take
the first in the order of the list2, i.e., the order of retrieval from the database.",2.1 Knowledge Retrieval,[0],[0]
"If one candidate has less than 10 facts, the overall fact candidates for the sample will be less than the maximum (100).",2.1 Knowledge Retrieval,[0],[0]
We implement our Knowledgeable Reader (KnReader) using as a basis the Attention Sum Reader as one of the strongest core models for single-hop RC.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
We extend it with a knowledge fact memory that is filled with pre-selected facts.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Our aim is to examine how adding commonsense knowledge to a simple yet effective model can improve the RC process and to show some evidence of that by attending on the incorporated knowledge facts.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"The model architecture is shown in Figure 2.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Base Attention Model.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"The Attention-Sum Reader (Kadlec et al., 2016), our base model for RC reads the input of story tokens d1..n, the question tokens q1..m, and the set of candidates a1..10 that occur in the story text.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
The model calculates the attention between the question representation rq and the story token context encodings of the candidate tokens a1..10 and sums the attention scores for the candidates that appear multiple times in the story.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"The model selects as answer the candidate that has the highest attention score.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Word Embeddings Layer.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We represent input document and question tokens w by looking up their embedding representations ei = Emb(wi), where Emb is an embedding lookup function.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We apply dropout (Srivastava et al., 2014) with keep
2We also experimented with re-ranking the facts with the same weight sums using tf-idf",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"but we did not notice a difference in performance.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"probability p = 0.8 to the output of the embeddings lookup layer.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Context Representations.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"To represent the document and question contexts, we first encode the tokens with a Bi-directional GRU (Gated Recurrent Unit) (Chung et al., 2014) to obtain context-encoded representations for document (cctxd1..n) and question (cctxq1..m) encoding:
cctxd1..n =",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
BiGRU ctx(ed1..n) ∈ Rn×2h (1) cctxq1..m = BiGRU ctx(eq1..m) ∈,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Rm×2h (2)
, where di and qi denote the ith token of a text sequence d (document) and q (question), respectively, n and m is the size of d and q and h the output hidden size (256) of a single GRU unit.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"BiGRU is defined in (3), with ei a word embedding vector
BiGRU ctx(ei, hiprev) =",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"[ −−−→ GRU(ei, −−−→ hiprev),
←−−− GRU(ei, ←−−− hiprev)]
(3)
, where hiprev = [ −−−→ hiprev , ←−−− hiprev ], and −−−→ hiprev and ←−−− hiprev are the previous hidden states of the forward and backward layers.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Below we use BiGRU ctx(ei) without the hidden state, for short.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Question Query Representation.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
For the question we construct a single vector representation rctxq by retrieving the token representation at the placeholder (XXXX) index pl (cf.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Figure 2):
rctxq = c ctx qi..m [pl] ∈",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"R 2h (4)
where [pl] is an element pickup operation.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Our question vector representation is different from the original AS Reader that builds the question by concatenating the last states of a forward and backward layer [ −−−→ GRU(em), ←−−− GRU(e1)].",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We changed the original representation as we observed some very long questions and in this way aim to prevent the context encoder from ’forgetting’ where the placeholder is.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Answer Prediction: Qctx to Dctx Attention.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"In order to predict the correct answer to the given question, we rank the given answer candidates a1..aL according to the normalized attention sum score between the context (ctx) representation of the question placeholder rctxq and the representation of the candidate tokens in the document:
P (ai|q, d) = softmax( ∑ αij ) (5)
αij = Att(r ctx q , c ctx dj ), i ∈",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"[1..L] (6)
, where j is an index pointer from the list of indices that point to the candidate ai token occurrences in the document context representation cd.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Att is a dot product.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Enriching Context Representations with Knowledge (Context+Knowledge).,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"To enhance the representation of the context, we add knowledge, retrieved as a set of knowledge facts.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Knowledge Encoding.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"For each instance in the dataset, we retrieve a number of relevant facts (cf. Section 2.1).",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Each retrieved fact is represented as a triple f = (wsubj1..Lsubj , w rel 0 , w obj 1..Lobj ), where wsubj1..Lsubj and w obj 1..Lobj
are a multi-word expressions representing the subject and object with sequence lengths Lsubj and Lobj , and wrel0 is a word token corresponding to a relation.3",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"As a result of fact encoding, we obtain a separate knowledge memory for each instance in the data.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"To encode the knowledge we use a BiGRU to encode the triple argument tokens into the following context-encoded representations:
fsubjlast = BiGRU(Emb(w subj 1..Lsubj ), 0) (7)
f rellast = BiGRU(Emb(w rel 0 ), f subj last ) (8)
fobjlast = BiGRU(Emb(w obj 1..Lsubj ), f rellast) (9)
, where fsubjlast , f rel last, f obj last are the final hidden states of the context encoder BiGRU , that are also used as initial representations for the encoding of the next triple attribute in left-to-right order.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
See Supplement for comprehensive visualizations.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
The motivation behind this encoding is: (i),2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We encode the knowledge fact attributes in the same vector space as the plain tokens; (ii) we preserve the triple directionality; (iii) we use the relation type as a way of filtering the subject information to initialize the object.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Querying the Knowledge Memory.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"To enrich the context representation of the document and question tokens with the facts collected in the knowledge memory, we select a single sum of weighted fact representations for each token using Key-Value retrieval (Miller et al., 2016).",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
In our model the key Mk(ey)i can be either f subj last or f,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"obj last and the value Mv(alue)i is f obj last.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"For each context-encoded token cctxsi (s = d, q; i the token index)",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"we attend over all knowledge
3The 0 in wrel0 indicates that we encode the relation as a single relation type word.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Ex.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"/r/IsUsedFor.
memory keys Mki in the retrieved P knowledge facts.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We use an attention function Att, scale the scalar attention value using softmax, multiply it with the value representation Mvi and sum the result into a single vector value representation cknsi :
cknsi = ∑ softmax(Att(cctx,Mk1..P ))",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"TMv1..P
(10) Att is a dot product, but it can be replaced with another attention function.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"As a result of this operation, the context token representation cctxsi and the corresponding retrieved knowledge cknsi are in the same vector space ∈ R2h.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Combine Context and Knowledge (ctx+kn).,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We combine the original context token representation cctxsi , with the acquired knowledge representation cknsi to obtain c ctx+kn si :
cctx+knsi = γc ctx si + (1− γ)c kn si (11)
, where γ = 0.5.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We keep γ static but it can be replaced with a gating function.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Answer Prediction: Qctx(+kn) to Dctx(+kn).,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
To rank answer candidates a1..,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"aL we use attention sum similar to Eq.5 over an attention αensembleij that combines attentions between context (ctx) and context+knowledge (ctx+kn) representations of the question (rctx(+kn)q ) and candidate token occurrences aij in the document c ctx(+kn) dj :
P (ai|q, d) = softmax( ∑ αensembleij ) (12)
αensembleij =
W1Att(r ctx q , c ctx dj )
+W2Att(r ctx q , c ctx+kn dj ) +W3Att(r ctx+kn q , c ctx dj )
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"+W4Att(r ctx+kn q , c ctx+kn dj )
(13)
, where j is an index pointer from the list of indices that point to the candidate ai token occurrences in the document context representation c ctx(+kn) d .",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"W1..4 are scalar weights initialized with 1.0 and optimized during training.4 We propose the combination of ctx and ctx + kn attentions because our task does not provide supervision whether the knowledge is needed or not.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"4An example for learned W1..4 is (2.13, 1.41, 1.49, 1.84) in setting (CBT CN, CN5Sel, Subj-Obj as k-v, 50 facts).",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We experiment with knowledge-enhanced clozestyle reading comprehension using the Common Nouns and Named Entities partitions of the Children’s Book Test (CBT) dataset (Hill et al., 2015).
",3 Data and Task Description,[0],[0]
In the CBT cloze-style task a system is asked to read a children story context of 20 sentences.,3 Data and Task Description,[0],[0]
"The following 21st sentence involves a placeholder token that the system needs to predict, by choosing from a given set of 10 candidate words from the document.",3 Data and Task Description,[0],[0]
An example with suggested external knowledge facts is given in Figure 1.,3 Data and Task Description,[0],[0]
"While in its Common Nouns setup, the task can be considered as a language modeling task, Hill et al. (2015) show that humans can answer the questions without the full context with an accuracy of only 64.4% and a language model alone with 57.7%.",3 Data and Task Description,[0],[0]
"By contrast, the human performance when given the full context is at 81.6%.",3 Data and Task Description,[0],[0]
"Since the best neural model (Munkhdalai and Yu, 2016) achieves only 72.0% on the task, we hypothesize that the task itself can benefit from external knowledge.",3 Data and Task Description,[0],[0]
"The characteristics of the data are shown in Table 1.
",3 Data and Task Description,[0],[0]
"Other popular cloze-style datasets such as CNN/Daily Mail (Hermann et al., 2015) or WhoDidWhat (Onishi et al., 2016) are mainly focused on finding Named Entities where the benefit of adding commonsense knowledge (as we show for the NE part of CBT) would be more limited.
",3 Data and Task Description,[0],[0]
Knowledge Source.,3 Data and Task Description,[0],[0]
As a source of commonsense knowledge we use the Open Mind Common Sense part of ConceptNet 5.0 that contains 630k fact triples.,3 Data and Task Description,[0],[0]
We refer to this entire source as CN5All.,3 Data and Task Description,[0],[0]
"We conduct experiments with subparts of this data: CN5WN3 which is the WordNet 3 part of CN5All (213k triples) and CN5Sel, which excludes the following WordNet relations: RelatedTo, IsA, Synonym, SimilarTo, HasContext.",3 Data and Task Description,[0],[0]
Cloze-Style Reading Comprehension.,4 Related Work,[0],[0]
"Following the original MCTest (Richardson et al., 2013) dataset multiple-choice version of cloze-style RC) recently several large-scale, automatically generated datasets for cloze-style reading comprehension gained a lot of attention, among others the ‘CNN/Daily Mail’ (Hermann et al., 2015; Onishi et al., 2016) and the Children’s Book Test (CBTest) data set (Hill et al., 2015).",4 Related Work,[0],[0]
"Early work introduced simple but good single turn models (Hermann et al., 2015; Kadlec et al., 2016; Chen et al., 2016), that read the document once with the question representation ‘in mind’ and select an answer from a given set of candidates.",4 Related Work,[0],[0]
"More complex models (Weston et al., 2015; Dhingra et al., 2017; Cui et al., 2017; Munkhdalai and Yu, 2016; Sordoni et al., 2016) perform multi-turn reading of the story context and the question, before inferring the correct answer or use features (GA Reader, Dhingra et al. (2017).",4 Related Work,[0],[0]
"Performing multiple hops and modeling a deeper relation between question and document was further developed by several models (Seo et al., 2017; Xiong et al., 2016; Wang et al., 2016, 2017; Shen et al., 2016) on another generation of RC datasets, e.g. SQuAD (Rajpurkar et al., 2016), NewsQA (Trischler et al., 2017) or TriviaQA (Joshi et al., 2017).
",4 Related Work,[0],[0]
Integrating Background Knowledge in Neural Models.,4 Related Work,[0],[0]
Integrating background knowledge in a neural model was proposed in the neural-checklist model by Kiddon et al. (2016) for text generation of recipes.,4 Related Work,[0],[0]
They copy words from a list of ingredients instead of inferring the word from a global vocabulary.,4 Related Work,[0],[0]
Ahn et al. (2016) proposed a language model that copies fact attributes from a topic knowledge memory.,4 Related Work,[0],[0]
"The model predicts a fact in the knowledge memory using a gating mechanism and given this fact, the next word to be selected is copied from the fact attributes.",4 Related Work,[0],[0]
"The knowledge facts are encoded using embeddings obtained using TransE (Bordes et al., 2013).",4 Related Work,[0],[0]
Yang et al. (2017) extended a seq2seq model with attention to external facts for dialogue and recipe generation and a co-reference resolution-aware language model.,4 Related Work,[0],[0]
A similar model was adopted by He et al. (2017) for answer generation in dialogue.,4 Related Work,[0],[0]
"Incorporating external knowledge in a neural model has proven beneficial for several other tasks: Yang and Mitchell (2017) incorporated knowledge di-
rectly into the LSTM cell state to improve event and entity extraction.",4 Related Work,[0],[0]
"They used knowledge embeddings trained on WordNet (Miller et al., 1990) and NELL (Mitchell et al., 2015) using the BILINEAR (Yang et al., 2014) model.
",4 Related Work,[0],[0]
"Work similar to ours is by Long et al. (2017), who have introduced a new task of Rare Entity Prediction.",4 Related Work,[0],[0]
"The task is to read a paragraph from WikiLinks (Singh et al., 2012) and to fill a blank field in place of a missing entity.",4 Related Work,[0],[0]
"Each missing entity is characterized with a short description derived from Freebase, and the system needs to choose one from a set of pre-selected candidates to fill the field.",4 Related Work,[0],[0]
"While the task is superficially similar to cloze-style reading comprehension, it differs considerably: first, when considering the text without the externally provided entity information, it is clearly ambiguous.",4 Related Work,[0],[0]
"In fact, the task is more similar to Entity Linking tasks in the Knowledge Base Population (KBP) tracks at TAC 2013-2017, which aim at detecting specific entities from Freebase.",4 Related Work,[0],[0]
"Our work, by contrast, examines the impact of injecting external knowledge in a reading comprehension, or NLU task, where the knowledge is drawn from a commonsense knowledge base, ConceptNet in our case.",4 Related Work,[0],[0]
"Another difference is that in their setup, the reference knowledge for the candidates is explicitly provided as a single, fixed set of knowledge facts (the entity description), encoded in a single representation.",4 Related Work,[0],[0]
"In our work, we are retrieving (typically) distinct sets of knowledge facts that might (or might not) be relevant for understanding the story and answering the question.",4 Related Work,[0],[0]
"Thus, in our setup, we crucially depend on the ability of the attention mechanism to retrieve relevant pieces of knowledge.",4 Related Work,[0],[0]
"Our aim is to examine to what extent commonsense knowledge can contribute to and improve the cloze-style RC task, that in principle is supposed to be solvable without explicitly given additional knowledge.",4 Related Work,[0],[0]
"We show that by integrating external commonsense knowledge we achieve clear improvements in reading comprehension performance over a strong baseline, and thus we can speculate that humans, when solving this RC task, are similarly using commonsense knowledge as implicitly understood background knowledge.
",4 Related Work,[0],[0]
Recent unpublished work in Weissenborn et al. (2017) is driven by similar intentions.,4 Related Work,[0],[0]
"The authors exploit knowledge from ConceptNet to improve the performance of a reading comprehen-
sion model, experimenting on the recent SQuAD (Rajpurkar et al., 2016) and TriviaQA (Joshi et al., 2017) datasets.",4 Related Work,[0],[0]
"While the source of the background knowledge is the same, the way of integrating this knowledge into the model and task is different.",4 Related Work,[0],[0]
(i),4 Related Work,[0],[0]
We are using attention to select unordered fact triples using key-value retrieval and (ii) we integrate the knowledge that is considered relevant explicitly for each token in the context.,4 Related Work,[0],[0]
"The model of Weissenborn et al. (2017), by contrast, explicitly reads the acquired additional knowledge sequentially after reading the document and question, but transfers the background knowledge implicitly, by refining the word embeddings of the words in the document and the question with the words from the supporting knowledge that share the same lemma.",4 Related Work,[0],[0]
"In contrast to the implicit knowledge transfer of Weissenborn et al. (2017), our explicit attention over external knowledge facts can deliver insights about the used knowledge and how it interacts with specific context tokens (see Section 6).",4 Related Work,[0],[0]
We perform quantitative analysis through experiments.,5 Experiments and Results,[0],[0]
We study the impact of the used knowledge and different model components that employ the external knowledge.,5 Experiments and Results,[0],[0]
"Some of the experiments below focus only on the Common Nouns (CN) dataset, as it has been shown to be more challenging than Named Entities (NE) in prior work.",5 Experiments and Results,[0],[0]
"We experiment with different model parameters.
",5.1 Model Parameters,[0],[0]
Number of facts.,5.1 Model Parameters,[0],[0]
"We explore different sizes of knowledge memories, in terms of number of acquired facts.",5.1 Model Parameters,[0],[0]
"If not stated otherwise, we use 50 facts per example.
",5.1 Model Parameters,[0],[0]
Key-Value Selection Strategy.,5.1 Model Parameters,[0],[0]
"We use two strategies for defining key and value (Key/Value): Subj/Obj and Obj/Obj, where Subj and Obj are the subject and object attributes in the fact triples and they are selected as Key and Value for the KV memory (see Section 2.2, Querying the Knowledge Memory).",5.1 Model Parameters,[0],[0]
"If not stated otherwise, we use the Subj/Obj strategy.
",5.1 Model Parameters,[0],[0]
Answer Selection Components.,5.1 Model Parameters,[0],[0]
"If not stated otherwise, we use ensemble attention αensemble (combinations of ctx and ctx+kn) to rank the answers.",5.1 Model Parameters,[0],[0]
"We call this our Full model (see Sec. 2.2).
Hyper-parameters.",5.1 Model Parameters,[0],[0]
"For our experiments we use pre-trained Glove (Pennington et al., 2014) embeddings, BiGRU with hidden size 256, batch size of 64 and learning reate of 0.001 as they were shown (Kadlec et al., 2016) to perform good on the AS Reader.",5.1 Model Parameters,[0],[0]
We perform experiments with the different model parameters described above.,5.2 Empirical Results,[0],[0]
"We report accuracy on the Dev and Test and use the results on Dev set for pruning the experiments.
",5.2 Empirical Results,[0],[0]
Knowledge Sources.,5.2 Empirical Results,[0],[0]
We experiment with different configuration of ConceptNet facts (see Section 3).,5.2 Empirical Results,[0],[0]
Results on the CBT CN dataset are shown in Table 2.,5.2 Empirical Results,[0],[0]
CN5Sel works best on the Dev set but CN5WN3 works much better on Test.,5.2 Empirical Results,[0],[0]
"Further experiments use the CN5Sel setup.
",5.2 Empirical Results,[0],[0]
Number of facts.,5.2 Empirical Results,[0],[0]
We further experiment with different numbers of facts on the Common Nouns dataset (Table 3).,5.2 Empirical Results,[0],[0]
"The best result on the Dev set is for 50 facts so we use it for further experiments.
",5.2 Empirical Results,[0],[0]
Component ablations.,5.2 Empirical Results,[0],[0]
"We ensemble the attentions from different combinations of the interaction between the question and document context (ctx) representations and context+knowledge (ctx+kn) representations in order to infer the right answer (see Section 2.2, Answer Ranking).
",5.2 Empirical Results,[0],[0]
"Table 4 shows that the combination of different interactions between ctx and ctx+kn representations leads to clear improvement over the w/o knowledge setup, in particular for the Common Nouns dataset.",5.2 Empirical Results,[0],[0]
"We also performed ablations for a model with 100 facts (see Supplement).
",5.2 Empirical Results,[0],[0]
Key-Value Selection Strategy.,5.2 Empirical Results,[0],[0]
"Table 5 shows that for the NE dataset, the two strategies perform
equally well on the Dev set, whereas the Subj/Obj strategy works slightly better on the Test set.",5.2 Empirical Results,[0],[0]
"For Common Nouns, Subj/Obj is better.
",5.2 Empirical Results,[0],[0]
Comparison to Previous Work.,5.2 Empirical Results,[0],[0]
Table 6 compares our model (Knowledgeable Reader) to previous work on the CBT datasets.,5.2 Empirical Results,[0],[0]
"We show the results of our model with the settings that performed best on the Dev sets of the two datasets NE and CN: for NE, (Dctx+kn, Qctx) with 100 facts; for CN the Full model with 50 facts, both with CN5Sel.
Note that our work focuses on the impact of external knowledge and employs a single inter-
action (single-hop) between the document context and the question so we primarily compare to and aim at improving over similar models.",5.2 Empirical Results,[0],[0]
KnReader clearly outperforms prior single-hop models on both datasets.,5.2 Empirical Results,[0],[0]
"While we do not improve over the state of the art, our model stands well among other models that perform multiple hops.",5.2 Empirical Results,[0],[0]
In the Supplement we also give comparison to ensemble models and some models that use re-ranking strategies.,5.2 Empirical Results,[0],[0]
Our experiments examined key parameters of the KnReader.,6.1 Analysis of the empirical results.,[0],[0]
"As expected, injection of background knowledge yields only small improvements over the baseline model for Named Entities.",6.1 Analysis of the empirical results.,[0],[0]
"However, on this dataset our single-hop model is competitive to most multi-hop neural architectures.
",6.1 Analysis of the empirical results.,[0],[0]
The integration of knowledge clearly helps for the Common Nouns task.,6.1 Analysis of the empirical results.,[0],[0]
The impact of knowledge sources (Table 2) is different on the Dev and Test sets which indicates that either the model or the data subsets are sensitive to different knowledge types and retrieved knowledge.,6.1 Analysis of the empirical results.,[0],[0]
Table 5 shows that attending over the Subj of the knowledge triple is slightly better than Obj.,6.1 Analysis of the empirical results.,[0],[0]
This shows that using a Key-Value memory is valuable.,6.1 Analysis of the empirical results.,[0],[0]
"A reason for lower performance of Obj/Obj is that the model picks facts that are similar to the candidate tokens, not adding much new information.",6.1 Analysis of the empirical results.,[0],[0]
From the empirical results we see that training and evaluation with less facts is slightly better.,6.1 Analysis of the empirical results.,[0],[0]
We hypothesize that this is related to the lack of supervision on the retrieved and attended knowledge.,6.1 Analysis of the empirical results.,[0],[0]
"Figure 3 shows the impact on prediction accuracy of individual components of the Full model, including the interaction between D and Q with ctx or ctx",6.2 Interpreting Component Importance,[0],[0]
+ kn (w/o ctx-only).,6.2 Interpreting Component Importance,[0],[0]
"The values for each component are obtained from the attention weights, without retraining the model.",6.2 Interpreting Component Importance,[0],[0]
The difference between blue (left) and orange (right) values indicates how much the module contributes to the model.,6.2 Interpreting Component Importance,[0],[0]
"Interestingly, the ranking of the contribution (Dctx, Qctx+kn > Dctx+kn, Qctx > Dctx+kn, Qctx+kn) corresponds to the component importance ablation on the Dev set, lines 5-8, Table 4.
",6.2 Interpreting Component Importance,[0],[0]
"Subj/Obj,  50  facts
Obj/Obj,  50  facts",6.2 Interpreting Component Importance,[0],[0]
"We will use the attention values of the interactions between Dctx(+kn) and Qctx(+kn) and attentions to facts from each candidate token and the question placeholder to interpret how knowledge is employed to make a prediction for a single example.
",6.3 Qualitative Data Investigation,[0],[0]
Method: Interpreting Model Components.,6.3 Qualitative Data Investigation,[0],[0]
"We manually inspect examples from the evaluation sets where KnReader improves prediction (blue (left) category, Fig. 3) or makes the prediction worse (orange (right) category, Fig. 3).",6.3 Qualitative Data Investigation,[0],[0]
"Figure 4 shows the question with placeholder, followed by answer candidates and their associated attention weights as assigned by the model w/o knowledge.",6.3 Qualitative Data Investigation,[0],[0]
The matrix shows selected facts and their assigned weights for the question and the candidate tokens.,6.3 Qualitative Data Investigation,[0],[0]
"Finally, we show the attention weights determined by the knowledge-enhanced D to Q interactions.",6.3 Qualitative Data Investigation,[0],[0]
The attention to the correct answer (head) is low when the model considers the text alone (w/o knowledge).,6.3 Qualitative Data Investigation,[0],[0]
"When adding retrieved knowledge to theQ only (row ctx, ctx+kn) and to both Q and D (row ctx + kn, ctx + kn) the score improves, while when adding knowledge to D alone (row ctx+ kn, ctx) the score remains ambiguous.",6.3 Qualitative Data Investigation,[0],[0]
The combined score Ensemble (see Eq. 13) then takes the final decision for the answer.,6.3 Qualitative Data Investigation,[0],[0]
"In this example, the question can be answered without the story.",6.3 Qualitative Data Investigation,[0],[0]
The model tries to find knowledge that is related to eyes.,6.3 Qualitative Data Investigation,[0],[0]
"The fact eyes /r/PartOf head is not contained in the retrieved knowledge but in-
stead the model selects the fact ear /r/PartOf head which receives the highest attention from Q. The weighted Obj representation (head) is added to the question with the highest weight, together with animal and bird from the next highly weighted facts This results in a high score for theQctx toDctx+kn interaction with candidate head.",6.3 Qualitative Data Investigation,[0],[0]
"See Supplement for more details.
",6.3 Qualitative Data Investigation,[0],[0]
"Using the method described above, we analyze several example cases (presented in Supplement) that highlight different aspects of our model.",6.3 Qualitative Data Investigation,[0],[0]
"Here we summarize our observations.
",6.3 Qualitative Data Investigation,[0],[0]
(i.),6.3 Qualitative Data Investigation,[0],[0]
"Answer prediction from Q or Q+D. In both human and machine RC, questions can be answered based on the question alone (Figure 4) or jointly with the story context (Case 2, Suppl.).",6.3 Qualitative Data Investigation,[0],[0]
"We show that empirically, enriching the question with knowledge is crucial for the first type, while enrichment of Q and D is required for the second.
",6.3 Qualitative Data Investigation,[0],[0]
(ii.),6.3 Qualitative Data Investigation,[0],[0]
Overcoming frequency bias..,6.3 Qualitative Data Investigation,[0],[0]
"We show
that when appropriate knowledge is available and selected, the model is able to correct a frequency bias towards an incorrect answer (Cases 1 and 3).
",6.3 Qualitative Data Investigation,[0],[0]
(iii.),6.3 Qualitative Data Investigation,[0],[0]
Providing appropriate knowledge.,6.3 Qualitative Data Investigation,[0],[0]
"We observe a lack of knowledge regarding events (e.g. take off vs. put on clothes, Case 2; climb up, Case 5).",6.3 Qualitative Data Investigation,[0],[0]
"Nevertheless relevant knowledge from CN5 can help predicting infrequent candidates (Case 2).
",6.3 Qualitative Data Investigation,[0],[0]
(iv.),6.3 Qualitative Data Investigation,[0],[0]
"Knowledge, Q and D encoding.",6.3 Qualitative Data Investigation,[0],[0]
"The context encoding of facts allows the model to detect knowledge that is semantically related, but not surface near to phrases in Q and D (Case 2).",6.3 Qualitative Data Investigation,[0],[0]
"The model finds facts to non-trivial paraphrases (e.g. undressed–naked, Case 2).",6.3 Qualitative Data Investigation,[0],[0]
"We propose a neural cloze-style reading comprehension model that incorporates external commonsense knowledge, building on a single-turn neural model.",7 Conclusion and Future Work,[0],[0]
"Incorporating external knowledge improves its results with a relative error rate reduction of 9% on Common Nouns, thus the model is able to compete with more complex RC models.",7 Conclusion and Future Work,[0],[0]
We show that the types of knowledge contained in ConceptNet are useful.,7 Conclusion and Future Work,[0],[0]
"We provide quantitative and qualitative evidence of the effectiveness of our model, that learns how to select relevant knowledge to improve RC.",7 Conclusion and Future Work,[0],[0]
"The attractiveness of our model lies in its transparency and flexibility: due to the attention mechanism, we can trace and analyze the facts considered in answering specific questions.",7 Conclusion and Future Work,[0],[0]
"This opens up for deeper investigation and future improvement of RC models in a targeted way, allowing us to investigate what knowledge sources are required for different data sets and domains.",7 Conclusion and Future Work,[0],[0]
"Since our model directly integrates background knowledge with the document and questioncontext representations, it can be adapted to very different task settings where we have a pair of two arguments (i.e. entailment, question answering, etc.)",7 Conclusion and Future Work,[0],[0]
"In future work, we will investigate even tighter integration of the attended knowledge and stronger reasoning methods.",7 Conclusion and Future Work,[0],[0]
This work has been supported by the German Research Foundation as part of the Research Training Group Adaptive Preparation of Information from Heterogeneous Sources (AIPHES) under grant No.,Acknowledgments,[0],[0]
GRK 1994/1.,Acknowledgments,[0],[0]
We thank the reviewers for their helpful questions and comments.,Acknowledgments,[0],[0]
"We introduce a neural reading comprehension model that integrates external commonsense knowledge, encoded as a keyvalue memory, in a cloze-style setting.",abstractText,[0],[0]
"Instead of relying only on document-toquestion interaction or discrete features as in prior work, our model attends to relevant external knowledge and combines this knowledge with the context representation before inferring the answer.",abstractText,[0],[0]
"This allows the model to attract and imply knowledge from an external knowledge source that is not explicitly stated in the text, but that is relevant for inferring the answer.",abstractText,[0],[0]
"Our model improves results over a very strong baseline on a hard Common Nouns dataset, making it a strong competitor of much more complex models.",abstractText,[0],[0]
"By including knowledge explicitly, our model can also provide evidence about the background knowledge used in the RC process.",abstractText,[0],[0]
Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1–15 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
The development of hospital information system and medical informatics drives the leverage of various medical data for a more efficient and intelligent medical care service.,1 Introduction,[0],[0]
"Among many kinds of medical data, electronic health records (EHRs) are one of the most valuable and informative data as they contain detailed information about the patients and the clinical practices.",1 Introduction,[0],[0]
"EHRs are essential to many intelligent clinical applications, such
∗Weinan Zhang is the corresponding author.
",1 Introduction,[0],[0]
"as hospital quality control and clinical decision support systems (Wu et al., 2015).",1 Introduction,[0],[0]
"Most of EHRs are recorded in an unstructured form, i.e., natural language.",1 Introduction,[0],[0]
"Hence, extracting structured information from EHRs using natural language processing (NLP), e.g., named entity recognition (NER) and entity linking, plays a fundamental role in medical informatics (Zhang and Elhadad, 2013).",1 Introduction,[0],[0]
"In this paper, we focus on medical NER from EHRs, which is a fundamental task and is widely studied in the research community (Nadeau and Sekine, 2007; Uzuner et al., 2011).
",1 Introduction,[0],[0]
"In practice, the difficulty of building a universally robust and high-performance medical NER system lies in the variety of medical terminologies and expressions among different departments of specialties and hospitals.",1 Introduction,[0],[0]
"However, building separate NER systems for so many specialties comes with a prohibitively high cost.",1 Introduction,[0],[0]
"The data privacy issue further discourages the sharing of the data across departments or hospitals, making it more difficult to train a canonical NER system to be applied everywhere.",1 Introduction,[0],[0]
"This raises a natural question: if we have sufficient annotated EHRs data in one source specialty, can we distill the knowledge and transfer it to help training models in a related target specialty with few annotations?",1 Introduction,[0],[0]
By transferring the knowledge we can achieve higher performance in target specialties with lower annotation cost and bypass the data sharing concerns.,1 Introduction,[0],[0]
"This is commonly referred to as transfer learning (Pan and Yang, 2010).
",1 Introduction,[0],[0]
"Current state-of-the-art transfer learning methods for NER are mainly based on deep neural networks, which perform an end-to-end training to distill sequential dependency patterns in the natural language (Ma and Hovy, 2016; Lample et al., 2016).",1 Introduction,[0],[0]
"These transfer learning methods include (i) feature representation transfer (Peng and Dredze, 2017; Kulkarni et al., 2016), which normally lever-
1
ages deep neural networks to learn a close feature mapping between the source and target domains, and (ii) parameter transfer (Murthy et al., 2016; Yang et al., 2017), which performs parameter sharing or joint training to get the target-domain model parameters close to those of the source-domain model.",1 Introduction,[0],[0]
"To the best of our knowledge, there is no previous literature working on transfer learning for NER in the medical domain, or even in a larger scope, i.e., medical natural language processing.
",1 Introduction,[0],[0]
"In this paper, we propose a novel NER transfer learning framework, namely label-aware double transfer learning (La-DTL): (i) We leverage bidirectional long-short term memory (Bi-LSTM) network (Graves and Schmidhuber, 2005) to automatically learn the text representations, based on which we perform a label-aware feature representation transfer.",1 Introduction,[0],[0]
"We propose a variant of maximum mean discrepancy (MMD) (Gretton et al., 2012), namely label-aware MMD (La-MMD), to explicitly reduce the domain discrepancy of feature representations of tokens with the same label between two domains.",1 Introduction,[0],[0]
(ii),1 Introduction,[0],[0]
"Based on the learned feature representations from Bi-LSTM, two conditional random field (CRF) models are performed for sequence labeling for source and target domain separately, where parameter transfer learning is performed.",1 Introduction,[0],[0]
"Specifically, an upper bound of KL divergence between the source and target domain’s CRF label distributions is added over the emission and transition matrices across the source and target CRF models to explore the shareable parts of the parameters.",1 Introduction,[0],[0]
"Both (i) and (ii) have a labelaware characteristic, which will be discussed later.",1 Introduction,[0],[0]
"We further argue that label-aware characteristic is crucial for transfer learning in sequence labeling problems, e.g., NER, because only when the corresponding labels are matched, can the “similar” contexts (i.e. feature representation) and model parameters be efficiently borrowed to improve the label prediction.
",1 Introduction,[0],[0]
Extensive experiments are conducted on 12 cross-specialty medical NER tasks with real-world EHRs.,1 Introduction,[0],[0]
"The experimental results demonstrate that La-DTL provides consistent accuracy improvement over strong baselines, with overall 2.62% to 6.70% absolute F1-score improvement over the state-of-the-art methods.",1 Introduction,[0],[0]
"Besides, the promising experimental results on other two non-medical NER scenarios indicate that La-DTL has the potential to be seamlessly adapted to a wide range of
NER tasks.",1 Introduction,[0],[0]
"Named Entity Recognition (NER) is fundamental in information extraction area which aims at automatic detection of named entities (e.g., person, organization, location and geo-political) in free text (Marrero et al., 2013).",2 Related Works,[0],[0]
"Many high-level applications such as entity linking (Moro et al., 2014) and knowledge graph construction (Hachey et al., 2011) could be built on top of an NER system.",2 Related Works,[0],[0]
"Traditional high-performance approaches include conditional random fields models (CRFs) (Lafferty et al., 2001), maximum entropy Markov models (MEMMs) (McCallum et al., 2000) and hidden Markov models (HMMs).",2 Related Works,[0],[0]
"Recently, many neural network-based models have been proposed (Collobert et al., 2011; Chiu and Nichols, 2016; Ma and Hovy, 2016; Lample et al., 2016), in which few feature engineering works are needed to train a high-performance NER system.",2 Related Works,[0],[0]
"The architecture of those neural network-based models are similar, where different neural networks (LSTMs, CNNs) at different levels (char- and word-level) are applied to learn feature representations, and on top of neural networks, a CRF model is employed to make label predictions.",2 Related Works,[0],[0]
Transfer Learning distills knowledge from a source domain to help create a high-performance learner for a target domain.,2 Related Works,[0],[0]
"Transfer learning algorithms are mainly categorized into three types, namely instance transfer, feature representation transfer and parameter transfer (Pan and Yang, 2010).",2 Related Works,[0],[0]
"Instance transfer normally samples or reweights source-domain samples to match the distribution of the target domain (Chen et al., 2011; Chu et al., 2013).",2 Related Works,[0],[0]
"Feature representation transfer typically learns a feature mapping which projects source and target domain data simultaneously onto a common feature space following similar distributions (Zhuang et al., 2015; Long et al., 2015; Shen et al., 2017).",2 Related Works,[0],[0]
"Parameter transfer normally involves a joint or constrained training for the models on source and target domains, usually introduce connections between source target parameters via sharing (Srivastava and Salakhutdinov, 2013), initialization (Perlich et al., 2014), or intermodel parameter penalty schemes (Zhang et al., 2016).",2 Related Works,[0],[0]
"Transfer Learning for NER Training a highperformance NER system requires expensive and
time-consuming manually annotated data.",2 Related Works,[0],[0]
"But sufficient labeled data is critical for the generalization of an NER system, especially for neural networkbased models.",2 Related Works,[0],[0]
"Thus, transfer learning for NER is a practically important problem.",2 Related Works,[0],[0]
The first group of methods focuses on sharing model parameters but they differ in the training schemes.,2 Related Works,[0],[0]
"He and Sun (2017) proposed to train the parameter-shared model with source and target data jointly, while the learning rates for sentences from source domain are re-weighted by the similarity with target domain corpus.",2 Related Works,[0],[0]
"Yang et al. (2017) proposed a family of frameworks which share model parameters in hierarchical recurrent networks to handle crossapplication, cross-lingual, and cross-domain transfer in sequence labeling tasks.",2 Related Works,[0],[0]
"Differently, Lee et al. (2017) first trained the model with source domain data and then fine-tuned the model with little annotated target domain data.
",2 Related Works,[0],[0]
"Domain adaptation method has been well studied in NER scenarios such as using distributed word representations (Kulkarni et al., 2016) and leveraging rule-based annotators (Chiticariu et al., 2010).",2 Related Works,[0],[0]
"Multi-task learning has also been studied to improve performance in multiple NER tasks by transferring meaningful knowledge from other tasks (Collobert et al., 2011; Peng and Dredze, 2016).",2 Related Works,[0],[0]
"To take the advantages of both domain adaptation and multi-task learning, Peng and Dredze (2017) proposed a multi-task domain adaptation model.",2 Related Works,[0],[0]
"This section briefly introduces bidirectional LSTM, conditional random field and maximum mean discrepancy, which are the building blocks of our transfer learning framework.",3 Preliminaries,[0],[0]
Bidirectional LSTM Recurrent neural networks (RNNs) are widely used in NLP tasks for their great capability to capture contextual information in sequence data.,3 Preliminaries,[0],[0]
"A widely used variant of RNNs is long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997), which incorporates input and forget gates to capture both long and short term dependencies.",3 Preliminaries,[0],[0]
"Furthermore, it will be beneficial if we process the sequence in not only a forward but also a backward way.",3 Preliminaries,[0],[0]
"Thus, bidirectional LSTM (Bi-LSTM) was employed in many previous works (Chiu and Nichols, 2016; Ma and Hovy, 2016; Lample et al., 2016) to capture bidirectional information in a sequence.",3 Preliminaries,[0],[0]
"More specifi-
cally, for token xt (embedding vector) at timestep t in sequence X = (x1,x2, ...,xn), the θbparameterized Bi-LSTM recurrently updates hidden vectors h→t = G f θb (X,h→t−1) and h ← t = Gbθb(X,h ← t+1) produced by a forward LSTM and a backward one, respectively.",3 Preliminaries,[0],[0]
"Then we concatenate h→t and h ← t to ht as the final hidden vector produced by Bi-LSTM:
ht = h → t ⊕ h←t .
",3 Preliminaries,[0],[0]
"The representations learned from Bi-LSTM for sequence X is thus denoted as H = (h1,h2, ...,hn).",3 Preliminaries,[0],[0]
Conditional Random Field,3 Preliminaries,[0],[0]
"The goal of NER is to detect named entities in a sequence X by predicting a sequence of labels y = (y1, y2, ..., yn).",3 Preliminaries,[0],[0]
"Conditional random field (CRF) is widely used to make joint labeling of the tokens in a sequence (Lafferty et al., 2001).
",3 Preliminaries,[0],[0]
"Recently, Lample et al. (2016) proposed to build a CRF layer on top of a Bi-LSTM so that the automatically learned feature representation H = (h1,h2, ...,hn) of the sequence can be directly fed into the CRF for sequence labeling.",3 Preliminaries,[0],[0]
"For a sequence of labels y, given the hidden vector sequence H, we define its θc-parametrized score function sθc(H,y) as:
sθc(H,y) =
n∑
i=1
Ei,yi +
n−1∑
i=1
Ayi,yi+1 ,
where E is the emission score matrix of size n×m (m is the number of unique labels), and is computed by E = HW where W is the label emission parameter matrix; A is the label transition parameter matrix; thus θc = {W,A}.",3 Preliminaries,[0],[0]
"We then define the conditional probability of label sequence y given H by a softmax over all possible label sequences in set Y(H) as:
pθc(y|H) = exp{sθc(H,y)}/Z(H) (1)",3 Preliminaries,[0],[0]
"=exp{sθc(H,y)} / ∑
y′∈Y(H) exp{sθc(H,y′)},
where θc is omitted for simplification in the following part.",3 Preliminaries,[0],[0]
The training objective in the CRF layer is to maximize the log-likelihood maxθc log p(y|H).,3 Preliminaries,[0],[0]
"In the label prediction phase, we give the output label sequence y∗ with the highest conditional probability y∗ = argmaxy′∈Y(H) p(y′|H) by dynamic programming (Sutton et al., 2012).",3 Preliminaries,[0],[0]
"Maximum Mean Discrepancy Maximum Mean Discrepancy (Gretton et al., 2012) is",3 Preliminaries,[0],[0]
a non-,3 Preliminaries,[0],[0]
parametric test statistic to measure the distribution discrepancy in terms of the distance between the kernel mean embeddings of two distributions p and q.,Bi-LSTM,[0],[0]
"The MMD is defined in particular function spaces that witness the difference in distributions
MMD(F , p, q) = sup f∈F (Ex∼p[f(x)]− Ey∼q[f(y)]).
",Bi-LSTM,[0],[0]
"By defining the function class F as the unit ball in a universal Reproducing Kernel Hilbert Space (RKHS), denoted by H, it holds that MMD[F , p, q] = 0 if and only if p = q.",Bi-LSTM,[0],[0]
"And then given two sets of samples X = {x1, ..., xm} and Y = {y1, ..., yn} independently and identically distributed (i.i.d.) from p and q on the data space X , the empirical estimate of MMD can be written as the distance between the empirical mean embeddings after mapping to RKHS
MMD(X,Y ) = ∥∥∥",Bi-LSTM,[0],[0]
"1 m m∑
i=1
φ(xi)− 1 n
n∑
j=1
φ(yj) ∥∥∥",Bi-LSTM,[0],[0]
"H , (2)
where φ(·) : X → H is the nonlinear feature mapping that inducesH.",Bi-LSTM,[0],[0]
"In this section, we present a label-aware double transfer learning (La-DTL) framework and discuss its rationale.",4 Methodology,[0],[0]
Figure 1 gives an overview of La-DTL for NER.,4.1 Framework Overview,[0],[0]
"From bottom up, each input sentence is converted
into a sequence of embedding vectors, which are then fed into a Bi-LSTM to sequentially encode contextual information into fixed-length hidden vectors.",4.1 Framework Overview,[0],[0]
The embedding and Bi-LSTM layers are shared among source/target domains.,4.1 Framework Overview,[0],[0]
"With labelaware maximum mean discrepancy (La-MMD) to reduce the feature representation discrepancy between two domains, the hidden vectors are directly fed into source/target domain specific CRF layers to predict the label sequence.",4.1 Framework Overview,[0],[0]
"We use domain constrained CRF layers to enhance the target domain performance.
",4.1 Framework Overview,[0],[0]
"More formally, let Ds = {(Xsi ,ysi )}N s
i=1",4.1 Framework Overview,[0],[0]
"be the training set of N s samples from the source domain and Dt = {(Xti,yti)}",4.1 Framework Overview,[0],[0]
"Nt
i=1",4.1 Framework Overview,[0],[0]
"be the training set of N t samples from the target domain, with N t N s. Bi-LSTM encodes a sentence X = (x1,x2, ...,xn) to hidden vectors H = (h1,h2, ...,hn).",4.1 Framework Overview,[0],[0]
We occasionally use H(X) to denote the corresponding hidden vectors when feeding X into the Bi-LSTM.,4.1 Framework Overview,[0],[0]
CRF decodes hidden vectors H to a label sequence ŷ =,4.1 Framework Overview,[0],[0]
"(ŷ1, ŷ2, ..., ŷn).",4.1 Framework Overview,[0],[0]
Our goal is to improve label prediction accuracy on the target domain Dt by utilizing the knowledge from the source domain,4.1 Framework Overview,[0],[0]
"Ds:
p(y|X) =p(y|H(X)),
log p(y|H) = n∑
i=1
",4.1 Framework Overview,[0],[0]
"Ei,yi +
n−1∑
i=1
Ayi,yi+1",4.1 Framework Overview,[0],[0]
− logZ(H).,4.1 Framework Overview,[0],[0]
"(3)
Thus training a transferable model p(y|X) requires both H(X) and p(y|H) to be transferable.
",4.1 Framework Overview,[0],[0]
"We use share word embedding and Bi-LSTM by approaching the feature representation distributions p(h|Ds) and p(h|Dt), i.e., the distributions of Bi-LSTM hidden vectors at each timestep of the sentences from the source and target domains respectively.",4.1 Framework Overview,[0],[0]
The rationale behind it lies on the insufficiency of labeled target data.,4.1 Framework Overview,[0],[0]
"Even though LSTM has high capacity, its generalization ability highly relies on viewing “sufficient” data.",4.1 Framework Overview,[0],[0]
"Otherwise, LSTM is very likely to overfit the data.",4.1 Framework Overview,[0],[0]
"Training on both source and target data, the BiLSTM is expected to learn feature representations with high quality.",4.1 Framework Overview,[0],[0]
"Yosinski et al. (2014) provided a justification of this solution that sharing bottom layers is promising for transfer learning in practice.
",4.1 Framework Overview,[0],[0]
"With the sentences projected onto the same hidden space, the conditional distribution p(hs|Ds) and p(ht|Dt), however, may be distant because
LSTM hidden vectors contain contextual information which is different across domains.",4.1 Framework Overview,[0],[0]
"In order to reduce source/target discrepancy, we refine MMD (Gretton et al., 2012) with label constraints, i.e., label-aware MMD (La-MMD).",4.1 Framework Overview,[0],[0]
"Using La-MMD, the source/target hidden states are pushed to similar distributions to make the feature representation H(X) transfer feasible.
",4.1 Framework Overview,[0],[0]
"Based on the hidden vectors from Bi-LSTM, we adopt independent CRF layers for each domain.",4.1 Framework Overview,[0],[0]
The rationale lies in the hypotheses that (i) the target domain predictor can better capture target data distribution which could be very unique; (ii) a good predictor trained on the source domain directly could be leveraged to assist the target domain predictor without directly borrowing the source domain training data to bypass the data privacy issue.,4.1 Framework Overview,[0],[0]
"With respect to the emission and transition score matrices ∑ Ei,yi and ∑ Ayi,yi+1 , we adopt an upper bound between source/target domains, which helps the target domain predictor to be guided by the source domain predictor.",4.1 Framework Overview,[0],[0]
"Thus p(y|H) is also transferable.
",4.1 Framework Overview,[0],[0]
"There are also other transfer methods, including fine-tuning, sharing parameter directly (without constraints) (He and Sun, 2017; Lee et al., 2017; Yang et al., 2017), etc.",4.1 Framework Overview,[0],[0]
"However, simply sharing models may dismiss target specific instances.",4.1 Framework Overview,[0],[0]
"The learning objective is to minimize the following loss L with respect to parameters Θ = {θb, θc}:
L = Lc + α LLa-MMD + β",4.2 Learning Objective,[0],[0]
"Lp + γ Lr,
where Lc is the CRF loss, LLa-MMD is the LaMMD loss,",4.2 Learning Objective,[0],[0]
"Lp is the parameter similarity loss on CRF layers, andLr is the regularization term, with α, β, γ as hyperparameters to balance loss terms.
",4.2 Learning Objective,[0],[0]
"The CRF loss is our ultimate objective predicting the label sequence given the input sentence, i.e., we minimize the negative log-likelihood of training samples from both source/target domains:
",4.2 Learning Objective,[0],[0]
"Lc = − ε Ns
Ns∑
i=1
log p(ysi |Hsi )",4.2 Learning Objective,[0],[0]
"− 1− ε N t
Nt∑
i=1
log p(yti |Hti),
where H are hidden vectors obtained from BiLSTM, ε is the balance coefficient.",4.2 Learning Objective,[0],[0]
The La-MMD loss LLa-MMD and parameter similarity loss,4.2 Learning Objective,[0],[0]
"Lp are discussed in Section 4.3 and 4.4, respectively.",4.2 Learning Objective,[0],[0]
"The
regularization term is to generally control overfitting:
Lr = ‖θb‖22 + ‖θc‖22.
",4.2 Learning Objective,[0],[0]
We will provide the model convergence and hyperparameter study in Section 5.1.,4.2 Learning Objective,[0],[0]
"To learn transferable feature representations, the maximum mean discrepancy (MMD) which measures the distance between two distributions, has been widely used in domain adaptation scenarios (Long et al., 2015; Rozantsev et al., 2016).",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
Almost all these works focus on reducing the marginal distribution distance between different domain features in an unsupervised manner to make them indistinguishable.,4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"However, considering a word is not evenly distributed conditioning on different labels, it may result in that the discriminative property of features from different domains may not be similar, which means that close source and target samples may not have the same label.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"Different from previous works, we propose label-aware MMD (La-MMD) in Eq.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"(5) to explicitly reduce the discrepancy between hidden representations with the same label, i.e., the linear combination of the MMD for each label.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
For each label class y ∈,4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"Yv, where Yv is the set of matched labels in two domains, we compute the squared population MMD between the hidden representations of source/target samples with the same label y:
MMD2(Rsy,Rty) = 1
(Nsy )2
Nsy∑
i,j=1
k(hsi ,h s j) +
1
(N ty)2
Nty∑
i,j=1
k(hti,h t j)
",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"− 2 NsyN ty
Nsy ,N t y∑
i,j=1
k(hsi ,h t j), (4)
where Rsy and Rty are sets of hidden representation hs and ht with corresponding number N sy and N t y. Eq.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
(4) can be easily derived by casting Eq.,4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"(2) into inner product form and applying 〈φ(x), φ(y)〉H = k(x, y) where k is the reproducing kernel function (Gretton et al., 2012).",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"For each label class, we compute the MMD loss in a normal manner.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"After that, we define the La-MMD loss as:
LLa-MMD = ∑
y∈Yv µy ·MMD2(Rsy,Rty), (5)
where µy is the corresponding coefficient.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"The illustration of La-MMD is shown in Figure 2.
",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"Once we have applied this La-MMD to our representations learned from Bi-LSTM, the representation distribution of instances with the same label from different domains should be close.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
Then the standard CRF layer which has a simple linear structure takes these similar representations as input and is likely to give a more transferable label decision for instances with the same label.,4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
Simply sharing the CRF layer is non-promising when source/target data are diversely distributed.,4.4 CRF Parameter Transfer,[0],[0]
According to probability decomposition in Eq.,4.4 CRF Parameter Transfer,[0],[0]
"(3), in order to transfer on source/target CRF layers, more specifically, p(y|H), we reduce the KL divergence from pt(y|H) to ps(y|H).",4.4 CRF Parameter Transfer,[0],[0]
"But directly reducing DKL(ps(y|H)||pt(y|H)) is intractable, we tend to reduce its upper bound:
DKL(p s(y|H)||pt(y|H))
",4.4 CRF Parameter Transfer,[0],[0]
"= ∑
y∈Y(H) ps(y|H)",4.4 CRF Parameter Transfer,[0],[0]
"log(p s(y|H) pt(y|H) )
",4.4 CRF Parameter Transfer,[0],[0]
"=−H(ps(y|H))− ∑
y∈Y(H) ps(y|H) log pt(y|H)
≤c(‖Ws −Wt‖22 + ‖As −At‖22) 1 2 , (6)
where H(·) is the entropy of distribution (·) and c is a constant.",4.4 CRF Parameter Transfer,[0],[0]
The detailed proof is provided in Appendix A.1.,4.4 CRF Parameter Transfer,[0],[0]
"Since c(‖Ws−Wt‖22+‖As−At‖22) is the upper bound of DKL(ps(y|H)‖pt(y|H)),
we conduct CRF parameter transfer by minimizing
Lp = ‖Ws −Wt‖22 + ‖A s −At‖22.
",4.4 CRF Parameter Transfer,[0],[0]
"It turns out that a similar regularization term is applied in our CRF parameter transfer method and the regularization framework (RF) for domain adaptation (Lu et al., 2016).",4.4 CRF Parameter Transfer,[0],[0]
"However, RF is proposed to generalize the feature augmentation method in (Daume III, 2007), and these two methods are only discussed from a perspective of the parameter.",4.4 CRF Parameter Transfer,[0],[0]
There is no guarantee that two models having similar parameters yields similar output distributions.,4.4 CRF Parameter Transfer,[0],[0]
"In this work, we discuss the model behavior in CRF conditions, and we successfully prove that two CRF models having similar parameters (in Euclidean space) yields similar output distributions.",4.4 CRF Parameter Transfer,[0],[0]
"In another word, our method guarantees transferability in the model behavior level, while previous works are limited in parameter level.
",4.4 CRF Parameter Transfer,[0],[0]
"The CRF parameter transfer is illustrated in Figure 3, which is also label-aware since the L2 constraint is added over parameters corresponding to the same label in two domains, e.g., WsO and W t O.",4.4 CRF Parameter Transfer,[0],[0]
"We train La-DTL in an end-to-end manner with mini-batch AdaGrad (Duchi et al., 2011).",4.5 Training,[0],[0]
"One mini-batch contains training samples from both domains, otherwise the computation of LLa-MMD can not be performed.",4.5 Training,[0],[0]
"During training, word (and character) embeddings are fine-tuned to adjust real data distribution.",4.5 Training,[0],[0]
"During both training and decoding (testing) of CRF layers, we use dynamic programming to compute the normalizer in Eq.",4.5 Training,[0],[0]
(1) and infer the label sequence.,4.5 Training,[0],[0]
"In this section, we evaluate La-DTL1 and other baseline methods on 12 cross-specialty NER problems based on real-world datasets.",5 Experiments,[0],[0]
The experimental results show that La-DTL steadily outperforms other baseline models in all tasks significantly.,5 Experiments,[0],[0]
We also conduct further ablation study and robustness study.,5 Experiments,[0],[0]
We evaluate La-DTL on two more nonmedical NER transfer tasks to validate its general efficacy over a wide range of applications.,5 Experiments,[0],[0]
Datasets We collected a Chinese medical NER (CM-NER) corpus for our experiments.,5.1 Cross-Specialty NER,[0],[0]
"This corpus contains 1600 de-identified EHRs of our affiliated hospital from four different specialties in four departments: Cardiology (500), Respiratory (500), Neurology (300) and Gastroenterology (300), and the research had been reviewed and approved by the ethics committee.",5.1 Cross-Specialty NER,[0],[0]
"Named entities are annotated in the BIOES format (Begin, Inside, Outside, End and Single), with 30 types in total.",5.1 Cross-Specialty NER,[0],[0]
The statistics of CM-NER is shown in Table 1.,5.1 Cross-Specialty NER,[0],[0]
Baselines The following methods are compared.,5.1 Cross-Specialty NER,[0],[0]
"For a fair comparison, we implement La-DTL and baselines with the same base model introduced in (Lample et al., 2016) but with different transfer techniques.
",5.1 Cross-Specialty NER,[0],[0]
"• Non-transfer uses the target domain labeled data only.
",5.1 Cross-Specialty NER,[0],[0]
"• Domain mask and Linear projection belong to the same framework proposed by Peng and Dredze (2017) but have different implementations at the projection layer, which aims to produce shared feature representations among different domains through a linear transformation.
",5.1 Cross-Specialty NER,[0],[0]
"• Re-training is proposed by Lee et al. (2017), where an artificial neural networks (ANNs)
1https://github.com/felixwzh/La-DTL
is first trained on the source domain and then re-trained on the target domain.
",5.1 Cross-Specialty NER,[0],[0]
"• Joint-training is a transfer learning method proposed by Yang et al. (2017) where different tasks are trained jointly.
",5.1 Cross-Specialty NER,[0],[0]
"• CD-learning is a cross-domain learning method proposed by He and Sun (2017), where each source domain training example’s learning rate is re-weighted.
",5.1 Cross-Specialty NER,[0],[0]
"Experimental Settings We use 23,217 unlabeled clinical records to train the word embeddings (word2vec) at 128 dimensions using skipgram model (Mikolov et al., 2013).",5.1 Cross-Specialty NER,[0],[0]
The hidden state size is set to be 200 for word-level Bi-LSTM.,5.1 Cross-Specialty NER,[0],[0]
"We evaluate La-DTL for cross-specialty NER with CM-NER in 12 transfer tasks, results shown in Table 2.",5.1 Cross-Specialty NER,[0],[0]
"For each task, we take the whole source domain training set Ds and 10% sentences of the target domain training set Dt as training data.",5.1 Cross-Specialty NER,[0],[0]
We use the development set in target domain to search hyper-parameters including training epochs.,5.1 Cross-Specialty NER,[0],[0]
We then take the models to make the prediction in target domain test set and use F1-score as the evaluation metric.,5.1 Cross-Specialty NER,[0],[0]
"Statistical significance has been determined using a randomization version of the paired sample t-test (Cohen, 1995).",5.1 Cross-Specialty NER,[0],[0]
"Results and Discussion From the results of 12 cross-specialty NER tasks shown in Table 2, we find that La-DTL outperforms all the strong baselines in all the 12 cross-specialty transfer learning tasks, with 2.62% to 6.70% F1-score lift over state-of-the-art baseline methods.",5.1 Cross-Specialty NER,[0],[0]
"Meanwhile, Linear projection and Domain mask (Peng and Dredze, 2017) do not perform as good as other three baselines, which may be because such linear transformation methods are likely to weaken the representations.",5.1 Cross-Specialty NER,[0],[0]
"While other three baseline methods all share the whole model between source/target domains but differ in the training schemes and performance.
",5.1 Cross-Specialty NER,[0],[0]
"To better understand the transferability of LaDTL, we also evaluate three variants of LaDTL: La-MMD, CRF-L2, and MMD-CRF-L2.",5.1 Cross-Specialty NER,[0],[0]
"La-MMD and CRF-L2 have the same networks and loss function as La-DTL but with different building blocks: La-MMD has β = 0, while CRFL2 has α = 0.",5.1 Cross-Specialty NER,[0],[0]
"In MMD-CRF-L2, we replace La-MMD loss LLa-MMD in La-DTL with a vanilla MMD loss:
LMMD = MMD2(Rs,Rt),
where Rs and Rt are sets of hidden representation from source and target domain.",5.1 Cross-Specialty NER,[0],[0]
"Results in Table 2 show that: (i) Using La-MMD alone does achieve satisfactory performance since it outperforms the best baseline Joint-training (Yang et al., 2017) in 7 of 12 tasks.",5.1 Cross-Specialty NER,[0],[0]
"And it has a significant improvement over Domain mask and Linear projection methods (Peng and Dredze, 2017), which indicates that using La-MMD to reduce the domain discrepancy of feature representations in sequence tagging tasks is promising.",5.1 Cross-Specialty NER,[0],[0]
"(ii) CRF-L2 is also a promising method when transferring between NER tasks, and it improves the La-MMD method significantly when these two methods are combined to form La-DTL.",5.1 Cross-Specialty NER,[0],[0]
(iii) Label-aware characteristic is important in sequence labeling problems because there is an obvious performance drop when La-MMD is replaced with a vanilla MMD in La-DTL.,5.1 Cross-Specialty NER,[0],[0]
But MMD-CRF-L2 still has very competitive performance compared to all the baseline methods.,5.1 Cross-Specialty NER,[0],[0]
"This shows positive empirical evidence that transferring knowledge at both BiLSTM feature representation level and CRF parameter level for NER tasks is better than transferring knowledge at only one of these two levels, as discussed in Section 4.1.",5.1 Cross-Specialty NER,[0],[0]
"We further study the sparsity problem (target domain) of La-DTL in C→R task comparing to Joint-training (Yang et al., 2017) and Non-transfer method.",Robustness to Target Domain Data Sparsity,[0],[0]
"We evaluate La-DTL with different data volume (sampling rate: 10%, 25%, 50%, 100%) on the target domain training set.",Robustness to Target Domain Data Sparsity,[0],[0]
Results are shown in Figure 4(a).,Robustness to Target Domain Data Sparsity,[0],[0]
"We observe that La-DTL outperforms Joint-training and Non-transfer results under all circumstances, and the improvement of LaDTL is more significant when the sampling rate is lower.
",Robustness to Target Domain Data Sparsity,[0],[0]
"To show La-DTL’s convergence and significant improvement over Joint-training, we repeat the 10% sampling rate experiment for 10 times with 10 random seeds.",Robustness to Target Domain Data Sparsity,[0],[0]
The F1-score on the target domain development set for two methods with a 95% confidence interval is shown in Figure 4(b) where La-DTL outperforms Joint-training method significantly.,Robustness to Target Domain Data Sparsity,[0],[0]
"Hyperparameter Study We study the influence of three key hyperparameters in La-DTL: α, β, and ε in C→R task with 10% target domain sampling rate.",Robustness to Target Domain Data Sparsity,[0],[0]
"We first apply a rough grid search for the three hyperparameters, and the result is (α = 0.02, β = 0.03, ε = 0.3).",Robustness to Target Domain Data Sparsity,[0],[0]
We then fix two hyperparameters and test the third one in a finer granularity.,Robustness to Target Domain Data Sparsity,[0],[0]
The results in Figure 5 indicate that setting α ∈,Robustness to Target Domain Data Sparsity,[0],[0]
"[0.01, 0.04] could better leverage LaMMD and further setting β ∈",Robustness to Target Domain Data Sparsity,[0],[0]
"[0.03, 0.12] and ε ∈",Robustness to Target Domain Data Sparsity,[0],[0]
"[0.3, 0.4] yields the best empirical perfor-
mance.",Robustness to Target Domain Data Sparsity,[0],[0]
This shows that we need to balance the learning objective of the source and target domains for better transferability.,Robustness to Target Domain Data Sparsity,[0],[0]
"To show La-DTL could be applied in a wide range of NER transfer learning scenarios, we make experiments on two non-medical NER tasks.",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
Corpora’s details are shown in Table 3.,5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
WeiboNER,5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"Transfer Following He and Sun (2017); Peng and Dredze (2017), we transfer knowledge from SighanNER (MSR corpus of the sixth SIGHAN Workshop on Chinese language processing) to WeiboNER (a social media NER corpus) (Peng and Dredze, 2015).",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
Results in Table 4 show that La-DTL outperforms all the baseline methods in Chinese social media domain.,5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
TwitterNER Transfer,5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
Following Yang et al.,5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"(2017) we transfer knowledge from CoNLL 2003 English NER (Tjong Kim Sang and De Meulder, 2003) to TwitterNER (Ritter et al., 2011).",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"Since the entity types in these two corpora cannot be exactly matched, La-DTL and Joint-training (Yang et al., 2017) can be applied directly in this case while other baselines can not.",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"Because the CRF parameter transfer of La-DTL is label-aware, and Jointtraining simply leverages two independent CRF layers.",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"The results are shown in Table 5, where LaDTL again outperforms Joint-training, indicating that La-DTL could be applied seamlessly to trans-
fer learning scenarios with mismatched label sets and languages like English.",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"In this paper, we propose La-DTL, a label-aware double transfer learning framework, to conduct both Bi-LSTM feature representation transfer and CRF parameter transfer with label-aware constraints for cross-specialty medical NER tasks.",6 Conclusions,[0],[0]
"To our best knowledge, this is the first work on transfer learning for medical NER in cross-specialty scenario.",6 Conclusions,[0],[0]
Experiments on 12 cross-specialty NER tasks show that La-DTL provides consistent performance improvement over strong baselines.,6 Conclusions,[0],[0]
"We further perform a set of experiments on different target domain data size, hyperparameter study and other non-medical NER tasks, where La-DTL shows great robustness and wide efficacy.",6 Conclusions,[0],[0]
"For future work, we plan to jointly perform NER and entity linking for better cross-specialty media structural information extraction.",6 Conclusions,[0],[0]
"The work done by SJTU is sponsored by Synyi-SJTU Innovation Program, National Natural Science Foundation of China (61632017, 61702327, 61772333) and Shanghai Sailing Program (17YF1428200).",Acknowledgments,[0],[0]
Recall the bound as in Eq.,A.1 Detailed Proof,[0],[0]
"(6):
Lemma A.1.",A.1 Detailed Proof,[0],[0]
c1(‖Ws −Wt‖22,A.1 Detailed Proof,[0],[0]
"+ ‖As −At‖22) is the upper bound of (ss(H,y)− st(H,y))2.
",A.1 Detailed Proof,[0],[0]
Proof of Lemma A.1.,A.1 Detailed Proof,[0],[0]
"⊗ refers to convolutional product, HW ,HA are mask matrices corresponding to the given hidden vectors H, and c1 is a constant.",A.1 Detailed Proof,[0],[0]
"We have:
(ss(H,y)− st(H,y))2
=(
n∑
i=1
Esi,yi + n−1∑
i=1
Asyi,yi+1",A.1 Detailed Proof,[0],[0]
"− n∑
i=1
Eti,yi − n−1∑
i=1
Atyi,yi+1) 2
=(Ws ⊗HW +",A.1 Detailed Proof,[0],[0]
"As ⊗HA −Wt ⊗HW −At ⊗HA)2
=((Ws −Wt)⊗HW + (As −At)⊗HA)2
≤2((Ws −Wt)⊗HW )2 + 2((As −At)⊗HA)2 =2( ∑
i,j
(Ws −Wt)i,j ·HWi,j)2 + 2( ∑
p,q
(As −At)p,q ·HAp,q)2
≤2( ∑
i,j
(Ws −Wt)2i,j · ∑
i,j
(HWi,j) 2)",A.1 Detailed Proof,[0],[0]
"+ 2(
∑
p,q
(As −At)2p,q · ∑
p,q
(HAp,q) 2)
",A.1 Detailed Proof,[0],[0]
"=2(‖Ws −Wt‖22 · ‖HW ‖22) + 2(‖As −At‖22 · ‖HA‖22) ≤c1(‖Ws −Wt‖22 + ‖As −At‖22).
",A.1 Detailed Proof,[0],[0]
Lemma A.2. c(‖Ws,A.1 Detailed Proof,[0],[0]
−Wt‖22,A.1 Detailed Proof,[0],[0]
+ ‖As −At‖22),A.1 Detailed Proof,[0],[0]
"1 2 is the upper bound of DKL(ps(y|H)||pt(y|H)).
",A.1 Detailed Proof,[0],[0]
Proof of Lemma A.2.,A.1 Detailed Proof,[0],[0]
With Lemma.,A.1 Detailed Proof,[0],[0]
"(A.1), we set ε = (c1(‖Ws −Wt‖22 + ‖As",A.1 Detailed Proof,[0],[0]
− At‖22)),A.1 Detailed Proof,[0],[0]
"1 2 ≥ 0 and c = 2c 1 2 1 , and we have:
ss(H,y)− ε ≤",A.1 Detailed Proof,[0],[0]
"st(H,y) ≤",A.1 Detailed Proof,[0],[0]
"ss(H,y) + ε, (7)
log{ ∑
y′∈Y(H) exp[ss(H,y′)]}",A.1 Detailed Proof,[0],[0]
"− ε ≤ log{
∑
y′∈Y(H) exp[st(H,y′)]",A.1 Detailed Proof,[0],[0]
"} ≤ log{
∑
y′∈Y(H) exp[ss(H,y′)]}+ ε.
(8)
With Eq. (7) and Eq.",A.1 Detailed Proof,[0],[0]
"(8), we can derive
− ∑
y∈Y(H) ps(y|H) log pt(y|H)
",A.1 Detailed Proof,[0],[0]
"=− ∑
y∈Y(H) ps(y|H) log exp[s t(H,y)]∑ y′∈Y(H) exp[s",A.1 Detailed Proof,[0],[0]
"t(H,y′)]
=− ∑
y∈Y(H) ps(y|H)
{ st(H,y)− log{ ∑
y′∈Y(H) exp[st(H,y′)]}
}
≤− ∑
y∈Y(H) ps(y|H)
{",A.1 Detailed Proof,[0],[0]
"ss(H,y)− ε− log{ ∑
y′∈Y(H) exp[ss(H,y′)]}",A.1 Detailed Proof,[0],[0]
"− ε
}
=− ∑
y∈Y(H) ps(y|H)
{ log exp[ss(H,y)]∑ y′∈Y(H) exp[s",A.1 Detailed Proof,[0],[0]
"s(H,y′)]",A.1 Detailed Proof,[0],[0]
"−2ε }
=− ∑
y∈Y(H) ps(y|H)
{ log ps(y|H)−2ε }
=H(ps(y|H))",A.1 Detailed Proof,[0],[0]
"+ 2ε.
",A.1 Detailed Proof,[0],[0]
"Finally, we have
DKL(p s(y|H)||pt(y|H))
",A.1 Detailed Proof,[0],[0]
"= ∑
y∈Y(H) ps(y|H)",A.1 Detailed Proof,[0],[0]
"log(p s(y|H) pt(y|H) )
",A.1 Detailed Proof,[0],[0]
"=−H(ps(y|H))− ∑
y∈Y(H) ps(y|H) log pt(y|H)
≤−H(ps(y|H))",A.1 Detailed Proof,[0],[0]
+H(ps(y|H)),A.1 Detailed Proof,[0],[0]
+ 2ε =c(‖Ws −Wt‖22 + ‖As −At‖22) 1 2 .,A.1 Detailed Proof,[0],[0]
"In clinical practice, patients with specific diseases would be assigned to different departments, and specialist doctors in their department may pay more attention to the specific disease.",A.2 Case Analysis,[0],[0]
"When writing a medical chart, these specific diseases and related clinical findings would have a more detailed description.",A.2 Case Analysis,[0],[0]
"Therefore, some medical terms would have enriched meanings in different departments accordingly.",A.2 Case Analysis,[0],[0]
"For example, patients with rheumatic heart disease are often treated in the department of Cardiology.",A.2 Case Analysis,[0],[0]
"The term, “rheumatic”, a modifier, describes and limits the type of “heart disease”.",A.2 Case Analysis,[0],[0]
"In English, “rheumatic” is an adjective modifying “heart disease”.",A.2 Case Analysis,[0],[0]
"However, in Chinese, “rheumatic heart disease” can be regarded as two diseases, “rheumatism” and “heart disease”.",A.2 Case Analysis,[0],[0]
"In the department of Cardiology, “rheumatic heart dis-
ease” is usually mentioned as a single term.",A.2 Case Analysis,[0],[0]
"While in other departments, “rheumatism” and “heart disease” are mostly two independent named entities in annotated datasets.",A.2 Case Analysis,[0],[0]
"As such, it is difficult to train an NER model to capture the relationship between “rheumatism” and “heart disease”, and band them as a whole.",A.2 Case Analysis,[0],[0]
"In the training set of our study, the diagnostic term “rheumatic heart disease” (including synonym) is mentioned for 17 times in Dept. Cardiology, 16 times in Dept. Respiratory, none in Dept. Neurology and 3 times in Dept. Gastroenterology.",A.2 Case Analysis,[0],[0]
"We use the data from the first 3 departments as source domain training set respectively, and the data from Dept.",A.2 Case Analysis,[0],[0]
Gastroenterology as the target domain training set.,A.2 Case Analysis,[0],[0]
"We test our models on the test set from Dept. Gastroenterology, where “rheumatic heart disease” is mentioned 3 times, and compare the results across models
with/without transfer learning.",A.2 Case Analysis,[0],[0]
"As expected, models with source training data from Dept.",A.2 Case Analysis,[0],[0]
"Cardiovascular and Respiration correctly predict all these entities, but the model using source data from Dept. Neurology fails and so does a model without transfer learning.
",A.2 Case Analysis,[0],[0]
Patients with pulmonary heart disease were often referred to Dept. Respiratory and Dept. Cardiology.,A.2 Case Analysis,[0],[0]
"In our training set, “pulmonary heart disease” (including synonym) is labeled for 24 times in Dept. Respiratory and 4 times in Dept. Cardiology.",A.2 Case Analysis,[0],[0]
"In English, “pulmonary” modified “heart disease”.",A.2 Case Analysis,[0],[0]
"In Chinese, “pulmonary heart disease” contains body structure “lung” and disease name “heart disease”.",A.2 Case Analysis,[0],[0]
"The model trained with the source set from both from department of respiratory and cardiology could correctly recognize the relation between lung and heart disease and predict the entity in the test set from Dept. Gastroenterology.
",A.2 Case Analysis,[0],[0]
"Similarly, “coronary atherosclerotic heart disease” contains two disease names, “coronary atherosclerosis” and “heart disease”.",A.2 Case Analysis,[0],[0]
Training model using source set from a department where the terms are enriched could improve the performance of recognizing the whole entity.,A.2 Case Analysis,[0],[0]
"The 30 entity types for medical domain are: Symptom, Disease, Examination, Treatment, Laboratory index, Products, Body structure, Frequency, Negative word, Value, Trend, Modification, Temporal word, Noun of locality, Degree modifier, Probability, Object, Organism, Location, Person, Pronoun, Privacy information, Accident, Action, Header, Instrument and material, Nonphysiological structure, Dosage, Scale, and Preposition.",A.3 Medical Experiments Details,[0],[0]
"WeiboNER Transfer Both SighanNER and WeiboNER are annotated in the BIO format (Begin, Inside and Outside), but there is one more entity type (geo-political) in WeiboNER.",A.4 Non-medical Experiments Details,[0],[0]
"For a fair comparison, we follow Peng and Dredze (2017); He and Sun (2017) to merge geo-political entities and locations in WeiboNER, to match different labeling schemes between WeiboNER and SighanNER.",A.4 Non-medical Experiments Details,[0],[0]
"We use the inconsistencies fixed second version of WeiboNER data and word embeddings provided by WeiboNER’s developers (Peng and Dredze, 2015)2 in this experiment.
",A.4 Non-medical Experiments Details,[0],[0]
"TwitterNER Transfer To show that La-DTL could be applied in transfer learning for NER scenario with mismatched
2 https://github.com/hltcoe/golden-horse
named entity types and languages like English, we conduct this experiment transfer from CoNLL 2003 English NER to TwitterNER.",A.4 Non-medical Experiments Details,[0],[0]
"The four entity types in CoNLL 2003 English NER are LOC, PER, ORG, and MISC.",A.4 Non-medical Experiments Details,[0],[0]
"The ten entity types in TwitterNER are company, facility, geo-loc, movie, musicartist, other, person, product, sportsteam, and tvshow.
",A.4 Non-medical Experiments Details,[0],[0]
"The Joint-training method (Yang et al., 2017) separates the CRF layers for each domain to bypass the label mismatch problem.",A.4 Non-medical Experiments Details,[0],[0]
"Since our La-DTL is label-aware, we match four pairs of named entities between two CoNLL 2003 English NER and TwitterNER: LOC with geo-loc, PER with person, ORG with company and MISC with other to compute LLa-MMD and Lp, and leave six named entities unmatched.",A.4 Non-medical Experiments Details,[0],[0]
"Following Yang et al. (2017), We leverage char-level Bi-LSTM to generate better word representations, concatenate it with pre-trained word embeddings and feed concatenated embeddings to the word-level Bi-LSTM.",A.4 Non-medical Experiments Details,[0],[0]
"The framework used for language like English is illustrated in Figure 6.
",A.4 Non-medical Experiments Details,[0],[0]
We also convert all characters to lowercase and use the same word embeddings provided by Yang et al. (2017)3.,A.4 Non-medical Experiments Details,[0],[0]
"Also, we concatenate the training set and the development set for both domains and sample the same 10% from TwitterNER as (Yang et al., 2017) to be target domain training data.",A.4 Non-medical Experiments Details,[0],[0]
"Since Yang et al. (2017) merge training and development set into training data, both Yang et al. (2017) and we report the best performance in the target domain test set.
",A.4 Non-medical Experiments Details,[0],[0]
3 https://github.com/kimiyoung/transfer,A.4 Non-medical Experiments Details,[0],[0]
"We study the problem of named entity recognition (NER) from electronic medical records, which is one of the most fundamental and critical problems for medical text mining.",abstractText,[0],[0]
Medical records which are written by clinicians from different specialties usually contain quite different terminologies and writing styles.,abstractText,[0],[0]
The difference of specialties and the cost of human annotation makes it particularly difficult to train a universal medical NER system.,abstractText,[0],[0]
"In this paper, we propose a labelaware double transfer learning framework (LaDTL) for cross-specialty NER, so that a medical NER system designed for one specialty could be conveniently applied to another one with minimal annotation efforts.",abstractText,[0],[0]
"The transferability is guaranteed by two components: (i) we propose label-aware MMD for feature representation transfer, and (ii) we perform parameter transfer with a theoretical upper bound which is also label aware.",abstractText,[0],[0]
We conduct extensive experiments on 12 cross-specialty NER tasks.,abstractText,[0],[0]
The experimental results demonstrate that La-DTL provides consistent accuracy improvement over strong baselines.,abstractText,[0],[0]
"Besides, the promising experimental results on non-medical NER scenarios indicate that LaDTL is potential to be seamlessly adapted to a wide range of NER tasks.",abstractText,[0],[0]
Label-aware Double Transfer Learning for Cross-Specialty Medical Named Entity Recognition,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 319–328, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"The recurrent sequence-to-sequence paradigm for natural language generation (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014) has achieved remarkable recent success and is now the approach of choice for applications such as machine translation (Bahdanau et al., 2015), caption generation (Xu et al., 2015) and speech recognition (Chorowski et al., 2015).",1 Introduction,[0],[0]
"While these models have developed sophisticated conditioning mechanisms, e.g. attention, fundamentally they are discriminative models trained only to approximate the conditional output distribution of strings.",1 Introduction,[0],[0]
"In this paper we explore modelling the
joint distribution of string pairs using a deep generative model and employing a discrete variational autoencoder (VAE) for inference (Kingma and Welling, 2014; Rezende et al., 2014; Mnih and Gregor, 2014).",1 Introduction,[0],[0]
We evaluate our generative approach on the task of sentence compression.,1 Introduction,[0],[0]
"This approach provides both alternative supervised objective functions and the opportunity to perform semi-supervised learning by exploiting the VAEs ability to marginalise the latent compressed text for unlabelled data.
",1 Introduction,[0],[0]
"Auto-encoders (Rumelhart et al., 1985) are a typical neural network architecture for learning compact data representations, with the general aim of performing dimensionality reduction on embeddings (Hinton and Salakhutdinov, 2006).",1 Introduction,[0],[0]
"In this paper, rather than seeking to embed inputs as points in a vector space, we describe them with explicit natural language sentences.",1 Introduction,[0],[0]
This approach is a natural fit for summarisation tasks such as sentence compression.,1 Introduction,[0],[0]
"According to this, we propose a generative auto-encoding sentence compression (ASC) model, where we introduce a latent language model to provide the variablelength compact summary.",1 Introduction,[0],[0]
The objective is to perform Bayesian inference for the posterior distribution of summaries conditioned on the observed utterances.,1 Introduction,[0],[0]
"Hence, in the framework of VAE, we construct an inference network as the variational approximation of the posterior, which generates compression samples to optimise the variational lower bound.
",1 Introduction,[0],[0]
"The most common family of variational autoencoders relies on the reparameterisation trick, which is not applicable for our discrete latent language model.",1 Introduction,[0],[0]
"Instead, we employ the REINFORCE algorithm (Mnih et al., 2014; Mnih and Gregor, 2014)
319
to mitigate the problem of high variance during sampling-based variational inference.",1 Introduction,[0],[0]
"Nevertheless, when directly applying the RNN encoder-decoder to model the variational distribution it is very difficult to generate reasonable compression samples in the early stages of training, since each hidden state of the sequence would have |V | possible words to be sampled from.",1 Introduction,[0],[0]
"To combat this we employ pointer networks (Vinyals et al., 2015) to construct the variational distribution.",1 Introduction,[0],[0]
"This biases the latent space to sequences composed of words only appearing in the source sentence (i.e. the size of softmax output for each state becomes the length of current source sentence), which amounts to applying an extractive compression model for the variational approximation.
",1 Introduction,[0],[0]
"In order to further boost the performance on sentence compression, we employ a supervised forcedattention sentence compression model (FSC) trained on labelled data to teach the ASC model to generate compression sentences.",1 Introduction,[0],[0]
The FSC model shares the pointer network of the ASC model and combines a softmax output layer over the whole vocabulary.,1 Introduction,[0],[0]
"Therefore, while training on the sentencecompression pairs, it is able to balance copying a word from the source sentence with generating it from the background distribution.",1 Introduction,[0],[0]
"More importantly, by jointly training on the labelled and unlabelled datasets, this shared pointer network enables the model to work in a semi-supervised scenario.",1 Introduction,[0],[0]
"In
this case, the FSC teaches the ASC to generate reasonable samples, while the pointer network trained on a large unlabelled data set helps the FSC model to perform better abstractive summarisation.
",1 Introduction,[0],[0]
"In Section 6, we evaluate the proposed model by jointly training the generative (ASC) and discriminative (FSC) models on the standard Gigaword sentence compression task with varying amounts of labelled and unlabelled data.",1 Introduction,[0],[0]
The results demonstrate that by introducing a latent language variable we are able to match the previous benchmakers with small amount of the supervised data.,1 Introduction,[0],[0]
When we employ our mixed discriminative and generative objective with all of the supervised data the model significantly outperforms all previously published results.,1 Introduction,[0],[0]
"In this section, we introduce the auto-encoding sentence compression model (Figure 1)1 in the framework of variational auto-encoders.",2 Auto-Encoding Sentence Compression,[0],[0]
"The ASC model consists of four recurrent neural networks – an encoder, a compressor, a decoder and a language model.
",2 Auto-Encoding Sentence Compression,[0],[0]
"Let s be the source sentence, and c be the compression sentence.",2 Auto-Encoding Sentence Compression,[0],[0]
The compression model (encodercompressor) is the inference network qφ(c|s) that takes source sentences s as inputs and generates extractive compressions c.,2 Auto-Encoding Sentence Compression,[0],[0]
"The reconstruction
1The language model, layer connections and decoder soft attentions are omitted in Figure 1 for clarity.
model (compressor-decoder) is the generative network pθ(s|c) that reconstructs source sentences s based on the latent compressions c. Hence, the forward pass starts from the encoder to the compressor and ends at the decoder.",2 Auto-Encoding Sentence Compression,[0],[0]
"As the prior distribution, a language model p(c) is pre-trained to regularise the latent compressions so that the samples drawn from the compression model are likely to be reasonable natural language sentences.",2 Auto-Encoding Sentence Compression,[0],[0]
"For the compression model (encoder-compressor), qφ(c|s), we employ a pointer network consisting of a bidirectional LSTM encoder that processes the source sentences, and an LSTM compressor that generates compressed sentences by attending to the encoded source words.
",2.1 Compression,[0],[0]
"Let si be the words in the source sentences, hei be the corresponding state outputs of the encoder.",2.1 Compression,[0],[0]
"hei are the concatenated hidden states from each direction:
hei = f−→enc(~h e i−1, si)||f←−enc( ~hei+1, si) (1)
",2.1 Compression,[0],[0]
"Further, let cj be the words in the compressed sentences, hcj be the state outputs of the compressor.",2.1 Compression,[0],[0]
"We construct the predictive distribution by attending to the words in the source sentences:
hcj =fcom(h c j−1, cj−1) (2)
uj(i) =w T 3",2.1 Compression,[0],[0]
tanh(W1h c j+W2h e,2.1 Compression,[0],[0]
"i ) (3)
qφ(cj |c1:j−1, s)= softmax(uj) (4)
where c0 is the start symbol for each compressed sentence and hc0 is initialised by the source sentence vector of he|s|.",2.1 Compression,[0],[0]
"In this case, all the words cj sampled from qφ(cj |c1:j−1, s) are the subset of the words appeared in the source sentence (i.e. cj ∈ s).",2.1 Compression,[0],[0]
"For the reconstruction model (compressor-decoder) pθ(s|c), we apply a soft attention sequence-tosequence model to generate the source sentence s based on the compression samples c ∼ qφ(c|s).
",2.2 Reconstruction,[0],[0]
"Let sk be the words in the reconstructed sentences and hdk be the corresponding state outputs of the decoder:
hdk = fdec(h d k−1, sk−1) (5)
",2.2 Reconstruction,[0],[0]
"In this model, we directly use the recurrent cell of the compressor to encode the compression samples2:
ĥ c j =fcom(ĥ c j−1, cj) (6)
where the state outputs ĥ c j corresponding to the word inputs cj are different from the outputs hcj in the compression model, since we block the information from the source sentences.",2.2 Reconstruction,[0],[0]
We also introduce a start symbol s0 for the reconstructed sentence and hd0 is initialised by the last state output ĥ c |c|.,2.2 Reconstruction,[0],[0]
"The soft attention model is defined as:
vk(j) =w T 6 tanh(W",2.2 Reconstruction,[0],[0]
4h d k,2.2 Reconstruction,[0],[0]
"+W 5ĥ c j) (7)
γk(j) = softmax(vk(j))",2.2 Reconstruction,[0],[0]
"(8)
dk = ∑|c|
j γk(j)ĥ
c j(vk(j)) (9)
We then construct the predictive probability distribution over reconstructed words using a softmax:
pθ(sk|s1:k−1, c) =",2.2 Reconstruction,[0],[0]
softmax(W 7dk) (10),2.2 Reconstruction,[0],[0]
"In the ASC model there are two sets of parameters, φ and θ, that need to be updated during inference.",2.3 Inference,[0],[0]
"Due to the non-differentiability of the model, the reparameterisation trick of the VAE is not applicable in this case.",2.3 Inference,[0],[0]
"Thus, we use the REINFORCE algorithm (Mnih et al., 2014; Mnih and Gregor, 2014) to reduce the variance of the gradient estimator.
",2.3 Inference,[0],[0]
"The variational lower bound of the ASC model is:
L =Eqφ(c|s)[log pθ(s|c)]−DKL[qφ(c|s)||p(c)]
6 log ∫ qφ(c|s) qφ(c|s) pθ(s|c)p(c)dc = log p(s) (11)
",2.3 Inference,[0],[0]
"Therefore, by optimising the lower bound (Eq. 11), the model balances the selection of keywords for the summaries and the efficacy of the composed compressions, corresponding to the reconstruction error and KL divergence respectively.
",2.3 Inference,[0],[0]
"In practise, the pre-trained language model prior p(c) prefers short sentences for compressions.",2.3 Inference,[0],[0]
"As one of the drawbacks of VAEs, the KL divergence term in the lower bound pushes every sample drawn
2The recurrent parameters of the compressor are not updated by the gradients from the reconstruction model.
from the variational distribution towards the prior.",2.3 Inference,[0],[0]
"Thus acting to regularise the posterior, but also to restrict the learning of the encoder.",2.3 Inference,[0],[0]
"If the estimator keeps sampling short compressions during inference, the LSTM decoder would gradually rely on the contexts from the decoded words instead of the information provided by the compressions, which does not yield the best performance on sentence compression.
",2.3 Inference,[0],[0]
"Here, we introduce a co-efficient λ to scale the learning signal of the KL divergence: L=Eqφ(c|s)[log pθ(s|c)]−λDKL[qφ(c|s)||p(c)]",2.3 Inference,[0],[0]
"(12)
",2.3 Inference,[0],[0]
"Although we are not optimising the exact variational lower bound, the ultimate goal of learning an effective compression model is mostly up to the reconstruction error.",2.3 Inference,[0],[0]
"In Section 6, we empirically apply λ = 0.1 for all the experiments on ASC model.",2.3 Inference,[0],[0]
"Interestingly, λ controls the compression rate of the sentences which can be a good point to be explored in future work.
",2.3 Inference,[0],[0]
"During the inference, we have different strategies for updating the parameters of φ and θ.",2.3 Inference,[0],[0]
"For the parameters θ in the reconstruction model, we directly update them by the gradients:
∂L ∂θ = Eqφ(c|s)[ ∂ log pθ(s|c) ∂θ",2.3 Inference,[0],[0]
"]
≈ 1 M
∑
m
∂ log pθ(s|c(m))",2.3 Inference,[0],[0]
"∂θ
(13)
",2.3 Inference,[0],[0]
"where we draw M samples c(m) ∼ qφ(c|s) independently for computing the stochastic gradients.
",2.3 Inference,[0],[0]
"For the parameters φ in the compression model, we firstly define the learning signal,
l(s, c) = log pθ(s|c)− λ(log qφ(c|s)− log p(c)).
",2.3 Inference,[0],[0]
"Then, we update the parameters φ by:
∂L ∂φ = Eqφ(c|s)[l(s, c) ∂ log qφ(c|s) ∂φ ]
≈ 1 M
∑
m
[l(s, c(m)) ∂ log qφ(c (m)|s) ∂φ ] (14)
",2.3 Inference,[0],[0]
"However, this gradient estimator has a big variance because the learning signal l(s, c(m)) relies on the samples from qφ(c|s).",2.3 Inference,[0],[0]
"Therefore, following the REINFORCE algorithm, we introduce two baselines b and b(s), the centred learning signal and inputdependent baseline respectively, to help reduce the variance.
",2.3 Inference,[0],[0]
"Here, we build an MLP to implement the inputdependent baseline b(s).",2.3 Inference,[0],[0]
"During training, we learn the two baselines by minimising the expectation:
Eqφ(c|s)[(l(s, c)− b− b(s))2].",2.3 Inference,[0],[0]
"(15)
Hence, the gradients w.r.t. φ are derived as,
∂L ∂φ",2.3 Inference,[0],[0]
"≈ 1 M
∑
m
(l(s, c(m))−b−b(s))∂ log qφ(c (m)|s)
∂φ
(16) which is basically a likelihood-ratio estimator.",2.3 Inference,[0],[0]
"In neural variational inference, the effectiveness of training largely depends on the quality of the inference network gradient estimator.",3 Forced-attention Sentence Compression,[0],[0]
"Although we introduce a biased estimator by using pointer networks, it is still very difficult for the compression model to generate reasonable natural language sentences at the early stage of learning, which results in
high-variance for the gradient estimator.",3 Forced-attention Sentence Compression,[0],[0]
"Here, we introduce our supervised forced-attention sentence compression (FSC) model to teach the compression model to generate coherent compressed sentences.
",3 Forced-attention Sentence Compression,[0],[0]
"Neither directly replicating the pointer network of ASC model, nor using a typical sequence-tosequence model, the FSC model employs a forceattention strategy (Figure 2) that encourages the compressor to select words appearing in the source sentence but keeps the original full output vocabulary V .",3 Forced-attention Sentence Compression,[0],[0]
The force-attention strategy is basically a combined pointer network that chooses whether to select a word from the source sentence s or to predict a word from V at each recurrent state.,3 Forced-attention Sentence Compression,[0],[0]
"Hence, the combined pointer network learns to copy the source words while predicting the word sequences of compressions.",3 Forced-attention Sentence Compression,[0],[0]
"By sharing the pointer networks between the ASC and FSC model, the biased estimator obtains further positive biases by training on a small set of labelled source-compression pairs.
",3 Forced-attention Sentence Compression,[0],[0]
"Here, the FSC model makes use of the compression model (Eq. 1 to 4) in the ASC model,
αj =softmax(uj), (17)
where αj(i), i ∈ (1, . . .",3 Forced-attention Sentence Compression,[0],[0]
", |s|) denotes the probability of selecting si as the prediction for cj .
",3 Forced-attention Sentence Compression,[0],[0]
"On the basis of the pointer network, we further introduce the probability of predicting cj that is selected from the full vocabulary,
βj = softmax(Wh c j), (18)
where βj(w), w ∈ (1, . . .",3 Forced-attention Sentence Compression,[0],[0]
", |V |) denotes the probability of selecting the wth from V as the prediction for cj .",3 Forced-attention Sentence Compression,[0],[0]
"To combine these two probabilities in the RNN, we define a selection factor t for each state output, which computes the semantic similarities between the current state and the attention vector,
ηj = ∑|s|
i αj(i)h
e i (19)
tj = σ(η T jMh c j).",3 Forced-attention Sentence Compression,[0],[0]
"(20)
Hence, the probability distribution over compressed words is defined as, p(cj |c1:j−1, s)= { tjαj(i) + (1− tj)βj(cj), cj=si (1− tj)βj(cj), cj 6∈s
(21)
",3 Forced-attention Sentence Compression,[0],[0]
"Essentially, the FSC model is the extended compression model of ASC by incorporating the pointer network with a softmax output layer over the full vocabulary.",3 Forced-attention Sentence Compression,[0],[0]
"So we employ φ to denote the parameters of the FSC model pφ(c|s), which covers the parameters of the variational distribution qφ(c|s).",3 Forced-attention Sentence Compression,[0],[0]
"As the auto-encoding sentence compression (ASC) model grants the ability to make use of an unlabelled dataset, we explore a semi-supervised training framework for the ASC and FSC models.",4 Semi-supervised Training,[0],[0]
"In this scenario we have a labelled dataset that contains source-compression parallel sentences, (s, c) ∈ L, and an unlabelled dataset that contains only source sentences s ∈ U.",4 Semi-supervised Training,[0],[0]
"The FSC model is trained on L so that we are able to learn the compression model by maximising the log-probability,
F = ∑
(c,s)∈L log pφ(c|s).",4 Semi-supervised Training,[0],[0]
"(22)
",4 Semi-supervised Training,[0],[0]
"While the ASC model is trained on U, where we maximise the modified variational lower bound, L= ∑
s∈U (Eqφ(c|s)[log pθ(s|c)]−λDKL[qφ(c|s)||p(c)]).
(23)
",4 Semi-supervised Training,[0],[0]
"The joint objective function of the semi-supervised learning is,
J= ∑
s∈U (Eqφ(c|s)[log pθ(s|c)]−λDKL[qφ(c|s)||p(c)])",4 Semi-supervised Training,[0],[0]
"+ ∑
(c,s)∈L log pφ(c|s).",4 Semi-supervised Training,[0],[0]
"(24)
Hence, the pointer network is trained on both unlabelled data, U, and labelled data, L, by a mixed criterion of REINFORCE and cross-entropy.",4 Semi-supervised Training,[0],[0]
"As one of the typical sequence-to-sequence tasks, sentence-level summarisation has been explored by a series of discriminative encoder-decoder neural models.",5 Related Work,[0],[0]
"Filippova et al. (2015) carries out extractive summarisation via deletion with LSTMs, while Rush et al. (2015) applies a convolutional encoder and an
attentional feed-forward decoder to generate abstractive summarises, which provides the benchmark for the Gigaword dataset.",5 Related Work,[0],[0]
Nallapati et al. (2016) further improves the performance by exploring multiple variants of RNN encoder-decoder models.,5 Related Work,[0],[0]
"The recent works Gulcehre et al. (2016), Nallapati et al. (2016) and Gu et al. (2016) also apply the similar idea of combining pointer networks and softmax output.",5 Related Work,[0],[0]
"However, different from all these discriminative models above, we explore generative models for sentence compression.",5 Related Work,[0],[0]
"Instead of training the discriminative model on a big labelled dataset, our original intuition of introducing a combined pointer networks is to bridge the unsupervised generative model (ASC) and supervised model (FSC) so that we could utilise a large additional dataset, either labelled or unlabelled, to boost the compression performance.",5 Related Work,[0],[0]
"Dai and Le (2015) also explored semi-supervised sequence learning, but in a pure deterministic model focused on learning better vector representations.
",5 Related Work,[0],[0]
Recently variational auto-encoders have been applied in a variety of fields as deep generative models.,5 Related Work,[0],[0]
"In computer vision Kingma and Welling (2014), Rezende et al. (2014), and Gregor et al. (2015) have demonstrated strong performance on the task of image generation and Eslami et al. (2016) proposed variable-sized variational auto-encoders to identify multiple objects in images.",5 Related Work,[0],[0]
"While in natural language processing, there are variants of VAEs on modelling documents (Miao et al., 2016), sentences (Bowman et al., 2015) and discovery of relations (Marcheggiani and Titov, 2016).",5 Related Work,[0],[0]
"Apart from the typical initiations of VAEs, there are also a series of works that employs generative models for supervised learning tasks.",5 Related Work,[0],[0]
"For instance, Ba et al. (2015) learns visual attention for multiple objects by optimising a variational lower bound, Kingma et al. (2014) implements a semi-supervised framework for image classification and Miao et al. (2016) applies a conditional variational approximation in the task of factoid question answering.",5 Related Work,[0],[0]
Dyer et al. (2016) proposes a generative model that explicitly extracts syntactic relationships among words and phrases which further supports the argument that generative models can be a statistically efficient method for learning neural networks from small data.,5 Related Work,[0],[0]
We evaluate the proposed models on the standard Gigaword3 sentence compression dataset.,6.1 Dataset & Setup,[0],[0]
This dataset was generated by pairing the headline of each article with its first sentence to create a source-compression pair.,6.1 Dataset & Setup,[0],[0]
"Rush et al. (2015) provided scripts4 to filter out outliers, resulting in roughly 3.8M training pairs, a 400K validation set, and a 400K test set.",6.1 Dataset & Setup,[0],[0]
"In the following experiments all models are trained on the training set with different data sizes5 and tested on a 2K subset, which is identical to the test set used by Rush et al. (2015) and Nallapati et al. (2016).",6.1 Dataset & Setup,[0],[0]
"We decode the sentences by k = 5 Beam search and test with full-length Rouge score.
",6.1 Dataset & Setup,[0],[0]
"For the ASC and FSC models, we use 256 for the dimension of both hidden units and lookup tables.",6.1 Dataset & Setup,[0],[0]
"In the ASC model, we apply a 3-layer bidirectional RNN with skip connections as the encoder, a 3-layer RNN pointer network with skip connections as the compressor, and a 1-layer vanilla RNN with soft attention as the decoder.",6.1 Dataset & Setup,[0],[0]
The language model prior is trained on the article sentences of the full training set using a 3-layer vanilla RNN with 0.5 dropout.,6.1 Dataset & Setup,[0],[0]
"To lower the computational cost, we apply different vocabulary sizes for encoder and compressor (119,506 and 68,897) which corresponds to the settings of Rush et al. (2015).",6.1 Dataset & Setup,[0],[0]
"Specifically, the vocabulary of the decoder is filtered by taking the most frequent 10,000 words from the vocabulary of the encoder, where the rest of the words are tagged as ‘<unk>’.",6.1 Dataset & Setup,[0],[0]
"In further consideration of efficiency, we use only one sample for the gradient estimator.",6.1 Dataset & Setup,[0],[0]
"We optimise the model by Adam (Kingma and Ba, 2015) with a 0.0002 learning rate and 64 sentences per batch.",6.1 Dataset & Setup,[0],[0]
The model converges in 5 epochs.,6.1 Dataset & Setup,[0],[0]
"Except for the pretrained language model, we do not use dropout or embedding initialisation for ASC and FSC models.",6.1 Dataset & Setup,[0],[0]
The first set of experiments evaluate the models on extractive summarisation.,6.2 Extractive Summarisation,[0],[0]
"Here, we denote the joint
3https://catalog.ldc.upenn.edu/LDC2012T21 4https://github.com/facebook/NAMAS 5The hyperparameters where tuned on the validation set to maximise the perplexity of the summaries rather than the reconstructed source sentences.
models by ASC+FSC1 and ASC+FSC2 where ASC is trained on unlabelled data and FSC is trained on labelled data.",6.2 Extractive Summarisation,[0],[0]
"The ASC+FSC1 model employs equivalent sized labelled and unlabelled datasets, where the article sentences of the unlabelled data are the same article sentences in the labelled data, so there is no additional unlabelled data applied in this case.",6.2 Extractive Summarisation,[0],[0]
"The ASC+FSC2 model employs the full unlabelled dataset in addition to the existing labelled dataset, which is the true semi-supervised setting.
",6.2 Extractive Summarisation,[0],[0]
Table 1 presents the test Rouge score on extractive compression.,6.2 Extractive Summarisation,[0],[0]
We can see that the ASC+FSC1 model achieves significant improvements on F-1 scores when compared to the supervised FSC model only trained on labelled data.,6.2 Extractive Summarisation,[0],[0]
"Moreover, fixing the labelled data size, the ASC+FSC2 model achieves better performance by using additional unlabelled data than the ASC+FSC1 model, which means the semi-supervised learning works in this scenario.",6.2 Extractive Summarisation,[0],[0]
"Interestingly, learning on the unlabelled data largely increases the precisions (though the recalls do not benefit from it) which leads to significant improvements on the F-1 Rouge scores.",6.2 Extractive Summarisation,[0],[0]
"And surprisingly, the extractive ASC+FSC1 model trained on full labelled data outperforms the abstractive NABS (Rush et al., 2015) baseline model (in Table 4).",6.2 Extractive Summarisation,[0],[0]
The second set of experiments evaluate performance on abstractive summarisation (Table 2).,6.3 Abstractive Summarisation,[0],[0]
"Consistently, we see that adding the generative objective to the discriminative model (ASC+FSC1) results in a significant boost on all the Rouge scores, while employing extra unlabelled data increase performance
further (ASC+FSC2).",6.3 Abstractive Summarisation,[0],[0]
"This validates the effectiveness of transferring the knowledge learned on unlabelled data to the supervised abstractive summarisation.
",6.3 Abstractive Summarisation,[0],[0]
"In Figure 3, we present the validation perplexity to compare the abilities of the three models to learn the compression languages.",6.3 Abstractive Summarisation,[0],[0]
"The ASC+FSC1(red) employs the same dataset for unlabelled and labelled training, while the ASC+FSC2(black) employs the full unlabelled dataset.",6.3 Abstractive Summarisation,[0],[0]
"Here, the joint ASC+FSC1 model obtains better perplexities than the single discriminative FSC model, but there is not much difference between ASC+FSC1 and ASC+FSC2 when the size of the labelled dataset grows.",6.3 Abstractive Summarisation,[0],[0]
"From the perspective of language modelling, the generative ASC model indeed helps the discriminative model learn to generate good summary sentences.",6.3 Abstractive Summarisation,[0],[0]
"Table 3 displays the validation perplexities of the benchmark models, where the joint ASC+FSC1 model trained on the full labelled and unlabelled datasets performs the best on modelling compression languages.
",6.3 Abstractive Summarisation,[0],[0]
Table 4 compares the test Rouge score on abstractive summarisation.,6.3 Abstractive Summarisation,[0],[0]
"Encouragingly, the semisupervised model ASC+FSC2 outperforms the baseline model NABS when trained on 500K supervised pairs, which is only about an eighth of the supervised data.",6.3 Abstractive Summarisation,[0],[0]
"In Nallapati et al. (2016), the authors exploit the full limits of discriminative RNN encoderdecoder models by incorporating a sampled softmax, expanded vocabulary, additional lexical features, and combined pointer networks6, which yields the best performance listed in Table 4.",6.3 Abstractive Summarisation,[0],[0]
"However, when all the data is employed with the mixed ob-
6The idea of the combined pointer networks is similar to the FSC model, but the implementations are slightly different.
",6.3 Abstractive Summarisation,[0],[0]
"jective ASC+FSC1 model, the result is significantly better than this previous state-of-the-art.",6.3 Abstractive Summarisation,[0],[0]
"As the semisupervised ASC+FSC2 model can be trained on unlimited unlabelled data, there is still significant space left for further performance improvements.
",6.3 Abstractive Summarisation,[0],[0]
Table 5 presents the examples of the compression sentences decoded by the joint model ASC+FSC1 and the FSC model trained on the full dataset.,6.3 Abstractive Summarisation,[0],[0]
"From the perspective of generative models, a significant contribution of our work is a process for reducing variance for discrete sampling-based variational inference.",7 Discussion,[0],[0]
"The first step is to introduce two baselines in the control variates method due to the fact that the reparameterisation trick is not applica-
ble for discrete latent variables.",7 Discussion,[0],[0]
However it is the second step of using a pointer network as the biased estimator that makes the key contribution.,7 Discussion,[0],[0]
"This results in a much smaller state space, bounded by the length of the source sentence (mostly between 20 and 50 tokens), compared to the full vocabulary.",7 Discussion,[0],[0]
The final step is to apply the FSC model to transfer the knowledge learned from the supervised data to the pointer network.,7 Discussion,[0],[0]
This further reduces the sampling variance by acting as a sort of bootstrap or constraint on the unsupervised latent space which could encode almost anything but which thus becomes biased towards matching the supervised distribution.,7 Discussion,[0],[0]
"By using these variance reduction methods, the ASC model is able to carry out effective variational inference for the latent language model so that it learns to summarise the sentences from the large unlabelled training data.
",7 Discussion,[0],[0]
"In a different vein, according to the reinforcement learning interpretation of sequence level training (Ranzato et al., 2016), the compression model of the ASC model acts as an agent which iteratively generates words (takes actions) to compose the com-
pression sentence and the reconstruction model acts as the reward function evaluating the quality of the compressed sentence which is provided as a reward signal.",7 Discussion,[0],[0]
Ranzato et al. (2016) presents a thorough empirical evaluation on three different NLP tasks by using additional sequence-level reward (BLEU and Rouge-2) to train the models.,7 Discussion,[0],[0]
"In the context of this paper, we apply a variational lower bound (mixed reconstruction error and KL divergence regularisation) instead of the explicit Rouge score.",7 Discussion,[0],[0]
Thus the ASC model is granted the ability to explore unlimited unlabelled data resources.,7 Discussion,[0],[0]
In addition we introduce a supervised FSC model to teach the compression model to generate stable sequences instead of starting with a random policy.,7 Discussion,[0],[0]
"In this case, the pointer network that bridges the supervised and unsupervised model is trained by a mixed criterion of REINFORCE and cross-entropy in an incremental learning framework.",7 Discussion,[0],[0]
"Eventually, according to the experimental results, the joint ASC and FSC model is able to learn a robust compression model by exploring both labelled and unlabelled data, which outperforms the other single discriminative compression models that are only trained by cross-entropy reward signal.",7 Discussion,[0],[0]
In this paper we have introduced a generative model for jointly modelling pairs of sequences and evaluated its efficacy on the task of sentence compression.,8 Conclusion,[0],[0]
The variational auto-encoding framework provided an effective inference algorithm for this approach and also allowed us to explore combinations of discriminative (FSC) and generative (ASC) compression models.,8 Conclusion,[0],[0]
The evaluation results show that supervised training of the combination of these models improves upon the state-of-the-art performance for the Gigaword compression dataset.,8 Conclusion,[0],[0]
When we train the supervised FSC model on a small amount of labelled data and the unsupervised ASC model on a large set of unlabelled data the combined model is able to outperform previously reported benchmarks trained on a great deal more supervised data.,8 Conclusion,[0],[0]
These results demonstrate that we are able to model language as a discrete latent variable in a variational auto-encoding framework and that the resultant generative model is able to effectively exploit both supervised and unsupervised data in sequence-to-sequence tasks.,8 Conclusion,[0],[0]
In this work we explore deep generative models of text in which the latent representation of a document is itself drawn from a discrete language model distribution.,abstractText,[0],[0]
We formulate a variational auto-encoder for inference in this model and apply it to the task of compressing sentences.,abstractText,[0],[0]
"In this application the generative model first draws a latent summary sentence from a background language model, and then subsequently draws the observed sentence conditioned on this latent summary.",abstractText,[0],[0]
In our empirical evaluation we show that generative formulations of both abstractive and extractive compression yield state-of-the-art results when trained on a large amount of supervised data.,abstractText,[0],[0]
"Further, we explore semi-supervised compression scenarios where we show that it is possible to achieve performance competitive with previously proposed supervised models while training on a fraction of the supervised data.",abstractText,[0],[0]
Language as a Latent Variable: Discrete Generative Models for Sentence Compression,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1928–1937 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1928",text,[0],[0]
"The recent years have seen an increased interest as well as rapid progress in semantic parsing and surface realization based on graph-structured semantic representations, e.g. Abstract Meaning Representation (AMR; Banarescu et al., 2013), Elementary Dependency Structure (EDS; Oepen and Lønning, 2006) and Depedendency-based Minimal Recursion Semantics (DMRS; Copestake, 2009).",1 Introduction,[0],[0]
"Still underexploited is a formal framework for manipulating graphs that parallels automata, tranducers or formal grammars for strings and trees.",1 Introduction,[0],[0]
Two such formalisms have recently been proposed and applied for NLP.,1 Introduction,[0],[0]
"One is graph grammar, e.g. Hyperedge Replacement Gram-
mar (HRG; Ehrig et al., 1999).",1 Introduction,[0],[0]
"The other is DAG automata, originally studied by Kamimura and Slutzki (1982) and extended by Chiang et al. (2018).",1 Introduction,[0],[0]
"In this paper, we study DAG transducers in depth, with the goal of building accurate, efficient yet robust natural language generation (NLG) systems.
",1 Introduction,[0],[0]
"The meaning representation studied in this work is what we call type-logical semantic graphs, i.e. semantic graphs grounded under type-logical semantics (Carpenter, 1997), one dominant theoretical framework for modeling natural language semantics.",1 Introduction,[0],[0]
"In this framework, adjuncts, such as adjective and adverbal phrases, are analyzed as (higher-order) functors, the function of which is to consume complex arguments (Kratzer and Heim, 1998).",1 Introduction,[0],[0]
"In the same spirit, generalized quantifiers, prepositions and function words in many languages other than English are also analyzed as higher-order functions.",1 Introduction,[0],[0]
"Accordingly, all the linguistic elements are treated as roots in type-logical semantic graphs, such as EDS and DMRS.",1 Introduction,[0],[0]
"This makes the typological structure quite flat rather than hierachical, which is an essential distinction between natural language semantics and syntax.
",1 Introduction,[0],[0]
"To the best of our knowledge, the only existing DAG transducer for NLG is the one proposed by Quernheim and Knight (2012).",1 Introduction,[0],[0]
Quernheim and Knight introduced a DAG-to-tree transducer that can be applied to AMR-to-text generation.,1 Introduction,[0],[0]
"This transducer is designed to handle hierarchical structures with limited reentrencies, and it is unsuitable for meaning graphs transformed from type-logical semantics.",1 Introduction,[0],[0]
"Furthermore, Quernheim and Knight did not describe how to acquire graph recognition and transduction rules from linguistic data, and reported no result of practical generation.",1 Introduction,[0],[0]
"It is still unknown to what extent a DAG transducer suits realistic NLG.
",1 Introduction,[0],[0]
"The design for string and tree transducers
(Comon et al., 1997) focuses on not only the logic of the computation for a new data structure, but also the corresponding control flow.",1 Introduction,[0],[0]
This is very similar the imperative programming paradigm: implementing algorithms with exact details in explicit steps.,1 Introduction,[0],[0]
"This design makes it very difficult to transform a type-logical semantic graph into a string, due to the fact their internal structures are highly diverse.",1 Introduction,[0],[0]
"We borrow ideas from declarative programming, another programming paradigm, which describes what a program must accomplish, rather than how to accomplish it.",1 Introduction,[0],[0]
We propose a novel DAG transducer to perform graphto-program transformation (§3).,1 Introduction,[0],[0]
"The input of our transducer is a semantic graph, while the output is a program licensed by a declarative programming language rather than linguistic structures.",1 Introduction,[0],[0]
"By executing such a program, we can easily get a surface string.",1 Introduction,[0],[0]
"This idea can be extended to other types of linguistic structures, e.g. syntactic trees or semantic representations of another language.
",1 Introduction,[0],[0]
"We conduct experiments on richly detailed semantic annotations licensed by English Resource Grammar (ERG; Flickinger, 2000).",1 Introduction,[0],[0]
"We introduce a principled method to derive transduction rules from DeepBank (Flickinger et al., 2012).",1 Introduction,[0],[0]
"Furthermore, we introduce a fine-to-coarse strategy to ensure that at least one sentence is generated for any input graph.",1 Introduction,[0],[0]
"Taking EDS graphs, a variable-free ERS format, as input, our NLG system achieves a BLEU-4 score of 68.07.",1 Introduction,[0],[0]
"On average, it produces more than 5 sentences in a second on an x86 64 GNU/Linux platform with two Intel Xeon E5-2620 CPUs.",1 Introduction,[0],[0]
"Since the data for experiments is newswire data, i.e. WSJ sentences from PTB (Marcus et al., 1993), the input graphs are quite large on average.",1 Introduction,[0],[0]
"The remarkable accuracy, efficiency and robustness demonstrate the feasibility of applying a DAG transducer to resolve NLG, as well as the effectiveness of our transducer design.",1 Introduction,[0],[0]
"A node-labeled simple graph over alphabet Σ is a triple G = (V,E, ℓ), where V is a finite set of nodes, E ⊆ V × V is an finite set of edges and ℓ : V → Σ is a labeling function.",2.1 Preliminaries,[0],[0]
"For a node v ∈ V , sets of its incoming and outgoing edges are denoted by in(v) and out(v) respectively.",2.1 Preliminaries,[0],[0]
"For an edge e ∈ E, its source node and target node are denoted by src(e) and tar(e) respectively.",2.1 Preliminaries,[0],[0]
"Gen-
erally speaking, a DAG is a directed acyclic simple graph.",2.1 Preliminaries,[0],[0]
"Different from trees, a DAG allows nodes to have multiple incoming edges.",2.1 Preliminaries,[0],[0]
"In this paper, we only consider DAGs that are unordered, node-labeled, multi-rooted1 and connected.
",2.1 Preliminaries,[0],[0]
"Conceptual graphs, including AMR and EDS, are both node-labeled and edge-labeled.",2.1 Preliminaries,[0],[0]
"It seems that without edge labels, a DAG is inadequate, but this problem can be solved easily by using the strategies introduced in (Chiang et al., 2018).",2.1 Preliminaries,[0],[0]
Take a labeled edge proper q BV−→ named for example2.,2.1 Preliminaries,[0],[0]
We can represent the same information by replacing it with two unlabeled edges and a new labeled node: proper q→ BV→ named.,2.1 Preliminaries,[0],[0]
"DAG automata are the core engines of graph transducers (Bohnet and Wanner, 2010; Quernheim and Knight, 2012).",2.2 Previous Work,[0],[0]
"In this work, we adopt Chiang et al. (2018)’s design and define a weighted DAG automaton as a tuple M = ⟨Σ, Q, δ,K⟩:
• Σ is an alphabet of node labels.
",2.2 Previous Work,[0],[0]
"• Q is a finite set of states.
",2.2 Previous Work,[0],[0]
"• (K,⊕,⊗, 0, 1) is a semiring of weights.
",2.2 Previous Work,[0],[0]
• δ,2.2 Previous Work,[0],[0]
:,2.2 Previous Work,[0],[0]
"Θ → K\{0} is a weight function that assigns nonzero weights to a finite transition set Θ. Every transition t ∈ Θ is of the form
{q1, · · · , qm} σ−→ {r1, · · · , rn}
where qi and rj are states in Q. A transition t getsm states on the incoming edges of a node and puts n states on the outgoing edges.",2.2 Previous Work,[0],[0]
"A transition that does not belong to Θ recieves a weight of zero.
",2.2 Previous Work,[0],[0]
"A run ofM on a DAGD = ⟨V,E, ℓ⟩ is an edge labeling function ρ :",2.2 Previous Work,[0],[0]
"E → Q. The weight of a run ρ (denoted as δ′(ρ)) is the product of all weights of local transitions:
δ′(ρ) = ⊗ v∈V δ",2.2 Previous Work,[0],[0]
"( ρ(in(v)) ℓ(v)−−→ ρ(out(v)) )
",2.2 Previous Work,[0],[0]
"Here, for a function f , we use f({a1, · · · , an}) to represent {f(a1), · · · , f(an)}.",2.2 Previous Work,[0],[0]
"If K is a boolean semiring, the automata fall backs to an unweighted
1A node without incoming edges is called root and a node without outgoing edges is called leaf.
",2.2 Previous Work,[0],[0]
"2 proper q and named are node labels, while BV is the edge label.
",2.2 Previous Work,[0],[0]
DAG automata or DAG acceptor.,2.2 Previous Work,[0],[0]
"A accepting run or recognition is a run, the weight of which is 1, meaning true.",2.2 Previous Work,[0],[0]
The DAG automata defined above can only be used for recognition.,2.3 Challenges,[0],[0]
"In order to generate sentences from semantic graphs, we need DAG transducers.",2.3 Challenges,[0],[0]
A DAG transducer is a DAG automata-augmented computation model for transducing well-formed DAGs to other data structures.,2.3 Challenges,[0],[0]
Quernheim and Knight (2012) focused on feature structures and introduced a DAG-to-Tree transducer to perform graph-to-tree transformation.,2.3 Challenges,[0],[0]
The input of their transducer is limited to single-rooted DAGs.,2.3 Challenges,[0],[0]
"When the labels of the leaves of an output tree in order are interpreted as words, this transducer can be applied to generate natural language sentences.
",2.3 Challenges,[0],[0]
"When applying Quernheim and Knight’s DAGto-Tree transducer on type-logic semantic graphs, e.g. ERS, there are some significant problems.",2.3 Challenges,[0],[0]
"First, it lacks the ability to reverse the direction of edges during transduction because it is difficult to keep acyclicy anymore if edge reversing is allowed.",2.3 Challenges,[0],[0]
"Second, it cannot handle multiple roots.",2.3 Challenges,[0],[0]
But we have discussed and reached the conclusion that multi-rootedness is a necessary requirement for representing type-logical semantic graphs.,2.3 Challenges,[0],[0]
It is difficult to decide which node should be the tree root during a ‘top-down’ transduction and it is also difficult to merge multiple unconnected nodes into one during a ‘bottom-up’ transduction.,2.3 Challenges,[0],[0]
"At the risk of oversimplifying, we argue that the function of the existing DAG-to-Tree transducer is to transform a hierachical structure into another hierarchical structure.",2.3 Challenges,[0],[0]
"Since the type-local semantic graphs are so flat, it is extremely difficult to adopt Quernheim and Knight’s design to handle such graphs.",2.3 Challenges,[0],[0]
"Third, there are unconnected nodes with direct dependencies, meaning that their correpsonding surface expressions appear to be very close.",2.3 Challenges,[0],[0]
The conceptual nodes even x deg and steep a 1 in Figure 4 are an example.,2.3 Challenges,[0],[0]
It is extremely difficult for the DAG-to-Tree transducer to handle this situation.,2.3 Challenges,[0],[0]
"In this paper, we introduce a design of transducers that can perform structure transformation towards
many data structures, including but not limited to trees.",3.1 Basic Idea,[0],[0]
"The basic idea is to give up the rewritting method to directly generate a new data structure piece by piece, while recognizing an input DAG.",3.1 Basic Idea,[0],[0]
"Instead, our transducer obtains target structures based on side effects of DAG recognition.",3.1 Basic Idea,[0],[0]
"The output of our transducer is no longer the target data structure itself, e.g. a tree or another DAG, and is now a program, i.e. a bunch of statements licensed by a particular declarative programming language.",3.1 Basic Idea,[0],[0]
"The target structures are constructed by executing such programs.
",3.1 Basic Idea,[0],[0]
"Since our main concern of this paper is natural language generation, we take strings, namely sequences of words, as our target structures.",3.1 Basic Idea,[0],[0]
"In this section, we introduce an extremely simple programming language for string concatenation and then details about how to leverage the power of declarative programming to perform DAG-tostring transformation.",3.1 Basic Idea,[0],[0]
"The syntax in the BNF format of our declarative programming language, denoted as Lc, for string calculation is:
⟨program⟩ ::= ⟨statement⟩∗ ⟨statement⟩ ::= ⟨variable⟩ = ⟨expr⟩
⟨expr⟩ ::= ⟨variable⟩",3.2 A Declarative Programming Language,[0],[0]
"| ⟨string⟩ | ⟨expr⟩ + ⟨expr⟩
Here a string is a sequence of characters selected from an alphabet (denoted as Σout) and can be empty (denoted as ϵ).",3.2 A Declarative Programming Language,[0],[0]
"The semantics of ‘=’ is value assignment, while the semantics of ‘+’ is string concatenation.",3.2 A Declarative Programming Language,[0],[0]
The value of variables are strings.,3.2 A Declarative Programming Language,[0],[0]
"For every statement, the left hand side is a variable and the right hand side is a sequence of string literals and variables that are combined through ‘+’.",3.2 A Declarative Programming Language,[0],[0]
"Equation (1) presents an exmaple program licensed by this language.
",3.2 A Declarative Programming Language,[0],[0]
"S = x21 + want+ x11
x11 = to+ go
x21 = x41 + John
x41 = ϵ
(1)
After solving these statements, we can query the values of all variables.",3.2 A Declarative Programming Language,[0],[0]
"In particular, we are interested in S, which is related to the desired natural language expression John want to go3.
3",3.2 A Declarative Programming Language,[0],[0]
The expression is a sequence of lemmas rather than inflected words.,3.2 A Declarative Programming Language,[0],[0]
"Refer to §4 for more details.
",3.2 A Declarative Programming Language,[0],[0]
"Using the relation between the variables, we can easily convert the statements in (1) to a rooted tree.",3.2 A Declarative Programming Language,[0],[0]
The result is shown in Figure 1.,3.2 A Declarative Programming Language,[0],[0]
"This tree is significantly different from the target structures discussed by Quernheim and Knight (2012) or other normal tree transducers (Comon et al., 1997).",3.2 A Declarative Programming Language,[0],[0]
This tree represents calculation to solve the program.,3.2 A Declarative Programming Language,[0],[0]
Constructing such internal trees is an essential function of the compiler of our programming language.,3.2 A Declarative Programming Language,[0],[0]
We introduce our DAG transducer using a simple example.,3.3 Informal Illustration,[0],[0]
"Figure 2 shows the original input graph D = (V,E, ℓ).",3.3 Informal Illustration,[0],[0]
"Without any loss of generality, we remove edge labels.",3.3 Informal Illustration,[0],[0]
Table 1 lists the rule set—R—for this example.,3.3 Informal Illustration,[0],[0]
Every row represents an applicable transduction rule that consists of two parts.,3.3 Informal Illustration,[0],[0]
"The left column is the recognition part displayed in the form I σ−→ O, where I , O and σ decode the state set of incoming edges, the state set of outgoing edges and the node label respectively.",3.3 Informal Illustration,[0],[0]
The right column is the generation part which consists of (multiple) templates of statements licensed by the programming language defined in the previous section.,3.3 Informal Illustration,[0],[0]
"In practice, two different rules may have a same recognition part but different generation parts.
",3.3 Informal Illustration,[0],[0]
"Every state q is of the form l(n, d) where l is the finite state label, n is the count of possible variables related to q, and d denotes the direction.",3.3 Informal Illustration,[0],[0]
"The value of d can only be r (reversed), u (unchanged) or e(empty).",3.3 Informal Illustration,[0],[0]
"Variable vl(j,d) represents the jth (1 ≤ j ≤ n) variable related to state q.",3.3 Informal Illustration,[0],[0]
"For example, vX(2,r) means the second variable of state X(3,r).",3.3 Informal Illustration,[0],[0]
"There are two special variables: S, which corresponds to the whole sentence and L, which corresponds to the output string associated to current node label.",3.3 Informal Illustration,[0],[0]
It is reasonable to assume that there exists a function ψ :,3.3 Informal Illustration,[0],[0]
"Σ → Σ∗out that maps a particular node label, i.e. concept, to a surface string.",3.3 Informal Illustration,[0],[0]
"Therefore L is determined by ψ.
",3.3 Informal Illustration,[0],[0]
"Now we are ready to apply transduction rules to
translateD into a string.",3.3 Informal Illustration,[0],[0]
"The transduction consists of two steps:
Recognition The goal of this step is to find an edge labeling function ρ : E → Q which satisfies that for every node v, ρ(in(v))
ℓ(v)−−→ ρ(out(v)) matches the recognition part of a rule in R. The recognition result is shown in Figure 3.",3.3 Informal Illustration,[0],[0]
"The red dashed edges in Figure 3 make up an intermediate graph T (ρ), which is a subgraph of D if edge direction is not taken into account.",3.3 Informal Illustration,[0],[0]
"Sometimes, T (ρ) paralles the syntactic structure of an output sentence.",3.3 Informal Illustration,[0],[0]
"For a labeling function ρ, we can construct intermediate graph T (ρ) by checking the direction parameter of every edge state.",3.3 Informal Illustration,[0],[0]
"For an edge e = (u, v) ∈ E, if the direction of ρ(e) is r, then (v, u) is in T (ρ).",3.3 Informal Illustration,[0],[0]
"If the direction is u, then (u, v) is in T (ρ).",3.3 Informal Illustration,[0],[0]
"If the direction is e, neither (u, v) nor (v, u) is included.",3.3 Informal Illustration,[0],[0]
The recognition process is slightly different from the one in Chiang et al. (2018).,3.3 Informal Illustration,[0],[0]
"Since incoming edges with an Empty(0,e) state carry no semantic information, they will be ignored during recognition.",3.3 Informal Illustration,[0],[0]
"For example, in Figure 3, we will only use e2 and e4 to match transducation rules for node named(John).
",3.3 Informal Illustration,[0],[0]
Instantiation We use rule(v) to denotes the rule used on node v. Assume s is the generation part of rule(v).,3.3 Informal Illustration,[0],[0]
"For every edge ei adjacent to v, assume ρ(ei) = l(n, d).",3.3 Informal Illustration,[0],[0]
"We replace L with ψ(ℓ(v)) and replace every occurrence of vl(j,d) in s with a new variable xij (1 ≤ j ≤ n).",3.3 Informal Illustration,[0],[0]
"Then we
get a newly generated expression for v. For example, node want v 1 is recognized using Rule 2, so we replace vNP(1,u) with x21, vVP(1,u) with x11 and L with want.",3.3 Informal Illustration,[0],[0]
"After instantiation, we get all the statements in Equation (1).
",3.3 Informal Illustration,[0],[0]
Our transducer is suitable for type-logical semantic graphs.,3.3 Informal Illustration,[0],[0]
Because declarative programming brings in more freedom for graph transduction.,3.3 Informal Illustration,[0],[0]
We can arrange the variables in almost any order without regard to the edge directions in original graphs.,3.3 Informal Illustration,[0],[0]
"Meanwhile, the multi-rooted problem can be solved easily because the generation is based on side effects.",3.3 Informal Illustration,[0],[0]
We do not need to decide which node is the tree root.,3.3 Informal Illustration,[0],[0]
"The formal definition of our DAG transducer described above is a tuple M = (Σ, Q,R,w, V, S) where:
• Σ is an alphabet of node labels.
",3.4 Definition,[0],[0]
• Q is a finite set of edge states.,3.4 Definition,[0],[0]
"Every state q ∈ Q is of the form l(n, d) where l is the state label, n is the variable count and d is the direction of state which can be r, u or e.
• R is a finite set of rules.",3.4 Definition,[0],[0]
"Every rule is of the form I σ−→ ⟨O,E⟩. E can be any kind of statement in a declarative programming language.",3.4 Definition,[0],[0]
It is called the generation part.,3.4 Definition,[0],[0]
"I , σ and O have the same meanings as they do in the previous section and they are called the recognition part.
",3.4 Definition,[0],[0]
• w is a score function.,3.4 Definition,[0],[0]
"Given a particular run and an anchor node,w assigns a score to measure the preference for a particular rule at this anchor node.
",3.4 Definition,[0],[0]
"• V is the set of parameterized variables that can be used in every expression.
",3.4 Definition,[0],[0]
"• S ∈ V is a distinguished, global variable.",3.4 Definition,[0],[0]
It is like the ‘goal’ of a program.,3.4 Definition,[0],[0]
Different languages exhibit different morphosyntactic and syntactico-semantic properties.,4 DAG Transduction-based NLG,[0],[0]
"For example, Russian and Arabic are morphologically-rich languages and heavily utilize grammatical markers to indicate grammatical as well as semantic functions.",4 DAG Transduction-based NLG,[0],[0]
"On the contrary, Chinese, as an analytic language, encodes grammatical and semantic information in a highly configurational rather than either inflectional or derivational way.",4 DAG Transduction-based NLG,[0],[0]
Such differences affects NLG significantly.,4 DAG Transduction-based NLG,[0],[0]
"Considering generating Chinese sentences, it seems sufficient to employ our DAG transducer to obtain a sequence of lemmas, since no morpholical production is needed.",4 DAG Transduction-based NLG,[0],[0]
"But for morphologically-rich languages, we do need to model complex morphological changes.
",4 DAG Transduction-based NLG,[0],[0]
"To unify a general framework for DAG transduction-based NLG, we propose a two-step strategy to achive meaning-to-text transformation.
",4 DAG Transduction-based NLG,[0],[0]
"• In the first phase, we are concerned with syntactico-semantic properties and utilize our DAG transducer to translate a semantic graph into sequential lemmas.",4 DAG Transduction-based NLG,[0],[0]
"Information such as tense, apsects, gender, etc. is attached to anchor lemmas.",4 DAG Transduction-based NLG,[0],[0]
"Actually, our transducer generates “want.",4 DAG Transduction-based NLG,[0],[0]
PRES” rather than “wants”.,4 DAG Transduction-based NLG,[0],[0]
"Here, “PRES” indicates a particular tense.
",4 DAG Transduction-based NLG,[0],[0]
"• In the second phase, we are concerned with morpho-syntactic properties and utilize a neural sequence-to-sequence model to obtain final surface strings from the outputs of the DAG transducer.",4 DAG Transduction-based NLG,[0],[0]
We present an empirical study on the feasibility of DAG transduction-based NLG.,5 Inducing Transduction Rules,[0],[0]
"We focus on
variable-free MRS representations, namely EDS (Oepen and Lønning, 2006).",5 Inducing Transduction Rules,[0],[0]
"The data set used in this work is DeepBank 1.1 (Flickinger et al., 2012).",5 Inducing Transduction Rules,[0],[0]
"In order to generate reasonable strings, three constraints must be kept during transduction.",5.1 EDS-specific Constraints,[0],[0]
"First, for a rule I σ−→ ⟨O,E⟩, a state with direction u in I or a state with direction r in O is called head state and its variables are called head variables.",5.1 EDS-specific Constraints,[0],[0]
"For example, the head state of rule 3 in Table 1 is VP(1,u) and the head state of rule 2 is DET(1,r).",5.1 EDS-specific Constraints,[0],[0]
There is at most one head state in a rule and only head variables or S can be the left sides of statements.,5.1 EDS-specific Constraints,[0],[0]
"If there is no head state, we assign the global S as its head.",5.1 EDS-specific Constraints,[0],[0]
"Otherwise, the number of statements is equal to the number of head variables and each statement has a distinguished left side variable.",5.1 EDS-specific Constraints,[0],[0]
An empty state does not have any variables.,5.1 EDS-specific Constraints,[0],[0]
"Second, every rule has no-copying, no-deleting statements.",5.1 EDS-specific Constraints,[0],[0]
"In other words, all variables must be used exactly once in a statement.",5.1 EDS-specific Constraints,[0],[0]
"Third, during recognition, a labeling function ρ is valid only if T (ρ) is a rooted tree.
",5.1 EDS-specific Constraints,[0],[0]
"After transduction, we get result ρ∗.",5.1 EDS-specific Constraints,[0],[0]
"The first and second constraints ensure that for all nodes, there is at most one incoming red dashed edge in T (ρ∗) and ‘data’ carried by variables of the only incoming red dashed edge or S is separated into variables of outgoing red dashed edges.",5.1 EDS-specific Constraints,[0],[0]
The last constraint ensures that we can solve all statements by a bottom-up process on tree T (ρ∗).,5.1 EDS-specific Constraints,[0],[0]
"Almost all NLG systems that heavily utilize a symbolic system to encode deep syntacticosemantic information lack some robustness, meaning that some input graphs may not be successfully processed.",5.2 Fine-to-Coarse Transduction,[0],[0]
There are two reasons: (1) some explicit linguistic constraints are not included; (2) exact decoding is too time-consuming while inexact decoding cannot cover the whole search space.,5.2 Fine-to-Coarse Transduction,[0],[0]
"To solve the robustness problem, we introduce a fine-to-coarse strategy to ensure that at least one sentence is generated for any input graph.",5.2 Fine-to-Coarse Transduction,[0],[0]
"There are three types of rules in our system, namely induced rules, extended rules and dynamic rules.",5.2 Fine-to-Coarse Transduction,[0],[0]
"The most fine-grained rules are applied to bring us precision, while the most coarse-grained rules are for robustness.
",5.2 Fine-to-Coarse Transduction,[0],[0]
"In order to extract reasonable rules, we will use both EDS graphs and the corresponding derivation trees provided by ERG.",5.2 Fine-to-Coarse Transduction,[0],[0]
The details will be described step-by-step in the following sections.,5.2 Fine-to-Coarse Transduction,[0],[0]
Figure 4 shows an example for obtaining induced rules.,5.3 Induced Rules,[0],[0]
"The induced rules are directly obtained by following three steps:
Finding intermediate tree T EDS graphs are highly regular semantic graphs.",5.3 Induced Rules,[0],[0]
It is not difficult to generate T based on a highly customized ‘breadthfirst’ search.,5.3 Induced Rules,[0],[0]
The generation starts from the ‘top’ node ( say v to in Figure 4) given by the EDS graph and traverse the whole graph.,5.3 Induced Rules,[0],[0]
"No more than thirty heuristic rules are used to decide the visiting order of nodes.
",5.3 Induced Rules,[0],[0]
Assigning states EDS graphs also provide span information for nodes.,5.3 Induced Rules,[0],[0]
We select a group of lexical nodes which have corresponding substrings in the original sentence.,5.3 Induced Rules,[0],[0]
"In Figure 4, these nodes are in bold font and directly followed by a span.",5.3 Induced Rules,[0],[0]
Then we merge spans from the bottom of T to the top to assign each red edge a span list.,5.3 Induced Rules,[0],[0]
"For each node n in T , we collect spans of every outgoing dashed edge of n into a list s.",5.3 Induced Rules,[0],[0]
"Some additional spans may be inserted into s. These spans do not occur in the EDS graph but they do occur in the sentence, i.e. than<29:33>.",5.3 Induced Rules,[0],[0]
Then we merge continuous spans in s and assign the remaining spans in s to the incoming red dashed edge of n. We apply a similar method to the derivation tree.,5.3 Induced Rules,[0],[0]
"As a result, every inner node of the derivation tree is associated with a span.",5.3 Induced Rules,[0],[0]
Then we align the edges in T to nodes of the inner derivation tree by comparing their spans.,5.3 Induced Rules,[0],[0]
"Finally edge labels in Figure 4 are generated.
",5.3 Induced Rules,[0],[0]
We use the concatenation of the edge labels in a span list as the state label.,5.3 Induced Rules,[0],[0]
The edge labels are joined in order with ‘ ’.,5.3 Induced Rules,[0],[0]
"Empty(0,e) is the state of the edges that do not belong to T (ignoring direction), such as e12.",5.3 Induced Rules,[0],[0]
The variable count of a state is equal to the size of the span list and the direction of a state is decided by whether the edge in T related to the state and its corresponding edge in D have different directions.,5.3 Induced Rules,[0],[0]
"For example, the state of e5 should be ADV PP(2,r).
",5.3 Induced Rules,[0],[0]
"Generating statements After the above two steps, we are ready to generate statements according to how spans are merged.",5.3 Induced Rules,[0],[0]
"For all nodes, spans of the incoming edges represent the left hand side and the outgoing edges represent the right hand side.",5.3 Induced Rules,[0],[0]
"For example, the rule for node comp will be:
{ADV(1,r)} comp−−−→",5.3 Induced Rules,[0],[0]
"{PP(1,u),",5.3 Induced Rules,[0],[0]
"ADV PP(2,r)}
vADV PP(1,r) = vADV(1,r)
vADV PP(2,r) =",5.3 Induced Rules,[0],[0]
"than+ vPP(1,u)",5.3 Induced Rules,[0],[0]
Extended rules are used when no induced rules can cover a given node.,5.4 Extended Rules,[0],[0]
"In theory, there can be unlimited modifier nodes pointing to a given node, such as PP and ADJ.",5.4 Extended Rules,[0],[0]
We use some manually written rules to slightly change an induced rule (prototype) by addition or deletion to generate a group of extended rules.,5.4 Extended Rules,[0],[0]
"The motivation here is to deal with the data sparseness problem.
",5.4 Extended Rules,[0],[0]
"For a group of selected non-head states in I , such as PP and ADJ.",5.4 Extended Rules,[0],[0]
We can produce new rules by removing or duplicating more of them.,5.4 Extended Rules,[0],[0]
"For example:
{NP(1,u),ADJ(1,r)} X n 1−−−−→ {} vNP(1,u) = vADJ(1,r)",5.4 Extended Rules,[0],[0]
+,5.4 Extended Rules,[0],[0]
"L
As a result, we get the two rules below:
{NP(1,u)} X n 1−−−−→ {} vNP(1,u) =",5.4 Extended Rules,[0],[0]
"L
{NP(1,u),ADJ(1,r)1,
ADJ(1,r)2} X n 1−−−−→ {}
vNP(1,u) = vADJ(1,r)1 + vADJ(1,r)2 + L",5.4 Extended Rules,[0],[0]
"During decoding, when neither induced nor extended rule is applicable, we create a dynamic rule on-the-fly.",5.5 Dynamic Rules,[0],[0]
"Our rule creator builds a new rule following the Markov assumption:
P (O|C) = P (q1|C) n∏
i=2
P (qi|C)P (qi|qi−1, C)
C = ⟨I,D⟩ represents the context.",5.5 Dynamic Rules,[0],[0]
"O = {q1, · · · , qn} denotes the outgoing states and I , D have the same meaning as before.",5.5 Dynamic Rules,[0],[0]
"Though they are unordered multisets, we can give them an explicit alphabet order by their edge labels.",5.5 Dynamic Rules,[0],[0]
There is also a group of hard constraints to make sure that the predicted rules are well-formed as the definition in §5 requires.,5.5 Dynamic Rules,[0],[0]
"This Markovization strategy is widely utilized by lexicalized and unlexicalized PCFG parsers (Collins, 1997; Klein and Manning, 2003).",5.5 Dynamic Rules,[0],[0]
"For a dynamic rule, all variables in this rule will appear in the statement.",5.5 Dynamic Rules,[0],[0]
We use a simple perceptron-based scorer to assign every variable a score and arrange them in an decreasing order.,5.5 Dynamic Rules,[0],[0]
"We use DeepBank 1.1 (Flickinger et al., 2012), i.e. gold-standard ERS annotations, as our main experimental data set to train a DAG transducer as well as a sequence-to-sequence morpholyzer, and wikiwoods (Flickinger et al., 2010), i.e. automatically-generated ERS annotations by ERG, as additional data set to enhance the sequence-to-sequence morpholyzer.",6.1 Set-up,[0],[0]
"The training,
development and test data sets are from DeepBank and split according to DeepBank’s recommendation.",6.1 Set-up,[0],[0]
"There are 34,505, 1,758 and 1,444 sentences (all disconnected graphs as well as their associated sentences are removed) in the training, development and test data sets.",6.1 Set-up,[0],[0]
"We use a small portion of wikiwoods data, c.a. 300K sentences, for experiments.
37,537 induced rules are directly extracted from the training data set, and 447,602 extended rules are obtained.",6.1 Set-up,[0],[0]
"For DAG recognition, at one particular position, there may be more than one rule applicable.",6.1 Set-up,[0],[0]
"In this case, we need a disambiguation model as well as a decoder to search for a globally optimal solution.",6.1 Set-up,[0],[0]
"In this work, we train a structured perceptron model (Collins, 2002) for disambiguation and employ a beam decoder.",6.1 Set-up,[0],[0]
The perceptron model used by our dynamic rule generator are trained with the induced rules.,6.1 Set-up,[0],[0]
"To get a sequence-to-sequence model, we use the open source tool—OpenNMT4.",6.1 Set-up,[0],[0]
We implement a fine-to-coarse beam search decoder.,6.2 The Decoder,[0],[0]
"Given a DAG D, our goal is to find the highest scored labeling function ρ:
ρ =",6.2 The Decoder,[0],[0]
"argmax ρ n∏ i=1 ∑ j wj · fj(rule(vi), D)
s.t. rule(vi) = ρ(in(vi))",6.2 The Decoder,[0],[0]
"ℓ(vi)−−−→ ⟨ρ(out(vi)), Ei⟩
where n is the node count and fj(·, ·) and wj represent a feature and the corresponding weight, respectively.",6.2 The Decoder,[0],[0]
The features are chosen from the context of the given node vi.,6.2 The Decoder,[0],[0]
We perform ‘topdown’ search to translate an input DAG into a morphology-function-enhanced lemma sequence.,6.2 The Decoder,[0],[0]
"Each hypothesis consists of the current DAG graph, the partial labeling function, the current hypothesis score and other graph information used to perform rule selection.",6.2 The Decoder,[0],[0]
The decoder will keep the corresponding partial intermediate graph T acyclic when decoding.,6.2 The Decoder,[0],[0]
The algorithm used by our decoder is displayed in Algorithm 1.,6.2 The Decoder,[0],[0]
"Function FindRules(h, n,R) will use hard constraints to select rules from the rule set R according to the contextual information.",6.2 The Decoder,[0],[0]
It will also perform an acyclic check on T .,6.2 The Decoder,[0],[0]
"Function Insert(h, r, n,B) will create and score a new hypothesis made from the given context and then insert it into beam B.
4https://github.com/OpenNMT/OpenNMT/
After we get the edge labeling function ρ, we use a simple linear equation solver to convert all statements to a sequence of lemmas.
",6.2 The Decoder,[0],[0]
Algorithm 1: Algorithm for our decoder.,6.2 The Decoder,[0],[0]
Input: D is the EDS graph.,6.2 The Decoder,[0],[0]
"RI and RE
are induced-rules and extended-rules respectively.
",6.2 The Decoder,[0],[0]
Result: The edge labeling function ρ.,6.2 The Decoder,[0],[0]
1 Q← all the roots in D 2 B1← empty beam 3 E ← ∅ 4 Insert initial hypothesis into B1 5 while Q is not empty: 6 B2← empty beam 7 n←,6.2 The Decoder,[0],[0]
"dequeue a node from Q 8 for h ∈ B1: 9 rules← FindRules(h, n,RI)
10 if rules is not empty: 11 for r ∈ rules: 12 Insert(h, r, n,B2) else: 13 rules← FindRules(h, n,RE) 14 for r ∈ rules: 15 Insert(h, r, n,B2) 16 if B2 is still empty: 17 for h ∈ B1: 18 r ← RuleGenerator(h, n) 19 Insert(h, r, n,B2) 20 B1← B2 21 for e ∈ out(n): 22 E ← E ∪ {e} 23 if in(tar(e))",6.2 The Decoder,[0],[0]
⊆ E: 24 Q← Q ∪ {tar(e)} 25 Extract ρ from best hypothesis in B1,6.2 The Decoder,[0],[0]
"In order to evaluate the effectiveness of our transducer for NLG, we try a group of tests showed in Table 2.",6.3 Accuracy,[0],[0]
All sequence-to-sequence models (either from lemma sequences to lemma sequences or lemma sequences to sentences) are trained on DeepBank and wikiwoods data set and tuned on the development data.,6.3 Accuracy,[0],[0]
The second column shows the BLEU-4 scores between generated lemma sequences and golden sequences of lemmas.,6.3 Accuracy,[0],[0]
The third column shows the BLEU-4 scores between generated sentences and golden sentences.,6.3 Accuracy,[0],[0]
"The fourth column shows the fraction of graphs in the test data set that can reach output sentences.
",6.3 Accuracy,[0],[0]
"The graphs that cannot received any natural language sentences are removed while conducting the BLEU evaluation.
",6.3 Accuracy,[0],[0]
"As we can conclude from Table 2, using only induced rules achieves the highest accuracy but the coverage is not satisfactory.",6.3 Accuracy,[0],[0]
Extended rules lead to a slight accuracy drop but with a great improvement of coverage (c.a. 10%).,6.3 Accuracy,[0],[0]
"Using dynamic rules, we observe a significant accuracy drop.",6.3 Accuracy,[0],[0]
"Nevertheless, we are able to handle all EDS graphs.",6.3 Accuracy,[0],[0]
The full-coverage robustness may benefit many NLP applications.,6.3 Accuracy,[0],[0]
The lemma sequences generated by our transducer are really close to the golden one.,6.3 Accuracy,[0],[0]
"This means that our model actually works and most reordering patterns are handled well by induced rules.
",6.3 Accuracy,[0],[0]
"Compared to the AMR generation task, our transducer on EDS graphs achieves much higher accuracies.",6.3 Accuracy,[0],[0]
"To make clear how much improvement is from the data and how much is from our DAG transducer, we implement a purely neural baseline.",6.3 Accuracy,[0],[0]
The baseline converts a DAG into a concept sequence by a pre-order DFS traversal on the intermediate tree of this DAG.,6.3 Accuracy,[0],[0]
Then we use a sequenceto-sequence model to transform this concept sequence to the lemma sequence for comparison.,6.3 Accuracy,[0],[0]
This is a kind of implementation of Konstas et al.’s model but evaluated on the EDS data.,6.3 Accuracy,[0],[0]
"We can see that on this task, our transducer is much better than a pure sequence-to-sequence model on DeepBank data.",6.3 Accuracy,[0],[0]
Table 3 shows the efficiency of the beam search decoder with a beam size of 128.,6.4 Efficiency,[0],[0]
The platform for this experiment is x86 64 GNU/Linux with two Intel Xeon E5-2620 CPUs.,6.4 Efficiency,[0],[0]
The second and third columns represent the average and the maximal time (in seconds) to translate an EDS graph.,6.4 Efficiency,[0],[0]
Using dynamic rules slow down the decoder to a great degree.,6.4 Efficiency,[0],[0]
"Since the data for experiments is newswire data, i.e. WSJ sentences from PTB (Marcus et al., 1993), the input graphs are quite large on average.",6.4 Efficiency,[0],[0]
"On average, it produces more than 5 sentences per second on CPU.",6.4 Efficiency,[0],[0]
We consider this a promising speed.,6.4 Efficiency,[0],[0]
We extend the work on DAG automata in Chiang et al. (2018) and propose a general method to build flexible DAG transducer.,7 Conclusion,[0],[0]
The key idea is to leverage a declarative programming language to minimize the computation burden of a graph transducer.,7 Conclusion,[0],[0]
We think may NLP tasks that involve graph manipulation may benefit from this design.,7 Conclusion,[0],[0]
"To exemplify our design, we develop a practical system for the semantic-graph-to-string task.",7 Conclusion,[0],[0]
"Our system is accurate (BLEU 68.07), efficient (more than 5 sentences per second on a CPU) and robust (fullcoverage).",7 Conclusion,[0],[0]
"The empirical evaluation confirms the usefulness a DAG transducer to resolve NLG, as well as the effectiveness of our design.",7 Conclusion,[0],[0]
"This work was supported by the National Natural Science Foundation of China (61772036, 61331011) and the Key Laboratory of Science, Technology and Standard in Press Industry (Key Laboratory of Intelligent Press Media Technology).",Acknowledgments,[0],[0]
We thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
Weiwei Sun is the corresponding author.,Acknowledgments,[0],[0]
A DAG automaton is a formal device for manipulating graphs.,abstractText,[0],[0]
"By augmenting a DAG automaton with transduction rules, a DAG transducer has potential applications in fundamental NLP tasks.",abstractText,[0],[0]
"In this paper, we propose a novel DAG transducer to perform graph-to-program transformation.",abstractText,[0],[0]
The target structure of our transducer is a program licensed by a declarative programming language rather than linguistic structures.,abstractText,[0],[0]
"By executing such a program, we can easily get a surface string.",abstractText,[0],[0]
Our transducer is designed especially for natural language generation (NLG) from type-logical semantic graphs.,abstractText,[0],[0]
"Taking Elementary Dependency Structures, a format of English Resource Semantics, as input, our NLG system achieves a BLEU-4 score of 68.07.",abstractText,[0],[0]
"This remarkable result demonstrates the feasibility of applying a DAG transducer to resolve NLG, as well as the effectiveness of our design.",abstractText,[0],[0]
Language Generation via DAG Transduction,title,[0],[0]
"Statistical language models estimate the probability distribution of a sequence of words by modeling the probability of the next word given preceding words, i.e.
P (w0, . . .",1. Introduction,[0],[0]
", wN ) =",1. Introduction,[0],[0]
P (w0) N∏ i=1,1. Introduction,[0],[0]
"P (wi|w0, . . .",1. Introduction,[0],[0]
", wi−1),
where wi are discrete word indices in a vocabulary.",1. Introduction,[0],[0]
"Language models are a critical part of systems for speech recognition (Yu & Deng, 2014) and machine translation (Koehn, 2010).
",1. Introduction,[0],[0]
"Recently, neural networks (Bengio et al., 2003; Mikolov et al., 2010; Jozefowicz et al., 2016) have been shown to
1Facebook AI Research.",1. Introduction,[0],[0]
"Correspondence to: Yann N. Dauphin <ynd@fb.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
outperform classical n-gram language models (Kneser & Ney, 1995; Chen & Goodman, 1996).",1. Introduction,[0],[0]
"These classical models suffer from data sparsity, which makes it difficult to represent large contexts and thus, long-range dependencies.",1. Introduction,[0],[0]
Neural language models tackle this issue by embedding words in continuous space over which a neural network is applied.,1. Introduction,[0],[0]
"The current state of the art for language modeling is based on long short term memory networks (LSTM; Hochreiter et al., 1997) which can theoretically model arbitrarily long dependencies.
",1. Introduction,[0],[0]
"In this paper, we introduce new gated convolutional networks and apply them to language modeling.",1. Introduction,[0],[0]
"Convolutional networks can be stacked to represent large context sizes and extract hierarchical features over larger and larger contexts with more abstractive features (LeCun & Bengio, 1995).",1. Introduction,[0],[0]
This allows them to model long-term dependencies by applyingO(Nk ) operations over a context of size N and kernel width k.,1. Introduction,[0],[0]
"In contrast, recurrent networks view the input as a chain structure and therefore require a linear number O(N) of operations.
",1. Introduction,[0],[0]
"Analyzing the input hierarchically bears resemblance to classical grammar formalisms which build syntactic tree structures of increasing granuality, e.g., sentences consist of noun phrases and verb phrases each comprising further internal structure (Manning & Schütze, 1999; Steedman, 2002).",1. Introduction,[0],[0]
"Hierarchical structure also eases learning since the number of non-linearities for a given context size is reduced compared to a chain structure, thereby mitigating the vanishing gradient problem (Glorot & Bengio, 2010).
",1. Introduction,[0],[0]
Modern hardware is well suited to models that are highly parallelizable.,1. Introduction,[0],[0]
"In recurrent networks, the next output depends on the previous hidden state which does not enable parallelization over the elements of a sequence.",1. Introduction,[0],[0]
"Convolutional networks, however, are very amenable to this computing paradigm since the computation of all input words can be performed simultaneously (§2).
",1. Introduction,[0],[0]
"Gating has been shown to be essential for recurrent neural networks to reach state-of-the-art performance (Jozefowicz et al., 2016).",1. Introduction,[0],[0]
"Our gated linear units reduce the vanishing gradient problem for deep architectures by providing a linear path for the gradients while retaining non-linear capabilities (§5.2).
",1. Introduction,[0],[0]
"We show that gated convolutional networks outperform other recently published language models such as LSTMs trained in a similar setting on the Google Billion Word Benchmark (Chelba et al., 2013).",1. Introduction,[0],[0]
"We also evaluate the ability of our models to deal with long-range dependencies on the WikiText-103 benchmark for which the model is conditioned on an entire paragraph rather than a single sentence and we achieve a new state-of-the-art on this dataset (Merity et al., 2016).",1. Introduction,[0],[0]
"Finally, we show that gated linear units achieve higher accuracy and converge faster than the LSTM-style gating of Oord et al. (2016; §4, §5).",1. Introduction,[0],[0]
In this paper we introduce a new neural language model that replaces the recurrent connections typically used in recurrent networks with gated temporal convolutions.,2. Approach,[0],[0]
"Neural language models (Bengio et al., 2003) produce a representation H =",2. Approach,[0],[0]
"[h0, . . .",2. Approach,[0],[0]
",hN ] of the context for each word w0, . . .",2. Approach,[0],[0]
", wN to predict the next word P (wi|hi).",2. Approach,[0],[0]
"Recurrent neural networks f compute H through a recurrent function hi = f(hi−1, wi−1) which is an inherently sequential process that cannot be parallelized over i.1
Our proposed approach convolves the inputs with a function f to obtain H = f ∗ w and therefore has no temporal dependencies, so it is easier to parallelize over the individual words of a sentence.",2. Approach,[0],[0]
This process will compute each context as a function of a number of preceding words.,2. Approach,[0],[0]
"Compared to recurrent networks, the context size is finite but we will demonstrate both that infinite contexts are not necessary and our models can represent large enough contexts to perform well in practice (§5).
",2. Approach,[0],[0]
Figure 1 illustrates the model architecture.,2. Approach,[0],[0]
Words are represented by a vector embedding stored in a lookup table D|V|×e where |V| is the number of words in the vocabulary and e is the embedding size.,2. Approach,[0],[0]
"The input to our model is a sequence of words w0, . . .",2. Approach,[0],[0]
", wN which are represented by word embeddings E =",2. Approach,[0],[0]
"[Dw0 , . . .",2. Approach,[0],[0]
",DwN ].",2. Approach,[0],[0]
"We compute the hidden layers h0, . . .",2. Approach,[0],[0]
", hL as
hl(X) =",2. Approach,[0],[0]
"(X ∗W + b)⊗ σ(X ∗V + c) (1)
wherem,n are respectively the number of input and output feature maps and k is the patch size, X ∈ RN×m is the input of layer hl (either word embeddings or the outputs of previous layers), W ∈ Rk×m×n, b ∈ Rn, V ∈ Rk×m×n, c ∈",2. Approach,[0],[0]
"Rn are learned parameters, σ is the sigmoid function and ⊗ is the element-wise product between matrices.
",2. Approach,[0],[0]
"When convolving inputs, we take care that hi does not contain information from future words.",2. Approach,[0],[0]
"We address this by shifting the convolutional inputs to prevent the kernels
1Parallelization is usually done over multiple sequences instead.
from seeing future context (Oord et al., 2016a).",2. Approach,[0],[0]
"Specifically, we zero-pad the beginning of the sequence with k−1 elements, assuming the first input element is the beginning of sequence marker which we do not predict and k is the width of the kernel.
",2. Approach,[0],[0]
The output of each layer is a linear projection X ∗W + b modulated by the gates σ(X ∗V + c).,2. Approach,[0],[0]
"Similar to LSTMs, these gates multiply each element of the matrix X∗W+b and control the information passed on in the hierarchy.",2. Approach,[0],[0]
We dub this gating mechanism Gated Linear Units (GLU).,2. Approach,[0],[0]
Stacking multiple layers on top of the input E gives a representation of the context for each word H = hL◦. .,2. Approach,[0],[0]
.◦,2. Approach,[0],[0]
h0(E).,2. Approach,[0],[0]
"We wrap the convolution and the gated linear unit in a preactivation residual block that adds the input of the block to
the output (He et al., 2015a).",2. Approach,[0],[0]
"The blocks have a bottleneck structure for computational efficiency and each block has up to 5 layers.
",2. Approach,[0],[0]
"The simplest choice to obtain model predictions is to use a softmax layer, but this choice is often computationally inefficient for large vocabularies and approximations such as noise contrastive estimation (Gutmann & Hyvärinen) or hierarchical softmax (Morin & Bengio, 2005) are preferred.",2. Approach,[0],[0]
"We choose an improvement of the latter known as adaptive softmax which assigns higher capacity to very frequent words and lower capacity to rare words (Grave et al., 2016a).",2. Approach,[0],[0]
This results in lower memory requirements as well as faster computation at both training and test time.,2. Approach,[0],[0]
"Gating mechanisms control the path through which information flows in the network and have proven to be useful for recurrent neural networks (Hochreiter & Schmidhuber, 1997).",3. Gating Mechanisms,[0],[0]
LSTMs enable long-term memory via a separate cell controlled by input and forget gates.,3. Gating Mechanisms,[0],[0]
This allows information to flow unimpeded through potentially many timesteps.,3. Gating Mechanisms,[0],[0]
"Without these gates, information could easily vanish through the transformations of each timestep.",3. Gating Mechanisms,[0],[0]
"In contrast, convolutional networks do not suffer from the same kind of vanishing gradient and we find experimentally that they do not require forget gates.
",3. Gating Mechanisms,[0],[0]
"Therefore, we consider models possessing solely output gates, which allow the network to control what information should be propagated through the hierarchy of layers.",3. Gating Mechanisms,[0],[0]
We show this mechanism to be useful for language modeling as it allows the model to select which words or features are relevant for predicting the next word.,3. Gating Mechanisms,[0],[0]
"Parallel to our work, Oord et al. (2016b) have shown the effectiveness of an LSTM-style mechanism of the form tanh(X∗W+b)⊗σ(X∗V+c) for the convolutional modeling of images.",3. Gating Mechanisms,[0],[0]
"Later, Kalchbrenner et al. (2016) extended this mechanism with additional gates for use in translation and character-level language modeling.
",3. Gating Mechanisms,[0],[0]
Gated linear units are a simplified gating mechanism based on the work of Dauphin & Grangier (2015) for nondeterministic gates that reduce the vanishing gradient problem by having linear units coupled to the gates.,3. Gating Mechanisms,[0],[0]
This retains the non-linear capabilities of the layer while allowing the gradient to propagate through the linear unit without scaling.,3. Gating Mechanisms,[0],[0]
"The gradient of the LSTM-style gating of which we dub gated tanh unit (GTU) is
∇[tanh(X)⊗ σ(X)]",3. Gating Mechanisms,[0],[0]
= tanh′(X)∇X⊗ σ(X) +σ′(X)∇X⊗ tanh(X).,3. Gating Mechanisms,[0],[0]
"(2)
Notice that it gradually vanishes as we stack layers because of the downscaling factors tanh′(X) and σ′(X).",3. Gating Mechanisms,[0],[0]
"In con-
trast, the gradient of the gated linear unit
∇[X⊗ σ(X)] = ∇X⊗ σ(X) + X⊗",3. Gating Mechanisms,[0],[0]
"σ′(X)∇X (3)
has a path ∇X ⊗ σ(X) without downscaling for the activated gating units in σ(X).",3. Gating Mechanisms,[0],[0]
This can be thought of as a multiplicative skip connection which helps gradients flow through the layers.,3. Gating Mechanisms,[0],[0]
We compare the different gating schemes experimentally in Section §5.2 and we find gated linear units allow for faster convergence to better perplexities.,3. Gating Mechanisms,[0],[0]
We report results on two public large-scale language modeling datasets.,4.1. Datasets,[0],[0]
"First, the Google Billion Word dataset (Chelba et al., 2013) is considered one of the largest language modeling datasets with almost one billion tokens and a vocabulary of over 800K words.",4.1. Datasets,[0],[0]
"In this dataset, words appearing less than 3 times are replaced with a special unknown symbol.",4.1. Datasets,[0],[0]
"The data is based on an English corpus of 30, 301, 028 sentences whose order has been shuffled.",4.1. Datasets,[0],[0]
"Second, WikiText-103 is a smaller dataset of over 100M tokens with a vocabulary of about 200K words (Merity et al., 2016).",4.1. Datasets,[0],[0]
"Different from GBW, the sentences are consecutive which allows models to condition on larger contexts rather than single sentences.",4.1. Datasets,[0],[0]
"For both datasets, we add a beginning of sequence marker <S > at the start of each line and an end of sequence marker </S> at the end of each line.",4.1. Datasets,[0],[0]
"On the Google Billion Word corpus each sequence is a single sentence, while on WikiText-103 a sequence is an entire paragraph.",4.1. Datasets,[0],[0]
The model sees <S> and </S >,4.1. Datasets,[0],[0]
as input but only predicts the end of sequence marker </S>.,4.1. Datasets,[0],[0]
We evaluate models by computing the perplexity e 1 N ∑N i,4.1. Datasets,[0],[0]
"− log p(wi|...,wi−1) on the standard held out test portion of each dataset.",4.1. Datasets,[0],[0]
"We implement our models in Torch (Collobert et al., 2011) and train on Tesla M40 GPUs.",4.2. Training,[0],[0]
"The majority of our models are trained on single GPU, as we focused on identifying compact architectures with good generalization and efficient computation at test time.",4.2. Training,[0],[0]
We trained larger models with an 8-GPU setup by copying the model onto each GPU and dividing the batch such that each worker computes 1/8th of the gradients.,4.2. Training,[0],[0]
The gradients are then summed using Nvidia NCCL.,4.2. Training,[0],[0]
"The multi-GPU setup allowed us to train models with larger hidden units.
",4.2. Training,[0],[0]
"We train using Nesterov’s momentum (Sutskever et al., 2013).",4.2. Training,[0],[0]
"While the cost in terms of memory is storing another vector of the size of the parameters, it increases the speed of convergence significantly with minimal additional
computation compared to standard stochastic gradient descent.",4.2. Training,[0],[0]
"The speed of convergence was further increased with gradient clipping (Pascanu et al., 2013) and weight normalization (Salimans & Kingma, 2016).
",4.2. Training,[0],[0]
Pascanu et al. (2013) argue for gradient clipping because it prevents the gradient explosion problem that characterizes RNNs.,4.2. Training,[0],[0]
"However, gradient clipping is not tied to RNNs, as it can be derived from the general concept of trust region methods.",4.2. Training,[0],[0]
"Gradient clipping is found using a spherical trust region
∆θ∗ = argmin s. t. ‖∆θ‖≤ f(θ) +∇fT∆θ
= −max(‖∇f‖, ) ∇f ‖∇f‖ .",4.2. Training,[0],[0]
"(4)
Empirically, our experiments converge significantly faster with the use of gradient clipping even though we do not use a recurrent architecture.
",4.2. Training,[0],[0]
"In combination, these methods led to stable and fast convergence with comparatively large learning rates such as 1.",4.2. Training,[0],[0]
We found good hyper-parameter configurations by crossvalidating with random search on a validation set.,4.3. Hyper-parameters,[0],[0]
"For model architecture, we select the number of residual blocks between {1, . . .",4.3. Hyper-parameters,[0],[0]
", 10}, the size of the embeddings with {128, . . .",4.3. Hyper-parameters,[0],[0]
", 256}, the number of units between {128, . . .",4.3. Hyper-parameters,[0],[0]
", 2048}, and the kernel width between {3, . . .",4.3. Hyper-parameters,[0],[0]
", 5}.
",4.3. Hyper-parameters,[0],[0]
"In general, finding a good architecture was simple and the rule of thumb is that the larger the model, the better the performance.",4.3. Hyper-parameters,[0],[0]
"In terms of optimization, we initialize the layers of the model with the Kaiming initialization (He et al., 2015b), with the learning rate sampled uniformly in the interval",4.3. Hyper-parameters,[0],[0]
"[1., 2.], the momentum set to 0.99, and clipping set to 0.1.",4.3. Hyper-parameters,[0],[0]
Good hyper-parameters for the optimizer are quite straightforward to find and the optimal values do not change much between datasets.,4.3. Hyper-parameters,[0],[0]
LSTMs and recurrent networks are able to capture long term dependencies and are fast becoming cornerstones in natural language processing.,5. Results,[0],[0]
"In this section, we compare strong LSTM and RNN models from the literature to our gated convolutional approach on two datasets.
",5. Results,[0],[0]
We find the GCNN outperforms the comparable LSTM results on Google billion words.,5. Results,[0],[0]
"To accurately compare these approaches, we control for the same number of GPUs and the adaptive softmax output model (Grave et al., 2016a), as these variables have a significant influence on performance.",5. Results,[0],[0]
"In this setting, the GCNN reaches 38.1 test perplexity while the comparable LSTM has 39.8 perplexity (Table 2).
",5. Results,[0],[0]
"Further, the GCNN obtains strong performance with much greater computational efficiency.",5. Results,[0],[0]
Figure 2 shows that our approach closes the previously significant gap between models that use the full softmax and models with the usually less accurate hierarchical softmax.,5. Results,[0],[0]
"Thanks to the adap-
tive softmax, the GCNN only requires a fraction of the operations to reach the same perplexity values.",5. Results,[0],[0]
"The GCNN outperforms other single model state-of-the-art approaches except the much larger LSTM of Jozefowicz et al. (2016), a model which requires more GPUs and the much more computationally expensive full softmax.",5. Results,[0],[0]
"In comparison, the largest model we have trained reaches 31.9 test perplexity compared to the 30.6 of that approach, but only requires training for 2 weeks on 8 GPUs compared to 3 weeks of training on 32 GPUs for the LSTM.",5. Results,[0],[0]
"Note that these results can be improved by either using mixtures of experts (Shazeer et al., 2017) or ensembles of these models.
",5. Results,[0],[0]
Another relevant concern is if the GCNN’s fixed context size can thoroughly model long sequences.,5. Results,[0],[0]
"On Google Bil-
∗appeared after submission
lion Word, the average sentence length is quite short — only 20 words.",5. Results,[0],[0]
We evaluate on WikiText-103 to determine if the model can perform well on a dataset where much larger contexts are available.,5. Results,[0],[0]
"On WikiText-103, an input sequence is an entire Wikipedia article instead of an individual sentence - increasing the average length to 4000 words.",5. Results,[0],[0]
"However, the GCNN outperforms LSTMs on this problem as well (Table 3).",5. Results,[0],[0]
The GCNN-8 model has 8 layers with 800 units each and the LSTM has 1024 units.,5. Results,[0],[0]
"These results show that GCNNs can model enough context to achieve strong results.
",5. Results,[0],[0]
We evaluated on the Gigaword dataset following Chen et al. (2016) to compare with fully connected models.,5. Results,[0],[0]
We found that the fully connected and convolutional network reach respectively 55.6 and 29.4 perplexity.,5. Results,[0],[0]
We also ran preliminary experiments on the much smaller Penn tree bank dataset.,5. Results,[0],[0]
"When we score the sentences independently, the GCNN and LSTM have comparable test perplexity with 108.7 and 109.3 respectively.",5. Results,[0],[0]
"However, it is possible to achieve better results by conditioning on previous sentences.",5. Results,[0],[0]
"Unlike the LSTM, we found that the GCNN overfits on this quite small dataset and so we note the model is better suited to larger scale problems.",5. Results,[0],[0]
Computational cost is an important consideration for language models.,5.1. Computational Efficiency,[0],[0]
"Depending on the application, there are a number of metrics to consider.",5.1. Computational Efficiency,[0],[0]
"We measure the throughput
of a model as the number of tokens that can be processed per second.",5.1. Computational Efficiency,[0],[0]
Throughput can be maximized by processing many sentences in parallel to amortize sequential operations.,5.1. Computational Efficiency,[0],[0]
"In contrast, responsiveness is the speed of processing the input sequentially, one token at a time.",5.1. Computational Efficiency,[0],[0]
Throughput is important because it indicates the time required to process a corpus of text and responsiveness is an indicator of the time to finish processing a sentence.,5.1. Computational Efficiency,[0],[0]
A model can have low responsiveness but high throughput by evaluating many sentences simultaneously through batching.,5.1. Computational Efficiency,[0],[0]
"In this case, such a model is slow in finishing processing individual sentences, but can process many sentences at a good rate.
",5.1. Computational Efficiency,[0],[0]
We evaluate the throughput and responsiveness for models that reach approximately 43.9 perplexity on the Google Billion Word benchmark.,5.1. Computational Efficiency,[0],[0]
"We consider the LSTM with 2048 units in Table 2, a GCNN-8Bottleneck with 7 Resnet blocks that have a bottleneck structure as described by (He et al., 2015a) and a GCNN-8 without bottlenecks.",5.1. Computational Efficiency,[0],[0]
A bottleneck block wedges a k > 1 convolution between two k = 1 layers.,5.1. Computational Efficiency,[0],[0]
This designs reduces computational cost by reducing and increasing dimensionality with the k = 1 layers so that the convolution operates in a lower dimensional space.,5.1. Computational Efficiency,[0],[0]
"Our results show that the use of bottleneck blocks is important to maintaining computational efficiency.
",5.1. Computational Efficiency,[0],[0]
"The throughput of the LSTM is measured by using a large batch of 750 sequences of length 20, resulting in 15, 000 tokens per batch.",5.1. Computational Efficiency,[0],[0]
"The responsiveness is the average speed to process a sequence of 15, 000 contiguous tokens.",5.1. Computational Efficiency,[0],[0]
Table 4 shows that the throughput for the LSTM and the GCNN are similar.,5.1. Computational Efficiency,[0],[0]
The LSTM performs very well on GPU because the large batch size of 750 enables high parallelization over different sentences.,5.1. Computational Efficiency,[0],[0]
"This is because the LSTM implementation has been thoroughly optimized and uses cuDNN, whereas the cuDNN implementation of convolutions is not been optimized for the 1-D convolutions we use in our model.",5.1. Computational Efficiency,[0],[0]
We believe much better performance can be achieved by a more efficient 1-D cuDNN convolution.,5.1. Computational Efficiency,[0],[0]
"Unlike the LSTM, the GCNN can be parallelized both over sequences as well as across the tokens of each sequence, allowing the GCNN to have 20x higher responsiveness.",5.1. Computational Efficiency,[0],[0]
"In this section, we compare the gated linear unit with other mechanisms as well as to models without gating.",5.2. Gating Mechanisms,[0],[0]
"We consider the LSTM-style gating mechanism (GTU) tanh(X ∗W + b)⊗ σ(X ∗V + c) of (Oord et al., 2016b) and networks that use regular ReLU or Tanh activations.",5.2. Gating Mechanisms,[0],[0]
"Gating units add parameters, so for fair comparison, we carefully cross-validate models with a comparable number of parameters.",5.2. Gating Mechanisms,[0],[0]
Figure 3 (left) shows that GLU networks converge to a lower perplexity than the other approaches on WikiText-103.,5.2. Gating Mechanisms,[0],[0]
"Similar to gated linear units, the ReLU has a linear path that lets the gradients easily pass through the active units.",5.2. Gating Mechanisms,[0],[0]
This translates to much faster convergence for both the ReLU and the GLU.,5.2. Gating Mechanisms,[0],[0]
"On the other hand, neither Tanh nor GTU have this linear path, and thus suffer from the vanishing gradient problem.",5.2. Gating Mechanisms,[0],[0]
"In the GTU, both the inputs as well as the gating units can cut the gradient when the units saturate.
",5.2. Gating Mechanisms,[0],[0]
"Comparing the GTU and Tanh models allows us to measure
the effect of gating since the Tanh model can be thought of as a GTU network with the sigmoid gating units removed.",5.2. Gating Mechanisms,[0],[0]
"The results (Figure 3, left) show that the gating units make a vast difference and provide useful modeling capabilities, as there is a large difference in the performance between GTU and Tanh units.",5.2. Gating Mechanisms,[0],[0]
"Similarly, while ReLU unit is not an exact ablation of the gating units in the GLU, it can be seen as a simplification ReLU(X) = X ⊗ (X > 0) where the gates become active depending on the sign of the input.",5.2. Gating Mechanisms,[0],[0]
"Also in this case, GLU units lead to lower perplexity.
",5.2. Gating Mechanisms,[0],[0]
In Figure 3 (right) we repeat the same experiment on the larger Google Billion Words dataset.,5.2. Gating Mechanisms,[0],[0]
We consider a fixed time budget of 100 hours because of the considerable training time required for this task.,5.2. Gating Mechanisms,[0],[0]
"Similar to WikiText-103, the gated linear units achieve the best results on this problem.",5.2. Gating Mechanisms,[0],[0]
"There is a gap of about 5 perplexity points between the GLU and ReLU which is similar to the difference between the LSTM and RNN models measured by (Jozefowicz et al., 2016) on the same dataset.",5.2. Gating Mechanisms,[0],[0]
The experiments so far have shown that the gated linear unit benefits from the linear path the unit provides compared to other non-linearities.,5.3. Non-linear Modeling,[0],[0]
"Next, we compare networks with GLUs to purely linear networks and networks with bilinear layers in order to measure the impact of the nonlinear path provided by the gates of the GLU.",5.3. Non-linear Modeling,[0],[0]
"One motivation for this experiment is the success of linear models on many natural language processing tasks (Manning & Schütze, 1999).",5.3. Non-linear Modeling,[0],[0]
We consider deep linear convolutional networks where the layers lack the gating units of the GLU and take the form hl(X) = X ∗W + b.,5.3. Non-linear Modeling,[0],[0]
"Stacking several layers on top of each other is simply a factorization of the model which remains linear up to the softmax, at which point it becomes log-linear.",5.3. Non-linear Modeling,[0],[0]
"Another variation of GLUs are bilinear layers (Mnih & Hinton, 2007) which take the form
hl(X) =",5.3. Non-linear Modeling,[0],[0]
(X ∗W + b)⊗,5.3. Non-linear Modeling,[0],[0]
"(X ∗V + c).
",5.3. Non-linear Modeling,[0],[0]
"Figure 5 shows that GLUs perform best, followed by bilinear layers and then linear layers.",5.3. Non-linear Modeling,[0],[0]
"Bilinear layers improve over linear ones by more than 40 perplexity points, and the GLU improves another 20 perplexity points over the bilinear model.",5.3. Non-linear Modeling,[0],[0]
"The linear model performs very poorly at perplexity 115 even compared to 67.6 of a Kneser-Ney 5-gram model, even though the former has access to more context.",5.3. Non-linear Modeling,[0],[0]
"Surprisingly, the introduction of the gated linear units is enough to reach 61 perplexity on Google Billion Word, which surpasses both Kneser-Ney 5-gram models and the non-linear neural model of (Ji et al., 2015).",5.3. Non-linear Modeling,[0],[0]
Figure 4 shows the impact of context size for the gated CNN.,5.4. Context Size,[0],[0]
We tried different combinations of network depth and kernel widths for each context size and chose the best performing one for each size.,5.4. Context Size,[0],[0]
"Generally, larger contexts
improve accuracy but returns drastically diminish with windows larger than 40 words, even for WikiText-103 where we may condition on an entire Wikipedia article.",5.4. Context Size,[0],[0]
This means that the unlimited context offered by recurrent models is not strictly necessary for language modeling.,5.4. Context Size,[0],[0]
"Furthermore, this finding is also congruent with the fact that good performance with recurrent networks can be obtained by truncating gradients after only 40 timesteps using truncated back propagation through time.",5.4. Context Size,[0],[0]
Figure 4 also shows that WikiText-103 benefits much more from larger context size than Google Billion Word as the performance degrades more sharply with smaller contexts.,5.4. Context Size,[0],[0]
WikiText-103 provides much more context than Google Billion Word where the average sentence size is 20.,5.4. Context Size,[0],[0]
"However, while the average size of the documents is close to 4000 tokens, we find that strong performance can be achieved with a context size as low as 30 tokens.",5.4. Context Size,[0],[0]
"In this section, we perform an ablation study of the impact of weight normalization and gradient clipping.",5.5. Training,[0],[0]
We separately cross-validate the hyper-parameters of each configuration to make the comparison fair.,5.5. Training,[0],[0]
"Due to the high cost of each of these experiments, we only consider a single iteration over the training data.",5.5. Training,[0],[0]
Figure 6 shows that both methods significantly speed up convergence.,5.5. Training,[0],[0]
Weight normalization in particular improves the speed by over two times.,5.5. Training,[0],[0]
This speedup is partly due to the ability to use much larger learning rates (1 instead of 0.01) than would otherwise be possible.,5.5. Training,[0],[0]
"Both clipping and weight normalization add computational overhead, but it is minor compared to the large gains in convergence speed.",5.5. Training,[0],[0]
We introduce a convolutional neural network for language modeling with a novel gating mechanism.,6. Conclusion,[0],[0]
"Compared to recurrent neural networks, our approach builds a hierarchical representation of the input words that makes it easier to capture long-range dependencies, similar in spirit to the tree-structured analysis of linguistic grammar formalisms.",6. Conclusion,[0],[0]
"The same property eases learning since features are passed through a fixed number of layers and non-linearities, unlike for recurrent networks where the number of processing steps differs depending on the position of the word in the input.",6. Conclusion,[0],[0]
The results show that our gated convolutional network achieves a new state of the art on WikiText-103.,6. Conclusion,[0],[0]
"On the Google Billion Word benchmark, we show competitive results can be achieved with significantly fewer resources.",6. Conclusion,[0],[0]
"We would like to thank Ben Graham, Jonas Gehring, Edouard Grave, Armand Joulin and Ronan Collobert for helpful discussions.",Acknowledgments,[0],[0]
The pre-dominant approach to language modeling to date is based on recurrent neural networks.,abstractText,[0],[0]
Their success on this task is often linked to their ability to capture unbounded context.,abstractText,[0],[0]
"In this paper we develop a finite context approach through stacked convolutions, which can be more efficient since they allow parallelization over sequential tokens.",abstractText,[0],[0]
We propose a novel simplified gating mechanism that outperforms Oord et al. (2016b) and investigate the impact of key architectural decisions.,abstractText,[0],[0]
"The proposed approach achieves state-of-the-art on the WikiText103 benchmark, even though it features longterm dependencies, as well as competitive results on the Google Billion Words benchmark.",abstractText,[0],[0]
Our model reduces the latency to score a sentence by an order of magnitude compared to a recurrent baseline.,abstractText,[0],[0]
"To our knowledge, this is the first time a non-recurrent approach is competitive with strong recurrent models on these large scale language tasks.",abstractText,[0],[0]
Language Modeling with Gated Convolutional Networks,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1–11, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.
In this paper, we consider the task of learning control policies for text-based games. In these games, all interactions in the virtual world are through text and the underlying state is not observed. The resulting language barrier makes such environments challenging for automatic game players. We employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback. This framework enables us to map text descriptions into vector representations that capture the semantics of the game states. We evaluate our approach on two game worlds, comparing against baselines using bag-ofwords and bag-of-bigrams for state representations. Our algorithm outperforms the baselines on both worlds demonstrating the importance of learning expressive representations. 1",text,[0],[0]
"In this paper, we address the task of learning control policies for text-based strategy games.",1 Introduction,[0],[0]
"These games, predecessors to modern graphical ones, still enjoy a large following worldwide.2",1 Introduction,[0],[0]
They often involve complex worlds with rich interactions and elaborate textual descriptions of the underlying states (see Figure 1).,1 Introduction,[0],[0]
Players read descriptions of the current world state and respond with natural language commands to take actions.,1 Introduction,[0],[0]
"Since the underlying state is not directly observable, the player has to understand the text in order to act, making it
∗Both authors contributed equally to this work.",1 Introduction,[0],[0]
"1Code is available at http://people.csail.mit.
edu/karthikn/mud-play.",1 Introduction,[0],[0]
"2http://mudstats.com/
challenging for existing AI programs to play these games (DePristo and Zubek, 2001).
",1 Introduction,[0],[0]
"In designing an autonomous game player, we have considerable latitude when selecting an adequate state representation to use.",1 Introduction,[0],[0]
The simplest method is to use a bag-of-words representation derived from the text description.,1 Introduction,[0],[0]
"However, this scheme disregards the ordering of words and the finer nuances of meaning that evolve from composing words into sentences and paragraphs.",1 Introduction,[0],[0]
"For instance, in State 2 in Figure 1, the agent has to understand that going east will lead it to the castle whereas moving south will take it to the standing archway.",1 Introduction,[0],[0]
"An alternative approach is to convert text descriptions to pre-specified representations using annotated training data, commonly used in
1
language grounding tasks (Matuszek et al., 2013; Kushman et al., 2014).
",1 Introduction,[0],[0]
"In contrast, our goal is to learn useful representations in conjunction with control policies.",1 Introduction,[0],[0]
We adopt a reinforcement learning framework and formulate game sequences as Markov Decision Processes.,1 Introduction,[0],[0]
An agent playing the game aims to maximize rewards that it obtains from the game engine upon the occurrence of certain events.,1 Introduction,[0],[0]
"The agent learns a policy in the form of an action-value function Q(s, a) which denotes the long-term merit of an action a in state s.
The action-value function is parametrized using a deep recurrent neural network, trained using the game feedback.",1 Introduction,[0],[0]
The network contains two modules.,1 Introduction,[0],[0]
The first one converts textual descriptions into vector representations that act as proxies for states.,1 Introduction,[0],[0]
"This component is implemented using Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997).",1 Introduction,[0],[0]
"The second module of the network scores the actions given the vector representation computed by the first.
",1 Introduction,[0],[0]
"We evaluate our model using two Multi-User Dungeon (MUD) games (Curtis, 1992; Amir and Doyle, 2002).",1 Introduction,[0],[0]
"The first game is designed to provide a controlled setup for the task, while the second is a publicly available one and contains human generated text descriptions with significant language variability.",1 Introduction,[0],[0]
We compare our algorithm against baselines of a random player and models that use bag-of-words or bag-of-bigrams representations for a state.,1 Introduction,[0],[0]
We demonstrate that our model LSTM-DQN significantly outperforms the baselines in terms of number of completed quests and accumulated rewards.,1 Introduction,[0],[0]
"For instance, on a fantasy MUD game, our model learns to complete 96% of the quests, while the bag-of-words model and a random baseline solve only 82% and 5% of the quests, respectively.",1 Introduction,[0],[0]
"Moreover, we show that the acquired representation can be reused across games, speeding up learning and leading to faster convergence of Q-values.",1 Introduction,[0],[0]
Learning control policies from text is gaining increasing interest in the NLP community.,2 Related Work,[0],[0]
"Example applications include interpreting help documentation for software (Branavan et al., 2010), navigating with directions (Vogel and Jurafsky, 2010; Kollar et al., 2010; Artzi and Zettlemoyer, 2013; Matuszek et al., 2013; Andreas and Klein, 2015)
and playing computer games (Eisenstein et al., 2009; Branavan et al., 2011a).
",2 Related Work,[0],[0]
Games provide a rich domain for grounded language analysis.,2 Related Work,[0],[0]
Prior work has assumed perfect knowledge of the underlying state of the game to learn policies.,2 Related Work,[0],[0]
Gorniak and Roy (2005) developed a game character that can be controlled by spoken instructions adaptable to the game situation.,2 Related Work,[0],[0]
The grounding of commands to actions is learned from a transcript manually annotated with actions and state attributes.,2 Related Work,[0],[0]
Eisenstein et al. (2009) learn game rules by analyzing a collection of game-related documents and precompiled traces of the game.,2 Related Work,[0],[0]
"In contrast to the above work, our model combines text interpretation and strategy learning in a single framework.",2 Related Work,[0],[0]
"As a result, textual analysis is guided by the received control feedback, and the learned strategy directly builds on the text interpretation.
",2 Related Work,[0],[0]
"Our work closely relates to an automatic game player that utilizes text manuals to learn strategies for Civilization (Branavan et al., 2011a).",2 Related Work,[0],[0]
"Similar to our approach, text analysis and control strategies are learned jointly using feedback provided by the game simulation.",2 Related Work,[0],[0]
"In their setup, states are fully observable, and the model learns a strategy by combining state/action features and features extracted from text.",2 Related Work,[0],[0]
"However, in our application, the state representation is not provided, but has to be inferred from a textual description.",2 Related Work,[0],[0]
"Therefore, it is not sufficient to extract features from text to supplement a simulation-based player.
",2 Related Work,[0],[0]
"Another related line of work consists of automatic video game players that infer state representations directly from raw pixels (Koutnı́k et al., 2013; Mnih et al., 2015).",2 Related Work,[0],[0]
"For instance, Mnih et al. (2015) learn control strategies using convolutional neural networks, trained with a variant of Q-learning (Watkins and Dayan, 1992).",2 Related Work,[0],[0]
"While both approaches use deep reinforcement learning for training, our work has important differences.",2 Related Work,[0],[0]
"In order to handle the sequential nature of text, we use Long Short-Term Memory networks to automatically learn useful representations for arbitrary text descriptions.",2 Related Work,[0],[0]
"Additionally, we show that decomposing the network into a representation layer and an action selector is useful for transferring the learnt representations to new game scenarios.",2 Related Work,[0],[0]
"Game Representation We represent a game by the tuple 〈H,A, T,R,Ψ〉, where H is the set of
all possible game states, A = {(a, o)} is the set of all commands (action-object pairs), T (h′ | h, a, o) is the stochastic transition function between states and R(h, a, o) is the reward function.",3 Background,[0],[0]
"The game state H is hidden from the player, who only receives a varying textual description, produced by a stochastic function Ψ : H → S. Specifically, the underlying state h in the game engine keeps track of attributes such as the player’s location, her health points, time of day, etc.",3 Background,[0],[0]
The function Ψ (also part of the game framework) then converts this state into a textual description of the location the player is at or a message indicating low health.,3 Background,[0],[0]
We do not assume access to either H or Ψ for our agent during both training and testing phases of our experiments.,3 Background,[0],[0]
"We denote the space of all possible text descriptions s to be S. Rewards are generated using R and are only given to the player upon completion of in-game quests.
",3 Background,[0],[0]
"Q-Learning Reinforcement Learning is a commonly used framework for learning control policies in game environments (Silver et al., 2007; Amato and Shani, 2010; Branavan et al., 2011b; Szita, 2012).",3 Background,[0],[0]
"The game environment can be formulated as a sequence of state transitions (s, a, r, s′) of a Markov Decision Process (MDP).",3 Background,[0],[0]
"The agent takes an action a in state s by consulting a state-action value function Q(s, a), which is a measure of the action’s expected long-term reward.",3 Background,[0],[0]
"Q-Learning (Watkins and Dayan, 1992) is a model-free technique which is used to learn an optimal Q(s, a) for the agent.",3 Background,[0],[0]
"Starting from a random Q-function, the agent continuously updates its Q-values by playing the game and obtaining rewards.",3 Background,[0],[0]
"The iterative updates are derived from the Bellman equation (Sutton and Barto, 1998):
(1)Qi+1(s, a) =",3 Background,[0],[0]
"E[r + γmax a′
Qi(s′, a′) | s, a]
where γ is a discount factor for future rewards and the expectation is over all game transitions that involved the agent taking action a in state s.
Using these evolving Q-values, the agent chooses the action with the highest Q(s, a) to maximize its expected future rewards.",3 Background,[0],[0]
"In practice, the trade-off between exploration and exploitation can be achieved following an -greedy policy (Sutton and Barto, 1998), where the agent performs a random action with probability .
",3 Background,[0],[0]
"Deep Q-Network In large games, it is often impractical to maintain the Q-value for all possible
state-action pairs.",3 Background,[0],[0]
"One solution to this problem is to approximate Q(s, a) using a parametrized function Q(s, a; θ), which can generalize over states and actions by considering higher-level attributes (Sutton and Barto, 1998; Branavan et al., 2011a).",3 Background,[0],[0]
"However, creating a good parametrization requires knowledge of the state and action spaces.",3 Background,[0],[0]
"One way to bypass this feature engineering is to use a Deep Q-Network (DQN) (Mnih et al., 2015).",3 Background,[0],[0]
"The DQN approximates the Q-value function with a deep neural network to predict Q(s, a) for all possible actions a simultaneously given the current state s. The non-linear function layers of the DQN also enable it to learn better value functions than linear approximators.",3 Background,[0],[0]
"In this section, we describe our model (DQN) and describe its use in learning good Q-value approximations for games with stochastic textual descriptions.",4 Learning Representations and Control Policies,[0],[0]
We divide our model into two parts.,4 Learning Representations and Control Policies,[0],[0]
The first module is a representation generator that converts the textual description of the current state into a vector.,4 Learning Representations and Control Policies,[0],[0]
This vector is then input into the second module which is an action scorer.,4 Learning Representations and Control Policies,[0],[0]
Figure 2 shows the overall architecture of our model.,4 Learning Representations and Control Policies,[0],[0]
"We learn the parameters of both the representation generator and the action scorer jointly, using the in-game reward feedback.
",4 Learning Representations and Control Policies,[0],[0]
Representation Generator (φR),4 Learning Representations and Control Policies,[0],[0]
The representation generator reads raw text displayed to the agent and converts it to a vector representation vs. A bag-of-words (BOW) representation is not sufficient to capture higher-order structures of sentences and paragraphs.,4 Learning Representations and Control Policies,[0],[0]
"The need for a better semantic representation of the text is evident from the average performance of this representation in playing MUD-games (as we show in Section 6).
",4 Learning Representations and Control Policies,[0],[0]
"In order to assimilate better representations, we utilize a Long Short-Term Memory network (LSTM) (Hochreiter and Schmidhuber, 1997) as a representation generator.",4 Learning Representations and Control Policies,[0],[0]
LSTMs are recurrent neural networks with the ability to connect and recognize long-range patterns between words in text.,4 Learning Representations and Control Policies,[0],[0]
They are more robust than BOW to small variations in word usage and are able to capture underlying semantics of sentences to some extent.,4 Learning Representations and Control Policies,[0],[0]
"In recent work, LSTMs have been used successfully in NLP tasks such as machine translation (Sutskever et al., 2014) and sentiment analysis (Tai et al., 2015) to compose vector representations of sentences from word-level embeddings (Mikolov et al., 2013; Pennington et al., 2014).",4 Learning Representations and Control Policies,[0],[0]
"In our setup, the LSTM network takes in word embeddings wk from the words in a description s and produces output vectors xk at each step.
",4 Learning Representations and Control Policies,[0],[0]
"To get the final state representation vs, we add a mean pooling layer which computes the elementwise mean over the output vectors xk.3
(2)vs = 1 n n∑ k=1 xk
Action Scorer (φA)",4 Learning Representations and Control Policies,[0],[0]
The action scorer module produces scores for the set of possible actions given the current state representation.,4 Learning Representations and Control Policies,[0],[0]
We use a multi-layered neural network for this purpose (see Figure 2).,4 Learning Representations and Control Policies,[0],[0]
"The input to this module is the vector from the representation generator, vs = φR(s) and the outputs are scores for actions",4 Learning Representations and Control Policies,[0],[0]
"a ∈ A. Scores for all actions are predicted simultaneously, which is computationally more efficient than scoring each state-action pair separately.",4 Learning Representations and Control Policies,[0],[0]
"Thus, by combining the representation generator and action scorer, we can obtain the approximation for the Qfunction as Q(s, a) ≈ φA(φR(s))[a].
",4 Learning Representations and Control Policies,[0],[0]
"An additional complexity in playing MUDgames is that the actions taken by the player are
3We also experimented with considering just the output vector of the LSTM after processing the last word.",4 Learning Representations and Control Policies,[0],[0]
"Empirically, we find that mean pooling leads to faster learning, so we use it in all our experiments.
",4 Learning Representations and Control Policies,[0],[0]
multi-word natural language commands such as eat apple or go east.,4 Learning Representations and Control Policies,[0],[0]
"Due to computational constraints, in this work we limit ourselves to consider commands to consist of one action (e.g. eat) and one argument object (e.g. apple).",4 Learning Representations and Control Policies,[0],[0]
"This assumption holds for the majority of the commands in our worlds, with the exception of one class of commands that require two arguments (e.g. move red-root right, move blue-root up).",4 Learning Representations and Control Policies,[0],[0]
We consider all possible actions and objects available in the game and predict both for each state using the same network (Figure 2).,4 Learning Representations and Control Policies,[0],[0]
"We consider the Q-value of the entire command (a, o) to be the average of the Qvalues of the action a and the object o.",4 Learning Representations and Control Policies,[0],[0]
"For the rest of this section, we only show equations forQ(s, a) but similar ones hold for Q(s, o).
",4 Learning Representations and Control Policies,[0],[0]
Parameter Learning,4 Learning Representations and Control Policies,[0],[0]
"We learn the parameters θR of the representation generator and θA of the action scorer using stochastic gradient descent with RMSprop (Tieleman and Hinton, 2012).",4 Learning Representations and Control Policies,[0],[0]
The complete training procedure is shown in Algorithm 1.,4 Learning Representations and Control Policies,[0],[0]
"In each iteration i, we update the parameters to reduce the discrepancy between the predicted value of the current state Q(st, at; θi) (where θi = [θR; θA]i) and the expected Q-value given the reward rt and the value of the next state maxa Q(st+1, a; θi−1).
",4 Learning Representations and Control Policies,[0],[0]
"We keep track of the agent’s previous experiences in a memory D.4 Instead of performing updates to the Q-value using transitions from the current episode, we sample a random transition (ŝ, â, s′, r) from D. Updating the parameters in this way avoids issues due to strong correlation when using transitions of the same episode (Mnih et al., 2015).",4 Learning Representations and Control Policies,[0],[0]
"Using the sampled transition and (1), we obtain the following loss function to minimize:
(3)Li(θi) =",4 Learning Representations and Control Policies,[0],[0]
"Eŝ,â[(yi −Q(ŝ, â; θi))2] where yi = Eŝ,â[r + γmaxa′",4 Learning Representations and Control Policies,[0],[0]
"Q(s′, a′; θi−1) | ŝ, â] is the target Q-value with parameters θi−1 fixed from the previous iteration.
",4 Learning Representations and Control Policies,[0],[0]
"The updates on the parameters θ can be performed using the following gradient of Li(θi): ∇θiLi(θi) = Eŝ,â[2(yi −Q(ŝ, â; θi))∇θiQ(ŝ, â; θi)]
For each epoch of training, the agent plays several episodes of the game, which is restarted after every terminal state.
",4 Learning Representations and Control Policies,[0],[0]
"4The memory is limited and rewritten in a first-in-first-out (FIFO) fashion.
",4 Learning Representations and Control Policies,[0],[0]
"Algorithm 1 Training Procedure for DQN with prioritized sampling 1: Initialize experience memory D 2: Initialize parameters of representation generator (φR) and action scorer (φA) randomly 3: for episode = 1,M do 4: Initialize game and get start state description s1 5: for t = 1, T do 6: Convert st (text) to representation vst using φR 7: if random() < then 8: Select a random action at 9: else 10: Compute Q(st, a) for all actions using φA(vst) 11: Select at = argmax Q(st, a) 12:",4 Learning Representations and Control Policies,[0],[0]
Execute action at and observe reward rt and new state st+1 13:,4 Learning Representations and Control Policies,[0],[0]
"Set priority pt = 1 if rt > 0, else pt = 0 14:",4 Learning Representations and Control Policies,[0],[0]
"Store transition (st, at, rt, st+1, pt) in D 15:",4 Learning Representations and Control Policies,[0],[0]
"Sample random mini batch of transitions (sj , aj , rj , sj+1, pj) from D,
with fraction ρ having pj = 1 16: Set yj =",4 Learning Representations and Control Policies,[0],[0]
{,4 Learning Representations and Control Policies,[0],[0]
rj,4 Learning Representations and Control Policies,[0],[0]
if sj+1 is terminal rj,4 Learning Representations and Control Policies,[0],[0]
"+ γ maxa′ Q(sj+1, a′; θ) if sj+1 is non-terminal 17:",4 Learning Representations and Control Policies,[0],[0]
Perform gradient descent step on the loss L(θ) =,4 Learning Representations and Control Policies,[0],[0]
"(yj −Q(sj , aj ; θ))2
Mini-batch Sampling In practice, online updates to the parameters θ are performed over a mini batch of state transitions, instead of a single transition.",4 Learning Representations and Control Policies,[0],[0]
"This increases the number of experiences used per step and is also more efficient due to optimized matrix operations.
",4 Learning Representations and Control Policies,[0],[0]
The simplest method to create these minibatches from the experience memory D is to sample uniformly at random.,4 Learning Representations and Control Policies,[0],[0]
"However, certain experiences are more valuable than others for the agent to learn from.",4 Learning Representations and Control Policies,[0],[0]
"For instance, rare transitions that provide positive rewards can be used more often to learn optimal Q-values faster.",4 Learning Representations and Control Policies,[0],[0]
"In our experiments, we consider such positive-reward transitions to have higher priority and keep track of them in D. We use prioritized sampling (inspired by Moore and Atkeson (1993)) to sample a fraction ρ of transitions from the higher priority pool and a fraction 1− ρ from the rest.",4 Learning Representations and Control Policies,[0],[0]
"Game Environment For our game environment, we modify Evennia,5 an open-source library for building online textual MUD games.",5 Experimental Setup,[0],[0]
"Evennia is a Python-based framework that allows one to easily create new games by writing a batch file describing the environment with details of rooms,
5http://www.evennia.com/
objects and actions.",5 Experimental Setup,[0],[0]
"The game engine keeps track of the game state internally, presenting textual descriptions to the player and receiving text commands from the player.",5 Experimental Setup,[0],[0]
"We conduct experiments on two worlds - a smaller Home world we created ourselves, and a larger, more complex Fantasy world created by Evennia’s developers.",5 Experimental Setup,[0],[0]
"The motivation behind Home world is to abstract away high-level planning and focus on the language understanding requirements of the game.
",5 Experimental Setup,[0],[0]
Table 1 provides statistics of the game worlds.,5 Experimental Setup,[0],[0]
We observe that the Fantasy world is moderately sized with a vocabulary of 1340 words and up to 100 different descriptions for a room.,5 Experimental Setup,[0],[0]
These descriptions were created manually by the game developers.,5 Experimental Setup,[0],[0]
"These diverse, engaging descriptions are designed to make it interesting and exciting for human players.",5 Experimental Setup,[0],[0]
"Several rooms have many alternative descriptions, invoked randomly on each visit by
the player.",5 Experimental Setup,[0],[0]
"Comparatively, the Home world is smaller: it has a very restricted vocabulary of 84 words and the room descriptions are relatively structured.",5 Experimental Setup,[0],[0]
"However, both the room descriptions (which are also varied and randomly provided to the agent) and the quest descriptions were adversarially created with negation and conjunction of facts to force an agent to actually understand the state in order to play well.",5 Experimental Setup,[0],[0]
"Therefore, this domain provides an interesting challenge for language understanding.
",5 Experimental Setup,[0],[0]
"In both worlds, the agent receives a positive reward on completing a quest, and negative rewards for getting into bad situations like falling off a bridge, or losing a battle.",5 Experimental Setup,[0],[0]
We also add small deterministic negative rewards for each nonterminating step.,5 Experimental Setup,[0],[0]
This incentivizes the agent to learn policies that solve quests in fewer steps.,5 Experimental Setup,[0],[0]
"The supplementary material has details on the reward structure.
",5 Experimental Setup,[0],[0]
"Home World We created Home world to mimic the environment of a typical house.6 The world consists of four rooms - a living room, a bedroom, a kitchen and a garden with connecting pathways.",5 Experimental Setup,[0],[0]
Every room is reachable from every other room.,5 Experimental Setup,[0],[0]
Each room contains a representative object that the agent can interact with.,5 Experimental Setup,[0],[0]
"For instance, the kitchen has an apple that the player can eat.",5 Experimental Setup,[0],[0]
Transitions between the rooms are deterministic.,5 Experimental Setup,[0],[0]
"At the start of each game episode, the player is placed in a random room and provided with a randomly selected quest.",5 Experimental Setup,[0],[0]
The text provided to the player contains both the description of her current state and that of the quest.,5 Experimental Setup,[0],[0]
"Thus, the player can begin in one of 16 different states (4 rooms × 4 quests), which adds to the world’s complexity.
",5 Experimental Setup,[0],[0]
An example of a quest given to the player in text is Not you are sleepy now,5 Experimental Setup,[0],[0]
but you are hungry now.,5 Experimental Setup,[0],[0]
"To complete this quest and obtain a reward, the player has to navigate through the house to reach the kitchen and eat the apple (i.e type in the command eat apple).",5 Experimental Setup,[0],[0]
"More importantly, the player should interpret that the quest does not require her to take a nap in the bedroom.",5 Experimental Setup,[0],[0]
"We created such misguiding quests to make it hard for agents to succeed without having an adequate level of language understanding.
",5 Experimental Setup,[0],[0]
"6An illustration is provided in the supplementary material.
",5 Experimental Setup,[0],[0]
Fantasy World,5 Experimental Setup,[0],[0]
The Fantasy world is considerably more complex and involves quests such as navigating through a broken bridge or finding the secret tomb of an ancient hero.,5 Experimental Setup,[0],[0]
This game also has stochastic transitions in addition to varying state descriptions provided to the player.,5 Experimental Setup,[0],[0]
"For instance, there is a possibility of the player falling from the bridge if she lingers too long on it.
",5 Experimental Setup,[0],[0]
"Due to the large command space in this game,7 we make use of cues provided by the game itself to narrow down the set of possible objects to consider in each state.",5 Experimental Setup,[0],[0]
"For instance, in the MUD example in Figure 1, the game provides a list of possible exits.",5 Experimental Setup,[0],[0]
"If the game does not provide such clues for the current state, we consider all objects in the game.
",5 Experimental Setup,[0],[0]
Evaluation We use two metrics for measuring an agent’s performance: (1) the cumulative reward obtained per episode averaged over the episodes and (2) the fraction of quests completed by the agent.,5 Experimental Setup,[0],[0]
The evaluation procedure is as follows.,5 Experimental Setup,[0],[0]
"In each epoch, we first train the agent on M episodes of T steps each.",5 Experimental Setup,[0],[0]
"At the end of this training, we have a testing phase of running M episodes of the game for T steps.",5 Experimental Setup,[0],[0]
"We useM = 50, T = 20 for the Home world and M = 20, T = 250 for the Fantasy world.",5 Experimental Setup,[0],[0]
"For all evaluation episodes, we run the agent following an -greedy policy with = 0.05, which makes the agent choose the best action according to its Q-values 95% of the time.",5 Experimental Setup,[0],[0]
"We report the agent’s performance at each epoch.
",5 Experimental Setup,[0],[0]
Baselines We compare our LSTM-DQN model with three baselines.,5 Experimental Setup,[0],[0]
The first is a Random agent that chooses both actions and objects uniformly at random from all available choices.8,5 Experimental Setup,[0],[0]
"The other two are BOW-DQN and BI-DQN, which use a bagof-words and a bag-of-bigrams representation of the text, respectively, as input to the DQN action scorer.",5 Experimental Setup,[0],[0]
"These baselines serve to illustrate the importance of having a good representation layer for the task.
",5 Experimental Setup,[0],[0]
"Settings For our DQN models, we used D = 100000, γ = 0.5.",5 Experimental Setup,[0],[0]
We use a learning rate of 0.0005 for RMSprop.,5 Experimental Setup,[0],[0]
We anneal the for -greedy from 1 to 0.2 over 100000 transitions.,5 Experimental Setup,[0],[0]
A mini-batch gradient update is performed every 4 steps of the gameplay.,5 Experimental Setup,[0],[0]
"We roll out the LSTM (over words) for
7We consider 222 possible command combinations of 6 actions and 37 object arguments.
",5 Experimental Setup,[0],[0]
"8In the case of the Fantasy world, the object choices are narrowed down using game clues as described earlier.
",5 Experimental Setup,[0],[0]
a maximum of 30 steps on the Home world and for 100 steps on the Fantasy world.,5 Experimental Setup,[0],[0]
"For the prioritized sampling, we used ρ = 0.25 for both worlds.",5 Experimental Setup,[0],[0]
We employed a mini-batch size of 64 and word embedding size d = 20 in all experiments.,5 Experimental Setup,[0],[0]
Home World Figure 3 illustrates the performance of LSTM-DQN compared to the baselines.,6 Results,[0],[0]
"We can observe that the Random baseline performs quite poorly, completing only around 10% of quests on average9 obtaining a low reward of around −1.58.",6 Results,[0],[0]
"The BOW-DQN model performs significantly better and is able to complete around 46% of the quests, with an average reward of 0.20.",6 Results,[0],[0]
The improvement in reward is due to both greater quest success rate and a lower rate of issuing invalid commands (e.g. eat apple would be invalid in the bedroom since there is no apple).,6 Results,[0],[0]
We notice that both the reward and quest completion graphs of this model are volatile.,6 Results,[0],[0]
"This is because the model fails to pick out differences between quests like Not you are hungry now but you are sleepy now and Not you are sleepy now but you
9Averaged over the last 10 epochs.
are hungry now.",6 Results,[0],[0]
The BI-DQN model suffers from the same issue although it performs slightly better than BOW-DQN by completing 48% of quests.,6 Results,[0],[0]
"In contrast, the LSTM-DQN model does not suffer from this issue and is able to complete 100% of the quests after around 50 epochs of training, achieving close to the optimal reward possible.10 This demonstrates that having an expressive representation for text is crucial to understanding the game states and choosing intelligent actions.
",6 Results,[0],[0]
"In addition, we also investigated the impact of using a deep neural network for modeling the action scorer φA. Figure 4 illustrates the performance of the BOW-DQN and BI-DQN models along with their simpler versions BOW-LIN and BI-LIN, which use a single linear layer for φA. It can be seen that the DQN models clearly achieve better performance than their linear counterparts, which points to them modeling the control policy better.
",6 Results,[0],[0]
Fantasy World,6 Results,[0],[0]
"We evaluate all the models on the Fantasy world in the same manner as before and report reward, quest completion rates and Q-
10Note that since each step incurs a penalty of −0.01, the best reward (on average) a player can get is around 0.98.
values.",6 Results,[0],[0]
"The quest we evaluate on involves crossing the broken bridge (which takes a minimum of five steps), with the possibility of falling off at random (a 5% chance) when the player is on the bridge.",6 Results,[0],[0]
The game has an additional quest of reaching a secret tomb.,6 Results,[0],[0]
"However, this is a complex quest that requires the player to memorize game events and perform high-level planning which are beyond the scope of this current work.",6 Results,[0],[0]
"Therefore, we focus only on the first quest.
",6 Results,[0],[0]
"From Figure 3 (bottom), we can see that the Random baseline does poorly in terms of both average per-episode reward11 and quest completion rates.",6 Results,[0],[0]
BOW-DQN converges to a much higher average reward of −12.68 and achieves around 82% quest completion.,6 Results,[0],[0]
"Again, the BOW-DQN is often confused by varying (10 different) descriptions of the portions of the bridge, which reflects in its erratic performance on the quest.",6 Results,[0],[0]
The BI-DQN performs very well on quest completion by finishing 97% of quests.,6 Results,[0],[0]
"However, this model tends to find sub-optimal solutions and gets an average reward of −26.68, even worse than BOW-DQN.",6 Results,[0],[0]
One reason for this is the negative rewards the agent obtains after falling off the bridge.,6 Results,[0],[0]
"The LSTM-DQN model again performs best, achieving an average reward of −11.33 and completing 96% of quests on average.",6 Results,[0],[0]
"Though this world does not contain descriptions adversarial to BOW-DQN or BIDQN, the LSTM-DQN obtains higher average reward by completing the quest in fewer steps and showing more resilience to variations in the state descriptions.
",6 Results,[0],[0]
Transfer Learning,6 Results,[0],[0]
"We would like the representations learnt by φR to be generic enough and
11Note that the rewards graph is in log scale.
",6 Results,[0],[0]
transferable to new game worlds.,6 Results,[0],[0]
"To test this, we created a second Home world with the same rooms, but a completely different map, changing the locations of the rooms and the pathways between them.",6 Results,[0],[0]
"The main differentiating factor of this world from the original home world lies in the high-level planning required to complete quests.
",6 Results,[0],[0]
"We initialized the LSTM part of an LSTMDQN agent with parameters θR learnt from the original home world and trained it on the new world.12 Figure 3 (top right) demonstrates that the agent with transferred parameters is able to learn quicker than an agent starting from scratch initialized with random parameters (No Transfer), reaching the optimal policy almost 20 epochs earlier.",6 Results,[0],[0]
"This indicates that these simulated worlds can be used to learn good representations for language that transfer across worlds.
",6 Results,[0],[0]
Prioritized sampling We also investigate the effects of different minibatch sampling procedures on the parameter learning.,6 Results,[0],[0]
"From Figure 3 (bottom right), we observe that using prioritized sampling significantly speeds up learning, with the agent achieving the optimal policy around 50 epochs faster than using uniform sampling.",6 Results,[0],[0]
"This shows promise for further research into different schemes of assigning priority to transitions.
",6 Results,[0],[0]
Representation Analysis We analyzed the representations learnt by the LSTM-DQN model on the Home world.,6 Results,[0],[0]
"Figure 5 shows a visualization
12The parameters for the Action Scorer (θA) are initialized randomly.
of learnt word embeddings, reduced to two dimensions using t-SNE (Van der Maaten and Hinton, 2008).",6 Results,[0],[0]
All the vectors were initialized randomly before training.,6 Results,[0],[0]
We can see that semantically similar words appear close together to form coherent subspaces.,6 Results,[0],[0]
"In fact, we observe four different subspaces, each for one type of room along with its corresponding object(s) and quest words.",6 Results,[0],[0]
"For instance, food items like pizza and rooms like kitchen are very close to the word hungry which appears in a quest description.",6 Results,[0],[0]
This shows that the agent learns to form meaningful associations between the semantics of the quest and the environment.,6 Results,[0],[0]
Table 2 shows some examples of descriptions from Fantasy world and their nearest neighbors using cosine similarity between their corresponding vector representations produced by LSTM-DQN.,6 Results,[0],[0]
The model is able to correlate descriptions of the same (or similar) underlying states and project them onto nearby points in the representation subspace.,6 Results,[0],[0]
We address the task of end-to-end learning of control policies for text-based games.,7 Conclusions,[0],[0]
"In these games, all interactions in the virtual world are through text and the underlying state is not observed.",7 Conclusions,[0],[0]
The resulting language variability makes such environments challenging for automatic game players.,7 Conclusions,[0],[0]
We employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback.,7 Conclusions,[0],[0]
This framework enables us to map text descriptions into vector representations that capture the semantics of the game states.,7 Conclusions,[0],[0]
Our experiments demonstrate the importance of learning good representations of text in order to play these games well.,7 Conclusions,[0],[0]
"Future directions include tackling high-level
planning and strategy learning to improve the performance of intelligent agents.",7 Conclusions,[0],[0]
"We are grateful to the developers of Evennia, the game framework upon which this work is based.",Acknowledgements,[0],[0]
"We also thank Nate Kushman, Clement Gehring, Gustavo Goretkin, members of MIT’s NLP group and the anonymous EMNLP reviewers for insightful comments and feedback.",Acknowledgements,[0],[0]
T. Kulkarni was graciously supported by the Leventhal Fellowship.,Acknowledgements,[0],[0]
"We would also like to acknowledge MIT’s Center for Brains, Minds and Machines (CBMM) for support.",Acknowledgements,[0],[0]
"In this paper, we consider the task of learning control policies for text-based games.",abstractText,[0],[0]
"In these games, all interactions in the virtual world are through text and the underlying state is not observed.",abstractText,[0],[0]
The resulting language barrier makes such environments challenging for automatic game players.,abstractText,[0],[0]
We employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback.,abstractText,[0],[0]
This framework enables us to map text descriptions into vector representations that capture the semantics of the game states.,abstractText,[0],[0]
"We evaluate our approach on two game worlds, comparing against baselines using bag-ofwords and bag-of-bigrams for state representations.",abstractText,[0],[0]
Our algorithm outperforms the baselines on both worlds demonstrating the importance of learning expressive representations.,abstractText,[0],[0]
1,abstractText,[0],[0]
Language Understanding for Text-based Games using Deep Reinforcement Learning,title,[0],[0]
"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1009–1019, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics",text,[0],[0]
Truth-finding algorithms aim to separate true statements (facts) from false information.,1 Introduction,[0],[0]
"More specifically, given a set of statements whose truthfulness is unknown (fact candidates), the key goal of truth-finding algorithms is to generate a ranking such that true statements are ranked ahead of false ones.",1 Introduction,[0],[0]
Truth-finders have the potential to address a major obstacle on the Web: the problem of sources spreading inaccurate and conflicting information.,1 Introduction,[0],[0]
This problem continues to grow with the development of tools for easy Web authorship.,1 Introduction,[0],[0]
"Blogs, forums and social networking websites are not subject to traditional journalistic standards.",1 Introduction,[0],[0]
"Consequently, the accuracy of information reported by these sources is often unclear.",1 Introduction,[0],[0]
Even more established newspapers and websites may sometimes report false information as they race to break stories.,1 Introduction,[0],[0]
"Therefore, truth-finding is becoming an in-
creasingly important problem.",1 Introduction,[0],[0]
"Information extraction projects aim to distill relational facts from natural language text (Auer et al., 2007; Bollacker et al., 2008; Carlson et al., 2010; Fader et al., 2011; Nakashole et al., 2011; Del Corro and Gemulla, 2013).",1 Introduction,[0],[0]
These projects have produced knowledge bases containing many millions of relational facts between entities.,1 Introduction,[0],[0]
"However, despite these impressive advances, there are still major limitations regarding precision.",1 Introduction,[0],[0]
"Within the context of information extraction, fact extractors assign confidence scores to extracted facts.",1 Introduction,[0],[0]
"However, such scores are often tied to the extractor’s ability to read and understand natural language text.",1 Introduction,[0],[0]
This is different from a score that indicates the degree to which a given fact candidate is believable.,1 Introduction,[0],[0]
Such a believability score is sometimes also referred to as a credibility score or truthfulness score.,1 Introduction,[0],[0]
The believability score reflects the likelihood that a given statement is true.,1 Introduction,[0],[0]
"Truth-finding algorithms aim to compute this score for each fact candidate.
",1 Introduction,[0],[0]
"Prior truth-finding methods are mostly based on iterative voting, where votes are propagated from sources to fact candidates and then back to sources (Yin et al., 2007; Galland et al., 2010; Pasternack and Roth, 2010; Li et al., 2011; Yin and Tan, 2011).",1 Introduction,[0],[0]
At the core of iterative voting is the assumption that candidates mentioned by many sources are more likely to be true.,1 Introduction,[0],[0]
"However, additional aspects of a source influence its trustworthiness, besides external votes.
",1 Introduction,[0],[0]
Our goal is to accurately assess truthfulness of fact candidates by taking into account the language of sources that mention them.,1 Introduction,[0],[0]
A Mechanical Turk study we carried out revealed that there is a significant correlation between objectivity of language and trustworthiness of sources.,1 Introduction,[0],[0]
"Objectivity of language refers to the use of neutral, impartial language, which is not personal, judgmental, or emotional.",1 Introduction,[0],[0]
"Trustworthiness refers to
1009
a source of information being reliable and truthful.",1 Introduction,[0],[0]
We use linguistics features to detect if a given source objectively states facts or is speculative and opinionated.,1 Introduction,[0],[0]
"Additionally, in order to ensure that fact candidates mentioned in similar sources have similar believability scores, our believability computation model incorporates influence of comentions.",1 Introduction,[0],[0]
"However, we must avoid falsely boosting co-mentioned fact candidates.",1 Introduction,[0],[0]
"Our model addresses potential false boosts in two ways: first, by ensuring that co-mention influence is only propagated to related fact candidates; second, by ensuring that the degree of co-mention influence is determined by the trustworthiness of the sources in which co-mentions occur.
",1 Introduction,[0],[0]
The contribution of this paper is a languageaware truth-finding approach.,1 Introduction,[0],[0]
"More precisely, we make the following contributions: (1) Alternative Fact Candidates: Truth-finders rank a given fact candidate with respect to its alternatives.",1 Introduction,[0],[0]
"For example, alternative places where Barack Obama could have been born.",1 Introduction,[0],[0]
Virtually all existing truth-finders assume that the alternatives are provided.,1 Introduction,[0],[0]
"In contrast, we developed a method for generating alternative fact candidates.",1 Introduction,[0],[0]
(2) Objectivity-Trustworthiness Correlation: We hypothesize that objectivity of language and trustworthiness of sources are positively correlated.,1 Introduction,[0],[0]
"To test this hypothesis, we designed a Mechanical Turk study.",1 Introduction,[0],[0]
The study showed that this correlation does in fact hold.,1 Introduction,[0],[0]
"(3) Objectivity Classifier: Using labeled data from the Mechanical Turk study, we developed and trained an objectivity classifier which performed better than prior proposed lexicons from literature.",1 Introduction,[0],[0]
"(4) Believability Computation: We developed FactChecker, a truth-finding method that linearly combines objectivity and comention influence.",1 Introduction,[0],[0]
Our experiments showed that FactChecker outperforms prior methods.,1 Introduction,[0],[0]
"In this section, we formally define what constitutes a fact candidate and describe how we go about understanding semantics of fact candidates.",2 Fact Candidates,[0],[0]
We then present our approach for generating alternative fact candidates.,2 Fact Candidates,[0],[0]
The triple format is the most common representation of facts in knowledge bases.,2.1 Representation,[0],[0]
"A formal specifi-
cation of the triple format is presented in the RDF primer1.",2.1 Representation,[0],[0]
"In RDF, data is represented as subjectpredicate-object (SPO) triples.",2.1 Representation,[0],[0]
"In this work, we restrict predicates to verbs (or verbal phrases such as “plays for”, “graduated from”, etc.).",2.1 Representation,[0],[0]
"Literature on automatic relation discovery (Fader et al., 2011) has shown that verbal phrases uncover a large fraction of binary predicates while reducing the amount of noisy phrases that do not denote any relations.",2.1 Representation,[0],[0]
"Therefore, we define a fact candidate as follows:
Definition 1 (Fact Candidate)",2.1 Representation,[0],[0]
"A fact candidate fi is an 〈S〉 V 〈O〉 triple; where S is the subject, V is a verbal phrase, and O is the object.",2.1 Representation,[0],[0]
"We aim to compute the truthfulness of fi, τ(fi) ∈ {T, F}, where T and F stand for true and false, respectively.
",2.1 Representation,[0],[0]
Note that in this paper we are interested in cases where τ(fi) is either T or F .,2.1 Representation,[0],[0]
"That is, we assess truthfulness of factual statements and not opinions whose truthfulness is often both T and F to some degree.",2.1 Representation,[0],[0]
"For example, the triples: 〈Obama〉 born in 〈Kenya〉 and 〈Obama〉 graduated from 〈Harvard〉 are valid fact candidates.",2.1 Representation,[0],[0]
"However, the triple: 〈Obama〉 deserves 〈Nobel Peace Prize〉 is not.",2.1 Representation,[0],[0]
"Based on the SVO triple, the meaning of a fact candidate can be unclear and ambiguous.",2.2 Semantics,[0],[0]
"Therefore, we first determine the semantics of a fact candidate before computing its truthfulness.",2.2 Semantics,[0],[0]
Entity Types.,2.2 Semantics,[0],[0]
We first determine the expected types of the subject and object in the SVO.,2.2 Semantics,[0],[0]
"For example, for the SVO 〈Einstein〉 died in 〈Princeton〉, the expected types are person × location.",2.2 Semantics,[0],[0]
"We determine this by first computing the types of entities that are valid for each verb (verbal phrase) in a large SVO collection of 114m SVO triples (Talukdar et al., 2012).",2.2 Semantics,[0],[0]
Typing verbal phrases is a once-off computation.,2.2 Semantics,[0],[0]
"Our phrase typing method is similar to prior work on typing relational phrases (Nakashole et al., 2012).",2.2 Semantics,[0],[0]
"Examples of typed phrases are: 〈person〉 died in 〈year〉, 〈person〉 died in 〈location〉, and 〈athlete〉 plays for 〈team〉.",2.2 Semantics,[0],[0]
"Given a triple, we look up the types for the subject and the object and then determine which of the typed phrases are compatible with the current triple.",2.2 Semantics,[0],[0]
"We look up entity types in a knowledge
1http://www.w3.org/TR/rdf-primer/
base containing entities and their types.",2.2 Semantics,[0],[0]
"In particular, we use the NELL entity typing API (Carlson et al., 2010).",2.2 Semantics,[0],[0]
"NELL’s entity typing method has high recall because when entities are not in the knowledge base, it performs on-the-fly type inference using the Web.",2.2 Semantics,[0],[0]
"This is not the case for other options such as (Auer et al., 2007; Bollacker et al., 2008; Hoffart et al., 2011).",2.2 Semantics,[0],[0]
Relation Cardinality.,2.2 Semantics,[0],[0]
"Next, we learn cardinalities of verbal phrases.",2.2 Semantics,[0],[0]
Cardinality refers to how arguments of a given relation relate to one another numerically.,2.2 Semantics,[0],[0]
"We define the relation cardinality of a verb Card(V ), as the average number of expected arguments per given subject.",2.2 Semantics,[0],[0]
"For example, for the relation “died in”, 1 location is expected for each subject.",2.2 Semantics,[0],[0]
"For other relations, the expected number of arguments can be greater than 1 but less than n : n ∈ R, n > 1.",2.2 Semantics,[0],[0]
We approximate n using statistics from the 114m SVO corpus based on the average number of arguments per given first argument.,2.2 Semantics,[0],[0]
"In a once-off computation, we generate cardinality approximations per typed verbal phrase V and its inverse V −1.",2.2 Semantics,[0],[0]
"For example, we generate the cardinality estimates for both: 〈person〉 died in 〈location〉 and for 〈location〉 INVERSE-OF(died in) 〈person〉.",2.2 Semantics,[0],[0]
Synonymous Relations.,2.2 Semantics,[0],[0]
Natural language is diverse.,2.2 Semantics,[0],[0]
Semantically similar phrases can be syntactically different.,2.2 Semantics,[0],[0]
"Therefore, we learn other verbs that can be used to substitute V in SVO.",2.2 Semantics,[0],[0]
"We pre-compute synonymous phrases from the 114m SVO corpus using distributional semantics in the same spirit as (Lin and Pantel, 2001; Nakashole et al., 2012).
",2.2 Semantics,[0],[0]
"Synonymous verbs, relation cardinalities, and entity types enable us to generate alternative fact candidates.",2.2 Semantics,[0],[0]
Truth-finding methods rank fi relative to alternative candidates.,2.3 Alternative Fact Candidates,[0],[0]
"While prior methods assume the alternatives are known apriori, we developed a method for generating alternative fact candidates.",2.3 Alternative Fact Candidates,[0],[0]
"For a given fi, we first identify the fixed argument.",2.3 Alternative Fact Candidates,[0],[0]
"The fixed argument is the argument of the SVO which when fixed, requires finding the fewest number of alternative candidates.",2.3 Alternative Fact Candidates,[0],[0]
"For example, for 〈Einstein〉 died in 〈Princeton〉, the solution is to fix the subject.",2.3 Alternative Fact Candidates,[0],[0]
"This is because the cardinality of 〈person〉 died in 〈location〉 is one (1).
",2.3 Alternative Fact Candidates,[0],[0]
"On the other hand, the cardinality of “INVERSEOF(died in)” is many(n).",2.3 Alternative Fact Candidates,[0],[0]
"In other words, the number of places where a person can be born (one) is much fewer than the number of people that can die in a place (many).",2.3 Alternative Fact Candidates,[0],[0]
"In our example, alternatives are possible places, other than Princeton, where Einstein could have died.",2.3 Alternative Fact Candidates,[0],[0]
For example: 〈Einstein〉 died in 〈Germany〉 or 〈Einstein〉 died in 〈Switzerland〉.,2.3 Alternative Fact Candidates,[0],[0]
"More generally, the fixed argument of fact candidate fi, is defined as follows:
Definition 2 (Fixed Argument) Let Card(V) be the cardinality of V and Card(V −1) be the cardinality of the inverse of V ,",2.3 Alternative Fact Candidates,[0],[0]
"if Card(V ) < Card(V −1), then the fixed argument is the subject, Argfixed(fi)",2.3 Alternative Fact Candidates,[0],[0]
"= S, else it is the object, O.",2.3 Alternative Fact Candidates,[0],[0]
"If Card(V ) == Card(V −1), then both arguments are fixed, one at a time.
",2.3 Alternative Fact Candidates,[0],[0]
We use the fixed argument to define a topic as the fixed argument plus the verb.,2.3 Alternative Fact Candidates,[0],[0]
"Therefore, for the SVO 〈X〉 died in 〈Y〉, the topic “places where X died”, (Argfixed = S), is not the same as the topic “people who died in Y” (Argfixed = O).
",2.3 Alternative Fact Candidates,[0],[0]
"To locate alternatives, we use the topic (Argfixed + V ) as a query.",2.3 Alternative Fact Candidates,[0],[0]
"We search three sources to either locate relevant documents or relevant triples: the Google Web search API, the 114m SVO collection, and the NELL KB.",2.3 Alternative Fact Candidates,[0],[0]
"The SVO collection and the KB return triples, however, the Web search API returns documents.",2.3 Alternative Fact Candidates,[0],[0]
"Therefore, we apply a triple extractor to the retrieved documents.",2.3 Alternative Fact Candidates,[0],[0]
"For all potential alternative triples, we perform type checking to ensure that the arguments of the triples are type-compatible with fi.",2.3 Alternative Fact Candidates,[0],[0]
"Furthermore, we generate an additional query for every synonymous verb sVi, replacing V with sVi.",2.3 Alternative Fact Candidates,[0],[0]
"Example queries are: “Einstein died in”, “Einstein passed in”, etc.",2.3 Alternative Fact Candidates,[0],[0]
"The principle of objective journalism, which is a significant part of journalistic ethics, aims to promote factual and fair reporting, undistorted by emotion or personal bias (Schudson, 1978; Kaplan, 2002).",3 Objectivity and Trustworthiness,[0],[0]
"Objectivity is also required in reference sources such as encyclopedias, scientific publications, and textbooks.",3 Objectivity and Trustworthiness,[0],[0]
"For example, Wikipedia enforces a neutral point-of-view policy (NPOV)2.",3 Objectivity and Trustworthiness,[0],[0]
"Articles violating the NPOV policy are marked
2http://en.wikipedia.org/wiki/Wikipedia:Neutral point of view
to indicate potential bias.",3 Objectivity and Trustworthiness,[0],[0]
"While opinions, emotions, and speculations can also be expressed using objective language, they are often stated using subjective language (Turney et al., 2002; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Wiebe et al., 2004; Liu et al., 2005; Recasens et al., 2013).",3 Objectivity and Trustworthiness,[0],[0]
"For example, consider the following pieces of text:
(S)",3 Objectivity and Trustworthiness,[0],[0]
"Well, I think Obama was born in Kenya because his grandma who lives in Kenya said he was born there.",3 Objectivity and Trustworthiness,[0],[0]
"(O) Theories allege that Obama’s published birth certificate is a forgery, that his actual birthplace is not Hawaii but Kenya.
",3 Objectivity and Trustworthiness,[0],[0]
Text S is a snippet from Yahoo Answers and text O is a snippet from the Wikipedia page titled: “Barack Obama Citizenship Conspiracy Theories”.,3 Objectivity and Trustworthiness,[0],[0]
"S is subjective, expressing the opinion of the author.",3 Objectivity and Trustworthiness,[0],[0]
"On the other hand, O is objective, stating only what has been alleged.",3 Objectivity and Trustworthiness,[0],[0]
"Literature on sentiment analysis (Turney et al., 2002; Liu et al., 2005), subjectivity detection (Riloff and Wiebe, 2003; Wiebe et al., 2004), and bias detection (Yu and Hatzivassiloglou, 2003; Recasens et al., 2013) has developed lexicons for identifying subjective language.",3 Objectivity and Trustworthiness,[0],[0]
"Due to the principle of objective journalism and the requirement of objectivity placed on reference sources, we hypothesize a link between objectivity and trustworthiness as follows.
",3 Objectivity and Trustworthiness,[0],[0]
Hypothesis 1,3 Objectivity and Trustworthiness,[0],[0]
Objective sources are more trustworthy than subjective sources.,3 Objectivity and Trustworthiness,[0],[0]
"Therefore, we can assume that fact candidates stated in objective sources are more likely to be true than those stated in subjective sources.
",3 Objectivity and Trustworthiness,[0],[0]
"To test the validity of the hypothesis, we carried out a study where we solicited human input.",3 Objectivity and Trustworthiness,[0],[0]
"We deployed an annotation study on Amazon Mechanical Turk (MTurk)3, a crowd-sourcing platform for tasks requiring human input.",3.1 Mechanical Turk Study,[0],[0]
Tasks on MTurk are small questionnaires consisting of a description and a set of questions.,3.1 Mechanical Turk Study,[0],[0]
Our study consisted of two independent tasks.,3.1 Mechanical Turk Study,[0],[0]
"The first task was titled “Trustworthiness of News Articles”, where annotators were given a link to a news article and
3http://www.mturk.com
Figure 1:",3.1 Mechanical Turk Study,[0],[0]
"Summary of the results of the annotation study on objectivity and trustworthiness.
",3.1 Mechanical Turk Study,[0],[0]
asked to judge if they thought it was trustworthy or not.,3.1 Mechanical Turk Study,[0],[0]
The second task was titled “Objectivity of News Articles”.,3.1 Mechanical Turk Study,[0],[0]
"For this task, annotators were asked to judge if a given article is objective or subjective.",3.1 Mechanical Turk Study,[0],[0]
For both tasks a third option of “not sure” was provided.,3.1 Mechanical Turk Study,[0],[0]
"We randomly selected 500 news articles from a corpus of about 300,000 news articles obtained from Google News from the topics of Top News, Business, Entertainment, and SciTech.",3.1 Mechanical Turk Study,[0],[0]
"For each task, every article was judged by three annotators.",3.1 Mechanical Turk Study,[0],[0]
This produced a total of 3000 annotations.,3.1 Mechanical Turk Study,[0],[0]
"When we analyzed the output, we accepted a label as valid for a given article if the label was selected by the majority of the judges.",3.1 Mechanical Turk Study,[0],[0]
"Based on this criteria, we obtained a set of 420 articles that were both labeled for trustworthiness and objectivity.
",3.1 Mechanical Turk Study,[0],[0]
A summary of the outcome of the study is shown in Figure 1; 74% of the untrustworthy articles were independently labeled as subjective.,3.1 Mechanical Turk Study,[0],[0]
"On the other hand, 64% of trustworthy articles were independently labeled as objective.",3.1 Mechanical Turk Study,[0],[0]
These results indicate a non-trivial positive correlation between objectivity and trustworthiness.,3.1 Mechanical Turk Study,[0],[0]
We leverage this correlation in our believability computation model.,3.1 Mechanical Turk Study,[0],[0]
"To incorporate objectivity in FactChecker, we require for a given source document, an objectivity score ∈",3.1 Mechanical Turk Study,[0],[0]
"[0, 1], where 0 means the source is subjective and 1 means it is objective.",3.1 Mechanical Turk Study,[0],[0]
"Next, describe our method for automatically determining objectivity of sources.",3.1 Mechanical Turk Study,[0],[0]
We trained a logistic regression classifier to predict the objectivity of a document.,3.2 Automatic Objectivity Detection,[0],[0]
"For training and testing data, we used the labeled data from the Mechanical Turk study.",3.2 Automatic Objectivity Detection,[0],[0]
"We additionally used labeled text from prior work on subjectivity detection (Pang and Lee, 2004).",3.2 Automatic Objectivity Detection,[0],[0]
"This resulted in a total of 4, 600 documents, half subjective and the other half objective.",3.2 Automatic Objectivity Detection,[0],[0]
"We used 4000 documents for
training, 2000 per label.",3.2 Automatic Objectivity Detection,[0],[0]
"The rest of the documents were split into a development set (380) and a test set (220).
",3.2 Automatic Objectivity Detection,[0],[0]
A summary of the features we used is shown in Table 1.,3.2 Automatic Objectivity Detection,[0],[0]
"Features 1-3 refer to lexicons developed by prior methods on subjectivity (Wiebe et al., 2004), sentiment analysis (Liu et al., 2005) and bias detection (Recasens et al., 2013).",3.2 Automatic Objectivity Detection,[0],[0]
Feature 4 refers to part-of-speech tags of the terms found in the document that are also in the lexicons.,3.2 Automatic Objectivity Detection,[0],[0]
"Feature 5 refers to bi-grams that frequently occur (mention frequency of > 10) in the 4, 600 documents.",3.2 Automatic Objectivity Detection,[0],[0]
"The most contributing features were the lexicons, features (1-3) and the frequent bi-grams, feature 5.",3.2 Automatic Objectivity Detection,[0],[0]
We discovered that using frequent bi-gram features instead of uni-grams or bi-grams resulted in higher precision.,3.2 Automatic Objectivity Detection,[0],[0]
"The classifier was able to determine that for example bi-grams such as “think that”, “so funny” and “you thought” are negative features for objectivity.",3.2 Automatic Objectivity Detection,[0],[0]
Evaluation results of our objectivity detector vs. baselines are shown in Table 2.,3.2 Automatic Objectivity Detection,[0],[0]
"FactChecker’s objectivity detector has precision of 0.7814 ± 0.0539, with a 0.9-confidence Wilson score interval (Brown et al., 2001) and this outperforms the baselines.",3.2 Automatic Objectivity Detection,[0],[0]
"Next, we describe how we leverage objectivity into FactChecker’s truthfulness model.",3.2 Automatic Objectivity Detection,[0],[0]
FactChecker computes the believability score of a fact candidate from its: i) objectivity score and (ii) co-mention score.,4 Believability Computation Model,[0],[0]
"In this section we define each of these scores.
",4 Believability Computation Model,[0],[0]
The objectivity score reflects the trustworthiness of sources where a fact candidate is mentioned.,4 Believability Computation Model,[0],[0]
"Given a fact candidate fi, mentioned in a set of documents Di, where each document d ∈
Di has objectivity O(d), fi’s objectivity score is defined as follows:
Definition 3 (Objectivity Score)
O(fi) = log|Di|.
∑ dk∈Di O(dk)
|Di| (1)
We do not use the sum of objectivity of sources as the objectivity score because this enables fact candidates mentioned in many low objectivity sources to have high aggregate objectivity.",4 Believability Computation Model,[0],[0]
"Similarly, we avoid using average objectivity of the sources as it overestimates objectivity of candidates stated in few sources.",4 Believability Computation Model,[0],[0]
A candidate mentioned in 10 sources with 0.9 objectivity should have higher objectivity than a candidate stated in 1 source of 0.9 objectivity.,4 Believability Computation Model,[0],[0]
"In Equation 1, log|Di| addresses this issue.
",4 Believability Computation Model,[0],[0]
The co-mention score aims to ensure that fact candidates mentioned in similar sources have similar believability scores.,4 Believability Computation Model,[0],[0]
"Suppose candidate fi is mentioned in many highly objective sources, another candidate fj is stated in only one highly objective source dk where fi is also mentioned.",4 Believability Computation Model,[0],[0]
Then the believability of fj should be boosted by it being co-mentioned with fi.,4 Believability Computation Model,[0],[0]
"If on the other hand fi and fj were co-mentioned in a subjective source, fj should receive less boost from fi.",4 Believability Computation Model,[0],[0]
"This leads us to the co-mention score µ(fi) of a candidate.
",4 Believability Computation Model,[0],[0]
"Definition 4 (Co-Mention Score)
µ(fi)",4 Believability Computation Model,[0],[0]
"= ρ(fi) + ∑ fj∈F wijµ(fj) (2)
Where ρ(fi) is the normalized mention frequency of fi.",4 Believability Computation Model,[0],[0]
The propagation weight wij controls how much boost is obtained from a co-mentioned candidate.,4 Believability Computation Model,[0],[0]
"We define propagation weight, wij , as the average of the objectivity of the sources that mention both candidates.
",4 Believability Computation Model,[0],[0]
"wij = average O(dk) : dk ∈ (Di ∩Dj) (3)
where O(dk) is the objectivity of document dk, Di and Dj are the sets of documents that mention fi and fj , respectively.",4 Believability Computation Model,[0],[0]
"Notice that we could boost co-mentioned but not related candidates, thereby causing false boosts.",4 Believability Computation Model,[0],[0]
"To remedy this, we only allow wij to be greater than zero if the fact candidates fi and fj are on the same topic.",4 Believability Computation Model,[0],[0]
Recall that the topic is determined by the fixed argument (Definition 2) and the verb.,4 Believability Computation Model,[0],[0]
"Allowing only fact candidates on the same topic to influence each other is important considering that many trivial facts are often repeated in sources of diverse quality.
",4 Believability Computation Model,[0],[0]
"To leverage the inter-dependencies among related co-mentioned fact candidates, we model the solution with a graph ranking method.",4 Believability Computation Model,[0],[0]
"Each fact candidate is a node and there is an edge between each pair of related fact candidate nodes fi and fj , with wij as the edge weight.",4 Believability Computation Model,[0],[0]
"Thus, equation 2 can be reformulated as µ = Mµ, where µ is the co-mention score vector and M is a Markov matrix which is stochastic, irreducible and aperiodic.",4 Believability Computation Model,[0],[0]
"Thus, a power method will converge to a solution in a similar manner to PageRank.",4 Believability Computation Model,[0],[0]
Implementation consists of iteratively applying Equation 2 until the change in the score is less than a threshold .,4 Believability Computation Model,[0],[0]
"The solution is the final co-mention scores of fact candidates.
",4 Believability Computation Model,[0],[0]
"Finally, to compute the believability score of a fact candidate, we linearly combine its objectivity score with its co-mention as follows:
Definition 5 (Believability Score)
β(fi)",4 Believability Computation Model,[0],[0]
"= λO(fi) + (1− λ)µ(fi) (4)
Where λ is a weighting parameter ∈",4 Believability Computation Model,[0],[0]
"[0, 1] which controls the relative importance of the two aspects of FactChecker.",4 Believability Computation Model,[0],[0]
"As we show in our experiments, λ can be robustly chosen within the range of 0.2 to 0.6.",4 Believability Computation Model,[0],[0]
"In our experiments we used λ = 0.6.
",4 Believability Computation Model,[0],[0]
The entire procedure of FactChecker is summarized in Algorithm 1.,4 Believability Computation Model,[0],[0]
We evaluated FactChecker for accuracy.,5 Evaluation,[0],[0]
We define accuracy as the probability of a true fact candidate having a higher believability score than a false candidate.,5 Evaluation,[0],[0]
Let τ(fi),5 Evaluation,[0],[0]
"∈ {T, F} be the truthfulness of a fact candidate fi, accuracy is defined as:
Algorithm 1 FactChecker Input: A set F of fact candidates Input: KB K, SVO corpus C, WebW Output: A set L of rankings ∀fi ∈ F L = ∅",5 Evaluation,[0],[0]
"while F 6= ∅ do
pick fi from F A= getAlternatives(fi,K,C,W) PriorityQueue Li = ∅ for all alternative fact candidates f ′j ∈",5 Evaluation,[0],[0]
A do β(f ′j),5 Evaluation,[0],[0]
"= getBelievabilityScore(f ′j) Li.insert(f ′j , β(f ′ j)) end for β(f i) = getBelievabilityScore(fi) Li.insert(fi, β(fi))",5 Evaluation,[0],[0]
"L ∪ Li Remove fi from F
end while return L
Acc =
∑ (τ(fi)=T :τ(fj)=F ) (β(fi) > β(fj))
",5 Evaluation,[0],[0]
"|{∀(fi, fj) : τ(fi)",5 Evaluation,[0],[0]
"= T ∧ τ(fj) = F}|
Datasets.",5 Evaluation,[0],[0]
We evaluated FactChecker on three datasets: i) KB Fact Candidates:,5 Evaluation,[0],[0]
"The first dataset consists of fact candidates taken from the fact extraction pipeline of a state-of-the-art knowledge base, NELL (Carlson et al., 2010).",5 Evaluation,[0],[0]
"The fact candidates span four different relation types: company acquisitions, book authors, movie directors and athlete teams.",5 Evaluation,[0],[0]
"For each fact candidate, we applied our alternative candidate generation method.",5 Evaluation,[0],[0]
We only considered fact candidates with non-trivial alternative candidate sets; where the alternative candidate set is greater than zero.,5 Evaluation,[0],[0]
"Since all of the baselines we compared against assume alternatives are provided, we apply all methods to the same set of alternative fact candidates discovered by our method.",5 Evaluation,[0],[0]
"Details of this dataset are shown as rows starting with “KB-” in Table 3.
ii)",5 Evaluation,[0],[0]
"Wikipedia Fact Candidates: For the second dataset, we did not restrict the fact candidates to specific topics from a knowledge base, instead we aimed to evaluate all fact candidates about a given entity.",5 Evaluation,[0],[0]
We selected entities from Wikipedia.,5 Evaluation,[0],[0]
"For this, we chose US politicians: all current state senators, all current state governors, and all 44 presidents.",5 Evaluation,[0],[0]
"First, we extracted fact candidates
from the infoboxes of the Wikipedia pages of the entities.",5 Evaluation,[0],[0]
"Second, we applied our alternative candidate generation method to discover alternatives from the Web, SVO corpus, and NELL.",5 Evaluation,[0],[0]
"Details of the resulting dataset are shown in the row “WKP Politicians” in Table 3.
iii) General Knowledge Quiz:",5 Evaluation,[0],[0]
The third dataset consists of questions from a general knowledge quiz 4.,5 Evaluation,[0],[0]
We selected questions from the inventions category.,5 Evaluation,[0],[0]
"Questions are multiple choice, with 4 options per question.",5 Evaluation,[0],[0]
"Thus, from each question, we created one fact candidate and 3 alternative candidates.",5 Evaluation,[0],[0]
Details of the resulting dataset are shown in the row “KWP Quiz” in Table 3.,5 Evaluation,[0],[0]
Baselines.,5 Evaluation,[0],[0]
We compared FactChecker against five baselines: i) Vote counts the number of sources that mention the fact candidate.,5 Evaluation,[0],[0]
ii),5 Evaluation,[0],[0]
TruthFinder is an iterative voting approach where votes are propagated from sources to fact candidates and then back to sources.,5 Evaluation,[0],[0]
"Implemented as described in (Yin et al., 2007).",5 Evaluation,[0],[0]
"iii) Investment is also based on transitive voting, however scores are updated differently.",5 Evaluation,[0],[0]
"A source gets a vote of trust from each candidate it “invests” in, but the vote is weighted by the proportion of trust the source previously “invested” in the candidate relative to other investors.",5 Evaluation,[0],[0]
"Implemented as described in (Pasternack and Roth, 2010).",5 Evaluation,[0],[0]
iv),5 Evaluation,[0],[0]
"PooledInvest is a variation of investment, we report both because in their paper, there was no clear winner among the two variations.",5 Evaluation,[0],[0]
"v) 2-Estimates is a probabilistic model which approximates error rates of sources and fact candidates (Galland et al., 2010).",5 Evaluation,[0],[0]
Figure 2 shows accuracy on KB fact candidates.,5.1 Accuracy on KB Fact Candidates,[0],[0]
"FactChecker achieves accuracy between 70% and 88% and is significantly more accurate than the
4http://www.indiabix.com/general-knowledge/
other approaches on all relations except company acquisitions.",5.1 Accuracy on KB Fact Candidates,[0],[0]
"On book authors, movie directors, and athlete teams, FactChecker outperforms all other approaches by at least 10%, 9%, and 8% respectively.",5.1 Accuracy on KB Fact Candidates,[0],[0]
"On company acquisitions, the different methods achieve similar accuracy, with TruthFinder being the most accurate and FactChecker is 4% behind.",5.1 Accuracy on KB Fact Candidates,[0],[0]
"Company acquisitions also yield the lowest difference between Vote and the highest performing method, of 6%.",5.1 Accuracy on KB Fact Candidates,[0],[0]
"For book authors, movie directors, and athlete teams, the difference between majority Vote and the highest performing method (FactChecker in this case) is 13%, 12%, and 13% respectively.",5.1 Accuracy on KB Fact Candidates,[0],[0]
"To quantify how various aspects of our approach affect overall performance, we studied two variations.",5.2 Accuracy of FactChecker Variations,[0],[0]
The first variation is FC-Objectivity which only uses objectivity to compute believability.,5.2 Accuracy of FactChecker Variations,[0],[0]
"Thus, λ = 1 in Definition 5.",5.2 Accuracy of FactChecker Variations,[0],[0]
"The second variation is FC-CoMention which only uses co-mention scores to compute believability, λ = 0.",5.2 Accuracy of FactChecker Variations,[0],[0]
"The
last variation is the full FactChecker method using both objectivity and co-mentions with λ = 0.6",5.2 Accuracy of FactChecker Variations,[0],[0]
"From Figure 3, it is clear that both the objectivity of sources and the influence of co-mentions contribute to the overall accuracy of FactChecker.",5.2 Accuracy of FactChecker Variations,[0],[0]
Full-fledged FactChecker performs better than both variations.,5.2 Accuracy of FactChecker Variations,[0],[0]
"In most cases, FC-Objectivity performs better than FC-CoMention.",5.2 Accuracy of FactChecker Variations,[0],[0]
"Table 4, column “WKP Politicians”, shows accuracy on Wikipedia fact candidates, with a 0.9- confidence Wilson score interval (Brown et al., 2001).",5.3 Accuracy on Wikipedia Fact Candidates,[0],[0]
For this dataset we again see FactChecker outperforming the other methods under comparison.,5.3 Accuracy on Wikipedia Fact Candidates,[0],[0]
"On this dataset, FactChecker has a accuracy of 0.9 ± 0.07 and a 5% accuracy advantage over the other methods.",5.3 Accuracy on Wikipedia Fact Candidates,[0],[0]
"The second best performance comes from the FC-Objectivity variation, with accuracy of 0.88± 0.08.",5.3 Accuracy on Wikipedia Fact Candidates,[0],[0]
"Table 4, column “GK Quiz ”, shows accuracy on the general knowledge quiz fact candidates.",5.4 Accuracy on General Knowledge Quiz,[0],[0]
"On this dataset, FactChecker and its objectivity-only variation (FC-objectivity) have the highest accuracy of 87%.",5.4 Accuracy on General Knowledge Quiz,[0],[0]
Notice that this dataset was the only one where we did not generate the alternative fact candidates.,5.4 Accuracy on General Knowledge Quiz,[0],[0]
"Instead, we took the options of the multiple choice questions as alternatives.",5.4 Accuracy on General Knowledge Quiz,[0],[0]
"Since the quiz is meant to be taken by humans, the alternatives are often very close, plausible answers.",5.4 Accuracy on General Knowledge Quiz,[0],[0]
"Yet even in this difficult setting, we see FactChecker outperforming the baselines.
",5.4 Accuracy on General Knowledge Quiz,[0],[0]
"Sample fact candidates, with ranked alternatives from all three datasets are shown in Table 5.
",5.4 Accuracy on General Knowledge Quiz,[0],[0]
Figure 4: Effect of λ of FactChecker.,5.4 Accuracy on General Knowledge Quiz,[0],[0]
We analyzed the effect of the selection of lambda λ (see Definition 5) on FactChecker’s performance.,5.5 Parameter Sensitivity,[0],[0]
The result of this analysis is shown in Figure 4.,5.5 Parameter Sensitivity,[0],[0]
FactChecker is insensitive to this parameter when λ is varied from 0.2 to 0.6.,5.5 Parameter Sensitivity,[0],[0]
"Therefore, lambda can be robustly chosen within this range.",5.5 Parameter Sensitivity,[0],[0]
"Overall, from these results we make the following observations: i) Majority vote is a competitive baseline; ii) Iterative voting-based methods provide slight improvements on majority vote.",5.6 Discussion,[0],[0]
This is due to the fact that at the core of iterative voting is still the assumption that fact candidates mentioned in many sources are more likely to be true.,5.6 Discussion,[0],[0]
"Therefore, for both majority vote and iterative voting, when mention frequencies of various alternatives are the same, accuracy suffers.",5.6 Discussion,[0],[0]
"Based on these observations, it is clear that truthfinding solutions need to incorporate fine-grained content-aware features outside of external votes.",5.6 Discussion,[0],[0]
FactChecker takes a step in this direction by incorporating the document-level feature of objectivity.,5.6 Discussion,[0],[0]
"There is a fairly small body of work on truthfinding (Yin et al., 2007; Galland et al., 2010; Pasternack and Roth, 2010; Li et al., 2011; Yin and Tan, 2011; Zhao et al., 2012; Pasternack and Roth, 2013).",6 Related Work,[0],[0]
"The method underlying most truth-finding algorithms is iterative transitive voting (Yin et al., 2007; Galland et al., 2010; Pasternack and Roth, 2010; Li et al., 2011).",6 Related Work,[0],[0]
Fact candidates are initialized with a score.,6 Related Work,[0],[0]
Trustworthiness of sources is then computed from the believability of the fact candidates they mention.,6 Related Work,[0],[0]
"In return, believability of candidates is recomputed based on the trustworthi-
ness of their sources.",6 Related Work,[0],[0]
This process is repeated over several iterations until convergence.,6 Related Work,[0],[0]
"(Yin et al., 2007) was the first to implement this idea, subsequent work improved upon iterative voting in several directions.",6 Related Work,[0],[0]
"(Dong et al., 2009) incorporates copying-detection; giving high trust to sources that are independently authored.",6 Related Work,[0],[0]
"(Galland et al., 2010) approximates error rates of sources and fact candidates.",6 Related Work,[0],[0]
"(Pasternack and Roth, 2010) introduces prior knowledge in the form of linear programming constraints in order to ensure that the truth discovered is consistent with what is already known.",6 Related Work,[0],[0]
"(Yin and Tan, 2011) introduces supervision by using ground truth facts so that sources that disagree with the ground truth are penalized.",6 Related Work,[0],[0]
"(Li et al., 2011) uses search engine APIs to gather additional evidence for believability of fact candidates.",6 Related Work,[0],[0]
"WikiTrust (Adler and Alfaro, 2007) is a content-aware but domain-specific method.",6 Related Work,[0],[0]
It computes trustworthiness of wiki authors based on the revision history of the articles they have authored.,6 Related Work,[0],[0]
"Motivated by interpretability of probabilistic scores, two recent papers addressed the truth-finding problem as a probabilistic inference problem over the sources and the fact candidates (Zhao et al., 2012; Pasternack and Roth, 2013).",6 Related Work,[0],[0]
"Truth-finders based on textual entailment such as TruthTeller (Lotan et al., 2013) determine if a sentence states something or not.",6 Related Work,[0],[0]
"The focus is on understanding natural language, including the use of negation.",6 Related Work,[0],[0]
"This is similar to the goal of fact extraction (Banko et al., 2007; Carlson et al., 2010; Fader et al., 2011; Nakashole et al., 2011; Del Corro and Gemulla, 2013).
",6 Related Work,[0],[0]
"In a departure from prior work, our method leverages language of sources in its believability
computation model.",6 Related Work,[0],[0]
"Furthermore, we introduced a co-mention score which is designed to avoid potential false boots among fact candidates.",6 Related Work,[0],[0]
"Additionally, we developed a method for generating alternative fact candidates.",6 Related Work,[0],[0]
Prior methods assume these are readily available.,6 Related Work,[0],[0]
"Only (Li et al., 2011) uses the Web to identify alternatives, however, this is only done after manually specifying the fixed argument.",6 Related Work,[0],[0]
"In contrast, we introduced a method for identifying the fixed argument based on relation cardinalities learned from SVO statistics.",6 Related Work,[0],[0]
"In this paper, we presented FactChecker, a language-aware approach to truth-finding.",7 Conclusion,[0],[0]
"In contrast to prior approaches, which rely on external votes, FactChecker includes objectivity of sources in its believability computation model.
",7 Conclusion,[0],[0]
FactChecker can be seen as a first step towards language-aware truth-finding.,7 Conclusion,[0],[0]
"Future directions include using more sentence-level features such the use of hedges, assertive verbs, and factive verbs.",7 Conclusion,[0],[0]
"These types of words fall into a class of words used to express certainties, speculations or doubts — these are important cues that FactChecker can leverage.",7 Conclusion,[0],[0]
We thank members of the NELL team at CMU for their helpful comments.,Acknowledgments,[0],[0]
This research was supported by DARPA under contract number FA8750-13-2-0005.,Acknowledgments,[0],[0]
"This paper introduces FactChecker, language-aware approach to truth-finding.",abstractText,[0],[0]
"FactChecker differs from prior approaches in that it does not rely on iterative peer voting, instead it leverages language to infer believability of fact candidates.",abstractText,[0],[0]
"In particular, FactChecker makes use of linguistic features to detect if a given source objectively states facts or is speculative and opinionated.",abstractText,[0],[0]
"To ensure that fact candidates mentioned in similar sources have similar believability, FactChecker augments objectivity with a co-mention score to compute the overall believability score of a fact candidate.",abstractText,[0],[0]
Our experiments on various datasets show that FactChecker yields higher accuracy than existing approaches.,abstractText,[0],[0]
Language-Aware Truth Assessment of Fact Candidates,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 151–160, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
151",text,[0],[0]
"Perception is a critical component of an intelligence architecture that converts raw sensor observations to a suitable representation for the task
that the robot is to perform.",1 INTRODUCTION,[0],[0]
Models of environments vary significantly depending on the application.,1 INTRODUCTION,[0],[0]
"For example, a robotic manipulator may need to model the objects in its environment with their six degree-of-freedom pose for grasping and dexterous manipulation tasks, whereas a self-driving car may need to model the dynamics of the environment in addition to domain-specific semantics such as stop signs, sidewalks and pedestrians etc. to safely navigate through the environment.
",1 INTRODUCTION,[0],[0]
The ability of robots to perform complex tasks is linked to the richness of the robot’s world model.,1 INTRODUCTION,[0],[0]
"As inferring exhaustively detailed world representations is impractical, it is common to infer representations which are highly specific to the task that the robot is to perform.",1 INTRODUCTION,[0],[0]
"However, in collaborative domains as we move towards more complex bi-directional interactions, manipulation tasks, and the environments, it becomes unclear how to best represent the environment in order to facilitate planning and reasoning for a wide distribution of tasks.",1 INTRODUCTION,[0],[0]
"As shown in the Figure 1, modeling the affordance between the chips can and its lid would be unnecessary for the task of picking up the mustard sauce bottle and vice versa.",1 INTRODUCTION,[0],[0]
"Inferring exhaustively detailed models of all of the objects in the environment is computationally expensive and inconsequential for the individual tasks, and inhibits real-time interaction with these collaborative robots.
",1 INTRODUCTION,[0],[0]
The utility of collaborative manipulators is also highly dependent on the speed and accuracy of communication between the human operator and the robot.,1 INTRODUCTION,[0],[0]
Natural language interfaces provide intuitive and muti-resolution means to interact with the robots in shared realms.,1 INTRODUCTION,[0],[0]
"In this work, we propose learning a model of language and perception that can adapt the configurations of the perception pipeline according to the task in order to infer representations that are necessary and suffi-
cient to facilitate planning and grounding for the intended task.",1 INTRODUCTION,[0],[0]
e.g. the top-right image in the Figure 1 shows the adaptively inferred world model pertaining to the instruction “pick up the leftmost blue gear” which is different than the one inferred for the instruction “pick up the largest red object”.,1 INTRODUCTION,[0],[0]
The algorithms and models presented in this paper span the topics that include robot perception and natural language understanding for human-robot interaction.,2 BACKGROUND,[0],[0]
Perception is a central problem in the the field of situated robotics.,2 BACKGROUND,[0],[0]
"Consequently, a plenty of research has focused on developing representations that can faciliate planning and reasoning for highly specific situated tasks.",2 BACKGROUND,[0],[0]
"These representations vary significantly depending on the application, from two-dimensional costmaps (Elfes, 1987), volumetric 3D voxel representations (Hornung et al., 2013, 2010), primitive shape based object approximations (Miller et al., 2003; Huebner and Kragic, 2008) to more rich representations that model high level semantic properties (Galindo et al., 2005; Pronobis and Jensfelt, 2012), 6 DOF pose of the objects of interest (Hudson et al., 2012) or affordances between objects (Daniele et al., 2017).",2 BACKGROUND,[0],[0]
"Since inferring exhaustively detailed world models is impractical, one solution is to design perception pipelines that infer task relevant world models (Eppner et al., 2016; Fallon et al., 2014).",2 BACKGROUND,[0],[0]
"Inferring efficient models that can support reason-
ing and planning for a wide distribution of tasks remains an open research question.
",2 BACKGROUND,[0],[0]
Natural language interfaces provides intutive and multi-resolution means to interact with the collaborative robots.,2 BACKGROUND,[0],[0]
"Contemporary models (Tellex et al., 2011; Howard et al., 2014; Boularias et al., 2015; Matuszek et al., 2013) frame the problem of language understanding as a symbol grounding problem (Harnad, 1990).",2 BACKGROUND,[0],[0]
"Specifically, of inferring correspondences between the linguistic constituents of the instruction and the symbols that represent perceived entities in the robot’s environment such as objects and regions or desired actions that the robot can take.",2 BACKGROUND,[0],[0]
"(Howard et al., 2014) frames this problem as one of inference in a probabilistic graphical model called a Distributed Correspondence Graph (DCG).",2 BACKGROUND,[0],[0]
This model leverages the hierarchical structure of the syntactically parsed instruction and conditional independence assumptions across constituents of a discrete symbol space to improve the run-time of probabilistic inference.,2 BACKGROUND,[0],[0]
"Other variations include the Hierarchical DCG (Propp et al., 2015) and Adaptive DCG (Paul et al., 2016) to further improve the run-time performance in cluttered environments with known environment models.",2 BACKGROUND,[0],[0]
"Recently, these models have been used to augment perception and representations.",2 BACKGROUND,[0],[0]
"(Daniele et al., 2017) uses DCG for supplementing perception with linguistic information for efficiently inferring kinematic models of articulated objects.",2 BACKGROUND,[0],[0]
"(Duvallet et al., 2014;
Hemachandra et al., 2015) use DCG to augment the representations by exploiting information in language instruction to build priors over the unknown parts of the world.",2 BACKGROUND,[0],[0]
A limitation of current applications of probabilistic graphical models for natural language symbol grounding is that they do not consider how to efficiently convert observations or measurements into sufficiently detailed representation suitable for inference.,2 BACKGROUND,[0],[0]
"We propose to use DCG for the problem of adapting the perception pipelines for inferring task optimal representations.
",2 BACKGROUND,[0],[0]
"Our work is most closely related to that of (Matuszek et al., 2013).",2 BACKGROUND,[0],[0]
Their work presents an approach for jointly learning the language and perception models for grounded attribute learning.,2 BACKGROUND,[0],[0]
Their model infers the subset of objects based on color and shape which satisfy the attributes described in the natural language description.,2 BACKGROUND,[0],[0]
"Similarly, (Hu et al., 2016) proposes deep learning based approach to directly segment objects in RGB images that are described by the instruction.",2 BACKGROUND,[0],[0]
"We differentiate our approach by expanding the diversity and complexity of perceptual classifiers, enabling verbs to modify object representations, and presenting an end-to-end approach to representation adaptation and symbol grounding using computationally efficient probabilistic graphical models.",2 BACKGROUND,[0],[0]
"In the following sections we introduce our approach to adapting perception pipelines, define our experiments, and present results against a suitable baseline.",2 BACKGROUND,[0],[0]
We describe the problem of understanding natural language instructions as one of probabilistic inference where we infer a distribution of symbols that express the intent of the utterance.,3 TECHNICAL APPROACH,[0],[0]
"The meaning of the instruction is taken in the context of a symbolic representation (Γ), observations (zt) and a representation of the language used to describe the instruction (Λ).",3 TECHNICAL APPROACH,[0],[0]
"A probabilistic inference using a symbolic representation that is described by the space of trajectories X (t) that the robot may take takes the form of equation:
",3 TECHNICAL APPROACH,[0],[0]
"x(t)∗ = arg max x(t)∈X(t) p(x(t)|Λ, zt) (1)
Solving this inference problem is computationally intractable when the space of possible trajectories is large.",3 TECHNICAL APPROACH,[0],[0]
"Contemporary approaches (Tellex
et al., 2011; Howard et al., 2014) frame this problem as a symbol grounding problem, i.e. inferring the most likely set of groundings (Γs∗) given a syntactically parsed instruction Λ = {λ1, ..., λm} and the world model Υ.
Γs∗ = arg max γ1...γn∈Γs p(γ1...γn|Λ,Υ) (2)
",3 TECHNICAL APPROACH,[0],[0]
"Here, the world model Υ is a function of the constructs of the robot’s perception pipeline (P ), and the raw observations zt.
",3 TECHNICAL APPROACH,[0],[0]
Υ,3 TECHNICAL APPROACH,[0],[0]
"≈ f(P, zt) (3)
",3 TECHNICAL APPROACH,[0],[0]
"The groundings Γs are symbols that represent objects, their semantic properties, regions derived from the world model, and robot actions and goals such as grasping the object of interest or navigating to a specific region in the environment.",3 TECHNICAL APPROACH,[0],[0]
"The set of all groundings Γs = {γ1, γ2, ..., γn} is called as the symbol space.",3 TECHNICAL APPROACH,[0],[0]
Thus the symbol space forms a finite space of interpretations in which the instruction will be grounded.,3 TECHNICAL APPROACH,[0],[0]
The DCG is a probabilistic graphical model of the form described in equation 2.,3 TECHNICAL APPROACH,[0],[0]
The model relates the linguistic components λi ∈ Λ to the groundings γj ∈,3 TECHNICAL APPROACH,[0],[0]
Γs through the binary correspondence variables φij ∈ Φ. DCG facilitates inferring the groundings at a parent phrase in the context of the groundings at its child phrases Φci.,3 TECHNICAL APPROACH,[0],[0]
"Formally, DCG searches for the most likely correspondence variables Φ∗ in the context of the groundings γij , phrases λi, child correspondences",3 TECHNICAL APPROACH,[0],[0]
"Φci and the world model Υ by maximizing the product of individual factors.
Φ∗",3 TECHNICAL APPROACH,[0],[0]
= arg max φij∈Φ |Λ|∏ i=1,3 TECHNICAL APPROACH,[0],[0]
"|Γs|∏ j=1 p(φij |γij , λi,Φci,Υ) (4)
Inferred correspondence variables Φ∗ represent the expression of the most likely groundings Γs∗.",3 TECHNICAL APPROACH,[0],[0]
"The factors in the equation 4 are approximated by log-linear models Ψ:
Φ∗ = arg max φij∈Φ |Λ|∏ i=1",3 TECHNICAL APPROACH,[0],[0]
"|Γs|∏ j=1 Ψ(φij , γij , λi,Φci,Υ) (5) Model training involves learning the log-linear factors from the labeled data relating phrases with true groundings.",3 TECHNICAL APPROACH,[0],[0]
Inference process involves searching for the set of correspondence variables that satisfy the above equation.,3 TECHNICAL APPROACH,[0],[0]
"The run-time performance of probabilistic inference with the DCG
is positively correlated with the complexity of the world model Υ. This is because the size of the symbolic representation Γs increases with the number of objects in the environment representation.",3 TECHNICAL APPROACH,[0],[0]
"Recognizing that some objects (and the symbols based on those objects) are inconsequential to the meaning of the instruction, we consider the optimal representation of the environment Υ∗ as one which is necessary and sufficient to solve equation 5.",3 TECHNICAL APPROACH,[0],[0]
"Thus we hypothesize that the time to solve equation 6 will be less than that for the equation 5.
Φ∗",3 TECHNICAL APPROACH,[0],[0]
= arg max φij∈Φ |Λ|∏ i=1,3 TECHNICAL APPROACH,[0],[0]
|Γs|∏,3 TECHNICAL APPROACH,[0],[0]
"j=1 Ψ(φij , γij , λi,Φci,Υ ∗)
(6) Typically the environment model Υ is computed by a perception module P from a set of observations z1:t = {z1 . . .",3 TECHNICAL APPROACH,[0],[0]
zt}.,3 TECHNICAL APPROACH,[0],[0]
In cluttered environments we assume that inferring an exhaustively detailed representation of the world that satisfies all possible instructions is impractical for real-time human-robot interactions.,3 TECHNICAL APPROACH,[0],[0]
We propose using language as mean to guide the generation of these necessary and sufficient environment representations Υ∗ in turn making it a task adaptive process.,3 TECHNICAL APPROACH,[0],[0]
"Thus we define Υ∗ inferred from a single observation as:
Υ∗ ≈ f(P, zt,Λ) (7)
where P denotes the perception pipeline of the robotic intelligence architecture.",3 TECHNICAL APPROACH,[0],[0]
We adapt DCG to model the above function by creating a novel class of symbols called as perceptual symbols ΓP .,3 TECHNICAL APPROACH,[0],[0]
Perceptual symbols are tied to their corresponding elements in the perception pipeline.,3 TECHNICAL APPROACH,[0],[0]
i.e. to the vision algorithms.,3 TECHNICAL APPROACH,[0],[0]
"Since this grounding space is independent of the world model Υ, the random variable used to represent the environment is removed from equation 5.",3 TECHNICAL APPROACH,[0],[0]
"We add a subscript p to denote that we are reasoning in the perceptual grounding space.
Φ∗",3 TECHNICAL APPROACH,[0],[0]
= arg max φij∈Φ |Λ|∏ i=1,3 TECHNICAL APPROACH,[0],[0]
"|ΓP |∏ j=1 Ψ(φij , γij , λi,Φci) (8)
Equation 8 represents the proposed model which we refer to as the language-perception model (LPM).",3 TECHNICAL APPROACH,[0],[0]
It infers the symbols that inform the perception pipeline configurations given a natural language instruction describing the task.,3 TECHNICAL APPROACH,[0],[0]
"The
space of symbols ΓP describe all possible configurations of the perception pipeline.",3 TECHNICAL APPROACH,[0],[0]
"For example, as shown in the Figure 1, for the instruction “pick up the leftmost blue gear”, we may need elements in our pipeline that can detect blue objects and gears.",3 TECHNICAL APPROACH,[0],[0]
"Detecting green objects, spherical shapes, or sixdimensional pose of the chips can object would not be necessary to generate the symbols necessary for the robot to perform the instruction.
",3 TECHNICAL APPROACH,[0],[0]
"We assume that the perception pipeline (P ) is populated with a set of elements E = {E1, ..., En} such that each subset Ei ∈ E represents a set of algorithms that are responsible for inferring a specific property of an object.",3 TECHNICAL APPROACH,[0],[0]
e.g. a red colordetection algorithm would be a member of the color detector family responsible for inferring the semantic property “color” of the object.,3 TECHNICAL APPROACH,[0],[0]
While a six degree-of-freedom (DOF) pose detection algorithm would be a member of the pose detector family.,3 TECHNICAL APPROACH,[0],[0]
"More generally, E can be defined as: E = {e1, e2, ..., em}.",3 TECHNICAL APPROACH,[0],[0]
"With these assumptions, we define our independent perceptual symbols as:
ΓIDP = {γei |ei ∈ E} (9)
We can imagine that these symbols would be useful to ground simple phrases such as ”the red object” or ”the ball” etc. where the phrases refer to a single property of the object.",3 TECHNICAL APPROACH,[0],[0]
In the more complicated phrases such as ”the red ball” or ”the blue box” we have a joint expression of properties.,3 TECHNICAL APPROACH,[0],[0]
"i.e. we are looking for objects which maximize the joint likelihood p(red, sphere|o).",3 TECHNICAL APPROACH,[0],[0]
Since these properties are independent we can infer them separately for every object ok ∈,3 TECHNICAL APPROACH,[0],[0]
"O. However, we can represent the above joint likelihood expression as p(red, sphere) = p(red)p(sphere|red).",3 TECHNICAL APPROACH,[0],[0]
"In this case, it allows conditioning the evaluation of sphere detection on only a subset of objects which were classified as being red by the red detector.",3 TECHNICAL APPROACH,[0],[0]
"To add this degree of freedom in the construction of the perception pipeline, we define additional set of symbols which we refer to as conditionally dependent perceptual symbols:
ΓCDP = {γei,ej |ei, ej ∈ E ; i 6= j} (10)
",3 TECHNICAL APPROACH,[0],[0]
"The expression of the symbol γei,ej refers to running the element ei from the perception pipeline on the subset of objects which were classified positive by the element ej .",3 TECHNICAL APPROACH,[0],[0]
"Finally the complete perceptual symbol space is:
ΓP = {ΓIDP ∪ ΓCDP } (11)",3 TECHNICAL APPROACH,[0],[0]
Herein with our experiments we demonstrate the utility of our language perception model for the task of grounded language understanding of the manipulation instructions.,4 EXPERIMENTAL DESIGN,[0],[0]
"As shown in Figure 3 the process involves two distinct inferences: Inferring the perceptual groundings given a language instruction ( eq. 8 ), and inferring high level motion planning constraints given the language and the generated world model ( eq. 5 and eq. 6 ).",4 EXPERIMENTAL DESIGN,[0],[0]
"In this section we describe our assumptions, and define the distinct symbolic representations used in our experiments for each of the above tasks.",4 EXPERIMENTAL DESIGN,[0],[0]
We then discuss our instruction corpus and the details of the individual experiments.,4 EXPERIMENTAL DESIGN,[0],[0]
For our experiments a Rethink Robotics Baxter Research Robot is placed behind a table.,Robot and the Environment,[0],[0]
The robot is assumed to perceive the environment using a head-mounted RGB-D sensor.,Robot and the Environment,[0],[0]
"Robot’s work space is populated using objects from the standard YCB dataset (Berk Calli, 2017), custom 3D printed ABS plastic objects, and multicolored rubber blocks.",Robot and the Environment,[0],[0]
We define the world complexity in terms of the number of objects present on the table in the robot’s field of view.,Robot and the Environment,[0],[0]
The world complexity ranges from 15 to 20 in our experiments.,Robot and the Environment,[0],[0]
The symbolic representation defines the space of symbols or meanings in which the natural language instruction will be grounded or understood.,Symbolic Representation,[0],[0]
As mentioned before we define two distinct sets of symbols in our experiments.,Symbolic Representation,[0],[0]
"ΓP defines the set of perceptual symbols which are used by the language perception model, and ΓS defines the set of symbols which are used by the symbol grounding model.
ΓP is a function of the elements E of the perception pipeline.",Symbolic Representation,[0],[0]
The elements ei ∈ E in our perception pipeline are selected such that they can model the robot’s environment with a spectrum of semantic and metric properties which will be necessary towards performing symbol grounding and planning for all of the instructions in our corpus.,Symbolic Representation,[0],[0]
"In our experiment we define E as:
E = {C ∪ G ∪ L ∪ B ∪ R ∪ P} (12)
Here, C is a set of color detectors, G is a set of geometry detectors, L is a set of object label detectors, B is a set of bounding box detectors, R
is a set of region detectors, and P is a set of pose detectors.
",Symbolic Representation,[0],[0]
C = { cdi | i ∈ color} G = { gdi | i ∈ geometry} L = { ldi | i ∈ label} B = { bdi,Symbolic Representation,[0],[0]
| i ∈ bbox} R = { rdi | i ∈ region} P = { pdi |,Symbolic Representation,[0],[0]
"i ∈ pose}
(13)
where color = {red, green, blue, white, yellow, orange}, geometry = {sphere, cylinder, cuboid}, label = {crackers box, chips can, pudding box, master chef can, bleach cleanser, soccer ball, mustard sauce bottle, sugar packet}, bbox = {non-oriented, oriented }, region = {left, right, center}, pose = { 3 DOF, 6 DOF }.",Symbolic Representation,[0],[0]
"Given the perception elements defined in the equation 13, we define the independent perceptual groundings ( ΓIDP ) previously defined in equation 9 as follows:
ΓC = {γcdi | cdi ∈ C} ΓG = {γgdi | gdi ∈ B} ΓL = {γldi | ldi ∈ L} ΓB = {γbdi | bdi ∈ B} ΓR = {γrdi | rdi ∈ R} ΓP = {γpdi | pdi ∈ P}
(14)
",Symbolic Representation,[0],[0]
"ΓIDP = { ΓC ∪ ΓG ∪ ΓL ∪ ΓB ∪ ΓR ∪ ΓP} (15)
",Symbolic Representation,[0],[0]
"We define the conditionally dependent perceptual groundings ( ΓCDP ) previously defined in equation 10 as following:
ΓGC = {γ(gdi,cdj) | gdi ∈ G, cdj ∈ C} ΓLC = {γ(ldi,cdj) | ldi ∈ L, cdj ∈ C} ΓPC = {γ(pdi,cdj) | pdi ∈ P, cdj ∈ C} ΓPG = {γ(pdi,gdj)",Symbolic Representation,[0],[0]
"| pdi ∈ P, gdj ∈ G} ΓPL = {γ(pdi,ldj)",Symbolic Representation,[0],[0]
"| pdi ∈ P, ldj ∈ L}
(16)
ΓCDP = { ΓGC ∪ ΓLC ∪ ΓPC ∪ ΓPG ∪ ΓPL} (17)
",Symbolic Representation,[0],[0]
These symbols provide us the ability to selectively infer desired properties in the world.,Symbolic Representation,[0],[0]
"Above presented independent and conditionally dependent symbols together cover the complete space of perceptual symbols used by the LPM:
ΓP = {ΓIDP ∪ ΓCDP } (18)
Algorithmic details of the percepion elements are as follows : A single RGB point cloud is fed in as a raw sensor observation to the pipeline.",Symbolic Representation,[0],[0]
"A RANSAC (Fischler and Bolles, 1981) based 3D plane detection technique is used for segmenting the table-top and the objects.",Symbolic Representation,[0],[0]
HSV colorspace is used for detecting colors.,Symbolic Representation,[0],[0]
RANSAC,Symbolic Representation,[0],[0]
based model fitting algorithms form the core of the geometry detectors.,Symbolic Representation,[0],[0]
A 4 layer ( 256 - 128 - 64 - 32 ) feed forward neural network is trained to infer the semantic labels of the objects.,Symbolic Representation,[0],[0]
It takes in a 32 x 32 RGB image and infers a distribution over 8 unique YCB object classes.,Symbolic Representation,[0],[0]
A PCA based oriented bounding box estimation algorithm is used to approximate the 6 DOF pose for the individual objects.,Symbolic Representation,[0],[0]
"Algorithms are implemented using OpenCV and PCL library (Rusu and Cousins, 2011).
",Symbolic Representation,[0],[0]
"The space of symbols for the symbol grounding model is similar to the representation defined in (Paul et al., 2016).",Symbolic Representation,[0],[0]
"This space uses symbols to represent objects in the world model (ΓO), semantic object labels (ΓL), object color(ΓC), object geometry(ΓG) regions in the world(ΓR), spatial relationships (ΓSR) and finally high level planning constraints that define the end goal (ΓPC).",Symbolic Representation,[0],[0]
The inferred constraints forms an input to a planning algorithm that can then generate trajectories to accomplish the desired task.,Symbolic Representation,[0],[0]
"Thus the complete symbol space for the symbol grounding model is:
ΓS = { ΓO∪ΓL∪,ΓC∪ΓG∪ΓR∪ΓSR∪ΓPC} (19)",Symbolic Representation,[0],[0]
"For training and testing the performance of the system we generate an instruction corpus using the linguistic patterns similar to that described in (Paul et al., 2016).",Corpus,[0],[0]
The corpus used in our experiments consists of 100 unique natural language instructions.,Corpus,[0],[0]
Details of the grammar extracted from this corpus is described in the appendix.,Corpus,[0],[0]
Each instruction describes a manipulation command to the robot while referring to the objects of interest using their semantic or metric properties.,Corpus,[0],[0]
e.g. “pick up the green cup” or “pick up the biggest blue object”.,Corpus,[0],[0]
If multiple instances of the same objects are present in the robot’s work space then the reference resolution is achieved by using spatial relationships to describe the object of interest.,Corpus,[0],[0]
"e.g.“the leftmost blue cube” or “rightmost red object” etc.
",Corpus,[0],[0]
"As shown in Figure 2, the instructions in the corpus are in the form of syntactically parsed trees.
",Corpus,[0],[0]
Each instruction is generated in the context of a specific table-top object arrangement.,Corpus,[0],[0]
Thus each instruction is associated with a pair of RGB-D image.,Corpus,[0],[0]
"A total of 10 unique table-top arrangements are used to generate the set of 100 instructions.
",Corpus,[0],[0]
One copy of the corpora is annotated for training LPM using (ΓP ) while another for training the symbol grounding model using (ΓS).,Corpus,[0],[0]
"The annotations for LPM corpus are selected such that that the perception pipelines configured using the annotated groundings would generate the optimal world representations that are necessary and sufficient to support grounding and planning for the given tasks.
",Corpus,[0],[0]
We have instructions with varying complexity in our corpus.,Corpus,[0],[0]
The instruction complexity from the perception point of view is quantified in terms of the total number of perceptual groundings expressed at the root level.,Corpus,[0],[0]
"e.g. “pick up the ball” is relatively a simple instruction with only single grounding expressed at the root level, while “pick up the blue cube and put the blue cube near the crackers box” is a more complicated instruction having seven groundings expressed at the root level.",Corpus,[0],[0]
This number was found to vary in the range of one to seven in our corpus.,Corpus,[0],[0]
We structure our experiments to validate two claims.,Experiments and Metrics,[0],[0]
The first claim is that adaptively inferring the task optimal representations reduce the perception run-time by avoiding exhaustively detailed uniform modeling of the world.,Experiments and Metrics,[0],[0]
The second claim is that reasoning in the context of these optimal representations also reduces the inference run-time of the symbol grounding model.,Experiments and Metrics,[0],[0]
An outline of our experiments is illustrated in Figure 3.,Experiments and Metrics,[0],[0]
"In the first experiment, we study the root-level inference accuracy of LPM ( groundings expressed at the root level of the phrase ) as a function of the gradual increase in the training fraction.",Experiments and Metrics,[0],[0]
"For each
value of training fraction in the range [ 0.2 , 0.9 ] increasing with a step of 0.1, we perform 15 validation experiments.",Experiments and Metrics,[0],[0]
The training data is sampled randomly for every individual experiment.,Experiments and Metrics,[0],[0]
"Additionally, we perform a leave-one-out cross validation experiment.",Experiments and Metrics,[0],[0]
"We use the inferences generated by the leave-one-out cross validation experiments as inputs to drive the adaptive perception for each instruction.
",Experiments and Metrics,[0],[0]
"In the second experiment, we compare the cumulative run-time of LPM inference ( eq. 8 ) and adaptive perception ( T1+T2 ) against the run-time for complete perception ( T4 ) - our baseline, for increasingly complex worlds.
",Experiments and Metrics,[0],[0]
"In the third experiment, we compare the inference time of the symbol grounding model reasoning in the context of the adaptively generated optimal world models ( T3, eq. 6 ) against the inference time of the same model but when reasoning in the context of the complete world models ( T5, eq. 5 ).",Experiments and Metrics,[0],[0]
We also check whether the planning constraints inferred in both cases match the ground truth or not.,Experiments and Metrics,[0],[0]
Experiments are performed on a system running a 2.2 GHz Intel Core i7 CPU with 16 GB RAM.,Experiments and Metrics,[0],[0]
This section presents the results obtained for the above mentioned three experiments.,5 RESULTS,[0],[0]
"Specifically, the learning characteristics of LPM, the impact of LPM on the perception run-time, and the impact the adaptive representations on the symbol grounding run-time.
",5 RESULTS,[0],[0]
Leftmost graph in the Figure 4 shows the results of the first experiment.,5 RESULTS,[0],[0]
We can see that the inference accuracy grows as a function of a gradual increase in the training data.,5 RESULTS,[0],[0]
"A growing trend is an indicator of the language diversity in the corpus.
",5 RESULTS,[0],[0]
"Mean inference accuracy starts at 39.25%±5 for k = 0.2 and it reaches 84% for leave-one-out cross validation experiment ( k = 0.99 ).
",5 RESULTS,[0],[0]
Middle graph in the Figure 4 shows the result of the second experiment.,5 RESULTS,[0],[0]
We can clearly see that the run-time for complete perception grows with the world complexity while the run-time of adaptive perception stays nearly flat and is significantly lower in all cases.,5 RESULTS,[0],[0]
"Since the adaptive perception run-time varies according to the task, we see bigger error bars.",5 RESULTS,[0],[0]
"The drop in the complete perception run-time for world complexity of 20 is justifiable as the run-time of our geometry detection algorithm was proportional to the size of the individual objects, and all of the objects for that example world were smaller than other examples.
",5 RESULTS,[0],[0]
Rightmost graph in the Figure 4 shows the result of the third experiment.,5 RESULTS,[0],[0]
It shows that the symbol grounding run-time when reasoning in the context of detailed world models( Υ ) grows as a function of the world complexity.,5 RESULTS,[0],[0]
"However, it is significantly lower when reasoning in the context of adaptively generated world models ( Υ∗ ) and is independent of the world complexity.
",5 RESULTS,[0],[0]
"The achieved run-time gains are meaningful
only if we do not incur a loss in the symbol grounding accuracy.",5 RESULTS,[0],[0]
Table 3 shows the impact of LPM on SG accuracy and summarizes the gains.,5 RESULTS,[0],[0]
"Real-time human-robot interaction is critical for the utility of the collaborative robotic manipula-
tors in shared tasks.",6 CONCLUSIONS,[0],[0]
"In scenarios where inferring exhaustively detailed models of all the objects is prohibitive, perception represents a bottleneck that inhibits real-time interactions with collaborative robots.",6 CONCLUSIONS,[0],[0]
Language provides an intuitive and multiresolution interface to interact with these robots.,6 CONCLUSIONS,[0],[0]
"While recent probabilistic frameworks have advanced our ability to interpret the meaning of complex instructions in cluttered environments, the problem of how language can channel the interpretation of the raw observations to construct world models which are necessary and sufficient for the symbol grounding task is not extensively studied.",6 CONCLUSIONS,[0],[0]
"Our proposed DCG based Language Perception Model, demonstrates that we can guide perception using language to construct world models which are suitable for efficiently interpreting the instruction.",6 CONCLUSIONS,[0],[0]
"This provides run-time gains in terms of both perception and symbol grounding, thereby improving the speed with which collaborative robots can understand and act upon human instructions.",6 CONCLUSIONS,[0],[0]
In ongoing and future work we are exploring how language can aid efficient construction of global maps for robot navigation and manipulation by intelligently sampling relevant observations from a set of observations.,6 CONCLUSIONS,[0],[0]
This work was supported in part by the National Science Foundation under grant IIS-1637813 and the New York State Center of Excellence in Data Science at the University of Rochester.,7 ACKNOWLEDGMENTS,[0],[0]
We list the grammar rules and the lexicon for our corpus to demonstrate the diversity of the instructions.,A Grammar and Lexicon of the Corpus,[0],[0]
Following table lists the words scraped from the instructions in our corpus.,A Grammar and Lexicon of the Corpus,[0],[0]
"We have a total of 56 unique words.
",A Grammar and Lexicon of the Corpus,[0],[0]
Following table lists the grammar rules scraped from the instructions in our corpus.,A Grammar and Lexicon of the Corpus,[0],[0]
We have a total of 23 unique grammar rules.,A Grammar and Lexicon of the Corpus,[0],[0]
The utility of collaborative manipulators for shared tasks is highly dependent on the speed and accuracy of communication between the human and the robot.,abstractText,[0],[0]
The run-time of recently developed probabilistic inference models for situated symbol grounding of natural language instructions depends on the complexity of the representation of the environment in which they reason.,abstractText,[0],[0]
"As we move towards more complex bi-directional interactions, tasks, and environments, we need intelligent perception models that can selectively infer precise pose, semantics, and affordances of the objects when inferring exhaustively detailed world models is inefficient and prohibits real-time interaction with these robots.",abstractText,[0],[0]
In this paper we propose a model of language and perception for the problem of adapting the configuration of the robot perception pipeline for tasks where constructing exhaustively detailed models of the environment is inefficient and inconsequential for symbol grounding.,abstractText,[0],[0]
We present experimental results from a synthetic corpus of natural language instructions for robot manipulation in example environments.,abstractText,[0],[0]
The results demonstrate that by adapting perception we get significant gains in terms of run-time for perception and situated symbol grounding of the language instructions without a loss in the accuracy of the latter.,abstractText,[0],[0]
Language-Guided Adaptive Perception for Efficient Grounded Communication with Robotic Manipulators in Cluttered Environments,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1183–1191 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1183",text,[0],[0]
"Language models (LMs) estimate the likelihood of a symbol sequence {xt}Tt=0, based on the joint probability,
p(x0, . . .",1 Introduction,[0],[0]
", xT )",1 Introduction,[0],[0]
"= p(x0) T∏ t=1 p(xt|x0, . . .",1 Introduction,[0],[0]
", xt−1).
(1)
To measure the quality of an LM, a commonly adopted metric is perplexity (PPL), defined as
PPL , exp { − 1 T T∑ t=0 log p(xt|x0, . .",1 Introduction,[0],[0]
.,1 Introduction,[0],[0]
", xt−1) } ,
A good language model has a small PPL, being able to assign higher likelihoods to sentences that are more likely to appear.
",1 Introduction,[0],[0]
"LMs are widely applied in automatic speech recognition (ASR) (Yu and Deng, 2014) and machine translation (MT) (Koehn, 2009).",1 Introduction,[0],[0]
"Following Koehn (2009), one may interpret the language
∗Contributions were made while at Baidu Research.
model as prior knowledge on the text to be inferred, which provides information complementary to the ASR or MT system itself.",1 Introduction,[0],[0]
"In practice, there are several ways to incorporate the language model.",1 Introduction,[0],[0]
"The simplest way may be re-scoring an n-best list returned by the ASR or MT system (Mikolov et al., 2010; Sundermeyer et al., 2012).",1 Introduction,[0],[0]
"A slightly more sophisticated way is to jointly consider the ASR/MT and language model in a beam search decoder (Amodei et al., 2016).",1 Introduction,[0],[0]
"Specifically, at each time step, the decoder appends every symbol in the vocabulary to each sequence in the current candidate set.",1 Introduction,[0],[0]
"For every hypothesis, a score is calculated as a linear combination of the log-likelihoods given by both the ASR/MT and language models.",1 Introduction,[0],[0]
"Then, only the top K hypotheses with the highest scores are retained, as an updated candidate set.",1 Introduction,[0],[0]
"More recently, Gulcehre et al. (2015) and Sriram et al. (2017) propose to predict the next symbol based on a fusion of the hidden states in the ASR/MT and language models.",1 Introduction,[0],[0]
"A gating mechanism is jointly trained to determine how much the language model should contribute.
",1 Introduction,[0],[0]
The afore-discussed language models are generative in the sense that they merely model the joint distribution of a symbol sequence (Eq.,1 Introduction,[0],[0]
(1)).,1 Introduction,[0],[0]
"While the research community is mostly focused on pushing the limit of PPL (e.g., Jozefowicz et al., 2016), very limited attention has been paid to the discrimination power of language models when they are applied to real tasks, such as ASR and MT (Li and Khudanpur, 2008).",1 Introduction,[0],[0]
"By contrast, discriminative language modeling aims at enhancing the performance in downstream applications.",1 Introduction,[0],[0]
"For example, existing works (Roark et al., 2004, 2007) often target at improving ASR accuracy.",1 Introduction,[0],[0]
"The key motivation underlying them is that the model should be able to discriminate between “good” and “bad” sentences in a task-specific sense, instead
of just modeling grammatical ones.",1 Introduction,[0],[0]
"The common methodology (Dikic et al., 2013) is to build a binary classifier upon hand-crafted features extracted from the sentences.",1 Introduction,[0],[0]
"However, it is not obvious how these methods can utilize large unannotated corpus, which is often easily available, and the hand-crafted features are also ad hoc and may result in suboptimal performance.
",1 Introduction,[0],[0]
"In this work, we study how to improve the discrimination ability of a recurrent network-based neural language model (RNNLM).",1 Introduction,[0],[0]
The goal is to enlarge the difference between the log-likelihoods of “good” and “bad” sentences.,1 Introduction,[0],[0]
"In an contrast to the existing works (Roark et al., 2004, 2007), our method does not rely on hand-crafted features, and is trained in end-to-end manner and able to take advantage of large external text corpus.",1 Introduction,[0],[0]
"In fact, it is a general training criterion that is transparent to the network architecture of the RNNLM, and can be applied to various text generation tasks, including ASR and MT.",1 Introduction,[0],[0]
Experiments on state-of-art ASR and MT systems show its significant advantage over an LM trained by minimizing PPL.,1 Introduction,[0],[0]
We first give some background knowledge on RNNLMs.,2 Background on RNNLM,[0],[0]
"The prototypical RNNLM (Mikolov et al., 2010) has one layer of recurrent cell and works as follows.",2 Background on RNNLM,[0],[0]
Denote a sentence as x =,2 Background on RNNLM,[0],[0]
"[x0, . . .",2 Background on RNNLM,[0],[0]
", xt, . . .",2 Background on RNNLM,[0],[0]
"], where the xt’s are words.",2 Background on RNNLM,[0],[0]
Let ~xt be the embedding vector for xt.,2 Background on RNNLM,[0],[0]
"The recurrent cell takes in the embedding and produces a hidden state ~ht by
~ht = σ(U~xt + V~ht−1),
where σ(z) = 1 1+e−z is sigmoid activation function.",2 Background on RNNLM,[0],[0]
~ht−1 is the hidden state at the last timestep.,2 Background on RNNLM,[0],[0]
U and V are learnable parameters.,2 Background on RNNLM,[0],[0]
"The ~ht is then passed into a multi-way classifier to produce a probability distribution over the vocabulary (for the next word),
~p = softmax(W~ht +~b).
",2 Background on RNNLM,[0],[0]
The W and ~b are also trainable parameters.,2 Background on RNNLM,[0],[0]
"The training objective is to maximize the loglikelihood of the next word, and the parameters are learned by back-propagation algorithm.
",2 Background on RNNLM,[0],[0]
"The vanilla recurrent cell can also be replaced by one or multiple layers of LSTM cells, which produces better results (Zaremba et al.,
2014).",2 Background on RNNLM,[0],[0]
"In a more general form, the RNNLM can be represented as a conditional probability, pθ(x
t|x0, . . .",2 Background on RNNLM,[0],[0]
", xt−1), parameterized by θ.",2 Background on RNNLM,[0],[0]
"In the prototypical case, θ =",2 Background on RNNLM,[0],[0]
"[U, V,W,~b].",2 Background on RNNLM,[0],[0]
"We could define the LM-score of a sentence x as
LM-score(x) , log pθ(x) = ∑ t log pθ(x t|x0, . . .",2 Background on RNNLM,[0],[0]
", xt−1).
",2 Background on RNNLM,[0],[0]
"The RNNLM is trained by maximizing the average LM-score over all the x’s in a corpus, or equivalently, minimizing the PPL on the corpus.",2 Background on RNNLM,[0],[0]
We motivate and formulate a large margin training criterion in this section.,3 Problem Formulation,[0],[0]
"Suppose for every reference sentence xi, we have a collection of hypotheses xi,j , j = 1, . . .",3 Problem Formulation,[0],[0]
",K, usually obtained as the top-K candidates by a beam search decoder.",3 Problem Formulation,[0],[0]
"An RNNLM trained by minimizing PPL cannot guarantee a higher score on the “gold” reference than the inferior hypothesis, which is undesirable.",3.1 A Motivating Example,[0],[0]
One example is given in Tab. 1.,3.1 A Motivating Example,[0],[0]
The reference is taken from the text labels of dev93’ set of Wall Street Journal (WSJ) dataset.,3.1 A Motivating Example,[0],[0]
"The hypothesis is generated by a CTC-based (Graves et al., 2006)",3.1 A Motivating Example,[0],[0]
ASR system trained on WSJ training set.,3.1 A Motivating Example,[0],[0]
Words in red are mistakes made by the hypothesis.,3.1 A Motivating Example,[0],[0]
We then train an RNNLM on Common Crawl1 copora by minimizing PPL.,3.1 A Motivating Example,[0],[0]
"Training follows a typical setup (Jozefowicz et al., 2016) with a vocabulary of 400K the most frequent words.",3.1 A Motivating Example,[0],[0]
Any out-ofvocabulary word is replaced by an 〈UNK〉 token.,3.1 A Motivating Example,[0],[0]
The RNNLM is then employed to score the sentences.,3.1 A Motivating Example,[0],[0]
The LM-score of the erroneous hypothesis is higher than that of the reference.,3.1 A Motivating Example,[0],[0]
"In fact, this is reasonable as “a decade as concerns” seems to be a more common phrase.",3.1 A Motivating Example,[0],[0]
"In the training corpus, we find that “a decade as concerns” appears once, but “its defeat is confirmed” does not appear.",3.1 A Motivating Example,[0],[0]
"Moreover, “a decade as” appears 2,280 times, but “its defeat is” appears only 24 times.",3.1 A Motivating Example,[0],[0]
"However, this is undesirable because if there is another hypothesis that happens to be the same as reference, which will not be ranked as the best candidate.
",3.1 A Motivating Example,[0],[0]
"It would be helpful if the LM can also learn from the imperfect hypotheses so that it can tell
1http://web-language-models.",3.1 A Motivating Example,[0],[0]
"s3-website-us-east-1.amazonaws.com/ wmt16/deduped/en-new.xz
apart “good” and “bad” candidates.",3.1 A Motivating Example,[0],[0]
"With this motivation, we train to assign larger LM-scores for the xi’s but smaller ones for the (imperfect) xi,j’s.",3.1 A Motivating Example,[0],[0]
A quantity of particular interest is log p(xi),3.1 A Motivating Example,[0],[0]
"− log p(xi,j), the margin/difference between the LM-scores of the references and the (imperfect) hypotheses.",3.1 A Motivating Example,[0],[0]
"The intuition is that the more positive the margin, the better the LM is at discrimination.",3.1 A Motivating Example,[0],[0]
"Without loss of generality, we assume that all the xi,j’s are imperfect and different from xi.",3.2 Straightforward but Failed Formulation,[0],[0]
"A straightforward way is to adopt the following objective:
min θ
1
N N∑ i=1",3.2 Straightforward but Failed Formulation,[0],[0]
"− log pθ(xi) + 1 K K∑ j=1 log pθ(xi,j)  .",3.2 Straightforward but Failed Formulation,[0],[0]
"(2)
Similar formulation is also seen in (Tachioka and Watanabe, 2015), where they only utilize one beam candidate, i.e., K = 1.",3.2 Straightforward but Failed Formulation,[0],[0]
Optimization can be carried out by mini-batch stochastic gradient descent (SGD).,3.2 Straightforward but Failed Formulation,[0],[0]
"Each iteration, SGD randomly samples a batch of i’s and j’s, computes stochastic gradient w.r.t.",3.2 Straightforward but Failed Formulation,[0],[0]
"θ,",3.2 Straightforward but Failed Formulation,[0],[0]
and takes an update step.,3.2 Straightforward but Failed Formulation,[0],[0]
"However, a potential problem with this formulation is that the second term (corresponding to the inferior hypotheses) may dominate the optimization.",3.2 Straightforward but Failed Formulation,[0],[0]
"Specifically, the training is almost always driven by the xi,j’s, but does not effectively enhance the discrimination.",3.2 Straightforward but Failed Formulation,[0],[0]
"We illustrate this fact in the following experiment.
",3.2 Straightforward but Failed Formulation,[0],[0]
"Using the ASR system in section 3.1, we extract 256 beam candidates for every training example in Wall Street Journal (WSJ) dataset.",3.2 Straightforward but Failed Formulation,[0],[0]
"Warm started from the pre-trained RNNLM in section 3.1, we apply SGD to minimize the loss in Eq.",3.2 Straightforward but Failed Formulation,[0],[0]
"(2), with a mini-batch size of 128.",3.2 Straightforward but Failed Formulation,[0],[0]
The training loss is shown in Fig.,3.2 Straightforward but Failed Formulation,[0],[0]
1a.,3.2 Straightforward but Failed Formulation,[0],[0]
"We observe that the learning dynamic is very unstable, and deceases to be negative.",3.2 Straightforward but Failed Formulation,[0],[0]
The unbound decreasing is due to the second term in Eq.,3.2 Straightforward but Failed Formulation,[0],[0]
(2) being negative and dominating the training process.,3.2 Straightforward but Failed Formulation,[0],[0]
"Next, we inspect log pθ(xi)",3.2 Straightforward but Failed Formulation,[0],[0]
"− log pθ(xi,j), the margin between the scores of a ground-truth and a candidate.",3.2 Straightforward but Failed Formulation,[0],[0]
In Fig.,3.2 Straightforward but Failed Formulation,[0],[0]
"2a, we histogram the margins for all the i, j’s in a dev set.",3.2 Straightforward but Failed Formulation,[0],[0]
"The distribution appears to be symmetric around zero, which indicates poor discrimination ability.",3.2 Straightforward but Failed Formulation,[0],[0]
"Given these facts, we conclude that the straightforward formulation in Eq.",3.2 Straightforward but Failed Formulation,[0],[0]
(2) is not effective.,3.2 Straightforward but Failed Formulation,[0],[0]
"To effectively utilize all the imperfect beam candidates, we propose the following objective,
min θ N∑ i=1",3.3 Large Margin Formulation,[0],[0]
"B∑ j=1 max { 0, τ−(log pθ(xi)−log pθ(xi,j)) } , (3) where log pθ(xi)",3.3 Large Margin Formulation,[0],[0]
"− logθ(xi,j) is the margin between the scores of a ground-truth xi and a can-
didate xi,j .",3.3 Large Margin Formulation,[0],[0]
The hinge loss on the margin encourages the log-likelihood of the ground-truth to be at least τ larger than that of the imperfect hypothesis.,3.3 Large Margin Formulation,[0],[0]
"We call an LM trained by the above formulation as Large Margin Language Model (LMLM).
",3.3 Large Margin Formulation,[0],[0]
"We repeat the same experiment in section 3.2, but change the objective function to Eq.",3.3 Large Margin Formulation,[0],[0]
(3) and set τ = 1.,3.3 Large Margin Formulation,[0],[0]
Fig.,3.3 Large Margin Formulation,[0],[0]
"1b shows the training loss, which steadily decreases and approaches zero rapidly.",3.3 Large Margin Formulation,[0],[0]
"Compared with the learning curve of naive formulation (Fig. 1a), the large margin based training is much more stable.",3.3 Large Margin Formulation,[0],[0]
"In Fig. 2b, we also examine the histogram of log pθ(xi)",3.3 Large Margin Formulation,[0],[0]
"− log pθ(xi,j), where pθ(·) is now the LM learned by LMLM.",3.3 Large Margin Formulation,[0],[0]
"Compared with the histogram by the conventional RNNLM, LMLM significantly moves the distribution to the positive side, indicating more discrimination.",3.3 Large Margin Formulation,[0],[0]
"In most cases, all beam candidates are imperfect.",3.4 Ranking Loss Type Formulation,[0],[0]
It may be beneficial to exploit the information that some candidates are relatively better than the others.,3.4 Ranking Loss Type Formulation,[0],[0]
We consider ranking them according to some metrics w.r.t.,3.4 Ranking Loss Type Formulation,[0],[0]
the ground-truth sentences.,3.4 Ranking Loss Type Formulation,[0],[0]
"For ASR, the metric is WER, and for MT, the metric is BLEU score.",3.4 Ranking Loss Type Formulation,[0],[0]
"We define xi,0 , xi and assume that the candidates {xi,j}Kj=1 are sorted such that
WER(xi,xi,j−1) <",3.4 Ranking Loss Type Formulation,[0],[0]
"WER(xi,xi,j)
for ASR, and
BLEU(xi,xi,j−1) > BLEU(xi,xi,j)
for MT.",3.4 Ranking Loss Type Formulation,[0],[0]
"In other words, xi,j−1 has better quality than xi,j .
",3.4 Ranking Loss Type Formulation,[0],[0]
We then enforce the “better” sentences to have a score at least τ larger than those “worse” ones.,3.4 Ranking Loss Type Formulation,[0],[0]
"This leads to the following formulation,
min θ N∑ i=1 B−1∑ j=0",3.4 Ranking Loss Type Formulation,[0],[0]
"B∑ k=j+1 max { 0,
τ",3.4 Ranking Loss Type Formulation,[0],[0]
"− (log pθ(xi,j)− logθ(xi,k)), } .",3.4 Ranking Loss Type Formulation,[0],[0]
"(4)
",3.4 Ranking Loss Type Formulation,[0],[0]
Compared with LMLM formulation Eq.,3.4 Ranking Loss Type Formulation,[0],[0]
"(3), the above introduces more comparisons among the candidates, and hence more computational cost during training.",3.4 Ranking Loss Type Formulation,[0],[0]
"We call this formulation rankingloss-based LMLM (rLMLM).
",3.4 Ranking Loss Type Formulation,[0],[0]
"To summarize this section, we have proposed LMLM and rLMLM that aim at discriminating between hypotheses in a task-specific (e.g., WER or BLEU) sense, instead of minimizing PPL.",3.4 Ranking Loss Type Formulation,[0],[0]
We apply the LMs trained under different criteria to rescore the beams in various ASR systems.,4 Experiments on ASR,[0],[0]
"In particular, we are interested in knowing which of the two training mechanisms is better: minimizing PPL (e.g., the RNNLM in Section 3.1), or fitting to the WER metric by the proposed methods.
",4 Experiments on ASR,[0],[0]
"Adapting an RNNLM to a specific domain has been of interest, especially to the speech community (Park et al., 2010; Chen et al., 2015; Ma et al., 2017).",4 Experiments on ASR,[0],[0]
We adopt Ma et al. (2017) that fine-tune the softmax layer of RNNLM by minimizing the PPL on the text labels of training set.,4 Experiments on ASR,[0],[0]
"According to Ma et al. (2017), the reason not to fine-tune all the layers is due to the limited text labels in the target domain.",4 Experiments on ASR,[0],[0]
"Indeed, we also observe overfitting if adapting all layers, but adapting only the softmax layer effectively decreases the PPL on the text labels of dev sets.",4 Experiments on ASR,[0],[0]
"We refer to this fine-tuning as RNNLM-adapted in the following sections.
",4 Experiments on ASR,[0],[0]
"To make a fair comparison with the adapted model, we also use the RNNLM as an initialization for our LMLM and rLMLM.",4 Experiments on ASR,[0],[0]
"In total, there are four language models for rescoring the beams.",4 Experiments on ASR,[0],[0]
"RNNLM and its adapted version that aim at reducing PPL; and the two proposed methods, LMLM and rLMLM that try to fit to WER.",4 Experiments on ASR,[0],[0]
The WSJ corpora consists of about 80 hours of read speech with texts drawn from a machinereadable corpus of Wall Street Journal news.,4.1 WSJ Dataset,[0],[0]
"We use the standard configuration of train si284 dataset for training, dev93 for development and eval92 for testing.
",4.1 WSJ Dataset,[0],[0]
"Our ASR model has one convolution layer, followed by 5 bidirectional RNNs and one fully connected layer, with a CTC loss on top.",4.1 WSJ Dataset,[0],[0]
"The text labels of the training set are used to train a 4-gram language model, which is employed in the ASR decoder.",4.1 WSJ Dataset,[0],[0]
The beam search decoder has a beam width of 2000.,4.1 WSJ Dataset,[0],[0]
"Before beam rescoring, this ASR system achieves a WER of 12.16 on dev93 set and 7.69 on eval92 set.",4.1 WSJ Dataset,[0],[0]
"To put this into perspective, we list some previous state-of-the-art system in Tab. 2.",4.1 WSJ Dataset,[0],[0]
"Compared with them, our baseline is already very competitive.",4.1 WSJ Dataset,[0],[0]
"The out-of-vocabulary rate of WSJ text is only 0.28%, making the RNNLM reasonable to use.
",4.1.1 WERs and PPLs,[0],[0]
"We apply the RNNLM, RNNLM-adapted (Ma et al., 2017), LMLM and rLMLM to rescore the beams on dev and test set.",4.1.1 WERs and PPLs,[0],[0]
The final score assigned to a beam is a weighted sum of the ASR and language model scores.,4.1.1 WERs and PPLs,[0],[0]
"The weight is found by minimizing the WER on the dev set.
",4.1.1 WERs and PPLs,[0],[0]
Tab. 3 reports the WERs on dev93 and eval92 sets.,4.1.1 WERs and PPLs,[0],[0]
All methods reduce the WER over the baseline without rescoring.,4.1.1 WERs and PPLs,[0],[0]
"However, LMLM and rLMLM are notably better than the other two methods.",4.1.1 WERs and PPLs,[0],[0]
"Moreover, although RNNLM and RNNLM-adapted achieve smaller PPLs on the text labels, the advantage does not transfer to WER.",4.1.1 WERs and PPLs,[0],[0]
"To better understand the proposed methods, we calculate the correlation coefficients between the hypotheses’ WERs and their scores (by different language models).",4.1.2 Correlation between scores and WERs,[0],[0]
"In specific, for every utterance in the test set, we have a set of beam candidates, their word level accuracies (100-WER) and scores given by an LM, from which a Pearson correlation coefficient can be calculated.",4.1.2 Correlation between scores and WERs,[0],[0]
"We calculate the coefficients for all the utterances in the test set, and boxplot these coefficients in Fig. 3.",4.1.2 Correlation between scores and WERs,[0],[0]
"The correlation coefficients by LMLM and rLMLM tend
to be higher than RNNLM and RNNLM-adapted.",4.1.2 Correlation between scores and WERs,[0],[0]
This indicates that LMLM and rLMLM are more aligned with the goal of reducing WER.,4.1.2 Correlation between scores and WERs,[0],[0]
Tab. 4 posts some examples from the test set.,4.1.3 Case Study,[0],[0]
"The first column lists the ground-truth labels, and their corresponding best candidates as re-ranked by the four LMs (see notes in the second column).",4.1.3 Case Study,[0],[0]
Words in red are mistakes made by the candidate sentences.,4.1.3 Case Study,[0],[0]
Scores of these sentences are listed in the last four columns.,4.1.3 Case Study,[0],[0]
"We have the following observations:
1. LMLM and rLMLM give worse scores on the ground-truth labels than RNNLM and RNNLM-adapted, which explains their higher PPL in Tab. 3.
2.",4.1.3 Case Study,[0],[0]
"In the first example, RNNLM and RNNLMadapted assign higher scores to a shorter sentence.",4.1.3 Case Study,[0],[0]
"This is reasonable (though not necessarily desirable) as LM-score is a summation of log-probabilities, each of which is negative.",4.1.3 Case Study,[0],[0]
"In contrast, LMLM and rLMLM are able to assign higher scores to longer and better candidates.
",4.1.3 Case Study,[0],[0]
3.,4.1.3 Case Study,[0],[0]
"In the other two examples, LMLM and rLMLM seem to favor more sensible sentences, though they are not more grammatical than those picked by RNNLM and RNNLMadapted.",4.1.3 Case Study,[0],[0]
"We conjecture that since LMLM and rLMLM utilize beam candidates in their training, they capture and compensate for
some weakness in the ASR, which is not achieved by RNNLM and RNNLM-adapted.",4.1.3 Case Study,[0],[0]
We further validate our methods on a larger noisy dataset collected by Liu et al. (2017).,4.2 10K Speech Dataset,[0],[0]
The dataset has about 10K hours of spontaneous speech.,4.2 10K Speech Dataset,[0],[0]
"The utterances are corrupted by background noise, and a large portion of them are accented.",4.2 10K Speech Dataset,[0],[0]
Therefore it is much more challenging than WSJ.,4.2 10K Speech Dataset,[0],[0]
We adopt the same training-dev-test split as in Liu et al. (2017).,4.2 10K Speech Dataset,[0],[0]
"In specific, there are 5.4M utterances for training, 2,066 for development and 2,054 for testing.
",4.2 10K Speech Dataset,[0],[0]
"The ASR we build has the same architecture as in Liu et al. (2017), except that its decoder integrates an in-domain 5-gram language model.",4.2 10K Speech Dataset,[0],[0]
"This system achieves a WER of 19.17 on dev set, better than the reported 19.77 baseline in Liu et al. (2017).",4.2 10K Speech Dataset,[0],[0]
"Based on the ASR, we repeat the same experiments in section 4.1.",4.2 10K Speech Dataset,[0],[0]
Tab. 5 reports WERs and PPLs on dev and test sets.,4.2 10K Speech Dataset,[0],[0]
"Both LMLM and rLMLM outperform the other methods in WER, although their PPLs are higher.",4.2 10K Speech Dataset,[0],[0]
This trend is similar to that in Tab. 3.,4.2 10K Speech Dataset,[0],[0]
"In this section, we experiment the large-margin criterion trained LM with a competitive Chineseto-English NMT system.",5 Experiments on NMT,[0],[0]
The NMT model is trained from 2M parallel sentence pairs.,5 Experiments on NMT,[0],[0]
"Following Shen et al. (2016), we use NIST 06 newswire portion (616 sentences) for development and NIST 08 newswire portion (691 sentences) for testing.",5 Experiments on NMT,[0],[0]
"We use OpenNMT-py2 package with the default configuration to train the model: batch size is 64; word embedding size is 500; dropout rate is 0.3; target vocabulary size is 50K; number of epochs is 20, after which a minimum dev perplexity of 7.72
2https://github.com/OpenNMT/OpenNMT-py
is achieved.",5 Experiments on NMT,[0],[0]
"We use a beam size of 10 for decoding, and report case-insensitive 4-reference BLEU-4 scores (by calling “multi bleu.perl”3).",5.1 BLEUs and PPLs,[0],[0]
The NMT model achieves 35.18 BLEU score on dev set and 31.52 on test set (see table 6).,5.1 BLEUs and PPLs,[0],[0]
"To put this into perspective, Shen et al. (2016) trains their models on 2.56M pairs of sentences and reports a dev BLEU score of 32.7 (via MOSES) or 30.7 (via RNNsearch, beam size of 10).",5.1 BLEUs and PPLs,[0],[0]
"So our NMT model is already very competitive.
",5.1 BLEUs and PPLs,[0],[0]
"To construct the training data for LMLM and rLMLM, 10 beam candidates are extracted for every sentence in the training set.",5.1 BLEUs and PPLs,[0],[0]
"We then follow the same experimental steps outlined in section 4.1, except that the ASR score is now changed to NMT score.",5.1 BLEUs and PPLs,[0],[0]
"In addition, we also find that normalizing the LM score by sentence length can improve the re-scoring performance substantially.",5.1 BLEUs and PPLs,[0],[0]
Tab. 6 compares the BLEU score after re-ranking by the different LMs.,5.1 BLEUs and PPLs,[0],[0]
LMLM and rLMLM,5.1 BLEUs and PPLs,[0],[0]
"both improve upon the baseline significantly, and outperform RNNLM and RNNLM-adapted by a notable margin.",5.1 BLEUs and PPLs,[0],[0]
"We also observe that the PPLs of LMLM and rLMLM are much larger than those of RNNLM and RNNLM-adapted, suggesting that the PPL metric may be very poorly correlated with BLEU.
",5.1 BLEUs and PPLs,[0],[0]
"Interestingly, RNNLM-adapted does not show any gain in BLEU score over RNNLM.",5.1 BLEUs and PPLs,[0],[0]
"To understand this, we recall that NMT is trained by minimizing PPL on target text.",5.1 BLEUs and PPLs,[0],[0]
Its decoder is implicitly an RNNLM on target language.,5.1 BLEUs and PPLs,[0],[0]
"We conjecture that adapting an LM to the target domain can only duplicate the functionality of the NMT decoder, which does not bring any additional benefit.",5.1 BLEUs and PPLs,[0],[0]
We measure the correlation between the LM scores and BLUEs.,5.2 Correlation between scores and BLEUs,[0],[0]
"The calculation is done on dev06 set in the same way as Section 4.1.2, but now we change the WERs to BLEUs.",5.2 Correlation between scores and BLEUs,[0],[0]
The boxplot of the correlation coefficients are shown in Fig. 4.,5.2 Correlation between scores and BLEUs,[0],[0]
"Compared with the boxplot in Fig. 3, now the correlation coefficients by all LMs are more dispersed.",5.2 Correlation between scores and BLEUs,[0],[0]
"Sometimes, they even take negative values.",5.2 Correlation between scores and BLEUs,[0],[0]
"The mean correlation by LMLM
3https://github.com/OpenNMT/ OpenNMT-py/blob/master/tools/multi-bleu.",5.2 Correlation between scores and BLEUs,[0],[0]
"perl
and rLMLM, however, is considerably higher than those by RNNLM and RNNLM-adapted.",5.2 Correlation between scores and BLEUs,[0],[0]
"“Language modeling is an art of determining the probability of a sequence of words” (Goodman, 2001).",6 Related Work,[0],[0]
"In the past decades, there has been a trend of increasing the context that an LM can condition on.",6 Related Work,[0],[0]
"N-gram models (Chen and Goodman, 1996) assume that each symbol depends on the previous N − 1 symbols.",6 Related Work,[0],[0]
"Feed forward neural network based LMs (Bengio et al., 2003) are not count based",6 Related Work,[0],[0]
but they inherit the restrictive assumption.,6 Related Work,[0],[0]
"To model longer-term dependencies, RNNLMs (Mikolov et al., 2010) are proposed.",6 Related Work,[0],[0]
"RNNLMs often achieve smaller PPLs than the N-gram counterparts (Sundermeyer et al., 2012; Zaremba et al., 2014; Jozefowicz et al., 2016).",6 Related Work,[0],[0]
"This paper focuses on RNNLM-type architectures.
",6 Related Work,[0],[0]
"While these works all adopt PPL as the metric
to optimize, sometimes one may optimize a taskspecific objective.",6 Related Work,[0],[0]
"For example, Kuo et al. (2002); Roark et al. (2007) and Dikic et al. (2013) propose discriminative LMs to improve speech recognition.",6 Related Work,[0],[0]
"The common methodology therein is to fit a probabilistic model, e.g., conditional random field (Roark et al., 2004), to the space of text candidates, and maximize the probability at the desired candidate.",6 Related Work,[0],[0]
The problem is often solved by perceptron algorithm.,6 Related Work,[0],[0]
"However, these methods all rely on ad-hoc choice of features, e.g., counts of n-grams where n varies in a small range (e.g.,1 to 3).",6 Related Work,[0],[0]
"Moreover, it is also not clear how these methods would take advantage of an existing language model (trained on large unsupervised corpus).",6 Related Work,[0],[0]
"Nevertheless, the same methodology can be extended to RNNLMs, thus avoiding the aforementioned limitations.",6 Related Work,[0],[0]
"For example, Auli and Gao (2014) train an RNNLM by favoring sentences with high BLEU scores and integrate it into a phrase-based MT decoder.
",6 Related Work,[0],[0]
"If we cast the problem of picking the best text sequence as a ranking problem, the aforementioned works can be considered as “pointwise” learning-to-rank approaches (Cossock and Zhang, 2008).",6 Related Work,[0],[0]
"In contrast, the proposed method is a “pairwise” approach (Liu, 2009), as it learns a neural language model by comparison between pairs of sentences.",6 Related Work,[0],[0]
"Earlier works in this fashion may date back to (Collins and Koo, 2005), which improves a semantic parser.",6 Related Work,[0],[0]
Learning “by pairwise comparison” is also seen in several MT literatures.,6 Related Work,[0],[0]
"For example, Hopkins and May (2011) propose to train a phrase-based MT system by minimizing a pairwise ranking loss.",6 Related Work,[0],[0]
Wiseman and Rush (2016) optimize the beam search process in a Neural Machine Translation (NMT) system.,6 Related Work,[0],[0]
"They enforce the score of a reference to be higher than that of its decoded k-th candidate by at least a unit margin.
",6 Related Work,[0],[0]
"Rather than optimizing the MT system itself, this work proposes a general method of training recurrent neural language models, which can benefit various text generation tasks, including speech recognition and machine translation.",6 Related Work,[0],[0]
We have proposed a large margin criterion for training recurrent neural language models.,7 Conclusions,[0],[0]
"Rather than minimizing PPL, the proposed criterion is based on comparison between pairs of sen-
tences.",7 Conclusions,[0],[0]
We have formulated two algorithms that implement the training criterion.,7 Conclusions,[0],[0]
"One compares between references and imperfect hypotheses (LMLM), the other compares between all pairs of hypotheses (rLMLM).",7 Conclusions,[0],[0]
We applied the language models trained by these two algorithms to speech recognition and machine translation.,7 Conclusions,[0],[0]
Both of them demonstrate superior performance over their minimum-PPL counterparts.,7 Conclusions,[0],[0]
"However, the performance gain from LMLM to rLMLM is small, although rLMLM is built on more pairwise comparisons and requires more training efforts.",7 Conclusions,[0],[0]
The efficiency with respect to the number of pairs is a future research topic.,7 Conclusions,[0],[0]
We propose a large margin criterion for training neural language models.,abstractText,[0],[0]
"Conventionally, neural language models are trained by minimizing perplexity (PPL) on grammatical sentences.",abstractText,[0],[0]
"However, we demonstrate that PPL may not be the best metric to optimize in some tasks, and further propose a large margin formulation.",abstractText,[0],[0]
The proposed method aims to enlarge the margin between the “good” and “bad” sentences in a task-specific sense.,abstractText,[0],[0]
It is trained end-to-end and can be widely applied to tasks that involve re-scoring of generated text.,abstractText,[0],[0]
"Compared with minimum-PPL training, our method gains up to 1.1 WER reduction for speech recognition and 1.0 BLEU increase for machine translation.",abstractText,[0],[0]
Large Margin Neural Language Model,title,[0],[0]
Mental illness is a major global health issue.,1 Introduction,[0],[0]
"In the U.S. alone, 43.6 million adults (18.1%) experience mental illness in a given year (National Institute of Mental Health, 2015).",1 Introduction,[0],[0]
"In addition to the person directly experiencing a mental illness, family, friends, and communities are also affected (Insel, 2008).
",1 Introduction,[0],[0]
"In many cases, mental health conditions can be treated effectively through psychotherapy and counseling (World Health Organization, 2015).",1 Introduction,[0],[0]
"However, it is far from obvious how to best conduct counseling conversations.",1 Introduction,[0],[0]
"Such conversations are free-form without strict rules, and involve many choices that
*Both authors contributed equally to the paper.
could make a difference in someone’s life.",1 Introduction,[0],[0]
"Thus far, quantitative evidence for effective conversation strategies has been scarce, since most studies on counseling have been limited to very small sample sizes and qualitative observations (e.g., Labov and Fanshel, (1977); Haberstroh et al., (2007)).",1 Introduction,[0],[0]
"However, recent advances in technology-mediated counseling conducted online or through texting (Haberstroh et al., 2007) have allowed counseling services to scale with increasing demands and to collect large-scale data on counseling conversations and their outcomes.
",1 Introduction,[0],[0]
Here we present the largest study on counseling conversation strategies published to date.,1 Introduction,[0],[0]
"We use data from an SMS texting-based counseling service where people in crisis (depression, self-harm, suicidal thoughts, anxiety, etc.), engage in therapeutic conversations with counselors.",1 Introduction,[0],[0]
The data contains millions of messages from eighty thousand counseling conversations conducted by hundreds of counselors over the course of one year.,1 Introduction,[0],[0]
"We develop a set of computational methods suited for large-scale discourse analysis to study how various linguistic aspects of conversations are correlated with conversation outcomes (collected via a follow-up survey).
",1 Introduction,[0],[0]
We focus our analyses on counselors instead of individual conversations because we are interested in general conversation strategies rather than properties of specific issues.,1 Introduction,[0],[0]
"We find that there are significant, quantifiable differences between more successful and less successful counselors in how they conduct conversations.
",1 Introduction,[0],[0]
"Our findings suggest actionable strategies that are associated with successful counseling:
463
Transactions of the Association for Computational Linguistics, vol. 4, pp.",1 Introduction,[0],[0]
"463–476, 2016.",1 Introduction,[0],[0]
Action Editor: Lillian Lee.,1 Introduction,[0],[0]
"Submission batch: 12/2015; Revision batch: 3/2016; 7/2016 Published 8/2016.
",1 Introduction,[0],[0]
c©2016 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
1.",1 Introduction,[0],[0]
"Adaptability (Section 5): Measuring the distance between vector representations of the language used in conversations going well and going badly, we find that successful counselors are more sensitive to the current trajectory of the conversation and react accordingly.",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
Dealing with Ambiguity (Section 6): We develop a clustering-based method to measure differences in how counselors respond to very similar ambiguous situations.,1 Introduction,[0],[0]
"We learn that successful counselors clarify situations by writing more, reflect back to check understanding, and make their conversation partner feel more comfortable through affirmation.",1 Introduction,[0],[0]
3.,1 Introduction,[0],[0]
"Creativity (Section 6.3): We quantify the diversity in counselor language by measuring cluster density in the space of counselor responses and find that successful counselors respond in a more creative way, not copying the person in distress exactly and not using too generic or “templated” responses.",1 Introduction,[0],[0]
4. Making Progress (Section 7): We develop a novel sequence-based unsupervised conversation model able to discover ordered conversation stages common to all conversations.,1 Introduction,[0],[0]
"Analyzing the progression of stages, we determine that successful counselors are quicker to get to know the core issue and faster to move on to collaboratively solving the problem.",1 Introduction,[0],[0]
5. Change in Perspective (Section 8): We develop novel measures of perspective change using psycholinguistics-inspired word frequency analysis.,1 Introduction,[0],[0]
"We find that people in distress are more likely to be more positive, think about the future, and consider others, when the counselors bring up these concepts.",1 Introduction,[0],[0]
"We further show that this perspective change is associated with better conversation outcomes consistent with psychological theories of depression.
",1 Introduction,[0],[0]
"Further, we demonstrate that counseling success on the level of individual conversations is predictable using features based on our discovered conversation strategies (Section 9).",1 Introduction,[0],[0]
Such predictive tools could be used to help counselors better progress through the conversation and could result in better counseling practices.,1 Introduction,[0],[0]
"The dataset used in this work has been released publicly and more information on dataset ac-
cess can be found at http://snap.stanford.",1 Introduction,[0],[0]
"edu/counseling.
",1 Introduction,[0],[0]
"Although we focus on crisis counseling in this work, our proposed methods more generally apply to other conversational settings and can be used to study how language in conversations relates to conversation outcomes.",1 Introduction,[0],[0]
"Our work relates to two lines of research:
Therapeutic Discourse Analysis & Psycholinguistics.",2 Related Work,[0],[0]
"The field of conversation analysis was born in the 1960s out of a suicide prevention center (Sacks and Jefferson, 1995; Van Dijk, 1997).",2 Related Work,[0],[0]
"Since then conversation analysis has been applied to various clinical settings including psychotherapy (Labov and Fanshel, 1977).",2 Related Work,[0],[0]
"Work in psycholinguistics has demonstrated that the words people use can reveal important aspects of their social and psychological worlds (Pennebaker et al., 2003).",2 Related Work,[0],[0]
"Previous work also found that there are linguistic cues associated with depression (Ramirez-Esparza et al., 2008; Campbell and Pennebaker, 2003) as well as with suicude (Pestian et al., 2012).",2 Related Work,[0],[0]
"These findings are consistent with Beck’s cognitive model of depression (1967; cognitive symptoms of depression precede the affective and mood symptoms) and with Pyszczynski and Greenberg’s self-focus model of depression (1987; depressed persons engage in higher levels of self-focus than non-depressed persons).
",2 Related Work,[0],[0]
"In this work, we propose an operationalized psycholinguistic model of perspective change and further provide empirical evidence for these theoretical models of depression.
",2 Related Work,[0],[0]
Large-scale Computational Linguistics Applied to Conversations.,2 Related Work,[0],[0]
"Large-scale studies have revealed subtle dynamics in conversations such as coordination or style matching effects (Niederhoffer and Pennebaker, 2002; Danescu-Niculescu-Mizil, 2012) as well as expressions of social power and status (Bramsen et al., 2011; Danescu-NiculescuMizil et al., 2012).",2 Related Work,[0],[0]
"Other studies have connected writing to measures of success in the context of requests (Althoff et al., 2014), user retention (Althoff and Leskovec, 2015), novels (Ashok et al., 2013), and scientific abstracts (Guerini et al., 2012).",2 Related Work,[0],[0]
"Prior
work has modeled dialogue acts in conversational speech based on linguistic cues and discourse coherence (Stolcke et al., 2000).",2 Related Work,[0],[0]
"Unsupervised machine learning models have also been used to model conversations and segment them into speech acts, topical clusters, or stages.",2 Related Work,[0],[0]
"Most approaches employ Hidden Markov Model-like models (Barzilay and Lee, 2004; Ritter et al., 2010; Paul, 2012; Yang et al., 2014) which are also used in this work to model progression through conversation stages.
",2 Related Work,[0],[0]
"Very recently, technology-mediated counseling has allowed the collection of large datasets on counseling.",2 Related Work,[0],[0]
Howes et al. (2014) find that symptom severity can be predicted from transcript data with comparable accuracy to face-to-face data but suggest that insights into style and dialogue structure are needed to predict measures of patient progress.,2 Related Work,[0],[0]
"Counseling datasets have also been used to predict the conversation outcome (Huang, 2015) but without modeling the within-conversation dynamics that are studied in this work.",2 Related Work,[0],[0]
"Other work has explored how novel interfaces based on topic models can support counselors during conversations (Dinakar et al., 2014a; 2014b; 2015; Chen, 2014).
",2 Related Work,[0],[0]
Our work joins these two lines of research by developing computational discourse analysis methods applicable to large datasets that are grounded in therapeutic discourse analysis and psycholinguistics.,2 Related Work,[0],[0]
"In this work, we study anonymized counseling conversations from a not-for-profit organization providing free crisis intervention via SMS messages.",3 Dataset Description,[0],[0]
"Textbased counseling conversations are particularly well suited for conversation analysis because all interactions between the two dialogue partners are fully observed (i.e., there are no non-textual or non-verbal cues).",3 Dataset Description,[0],[0]
"Moreover, the conversations are important, constrained to dialogue between two people, and outcomes can be clearly defined (i.e., we follow up with the conversation partner as to whether they feel better afterwards), which enables the study of how conversation features are associated with actual outcomes.
",3 Dataset Description,[0],[0]
Counseling Process.,3 Dataset Description,[0],[0]
Any person in distress can text the organization’s public number.,3 Dataset Description,[0],[0]
"Incoming requests are put into a queue and an available coun-
selor picks the request from the queue and engages with the incoming conversation.",3 Dataset Description,[0],[0]
We refer to the crisis counselor as the counselor and the person in distress as the texter.,3 Dataset Description,[0],[0]
"After the conversation ends, the texter receives a follow-up question (“How are you feeling now?",3 Dataset Description,[0],[0]
"Better, same, or worse?”) which we use as our conversation quality ground-truth (we use binary labels: good versus same/worse, since we care about improving the situation).",3 Dataset Description,[0],[0]
"In contrast to previous work that has used human judges to rate a caller’s crisis state (Kalafat et al., 2007), we directly obtain this feedback from the texter.",3 Dataset Description,[0],[0]
"Furthermore, the counselor fills out a post-conversation report (e.g., suicide risk, main issue such as depression, relationship, self-harm, suicide, etc.).",3 Dataset Description,[0],[0]
"All crisis counselors receive extensive training and commit to weekly shifts for a full year.
",3 Dataset Description,[0],[0]
Dataset Statistics.,3 Dataset Description,[0],[0]
"Our dataset contains 408 counselors and 3.2 million messages in 80,885 conversations between November 2013 and November 2014 (see Table 1).",3 Dataset Description,[0],[0]
"All system messages (e.g., instructions), as well as texts that contain survey responses (revealing the ground-truth label for the conversation) were filtered out.",3 Dataset Description,[0],[0]
"Out of these conversations, we use the 15,555, or 19.2%, that contain a groundtruth label (whether the texter feels better or the same/worse after the conversation) for the following analyses.",3 Dataset Description,[0],[0]
Conversations span a variety of issues of different difficulties (see rows one and two of Table 2).,3 Dataset Description,[0],[0]
Approval to analyze the dataset was obtained from the Stanford IRB.,3 Dataset Description,[0],[0]
The primary goal of this paper is to study strategies that lead to conversations with positive outcomes.,4 Defining Counseling Quality,[0],[0]
"Thus, we require a ground-truth notion of conversation quality.",4 Defining Counseling Quality,[0],[0]
"In principle, we could study individ-
ual conversations and aim to understand what factors make the conversation partner (texter) feel better.",4 Defining Counseling Quality,[0],[0]
"However, it is advantageous to focus on the conversation actor (counselor) instead of individual conversations.
",4 Defining Counseling Quality,[0],[0]
"There are several benefits of focusing analyses on counselors (rather than individual conversations): First, we are interested in general conversation strategies rather than properties of main issues (e.g., depression vs. suicide).",4 Defining Counseling Quality,[0],[0]
"While each conversation is different and will revolve around its main issue, we assume that counselors have a particular style and strategy that is invariant across conversations.",4 Defining Counseling Quality,[0],[0]
"Second, we assume that conversation quality is noisy.",4 Defining Counseling Quality,[0],[0]
Even a very good counselor will face some hard conversations in which they do everything right but are still unable to make their conversation partner feel better.,4 Defining Counseling Quality,[0],[0]
"Over time, however, the “true” quality of the counselor will become apparent.",4 Defining Counseling Quality,[0],[0]
"Third, our goal is to understand successful conversation strategies and to make use of these insights in counselor training.",4 Defining Counseling Quality,[0],[0]
"Focusing on the counselor is helpful in understanding, monitoring, and improving counselors’ conversation strategies.
",4 Defining Counseling Quality,[0],[0]
More vs. Less Successful Counselors.,4 Defining Counseling Quality,[0],[0]
We split the counselors into two groups and then compare their behavior.,4 Defining Counseling Quality,[0],[0]
"Out of the 113 counselors with more than 15 labeled conversations of at least 30 messages each, we use the most successful 40 counselors as “more successful” counselors and the bottom 40 as “less successful” counselors.",4 Defining Counseling Quality,[0],[0]
"Their average success rates are 66.3-85.5% and 42.1-58.6%, respectively.",4 Defining Counseling Quality,[0],[0]
"While the counselor-level analysis is of primary concern, we will also differentiate between counselor behavior in “positive” versus “negative” conversations (i.e., those that will eventually make the texter feel better vs. not).",4 Defining Counseling Quality,[0],[0]
"Thus, in the remainder of the paper we differentiate between more vs. less successful counselors and positive vs. negative conver-
sations. Studying the cross product of counselors and conversations allows us to gain insights on how both groups behave in positive and negative conversations.",4 Defining Counseling Quality,[0],[0]
"For example, Figure 1 illustrates why differentiating between counselors and as well as conversations is necessary: differences in counselor message length over the course of the conversation are bigger between more and less successful counselors than between positive and negative conversations.
",4 Defining Counseling Quality,[0],[0]
Initial Analysis.,4 Defining Counseling Quality,[0],[0]
Before focusing on detailed analyses of counseling strategies we address two important questions: Do counselors specialize in certain issues?,4 Defining Counseling Quality,[0],[0]
"And, do successful counselors appear successful only because they handle “easier” cases?
",4 Defining Counseling Quality,[0],[0]
"To gain insights into the “specialization hypothesis” we make use the counselor annotation of the main issue (depression, self-harm, etc.).",4 Defining Counseling Quality,[0],[0]
We compare success rates of counselors across different issues and find that successful counselors have a higher fraction of positive conversations across all issues and that less successful counselors typically do not excel at a particular issue.,4 Defining Counseling Quality,[0],[0]
"Thus, we conclude
that counseling quality is a general trait or skill and supporting that the split into more and less successful counselors is meaningful.
",4 Defining Counseling Quality,[0],[0]
Another simple explanation of the differences between more and less successful counselors could be that successful counselors simply pick “easy” issues.,4 Defining Counseling Quality,[0],[0]
"However, we find that this is not the case.",4 Defining Counseling Quality,[0],[0]
"In particular, we find that both counselor groups are very similar in how they select conversations from the queue (picking the top-most in 60.1% vs. 60.3%, respectively), work similar shifts, and handle a similar number of conversations simultaneously (1.98 vs. 1.83).",4 Defining Counseling Quality,[0],[0]
"Further, we find that both groups face similar distributions of issues over time (see Table 2).",4 Defining Counseling Quality,[0],[0]
"We attribute the largest difference, “NA” (main issue not reported), to the more successful counselors being more diligent in filling out the post-conversation report and having fewer conversations that end before the main issue is introduced.",4 Defining Counseling Quality,[0],[0]
In the remainder of the paper we focus on factors that mediate the outcome of a conversation.,5 Counselor Adaptability,[0],[0]
"First, we examine whether successful counselors are more aware that their current conversation is going well or badly and study how the counselor adapts to the situation.",5 Counselor Adaptability,[0],[0]
We investigate this question by looking for language differences between positive and negative conversations.,5 Counselor Adaptability,[0],[0]
"In particular, we compute a distance measure between the language counselors use in positive conversations and the language counselors use in negative conversations and observe how this distance changes over time.
",5 Counselor Adaptability,[0],[0]
We capture the time dimension by breaking up each conversation into five even chunks of messages.,5 Counselor Adaptability,[0],[0]
"Then, for each set of counselors (more successful or less successful), conversation outcome (positive or negative), and chunk (first 20%, second 20%, etc.), we build a TF-IDF vector of word occurrences to represent the language of counselors within this subset.",5 Counselor Adaptability,[0],[0]
"We use the global inverse document (i.e., conversation) frequencies instead of the ones from each subset to make the vectors directly comparable and control for different counselors having different numbers of conversations by weighting conversations so all counselors have equal contributions.",5 Counselor Adaptability,[0],[0]
"We then measure the difference between the “posi-
tive” and “negative” vector representations by taking the cosine distance in the induced vector space.",5 Counselor Adaptability,[0],[0]
"We also explored using Jensen-Shannon divergence between traditional probabilistic language models and found these methods gave similar results.
Results.",5 Counselor Adaptability,[0],[0]
We find more successful counselors are more sensitive to whether the conversation is going well or badly and vary their language accordingly (Figure 2).,5 Counselor Adaptability,[0],[0]
"At the beginning of the conversation, the language between positive and negative conversations is quite similar, but then the distance in language increases over time.",5 Counselor Adaptability,[0],[0]
"This increase in distance is much larger for more successful counselors than less successful ones, suggesting they are more aware of when conversations are going poorly and adapt their counseling more in an attempt to remedy the situation.",5 Counselor Adaptability,[0],[0]
"Observing that successful counselors are better at adapting to the conversation, we next examine how counselors differ and what factors determine the differences.",6 Reacting to Ambiguity,[0],[0]
"In particular, domain experts have suggested that more successful counselors are better at handling ambiguity in the conversation (Levitt and Jacques, 2005).",6 Reacting to Ambiguity,[0],[0]
"Here, we use ambiguity to refer to the uncertainty of the situation and the texter’s actual core issue resulting from insufficiently short or uncertain descriptions.",6 Reacting to Ambiguity,[0],[0]
Does initial ambiguity of the situation negatively affect the conversation?,6 Reacting to Ambiguity,[0],[0]
"How do more successful counselors deal with ambiguous situations?
Ambiguity.",6 Reacting to Ambiguity,[0],[0]
Throughout this section we measure ambiguity in the conversation as the shortness of the texter’s responses in number of words.,6 Reacting to Ambiguity,[0],[0]
"While ambiguity could also be measured through concreteness ratings of the words in each message (e.g., using concreteness ratings from Brysbaert et al. (2014)), we find that results are very similar and that length and concreteness are strongly related and hard to distinguish.",6 Reacting to Ambiguity,[0],[0]
"It is challenging to measure ambiguity and reactions to ambiguity at arbitrary points throughout the conversation since it strongly depends on the context of the entire conversation (i.e., all earlier messages and questions).",6.1 Initial Ambiguity and Situation Setter,[0],[0]
"However, we can study nearly identi-
cal beginnings of conversations where we can directly compare how more successful and less successful counselors react given nearly identical situations (the texter first sharing their reason for texting in).",6.1 Initial Ambiguity and Situation Setter,[0],[0]
"We identify the situation setter within each conversation as the first long message by the texter (typically a response to a “Can you tell me more about what is going on?” question by the counselor).
Results.",6.1 Initial Ambiguity and Situation Setter,[0],[0]
We find that ambiguity plays an important role in counseling conversations.,6.1 Initial Ambiguity and Situation Setter,[0],[0]
"Figure 3 shows that more ambiguous situations (shorter length of situation setter) are less likely to result in successful conversations (we obtain similar results when measuring concreteness (Brysbaert et al., 2014) directly).",6.1 Initial Ambiguity and Situation Setter,[0],[0]
"Further, we find that counselors generally react to short and ambiguous situation setters by writing significantly more than the texters (Figure 4; if counselors wrote exactly as much as the texter, we would expect a horizontal line y = 1).",6.1 Initial Ambiguity and Situation Setter,[0],[0]
"However, more successful counselors react more strongly to ambiguous situations than less successful counselors.",6.1 Initial Ambiguity and Situation Setter,[0],[0]
"Having observed that ambiguity plays an important role in counseling conversations, we now examine in greater detail how counselors respond to nearly identical situations.
",6.2 How to Respond to Ambiguity,[0],[0]
"We match situation setters by representing them through TF-IDF vectors on bigrams and find similar situation setters as nearest neighbors within a certain cosine distance in the induced space.1 We only consider situation setters that are part of a dense cluster with at least 10 neighbors, allowing us to compare follow-up responses by the counselors (4829/12770 situation setters were part of one of 589 such clusters).",6.2 How to Respond to Ambiguity,[0],[0]
"We also used distributed word embeddings (e.g., (Mikolov et al., 2013))",6.2 How to Respond to Ambiguity,[0],[0]
instead of TF-IDF vectors,6.2 How to Respond to Ambiguity,[0],[0]
"but found the latter to produce better clusters.
",6.2 How to Respond to Ambiguity,[0],[0]
"Based on counselor training materials we hypothesize that more successful counselors
• address ambiguity by writing more themselves, • use more check questions (statements that tell
the conversation partner that you understand 1 Threshold manually set after qualitative analysis of matches from randomly chosen clusters.",6.2 How to Respond to Ambiguity,[0],[0]
"Results were not overly sensitive to threshold choice, choice of representation (e.g., word vectors), and distance measure (e.g., Euclidean).
them while avoiding the introduction of any opinion or advice (Labov and Fanshel, 1977); e.g.“that sounds like...”),
• check for suicidal thoughts early (e.g., “want to die”),
• thank the texter for showing the courage to talk to them (e.g., “appreciate”),
• use more hedges (mitigating words used to lessen the impact of an utterance; e.g., “maybe”, “fairly”),
• and that they are less likely to respond with surprise (e.g., “oh, this sounds really awful”).
",6.2 How to Respond to Ambiguity,[0],[0]
"A set of regular expressions is used to detect each class of responses (similar to the examples above).
",6.2 How to Respond to Ambiguity,[0],[0]
Results.,6.2 How to Respond to Ambiguity,[0],[0]
We find several statistically significant differences in how counselors respond to nearly identical situation setters (see Table 3).,6.2 How to Respond to Ambiguity,[0],[0]
"While situation setters tend to be slightly longer for more successful counselors (suggesting that conversations are not perfectly randomly assigned), counselor responses are significantly longer and also spur longer texter responses.",6.2 How to Respond to Ambiguity,[0],[0]
"Further, the more successful counselors respond in a way that is less similar to the original situation setter (measured by cosine similarity in TFIDF space) compared to less successful counselors (but the texter’s response does not seem affected).",6.2 How to Respond to Ambiguity,[0],[0]
"We do find that more successful counselors use more check questions, check for suicide ideation more often, show the texter more appreciation, and use more hedges, but we did not find a significant difference with respect to responding with surprise.",6.2 How to Respond to Ambiguity,[0],[0]
"In Section 6.2, we observed that more successful counselors make use of certain templates (including check questions, checks for suicidal thoughts, affirmation, and using hedges).",6.3 Response Templates and Creativity,[0],[0]
"While this could suggest that counselors should stick to such predefined templates, we find that, in fact, more successful counselors do respond in more creative ways.
",6.3 Response Templates and Creativity,[0],[0]
"We define a measure of how “templated” the counselors responses are by counting the number of similar responses in TF-IDF space for the counselor reaction (c.f., Section 6.2; again using a manually defined and validated threshold on cosine distance).
",6.3 Response Templates and Creativity,[0],[0]
Figure 5 shows that more successful counselors use less common/templated questions.,6.3 Response Templates and Creativity,[0],[0]
"This suggests that while more successful counselors questions follow certain patterns, they are more creative in their response to each situation.",6.3 Response Templates and Creativity,[0],[0]
"This tailoring of responses requires more effort from the counselor, which is consistent with the results in Figure 1 that showed that more successful counselors put in more effort in composing longer messages as well.",6.3 Response Templates and Creativity,[0],[0]
"After demonstrating content-level differences between counselors, we now explore temporal differences in how counselors progress through conversations.",7 Ensuring Conversation Progress,[0],[0]
"Using an unsupervised conversation model, we are able to discover distinct conversation stages and find differences between counselors in how they
move through these stages.",7 Ensuring Conversation Progress,[0],[0]
We further provide evidence that these differences could be related to power and authority by measuring linguistic coordination between the counselor and texter.,7 Ensuring Conversation Progress,[0],[0]
Counseling conversations follow a common structure due to the nature of conversation as well as counselor training.,7.1 Unsupervised Conversation Model,[0],[0]
"Typically, counselors first introduce themselves, get to know the texter and their situation, and then engage in constructive problem solving.",7.1 Unsupervised Conversation Model,[0],[0]
"We employ unsupervised conversation modeling techniques to capture this stage-like structure within conversations.
",7.1 Unsupervised Conversation Model,[0],[0]
Our conversation model is a message-level Hidden Markov Model (HMM).,7.1 Unsupervised Conversation Model,[0],[0]
Figure 6 illustrates the basic model where hidden states of the HMM represent conversation stages.,7.1 Unsupervised Conversation Model,[0],[0]
"Unlike in prior work on conversation modeling, we impose a fixed ordering on the stages and only allow transitions from the current stage to the next one (Figure 7).",7.1 Unsupervised Conversation Model,[0],[0]
This causes it to learn a fixed dialogue structure common to all of the counseling sessions as opposed to conversation topics.,7.1 Unsupervised Conversation Model,[0],[0]
"Furthermore, we separately model counselor and texter messages by treating their turns in the conversation as distinct states.",7.1 Unsupervised Conversation Model,[0],[0]
"We train the conversation model with expectation maximization, using the forward-backward algorithm to produce the distributions during each expectation step.",7.1 Unsupervised Conversation Model,[0],[0]
We initialized the model with each stage producing messages according to a unigram distribution estimated from all messages in the dataset and uniform transition probabilities.,7.1 Unsupervised Conversation Model,[0],[0]
"The unigram language models are defined over all words occurring more than 20 times (over 98% of words in the dataset), with other words replaced by an unknown token.
",7.1 Unsupervised Conversation Model,[0],[0]
Results.,7.1 Unsupervised Conversation Model,[0],[0]
We explored training the model with various numbers of stages and found five stages to produce a distinct and easily interpretable representation of a conversation’s progress.,7.1 Unsupervised Conversation Model,[0],[0]
Table 4 shows the words most unique to each stage.,7.1 Unsupervised Conversation Model,[0],[0]
The first and last stages consist of the basic introductions and wrapups common to all conversations.,7.1 Unsupervised Conversation Model,[0],[0]
"In stage 2, the texter introduces the main issue, while the counselor asks for clarifications and expresses empathy for the situation.",7.1 Unsupervised Conversation Model,[0],[0]
"In stage 3, the counselor and texter discuss the problem, particularly in relation to the other
people involved.",7.1 Unsupervised Conversation Model,[0],[0]
"In stage 4, the counselor and texter discuss actionable strategies that could help the texter.",7.1 Unsupervised Conversation Model,[0],[0]
This is a well-known part of crisis counselor training called “collaborative problem solving.”,7.1 Unsupervised Conversation Model,[0],[0]
Do counselors differ in how much time they spend at each stage?,7.2 Analyzing Counselor Progression,[0],[0]
"In order to explore how counselors progress through the stages, we use the Viterbi algorithm to assign each conversation the most likely sequence of stages according to our conversation model.",7.2 Analyzing Counselor Progression,[0],[0]
We then compute the average duration in messages of each stage for both more and less successful counselors.,7.2 Analyzing Counselor Progression,[0],[0]
"We control for the different distributions of positive and negative conversations among more successful and less successful counselors by giving the two classes of conversations equal weight and control for different conversation lengths by only including conversations between 40 and 60 messages long.
Results.",7.2 Analyzing Counselor Progression,[0],[0]
"We find that more successful counselors are quicker to move past the earlier stages, partic-
ularly stage 2, and spend more time in later stages, particularly stage 4 (Figure 8).",7.2 Analyzing Counselor Progression,[0],[0]
"This suggests they are able to more quickly get to know the texter and then spend more time in the problem solving phase of the conversation, which could be one of the reasons they are more successful.",7.2 Analyzing Counselor Progression,[0],[0]
One possible explanation for the more successful counselors’ ability to quickly move through the early stages is that they have more “power” in the conversation and can thus exert more control over the progression of the conversation.,7.3 Coordination and Power Differences,[0],[0]
"We explore this idea by analyzing linguistic coordination, which measures how much the conversation partners adapt to each other’s conversational styles.",7.3 Coordination and Power Differences,[0],[0]
"Research has shown that conversation participants who have a greater position of power coordinate less (i.e., they do not adapt their linguistic style to mimic the other conversational participant as strongly) (DanescuNiculescu-Mizil et al., 2012).
",7.3 Coordination and Power Differences,[0],[0]
"In our analysis, we use the “Aggregated 2” coordination measure C(B,A) from Danescu-NiculescuMizil (2012), which measures how much group B coordinates to group A (a higher number means more coordination).",7.3 Coordination and Power Differences,[0],[0]
"The measure is computed by
counting how often specific markers (e.g., auxiliary verbs) are exhibited in conversations.",7.3 Coordination and Power Differences,[0],[0]
"If someone tends to use a particular marker right after their conversation partner uses that marker, it suggests they are coordinating to their partner.
",7.3 Coordination and Power Differences,[0],[0]
"Formally, let set S be a set of exchanges, each involving an initial utterance u1 by a ∈ A and a reply u2 by b ∈",7.3 Coordination and Power Differences,[0],[0]
B.,7.3 Coordination and Power Differences,[0],[0]
"Then the coordination of b to A according to a linguistic marker m is:
Cm(b, A) = P (Emu2→u1 |Emu1)− P (Emu2→u1) where Emu1 is the event that utterance u1 exhibits m (i.e., contains a word from category m) and Emu2→u1 is the event that reply u2 to u1 exhibits m. The probabilities are estimated across all exchanges in S. To aggregate across different markers, we average the coordination values of Cm(b, A) over all markers m to get a macro-average C(b, A).",7.3 Coordination and Power Differences,[0],[0]
"The coordination between groups B and A is then defined as the mean of the coordinations of all members of group B towards the group A.
",7.3 Coordination and Power Differences,[0],[0]
"We use eight markers from Danescu-NiculescuMizil (2012), which are considered to be processed by humans in a generally non-conscious fashion: articles, auxiliary verbs, conjunctions, high-frequency adverbs, indefinite pronouns, personal pronouns, prepositions, and quantifiers.
Results.",7.3 Coordination and Power Differences,[0],[0]
"Texters coordinate less than counselors, with texters having a coordination value of C(texter, counselor)=0.019 compared to the counselor’s C(counselor, texter)=0.030, suggesting that the texters hold more “power” in the conversation.",7.3 Coordination and Power Differences,[0],[0]
"However, more successful counselors coordinate less than less successful ones (C(more succ.",7.3 Coordination and Power Differences,[0],[0]
"counselors, texter)=0.029 vs. C(less succ.",7.3 Coordination and Power Differences,[0],[0]
"counselors, texter)=0.032).",7.3 Coordination and Power Differences,[0],[0]
All differences are statistically significant (p < 0.01; MannWhitney U test).,7.3 Coordination and Power Differences,[0],[0]
"This suggests that more successful counselors act with more control over the conversa-
tion, which could explain why they are quicker to make it through the initial conversation stages.",7.3 Coordination and Power Differences,[0],[0]
"Thus far, we have studied conversation dynamics and their relation to conversation success from the counselor perspective.",8 Facilitating Perspective Change,[0],[0]
"In this section, we show that perspective change in the texter over time is associated with a higher likelihood of conversation success.",8 Facilitating Perspective Change,[0],[0]
"Prior work has shown that day-to-day changes in writing style are associated with positive health outcomes (Campbell and Pennebaker, 2003), and existing theories link depression to a negative view of the future (Pyszczynski et al., 1987) and a selffocusing style (Pyszczynski and Greenberg, 1987).",8 Facilitating Perspective Change,[0],[0]
"Here, we propose a novel measure to quantify three orthogonal aspects of perspective change within a single conversation: time, self, and sentiment.",8 Facilitating Perspective Change,[0],[0]
"Further, we show that the counselor might be able to actively induce perspective change.
",8 Facilitating Perspective Change,[0],[0]
Time.,8 Facilitating Perspective Change,[0],[0]
"Texters start explaining their issue largely in terms of the past and present but over time talk more about the future (see Figure 9A; each plot shows the relative amount of words in the LIWC past, present, and future categories (Tausczik and Pennebaker, 2010)).",8 Facilitating Perspective Change,[0],[0]
We find that texters writing more about the future are more likely to feel better after the conversation.,8 Facilitating Perspective Change,[0],[0]
"This suggests that changing the perspective from issues in the past towards the future is associated with a higher likelihood of successfully working through the crisis.
",8 Facilitating Perspective Change,[0],[0]
Self.,8 Facilitating Perspective Change,[0],[0]
"Another important aspect of behavior change is to what degree the texter is able to change their perspective from talking about themselves to considering others and potentially the effect of their situation on others (Pyszczynski and Greenberg, 1987; Campbell and Pennebaker, 2003).",8 Facilitating Perspective Change,[0],[0]
"We measure how much the texter is focused on themselves by the relative amount of first person singular pronouns (I, me, mine) versus third person singular/plural pronouns (she, her, him / they, their), again using LIWC.",8 Facilitating Perspective Change,[0],[0]
"Figure 9B shows that a smaller amount of self-focus is associated with more successful conversations (providing support for the self-focus model of depression (Pyszczynski and Greenberg, 1987)).",8 Facilitating Perspective Change,[0],[0]
"We hypothesize that the lack of difference at the end of the conversation is due to conversation norms such
as thanking the counselor (“I really appreciate it.”)",8 Facilitating Perspective Change,[0],[0]
"even if the texter does not actually feel better.
Sentiment.",8 Facilitating Perspective Change,[0],[0]
"Lastly, we investigate how much a change in sentiment of the texter throughout the conversation is associated with conversation success.",8 Facilitating Perspective Change,[0],[0]
We measure sentiment as the relative fraction of positive words using the LIWC PosEmo and NegEmo sentiment lexicons.,8 Facilitating Perspective Change,[0],[0]
"The results in Figure 9C show that texters always start out more negative (value below 0.5), but that the sentiment becomes more positive over time for both positive and negative conversations.",8 Facilitating Perspective Change,[0],[0]
"However, we find that the separation between both groups grows larger over time, which suggests that a positive perspective change throughout the conversation is related to higher likelihood of conversation success.",8 Facilitating Perspective Change,[0],[0]
We find that both curves increase significantly at the very end of the conversation.,8 Facilitating Perspective Change,[0],[0]
"Again, we attribute this to conversation norms such as thanking the counselor for listening even when the texter does not actually feel better.",8 Facilitating Perspective Change,[0],[0]
"Together with the result on talking about the future, these findings are consistent with the theory of Pyszczynski et al.",8 Facilitating Perspective Change,[0],[0]
"(1987) that depression is related to a negative view of the future.
",8 Facilitating Perspective Change,[0],[0]
Role of a Counselor.,8 Facilitating Perspective Change,[0],[0]
"Given that positive conversations often exhibit perspective change, a natural question is how counselors can encourage perspective change in the texter.",8 Facilitating Perspective Change,[0],[0]
"We investigate this by exploring the hypothesis that the texter will tend to talk more about something (e.g., the future), if the counselor first talks about it.",8 Facilitating Perspective Change,[0],[0]
"We measure this tendency using the same coordination measures as Section 7.3 except that instead of using stylistic LIWC markers (e.g., auxiliary verbs, quantifiers), we use the LIWC markers relevant to the particular aspect of perspective change (e.g., Future, HeShe, PosEmo).",8 Facilitating Perspective Change,[0],[0]
In all cases we find a statistically significant (p < 0.01; Mann-Whitney U-test) increase in the likelihood of the texter using a LIWC marker if the counselor used it in the previous message (~4-5% change).,8 Facilitating Perspective Change,[0],[0]
This link between perspective change and how the counselor conducts the conversation suggests that the counselor might be able to actively induce measurable perspective change in the texter.,8 Facilitating Perspective Change,[0],[0]
"In this section, we combine our quantitative insights into a prediction task.",9 Predicting Counseling Success,[0],[0]
We show that the linguistic aspects of crisis counseling explored in previous sections have predictive power at the level of individual conversations by evaluating their effectiveness as features in classifying the outcome of conversations.,9 Predicting Counseling Success,[0],[0]
"Specifically, we create a balanced dataset of positive and negative conversations more than 30 messages long and train a logistic regression model to predict the outcome given the first x% of messages in the conversation.",9 Predicting Counseling Success,[0],[0]
There are 3619 such negative conversations and and we randomly subsample the larger set of positive conversations.,9 Predicting Counseling Success,[0],[0]
We train the model with batch gradient descent and use L1 regularization when n-gram features are present and L2 regularization otherwise.,9 Predicting Counseling Success,[0],[0]
"We evaluate our model with 10-fold cross-validation and compare models using the area under the ROC curve (AUC).
",9 Predicting Counseling Success,[0],[0]
Features.,9 Predicting Counseling Success,[0],[0]
"We include three aspects of counselor messages discussed in Section 6: hedges, check questions, and the similarity between the counselor’s message and previous texter message.",9 Predicting Counseling Success,[0],[0]
We add a measure of how much progress the counselor has made (Section 7) by computing the Viterbi path of stages for the conversation (only for the first x%) with the HMM conversation model and then adding the duration of each stage (in #messages) as a feature.,9 Predicting Counseling Success,[0],[0]
"Additionally, we add average message length
and average sentiment per message using VADER sentiment (Hutto and Gilbert, 2014).",9 Predicting Counseling Success,[0],[0]
"Further, we add temporal dynamics to the model by adding feature conjunctions with the stages HMM model.",9 Predicting Counseling Success,[0],[0]
"After running the stages model over the x% of the conversation available to the classifier, we add each feature’s average value over each stage as additional features.",9 Predicting Counseling Success,[0],[0]
"Lastly, we explore the benefits of adding surface-level text features to the model by adding unigram and bigram features.",9 Predicting Counseling Success,[0],[0]
"Because the focus of this work is on counseling strategies, we primarily experiment with models using only features from counselor messages.",9 Predicting Counseling Success,[0],[0]
"For completeness, we also report results for a model including texter features.
",9 Predicting Counseling Success,[0],[0]
Prediction Results.,9 Predicting Counseling Success,[0],[0]
"The model’s accuracy increases with x, and we show that the model is able to dis-
tinguish positive and negative conversations after only seeing the first 20% of the conversation (see Figure 10).",9 Predicting Counseling Success,[0],[0]
"We attribute the significant increase in performance for x = 100 (Accuracy=0.687, AUC=0.716) to strong linguistic cues that appear as a conversation wraps up (e.g., “I’m glad you feel better.”).",9 Predicting Counseling Success,[0],[0]
"To avoid this issue, our detailed feature analysis is performed at x = 80.
",9 Predicting Counseling Success,[0],[0]
Feature Analysis.,9 Predicting Counseling Success,[0],[0]
The model performance as features are incrementally added to the model is shown in Table 5.,9 Predicting Counseling Success,[0],[0]
All features improve model accuracy significantly (p < 0.001; paired bootstrap resampling test).,9 Predicting Counseling Success,[0],[0]
Adding n-gram features produces the largest boost in AUC and significantly improves over a model just using n-gram features (0.638 vs. 0.652 AUC).,9 Predicting Counseling Success,[0],[0]
Note that most features in the full model are based on word frequency counts that can be derived from n-grams which explains why a simple n-gram model already performs quite well.,9 Predicting Counseling Success,[0],[0]
"However, our model performs well with only a small set of linguistic features, demonstrating they provide a substantial amount of the predictive power.",9 Predicting Counseling Success,[0],[0]
"The effectiveness of these features shows that, in addition to exhibiting group-level differences reported earlier in this paper, they provide useful signal for predicting the outcome of individual conversations.",9 Predicting Counseling Success,[0],[0]
Knowledge about how to conduct a successful counseling conversation has been limited by the fact that studies have remained largely qualitative and smallscale.,10 Conclusion & Future Work,[0],[0]
"In this work, we presented a large-scale quan-
titative study on the discourse of counseling conversations.",10 Conclusion & Future Work,[0],[0]
We developed a set of novel computational discourse analysis methods suited for largescale datasets and used them to discover actionable conversation strategies that are associated with better conversation outcomes.,10 Conclusion & Future Work,[0],[0]
We hope that this work will inspire future generations of tools available to people in crisis as well as their counselors.,10 Conclusion & Future Work,[0],[0]
"For example, our insights could help improve counselor training and give rise to real-time counseling quality monitoring and answer suggestion support tools.
",10 Conclusion & Future Work,[0],[0]
Acknowledgements.,10 Conclusion & Future Work,[0],[0]
"We thank Bob Filbin for facilitating the research, Cristian Danescu-NiculescuMizil for many helpful discussions, and Dan Jurafsky, Chris Manning, Justin Cheng, Peter Clark, David Hallac, Caroline Suen, Yilun Wang and the anonymous reviewers for their valuable feedback on the manuscript.",10 Conclusion & Future Work,[0],[0]
"This research has been supported in part by NSF CNS-1010921, IIS-1149837, NIH BD2K, ARO MURI, DARPA XDATA, DARPA SIMPLEX, Stanford Data Science Initiative, Boeing, Lightspeed, SAP, and Volkswagen.",10 Conclusion & Future Work,[0],[0]
Mental illness is one of the most pressing public health issues of our time.,abstractText,[0],[0]
"While counseling and psychotherapy can be effective treatments, our knowledge about how to conduct successful counseling conversations has been limited due to lack of large-scale data with labeled outcomes of the conversations.",abstractText,[0],[0]
"In this paper, we present a large-scale, quantitative study on the discourse of text-message-based counseling conversations.",abstractText,[0],[0]
We develop a set of novel computational discourse analysis methods to measure how various linguistic aspects of conversations are correlated with conversation outcomes.,abstractText,[0],[0]
"Applying techniques such as sequence-based conversation models, language model comparisons, message clustering, and psycholinguistics-inspired word frequency analyses, we discover actionable conversation strategies that are associated with better conversation outcomes.",abstractText,[0],[0]
Large-scale Analysis of Counseling Conversations: An Application of Natural Language Processing to Mental Health,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2344–2356 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2344",text,[0],[0]
"Being a classic language exercise, the cloze test (Taylor, 1953) is an accurate assessment of language proficiency (Fotos, 1991; Jonz, 1991; Tremblay, 2011) and has been widely employed in language examinations.",1 Introduction,[0],[0]
"Under a typical setting, a cloze test requires examinees to fill in missing words (or sentences) to best fit the surrounding context.",1 Introduction,[0],[0]
"To facilitate natural language understanding, automatically-generated cloze datasets are introduced to measure the ability of machines in reading comprehension (Hermann et al., 2015; Hill et al., 2016; Onishi et al., 2016).",1 Introduction,[0],[0]
"In these datasets, each cloze question typically consists of
∗ Equal contribution.",1 Introduction,[0],[0]
1CLOTH (CLOze test by TeacHers) is available at http://www.cs.cmu.edu/˜glai1/data/cloth/. 2The leaderboard is available at http://www.,1 Introduction,[0],[0]
"qizhexie.com/data/CLOTH_leaderboard.html
",1 Introduction,[0],[0]
a context paragraph and a question sentence.,1 Introduction,[0],[0]
"By randomly replacing a particular word in the question sentence with a blank symbol, a single test case is created.",1 Introduction,[0],[0]
"For instance, CNN/Daily Mail datasets (Hermann et al., 2015) use news articles as contexts and summary bullet points as the question sentence.",1 Introduction,[0],[0]
Only named entities are removed when creating the blanks.,1 Introduction,[0],[0]
"Similarly, in Children’s Books test (CBT) (Hill et al., 2016), cloze questions are obtained by removing a word in the last sentence of every consecutive 21 sentences, with the first 20 sentences being the context.",1 Introduction,[1.0],"['Similarly, in Children’s Books test (CBT) (Hill et al., 2016), cloze questions are obtained by removing a word in the last sentence of every consecutive 21 sentences, with the first 20 sentences being the context.']"
"Different from CNN/Daily Mail datasets, CBT also provides each question with a candidate answer set, consisting of randomly sampled words with the same part-of-speech tag from the context as that of the correct answer.
",1 Introduction,[0.9999999745471218],"['Different from CNN/Daily Mail datasets, CBT also provides each question with a candidate answer set, consisting of randomly sampled words with the same part-of-speech tag from the context as that of the correct answer.']"
"Thanks to the automatic generation process, these datasets can be very large in size, leading to significant research progresses.",1 Introduction,[0],[0]
"However, compared to how humans would create cloze questions and evaluate reading comprehension ability, the automatic generation process bears some inevitable issues.",1 Introduction,[0],[0]
"Firstly, blanks are chosen uniformly without considering which aspect of the language phenomenon that questions will test.",1 Introduction,[0],[0]
"Hence, quite a portion of automatically-generated questions can be purposeless or even trivial to answer.",1 Introduction,[0],[0]
Another issue involves the ambiguity of answers.,1 Introduction,[0],[0]
"Given a context and a sentence with a blank, there can be multiple words that fit almost equally well into the blank.",1 Introduction,[0],[0]
"A possible solution is to include a candidate option set, as done by CBT, to get rid of the ambiguity.",1 Introduction,[0],[0]
"However, automatically generating the candidate option set can be problematic since it cannot guarantee the ambiguity is removed.",1 Introduction,[0],[0]
"More importantly, automaticallygenerated candidates can be totally irrelevant or simply grammatically unsuitable for the blank, resulting in again purposeless or trivial questions.
",1 Introduction,[0],[0]
"Probably due to these unsatisfactory issues, neural models have achieved comparable results to the human-level performance within a very short time (Chen et al., 2016; Dhingra et al., 2016; Seo et al., 2016).",1 Introduction,[0],[0]
"While there have been works trying to incorporate human design into cloze question generation (Zweig and Burges, 2011; Paperno et al., 2016), due to the expensive labeling process, the MSR Sentence Completion Challenge created by this effort has 1, 040 questions and the LAMBADA (Paperno et al., 2016) dataset has 10, 022 questions, limiting the possibility of developing powerful neural models on it.",1 Introduction,[1.0],"['While there have been works trying to incorporate human design into cloze question generation (Zweig and Burges, 2011; Paperno et al., 2016), due to the expensive labeling process, the MSR Sentence Completion Challenge created by this effort has 1, 040 questions and the LAMBADA (Paperno et al., 2016) dataset has 10, 022 questions, limiting the possibility of developing powerful neural models on it.']"
"As a result of the small size, human-created questions are only used to compose development sets and test sets.",1 Introduction,[0],[0]
"Motivated by the aforementioned drawbacks, we propose CLOTH, a large-scale cloze test dataset collected from English exams.",1 Introduction,[1.0],"['Motivated by the aforementioned drawbacks, we propose CLOTH, a large-scale cloze test dataset collected from English exams.']"
Questions in the dataset are designed by middle-school and highschool teachers to prepare Chinese students for entrance exams.,1 Introduction,[1.0],['Questions in the dataset are designed by middle-school and highschool teachers to prepare Chinese students for entrance exams.']
"To design a cloze test, teachers firstly determine the words that can test students’ knowledge of vocabulary, reasoning or grammar; then replace those words with blanks and provide other three candidate options for each blank.",1 Introduction,[0],[0]
"If a question does not specifically test grammar usage, all of the candidate options would complete the sentence with correct grammar, leading to highly nuanced questions.",1 Introduction,[0],[0]
"As a result, human-created questions are usually harder and are a better assessment of language proficiency.",1 Introduction,[0],[0]
"A general cloze test evaluates several aspects of language proficiency including vocabulary, reasoning and grammar, which are key components of comprehending natural language.
",1 Introduction,[0],[0]
"To verify if human-created cloze questions are difficult for current models, we train and evaluate the state-of-the-art language model (LM) and machine comprehension models on this dataset, including a language model trained on the One Billion Word Corpus.",1 Introduction,[0],[0]
We find that the state-of-theart model lags behind human performance even if the model is trained on a large external corpus.,1 Introduction,[1.0],['We find that the state-of-theart model lags behind human performance even if the model is trained on a large external corpus.']
We analyze where the model fails compared to humans who perform well.,1 Introduction,[0],[0]
"After conducting error analysis, we assume the performance gap results from the model’s inability to use a long-term context.",1 Introduction,[0],[0]
"To examine this assumption, we evaluate human-level performance when the human subjects are only allowed to see one sentence as the context.",1 Introduction,[0],[0]
"Our assumption is confirmed by the
matched performances of the models and human when given only one sentence.",1 Introduction,[0],[0]
"In addition, we demonstrate that human-created data is more difficult than automatically-generated data.",1 Introduction,[0],[0]
"Specifically, it is much easier for the same model to perform well on automatically-generated data.
",1 Introduction,[0],[0]
We hope that CLOTH provides a valuable testbed for both the language modeling community and the machine comprehension community.,1 Introduction,[0],[0]
"Specifically, the language modeling community can use CLOTH to evaluate their models’ abilities in modeling long contexts, while the machine comprehension community can use CLOTH to test machine’s understanding of language phenomena.",1 Introduction,[0],[0]
"Large-scale automatically-generated cloze tests (Hermann et al., 2015; Hill et al., 2016; Onishi et al., 2016) lead to significant research advancements.",2 Related Work,[0],[0]
"However, generated questions do not consider language phenomenon to be tested and are relatively easy to solve.",2 Related Work,[0],[0]
"Recently proposed reading comprehension datasets are all labeled by humans to ensure a high quality (Rajpurkar et al., 2016; Joshi et al., 2017; Trischler et al., 2016; Nguyen et al., 2016).
",2 Related Work,[0],[0]
"Perhaps the closet work to CLOTH is the LAMBADA dataset (Paperno et al., 2016).",2 Related Work,[0],[0]
LAMBADA also targets at finding challenging words to test LM’s ability in comprehending a longer context.,2 Related Work,[0],[0]
"However, LAMBADA does not provide a candidate set for each question, which can cause ambiguities when multiple words can fit in.",2 Related Work,[0],[0]
"Furthermore, only test set and development set are labeled manually.",2 Related Work,[0],[0]
"The provided training set is the unlabeled Book Corpus (Zhu et al., 2015).",2 Related Work,[0],[0]
"Such unlabeled data do not emphasize long-dependency questions and have a mismatched distribution with the test set, as showed in Section 5.",2 Related Work,[0],[0]
"Further, the Book Corpus is too large to allow rapid algorithm development for researchers who do not have access to a huge amount of computational power.
",2 Related Work,[0],[0]
"Aiming to evaluate machines under the same conditions that the humans are evaluated, there is a growing interest in obtaining data from examinations.",2 Related Work,[0],[0]
"NTCIR QA Lab (Shibuki et al., 2014) contains a set of real-world college entrance exam questions.",2 Related Work,[0],[0]
"The Entrance Exams task at CLEF QA Track (Peñas et al., 2014; Rodrigo et al., 2015) evaluates machine’s reading comprehension abil-
ity.",2 Related Work,[0],[0]
"The AI2 Reasoning Challenge (Clark et al., 2018; Schoenick et al., 2017) contains approximately eight thousand scientific questions used in middle school.",2 Related Work,[0],[0]
Lai et al. (2017) proposes the first large-scale machine comprehension dataset obtained from exams.,2 Related Work,[0],[0]
They show that questions designed by teachers have a significantly larger proportion of reasoning questions.,2 Related Work,[0],[0]
Our dataset focuses on evaluating both language proficiency and reasoning abilities.,2 Related Work,[0],[0]
"In this section, we introduce the CLOTH dataset that is collected from English examinations, and study its abilities of assessment.",3 CLOTH Dataset,[0],[0]
We collect the raw data from three free and public websites in China that gather exams created by English teachers to prepare students for college/high school entrance exams3.,3.1 Data Collection and Statistics,[1.0],['We collect the raw data from three free and public websites in China that gather exams created by English teachers to prepare students for college/high school entrance exams3.']
"Before cleaning, there are 20, 605 passages and 332, 755 questions.",3.1 Data Collection and Statistics,[0],[0]
We perform the following processes to ensure the validity of data:,3.1 Data Collection and Statistics,[0],[0]
"Firstly, we remove questions with an inconsistent format such as questions with more than four options.",3.1 Data Collection and Statistics,[0],[0]
Then we filter all questions whose validity relies on external information such as pictures or tables.,3.1 Data Collection and Statistics,[0],[0]
"Further, we find that half of the total passages are duplicates and we delete those passages.",3.1 Data Collection and Statistics,[0],[0]
"Lastly, on one of the websites, the answers are stored as images.",3.1 Data Collection and Statistics,[0],[0]
We use two OCR software programs4 to extract the answers from images.,3.1 Data Collection and Statistics,[0],[0]
We discard the questions when results from the two software are different.,3.1 Data Collection and Statistics,[0],[0]
"After the cleaning process, we obtain a clean dataset of 7, 131 passages and 99, 433 questions.
",3.1 Data Collection and Statistics,[0],[0]
"Since high school questions are more difficult than middle school questions, we divide the datasets into CLOTH-M and CLOTH-H, which stand for the middle school part and the high school part.",3.1 Data Collection and Statistics,[0],[0]
We split 11% of the data for both the test set and the development set.,3.1 Data Collection and Statistics,[0],[0]
The detailed statistics of the whole dataset and two subsets are presented in Table 1.,3.1 Data Collection and Statistics,[0],[0]
"Note that the questions were created to test non-native speakers, hence the vocabulary size is not very large.
",3.1 Data Collection and Statistics,[0],[0]
"3 The three websites include http://www.21cnjy.com/; http://5utk.ks5u.com/; http://zujuan.xkw.com/. We checked that CLOTH does not contain sentence completion example questions from GRE, SAT and PSAT.
4tesseract: https://github.com/tesseract-ocr; ABBYY FineReader: https://www.abbyy.com/en-us/finereader/",3.1 Data Collection and Statistics,[0],[0]
"In order to evaluate students’ mastery of a language, teachers usually design tests in a way that questions cover different aspects of a language.",3.2 Question Type Analysis,[0],[0]
"Specifically, they first identify words in the passage that can examine students’ knowledge in vocabulary, logic, or grammar.",3.2 Question Type Analysis,[0],[0]
"Then, they replace the words with blanks and prepare three incorrect but nuanced candidate options to make the test non-trivial.",3.2 Question Type Analysis,[0],[0]
"A sample passage is presented in Table 2.
",3.2 Question Type Analysis,[0],[0]
"To understand the abilities of assessment on this dataset, we divide questions into several types and label the proportion of each type.",3.2 Question Type Analysis,[0],[0]
"According to English teachers who regularly create cloze test questions for English exams in China, there are largely three types: grammar, vocabulary and reasoning.",3.2 Question Type Analysis,[0],[0]
Grammar questions are easily differentiated from other two categories.,3.2 Question Type Analysis,[1.0],['Grammar questions are easily differentiated from other two categories.']
"However, the teachers themselves cannot specify a clear distinction between reasoning questions and vocabulary questions since all questions require comprehending the words within the context and conducting some level of reasoning by recognizing incomplete information or conceptual overlap.
",3.2 Question Type Analysis,[0],[0]
"Hence, we divided the questions except grammar questions based on the difficulty level for a machine to answer the question, following works on analyzing machine comprehension datasets (Chen et al., 2016; Trischler et al., 2016).",3.2 Question Type Analysis,[0],[0]
"In particular, we divide them in terms of their dependency ranges, since questions that only involve a single sentence are easier to answer than questions involving evidence distributed in multiple sentences.",3.2 Question Type Analysis,[0],[0]
"Further, we divided questions involving long-term dependency into matching/paraphrasing questions and reasoning questions since matching questions are easier.",3.2 Question Type Analysis,[0],[0]
"The four types include:
• Grammar: The question is about grammar usage, involving tense, preposition usage, active/passive voices, subjunctive mood and so on.
",3.2 Question Type Analysis,[0],[0]
• Short-term-reasoning: The question is about content words and can be answered based on the information within the same sentence.,3.2 Question Type Analysis,[0],[0]
"Note that the content words can evaluate knowledge of both vocabulary and reasoning.
",3.2 Question Type Analysis,[0],[0]
• Matching/paraphrasing:,3.2 Question Type Analysis,[0],[0]
"The question is answered by copying/paraphrasing a word in the context.
",3.2 Question Type Analysis,[0],[0]
"• Long-term-reasoning: The answer must be inferred from synthesizing information distributed across multiple sentences.
",3.2 Question Type Analysis,[0],[0]
"We sample 100 passages in the high school category and the middle school category respectively with totally 3, 000 questions.",3.2 Question Type Analysis,[0],[0]
The types of these questions are labeled on Amazon Turk.,3.2 Question Type Analysis,[0],[0]
We pay $1 and $0.5 for high school passages and middle school passages respectively.,3.2 Question Type Analysis,[0],[0]
"We refer readers to Appendix A.1 for details of the labeling processes and the labeled sample passage.
",3.2 Question Type Analysis,[0],[0]
The proportion of different questions is shown in Table 3.,3.2 Question Type Analysis,[0],[0]
"The majority of questions are shortterm-reasoning questions while approximately 22.4% of the data needs long-term information, in which the long-term-reasoning questions constitute a large proportion.",3.2 Question Type Analysis,[1.0],"['The majority of questions are shortterm-reasoning questions while approximately 22.4% of the data needs long-term information, in which the long-term-reasoning questions constitute a large proportion.']"
"In this section, we investigate if human-created cloze test is a challenging problem for state-ofthe-art models.",4 Exploring Models’ Limits,[0],[0]
We find that LM trained on the One Billion Word Corpus can achieve a remarkable score but cannot solve the cloze test.,4 Exploring Models’ Limits,[0],[0]
"After conducting an error analysis, we hypothesize that the model is not able to deal with long-term dependencies.",4 Exploring Models’ Limits,[0],[0]
We verify the hypothesis by comparing the model’s performance with the human performance when the information humans obtain is limited to one sentence.,4 Exploring Models’ Limits,[0],[0]
"LSTM To test the performance of RNN-based supervised models, we train a bidirectional LSTM (Hochreiter and Schmidhuber, 1997) to predict the missing word given the context with only labeled data.",4.1 Human and Model Performance,[0],[0]
"The implementation details are in Appendix A.3.
",4.1 Human and Model Performance,[0],[0]
"Attentive Readers To enable the model to gather information from a longer context, we aug-
ment the supervised LSTM model with the attention mechanism (Bahdanau et al., 2014), so that the representation at the blank is used as a query to find the relevant context in the document and a blank-specific representation of the document is used to score each candidate answer.",4.1 Human and Model Performance,[0],[0]
"Specifically, we adapt the Stanford Attentive Reader (Chen et al., 2016) and the positionaware attention model (Zhang et al., 2017) to the cloze test problem.",4.1 Human and Model Performance,[1.0],"['Specifically, we adapt the Stanford Attentive Reader (Chen et al., 2016) and the positionaware attention model (Zhang et al., 2017) to the cloze test problem.']"
"With the position-aware attention model, the attention scores are based on both the context match and the distance from a context to the blank.",4.1 Human and Model Performance,[1.0],"['With the position-aware attention model, the attention scores are based on both the context match and the distance from a context to the blank.']"
"Both attention models are trained only with human-created blanks just as the LSTM model.
",4.1 Human and Model Performance,[0],[0]
LM,4.1 Human and Model Performance,[0],[0]
"In cloze test, the context on both sides may be enough to determine the correct answer.",4.1 Human and Model Performance,[0],[0]
"Suppose xi is the missing word and x1, · · · , xi−1, xi+1, · · · , xn are the context, we choose xi that maximizes the joint probability p(x1, · · · , xn), which essentially maximizes the conditional likelihood p(xi | x1, · · · , xi−1, xi+1, · · · , xn).",4.1 Human and Model Performance,[1.0],"['Suppose xi is the missing word and x1, · · · , xi−1, xi+1, · · · , xn are the context, we choose xi that maximizes the joint probability p(x1, · · · , xn), which essentially maximizes the conditional likelihood p(xi | x1, · · · , xi−1, xi+1, · · · , xn).']"
"Therefore, LM can be naturally adapted to cloze test.
",4.1 Human and Model Performance,[0],[0]
"In essence, LM treats each word as a possible blank and learns to predict it.",4.1 Human and Model Performance,[0],[0]
"As a result, it receives more supervision than the LSTM trained on human-labeled questions.",4.1 Human and Model Performance,[0],[0]
"Besides training a neural LM on our dataset, interested in whether the state-of-the-art LM can solve cloze test, we also test the LM trained on the One Billion Word Benchmark (Chelba et al., 2013) (referred as 1BLM) that achieves a perplexity of 30.0 (Jozefowicz et al., 2016)5.",4.1 Human and Model Performance,[0],[0]
"To make the evaluation time tractable, we limit the context length to one sentence or three sentences.",4.1 Human and Model Performance,[0],[0]
"Note that the One Billion Word Corpus does not overlap with the CLOTH
5The pre-trained model is obtained from https://github.com/tensorflow/models/tree/master/research/ lm 1b
Passage: Nancy had just got a job as a secretary in a company.",4.1 Human and Model Performance,[0],[0]
"Monday was the first day she went to work, so she was very 1 and arrived early.",4.1 Human and Model Performance,[0],[0]
She 2 the door open and found nobody there.,4.1 Human and Model Performance,[0],[0]
”I am the 3 to arrive.”,4.1 Human and Model Performance,[0],[0]
She thought and came to her desk.,4.1 Human and Model Performance,[0],[0]
She was surprised to find a bunch of 4 on it.,4.1 Human and Model Performance,[0],[0]
They were fresh.,4.1 Human and Model Performance,[0],[0]
She 5 them and they were sweet.,4.1 Human and Model Performance,[0],[0]
She looked around for a 6 to put them in.,4.1 Human and Model Performance,[0],[0]
”Somebody has sent me flowers the very first day!”,4.1 Human and Model Performance,[0],[0]
she thought 7 . ”,4.1 Human and Model Performance,[0],[0]
But who could it be?”,4.1 Human and Model Performance,[0],[0]
she began to 8 .,4.1 Human and Model Performance,[0],[0]
The day passed quickly and Nancy did everything with 9 interest.,4.1 Human and Model Performance,[0],[0]
"For the following days of the 10 , the first thing Nancy did was to change water for the followers and then set about her work.",4.1 Human and Model Performance,[0],[0]
Then came another Monday.,4.1 Human and Model Performance,[0],[0]
11,4.1 Human and Model Performance,[0],[0]
she came near her desk she was overjoyed to see a(n) 12 bunch of flowers there.,4.1 Human and Model Performance,[0],[0]
"She quickly put them in the vase, 13 the old ones.",4.1 Human and Model Performance,[0],[0]
The same thing happened again the next Monday.,4.1 Human and Model Performance,[0],[0]
Nancy began to think of ways to find out the 14 .,4.1 Human and Model Performance,[0],[0]
"On Tuesday afternoon, she was sent to hand in a plan to the 15 .",4.1 Human and Model Performance,[0],[0]
She waited for his directives at his secretary’s 16 .,4.1 Human and Model Performance,[0],[0]
"She happened to see on the desk a half-opened notebook, which 17 : ”In order to keep the secretaries in high spirits, the company has decided that every Monday morning a bunch of fresh flowers should be put on each secretarys desk.”",4.1 Human and Model Performance,[0],[0]
"Later, she was told that their general manager was a business management psychologist.
corpus.
Human performance We measure the performance of Amazon Mechanical Turkers on 3, 000 sampled questions when the whole passage is given.
",4.1 Human and Model Performance,[0],[0]
Results The comparison is shown in Table 4.,4.1 Human and Model Performance,[0],[0]
Both attentive readers achieve similar accuracy to the LSTM.,4.1 Human and Model Performance,[0],[0]
We hypothesize that the reason of the attention model’s unsatisfactory performance is that the evidence of a question cannot be simply found by matching the context.,4.1 Human and Model Performance,[0],[0]
"Similarly, on reading comprehension, though attention-based models (Wang et al., 2017; Seo et al., 2016; Dhingra
et al., 2016) have reached human performance on the SQuAD dataset (Rajpurkar et al., 2016), their performance is still not comparable to human performance on datasets that focus more on reasoning where the evidence cannot be simply found by a matching behavior (Lai et al., 2017; Xu et al., 2017).",4.1 Human and Model Performance,[0],[0]
"Since the focus of this paper is to analyze the proposed dataset, we leave the design of reasoning oriented attention models for future work.
",4.1 Human and Model Performance,[0],[0]
The LM achieves much better performance than LSTM.,4.1 Human and Model Performance,[0],[0]
"The gap is larger when the LM is trained on the 1 Billion Word Corpus, indicating that more training data results in a better generalization.",4.1 Human and Model Performance,[0],[0]
"Specifically, the accuracy of 1B-LM is 0.695 when one sentence is used as the context.",4.1 Human and Model Performance,[0],[0]
It indicates that LM can learn sophisticated language regularities when given sufficient data.,4.1 Human and Model Performance,[0],[0]
"The same conclusion can also be drawn from the success of a concurrent work ELMo which uses LM representations as word vectors and achieves state-ofthe-art results on six language tasks (Peters et al.,
2018).",4.1 Human and Model Performance,[0],[0]
"However, if we increase the context length to three sentences, the accuracy of 1B-LM only has a marginal improvement.",4.1 Human and Model Performance,[0],[0]
"In contrast, humans outperform 1B-LM by a significant margin, which demonstrates that deliberately designed questions in CLOTH are not completely solved even for state-of-the-art models.",4.1 Human and Model Performance,[0],[0]
"In this section, we would like to understand why 1B-LM lags behind human performance.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
We find that most of the errors involve long-term reasoning.,4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"Additionally, in a lot of cases, the dependency is within the context of three sentences.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
We show several errors made by the 1B-LM in Table 5.,4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"In the first example, the model does not know that Nancy found nobody in the company means that Nancy was the first one to arrive at the company.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"In the second and third example, the model fails probably because of not recognizing “they” referred to “flowers”.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
The dependency in the last case is longer.,4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"It depends on the fact that Nancy was alone in the company.
",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"Based on the case study, we hypothesize that the LM is not able to take long-term information into account, although it achieves a surprisingly good overall performance.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"Additionally, the 1BLM is trained on the sentence level, which might also result in the inability to track paragraph level information.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"However, to investigate the differences between training on sentence level and on paragraph level, a prohibitive amount of computational resource is required to train a large model on the 1 Billion Word Corpus.
",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[1.0000000253052654],"['However, to investigate the differences between training on sentence level and on paragraph level, a prohibitive amount of computational resource is required to train a large model on the 1 Billion Word Corpus.']"
"On the other hand, a practical comparison is to test the model’s performance on different types of questions.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"We find that the model’s accuracy is 0.591 on long-term-reasoning questions of CLOTH-H while it achieves 0.693 on short-termreasoning (a comprehensive type-specific performance is available in Appendix A.3), which partially confirms that long-term-reasoning is harder.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"However, we could not completely rely on the performance on specific questions types, partly due to a large variance caused by the small sample size.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
Another reason is that the reliability of question type labels depends on whether turkers are careful enough.,4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[1.0],['Another reason is that the reliability of question type labels depends on whether turkers are careful enough.']
"For example, in the error analysis shown in Table 5, a careless turker would label the second example as short-term-reasoning without noticing
that the meaning of “they” relies on a long context.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[1.0000000260422885],"['For example, in the error analysis shown in Table 5, a careless turker would label the second example as short-term-reasoning without noticing that the meaning of “they” relies on a long context.']"
"To objectively verify if the LM’s strengths lie in dealing with short-term information, we obtain the ceiling performance of only utilizing shortterm information.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"Showing only one sentence as the context, we ask the Turkers to select an option based on their best guesses given the insufficient information.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"By limiting the context span manually, the ceiling performance with the access to only a short context is estimated accurately.
",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[1.0000000160153455],"['By limiting the context span manually, the ceiling performance with the access to only a short context is estimated accurately.']"
"As shown in Table 6, The performance of 1BLM using one sentence as the context can almost match the human ceiling performance of only using short-term information.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[1.0],"['As shown in Table 6, The performance of 1BLM using one sentence as the context can almost match the human ceiling performance of only using short-term information.']"
Hence we conclude that the LM can almost perfectly solve all shortterm cloze questions.,4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"However, the performance of LM is not improved significantly when a longterm context is given, indicating that the performance gap is due to the inability of long-term reasoning.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"In this section, we demonstrate that humancreated data is a better testbed than automaticallygenerated cloze test since it results in a larger gap between model’s performance and human performance.
",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
A casual observation is that a cloze test can be created by randomly deleting words and randomly sampling candidate options.,5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"In fact, to generate large-scale data, similar generation processes have been introduced and widely used in machine comprehension (Hermann et al., 2015; Hill et al., 2016; Onishi et al., 2016).",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"However, research on cloze test design (Sachs et al., 1997) shows that tests created by deliberately deleting words are more reliable than tests created by randomly or periodically deleting words.",5 Comparing Human-created Data and Automatically-generated Data,[1.0],"['However, research on cloze test design (Sachs et al., 1997) shows that tests created by deliberately deleting words are more reliable than tests created by randomly or periodically deleting words.']"
"To design accurate language proficiency assessment, teachers usually deliberately select words in order to examine students’ proficiency in grammar, vocabulary and reasoning.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"Moreover, in order to make the question non-trivial, three incorrect options provided by teachers are usually grammatically correct and relevant to the context.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"For instance, in the fourth problem of the sample passage shown in Table 2, “grapes”, “flowers” and “bananas” all fit the description of being fresh.
",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"Hence we naturally hypothesize that humangenerated data has distinct characteristics when
compared with automatically-generated data.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"To verify this assumption, we compare the LSTM model’s performance when given different proportions of the two types of data.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"Specifically, to train a model with α percent of automatically-generated data, we randomly replace a percent blanks with blanks at random positions, while keeping the remaining 1 − α percent questions the same.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
The candidate options for the generated blanks are random words sampled from the unigram distribution.,5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"We test models obtained with varying α on human-created data and automatically-generated data respectively.
",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"From the comparison in Table 7, we have the following observations: (1) human-created data leads to a larger gap between model’s performance and the ceiling/human performance.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"The model’s performance and human’s performance
on the human-created data are 0.484 and 0.859 respectively, as shown in Tab. 4, leading to a gap of 0.376.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"In comparison, the performance gap on the automatically-generated data is at most 0.185 since the model’s performance reaches an accuracy of 0.815 when fully trained on generated data.",5 Comparing Human-created Data and Automatically-generated Data,[1.0],"['In comparison, the performance gap on the automatically-generated data is at most 0.185 since the model’s performance reaches an accuracy of 0.815 when fully trained on generated data.']"
"(2) Although human-created data may provide more information in distinguishing similar words, the distributional mismatch between two types of data makes it non-trivial to transfer the knowledge gained from human-created data to tackle automatically-generated data.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"Specifically, the model’s performance on automatically-generated data monotonically decreases when given a higher ratio of human-created data.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"In Section 4.1, we show that LM is able to take advantage of more supervision since it predicts each word based on the context.",6 Combining Human-created Data with Automatically-generated Data,[0],[0]
"At the same time, we also show that human-created data and the automatically-generated data are quite different in Section 5.",6 Combining Human-created Data with Automatically-generated Data,[0],[0]
"In this section, we propose a model that takes advantage of both sources.",6 Combining Human-created Data with Automatically-generated Data,[0],[0]
"Specifically, for each question, regardless of being human-created or automatically-generated, we can compute the negative log likelihood of the correct answer as the loss function.",6.1 Representative-based Model,[0],[0]
"Suppose JH is the average negative log likelihood loss for human-created questions and JR is the loss function on generated questions, we combine losses on human-created questions and generated questions by simply adding them together, i.e., JR + JH is used as the final loss function.",6.1 Representative-based Model,[0],[0]
"We will introduce the definition of JR in the following paragraphs.
",6.1 Representative-based Model,[0],[0]
"Although automatically-generated data has a
large quantity and is valuable to the model training, as shown in the previous Section, automatically-generated questions are quite different from human-created questions.",6.1 Representative-based Model,[0],[0]
"Ideally, a large amount of human-created questions is more desirable than a large amount of automaticallygenerated questions.",6.1 Representative-based Model,[0],[0]
A possible avenue towards having large-scale human-created data is to automatically pick out a large number of generated questions which are representative of or similar to human-created questions.,6.1 Representative-based Model,[1.0],['A possible avenue towards having large-scale human-created data is to automatically pick out a large number of generated questions which are representative of or similar to human-created questions.']
"In other words, we train a network to predict whether a question is a generated question or a human-created question.",6.1 Representative-based Model,[1.0],"['In other words, we train a network to predict whether a question is a generated question or a human-created question.']"
A generated question is representative of human-created questions if it has a high probability of being a human-created question.,6.1 Representative-based Model,[0],[0]
"Then we can give higher weights to questions that resemble human-created question.
",6.1 Representative-based Model,[0],[0]
We first introduce our method to obtain the representativeness information.,6.1 Representative-based Model,[0],[0]
"Let x denote the passage and z denote whether a word is selected as a question by human, i.e., z is 1 if this word is selected to be filled in the original passage or 0 otherwise.",6.1 Representative-based Model,[1.0],"['Let x denote the passage and z denote whether a word is selected as a question by human, i.e., z is 1 if this word is selected to be filled in the original passage or 0 otherwise.']"
Suppose hi is the representation of i-th word given by a bidirectional LSTM.,6.1 Representative-based Model,[0],[0]
"The network computes the probability pi of xi being a humancreated question as follows:
",6.1 Representative-based Model,[0],[0]
li = h T,6.1 Representative-based Model,[0],[0]
"i wxi ; pi = Sigmoid(li)
where li is the logit which will be used as in the final model and wxi is the the word embedding.",6.1 Representative-based Model,[0],[0]
"We train the network to minimize the binary cross entropy between p and ground-truth labels at each token.
",6.1 Representative-based Model,[0],[0]
"After obtaining the representativeness information, we define the representativeness weighted loss function as
JR = ∑ i 6∈H Softmaxi( l1 α , · · · , ln α )",6.1 Representative-based Model,[0],[0]
"Ji
where Ji denotes the negative log likelihood loss for the i−th question and let li be the output representativeness of the i-th question and H is the set of all human-generated questions and α is the temperature of the Softmax function.",6.1 Representative-based Model,[0],[0]
The model degenerates into assigning a uniform weight to all questions when the temperature is +∞. We set α to 2 based on the performance on the dev set.,6.1 Representative-based Model,[0],[0]
"6.
6The code is available at https://github.com/qizhex/Largescale-Cloze-Test-Dataset-Created-by-Teachers",6.1 Representative-based Model,[0],[0]
We summarize performances of all models in Table 8.,6.2 Results,[0],[0]
"Our representativeness model outperforms all other models that do not use external data on CLOTH, CLOTH-H and CLOTH-M.",6.2 Results,[0],[0]
"In this section, we verify the effectiveness of the representativeness-based averaging by ablation studies.",6.3 Analysis,[0],[0]
"When we remove the representativeness information by setting α to infinity, the accuracy drops from 0.583 to 0.566.",6.3 Analysis,[0],[0]
"When we further remove the human-created data so that only generated data is employed, the accuracy drops to 0.543, similar to the performance of LM.",6.3 Analysis,[0],[0]
"The results further confirm that it is beneficial to incorporate human-created questions into training.
",6.3 Analysis,[0],[0]
A sample of the predicted representativeness is shown in Figure 17.,6.3 Analysis,[0],[0]
"Clearly, words that are too obvious have low scores, such as punctuation marks, simple words “a” and “the”.",6.3 Analysis,[0],[0]
"In contrast, content words whose semantics are directly related to the context have a higher score, e.g., “same”, “similar”, “difference” have a high score when the difference between two objects is discussed and “secrets” has a high score since it is related to the subsequent sentence “does not want to share with others”.",6.3 Analysis,[0],[0]
"Our prediction model achieves an F1 score of 36.5 on the test set, which is understandable since
7The script to generate the Figure is obtained at https://gist.github.com/ihsgnef/ f13c35cd46624c8f458a4d23589ac768
there are many plausible questions within a passage.
",6.3 Analysis,[0],[0]
"It has been shown that features such as morphology information and readability are beneficial in cloze test prediction (Skory and Eskenazi, 2010; Correia et al., 2012, 2010; Kurtasov, 2013).",6.3 Analysis,[0],[0]
We leave investigating the advanced approaches of automatically designing cloze test to future work.,6.3 Analysis,[0],[0]
"In this paper, we propose a large-scale cloze test dataset CLOTH that is designed by teachers.",7 Conclusion and Discussion,[1.0],"['In this paper, we propose a large-scale cloze test dataset CLOTH that is designed by teachers.']"
"With missing blanks and candidate options carefully created by teachers to test different aspects of language phenomena, CLOTH requires a deep language understanding and better captures the complexity of human language.",7 Conclusion and Discussion,[0],[0]
We find that human outperforms 1B-LM by a significant margin.,7 Conclusion and Discussion,[0],[0]
"After detailed analysis, we find that the performance gap is due to the model’s inability to understanding a long context.",7 Conclusion and Discussion,[0],[0]
"We also show that, compared to automatically-generated questions, human-created questions are more difficult and lead to a larger margin between human performance and the model’s performance.
",7 Conclusion and Discussion,[1.0000000468498866],"['We also show that, compared to automatically-generated questions, human-created questions are more difficult and lead to a larger margin between human performance and the model’s performance.']"
"Despite the excellent performance of 1B-LM when compared with models trained only on CLOTH, it is still important to investigate and create more effective models and algorithms which provide complementary advantages to having a large amount of data.",7 Conclusion and Discussion,[0],[0]
"For rapid algorithm developments, we suggest training models only on the training set of CLOTH and comparing with models that do not utilize external data.
",7 Conclusion and Discussion,[0],[0]
We hope our dataset provides a valuable testbed to the language modeling community and the machine comprehension community.,7 Conclusion and Discussion,[1.0],['We hope our dataset provides a valuable testbed to the language modeling community and the machine comprehension community.']
"In particular, the language modeling community can use
CLOTH to evaluate their models’ abilities in modeling a long context.",7 Conclusion and Discussion,[0],[0]
"In addition, the machine comprehension community may also find CLOTH useful in evaluating machine’s understanding of language phenomena including vocabulary, reasoning and grammar, which are key components of comprehending natural language.
",7 Conclusion and Discussion,[0],[0]
"In our future work, we would like to design algorithms to better model a long context, to utilize external knowledge, and to explore more effective semi-supervised learning approaches.",7 Conclusion and Discussion,[0],[0]
"Firstly, we would like to investigate efficient ways of utilizing external knowledge such as paraphrasing and semantic concepts like prior works (Dong et al., 2017; Dasigi et al., 2017).",7 Conclusion and Discussion,[0],[0]
"In comparison, training on a large external dataset is actually a time-consuming way of utilizing external knowledge.",7 Conclusion and Discussion,[0],[0]
"Secondly, to use the generated questions more effectively, the representative-based semisupervised approach might be improved by techniques studied in active learning and hard example mining (Settles, 2009; Shrivastava et al., 2016; Chang et al., 2017).",7 Conclusion and Discussion,[0],[0]
"We thank Yulun Du, Kaiyu Shi and Zhilin Yang for insightful discussions and suggestions on the draft.",Acknowledgement,[0],[0]
We thank Shi Feng for the script to highlight representative words.,Acknowledgement,[0],[0]
This research was supported in part by DARPA grant FA8750-12-20342 funded under the DEFT program.,Acknowledgement,[0],[0]
"A.1 Question Type Labeling To label the questions, we provided the definition and an example for each question category to the Amazon Mechanical Turkers.",A Appendix,[0],[0]
"To ensure quality, we limited the workers to master Turkers who are experienced and maintain a high acceptance rate.",A Appendix,[0],[0]
"However, we did not restrict the backgrounds of the Turkers since master Turkers should have a reasonable amount of knowledge about English to conduct previous tasks.",A Appendix,[0],[0]
"In addition, the vocabulary used in CLOTH are usually not difficult since they are constructed to test non-native speakers in middle school or high school.",A Appendix,[1.0],"['In addition, the vocabulary used in CLOTH are usually not difficult since they are constructed to test non-native speakers in middle school or high school.']"
"To get a concrete idea of the nature of question types, please refer to examples shown in Tab. 10.
",A Appendix,[0],[0]
A.2 Type-specific Performance Analysis We can also further verify the strengths and weaknesses of the 1B-LM by studying the performance of models and human on different question categories.,A Appendix,[0],[0]
Note that the performance presented here may be subject to a high variance due to the limited number of samples in each category.,A Appendix,[0],[0]
"From the comparison shown in Figure 2, we see that 1B-LM is indeed good at short-term questions.",A Appendix,[1.0],"['From the comparison shown in Figure 2, we see that 1B-LM is indeed good at short-term questions.']"
"Specifically, when the human only has access to the context of one sentence, 1B-LM is close to human’s performance on almost all categories.",A Appendix,[0],[0]
"Further, comparing LM and 1B-LM, we find that training on the large corpus leads to improvements on all categories, showing that training on a large amount of data leads to a substantial improvement in learning complex language regularities.
",A Appendix,[0],[0]
A.3 Implementation Details,A Appendix,[0],[0]
"We implement our models using PyTorch (Paszke et al., 2017).",A Appendix,[0],[0]
We train our model on all questions in CLOTH and test it on CLOTH-M and CLOTH-H separately.,A Appendix,[0],[0]
"For our final model, we use Adam (Kingma and Ba, 2014) with the learning rate of 0.001.",A Appendix,[0],[0]
"The hidden dimension is set to 650 and we initialize the word embedding by 300-dimensional Glove word vector (Pennington et al., 2014).",A Appendix,[1.0],"['The hidden dimension is set to 650 and we initialize the word embedding by 300-dimensional Glove word vector (Pennington et al., 2014).']"
The temperature α is set to 2.,A Appendix,[0],[0]
"We tried to increase the dimensionality of the model but do not observe performance improvement.
",A Appendix,[0],[0]
"When we train the small LM on CLOTH, we largely follow the recommended hyperparameters in the Pytorch LM example8.",A Appendix,[0],[0]
"Specifically, we employ a 2-layer LSTM with hidden dimension as 1024.",A Appendix,[0],[0]
The input embedding and output weight matrix are tied.,A Appendix,[0],[0]
We set the dropout rate to 0.5.,A Appendix,[0],[0]
"The initial learning rate is set to 10 and divided by 4 whenever the PPL stops improving on the dev set.
",A Appendix,[0],[0]
"We predict the answer for each blank independently for all of the models mentioned in this paper, since we do not observe significant performance improvements in our preliminary experiments when an auto-regressive approach is employed, i.e., when we fill all previous blanks with predicted answers.",A Appendix,[0],[0]
"We hypothesize that, regardless of whether there exist inter-blank dependencies, since blanks are usually
8https://github.com/pytorch/examples/tree/master/word language model
distributed far away from each other, LSTM is not able to capture such long dependencies.",A Appendix,[0],[0]
"When testing language models, we use the longest text spans that do not contain blanks.",A Appendix,[0],[0]
Cloze tests are widely adopted in language exams to evaluate students’ language proficiency.,abstractText,[0],[0]
"In this paper, we propose the first large-scale human-created cloze test dataset CLOTH 1 2, containing questions used in middle-school and high-school language exams.",abstractText,[0],[0]
"With missing blanks carefully created by teachers and candidate choices purposely designed to be nuanced, CLOTH requires a deeper language understanding and a wider attention span than previously automaticallygenerated cloze datasets.",abstractText,[0],[0]
We test the performance of dedicatedly designed baseline models including a language model trained on the One Billion Word Corpus and show humans outperform them by a significant margin.,abstractText,[0],[0]
"We investigate the source of the performance gap, trace model deficiencies to some distinct properties of CLOTH, and identify the limited ability of comprehending the long-term context to be the key bottleneck.",abstractText,[0],[0]
Large-scale Cloze Test Dataset Created by Teachers,title,[0],[0]

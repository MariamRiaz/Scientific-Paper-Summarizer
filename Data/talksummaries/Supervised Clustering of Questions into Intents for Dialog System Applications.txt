0	55	The recent years have seen a resurgent interest for dialog systems, ranging from help desks and more complex task-based dialog to general purpose conversational agents, e.g., Alexa, Cortana or Siri.
1	13	All these different application scenarios show that users expect to formulate complex information needs in natural language, with no limitation to their expressiveness.
2	19	In other words, standard shallow semantic parsing based on concept segmentation and labeling is no longer sufficient for dialog modeling in today’s applications.
6	14	This is a rather costly, difficult and time consuming task, which can often prevent the fast prototyping of dialog systems even for small domains.
8	33	For example, in the recent 2016/2017 Natural Language Understanding Benchmarks (Coucke et al., 2017), the organizers have evaluated built-in intents generated by the major dialog managers (Apple’s SiriKit, Amazon’s Alexa, Microsoft’s Luis, Google’s Dialogflow, and Snips.ai) against a rather small set of relatively generic intents (e.g., GetWeather).
10	13	To our knowledge, no previous work has been dedicated to automatizing this task, mainly because the underlying problem, semantic question paraphrasing, is very challenging.
12	41	In this paper, we propose a model for automatically clustering questions into user intent categories, which can help the design of dialog systems.
13	21	Our approach aims at overcoming the difficulty of providing a unique definition of intent from either a theoretical or practical perspective.
16	14	This is one of our major contributions: providing an effective supervised clustering approach, which can learn definitions from examples.
19	172	The main difference with CR consists in substituting mentions and their vector representation with the one of entire questions.
21	17	To train our model, we define a clustering corpus by automatically deriving question clusters from the Quora data, complementing the available question pair annotation with the transitive closure of the semantic matching property.
57	27	In this paper, we explore techniques for clustering questions into user intent.
58	62	To this end, an input set of questions Q undergoes splitting into subsets (clusters), ci = {qij} Ni j=1, where q i j is the j-th ques- tion in the cluster i of sizeNi and ⊔ i ci = Q.
59	42	Each ci is assumed to contain questions with the same intent, i.e., to represent a distinct intent.
62	41	In this work, we pose the task as a supervised clustering problem following the formulation by Finley and Joachims (2005).
63	40	Having the train- ing examples of the form {(xi,yi)}ni=1, where each input xi is a set of elements of some nature and yi – the corresponding gold standard clustering of such a set, the goal is to learn a predictor h : X → Y , from the space of sets X to the space of clusterings Y .
64	21	Supervised clustering has been shown particularly effective for the NLP task of coreference resolution (Yu and Joachims, 2009; Fernandes et al., 2014).
65	16	These models learn to infer an optimal clustering y of an input set x in a structured way, i.e., as one output object optimizing a global scoring function f : X × Y → R. This is different from local models, which aggregate multiple clustering decisions taken with respect to pairs of elements.
66	20	At the test time, the global models draw predictions by finding ŷ = argmax y∈Y f(x,y).
67	21	(1) In the following, we give the necessary details of the original approach of Yu and Joachims (2009) and its adaptation for clustering questions.
70	31	The nodes, aka elements represented by them, in each connected component (spanning tree) of h are considered to belong to the same cluster.
73	69	A linear model w is trained using the Latent formulation of the Structural SVM learner (LSSVM), to score the output clusterings according to the function f(x,y,h) = w · Φ(x,y,h).
79	53	In such work, the classifier is trained with SVMs, which learn a classification function f : Q × Q → {0, 1} on duplicate vs. non-duplicate pairs of questions belonging to the question set Q.
84	11	, 4]), after stopword removal, greedy string tiling (Wise, 1996), longest common subsequences (Allison and Dix, 1986), Jaccard coefficient (Jaccard, 1901), word containment (Lyon et al., 2001), and cosine similarity.
89	17	The original Quora task requires detecting whether two questions are semantically duplicate or not.
95	39	Note that the coders label pairs in isolation, only having access to one pair to be labeled at a time on Quora website (answer base).
102	14	In (3), the lexical material is very similar, yet the questions are rather distinct, as reflected in the Quora annotation.
103	24	They also express very different user intents: while q1 is a generic curiosity question about automobiles, q2 is a practical request for information on R&D in the automotive industry.
104	64	Example (4) shows why Quora duplicate detection task is very challenging and requires a very good level of NL Understanding: while these three questions are very similar on the surface level, they all convey distinct semantics.
105	38	Differently from the original task, in this work, we are interested in automatically acquiring intents from large question repositories.

12	66	Depending on the task objective, geocoding methodologies can be divided into two distinct categories: (1) document geocoding, which aims at locating a piece of text as a whole, for example geolocating Twitter users (Rahimi et al., 2016, 2017; Roller et al., 2012; Rahimi et al., 2015), Wikipedia articles and/or web pages (Cheng et al., 2010; Backstrom et al., 2010; Wing and Baldridge, 2011; Dredze et al., 2013; Wing and Baldridge, 2014).
17	22	This phase may optionally include metonymy resolution, see (Zhang and Gelernter, 2015; Gritta et al., 2017a).
18	31	The goal of geocoding is to choose the correct coordinates for a location mention from a set of candidates.
30	45	It seems to be mostly rule-based though details of its algorithm are underspecified, short of reading the source code.
31	41	Unlike the Edinburgh Parser, this geocoder seems to overly rely on population data, seemingly mirroring the behaviour of a naive population baseline.
32	19	Rule-based systems can perform well though the variance in performance is high (see Table 1).
34	35	It is unclear how geocoding is performed, however, the inclusion of proprietary methods makes evaluation broader and more informative.
35	76	The statistical geocoder Topocluster (DeLozier et al., 2015) divides the world surface into a grid (0.5 x 0.5 degrees, approximately 60K tiles) and uses lexical features to model the geographic distribution of context words over this grid.
39	41	Roller et al. (2012) used the Good-Turing Frequency Estimation to learn document probability distributions over the vocabulary with Kullback-Leibler divergence as the similarity function to choose the correct bucket in the k-d tree (world representation).
41	28	Among the recent machine learning methods, bag-of-words representations combined with a Support Vector Machine (Melo and Martins, 2015) or Logistic Regression (Wing and Baldridge, 2014) have also achieved good results.
43	20	The machine learning-based geocoder by Santos et al. (2015) supplemented lexical features, represented as a bag-of-words, with an exhaustive set of manually generated geographic features and spatial heuristics such as geospatial containment and geodesic distances between entities.
49	31	Consider an example disambiguation of Cairo in a sentence: “The Giza pyramid complex is an archaeological site on the Giza Plateau, on the outskirts of Cairo, Egypt.”.
50	17	Here, Cairo is the Target Entity; Egypt, Giza and Giza Plateau are the Location Mentions; the rest of the sentence forms the Context Words (excluding stopwords).
52	31	We used separate layers, convolutional and/or dense (fully-connected), with ReLu activations (Nair and Hinton, 2010) to break up the task into smaller, focused modules in order to learn distinct lexical feature patterns, phrases and keywords for different types of inputs, concatenating only at a higher level of abstraction.
117	40	It is an informative metric as it also indicates the total error but treats all errors as equivalent and is sensitive to outliers; (2) Accuracy@161km is the percentage of errors that are smaller than 161km (100 miles).
120	22	While it is not an intuitive metric, AUC is robust to outliers and measures all errors.
121	36	A versatile geocoder should be able to maximise all three metrics.
129	48	High quality, free and open datasets are not readily available (GeoVirus tries to address this).
130	28	The following corpora could not be included: WoTR (DeLozier et al., 2016) due to limited coverage (southern US) and domain type (historical language, the 1860s), (De Oliveira et al., 2017) contains fewer than 180 locations, GeoCorpora (Wallgrün et al., 2017) could not be retrieved in full due to deleted Twitter users/tweets, GeoText (Eisenstein et al., 2010) only allows for user geocoding, SpatialML (Mani et al., 2010) involves prohibitive costs, GeoSemCor (Buscaldi and Rosso, 2008) was annotated with WordNet senses (rather than coordinates).
132	18	It was constructed from free WikiNews8 and collected during 08/2017 - 09/2017.
133	27	The dataset is suitable for the evaluation of Geotagging/Named Entity Recognition and Geocoding/Toponym Resolution.
134	20	Articles were identified using the WikiNews search box and keywords such as Ebola, Bird Flu, Swine Flu, AIDS, Mad Cow Disease, West Nile Disease, etc.
147	24	The geocoding difficulty based on the ambiguity of each dataset is: LGL (moderate to hard), WIK (very hard), GEO (easy to mod- erate).
161	19	The Multi-Layer Perceptron (MLP) model using only MapVec with no lexical features is almost as effective but more importantly, it is significantly better than the population baseline (Table 2).
169	61	To that end, we have evaluated it with the Random Forest without using any lexical features.
170	39	This model was well suited to the geocoding task despite training with only half of the 400K training data (due to memory constraints, partial fit is unavailable for batch training in SciKit Learn).
180	43	We note that GeoVirus has a dual function, NER (not evaluated but useful for future work) and Geocoding.
181	19	We made all of our resources freely available11 for full reproducibility (Goodman et al., 2016).
182	161	The Pearson correlation coefficient of the target entity ambiguity and the error size was only r ≈ 0.2 suggesting that CamCoder’s geocoding errors do not simply rise with location ambiguity.
183	46	Errors were also not correlated (r ≈ 0.0) with population size with all types of locations geocoded to various degrees of accuracy.

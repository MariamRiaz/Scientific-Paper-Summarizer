2	31	For example, what headlines do users click on, and why?
3	17	With the volume of news being consumed online today, there is great interest in addressing this problem algorithmically.
4	14	We collaborate with a large Danish newspaper, who gave us access to several years’ worth of headlines, and the number of clicks generated by readers.
7	14	That work found that bag-ofword models based on headlines did indeed have predictive value concerning viewing behavior, although models based on the article body were more accurate.
11	6	So human readers can “imagine” the article before they read it and implicitly base their behavior on their expectation.” (Hardt and Rambow, 2017) In other words, readers are able to anticipate the contents of an article in advance from a headline, because of the linguistic and world knowledge that they bring to bear when assessing the headline.
13	26	We test this hypothesis by defining ways to model aspects of the lexical, structural, and topical knowledge of human news readers: • Lexical – Word Embeddings: we provide our models with pretrained word embeddings from large datasets.
14	40	This models aspects of the rich lexical information and association that human readers bring to bear in reading a headline.
16	19	• Topical – Section Prediction: Each article is labeled with a section (sports, politics, etc).
18	8	This models the ability of a news reader to understand the most salient and interesting topical material in a headline text.
43	11	The resulting dataset consists of 82,532 articles and a total of 281,005,390 user views.
44	8	We furthermore extracted the news section each article belongs to (sports, politics, etc.)
45	23	We bin the articles by numbers of clicks into 2 bins, thus defining a classification task: is the article in the top 50% of clicks or not?
51	16	The corpus has been automatically annotated for part of speech and lemmatization, and we use this for our POS tagging task.
54	10	Data Statement A. CURATION RATIONALE The dataset is collected by Jyllands-Posten as part of a general strategy to understand user behavior and preferences with respect to the news content on the site.
57	9	D. ANNOTATOR DEMOGRAPHIC There is no manual annotation of the text.
62	55	Logistic Regression We define the following features for logistic regression models: 1. n-chars: sequences of n characters, with n ranging from 2 to 6 in all experiments.
63	18	2. word unigrams: tfidf scores for all word unigrams 3. word bigrams: tfidf scores for all word bigrams GRU Neural Network While the task is classification, which could be done with a feed-forward model, we want a sequential architecture, so that we can incorporate POS tagging as an auxiliary task, adding POS output at each time step.
65	50	Each layer k consists of two sets of units, labeled fw and bw that process the sequence forwards and backwards respectively, so that information from the whole sequence is available on every timestep t. The two directions’ activations are concatenated and fed to a fully-connected softmax (for multi-class classification) or sigmoid layer (for binary classification) to get the output probability ykt of the task associated with layer k. So that higher level tasks can benefit, we embed the output probabilities using the fully connected label embedding LE layer, a technique used on similar scenarios (Rønning et al., 2018).
66	39	The embedded label gets concatenated with the GRU output to get the activation akt that gets fed in the next layer, or the final fully connected prediction layer, as presented in figure 2.
67	71	In the sequential auxiliary task, i.e. POS tagging, this is done for every timestep, while for the classification tasks the prediction is made on the final timestep.
69	83	Auxiliary Tasks In our setup, we use two auxiliary tasks: 1.
79	33	While this is not common with adaptive methods such as Adam, it performed better.
80	11	We stop training if the accuracy on the development set stops improving.
82	7	We also give the best score from Hardt and Rambow (2017) for comparison purposes (note, though, that the data sets are not identical and can therefore not be directly compared).
86	19	Our main focus in this paper is on MTL as a framework to explore the lexical, structural and topical knowledge involved in users’ selection of headlines.
87	71	However, recognizing a popular headline and giving advice on how to write one are not the same: we want to provide editors and journalists with insights as to what constructions are likely to attract more eyeballs.
89	48	Table 3 displays the top 20 unigrams based on their coefficients in the logistic regression model.
92	39	This follows Blom and Hansen (2015), who suggest that headline ”clickbait” often relies on forward-looking expressions, such as ”This”, as in, e.g., ”This is how you should eat an avocado”.
96	24	The second person pronoun is also on the list – in general, it was found that second person pronouns are far more predictive of popularity than first or third person pronouns.
97	17	Finally, several unigrams identify sections of the newspaper of particular interest (car, weather, analysis, and satire).

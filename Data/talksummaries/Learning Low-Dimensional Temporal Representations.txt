50	6	We learn an abstract templateM consisting of ordered temporal structures for each sequence class from all its training sequence samples.
51	4	Each sequence X = [x1,x2, · · · ,xT ] consists of a series of ordered frame-wide feature vectors, where xt is the feature vector extracted from the t-th frame, and T is the length of the sequence.
53	1	Different sequence samples may have different lengths.
62	1	We employ the modified DTW algorithm (Su et al., 2016; 2017b) to compute the optimal warping path.
66	1	The corresponding optimal warping path is obtained by back tracking.
67	1	Based on the dynamic alignment Eq.
71	2	(1) to update the alignment path Pn, for n = 1, · · · , N .
72	1	We Algorithm 1 Abstract template learning Input: {X1, · · · ,XN}; L; a; Output: M;Pn, n = 1, · · · , N ; 1: Initialize the uniform alignment path Pn for the train- ing sequence Xn, for n = 1, · · · , N ; 2: Compute the initial abstract templateM using Eq.
76	1	(2) with the updated Pn again.
82	1	(3) The value of the objective function in Eq.
83	1	(3) decreases by both alternative procedures in Alg.1.
95	1	(6) miu and m j v denote the u-th element of M i and the v-th element of Mj , respectively.
98	2	Constructing the inter-class scatter by Eq.
107	2	1 can still be performed and meaningful scatters can thereby be constructed.
116	1	The alignments may change accordingly, which should be re-calculated using Alg.
137	2	To ensure the convergence and compensate the omitted item when deriving Eq.
140	1	In our experiments, we found that the two procedures can be neglected, and the LT-LDA still converges while the computational complexity is reduced.
154	1	Nt is the total number of vectors in all the training sequences from all the samples.
155	1	Following (Dhillon et al., 2005; Ye et al., 2007), the weighted indicator matrix is defined as F = T(TTT)− 1 2 .
175	1	The complexity of updating P using Alg.
179	1	2 is O(I ′(ICNLTd+ CNTd2 + C2L2d2 + d3)), I ′ is the number of iterations in Alg.
191	1	For the Olympic Sports dataset, we employ the improved dense trajectories (Wang & Schmid, 2013) based frame-wise features.
197	1	For the DTW classifier, the training sequence that has the smallest sum of DTW distances with all other sequences from the same class is selected as the template of this class.
200	2	For the SVM classifier, we encode each sequence into a vector by rank pooling (Fernando et al., 2015).
209	1	LT-LDA achieves the highest multi-class performances when L = 9 on this dataset.
225	5	In the learned subspace of ini-LT-LDA, al- though different classes get better separated under the alignments in the original space, additional confusions may be introduced due to the changes of alignments.
250	4	LT-LDA outperforms the state-of-the-art results using only 45 dimensions.
251	30	In this paper, we have presented a DR method for sequence data, called LT-LDA, which learns the subspace and infers the latent alignments within it simultaneously.
252	213	We formulate the learning of the subspace, the latent alignments, and the temporal structures into a joint objective function, and solve it by iteratively repeating the two alternative procedures of applying LDA and learning the abstract templates.
253	215	The effectiveness of the proposed method is demonstrated on three action datasets with various evaluation measures and classifiers.

0	17	Time-offset interaction allows real-time synchronous conversational interaction with a person who is not only physically absent, but also not engaged in the conversation at the same time.
7	38	One of the biggest questions is how much material needs to be recorded in order to support free-flowing conversation with naive interactors who don’t know specifically what they can ask.
9	25	There we showed that an iterative development process involving two separated recording sessions, with Wizard of Oz testing in the middle, resulted in a body of material of around 2000 responses that could be used to answer over 95% of questions from the desired target audience.
14	15	In this paper, we address the second question, of whether time-offset interaction can be automatically supported at a scale that can support interaction with people who know only the general topic of discussion, not what specific content is available.
18	69	In Section 5, we present our results, 199 showing that over 70% of user utterances can be given a direct answer, and an even higher percentage can reach task success through a clarification process.
31	102	Currently, an important aspect of Holocaust education in museums and classrooms is the opportunity to meet a survivor, hear their story firsthand, and interact with them.
32	44	This direct contact and ability to ask questions literally brings the topic to life and motivates many toward further historical study and ap- preciation and determination of tolerance for others.
33	34	Unfortunately, due to the age of survivors, this opportunity will not be available far into the future.
34	55	The New Dimensions in Testimony project (Maio et al., 2012) is an effort to preserve as much as possible of this kind of interaction.
36	22	The most obvious topic of conversation is Pinchas’ experiences during World War II, including the Nazi invasion of Poland, his time in the Warsaw Ghetto, his experiences in the concentration camps, and his liberation.
42	25	Figure 1 shows the overall system architecture.
45	27	Solid arrows represent messages passed via ActiveMQ and dotted lines represent data going over TCP/IP.
87	53	Instead, these questions formed the basis for an interview script that was used for eliciting the survivor statements during the recording sessions.
88	26	The first training data include the actual utterances used during these elicitation interviews.
109	35	It is impractical to check each of the 400 test utterances against all 1726 possible responses, so instead we used the following procedure to identify responses that are likely to come up in response to specific test questions: we trained the system under different partitions of the training data and different training parameters, ran the test questions through each of the system versions, and from each system run we collected the responses that the system considered appropriate (that is, above threshold) for each question.
124	53	The top answer can be one of three outcomes: it can be appropriate (good), inappropriate (bad), or below threshold, in which case an off-topic response is served.
126	57	This makes it difficult to compare systems with different off-topic rates: how do two systems compare if one gives more good and bad responses than the other, but fewer off-topics?
131	99	Our final training sets include the elicitation questions and system testing 2014 (without Wizard of Oz data), and the same with the system testing 2015 added.
132	157	All of the classifiers were trained in NPCEditor using the same options: text unigrams for the question language models, text unigrams plus IDs for the response language models, and F-score as the classifier scoring function during training.
133	18	We used 3 versions of the test utterances: the transcribed text, the output of Google ASR, and the output of PocketSphinx, and ran each version through each of the 6 classifiers – a total of 18 configurations.
135	36	The responses were ranked by the classifier confidence, and for each possible cutoff point (from returning zero offtopic responses to returning off-topic responses for all 400 utterances), we calculated the number of errors among the on-topic responses and plotted that against the number of off-topics.
152	23	Automatic speech recognition does impose a performance penalty compared to testing on transcriptions, but the penalty is not very large: classifier errors when testing with Google ASR are between 1 and 3 percentage points higher than with transcriptions, while PocketSphinx fares somewhat worse, with classifier errors about 5 to 8 percentage points Test set: Transcriptions Training on all the data higher than with transcriptions.
161	17	The time-offset interaction system has been temporarily installed at the Illinois Holocaust Museum and Education Center in Skokie, Illinois, where visitors interact with the system as part of their museum experience (Isaacs, 2015).
174	37	Time-offset interaction has a large potential impact on preservation and education – people in the future will be able to not only see and listen to historical figures, but also to interact with them in conversation.
175	126	Future research into time-offset interaction will need to generalize the development process, in order to enable efficient use of resources by identifying common user questions that are specific to the person, ones that are specific to the dialogue context or conversation topic, and ones that are of more general application.
183	29	The following dialogue excerpt is taken from the beta testing in Illinois (see section 6).
184	35	Speech recognition output is shown in italics when it departs substantially from the spoken text.
185	30	User Hello Pinchas, how are you?
187	246	Pinchas I can see you and I can hear you.
189	40	how thick is can you hear me Pinchas I can hear you, yeah.

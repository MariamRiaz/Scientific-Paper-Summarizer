3	9	From a destructive perspective, the person could remove one piece at a time from the original model and record where each piece was removed; then, the person could easily construct a replica by reversing the recorded destructive process.
4	15	Analogous to building a replica given an original model, estimating a complex distribution via deep networks given samples from the true distribution can be viewed from the constructive or destructive perspective.
5	44	Deep generative models such as VAEs (Kingma & Welling, 2014; Rezende et al., 2014), GANs (Goodfellow et al., 2014) and variants estimate a constructive transformation from samples of a simple base distribution to samples from a complex distribution (e.g. distribution of real images).1 Formally, this amounts to the following approximation: z ∼ BaseDistribution x̂ ≡ Gφ(z) ∼ GenerativeDistribution , (1) where z is a latent variable, φ are the parameters of the generative network, and x̂ approximates x, the true observed variable.
6	5	As a mirror of the constructive process, we propose estimating an invertible destructive transformation, or destructive flow, from the input distribution to the base distribution: x ∼ DataDistribution ẑ ≡ Dθ(x) ∼ ApproximateBaseDistribution , (2) where x is from the true data distribution and ẑ is an approximation to the base distribution of z.
13	6	Then, by sampling from a Gaussian and computing the inverse transformation, a sample from the original density could be obtained.
16	5	More recently, there has been a line of work that carefully constructs a neural network model to parameterize a valid autoregressive distribution (Germain et al., 2015; Dinh et al., 2015; Graves, 2016; Dinh et al., 2017; Papamakarios et al., 2017).
17	5	These models compute a linear transformation of the inputs but the shift and scale parameters are functions of deep neural networks; thus, these more recent models can be seen as a hybrid between neural networks and linear transformations.
22	20	Our framework can leverage the power of both deep and shallow density estimators to form a deep density model.
25	4	Our destructor definition provides a common interface for all previous methods (with trivial modifications as discussed in future sections) enabling them to be systematically combined, evaluated and improved.
29	9	Merely using shallow density estimates, we train deep density models in a greedy fashion similar to previous work on Gaussianization (e.g. (Tabak & Turner, 2013; Chen & Gopinath, 2000; Laparra et al., 2011)).
30	8	We believe this abstract framework lays the groundwork for developing modular invertible transformations that can be composed, evaluated, and improved separately or together.
47	6	A transformation class {Dθ : θ ∈ Θ} is said to destroy a class of densities {Pψ : ψ ∈ Ψ} if the following properties hold: 1.
55	66	This builds on the intuition of the univariate CDF, which is a destructive transformation class for any univariate distribution that transforms any variable into a univariate uniform variable.
57	6	Importantly, however, it should be noted that this multivariate CDF transformation (where Dθ : Rd → [0, 1]d) is quite different than the multivariate CDF function (where F : Rd → [0, 1]) because it can be inverted unlike the multivariate CDF function.
63	8	1 but also has the following properties: 1.
66	6	The identity requirement in Eq.
74	5	This canonical density destructor class leads us to the following group-theoretic characterization of destructive deep learning models.
76	6	Given a canonical destructive transformation class {Dθ : θ ∈ Θ} defined in Def.
77	10	2, we define the deep density destructor group as the group generated by 〈{Dθ : θ ∈ Θ} ∪ {D−1θ : θ ∈ Θ}〉 where the group operation is function composition.
78	8	The above definition provides an elegant characterization of all possible deep density models of any depth given a destructive transformation class—which can either be defined by the transformation class itself or derived based on a given density class.
104	10	For example, an independent histogram could be used to individually destroy each leaf node before projecting to the appropriate hyperrectangle.
107	5	The main idea is that we can destroy the structure based on pixel locality (i.e. the smoothness property of real images) by destroying the structure of pairs of nearby pixels.
111	20	We implement a simple non-parametric greedy algorithm which merely estimates a density at each layer, transforms the training data via the associated destructor and repeats this process until the likelihood on a held-out validation set decreases.7 Note that layers can be added as long as the model does not overfit the training data.
112	34	For the models in our experiments, we only leverage classical shallow density estimators such as Gaussian mixtures or tree densities at each layer but more advanced density estimators could also be used.
120	11	As the training data is transformed from the original density to the uniform density, the implicit generative density converges towards the true density.
122	75	For this toy experiment, we choose a simple but difficult-to-estimate synthetic dataset of concentric circles as seen in Fig.
124	39	Note that this dataset does not contain any obvious information in the marginals and the underlying density is nearly a low-dimensional manifold—thus very roughly approximating some of the difficult density estimation problems in practice such as Table 1.
125	38	Examples of Density Destructor Classes Description Density Transformation Autoregressive Density ∏d s=1 Ps(xs |x1:s−1) [F1(x1), F2(x2 |x1), · · · , Fd(xd |x1:s−1)] Mixture of Gaussians Conditionals (e.g. MADE, MAF) ∏d s=1 [∑m t=1 πt(x1:s−1)× PN (xs |µst(x1:s−1), σ2st(x1:s−1)) ] [F1(x1), F2(x2 |x1), · · · , Fd(xd |x1, · · · , xs−1) ] Block Gaussian Conditionals (e.g. Real NVP, NICE) PN (x1:t | 0, I) × PN (xt+1:d |µ(x1:t),σ2(x1:t)) [ Φ(x1:t),Φ( xt+1−µt+1(x1:t) σt+1(x1:t) ), · · · ,Φ(xd−µd(x1:t) σd(x1:t) ) ] Linear Projection Density Pψ(Wx) Dθ(Wx) Independent Components (e.g. Gaussianization via ICA) ∏d s=1 Ps(w T s x) F (Wx) Gaussian (e.g. via PCA) PN (x |µ,Σ) Φ(Σ− 1 2 (x− µ)) Copula-based Density Pcop(F (x)) ∏d s=1 Ps(xs) Dθ(F (x)) Gaussian Copula PN -copR (F (x)) ∏d s=1 Ps(xs) Φ(R − 1 2 Φ−1(F (x))) Gaussian Mixture (note that Fs(xs |x−s) is computable) ∑m t=1 πtPN (x) [F1(x1), F2(x2 |x1), · · · , Fd(xd |x1, · · · , xs−1)] Examples of new destructors enabled by our unified destructor framework Piecewise Density (or Tree Density) {Pψ`(x), if x ∈ L`} , where L` are the disjoint subspaces of the leaves.
126	24	{Dθ`(x), if x ∈ L`} Piecewise Uniform (e.g. DET) {c`, if x ∈ L`} {diag(a`)x+ b`, if x ∈ L`} Image-Specific Feature Pairs ∏ P∈P PP (xP (1), xP (2)), where feature pairs P are based on pixel locality.
128	82	The transformed samples (top) and implicit density (bottom) at different layers of the DensityTree (100) model described in Sec.

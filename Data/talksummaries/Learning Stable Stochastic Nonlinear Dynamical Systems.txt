4	69	But often this set of model candidates is difficult to find, especially for complex, possibly non-deterministic, systems (Ljung, 1998).
6	23	We consider the following two application scenarios: First, assume a set of trajectories for a robotic task is given through human demonstrations, e.g., object grasping.
9	27	Second, consider a dynamical system which is known to be stable, e.g., a pendulum which rests in hanging position.
31	16	Based on these measurements, we model the unknown dynamics f̂ including the distribution ω̂k using the prior knowledge, that the stochastic process (1) converges to the origin xk = 0.
34	34	(2b) As different stochastic stability concepts exist, the convergence in (2b) is defined as convergence with probability one (w.p.1) (Kushner, 1971): Definition 1 (Convergence w.p.1).
36	16	This also implies the following type of convergence, which might be more intuitive to the reader.
60	20	The literature on stability criteria for dynamical systems is very rich and for nonlinear systems Lyapunov type methods are often used.
61	87	They are based on the following idea: If there is a function representing the ”energy” in the system (called Lyapunov function) which constantly decreases over time, the state will converge to a ”zero energy” state, the origin.
64	20	Given a positive definite function V (xk) ≥ 0 for which E [V (xk+1)|xk]−V (xk) ≤ −αV (xk), ∀xk ∈ X \ 0, (5) for some α > 0 then E [V (xk+m)|xk] ≤ (1− α)mV (xk) and (6) V (xk+m)→ 0 for m→∞ (w.p.1).
67	20	The process is globally exponentially stable at xk = 0 if there exists a P 0 such that E [Aᵀ(xk)]P E [A(xk)] +Q− (1− α)P 0, ∀xk ∈ X , (8) for some α > 0, where Q is defined as Q(i,j)(xk) = ∑ l P(l,:) C [ A(:,i)(xk),A(l,j)(xk) ] , (9) for any x0 ∈ X .
72	22	The interpretation of Proposition 1 is analogue to the linear deterministic case xk+1 = Axk which is stable if there exists a matrix P for which AᵀPA − P ≺ 0: In the nonlinear case in (3) the negative definiteness must be fulfilled for A(xk), ∀xk ∈ X .
75	18	The scalar case, considered in the following remark, also allows an intuitive insight to the Proposition 1: There is a trade-off between the magnitude of the expected value and the variance of A as follows: Remark 1.
78	44	Chose any probability distribution for the random variable A in (3) which is given by a fixed set of parameters θ ∈ Θ and whose first two moments are available.
80	35	Chose any parametric regression method to represent the mapping θψ : X → Θ.
81	14	The parameters of this mapping are denoted by ψ ∈ Ψ.
84	40	The optimization (12) is a general constrained nonlinear program in a rather high dimensional space (depending on number of parameters of the regression method in step 2).
85	18	However, independent of the optimality, the model fψ∗ of the form (3) is exponentially stable, thus any sample path of the system converges.
88	31	One example of such a distribution is the Beta distribution as given in the following corollary.
89	25	The scalar system xk+1 = A(xk)xk where A(xk) = κ(Ã(xk)− η) with Beta distributed Ã(xk) ∼ B(a(xk), b(xk)) and κ = 2, η = 0.5 with state dependent parameters [a(xk) b(xk)]ᵀ = θ ψ B (xk), with any θψB : X → ΘB = R2+ is exponentially stable.
111	30	We validate our approach, labeled LeSSS (for Learning Stable Stochastic Systems), using synthetic and human motion data and the simulation of a chemical reactor.
112	25	For the Beta distribution, Gaussian Mixture Regression (GMR) is used for the mapping from the state to the parameters θB : X → ΘB.
119	25	The 2d = 4 closest data points are considered for fitting the training parameters of the Dirichlet distribution locally.
130	47	• The Stable Estimator of Dynamical Systems (SEDS) as introduced by Khansari-Zadeh & Billard (2011) constraints the likelihood optimization of GMR parameters to a class of mean stable dynamical timecontinuous systems.
134	21	For our simulations, five mixtures are employed.
137	45	The learning algorithm is given 100 training points {x̄n, x̄n+1}100n=1 equally spaced in the state space interval [−8, 8] which are drawn from the state dependent Beta distribution (14).
145	16	For the next simulation, we use the data set for lettershaped motions provided by Khansari-Zadeh & Billard (2011).
169	43	The stable LDS is not capable to capture the varying behavior in the different regions of the piecewise affine system and therefore fails in accuracy of the reproduction.
173	14	Table 1 compares the methods with regard to the reproduction precision quantitatively.
176	22	The incorporation of the prior knowledge on goal convergence ensures that the learned model is stable in probability.
183	87	This work only deals with system with a single equilibrium point, but could be extended to system with more complex attractor dynamics.

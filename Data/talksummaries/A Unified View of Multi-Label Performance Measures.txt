21	10	The rest of the paper is organized as follows.
22	18	Section 2 introduces the notation and definitions of eleven multi-label performance measures.
31	22	H : Rd → {0, 1}l is the multi-label classifier, which consists of l models, one for a label, so H = {h1, .
32	32	, hl} and hj(xi) denotes the prediction of yij .
44	11	The first five measures (Hamming loss, ranking loss, one-error, coverage, average precision) are considered in Schapire & Singer (2000) and a multitude of works, e.g., Huang et al. (2012) and Zhang & Wu (2015).
46	8	These F-measures are popluar both in algorithm evaluation (Liu & Tsang, 2015) and theoretical analysis (Koyejo et al., 2015).
48	33	Some of these measures are defined on classifier H , and they care about the binary classification performance.
49	20	While some of these measures are defined on predictor F , and they usually measure the ranking performance of the predictor.
59	56	, fl}, a training set (X,Y ), the instancewise margin on label Y ·j is defined as: γinstj = min a,b {fj(xa)− fj(xb) | (a, b) ∈ Y +·j × Y − ·j }.
60	79	Y +·j × Y − ·j is the set of all the (positive, negative) instance index pairs of label j. Label-wise margin and instance-wise margin describe the discriminative ability of F .
64	10	Although we prefer maximizing these two margins, with respect to performance measures, the objective can be relaxed.
103	9	For micro-AUC, a double effective F can optimize it as the number of instances increases.
128	20	In the light of the analysis, the performance on different performance measures through optimizing margins can be expected.
132	10	The above analysis reveals that maximizing different margins will optimize different measures, and if possible, double effective F is prefered since it enjoys the benefits of maximizing both the label-wise margin and the instancewise margin.
136	8	We propose the following formulation: argmin W ,ξ l∑ i=1 ||wi||2 + λ1 m∑ i=1 ∑ (u,v) ξuvi + λ2 l∑ j=1 ∑ (a,b) ξjab s.t.
139	18	When both λ1 and λ2 are positive, both label-wise and instance-wise margins are considered.
148	11	10: end if 11: Random sample index j of label using weight clabel.
162	11	We conduct experiments on synthetic data with 4 labels.
166	10	The number of co-occurrent labels varies, the regions of each label are different and the data cannot be perfectly seperated by a linear learner.
167	12	To demonstrate the relationship between margins and performance measures, we degenerate LIMO to only consider either margin by setting the trade-off parameter λ1 or λ2 to zero.
172	22	Ten replications of the experiment are conducted and the average results are reported.
173	14	Because the range of performance measure coverage is not [0, 1], while some performance measures are better when higher, and some are better when lower, we rescale all the performance values into relative values for clearer visualization.
176	10	instance F1 macro F1 micro F1 Hamming loss 1.0 0.8 0.6 0.4 0.2 0.0 LIMO-inst-t LIMO-inst-t(x) LIMO-label-t LIMO-label-t(x) LIMO-t LIMO-t(x) 0.804 0.852 0.837 0.188 relative value a b s o lu te w o rs t v a lu e * * * * * The results shown in Figure 2 support our theoretical findings in Table 2.
186	17	By considering both label-wise margin and instance-wise margin, LIMO works well on all four classificaiton measures.
189	11	We choose them because they denote different domains: (i) A music dataset CAL500, (ii) an email dataset enron, (iii) a clinical text dataset medical, (iv) an image dataset corel5k, (v) a tagging dataset bibtex.
211	21	LIMO with nonlinear predictors may perform better, which needs a novel optimization algorithm.
212	15	In this paper, we establish a unified view for a variety of multi-label performance measures.
216	44	This explains why some measures seem to be redundant in experiments, and suggests that in future empirical studies, rather than randomly grasp a set of measures for evaluation, it is more informative to evaluate using measures with different properties, such as some measures optimized by label-wise effective predictors and some optimized by instance-wise effective predictors.
217	35	In the future, it is encouraging to study the asymptotic properties of these performance measures when the two margins are suboptimal.
218	25	The margin view also sheds a light for the design of novel multi-label algorithms.

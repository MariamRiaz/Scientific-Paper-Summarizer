3	26	Moreover, approximating semantic similarity by graded geometric distance in a vector space is an effective strategy to address the many linguistic phenomena that are better characterized in gradient rather than discrete terms, such as synonymy, selectional preferences, and semantic priming (Baroni and Lenci, 2010; Erk et al., 2010; Padó and Lapata, 2007, among others).
4	31	However, not all aspects of human semantic knowledge are satisfactorily captured in terms of fuzzy relations and graded similarity.
5	83	In particular, our knowledge of the meaning of words denoting specific entities involves a number of “hard facts” about the referents they denote that are best formalized as attribute-value pairs, of the sort that are stored in manually-curated knowledge bases, such as FreeBase or Wikidata.1 While distributional vectors can capture the useful fact that, say, Italy is in many ways more similar to Spain than to Germany, as humans we also know (or we can easily look up) a set of objective facts about Italy, such as what is its capital, its area, its official language and GDP, that are difficult to express in the language of vector algebra and geometry.
6	43	In this paper, we explore the hypothesis that distributional vectors implicitly encode such attributes of referential entities, which we will call referential attributes.
9	11	This model makes predictions that are significantly better than an informed baseline, in-between the latter and an upper-bound method.
12	13	12 We see our experiment as a first step towards integrating conceptual and referential aspects of meaning in distributional semantics, as we further discuss in the conclusion.
13	34	Mikolov et al.’s (2013) skip-gram model is a state-of-the-art “predictive” distributional semantic model which represents each word in a space of latent dimensions optimized to predict the contexts of the word’s occurrences.
29	18	We linearly rescale all numeric attributes to [0..1] and translate all categorical attributes into a binary representation by suffixing the original value to the original attribute name.
32	19	Finally, we partition the data into training, validation, and test set, using a 60-20-20 percent split.
48	53	As an upper bound, we train a model that uses the same architecture as described above but uses as input not distributional vectors but the FreeBase attributes themselves.
51	20	Since there is no appropriate unified evaluation measure that covers both numeric and binary attributes, we evaluate them separately.
54	14	As an example, take the population::2011::number attribute, and imagine that we only have three countries (Germany: 80M; Spain: 36M; and Netherlands: 17M).
63	26	We also normalize the rank difference to obtain a number between zero and one.
64	48	In a second step, we define the quality of the complete model, the normalized rank score (NRS), as the mean of all attribute quality scores, in parallel to our evaluation on binary attributes.
66	11	Let a ∈ A denote an attribute.
68	32	Finally, let r(v, S) denote the rank of value v in the list resulting when ordering the set S. Now we can define: Q(a) = 1 ||I||med{|r(pa(i), I) − (1) r(ga(i), I)| − 1 | i ∈ Ts} NRS = 1 ||A|| ∑ a∈A Q(a) (2) This measure can be interpreted similarly to Mean Reciprocal Rank (Manning et al., 2008): It has range [0..1], with smaller numbers indicating better ranking: 0.1, for example, means that, on average, the prediction is 10% of the ranks off (e.g., by four countries in a forty-country list).4 Note that, when evaluating each instance i, we use gold-standard values for all other instances, so that there the baseline is not hampered by ties.
70	18	For accuracy 1 is best, but for NRS 0 is best.
84	14	The model whose performance we are actually interested in, DIST2REF, in which we map from distributional information to FreeBase features, performs with remarkable consistency between these two extremes.
89	26	We think that these are overall promising results, given that the FreeBase attributes we predict are fairly fine-grained, and we only use generic distributional information as input.
98	13	For each group, we report average normalized rank score (NRS) and accuracy, respectively, for both DIST2REF and the baseline.
100	16	Attributes that are contextually supported include for instance those related to socioeconomic development (see below for details); people talk (and so write) about countries being more or less developed, rich, having one or another kind of laws, and this is captured in the abstractions over textual context that distributional models perform.
122	34	The same goes for the remaining attribute groups, for instance casualties (describing the total number of military casualties incurred in history), date founded and date dissolved,5 or climate avg rainfall.
127	18	We decided not to exclude them from evaluation for robustness’ sake, since there is no automatic way to identify contextually unsupported attributes in a new dataset.
129	24	However, we fare relatively badly on government-related attributes (form of government, governing officials).
135	14	To analyze the difference between the distributional representations and the output of our model, we focus on geolocation, our best attribute group.
137	52	Table 4 shows that DIST2REF extracts even more precise distance information from distributional vectors.
145	25	Note that these effects have an actual cognitive basis: Human intuitions about objective physical distance between countries and cities are biased by cognitive, cultural and socioeconomic factors, as explored for example in Friedman et al. (2002), who report that Texans locate Canadian cities closer to the US border relative to Mexican cities, despite their proximity to the latter, and that they place Southern US cities further south than they really are.
146	69	Interestingly, DIST2REF does also show some cultural effects in its geolocation errors: For example, some Pacific island states with lesser-known identities (e.g., Nauru and French Polynesia) are placed in the Indian Ocean, where we find the perhaps prototypes of beautiful islands, like Seychelles and Mauritius; also, Central American countries (such as Panama, El Salvador, and Nicaragua) move towards their “cultural center of gravity”, South America.
149	31	And while both DIST2REF and WORD2VEC place Mexican and Spanish cities in our test set closer to each other than they actually are, WORD2VEC does so to a much larger extent.
169	13	We have shown that a simple model can learn to predict, to a reasonable degree of accuracy, ref- erential attributes of an entity that are typically seen in a knowledge base from the corresponding corpus-based distributional representation.

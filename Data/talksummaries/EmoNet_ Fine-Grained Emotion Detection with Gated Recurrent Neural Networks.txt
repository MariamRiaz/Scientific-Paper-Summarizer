0	62	According to the Oxford English Dictionary, emotion is defined as “[a] strong feeling deriving from one’s circumstances, mood, or relationships with others.” 1 This “standard” definition identifies emotions as constructs involving something innate that is often invoked in social interactions and that aids in communicating with others(Hwang and Matsumoto, 2016).
1	45	It is no exaggeration that humans are emotional beings: Emotions are an integral part of human life, and affect our decision making as well as our mental and physical health.
2	92	As such, developing emotion detection models is important; they have a wide array of applications, ranging from building nuanced virtual assistants that cater for the emotions of their users to detecting the emotions of social media users in order to understand their mental and/or physical health.
4	20	Recent advances in machine learning for natural language processing (NLP) suggest that, given enough labeled data, there should be an opportunity to build better emotion detection models.
5	14	Manual labeling of data, however, is costly and so it is desirable to develop labeled emotion data without annotators.
7	32	In this work, we seek to enable deep learning by creating a large dataset of fine-grained emotions using Twitter data.
10	14	Overall, we make the following contributions: 1) Grounded in psychological theory of emotions, we build a large-scale, high quality dataset of tweets labeled with emotions.
63	11	Emotions in the blank spaces are the primary emotion dyads (i.e., emotions that are mixtures of two of the primary emotions).
64	111	For this work, we exclude the dyads in the exploded model from our treatment.
65	102	For simplicity, we refer to the circles as plutchik-1: with the emotions {admiration, amazement, ecstasy, grief, loathing, rage, terror, vigilance}, plutchik-2: with the emotions {joy, trust, fear, surprise, sadness, disgust, anger, anticipation}, and plutchik-3: with the emotions {acceptance, annoyance, apprehension, boredom, distraction, interest, pensiveness, serenity}.
66	14	The wheel is shown in Figure 1.
71	71	For example, for the joy emotion, a subset of the seeds in our expanded set is {“happy”, “happiness”, “joy”, “joyful”, “joyfully”, “delighted”, “feelingsunny”, “blithe”, “beatific”, “exhilarated”, “blissful”, “walkingonair”, “jubilant”}.
73	15	We also used Twitter API to crawl Twitter with hashtags from the expanded set.
74	22	Using this method, we were able to acquire a dataset of about 1/4 billion tweets covering an extended time span from July 2009 till January 2017.
75	48	Twitter data are very noisy, not only because of use of non-standard typography (which is less of a problem here) but due to the many duplicate tweets and the fact that tweets often have multiple emotion hashtags.
94	10	We wanted to validate our use of hashtags in a similar fashion and on a bigger random sample.
97	39	For each of the remaining 5,584 tweets, the annotators assign a binary tag from the set {relevant, irrelevant} to indicate whether a tweet carries an emotion category as assigned using our distant supervision method or not.
100	36	We also find that if we relax the constraint on the hashtag position such that we allow the hashtag to occur in the last quarter of a tweet (based on a total tweet character count), we acquire 85.43% relevant tweets.
105	91	One advantage of using distant supervision under these conditions for labeling emotion data, as (Wang et al., 2012) also notes, is that the label is assigned by the writer of the tweet himself/herself rather than an annotator who could wrongly decide what category a tweet is.
107	10	Another advantage of this method is obviously that it enables us to acquire a sufficiently large training set to use deep learning.
109	10	For our core modeling, we use Gated Recurrent Neural Networks (GRNNs), a modern variation of recurrent neural networks (RNNs), which we now turn to introduce.
111	10	Recurrent Neural Network A recurrent neural network (RNN) is one type of neural network architecture that is particularly suited for modeling sequential information.
141	62	PAC achieves an overall F-score of 64.86% on plutchik-1, 53.30% on plutchik-2, and 68.14% on plutchik-3, two of which are higher than an arbitrary baseline3 of 60%.
149	10	We now investigate the task of predicting each of the 8 primary emotion dimensions represented by the sectors of the wheel (where the three degrees of intensity of a given emotion are reduced to a single emotion dimension [e.g., {ecstasy, joy, serenity} are reduced to the joy dimension]).
150	23	We concatenate the 80% training data (TRAIN) from each of the 3 circles’ data into a single training set (TRAIN-ALL), the 10% DEV to form DEV-ALL, and the 10% TEST to form TEST-ALL.
154	264	As far as we know, this is the first work on modeling these dimensions.
155	24	We compare our results on the 8 basic emotions to the published literature.
156	46	As Table 6 shows, on this subset of emotions, our system is 4.53% (acc) higher than the best published results (Volkova and Bachrach, 2016), facilitated by the fact that we have an order of magnitude more training data.
158	83	In this paper, we built a large, automatically curated dataset for emotion detection using distant supervision and then used GRNNs to model finegrained emotion, achieving a new state-of-the-art performance.
159	21	We also extended the classification to 8 primary emotion dimensions situated in psychological theory of emotion.

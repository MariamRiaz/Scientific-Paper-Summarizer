2	27	, νK and the agent sequentially chooses from which distribution to sample an observation.
4	26	In the MAB literature, distributions are also referred to as arms, and sampling a realization from a distribution νi is referred to as pulling arm i.
6	21	In this problem, the goal is to find the k best arms, that is, k arms with the largest means.
8	20	In many application domains, the arms and the criteria for a good arm are multi-dimensional in nature.
10	42	For a multilabel classification task (where examples are associated with multiple labels), a worker can be modeled as a multi-dimensional arm where each dimension corresponds to her accuracy at identifying a particular label, and a natural definition for a “good worker” is that her accuracy is above some threshold for each label (e.g., 90%).
11	36	A common approach for finding such workers is to use a collection of examples labeled by domain experts as a set of tests.
13	35	As another example, consider A/B testing for designing products such as websites, ads, and video games.
18	31	The pure exploration MAB literature lacks (i) a simple framework for describing problems where the arms and criteria are multi-dimensional and (ii) practical algorithms for addressing these problems.
20	15	We introduce the feasible arm identification problem in which arms are associated with multi-dimensional distributions and the goal is to find arms whose means belong to a given polyhedron1 P “ tx : Ax ď bu.
72	21	The game is as follows: there are T rounds and at each round t, the agent chooses an arm It P rKs and observes a realization Xt „ νIt .
73	19	The goal is to identify all of the arms whose means belong to the polyhedron.
82	36	Our analysis assumes that each νi is a multi-dimensional sub-Gaussian distribution, which we now define (see Vershynin et al. (2017) for more details).
84	18	We say that X is R-sub-Gaussian if E exppX 2 R2 q ď 2.
88	19	We say that a random vector X is R-sub-Gaussian if }X}ψ2 ď R. Henceforth, we assume that ν1, .
112	42	Then, T ě 25H̃R2D logp48plogpT q ` 1qKDqq implies that, for any algorithm, sup BPBP, ,H̃,R EBpLT, ppSqq ě expp´14 T H̃R2 q.
113	26	In words, this result says essentially that for any polyhedron P and tolerance ě 0, the induced class of feasible arm identification problems with P and has a minimax lower bound on the order of expp´c THR2 q where c is a constant.
114	16	Henceforth, we say that an algorithm is nearly optimal if for large enough T its expected loss decays as Opexpp´c THR2 qq where c is a constant.
115	23	In this section, we extend three algorithms to the feasible arm identification problem, namely, an upper confidence bound based algorithm (UCBE) (Audibert and Bubeck, 2010), a successive accepts and rejects algorithm (SAR) (Bubeck et al., 2013; Chen et al., 2014), and the Anytime Parameter-free Thresholding algorithm (APT) (Locatelli et al., 2016).
128	15	At each time step t, it pulls an arm i that minimizes p∆p qi,Tiptq´ b a Tiptq breaking ties arbitrarily where a is a hyperparameter.
137	17	At the end of each round, it removes from Q an arm i that maximizes p∆ p q i,Tiptq.
145	62	Similar to previous results on SAR-type algorithms in the fixed budget setting (Audibert and Bubeck, 2010; Chen et al., 2014), our upper bound on MD-SAR is loose by a factor of logpKq in the exponential.
146	63	While the guarantee is not tight, it has the significant practical advantage over MD-UCBE that it does not involve a difficult-to-tune hyperparameter.
147	152	On the other hand, MD-SAR has the limitation that it needs to know T in advance.
148	56	Algorithm 3 MD-APT: Multi-dimensional Anytime Parameter-Free Thresholding algorithm 1: Input: K arms, polyhedron P , tolerance , budget T 2: for t “ 1, .
149	27	, T do 3: if t ď K then 4: SampleXt „ νt.
150	19	5: else 6: Choose It “ arg mini p∆ p q i,Tiptq a Tiptq and sampleXt „ νIt .
151	23	7: end if 8: end for 9: Return: pS “ ti P rKs : pµi,Tipt`1q P P u MD-APT (Algorithm 3) is a modification of the APT algorithm in Locatelli et al. (2016).
152	53	After an initialization phase in which it pulls each arm once, at each round t, it pulls an arm i that minimizes p∆p qi,Tiptq a Tiptq.
154	31	For simplicity, let “ 0; the case ą 0 is not as clear since arms whose distance to the boundary is less than do not need to be sampled at all.
156	17	Thus, such a static allocation is nearly optimal.

36	1	Our proof is also shorter and much more elementary by comparison.
42	1	In other words, in (P2) we consider the task of optimizing f over those matrices A ∈MdL×d0 that can be realized by an L-fold product A = WLWL−1 · · ·W1 W` ∈Md`×d`−1 (2) of matrices.
46	1	As a matrix of the form (2) has rank at most min{d0, .
50	1	Assume that f(A) is any differentiable function and that the structural condition (3) holds.
51	1	Then at any local minimizer ( Ŵ1, .
55	1	,WL) = f(WL · · ·W1) for f(A) some convex and differentiable function.
65	1	Using the cyclic property Tr(ABC) = Tr(CAB) of the trace then gives 〈∇f(A) , Wk+1,+HWk−1,− 〉fro = Tr ( ∇f(A)TWk+1,+HWk−1,− ) = Tr ( Wk−1,−∇f(A)TWk+1,+H ) = 〈WTk+1,+∇f(A)WTk−1,− , H 〉fro which, in light of (4), gives the desired formula for∇WkF .
66	1	The formulas for∇W1F and∇WLF are obtained similarly.
78	1	If ŴL−1,− has a trivial kernel, i.e. ker(ŴL−1,−) = {0}, then the theorem follows easily.
79	1	The critical point condition (7) part (iii) implies ŴL−1,−∇f ( Â )T = 0, and since ŴL−1,− has a trivial kernel this implies ∇f ( Â ) = ∇f ( ŴLŴL−1 · · · Ŵ1 ) = 0 as desired.
80	1	The remainder of the proof concerns the case that ŴL−1,− has a nontrivial kernel.
84	1	(9) Any such perturbation also defines a local minimizer.
85	1	Any tuple of matrices ( W̃1, .
98	1	Let ûk denote the corresponding dth0 column of Ûk, which exists since dk ≥ d0.
103	1	To prove (9) let W̃k,− = W̃k · · · W̃1 and Ŵk,− = Ŵk · · · Ŵ1 denote the truncated products of the matrices W̃k and Ŵk.
111	1	The critical point conditions (i) 0 = W̃T2,+∇f ( Ã ) , (ii) 0 = W̃Tk+1,+∇f ( Ã ) W̃Tk−1,− ∀ 2 ≤ k ≤ L− 1, (iii) 0 = ∇f ( Ã ) W̃TL−1,− therefore hold as well for all choices of wk∗+1, .
112	1	, δL satisfying (14) and (15).
117	1	, δL satisfying (14) and (15).
120	1	Right multiplying the last equality by ûk∗ and using the fact that (wk∗+1û T k∗ )ûk∗ = wk∗+1û T k∗ ûk∗ = wk∗+1 shows ∇f ( Â )T W̃L · · · W̃k∗+2wk∗+1 = 0 (21) for all choices of wk∗+1 with unit length.
121	1	Thus (21) implies ∇f ( Â )T W̃L · · · W̃k∗+2 = 0 for all choices of wk∗+2, .
122	1	, δL satisfying (14) and (15).
126	1	First, theorem 3 fails if we refer to critical points rather than local minimizers.
136	1	For this function even a two layer deep linear problem F ( W1,W2) := f(W2W1) W2 ∈ R2, W1 ∈ R has sub-optimal local minimizers; the point (Ŵ1, Ŵ2) = ( 0, [ 1 0 ]) (23) provides an example of a sub-optimal solution.
141	1	The proof of theorem 3 requires a single-valued derivative ∇f(Â) at a local optimum, but with f(x, y) as in (22) its subdifferential ∂f(0) = {(x, y) ∈ R2 : −1 ≤ x ≤ 1, y = 0} is multi-valued at the sub-optimal local minimum (23).
144	1	, L} is necessary for theorem 3 to hold as well.
147	1	Then ∇f ( WL · · ·W1 ) 6= 0 at all critical points of (P2), and so theorem 3 fails.
148	1	Finally, if we do not require convexity of f(A) then it is not true, in general, that local minima of (P2) correspond to minima of the original problem.
149	8	The functions f(x, y) = x2 − y2 F (W1,W2) = f(W2W1) and the minimizer (23) illustrate this point.
150	61	While the origin is clearly a saddle point of the one layer problem, the argument leading to (24) shows that (23) is a local minimizer for the deep linear problem.
151	61	So in the absence of additional structural assumptions on f(A), we may infer that a minimizer of the deep linear problem satisfies first-order optimality for the original problem, but nothing more.

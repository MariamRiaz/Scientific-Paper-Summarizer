0,1,label2,summary_sentences
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 364–369 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
364",text,[0],[0]
"Semantic role labeling (SRL) captures predicateargument relations, such as “who did what to whom.”",1 Introduction,[0],[0]
"Recent high-performing SRL models (He et al., 2017; Marcheggiani et al., 2017; Tan et al., 2018) are BIO-taggers, labeling argument spans for a single predicate at a time (as shown in Figure 1).",1 Introduction,[0],[0]
"They are typically only evaluated with gold predicates, and must be pipelined with error-prone predicate identification models for deployment.
",1 Introduction,[0],[0]
We propose an end-to-end approach for predicting all the predicates and their argument spans in one forward pass.,1 Introduction,[0],[0]
"Our model builds on a recent coreference resolution model (Lee et al., 2017), by making central use of learned, contextualized span representations.",1 Introduction,[0],[0]
We use these representations to predict SRL graphs directly over text spans.,1 Introduction,[0],[0]
"Each edge is identified by independently predicting which role, if any, holds between every possible pair of text spans, while using aggressive beam
1Code and models: https://github.com/luheng/lsgn
pruning for efficiency.",1 Introduction,[0],[0]
"The final graph is simply the union of predicted SRL roles (edges) and their associated text spans (nodes).
",1 Introduction,[0],[0]
"Our span-graph formulation overcomes a key limitation of semi-markov and BIO-based models (Kong et al., 2016; Zhou and Xu, 2015; Yang and Mitchell, 2017; He et al., 2017; Tan et al., 2018): it can model overlapping spans across different predicates in the same output structure (see Figure 1).",1 Introduction,[0],[0]
"The span representations also generalize the token-level representations in BIObased models, letting the model dynamically decide which spans and roles to include, without using previously standard syntactic features (Punyakanok et al., 2008; FitzGerald et al., 2015).
",1 Introduction,[0],[0]
"To the best of our knowledge, this is the first span-based SRL model that does not assume that predicates are given.",1 Introduction,[0],[0]
"In this more realistic setting, where the predicate must be predicted, our model achieves state-of-the-art performance on PropBank.",1 Introduction,[0],[0]
"It also reinforces the strong performance of similar span embedding methods for coreference (Lee et al., 2017), suggesting that this style of models could be used for other span-span relation tasks, such as syntactic parsing (Stern et al., 2017), relation extraction (Miwa and Bansal, 2016), and QA-SRL (FitzGerald et al., 2018).",1 Introduction,[0],[0]
"We consider the space of possible predicates to be all the tokens in the input sentence, and the space of arguments to be all continuous spans.",2 Model,[0],[0]
"Our model decides what relation exists between each predicate-argument pair (including no relation).
",2 Model,[0],[0]
"Formally, given a sequence X = w1, . . .",2 Model,[0],[0]
", wn, we wish to predict a set of labeled predicateargument relations Y ⊆ P ×",2 Model,[0],[0]
"A × L, where P = {w1, . . .",2 Model,[0],[0]
", wn} is the set of all tokens (predicates), A = {(wi, . . .",2 Model,[0],[0]
", wj) | 1 ≤",2 Model,[0],[0]
"i ≤ j ≤ n} contains all the spans (arguments), and L is the space of semantic role labels, including a null label indicating no relation.",2 Model,[0],[0]
"The final SRL output would be all the non-empty relations {(p, a, l) ∈ Y",2 Model,[0],[0]
"| l 6= }.
",2 Model,[0],[0]
"We then define a set of random variables, where each random variable yp,a corresponds to a predicate p ∈ P and an argument a ∈ A, taking value from the discrete label space L.",2 Model,[0],[0]
"The random variables yp,a are conditionally independent of each other given the input X:
P (Y | X) = ∏
p∈P,a∈A P (yp,a | X) (1)
P (yp,a = l | X) = exp(φ(p, a, l))∑
l′∈L exp(φ(p, a, l′))
",2 Model,[0],[0]
"(2)
Where φ(p, a, l) is a scoring function for a possible (predicate, argument, label) combination.",2 Model,[0],[0]
"φ is decomposed into two unary scores on the predicate and the argument (defined in Section 3), as well as a label-specific score for the relation:
φ(p, a, l) = Φa(a) + Φp(p) +",2 Model,[0],[0]
"Φ (l) rel (a, p) (3)
",2 Model,[0],[0]
"The score for the null label is set to a constant: φ(p, a, ) = 0, similar to logistic regression.
",2 Model,[0],[0]
"Learning For each input X , we minimize the negative log likelihood of the gold structure Y ∗:
",2 Model,[0],[0]
J (X) =,2 Model,[0],[0]
"− logP (Y ∗ | X) (4)
Beam pruning As our model deals with O(n2) possible argument spans and O(n) possible predicates, it needs to consider O(n3|L|) possible relations, which is computationally impractical.",2 Model,[0],[0]
"To overcome this issue, we define two beams Ba and Bp for storing the candidate arguments and predicates, respectively.",2 Model,[0],[0]
The candidates in each beam are ranked by their unary score (Φa or Φp).,2 Model,[0],[0]
The sizes of the beams are limited by λan and λpn.,2 Model,[0],[0]
"Elements that fall out of the beam do not participate
in computing the edge factors Φ(l)rel , reducing the overall number of relational factors evaluated by the model to O(n2|L|).",2 Model,[0],[0]
"We also limit the maximum width of spans to a fixed number W (e.g. W = 30), further reducing the number of computed unary factors to O(n).",2 Model,[0],[0]
"Our model builds contextualized representations for argument spans a and predicate words p based on BiLSTM outputs (Figure 2) and uses feedforward networks to compute the factor scores in φ(p, a, l) described in Section 2 (Figure 3).
",3 Neural Architecture,[0],[0]
"Word-level contexts The bottom layer consists of pre-trained word embeddings concatenated with character-based representations, i.e. for each token wi, we have xi = [WORDEMB(wi); CHARCNN(wi)].",3 Neural Architecture,[0],[0]
"We then contextualize each xi using an m-layered bidirectional LSTM with highway connections (Zhang et al., 2016), which we denote as x̄i.
Argument and predicate representation We build contextualized representations for all candidate arguments a ∈ A and predicates p ∈ P .",3 Neural Architecture,[0],[0]
"The argument representation contains the following: end points from the BiLSTM outputs (x̄START(a), x̄END(a)), a soft head word xh(a), and embedded span width features f(a), similar to Lee et al. (2017).",3 Neural Architecture,[0],[0]
"The predicate representation is simply the BiLSTM output at the position INDEX(p).
",3 Neural Architecture,[0],[0]
"g(a) =[x̄START(a); x̄END(a); xh(a); f(a)] (5)
g(p) =x̄INDEX(p) (6)
The soft head representation xh(a) is an attention mechanism over word inputs x in the argument span, where the weights e(a) are computed via a linear layer over the BiLSTM outputs x̄.
xh(a) = xSTART(a):END(a)e(s) ᵀ (7) e(a)",3 Neural Architecture,[0],[0]
"= SOFTMAX(wᵀe x̄START(a):END(a)) (8)
xSTART(a):END(a) is a shorthand for stacking a list of vectors xt, where START(a) ≤ t ≤ END(a).
",3 Neural Architecture,[0],[0]
"Scoring The scoring functions Φ are implemented with feed-forward networks based on the predicate and argument representations g:
Φa(a) =w ᵀ a MLPa(g(a))",3 Neural Architecture,[0],[0]
(9) Φp(p),3 Neural Architecture,[0],[0]
"=w ᵀ pMLPp(g(p)) (10)
Φ (l) rel (a, p) =w (l)ᵀ r MLPr([g(a); g(p)]) (11)",3 Neural Architecture,[0],[0]
"We experiment on the CoNLL 2005 (Carreras and Màrquez, 2005) and CoNLL 2012 (OntoNotes 5.0, (Pradhan et al., 2013)) benchmarks, using two SRL setups: end-to-end and gold predicates.",4 Experiments,[0],[0]
"In the end-to-end setup, a system takes a tokenized sentence as input, and predicts all the predicates and their arguments.",4 Experiments,[0],[0]
"Systems are evaluated on the micro-averaged F1 for correctly predicting (predicate, argument span, label) tuples.",4 Experiments,[0],[0]
"For comparison with previous systems, we also report results with gold predicates, in which the complete set of predicates in the input sentence is given as well.",4 Experiments,[0],[0]
"Other experimental setups and hyperparameteres are listed in Appendix A.1.
ELMo embeddings To further improve performance, we also add ELMo word representations (Peters et al., 2018) to the BiLSTM input (in the +ELMo rows).",4 Experiments,[0],[0]
"Since the contextualized representations ELMo provides can be applied to most previous neural systems, the improvement is orthogonal to our contribution.",4 Experiments,[0],[0]
"In Table 1 and 2, we organize all the results into two categories: the comparable single model systems, and the mod-
els augmented with ELMo or ensembling (in the PoE rows).
",4 Experiments,[0],[0]
"End-to-end results As shown in Table 1,2 our joint model outperforms the previous best pipeline system (He et al., 2017) by an F1 difference of anywhere between 1.3 and 6.0 in every setting.",4 Experiments,[0],[0]
"The improvement is larger on the Brown test set, which is out-of-domain, and the CoNLL 2012 test set, which contains nominal predicates.",4 Experiments,[0],[0]
"On all datasets, our model is able to predict over 40% of the sentences completely correctly.
",4 Experiments,[0],[0]
"Results with gold predicates To compare with additional previous systems, we also conduct experiments with gold predicates by constraining our predicate beam to be gold predicates only.",4 Experiments,[0],[0]
"As shown in Table 2, our model significantly out-performs He et al. (2017), but falls short of Tan et al. (2018), a very recent attention-based (Vaswani et al., 2017)",4 Experiments,[0],[0]
BIO-tagging model that was developed concurrently with our work.,4 Experiments,[0],[0]
"By adding the contextualized ELMo representations, we are able to out-perform all previous systems, including Peters et al. (2018), which applies ELMo to the SRL model introduced in He et al. (2017).",4 Experiments,[0],[0]
Our model’s architecture differs significantly from previous BIO systems in terms of both input and decision space.,5 Analysis,[0],[0]
"To better understand our model’s strengths and weaknesses, we perform three analyses following Lee et al. (2017) and He et al. (2017), studying (1) the effectiveness of beam
2For the end-to-end setting on CoNLL 2012, we used a subset of the train/dev data from previous work due to noise in the dataset; the dev result is not directly comparable.",5 Analysis,[0],[0]
"See Appendix A.2 for detailed explanation.
",5 Analysis,[0],[0]
"pruning, (2) the ability to capture long-range dependencies, (3) agreement with syntactic spans, and (4) the ability to predict globally consistent SRL structures.",5 Analysis,[0],[0]
The analyses are performed on the development sets without using ELMo embeddings.,5 Analysis,[0],[0]
"3
Effectiveness of beam pruning Figure 4 shows the predicate and argument spans kept in the beam, sorted with their unary scores.",5 Analysis,[0],[0]
"Our model efficiently prunes unlikely argument spans and predicates, significantly reduces the number of edges it needs to consider.",5 Analysis,[0],[0]
Figure 5 shows the recall of predicate words on the CoNLL 2012 development set.,5 Analysis,[0],[0]
"By retaining λp = 0.4 predicates per word, we are able to keep over 99.7% argument-bearing predicates.",5 Analysis,[0],[0]
"Compared to having a part-of-speech tagger (POS:X in Figure 5), our joint beam pruning allowing the model to have a soft trade-off between efficiency and recall.4
Long-distance dependencies Figure 6 shows the performance breakdown by binned distance between arguments to the given predicates.",5 Analysis,[0],[0]
"Our model is better at accurately predicting arguments that are farther away from the predicates, even
3For comparability with prior work, analyses (2)-(4) are performed on the CoNLL 05 dev set with gold predicates.
",5 Analysis,[0],[0]
"4The predicate ID accuracy of our model is not comparable with that reported in He et al. (2017), since our model does not predict non-argument-bearing predicates.
",5 Analysis,[0],[0]
"compared to an ensemble model (He et al., 2017) that has a higher overall F1.",5 Analysis,[0],[0]
"This is very likely due to architectural differences; in a BIO tagger, predicate information passes through many LSTM timesteps before reaching a long-distance argument, whereas our architecture enables direct connections between all predicates-arguments pairs.
Agreement with syntax As mentioned in He et al. (2017), their BIO-based SRL system has good agreement with gold syntactic span boundaries (94.3%) but falls short of previous syntaxbased systems (Punyakanok et al., 2004).",5 Analysis,[0],[0]
"By directly modeling span information, our model achieves comparable syntactic agreement (95.0%) to Punyakanok et al. (2004) without explicitly modeling syntax.
",5 Analysis,[0],[0]
"Global consistency On the other hand, our model suffers from global consistency issues.",5 Analysis,[0],[0]
"For example, on the CoNLL 2005 test set, our model has lower complete-predicate accuracy (62.6%) than the BIO systems (He et al., 2017; Tan et al., 2018) (64.3%-66.4%).",5 Analysis,[0],[0]
"Table 3 shows its viola-
tions of global structural constraints5 compared to previous systems.",5 Analysis,[0],[0]
Our model made more constraint violations compared to previous systems.,5 Analysis,[0],[0]
"For example, our model predicts duplicate core arguments6 (shown in the U column in Table 3) more often than previous work.",5 Analysis,[0],[0]
"This is due to the fact that our model uses independent classifiers to label each predicate-argument pair, making it difficult for them to implicitly track the decisions made for several arguments with the same predicate.
",5 Analysis,[0],[0]
"The Ours+decode row in Table 3 shows SRL performance after enforcing the U-constraint using dynamic programming (Täckström et al., 2015) at decoding time.",5 Analysis,[0],[0]
"Constrained decoding at test time is effective at eliminating all the core-role inconsistencies (shown in the U-column), but did not bring significant gain on the end result (shown
5Punyakanok et al. (2008) described a list of global constraints for SRL systems, e.g., there can be at most one core argument of each type for each predicate.
6Arguments with labels ARG0,ARG1,. . .",5 Analysis,[0],[0]
",",5 Analysis,[0],[0]
"ARG5 and AA.
in SRL F1), which only evaluates the piece-wise predicate-argument structures.",5 Analysis,[0],[0]
"We proposed a new SRL model that is able to jointly predict all predicates and argument spans, generalized from a recent coreference system (Lee et al., 2017).",6 Conclusion and Future Work,[0],[0]
"Compared to previous BIO systems, our new model supports joint predicate identification and is able to incorporate span-level features.",6 Conclusion and Future Work,[0],[0]
"Empirically, the model does better at longrange dependencies and agreement with syntactic boundaries, but is weaker at global consistency, due to our strong independence assumption.
",6 Conclusion and Future Work,[0],[0]
"In the future, we could incorporate higher-order inference methods (Lee et al., 2018) to relax this assumption.",6 Conclusion and Future Work,[0],[0]
"It would also be interesting to combine our span-based architecture with the selfattention layers (Tan et al., 2018; Strubell et al., 2018) for more effective contextualization.",6 Conclusion and Future Work,[0],[0]
"This research was supported in part by the ARO (W911NF-16-1-0121), the NSF (IIS-1252835, IIS-1562364), a gift from Tencent, and an Allen Distinguished Investigator Award.",Acknowledgments,[0],[0]
"We thank Eunsol Choi, Dipanjan Das, Nicholas Fitzgerald, Ariel Holtzman, Julian Michael, Noah Smith, Swabha Swayamdipta, and our anonymous reviewers for helpful feedback.",Acknowledgments,[0],[0]
"Recent BIO-tagging-based neural semantic role labeling models are very high performing, but assume gold predicates as part of the input and cannot incorporate span-level features.",abstractText,[0],[0]
"We propose an endto-end approach for jointly predicting all predicates, arguments spans, and the relations between them.",abstractText,[0],[0]
"The model makes independent decisions about what relationship, if any, holds between every possible word-span pair, and learns contextualized span representations that provide rich, shared input features for each decision.",abstractText,[0],[0]
Experiments demonstrate that this approach sets a new state of the art on PropBank SRL without gold predicates.1,abstractText,[0],[0]
Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 401–406 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
401",text,[0],[0]
"Neural NER trains a deep neural network for the NER task and has become quite popular as they minimize the need for hand-crafted features and, learn feature representations from the training data itself.",1 Introduction,[0],[0]
"Recently, multilingual learning has been shown to benefit Neural NER in a resource-rich language setting (Gillick et al., 2016; Yang et al., 2017).",1 Introduction,[0],[0]
Multilingual learning aims to improve the NER performance on the language under consideration (primary language) by adding training data from one or more assisting languages.,1 Introduction,[0],[0]
The neural network is trained on the combined data of the primary (DP ) and the assisting languages (DA).,1 Introduction,[0],[0]
"The neural network has a combination of languagedependent and language-independent layers, and, the network learns better cross-lingual features via these language-independent layers.
∗This work began when the second author was a research scholar at IIT Bombay
Existing approaches add all training sentences from the assisting language to the primary language and train the neural network on the combined data.",1 Introduction,[0],[0]
"However, data from assisting languages can introduce a drift in the tag distribution for named entities, since the common named entities from the two languages may have vastly divergent tag distributions.",1 Introduction,[0],[0]
"For example, the entity China appears in training split of Spanish (primary) and English (assisting) (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003) with the corresponding tag frequencies, Spanish = { Loc : 20, Org : 49, Misc : 1 } and English = { Loc : 91, Org : 7 }.",1 Introduction,[0],[0]
"By adding English data to Spanish, the tag distribution of China is skewed towards Location entity in Spanish.",1 Introduction,[0],[0]
This leads to a drop in named entity recognition performance.,1 Introduction,[0],[0]
"In this work, we address this problem of drift in tag distribution owing to adding training data from a supporting language.
",1 Introduction,[0],[0]
"The problem is similar to the problem of data selection for domain adaptation of various NLP tasks, except that additional complexity is introduced due to the multilingual nature of the learning task.",1 Introduction,[0],[0]
"For domain adaptation in various NLP tasks, several approaches have been proposed to address drift in data distribution (Moore and Lewis, 2010; Axelrod et al., 2011; Ruder and Plank, 2017).",1 Introduction,[0],[0]
"For instance, in machine translation, sentences from out-of-domain data are selected based on a suitably defined metric (Moore and Lewis, 2010; Axelrod et al., 2011).",1 Introduction,[0],[0]
The metric attempts to capture similarity of the out-of-domain sentences with the in-domain data.,1 Introduction,[0],[0]
"Out-of-domain sentences most similar to the in-domain data are added.
",1 Introduction,[0],[0]
"Like the domain adaptation techniques summarized above, we propose to judiciously add sentences from the assisting language to the primary language data based on the divergence between the tag distributions of named entities in the train-
ing instances.",1 Introduction,[0],[0]
"Adding assisting language sentences with lower divergence reduces the possibility of entity drift enabling the multilingual model to learn better cross-lingual features.
",1 Introduction,[0],[0]
Following are the contributions of the paper: (a) We present a simple approach to select assisting language sentences based on symmetric KLDivergence of overlapping entities (b) We demonstrate the benefits of multilingual Neural NER on low-resource languages.,1 Introduction,[0],[0]
"We compare the proposed data selection approach with monolingual Neural NER system, and the multilingual Neural NER system trained using all assisting language sentences.",1 Introduction,[0],[0]
"To the best of our knowledge, ours is the first work for judiciously selecting a subset of sentences from an assisting language for multilingual Neural NER.",1 Introduction,[0],[0]
"For every assisting language sentence, we calculate the sentence score based on the average symmetric KL-Divergence score of overlapping entities present in that sentence.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"By overlapping entities, we mean entities whose surface form appears in both the languages’ training data.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"The symmetric KL-Divergence SKL(x), of a named entity x, is defined as follows,
SKL(x) =",2 Judicious Selection of Assisting Language Sentences,[0],[0]
[ KL( Pp(x) || Pa(x) ),2 Judicious Selection of Assisting Language Sentences,[0],[0]
+KL( Pa(x) ||,2 Judicious Selection of Assisting Language Sentences,[0],[0]
Pp(x) ) ] /2,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"(1)
where Pp(x) and Pa(x) are the probability distributions for entity x in the primary (p) and the assisting (a) languages respectively.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"KL refers to the standard KL-Divergence score between the two probability distributions.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
KL-Divergence calculates the distance between the two probability distributions.,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Lower the KLDivergence score, higher is the tag agreement for an entity in both the languages thereby, reducing the possibility of entity drift in multilingual learning.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
Assisting language sentences with the sentence score below a threshold value are added to the primary language data for multilingual learning.,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"If an assisting language sentence contains no overlapping entities, the corresponding sentence score is zero resulting in its selection.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Network Architecture
Several deep learning models (Collobert et al., 2011; Ma and Hovy, 2016; Murthy and Bhattacharyya, 2016; Lample et al., 2016; Yang et al., 2017) have been proposed for monolingual NER in the literature.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Apart from the model by Collobert et al. (2011), remaining approaches extract sub-word features using either Convolution Neural Networks (CNNs) or Bi-LSTMs.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
The proposed data selection strategy for multilingual Neural NER can be used with any of the existing models.,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"We choose the model by Murthy and Bhattacharyya (2016)1 in our experiments.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Multilingual Learning
We consider two parameter sharing configurations for multilingual learning (i) sub-word feature extractors shared across languages (Yang et al., 2017)",2 Judicious Selection of Assisting Language Sentences,[0],[0]
(Sub-word) (ii) the entire network trained in a language independent way (All).,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"As Murthy and Bhattacharyya (2016) use CNNs to extract sub-word features, only the character-level CNNs are shared for the Sub-word configuration.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
1The code is available here: https://github.com/ murthyrudra/NeuralNER,2 Judicious Selection of Assisting Language Sentences,[0],[0]
In this section we list the datasets used and the network configurations used in our experiments.,3 Experimental Setup,[0],[0]
The Table 1 lists the datasets used in our experiments along with pre-trained word embeddings used and other dataset statistics.,3.1 Datasets,[0],[0]
"For German NER, we use ep-96-04-16.conll to create train and development splits, and use ep-96-04-15.conll as test split.",3.1 Datasets,[0],[0]
"As Italian has a different tag set compared to English, Spanish and Dutch, we do not share output layer for All configuration in multilingual experiments involving Italian.",3.1 Datasets,[0],[0]
"Even though the languages considered are resource-rich languages, we consider German and Italian as primary languages due to their relatively lower number of train tokens.",3.1 Datasets,[0],[0]
"The German NER data followed IO notation and for all experiments involving German, we converted other language data to IO notation.",3.1 Datasets,[0],[0]
"Similarly, the Italian NER data followed IOBES notation and for all experiments involving Italian, we converted other language data to IOBES notation.
",3.1 Datasets,[0],[0]
"For low-resource language setup, we consider the following Indian languages: Hindi, Marathi2, Bengali, Tamil and Malayalam.",3.1 Datasets,[0],[0]
Except for Hindi all are low-resource languages.,3.1 Datasets,[0],[0]
"We consider only Person, Location and Organization tags.",3.1 Datasets,[0],[0]
"Though the scripts of these languages are different, they share the same set of phonemes making script mapping across languages easier.",3.1 Datasets,[0],[0]
"We convert Tamil, Bengali and Malayalam data to the Devanagari script using the Indic NLP li-
2Data is available here: http://www.cfilt.iitb.",3.1 Datasets,[0],[0]
"ac.in/ner/annotated_corpus/
brary3 (Kunchukuttan et al., 2015)",3.1 Datasets,[0],[0]
"thereby, allowing sharing of sub-word features across the Indian languages.",3.1 Datasets,[0],[0]
"For Indian languages, the annotated data followed the IOB format.",3.1 Datasets,[0],[0]
"With the exception of English, Spanish and Dutch, remaining language datasets did not have official train and development splits provided.",3.2 Network Hyper-parameters,[0],[0]
We randomly select 70% of the train split for training the model and remaining as development split.,3.2 Network Hyper-parameters,[0],[0]
"The threshold for sentence score SKL, is selected based on cross-validation for every language pair.",3.2 Network Hyper-parameters,[0],[0]
The dimensions of the Bi-LSTM hidden layer are 200 and 400 for the monolingual and multilingual experiments respectively.,3.2 Network Hyper-parameters,[0],[0]
"We extract 20 features per convolution filter, with width varying from 1 to 9.",3.2 Network Hyper-parameters,[0],[0]
The initial learning rate is 0.4 and multiplied by 0.7 when validation error increases.,3.2 Network Hyper-parameters,[0],[0]
The training is stopped when the learning rate drops below 0.002.,3.2 Network Hyper-parameters,[0],[0]
"We assign a weight of 0.1 to assisting language sentences and oversample primary language sentences to match the assisting language sentence count in all multilingual experiments.
",3.2 Network Hyper-parameters,[0],[0]
"For European languages, we have performed hyper-parameter tuning for both the monolingual and multilingual learning (with all assisting language sentences) configurations.",3.2 Network Hyper-parameters,[0],[0]
The best hyperparameter values for the language pair involved were observed to be within similar range.,3.2 Network Hyper-parameters,[0],[0]
"Hence, we chose the same set of hyper-parameter values for all languages.
",3.2 Network Hyper-parameters,[0],[0]
3https://github.com/anoopkunchukuttan/ indic_nlp_library,3.2 Network Hyper-parameters,[0],[0]
We now present the results on both resource-rich and resource-poor languages.,4 Results,[0],[0]
Table 2 presents the results for German and Italian NER.,4.1 Resource-Rich Languages,[0],[0]
"We consistently observe improvements for German and Italian NER using our data selection strategy, irrespective of whether only subword features are shared (Sub-word) or the entire network (All) is shared across languages.
",4.1 Resource-Rich Languages,[0],[0]
Adding all Spanish/Dutch sentences to Italian data leads to drop in Italian NER performance when all layers are shared.,4.1 Resource-Rich Languages,[0],[0]
Label drift from overlapping entities is one of the reasons for the poor results.,4.1 Resource-Rich Languages,[0],[0]
This can be observed by comparing the histograms of English and Spanish sentences ranked by the SKL scores for Italian multilingual learning (Figure 1).,4.1 Resource-Rich Languages,[0],[0]
Most English sentences have lower SKL scores indicating higher tag agreement for overlapping entities and lower drift in tag distribution.,4.1 Resource-Rich Languages,[0],[0]
"Hence, adding all English sentences improves Italian NER accuracy.",4.1 Resource-Rich Languages,[0],[0]
"In contrast, most Spanish sentences have larger SKL
scores and adding these sentences adversely impacts Italian NER performance.",4.1 Resource-Rich Languages,[0],[0]
"By judiciously selecting assisting language sentences, we eliminate sentences which are responsible for drift occurring during multilingual learning.
",4.1 Resource-Rich Languages,[0],[0]
"To understand how overlapping entities impact the NER performance, we study the statistics of overlapping named entities between ItalianEnglish and Italian-Spanish pairs.",4.1 Resource-Rich Languages,[0],[0]
911 and 916 unique entities out of 4061 unique Italian entities appear in the English and Spanish data respectively.,4.1 Resource-Rich Languages,[0],[0]
We had hypothesized that entities with divergent tag distribution are responsible for hindering the performance in multilingual learning.,4.1 Resource-Rich Languages,[0],[0]
If we sort the common entities based on their SKL divergence value.,4.1 Resource-Rich Languages,[0],[0]
We observe that 484 out of 911 common entities in English and 535 out of 916 common entities in Spanish have an SKL score greater than 1.0. 162 out of 484 common entities in English-Italian data having SKL divergence value greater than 1.0 also appear more than 10 times in the English corpus.,4.1 Resource-Rich Languages,[0],[0]
"Similarly, 123 out of 535 common entities in Spanish-Italian data having SKL divergence value greater than 1.0 also appear more than 10 times in the Spanish corpus.",4.1 Resource-Rich Languages,[0],[0]
"However, these common 162 entities have a combined frequency of 12893 in English, meanwhile the 123 common entities have a combined frequency of 34945 in Spanish.",4.1 Resource-Rich Languages,[0],[0]
"To summarize, although the number of overlapping entities is comparable in English and Spanish sentences, entities with larger SKL divergence score appears more frequently in Spanish sentences compared to English sentences.",4.1 Resource-Rich Languages,[0],[0]
"As a consequence, adding all Spanish sentences leads to significant drop in Italian NER performance which is not the case when all English sentences are added.",4.1 Resource-Rich Languages,[0],[0]
"As Indian languages exhibit high lexical overlap (Kunchukuttan and Bhattacharyya, 2016) and syntactic relatedness (V Subbãrão, 2012), we share all layers of the network across languages.",4.2 Resource-Poor Languages,[0],[0]
Table 3 presents the results.,4.2 Resource-Poor Languages,[0],[0]
"Bengali, Malayalam, and Tamil (low-resource languages) benefits from our data selection strategy.",4.2 Resource-Poor Languages,[0],[0]
"Hindi and Marathi NER performance improves when the other is used as assisting language.
",4.2 Resource-Poor Languages,[0],[0]
"Bengali, Malayalam, and Tamil have weaker baselines compared to Hindi and Marathi, and are benefited from our approach irrespective of the assisting language chosen.",4.2 Resource-Poor Languages,[0],[0]
"However, Hindi and Marathi are not benefited from multilingual learning with Bengali, Malayalam and Tamil.",4.2 Resource-Poor Languages,[0],[0]
Malayalam and Tamil being morphologically rich have low entity overlap (surface level) with Hindi and Marathi.,4.2 Resource-Poor Languages,[0],[0]
"As a result, only 2-3% of Malayalam and Tamil sentences are eliminated from our approach, leading to no gains from multilingual learning.",4.2 Resource-Poor Languages,[0],[0]
Hindi and Marathi are negatively impacted by noisy Bengali data.,4.2 Resource-Poor Languages,[0],[0]
"Bengali has less training sentences compared to other languages and, choosing a low SKL threshold results in selecting very few Bengali sentences for multilingual learning.",4.2 Resource-Poor Languages,[0],[0]
"Here, we study the influence of SKL score threshold on the NER performance.",4.3 Influence of SKL Threshold,[0],[0]
We run experiments for Italian NER by adding Spanish training sentences and sharing all layers except for output layer across languages.,4.3 Influence of SKL Threshold,[0],[0]
"We vary the threshold value from 1.0 to 9.0 in steps of 1, and select sentences with score less than the threshold.",4.3 Influence of SKL Threshold,[0],[0]
"A threshold of 0.0 indicates monolingual training and threshold greater than 9.0 indicates all assist-
ing language sentences considered.",4.3 Influence of SKL Threshold,[0],[0]
The plot of Italian test F-Score against SKL score is shown in the Figure 2.,4.3 Influence of SKL Threshold,[0],[0]
Italian test F-Score increases initially as we add more and more Spanish sentences and then drops due to influence of drift becoming significant.,4.3 Influence of SKL Threshold,[0],[0]
"Finding the right SKL threshold is important, hence we use a validation set to tune the SKL threshold.",4.3 Influence of SKL Threshold,[0],[0]
"In this paper, we address the problem of divergence in tag distribution between primary and assisting languages for multilingual Neural NER.",5 Conclusion,[0],[0]
We show that filtering out the assisting language sentences exhibiting significant divergence in the tag distribution can improve NER accuracy.,5 Conclusion,[0],[0]
We propose to use the symmetric KL-Divergence metric to measure the tag distribution divergence.,5 Conclusion,[0],[0]
We observe consistent improvements in multilingual Neural NER performance using our data selection strategy.,5 Conclusion,[0],[0]
"The strategy shows benefits for extremely low resource primary languages too.
",5 Conclusion,[0],[0]
"This problem of drift in data distribution may not be unique to multilingual NER, and we plan to study the influence of data selection for multilingual learning on other NLP tasks like sentiment analysis, question answering, neural machine translation, etc.",5 Conclusion,[0],[0]
"We also plan to explore more metrics for multilingual learning, specifically for morphologically rich languages.",5 Conclusion,[0],[0]
"We thank Gajanan Rane and Geetanjali Rane for annotating the Marathi data, which was created as part of the CLIA project.",Acknowledgements,[0],[0]
Multilingual learning for Neural Named Entity Recognition (NNER) involves jointly training a neural network for multiple languages.,abstractText,[0],[0]
"Typically, the goal is improving the NER performance of one of the languages (the primary language) using the other assisting languages.",abstractText,[0],[0]
We show that the divergence in the tag distributions of the common named entities between the primary and assisting languages can reduce the effectiveness of multilingual learning.,abstractText,[0],[0]
"To alleviate this problem, we propose a metric based on symmetric KL divergence to filter out the highly divergent training instances in the assisting language.",abstractText,[0],[0]
"We empirically show that our data selection strategy improves NER performance in many languages, including those with very limited training data.",abstractText,[0],[0]
Judicious Selection of Training Data in Assisting Language for Multilingual Neural NER,title,[0],[0]
The key challenge of drug discovery is to find target molecules with desired chemical properties.,1. Introduction,[0],[0]
"Currently, this task takes years of development and exploration by expert chemists and pharmacologists.",1. Introduction,[0],[0]
Our ultimate goal is to automate this process.,1. Introduction,[0],[0]
"From a computational perspective, we decompose the challenge into two complementary subtasks: learning to represent molecules in a continuous manner that facilitates the prediction and optimization of their properties (encoding); and learning to map an optimized continuous representation back into a molecular graph with improved properties (decoding).",1. Introduction,[0],[0]
"While deep learning has been extensively investigated for molecular graph encoding (Duvenaud et al., 2015; Kearnes et al., 2016; Gilmer et al., 2017), the harder combinatorial task of molecular graph generation from latent representation remains under-explored.
",1. Introduction,[0],[0]
1MIT Computer Science & Artificial Intelligence Lab.,1. Introduction,[0],[0]
"Correspondence to: Wengong Jin <wengong@csail.mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"Prior work on drug design formulated the graph generation task as a string generation problem (Gómez-Bombarelli et al., 2016; Kusner et al., 2017) in an attempt to side-step direct generation of graphs.",1. Introduction,[0],[0]
"Specifically, these models start by generating SMILES (Weininger, 1988), a linear string notation used in chemistry to describe molecular structures.",1. Introduction,[0],[0]
"SMILES strings can be translated into graphs via deterministic mappings (e.g., using RDKit (Landrum, 2006)).",1. Introduction,[0],[0]
"However, this design has two critical limitations.",1. Introduction,[0],[0]
"First, the SMILES representation is not designed to capture molecular similarity.",1. Introduction,[0],[0]
"For instance, two molecules with similar chemical structures may be encoded into markedly different SMILES strings (e.g., Figure 1).",1. Introduction,[0],[0]
This prevents generative models like variational autoencoders from learning smooth molecular embeddings.,1. Introduction,[0],[0]
"Second, essential chemical properties such as molecule validity are easier to express on graphs rather than linear SMILES representations.",1. Introduction,[0],[0]
"We hypothesize that operating directly on graphs improves generative modeling of valid chemical structures.
",1. Introduction,[0],[0]
Our primary contribution is a new generative model of molecular graphs.,1. Introduction,[0],[0]
While one could imagine solving the problem in a standard manner – generating graphs node by node – the approach is not ideal for molecules.,1. Introduction,[0],[0]
"This is because creating molecules atom by atom would force the model to generate chemically invalid intermediaries (see, e.g., Figure 2), delaying validation until a complete graph is generated.",1. Introduction,[0],[0]
"Instead, we propose to generate molecular graphs in two phases by exploiting valid subgraphs as components.",1. Introduction,[0],[0]
"The overall generative approach, cast as a junction tree variational autoencoder, first generates a tree structured object (a junction tree) whose role is to represent the scaffold of subgraph components and their coarse relative arrangements.",1. Introduction,[0],[0]
The components are valid chemical substructures automatically extracted from the training set using tree decomposition and are used as building blocks.,1. Introduction,[0],[0]
"In the sec-
ond phase, the subgraphs (nodes in the tree) are assembled together into a coherent molecular graph.
",1. Introduction,[0],[0]
We evaluate our model on multiple tasks ranging from molecular generation to optimization of a given molecule according to desired properties.,1. Introduction,[0],[0]
"As baselines, we utilize state-of-the-art SMILES-based generation approaches (Kusner et al., 2017; Dai et al., 2018).",1. Introduction,[0],[0]
"We demonstrate that our model produces 100% valid molecules when sampled from a prior distribution, outperforming the top performing baseline by a significant margin.",1. Introduction,[0],[0]
"In addition, we show that our model excels in discovering molecules with desired properties, yielding a 30% relative gain over the baselines.",1. Introduction,[0],[0]
"Our approach extends the variational autoencoder (Kingma & Welling, 2013) to molecular graphs by introducing a suitable encoder and a matching decoder.",2. Junction Tree Variational Autoencoder,[0],[0]
"Deviating from previous work (Gómez-Bombarelli et al., 2016; Kusner et al., 2017), we interpret each molecule as having been built from subgraphs chosen out of a vocabulary of valid components.",2. Junction Tree Variational Autoencoder,[0],[0]
These components are used as building blocks both when encoding a molecule into a vector representation as well as when decoding latent vectors back into valid molecular graphs.,2. Junction Tree Variational Autoencoder,[0],[0]
"The key advantage of this view is that the decoder can realize a valid molecule piece by piece by utilizing the collection of valid components and how they interact, rather than trying to build the molecule atom by atom through chemically invalid intermediaries (Figure 2).",2. Junction Tree Variational Autoencoder,[0],[0]
"An aromatic bond, for example, is chemically invalid on its own unless the entire aromatic ring is present.",2. Junction Tree Variational Autoencoder,[0],[0]
"It would be therefore challenging to learn to build rings atom by atom rather than by introducing rings as part of the basic vocabulary.
",2. Junction Tree Variational Autoencoder,[0],[0]
"Our vocabulary of components, such as rings, bonds and individual atoms, is chosen to be large enough so that a given molecule can be covered by overlapping components or clusters of atoms.",2. Junction Tree Variational Autoencoder,[0],[0]
"The clusters serve the role analogous to cliques in graphical models, as they are expressive enough that a molecule can be covered by overlapping clusters without forming cluster cycles.",2. Junction Tree Variational Autoencoder,[0],[0]
"In this sense, the clusters serve as cliques in a (non-optimal) triangulation of the molecular graph.",2. Junction Tree Variational Autoencoder,[0],[0]
We form a junction tree of such clusters and use it as the tree representation of the molecule.,2. Junction Tree Variational Autoencoder,[0],[0]
"Since our choice of cliques is constrained a priori, we cannot guarantee that a junction tree exists with such clusters for an arbitrary
molecule.",2. Junction Tree Variational Autoencoder,[0],[0]
"However, our clusters are built on the basis of the molecules in the training set to ensure that a corresponding junction tree can be found.",2. Junction Tree Variational Autoencoder,[0],[0]
"Empirically, our clusters cover most of the molecules in the test set.
",2. Junction Tree Variational Autoencoder,[0],[0]
The original molecular graph and its associated junction tree offer two complementary representations of a molecule.,2. Junction Tree Variational Autoencoder,[0],[0]
We therefore encode the molecule into a two-part latent representation z,2. Junction Tree Variational Autoencoder,[0],[0]
=,2. Junction Tree Variational Autoencoder,[0],[0]
"[zT , zG] where zT encodes the tree structure and what the clusters are in the tree without fully capturing how exactly the clusters are mutually connected.",2. Junction Tree Variational Autoencoder,[0],[0]
zG encodes the graph to capture the fine-grained connectivity.,2. Junction Tree Variational Autoencoder,[0],[0]
Both parts are created by tree and graph encoders q(zT |T ) and q(zG|G).,2. Junction Tree Variational Autoencoder,[0],[0]
The latent representation is then decoded back into a molecular graph in two stages.,2. Junction Tree Variational Autoencoder,[0],[0]
"As illustrated in Figure 3, we first reproduce the junction tree using a tree decoder p(T |zT )",2. Junction Tree Variational Autoencoder,[0],[0]
based on the information in zT .,2. Junction Tree Variational Autoencoder,[0],[0]
"Second, we predict the fine grain connectivity between the clusters in the junction tree using a graph decoder p(G|T , zG) to realize the full molecular graph.",2. Junction Tree Variational Autoencoder,[0],[0]
"The junction tree approach allows us to maintain chemical feasibility during generation.
",2. Junction Tree Variational Autoencoder,[0],[0]
"Notation A molecular graph is defined as G = (V,E) where V is the set of atoms (vertices) and E the set of bonds (edges).",2. Junction Tree Variational Autoencoder,[0],[0]
Let N(x) be the neighbor of x. We denote sigmoid function as σ(·) and ReLU function as τ(·).,2. Junction Tree Variational Autoencoder,[0],[0]
"We use i, j, k for nodes in the tree and u, v, w for nodes in the graph.",2. Junction Tree Variational Autoencoder,[0],[0]
A tree decomposition maps a graph G into a junction tree by contracting certain vertices into a single node so that G becomes cycle-free.,2.1. Junction Tree,[0],[0]
"Formally, given a graph G, a junction tree TG = (V, E ,X ) is a connected labeled tree whose node set is V = {C1, · · · , Cn} and edge set is E .",2.1. Junction Tree,[0],[0]
"Each node or cluster Ci = (Vi, Ei) is an induced subgraph of G, satisfying the following constraints:
1.",2.1. Junction Tree,[0],[0]
"The union of all clusters equals G. That is, ⋃ i Vi = V
and ⋃ iEi = E.
2.",2.1. Junction Tree,[0],[0]
"Running intersection: For all clusters Ci, Cj and Ck, Vi ∩ Vj ⊆ Vk if Ck is on the path from Ci to Cj .
",2.1. Junction Tree,[0],[0]
"Viewing induced subgraphs as cluster labels, junction trees are labeled trees with label vocabulary X .",2.1. Junction Tree,[0],[0]
"By our molecule tree decomposition, X contains only cycles (rings) and single edges.",2.1. Junction Tree,[0],[0]
"Thus the vocabulary size is limited (|X | = 780 for a standard dataset with 250K molecules).
",2.1. Junction Tree,[0],[0]
"Tree Decomposition of Molecules Here we present our tree decomposition algorithm tailored for molecules, which finds its root in chemistry (Rarey & Dixon, 1998).",2.1. Junction Tree,[0],[0]
Our cluster vocabulary X includes chemical structures such as bonds and rings (Figure 3).,2.1. Junction Tree,[0],[0]
"Given a graphG, we first find all its simple cycles, and its edges not belonging to any cycles.",2.1. Junction Tree,[0],[0]
"Two simple rings are merged together if they have more than two overlapping atoms, as they constitute a specific structure called bridged compounds (Clayden et al., 2001).",2.1. Junction Tree,[0],[0]
Each of those cycles or edges is considered as a cluster.,2.1. Junction Tree,[0],[0]
"Next, a cluster graph is constructed by adding edges between all intersecting clusters.",2.1. Junction Tree,[0],[0]
"Finally, we select one of its spanning trees as the junction tree of G (Figure 3).",2.1. Junction Tree,[0],[0]
"As a result of ring merging, any two clusters in the junction tree have at most two atoms in common, facilitating efficient inference in the graph decoding phase.",2.1. Junction Tree,[0],[0]
The detailed procedure is described in the supplementary.,2.1. Junction Tree,[0],[0]
"We first encode the latent representation of G by a graph message passing network (Dai et al., 2016; Gilmer et al., 2017).",2.2. Graph Encoder,[0],[0]
"Each vertex v has a feature vector xv indicating the atom type, valence, and other properties.",2.2. Graph Encoder,[0],[0]
"Similarly, each edge (u, v) ∈ E has a feature vector xuv indicating its bond type, and two hidden vectors νuv and νvu denoting the message from u to v and vice versa.",2.2. Graph Encoder,[0],[0]
"Due to the loopy structure of the graph, messages are exchanged in a loopy belief propagation fashion:
ν(t)uv = τ(W",2.2. Graph Encoder,[0],[0]
"g 1xu +W g 2xuv +W g 3 ∑ w∈N(u)\v ν(t−1)wu ) (1)
where ν(t)uv is the message computed in t-th iteration, initialized with ν(0)uv = 0.",2.2. Graph Encoder,[0],[0]
"After T steps of iteration, we aggregate
those messages as the latent vector of each vertex, which captures its local graphical structure:
hu =",2.2. Graph Encoder,[0],[0]
"τ(U g 1xu + ∑ v∈N(u) Ug2ν (T ) vu ) (2)
",2.2. Graph Encoder,[0],[0]
The final graph representation is hG = ∑ i hi/|V |.,2.2. Graph Encoder,[0],[0]
The mean µG and log variance logσG of the variational posterior approximation are computed from hG with two separate affine layers.,2.2. Graph Encoder,[0],[0]
"zG is sampled from a Gaussian N (µG,σG).",2.2. Graph Encoder,[0],[0]
We similarly encode TG with a tree message passing network.,2.3. Tree Encoder,[0],[0]
Each cluster Ci is represented by a one-hot encoding xi representing its label type.,2.3. Tree Encoder,[0],[0]
"Each edge (Ci, Cj) is associated with two message vectors mij and mji.",2.3. Tree Encoder,[0],[0]
We pick an arbitrary leaf node as the root and propagate messages in two phases.,2.3. Tree Encoder,[0],[0]
"In the first bottom-up phase, messages are initiated from the leaf nodes and propagated iteratively towards root.",2.3. Tree Encoder,[0],[0]
"In the top-down phase, messages are propagated from the root to all the leaf nodes.",2.3. Tree Encoder,[0],[0]
"Message mij is updated as:
mij = GRU(xi, {mki}k∈N(i)\j) (3)
where GRU is a Gated Recurrent Unit (Chung et al., 2014; Li et al., 2015) adapted for tree message passing:
sij = ∑
k∈N(i)\j mki (4)
",2.3. Tree Encoder,[0],[0]
zij = σ(W zxi +U zsij + b z) (5) rki = σ(W rxi +U rmki + b r),2.3. Tree Encoder,[0],[0]
"(6)
m̃ij = tanh(Wxi +U ∑
k∈N(i)\j
rki mki) (7)
mij = (1− zij) sij + zij m̃ij (8)
The message passing follows the schedule where mij is computed only when all its precursors {mki | k ∈ N(i)\j} have been computed.",2.3. Tree Encoder,[0],[0]
"This architectural design is motivated by the belief propagation algorithm over trees and is thus different from the graph encoder.
",2.3. Tree Encoder,[0],[0]
"After the message passing, we obtain the latent representation of each node hi by aggregating its inward messages:
hi = τ(W oxi + ∑ k∈N(i) Uomki) (9)
",2.3. Tree Encoder,[0],[0]
"The final tree representation is hTG = hroot, which encodes a rooted tree (T , root).",2.3. Tree Encoder,[0],[0]
"Unlike the graph encoder, we do not apply node average pooling because it confuses the tree decoder which node to generate first.",2.3. Tree Encoder,[0],[0]
zTG is sampled in a similar way as in the graph encoder.,2.3. Tree Encoder,[0],[0]
"For simplicity, we abbreviate zTG as zT from now on.
",2.3. Tree Encoder,[0],[0]
This tree encoder plays two roles in our framework.,2.3. Tree Encoder,[0],[0]
"First, it is used to compute zT , which only requires the bottom-up phase of the network.",2.3. Tree Encoder,[0],[0]
"Second, after a tree T̂ is decoded
from zT , it is used to compute messages m̂ij over the entire T̂ , to provide essential contexts of every node during graph decoding.",2.3. Tree Encoder,[0],[0]
This requires both top-down and bottom-up phases.,2.3. Tree Encoder,[0],[0]
We will elaborate this in section 2.5.,2.3. Tree Encoder,[0],[0]
We decode a junction tree T from its encoding zT with a tree structured decoder.,2.4. Tree Decoder,[0],[0]
The tree is constructed in a top-down fashion by generating one node at a time.,2.4. Tree Decoder,[0],[0]
"As illustrated in Figure 4, our tree decoder traverses the entire tree from the root, and generates nodes in their depth-first order.",2.4. Tree Decoder,[0],[0]
"For every visited node, the decoder first makes a topological prediction: whether this node has children to be generated.",2.4. Tree Decoder,[0],[0]
"When a new child node is created, we predict its label and recurse this process.",2.4. Tree Decoder,[0],[0]
Recall that cluster labels represent subgraphs in a molecule.,2.4. Tree Decoder,[0],[0]
"The decoder backtracks when a node has no more children to generate.
",2.4. Tree Decoder,[0],[0]
"At each time step, a node receives information from other nodes in the current tree for making those predictions.",2.4. Tree Decoder,[0],[0]
The information is propagated through message vectors hij when trees are incrementally constructed.,2.4. Tree Decoder,[0],[0]
"Formally, let Ẽ = {(i1, j1), · · · , (im, jm)} be the edges traversed in a depth first traversal over T = (V, E), where m = 2|E| as each edge is traversed in both directions.",2.4. Tree Decoder,[0],[0]
The model visits node it at time t. Let Ẽt be the first t edges in Ẽ .,2.4. Tree Decoder,[0],[0]
"The message hit,jt is updated through previous messages:
hit,jt = GRU(xit , {hk,it}(k,it)∈Ẽt,k 6=jt) (10)
where GRU is the same recurrent unit as in the tree encoder.
",2.4. Tree Decoder,[0],[0]
"Topological Prediction When the model visits node it, it makes a binary prediction on whether it still has children to be generated.",2.4. Tree Decoder,[0],[0]
"We compute this probability by combining
Algorithm 1 Tree decoding at sampling time Require:",2.4. Tree Decoder,[0],[0]
"Latent representation zT
1: Initialize: Tree T̂ ← ∅ 2: function SampleTree(i, t) 3:",2.4. Tree Decoder,[0],[0]
Set Xi ← all cluster labels that are chemically compatible with node i and its current neighbors.,2.4. Tree Decoder,[0],[0]
4: Set dt ← expand with probability pt. .,2.4. Tree Decoder,[0],[0]
Eq.(11) 5:,2.4. Tree Decoder,[0],[0]
if dt = expand and Xi 6= ∅,2.4. Tree Decoder,[0],[0]
then 6: Create a node j and add it to tree T̂ .,2.4. Tree Decoder,[0],[0]
"7: Sample the label of node j from Xi .. Eq.(12) 8: SampleTree(j, t+ 1) 9: end if
10: end function
zT , node features xit and inward messages hk,it via a one hidden layer network followed by a sigmoid function:
pt = σ(u d ·τ(Wd1xit+Wd2zT +Wd3 ∑ (k,it)∈Ẽt hk,it) (11)
Label Prediction When a child node j is generated from its parent i, we predict its node label with
qj = softmax(Ulτ(Wl1zT",2.4. Tree Decoder,[0],[0]
+,2.4. Tree Decoder,[0],[0]
W l 2hij)),2.4. Tree Decoder,[0],[0]
"(12)
where qj is a distribution over label vocabulary X .",2.4. Tree Decoder,[0],[0]
"When j is a root node, its parent i is a virtual node and hij = 0.
",2.4. Tree Decoder,[0],[0]
Learning The tree decoder aims to maximize the likelihood p(T |zT ).,2.4. Tree Decoder,[0],[0]
"Let p̂t ∈ {0, 1} and q̂j be the ground truth topological and label values, the decoder minimizes the following cross entropy loss:1
Lc(T ) =",2.4. Tree Decoder,[0],[0]
"∑
t Ld(pt, p̂t)",2.4. Tree Decoder,[0],[0]
"+ ∑ j Ll(qj , q̂j) (13)
",2.4. Tree Decoder,[0],[0]
"Similar to sequence generation, during training we perform teacher forcing: after topological and label prediction at each step, we replace them with their ground truth so that the model makes predictions given correct histories.
",2.4. Tree Decoder,[0],[0]
Decoding & Feasibility Check Algorithm 1 shows how a tree is sampled from zT .,2.4. Tree Decoder,[0],[0]
The tree is constructed recursively guided by topological predictions without any external guidance used in training.,2.4. Tree Decoder,[0],[0]
"To ensure the sampled tree could be realized into a valid molecule, we define set Xi to be cluster labels that are chemically compatible with node i and its current neighbors.",2.4. Tree Decoder,[0],[0]
"When a child node j is generated from node i, we sample its label from Xi with a renormalized distribution qj over Xi by masking out invalid labels.",2.4. Tree Decoder,[0],[0]
"The final step of our model is to reproduce a molecular graph G that underlies the predicted junction tree T̂ = (V̂, Ê).
",2.5. Graph Decoder,[0],[0]
1The node ordering is not unique as the order within sibling nodes is ambiguous.,2.5. Graph Decoder,[0],[0]
"In this paper we train our model with one ordering and leave this issue for future work.
",2.5. Graph Decoder,[0],[0]
Note that this step is not deterministic since there are potentially many molecules that correspond to the same junction tree.,2.5. Graph Decoder,[0],[0]
The underlying degree of freedom pertains to how neighboring clusters Ci and Cj are attached to each other as subgraphs.,2.5. Graph Decoder,[0],[0]
"Our goal here is to assemble the subgraphs (nodes in the tree) together into the correct molecular graph.
",2.5. Graph Decoder,[0],[0]
Let G(T ) be the set of graphs whose junction tree is T .,2.5. Graph Decoder,[0],[0]
"Decoding graph Ĝ from T̂ = (V̂, Ê) is a structured prediction:
Ĝ = arg max G′∈G(T̂ )
",2.5. Graph Decoder,[0],[0]
"fa(G′) (14)
where fa is a scoring function over candidate graphs.",2.5. Graph Decoder,[0],[0]
We only consider scoring functions that decompose across the clusters and their neighbors.,2.5. Graph Decoder,[0],[0]
"In other words, each term in the scoring function depends only on how a cluster Ci is attached to its neighboring clusters",2.5. Graph Decoder,[0],[0]
"Cj , j ∈ NT̂ (i) in the tree T̂ .",2.5. Graph Decoder,[0],[0]
The problem of finding the highest scoring graph Ĝ – the assembly task – could be cast as a graphical model inference task in a model induced by the junction tree.,2.5. Graph Decoder,[0],[0]
"However, for efficiency reasons, we will assemble the molecular graph one neighborhood at a time, following the order in which the tree itself was decoded.",2.5. Graph Decoder,[0],[0]
"In other words, we start by sampling the assembly of the root and its neighbors according to their
scores.",2.5. Graph Decoder,[0],[0]
"Then we proceed to assemble the neighbors and their associated clusters (removing the degrees of freedom set by the root assembly), and so on.
",2.5. Graph Decoder,[0],[0]
It remains to be specified how each neighborhood realization is scored.,2.5. Graph Decoder,[0],[0]
"Let Gi be the subgraph resulting from a particular merging of cluster Ci in the tree with its neighbors Cj , j ∈ NT̂ (i).",2.5. Graph Decoder,[0],[0]
We score Gi as a candidate subgraph by first deriving a vector representation hGi and then using fai (Gi) = hGi · zG as the subgraph score.,2.5. Graph Decoder,[0],[0]
"To this end, let u, v specify atoms in the candidate subgraph Gi and let αv = i",2.5. Graph Decoder,[0],[0]
if v ∈ Ci and αv = j if v ∈,2.5. Graph Decoder,[0],[0]
Cj \ Ci.,2.5. Graph Decoder,[0],[0]
"The indices αv are used to mark the position of the atoms in the junction tree, and to retrieve messages m̂i,j summarizing the subtree under i along the edge (i, j) obtained by running the tree encoding algorithm.",2.5. Graph Decoder,[0],[0]
"The neural messages pertaining to the atoms and bonds in subgraph Gi are obtained and aggregated into hGi , similarly to the encoding step, but with different (learned) parameters:
µ(t)uv = τ(W a 1xu +W a 2xuv +W a 3µ̃ (t−1) uv ) (15)
µ̃(t−1)uv =
{∑ w∈N(u)\v µ (t−1) wu",2.5. Graph Decoder,[0],[0]
"αu = αv
m̂αu,αv + ∑ w∈N(u)\v µ",2.5. Graph Decoder,[0],[0]
(t−1) wu,2.5. Graph Decoder,[0],[0]
"αu 6= αv
The major difference from Eq.",2.5. Graph Decoder,[0],[0]
"(1) is that we augment the model with tree messages m̂αu,αv derived by running the tree encoder over the predicted tree T̂ .",2.5. Graph Decoder,[0],[0]
"m̂αu,αv provides a tree dependent positional context for bond (u, v) (illustrated as subtree A in Figure 5).
",2.5. Graph Decoder,[0],[0]
"Learning The graph decoder parameters are learned to maximize the log-likelihood of predicting correct subgraphs Gi of the ground true graph G at each tree node:
Lg(G)",2.5. Graph Decoder,[0],[0]
= ∑ i fa(Gi)− log ∑ G′i∈Gi exp(fa(G′i))  ,2.5. Graph Decoder,[0],[0]
"(16) where Gi is the set of possible candidate subgraphs at tree node i. During training, we again apply teacher forcing, i.e. we feed the graph decoder with ground truth trees as input.
",2.5. Graph Decoder,[0],[0]
Complexity,2.5. Graph Decoder,[0],[0]
"By our tree decomposition, any two clusters share at most two atoms, so we only need to merge at most two atoms or one bond.",2.5. Graph Decoder,[0],[0]
"By pruning chemically invalid subgraphs and merging isomorphic graphs, |Gi| ≈ 4 on average when tested on a standard ZINC drug dataset.",2.5. Graph Decoder,[0],[0]
"The computational complexity of JT-VAE is therefore linear in the number of clusters, scaling nicely to large graphs.",2.5. Graph Decoder,[0],[0]
Our evaluation efforts measure various aspects of molecular generation.,3. Experiments,[0],[0]
"The first two evaluations follow previously proposed tasks (Kusner et al., 2017).",3. Experiments,[0],[0]
"We also introduce a third task — constrained molecule optimization.
",3. Experiments,[0],[0]
"• Molecule reconstruction and validity We test the VAE models on the task of reconstructing input molecules from their latent representations, and decoding valid molecules when sampling from prior distribution.",3. Experiments,[0],[0]
(Section 3.1) •,3. Experiments,[0],[0]
"Bayesian optimization Moving beyond generating valid
molecules, we test how the model can produce novel molecules with desired properties.",3. Experiments,[0],[0]
"To this end, we perform Bayesian optimization in the latent space to search molecules with specified properties.",3. Experiments,[0],[0]
"(Section 3.2)
• Constrained molecule optimization The task is to modify given molecules to improve specified properties, while constraining the degree of deviation from the original molecule.",3. Experiments,[0],[0]
"This is a more realistic scenario in drug discovery, where development of new drugs usually starts with known molecules such as existing drugs (Besnard et al., 2012).",3. Experiments,[0],[0]
"Since it is a new task, we cannot compare to any existing baselines.",3. Experiments,[0],[0]
"(Section 3.3)
",3. Experiments,[0],[0]
"Below we describe the data, baselines and model configuration that are shared across the tasks.",3. Experiments,[0],[0]
"Additional setup details are provided in the task-specific sections.
",3. Experiments,[0],[0]
"Data We use the ZINC molecule dataset from Kusner et al. (2017) for our experiments, with the same training/testing split.",3. Experiments,[0],[0]
"It contains about 250K drug molecules extracted from the ZINC database (Sterling & Irwin, 2015).
",3. Experiments,[0],[0]
"Baselines We compare our approach with SMILES-based baselines: 1) Character VAE (CVAE) (Gómez-Bombarelli et al., 2016) which generates SMILES strings character by character; 2) Grammar VAE (GVAE) (Kusner et al., 2017) that generates SMILES following syntactic constraints given
by a context-free grammar; 3) Syntax-directed VAE (SDVAE) (Dai et al., 2018) that incorporates both syntactic and semantic constraints of SMILES via attribute grammar.",3. Experiments,[0],[0]
"For molecule generation task, we also compare with GraphVAE (Simonovsky & Komodakis, 2018) that directly generates atom labels and adjacency matrices of graphs.
",3. Experiments,[0],[0]
"Model Configuration To be comparable with the above baselines, we set the latent space dimension as 56, i.e., the tree and graph representation hT and hG have 28 dimensions each.",3. Experiments,[0],[0]
Full training details and model configurations are provided in the appendix.,3. Experiments,[0],[0]
Setup The first task is to reconstruct and sample molecules from latent space.,3.1. Molecule Reconstruction and Validity,[0],[0]
"Since both encoding and decoding process are stochastic, we estimate reconstruction accuracy by Monte Carlo method used in (Kusner et al., 2017):",3.1. Molecule Reconstruction and Validity,[0],[0]
Each molecule is encoded 10 times and each encoding is decoded 10 times.,3.1. Molecule Reconstruction and Validity,[0],[0]
"We report the portion of the 100 decoded molecules that are identical to the input molecule.
",3.1. Molecule Reconstruction and Validity,[0],[0]
"To compute validity, we sample 1000 latent vectors from the prior distribution N (0, I), and decode each of these vectors 100 times.",3.1. Molecule Reconstruction and Validity,[0],[0]
We report the percentage of decoded molecules that are chemically valid (checked by RDKit).,3.1. Molecule Reconstruction and Validity,[0],[0]
"For ablation study, we also report the validity of our model without validity check in decoding phase.
",3.1. Molecule Reconstruction and Validity,[0],[0]
"Results Table 1 shows that JT-VAE outperforms previous models in molecule reconstruction, and always pro-
duces valid molecules when sampled from prior distribution.",3.1. Molecule Reconstruction and Validity,[0],[0]
"When validity check is removed, our model could still generates 93.5% valid molecules.",3.1. Molecule Reconstruction and Validity,[0],[0]
This shows our method does not heavily rely on prior knowledge.,3.1. Molecule Reconstruction and Validity,[0],[0]
"As shown in Figure 6, the sampled molecules have non-trivial structures such as simple chains.",3.1. Molecule Reconstruction and Validity,[0],[0]
We further sampled 5000 molecules from prior and found they are all distinct from the training set.,3.1. Molecule Reconstruction and Validity,[0],[0]
"Thus our model is not a simple memorization.
",3.1. Molecule Reconstruction and Validity,[0],[0]
Analysis We qualitatively examine the latent space of JTVAE by visualizing the neighborhood of molecules.,3.1. Molecule Reconstruction and Validity,[0],[0]
"Given a molecule, we follow the method in Kusner et al. (2017) to construct a grid visualization of its neighborhood.",3.1. Molecule Reconstruction and Validity,[0],[0]
Figure 6 shows the local neighborhood of the same molecule visualized in Dai et al. (2018).,3.1. Molecule Reconstruction and Validity,[0],[0]
"In comparison, our neighborhood does not contain molecules with huge rings (with more than 7 atoms), which rarely occur in the dataset.",3.1. Molecule Reconstruction and Validity,[0],[0]
We also highlight two groups of closely resembling molecules that have identical tree structures but vary only in how clusters are attached together.,3.1. Molecule Reconstruction and Validity,[0],[0]
This demonstrates the smoothness of learned molecular embeddings.,3.1. Molecule Reconstruction and Validity,[0],[0]
Setup The second task is to produce novel molecules with desired properties.,3.2. Bayesian Optimization,[0],[0]
"Following (Kusner et al., 2017), our target chemical property y(·) is octanol-water partition coefficients (logP) penalized by the synthetic accessibility (SA) score and number of long cycles.2 To perform Bayesian optimization (BO), we first train a VAE and associate each molecule with a latent vector, given by the mean of the variational encoding distribution.",3.2. Bayesian Optimization,[0],[0]
"After the VAE is learned, we train a sparse Gaussian process (SGP) to predict y(m) given its latent representation.",3.2. Bayesian Optimization,[0],[0]
"Then we perform five iterations of batched BO using the expected improvement heuristic.
",3.2. Bayesian Optimization,[0],[0]
"For comparison, we report 1) the predictive performance of SGP trained on latent encodings learned by different VAEs, measured by log-likelihood (LL) and root mean square error (RMSE) with 10-fold cross validation.",3.2. Bayesian Optimization,[0],[0]
"2) The top-3 molecules found by BO under different models.
2y(m) = logP (m) − SA(m)",3.2. Bayesian Optimization,[0],[0]
"− cycle(m) where cycle(m) counts the number of rings that have more than six atoms.
",3.2. Bayesian Optimization,[0],[0]
"Results As shown in Table 2, JT-VAE finds molecules with significantly better scores than previous methods.",3.2. Bayesian Optimization,[0],[0]
Figure 7 lists the top-3 best molecules found by JT-VAE.,3.2. Bayesian Optimization,[0],[0]
"In fact, JT-VAE finds over 50 molecules with scores over 3.50 (the second best molecule proposed by SD-VAE).",3.2. Bayesian Optimization,[0],[0]
"Moreover, the SGP yields better predictive performance when trained on JT-VAE embeddings (Table 3).",3.2. Bayesian Optimization,[0],[0]
Setup The third task is to perform molecule optimization in a constrained scenario.,3.3. Constrained Optimization,[0],[0]
"Given a molecule m, the task is to find a different molecule m′ that has the highest property value with the molecular similarity sim(m,m′)",3.3. Constrained Optimization,[0],[0]
≥ δ for some threshold δ.,3.3. Constrained Optimization,[0],[0]
"We use Tanimoto similarity with Morgan fingerprint (Rogers & Hahn, 2010) as the similarity metric, and penalized logP coefficient as our target chemical property.",3.3. Constrained Optimization,[0],[0]
"For this task, we jointly train a property predictor F (parameterized by a feed-forward network) with JT-VAE to predict y(m) from the latent embedding of m. To optimize a molecule m, we start from its latent representation, and apply gradient ascent in the latent space to improve the predicted score F (·), similar to (Mueller et al., 2017).",3.3. Constrained Optimization,[0],[0]
"After applying K = 80 gradient steps, K molecules are decoded from resulting latent trajectories, and we report the molecule with the highest F (·) that satisfies the similarity constraint.",3.3. Constrained Optimization,[0],[0]
"A modification succeeds if one of the decoded molecules satisfies the constraint and is distinct from the original.
",3.3. Constrained Optimization,[0],[0]
"To provide the greatest challenge, we selected 800 molecules with the lowest property score y(·) from the test set.",3.3. Constrained Optimization,[0],[0]
"We report the success rate (how often a modification succeeds), and among success cases the average improvement y(m′)− y(m) and molecular similarity sim(m,m′) between the original and modified molecules m and m′.
Results Our results are summarized in Table 4.",3.3. Constrained Optimization,[0],[0]
"The unconstrained scenario (δ = 0) has the best average improvement, but often proposes dissimilar molecules.",3.3. Constrained Optimization,[0],[0]
"When we tighten the constraint to δ = 0.4, about 80% of the time our model finds similar molecules, with an average improvement 0.84.",3.3. Constrained Optimization,[0],[0]
This also demonstrates the smoothness of the learned latent space.,3.3. Constrained Optimization,[0],[0]
Figure 8 illustrates an effective modification resulting in a similar molecule with great improvement.,3.3. Constrained Optimization,[0],[0]
Molecule Generation Previous work on molecule generation mostly operates on SMILES strings.,4. Related Work,[0],[0]
GómezBombarelli,4. Related Work,[0],[0]
et al. (2016); Segler et al. (2017) built generative models of SMILES strings with recurrent decoders.,4. Related Work,[0],[0]
"Unfortunately, these models could generate invalid SMILES that do not result in any molecules.",4. Related Work,[0],[0]
"To remedy this issue, Kusner et al. (2017); Dai et al. (2018) complemented the decoder with syntactic and semantic constraints of SMILES by context free and attribute grammars, but these grammars do not fully capture chemical validity.",4. Related Work,[0],[0]
"Other techniques such as active learning (Janz et al., 2017) and reinforcement learning (Guimaraes et al., 2017) encourage the model to generate valid SMILES through additional training signal.",4. Related Work,[0],[0]
"Very recently, Simonovsky & Komodakis (2018) proposed to generate molecular graphs by predicting their adjacency matrices, and Li et al. (2018) generated molecules node by node.",4. Related Work,[0],[0]
"In comparison, our method enforces chemical validity and is more efficient due to the coarse-to-fine generation.
",4. Related Work,[0],[0]
Graph-structured Encoders,4. Related Work,[0],[0]
"The neural network formulation on graphs was first proposed by Gori et al. (2005); Scarselli et al. (2009), and later enhanced by Li et al. (2015) with gated recurrent units.",4. Related Work,[0],[0]
"For recurrent architectures over
graphs, Lei et al. (2017) designed Weisfeiler-Lehman kernel network inspired by graph kernels.",4. Related Work,[0],[0]
"Dai et al. (2016) considered a different architecture where graphs were viewed as latent variable graphical models, and derived their model from message passing algorithms.",4. Related Work,[0],[0]
"Our tree and graph encoder are closely related to this graphical model perspective, and to neural message passing networks (Gilmer et al., 2017).",4. Related Work,[0],[0]
"For convolutional architectures, Duvenaud et al. (2015) introduced a convolution-like propagation on molecular graphs, which was generalized to other domains by Niepert et al. (2016).",4. Related Work,[0],[0]
Bruna et al. (2013); Henaff et al. (2015) developed graph convolution in spectral domain via graph Laplacian.,4. Related Work,[0],[0]
"For applications, graph neural networks are used in semisupervised classification (Kipf & Welling, 2016), computer vision (Monti et al., 2016), and chemical domains (Kearnes et al., 2016; Schütt et al., 2017; Jin et al., 2017).
",4. Related Work,[0],[0]
Tree-structured Models,4. Related Work,[0],[0]
"Our tree encoder is related to recursive neural networks and tree-LSTM (Socher et al., 2013; Tai et al., 2015; Zhu et al., 2015).",4. Related Work,[0],[0]
These models encode tree structures where nodes in the tree are bottom-up transformed into vector representations.,4. Related Work,[0],[0]
"In contrast, our model propagates information both bottom-up and top-down.
",4. Related Work,[0],[0]
"On the decoding side, tree generation naturally arises in natural language parsing (Dyer et al., 2016; Kiperwasser & Goldberg, 2016).",4. Related Work,[0],[0]
"Different from our approach, natural language parsers have access to input words and only predict the topology of the tree.",4. Related Work,[0],[0]
"For general purpose tree generation, Vinyals et al. (2015); Aharoni & Goldberg (2017) applied recurrent networks to generate linearized version of trees, but their architectures were entirely sequence-based.",4. Related Work,[0],[0]
Dong & Lapata (2016); Alvarez-Melis & Jaakkola (2016) proposed tree-based architectures that construct trees top-down from the root.,4. Related Work,[0],[0]
"Our model is most closely related to Alvarez-Melis & Jaakkola (2016) that disentangles topological prediction from label prediction, but we generate nodes in a depth-first order and have additional steps that propagate information bottom-up.",4. Related Work,[0],[0]
"This forward-backward propagation also appears in Parisotto et al. (2016), but their model is node based whereas ours is based on message passing.",4. Related Work,[0],[0]
In this paper we present a junction tree variational autoencoder for generating molecular graphs.,5. Conclusion,[0],[0]
Our method significantly outperforms previous work in molecule generation and optimization.,5. Conclusion,[0],[0]
"For future work, we attempt to generalize our method for general low-treewidth graphs.",5. Conclusion,[0],[0]
"We thank Jonas Mueller, Chengtao Li, Tao Lei and MIT NLP Group for their helpful comments.",Acknowledgement,[0],[0]
This work was supported by the DARPA Make-It program under contract ARO W911NF-16-2-0023.,Acknowledgement,[0],[0]
We seek to automate the design of molecules based on specific chemical properties.,abstractText,[0],[0]
"In computational terms, this task involves continuous embedding and generation of molecular graphs.",abstractText,[0],[0]
"Our primary contribution is the direct realization of molecular graphs, a task previously approached by generating linear SMILES strings instead of graphs.",abstractText,[0],[0]
"Our junction tree variational autoencoder generates molecular graphs in two phases, by first generating a tree-structured scaffold over chemical substructures, and then combining them into a molecule with a graph message passing network.",abstractText,[0],[0]
This approach allows us to incrementally expand molecules while maintaining chemical validity at every step.,abstractText,[0],[0]
We evaluate our model on multiple tasks ranging from molecular generation to optimization.,abstractText,[0],[0]
"Across these tasks, our model outperforms previous state-of-the-art baselines by a significant margin.",abstractText,[0],[0]
Junction Tree Variational Autoencoder for Molecular Graph Generation,title,[0],[0]
"by using adaptively chosen pairwise comparisons. Our goal is to recover the ranking accurately but to sample the comparisons sparingly. If all comparison outcomes are consistent with the ranking, the optimal solution is to use an efficient sorting algorithm, such as Quicksort. But how do sorting algorithms behave if some comparison outcomes are inconsistent with the ranking? We give favorable guarantees for Quicksort for the popular Bradley–Terry model, under natural assumptions on the parameters. Furthermore, we empirically demonstrate that sorting algorithms lead to a very simple and effective active learning strategy: repeatedly sort the items. This strategy performs as well as state-of-the-art methods (and much better than random sampling) at a minuscule fraction of the computational cost.",text,[0],[0]
"The problem of recovering a ranking over n items from noisy outcomes of pairwise comparisons has attracted, in the last century, much research interest, driven by applications in sports (Elo, 1978), social sciences (Thurstone, 1927; Salganik & Levy, 2015) and—more recently—recommender systems (Houlsby et al., 2012).",1 Introduction,[0],[0]
"Whereas pairwise comparison models and related inference algorithms have been extensively studied, the issue of which pairwise comparisons to sample, also known as active learning, has received significantly less attention.",1 Introduction,[0],[0]
"To understand the potential benefits of adaptively selecting samples, consider the case where comparison outcomes are noiseless, i.e., consistent with a linear order on a set of n items.",1 Introduction,[0],[0]
"If pairs of items are selected at random, it is necessary to collect Ω(n2) comparisons to recover the ranking (Alon et al., 1994).",1 Introduction,[0],[0]
"In contrast, by using an efficient sorting algorithm, O(n log n) adaptively
1School of Computer and Communication Sciences, EPFL, Lausanne, Switzerland.",1 Introduction,[0],[0]
"Correspondence to: Lucas Maystre <lucas.maystre@epfl.ch>.
",1 Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1 Introduction,[0],[0]
"Copyright 2017 by the author(s).
chosen comparisons are sufficient.",1 Introduction,[0],[0]
"In this work, we demonstrate that sorting algorithms can also be helpful in the noisy setting, where some comparison outcomes are inconsistent with the ranking: despite errors, sorting algorithms tend to select informative samples.",1 Introduction,[0],[0]
"We focus on the Bradley–Terry (BT) model, a widely-used probabilistic model of comparison outcomes.",1 Introduction,[0],[0]
"In this model, each item is associated with a parameter on the real line, and the probability of observing an incorrect outcome decreases as the distance between the items’ parameters increases.
",1 Introduction,[0],[0]
"First, we study the output of a single execution of Quicksort when comparison outcomes are generated from a BT model, under the assumption that the distance between adjacent parameters is (stochastically) uniform across the ranking.",1 Introduction,[0],[0]
"We measure the quality of a ranking estimate by its displacement with respect to the ground truth, i.e., the sum of rank differences.",1 Introduction,[0],[0]
We show that Quicksort’s output is a good approximation to the ground-truth ranking: no method comparing every pair of items at most once can do better (up to constant factors).,1 Introduction,[0],[0]
"Furthermore, we show that by aggregating O(log5 n) independent runs of Quicksort, it is possible to recover the exact rank for all but a vanishing fraction of the items.",1 Introduction,[0],[0]
"These theoretical results suggest that adaptive sampling is able to bring a substantial acceleration to the learning process.
",1 Introduction,[0],[0]
"Second, we propose a practical active-learning (AL) strategy that consists of repeatedly sorting the items.",1 Introduction,[0],[0]
We evaluate our sorting-based method on three datasets and compare it to existing AL methods.,1 Introduction,[0],[0]
We observe that all the strategies that we consider lead to better ranking estimates noticeably faster than random sampling.,1 Introduction,[0],[0]
"However, most strategies are challenging to operate and computationally expensive, thus hindering wider adoption (Schein & Ungar, 2007).",1 Introduction,[0],[0]
"In this regard, sorting-based AL stands out, as a) it is computationally-speaking as inexpensive as random sampling, b) it is trivial to implement, and c)",1 Introduction,[0],[0]
it requires no tuning of hyperparameters.,1 Introduction,[0],[0]
"We consider n items that are represented by consecutive integers [n] = {1, . . .",1.1 Preliminaries and Notation,[0],[0]
", n}.",1.1 Preliminaries and Notation,[0],[0]
"Without loss of generality, we
assume that the items are ranked by increasing preference1, i.e., i < j means that j is (in expectation) preferred to i.",1.1 Preliminaries and Notation,[0],[0]
"When j is preferred to i as a result of a pairwise comparison, we denote the observation by i ≺ j.",1.1 Preliminaries and Notation,[0],[0]
"If i < j, we say that i ≺ j is a consistent outcome and j ≺ i an inconsistent (incorrect) outcome.",1.1 Preliminaries and Notation,[0],[0]
"In most of the paper, pairwise comparison outcomes follow a Bradley–Terry model with parameters θ = [ θ1 · · · θn ]
∈ Rn, denoted BT(θ).",1.1 Preliminaries and Notation,[0],[0]
"The parameters θ1 < · · · < θn represent the utilities of items 1, . . .",1.1 Preliminaries and Notation,[0],[0]
",",1.1 Preliminaries and Notation,[0],[0]
"n, and the probability of observing the outcome",1.1 Preliminaries and Notation,[0],[0]
"i ≺ j is
p(i ≺ j | θ) = 1
1 + exp[−(θj − θi)] .
",1.1 Preliminaries and Notation,[0],[0]
The probability of observing an inconsistent comparison decreases with the distance between the items.,1.1 Preliminaries and Notation,[0],[0]
"This captures the intuitive notion that some pairs of items are easy to compare and some are more difficult (Zermelo, 1928; Bradley & Terry, 1952).
",1.1 Preliminaries and Notation,[0],[0]
"A ranking σ is a function that maps an item to its rank, i.e., σ(i) = rank of item i.",1.1 Preliminaries and Notation,[0],[0]
"The (ground-truth) identity ranking is denoted by id, i.e. id(i) = i. To measure the quality of a ranking σ with respect to the ground-truth, we consider the displacement
∆(σ) =
n ∑
i=1
|σ(i)− i|,
also known as Spearman’s footrule distance.",1.1 Preliminaries and Notation,[0],[0]
"Another metric widely used in practice is the Kendall–Tau distance, defined as K(σ) =",1.1 Preliminaries and Notation,[0],[0]
"∑
i<j 1 {σ(i) > σ(j)}.",1.1 Preliminaries and Notation,[0],[0]
"Both metrics are equiv-
alent up to a factor of two2, such that bounds on ∆(σ) also hold for K(σ) up to constant factors.
",1.1 Preliminaries and Notation,[0],[0]
"Finally, we say that an event A holds with high probability if P [A] → 1 as n → ∞. For a random variable X and a sequence of numbers an, we say that X = O(an) with high probability if P",1.1 Preliminaries and Notation,[0],[0]
[|X| ≤ can]→,1.1 Preliminaries and Notation,[0],[0]
"1 as n→∞ for some constant c that does not depend on n.
Outline of the paper.",1.1 Preliminaries and Notation,[0],[0]
We begin by briefly reviewing related literature in Section 2.,1.1 Preliminaries and Notation,[0],[0]
"Next, in Section 3, we study the displacement of Quicksort’s output under noisy comparisons.",1.1 Preliminaries and Notation,[0],[0]
"In Section 4, we empirically evaluate several AL strategies on three datasets.",1.1 Preliminaries and Notation,[0],[0]
"Finally, we conclude in Section 5.",1.1 Preliminaries and Notation,[0],[0]
Passive setting.,2 Related Work,[0],[0]
"Recently, there have been a number of results on the sample complexity of the BT model, based on
1 This convention greatly simplifies the notation throughout the paper, but differs from that used in most of the preference learning literature.",2 Related Work,[0],[0]
"In our paper, the item with rank 1 is the worst.
2∆(σ)/2 ≤ K(σ)",2 Related Work,[0],[0]
"≤ ∆(σ) (Diaconis & Graham, 1977).
",2 Related Work,[0],[0]
"the assumption that all pairs of items are chosen before any comparison outcome is revealed (Negahban et al., 2012; Hajek et al., 2014; Rajkumar & Agarwal, 2014; Vojnovic & Yun, 2016).",2 Related Work,[0],[0]
"In general, these results reveal that choosing pairs of items uniformly at random is essentially optimal.",2 Related Work,[0],[0]
"Furthermore, they suggest that the ranking induced by the BT model cannot be recovered with less than Ω(n2) comparisons.",2 Related Work,[0],[0]
"Our work shows that by adaptively selecting pairs based on observed outcomes, we observe substantial gains.
",2 Related Work,[0],[0]
Active preference learning.,2 Related Work,[0],[0]
AL approaches for learning a ranking based on noisy comparison outcomes have been studied under various assumptions.,2 Related Work,[0],[0]
"Braverman & Mossel (2008) examine a model where outcomes of pairwise comparisons are flipped with a small, constant probability.",2 Related Work,[0],[0]
"Ailon (2012) considers an adversarial setting (comparison outcomes can be arbitrary) and investigates AL in the context of finding a ranking that minimizes the number of inconsistent outcomes, also known as the minimum feedback-arc set problem on tournaments (MFAST).",2 Related Work,[0],[0]
"These theoretical studies imply, in their respective settings, that O(n logk n) comparison outcomes are enough to recover a near-optimal ranking.",2 Related Work,[0],[0]
"Jamieson & Nowak (2011) propose an efficient active-ranking algorithm that is applicable if items can be embedded in Rd (e.g., using d features) and assuming that admissible rankings satisfy some geometric constraints.",2 Related Work,[0],[0]
Wang et al. (2014) study a collaborative preference-learning problem and show that a variant of uncertainty sampling (a well-known AL strategy) works well for their problem.,2 Related Work,[0],[0]
"In this work, we assume that we do not have access to item features and that comparison outcomes follow a single BT model.
",2 Related Work,[0],[0]
Bayesian methods.,2 Related Work,[0],[0]
"From a practical standpoint, Bayesian methods provide an effective way to select informative samples (MacKay, 1992).",2 Related Work,[0],[0]
"However, they can be difficult to scale if the number of items is large.",2 Related Work,[0],[0]
"Work on Bayesian active preference learning includes Chu & Ghahramani (2005), Houlsby et al. (2012), Salimans et al. (2012) and Chen et al. (2013).",2 Related Work,[0],[0]
"We compare our AL strategy to these methods in Section 4.
",2 Related Work,[0],[0]
Multi-armed bandit.,2 Related Work,[0],[0]
"The dueling bandit problem (Yue et al., 2009) is somewhat related to our work.",2 Related Work,[0],[0]
"In this problem, the goal is to identify the best item based on noisy comparison outcomes, using as few adaptively chosen samples as possible.",2 Related Work,[0],[0]
Two recent papers also extend the problem to that of recovering the entire ranking (instead of only the top element).,2 Related Work,[0],[0]
"The work of Szörényi et al. (2015) is the closest to ours, as it also uses the BT model.",2 Related Work,[0],[0]
"One of their results is similar to our Theorem 2: They show that a quasi-linear number of comparisons is sufficient to recover the true ranking, under some conditions on θ.",2 Related Work,[0],[0]
Heckel et al. (2016) investigate a non-parametric model and develop some theoretical guarantees.,2 Related Work,[0],[0]
"In contrast to these works, our paper studies practical
Algorithm 1 Quicksort
Require: set of items V 1: if |V | < 2 then return list(V ) ⊲",2 Related Work,[0],[0]
Terminating case.,2 Related Work,[0],[0]
"2: L← ∅, R← ∅ 3: p← element of V selected uniformly at random 4: for i ∈ V \ {p} do 5: if i ≺ p then ⊲",2 Related Work,[0],[0]
Pairwise comparison.,2 Related Work,[0],[0]
"6: L← L ∪ {i} 7: else
8: R← R ∪ {i}
9: return Quicksort(L) · p · Quicksort(R)
comparison budgets: we give theoretical guarantees for the output obtained from a single call to Quicksort, and in our experiments we never exceed ≈ 10 calls.
",2 Related Work,[0],[0]
Quicksort.,2 Related Work,[0],[0]
"The Quicksort algorithm (Hoare, 1962) is one of the most widely studied sorting procedures.",2 Related Work,[0],[0]
Quicksort has been shown to produce useful rankings beyond classic sorting problems.,2 Related Work,[0],[0]
"For example, Ailon et al. (2008) show that Quicksort produces (in expectation) a 3-approximation to the MFAST problem.",2 Related Work,[0],[0]
"Quicksort combined with BT comparison outcomes has also been proposed as a probabilistic ranking model (Ailon, 2008).",2 Related Work,[0],[0]
We take advantage of some of the properties of this ranking model in order to derive the theoretical results of Section 3.,2 Related Work,[0],[0]
"In this section, we begin by studying the behavior and output of Quicksort under inconsistent comparison outcomes, without any assumptions on the noise generating process.",3 Theoretical Results,[0],[0]
"Then, starting in Section 3.1, we focus on comparison outcomes generated by the BT model.",3 Theoretical Results,[0],[0]
"Due to limited space, most full proofs are deferred to the supplementary material (Section A).
",3 Theoretical Results,[0],[0]
Quicksort (Algorithm 1) is best described as a recursive procedure.,3 Theoretical Results,[0],[0]
"At each step of the recursion, a pivot item p is chosen uniformly at random (line 3).",3 Theoretical Results,[0],[0]
"Then, during the partition operation (lines 4–8), every other item is compared to p and added to the set L or R, depending on the outcome.",3 Theoretical Results,[0],[0]
"If all comparison outcomes are consistent, it is well-known that Quicksort terminates after sampling O(n log n) comparisons with high probability.",3 Theoretical Results,[0],[0]
What happens if we drop the consistency assumption?,3 Theoretical Results,[0],[0]
"The following two lemmas state that these key properties remain valid, no matter which (and how many) comparison outcomes are inconsistent.
",3 Theoretical Results,[0],[0]
Lemma 1.,3 Theoretical Results,[0],[0]
"Quicksort always terminates and samples each of the n(n−1)/2 possible comparisons at most once.
",3 Theoretical Results,[0],[0]
Proof.,3 Theoretical Results,[0],[0]
The proof is identical to the consistent setting.,3 Theoretical Results,[0],[0]
"Consider the state of L and R at the end of a partition operation.
",3 Theoretical Results,[0],[0]
"Because |L|+ |R| = |V |−1, the recursive calls are made on sets of items of strictly decreasing cardinality, and the algorithm terminates after a finite number of steps.",3 Theoretical Results,[0],[0]
"Furthermore, suppose that Quicksort samples an outcome for the pair (i, j).",3 Theoretical Results,[0],[0]
Then either i or j is the pivot in a partition operation.,3 Theoretical Results,[0],[0]
"In either case, the pivot is not included in the recursive calls, which ensures that (i, j) cannot be compared again.
",3 Theoretical Results,[0],[0]
Lemma 2.,3 Theoretical Results,[0],[0]
"Quicksort samples O(n log n) comparisons w.h.p.
",3 Theoretical Results,[0],[0]
Proof (sketch).,3 Theoretical Results,[0],[0]
"We follow a standard analysis of Quicksort (see, e.g., Dubhashi & Panconesi, 2009, Section 3.3.3).",3 Theoretical Results,[0],[0]
"With high probability, we choose a “good” pivot (i.e., one that results in a balanced partition) a constant fraction of the time.",3 Theoretical Results,[0],[0]
"In this case, the depth of the call tree is O(log n).",3 Theoretical Results,[0],[0]
"As there are at most n comparisons at each level of the call tree, we conclude that Quicksort uses O(n log n) comparisons in total.",3 Theoretical Results,[0],[0]
"With respect to the standard proof, we need some additional work to formalize the notion of “good” pivot to the setting where comparison outcomes are not consistent with a linear order.
",3 Theoretical Results,[0],[0]
"Lemma 2 complements Theorem 3 in Ailon & Mohri (2010), which states that Quicksort samples O(n log n) in expectation.",3 Theoretical Results,[0],[0]
These results might suggest that all properties of Quicksort carry over to the noisy setting.,3 Theoretical Results,[0],[0]
This is not the case.,3 Theoretical Results,[0],[0]
"For example, although Quicksort uses approximately 2n lnn comparisons on average in the noiseless setting (Sedgewick & Wayne, 2011), this number can be distinctly different with inconsistent comparison outcomes3.
Quicksort (and efficient sorting algorithms in general) infer most pairs of items’ relative position by transitivity and thus rely heavily on the consistency of comparison outcomes.",3 Theoretical Results,[0],[0]
"In the noisy case, it is therefore important to precisely understand the effect of an inconsistent outcome on the output of the algorithm; this effect extends beyond the pair of items whose comparison outcome was inconsistent.",3 Theoretical Results,[0],[0]
"For this purpose, the next Lemma bounds the displacement of Quicksort’s output as a function of the inconsistent outcomes.
",3 Theoretical Results,[0],[0]
Lemma 3.,3 Theoretical Results,[0],[0]
Let E be the set of pairs sampled by Quicksort and whose outcome is inconsistent with id. Let σ be the output.,3 Theoretical Results,[0],[0]
"Then,
∆(σ) ≤ 2 ∑
(i,j)∈E
|i− j|
Proof (sketch).",3 Theoretical Results,[0],[0]
"Consider the first partition operation, with pivot p, resulting in partitions L and R. Denote the errors
3E.g., if comparison outcomes are uniformly random, all items are “good” pivots w.h.p., and the average number of comparisons will be closer to n log
2 n on average, for large n.
made during this partition operation by E1.",3 Theoretical Results,[0],[0]
"We can show that the displacement is bounded by
∆(σ) ≤ ∆L(σ) + ∆R(σ) + 2 ∑
(i,j)∈E1
|i− j|,
where ∆L(σ) and ∆R(σ) represent the displacement of the ordering induced by σ on L and R, respectively.",3 Theoretical Results,[0],[0]
"In other words, the total displacement can be decomposed into a term that represents the “local” displacement due to the partition operation and into two terms that account for errors in the recursive calls.",3 Theoretical Results,[0],[0]
"We obtain the desired result by recursively bounding ∆L(σ) and ∆R(σ).
",3 Theoretical Results,[0],[0]
"Informally, Lemma 3 states that the displacement can be bounded by a sum of “local shifts” due to the inconsistent outcomes and that the price to pay for any information inferred by transitivity is bounded by a factor two.",3 Theoretical Results,[0],[0]
"Lemma 3 is a crucial component of our subsequent analysis of BT noise, and we believe that it can be useful in order to investigate Quicksort under a wide variety of other noise generating processes.",3 Theoretical Results,[0],[0]
"From here on, we assume that comparison outcomes are generated from BT(θ).",3.1 Displacement in the Poisson Model,[0],[0]
"Clearly, any results on the displacement of a ranking estimated from samples of a BT model will depend on θ; it is easy to construct a model instance for which it is arbitrarily hard to recover the ranking, by choosing parameters sufficiently close to each other.",3.1 Displacement in the Poisson Model,[0],[0]
Our approach is as follows.,3.1 Displacement in the Poisson Model,[0],[0]
"We postulate a family of distributions over θ, and we give bounds on the displacement that hold with high probability.
",3.1 Displacement in the Poisson Model,[0],[0]
"We suppose that comparison outcomes are (in expectation) uniformly noisy across the ranking: i.e., comparing two elements at the bottom is (a priori) as difficult as comparing two elements at the top or in the middle.",3.1 Displacement in the Poisson Model,[0],[0]
"This means that the probability distribution over parameters θ1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", θn results in (random) distances |θi+k−θi| that depend only on k. One such distribution arises if the parameters are drawn from a Poisson point process of rate λ.",3.1 Displacement in the Poisson Model,[0],[0]
"That is,
i.i.d.",3.1 Displacement in the Poisson Model,[0],[0]
"x1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", xn−1 ∼ Exp(λ), θi =
i−1 ∑
k=1
xk.",3.1 Displacement in the Poisson Model,[0],[0]
"(1)
The average distance between two items separated by k positions in the ordering is E",3.1 Displacement in the Poisson Model,[0],[0]
[θi+k,3.1 Displacement in the Poisson Model,[0],[0]
− θi] = k/λ.,3.1 Displacement in the Poisson Model,[0],[0]
"Although the distance between adjacent items is constant in expectation, we allow some parameters to be arbitrarily close4.",3.1 Displacement in the Poisson Model,[0],[0]
"The parameter λ controls the expected level of noise; a large λ is
4 In particular, the expected minimum distance between two items (i.e., the min of n exponential r.v.s) decreases as (nλ)−1 as n increases.
likely to result in a larger number of inconsistent outcomes.",3.1 Displacement in the Poisson Model,[0],[0]
"Although the precise choice of this Poisson model is driven by tractability concerns, in Section 3.2 we argue that it is essentially equivalent to choosing the parameters independently and uniformly at random in the interval",3.1 Displacement in the Poisson Model,[0],[0]
"[0, (n+1)/λ], when λ is fixed and n is large.",3.1 Displacement in the Poisson Model,[0],[0]
"We are now ready to state our main result.
",3.1 Displacement in the Poisson Model,[0],[0]
Theorem 1.,3.1 Displacement in the Poisson Model,[0],[0]
Let θ be sampled from a Poisson point process of rate λ.,3.1 Displacement in the Poisson Model,[0],[0]
Let σ be the output of Quicksort using comparison outcomes sampled from BT(θ).,3.1 Displacement in the Poisson Model,[0],[0]
"Then, w.h.p.,
∆(σ) = O(λ2n), (2)
max i |σ(i)− i| = O(λ log n).",3.1 Displacement in the Poisson Model,[0],[0]
"(3)
Proof (sketch).",3.1 Displacement in the Poisson Model,[0],[0]
"Let zij be the indicator random variable of the event “the comparison between i and j results in an error”, and let dij = |θi",3.1 Displacement in the Poisson Model,[0],[0]
− θj |.,3.1 Displacement in the Poisson Model,[0],[0]
"The distance dij is a sum of |i − j| exponential random variables, i.e., dij ∼ Gamma(|i− j|, λ), and we can show that
E",3.1 Displacement in the Poisson Model,[0],[0]
"[zij ] = E
[
1
1 + exp(dij)
]
≤ E",3.1 Displacement in the Poisson Model,[0],[0]
[exp(−dij)],3.1 Displacement in the Poisson Model,[0],[0]
"= (1 + 1/λ) −|i−j|.
Using Lemma 3 and the fact that every pair of items is compared at most once, we find
E [∆] ≤ 2 ∑
i<j
|i−",3.1 Displacement in the Poisson Model,[0],[0]
j|E,3.1 Displacement in the Poisson Model,[0],[0]
"[zij ]
≤ 2n
∞ ∑
k=0
k(1 + 1/λ)−k = 2nλ(λ+ 1).
",3.1 Displacement in the Poisson Model,[0],[0]
"The random variables {zij} are not unconditionally independent (they are independent when conditioned on θ) but, with some more work, we can show that Var [∆] = O(n).",3.1 Displacement in the Poisson Model,[0],[0]
"By using a Chebyshev bound, (2) follows.
",3.1 Displacement in the Poisson Model,[0],[0]
"In order to prove (3), we take advantage of a theorem due to Ailon (2008) which states that
P",3.1 Displacement in the Poisson Model,[0],[0]
[σ(i) < σ(j),3.1 Displacement in the Poisson Model,[0],[0]
"| θ] = p(i ≺ j | θ),
even if i and j were not directly compared with each other.",3.1 Displacement in the Poisson Model,[0],[0]
We use a Chernoff bound on dij to show that the relative order between any two items separated by at least O(λ log n) positions is correct with high probability.,3.1 Displacement in the Poisson Model,[0],[0]
"The second part of the claim follows easily.
",3.1 Displacement in the Poisson Model,[0],[0]
"Note that any method that compares each pair of items at most once results in a ranking estimate τ with displacement ∆(τ) = Ω(n) with high probability: As there is only a single (possibly inconsistent) comparison outcome between each pair of adjacent items, it is likely that a constant fraction of the items will be ranked incorrectly, resulting in a
Algorithm 2 Multisort
Require: set of items V , number of iterations m",3.1 Displacement in the Poisson Model,[0],[0]
"1: S ← ∅ 2: for k = 1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
",m do 3: σ ← Quicksort(V ) 4: S ← S ∪ {σ}
5: return Copeland aggregation of S
displacement that grows linearly in n. Hence, our bound on ∆(σ) shows that Quicksort is order-optimal (in n).
",3.1 Displacement in the Poisson Model,[0],[0]
"In light of Theorem 1, a natural question to ask is as follows.",3.1 Displacement in the Poisson Model,[0],[0]
How many comparisons are needed in order to find the correct ranking?,3.1 Displacement in the Poisson Model,[0],[0]
"Clearly, finding the exact ranking is difficult: in fact, Ω(n) comparison outcomes are necessary to discriminate the closest pair of items reliably (see supplementary material, Section B).",3.1 Displacement in the Poisson Model,[0],[0]
"As such, we will focus on finding a ranking that matches the ground truth everywhere, except at a vanishing fraction of the items.
",3.1 Displacement in the Poisson Model,[0],[0]
"Multiple runs of Quicksort likely produce different outputs, because of the noisy comparison outcomes and because the algorithm itself is randomized (the pivot selection is random).",3.1 Displacement in the Poisson Model,[0],[0]
"By aggregating m independent outputs of Quicksort, is it possible to produce a better ranking estimate?",3.1 Displacement in the Poisson Model,[0],[0]
"Similarly to Szörényi et al. (2015), we combine the m outputs σ1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", σm into an aggregate ranking σ̂ using Copeland’s method.",3.1 Displacement in the Poisson Model,[0],[0]
"The method assigns, to each item, a score that corresponds to the number of items that it beats in a majority of the rankings, and it then ranks the items by increasing score (Copeland, 1951).",3.1 Displacement in the Poisson Model,[0],[0]
"We call the procedure Multisort and describe it in Algorithm 2.
Theorem 2.",3.1 Displacement in the Poisson Model,[0],[0]
Let θ be sampled from a Poisson point process of rate λ.,3.1 Displacement in the Poisson Model,[0],[0]
Let σ̂ be the output of Multisort using m = O(λ2 log5 n) and comparison outcomes sampled from BT(θ).,3.1 Displacement in the Poisson Model,[0],[0]
"Then, w.h.p.,
∆(σ̂) = o(λn).
",3.1 Displacement in the Poisson Model,[0],[0]
Proof (sketch).,3.1 Displacement in the Poisson Model,[0],[0]
"We use results on the order statistics of the distances x1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", xn−1 between successive items, as defined in (1), to partition the items into two disjoint subsets B and G. The set B contains a vanishing (1/ log2 n)-fraction of “bad” items that are difficult to order.",3.1 Displacement in the Poisson Model,[0],[0]
The set G is such that the smallest distance dij from any item,3.1 Displacement in the Poisson Model,[0],[0]
i ∈ G to any other item j ∈,3.1 Displacement in the Poisson Model,[0],[0]
[n] is bounded from below by c/(λ log2 n).,3.1 Displacement in the Poisson Model,[0],[0]
"We can show that with m = O(λ2 log5 n), for any i ∈ G and j ∈",3.1 Displacement in the Poisson Model,[0],[0]
[n] we have i < j ⇐⇒ σ(i) < σ(j) in a majority of the Quicksort outputs (with high probability).,3.1 Displacement in the Poisson Model,[0],[0]
This implies that σ̂(i),3.1 Displacement in the Poisson Model,[0],[0]
= i for all i ∈ G with high probability.,3.1 Displacement in the Poisson Model,[0],[0]
"Using (3) for items in B, we have
∆(σ̂) = |B| ·O(λ log n) = O(λn/ log n)
with high probability.
",3.1 Displacement in the Poisson Model,[0],[0]
Theorem 2 states that all but a vanishing fraction of items are correctly ranked using O(λ2n log6 n) comparisons.,3.1 Displacement in the Poisson Model,[0],[0]
"This result should be compared to the Ω(n2) comparisons needed if samples are selected uniformly at random.
",3.1 Displacement in the Poisson Model,[0],[0]
Empirical validation.,3.1 Displacement in the Poisson Model,[0],[0]
"In Figure 1, we illustrate the results of Theorems 1 and 2 by running simulations for increasing n and different values of λ.",3.1 Displacement in the Poisson Model,[0],[0]
"The bound on ∆(σ) is tight in n, but the dependence on λ appears to be linear rather than quadratic.",3.1 Displacement in the Poisson Model,[0],[0]
The bound on maxi|σ(i)− i| appears to be tight in n and λ.,3.1 Displacement in the Poisson Model,[0],[0]
"Finally, we compare the Copeland aggregation of m outputs of Quicksort with the ranking induced by the maximum-likelihood (ML) estimate, inferred from the outcomes of all the pairwise comparisons sampled by the m runs.",3.1 Displacement in the Poisson Model,[0],[0]
"Although the ranking induced by the ML estimate does not benefit from the guarantees of Theorem 2, it performs better in practice.",3.1 Displacement in the Poisson Model,[0],[0]
We will make use of this observation in Section 4.,3.1 Displacement in the Poisson Model,[0],[0]
A different (perhaps more natural) assumption on the parameters θ is to consider that they are drawn independently and uniformly at random over some interval.,3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"That is,
i.i.d. θ̄1, . . .",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
", θ̄n ∼ U(0, (n+ 1)/λ),
with θ1, . . .",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
", θn the order statistics of θ̄, i.e., the random variables arranged in increasing order.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"From some elementary results on the joint distribution of order statistics (see, e.g., Arnold et al., 2008), we see that
|θi+k",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"− θi| ∼ (n+ 1)/λ · Beta(k, n− k + 1),
i.e., a Beta random variable rescaled between 0 and (n + 1)/λ.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"Letting fk,n(x) be the probability density of |θi+k",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"− θi|, we have, for any fixed k and λ,
fk,n(x) ∝",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"x k−1
[
1− λx
n+ 1
]n−k n→∞ −−−−→ xk−1e−λx.
",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"We recognize the functional form of the density of a Gamma(k, λ) distribution.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"Hence, the Poisson model and the i.i.d. uniform model are essentially equivalent for fixed λ and large n, and we can expect the results developed in Section 3.1 to hold under this distribution as well.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"In practice, the comparison budget for estimating a ranking from noisy data might typically be larger than that for a single call to Quicksort, and it might not exactly match the number of comparisons required to run a given number of calls to Quicksort to completion.",4 Experimental Results,[0],[0]
"Building upon the observations made at the end of Section 3.1, we suggest the following practical active-learning strategy: for a budget of
c pairwise comparisons, run the sorting procedure repeatedly until the budget is depleted (the last call might have to be truncated).",4 Experimental Results,[0],[0]
"Then, retain only the set of c comparison pairs and their outcomes and discard the rankings produced by the sorting procedure.",4 Experimental Results,[0],[0]
"The final ranking estimate is then induced from the ML estimate over the set of c comparison outcomes.
",4 Experimental Results,[0],[0]
"In this section, we demonstrate the effectiveness of this sampling strategy on synthetic and real-world data.",4 Experimental Results,[0],[0]
"In particular, we show that it is comparable to existing AL strategies at a minuscule fraction of the computational cost.",4 Experimental Results,[0],[0]
"To assess the relative merits of our sorting-based strategy, we consider three strategies that we believe are representative of the state of the art in active preference learning.
",4.1 Competing Sampling Strategies,[0],[0]
Uncertainty sampling.,4.1 Competing Sampling Strategies,[0],[0]
"Developed in the context of classification tasks, this popular active-learning heuristic suggests to greedily sample the point that lies closest to the decision boundary (Settles, 2012).",4.1 Competing Sampling Strategies,[0],[0]
"In the context of a ranking task, this corresponds to sampling the pair of items whose relative order is most uncertain.",4.1 Competing Sampling Strategies,[0],[0]
"After t observations, given an estimate of model parameters θt, the strategy selects the (t+1)-st pair uniformly at random in
argmin i 6=j
|θti − θ t j |.
",4.1 Competing Sampling Strategies,[0],[0]
This set can be computed in time O(n log n) by sorting the parameters.,4.1 Competing Sampling Strategies,[0],[0]
"The parameters themselves need to be estimated, e.g., using (penalized) ML inference that in practice can be the dominating cost.
",4.1 Competing Sampling Strategies,[0],[0]
Bayesian methods.,4.1 Competing Sampling Strategies,[0],[0]
"If we have access to a full posterior distribution qt(θ) instead of a point estimate θt, we can take advantage of the extra information on the uncertainty of the parameters to improve the selection strategy.",4.1 Competing Sampling Strategies,[0],[0]
"A principled approach to AL consists of sampling the point that
maximizes the expected information gain (MacKay, 1992).",4.1 Competing Sampling Strategies,[0],[0]
"That is, the pair of items at iteration t+ 1 is selected in
argmax i 6=j
H(qt)−E",4.1 Competing Sampling Strategies,[0],[0]
"[ H(qt+1) ] , (4)
where H(·) denotes the entropy function.",4.1 Competing Sampling Strategies,[0],[0]
A conceptually similar but slightly different selection strategy is given by Chen et al. (2013).,4.1 Competing Sampling Strategies,[0],[0]
"Letting qij be the marginal distribution of (θi, θj), the pair is selected in
argmax i 6=j
E",4.1 Competing Sampling Strategies,[0],[0]
"[ KL(qt+1ij ‖q t ij) ] , (5)
where KL(·) denotes the Kullback–Leibler divergence.",4.1 Competing Sampling Strategies,[0],[0]
"Computing the exact posterior is not analytically tractable for the BT model, but a Gaussian approximation can be found in time O(n3).",4.1 Competing Sampling Strategies,[0],[0]
Criteria (4) and (5) can be computed in constant time for each pair of items.,4.1 Competing Sampling Strategies,[0],[0]
"The dominating cost is again that of estimating θ (or, in this case, q(θ)).
",4.1 Competing Sampling Strategies,[0],[0]
"In addition to these existing AL strategies, we also include in our experiments a variation of our sorting-based strategy that uses Mergesort instead of Quicksort.",4.1 Competing Sampling Strategies,[0],[0]
"In the noiseless setting, Mergesort is known to use on average≈ 39 % fewer comparisons than Quicksort per run (Knuth, 1998), but it does not benefit from the theoretical guarantees developed in Section 3.",4.1 Competing Sampling Strategies,[0],[0]
"In this section, we briefly discuss the running time of the methods.",4.2 Running Time,[0],[0]
We implement ML and Bayesian approximate inference algorithms for the BT model as a Python library5.,4.2 Running Time,[0],[0]
"For ML inference, we find that the fastest running time is achieved by a truncated Newton algorithm (even for large n).",4.2 Running Time,[0],[0]
"For approximate Bayesian inference, we use a variant of the expectation-propagation algorithm outlined by Chu & Ghahramani (2005).",4.2 Running Time,[0],[0]
"All experiments are performed on
5See: http://lucas.maystre.ch/choix.
a server with a 12-core Xeon X5670 processor running at 2.93 GHz.",4.2 Running Time,[0],[0]
"Numerical computations take advantage of the Intel Math Kernel Library.
",4.2 Running Time,[0],[0]
We illustrate the running time of AL strategies as follows.,4.2 Running Time,[0],[0]
"For n ∈ {102, 103, 104}, we generate outcomes for n comparisons pairs chosen uniformly at random among n items.",4.2 Running Time,[0],[0]
"For each strategy, we then measure the time it takes to select the (n+1)-st pair of items adaptively.",4.2 Running Time,[0],[0]
The results are presented in Table 1.,4.2 Running Time,[0],[0]
"Note that these numbers are intended to be considered as orders of magnitude, rather than exact values, as they depend on the particular combination of software and hardware that we use.",4.2 Running Time,[0],[0]
The running time of the Bayesian AL strategies exceed 10 hours for n = 104 and the calls were stopped ahead of completion.,4.2 Running Time,[0],[0]
"Our sorting-based methods, like random sampling, are the only AL strategies whose running time is constant for increasing n",4.2 Running Time,[0],[0]
(and for increasing c).,4.2 Running Time,[0],[0]
"In fact, their running time is negligible in comparison to the other strategies, including uncertainty sampling.",4.2 Running Time,[0],[0]
"We now investigate three datasets and measure the displacement of rankings estimated from adaptively-chosen samples, as a function of the budget c. Note that in order to use uncertainty sampling and Bayesian methods, it is necessary to choose a regularization strength or prior variance in the inference step.",4.3 Empirical Evaluation,[0],[0]
"Different values can result in drastically different outcomes (in particular for uncertainty sampling) and, in practice, choosing a good value can be a significant challenge6.",4.3 Empirical Evaluation,[0],[0]
"In the following, we report results for the values that worked best a posteriori.
",4.3 Empirical Evaluation,[0],[0]
Synthetic dataset.,4.3 Empirical Evaluation,[0],[0]
We generate n i.i.d.,4.3 Empirical Evaluation,[0],[0]
"parameters θ1, . .",4.3 Empirical Evaluation,[0],[0]
.,4.3 Empirical Evaluation,[0],[0]
", θn uniformly in [0, (n + 1)/λ] and draw samples from BT(θ).",4.3 Empirical Evaluation,[0],[0]
The ground-truth ranking is the one induced by the parameters.,4.3 Empirical Evaluation,[0],[0]
Figure 2 presents results for n = 200 and λ,4.3 Empirical Evaluation,[0],[0]
"= 5 (plots for different values of λ are presented in the supplementary material, Section C, and are qualitatively
6Observe that our sorting-based approach is entirely parameterfree and is therefore not affected by this issue.
similar).",4.3 Empirical Evaluation,[0],[0]
"In comparison to random sampling, AL is very effective and results in significantly better ranking estimates for any given number of comparisons.",4.3 Empirical Evaluation,[0],[0]
"The two Bayesian methods, though being the most computationally expensive, perform the best for all values of c, but are nearly indistinguishable from uncertainty sampling.",4.3 Empirical Evaluation,[0],[0]
The two sorting-based strategies perform similarly (with a small edge for Mergesort).,4.3 Empirical Evaluation,[0],[0]
"They are slightly worse than the Bayesian methods but are still able to reap most of the benefits of active learning.
",4.3 Empirical Evaluation,[0],[0]
Sushi dataset.,4.3 Empirical Evaluation,[0],[0]
"Next, we consider a dataset of Sushi preferences (Kamishima & Akaho, 2009).",4.3 Empirical Evaluation,[0],[0]
"In this dataset, 5000 respondents give a strict ordering over 10 different types of sushi.",4.3 Empirical Evaluation,[0],[0]
These 10 sushi are chosen among a larger set of n = 100 items.,4.3 Empirical Evaluation,[0],[0]
"To suit our purposes, we decompose each 10-way partial ranking into pairwise comparisons, resulting in 225 000 comparison outcomes.",4.3 Empirical Evaluation,[0],[0]
"We use all comparisons to fit a BT model that induces a ground-truth ranking7.
",4.3 Empirical Evaluation,[0],[0]
"The comparisons are dense, and there is at least one comparison outcome for almost all pairs.",4.3 Empirical Evaluation,[0],[0]
"When an outcome for pair (i, j) is requested, we sample uniformly at random over all outcomes observed for this pair.",4.3 Empirical Evaluation,[0],[0]
"In the rare case where no outcome is available, we return i ≺ j with probability 1/2.",4.3 Empirical Evaluation,[0],[0]
"This enables us to compare sampling strategies in a realistic setting, where the assumptions of the BT model do not necessarily hold anymore.
",4.3 Empirical Evaluation,[0],[0]
Results are shown in Figure 3 (left).,4.3 Empirical Evaluation,[0],[0]
"Once again, active learning performs noticeably better than random sampling.",4.3 Empirical Evaluation,[0],[0]
"On this real-world dataset, the performance of our sorting-based strategies is indistinguishable from that of the Bayesian
7 The BT-induced ranking is almost the same as that obtained using the Copeland score.",4.3 Empirical Evaluation,[0],[0]
"The results are very similar if the Copeland aggregation is used as ground truth.
methods, after completing one entire call to the sorting procedure (slightly less than 1000 comparisons).",4.3 Empirical Evaluation,[0],[0]
"This result should be interpreted in light of the time needed to select all 104 pairs: a fraction of a second for sorting-based strategies, and several hours for the Bayesian methods.",4.3 Empirical Evaluation,[0],[0]
"Finally, we observe that the performance of uncertainty sampling progressively degrades as c increases.",4.3 Empirical Evaluation,[0],[0]
"A detailed analysis reveals that uncertainty sampling increasingly focuses on a small set of hard-to-discriminate pairs, symptomatic of a well-known issue (Settles, 2012).
GIFGIF dataset.",4.3 Empirical Evaluation,[0],[0]
GIFGIF8 is a project of the MIT Media Lab that aims at explaining the emotions communicated by a collection of animated GIF images.,4.3 Empirical Evaluation,[0],[0]
"Users of the website are shown a prompt with two images and a question, “Which better expresses x?” where x is one of 17 emotions.",4.3 Empirical Evaluation,[0],[0]
"The users can click on either image, or use a third option, neither.",4.3 Empirical Evaluation,[0],[0]
"To date, over three million comparison outcomes have been collected.",4.3 Empirical Evaluation,[0],[0]
"For the purpose of our experiment, we restrict ourselves to a single emotion, happiness; and we ignore outcomes that resulted in neither.",4.3 Empirical Evaluation,[0],[0]
"We consider 106 887 comparison outcomes over n = 6120 items—a significant increase in scale compared to the Sushi dataset.
",4.3 Empirical Evaluation,[0],[0]
"As the data, despite a relatively large number of comparisons, remains sparse (less than 20 comparisons per item on average), we proceed as follows.",4.3 Empirical Evaluation,[0],[0]
We fit a BT model by using all the available comparisons and use the induced ranking as ground truth.,4.3 Empirical Evaluation,[0],[0]
"We then generate new, synthetic comparison outcomes from the BT model.",4.3 Empirical Evaluation,[0],[0]
"In this sense, the experiment enables us to compare sampling strategies by using a large BT model with realistic parameters.",4.3 Empirical Evaluation,[0],[0]
"The large number of items makes uncertainty sampling and the two Bayesian
8See http://www.gif.gf/.",4.3 Empirical Evaluation,[0],[0]
"Data available at http:// lucas.maystre.ch/gifgif-data.
methods prohibitively expensive.",4.3 Empirical Evaluation,[0],[0]
"We try a simplified, computationally less expensive version of uncertainty sampling where, at every iteration, each item is compared to its two closest neighbors, but this heuristic fails spectacularly: The resulting displacement is over 5× larger than random sampling for c = 106, and is therefore not reported here (see supplementary material, Section C).
",4.3 Empirical Evaluation,[0],[0]
Figure 3 (right) compares the displacement of random sampling to that of the two sorting-based sampling strategies for increasing c.,4.3 Empirical Evaluation,[0],[0]
The adaptive sampling approaches perform systematically better.,4.3 Empirical Evaluation,[0],[0]
"After 106 comparisons, the displacement of random sampling is 14 % and 23 % larger than that of Quicksort and Mergesort, respectively.",4.3 Empirical Evaluation,[0],[0]
"Conversely, in order to reach any target displacement, Mergesort requires approximately 2× fewer comparisons than random sampling.",4.3 Empirical Evaluation,[0],[0]
"In this work, we demonstrate that active learning can substantively speed up the task of learning a ranking from noisy comparisons gains—both in theory and in practice.",5 Conclusion,[0],[0]
"With the advent of large-scale crowdsourced ranking surveys, exemplified by GIFGIF and wiki surveys (Salganik & Levy, 2015), there is a clear need for practical AL strategies.",5 Conclusion,[0],[0]
"However, existing methods are complex and computationally expensive to operate even for a reasonable number of items (a few thousands).",5 Conclusion,[0],[0]
"We show that a deceptively simple idea—repeatedly sorting the items—is able to bring in all the benefits of active learning, is trivial to implement, and is computationally no more expensive that random sampling.",5 Conclusion,[0],[0]
"Therefore, we believe that our method can be broadly useful for machine-learning practitioners interested in ranking problems.",5 Conclusion,[0],[0]
"We thank Holly Cogliati-Bauereis, Ksenia Konyushkova, Brunella Spinelli and the anonymous reviewers for careful proofreading and helpful comments.",Acknowledgments,[0],[0]
We address the problem of learning a ranking by using adaptively chosen pairwise comparisons.,abstractText,[0],[0]
Our goal is to recover the ranking accurately but to sample the comparisons sparingly.,abstractText,[0],[0]
"If all comparison outcomes are consistent with the ranking, the optimal solution is to use an efficient sorting algorithm, such as Quicksort.",abstractText,[0],[0]
But how do sorting algorithms behave if some comparison outcomes are inconsistent with the ranking?,abstractText,[0],[0]
"We give favorable guarantees for Quicksort for the popular Bradley–Terry model, under natural assumptions on the parameters.",abstractText,[0],[0]
"Furthermore, we empirically demonstrate that sorting algorithms lead to a very simple and effective active learning strategy: repeatedly sort the items.",abstractText,[0],[0]
This strategy performs as well as state-of-the-art methods (and much better than random sampling) at a minuscule fraction of the computational cost.,abstractText,[0],[0]
Just Sort It! A Simple and Effective Approach to Active Preference Learning,title,[0],[0]
K-means clustering is a classical clustering problems and has been studied for several decades.,1. Introduction,[0],[0]
The goal of K-Means clustering is to find a set of k cluster centers for a dataset such that the sum of squared distances of each point to its closest cluster center is minimized.,1. Introduction,[0],[0]
"While it is known that k-means clustering is an NP hard optimization problem even for k = 2 (Dasgupta, 2008), in practice a local search heuristic due to Lloyd (Lloyd, 1982) is widely used for solving K-means clustering problem.",1. Introduction,[0],[0]
"Lloyd’s iterative
1Department of Electrical Engineering & Computer Science, Wichita State University, KS, USA.",1. Introduction,[0],[0]
"Correspondence to: Kaushik Sinha <kaushik.sinha@wichita.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
algorithm begins with k arbitrary “cluster centers”, and in each iteration, each point is assigned to the nearest cluster center, and each cluster center is recomputed as the center of mass of all points assigned to it.",1. Introduction,[0],[0]
These last two steps are repeated until the process stabilizes.,1. Introduction,[0],[0]
"Lloyd’s algorithm for k-means clustering is known to be one of the top ten data mining tools of the last fifty years (Wu, 2008).
",1. Introduction,[0],[0]
"K-means clustering is typically performed on a data matrix A ∈ Rn×d, consisting of n data points each having d attributes/features and per iteration computational cost of Lloyd’s algorithm is O(nkd).",1. Introduction,[0],[0]
In recent years there has been a series of work towards reducing this computational cost and speeding up k-means clustering computation.,1. Introduction,[0],[0]
Most of these works can broadly be classified into three categories.,1. Introduction,[0],[0]
"In the first category, K-means clustering algorithm is accelerated by avoiding unnecessary distance calculations by applying various forms of triangular inequality and by keeping track of lower and upper bounds for distances between points and cluster centers (Elkan, 2003; Hamerly, 2010; Drake & Hamerly, 2012; Ding et al., 2015; Newling & Fleuret, 2016; Bottesch et al., 2016).",1. Introduction,[0],[0]
All these algorithms ensure the exact same clustering result that would have been obtained had one applied Lloyd’s heuristic from the same set of initial cluster centers without applying any distance inequality bounds.,1. Introduction,[0],[0]
"In the second category, various dimension reduction techniques are applied to data matrix A to reduce data dimensionality from d to d′ (d′ d), where d′ is independent of n and d, so that optimal k-means clustering solution of dimensionality reduced dataset A′ ∈",1. Introduction,[0],[0]
"Rn×d′ ensures an approximately optimal k-means clustering objective function of A. Most prominent among these is the random projection based dimensionality reduction technique that reduces data dimensionality from d to Ω(k/ 2) resulting in (1 + ) approximation of the optimal k-means objective function (Boutsidis et al., 2010; 2015; Cohen et al., 2015) and also from d to O(log(k)/ 2) resulting in (9 + ) approximation of the optimal k-means objective function (Cohen et al., 2015).",1. Introduction,[0],[0]
"Recently, (Liu et al., 2017) demonstrated the the random projection step can be performed by multiplying with a sparse matrix that yields the same (1 + ) approximation guarantee.",1. Introduction,[0],[0]
"Additionally, random feature selection method reduces data dimensionality from d to Ω(k log k/ 2) resulting in (1 + ) approximation of the optimal k-means objective function (Boutsidis et al.,
2015; Cohen et al., 2015).",1. Introduction,[0],[0]
"In the third category, a smaller subset of n data points called coresets, are constructed so that optimal weighted k-means clustering objective function performed on this coreset is (1 + ) approximation of the optimal k-means objective function performed on the original dataset (Feldman & Langberg, 2011; Feldman et al., 2013).",1. Introduction,[0],[0]
"In k-means clustering using Lloyd’s heuristic, a major computational bottleneck arises from Euclidean distance computation between each data point and k cluster centers in every iteration.",1. Introduction,[0],[0]
"For a data point a ∈ Rd and a cluster center µ ∈ Rd, the Euclidean distance can be represented as, ‖a",1. Introduction,[0],[0]
− µ‖2 = ‖a‖2 + ‖µ‖2,1. Introduction,[0],[0]
"− 2a>µ. Note that ‖a‖2 needs be computed for each data point only once over all iterations of Lloyd’s heuristics (and can be done off-line), ‖µ‖2 needs be computed once for each cluster center in each iteration, while the dot product needs to be computed for every possible data point, cluster center pair in every single iteration.",1. Introduction,[0],[0]
"In fact, the dot product between a cluster center µ and all n data points can be computed by a simple matrix-vector multiplication:",1. Introduction,[0],[0]
Aµ.,1. Introduction,[0],[0]
"If the data matrix A is significantly sparse (i.e., number of non-zero entries is reasonable small) the above matrix vector multiplication can be performed reasonably fast.",1. Introduction,[0],[0]
"A key question that is not addressed in the literature is, To what extent the data matrix A can be made sparse without significantly affecting optimal k-means clustering objective?",1. Introduction,[0],[0]
"In this paper we show that under mild conditions, we can randomly sparsify data matrix A to obtain a sparse data matrix Ã such that optimal k-means clustering solution of Ã yields an approximately optimal k-means clustering objective of A with high probability.",1. Introduction,[0],[0]
Note that such a sparsification scheme can be extremely useful in practice.,1. Introduction,[0],[0]
"If the original data matrix is reasonably dense, then such sparsification results in fast matrix-vector multiplication, thereby speeding up k-means clustering.",1. Introduction,[0],[0]
"However, it may seem at first that for many real world high dimensional datasets that are very sparse to begin with, such as text datasets represented in “bag of word” format, such sparsification scheme may not be useful.",1. Introduction,[0],[0]
"But, note that instead of directly working with high dimensional data, typically a random projection step is often applied first to reduce data dimensionality since it is known that optimal k-means clustering solution of this randomly projected dataset results in approximately optimal k-means clustering objective of the original high dimensional dataset (Boutsidis et al., 2010; 2015; Cohen et al., 2015; Liu et al., 2017).",1. Introduction,[0],[0]
"Unfortunately, such a random projection step results in a dense projected data matrix.",1. Introduction,[0],[0]
"Interestingly, our sparsification method can now be applied on this projected dense data matrix to reap further computational benefit in addition to the computational benefit already achieved by random projection step (see Figure 1).
",1. Introduction,[0],[0]
"To quantify the approximation factor as well as the level of sparsity of our proposed method, we use ideas from
(Achlioptas & Mcsherry, 2007) which establishes that random matrix sparsification approximately preserves low rank matrix structure with high probability and also ideas from (Cohen et al., 2015) which establishes to what extent an approximately optimal low rank matrix serves as a projection cost preserving sketch.",1. Introduction,[0],[0]
"To the best of our knowledge, this is the first result that quantifies how random matrix sparsification affects k-means clustering.",1. Introduction,[0],[0]
"In particular, we make the following contributions in this paper.
",1. Introduction,[0],[0]
"• We show that for any ∈ (0, 1), a dense data matrix A ∈ Rn×d can be randomly sparsified to yield a data matrix Ã ∈",1. Introduction,[0],[0]
"Rn×d, such that, Ã contains O(nk/ 9 + d log4 n) non-zero entries in expectation, and optimal k-means clustering solution of Ã results in (1 + ) approximation of optimal k-means objective of A with high probability.
",1. Introduction,[0],[0]
"• We show that for any ∈ (0, 1), a dense data matrix A ∈ Rn×d can be randomly sparsified to yield a data matrix Ã ∈",1. Introduction,[0],[0]
"Rn×d, such that, Ã contains O(nk/ 9 + d log4 n) non-zero entries in expectation, and any approximately optimal k-means clustering solution of Ã, having (1 + ) approximation of optimal k-means objective of Ã, results in (1 +O( )) approximation of optimal k-means objective of A with high probability.
",1. Introduction,[0],[0]
"• We present experimental results on three real world datasets to demonstrate effect of our proposed random sparsification scheme on k-means clustering solution.
",1. Introduction,[0],[0]
The rest of the paper is organized as follows.,1. Introduction,[0],[0]
In section 2 we present k-means clustering problem in matrix notation and introduce uniform and non-uniform sampling strategies for random matrix sparsification.,1. Introduction,[0],[0]
We propose an algorithm for k-means clustering using random matrix sparsification in section 3 and present its analysis in section 4.,1. Introduction,[0],[0]
Empirical evaluations are presented in section 5.,1. Introduction,[0],[0]
"Finally, we conclude and point out a few open questions in section 6.",1. Introduction,[0],[0]
We use bold lower case letters to denote vectors and bold upper case letters to denote matrices.,2.1. Notation and linear algebra basics,[0],[0]
"For any n and d, consider a matrix A ∈ Rn×d with rank r = rank(A).",2.1. Notation and linear algebra basics,[0],[0]
"Using singular value decomposition A can be written as A = UΣV>, where U ∈ Rn×r contains r left singular vectors u1,u2, . . .",2.1. Notation and linear algebra basics,[0],[0]
",ur ∈ Rn, V contains r right singular vectors v1,v2, . . .",2.1. Notation and linear algebra basics,[0],[0]
",vr ∈ Rd, and Σ ∈",2.1. Notation and linear algebra basics,[0],[0]
Rr×r is a positive diagonal matrix containing the singular values of A : σ1(A),2.1. Notation and linear algebra basics,[0],[0]
≥ σ2(A),2.1. Notation and linear algebra basics,[0],[0]
≥ · · · ≥ σr(A).,2.1. Notation and linear algebra basics,[0],[0]
A can also be written as A = ∑r i=1,2.1. Notation and linear algebra basics,[0],[0]
σi(A)uiv >,2.1. Notation and linear algebra basics,[0],[0]
i .,2.1. Notation and linear algebra basics,[0],[0]
"For any k ≤ r,
Ak = ∑k i=1",2.1. Notation and linear algebra basics,[0],[0]
σi(A)uiv >,2.1. Notation and linear algebra basics,[0],[0]
"i is the best rank k approximation to A for any unitarily invariant norm, including Frobenious
and spectral norm (Mirsky, 1960).",2.1. Notation and linear algebra basics,[0],[0]
Note that,2.1. Notation and linear algebra basics,[0],[0]
A = Ak + Ar−k,2.1. Notation and linear algebra basics,[0],[0]
where Ar−k =,2.1. Notation and linear algebra basics,[0],[0]
∑r,2.1. Notation and linear algebra basics,[0],[0]
i=k+1 σi(A)uiv >,2.1. Notation and linear algebra basics,[0],[0]
i .,2.1. Notation and linear algebra basics,[0],[0]
"Therefore, Ar−k = A−Ak.",2.1. Notation and linear algebra basics,[0],[0]
"Square Frobenious norm of A is given by ‖A‖2F = ∑ i,jA(i, j) 2 = trace(AA>)",2.1. Notation and linear algebra basics,[0],[0]
= ∑,2.1. Notation and linear algebra basics,[0],[0]
i σ 2,2.1. Notation and linear algebra basics,[0],[0]
i (A).,2.1. Notation and linear algebra basics,[0],[0]
The spectral norm of A is given by ‖A‖2 = σ1(A).,2.1. Notation and linear algebra basics,[0],[0]
Ak satisfies ‖A −Ak‖F =,2.1. Notation and linear algebra basics,[0],[0]
"minB,rank(B)=k ‖A",2.1. Notation and linear algebra basics,[0],[0]
"− B‖F and ‖A−Ak‖2 = minB,rank(B)=k ‖A−B‖2.",2.1. Notation and linear algebra basics,[0],[0]
"The objective of k-means clustering is to partition n data points in Rd, {a1, . . .",2.2. K-means clustering,[0],[0]
",an}, into k non-overlapping clusters C = {C1, . . .",2.2. K-means clustering,[0],[0]
", Ck} such that points that are close to each other belong to the same cluster and points that are far from each other belong to to different clusters.",2.2. K-means clustering,[0],[0]
"Let µi be the centroid of cluster Ci and for any data point ai, let C(ai) be the index of the cluster to which ai is assigned to.",2.2. K-means clustering,[0],[0]
"The goal of k-means clustering is to minimize the objective function
k∑ i=1",2.2. K-means clustering,[0],[0]
∑ aj∈Ci ‖aj −µi‖22,2.2. K-means clustering,[0],[0]
"= n∑ j=1 ‖aj −µC(aj)‖ 2 2 (1)
",2.2. K-means clustering,[0],[0]
"Let A ∈ Rn×d be a data matrix containing the n data points {a1, . . .",2.2. K-means clustering,[0],[0]
",an} as rows and for any clustering C, let XC ∈ Rn×k be the cluster indicator matrix, with XC(i, j) = 1/ √",2.2. K-means clustering,[0],[0]
"|Cj | if ai is assigned to Cj and XC(i, j) = 0",2.2. K-means clustering,[0],[0]
otherwise.,2.2. K-means clustering,[0],[0]
"The k-means objective function given in equation 1 can now be represented in the matrix notation as,
",2.2. K-means clustering,[0],[0]
"‖A−XCX>CA‖2F = n∑ j=1 ‖aj −µC(aj)‖ 2 2 (2)
",2.2. K-means clustering,[0],[0]
"By construction, the columns of XC have disjoint support and are orthonormal vectors and XCX>C is an orthogonal projection matrix of rank k.",2.2. K-means clustering,[0],[0]
Let S be the set of all possible rank k cluster projection matrices of the form,2.2. K-means clustering,[0],[0]
XCX>C .,2.2. K-means clustering,[0],[0]
"The objective of k-means clustering is to find an optimal clustering of A that minimizes the objective function in equation
2, that is, to find XCopt such that,
XCopt = argmin XCX>C ∈S
‖A−XCX>CA‖2F
As mentioned earlier, finding XCopt is an NP-hard problem.",2.2. K-means clustering,[0],[0]
"Any cluster indicator matrix Xγ is called an γapproximation for the k-means clustering problem (γ ≥ 1) for data matrix A if it satisfies,
‖A−XγX>γA‖2F ≤",2.2. K-means clustering,[0],[0]
γ min,2.2. K-means clustering,[0],[0]
XCX>C ∈S,2.2. K-means clustering,[0],[0]
"‖A−XCX>CA‖2F
= γ‖A−XCoptX>CoptA‖ 2 F",2.2. K-means clustering,[0],[0]
"Given a data matrix A ∈ Rn×d, the basic idea of random matrix sparsification is to randomly sparsify the entries of A to get a matrix Ã ∈ Rn×d such that Ã contains fewer nonzero entries compared to A. Such a sparse matrix Ã speeds up matrix-vector multiplication by decreasing the number of arithmetic operations.",2.3. Random matrix sparsification,[0],[0]
"Let us write Ã = A+N, where N ∈ Rn×d.",2.3. Random matrix sparsification,[0],[0]
"A fundamental result of random matrix theory is that, as long as N is a random matrix whose entries are zero mean, independent random variables with bounded variance, no low dimensional subspace accommodates N well, i.e., ‖Nm‖2 and ‖Nm‖F are small for small m. In fact, optimal rank m approximation to Ã approximates A nearly as well as Am as long as ‖Am‖ ‖Nm‖ (for both Frobenious and spectral norm) and the quantity ‖Nm‖ bounds the influence that N may exert on the optimal rank m approximation to Ã.",2.3. Random matrix sparsification,[0],[0]
"Next we describe a simple random uniform sampling scheme as well as a simple non-uniform sampling scheme for generating sparse Ã that were proposed in (Achlioptas & Mcsherry, 2007) along with bounds on ‖Nm‖.",2.3. Random matrix sparsification,[0],[0]
"In the following, we set b to be b = max(i,j) |A(i, j)|.",2.3. Random matrix sparsification,[0],[0]
"In random matrix sparsificaion using uniform sampling scheme, p fraction of entries of A are set to zero to obtain a sparse Ã.",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"In particular,
Ã(i, j) = { A(i, j)/p with probability p 0 otherwise
(3)
It was shown in (Achlioptas & Mcsherry, 2007) that as long as p is bounded from below, with high probability, ‖Nm‖ is bounded as shown below (a simplified version of a result from (Achlioptas & Mcsherry, 2007)).
",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
Theorem 1.,2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"[Theorem 2 of (Achlioptas & Mcsherry, 2007)]",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"For p ≥ (8 log n)4/n, let Ã be the random sparse matrix obtained by applying uniform sampling scheme (equation 3).",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"Then with probability at least (1 − 1/n19 log3 n), for any m ≤ min{n, d}, N satisfies ‖Nm‖2 ≤",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"4b √ n/p and
‖Nm‖F ≤",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
4b,2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
√ mn/p.,2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
Random sparsification using uniform sampling can be improved by retaining entries with probability that depends on their magnitude.,2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"For any p > 0 define τij = p(A(i, j)/b)2
and let pij = max { τij , √ τij × (8 log n)4/n } .",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"Then a
sparse Ã can be obtained from A using the following nonuniform sampling scheme.
",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"Ã(i, j) = { A(i, j)/pij with probability pij 0",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"otherwise (4)
Such non-uniform sampling scheme yields greater sparsification when entry magnitudes vary, without increasing error bound of Theorem 1.
",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
Theorem 2.,2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"[Theorem 3 of (Achlioptas & Mcsherry, 2007)] Let Ã be the random sparse matrix obtained by applying non-uniform sampling scheme (equation 4).",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"Then with probability at least (1− 1/n19 log3 n), for any m ≤ min{n, d}, N satisfies ‖Nm‖2 ≤",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
4b √ n/p and ‖Nm‖F ≤ 4b √ mn/p.,2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
most p(‖A‖F /b)2,"In addition, expected number of non-zero entries in Ã is at",[0],[0]
"+ d(8 log n)4.
","In addition, expected number of non-zero entries in Ã is at",[0],[0]
"For any s > 0, setting p = s(b/‖A‖F )2 in the above Theorem ensures that expected number of non-zero entries in Ã is at most s+ d(8 log n)4.","In addition, expected number of non-zero entries in Ã is at",[0],[0]
"While the goal of k-means clustering is to well approximate each row of A with its cluster center, as can be seen from equation 1, an equivalent formulation in equation 2 shows that the problem actually amounts to finding an optimal rank
Algorithm 1 K-means clustering using random sparsification Input : Data matrix A ∈ Rn×d, number of clusters k, a positive scalar p and a γ-approximation k-means algorithm.",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"Output : Cluster indicator matrix Xγ̃ determining a k partition of the rows of A.
1: Compute Ã using non-uniform sampling scheme (equation 4).",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
2: Run the γ-approximation k-means algorithm on Ã to obtain Xγ̃ .,3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"3: Return Xγ̃ .
",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"k subspace for approximating the columns of A. Moreover, the choice of subspace is constrained because it must be spanned by the columns of a cluster indicator matrix.",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"The random sampling schemes presented in the previous section yields a sparse Ã whose optimal rank m approximation Ãm approximates Am reasonably well for small m. For appropriate choice of m, if such Am approximates optimal rank k subspace for approximating the columns of A well, then a reasonable strategy for k-means clustering that will reduce number of arithmetic operations is to perform kmeans clustering on Ã, instead of A, and hope that optimal k-means clustering solution of Ã will be close to optimal kmeans clustering solution of A. We propose such a strategy in Algorithm 1.",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
In the next section we present an analysis of this algorithm and prove that an optimal k-means clustering solution of Ã indeed results in an approximately optimal k-means objective of A.,3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
In this section we present an analysis of Algorithm 1.,4. Analysis of algorithm,[0],[0]
For all our results we have assumed that n,4. Analysis of algorithm,[0],[0]
≥,4. Analysis of algorithm,[0],[0]
d.,4. Analysis of algorithm,[0],[0]
"The main intuition for the technical part of the proof is that even though A and Ã look very different because of the enforced sparse structure, if their appropriate low-rank structures are similar, that is enough to argue that optimal k-means solution of Ã is close to optimal k-means solution of A. We use the notion of projection cost preserving sketch1 as a useful mathematical object for our proof.",4. Analysis of algorithm,[0],[0]
"If B is a rank k projection-cost preserving sketch for A with error 1, then it implies (can be easily shown) that optimal k-means solution of B is (1 + 1) optimal k-means solution of A (Cohen et al., 2015).",4. Analysis of algorithm,[0],[0]
"It turns out that for appropriate choice of m = m(k, 1), the best rankm approximation of A, namely Am, constructed by the m largest SVD structure form a rank k projection-cost preserving sketch for A with error 1.
1B ∈ Rn×d ′
is a rank k projection-cost preserving sketch of A ∈ Rn×d, with error 0 ≤ ≤ 1 if, for all rank k orthogonal projection matrices P ∈ Rn×n it holds",4. Analysis of algorithm,[0],[0]
that (1− )‖A−PA‖2F ≤,4. Analysis of algorithm,[0],[0]
‖B − PB‖2F + c ≤ (1 + ),4. Analysis of algorithm,[0],[0]
‖A,4. Analysis of algorithm,[0],[0]
"− PA‖2F for some fixed nonnegative constant c that may depend on A and B but is independent of P.
Similarly, Ãm is a rank k projection-cost preserving sketch for Ã.",4. Analysis of algorithm,[0],[0]
"We show that optimal k-means solution of Ã is close to optimal k-mean solution of A in two steps.
1.",4. Analysis of algorithm,[0],[0]
"First, we show the reverse direction of the implication of rank k projection-cost preserving sketch also holds.",4. Analysis of algorithm,[0],[0]
"In particular, we show that an optimal k-means solution of Ã is also (1 +O( 1)) optimal for Ãm.
2.",4. Analysis of algorithm,[0],[0]
Then we show that Ãm is also rank k projection-cost preserving sketch for A with a different error 2.,4. Analysis of algorithm,[0],[0]
"(this is where we quantify amount of sparsity to k-means error)
",4. Analysis of algorithm,[0],[0]
"Combining these two facts and properly choosing 1 and 2, we conclude that optimal k-means solution of Ã is (1 + )",4. Analysis of algorithm,[0],[0]
optimal k-means solution of A. We lay out the necessary details in the following subsections.,4. Analysis of algorithm,[0],[0]
"Ã and Ãm
We first show that close to optimal cluster indicator matrix obtained by solving k-means clustering problem on Ã yields a close to optimal k-means objective of Ãm.
",4.1. Relation between clustering objective functions of,[0],[0]
Lemma 1.,4.1. Relation between clustering objective functions of,[0],[0]
"For any 0 < ≤ 1/2, let m = dk/ e.",4.1. Relation between clustering objective functions of,[0],[0]
For any Ã ∈ Rn×d with rank r ≥ dk/,4.1. Relation between clustering objective functions of,[0],[0]
"e + k, let Ãm be its best rank m approximation.",4.1. Relation between clustering objective functions of,[0],[0]
"For any set S of rank k cluster projection matrices, let P̃∗ = argminP∈S ‖Ã",4.1. Relation between clustering objective functions of,[0],[0]
− PÃ‖2F and P̃∗m = argminP∈S ‖Ãm−PÃm‖2F .,4.1. Relation between clustering objective functions of,[0],[0]
"For any γ ≥ 1, if ‖Ã− P̂Ã‖2F ≤ γ‖Ã− P̃∗Ã‖2F , then, ‖Ãm− P̂Ãm‖2F ≤ γ‖Ãm",4.1. Relation between clustering objective functions of,[0],[0]
− P̃∗mÃm‖2F,4.1. Relation between clustering objective functions of,[0],[0]
+ (γ − 1)‖Ã − Ãm‖2F + ‖P̂(Ã − Ãm)‖2F .,4.1. Relation between clustering objective functions of,[0],[0]
"In particular, the following holds.
",4.1. Relation between clustering objective functions of,[0],[0]
(i),4.1. Relation between clustering objective functions of,[0],[0]
"If γ = 1, then, ‖Ãm − P̃∗Ãm‖2F ≤ (1 + 2 )‖Ãm",4.1. Relation between clustering objective functions of,[0],[0]
− P̃∗mÃm‖2.,4.1. Relation between clustering objective functions of,[0],[0]
(ii),4.1. Relation between clustering objective functions of,[0],[0]
"If γ = 1 + 1, for any 0 < 1 < 1 satisfying 1 ∑r i=m+1 σ 2 i (Ã) ≤ ∑m+k",4.1. Relation between clustering objective functions of,[0],[0]
"i=m+1 σ 2 i (Ã), then, ‖Ãm",4.1. Relation between clustering objective functions of,[0],[0]
− P̂Ãm‖2F ≤ (1 + 1 + 4 ),4.1. Relation between clustering objective functions of,[0],[0]
‖Ãm,4.1. Relation between clustering objective functions of,[0],[0]
"− P̃∗mÃm‖2.
",4.1. Relation between clustering objective functions of,[0],[0]
"Proof of the above lemma, which follows from repeated applications of linear algebra basics, choice of m, definition of P̂ and optimality of P̃∗, is long and technical and is differed to the supplementary material for better readability.",4.1. Relation between clustering objective functions of,[0],[0]
"Note that on the left hand side of the first inequality above (for γ = 1), we have used P̃∗ instead of P̂ since P̂ and P̃∗ are identical for γ",4.1. Relation between clustering objective functions of,[0],[0]
= 1.,4.1. Relation between clustering objective functions of,[0],[0]
Now we show that optimal cluster indicator matrix obtained by solving k-means clustering problem on Ãm results in close to optimal k-means objective of A. Let P∗,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"=
argminP∈S",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
‖A − PA‖2F and P̃∗m =,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
argminP∈S,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
‖Ãm,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
− PÃm‖2F .,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Our goal is to show that ‖A−P̃∗mA‖2F is close to ‖A−P∗A‖2F .,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"In fact, we prove a stronger result showing that Ãm is a rank k projection cost preserving sketch2 of A.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
We do this in multiple steps.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"First we show that for small k, Ãm is approximately best rank m subspace of A. Next, we show that such an Ãm is a rank k projection cost preserving sketch for A, which in turn ensures the required guarantee.
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
We start with the following lemma which is a consequence of Theorem 2.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Lemma 2.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Fix any m ≥ 1 and let 0 < 2,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
< 1/,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"√ m. Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = 16nb 2
22‖A‖2F .",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Then Ã contains O ( n 22 + d(log n)4 ) non-zero entries in expectation and with probability at least (1− 1/n19 log3 n),
‖A− Ãm‖F ≤ ‖A−Am‖F + 3 √ 2m 1/4‖A‖F
We tailor the above result to show that under mild conditions Ãm approximates Am reasonably well.
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Lemma 3.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Fix any 3, where 0 < 3 < 1.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Let rank of A be ρ.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Fix any k that satisfies ∑k/ 3 i=1 σ,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
2 i (A) ≤ 12,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
∑ρ i=1,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
σ 2,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"i (A), and let m = dk/ 3e.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = O ( nb2k
93‖A‖2F
) .",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Then Ã contains
O ( nk 93 + d(log n)4 ) non-zero entries in expectation and with probability at least (1− 1/n19 log3 n),
‖A− Ãm‖F ≤ (1 + 23)‖A−Am‖F
Next, we use a result from (Cohen et al., 2015) to show that if Ãm is close to best rank approximation of A, then Ãm is rank k projection cost preserving sketch for A.
Theorem 3.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"[Theorem 9 of (Cohen et al., 2015)] Let m = dk/ 3e.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"For any A ∈ Rn×d, 0 ≤ 4 ≤ 1 and any B ∈ Rn×d with rank(B) = m satisfying ‖A",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"− B‖2F ≤ (1 + 24)‖A−Am‖2F , the sketch B is a projection cost preserving sketch for A. Specifically, for all rank k orthogonal projections P,
(1− 2 4)‖A−PA‖2F ≤",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
‖B−PB‖2F,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
+ c ≤,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"(1 + 2 3 + 5 4)‖A−PA‖2F
where c is a non-negative scalar.
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"From Lemma 3 we see that with high probability, ‖A − Ãm‖2F ≤ (1 + 2 23 + 43)‖A −Am‖2F = (1 + 3 23)‖A −
2If B is a rank k projection cost preserving sketch of A, then optimal k-means clustering solution of B results in approximately optimal k-means clustering objective of A (Cohen et al., 2015).
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Am‖2F .,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Setting 4 = √
3 3 and B = Ãm, it follows from Theorem 3 that Ãm is a rank k projection cost preserving sketch of A.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
We combine these results from previous two subsections to present the main result of this paper.,4.3. Main result,[0],[0]
Theorem 4.,4.3. Main result,[0],[0]
"Fix any , where 0 < < 1/4.",4.3. Main result,[0],[0]
Let rank of A be ρ.,4.3. Main result,[0],[0]
For any k that satisfies ∑k/ i=1,4.3. Main result,[0],[0]
σ,4.3. Main result,[0],[0]
2,4.3. Main result,[0],[0]
i (A) ≤ 1 2 ∑ρ i=1,4.3. Main result,[0],[0]
σ 2,4.3. Main result,[0],[0]
"i (A), and let m = dk/ e. Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = O ( nb2k
9‖A‖2F
) .",4.3. Main result,[0],[0]
"For any
set S of rank k cluster projection matrices, let P∗",4.3. Main result,[0],[0]
= argminP∈S,4.3. Main result,[0],[0]
"‖A−PA‖2F , P̃∗ = argminP∈S ‖Ã−PÃ‖2F and P̃∗m = argminP∈S",4.3. Main result,[0],[0]
‖Ãm,4.3. Main result,[0],[0]
− PÃm‖2F .,4.3. Main result,[0],[0]
"For any γ ≥ 1, if ‖Ã − P̂Ã‖2F ≤ γ‖Ã",4.3. Main result,[0],[0]
"− P̃∗Ã‖2F , then Ã contains O ( nk 9 + d(log n) 4 )
non-zero entries in expectation and with probability at least (1 − 1/n19 log3 n)",4.3. Main result,[0],[0]
"the following holds,
(i)",4.3. Main result,[0],[0]
"If γ = 1, then ‖A−P̂A‖2F ≤ (1+2 )(1+11 ) 1−4 ‖A−P ∗A‖2
(ii) If γ = 1 + 1, for any 0 < 1 < 1 satisfying 1 ∑r i=m+1 σ 2 i (Ã) ≤ ∑m+k",4.3. Main result,[0],[0]
"i=m+1 σ 2 i (Ã), then ‖A − P̂A‖2F ≤ (1+ 1+4 )(1+11 ) 1−4 ‖A−P ∗A‖2
Proof.",4.3. Main result,[0],[0]
Set 3 = .,4.3. Main result,[0],[0]
"Then from Lemma 3 we get, ‖A − Ãm‖2F ≤ (1 + 3 2)‖A −Am‖2F .",4.3. Main result,[0],[0]
"Now setting B = Ãm and 4 = √ 3 in Theorem 3, for any rank k orthogonal projection P we get, (1− 2 √
3 )‖A−PA‖2F ≤",4.3. Main result,[0],[0]
‖Ãm −PÃm‖2F + c ≤,4.3. Main result,[0],[0]
"(1 + 2 + 5 √ 3 )‖A−PA‖2F
or simplifying,
(1− 4 )‖A−PA‖2F ≤",4.3. Main result,[0],[0]
‖Ãm −PÃm‖2F + c ≤,4.3. Main result,[0],[0]
(1 + 11 )‖A−PA‖2F,4.3. Main result,[0],[0]
"(5)
Let γ1 = (1 + 2 ) if γ = 1 and γ1 = (1 + 1 + 4 ) if γ ≥ 1.",4.3. Main result,[0],[0]
Then from lemma 1 we get ‖Ãm,4.3. Main result,[0],[0]
− P̂Ãm‖2F ≤ γ1‖Ãm,4.3. Main result,[0],[0]
− P̃∗mÃm‖2.,4.3. Main result,[0],[0]
"Using this result and repeated application of Equation 5 we get,
‖A− P̂A‖2F
≤ 1 1− 4
{",4.3. Main result,[0],[0]
"‖Ãm − P̂Ãm‖2F + c } ≤ 1
1− 4
{ γ1‖Ãm − P̃∗mÃm‖2F + c } ≤ 1
1− 4
{ γ1‖Ãm −P∗Ãm‖2F + c } ≤ 1
1− 4 { γ1",4.3. Main result,[0],[0]
[ (1 + 11 ),4.3. Main result,[0],[0]
‖A−P∗A‖2F,4.3. Main result,[0],[0]
− c ],4.3. Main result,[0],[0]
"+ c }
≤",4.3. Main result,[0],[0]
γ1(1 + 11 ),4.3. Main result,[0],[0]
"1− 4 ‖A−P∗A‖2F
Substituting appropriate value of γ1 yields the result.
",4.3. Main result,[0],[0]
The above result (Theorem 4) is obtained by stitching together many intermediate results.,4.3. Main result,[0],[0]
"To make sure that everything works at the end, we have different ranges for in Lemma 1 and Theorem 4.
",4.3. Main result,[0],[0]
A simple consequence of the above theorem is the following result which ensures (1 + ′) approximation for any 0,4.3. Main result,[0],[0]
< ′,4.3. Main result,[0],[0]
"< 1.
",4.3. Main result,[0],[0]
Corollary 1.,4.3. Main result,[0],[0]
"Fix any ′, where 0 < ′",4.3. Main result,[0],[0]
< 1.,4.3. Main result,[0],[0]
Let rank of A be ρ.,4.3. Main result,[0],[0]
Let m = O(k/ ′) and fix any k that satisfies∑m i=1 σ,4.3. Main result,[0],[0]
2,4.3. Main result,[0],[0]
i (A) ≤ 12,4.3. Main result,[0],[0]
∑ρ i=1,4.3. Main result,[0],[0]
σ 2,4.3. Main result,[0],[0]
i (A).,4.3. Main result,[0],[0]
"Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = O ( nb2k
( ′)9‖A‖2F
) .",4.3. Main result,[0],[0]
"For any set S of rank
k cluster projection matrices, let P∗",4.3. Main result,[0],[0]
= argminP∈S ‖A− PA‖2F and P̃∗ = argminP∈S ‖Ã,4.3. Main result,[0],[0]
− PÃ‖2F .,4.3. Main result,[0],[0]
For any 1 ≤ γ ≤ 2 satisfying (γ − 1) ∑r,4.3. Main result,[0],[0]
"i=m+1 σ
2 i (Ã) ≤∑m+k
i=m+1 σ 2 i (Ã), if ‖Ã− P̂Ã‖2F ≤ γ‖Ã−",4.3. Main result,[0],[0]
"P̃∗Ã‖2F , then Ã contains O (
nk ( ′)9 + d(log n)
4 )
non-zero entries in ex-
pectation and with probability at least (1−1/n19 log3 n)",4.3. Main result,[0],[0]
"the following holds,
‖A− P̂A‖2F ≤",4.3. Main result,[0],[0]
γ(1 + ′)‖A−P∗A‖2,4.3. Main result,[0],[0]
"In this section we present empirical evaluation of our proposed algorithm on three real world datasets: USPS, RCV1 and TDT2.",5. Empirical evaluations,[0],[0]
"The USPS dataset (Hull, 1994) contains 9298 handwritten digit images, where each 16 × 16 image is represented by a feature vector of length 256.",5. Empirical evaluations,[0],[0]
"We seek to find k = 10 clusters, one for each of the ten digits.",5. Empirical evaluations,[0],[0]
"The RCV1 dataset (Lewis et al., 2004) is an archive of over 800, 000 manually categorized news articles recently made available by Reuters.",5. Empirical evaluations,[0],[0]
"We use a smaller subset of this dataset available from LIBSVM webpage (LIB) containing 15, 564 news articles from 53 categories.",5. Empirical evaluations,[0],[0]
"Each such news article is represented by a feature vector of length 47, 236.",5. Empirical evaluations,[0],[0]
"We seek to find k = 53 clusters, one for each news article category.",5. Empirical evaluations,[0],[0]
"The TDT2 dataset (Cieri et al., 1999) consists of 11201 text documents which are classified into 96 semantic categories.",5. Empirical evaluations,[0],[0]
"We use a smaller subset of this dataset available from Deng Cai’s webpage3 where those documents appearing in two or more categories are removed, and only the largest 30 categories are kept, resulting in 9, 394 documents in total.",5. Empirical evaluations,[0],[0]
"Each such document is represented by a feature vector of length 36, 771.",5. Empirical evaluations,[0],[0]
"We seek to find k = 30 clusters, one for each news article category.",5. Empirical evaluations,[0],[0]
"For USPS dataset, all (100%) data matrix entries are non-zero.",5. Empirical evaluations,[0],[0]
"However, for TDT2 dataset, only 0.35% entries of the 9394 × 36771 data matrix are
3http://www.cad.zju.edu.cn/home/dengcai/Data/TextData.html
non-zero, while for RCV1 dataset, only 0.14% entries of the 15564 × 47236 data matrix are non-zero.",5. Empirical evaluations,[0],[0]
Since these two later datasets are already very sparse we reduce data dimensionality to 1000 using random projection in both cases by multiplying original data matrices with a random projection matrix (of appropriate size) whose entries are standard i.i.d.,5. Empirical evaluations,[0],[0]
normals4.,5. Empirical evaluations,[0],[0]
"After this random projection step, resulting projected data matrices become dense matrices, each containing 100% non-zero entries.",5. Empirical evaluations,[0],[0]
"As we will demonstrate next, for these two dense projected matrices our proposed sparsification method finds k-means clustering solution without severely affecting cluster quality.
",5. Empirical evaluations,[0],[0]
"To apply Lloyd’s heuristic for k-means clustering we use Matlab’s kmeans function which, by default, uses kmeans++ algorithm (Arthur & Vassilvitskii, 2007) for cluster center initialization.",5. Empirical evaluations,[0],[0]
"We repeat this clustering 30 times, each time initializing cluster center using k-means++ and selecting the final clustering as the one with lowest k-means objective.",5. Empirical evaluations,[0],[0]
"We demonstrate the effect of random sparsification obtained by uniform and non-uniform sampling on k-means clustering by reporting the following quantities, (a) the ratio h1(q) = ‖A−XqX>q",5. Empirical evaluations,[0],[0]
A‖2F /‖A−XX,5. Empirical evaluations,[0],[0]
">A‖2F , (b) cluster quality h2(q), measured by normalized mutual information (with respect to ground truth cluster labels of A) of a sparse data matrix Ã whose q fracation of entries are non-zero, and (c) normalized objective function h3(q) =",5. Empirical evaluations,[0],[0]
‖A − XqX>q A‖2F /‖A‖2F,5. Empirical evaluations,[0],[0]
",",5. Empirical evaluations,[0],[0]
as we vary q.,5. Empirical evaluations,[0],[0]
"In the above description, Xq is the cluster indicator matrix obtained by running k-means on sparse data matrix Ã whose q fraction of entries are non-zero and X is the cluster indicator matrix obtained by running k-means on A.
For uniform sampling, p simply indicates that p fraction
4It has been shown (Cohen et al., 2015) that such dimensionality reduction introduces (1 + ) relative error to optimal k-means objective.",5. Empirical evaluations,[0],[0]
"We chose projected dimension to be 1000 since increasing it further did not increase normalized mutual information significantly.
of entries of Ã are non-zero (in expectation, when A is dense matrix).",5. Empirical evaluations,[0],[0]
"For non-uniform sampling, number of nonzero entries in Ã can only be guaranteed by Theorem 2, which typically holds for large n.",5. Empirical evaluations,[0],[0]
In our empirical evaluation we use a slightly different strategy for non-uniform sampling than what is presented in section 2.3.2.,5. Empirical evaluations,[0],[0]
"However, this modified strategy, in principle, is still similar to what is presented in section 2.3.2.",5. Empirical evaluations,[0],[0]
"For any fixed value of p, note that τij = p(A(i, j)/b)
2.",5. Empirical evaluations,[0],[0]
"Now, instead of using pij in terms of τij as given in section 2.3.2, we use,
pij = { τij if τij ≥ p× f√ τij × p× f",5. Empirical evaluations,[0],[0]
"otherwise
where, f > 1, is to be chosen later.",5. Empirical evaluations,[0],[0]
"Therefore, for τij < p×f , pij = √ τij × p× f = p×(|A(i, j)|/b)× √ f .",5. Empirical evaluations,[0],[0]
"The basic idea is still same as before, i.e., when τij is small, instead of setting pij ∝",5. Empirical evaluations,[0],[0]
"(A(i, j))2, we set pij ∝",5. Empirical evaluations,[0],[0]
"|A(i, j)|.",5. Empirical evaluations,[0],[0]
"Now consider the case when τij < p× f , for all i, j.",5. Empirical evaluations,[0],[0]
"The expected number of non-zero entries is ∑ i,j p ×",5. Empirical evaluations,[0],[0]
√ f ×,5. Empirical evaluations,[0],[0]
"(|A(i, j)|/b) = pnd×",5. Empirical evaluations,[0],[0]
"√ f×Avg(|A(i, j)|/b).",5. Empirical evaluations,[0],[0]
"Therefore, if we choose5 f = 1/(Avg(|A(i, j)|/b))2, expected number of non-zero entries in Ã is pnd.",5. Empirical evaluations,[0],[0]
"In general, when the condition τij < p× f does not hold for all i, j, the expected fraction will be even less since pij < p, for τij ≥ p× f .",5. Empirical evaluations,[0],[0]
"In our experimental setting, we set f = 1/(Avg(|A(i, j)|/b))2.",5. Empirical evaluations,[0],[0]
"This ensures for any p, non-uniform sampling results in at most p fraction of non-zero entries in Ã. In our experiments, we vary p from 0.01 to 1.0 in steps of 0.01 and for each value of p, the number of of non-zero entries in Ã obtained due to non-uniform sampling is denoted by q and is plotted in Figure 2 for all three datasets.",5. Empirical evaluations,[0],[0]
"Observe that for all values of p, q = p for uniform sampling and q ≤ p for non-uniform sampling.
",5. Empirical evaluations,[0],[0]
"Next, in Figure 3 we show how random sparsification affects k-means clustering quality with increasing q.",5. Empirical evaluations,[0],[0]
"As can be seen from Figure 3, with increasing q, h1(q) and h3(q) decrease, while h2(q) increases as one would expect.",5. Empirical evaluations,[0],[0]
"In fact, h1(q) decreases quickly towards its optimal value 1 and corresponding h2(q) value quickly increases towards optimal k-means normalized mutual information of A. The normalized k-means objective h3(q)",5. Empirical evaluations,[0],[0]
"also shows steady decrease with increasing q. As can be seen from Figure 3, for all three datasets, non-uniform sampling yields better k-means clustering performance compared to uniform sampling.",5. Empirical evaluations,[0],[0]
"This makes perfect sense since non-uniform sampling, unlike uniform sampling, enforces sparsity by retaining entries with probability that depends on their magnitude.",5. Empirical evaluations,[0],[0]
"In fact, for TDT2 and RCV1 datasets, non-uniform sampling results in significant improvement in k-means clustering performance compared to uniform sampling.
",5. Empirical evaluations,[0],[0]
"5Avg(|A(i, j)|) represents average over all entries |A(i, j)|.
USPS
TDT2
RCV1",5. Empirical evaluations,[0],[0]
In this paper we proposed a simple algorithm for k-means clustering using random matrix sparsification and presented its analysis.,6. Conclusion,[0],[0]
"We proved that under mild condition, for any ∈ (0, 1), a dense data matrix A ∈ Rn×d can be randomly sparsified to yield a data matrix Ã ∈ Rn×d containing O(nk/ 9 + d log4 n) non-zero entries in expectation, such that an (1+ )-approximate k-mean clustering solution of Ã results in (1 +O( ))-approximate clustering solution of A with high probability.",6. Conclusion,[0],[0]
"Empirical results on three real world datasets demonstrated that k-means clustering solution of Ã was indeed very close to k-means clustering solution of A. Moreover, sparsification obtained by non-uniform sampling resulted in better cluster quality compared to uniform sampling.",6. Conclusion,[0],[0]
Empirical results also seem to suggest that the O(1/ 9) dependence on the number of non-zero entries in Ã is possibly a bit loose.,6. Conclusion,[0],[0]
We conclude this paper with two possible open questions: (a) Is it possible to analytically provide a better estimate (by improving dependence on 1/ ) of the number of non-zero entries in the sparse matrix Ã that ensures (1 + ) approximation guarantee?,6. Conclusion,[0],[0]
"and, (b) Using different proof technique, is it possible to show that γ-approximate clustering solution of Ã will result in γ(1 + )-approximate solution of A as shown in Corollary 1, even for γ > 2?",6. Conclusion,[0],[0]
"In other words, is the restriction on γ
in Corollary 1 a limitation of the proof technique or does it indicate computational hardness of the problem?",6. Conclusion,[0],[0]
K-means clustering algorithm using Lloyd’s heuristic is one of the most commonly used tools in data mining and machine learning that shows promising performance.,abstractText,[0],[0]
"However, it suffers from a high computational cost resulting from pairwise Euclidean distance computations between data points and cluster centers in each iteration of Lloyd’s heuristic.",abstractText,[0],[0]
"Main contributing factor of this computational bottle neck is a matrix-vector multiplication step, where the matrix contains all the data points and the vector is a cluster center.",abstractText,[0],[0]
In this paper we show that we can randomly sparsify the original data matrix resulting in a sparse data matrix which can significantly speed up the above mentioned matrix vector multiplication step without significantly affecting cluster quality.,abstractText,[0],[0]
"In particular, we show that optimal k-means clustering solution of the sparse data matrix, obtained by applying random matrix sparsification, results in an approximately optimal k-means clustering objective of the original data matrix.",abstractText,[0],[0]
Our empirical studies on three real world datasets corroborate our theoretical findings and demonstrate that our proposed sparsification method can indeed achieve satisfactory clustering performance.,abstractText,[0],[0]
K-means clustering using random matrix sparsification,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1470–1480 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics
We introduce KBGAN, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models. Because knowledge graphs typically only contain positive facts, sampling useful negative training examples is a nontrivial task. Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training. Inspired by generative adversarial networks (GANs), we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in GANs. This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks. In experiments, we adversarially train two translation-based models, TRANSE and TRANSD, each with assistance from one of the two probability-based models, DISTMULT and COMPLEX. We evaluate the performances of KBGAN on the link prediction task, using three knowledge base completion datasets: FB15k-237, WN18 and WN18RR. Experimental results show that adversarial training substantially improves the performances of target embedding models under various settings.",text,[0],[0]
"Knowledge graph (Dong et al., 2014) is a powerful graph structure that can provide direct access of knowledge to users via various applications such as structured search, question answering, and intelligent virtual assistant.",1 Introduction,[0],[0]
"A common representation of knowledge graph beliefs is in the
form of a discrete relational triple such as LocatedIn(NewOrleans,Louisiana).
",1 Introduction,[0],[0]
A main challenge for using discrete representation of knowledge graph is the lack of capability of accessing the similarities among different entities and relations.,1 Introduction,[0],[0]
"Knowledge graph embedding (KGE) techniques (e.g., RESCAL (Nickel et al., 2011), TRANSE (Bordes et al., 2013), DISTMULT (Yang et al., 2015), and COMPLEX (Trouillon et al., 2016)) have been proposed in recent years to deal with the issue.",1 Introduction,[0],[0]
"The main idea is to represent the entities and relations in a vector space, and one can use machine learning technique to learn the continuous representation of the knowledge graph in the latent space.
",1 Introduction,[0],[0]
"However, even steady progress has been made in developing novel algorithms for knowledge graph embedding, there is still a common challenge in this line of research.",1 Introduction,[0],[0]
"For space efficiency, common knowledge graphs such as Freebase (Bollacker et al., 2008), Yago (Suchanek et al., 2007), and NELL (Mitchell et al., 2015) by default only stores beliefs, rather than disbeliefs.",1 Introduction,[0],[0]
"Therefore, when training the embedding models, there is only the natural presence of the positive examples.",1 Introduction,[0],[0]
"To use negative examples, a common method is to remove the correct tail entity, and randomly sample from a uniform distribution (Bordes et al., 2013).",1 Introduction,[0],[0]
"Unfortunately, this approach is not ideal, because the sampled entity could be completely unrelated to the head and the target relation, and thus the quality of randomly generated negative examples is often poor (e.g, LocatedIn(NewOrleans,BarackObama)).",1 Introduction,[0],[0]
"Other approach might leverage external ontological constraints such as entity types (Krompaß et al., 2015) to generate negative examples, but such resource does not always exist or accessible.
",1 Introduction,[0],[0]
"In this work, we provide a generic solution to improve the training of a wide range of knowl-
1470
edge graph embedding models.",1 Introduction,[0],[0]
"Inspired by the recent advances of generative adversarial deep models (Goodfellow et al., 2014), we propose a novel adversarial learning framework, namely, KBGAN, for generating better negative examples to train knowledge graph embedding models.",1 Introduction,[0],[0]
"More specifically, we consider probabilitybased, log-loss embedding models as the generator to supply better quality negative examples, and use distance-based, margin-loss embedding models as the discriminator to generate the final knowledge graph embeddings.",1 Introduction,[0],[0]
"Since the generator has a discrete generation step, we cannot directly use the gradient-based approach to backpropagate the errors.",1 Introduction,[0],[0]
"We then consider a onestep reinforcement learning setting, and use a variance-reduction REINFORCE method to achieve this goal.",1 Introduction,[0],[0]
"Empirically, we perform experiments on three common KGE datasets (FB15K-237, WN18 and WN18RR), and verify the adversarial learning approach with a set of KGE models.",1 Introduction,[0],[0]
"Our experiments show that across various settings, this adversarial learning mechanism can significantly improve the performance of some of the most commonly used translation based KGE methods.",1 Introduction,[0],[0]
"Our contributions are three-fold:
•",1 Introduction,[0],[0]
"We are the first to consider adversarial learning to generate useful negative training examples to improve knowledge graph embedding.
",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"This adversarial learning framework applies to a wide range of KGE models, without the need of external ontologies constraints.
",1 Introduction,[0],[0]
• Our method shows consistent performance gains on three commonly used KGE datasets.,1 Introduction,[0],[0]
"A large number of knowledge graph embedding models, which represent entities and relations in a knowledge graph with vectors or matrices, have been proposed in recent years.",2.1 Knowledge Graph Embeddings,[0],[0]
"RESCAL (Nickel et al., 2011) is one of the earliest studies on matrix factorization based knowledge graph embedding models, using a bilinear form as score function.",2.1 Knowledge Graph Embeddings,[0],[0]
"TRANSE (Bordes et al., 2013) is the first model to introduce translation-based embedding.",2.1 Knowledge Graph Embeddings,[0],[0]
"Later variants, such as TRANSH (Wang et al., 2014), TRANSR (Lin et al., 2015) and TRANSD (Ji et al., 2015), extend TRANSE by projecting the embedding vectors of entities into various spaces.",2.1 Knowledge Graph Embeddings,[0],[0]
"DISTMULT (Yang et al., 2015) simplifies RESCAL by only using a diagonal matrix, and COMPLEX (Trouillon et al., 2016) extends DISTMULT into the complex number field.",2.1 Knowledge Graph Embeddings,[0],[0]
"(Nickel et al., 2015) is a comprehensive survey on these models.
",2.1 Knowledge Graph Embeddings,[0],[0]
Some of the more recent models achieve strong performances.,2.1 Knowledge Graph Embeddings,[0],[0]
"MANIFOLDE (Xiao et al., 2016) embeds a triple as a manifold rather than a point.",2.1 Knowledge Graph Embeddings,[0],[0]
"HOLE (Nickel et al., 2016) employs circular correlation to combine the two entities in a triple.",2.1 Knowledge Graph Embeddings,[0],[0]
"CONVE (Dettmers et al., 2017) uses a convolutional neural network as the score function.",2.1 Knowledge Graph Embeddings,[0],[0]
"However, most of these studies use uniform sampling to generate negative training examples (Bordes et al., 2013).",2.1 Knowledge Graph Embeddings,[0],[0]
"Because our framework is independent of the concrete form of models, all these models can be potentially incorporated into our framework, regardless of the complexity.",2.1 Knowledge Graph Embeddings,[0],[0]
"As a proof of principle, our work focuses on simpler models.",2.1 Knowledge Graph Embeddings,[0],[0]
Table 1 summarizes the score functions and dimensions of all models mentioned above.,2.1 Knowledge Graph Embeddings,[0],[0]
"Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) was originally proposed for generating samples in a continuous space such as images.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"A GAN consists of two parts, the generator and the discriminator.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
The generator accepts a noise input and outputs an image.,2.2 Generative Adversarial Networks and its Variants,[0],[0]
The discriminator is a classifier which classifies images as “true” (from the ground truth set) or “fake” (generated by the generator).,2.2 Generative Adversarial Networks and its Variants,[0],[0]
"When training a GAN, the generator and the discriminator play a minimax game, in which the generator tries to generate “real” images to deceive the discriminator, and the discriminator tries to tell them apart from ground truth images.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"GANs are also capable of generating samples satisfying certain requirements, such as conditional GAN (Mirza and Osindero, 2014).
",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"It is not possible to use GANs in its original form for generating discrete samples like natural language sentences or knowledge graph triples, because the discrete sampling step prevents gradients from propagating back to the generator.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"SEQGAN (Yu et al., 2017) is one of the first successful solutions to this problem by using reinforcement learning—It trains the generator using policy gradient and other tricks.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"IRGAN (Wang et al., 2017) is a recent work which combines two categories of information retrieval models into a discrete GAN framework.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"Likewise, our framework relies on policy gradient to train the generator which provides discrete negative triples.
",2.2 Generative Adversarial Networks and its Variants,[0],[0]
The discriminator in a GAN is not necessarily a classifier.,2.2 Generative Adversarial Networks and its Variants,[0],[0]
"Wasserstein GAN or WGAN (Arjovsky et al., 2017) uses a regressor with clipped parameters as its discriminator, based on solid analysis about the mathematical nature of GANs.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"GOGAN (Juefei-Xu et al., 2017) further replaces the loss function in WGAN with marginal loss.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"Although originating from very different fields, the form of loss function in our framework turns out to be more closely related to the one in GOGAN.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"In this section, we first define two types of training objectives in knowledge graph embedding models to show how KBGAN can be applied.",3 Our Approaches,[0],[0]
"Then, we demonstrate a long overlooked problem about negative sampling which motivates us to propose KBGAN to address the problem.",3 Our Approaches,[0],[0]
"Finally, we dive into the mathematical, and algorithmic details of
KBGAN.",3 Our Approaches,[0],[0]
"For a given knowledge graph, let E be the set of entities, R be the set of relations, and T be the set of ground truth triples.",3.1 Types of Training Objectives,[0],[0]
"In general, a knowledge graph embedding (KGE) model can be formulated as a score function f(h, r, t), h, t ∈ E , r ∈ R which assigns a score to every possible triple in the knowledge graph.",3.1 Types of Training Objectives,[0],[0]
"The estimated likelihood of a triple to be true depends only on its score given by the score function.
",3.1 Types of Training Objectives,[0],[0]
"Different models formulate their score function based on different designs, and therefore interpret scores differently, which further lead to various training objectives.",3.1 Types of Training Objectives,[0],[0]
"Two common forms of training objectives are particularly of our interest: Marginal loss function is commonly used by a large group of models called translation-based models, whose score function models distance between points or vectors, such as TRANSE, TRANSH, TRANSR, TRANSD and so on.",3.1 Types of Training Objectives,[0],[0]
"In these models, smaller distance indicates a higher likelihood of truth, but only qualitatively.",3.1 Types of Training Objectives,[0],[0]
"The marginal loss function takes the following form:
Lm = ∑
(h,r,t)∈T [f(h, r, t)− f(h′, r, t′) +",3.1 Types of Training Objectives,[0],[0]
"γ]+ (1)
where γ is the margin, [·]+ = max(0, ·) is the hinge function, and (h′, r, t′) is a negative triple.",3.1 Types of Training Objectives,[0],[0]
"The negative triple is generated by replacing the head entity or the tail entity of a positive triple with a random entity in the knowledge graph, or formally (h′, r, t′) ∈ {(h′, r, t)|h′ ∈ E} ∪ {(h, r, t′)|t′ ∈ E}.",3.1 Types of Training Objectives,[0],[0]
Log-softmax loss function is commonly used by models whose score function has probabilistic interpretation.,3.1 Types of Training Objectives,[0],[0]
"Some notable examples are RESCAL, DISTMULT, COMPLEX.",3.1 Types of Training Objectives,[0],[0]
"Applying the softmax function on scores of a given set of triples gives the probability of a triple to be the best one among them: p(h, r, t) = exp f(h,r,t)∑
(h′,r,t′) exp f(h ′,r,t′) .",3.1 Types of Training Objectives,[0],[0]
"The loss
function is the negative log-likelihood of this probabilistic model:
",3.1 Types of Training Objectives,[0],[0]
"Ll = ∑
(h,r,t)∈T − log exp f(h, r, t)∑ exp f(h′, r, t′)
(h′, r, t′) ∈ {(h, r, t)} ∪Neg(h, r, t) (2) where Neg(h, r, t) ⊂ {(h′, r, t)|h′ ∈ E} ∪ {(h, r, t′)|t′ ∈ E} is a set of sampled corrupted triples.
",3.1 Types of Training Objectives,[0],[0]
"Other forms of loss functions exist, for example CONVE uses a triple-wise logistic function to model how likely the triple is true, but by far the two described above are the most common.",3.1 Types of Training Objectives,[0],[0]
"Also, softmax function gives an probabilistic distribution over a set of triples, which is necessary for a generator to sample from them.",3.1 Types of Training Objectives,[0],[0]
"Most previous KGE models use uniform negative sampling for generating negative triples, that is, replacing the head or tail entity of a positive triple with any of the entities in E , all with equal probability.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Most of the negative triples generated in this way contribute little to learning an effective embedding, because they are too obviously false.
",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"To demonstrate this issue, let us consider the following example.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Suppose we have a ground truth triple LocatedIn(NewOrleans,Louisiana), and corrupt it by replacing its tail entity.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"First, we remove the tail entity, leaving LocatedIn(NewOrleans,?).",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Because the relation LocatedIn constraints types of its entities, “?” must be a geographical region.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"If we fill “?” with a random entity e ∈ E , the probability of e having a wrong type is very high, resulting in ridiculous triples like LocatedIn(NewOrleans,BarackObama) or LocatedIn(NewOrleans,StarTrek).",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Such triples are considered “too easy”, because they can be eliminated solely by types.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"In contrast, LocatedIn(NewOrleans,Florida) is a very useful negative triple, because it satisfies type constraints, but it cannot be proved wrong without detailed knowl-
edge of American geography.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"If a KGE model is fed with mostly “too easy” negative examples, it would probably only learn to represent types, not the underlying semantics.
",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"The problem is less severe to models using logsoftmax loss function, because they typically samples tens or hundreds of negative triples for one positive triple in each iteration, and it is likely to have a few useful negatives among them.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"For instance, (Trouillon et al., 2016) found that a 100:1 negative-to-positive ratio results in the best performance for COMPLEX.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"However, for marginal loss function, whose negative-to-positive ratio is always 1:1, the low quality of uniformly sampled negatives can seriously damage their performance.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Inspired by GANs, we propose an adversarial training framework named KBGAN which uses a KGE model with softmax probabilities to provide high-quality negative samples for the training of a KGE model whose training objective is marginal loss function.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"This framework is independent of the score functions of these two models, and therefore possesses some extent of universality.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Figure 1 illustrates the overall structure of KBGAN.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In parallel to terminologies used in GAN literature, we will simply call these two models generator and discriminator respectively in the rest of this paper.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"We use softmax probabilistic models as the generator because they can adequately model the “sampling from a probability distribu-
Algorithm 1: The KBGAN algorithm Data: training set of positive fact triples T = {(h, r, t)}",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Input: Pre-trained generator G with parameters θG and score function fG(h, r, t), and pre-trained discriminator D with
parameters θD and score function fD(h, r, t)",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Output: Adversarially trained discriminator
1 b←− 0; // baseline for policy gradient 2 repeat 3 Sample a mini-batch of data Tbatch from T ; 4 GG ←− 0, GD ←− 0; // gradients of parameters of G and D 5 rsum ←− 0; // for calculating the baseline 6 for (h, r, t) ∈",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Tbatch do 7 Uniformly randomly sample Ns negative triples Neg(h, r, t) =",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"{(h′i, r, t′i)}i=1...",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
Ns ; 8 Obtain their probability of being generated: pi = exp fG(h ′,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"i,r,t ′",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
i)∑Ns,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"j=1 exp fG(h ′ j ,r,t ′ j)
;
9 Sample one negative triple (h′s, r, t′s) from Neg(h, r, t) according to {pi}i=1...",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
Ns .,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Assume its probability to be ps;
10 GD ←− GD +∇θD",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"[fD(h, r, t)− fD(h′s, r, t′s) + γ]+; // accumulate gradients for D 11 r ←− −fD(h′s, r, t′s), rsum ←− rsum + r; // r is the reward 12 GG ←− GG",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
+ (r − b)∇θG log ps; // accumulate gradients for G 13 end 14 θG ←−,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
θG,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"+ ηGGG,",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"θD ←− θD − ηDGD; // update parameters 15 b← rsum/|Tbatch|; // update baseline 16 until convergence;
tion” process of discrete GANs, and we aim at improving discriminators based on marginal loss because they can benefit more from high-quality negative samples.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Note that a major difference between GAN and our work is that, the ultimate goal of our framework is to produce a good discriminator, whereas GANS are aimed at training a good generator.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In addition, the discriminator here is not a classifier as it would be in most GANs.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Intuitively, the discriminator should assign a relatively small distance to a high-quality negative sample.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In order to encourage the generator to generate useful negative samples, the objective of the generator is to minimize the distance given by discriminator for its generated triples.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"And just like the ordinary training process, the objective of the discriminator is to minimize the marginal loss between the positive triple and the generated negative triple.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In an adversarial training setting, the generator and the discriminator are alternatively trained towards their respective objectives.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Suppose that the generator produces a probability distribution on negative triples pG(h
′, r, t′|h, r, t) given a positive triple (h, r, t), and generates negative triples (h′, r, t′) by sampling from this distribution.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Let fD(h, r, t) be the score function of the discriminator.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The objective of the discriminator can be formulated as
minimizing the following marginal loss function:
LD = ∑
(h,r,t)∈T [fD(h, r, t)− fD(h′, r, t′) + γ]+
(h′, r, t′) ∼ pG(h′, r, t′|h, r, t) (3)
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The only difference between this loss function and Equation 1 is that it uses negative samples from the generator.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The objective of the generator can be formulated as maximizing the following expectation of negative distances:
RG = ∑
(h,r,t)∈T E[−fD(h′, r, t′)]
(h′, r, t′) ∼ pG(h′, r, t′|h, r, t) (4)
RG involves a discrete sampling step, so we cannot find its gradient with simple differentiation.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"We use a simple special case of Policy Gradient Theorem1 (Sutton et al., 2000) to obtain the gradient of RG with respect to parameters of the generator:
∇GRG = ∑
(h,r,t)∈T E(h′,r,t′)∼pG(h′,r,t′|h,r,t)
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"[−fD(h′, r, t′)∇G log pG(h′, r, t′|h, r, t)]
' ∑
(h,r,t)∈T
1
N
∑
(h′i,r,t ′",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"i)∼pG(h′,r,t′|h,r,t),i=1...",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"N
[−fD(h′, r, t′)∇G log pG(h′, r, t′|h, r, t)]",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"(5) 1A proof can be found in the supplementary material
where the second approximate equality means we approximate the expectation with sampling in practice.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Now we can calculate the gradient of RG and optimize it with gradient-based algorithms.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Policy Gradient Theorem arises from reinforcement learning (RL), so we would like to draw an analogy between our model and an RL model.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
The generator can be viewed as an agent which interacts with the environment by performing actions and improves itself by maximizing the reward returned from the environment in response of its actions.,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Correspondingly, the discriminator can be viewed as the environment.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Using RL terminologies, (h, r, t) is the state (which determines what actions the actor can take), pG(h′, r, t′|h, r, t) is the policy (how the actor choose actions), (h′, r, t′) is the action, and −fD(h′, r, t′) is the reward.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The method of optimizing RG described above is called REINFORCE (Williams, 1992) algorithm in RL.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Our model is a simple special case of RL, called one-step RL.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In a typical RL setting, each action performed by the agent will change its state, and the agent will perform a series of actions (called an epoch) until it reaches certain states or the number of actions reaches a certain limit.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"However, in the analogy above, actions does not affect the state, and after each action we restart with another unrelated state, so each epoch consists of only one action.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To reduce the variance of REINFORCE algorithm, it is common to subtract a baseline from the reward, which is an arbitrary number that only depends on the state, with-
out affecting the expectation of gradients.2 In our case, we replace −fD(h′, r, t′) with −fD(h′, r, t′)",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"− b(h, r, t) in the equation above to introduce the baseline.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To avoid introducing new parameters, we simply let b be a constant, the average reward of the whole training set: b =∑
(h,r,t)∈T E(h′,r,t′)∼pG(h′,r,t′|h,r,t)[−fD(h′, r, t′)].",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In practice, b is approximated by the mean of rewards of recently generated negative triples.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Let the generator’s score function to be fG(h, r, t), given a set of candidate negative triples Neg(h, r, t) ⊂ {(h′, r, t)|h′ ∈ E}∪{(h, r, t′)|t′ ∈ E}, the probability distribution pG is modeled as:
pG(h ′, r, t′|h, r, t)",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"= exp fG(h ′, r, t′)∑ exp fG(h∗, r, t∗) (h∗, r, t∗) ∈ Neg(h, r, t) (6) Ideally, Neg(h, r, t) should contain all possible negatives.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"However, knowledge graphs are usually highly incomplete, so the ”hardest” negative triples are very likely to be false negatives (true facts).",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To address this issue, we instead generate Neg(h, r, t) by uniformly sampling of Ns entities (a small number compared to the number of all possible negatives) from E to replace h or t. Because in real-world knowledge graphs, true negatives are usually far more than false negatives, such set would be unlikely to contain any false negative, and the negative selected by the generator would likely be a true negative.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Using a small Neg(h, r, t) can also significantly reduce computational complexity.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Besides, we adopt the “bern” sampling technique (Wang et al., 2014) which replaces the “1” side in “1-to-N” and “N-to-1” relations with higher probability to further reduce false negatives.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
Algorithm 1 summarizes the whole adversarial training process.,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Both the generator and the dis-
2A proof of such fact can also be found in the supplementary material
criminator require pre-training, which is the same as conventionally training a single KBE model with uniform negative sampling.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Formally speaking, one can pre-train the generator by minimizing the loss function defined in Equation (1), and pre-train the discriminator by minimizing the loss function defined in Equation (2).",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Line 14 in the algorithm assumes that we are using the vanilla gradient descent as the optimization method, but obviously one can substitute it with any gradientbased optimization algorithm.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To evaluate our proposed framework, we test its performance for the link prediction task with different generators and discriminators.",4 Experiments,[0],[0]
"For the generator, we choose two classical probability-based KGE model, DISTMULT and COMPLEX, and for the discriminator, we also choose two classical translation-based KGE model, TRANSE and TRANSD, resulting in four possible combinations of generator and discriminator in total.",4 Experiments,[0],[0]
See Table 1 for a brief summary of these models.,4 Experiments,[0],[0]
"We use three common knowledge base completion datasets for our experiment: FB15k-237, WN18 and WN18RR. FB15k-237 is a subset of FB15k introduced by (Toutanova and Chen, 2015), which removed redundant relations in FB15k and greatly reduced the number of relations.",4.1.1 Datasets,[0],[0]
"Likewise, WN18RR is a subset of WN18 introduced by (Dettmers et al., 2017) which removes reversing relations and dramatically increases the difficulty of reasoning.",4.1.1 Datasets,[0],[0]
"Both FB15k and WN18 are first introduced by (Bordes et al., 2013) and have been commonly used in knowledge graph researches.",4.1.1 Datasets,[0],[0]
Statistics of datasets we used are shown in Table 3.,4.1.1 Datasets,[0],[0]
"Following previous works like (Yang et al., 2015) and (Trouillon et al., 2016), for each run, we report two common metrics, mean reciprocal ranking (MRR) and hits at 10 (H@10).",4.1.2 Evaluation Protocols,[0],[0]
"We only report scores under the filtered setting (Bordes et al., 2013), which removes all triples appeared in training, validating, and testing sets from candidate triples before obtaining the rank of the ground truth triple.",4.1.2 Evaluation Protocols,[0],[0]
"3 In the pre-training stage, we train every model to convergence for 1000 epochs, and divide every epoch into 100 mini-batches.",4.1.3 Implementation Details,[0],[0]
"To avoid overfitting, we adopt early stopping by evaluating MRR on the validation set every 50 epochs.",4.1.3 Implementation Details,[0],[0]
"We tried γ = 0.5, 1, 2, 3, 4, 5 and L1, L2 distances for TRANSE and TRANSD, and λ = 0.01, 0.1, 1, 10 for DISTMULT and COMPLEX, and determined the best hyperparameters listed on table 2, based on their performances on the validation set after pre-training.",4.1.3 Implementation Details,[0],[0]
"Due to limited computation resources, we deliberately limit the dimensions of embeddings to k = 50, similar to the one used in earlier works, to save time.",4.1.3 Implementation Details,[0],[0]
"We also apply certain constraints or regularizations to these models, which are mostly the same as those described in their original publications, and also listed on table 2.
",4.1.3 Implementation Details,[0],[0]
"In the adversarial training stage, we keep all the hyperparamters determined in the pre-training stage unchanged.",4.1.3 Implementation Details,[0],[0]
"The number of candidate negative triples, Ns, is set to 20 in all cases, which is proven to be optimal among the candidate set of {5, 10, 20, 30, 50}.",4.1.3 Implementation Details,[0],[0]
"We train for 5000 epochs, with 100 mini-batches for each epoch.",4.1.3 Implementation Details,[0],[0]
"We also use early stopping in adversarial training by evaluating MRR on the validation set every 100 epochs.
",4.1.3 Implementation Details,[0],[0]
"We use the self-adaptive optimization method Adam (Kingma and Ba, 2015) for all trainings, and always use the recommended default setting α = 0.001, β1 = 0.9, β2 = 0.999, = 10 −8.",4.1.3 Implementation Details,[0],[0]
Results of our experiments as well as baselines are shown in Table 4.,4.2 Results,[0],[0]
"All settings of adversarial training bring a pronounced improvement to the model, which indicates that our method is consistently effective in various cases.",4.2 Results,[0],[0]
"TRANSE performs slightly worse than TRANSD on FB15k-237 and WN18, but better on WN18RR.",4.2 Results,[0],[0]
"Using DISTMULT or COMPLEX as the generator does not affect performance greatly.
",4.2 Results,[0],[0]
"TRANSE and TRANSD enhanced by KBGAN can significantly beat their corresponding baseline implementations, and outperform stronger baselines in some cases.",4.2 Results,[0],[0]
"As a prototypical and proofof-principle experiment, we have never expected state-of-the-art results.",4.2 Results,[0],[0]
"Being simple models pro-
3The KBGAN source code is available at https:// github.com/cai-lw/KBGAN
posed several years ago, TRANSE and TRANSD has their limitations in expressiveness that are unlikely to be fully compensated by better training technique.",4.2 Results,[0],[0]
"In future researches, people may try employing more advanced models into KBGAN, and we believe it has the potential to become stateof-the-art.
",4.2 Results,[0],[0]
"To illustrate our training progress, we plot performances of the discriminator on validation set over epochs, which are displayed in Figure 2.",4.2 Results,[0],[0]
"As all these graphs show, our performances are always in increasing trends, converging to its max-
imum as training proceeds, which indicates that KBGAN is a robust GAN that can converge to good results in various settings, although GANs are wellknown for difficulty in convergence.",4.2 Results,[0],[0]
"Fluctuations in these graphs may seem more prominent than other KGE models, but is considered normal for an adversially trained model.",4.2 Results,[0],[0]
Note that in some cases the curve still tends to rise after 5000 epochs.,4.2 Results,[0],[0]
"We do not have sufficient computation resource to train for more epochs, but we believe that they will also eventually converge.",4.2 Results,[0],[0]
"To demonstrate that our approach does generate better negative samples, we list some examples of them in Table 5, using the KBGAN (TRANSE + DISTMULT) model and the WN18 dataset.",4.3 Case study,[0],[0]
"All hyperparameters are the same as those described in Section 4.1.3.
",4.3 Case study,[0],[0]
"Compared to uniform random negatives which are almost always totally unrelated, the generator generates more semantically related negative samples, which is different from type relatedness we used as example in Section 3.2, but also helps training.",4.3 Case study,[0],[0]
"In the first example, two of the five terms are physically related to the process of distilling liquids.",4.3 Case study,[0],[0]
"In the second example, three of the five entities are geographical objects.",4.3 Case study,[0],[0]
"In the third example, two of the five entities express the concept of “gather”.
",4.3 Case study,[0],[0]
"Because we deliberately limited the strength of generated negatives by using a small Ns as described in Section 3.3, the semantic relation is pretty weak, and there are still many unrelated entities.",4.3 Case study,[0],[0]
"However, empirical results (when selecting the optimal Ns) shows that such situation is more beneficial for training the discriminator than generating even stronger negatives.",4.3 Case study,[0],[0]
We propose a novel adversarial learning method for improving a wide range of knowledge graph embedding models—We designed a generatordiscriminator framework with dual KGE components.,5 Conclusions,[0],[0]
"Unlike random uniform sampling, the generator model generates higher quality negative examples, which allow the discriminator model to learn better.",5 Conclusions,[0],[0]
"To enable backpropagation of error, we introduced a one-step REINFORCE method to seamlessly integrate the two modules.",5 Conclusions,[0],[0]
"Experimentally, we tested the proposed ideas with four commonly used KGE models on three datasets, and the results showed that the adversarial learning framework brought consistent improvements to various KGE models under different settings.",5 Conclusions,[0],[0]
"We introduce KBGAN, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models.",abstractText,[0],[0]
"Because knowledge graphs typically only contain positive facts, sampling useful negative training examples is a nontrivial task.",abstractText,[0],[0]
"Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training.",abstractText,[0],[0]
"Inspired by generative adversarial networks (GANs), we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in GANs.",abstractText,[0],[0]
"This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks.",abstractText,[0],[0]
"In experiments, we adversarially train two translation-based models, TRANSE and TRANSD, each with assistance from one of the two probability-based models, DISTMULT and COMPLEX.",abstractText,[0],[0]
"We evaluate the performances of KBGAN on the link prediction task, using three knowledge base completion datasets: FB15k-237, WN18 and WN18RR.",abstractText,[0],[0]
Experimental results show that adversarial training substantially improves the performances of target embedding models under various settings.,abstractText,[0],[0]
KBGAN: Adversarial Learning for Knowledge Graph Embeddings,title,[0],[0]
"Inference of parameters in a probabilistic model is an essential ingredient in model-based statistical approaches, both in the frequentist and Bayesian paradigms.",1. Introduction,[0],[0]
"Given a probabilistic model P (y|θ), which is a conditional distribution of observations y given a parameter θ, the aim is to make inference about the parameter θ∗ that generated an observed data y∗.",1. Introduction,[0],[0]
"When the model P (y|θ) admits a conditional density `(y|θ), such an inference can be made on the basis of evaluations of `(y∗|θ); this is the likelihood of y∗ as a function of θ.",1. Introduction,[0],[0]
"However, in modern scientific and engineering problems in which the model P (y|θ) is required to be sophisticated and complex, the likelihood function `(y∗|θ) might no longer be available.",1. Introduction,[0],[0]
"This may be because the density form of P (y|θ) is elusive, or the evaluation of the likelihood `(y∗|θ) is computationally very expensive.",1. Introduction,[0],[0]
"Such situations, in which `(y|θ) (or P (y|θ)) are referred to as intractable likelihood, make the inference problem quite challenging and are commonly found in the literature on
1NEC Corporation 2National Institute of Advanced Industrial Science and Technology 3Max Planck Institute for Intelligent Systems 4The Institute of Statistical Mathematics.",1. Introduction,[0],[0]
"Correspondence to: Takafumi Kajihara <t-kajihara@ct.jp.nec.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"population genetics (Pritchard et al., 1999) and dynamical systems (Toni et al., 2009), to name just two.
",1. Introduction,[0],[0]
"Approximate Bayesian Computation (ABC) is a class of computational methods for Bayesian inference with intractable likelihood (Tavaré et al., 1997; Pritchard et al., 1999; Beaumont et al., 2002) that is applicable as long as sampling from the model P (y|θ) is possible.",1. Introduction,[0],[0]
"Given a prior π(θ) on the parameter space, the basic ABC constructs a Monte Carlo approximation to the posterior Py∗(θ) ∝",1. Introduction,[0],[0]
"P (y∗|θ)π(θ) in the following way: i) sample pairs (yi, θi) of pseudo data yi and parameter θi from the joint distribution P (y|θ)π(θ), where i = 1, . . .",1. Introduction,[0],[0]
", n for some n ∈ N, ii) maintain only those parameters θi associated with yi that are “close enough” to the observed data y∗, and iii) regard them as samples from the posterior Py∗(θ).",1. Introduction,[0],[0]
"ABC has been extensively studied in statistics and machine learning; see, e.g., Del Moral et al. (2012); Fukumizu et al. (2013); Meeds and Welling (2014); Park et al. (2016); Mitrovic et al. (2016).
",1. Introduction,[0],[0]
"In this paper, we rather take the frequentist perspective, and deal with the problem of maximum likelihood estimation (MLE) with intractable likelihood.",1. Introduction,[0],[0]
"That is, we consider situations in which one believes that there is a “true” parameter θ∗ that generated the data y∗ and wishes to obtain a point estimate for it.",1. Introduction,[0],[0]
"This problem is also motivated by the following situations encountered in practice: 1) Consider a situation in which the model is computationally expensive (e.g., a state-space model) and one wants to perform prediction based on it.",1. Introduction,[0],[0]
"In this case fully Bayesian prediction would require simulation from each of sampled parameters, which might be quite costly.",1. Introduction,[0],[0]
"If one has a point estimate of the true parameter θ∗, then the computational cost can be drastically reduced.",1. Introduction,[0],[0]
2) Consider a situation in which one only has limited knowledge w.r.t. model parameters.,1. Introduction,[0],[0]
"In this case, it is generally difficult to specify an appropriate prior distribution over the parameter space, and thus the resulting posterior may not be reliable.1 Methods for point estimation with intractable likelihood have been reported in the literature, including the method of simulated-moments (McFadden, 1989), indirect inference (Gourieroux et al.,
1For point estimation, one may think of using the maximum a posterior (MAP) estimate, but it may again be unreliable (as for the posterior distribution itself), if the prior distribution cannot be specified appropriately.
1993), ABC-based MAP estimation (Rubio et al., 2013), noisy ABC-MLE (Dean et al., 2014; Yıldırım et al., 2015), an approach based on Bayesian optimization (Gutmann and Corander, 2016), and data-cloning ABC (Picchini and Anderson, 2017).",1. Introduction,[0],[0]
"We will discuss these existing approaches in Sec. 4.
",1. Introduction,[0],[0]
"Our contribution is in proposing a novel approach to point estimation with intractable likelihood on the basis of kernel mean embedding of distributions (Muandet et al., 2017), a framework for statistical inference using reproducing kernel Hilbert spaces.",1. Introduction,[0],[0]
"Specifically, our approach extends kernel ABC (Fukumizu et al., 2013; Nakagome et al., 2013), a method for ABC using kernel embedding of conditional distributions (Song et al., 2009; 2013), to point estimation with intractable likelihood.",1. Introduction,[0],[0]
"The novelty lies in combining kernel ABC with kernel herding (Chen et al., 2010), a deterministic sampling method similar to quasi-Monte Carlo (Dick et al., 2013), and in applying these two methods iteratively to the same observed data in a recursive way.",1. Introduction,[0],[0]
We term this approach kernel recursive ABC.,1. Introduction,[0],[0]
"A theoretical explanation will be provided for this approach, discussing how such recursion yields a point estimate for the true parameter.",1. Introduction,[0],[0]
"We also discuss that the combination of kernel ABC and kernel herding leads to robustness against misspecification of a prior for the true parameter; this is an advantage over existing methods, and will be demonstrated experimentally.
",1. Introduction,[0],[0]
This paper is organized as follows.,1. Introduction,[0],[0]
We briefly review kernel ABC and kernel herding in Sec. 2 and propose kernel recursive ABC in Sec. 3.,1. Introduction,[0],[0]
We report experimental results of comparisons with existing methods in Sec. 4.,1. Introduction,[0],[0]
"The experiments include parameter estimation for a real-world pedestrian flow simulator (Yamashita et al., 2010), which may be of independent interest as application.",1. Introduction,[0],[0]
"Kernel ABC is an algorithm that executes ABC in a reproducing kernel Hilbert space (RKHS) and produces a reliable solution even in moderately large dimensional problems (Fukumizu et al., 2013; Nakagome et al., 2013).",2.1. Kernel ABC,[0],[0]
"It is based on the framework of kernel mean embeddings, in which all probability measures are represented as elements in an RKHS (see Muandet et al. (2017) for a recent survey of this field).",2.1. Kernel ABC,[0],[0]
"Let Θ be a measurable space, k : Θ × Θ → R be a measurable positive definite kernel, and H be its RKHS.",2.1. Kernel ABC,[0],[0]
"In this framework, any probability measure P on Θ will be represented as a Bochner integral
µP",2.1. Kernel ABC,[0],[0]
":= ∫ Θ k(·, θ)dP (θ) ∈ H, (1)
which is called the kernel mean of P .",2.1. Kernel ABC,[0],[0]
"If the mapping P → µP is injective, in which case µP preserves all the
information in P , the kernel k is referred to as being characteristic (Fukumizu et al., 2008).",2.1. Kernel ABC,[0],[0]
"Characteristic kernels on Θ = Rd, for example, include Gaussian and Matérn kernels (Sriperumbudur et al., 2010).
",2.1. Kernel ABC,[0],[0]
Let Y be another measurable space and assume that an observed data y∗ ∈ Y is provided.,2.1. Kernel ABC,[0],[0]
(y∗ is often a set of sample points.),2.1. Kernel ABC,[0],[0]
"Given a conditional probability P (y|θ) and a prior π(θ), we wish to obtain the posterior distribution Py∗(θ) ∝",2.1. Kernel ABC,[0],[0]
P,2.1. Kernel ABC,[0],[0]
"(y∗|θ)π(θ).2 As in a standard ABC, kernel ABC achieves this by first generating pairs of pseudo data and parameter {(yi, θi)}ni=1 from the joint distribution P (y|θ)π(θ).",2.1. Kernel ABC,[0],[0]
"It then estimates the kernel mean of the posterior Py∗ , which we denote by
µPy∗ := ∫",2.1. Kernel ABC,[0],[0]
"Θ k(·, θ)dPy∗(θ) ∈ H.
",2.1. Kernel ABC,[0],[0]
"Given a measurable positive definite kernel kY on Y , the estimator is given by
µ̂Py∗ = n∑ i=1 wik(·, θi) ∈ H, (2)
",2.1. Kernel ABC,[0],[0]
"w := (w1, . . .",2.1. Kernel ABC,[0],[0]
", wn) T := (G+ nδI)−1k(y∗), (3)
where k(y∗)",2.1. Kernel ABC,[0],[0]
":= (kY(y1, y∗), . . .",2.1. Kernel ABC,[0],[0]
", kY(yn, y∗))T ∈",2.1. Kernel ABC,[0],[0]
"Rn, G := (kY(yi, yj)) n",2.1. Kernel ABC,[0],[0]
"i,j=1 ∈ Rn×n, δ > 0 is a regularization constant, and I ∈ Rn×n is an identity matrix.",2.1. Kernel ABC,[0],[0]
"The estimator (2) is essentially an (RKHS-valued) kernel ridge regression (Grünewälder et al., 2012):",2.1. Kernel ABC,[0],[0]
"Given training data {(yi, k(·, θi))}ni=1, the weights (3) provide an estimator for the mapping y∗ ⇒",2.1. Kernel ABC,[0],[0]
"k(·, θ∗).",2.1. Kernel ABC,[0],[0]
"For consistency and convergence results, which require δ → 0 as n→∞, we re refer to Fukumizu et al. (2013) and Muandet et al. (2017).",2.1. Kernel ABC,[0],[0]
"Kernel herding is a deterministic sampling technique based on the kernel mean representation of a distribution (Chen et al., 2010) and can be seen as a greedy approach to quasiMonte Carlo (Dick et al., 2013).",2.2. Kernel herding,[0],[0]
"Consider sampling from P using the kernel mean µP (1), and assume that one is able to evaluate function values of µP .",2.2. Kernel herding,[0],[0]
"Kernel herding greedily obtains sample points θ1, θ2, . . .",2.2. Kernel herding,[0],[0]
", θn by iterating the following steps: Defining h0 := µP ,
θt+1 = argmax θ∈Θ ht(θ), (4) ht+1 = ht + µP",2.2. Kernel herding,[0],[0]
"− k(·, θt+1) ∈ H, (5)
where t = 0, . . .",2.2. Kernel herding,[0],[0]
", n− 1.",2.2. Kernel herding,[0],[0]
"Chen et al. (2010) has shown that, if there exists a constant C > 0",2.2. Kernel herding,[0],[0]
"such that k(θ, θ) = C for all θ ∈ Θ, this procedure will be identical to the greedy
2There is abuse of notation here, as P (y|θ) does not denote a conditional density but a conditional distribution.
",2.2. Kernel herding,[0],[0]
Algorithm 1 Kernel Recursive ABC Input:,2.2. Kernel herding,[0],[0]
"A prior distribution π, an observed data y∗, a data generator P (y|θ), the number Niter of iterations, the number n of simulated pairs, a kernel k on Θ, a kernel kY on Y , and a regularization constant δ > 0",2.2. Kernel herding,[0],[0]
"Output: A point estimate θ́. for N = 1, ..., Niter do
if N = 1 then for i = 1, ..., n do
Sample θ1,i ∼ π(θ) i.i.d. end for
end if for i = 1, ..., n do
Generate yN,i ∼ P (·|θN,i) end for Compute G := (kY(yN,i, yN,i))ni,j=1 ∈ Rn×n and k(y) := (kY(yN,i, y
∗))ni=1 ∈",2.2. Kernel herding,[0],[0]
Rn.,2.2. Kernel herding,[0],[0]
"Calculate w = (w1, . . .",2.2. Kernel herding,[0],[0]
", wn)T ∈",2.2. Kernel herding,[0],[0]
Rn by Eq.(3).,2.2. Kernel herding,[0],[0]
"Construct a kernel mean estimate of the powered posterior µ̂PN := ∑n i=1 wik(·, θN,i)",2.2. Kernel herding,[0],[0]
"Sample {θN+1,t}nt=1 by performing kernel herding Eqs.(4) (5) with µP := µ̂PN .
",2.2. Kernel herding,[0],[0]
"end for Obtain a point estimate θ́ := θNiter+1,1
minimization of the maximum mean discrepancy (MMD) (Gretton et al., 2007; 2012):
n",2.2. Kernel herding,[0],[0]
:= ∥∥∥∥∥µP,2.2. Kernel herding,[0],[0]
"− 1n n∑ t=1 k(·, θt) ∥∥∥∥∥",2.2. Kernel herding,[0],[0]
"H , (6)
where ‖ · ‖H denotes the norm of H. That is, the points θ1, . . .",2.2. Kernel herding,[0],[0]
", θn are obtained so as to (greedily) minimize the distance εn between µP and the empirical kernel mean 1 n ∑n t=1",2.2. Kernel herding,[0],[0]
k,2.2. Kernel herding,[0],[0]
"(·, θt).",2.2. Kernel herding,[0],[0]
"The generated points θ1, . .",2.2. Kernel herding,[0],[0]
.,2.2. Kernel herding,[0],[0]
", θn are also called super-samples because they are more informative than those from random sampling; this is in the sense that error decreases at the rate n = O(n−1) if the RKHS is finite-dimensional (Bach et al., 2012), which is faster than the rate n = O(n−1/2) of random sampling (Smola et al., 2007).",2.2. Kernel herding,[0],[0]
"Convergence guarantees are also provided even when the optimization problem in (4) is solved approximately (Lacoste-Julien et al., 2015) and when the kernel mean µP is replaced by an empirical estimate µ̂P of the form (2) (Kanagawa et al., 2016b).",2.2. Kernel herding,[0],[0]
Note that the decay n → 0 of the error (6) as n→∞ implies the convergence of expectation 1 n,2.2. Kernel herding,[0],[0]
"∑n t=1 f(θt) → ∫ f(x)dP (x) for all functions f in the RKHSH and for functions f that can be approximated well by the RKHS functions (Kanagawa et al., 2016a).",2.2. Kernel herding,[0],[0]
"Our idea is to recursively apply Bayes’ rule to the same
observed data y∗ by using the posterior obtained in one iteration as a prior for the next iteration.",3. Proposed method,[0],[0]
"For this, let `(θ) := `(y∗|θ) be a likelihood function and π(θ) be a prior density, where θ ∈ Θ, with Θ being a measurable space.",3. Proposed method,[0],[0]
Consider the population setting in which no estimation procedure is involved.,3. Proposed method,[0],[0]
"After theN -th recursion, the posterior distribution becomes
pN (θ) :",3. Proposed method,[0],[0]
"= C −1 N π(θ)(`(θ)) N , (7)
where CN := ∫
Θ π(θ) (`(θ))
",3. Proposed method,[0],[0]
"N dθ is a normalization con-
stant.",3. Proposed method,[0],[0]
We refer here to this as a powered posterior.,3. Proposed method,[0],[0]
"If ` has a unique global maximum at θ∞ ∈ Θ and the support of π contains θ∞, one can show that pN converges weakly to the Dirac distribution δθ∞ at θ∞ under certain conditions (Lele et al., 2010).",3. Proposed method,[0],[0]
"In other words, the effect of the prior diminishes as the recursion proceeds, and the powered posterior degenerates at the maximum likelihood point, providing a method for MLE.",3. Proposed method,[0],[0]
"A similar idea has been discussed by Doucet et al. (2002); Lele et al. (2010) in the context of data augmentation and data cloning, in which one replicates the observed data y∗ multiple times and applies Bayes’ rule once; our approach is different, as we employ recursive applications of Bayes’ rule multiple times (this turns out to be beneficial in our approach, as is shown below).
",3. Proposed method,[0],[0]
"Based on the above idea, we propose to recursively applying kernel ABC (Sec. 2.1) and kernel herding (Sec. 2.2).",3. Proposed method,[0],[0]
"Specifically, the proposed method (Algorithm 1) iterates the following procedures: (i) At the N -th iteration, the kernel mean µPN := ∫ k(·, θ)pN (θ)dθ of the powered posterior (7) is estimated using simulated pairs {(θN,i, yN,i)}ni=1 via kernel ABC; (ii) from the estimate µ̂PN of µPN given in (i), new parameters {θN+1,i}ni=1 are generated via kernel herding, and new pseudo-data {yN+1,i}ni=1 are generated from the simulator P (yN+1,i|θN+1,i) in the N + 1-th iteration.",3. Proposed method,[0],[0]
"After iterating these procedures Niter times, point estimate θ́ for the true parameter is given as the first point θNiter+1,1 from kernel herding at the last iteration.
",3. Proposed method,[0],[0]
Auto-correction mechanism.,3. Proposed method,[0],[0]
"An interesting feature of the proposed approach is that, as experimentally indicated in Sec. 4.2, it is equipped with an auto-correction mechanism: If the parameters θN,1, . . .",3. Proposed method,[0],[0]
", θN,n",3. Proposed method,[0],[0]
at theN -th,3. Proposed method,[0],[0]
iteration,3. Proposed method,[0],[0]
"are far apart from the true parameter θ∗, then Algorithm 1 searches for the parameters θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,n at the next iteration, so as to explore the parameter space Θ.",3. Proposed method,[0],[0]
"For instance, if the prior π(θ) is misspecified, meaning that the true parameter θ∗ is not contained in the support of π(θ), then the initial parameters θ1,1, . . .",3. Proposed method,[0],[0]
", θ1,n from π(θ) are likely to be apart from the true parameter θ∗.",3. Proposed method,[0],[0]
"The auto-correction mechanism makes the proposed method robust to such misspecification and makes it suitable for use in situations in which one lacks appropriate prior knowledge about the true parameter.
",3. Proposed method,[0],[0]
"To explain how this works, let us explicitly write down the procedure (4) (5) of kernel herding as used in Algorithm 1.
",3. Proposed method,[0],[0]
"Given that t (< n) points θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,t have already been generated, the next point θN+1,t+1 is obtained as
θN+1,t+1 := (8)
argmax θ∈Θ n∑ i=1",3. Proposed method,[0],[0]
"wik(θ, θN,i)− 1 t+ 1",3. Proposed method,[0],[0]
t∑ i=1,3. Proposed method,[0],[0]
"k(θ, θN+1,i),
where the weights w1, . . .",3. Proposed method,[0],[0]
", wn are given as (3).",3. Proposed method,[0],[0]
"Assume that all the simulated parameters θN,1, . . .",3. Proposed method,[0],[0]
", θN,n at the N -th iteration are far apart from the true parameter θ∗:",3. Proposed method,[0],[0]
"If N = 1, these are the parameters sampled from the prior π(θ).",3. Proposed method,[0],[0]
"Then it is likely the resulting simulated data yN,1, . . .",3. Proposed method,[0],[0]
", yN,n are dissimilar to the observed data y∗.",3. Proposed method,[0],[0]
"In this case, each component of the vector k(y) := (kY(yN,i, y∗))ni=1 ∈",3. Proposed method,[0],[0]
"Rn becomes nearly 0, since kY(yN,i, y∗) quantifies the similarity between y∗ and yN,i. As a result, each of the weights w1, . .",3. Proposed method,[0],[0]
.,3. Proposed method,[0],[0]
", wn given by kernel ABC (3) also become nearly 0, and thus the first term on the right side in (8) will be ignorable.",3. Proposed method,[0],[0]
"The point θN+1,t+1 is then obtained so as to roughly maximize the second term − 1t+1 ∑t i=1",3. Proposed method,[0],[0]
"k(θN+1,t+1, θN+1,i), or, equivalently, so as
to minimize ∑t i=1",3. Proposed method,[0],[0]
"k(θN+1,t+1, θN+1,i).",3. Proposed method,[0],[0]
"Since the kernel k(θN+1,t+1, θN+1,i) measures the similarity between θN+1,t+1 and θN+1,i, the new point θN+1,t+1 is located apart from the points θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,t generated so far.",3. Proposed method,[0],[0]
"In this way, the parameters θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,n at theN+1th iteration are made to explore the parameter space Θ if parameters θN,1, . . .",3. Proposed method,[0],[0]
", θN,n at the N -th iteration are far apart from the true parameter θ∗.",3. Proposed method,[0],[0]
We provide here a theoretical basis for the proposed recursive approach.,3.1. Theoretical analysis,[0],[0]
"Since the consistency of kernel ABC and kernel herding have already been established in the literature (Fukumizu et al., 2013; Bach et al., 2012), we focus on convergence analysis in the population setting, that is, convergence analysis for the kernel mean of the powered posterior (7) and for the resulting point estimate.",3.1. Theoretical analysis,[0],[0]
We nevertheless note that convergence analysis of the overall procedure of Algorithm 1 remains an important topic for future research.,3.1. Theoretical analysis,[0],[0]
"All the proofs can be found in the Supplementary Materials.
",3.1. Theoretical analysis,[0],[0]
"Below, we let Θ be a Borel measurable set in Rd.",3.1. Theoretical analysis,[0],[0]
"Denote by PN the probability measure induced by the powered posterior density pN (7), and let µPN := ∫ k(·, θ)dPN (θ) ∈ H be its kernel mean, where k is a kernel on Θ and H is its RKHS.",3.1. Theoretical analysis,[0],[0]
We require the following assumption for the likelihood function ` and the prior π for theoretical analysis.,3.1. Theoretical analysis,[0],[0]
Assumption 1.,3.1. Theoretical analysis,[0],[0]
"(i) ` has a unique global maximum at θ∞ ∈ Θ, and π(θ∞) > 0; (ii) π is continuous at θ∞, ` has continuous second derivatives in the neighborhood of θ∞, and the Hessian of ` at θ∞ is strictly negative-definite.
",3.1. Theoretical analysis,[0],[0]
"Our first result below shows that, under Assumption 1, the
powered posterior PN (7) converges to the Dirac distribution δθ∞ in the RKHSH as N →∞; this provides a theoretical basis for recursively applying the kernel ABC.
",3.1. Theoretical analysis,[0],[0]
Proposition 1.,3.1. Theoretical analysis,[0],[0]
Let Θ ⊂ Rd be a Borel measurable set and k : Θ × Θ → R be a continuous bounded kernel.,3.1. Theoretical analysis,[0],[0]
"Under Assumption 1, we have limN→∞ ‖µPN",3.1. Theoretical analysis,[0],[0]
"− k(·, θ∞)‖H = 0.
Proposition 2 below provides a justification for the use of the first point of kernel herding (here this is θN",3.1. Theoretical analysis,[0],[0]
:= argminθ̃∈Θ ‖µPN,3.1. Theoretical analysis,[0],[0]
"− k(·, θ̃)‖H; see Sec. 2.2) as a point estimate of θ∞. To this end, we introduce the following assumption on the kernel, which is satisfied by, for example, Gaussian and Matérn kernels.
",3.1. Theoretical analysis,[0],[0]
Assumption 2.,3.1. Theoretical analysis,[0],[0]
(i),3.1. Theoretical analysis,[0],[0]
"There exists a constant C > 0 such that k(θ, θ) = C for all θ ∈ Θ. (ii)",3.1. Theoretical analysis,[0],[0]
"It holds that k(θ, θ′) < C for all θ, θ′ ∈ Θ with θ 6= θ′. Proposition 2.",3.1. Theoretical analysis,[0],[0]
"Let Θ ⊂ Rd be a compact set, and k : Θ × Θ → R be a continuous, bounded kernel.",3.1. Theoretical analysis,[0],[0]
Let θN,3.1. Theoretical analysis,[0],[0]
:,3.1. Theoretical analysis,[0],[0]
"= argminθ̃∈Θ
∥∥∥µPN − k(·, θ̃)∥∥∥H. If Assumptions 1 and 2 hold, then we have θN → θ∞ as N →∞.
We make a few remarks regarding Assumption 1.",3.1. Theoretical analysis,[0],[0]
"The assumption that ` has a unique global maximum is not satisfied if the model is singular, an example being mixture models: In this case there are multiple global maximums.",3.1. Theoretical analysis,[0],[0]
"However, our experiment in Sec. 4.5 shows that even for mixture models, the proposed method works reasonably well.",3.1. Theoretical analysis,[0],[0]
"This suggests that, in an empirical setting, a point estimate may converge to one of the global maximums.",3.1. Theoretical analysis,[0],[0]
"The assumption π(θ∞) > 0 will also not be satisfied if the support π does not contain θ∞, but the proposed method performs well even in this case (as shown in 4.2), possibly thanks to the auto-correction mechanism explained above.",3.1. Theoretical analysis,[0],[0]
We reserve further analysis of these properties for future work.,3.1. Theoretical analysis,[0],[0]
We have conducted a variety of experiments comparing the proposed method with existing approaches.,4. Experiments,[0],[0]
"We begin with a quick review of these approaches (Sec. 4.1), and report experimental results on point estimation with a misspecified prior (Sec. 4.2), population dynamics of the blowfly (Sec. 4.3), alpha stable distributions (Sec. 4.4), Gaussian mixture models with redundant components (Sec. 4.5), and a real-world pedestrian simulator (Sec. 4.6).",4. Experiments,[0],[0]
"K2-ABC (Park et al., 2016) is an ABC method that represents the empirical distributions of simulated and test observations as kernel means in an RKHS.",4.1. Existing approaches and experimental settings,[0],[0]
"For each of simulated parameters, the associated weight is calculated by using the RKHS distance between the kernel means (i.e., MMD), and the resulting weighted sample is treated as a posterior
distribution.",4.1. Existing approaches and experimental settings,[0],[0]
"Adaptive SMC-ABC (Del Moral et al., 2012) is a rejection-based approach based on sequential Monte Carlo, which sequentially updates the tolerance level and the associated proposal distribution in an adaptive manner.",4.1. Existing approaches and experimental settings,[0],[0]
This method is a state-of-the-art ABC approach.,4.1. Existing approaches and experimental settings,[0],[0]
"The approach by Gutmann and Corander (2016), which we refer to as Bayesian Optimization for simplicity, is a method for MLE with intractable likelihood based on Bayesian optimization (Brochu et al., 2010).",4.1. Existing approaches and experimental settings,[0],[0]
This method optimizes the parameters in a intractable model so as to minimize the discrepancy between the simulated and test observations.,4.1. Existing approaches and experimental settings,[0],[0]
"Note that comparison with this method in terms of computation time may not make sense (although we report them for purposes of completeness), as we used publicly available code3 for implementation.",4.1. Existing approaches and experimental settings,[0],[0]
"The method of simulated moments (MSM) (McFadden, 1989) optimizes the parameter in the model so that the resulting moments of simulated data match those of observe data.",4.1. Existing approaches and experimental settings,[0],[0]
"MSM may be seen a special case of indirect inference (Gourieroux et al., 1993), an approach studied in econometrics.4 Data-cloning ABC (ABC-DC) (Picchini and Anderson, 2017) is an approach combining ABC-MCMC (Marjoram et al., 2003) and Data Cloning (Lele et al., 2010), replicating observed data multiple times to achieve MLE with intractable likelihood.
",4.1. Existing approaches and experimental settings,[0],[0]
Experimental settings.,4.1. Existing approaches and experimental settings,[0],[0]
"Unless otherwise specified, the following settings were applied in the experiments.",4.1. Existing approaches and experimental settings,[0],[0]
"For all the methods that employed kernels, we used Gaussian kernels.",4.1. Existing approaches and experimental settings,[0],[0]
"The discrepancy between the simulated and observed data was measured by the energy distance (Székely and Rizzo, 2013), which is a standard metric for distributions in statistics and can be computed only from pairwise Euclidean distances between data points.",4.1. Existing approaches and experimental settings,[0],[0]
"Since the usual quadratic time estimator was too costly, we used a linear time estimator for computing the energy distance (see the Supplementary Materials for details).
",4.1. Existing approaches and experimental settings,[0],[0]
"For each method, unless otherwise specified, we determined the hyper-parameters on the basis of the cross-validationlike approach described in Park et al. (2016, Sec. 4).",4.1. Existing approaches and experimental settings,[0],[0]
"That is, to evaluate one configuration of hyper-parameters, we first used 75% of the observed data for point estimation and then computed the discrepancy between the rest of the observed data and the ones simulated from point estimates; after applying this procedure to all candidate configurations, the one with the lowest discrepancy was finally selected.",4.1. Existing approaches and experimental settings,[0],[0]
"The bandwidth of a Gaussian kernel was selected from candidate values, each of which is the median (of pairwise distances) multiplied by logarithmically equally spaced values between 2−4 and 24 (Takeuchi et al., 2006, Sec. 5.1.1).",4.1. Existing approaches and experimental settings,[0],[0]
"Regularization constants for the proposed method and kernel ABC, as well as the soft threshold for K2-ABC, were selected
3https://sheffieldml.github.io/GPyOpt/ 4MSM is a special case of indirect inference because the mo-
ments can be regarded as the parameters of an auxiliary model.
from logarithmically spaced values between 10−4 and 1.",4.1. Existing approaches and experimental settings,[0],[0]
"To compute MMD for K2-ABC, a linear time estimator (Gretton et al., 2012, Sec. 6) was used to reduce computational time, as the usual quadratic time estimator was too costly.",4.1. Existing approaches and experimental settings,[0],[0]
"For Adaptive SMC-ABC, the initial tolerance level was set as the median of pairwise distances between the observed and simulated data.",4.1. Existing approaches and experimental settings,[0],[0]
"For Bayesian Optimization, we used Expected Improvement as an acquisition function, and all the hyper-parameters were marginalized out following the approach of Snoek et al. (2012, Sec. 3.2).",4.1. Existing approaches and experimental settings,[0],[0]
"For MSM, the number of moments were selected from a range up to 30 by the cross-validation like approach.",4.1. Existing approaches and experimental settings,[0],[0]
"For ABC-DC, we employed, in particular, dynamic ABC-DC, which automatically adjusts its associated parameters.",4.1. Existing approaches and experimental settings,[0],[0]
"To obtain point estimates with kernel ABC and K2-ABC, we computed the means of the resulting posterior distributions.",4.1. Existing approaches and experimental settings,[0],[0]
"For Adaptive SMC-ABC, point estimates were obtained as posterior means as well as MAP estimates by applying the mean shift algorithm to posterior weighted samples (Fukunaga and Hostetler, 1975), the latter essentially being an approach suggested by Rubio et al. (2013).
",4.1. Existing approaches and experimental settings,[0],[0]
"The following abbreviations may be used for the sake of simplicity; kernel recursive ABC is referred to as KR-ABC, kernel ABC as K-ABC, adaptive SMC-ABC as SMC-ABC, Bayesian Optimization as BO, and Dynamic ABC-DC as ABC-DC.",4.1. Existing approaches and experimental settings,[0],[0]
"For our method, we also report results based on a half number of iterations, which we call KR-ABC (less).",4.1. Existing approaches and experimental settings,[0],[0]
"As a proof of concept regarding the auto-correction mechanism of the proposed method described in Sec.3, we have performed an experiment for when the prior distribution is severely misspecified (see the Supplementary Materials for an illustration).",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"The task is to estimate the mean vector of a 20-dimensional Gaussian distribution Normal(µ,Σ), where the true mean vector is µ := (10, 50, 90, 130, 180, 280, 390, 430, 520, 630, 1010, 1050, 1090, 1130, 1180, 1280, 1390, 1430, 1520, 1630)T ∈ R20.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
The covariance matrix Σ ∈ R20×20 is assumed to be known and is a diagonal matrix with all diagonal elements being 40.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
Test data y∗ consisted of 100 i.i.d.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
observations from this Gaussian distribution.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"As a prior for the mean vector µ, we used the uniform distribution on [9× 106, 107]20, which is extremely misspecified.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For Bayesian optimization, the space to be explored was set as [0, 107]20.
",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"In this experiment, each pseudo data was made from 100 observations simulated with one parameter configuration.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
K2-ABC and K-ABC used 3000 pairs of a parameter and pseudo-data.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For the proposed method and SMC-ABC, we generated 100 pairs of a parameter and pseudo-data for the initial iteration, and then the iterations were repeated 30
times, resulting in a total of 3000 simulations.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For the proposed method, the bandwidth of the kernel kY on observed data was recomputed for each iteration, using the median heuristic.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For SMC-ABC, the parameter α ∈ (0, 1), which controls the trade-off between the speed of convergence and the accuracy of posterior approximation, was set to be 0.3, as we found this value to be the best in terms of the trade-off.
",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For each method, we ran 30 independent trials, and the results in averages and standard deviations are shown in Table 1, where the parameter error is the mean (over 20 dimensions) of the absolute difference between the estimated and the true parameter values divided by the true value, and the data error is the energy distance between the true data and pseudo data simulated with the estimated parameter.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"Surprisingly, the proposed method successfully approached the true parameter even when the prior was severely misspecified.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"As discussed in Sec 3 and demonstrated in the Supplementary Materials, this would appear to be because of the use of kernel herding, which automatically widens the space to explore when simulated data is far apart from test data.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"As expected, other methods were unable to approach the true parameter.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"Following Park et al. (2016), we performed an experiment on parameter estimation with a dynamical system of blowfly populations (Wood, 2010), which is defined as
Nt+1 = PNt−τ exp (−Nt−τ/N0) et + Nt exp(−δ t),
where t = 1, . . .",4.3. Ecological dynamic systems: blowfly,[0],[0]
", T are time indices, Nt is the population at time t, et ∼ Gam( 1σ2pσ 2 p) and t ∼ Gam( 1σ2d , σ 2 d) are independent Gamma-distributed noise, and θ := (P ∈ N, N0 ∈ N,",4.3. Ecological dynamic systems: blowfly,[0],[0]
"σd ∈ R+, σp ∈",4.3. Ecological dynamic systems: blowfly,[0],[0]
"R+, τ",4.3. Ecological dynamic systems: blowfly,[0],[0]
"∈ N, δ ∈",4.3. Ecological dynamic systems: blowfly,[0],[0]
R+) are the parameters of the system.,4.3. Ecological dynamic systems: blowfly,[0],[0]
"The task is to estimate θ from observed values of N1, . . .",4.3. Ecological dynamic systems: blowfly,[0],[0]
", NT .",4.3. Ecological dynamic systems: blowfly,[0],[0]
"We set the true parameters as θ = (29, 260, 0.6, 0.3, 7, 0.2), and the time-length T for both the observed and pseudo data as T = 1000.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"Following Park et al. (2016, Sec. 4), for each parameter we defined a Gaussian prior on its logarithm (see the Supplementary Materials for a definition).",4.3. Ecological dynamic systems: blowfly,[0],[0]
"In this experiment, for all methods we converted the observed and pseudo-data into histograms
with 1000 bins (i.e., we treated each data as a 1000 dim.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"vector), as this produced better results.",4.3. Ecological dynamic systems: blowfly,[0],[0]
K2-ABC and K-ABC used 1300 pairs of a parameter and a pseudo-data item.,4.3. Ecological dynamic systems: blowfly,[0],[0]
"For the proposed method and SMC-ABC, we generated 100 pairs of a parameter and pseudo-data for the initial iteration, and the iterations were then repeated 13 times, resulting in total 1300 simulations.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"For SMC-ABC, we set the parameter α ∈ (0, 1) to be 0.3, as in Sec. 4.2.
",4.3. Ecological dynamic systems: blowfly,[0],[0]
"For each method we performed 30 independent trials, and the results are summarized in Table 2.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"The proposed method performed the best, even when the number of simulations was halved (i.e., KR-ABC (less)).",4.3. Ecological dynamic systems: blowfly,[0],[0]
"In addition to the competitive methods described earlier, we performed a comparison with the method called noisy ABC-MLE (Yıldırım et al., 2015).",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"This method assumes that sampling from the intractable model can be realized by deterministic mapping applied to a simple random variable, and that the gradient of the deterministic mapping is available.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"This method can, then, only be applied to a limited class of generative models, though for such models it can perform well.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"Although the main scope of this paper is on simulation models in which such gradient information is unavailable, we performed this experiment in order to see how the proposed method compared with this method without relying on the gradient information.
",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"We also considered parameter estimation with multivariate elliptically contoured alpha stable distributions (Nolan, 2013), which subsume heavy-tailed and skewed distributions and are popular for modeling financial data.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"This family of distributions in general does not admit closedform expressions for density functions, which means they are “intractable” in the sense that the standard procedure for parameter estimation cannot be employed.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"However, sampling of a random vector X ∈ Rd from this family is possible in the following way:
X := A1/2G + δ ∈ Rd, G ∼ Normal(0, Q),",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"A := τθ(U1, U2) ∈ R,
U1 ∼ Unif(−π/2, π/2), U2 ∼ Exp(1),
where Q ∈ Rd×d is positive definite, δ ∈ Rd, θ := (α, β, µ, σ) ∈ (0, 2] ×",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"[−1, 1] × R ×",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"[0,∞), τθ is a deterministic mapping whose concrete form is described in the Supplementary Materials, and Unif and Exp denote uniform and exponential distributions, respectively.
",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"We dealt with estimation of α := 1.3 and Q, while fixing the other parameters as δ := 0, β := 1, µ := 0, and σ",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
:= 1.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
We restricted Q to be a positive definite matrix such that all diagonal elements are the same and so are the off-diagonal elements.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
We defined true Q to be a matrix whose diagonal elements are 1.0 and off-diagonals are 0.2.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"Therefore the task was to estimate these three values (i.e., 1.3 for α, and 1.0 and 0.2 for Q).",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"We used Unif[0, 2] as a prior for α, and Unif[0, 5] as a prior for each of the diagonal and offdiagonal values of Q.
Figure 1 shows results for the averages of mean square errors in parameter estimation over 30 independent trials, with variation in the dimensionality d from 2 to 16.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"For each method we sampled a total of 1400 pairs of a parameter and a pseudo-data item, and for iterative methods we used 100 pairs in each iteration.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
Each pseudo-data (and observed-data) was made up of 1000 points.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"The noisy ABC-MLE exploited the gradient information in τθ, while the other methods did not.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
The proposed method was competitive with BO and outperformed the other methods with the exception of the noisy ABC-MLE.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"Although the noisy ABC-MLE was accurate for lower-dimensionality (as expected), it exhibited a steep increase in errors for higher dimensionality.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"In contrast, the performance degradation of the proposed method was mild for higher dimensionality.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
We consider here a parametric model in which there exist redundant parameters for expressing given data.,4.5. Gaussian mixture with redundant components,[0],[0]
"We are interested in whether point estimation with the proposed method results in elimination of the redundant parameters
when applied to such a model.",4.5. Gaussian mixture with redundant components,[0],[0]
"This was motivated by Yamazaki and Kaji (2013), who argued that, for mixture models, the use of a Dirichlet prior with a sufficiently small concentration parameter leads to elimination of unnecessary components.",4.5. Gaussian mixture with redundant components,[0],[0]
"We therefore focus on mixture models with redundant components.
",4.5. Gaussian mixture with redundant components,[0],[0]
"Specifically, we considered Gaussian mixture models.",4.5. Gaussian mixture with redundant components,[0],[0]
"We defined the true model as a two-component Gaussian mixture ∑2 i=1 φiNormal(µi, 20) of equal variances.",4.5. Gaussian mixture with redundant components,[0],[0]
"The task was to estimate the mixture coefficients (φ1, φ2, ) := (0.7, 0.3) and the associate means (µ1, µ2) := (110, 70), provided 3000 i.i.d. sample points from the model as observed data y∗. We employed an over-parametrized model for point estimation (i.e., no method used the knowledge that the truth consisted of 2 components), which is a fourcomponent Gaussian mixture ∑4 i=1 φiNormal(µi, 20).",4.5. Gaussian mixture with redundant components,[0],[0]
"We used a 4-dimensional Dirichlet distribution with equal concentration parameters 0.01 as a prior for the coefficients (φ1, . . .",4.5. Gaussian mixture with redundant components,[0],[0]
", φ4), and Normal(0, 100) as a prior for each of µ1, . . .",4.5. Gaussian mixture with redundant components,[0],[0]
", µ4.
",4.5. Gaussian mixture with redundant components,[0],[0]
"For each method, we generated a total of 1000 pairs of a parameter and pseudo-data, and for iterative methods, we made use of 100 pairs in each iteration, resulting in 10 iterations.",4.5. Gaussian mixture with redundant components,[0],[0]
Each pseudo-data consisted of 3000 simulated observations.,4.5. Gaussian mixture with redundant components,[0],[0]
"For all the methods, we converted each data item into a histogram of 300 bins and treated it as a 300 dim.",4.5. Gaussian mixture with redundant components,[0],[0]
vector since this resulted in better performances.,4.5. Gaussian mixture with redundant components,[0],[0]
"We set the parameter α ∈ (0, 1) of SMC-ABC to be 0.2, as this performed well in this experiment.
",4.5. Gaussian mixture with redundant components,[0],[0]
"We ran each algorithm 30 times, and the resulting average errors and standard deviations are shown in Table 3, where the φ error and µ error denote the errors for the coefficients and the means, respectively, as measured in terms of Euclidean distance.",4.5. Gaussian mixture with redundant components,[0],[0]
"More precisely, since any permutation of component labels will result in the same model, we first sorted the estimated parameters {(φi, µi)} so that φ1 ≥ · · · ≥ φ4, and we then measured the errors w.r.t.",4.5. Gaussian mixture with redundant components,[0],[0]
"the ground truth φ := (0.7, 0.3, 0, 0) and µ := (110, 70).",4.5. Gaussian mixture with redundant components,[0],[0]
"For the µ error, we computed the errors only for the estimated means µ1, µ2 associated with the two largest coefficients since there was no ground truth for the redundant components µ3, µ4.",4.5. Gaussian mixture with redundant components,[0],[0]
"Results show that the proposed KR-ABC performed best, indicating that the dominant components were successfully estimated.",4.5. Gaussian mixture with redundant components,[0],[0]
"Our final experiment was parameter estimation with CrowdWalk, a publicly available real-world simulator5 for the movements of pedestrians in a commercial district (Yamashita et al., 2010).",4.6. Real-world pedestrian simulator,[0],[0]
"It has been used to gain insights into pedestrian behavior at a variety of events and occurrences, such as fireworks festivals and evacuations after earthquakes.",4.6. Real-world pedestrian simulator,[0],[0]
"As this simulator is complicated and also computationally expensive, its likelihood function is intractable.
",4.6. Real-world pedestrian simulator,[0],[0]
"Using CrowdWalk, we simulated the movements of pedestrians in Ginza, a commercial district in Tokyo (see Supplementary Materials for an illustration).",4.6. Real-world pedestrian simulator,[0],[0]
"Specifically, we modeled pedestrians as a mixture of multiple groups, each of which has the following 6 parameters (below i denotes the index of a group): (1) θ(N)i ∈ N: the number of pedestrians in the group; (2) θ(T )",4.6. Real-world pedestrian simulator,[0],[0]
i ∈,4.6. Real-world pedestrian simulator,[0],[0]
R+:,4.6. Real-world pedestrian simulator,[0],[0]
"the time when the group starts to move; (3) θ(S)i ∈ R2: the starting location of the group (e.g., stations); (4) θ(G)i ∈ R2: the goal location of the group; (5) θ(P )",4.6. Real-world pedestrian simulator,[0],[0]
"i ∈ R2: the intermediate location(s) that the pedestrians in the group visit (e.g., stores); and (6) θ
(R)",4.6. Real-world pedestrian simulator,[0],[0]
i ∈,4.6. Real-world pedestrian simulator,[0],[0]
"R+: the time duration(s) of the pedestrians’ visit(s)
at the intermediate location(s).
",4.6. Real-world pedestrian simulator,[0],[0]
"In this experiment, we focused on estimation of the first two parameters θ(N)i , θ (T )",4.6. Real-world pedestrian simulator,[0],[0]
"i , and fixed the other parameters.",4.6. Real-world pedestrian simulator,[0],[0]
"We defined the true model as a mixture of 5 pedestrian groups, and set their parameters as (θ∗(N)1 , . . .",4.6. Real-world pedestrian simulator,[0],[0]
", θ ∗(N) 5 ) := (100, 100, 100, 100, 100) and (θ ∗(T ) 1 , . .",4.6. Real-world pedestrian simulator,[0],[0]
.,4.6. Real-world pedestrian simulator,[0],[0]
", θ ∗(T ) 5 ) := (30, 60, 90, 120, 150).",4.6. Real-world pedestrian simulator,[0],[0]
"As in Sec. 4.5, we used a redundant model of a mixture of 10 groups for parameter estimation.",4.6. Real-world pedestrian simulator,[0],[0]
"The goal was to detect the active 5 groups of the true model, without knowing that the truth consists of 5 groups.",4.6. Real-world pedestrian simulator,[0],[0]
"For simplicity, 5 (unknown) groups among the 10 candidate groups included the parameters of the true model other than θ∗(N)i , θ ∗(T ) i ; see the Supplementary Materials for details.
",4.6. Real-world pedestrian simulator,[0],[0]
We defined prior distributions as follows.,4.6. Real-world pedestrian simulator,[0],[0]
First we assumed the total number 500 of pedestrians to be known.,4.6. Real-world pedestrian simulator,[0],[0]
"The mixing coefficients of the mixture of 10 groups are given by (φ1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", φ10) =",4.6. Real-world pedestrian simulator,[0],[0]
"(θ (N) 1 , . . .",4.6. Real-world pedestrian simulator,[0],[0]
", θ (N) 10 )/500.",4.6. Real-world pedestrian simulator,[0],[0]
"Thus, rather than directly putting a prior on (θ(N)1 , . .",4.6. Real-world pedestrian simulator,[0],[0]
.,4.6. Real-world pedestrian simulator,[0],[0]
", θ (N) 10 ), we defined a prior on the mixing coefficients (φ1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", φ10).",4.6. Real-world pedestrian simulator,[0],[0]
"Specifically, we used a Dirichlet prior with a small concentration parameter, as in Sec. 4.5, in order to eliminate 5 redundant components:
(φ1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", φ10)",4.6. Real-world pedestrian simulator,[0],[0]
"∼ Dirichlet(α1, ..., α10), θ
(N)",4.6. Real-world pedestrian simulator,[0],[0]
"i := φi ∗ 500, (i = 1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", 10)
where α1 = · · · = α10 = 0.01 denote the concentration 5https://github.com/crest-cassia/CrowdWalk
parameters.",4.6. Real-world pedestrian simulator,[0],[0]
"For each of θ(T )1 , . . .",4.6. Real-world pedestrian simulator,[0],[0]
", θ (T ) 10 , we defined a broad uniform prior θ(T )i ∼ Unif(0, 480).
",4.6. Real-world pedestrian simulator,[0],[0]
"From the true model, we simulated 4200 time steps of pedestrian flow as observed data.",4.6. Real-world pedestrian simulator,[0],[0]
We made 5× 5 = 25 grids in a map of Ginza and computed a histogram of the corresponding 25 bins for each time step.,4.6. Real-world pedestrian simulator,[0],[0]
"Thus, observed data was made up of 4200 vectors in R25.",4.6. Real-world pedestrian simulator,[0],[0]
"In the same way, each method generated a total of 4200 vectors, and each iterative method made use of 200 vectors in each iteration, running 21 iterations in total.",4.6. Real-world pedestrian simulator,[0],[0]
"For SMC-ABC, we set the parameter α ∈ (0, 1) to be 0.2, as in the previous experiment.
",4.6. Real-world pedestrian simulator,[0],[0]
"We ran each method 20 times, and the resulting averages and standard deviations for errors are summarized in Table 4, where “θ(N) error” and “θ(T ) error” denote the errors of the corresponding estimated parameters, as measured in terms of Euclidean distance.",4.6. Real-world pedestrian simulator,[0],[0]
"These errors were computed in the same way as in Sec. 4.5 (e.g., the estimated parameters were sorted according to the magnitudes of the mixing coefficients).",4.6. Real-world pedestrian simulator,[0],[0]
"Results show that our method performed the best, confirming its effectiveness.",4.6. Real-world pedestrian simulator,[0],[0]
"In the Supplementary Materials, we also report the point estimates made using the proposed method, showing that the true parameters were estimated reasonably accurately.",4.6. Real-world pedestrian simulator,[0],[0]
We have proposed kernel recursive ABC for point estimation with intractable likelihood and have empirically investigated the effectiveness of this approach.,5. Summary and future work,[0],[0]
"While we have also provided theoretical analysis to a certain extent, there remain important theoretical topics, as discussed in Sec. 3.1, that we wish to reserve for future research.",5. Summary and future work,[0],[0]
"We thank the anonymous reviewers as well as Itaru Nishioka, Itsuki Noda, Takashi Washio, Shinji Ito, Wittawat Jitkrittum, and Marie Oshima for their helpful comments and support.",Acknowledgements,[0],[0]
We also thank Shuhei Mano for providing his code.,Acknowledgements,[0],[0]
MK has been supported by the European Research Council (StG Project PANAMA).,Acknowledgements,[0],[0]
KF has been supported by JSPS KAKENHI 26280009.,Acknowledgements,[0],[0]
We propose a novel approach to parameter estimation for simulator-based statistical models with intractable likelihood.,abstractText,[0],[0]
Our proposed method involves recursive application of kernel ABC and kernel herding to the same observed data.,abstractText,[0],[0]
"We provide a theoretical explanation regarding why the approach works, showing (for the population setting) that, under a certain assumption, point estimates obtained with this method converge to the true parameter, as recursion proceeds.",abstractText,[0],[0]
"We have conducted a variety of numerical experiments, including parameter estimation for a realworld pedestrian flow simulator, and show that in most cases our method outperforms existing approaches.",abstractText,[0],[0]
Kernel Recursive ABC: Point Estimation with Intractable Likelihood,title,[0],[0]
"1 Kernelized Support Tensor Train Machines Cong Chen, Kim Batselier, Wenjian Yu, Senior Member, IEEE, Ngai Wong, Senior Member, IEEE
Abstract—Tensor, a multi-dimensional data structure, has been exploited recently in the machine learning community. Traditional machine learning approaches are vector- or matrixbased, and cannot handle tensorial data directly. In this paper, we propose a tensor train (TT)-based kernel technique for the first time, and apply it to the conventional support vector machine (SVM) for image classification. Specifically, we propose a kernelized support tensor train machine that accepts tensorial input and preserves the intrinsic kernel property. The main contributions are threefold. First, we propose a TT-based feature mapping procedure that maintains the TT structure in the feature space. Second, we demonstrate two ways to construct the TTbased kernel function while considering consistency with the TT inner product and preservation of information. Third, we show that it is possible to apply different kernel functions on different data modes. In principle, our method tensorizes the standard SVM on its input structure and kernel mapping scheme. Extensive experiments are performed on real-world tensor data, which demonstrates the superiority of the proposed scheme under few-sample high-dimensional inputs.
I. INTRODUCTION
Many real-world data appear in matrix or tensor format. For example, a grayscale picture is a 2-way tensor (i.e. a matrix), a color image or a grayscale video is naturally a 3-way tensor, and a color video can be regarded as a 4- way tensor. In such circumstances, extending the vector-based machine learning algorithms to their tensorial format has recently attracted significant interest in the machine learning and data mining communities.For example, neighborhood preserving embedding (NPE) was extended to tensor neighborhood preserving embedding (TNPE) in [1], principal component analysis to multilinear principal component analysis (MPCA) in [2], support vector machines (SVMs) [3] to support tensor machines (STMs) in [4], and restricted Boltzmann machines to their tensorial formats in [5].
By reformulating the aforementioned machine learning algorithms into the tensorial framework, a huge performance improvement has been achieved. The main reasons for this improvement can be summarized as follows. Firstly, these tensorized algorithms can naturally utilize the multi-way structure of the original tensor data, which is believed to be useful in
This work is partially supported by the Hong Kong Research Grants Council under Project 17246416, the University Research Committee of The University of Hong Kong, Tsinghua University Initiative Scientific Research Program, and NSFC under grant No. 61872206.
Cong Chen is with the Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong. Email: chencong@eee.hku.hk.
Kim Batselier is with the Delft Center for Systems and Control, Delft University of Technology, Delft, Netherlands. Email: k.batselier@tudelft.nl.
Wenjian Yu is with BNRist, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China. Email: yuwj@tsinghua.edu.cn.
Ngai Wong is with the Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong. Email: nwong@eee.hku.hk.
many machine learning applications such as pattern recognition [6], image completion [7] and anomaly detection [8]. Secondly, vectorizing tensor data leads to high-dimensional vectors, which may cause overfitting especially when the training sample size is relatively small [9]. On the contrary, tensor-based approaches usually derive a more structural and robust model that commonly involves much fewer model parameters, which not only alleviates the overfitting problem, but also saves a lot of storage and computation resources [10], [11].
In this paper, we propose a kernelized support tensor train machine (K-STTM) to address few-sample image classification problems due to the fact that collecting labeled pictures is very expensive and time-consuming in many research areas. Specifically, we first employ the tensor train (TT) decomposition [12] to decompose the given tensor data so that a more compact and informative representation of it can be derived. Secondly, we define a TT-based feature mapping strategy to derive a high-dimensional TT in the feature space. This strategy enables us to apply different feature mappings on different data modes, which naturally provides a way to leverage the multi-modal nature of tensor structured data. Thirdly, we propose two ways to build the kernel matrix with the consideration of the consistency with the TT inner product and preservation of information. The constructed kernel matrix is then used by kernel machines to solve the image classification problems.
There are two main advantages from the proposed methods. On the one hand, the proposed methods are naturally nonlinear classifiers. It is common that real-life data are not linearly separable. However, most existing supervised tensor learning methods which employ tensor input are often based on a linear model and cannot deal with nonlinear classification problems. In that case, our proposed methods can handle nonlinear learning problems on tensor data better. On the other hand, conventional tensor-based kernel methods focus on flatting tensor data into matrices [13], [14], and thus can only preserve one-mode relationships within the tensor itself. However, our proposed approaches can capture and exploit multi-mode relationships, which commonly leads to more powerful and accurate models.
The superiority of our methods is validated through extensive experiments. It is observed that our methods achieve a much better performance than the linear supervised tensor learning methods, which indicates the importance of introducing kernel trick. Furthermore, our methods achieve a better classification performance when the input data are truly highdimensional. Applying different kernel functions on different data modes is also investigated and shows an obvious improvement compared with the baseline.
The rest of this paper is organized as follows. In Section II,
ar X
iv :2
00 1.
00 36
0v 1
[ cs
.L G
] 2
J an
2 02
0
2 we briefly review some related works in supervised tensor learning. Some useful notations and tensor arithmetic are further introduced in Section III. In Section IV, we formulate the proposed kernelized support tensor train machine (K-
STTM). Experiments are shown in Section V to validate the superiority of our methods. Lastly, we draw conclusions and propose some possible extended works in Section VI.",text,[0],[0]
"As one of the most typical supervised learning algorithms, SVM [3] has achieved an enormous success in pattern classification by minimizing the Vapnik-Chervonenkis dimensions and structural risk.",II. RELATED WORKS,[0],[0]
"However, a standard SVM can not deal with tensorial input directly.",II. RELATED WORKS,[0],[0]
The first work that extends SVM to handle tensorial input is [4].,II. RELATED WORKS,[0],[0]
"More precisely, a supervised tensor learning (STL) scheme was proposed to train a support tensor machine (STM), where the hyperplane parameters are modeled as a rank-1 tensor instead of a vector.",II. RELATED WORKS,[0],[0]
"For the parameter training, they employed the alternating projection optimization method.
",II. RELATED WORKS,[0],[0]
"Although STM is capable to classify tensorial data directly, the expressive power of a rank-1 weight tensor is limited, which often leads to a poor classification accuracy.",II. RELATED WORKS,[0],[0]
"To increase the model expression capacity, several works were proposed recently based on the STL scheme.",II. RELATED WORKS,[0],[0]
Ref.,II. RELATED WORKS,[0],[0]
"[15] employs a more general tensor structure, i.e., the canonical polyadic (CP) format, to replace the rank-1 weight tensor in STM.",II. RELATED WORKS,[0],[0]
"However, it is an NP-complete problem to determine the CP-rank.",II. RELATED WORKS,[0],[0]
"In [16], the STM is generalized to a support Tucker machine (STuM) by representing the weight parameter as a Tucker tensor.",II. RELATED WORKS,[0],[0]
"Nevertheless, the number of model parameters in STuM is exponentially large, which often leads to a large amount of storage and computation consumption.",II. RELATED WORKS,[0],[0]
"To overcome this, Ref.",II. RELATED WORKS,[0],[0]
"[17] proposed a support tensor train machine (STTM), which assumes the potential weight tensor format is a TT.",II. RELATED WORKS,[0],[0]
"By doing so, the corresponding optimization problem is more scalable and can be solved efficiently.",II. RELATED WORKS,[0],[0]
The aforementioned work are all based on the assumption that the given tensorial data are linearly separable.,II. RELATED WORKS,[0],[0]
"However, this is not the case in most real-world data.",II. RELATED WORKS,[0],[0]
"It is worth noting that though STTM sounds like the linear case of the proposed K-STTM, they are totally different when the linear kernel is applied on K-STTM.",II. RELATED WORKS,[0],[0]
"Specifically, K-STTM and STTM use two totally different schemes to train the corresponding model.",II. RELATED WORKS,[0],[0]
"For KSTTM, it first constructs the kernel matrix with the proposed TT-based kernel function, and then solves the standard SVM problem.",II. RELATED WORKS,[0],[0]
"However, in STTM, it assumes the parameter in the classification hyperplane can be modeled as a TT, and only updates one TT-core at a time by reformulating the training data.
",II. RELATED WORKS,[0],[0]
"To extend the linear tensorial classifiers to the nonlinear case, the authors in [18] proposed a nonlinear supervised learning scheme called dual structure-preserving kernels (DuSK).",II. RELATED WORKS,[0],[0]
"Specifically, based on the CP tensor structure, they define a corresponding kernel trick to map the CP format data into a higher-dimensional feature space.",II. RELATED WORKS,[0],[0]
"Through the introduction of the kernel trick, DuSK can achieve a higher classification
a a A A
Fig. 1: Graphical representation of a scalar a, vector a, matrix A, and third-order tensor A.
I1
I2 I4
I3 I5A B
Fig. 2: Index contraction between two 3-way tensors A and B.
accuracy.",II. RELATED WORKS,[0],[0]
"However, since DuSK is based on the CP decomposition, the NP-complete problem on the rank determination still exists.",II. RELATED WORKS,[0],[0]
"Moreover, through introducing a kernelized CP tensor factorization technique, the same research group in [18] further proposed the Multi-way Multi-level Kernel model [19] and kernelized support tensor machine model [20].",II. RELATED WORKS,[0],[0]
"Nevertheless, the CP-rank determination issue still exists since they are all based on the CP decomposition.
",II. RELATED WORKS,[0],[0]
"To avoid the above issues, we propose the K-STTM, which not only introduces the customized kernel function to handle nonlinear classification problems, but also achieves an efficient model training since the scalable TT format is employed.",II. RELATED WORKS,[0],[0]
"In this Section, we review some basic tensor notations and operations, together with the related tensor train decomposition method.",III. PRELIMINARIES,[0],[0]
Tensors in this paper are multi-dimensional arrays that generalize vectors (first-order tensors) and matrices (secondorder tensors) to higher orders.,A. Tensor basics,[0],[0]
"A dth-order or d-way tensor is denoted as A ∈ RI1×I2×···×Id and the element of A by A(i1, i2 . . .",A. Tensor basics,[0],[0]
", id), where 1≤ ik ≤ Ik, k = 1, 2, . . .",A. Tensor basics,[0],[0]
", d. The numbers I1, I2, . .",A. Tensor basics,[0],[0]
.,A. Tensor basics,[0],[0]
", Id are called the dimensions of the tensor A.",A. Tensor basics,[0],[0]
"We use boldface capital calligraphic letters A, B, . . .",A. Tensor basics,[0],[0]
"to denote tensors, boldface capital letters A, B, . . .",A. Tensor basics,[0],[0]
"to denote matrices, boldface letters a, b, . . .",A. Tensor basics,[0],[0]
"to denote vectors, and roman letters a, b, . . .",A. Tensor basics,[0],[0]
to denote scalars.,A. Tensor basics,[0],[0]
"An intuitive and useful graphical representation of scalars, vectors, matrices and tensors is depicted in Figure 1.",A. Tensor basics,[0],[0]
"The unconnected edges, also called free legs, are the indices of the tensor.",A. Tensor basics,[0],[0]
"Therefore scalars have no free legs, while a matrix has 2 free legs.",A. Tensor basics,[0],[0]
We will employ these graphical representations to visualize the tensor networks and operations in the following sections whenever possible and refer to [21] for more details.,A. Tensor basics,[0],[0]
"We now briefly introduce some important tensor operations.
",A. Tensor basics,[0],[0]
"Definition 1: (Tensor index contraction): A tensor index contraction is the sum over all possible values of the repeated indices in a set of tensors.
3 A(1) A(2) A(d)...",A. Tensor basics,[0],[0]
"R1 R2 R3 Rd Rd+1
I1 I2 Id
Fig. 3: Tensor train decomposition of a d-way tensor A into d 3-way tensors A(1),A(2) . . .",A. Tensor basics,[0],[0]
",A(d).
",A. Tensor basics,[0],[0]
"For example, the following contraction of two 3-way tensors A and B
C(i1, i2, i4, i5) = I3∑ i3=1 A(i1, i2, i3)B(i3, i4, i5),
over the i3 index produces a four-way tensor C. We also present the graphical representation of this contraction in Figure 2, where the summation over i3 is indicated by the connected edge.",A. Tensor basics,[0],[0]
"After this contraction, the tensor diagram contains four free legs indexed by i1, i2, i4, i5, respectively.
",A. Tensor basics,[0],[0]
"Definition 2: (Tensor inner product): For two tensors A,B ∈ RI1×I2×···×Id , their inner product 〈A,B〉 is defined as
〈A,B〉 = I1∑ i1=1 I2∑ i2=1 · · · Id∑ id=1 ai1,i2,··· ,idbi1,i2,··· ,id .
",A. Tensor basics,[0],[0]
"Definition 3: (Tensor Frobenius norm): The Frobenius norm of a tensor A ∈ RI1×I2×···×Id is defined as ||A||F =√ 〈A,A〉.",A. Tensor basics,[0],[0]
Here we briefly introduce the tensor train (TT) decomposition that will be utilized in the proposed K-STTM.,B. Tensor train decomposition,[0],[0]
"A TT decomposition [12] represents a d-way tensor A as d 3-way tensors A(1), A(2), . . .",B. Tensor train decomposition,[0],[0]
", A(d) such that a particular entry of A is written as the matrix product
A(i1, . . .",B. Tensor train decomposition,[0],[0]
", id) = A(1)(:, i1, :) · · ·A(d)(:, id, :), (1)
where A(k)(:, ik, :) is naturally a matrix since we fix the second index.",B. Tensor train decomposition,[0],[0]
"Each tensor A(k), k = 1, . . .",B. Tensor train decomposition,[0],[0]
", d, is called a TT-core and has dimensions Rk × Ik ×Rk+1.",B. Tensor train decomposition,[0],[0]
"Storage of a tensor as a TT therefore reduces from
∏d i=1",B. Tensor train decomposition,[0],[0]
Ri down,B. Tensor train decomposition,[0],[0]
"to∑d
i=1 RiIiRi+1.",B. Tensor train decomposition,[0],[0]
In order for the left-hand-side of (1) to be a scalar we require that R1 = Rd+1 = 1.,B. Tensor train decomposition,[0],[0]
The remaining Rk values are called the TT-ranks.,B. Tensor train decomposition,[0],[0]
"Figure 3 demonstrates how TT-decomposition decomposes a d-way tensor A, where the edges connecting the different circles indicate the matrixmatrix products of (1).",B. Tensor train decomposition,[0],[0]
"To simplify the statement, we define the notation TT (·), which means perform TT decomposition on a d-way tensor.",B. Tensor train decomposition,[0],[0]
"For example, TT (A) is the resulting TT after doing TT decomposition on the full tensor A, namely, A(1), A(2), · · · , A(d) are derived.
",B. Tensor train decomposition,[0],[0]
"Definition 4: (TT inner product): The inner product between two tensor trains TT (A) and TT (B) is denoted as 〈TT (A), TT (B)〉.",B. Tensor train decomposition,[0],[0]
The tensor network diagram of the inner product of two TTs is shown in Figure 4.,B. Tensor train decomposition,[0],[0]
"The lack of unconnected edges in Figure 4 implies that 〈TT (A), TT (B)〉 is a scalar.
A(1) A(2) A(d)
B(1) B(2) B(d)
...
...
",B. Tensor train decomposition,[0],[0]
Fig. 4: The inner product between two d-way tensor trains.,B. Tensor train decomposition,[0],[0]
"Since this work is based on traditional SVM, we therefore briefly review the main idea of an SVM.",C. Support vector machines,[0],[0]
"Assume we have a dataset D={xi, yi}Mi=1 of M labeled samples, where xi ∈ Rn are the vectorized data samples with labels yi ∈ {−1, 1}.",C. Support vector machines,[0],[0]
"The goal of an SVM is to find a discriminant hyperplane
f(x) = wTx + b (2)
that maximizes the margin between the two classes where w and b are the weight vector and bias, respectively.",C. Support vector machines,[0],[0]
"However, an SVM is very sensitive to noise since it requires all the training samples to meet the hard margin constraint.",C. Support vector machines,[0],[0]
"In that case, the trained model tends to overfit.",C. Support vector machines,[0],[0]
"To solve this, slack variables ξ1, . . .",C. Support vector machines,[0],[0]
", ξM are introduced to allow some certain samples to be misclassified, thus enhancing the robustness of the trained model.",C. Support vector machines,[0],[0]
"We can express the learning problem as a quadratic optimization problem
min w,b,ξ
1 2 ||w||2F + C M∑ i=1",C. Support vector machines,[0],[0]
"ξi
subject to yi(wTxi + b) ≥ 1− ξi, ξi ≥ 0, i = 1, . . .",C. Support vector machines,[0],[0]
",M. (3)
",C. Support vector machines,[0],[0]
The parameter C controls the trade-off between the size of the weight vector w and the size of the slack variables.,C. Support vector machines,[0],[0]
"It is more common to solve the dual problem of (3), especially when the feature size n is larger than the sample size M .",C. Support vector machines,[0],[0]
"The dual problem format of (3) is
min α1,α2,··· ,αM M∑ i=1",C. Support vector machines,[0],[0]
αi− 1 2 M∑,C. Support vector machines,[0],[0]
"i,j=1 αiαjyiyj〈xi,xj〉
subject to M∑ i=1",C. Support vector machines,[0],[0]
αiyi,C. Support vector machines,[0],[0]
"= 0,
0 ≤ αi ≤ C, i = 1, . . .",C. Support vector machines,[0],[0]
",M, (4)
where 〈xi,xj〉 represents the inner product between vector xi and xj and αi (i = 1, . . .",C. Support vector machines,[0],[0]
",M) are the Lagrange multipliers.
",C. Support vector machines,[0],[0]
"To solve a nonlinear classification problem with SVM, researchers further introduced the kernel trick that projects the original vectorial data onto a much higher-dimensional feature space through a nonlinear mapping function φ.",C. Support vector machines,[0],[0]
"In the feature space, the data generally become more (linearly) separable.",C. Support vector machines,[0],[0]
"By doing so, the optimization in (4) is transformed into
min α1,α2,··· ,αM M∑ i=1",C. Support vector machines,[0],[0]
αi− 1 2 M∑,C. Support vector machines,[0],[0]
"i,j=1 αiαjyiyj〈φ(xi), φ(xj)〉 (5)
4 with the same constraints as in (4).",C. Support vector machines,[0],[0]
"It turns out that it is possible to make the computation easier by replacing the inner product term 〈φ(xi), φ(xj)〉 with a kernel function k(xi,xj).",C. Support vector machines,[0],[0]
"In that case, the inner product in the high-dimensional feature space can be computed without the need to explicitly compute the mappings φ(xi), φ(xj).",C. Support vector machines,[0],[0]
"In this section, we first demonstrate the tensor-based kernel learning problem and then introduce the proposed K-STTM.",IV. KERNELIZED SUPPORT TENSOR TRAIN MACHINES,[0],[0]
"Given M tensorial training data and their labels, i.e., dataset D = {X i, yi}Mi=1, where X",A. Problem statement,[0],[0]
i ∈,A. Problem statement,[0],[0]
"RI1×I2×···×Id and yi ∈ {−1, 1}, we want to find a hyperplane
f(X ) = 〈W ,X 〉+ b",A. Problem statement,[0],[0]
(6) that separates the tensorial data into two classes.,A. Problem statement,[0],[0]
W is the hyperplane weight tensor with the same dimensions as X i and b is the bias.,A. Problem statement,[0],[0]
"Similar to the primal problem in SVM, we can derive the corresponding primal optimization problem for (6)
min W,b,ξ
1 2 ||W ||2F + C M∑ i=1",A. Problem statement,[0],[0]
"ξi
subject to yi(〈W ,X i〉+ b) ≥ 1− ξi, ξi ≥ 0, i = 1, . .",A. Problem statement,[0],[0]
.,A. Problem statement,[0],[0]
",M. (7)
",A. Problem statement,[0],[0]
"Following the scheme of the kernel trick for conventional SVMs, we introduce a nonlinear feature mapping function Φ(·).",A. Problem statement,[0],[0]
"Then, given a tensor X ∈ RI1×I2×···×Id , we assume it is mapped into the Hilbert space H by
Φ : X → Φ(X ) ∈ RH1×H2×···×Hd .",A. Problem statement,[0],[0]
(8) We need to mention that the dimension of projected tensor Φ(X ) can be infinite depending on the feature mapping function Φ(·).,A. Problem statement,[0],[0]
"The resulting Hilbert space is then called the tensor feature space and we can further develop the following model
min W,b,ξ
1 2 ||W ||2F + C M∑ i=1",A. Problem statement,[0],[0]
"ξi
subject to yi(〈W ,Φ(X i)〉+ b) ≥ 1− ξi, ξi ≥ 0, i = 1, . . .",A. Problem statement,[0],[0]
",M, (9)
with parameter tensor W ∈ RH1×H2×···×Hd .",A. Problem statement,[0],[0]
This model is naturally a linear classifier on the tensor feature space.,A. Problem statement,[0],[0]
"However, when we map the classifier back to the original data space, it is a nonlinear classifier.",A. Problem statement,[0],[0]
"To obtain the tensor-based kernel optimization model, we need to transfer model (9) into its dual, namely
min α1,α2,··· ,αM M∑ i=1",A. Problem statement,[0],[0]
αi− 1 2 M∑,A. Problem statement,[0],[0]
"i,j=1 αiαjyiyj〈Φ(X i),Φ(X j)〉
subject to M∑ i=1",A. Problem statement,[0],[0]
αiyi,A. Problem statement,[0],[0]
"= 0,
0 ≤ αi ≤ C, i = 1, . .",A. Problem statement,[0],[0]
.,A. Problem statement,[0],[0]
",M, (10)
where αi are the Lagrange multipliers.",A. Problem statement,[0],[0]
The key task we need to solve is to define a tensorial kernel function,A. Problem statement,[0],[0]
"K(X i,X j) that computes the inner product 〈Φ(X i),Φ(X j)〉 in the original data space instead of the feature space.",A. Problem statement,[0],[0]
"Although tensor is a natural structure for representing realworld data, there is no guarantee that such a representation works well for kernel learning.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Instead of the full tensor, here we employ a TT for data representation due to the following reasons:
1) Real-life data often contain redundant information, which is not useful for kernel learning.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
The TT decomposition has proven to be efficient for removing the redundant information in the original data and provides a more compact data representation.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
2),B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Compared to the Tucker decomposition whose storage scales exponentially with the core tensor, a TT is more scalable (parameter number grows linearly with the tensor order d), which reduces the computation during kernel learning.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"3) Unlike the CP decomposition, determining the TT-rank is easily achieved through a series of singular value decompositions (TT-SVD [12] ).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
This naturally leads to a faster data transformation to the TT format.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
4),B. Customized kernel mapping schemes for TT-based data,[0],[0]
It is convenient to implement different operations on different tensor modes when data is in the TT format.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Since a TT decomposition decomposes the original data into many TT cores, it is possible to apply different kernel functions on different TT cores for a better classification performance.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Furthermore, we can emphasize the importance of different tensor modes by putting different weights on those TT cores during the kernel mapping.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"For example, a color image is a 3-way (pixel-pixel-color) tensor.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"The color mode can be treated differently with the two pixel modes since they contain different kinds of information, as will be exemplified later.
",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"In the following, we demonstrate the proposed TT-based feature mapping approach.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Specifically, we map all fibers in each TT-core to the feature space, namely
Φ : X (i)(ri, :, ri+1)→ Φ(X (i)(ri, :, ri+1))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"∈ RHi
1 ≤",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"ri ≤ Ri, i = 1, . . .",B. Customized kernel mapping schemes for TT-based data,[0],[0]
", d, (11)
where X (i) and Ri are the i-th TT-core and TT-rank of TT (X ), respectively.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"The fibers of each TT-core are naturally vectors, so the feature mapping works in the same way as for the conventional SVM.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"We then represent the resulting high-dimensional TT, which is in the tensor feature space, as Φ(TT (X ))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
∈ RH1×H2×···×Hd .,B. Customized kernel mapping schemes for TT-based data,[0],[0]
We stress that Φ(TT (X )) is still in a TT format with the same TT-ranks as TT (X ).,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"In this sense, the TT format data structure is preserved after the feature mapping.
",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"After mapping the TT format data into the TT-based highdimensional feature space, we then demonstrate the two proposed approaches for computing the inner product between two mapped TT format data using kernel function.
5 1) K-STTM-Prod:",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"The first method is called K-STTM-Prod since we implement consecutive multiplication operations on d fiber inner products, which is consistent with the result of an inner product between two TTs.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
Assuming Φ(TT (X )),B. Customized kernel mapping schemes for TT-based data,[0],[0]
and,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Φ(TT (Y)) ∈ RH1×H2×···×Hd with TT-ranks Ri and R̂i, i = 1, 2, . . .",B. Customized kernel mapping schemes for TT-based data,[0],[0]
", d, respectively, their inner product can be computed from
〈Φ(TT (X )),Φ(TT (Y))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"〉 = R1∑ r1=1 · · · Rd∑ rd=1 R̂1∑ r̂1=1 · · · R̂d∑ r̂d=1
( d∏ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"〈Φ(X (i)(ri, :, ri+1)),Φ(Y(i)(r̂i, :, r̂i+1))〉).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"(12)
We remark that (12) derives the exact same result as Figure 4 (assuming X = A and Y = B) when an identity feature mapping function Φ(·) is used, namely Φ(TT (X ))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
=TT (X ).,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"What is more, since each fiber of a mapped TT-core is naturally a vector, we have
〈Φ(X (i)(ri, :, ri+1)),Φ(Y(i)(r̂i, :, r̂i+1))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"〉 = K(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1)), (13)
where K(·) can be any kernel function used for a standard SVM, such as a Gaussian RBF kernel, polynomial kernel, linear kernel etc.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Combining (12) and (13), we obtain the corresponding TT-based kernel function
K(TT (X ), TT (Y))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"= R1∑ r1=1 · · · Rd∑ rd=1 R̂1∑ r̂1=1 · · · R̂d∑ r̂d=1
( d∏ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"K(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1))).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"(14)
As mentioned before, different kernel functions can be applied on different tensor modes i = 1, 2, . . .",B. Customized kernel mapping schemes for TT-based data,[0],[0]
", d. Therefore, the second line in (14) can be generalized to
( d∏ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Ki(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1))).
",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"One possible application is in color image classification, where one could apply Gaussian RBF kernels K1 and K2 on its first two spatial modes, while choosing a linear or polynomial kernel K3 for the color mode.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"This will be investigated in the experiments.
2) K-STTM-Sum: The second method we propose to construct a TT kernel function is called K-STTM-Sum.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Instead of implementing consecutive multiplication operations on d fiber inner products like in K-STTM-Prod, K-STTM-Sum performs consecutive addition operations on them.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
This idea is inspired by [22] which argues that the product of inner products can lead to the loss/misinterpretation of information.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Take the linear kernel as an example, the inner product between two fibers of the same mode could be negative, which indicates a low similarity between those two fibers.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"However, by implementing consecutive multiplication operations on d fiber inner products, highly negative values could result in a large positive value.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"In that case, the overall similarity is high which is clearly unwanted.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"This situation also appears
when employing Gaussian RBF kernels.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"A nearly zero value would be assigned to two non-similar fibers, which could influence the final result significantly.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"To this end, we propose the K-STTM-Sum.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Similar to K-STTM-Prod, we can obtain the corresponding kernel function as
K(TT (X ), TT (Y))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"= R1∑ r1=1 · · · Rd∑ rd=1 R̂1∑ r̂1=1 · · · R̂d∑ r̂d=1
( d∑ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Ki(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1))).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
(15),B. Customized kernel mapping schemes for TT-based data,[0],[0]
"After defining the TT-based kernel function, we can then replace the term 〈Φ(X i),Φ(X j)〉 in (10) with (14) or (15), and derive our final kernel optimization problem based on the TT structure, namely,
min α1,α2,··· ,αM M∑ i=1",C. Kernel optimization problem,[0],[0]
αi− 1 2 M∑,C. Kernel optimization problem,[0],[0]
"i,j=1 αiαjyiyjK(TT",C. Kernel optimization problem,[0],[0]
"(X i), TT (X j))
subject to M∑ i=1",C. Kernel optimization problem,[0],[0]
αiyi,C. Kernel optimization problem,[0],[0]
"= 0,
0 ≤ αi ≤ C, i = 1, . . .",C. Kernel optimization problem,[0],[0]
",M. (16)
",C. Kernel optimization problem,[0],[0]
"After solving (16), we can get the unknown model parameters α1, α2, . . .",C. Kernel optimization problem,[0],[0]
", αM and the resulting decision function is then represented as
f(X )",C. Kernel optimization problem,[0],[0]
= sign( M∑ i=1,C. Kernel optimization problem,[0],[0]
αiyiK(TT,C. Kernel optimization problem,[0],[0]
"(X i), TT (X ))",C. Kernel optimization problem,[0],[0]
+ b).,C. Kernel optimization problem,[0],[0]
"(17)
Here we take the Gaussian RBF kernel as an example and summarize the training algorithm of the K-STTM-Prod/Sum as pseudo-code in Algorithm 1.",C. Kernel optimization problem,[0],[0]
An alternative for doing a grid search to find optimal hyperparameters would be crossvalidation.,C. Kernel optimization problem,[0],[0]
"Generalizing the binary classification to multiclassification can be easily achieved by utilizing a one-vs-one or one-vs-all strategy, namely, we can build several binary classifiers to do multi-class classification.",C. Kernel optimization problem,[0],[0]
"A key property of kernel function in standard SVM is that the resulting kernel matrix is positive semi-definite, which guarantees the mapped high-dimensional feature space is truly an inner product space.",D. Kernel validity,[0],[0]
"Therefore, we provide Theorem 1 to show the validity of K-STTM-Prod and K-STTM-Sum.
Theorem 1: Kernel functions K-STTM-Prod and K-STTMSum produce positive semi-definite kernel matrices.
",D. Kernel validity,[0],[0]
We provide the proof here.,D. Kernel validity,[0],[0]
1) Validity of K-STTM-Prod:,D. Kernel validity,[0],[0]
We first demonstrate the kernel function validity of K-STTM-Prod.,D. Kernel validity,[0],[0]
The goal is to show that the final kernel matrix constructed by (14) is positive semidefinite.,D. Kernel validity,[0],[0]
"In the actual implementation, it is extremely inefficient to use TT decomposition to decompose each tensorial sample one by one.",D. Kernel validity,[0],[0]
"The way we did it is by first stacking all
6 Algorithm 1 K-STTM-Prod/Sum Algorithm
Input: Training dataset {X i ∈ RI1×···×Id , yi ∈ {−1, 1}}Mi=1; Validation dataset {X j ∈ RI1×···×Id , yj ∈ {−1, 1}}Nj=1; The pre-set TT-ranks R1, R2, . . .",D. Kernel validity,[0],[0]
", Rd+1; The range of the performance trade-off parameter C and kernel width parameter σ, namely [Cmin, Cmax], and [σmin, σmax].",D. Kernel validity,[0],[0]
"Output: The Lagrange multipliers α1, α2, . . .",D. Kernel validity,[0],[0]
", αM ; The bias b.
1: Compute the TT approximation of training samples {X i}Mi=1 and validation set {X j}Nj=1 with the given TTranks using TT-SVD.",D. Kernel validity,[0],[0]
2: for C from Cmin to Cmax do 3: for σ from σmin to σmax do 4:,D. Kernel validity,[0],[0]
"Apply Gaussian RBF kernel on all the tensor modes,
and construct the kernel matrix according to (14) or (15), which are corresponding to K-STTM-Prod and K-STTM-Sum, respectively.
5: Solve (16) using the resulting kernel matrix.",D. Kernel validity,[0],[0]
6: Compute the classification accuracy on validation set.,D. Kernel validity,[0],[0]
"7: end for 8: end for 9: Find the best C and σ according to the classification
accuracy on validation set.",D. Kernel validity,[0],[0]
"10: Train the K-STTM with the best C and σ by imple-
menting step 4 and 5.",D. Kernel validity,[0],[0]
"Thus the the Lagrange multipliers α1, α2, . . .",D. Kernel validity,[0],[0]
", αM and the bias b are obtained.
",D. Kernel validity,[0],[0]
the d-way samples and then compute a TT decomposition on the resulting (d+ 1)-way tensor directly.,D. Kernel validity,[0],[0]
"By doing so, all TTbased training samples have the same TT-ranks.",D. Kernel validity,[0],[0]
"Also in the case where we compute the TT decomposition separately for each sample, we can still set the TT-ranks of all samples to be identical.",D. Kernel validity,[0],[0]
"That means Ri is equal to R̂i, i = 1, 2, . . .",D. Kernel validity,[0],[0]
", d for all the TT-based training samples.",D. Kernel validity,[0],[0]
We can then compute the final kernel matrix by doing R21×. .,D. Kernel validity,[0],[0]
.×R2d,D. Kernel validity,[0],[0]
"matrix summations, while each matrix in the summation procedure is computed by d times matrix Hadamard product.",D. Kernel validity,[0],[0]
"The matrix factors in the d times Hadamard product are valid kernel matrices since they are computed using the standard kernel function.
",D. Kernel validity,[0],[0]
"Through the above analysis, the goal now transforms into proving that the summation or Hadamard product between two positive semi-definite matrices A and B ∈ Rn×n still results in a positive semi-definite matrix.
",D. Kernel validity,[0],[0]
"For the summation case, we have{ uTAu ≥ 0, uTBu ≥ 0.
(18)
for every non-zero column vector u ∈ Rn.",D. Kernel validity,[0],[0]
"Obviously we can conclude that
uT (A+B)u ≥ 0, (19)
namely A + B is still positive semi-definite.",D. Kernel validity,[0],[0]
"For the Hadamard product case, we refer to the the Schur product theorem [23] and we can easily obtain
uT (A B)u ≥ 0, (20)
for every non-zero column vector u ∈",D. Kernel validity,[0],[0]
"Rn, where is the Hadamard product.",D. Kernel validity,[0],[0]
"Thus A B is still positive semi-definite.
",D. Kernel validity,[0],[0]
"Through the above analysis, we can conclude that by constraining the TT-based training samples to have identical TT-ranks, we can get a valid kernel matrix using K-STTMProd.
2) Validity of K-STTM-Sum: The proof for the validity of K-STTM-Sum is similar as it for K-STTM-Prod.",D. Kernel validity,[0],[0]
The difference between kernel functions (14) and (15) is that (15) only replaces the product with a summation.,D. Kernel validity,[0],[0]
"In that case, for K-STTM-Sum, the final kernel matrix is produced by the summation of a set of valid positive semi-definite matrices.",D. Kernel validity,[0],[0]
"Namely, we can still get a valid kernel matrix using K-STTMSum.",D. Kernel validity,[0],[0]
"Here we demonstrate the convergence analysis of our proposed methods and compare the storage and computation complexity with the standard SVM.
",E. Convergence and complexity,[0],[0]
"For the convergence analysis, it is same as it in standard SVM problem.",E. Convergence and complexity,[0],[0]
We already show the kernel validity of (14) and (15) in Theorem 1.,E. Convergence and complexity,[0],[0]
"With a valid kernel matrix, we can solve a quadratic programming problem to get the Lagrange multipliers αi and bias b, which is same as the procedure in standard SVM.",E. Convergence and complexity,[0],[0]
"Consequently, the convergence analysis is exactly same as it in standard SVM.
",E. Convergence and complexity,[0],[0]
"For the storage complexity analysis, the original tensorial sample storage is O(MId), where I is the maximum value of Ii, i = 1, 2, . . .",E. Convergence and complexity,[0],[0]
", d.",E. Convergence and complexity,[0],[0]
"After representing the original tensorial data as TTs, the data storage becomes to O(MdIR2), where R is the maximum TT-rank.",E. Convergence and complexity,[0],[0]
"This shows a great reduction especially when the data order d is large.
",E. Convergence and complexity,[0],[0]
"For the computation complexity, the overall result of KSTTM-Prod is the same as the result of K-STTM-Sum if we neglect those low-order polynomial terms.",E. Convergence and complexity,[0],[0]
This can be observed from (14) and (15).,E. Convergence and complexity,[0],[0]
The main computation costs are similar in those two equations.,E. Convergence and complexity,[0],[0]
Therefore we just analyze the K-STTM-Prod method.,E. Convergence and complexity,[0],[0]
"The computational complexity of constructing the kernel matrix in standard SVM is O(M2Id), where n is the maximum dimension of Ii, i = 1, 2, ...",E. Convergence and complexity,[0],[0]
"d. When applying the accelerating implementation of K-STTMProd, its kernel matrix computation complexity is O(dI2R4 + M2IdR 2 d), where I and R are the maximum values of Ii and Ri, i = 1, 2, ...",E. Convergence and complexity,[0],[0]
d,E. Convergence and complexity,[0],[0]
"− 1, respectively.",E. Convergence and complexity,[0],[0]
"Real-world data is commonly low-rank, so the TT-ranks Ri are generally small.",E. Convergence and complexity,[0],[0]
"Moreover, their dimensions Ii are very high.",E. Convergence and complexity,[0],[0]
That indicates our proposed method is more efficient than its vector counterpart since the computation complexity is reduced from exponential to polynomial.,E. Convergence and complexity,[0],[0]
"We evaluate the effectiveness of the two proposed schemes, K-STTM-Prod and K-STTM-Sum, on real-world tensorial datasets and contrast our methods with the following seven methods as a baseline.",V. EXPERIMENTS,[0],[0]
"• SVM: SVM [3] is one of the most widely used vector-
based method for classification.",V. EXPERIMENTS,[0],[0]
"What is more, the proposed K-STTM is a tensorial extension of SVM, so SVM
7 is selected as a baseline.",V. EXPERIMENTS,[0],[0]
"We employ the widely used convex optimization solver CVX∗ to solve the quadratic programming problem.
",V. EXPERIMENTS,[0],[0]
"• STM: STM [4] is the first method which extends SVM to the tensorial format, which employs alternating optimization scheme to update the weight tensors and outperforms kernel SVM in some tasks.",V. EXPERIMENTS,[0],[0]
• STuM:,V. EXPERIMENTS,[0],[0]
It is a kind of support tensor machine which is based on the Tucker decomposition [16].,V. EXPERIMENTS,[0],[0]
The training procedure is similar as the one in STM. •,V. EXPERIMENTS,[0],[0]
"STTM: STTM [17] assumes the weight tensor is a scalable tensor train, which enables STTM to deal with high-dimensional data classification.",V. EXPERIMENTS,[0],[0]
"STM, STuM, and STTM are all tensor-based linear classifiers.",V. EXPERIMENTS,[0],[0]
"In very small sample size problem, sometimes linear classifier are observed to achieve a better classification accuracy than nonlinear classifier [18] since a linear classifier is commonly less complex and more stable and can be better trained than nonlinear classifiers.",V. EXPERIMENTS,[0],[0]
• DuSK: DuSK is a kernelized support tensor machine using the CP decomposition [18].,V. EXPERIMENTS,[0],[0]
"Through introducing the kernel trick, it can deal with nonlinear classification tasks.",V. EXPERIMENTS,[0],[0]
• 3D CNN:,V. EXPERIMENTS,[0],[0]
CNN is one of the most powerful structure for image classification.,V. EXPERIMENTS,[0],[0]
The 3D CNN we employ here is an extension of the 2D version in [24].,V. EXPERIMENTS,[0],[0]
We replace the 2D convolutional kernels with 3D ones and keep other settings the same.,V. EXPERIMENTS,[0],[0]
"Though 3D CNN is a relatively simple CNN model, it has an advantage in dealing with small sample size problems since it can be trained better than the complicated CNN model.",V. EXPERIMENTS,[0],[0]
• TT Classifier:,V. EXPERIMENTS,[0],[0]
"As an updated tensor classification method, TT classifier [25] trains a TT as a polynomial classifier and achieves good results on tensorial image classification tasks.
",V. EXPERIMENTS,[0],[0]
"For simplicity, all of the kernel based methods, i.e., SVM, DuSK, and K-STTM, employ the Gaussian RBF kernel.",V. EXPERIMENTS,[0],[0]
"The optimal parameters, namely the performance trade-off parameter C, RBF kernel parameter σ, hidden layer size in 3D CNN, plus the corresponding tensor rank in STuM, STTM, DuSK, TT classifier and K-STTM, are determined through a grid search.",V. EXPERIMENTS,[0],[0]
The detail of the hyperparameter search schemes of all methods in all experiments are demonstrated in Appendix.,V. EXPERIMENTS,[0],[0]
"First, our proposed methods are compared with the above methods on the well-known MNIST dataset [26], which has a training set of 60k samples and a testing set of 10k samples.",A. MNIST,[0],[0]
"Each sample is a 28 × 28 grayscale image of a handwritten digit {0, . . .",A. MNIST,[0],[0]
", 9}.",A. MNIST,[0],[0]
"Although there are total 60k training samples, we care more about the small sample size problem.",A. MNIST,[0],[0]
"Thus for each class, we randomly choose 50 samples for model training and another 50 for validation.",A. MNIST,[0],[0]
All test samples in each class are used for checking the classification performance of each trained model.,A. MNIST,[0],[0]
"Since an SVM is naturally a binary classifier,
∗http://cvxr.com/cvx/
we randomly choose 10 digit pairs out of 45 to check the classification accuracy.
",A. MNIST,[0],[0]
Table I shows the classification results on different digit pairs.,A. MNIST,[0],[0]
"DuSK achieves the lowest accuracy among all the methods , which may be caused by the CP-rank searching: Finding a good CP-rank is an NP-complete problem, so DuSK may perform poorly if it fails to do so.",A. MNIST,[0],[0]
"Due to the naturally linearity of STM, STuM and STTM, they also can not achieve a good classification accuracy on real-world data.",A. MNIST,[0],[0]
"TT classifier even achieves a very poor classification performance on some digit pairs since it is naturally a polynomial classifier, whose classification power is limited.",A. MNIST,[0],[0]
We notice that the two proposed approaches K-STTM-Prod and K-STTM-Sum only achieve a slightly better accuracy than SVM and 3D CNN on some digit pairs.,A. MNIST,[0],[0]
The main reason that SVM and 3D CNN perform very well also is that MNIST is a relatively small dataset.,A. MNIST,[0],[0]
"The data dimension is 784 only, thus conventional SVM and 3D CNN do not encounter the curse of dimensionality and no overfitting occurs.",A. MNIST,[0],[0]
The advantage of tensorial methods are expected to be more apparent when the problem is truly high-dimensional.,A. MNIST,[0],[0]
"We therefore consider in the second experiment fMRI image data, whose dimensions are higher than 32k.
",A. MNIST,[0],[0]
We also investigate the influence of the TT-rank on the classification accuracy.,A. MNIST,[0],[0]
Figure 5 shows how the classification accuracy of K-STTM-Prod and K-STTM-Sum changes along with increasing TT-rank on two randomly selected digit pairs.,A. MNIST,[0],[0]
"We can observe that K-STTM with a small TT-rank can achieve a similar classification performance when it with high TT-rank, and the highest accuracies are all achieved when TTrank is around 5, which means we can select a relatively small TT-rank R to reduce the cost of kernel computation, while at the same time keep the classification performance.",A. MNIST,[0],[0]
This validates the computation complexity analysis in Section IV-E since the R and Rd in O(dI2R4 +M2IdR2d) are often small.,A. MNIST,[0],[0]
"As we mentioned in experiment V-A, tensorial method shows more apparent advantages on high-dimensional dataset.",B. fMRI datasets,[0],[0]
"Thus we consider two high-dimensional fMRI datasets, namely the StarPlus fMRI dataset† and the CMU Science 2008 fMRI dataset (CMU2008)",B. fMRI datasets,[0],[0]
[27] to evaluate the classification performance of different models.,B. fMRI datasets,[0],[0]
An fMRI image is essentially a 3-way tensor.,B. fMRI datasets,[0],[0]
"Figure 6 from [18] illustrates the tensorial structure of the fMRI image.
1) StarPlus fMRI dataset:",B. fMRI datasets,[0],[0]
"The fMRI images in StarPlus dataset are with dimensions 64 × 64 × 8 that contains 25 to 30 anatomically defined regions (called“Regions of Interest”, or ROIs).",B. fMRI datasets,[0],[0]
"To achieve a better classification accuracy, we only consider the following ROIs: ‘CALC’ ‘LIPL’ ‘LT’ ‘LTRIA’ ‘LOPER’ ‘LIPS’ ‘LDLPFC’.",B. fMRI datasets,[0],[0]
"After extracting those ROIs, we further normalize the data of each subject.",B. fMRI datasets,[0],[0]
StarPlus fMRI dataset contains the brain images of 6 human subjects.,B. fMRI datasets,[0],[0]
"The data of each human subject is partitioned into trials, and each subject has 40 effective trials.",B. fMRI datasets,[0],[0]
"Here we only use the first 4 seconds of each trial since the subject was shown one kind of
†http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-81/www/
8
TABLE",B. fMRI datasets,[0],[0]
I:,B. fMRI datasets,[0],[0]
"Classification accuracy of different methods for different MNIST digit pairs.
",B. fMRI datasets,[0],[0]
Digit pair SVM STM STuM STTM DuSK,B. fMRI datasets,[0],[0]
"3D CNN TT classiifer K-STTM-Prod K-STTM-Sum
{‘1’,‘2’} 98.15% 94.09% 97.96% 97.69% 89.16% 98.20% 73.93% 99.22% 99.27% {‘1’,‘7’} 97.73% 96.62% 97.87% 97.83% 80.95% 98.19% 96.99% 98.34% 98.20% {‘1’,‘8’} 96.49% 93.78% 95.92% 96.30% 87.63% 97.24% 84.48% 97.97% 98.06% {‘2’,‘4’} 98.36% 96.32% 97.46% 97.52% 77.26% 96.27% 93.45% 99.01% 98.61% {‘2’,‘7’} 96.41% 94.46% 95.58% 95.58% 81.26% 94.22% 94.22% 97.09% 96.95% {‘4’,‘6’} 97.16% 97.57% 97.47% 97.42% 78.66% 96.18% 93.71% 98.30% 97.74% {‘4’,‘9’} 89.50% 86.53% 90.65% 90.86% 68.46% 91.91% 59.12% 93.27% 91.77% {‘5’,‘6’} 96.00% 95.29% 95.24% 94.92% 75.78% 92.75% 88.16% 96.49% 96.76% {‘5’,‘8’} 86.92% 78.18% 91.47% 88.10% 70.69% 90.46% 63.56% 94.32% 91.59% {‘7’,‘8’} 94.46% 92.30% 95.85% 95.40% 75.97% 94.30% 94.46% 96.76% 96.16%
TABLE II:",B. fMRI datasets,[0],[0]
"Classification accuracy of different methods for different subjects in StarPlus fMRI datasets.
",B. fMRI datasets,[0],[0]
"Subject SVM STM STuM STTM DuSK 3D CNN TT classifier K-STTM-Prod K-STTM-Sum
04799 50.00%∗ 36.67% 35.83% 39.61% 47.50% 51.67% 57.50% 68.33% 66.67% 04820 50.00%∗ 43.33% 35.00% 45.83% 46.67% 44.16% 54.17% 70.00% 62.50% 04847 50.00%∗ 38.33% 17.50% 47.50% 53.33% 55.00% 61.67% 65.00% 65.00% 05675",B. fMRI datasets,[0],[0]
"50.00%∗ 37.50% 30.83% 35.00% 55.00% 47.50% 55.00% 60.00% 60.00% 05680 50.00%∗ 38.33% 39.17% 40.00% 64.17% 68.33% 60.83% 73.33% 75.00% 05710 50.00%∗ 40.00% 30.00% 43.33% 54.16% 47.50% 53.33% 59.17% 58.33% ∗ SVM classifies all test samples into one class since no good hyperparameter setting can be found by grid search.
",B. fMRI datasets,[0],[0]
Fig. 5: Classification accuracy of K-STTM-Prod and K-STTM-Sum with different TT-rank on two randomly selected digit pairs.,B. fMRI datasets,[0],[0]
"Top figure: digit pair ‘1’,‘2’; bottom figure: digit pair ‘5’,‘6’.
stimulus (sentence or picture) during the whole period.",B. fMRI datasets,[0],[0]
"The fMRI images were collected every 500 msec, thus we can utilize 8 fMRI images in each trial.",B. fMRI datasets,[0],[0]
"Overall, we have 320 fMRI images: one half of them were collected when the subject was shown a picture, the other half were collected when the subject was shown a sentence, while we randomly select 140 images for training, 60 for validation and the left for testing.
",B. fMRI datasets,[0],[0]
The classification results are listed in Table II.,B. fMRI datasets,[0],[0]
"Due to the very high-dimensional and sparse data, SVM fails to find a good hyperparameter setting thus can not do classification.",B. fMRI datasets,[0],[0]
"Since fMRI data are very complicated, those linear classifiers, namely STM, STuM and STTM, can not achieve an acceptable performance, and the classification accuracies of them are all
Fig. 6: fMRI images from [18].",B. fMRI datasets,[0],[0]
"(a) An illustration of a 3-way tensor (fMRI image), (b) Visualization of an fMRI image.
lower than 50%.",B. fMRI datasets,[0],[0]
The classification result of TT classifier is poor on several subjects.,B. fMRI datasets,[0],[0]
DuSK also performs poor on subjects ‘04799’ and ‘04820’.,B. fMRI datasets,[0],[0]
"Due to the small number of training samples and high-dimensional data size, the 3D CNN overfits and can not be well trained, while our proposed two methods still achieve the highest classification accuracy on all human subjects.
",B. fMRI datasets,[0],[0]
2) CMU2008:,B. fMRI datasets,[0],[0]
The second fMRI dataset we consider is CMU2008.,B. fMRI datasets,[0],[0]
It shows the brain activities associated with the meanings of nouns.,B. fMRI datasets,[0],[0]
"During the data collection period, the subjects were asked to view 60 different word-picture from 12 semantic categories.",B. fMRI datasets,[0],[0]
There are 5 pictures in each categories and each images is shown to the subject for 6 times.,B. fMRI datasets,[0],[0]
"Therefore, we can get 30 fMRI images for each semantic category, and each fMRI image is with dimensions 51 × 61 × 23.",B. fMRI datasets,[0],[0]
"In this experiment, we consider all the ROIs thus the classified fMRI images are relatively denser than the images we classified in the StarPlus example.",B. fMRI datasets,[0],[0]
"Considering the extremely small number of samples in each category, we therefore follow the experiment settings in [28] , which combines two similar categories into an integrated class.",B. fMRI datasets,[0],[0]
"Specifically, we combine categories
9
animal and insect as class Animals, and categories tool and furniture as class Tools.",B. fMRI datasets,[0],[0]
"By doing so, we have 60 samples in both Animals and Tools classes.",B. fMRI datasets,[0],[0]
"We separate the total 120 fMRI images as training, validation and testing sets, with 50, 20 and 50 images respectively.
",B. fMRI datasets,[0],[0]
Table III shows the binary classification results of different models.,B. fMRI datasets,[0],[0]
"We notice that SVM can perform classification on this dataset since we include all ROIs, which facilitates the hyperparameter searching procedure.",B. fMRI datasets,[0],[0]
"However, its classification accuracies on four subjects are lower than 50%.",B. fMRI datasets,[0],[0]
"The linear and polynomial model, namely STM, STuM, STTM, and TT classiifer, can only achieve an acceptable performance on a few subjects.",B. fMRI datasets,[0],[0]
"Due to the high-dimensional data size, DuSK fails to find a good CP-rank in acceptable time and can not achieve a good classification accuracy.",B. fMRI datasets,[0],[0]
3D CNN still performs poor due to the very few training samples and high-dimensional feature size.,B. fMRI datasets,[0],[0]
Our proposed two methods still achieve the best classification results on all subjects.,B. fMRI datasets,[0],[0]
"In this experiment, we use the CIFAR-10 dataset [29] to investigate the fourth claim in Section IV-B, namely, we can perform different kernel functions on different tensor modes.",C. CIFAR-10,[0],[0]
Here we demonstrate the effect on K-STTM-Prod only.,C. CIFAR-10,[0],[0]
We also randomly select ten class pairs to do binary classification.,C. CIFAR-10,[0],[0]
"Without overlap, 50 samples from the training set of each class are picked randomly for model training and validation respectively, while all the test samples of each class are used for testing.",C. CIFAR-10,[0],[0]
"Since each color image is naturally a threeway tensor (pixel-pixel-color), and the first two tensor modes are related to pixel intensity, we therefore utilize the same Gaussian RBF kernel for the first two tensor modes and try a different kernel (linear or polynomial) for the third mode.",C. CIFAR-10,[0],[0]
"The parameters c, d in the polynomial kernel k(x,y) = (xTy+c)d
were empirically set to c = 1 and d = 2.",C. CIFAR-10,[0],[0]
"The baseline case is when the Gaussian RBF kernel is applied to all tensor modes.
",C. CIFAR-10,[0],[0]
Table IV lists the classification results.,C. CIFAR-10,[0],[0]
We can observe that K-STTM-Prod still achieves the best accuracy on all class pairs.,C. CIFAR-10,[0],[0]
"And by applying a linear or polynomial kernel on the color mode, the classification accuracy of K-STTMProd outperforms the baseline case (RBF-RBF-RBF) on nine class pairs, which indicates the potential benefit of employing different kernel functions on different tensor modes when they contain different kind of information.",C. CIFAR-10,[0],[0]
"Since the data size of CIFAR-10 is also relatively small, we get a similar observation as the MNIST experiment, namely our method only achieves slightly better classification performance than SVM and 3D CNN on some class pairs.",C. CIFAR-10,[0],[0]
"Due to the constrained rank-one model setting, STM can not achieve an acceptable performance.",C. CIFAR-10,[0],[0]
"The other two linear classifiers, namely STuM and STTM still perform poor on most of the class pairs.",C. CIFAR-10,[0],[0]
The TT classifier has a similar performance as the STM in this experiment.,C. CIFAR-10,[0],[0]
This paper has proposed a tensor train (TT)-based kernel trick for the first time and devised a kernelized support tensor train machine (K-STTM).,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Assuming a low-rank TT as the prior structure of multi-dimensional data, we first define a corresponding feature mapping scheme that keeps the TT structure in the feature space.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Furthermore, two kernel function construction schemes are proposed with consideration of consistency with the TT inner product and the preservation of information, respectively.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
The feasibility of applying different kernel mappings on the tensor modes with different characteristics is also investigated.,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Experiments have demonstrated the superiority of K-STTM over conventional approaches for tensorial data in few-sample size problems.
",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"10
We further envision two future research directions based on the K-STTM framework.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Firstly, instead of constructing a kernel matrix in the K-STTM formula, we will consider building a kernel tensor.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
We believe that the kernel matrix constructed for each mode can contain different information.,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
Simply multiplying or adding this information may not be the best solution.,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Subsequently, we propose to stack this information into a 3-way kernel tensor and develop a better way to exploit information in each of the modes.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Secondly, we will embed the proposed kernel mapping trick into other kernel-based methods such as LSSVM [30], kernel PCA [31] etc., such that these methods can directly deal with tensorial data and achieve potentially better performance.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Tensor, a multi-dimensional data structure, has been exploited recently in the machine learning community.",abstractText,[0],[0]
"Traditional machine learning approaches are vectoror matrixbased, and cannot handle tensorial data directly.",abstractText,[0],[0]
"In this paper, we propose a tensor train (TT)-based kernel technique for the first time, and apply it to the conventional support vector machine (SVM) for image classification.",abstractText,[0],[0]
"Specifically, we propose a kernelized support tensor train machine that accepts tensorial input and preserves the intrinsic kernel property.",abstractText,[0],[0]
The main contributions are threefold.,abstractText,[0],[0]
"First, we propose a TT-based feature mapping procedure that maintains the TT structure in the feature space.",abstractText,[0],[0]
"Second, we demonstrate two ways to construct the TTbased kernel function while considering consistency with the TT inner product and preservation of information.",abstractText,[0],[0]
"Third, we show that it is possible to apply different kernel functions on different data modes.",abstractText,[0],[0]
"In principle, our method tensorizes the standard SVM on its input structure and kernel mapping scheme.",abstractText,[0],[0]
"Extensive experiments are performed on real-world tensor data, which demonstrates the superiority of the proposed scheme under few-sample high-dimensional inputs.",abstractText,[0],[0]
Kernelized Support Tensor Train Machines,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1400–1409, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
Directly reading documents and being able to answer questions from them is an unsolved challenge. To avoid its inherent difficulty, question answering (QA) has been directed towards using Knowledge Bases (KBs) instead, which has proven effective. Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g. Wikipedia contains much more information than Freebase. In this work we introduce a new method, Key-Value Memory Networks, that makes reading documents more viable by utilizing different encodings in the addressing and output stages of the memory read operation. To compare using KBs, information extraction or Wikipedia documents directly in a single framework we construct an analysis tool, WIKIMOVIES, a QA dataset that contains raw text alongside a preprocessed KB, in the domain of movies. Our method reduces the gap between all three settings. It also achieves state-of-the-art results on the existing WIKIQA benchmark.",text,[0],[0]
"Question answering (QA) has been a long standing research problem in natural language processing, with the first systems attempting to answer questions by directly reading documents (Voorhees and Tice, 2000).",1 Introduction,[0],[0]
"The development of large-scale Knowledge Bases (KBs) such as Freebase (Bollacker et al., 2008) helped organize information into structured forms, prompting recent progress to focus on answering questions by converting them into logical forms that
can be used to query such databases (Berant et al., 2013; Kwiatkowski et al., 2013; Fader et al., 2014).
",1 Introduction,[0],[0]
"Unfortunately, KBs have intrinsic limitations such as their inevitable incompleteness and fixed schemas that cannot support all varieties of answers.",1 Introduction,[0],[0]
"Since information extraction (IE) (Craven et al., 2000), intended to fill in missing information in KBs, is neither accurate nor reliable enough, collections of raw textual resources and documents such as Wikipedia will always contain more information.",1 Introduction,[0],[0]
"As a result, even if KBs can be satisfactory for closed-domain problems, they are unlikely to scale up to answer general questions on any topic.",1 Introduction,[0],[0]
"Starting from this observation, in this work we study the problem of answering by directly reading documents.
",1 Introduction,[0],[0]
"Retrieving answers directly from text is harder than from KBs because information is far less structured, is indirectly and ambiguously expressed, and is usually scattered across multiple documents.",1 Introduction,[0],[0]
This explains why using a satisfactory KB—typically only available in closed domains—is preferred over raw text.,1 Introduction,[0],[0]
"We postulate that before trying to provide answers that are not in KBs, document-based QA systems should first reach KB-based systems’ performance in such closed domains, where clear comparison and evaluation is possible.",1 Introduction,[0],[0]
"To this end, this paper introduces WIKIMOVIES, a new analysis tool that allows for measuring the performance of QA systems when the knowledge source is switched from a KB to unstructured documents.",1 Introduction,[0],[0]
"WIKIMOVIES contains ∼100k questions in the movie domain, and was designed to be answerable by using either a perfect KB (based on OMDb1), Wikipedia pages or an imper-
1http://www.omdbapi.com
1400
fect KB obtained through running an engineered IE pipeline on those pages.
",1 Introduction,[0],[0]
"To bridge the gap between using a KB and reading documents directly, we still lack appropriate machine learning algorithms.",1 Introduction,[0],[0]
"In this work we propose the Key-Value Memory Network (KV-MemNN), a new neural network architecture that generalizes the original Memory Network (Sukhbaatar et al., 2015) and can work with either knowledge source.",1 Introduction,[0],[0]
The KV-MemNN performs QA by first storing facts in a key-value structured memory before reasoning on them in order to predict an answer.,1 Introduction,[0],[0]
"The memory is designed so that the model learns to use keys to address relevant memories with respect to the question, whose corresponding values are subsequently returned.",1 Introduction,[0],[0]
"This structure allows the model to encode prior knowledge for the considered task and to leverage possibly complex transforms between keys and values, while still being trained using standard backpropagation via stochastic gradient descent.
",1 Introduction,[0],[0]
"Our experiments on WIKIMOVIES indicate that, thanks to its key-value memory, the KV-MemNN consistently outperforms the original Memory Network, and reduces the gap between answering from a human-annotated KB, from an automatically extracted KB or from directly reading Wikipedia.",1 Introduction,[0],[0]
"We confirm our findings on WIKIQA (Yang et al., 2015), another Wikipedia-based QA benchmark where no KB is available, where we demonstrate that KV-MemNN can reach state-of-the-art results— surpassing the most recent attention-based neural network models.",1 Introduction,[0],[0]
"Early QA systems were based on information retrieval and were designed to return snippets of text containing an answer (Voorhees and Tice, 2000; Banko et al., 2002), with limitations in terms of question complexity and response coverage.",2 Related Work,[0],[0]
"The creation of large-scale KBs (Auer et al., 2007; Bollacker et al., 2008) have led to the development of a new class of QA methods based on semantic parsing (Berant et al., 2013; Kwiatkowski et al., 2013; Fader et al., 2014; Yih et al., 2015) that can return precise answers to complicated compositional questions.",2 Related Work,[0],[0]
"Due to the sparsity of KB data, however, the main challenge shifts from finding answers to developing efficient information extraction methods to populate KBs auto-
matically (Craven et al., 2000; Carlson et al., 2010)— not an easy problem.
",2 Related Work,[0],[0]
"For this reason, recent initiatives are returning to the original setting of directly answering from text using datasets like TRECQA (Wang et al., 2007), which is based on classical TREC resources (Voorhees et al., 1999), and WIKIQA (Yang et al., 2015), which is extracted from Wikipedia.",2 Related Work,[0],[0]
"Both benchmarks are organized around the task of answer sentence selection, where a system must identify the sentence containing the correct answer in a collection of documents, but need not return the actual answer as a KB-based system would do.",2 Related Work,[0],[0]
"Unfortunately, these datasets are very small (hundreds of examples) and, because of their answer selection setting, do not offer the option to directly compare answering from a KB against answering from pure text.",2 Related Work,[0],[0]
"Using similar resources as the dialog dataset of Dodge et al. (2016), our new benchmark WIKIMOVIES addresses both deficiencies by providing a substantial corpus of questionanswer pairs that can be answered by either using a KB or a corresponding set of documents.
",2 Related Work,[0],[0]
"Even though standard pipeline QA systems like AskMR (Banko et al., 2002) have been recently revisited (Tsai et al., 2015), the best published results on TRECQA and WIKIQA have been obtained by either convolutional neural networks (Santos et al., 2016; Yin and Schütze, 2015; Wang et al., 2016) or recurrent neural networks (Miao et al., 2015)— both usually with attention mechanisms inspired by (Bahdanau et al., 2015).",2 Related Work,[0],[0]
"In this work, we introduce KV-MemNNs, a Memory Network model that operates a symbolic memory structured as (key, value) pairs.",2 Related Work,[0],[0]
Such structured memory is not employed in any existing attention-based neural network architecture for QA.,2 Related Work,[0],[0]
"As we will show, it gives the model greater flexibility for encoding knowledge sources and helps shrink the gap between directly reading documents and answering from a KB.",2 Related Work,[0],[0]
"The Key-Value Memory Network model is based on the Memory Network (MemNNs) model (Weston et al., 2015; Sukhbaatar et al., 2015) which has proven useful for a variety of document reading and question answering tasks: for reading children’s books and answering questions about them (Hill et al., 2016), for complex reasoning over sim-
ulated stories (Weston et al., 2016) and for utilizing KBs to answer questions (Bordes et al., 2015).
",3 Key-Value Memory Networks,[0],[0]
Key-value paired memories are a generalization of the way context (e.g. knowledge bases or documents to be read) are stored in memory.,3 Key-Value Memory Networks,[0],[0]
The lookup (addressing) stage is based on the key memory while the reading stage (giving the returned result) uses the value memory.,3 Key-Value Memory Networks,[0],[0]
This gives both (i) greater flexibility for the practitioner to encode prior knowledge about their task; and (ii) more effective power in the model via nontrivial transforms between key and value.,3 Key-Value Memory Networks,[0],[0]
"The key should be designed with features to help match it to the question, while the value should be designed with features to help match it to the response (answer).",3 Key-Value Memory Networks,[0],[0]
An important property of the model is that the entire model can be trained with key-value transforms while still using standard backpropagation via stochastic gradient descent.,3 Key-Value Memory Networks,[0],[0]
Our model is based on the end-to-end Memory Network architecture of Sukhbaatar et al. (2015).,3.1 Model Description,[0],[0]
"A high-level view of both models is as follows: one defines a memory, which is a possibly very large array of slots which can encode both long-term and short-term context.",3.1 Model Description,[0],[0]
"At test time one is given a query (e.g. the question in QA tasks), which is used to iteratively address and read from the memory (these iterations are also referred to as “hops”) looking for relevant information to answer the question.",3.1 Model Description,[0],[0]
"At each step, the collected information from the memory is cumulatively added to the original query to build context for the next round.",3.1 Model Description,[0],[0]
"At the last iteration, the final
retrieved context and the most recent query are combined as features to predict a response from a list of candidates.
",3.1 Model Description,[0],[0]
"Figure 1 illustrates the KV-MemNN model architecture.
",3.1 Model Description,[0],[0]
"In KV-MemNNs we define the memory slots as pairs of vectors (k1, v1) . . .",3.1 Model Description,[0],[0]
", (kM , vM ) and denote the question x.",3.1 Model Description,[0],[0]
"The addressing and reading of the memory involves three steps:
• Key Hashing: the question can be used to preselect a small subset of the possibly large array.",3.1 Model Description,[0],[0]
"This is done using an inverted index that finds a subset (kh1 , vh1), . . .",3.1 Model Description,[0],[0]
", (khN , vhN ) of memories of size N where the key shares at least one word with the question with frequency < F = 1000 (to ignore stop words), following Dodge et al. (2016).",3.1 Model Description,[0],[0]
"More sophisticated retrieval schemes could be used here, see e.g. Manning et al. (2008),
• Key Addressing: during addressing, each candidate memory is assigned a relevance probability by comparing the question to each key:
phi = Softmax(AΦX(x) ·AΦK(khi))
where Φ· are feature maps of dimension D, A is a d×D matrix and Softmax(zi) = ezi/ ∑ j e
zj .",3.1 Model Description,[0],[0]
"We discuss choices of feature map in Sec. 3.2.
",3.1 Model Description,[0],[0]
"• Value Reading: in the final reading step, the values of the memories are read by taking their weighted sum using the addressing probabilities,
and the vector o is returned:
o = ∑
i
phiAΦV (vhi) .
",3.1 Model Description,[0],[0]
The memory access process is conducted by the “controller” neural network using q = AΦX(x) as the query.,3.1 Model Description,[0],[0]
"After receiving the result o, the query is updated with q2 = R1(q + o) where R is a d × d matrix.",3.1 Model Description,[0],[0]
"The memory access is then repeated (specifically, only the addressing and reading steps, but not the hashing), using a different matrix",3.1 Model Description,[0],[0]
"Rj on each hop, j. The key addressing equation is transformed accordingly to use the updated query:
phi = Softmax(q > j+1AΦK(khi)) .
",3.1 Model Description,[0],[0]
The motivation for this is that new evidence can be combined into the query to focus on and retrieve more pertinent information in subsequent accesses.,3.1 Model Description,[0],[0]
"Finally, after a fixed number H hops, the resulting state of the controller is used to compute a final prediction over the possible outputs:
â = argmaxi=1,...,CSoftmax(q > H+1BΦY (yi))
where yi are the possible candidate outputs, e.g. all the entities in the KB, or all possible candidate answer sentences in the case of a dataset like WIKIQA (see Sec. 5.2).",3.1 Model Description,[0],[0]
The d×D matrix B can also be constrained to be identical to A.,3.1 Model Description,[0],[0]
"The whole network is trained end-to-end, and the model learns to perform the iterative accesses to output the desired target a by minimizing a standard cross-entropy loss between â and the correct answer a. Backpropagation and stochastic gradient descent are thus used to learn the matrices A,B and R1, . . .",3.1 Model Description,[0],[0]
", RH .
To obtain the standard End-To-End Memory Network of Sukhbaatar et al. (2015) one can simply set the key and value to be the same for all memories.",3.1 Model Description,[0],[0]
"Hashing was not used in that paper, but is important for computational efficiency for large memory sizes, as already shown in Dodge et al. (2016).",3.1 Model Description,[0],[0]
We will now go on to describe specific applications of key-value memories for the task of reading KBs or documents.,3.1 Model Description,[0],[0]
There are a variety of ways to employ key-value memories that can have important effects on overall performance.,3.2 Key-Value Memories,[0],[0]
"The ability to encode prior knowledge in
this way is an important component of KV-MemNNs, and we are free to define ΦX ,ΦY ,ΦK and ΦV for the query, answer, keys and values respectively.",3.2 Key-Value Memories,[0],[0]
"We now describe several possible variants of ΦK and ΦV that we tried in our experiments, for simplicity we kept ΦX and ΦY fixed as bag-of-words representations.
",3.2 Key-Value Memories,[0],[0]
KB Triple Knowledge base entries have a structure of triple “subject relation object” (see Table 1 for examples).,3.2 Key-Value Memories,[0],[0]
"The representation we consider is simple: the key is composed of the left-hand side entity (subject) and the relation, and the value is the right-hand side entity (object).",3.2 Key-Value Memories,[0],[0]
We double the KB and consider the reversed relation as well (e.g. we now have two triples “Blade Runner directed_by Ridley Scott” and “Ridley Scott !,3.2 Key-Value Memories,[0],[0]
directed_by Blade Runner” where !,3.2 Key-Value Memories,[0],[0]
directed_by is a different entry in the dictionary than directed_by).,3.2 Key-Value Memories,[0],[0]
Having the entry both ways round is important for answering different kinds of questions (“Who directed Blade Runner?” vs. “What did Ridley Scott direct?”).,3.2 Key-Value Memories,[0],[0]
"For a standard MemNN that does not have key-value pairs the whole triple has to be encoded into the same memory slot.
",3.2 Key-Value Memories,[0],[0]
Sentence Level,3.2 Key-Value Memories,[0],[0]
"For representing a document, one can split it up into sentences, with each memory slot encoding one sentence.",3.2 Key-Value Memories,[0],[0]
Both the key and the value encode the entire sentence as a bag-of-words.,3.2 Key-Value Memories,[0],[0]
"As the key and value are the same in this case, this is identical to a standard MemNN and this approach has been used in several papers (Weston et al., 2016; Dodge et al., 2016).
",3.2 Key-Value Memories,[0],[0]
Window Level Documents are split up into windows of W words; in our tasks we only include windows where the center word is an entity.,3.2 Key-Value Memories,[0],[0]
Windows are represented using bag-of-words.,3.2 Key-Value Memories,[0],[0]
"Window representations for MemNNs have been shown to work well previously (Hill et al., 2016).",3.2 Key-Value Memories,[0],[0]
"However, in Key-Value MemNNs we encode the key as the entire window, and the value as only the center word, which is not possible in the MemNN architecture.",3.2 Key-Value Memories,[0],[0]
"This makes sense because the entire window is more likely to be pertinent as a match for the question (as the key), whereas the entity at the center is more pertinent as a match for the answer (as the value).",3.2 Key-Value Memories,[0],[0]
"We will compare these approaches in our experiments.
",3.2 Key-Value Memories,[0],[0]
"Window + Center Encoding Instead of representing the window as a pure bag-of-words, thus mixing
the window center with the rest of the window, we can also encode them with different features.",3.2 Key-Value Memories,[0],[0]
"Here, we double the size, D, of the dictionary and encode the center of the window and the value using the second dictionary.",3.2 Key-Value Memories,[0],[0]
"This should help the model pick out the relevance of the window center (more related to the answer) as compared to the words either side of it (more related to the question).
",3.2 Key-Value Memories,[0],[0]
Window + Title,3.2 Key-Value Memories,[0],[0]
The title of a document is commonly the answer to a question that relates to the text it contains.,3.2 Key-Value Memories,[0],[0]
For example “What did Harrison Ford star in?” can be (partially) answered by the Wikipedia document with the title “Blade Runner”.,3.2 Key-Value Memories,[0],[0]
"For this reason, we also consider a representation where the key is the word window as before, but the value is the document title.",3.2 Key-Value Memories,[0],[0]
"We also keep all the standard (window, center) key-value pairs from the window-level representation as well, thus doubling the number of memory slots in comparison.",3.2 Key-Value Memories,[0],[0]
"To differentiate the two keys with different values we add an extra feature “_window_” or “_title_” to the key, depending on the value.",3.2 Key-Value Memories,[0],[0]
The “_title_” version also includes the actual movie title in the key.,3.2 Key-Value Memories,[0],[0]
This representation can be combined with center encoding.,3.2 Key-Value Memories,[0],[0]
Note that this representation is inherently specific to datasets in which there is an apparent or meaningful title for each document.,3.2 Key-Value Memories,[0],[0]
The WIKIMOVIES benchmark consists of questionanswer pairs in the domain of movies.,4 The WikiMovies Benchmark,[0],[0]
It was built with the following goals in mind: (i) machine learning techniques should have ample training examples for learning; and (ii) one can analyze easily the performance of different representations of knowledge and break down the results by question type.,4 The WikiMovies Benchmark,[0],[0]
The dataset can be downloaded from http://fb.ai/babi.,4 The WikiMovies Benchmark,[0],[0]
We construct three forms of knowledge representation: (i),4.1 Knowledge Representations,[0],[0]
Doc: raw Wikipedia documents consisting of the pages of the movies mentioned; (ii) KB: a classical graph-based KB consisting of entities and relations created from the Open Movie Database (OMDb) and MovieLens; and (iii) IE: information extraction performed on the Wikipedia pages to build a KB in a similar form as (ii).,4.1 Knowledge Representations,[0],[0]
"We take care to construct
QA pairs such that they are all potentially answerable from either the KB from (ii) or the original Wikipedia documents from (i) to eliminate data sparsity issues.",4.1 Knowledge Representations,[0],[0]
"However, it should be noted that the advantage of working from raw documents in real applications is that data sparsity is less of a concern than for a KB, while on the other hand the KB has the information already parsed in a form amenable to manipulation by machines.",4.1 Knowledge Representations,[0],[0]
"This dataset can help analyze what methods we need to close the gap between all three settings, and in particular what are the best methods for reading documents when a KB is not available.",4.1 Knowledge Representations,[0],[0]
"A sample of the dataset is shown in Table 1.
",4.1 Knowledge Representations,[0],[0]
Doc We selected a set of Wikipedia articles about movies by identifying a set of movies from OMDb2 that had an associated article by title match.,4.1 Knowledge Representations,[0],[0]
We keep the title and the first section (before the contents box) for each article.,4.1 Knowledge Representations,[0],[0]
"This gives∼17k documents (movies) which comprise the set of documents our models will read from in order to answer questions.
2 http://beforethecode.com/projects/omdb/download.aspx
KB",4.1 Knowledge Representations,[0],[0]
Our set of movies were also matched to the MovieLens dataset3.,4.1 Knowledge Representations,[0],[0]
"We built a KB using OMDb and MovieLens metadata with entries for each movie and nine different relation types: director, writer, actor, release year, language, genre, tags, IMDb rating and IMDb votes, with ∼10k related actors, ∼6k directors and∼43k entities in total.",4.1 Knowledge Representations,[0],[0]
The KB is stored as triples; see Table 1 for examples.,4.1 Knowledge Representations,[0],[0]
"IMDb ratings and votes are originally real-valued but are binned and converted to text (“unheard of”, “unknown”, “well known”, “highly watched”, “famous”).",4.1 Knowledge Representations,[0],[0]
"We finally only retain KB triples where the entities also appear in the Wikipedia articles4 to try to guarantee that all QA pairs will be equally answerable by either the KB or Wikipedia document sources.
",4.1 Knowledge Representations,[0],[0]
IE,4.1 Knowledge Representations,[0],[0]
"As an alternative to directly reading documents, we explore leveraging information extraction techniques to transform documents into a KB format.",4.1 Knowledge Representations,[0],[0]
An IE-KB representation has attractive properties such as more precise and compact expressions of facts and logical key-value pairings based on subjectverb-object groupings.,4.1 Knowledge Representations,[0],[0]
This can come at the cost of lower recall due to malformed or completely missing triplets.,4.1 Knowledge Representations,[0],[0]
For IE we use standard open-source software followed by some task-specific engineering to improve the results.,4.1 Knowledge Representations,[0],[0]
"We first employ coreference resolution via the Stanford NLP Toolkit (Manning et al., 2014) to reduce ambiguity by replacing pronominal (“he”, “it”) and nominal (“the film”) references with their representative entities.",4.1 Knowledge Representations,[0],[0]
"Next we use the SENNA semantic role labeling tool (Collobert et al., 2011) to uncover the grammatical structure of each sentence and pair verbs with their arguments.",4.1 Knowledge Representations,[0],[0]
"Each triplet is cleaned of words that are not recognized entities, and lemmatization is done to collapse different inflections of important task-specific verbs to one form (e.g. stars, starring, star→ starred).",4.1 Knowledge Representations,[0],[0]
"Finally, we append the movie title to each triple similar to the “Window + Title” representation of Sec. 3.2, which improved results.",4.1 Knowledge Representations,[0],[0]
"Within the dataset’s more than 100,000 questionanswer pairs, we distinguish 13 classes of question
3 http://grouplens.org/datasets/movielens/
4The dataset also includes the slightly larger version without this constraint.
",4.2 Question-Answer Pairs,[0],[0]
corresponding to different kinds of edges in our KB.,4.2 Question-Answer Pairs,[0],[0]
"They range in scope from specific—such as actor to movie: “What movies did Harrison Ford star in?” and movie to actors: “Who starred in Blade Runner?”—to more general, such as tag to movie: “Which films can be described by dystopian?”; see Table 4 for the full list.",4.2 Question-Answer Pairs,[0],[0]
"For some question there can be multiple correct answers.
",4.2 Question-Answer Pairs,[0],[0]
"Using SimpleQuestions (Bordes et al., 2015), an existing open-domain question answering dataset based on Freebase, we identified the subset of questions posed by human annotators that covered our question types.",4.2 Question-Answer Pairs,[0],[0]
We created our question set by substituting the entities in those questions with entities from all of our KB triples.,4.2 Question-Answer Pairs,[0],[0]
"For example, if the original question written by an annotator was “What movies did Harrison Ford star in?”, we created a pattern “What movies did [@actor] star in?”, which we substitute for any other actors in our set, and repeat this for all annotations.",4.2 Question-Answer Pairs,[0],[0]
"We split the questions into disjoint training, development and test sets with ∼96k, 10k and 10k examples, respectively.",4.2 Question-Answer Pairs,[0],[0]
The same question (even worded differently) cannot appear in both train and test sets.,4.2 Question-Answer Pairs,[0],[0]
"Note that this is much larger than most existing datasets; for example, the WIKIQA dataset (Yang et al., 2015) for which we also conduct experiments in Sec.",4.2 Question-Answer Pairs,[0],[0]
5.2 has only ∼1000 training pairs.,4.2 Question-Answer Pairs,[0],[0]
This section describes our experiments on WIKIMOVIES and WIKIQA.,5 Experiments,[0],[0]
We conducted experiments on the WIKIMOVIES dataset described in Sec. 4.,5.1 WikiMovies,[0],[0]
"Our main goal is to compare the performance of KB, IE and Wikipedia (Doc) sources when trying varying learning methods.",5.1 WikiMovies,[0],[0]
"We compare four approaches: (i) the QA system of Bordes et al. (2014) that performs well on existing datasets WebQuestions (Berant et al., 2013) and SimpleQuestions (Bordes et al., 2015) that use KBs only; (ii) supervised embeddings that do not make use of a KB at all but learn question-to-answer embeddings directly and hence act as a sanity check (Dodge et al., 2016); (iii) Memory Networks; and (iv) Key-Value Memory Networks.",5.1 WikiMovies,[0],[0]
"Performance is reported using the accuracy of the top hit (single answer) over all possible answers (all entities), i.e. the hits@1 metric measured in percent.",5.1 WikiMovies,[0],[0]
"In all cases hyperparameters are optimized on the development set, including the memory representations of Sec. 3.2 for MemNNs and KV-MemNNs.",5.1 WikiMovies,[0],[0]
"As MemNNs do not support key-value pairs, we concatenate key and value together when they differ instead.
",5.1 WikiMovies,[0],[0]
The main results are given in Table 2.,5.1 WikiMovies,[0],[0]
"The QA system of Bordes et al. (2014) outperforms Supervised Embeddings and Memory Networks for KB and IE-based KB representations, but is designed to work with a KB, not with documents (hence the N/A in that column).",5.1 WikiMovies,[0],[0]
"However, Key-Value Memory Networks outperform all other methods on all three data source types.",5.1 WikiMovies,[0],[0]
"Reading from Wikipedia documents directly (Doc) outperforms an IE-based KB (IE), which is an encouraging result towards automated machine reading though a gap to a humanannotated KB still remains (93.9 vs. 76.2).",5.1 WikiMovies,[0],[0]
The best memory representation for directly reading documents uses “Window-level + Center Encoding + Title” (W = 7 and H = 2); see Table 3 for a comparison of results for different representation types.,5.1 WikiMovies,[0],[0]
"Both center encoding and title features help the windowlevel representation, while sentence-level is inferior.
",5.1 WikiMovies,[0],[0]
QA Breakdown A breakdown by question type comparing the different data sources for KVMemNNs is given in Table 4.,5.1 WikiMovies,[0],[0]
"IE loses out especially
to Doc (and KB) on Writer, Director and Actor to Movie, perhaps because coreference is difficult in these cases – although it has other losses elsewhere too.",5.1 WikiMovies,[0],[0]
"Note that only 56% of subject-object pairs in IE match the triples in the original KB, so losses are expected.",5.1 WikiMovies,[0],[0]
"Doc loses out to KB particularly on Tag to Movie, Movie to Tags, Movie to Writer and Movie to Actors.",5.1 WikiMovies,[0],[0]
Tag questions are hard because they can reference more or less any word in the entire Wikipedia document; see Table 1.,5.1 WikiMovies,[0],[0]
"Movie to Writer/Actor are hard because there is likely only one or a few references to the answer across all documents, whereas for Writer/Actor to Movie there are more possible answers to find.
",5.1 WikiMovies,[0],[0]
"KB vs. Synthetic Document Analysis To further understand the difference between using a KB versus reading documents directly, we conducted an experiment where we constructed synthetic documents using the KB.",5.1 WikiMovies,[0],[0]
"For a given movie, we use a simple grammar to construct a synthetic “Wikipedia” doc-
ument based on the KB triples: for each relation type we have a set of template phrases (100 in total) used to generate the fact, e.g. “Blade Runner came out in 1982” for the entry BLADE RUNNER RELEASE_YEAR 1982.",5.1 WikiMovies,[0],[0]
"We can then parameterize the complexity of our synthetic documents: (i) using one template, or all of them; (ii) using conjunctions to combine facts into single sentences or not; and (iii) using coreference between sentences where we replace the movie name with “it”.5 The purpose of this experiment is to find which aspects are responsible for the gap in performance to a KB.",5.1 WikiMovies,[0],[0]
The results are given in Table 5.,5.1 WikiMovies,[0],[0]
"They indicate that some of the loss (93.9% for KB to 82.9% for One Template Sentence) in performance is due directly to representing in sentence form, making the subject, relation and object harder to extract.",5.1 WikiMovies,[0],[0]
Moving to a larger number of templates does not deteriorate performance much (80%).,5.1 WikiMovies,[0],[0]
The remaining performance drop seems to be split roughly equally between conjunctions (74%) and coreference (76%).,5.1 WikiMovies,[0],[0]
The hardest synthetic dataset combines these (All Templates + Conj.,5.1 WikiMovies,[0],[0]
+ Coref.),5.1 WikiMovies,[0],[0]
and is actually harder than using the real Wikipedia documents (72.5% vs. 76.2%).,5.1 WikiMovies,[0],[0]
"This is possibly because the amount of conjunctions and coreferences we make are artificially too high (50% and 80% of the time, respectively).",5.1 WikiMovies,[0],[0]
"WIKIQA (Yang et al., 2015) is an existing dataset for answer sentence selection using Wikipedia as the knowledge source.",5.2 WikiQA,[0],[0]
"The task is, given a question, to select the sentence coming from a Wikipedia document that best answers the question, where performance is measured using mean average preci-
5This data is also part of the WIKIMOVIES benchmark.
",5.2 WikiQA,[0],[0]
sion (MAP) and mean reciprocal rank (MRR) of the ranked set of answers.,5.2 WikiQA,[0],[0]
"The dataset uses a pre-built information retrieval step and hence provides a fixed set of candidate sentences per question, so systems do not have to consider ranking all of Wikipedia.",5.2 WikiQA,[0],[0]
"In contrast to WIKIMOVIES, the training set size is small (∼1000 examples) while the topic is much more broad (all of Wikipedia, rather than just movies) and the questions can only be answered by reading the documents, so no comparison to the use of KBs can be performed.",5.2 WikiQA,[0],[0]
"However, a wide range of methods have already been tried on WIKIQA, thus providing a useful benchmark to test if the same results found on WIKIMOVIES carry across to WIKIQA, in particular the performance of Key-Value Memory Networks.
",5.2 WikiQA,[0],[0]
"Due to the size of the training set, following many other works (Yang et al., 2015; Santos et al., 2016; Miao et al., 2015) we pre-trained the word vectors (matrices A and B which are constrained to be identical) before training KV-MemNNs.",5.2 WikiQA,[0],[0]
"We employed Supervised Embeddings (Dodge et al., 2016) for that goal, training on all of Wikipedia while treating the input as a random sentence and the target as the subsequent sentence.",5.2 WikiQA,[0],[0]
"We then trained KV-MemNNs with dropout regularization: we sample words from the question, memory representations and the answers, choosing the dropout rate using the development set.",5.2 WikiQA,[0],[0]
"Finally, again following other successful methods (Yin and Schütze, 2015), we combine our approach with exact matching word features between question and answers.",5.2 WikiQA,[0],[0]
Key hashing was not used as candidates were already pre-selected.,5.2 WikiQA,[0],[0]
"To represent the memories, we used the Window-Level representation (the best choice on the dev set was W = 7) as the key and the whole sentence as the value, as the value should match the answer which in this case is a sentence.",5.2 WikiQA,[0],[0]
"Additionally, in the representation all numbers in the text and the phrase “how many” in the question were replaced with the feature “_number_”.",5.2 WikiQA,[0],[0]
"The best choice of hops was also H = 2 for KV-MemNNs.
",5.2 WikiQA,[0],[0]
The results are given in Table 6.,5.2 WikiQA,[0],[0]
"Key-Value Memory Networks outperform a large set of other methods, although the results of the L.D.C. method of (Wang et al., 2016) are very similar.",5.2 WikiQA,[0],[0]
"Memory Networks, which cannot easily pair windows to sentences, perform much worse, highlighting the importance of key-value memories.",5.2 WikiQA,[0],[0]
"We studied the problem of directly reading documents in order to answer questions, concentrating our analysis on the gap between such direct methods and using human-annotated or automatically constructed KBs.",6 Conclusion,[0],[0]
"We presented a new model, Key-Value Memory Networks, which helps bridge this gap, outperforming several other methods across two datasets, WIKIMOVIES and WIKIQA.",6 Conclusion,[0],[0]
"However, some gap in performance still remains.",6 Conclusion,[0],[0]
WIKIMOVIES serves as an analysis tool to shed some light on the causes.,6 Conclusion,[0],[0]
"Future work should try to close this gap further.
",6 Conclusion,[0],[0]
Key-Value Memory Networks are versatile models for reading documents or KBs and answering questions about them—allowing to encode prior knowledge about the task at hand in the key and value memories.,6 Conclusion,[0],[0]
"These models could be applied to storing and reading memories for other tasks as well, and future work should try them in other domains, such as in a full dialog setting.",6 Conclusion,[0],[0]
Directly reading documents and being able to answer questions from them is an unsolved challenge.,abstractText,[0],[0]
"To avoid its inherent difficulty, question answering (QA) has been directed towards using Knowledge Bases (KBs) instead, which has proven effective.",abstractText,[0],[0]
"Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g. Wikipedia contains much more information than Freebase.",abstractText,[0],[0]
"In this work we introduce a new method, Key-Value Memory Networks, that makes reading documents more viable by utilizing different encodings in the addressing and output stages of the memory read operation.",abstractText,[0],[0]
"To compare using KBs, information extraction or Wikipedia documents directly in a single framework we construct an analysis tool, WIKIMOVIES, a QA dataset that contains raw text alongside a preprocessed KB, in the domain of movies.",abstractText,[0],[0]
Our method reduces the gap between all three settings.,abstractText,[0],[0]
It also achieves state-of-the-art results on the existing WIKIQA benchmark.,abstractText,[0],[0]
Key-Value Memory Networks for Directly Reading Documents,title,[0],[0]
"Proceedings of the SIGDIAL 2017 Conference, pages 37–49, Saarbrücken, Germany, 15-17 August 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"With the success of new speech-based humancomputer interfaces, there is a great need for effective task-oriented dialogue agents that can handle everyday tasks such as scheduling events and booking hotels.",1 Introduction,[0],[0]
Current commercial dialogue agents are often brittle pattern-matching systems which are unable to maintain the kind of flexible conversations that people desire.,1 Introduction,[0],[0]
"Neural dialogue agents present one of the most promising avenues for leveraging dialogue corpora to build statistical models directly from data by using powerful distributed representations (Bordes and Weston, 2016; Wen et al., 2016b; Dhingra et al., 2016).
",1 Introduction,[0],[0]
"While this work has been somewhat successful, these task-oriented neural dialogue models suffer from a number of problems: 1) They struggle to effectively reason over and incorporate knowledge base information while still preserving their endto-end trainability and 2)",1 Introduction,[0],[0]
"They often require explicitly modelling user dialogues with belief trackers and dialogue state information, which necessitates additional data annotation and also breaks differentiability.
",1 Introduction,[0],[0]
"To address some of the modelling issues in previous neural dialogue agents, we introduce a new architecture called the Key-Value Retrieval Network.",1 Introduction,[0],[0]
"This model augments existing recurrent network architectures with an attention-based key-value retrieval mechanism over the entries of a knowledge base, which is inspired by recent work on key-value memory networks (Miller et al., 2016).",1 Introduction,[0],[0]
"By doing so, it is able to learn how to extract useful information from a knowledge base directly from data in an end-to-end fashion, with-
37
out the need for explicit training of belief or intent trackers as is done in traditional task-oriented dialogue systems.",1 Introduction,[0],[0]
"The architecture has no dependence on the specifics of the data domain, learning how to appropriately incorporate world knowledge into its dialogue utterances via attention over the key-value entries of the underlying knowledge base.
",1 Introduction,[0],[0]
"In addition, we introduce and make publicly available a new corpus of 3,031 dialogues spanning three different domain types in the incar personal assistant space: calendar scheduling, weather information retrieval, and point-ofinterest navigation.",1 Introduction,[0],[0]
The dialogues are grounded through knowledge bases.,1 Introduction,[0],[0]
This makes them ideal for building dialogue architectures that seamlessly reason over world knowledge.,1 Introduction,[0],[0]
"The multi-domain nature of the dialogues in the corpus also makes this dataset an apt test bed for generalizability of modelling architectures.1
The main contributions of our work are therefore two-fold: 1) We introduce the Key-Value Retrieval Network, a highly performant neural taskoriented dialogue agent that is able to smoothly incorporate information from underlying knowledge bases through a novel key-value retrieval mechanism.",1 Introduction,[0],[0]
"Unlike other dialogue agents which only rely on prior dialogue history for generation (Kannan et al., 2016; Eric and Manning, 2017), our architecture is able to access and use database-style information, while still retaining the text generation advantages of recent neural models.",1 Introduction,[0],[0]
"By doing so, our model outperforms a competitive rulebased system and other baseline neural models on a number of automatic metrics as well as human evaluation.",1 Introduction,[0],[0]
2),1 Introduction,[0],[0]
We release a new publicly-available dialogue corpus across three distinct domains in the in-car personal assistant space that we hope will help further work on task-oriented dialogue agents.,1 Introduction,[0],[0]
"While recent neural dialogue models have explicitly modelled dialogue state through belief and user intent trackers (Wen et al., 2016b; Dhingra et al., 2016; Henderson et al., 2014b), we choose instead to rely on learned neural representations for implicit modelling of dialogue state, forming
1The data is available for download at https://nlp.stanford.edu/blog/a-new-multi-turn-multidomain-task-oriented-dialogue-dataset/
a truly end-to-end trainable system.",2 Key-Value Retrieval Networks,[0],[0]
Our model starts with an encoder-decoder sequence architecture and is further augmented with an attentionbased retrieval mechanism that effectively reasons over a key-value representation of the underlying knowledge base.,2 Key-Value Retrieval Networks,[0],[0]
We describe each component of our model in the subsequent sections.,2 Key-Value Retrieval Networks,[0],[0]
"Given a dialogue between a user (u) and a system (s), we represent the dialogue utterances as {(u1, s1), (u2, s2), . . .",2.1 Encoder,[0],[0]
", (uk, sk)} where k denotes the number of turns in the dialogue.",2.1 Encoder,[0],[0]
"At the ith turn of the dialogue, we encode the aggregated dialogue context composed of the tokens of (u1, s1, . . .",2.1 Encoder,[0],[0]
", si−1, ui).",2.1 Encoder,[0],[0]
"Letting x1, . . .",2.1 Encoder,[0],[0]
", xm denote these tokens, we first embed these tokens using a trained embedding function φemb that maps each token to a fixed-dimensional vector.",2.1 Encoder,[0],[0]
"These mappings are fed into the encoder to produce contextsensitive hidden representations h1, . . .",2.1 Encoder,[0],[0]
", hm, by repeatedly applying the recurrence:
hi = LSTM(φemb(xi), hi−1) (1)
where the recurrence uses a long-short-term memory unit, as described by (Hochreiter and Schmidhuber, 1997).",2.1 Encoder,[0],[0]
The vanilla sequence-to-sequence decoder predicts the tokens of the ith system response si by first computing decoder hidden states via the recurrent unit.,2.2 Decoder,[0],[0]
"We denote h̃1, . . .",2.2 Decoder,[0],[0]
", h̃n as the hidden states of the decoder and y1, . . .",2.2 Decoder,[0],[0]
", yn as the output tokens.",2.2 Decoder,[0],[0]
"We extend this decoder with an attentionbased model (Bahdanau et al., 2015; Luong et al., 2015a), where, at every time step t of the decoding, an attention score ati is computed for each hidden state hi of the encoder, using the attention mechanism of (Vinyals et al., 2015).",2.2 Decoder,[0],[0]
"Formally this attention can be described by the following equations:
uti = w T tanh(W2 tanh(W1[hi, h̃t])))",2.2 Decoder,[0],[0]
"(2) ati = Softmax(u t i) (3)
h̃′t = m∑
i=1
atihi (4)
",2.2 Decoder,[0],[0]
"ot = U [h̃t, h̃′t] (5) yt = Softmax(ot) (6)
where U , W1, W2, and w are trainable parameters of the model and ot represents the logits over the tokens of the output vocabulary V .",2.2 Decoder,[0],[0]
"In (2) above, the attention logit on hi is computed via a twolayer MLP function with a tanh nonlinearity at the intermediate layers.",2.2 Decoder,[0],[0]
"During training, the next token yt is predicted so as to maximize the loglikelihood of the correct output sequence given the input sequence.",2.2 Decoder,[0],[0]
"Recently, some neural task-oriented dialogue agents that query underlying knowledge bases (KBs) and extract relevant entities either do the following: 1) create and execute well-formatted API calls to the KB, operations which require intermediate supervision in the form of training slot trackers and which break differentiability (Wen et al., 2016b), or 2) softly attend to the KB and combine this probability distribution with belief trackers as state input for a reinforcement learning policy (Dhingra et al., 2016).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"We choose to build off the latter approach as it fits nicely into the end-to-end trainable framework of sequenceto-sequence modelling, though we are in a supervised learning setting and we do away with explicit representations of belief trackers or dialogue state.
",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For storing the KB of a given dialogue, we take inspiration from the work of (Miller et al., 2016) which found that a key-value structured memory allowed for efficient machine reading of documents.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"We store every entry of our KB using a (subject, relation, object) representation.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In our representation a KB entry from the dialogue in Figure 1 such as (event=dinner, time=8pm, date=the 13th, party=Ana, agenda=“-”) would be normalized into four separate triples of the form (dinner, time, 8pm).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
Every KB has at most 230 normalized triples.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"This formalism is similar to a neo-Davidsonian or RDF-style representation of events.
",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Recent literature has shown that incorporating a copying mechanism into neural architectures improves performance on various sequenceto-sequence tasks (Jia and Liang, 2016; Gu et al., 2016; Ling et al., 2016; Gulcehre et al., 2016; Eric and Manning, 2017).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"We build off this intuition in the following way: at every timestep of decoding, we take the decoder hidden state and compute an attention score with the key of each normalized
KB entry.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For our purposes, the key of an entry corresponds to the sum of the word embeddings of the subject (meeting) and relation (time).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
The attention logits then become the logits of the value for that KB entry.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For our KB attentions, we replace the embedding of the value with a canonicalized token representation.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For example, the value 5pm is replaced with the canonicalized representation meeting time.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"At runtime, if we decode this canonicalized representation token, we convert it into the actual value of the KB entry (5pm in our running example) through a KB lookup.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
Note that this means we are expanding our original output vocabulary to |V,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
| + n,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"where n is the number of separate canonical key representation KB entries.
",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In particular, let kj denote the word embedding of the key of our j th normalized KB entry.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
We can now formalize the decoding for our KB attentionbased retrieval.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Assume that we have m distinct triples in our KB and that we are in the tth timestep of decoding:
utj = r T",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
tanh(W ′2,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
tanh(W ′,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"1[kj , h̃t])))",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"(7) ot = U [h̃t, h̃′t] + v̄ t (8) yt = Softmax(ot) (9)
where r, W ′1, and W ′2 are trainable parameters.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In (8) above, v̄t is a sparse vector with length |V",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
| + n.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Within v̄t, the entry for the value embedding vj corresponding to the key kj is equal to the logit score utj on kj .",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Hence, the m entries of v̄t corresponding to the values in the KB are non-zero, whereas the remaining entries corresponding to the original vocabulary tokens are 0.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
This sparse vector contains our aggregated KB logit scores which we combine with the original logits to get a modified ot.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
We then select the argmax token as input to the next timestep.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"This description seeks to capture the intuition that in response to the query What time is my meeting, we want the model to put a high attention weight on the key representation for the (meeting, time, 5pm)",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"KB triple, which should then lead the model to favor outputting the value token at the given timestep.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
We provide a visualization of the KeyValue Retrieval Network in Figure 2.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In an effort to further work in multi-domain dialogue agents, we built a corpus of multi-turn
dialogues in three distinct domains: calendar scheduling, weather information retrieval, and point-of-interest navigation.","3 A Multi-Turn, Multi-Domain Dialogue Dataset",[0],[0]
"While these domains are different, they are all relevant to the overarching theme of tasks that users would expect of a sophisticated in-car personal assistant.","3 A Multi-Turn, Multi-Domain Dialogue Dataset",[0],[0]
"The data for the multi-turn dialogues was collected using a Wizard-of-Oz scheme inspired by that of (Wen et al., 2016b).",3.1 Data Collection,[0],[0]
"In our scheme, users had two potential modes they could play: Driver and Car Assistant.",3.1 Data Collection,[0],[0]
"In the Driver mode, users were presented with a task that listed certain information they were trying to extract from the Car Assistant as well as the dialogue history exchanged between Driver and Car Assistant up to that point.",3.1 Data Collection,[0],[0]
An example task presented could be: You want to find what the temperature is like in San Mateo over the next two days.,3.1 Data Collection,[0],[0]
"The Driver was then only responsible for contributing a single line of dialogue that appropriately continued the discourse given the prior dialogue history and the task definition.
",3.1 Data Collection,[0],[0]
"Tasks were randomly specified by selecting values (5pm, Saturday, San Francisco, etc.)",3.1 Data Collection,[0],[0]
"for three to five slots (time, date, location, etc.), de-
pending on the domain type.",3.1 Data Collection,[0],[0]
"Values specified for the slots were chosen according to a uniform distribution from a per-domain candidate set.
",3.1 Data Collection,[0],[0]
"In the Car Assistant mode, users were presented with the dialogue history exchanged up to that point in the running dialogue and a private knowledge base known only to the Car Assistant with information that could be useful for satisfying the Driver query.",3.1 Data Collection,[0],[0]
"Examples of knowledge bases could include a calendar of event information, a collection of weekly forecasts for nearby cities, or a collection of nearby points-of-interest with relevant information.",3.1 Data Collection,[0],[0]
The Car Assistant was then responsible for using this private information to provide a single utterance that progressed the user-directed dialogues.,3.1 Data Collection,[0],[0]
"The Car Assistant was also asked to fill in dialogue state information for mentioned slots and values in the dialogue history up to that point.
",3.1 Data Collection,[0],[0]
Each private knowledge base had six to seven distinct rows and five to seven attribute types.,3.1 Data Collection,[0],[0]
"The private knowledge bases used were generated by uniformly selecting a value for a given attribute type, where each attribute type had a variable number of candidate values.",3.1 Data Collection,[0],[0]
"Some knowledge bases intentionally lacked attributes to encourage diversity in discourse.
",3.1 Data Collection,[0],[0]
"During data collection, some of the dialogues
in the calendar scheduling domain did not explicitly require the use of a KB.",3.1 Data Collection,[0],[0]
"For example, in a task such as Set a meeting reminder at 3pm, we hoped to encourage dialogues that required the Car Assistant to execute a task while asking for Driver clarification on underspecified information.",3.1 Data Collection,[0],[0]
"Roughly half of the scheduling dialogues fell into this category.
",3.1 Data Collection,[0],[0]
"While specifying the attribute types and values in each task presented to the Driver allowed us to ground the subject of each dialogue with our desired entities, it would occasionally result in more mechanical discourse exchanges.",3.1 Data Collection,[0],[0]
"To encourage more naturalistic, unbiased utterances, we had users record themselves saying commands in response to underspecified visual depictions of an action a car assistant could perform.",3.1 Data Collection,[0],[0]
These commands were transcribed and then inserted as the first exchange in a given dialogue on behalf of the Driver.,3.1 Data Collection,[0],[0]
"Roughly ∼1,500 of the dialogues employed this transcribed audio command firstutterance technique.
",3.1 Data Collection,[0],[0]
241 unique workers from Amazon Mechanical Turk were anonymously recruited to use the interface we built over a period of about six days.,3.1 Data Collection,[0],[0]
Data statistics are provided in Table 1 and slot types and values are provided in Table 2.,3.1 Data Collection,[0],[0]
"A screenshot of the user-facing interfaces for the data collection, as well as a visual used to prompt user recorded commands, are provided in the supplementary material.",3.1 Data Collection,[0],[0]
Task-oriented agents for spoken dialogue systems have been the subject of extensive research effort.,4 Related Work,[0],[0]
"One line of work by (Young et al., 2013) has tackled the problem using partially observable Markov decision processes and reinforcement learning with carefully designed action spaces, though the number of distinct action states makes this approach often brittle and computationally intractable.
",4 Related Work,[0],[0]
"The recent successes of neural architectures on a number of traditional natural language processing subtasks (Bahdanau et al., 2015; Sutskever et al., 2014; Vinyals et al., 2015) have motivated investigation into dialogue agents that can effectively make use of distributed neural representations for dialogue state management, belief tracking, and response generation.",4 Related Work,[0],[0]
"Recent work by (Wen et al., 2016b) has built systems with modularly-connected representation, belief state, and generation components.",4 Related Work,[0],[0]
"These models learn to explicitly represent user intent through intermediate supervision, which breaks end-to-end trainability.",4 Related Work,[0],[0]
"Other work by (Bordes and Weston, 2016; Liu and Perez, 2016) stores dialogue context in a memory module and repeatedly queries and reasons about this context to select an adequate system response from a set of all candidate responses.
",4 Related Work,[0],[0]
"Another line of recent work has developed taskoriented models which are amenable to both supervised learning and reinforcement learning and are able to incorporate domain-specific knowledge via explicitly-provided features and model-output restrictions (Williams et al., 2017).",4 Related Work,[0],[0]
"Our model contrasts with these works in that training is done in a strictly supervised fashion via a per utterance token generative process, and the model does not need dialogue state trackers, relying instead on latent neural embeddings for accurate system response generation.
",4 Related Work,[0],[0]
"Research in task-oriented dialogue often struggles with a lack of standard, publicly available datasets.",4 Related Work,[0],[0]
"Several classical corpora have consisted of moderately-sized collections of dialogues related to travel-booking (Hemphill et al., 1990;
Bennett and Rudnicky, 2002).",4 Related Work,[0],[0]
"Another wellknown corpus is derived from a series of competitions on the task of dialogue-state tracking (Williams et al., 2013).",4 Related Work,[0],[0]
"While the competitions were designed to test systems for state tracking, recent work has chosen to repurpose this data by only using the transcripts of dialogues without state annotation for developing systems (Bordes and Weston, 2016; Williams et al., 2017).",4 Related Work,[0],[0]
"More recently, Maluuba has released a dataset of hotel and travel-booking dialogues collected in a Wizard-ofOz Scheme with elaborate semantic frames annotated (Asri et al., 2017).",4 Related Work,[0],[0]
This dataset aims to encourage research in non-linear decision-making processes that are present in task-oriented dialogues.,4 Related Work,[0],[0]
In this section we first introduce the details of the experiments and then present results from both automatic and human evaluation.,5 Experiments,[0],[0]
"For our experiments, we divided the dialogues into train/validation/test sets using a 0.8/0.1/0.1 data split and ensured that each domain type was equally represented in each of the splits.
",5.1 Details,[0],[0]
"To reduce lexical variability, in a pre-processing step, we map the variant surface expression of entities to a canonical form using named entity recognition and linking.",5.1 Details,[0],[0]
"For example, the surface form 20 Main Street is mapped to Pizza My Heart address.",5.1 Details,[0],[0]
"During inference, our model outputs the canonical forms of the entities, and so we realize their surface forms by running the system output through an inverse lexicon.",5.1 Details,[0],[0]
The inverse lexicon converts the entities back to their surface forms by sampling from a multinomial distribution with parameters of the distribution equal to the frequency count of a given surface form for an entity as observed in the training and validation data.,5.1 Details,[0],[0]
"Note that for the purposes of computing our evaluation metrics, we operate on the canonicalized forms, so that any non-deterministic variability in surface form realization does not affect the computed metrics.",5.1 Details,[0],[0]
"We trained using a cross-entropy loss and the Adam optimizer (Kingma and Ba, 2015) with learning rates sampled from the interval
[10−4, 10−3].",5.2 Hyperparameters,[0],[0]
"We applied dropout (Hinton et al., 2012) as a regularizer to the input and output of the LSTM.",5.2 Hyperparameters,[0],[0]
We also added an l2 regularization penalty on the weights of the model.,5.2 Hyperparameters,[0],[0]
"We identified hyperparameters by random search, evaluating on the held-out validation subset of the data.",5.2 Hyperparameters,[0],[0]
"Dropout keep rates were sampled from [0.8, 0.9] and the l2 coefficient was sampled from [3 · 10−6, 10−5].",5.2 Hyperparameters,[0],[0]
"We used word embeddings, hidden layer, and cell sizes with size 200.",5.2 Hyperparameters,[0],[0]
We applied gradient clipping with a clip-value of 10 to avoid gradient explosions during training.,5.2 Hyperparameters,[0],[0]
"The attention, output parameters, word embeddings, and LSTM weights were randomly initialized from a uniform unit-scaled distribution in the style of (Sussillo and Abbott, 2015).",5.2 Hyperparameters,[0],[0]
"We also added a bias of 1 to the LSTM cell forget gate in the style of (Pham et al., 2014).",5.2 Hyperparameters,[0],[0]
"We provide several baseline models for comparing performance of the Key-Value Retrieval Network:
• Rule-Based Model:",5.3 Baseline Models,[0],[0]
"This model is a traditional rule-based system with modular dialogue state trackers, KB query, and natural language generation components.",5.3 Baseline Models,[0],[0]
It first does an extensive domain-dependent keyword search in the user utterances to detect intent.,5.3 Baseline Models,[0],[0]
The user utterances are also provided to a lexicon to extract any entities mentioned.,5.3 Baseline Models,[0],[0]
"Collectively, this information forms the dialogue state up to a given point in the dialogue.",5.3 Baseline Models,[0],[0]
"This dialogue state is used to query the KB as appropriate, and the returned KB values are used to fill in predefined template system responses.
",5.3 Baseline Models,[0],[0]
"• Copy-Augmented Sequence-to-Sequence Network: This model is derived from the work of (Eric and Manning, 2017).",5.3 Baseline Models,[0],[0]
"It augments a sequence-to-sequence architecture with encoder attention, with an additional attention-based hard-copy mechanism over the KB entities mentioned in the encoder context.",5.3 Baseline Models,[0],[0]
This model does not explicitly incorporate information from the underlying KB and instead relies solely on dialogue history for system response generation.,5.3 Baseline Models,[0],[0]
"Unlike the best performing model of (Eric and Manning, 2017), we do not enhance the inputs to the encoder with additional entity type features, as we found that the
model performed worse on our data with this added mechanism.",5.3 Baseline Models,[0],[0]
"We choose this model for comparison as it is also end-to-end trainable and implicitly models dialogue state through learned neural representations, putting it in the same class of dialogue models as our key-value retrieval net.",5.3 Baseline Models,[0],[0]
This model has also been shown to be a competitive task-oriented dialogue baseline that can accurately interpret user input and act on this input through latent distributed representation.,5.3 Baseline Models,[0],[0]
We refer to this model as Copy Net in the results tables.,5.3 Baseline Models,[0],[0]
"Though prior work has shown that automatic evaluation metrics often correlate poorly with human assessments of dialogue agents (Liu et al., 2016), we report a number of automatic metrics in Table 3.",5.4.1 Metrics,[0],[0]
"These metrics are provided for coarse-grained evaluation of dialogue response quality:
• BLEU:",5.4.1 Metrics,[0],[0]
"We use the BLEU metric, commonly employed in evaluating machine translation systems (Papineni et al., 2002), which has also been used in past literature for evaluating dialogue systems both of the chatbot and task-oriented variety (Ritter et al., 2011; Li et al., 2016; Wen et al., 2016b).",5.4.1 Metrics,[0],[0]
"While work by (Liu et al., 2016) has demonstrated that ngram based evaluation metrics such as BLEU and METEOR do not correlate well with human performance on non-task-oriented dialogue datasets, recently (Sharma et al., 2017) have shown that these metrics can show comparatively stronger correlation with human assessment on task-oriented datasets.",5.4.1 Metrics,[0],[0]
"We, therefore, calculate average BLEU score over all responses generated by the system, and primarily report these scores to gauge our
model’s ability to accurately generate the language patterns seen in our data.
",5.4.1 Metrics,[0],[0]
• Entity F1: Each human Turker’s Car Assistant response in the test data defines a gold set of entities.,5.4.1 Metrics,[0],[0]
"To compute an entity F1, we micro-average over the entire set of system dialogue responses and use the entities in their canonicalized forms.",5.4.1 Metrics,[0],[0]
This metric evaluates the model’s ability to generate relevant entities from the underlying knowledge base and to capture the semantics of the userinitiated dialogue flow.,5.4.1 Metrics,[0],[0]
"Given that our test set contains dialogues from all three domains, we compute a per-domain entity F1 as well as an aggregated dataset entity F1.",5.4.1 Metrics,[0],[0]
"We note that other work on task-oriented dialogue by (Wen et al., 2016b; Henderson et al., 2014a) have reported the slot-tracking accuracy of their systems, which is a similar but perhaps more informative and fine-grained notion of a system’s ability to capture user semantics.",5.4.1 Metrics,[0],[0]
"Because our model does not have provisions for slot-tracking by design, we are unable to report such a metric and hence report our entity F1.",5.4.1 Metrics,[0],[0]
"We see that of our baseline models, Copy Net has the lowest aggregate entity F1 performance.",5.4.2 Results,[0],[0]
"Though it has the highest model entity F1 for the weather domain dialogues, it performs very poorly in the other domains, indicating its inability to generalize well to multiple dialogue domains and to accurately integrate relevant entities into its responses.",5.4.2 Results,[0],[0]
"Copy Net does, however, have the second highest BLEU score, which is not surprising given that the model is a powerful extension to the sequence-to-sequence modelling class, which is known to have very robust language modelling capabilities.
",5.4.2 Results,[0],[0]
"Our rule-based model has the lowest BLEU score, which is a consequence of the fact that the naturalness of the system output is very limited by the number of diverse and distinct response templates we manually provided.",5.4.2 Results,[0],[0]
This is a common issue with heuristic dialogue agents and one that could be partially alleviated through a larger collection of lexically rich response templates.,5.4.2 Results,[0],[0]
"However, the rule-based system has a very competitive aggregate entity F1.",5.4.2 Results,[0],[0]
"This is because it was designed to accurately parse the semantics of user utterances and query the underlying KB of the dialogue, through manually-provided heuristics.
",5.4.2 Results,[0],[0]
"As precursors to our key-value retrieval net, we first report results of a model that does not compute an attention over the KB (referred to as Attn.",5.4.2 Results,[0],[0]
Seq2Seq),5.4.2 Results,[0],[0]
"and show that without computing attention over the KB, the model performs poorly in entity F1 as its output is agnostic to the world state represented in the KB.",5.4.2 Results,[0],[0]
Note that this model is effectively a sequence-to-sequence model with encoder attention.,5.4.2 Results,[0],[0]
If we include an attention over the KB but do not compute an encoder attention (referred to as KV Retrieval Net no enc.,5.4.2 Results,[0],[0]
"attn.), the entity F1 increases drastically, showing that the model is able to incorporate relevant entities from the KB.",5.4.2 Results,[0],[0]
"Finally, we combine these two attention mechanisms to get our final key-value retrieval net.",5.4.2 Results,[0],[0]
"Our proposed key-value retrieval net has the highest modelling performance in BLEU, aggregate entity F1, and entity F1 for the scheduling and navigation domains.",5.4.2 Results,[0],[0]
It outperforms the rule-based aggregate entity F1 by 4.2% and outperforms the Copy Net BLEU score by 2.2 points as well as its entity F1 by 11%.,5.4.2 Results,[0],[0]
"These salient gains are noteworthy because our model is able to achieve them by learning its latent representationts directly from data, without the need for heuristics or manual labelling.
",5.4.2 Results,[0],[0]
We also report human performance on the provided metrics.,5.4.2 Results,[0],[0]
These scores were computed by taking the dialogues of the test set and having a second distinct batch of Amazon Mechanical Turk workers provide system responses given prior dialogue context.,5.4.2 Results,[0],[0]
"This, in effect, functions as an interannotator agreement score and sets a human upper bound on model performance.",5.4.2 Results,[0],[0]
"We see that there is a sizable gap between human performance on entity F1 and that of our key-value retrieval net (∼ 12.7%), though our model is on par with human performance in BLEU score.",5.4.2 Results,[0],[0]
"We randomly generated 120 distinct scenarios across the three dialogue domains, where a scenario is defined by an underlying KB as well as a user goal for the dialogue (e.g. find the nearest gas station, avoiding heavy traffic).",5.5 Human Evaluation,[0],[0]
"We then paired Amazon Mechanical Turkers with one of our systems in a real-time chat environment, where each Turker played the role of the Driver.",5.5 Human Evaluation,[0],[0]
"We evaluated the rule-based model, Copy Net, and key-value retrieval network on each of the 120 scenarios.",5.5 Human Evaluation,[0],[0]
"We also paired a Turker with another Turker for each of the scenarios, in order to get evaluations of human performance.",5.5 Human Evaluation,[0],[0]
"At the end of the chat, the Turker was asked to judge the quality of their partner according to fluency, cooperativeness, and humanlikeness on a scale from 1 to 5.",5.5 Human Evaluation,[0],[0]
The average scores per pairing are reported in Table 4.,5.5 Human Evaluation,[0],[0]
"In a separate experiment, we also had Turkers evaluate the outputs of the systems on 80 randomly selected dialogues from the test split of our dataset.",5.5 Human Evaluation,[0],[0]
"Those outputs were evaluated according to correctness, appropriateness, and humanlikeness of the responses, and the scores are reported in Table 5.
",5.5 Human Evaluation,[0],[0]
"We see that on real-time dialogues the key-value retrieval network outperforms the baseline models on all of the metrics, with especially sizeable performance gains over the Copy Net which is the only other recurrent neural model evaluated.",5.5 Human Evaluation,[0],[0]
"We also see that human performance on this assessment sets the upper bound on scores, as expected.",5.5 Human Evaluation,[0],[0]
"The results on human evaluation of test outputs show that the rule-based model provides the most correct system responses, the KV network provides the most appropriate responses, and the Copy Net gives the most humanlike responses by small margins.",5.5 Human Evaluation,[0],[0]
"We should note, however, that the second regime for human evaluation is more unrealistic because it involves providing a dialogue context that is directly sampled from our dataset, whereas the first regime of real-time dialogues measures the models’ abilities to adapt to new and noisier user input.",5.5 Human Evaluation,[0],[0]
"This suggests that the first set of results are more meaningful and representative for assessing overall model efficacy.
",5.5 Human Evaluation,[0],[0]
Examples of dialogues conducted between our model and Turkers are included in Figure 3.,5.5 Human Evaluation,[0],[0]
"Particularly noteworthy is our model’s ability to seamlessly integrate world information from the underlying KBs in the respective dialogues, while
still producing very naturalistic utterances.",5.5 Human Evaluation,[0],[0]
The model is able to do this effectively across multiple domains.,5.5 Human Evaluation,[0],[0]
"In this work, we have presented a novel neural task-oriented dialogue model that is able to sustain grounded discourse across a variety of domains by retrieving world knowledge represented in knowledge bases.",6 Conclusion and Future Work,[0],[0]
"It smoothly incorporates
this world knowledge into natural-sounding system responses in an end-to-end trainable fashion, without the need to explicitly model dialogue state.",6 Conclusion and Future Work,[0],[0]
Our model outperforms competitive heuristic and neural baselines on both automatic and human evaluation metrics.,6 Conclusion and Future Work,[0],[0]
"In addition, we have introduced a publicly available dialogue dataset across three domains in the in-car personal assistant space that we hope will help the data scarcity issue present in task-oriented dialogue research.
",6 Conclusion and Future Work,[0],[0]
Future work will address closing the margin between the Key-Value Retrieval Network and human performance on the various metrics.,6 Conclusion and Future Work,[0],[0]
This will include developing new methods for robust handling of joint KB attributes as well as usage of the KB that requires more pragmatic understanding of the world via notions such as temporal reasoning.,6 Conclusion and Future Work,[0],[0]
"The authors wish to thank He He, Peng Qi, Urvashi Khandelwal, and Reid Pryzant for their valuable feedback and insights.",Acknowledgments,[0],[0]
"We gratefully acknowledge the funding of the Ford Research and Innovation Center, under Grant No. 124344.",Acknowledgments,[0],[0]
Neural task-oriented dialogue systems often struggle to smoothly interface with a knowledge base.,abstractText,[0],[0]
"In this work, we seek to address this problem by proposing a new neural dialogue agent that is able to effectively sustain grounded, multi-domain discourse through a novel key-value retrieval mechanism.",abstractText,[0],[0]
The model is end-to-end differentiable and does not need to explicitly model dialogue state or belief trackers.,abstractText,[0],[0]
"We also release a new dataset of 3,031 dialogues that are grounded through underlying knowledge bases and span three distinct tasks in the in-car personal assistant space: calendar scheduling, weather information retrieval, and point-of-interest navigation.",abstractText,[0],[0]
Our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rulebased system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics.,abstractText,[0],[0]
Key-Value Retrieval Networks for Task-Oriented Dialogue,title,[0],[0]
Reasoning is a key concept in artificial intelligence.,1. Introduction,[0],[0]
"A host of applications such as search engines, question-answering systems, conversational dialogue systems, and social networks require reasoning over underlying structured knowledge.",1. Introduction,[0],[0]
Effective representation and learning over such knowledge has come to the fore as a very important task.,1. Introduction,[0],[0]
"In particular, Knowledge Graphs have gained much attention as an important model for studying complex multi-relational settings.",1. Introduction,[0],[0]
"Traditionally, knowledge graphs are considered to be static snapshot of multi-relational data.",1. Introduction,[0],[0]
"However, recent availability of large amount of event based interaction data that exhibits complex temporal dynamics in addition to its multi-relational nature has created the need for approaches that can characterize and reason over tempo-
1College of Computing, Georgia Institute of Technology.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Rakshit Trivedi <rstrivedi@gatech.edu>, Le Song <lsong@cc.gatech.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
rally evolving systems.",1. Introduction,[0],[0]
"For instance, GDELT (Leetaru & Schrodt, 2013) and ICEWS (Boschee et al., 2017) are two popular event based data repository that contains evolving knowledge about entity interactions across the globe.
",1. Introduction,[0],[0]
"Thus traditional knowledge graphs need to be augmented into Temporal Knowledge Graphs, where facts occur, recur or evolve over time in these graphs, and each edge in the graphs have temporal information associated with it.",1. Introduction,[0],[0]
Figure 1 shows a subgraph snapshot of such temporal knowledge graph.,1. Introduction,[0],[0]
Static knowledge graphs suffer from incompleteness resulting in their limited reasoning ability.,1. Introduction,[0],[0]
Most work on static graphs have therefore focussed on advancing entity-relationship representation learning to infer missing facts based on available knowledge.,1. Introduction,[0],[0]
"But these methods lack ability to use rich temporal dynamics available in underlying data represented by temporal knowledge graphs.
",1. Introduction,[0],[0]
Effectively capturing temporal dependencies across facts in addition to the relational (structural) dependencies can help improve the understanding on behavior of entities and how they contribute to generation of facts over time.,1. Introduction,[0],[0]
"For example, one can precisely answer questions like:
• Object prediction.",1. Introduction,[0],[0]
"(Who) will Donald Trump mention next?
",1. Introduction,[0],[0]
• Subject prediction.,1. Introduction,[0],[0]
"(Which country) will provide material support to US next month?
",1. Introduction,[0],[0]
• Time prediction.,1. Introduction,[0],[0]
"(When) will Bob visit Burger King?
”People (entities) change over time and so do relationships.”",1. Introduction,[0],[0]
"When two entities forge a relationship, the newly formed edge drives their preferences and behavior.",1. Introduction,[0],[0]
"This change is effected by combination of their own historical factors (temporal evolution) and their compatibility with the historical factors of the other entity (mutual evolution).
",1. Introduction,[0],[0]
"For instance, if two countries have tense relationships, they are more likely to engage in conflicts.",1. Introduction,[0],[0]
"On the other hand, two countries forging an alliance are most likely to take confrontational stands against enemies of each other.",1. Introduction,[0],[0]
"Finally, time plays a vital role in this process.",1. Introduction,[0],[0]
A country that was once peaceful may not have same characteristics 10 years in future due to various facts (events) that may occur during that period.,1. Introduction,[0],[0]
Being able to capture this temporal and evolutionary effects can help us reason better about future relationship of an entity.,1. Introduction,[0],[0]
"We term this combined phenomenon of evolving entities and their dynamically changing relationships over time as “knowledge evolution”.
",1. Introduction,[0],[0]
"In this paper, we propose an elegant framework to model knowledge evolution and reason over complex non-linear interactions between entities in a multi-relational setting.",1. Introduction,[0],[0]
The key idea of our work is to model the occurrence of a fact as multidimensional temporal point process whose conditional intensity function is modulated by the relationship score for that fact.,1. Introduction,[0],[0]
The relationship score further depends on the dynamically evolving entity embeddings.,1. Introduction,[0],[0]
"Specifically, our work makes the following contributions:
• We propose a novel deep learning architecture that evolves over time based on availability of new facts.",1. Introduction,[0],[0]
"The dynamically evolving network will ingest the incoming new facts, learn from them and update the embeddings of involved entities based on their recent relationships and temporal behavior.",1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
"Besides predicting the occurrence of a fact, our architecture has ability to predict time when the fact may potentially occur which is not possible by any prior relational learning approaches to the best of our knowledge.",1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
Our model supports Open World Assumption as missing links are not considered to be false and may potentially occur in future.,1. Introduction,[0],[0]
It further supports prediction over unseen entities due to its novel dynamic embedding process.,1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
The large-scale experiments on two real world datasets show that our framework has consistently and significantly better performance for link prediction than stateof-arts that do not account for temporal and evolving non-linear dynamics.,1. Introduction,[0],[0]
• Our work aims to introduce the use of powerful mathematical tool of temporal point process framework for temporal reasoning over dynamically evolving knowledge graphs.,1. Introduction,[0],[0]
It has potential to open a new research direction in reasoning over time for various multi-relational settings with underlying spatio-temporal dynamics.,1. Introduction,[0],[0]
"A temporal point process (Cox & Lewis, 2006) is a random process whose realization consists of a list of events localized in time, {ti} with ti ∈ R+.",2.1. Temporal Point Process,[0],[0]
"Equivalently, a given temporal point process can be represented as a counting process, N(t), which records the number of events before time t.
An important way to characterize temporal point processes is via the conditional intensity function λ(t), a stochastic model for the time of the next event given all the previous events.",2.1. Temporal Point Process,[0],[0]
"Formally, λ(t)dt is the conditional probability of observing an event in a small window [t, t+ dt) given the history T (t) := {tk|tk < t} up to t, i.e.,
λ(t)dt := P {event in [t, t+ dt)|T (t)} = E[dN(t)|T (t)]
(1)
where one typically assumes that only one event can happen in a small window of size dt, i.e., dN(t) ∈ {0, 1}.
",2.1. Temporal Point Process,[0],[0]
"From the survival analysis theory (Aalen et al., 2008), given the history T = {t1, . . .",2.1. Temporal Point Process,[0],[0]
", tn}, for any t > tn, we characterize the conditional probability that no event happens during [tn, t) as S(t|T ) =",2.1. Temporal Point Process,[0],[0]
exp ( − ∫ t tn λ(τ) dτ ) .,2.1. Temporal Point Process,[0],[0]
"Moreover, the conditional density that an event occurs at time t is defined as : f(t) = λ(t)S(t) (2)
The functional form of the intensity λ(t) is often designed to capture the phenomena of interests.",2.1. Temporal Point Process,[0],[0]
"Some Common forms include: Poisson Process, Hawkes processes (Hawkes, 1971), Self-Correcting Process (Isham & Westcott, 1979), Power Law and Rayleigh Process.
",2.1. Temporal Point Process,[0],[0]
"Rayleigh Process is a non-monotonic process and is welladapted to modeling fads, where event likelihood drops rapidly after rising to a peak.",2.1. Temporal Point Process,[0],[0]
"Its intensity function is λ(t) = α · (t), where α > 0 is the weight parameter, and the log survival function is logS(t|α) = −α · (t)2/2.",2.1. Temporal Point Process,[0],[0]
We define a Temporal Knowledge Graph (TKG) as a multirelational directed graph with timestamped edges between any pair of nodes.,2.2. Temporal Knowledge Graph representation,[0],[0]
"In a TKG, each edge between two nodes represent an event in the real world and edge type (relationship) represent the corresponding event type.",2.2. Temporal Knowledge Graph representation,[0],[0]
Further an edge may be available multiple times (recurrence).,2.2. Temporal Knowledge Graph representation,[0],[0]
We do not allow duplicate edges and self-loops in graph.,2.2. Temporal Knowledge Graph representation,[0],[0]
"Hence, all recurrent edges will have different time points and every edge will have distinct subject and object entities.
",2.2. Temporal Knowledge Graph representation,[0],[0]
"Given ne entities and nr relationships, we extend traditional triplet representation for knowledge graphs to introduce time dimension and represent each fact in TKG as a quadruplet (es, r, eo, t), where es, eo ∈ {1, . . .",2.2. Temporal Knowledge Graph representation,[0],[0]
", ne}, es 6= eo,
r ∈ {1, . . .",2.2. Temporal Knowledge Graph representation,[0],[0]
", nr}, t ∈",2.2. Temporal Knowledge Graph representation,[0],[0]
R+.,2.2. Temporal Knowledge Graph representation,[0],[0]
"It represents the creation of relationship edge r between subject entity es, and object entity eo at time t. The complete TKG can therefore be represented as an ne × ne",2.2. Temporal Knowledge Graph representation,[0],[0]
× nr × T - dimensional tensor where T is the total number of available time points.,2.2. Temporal Knowledge Graph representation,[0],[0]
"Consider a TKG comprising of N edges and denote the globally ordered set of corresponding N observed events as D = {(es, r, eo, t)n}Nn=1, where 0 ≤ t1 ≤ t2 . . .",2.2. Temporal Knowledge Graph representation,[0],[0]
≤ T .,2.2. Temporal Knowledge Graph representation,[0],[0]
We present our unified knowledge evolution framework (Know-Evolve) for reasoning over temporal knowledge graphs.,3. Evolutionary Knowledge Network,[0],[0]
"The reasoning power of Know-Evolve stems from the following three major components:
1.",3. Evolutionary Knowledge Network,[0],[0]
"A powerful mathematical tool of temporal point process that models occurrence of a fact.
2.",3. Evolutionary Knowledge Network,[0],[0]
"A bilinear relationship score that captures multirelational interactions between entities and modulates the intensity function of above point process.
",3. Evolutionary Knowledge Network,[0],[0]
3.,3. Evolutionary Knowledge Network,[0],[0]
A novel deep recurrent network that learns non-linearly and mutually evolving latent representations of entities based on their interactions with other entities in multirelational space over time.,3. Evolutionary Knowledge Network,[0],[0]
Large scale temporal knowledge graphs exhibit highly heterogeneous temporal patterns of events between entities.,3.1. Temporal Process,[0],[0]
Discrete epoch based methods to model such temporal behavior fail to capture the underlying intricate temporal dependencies.,3.1. Temporal Process,[0],[0]
"We therefore model time as a random variable and use temporal point process to model occurrence of fact.
",3.1. Temporal Process,[0],[0]
"More concretely, given a set of observed events O corresponding to a TKG, we construct a relationship-modulated multidimensional point process to model occurrence of these events.",3.1. Temporal Process,[0],[0]
"We characterize this point process with the following conditional intensity function:
λe s,eo r (t|t̄) = f(ge",3.1. Temporal Process,[0],[0]
"s,eo r (t̄))",3.1. Temporal Process,[0],[0]
"∗ (t− t̄) (3)
where t > t̄, t is the time of the current event and t̄ = max(te
s−, teo−) is the most recent time point when either subject or object entity was involved in an event before time t. Thus, λe s,eo
r (t|t̄) represents intensity of event involving triplet (es, r, ej) at time t given previous time point t̄ when either es or eo was involved in an event.",3.1. Temporal Process,[0],[0]
This modulates the intensity of current event based on most recent activity on either entities’ timeline and allows to capture scenarios like non-periodic events and previously unseen events.,3.1. Temporal Process,[0],[0]
f(·) = exp(·) ensures that intensity is positive and well defined.,3.1. Temporal Process,[0],[0]
"The first term in (3) modulates the intensity function by the relational compatibility score between the involved enti-
ties in that specific relationship.",3.2. Relational Score Function,[0],[0]
"Specifically, for an event (es, r, eo, t) ∈ D occurring at time t, the score term ges,eor is computed using a bilinear formulation as follows:
ge s,eo r (t) =",3.2. Relational Score Function,[0],[0]
v,3.2. Relational Score Function,[0],[0]
es(t−)T,3.2. Relational Score Function,[0],[0]
·,3.2. Relational Score Function,[0],[0]
"Rr · ve o (t−) (4)
where ve s , ve s ∈ Rd represent latent feature embeddings of entities appearing in subject and object position respectively.",3.2. Relational Score Function,[0],[0]
Rr ∈ Rd×d represents relationship weight matrix which attempts to capture interaction between two entities in the specific relationship space r.,3.2. Relational Score Function,[0],[0]
This matrix is unique for each relation in dataset and is learned during training.,3.2. Relational Score Function,[0],[0]
"t is time of current event and t− represent time point just before time t. ve s
(t−) and veo(t−), therefore represent most recently updated vector embeddings of subject and object entities respectively before time t. As these entity embeddings evolve and update over time, ge s,eo
r (t) is able to capture cumulative knowledge learned about the entities over the history of events that have affected their embeddings.",3.2. Relational Score Function,[0],[0]
We represent latent feature embedding of an entity e at time t with a low-dimensional vector ve(t).,3.3. Dynamically Evolving Entity Representations,[0],[0]
We add superscript s and o as shown in Eq.,3.3. Dynamically Evolving Entity Representations,[0],[0]
(4) to indicate if the embedding corresponds to entity in subject or object position respectively.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"We also use relationship-specific low-dimensional representation for each relation type.
",3.3. Dynamically Evolving Entity Representations,[0],[0]
The latent representations of entities change over time as entities forge relationships with each other.,3.3. Dynamically Evolving Entity Representations,[0],[0]
We design novel deep recurrent neural network based update functions to capture mutually evolving and nonlinear dynamics of entities in their vector space representations.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"We consider an event m = (es, r, eo, t)m ∈ D occurring at time t. Also, consider that event m is entity es’s p-th event while it is entity eo’s q-th event.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"As entities participate in events in a heterogeneous pattern, it is less likely that p = q",3.3. Dynamically Evolving Entity Representations,[0],[0]
although not impossible.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Having observed this event, we update the embeddings of two involved entities as follows:
Subject Embedding:
ve s
(tp) = σ(W s t(tp − tp−1) +",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Whh · he
s
(tp−))",3.3. Dynamically Evolving Entity Representations,[0],[0]
"he s (tp−) = σ(Wh · [ve s (tp−1)⊕ ve o (tp−)⊕ re s p−1])
(5)
Object Embedding:
ve o
(tq) = σ(W o t (tq − tq−1) +",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Whh · he
o
(tq−))",3.3. Dynamically Evolving Entity Representations,[0],[0]
"he o (tq−) = σ(Wh · [ve o (tq−1)⊕ ve s (tq−)⊕ re o q−1])
(6)
where, ve s , ve o ∈ Rd.",3.3. Dynamically Evolving Entity Representations,[0],[0]
tp = tq = tm is the time of observed event.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"For subject embedding update in Eq. (5), tp−1 is the time point of the previous event in which entity es was
involved.",3.3. Dynamically Evolving Entity Representations,[0],[0]
tp− is the timepoint just before time tp.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Hence, ve s
(tp−1) represents latest embedding for entity es that was updated after (p − 1)-th event for that entity.",3.3. Dynamically Evolving Entity Representations,[0],[0]
veo(tp−) represents latest embedding for entity eo that was updated any time just before tp = tm.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"This accounts for the fact that entity eo may have been involved in some other event during the interval between current (p) and previous (p− 1) event of entity es. re s
p−1 ∈ Rc represent relationship embedding that corresponds to relationship type of the (p− 1)-th event of entity es.",3.3. Dynamically Evolving Entity Representations,[0],[0]
Note that the relationship vectors are static and do not evolve over time.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"he s
(tp−)",3.3. Dynamically Evolving Entity Representations,[0],[0]
∈ Rd is the hidden layer.,3.3. Dynamically Evolving Entity Representations,[0],[0]
The semantics of notations apply similarly to object embedding update in Eq.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"(6).
",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Wst,W o t ∈ Rd×1, Whh ∈ Rd×l and Wh ∈ Rl×(2d+c) are weight parameters in network learned during training.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Wst,W o t captures variation in temporal drift for subject and object respectively.",3.3. Dynamically Evolving Entity Representations,[0],[0]
Whh is shared parameter that captures recurrent participation effect for each entity.,3.3. Dynamically Evolving Entity Representations,[0],[0]
Wh is a shared projection matrix applied to consider the compatibility of entities in their previous relationships.,3.3. Dynamically Evolving Entity Representations,[0],[0]
⊕ represent simple concatenation operator.,3.3. Dynamically Evolving Entity Representations,[0],[0]
σ(·) denotes nonlinear activation function (tanh in our case).,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Our formulations use simple RNN units but it can be replaced with more expressive
units like LSTM or GRU in straightforward manner.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"In our experiments, we choose d = l and d 6= c",3.3. Dynamically Evolving Entity Representations,[0],[0]
but they can be chosen differently.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Below we explain the rationales of our deep recurrent architecture that captures nonlinear evolutionary dynamics of entities over time.
",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Reasoning Based on Structural Dependency: The hidden layer (he s
) reasons for an event by capturing the compatibility of most recent subject embedding with most recent object embedding in previous relationship of subject entity.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"This accounts for the behavior that within a short period of time, entities tend to form relationships with other entities that have similar recent actions and goals.",3.3. Dynamically Evolving Entity Representations,[0],[0]
This layer thereby uses historical information of the two nodes involved in current event and the edges they both created before this event.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"This holds symmetrically for hidden layer (he o ).
",3.3. Dynamically Evolving Entity Representations,[0],[0]
Reasoning based on Temporal Dependency: The recurrent layer uses hidden layer information to model the intertwined evolution of entity embeddings over time.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Specifically this layer has two main components:
• Drift over time:",3.3. Dynamically Evolving Entity Representations,[0],[0]
The first term captures the temporal difference between consecutive events on respective dimension of each entity.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"This captures the external influences
that entities may have experienced between events and allows to smoothly drift their features over time.",3.3. Dynamically Evolving Entity Representations,[0],[0]
This term will not contribute anything in case when multiple events happen for an entity at same time point (e.g. within a day in our dataset).,3.3. Dynamically Evolving Entity Representations,[0],[0]
"While tp − tp−1 may exhibit high variation, the corresponding weight parameter will capture these variations and along with the second recurrent term, it will prevent ve s (tp) to collapse.
",3.3. Dynamically Evolving Entity Representations,[0],[0]
• Relation-specific Mutual Evolution: The latent features of both subject and object entities influence each other.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"In multi-relational setting, this is further affected by the relationship they form.",3.3. Dynamically Evolving Entity Representations,[0],[0]
Recurrent update to entity embedding with the information from the hidden layer allows to capture the intricate non-linear and evolutionary dynamics of an entity with respect to itself and the other entity in a specific relationship space.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Figure (2) and Figure (3) shows the architecture of knowledge evolution framework and one step of our model.
",3.4. Understanding Unified View of Know-Evolve,[0],[0]
The updates to the entity representations in Eq. (5) and (6) are driven by the events involving those entities which makes the embeddings piecewise constant i.e. an entity embedding remains unchanged in the duration between two events involving that entity and updates only when an event happens on its dimension.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
This is justifiable as an entity’s features may update only when it forges a relationship with other entity within the graph.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
"Note that the first term in Eq. (5) and (6) already accounts for any external influences.
",3.4. Understanding Unified View of Know-Evolve,[0],[0]
"Having observed an event at time t, Know-Evolve considers it as an incoming fact that brings new knowledge about the entities involved in that event.",3.4. Understanding Unified View of Know-Evolve,[0],[0]
It computes the intensity of that event in Eq.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
(3) which is based on relational compatibility score in Eq. (4) between most recent latent embeddings of involved entities.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
"As these embeddings are piecewise constant, we use time interval term (t− t̄) in Eq.",3.4. Understanding Unified View of Know-Evolve,[0],[0]
(3) to make the overall intensity piecewise linear which is standard mathematical choice for efficient computation in point process framework.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
This formulation naturally leads to Rayleigh distribution which models time interval between current event and most recent event on either entities’ dimension.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
Rayleigh distribution has an added benefit of having a simple analytic form of likelihood which can be further used to find entity for which the likelihood reaches maximum value and thereby make precise entity predictions.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
"The complete parameter space for the above model is: Ω = {{Ve}e=1:ne , {Rr}r=1:nr ,We,Wst,Wot ,Wh, Whh,Wr}.",4. Efficient Training Procedure,[0],[0]
"Although Know-Evolve gains expressive power from deep architecture, Table 4 (Appendix D) shows that the memory footprint of our model is comparable to
simpler relational models.",4. Efficient Training Procedure,[0],[0]
The intensity function in (3) allows to use maximum likelihood estimation over all the facts as our objective function.,4. Efficient Training Procedure,[0],[0]
"Concretely, given a collection of facts recorded in a temporal window [0, T ), we learn the model by minimizing the joint negative log likelihood of intensity function (Daley & Vere-Jones, 2007) written as:
L =",4. Efficient Training Procedure,[0],[0]
"− N∑ p=1 log ( λe s,eo r (tp|t̄p) )
︸ ︷︷ ︸ happened events
+ nr∑ r=1",4. Efficient Training Procedure,[0],[0]
"ne∑ es=1 ne∑ eo=1 ∫ T 0 λe s,eo
r (τ |τ̄) dτ︸ ︷︷ ︸ survival term
(7)
",4. Efficient Training Procedure,[0],[0]
The first term maximizes the probability of specific type of event between two entities; the second term penalizes non-presence of all possible types of events between all possible entity pairs in a given observation window.,4. Efficient Training Procedure,[0],[0]
We use Back Propagation Through Time (BPTT) algorithm to train our model.,4. Efficient Training Procedure,[0],[0]
"Previous techniques (Du et al., 2016; Hidasi et al., 2016) that use BPTT algorithm decompose data into independent sequences and train on mini-batches of those sequences.",4. Efficient Training Procedure,[0],[0]
But there exists intricate relational and temporal dependencies between data points in our setting which limits our ability to efficiently train by decomposing events into independent sequences.,4. Efficient Training Procedure,[0],[0]
"To address this challenge, we design an efficient Global BPTT algorithm (Algorithm 2, Appendix A) that creates mini-batches of events over global timeline in sliding window fashion and allows to capture dependencies across batches while retaining efficiency.
",4. Efficient Training Procedure,[0],[0]
Intractable Survival Term.,4. Efficient Training Procedure,[0],[0]
"To compute the second survival term in (7), since our intensity function is modulated by relation-specific parameter, for each relationship we need to compute survival probability over all pairs of entities.",4. Efficient Training Procedure,[0],[0]
"Next, given a relation r and entity pair (es, eo), we denote P(es,eo) as total number of events of type r involving either es or eo in window",4. Efficient Training Procedure,[0],[0]
"[T0, T ).",4. Efficient Training Procedure,[0],[0]
"As our intensity function is piecewise-linear, we can decompose the integration term − ∫ T T0 λe s,eo
r (τ |τ̄)dτ into multiple time intervals where intensity is constant:∫ T
T0
λe s,eo
r (τ |τ̄)dτ
= P(es,eo)−1∑ p=1 ∫ tp+1 tp λe s,eo r (τ |τ̄)dτ
= P(es,eo)−1∑ p=1 (t2p+1 − t2p) · exp(ve s (tp) T ·Rr · ve o (tp))
(8)
The integral calculations in (8) for all possible triplets requiresO(n2r) computations (n is number of entities and r is the number of relations).",4. Efficient Training Procedure,[0],[0]
"This is computationally intractable
Algorithm 1 Survival Loss Computation in mini-batch Input: Minibatch E , size s, Batch Entity List bl loss = 0.0 for p = 0 to s− 1 do
subj feat = Ep → ve s
(t−) obj feat = Ep → ve o
(t−) rel weight =",4. Efficient Training Procedure,[0],[0]
Ep → Rr t end =,4. Efficient Training Procedure,[0],[0]
"Ep → t subj surv = 0, obj surv = 0, total surv = 0 for i = 0 to bl.size do
obj other = bl[i] if obj other == Ep → es then
continue end if t̄ = max(te
s−, teo−) subj surv",4. Efficient Training Procedure,[0],[0]
+= (t end2 − t̄2) · exp(subj featT · rel weight ·,4. Efficient Training Procedure,[0],[0]
"obj other feat)
end for for j = 0 to bl.size do
subj other = bl[i] if subj other == Ep → eo then
continue end if t̄ = max(te
s−, teo−)",4. Efficient Training Procedure,[0],[0]
obj surv += (t end2,4. Efficient Training Procedure,[0],[0]
"− t̄2) · exp(subj other featT · rel weight · obj feat)
end for loss += subj",4. Efficient Training Procedure,[0],[0]
"surv + obj surv
end for
and also unnecessary.",4. Efficient Training Procedure,[0],[0]
Knowledge tensors are inherently sparse and hence it is plausible to approximate the survival loss in a stochastic setting.,4. Efficient Training Procedure,[0],[0]
"We take inspiration from techniques like noise contrastive (Gutmann & Hyvärinen, 2012) estimation and adopt a random sampling strategy to compute survival loss:",4. Efficient Training Procedure,[0],[0]
"Given a mini-batch of events, for each relation in the mini-batch, we compute dyadic survival term across all entities in that batch.",4. Efficient Training Procedure,[0],[0]
Algorithm 1 presents the survival loss computation procedure.,4. Efficient Training Procedure,[0],[0]
"While this procedure may randomly avoid penalizing some dimensions in a relationship, it still includes all dimensions that had events on them.",4. Efficient Training Procedure,[0],[0]
The computational complexity for this procedure will be O(2n′r′m) where m is size of mini-batch and n′ and r′ represent number of entities and relations in the mini-batch.,4. Efficient Training Procedure,[0],[0]
"We use two datasets: Global Database of Events, Language, and Tone (GDELT) (Leetaru & Schrodt, 2013) and Integrated Crisis Early Warning System (ICEWS) (Boschee et al., 2017) which has recently gained attention in learning community (Schein et al., 2016) as useful temporal KGs.",5.1. Temporal Knowledge Graph Data,[0],[0]
"GDELT data is collected from April 1, 2015 to Mar 31,
2016 (temporal granularity of 15 mins).",5.1. Temporal Knowledge Graph Data,[0],[0]
"ICEWS dataset is collected from Jan 1, 2014 to Dec 31, 2014 (temporal granularity of 24 hrs).",5.1. Temporal Knowledge Graph Data,[0],[0]
"Both datasets contain records of events that include two actors, action type and timestamp of event.",5.1. Temporal Knowledge Graph Data,[0],[0]
We use different hierarchy of actions in two datasets - (top level 20 relations for GDELT while last level 260 relations for ICEWS) - to test on variety of knowledge tensor configurations.,5.1. Temporal Knowledge Graph Data,[0],[0]
Note that this does not filter any record from the dataset.,5.1. Temporal Knowledge Graph Data,[0],[0]
"We process both datasets to remove any duplicate quadruples, any mono-actor events (i.e., we use only dyadic events), and self-loops.",5.1. Temporal Knowledge Graph Data,[0],[0]
We report our main results on full versions of each dataset.,5.1. Temporal Knowledge Graph Data,[0],[0]
We create smaller version of both datasets for exploration purposes.,5.1. Temporal Knowledge Graph Data,[0],[0]
Table 1 (Appendix B) provide statistics about the data and Table 2 (Appendix B) demonstrates the sparsity of knowledge tensor.,5.1. Temporal Knowledge Graph Data,[0],[0]
"We compare the performance of our method with following relational learning methods: RESCAL, Neural Tensor Network (NTN), Multiway Neural Network (ER-MLP), TransE and TransR.",5.2. Competitors,[0],[0]
"To the best of our knowledge, there are no existing relational learning approaches that can predict time for a new fact.",5.2. Competitors,[0],[0]
"Hence we devised two baseline methods for evaluating time prediction performance — (i) Multi-dimensional Hawkes process (MHP): We model dyadic entity interactions as multi-dimensional Hawkes process similar to (Du et al., 2015).",5.2. Competitors,[0],[0]
"Here, an entity pair constitutes a dimension and for each pair we collect sequence of events on its dimension and train and test on that sequence.",5.2. Competitors,[0],[0]
Relationship is not modeled in this setup.,5.2. Competitors,[0],[0]
"(ii) Recurrent Temporal Point Process (RTPP): We implement a simplified version of RMTPP (Du et al., 2016) where we do not predict the marker.",5.2. Competitors,[0],[0]
"For training, we concatenate static entity and relationship embeddings and augment the resulting vector with temporal feature.",5.2. Competitors,[0],[0]
This augmented unit is used as input to global RNN which produces output vector ht.,5.2. Competitors,[0],[0]
"During test time, for a given triplet, we use this vector ht to compute conditional intensity of the event given history which is further used to predict next event time.",5.2. Competitors,[0],[0]
Appendix C provides implementation details of our method and competitors.,5.2. Competitors,[0],[0]
"We report experimental results on two tasks: Link prediction and Time prediction.
",5.3. Evaluation Protocol,[0],[0]
Link prediction:,5.3. Evaluation Protocol,[0],[0]
"Given a test quadruplet (es, r, eo, t), we replace eo with all the entities in the dataset and compute the conditional density de s,eo
r = λ es,eo r (t)S es,eo
r (t) for the resulting quadruplets including the ground truth.",5.3. Evaluation Protocol,[0],[0]
We then sort all the quadruplets in the descending order of this density to rank the correct entity for object position.,5.3. Evaluation Protocol,[0],[0]
"We also conduct testing after applying the filtering techniques described in (Bordes et al., 2013) -",5.3. Evaluation Protocol,[0],[0]
"we only rank against the entities that do not generate a true triplet (seen in train) when it replaces
ground truth object.",5.3. Evaluation Protocol,[0],[0]
"We report Mean Absolute Rank (MAR), Standard Deviation for MAR and HITS@10 (correct entity in top 10 predictions) for both Raw and Filtered Versions.
",5.3. Evaluation Protocol,[0],[0]
"Time prediction: Give a test triplet (es, r, eo), we predict the expected value of next time the fact (es, r, eo) can occur.",5.3. Evaluation Protocol,[0],[0]
"This expectation is defined by: Ees,eor (t) =√
π
2 exp(ge s,eo r (t)) , where ge
s,eo
r (t) is computed using equa-
tion (4).",5.3. Evaluation Protocol,[0],[0]
"We report Mean Absolute Error (MAE) between the predicted time and true time in hours.
",5.3. Evaluation Protocol,[0],[0]
Sliding Window Evaluation.,5.3. Evaluation Protocol,[0],[0]
"As our work concentrates on temporal knowledge graphs, it is more interesting to see the performance of methods over time span of test set as compared to single rank value.",5.3. Evaluation Protocol,[0],[0]
This evaluation method can help to realize the effect of modeling temporal and evolutionary knowledge.,5.3. Evaluation Protocol,[0],[0]
We therefore partition our test set in 12 different slides and report results in each window.,5.3. Evaluation Protocol,[0],[0]
"For both datasets, each slide included 2 weeks of time.",5.3. Evaluation Protocol,[0],[0]
Link Prediction Results.,5.4. Quantitative Analysis,[0],[0]
"Figure (4, 5, 6) demonstrate link prediction performance comparison on both datasets.",5.4. Quantitative Analysis,[0],[0]
"Know-Evolve significantly and consistently outperforms all competitors in terms of prediction rank without any dete-
rioration over time.",5.4. Quantitative Analysis,[0],[0]
Neural Tensor Network’s second best performance compared to other baselines demonstrate its rich expressive power but it fails to capture the evolving dynamics of intricate dependencies over time.,5.4. Quantitative Analysis,[0],[0]
"This is further substantiated by its decreasing performance as we move test window further in time.
",5.4. Quantitative Analysis,[0],[0]
The second row represents deviation error for MAR across samples in a given test window.,5.4. Quantitative Analysis,[0],[0]
Our method achieves significantly low deviation error compared to competitors making it most stable.,5.4. Quantitative Analysis,[0],[0]
"Finally, high performance on HITS@10 metric demonstrates extensive discriminative ability of KnowEvolve.",5.4. Quantitative Analysis,[0],[0]
"For instance, GDELT has only 20 relations but 32M events where many entities interact with each other in multiple relationships.",5.4. Quantitative Analysis,[0],[0]
"In this complex setting, other methods depend only on static entity embeddings to perform prediction unlike our method which does effectively infers new knowledge using powerful evolutionary network and provides accurate prediction results.
",5.4. Quantitative Analysis,[0],[0]
Time Prediction Results.,5.4. Quantitative Analysis,[0],[0]
Figure 7 demonstrates that Know-Evolve performs significantly better than other point process based methods for predicting time.,5.4. Quantitative Analysis,[0],[0]
MHP uses a specific parametric form of the intensity function which limits its expressiveness.,5.4. Quantitative Analysis,[0],[0]
"Further, each entity pair interaction is modeled as an independent dimension and does not take
into account relational feature which fails to capture the intricate influence of different entities on each other.",5.4. Quantitative Analysis,[0],[0]
"On the other hand, RTPP uses relational features as part of input, but it sees all events globally and cannot model the intricate evolutionary dependencies on past events.",5.4. Quantitative Analysis,[0],[0]
"We observe that our method effectively captures such non-linear relational and temporal dynamics.
",5.4. Quantitative Analysis,[0],[0]
"In addition to the superior quantitative performance, we demonstrate the effectiveness of our method by providing extensive exploratory analysis in Appendix E.",5.4. Quantitative Analysis,[0],[0]
"In this section, we discuss relevant works in relational learning and temporal modeling techniques.",6. Related Work,[0],[0]
"Among various relational learning techniques, neural embedding models that focus on learning low-dimensional representations of entities and relations have shown stateof-the-art performance.",6.1. Relational Learning,[0],[0]
These methods compute a score for the fact based on different operations on these latent representations.,6.1. Relational Learning,[0],[0]
"Such models can be mainly categorized into two variants:
Compositional Models.",6.1. Relational Learning,[0],[0]
"RESCAL (Nickel et al., 2011) uses a relation specific weight matrix to explain triplets via pairwise interactions of latent features.",6.1. Relational Learning,[0],[0]
"Neural Tensor Network (NTN) (Socher et al., 2013) is more expressive model as it combines a standard NN layer with a bilinear tensor layer.",6.1. Relational Learning,[0],[0]
"(Dong et al., 2014) employs a concatenationprojection method to project entities and relations to lower dimensional space.",6.1. Relational Learning,[0],[0]
"Other sophisticated models include Holographic Embeddings (HoLE) (Nickel et al., 2016b) that employs circular correlation on entity embeddings and Neural Association Models (NAM) (Liu et al., 2016), a deep network used for probabilistic reasoning.
",6.1. Relational Learning,[0],[0]
Translation Based Models.,6.1. Relational Learning,[0],[0]
"(Bordes et al., 2011) uses two relation-specific matrices to project subject and object entities and computes L1 distance to score a fact between two entity vectors.",6.1. Relational Learning,[0],[0]
"(Bordes et al., 2013) proposed TransE model that computes score as a distance between relation-specific translations of entity embeddings.",6.1. Relational Learning,[0],[0]
"(Wang et al., 2014) improved",6.1. Relational Learning,[0],[0]
"TransE by allowing entities to have distributed representations on relation specific hyperplane where distance
between them is computed.",6.1. Relational Learning,[0],[0]
TransR,6.1. Relational Learning,[0],[0]
"(Lin et al., 2015) extends this model to use separate semantic spaces for entities and relations and does translation in the relationship space.
",6.1. Relational Learning,[0],[0]
"(Nickel et al., 2016a) and (Yang et al., 2015; Toutanova & Chen, 2015) contains comprehensive reviews and empirical comparison of relational learning techniques respectively.",6.1. Relational Learning,[0],[0]
All these methods consider knowledge graphs as static models and lack ability to capture temporally evolving dynamics.,6.1. Relational Learning,[0],[0]
"Temporal point processes have been shown as very effective tool to model various intricate temporal behaviors in networks (Yang & Zha, 2013; Farajtabar et al., 2014; 2015; Du et al., 2015; 2016; Wang et al., 2016a;b;c; 2017a;b).",6.2. Temporal Modeling,[0],[0]
"Recently, (Wang et al., 2016a; Dai et al., 2016b) proposed novel co-evolutionary feature embedding process that captures self-evolution and co-evolution dynamics of users and items interacting in a recommendation system.",6.2. Temporal Modeling,[0],[0]
"In relational setting, (Loglisci et al., 2015) proposed relational mining approach to discover changes in structure of dynamic network over time.",6.2. Temporal Modeling,[0],[0]
"(Loglisci & Malerba, 2017) proposes method to capture temporal autocorrelation in data to improve predictive performance.",6.2. Temporal Modeling,[0],[0]
"(Sharan & Neville, 2008) proposes summarization techniques to model evolving relational-temporal domains.",6.2. Temporal Modeling,[0],[0]
"Recently, (Esteban et al., 2016) proposed multiway neural network architecture for modeling event based relational graph.",6.2. Temporal Modeling,[0],[0]
The authors draw a synergistic relation between a static knowledge graph and an event set wherein the knowledge graph provide information about entities participating in events and new events in turn contribute to enhancement of knowledge graph.,6.2. Temporal Modeling,[0],[0]
They do not capture the evolving dynamics of entities and model time as discrete points which limits its capacity to model complex temporal dynamics.,6.2. Temporal Modeling,[0],[0]
"(Jiang et al., 2016) models dependence of relationship on time to facilitate time-aware link prediction but do not capture evolving entity dynamics.",6.2. Temporal Modeling,[0],[0]
We propose a novel deep evolutionary knowledge network that efficiently learns non-linearly evolving entity representations over time in multi-relational setting.,7. Conclusion,[0],[0]
Evolutionary dynamics of both subject and object entities are captured by deep recurrent architecture that models historical evolution of entity embeddings in a specific relationship space.,7. Conclusion,[0],[0]
The occurrence of a fact is then modeled by multivariate point process that captures temporal dependencies across facts.,7. Conclusion,[0],[0]
The superior performance and high scalability of our method on large real-world temporal knowledge graphs demonstrate the importance of supporting temporal reasoning in dynamically evolving relational systems.,7. Conclusion,[0],[0]
Our work establishes previously unexplored connection between relational processes and temporal point processes with a potential to open a new direction of research on reasoning over time.,7. Conclusion,[0],[0]
"This project was supported in part by NSF IIS-1218749, NIH BIGDATA 1R01GM108341, NSF CAREER IIS1350983,",Acknowledgement,[0],[0]
"NSF IIS-1639792 EAGER, ONR N00014-15-12340, NVIDIA, Intel and Amazon AWS.",Acknowledgement,[0],[0]
The availability of large scale event data with time stamps has given rise to dynamically evolving knowledge graphs that contain temporal information for each edge.,abstractText,[0],[0]
Reasoning over time in such dynamic knowledge graphs is not yet well understood.,abstractText,[0],[0]
"To this end, we present Know-Evolve, a novel deep evolutionary knowledge network that learns non-linearly evolving entity representations over time.",abstractText,[0],[0]
The occurrence of a fact (edge) is modeled as a multivariate point process whose intensity function is modulated by the score for that fact computed based on the learned entity embeddings.,abstractText,[0],[0]
We demonstrate significantly improved performance over various relational learning approaches on two large scale real-world datasets.,abstractText,[0],[0]
"Further, our method effectively predicts occurrence or recurrence time of a fact which is novel compared to prior reasoning approaches in multirelational setting.",abstractText,[0],[0]
Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2038–2043, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Large-scale knowledge bases (KB) like Freebase (Bollacker et al., 2008), Yago (Suchanek et al., 2007), NELL (Mitchell et al., 2015) can be useful in a variety of applications like natural language question answering, semantic search engines, etc.",1 Introduction,[0],[0]
These knowledge bases consist of millions of real world entities and relationships between them which are stored in the form of a directed graph where links represent relations and nodes represent the entities.,1 Introduction,[0],[0]
"Although such KBs contain millions of entities, they are still very sparse, i.e., they are missing a large number of relations between existing entities (West et al., 2014).
",1 Introduction,[0],[0]
Performing inference over the knowledge graph for predicting relations between two entities is one way of densifying the KB graph.,1 Introduction,[0],[0]
"For example,
from (Germany, playsinTournament, FIFA) and (FIFA, tournamentofSport, Soccer), we can infer (Germany, playsSport, Soccer).",1 Introduction,[0],[0]
"The Path Ranking Algorithm (PRA) (Lao and Cohen, 2010), (Lao et al., 2011) performs such an inference by learning inference rules over the knowledge graph.
",1 Introduction,[0],[0]
"If the knowledge graph is sparse, i.e., if there are a very few or no paths between source and target entities, then PRA is unable to predict the existence of a relation.",1 Introduction,[0],[0]
"To address this shortcoming, (Lao et al., 2012) augmented the knowledge graph with paths obtained from an external corpus.",1 Introduction,[0],[0]
The added paths consisted of unlexicalized dependency labels obtained from a dependency parsed external corpus.,1 Introduction,[0],[0]
"To improve the expressivity of the added paths, instead of the unlexicalized labels, (Gardner et al., 2013) augmented the KB graph with verbs (surface relations) from a corpus containing over 600 million Subject-Verb-Object (SVO) triples.",1 Introduction,[0],[0]
"These verbs act as edges that connect previously unconnected entities thereby increasing the connectivity of the KB graph which can potentially improve PRA performance.
",1 Introduction,[0],[0]
"However, naı̈vely adding these edges increases the feature sparsity which degrades the discriminative ability of the logistic regression classifier
2038
used in PRA.",1 Introduction,[0],[0]
"This can be addressed by adding latent relations obtained by clustering the surface relations, instead of directly adding the surface relations.",1 Introduction,[0],[0]
"This reduces feature sparsity and has been shown to improve PRA inference (Gardner et al., 2013) , (Gardner et al., 2014).
",1 Introduction,[0],[0]
In this article we propose a scheme for augmenting the KB using paths obtained by mining noun phrases that connect two SVO triples from an external corpus.,1 Introduction,[0],[0]
We term these noun phrases as bridging entities since they bridge two KB relations to form a path.,1 Introduction,[0],[0]
"This is different from the scheme in (Gardner et al., 2013) and (Gardner et al., 2014), which adds edges between KB nodes by mining surface relations from an external corpus.",1 Introduction,[0],[0]
"We search for such bridging entities in the corpus by performing a limited depth DFS (depth first search) on the corpus graph in an on-demand fashion.
",1 Introduction,[0],[0]
"We term this procedure as On-Demand Augmentation (ODA), because the search can be performed during test time in an on-demand manner.",1 Introduction,[0],[0]
"In contrast, the previous approaches of adding edges or embeddings to the KB (Gardner et al., 2013), and vector space random walk PRA (Gardner et al., 2014) are batch procedures.",1 Introduction,[0],[0]
"As we shall see in Section 4, due to a limited search space, on-demand augmentation is much faster compared to algorithms in (Gardner et al., 2013; Gardner et al., 2014).",1 Introduction,[0],[0]
"Furthermore, since edges are not added blindly, on-demand augmentation does not increase feature sparsity which is responsible for performance degradation.",1 Introduction,[0],[0]
"Our experiments suggest that ODA provides better performance than (Gardner et al., 2013) and nearly the same prediction performance as provided by (Gardner et al., 2014), but in both cases with the added advantage of faster running time and greater flexibility due to its online and on-demand nature.",1 Introduction,[0],[0]
The code along with the results can be obtained at https://github.com/malllabiisc/pra-oda.,1 Introduction,[0],[0]
"Using surface level relations and noun phrases for extracting meaningful relational facts is not a new idea (Hearst, 1992),(Brin, 1999), (Etzioni et al., 2004).",2 Related Work,[0],[0]
"However, none of them make use of Knowledge Bases for improving information extraction.
",2 Related Work,[0],[0]
"The Path Ranking Algorithm (PRA) first proposed in (Lao and Cohen, 2010) was used for per-
forming inference over a KB in (Lao et al., 2011).",2 Related Work,[0],[0]
"It was extended by (Lao et al., 2012), to improve the inference by augmenting the KB with syntactic information obtained from a dependency parsed corpus.",2 Related Work,[0],[0]
"Augmenting the KB for improving PRA inference using surface relations mined from an external corpus and using latent edge labels obtained by performing PCA on the surface relations was explored in (Gardner et al., 2013).",2 Related Work,[0],[0]
"Instead of hard mapping of surface relations to latent embeddings, (Gardner et al., 2014) perform a ‘soft’ mapping using vector space random walks.",2 Related Work,[0],[0]
"This allows the random walker to traverse an edge semantically similar to the current edge type more frequently than other edges.
",2 Related Work,[0],[0]
"Although, like others, we too use an external corpus to augment the KB, the crucial difference in our approach is that apart from adding surface relations, we also add bridging entities that enable us to create new paths in the KB.",2 Related Work,[0],[0]
"Furthermore, the procedure is targeted so that only paths that play a part in inferring the relations that are of interest are added.",2 Related Work,[0],[0]
"Thus, the number of paths added in this manner is much lower than the number of surface relations added using the procedure in (Gardner et al., 2013).",2 Related Work,[0],[0]
"As we shall see in Section 4, this results in a more effective algorithm with faster runtime.",2 Related Work,[0],[0]
"We first present a brief overview of the Path Ranking Algorithm (PRA) (Lao and Cohen, 2010).",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
The PRA uses paths as features for a logistic regression classifier which predicts if the given relation exists between a pair of entities.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"For a given pair of entities s and t, the path type connecting s to t form the feature vector.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
A path types π is an ordered set of relations.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
Paths with the same ordered relations but different intermediate or terminal entities belong to the same path type.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"For example, s1
v0−→ x1 v1−→ t1 and s2 v0−→ x2 v1−→ t2 belong to path type v0−→ v1−→.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"The value of a feature, is taken to be P (s → t;π), where P (s → t;π) is the probability of reaching t from s by traversing paths of type π.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
PRA approximates these probabilities by running a random walk (RW) on the KB graph.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"Let F = {π1, π2, ..., πk} be the set of all path types.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"For predicting the existence of relation r between entities s and t, the logistic regression classifier outputs a score which is a measure of the
confidence that r exists between s and t. It does so by first assigning weights to the features in the training phase.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"The score is given by
S(s, t, r) = ∑ π∈F P (s→ t;π)× θrπ (1)
where θrπ is the weight learned by the logistic regression classifier during training specially for relation r and path type π.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"During the test phase, since targets are not available, the PRA gathers candidate targets by performing a random walk and then computes feature vectors and the score.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"PRA-SVO and PRA-VS are the systems proposed in (Gardner et al., 2013) and (Gardner et al., 2014) respectively, where the KB graph is augmented with edges mined from a large subject-verb-object (SVO) triple corpus.",3.2 PRA-SVO and PRA-VS,[0],[0]
"In these two systems, only new edges are added over the fixed set of nodes, and the augmentation happens in a batch, offline setting.",3.2 PRA-SVO and PRA-VS,[0],[0]
"In contrast, PRA-ODA, the method proposed in the paper, also expands the set of nodes through bridging entities, and performs the augmentation in an on-demand manner.",3.2 PRA-SVO and PRA-VS,[0],[0]
Training: Let s and t be any two KB entities and let s(n) and t(n) be their corresponding noun phrase representations or aliases.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We search for bridging entities x1, x2, ..xn by performing limited depth first search (DFS) starting with sn such that we obtain a path s ALIAS−→ s(n) v0−→ x1 v1−→ ...
vn−1−→",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
xn vn−→ t(n) ALIAS−→,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"t, where vi are verbs present in the corpus graph.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"This is done for all n ≤ dmax− 1, where dmax is the maximum depth of DFS.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
We add an ‘ALIAS’ edge between the KB entity and its noun phase representation.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"The usefulness of bridging entities is illustrated in Fig. 1.
",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We mine bridging entities from a corpus containing over 600 million SVO triples which were obtained from the ClueWeb09 corpus (Callan et
al., 2009)",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"parsed using the MALT parser (Nivre et al., 2007).",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
We use Mongo DB to store the triples as an adjacency list.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"During training time, for any relation that is being inferred, both the source and its corresponding target entities are known.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
A limited depth DFS is performed for all depths less then dmax on the SVO graph with the aliases of subject entity acting as the starting points.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
Such aliases are available for the NELL and Freebase knowledge bases.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
The DFS is said to discover a path if the terminating entity of the path matches any alias of the target entity.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We choose to use aliases to perform string match, since it is easy to change the softness of the match by simply adding more aliases.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
This is done for all training sourcetarget pairs.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"A few examples of added paths are shown in Table 1.
",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
The SVO graph is noisy since it is obtained by parsing the ClueWeb corpus which was obtained by scraping the web.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"To reduce noise, we add the top K most frequent discovered SVO path types, whereK is a tunable parameter.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
By SVO path type we refer to a set of ordered verbs mined from the SVO corpus.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"There is a possibility that the bridging entities, extracted from the corpus, may be present in the KB.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"If the bridging entity matches any alias, then it is treated as an alias to an existing KB entity.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"If not, then the bridging entity is added to the KB as a new entity.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
To avoid overfitting we add negative data to the training set.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Furthermore, only high quality expressive bridging entities result in meaningful and discriminative paths.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Although the quality of bridging entities depend on the corpus, low quality bridging entities can be filtered out by adding negative training data.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Low quality bridging entities connect source target pairs from both positive and negative training sets, and hence are eliminated by the sparse logistic regression classifier.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"The negative dataset is generated using the closed world assumption by performing a random walk.
",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"After augmenting the KB, we run the training phase of the PRA algorithm to obtain the feature (path) weights computed by the logistic regression
classifier.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
Query Time:,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
The set of target entities corresponding to a source entity and the relation being predicted is not available during query (test) time.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
We use all the entities included in the range of the relation being predicted as candidate target entities.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"For example, if the relation is riverFlowsThroughCity, the candidate target set would include entities in the KB that are cities.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"The DFS is now performed starting from source entities as during training, but this time only restricting to paths with positive weights learned during training.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Any path (along with bridging entities) found during this search are added to the KB, and the PRA algorithm is now run over this augmented graph.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We used the implementation of PRA provided by the authors of (Gardner et al., 2014).",4 Experiments,[0],[0]
"For our experiments, we used the same 10 NELL relation data as used in (Gardner et al., 2014).",4 Experiments,[0],[0]
"The augmentation resulted in the addition of 1086 paths during training and 1430 paths during test time.
",4 Experiments,[0],[0]
"We split the NELL data into 60% training data, 15 % development data and 25% test data.",4 Experiments,[0],[0]
"Values for dmax, and K, the most frequent paths, were obtained by tuning on a development set for 4 relations (athleteplaysforsport,actorstarredinmovie,citylocatedincountry
and journalistwritesforpublication).",4 Experiments,[0],[0]
"The hyperparameter values dmax = 2, K = 10 reported the highest MRR and were used for the rest of the relations.",4 Experiments,[0],[0]
"For the L1 and L2 regularization parameters in the logistic regression classifier, we used the same values as used in (Gardner et al., 2013; Gardner et al., 2014), viz., L1 = 0.005, and L2 = 1.0.",4 Experiments,[0],[0]
"This is because the parameters were reported to be robust, and seemed to work well even when the knowledge base was augmented.
",4 Experiments,[0],[0]
"We compare the results (PRA-ODA) with the PRA algorithm executed on the NELL KB, NELL KB augmented with surface relations (PRA-SVO) (Gardner et al., 2013) and vector space random walk PRA (PRA-VS) (Gardner et al., 2014).",4 Experiments,[0],[0]
"The run times, i.e, the time taken to perform an entire experiment for PRA-SVO and PRA-VS includes the time taken to augment NELL KB with SVO edges.",4 Experiments,[0],[0]
The PRA-VS runtime also includes the time taken for generating embeddings to perform the vector space random walk.,4 Experiments,[0],[0]
"As can be seen from Table 2 and Table 3, our scheme, PRA-ODA, provides performance equivalent to PRA-VS with faster running time (speed up of 1.8).",4 Experiments,[0],[0]
"In addition to the time taken for the full SVO augmentation, PRA-VS takes additional time to generate embeddings (13 minutes) from the added verbs.",4 Experiments,[0],[0]
"We note that the batch augmentation in case of PRA-SVO and PRA-VS, and embedding computation in case of PRA-VS are all specific to the relations in the evaluation set, and hence can’t be ignored as a one-time offline cost.",4 Experiments,[0],[0]
"In other words, these costs are likely to increase as more relations (and their instances) are included during training and testing.",4 Experiments,[0],[0]
"Runtime gains with PRA-ODA are likely to be even more pronounced in such settings.
",4 Experiments,[0],[0]
An additional advantage of the proposed algorithm is that it can also be run on the top of any PRA based algorithm such as the PRA-SVO and PRA-VS.,4 Experiments,[0],[0]
"In this paper, we investigated the usefulness of adding paths to a Knowledge Base for improving its connectivity by mining bridging entities from an external corpus.",5 Conclusion,[0],[0]
"While previous KB augmentation methods focused only on augmentation using mined surface verbs while keeping the node set fixed, we extended these approaches by also adding bridging entities in an online fashion.",5 Conclusion,[0],[0]
We used a large corpus of 500 million web text corpus to mine these additional edges and bridging entities.,5 Conclusion,[0],[0]
"Through experiments on real-world datasets, we demonstrate that the proposed approach is not only comparable or better than other state-of-theart baselines, but more importantly provides faster overall runtime compared with the alternatives.",5 Conclusion,[0],[0]
This work is supported in part by a gift from Google.,Acknowledgment,[0],[0]
"Large-scale Knowledge Bases (such as NELL, Yago, Freebase, etc.) are often sparse, i.e., a large number of valid relations between existing entities are missing.",abstractText,[0],[0]
"Recent research have addressed this problem by augmenting the KB graph with additional edges mined from a large text corpus while keeping the set of nodes fixed, and then using the Path Ranking Algorithm (PRA) to perform KB inference over this augmented graph.",abstractText,[0],[0]
"In this paper, we extend this line of work by augmenting the KB graph not only with edges, but also with bridging entities, where both the edges and bridging entities are mined from a 500 million web text corpus.",abstractText,[0],[0]
"Through experiments on real-world datasets, we demonstrate the value of bridging entities in improving the performance and running time of PRA in the KB inference task.",abstractText,[0],[0]
Knowledge Base Inference using Bridging Entities,title,[0],[0]
"We consider the problem of completing a partial knowledge base (KB) containing facts about gener-
∗This work was done while the author was affiliated with the Allen Institute for Artificial Intelligence.
ics or common nouns, represented as a third-order tensor of (source, relation, target) triples, such as (butterfly, pollinate, flower) and (thermometer, measure, temperature).",1 Introduction,[0],[0]
Such facts capture common knowledge that humans have about the world.,1 Introduction,[0],[0]
They are arguably essential for intelligent agents with human-like conversational abilities as well as for specific applications such as question answering.,1 Introduction,[0],[0]
"We demonstrate that state-of-the-art KB completion methods perform poorly when faced with generics, while our strategies for incorporating external knowledge as well as obtaining additional annotations for rare entities provide the first successful solution to this challenging new task.
",1 Introduction,[0],[0]
"Since generics represent classes of similar individuals, the truth value yi of a generics triple xi = (s, r, t) depends on the quantification semantics one associates with s and t. Indeed, the semantics of generics statements can be ambiguous, even selfcontradictory, due to cultural norms.",1 Introduction,[0],[0]
"As Leslie (2008) points out, ‘ducks lay eggs’ is generally considered true while ‘ducks are female’, which is true for a broader set of ducks than the former statement, is generally considered false.
",1 Introduction,[0],[0]
"To avoid deep philosophical issues, we fix a particular mathematical semantics that is especially relevant for noisy facts derived automatically from text: associate s with a categorical quantification from {all, some, none} and associate t (implicitly) with some.",1 Introduction,[0],[0]
"For instance, “all butterflies pollinate (some) flower” and “some animals live in (some) forest”.",1 Introduction,[0],[0]
"When presenting such triples to humans, they are phrased as: is it true that all butterflies pollinate some flower?",1 Introduction,[0],[0]
"As a notational shortcut, we treat the quantification of s as the categorical label yi for the triple xi.",1 Introduction,[0],[0]
"For example, (butterfly, pollinate, flower)
197
Transactions of the Association for Computational Linguistics, vol. 6, pp.",1 Introduction,[0],[0]
"197–210, 2018.",1 Introduction,[0],[0]
Action Editor: Hinrich Schütze.,1 Introduction,[0],[0]
"Submission batch: 6/2017; Revision batch: 9/2017; Published 4/2018.
",1 Introduction,[0],[0]
c©2018 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
is labeled all while (animal, live in, forest) is labeled some.",1 Introduction,[0],[0]
"Given a noisy KB of such labeled triples, the task is to infer more triples.
",1 Introduction,[0],[0]
"Tensor factorization and graph based methods have both been found to be very effective for expanding knowledge bases, but have focused on named entity KBs such as Freebase (Bollacker et al., 2008) involving relations with clear semantics such as liveIn and isACityIn, and disambiguated entities such as Barack Obama or Hawaii.",1 Introduction,[0],[0]
"Completing KBs that involve facts about generics, however, brings up new challenges, as evidenced by our empirical results when using existing methods.
",1 Introduction,[0],[0]
It has been observed that Horn clauses often reliably connect predicates in the named-entity setting.,1 Introduction,[0],[0]
"For instance, for any person x, city y, and country z, (x, liveIn, y) & (y, isACityIn, z) ⇒",1 Introduction,[0],[0]
"(x, liveIn, z).",1 Introduction,[0],[0]
"With generics, however, clear patterns or reliable first-order logic rules are rare, in part due to each generic representing a collection of individuals that often have similarities with respect to some relations and differences with respect to others.",1 Introduction,[0],[0]
"For instance, (x, liveIn, mountain) is true for many cats and caribou, but there is little tangible similarity between the two animals and it is unclear what, if anything, can be carried over from one to the other.",1 Introduction,[0],[0]
"On the other hand, if we take two animals that share a ‘parent’ in some taxonomy (e.g., reindeer and deer), then the likelihood of knowledge transfer increases.
",1 Introduction,[0],[0]
"We propose to make use of additional rich background knowledge complementing the information present in the KB itself, such as a taxonomic hierarchy of entities (available from sources such as WordNet (Miller, 1995)) and the corresponding entity types and relation schema.",1 Introduction,[0],[0]
"Our key insight is that, if used appropriately, taxonomic and schema information can be surprisingly effective in making tensor factorization methods vastly more effective for generics for deriving high precision facts.
",1 Introduction,[0],[0]
"Intuitively, for generics, many properties of interest are themselves generic (e.g., living in forests, as opposed to living in a specific forest) and tend to be shared by siblings in a taxonomy (e.g., finch, oriole, and hummingbird).",1 Introduction,[0],[0]
"In contrast, siblings of named entities (e.g., various people) often differ substantially in the properties we typically care about and model (e.g., who they are married to, where they live, etc.).",1 Introduction,[0],[0]
"Methods that use type information are
thus more promising for generics than for classical NLP tasks involving named entities.",1 Introduction,[0],[0]
"We propose three ways of using this information and empirically demonstrate the effectiveness of each on two variants of a KB of elementary level science facts (Dalvi et al., 2017).1
First, we observe that simply imposing schema consistency (Section 3.1) on derived facts can significantly boost state-of-the-art methods such as Holographic Embeddings (HolE) (Nickel et al., 2016b) from nearly no new facts at 80% precision to over 10,000 new facts, starting with a generics KB of a similar size.",1 Introduction,[0],[0]
"Other embedding methods, such as TransE (Bordes et al., 2013), RESCAL (Nickel et al., 2011), and SICTF (Nimishakavi et al., 2016) (which uses schema information as well), also produced no new facts at 80% precision.",1 Introduction,[0],[0]
"Graph-based completion methods did not scale to our densely connected tensors.2
Second, one can further boost performance by transferring knowledge up and down the taxonomic hierarchy, using the quantification semantics of generics (Section 3.2).",1 Introduction,[0],[0]
"We show that expanding the starting tensor this way before applying tensor factorization is complementary and results in a statistically significantly higher precision (86.4% as opposed to 82%) over new facts at the same yield.
",1 Introduction,[0],[0]
"Finally, we propose a novel limited-budget taxonomy guided active learning method to address the challenge of significant incompleteness in generics KBs, by quantifying uncertainty via siblings (Section 4).",1 Introduction,[0],[0]
"Dalvi et al. (2017) have observed that, when using information extraction methods, it is much harder to derive reliable facts about generics than about named entities.",1 Introduction,[0],[0]
"This makes generics KBs vastly incomplete, with no or very little information about certain entities such as caribou or oriole.
",1 Introduction,[0],[0]
1We are unaware of other large generics KBs.,1 Introduction,[0],[0]
"Our method does not employ rules or choices specific to this dataset and is expected to generalize to other generics KBs, as and when they become available.
2On the smaller Animals tensor (to be described later),",1 Introduction,[0],[0]
"PRA (Lao et al., 2011) generated very few high-precision facts after 30 hours.",1 Introduction,[0],[0]
"SFE (Gardner and Mitchell, 2015) was unable to finish training a classifier for any relation after a day, in part due to the high connectivity of generics like animal.",1 Introduction,[0],[0]
"On the other hand, HolE is trained in a couple of minutes even on the larger Science tensor, and can be made even faster using the method of Hayashi and Shimbo (2017).
",1 Introduction,[0],[0]
"Our active learning approach addresses the following question: Given a new entity3 ẽ and a budget B, what is a good set Q of B queries about ẽ to annotate (via humans) such that expanding the original tensor with Q helps a KB completion method infer many more high precision facts about ẽ?
We propose to define a correlation based measure of the uncertainty of each unannotated triple (i.e., a potential query) involving ẽ, based on how frequently the corresponding triple is true for ẽ’s siblings in the taxonomic hierarchy (Section 4.1).",1 Introduction,[0],[0]
"We then develop a submodular objective function, and a corresponding greedy (1 − 1/e)-approximation, to search for a small subset of triples to annotate that optimally balances diversity with coverage (Section 4.2).",1 Introduction,[0],[0]
We demonstrate that annotating this balanced subset makes tensor factorization derive substantially more new and interesting facts compared to several active learning baselines.,1 Introduction,[0],[0]
"For example, with a budget to annotate 100 queries about a new entity oriole, random queries lead to no new true facts at all (via annotation followed by tensor factorization), imposing schema consistency results in 83 new facts, and our proposed method ends up with 483 new facts.",1 Introduction,[0],[0]
"This demonstrates that well-designed intelligent queries can be substantially more effective in gathering facts about the new entity.
",1 Introduction,[0],[0]
"In summary, this work tackles, for the first time, the challenging task of knowledge completion for generics, by imposing consistency with external knowledge.",1 Introduction,[0],[0]
"Our efficient sibling-guided active learning approach addresses the paucity of facts about certain entities, successfully inferring a substantial number of new facts about them.",1 Introduction,[0],[0]
KB completion approaches fall into two main classes: graph-based methods and those employing low-dimensional embeddings via matrix or tensor factorization.,1.1 Related Work,[0],[0]
"The former uses graph traversal techniques to complete the KB, by learning which types of paths or transitions are indicative of which relation between the start and end points (Lao et al., 2011; Gardner and Mitchell, 2015).",1.1 Related Work,[0],[0]
"This class of solutions, unfortunately, does not scale well to
3Unless otherwise stated, we will henceforth use entity to refer to a singular common noun that represents a class or group of individuals, such as animal, hummingbird, forest, etc.
our setting (cf. Footnote 2).",1.1 Related Work,[0],[0]
"This appears due, at least in part, to different connectivity characteristics of generics tensors compared to named entity ones such as FB15k (Bordes et al., 2013).",1.1 Related Work,[0],[0]
"Advances in the latter set of methods have led to several embedding-based methods that are highly successful at KB completion for named entities (Nickel et al., 2011; Riedel et al., 2013; Dong et al., 2014; Trouillon et al., 2016; Nickel et al., 2016a).",1.1 Related Work,[0],[0]
"We compare against many of these, including variants of HolE, TransE, and RESCAL.
",1.1 Related Work,[0],[0]
"Recent work on incorporating entity type and relation schema in tensor factorization (Krompaß et al., 2014; Krompaß et al., 2015; Xie et al., 2016b) has focused on factual databases about named entities, which, as discussed earlier, have very different characteristics than generics tensors.",1.1 Related Work,[0],[0]
Nimishakavi et al. (2016) use entity type information as a matrix in the context of non-negative RESCAL for schema induction on medical research documents.,1.1 Related Work,[0],[0]
"As a byproduct, they complete missing entries in the tensor in a schema-compatible manner.",1.1 Related Work,[0],[0]
"We show that our proposal performs better on generics tensors than their method, SICTF.",1.1 Related Work,[0],[0]
"SICTF, in turn, is meant to be an improvement over the TRESCAL system of Chang et al. (2014), which also incorporates types in RESCAL in a similar manner.",1.1 Related Work,[0],[0]
"Recently, Schütze et al. (2017) proposed a neural model for fine-grained entity typing and for robustly using type information to improve relation extraction, but this is targeted for Freebase style named entities.
",1.1 Related Work,[0],[0]
"For schema-aware discriminative training of embeddings, Xie et al. (2016b) use a flexible ratio of negative samples from both schema consistent and schema inconsistent triples.",1.1 Related Work,[0],[0]
"Their combined ideas, however, do not improve upon vanilla HolE (one of our baselines) on the standard FB15k (Bordes et al., 2013) dataset.",1.1 Related Work,[0],[0]
"They also consider imposing hierarchical types for Freebase, as entities may have different meanings when they have different types— an issue that typically does not apply to generics KBs.",1.1 Related Work,[0],[0]
Komninos and Manandhar (2017) use type information along with additional textual evidence for knowledge base completion on the FB15k237 dataset.,1.1 Related Work,[0],[0]
"They learn embeddings for types, along with entities and relations, and show that this way of incorporating type information has a (small) contribution towards improving performance.",1.1 Related Work,[0],[0]
"Incorpo-
rating given first order logic rules has been explored for the simpler case of matrix factorization (Rocktaschel et al., 2015; Demeester et al., 2016).",1.1 Related Work,[0],[0]
"Existing first order logic rule extraction methods, however, struggle to find meaningful rules for generics, making this approach not yet viable in our setting.
",1.1 Related Work,[0],[0]
Xie et al. (2016a) consider inferring facts about a new entity ẽ given a ‘description’ of that entity.,1.1 Related Work,[0],[0]
"They use Convolutional Neural Networks (CNNs) to encode the description, deriving an embedding for ẽ. Such a description in our context would correspond to knowing some factual triples about ẽ, which is a restricted version of our active learning setting.
Krishnamurthy and Singh (2013) consider active learning for a particular kind of tensor decomposition, namely CP or Candecomp/Parafac decomposition into a low dimensional space.",1.1 Related Work,[0],[0]
They start with an empty tensor and look for the most informative slices and columns to fill completely to achieve optimal sample complexity.,1.1 Related Work,[0],[0]
"Their framework builds upon the incoherence assumption on the column space, which does not apply to generics KB.
Hegde and Talukdar (2015) use an entity-centric information extraction (IE) approach for obtaining new facts about entities of interest.",1.1 Related Work,[0],[0]
Narasimhan et al. (2016) use a reinforcement learning approach to issue search queries to acquire additional evidence for a candidate fact.,1.1 Related Work,[0],[0]
"Both of these works, and others along similar lines, are advanced IE techniques that operate via a search for new documents and extraction of facts from them.",1.1 Related Work,[0],[0]
"This is different from the KB completion task, where the only source of information is the starting KB and possibly some details about the involved entities and relations.",1.1 Related Work,[0],[0]
"We consider knowledge expressed in terms of (source, relation, target) triples, abbreviated as (s, r, t).",2 Tensors of Generics,[0],[0]
"Such a triple may refer to (subject, predicate, object) style facts commonly used in information extraction.",2 Tensors of Generics,[0],[0]
"Each source and target is an entity that is a generic noun, e.g., animals, habitats, or food items.",2 Tensors of Generics,[0],[0]
"Examples of relations include foundIn, eat, etc.",2 Tensors of Generics,[0],[0]
"As mentioned earlier, with each generics triple (s, r, t), we associate a categorical truth value q ∈",2 Tensors of Generics,[0],[0]
"{all, some, none}, defining the quantification semantics “q s r (some) t”.",2 Tensors of Generics,[0],[0]
"For instance, “some an-
imals live in (some) forest” and “all dogs eat (some) bone”.",2 Tensors of Generics,[0],[0]
"Given a set K of such triples with annotated truth values, the task is to predict additional triples K ′",2 Tensors of Generics,[0],[0]
"that are also likely to be true.
",2 Tensors of Generics,[0],[0]
"In addition to a list of triples, we assume access to background information in the form of entity types and the corresponding relation schema, as well as a taxonomic hierarchy.4 Let ET denote the set of possible entity types.",2 Tensors of Generics,[0],[0]
"For each relation r, the relation schema imposes a type constraint on the entities that may appear as its source or target.",2 Tensors of Generics,[0],[0]
"Specifically, using [`] to denote the set {1, 2, . . .",2 Tensors of Generics,[0],[0]
", `}, the schema for r is a collection Sr = {(D(i)r ,R(i)r ) ⊆ ET × ET",2 Tensors of Generics,[0],[0]
| i ∈,2 Tensors of Generics,[0],[0]
"[`]} of domain-range pairs with the following property: the truth value of (s, r, t) is none whenever for every",2 Tensors of Generics,[0],[0]
i ∈,2 Tensors of Generics,[0],[0]
[`] it is the case that s /∈,2 Tensors of Generics,[0],[0]
D(i)r or t /∈,2 Tensors of Generics,[0],[0]
R(i)r .,2 Tensors of Generics,[0],[0]
"For example, the relation foundIn may be associated with the schema SfoundIn = {(animal, location), (insect, animal), (plant, habitat), . . .",2 Tensors of Generics,[0],[0]
}.,2 Tensors of Generics,[0],[0]
"Similarly, the taxonomic hierarchy defines a partial order H over all entities that captures the “isa” relation, with direct links such as isa(dog, mammal) or isa(gerbil, rodent).",2 Tensors of Generics,[0],[0]
"We use this information to extract “siblings” of a given entity, i.e., entities that share a common parent (this may be easily generalized to any common ancestor).",2 Tensors of Generics,[0],[0]
We begin with an overview of tensor factorization for KB completion for generics.,3 Guided Knowledge Completion,[0],[0]
"Let (s, r, t) be a generics triple associated with a categorical quantification label q ∈ {all, some, none}.",3 Guided Knowledge Completion,[0],[0]
"For example, ((cat, havePart, whiskers), all), ((cat, liveIn, homes), some), and ((cat, eat, bear), none).",3 Guided Knowledge Completion,[0],[0]
Predicting such labels is thus a multi-class classification problem.,3 Guided Knowledge Completion,[0],[0]
"Given a set K of labeled triples, the goal of tensor factorization is to learn a low-dimensional embedding h for each entity and relation such that some function f of h best captures the given labels.",3 Guided Knowledge Completion,[0],[0]
"Given a new triple, we can then use f and the learned h to predict the probability of each label for it.",3 Guided Knowledge Completion,[0],[0]
"K often contains only “positive” triples, i.e., those with label all or some.",3 Guided Knowledge Completion,[0],[0]
"A common step in discriminative training for h is thus negative sampling, i.e., generating additional triples that (are expected to) have
4We do not assume that the schema or taxonomy is perfect, and instead rely on these only for heuristic guidance.
",3 Guided Knowledge Completion,[0],[0]
label none.,3 Guided Knowledge Completion,[0],[0]
"With [m] denoting the set {1, 2, . . .",3 Guided Knowledge Completion,[0],[0]
",m} as before, let K = {(xi, yi),",3 Guided Knowledge Completion,[0],[0]
i ∈,3 Guided Knowledge Completion,[0],[0]
[m]} be a set of triples,3 Guided Knowledge Completion,[0],[0]
"xi = (si, ri, ti) and corresponding labels",3 Guided Knowledge Completion,[0],[0]
"yi ∈ {1, 2, 3} equivalent to categorical quantification label qi ∈ {all, some, none}.",3 Guided Knowledge Completion,[0],[0]
"We learn entity and relation embeddings Θ that minimize the multinomial logistic loss defined as:
min Θ
m∑
i=1
3∑
k=1
−1{yi = k} log Pr(yi = k | xi,Θ)
=",3 Guided Knowledge Completion,[0],[0]
"min Θ
m∑
i=1
3∑
k=1
−1{yi = k} log σ(yi f(hr, hs, ht))
(1)
where hr, hs, ht ∈ Rd denote the learned embeddings (latent vectors) for s, r, t, respectively, and σ(·) is the sigmoid function defined as σ(z) =
1 1+exp(−z) .
",3 Guided Knowledge Completion,[0],[0]
"If the all categorical label for generics is unavailable,5 we can simplify the label space to {some, none}, modeled as yi ∈ {±1}, and reduce the model to binary classification:
min Θ
m∑
i=1
log [1 + exp",3 Guided Knowledge Completion,[0],[0]
"[−yi f(hr, hs, ht)]] .",3 Guided Knowledge Completion,[0],[0]
"(2)
We remark that while this generics task with only two labels appears superficially similar to the standard KB completion task for named entities, the underlying challenges and solutions are different.",3 Guided Knowledge Completion,[0],[0]
"For instance, the approach of using taxonomic information (as opposed to just entity types) as a guide is uniquely suited to generics KBs; the reason being that a generic entity refers to a set of individuals, with a natural subset/superset relation forming a taxonomy, whereas in standard KBs an entity refers to one specific individual.",3 Guided Knowledge Completion,[0],[0]
"This prevents taxonomy based rules from providing useful information for standard KBs, while our results demonstrate their high value when reasoning with generics.",3 Guided Knowledge Completion,[0],[0]
"Differences like this lead to differences in what is successful in each setting and what is not.
",3 Guided Knowledge Completion,[0],[0]
"5This happens to be the case for current generics KBs, but is expected to change with increasing interest in the research community.",3 Guided Knowledge Completion,[0],[0]
"A step in this direction is a recent version of the Aristo Tuple KB, http://allenai.org/data/aristo-tuple-kb, which includes most as a quantification label, in addition to some.
",3 Guided Knowledge Completion,[0],[0]
"While all our proposed schemes are embedding oblivious, for concreteness, we describe and evaluate them for the Holographic Embedding or HolE (Nickel et al., 2016b) which models the label probability as:
f(hr, hs, ht) = h > r",3 Guided Knowledge Completion,[0],[0]
"(hs ◦ ht) (3)
where ◦ : Rd × Rd → Rd denotes circular correlation defined as:
[a ◦ b]k = d−1∑
i=0
aib(i+k) mod d .",3 Guided Knowledge Completion,[0],[0]
"(4)
Intuitively, the k-th dimension of circular correlation captures how related a is to b when the dimensions of the latter are shifted (circularly, via the mod operation) by k.",3 Guided Knowledge Completion,[0],[0]
In particular [a ◦ b]0 is simply the dot product of a and b.,3 Guided Knowledge Completion,[0],[0]
As can be deduced from Eqns.,3 Guided Knowledge Completion,[0],[0]
"(3)-(4), this model resembles circular convolution, but can capture, to some extent, relations that are asymmetric among the source and target entities.",3 Guided Knowledge Completion,[0],[0]
This is because [a ◦ b] is not the same as [b ◦a] but is rather “flipped” ([a◦b]k = [b◦a]d−k).,3 Guided Knowledge Completion,[0],[0]
"If we consider the d × d matrix Mab of element-wise relationships between a and b, the HolE embedding of a relation r between a and b defines a weighted sum of circular anti-diagonals of Mab.
",3 Guided Knowledge Completion,[0],[0]
"Circular correlation can be computed using the fast Fourier transform (FFT), making HolE quite efficient in practice.",3 Guided Knowledge Completion,[0],[0]
"Hayashi and Shimbo (2017) recently showed that HolE and complex embeddings (Trouillon et al., 2016), which is another stateof-the-art method for KB completion, are equivalent and differ only in terms of constraints on initial values.",3 Guided Knowledge Completion,[0],[0]
"Further, they proposed a linear time computation for HolE by staying fully within the frequency domain of FFT.",3 Guided Knowledge Completion,[0],[0]
"As described earlier, relation schema Sr imposes a restriction on sources and targets that may occur with a relation r.",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
We can incorporate this knowledge both at training and at test times.,3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
Doing this at test time simply translates to relabeling schemainconsistent predicted triples as none.,3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"Incorporating this knowledge at training time can be done as a constraint on the random negative samples that
the method generates to complement the given, typically positive, triples for training.
",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"In general, the ratio of random negative samples from the entire tensor T and random negative samples from the schema consistent portion T ′ of T is a parameter that should be tuned such that the resulting negative samples mimic the true distribution of labels.",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
It is worth noting that whether the locally closed world assumption (LCWA) holds or not plays an important role in determining this ratio.,3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"However, the idea of mixing the two kinds of negative samples has been used in the literature without considering the nature of the dataset, resulting in some seemingly contradicting empirical results on the optimal ratio (Li et al., 2016; Xie et al., 2016b; Shi and Weninger, 2017; Xie et al., 2017).",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"As discussed later, we found sampling from T to work best on our datasets.",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"It is challenging to come up with complex Horn or first order logic rules for generics, as each entity represents a class of individuals that may not all behave identically.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"However, we can derive simple yet highly effective rules based on categorical quantification labels, leveraging the fact that entities come from different levels in a taxonomy hierarchy.
",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
Let p be the parent entity for entity set {ci}.,3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"Note that ci itself is a generic, that is, a class of individuals rather than a single individual.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"This allows one to make meaningful existential statements such as: if a property holds for all or most members of even one class ci, then it holds for some (reasonable number of) members of its parent class p.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"We use the following rules:6
((p, rj , tj), all)⇒ ∀i ((ci, rj , tj), all) ∀i ((ci, rj , tj), all)⇒ ((p, ej , tj), all) ∃i",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"((ci, rj , tj), all)⇒ ((p, ej , tj), some)
∃i",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"((ci, rj , tj), some)⇒ ((p, ej , tj), some)
",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"We apply these rules to address sparsity of generics tensors, making tensor factorization more robust.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"Specifically, given initial triples K, we use applicable rules to derive additional triples K ′, perform
6The last rule may not be appropriate for KBs where some may refer to the extreme case of a single individual.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"This is not the case for the KBs we use for our evaluation.
tensor factorization on K ∪K ′, and then revisit the triples in K ′ using their predicted label probabilities.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"Note that this approach allows us to be robust to taxonomic errors: instead of assuming each triple in K ′ is true, we use this only as a prior and let tensor factorization determine the final prediction based on global patterns it finds.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"To address the incomplete nature of generics KBs, we consider rare entities for which we have very few facts, or new entities which are present in the taxonomy but for which we have no facts in the KB.",4 Active Learning for New or Rare Entities,[0],[0]
"The goal is to use tensor factorization to generate high quality facts about such entities.
",4 Active Learning for New or Rare Entities,[0],[0]
"For instance, consider the task of inferring facts about oriole, where all we know is that it is a bird.",4 Active Learning for New or Rare Entities,[0],[0]
"We assume a restricted budget on the number of facts we can query (for human annotation) about oriole, using which we would like to predict many more high-quality facts about it.
",4 Active Learning for New or Rare Entities,[0],[0]
"Given a fixed query budget B, what is the optimal set of queries we should generate for human annotation about a new or rare entity ẽ for this task?",4 Active Learning for New or Rare Entities,[0],[0]
We view this as an active learning problem and propose a two-step algorithm.,4 Active Learning for New or Rare Entities,[0],[0]
"First, we use taxonomy guided uncertainty sampling to propose a list L to potentially query.",4 Active Learning for New or Rare Entities,[0],[0]
"Next, we describe a submodular objective function and a corresponding linear time algorithm to choose an optimal subset L̂ ⊆ L satisfying |L̂| = B. We then use L̂ for human annotation, append the result to the original KB, and perform tensor factorization to predict additional new facts about ẽ. For notational simplicity and without loss of generality, throughout this section, we consider the case where ẽ appears as the source entity in the triple; the ideas apply equally when ẽ appears as the target entity in the triple.",4 Active Learning for New or Rare Entities,[0],[0]
We now discuss the active learning and specifically uncertainty sampling method we use to propose a list of triples to query.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Uncertainty sampling considers the uncertainty for each possible triple (ẽ, ri, ei), defined as how far away from 0.5 the conditional probability is of this fact, given the facts we already
know from the KB (Settles, 2012).",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
The question is how to model this conditional probability.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"A simple baseline is to consider Random queries, i.e., r, e are selected randomly from the list of relations and entities in the tensor, respectively.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"To infer information about ẽ, we propose the following approximation for the conditional probability of a new fact about ẽ given the KB.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Let Ẽẽ = {e | corr(ẽ, e) > 0} be the set of entities that are correlated with ẽ, Ω = {((ei, ri, e′i), yi)",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"| ei ∈ Ẽẽ} be the set of known facts about such entities, and yi be the label for the triple (ei, ri, e′i).",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"We have:
Pr(f(hri , hẽ, he′i)) ' 1 |Ω| ∑
ei∈Ẽẽ
corr(ẽ, ei) yi.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(5)
However, in practice, we cannot measure corr(ẽ, ei) for every entry in the KB as we do not have complete information about ẽ. One simple idea is to consider that every entity is correlated with ẽ: corr(ẽ, ei) = 1 ∀ei ∈ E.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"We will refer to this as Schema Consistent query proposal as this relates to summing over all possible (hence schema consistent) facts.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Since we have access to taxonomy information, we can do a more precise, Sibling Guided, approximation.7",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"We propose the following approximation for corr(ẽ, ei) for ei ∈ E:
corr(ẽ, ei) =",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
{ 1 if ei ∈ sibling(ẽ) 0,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
otherwise .,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(6)
Eqns.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(5) and (6) can be used to infer uncertain triples: if every sibling of ẽ has relationship r with an entity e′, we can infer for “free” that this is the case for ẽ as well.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"On the other hand, when siblings disagree in this respect, there is more uncertainty about (ẽ, r, e′)",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(according to (5) and (6)), making this triple a good candidate to query.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"In our example of oriole, the siblings are the birds that exist in the tensor, e.g., hummingbird, finch, woodpecker, etc.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"All of them (eat, insect) and hence we infer this for oriole.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"But there is no agreement on (appearIn, farm) and hence this is added to the query list.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
7One may also define corr based on entity similarity in a distributional space.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
One challenge here is that such similarity generally doesn’t preserve types.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"For example, dog may cooccur more often with and thus be “closer” to bone or barking in a distributional space, than to siblings such as cat or other pet animals, which are more helpful in our setting.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Algorithm 1: Active Learning for Query Proposal
input new entity ẽ, KB, taxonomy, lower bound κM on agreement, lower bound τL on uncertainty, upper bound τU on uncertainty
1: extract list Sẽ of sibling(ẽ) using taxonomy 2: for each ei ∈ Sẽ, add all facts about ei to Ω 3: for (ẽ, ri, e′i) ∈ Ω do 4: use (5)-(6) to estimate Pr(f(hri , hẽ, he′i)) 5",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
: if p ≥ κM,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"then add (ẽ, ri, e′i) to M 6: if τL ≤ p ≤ τU then add (ẽ, ri, e′i) to L
output L, M
Algorithm 1 formalizes this process.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Setting some upper (τU ) and lower (τL) bounds on the conditional probability (Eqn. (5)) which quantifies the uncertainty, we reach a set L = {(ẽ, ri, ei), i ∈",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
I} of triples to query.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
Using another high threshold κM,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"> τU , we also infer the set M = {(ẽ, rj , ej), j ∈ J} of triples that a large majority of siblings agree upon, and hence ẽ is expected to agree with as well.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
Triples whose conditional probability estimate is between κM and τU are considered neither certain enough to include in M nor uncertain enough to justify adding to L for human annotation in hopes of learning from it.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Similarly, triples with a conditional probability estimate lower than τL are discarded.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
The output of Algorithm 1 is the list L to query and the list M to add directly to the knowledge base.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Given the list L as above (Algorithm 1), which we can write in short as L = {(ri, ei), i ∈",4.2 Efficient Subset Selection,[0],[0]
"I}, the problem is to find the “best” subset L̂. A baseline for such a selection is to choose the top k queries.",4.2 Efficient Subset Selection,[0],[0]
"We will refer to this as TK subset selection.
",4.2 Efficient Subset Selection,[0],[0]
"Viewing subset selection as a combinatorial problem, we devise an objective F that models several natural properties of this subset.",4.2 Efficient Subset Selection,[0],[0]
"We then prove that F is submodular, that is, the marginal gain inF(L) obtained by adding one more item to L decreases as L grows.8",4.2 Efficient Subset Selection,[0],[0]
"Importantly, this implies that there is a simple known greedy algorithm that can efficiently compute a worst-case (1 − 1/e)-approximation of
8Formally, for L′′ ⊆ L′",4.2 Efficient Subset Selection,[0],[0]
"⊆ L and for l = (rl, el) ∈",4.2 Efficient Subset Selection,[0],[0]
"L \ L′, we have F(L′′ ∪ l)−F(L′′) ≥ F(L′ ∪ l)−F(L′).
",4.2 Efficient Subset Selection,[0],[0]
"the global optimum of F (Nemhauser et al., 1978).",4.2 Efficient Subset Selection,[0],[0]
"We refer to this as SM subset selection.
",4.2 Efficient Subset Selection,[0],[0]
"Since queried samples will eventually be fed into tensor factorization, we would like L̂ to cover entities (for the other argument of the triple) and relations as much as possible.",4.2 Efficient Subset Selection,[0],[0]
"In addition, we would like L̂ to be diverse, i.e., prioritize relations and entities that are more varied.9",4.2 Efficient Subset Selection,[0],[0]
"At the same time, we would also want to minimize redundancy, i.e., avoid choosing relations (entities) that are too similar.",4.2 Efficient Subset Selection,[0],[0]
"Let F(L̂, R
L̂ , E L̂ ) denote our objective, where R L̂ , E L̂
is the set of relations and entities in L̂, respectively.",4.2 Efficient Subset Selection,[0],[0]
"We decompose it as:
F(L̂, R L̂ , E L̂ ) = wCC(L̂, RL̂, EL̂) (7)
+ wDD(L̂, RL̂, EL̂)− wRR(L̂, RL̂, EL̂)
where the terms in RHS correspond to coverage, diversity, and redundancy, respectively, and wC , wD, wR are the corresponding non-negative weights.",4.2 Efficient Subset Selection,[0],[0]
"Next, we propose functional forms for these terms.",4.2 Efficient Subset Selection,[0],[0]
"Note that any function that captures the described properties can be used instead, as long as the objective remains submodular.
",4.2 Efficient Subset Selection,[0],[0]
"Let R and E denote the set of relations and entities in the KB, respectively.",4.2 Efficient Subset Selection,[0],[0]
"The coverage simply captures the fraction of entity and relations that we have included in L̂:
C(L̂, R L̂ , E L̂ ) = |R",4.2 Efficient Subset Selection,[0],[0]
L̂ | |R| + |E,4.2 Efficient Subset Selection,[0],[0]
"L̂ | |E| .
",4.2 Efficient Subset Selection,[0],[0]
"The diversity for L̂ is the sum of the diversity measure of the entities and relations included in the set:
D(L̂, R L̂ , E L̂ ) =
∑
(r,e)∈L̂
",4.2 Efficient Subset Selection,[0],[0]
"[Vr + Ve] ,
Vr = |ESr |+",4.2 Efficient Subset Selection,[0],[0]
|ETr,4.2 Efficient Subset Selection,[0],[0]
"| |E| , Ve = |Re|+ |ESe | |R|+ |E| .
",4.2 Efficient Subset Selection,[0],[0]
"Here Vr and Ve represent the diversity measure of relation r and entity e, respectively.",4.2 Efficient Subset Selection,[0],[0]
"We use ESr , ETr to denote the set of sources and targets that appear
9This agrees with the sampling method of Chen et al. (2014) for factorizing coherent matrices with missing values, which chooses samples with probability proportional to their local coherence.
",4.2 Efficient Subset Selection,[0],[0]
Algorithm 2:,4.2 Efficient Subset Selection,[0],[0]
"Query Subset Selection input KB, budget B, query list L from Alg. 1.
1: ∀(r, e) ∈ L, compute the diversity measure Vr, Ve 2: L̂← ∅ 3: for j = 1 to B do 4: ∀l ∈ L \ L̂ : G(l) = F(L̂ ∪ l)−F(L̂), for F in (7) 5:",4.2 Efficient Subset Selection,[0],[0]
"Select l∗ = arg max
L\L̂ G(l) 6: Add l∗ to L̂
output L̂
for relation r in the KB, Re as the set of relations in the KB that have e as their target, and ESe as the set of entities that appear as the first entity when e is the second entity of the triple in the KB.",4.2 Efficient Subset Selection,[0],[0]
"The diversity measure for each relation r is defined as the ratio of the number of entities that appear in the KB as its source or target, over the total number of entities.",4.2 Efficient Subset Selection,[0],[0]
"Similarly, for an entity e, its diversity is defined as the ratio of the number of relations involving e plus the number of source entities that co-occur with e in a relation, over the total number of relations and entities.",4.2 Efficient Subset Selection,[0],[0]
"Note that the diversity measure is an intrinsic characteristic of each entity and relationship, dictated by the KB and independent of the set L, and can thus be computed in advance.
",4.2 Efficient Subset Selection,[0],[0]
"As described above, redundancy is a measure of similarity between relations(entities) in L̂. Tensor factorization yields an embedding for each relation(entity) given the facts they participated in.",4.2 Efficient Subset Selection,[0],[0]
"Therefore, the learned embeddings are one of the best options for capturing similarities.",4.2 Efficient Subset Selection,[0],[0]
"Let he (and hr) denote the learned embedding for entity e (and relation r, resp.).",4.2 Efficient Subset Selection,[0],[0]
"We define
R(L̂, R L̂ , E L̂ ) =
∑
r1,r2∈L̂
‖hr1",4.2 Efficient Subset Selection,[0],[0]
"− hr2‖
+ ∑
e1,e2∈L̂
‖he1 − he2‖.
This completes the definition of all pieces of our objective function, F , from Eqn.",4.2 Efficient Subset Selection,[0],[0]
(7).,4.2 Efficient Subset Selection,[0],[0]
"In Algorithm 2, we present our efficient greedy method to select a subset of L that approximately optimizes F .
",4.2 Efficient Subset Selection,[0],[0]
"Despite being a greedy approach that simply adds the currently most valuable single query to L̂ and
repeats, the submodular nature of F , which we will prove shortly, guarantees that Algorithm 2 provides an approximation that, even in the worse case, is no worse than a factor of 1 − 1/e from the (unknown) true optimum of F .",4.2 Efficient Subset Selection,[0],[0]
This is formalized in the following theorem.,4.2 Efficient Subset Selection,[0],[0]
"Since addition preserves submodularity and the weights wC , wD, wR are non-negative, we will show that each of the three terms in F is submodular.
",4.2 Efficient Subset Selection,[0],[0]
Theorem 1.,4.2 Efficient Subset Selection,[0],[0]
"Given a tensor KB, a budget B, and a candidate query list L, the quality F(L̂, R
L̂ , E L̂ )
of the output L̂ of Algorithm 2 is a (1 − 1/e)approximation of the global optimum of F .",4.2 Efficient Subset Selection,[0],[0]
Proof.,4.2 Efficient Subset Selection,[0],[0]
"In order to prove the result, it suffices to show that F(L̂, R
L̂ , E L̂ ) in Equation (7) is submod-
ular (Nemhauser et al., 1978).",4.2 Efficient Subset Selection,[0],[0]
"To this end, we show that for L′′ ⊆ L′ ⊆ L and for l = (rl, el) ∈",4.2 Efficient Subset Selection,[0],[0]
"L \ L′,
F(L′′ ∪ l)−F(L′′) ≥ F(L′ ∪ l)−F(L′).
",4.2 Efficient Subset Selection,[0],[0]
"Since addition preserves submodularity and the weights wC , wD, wR are non-negative, it suffices to show that each term in F is submodular.
",4.2 Efficient Subset Selection,[0],[0]
"First, consider the coverage term, C(L̂, R L̂ , E L̂ ).
",4.2 Efficient Subset Selection,[0],[0]
"In order to prove that it is submodular, we verify:
(|RL′′∪l| − |RL′′ |)",4.2 Efficient Subset Selection,[0],[0]
|R| ≥ (|RL′∪l| − |RL′ |),4.2 Efficient Subset Selection,[0],[0]
"|R| , (|EL′′∪l| − |EL′′",4.2 Efficient Subset Selection,[0],[0]
|),4.2 Efficient Subset Selection,[0],[0]
"|E| ≥ (|EL′∪l| − |EL′ |) |E| .
",4.2 Efficient Subset Selection,[0],[0]
"Note that for the numerators of each of the above lines, the difference can be either +1 or 0.",4.2 Efficient Subset Selection,[0],[0]
"Since L′′ ⊂ L′, LHS is, by definition, never less than RHS and the inequalities holds.
",4.2 Efficient Subset Selection,[0],[0]
"Next, consider the diversity term, D(L̂, R L̂ , E L̂ ).",4.2 Efficient Subset Selection,[0],[0]
The above argument directly applies here as well.,4.2 Efficient Subset Selection,[0],[0]
"Finally, consider the redundancy term.",4.2 Efficient Subset Selection,[0],[0]
"In order to show that −R(L̂, R L̂ , E L̂ ) is submodular, note that when taking the difference between R(L′′ ∪ l) and R(L′′) the terms that correspond to both entities (or both relations) being in L′′ cancel out.",4.2 Efficient Subset Selection,[0],[0]
The same holds forR(L′ ∪ l)−R(L′).,4.2 Efficient Subset Selection,[0],[0]
"We thus have: R(L′′ ∪ l)−R(L′′) =
∑
rl∈l,r2∈L′′ ‖hr1",4.2 Efficient Subset Selection,[0],[0]
"− hr2‖+
∑
el∈l,e2∈L′′ ‖he1",4.2 Efficient Subset Selection,[0],[0]
"− he2‖
R(L′ ∪ l)−R(L′) = ∑
rl∈l,r2∈L′",4.2 Efficient Subset Selection,[0],[0]
‖hr1,4.2 Efficient Subset Selection,[0],[0]
"− hr2‖+
∑
el∈l,e2∈L′ ‖he1 − he2‖.
Since L′′ ⊆ L′ and norms are non-negative,
R(L′′ ∪ l)−R(L′′) ≤ R(L′ ∪ l)−R(L′).
",4.2 Efficient Subset Selection,[0],[0]
"The reverse inequality holds for the negation of both sides, proving that −R(L̂, R
L̂ , E L̂ ) is submodular.
",4.2 Efficient Subset Selection,[0],[0]
Combining the three items concludes the proof.,4.2 Efficient Subset Selection,[0],[0]
We will complement this theoretical guarantee in the experiments section (cf. Table 3) by empirically comparing the performance of our query proposal and subset selection methods with baselines.,4.2 Efficient Subset Selection,[0],[0]
"We begin with a description of the datasets and the general setup, then evaluate the effectiveness of our guided KB completion approach, and end with an evaluation of our active learning method.10",5 Experiments,[0],[0]
"To assess the quality of our guided KB completion method, we consider the only large existing knowledge bases about generics that we are aware of:
1.",5.1 Dataset and Setup,[0],[0]
"A Science tensor containing facts about various scientific activities, entities (e.g., animals, instruments, body parts), units, locations, occupations, etc.",5.1 Dataset and Setup,[0],[0]
"(Dalvi et al., 2017).11",5.1 Dataset and Setup,[0],[0]
This starting tensor has a precision of about 80% and acts as a valuable resource for challenging tasks such as question answering.,5.1 Dataset and Setup,[0],[0]
"Our goal is to start with this tensor and infer more scientific facts at a similar or higher level of precision.
",5.1 Dataset and Setup,[0],[0]
2.,5.1 Dataset and Setup,[0],[0]
An Animals sub,5.1 Dataset and Setup,[0],[0]
"-tensor of the Science tensor, which focuses on facts about animals and also has a similar starting precision.",5.1 Dataset and Setup,[0],[0]
"Again, the goal is to infer more facts about animals.
",5.1 Dataset and Setup,[0],[0]
The mainstream approach for KB completion is to focus on entities that are mentioned sufficiently often.,5.1 Dataset and Setup,[0],[0]
"For instance, the commonly used FB15K dataset guarantees that every entity appears at least 100 times.",5.1 Dataset and Setup,[0],[0]
"As a milder version of this, we focus on the subset of the starting tensors where every entity appears at least 20 times.",5.1 Dataset and Setup,[0],[0]
"The resulting statistics of the tensors we use here are shown in Table 1.
10Data and code available from the authors.",5.1 Dataset and Setup,[0],[0]
"11Aristo Tuple KB v0, http://allenai.org/data/aristo-tuple-kb.
",5.1 Dataset and Setup,[0],[0]
"This data, which is the only one we are aware of with generics, does not include ((s, r, t), all) style triples.",5.1 Dataset and Setup,[0],[0]
We therefore use the objective function in Eqn.,5.1 Dataset and Setup,[0],[0]
(2) rather than the multi-class one in Eqn. (1).,5.1 Dataset and Setup,[0],[0]
"Despite this limitation of the dataset and its superficial similarity to the binary classification task underlying standard (non-generics) KB completion, our results reveal that extending a generics KB is surprisingly difficult for existing methods.
",5.1 Dataset and Setup,[0],[0]
"Dalvi et al. (2017) use a pipeline consisting of Open IE (Banko et al., 2007) extractions, aggregation, and clean up via crowd-sourcing to generate the Science tensor.",5.1 Dataset and Setup,[0],[0]
"These facts come with a relevant WordNet (Miller, 1995) based taxonomy, entity types (derived from WordNet ‘synsets’), and relation schema.",5.1 Dataset and Setup,[0],[0]
"Our method capitalizes on this additional information12 to perform high quality knowledge completion.
",5.1 Dataset and Setup,[0],[0]
Our evaluation metric is the accuracy of the top k triples generated by various KB completion methods.,5.1 Dataset and Setup,[0],[0]
"We also visualize entire precision-recall curves, where possible.",5.1 Dataset and Setup,[0],[0]
"While this metric requires human annotation and is thus more cumbersome than fullyautomatic metrics, it is arguably more suitable for evaluating generative tasks with a massive output space, such as KB completion.",5.1 Dataset and Setup,[0],[0]
"In this setting, evaluation against a relatively small held out test set can be misleading—a method may be highly accurate at generating thousands of valid and useful triples even if it does not necessarily classify specific held out instances accurately.",5.1 Dataset and Setup,[0],[0]
"While measures such MAP and MRR have been used in the past to alleviate this, they provide only a partial solution to the inherent difficulty of evaluating generative systems.",5.1 Dataset and Setup,[0],[0]
"Annotation-efficient evaluation methods have recently been proposed to address this challenge (Sabharwal and Sedghi, 2017).
",5.1 Dataset and Setup,[0],[0]
"12In order to limit potential error propagation, we collapse the taxonomy to the top two levels in our experiments.",5.1 Dataset and Setup,[0],[0]
"We first compare our method (Section 3) with existing KB completion techniques on the Animals tensor, and then demonstrate that its effectiveness carries over scalably to the larger Science tensor as well.",5.2 Guided KB Completion,[0],[0]
"In what follows, T denotes the tensor under consideration.
",5.2 Guided KB Completion,[0],[0]
"We examine two alternatives for generating negative samples: given a triple (s, r, t) ∈ T , replace s with (1) any entity s′ or (2) an entity s′ of the same type as s.",5.2 Guided KB Completion,[0],[0]
"The resulting perturbed triple (s′, r, t) is then treated as a negative sample if it is not present in T .",5.2 Guided KB Completion,[0],[0]
"We also considered a weighted combination of (1) and (2), and found random sampling to be the most reliable on our datasets.",5.2 Guided KB Completion,[0],[0]
"This complies with the commonly used LCWA assumption not being applicable to these tensors.
",5.2 Guided KB Completion,[0],[0]
"As baselines, we consider extensions of three state-of-the-art embedding-based KB completion methods: HolE, TransE, and RESCAL.",5.2 Guided KB Completion,[0],[0]
"As mentioned earlier, two leading graph-based methods, SFE and PRA, did not scale well.",5.2 Guided KB Completion,[0],[0]
Both vanilla TransE and RESCAL resulted in poor performance; we thus report numbers only for their extensions.,5.2 Guided KB Completion,[0],[0]
"Specifically, we consider 3 baselines: (1) HolE, (2) TransE+Schema, and (3) SICTF which extends
RESCAL and incorporates schema.",5.2 Guided KB Completion,[0],[0]
Figure 1 shows the resulting precision-yield curves for the predictions made by each method on the Animals dataset containing 10.6K facts.,5.2 Guided KB Completion,[0],[0]
"Specifically, for each method, we rank the predictions based on the method’s assigned score and compute the precision of the top k predictions for varying k.",5.2 Guided KB Completion,[0],[0]
"As expected, we observe a generally decreasing trend as k increases.",5.2 Guided KB Completion,[0],[0]
TransE+ITRS gave a precision of only around 10% and is omitted from the plot.,5.2 Guided KB Completion,[0],[0]
"We make two observations:
First, deriving new facts for these generics tensors at a high precision is challenging!",5.2 Guided KB Completion,[0],[0]
"Specifically, none of the baseline methods (black and pink curves), which represent state of the art for named-entity tensors, achieve a yield of more than 10% of T (i.e., 1K predictions) even at a precision of just 60%.
",5.2 Guided KB Completion,[0],[0]
"Second, external information, if used appropriately, can be surprisingly powerful in this setting.",5.2 Guided KB Completion,[0],[0]
"Specifically, simply incorporating relation schema (ITRS, blue curve) allows HolE-based completion to double the size of the starting tensor T by producing over 10K new triples at a precision of 82%.",5.2 Guided KB Completion,[0],[0]
"Further, incorporating entity taxonomy (IET, green
curve) to address tensor sparsity results in the same yield at a statistically significantly higher precision of 86.4%.
",5.2 Guided KB Completion,[0],[0]
"It turns out that not only does our method result in substantially improved PR curves, it also generates qualitatively more interesting and useful generic facts about the world than previous methods.",5.2 Guided KB Completion,[0],[0]
"We illustrate this in Table 2, which lists the top 20 predictions made by various approaches.",5.2 Guided KB Completion,[0],[0]
"The triples shown in red are false predictions (e.g., (penguin, has part, tooth), (grass, graze in, man), (caterpillar, turn into, bird)) or uninteresting ones (e.g., (water, is known as, water)).",5.2 Guided KB Completion,[0],[0]
"As we see, a vast majority of the top 20 predictions made by both vanilla HolE and SICTF fall into these categories.",5.2 Guided KB Completion,[0],[0]
"On the other hand, our method, HolE+ITRS+IET, predicts 19 true tripes out of the top 20, including interesting scientific facts that were evidently missing from the starting tensor, such as (salmon, thrive in, water), (fish, swim in, ocean) and (insect, destroy, tree).
",5.2 Guided KB Completion,[0],[0]
"Finally, we evaluate our proposal on the entire Science dataset with 66.6K facts.",5.2 Guided KB Completion,[0],[0]
"Since graph-based methods did not scale well to the much smaller Animals dataset and other methods performed substan-
tially worse there, we focus here on the scalability and prediction quality of our method.",5.2 Guided KB Completion,[0],[0]
"We found that HolE+ITRS+IET scales well to this high dimension, doubling the number of facts by adding 66K new facts at 74% precision.",5.2 Guided KB Completion,[0],[0]
"Although the Science tensor is 1,000 times larger than the Animals tensor, the method took only 10x longer to run (3 minutes on Animals tensor vs. 56 minutes on Science tensor, using a 2.8GHz, 16GB Macbook Pro).",5.2 Guided KB Completion,[0],[0]
"With additional improvements such as parallelization, it is easily possible to further scale the method up to substantially larger tensors.",5.2 Guided KB Completion,[0],[0]
"To assess the quality of our active learning mechanism (Section 4), we consider predicting facts about a new entity ẽ that is not in the Animals tensor.",5.3 Active Learning for New Entities,[0],[0]
"For illustration, we choose ẽ from the Science tensor vocabulary while ensuring that it is present in the WordNet taxonomy.
",5.3 Active Learning for New Entities,[0],[0]
The setup is as follows.,5.3 Active Learning for New Entities,[0],[0]
"We first use a query generation mechanism (Random, Schema Consistent, or Sibling Guided; cf. Section 4.1) to propose an ordered list L of facts about ẽ to annotate.",5.3 Active Learning for New Entities,[0],[0]
"Next, we perform subset selection (Top k or TK, Submodular or SM; cf. Section 4.2) on L to identify a subset L̂ of up to 100 most promising queries.",5.3 Active Learning for New Entities,[0],[0]
"These are then annotated and the true ones fed into tensor factorization as additional input to infer further new facts about ẽ.
In Table 3, we assess the quality of L̂ in two ways, when |L̂| = 100: how many true facts does L̂ have and how many overall new facts does this annotation produce about ẽ. Figure 2 provides a complementary view, focusing on the overall number of new facts inferred as |L̂| increases.",5.3 Active Learning for New Entities,[0],[0]
"While these illus-
trative numbers are for a representative new entity, reindeer, the overall trend and order of numbers remained the same for other new entities we experimented with.
",5.3 Active Learning for New Entities,[0],[0]
We mention some highlights from Table 3.,5.3 Active Learning for New Entities,[0],[0]
"First, not surprisingly, randomly choosing triples about ẽ to annotate is ineffective.",5.3 Active Learning for New Entities,[0],[0]
"Second, choosing schema consistent triples results in 73 true triples (out of 100) but these facts help tensor factorization very little, resulting in only 10 additional new triples about ẽ.",5.3 Active Learning for New Entities,[0],[0]
"Our proposed sibling guided querying mechanism results not only in nearly all 100 facts being true along with 17 true facts inferred from sibling agreement (set M in Alg. 1), but also, combined with submodular subset selection for balancing diversity with coverage (Alg. 2), ultimately results in 483 new
facts about ẽ. These facts cover interesting new information such as (reindeer, eat, fruit), (wolf, chase, reindeer), and (reindeer, provide, fur).
",5.3 Active Learning for New Entities,[0],[0]
"Finally, the plot in Figure 2 demonstrates that the qualitative trends remain the same, irrespective of the number |L̂| of queries annotated.",5.3 Active Learning for New Entities,[0],[0]
"Overall, our sibling guided queries with submodular subset selection (green triangles, top-most curve) ultimately results in 5.8 times more new facts about ẽ than a non-trivial, uncertainly based, schema consistent baseline (black stars, 3rd curve from the top).",5.3 Active Learning for New Entities,[0],[0]
This attests to the efficacy of the method on this challenging problem and dataset.,5.3 Active Learning for New Entities,[0],[0]
"This work explores KB completion for a new class of problems, namely completing generics KBs, which is an essential step for including general world knowledge in intelligent machines.",6 Conclusion,[0],[0]
The differences between generics and much studied named entity KBs make existing techniques either not scale well or produce facts at an undesirably low precision out of the box.,6 Conclusion,[0],[0]
We demonstrate that incorporating entity taxonomy and relation schema appropriately can be highly effective for generics KBs.,6 Conclusion,[0],[0]
"Further, to address scarcity of facts about certain entities in such KBs, we present a novel active learning approach using sibling guided uncertainty estimation along with submodular subset selection.",6 Conclusion,[0],[0]
"The proposed techniques substantially outperform various baselines, setting a new state of the art for this challenging class of completion problems.
",6 Conclusion,[0],[0]
Our method is applicable to KBs that have an associated entity taxonomy and relation schema.,6 Conclusion,[0],[0]
It is expected to be successful when information from siblings can be used to guide what is likely to be true and what is a good candidate to query for a given entity.,6 Conclusion,[0],[0]
"We focus on KBs of generics where such information is available and—as we show—is highly valuable for effective KB completion.
",6 Conclusion,[0],[0]
Why does our use of types work substantially better in our setting than the use of types in various baselines?,6 Conclusion,[0],[0]
One hypothesis is the following.,6 Conclusion,[0],[0]
The use of complicated models requires substantial data and information.,6 Conclusion,[0],[0]
"In our KB, the information appears so sparse and incomplete that using types in complicated ways is not productive.",6 Conclusion,[0],[0]
"Our proposal instead
attempts to use type information only to gently enhance the signal and reduce noise, before performing tensor decomposition.",6 Conclusion,[0],[0]
"We hope this work will trigger further exploration of knowledge bases with generics, a key aspect of machine intelligence.",6 Conclusion,[0],[0]
"The authors would like to thank Peter Clark for fruitful discussions, valuable feedback, and crowdsourcing annotations; Matt Gardner for constructive comments and assessing graph-based completion methods on our datasets; and Udai Saini and Partha Talukdar for evaluating their CNTF approach on our datasets.",Acknowledgments,[0],[0]
"Given a knowledge base or KB containing (noisy) facts about common nouns or generics, such as “all trees produce oxygen” or “some animals live in forests”, we consider the problem of inferring additional such facts at a precision similar to that of the starting KB.",abstractText,[0],[0]
"Such KBs capture general knowledge about the world, and are crucial for various applications such as question answering.",abstractText,[0],[0]
"Different from commonly studied named entity KBs such as Freebase, generics KBs involve quantification, have more complex underlying regularities, tend to be more incomplete, and violate the commonly used locally closed world assumption (LCWA).",abstractText,[0],[0]
"We show that existing KB completion methods struggle with this new task, and present the first approach that is successful.",abstractText,[0],[0]
"Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting.",abstractText,[0],[0]
"First, our simple yet effective knowledge guided tensor factorization approach achieves state-of-the-art results on two generics KBs (80% precise) for science, doubling their size at 74%-86% precision.",abstractText,[0],[0]
"Second, our novel taxonomy guided, submodular, active learning method for collecting annotations about rare entities (e.g., oriole, a bird) is 6x more effective at inferring further new facts about them than multiple active learning baselines.",abstractText,[0],[0]
Knowledge Completion for Generics using Guided Tensor Factorization,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3198–3207 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3198",text,[0],[0]
"Knowledge Graphs (KGs) are extremely useful resources for many AI-related applications, such as question answering, information retrieval and query expansion.",1 Introduction,[0],[0]
"Indeed, KGs are multi-relational directed graphs composed of entities as nodes and relations as edges.",1 Introduction,[0],[0]
"They represent information about real-world entities and relations in the form of knowledge triples, which is denoted as (h, r, t), where h and t correspond to the head and tail entities and r denotes the relation between them, e.g., (Donald Trump, presidentOf, USA).",1 Introduction,[0],[0]
"Large
scale, collaboratively created KGs , such as Freebase (Bollacker et al., 2008), WordNet (Miller, 1994), Yago (Suchanek et al., 2007), Gene Ontology (Sherlock, 2009), NELL (Carlson et al., 2010) and Google’s KG1, have recently become available.",1 Introduction,[0],[0]
"However, despite the impressively large sizes, the coverage of most existing KGs are far from complete.",1 Introduction,[0],[0]
"This has motivated research in knowledge base completion task, which includes KGE methods aiming to embed entities and relations in KGs into low-dimensional embeddings.
",1 Introduction,[0],[0]
"In the literature, there are a number of studies about KGE models.",1 Introduction,[0],[0]
"These models embed entities and relations into latent vectors and complete KGs based on these vectors, such as TransE (Bordes et al., 2013), TransH (Wang et al., 2014) and TransR",1 Introduction,[0],[0]
"(Lin et al., 2015b).",1 Introduction,[0],[0]
"However, most of the existing works simply embed relations into vectors.",1 Introduction,[0],[0]
Less efforts have been made for investigating the rich information from the relation structure.,1 Introduction,[0],[0]
"Indeed, in this research, we define a three-layer hierarchical relation structure (HRS), which can be conformed by relation clusters, relations and subrelations in KGs.
",1 Introduction,[0],[0]
• Relation clusters: Semantically similar relations are often observed in Large-scales KGs.,1 Introduction,[0],[0]
"For example, the relation ’producerOf’ and ’directorOf’ may be semantically related if both of them describe a relation between a person and a film.",1 Introduction,[0],[0]
These semantically similar relations can make up relation clusters.,1 Introduction,[0],[0]
"We believe the information from semantically similar relations is of great value, and relations in the same group can be trained in a collective way to facilitate the knowledge sharing when learning the embeddings of related relations.
",1 Introduction,[0],[0]
"• Relations: A relation connects the head and 1https://www.google.com/intl/es419/insidesearch/features/ search/knowledge.html
tail entities in a knowledge triple, denoted as (h, r, t), where h and t correspond to the head and tail entities and r denotes the relation between them.
",1 Introduction,[0],[0]
• Sub-relations: There are relations that have multiple semantic meanings and can be split into several sub-relations.,1 Introduction,[0],[0]
"For example, the relation partOf has at least two semantics: location-related as (New Y ork, partOf , USA) and composition-related as (monitor, partOf , television).",1 Introduction,[0],[0]
"We believe the subrelations can give fine-grained descriptions for each relation.
",1 Introduction,[0],[0]
"The relation clusters, relations and sub-relations correspond to the top, middle and bottom layer of the three-layer HRS.
",1 Introduction,[0],[0]
"In this paper, we extend state-of-the-art models TransE (Bordes et al., 2013), TransH (Wang et al., 2014) and DistMult (Yang et al., 2015) to learn knowledge representations by leveraging the rich information from the HRS.",1 Introduction,[0],[0]
"Moreover, the same technique can easily be used to extend other stateof-the-art models and utilize the HRS information.",1 Introduction,[0],[0]
"In the proposed models, for each knowledge triple (h, r, t), the embedding of r is the sum of three embedding vectors, which correspond to the three layers of the HRS respectively and therefore, the information from the HRS is leveraged.",1 Introduction,[0],[0]
"Particularly, instead of using additional information like text or paths, our model simply use the knowledge triples in KGs and the rich information from the HRS.",1 Introduction,[0],[0]
"Extensive experiments on popular benchmark data sets demonstrate the effectiveness of our models.
",1 Introduction,[0],[0]
"In summary, we highlight our key contributions as follows,
1.",1 Introduction,[0],[0]
"We propose a technique by making use of the HRS information to conduct the KGE task, and extend three state-of-the-art models to utilize this technique.",1 Introduction,[0],[0]
"The technique can be easily applied to other KGE models.
",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
"Our proposed models don’t use additional information like text or paths, instead, we only use the knowledge triples in KGs and take advantage of the rich information from the HRS.
3.",1 Introduction,[0],[0]
"We evaluate our models on popular benchmark data sets, and the results show that our
extended models achieve substantial improvements against the original models as well as other state-of-the-art baselines.",1 Introduction,[0],[0]
We extend three popular KGE models by leveraging the HRS information in this study.,2 Preliminaries and Related Work,[0],[0]
"Therefore, in this section, we first introduce the three existing models TransE (Bordes et al., 2013), TransH (Wang et al., 2014) and DistMult (Yang et al., 2015) in detail.",2 Preliminaries and Related Work,[0],[0]
"Then, we further summarize other state-of-the-art models on the topic of KGE.",2 Preliminaries and Related Work,[0],[0]
"Recently, a number of KGE models have been proposed.","2.1 TransE, TransH and DistMult",[0],[0]
"These methods learn low-dimensional vector representations for entities and relations (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015b).
","2.1 TransE, TransH and DistMult",[0],[0]
"TransE (Bordes et al., 2013) is one of the most widely used model, which views relations as translations from a head entity to a tail entity on the same low-dimensional hyperplane, i.e, h + r","2.1 TransE, TransH and DistMult",[0],[0]
"≈ t when (h, r, t) holds.","2.1 TransE, TransH and DistMult",[0],[0]
This indicates that t should be the nearest neighbor of h+ r.,"2.1 TransE, TransH and DistMult",[0],[0]
"In this case, the score function of TransE is defined as
fr(h, t) = ‖h+ r− t‖Ln , (1)
which can be measured by L1 or L2 norm.","2.1 TransE, TransH and DistMult",[0],[0]
"Positive triples are supposed to have lower scores than negative ones.
","2.1 TransE, TransH and DistMult",[0],[0]
"TransH (Wang et al., 2014) introduces a mechanism of projecting entities into relation-specific hyperplanes that enables different roles of an entity in different relations.","2.1 TransE, TransH and DistMult",[0],[0]
TransH models the relation as a vector r on a hyperplane wr and assumes that h⊥ +,"2.1 TransE, TransH and DistMult",[0],[0]
"r ≈ t⊥ when (h, r, t) holds, where h⊥ and t⊥ are the projection of h and t in the relationspecific hyperplane.","2.1 TransE, TransH and DistMult",[0],[0]
"The score function of TransH is defined as
fr(h, t) = ‖h⊥ + r− t⊥‖22 , (2)
","2.1 TransE, TransH and DistMult",[0],[0]
"where h⊥ = h−w>r hwr, t⊥ = t−w>r twr and ‖wr‖2 = 1.","2.1 TransE, TransH and DistMult",[0],[0]
"Like triples in TransE, positive triples in TransH should have lower scores than negative ones.
","2.1 TransE, TransH and DistMult",[0],[0]
"DistMult (Yang et al., 2015) adopts a bilinear score function to compute the scores given (h, r, t) triples.","2.1 TransE, TransH and DistMult",[0],[0]
"The score function is defined as
fr(h, t) =","2.1 TransE, TransH and DistMult",[0],[0]
"hMrt, (3)
where Mr is a relation-specific diagonal matrix, which represents the characteristics of a relation.","2.1 TransE, TransH and DistMult",[0],[0]
"Different from TransE and TransH, positive triples should have larger scores than negative ones.","2.1 TransE, TransH and DistMult",[0],[0]
"Besides TransE, TransH and DistMult, there are also many models on the topic of KGE. TransR",2.2 Other KGE Models,[0],[0]
"(Lin et al., 2015b) embeds entities and relations into separate entity space and relationspecific spaces.",2.2 Other KGE Models,[0],[0]
"ComplEx (Welbl et al., 2016) extends DistMult to embed entities and relations into complex vectors instead of real-valued ones.",2.2 Other KGE Models,[0],[0]
"HolE (Nickel et al., 2016) employs circular correlations to create compositional representations.",2.2 Other KGE Models,[0],[0]
"ProjE (Shi and Weninger, 2017) adopts a twolayer network to embed entities and relations.",2.2 Other KGE Models,[0],[0]
"Other KGE models also try to embeds entities and relations in various ways, such as Unstructured Model (Bordes et al., 2012a, 2014), Structured Embedding (Bordes et al., 2012b), Single Layer Model (Socher et al., 2013), Semantic Matching Energy (Bordes et al., 2012a, 2014), NTN Model (Socher et al., 2013), etc.
",2.2 Other KGE Models,[0],[0]
Many efforts have been devoted to building models using additional information like paths or text.,2.2 Other KGE Models,[0],[0]
"For instance, PTransE (Lin et al., 2015a) and R-GCN (Schlichtkrull et al., 2017) use paths as additional information, while DKRL (Xie et al., 2016) and SSP (Xiao et al., 2017) adopt text to assist the embedding task.
",2.2 Other KGE Models,[0],[0]
Some KGE works focus on making use of the information from relations.,2.2 Other KGE Models,[0],[0]
"CTransR (Lin et al., 2015b), TransD",2.2 Other KGE Models,[0],[0]
"(Ji et al., 2015) and TransG",2.2 Other KGE Models,[0],[0]
"(Xiao et al., 2016) try to find fine-grained representations for each relation.",2.2 Other KGE Models,[0],[0]
"However, these works didn’t utilize the information from semantically similar relations and the HRS is also not exploited.",2.2 Other KGE Models,[0],[0]
"Different from the above studies, we believe semantically similar relations can make up relation clusters, and some relations may have multiple semantic meanings and can be split into fine-grained subrelations.",2.2 Other KGE Models,[0],[0]
"In this paper, we take advantage of the three-layer HRS and conduct the KGE task by extending three widely used models.",2.2 Other KGE Models,[0],[0]
"In this section, we provide the technical details of how to extend existing KGE models by leveraging the HRS information.",3 Methodology,[0],[0]
We first formally define the HRS and its integration with existing models.,3 Methodology,[0],[0]
"Then
we introduce the new loss functions of extended models TransE-HRS, TransH-HRS and DistMultHRS.",3 Methodology,[0],[0]
"Finally, two variants of the HRS models and implementation details are provided.",3 Methodology,[0],[0]
"Given a KG G = {(h, r, t)} ⊆ E × R× E , where E and R are the entity (node) set and relation (edge) set respectively.",3.1 Hierarchical Relation Structure,[0],[0]
We believe the relations in KGs can make up relation clusters as well as be split into fine-grained sub-relations.,3.1 Hierarchical Relation Structure,[0],[0]
"On the one hand, large scale KGs always have semantically related relations.",3.1 Hierarchical Relation Structure,[0],[0]
The information from semantically similar relations is of great value and these relations should be trained in a collective way.,3.1 Hierarchical Relation Structure,[0],[0]
"In this way, meaningful associations among related relations can be utilized and less frequent relations can be enriched with more training data.",3.1 Hierarchical Relation Structure,[0],[0]
"On the other hand, some relations may have multiple semantic meanings and can be split into several subrelations, which can provide fine-grained descriptions for each relation.",3.1 Hierarchical Relation Structure,[0],[0]
"In general, relations in KGs conform to a three-layer HRS, as shown in Figure 1.",3.1 Hierarchical Relation Structure,[0],[0]
"The HRS include a relation cluster layer, a relation layer and a sub-relation layer, which are denoted in yellow, green and blue in Figure 1 respectively.
",3.1 Hierarchical Relation Structure,[0],[0]
"For a triple (h, r, t) in the HRS model, the embedding of r is comprised of three parts: the relation cluster embedding rc, relation-specific embedding r′ and sub-relation embedding rs, which is denotes as
r = rc + r ′ + rs.",3.1 Hierarchical Relation Structure,[0],[0]
"(4)
",3.1 Hierarchical Relation Structure,[0],[0]
"According to the above equation, the embedding of each relation can leverage the information from the three-layer HRS.",3.1 Hierarchical Relation Structure,[0],[0]
"The relation clusters and subrelations are determined by k-means algorithm based on the results of TransE:
• Relation clusters.",3.1 Hierarchical Relation Structure,[0],[0]
"We first run TransE on a given data set and obtain the embeddings of relations r1, r2, r3, ..., r|R|, where |R| is the number of relations.",3.1 Hierarchical Relation Structure,[0],[0]
"Then, the k-means algorithm is applied on these embeddings.",3.1 Hierarchical Relation Structure,[0],[0]
"In this way, we get relation clusters C1, C2, C3, ..., C|C|, where C is the set of relation clusters.",3.1 Hierarchical Relation Structure,[0],[0]
"Previous studies have shown that the embeddings of semantically similar relations locate near each other in the latent space (Yang et al., 2015).",3.1 Hierarchical Relation Structure,[0],[0]
"In this way, we are able to find relation clusters composed of semantically related relations.
",3.1 Hierarchical Relation Structure,[0],[0]
• Sub-relations.,3.1 Hierarchical Relation Structure,[0],[0]
TransE assumes that t − h,3.1 Hierarchical Relation Structure,[0],[0]
"≈ r when (h, r, t) holds.",3.1 Hierarchical Relation Structure,[0],[0]
"For each triple (h, r, t), we define that r̂ = t−h, where h and t are obtained from the results of TransE. For each relation, we collect all the r̂ and adopt the k-means algorithm to cluster these vectors into several groups Sr1 , Sr2 , Sr3 , ..., Srnr , where nr is the number of subrelations for",3.1 Hierarchical Relation Structure,[0],[0]
relation r.,3.1 Hierarchical Relation Structure,[0],[0]
Each group corresponds to a fine-grained sub-relation.,3.1 Hierarchical Relation Structure,[0],[0]
"The loss of the extended HRS model is comprised of two parts, as is shown in Equation (5),
LTotal =",3.2 Loss Function,[0],[0]
"LOrig + LHRS , (5)
where LOrig is the loss function of the original model, while LHRS is the loss function for the HRS information.
",3.2 Loss Function,[0],[0]
"We know that TransE, TransH and DistMult all adopt a margin-based ranking loss.",3.2 Loss Function,[0],[0]
"Taking TransE as an example, the loss function of TransE for the first part LOrig is shown as Equation (6),
LOrig = |C|∑ c=1 ∑ r∈Cc ∑ (h,r,t)∈4r ∑ (h′,r,t′)∈4′r",3.2 Loss Function,[0],[0]
"[γ + fr(h, t)
",3.2 Loss Function,[0],[0]
"− fr(h′, t′)]+, (6)
where [x]+ = max(0, x), 4r denotes the set of positive triples for relation r and 4′r = {(h′, r, t)|h′ ∈ E}∪{(h, r, t′)|t′ ∈ E} is the set of negative ones for relation r. γ is the margin separating the positive triples from the negative ones.",3.2 Loss Function,[0],[0]
"fr(h, t) is the score function as shown in Equation (7),
fr(h, t) = ∥∥h+",3.2 Loss Function,[0],[0]
rc + r′ + rs,3.2 Loss Function,[0],[0]
"− t∥∥Ln , (7)
which can be measured by L1 or L2 norm.",3.2 Loss Function,[0],[0]
"Positive triples are supposed to have lower scores than negative ones.
",3.2 Loss Function,[0],[0]
"The second part, LHRS , is composed of three regularized terms, which is shown in Equation (8),
LHRS = λ1 ∑ rc∈C ‖rc‖22 + λ2 ∑ r′∈R ∥∥r′∥∥2 2
+ λ3 ∑ rs∈S ‖rs‖22 , (8)
where C = {C1, C2, ..., C|C|} is the set of relation clusters, S = {Sr1 , Sr2 , Sr3 , ..., Srnr |r ∈ R} is the set of fine-grained sub-relations, nr is the number of sub-relations for relation r. λ1, λ2 and λ3 are trade-off parameters.",3.2 Loss Function,[0],[0]
"Large value of λ1 will result in the separate training of each relation, while large value of λ2 will lead to all relations in the same relation cluster sharing the same embedding vector.",3.2 Loss Function,[0],[0]
"λ3 should be larger than λ1 and λ2 to restrict rs to be a small value, i.e., the sub-relations from the same relation should be close.",3.2 Loss Function,[0],[0]
"Additionally, we introduce two variants of the HRS model: the top-middle model and the middle-bottom model.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
The top-middle model only uses the HRS by leveraging the information from the top to the middle layer.,3.3 Variants of the HRS Model and Implementation details,[0],[0]
"For this model, the relation embedding and the loss for HRS is defined as Equation (9) and (10).
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"r = rc + r ′, (9)
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
LHRS = λ1 ∑ rc∈C ‖rc‖22 + λ2 ∑ r′∈R ∥∥r′∥∥2 2 .,3.3 Variants of the HRS Model and Implementation details,[0],[0]
"(10)
While the middle-bottom model only utilizes the information from the middle to the bottom layer.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"The relation embedding and HRS loss are defined as Equation (11) and (12).
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"r = r′ + rs, (11)
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
LHRS = λ2 ∑ r′∈R ∥∥r′∥∥2 2 + λ3 ∑ rs∈S ‖rs‖22 .,3.3 Variants of the HRS Model and Implementation details,[0],[0]
"(12)
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"The learning process of the extended models is carried out by using the Adam (Kingma and Ba, 2014) optimizer.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"For the extended models of TransE, all the entity and relation embedding parameters are initialized with a uniform distribution U [ − 6√
k , 6√ k
] following TransE, where k
is the dimension of the embedding space.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"For the extended models of TransH and DistMult, we initialize these parameters with the results of TransE. For the relation cluster embeddings and sub-relation embeddings, we initialize all the parameters with the value of zero.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"In this research, we evaluate the performances of our extended models on popular benchmarks FB15k (Bordes et al., 2013), FB15k237 (Toutanova and Chen, 2015), FB13(Socher et al., 2013), WN18 (Bordes et al., 2013) and WN11 (Socher et al., 2013).",4.1 Data Sets,[0],[0]
"FB15k, FB15k237 and FB13 are extracted from Freebase (Bollacker et al., 2008), which provides general facts of the world.",4.1 Data Sets,[0],[0]
"WN18 and WN11 are obtained from WordNet (Miller, 1994), which provides semantic knowledge of words.",4.1 Data Sets,[0],[0]
"FB15k-237 and WN18 are used for the task of link prediction, FB13 and WN11 are used for the triple classification task, while FB15k is used for both tasks.",4.1 Data Sets,[0],[0]
The statistics of the five data sets are summarized in Table 1.,4.1 Data Sets,[0],[0]
"To demonstrate the effectiveness of our models, we compare results with the following baselines.
",4.2 Baselines,[0],[0]
•,4.2 Baselines,[0],[0]
"TransE (Bordes et al., 2013): one of the most widely used KGE models.
",4.2 Baselines,[0],[0]
"• TransH (Wang et al., 2014): a KGE model which adopts relation-specific hyperplanes to lay entities and relations.
",4.2 Baselines,[0],[0]
"• DistMult (Yang et al., 2015): a state of the art model which uses a bilinear score function to compute scores of knowledge triples.
",4.2 Baselines,[0],[0]
"• CTransR (Lin et al., 2015b): a pioneering KGE model which exploits fine-grained sub-relations for each relation.
• TransD",4.2 Baselines,[0],[0]
"(Ji et al., 2015): an improvement of CTransR, which embeds KGs using dynamic mapping matrices.
• TransG",4.2 Baselines,[0],[0]
"(Xiao et al., 2016): the first generative KGE model that uses a non-parametric bayesian model to embed KGs.",4.2 Baselines,[0],[0]
"Link prediction, a.k.a. knowledge graph completion, aims to fill the missing values into incomplete knowledge triples.",4.3 Link Prediction,[0],[0]
"More formally, the goal of link prediction is to predict either the head entity in a given query (?, r, t) or the tail entity in a given query (h, r, ?).",4.3 Link Prediction,[0],[0]
All the parameters are set by some preliminary test.,4.3.1 Experimental Settings,[0],[0]
"For TransE-HRS, TransE-top-middle and TransE-middle-bottom, λ1, λ2, λ3 and the margin γ are set as λ1 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 4, λ3 = 1e−3, γ = 2.",4.3.1 Experimental Settings,[0],[0]
"For the extended models of TransH, we set the parameters as λ1 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ3 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 3, γ = 1.",4.3.1 Experimental Settings,[0],[0]
"For the extended models of DistMult, the parameters are set as λ1 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 4, λ3 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 3, γ = 1.",4.3.1 Experimental Settings,[0],[0]
"For all the above models, the learning rate ς , batch size b and embedding size k are set as ς = 1e",4.3.1 Experimental Settings,[0],[0]
"− 3, b = 4096, k = 100.",4.3.1 Experimental Settings,[0],[0]
The L1 norm is adopted by the score function of TransE and its extended models.,4.3.1 Experimental Settings,[0],[0]
"The number of relation clusters are set as 300, 120 and 10 for FB15k, FB15k-237 and WN18 respectively.",4.3.1 Experimental Settings,[0],[0]
"For all the data sets, we generate 3 subrelations for relations that have more than 500 occurrences in the training set.",4.3.1 Experimental Settings,[0],[0]
"For all the extended models and baselines, we produce negative triples following the “bern” sampling strategy which was introduced in TransH (Wang et al., 2014).",4.3.1 Experimental Settings,[0],[0]
"For baselines TransE, TransH and DistMult, the embedding parameters of entities and relations are initialized the same way as the extended models for a fair comparison.
",4.3.1 Experimental Settings,[0],[0]
"In the test phase, we replace the head and tail entities with all the entities in KG in turn for each triple in the test set.",4.3.1 Experimental Settings,[0],[0]
Then we compute a score for each corrupted triple.,4.3.1 Experimental Settings,[0],[0]
"Note that for each corrupted
triple (h′, r, t′), the sub-relation is determined by t′ − h′, i.e., the k-means model is adopted to assign t′−h′ to a specific sub-relation of r. We rank all the candidate entities according to the scores.",4.3.1 Experimental Settings,[0],[0]
"Specifically, positive candidates are supposed to precede negative ones.",4.3.1 Experimental Settings,[0],[0]
"Finally, the rank of the correct entity is stored.",4.3.1 Experimental Settings,[0],[0]
"We compare our models with baselines using the following metrics: (1) Mean Rank (MR, the mean of all the predicted ranks); (2) Mean Reciprocal Rank (MRR, the mean of all the reciprocals of predicted ranks); (3) Hits@n",4.3.1 Experimental Settings,[0],[0]
"(Hn, the proportion of ranks not larger than n).",4.3.1 Experimental Settings,[0],[0]
Lower values of MR and larger values of MRR and Hn indicate better performance.,4.3.1 Experimental Settings,[0],[0]
"All the results are reported in the “filtered” setting (Bordes et al., 2013).",4.3.1 Experimental Settings,[0],[0]
Evaluation results are shown in Table 2.,4.3.2 Experimental Results,[0],[0]
We divide all the results into 4 groups.,4.3.2 Experimental Results,[0],[0]
"The second, third and forth group are results of TransE, TransH, DistMult and their extended models respectively, while the first group are results of other state-ofthe-art competitors.",4.3.2 Experimental Results,[0],[0]
Results in bold font are the best results in the group and the underlined results denote the best results in the column.,4.3.2 Experimental Results,[0],[0]
"From Table 1, we have the following findings: (1) Our extended models outperform the original models, which indicates that the information learned from the HRS is valuable; (2) For WN18, the results from ‘top-middle’ models of TransE, TransH and DistMult are worse than the original models, and HRS models can’t outperform middle-bottom ones.",4.3.2 Experimental Results,[0],[0]
We conjecture the reason lies as follows: WN18 has only 18 relations and the semantic correlation among relations is small.,4.3.2 Experimental Results,[0],[0]
"In this case, the information learned from the top to the middle layer of the HRS may lead to worse results since for each relation, even though the information learned from semantically similar relations are useful, the information learned from unrelated relations may damage the results.",4.3.2 Experimental Results,[0],[0]
"The results indicate that HRS models are especially useful for KGs with dense semantic distributions over relations; (3) For WN18, TransE-middle-bottom and DistMult-middle-bottom achieve the best results on MRR, Hits@10, Hits@3 and Hits@1 while failing to get the best results on MR in the same group.",4.3.2 Experimental Results,[0],[0]
"Further analysis shows that in the results of TransE-middle-bottom, 56 test triples get ranks more than 10000, leading to more than 110 MR loss.",4.3.2 Experimental Results,[0],[0]
"While in the results of DistMult-middle-
bottom, there exist 37 test triples whose ranks are more than 7000, which would lead to about 50 MR loss.",4.3.2 Experimental Results,[0],[0]
"Indeed, MR is sensitive to these high ranks, which lead to worse results on the metric of MR; (4) From all the results, based on the good basic model DistMult, the extended models of DistMult can achieve the best performance compared with other state-of-the-art baselines CTransR, TransD and TransG.
We also provide some case studies on relation clusters and sub-relations.",4.3.2 Experimental Results,[0],[0]
Table 3 shows some relation clusters of FB15k.,4.3.2 Experimental Results,[0],[0]
"Cluster 1 to 3 are Olympics-related, basketball-related and software-related relations respectively.",4.3.2 Experimental Results,[0],[0]
From Table 3 we can see that semantically related relations can join the same cluster.,4.3.2 Experimental Results,[0],[0]
"Table 4 shows some (head, tail) pairs for the sub-relations of ‘/educational institution/education/degree’.",4.3.2 Experimental Results,[0],[0]
"Sub-relation 1 to 3 are about the degree of Doctor, Master and Bachelor respectively.",4.3.2 Experimental Results,[0],[0]
"Table 5 gives some (head, tail) pairs for the sub-relations of ’/music/artist/genre’.",4.3.2 Experimental Results,[0],[0]
Sub-relation 1 and 2 are about rock music and pop music respectively while subcluster 3 is about other kinds of music.,4.3.2 Experimental Results,[0],[0]
"From Table 4 and 5, we can see that different sub-relations give fine-grained descriptions for each relation.",4.3.2 Experimental Results,[0],[0]
"In this section, we study the performance affected by the number of relation clusters N1 as well as the number of sub-relations for each relation N2.",4.3.3 Parameter Study,[0],[0]
The results in Figure 2 and 3 clearly show that there exists an optimal value of N1 and N2 for each dataset.,4.3.3 Parameter Study,[0],[0]
All three models keep achieving better results as we increase the number of clusters from 0 to the optimal value.,4.3.3 Parameter Study,[0],[0]
"Then, after N1 and N2 exceed the optimal point, the performance starts falling down.",4.3.3 Parameter Study,[0],[0]
The reason lies as: (1) Smaller value of N1 leads to large-sized relation clusters.,4.3.3 Parameter Study,[0],[0]
Some unrelated relations may join in the same large-sized cluster and degrade the performance of our models.,4.3.3 Parameter Study,[0],[0]
"Larger value of N1 leads to small-sized relation clusters, thus less information can be leveraged by each relation, leading to the unsatisfying performance; (2) Smaller value of N2 can’t provide sufficient representations for each relation and degrade the performance of our models.",4.3.3 Parameter Study,[0],[0]
Larger value ofN2 may lead to lacking of training data for each sub-relation and also result in the unsatisfying performance.,4.3.3 Parameter Study,[0],[0]
"In order to testify the discriminative capability of our models, we conduct a triple classification task aiming to predict the label (True or False) of a given triple (h, r, t).",4.4 Triple Classification,[0],[0]
"In this paper, we use three datasets WN11, FB13 and FB15k to evaluate our models.",4.4.1 Experimental Settings,[0],[0]
"The data sets WN11 and FB13 released by NTN (Socher et al., 2013) already have negative triples.",4.4.1 Experimental Settings,[0],[0]
"The test set of FB15k only contains correct triples, which re-
quires us to construct negative triples.",4.4.1 Experimental Settings,[0],[0]
"In this study, we construct negative triples following the same setting used for FB13 (Socher et al., 2013).",4.4.1 Experimental Settings,[0],[0]
"For the extended models of TransE, λ1, λ2, λ3 and γ are set as λ1 = 1e−5, λ2 = 1e−5, λ3 = 1e−3 and γ = 4.",4.4.1 Experimental Settings,[0],[0]
"For the extended models of TransH, we set λ1 = 1e",4.4.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.4.1 Experimental Settings,[0],[0]
"− 4, λ3 = 1e",4.4.1 Experimental Settings,[0],[0]
− 3 and γ = 5.,4.4.1 Experimental Settings,[0],[0]
"While for the extended models of DistMult, parameters are set as λ1 = 1e",4.4.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e− 4, λ3 = 1e− 2 and γ = 4.",4.4.1 Experimental Settings,[0],[0]
"For WN11 and FB13, we generate 2 sub-relations for each relation.",4.4.1 Experimental Settings,[0],[0]
"For FB15k, we generate 3 sub-relations for
relations that have more than 500 occurrences in the training set.",4.4.1 Experimental Settings,[0],[0]
Other parameters are set as introduced in Section 4.3.1.,4.4.1 Experimental Settings,[0],[0]
"We follow the same decision process as NTN (Socher et al., 2013): for TransE and TransH, a triple is predicted to be positive if fr(h, t) is below a threshold, while for DistMult, a triple is regarded as a positive one if fr(h, t) is above a threshold; otherwise negative.",4.4.1 Experimental Settings,[0],[0]
The thresholds are determined on the validation set.,4.4.1 Experimental Settings,[0],[0]
We adopt accuracy as our evaluation metric.,4.4.1 Experimental Settings,[0],[0]
"Finally, the evaluation results in Table 6 lead to the following findings: (1) Our models outperform other baselines on WN11 and FB15k, and obtain comparable results with baselines on FB13, which validate the effectiveness of our models; (2) The extended models TransE-HRS, TransH-HRS and DistMult-HRS achieve substantial improvements against the original models.",4.4.2 Experimental Results,[0],[0]
"On WN11, TransE-
HRS outperforms TransE with a margin as large as 10.9%.",4.4.2 Experimental Results,[0],[0]
These improvements indicates the technique of utilizing the HRS information is capable to be extended to different KGE models.,4.4.2 Experimental Results,[0],[0]
"Figure 4
shows the classification accuracy of different relations on WN11.",4.4.2 Experimental Results,[0],[0]
"We can see that extended models significantly improve the original models in each relation classification task, which again validate the effectiveness of our models.",4.4.2 Experimental Results,[0],[0]
"In this paper, we found that relations in KGs conform to a three-layer HRS.",5 Conclusion,[0],[0]
"This HRS model provides a critical capacity for embedding entities and relations, and along this line we extended three state-of-the-art models to leverage the HRS information.",5 Conclusion,[0],[0]
The technique we used can be easily applied to extend other KGE models.,5 Conclusion,[0],[0]
"Moreover, our proposed models don’t need additional information like text or paths, instead, we made full use of the knowledge triples in KGs and the rich information from the HRS.",5 Conclusion,[0],[0]
We evaluate our model on the link prediction task and triple classification task.,5 Conclusion,[0],[0]
"The results show that our extended models achieve substantial improvements against the original models as well as other baseline competitors.
",5 Conclusion,[0],[0]
"In the future, we will utilize more sophisticated models to leverage the HRS information, e.g, (1) utilize the embeddings of the three layers in a more sophisticated way instead of sum them together;
(2) determine the number of relation clusters and sub-relations automatically instead of manually.",5 Conclusion,[0],[0]
"The research work is supported by the National Key Research and Development Program of China under Grant No. 2018YFB1004300, the National Natural Science Foundation of China under Grant No. 61773361, 61473273, 91546122, Guangdong provincial science and technology plan projects under Grant No. 2015 B010109005, the Project of Youth Innovation Promotion Association CAS under Grant No. 2017146.",Acknowledgements,[0],[0]
This work is also partly supported by the funding of WeChat cooperation project.,Acknowledgements,[0],[0]
"We thank Bo Chen, Leyu Lin, Cheng Niu, Xiaohu Cheng for their constructive advices.",Acknowledgements,[0],[0]
"The rapid development of knowledge graphs (KGs), such as Freebase and WordNet, has changed the paradigm for AI-related applications.",abstractText,[0],[0]
"However, even though these KGs are impressively large, most of them are suffering from incompleteness, which leads to performance degradation of AI applications.",abstractText,[0],[0]
Most existing researches are focusing on knowledge graph embedding (KGE) models.,abstractText,[0],[0]
"Nevertheless, those models simply embed entities and relations into latent vectors without leveraging the rich information from the relation structure.",abstractText,[0],[0]
"Indeed, relations in KGs conform to a three-layer hierarchical relation structure (HRS), i.e., semantically similar relations can make up relation clusters and some relations can be further split into several fine-grained sub-relations.",abstractText,[0],[0]
"Relation clusters, relations and sub-relations can fit in the top, the middle and the bottom layer of three-layer HRS respectively.",abstractText,[0],[0]
"To this end, in this paper, we extend existing KGE models TransE, TransH and DistMult, to learn knowledge representations by leveraging the information from the HRS.",abstractText,[0],[0]
"Particularly, our approach is capable to extend other KGE models.",abstractText,[0],[0]
"Finally, the experiment results clearly validate the effectiveness of the proposed approach against baselines.",abstractText,[0],[0]
Knowledge Graph Embedding with Hierarchical Relation Structure,title,[0],[0]
"Proceedings of the SIGDIAL 2015 Conference, pages 12–21, Prague, Czech Republic, 2-4 September 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
"Partially observable Markov decision processes (POMDP) (Young et al., 2013) are a popular framework to model dialogue management as a reinforcement learning (RL) problem.",1 Introduction,[0],[0]
"In a POMDP, a state tracker (Thomson and Young, 2010)(Williams, 2014) maintains a distribution over possible user goals (states), called the belief state, and RL methods (Sutton and Barto,
1998) are used to optimize a metric called cumulative reward, a score that combines dialogue success rate and dialogue length.",1 Introduction,[0],[0]
"However, existing model-based RL approaches become intractable for real world sized dialogue systems (Williams and Young, 2007), and model-free approaches often need a large number of dialogues to converge to the optimal policy (Jurčı́ček et al., 2012).
",1 Introduction,[0],[0]
"Recently, Gaussian process (GP) based RL (Engel et al., 2005) has been proposed for dialogue policy optimization, reducing the number of interactions needed to converge to the optimal policy by an order of magnitude with respect to other POMDP models, allowing the policy to be learned directly from real users interactions (Gašić et al., 2013 a).",1 Introduction,[0],[0]
"In addition, using transfer learning methods (Taylor and Stone, 2009) to initialise the policy with data gathered from dialogue systems in different domains has increased the learning speed of the policy further (Gašić et al., 2013 b), and provided an acceptable system performance when there is no domain specific data available.",1 Introduction,[0],[0]
"In the case of dialogue managers personalised for a single speaker, data gathered from other “source” speakers can be used to pre-train the policy, but if the dynamics of the other speakers are very different, this data will have a different distribution than the data of the current “target” speaker, and therefore, using this data to train the policy model does not have any benefit.",1 Introduction,[0],[0]
"In the context of speaker specific acoustic models for users with dysarthria (a speech impairment), Christensen et al. (2014) demonstrated that using a speaker similarity metric to select the data to train the acoustic models improves ASR performance.",1 Introduction,[0],[0]
"Taking this idea into dialogue management, if a similarity metric is defined between different speakers, this metric can be used to select which data from the source speakers is used to train the model, and even to weight the influence of the data from each speaker in the model.",1 Introduction,[0],[0]
"As GP-RL is a non-parametric
12
method, a straightforward way to transfer knowledge is to directly initialise the GP model for the target speaker using data from source speakers, and update the GP with the data from the target speaker as this is gathered through interaction.",1 Introduction,[0],[0]
"But GP-RL soon becomes intractable as the data amount increases, limiting the amount of data that can be transferred.",1 Introduction,[0],[0]
"Gašić et al. (2013 a) proposes to transfer knowledge between domains by using the source data to train a prior GP, whose posterior is used as prior mean in the new GP.",1 Introduction,[0],[0]
"Another option is to use a GP approximation method (Quiñonero and Rasmussen, 2005) which permits data selection, use the speaker similarity metric to select the source data to initialise the policy, and then discard source data points as data points from the target speaker become available, keeping the number of data points up to a maximum.
",1 Introduction,[0],[0]
"This paper investigates knowledge transfer between speakers in the context of a spoken environmental control system personalised for speakers with dysarthria (Christensen et al., 2013), where the ASR is adapted as speaker specific data is gathered (Christensen et al., 2012), thus improving the ASR performance with usage.",1 Introduction,[0],[0]
The paper is organised as follows: Section 2 gives the background of GP-RL and defines the methods to select and weight the transferred data.,1 Introduction,[0],[0]
"Section 3 presents the experimental setup of the environmental control system and the different dysarthric simulated users, as well as the different features used to define the speaker similarities.",1 Introduction,[0],[0]
In Section 4 the results of the experiments are presented and explained and Section 5 concludes the paper.,1 Introduction,[0],[0]
"The objective of a POMDP based dialogue manager is to find the policy π(b) = a that maximizes the expected cumulative reward ci defined as the sum of immediate rewards from time step i until the dialogue is finished, where a ∈ A is the action taken by the manager, and the belief state b is a probability distribution over a discrete set of states S .",2 GPs for reinforcement learning,[0],[0]
"The Q-function defines the expected cumulative reward when the dialogue is in belief state bi and action ai is taken, following policy π:
Q(bi, ai) = Eπ[ci] ; where ci = N∑ n=i γn−irn (1)
where N is the time step at which the terminal action is taken (end of the dialogue), ri is the immediate reward given by the reward function, and
0 ≤",2 GPs for reinforcement learning,[0],[0]
"γ ≤ 1 is the discount factor, which weights future rewards.",2 GPs for reinforcement learning,[0],[0]
"If ci is considered to be a random variable, it can be modelled as a mean plus a residual, ci = Q(bi, ai) +",2 GPs for reinforcement learning,[0],[0]
"∆Q(bi, ai).",2 GPs for reinforcement learning,[0],[0]
"Then the immediate reward ri can be written recursively as the temporal difference (TD) between Q at time i and i+ 1:
ri = Q(bi, ai) + ∆Q(bi, ai) −γiQ(bi+1, ai+1)− γi∆Q(bi+1, ai+1)(2)
where γi = 0",2 GPs for reinforcement learning,[0],[0]
"if ai is a terminal action1, and the discount factor γ otherwise.",2 GPs for reinforcement learning,[0],[0]
"Given a set of observed belief-action points (bi, ai), with their respective ri values, the set of linear equations can be represented in matrix form as:
rt−1 = Htqt + Ht∆qt (3)
where qt=[Q(b1, a1), Q(b2, a2), ..., Q(bt, at)]",2 GPs for reinforcement learning,[0],[0]
">, ∆qt=[∆Q(b1, a1),∆Q(b2, a2), ...,∆Q(bt, at)]",2 GPs for reinforcement learning,[0],[0]
"> , rt−1 = [r1, r2, ..., rt−1]> and
Ht =  1 −γ1 . . .",2 GPs for reinforcement learning,[0],[0]
0 0 0 1 . . .,2 GPs for reinforcement learning,[0],[0]
0 0 ... . . .,2 GPs for reinforcement learning,[0],[0]
. .,2 GPs for reinforcement learning,[0],[0]
.,2 GPs for reinforcement learning,[0],[0]
"...
... 0 0 . . .",2 GPs for reinforcement learning,[0],[0]
1 −γt−1  ,2 GPs for reinforcement learning,[0],[0]
"If the random variables qt are assumed to have a joint Gaussian distribution with zero mean and ∆Q(bi, ai) ∼ N (0, σ2), the system can be modelled as a GP (Rasmussen and Williams, 2005), with the covariance matrix determined by a kernel function defined independently over the belief and the action space (Engel et al., 2005):
ki,j = k((bi, ai), (bj , aj))",2 GPs for reinforcement learning,[0],[0]
"= kb(bi,bj)ka(ai, aj) (4) To simplify the notation, from now on xi = (bi, ai) will be defined as each belief-action point, and KY,Y ′",2 GPs for reinforcement learning,[0],[0]
"as the matrix of size |Y| × |Y′| whose elements are computed by the kernel function (eq. 4) between any set of points Y and Y′. For a new belief-action point x∗ = (b∗, a∗), the posterior of the expected cumulative reward can be computed:
Q(x∗)|Xt, rt−1 ∼ N (Q̄(x∗), Q̂(x∗))",2 GPs for reinforcement learning,[0],[0]
"Q̄(x∗) = K∗,XH>t (HtKX,XH > t + Σt)
",2 GPs for reinforcement learning,[0],[0]
"−1rt−1 Q̂(x∗) = k(x∗,x∗)
−K∗,XH>t (HtKX,XH>t + Σt)−1HtKX,∗ (5)
1As dialogue management is an episodic RL problem, the temporal difference relationship between 2 consecutive belief-action points only happens if the points belong to the same dialogue.
",2 GPs for reinforcement learning,[0],[0]
"where Xt is the set of size t of all the previously visited (bi, ai) points, ∗ denotes the set of size 1 composed by the new belief-action point to be evaluated and Σt = σ2HtH>t .",2 GPs for reinforcement learning,[0],[0]
Q̄ and,2 GPs for reinforcement learning,[0],[0]
"Q̂ represent the mean and the variance of Q respectively.
",2 GPs for reinforcement learning,[0],[0]
To further simplify the notation it is possible to redefine eq. 5 by defining a kernel in the temporal difference space instead of in the belief-action space.,2 GPs for reinforcement learning,[0],[0]
"If the set of belief-action points Xt is redefined2 as Zt where zi = (bi, ai,bi+1, ai+1), with bi+1 and ai+1 set to any default values if ai is a terminal action, a kernel function between 2 temporal difference points can be defined as:
ktdi,j = k td(zi, zj)
= ktd((bi, ai,bi+1, ai+1), (bj , aj ,bj+1, aj+1))",2 GPs for reinforcement learning,[0],[0]
"= (ki,j + γiγjki+1,j+1 − γiki+1,j − γjki,j+1)
(6) where ki,j is the kernel function in the beliefaction space (eq. 4) and γi = 0 and γj = 0",2 GPs for reinforcement learning,[0],[0]
"if ai and aj are terminal actions respectively, or the discount factor γ otherwise (as in eq. 2).",2 GPs for reinforcement learning,[0],[0]
"When ai is a terminal action, the value of ai+1 and bi+1 in zi is irrelevant, as it will be multiplied by γi = 0.",2 GPs for reinforcement learning,[0],[0]
"In the same way, when this kernel is used to compute the covariance vector between a new test point and the set Zt, as the new point x∗ = (b∗, a∗) lies in the belief-action space, it is redefined as z∗ = (b∗, a∗,b∗+1, a∗+1) with b∗+1 and a∗+1 set to default values.",2 GPs for reinforcement learning,[0],[0]
"Then, a∗ is considered a terminal action, so b∗+1 and a∗+1 won’t affect the value of ktdi∗ due to γ∗ = 0.",2 GPs for reinforcement learning,[0],[0]
"A more detailed derivation of the temporal difference kernel is given in appendix A. Using the temporal difference kernel defined in eq. 6, eq. 5 can be rewritten as:
Q(z∗)|Zt, rt−1 ∼ N (Q̄(z∗), Q̂(z∗))",2 GPs for reinforcement learning,[0],[0]
Q̄(z∗),2 GPs for reinforcement learning,[0],[0]
"= Ktd∗,Z(K td Z,Z + Σt)
−1rt−1 Q̂(z∗) =",2 GPs for reinforcement learning,[0],[0]
"ktd(z∗, z∗)−Ktd∗,Z(KtdZ,Z + Σt)−1KtdZ,∗ (7) where KtdY,Y ′ is the covariance matrix computed with the temporal difference kernel between any set of TD points Y and Y′. With this notation, the shape of the equation for the posterior of Q is equivalent to classic GP regression models.",2 GPs for reinforcement learning,[0],[0]
"Thus, it is straightforward to apply a wide range of well studied GP techniques, such as sparse methods.",2 GPs for reinforcement learning,[0],[0]
"Redefining the belief-action set of points Xt as the set of temporal difference points Zt also simplifies the selection of data points (e.g. to select inducing
2Take into account that |Zt| = |Xt| − 1
points in sparse models), because the dependency between consecutive points is well defined.
",2 GPs for reinforcement learning,[0],[0]
"The GP literature proposes various sparse methods which select a subset of inducing points U of size m < t from the set of training points Z (Quiñonero and Rasmussen, 2005).",2 GPs for reinforcement learning,[0],[0]
In this paper the deterministic training conditional (DTC) method is used.,2 GPs for reinforcement learning,[0],[0]
"Once the subset of points has been selected and assuming ∆Q(bi, ai)",2 GPs for reinforcement learning,[0],[0]
"− γi∆Q(bi+1, ai+1) ∼ N (0, σ2) as in (Engel et al., 2003), the GP posterior can be approximated in O(t ·m2) with the DTC method as: Qdtc(z∗)|Zt, rt−1 ∼ N (Q̄dtc(z∗), Q̂dtc(z∗))",2 GPs for reinforcement learning,[0],[0]
"Q̄dtc(z∗) = σ−2Ktd∗,UΛK td U,Zrt−1
Q̂dtc(z∗) = ktd(z∗, z∗)−Φ + Ktd∗,UΛKtdU,∗ (8)
where Λ = (σ−2KtdU,ZK td Z,U +K td U,U ) −1",2 GPs for reinforcement learning,[0],[0]
"and Φ = Ktd∗,U (K td U,U )
−1KtdU,∗.",2 GPs for reinforcement learning,[0],[0]
"Once the posterior for any new belief-action point can be computed with eq. 7 or eq. 8, the policy π(b) = a can be computed as the action a that maximizes the Q-function from the current belief state b∗, but in order to avoid getting stuck in a local optimum, an exploration-exploitation approach should be taken.",2 GPs for reinforcement learning,[0],[0]
"One of the advantages of GPs is that they compute the uncertainty of the expected cumulative reward in form of a variance, which can be used as a metric for active exploration (Geist and Pietquin, 2011) to speed up the learning of the policy with an -greedy approach:
π(b∗) = { arg max a∈A Q̄(b∗, a) with prob.",2 GPs for reinforcement learning,[0],[0]
"(1− )
arg max a∈A Q̂(b∗, a) with prob.
(9) where controls the exploration rate.",2 GPs for reinforcement learning,[0],[0]
"The policy optimization loop is performed following the Episodic GP-Sarsa algorithm defined by (Gašić and Young, 2014).",2 GPs for reinforcement learning,[0],[0]
"The scenario where a statistical model for a specific “target” task must be trained, but only data from different but related “source” tasks is available, is known as transfer learning (Pan and Yang, 2010).",2.1 Transfer learning with GP-RL,[0],[0]
"In the context of this paper the different tasks will be dialogues with different speakers, and three points of transfer learning will be addressed:
• How to transfer the knowledge
•",2.1 Transfer learning with GP-RL,[0],[0]
"In the case of multiple source speakers, which data to transfer, and
• How to weight data from different sources.
",2.1 Transfer learning with GP-RL,[0],[0]
"In the context of reinforcement learning (Taylor and Stone, 2009) and dialogue policy optimization (Gašić et al., 2013 a), transfer learning has been shown to increase the performance of the system in the initial stages of use and to speed up the policy learning, requiring a smaller amount of target data to reach the optimal policy.",2.1 Transfer learning with GP-RL,[0],[0]
The most straightforward way to transfer the data in GP-RL is to initialise the set of temporal difference points,2.1.1 Knowledge transfer,[0],[0]
Zt of the GP with the source points and then continue updating it with target data points as they are gathered through interaction.,2.1.1 Knowledge transfer,[0],[0]
"However, this approach has a few shortcomings.",2.1.1 Knowledge transfer,[0],[0]
"First, as GP-RLs complexity increases with the number of data points, the model might quickly become intractable if it is initialised with too many source points.",2.1.1 Knowledge transfer,[0],[0]
"Also, when data points from the target speaker are gathered through interaction, the source points may not improve the performance of the system, while increasing the model complexity.",2.1.1 Knowledge transfer,[0],[0]
"Second, as the computation of the variance for a new point depends on the number of close points already visited, the variance of the new belief-action points will be reduced by the effect of the source points close in the belief-action space.",2.1.1 Knowledge transfer,[0],[0]
"If the distribution of the source data points is unbalanced, the effectiveness of the policy of eq. 9 will be affected.",2.1.1 Knowledge transfer,[0],[0]
Gašić,2.1.1 Knowledge transfer,[0],[0]
"et al. (2013 a) proposes to use the source points to train a prior GP, and use its posterior as mean function for the GP trained with the target points.",2.1.1 Knowledge transfer,[0],[0]
"With this approach, the mean of the posterior in eq. 7 will be modified as:
Q̄(z∗)",2.1.1 Knowledge transfer,[0],[0]
=,2.1.1 Knowledge transfer,[0],[0]
"m(z∗)+Ktd∗,Z(K td Z,Z+Σ)",2.1.1 Knowledge transfer,[0],[0]
−1(rt−1−mt) (10) where m(z∗) is the mean of the posterior of the Q-function given by the prior GP and mt =,2.1.1 Knowledge transfer,[0],[0]
"[m(z0), ...,m(zt)]",2.1.1 Knowledge transfer,[0],[0]
>.,2.1.1 Knowledge transfer,[0],[0]
"If the DTC approach (eq. 8) is taken, the posterior Q-function mean becomes:
Q̄dtc(z∗) =",2.1.1 Knowledge transfer,[0],[0]
"m(z∗)+σ−2Ktd∗,UΛK td U,Z(rt−1−mt)
(11)",2.1.1 Knowledge transfer,[0],[0]
"This approach has the advantage of being computationally cheaper than the former method while modelling the uncertainty for new target points more accurately, but at the cost of not taking into account the correlation between source and target points, which might reduce the performance when there is a small amount of target data.
",2.1.1 Knowledge transfer,[0],[0]
"A third approach combines the two previous methods, using a portion of the transfer points to train a GP for the prior mean function, while the rest is used to initialise the set Zt of the GP that will be updated with target points.",2.1.1 Knowledge transfer,[0],[0]
This method will be computationally cheaper than the first one while increasing the performance of the second method with a small amount of target data.,2.1.1 Knowledge transfer,[0],[0]
"As non-parametric models, the complexity of GPs will increase with the number of data points, limiting the amount of source data that can be transferred.",2.1.2 Transfer data selection,[0],[0]
"Additionally, if the points come from multiple sources, it is possible that the data distribution from some sources is more similar to the target speaker than others, hence transferring data from these sources will increase performance.",2.1.2 Transfer data selection,[0],[0]
"We propose to extract a speaker feature vector s from each speaker and define a similarity function f(s, s′) between speakers (see sec. 3.4).",2.1.2 Transfer data selection,[0],[0]
"The data can be selected by choosing the points from the source speakers more similar to the target.
",2.1.2 Transfer data selection,[0],[0]
"With the DTC approach (eq. 8), a subset of inducing points Um must be selected.",2.1.2 Transfer data selection,[0],[0]
The most straightforward way is to select the most similar points to the speaker from the transferred points.,2.1.2 Transfer data selection,[0],[0]
"As the user interacts with the system and target data points are gathered, these points may be used as inducing points.",2.1.2 Transfer data selection,[0],[0]
"This approach acts like another layer of data selection; the reduced complexity will allow for the transfer of more source points, while using the target points as inducing points will mean that only the source points that lie in the same part of the belief-action space as the target points have influence on the model.",2.1.2 Transfer data selection,[0],[0]
"When transferring data from multiple sources, the similarity between each source and the target speaker might be different.",2.1.3 Transfer data weighting,[0],[0]
Thus the data from a source more similar to the target should have more influence in the model than less similar ones.,2.1.3 Transfer data weighting,[0],[0]
"As a GP is defined by computing covariances between data points through a kernel function, one way to weight the data from different sources is to extend the belief-action vector used to compute the covariance with the speaker feature vector s explained in the previous section as xi = (bi, ai, si), and then extend the kernel (eq. 4) by multiplying it by a new kernel in the speaker space ks as:
kexti,j = k((bi, ai, si), (bj , aj , sj))
",2.1.3 Transfer data weighting,[0],[0]
"= kb(bi,bj)ka(ai, aj)ks(si, sj) (12)
",2.1.3 Transfer data weighting,[0],[0]
"By adding this extra space to the data points, the covariance between points will not only depend on the similarity between points in the belief-action space, but also in the speaker space, reducing the covariance between two points that lie in different parts of the speaker space.",2.1.3 Transfer data weighting,[0],[0]
This approach will also help to partially deal with the variance computing problem of the first model in sec.,2.1.3 Transfer data weighting,[0],[0]
"2.1.1, as the source points will lie on a different part of the speaker space than the new target points, thus having less influence in the variance computation.",2.1.3 Transfer data weighting,[0],[0]
"3 Experimental setup To test the system in a scenario with high variability between the dynamics of the speakers, the experiments are performed within the context of a voice-enabled control system designed to help speakers with dysarthria to interact with their home devices (TV, radio, lamps...), where the speakers have different severities of dysarthria (this is an instance of the homeService application (Christensen et al., 2013)).",2.1.3 Transfer data weighting,[0],[0]
"The system has a vocabulary of 36 commands and is organised in a tree setup where each node in the tree represents either a device (e.g. “TV”), a property of that device (e.g. “channel”), or actions that trigger some change in one of the devices (e.g. “one”, child of “channel”, will change the TV to channel one).",2.1.3 Transfer data weighting,[0],[0]
"When the system transitions to one of the terminal nodes that trigger an action, the action associated with this node is performed, and subsequently the system returns to the root node.",2.1.3 Transfer data weighting,[0],[0]
In the following experiments a dialogue will be considered finished when one of the terminal node actions is carried out.,2.1.3 Transfer data weighting,[0],[0]
"In the non-terminal nodes, the user may either speak one of the commands available in that node (defined by its children nodes) to transition to them, or say the meta-command “back” to return to its parent node.",2.1.3 Transfer data weighting,[0],[0]
"The ASR is configured to recognise single words, so there is no need for a language understanding system, as the concepts are just a direct mapping from the ASR output.",2.1.3 Transfer data weighting,[0],[0]
"A more detailed explanation of the system is given in (Casanueva et al., 2014) and two example dialogues are presented in Appendix B.",2.1.3 Transfer data weighting,[0],[0]
"In the homeService application, each system is personalised for a single speaker by adapting the
ASR system’s acoustic model as more data is gathered through interaction, thus increasing the accuracy of the ASR over time.",3.1 Simulated dysarthric users,[0],[0]
"In the following experiments, the system is tested by interacting with a set of simulated users with dysarthria, where each user interacts with a set of different ASR simulators, arising from the different amounts of data used to adapt the ASR.",3.1 Simulated dysarthric users,[0],[0]
"To train the ASR simulator for these users, data from a dysarthric speech database (UASpeech database (Kim et al., 2008)) has been used.",3.1 Simulated dysarthric users,[0],[0]
"Table 1 shows the characteristics of the 15 speakers of the database, and the ASR accuracy for each speaker in the 36 word vocabulary of the system without adaptation and adapted with 500 words from that speaker.",3.1 Simulated dysarthric users,[0],[0]
"Additionally, an intelligibility measure assessment is presented for each speaker as the percentage of words spoken by each speaker which are understood by unfamiliar speakers; these are shown in the second column in table 1.
",3.1 Simulated dysarthric users,[0],[0]
The system is tested with 6 different simulated users trained with data from low and medium intelligibility3 speakers.,3.1 Simulated dysarthric users,[0],[0]
"Each user interacts with 4 different ASRs, adapted with 0, 150, 300 and 500 words respectively.",3.1 Simulated dysarthric users,[0],[0]
"For a more detailed explanation of the simulated users configuration, the reader may refer to (Casanueva et al., 2014).",3.1 Simulated dysarthric users,[0],[0]
"Each non-terminal node in the tree is modelled as an independent POMDP where the state set S is the set of possible goals of the node and the action setA is the set of actions associated with each goal plus an “ask” action, which requests the user to repeat his last command.",3.2 POMDP setup,[0],[0]
"The reward function for all the POMDPs is -1 for the “ask” action, and +10 for each other action if it corresponds to the user goal, or -10 otherwise, and γ = 0.95.",3.2 POMDP setup,[0],[0]
"The state tracker is a logistic regression classifier (Pedregosa et al., 2011), where classes are the set of states",3.2 POMDP setup,[0],[0]
S.,3.2 POMDP setup,[0],[0]
The belief state b is computed as the posterior over the states given the last 5 observations (N-best lists with normalised confidence scores).,3.2 POMDP setup,[0],[0]
"For each speaker, the state tracker has been trained with data from the other 14 speakers.
",3.2 POMDP setup,[0],[0]
"3In (Casanueva et al., 2014)",3.2 POMDP setup,[0],[0]
"it was shown that, with a 36 command setup, statistical DM is most useful for low and medium intelligibility speakers.",3.2 POMDP setup,[0],[0]
"For high intelligibility speakers, the ASR accuracy is close to 100% so the improvement obtained from DM is small, and for very low intelligibility speakers, the absolute performance is not high enough to make the system useful.",3.2 POMDP setup,[0],[0]
The DTC approach (eq. 8) is used to compute the Q-function for the policy (eq. 9) with Gaussian noise variance σ2 = 5.,3.3 Policy models,[0],[0]
"The kernel over the belief space is a radial basis function kernel (RBF):
kb(bi,bj) = σ2k exp ( − ||bi − bj || 2
2l2k
) (13)
with variance σ2k = 25 and lengthscale l 2 k = 0.5.",3.3 Policy models,[0],[0]
"The delta kernel is used over the action space:
ka(ai, aj) = δ(ai, aj) =",3.3 Policy models,[0],[0]
"{
1 if ai = aj 0",3.3 Policy models,[0],[0]
"otherwise
(14)
and the kernels over the speaker space are defined in section 3.4.",3.3 Policy models,[0],[0]
The size of the inducing set Um is 500 and the maximum size of the TD points set Zt is 2000.,3.3 Policy models,[0],[0]
"Whenever a new data point is observed from the target speaker, it is added to the set of inducing points Um, and the first point of the set Um (which, due to the ordering done by data selection, corresponds to the least similar source point or to the oldest target point) is discarded from the inducing set.",3.3 Policy models,[0],[0]
"Whenever a new data point is observed and the size of the set of temporal difference points |Zt| = 2000, the first point of this set is discarded.",3.3 Policy models,[0],[0]
"Three variations of the DTC approach are used:
• DTC:",3.3 Policy models,[0],[0]
"Equation 8 is used to compute the Q posterior for the policy (eq. 9) and the set of temporal difference points Zt is initialised with the source points.
",3.3 Policy models,[0],[0]
"• Prior: Equation 11 is used to compute the Q posterior for the policy (eq. 9) and the prior GP is trained with the source points.
",3.3 Policy models,[0],[0]
•,3.3 Policy models,[0],[0]
Hybrid:,3.3 Policy models,[0],[0]
"Equation 11 is used to compute the Q posterior for the policy (eq. 9), the prior GP is trained with half of the source points and the set of temporal difference points Zt is initialised with the other half.",3.3 Policy models,[0],[0]
To compute the similarities between speakers a vector of speaker features s must be extracted.,3.4 Speaker similarities,[0],[0]
"Different kinds of features may be extracted, such
as meta-data based features, acoustic features, features related to the ASR performance, etc.",3.4 Speaker similarities,[0],[0]
"In this paper, we explore 3 different methods to extract s;
• Intelligibility assessment: The intelligibility assessment for each speaker in the UASpeech database (table 1) can be used as a single dimensional feature.
",3.4 Speaker similarities,[0],[0]
"• I-vectors: Martı́nez et al. (2013) showed that i-vectors (Dehak et al., 2011) can be used to predict the intelligibility of a dysarthric speaker.",3.4 Speaker similarities,[0],[0]
"For each speaker, s is defined as a 400 dimensional vector corresponding to the mean i-vector extracted from each utterance from that speaker.",3.4 Speaker similarities,[0],[0]
"For more information on the i-vector extraction and characteristics, refer to (Martı́nez et al., 2014).
",3.4 Speaker similarities,[0],[0]
• ASR accuracy:,3.4 Speaker similarities,[0],[0]
The performance statistics of the ASR (e.g. accuracy) can be used as speaker features.,3.4 Speaker similarities,[0],[0]
"In this paper we use the accuracy per word (command), defining s as a 36 dimensional vector where each element is the ASR accuracy for each of the 36 commands.
",3.4 Speaker similarities,[0],[0]
"The kernel over the speaker space ks (eq. 12), is defined as an RBF kernel (eq. 13).",3.4 Speaker similarities,[0],[0]
"This kernel is used both to compute the similarity between speakers in order to select data (section 2.1.2), and to weight the data from each source speaker (section 2.1.3).",3.4 Speaker similarities,[0],[0]
ks has variance σ2k = 1 and the lengthscale l2k varies depending on the features.,3.4 Speaker similarities,[0],[0]
"For intelligibility features l2k = 0.5, for i-vectors l2k = 8.0 and for ASR accuracy features",3.4 Speaker similarities,[0],[0]
l 2 k = 4.0,3.4 Speaker similarities,[0],[0]
"In the following experiments the reward is computed as -1 for each dialogue turn, +20 if the dialogue was successful4.",4 Results,[0],[0]
"The system has been tested
4Because of the variable depth tree structure of the spoken dialogue system, the sum or average of cumulative rewards obtained in each sub-dialogue is not a good measure of the overall system performance.",4 Results,[0],[0]
"If the dialogue gets stuck in a loop going back and forth between two sub-dialogues, the extra amount of turns spent in this loop would not be reflected in the average of rewards
with the 24 speaker-ASR pairs explained in section 3.1, and in the following figures, each plotted line is the average results for these 24 speakerASR pairs.",4 Results,[0],[0]
"As the behaviour of the simulated user and some data selection methods partially depend on random variables, each experiment has been initialised with four different seeds and all the results presented are the average of the four seeds tested over 500 dialogues.",4 Results,[0],[0]
"In all the experiments the data to initialise each POMDP is transferred from a pool of 4200 points corresponding to 300 points from each speaker in table 1 except the speaker being tested, where each data pool is different for each seed.
",4 Results,[0],[0]
Figure 1 compares the different policy models presented in section 3.3 using the intelligibility measure based similarity to select and weight the data.,4 Results,[0],[0]
The dotted line named DTC-conv shows the performance of the DTC policy when trained until convergence with the target speaker by simulating 1200 sub-dialogues in each node.,4 Results,[0],[0]
DTC-1000 and DTC-2000 show the performance of the basic DTC approach when 1000 and 2000 source points are transferred respectively.,4 Results,[0],[0]
"It can be observed that, transferring more points boosts the performance, but at the cost of increasing the complexity.",4 Results,[0],[0]
pri-1000 and pri-2000 show the performance of the prior policy with 1000 and 2000 transfer points respectively.,4 Results,[0],[0]
The success rate is above the DTC policy but the learning rate for the reward is slower.,4 Results,[0],[0]
This might be because the small amount of target data points make the predictions of the Q-function given by the GP unreliable.,4 Results,[0],[0]
"Hyb-1000 and hyb-2000 show the performance of the hybrid model, showing the best behaviour on success rate after 100 dialogues, and for hyb-2000 even outperforming DTC-2000 in reward after 400 dialogues.
",4 Results,[0],[0]
"In figure 2 the different approaches to compute the speaker similarities for data selection
and weighting presented in section 3.4 are compared, using the DTC model with 1000 transfer points (named DTC-1000 in the previous figure).",4 Results,[0],[0]
"DTC-int uses the intelligibility measure based features, DTC-iv the i-vector features and DTC-acc the ASR accuracy based features.",4 Results,[0],[0]
"DTC-iv outperforms the other two features, followed closely by DTC-acc.",4 Results,[0],[0]
"The performance of DTC-int is way below the other two metrics, suggesting that the information given by intelligibility assessments is a weak feature for source speaker selection (as it is done by humans, it might be very noisy).",4 Results,[0],[0]
"As DTC-acc uses information about the ASR statistics (which is the input for the dialogue manager), it might be expected that it will outperform the rest, but in this case a purely acoustic based measure such as the DTC-iv works better.",4 Results,[0],[0]
"The reason for this might be that these features are not correlated to the ASR performance, so hidden variables are used to better organise the data.",4 Results,[0],[0]
"To investigate the usefulness of similarity based data selection, two different data selection methods which do not weight the transferred data have been tried.",4 Results,[0],[0]
"DTC-randspk selects the ordering of the speakers from whom the data is transferred at random, and has a much worse performance than the similarity based method, but DTC-allspk selects the 1000 source points from all the speakers, selecting 1000 points at random from the pool of 4200 points and, as it can be seen, the reward obtained by this method is slightly better than with DTC-iv, even if the success rate is lower.",4 Results,[0],[0]
"This suggests that transferring points from more speakers rather than from just the closest ones is a better strategy, probably because points selected by this method are distributed more uniformly over the belief-action space.",4 Results,[0],[0]
"A method which does a trade-off between filling the belief-action space while selecting the most similar points could be a better option.
",4 Results,[0],[0]
"To further investigate the effect of selection and weighting of the data, figure 3 plots the results for the DTC policy model using the i-vector based similarity to weight the data but different data selection methods.",4 Results,[0],[0]
"iv-clo selects the closest speakers with respect to the i-vector metric, iv-randspk orders the speakers at random, and iv-allspk selects the 1000 transfer points from all the speakers but the tested one.",4 Results,[0],[0]
"As in the previous figure, selecting speakers by similarity works better than selecting speakers at random, but selecting the points from all the speakers and weighting them with the ivector metric outperforms all the previous meth-
ods.",4 Results,[0],[0]
"This might be because weighting the data does a kind of data selection, as the data points from source speakers closer to the target will have more influence than the further ones, while transferring points from all the speakers covers a bigger part of the belief-action space.",4 Results,[0],[0]
"acc-allspk and allspk-uw show the results of weighting the data with the ASR accuracy metric and not weighting the data respectively, when selecting the data from all speakers.",4 Results,[0],[0]
"The accuracy metric performs worse than the i-vector metric once again, but it still outperforms not weighting the data, suggesting that data weighting works for different metrics.",4 Results,[0],[0]
Finally iv-allspk-hyb plots the performance of the hybrid model when selecting the data from all the speakers and weighting it with the i-vector based similarity.,4 Results,[0],[0]
"Even if it is computationally cheaper, it outperforms iv-allspk after 100 dialogues, suggesting that with a good similarity metric and data selection method, the hybrid model in section 3.3 is the best option to take.",4 Results,[0],[0]
"When transferring knowledge between speakers in a GP-RL based policy, weighting the data by using a similarity metric between speakers, and to a lesser extent, selecting the data using this similarity, improves the performance of the dialogue manager.",5 Conclusions,[0],[0]
"By defining a kernel between temporal difference points and interpreting the Q-function as a GP regression problem where data points are in the TD space, sparse methods that allow the selection of the subset of inducing points such as DTC can be applied.",5 Conclusions,[0],[0]
"In a transfer learning scenario, DTC permits a larger number of data points to be transferred and the selection of points collected from the target speaker as inducing points.
",5 Conclusions,[0],[0]
"We showed that using part of the transferred data to train a prior GP for the mean function,
and the rest to initialize the set of points of the GP, improves the performance of each of these approaches.",5 Conclusions,[0],[0]
"Transferring data points from a larger number of speakers outperformed selecting the data points only from the more similar ones, probably because the belief-action space is covered better.",5 Conclusions,[0],[0]
This suggests that more complex data selection algorithms that trade-off between selecting the data points by similarity and covering more uniformly the belief-action space should be used.,5 Conclusions,[0],[0]
"Also, increasing the amount of data transferred increased the performance, but the complexity increase of GP-RL limits the amount of data that can be transferred.",5 Conclusions,[0],[0]
"More computationally efficient ways to transfer the data could be studied.
",5 Conclusions,[0],[0]
"Of the three metrics based on speaker features tested (speaker intelligibility, i-vectors and ASR accuracy), i-vectors outperformed the rest.",5 Conclusions,[0],[0]
This suggest that i-vectors are a potentially good feature for speaker specific dialogue management and could be used in other tasks such as state tracking.,5 Conclusions,[0],[0]
"ASR accuracy based metrics also outperformed the intelligibility based one, and as ASR accuracy and i-vector are uncorrelated features, a combination of them could give further improvement.
",5 Conclusions,[0],[0]
"Finally, as the models were tested with simulated users in a hierarchically structured dialogue system (following the structure of the homeService application), future work directions include evaluating the policy models in a mixed initiative dialogue system and testing them with real users.",5 Conclusions,[0],[0]
The research leading to these results was supported by the University of Sheffield studentship network PIPIN and EPSRC Programme Grant EP/I031022/1 (Natural Speech Technology).,Acknowledgements,[0],[0]
The authors would like to thank David Martı́nez for providing the i-vectors used in this paper.,Acknowledgements,[0],[0]
"In equation 5, a linear transformation from the belief-action space to the temporal difference space is applied to the to the covariance vector K∗,X and to the covariance matrix KX,X by multiplying them by the matrix Ht.",Appendix A. Temporal difference kernel,[0],[0]
"Deriving the term HtKX,XH>t we obtain the matrix in eq. 15 (page bottom), where ki,j is the kernel function between two belief-action points xi = (bi, ai) and xj = (bj , aj), defined in eq. 4.",Appendix A. Temporal difference kernel,[0],[0]
"The transformed matrix (eq. 15) has the form of a covariance matrix where each element is a sum of kernel functions ki,j between belief-action points on time i or i + 1 weighted by the discount factors.",Appendix A. Temporal difference kernel,[0],[0]
"So each element of this matrix can be defined as a function of 2 temporal differences between belief-action points (TD points),",Appendix A. Temporal difference kernel,[0],[0]
"zi = (bi, ai,bi+1, ai+1) and zj = (bj , aj ,bj+1, aj+1) in the form of (eq. 6):
ktdi,j = (ki,j + γiγjki+1,j+1− γiki+1,j − γjki,j+1) (16) where γi and γj will be 0 if ai and aj are terminal actions respectively.",Appendix A. Temporal difference kernel,[0],[0]
"Deriving the term K∗,XH>t (and HtKX,∗)",Appendix A. Temporal difference kernel,[0],[0]
"we obtain:
K∗,XH>t =[ (k1,∗
−γ1k2,∗) (k2,∗ −γ2k3,∗) . . .",Appendix A. Temporal difference kernel,[0],[0]
"(kt−1,∗ −γt−1kt,∗) ] (17)
which is a vector with ktdi,∗ = (ki,∗ − γiki+1,∗) for each term.",Appendix A. Temporal difference kernel,[0],[0]
"This is equivalent to equation 16 if the action of the new point a∗ is considered a terminal action, thus γ∗ = 0.",Appendix A. Temporal difference kernel,[0],[0]
"Then, redefining the set of belief-action points Xt as the set of beliefaction temporal difference points denoted as Zt, and defining Ktd as the covariance matrix computed with the kernel function between two temporal difference points (eq. 6), eq. 7 can be derived from eq. 5 by doing the following substitutions: K∗,XH>t = Ktd∗,Z , HtKX,∗ = K td Z,∗ and HtKX,XH>t = KtdZ,Z .",Appendix A. Temporal difference kernel,[0],[0]
"For a more detailed description of the hierarchical structure of the homeService environment, this appendix presents two example dialogues between an user and the system.",Appendix B. Example homeService dialogues,[0],[0]
"The second column represents the actions taken either by the user (commands) or by the system (actions)
",Appendix B. Example homeService dialogues,[0],[0]
"Dialogue 1: Goal = {TV, Channel, One} Dialogue starts in node “Devices” Sub-dialogue “Devices”
User TV ( Speaks the command “TV”) System Ask (Requests to repeat last command) User TV (Repeats his last command) System TV (Dialogue transitions to node “TV”)
",Appendix B. Example homeService dialogues,[0],[0]
Sub-dialogue “TV” User Chan.,Appendix B. Example homeService dialogues,[0],[0]
(Command “Channel”) System Chan.,Appendix B. Example homeService dialogues,[0],[0]
"(Transitions to node “Channel”)
",Appendix B. Example homeService dialogues,[0],[0]
Sub-dialogue “Channel” User One (Command “One”) System One (Performs action TV-Channel-One),Appendix B. Example homeService dialogues,[0],[0]
"As an action has been taken in a terminal node, the dialogue ends.
",Appendix B. Example homeService dialogues,[0],[0]
"Dialogue 2: Goal = {Hi-fi, On} Dialogue starts in node “Devices” Sub-dialogue “Devices”
User Hi-fi (Command “Hi-fi”) System Light (transitions to node Light)
",Appendix B. Example homeService dialogues,[0],[0]
"Sub-dialogue “Light” User Back (Requests to go to previous node) System Back (transitions to node Devices)
Sub-dialogue “Devices” User Hi-fi (Command “Hi-fi”)",Appendix B. Example homeService dialogues,[0],[0]
"System Hi-fi (transitions to node Hi-fi)
Sub-dialogue “Hi-fi” User On (Command “On”) System Off (Performs action Hifi-Off)",Appendix B. Example homeService dialogues,[0],[0]
"As the action taken in the terminal node does not match the goal, it is a failed dialogue.",Appendix B. Example homeService dialogues,[0],[0]
"Model-free reinforcement learning has been shown to be a promising data driven approach for automatic dialogue policy optimization, but a relatively large amount of dialogue interactions is needed before the system reaches reasonable performance.",abstractText,[0],[0]
"Recently, Gaussian process based reinforcement learning methods have been shown to reduce the number of dialogues needed to reach optimal performance, and pre-training the policy with data gathered from different dialogue systems has further reduced this amount.",abstractText,[0],[0]
"Following this idea, a dialogue system designed for a single speaker can be initialised with data from other speakers, but if the dynamics of the speakers are very different the model will have a poor performance.",abstractText,[0],[0]
"When data gathered from different speakers is available, selecting the data from the most similar ones might improve the performance.",abstractText,[0],[0]
"We propose a method which automatically selects the data to transfer by defining a similarity measure between speakers, and uses this measure to weight the influence of the data from each speaker in the policy model.",abstractText,[0],[0]
The methods are tested by simulating users with different severities of dysarthria interacting with a voice enabled environmental control system.,abstractText,[0],[0]
Knowledge transfer between speakers for personalised dialogue management,title,[0],[0]
"Proceedings of NAACL-HLT 2013, pages 1206–1215, Atlanta, Georgia, 9–14 June 2013. c©2013 Association for Computational Linguistics",text,[0],[0]
"Despite morphological phenomena’s salience in most human languages, many NLP systems treat fully inflected forms as the atomic units of language.",1 Introduction,[0],[0]
"By assuming independence of lexical stems’ various surface forms, this avoidance approach exacerbates the problem of data sparseness.",1 Introduction,[0],[0]
"If it is employed at all, morphological analysis of text tends to be treated as a preprocessing step to other NLP modules.",1 Introduction,[0],[0]
"While this latter disambiguation approach helps address data sparsity concerns, it has substantial drawbacks: it requires supervised learning from expert-annotated corpora, and determining the optimal morphological granularity is labor-intensive (Habash and Sadat, 2006).
",1 Introduction,[0],[0]
"Neither approach fully exploits the finite-state transducer (FST) technology that has been so successful for modeling the mapping between surface
forms and their morphological analyses (Karttunen and Beesley, 2005), and the mature collections of high quality transducers that already exist for many languages (e.g., Turkish, Russian, Arabic).",1 Introduction,[0],[0]
"Much linguistic knowledge is encoded in such FSTs.
",1 Introduction,[0],[0]
"In this paper, we develop morphology-aware nonparametric Bayesian language models that bring together hand-written FSTs with statistical modeling and require no token-level annotation.",1 Introduction,[0],[0]
The sparsity issue discussed above is addressed by hierarchical priors that share statistical strength across different inflections of the same stem by backing off to word formation models that piece together morphemes using FSTs.,1 Introduction,[0],[0]
"Furthermore, because of the nonparametric formulation of our models, the regular morphological patterns found in the long tail of word types will rely more heavily on deeper analysis, while frequent and idiosyncratically behaved forms are modeled opaquely.
",1 Introduction,[0],[0]
"Our prior can be used in virtually any generative model of language as a replacement for multinomial distributions over words, bringing morphological awareness to numerous applications.",1 Introduction,[0],[0]
"For various morphologically rich languages, we show that:
• our model can provide rudimentary unsupervised disambiguation for a highly ambiguous analyzer;
• integrating morphology into n-gram language models allows better generalization to unseen words and can improve the performance of applications that are truly open vocabulary; and
• bilingual word alignment models also benefit greatly from sharing translation information
1206
across stems.
",1 Introduction,[0],[0]
"We are particularly interested in low-resource scenarios, where one has to make the most of the small quantity of available data, and overcoming data sparseness is crucial.",1 Introduction,[0],[0]
"If analyzers exist in such settings, they tend to be highly ambiguous, and annotated data for learning to disambiguate are also likely to be scarce or non-existent.",1 Introduction,[0],[0]
"Therefore, in our experiments with Russian, we compare two analyzers: a rapidly-developed guesser, which models regular inflectional paradigms but contains no lexicon or irregular forms, and a high-quality analyzer.",1 Introduction,[0],[0]
"In this section, we describe a generative model of word formation based on Pitman-Yor processes that generates word types using a finite-state morphological generator.",2 Word Models with Morphology,[0],[0]
"At a high level, the process first produces lexicons of stems and inflectional patterns; then it generates a lexicon of inflected forms using the finite-state generator.",2 Word Models with Morphology,[0],[0]
"Finally, the inflected forms are used to generate observed data.",2 Word Models with Morphology,[0],[0]
"Different independence assumptions can be made at each of these levels to encode beliefs about where stems, inflections, and surface forms should share statistical strength.",2 Word Models with Morphology,[0],[0]
"Our work relies extensively on Pitman-Yor processes, which provide a flexible framework for expressing backoff and interpolation relationships and extending standard models with richer word distributions (Pitman and Yor, 1997).",2.1 Pitman-Yor Processes,[0],[0]
"They have been shown to match the performance of state-of-the-art language models and to give estimates that follow appropriate power laws (Teh, 2006).
",2.1 Pitman-Yor Processes,[0],[0]
"A draw from a Pitman-Yor process (PYP), denoted G ∼ PY(d, θ,G0), is a discrete distribution over a (possibly infinite) set of events, which we denote abstractly E .",2.1 Pitman-Yor Processes,[0],[0]
The process is parameterized by a discount parameter 0 ≤,2.1 Pitman-Yor Processes,[0],[0]
"d < 1, a strength parameter θ > −d, and a base distribution G0 over the event space E .
",2.1 Pitman-Yor Processes,[0],[0]
"In this work, our focus is on the base distribution G0.",2.1 Pitman-Yor Processes,[0],[0]
"We place vague priors on the hyperparameters d ∼ U([0, 1]) and (θ + d) ∼ Gamma(1, 1).",2.1 Pitman-Yor Processes,[0],[0]
Inference in PYPs is discussed below.,2.1 Pitman-Yor Processes,[0],[0]
The most basic expression of our model is a unigram model of text.,2.2 Unigram Morphology Model,[0],[0]
"So far, we only assume that each word can be analyzed into a stem and a sequence of morphemes forming an inflection pattern.",2.2 Unigram Morphology Model,[0],[0]
"LetGs be a distribution over stems,Gp be a distribution over inflectional patterns, and let GENERATE be a deterministic mapping from 〈stem, pattern〉 pairs to inflected word forms.1 An inflected word type is generated with the following process, which we designate MP(Gs, Gd,GENERATE):
stem ∼ Gs pattern ∼ Gp
word = GENERATE(stem, pattern)
",2.2 Unigram Morphology Model,[0],[0]
"For example, in Russian, we might sample stem = прочий,2 pattern = STEM+Adj+Pl+Dat, and obtain word = прочим.
",2.2 Unigram Morphology Model,[0],[0]
This model could be used directly to generate observed tokens.,2.2 Unigram Morphology Model,[0],[0]
"However, we have said nothing about Gs and Gp, and the assumption that stems and patterns are independent is clearly unsatisfying.",2.2 Unigram Morphology Model,[0],[0]
"We therefore assume that both the stem and the pattern distributions are generated from PY processes, and that MP(Gs, Gp,GENERATE) is itself the base distribution of a PYP.
",2.2 Unigram Morphology Model,[0],[0]
"Gs ∼ PY(ds, θs, G0s) Gp ∼ PY(dp, θp, G0p)",2.2 Unigram Morphology Model,[0],[0]
"Gw ∼ PY(d, θ,MP(Gs, Gp,GENERATE))
",2.2 Unigram Morphology Model,[0],[0]
"A draw Gw from this PYP is a unigram distribution over tokens.
",2.2 Unigram Morphology Model,[0],[0]
"2.3 Base Stem Model G0s In general there are an unbounded number of stems possible in any language, so we set G0s to be character trigram model, which we statically estimate, with Kneser-Ney smoothing, from a large corpus of word types in the language being modeled.",2.2 Unigram Morphology Model,[0],[0]
"While using fixed parameters estimated to maximize likelihood is
1The assumption of determinism is only inappropriate in cases of inflectional spelling variants (e.g., modeled vs. modelled) or pronunciation variants (e.g., reduced forms in certain environments).
2прочий (pronounced [pr5tCij]) = other
questionable from the perspective of Bayesian learning, it is tremendously beneficial for computational reasons.",2.2 Unigram Morphology Model,[0],[0]
"For some applications (e.g., word alignment), the set of possible stems for a corpus S can be precomputed, so we will also experiment with using a uniform stem distribution based on this set.
",2.2 Unigram Morphology Model,[0],[0]
2.4 Base Pattern Model G0p,2.2 Unigram Morphology Model,[0],[0]
"Several choices are possible for the base pattern distribution:
MP0 We can assume a uniformG0p when the number of patterns is small.
",2.2 Unigram Morphology Model,[0],[0]
"MP1 To be able to generalize to new patterns, we can draw the length of the pattern from a Poisson distribution and generate morphemes one by one from a uniform distribution.
",2.2 Unigram Morphology Model,[0],[0]
"MP2 A more informative prior is a Markov chain of morphemes, where each morpheme is generated conditional on the preceding morpheme.
",2.2 Unigram Morphology Model,[0],[0]
"The choice of the base pattern distribution could depend on the complexity of the inflectional patterns produced by the morphological analyzer, reflecting the type of morphological phenomena present in a given language.",2.2 Unigram Morphology Model,[0],[0]
"For example, the number of possible patterns can practically be considered finite in Russian, but this assumption is not valid for languages with more extensive derivational morphology like Turkish.",2.2 Unigram Morphology Model,[0],[0]
"For most applications, rather than directly generating from a model using the processes outlined above, we seek to infer posterior distributions over latent parameters and structures, given a sample of data.
",2.5 Posterior Inference,[0],[0]
"Although there is no known analytic form of the PYP density, it is possible to marginalize the draws from it and to work directly with observations.",2.5 Posterior Inference,[0],[0]
"This marginalization produces the classical Chinese restaurant process representation (Teh, 2006).",2.5 Posterior Inference,[0],[0]
"When working with the morphology models we are proposing, we also need to marginalize the different latent forms (stems s and patterns p) that may have given rise to a given word",2.5 Posterior Inference,[0],[0]
"w. Thus, we require that the inverse relation of GENERATE is
available to compute the marginal base word distribution:
p(w | G0w) =",2.5 Posterior Inference,[0],[0]
"∑
GENERATE(s,p)=w
p(s | Gs) p(p",2.5 Posterior Inference,[0],[0]
"| Gp)
Since our approach encodes morphology using FSTs, which are invertible, this poses no problem.
",2.5 Posterior Inference,[0],[0]
"To illustrate, consider the Russian word прочим, which may be analyzed in several ways:
прочий +Adj +Sg +Neut +Instr прочий +Adj +Sg +Masc +Instr прочий +Adj +Pl +Dat
прочить +Verb +Pl +1P прочее +Pro +Sg +Ins
Because the set of possible analyses is in general small, marginalization is fast and complex",2.5 Posterior Inference,[0],[0]
"blocked sampling is not necessary.
",2.5 Posterior Inference,[0],[0]
"Finally, to infer hyperparameter values (d, θ, . . .)",2.5 Posterior Inference,[0],[0]
", a Metropolis-Hastings update is interleaved with Gibbs sampling steps for the rest of the hidden variables.3
Having described a model for generating words, we now show its usage in several contexts.",2.5 Posterior Inference,[0],[0]
"Given a rule-based morphological analyzer encoded as an unweighted FST and a corpus on which the analyzer has been run – possibly generating multiple analyses for each token – we can use our unigram model to learn a probabilistic model of disambiguation in an unsupervised setting (i.e., without annotated examples).",3 Unsupervised Morphological Disambiguation,[0],[0]
The corpus is assumed to be generated from the unigram distribution,3 Unsupervised Morphological Disambiguation,[0],[0]
"Gw, and the base stem model is set to a fixed character trigram",3 Unsupervised Morphological Disambiguation,[0],[0]
model.4,3 Unsupervised Morphological Disambiguation,[0],[0]
"After learning the parameters of the model, we can find for each word in the vocabulary its most likely analysis and use this as a crude disambiguation step.
",3 Unsupervised Morphological Disambiguation,[0],[0]
"3The proposal distribution for Metropolis-Hastings is a Beta distribution (d) or a Gamma distribution (θ+d) centered on the previous parameter values.
",3 Unsupervised Morphological Disambiguation,[0],[0]
4Experiments suggest that this is important to constrain the model to realistic stems.,3 Unsupervised Morphological Disambiguation,[0],[0]
"Finite-state morphological analyzers are usually specified in three parts: a stem lexicon, which defines the words in the language and classifies them into several categories according to their grammatical function and their morphological properties; a set of prefixes and suffixes that can be applied to each category to form surface words; and possibly alternation rules that can encode exceptions and spelling variations.",3.1 Morphological Guessers,[0],[0]
The combination of these parts provides a powerful framework for defining a generative model of words.,3.1 Morphological Guessers,[0],[0]
Such models can be reversed to obtain an analyzer.,3.1 Morphological Guessers,[0],[0]
"However, while the two latter parts can be relatively easy to specify, enumerating a comprehensive stem lexicon is a time consuming and necessarily incomplete process, as some categories are truly open-class.
",3.1 Morphological Guessers,[0],[0]
"To allow unknown words to be analyzed, one can use a guesser that attempts to analyze words missing in the lexicon.",3.1 Morphological Guessers,[0],[0]
Can we eliminate the stem lexicon completely and use only the guesser?,3.1 Morphological Guessers,[0],[0]
This is what we try to do by designing a lexicon-free analyzer for Russian.,3.1 Morphological Guessers,[0],[0]
"A guesser was developed in three hours; it is prone to over-generation and produces ambiguous analyses for most words but covers a large number of morphological phenomena (gender, case, tense, etc.).",3.1 Morphological Guessers,[0],[0]
"For example, the word иврите5 can be correctly analyzed as иврит+Noun+Masc+Prep+Sg but also as the incorrect forms: иврить+Verb+Pres+2P+Pl, иврита+Noun+Fem+Dat+Sg, ивритя+Noun+Fem+Prep+Sg, and more.",3.1 Morphological Guessers,[0],[0]
"We train the unigram model on a 1.7M-word corpus of TED talks transcriptions translated into Russian (Cettolo et al., 2012) and evaluate our analyzer against a test set consisting of 1,500 goldstandard analyses obtained from the morphology disambiguation task of the DIALOG 2010 conference (Lyaševskaya et al., 2010).6
Each analysis is composed of a lemma (иврит), a part of speech (Noun), and a sequence of additional functional morphemes (Masc,Prep,Sg).",3.2 Disambiguation Experiments,[0],[0]
"We consider only open-class categories: nouns, ad-
5иврите = Hebrew (masculine noun, prepositional case) 6http://ru-eval.ru
jectives, adverbs and verbs, and evaluate the output of our model with three metrics: the lemma accuracy, the part-of-speech accuracy, and the morphology F -measure.7
As a baseline, we consider picking a random analysis from output of the analyzer or choosing the most frequent lemma and the most frequent morphological pattern.8",3.2 Disambiguation Experiments,[0],[0]
"Then, we use our model with each of the three versions of the pattern model described in §2.2.",3.2 Disambiguation Experiments,[0],[0]
"Finally, as an upper bound, we use the gold standard to select one of the analyses produced by the guesser.
",3.2 Disambiguation Experiments,[0],[0]
"Since our evaluation is not directly comparable to the standard for this task, we use for reference a high-quality analyzer from Xerox9 disambiguated with the MP0 model (all of the models have very close accuracy in this case).
",3.2 Disambiguation Experiments,[0],[0]
"Considering the amount of effort put in developing the guesser, the baseline POS tagging accuracy is relatively good.",3.2 Disambiguation Experiments,[0],[0]
"However, the disambiguation is largely improved by using our unigram model with respect to all the evaluation categories.",3.2 Disambiguation Experiments,[0],[0]
"We are still far from the performance of a high-quality analyzer but, in absence of such a resource, our technique might be a sensible option.",3.2 Disambiguation Experiments,[0],[0]
"We also note that there is no clear winner in terms of pattern model, and conclude that this choice is task-specific.
",3.2 Disambiguation Experiments,[0],[0]
"7F -measure computed for the set of additional morphemes and averaged over the words in the corpus.
8We estimate these frequencies by assuming each analysis of each token is uniformly likely, then summing fractional counts.
",3.2 Disambiguation Experiments,[0],[0]
9http://open.xerox.com/Services/ fst-nlp-tools/Pages/morphology,3.2 Disambiguation Experiments,[0],[0]
We now integrate our unigram model in a hierarchical Pitman-Yor n-gram language model (Fig. 1).,4 Open Vocabulary Language Models,[0],[0]
"The training corpus words are assumed to be generated from a distribution Gnw drawn from PY(dn, θn, G n−1 w ), where G n−1 w is defined recursively down to the base model G0w.",4 Open Vocabulary Language Models,[0],[0]
"Previous work Teh (2006) simply used G0w = U(V ) where V is the word vocabulary, but in our case G0w is the MP defined in §2.2.
",4 Open Vocabulary Language Models,[0],[0]
We are interested in evaluating our model in an open vocabulary scenario where the ability to explain new unseen words matters.,4 Open Vocabulary Language Models,[0],[0]
"We expect our model to be able to generalize better thanks to the combination of a morphological analyzer and a stem distribution which is less sparse than the word distribution (for example, for the 1.6M word Turkish corpus, |V",4 Open Vocabulary Language Models,[0],[0]
"| ≈ 3.5|S| ≈ 140k).
",4 Open Vocabulary Language Models,[0],[0]
"To integrate out-of-vocabulary words in our evaluation, we use infinite base distributions: G0w (in the baseline model) or G0s (in the MP) are character trigram models.",4 Open Vocabulary Language Models,[0],[0]
"We define perplexity of a held-out test corpus in the standard way:
ppl = exp ( − 1 N N∑ i=1",4 Open Vocabulary Language Models,[0],[0]
"log p (wi | wi−n+1 · · ·wi−1) )
",4 Open Vocabulary Language Models,[0],[0]
"but compared to the common practice, we do not need to discount OOVs from this sum since the model vocabulary is infinite.",4 Open Vocabulary Language Models,[0],[0]
Note that we also marginalize by summing over all the possible analyses for a given word when computing its base probability according to the MP.,4 Open Vocabulary Language Models,[0],[0]
We train several trigram models on the Russian TED talks corpus used in the previous section.,4.1 Language Modeling Experiments,[0],[0]
Our baseline is a hierarchical PY trigram model with a trigram character model as the base word distribution.,4.1 Language Modeling Experiments,[0],[0]
We compare it with our model using the same character model for the base stem distribution.,4.1 Language Modeling Experiments,[0],[0]
Both of the morphological analyzers described in the previous section help obtaining perplexity reductions (Table 2).,4.1 Language Modeling Experiments,[0],[0]
"We ran a similar experiment on the Turkish version of this corpus (1.6M words) with a highquality analyzer (Oflazer, 1994) and obtain even larger gains (Table 3).
",4.1 Language Modeling Experiments,[0],[0]
These results can partly be attributed to the high OOV rate in these conditions: 4% for the Russian corpus and 6% for the Turkish corpus.,4.1 Language Modeling Experiments,[0],[0]
"It is difficult to know whether a decrease in perplexity, as measured in the previous section, will result in a performance improvement in downstream applications.",4.2 Predictive Text Input,[0],[0]
"As a confirmation that correctly modeling new words matters, we consider a predictive task with a truly open vocabulary and that requires only a language model: predictive text input.
",4.2 Predictive Text Input,[0],[0]
"Given some text, we encode it using a lossy deterministic character mapping, and try to recover the original content by computing the most likely word sequence.",4.2 Predictive Text Input,[0],[0]
This task is inspired by predictive text input systems available on cellphones with a 9-key keypad.,4.2 Predictive Text Input,[0],[0]
"For example, the string gave me a cup is encoded as 4283 63 2 287, which could also be decoded as: hate of a bus.
",4.2 Predictive Text Input,[0],[0]
"Silfverberg et al. (2012) describe a system designed for this task in Finnish, which is composed of a weighted finite-state morphological analyzer trained on IRC logs.",4.2 Predictive Text Input,[0],[0]
"However, their system is restricted to words that are encoded in the analyzer’s lexicon and does not use context for disambiguation.
",4.2 Predictive Text Input,[0],[0]
"In our experiments, we use the same Turkish TED talks corpus as the previous section.",4.2 Predictive Text Input,[0],[0]
"As a baseline, we use a trigram character language model.",4.2 Predictive Text Input,[0],[0]
We produce a character lattice which encodes all the possible interpretations for a word and compose it with a finite-state representation of the character LM using OpenFST,4.2 Predictive Text Input,[0],[0]
"(Allauzen et al., 2007).",4.2 Predictive Text Input,[0],[0]
"Alternatively, we can use a unigram word model to decode this lattice, backing off to the character language model if no solution is found.",4.2 Predictive Text Input,[0],[0]
"Finally, to be able to make use of word context, we can extract the k most likely paths according to the character LM and produce a word lattice, which is in turn decoded with a language model defined over the extracted vocabulary.
",4.2 Predictive Text Input,[0],[0]
"We measure word and character error rate (WER, CER) on the predicted word sequence and observe large improvements in both of these metrics by modeling morphology, both at the unigram level and when context is used (Table 4).
",4.2 Predictive Text Input,[0],[0]
"Preliminary experiments with a corpus of 1.6M Turkish tweets, an arguably more appropriate domain this task, show smaller but consistent improving: the trigram word error rate is reduced from 26% to 24% when our model is used.",4.2 Predictive Text Input,[0],[0]
"While our model is an important step forward in practical modeling of OOVs using morphological processes, we have made the linguistically naive assumption that morphology applies inside the language’s lexicon but has no effect on the process that put inflected lexemes together into sentences.",4.3 Limitations,[0],[0]
"In this
regard, our model is a minor variant on traditional ngram models that work with “opaque” word forms.",4.3 Limitations,[0],[0]
How to best relax this assumption in a computationally tractable way is an important open question left for future work.,4.3 Limitations,[0],[0]
Monolingual models of language are not the only models that can benefit from taking into account morphology.,5 Word Alignment Model,[0],[0]
"In fact, alignment models are a good candidate for using richer word distributions: they assume a target word distribution conditioned on each source word.",5 Word Alignment Model,[0],[0]
"When the target language is morphologically rich, classic independence assumptions produce very weak models unless some kind of preprocessing is applied to one side of the corpus.",5 Word Alignment Model,[0],[0]
"An alternative is to use our unigram model as a word translation distribution for each source word in the corpus.
",5 Word Alignment Model,[0],[0]
"Our alignment model is based on a simple variant of IBM Model 2 where the alignment distribution is only controlled by two parameters, λ and p0 (Dyer et al., 2013).",5 Word Alignment Model,[0],[0]
p0 is the probability of the null alignment.,5 Word Alignment Model,[0],[0]
"For a source sentence f of length n, a target sentence e of lengthm and a latent alignment a, we define the following alignment link probabilities (j 6= 0):
p(ai = j | n,m) ∝",5 Word Alignment Model,[0],[0]
(1− p0) exp ( −λ ∣∣∣∣,5 Word Alignment Model,[0],[0]
"im − jn ∣∣∣∣) λ controls the flatness of this distribution: larger values make the probabilities more peaked around the diagonal of the alignment matrix.
",5 Word Alignment Model,[0],[0]
"Each target word is then generated given a source word and a latent alignment link from the word translation distribution p(ei | fai , Gw).",5 Word Alignment Model,[0],[0]
"Note that this is effectively a unigram distribution over target words, albeit conditioned on the source word fj .",5 Word Alignment Model,[0],[0]
Here is where our model differs from classic alignment models: the unigram distribution Gw is assumed be generated from a PY process.,5 Word Alignment Model,[0],[0]
"There are two choices for the base word distribution:
• As a baseline, we use a uniform base distribution over the target vocabulary: G0w = U(V ).
",5 Word Alignment Model,[0],[0]
"• We define a stem distribution Gs[f ] for each source word f , a shared pattern distributionGp, and set G0w[f ] = MP(Gs[f ], Gp).",5 Word Alignment Model,[0],[0]
"In this case,
we obtain the model depicted in Fig. 2.",5 Word Alignment Model,[0],[0]
"The stem and the pattern models are also given PY priors with uniform base distribution (G0s = U(S)).
",5 Word Alignment Model,[0],[0]
"Finally, we put uninformative priors on the alignment distribution parameters: p0 ∼ Beta(α, β) is collapsed and λ ∼ Gamma(k, θ) is inferred using Metropolis-Hastings.
",5 Word Alignment Model,[0],[0]
Experiments We evaluate the alignment error rate of our models for two language pairs with rich morphology on the target side.,5 Word Alignment Model,[0],[0]
"We compare to alignments inferred using IBM Model 4 trained with EM (Brown et al., 1993),10 a version of our baseline model (described above) without PY priors (learned using EM), and the PY-based baseline.",5 Word Alignment Model,[0],[0]
"We consider two language pairs.
",5 Word Alignment Model,[0],[0]
"English-Turkish We use a 2.8M word cleaned version of the South-East European Times corpus (Tyers and Alperen, 2010) and gold-standard alignments from Çakmak et al. (2012).",5 Word Alignment Model,[0],[0]
"Our morphological analyzer is identical to the one used in the previous sections.
",5 Word Alignment Model,[0],[0]
"English-Czech We use the 1.3M word News Commentary corpus and gold-standard alignments
10We use the default GIZA++ stage training scheme:",5 Word Alignment Model,[0],[0]
"Model 1 + HMM + Model 3 + Model 4.
from Bojar and Prokopová (2006).",5 Word Alignment Model,[0],[0]
"The morphological analyzer is provided by Xerox.
",5 Word Alignment Model,[0],[0]
Results Results are shown in Table 5.,5 Word Alignment Model,[0],[0]
Our lightly parameterized model performs much better than IBM Model 4 in these small-data conditions.,5 Word Alignment Model,[0],[0]
"With an identical model, we find PY priors outperform traditional multinomial distributions.",5 Word Alignment Model,[0],[0]
"Adding morphology further reduced the alignment error rate, for both languages.
",5 Word Alignment Model,[0],[0]
"As an example of how our model generalizes better, consider the sentence pair in Fig. 3, taken from the evaluation data.",5 Word Alignment Model,[0],[0]
"The two words composing the Turkish sentence are not found elsewhere in the corpus, but several related inflections occur.11",5 Word Alignment Model,[0],[0]
"It is therefore trivial for the stem-base model to find the correct alignment (marked in black), while all the other models have no evidence for it and choose an arbitrary alignment (gray points).",5 Word Alignment Model,[0],[0]
"Computational morphology has received considerable attention in NLP since the early work on twolevel morphology (Koskenniemi, 1984; Kaplan and
11ödevinin, ödevini, ödevleri; bitmez, bitirileceğinden, bitmesiyle, ...
Kay, 1994).",6 Related Work,[0],[0]
"It is now widely accepted that finitestate transducers have sufficient power to express nearly all morphological phenomena, and the XFST toolkit (Beesley and Karttunen, 2003) has contributed to the practical adoption of this modeling approach.",6 Related Work,[0],[0]
"Recently, open-source tools have been released: in this paper, we used Foma (Hulden, 2009) to develop the Russian guesser.
",6 Related Work,[0],[0]
"Since some inflected forms have several possible analyses, there has been a great deal of work on selecting the intended one in context (Hakkani-Tür et al., 2000; Hajič et al., 2001; Habash and Rambow, 2005; Smith et al., 2005; Habash et al., 2009).",6 Related Work,[0],[0]
"Our disambiguation model is closely related to generative models used for this purpose (Hakkani-Tür et al., 2000).
",6 Related Work,[0],[0]
"Rule-based analysis is not the only approach to modeling morphology, and many unsupervised models have been proposed.12 Heuristic segmentation approaches based on the minimum description length principle (Goldsmith, 2001; Creutz and Lagus, 2007; de Marcken, 1996; Brent et al., 1995) have been shown to be effective, and Bayesian model-based versions have been proposed as well (Goldwater et al., 2011; Snyder and Barzilay, 2008; Snover and Brent, 2001).",6 Related Work,[0],[0]
"In §3, we suggested a third way between rule-based approaches and fully unsupervised learning that combines the best of both worlds.
",6 Related Work,[0],[0]
"Morphological analysis or segmentation is crucial to the performance of several applications: machine translation (Goldwater and McClosky, 2005; AlHaj and Lavie, 2010; Oflazer and El-Kahlout, 2007; Minkov et al., 2007; Habash and Sadat, 2006, inter alia), automatic speech recognition (Creutz et al., 2007), and syntactic parsing (Tsarfaty et al., 2010).",6 Related Work,[0],[0]
"Several methods have been proposed to integrate morphology into n-gram language models, including factored language models (Bilmes and Kirchhoff, 2003), discriminative language modeling (Arısoy et al., 2008), and more heuristic approaches (Monz, 2011).
",6 Related Work,[0],[0]
"Despite the fundamentally open nature of the lexicon (Heaps, 1978), there has been distressingly lit-
12Developing a high-coverage analyzer can be a timeconsuming process even with the simplicity of modern toolkits, and unsupervised morphology learning is an attractive problem for computational cognitive science.
",6 Related Work,[0],[0]
tle attention to the general problem of open vocabulary language modeling problem (most applications make a closed-vocabulary assumption).,6 Related Work,[0],[0]
"The classic exploration of open vocabulary language modeling is Brown et al. (1992), which proposed the strategy of interpolating between word- and character-based models.",6 Related Work,[0],[0]
Character-based language models are reviewed by Carpenter (2005).,6 Related Work,[0],[0]
"So-called hybrid models that model both words and sublexical units have become popular in speech recognition (Shaik et al., 2012; Parada et al., 2011; Bazzi, 2002).",6 Related Work,[0],[0]
"Openvocabulary language language modeling has also recently been explored in the context of assistive technologies (Roark, 2009).
",6 Related Work,[0],[0]
"Finally, Pitman-Yor processes (PYPs) have become widespread in natural language processing since they are natural power-law generators.",6 Related Work,[0],[0]
"It has been shown that the widely used modified KneserNey estimator (Chen and Goodman, 1998) for ngram language models is an approximation of the posterior predictive distribution of a language model with hierarchical PYP priors (Goldwater et al., 2011; Teh, 2006).",6 Related Work,[0],[0]
We described a generative model which makes use of morphological analyzers to produce richer word distributions through sharing of statistical strength between stems.,7 Conclusion,[0],[0]
We have shown how it can be integrated into several models central to NLP applications and have empirically validated the effectiveness of these changes.,7 Conclusion,[0],[0]
"Although this paper mostly focused on languages that are well studied and for which high-quality analyzers are available, our models are especially relevant in low-resource scenarios because they do not require disambiguated analyses.",7 Conclusion,[0],[0]
"In future work, we plan to apply these techniques to languages such as Kinyarwanda, a resource-poor but morphologically rich language spoken in Rwanda.",7 Conclusion,[0],[0]
It is our belief that knowledge-rich models can help bridge the gap between low- and high-resource languages.,7 Conclusion,[0],[0]
"We thank Kemal Oflazer for making his Turkish language morphological analyzer available to us and Brendan O’Connor for gathering the Turkish tweets used in
the predictive text experiments.",Acknowledgments,[0],[0]
This work was sponsored by the U. S. Army Research Laboratory and the U. S. Army Research Office under contract/grant number W911NF-10-1-0533.,Acknowledgments,[0],[0]
We present a morphology-aware nonparametric Bayesian model of language whose prior distribution uses manually constructed finitestate transducers to capture the word formation processes of particular languages.,abstractText,[0],[0]
"This relaxes the word independence assumption and enables sharing of statistical strength across, for example, stems or inflectional paradigms in different contexts.",abstractText,[0],[0]
Our model can be used in virtually any scenario where multinomial distributions over words would be used.,abstractText,[0],[0]
"We obtain state-of-the-art results in language modeling, word alignment, and unsupervised morphological disambiguation for a variety of morphologically rich languages.",abstractText,[0],[0]
Knowledge-Rich Morphological Priors for Bayesian Language Models,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 821–832 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
821",text,[0],[0]
"Reading comprehension (RC) is a language understanding task similar to question answering, where a system is expected to read a given passage of text and answer questions about it.",1 Introduction,[0],[0]
"Cloze-style reading comprehension is a task setting where the question is formed by replacing a token in a sentence of the story with a placeholder (left part of Figure 1).
",1 Introduction,[0],[0]
"In contrast to many previous complex models (Weston et al., 2015; Dhingra et al., 2017; Cui et al., 2017; Munkhdalai and Yu, 2016; Sordoni et al., 2016) that perform multi-turn reading of a story and a question before inferring the correct answer, we aim to tackle the cloze-style RC task in a way that resembles how humans solve it: using, in addition, background knowledge.",1 Introduction,[0],[0]
"We develop
a neural model for RC that can successfully deal with tasks where most of the information to infer answers from is given in the document (story), but where additional information is needed to predict the answer, which can be retrieved from a knowledge base and added to the context representations explicitly.1",1 Introduction,[0],[0]
"An illustration is given in Figure 1.
",1 Introduction,[0],[0]
"Such knowledge may be commonsense knowledge or factual background knowledge about entities and events that is not explicitly expressed but can be found in a knowledge base such as ConceptNet (Speer et al., 2017), BabelNet (Navigli and Ponzetto, 2012), Freebase (Tanon et al., 2016) or domain-specific KBs collected with Information Extraction approaches (Fader et al., 2011; Mausam et al., 2012; Bhutani et al., 2016).",1 Introduction,[0],[0]
"Thus, we aim to define a neural model that encodes preselected knowledge in a memory, and that learns to include the available knowledge as an enrichment to the context representation.
",1 Introduction,[0],[0]
"The main difference of our model to prior state-of-the-art is that instead of relying only on document-to-question interaction or discrete features while performing multiple hops over the document, our model (i) attends to relevant selected
1‘Context representation’ refers to a vector representation computed from textual information only (i.e., document (story) or question).
",1 Introduction,[0],[0]
"external knowledge and (ii) combines this knowledge with the context representation before inferring the answer, in a single hop.",1 Introduction,[0],[0]
"This allows the model to explicitly imply knowledge that is not stated in the text, but is relevant for inferring the answer, and that can be found in an external knowledge source.",1 Introduction,[0],[0]
"Moreover, by including knowledge explicitly, our model provides evidence and insight about the used knowledge in the RC.
",1 Introduction,[0],[0]
"Our main contributions are: (i) We develop a method for integrating knowledge in a simple but effective reading comprehension model (AS Reader, Kadlec et al. (2016)) and improve its results significantly whereas other models employ features or multiple hops.",1 Introduction,[0],[0]
"(ii) We examine two sources of common knowledge: WordNet (Miller et al., 1990) and ConceptNet (Speer et al., 2017) and show that this type of knowledge is important for answering common nouns questions and also improves slightly the performance for named entities.
",1 Introduction,[0],[0]
"(iii) We show that knowledge facts can be added directly to the text-only representation, enriching the neural context encoding.",1 Introduction,[0],[0]
(iv) We demonstrate the effectiveness of the injected knowledge by case studies and data statistics in a qualitative evaluation study.,1 Introduction,[0],[0]
"In this work, we examine the impact of using external knowledge as supporting information for the task of cloze style reading comprehension.
",2 Reading Comprehension with Background Knowledge Sources,[0],[0]
We build a system with two modules.,2 Reading Comprehension with Background Knowledge Sources,[0],[0]
"The first, Knowledge Retrieval, performs fact retrieval and selects a number of facts f1, ..., fp that might be relevant for connecting story, question and candidate answers.",2 Reading Comprehension with Background Knowledge Sources,[0],[0]
"The second, main module, the Knowledgeable Reader, is a knowledge-enhanced neural module.",2 Reading Comprehension with Background Knowledge Sources,[0],[0]
"It uses the input of the story context tokens d1..m, the question tokens q1..n, the set of answer candidates a1..k and a set of ‘relevant’ background knowledge facts f1..p in order to select the right answer.",2 Reading Comprehension with Background Knowledge Sources,[0],[0]
"To include external knowledge for the RC task, we encode each fact f1..p and use attention to select the most relevant among them for each token in the story and question.",2 Reading Comprehension with Background Knowledge Sources,[0],[0]
We expect that enriching the text with additional knowledge about the mentioned concepts will improve the prediction of correct answers in a strong single-pass system.,2 Reading Comprehension with Background Knowledge Sources,[0],[0]
See Figure 1 for illustration.,2 Reading Comprehension with Background Knowledge Sources,[0],[0]
"In our experiments we use knowledge from the Open Mind Common Sense (OMCS, Singh et al. (2002)) part of ConceptNet, a crowd-sourced resource of commonsense knowledge with a total of ∼630k facts.",2.1 Knowledge Retrieval,[0],[0]
"Each fact fi is represented as a triple fi=(subject, relation, object), where subject and object can be multi-word expressions and relation is a relation type.",2.1 Knowledge Retrieval,[0],[0]
"An example is: ([bow]subj , [IsUsedFor]rel, [hunt, animals]obj)
",2.1 Knowledge Retrieval,[0],[0]
"We experiment with three set-ups: using (i) all facts from OMCS that pertain to ConceptNet, referred to as CN5All, (ii) using all facts from CN5All excluding some WordNet relations referred to as CN5Sel(ected) (see Section 3), and using (iii) facts from OMCS that have source set to WordNet (CN5WN3).
",2.1 Knowledge Retrieval,[0],[0]
Retrieving relevant knowledge.,2.1 Knowledge Retrieval,[0],[0]
"For each instance (D, Q, A1..10) we retrieve relevant commonsense background facts.",2.1 Knowledge Retrieval,[0],[0]
"We first retrieve facts that contain lemmas that can be looked up via tokens contained in any D(ocument), Q(uestion) or A(nswer candidates).",2.1 Knowledge Retrieval,[0],[0]
"We add a weight value for each node: 4, if it contains a lemma of a candidate token from A; 3, if it contains a lemma from the tokens of Q; and 2 if it contains a lemma from the tokens of D. The selected weights are chosen heuristically such that they model relative fact importance in different interactions as A+A > A+Q",2.1 Knowledge Retrieval,[0],[0]
> A+D,2.1 Knowledge Retrieval,[0],[0]
>D+Q>,2.1 Knowledge Retrieval,[0],[0]
"D+D. We weight the fact triples that contain these lemmas as nodes, by summing the weights of the subject and object arguments.",2.1 Knowledge Retrieval,[0],[0]
"Next, we sort the knowledge triples by this overall weight value.",2.1 Knowledge Retrieval,[0],[0]
"To limit the memory of our model, we run experiments with different sizes of the top number of facts (P ) selected from all instance fact candidates, P ∈ {50, 100, 200}.",2.1 Knowledge Retrieval,[0],[0]
"As additional retrieval limitation, we force the number of facts per answer candidate to be the same, in order to avoid a frequency bias for an answer candidate that appears more often in the knowledge source.",2.1 Knowledge Retrieval,[0],[0]
"Thus, if we select the maximum 100 facts for each task instance and we have 10 answer candidates ai=1..10, we retrieve the top 10 facts for each candidate ai that has either a subject or an object lemma for a token in ai.",2.1 Knowledge Retrieval,[0],[0]
"If the same fact contains lemmas of two candidates ai and aj (j > i), we add the fact once for ai and do not add the same fact again for aj .",2.1 Knowledge Retrieval,[0],[0]
"If several facts have the same weight, we take
the first in the order of the list2, i.e., the order of retrieval from the database.",2.1 Knowledge Retrieval,[0],[0]
"If one candidate has less than 10 facts, the overall fact candidates for the sample will be less than the maximum (100).",2.1 Knowledge Retrieval,[0],[0]
We implement our Knowledgeable Reader (KnReader) using as a basis the Attention Sum Reader as one of the strongest core models for single-hop RC.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
We extend it with a knowledge fact memory that is filled with pre-selected facts.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Our aim is to examine how adding commonsense knowledge to a simple yet effective model can improve the RC process and to show some evidence of that by attending on the incorporated knowledge facts.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"The model architecture is shown in Figure 2.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Base Attention Model.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"The Attention-Sum Reader (Kadlec et al., 2016), our base model for RC reads the input of story tokens d1..n, the question tokens q1..m, and the set of candidates a1..10 that occur in the story text.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
The model calculates the attention between the question representation rq and the story token context encodings of the candidate tokens a1..10 and sums the attention scores for the candidates that appear multiple times in the story.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"The model selects as answer the candidate that has the highest attention score.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Word Embeddings Layer.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We represent input document and question tokens w by looking up their embedding representations ei = Emb(wi), where Emb is an embedding lookup function.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We apply dropout (Srivastava et al., 2014) with keep
2We also experimented with re-ranking the facts with the same weight sums using tf-idf",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"but we did not notice a difference in performance.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"probability p = 0.8 to the output of the embeddings lookup layer.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Context Representations.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"To represent the document and question contexts, we first encode the tokens with a Bi-directional GRU (Gated Recurrent Unit) (Chung et al., 2014) to obtain context-encoded representations for document (cctxd1..n) and question (cctxq1..m) encoding:
cctxd1..n =",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
BiGRU ctx(ed1..n) ∈ Rn×2h (1) cctxq1..m = BiGRU ctx(eq1..m) ∈,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Rm×2h (2)
, where di and qi denote the ith token of a text sequence d (document) and q (question), respectively, n and m is the size of d and q and h the output hidden size (256) of a single GRU unit.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"BiGRU is defined in (3), with ei a word embedding vector
BiGRU ctx(ei, hiprev) =",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"[ −−−→ GRU(ei, −−−→ hiprev),
←−−− GRU(ei, ←−−− hiprev)]
(3)
, where hiprev = [ −−−→ hiprev , ←−−− hiprev ], and −−−→ hiprev and ←−−− hiprev are the previous hidden states of the forward and backward layers.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Below we use BiGRU ctx(ei) without the hidden state, for short.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Question Query Representation.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
For the question we construct a single vector representation rctxq by retrieving the token representation at the placeholder (XXXX) index pl (cf.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Figure 2):
rctxq = c ctx qi..m [pl] ∈",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"R 2h (4)
where [pl] is an element pickup operation.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Our question vector representation is different from the original AS Reader that builds the question by concatenating the last states of a forward and backward layer [ −−−→ GRU(em), ←−−− GRU(e1)].",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We changed the original representation as we observed some very long questions and in this way aim to prevent the context encoder from ’forgetting’ where the placeholder is.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Answer Prediction: Qctx to Dctx Attention.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"In order to predict the correct answer to the given question, we rank the given answer candidates a1..aL according to the normalized attention sum score between the context (ctx) representation of the question placeholder rctxq and the representation of the candidate tokens in the document:
P (ai|q, d) = softmax( ∑ αij ) (5)
αij = Att(r ctx q , c ctx dj ), i ∈",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"[1..L] (6)
, where j is an index pointer from the list of indices that point to the candidate ai token occurrences in the document context representation cd.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Att is a dot product.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Enriching Context Representations with Knowledge (Context+Knowledge).,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"To enhance the representation of the context, we add knowledge, retrieved as a set of knowledge facts.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Knowledge Encoding.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"For each instance in the dataset, we retrieve a number of relevant facts (cf. Section 2.1).",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"Each retrieved fact is represented as a triple f = (wsubj1..Lsubj , w rel 0 , w obj 1..Lobj ), where wsubj1..Lsubj and w obj 1..Lobj
are a multi-word expressions representing the subject and object with sequence lengths Lsubj and Lobj , and wrel0 is a word token corresponding to a relation.3",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"As a result of fact encoding, we obtain a separate knowledge memory for each instance in the data.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"To encode the knowledge we use a BiGRU to encode the triple argument tokens into the following context-encoded representations:
fsubjlast = BiGRU(Emb(w subj 1..Lsubj ), 0) (7)
f rellast = BiGRU(Emb(w rel 0 ), f subj last ) (8)
fobjlast = BiGRU(Emb(w obj 1..Lsubj ), f rellast) (9)
, where fsubjlast , f rel last, f obj last are the final hidden states of the context encoder BiGRU , that are also used as initial representations for the encoding of the next triple attribute in left-to-right order.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
See Supplement for comprehensive visualizations.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
The motivation behind this encoding is: (i),2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We encode the knowledge fact attributes in the same vector space as the plain tokens; (ii) we preserve the triple directionality; (iii) we use the relation type as a way of filtering the subject information to initialize the object.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Querying the Knowledge Memory.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"To enrich the context representation of the document and question tokens with the facts collected in the knowledge memory, we select a single sum of weighted fact representations for each token using Key-Value retrieval (Miller et al., 2016).",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
In our model the key Mk(ey)i can be either f subj last or f,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"obj last and the value Mv(alue)i is f obj last.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"For each context-encoded token cctxsi (s = d, q; i the token index)",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"we attend over all knowledge
3The 0 in wrel0 indicates that we encode the relation as a single relation type word.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Ex.,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"/r/IsUsedFor.
memory keys Mki in the retrieved P knowledge facts.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We use an attention function Att, scale the scalar attention value using softmax, multiply it with the value representation Mvi and sum the result into a single vector value representation cknsi :
cknsi = ∑ softmax(Att(cctx,Mk1..P ))",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"TMv1..P
(10) Att is a dot product, but it can be replaced with another attention function.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"As a result of this operation, the context token representation cctxsi and the corresponding retrieved knowledge cknsi are in the same vector space ∈ R2h.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Combine Context and Knowledge (ctx+kn).,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We combine the original context token representation cctxsi , with the acquired knowledge representation cknsi to obtain c ctx+kn si :
cctx+knsi = γc ctx si + (1− γ)c kn si (11)
, where γ = 0.5.",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We keep γ static but it can be replaced with a gating function.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
Answer Prediction: Qctx(+kn) to Dctx(+kn).,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
To rank answer candidates a1..,2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"aL we use attention sum similar to Eq.5 over an attention αensembleij that combines attentions between context (ctx) and context+knowledge (ctx+kn) representations of the question (rctx(+kn)q ) and candidate token occurrences aij in the document c ctx(+kn) dj :
P (ai|q, d) = softmax( ∑ αensembleij ) (12)
αensembleij =
W1Att(r ctx q , c ctx dj )
+W2Att(r ctx q , c ctx+kn dj ) +W3Att(r ctx+kn q , c ctx dj )
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"+W4Att(r ctx+kn q , c ctx+kn dj )
(13)
, where j is an index pointer from the list of indices that point to the candidate ai token occurrences in the document context representation c ctx(+kn) d .",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"W1..4 are scalar weights initialized with 1.0 and optimized during training.4 We propose the combination of ctx and ctx + kn attentions because our task does not provide supervision whether the knowledge is needed or not.
",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"4An example for learned W1..4 is (2.13, 1.41, 1.49, 1.84) in setting (CBT CN, CN5Sel, Subj-Obj as k-v, 50 facts).",2.2 Neural Model: Extending the Attention Sum Reader with a Knowledge Memory,[0],[0]
"We experiment with knowledge-enhanced clozestyle reading comprehension using the Common Nouns and Named Entities partitions of the Children’s Book Test (CBT) dataset (Hill et al., 2015).
",3 Data and Task Description,[0],[0]
In the CBT cloze-style task a system is asked to read a children story context of 20 sentences.,3 Data and Task Description,[0],[0]
"The following 21st sentence involves a placeholder token that the system needs to predict, by choosing from a given set of 10 candidate words from the document.",3 Data and Task Description,[0],[0]
An example with suggested external knowledge facts is given in Figure 1.,3 Data and Task Description,[0],[0]
"While in its Common Nouns setup, the task can be considered as a language modeling task, Hill et al. (2015) show that humans can answer the questions without the full context with an accuracy of only 64.4% and a language model alone with 57.7%.",3 Data and Task Description,[0],[0]
"By contrast, the human performance when given the full context is at 81.6%.",3 Data and Task Description,[0],[0]
"Since the best neural model (Munkhdalai and Yu, 2016) achieves only 72.0% on the task, we hypothesize that the task itself can benefit from external knowledge.",3 Data and Task Description,[0],[0]
"The characteristics of the data are shown in Table 1.
",3 Data and Task Description,[0],[0]
"Other popular cloze-style datasets such as CNN/Daily Mail (Hermann et al., 2015) or WhoDidWhat (Onishi et al., 2016) are mainly focused on finding Named Entities where the benefit of adding commonsense knowledge (as we show for the NE part of CBT) would be more limited.
",3 Data and Task Description,[0],[0]
Knowledge Source.,3 Data and Task Description,[0],[0]
As a source of commonsense knowledge we use the Open Mind Common Sense part of ConceptNet 5.0 that contains 630k fact triples.,3 Data and Task Description,[0],[0]
We refer to this entire source as CN5All.,3 Data and Task Description,[0],[0]
"We conduct experiments with subparts of this data: CN5WN3 which is the WordNet 3 part of CN5All (213k triples) and CN5Sel, which excludes the following WordNet relations: RelatedTo, IsA, Synonym, SimilarTo, HasContext.",3 Data and Task Description,[0],[0]
Cloze-Style Reading Comprehension.,4 Related Work,[0],[0]
"Following the original MCTest (Richardson et al., 2013) dataset multiple-choice version of cloze-style RC) recently several large-scale, automatically generated datasets for cloze-style reading comprehension gained a lot of attention, among others the ‘CNN/Daily Mail’ (Hermann et al., 2015; Onishi et al., 2016) and the Children’s Book Test (CBTest) data set (Hill et al., 2015).",4 Related Work,[0],[0]
"Early work introduced simple but good single turn models (Hermann et al., 2015; Kadlec et al., 2016; Chen et al., 2016), that read the document once with the question representation ‘in mind’ and select an answer from a given set of candidates.",4 Related Work,[0],[0]
"More complex models (Weston et al., 2015; Dhingra et al., 2017; Cui et al., 2017; Munkhdalai and Yu, 2016; Sordoni et al., 2016) perform multi-turn reading of the story context and the question, before inferring the correct answer or use features (GA Reader, Dhingra et al. (2017).",4 Related Work,[0],[0]
"Performing multiple hops and modeling a deeper relation between question and document was further developed by several models (Seo et al., 2017; Xiong et al., 2016; Wang et al., 2016, 2017; Shen et al., 2016) on another generation of RC datasets, e.g. SQuAD (Rajpurkar et al., 2016), NewsQA (Trischler et al., 2017) or TriviaQA (Joshi et al., 2017).
",4 Related Work,[0],[0]
Integrating Background Knowledge in Neural Models.,4 Related Work,[0],[0]
Integrating background knowledge in a neural model was proposed in the neural-checklist model by Kiddon et al. (2016) for text generation of recipes.,4 Related Work,[0],[0]
They copy words from a list of ingredients instead of inferring the word from a global vocabulary.,4 Related Work,[0],[0]
Ahn et al. (2016) proposed a language model that copies fact attributes from a topic knowledge memory.,4 Related Work,[0],[0]
"The model predicts a fact in the knowledge memory using a gating mechanism and given this fact, the next word to be selected is copied from the fact attributes.",4 Related Work,[0],[0]
"The knowledge facts are encoded using embeddings obtained using TransE (Bordes et al., 2013).",4 Related Work,[0],[0]
Yang et al. (2017) extended a seq2seq model with attention to external facts for dialogue and recipe generation and a co-reference resolution-aware language model.,4 Related Work,[0],[0]
A similar model was adopted by He et al. (2017) for answer generation in dialogue.,4 Related Work,[0],[0]
"Incorporating external knowledge in a neural model has proven beneficial for several other tasks: Yang and Mitchell (2017) incorporated knowledge di-
rectly into the LSTM cell state to improve event and entity extraction.",4 Related Work,[0],[0]
"They used knowledge embeddings trained on WordNet (Miller et al., 1990) and NELL (Mitchell et al., 2015) using the BILINEAR (Yang et al., 2014) model.
",4 Related Work,[0],[0]
"Work similar to ours is by Long et al. (2017), who have introduced a new task of Rare Entity Prediction.",4 Related Work,[0],[0]
"The task is to read a paragraph from WikiLinks (Singh et al., 2012) and to fill a blank field in place of a missing entity.",4 Related Work,[0],[0]
"Each missing entity is characterized with a short description derived from Freebase, and the system needs to choose one from a set of pre-selected candidates to fill the field.",4 Related Work,[0],[0]
"While the task is superficially similar to cloze-style reading comprehension, it differs considerably: first, when considering the text without the externally provided entity information, it is clearly ambiguous.",4 Related Work,[0],[0]
"In fact, the task is more similar to Entity Linking tasks in the Knowledge Base Population (KBP) tracks at TAC 2013-2017, which aim at detecting specific entities from Freebase.",4 Related Work,[0],[0]
"Our work, by contrast, examines the impact of injecting external knowledge in a reading comprehension, or NLU task, where the knowledge is drawn from a commonsense knowledge base, ConceptNet in our case.",4 Related Work,[0],[0]
"Another difference is that in their setup, the reference knowledge for the candidates is explicitly provided as a single, fixed set of knowledge facts (the entity description), encoded in a single representation.",4 Related Work,[0],[0]
"In our work, we are retrieving (typically) distinct sets of knowledge facts that might (or might not) be relevant for understanding the story and answering the question.",4 Related Work,[0],[0]
"Thus, in our setup, we crucially depend on the ability of the attention mechanism to retrieve relevant pieces of knowledge.",4 Related Work,[0],[0]
"Our aim is to examine to what extent commonsense knowledge can contribute to and improve the cloze-style RC task, that in principle is supposed to be solvable without explicitly given additional knowledge.",4 Related Work,[0],[0]
"We show that by integrating external commonsense knowledge we achieve clear improvements in reading comprehension performance over a strong baseline, and thus we can speculate that humans, when solving this RC task, are similarly using commonsense knowledge as implicitly understood background knowledge.
",4 Related Work,[0],[0]
Recent unpublished work in Weissenborn et al. (2017) is driven by similar intentions.,4 Related Work,[0],[0]
"The authors exploit knowledge from ConceptNet to improve the performance of a reading comprehen-
sion model, experimenting on the recent SQuAD (Rajpurkar et al., 2016) and TriviaQA (Joshi et al., 2017) datasets.",4 Related Work,[0],[0]
"While the source of the background knowledge is the same, the way of integrating this knowledge into the model and task is different.",4 Related Work,[0],[0]
(i),4 Related Work,[0],[0]
We are using attention to select unordered fact triples using key-value retrieval and (ii) we integrate the knowledge that is considered relevant explicitly for each token in the context.,4 Related Work,[0],[0]
"The model of Weissenborn et al. (2017), by contrast, explicitly reads the acquired additional knowledge sequentially after reading the document and question, but transfers the background knowledge implicitly, by refining the word embeddings of the words in the document and the question with the words from the supporting knowledge that share the same lemma.",4 Related Work,[0],[0]
"In contrast to the implicit knowledge transfer of Weissenborn et al. (2017), our explicit attention over external knowledge facts can deliver insights about the used knowledge and how it interacts with specific context tokens (see Section 6).",4 Related Work,[0],[0]
We perform quantitative analysis through experiments.,5 Experiments and Results,[0],[0]
We study the impact of the used knowledge and different model components that employ the external knowledge.,5 Experiments and Results,[0],[0]
"Some of the experiments below focus only on the Common Nouns (CN) dataset, as it has been shown to be more challenging than Named Entities (NE) in prior work.",5 Experiments and Results,[0],[0]
"We experiment with different model parameters.
",5.1 Model Parameters,[0],[0]
Number of facts.,5.1 Model Parameters,[0],[0]
"We explore different sizes of knowledge memories, in terms of number of acquired facts.",5.1 Model Parameters,[0],[0]
"If not stated otherwise, we use 50 facts per example.
",5.1 Model Parameters,[0],[0]
Key-Value Selection Strategy.,5.1 Model Parameters,[0],[0]
"We use two strategies for defining key and value (Key/Value): Subj/Obj and Obj/Obj, where Subj and Obj are the subject and object attributes in the fact triples and they are selected as Key and Value for the KV memory (see Section 2.2, Querying the Knowledge Memory).",5.1 Model Parameters,[0],[0]
"If not stated otherwise, we use the Subj/Obj strategy.
",5.1 Model Parameters,[0],[0]
Answer Selection Components.,5.1 Model Parameters,[0],[0]
"If not stated otherwise, we use ensemble attention αensemble (combinations of ctx and ctx+kn) to rank the answers.",5.1 Model Parameters,[0],[0]
"We call this our Full model (see Sec. 2.2).
Hyper-parameters.",5.1 Model Parameters,[0],[0]
"For our experiments we use pre-trained Glove (Pennington et al., 2014) embeddings, BiGRU with hidden size 256, batch size of 64 and learning reate of 0.001 as they were shown (Kadlec et al., 2016) to perform good on the AS Reader.",5.1 Model Parameters,[0],[0]
We perform experiments with the different model parameters described above.,5.2 Empirical Results,[0],[0]
"We report accuracy on the Dev and Test and use the results on Dev set for pruning the experiments.
",5.2 Empirical Results,[0],[0]
Knowledge Sources.,5.2 Empirical Results,[0],[0]
We experiment with different configuration of ConceptNet facts (see Section 3).,5.2 Empirical Results,[0],[0]
Results on the CBT CN dataset are shown in Table 2.,5.2 Empirical Results,[0],[0]
CN5Sel works best on the Dev set but CN5WN3 works much better on Test.,5.2 Empirical Results,[0],[0]
"Further experiments use the CN5Sel setup.
",5.2 Empirical Results,[0],[0]
Number of facts.,5.2 Empirical Results,[0],[0]
We further experiment with different numbers of facts on the Common Nouns dataset (Table 3).,5.2 Empirical Results,[0],[0]
"The best result on the Dev set is for 50 facts so we use it for further experiments.
",5.2 Empirical Results,[0],[0]
Component ablations.,5.2 Empirical Results,[0],[0]
"We ensemble the attentions from different combinations of the interaction between the question and document context (ctx) representations and context+knowledge (ctx+kn) representations in order to infer the right answer (see Section 2.2, Answer Ranking).
",5.2 Empirical Results,[0],[0]
"Table 4 shows that the combination of different interactions between ctx and ctx+kn representations leads to clear improvement over the w/o knowledge setup, in particular for the Common Nouns dataset.",5.2 Empirical Results,[0],[0]
"We also performed ablations for a model with 100 facts (see Supplement).
",5.2 Empirical Results,[0],[0]
Key-Value Selection Strategy.,5.2 Empirical Results,[0],[0]
"Table 5 shows that for the NE dataset, the two strategies perform
equally well on the Dev set, whereas the Subj/Obj strategy works slightly better on the Test set.",5.2 Empirical Results,[0],[0]
"For Common Nouns, Subj/Obj is better.
",5.2 Empirical Results,[0],[0]
Comparison to Previous Work.,5.2 Empirical Results,[0],[0]
Table 6 compares our model (Knowledgeable Reader) to previous work on the CBT datasets.,5.2 Empirical Results,[0],[0]
"We show the results of our model with the settings that performed best on the Dev sets of the two datasets NE and CN: for NE, (Dctx+kn, Qctx) with 100 facts; for CN the Full model with 50 facts, both with CN5Sel.
Note that our work focuses on the impact of external knowledge and employs a single inter-
action (single-hop) between the document context and the question so we primarily compare to and aim at improving over similar models.",5.2 Empirical Results,[0],[0]
KnReader clearly outperforms prior single-hop models on both datasets.,5.2 Empirical Results,[0],[0]
"While we do not improve over the state of the art, our model stands well among other models that perform multiple hops.",5.2 Empirical Results,[0],[0]
In the Supplement we also give comparison to ensemble models and some models that use re-ranking strategies.,5.2 Empirical Results,[0],[0]
Our experiments examined key parameters of the KnReader.,6.1 Analysis of the empirical results.,[0],[0]
"As expected, injection of background knowledge yields only small improvements over the baseline model for Named Entities.",6.1 Analysis of the empirical results.,[0],[0]
"However, on this dataset our single-hop model is competitive to most multi-hop neural architectures.
",6.1 Analysis of the empirical results.,[0],[0]
The integration of knowledge clearly helps for the Common Nouns task.,6.1 Analysis of the empirical results.,[0],[0]
The impact of knowledge sources (Table 2) is different on the Dev and Test sets which indicates that either the model or the data subsets are sensitive to different knowledge types and retrieved knowledge.,6.1 Analysis of the empirical results.,[0],[0]
Table 5 shows that attending over the Subj of the knowledge triple is slightly better than Obj.,6.1 Analysis of the empirical results.,[0],[0]
This shows that using a Key-Value memory is valuable.,6.1 Analysis of the empirical results.,[0],[0]
"A reason for lower performance of Obj/Obj is that the model picks facts that are similar to the candidate tokens, not adding much new information.",6.1 Analysis of the empirical results.,[0],[0]
From the empirical results we see that training and evaluation with less facts is slightly better.,6.1 Analysis of the empirical results.,[0],[0]
We hypothesize that this is related to the lack of supervision on the retrieved and attended knowledge.,6.1 Analysis of the empirical results.,[0],[0]
"Figure 3 shows the impact on prediction accuracy of individual components of the Full model, including the interaction between D and Q with ctx or ctx",6.2 Interpreting Component Importance,[0],[0]
+ kn (w/o ctx-only).,6.2 Interpreting Component Importance,[0],[0]
"The values for each component are obtained from the attention weights, without retraining the model.",6.2 Interpreting Component Importance,[0],[0]
The difference between blue (left) and orange (right) values indicates how much the module contributes to the model.,6.2 Interpreting Component Importance,[0],[0]
"Interestingly, the ranking of the contribution (Dctx, Qctx+kn > Dctx+kn, Qctx > Dctx+kn, Qctx+kn) corresponds to the component importance ablation on the Dev set, lines 5-8, Table 4.
",6.2 Interpreting Component Importance,[0],[0]
"Subj/Obj,  50  facts
Obj/Obj,  50  facts",6.2 Interpreting Component Importance,[0],[0]
"We will use the attention values of the interactions between Dctx(+kn) and Qctx(+kn) and attentions to facts from each candidate token and the question placeholder to interpret how knowledge is employed to make a prediction for a single example.
",6.3 Qualitative Data Investigation,[0],[0]
Method: Interpreting Model Components.,6.3 Qualitative Data Investigation,[0],[0]
"We manually inspect examples from the evaluation sets where KnReader improves prediction (blue (left) category, Fig. 3) or makes the prediction worse (orange (right) category, Fig. 3).",6.3 Qualitative Data Investigation,[0],[0]
"Figure 4 shows the question with placeholder, followed by answer candidates and their associated attention weights as assigned by the model w/o knowledge.",6.3 Qualitative Data Investigation,[0],[0]
The matrix shows selected facts and their assigned weights for the question and the candidate tokens.,6.3 Qualitative Data Investigation,[0],[0]
"Finally, we show the attention weights determined by the knowledge-enhanced D to Q interactions.",6.3 Qualitative Data Investigation,[0],[0]
The attention to the correct answer (head) is low when the model considers the text alone (w/o knowledge).,6.3 Qualitative Data Investigation,[0],[0]
"When adding retrieved knowledge to theQ only (row ctx, ctx+kn) and to both Q and D (row ctx + kn, ctx + kn) the score improves, while when adding knowledge to D alone (row ctx+ kn, ctx) the score remains ambiguous.",6.3 Qualitative Data Investigation,[0],[0]
The combined score Ensemble (see Eq. 13) then takes the final decision for the answer.,6.3 Qualitative Data Investigation,[0],[0]
"In this example, the question can be answered without the story.",6.3 Qualitative Data Investigation,[0],[0]
The model tries to find knowledge that is related to eyes.,6.3 Qualitative Data Investigation,[0],[0]
"The fact eyes /r/PartOf head is not contained in the retrieved knowledge but in-
stead the model selects the fact ear /r/PartOf head which receives the highest attention from Q. The weighted Obj representation (head) is added to the question with the highest weight, together with animal and bird from the next highly weighted facts This results in a high score for theQctx toDctx+kn interaction with candidate head.",6.3 Qualitative Data Investigation,[0],[0]
"See Supplement for more details.
",6.3 Qualitative Data Investigation,[0],[0]
"Using the method described above, we analyze several example cases (presented in Supplement) that highlight different aspects of our model.",6.3 Qualitative Data Investigation,[0],[0]
"Here we summarize our observations.
",6.3 Qualitative Data Investigation,[0],[0]
(i.),6.3 Qualitative Data Investigation,[0],[0]
"Answer prediction from Q or Q+D. In both human and machine RC, questions can be answered based on the question alone (Figure 4) or jointly with the story context (Case 2, Suppl.).",6.3 Qualitative Data Investigation,[0],[0]
"We show that empirically, enriching the question with knowledge is crucial for the first type, while enrichment of Q and D is required for the second.
",6.3 Qualitative Data Investigation,[0],[0]
(ii.),6.3 Qualitative Data Investigation,[0],[0]
Overcoming frequency bias..,6.3 Qualitative Data Investigation,[0],[0]
"We show
that when appropriate knowledge is available and selected, the model is able to correct a frequency bias towards an incorrect answer (Cases 1 and 3).
",6.3 Qualitative Data Investigation,[0],[0]
(iii.),6.3 Qualitative Data Investigation,[0],[0]
Providing appropriate knowledge.,6.3 Qualitative Data Investigation,[0],[0]
"We observe a lack of knowledge regarding events (e.g. take off vs. put on clothes, Case 2; climb up, Case 5).",6.3 Qualitative Data Investigation,[0],[0]
"Nevertheless relevant knowledge from CN5 can help predicting infrequent candidates (Case 2).
",6.3 Qualitative Data Investigation,[0],[0]
(iv.),6.3 Qualitative Data Investigation,[0],[0]
"Knowledge, Q and D encoding.",6.3 Qualitative Data Investigation,[0],[0]
"The context encoding of facts allows the model to detect knowledge that is semantically related, but not surface near to phrases in Q and D (Case 2).",6.3 Qualitative Data Investigation,[0],[0]
"The model finds facts to non-trivial paraphrases (e.g. undressed–naked, Case 2).",6.3 Qualitative Data Investigation,[0],[0]
"We propose a neural cloze-style reading comprehension model that incorporates external commonsense knowledge, building on a single-turn neural model.",7 Conclusion and Future Work,[0],[0]
"Incorporating external knowledge improves its results with a relative error rate reduction of 9% on Common Nouns, thus the model is able to compete with more complex RC models.",7 Conclusion and Future Work,[0],[0]
We show that the types of knowledge contained in ConceptNet are useful.,7 Conclusion and Future Work,[0],[0]
"We provide quantitative and qualitative evidence of the effectiveness of our model, that learns how to select relevant knowledge to improve RC.",7 Conclusion and Future Work,[0],[0]
"The attractiveness of our model lies in its transparency and flexibility: due to the attention mechanism, we can trace and analyze the facts considered in answering specific questions.",7 Conclusion and Future Work,[0],[0]
"This opens up for deeper investigation and future improvement of RC models in a targeted way, allowing us to investigate what knowledge sources are required for different data sets and domains.",7 Conclusion and Future Work,[0],[0]
"Since our model directly integrates background knowledge with the document and questioncontext representations, it can be adapted to very different task settings where we have a pair of two arguments (i.e. entailment, question answering, etc.)",7 Conclusion and Future Work,[0],[0]
"In future work, we will investigate even tighter integration of the attended knowledge and stronger reasoning methods.",7 Conclusion and Future Work,[0],[0]
This work has been supported by the German Research Foundation as part of the Research Training Group Adaptive Preparation of Information from Heterogeneous Sources (AIPHES) under grant No.,Acknowledgments,[0],[0]
GRK 1994/1.,Acknowledgments,[0],[0]
We thank the reviewers for their helpful questions and comments.,Acknowledgments,[0],[0]
"We introduce a neural reading comprehension model that integrates external commonsense knowledge, encoded as a keyvalue memory, in a cloze-style setting.",abstractText,[0],[0]
"Instead of relying only on document-toquestion interaction or discrete features as in prior work, our model attends to relevant external knowledge and combines this knowledge with the context representation before inferring the answer.",abstractText,[0],[0]
"This allows the model to attract and imply knowledge from an external knowledge source that is not explicitly stated in the text, but that is relevant for inferring the answer.",abstractText,[0],[0]
"Our model improves results over a very strong baseline on a hard Common Nouns dataset, making it a strong competitor of much more complex models.",abstractText,[0],[0]
"By including knowledge explicitly, our model can also provide evidence about the background knowledge used in the RC process.",abstractText,[0],[0]
Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1–15 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
The development of hospital information system and medical informatics drives the leverage of various medical data for a more efficient and intelligent medical care service.,1 Introduction,[0],[0]
"Among many kinds of medical data, electronic health records (EHRs) are one of the most valuable and informative data as they contain detailed information about the patients and the clinical practices.",1 Introduction,[0],[0]
"EHRs are essential to many intelligent clinical applications, such
∗Weinan Zhang is the corresponding author.
",1 Introduction,[0],[0]
"as hospital quality control and clinical decision support systems (Wu et al., 2015).",1 Introduction,[0],[0]
"Most of EHRs are recorded in an unstructured form, i.e., natural language.",1 Introduction,[0],[0]
"Hence, extracting structured information from EHRs using natural language processing (NLP), e.g., named entity recognition (NER) and entity linking, plays a fundamental role in medical informatics (Zhang and Elhadad, 2013).",1 Introduction,[0],[0]
"In this paper, we focus on medical NER from EHRs, which is a fundamental task and is widely studied in the research community (Nadeau and Sekine, 2007; Uzuner et al., 2011).
",1 Introduction,[0],[0]
"In practice, the difficulty of building a universally robust and high-performance medical NER system lies in the variety of medical terminologies and expressions among different departments of specialties and hospitals.",1 Introduction,[0],[0]
"However, building separate NER systems for so many specialties comes with a prohibitively high cost.",1 Introduction,[0],[0]
"The data privacy issue further discourages the sharing of the data across departments or hospitals, making it more difficult to train a canonical NER system to be applied everywhere.",1 Introduction,[0],[0]
"This raises a natural question: if we have sufficient annotated EHRs data in one source specialty, can we distill the knowledge and transfer it to help training models in a related target specialty with few annotations?",1 Introduction,[0],[0]
By transferring the knowledge we can achieve higher performance in target specialties with lower annotation cost and bypass the data sharing concerns.,1 Introduction,[0],[0]
"This is commonly referred to as transfer learning (Pan and Yang, 2010).
",1 Introduction,[0],[0]
"Current state-of-the-art transfer learning methods for NER are mainly based on deep neural networks, which perform an end-to-end training to distill sequential dependency patterns in the natural language (Ma and Hovy, 2016; Lample et al., 2016).",1 Introduction,[0],[0]
"These transfer learning methods include (i) feature representation transfer (Peng and Dredze, 2017; Kulkarni et al., 2016), which normally lever-
1
ages deep neural networks to learn a close feature mapping between the source and target domains, and (ii) parameter transfer (Murthy et al., 2016; Yang et al., 2017), which performs parameter sharing or joint training to get the target-domain model parameters close to those of the source-domain model.",1 Introduction,[0],[0]
"To the best of our knowledge, there is no previous literature working on transfer learning for NER in the medical domain, or even in a larger scope, i.e., medical natural language processing.
",1 Introduction,[0],[0]
"In this paper, we propose a novel NER transfer learning framework, namely label-aware double transfer learning (La-DTL): (i) We leverage bidirectional long-short term memory (Bi-LSTM) network (Graves and Schmidhuber, 2005) to automatically learn the text representations, based on which we perform a label-aware feature representation transfer.",1 Introduction,[0],[0]
"We propose a variant of maximum mean discrepancy (MMD) (Gretton et al., 2012), namely label-aware MMD (La-MMD), to explicitly reduce the domain discrepancy of feature representations of tokens with the same label between two domains.",1 Introduction,[0],[0]
(ii),1 Introduction,[0],[0]
"Based on the learned feature representations from Bi-LSTM, two conditional random field (CRF) models are performed for sequence labeling for source and target domain separately, where parameter transfer learning is performed.",1 Introduction,[0],[0]
"Specifically, an upper bound of KL divergence between the source and target domain’s CRF label distributions is added over the emission and transition matrices across the source and target CRF models to explore the shareable parts of the parameters.",1 Introduction,[0],[0]
"Both (i) and (ii) have a labelaware characteristic, which will be discussed later.",1 Introduction,[0],[0]
"We further argue that label-aware characteristic is crucial for transfer learning in sequence labeling problems, e.g., NER, because only when the corresponding labels are matched, can the “similar” contexts (i.e. feature representation) and model parameters be efficiently borrowed to improve the label prediction.
",1 Introduction,[0],[0]
Extensive experiments are conducted on 12 cross-specialty medical NER tasks with real-world EHRs.,1 Introduction,[0],[0]
"The experimental results demonstrate that La-DTL provides consistent accuracy improvement over strong baselines, with overall 2.62% to 6.70% absolute F1-score improvement over the state-of-the-art methods.",1 Introduction,[0],[0]
"Besides, the promising experimental results on other two non-medical NER scenarios indicate that La-DTL has the potential to be seamlessly adapted to a wide range of
NER tasks.",1 Introduction,[0],[0]
"Named Entity Recognition (NER) is fundamental in information extraction area which aims at automatic detection of named entities (e.g., person, organization, location and geo-political) in free text (Marrero et al., 2013).",2 Related Works,[0],[0]
"Many high-level applications such as entity linking (Moro et al., 2014) and knowledge graph construction (Hachey et al., 2011) could be built on top of an NER system.",2 Related Works,[0],[0]
"Traditional high-performance approaches include conditional random fields models (CRFs) (Lafferty et al., 2001), maximum entropy Markov models (MEMMs) (McCallum et al., 2000) and hidden Markov models (HMMs).",2 Related Works,[0],[0]
"Recently, many neural network-based models have been proposed (Collobert et al., 2011; Chiu and Nichols, 2016; Ma and Hovy, 2016; Lample et al., 2016), in which few feature engineering works are needed to train a high-performance NER system.",2 Related Works,[0],[0]
"The architecture of those neural network-based models are similar, where different neural networks (LSTMs, CNNs) at different levels (char- and word-level) are applied to learn feature representations, and on top of neural networks, a CRF model is employed to make label predictions.",2 Related Works,[0],[0]
Transfer Learning distills knowledge from a source domain to help create a high-performance learner for a target domain.,2 Related Works,[0],[0]
"Transfer learning algorithms are mainly categorized into three types, namely instance transfer, feature representation transfer and parameter transfer (Pan and Yang, 2010).",2 Related Works,[0],[0]
"Instance transfer normally samples or reweights source-domain samples to match the distribution of the target domain (Chen et al., 2011; Chu et al., 2013).",2 Related Works,[0],[0]
"Feature representation transfer typically learns a feature mapping which projects source and target domain data simultaneously onto a common feature space following similar distributions (Zhuang et al., 2015; Long et al., 2015; Shen et al., 2017).",2 Related Works,[0],[0]
"Parameter transfer normally involves a joint or constrained training for the models on source and target domains, usually introduce connections between source target parameters via sharing (Srivastava and Salakhutdinov, 2013), initialization (Perlich et al., 2014), or intermodel parameter penalty schemes (Zhang et al., 2016).",2 Related Works,[0],[0]
"Transfer Learning for NER Training a highperformance NER system requires expensive and
time-consuming manually annotated data.",2 Related Works,[0],[0]
"But sufficient labeled data is critical for the generalization of an NER system, especially for neural networkbased models.",2 Related Works,[0],[0]
"Thus, transfer learning for NER is a practically important problem.",2 Related Works,[0],[0]
The first group of methods focuses on sharing model parameters but they differ in the training schemes.,2 Related Works,[0],[0]
"He and Sun (2017) proposed to train the parameter-shared model with source and target data jointly, while the learning rates for sentences from source domain are re-weighted by the similarity with target domain corpus.",2 Related Works,[0],[0]
"Yang et al. (2017) proposed a family of frameworks which share model parameters in hierarchical recurrent networks to handle crossapplication, cross-lingual, and cross-domain transfer in sequence labeling tasks.",2 Related Works,[0],[0]
"Differently, Lee et al. (2017) first trained the model with source domain data and then fine-tuned the model with little annotated target domain data.
",2 Related Works,[0],[0]
"Domain adaptation method has been well studied in NER scenarios such as using distributed word representations (Kulkarni et al., 2016) and leveraging rule-based annotators (Chiticariu et al., 2010).",2 Related Works,[0],[0]
"Multi-task learning has also been studied to improve performance in multiple NER tasks by transferring meaningful knowledge from other tasks (Collobert et al., 2011; Peng and Dredze, 2016).",2 Related Works,[0],[0]
"To take the advantages of both domain adaptation and multi-task learning, Peng and Dredze (2017) proposed a multi-task domain adaptation model.",2 Related Works,[0],[0]
"This section briefly introduces bidirectional LSTM, conditional random field and maximum mean discrepancy, which are the building blocks of our transfer learning framework.",3 Preliminaries,[0],[0]
Bidirectional LSTM Recurrent neural networks (RNNs) are widely used in NLP tasks for their great capability to capture contextual information in sequence data.,3 Preliminaries,[0],[0]
"A widely used variant of RNNs is long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997), which incorporates input and forget gates to capture both long and short term dependencies.",3 Preliminaries,[0],[0]
"Furthermore, it will be beneficial if we process the sequence in not only a forward but also a backward way.",3 Preliminaries,[0],[0]
"Thus, bidirectional LSTM (Bi-LSTM) was employed in many previous works (Chiu and Nichols, 2016; Ma and Hovy, 2016; Lample et al., 2016) to capture bidirectional information in a sequence.",3 Preliminaries,[0],[0]
"More specifi-
cally, for token xt (embedding vector) at timestep t in sequence X = (x1,x2, ...,xn), the θbparameterized Bi-LSTM recurrently updates hidden vectors h→t = G f θb (X,h→t−1) and h ← t = Gbθb(X,h ← t+1) produced by a forward LSTM and a backward one, respectively.",3 Preliminaries,[0],[0]
"Then we concatenate h→t and h ← t to ht as the final hidden vector produced by Bi-LSTM:
ht = h → t ⊕ h←t .
",3 Preliminaries,[0],[0]
"The representations learned from Bi-LSTM for sequence X is thus denoted as H = (h1,h2, ...,hn).",3 Preliminaries,[0],[0]
Conditional Random Field,3 Preliminaries,[0],[0]
"The goal of NER is to detect named entities in a sequence X by predicting a sequence of labels y = (y1, y2, ..., yn).",3 Preliminaries,[0],[0]
"Conditional random field (CRF) is widely used to make joint labeling of the tokens in a sequence (Lafferty et al., 2001).
",3 Preliminaries,[0],[0]
"Recently, Lample et al. (2016) proposed to build a CRF layer on top of a Bi-LSTM so that the automatically learned feature representation H = (h1,h2, ...,hn) of the sequence can be directly fed into the CRF for sequence labeling.",3 Preliminaries,[0],[0]
"For a sequence of labels y, given the hidden vector sequence H, we define its θc-parametrized score function sθc(H,y) as:
sθc(H,y) =
n∑
i=1
Ei,yi +
n−1∑
i=1
Ayi,yi+1 ,
where E is the emission score matrix of size n×m (m is the number of unique labels), and is computed by E = HW where W is the label emission parameter matrix; A is the label transition parameter matrix; thus θc = {W,A}.",3 Preliminaries,[0],[0]
"We then define the conditional probability of label sequence y given H by a softmax over all possible label sequences in set Y(H) as:
pθc(y|H) = exp{sθc(H,y)}/Z(H) (1)",3 Preliminaries,[0],[0]
"=exp{sθc(H,y)} / ∑
y′∈Y(H) exp{sθc(H,y′)},
where θc is omitted for simplification in the following part.",3 Preliminaries,[0],[0]
The training objective in the CRF layer is to maximize the log-likelihood maxθc log p(y|H).,3 Preliminaries,[0],[0]
"In the label prediction phase, we give the output label sequence y∗ with the highest conditional probability y∗ = argmaxy′∈Y(H) p(y′|H) by dynamic programming (Sutton et al., 2012).",3 Preliminaries,[0],[0]
"Maximum Mean Discrepancy Maximum Mean Discrepancy (Gretton et al., 2012) is",3 Preliminaries,[0],[0]
a non-,3 Preliminaries,[0],[0]
parametric test statistic to measure the distribution discrepancy in terms of the distance between the kernel mean embeddings of two distributions p and q.,Bi-LSTM,[0],[0]
"The MMD is defined in particular function spaces that witness the difference in distributions
MMD(F , p, q) = sup f∈F (Ex∼p[f(x)]− Ey∼q[f(y)]).
",Bi-LSTM,[0],[0]
"By defining the function class F as the unit ball in a universal Reproducing Kernel Hilbert Space (RKHS), denoted by H, it holds that MMD[F , p, q] = 0 if and only if p = q.",Bi-LSTM,[0],[0]
"And then given two sets of samples X = {x1, ..., xm} and Y = {y1, ..., yn} independently and identically distributed (i.i.d.) from p and q on the data space X , the empirical estimate of MMD can be written as the distance between the empirical mean embeddings after mapping to RKHS
MMD(X,Y ) = ∥∥∥",Bi-LSTM,[0],[0]
"1 m m∑
i=1
φ(xi)− 1 n
n∑
j=1
φ(yj) ∥∥∥",Bi-LSTM,[0],[0]
"H , (2)
where φ(·) : X → H is the nonlinear feature mapping that inducesH.",Bi-LSTM,[0],[0]
"In this section, we present a label-aware double transfer learning (La-DTL) framework and discuss its rationale.",4 Methodology,[0],[0]
Figure 1 gives an overview of La-DTL for NER.,4.1 Framework Overview,[0],[0]
"From bottom up, each input sentence is converted
into a sequence of embedding vectors, which are then fed into a Bi-LSTM to sequentially encode contextual information into fixed-length hidden vectors.",4.1 Framework Overview,[0],[0]
The embedding and Bi-LSTM layers are shared among source/target domains.,4.1 Framework Overview,[0],[0]
"With labelaware maximum mean discrepancy (La-MMD) to reduce the feature representation discrepancy between two domains, the hidden vectors are directly fed into source/target domain specific CRF layers to predict the label sequence.",4.1 Framework Overview,[0],[0]
"We use domain constrained CRF layers to enhance the target domain performance.
",4.1 Framework Overview,[0],[0]
"More formally, let Ds = {(Xsi ,ysi )}N s
i=1",4.1 Framework Overview,[0],[0]
"be the training set of N s samples from the source domain and Dt = {(Xti,yti)}",4.1 Framework Overview,[0],[0]
"Nt
i=1",4.1 Framework Overview,[0],[0]
"be the training set of N t samples from the target domain, with N t N s. Bi-LSTM encodes a sentence X = (x1,x2, ...,xn) to hidden vectors H = (h1,h2, ...,hn).",4.1 Framework Overview,[0],[0]
We occasionally use H(X) to denote the corresponding hidden vectors when feeding X into the Bi-LSTM.,4.1 Framework Overview,[0],[0]
CRF decodes hidden vectors H to a label sequence ŷ =,4.1 Framework Overview,[0],[0]
"(ŷ1, ŷ2, ..., ŷn).",4.1 Framework Overview,[0],[0]
Our goal is to improve label prediction accuracy on the target domain Dt by utilizing the knowledge from the source domain,4.1 Framework Overview,[0],[0]
"Ds:
p(y|X) =p(y|H(X)),
log p(y|H) = n∑
i=1
",4.1 Framework Overview,[0],[0]
"Ei,yi +
n−1∑
i=1
Ayi,yi+1",4.1 Framework Overview,[0],[0]
− logZ(H).,4.1 Framework Overview,[0],[0]
"(3)
Thus training a transferable model p(y|X) requires both H(X) and p(y|H) to be transferable.
",4.1 Framework Overview,[0],[0]
"We use share word embedding and Bi-LSTM by approaching the feature representation distributions p(h|Ds) and p(h|Dt), i.e., the distributions of Bi-LSTM hidden vectors at each timestep of the sentences from the source and target domains respectively.",4.1 Framework Overview,[0],[0]
The rationale behind it lies on the insufficiency of labeled target data.,4.1 Framework Overview,[0],[0]
"Even though LSTM has high capacity, its generalization ability highly relies on viewing “sufficient” data.",4.1 Framework Overview,[0],[0]
"Otherwise, LSTM is very likely to overfit the data.",4.1 Framework Overview,[0],[0]
"Training on both source and target data, the BiLSTM is expected to learn feature representations with high quality.",4.1 Framework Overview,[0],[0]
"Yosinski et al. (2014) provided a justification of this solution that sharing bottom layers is promising for transfer learning in practice.
",4.1 Framework Overview,[0],[0]
"With the sentences projected onto the same hidden space, the conditional distribution p(hs|Ds) and p(ht|Dt), however, may be distant because
LSTM hidden vectors contain contextual information which is different across domains.",4.1 Framework Overview,[0],[0]
"In order to reduce source/target discrepancy, we refine MMD (Gretton et al., 2012) with label constraints, i.e., label-aware MMD (La-MMD).",4.1 Framework Overview,[0],[0]
"Using La-MMD, the source/target hidden states are pushed to similar distributions to make the feature representation H(X) transfer feasible.
",4.1 Framework Overview,[0],[0]
"Based on the hidden vectors from Bi-LSTM, we adopt independent CRF layers for each domain.",4.1 Framework Overview,[0],[0]
The rationale lies in the hypotheses that (i) the target domain predictor can better capture target data distribution which could be very unique; (ii) a good predictor trained on the source domain directly could be leveraged to assist the target domain predictor without directly borrowing the source domain training data to bypass the data privacy issue.,4.1 Framework Overview,[0],[0]
"With respect to the emission and transition score matrices ∑ Ei,yi and ∑ Ayi,yi+1 , we adopt an upper bound between source/target domains, which helps the target domain predictor to be guided by the source domain predictor.",4.1 Framework Overview,[0],[0]
"Thus p(y|H) is also transferable.
",4.1 Framework Overview,[0],[0]
"There are also other transfer methods, including fine-tuning, sharing parameter directly (without constraints) (He and Sun, 2017; Lee et al., 2017; Yang et al., 2017), etc.",4.1 Framework Overview,[0],[0]
"However, simply sharing models may dismiss target specific instances.",4.1 Framework Overview,[0],[0]
"The learning objective is to minimize the following loss L with respect to parameters Θ = {θb, θc}:
L = Lc + α LLa-MMD + β",4.2 Learning Objective,[0],[0]
"Lp + γ Lr,
where Lc is the CRF loss, LLa-MMD is the LaMMD loss,",4.2 Learning Objective,[0],[0]
"Lp is the parameter similarity loss on CRF layers, andLr is the regularization term, with α, β, γ as hyperparameters to balance loss terms.
",4.2 Learning Objective,[0],[0]
"The CRF loss is our ultimate objective predicting the label sequence given the input sentence, i.e., we minimize the negative log-likelihood of training samples from both source/target domains:
",4.2 Learning Objective,[0],[0]
"Lc = − ε Ns
Ns∑
i=1
log p(ysi |Hsi )",4.2 Learning Objective,[0],[0]
"− 1− ε N t
Nt∑
i=1
log p(yti |Hti),
where H are hidden vectors obtained from BiLSTM, ε is the balance coefficient.",4.2 Learning Objective,[0],[0]
The La-MMD loss LLa-MMD and parameter similarity loss,4.2 Learning Objective,[0],[0]
"Lp are discussed in Section 4.3 and 4.4, respectively.",4.2 Learning Objective,[0],[0]
"The
regularization term is to generally control overfitting:
Lr = ‖θb‖22 + ‖θc‖22.
",4.2 Learning Objective,[0],[0]
We will provide the model convergence and hyperparameter study in Section 5.1.,4.2 Learning Objective,[0],[0]
"To learn transferable feature representations, the maximum mean discrepancy (MMD) which measures the distance between two distributions, has been widely used in domain adaptation scenarios (Long et al., 2015; Rozantsev et al., 2016).",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
Almost all these works focus on reducing the marginal distribution distance between different domain features in an unsupervised manner to make them indistinguishable.,4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"However, considering a word is not evenly distributed conditioning on different labels, it may result in that the discriminative property of features from different domains may not be similar, which means that close source and target samples may not have the same label.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"Different from previous works, we propose label-aware MMD (La-MMD) in Eq.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"(5) to explicitly reduce the discrepancy between hidden representations with the same label, i.e., the linear combination of the MMD for each label.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
For each label class y ∈,4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"Yv, where Yv is the set of matched labels in two domains, we compute the squared population MMD between the hidden representations of source/target samples with the same label y:
MMD2(Rsy,Rty) = 1
(Nsy )2
Nsy∑
i,j=1
k(hsi ,h s j) +
1
(N ty)2
Nty∑
i,j=1
k(hti,h t j)
",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"− 2 NsyN ty
Nsy ,N t y∑
i,j=1
k(hsi ,h t j), (4)
where Rsy and Rty are sets of hidden representation hs and ht with corresponding number N sy and N t y. Eq.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
(4) can be easily derived by casting Eq.,4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"(2) into inner product form and applying 〈φ(x), φ(y)〉H = k(x, y) where k is the reproducing kernel function (Gretton et al., 2012).",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"For each label class, we compute the MMD loss in a normal manner.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"After that, we define the La-MMD loss as:
LLa-MMD = ∑
y∈Yv µy ·MMD2(Rsy,Rty), (5)
where µy is the corresponding coefficient.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"The illustration of La-MMD is shown in Figure 2.
",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
"Once we have applied this La-MMD to our representations learned from Bi-LSTM, the representation distribution of instances with the same label from different domains should be close.",4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
Then the standard CRF layer which has a simple linear structure takes these similar representations as input and is likely to give a more transferable label decision for instances with the same label.,4.3 Bi-LSTM Feature Representation Transfer,[0],[0]
Simply sharing the CRF layer is non-promising when source/target data are diversely distributed.,4.4 CRF Parameter Transfer,[0],[0]
According to probability decomposition in Eq.,4.4 CRF Parameter Transfer,[0],[0]
"(3), in order to transfer on source/target CRF layers, more specifically, p(y|H), we reduce the KL divergence from pt(y|H) to ps(y|H).",4.4 CRF Parameter Transfer,[0],[0]
"But directly reducing DKL(ps(y|H)||pt(y|H)) is intractable, we tend to reduce its upper bound:
DKL(p s(y|H)||pt(y|H))
",4.4 CRF Parameter Transfer,[0],[0]
"= ∑
y∈Y(H) ps(y|H)",4.4 CRF Parameter Transfer,[0],[0]
"log(p s(y|H) pt(y|H) )
",4.4 CRF Parameter Transfer,[0],[0]
"=−H(ps(y|H))− ∑
y∈Y(H) ps(y|H) log pt(y|H)
≤c(‖Ws −Wt‖22 + ‖As −At‖22) 1 2 , (6)
where H(·) is the entropy of distribution (·) and c is a constant.",4.4 CRF Parameter Transfer,[0],[0]
The detailed proof is provided in Appendix A.1.,4.4 CRF Parameter Transfer,[0],[0]
"Since c(‖Ws−Wt‖22+‖As−At‖22) is the upper bound of DKL(ps(y|H)‖pt(y|H)),
we conduct CRF parameter transfer by minimizing
Lp = ‖Ws −Wt‖22 + ‖A s −At‖22.
",4.4 CRF Parameter Transfer,[0],[0]
"It turns out that a similar regularization term is applied in our CRF parameter transfer method and the regularization framework (RF) for domain adaptation (Lu et al., 2016).",4.4 CRF Parameter Transfer,[0],[0]
"However, RF is proposed to generalize the feature augmentation method in (Daume III, 2007), and these two methods are only discussed from a perspective of the parameter.",4.4 CRF Parameter Transfer,[0],[0]
There is no guarantee that two models having similar parameters yields similar output distributions.,4.4 CRF Parameter Transfer,[0],[0]
"In this work, we discuss the model behavior in CRF conditions, and we successfully prove that two CRF models having similar parameters (in Euclidean space) yields similar output distributions.",4.4 CRF Parameter Transfer,[0],[0]
"In another word, our method guarantees transferability in the model behavior level, while previous works are limited in parameter level.
",4.4 CRF Parameter Transfer,[0],[0]
"The CRF parameter transfer is illustrated in Figure 3, which is also label-aware since the L2 constraint is added over parameters corresponding to the same label in two domains, e.g., WsO and W t O.",4.4 CRF Parameter Transfer,[0],[0]
"We train La-DTL in an end-to-end manner with mini-batch AdaGrad (Duchi et al., 2011).",4.5 Training,[0],[0]
"One mini-batch contains training samples from both domains, otherwise the computation of LLa-MMD can not be performed.",4.5 Training,[0],[0]
"During training, word (and character) embeddings are fine-tuned to adjust real data distribution.",4.5 Training,[0],[0]
"During both training and decoding (testing) of CRF layers, we use dynamic programming to compute the normalizer in Eq.",4.5 Training,[0],[0]
(1) and infer the label sequence.,4.5 Training,[0],[0]
"In this section, we evaluate La-DTL1 and other baseline methods on 12 cross-specialty NER problems based on real-world datasets.",5 Experiments,[0],[0]
The experimental results show that La-DTL steadily outperforms other baseline models in all tasks significantly.,5 Experiments,[0],[0]
We also conduct further ablation study and robustness study.,5 Experiments,[0],[0]
We evaluate La-DTL on two more nonmedical NER transfer tasks to validate its general efficacy over a wide range of applications.,5 Experiments,[0],[0]
Datasets We collected a Chinese medical NER (CM-NER) corpus for our experiments.,5.1 Cross-Specialty NER,[0],[0]
"This corpus contains 1600 de-identified EHRs of our affiliated hospital from four different specialties in four departments: Cardiology (500), Respiratory (500), Neurology (300) and Gastroenterology (300), and the research had been reviewed and approved by the ethics committee.",5.1 Cross-Specialty NER,[0],[0]
"Named entities are annotated in the BIOES format (Begin, Inside, Outside, End and Single), with 30 types in total.",5.1 Cross-Specialty NER,[0],[0]
The statistics of CM-NER is shown in Table 1.,5.1 Cross-Specialty NER,[0],[0]
Baselines The following methods are compared.,5.1 Cross-Specialty NER,[0],[0]
"For a fair comparison, we implement La-DTL and baselines with the same base model introduced in (Lample et al., 2016) but with different transfer techniques.
",5.1 Cross-Specialty NER,[0],[0]
"• Non-transfer uses the target domain labeled data only.
",5.1 Cross-Specialty NER,[0],[0]
"• Domain mask and Linear projection belong to the same framework proposed by Peng and Dredze (2017) but have different implementations at the projection layer, which aims to produce shared feature representations among different domains through a linear transformation.
",5.1 Cross-Specialty NER,[0],[0]
"• Re-training is proposed by Lee et al. (2017), where an artificial neural networks (ANNs)
1https://github.com/felixwzh/La-DTL
is first trained on the source domain and then re-trained on the target domain.
",5.1 Cross-Specialty NER,[0],[0]
"• Joint-training is a transfer learning method proposed by Yang et al. (2017) where different tasks are trained jointly.
",5.1 Cross-Specialty NER,[0],[0]
"• CD-learning is a cross-domain learning method proposed by He and Sun (2017), where each source domain training example’s learning rate is re-weighted.
",5.1 Cross-Specialty NER,[0],[0]
"Experimental Settings We use 23,217 unlabeled clinical records to train the word embeddings (word2vec) at 128 dimensions using skipgram model (Mikolov et al., 2013).",5.1 Cross-Specialty NER,[0],[0]
The hidden state size is set to be 200 for word-level Bi-LSTM.,5.1 Cross-Specialty NER,[0],[0]
"We evaluate La-DTL for cross-specialty NER with CM-NER in 12 transfer tasks, results shown in Table 2.",5.1 Cross-Specialty NER,[0],[0]
"For each task, we take the whole source domain training set Ds and 10% sentences of the target domain training set Dt as training data.",5.1 Cross-Specialty NER,[0],[0]
We use the development set in target domain to search hyper-parameters including training epochs.,5.1 Cross-Specialty NER,[0],[0]
We then take the models to make the prediction in target domain test set and use F1-score as the evaluation metric.,5.1 Cross-Specialty NER,[0],[0]
"Statistical significance has been determined using a randomization version of the paired sample t-test (Cohen, 1995).",5.1 Cross-Specialty NER,[0],[0]
"Results and Discussion From the results of 12 cross-specialty NER tasks shown in Table 2, we find that La-DTL outperforms all the strong baselines in all the 12 cross-specialty transfer learning tasks, with 2.62% to 6.70% F1-score lift over state-of-the-art baseline methods.",5.1 Cross-Specialty NER,[0],[0]
"Meanwhile, Linear projection and Domain mask (Peng and Dredze, 2017) do not perform as good as other three baselines, which may be because such linear transformation methods are likely to weaken the representations.",5.1 Cross-Specialty NER,[0],[0]
"While other three baseline methods all share the whole model between source/target domains but differ in the training schemes and performance.
",5.1 Cross-Specialty NER,[0],[0]
"To better understand the transferability of LaDTL, we also evaluate three variants of LaDTL: La-MMD, CRF-L2, and MMD-CRF-L2.",5.1 Cross-Specialty NER,[0],[0]
"La-MMD and CRF-L2 have the same networks and loss function as La-DTL but with different building blocks: La-MMD has β = 0, while CRFL2 has α = 0.",5.1 Cross-Specialty NER,[0],[0]
"In MMD-CRF-L2, we replace La-MMD loss LLa-MMD in La-DTL with a vanilla MMD loss:
LMMD = MMD2(Rs,Rt),
where Rs and Rt are sets of hidden representation from source and target domain.",5.1 Cross-Specialty NER,[0],[0]
"Results in Table 2 show that: (i) Using La-MMD alone does achieve satisfactory performance since it outperforms the best baseline Joint-training (Yang et al., 2017) in 7 of 12 tasks.",5.1 Cross-Specialty NER,[0],[0]
"And it has a significant improvement over Domain mask and Linear projection methods (Peng and Dredze, 2017), which indicates that using La-MMD to reduce the domain discrepancy of feature representations in sequence tagging tasks is promising.",5.1 Cross-Specialty NER,[0],[0]
"(ii) CRF-L2 is also a promising method when transferring between NER tasks, and it improves the La-MMD method significantly when these two methods are combined to form La-DTL.",5.1 Cross-Specialty NER,[0],[0]
(iii) Label-aware characteristic is important in sequence labeling problems because there is an obvious performance drop when La-MMD is replaced with a vanilla MMD in La-DTL.,5.1 Cross-Specialty NER,[0],[0]
But MMD-CRF-L2 still has very competitive performance compared to all the baseline methods.,5.1 Cross-Specialty NER,[0],[0]
"This shows positive empirical evidence that transferring knowledge at both BiLSTM feature representation level and CRF parameter level for NER tasks is better than transferring knowledge at only one of these two levels, as discussed in Section 4.1.",5.1 Cross-Specialty NER,[0],[0]
"We further study the sparsity problem (target domain) of La-DTL in C→R task comparing to Joint-training (Yang et al., 2017) and Non-transfer method.",Robustness to Target Domain Data Sparsity,[0],[0]
"We evaluate La-DTL with different data volume (sampling rate: 10%, 25%, 50%, 100%) on the target domain training set.",Robustness to Target Domain Data Sparsity,[0],[0]
Results are shown in Figure 4(a).,Robustness to Target Domain Data Sparsity,[0],[0]
"We observe that La-DTL outperforms Joint-training and Non-transfer results under all circumstances, and the improvement of LaDTL is more significant when the sampling rate is lower.
",Robustness to Target Domain Data Sparsity,[0],[0]
"To show La-DTL’s convergence and significant improvement over Joint-training, we repeat the 10% sampling rate experiment for 10 times with 10 random seeds.",Robustness to Target Domain Data Sparsity,[0],[0]
The F1-score on the target domain development set for two methods with a 95% confidence interval is shown in Figure 4(b) where La-DTL outperforms Joint-training method significantly.,Robustness to Target Domain Data Sparsity,[0],[0]
"Hyperparameter Study We study the influence of three key hyperparameters in La-DTL: α, β, and ε in C→R task with 10% target domain sampling rate.",Robustness to Target Domain Data Sparsity,[0],[0]
"We first apply a rough grid search for the three hyperparameters, and the result is (α = 0.02, β = 0.03, ε = 0.3).",Robustness to Target Domain Data Sparsity,[0],[0]
We then fix two hyperparameters and test the third one in a finer granularity.,Robustness to Target Domain Data Sparsity,[0],[0]
The results in Figure 5 indicate that setting α ∈,Robustness to Target Domain Data Sparsity,[0],[0]
"[0.01, 0.04] could better leverage LaMMD and further setting β ∈",Robustness to Target Domain Data Sparsity,[0],[0]
"[0.03, 0.12] and ε ∈",Robustness to Target Domain Data Sparsity,[0],[0]
"[0.3, 0.4] yields the best empirical perfor-
mance.",Robustness to Target Domain Data Sparsity,[0],[0]
This shows that we need to balance the learning objective of the source and target domains for better transferability.,Robustness to Target Domain Data Sparsity,[0],[0]
"To show La-DTL could be applied in a wide range of NER transfer learning scenarios, we make experiments on two non-medical NER tasks.",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
Corpora’s details are shown in Table 3.,5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
WeiboNER,5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"Transfer Following He and Sun (2017); Peng and Dredze (2017), we transfer knowledge from SighanNER (MSR corpus of the sixth SIGHAN Workshop on Chinese language processing) to WeiboNER (a social media NER corpus) (Peng and Dredze, 2015).",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
Results in Table 4 show that La-DTL outperforms all the baseline methods in Chinese social media domain.,5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
TwitterNER Transfer,5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
Following Yang et al.,5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"(2017) we transfer knowledge from CoNLL 2003 English NER (Tjong Kim Sang and De Meulder, 2003) to TwitterNER (Ritter et al., 2011).",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"Since the entity types in these two corpora cannot be exactly matched, La-DTL and Joint-training (Yang et al., 2017) can be applied directly in this case while other baselines can not.",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"Because the CRF parameter transfer of La-DTL is label-aware, and Jointtraining simply leverages two independent CRF layers.",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"The results are shown in Table 5, where LaDTL again outperforms Joint-training, indicating that La-DTL could be applied seamlessly to trans-
fer learning scenarios with mismatched label sets and languages like English.",5.2 NER Transfer Experiment on Non-medical Corpus,[0],[0]
"In this paper, we propose La-DTL, a label-aware double transfer learning framework, to conduct both Bi-LSTM feature representation transfer and CRF parameter transfer with label-aware constraints for cross-specialty medical NER tasks.",6 Conclusions,[0],[0]
"To our best knowledge, this is the first work on transfer learning for medical NER in cross-specialty scenario.",6 Conclusions,[0],[0]
Experiments on 12 cross-specialty NER tasks show that La-DTL provides consistent performance improvement over strong baselines.,6 Conclusions,[0],[0]
"We further perform a set of experiments on different target domain data size, hyperparameter study and other non-medical NER tasks, where La-DTL shows great robustness and wide efficacy.",6 Conclusions,[0],[0]
"For future work, we plan to jointly perform NER and entity linking for better cross-specialty media structural information extraction.",6 Conclusions,[0],[0]
"The work done by SJTU is sponsored by Synyi-SJTU Innovation Program, National Natural Science Foundation of China (61632017, 61702327, 61772333) and Shanghai Sailing Program (17YF1428200).",Acknowledgments,[0],[0]
Recall the bound as in Eq.,A.1 Detailed Proof,[0],[0]
"(6):
Lemma A.1.",A.1 Detailed Proof,[0],[0]
c1(‖Ws −Wt‖22,A.1 Detailed Proof,[0],[0]
"+ ‖As −At‖22) is the upper bound of (ss(H,y)− st(H,y))2.
",A.1 Detailed Proof,[0],[0]
Proof of Lemma A.1.,A.1 Detailed Proof,[0],[0]
"⊗ refers to convolutional product, HW ,HA are mask matrices corresponding to the given hidden vectors H, and c1 is a constant.",A.1 Detailed Proof,[0],[0]
"We have:
(ss(H,y)− st(H,y))2
=(
n∑
i=1
Esi,yi + n−1∑
i=1
Asyi,yi+1",A.1 Detailed Proof,[0],[0]
"− n∑
i=1
Eti,yi − n−1∑
i=1
Atyi,yi+1) 2
=(Ws ⊗HW +",A.1 Detailed Proof,[0],[0]
"As ⊗HA −Wt ⊗HW −At ⊗HA)2
=((Ws −Wt)⊗HW + (As −At)⊗HA)2
≤2((Ws −Wt)⊗HW )2 + 2((As −At)⊗HA)2 =2( ∑
i,j
(Ws −Wt)i,j ·HWi,j)2 + 2( ∑
p,q
(As −At)p,q ·HAp,q)2
≤2( ∑
i,j
(Ws −Wt)2i,j · ∑
i,j
(HWi,j) 2)",A.1 Detailed Proof,[0],[0]
"+ 2(
∑
p,q
(As −At)2p,q · ∑
p,q
(HAp,q) 2)
",A.1 Detailed Proof,[0],[0]
"=2(‖Ws −Wt‖22 · ‖HW ‖22) + 2(‖As −At‖22 · ‖HA‖22) ≤c1(‖Ws −Wt‖22 + ‖As −At‖22).
",A.1 Detailed Proof,[0],[0]
Lemma A.2. c(‖Ws,A.1 Detailed Proof,[0],[0]
−Wt‖22,A.1 Detailed Proof,[0],[0]
+ ‖As −At‖22),A.1 Detailed Proof,[0],[0]
"1 2 is the upper bound of DKL(ps(y|H)||pt(y|H)).
",A.1 Detailed Proof,[0],[0]
Proof of Lemma A.2.,A.1 Detailed Proof,[0],[0]
With Lemma.,A.1 Detailed Proof,[0],[0]
"(A.1), we set ε = (c1(‖Ws −Wt‖22 + ‖As",A.1 Detailed Proof,[0],[0]
− At‖22)),A.1 Detailed Proof,[0],[0]
"1 2 ≥ 0 and c = 2c 1 2 1 , and we have:
ss(H,y)− ε ≤",A.1 Detailed Proof,[0],[0]
"st(H,y) ≤",A.1 Detailed Proof,[0],[0]
"ss(H,y) + ε, (7)
log{ ∑
y′∈Y(H) exp[ss(H,y′)]}",A.1 Detailed Proof,[0],[0]
"− ε ≤ log{
∑
y′∈Y(H) exp[st(H,y′)]",A.1 Detailed Proof,[0],[0]
"} ≤ log{
∑
y′∈Y(H) exp[ss(H,y′)]}+ ε.
(8)
With Eq. (7) and Eq.",A.1 Detailed Proof,[0],[0]
"(8), we can derive
− ∑
y∈Y(H) ps(y|H) log pt(y|H)
",A.1 Detailed Proof,[0],[0]
"=− ∑
y∈Y(H) ps(y|H) log exp[s t(H,y)]∑ y′∈Y(H) exp[s",A.1 Detailed Proof,[0],[0]
"t(H,y′)]
=− ∑
y∈Y(H) ps(y|H)
{ st(H,y)− log{ ∑
y′∈Y(H) exp[st(H,y′)]}
}
≤− ∑
y∈Y(H) ps(y|H)
{",A.1 Detailed Proof,[0],[0]
"ss(H,y)− ε− log{ ∑
y′∈Y(H) exp[ss(H,y′)]}",A.1 Detailed Proof,[0],[0]
"− ε
}
=− ∑
y∈Y(H) ps(y|H)
{ log exp[ss(H,y)]∑ y′∈Y(H) exp[s",A.1 Detailed Proof,[0],[0]
"s(H,y′)]",A.1 Detailed Proof,[0],[0]
"−2ε }
=− ∑
y∈Y(H) ps(y|H)
{ log ps(y|H)−2ε }
=H(ps(y|H))",A.1 Detailed Proof,[0],[0]
"+ 2ε.
",A.1 Detailed Proof,[0],[0]
"Finally, we have
DKL(p s(y|H)||pt(y|H))
",A.1 Detailed Proof,[0],[0]
"= ∑
y∈Y(H) ps(y|H)",A.1 Detailed Proof,[0],[0]
"log(p s(y|H) pt(y|H) )
",A.1 Detailed Proof,[0],[0]
"=−H(ps(y|H))− ∑
y∈Y(H) ps(y|H) log pt(y|H)
≤−H(ps(y|H))",A.1 Detailed Proof,[0],[0]
+H(ps(y|H)),A.1 Detailed Proof,[0],[0]
+ 2ε =c(‖Ws −Wt‖22 + ‖As −At‖22) 1 2 .,A.1 Detailed Proof,[0],[0]
"In clinical practice, patients with specific diseases would be assigned to different departments, and specialist doctors in their department may pay more attention to the specific disease.",A.2 Case Analysis,[0],[0]
"When writing a medical chart, these specific diseases and related clinical findings would have a more detailed description.",A.2 Case Analysis,[0],[0]
"Therefore, some medical terms would have enriched meanings in different departments accordingly.",A.2 Case Analysis,[0],[0]
"For example, patients with rheumatic heart disease are often treated in the department of Cardiology.",A.2 Case Analysis,[0],[0]
"The term, “rheumatic”, a modifier, describes and limits the type of “heart disease”.",A.2 Case Analysis,[0],[0]
"In English, “rheumatic” is an adjective modifying “heart disease”.",A.2 Case Analysis,[0],[0]
"However, in Chinese, “rheumatic heart disease” can be regarded as two diseases, “rheumatism” and “heart disease”.",A.2 Case Analysis,[0],[0]
"In the department of Cardiology, “rheumatic heart dis-
ease” is usually mentioned as a single term.",A.2 Case Analysis,[0],[0]
"While in other departments, “rheumatism” and “heart disease” are mostly two independent named entities in annotated datasets.",A.2 Case Analysis,[0],[0]
"As such, it is difficult to train an NER model to capture the relationship between “rheumatism” and “heart disease”, and band them as a whole.",A.2 Case Analysis,[0],[0]
"In the training set of our study, the diagnostic term “rheumatic heart disease” (including synonym) is mentioned for 17 times in Dept. Cardiology, 16 times in Dept. Respiratory, none in Dept. Neurology and 3 times in Dept. Gastroenterology.",A.2 Case Analysis,[0],[0]
"We use the data from the first 3 departments as source domain training set respectively, and the data from Dept.",A.2 Case Analysis,[0],[0]
Gastroenterology as the target domain training set.,A.2 Case Analysis,[0],[0]
"We test our models on the test set from Dept. Gastroenterology, where “rheumatic heart disease” is mentioned 3 times, and compare the results across models
with/without transfer learning.",A.2 Case Analysis,[0],[0]
"As expected, models with source training data from Dept.",A.2 Case Analysis,[0],[0]
"Cardiovascular and Respiration correctly predict all these entities, but the model using source data from Dept. Neurology fails and so does a model without transfer learning.
",A.2 Case Analysis,[0],[0]
Patients with pulmonary heart disease were often referred to Dept. Respiratory and Dept. Cardiology.,A.2 Case Analysis,[0],[0]
"In our training set, “pulmonary heart disease” (including synonym) is labeled for 24 times in Dept. Respiratory and 4 times in Dept. Cardiology.",A.2 Case Analysis,[0],[0]
"In English, “pulmonary” modified “heart disease”.",A.2 Case Analysis,[0],[0]
"In Chinese, “pulmonary heart disease” contains body structure “lung” and disease name “heart disease”.",A.2 Case Analysis,[0],[0]
"The model trained with the source set from both from department of respiratory and cardiology could correctly recognize the relation between lung and heart disease and predict the entity in the test set from Dept. Gastroenterology.
",A.2 Case Analysis,[0],[0]
"Similarly, “coronary atherosclerotic heart disease” contains two disease names, “coronary atherosclerosis” and “heart disease”.",A.2 Case Analysis,[0],[0]
Training model using source set from a department where the terms are enriched could improve the performance of recognizing the whole entity.,A.2 Case Analysis,[0],[0]
"The 30 entity types for medical domain are: Symptom, Disease, Examination, Treatment, Laboratory index, Products, Body structure, Frequency, Negative word, Value, Trend, Modification, Temporal word, Noun of locality, Degree modifier, Probability, Object, Organism, Location, Person, Pronoun, Privacy information, Accident, Action, Header, Instrument and material, Nonphysiological structure, Dosage, Scale, and Preposition.",A.3 Medical Experiments Details,[0],[0]
"WeiboNER Transfer Both SighanNER and WeiboNER are annotated in the BIO format (Begin, Inside and Outside), but there is one more entity type (geo-political) in WeiboNER.",A.4 Non-medical Experiments Details,[0],[0]
"For a fair comparison, we follow Peng and Dredze (2017); He and Sun (2017) to merge geo-political entities and locations in WeiboNER, to match different labeling schemes between WeiboNER and SighanNER.",A.4 Non-medical Experiments Details,[0],[0]
"We use the inconsistencies fixed second version of WeiboNER data and word embeddings provided by WeiboNER’s developers (Peng and Dredze, 2015)2 in this experiment.
",A.4 Non-medical Experiments Details,[0],[0]
"TwitterNER Transfer To show that La-DTL could be applied in transfer learning for NER scenario with mismatched
2 https://github.com/hltcoe/golden-horse
named entity types and languages like English, we conduct this experiment transfer from CoNLL 2003 English NER to TwitterNER.",A.4 Non-medical Experiments Details,[0],[0]
"The four entity types in CoNLL 2003 English NER are LOC, PER, ORG, and MISC.",A.4 Non-medical Experiments Details,[0],[0]
"The ten entity types in TwitterNER are company, facility, geo-loc, movie, musicartist, other, person, product, sportsteam, and tvshow.
",A.4 Non-medical Experiments Details,[0],[0]
"The Joint-training method (Yang et al., 2017) separates the CRF layers for each domain to bypass the label mismatch problem.",A.4 Non-medical Experiments Details,[0],[0]
"Since our La-DTL is label-aware, we match four pairs of named entities between two CoNLL 2003 English NER and TwitterNER: LOC with geo-loc, PER with person, ORG with company and MISC with other to compute LLa-MMD and Lp, and leave six named entities unmatched.",A.4 Non-medical Experiments Details,[0],[0]
"Following Yang et al. (2017), We leverage char-level Bi-LSTM to generate better word representations, concatenate it with pre-trained word embeddings and feed concatenated embeddings to the word-level Bi-LSTM.",A.4 Non-medical Experiments Details,[0],[0]
"The framework used for language like English is illustrated in Figure 6.
",A.4 Non-medical Experiments Details,[0],[0]
We also convert all characters to lowercase and use the same word embeddings provided by Yang et al. (2017)3.,A.4 Non-medical Experiments Details,[0],[0]
"Also, we concatenate the training set and the development set for both domains and sample the same 10% from TwitterNER as (Yang et al., 2017) to be target domain training data.",A.4 Non-medical Experiments Details,[0],[0]
"Since Yang et al. (2017) merge training and development set into training data, both Yang et al. (2017) and we report the best performance in the target domain test set.
",A.4 Non-medical Experiments Details,[0],[0]
3 https://github.com/kimiyoung/transfer,A.4 Non-medical Experiments Details,[0],[0]
"We study the problem of named entity recognition (NER) from electronic medical records, which is one of the most fundamental and critical problems for medical text mining.",abstractText,[0],[0]
Medical records which are written by clinicians from different specialties usually contain quite different terminologies and writing styles.,abstractText,[0],[0]
The difference of specialties and the cost of human annotation makes it particularly difficult to train a universal medical NER system.,abstractText,[0],[0]
"In this paper, we propose a labelaware double transfer learning framework (LaDTL) for cross-specialty NER, so that a medical NER system designed for one specialty could be conveniently applied to another one with minimal annotation efforts.",abstractText,[0],[0]
"The transferability is guaranteed by two components: (i) we propose label-aware MMD for feature representation transfer, and (ii) we perform parameter transfer with a theoretical upper bound which is also label aware.",abstractText,[0],[0]
We conduct extensive experiments on 12 cross-specialty NER tasks.,abstractText,[0],[0]
The experimental results demonstrate that La-DTL provides consistent accuracy improvement over strong baselines.,abstractText,[0],[0]
"Besides, the promising experimental results on non-medical NER scenarios indicate that LaDTL is potential to be seamlessly adapted to a wide range of NER tasks.",abstractText,[0],[0]
Label-aware Double Transfer Learning for Cross-Specialty Medical Named Entity Recognition,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 319–328, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"The recurrent sequence-to-sequence paradigm for natural language generation (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014) has achieved remarkable recent success and is now the approach of choice for applications such as machine translation (Bahdanau et al., 2015), caption generation (Xu et al., 2015) and speech recognition (Chorowski et al., 2015).",1 Introduction,[0],[0]
"While these models have developed sophisticated conditioning mechanisms, e.g. attention, fundamentally they are discriminative models trained only to approximate the conditional output distribution of strings.",1 Introduction,[0],[0]
"In this paper we explore modelling the
joint distribution of string pairs using a deep generative model and employing a discrete variational autoencoder (VAE) for inference (Kingma and Welling, 2014; Rezende et al., 2014; Mnih and Gregor, 2014).",1 Introduction,[0],[0]
We evaluate our generative approach on the task of sentence compression.,1 Introduction,[0],[0]
"This approach provides both alternative supervised objective functions and the opportunity to perform semi-supervised learning by exploiting the VAEs ability to marginalise the latent compressed text for unlabelled data.
",1 Introduction,[0],[0]
"Auto-encoders (Rumelhart et al., 1985) are a typical neural network architecture for learning compact data representations, with the general aim of performing dimensionality reduction on embeddings (Hinton and Salakhutdinov, 2006).",1 Introduction,[0],[0]
"In this paper, rather than seeking to embed inputs as points in a vector space, we describe them with explicit natural language sentences.",1 Introduction,[0],[0]
This approach is a natural fit for summarisation tasks such as sentence compression.,1 Introduction,[0],[0]
"According to this, we propose a generative auto-encoding sentence compression (ASC) model, where we introduce a latent language model to provide the variablelength compact summary.",1 Introduction,[0],[0]
The objective is to perform Bayesian inference for the posterior distribution of summaries conditioned on the observed utterances.,1 Introduction,[0],[0]
"Hence, in the framework of VAE, we construct an inference network as the variational approximation of the posterior, which generates compression samples to optimise the variational lower bound.
",1 Introduction,[0],[0]
"The most common family of variational autoencoders relies on the reparameterisation trick, which is not applicable for our discrete latent language model.",1 Introduction,[0],[0]
"Instead, we employ the REINFORCE algorithm (Mnih et al., 2014; Mnih and Gregor, 2014)
319
to mitigate the problem of high variance during sampling-based variational inference.",1 Introduction,[0],[0]
"Nevertheless, when directly applying the RNN encoder-decoder to model the variational distribution it is very difficult to generate reasonable compression samples in the early stages of training, since each hidden state of the sequence would have |V | possible words to be sampled from.",1 Introduction,[0],[0]
"To combat this we employ pointer networks (Vinyals et al., 2015) to construct the variational distribution.",1 Introduction,[0],[0]
"This biases the latent space to sequences composed of words only appearing in the source sentence (i.e. the size of softmax output for each state becomes the length of current source sentence), which amounts to applying an extractive compression model for the variational approximation.
",1 Introduction,[0],[0]
"In order to further boost the performance on sentence compression, we employ a supervised forcedattention sentence compression model (FSC) trained on labelled data to teach the ASC model to generate compression sentences.",1 Introduction,[0],[0]
The FSC model shares the pointer network of the ASC model and combines a softmax output layer over the whole vocabulary.,1 Introduction,[0],[0]
"Therefore, while training on the sentencecompression pairs, it is able to balance copying a word from the source sentence with generating it from the background distribution.",1 Introduction,[0],[0]
"More importantly, by jointly training on the labelled and unlabelled datasets, this shared pointer network enables the model to work in a semi-supervised scenario.",1 Introduction,[0],[0]
"In
this case, the FSC teaches the ASC to generate reasonable samples, while the pointer network trained on a large unlabelled data set helps the FSC model to perform better abstractive summarisation.
",1 Introduction,[0],[0]
"In Section 6, we evaluate the proposed model by jointly training the generative (ASC) and discriminative (FSC) models on the standard Gigaword sentence compression task with varying amounts of labelled and unlabelled data.",1 Introduction,[0],[0]
The results demonstrate that by introducing a latent language variable we are able to match the previous benchmakers with small amount of the supervised data.,1 Introduction,[0],[0]
When we employ our mixed discriminative and generative objective with all of the supervised data the model significantly outperforms all previously published results.,1 Introduction,[0],[0]
"In this section, we introduce the auto-encoding sentence compression model (Figure 1)1 in the framework of variational auto-encoders.",2 Auto-Encoding Sentence Compression,[0],[0]
"The ASC model consists of four recurrent neural networks – an encoder, a compressor, a decoder and a language model.
",2 Auto-Encoding Sentence Compression,[0],[0]
"Let s be the source sentence, and c be the compression sentence.",2 Auto-Encoding Sentence Compression,[0],[0]
The compression model (encodercompressor) is the inference network qφ(c|s) that takes source sentences s as inputs and generates extractive compressions c.,2 Auto-Encoding Sentence Compression,[0],[0]
"The reconstruction
1The language model, layer connections and decoder soft attentions are omitted in Figure 1 for clarity.
model (compressor-decoder) is the generative network pθ(s|c) that reconstructs source sentences s based on the latent compressions c. Hence, the forward pass starts from the encoder to the compressor and ends at the decoder.",2 Auto-Encoding Sentence Compression,[0],[0]
"As the prior distribution, a language model p(c) is pre-trained to regularise the latent compressions so that the samples drawn from the compression model are likely to be reasonable natural language sentences.",2 Auto-Encoding Sentence Compression,[0],[0]
"For the compression model (encoder-compressor), qφ(c|s), we employ a pointer network consisting of a bidirectional LSTM encoder that processes the source sentences, and an LSTM compressor that generates compressed sentences by attending to the encoded source words.
",2.1 Compression,[0],[0]
"Let si be the words in the source sentences, hei be the corresponding state outputs of the encoder.",2.1 Compression,[0],[0]
"hei are the concatenated hidden states from each direction:
hei = f−→enc(~h e i−1, si)||f←−enc( ~hei+1, si) (1)
",2.1 Compression,[0],[0]
"Further, let cj be the words in the compressed sentences, hcj be the state outputs of the compressor.",2.1 Compression,[0],[0]
"We construct the predictive distribution by attending to the words in the source sentences:
hcj =fcom(h c j−1, cj−1) (2)
uj(i) =w T 3",2.1 Compression,[0],[0]
tanh(W1h c j+W2h e,2.1 Compression,[0],[0]
"i ) (3)
qφ(cj |c1:j−1, s)= softmax(uj) (4)
where c0 is the start symbol for each compressed sentence and hc0 is initialised by the source sentence vector of he|s|.",2.1 Compression,[0],[0]
"In this case, all the words cj sampled from qφ(cj |c1:j−1, s) are the subset of the words appeared in the source sentence (i.e. cj ∈ s).",2.1 Compression,[0],[0]
"For the reconstruction model (compressor-decoder) pθ(s|c), we apply a soft attention sequence-tosequence model to generate the source sentence s based on the compression samples c ∼ qφ(c|s).
",2.2 Reconstruction,[0],[0]
"Let sk be the words in the reconstructed sentences and hdk be the corresponding state outputs of the decoder:
hdk = fdec(h d k−1, sk−1) (5)
",2.2 Reconstruction,[0],[0]
"In this model, we directly use the recurrent cell of the compressor to encode the compression samples2:
ĥ c j =fcom(ĥ c j−1, cj) (6)
where the state outputs ĥ c j corresponding to the word inputs cj are different from the outputs hcj in the compression model, since we block the information from the source sentences.",2.2 Reconstruction,[0],[0]
We also introduce a start symbol s0 for the reconstructed sentence and hd0 is initialised by the last state output ĥ c |c|.,2.2 Reconstruction,[0],[0]
"The soft attention model is defined as:
vk(j) =w T 6 tanh(W",2.2 Reconstruction,[0],[0]
4h d k,2.2 Reconstruction,[0],[0]
"+W 5ĥ c j) (7)
γk(j) = softmax(vk(j))",2.2 Reconstruction,[0],[0]
"(8)
dk = ∑|c|
j γk(j)ĥ
c j(vk(j)) (9)
We then construct the predictive probability distribution over reconstructed words using a softmax:
pθ(sk|s1:k−1, c) =",2.2 Reconstruction,[0],[0]
softmax(W 7dk) (10),2.2 Reconstruction,[0],[0]
"In the ASC model there are two sets of parameters, φ and θ, that need to be updated during inference.",2.3 Inference,[0],[0]
"Due to the non-differentiability of the model, the reparameterisation trick of the VAE is not applicable in this case.",2.3 Inference,[0],[0]
"Thus, we use the REINFORCE algorithm (Mnih et al., 2014; Mnih and Gregor, 2014) to reduce the variance of the gradient estimator.
",2.3 Inference,[0],[0]
"The variational lower bound of the ASC model is:
L =Eqφ(c|s)[log pθ(s|c)]−DKL[qφ(c|s)||p(c)]
6 log ∫ qφ(c|s) qφ(c|s) pθ(s|c)p(c)dc = log p(s) (11)
",2.3 Inference,[0],[0]
"Therefore, by optimising the lower bound (Eq. 11), the model balances the selection of keywords for the summaries and the efficacy of the composed compressions, corresponding to the reconstruction error and KL divergence respectively.
",2.3 Inference,[0],[0]
"In practise, the pre-trained language model prior p(c) prefers short sentences for compressions.",2.3 Inference,[0],[0]
"As one of the drawbacks of VAEs, the KL divergence term in the lower bound pushes every sample drawn
2The recurrent parameters of the compressor are not updated by the gradients from the reconstruction model.
from the variational distribution towards the prior.",2.3 Inference,[0],[0]
"Thus acting to regularise the posterior, but also to restrict the learning of the encoder.",2.3 Inference,[0],[0]
"If the estimator keeps sampling short compressions during inference, the LSTM decoder would gradually rely on the contexts from the decoded words instead of the information provided by the compressions, which does not yield the best performance on sentence compression.
",2.3 Inference,[0],[0]
"Here, we introduce a co-efficient λ to scale the learning signal of the KL divergence: L=Eqφ(c|s)[log pθ(s|c)]−λDKL[qφ(c|s)||p(c)]",2.3 Inference,[0],[0]
"(12)
",2.3 Inference,[0],[0]
"Although we are not optimising the exact variational lower bound, the ultimate goal of learning an effective compression model is mostly up to the reconstruction error.",2.3 Inference,[0],[0]
"In Section 6, we empirically apply λ = 0.1 for all the experiments on ASC model.",2.3 Inference,[0],[0]
"Interestingly, λ controls the compression rate of the sentences which can be a good point to be explored in future work.
",2.3 Inference,[0],[0]
"During the inference, we have different strategies for updating the parameters of φ and θ.",2.3 Inference,[0],[0]
"For the parameters θ in the reconstruction model, we directly update them by the gradients:
∂L ∂θ = Eqφ(c|s)[ ∂ log pθ(s|c) ∂θ",2.3 Inference,[0],[0]
"]
≈ 1 M
∑
m
∂ log pθ(s|c(m))",2.3 Inference,[0],[0]
"∂θ
(13)
",2.3 Inference,[0],[0]
"where we draw M samples c(m) ∼ qφ(c|s) independently for computing the stochastic gradients.
",2.3 Inference,[0],[0]
"For the parameters φ in the compression model, we firstly define the learning signal,
l(s, c) = log pθ(s|c)− λ(log qφ(c|s)− log p(c)).
",2.3 Inference,[0],[0]
"Then, we update the parameters φ by:
∂L ∂φ = Eqφ(c|s)[l(s, c) ∂ log qφ(c|s) ∂φ ]
≈ 1 M
∑
m
[l(s, c(m)) ∂ log qφ(c (m)|s) ∂φ ] (14)
",2.3 Inference,[0],[0]
"However, this gradient estimator has a big variance because the learning signal l(s, c(m)) relies on the samples from qφ(c|s).",2.3 Inference,[0],[0]
"Therefore, following the REINFORCE algorithm, we introduce two baselines b and b(s), the centred learning signal and inputdependent baseline respectively, to help reduce the variance.
",2.3 Inference,[0],[0]
"Here, we build an MLP to implement the inputdependent baseline b(s).",2.3 Inference,[0],[0]
"During training, we learn the two baselines by minimising the expectation:
Eqφ(c|s)[(l(s, c)− b− b(s))2].",2.3 Inference,[0],[0]
"(15)
Hence, the gradients w.r.t. φ are derived as,
∂L ∂φ",2.3 Inference,[0],[0]
"≈ 1 M
∑
m
(l(s, c(m))−b−b(s))∂ log qφ(c (m)|s)
∂φ
(16) which is basically a likelihood-ratio estimator.",2.3 Inference,[0],[0]
"In neural variational inference, the effectiveness of training largely depends on the quality of the inference network gradient estimator.",3 Forced-attention Sentence Compression,[0],[0]
"Although we introduce a biased estimator by using pointer networks, it is still very difficult for the compression model to generate reasonable natural language sentences at the early stage of learning, which results in
high-variance for the gradient estimator.",3 Forced-attention Sentence Compression,[0],[0]
"Here, we introduce our supervised forced-attention sentence compression (FSC) model to teach the compression model to generate coherent compressed sentences.
",3 Forced-attention Sentence Compression,[0],[0]
"Neither directly replicating the pointer network of ASC model, nor using a typical sequence-tosequence model, the FSC model employs a forceattention strategy (Figure 2) that encourages the compressor to select words appearing in the source sentence but keeps the original full output vocabulary V .",3 Forced-attention Sentence Compression,[0],[0]
The force-attention strategy is basically a combined pointer network that chooses whether to select a word from the source sentence s or to predict a word from V at each recurrent state.,3 Forced-attention Sentence Compression,[0],[0]
"Hence, the combined pointer network learns to copy the source words while predicting the word sequences of compressions.",3 Forced-attention Sentence Compression,[0],[0]
"By sharing the pointer networks between the ASC and FSC model, the biased estimator obtains further positive biases by training on a small set of labelled source-compression pairs.
",3 Forced-attention Sentence Compression,[0],[0]
"Here, the FSC model makes use of the compression model (Eq. 1 to 4) in the ASC model,
αj =softmax(uj), (17)
where αj(i), i ∈ (1, . . .",3 Forced-attention Sentence Compression,[0],[0]
", |s|) denotes the probability of selecting si as the prediction for cj .
",3 Forced-attention Sentence Compression,[0],[0]
"On the basis of the pointer network, we further introduce the probability of predicting cj that is selected from the full vocabulary,
βj = softmax(Wh c j), (18)
where βj(w), w ∈ (1, . . .",3 Forced-attention Sentence Compression,[0],[0]
", |V |) denotes the probability of selecting the wth from V as the prediction for cj .",3 Forced-attention Sentence Compression,[0],[0]
"To combine these two probabilities in the RNN, we define a selection factor t for each state output, which computes the semantic similarities between the current state and the attention vector,
ηj = ∑|s|
i αj(i)h
e i (19)
tj = σ(η T jMh c j).",3 Forced-attention Sentence Compression,[0],[0]
"(20)
Hence, the probability distribution over compressed words is defined as, p(cj |c1:j−1, s)= { tjαj(i) + (1− tj)βj(cj), cj=si (1− tj)βj(cj), cj 6∈s
(21)
",3 Forced-attention Sentence Compression,[0],[0]
"Essentially, the FSC model is the extended compression model of ASC by incorporating the pointer network with a softmax output layer over the full vocabulary.",3 Forced-attention Sentence Compression,[0],[0]
"So we employ φ to denote the parameters of the FSC model pφ(c|s), which covers the parameters of the variational distribution qφ(c|s).",3 Forced-attention Sentence Compression,[0],[0]
"As the auto-encoding sentence compression (ASC) model grants the ability to make use of an unlabelled dataset, we explore a semi-supervised training framework for the ASC and FSC models.",4 Semi-supervised Training,[0],[0]
"In this scenario we have a labelled dataset that contains source-compression parallel sentences, (s, c) ∈ L, and an unlabelled dataset that contains only source sentences s ∈ U.",4 Semi-supervised Training,[0],[0]
"The FSC model is trained on L so that we are able to learn the compression model by maximising the log-probability,
F = ∑
(c,s)∈L log pφ(c|s).",4 Semi-supervised Training,[0],[0]
"(22)
",4 Semi-supervised Training,[0],[0]
"While the ASC model is trained on U, where we maximise the modified variational lower bound, L= ∑
s∈U (Eqφ(c|s)[log pθ(s|c)]−λDKL[qφ(c|s)||p(c)]).
(23)
",4 Semi-supervised Training,[0],[0]
"The joint objective function of the semi-supervised learning is,
J= ∑
s∈U (Eqφ(c|s)[log pθ(s|c)]−λDKL[qφ(c|s)||p(c)])",4 Semi-supervised Training,[0],[0]
"+ ∑
(c,s)∈L log pφ(c|s).",4 Semi-supervised Training,[0],[0]
"(24)
Hence, the pointer network is trained on both unlabelled data, U, and labelled data, L, by a mixed criterion of REINFORCE and cross-entropy.",4 Semi-supervised Training,[0],[0]
"As one of the typical sequence-to-sequence tasks, sentence-level summarisation has been explored by a series of discriminative encoder-decoder neural models.",5 Related Work,[0],[0]
"Filippova et al. (2015) carries out extractive summarisation via deletion with LSTMs, while Rush et al. (2015) applies a convolutional encoder and an
attentional feed-forward decoder to generate abstractive summarises, which provides the benchmark for the Gigaword dataset.",5 Related Work,[0],[0]
Nallapati et al. (2016) further improves the performance by exploring multiple variants of RNN encoder-decoder models.,5 Related Work,[0],[0]
"The recent works Gulcehre et al. (2016), Nallapati et al. (2016) and Gu et al. (2016) also apply the similar idea of combining pointer networks and softmax output.",5 Related Work,[0],[0]
"However, different from all these discriminative models above, we explore generative models for sentence compression.",5 Related Work,[0],[0]
"Instead of training the discriminative model on a big labelled dataset, our original intuition of introducing a combined pointer networks is to bridge the unsupervised generative model (ASC) and supervised model (FSC) so that we could utilise a large additional dataset, either labelled or unlabelled, to boost the compression performance.",5 Related Work,[0],[0]
"Dai and Le (2015) also explored semi-supervised sequence learning, but in a pure deterministic model focused on learning better vector representations.
",5 Related Work,[0],[0]
Recently variational auto-encoders have been applied in a variety of fields as deep generative models.,5 Related Work,[0],[0]
"In computer vision Kingma and Welling (2014), Rezende et al. (2014), and Gregor et al. (2015) have demonstrated strong performance on the task of image generation and Eslami et al. (2016) proposed variable-sized variational auto-encoders to identify multiple objects in images.",5 Related Work,[0],[0]
"While in natural language processing, there are variants of VAEs on modelling documents (Miao et al., 2016), sentences (Bowman et al., 2015) and discovery of relations (Marcheggiani and Titov, 2016).",5 Related Work,[0],[0]
"Apart from the typical initiations of VAEs, there are also a series of works that employs generative models for supervised learning tasks.",5 Related Work,[0],[0]
"For instance, Ba et al. (2015) learns visual attention for multiple objects by optimising a variational lower bound, Kingma et al. (2014) implements a semi-supervised framework for image classification and Miao et al. (2016) applies a conditional variational approximation in the task of factoid question answering.",5 Related Work,[0],[0]
Dyer et al. (2016) proposes a generative model that explicitly extracts syntactic relationships among words and phrases which further supports the argument that generative models can be a statistically efficient method for learning neural networks from small data.,5 Related Work,[0],[0]
We evaluate the proposed models on the standard Gigaword3 sentence compression dataset.,6.1 Dataset & Setup,[0],[0]
This dataset was generated by pairing the headline of each article with its first sentence to create a source-compression pair.,6.1 Dataset & Setup,[0],[0]
"Rush et al. (2015) provided scripts4 to filter out outliers, resulting in roughly 3.8M training pairs, a 400K validation set, and a 400K test set.",6.1 Dataset & Setup,[0],[0]
"In the following experiments all models are trained on the training set with different data sizes5 and tested on a 2K subset, which is identical to the test set used by Rush et al. (2015) and Nallapati et al. (2016).",6.1 Dataset & Setup,[0],[0]
"We decode the sentences by k = 5 Beam search and test with full-length Rouge score.
",6.1 Dataset & Setup,[0],[0]
"For the ASC and FSC models, we use 256 for the dimension of both hidden units and lookup tables.",6.1 Dataset & Setup,[0],[0]
"In the ASC model, we apply a 3-layer bidirectional RNN with skip connections as the encoder, a 3-layer RNN pointer network with skip connections as the compressor, and a 1-layer vanilla RNN with soft attention as the decoder.",6.1 Dataset & Setup,[0],[0]
The language model prior is trained on the article sentences of the full training set using a 3-layer vanilla RNN with 0.5 dropout.,6.1 Dataset & Setup,[0],[0]
"To lower the computational cost, we apply different vocabulary sizes for encoder and compressor (119,506 and 68,897) which corresponds to the settings of Rush et al. (2015).",6.1 Dataset & Setup,[0],[0]
"Specifically, the vocabulary of the decoder is filtered by taking the most frequent 10,000 words from the vocabulary of the encoder, where the rest of the words are tagged as ‘<unk>’.",6.1 Dataset & Setup,[0],[0]
"In further consideration of efficiency, we use only one sample for the gradient estimator.",6.1 Dataset & Setup,[0],[0]
"We optimise the model by Adam (Kingma and Ba, 2015) with a 0.0002 learning rate and 64 sentences per batch.",6.1 Dataset & Setup,[0],[0]
The model converges in 5 epochs.,6.1 Dataset & Setup,[0],[0]
"Except for the pretrained language model, we do not use dropout or embedding initialisation for ASC and FSC models.",6.1 Dataset & Setup,[0],[0]
The first set of experiments evaluate the models on extractive summarisation.,6.2 Extractive Summarisation,[0],[0]
"Here, we denote the joint
3https://catalog.ldc.upenn.edu/LDC2012T21 4https://github.com/facebook/NAMAS 5The hyperparameters where tuned on the validation set to maximise the perplexity of the summaries rather than the reconstructed source sentences.
models by ASC+FSC1 and ASC+FSC2 where ASC is trained on unlabelled data and FSC is trained on labelled data.",6.2 Extractive Summarisation,[0],[0]
"The ASC+FSC1 model employs equivalent sized labelled and unlabelled datasets, where the article sentences of the unlabelled data are the same article sentences in the labelled data, so there is no additional unlabelled data applied in this case.",6.2 Extractive Summarisation,[0],[0]
"The ASC+FSC2 model employs the full unlabelled dataset in addition to the existing labelled dataset, which is the true semi-supervised setting.
",6.2 Extractive Summarisation,[0],[0]
Table 1 presents the test Rouge score on extractive compression.,6.2 Extractive Summarisation,[0],[0]
We can see that the ASC+FSC1 model achieves significant improvements on F-1 scores when compared to the supervised FSC model only trained on labelled data.,6.2 Extractive Summarisation,[0],[0]
"Moreover, fixing the labelled data size, the ASC+FSC2 model achieves better performance by using additional unlabelled data than the ASC+FSC1 model, which means the semi-supervised learning works in this scenario.",6.2 Extractive Summarisation,[0],[0]
"Interestingly, learning on the unlabelled data largely increases the precisions (though the recalls do not benefit from it) which leads to significant improvements on the F-1 Rouge scores.",6.2 Extractive Summarisation,[0],[0]
"And surprisingly, the extractive ASC+FSC1 model trained on full labelled data outperforms the abstractive NABS (Rush et al., 2015) baseline model (in Table 4).",6.2 Extractive Summarisation,[0],[0]
The second set of experiments evaluate performance on abstractive summarisation (Table 2).,6.3 Abstractive Summarisation,[0],[0]
"Consistently, we see that adding the generative objective to the discriminative model (ASC+FSC1) results in a significant boost on all the Rouge scores, while employing extra unlabelled data increase performance
further (ASC+FSC2).",6.3 Abstractive Summarisation,[0],[0]
"This validates the effectiveness of transferring the knowledge learned on unlabelled data to the supervised abstractive summarisation.
",6.3 Abstractive Summarisation,[0],[0]
"In Figure 3, we present the validation perplexity to compare the abilities of the three models to learn the compression languages.",6.3 Abstractive Summarisation,[0],[0]
"The ASC+FSC1(red) employs the same dataset for unlabelled and labelled training, while the ASC+FSC2(black) employs the full unlabelled dataset.",6.3 Abstractive Summarisation,[0],[0]
"Here, the joint ASC+FSC1 model obtains better perplexities than the single discriminative FSC model, but there is not much difference between ASC+FSC1 and ASC+FSC2 when the size of the labelled dataset grows.",6.3 Abstractive Summarisation,[0],[0]
"From the perspective of language modelling, the generative ASC model indeed helps the discriminative model learn to generate good summary sentences.",6.3 Abstractive Summarisation,[0],[0]
"Table 3 displays the validation perplexities of the benchmark models, where the joint ASC+FSC1 model trained on the full labelled and unlabelled datasets performs the best on modelling compression languages.
",6.3 Abstractive Summarisation,[0],[0]
Table 4 compares the test Rouge score on abstractive summarisation.,6.3 Abstractive Summarisation,[0],[0]
"Encouragingly, the semisupervised model ASC+FSC2 outperforms the baseline model NABS when trained on 500K supervised pairs, which is only about an eighth of the supervised data.",6.3 Abstractive Summarisation,[0],[0]
"In Nallapati et al. (2016), the authors exploit the full limits of discriminative RNN encoderdecoder models by incorporating a sampled softmax, expanded vocabulary, additional lexical features, and combined pointer networks6, which yields the best performance listed in Table 4.",6.3 Abstractive Summarisation,[0],[0]
"However, when all the data is employed with the mixed ob-
6The idea of the combined pointer networks is similar to the FSC model, but the implementations are slightly different.
",6.3 Abstractive Summarisation,[0],[0]
"jective ASC+FSC1 model, the result is significantly better than this previous state-of-the-art.",6.3 Abstractive Summarisation,[0],[0]
"As the semisupervised ASC+FSC2 model can be trained on unlimited unlabelled data, there is still significant space left for further performance improvements.
",6.3 Abstractive Summarisation,[0],[0]
Table 5 presents the examples of the compression sentences decoded by the joint model ASC+FSC1 and the FSC model trained on the full dataset.,6.3 Abstractive Summarisation,[0],[0]
"From the perspective of generative models, a significant contribution of our work is a process for reducing variance for discrete sampling-based variational inference.",7 Discussion,[0],[0]
"The first step is to introduce two baselines in the control variates method due to the fact that the reparameterisation trick is not applica-
ble for discrete latent variables.",7 Discussion,[0],[0]
However it is the second step of using a pointer network as the biased estimator that makes the key contribution.,7 Discussion,[0],[0]
"This results in a much smaller state space, bounded by the length of the source sentence (mostly between 20 and 50 tokens), compared to the full vocabulary.",7 Discussion,[0],[0]
The final step is to apply the FSC model to transfer the knowledge learned from the supervised data to the pointer network.,7 Discussion,[0],[0]
This further reduces the sampling variance by acting as a sort of bootstrap or constraint on the unsupervised latent space which could encode almost anything but which thus becomes biased towards matching the supervised distribution.,7 Discussion,[0],[0]
"By using these variance reduction methods, the ASC model is able to carry out effective variational inference for the latent language model so that it learns to summarise the sentences from the large unlabelled training data.
",7 Discussion,[0],[0]
"In a different vein, according to the reinforcement learning interpretation of sequence level training (Ranzato et al., 2016), the compression model of the ASC model acts as an agent which iteratively generates words (takes actions) to compose the com-
pression sentence and the reconstruction model acts as the reward function evaluating the quality of the compressed sentence which is provided as a reward signal.",7 Discussion,[0],[0]
Ranzato et al. (2016) presents a thorough empirical evaluation on three different NLP tasks by using additional sequence-level reward (BLEU and Rouge-2) to train the models.,7 Discussion,[0],[0]
"In the context of this paper, we apply a variational lower bound (mixed reconstruction error and KL divergence regularisation) instead of the explicit Rouge score.",7 Discussion,[0],[0]
Thus the ASC model is granted the ability to explore unlimited unlabelled data resources.,7 Discussion,[0],[0]
In addition we introduce a supervised FSC model to teach the compression model to generate stable sequences instead of starting with a random policy.,7 Discussion,[0],[0]
"In this case, the pointer network that bridges the supervised and unsupervised model is trained by a mixed criterion of REINFORCE and cross-entropy in an incremental learning framework.",7 Discussion,[0],[0]
"Eventually, according to the experimental results, the joint ASC and FSC model is able to learn a robust compression model by exploring both labelled and unlabelled data, which outperforms the other single discriminative compression models that are only trained by cross-entropy reward signal.",7 Discussion,[0],[0]
In this paper we have introduced a generative model for jointly modelling pairs of sequences and evaluated its efficacy on the task of sentence compression.,8 Conclusion,[0],[0]
The variational auto-encoding framework provided an effective inference algorithm for this approach and also allowed us to explore combinations of discriminative (FSC) and generative (ASC) compression models.,8 Conclusion,[0],[0]
The evaluation results show that supervised training of the combination of these models improves upon the state-of-the-art performance for the Gigaword compression dataset.,8 Conclusion,[0],[0]
When we train the supervised FSC model on a small amount of labelled data and the unsupervised ASC model on a large set of unlabelled data the combined model is able to outperform previously reported benchmarks trained on a great deal more supervised data.,8 Conclusion,[0],[0]
These results demonstrate that we are able to model language as a discrete latent variable in a variational auto-encoding framework and that the resultant generative model is able to effectively exploit both supervised and unsupervised data in sequence-to-sequence tasks.,8 Conclusion,[0],[0]
In this work we explore deep generative models of text in which the latent representation of a document is itself drawn from a discrete language model distribution.,abstractText,[0],[0]
We formulate a variational auto-encoder for inference in this model and apply it to the task of compressing sentences.,abstractText,[0],[0]
"In this application the generative model first draws a latent summary sentence from a background language model, and then subsequently draws the observed sentence conditioned on this latent summary.",abstractText,[0],[0]
In our empirical evaluation we show that generative formulations of both abstractive and extractive compression yield state-of-the-art results when trained on a large amount of supervised data.,abstractText,[0],[0]
"Further, we explore semi-supervised compression scenarios where we show that it is possible to achieve performance competitive with previously proposed supervised models while training on a fraction of the supervised data.",abstractText,[0],[0]
Language as a Latent Variable: Discrete Generative Models for Sentence Compression,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1928–1937 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1928",text,[0],[0]
"The recent years have seen an increased interest as well as rapid progress in semantic parsing and surface realization based on graph-structured semantic representations, e.g. Abstract Meaning Representation (AMR; Banarescu et al., 2013), Elementary Dependency Structure (EDS; Oepen and Lønning, 2006) and Depedendency-based Minimal Recursion Semantics (DMRS; Copestake, 2009).",1 Introduction,[0],[0]
"Still underexploited is a formal framework for manipulating graphs that parallels automata, tranducers or formal grammars for strings and trees.",1 Introduction,[0],[0]
Two such formalisms have recently been proposed and applied for NLP.,1 Introduction,[0],[0]
"One is graph grammar, e.g. Hyperedge Replacement Gram-
mar (HRG; Ehrig et al., 1999).",1 Introduction,[0],[0]
"The other is DAG automata, originally studied by Kamimura and Slutzki (1982) and extended by Chiang et al. (2018).",1 Introduction,[0],[0]
"In this paper, we study DAG transducers in depth, with the goal of building accurate, efficient yet robust natural language generation (NLG) systems.
",1 Introduction,[0],[0]
"The meaning representation studied in this work is what we call type-logical semantic graphs, i.e. semantic graphs grounded under type-logical semantics (Carpenter, 1997), one dominant theoretical framework for modeling natural language semantics.",1 Introduction,[0],[0]
"In this framework, adjuncts, such as adjective and adverbal phrases, are analyzed as (higher-order) functors, the function of which is to consume complex arguments (Kratzer and Heim, 1998).",1 Introduction,[0],[0]
"In the same spirit, generalized quantifiers, prepositions and function words in many languages other than English are also analyzed as higher-order functions.",1 Introduction,[0],[0]
"Accordingly, all the linguistic elements are treated as roots in type-logical semantic graphs, such as EDS and DMRS.",1 Introduction,[0],[0]
"This makes the typological structure quite flat rather than hierachical, which is an essential distinction between natural language semantics and syntax.
",1 Introduction,[0],[0]
"To the best of our knowledge, the only existing DAG transducer for NLG is the one proposed by Quernheim and Knight (2012).",1 Introduction,[0],[0]
Quernheim and Knight introduced a DAG-to-tree transducer that can be applied to AMR-to-text generation.,1 Introduction,[0],[0]
"This transducer is designed to handle hierarchical structures with limited reentrencies, and it is unsuitable for meaning graphs transformed from type-logical semantics.",1 Introduction,[0],[0]
"Furthermore, Quernheim and Knight did not describe how to acquire graph recognition and transduction rules from linguistic data, and reported no result of practical generation.",1 Introduction,[0],[0]
"It is still unknown to what extent a DAG transducer suits realistic NLG.
",1 Introduction,[0],[0]
"The design for string and tree transducers
(Comon et al., 1997) focuses on not only the logic of the computation for a new data structure, but also the corresponding control flow.",1 Introduction,[0],[0]
This is very similar the imperative programming paradigm: implementing algorithms with exact details in explicit steps.,1 Introduction,[0],[0]
"This design makes it very difficult to transform a type-logical semantic graph into a string, due to the fact their internal structures are highly diverse.",1 Introduction,[0],[0]
"We borrow ideas from declarative programming, another programming paradigm, which describes what a program must accomplish, rather than how to accomplish it.",1 Introduction,[0],[0]
We propose a novel DAG transducer to perform graphto-program transformation (§3).,1 Introduction,[0],[0]
"The input of our transducer is a semantic graph, while the output is a program licensed by a declarative programming language rather than linguistic structures.",1 Introduction,[0],[0]
"By executing such a program, we can easily get a surface string.",1 Introduction,[0],[0]
"This idea can be extended to other types of linguistic structures, e.g. syntactic trees or semantic representations of another language.
",1 Introduction,[0],[0]
"We conduct experiments on richly detailed semantic annotations licensed by English Resource Grammar (ERG; Flickinger, 2000).",1 Introduction,[0],[0]
"We introduce a principled method to derive transduction rules from DeepBank (Flickinger et al., 2012).",1 Introduction,[0],[0]
"Furthermore, we introduce a fine-to-coarse strategy to ensure that at least one sentence is generated for any input graph.",1 Introduction,[0],[0]
"Taking EDS graphs, a variable-free ERS format, as input, our NLG system achieves a BLEU-4 score of 68.07.",1 Introduction,[0],[0]
"On average, it produces more than 5 sentences in a second on an x86 64 GNU/Linux platform with two Intel Xeon E5-2620 CPUs.",1 Introduction,[0],[0]
"Since the data for experiments is newswire data, i.e. WSJ sentences from PTB (Marcus et al., 1993), the input graphs are quite large on average.",1 Introduction,[0],[0]
"The remarkable accuracy, efficiency and robustness demonstrate the feasibility of applying a DAG transducer to resolve NLG, as well as the effectiveness of our transducer design.",1 Introduction,[0],[0]
"A node-labeled simple graph over alphabet Σ is a triple G = (V,E, ℓ), where V is a finite set of nodes, E ⊆ V × V is an finite set of edges and ℓ : V → Σ is a labeling function.",2.1 Preliminaries,[0],[0]
"For a node v ∈ V , sets of its incoming and outgoing edges are denoted by in(v) and out(v) respectively.",2.1 Preliminaries,[0],[0]
"For an edge e ∈ E, its source node and target node are denoted by src(e) and tar(e) respectively.",2.1 Preliminaries,[0],[0]
"Gen-
erally speaking, a DAG is a directed acyclic simple graph.",2.1 Preliminaries,[0],[0]
"Different from trees, a DAG allows nodes to have multiple incoming edges.",2.1 Preliminaries,[0],[0]
"In this paper, we only consider DAGs that are unordered, node-labeled, multi-rooted1 and connected.
",2.1 Preliminaries,[0],[0]
"Conceptual graphs, including AMR and EDS, are both node-labeled and edge-labeled.",2.1 Preliminaries,[0],[0]
"It seems that without edge labels, a DAG is inadequate, but this problem can be solved easily by using the strategies introduced in (Chiang et al., 2018).",2.1 Preliminaries,[0],[0]
Take a labeled edge proper q BV−→ named for example2.,2.1 Preliminaries,[0],[0]
We can represent the same information by replacing it with two unlabeled edges and a new labeled node: proper q→ BV→ named.,2.1 Preliminaries,[0],[0]
"DAG automata are the core engines of graph transducers (Bohnet and Wanner, 2010; Quernheim and Knight, 2012).",2.2 Previous Work,[0],[0]
"In this work, we adopt Chiang et al. (2018)’s design and define a weighted DAG automaton as a tuple M = ⟨Σ, Q, δ,K⟩:
• Σ is an alphabet of node labels.
",2.2 Previous Work,[0],[0]
"• Q is a finite set of states.
",2.2 Previous Work,[0],[0]
"• (K,⊕,⊗, 0, 1) is a semiring of weights.
",2.2 Previous Work,[0],[0]
• δ,2.2 Previous Work,[0],[0]
:,2.2 Previous Work,[0],[0]
"Θ → K\{0} is a weight function that assigns nonzero weights to a finite transition set Θ. Every transition t ∈ Θ is of the form
{q1, · · · , qm} σ−→ {r1, · · · , rn}
where qi and rj are states in Q. A transition t getsm states on the incoming edges of a node and puts n states on the outgoing edges.",2.2 Previous Work,[0],[0]
"A transition that does not belong to Θ recieves a weight of zero.
",2.2 Previous Work,[0],[0]
"A run ofM on a DAGD = ⟨V,E, ℓ⟩ is an edge labeling function ρ :",2.2 Previous Work,[0],[0]
"E → Q. The weight of a run ρ (denoted as δ′(ρ)) is the product of all weights of local transitions:
δ′(ρ) = ⊗ v∈V δ",2.2 Previous Work,[0],[0]
"( ρ(in(v)) ℓ(v)−−→ ρ(out(v)) )
",2.2 Previous Work,[0],[0]
"Here, for a function f , we use f({a1, · · · , an}) to represent {f(a1), · · · , f(an)}.",2.2 Previous Work,[0],[0]
"If K is a boolean semiring, the automata fall backs to an unweighted
1A node without incoming edges is called root and a node without outgoing edges is called leaf.
",2.2 Previous Work,[0],[0]
"2 proper q and named are node labels, while BV is the edge label.
",2.2 Previous Work,[0],[0]
DAG automata or DAG acceptor.,2.2 Previous Work,[0],[0]
"A accepting run or recognition is a run, the weight of which is 1, meaning true.",2.2 Previous Work,[0],[0]
The DAG automata defined above can only be used for recognition.,2.3 Challenges,[0],[0]
"In order to generate sentences from semantic graphs, we need DAG transducers.",2.3 Challenges,[0],[0]
A DAG transducer is a DAG automata-augmented computation model for transducing well-formed DAGs to other data structures.,2.3 Challenges,[0],[0]
Quernheim and Knight (2012) focused on feature structures and introduced a DAG-to-Tree transducer to perform graph-to-tree transformation.,2.3 Challenges,[0],[0]
The input of their transducer is limited to single-rooted DAGs.,2.3 Challenges,[0],[0]
"When the labels of the leaves of an output tree in order are interpreted as words, this transducer can be applied to generate natural language sentences.
",2.3 Challenges,[0],[0]
"When applying Quernheim and Knight’s DAGto-Tree transducer on type-logic semantic graphs, e.g. ERS, there are some significant problems.",2.3 Challenges,[0],[0]
"First, it lacks the ability to reverse the direction of edges during transduction because it is difficult to keep acyclicy anymore if edge reversing is allowed.",2.3 Challenges,[0],[0]
"Second, it cannot handle multiple roots.",2.3 Challenges,[0],[0]
But we have discussed and reached the conclusion that multi-rootedness is a necessary requirement for representing type-logical semantic graphs.,2.3 Challenges,[0],[0]
It is difficult to decide which node should be the tree root during a ‘top-down’ transduction and it is also difficult to merge multiple unconnected nodes into one during a ‘bottom-up’ transduction.,2.3 Challenges,[0],[0]
"At the risk of oversimplifying, we argue that the function of the existing DAG-to-Tree transducer is to transform a hierachical structure into another hierarchical structure.",2.3 Challenges,[0],[0]
"Since the type-local semantic graphs are so flat, it is extremely difficult to adopt Quernheim and Knight’s design to handle such graphs.",2.3 Challenges,[0],[0]
"Third, there are unconnected nodes with direct dependencies, meaning that their correpsonding surface expressions appear to be very close.",2.3 Challenges,[0],[0]
The conceptual nodes even x deg and steep a 1 in Figure 4 are an example.,2.3 Challenges,[0],[0]
It is extremely difficult for the DAG-to-Tree transducer to handle this situation.,2.3 Challenges,[0],[0]
"In this paper, we introduce a design of transducers that can perform structure transformation towards
many data structures, including but not limited to trees.",3.1 Basic Idea,[0],[0]
"The basic idea is to give up the rewritting method to directly generate a new data structure piece by piece, while recognizing an input DAG.",3.1 Basic Idea,[0],[0]
"Instead, our transducer obtains target structures based on side effects of DAG recognition.",3.1 Basic Idea,[0],[0]
"The output of our transducer is no longer the target data structure itself, e.g. a tree or another DAG, and is now a program, i.e. a bunch of statements licensed by a particular declarative programming language.",3.1 Basic Idea,[0],[0]
"The target structures are constructed by executing such programs.
",3.1 Basic Idea,[0],[0]
"Since our main concern of this paper is natural language generation, we take strings, namely sequences of words, as our target structures.",3.1 Basic Idea,[0],[0]
"In this section, we introduce an extremely simple programming language for string concatenation and then details about how to leverage the power of declarative programming to perform DAG-tostring transformation.",3.1 Basic Idea,[0],[0]
"The syntax in the BNF format of our declarative programming language, denoted as Lc, for string calculation is:
⟨program⟩ ::= ⟨statement⟩∗ ⟨statement⟩ ::= ⟨variable⟩ = ⟨expr⟩
⟨expr⟩ ::= ⟨variable⟩",3.2 A Declarative Programming Language,[0],[0]
"| ⟨string⟩ | ⟨expr⟩ + ⟨expr⟩
Here a string is a sequence of characters selected from an alphabet (denoted as Σout) and can be empty (denoted as ϵ).",3.2 A Declarative Programming Language,[0],[0]
"The semantics of ‘=’ is value assignment, while the semantics of ‘+’ is string concatenation.",3.2 A Declarative Programming Language,[0],[0]
The value of variables are strings.,3.2 A Declarative Programming Language,[0],[0]
"For every statement, the left hand side is a variable and the right hand side is a sequence of string literals and variables that are combined through ‘+’.",3.2 A Declarative Programming Language,[0],[0]
"Equation (1) presents an exmaple program licensed by this language.
",3.2 A Declarative Programming Language,[0],[0]
"S = x21 + want+ x11
x11 = to+ go
x21 = x41 + John
x41 = ϵ
(1)
After solving these statements, we can query the values of all variables.",3.2 A Declarative Programming Language,[0],[0]
"In particular, we are interested in S, which is related to the desired natural language expression John want to go3.
3",3.2 A Declarative Programming Language,[0],[0]
The expression is a sequence of lemmas rather than inflected words.,3.2 A Declarative Programming Language,[0],[0]
"Refer to §4 for more details.
",3.2 A Declarative Programming Language,[0],[0]
"Using the relation between the variables, we can easily convert the statements in (1) to a rooted tree.",3.2 A Declarative Programming Language,[0],[0]
The result is shown in Figure 1.,3.2 A Declarative Programming Language,[0],[0]
"This tree is significantly different from the target structures discussed by Quernheim and Knight (2012) or other normal tree transducers (Comon et al., 1997).",3.2 A Declarative Programming Language,[0],[0]
This tree represents calculation to solve the program.,3.2 A Declarative Programming Language,[0],[0]
Constructing such internal trees is an essential function of the compiler of our programming language.,3.2 A Declarative Programming Language,[0],[0]
We introduce our DAG transducer using a simple example.,3.3 Informal Illustration,[0],[0]
"Figure 2 shows the original input graph D = (V,E, ℓ).",3.3 Informal Illustration,[0],[0]
"Without any loss of generality, we remove edge labels.",3.3 Informal Illustration,[0],[0]
Table 1 lists the rule set—R—for this example.,3.3 Informal Illustration,[0],[0]
Every row represents an applicable transduction rule that consists of two parts.,3.3 Informal Illustration,[0],[0]
"The left column is the recognition part displayed in the form I σ−→ O, where I , O and σ decode the state set of incoming edges, the state set of outgoing edges and the node label respectively.",3.3 Informal Illustration,[0],[0]
The right column is the generation part which consists of (multiple) templates of statements licensed by the programming language defined in the previous section.,3.3 Informal Illustration,[0],[0]
"In practice, two different rules may have a same recognition part but different generation parts.
",3.3 Informal Illustration,[0],[0]
"Every state q is of the form l(n, d) where l is the finite state label, n is the count of possible variables related to q, and d denotes the direction.",3.3 Informal Illustration,[0],[0]
"The value of d can only be r (reversed), u (unchanged) or e(empty).",3.3 Informal Illustration,[0],[0]
"Variable vl(j,d) represents the jth (1 ≤ j ≤ n) variable related to state q.",3.3 Informal Illustration,[0],[0]
"For example, vX(2,r) means the second variable of state X(3,r).",3.3 Informal Illustration,[0],[0]
"There are two special variables: S, which corresponds to the whole sentence and L, which corresponds to the output string associated to current node label.",3.3 Informal Illustration,[0],[0]
It is reasonable to assume that there exists a function ψ :,3.3 Informal Illustration,[0],[0]
"Σ → Σ∗out that maps a particular node label, i.e. concept, to a surface string.",3.3 Informal Illustration,[0],[0]
"Therefore L is determined by ψ.
",3.3 Informal Illustration,[0],[0]
"Now we are ready to apply transduction rules to
translateD into a string.",3.3 Informal Illustration,[0],[0]
"The transduction consists of two steps:
Recognition The goal of this step is to find an edge labeling function ρ : E → Q which satisfies that for every node v, ρ(in(v))
ℓ(v)−−→ ρ(out(v)) matches the recognition part of a rule in R. The recognition result is shown in Figure 3.",3.3 Informal Illustration,[0],[0]
"The red dashed edges in Figure 3 make up an intermediate graph T (ρ), which is a subgraph of D if edge direction is not taken into account.",3.3 Informal Illustration,[0],[0]
"Sometimes, T (ρ) paralles the syntactic structure of an output sentence.",3.3 Informal Illustration,[0],[0]
"For a labeling function ρ, we can construct intermediate graph T (ρ) by checking the direction parameter of every edge state.",3.3 Informal Illustration,[0],[0]
"For an edge e = (u, v) ∈ E, if the direction of ρ(e) is r, then (v, u) is in T (ρ).",3.3 Informal Illustration,[0],[0]
"If the direction is u, then (u, v) is in T (ρ).",3.3 Informal Illustration,[0],[0]
"If the direction is e, neither (u, v) nor (v, u) is included.",3.3 Informal Illustration,[0],[0]
The recognition process is slightly different from the one in Chiang et al. (2018).,3.3 Informal Illustration,[0],[0]
"Since incoming edges with an Empty(0,e) state carry no semantic information, they will be ignored during recognition.",3.3 Informal Illustration,[0],[0]
"For example, in Figure 3, we will only use e2 and e4 to match transducation rules for node named(John).
",3.3 Informal Illustration,[0],[0]
Instantiation We use rule(v) to denotes the rule used on node v. Assume s is the generation part of rule(v).,3.3 Informal Illustration,[0],[0]
"For every edge ei adjacent to v, assume ρ(ei) = l(n, d).",3.3 Informal Illustration,[0],[0]
"We replace L with ψ(ℓ(v)) and replace every occurrence of vl(j,d) in s with a new variable xij (1 ≤ j ≤ n).",3.3 Informal Illustration,[0],[0]
"Then we
get a newly generated expression for v. For example, node want v 1 is recognized using Rule 2, so we replace vNP(1,u) with x21, vVP(1,u) with x11 and L with want.",3.3 Informal Illustration,[0],[0]
"After instantiation, we get all the statements in Equation (1).
",3.3 Informal Illustration,[0],[0]
Our transducer is suitable for type-logical semantic graphs.,3.3 Informal Illustration,[0],[0]
Because declarative programming brings in more freedom for graph transduction.,3.3 Informal Illustration,[0],[0]
We can arrange the variables in almost any order without regard to the edge directions in original graphs.,3.3 Informal Illustration,[0],[0]
"Meanwhile, the multi-rooted problem can be solved easily because the generation is based on side effects.",3.3 Informal Illustration,[0],[0]
We do not need to decide which node is the tree root.,3.3 Informal Illustration,[0],[0]
"The formal definition of our DAG transducer described above is a tuple M = (Σ, Q,R,w, V, S) where:
• Σ is an alphabet of node labels.
",3.4 Definition,[0],[0]
• Q is a finite set of edge states.,3.4 Definition,[0],[0]
"Every state q ∈ Q is of the form l(n, d) where l is the state label, n is the variable count and d is the direction of state which can be r, u or e.
• R is a finite set of rules.",3.4 Definition,[0],[0]
"Every rule is of the form I σ−→ ⟨O,E⟩. E can be any kind of statement in a declarative programming language.",3.4 Definition,[0],[0]
It is called the generation part.,3.4 Definition,[0],[0]
"I , σ and O have the same meanings as they do in the previous section and they are called the recognition part.
",3.4 Definition,[0],[0]
• w is a score function.,3.4 Definition,[0],[0]
"Given a particular run and an anchor node,w assigns a score to measure the preference for a particular rule at this anchor node.
",3.4 Definition,[0],[0]
"• V is the set of parameterized variables that can be used in every expression.
",3.4 Definition,[0],[0]
"• S ∈ V is a distinguished, global variable.",3.4 Definition,[0],[0]
It is like the ‘goal’ of a program.,3.4 Definition,[0],[0]
Different languages exhibit different morphosyntactic and syntactico-semantic properties.,4 DAG Transduction-based NLG,[0],[0]
"For example, Russian and Arabic are morphologically-rich languages and heavily utilize grammatical markers to indicate grammatical as well as semantic functions.",4 DAG Transduction-based NLG,[0],[0]
"On the contrary, Chinese, as an analytic language, encodes grammatical and semantic information in a highly configurational rather than either inflectional or derivational way.",4 DAG Transduction-based NLG,[0],[0]
Such differences affects NLG significantly.,4 DAG Transduction-based NLG,[0],[0]
"Considering generating Chinese sentences, it seems sufficient to employ our DAG transducer to obtain a sequence of lemmas, since no morpholical production is needed.",4 DAG Transduction-based NLG,[0],[0]
"But for morphologically-rich languages, we do need to model complex morphological changes.
",4 DAG Transduction-based NLG,[0],[0]
"To unify a general framework for DAG transduction-based NLG, we propose a two-step strategy to achive meaning-to-text transformation.
",4 DAG Transduction-based NLG,[0],[0]
"• In the first phase, we are concerned with syntactico-semantic properties and utilize our DAG transducer to translate a semantic graph into sequential lemmas.",4 DAG Transduction-based NLG,[0],[0]
"Information such as tense, apsects, gender, etc. is attached to anchor lemmas.",4 DAG Transduction-based NLG,[0],[0]
"Actually, our transducer generates “want.",4 DAG Transduction-based NLG,[0],[0]
PRES” rather than “wants”.,4 DAG Transduction-based NLG,[0],[0]
"Here, “PRES” indicates a particular tense.
",4 DAG Transduction-based NLG,[0],[0]
"• In the second phase, we are concerned with morpho-syntactic properties and utilize a neural sequence-to-sequence model to obtain final surface strings from the outputs of the DAG transducer.",4 DAG Transduction-based NLG,[0],[0]
We present an empirical study on the feasibility of DAG transduction-based NLG.,5 Inducing Transduction Rules,[0],[0]
"We focus on
variable-free MRS representations, namely EDS (Oepen and Lønning, 2006).",5 Inducing Transduction Rules,[0],[0]
"The data set used in this work is DeepBank 1.1 (Flickinger et al., 2012).",5 Inducing Transduction Rules,[0],[0]
"In order to generate reasonable strings, three constraints must be kept during transduction.",5.1 EDS-specific Constraints,[0],[0]
"First, for a rule I σ−→ ⟨O,E⟩, a state with direction u in I or a state with direction r in O is called head state and its variables are called head variables.",5.1 EDS-specific Constraints,[0],[0]
"For example, the head state of rule 3 in Table 1 is VP(1,u) and the head state of rule 2 is DET(1,r).",5.1 EDS-specific Constraints,[0],[0]
There is at most one head state in a rule and only head variables or S can be the left sides of statements.,5.1 EDS-specific Constraints,[0],[0]
"If there is no head state, we assign the global S as its head.",5.1 EDS-specific Constraints,[0],[0]
"Otherwise, the number of statements is equal to the number of head variables and each statement has a distinguished left side variable.",5.1 EDS-specific Constraints,[0],[0]
An empty state does not have any variables.,5.1 EDS-specific Constraints,[0],[0]
"Second, every rule has no-copying, no-deleting statements.",5.1 EDS-specific Constraints,[0],[0]
"In other words, all variables must be used exactly once in a statement.",5.1 EDS-specific Constraints,[0],[0]
"Third, during recognition, a labeling function ρ is valid only if T (ρ) is a rooted tree.
",5.1 EDS-specific Constraints,[0],[0]
"After transduction, we get result ρ∗.",5.1 EDS-specific Constraints,[0],[0]
"The first and second constraints ensure that for all nodes, there is at most one incoming red dashed edge in T (ρ∗) and ‘data’ carried by variables of the only incoming red dashed edge or S is separated into variables of outgoing red dashed edges.",5.1 EDS-specific Constraints,[0],[0]
The last constraint ensures that we can solve all statements by a bottom-up process on tree T (ρ∗).,5.1 EDS-specific Constraints,[0],[0]
"Almost all NLG systems that heavily utilize a symbolic system to encode deep syntacticosemantic information lack some robustness, meaning that some input graphs may not be successfully processed.",5.2 Fine-to-Coarse Transduction,[0],[0]
There are two reasons: (1) some explicit linguistic constraints are not included; (2) exact decoding is too time-consuming while inexact decoding cannot cover the whole search space.,5.2 Fine-to-Coarse Transduction,[0],[0]
"To solve the robustness problem, we introduce a fine-to-coarse strategy to ensure that at least one sentence is generated for any input graph.",5.2 Fine-to-Coarse Transduction,[0],[0]
"There are three types of rules in our system, namely induced rules, extended rules and dynamic rules.",5.2 Fine-to-Coarse Transduction,[0],[0]
"The most fine-grained rules are applied to bring us precision, while the most coarse-grained rules are for robustness.
",5.2 Fine-to-Coarse Transduction,[0],[0]
"In order to extract reasonable rules, we will use both EDS graphs and the corresponding derivation trees provided by ERG.",5.2 Fine-to-Coarse Transduction,[0],[0]
The details will be described step-by-step in the following sections.,5.2 Fine-to-Coarse Transduction,[0],[0]
Figure 4 shows an example for obtaining induced rules.,5.3 Induced Rules,[0],[0]
"The induced rules are directly obtained by following three steps:
Finding intermediate tree T EDS graphs are highly regular semantic graphs.",5.3 Induced Rules,[0],[0]
It is not difficult to generate T based on a highly customized ‘breadthfirst’ search.,5.3 Induced Rules,[0],[0]
The generation starts from the ‘top’ node ( say v to in Figure 4) given by the EDS graph and traverse the whole graph.,5.3 Induced Rules,[0],[0]
"No more than thirty heuristic rules are used to decide the visiting order of nodes.
",5.3 Induced Rules,[0],[0]
Assigning states EDS graphs also provide span information for nodes.,5.3 Induced Rules,[0],[0]
We select a group of lexical nodes which have corresponding substrings in the original sentence.,5.3 Induced Rules,[0],[0]
"In Figure 4, these nodes are in bold font and directly followed by a span.",5.3 Induced Rules,[0],[0]
Then we merge spans from the bottom of T to the top to assign each red edge a span list.,5.3 Induced Rules,[0],[0]
"For each node n in T , we collect spans of every outgoing dashed edge of n into a list s.",5.3 Induced Rules,[0],[0]
"Some additional spans may be inserted into s. These spans do not occur in the EDS graph but they do occur in the sentence, i.e. than<29:33>.",5.3 Induced Rules,[0],[0]
Then we merge continuous spans in s and assign the remaining spans in s to the incoming red dashed edge of n. We apply a similar method to the derivation tree.,5.3 Induced Rules,[0],[0]
"As a result, every inner node of the derivation tree is associated with a span.",5.3 Induced Rules,[0],[0]
Then we align the edges in T to nodes of the inner derivation tree by comparing their spans.,5.3 Induced Rules,[0],[0]
"Finally edge labels in Figure 4 are generated.
",5.3 Induced Rules,[0],[0]
We use the concatenation of the edge labels in a span list as the state label.,5.3 Induced Rules,[0],[0]
The edge labels are joined in order with ‘ ’.,5.3 Induced Rules,[0],[0]
"Empty(0,e) is the state of the edges that do not belong to T (ignoring direction), such as e12.",5.3 Induced Rules,[0],[0]
The variable count of a state is equal to the size of the span list and the direction of a state is decided by whether the edge in T related to the state and its corresponding edge in D have different directions.,5.3 Induced Rules,[0],[0]
"For example, the state of e5 should be ADV PP(2,r).
",5.3 Induced Rules,[0],[0]
"Generating statements After the above two steps, we are ready to generate statements according to how spans are merged.",5.3 Induced Rules,[0],[0]
"For all nodes, spans of the incoming edges represent the left hand side and the outgoing edges represent the right hand side.",5.3 Induced Rules,[0],[0]
"For example, the rule for node comp will be:
{ADV(1,r)} comp−−−→",5.3 Induced Rules,[0],[0]
"{PP(1,u),",5.3 Induced Rules,[0],[0]
"ADV PP(2,r)}
vADV PP(1,r) = vADV(1,r)
vADV PP(2,r) =",5.3 Induced Rules,[0],[0]
"than+ vPP(1,u)",5.3 Induced Rules,[0],[0]
Extended rules are used when no induced rules can cover a given node.,5.4 Extended Rules,[0],[0]
"In theory, there can be unlimited modifier nodes pointing to a given node, such as PP and ADJ.",5.4 Extended Rules,[0],[0]
We use some manually written rules to slightly change an induced rule (prototype) by addition or deletion to generate a group of extended rules.,5.4 Extended Rules,[0],[0]
"The motivation here is to deal with the data sparseness problem.
",5.4 Extended Rules,[0],[0]
"For a group of selected non-head states in I , such as PP and ADJ.",5.4 Extended Rules,[0],[0]
We can produce new rules by removing or duplicating more of them.,5.4 Extended Rules,[0],[0]
"For example:
{NP(1,u),ADJ(1,r)} X n 1−−−−→ {} vNP(1,u) = vADJ(1,r)",5.4 Extended Rules,[0],[0]
+,5.4 Extended Rules,[0],[0]
"L
As a result, we get the two rules below:
{NP(1,u)} X n 1−−−−→ {} vNP(1,u) =",5.4 Extended Rules,[0],[0]
"L
{NP(1,u),ADJ(1,r)1,
ADJ(1,r)2} X n 1−−−−→ {}
vNP(1,u) = vADJ(1,r)1 + vADJ(1,r)2 + L",5.4 Extended Rules,[0],[0]
"During decoding, when neither induced nor extended rule is applicable, we create a dynamic rule on-the-fly.",5.5 Dynamic Rules,[0],[0]
"Our rule creator builds a new rule following the Markov assumption:
P (O|C) = P (q1|C) n∏
i=2
P (qi|C)P (qi|qi−1, C)
C = ⟨I,D⟩ represents the context.",5.5 Dynamic Rules,[0],[0]
"O = {q1, · · · , qn} denotes the outgoing states and I , D have the same meaning as before.",5.5 Dynamic Rules,[0],[0]
"Though they are unordered multisets, we can give them an explicit alphabet order by their edge labels.",5.5 Dynamic Rules,[0],[0]
There is also a group of hard constraints to make sure that the predicted rules are well-formed as the definition in §5 requires.,5.5 Dynamic Rules,[0],[0]
"This Markovization strategy is widely utilized by lexicalized and unlexicalized PCFG parsers (Collins, 1997; Klein and Manning, 2003).",5.5 Dynamic Rules,[0],[0]
"For a dynamic rule, all variables in this rule will appear in the statement.",5.5 Dynamic Rules,[0],[0]
We use a simple perceptron-based scorer to assign every variable a score and arrange them in an decreasing order.,5.5 Dynamic Rules,[0],[0]
"We use DeepBank 1.1 (Flickinger et al., 2012), i.e. gold-standard ERS annotations, as our main experimental data set to train a DAG transducer as well as a sequence-to-sequence morpholyzer, and wikiwoods (Flickinger et al., 2010), i.e. automatically-generated ERS annotations by ERG, as additional data set to enhance the sequence-to-sequence morpholyzer.",6.1 Set-up,[0],[0]
"The training,
development and test data sets are from DeepBank and split according to DeepBank’s recommendation.",6.1 Set-up,[0],[0]
"There are 34,505, 1,758 and 1,444 sentences (all disconnected graphs as well as their associated sentences are removed) in the training, development and test data sets.",6.1 Set-up,[0],[0]
"We use a small portion of wikiwoods data, c.a. 300K sentences, for experiments.
37,537 induced rules are directly extracted from the training data set, and 447,602 extended rules are obtained.",6.1 Set-up,[0],[0]
"For DAG recognition, at one particular position, there may be more than one rule applicable.",6.1 Set-up,[0],[0]
"In this case, we need a disambiguation model as well as a decoder to search for a globally optimal solution.",6.1 Set-up,[0],[0]
"In this work, we train a structured perceptron model (Collins, 2002) for disambiguation and employ a beam decoder.",6.1 Set-up,[0],[0]
The perceptron model used by our dynamic rule generator are trained with the induced rules.,6.1 Set-up,[0],[0]
"To get a sequence-to-sequence model, we use the open source tool—OpenNMT4.",6.1 Set-up,[0],[0]
We implement a fine-to-coarse beam search decoder.,6.2 The Decoder,[0],[0]
"Given a DAG D, our goal is to find the highest scored labeling function ρ:
ρ =",6.2 The Decoder,[0],[0]
"argmax ρ n∏ i=1 ∑ j wj · fj(rule(vi), D)
s.t. rule(vi) = ρ(in(vi))",6.2 The Decoder,[0],[0]
"ℓ(vi)−−−→ ⟨ρ(out(vi)), Ei⟩
where n is the node count and fj(·, ·) and wj represent a feature and the corresponding weight, respectively.",6.2 The Decoder,[0],[0]
The features are chosen from the context of the given node vi.,6.2 The Decoder,[0],[0]
We perform ‘topdown’ search to translate an input DAG into a morphology-function-enhanced lemma sequence.,6.2 The Decoder,[0],[0]
"Each hypothesis consists of the current DAG graph, the partial labeling function, the current hypothesis score and other graph information used to perform rule selection.",6.2 The Decoder,[0],[0]
The decoder will keep the corresponding partial intermediate graph T acyclic when decoding.,6.2 The Decoder,[0],[0]
The algorithm used by our decoder is displayed in Algorithm 1.,6.2 The Decoder,[0],[0]
"Function FindRules(h, n,R) will use hard constraints to select rules from the rule set R according to the contextual information.",6.2 The Decoder,[0],[0]
It will also perform an acyclic check on T .,6.2 The Decoder,[0],[0]
"Function Insert(h, r, n,B) will create and score a new hypothesis made from the given context and then insert it into beam B.
4https://github.com/OpenNMT/OpenNMT/
After we get the edge labeling function ρ, we use a simple linear equation solver to convert all statements to a sequence of lemmas.
",6.2 The Decoder,[0],[0]
Algorithm 1: Algorithm for our decoder.,6.2 The Decoder,[0],[0]
Input: D is the EDS graph.,6.2 The Decoder,[0],[0]
"RI and RE
are induced-rules and extended-rules respectively.
",6.2 The Decoder,[0],[0]
Result: The edge labeling function ρ.,6.2 The Decoder,[0],[0]
1 Q← all the roots in D 2 B1← empty beam 3 E ← ∅ 4 Insert initial hypothesis into B1 5 while Q is not empty: 6 B2← empty beam 7 n←,6.2 The Decoder,[0],[0]
"dequeue a node from Q 8 for h ∈ B1: 9 rules← FindRules(h, n,RI)
10 if rules is not empty: 11 for r ∈ rules: 12 Insert(h, r, n,B2) else: 13 rules← FindRules(h, n,RE) 14 for r ∈ rules: 15 Insert(h, r, n,B2) 16 if B2 is still empty: 17 for h ∈ B1: 18 r ← RuleGenerator(h, n) 19 Insert(h, r, n,B2) 20 B1← B2 21 for e ∈ out(n): 22 E ← E ∪ {e} 23 if in(tar(e))",6.2 The Decoder,[0],[0]
⊆ E: 24 Q← Q ∪ {tar(e)} 25 Extract ρ from best hypothesis in B1,6.2 The Decoder,[0],[0]
"In order to evaluate the effectiveness of our transducer for NLG, we try a group of tests showed in Table 2.",6.3 Accuracy,[0],[0]
All sequence-to-sequence models (either from lemma sequences to lemma sequences or lemma sequences to sentences) are trained on DeepBank and wikiwoods data set and tuned on the development data.,6.3 Accuracy,[0],[0]
The second column shows the BLEU-4 scores between generated lemma sequences and golden sequences of lemmas.,6.3 Accuracy,[0],[0]
The third column shows the BLEU-4 scores between generated sentences and golden sentences.,6.3 Accuracy,[0],[0]
"The fourth column shows the fraction of graphs in the test data set that can reach output sentences.
",6.3 Accuracy,[0],[0]
"The graphs that cannot received any natural language sentences are removed while conducting the BLEU evaluation.
",6.3 Accuracy,[0],[0]
"As we can conclude from Table 2, using only induced rules achieves the highest accuracy but the coverage is not satisfactory.",6.3 Accuracy,[0],[0]
Extended rules lead to a slight accuracy drop but with a great improvement of coverage (c.a. 10%).,6.3 Accuracy,[0],[0]
"Using dynamic rules, we observe a significant accuracy drop.",6.3 Accuracy,[0],[0]
"Nevertheless, we are able to handle all EDS graphs.",6.3 Accuracy,[0],[0]
The full-coverage robustness may benefit many NLP applications.,6.3 Accuracy,[0],[0]
The lemma sequences generated by our transducer are really close to the golden one.,6.3 Accuracy,[0],[0]
"This means that our model actually works and most reordering patterns are handled well by induced rules.
",6.3 Accuracy,[0],[0]
"Compared to the AMR generation task, our transducer on EDS graphs achieves much higher accuracies.",6.3 Accuracy,[0],[0]
"To make clear how much improvement is from the data and how much is from our DAG transducer, we implement a purely neural baseline.",6.3 Accuracy,[0],[0]
The baseline converts a DAG into a concept sequence by a pre-order DFS traversal on the intermediate tree of this DAG.,6.3 Accuracy,[0],[0]
Then we use a sequenceto-sequence model to transform this concept sequence to the lemma sequence for comparison.,6.3 Accuracy,[0],[0]
This is a kind of implementation of Konstas et al.’s model but evaluated on the EDS data.,6.3 Accuracy,[0],[0]
"We can see that on this task, our transducer is much better than a pure sequence-to-sequence model on DeepBank data.",6.3 Accuracy,[0],[0]
Table 3 shows the efficiency of the beam search decoder with a beam size of 128.,6.4 Efficiency,[0],[0]
The platform for this experiment is x86 64 GNU/Linux with two Intel Xeon E5-2620 CPUs.,6.4 Efficiency,[0],[0]
The second and third columns represent the average and the maximal time (in seconds) to translate an EDS graph.,6.4 Efficiency,[0],[0]
Using dynamic rules slow down the decoder to a great degree.,6.4 Efficiency,[0],[0]
"Since the data for experiments is newswire data, i.e. WSJ sentences from PTB (Marcus et al., 1993), the input graphs are quite large on average.",6.4 Efficiency,[0],[0]
"On average, it produces more than 5 sentences per second on CPU.",6.4 Efficiency,[0],[0]
We consider this a promising speed.,6.4 Efficiency,[0],[0]
We extend the work on DAG automata in Chiang et al. (2018) and propose a general method to build flexible DAG transducer.,7 Conclusion,[0],[0]
The key idea is to leverage a declarative programming language to minimize the computation burden of a graph transducer.,7 Conclusion,[0],[0]
We think may NLP tasks that involve graph manipulation may benefit from this design.,7 Conclusion,[0],[0]
"To exemplify our design, we develop a practical system for the semantic-graph-to-string task.",7 Conclusion,[0],[0]
"Our system is accurate (BLEU 68.07), efficient (more than 5 sentences per second on a CPU) and robust (fullcoverage).",7 Conclusion,[0],[0]
"The empirical evaluation confirms the usefulness a DAG transducer to resolve NLG, as well as the effectiveness of our design.",7 Conclusion,[0],[0]
"This work was supported by the National Natural Science Foundation of China (61772036, 61331011) and the Key Laboratory of Science, Technology and Standard in Press Industry (Key Laboratory of Intelligent Press Media Technology).",Acknowledgments,[0],[0]
We thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
Weiwei Sun is the corresponding author.,Acknowledgments,[0],[0]
A DAG automaton is a formal device for manipulating graphs.,abstractText,[0],[0]
"By augmenting a DAG automaton with transduction rules, a DAG transducer has potential applications in fundamental NLP tasks.",abstractText,[0],[0]
"In this paper, we propose a novel DAG transducer to perform graph-to-program transformation.",abstractText,[0],[0]
The target structure of our transducer is a program licensed by a declarative programming language rather than linguistic structures.,abstractText,[0],[0]
"By executing such a program, we can easily get a surface string.",abstractText,[0],[0]
Our transducer is designed especially for natural language generation (NLG) from type-logical semantic graphs.,abstractText,[0],[0]
"Taking Elementary Dependency Structures, a format of English Resource Semantics, as input, our NLG system achieves a BLEU-4 score of 68.07.",abstractText,[0],[0]
"This remarkable result demonstrates the feasibility of applying a DAG transducer to resolve NLG, as well as the effectiveness of our design.",abstractText,[0],[0]
Language Generation via DAG Transduction,title,[0],[0]
"Statistical language models estimate the probability distribution of a sequence of words by modeling the probability of the next word given preceding words, i.e.
P (w0, . . .",1. Introduction,[0],[0]
", wN ) =",1. Introduction,[0],[0]
P (w0) N∏ i=1,1. Introduction,[0],[0]
"P (wi|w0, . . .",1. Introduction,[0],[0]
", wi−1),
where wi are discrete word indices in a vocabulary.",1. Introduction,[0],[0]
"Language models are a critical part of systems for speech recognition (Yu & Deng, 2014) and machine translation (Koehn, 2010).
",1. Introduction,[0],[0]
"Recently, neural networks (Bengio et al., 2003; Mikolov et al., 2010; Jozefowicz et al., 2016) have been shown to
1Facebook AI Research.",1. Introduction,[0],[0]
"Correspondence to: Yann N. Dauphin <ynd@fb.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
outperform classical n-gram language models (Kneser & Ney, 1995; Chen & Goodman, 1996).",1. Introduction,[0],[0]
"These classical models suffer from data sparsity, which makes it difficult to represent large contexts and thus, long-range dependencies.",1. Introduction,[0],[0]
Neural language models tackle this issue by embedding words in continuous space over which a neural network is applied.,1. Introduction,[0],[0]
"The current state of the art for language modeling is based on long short term memory networks (LSTM; Hochreiter et al., 1997) which can theoretically model arbitrarily long dependencies.
",1. Introduction,[0],[0]
"In this paper, we introduce new gated convolutional networks and apply them to language modeling.",1. Introduction,[0],[0]
"Convolutional networks can be stacked to represent large context sizes and extract hierarchical features over larger and larger contexts with more abstractive features (LeCun & Bengio, 1995).",1. Introduction,[0],[0]
This allows them to model long-term dependencies by applyingO(Nk ) operations over a context of size N and kernel width k.,1. Introduction,[0],[0]
"In contrast, recurrent networks view the input as a chain structure and therefore require a linear number O(N) of operations.
",1. Introduction,[0],[0]
"Analyzing the input hierarchically bears resemblance to classical grammar formalisms which build syntactic tree structures of increasing granuality, e.g., sentences consist of noun phrases and verb phrases each comprising further internal structure (Manning & Schütze, 1999; Steedman, 2002).",1. Introduction,[0],[0]
"Hierarchical structure also eases learning since the number of non-linearities for a given context size is reduced compared to a chain structure, thereby mitigating the vanishing gradient problem (Glorot & Bengio, 2010).
",1. Introduction,[0],[0]
Modern hardware is well suited to models that are highly parallelizable.,1. Introduction,[0],[0]
"In recurrent networks, the next output depends on the previous hidden state which does not enable parallelization over the elements of a sequence.",1. Introduction,[0],[0]
"Convolutional networks, however, are very amenable to this computing paradigm since the computation of all input words can be performed simultaneously (§2).
",1. Introduction,[0],[0]
"Gating has been shown to be essential for recurrent neural networks to reach state-of-the-art performance (Jozefowicz et al., 2016).",1. Introduction,[0],[0]
"Our gated linear units reduce the vanishing gradient problem for deep architectures by providing a linear path for the gradients while retaining non-linear capabilities (§5.2).
",1. Introduction,[0],[0]
"We show that gated convolutional networks outperform other recently published language models such as LSTMs trained in a similar setting on the Google Billion Word Benchmark (Chelba et al., 2013).",1. Introduction,[0],[0]
"We also evaluate the ability of our models to deal with long-range dependencies on the WikiText-103 benchmark for which the model is conditioned on an entire paragraph rather than a single sentence and we achieve a new state-of-the-art on this dataset (Merity et al., 2016).",1. Introduction,[0],[0]
"Finally, we show that gated linear units achieve higher accuracy and converge faster than the LSTM-style gating of Oord et al. (2016; §4, §5).",1. Introduction,[0],[0]
In this paper we introduce a new neural language model that replaces the recurrent connections typically used in recurrent networks with gated temporal convolutions.,2. Approach,[0],[0]
"Neural language models (Bengio et al., 2003) produce a representation H =",2. Approach,[0],[0]
"[h0, . . .",2. Approach,[0],[0]
",hN ] of the context for each word w0, . . .",2. Approach,[0],[0]
", wN to predict the next word P (wi|hi).",2. Approach,[0],[0]
"Recurrent neural networks f compute H through a recurrent function hi = f(hi−1, wi−1) which is an inherently sequential process that cannot be parallelized over i.1
Our proposed approach convolves the inputs with a function f to obtain H = f ∗ w and therefore has no temporal dependencies, so it is easier to parallelize over the individual words of a sentence.",2. Approach,[0],[0]
This process will compute each context as a function of a number of preceding words.,2. Approach,[0],[0]
"Compared to recurrent networks, the context size is finite but we will demonstrate both that infinite contexts are not necessary and our models can represent large enough contexts to perform well in practice (§5).
",2. Approach,[0],[0]
Figure 1 illustrates the model architecture.,2. Approach,[0],[0]
Words are represented by a vector embedding stored in a lookup table D|V|×e where |V| is the number of words in the vocabulary and e is the embedding size.,2. Approach,[0],[0]
"The input to our model is a sequence of words w0, . . .",2. Approach,[0],[0]
", wN which are represented by word embeddings E =",2. Approach,[0],[0]
"[Dw0 , . . .",2. Approach,[0],[0]
",DwN ].",2. Approach,[0],[0]
"We compute the hidden layers h0, . . .",2. Approach,[0],[0]
", hL as
hl(X) =",2. Approach,[0],[0]
"(X ∗W + b)⊗ σ(X ∗V + c) (1)
wherem,n are respectively the number of input and output feature maps and k is the patch size, X ∈ RN×m is the input of layer hl (either word embeddings or the outputs of previous layers), W ∈ Rk×m×n, b ∈ Rn, V ∈ Rk×m×n, c ∈",2. Approach,[0],[0]
"Rn are learned parameters, σ is the sigmoid function and ⊗ is the element-wise product between matrices.
",2. Approach,[0],[0]
"When convolving inputs, we take care that hi does not contain information from future words.",2. Approach,[0],[0]
"We address this by shifting the convolutional inputs to prevent the kernels
1Parallelization is usually done over multiple sequences instead.
from seeing future context (Oord et al., 2016a).",2. Approach,[0],[0]
"Specifically, we zero-pad the beginning of the sequence with k−1 elements, assuming the first input element is the beginning of sequence marker which we do not predict and k is the width of the kernel.
",2. Approach,[0],[0]
The output of each layer is a linear projection X ∗W + b modulated by the gates σ(X ∗V + c).,2. Approach,[0],[0]
"Similar to LSTMs, these gates multiply each element of the matrix X∗W+b and control the information passed on in the hierarchy.",2. Approach,[0],[0]
We dub this gating mechanism Gated Linear Units (GLU).,2. Approach,[0],[0]
Stacking multiple layers on top of the input E gives a representation of the context for each word H = hL◦. .,2. Approach,[0],[0]
.◦,2. Approach,[0],[0]
h0(E).,2. Approach,[0],[0]
"We wrap the convolution and the gated linear unit in a preactivation residual block that adds the input of the block to
the output (He et al., 2015a).",2. Approach,[0],[0]
"The blocks have a bottleneck structure for computational efficiency and each block has up to 5 layers.
",2. Approach,[0],[0]
"The simplest choice to obtain model predictions is to use a softmax layer, but this choice is often computationally inefficient for large vocabularies and approximations such as noise contrastive estimation (Gutmann & Hyvärinen) or hierarchical softmax (Morin & Bengio, 2005) are preferred.",2. Approach,[0],[0]
"We choose an improvement of the latter known as adaptive softmax which assigns higher capacity to very frequent words and lower capacity to rare words (Grave et al., 2016a).",2. Approach,[0],[0]
This results in lower memory requirements as well as faster computation at both training and test time.,2. Approach,[0],[0]
"Gating mechanisms control the path through which information flows in the network and have proven to be useful for recurrent neural networks (Hochreiter & Schmidhuber, 1997).",3. Gating Mechanisms,[0],[0]
LSTMs enable long-term memory via a separate cell controlled by input and forget gates.,3. Gating Mechanisms,[0],[0]
This allows information to flow unimpeded through potentially many timesteps.,3. Gating Mechanisms,[0],[0]
"Without these gates, information could easily vanish through the transformations of each timestep.",3. Gating Mechanisms,[0],[0]
"In contrast, convolutional networks do not suffer from the same kind of vanishing gradient and we find experimentally that they do not require forget gates.
",3. Gating Mechanisms,[0],[0]
"Therefore, we consider models possessing solely output gates, which allow the network to control what information should be propagated through the hierarchy of layers.",3. Gating Mechanisms,[0],[0]
We show this mechanism to be useful for language modeling as it allows the model to select which words or features are relevant for predicting the next word.,3. Gating Mechanisms,[0],[0]
"Parallel to our work, Oord et al. (2016b) have shown the effectiveness of an LSTM-style mechanism of the form tanh(X∗W+b)⊗σ(X∗V+c) for the convolutional modeling of images.",3. Gating Mechanisms,[0],[0]
"Later, Kalchbrenner et al. (2016) extended this mechanism with additional gates for use in translation and character-level language modeling.
",3. Gating Mechanisms,[0],[0]
Gated linear units are a simplified gating mechanism based on the work of Dauphin & Grangier (2015) for nondeterministic gates that reduce the vanishing gradient problem by having linear units coupled to the gates.,3. Gating Mechanisms,[0],[0]
This retains the non-linear capabilities of the layer while allowing the gradient to propagate through the linear unit without scaling.,3. Gating Mechanisms,[0],[0]
"The gradient of the LSTM-style gating of which we dub gated tanh unit (GTU) is
∇[tanh(X)⊗ σ(X)]",3. Gating Mechanisms,[0],[0]
= tanh′(X)∇X⊗ σ(X) +σ′(X)∇X⊗ tanh(X).,3. Gating Mechanisms,[0],[0]
"(2)
Notice that it gradually vanishes as we stack layers because of the downscaling factors tanh′(X) and σ′(X).",3. Gating Mechanisms,[0],[0]
"In con-
trast, the gradient of the gated linear unit
∇[X⊗ σ(X)] = ∇X⊗ σ(X) + X⊗",3. Gating Mechanisms,[0],[0]
"σ′(X)∇X (3)
has a path ∇X ⊗ σ(X) without downscaling for the activated gating units in σ(X).",3. Gating Mechanisms,[0],[0]
This can be thought of as a multiplicative skip connection which helps gradients flow through the layers.,3. Gating Mechanisms,[0],[0]
We compare the different gating schemes experimentally in Section §5.2 and we find gated linear units allow for faster convergence to better perplexities.,3. Gating Mechanisms,[0],[0]
We report results on two public large-scale language modeling datasets.,4.1. Datasets,[0],[0]
"First, the Google Billion Word dataset (Chelba et al., 2013) is considered one of the largest language modeling datasets with almost one billion tokens and a vocabulary of over 800K words.",4.1. Datasets,[0],[0]
"In this dataset, words appearing less than 3 times are replaced with a special unknown symbol.",4.1. Datasets,[0],[0]
"The data is based on an English corpus of 30, 301, 028 sentences whose order has been shuffled.",4.1. Datasets,[0],[0]
"Second, WikiText-103 is a smaller dataset of over 100M tokens with a vocabulary of about 200K words (Merity et al., 2016).",4.1. Datasets,[0],[0]
"Different from GBW, the sentences are consecutive which allows models to condition on larger contexts rather than single sentences.",4.1. Datasets,[0],[0]
"For both datasets, we add a beginning of sequence marker <S > at the start of each line and an end of sequence marker </S> at the end of each line.",4.1. Datasets,[0],[0]
"On the Google Billion Word corpus each sequence is a single sentence, while on WikiText-103 a sequence is an entire paragraph.",4.1. Datasets,[0],[0]
The model sees <S> and </S >,4.1. Datasets,[0],[0]
as input but only predicts the end of sequence marker </S>.,4.1. Datasets,[0],[0]
We evaluate models by computing the perplexity e 1 N ∑N i,4.1. Datasets,[0],[0]
"− log p(wi|...,wi−1) on the standard held out test portion of each dataset.",4.1. Datasets,[0],[0]
"We implement our models in Torch (Collobert et al., 2011) and train on Tesla M40 GPUs.",4.2. Training,[0],[0]
"The majority of our models are trained on single GPU, as we focused on identifying compact architectures with good generalization and efficient computation at test time.",4.2. Training,[0],[0]
We trained larger models with an 8-GPU setup by copying the model onto each GPU and dividing the batch such that each worker computes 1/8th of the gradients.,4.2. Training,[0],[0]
The gradients are then summed using Nvidia NCCL.,4.2. Training,[0],[0]
"The multi-GPU setup allowed us to train models with larger hidden units.
",4.2. Training,[0],[0]
"We train using Nesterov’s momentum (Sutskever et al., 2013).",4.2. Training,[0],[0]
"While the cost in terms of memory is storing another vector of the size of the parameters, it increases the speed of convergence significantly with minimal additional
computation compared to standard stochastic gradient descent.",4.2. Training,[0],[0]
"The speed of convergence was further increased with gradient clipping (Pascanu et al., 2013) and weight normalization (Salimans & Kingma, 2016).
",4.2. Training,[0],[0]
Pascanu et al. (2013) argue for gradient clipping because it prevents the gradient explosion problem that characterizes RNNs.,4.2. Training,[0],[0]
"However, gradient clipping is not tied to RNNs, as it can be derived from the general concept of trust region methods.",4.2. Training,[0],[0]
"Gradient clipping is found using a spherical trust region
∆θ∗ = argmin s. t. ‖∆θ‖≤ f(θ) +∇fT∆θ
= −max(‖∇f‖, ) ∇f ‖∇f‖ .",4.2. Training,[0],[0]
"(4)
Empirically, our experiments converge significantly faster with the use of gradient clipping even though we do not use a recurrent architecture.
",4.2. Training,[0],[0]
"In combination, these methods led to stable and fast convergence with comparatively large learning rates such as 1.",4.2. Training,[0],[0]
We found good hyper-parameter configurations by crossvalidating with random search on a validation set.,4.3. Hyper-parameters,[0],[0]
"For model architecture, we select the number of residual blocks between {1, . . .",4.3. Hyper-parameters,[0],[0]
", 10}, the size of the embeddings with {128, . . .",4.3. Hyper-parameters,[0],[0]
", 256}, the number of units between {128, . . .",4.3. Hyper-parameters,[0],[0]
", 2048}, and the kernel width between {3, . . .",4.3. Hyper-parameters,[0],[0]
", 5}.
",4.3. Hyper-parameters,[0],[0]
"In general, finding a good architecture was simple and the rule of thumb is that the larger the model, the better the performance.",4.3. Hyper-parameters,[0],[0]
"In terms of optimization, we initialize the layers of the model with the Kaiming initialization (He et al., 2015b), with the learning rate sampled uniformly in the interval",4.3. Hyper-parameters,[0],[0]
"[1., 2.], the momentum set to 0.99, and clipping set to 0.1.",4.3. Hyper-parameters,[0],[0]
Good hyper-parameters for the optimizer are quite straightforward to find and the optimal values do not change much between datasets.,4.3. Hyper-parameters,[0],[0]
LSTMs and recurrent networks are able to capture long term dependencies and are fast becoming cornerstones in natural language processing.,5. Results,[0],[0]
"In this section, we compare strong LSTM and RNN models from the literature to our gated convolutional approach on two datasets.
",5. Results,[0],[0]
We find the GCNN outperforms the comparable LSTM results on Google billion words.,5. Results,[0],[0]
"To accurately compare these approaches, we control for the same number of GPUs and the adaptive softmax output model (Grave et al., 2016a), as these variables have a significant influence on performance.",5. Results,[0],[0]
"In this setting, the GCNN reaches 38.1 test perplexity while the comparable LSTM has 39.8 perplexity (Table 2).
",5. Results,[0],[0]
"Further, the GCNN obtains strong performance with much greater computational efficiency.",5. Results,[0],[0]
Figure 2 shows that our approach closes the previously significant gap between models that use the full softmax and models with the usually less accurate hierarchical softmax.,5. Results,[0],[0]
"Thanks to the adap-
tive softmax, the GCNN only requires a fraction of the operations to reach the same perplexity values.",5. Results,[0],[0]
"The GCNN outperforms other single model state-of-the-art approaches except the much larger LSTM of Jozefowicz et al. (2016), a model which requires more GPUs and the much more computationally expensive full softmax.",5. Results,[0],[0]
"In comparison, the largest model we have trained reaches 31.9 test perplexity compared to the 30.6 of that approach, but only requires training for 2 weeks on 8 GPUs compared to 3 weeks of training on 32 GPUs for the LSTM.",5. Results,[0],[0]
"Note that these results can be improved by either using mixtures of experts (Shazeer et al., 2017) or ensembles of these models.
",5. Results,[0],[0]
Another relevant concern is if the GCNN’s fixed context size can thoroughly model long sequences.,5. Results,[0],[0]
"On Google Bil-
∗appeared after submission
lion Word, the average sentence length is quite short — only 20 words.",5. Results,[0],[0]
We evaluate on WikiText-103 to determine if the model can perform well on a dataset where much larger contexts are available.,5. Results,[0],[0]
"On WikiText-103, an input sequence is an entire Wikipedia article instead of an individual sentence - increasing the average length to 4000 words.",5. Results,[0],[0]
"However, the GCNN outperforms LSTMs on this problem as well (Table 3).",5. Results,[0],[0]
The GCNN-8 model has 8 layers with 800 units each and the LSTM has 1024 units.,5. Results,[0],[0]
"These results show that GCNNs can model enough context to achieve strong results.
",5. Results,[0],[0]
We evaluated on the Gigaword dataset following Chen et al. (2016) to compare with fully connected models.,5. Results,[0],[0]
We found that the fully connected and convolutional network reach respectively 55.6 and 29.4 perplexity.,5. Results,[0],[0]
We also ran preliminary experiments on the much smaller Penn tree bank dataset.,5. Results,[0],[0]
"When we score the sentences independently, the GCNN and LSTM have comparable test perplexity with 108.7 and 109.3 respectively.",5. Results,[0],[0]
"However, it is possible to achieve better results by conditioning on previous sentences.",5. Results,[0],[0]
"Unlike the LSTM, we found that the GCNN overfits on this quite small dataset and so we note the model is better suited to larger scale problems.",5. Results,[0],[0]
Computational cost is an important consideration for language models.,5.1. Computational Efficiency,[0],[0]
"Depending on the application, there are a number of metrics to consider.",5.1. Computational Efficiency,[0],[0]
"We measure the throughput
of a model as the number of tokens that can be processed per second.",5.1. Computational Efficiency,[0],[0]
Throughput can be maximized by processing many sentences in parallel to amortize sequential operations.,5.1. Computational Efficiency,[0],[0]
"In contrast, responsiveness is the speed of processing the input sequentially, one token at a time.",5.1. Computational Efficiency,[0],[0]
Throughput is important because it indicates the time required to process a corpus of text and responsiveness is an indicator of the time to finish processing a sentence.,5.1. Computational Efficiency,[0],[0]
A model can have low responsiveness but high throughput by evaluating many sentences simultaneously through batching.,5.1. Computational Efficiency,[0],[0]
"In this case, such a model is slow in finishing processing individual sentences, but can process many sentences at a good rate.
",5.1. Computational Efficiency,[0],[0]
We evaluate the throughput and responsiveness for models that reach approximately 43.9 perplexity on the Google Billion Word benchmark.,5.1. Computational Efficiency,[0],[0]
"We consider the LSTM with 2048 units in Table 2, a GCNN-8Bottleneck with 7 Resnet blocks that have a bottleneck structure as described by (He et al., 2015a) and a GCNN-8 without bottlenecks.",5.1. Computational Efficiency,[0],[0]
A bottleneck block wedges a k > 1 convolution between two k = 1 layers.,5.1. Computational Efficiency,[0],[0]
This designs reduces computational cost by reducing and increasing dimensionality with the k = 1 layers so that the convolution operates in a lower dimensional space.,5.1. Computational Efficiency,[0],[0]
"Our results show that the use of bottleneck blocks is important to maintaining computational efficiency.
",5.1. Computational Efficiency,[0],[0]
"The throughput of the LSTM is measured by using a large batch of 750 sequences of length 20, resulting in 15, 000 tokens per batch.",5.1. Computational Efficiency,[0],[0]
"The responsiveness is the average speed to process a sequence of 15, 000 contiguous tokens.",5.1. Computational Efficiency,[0],[0]
Table 4 shows that the throughput for the LSTM and the GCNN are similar.,5.1. Computational Efficiency,[0],[0]
The LSTM performs very well on GPU because the large batch size of 750 enables high parallelization over different sentences.,5.1. Computational Efficiency,[0],[0]
"This is because the LSTM implementation has been thoroughly optimized and uses cuDNN, whereas the cuDNN implementation of convolutions is not been optimized for the 1-D convolutions we use in our model.",5.1. Computational Efficiency,[0],[0]
We believe much better performance can be achieved by a more efficient 1-D cuDNN convolution.,5.1. Computational Efficiency,[0],[0]
"Unlike the LSTM, the GCNN can be parallelized both over sequences as well as across the tokens of each sequence, allowing the GCNN to have 20x higher responsiveness.",5.1. Computational Efficiency,[0],[0]
"In this section, we compare the gated linear unit with other mechanisms as well as to models without gating.",5.2. Gating Mechanisms,[0],[0]
"We consider the LSTM-style gating mechanism (GTU) tanh(X ∗W + b)⊗ σ(X ∗V + c) of (Oord et al., 2016b) and networks that use regular ReLU or Tanh activations.",5.2. Gating Mechanisms,[0],[0]
"Gating units add parameters, so for fair comparison, we carefully cross-validate models with a comparable number of parameters.",5.2. Gating Mechanisms,[0],[0]
Figure 3 (left) shows that GLU networks converge to a lower perplexity than the other approaches on WikiText-103.,5.2. Gating Mechanisms,[0],[0]
"Similar to gated linear units, the ReLU has a linear path that lets the gradients easily pass through the active units.",5.2. Gating Mechanisms,[0],[0]
This translates to much faster convergence for both the ReLU and the GLU.,5.2. Gating Mechanisms,[0],[0]
"On the other hand, neither Tanh nor GTU have this linear path, and thus suffer from the vanishing gradient problem.",5.2. Gating Mechanisms,[0],[0]
"In the GTU, both the inputs as well as the gating units can cut the gradient when the units saturate.
",5.2. Gating Mechanisms,[0],[0]
"Comparing the GTU and Tanh models allows us to measure
the effect of gating since the Tanh model can be thought of as a GTU network with the sigmoid gating units removed.",5.2. Gating Mechanisms,[0],[0]
"The results (Figure 3, left) show that the gating units make a vast difference and provide useful modeling capabilities, as there is a large difference in the performance between GTU and Tanh units.",5.2. Gating Mechanisms,[0],[0]
"Similarly, while ReLU unit is not an exact ablation of the gating units in the GLU, it can be seen as a simplification ReLU(X) = X ⊗ (X > 0) where the gates become active depending on the sign of the input.",5.2. Gating Mechanisms,[0],[0]
"Also in this case, GLU units lead to lower perplexity.
",5.2. Gating Mechanisms,[0],[0]
In Figure 3 (right) we repeat the same experiment on the larger Google Billion Words dataset.,5.2. Gating Mechanisms,[0],[0]
We consider a fixed time budget of 100 hours because of the considerable training time required for this task.,5.2. Gating Mechanisms,[0],[0]
"Similar to WikiText-103, the gated linear units achieve the best results on this problem.",5.2. Gating Mechanisms,[0],[0]
"There is a gap of about 5 perplexity points between the GLU and ReLU which is similar to the difference between the LSTM and RNN models measured by (Jozefowicz et al., 2016) on the same dataset.",5.2. Gating Mechanisms,[0],[0]
The experiments so far have shown that the gated linear unit benefits from the linear path the unit provides compared to other non-linearities.,5.3. Non-linear Modeling,[0],[0]
"Next, we compare networks with GLUs to purely linear networks and networks with bilinear layers in order to measure the impact of the nonlinear path provided by the gates of the GLU.",5.3. Non-linear Modeling,[0],[0]
"One motivation for this experiment is the success of linear models on many natural language processing tasks (Manning & Schütze, 1999).",5.3. Non-linear Modeling,[0],[0]
We consider deep linear convolutional networks where the layers lack the gating units of the GLU and take the form hl(X) = X ∗W + b.,5.3. Non-linear Modeling,[0],[0]
"Stacking several layers on top of each other is simply a factorization of the model which remains linear up to the softmax, at which point it becomes log-linear.",5.3. Non-linear Modeling,[0],[0]
"Another variation of GLUs are bilinear layers (Mnih & Hinton, 2007) which take the form
hl(X) =",5.3. Non-linear Modeling,[0],[0]
(X ∗W + b)⊗,5.3. Non-linear Modeling,[0],[0]
"(X ∗V + c).
",5.3. Non-linear Modeling,[0],[0]
"Figure 5 shows that GLUs perform best, followed by bilinear layers and then linear layers.",5.3. Non-linear Modeling,[0],[0]
"Bilinear layers improve over linear ones by more than 40 perplexity points, and the GLU improves another 20 perplexity points over the bilinear model.",5.3. Non-linear Modeling,[0],[0]
"The linear model performs very poorly at perplexity 115 even compared to 67.6 of a Kneser-Ney 5-gram model, even though the former has access to more context.",5.3. Non-linear Modeling,[0],[0]
"Surprisingly, the introduction of the gated linear units is enough to reach 61 perplexity on Google Billion Word, which surpasses both Kneser-Ney 5-gram models and the non-linear neural model of (Ji et al., 2015).",5.3. Non-linear Modeling,[0],[0]
Figure 4 shows the impact of context size for the gated CNN.,5.4. Context Size,[0],[0]
We tried different combinations of network depth and kernel widths for each context size and chose the best performing one for each size.,5.4. Context Size,[0],[0]
"Generally, larger contexts
improve accuracy but returns drastically diminish with windows larger than 40 words, even for WikiText-103 where we may condition on an entire Wikipedia article.",5.4. Context Size,[0],[0]
This means that the unlimited context offered by recurrent models is not strictly necessary for language modeling.,5.4. Context Size,[0],[0]
"Furthermore, this finding is also congruent with the fact that good performance with recurrent networks can be obtained by truncating gradients after only 40 timesteps using truncated back propagation through time.",5.4. Context Size,[0],[0]
Figure 4 also shows that WikiText-103 benefits much more from larger context size than Google Billion Word as the performance degrades more sharply with smaller contexts.,5.4. Context Size,[0],[0]
WikiText-103 provides much more context than Google Billion Word where the average sentence size is 20.,5.4. Context Size,[0],[0]
"However, while the average size of the documents is close to 4000 tokens, we find that strong performance can be achieved with a context size as low as 30 tokens.",5.4. Context Size,[0],[0]
"In this section, we perform an ablation study of the impact of weight normalization and gradient clipping.",5.5. Training,[0],[0]
We separately cross-validate the hyper-parameters of each configuration to make the comparison fair.,5.5. Training,[0],[0]
"Due to the high cost of each of these experiments, we only consider a single iteration over the training data.",5.5. Training,[0],[0]
Figure 6 shows that both methods significantly speed up convergence.,5.5. Training,[0],[0]
Weight normalization in particular improves the speed by over two times.,5.5. Training,[0],[0]
This speedup is partly due to the ability to use much larger learning rates (1 instead of 0.01) than would otherwise be possible.,5.5. Training,[0],[0]
"Both clipping and weight normalization add computational overhead, but it is minor compared to the large gains in convergence speed.",5.5. Training,[0],[0]
We introduce a convolutional neural network for language modeling with a novel gating mechanism.,6. Conclusion,[0],[0]
"Compared to recurrent neural networks, our approach builds a hierarchical representation of the input words that makes it easier to capture long-range dependencies, similar in spirit to the tree-structured analysis of linguistic grammar formalisms.",6. Conclusion,[0],[0]
"The same property eases learning since features are passed through a fixed number of layers and non-linearities, unlike for recurrent networks where the number of processing steps differs depending on the position of the word in the input.",6. Conclusion,[0],[0]
The results show that our gated convolutional network achieves a new state of the art on WikiText-103.,6. Conclusion,[0],[0]
"On the Google Billion Word benchmark, we show competitive results can be achieved with significantly fewer resources.",6. Conclusion,[0],[0]
"We would like to thank Ben Graham, Jonas Gehring, Edouard Grave, Armand Joulin and Ronan Collobert for helpful discussions.",Acknowledgments,[0],[0]
The pre-dominant approach to language modeling to date is based on recurrent neural networks.,abstractText,[0],[0]
Their success on this task is often linked to their ability to capture unbounded context.,abstractText,[0],[0]
"In this paper we develop a finite context approach through stacked convolutions, which can be more efficient since they allow parallelization over sequential tokens.",abstractText,[0],[0]
We propose a novel simplified gating mechanism that outperforms Oord et al. (2016b) and investigate the impact of key architectural decisions.,abstractText,[0],[0]
"The proposed approach achieves state-of-the-art on the WikiText103 benchmark, even though it features longterm dependencies, as well as competitive results on the Google Billion Words benchmark.",abstractText,[0],[0]
Our model reduces the latency to score a sentence by an order of magnitude compared to a recurrent baseline.,abstractText,[0],[0]
"To our knowledge, this is the first time a non-recurrent approach is competitive with strong recurrent models on these large scale language tasks.",abstractText,[0],[0]
Language Modeling with Gated Convolutional Networks,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1–11, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.
In this paper, we consider the task of learning control policies for text-based games. In these games, all interactions in the virtual world are through text and the underlying state is not observed. The resulting language barrier makes such environments challenging for automatic game players. We employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback. This framework enables us to map text descriptions into vector representations that capture the semantics of the game states. We evaluate our approach on two game worlds, comparing against baselines using bag-ofwords and bag-of-bigrams for state representations. Our algorithm outperforms the baselines on both worlds demonstrating the importance of learning expressive representations. 1",text,[0],[0]
"In this paper, we address the task of learning control policies for text-based strategy games.",1 Introduction,[0],[0]
"These games, predecessors to modern graphical ones, still enjoy a large following worldwide.2",1 Introduction,[0],[0]
They often involve complex worlds with rich interactions and elaborate textual descriptions of the underlying states (see Figure 1).,1 Introduction,[0],[0]
Players read descriptions of the current world state and respond with natural language commands to take actions.,1 Introduction,[0],[0]
"Since the underlying state is not directly observable, the player has to understand the text in order to act, making it
∗Both authors contributed equally to this work.",1 Introduction,[0],[0]
"1Code is available at http://people.csail.mit.
edu/karthikn/mud-play.",1 Introduction,[0],[0]
"2http://mudstats.com/
challenging for existing AI programs to play these games (DePristo and Zubek, 2001).
",1 Introduction,[0],[0]
"In designing an autonomous game player, we have considerable latitude when selecting an adequate state representation to use.",1 Introduction,[0],[0]
The simplest method is to use a bag-of-words representation derived from the text description.,1 Introduction,[0],[0]
"However, this scheme disregards the ordering of words and the finer nuances of meaning that evolve from composing words into sentences and paragraphs.",1 Introduction,[0],[0]
"For instance, in State 2 in Figure 1, the agent has to understand that going east will lead it to the castle whereas moving south will take it to the standing archway.",1 Introduction,[0],[0]
"An alternative approach is to convert text descriptions to pre-specified representations using annotated training data, commonly used in
1
language grounding tasks (Matuszek et al., 2013; Kushman et al., 2014).
",1 Introduction,[0],[0]
"In contrast, our goal is to learn useful representations in conjunction with control policies.",1 Introduction,[0],[0]
We adopt a reinforcement learning framework and formulate game sequences as Markov Decision Processes.,1 Introduction,[0],[0]
An agent playing the game aims to maximize rewards that it obtains from the game engine upon the occurrence of certain events.,1 Introduction,[0],[0]
"The agent learns a policy in the form of an action-value function Q(s, a) which denotes the long-term merit of an action a in state s.
The action-value function is parametrized using a deep recurrent neural network, trained using the game feedback.",1 Introduction,[0],[0]
The network contains two modules.,1 Introduction,[0],[0]
The first one converts textual descriptions into vector representations that act as proxies for states.,1 Introduction,[0],[0]
"This component is implemented using Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997).",1 Introduction,[0],[0]
"The second module of the network scores the actions given the vector representation computed by the first.
",1 Introduction,[0],[0]
"We evaluate our model using two Multi-User Dungeon (MUD) games (Curtis, 1992; Amir and Doyle, 2002).",1 Introduction,[0],[0]
"The first game is designed to provide a controlled setup for the task, while the second is a publicly available one and contains human generated text descriptions with significant language variability.",1 Introduction,[0],[0]
We compare our algorithm against baselines of a random player and models that use bag-of-words or bag-of-bigrams representations for a state.,1 Introduction,[0],[0]
We demonstrate that our model LSTM-DQN significantly outperforms the baselines in terms of number of completed quests and accumulated rewards.,1 Introduction,[0],[0]
"For instance, on a fantasy MUD game, our model learns to complete 96% of the quests, while the bag-of-words model and a random baseline solve only 82% and 5% of the quests, respectively.",1 Introduction,[0],[0]
"Moreover, we show that the acquired representation can be reused across games, speeding up learning and leading to faster convergence of Q-values.",1 Introduction,[0],[0]
Learning control policies from text is gaining increasing interest in the NLP community.,2 Related Work,[0],[0]
"Example applications include interpreting help documentation for software (Branavan et al., 2010), navigating with directions (Vogel and Jurafsky, 2010; Kollar et al., 2010; Artzi and Zettlemoyer, 2013; Matuszek et al., 2013; Andreas and Klein, 2015)
and playing computer games (Eisenstein et al., 2009; Branavan et al., 2011a).
",2 Related Work,[0],[0]
Games provide a rich domain for grounded language analysis.,2 Related Work,[0],[0]
Prior work has assumed perfect knowledge of the underlying state of the game to learn policies.,2 Related Work,[0],[0]
Gorniak and Roy (2005) developed a game character that can be controlled by spoken instructions adaptable to the game situation.,2 Related Work,[0],[0]
The grounding of commands to actions is learned from a transcript manually annotated with actions and state attributes.,2 Related Work,[0],[0]
Eisenstein et al. (2009) learn game rules by analyzing a collection of game-related documents and precompiled traces of the game.,2 Related Work,[0],[0]
"In contrast to the above work, our model combines text interpretation and strategy learning in a single framework.",2 Related Work,[0],[0]
"As a result, textual analysis is guided by the received control feedback, and the learned strategy directly builds on the text interpretation.
",2 Related Work,[0],[0]
"Our work closely relates to an automatic game player that utilizes text manuals to learn strategies for Civilization (Branavan et al., 2011a).",2 Related Work,[0],[0]
"Similar to our approach, text analysis and control strategies are learned jointly using feedback provided by the game simulation.",2 Related Work,[0],[0]
"In their setup, states are fully observable, and the model learns a strategy by combining state/action features and features extracted from text.",2 Related Work,[0],[0]
"However, in our application, the state representation is not provided, but has to be inferred from a textual description.",2 Related Work,[0],[0]
"Therefore, it is not sufficient to extract features from text to supplement a simulation-based player.
",2 Related Work,[0],[0]
"Another related line of work consists of automatic video game players that infer state representations directly from raw pixels (Koutnı́k et al., 2013; Mnih et al., 2015).",2 Related Work,[0],[0]
"For instance, Mnih et al. (2015) learn control strategies using convolutional neural networks, trained with a variant of Q-learning (Watkins and Dayan, 1992).",2 Related Work,[0],[0]
"While both approaches use deep reinforcement learning for training, our work has important differences.",2 Related Work,[0],[0]
"In order to handle the sequential nature of text, we use Long Short-Term Memory networks to automatically learn useful representations for arbitrary text descriptions.",2 Related Work,[0],[0]
"Additionally, we show that decomposing the network into a representation layer and an action selector is useful for transferring the learnt representations to new game scenarios.",2 Related Work,[0],[0]
"Game Representation We represent a game by the tuple 〈H,A, T,R,Ψ〉, where H is the set of
all possible game states, A = {(a, o)} is the set of all commands (action-object pairs), T (h′ | h, a, o) is the stochastic transition function between states and R(h, a, o) is the reward function.",3 Background,[0],[0]
"The game state H is hidden from the player, who only receives a varying textual description, produced by a stochastic function Ψ : H → S. Specifically, the underlying state h in the game engine keeps track of attributes such as the player’s location, her health points, time of day, etc.",3 Background,[0],[0]
The function Ψ (also part of the game framework) then converts this state into a textual description of the location the player is at or a message indicating low health.,3 Background,[0],[0]
We do not assume access to either H or Ψ for our agent during both training and testing phases of our experiments.,3 Background,[0],[0]
"We denote the space of all possible text descriptions s to be S. Rewards are generated using R and are only given to the player upon completion of in-game quests.
",3 Background,[0],[0]
"Q-Learning Reinforcement Learning is a commonly used framework for learning control policies in game environments (Silver et al., 2007; Amato and Shani, 2010; Branavan et al., 2011b; Szita, 2012).",3 Background,[0],[0]
"The game environment can be formulated as a sequence of state transitions (s, a, r, s′) of a Markov Decision Process (MDP).",3 Background,[0],[0]
"The agent takes an action a in state s by consulting a state-action value function Q(s, a), which is a measure of the action’s expected long-term reward.",3 Background,[0],[0]
"Q-Learning (Watkins and Dayan, 1992) is a model-free technique which is used to learn an optimal Q(s, a) for the agent.",3 Background,[0],[0]
"Starting from a random Q-function, the agent continuously updates its Q-values by playing the game and obtaining rewards.",3 Background,[0],[0]
"The iterative updates are derived from the Bellman equation (Sutton and Barto, 1998):
(1)Qi+1(s, a) =",3 Background,[0],[0]
"E[r + γmax a′
Qi(s′, a′) | s, a]
where γ is a discount factor for future rewards and the expectation is over all game transitions that involved the agent taking action a in state s.
Using these evolving Q-values, the agent chooses the action with the highest Q(s, a) to maximize its expected future rewards.",3 Background,[0],[0]
"In practice, the trade-off between exploration and exploitation can be achieved following an -greedy policy (Sutton and Barto, 1998), where the agent performs a random action with probability .
",3 Background,[0],[0]
"Deep Q-Network In large games, it is often impractical to maintain the Q-value for all possible
state-action pairs.",3 Background,[0],[0]
"One solution to this problem is to approximate Q(s, a) using a parametrized function Q(s, a; θ), which can generalize over states and actions by considering higher-level attributes (Sutton and Barto, 1998; Branavan et al., 2011a).",3 Background,[0],[0]
"However, creating a good parametrization requires knowledge of the state and action spaces.",3 Background,[0],[0]
"One way to bypass this feature engineering is to use a Deep Q-Network (DQN) (Mnih et al., 2015).",3 Background,[0],[0]
"The DQN approximates the Q-value function with a deep neural network to predict Q(s, a) for all possible actions a simultaneously given the current state s. The non-linear function layers of the DQN also enable it to learn better value functions than linear approximators.",3 Background,[0],[0]
"In this section, we describe our model (DQN) and describe its use in learning good Q-value approximations for games with stochastic textual descriptions.",4 Learning Representations and Control Policies,[0],[0]
We divide our model into two parts.,4 Learning Representations and Control Policies,[0],[0]
The first module is a representation generator that converts the textual description of the current state into a vector.,4 Learning Representations and Control Policies,[0],[0]
This vector is then input into the second module which is an action scorer.,4 Learning Representations and Control Policies,[0],[0]
Figure 2 shows the overall architecture of our model.,4 Learning Representations and Control Policies,[0],[0]
"We learn the parameters of both the representation generator and the action scorer jointly, using the in-game reward feedback.
",4 Learning Representations and Control Policies,[0],[0]
Representation Generator (φR),4 Learning Representations and Control Policies,[0],[0]
The representation generator reads raw text displayed to the agent and converts it to a vector representation vs. A bag-of-words (BOW) representation is not sufficient to capture higher-order structures of sentences and paragraphs.,4 Learning Representations and Control Policies,[0],[0]
"The need for a better semantic representation of the text is evident from the average performance of this representation in playing MUD-games (as we show in Section 6).
",4 Learning Representations and Control Policies,[0],[0]
"In order to assimilate better representations, we utilize a Long Short-Term Memory network (LSTM) (Hochreiter and Schmidhuber, 1997) as a representation generator.",4 Learning Representations and Control Policies,[0],[0]
LSTMs are recurrent neural networks with the ability to connect and recognize long-range patterns between words in text.,4 Learning Representations and Control Policies,[0],[0]
They are more robust than BOW to small variations in word usage and are able to capture underlying semantics of sentences to some extent.,4 Learning Representations and Control Policies,[0],[0]
"In recent work, LSTMs have been used successfully in NLP tasks such as machine translation (Sutskever et al., 2014) and sentiment analysis (Tai et al., 2015) to compose vector representations of sentences from word-level embeddings (Mikolov et al., 2013; Pennington et al., 2014).",4 Learning Representations and Control Policies,[0],[0]
"In our setup, the LSTM network takes in word embeddings wk from the words in a description s and produces output vectors xk at each step.
",4 Learning Representations and Control Policies,[0],[0]
"To get the final state representation vs, we add a mean pooling layer which computes the elementwise mean over the output vectors xk.3
(2)vs = 1 n n∑ k=1 xk
Action Scorer (φA)",4 Learning Representations and Control Policies,[0],[0]
The action scorer module produces scores for the set of possible actions given the current state representation.,4 Learning Representations and Control Policies,[0],[0]
We use a multi-layered neural network for this purpose (see Figure 2).,4 Learning Representations and Control Policies,[0],[0]
"The input to this module is the vector from the representation generator, vs = φR(s) and the outputs are scores for actions",4 Learning Representations and Control Policies,[0],[0]
"a ∈ A. Scores for all actions are predicted simultaneously, which is computationally more efficient than scoring each state-action pair separately.",4 Learning Representations and Control Policies,[0],[0]
"Thus, by combining the representation generator and action scorer, we can obtain the approximation for the Qfunction as Q(s, a) ≈ φA(φR(s))[a].
",4 Learning Representations and Control Policies,[0],[0]
"An additional complexity in playing MUDgames is that the actions taken by the player are
3We also experimented with considering just the output vector of the LSTM after processing the last word.",4 Learning Representations and Control Policies,[0],[0]
"Empirically, we find that mean pooling leads to faster learning, so we use it in all our experiments.
",4 Learning Representations and Control Policies,[0],[0]
multi-word natural language commands such as eat apple or go east.,4 Learning Representations and Control Policies,[0],[0]
"Due to computational constraints, in this work we limit ourselves to consider commands to consist of one action (e.g. eat) and one argument object (e.g. apple).",4 Learning Representations and Control Policies,[0],[0]
"This assumption holds for the majority of the commands in our worlds, with the exception of one class of commands that require two arguments (e.g. move red-root right, move blue-root up).",4 Learning Representations and Control Policies,[0],[0]
We consider all possible actions and objects available in the game and predict both for each state using the same network (Figure 2).,4 Learning Representations and Control Policies,[0],[0]
"We consider the Q-value of the entire command (a, o) to be the average of the Qvalues of the action a and the object o.",4 Learning Representations and Control Policies,[0],[0]
"For the rest of this section, we only show equations forQ(s, a) but similar ones hold for Q(s, o).
",4 Learning Representations and Control Policies,[0],[0]
Parameter Learning,4 Learning Representations and Control Policies,[0],[0]
"We learn the parameters θR of the representation generator and θA of the action scorer using stochastic gradient descent with RMSprop (Tieleman and Hinton, 2012).",4 Learning Representations and Control Policies,[0],[0]
The complete training procedure is shown in Algorithm 1.,4 Learning Representations and Control Policies,[0],[0]
"In each iteration i, we update the parameters to reduce the discrepancy between the predicted value of the current state Q(st, at; θi) (where θi = [θR; θA]i) and the expected Q-value given the reward rt and the value of the next state maxa Q(st+1, a; θi−1).
",4 Learning Representations and Control Policies,[0],[0]
"We keep track of the agent’s previous experiences in a memory D.4 Instead of performing updates to the Q-value using transitions from the current episode, we sample a random transition (ŝ, â, s′, r) from D. Updating the parameters in this way avoids issues due to strong correlation when using transitions of the same episode (Mnih et al., 2015).",4 Learning Representations and Control Policies,[0],[0]
"Using the sampled transition and (1), we obtain the following loss function to minimize:
(3)Li(θi) =",4 Learning Representations and Control Policies,[0],[0]
"Eŝ,â[(yi −Q(ŝ, â; θi))2] where yi = Eŝ,â[r + γmaxa′",4 Learning Representations and Control Policies,[0],[0]
"Q(s′, a′; θi−1) | ŝ, â] is the target Q-value with parameters θi−1 fixed from the previous iteration.
",4 Learning Representations and Control Policies,[0],[0]
"The updates on the parameters θ can be performed using the following gradient of Li(θi): ∇θiLi(θi) = Eŝ,â[2(yi −Q(ŝ, â; θi))∇θiQ(ŝ, â; θi)]
For each epoch of training, the agent plays several episodes of the game, which is restarted after every terminal state.
",4 Learning Representations and Control Policies,[0],[0]
"4The memory is limited and rewritten in a first-in-first-out (FIFO) fashion.
",4 Learning Representations and Control Policies,[0],[0]
"Algorithm 1 Training Procedure for DQN with prioritized sampling 1: Initialize experience memory D 2: Initialize parameters of representation generator (φR) and action scorer (φA) randomly 3: for episode = 1,M do 4: Initialize game and get start state description s1 5: for t = 1, T do 6: Convert st (text) to representation vst using φR 7: if random() < then 8: Select a random action at 9: else 10: Compute Q(st, a) for all actions using φA(vst) 11: Select at = argmax Q(st, a) 12:",4 Learning Representations and Control Policies,[0],[0]
Execute action at and observe reward rt and new state st+1 13:,4 Learning Representations and Control Policies,[0],[0]
"Set priority pt = 1 if rt > 0, else pt = 0 14:",4 Learning Representations and Control Policies,[0],[0]
"Store transition (st, at, rt, st+1, pt) in D 15:",4 Learning Representations and Control Policies,[0],[0]
"Sample random mini batch of transitions (sj , aj , rj , sj+1, pj) from D,
with fraction ρ having pj = 1 16: Set yj =",4 Learning Representations and Control Policies,[0],[0]
{,4 Learning Representations and Control Policies,[0],[0]
rj,4 Learning Representations and Control Policies,[0],[0]
if sj+1 is terminal rj,4 Learning Representations and Control Policies,[0],[0]
"+ γ maxa′ Q(sj+1, a′; θ) if sj+1 is non-terminal 17:",4 Learning Representations and Control Policies,[0],[0]
Perform gradient descent step on the loss L(θ) =,4 Learning Representations and Control Policies,[0],[0]
"(yj −Q(sj , aj ; θ))2
Mini-batch Sampling In practice, online updates to the parameters θ are performed over a mini batch of state transitions, instead of a single transition.",4 Learning Representations and Control Policies,[0],[0]
"This increases the number of experiences used per step and is also more efficient due to optimized matrix operations.
",4 Learning Representations and Control Policies,[0],[0]
The simplest method to create these minibatches from the experience memory D is to sample uniformly at random.,4 Learning Representations and Control Policies,[0],[0]
"However, certain experiences are more valuable than others for the agent to learn from.",4 Learning Representations and Control Policies,[0],[0]
"For instance, rare transitions that provide positive rewards can be used more often to learn optimal Q-values faster.",4 Learning Representations and Control Policies,[0],[0]
"In our experiments, we consider such positive-reward transitions to have higher priority and keep track of them in D. We use prioritized sampling (inspired by Moore and Atkeson (1993)) to sample a fraction ρ of transitions from the higher priority pool and a fraction 1− ρ from the rest.",4 Learning Representations and Control Policies,[0],[0]
"Game Environment For our game environment, we modify Evennia,5 an open-source library for building online textual MUD games.",5 Experimental Setup,[0],[0]
"Evennia is a Python-based framework that allows one to easily create new games by writing a batch file describing the environment with details of rooms,
5http://www.evennia.com/
objects and actions.",5 Experimental Setup,[0],[0]
"The game engine keeps track of the game state internally, presenting textual descriptions to the player and receiving text commands from the player.",5 Experimental Setup,[0],[0]
"We conduct experiments on two worlds - a smaller Home world we created ourselves, and a larger, more complex Fantasy world created by Evennia’s developers.",5 Experimental Setup,[0],[0]
"The motivation behind Home world is to abstract away high-level planning and focus on the language understanding requirements of the game.
",5 Experimental Setup,[0],[0]
Table 1 provides statistics of the game worlds.,5 Experimental Setup,[0],[0]
We observe that the Fantasy world is moderately sized with a vocabulary of 1340 words and up to 100 different descriptions for a room.,5 Experimental Setup,[0],[0]
These descriptions were created manually by the game developers.,5 Experimental Setup,[0],[0]
"These diverse, engaging descriptions are designed to make it interesting and exciting for human players.",5 Experimental Setup,[0],[0]
"Several rooms have many alternative descriptions, invoked randomly on each visit by
the player.",5 Experimental Setup,[0],[0]
"Comparatively, the Home world is smaller: it has a very restricted vocabulary of 84 words and the room descriptions are relatively structured.",5 Experimental Setup,[0],[0]
"However, both the room descriptions (which are also varied and randomly provided to the agent) and the quest descriptions were adversarially created with negation and conjunction of facts to force an agent to actually understand the state in order to play well.",5 Experimental Setup,[0],[0]
"Therefore, this domain provides an interesting challenge for language understanding.
",5 Experimental Setup,[0],[0]
"In both worlds, the agent receives a positive reward on completing a quest, and negative rewards for getting into bad situations like falling off a bridge, or losing a battle.",5 Experimental Setup,[0],[0]
We also add small deterministic negative rewards for each nonterminating step.,5 Experimental Setup,[0],[0]
This incentivizes the agent to learn policies that solve quests in fewer steps.,5 Experimental Setup,[0],[0]
"The supplementary material has details on the reward structure.
",5 Experimental Setup,[0],[0]
"Home World We created Home world to mimic the environment of a typical house.6 The world consists of four rooms - a living room, a bedroom, a kitchen and a garden with connecting pathways.",5 Experimental Setup,[0],[0]
Every room is reachable from every other room.,5 Experimental Setup,[0],[0]
Each room contains a representative object that the agent can interact with.,5 Experimental Setup,[0],[0]
"For instance, the kitchen has an apple that the player can eat.",5 Experimental Setup,[0],[0]
Transitions between the rooms are deterministic.,5 Experimental Setup,[0],[0]
"At the start of each game episode, the player is placed in a random room and provided with a randomly selected quest.",5 Experimental Setup,[0],[0]
The text provided to the player contains both the description of her current state and that of the quest.,5 Experimental Setup,[0],[0]
"Thus, the player can begin in one of 16 different states (4 rooms × 4 quests), which adds to the world’s complexity.
",5 Experimental Setup,[0],[0]
An example of a quest given to the player in text is Not you are sleepy now,5 Experimental Setup,[0],[0]
but you are hungry now.,5 Experimental Setup,[0],[0]
"To complete this quest and obtain a reward, the player has to navigate through the house to reach the kitchen and eat the apple (i.e type in the command eat apple).",5 Experimental Setup,[0],[0]
"More importantly, the player should interpret that the quest does not require her to take a nap in the bedroom.",5 Experimental Setup,[0],[0]
"We created such misguiding quests to make it hard for agents to succeed without having an adequate level of language understanding.
",5 Experimental Setup,[0],[0]
"6An illustration is provided in the supplementary material.
",5 Experimental Setup,[0],[0]
Fantasy World,5 Experimental Setup,[0],[0]
The Fantasy world is considerably more complex and involves quests such as navigating through a broken bridge or finding the secret tomb of an ancient hero.,5 Experimental Setup,[0],[0]
This game also has stochastic transitions in addition to varying state descriptions provided to the player.,5 Experimental Setup,[0],[0]
"For instance, there is a possibility of the player falling from the bridge if she lingers too long on it.
",5 Experimental Setup,[0],[0]
"Due to the large command space in this game,7 we make use of cues provided by the game itself to narrow down the set of possible objects to consider in each state.",5 Experimental Setup,[0],[0]
"For instance, in the MUD example in Figure 1, the game provides a list of possible exits.",5 Experimental Setup,[0],[0]
"If the game does not provide such clues for the current state, we consider all objects in the game.
",5 Experimental Setup,[0],[0]
Evaluation We use two metrics for measuring an agent’s performance: (1) the cumulative reward obtained per episode averaged over the episodes and (2) the fraction of quests completed by the agent.,5 Experimental Setup,[0],[0]
The evaluation procedure is as follows.,5 Experimental Setup,[0],[0]
"In each epoch, we first train the agent on M episodes of T steps each.",5 Experimental Setup,[0],[0]
"At the end of this training, we have a testing phase of running M episodes of the game for T steps.",5 Experimental Setup,[0],[0]
"We useM = 50, T = 20 for the Home world and M = 20, T = 250 for the Fantasy world.",5 Experimental Setup,[0],[0]
"For all evaluation episodes, we run the agent following an -greedy policy with = 0.05, which makes the agent choose the best action according to its Q-values 95% of the time.",5 Experimental Setup,[0],[0]
"We report the agent’s performance at each epoch.
",5 Experimental Setup,[0],[0]
Baselines We compare our LSTM-DQN model with three baselines.,5 Experimental Setup,[0],[0]
The first is a Random agent that chooses both actions and objects uniformly at random from all available choices.8,5 Experimental Setup,[0],[0]
"The other two are BOW-DQN and BI-DQN, which use a bagof-words and a bag-of-bigrams representation of the text, respectively, as input to the DQN action scorer.",5 Experimental Setup,[0],[0]
"These baselines serve to illustrate the importance of having a good representation layer for the task.
",5 Experimental Setup,[0],[0]
"Settings For our DQN models, we used D = 100000, γ = 0.5.",5 Experimental Setup,[0],[0]
We use a learning rate of 0.0005 for RMSprop.,5 Experimental Setup,[0],[0]
We anneal the for -greedy from 1 to 0.2 over 100000 transitions.,5 Experimental Setup,[0],[0]
A mini-batch gradient update is performed every 4 steps of the gameplay.,5 Experimental Setup,[0],[0]
"We roll out the LSTM (over words) for
7We consider 222 possible command combinations of 6 actions and 37 object arguments.
",5 Experimental Setup,[0],[0]
"8In the case of the Fantasy world, the object choices are narrowed down using game clues as described earlier.
",5 Experimental Setup,[0],[0]
a maximum of 30 steps on the Home world and for 100 steps on the Fantasy world.,5 Experimental Setup,[0],[0]
"For the prioritized sampling, we used ρ = 0.25 for both worlds.",5 Experimental Setup,[0],[0]
We employed a mini-batch size of 64 and word embedding size d = 20 in all experiments.,5 Experimental Setup,[0],[0]
Home World Figure 3 illustrates the performance of LSTM-DQN compared to the baselines.,6 Results,[0],[0]
"We can observe that the Random baseline performs quite poorly, completing only around 10% of quests on average9 obtaining a low reward of around −1.58.",6 Results,[0],[0]
"The BOW-DQN model performs significantly better and is able to complete around 46% of the quests, with an average reward of 0.20.",6 Results,[0],[0]
The improvement in reward is due to both greater quest success rate and a lower rate of issuing invalid commands (e.g. eat apple would be invalid in the bedroom since there is no apple).,6 Results,[0],[0]
We notice that both the reward and quest completion graphs of this model are volatile.,6 Results,[0],[0]
"This is because the model fails to pick out differences between quests like Not you are hungry now but you are sleepy now and Not you are sleepy now but you
9Averaged over the last 10 epochs.
are hungry now.",6 Results,[0],[0]
The BI-DQN model suffers from the same issue although it performs slightly better than BOW-DQN by completing 48% of quests.,6 Results,[0],[0]
"In contrast, the LSTM-DQN model does not suffer from this issue and is able to complete 100% of the quests after around 50 epochs of training, achieving close to the optimal reward possible.10 This demonstrates that having an expressive representation for text is crucial to understanding the game states and choosing intelligent actions.
",6 Results,[0],[0]
"In addition, we also investigated the impact of using a deep neural network for modeling the action scorer φA. Figure 4 illustrates the performance of the BOW-DQN and BI-DQN models along with their simpler versions BOW-LIN and BI-LIN, which use a single linear layer for φA. It can be seen that the DQN models clearly achieve better performance than their linear counterparts, which points to them modeling the control policy better.
",6 Results,[0],[0]
Fantasy World,6 Results,[0],[0]
"We evaluate all the models on the Fantasy world in the same manner as before and report reward, quest completion rates and Q-
10Note that since each step incurs a penalty of −0.01, the best reward (on average) a player can get is around 0.98.
values.",6 Results,[0],[0]
"The quest we evaluate on involves crossing the broken bridge (which takes a minimum of five steps), with the possibility of falling off at random (a 5% chance) when the player is on the bridge.",6 Results,[0],[0]
The game has an additional quest of reaching a secret tomb.,6 Results,[0],[0]
"However, this is a complex quest that requires the player to memorize game events and perform high-level planning which are beyond the scope of this current work.",6 Results,[0],[0]
"Therefore, we focus only on the first quest.
",6 Results,[0],[0]
"From Figure 3 (bottom), we can see that the Random baseline does poorly in terms of both average per-episode reward11 and quest completion rates.",6 Results,[0],[0]
BOW-DQN converges to a much higher average reward of −12.68 and achieves around 82% quest completion.,6 Results,[0],[0]
"Again, the BOW-DQN is often confused by varying (10 different) descriptions of the portions of the bridge, which reflects in its erratic performance on the quest.",6 Results,[0],[0]
The BI-DQN performs very well on quest completion by finishing 97% of quests.,6 Results,[0],[0]
"However, this model tends to find sub-optimal solutions and gets an average reward of −26.68, even worse than BOW-DQN.",6 Results,[0],[0]
One reason for this is the negative rewards the agent obtains after falling off the bridge.,6 Results,[0],[0]
"The LSTM-DQN model again performs best, achieving an average reward of −11.33 and completing 96% of quests on average.",6 Results,[0],[0]
"Though this world does not contain descriptions adversarial to BOW-DQN or BIDQN, the LSTM-DQN obtains higher average reward by completing the quest in fewer steps and showing more resilience to variations in the state descriptions.
",6 Results,[0],[0]
Transfer Learning,6 Results,[0],[0]
"We would like the representations learnt by φR to be generic enough and
11Note that the rewards graph is in log scale.
",6 Results,[0],[0]
transferable to new game worlds.,6 Results,[0],[0]
"To test this, we created a second Home world with the same rooms, but a completely different map, changing the locations of the rooms and the pathways between them.",6 Results,[0],[0]
"The main differentiating factor of this world from the original home world lies in the high-level planning required to complete quests.
",6 Results,[0],[0]
"We initialized the LSTM part of an LSTMDQN agent with parameters θR learnt from the original home world and trained it on the new world.12 Figure 3 (top right) demonstrates that the agent with transferred parameters is able to learn quicker than an agent starting from scratch initialized with random parameters (No Transfer), reaching the optimal policy almost 20 epochs earlier.",6 Results,[0],[0]
"This indicates that these simulated worlds can be used to learn good representations for language that transfer across worlds.
",6 Results,[0],[0]
Prioritized sampling We also investigate the effects of different minibatch sampling procedures on the parameter learning.,6 Results,[0],[0]
"From Figure 3 (bottom right), we observe that using prioritized sampling significantly speeds up learning, with the agent achieving the optimal policy around 50 epochs faster than using uniform sampling.",6 Results,[0],[0]
"This shows promise for further research into different schemes of assigning priority to transitions.
",6 Results,[0],[0]
Representation Analysis We analyzed the representations learnt by the LSTM-DQN model on the Home world.,6 Results,[0],[0]
"Figure 5 shows a visualization
12The parameters for the Action Scorer (θA) are initialized randomly.
of learnt word embeddings, reduced to two dimensions using t-SNE (Van der Maaten and Hinton, 2008).",6 Results,[0],[0]
All the vectors were initialized randomly before training.,6 Results,[0],[0]
We can see that semantically similar words appear close together to form coherent subspaces.,6 Results,[0],[0]
"In fact, we observe four different subspaces, each for one type of room along with its corresponding object(s) and quest words.",6 Results,[0],[0]
"For instance, food items like pizza and rooms like kitchen are very close to the word hungry which appears in a quest description.",6 Results,[0],[0]
This shows that the agent learns to form meaningful associations between the semantics of the quest and the environment.,6 Results,[0],[0]
Table 2 shows some examples of descriptions from Fantasy world and their nearest neighbors using cosine similarity between their corresponding vector representations produced by LSTM-DQN.,6 Results,[0],[0]
The model is able to correlate descriptions of the same (or similar) underlying states and project them onto nearby points in the representation subspace.,6 Results,[0],[0]
We address the task of end-to-end learning of control policies for text-based games.,7 Conclusions,[0],[0]
"In these games, all interactions in the virtual world are through text and the underlying state is not observed.",7 Conclusions,[0],[0]
The resulting language variability makes such environments challenging for automatic game players.,7 Conclusions,[0],[0]
We employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback.,7 Conclusions,[0],[0]
This framework enables us to map text descriptions into vector representations that capture the semantics of the game states.,7 Conclusions,[0],[0]
Our experiments demonstrate the importance of learning good representations of text in order to play these games well.,7 Conclusions,[0],[0]
"Future directions include tackling high-level
planning and strategy learning to improve the performance of intelligent agents.",7 Conclusions,[0],[0]
"We are grateful to the developers of Evennia, the game framework upon which this work is based.",Acknowledgements,[0],[0]
"We also thank Nate Kushman, Clement Gehring, Gustavo Goretkin, members of MIT’s NLP group and the anonymous EMNLP reviewers for insightful comments and feedback.",Acknowledgements,[0],[0]
T. Kulkarni was graciously supported by the Leventhal Fellowship.,Acknowledgements,[0],[0]
"We would also like to acknowledge MIT’s Center for Brains, Minds and Machines (CBMM) for support.",Acknowledgements,[0],[0]
"In this paper, we consider the task of learning control policies for text-based games.",abstractText,[0],[0]
"In these games, all interactions in the virtual world are through text and the underlying state is not observed.",abstractText,[0],[0]
The resulting language barrier makes such environments challenging for automatic game players.,abstractText,[0],[0]
We employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback.,abstractText,[0],[0]
This framework enables us to map text descriptions into vector representations that capture the semantics of the game states.,abstractText,[0],[0]
"We evaluate our approach on two game worlds, comparing against baselines using bag-ofwords and bag-of-bigrams for state representations.",abstractText,[0],[0]
Our algorithm outperforms the baselines on both worlds demonstrating the importance of learning expressive representations.,abstractText,[0],[0]
1,abstractText,[0],[0]
Language Understanding for Text-based Games using Deep Reinforcement Learning,title,[0],[0]
"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1009–1019, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics",text,[0],[0]
Truth-finding algorithms aim to separate true statements (facts) from false information.,1 Introduction,[0],[0]
"More specifically, given a set of statements whose truthfulness is unknown (fact candidates), the key goal of truth-finding algorithms is to generate a ranking such that true statements are ranked ahead of false ones.",1 Introduction,[0],[0]
Truth-finders have the potential to address a major obstacle on the Web: the problem of sources spreading inaccurate and conflicting information.,1 Introduction,[0],[0]
This problem continues to grow with the development of tools for easy Web authorship.,1 Introduction,[0],[0]
"Blogs, forums and social networking websites are not subject to traditional journalistic standards.",1 Introduction,[0],[0]
"Consequently, the accuracy of information reported by these sources is often unclear.",1 Introduction,[0],[0]
Even more established newspapers and websites may sometimes report false information as they race to break stories.,1 Introduction,[0],[0]
"Therefore, truth-finding is becoming an in-
creasingly important problem.",1 Introduction,[0],[0]
"Information extraction projects aim to distill relational facts from natural language text (Auer et al., 2007; Bollacker et al., 2008; Carlson et al., 2010; Fader et al., 2011; Nakashole et al., 2011; Del Corro and Gemulla, 2013).",1 Introduction,[0],[0]
These projects have produced knowledge bases containing many millions of relational facts between entities.,1 Introduction,[0],[0]
"However, despite these impressive advances, there are still major limitations regarding precision.",1 Introduction,[0],[0]
"Within the context of information extraction, fact extractors assign confidence scores to extracted facts.",1 Introduction,[0],[0]
"However, such scores are often tied to the extractor’s ability to read and understand natural language text.",1 Introduction,[0],[0]
This is different from a score that indicates the degree to which a given fact candidate is believable.,1 Introduction,[0],[0]
Such a believability score is sometimes also referred to as a credibility score or truthfulness score.,1 Introduction,[0],[0]
The believability score reflects the likelihood that a given statement is true.,1 Introduction,[0],[0]
"Truth-finding algorithms aim to compute this score for each fact candidate.
",1 Introduction,[0],[0]
"Prior truth-finding methods are mostly based on iterative voting, where votes are propagated from sources to fact candidates and then back to sources (Yin et al., 2007; Galland et al., 2010; Pasternack and Roth, 2010; Li et al., 2011; Yin and Tan, 2011).",1 Introduction,[0],[0]
At the core of iterative voting is the assumption that candidates mentioned by many sources are more likely to be true.,1 Introduction,[0],[0]
"However, additional aspects of a source influence its trustworthiness, besides external votes.
",1 Introduction,[0],[0]
Our goal is to accurately assess truthfulness of fact candidates by taking into account the language of sources that mention them.,1 Introduction,[0],[0]
A Mechanical Turk study we carried out revealed that there is a significant correlation between objectivity of language and trustworthiness of sources.,1 Introduction,[0],[0]
"Objectivity of language refers to the use of neutral, impartial language, which is not personal, judgmental, or emotional.",1 Introduction,[0],[0]
"Trustworthiness refers to
1009
a source of information being reliable and truthful.",1 Introduction,[0],[0]
We use linguistics features to detect if a given source objectively states facts or is speculative and opinionated.,1 Introduction,[0],[0]
"Additionally, in order to ensure that fact candidates mentioned in similar sources have similar believability scores, our believability computation model incorporates influence of comentions.",1 Introduction,[0],[0]
"However, we must avoid falsely boosting co-mentioned fact candidates.",1 Introduction,[0],[0]
"Our model addresses potential false boosts in two ways: first, by ensuring that co-mention influence is only propagated to related fact candidates; second, by ensuring that the degree of co-mention influence is determined by the trustworthiness of the sources in which co-mentions occur.
",1 Introduction,[0],[0]
The contribution of this paper is a languageaware truth-finding approach.,1 Introduction,[0],[0]
"More precisely, we make the following contributions: (1) Alternative Fact Candidates: Truth-finders rank a given fact candidate with respect to its alternatives.",1 Introduction,[0],[0]
"For example, alternative places where Barack Obama could have been born.",1 Introduction,[0],[0]
Virtually all existing truth-finders assume that the alternatives are provided.,1 Introduction,[0],[0]
"In contrast, we developed a method for generating alternative fact candidates.",1 Introduction,[0],[0]
(2) Objectivity-Trustworthiness Correlation: We hypothesize that objectivity of language and trustworthiness of sources are positively correlated.,1 Introduction,[0],[0]
"To test this hypothesis, we designed a Mechanical Turk study.",1 Introduction,[0],[0]
The study showed that this correlation does in fact hold.,1 Introduction,[0],[0]
"(3) Objectivity Classifier: Using labeled data from the Mechanical Turk study, we developed and trained an objectivity classifier which performed better than prior proposed lexicons from literature.",1 Introduction,[0],[0]
"(4) Believability Computation: We developed FactChecker, a truth-finding method that linearly combines objectivity and comention influence.",1 Introduction,[0],[0]
Our experiments showed that FactChecker outperforms prior methods.,1 Introduction,[0],[0]
"In this section, we formally define what constitutes a fact candidate and describe how we go about understanding semantics of fact candidates.",2 Fact Candidates,[0],[0]
We then present our approach for generating alternative fact candidates.,2 Fact Candidates,[0],[0]
The triple format is the most common representation of facts in knowledge bases.,2.1 Representation,[0],[0]
"A formal specifi-
cation of the triple format is presented in the RDF primer1.",2.1 Representation,[0],[0]
"In RDF, data is represented as subjectpredicate-object (SPO) triples.",2.1 Representation,[0],[0]
"In this work, we restrict predicates to verbs (or verbal phrases such as “plays for”, “graduated from”, etc.).",2.1 Representation,[0],[0]
"Literature on automatic relation discovery (Fader et al., 2011) has shown that verbal phrases uncover a large fraction of binary predicates while reducing the amount of noisy phrases that do not denote any relations.",2.1 Representation,[0],[0]
"Therefore, we define a fact candidate as follows:
Definition 1 (Fact Candidate)",2.1 Representation,[0],[0]
"A fact candidate fi is an 〈S〉 V 〈O〉 triple; where S is the subject, V is a verbal phrase, and O is the object.",2.1 Representation,[0],[0]
"We aim to compute the truthfulness of fi, τ(fi) ∈ {T, F}, where T and F stand for true and false, respectively.
",2.1 Representation,[0],[0]
Note that in this paper we are interested in cases where τ(fi) is either T or F .,2.1 Representation,[0],[0]
"That is, we assess truthfulness of factual statements and not opinions whose truthfulness is often both T and F to some degree.",2.1 Representation,[0],[0]
"For example, the triples: 〈Obama〉 born in 〈Kenya〉 and 〈Obama〉 graduated from 〈Harvard〉 are valid fact candidates.",2.1 Representation,[0],[0]
"However, the triple: 〈Obama〉 deserves 〈Nobel Peace Prize〉 is not.",2.1 Representation,[0],[0]
"Based on the SVO triple, the meaning of a fact candidate can be unclear and ambiguous.",2.2 Semantics,[0],[0]
"Therefore, we first determine the semantics of a fact candidate before computing its truthfulness.",2.2 Semantics,[0],[0]
Entity Types.,2.2 Semantics,[0],[0]
We first determine the expected types of the subject and object in the SVO.,2.2 Semantics,[0],[0]
"For example, for the SVO 〈Einstein〉 died in 〈Princeton〉, the expected types are person × location.",2.2 Semantics,[0],[0]
"We determine this by first computing the types of entities that are valid for each verb (verbal phrase) in a large SVO collection of 114m SVO triples (Talukdar et al., 2012).",2.2 Semantics,[0],[0]
Typing verbal phrases is a once-off computation.,2.2 Semantics,[0],[0]
"Our phrase typing method is similar to prior work on typing relational phrases (Nakashole et al., 2012).",2.2 Semantics,[0],[0]
"Examples of typed phrases are: 〈person〉 died in 〈year〉, 〈person〉 died in 〈location〉, and 〈athlete〉 plays for 〈team〉.",2.2 Semantics,[0],[0]
"Given a triple, we look up the types for the subject and the object and then determine which of the typed phrases are compatible with the current triple.",2.2 Semantics,[0],[0]
"We look up entity types in a knowledge
1http://www.w3.org/TR/rdf-primer/
base containing entities and their types.",2.2 Semantics,[0],[0]
"In particular, we use the NELL entity typing API (Carlson et al., 2010).",2.2 Semantics,[0],[0]
"NELL’s entity typing method has high recall because when entities are not in the knowledge base, it performs on-the-fly type inference using the Web.",2.2 Semantics,[0],[0]
"This is not the case for other options such as (Auer et al., 2007; Bollacker et al., 2008; Hoffart et al., 2011).",2.2 Semantics,[0],[0]
Relation Cardinality.,2.2 Semantics,[0],[0]
"Next, we learn cardinalities of verbal phrases.",2.2 Semantics,[0],[0]
Cardinality refers to how arguments of a given relation relate to one another numerically.,2.2 Semantics,[0],[0]
"We define the relation cardinality of a verb Card(V ), as the average number of expected arguments per given subject.",2.2 Semantics,[0],[0]
"For example, for the relation “died in”, 1 location is expected for each subject.",2.2 Semantics,[0],[0]
"For other relations, the expected number of arguments can be greater than 1 but less than n : n ∈ R, n > 1.",2.2 Semantics,[0],[0]
We approximate n using statistics from the 114m SVO corpus based on the average number of arguments per given first argument.,2.2 Semantics,[0],[0]
"In a once-off computation, we generate cardinality approximations per typed verbal phrase V and its inverse V −1.",2.2 Semantics,[0],[0]
"For example, we generate the cardinality estimates for both: 〈person〉 died in 〈location〉 and for 〈location〉 INVERSE-OF(died in) 〈person〉.",2.2 Semantics,[0],[0]
Synonymous Relations.,2.2 Semantics,[0],[0]
Natural language is diverse.,2.2 Semantics,[0],[0]
Semantically similar phrases can be syntactically different.,2.2 Semantics,[0],[0]
"Therefore, we learn other verbs that can be used to substitute V in SVO.",2.2 Semantics,[0],[0]
"We pre-compute synonymous phrases from the 114m SVO corpus using distributional semantics in the same spirit as (Lin and Pantel, 2001; Nakashole et al., 2012).
",2.2 Semantics,[0],[0]
"Synonymous verbs, relation cardinalities, and entity types enable us to generate alternative fact candidates.",2.2 Semantics,[0],[0]
Truth-finding methods rank fi relative to alternative candidates.,2.3 Alternative Fact Candidates,[0],[0]
"While prior methods assume the alternatives are known apriori, we developed a method for generating alternative fact candidates.",2.3 Alternative Fact Candidates,[0],[0]
"For a given fi, we first identify the fixed argument.",2.3 Alternative Fact Candidates,[0],[0]
"The fixed argument is the argument of the SVO which when fixed, requires finding the fewest number of alternative candidates.",2.3 Alternative Fact Candidates,[0],[0]
"For example, for 〈Einstein〉 died in 〈Princeton〉, the solution is to fix the subject.",2.3 Alternative Fact Candidates,[0],[0]
"This is because the cardinality of 〈person〉 died in 〈location〉 is one (1).
",2.3 Alternative Fact Candidates,[0],[0]
"On the other hand, the cardinality of “INVERSEOF(died in)” is many(n).",2.3 Alternative Fact Candidates,[0],[0]
"In other words, the number of places where a person can be born (one) is much fewer than the number of people that can die in a place (many).",2.3 Alternative Fact Candidates,[0],[0]
"In our example, alternatives are possible places, other than Princeton, where Einstein could have died.",2.3 Alternative Fact Candidates,[0],[0]
For example: 〈Einstein〉 died in 〈Germany〉 or 〈Einstein〉 died in 〈Switzerland〉.,2.3 Alternative Fact Candidates,[0],[0]
"More generally, the fixed argument of fact candidate fi, is defined as follows:
Definition 2 (Fixed Argument) Let Card(V) be the cardinality of V and Card(V −1) be the cardinality of the inverse of V ,",2.3 Alternative Fact Candidates,[0],[0]
"if Card(V ) < Card(V −1), then the fixed argument is the subject, Argfixed(fi)",2.3 Alternative Fact Candidates,[0],[0]
"= S, else it is the object, O.",2.3 Alternative Fact Candidates,[0],[0]
"If Card(V ) == Card(V −1), then both arguments are fixed, one at a time.
",2.3 Alternative Fact Candidates,[0],[0]
We use the fixed argument to define a topic as the fixed argument plus the verb.,2.3 Alternative Fact Candidates,[0],[0]
"Therefore, for the SVO 〈X〉 died in 〈Y〉, the topic “places where X died”, (Argfixed = S), is not the same as the topic “people who died in Y” (Argfixed = O).
",2.3 Alternative Fact Candidates,[0],[0]
"To locate alternatives, we use the topic (Argfixed + V ) as a query.",2.3 Alternative Fact Candidates,[0],[0]
"We search three sources to either locate relevant documents or relevant triples: the Google Web search API, the 114m SVO collection, and the NELL KB.",2.3 Alternative Fact Candidates,[0],[0]
"The SVO collection and the KB return triples, however, the Web search API returns documents.",2.3 Alternative Fact Candidates,[0],[0]
"Therefore, we apply a triple extractor to the retrieved documents.",2.3 Alternative Fact Candidates,[0],[0]
"For all potential alternative triples, we perform type checking to ensure that the arguments of the triples are type-compatible with fi.",2.3 Alternative Fact Candidates,[0],[0]
"Furthermore, we generate an additional query for every synonymous verb sVi, replacing V with sVi.",2.3 Alternative Fact Candidates,[0],[0]
"Example queries are: “Einstein died in”, “Einstein passed in”, etc.",2.3 Alternative Fact Candidates,[0],[0]
"The principle of objective journalism, which is a significant part of journalistic ethics, aims to promote factual and fair reporting, undistorted by emotion or personal bias (Schudson, 1978; Kaplan, 2002).",3 Objectivity and Trustworthiness,[0],[0]
"Objectivity is also required in reference sources such as encyclopedias, scientific publications, and textbooks.",3 Objectivity and Trustworthiness,[0],[0]
"For example, Wikipedia enforces a neutral point-of-view policy (NPOV)2.",3 Objectivity and Trustworthiness,[0],[0]
"Articles violating the NPOV policy are marked
2http://en.wikipedia.org/wiki/Wikipedia:Neutral point of view
to indicate potential bias.",3 Objectivity and Trustworthiness,[0],[0]
"While opinions, emotions, and speculations can also be expressed using objective language, they are often stated using subjective language (Turney et al., 2002; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Wiebe et al., 2004; Liu et al., 2005; Recasens et al., 2013).",3 Objectivity and Trustworthiness,[0],[0]
"For example, consider the following pieces of text:
(S)",3 Objectivity and Trustworthiness,[0],[0]
"Well, I think Obama was born in Kenya because his grandma who lives in Kenya said he was born there.",3 Objectivity and Trustworthiness,[0],[0]
"(O) Theories allege that Obama’s published birth certificate is a forgery, that his actual birthplace is not Hawaii but Kenya.
",3 Objectivity and Trustworthiness,[0],[0]
Text S is a snippet from Yahoo Answers and text O is a snippet from the Wikipedia page titled: “Barack Obama Citizenship Conspiracy Theories”.,3 Objectivity and Trustworthiness,[0],[0]
"S is subjective, expressing the opinion of the author.",3 Objectivity and Trustworthiness,[0],[0]
"On the other hand, O is objective, stating only what has been alleged.",3 Objectivity and Trustworthiness,[0],[0]
"Literature on sentiment analysis (Turney et al., 2002; Liu et al., 2005), subjectivity detection (Riloff and Wiebe, 2003; Wiebe et al., 2004), and bias detection (Yu and Hatzivassiloglou, 2003; Recasens et al., 2013) has developed lexicons for identifying subjective language.",3 Objectivity and Trustworthiness,[0],[0]
"Due to the principle of objective journalism and the requirement of objectivity placed on reference sources, we hypothesize a link between objectivity and trustworthiness as follows.
",3 Objectivity and Trustworthiness,[0],[0]
Hypothesis 1,3 Objectivity and Trustworthiness,[0],[0]
Objective sources are more trustworthy than subjective sources.,3 Objectivity and Trustworthiness,[0],[0]
"Therefore, we can assume that fact candidates stated in objective sources are more likely to be true than those stated in subjective sources.
",3 Objectivity and Trustworthiness,[0],[0]
"To test the validity of the hypothesis, we carried out a study where we solicited human input.",3 Objectivity and Trustworthiness,[0],[0]
"We deployed an annotation study on Amazon Mechanical Turk (MTurk)3, a crowd-sourcing platform for tasks requiring human input.",3.1 Mechanical Turk Study,[0],[0]
Tasks on MTurk are small questionnaires consisting of a description and a set of questions.,3.1 Mechanical Turk Study,[0],[0]
Our study consisted of two independent tasks.,3.1 Mechanical Turk Study,[0],[0]
"The first task was titled “Trustworthiness of News Articles”, where annotators were given a link to a news article and
3http://www.mturk.com
Figure 1:",3.1 Mechanical Turk Study,[0],[0]
"Summary of the results of the annotation study on objectivity and trustworthiness.
",3.1 Mechanical Turk Study,[0],[0]
asked to judge if they thought it was trustworthy or not.,3.1 Mechanical Turk Study,[0],[0]
The second task was titled “Objectivity of News Articles”.,3.1 Mechanical Turk Study,[0],[0]
"For this task, annotators were asked to judge if a given article is objective or subjective.",3.1 Mechanical Turk Study,[0],[0]
For both tasks a third option of “not sure” was provided.,3.1 Mechanical Turk Study,[0],[0]
"We randomly selected 500 news articles from a corpus of about 300,000 news articles obtained from Google News from the topics of Top News, Business, Entertainment, and SciTech.",3.1 Mechanical Turk Study,[0],[0]
"For each task, every article was judged by three annotators.",3.1 Mechanical Turk Study,[0],[0]
This produced a total of 3000 annotations.,3.1 Mechanical Turk Study,[0],[0]
"When we analyzed the output, we accepted a label as valid for a given article if the label was selected by the majority of the judges.",3.1 Mechanical Turk Study,[0],[0]
"Based on this criteria, we obtained a set of 420 articles that were both labeled for trustworthiness and objectivity.
",3.1 Mechanical Turk Study,[0],[0]
A summary of the outcome of the study is shown in Figure 1; 74% of the untrustworthy articles were independently labeled as subjective.,3.1 Mechanical Turk Study,[0],[0]
"On the other hand, 64% of trustworthy articles were independently labeled as objective.",3.1 Mechanical Turk Study,[0],[0]
These results indicate a non-trivial positive correlation between objectivity and trustworthiness.,3.1 Mechanical Turk Study,[0],[0]
We leverage this correlation in our believability computation model.,3.1 Mechanical Turk Study,[0],[0]
"To incorporate objectivity in FactChecker, we require for a given source document, an objectivity score ∈",3.1 Mechanical Turk Study,[0],[0]
"[0, 1], where 0 means the source is subjective and 1 means it is objective.",3.1 Mechanical Turk Study,[0],[0]
"Next, describe our method for automatically determining objectivity of sources.",3.1 Mechanical Turk Study,[0],[0]
We trained a logistic regression classifier to predict the objectivity of a document.,3.2 Automatic Objectivity Detection,[0],[0]
"For training and testing data, we used the labeled data from the Mechanical Turk study.",3.2 Automatic Objectivity Detection,[0],[0]
"We additionally used labeled text from prior work on subjectivity detection (Pang and Lee, 2004).",3.2 Automatic Objectivity Detection,[0],[0]
"This resulted in a total of 4, 600 documents, half subjective and the other half objective.",3.2 Automatic Objectivity Detection,[0],[0]
"We used 4000 documents for
training, 2000 per label.",3.2 Automatic Objectivity Detection,[0],[0]
"The rest of the documents were split into a development set (380) and a test set (220).
",3.2 Automatic Objectivity Detection,[0],[0]
A summary of the features we used is shown in Table 1.,3.2 Automatic Objectivity Detection,[0],[0]
"Features 1-3 refer to lexicons developed by prior methods on subjectivity (Wiebe et al., 2004), sentiment analysis (Liu et al., 2005) and bias detection (Recasens et al., 2013).",3.2 Automatic Objectivity Detection,[0],[0]
Feature 4 refers to part-of-speech tags of the terms found in the document that are also in the lexicons.,3.2 Automatic Objectivity Detection,[0],[0]
"Feature 5 refers to bi-grams that frequently occur (mention frequency of > 10) in the 4, 600 documents.",3.2 Automatic Objectivity Detection,[0],[0]
"The most contributing features were the lexicons, features (1-3) and the frequent bi-grams, feature 5.",3.2 Automatic Objectivity Detection,[0],[0]
We discovered that using frequent bi-gram features instead of uni-grams or bi-grams resulted in higher precision.,3.2 Automatic Objectivity Detection,[0],[0]
"The classifier was able to determine that for example bi-grams such as “think that”, “so funny” and “you thought” are negative features for objectivity.",3.2 Automatic Objectivity Detection,[0],[0]
Evaluation results of our objectivity detector vs. baselines are shown in Table 2.,3.2 Automatic Objectivity Detection,[0],[0]
"FactChecker’s objectivity detector has precision of 0.7814 ± 0.0539, with a 0.9-confidence Wilson score interval (Brown et al., 2001) and this outperforms the baselines.",3.2 Automatic Objectivity Detection,[0],[0]
"Next, we describe how we leverage objectivity into FactChecker’s truthfulness model.",3.2 Automatic Objectivity Detection,[0],[0]
FactChecker computes the believability score of a fact candidate from its: i) objectivity score and (ii) co-mention score.,4 Believability Computation Model,[0],[0]
"In this section we define each of these scores.
",4 Believability Computation Model,[0],[0]
The objectivity score reflects the trustworthiness of sources where a fact candidate is mentioned.,4 Believability Computation Model,[0],[0]
"Given a fact candidate fi, mentioned in a set of documents Di, where each document d ∈
Di has objectivity O(d), fi’s objectivity score is defined as follows:
Definition 3 (Objectivity Score)
O(fi) = log|Di|.
∑ dk∈Di O(dk)
|Di| (1)
We do not use the sum of objectivity of sources as the objectivity score because this enables fact candidates mentioned in many low objectivity sources to have high aggregate objectivity.",4 Believability Computation Model,[0],[0]
"Similarly, we avoid using average objectivity of the sources as it overestimates objectivity of candidates stated in few sources.",4 Believability Computation Model,[0],[0]
A candidate mentioned in 10 sources with 0.9 objectivity should have higher objectivity than a candidate stated in 1 source of 0.9 objectivity.,4 Believability Computation Model,[0],[0]
"In Equation 1, log|Di| addresses this issue.
",4 Believability Computation Model,[0],[0]
The co-mention score aims to ensure that fact candidates mentioned in similar sources have similar believability scores.,4 Believability Computation Model,[0],[0]
"Suppose candidate fi is mentioned in many highly objective sources, another candidate fj is stated in only one highly objective source dk where fi is also mentioned.",4 Believability Computation Model,[0],[0]
Then the believability of fj should be boosted by it being co-mentioned with fi.,4 Believability Computation Model,[0],[0]
"If on the other hand fi and fj were co-mentioned in a subjective source, fj should receive less boost from fi.",4 Believability Computation Model,[0],[0]
"This leads us to the co-mention score µ(fi) of a candidate.
",4 Believability Computation Model,[0],[0]
"Definition 4 (Co-Mention Score)
µ(fi)",4 Believability Computation Model,[0],[0]
"= ρ(fi) + ∑ fj∈F wijµ(fj) (2)
Where ρ(fi) is the normalized mention frequency of fi.",4 Believability Computation Model,[0],[0]
The propagation weight wij controls how much boost is obtained from a co-mentioned candidate.,4 Believability Computation Model,[0],[0]
"We define propagation weight, wij , as the average of the objectivity of the sources that mention both candidates.
",4 Believability Computation Model,[0],[0]
"wij = average O(dk) : dk ∈ (Di ∩Dj) (3)
where O(dk) is the objectivity of document dk, Di and Dj are the sets of documents that mention fi and fj , respectively.",4 Believability Computation Model,[0],[0]
"Notice that we could boost co-mentioned but not related candidates, thereby causing false boosts.",4 Believability Computation Model,[0],[0]
"To remedy this, we only allow wij to be greater than zero if the fact candidates fi and fj are on the same topic.",4 Believability Computation Model,[0],[0]
Recall that the topic is determined by the fixed argument (Definition 2) and the verb.,4 Believability Computation Model,[0],[0]
"Allowing only fact candidates on the same topic to influence each other is important considering that many trivial facts are often repeated in sources of diverse quality.
",4 Believability Computation Model,[0],[0]
"To leverage the inter-dependencies among related co-mentioned fact candidates, we model the solution with a graph ranking method.",4 Believability Computation Model,[0],[0]
"Each fact candidate is a node and there is an edge between each pair of related fact candidate nodes fi and fj , with wij as the edge weight.",4 Believability Computation Model,[0],[0]
"Thus, equation 2 can be reformulated as µ = Mµ, where µ is the co-mention score vector and M is a Markov matrix which is stochastic, irreducible and aperiodic.",4 Believability Computation Model,[0],[0]
"Thus, a power method will converge to a solution in a similar manner to PageRank.",4 Believability Computation Model,[0],[0]
Implementation consists of iteratively applying Equation 2 until the change in the score is less than a threshold .,4 Believability Computation Model,[0],[0]
"The solution is the final co-mention scores of fact candidates.
",4 Believability Computation Model,[0],[0]
"Finally, to compute the believability score of a fact candidate, we linearly combine its objectivity score with its co-mention as follows:
Definition 5 (Believability Score)
β(fi)",4 Believability Computation Model,[0],[0]
"= λO(fi) + (1− λ)µ(fi) (4)
Where λ is a weighting parameter ∈",4 Believability Computation Model,[0],[0]
"[0, 1] which controls the relative importance of the two aspects of FactChecker.",4 Believability Computation Model,[0],[0]
"As we show in our experiments, λ can be robustly chosen within the range of 0.2 to 0.6.",4 Believability Computation Model,[0],[0]
"In our experiments we used λ = 0.6.
",4 Believability Computation Model,[0],[0]
The entire procedure of FactChecker is summarized in Algorithm 1.,4 Believability Computation Model,[0],[0]
We evaluated FactChecker for accuracy.,5 Evaluation,[0],[0]
We define accuracy as the probability of a true fact candidate having a higher believability score than a false candidate.,5 Evaluation,[0],[0]
Let τ(fi),5 Evaluation,[0],[0]
"∈ {T, F} be the truthfulness of a fact candidate fi, accuracy is defined as:
Algorithm 1 FactChecker Input: A set F of fact candidates Input: KB K, SVO corpus C, WebW Output: A set L of rankings ∀fi ∈ F L = ∅",5 Evaluation,[0],[0]
"while F 6= ∅ do
pick fi from F A= getAlternatives(fi,K,C,W) PriorityQueue Li = ∅ for all alternative fact candidates f ′j ∈",5 Evaluation,[0],[0]
A do β(f ′j),5 Evaluation,[0],[0]
"= getBelievabilityScore(f ′j) Li.insert(f ′j , β(f ′ j)) end for β(f i) = getBelievabilityScore(fi) Li.insert(fi, β(fi))",5 Evaluation,[0],[0]
"L ∪ Li Remove fi from F
end while return L
Acc =
∑ (τ(fi)=T :τ(fj)=F ) (β(fi) > β(fj))
",5 Evaluation,[0],[0]
"|{∀(fi, fj) : τ(fi)",5 Evaluation,[0],[0]
"= T ∧ τ(fj) = F}|
Datasets.",5 Evaluation,[0],[0]
We evaluated FactChecker on three datasets: i) KB Fact Candidates:,5 Evaluation,[0],[0]
"The first dataset consists of fact candidates taken from the fact extraction pipeline of a state-of-the-art knowledge base, NELL (Carlson et al., 2010).",5 Evaluation,[0],[0]
"The fact candidates span four different relation types: company acquisitions, book authors, movie directors and athlete teams.",5 Evaluation,[0],[0]
"For each fact candidate, we applied our alternative candidate generation method.",5 Evaluation,[0],[0]
We only considered fact candidates with non-trivial alternative candidate sets; where the alternative candidate set is greater than zero.,5 Evaluation,[0],[0]
"Since all of the baselines we compared against assume alternatives are provided, we apply all methods to the same set of alternative fact candidates discovered by our method.",5 Evaluation,[0],[0]
"Details of this dataset are shown as rows starting with “KB-” in Table 3.
ii)",5 Evaluation,[0],[0]
"Wikipedia Fact Candidates: For the second dataset, we did not restrict the fact candidates to specific topics from a knowledge base, instead we aimed to evaluate all fact candidates about a given entity.",5 Evaluation,[0],[0]
We selected entities from Wikipedia.,5 Evaluation,[0],[0]
"For this, we chose US politicians: all current state senators, all current state governors, and all 44 presidents.",5 Evaluation,[0],[0]
"First, we extracted fact candidates
from the infoboxes of the Wikipedia pages of the entities.",5 Evaluation,[0],[0]
"Second, we applied our alternative candidate generation method to discover alternatives from the Web, SVO corpus, and NELL.",5 Evaluation,[0],[0]
"Details of the resulting dataset are shown in the row “WKP Politicians” in Table 3.
iii) General Knowledge Quiz:",5 Evaluation,[0],[0]
The third dataset consists of questions from a general knowledge quiz 4.,5 Evaluation,[0],[0]
We selected questions from the inventions category.,5 Evaluation,[0],[0]
"Questions are multiple choice, with 4 options per question.",5 Evaluation,[0],[0]
"Thus, from each question, we created one fact candidate and 3 alternative candidates.",5 Evaluation,[0],[0]
Details of the resulting dataset are shown in the row “KWP Quiz” in Table 3.,5 Evaluation,[0],[0]
Baselines.,5 Evaluation,[0],[0]
We compared FactChecker against five baselines: i) Vote counts the number of sources that mention the fact candidate.,5 Evaluation,[0],[0]
ii),5 Evaluation,[0],[0]
TruthFinder is an iterative voting approach where votes are propagated from sources to fact candidates and then back to sources.,5 Evaluation,[0],[0]
"Implemented as described in (Yin et al., 2007).",5 Evaluation,[0],[0]
"iii) Investment is also based on transitive voting, however scores are updated differently.",5 Evaluation,[0],[0]
"A source gets a vote of trust from each candidate it “invests” in, but the vote is weighted by the proportion of trust the source previously “invested” in the candidate relative to other investors.",5 Evaluation,[0],[0]
"Implemented as described in (Pasternack and Roth, 2010).",5 Evaluation,[0],[0]
iv),5 Evaluation,[0],[0]
"PooledInvest is a variation of investment, we report both because in their paper, there was no clear winner among the two variations.",5 Evaluation,[0],[0]
"v) 2-Estimates is a probabilistic model which approximates error rates of sources and fact candidates (Galland et al., 2010).",5 Evaluation,[0],[0]
Figure 2 shows accuracy on KB fact candidates.,5.1 Accuracy on KB Fact Candidates,[0],[0]
"FactChecker achieves accuracy between 70% and 88% and is significantly more accurate than the
4http://www.indiabix.com/general-knowledge/
other approaches on all relations except company acquisitions.",5.1 Accuracy on KB Fact Candidates,[0],[0]
"On book authors, movie directors, and athlete teams, FactChecker outperforms all other approaches by at least 10%, 9%, and 8% respectively.",5.1 Accuracy on KB Fact Candidates,[0],[0]
"On company acquisitions, the different methods achieve similar accuracy, with TruthFinder being the most accurate and FactChecker is 4% behind.",5.1 Accuracy on KB Fact Candidates,[0],[0]
"Company acquisitions also yield the lowest difference between Vote and the highest performing method, of 6%.",5.1 Accuracy on KB Fact Candidates,[0],[0]
"For book authors, movie directors, and athlete teams, the difference between majority Vote and the highest performing method (FactChecker in this case) is 13%, 12%, and 13% respectively.",5.1 Accuracy on KB Fact Candidates,[0],[0]
"To quantify how various aspects of our approach affect overall performance, we studied two variations.",5.2 Accuracy of FactChecker Variations,[0],[0]
The first variation is FC-Objectivity which only uses objectivity to compute believability.,5.2 Accuracy of FactChecker Variations,[0],[0]
"Thus, λ = 1 in Definition 5.",5.2 Accuracy of FactChecker Variations,[0],[0]
"The second variation is FC-CoMention which only uses co-mention scores to compute believability, λ = 0.",5.2 Accuracy of FactChecker Variations,[0],[0]
"The
last variation is the full FactChecker method using both objectivity and co-mentions with λ = 0.6",5.2 Accuracy of FactChecker Variations,[0],[0]
"From Figure 3, it is clear that both the objectivity of sources and the influence of co-mentions contribute to the overall accuracy of FactChecker.",5.2 Accuracy of FactChecker Variations,[0],[0]
Full-fledged FactChecker performs better than both variations.,5.2 Accuracy of FactChecker Variations,[0],[0]
"In most cases, FC-Objectivity performs better than FC-CoMention.",5.2 Accuracy of FactChecker Variations,[0],[0]
"Table 4, column “WKP Politicians”, shows accuracy on Wikipedia fact candidates, with a 0.9- confidence Wilson score interval (Brown et al., 2001).",5.3 Accuracy on Wikipedia Fact Candidates,[0],[0]
For this dataset we again see FactChecker outperforming the other methods under comparison.,5.3 Accuracy on Wikipedia Fact Candidates,[0],[0]
"On this dataset, FactChecker has a accuracy of 0.9 ± 0.07 and a 5% accuracy advantage over the other methods.",5.3 Accuracy on Wikipedia Fact Candidates,[0],[0]
"The second best performance comes from the FC-Objectivity variation, with accuracy of 0.88± 0.08.",5.3 Accuracy on Wikipedia Fact Candidates,[0],[0]
"Table 4, column “GK Quiz ”, shows accuracy on the general knowledge quiz fact candidates.",5.4 Accuracy on General Knowledge Quiz,[0],[0]
"On this dataset, FactChecker and its objectivity-only variation (FC-objectivity) have the highest accuracy of 87%.",5.4 Accuracy on General Knowledge Quiz,[0],[0]
Notice that this dataset was the only one where we did not generate the alternative fact candidates.,5.4 Accuracy on General Knowledge Quiz,[0],[0]
"Instead, we took the options of the multiple choice questions as alternatives.",5.4 Accuracy on General Knowledge Quiz,[0],[0]
"Since the quiz is meant to be taken by humans, the alternatives are often very close, plausible answers.",5.4 Accuracy on General Knowledge Quiz,[0],[0]
"Yet even in this difficult setting, we see FactChecker outperforming the baselines.
",5.4 Accuracy on General Knowledge Quiz,[0],[0]
"Sample fact candidates, with ranked alternatives from all three datasets are shown in Table 5.
",5.4 Accuracy on General Knowledge Quiz,[0],[0]
Figure 4: Effect of λ of FactChecker.,5.4 Accuracy on General Knowledge Quiz,[0],[0]
We analyzed the effect of the selection of lambda λ (see Definition 5) on FactChecker’s performance.,5.5 Parameter Sensitivity,[0],[0]
The result of this analysis is shown in Figure 4.,5.5 Parameter Sensitivity,[0],[0]
FactChecker is insensitive to this parameter when λ is varied from 0.2 to 0.6.,5.5 Parameter Sensitivity,[0],[0]
"Therefore, lambda can be robustly chosen within this range.",5.5 Parameter Sensitivity,[0],[0]
"Overall, from these results we make the following observations: i) Majority vote is a competitive baseline; ii) Iterative voting-based methods provide slight improvements on majority vote.",5.6 Discussion,[0],[0]
This is due to the fact that at the core of iterative voting is still the assumption that fact candidates mentioned in many sources are more likely to be true.,5.6 Discussion,[0],[0]
"Therefore, for both majority vote and iterative voting, when mention frequencies of various alternatives are the same, accuracy suffers.",5.6 Discussion,[0],[0]
"Based on these observations, it is clear that truthfinding solutions need to incorporate fine-grained content-aware features outside of external votes.",5.6 Discussion,[0],[0]
FactChecker takes a step in this direction by incorporating the document-level feature of objectivity.,5.6 Discussion,[0],[0]
"There is a fairly small body of work on truthfinding (Yin et al., 2007; Galland et al., 2010; Pasternack and Roth, 2010; Li et al., 2011; Yin and Tan, 2011; Zhao et al., 2012; Pasternack and Roth, 2013).",6 Related Work,[0],[0]
"The method underlying most truth-finding algorithms is iterative transitive voting (Yin et al., 2007; Galland et al., 2010; Pasternack and Roth, 2010; Li et al., 2011).",6 Related Work,[0],[0]
Fact candidates are initialized with a score.,6 Related Work,[0],[0]
Trustworthiness of sources is then computed from the believability of the fact candidates they mention.,6 Related Work,[0],[0]
"In return, believability of candidates is recomputed based on the trustworthi-
ness of their sources.",6 Related Work,[0],[0]
This process is repeated over several iterations until convergence.,6 Related Work,[0],[0]
"(Yin et al., 2007) was the first to implement this idea, subsequent work improved upon iterative voting in several directions.",6 Related Work,[0],[0]
"(Dong et al., 2009) incorporates copying-detection; giving high trust to sources that are independently authored.",6 Related Work,[0],[0]
"(Galland et al., 2010) approximates error rates of sources and fact candidates.",6 Related Work,[0],[0]
"(Pasternack and Roth, 2010) introduces prior knowledge in the form of linear programming constraints in order to ensure that the truth discovered is consistent with what is already known.",6 Related Work,[0],[0]
"(Yin and Tan, 2011) introduces supervision by using ground truth facts so that sources that disagree with the ground truth are penalized.",6 Related Work,[0],[0]
"(Li et al., 2011) uses search engine APIs to gather additional evidence for believability of fact candidates.",6 Related Work,[0],[0]
"WikiTrust (Adler and Alfaro, 2007) is a content-aware but domain-specific method.",6 Related Work,[0],[0]
It computes trustworthiness of wiki authors based on the revision history of the articles they have authored.,6 Related Work,[0],[0]
"Motivated by interpretability of probabilistic scores, two recent papers addressed the truth-finding problem as a probabilistic inference problem over the sources and the fact candidates (Zhao et al., 2012; Pasternack and Roth, 2013).",6 Related Work,[0],[0]
"Truth-finders based on textual entailment such as TruthTeller (Lotan et al., 2013) determine if a sentence states something or not.",6 Related Work,[0],[0]
"The focus is on understanding natural language, including the use of negation.",6 Related Work,[0],[0]
"This is similar to the goal of fact extraction (Banko et al., 2007; Carlson et al., 2010; Fader et al., 2011; Nakashole et al., 2011; Del Corro and Gemulla, 2013).
",6 Related Work,[0],[0]
"In a departure from prior work, our method leverages language of sources in its believability
computation model.",6 Related Work,[0],[0]
"Furthermore, we introduced a co-mention score which is designed to avoid potential false boots among fact candidates.",6 Related Work,[0],[0]
"Additionally, we developed a method for generating alternative fact candidates.",6 Related Work,[0],[0]
Prior methods assume these are readily available.,6 Related Work,[0],[0]
"Only (Li et al., 2011) uses the Web to identify alternatives, however, this is only done after manually specifying the fixed argument.",6 Related Work,[0],[0]
"In contrast, we introduced a method for identifying the fixed argument based on relation cardinalities learned from SVO statistics.",6 Related Work,[0],[0]
"In this paper, we presented FactChecker, a language-aware approach to truth-finding.",7 Conclusion,[0],[0]
"In contrast to prior approaches, which rely on external votes, FactChecker includes objectivity of sources in its believability computation model.
",7 Conclusion,[0],[0]
FactChecker can be seen as a first step towards language-aware truth-finding.,7 Conclusion,[0],[0]
"Future directions include using more sentence-level features such the use of hedges, assertive verbs, and factive verbs.",7 Conclusion,[0],[0]
"These types of words fall into a class of words used to express certainties, speculations or doubts — these are important cues that FactChecker can leverage.",7 Conclusion,[0],[0]
We thank members of the NELL team at CMU for their helpful comments.,Acknowledgments,[0],[0]
This research was supported by DARPA under contract number FA8750-13-2-0005.,Acknowledgments,[0],[0]
"This paper introduces FactChecker, language-aware approach to truth-finding.",abstractText,[0],[0]
"FactChecker differs from prior approaches in that it does not rely on iterative peer voting, instead it leverages language to infer believability of fact candidates.",abstractText,[0],[0]
"In particular, FactChecker makes use of linguistic features to detect if a given source objectively states facts or is speculative and opinionated.",abstractText,[0],[0]
"To ensure that fact candidates mentioned in similar sources have similar believability, FactChecker augments objectivity with a co-mention score to compute the overall believability score of a fact candidate.",abstractText,[0],[0]
Our experiments on various datasets show that FactChecker yields higher accuracy than existing approaches.,abstractText,[0],[0]
Language-Aware Truth Assessment of Fact Candidates,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 151–160, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
151",text,[0],[0]
"Perception is a critical component of an intelligence architecture that converts raw sensor observations to a suitable representation for the task
that the robot is to perform.",1 INTRODUCTION,[0],[0]
Models of environments vary significantly depending on the application.,1 INTRODUCTION,[0],[0]
"For example, a robotic manipulator may need to model the objects in its environment with their six degree-of-freedom pose for grasping and dexterous manipulation tasks, whereas a self-driving car may need to model the dynamics of the environment in addition to domain-specific semantics such as stop signs, sidewalks and pedestrians etc. to safely navigate through the environment.
",1 INTRODUCTION,[0],[0]
The ability of robots to perform complex tasks is linked to the richness of the robot’s world model.,1 INTRODUCTION,[0],[0]
"As inferring exhaustively detailed world representations is impractical, it is common to infer representations which are highly specific to the task that the robot is to perform.",1 INTRODUCTION,[0],[0]
"However, in collaborative domains as we move towards more complex bi-directional interactions, manipulation tasks, and the environments, it becomes unclear how to best represent the environment in order to facilitate planning and reasoning for a wide distribution of tasks.",1 INTRODUCTION,[0],[0]
"As shown in the Figure 1, modeling the affordance between the chips can and its lid would be unnecessary for the task of picking up the mustard sauce bottle and vice versa.",1 INTRODUCTION,[0],[0]
"Inferring exhaustively detailed models of all of the objects in the environment is computationally expensive and inconsequential for the individual tasks, and inhibits real-time interaction with these collaborative robots.
",1 INTRODUCTION,[0],[0]
The utility of collaborative manipulators is also highly dependent on the speed and accuracy of communication between the human operator and the robot.,1 INTRODUCTION,[0],[0]
Natural language interfaces provide intuitive and muti-resolution means to interact with the robots in shared realms.,1 INTRODUCTION,[0],[0]
"In this work, we propose learning a model of language and perception that can adapt the configurations of the perception pipeline according to the task in order to infer representations that are necessary and suffi-
cient to facilitate planning and grounding for the intended task.",1 INTRODUCTION,[0],[0]
e.g. the top-right image in the Figure 1 shows the adaptively inferred world model pertaining to the instruction “pick up the leftmost blue gear” which is different than the one inferred for the instruction “pick up the largest red object”.,1 INTRODUCTION,[0],[0]
The algorithms and models presented in this paper span the topics that include robot perception and natural language understanding for human-robot interaction.,2 BACKGROUND,[0],[0]
Perception is a central problem in the the field of situated robotics.,2 BACKGROUND,[0],[0]
"Consequently, a plenty of research has focused on developing representations that can faciliate planning and reasoning for highly specific situated tasks.",2 BACKGROUND,[0],[0]
"These representations vary significantly depending on the application, from two-dimensional costmaps (Elfes, 1987), volumetric 3D voxel representations (Hornung et al., 2013, 2010), primitive shape based object approximations (Miller et al., 2003; Huebner and Kragic, 2008) to more rich representations that model high level semantic properties (Galindo et al., 2005; Pronobis and Jensfelt, 2012), 6 DOF pose of the objects of interest (Hudson et al., 2012) or affordances between objects (Daniele et al., 2017).",2 BACKGROUND,[0],[0]
"Since inferring exhaustively detailed world models is impractical, one solution is to design perception pipelines that infer task relevant world models (Eppner et al., 2016; Fallon et al., 2014).",2 BACKGROUND,[0],[0]
"Inferring efficient models that can support reason-
ing and planning for a wide distribution of tasks remains an open research question.
",2 BACKGROUND,[0],[0]
Natural language interfaces provides intutive and multi-resolution means to interact with the collaborative robots.,2 BACKGROUND,[0],[0]
"Contemporary models (Tellex et al., 2011; Howard et al., 2014; Boularias et al., 2015; Matuszek et al., 2013) frame the problem of language understanding as a symbol grounding problem (Harnad, 1990).",2 BACKGROUND,[0],[0]
"Specifically, of inferring correspondences between the linguistic constituents of the instruction and the symbols that represent perceived entities in the robot’s environment such as objects and regions or desired actions that the robot can take.",2 BACKGROUND,[0],[0]
"(Howard et al., 2014) frames this problem as one of inference in a probabilistic graphical model called a Distributed Correspondence Graph (DCG).",2 BACKGROUND,[0],[0]
This model leverages the hierarchical structure of the syntactically parsed instruction and conditional independence assumptions across constituents of a discrete symbol space to improve the run-time of probabilistic inference.,2 BACKGROUND,[0],[0]
"Other variations include the Hierarchical DCG (Propp et al., 2015) and Adaptive DCG (Paul et al., 2016) to further improve the run-time performance in cluttered environments with known environment models.",2 BACKGROUND,[0],[0]
"Recently, these models have been used to augment perception and representations.",2 BACKGROUND,[0],[0]
"(Daniele et al., 2017) uses DCG for supplementing perception with linguistic information for efficiently inferring kinematic models of articulated objects.",2 BACKGROUND,[0],[0]
"(Duvallet et al., 2014;
Hemachandra et al., 2015) use DCG to augment the representations by exploiting information in language instruction to build priors over the unknown parts of the world.",2 BACKGROUND,[0],[0]
A limitation of current applications of probabilistic graphical models for natural language symbol grounding is that they do not consider how to efficiently convert observations or measurements into sufficiently detailed representation suitable for inference.,2 BACKGROUND,[0],[0]
"We propose to use DCG for the problem of adapting the perception pipelines for inferring task optimal representations.
",2 BACKGROUND,[0],[0]
"Our work is most closely related to that of (Matuszek et al., 2013).",2 BACKGROUND,[0],[0]
Their work presents an approach for jointly learning the language and perception models for grounded attribute learning.,2 BACKGROUND,[0],[0]
Their model infers the subset of objects based on color and shape which satisfy the attributes described in the natural language description.,2 BACKGROUND,[0],[0]
"Similarly, (Hu et al., 2016) proposes deep learning based approach to directly segment objects in RGB images that are described by the instruction.",2 BACKGROUND,[0],[0]
"We differentiate our approach by expanding the diversity and complexity of perceptual classifiers, enabling verbs to modify object representations, and presenting an end-to-end approach to representation adaptation and symbol grounding using computationally efficient probabilistic graphical models.",2 BACKGROUND,[0],[0]
"In the following sections we introduce our approach to adapting perception pipelines, define our experiments, and present results against a suitable baseline.",2 BACKGROUND,[0],[0]
We describe the problem of understanding natural language instructions as one of probabilistic inference where we infer a distribution of symbols that express the intent of the utterance.,3 TECHNICAL APPROACH,[0],[0]
"The meaning of the instruction is taken in the context of a symbolic representation (Γ), observations (zt) and a representation of the language used to describe the instruction (Λ).",3 TECHNICAL APPROACH,[0],[0]
"A probabilistic inference using a symbolic representation that is described by the space of trajectories X (t) that the robot may take takes the form of equation:
",3 TECHNICAL APPROACH,[0],[0]
"x(t)∗ = arg max x(t)∈X(t) p(x(t)|Λ, zt) (1)
Solving this inference problem is computationally intractable when the space of possible trajectories is large.",3 TECHNICAL APPROACH,[0],[0]
"Contemporary approaches (Tellex
et al., 2011; Howard et al., 2014) frame this problem as a symbol grounding problem, i.e. inferring the most likely set of groundings (Γs∗) given a syntactically parsed instruction Λ = {λ1, ..., λm} and the world model Υ.
Γs∗ = arg max γ1...γn∈Γs p(γ1...γn|Λ,Υ) (2)
",3 TECHNICAL APPROACH,[0],[0]
"Here, the world model Υ is a function of the constructs of the robot’s perception pipeline (P ), and the raw observations zt.
",3 TECHNICAL APPROACH,[0],[0]
Υ,3 TECHNICAL APPROACH,[0],[0]
"≈ f(P, zt) (3)
",3 TECHNICAL APPROACH,[0],[0]
"The groundings Γs are symbols that represent objects, their semantic properties, regions derived from the world model, and robot actions and goals such as grasping the object of interest or navigating to a specific region in the environment.",3 TECHNICAL APPROACH,[0],[0]
"The set of all groundings Γs = {γ1, γ2, ..., γn} is called as the symbol space.",3 TECHNICAL APPROACH,[0],[0]
Thus the symbol space forms a finite space of interpretations in which the instruction will be grounded.,3 TECHNICAL APPROACH,[0],[0]
The DCG is a probabilistic graphical model of the form described in equation 2.,3 TECHNICAL APPROACH,[0],[0]
The model relates the linguistic components λi ∈ Λ to the groundings γj ∈,3 TECHNICAL APPROACH,[0],[0]
Γs through the binary correspondence variables φij ∈ Φ. DCG facilitates inferring the groundings at a parent phrase in the context of the groundings at its child phrases Φci.,3 TECHNICAL APPROACH,[0],[0]
"Formally, DCG searches for the most likely correspondence variables Φ∗ in the context of the groundings γij , phrases λi, child correspondences",3 TECHNICAL APPROACH,[0],[0]
"Φci and the world model Υ by maximizing the product of individual factors.
Φ∗",3 TECHNICAL APPROACH,[0],[0]
= arg max φij∈Φ |Λ|∏ i=1,3 TECHNICAL APPROACH,[0],[0]
"|Γs|∏ j=1 p(φij |γij , λi,Φci,Υ) (4)
Inferred correspondence variables Φ∗ represent the expression of the most likely groundings Γs∗.",3 TECHNICAL APPROACH,[0],[0]
"The factors in the equation 4 are approximated by log-linear models Ψ:
Φ∗ = arg max φij∈Φ |Λ|∏ i=1",3 TECHNICAL APPROACH,[0],[0]
"|Γs|∏ j=1 Ψ(φij , γij , λi,Φci,Υ) (5) Model training involves learning the log-linear factors from the labeled data relating phrases with true groundings.",3 TECHNICAL APPROACH,[0],[0]
Inference process involves searching for the set of correspondence variables that satisfy the above equation.,3 TECHNICAL APPROACH,[0],[0]
"The run-time performance of probabilistic inference with the DCG
is positively correlated with the complexity of the world model Υ. This is because the size of the symbolic representation Γs increases with the number of objects in the environment representation.",3 TECHNICAL APPROACH,[0],[0]
"Recognizing that some objects (and the symbols based on those objects) are inconsequential to the meaning of the instruction, we consider the optimal representation of the environment Υ∗ as one which is necessary and sufficient to solve equation 5.",3 TECHNICAL APPROACH,[0],[0]
"Thus we hypothesize that the time to solve equation 6 will be less than that for the equation 5.
Φ∗",3 TECHNICAL APPROACH,[0],[0]
= arg max φij∈Φ |Λ|∏ i=1,3 TECHNICAL APPROACH,[0],[0]
|Γs|∏,3 TECHNICAL APPROACH,[0],[0]
"j=1 Ψ(φij , γij , λi,Φci,Υ ∗)
(6) Typically the environment model Υ is computed by a perception module P from a set of observations z1:t = {z1 . . .",3 TECHNICAL APPROACH,[0],[0]
zt}.,3 TECHNICAL APPROACH,[0],[0]
In cluttered environments we assume that inferring an exhaustively detailed representation of the world that satisfies all possible instructions is impractical for real-time human-robot interactions.,3 TECHNICAL APPROACH,[0],[0]
We propose using language as mean to guide the generation of these necessary and sufficient environment representations Υ∗ in turn making it a task adaptive process.,3 TECHNICAL APPROACH,[0],[0]
"Thus we define Υ∗ inferred from a single observation as:
Υ∗ ≈ f(P, zt,Λ) (7)
where P denotes the perception pipeline of the robotic intelligence architecture.",3 TECHNICAL APPROACH,[0],[0]
We adapt DCG to model the above function by creating a novel class of symbols called as perceptual symbols ΓP .,3 TECHNICAL APPROACH,[0],[0]
Perceptual symbols are tied to their corresponding elements in the perception pipeline.,3 TECHNICAL APPROACH,[0],[0]
i.e. to the vision algorithms.,3 TECHNICAL APPROACH,[0],[0]
"Since this grounding space is independent of the world model Υ, the random variable used to represent the environment is removed from equation 5.",3 TECHNICAL APPROACH,[0],[0]
"We add a subscript p to denote that we are reasoning in the perceptual grounding space.
Φ∗",3 TECHNICAL APPROACH,[0],[0]
= arg max φij∈Φ |Λ|∏ i=1,3 TECHNICAL APPROACH,[0],[0]
"|ΓP |∏ j=1 Ψ(φij , γij , λi,Φci) (8)
Equation 8 represents the proposed model which we refer to as the language-perception model (LPM).",3 TECHNICAL APPROACH,[0],[0]
It infers the symbols that inform the perception pipeline configurations given a natural language instruction describing the task.,3 TECHNICAL APPROACH,[0],[0]
"The
space of symbols ΓP describe all possible configurations of the perception pipeline.",3 TECHNICAL APPROACH,[0],[0]
"For example, as shown in the Figure 1, for the instruction “pick up the leftmost blue gear”, we may need elements in our pipeline that can detect blue objects and gears.",3 TECHNICAL APPROACH,[0],[0]
"Detecting green objects, spherical shapes, or sixdimensional pose of the chips can object would not be necessary to generate the symbols necessary for the robot to perform the instruction.
",3 TECHNICAL APPROACH,[0],[0]
"We assume that the perception pipeline (P ) is populated with a set of elements E = {E1, ..., En} such that each subset Ei ∈ E represents a set of algorithms that are responsible for inferring a specific property of an object.",3 TECHNICAL APPROACH,[0],[0]
e.g. a red colordetection algorithm would be a member of the color detector family responsible for inferring the semantic property “color” of the object.,3 TECHNICAL APPROACH,[0],[0]
While a six degree-of-freedom (DOF) pose detection algorithm would be a member of the pose detector family.,3 TECHNICAL APPROACH,[0],[0]
"More generally, E can be defined as: E = {e1, e2, ..., em}.",3 TECHNICAL APPROACH,[0],[0]
"With these assumptions, we define our independent perceptual symbols as:
ΓIDP = {γei |ei ∈ E} (9)
We can imagine that these symbols would be useful to ground simple phrases such as ”the red object” or ”the ball” etc. where the phrases refer to a single property of the object.",3 TECHNICAL APPROACH,[0],[0]
In the more complicated phrases such as ”the red ball” or ”the blue box” we have a joint expression of properties.,3 TECHNICAL APPROACH,[0],[0]
"i.e. we are looking for objects which maximize the joint likelihood p(red, sphere|o).",3 TECHNICAL APPROACH,[0],[0]
Since these properties are independent we can infer them separately for every object ok ∈,3 TECHNICAL APPROACH,[0],[0]
"O. However, we can represent the above joint likelihood expression as p(red, sphere) = p(red)p(sphere|red).",3 TECHNICAL APPROACH,[0],[0]
"In this case, it allows conditioning the evaluation of sphere detection on only a subset of objects which were classified as being red by the red detector.",3 TECHNICAL APPROACH,[0],[0]
"To add this degree of freedom in the construction of the perception pipeline, we define additional set of symbols which we refer to as conditionally dependent perceptual symbols:
ΓCDP = {γei,ej |ei, ej ∈ E ; i 6= j} (10)
",3 TECHNICAL APPROACH,[0],[0]
"The expression of the symbol γei,ej refers to running the element ei from the perception pipeline on the subset of objects which were classified positive by the element ej .",3 TECHNICAL APPROACH,[0],[0]
"Finally the complete perceptual symbol space is:
ΓP = {ΓIDP ∪ ΓCDP } (11)",3 TECHNICAL APPROACH,[0],[0]
Herein with our experiments we demonstrate the utility of our language perception model for the task of grounded language understanding of the manipulation instructions.,4 EXPERIMENTAL DESIGN,[0],[0]
"As shown in Figure 3 the process involves two distinct inferences: Inferring the perceptual groundings given a language instruction ( eq. 8 ), and inferring high level motion planning constraints given the language and the generated world model ( eq. 5 and eq. 6 ).",4 EXPERIMENTAL DESIGN,[0],[0]
"In this section we describe our assumptions, and define the distinct symbolic representations used in our experiments for each of the above tasks.",4 EXPERIMENTAL DESIGN,[0],[0]
We then discuss our instruction corpus and the details of the individual experiments.,4 EXPERIMENTAL DESIGN,[0],[0]
For our experiments a Rethink Robotics Baxter Research Robot is placed behind a table.,Robot and the Environment,[0],[0]
The robot is assumed to perceive the environment using a head-mounted RGB-D sensor.,Robot and the Environment,[0],[0]
"Robot’s work space is populated using objects from the standard YCB dataset (Berk Calli, 2017), custom 3D printed ABS plastic objects, and multicolored rubber blocks.",Robot and the Environment,[0],[0]
We define the world complexity in terms of the number of objects present on the table in the robot’s field of view.,Robot and the Environment,[0],[0]
The world complexity ranges from 15 to 20 in our experiments.,Robot and the Environment,[0],[0]
The symbolic representation defines the space of symbols or meanings in which the natural language instruction will be grounded or understood.,Symbolic Representation,[0],[0]
As mentioned before we define two distinct sets of symbols in our experiments.,Symbolic Representation,[0],[0]
"ΓP defines the set of perceptual symbols which are used by the language perception model, and ΓS defines the set of symbols which are used by the symbol grounding model.
ΓP is a function of the elements E of the perception pipeline.",Symbolic Representation,[0],[0]
The elements ei ∈ E in our perception pipeline are selected such that they can model the robot’s environment with a spectrum of semantic and metric properties which will be necessary towards performing symbol grounding and planning for all of the instructions in our corpus.,Symbolic Representation,[0],[0]
"In our experiment we define E as:
E = {C ∪ G ∪ L ∪ B ∪ R ∪ P} (12)
Here, C is a set of color detectors, G is a set of geometry detectors, L is a set of object label detectors, B is a set of bounding box detectors, R
is a set of region detectors, and P is a set of pose detectors.
",Symbolic Representation,[0],[0]
C = { cdi | i ∈ color} G = { gdi | i ∈ geometry} L = { ldi | i ∈ label} B = { bdi,Symbolic Representation,[0],[0]
| i ∈ bbox} R = { rdi | i ∈ region} P = { pdi |,Symbolic Representation,[0],[0]
"i ∈ pose}
(13)
where color = {red, green, blue, white, yellow, orange}, geometry = {sphere, cylinder, cuboid}, label = {crackers box, chips can, pudding box, master chef can, bleach cleanser, soccer ball, mustard sauce bottle, sugar packet}, bbox = {non-oriented, oriented }, region = {left, right, center}, pose = { 3 DOF, 6 DOF }.",Symbolic Representation,[0],[0]
"Given the perception elements defined in the equation 13, we define the independent perceptual groundings ( ΓIDP ) previously defined in equation 9 as follows:
ΓC = {γcdi | cdi ∈ C} ΓG = {γgdi | gdi ∈ B} ΓL = {γldi | ldi ∈ L} ΓB = {γbdi | bdi ∈ B} ΓR = {γrdi | rdi ∈ R} ΓP = {γpdi | pdi ∈ P}
(14)
",Symbolic Representation,[0],[0]
"ΓIDP = { ΓC ∪ ΓG ∪ ΓL ∪ ΓB ∪ ΓR ∪ ΓP} (15)
",Symbolic Representation,[0],[0]
"We define the conditionally dependent perceptual groundings ( ΓCDP ) previously defined in equation 10 as following:
ΓGC = {γ(gdi,cdj) | gdi ∈ G, cdj ∈ C} ΓLC = {γ(ldi,cdj) | ldi ∈ L, cdj ∈ C} ΓPC = {γ(pdi,cdj) | pdi ∈ P, cdj ∈ C} ΓPG = {γ(pdi,gdj)",Symbolic Representation,[0],[0]
"| pdi ∈ P, gdj ∈ G} ΓPL = {γ(pdi,ldj)",Symbolic Representation,[0],[0]
"| pdi ∈ P, ldj ∈ L}
(16)
ΓCDP = { ΓGC ∪ ΓLC ∪ ΓPC ∪ ΓPG ∪ ΓPL} (17)
",Symbolic Representation,[0],[0]
These symbols provide us the ability to selectively infer desired properties in the world.,Symbolic Representation,[0],[0]
"Above presented independent and conditionally dependent symbols together cover the complete space of perceptual symbols used by the LPM:
ΓP = {ΓIDP ∪ ΓCDP } (18)
Algorithmic details of the percepion elements are as follows : A single RGB point cloud is fed in as a raw sensor observation to the pipeline.",Symbolic Representation,[0],[0]
"A RANSAC (Fischler and Bolles, 1981) based 3D plane detection technique is used for segmenting the table-top and the objects.",Symbolic Representation,[0],[0]
HSV colorspace is used for detecting colors.,Symbolic Representation,[0],[0]
RANSAC,Symbolic Representation,[0],[0]
based model fitting algorithms form the core of the geometry detectors.,Symbolic Representation,[0],[0]
A 4 layer ( 256 - 128 - 64 - 32 ) feed forward neural network is trained to infer the semantic labels of the objects.,Symbolic Representation,[0],[0]
It takes in a 32 x 32 RGB image and infers a distribution over 8 unique YCB object classes.,Symbolic Representation,[0],[0]
A PCA based oriented bounding box estimation algorithm is used to approximate the 6 DOF pose for the individual objects.,Symbolic Representation,[0],[0]
"Algorithms are implemented using OpenCV and PCL library (Rusu and Cousins, 2011).
",Symbolic Representation,[0],[0]
"The space of symbols for the symbol grounding model is similar to the representation defined in (Paul et al., 2016).",Symbolic Representation,[0],[0]
"This space uses symbols to represent objects in the world model (ΓO), semantic object labels (ΓL), object color(ΓC), object geometry(ΓG) regions in the world(ΓR), spatial relationships (ΓSR) and finally high level planning constraints that define the end goal (ΓPC).",Symbolic Representation,[0],[0]
The inferred constraints forms an input to a planning algorithm that can then generate trajectories to accomplish the desired task.,Symbolic Representation,[0],[0]
"Thus the complete symbol space for the symbol grounding model is:
ΓS = { ΓO∪ΓL∪,ΓC∪ΓG∪ΓR∪ΓSR∪ΓPC} (19)",Symbolic Representation,[0],[0]
"For training and testing the performance of the system we generate an instruction corpus using the linguistic patterns similar to that described in (Paul et al., 2016).",Corpus,[0],[0]
The corpus used in our experiments consists of 100 unique natural language instructions.,Corpus,[0],[0]
Details of the grammar extracted from this corpus is described in the appendix.,Corpus,[0],[0]
Each instruction describes a manipulation command to the robot while referring to the objects of interest using their semantic or metric properties.,Corpus,[0],[0]
e.g. “pick up the green cup” or “pick up the biggest blue object”.,Corpus,[0],[0]
If multiple instances of the same objects are present in the robot’s work space then the reference resolution is achieved by using spatial relationships to describe the object of interest.,Corpus,[0],[0]
"e.g.“the leftmost blue cube” or “rightmost red object” etc.
",Corpus,[0],[0]
"As shown in Figure 2, the instructions in the corpus are in the form of syntactically parsed trees.
",Corpus,[0],[0]
Each instruction is generated in the context of a specific table-top object arrangement.,Corpus,[0],[0]
Thus each instruction is associated with a pair of RGB-D image.,Corpus,[0],[0]
"A total of 10 unique table-top arrangements are used to generate the set of 100 instructions.
",Corpus,[0],[0]
One copy of the corpora is annotated for training LPM using (ΓP ) while another for training the symbol grounding model using (ΓS).,Corpus,[0],[0]
"The annotations for LPM corpus are selected such that that the perception pipelines configured using the annotated groundings would generate the optimal world representations that are necessary and sufficient to support grounding and planning for the given tasks.
",Corpus,[0],[0]
We have instructions with varying complexity in our corpus.,Corpus,[0],[0]
The instruction complexity from the perception point of view is quantified in terms of the total number of perceptual groundings expressed at the root level.,Corpus,[0],[0]
"e.g. “pick up the ball” is relatively a simple instruction with only single grounding expressed at the root level, while “pick up the blue cube and put the blue cube near the crackers box” is a more complicated instruction having seven groundings expressed at the root level.",Corpus,[0],[0]
This number was found to vary in the range of one to seven in our corpus.,Corpus,[0],[0]
We structure our experiments to validate two claims.,Experiments and Metrics,[0],[0]
The first claim is that adaptively inferring the task optimal representations reduce the perception run-time by avoiding exhaustively detailed uniform modeling of the world.,Experiments and Metrics,[0],[0]
The second claim is that reasoning in the context of these optimal representations also reduces the inference run-time of the symbol grounding model.,Experiments and Metrics,[0],[0]
An outline of our experiments is illustrated in Figure 3.,Experiments and Metrics,[0],[0]
"In the first experiment, we study the root-level inference accuracy of LPM ( groundings expressed at the root level of the phrase ) as a function of the gradual increase in the training fraction.",Experiments and Metrics,[0],[0]
"For each
value of training fraction in the range [ 0.2 , 0.9 ] increasing with a step of 0.1, we perform 15 validation experiments.",Experiments and Metrics,[0],[0]
The training data is sampled randomly for every individual experiment.,Experiments and Metrics,[0],[0]
"Additionally, we perform a leave-one-out cross validation experiment.",Experiments and Metrics,[0],[0]
"We use the inferences generated by the leave-one-out cross validation experiments as inputs to drive the adaptive perception for each instruction.
",Experiments and Metrics,[0],[0]
"In the second experiment, we compare the cumulative run-time of LPM inference ( eq. 8 ) and adaptive perception ( T1+T2 ) against the run-time for complete perception ( T4 ) - our baseline, for increasingly complex worlds.
",Experiments and Metrics,[0],[0]
"In the third experiment, we compare the inference time of the symbol grounding model reasoning in the context of the adaptively generated optimal world models ( T3, eq. 6 ) against the inference time of the same model but when reasoning in the context of the complete world models ( T5, eq. 5 ).",Experiments and Metrics,[0],[0]
We also check whether the planning constraints inferred in both cases match the ground truth or not.,Experiments and Metrics,[0],[0]
Experiments are performed on a system running a 2.2 GHz Intel Core i7 CPU with 16 GB RAM.,Experiments and Metrics,[0],[0]
This section presents the results obtained for the above mentioned three experiments.,5 RESULTS,[0],[0]
"Specifically, the learning characteristics of LPM, the impact of LPM on the perception run-time, and the impact the adaptive representations on the symbol grounding run-time.
",5 RESULTS,[0],[0]
Leftmost graph in the Figure 4 shows the results of the first experiment.,5 RESULTS,[0],[0]
We can see that the inference accuracy grows as a function of a gradual increase in the training data.,5 RESULTS,[0],[0]
"A growing trend is an indicator of the language diversity in the corpus.
",5 RESULTS,[0],[0]
"Mean inference accuracy starts at 39.25%±5 for k = 0.2 and it reaches 84% for leave-one-out cross validation experiment ( k = 0.99 ).
",5 RESULTS,[0],[0]
Middle graph in the Figure 4 shows the result of the second experiment.,5 RESULTS,[0],[0]
We can clearly see that the run-time for complete perception grows with the world complexity while the run-time of adaptive perception stays nearly flat and is significantly lower in all cases.,5 RESULTS,[0],[0]
"Since the adaptive perception run-time varies according to the task, we see bigger error bars.",5 RESULTS,[0],[0]
"The drop in the complete perception run-time for world complexity of 20 is justifiable as the run-time of our geometry detection algorithm was proportional to the size of the individual objects, and all of the objects for that example world were smaller than other examples.
",5 RESULTS,[0],[0]
Rightmost graph in the Figure 4 shows the result of the third experiment.,5 RESULTS,[0],[0]
It shows that the symbol grounding run-time when reasoning in the context of detailed world models( Υ ) grows as a function of the world complexity.,5 RESULTS,[0],[0]
"However, it is significantly lower when reasoning in the context of adaptively generated world models ( Υ∗ ) and is independent of the world complexity.
",5 RESULTS,[0],[0]
"The achieved run-time gains are meaningful
only if we do not incur a loss in the symbol grounding accuracy.",5 RESULTS,[0],[0]
Table 3 shows the impact of LPM on SG accuracy and summarizes the gains.,5 RESULTS,[0],[0]
"Real-time human-robot interaction is critical for the utility of the collaborative robotic manipula-
tors in shared tasks.",6 CONCLUSIONS,[0],[0]
"In scenarios where inferring exhaustively detailed models of all the objects is prohibitive, perception represents a bottleneck that inhibits real-time interactions with collaborative robots.",6 CONCLUSIONS,[0],[0]
Language provides an intuitive and multiresolution interface to interact with these robots.,6 CONCLUSIONS,[0],[0]
"While recent probabilistic frameworks have advanced our ability to interpret the meaning of complex instructions in cluttered environments, the problem of how language can channel the interpretation of the raw observations to construct world models which are necessary and sufficient for the symbol grounding task is not extensively studied.",6 CONCLUSIONS,[0],[0]
"Our proposed DCG based Language Perception Model, demonstrates that we can guide perception using language to construct world models which are suitable for efficiently interpreting the instruction.",6 CONCLUSIONS,[0],[0]
"This provides run-time gains in terms of both perception and symbol grounding, thereby improving the speed with which collaborative robots can understand and act upon human instructions.",6 CONCLUSIONS,[0],[0]
In ongoing and future work we are exploring how language can aid efficient construction of global maps for robot navigation and manipulation by intelligently sampling relevant observations from a set of observations.,6 CONCLUSIONS,[0],[0]
This work was supported in part by the National Science Foundation under grant IIS-1637813 and the New York State Center of Excellence in Data Science at the University of Rochester.,7 ACKNOWLEDGMENTS,[0],[0]
We list the grammar rules and the lexicon for our corpus to demonstrate the diversity of the instructions.,A Grammar and Lexicon of the Corpus,[0],[0]
Following table lists the words scraped from the instructions in our corpus.,A Grammar and Lexicon of the Corpus,[0],[0]
"We have a total of 56 unique words.
",A Grammar and Lexicon of the Corpus,[0],[0]
Following table lists the grammar rules scraped from the instructions in our corpus.,A Grammar and Lexicon of the Corpus,[0],[0]
We have a total of 23 unique grammar rules.,A Grammar and Lexicon of the Corpus,[0],[0]
The utility of collaborative manipulators for shared tasks is highly dependent on the speed and accuracy of communication between the human and the robot.,abstractText,[0],[0]
The run-time of recently developed probabilistic inference models for situated symbol grounding of natural language instructions depends on the complexity of the representation of the environment in which they reason.,abstractText,[0],[0]
"As we move towards more complex bi-directional interactions, tasks, and environments, we need intelligent perception models that can selectively infer precise pose, semantics, and affordances of the objects when inferring exhaustively detailed world models is inefficient and prohibits real-time interaction with these robots.",abstractText,[0],[0]
In this paper we propose a model of language and perception for the problem of adapting the configuration of the robot perception pipeline for tasks where constructing exhaustively detailed models of the environment is inefficient and inconsequential for symbol grounding.,abstractText,[0],[0]
We present experimental results from a synthetic corpus of natural language instructions for robot manipulation in example environments.,abstractText,[0],[0]
The results demonstrate that by adapting perception we get significant gains in terms of run-time for perception and situated symbol grounding of the language instructions without a loss in the accuracy of the latter.,abstractText,[0],[0]
Language-Guided Adaptive Perception for Efficient Grounded Communication with Robotic Manipulators in Cluttered Environments,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1183–1191 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1183",text,[0],[0]
"Language models (LMs) estimate the likelihood of a symbol sequence {xt}Tt=0, based on the joint probability,
p(x0, . . .",1 Introduction,[0],[0]
", xT )",1 Introduction,[0],[0]
"= p(x0) T∏ t=1 p(xt|x0, . . .",1 Introduction,[0],[0]
", xt−1).
(1)
To measure the quality of an LM, a commonly adopted metric is perplexity (PPL), defined as
PPL , exp { − 1 T T∑ t=0 log p(xt|x0, . .",1 Introduction,[0],[0]
.,1 Introduction,[0],[0]
", xt−1) } ,
A good language model has a small PPL, being able to assign higher likelihoods to sentences that are more likely to appear.
",1 Introduction,[0],[0]
"LMs are widely applied in automatic speech recognition (ASR) (Yu and Deng, 2014) and machine translation (MT) (Koehn, 2009).",1 Introduction,[0],[0]
"Following Koehn (2009), one may interpret the language
∗Contributions were made while at Baidu Research.
model as prior knowledge on the text to be inferred, which provides information complementary to the ASR or MT system itself.",1 Introduction,[0],[0]
"In practice, there are several ways to incorporate the language model.",1 Introduction,[0],[0]
"The simplest way may be re-scoring an n-best list returned by the ASR or MT system (Mikolov et al., 2010; Sundermeyer et al., 2012).",1 Introduction,[0],[0]
"A slightly more sophisticated way is to jointly consider the ASR/MT and language model in a beam search decoder (Amodei et al., 2016).",1 Introduction,[0],[0]
"Specifically, at each time step, the decoder appends every symbol in the vocabulary to each sequence in the current candidate set.",1 Introduction,[0],[0]
"For every hypothesis, a score is calculated as a linear combination of the log-likelihoods given by both the ASR/MT and language models.",1 Introduction,[0],[0]
"Then, only the top K hypotheses with the highest scores are retained, as an updated candidate set.",1 Introduction,[0],[0]
"More recently, Gulcehre et al. (2015) and Sriram et al. (2017) propose to predict the next symbol based on a fusion of the hidden states in the ASR/MT and language models.",1 Introduction,[0],[0]
"A gating mechanism is jointly trained to determine how much the language model should contribute.
",1 Introduction,[0],[0]
The afore-discussed language models are generative in the sense that they merely model the joint distribution of a symbol sequence (Eq.,1 Introduction,[0],[0]
(1)).,1 Introduction,[0],[0]
"While the research community is mostly focused on pushing the limit of PPL (e.g., Jozefowicz et al., 2016), very limited attention has been paid to the discrimination power of language models when they are applied to real tasks, such as ASR and MT (Li and Khudanpur, 2008).",1 Introduction,[0],[0]
"By contrast, discriminative language modeling aims at enhancing the performance in downstream applications.",1 Introduction,[0],[0]
"For example, existing works (Roark et al., 2004, 2007) often target at improving ASR accuracy.",1 Introduction,[0],[0]
"The key motivation underlying them is that the model should be able to discriminate between “good” and “bad” sentences in a task-specific sense, instead
of just modeling grammatical ones.",1 Introduction,[0],[0]
"The common methodology (Dikic et al., 2013) is to build a binary classifier upon hand-crafted features extracted from the sentences.",1 Introduction,[0],[0]
"However, it is not obvious how these methods can utilize large unannotated corpus, which is often easily available, and the hand-crafted features are also ad hoc and may result in suboptimal performance.
",1 Introduction,[0],[0]
"In this work, we study how to improve the discrimination ability of a recurrent network-based neural language model (RNNLM).",1 Introduction,[0],[0]
The goal is to enlarge the difference between the log-likelihoods of “good” and “bad” sentences.,1 Introduction,[0],[0]
"In an contrast to the existing works (Roark et al., 2004, 2007), our method does not rely on hand-crafted features, and is trained in end-to-end manner and able to take advantage of large external text corpus.",1 Introduction,[0],[0]
"In fact, it is a general training criterion that is transparent to the network architecture of the RNNLM, and can be applied to various text generation tasks, including ASR and MT.",1 Introduction,[0],[0]
Experiments on state-of-art ASR and MT systems show its significant advantage over an LM trained by minimizing PPL.,1 Introduction,[0],[0]
We first give some background knowledge on RNNLMs.,2 Background on RNNLM,[0],[0]
"The prototypical RNNLM (Mikolov et al., 2010) has one layer of recurrent cell and works as follows.",2 Background on RNNLM,[0],[0]
Denote a sentence as x =,2 Background on RNNLM,[0],[0]
"[x0, . . .",2 Background on RNNLM,[0],[0]
", xt, . . .",2 Background on RNNLM,[0],[0]
"], where the xt’s are words.",2 Background on RNNLM,[0],[0]
Let ~xt be the embedding vector for xt.,2 Background on RNNLM,[0],[0]
"The recurrent cell takes in the embedding and produces a hidden state ~ht by
~ht = σ(U~xt + V~ht−1),
where σ(z) = 1 1+e−z is sigmoid activation function.",2 Background on RNNLM,[0],[0]
~ht−1 is the hidden state at the last timestep.,2 Background on RNNLM,[0],[0]
U and V are learnable parameters.,2 Background on RNNLM,[0],[0]
"The ~ht is then passed into a multi-way classifier to produce a probability distribution over the vocabulary (for the next word),
~p = softmax(W~ht +~b).
",2 Background on RNNLM,[0],[0]
The W and ~b are also trainable parameters.,2 Background on RNNLM,[0],[0]
"The training objective is to maximize the loglikelihood of the next word, and the parameters are learned by back-propagation algorithm.
",2 Background on RNNLM,[0],[0]
"The vanilla recurrent cell can also be replaced by one or multiple layers of LSTM cells, which produces better results (Zaremba et al.,
2014).",2 Background on RNNLM,[0],[0]
"In a more general form, the RNNLM can be represented as a conditional probability, pθ(x
t|x0, . . .",2 Background on RNNLM,[0],[0]
", xt−1), parameterized by θ.",2 Background on RNNLM,[0],[0]
"In the prototypical case, θ =",2 Background on RNNLM,[0],[0]
"[U, V,W,~b].",2 Background on RNNLM,[0],[0]
"We could define the LM-score of a sentence x as
LM-score(x) , log pθ(x) = ∑ t log pθ(x t|x0, . . .",2 Background on RNNLM,[0],[0]
", xt−1).
",2 Background on RNNLM,[0],[0]
"The RNNLM is trained by maximizing the average LM-score over all the x’s in a corpus, or equivalently, minimizing the PPL on the corpus.",2 Background on RNNLM,[0],[0]
We motivate and formulate a large margin training criterion in this section.,3 Problem Formulation,[0],[0]
"Suppose for every reference sentence xi, we have a collection of hypotheses xi,j , j = 1, . . .",3 Problem Formulation,[0],[0]
",K, usually obtained as the top-K candidates by a beam search decoder.",3 Problem Formulation,[0],[0]
"An RNNLM trained by minimizing PPL cannot guarantee a higher score on the “gold” reference than the inferior hypothesis, which is undesirable.",3.1 A Motivating Example,[0],[0]
One example is given in Tab. 1.,3.1 A Motivating Example,[0],[0]
The reference is taken from the text labels of dev93’ set of Wall Street Journal (WSJ) dataset.,3.1 A Motivating Example,[0],[0]
"The hypothesis is generated by a CTC-based (Graves et al., 2006)",3.1 A Motivating Example,[0],[0]
ASR system trained on WSJ training set.,3.1 A Motivating Example,[0],[0]
Words in red are mistakes made by the hypothesis.,3.1 A Motivating Example,[0],[0]
We then train an RNNLM on Common Crawl1 copora by minimizing PPL.,3.1 A Motivating Example,[0],[0]
"Training follows a typical setup (Jozefowicz et al., 2016) with a vocabulary of 400K the most frequent words.",3.1 A Motivating Example,[0],[0]
Any out-ofvocabulary word is replaced by an 〈UNK〉 token.,3.1 A Motivating Example,[0],[0]
The RNNLM is then employed to score the sentences.,3.1 A Motivating Example,[0],[0]
The LM-score of the erroneous hypothesis is higher than that of the reference.,3.1 A Motivating Example,[0],[0]
"In fact, this is reasonable as “a decade as concerns” seems to be a more common phrase.",3.1 A Motivating Example,[0],[0]
"In the training corpus, we find that “a decade as concerns” appears once, but “its defeat is confirmed” does not appear.",3.1 A Motivating Example,[0],[0]
"Moreover, “a decade as” appears 2,280 times, but “its defeat is” appears only 24 times.",3.1 A Motivating Example,[0],[0]
"However, this is undesirable because if there is another hypothesis that happens to be the same as reference, which will not be ranked as the best candidate.
",3.1 A Motivating Example,[0],[0]
"It would be helpful if the LM can also learn from the imperfect hypotheses so that it can tell
1http://web-language-models.",3.1 A Motivating Example,[0],[0]
"s3-website-us-east-1.amazonaws.com/ wmt16/deduped/en-new.xz
apart “good” and “bad” candidates.",3.1 A Motivating Example,[0],[0]
"With this motivation, we train to assign larger LM-scores for the xi’s but smaller ones for the (imperfect) xi,j’s.",3.1 A Motivating Example,[0],[0]
A quantity of particular interest is log p(xi),3.1 A Motivating Example,[0],[0]
"− log p(xi,j), the margin/difference between the LM-scores of the references and the (imperfect) hypotheses.",3.1 A Motivating Example,[0],[0]
"The intuition is that the more positive the margin, the better the LM is at discrimination.",3.1 A Motivating Example,[0],[0]
"Without loss of generality, we assume that all the xi,j’s are imperfect and different from xi.",3.2 Straightforward but Failed Formulation,[0],[0]
"A straightforward way is to adopt the following objective:
min θ
1
N N∑ i=1",3.2 Straightforward but Failed Formulation,[0],[0]
"− log pθ(xi) + 1 K K∑ j=1 log pθ(xi,j)  .",3.2 Straightforward but Failed Formulation,[0],[0]
"(2)
Similar formulation is also seen in (Tachioka and Watanabe, 2015), where they only utilize one beam candidate, i.e., K = 1.",3.2 Straightforward but Failed Formulation,[0],[0]
Optimization can be carried out by mini-batch stochastic gradient descent (SGD).,3.2 Straightforward but Failed Formulation,[0],[0]
"Each iteration, SGD randomly samples a batch of i’s and j’s, computes stochastic gradient w.r.t.",3.2 Straightforward but Failed Formulation,[0],[0]
"θ,",3.2 Straightforward but Failed Formulation,[0],[0]
and takes an update step.,3.2 Straightforward but Failed Formulation,[0],[0]
"However, a potential problem with this formulation is that the second term (corresponding to the inferior hypotheses) may dominate the optimization.",3.2 Straightforward but Failed Formulation,[0],[0]
"Specifically, the training is almost always driven by the xi,j’s, but does not effectively enhance the discrimination.",3.2 Straightforward but Failed Formulation,[0],[0]
"We illustrate this fact in the following experiment.
",3.2 Straightforward but Failed Formulation,[0],[0]
"Using the ASR system in section 3.1, we extract 256 beam candidates for every training example in Wall Street Journal (WSJ) dataset.",3.2 Straightforward but Failed Formulation,[0],[0]
"Warm started from the pre-trained RNNLM in section 3.1, we apply SGD to minimize the loss in Eq.",3.2 Straightforward but Failed Formulation,[0],[0]
"(2), with a mini-batch size of 128.",3.2 Straightforward but Failed Formulation,[0],[0]
The training loss is shown in Fig.,3.2 Straightforward but Failed Formulation,[0],[0]
1a.,3.2 Straightforward but Failed Formulation,[0],[0]
"We observe that the learning dynamic is very unstable, and deceases to be negative.",3.2 Straightforward but Failed Formulation,[0],[0]
The unbound decreasing is due to the second term in Eq.,3.2 Straightforward but Failed Formulation,[0],[0]
(2) being negative and dominating the training process.,3.2 Straightforward but Failed Formulation,[0],[0]
"Next, we inspect log pθ(xi)",3.2 Straightforward but Failed Formulation,[0],[0]
"− log pθ(xi,j), the margin between the scores of a ground-truth and a candidate.",3.2 Straightforward but Failed Formulation,[0],[0]
In Fig.,3.2 Straightforward but Failed Formulation,[0],[0]
"2a, we histogram the margins for all the i, j’s in a dev set.",3.2 Straightforward but Failed Formulation,[0],[0]
"The distribution appears to be symmetric around zero, which indicates poor discrimination ability.",3.2 Straightforward but Failed Formulation,[0],[0]
"Given these facts, we conclude that the straightforward formulation in Eq.",3.2 Straightforward but Failed Formulation,[0],[0]
(2) is not effective.,3.2 Straightforward but Failed Formulation,[0],[0]
"To effectively utilize all the imperfect beam candidates, we propose the following objective,
min θ N∑ i=1",3.3 Large Margin Formulation,[0],[0]
"B∑ j=1 max { 0, τ−(log pθ(xi)−log pθ(xi,j)) } , (3) where log pθ(xi)",3.3 Large Margin Formulation,[0],[0]
"− logθ(xi,j) is the margin between the scores of a ground-truth xi and a can-
didate xi,j .",3.3 Large Margin Formulation,[0],[0]
The hinge loss on the margin encourages the log-likelihood of the ground-truth to be at least τ larger than that of the imperfect hypothesis.,3.3 Large Margin Formulation,[0],[0]
"We call an LM trained by the above formulation as Large Margin Language Model (LMLM).
",3.3 Large Margin Formulation,[0],[0]
"We repeat the same experiment in section 3.2, but change the objective function to Eq.",3.3 Large Margin Formulation,[0],[0]
(3) and set τ = 1.,3.3 Large Margin Formulation,[0],[0]
Fig.,3.3 Large Margin Formulation,[0],[0]
"1b shows the training loss, which steadily decreases and approaches zero rapidly.",3.3 Large Margin Formulation,[0],[0]
"Compared with the learning curve of naive formulation (Fig. 1a), the large margin based training is much more stable.",3.3 Large Margin Formulation,[0],[0]
"In Fig. 2b, we also examine the histogram of log pθ(xi)",3.3 Large Margin Formulation,[0],[0]
"− log pθ(xi,j), where pθ(·) is now the LM learned by LMLM.",3.3 Large Margin Formulation,[0],[0]
"Compared with the histogram by the conventional RNNLM, LMLM significantly moves the distribution to the positive side, indicating more discrimination.",3.3 Large Margin Formulation,[0],[0]
"In most cases, all beam candidates are imperfect.",3.4 Ranking Loss Type Formulation,[0],[0]
It may be beneficial to exploit the information that some candidates are relatively better than the others.,3.4 Ranking Loss Type Formulation,[0],[0]
We consider ranking them according to some metrics w.r.t.,3.4 Ranking Loss Type Formulation,[0],[0]
the ground-truth sentences.,3.4 Ranking Loss Type Formulation,[0],[0]
"For ASR, the metric is WER, and for MT, the metric is BLEU score.",3.4 Ranking Loss Type Formulation,[0],[0]
"We define xi,0 , xi and assume that the candidates {xi,j}Kj=1 are sorted such that
WER(xi,xi,j−1) <",3.4 Ranking Loss Type Formulation,[0],[0]
"WER(xi,xi,j)
for ASR, and
BLEU(xi,xi,j−1) > BLEU(xi,xi,j)
for MT.",3.4 Ranking Loss Type Formulation,[0],[0]
"In other words, xi,j−1 has better quality than xi,j .
",3.4 Ranking Loss Type Formulation,[0],[0]
We then enforce the “better” sentences to have a score at least τ larger than those “worse” ones.,3.4 Ranking Loss Type Formulation,[0],[0]
"This leads to the following formulation,
min θ N∑ i=1 B−1∑ j=0",3.4 Ranking Loss Type Formulation,[0],[0]
"B∑ k=j+1 max { 0,
τ",3.4 Ranking Loss Type Formulation,[0],[0]
"− (log pθ(xi,j)− logθ(xi,k)), } .",3.4 Ranking Loss Type Formulation,[0],[0]
"(4)
",3.4 Ranking Loss Type Formulation,[0],[0]
Compared with LMLM formulation Eq.,3.4 Ranking Loss Type Formulation,[0],[0]
"(3), the above introduces more comparisons among the candidates, and hence more computational cost during training.",3.4 Ranking Loss Type Formulation,[0],[0]
"We call this formulation rankingloss-based LMLM (rLMLM).
",3.4 Ranking Loss Type Formulation,[0],[0]
"To summarize this section, we have proposed LMLM and rLMLM that aim at discriminating between hypotheses in a task-specific (e.g., WER or BLEU) sense, instead of minimizing PPL.",3.4 Ranking Loss Type Formulation,[0],[0]
We apply the LMs trained under different criteria to rescore the beams in various ASR systems.,4 Experiments on ASR,[0],[0]
"In particular, we are interested in knowing which of the two training mechanisms is better: minimizing PPL (e.g., the RNNLM in Section 3.1), or fitting to the WER metric by the proposed methods.
",4 Experiments on ASR,[0],[0]
"Adapting an RNNLM to a specific domain has been of interest, especially to the speech community (Park et al., 2010; Chen et al., 2015; Ma et al., 2017).",4 Experiments on ASR,[0],[0]
We adopt Ma et al. (2017) that fine-tune the softmax layer of RNNLM by minimizing the PPL on the text labels of training set.,4 Experiments on ASR,[0],[0]
"According to Ma et al. (2017), the reason not to fine-tune all the layers is due to the limited text labels in the target domain.",4 Experiments on ASR,[0],[0]
"Indeed, we also observe overfitting if adapting all layers, but adapting only the softmax layer effectively decreases the PPL on the text labels of dev sets.",4 Experiments on ASR,[0],[0]
"We refer to this fine-tuning as RNNLM-adapted in the following sections.
",4 Experiments on ASR,[0],[0]
"To make a fair comparison with the adapted model, we also use the RNNLM as an initialization for our LMLM and rLMLM.",4 Experiments on ASR,[0],[0]
"In total, there are four language models for rescoring the beams.",4 Experiments on ASR,[0],[0]
"RNNLM and its adapted version that aim at reducing PPL; and the two proposed methods, LMLM and rLMLM that try to fit to WER.",4 Experiments on ASR,[0],[0]
The WSJ corpora consists of about 80 hours of read speech with texts drawn from a machinereadable corpus of Wall Street Journal news.,4.1 WSJ Dataset,[0],[0]
"We use the standard configuration of train si284 dataset for training, dev93 for development and eval92 for testing.
",4.1 WSJ Dataset,[0],[0]
"Our ASR model has one convolution layer, followed by 5 bidirectional RNNs and one fully connected layer, with a CTC loss on top.",4.1 WSJ Dataset,[0],[0]
"The text labels of the training set are used to train a 4-gram language model, which is employed in the ASR decoder.",4.1 WSJ Dataset,[0],[0]
The beam search decoder has a beam width of 2000.,4.1 WSJ Dataset,[0],[0]
"Before beam rescoring, this ASR system achieves a WER of 12.16 on dev93 set and 7.69 on eval92 set.",4.1 WSJ Dataset,[0],[0]
"To put this into perspective, we list some previous state-of-the-art system in Tab. 2.",4.1 WSJ Dataset,[0],[0]
"Compared with them, our baseline is already very competitive.",4.1 WSJ Dataset,[0],[0]
"The out-of-vocabulary rate of WSJ text is only 0.28%, making the RNNLM reasonable to use.
",4.1.1 WERs and PPLs,[0],[0]
"We apply the RNNLM, RNNLM-adapted (Ma et al., 2017), LMLM and rLMLM to rescore the beams on dev and test set.",4.1.1 WERs and PPLs,[0],[0]
The final score assigned to a beam is a weighted sum of the ASR and language model scores.,4.1.1 WERs and PPLs,[0],[0]
"The weight is found by minimizing the WER on the dev set.
",4.1.1 WERs and PPLs,[0],[0]
Tab. 3 reports the WERs on dev93 and eval92 sets.,4.1.1 WERs and PPLs,[0],[0]
All methods reduce the WER over the baseline without rescoring.,4.1.1 WERs and PPLs,[0],[0]
"However, LMLM and rLMLM are notably better than the other two methods.",4.1.1 WERs and PPLs,[0],[0]
"Moreover, although RNNLM and RNNLM-adapted achieve smaller PPLs on the text labels, the advantage does not transfer to WER.",4.1.1 WERs and PPLs,[0],[0]
"To better understand the proposed methods, we calculate the correlation coefficients between the hypotheses’ WERs and their scores (by different language models).",4.1.2 Correlation between scores and WERs,[0],[0]
"In specific, for every utterance in the test set, we have a set of beam candidates, their word level accuracies (100-WER) and scores given by an LM, from which a Pearson correlation coefficient can be calculated.",4.1.2 Correlation between scores and WERs,[0],[0]
"We calculate the coefficients for all the utterances in the test set, and boxplot these coefficients in Fig. 3.",4.1.2 Correlation between scores and WERs,[0],[0]
"The correlation coefficients by LMLM and rLMLM tend
to be higher than RNNLM and RNNLM-adapted.",4.1.2 Correlation between scores and WERs,[0],[0]
This indicates that LMLM and rLMLM are more aligned with the goal of reducing WER.,4.1.2 Correlation between scores and WERs,[0],[0]
Tab. 4 posts some examples from the test set.,4.1.3 Case Study,[0],[0]
"The first column lists the ground-truth labels, and their corresponding best candidates as re-ranked by the four LMs (see notes in the second column).",4.1.3 Case Study,[0],[0]
Words in red are mistakes made by the candidate sentences.,4.1.3 Case Study,[0],[0]
Scores of these sentences are listed in the last four columns.,4.1.3 Case Study,[0],[0]
"We have the following observations:
1. LMLM and rLMLM give worse scores on the ground-truth labels than RNNLM and RNNLM-adapted, which explains their higher PPL in Tab. 3.
2.",4.1.3 Case Study,[0],[0]
"In the first example, RNNLM and RNNLMadapted assign higher scores to a shorter sentence.",4.1.3 Case Study,[0],[0]
"This is reasonable (though not necessarily desirable) as LM-score is a summation of log-probabilities, each of which is negative.",4.1.3 Case Study,[0],[0]
"In contrast, LMLM and rLMLM are able to assign higher scores to longer and better candidates.
",4.1.3 Case Study,[0],[0]
3.,4.1.3 Case Study,[0],[0]
"In the other two examples, LMLM and rLMLM seem to favor more sensible sentences, though they are not more grammatical than those picked by RNNLM and RNNLMadapted.",4.1.3 Case Study,[0],[0]
"We conjecture that since LMLM and rLMLM utilize beam candidates in their training, they capture and compensate for
some weakness in the ASR, which is not achieved by RNNLM and RNNLM-adapted.",4.1.3 Case Study,[0],[0]
We further validate our methods on a larger noisy dataset collected by Liu et al. (2017).,4.2 10K Speech Dataset,[0],[0]
The dataset has about 10K hours of spontaneous speech.,4.2 10K Speech Dataset,[0],[0]
"The utterances are corrupted by background noise, and a large portion of them are accented.",4.2 10K Speech Dataset,[0],[0]
Therefore it is much more challenging than WSJ.,4.2 10K Speech Dataset,[0],[0]
We adopt the same training-dev-test split as in Liu et al. (2017).,4.2 10K Speech Dataset,[0],[0]
"In specific, there are 5.4M utterances for training, 2,066 for development and 2,054 for testing.
",4.2 10K Speech Dataset,[0],[0]
"The ASR we build has the same architecture as in Liu et al. (2017), except that its decoder integrates an in-domain 5-gram language model.",4.2 10K Speech Dataset,[0],[0]
"This system achieves a WER of 19.17 on dev set, better than the reported 19.77 baseline in Liu et al. (2017).",4.2 10K Speech Dataset,[0],[0]
"Based on the ASR, we repeat the same experiments in section 4.1.",4.2 10K Speech Dataset,[0],[0]
Tab. 5 reports WERs and PPLs on dev and test sets.,4.2 10K Speech Dataset,[0],[0]
"Both LMLM and rLMLM outperform the other methods in WER, although their PPLs are higher.",4.2 10K Speech Dataset,[0],[0]
This trend is similar to that in Tab. 3.,4.2 10K Speech Dataset,[0],[0]
"In this section, we experiment the large-margin criterion trained LM with a competitive Chineseto-English NMT system.",5 Experiments on NMT,[0],[0]
The NMT model is trained from 2M parallel sentence pairs.,5 Experiments on NMT,[0],[0]
"Following Shen et al. (2016), we use NIST 06 newswire portion (616 sentences) for development and NIST 08 newswire portion (691 sentences) for testing.",5 Experiments on NMT,[0],[0]
"We use OpenNMT-py2 package with the default configuration to train the model: batch size is 64; word embedding size is 500; dropout rate is 0.3; target vocabulary size is 50K; number of epochs is 20, after which a minimum dev perplexity of 7.72
2https://github.com/OpenNMT/OpenNMT-py
is achieved.",5 Experiments on NMT,[0],[0]
"We use a beam size of 10 for decoding, and report case-insensitive 4-reference BLEU-4 scores (by calling “multi bleu.perl”3).",5.1 BLEUs and PPLs,[0],[0]
The NMT model achieves 35.18 BLEU score on dev set and 31.52 on test set (see table 6).,5.1 BLEUs and PPLs,[0],[0]
"To put this into perspective, Shen et al. (2016) trains their models on 2.56M pairs of sentences and reports a dev BLEU score of 32.7 (via MOSES) or 30.7 (via RNNsearch, beam size of 10).",5.1 BLEUs and PPLs,[0],[0]
"So our NMT model is already very competitive.
",5.1 BLEUs and PPLs,[0],[0]
"To construct the training data for LMLM and rLMLM, 10 beam candidates are extracted for every sentence in the training set.",5.1 BLEUs and PPLs,[0],[0]
"We then follow the same experimental steps outlined in section 4.1, except that the ASR score is now changed to NMT score.",5.1 BLEUs and PPLs,[0],[0]
"In addition, we also find that normalizing the LM score by sentence length can improve the re-scoring performance substantially.",5.1 BLEUs and PPLs,[0],[0]
Tab. 6 compares the BLEU score after re-ranking by the different LMs.,5.1 BLEUs and PPLs,[0],[0]
LMLM and rLMLM,5.1 BLEUs and PPLs,[0],[0]
"both improve upon the baseline significantly, and outperform RNNLM and RNNLM-adapted by a notable margin.",5.1 BLEUs and PPLs,[0],[0]
"We also observe that the PPLs of LMLM and rLMLM are much larger than those of RNNLM and RNNLM-adapted, suggesting that the PPL metric may be very poorly correlated with BLEU.
",5.1 BLEUs and PPLs,[0],[0]
"Interestingly, RNNLM-adapted does not show any gain in BLEU score over RNNLM.",5.1 BLEUs and PPLs,[0],[0]
"To understand this, we recall that NMT is trained by minimizing PPL on target text.",5.1 BLEUs and PPLs,[0],[0]
Its decoder is implicitly an RNNLM on target language.,5.1 BLEUs and PPLs,[0],[0]
"We conjecture that adapting an LM to the target domain can only duplicate the functionality of the NMT decoder, which does not bring any additional benefit.",5.1 BLEUs and PPLs,[0],[0]
We measure the correlation between the LM scores and BLUEs.,5.2 Correlation between scores and BLEUs,[0],[0]
"The calculation is done on dev06 set in the same way as Section 4.1.2, but now we change the WERs to BLEUs.",5.2 Correlation between scores and BLEUs,[0],[0]
The boxplot of the correlation coefficients are shown in Fig. 4.,5.2 Correlation between scores and BLEUs,[0],[0]
"Compared with the boxplot in Fig. 3, now the correlation coefficients by all LMs are more dispersed.",5.2 Correlation between scores and BLEUs,[0],[0]
"Sometimes, they even take negative values.",5.2 Correlation between scores and BLEUs,[0],[0]
"The mean correlation by LMLM
3https://github.com/OpenNMT/ OpenNMT-py/blob/master/tools/multi-bleu.",5.2 Correlation between scores and BLEUs,[0],[0]
"perl
and rLMLM, however, is considerably higher than those by RNNLM and RNNLM-adapted.",5.2 Correlation between scores and BLEUs,[0],[0]
"“Language modeling is an art of determining the probability of a sequence of words” (Goodman, 2001).",6 Related Work,[0],[0]
"In the past decades, there has been a trend of increasing the context that an LM can condition on.",6 Related Work,[0],[0]
"N-gram models (Chen and Goodman, 1996) assume that each symbol depends on the previous N − 1 symbols.",6 Related Work,[0],[0]
"Feed forward neural network based LMs (Bengio et al., 2003) are not count based",6 Related Work,[0],[0]
but they inherit the restrictive assumption.,6 Related Work,[0],[0]
"To model longer-term dependencies, RNNLMs (Mikolov et al., 2010) are proposed.",6 Related Work,[0],[0]
"RNNLMs often achieve smaller PPLs than the N-gram counterparts (Sundermeyer et al., 2012; Zaremba et al., 2014; Jozefowicz et al., 2016).",6 Related Work,[0],[0]
"This paper focuses on RNNLM-type architectures.
",6 Related Work,[0],[0]
"While these works all adopt PPL as the metric
to optimize, sometimes one may optimize a taskspecific objective.",6 Related Work,[0],[0]
"For example, Kuo et al. (2002); Roark et al. (2007) and Dikic et al. (2013) propose discriminative LMs to improve speech recognition.",6 Related Work,[0],[0]
"The common methodology therein is to fit a probabilistic model, e.g., conditional random field (Roark et al., 2004), to the space of text candidates, and maximize the probability at the desired candidate.",6 Related Work,[0],[0]
The problem is often solved by perceptron algorithm.,6 Related Work,[0],[0]
"However, these methods all rely on ad-hoc choice of features, e.g., counts of n-grams where n varies in a small range (e.g.,1 to 3).",6 Related Work,[0],[0]
"Moreover, it is also not clear how these methods would take advantage of an existing language model (trained on large unsupervised corpus).",6 Related Work,[0],[0]
"Nevertheless, the same methodology can be extended to RNNLMs, thus avoiding the aforementioned limitations.",6 Related Work,[0],[0]
"For example, Auli and Gao (2014) train an RNNLM by favoring sentences with high BLEU scores and integrate it into a phrase-based MT decoder.
",6 Related Work,[0],[0]
"If we cast the problem of picking the best text sequence as a ranking problem, the aforementioned works can be considered as “pointwise” learning-to-rank approaches (Cossock and Zhang, 2008).",6 Related Work,[0],[0]
"In contrast, the proposed method is a “pairwise” approach (Liu, 2009), as it learns a neural language model by comparison between pairs of sentences.",6 Related Work,[0],[0]
"Earlier works in this fashion may date back to (Collins and Koo, 2005), which improves a semantic parser.",6 Related Work,[0],[0]
Learning “by pairwise comparison” is also seen in several MT literatures.,6 Related Work,[0],[0]
"For example, Hopkins and May (2011) propose to train a phrase-based MT system by minimizing a pairwise ranking loss.",6 Related Work,[0],[0]
Wiseman and Rush (2016) optimize the beam search process in a Neural Machine Translation (NMT) system.,6 Related Work,[0],[0]
"They enforce the score of a reference to be higher than that of its decoded k-th candidate by at least a unit margin.
",6 Related Work,[0],[0]
"Rather than optimizing the MT system itself, this work proposes a general method of training recurrent neural language models, which can benefit various text generation tasks, including speech recognition and machine translation.",6 Related Work,[0],[0]
We have proposed a large margin criterion for training recurrent neural language models.,7 Conclusions,[0],[0]
"Rather than minimizing PPL, the proposed criterion is based on comparison between pairs of sen-
tences.",7 Conclusions,[0],[0]
We have formulated two algorithms that implement the training criterion.,7 Conclusions,[0],[0]
"One compares between references and imperfect hypotheses (LMLM), the other compares between all pairs of hypotheses (rLMLM).",7 Conclusions,[0],[0]
We applied the language models trained by these two algorithms to speech recognition and machine translation.,7 Conclusions,[0],[0]
Both of them demonstrate superior performance over their minimum-PPL counterparts.,7 Conclusions,[0],[0]
"However, the performance gain from LMLM to rLMLM is small, although rLMLM is built on more pairwise comparisons and requires more training efforts.",7 Conclusions,[0],[0]
The efficiency with respect to the number of pairs is a future research topic.,7 Conclusions,[0],[0]
We propose a large margin criterion for training neural language models.,abstractText,[0],[0]
"Conventionally, neural language models are trained by minimizing perplexity (PPL) on grammatical sentences.",abstractText,[0],[0]
"However, we demonstrate that PPL may not be the best metric to optimize in some tasks, and further propose a large margin formulation.",abstractText,[0],[0]
The proposed method aims to enlarge the margin between the “good” and “bad” sentences in a task-specific sense.,abstractText,[0],[0]
It is trained end-to-end and can be widely applied to tasks that involve re-scoring of generated text.,abstractText,[0],[0]
"Compared with minimum-PPL training, our method gains up to 1.1 WER reduction for speech recognition and 1.0 BLEU increase for machine translation.",abstractText,[0],[0]
Large Margin Neural Language Model,title,[0],[0]
Mental illness is a major global health issue.,1 Introduction,[0],[0]
"In the U.S. alone, 43.6 million adults (18.1%) experience mental illness in a given year (National Institute of Mental Health, 2015).",1 Introduction,[0],[0]
"In addition to the person directly experiencing a mental illness, family, friends, and communities are also affected (Insel, 2008).
",1 Introduction,[0],[0]
"In many cases, mental health conditions can be treated effectively through psychotherapy and counseling (World Health Organization, 2015).",1 Introduction,[0],[0]
"However, it is far from obvious how to best conduct counseling conversations.",1 Introduction,[0],[0]
"Such conversations are free-form without strict rules, and involve many choices that
*Both authors contributed equally to the paper.
could make a difference in someone’s life.",1 Introduction,[0],[0]
"Thus far, quantitative evidence for effective conversation strategies has been scarce, since most studies on counseling have been limited to very small sample sizes and qualitative observations (e.g., Labov and Fanshel, (1977); Haberstroh et al., (2007)).",1 Introduction,[0],[0]
"However, recent advances in technology-mediated counseling conducted online or through texting (Haberstroh et al., 2007) have allowed counseling services to scale with increasing demands and to collect large-scale data on counseling conversations and their outcomes.
",1 Introduction,[0],[0]
Here we present the largest study on counseling conversation strategies published to date.,1 Introduction,[0],[0]
"We use data from an SMS texting-based counseling service where people in crisis (depression, self-harm, suicidal thoughts, anxiety, etc.), engage in therapeutic conversations with counselors.",1 Introduction,[0],[0]
The data contains millions of messages from eighty thousand counseling conversations conducted by hundreds of counselors over the course of one year.,1 Introduction,[0],[0]
"We develop a set of computational methods suited for large-scale discourse analysis to study how various linguistic aspects of conversations are correlated with conversation outcomes (collected via a follow-up survey).
",1 Introduction,[0],[0]
We focus our analyses on counselors instead of individual conversations because we are interested in general conversation strategies rather than properties of specific issues.,1 Introduction,[0],[0]
"We find that there are significant, quantifiable differences between more successful and less successful counselors in how they conduct conversations.
",1 Introduction,[0],[0]
"Our findings suggest actionable strategies that are associated with successful counseling:
463
Transactions of the Association for Computational Linguistics, vol. 4, pp.",1 Introduction,[0],[0]
"463–476, 2016.",1 Introduction,[0],[0]
Action Editor: Lillian Lee.,1 Introduction,[0],[0]
"Submission batch: 12/2015; Revision batch: 3/2016; 7/2016 Published 8/2016.
",1 Introduction,[0],[0]
c©2016 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
1.",1 Introduction,[0],[0]
"Adaptability (Section 5): Measuring the distance between vector representations of the language used in conversations going well and going badly, we find that successful counselors are more sensitive to the current trajectory of the conversation and react accordingly.",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
Dealing with Ambiguity (Section 6): We develop a clustering-based method to measure differences in how counselors respond to very similar ambiguous situations.,1 Introduction,[0],[0]
"We learn that successful counselors clarify situations by writing more, reflect back to check understanding, and make their conversation partner feel more comfortable through affirmation.",1 Introduction,[0],[0]
3.,1 Introduction,[0],[0]
"Creativity (Section 6.3): We quantify the diversity in counselor language by measuring cluster density in the space of counselor responses and find that successful counselors respond in a more creative way, not copying the person in distress exactly and not using too generic or “templated” responses.",1 Introduction,[0],[0]
4. Making Progress (Section 7): We develop a novel sequence-based unsupervised conversation model able to discover ordered conversation stages common to all conversations.,1 Introduction,[0],[0]
"Analyzing the progression of stages, we determine that successful counselors are quicker to get to know the core issue and faster to move on to collaboratively solving the problem.",1 Introduction,[0],[0]
5. Change in Perspective (Section 8): We develop novel measures of perspective change using psycholinguistics-inspired word frequency analysis.,1 Introduction,[0],[0]
"We find that people in distress are more likely to be more positive, think about the future, and consider others, when the counselors bring up these concepts.",1 Introduction,[0],[0]
"We further show that this perspective change is associated with better conversation outcomes consistent with psychological theories of depression.
",1 Introduction,[0],[0]
"Further, we demonstrate that counseling success on the level of individual conversations is predictable using features based on our discovered conversation strategies (Section 9).",1 Introduction,[0],[0]
Such predictive tools could be used to help counselors better progress through the conversation and could result in better counseling practices.,1 Introduction,[0],[0]
"The dataset used in this work has been released publicly and more information on dataset ac-
cess can be found at http://snap.stanford.",1 Introduction,[0],[0]
"edu/counseling.
",1 Introduction,[0],[0]
"Although we focus on crisis counseling in this work, our proposed methods more generally apply to other conversational settings and can be used to study how language in conversations relates to conversation outcomes.",1 Introduction,[0],[0]
"Our work relates to two lines of research:
Therapeutic Discourse Analysis & Psycholinguistics.",2 Related Work,[0],[0]
"The field of conversation analysis was born in the 1960s out of a suicide prevention center (Sacks and Jefferson, 1995; Van Dijk, 1997).",2 Related Work,[0],[0]
"Since then conversation analysis has been applied to various clinical settings including psychotherapy (Labov and Fanshel, 1977).",2 Related Work,[0],[0]
"Work in psycholinguistics has demonstrated that the words people use can reveal important aspects of their social and psychological worlds (Pennebaker et al., 2003).",2 Related Work,[0],[0]
"Previous work also found that there are linguistic cues associated with depression (Ramirez-Esparza et al., 2008; Campbell and Pennebaker, 2003) as well as with suicude (Pestian et al., 2012).",2 Related Work,[0],[0]
"These findings are consistent with Beck’s cognitive model of depression (1967; cognitive symptoms of depression precede the affective and mood symptoms) and with Pyszczynski and Greenberg’s self-focus model of depression (1987; depressed persons engage in higher levels of self-focus than non-depressed persons).
",2 Related Work,[0],[0]
"In this work, we propose an operationalized psycholinguistic model of perspective change and further provide empirical evidence for these theoretical models of depression.
",2 Related Work,[0],[0]
Large-scale Computational Linguistics Applied to Conversations.,2 Related Work,[0],[0]
"Large-scale studies have revealed subtle dynamics in conversations such as coordination or style matching effects (Niederhoffer and Pennebaker, 2002; Danescu-Niculescu-Mizil, 2012) as well as expressions of social power and status (Bramsen et al., 2011; Danescu-NiculescuMizil et al., 2012).",2 Related Work,[0],[0]
"Other studies have connected writing to measures of success in the context of requests (Althoff et al., 2014), user retention (Althoff and Leskovec, 2015), novels (Ashok et al., 2013), and scientific abstracts (Guerini et al., 2012).",2 Related Work,[0],[0]
"Prior
work has modeled dialogue acts in conversational speech based on linguistic cues and discourse coherence (Stolcke et al., 2000).",2 Related Work,[0],[0]
"Unsupervised machine learning models have also been used to model conversations and segment them into speech acts, topical clusters, or stages.",2 Related Work,[0],[0]
"Most approaches employ Hidden Markov Model-like models (Barzilay and Lee, 2004; Ritter et al., 2010; Paul, 2012; Yang et al., 2014) which are also used in this work to model progression through conversation stages.
",2 Related Work,[0],[0]
"Very recently, technology-mediated counseling has allowed the collection of large datasets on counseling.",2 Related Work,[0],[0]
Howes et al. (2014) find that symptom severity can be predicted from transcript data with comparable accuracy to face-to-face data but suggest that insights into style and dialogue structure are needed to predict measures of patient progress.,2 Related Work,[0],[0]
"Counseling datasets have also been used to predict the conversation outcome (Huang, 2015) but without modeling the within-conversation dynamics that are studied in this work.",2 Related Work,[0],[0]
"Other work has explored how novel interfaces based on topic models can support counselors during conversations (Dinakar et al., 2014a; 2014b; 2015; Chen, 2014).
",2 Related Work,[0],[0]
Our work joins these two lines of research by developing computational discourse analysis methods applicable to large datasets that are grounded in therapeutic discourse analysis and psycholinguistics.,2 Related Work,[0],[0]
"In this work, we study anonymized counseling conversations from a not-for-profit organization providing free crisis intervention via SMS messages.",3 Dataset Description,[0],[0]
"Textbased counseling conversations are particularly well suited for conversation analysis because all interactions between the two dialogue partners are fully observed (i.e., there are no non-textual or non-verbal cues).",3 Dataset Description,[0],[0]
"Moreover, the conversations are important, constrained to dialogue between two people, and outcomes can be clearly defined (i.e., we follow up with the conversation partner as to whether they feel better afterwards), which enables the study of how conversation features are associated with actual outcomes.
",3 Dataset Description,[0],[0]
Counseling Process.,3 Dataset Description,[0],[0]
Any person in distress can text the organization’s public number.,3 Dataset Description,[0],[0]
"Incoming requests are put into a queue and an available coun-
selor picks the request from the queue and engages with the incoming conversation.",3 Dataset Description,[0],[0]
We refer to the crisis counselor as the counselor and the person in distress as the texter.,3 Dataset Description,[0],[0]
"After the conversation ends, the texter receives a follow-up question (“How are you feeling now?",3 Dataset Description,[0],[0]
"Better, same, or worse?”) which we use as our conversation quality ground-truth (we use binary labels: good versus same/worse, since we care about improving the situation).",3 Dataset Description,[0],[0]
"In contrast to previous work that has used human judges to rate a caller’s crisis state (Kalafat et al., 2007), we directly obtain this feedback from the texter.",3 Dataset Description,[0],[0]
"Furthermore, the counselor fills out a post-conversation report (e.g., suicide risk, main issue such as depression, relationship, self-harm, suicide, etc.).",3 Dataset Description,[0],[0]
"All crisis counselors receive extensive training and commit to weekly shifts for a full year.
",3 Dataset Description,[0],[0]
Dataset Statistics.,3 Dataset Description,[0],[0]
"Our dataset contains 408 counselors and 3.2 million messages in 80,885 conversations between November 2013 and November 2014 (see Table 1).",3 Dataset Description,[0],[0]
"All system messages (e.g., instructions), as well as texts that contain survey responses (revealing the ground-truth label for the conversation) were filtered out.",3 Dataset Description,[0],[0]
"Out of these conversations, we use the 15,555, or 19.2%, that contain a groundtruth label (whether the texter feels better or the same/worse after the conversation) for the following analyses.",3 Dataset Description,[0],[0]
Conversations span a variety of issues of different difficulties (see rows one and two of Table 2).,3 Dataset Description,[0],[0]
Approval to analyze the dataset was obtained from the Stanford IRB.,3 Dataset Description,[0],[0]
The primary goal of this paper is to study strategies that lead to conversations with positive outcomes.,4 Defining Counseling Quality,[0],[0]
"Thus, we require a ground-truth notion of conversation quality.",4 Defining Counseling Quality,[0],[0]
"In principle, we could study individ-
ual conversations and aim to understand what factors make the conversation partner (texter) feel better.",4 Defining Counseling Quality,[0],[0]
"However, it is advantageous to focus on the conversation actor (counselor) instead of individual conversations.
",4 Defining Counseling Quality,[0],[0]
"There are several benefits of focusing analyses on counselors (rather than individual conversations): First, we are interested in general conversation strategies rather than properties of main issues (e.g., depression vs. suicide).",4 Defining Counseling Quality,[0],[0]
"While each conversation is different and will revolve around its main issue, we assume that counselors have a particular style and strategy that is invariant across conversations.",4 Defining Counseling Quality,[0],[0]
"Second, we assume that conversation quality is noisy.",4 Defining Counseling Quality,[0],[0]
Even a very good counselor will face some hard conversations in which they do everything right but are still unable to make their conversation partner feel better.,4 Defining Counseling Quality,[0],[0]
"Over time, however, the “true” quality of the counselor will become apparent.",4 Defining Counseling Quality,[0],[0]
"Third, our goal is to understand successful conversation strategies and to make use of these insights in counselor training.",4 Defining Counseling Quality,[0],[0]
"Focusing on the counselor is helpful in understanding, monitoring, and improving counselors’ conversation strategies.
",4 Defining Counseling Quality,[0],[0]
More vs. Less Successful Counselors.,4 Defining Counseling Quality,[0],[0]
We split the counselors into two groups and then compare their behavior.,4 Defining Counseling Quality,[0],[0]
"Out of the 113 counselors with more than 15 labeled conversations of at least 30 messages each, we use the most successful 40 counselors as “more successful” counselors and the bottom 40 as “less successful” counselors.",4 Defining Counseling Quality,[0],[0]
"Their average success rates are 66.3-85.5% and 42.1-58.6%, respectively.",4 Defining Counseling Quality,[0],[0]
"While the counselor-level analysis is of primary concern, we will also differentiate between counselor behavior in “positive” versus “negative” conversations (i.e., those that will eventually make the texter feel better vs. not).",4 Defining Counseling Quality,[0],[0]
"Thus, in the remainder of the paper we differentiate between more vs. less successful counselors and positive vs. negative conver-
sations. Studying the cross product of counselors and conversations allows us to gain insights on how both groups behave in positive and negative conversations.",4 Defining Counseling Quality,[0],[0]
"For example, Figure 1 illustrates why differentiating between counselors and as well as conversations is necessary: differences in counselor message length over the course of the conversation are bigger between more and less successful counselors than between positive and negative conversations.
",4 Defining Counseling Quality,[0],[0]
Initial Analysis.,4 Defining Counseling Quality,[0],[0]
Before focusing on detailed analyses of counseling strategies we address two important questions: Do counselors specialize in certain issues?,4 Defining Counseling Quality,[0],[0]
"And, do successful counselors appear successful only because they handle “easier” cases?
",4 Defining Counseling Quality,[0],[0]
"To gain insights into the “specialization hypothesis” we make use the counselor annotation of the main issue (depression, self-harm, etc.).",4 Defining Counseling Quality,[0],[0]
We compare success rates of counselors across different issues and find that successful counselors have a higher fraction of positive conversations across all issues and that less successful counselors typically do not excel at a particular issue.,4 Defining Counseling Quality,[0],[0]
"Thus, we conclude
that counseling quality is a general trait or skill and supporting that the split into more and less successful counselors is meaningful.
",4 Defining Counseling Quality,[0],[0]
Another simple explanation of the differences between more and less successful counselors could be that successful counselors simply pick “easy” issues.,4 Defining Counseling Quality,[0],[0]
"However, we find that this is not the case.",4 Defining Counseling Quality,[0],[0]
"In particular, we find that both counselor groups are very similar in how they select conversations from the queue (picking the top-most in 60.1% vs. 60.3%, respectively), work similar shifts, and handle a similar number of conversations simultaneously (1.98 vs. 1.83).",4 Defining Counseling Quality,[0],[0]
"Further, we find that both groups face similar distributions of issues over time (see Table 2).",4 Defining Counseling Quality,[0],[0]
"We attribute the largest difference, “NA” (main issue not reported), to the more successful counselors being more diligent in filling out the post-conversation report and having fewer conversations that end before the main issue is introduced.",4 Defining Counseling Quality,[0],[0]
In the remainder of the paper we focus on factors that mediate the outcome of a conversation.,5 Counselor Adaptability,[0],[0]
"First, we examine whether successful counselors are more aware that their current conversation is going well or badly and study how the counselor adapts to the situation.",5 Counselor Adaptability,[0],[0]
We investigate this question by looking for language differences between positive and negative conversations.,5 Counselor Adaptability,[0],[0]
"In particular, we compute a distance measure between the language counselors use in positive conversations and the language counselors use in negative conversations and observe how this distance changes over time.
",5 Counselor Adaptability,[0],[0]
We capture the time dimension by breaking up each conversation into five even chunks of messages.,5 Counselor Adaptability,[0],[0]
"Then, for each set of counselors (more successful or less successful), conversation outcome (positive or negative), and chunk (first 20%, second 20%, etc.), we build a TF-IDF vector of word occurrences to represent the language of counselors within this subset.",5 Counselor Adaptability,[0],[0]
"We use the global inverse document (i.e., conversation) frequencies instead of the ones from each subset to make the vectors directly comparable and control for different counselors having different numbers of conversations by weighting conversations so all counselors have equal contributions.",5 Counselor Adaptability,[0],[0]
"We then measure the difference between the “posi-
tive” and “negative” vector representations by taking the cosine distance in the induced vector space.",5 Counselor Adaptability,[0],[0]
"We also explored using Jensen-Shannon divergence between traditional probabilistic language models and found these methods gave similar results.
Results.",5 Counselor Adaptability,[0],[0]
We find more successful counselors are more sensitive to whether the conversation is going well or badly and vary their language accordingly (Figure 2).,5 Counselor Adaptability,[0],[0]
"At the beginning of the conversation, the language between positive and negative conversations is quite similar, but then the distance in language increases over time.",5 Counselor Adaptability,[0],[0]
"This increase in distance is much larger for more successful counselors than less successful ones, suggesting they are more aware of when conversations are going poorly and adapt their counseling more in an attempt to remedy the situation.",5 Counselor Adaptability,[0],[0]
"Observing that successful counselors are better at adapting to the conversation, we next examine how counselors differ and what factors determine the differences.",6 Reacting to Ambiguity,[0],[0]
"In particular, domain experts have suggested that more successful counselors are better at handling ambiguity in the conversation (Levitt and Jacques, 2005).",6 Reacting to Ambiguity,[0],[0]
"Here, we use ambiguity to refer to the uncertainty of the situation and the texter’s actual core issue resulting from insufficiently short or uncertain descriptions.",6 Reacting to Ambiguity,[0],[0]
Does initial ambiguity of the situation negatively affect the conversation?,6 Reacting to Ambiguity,[0],[0]
"How do more successful counselors deal with ambiguous situations?
Ambiguity.",6 Reacting to Ambiguity,[0],[0]
Throughout this section we measure ambiguity in the conversation as the shortness of the texter’s responses in number of words.,6 Reacting to Ambiguity,[0],[0]
"While ambiguity could also be measured through concreteness ratings of the words in each message (e.g., using concreteness ratings from Brysbaert et al. (2014)), we find that results are very similar and that length and concreteness are strongly related and hard to distinguish.",6 Reacting to Ambiguity,[0],[0]
"It is challenging to measure ambiguity and reactions to ambiguity at arbitrary points throughout the conversation since it strongly depends on the context of the entire conversation (i.e., all earlier messages and questions).",6.1 Initial Ambiguity and Situation Setter,[0],[0]
"However, we can study nearly identi-
cal beginnings of conversations where we can directly compare how more successful and less successful counselors react given nearly identical situations (the texter first sharing their reason for texting in).",6.1 Initial Ambiguity and Situation Setter,[0],[0]
"We identify the situation setter within each conversation as the first long message by the texter (typically a response to a “Can you tell me more about what is going on?” question by the counselor).
Results.",6.1 Initial Ambiguity and Situation Setter,[0],[0]
We find that ambiguity plays an important role in counseling conversations.,6.1 Initial Ambiguity and Situation Setter,[0],[0]
"Figure 3 shows that more ambiguous situations (shorter length of situation setter) are less likely to result in successful conversations (we obtain similar results when measuring concreteness (Brysbaert et al., 2014) directly).",6.1 Initial Ambiguity and Situation Setter,[0],[0]
"Further, we find that counselors generally react to short and ambiguous situation setters by writing significantly more than the texters (Figure 4; if counselors wrote exactly as much as the texter, we would expect a horizontal line y = 1).",6.1 Initial Ambiguity and Situation Setter,[0],[0]
"However, more successful counselors react more strongly to ambiguous situations than less successful counselors.",6.1 Initial Ambiguity and Situation Setter,[0],[0]
"Having observed that ambiguity plays an important role in counseling conversations, we now examine in greater detail how counselors respond to nearly identical situations.
",6.2 How to Respond to Ambiguity,[0],[0]
"We match situation setters by representing them through TF-IDF vectors on bigrams and find similar situation setters as nearest neighbors within a certain cosine distance in the induced space.1 We only consider situation setters that are part of a dense cluster with at least 10 neighbors, allowing us to compare follow-up responses by the counselors (4829/12770 situation setters were part of one of 589 such clusters).",6.2 How to Respond to Ambiguity,[0],[0]
"We also used distributed word embeddings (e.g., (Mikolov et al., 2013))",6.2 How to Respond to Ambiguity,[0],[0]
instead of TF-IDF vectors,6.2 How to Respond to Ambiguity,[0],[0]
"but found the latter to produce better clusters.
",6.2 How to Respond to Ambiguity,[0],[0]
"Based on counselor training materials we hypothesize that more successful counselors
• address ambiguity by writing more themselves, • use more check questions (statements that tell
the conversation partner that you understand 1 Threshold manually set after qualitative analysis of matches from randomly chosen clusters.",6.2 How to Respond to Ambiguity,[0],[0]
"Results were not overly sensitive to threshold choice, choice of representation (e.g., word vectors), and distance measure (e.g., Euclidean).
them while avoiding the introduction of any opinion or advice (Labov and Fanshel, 1977); e.g.“that sounds like...”),
• check for suicidal thoughts early (e.g., “want to die”),
• thank the texter for showing the courage to talk to them (e.g., “appreciate”),
• use more hedges (mitigating words used to lessen the impact of an utterance; e.g., “maybe”, “fairly”),
• and that they are less likely to respond with surprise (e.g., “oh, this sounds really awful”).
",6.2 How to Respond to Ambiguity,[0],[0]
"A set of regular expressions is used to detect each class of responses (similar to the examples above).
",6.2 How to Respond to Ambiguity,[0],[0]
Results.,6.2 How to Respond to Ambiguity,[0],[0]
We find several statistically significant differences in how counselors respond to nearly identical situation setters (see Table 3).,6.2 How to Respond to Ambiguity,[0],[0]
"While situation setters tend to be slightly longer for more successful counselors (suggesting that conversations are not perfectly randomly assigned), counselor responses are significantly longer and also spur longer texter responses.",6.2 How to Respond to Ambiguity,[0],[0]
"Further, the more successful counselors respond in a way that is less similar to the original situation setter (measured by cosine similarity in TFIDF space) compared to less successful counselors (but the texter’s response does not seem affected).",6.2 How to Respond to Ambiguity,[0],[0]
"We do find that more successful counselors use more check questions, check for suicide ideation more often, show the texter more appreciation, and use more hedges, but we did not find a significant difference with respect to responding with surprise.",6.2 How to Respond to Ambiguity,[0],[0]
"In Section 6.2, we observed that more successful counselors make use of certain templates (including check questions, checks for suicidal thoughts, affirmation, and using hedges).",6.3 Response Templates and Creativity,[0],[0]
"While this could suggest that counselors should stick to such predefined templates, we find that, in fact, more successful counselors do respond in more creative ways.
",6.3 Response Templates and Creativity,[0],[0]
"We define a measure of how “templated” the counselors responses are by counting the number of similar responses in TF-IDF space for the counselor reaction (c.f., Section 6.2; again using a manually defined and validated threshold on cosine distance).
",6.3 Response Templates and Creativity,[0],[0]
Figure 5 shows that more successful counselors use less common/templated questions.,6.3 Response Templates and Creativity,[0],[0]
"This suggests that while more successful counselors questions follow certain patterns, they are more creative in their response to each situation.",6.3 Response Templates and Creativity,[0],[0]
"This tailoring of responses requires more effort from the counselor, which is consistent with the results in Figure 1 that showed that more successful counselors put in more effort in composing longer messages as well.",6.3 Response Templates and Creativity,[0],[0]
"After demonstrating content-level differences between counselors, we now explore temporal differences in how counselors progress through conversations.",7 Ensuring Conversation Progress,[0],[0]
"Using an unsupervised conversation model, we are able to discover distinct conversation stages and find differences between counselors in how they
move through these stages.",7 Ensuring Conversation Progress,[0],[0]
We further provide evidence that these differences could be related to power and authority by measuring linguistic coordination between the counselor and texter.,7 Ensuring Conversation Progress,[0],[0]
Counseling conversations follow a common structure due to the nature of conversation as well as counselor training.,7.1 Unsupervised Conversation Model,[0],[0]
"Typically, counselors first introduce themselves, get to know the texter and their situation, and then engage in constructive problem solving.",7.1 Unsupervised Conversation Model,[0],[0]
"We employ unsupervised conversation modeling techniques to capture this stage-like structure within conversations.
",7.1 Unsupervised Conversation Model,[0],[0]
Our conversation model is a message-level Hidden Markov Model (HMM).,7.1 Unsupervised Conversation Model,[0],[0]
Figure 6 illustrates the basic model where hidden states of the HMM represent conversation stages.,7.1 Unsupervised Conversation Model,[0],[0]
"Unlike in prior work on conversation modeling, we impose a fixed ordering on the stages and only allow transitions from the current stage to the next one (Figure 7).",7.1 Unsupervised Conversation Model,[0],[0]
This causes it to learn a fixed dialogue structure common to all of the counseling sessions as opposed to conversation topics.,7.1 Unsupervised Conversation Model,[0],[0]
"Furthermore, we separately model counselor and texter messages by treating their turns in the conversation as distinct states.",7.1 Unsupervised Conversation Model,[0],[0]
"We train the conversation model with expectation maximization, using the forward-backward algorithm to produce the distributions during each expectation step.",7.1 Unsupervised Conversation Model,[0],[0]
We initialized the model with each stage producing messages according to a unigram distribution estimated from all messages in the dataset and uniform transition probabilities.,7.1 Unsupervised Conversation Model,[0],[0]
"The unigram language models are defined over all words occurring more than 20 times (over 98% of words in the dataset), with other words replaced by an unknown token.
",7.1 Unsupervised Conversation Model,[0],[0]
Results.,7.1 Unsupervised Conversation Model,[0],[0]
We explored training the model with various numbers of stages and found five stages to produce a distinct and easily interpretable representation of a conversation’s progress.,7.1 Unsupervised Conversation Model,[0],[0]
Table 4 shows the words most unique to each stage.,7.1 Unsupervised Conversation Model,[0],[0]
The first and last stages consist of the basic introductions and wrapups common to all conversations.,7.1 Unsupervised Conversation Model,[0],[0]
"In stage 2, the texter introduces the main issue, while the counselor asks for clarifications and expresses empathy for the situation.",7.1 Unsupervised Conversation Model,[0],[0]
"In stage 3, the counselor and texter discuss the problem, particularly in relation to the other
people involved.",7.1 Unsupervised Conversation Model,[0],[0]
"In stage 4, the counselor and texter discuss actionable strategies that could help the texter.",7.1 Unsupervised Conversation Model,[0],[0]
This is a well-known part of crisis counselor training called “collaborative problem solving.”,7.1 Unsupervised Conversation Model,[0],[0]
Do counselors differ in how much time they spend at each stage?,7.2 Analyzing Counselor Progression,[0],[0]
"In order to explore how counselors progress through the stages, we use the Viterbi algorithm to assign each conversation the most likely sequence of stages according to our conversation model.",7.2 Analyzing Counselor Progression,[0],[0]
We then compute the average duration in messages of each stage for both more and less successful counselors.,7.2 Analyzing Counselor Progression,[0],[0]
"We control for the different distributions of positive and negative conversations among more successful and less successful counselors by giving the two classes of conversations equal weight and control for different conversation lengths by only including conversations between 40 and 60 messages long.
Results.",7.2 Analyzing Counselor Progression,[0],[0]
"We find that more successful counselors are quicker to move past the earlier stages, partic-
ularly stage 2, and spend more time in later stages, particularly stage 4 (Figure 8).",7.2 Analyzing Counselor Progression,[0],[0]
"This suggests they are able to more quickly get to know the texter and then spend more time in the problem solving phase of the conversation, which could be one of the reasons they are more successful.",7.2 Analyzing Counselor Progression,[0],[0]
One possible explanation for the more successful counselors’ ability to quickly move through the early stages is that they have more “power” in the conversation and can thus exert more control over the progression of the conversation.,7.3 Coordination and Power Differences,[0],[0]
"We explore this idea by analyzing linguistic coordination, which measures how much the conversation partners adapt to each other’s conversational styles.",7.3 Coordination and Power Differences,[0],[0]
"Research has shown that conversation participants who have a greater position of power coordinate less (i.e., they do not adapt their linguistic style to mimic the other conversational participant as strongly) (DanescuNiculescu-Mizil et al., 2012).
",7.3 Coordination and Power Differences,[0],[0]
"In our analysis, we use the “Aggregated 2” coordination measure C(B,A) from Danescu-NiculescuMizil (2012), which measures how much group B coordinates to group A (a higher number means more coordination).",7.3 Coordination and Power Differences,[0],[0]
"The measure is computed by
counting how often specific markers (e.g., auxiliary verbs) are exhibited in conversations.",7.3 Coordination and Power Differences,[0],[0]
"If someone tends to use a particular marker right after their conversation partner uses that marker, it suggests they are coordinating to their partner.
",7.3 Coordination and Power Differences,[0],[0]
"Formally, let set S be a set of exchanges, each involving an initial utterance u1 by a ∈ A and a reply u2 by b ∈",7.3 Coordination and Power Differences,[0],[0]
B.,7.3 Coordination and Power Differences,[0],[0]
"Then the coordination of b to A according to a linguistic marker m is:
Cm(b, A) = P (Emu2→u1 |Emu1)− P (Emu2→u1) where Emu1 is the event that utterance u1 exhibits m (i.e., contains a word from category m) and Emu2→u1 is the event that reply u2 to u1 exhibits m. The probabilities are estimated across all exchanges in S. To aggregate across different markers, we average the coordination values of Cm(b, A) over all markers m to get a macro-average C(b, A).",7.3 Coordination and Power Differences,[0],[0]
"The coordination between groups B and A is then defined as the mean of the coordinations of all members of group B towards the group A.
",7.3 Coordination and Power Differences,[0],[0]
"We use eight markers from Danescu-NiculescuMizil (2012), which are considered to be processed by humans in a generally non-conscious fashion: articles, auxiliary verbs, conjunctions, high-frequency adverbs, indefinite pronouns, personal pronouns, prepositions, and quantifiers.
Results.",7.3 Coordination and Power Differences,[0],[0]
"Texters coordinate less than counselors, with texters having a coordination value of C(texter, counselor)=0.019 compared to the counselor’s C(counselor, texter)=0.030, suggesting that the texters hold more “power” in the conversation.",7.3 Coordination and Power Differences,[0],[0]
"However, more successful counselors coordinate less than less successful ones (C(more succ.",7.3 Coordination and Power Differences,[0],[0]
"counselors, texter)=0.029 vs. C(less succ.",7.3 Coordination and Power Differences,[0],[0]
"counselors, texter)=0.032).",7.3 Coordination and Power Differences,[0],[0]
All differences are statistically significant (p < 0.01; MannWhitney U test).,7.3 Coordination and Power Differences,[0],[0]
"This suggests that more successful counselors act with more control over the conversa-
tion, which could explain why they are quicker to make it through the initial conversation stages.",7.3 Coordination and Power Differences,[0],[0]
"Thus far, we have studied conversation dynamics and their relation to conversation success from the counselor perspective.",8 Facilitating Perspective Change,[0],[0]
"In this section, we show that perspective change in the texter over time is associated with a higher likelihood of conversation success.",8 Facilitating Perspective Change,[0],[0]
"Prior work has shown that day-to-day changes in writing style are associated with positive health outcomes (Campbell and Pennebaker, 2003), and existing theories link depression to a negative view of the future (Pyszczynski et al., 1987) and a selffocusing style (Pyszczynski and Greenberg, 1987).",8 Facilitating Perspective Change,[0],[0]
"Here, we propose a novel measure to quantify three orthogonal aspects of perspective change within a single conversation: time, self, and sentiment.",8 Facilitating Perspective Change,[0],[0]
"Further, we show that the counselor might be able to actively induce perspective change.
",8 Facilitating Perspective Change,[0],[0]
Time.,8 Facilitating Perspective Change,[0],[0]
"Texters start explaining their issue largely in terms of the past and present but over time talk more about the future (see Figure 9A; each plot shows the relative amount of words in the LIWC past, present, and future categories (Tausczik and Pennebaker, 2010)).",8 Facilitating Perspective Change,[0],[0]
We find that texters writing more about the future are more likely to feel better after the conversation.,8 Facilitating Perspective Change,[0],[0]
"This suggests that changing the perspective from issues in the past towards the future is associated with a higher likelihood of successfully working through the crisis.
",8 Facilitating Perspective Change,[0],[0]
Self.,8 Facilitating Perspective Change,[0],[0]
"Another important aspect of behavior change is to what degree the texter is able to change their perspective from talking about themselves to considering others and potentially the effect of their situation on others (Pyszczynski and Greenberg, 1987; Campbell and Pennebaker, 2003).",8 Facilitating Perspective Change,[0],[0]
"We measure how much the texter is focused on themselves by the relative amount of first person singular pronouns (I, me, mine) versus third person singular/plural pronouns (she, her, him / they, their), again using LIWC.",8 Facilitating Perspective Change,[0],[0]
"Figure 9B shows that a smaller amount of self-focus is associated with more successful conversations (providing support for the self-focus model of depression (Pyszczynski and Greenberg, 1987)).",8 Facilitating Perspective Change,[0],[0]
"We hypothesize that the lack of difference at the end of the conversation is due to conversation norms such
as thanking the counselor (“I really appreciate it.”)",8 Facilitating Perspective Change,[0],[0]
"even if the texter does not actually feel better.
Sentiment.",8 Facilitating Perspective Change,[0],[0]
"Lastly, we investigate how much a change in sentiment of the texter throughout the conversation is associated with conversation success.",8 Facilitating Perspective Change,[0],[0]
We measure sentiment as the relative fraction of positive words using the LIWC PosEmo and NegEmo sentiment lexicons.,8 Facilitating Perspective Change,[0],[0]
"The results in Figure 9C show that texters always start out more negative (value below 0.5), but that the sentiment becomes more positive over time for both positive and negative conversations.",8 Facilitating Perspective Change,[0],[0]
"However, we find that the separation between both groups grows larger over time, which suggests that a positive perspective change throughout the conversation is related to higher likelihood of conversation success.",8 Facilitating Perspective Change,[0],[0]
We find that both curves increase significantly at the very end of the conversation.,8 Facilitating Perspective Change,[0],[0]
"Again, we attribute this to conversation norms such as thanking the counselor for listening even when the texter does not actually feel better.",8 Facilitating Perspective Change,[0],[0]
"Together with the result on talking about the future, these findings are consistent with the theory of Pyszczynski et al.",8 Facilitating Perspective Change,[0],[0]
"(1987) that depression is related to a negative view of the future.
",8 Facilitating Perspective Change,[0],[0]
Role of a Counselor.,8 Facilitating Perspective Change,[0],[0]
"Given that positive conversations often exhibit perspective change, a natural question is how counselors can encourage perspective change in the texter.",8 Facilitating Perspective Change,[0],[0]
"We investigate this by exploring the hypothesis that the texter will tend to talk more about something (e.g., the future), if the counselor first talks about it.",8 Facilitating Perspective Change,[0],[0]
"We measure this tendency using the same coordination measures as Section 7.3 except that instead of using stylistic LIWC markers (e.g., auxiliary verbs, quantifiers), we use the LIWC markers relevant to the particular aspect of perspective change (e.g., Future, HeShe, PosEmo).",8 Facilitating Perspective Change,[0],[0]
In all cases we find a statistically significant (p < 0.01; Mann-Whitney U-test) increase in the likelihood of the texter using a LIWC marker if the counselor used it in the previous message (~4-5% change).,8 Facilitating Perspective Change,[0],[0]
This link between perspective change and how the counselor conducts the conversation suggests that the counselor might be able to actively induce measurable perspective change in the texter.,8 Facilitating Perspective Change,[0],[0]
"In this section, we combine our quantitative insights into a prediction task.",9 Predicting Counseling Success,[0],[0]
We show that the linguistic aspects of crisis counseling explored in previous sections have predictive power at the level of individual conversations by evaluating their effectiveness as features in classifying the outcome of conversations.,9 Predicting Counseling Success,[0],[0]
"Specifically, we create a balanced dataset of positive and negative conversations more than 30 messages long and train a logistic regression model to predict the outcome given the first x% of messages in the conversation.",9 Predicting Counseling Success,[0],[0]
There are 3619 such negative conversations and and we randomly subsample the larger set of positive conversations.,9 Predicting Counseling Success,[0],[0]
We train the model with batch gradient descent and use L1 regularization when n-gram features are present and L2 regularization otherwise.,9 Predicting Counseling Success,[0],[0]
"We evaluate our model with 10-fold cross-validation and compare models using the area under the ROC curve (AUC).
",9 Predicting Counseling Success,[0],[0]
Features.,9 Predicting Counseling Success,[0],[0]
"We include three aspects of counselor messages discussed in Section 6: hedges, check questions, and the similarity between the counselor’s message and previous texter message.",9 Predicting Counseling Success,[0],[0]
We add a measure of how much progress the counselor has made (Section 7) by computing the Viterbi path of stages for the conversation (only for the first x%) with the HMM conversation model and then adding the duration of each stage (in #messages) as a feature.,9 Predicting Counseling Success,[0],[0]
"Additionally, we add average message length
and average sentiment per message using VADER sentiment (Hutto and Gilbert, 2014).",9 Predicting Counseling Success,[0],[0]
"Further, we add temporal dynamics to the model by adding feature conjunctions with the stages HMM model.",9 Predicting Counseling Success,[0],[0]
"After running the stages model over the x% of the conversation available to the classifier, we add each feature’s average value over each stage as additional features.",9 Predicting Counseling Success,[0],[0]
"Lastly, we explore the benefits of adding surface-level text features to the model by adding unigram and bigram features.",9 Predicting Counseling Success,[0],[0]
"Because the focus of this work is on counseling strategies, we primarily experiment with models using only features from counselor messages.",9 Predicting Counseling Success,[0],[0]
"For completeness, we also report results for a model including texter features.
",9 Predicting Counseling Success,[0],[0]
Prediction Results.,9 Predicting Counseling Success,[0],[0]
"The model’s accuracy increases with x, and we show that the model is able to dis-
tinguish positive and negative conversations after only seeing the first 20% of the conversation (see Figure 10).",9 Predicting Counseling Success,[0],[0]
"We attribute the significant increase in performance for x = 100 (Accuracy=0.687, AUC=0.716) to strong linguistic cues that appear as a conversation wraps up (e.g., “I’m glad you feel better.”).",9 Predicting Counseling Success,[0],[0]
"To avoid this issue, our detailed feature analysis is performed at x = 80.
",9 Predicting Counseling Success,[0],[0]
Feature Analysis.,9 Predicting Counseling Success,[0],[0]
The model performance as features are incrementally added to the model is shown in Table 5.,9 Predicting Counseling Success,[0],[0]
All features improve model accuracy significantly (p < 0.001; paired bootstrap resampling test).,9 Predicting Counseling Success,[0],[0]
Adding n-gram features produces the largest boost in AUC and significantly improves over a model just using n-gram features (0.638 vs. 0.652 AUC).,9 Predicting Counseling Success,[0],[0]
Note that most features in the full model are based on word frequency counts that can be derived from n-grams which explains why a simple n-gram model already performs quite well.,9 Predicting Counseling Success,[0],[0]
"However, our model performs well with only a small set of linguistic features, demonstrating they provide a substantial amount of the predictive power.",9 Predicting Counseling Success,[0],[0]
"The effectiveness of these features shows that, in addition to exhibiting group-level differences reported earlier in this paper, they provide useful signal for predicting the outcome of individual conversations.",9 Predicting Counseling Success,[0],[0]
Knowledge about how to conduct a successful counseling conversation has been limited by the fact that studies have remained largely qualitative and smallscale.,10 Conclusion & Future Work,[0],[0]
"In this work, we presented a large-scale quan-
titative study on the discourse of counseling conversations.",10 Conclusion & Future Work,[0],[0]
We developed a set of novel computational discourse analysis methods suited for largescale datasets and used them to discover actionable conversation strategies that are associated with better conversation outcomes.,10 Conclusion & Future Work,[0],[0]
We hope that this work will inspire future generations of tools available to people in crisis as well as their counselors.,10 Conclusion & Future Work,[0],[0]
"For example, our insights could help improve counselor training and give rise to real-time counseling quality monitoring and answer suggestion support tools.
",10 Conclusion & Future Work,[0],[0]
Acknowledgements.,10 Conclusion & Future Work,[0],[0]
"We thank Bob Filbin for facilitating the research, Cristian Danescu-NiculescuMizil for many helpful discussions, and Dan Jurafsky, Chris Manning, Justin Cheng, Peter Clark, David Hallac, Caroline Suen, Yilun Wang and the anonymous reviewers for their valuable feedback on the manuscript.",10 Conclusion & Future Work,[0],[0]
"This research has been supported in part by NSF CNS-1010921, IIS-1149837, NIH BD2K, ARO MURI, DARPA XDATA, DARPA SIMPLEX, Stanford Data Science Initiative, Boeing, Lightspeed, SAP, and Volkswagen.",10 Conclusion & Future Work,[0],[0]
Mental illness is one of the most pressing public health issues of our time.,abstractText,[0],[0]
"While counseling and psychotherapy can be effective treatments, our knowledge about how to conduct successful counseling conversations has been limited due to lack of large-scale data with labeled outcomes of the conversations.",abstractText,[0],[0]
"In this paper, we present a large-scale, quantitative study on the discourse of text-message-based counseling conversations.",abstractText,[0],[0]
We develop a set of novel computational discourse analysis methods to measure how various linguistic aspects of conversations are correlated with conversation outcomes.,abstractText,[0],[0]
"Applying techniques such as sequence-based conversation models, language model comparisons, message clustering, and psycholinguistics-inspired word frequency analyses, we discover actionable conversation strategies that are associated with better conversation outcomes.",abstractText,[0],[0]
Large-scale Analysis of Counseling Conversations: An Application of Natural Language Processing to Mental Health,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2344–2356 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2344",text,[0],[0]
"Being a classic language exercise, the cloze test (Taylor, 1953) is an accurate assessment of language proficiency (Fotos, 1991; Jonz, 1991; Tremblay, 2011) and has been widely employed in language examinations.",1 Introduction,[0],[0]
"Under a typical setting, a cloze test requires examinees to fill in missing words (or sentences) to best fit the surrounding context.",1 Introduction,[0],[0]
"To facilitate natural language understanding, automatically-generated cloze datasets are introduced to measure the ability of machines in reading comprehension (Hermann et al., 2015; Hill et al., 2016; Onishi et al., 2016).",1 Introduction,[0],[0]
"In these datasets, each cloze question typically consists of
∗ Equal contribution.",1 Introduction,[0],[0]
1CLOTH (CLOze test by TeacHers) is available at http://www.cs.cmu.edu/˜glai1/data/cloth/. 2The leaderboard is available at http://www.,1 Introduction,[0],[0]
"qizhexie.com/data/CLOTH_leaderboard.html
",1 Introduction,[0],[0]
a context paragraph and a question sentence.,1 Introduction,[0],[0]
"By randomly replacing a particular word in the question sentence with a blank symbol, a single test case is created.",1 Introduction,[0],[0]
"For instance, CNN/Daily Mail datasets (Hermann et al., 2015) use news articles as contexts and summary bullet points as the question sentence.",1 Introduction,[0],[0]
Only named entities are removed when creating the blanks.,1 Introduction,[0],[0]
"Similarly, in Children’s Books test (CBT) (Hill et al., 2016), cloze questions are obtained by removing a word in the last sentence of every consecutive 21 sentences, with the first 20 sentences being the context.",1 Introduction,[0],[0]
"Different from CNN/Daily Mail datasets, CBT also provides each question with a candidate answer set, consisting of randomly sampled words with the same part-of-speech tag from the context as that of the correct answer.
",1 Introduction,[0],[0]
"Thanks to the automatic generation process, these datasets can be very large in size, leading to significant research progresses.",1 Introduction,[0],[0]
"However, compared to how humans would create cloze questions and evaluate reading comprehension ability, the automatic generation process bears some inevitable issues.",1 Introduction,[0],[0]
"Firstly, blanks are chosen uniformly without considering which aspect of the language phenomenon that questions will test.",1 Introduction,[0],[0]
"Hence, quite a portion of automatically-generated questions can be purposeless or even trivial to answer.",1 Introduction,[0],[0]
Another issue involves the ambiguity of answers.,1 Introduction,[0],[0]
"Given a context and a sentence with a blank, there can be multiple words that fit almost equally well into the blank.",1 Introduction,[0],[0]
"A possible solution is to include a candidate option set, as done by CBT, to get rid of the ambiguity.",1 Introduction,[0],[0]
"However, automatically generating the candidate option set can be problematic since it cannot guarantee the ambiguity is removed.",1 Introduction,[0],[0]
"More importantly, automaticallygenerated candidates can be totally irrelevant or simply grammatically unsuitable for the blank, resulting in again purposeless or trivial questions.
",1 Introduction,[0],[0]
"Probably due to these unsatisfactory issues, neural models have achieved comparable results to the human-level performance within a very short time (Chen et al., 2016; Dhingra et al., 2016; Seo et al., 2016).",1 Introduction,[0],[0]
"While there have been works trying to incorporate human design into cloze question generation (Zweig and Burges, 2011; Paperno et al., 2016), due to the expensive labeling process, the MSR Sentence Completion Challenge created by this effort has 1, 040 questions and the LAMBADA (Paperno et al., 2016) dataset has 10, 022 questions, limiting the possibility of developing powerful neural models on it.",1 Introduction,[0],[0]
"As a result of the small size, human-created questions are only used to compose development sets and test sets.",1 Introduction,[0],[0]
"Motivated by the aforementioned drawbacks, we propose CLOTH, a large-scale cloze test dataset collected from English exams.",1 Introduction,[0],[0]
Questions in the dataset are designed by middle-school and highschool teachers to prepare Chinese students for entrance exams.,1 Introduction,[0],[0]
"To design a cloze test, teachers firstly determine the words that can test students’ knowledge of vocabulary, reasoning or grammar; then replace those words with blanks and provide other three candidate options for each blank.",1 Introduction,[0],[0]
"If a question does not specifically test grammar usage, all of the candidate options would complete the sentence with correct grammar, leading to highly nuanced questions.",1 Introduction,[0],[0]
"As a result, human-created questions are usually harder and are a better assessment of language proficiency.",1 Introduction,[0],[0]
"A general cloze test evaluates several aspects of language proficiency including vocabulary, reasoning and grammar, which are key components of comprehending natural language.
",1 Introduction,[0],[0]
"To verify if human-created cloze questions are difficult for current models, we train and evaluate the state-of-the-art language model (LM) and machine comprehension models on this dataset, including a language model trained on the One Billion Word Corpus.",1 Introduction,[0],[0]
We find that the state-of-theart model lags behind human performance even if the model is trained on a large external corpus.,1 Introduction,[0],[0]
We analyze where the model fails compared to humans who perform well.,1 Introduction,[0],[0]
"After conducting error analysis, we assume the performance gap results from the model’s inability to use a long-term context.",1 Introduction,[0],[0]
"To examine this assumption, we evaluate human-level performance when the human subjects are only allowed to see one sentence as the context.",1 Introduction,[0],[0]
"Our assumption is confirmed by the
matched performances of the models and human when given only one sentence.",1 Introduction,[0],[0]
"In addition, we demonstrate that human-created data is more difficult than automatically-generated data.",1 Introduction,[0],[0]
"Specifically, it is much easier for the same model to perform well on automatically-generated data.
",1 Introduction,[0],[0]
We hope that CLOTH provides a valuable testbed for both the language modeling community and the machine comprehension community.,1 Introduction,[0],[0]
"Specifically, the language modeling community can use CLOTH to evaluate their models’ abilities in modeling long contexts, while the machine comprehension community can use CLOTH to test machine’s understanding of language phenomena.",1 Introduction,[0],[0]
"Large-scale automatically-generated cloze tests (Hermann et al., 2015; Hill et al., 2016; Onishi et al., 2016) lead to significant research advancements.",2 Related Work,[0],[0]
"However, generated questions do not consider language phenomenon to be tested and are relatively easy to solve.",2 Related Work,[0],[0]
"Recently proposed reading comprehension datasets are all labeled by humans to ensure a high quality (Rajpurkar et al., 2016; Joshi et al., 2017; Trischler et al., 2016; Nguyen et al., 2016).
",2 Related Work,[0],[0]
"Perhaps the closet work to CLOTH is the LAMBADA dataset (Paperno et al., 2016).",2 Related Work,[0],[0]
LAMBADA also targets at finding challenging words to test LM’s ability in comprehending a longer context.,2 Related Work,[0],[0]
"However, LAMBADA does not provide a candidate set for each question, which can cause ambiguities when multiple words can fit in.",2 Related Work,[0],[0]
"Furthermore, only test set and development set are labeled manually.",2 Related Work,[0],[0]
"The provided training set is the unlabeled Book Corpus (Zhu et al., 2015).",2 Related Work,[0],[0]
"Such unlabeled data do not emphasize long-dependency questions and have a mismatched distribution with the test set, as showed in Section 5.",2 Related Work,[0],[0]
"Further, the Book Corpus is too large to allow rapid algorithm development for researchers who do not have access to a huge amount of computational power.
",2 Related Work,[0],[0]
"Aiming to evaluate machines under the same conditions that the humans are evaluated, there is a growing interest in obtaining data from examinations.",2 Related Work,[0],[0]
"NTCIR QA Lab (Shibuki et al., 2014) contains a set of real-world college entrance exam questions.",2 Related Work,[0],[0]
"The Entrance Exams task at CLEF QA Track (Peñas et al., 2014; Rodrigo et al., 2015) evaluates machine’s reading comprehension abil-
ity.",2 Related Work,[0],[0]
"The AI2 Reasoning Challenge (Clark et al., 2018; Schoenick et al., 2017) contains approximately eight thousand scientific questions used in middle school.",2 Related Work,[0],[0]
Lai et al. (2017) proposes the first large-scale machine comprehension dataset obtained from exams.,2 Related Work,[0],[0]
They show that questions designed by teachers have a significantly larger proportion of reasoning questions.,2 Related Work,[0],[0]
Our dataset focuses on evaluating both language proficiency and reasoning abilities.,2 Related Work,[0],[0]
"In this section, we introduce the CLOTH dataset that is collected from English examinations, and study its abilities of assessment.",3 CLOTH Dataset,[0],[0]
We collect the raw data from three free and public websites in China that gather exams created by English teachers to prepare students for college/high school entrance exams3.,3.1 Data Collection and Statistics,[0],[0]
"Before cleaning, there are 20, 605 passages and 332, 755 questions.",3.1 Data Collection and Statistics,[0],[0]
We perform the following processes to ensure the validity of data:,3.1 Data Collection and Statistics,[0],[0]
"Firstly, we remove questions with an inconsistent format such as questions with more than four options.",3.1 Data Collection and Statistics,[0],[0]
Then we filter all questions whose validity relies on external information such as pictures or tables.,3.1 Data Collection and Statistics,[0],[0]
"Further, we find that half of the total passages are duplicates and we delete those passages.",3.1 Data Collection and Statistics,[0],[0]
"Lastly, on one of the websites, the answers are stored as images.",3.1 Data Collection and Statistics,[0],[0]
We use two OCR software programs4 to extract the answers from images.,3.1 Data Collection and Statistics,[0],[0]
We discard the questions when results from the two software are different.,3.1 Data Collection and Statistics,[0],[0]
"After the cleaning process, we obtain a clean dataset of 7, 131 passages and 99, 433 questions.
",3.1 Data Collection and Statistics,[0],[0]
"Since high school questions are more difficult than middle school questions, we divide the datasets into CLOTH-M and CLOTH-H, which stand for the middle school part and the high school part.",3.1 Data Collection and Statistics,[0],[0]
We split 11% of the data for both the test set and the development set.,3.1 Data Collection and Statistics,[0],[0]
The detailed statistics of the whole dataset and two subsets are presented in Table 1.,3.1 Data Collection and Statistics,[0],[0]
"Note that the questions were created to test non-native speakers, hence the vocabulary size is not very large.
",3.1 Data Collection and Statistics,[0],[0]
"3 The three websites include http://www.21cnjy.com/; http://5utk.ks5u.com/; http://zujuan.xkw.com/. We checked that CLOTH does not contain sentence completion example questions from GRE, SAT and PSAT.
4tesseract: https://github.com/tesseract-ocr; ABBYY FineReader: https://www.abbyy.com/en-us/finereader/",3.1 Data Collection and Statistics,[0],[0]
"In order to evaluate students’ mastery of a language, teachers usually design tests in a way that questions cover different aspects of a language.",3.2 Question Type Analysis,[0],[0]
"Specifically, they first identify words in the passage that can examine students’ knowledge in vocabulary, logic, or grammar.",3.2 Question Type Analysis,[0],[0]
"Then, they replace the words with blanks and prepare three incorrect but nuanced candidate options to make the test non-trivial.",3.2 Question Type Analysis,[0],[0]
"A sample passage is presented in Table 2.
",3.2 Question Type Analysis,[0],[0]
"To understand the abilities of assessment on this dataset, we divide questions into several types and label the proportion of each type.",3.2 Question Type Analysis,[0],[0]
"According to English teachers who regularly create cloze test questions for English exams in China, there are largely three types: grammar, vocabulary and reasoning.",3.2 Question Type Analysis,[0],[0]
Grammar questions are easily differentiated from other two categories.,3.2 Question Type Analysis,[0],[0]
"However, the teachers themselves cannot specify a clear distinction between reasoning questions and vocabulary questions since all questions require comprehending the words within the context and conducting some level of reasoning by recognizing incomplete information or conceptual overlap.
",3.2 Question Type Analysis,[0],[0]
"Hence, we divided the questions except grammar questions based on the difficulty level for a machine to answer the question, following works on analyzing machine comprehension datasets (Chen et al., 2016; Trischler et al., 2016).",3.2 Question Type Analysis,[0],[0]
"In particular, we divide them in terms of their dependency ranges, since questions that only involve a single sentence are easier to answer than questions involving evidence distributed in multiple sentences.",3.2 Question Type Analysis,[0],[0]
"Further, we divided questions involving long-term dependency into matching/paraphrasing questions and reasoning questions since matching questions are easier.",3.2 Question Type Analysis,[0],[0]
"The four types include:
• Grammar: The question is about grammar usage, involving tense, preposition usage, active/passive voices, subjunctive mood and so on.
",3.2 Question Type Analysis,[0],[0]
• Short-term-reasoning: The question is about content words and can be answered based on the information within the same sentence.,3.2 Question Type Analysis,[0],[0]
"Note that the content words can evaluate knowledge of both vocabulary and reasoning.
",3.2 Question Type Analysis,[0],[0]
• Matching/paraphrasing:,3.2 Question Type Analysis,[0],[0]
"The question is answered by copying/paraphrasing a word in the context.
",3.2 Question Type Analysis,[0],[0]
"• Long-term-reasoning: The answer must be inferred from synthesizing information distributed across multiple sentences.
",3.2 Question Type Analysis,[0],[0]
"We sample 100 passages in the high school category and the middle school category respectively with totally 3, 000 questions.",3.2 Question Type Analysis,[0],[0]
The types of these questions are labeled on Amazon Turk.,3.2 Question Type Analysis,[0],[0]
We pay $1 and $0.5 for high school passages and middle school passages respectively.,3.2 Question Type Analysis,[0],[0]
"We refer readers to Appendix A.1 for details of the labeling processes and the labeled sample passage.
",3.2 Question Type Analysis,[0],[0]
The proportion of different questions is shown in Table 3.,3.2 Question Type Analysis,[0],[0]
"The majority of questions are shortterm-reasoning questions while approximately 22.4% of the data needs long-term information, in which the long-term-reasoning questions constitute a large proportion.",3.2 Question Type Analysis,[0],[0]
"In this section, we investigate if human-created cloze test is a challenging problem for state-ofthe-art models.",4 Exploring Models’ Limits,[0],[0]
We find that LM trained on the One Billion Word Corpus can achieve a remarkable score but cannot solve the cloze test.,4 Exploring Models’ Limits,[0],[0]
"After conducting an error analysis, we hypothesize that the model is not able to deal with long-term dependencies.",4 Exploring Models’ Limits,[0],[0]
We verify the hypothesis by comparing the model’s performance with the human performance when the information humans obtain is limited to one sentence.,4 Exploring Models’ Limits,[0],[0]
"LSTM To test the performance of RNN-based supervised models, we train a bidirectional LSTM (Hochreiter and Schmidhuber, 1997) to predict the missing word given the context with only labeled data.",4.1 Human and Model Performance,[0],[0]
"The implementation details are in Appendix A.3.
",4.1 Human and Model Performance,[0],[0]
"Attentive Readers To enable the model to gather information from a longer context, we aug-
ment the supervised LSTM model with the attention mechanism (Bahdanau et al., 2014), so that the representation at the blank is used as a query to find the relevant context in the document and a blank-specific representation of the document is used to score each candidate answer.",4.1 Human and Model Performance,[0],[0]
"Specifically, we adapt the Stanford Attentive Reader (Chen et al., 2016) and the positionaware attention model (Zhang et al., 2017) to the cloze test problem.",4.1 Human and Model Performance,[0],[0]
"With the position-aware attention model, the attention scores are based on both the context match and the distance from a context to the blank.",4.1 Human and Model Performance,[0],[0]
"Both attention models are trained only with human-created blanks just as the LSTM model.
",4.1 Human and Model Performance,[0],[0]
LM,4.1 Human and Model Performance,[0],[0]
"In cloze test, the context on both sides may be enough to determine the correct answer.",4.1 Human and Model Performance,[0],[0]
"Suppose xi is the missing word and x1, · · · , xi−1, xi+1, · · · , xn are the context, we choose xi that maximizes the joint probability p(x1, · · · , xn), which essentially maximizes the conditional likelihood p(xi | x1, · · · , xi−1, xi+1, · · · , xn).",4.1 Human and Model Performance,[0],[0]
"Therefore, LM can be naturally adapted to cloze test.
",4.1 Human and Model Performance,[0],[0]
"In essence, LM treats each word as a possible blank and learns to predict it.",4.1 Human and Model Performance,[0],[0]
"As a result, it receives more supervision than the LSTM trained on human-labeled questions.",4.1 Human and Model Performance,[0],[0]
"Besides training a neural LM on our dataset, interested in whether the state-of-the-art LM can solve cloze test, we also test the LM trained on the One Billion Word Benchmark (Chelba et al., 2013) (referred as 1BLM) that achieves a perplexity of 30.0 (Jozefowicz et al., 2016)5.",4.1 Human and Model Performance,[0],[0]
"To make the evaluation time tractable, we limit the context length to one sentence or three sentences.",4.1 Human and Model Performance,[0],[0]
"Note that the One Billion Word Corpus does not overlap with the CLOTH
5The pre-trained model is obtained from https://github.com/tensorflow/models/tree/master/research/ lm 1b
Passage: Nancy had just got a job as a secretary in a company.",4.1 Human and Model Performance,[0],[0]
"Monday was the first day she went to work, so she was very 1 and arrived early.",4.1 Human and Model Performance,[0],[0]
She 2 the door open and found nobody there.,4.1 Human and Model Performance,[0],[0]
”I am the 3 to arrive.”,4.1 Human and Model Performance,[0],[0]
She thought and came to her desk.,4.1 Human and Model Performance,[0],[0]
She was surprised to find a bunch of 4 on it.,4.1 Human and Model Performance,[0],[0]
They were fresh.,4.1 Human and Model Performance,[0],[0]
She 5 them and they were sweet.,4.1 Human and Model Performance,[0],[0]
She looked around for a 6 to put them in.,4.1 Human and Model Performance,[0],[0]
”Somebody has sent me flowers the very first day!”,4.1 Human and Model Performance,[0],[0]
she thought 7 . ”,4.1 Human and Model Performance,[0],[0]
But who could it be?”,4.1 Human and Model Performance,[0],[0]
she began to 8 .,4.1 Human and Model Performance,[0],[0]
The day passed quickly and Nancy did everything with 9 interest.,4.1 Human and Model Performance,[0],[0]
"For the following days of the 10 , the first thing Nancy did was to change water for the followers and then set about her work.",4.1 Human and Model Performance,[0],[0]
Then came another Monday.,4.1 Human and Model Performance,[0],[0]
11,4.1 Human and Model Performance,[0],[0]
she came near her desk she was overjoyed to see a(n) 12 bunch of flowers there.,4.1 Human and Model Performance,[0],[0]
"She quickly put them in the vase, 13 the old ones.",4.1 Human and Model Performance,[0],[0]
The same thing happened again the next Monday.,4.1 Human and Model Performance,[0],[0]
Nancy began to think of ways to find out the 14 .,4.1 Human and Model Performance,[0],[0]
"On Tuesday afternoon, she was sent to hand in a plan to the 15 .",4.1 Human and Model Performance,[0],[0]
She waited for his directives at his secretary’s 16 .,4.1 Human and Model Performance,[0],[0]
"She happened to see on the desk a half-opened notebook, which 17 : ”In order to keep the secretaries in high spirits, the company has decided that every Monday morning a bunch of fresh flowers should be put on each secretarys desk.”",4.1 Human and Model Performance,[0],[0]
"Later, she was told that their general manager was a business management psychologist.
corpus.
Human performance We measure the performance of Amazon Mechanical Turkers on 3, 000 sampled questions when the whole passage is given.
",4.1 Human and Model Performance,[0],[0]
Results The comparison is shown in Table 4.,4.1 Human and Model Performance,[0],[0]
Both attentive readers achieve similar accuracy to the LSTM.,4.1 Human and Model Performance,[0],[0]
We hypothesize that the reason of the attention model’s unsatisfactory performance is that the evidence of a question cannot be simply found by matching the context.,4.1 Human and Model Performance,[0],[0]
"Similarly, on reading comprehension, though attention-based models (Wang et al., 2017; Seo et al., 2016; Dhingra
et al., 2016) have reached human performance on the SQuAD dataset (Rajpurkar et al., 2016), their performance is still not comparable to human performance on datasets that focus more on reasoning where the evidence cannot be simply found by a matching behavior (Lai et al., 2017; Xu et al., 2017).",4.1 Human and Model Performance,[0],[0]
"Since the focus of this paper is to analyze the proposed dataset, we leave the design of reasoning oriented attention models for future work.
",4.1 Human and Model Performance,[0],[0]
The LM achieves much better performance than LSTM.,4.1 Human and Model Performance,[0],[0]
"The gap is larger when the LM is trained on the 1 Billion Word Corpus, indicating that more training data results in a better generalization.",4.1 Human and Model Performance,[0],[0]
"Specifically, the accuracy of 1B-LM is 0.695 when one sentence is used as the context.",4.1 Human and Model Performance,[0],[0]
It indicates that LM can learn sophisticated language regularities when given sufficient data.,4.1 Human and Model Performance,[0],[0]
"The same conclusion can also be drawn from the success of a concurrent work ELMo which uses LM representations as word vectors and achieves state-ofthe-art results on six language tasks (Peters et al.,
2018).",4.1 Human and Model Performance,[0],[0]
"However, if we increase the context length to three sentences, the accuracy of 1B-LM only has a marginal improvement.",4.1 Human and Model Performance,[0],[0]
"In contrast, humans outperform 1B-LM by a significant margin, which demonstrates that deliberately designed questions in CLOTH are not completely solved even for state-of-the-art models.",4.1 Human and Model Performance,[0],[0]
"In this section, we would like to understand why 1B-LM lags behind human performance.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
We find that most of the errors involve long-term reasoning.,4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"Additionally, in a lot of cases, the dependency is within the context of three sentences.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
We show several errors made by the 1B-LM in Table 5.,4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"In the first example, the model does not know that Nancy found nobody in the company means that Nancy was the first one to arrive at the company.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"In the second and third example, the model fails probably because of not recognizing “they” referred to “flowers”.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
The dependency in the last case is longer.,4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"It depends on the fact that Nancy was alone in the company.
",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"Based on the case study, we hypothesize that the LM is not able to take long-term information into account, although it achieves a surprisingly good overall performance.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"Additionally, the 1BLM is trained on the sentence level, which might also result in the inability to track paragraph level information.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"However, to investigate the differences between training on sentence level and on paragraph level, a prohibitive amount of computational resource is required to train a large model on the 1 Billion Word Corpus.
",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"On the other hand, a practical comparison is to test the model’s performance on different types of questions.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"We find that the model’s accuracy is 0.591 on long-term-reasoning questions of CLOTH-H while it achieves 0.693 on short-termreasoning (a comprehensive type-specific performance is available in Appendix A.3), which partially confirms that long-term-reasoning is harder.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"However, we could not completely rely on the performance on specific questions types, partly due to a large variance caused by the small sample size.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
Another reason is that the reliability of question type labels depends on whether turkers are careful enough.,4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"For example, in the error analysis shown in Table 5, a careless turker would label the second example as short-term-reasoning without noticing
that the meaning of “they” relies on a long context.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"To objectively verify if the LM’s strengths lie in dealing with short-term information, we obtain the ceiling performance of only utilizing shortterm information.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"Showing only one sentence as the context, we ask the Turkers to select an option based on their best guesses given the insufficient information.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"By limiting the context span manually, the ceiling performance with the access to only a short context is estimated accurately.
",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"As shown in Table 6, The performance of 1BLM using one sentence as the context can almost match the human ceiling performance of only using short-term information.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
Hence we conclude that the LM can almost perfectly solve all shortterm cloze questions.,4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"However, the performance of LM is not improved significantly when a longterm context is given, indicating that the performance gap is due to the inability of long-term reasoning.",4.2 Analyzing 1B-LM’s Strengths and Weaknesses,[0],[0]
"In this section, we demonstrate that humancreated data is a better testbed than automaticallygenerated cloze test since it results in a larger gap between model’s performance and human performance.
",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
A casual observation is that a cloze test can be created by randomly deleting words and randomly sampling candidate options.,5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"In fact, to generate large-scale data, similar generation processes have been introduced and widely used in machine comprehension (Hermann et al., 2015; Hill et al., 2016; Onishi et al., 2016).",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"However, research on cloze test design (Sachs et al., 1997) shows that tests created by deliberately deleting words are more reliable than tests created by randomly or periodically deleting words.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"To design accurate language proficiency assessment, teachers usually deliberately select words in order to examine students’ proficiency in grammar, vocabulary and reasoning.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"Moreover, in order to make the question non-trivial, three incorrect options provided by teachers are usually grammatically correct and relevant to the context.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"For instance, in the fourth problem of the sample passage shown in Table 2, “grapes”, “flowers” and “bananas” all fit the description of being fresh.
",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"Hence we naturally hypothesize that humangenerated data has distinct characteristics when
compared with automatically-generated data.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"To verify this assumption, we compare the LSTM model’s performance when given different proportions of the two types of data.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"Specifically, to train a model with α percent of automatically-generated data, we randomly replace a percent blanks with blanks at random positions, while keeping the remaining 1 − α percent questions the same.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
The candidate options for the generated blanks are random words sampled from the unigram distribution.,5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"We test models obtained with varying α on human-created data and automatically-generated data respectively.
",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"From the comparison in Table 7, we have the following observations: (1) human-created data leads to a larger gap between model’s performance and the ceiling/human performance.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"The model’s performance and human’s performance
on the human-created data are 0.484 and 0.859 respectively, as shown in Tab. 4, leading to a gap of 0.376.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"In comparison, the performance gap on the automatically-generated data is at most 0.185 since the model’s performance reaches an accuracy of 0.815 when fully trained on generated data.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"(2) Although human-created data may provide more information in distinguishing similar words, the distributional mismatch between two types of data makes it non-trivial to transfer the knowledge gained from human-created data to tackle automatically-generated data.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"Specifically, the model’s performance on automatically-generated data monotonically decreases when given a higher ratio of human-created data.",5 Comparing Human-created Data and Automatically-generated Data,[0],[0]
"In Section 4.1, we show that LM is able to take advantage of more supervision since it predicts each word based on the context.",6 Combining Human-created Data with Automatically-generated Data,[0],[0]
"At the same time, we also show that human-created data and the automatically-generated data are quite different in Section 5.",6 Combining Human-created Data with Automatically-generated Data,[0],[0]
"In this section, we propose a model that takes advantage of both sources.",6 Combining Human-created Data with Automatically-generated Data,[0],[0]
"Specifically, for each question, regardless of being human-created or automatically-generated, we can compute the negative log likelihood of the correct answer as the loss function.",6.1 Representative-based Model,[0],[0]
"Suppose JH is the average negative log likelihood loss for human-created questions and JR is the loss function on generated questions, we combine losses on human-created questions and generated questions by simply adding them together, i.e., JR + JH is used as the final loss function.",6.1 Representative-based Model,[0],[0]
"We will introduce the definition of JR in the following paragraphs.
",6.1 Representative-based Model,[0],[0]
"Although automatically-generated data has a
large quantity and is valuable to the model training, as shown in the previous Section, automatically-generated questions are quite different from human-created questions.",6.1 Representative-based Model,[0],[0]
"Ideally, a large amount of human-created questions is more desirable than a large amount of automaticallygenerated questions.",6.1 Representative-based Model,[0],[0]
A possible avenue towards having large-scale human-created data is to automatically pick out a large number of generated questions which are representative of or similar to human-created questions.,6.1 Representative-based Model,[0],[0]
"In other words, we train a network to predict whether a question is a generated question or a human-created question.",6.1 Representative-based Model,[0],[0]
A generated question is representative of human-created questions if it has a high probability of being a human-created question.,6.1 Representative-based Model,[0],[0]
"Then we can give higher weights to questions that resemble human-created question.
",6.1 Representative-based Model,[0],[0]
We first introduce our method to obtain the representativeness information.,6.1 Representative-based Model,[0],[0]
"Let x denote the passage and z denote whether a word is selected as a question by human, i.e., z is 1 if this word is selected to be filled in the original passage or 0 otherwise.",6.1 Representative-based Model,[0],[0]
Suppose hi is the representation of i-th word given by a bidirectional LSTM.,6.1 Representative-based Model,[0],[0]
"The network computes the probability pi of xi being a humancreated question as follows:
",6.1 Representative-based Model,[0],[0]
li = h T,6.1 Representative-based Model,[0],[0]
"i wxi ; pi = Sigmoid(li)
where li is the logit which will be used as in the final model and wxi is the the word embedding.",6.1 Representative-based Model,[0],[0]
"We train the network to minimize the binary cross entropy between p and ground-truth labels at each token.
",6.1 Representative-based Model,[0],[0]
"After obtaining the representativeness information, we define the representativeness weighted loss function as
JR = ∑ i 6∈H Softmaxi( l1 α , · · · , ln α )",6.1 Representative-based Model,[0],[0]
"Ji
where Ji denotes the negative log likelihood loss for the i−th question and let li be the output representativeness of the i-th question and H is the set of all human-generated questions and α is the temperature of the Softmax function.",6.1 Representative-based Model,[0],[0]
The model degenerates into assigning a uniform weight to all questions when the temperature is +∞. We set α to 2 based on the performance on the dev set.,6.1 Representative-based Model,[0],[0]
"6.
6The code is available at https://github.com/qizhex/Largescale-Cloze-Test-Dataset-Created-by-Teachers",6.1 Representative-based Model,[0],[0]
We summarize performances of all models in Table 8.,6.2 Results,[0],[0]
"Our representativeness model outperforms all other models that do not use external data on CLOTH, CLOTH-H and CLOTH-M.",6.2 Results,[0],[0]
"In this section, we verify the effectiveness of the representativeness-based averaging by ablation studies.",6.3 Analysis,[0],[0]
"When we remove the representativeness information by setting α to infinity, the accuracy drops from 0.583 to 0.566.",6.3 Analysis,[0],[0]
"When we further remove the human-created data so that only generated data is employed, the accuracy drops to 0.543, similar to the performance of LM.",6.3 Analysis,[0],[0]
"The results further confirm that it is beneficial to incorporate human-created questions into training.
",6.3 Analysis,[0],[0]
A sample of the predicted representativeness is shown in Figure 17.,6.3 Analysis,[0],[0]
"Clearly, words that are too obvious have low scores, such as punctuation marks, simple words “a” and “the”.",6.3 Analysis,[0],[0]
"In contrast, content words whose semantics are directly related to the context have a higher score, e.g., “same”, “similar”, “difference” have a high score when the difference between two objects is discussed and “secrets” has a high score since it is related to the subsequent sentence “does not want to share with others”.",6.3 Analysis,[0],[0]
"Our prediction model achieves an F1 score of 36.5 on the test set, which is understandable since
7The script to generate the Figure is obtained at https://gist.github.com/ihsgnef/ f13c35cd46624c8f458a4d23589ac768
there are many plausible questions within a passage.
",6.3 Analysis,[0],[0]
"It has been shown that features such as morphology information and readability are beneficial in cloze test prediction (Skory and Eskenazi, 2010; Correia et al., 2012, 2010; Kurtasov, 2013).",6.3 Analysis,[0],[0]
We leave investigating the advanced approaches of automatically designing cloze test to future work.,6.3 Analysis,[0],[0]
"In this paper, we propose a large-scale cloze test dataset CLOTH that is designed by teachers.",7 Conclusion and Discussion,[0],[0]
"With missing blanks and candidate options carefully created by teachers to test different aspects of language phenomena, CLOTH requires a deep language understanding and better captures the complexity of human language.",7 Conclusion and Discussion,[0],[0]
We find that human outperforms 1B-LM by a significant margin.,7 Conclusion and Discussion,[0],[0]
"After detailed analysis, we find that the performance gap is due to the model’s inability to understanding a long context.",7 Conclusion and Discussion,[0],[0]
"We also show that, compared to automatically-generated questions, human-created questions are more difficult and lead to a larger margin between human performance and the model’s performance.
",7 Conclusion and Discussion,[0],[0]
"Despite the excellent performance of 1B-LM when compared with models trained only on CLOTH, it is still important to investigate and create more effective models and algorithms which provide complementary advantages to having a large amount of data.",7 Conclusion and Discussion,[0],[0]
"For rapid algorithm developments, we suggest training models only on the training set of CLOTH and comparing with models that do not utilize external data.
",7 Conclusion and Discussion,[0],[0]
We hope our dataset provides a valuable testbed to the language modeling community and the machine comprehension community.,7 Conclusion and Discussion,[0],[0]
"In particular, the language modeling community can use
CLOTH to evaluate their models’ abilities in modeling a long context.",7 Conclusion and Discussion,[0],[0]
"In addition, the machine comprehension community may also find CLOTH useful in evaluating machine’s understanding of language phenomena including vocabulary, reasoning and grammar, which are key components of comprehending natural language.
",7 Conclusion and Discussion,[0],[0]
"In our future work, we would like to design algorithms to better model a long context, to utilize external knowledge, and to explore more effective semi-supervised learning approaches.",7 Conclusion and Discussion,[0],[0]
"Firstly, we would like to investigate efficient ways of utilizing external knowledge such as paraphrasing and semantic concepts like prior works (Dong et al., 2017; Dasigi et al., 2017).",7 Conclusion and Discussion,[0],[0]
"In comparison, training on a large external dataset is actually a time-consuming way of utilizing external knowledge.",7 Conclusion and Discussion,[0],[0]
"Secondly, to use the generated questions more effectively, the representative-based semisupervised approach might be improved by techniques studied in active learning and hard example mining (Settles, 2009; Shrivastava et al., 2016; Chang et al., 2017).",7 Conclusion and Discussion,[0],[0]
"We thank Yulun Du, Kaiyu Shi and Zhilin Yang for insightful discussions and suggestions on the draft.",Acknowledgement,[0],[0]
We thank Shi Feng for the script to highlight representative words.,Acknowledgement,[0],[0]
This research was supported in part by DARPA grant FA8750-12-20342 funded under the DEFT program.,Acknowledgement,[0],[0]
"A.1 Question Type Labeling To label the questions, we provided the definition and an example for each question category to the Amazon Mechanical Turkers.",A Appendix,[0],[0]
"To ensure quality, we limited the workers to master Turkers who are experienced and maintain a high acceptance rate.",A Appendix,[0],[0]
"However, we did not restrict the backgrounds of the Turkers since master Turkers should have a reasonable amount of knowledge about English to conduct previous tasks.",A Appendix,[0],[0]
"In addition, the vocabulary used in CLOTH are usually not difficult since they are constructed to test non-native speakers in middle school or high school.",A Appendix,[0],[0]
"To get a concrete idea of the nature of question types, please refer to examples shown in Tab. 10.
",A Appendix,[0],[0]
A.2 Type-specific Performance Analysis We can also further verify the strengths and weaknesses of the 1B-LM by studying the performance of models and human on different question categories.,A Appendix,[0],[0]
Note that the performance presented here may be subject to a high variance due to the limited number of samples in each category.,A Appendix,[0],[0]
"From the comparison shown in Figure 2, we see that 1B-LM is indeed good at short-term questions.",A Appendix,[0],[0]
"Specifically, when the human only has access to the context of one sentence, 1B-LM is close to human’s performance on almost all categories.",A Appendix,[0],[0]
"Further, comparing LM and 1B-LM, we find that training on the large corpus leads to improvements on all categories, showing that training on a large amount of data leads to a substantial improvement in learning complex language regularities.
",A Appendix,[0],[0]
A.3 Implementation Details,A Appendix,[0],[0]
"We implement our models using PyTorch (Paszke et al., 2017).",A Appendix,[0],[0]
We train our model on all questions in CLOTH and test it on CLOTH-M and CLOTH-H separately.,A Appendix,[0],[0]
"For our final model, we use Adam (Kingma and Ba, 2014) with the learning rate of 0.001.",A Appendix,[0],[0]
"The hidden dimension is set to 650 and we initialize the word embedding by 300-dimensional Glove word vector (Pennington et al., 2014).",A Appendix,[0],[0]
The temperature α is set to 2.,A Appendix,[0],[0]
"We tried to increase the dimensionality of the model but do not observe performance improvement.
",A Appendix,[0],[0]
"When we train the small LM on CLOTH, we largely follow the recommended hyperparameters in the Pytorch LM example8.",A Appendix,[0],[0]
"Specifically, we employ a 2-layer LSTM with hidden dimension as 1024.",A Appendix,[0],[0]
The input embedding and output weight matrix are tied.,A Appendix,[0],[0]
We set the dropout rate to 0.5.,A Appendix,[0],[0]
"The initial learning rate is set to 10 and divided by 4 whenever the PPL stops improving on the dev set.
",A Appendix,[0],[0]
"We predict the answer for each blank independently for all of the models mentioned in this paper, since we do not observe significant performance improvements in our preliminary experiments when an auto-regressive approach is employed, i.e., when we fill all previous blanks with predicted answers.",A Appendix,[0],[0]
"We hypothesize that, regardless of whether there exist inter-blank dependencies, since blanks are usually
8https://github.com/pytorch/examples/tree/master/word language model
distributed far away from each other, LSTM is not able to capture such long dependencies.",A Appendix,[0],[0]
"When testing language models, we use the longest text spans that do not contain blanks.",A Appendix,[0],[0]
Cloze tests are widely adopted in language exams to evaluate students’ language proficiency.,abstractText,[0],[0]
"In this paper, we propose the first large-scale human-created cloze test dataset CLOTH 1 2, containing questions used in middle-school and high-school language exams.",abstractText,[0],[0]
"With missing blanks carefully created by teachers and candidate choices purposely designed to be nuanced, CLOTH requires a deeper language understanding and a wider attention span than previously automaticallygenerated cloze datasets.",abstractText,[0],[0]
We test the performance of dedicatedly designed baseline models including a language model trained on the One Billion Word Corpus and show humans outperform them by a significant margin.,abstractText,[0],[0]
"We investigate the source of the performance gap, trace model deficiencies to some distinct properties of CLOTH, and identify the limited ability of comprehending the long-term context to be the key bottleneck.",abstractText,[0],[0]
Large-scale Cloze Test Dataset Created by Teachers,title,[0],[0]
"Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016; Wu et al., 2016).",1. Introduction,[0],[0]
"Discovering neural network architectures, however, remains a laborious task.",1. Introduction,[0],[0]
"Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al. (2015); He et al. (2016); Huang et al. (2016a), among many others).
",1. Introduction,[0],[0]
"1Google Brain, Mountain View, California, USA 2Google Research, Mountain View, California, USA.",1. Introduction,[0],[0]
"Correspondence to: Esteban Real <ereal@google.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"It is therefore not surprising that in recent years, techniques to automatically discover these architectures have been gaining popularity (Bergstra & Bengio, 2012; Snoek et al., 2012; Han et al., 2015; Baker et al., 2016; Zoph & Le, 2016).",1. Introduction,[0],[0]
"One of the earliest such “neuro-discovery” methods was neuro-evolution (Miller et al., 1989; Stanley & Miikkulainen, 2002; Stanley, 2007; Bayer et al., 2009; Stanley et al., 2009; Breuel & Shafait, 2010; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Zaremba, 2015; Fernando et al., 2016; Morse & Stanley, 2016).",1. Introduction,[0],[0]
"Despite the promising results, the deep learning community generally perceives evolutionary algorithms to be incapable of matching the accuracies of hand-designed models (Verbancsics & Harguess, 2013; Baker et al., 2016; Zoph & Le, 2016).",1. Introduction,[0],[0]
"In this paper, we show that it is possible to evolve such competitive models today, given enough computational power.
",1. Introduction,[0],[0]
"We used slightly-modified known evolutionary algorithms and scaled up the computation to unprecedented levels, as far as we know.",1. Introduction,[0],[0]
"This, together with a set of novel and intuitive mutation operators, allowed us to reach competitive accuracies on the CIFAR-10 dataset.",1. Introduction,[0],[0]
"This dataset was chosen because it requires large networks to reach high accuracies, thus presenting a computational challenge.",1. Introduction,[0],[0]
We also took a small first step toward generalization and evolved networks on the CIFAR-100 dataset.,1. Introduction,[0],[0]
"In transitioning from CIFAR-10 to CIFAR-100, we did not modify any aspect or parameter of our algorithm.",1. Introduction,[0],[0]
"Our typical neuro-evolution outcome on CIFAR-10 had a test accuracy with µ = 94.1%, σ = 0.4% @ 9×1019 FLOPs, and our top model (by validation accuracy) had a test accuracy of 94.6% @ 4×1020 FLOPs.",1. Introduction,[0],[0]
"Ensembling the validation-top 2 models from each population reaches a test accuracy of 95.6%, at no additional training cost.",1. Introduction,[0],[0]
"On CIFAR-100, our single experiment resulted in a test accuracy of 77.0% @ 2×1020 FLOPs.",1. Introduction,[0],[0]
"As far as we know, these are the most accurate results obtained on these datasets by automated discovery methods that start from trivial initial conditions.
",1. Introduction,[0],[0]
"Throughout this study, we placed special emphasis on the simplicity of the algorithm.",1. Introduction,[0],[0]
"In particular, it is a “oneshot” technique, producing a fully trained neural network requiring no post-processing.",1. Introduction,[0],[0]
It also has few impactful meta-parameters (i.e. parameters not optimized by the algorithm).,1. Introduction,[0],[0]
"Starting out with poor-performing models with
no convolutions, the algorithm must evolve complex convolutional neural networks while navigating a fairly unrestricted search space: no fixed depth, arbitrary skip connections, and numerical parameters that have few restrictions on the values they can take.",1. Introduction,[0],[0]
We also paid close attention to result reporting.,1. Introduction,[0],[0]
"Namely, we present the variability in our results in addition to the top value, we account for researcher degrees of freedom (Simmons et al., 2011), we study the dependence on the meta-parameters, and we disclose the amount of computation necessary to reach the main results.",1. Introduction,[0],[0]
We are hopeful that our explicit discussion of computation cost could spark more study of efficient model search and training.,1. Introduction,[0],[0]
Studying model performance normalized by computational investment allows consideration of economic concepts like opportunity cost.,1. Introduction,[0],[0]
"Neuro-evolution dates back many years (Miller et al., 1989), originally being used only to evolve the weights of a fixed architecture.",2. Related Work,[0],[0]
Stanley & Miikkulainen (2002) showed that it was advantageous to simultaneously evolve the architecture using the NEAT algorithm.,2. Related Work,[0],[0]
"NEAT has three kinds of mutations: (i) modify a weight, (ii) add a connection between existing nodes, or (iii) insert a node while splitting an existing connection.",2. Related Work,[0],[0]
"It also has a mechanism for recombining two models into one and a strategy to promote diversity known as fitness sharing (Goldberg et al., 1987).",2. Related Work,[0],[0]
Evolutionary algorithms represent the models using an encoding that is convenient for their purpose— analogous to nature’s DNA.,2. Related Work,[0],[0]
NEAT uses a direct encoding: every node and every connection is stored in the DNA.,2. Related Work,[0],[0]
"The alternative paradigm, indirect encoding, has been the subject of much neuro-evolution research (Gruau, 1993; Stanley et al., 2009; Pugh & Stanley, 2013; Kim & Rigazio,
2015; Fernando et al., 2016).",2. Related Work,[0],[0]
"For example, the CPPN (Stanley, 2007; Stanley et al., 2009) allows for the evolution of repeating features at different scales.",2. Related Work,[0],[0]
"Also, Kim & Rigazio (2015) use an indirect encoding to improve the convolution filters in an initially highly-optimized fixed architecture.
",2. Related Work,[0],[0]
"Research on weight evolution is still ongoing (Morse & Stanley, 2016) but the broader machine learning community defaults to back-propagation for optimizing neural network weights (Rumelhart et al., 1988).",2. Related Work,[0],[0]
"Back-propagation and evolution can be combined as in Stanley et al. (2009), where only the structure is evolved.",2. Related Work,[0],[0]
Their algorithm follows an alternation of architectural mutations and weight back-propagation.,2. Related Work,[0],[0]
"Similarly, Breuel & Shafait (2010) use this approach for hyper-parameter search.",2. Related Work,[0],[0]
"Fernando et al. (2016) also use back-propagation, allowing the trained weights to be inherited through the structural modifications.
",2. Related Work,[0],[0]
"The above studies create neural networks that are small in comparison to the typical modern architectures used for image classification (He et al., 2016; Huang et al., 2016a).",2. Related Work,[0],[0]
"Their focus is on the encoding or the efficiency of the evolutionary process, but not on the scale.",2. Related Work,[0],[0]
"When it comes to images, some neuro-evolution results reach the computational scale required to succeed on the MNIST dataset (LeCun et al., 1998).",2. Related Work,[0],[0]
"Yet, modern classifiers are often tested on realistic images, such as those in the CIFAR datasets (Krizhevsky & Hinton, 2009), which are much more challenging.",2. Related Work,[0],[0]
"These datasets require large models to achieve high accuracy.
",2. Related Work,[0],[0]
Non-evolutionary neuro-discovery methods have been more successful at tackling realistic image data.,2. Related Work,[0],[0]
"Snoek et al. (2012) used Bayesian optimization to tune 9 hyper-parameters for a fixed-depth architecture, reach-
ing a new state of the art at the time.",2. Related Work,[0],[0]
Zoph & Le (2016) used reinforcement learning on a deeper fixed-length architecture.,2. Related Work,[0],[0]
"In their approach, a neural network—the “discoverer”—constructs a convolutional neural network—the “discovered”—one layer at a time.",2. Related Work,[0],[0]
"In addition to tuning layer parameters, they add and remove skip connections.",2. Related Work,[0],[0]
"This, together with some manual postprocessing, gets them very close to the (current) state of the art.",2. Related Work,[0],[0]
"(Additionally, they surpassed the state of the art on a sequence-to-sequence problem.)",2. Related Work,[0],[0]
"Baker et al. (2016) use Q-learning to also discover a network one layer at a time, but in their approach, the number of layers is decided by the discoverer.",2. Related Work,[0],[0]
"This is a desirable feature, as it would allow a system to construct shallow or deep solutions, as may be the requirements of the dataset at hand.",2. Related Work,[0],[0]
Different datasets would not require specially tuning the algorithm.,2. Related Work,[0],[0]
"Comparisons among these methods are difficult because they explore very different search spaces and have very different initial conditions (Table 2).
",2. Related Work,[0],[0]
"Tangentially, there has also been neuro-evolution work on LSTM structure (Bayer et al., 2009; Zaremba, 2015), but this is beyond the scope of this paper.",2. Related Work,[0],[0]
"Also related to this work is that of Saxena & Verbeek (2016), who embed convolutions with different parameters into a species of “supernetwork” with many parallel paths.",2. Related Work,[0],[0]
Their algorithm then selects and ensembles paths in the super-network.,2. Related Work,[0],[0]
"Finally, canonical approaches to hyper-parameter search are grid search (used in Zagoruyko & Komodakis (2016), for example) and random search, the latter being the better of the
two (Bergstra & Bengio, 2012).
",2. Related Work,[0],[0]
"Our approach builds on previous work, with some important differences.",2. Related Work,[0],[0]
We explore large model-architecture search spaces starting with basic initial conditions to avoid priming the system with information about known good strategies for the specific dataset at hand.,2. Related Work,[0],[0]
"Our encoding is different from the neuro-evolution methods mentioned above: we use a simplified graph as our DNA, which is transformed to a full neural network graph for training and evaluation (Section 3).",2. Related Work,[0],[0]
Some of the mutations acting on this DNA are reminiscent of NEAT.,2. Related Work,[0],[0]
"However, instead of single nodes, one mutation can insert whole layers—i.e. tens to hundreds of nodes at a time.",2. Related Work,[0],[0]
"We also allow for these layers to be removed, so that the evolutionary process can simplify an architecture in addition to complexifying it.",2. Related Work,[0],[0]
"Layer parameters are also mutable, but we do not prescribe a small set of possible values to choose from, to allow for a larger search space.",2. Related Work,[0],[0]
We do not use fitness sharing.,2. Related Work,[0],[0]
"We report additional results using recombination, but for the most part, we used mutation only.",2. Related Work,[0],[0]
"On the other hand, we do use back-propagation to optimize the weights, which can be inherited across mutations.",2. Related Work,[0],[0]
"Together with a learning rate mutation, this allows the exploration of the space of learning rate schedules, yielding fully trained models at the end of the evolutionary process (Section 3).",2. Related Work,[0],[0]
"Tables 1 and 2 compare our approach with hand-designed architectures and with other neuro-discovery techniques, respectively.",2. Related Work,[0],[0]
"To automatically search for high-performing neural network architectures, we evolve a population of models.",3.1. Evolutionary Algorithm,[0],[0]
Each model—or individual—is a trained architecture.,3.1. Evolutionary Algorithm,[0],[0]
The model’s accuracy on a separate validation dataset is a measure of the individual’s quality or fitness.,3.1. Evolutionary Algorithm,[0],[0]
"During each evolutionary step, a computer—a worker—chooses two individuals at random from this population and compares their fitnesses.",3.1. Evolutionary Algorithm,[0],[0]
The worst of the pair is immediately removed from the population—it is killed.,3.1. Evolutionary Algorithm,[0],[0]
"The best of the pair is selected to be a parent, that is, to undergo reproduction.",3.1. Evolutionary Algorithm,[0],[0]
"By this we mean that the worker creates a copy of the parent and modifies this copy by applying a mutation, as described below.",3.1. Evolutionary Algorithm,[0],[0]
We will refer to this modified copy as the child.,3.1. Evolutionary Algorithm,[0],[0]
"After the worker creates the child, it trains this child, evaluates it on the validation set, and puts it back into the population.",3.1. Evolutionary Algorithm,[0],[0]
The child then becomes alive—i.e. free to act as a parent.,3.1. Evolutionary Algorithm,[0],[0]
"Our scheme, therefore, uses repeated pairwise competitions of random individuals, which makes it an example of tournament selection (Goldberg & Deb, 1991).",3.1. Evolutionary Algorithm,[0],[0]
Using pairwise comparisons instead of whole population operations prevents workers from idling when they finish early.,3.1. Evolutionary Algorithm,[0],[0]
"Code and more detail about the methods described below can be found in Supplementary Section S1.
",3.1. Evolutionary Algorithm,[0],[0]
Using this strategy to search large spaces of complex image models requires considerable computation.,3.1. Evolutionary Algorithm,[0],[0]
"To achieve scale, we developed a massively-parallel, lock-free infrastructure.",3.1. Evolutionary Algorithm,[0],[0]
Many workers operate asynchronously on different computers.,3.1. Evolutionary Algorithm,[0],[0]
They do not communicate directly with each other.,3.1. Evolutionary Algorithm,[0],[0]
"Instead, they use a shared file-system, where the population is stored.",3.1. Evolutionary Algorithm,[0],[0]
The file-system contains directories that represent the individuals.,3.1. Evolutionary Algorithm,[0],[0]
"Operations on these individuals, such as the killing of one, are represented as atomic renames on the directory2.",3.1. Evolutionary Algorithm,[0],[0]
"Occasionally, a worker may concurrently modify the individual another worker is operating on.",3.1. Evolutionary Algorithm,[0],[0]
"In this case, the affected worker simply gives up and tries again.",3.1. Evolutionary Algorithm,[0],[0]
"The population size is 1000 individuals, unless otherwise stated.",3.1. Evolutionary Algorithm,[0],[0]
The number of workers is always 1 4 of the population size.,3.1. Evolutionary Algorithm,[0],[0]
"To allow for long run-times with a limited amount of space, dead individuals’ directories are frequently garbage-collected.",3.1. Evolutionary Algorithm,[0],[0]
Individual architectures are encoded as a graph that we refer to as the DNA.,3.2. Encoding and Mutations,[0],[0]
"In this graph, the vertices represent rank-3 tensors or activations.",3.2. Encoding and Mutations,[0],[0]
"As is standard for a convo-
2The use of the file-name string to contain key information about the individual was inspired by Breuel & Shafait (2010), and it speeds up disk access enormously.",3.2. Encoding and Mutations,[0],[0]
"In our case, the file name contains the state of the individual (alive, dead, training, etc.).
lutional network, two of the dimensions of the tensor represent the spatial coordinates of the image and the third is a number of channels.",3.2. Encoding and Mutations,[0],[0]
"Activation functions are applied at the vertices and can be either (i) batch-normalization (Ioffe & Szegedy, 2015) with rectified linear units (ReLUs) or (ii) plain linear units.",3.2. Encoding and Mutations,[0],[0]
The graph’s edges represent identity connections or convolutions and contain the mutable numerical parameters defining the convolution’s properties.,3.2. Encoding and Mutations,[0],[0]
"When multiple edges are incident on a vertex, their spatial scales or numbers of channels may not coincide.",3.2. Encoding and Mutations,[0],[0]
"However, the vertex must have a single size and number of channels for its activations.",3.2. Encoding and Mutations,[0],[0]
The inconsistent inputs must be resolved.,3.2. Encoding and Mutations,[0],[0]
Resolution is done by choosing one of the incoming edges as the primary one.,3.2. Encoding and Mutations,[0],[0]
We pick this primary edge to be the one that is not a skip connection.,3.2. Encoding and Mutations,[0],[0]
"The activations coming from the non-primary edges are reshaped through zerothorder interpolation in the case of the size and through truncation/padding in the case of the number of channels, as in He et al. (2016).",3.2. Encoding and Mutations,[0],[0]
"In addition to the graph, the learning-rate value is also stored in the DNA.
",3.2. Encoding and Mutations,[0],[0]
A child is similar but not identical to the parent because of the action of a mutation.,3.2. Encoding and Mutations,[0],[0]
"In each reproduction event, the worker picks a mutation at random from a predetermined set.",3.2. Encoding and Mutations,[0],[0]
"The set contains the following mutations:
• ALTER-LEARNING-RATE (sampling details below).",3.2. Encoding and Mutations,[0],[0]
• IDENTITY (effectively means “keep training”).,3.2. Encoding and Mutations,[0],[0]
"• RESET-WEIGHTS (sampled as in He et al. (2015), for
example).",3.2. Encoding and Mutations,[0],[0]
"• INSERT-CONVOLUTION (inserts a convolution at a ran-
dom location in the “convolutional backbone”, as in Figure 1.",3.2. Encoding and Mutations,[0],[0]
"The inserted convolution has 3 × 3 filters, strides of 1 or 2 at random, number of channels same as input.",3.2. Encoding and Mutations,[0],[0]
May apply batch-normalization and ReLU activation or none at random).,3.2. Encoding and Mutations,[0],[0]
• REMOVE-CONVOLUTION.,3.2. Encoding and Mutations,[0],[0]
• ALTER-STRIDE (only powers of 2 are allowed).,3.2. Encoding and Mutations,[0],[0]
• ALTER-NUMBER-OF-CHANNELS (of random conv.).,3.2. Encoding and Mutations,[0],[0]
"• FILTER-SIZE (horizontal or vertical at random, on ran-
dom convolution, odd values only).",3.2. Encoding and Mutations,[0],[0]
"• INSERT-ONE-TO-ONE (inserts a one-to-one/identity
connection, analogous to insert-convolution mutation).",3.2. Encoding and Mutations,[0],[0]
• ADD-SKIP (identity between random layers).,3.2. Encoding and Mutations,[0],[0]
"• REMOVE-SKIP (removes random skip).
",3.2. Encoding and Mutations,[0],[0]
These specific mutations were chosen for their similarity to the actions that a human designer may take when improving an architecture.,3.2. Encoding and Mutations,[0],[0]
This may clear the way for hybrid evolutionary–hand-design methods in the future.,3.2. Encoding and Mutations,[0],[0]
"The probabilities for the mutations were not tuned in any way.
",3.2. Encoding and Mutations,[0],[0]
A mutation that acts on a numerical parameter chooses the new value at random around the existing value.,3.2. Encoding and Mutations,[0],[0]
All sampling is from uniform distributions.,3.2. Encoding and Mutations,[0],[0]
"For example, a mutation acting on a convolution with 10 output channels will
result in a convolution having between 5 and 20 output channels (that is, half to twice the original value).",3.2. Encoding and Mutations,[0],[0]
All values within the range are possible.,3.2. Encoding and Mutations,[0],[0]
"As a result, the models are not constrained to a number of filters that is known to work well.",3.2. Encoding and Mutations,[0],[0]
"The same is true for all other parameters, yielding a “dense” search space.",3.2. Encoding and Mutations,[0],[0]
"In the case of the strides, this applies to the log-base-2 of the value, to allow for activation shapes to match more easily3.",3.2. Encoding and Mutations,[0],[0]
"In principle, there is also no upper limit to any of the parameters.",3.2. Encoding and Mutations,[0],[0]
"All model depths are attainable, for example.",3.2. Encoding and Mutations,[0],[0]
"Up to hardware constraints, the search space is unbounded.",3.2. Encoding and Mutations,[0],[0]
The dense and unbounded nature of the parameters result in the exploration of a truly large set of possible architectures.,3.2. Encoding and Mutations,[0],[0]
"Every evolution experiment begins with a population of simple individuals, all with a learning rate of 0.1.",3.3. Initial Conditions,[0],[0]
They are all very bad performers.,3.3. Initial Conditions,[0],[0]
Each initial individual constitutes just a single-layer model with no convolutions.,3.3. Initial Conditions,[0],[0]
This conscious choice of poor initial conditions forces evolution to make the discoveries by itself.,3.3. Initial Conditions,[0],[0]
The experimenter contributes mostly through the choice of mutations that demarcate a search space.,3.3. Initial Conditions,[0],[0]
"Altogether, the use of poor initial conditions and a large search space limits the experimenter’s impact.",3.3. Initial Conditions,[0],[0]
"In other words, it prevents the experimenter from “rigging” the experiment to succeed.",3.3. Initial Conditions,[0],[0]
Training and validation is done on the CIFAR-10 dataset.,3.4. Training and Validation,[0],[0]
"This dataset consists of 50,000 training examples and 10,000 test examples, all of which are 32 x 32 color images labeled with 1 of 10 common object classes (Krizhevsky & Hinton, 2009).",3.4. Training and Validation,[0],[0]
"5,000 of the training examples are held out in a validation set.",3.4. Training and Validation,[0],[0]
"The remaining 45,000 examples constitute our actual training set.",3.4. Training and Validation,[0],[0]
The training set is augmented as in He et al. (2016).,3.4. Training and Validation,[0],[0]
"The CIFAR-100 dataset has the same number of dimensions, colors and examples as CIFAR-10, but uses 100 classes, making it much more challenging.
",3.4. Training and Validation,[0],[0]
"Training is done with TensorFlow (Abadi et al., 2016), using SGD with a momentum of 0.9 (Sutskever et al., 2013), a batch size of 50, and a weight decay of 0.0001.",3.4. Training and Validation,[0],[0]
"Each training runs for 25,600 steps, a value chosen to be brief enough so that each individual could be trained in a few seconds to a few hours, depending on model size.",3.4. Training and Validation,[0],[0]
The loss function is the cross-entropy.,3.4. Training and Validation,[0],[0]
"Once training is complete, a single evaluation on the validation set provides the accuracy to use as the individual’s fitness.",3.4. Training and Validation,[0],[0]
Ensembling was done by majority voting during the testing evaluation.,3.4. Training and Validation,[0],[0]
"The models used in the ensemble were selected by validation accuracy.
",3.4. Training and Validation,[0],[0]
"3For integer DNA parameters, we actually store and mutate a floating-point value.",3.4. Training and Validation,[0],[0]
This allows multiple small mutations to have a cumulative effect in spite of integer round-off.,3.4. Training and Validation,[0],[0]
"To estimate computation costs, we identified the basic TensorFlow (TF) operations used by our model training and validation, like convolutions, generic matrix multiplications, etc.",3.5. Computation cost,[0],[0]
"For each of these TF operations, we estimated the theoretical number of floating-point operations (FLOPs) required.",3.5. Computation cost,[0],[0]
"This resulted in a map from TF operation to FLOPs, which is valid for all our experiments.
",3.5. Computation cost,[0],[0]
"For each individual within an evolution experiment, we compute the total FLOPs incurred by the TF operations in its architecture over one batch of examples, both during its training (Ft FLOPs) and during its validation (Fv FLOPs).",3.5. Computation cost,[0],[0]
"Then we assign to the individual the cost FtNt + FvNv , where Nt and Nv are the number of training and validation batches, respectively.",3.5. Computation cost,[0],[0]
"The cost of the experiment is then the sum of the costs of all its individuals.
",3.5. Computation cost,[0],[0]
We intend our FLOPs measurement as a coarse estimate only.,3.5. Computation cost,[0],[0]
"We do not take into account input/output, data preprocessing, TF graph building or memory-copying operations.",3.5. Computation cost,[0],[0]
Some of these unaccounted operations take place once per training run or once per step and some have a component that is constant in the model size (such as disk-access latency or input data cropping).,3.5. Computation cost,[0],[0]
"We therefore expect the estimate to be more useful for large architectures (for example, those with many convolutions).",3.5. Computation cost,[0],[0]
We need architectures that are trained to completion within an evolution experiment.,3.6. Weight Inheritance,[0],[0]
"If this does not happen, we are forced to retrain the best model at the end, possibly having to explore its hyper-parameters.",3.6. Weight Inheritance,[0],[0]
Such extra exploration tends to depend on the details of the model being retrained.,3.6. Weight Inheritance,[0],[0]
"On the other hand, 25,600 steps are not enough to fully train each individual.",3.6. Weight Inheritance,[0],[0]
Training a large model to completion is prohibitively slow for evolution.,3.6. Weight Inheritance,[0],[0]
"To resolve this dilemma, we allow the children to inherit the parents’ weights whenever possible.",3.6. Weight Inheritance,[0],[0]
"Namely, if a layer has matching shapes, the weights are preserved.",3.6. Weight Inheritance,[0],[0]
"Consequently, some mutations preserve all the weights (like the identity or learning-rate mutations), some preserve none (the weightresetting mutation), and most preserve some but not all.",3.6. Weight Inheritance,[0],[0]
An example of the latter is the filter-size mutation: only the filters of the convolution being mutated will be discarded.,3.6. Weight Inheritance,[0],[0]
"To avoid over-fitting, neither the evolutionary algorithm nor the neural network training ever see the testing set.",3.7. Reporting Methodology,[0],[0]
"Each time we refer to “the best model”, we mean the model with the highest validation accuracy.",3.7. Reporting Methodology,[0],[0]
"However, we always report the test accuracy.",3.7. Reporting Methodology,[0],[0]
"This applies not only to the choice of the best individual within an experiment, but also to the choice
of the best experiment.",3.7. Reporting Methodology,[0],[0]
"Moreover, we only include experiments that we managed to reproduce, unless explicitly noted.",3.7. Reporting Methodology,[0],[0]
"Any statistical analysis was fully decided upon before seeing the results of the experiment reported, to avoid tailoring our analysis to our experimental data (Simmons et al., 2011).",3.7. Reporting Methodology,[0],[0]
"We want to answer the following questions:
• Can a simple one-shot evolutionary process start from trivial initial conditions and yield fully trained models that rival hand-designed architectures?",4. Experiments and Results,[0],[0]
"• What are the variability in outcomes, the parallelizability, and the computation cost of the method?",4. Experiments and Results,[0],[0]
"• Can an algorithm designed iterating on CIFAR-10 be applied, without any changes at all, to CIFAR-100 and still produce competitive models?
",4. Experiments and Results,[0],[0]
We used the algorithm in Section 3 to perform several experiments.,4. Experiments and Results,[0],[0]
"Each experiment evolves a population in a few days, typified by the example in Figure 1.",4. Experiments and Results,[0],[0]
"The figure also contains examples of the architectures discovered, which turn out to be surprisingly simple.",4. Experiments and Results,[0],[0]
"Evolution attempts skip connections but frequently rejects them.
",4. Experiments and Results,[0],[0]
"To get a sense of the variability in outcomes, we repeated the experiment 5 times.",4. Experiments and Results,[0],[0]
"Across all 5 experiment runs, the best model by validation accuracy has a testing accuracy of 94.6%.",4. Experiments and Results,[0],[0]
"Not all experiments reach the same accuracy, but they get close (µ=94.1%, σ=0.4).",4. Experiments and Results,[0],[0]
Fine differences in the experiment outcome may be somewhat distinguishable by validation accuracy (correlation coefficient = 0.894).,4. Experiments and Results,[0],[0]
The total amount of computation across all 5 experiments was 4×1020 FLOPs (or 9×1019 FLOPs on average per experiment).,4. Experiments and Results,[0],[0]
Each experiment was distributed over 250 parallel workers (Section 3.1).,4. Experiments and Results,[0],[0]
"Figure 2 shows the progress of the experiments in detail.
",4. Experiments and Results,[0],[0]
"As a control, we disabled the selection mechanism, thereby reproducing and killing random individuals.",4. Experiments and Results,[0],[0]
This is the form of random search that is most compatible with our infrastructure.,4. Experiments and Results,[0],[0]
The probability distributions for the parameters are implicitly determined by the mutations.,4. Experiments and Results,[0],[0]
This control only achieves an accuracy of 87.3% in the same amount of run time on the same hardware (Figure 2).,4. Experiments and Results,[0],[0]
The total amount of computation was 2×1017 FLOPs.,4. Experiments and Results,[0],[0]
"The low FLOP count is a consequence of random search generating many small, inadequate models that train quickly but consume roughly constant amounts of setup time (not included in the FLOP count).",4. Experiments and Results,[0],[0]
"We attempted to minimize this overhead by avoiding unnecessary disk access operations, to no avail: too much overhead remains spent on a combination of neural network setup, data augmentation, and training step initialization.
",4. Experiments and Results,[0],[0]
We also ran a partial control where the weight-inheritance mechanism is disabled.,4. Experiments and Results,[0],[0]
"This run also results in a lower accuracy (92.2%) in the same amount of time (Figure 2), using 9×1019 FLOPs.",4. Experiments and Results,[0],[0]
"This shows that weight inheritance is important in the process.
",4. Experiments and Results,[0],[0]
"Finally, we applied our neuro-evolution algorithm, without any changes and with the same meta-parameters, to CIFAR-100.",4. Experiments and Results,[0],[0]
"Our only experiment reached an accuracy of 77.0%, using 2× 1020 FLOPs.",4. Experiments and Results,[0],[0]
We did not attempt other datasets.,4. Experiments and Results,[0],[0]
Table 1 shows that both the CIFAR-10 and CIFAR-100 results are competitive with modern handdesigned networks.,4. Experiments and Results,[0],[0]
Meta-parameters.,5. Analysis,[0],[0]
We observe that populations evolve until they plateau at some local optimum (Figure 2).,5. Analysis,[0],[0]
"The fitness (i.e. validation accuracy) value at this optimum varies between experiments (Figure 2, inset).",5. Analysis,[0],[0]
"Since not all experiments reach the highest possible value, some populations are getting “trapped” at inferior local optima.",5. Analysis,[0],[0]
This entrapment is affected by two important meta-parameters (i.e. parameters that are not optimized by the algorithm).,5. Analysis,[0],[0]
These are the population size and the number of training steps per individual.,5. Analysis,[0],[0]
"Below we discuss them and consider their relationship to local optima.
",5. Analysis,[0],[0]
Effect of population size.,5. Analysis,[0],[0]
"Larger populations explore the space of models more thoroughly, and this helps reach better optima (Figure 3, left).",5. Analysis,[0],[0]
"Note, in particular, that a population of size 2 can get trapped at very low fitness values.",5. Analysis,[0],[0]
"Some intuition about this can be gained by considering the fate of a super-fit individual, i.e. an individual such that any one architectural mutation reduces its fitness (even though a sequence of many mutations may improve it).",5. Analysis,[0],[0]
"In the case of a population of size 2, if the super-fit individual wins once, it will win every time.",5. Analysis,[0],[0]
"After the first win, it will produce a child that is one mutation away.",5. Analysis,[0],[0]
"By definition of super-fit, therefore, this child is inferior4.",5. Analysis,[0],[0]
"Consequently, in the next round of tournament selection, the super-fit individual competes against its child and wins again.",5. Analysis,[0],[0]
This cycle repeats forever and the population is trapped.,5. Analysis,[0],[0]
"Even if a sequence of two mutations would allow for an “escape” from the local optimum, such a sequence can never take place.",5. Analysis,[0],[0]
This is only a rough argument to heuristically suggest why a population of size 2 is easily trapped.,5. Analysis,[0],[0]
"More generally, Figure 3 (left) empirically demonstrates a benefit from an increase in population size.",5. Analysis,[0],[0]
"Theoretical analyses of this dependence are quite complex and assume very specific models of population dynamics; often larger populations are better at handling local optima, at least beyond a size threshold (Weinreich & Chao (2005) and references
4Except after identity or learning rate mutations, but these produce a child with the same architecture as the parent.
therein).",5. Analysis,[0],[0]
Effect of number of training steps.,5. Analysis,[0],[0]
The other metaparameter is the number T of training steps for each individual.,5. Analysis,[0],[0]
"Accuracy increases with T (Figure 3, right).",5. Analysis,[0],[0]
Larger T means an individual needs to undergo fewer identity mutations to reach a given level of training.,5. Analysis,[0],[0]
Escaping local optima.,5. Analysis,[0],[0]
"While we might increase population size or number of steps to prevent a trapped population from forming, we can also free an already trapped population.",5. Analysis,[0],[0]
"For example, increasing the mutation rate or resetting all the weights of a population (Figure 4) work well but are quite costly (more details in Supplementary Section S3).",5. Analysis,[0],[0]
Recombination.,5. Analysis,[0],[0]
None of the results presented so far used recombination.,5. Analysis,[0],[0]
"However, we explored three forms of recombination in additional experiments.",5. Analysis,[0],[0]
"Following Tuson & Ross (1998), we attempted to evolve the mutation probability distribution too.",5. Analysis,[0],[0]
"On top of this, we employed a recombination strategy by which a child could inherit structure from one parent and mutation probabilities from another.",5. Analysis,[0],[0]
"The goal was to allow individuals that progressed well due to good mutation choices to quickly propagate
such choices to others.",5. Analysis,[0],[0]
"In a separate experiment, we attempted recombining the trained weights from two parents in the hope that each parent may have learned different concepts from the training data.",5. Analysis,[0],[0]
"In a third experiment, we recombined structures so that the child fused the architectures of both parents side-by-side, generating wide models fast.",5. Analysis,[0],[0]
"While none of these approaches improved our recombination-free results, further study seems warranted.",5. Analysis,[0],[0]
"In this paper we have shown that (i) neuro-evolution is capable of constructing large, accurate networks for two challenging and popular image classification benchmarks; (ii) neuro-evolution can do this starting from trivial initial conditions while searching a very large space; (iii) the process, once started, needs no experimenter participation; and (iv) the process yields fully trained models.",6. Conclusion,[0],[0]
Completely training models required weight inheritance (Sections 3.6).,6. Conclusion,[0],[0]
"In contrast to reinforcement learning, evolution provides a natural framework for weight inheritance: mutations can be constructed to guarantee a large degree of similarity be-
tween the original and mutated models—as we did.",6. Conclusion,[0],[0]
"Evolution also has fewer tunable meta-parameters with a fairly predictable effect on the variance of the results, which can be made small.
",6. Conclusion,[0],[0]
"While we did not focus on reducing computation costs, we hope that future algorithmic and hardware improvement will allow more economical implementation.",6. Conclusion,[0],[0]
"In that case, evolution would become an appealing approach to neurodiscovery for reasons beyond the scope of this paper.",6. Conclusion,[0],[0]
"For example, it “hits the ground running”, improving on arbitrary initial models as soon as the experiment begins.",6. Conclusion,[0],[0]
The mutations used can implement recent advances in the field and can be introduced without having to restart an experiment.,6. Conclusion,[0],[0]
"Furthermore, recombination can merge improvements developed by different individuals, even if they come from other populations.",6. Conclusion,[0],[0]
"Moreover, it may be possible to combine neuro-evolution with other automatic architecture discovery methods.",6. Conclusion,[0],[0]
"We wish to thank Vincent Vanhoucke, Megan Kacholia, Rajat Monga, and especially Jeff Dean for their support and valuable input; Geoffrey Hinton, Samy Bengio, Thomas Breuel, Mark DePristo, Vishy Tirumalashetty, Martin Abadi, Noam Shazeer, Yoram Singer, Dumitru Erhan, Pierre Sermanet, Xiaoqiang Zheng, Shan Carter and Vijay Vasudevan for helpful discussions; Thomas Breuel, Xin Pan and Andy Davis for coding contributions; and the larger Google Brain team for help with TensorFlow and training vision models.",Acknowledgements,[0],[0]
"Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone.",abstractText,[0],[0]
"Our goal is to minimize human participation, so we employ evolutionary algorithms to discover such networks automatically.",abstractText,[0],[0]
"Despite significant computational requirements, we show that it is now possible to evolve models with accuracies within the range of those published in the last year.",abstractText,[0],[0]
"Specifically, we employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions and reaching accuracies of 94.6% (95.6% for ensemble) and 77.0%, respectively.",abstractText,[0],[0]
"To do this, we use novel and intuitive mutation operators that navigate large search spaces; we stress that no human participation is required once evolution starts and that the output is a fully-trained model.",abstractText,[0],[0]
"Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.",abstractText,[0],[0]
Large-Scale Evolution of Image Classifiers,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 432–437 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
432",text,[0],[0]
Spoken Dialogue Systems (SDS) are computer programs that can hold a conversation with a human.,1 Introduction,[0],[0]
"These can be task-based systems that help the user achieve specific goals, e.g. finding and booking hotels or restaurants.",1 Introduction,[0],[0]
"In order for the SDS to infer the user goals/intentions during the conversation, its Belief Tracking (BT) component maintains a distribution of states, called a belief state, across dialogue turns (Young et al., 2010).",1 Introduction,[0],[0]
The belief state is used by the system to take actions in each turn until the conversation is concluded and the user goal is achieved.,1 Introduction,[0],[0]
"In order to extract these belief states from the conversation, traditional approaches use a Spoken Language
Understanding (SLU) unit that utilizes a semantic dictionary to hold all the key terms, rephrasings and alternative mentions of a belief state.",1 Introduction,[0],[0]
"The SLU then delexicalises each turn using this semantic dictionary, before it passes it to the BT component (Wang and Lemon, 2013; Henderson et al., 2014b; Williams, 2014; Zilka and Jurcicek, 2015; Perez and Liu, 2016; Rastogi et al., 2017).",1 Introduction,[0],[0]
"However, this approach is not scalable to multi-domain dialogues because of the effort required to define a semantic dictionary for each domain.",1 Introduction,[0],[0]
"More advanced approaches, such as the Neural Belief Tracker (NBT), use word embeddings to alleviate the need for delexicalisation and combine the SLU and BT into one unit, mapping directly from turns to belief states (Mrkšić et al., 2017).",1 Introduction,[0],[0]
"Nevertheless, the NBT model does not tackle the problem of mixing different domains in a conversation.",1 Introduction,[0],[0]
"Moreover, as each slot is trained independently without sharing information between different slots, scaling such approaches to large multi-domain systems is greatly hindered.
",1 Introduction,[0],[0]
"In this paper, we propose a model that jointly identifies the domain and tracks the belief states corresponding to that domain.",1 Introduction,[0],[0]
It uses semantic similarity between ontology terms and turn utterances to allow for parameter sharing between different slots across domains and within a single domain.,1 Introduction,[0],[0]
"In addition, the model parameters are independent of the ontology/belief states, thus the dimensionality of the parameters does not increase with the size of the ontology, making the model practically feasible to deploy in multidomain environments without any modifications.",1 Introduction,[0],[0]
"Finally, we introduce a new, large-scale corpora of natural, human-human conversations providing new possibilities to train complex, neural-based models.",1 Introduction,[0],[0]
Our model systematically improves upon state-of-the-art neural approaches both in single and multi-domain conversations.,1 Introduction,[0],[0]
The belief states of the BT are defined based on an ontology - the structured representation of the database which contains entities the system can talk about.,2 Background,[0],[0]
The ontology defines the terms over which the distribution is to be tracked in the dialogue.,2 Background,[0],[0]
This ontology is constructed in terms of slots and values in a single domain setting.,2 Background,[0],[0]
"Or, alternatively, in terms of domains, slots and values in a multi-domain environment.",2 Background,[0],[0]
"Each domain consists of multiple slots and each slot contains several values, e.g. domain=hotel, slot=price, value=expensive.",2 Background,[0],[0]
"In each turn, the BT fits a distribution over the values of each slot in each domain, and a none value is added to each slot to indicate if the slot is not mentioned so that the distribution sums up to 1.",2 Background,[0],[0]
The BT then passes these states to the Policy Optimization unit as full probability distributions to take actions.,2 Background,[0],[0]
"This allows robustness to noisy environments (Young et al., 2010).",2 Background,[0],[0]
"The larger the ontology, the more flexible and multi-purposed the system is, but the harder it is to train and maintain a good quality BT.",2 Background,[0],[0]
"In recent years, a plethora of research has been generated on belief tracking (Williams et al., 2016).",3 Related Work,[0],[0]
"For the purposes of this paper, two previously proposed models are particularly relevant.",3 Related Work,[0],[0]
"The main idea behind the NBT (Mrkšić et al., 2017) is to use semantically specialized pretrained word embeddings to encode the user utterance, the system act and the candidate slots and values taken from the ontology.",3.1 Neural Belief Tracker (NBT),[0],[0]
These are fed to semantic decoding and context modeling modules that apply a three-way gating mechanism and pass the output to a non-linear classifier layer to produce a distribution over the values for each slot.,3.1 Neural Belief Tracker (NBT),[0],[0]
"It uses a simple update rule, p(st) = βp(st−1)+λy, where p(st) is the belief state at time step t, y is the output of the binary decision maker of the NBT and β and λ are tunable parameters.
",3.1 Neural Belief Tracker (NBT),[0],[0]
The NBT leverages semantic information from the word embeddings to resolve lexical/morphological ambiguity and maximize the shared parameters across the values of each slot.,3.1 Neural Belief Tracker (NBT),[0],[0]
"However, it only applies to a single domain and does not share parameters across slots.",3.1 Neural Belief Tracker (NBT),[0],[0]
"Recently, Rastogi et al. (2017) proposed a multidomain approach using delexicalized utterances fed to a two layer stacked bi-directional GRU network to extract features from the user and the system utterances.",3.2 Multi-domain Dialogue State Tracking,[0],[0]
"These, combined with the candidate slots and values, are passed to a feed-forward neural network with a softmax in the last layer.",3.2 Multi-domain Dialogue State Tracking,[0],[0]
"The candidate set fed to the network consists of the selected candidates from the previous turn and candidates from the ontology to a limit K, which restricts the maximum size of the chosen set.",3.2 Multi-domain Dialogue State Tracking,[0],[0]
"Consequently, the model does not need an ad-hoc belief state update mechanism like in the NBT.
",3.2 Multi-domain Dialogue State Tracking,[0],[0]
"The parameters of the GRU network are defined for the domain, whereas the parameters of the feed-forward network are defined per slot, allowing transfer learning across different domains.",3.2 Multi-domain Dialogue State Tracking,[0],[0]
"However, the model relies on delexicalization to extract the features, which limits the performance of the BT, as it does not scale to the rich variety of the language.",3.2 Multi-domain Dialogue State Tracking,[0],[0]
"Moreover, the number of parameters increases with the number of slots.",3.2 Multi-domain Dialogue State Tracking,[0],[0]
The core idea is to leverage semantic similarities between the utterances and ontology terms to compute the belief state distribution.,4 Method,[0],[0]
"In this way, the model parameters only learn to model the interactions between turn utterances and ontology terms in the semantic space, rather than the mapping from utterances to states.",4 Method,[0],[0]
"Consequently, information is shared between both slots and across domains.",4 Method,[0],[0]
"Additionally, the number of parameters does not increase with the ontology size.",4 Method,[0],[0]
Domain tracking is considered as a separate task but is learned jointly with the belief state tracking of the slots and values.,4 Method,[0],[0]
"The proposed model uses semantically specialized pre-trained word embeddings (Wieting et al., 2015).",4 Method,[0],[0]
"To encode the user and system utterances, we employed 7 independent bi-directional LSTMs (Graves and Schmidhuber, 2005).",4 Method,[0],[0]
"Three of them are used to encode the system utterance for domain, slot and value tracking respectively.",4 Method,[0],[0]
"Similarly, three Bi-LSTMs encode the user utterance while and the last one is used to track the user affirmation.",4 Method,[0],[0]
"A variant of the CNNs as a feature extractor, similar to the one used in the NBT-CNN (Mrkšić et al., 2017) is also employed.",4 Method,[0],[0]
Figure 1 presents the system architecture with two bi-directional LSTM networks as information encoders running over the word embeddings of the user and system utterances.,4.1 Domain Tracking,[0],[0]
"The last hidden states of the forward and backward layers are concatenated to produce hdusr,h d sys of size L for the user and system utterances respectively.",4.1 Domain Tracking,[0],[0]
"In the second variant of the model, CNNs are used to produce these vectors (Kim, 2014; Kalchbrenner et al., 2014).",4.1 Domain Tracking,[0],[0]
"To detect the presence of the domain in the dialogue turn, element-wise multiplication is used as a similarity metric between the hidden states and the ontology embeddings of the domain:
dk = h",4.1 Domain Tracking,[0],[0]
d,4.1 Domain Tracking,[0],[0]
k,4.1 Domain Tracking,[0],[0]
"tanh(Wd ed + bd),
where k ∈ {usr, sys}, ed is the embedding vector of the domain and",4.1 Domain Tracking,[0],[0]
Wd ∈ RL×D transforms the domain word embeddings of dimension D to the hidden representation.,4.1 Domain Tracking,[0],[0]
"The information about semantic similarity is held by dusr and dsys, which are fed to a non-linear layer to output a binary decision:
Pt(d) = σ(wd {dusr ⊕ dsys}+ bd),
where wd ∈ R2L and bd are learnable parameters that map the semantic similarity to a belief state probability Pt(d) of a domain d at a turn t.",4.1 Domain Tracking,[0],[0]
Slots and values are tracked using a similar architecture as for domain tracking (Figure 1).,4.2 Candidate Slots and Values Tracking,[0],[0]
"However, to correctly model the context of the systemuser dialogue at each turn, three different cases are considered when computing the similarity vectors:
1.",4.2 Candidate Slots and Values Tracking,[0],[0]
"Inform: The user is informing the system about his/her goal, e.g. ’I am looking for a restaurant that serves Turkish food’.",4.2 Candidate Slots and Values Tracking,[0],[0]
2.,4.2 Candidate Slots and Values Tracking,[0],[0]
Request: The system is requesting information by asking the user about the value of a specific slot.,4.2 Candidate Slots and Values Tracking,[0],[0]
If the system utterance is: ’When do you want the taxi to arrive?’,4.2 Candidate Slots and Values Tracking,[0],[0]
and the user answers with ’19:30’.,4.2 Candidate Slots and Values Tracking,[0],[0]
3.,4.2 Candidate Slots and Values Tracking,[0],[0]
Confirm: The system wants to confirm information about the value of a specific slot.,4.2 Candidate Slots and Values Tracking,[0],[0]
"If the system asked: ’Would you like free parking?’, the user can either affirm positively or negatively.",4.2 Candidate Slots and Values Tracking,[0],[0]
"The model detects the user affirmation, using a separate bi-directional LSTM or CNN to output hausr.
",4.2 Candidate Slots and Values Tracking,[0],[0]
"The three cases are modelled as following:
ys,vinf = winf {susr ⊕ vusr}+ binf , ys,vreq = wreq {ssys ⊕ vusr}+ breq, ys,vaf = waf {ssys ⊕ vsys ⊕ h a usr}+ baf ,
where sk,vk for k ∈ {usr, sys} represent semantic similarity between the user and system utterances and the ontology slot and value terms respectively computed as shown in Figure 1, and w and b are learnable parameters.
",4.2 Candidate Slots and Values Tracking,[0],[0]
"The distribution over the values of slot s in domain d at turn t can be computed by summing the unscaled states, yinf , yreq and yaf for each value v in s, and applying a softmax to normalize the distribution:
Pt(s, v) = softmax(ys,vinf + y s,v req + y s,v af ).",4.2 Candidate Slots and Values Tracking,[0],[0]
"Since dialogue systems in the real-world operate in noisy environments, a robust BT should utilize the flow of the conversation to reduce the uncertainty in the belief state distribution.",4.3 Belief State Update,[0],[0]
"This can be achieved by passing the output of the decision maker, at each turn, as an input to an RNN that runs over the dialogue turns as shown in Figure 1, which allows the gradients to be propagated across turns.",4.3 Belief State Update,[0],[0]
This alleviates the problem of tuning hyper-parameters for rule-based updates.,4.3 Belief State Update,[0],[0]
"To avoid the vanishing gradient problem, three networks were tested: a simple RNN, an RNN with a memory cell (Henderson et al., 2014a) and a LSTM.",4.3 Belief State Update,[0],[0]
The RNN with a memory cell proved to give the best results.,4.3 Belief State Update,[0],[0]
"In addition to the fact that it reduces the vanishing gradient problem, this variant is less complex than an LSTM, which makes training easier.",4.3 Belief State Update,[0],[0]
"Furthermore, a variant of RNN used for domain tracking has all its weights of the form: Wi = αiI, where αi is a distinct learnable parameter for hidden, memory and previous state layers and I is the identity matrix.",4.3 Belief State Update,[0],[0]
"Similarly, weights of the RNN used to track the slots and values is of the form: Wj = γjI+",4.3 Belief State Update,[0],[0]
"λj(1− I), where γj and λj are the learnable parameters.",4.3 Belief State Update,[0],[0]
These two variants of RNN are a combination of Henderson et al. (2014a) and Mrkvsić and Vulić (2018) previous works.,4.3 Belief State Update,[0],[0]
"The output is P1:T (d) and P1:T (s,v), which represents the joint probability distribution of the domains and slots and values respectively over the complete dialogue.",4.3 Belief State Update,[0],[0]
"Combining these together produces the full belief state distribution of the dialogue:
P1:T (d, s,v) = P1:T (d)P1:T (s,v).",4.3 Belief State Update,[0],[0]
Domain tracking and slots and values tracking are trained disjointly.,4.4 Training Criteria,[0],[0]
"Belief state labels for each turn
are split into domains and slots and values.",4.4 Training Criteria,[0],[0]
"Thanks to the disjoint training, the learning of slot and value belief states are not restricted to a specific domain.",4.4 Training Criteria,[0],[0]
"Therefore, the model shares the knowledge of slots and values across different domains.",4.4 Training Criteria,[0],[0]
"The loss function for the domain tracking is:
Ld = − N∑
n=1 ∑ d∈D tn(d)logPn1:T (d),
where d is a vector of domains over the dialogue, tn(d) is the domain label for the dialogue n",4.4 Training Criteria,[0],[0]
and N is the number of dialogues.,4.4 Training Criteria,[0],[0]
"Similarly, the loss function for the slots and values tracking is:
Ls,v = − N∑
n=1 ∑ s,v∈S,V tn(s,v)logPn1:T (s,v),
where s and v are vectors of slots and values over the dialogue and tn(s,v) is the joint label vector for the dialogue n.",4.4 Training Criteria,[0],[0]
"Neural approaches to statistical dialogue development, especially in a task-oriented paradigm, are greatly hindered by the lack of large scale datasets.",5 Datasets and Baselines,[0],[0]
"That is why, following the Wizard-of-Oz (WOZ) approach (Kelley, 1984; Wen et al., 2017), we ran text-based multi-domain corpus data collection scheme through Amazon MTurk.",5 Datasets and Baselines,[0],[0]
The main goal of the data collection was to acquire humanhuman conversations between a tourist visiting a city and a clerk from an information center.,5 Datasets and Baselines,[0],[0]
"At the beginning of each dialogue the user (visitor) was given explicit instructions about the goal to fulfill, which often spanned multiple domains.",5 Datasets and Baselines,[0],[0]
The task of the system (wizard) is to assist a visitor having an access to databases over domains.,5 Datasets and Baselines,[0],[0]
"The WOZ paradigm allowed us to obtain natural and semantically rich multi-topic dialogues spanning over multiple domains such as hotels, attractions, restaurants, booking trains or taxis.",5 Datasets and Baselines,[0],[0]
The dialogues cover from 1 up to 5 domains per dialogue greatly varying in length and complexity.,5 Datasets and Baselines,[0],[0]
The data consists of 2480 single-domain dialogues and 7375 multi-domain dialogues usually spanning from 2 up to 5 domains.,5.1 Data Structure,[0],[0]
Some domains consists also of sub-domains like booking.,5.1 Data Structure,[0],[0]
"The average sentence lengths are 11.63 and 15.01 for users
and wizards respectively.",5.1 Data Structure,[0],[0]
"The combined ontology consists of 5 domains, 27 slots and 663 values making it significantly larger than observed in other datasets.",5.1 Data Structure,[0],[0]
"To enforce reproducibility of results, we distribute the corpus with a pre-specified train/test/development random split.",5.1 Data Structure,[0],[0]
The test and development sets contain 1k examples each.,5.1 Data Structure,[0],[0]
"Each dialogues consists of a goal, user and system utterances and a belief state per turn.",5.1 Data Structure,[0],[0]
The data and model is publicly available.1,5.1 Data Structure,[0],[0]
"We also used the extended WOZ 2.0 dataset (Wen et al., 2017).2 WOZ2 dataset consists of 1200 single topic dialogues constrained to the restaurant domain.",5.2 Evaluation,[0],[0]
All the weights were initialised using normal distribution of zero mean and unit variance and biases were initialised to zero.,5.2 Evaluation,[0],[0]
"ADAM optimizer (Kingma and Ba, 2014) (with 64 batch size) is used to train all the models for 600 epochs.",5.2 Evaluation,[0],[0]
"Dropout (Srivastava et al., 2014) was used for regularisation (50% dropout rate on all the intermediate representations).",5.2 Evaluation,[0],[0]
"For each of the two datasets we compare our proposed architecture (using either Bi-LSTM or CNN as encoders) to the NBT model3 (Mrkšić et al., 2017).",5.2 Evaluation,[0],[0]
"Table 1 shows the performance of our model in tracking the belief state of single-domain dialogues, compared to the NBT-CNN variant of the NBT discussed in Section 3.1.",6 Results,[0],[0]
Our model outperforms NBT in all the three slots and the joint goals for the two datasets.,6 Results,[0],[0]
"NBT previously achieved state-of-the-art results (Mrkšić et al., 2017).",6 Results,[0],[0]
"Moreover, the performance of all models is worse on the new dataset for restaurant compared to WOZ 2.0.
",6 Results,[0],[0]
1http://dialogue.mi.eng.cam.ac.uk/index.php/corpus/ 2Publicly available at https://mi.eng.cam.ac.,6 Results,[0],[0]
uk/˜nm480/woz_2.0.zip.,6 Results,[0],[0]
"3Publicly available at https://github.com/ nmrksic/neural-belief-tracker.
",6 Results,[0],[0]
"This is because the dialogues in the new dataset are richer and more noisier, as a closer resemblance to real environment dialogues.
",6 Results,[0],[0]
Table 2 presents the results on multi-domain dialogues from the new dataset described in Section 5.,6 Results,[0],[0]
"To demonstrate the difficulty of the multidomain belief tracking problem, values of a theoretical baseline that samples the belief state uniformly at random are also presented.",6 Results,[0],[0]
Our model gracefully handles such a difficult task.,6 Results,[0],[0]
"In most of the cases, CNNs demonstrate better performance than Bi-LSTMs.",6 Results,[0],[0]
"We hypothesize that this comes from the effectiveness of extracting local and position-invariant features, which are crucial for semantic similarities (Yin et al., 2017).",6 Results,[0],[0]
"In this paper, we proposed a new approach that tackles the issue of multi-domain belief tracking, such as model parameter scalability with the ontology size.",7 Conclusions,[0],[0]
Our model shows improved performance in single-domain tasks compared to the state-ofthe-art NBT method.,7 Conclusions,[0],[0]
"By exploiting semantic similarities between dialogue utterances and ontology terms, the model alleviates the need for ontologydependent parameters and maximizes the amount of information shared between slots and across domains.",7 Conclusions,[0],[0]
"In future, we intend to investigate introducing new domains and ontology terms without further training thus performing zero-shot learning.
",7 Conclusions,[0],[0]
4F1-score is computed by considering all the values in each slot of each domain as positive and the ”none” state of the slot as negative.,7 Conclusions,[0],[0]
"The authors would like to thank Nikola Mrkšić, Jacquie Rowe, the Cambridge Dialogue Systems Group and the ACL reviewers for their constructive feedback.",Acknowledgments,[0],[0]
"Paweł Budzianowski is supported by EPSRC Council and Toshiba Research Europe Ltd, Cambridge Research Laboratory.",Acknowledgments,[0],[0]
The data collection was funded through Google Faculty Award.,Acknowledgments,[0],[0]
Robust dialogue belief tracking is a key component in maintaining good quality dialogue systems.,abstractText,[0],[0]
"The tasks that dialogue systems are trying to solve are becoming increasingly complex, requiring scalability to multi-domain, semantically rich dialogues.",abstractText,[0],[0]
"However, most current approaches have difficulty scaling up with domains because of the dependency of the model parameters on the dialogue ontology.",abstractText,[0],[0]
"In this paper, a novel approach is introduced that fully utilizes semantic similarity between dialogue utterances and the ontology terms, allowing the information to be shared across domains.",abstractText,[0],[0]
"The evaluation is performed on a recently collected multi-domain dialogues dataset, one order of magnitude larger than currently available corpora.",abstractText,[0],[0]
"Our model demonstrates great capability in handling multi-domain dialogues, simultaneously outperforming existing state-of-the-art models in singledomain dialogue tracking tasks.",abstractText,[0],[0]
Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 2051–2060 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
2051",text,[0],[0]
"Learning semantic parsers to predict the predicateargument structures of a sentence is a long standing, open challenge (Palmer et al., 2005; Baker et al., 1998).",1 Introduction,[0],[0]
"Such systems are typically trained from datasets that are difficult to gather,1 but recent research has explored training nonexperts to provide this style of semantic supervision (Abend and Rappoport, 2013; Basile et al., 2012; Reisinger et al., 2015; He et al., 2015).",1 Introduction,[0],[0]
"In this paper, we show for the first time that it is possible to go even further by crowdsourcing a large
∗ Much of this work was done while these authors were at the Allen Institute for Artificial Intelligence.
1The PropBank (Bonial et al., 2010) and FrameNet (Ruppenhofer et al., 2016) annotation guides are 89 and 119 pages, respectively.
scale dataset that can be used to train high quality parsers at modest cost.
",1 Introduction,[0],[0]
We adopt the Question-Answer-driven Semantic Role Labeling (QA-SRL),1 Introduction,[0],[0]
"(He et al., 2015) annotation scheme.",1 Introduction,[0],[0]
"QA-SRL is appealing because it is intuitive to non-experts, has been shown to closely match the structure of traditional predicate-argument structure annotation schemes (He et al., 2015), and has been used for end tasks such as Open IE (Stanovsky and Dagan, 2016).",1 Introduction,[0],[0]
"In QA-SRL, each predicate-argument relationship is labeled with a question-answer pair (see Figure 1).",1 Introduction,[0],[0]
"He et al. (2015) showed that high precision QA-SRL annotations can be gathered with limited training but that high recall is challenging to achieve; it is relatively easy to gather answerable questions, but difficult to ensure that every possible question is labeled for every verb.",1 Introduction,[0],[0]
"For this reason, they hired and trained hourly annotators and only labeled a relatively small dataset (3000 sentences).
",1 Introduction,[0],[0]
"Our first contribution is a new, scalable approach for crowdsourcing QA-SRL.",1 Introduction,[0],[0]
"We introduce a streamlined web interface (including an autosuggest mechanism and automatic quality control to boost recall) and use a validation stage to en-
sure high precision (i.e. all the questions must be answerable).",1 Introduction,[0],[0]
"With this approach, we produce QA-SRL Bank 2.0, a dataset with 133,479 verbs from 64,018 sentences across 3 domains, totaling 265,140 question-answer pairs, in just 9 days.",1 Introduction,[0],[0]
"Our analysis shows that the data has high precision with good recall, although it does not cover every possible question.",1 Introduction,[0],[0]
"Figure 1 shows example annotations.
",1 Introduction,[0],[0]
"Using this data, our second contribution is a comparison of several new models for learning a QA-SRL parser.",1 Introduction,[0],[0]
"We follow a pipeline approach where the parser does (1) unlabeled span detection to determine the arguments of a given verb, and (2) question generation to label the relationship between the predicate and each detected span.",1 Introduction,[0],[0]
Our best model uses a span-based representation similar to that introduced by Lee et al. (2016) and a custom LSTM to decode questions from a learned span encoding.,1 Introduction,[0],[0]
"Our model does not require syntactic information and can be trained directly from the crowdsourced span labels.
",1 Introduction,[0],[0]
"Experiments demonstrate that the model does well on our new data, achieving up to 82.2% spandetection F1 and 47.2% exact-match question accuracy relative to the human annotations.",1 Introduction,[0],[0]
"We also demonstrate the utility of learning to predict easily interpretable QA-SRL structures, using a simple data bootstrapping approach to expand our dataset further.",1 Introduction,[0],[0]
"By tuning our model to favor recall, we over-generate questions which can be validated using our annotation pipeline, allowing for greater recall without requiring costly redundant annotations in the question writing step.",1 Introduction,[0],[0]
Performing this procedure on the training and development sets grows them by 20% and leads to improvements when retraining our models.,1 Introduction,[0],[0]
"Our final parser is highly accurate, achieving 82.6% question accuracy and 77.6% span-level precision in an human evaluation.",1 Introduction,[0],[0]
"Our data, code, and trained models will be made publicly available.2",1 Introduction,[0],[0]
"A QA-SRL annotation consists of a set of question-answer pairs for each verbal predicate in a sentence, where each answer is a set of contiguous spans from the sentence.",2 Data Annotation,[0],[0]
QA-SRL questions are defined by a 7-slot template shown in Table 1.,2 Data Annotation,[0],[0]
"We introduce a crowdsourcing pipeline to collect annotations rapidly, cheaply, and at large scale.
",2 Data Annotation,[0],[0]
"2http://qasrl.org
Pipeline",2 Data Annotation,[0],[0]
Our crowdsourcing pipeline consists of a generation and validation step.,2 Data Annotation,[0],[0]
"In the generation step, a sentence with one of its verbs marked is shown to a single worker, who must write QASRL questions for the verb and highlight their answers in the sentence.",2 Data Annotation,[0],[0]
"The questions are passed to the validation step, where n workers answer each question or mark it as invalid.",2 Data Annotation,[0],[0]
"In each step, no two answers to distinct questions may overlap with each other, to prevent redundancy.
",2 Data Annotation,[0],[0]
"Instructions Workers are instructed that a valid question-answer pair must satisfy three criteria: 1) the question is grammatical, 2) the questionanswer pair is asking about the time, place, participants, etc., of the target verb, and 3) all correct answers to each question are given.
",2 Data Annotation,[0],[0]
Autocomplete We provide an autocomplete drop-down to streamline question writing.,2 Data Annotation,[0],[0]
Autocomplete is implemented as a Non-deterministic Finite Automaton (NFA) whose states correspond to the 7 QA-SRL slots paired with a partial representation of the question’s syntax.,2 Data Annotation,[0],[0]
"We use the NFA to make the menu more compact by disallowing obviously ungrammatical combinations (e.g., What did been appeared?), and the syntactic representation to auto-suggest complete questions about arguments that have not yet been covered (see Figure 2).",2 Data Annotation,[0],[0]
"The auto-suggest feature significantly reduces the number of keystrokes required to enter new questions after the first one, speeding up the annotation process and making it easier for annotators to provide higher recall.
",2 Data Annotation,[0],[0]
"Payment and quality control Generation pays 5c for the first QA pair (required), plus 5c, 6c, etc. for each successive QA pair (optional), to boost recall.",2 Data Annotation,[0],[0]
"The validation step pays 8c per verb, plus a 2c bonus per question beyond four.",2 Data Annotation,[0],[0]
"Generation workers must write at least 2 questions per verb and have 85% of their questions counted valid, and validators must maintain 85% answer span agreement with others, or they are disqualified from further work.",2 Data Annotation,[0],[0]
"A validator’s answer is considered to agree with others if their answer span overlaps with answer spans provided by a majority of workers.
",2 Data Annotation,[0],[0]
"Preprocessing We use the Stanford CoreNLP tools (Manning et al., 2014) for sentence segmentation, tokenizing, and POS-tagging.",2 Data Annotation,[0],[0]
"We identify verbs by POS tag, with heuristics to filter out auxiliary verbs while retaining non-auxiliary uses of “have” and “do.”",2 Data Annotation,[0],[0]
"We identify conjugated forms of each verb for the QA-SRL templates by finding them in Wiktionary.3
Dataset We gathered annotations for 133,479 verb mentions in 64,018 sentences (1.27M tokens) across 3 domains: Wikipedia, Wikinews, and science textbook text from the Textbook Question Answering (TQA) dataset (Kembhavi et al., 2017).",2 Data Annotation,[0],[0]
"We partitioned the source documents into train, dev, and test, sampled paragraph-wise from each document with an 80/10/10 split by sentence.
",2 Data Annotation,[0],[0]
"Annotation in our pipeline with n = 2 valida-
3www.wiktionary.org
tors took 9 days on Amazon Mechanical Turk.4 1,165 unique workers participated, annotating a total of 299,308 questions.",2 Data Annotation,[0],[0]
"Of these, 265,140 (or 89%) were considered valid by both validators, for an average of 1.99 valid questions per verb and 4.14 valid questions per sentence.",2 Data Annotation,[0],[0]
See Table 2 for a breakdown of dataset statistics by domain.,2 Data Annotation,[0],[0]
"The total cost was $43,647.33, for an average of 32.7c per verb mention, 14.6c per question, or 16.5c per valid question.",2 Data Annotation,[0],[0]
"For comparison, He et al. (2015) interviewed and hired contractors to annotate data at much smaller scale for a cost of about 50c per verb.",2 Data Annotation,[0],[0]
"Our annotation scheme is cheaper, far more scalable, and provides more (though noisier) supervision for answer spans.
",2 Data Annotation,[0],[0]
"To allow for more careful evaluation, we validated 5,205 sentences at a higher density (up to 1,000 for each domain in dev and test), re-running the generated questions through validation with n = 3 for a total of 6 answer annotations for each question.
",2 Data Annotation,[0],[0]
Quality Judgments of question validity had moderate agreement.,2 Data Annotation,[0],[0]
"About 89.5% of validator judgments rated a question as valid, and the agreement rate between judgments of the same question on whether the question is invalid is 90.9%.",2 Data Annotation,[0],[0]
This gives a Fleiss’s Kappa of 0.51.,2 Data Annotation,[0],[0]
"In the higherdensity re-run, validators were primed to be more critical: 76.5% of judgments considered a question valid, and agreement was at 83.7%, giving a Fleiss’s Kappa of 0.55.
",2 Data Annotation,[0],[0]
"Despite being more critical in the denser annotation round, questions marked valid in the original dataset were marked valid by the new annotators in 86% of cases, showing our data’s relatively high precision.",2 Data Annotation,[0],[0]
"The high precision of our annotation pipeline is also backed up by our small-scale manual evaluation (see Coverage below).
",2 Data Annotation,[0],[0]
"Answer spans for each question also exhibit
4www.mturk.com
good agreement.",2 Data Annotation,[0],[0]
"On the original dataset, each answer span has a 74.8% chance to exactly match one provided by another annotator (up to two), and on the densely annotated subset, each answer span has an 83.1% chance to exactly match one provided by another annotator (up to five).
",2 Data Annotation,[0],[0]
Coverage Accurately measuring recall for QASRL annotations is an open challenge.,2 Data Annotation,[0],[0]
"For example, question 6 in Figure 1 reveals an inferred temporal relation that would not be annotated as part of traditional SRL.",2 Data Annotation,[0],[0]
"Exhaustively enumerating the full set of such questions is difficult, even for experts.
",2 Data Annotation,[0],[0]
"However, we can compare to the original QASRL dataset (He et al., 2015), where Wikipedia sentences were annotated with 2.43 questions per verb.",2 Data Annotation,[0],[0]
"Our data has lower—but loosely comparable—recall, with 2.05 questions per verb in Wikipedia.
",2 Data Annotation,[0],[0]
"In order to further analyze the quality of our annotations relative to (He et al., 2015), we reannotate a 100-verb subset of their data both manually (aiming for exhaustivity) and with our crowdsourcing pipeline.",2 Data Annotation,[0],[0]
"We merge the three sets of annotations, manually remove bad questions (and their answers), and calculate the precision and recall of the crowdsourced annotations and those of He et al. (2015) against this pooled, filtered dataset (using the span detection metrics described in Section 4).",2 Data Annotation,[0],[0]
"Results, shown in Table 3, show that our pipeline produces comparable precision with only a modest decrease in recall.",2 Data Annotation,[0],[0]
"Interestingly, readding the questions rejected in the validation step greatly increases recall with only a small decrease in precision, showing that validators sometimes rejected questions considered valid by the authors.",2 Data Annotation,[0],[0]
"However, we use the filtered dataset for our experiments, and in Section 5, we show how another crowdsourcing step can further improve recall.",2 Data Annotation,[0],[0]
"Given a sentence X = x0, . . .",3 Models,[0],[0]
", xn, the goal of a QA-SRL parser is to produce a set of tuples (vi,Qi,Si), where v ∈ {0, . . .",3 Models,[0],[0]
", n} is the index of a verbal predicate, Qi is a question, and Si ∈ {(i, j)",3 Models,[0],[0]
"| i, j ∈",3 Models,[0],[0]
"[0, n], j ≥ i} is a set of spans which are valid answers.",3 Models,[0],[0]
"Our proposed parsers construct these tuples in a three-step pipeline:
1.",3 Models,[0],[0]
Verbal predicates are identified using the same POS-tags and heuristics as in data collection (see Section 2).,3 Models,[0],[0]
2.,3 Models,[0],[0]
Unlabeled span detection selects a set Sv of spans as arguments for a given verb v. 3.,3 Models,[0],[0]
Question generation predicts a question for each span in Sv.,3 Models,[0],[0]
"Spans are then grouped by question, giving each question a set of answers.
",3 Models,[0],[0]
"We describe two models for unlabeled span detection in section 3.1, followed by question generation in section 3.2.",3 Models,[0],[0]
All models are built on an LSTM encoding of the sentence.,3 Models,[0],[0]
"Like He et al. (2017), we start with an input Xv = {x0 . .",3 Models,[0],[0]
".xn}, where the representation xi at each time step is a concatenation of the token wi’s embedding and an embedded binary feature (i = v) which indicates whether wi is the predicate under consideration.",3 Models,[0],[0]
"We then compute the output representation Hv = BILSTM(Xv) using a stacked alternating LSTM (Zhou and Xu, 2015) with highway connections (Srivastava et al., 2015) and recurrent dropout (Gal and Ghahramani, 2016).",3 Models,[0],[0]
"Since the span detection and question generation models both use an LSTM encoding, this component could in principle be shared between them.",3 Models,[0],[0]
"However, in preliminary experiments we found that sharing hurt performance, so for the remainder of this work each model is trained independently.",3 Models,[0],[0]
"Given an encoded sentence Hv, the goal of span detection is to select the spans Sv that correspond to arguments of the given predicate.",3.1 Span Detection,[0],[0]
"We explore two models: a sequence-tagging model with BIO encoding, and a span-based model which assigns a probability to every possible span.",3.1 Span Detection,[0],[0]
"Our BIO model predicts a set of spans via a sequence y where each yi ∈ {B, I,O}, representing a token at the beginning, interior, or outside of any span, respectively.",3.1.1 BIO Sequence Model,[0],[0]
"Similar to He et al.
(2017), we make independent predictions for each token at training time, and use Viterbi decoding to enforce hard BIO-constraints5 at test time.",3.1.1 BIO Sequence Model,[0],[0]
The resulting sequences are in one-to-one correspondence with sets Sv of spans which are pairwise non-overlapping.,3.1.1 BIO Sequence Model,[0],[0]
"The locally-normalized BIO-tag distributions are computed from the BiLSTM outputs Hv = {hv0, . . .",3.1.1 BIO Sequence Model,[0],[0]
",hvn}:
p(yt | x) ∝",3.1.1 BIO Sequence Model,[0],[0]
exp(wᵀtagMLP(hvt) + btag),3.1.1 BIO Sequence Model,[0],[0]
(1),3.1.1 BIO Sequence Model,[0],[0]
Our span-based model makes independent binary decisions for all O(n2) spans in the sentence.,3.1.2 Span-based Model,[0],[0]
"Following Lee et al. (2016), the representation of a span (i, j) is the concatenation of the BiLSTM output at each endpoint:
svij = [hvi,hvj",3.1.2 Span-based Model,[0],[0]
].,3.1.2 Span-based Model,[0],[0]
"(2)
The probability that the span is an argument of predicate v is computed by the sigmoid function:
p(yij |Xv) = σ(wᵀspanMLP(svij) + bspan) (3)
",3.1.2 Span-based Model,[0],[0]
"At training time, we minimize the binary cross entropy summed over all n2 possible spans, counting a span as a positive example if it appears as an answer to any question.
",3.1.2 Span-based Model,[0],[0]
"At test time, we choose a threshold τ and select every span that the model assigns probability greater than τ , allowing us to trade off precision and recall.",3.1.2 Span-based Model,[0],[0]
We introduce two question generation models.,3.2 Question Generation,[0],[0]
"Given a span representation svij defined in subsubsection 3.1.2, our models generate questions by picking a word for each question slot (see Section 2).",3.2 Question Generation,[0],[0]
"Each model calculates a joint distribution p(y | Xv, svij) over values y = (y1, . . .",3.2 Question Generation,[0],[0]
", y7) for the question slots given a span svij , and is trained to minimize the negative log-likelihood of gold slot values.",3.2 Question Generation,[0],[0]
"The local model predicts the words for each slot independently:
p(yk |Xv, svij) ∝ exp(wᵀkMLP(svij) + bk).",3.2.1 Local Model,[0],[0]
"(4)
5E.g., an I-tag should only follow a B-tag.",3.2.1 Local Model,[0],[0]
The sequence model uses the machinery of an RNN to share information between slots.,3.2.2 Sequence Model,[0],[0]
"At each slot k, we apply a multiple layers of LSTM cells:
hl,k, cl,k = LSTMCELLl,k(hl−1,k,hl,k−1, cl,k−1) (5) where the initial input at each slot is a concatenation of the span representation and the embedding of the previous word of the question: h0,k = [svij ;yk−1].",3.2.2 Sequence Model,[0],[0]
"Since each question slot predicts from a different set of words, we found it beneficial to use separate weights for the LSTM cells at each slot k.",3.2.2 Sequence Model,[0],[0]
"During training, we feed in the gold token at the previous slot, while at test time, we use the predicted token.",3.2.2 Sequence Model,[0],[0]
"The output distribution at slot k is computed via the final layers’ output vector hLk:
p(yk |Xv, svij) ∝",3.2.2 Sequence Model,[0],[0]
exp(wᵀkMLP(hLk),3.2.2 Sequence Model,[0],[0]
+ bk) (6),3.2.2 Sequence Model,[0],[0]
Automatic evaluation for QA-SRL parsing presents multiple challenges.,4 Initial Results,[0],[0]
"In this section, we introduce automatic metrics that can help us compare models.",4 Initial Results,[0],[0]
"In Section 6, we will report human evaluation results for our final system.",4 Initial Results,[0],[0]
Metrics We evaluate span detection using a modified notion of precision and recall.,4.1 Span Detection,[0],[0]
We count predicted spans as correct if they match any of the labeled spans in the dataset.,4.1 Span Detection,[0],[0]
Since each predicted span could potentially be a match to multiple questions (due to overlapping annotations),4.1 Span Detection,[0],[0]
we map each predicted span to one matching question in the way that maximizes measured recall using maximum bipartite matching.,4.1 Span Detection,[0],[0]
"We use both exact match and intersection-over-union (IOU) greater than 0.5 as matching criteria.
",4.1 Span Detection,[0],[0]
Results Table 4 shows span detection results on the development set.,4.1 Span Detection,[0],[0]
We report results for the span-based models at two threshold values τ,4.1 Span Detection,[0],[0]
": τ = 0.5, and τ = τ∗ maximizing F1.",4.1 Span Detection,[0],[0]
"The span-based model significantly improves over the BIO model in both precision and recall, although the difference is less pronounced under IOU matching.",4.1 Span Detection,[0],[0]
"Metrics Like all generation tasks, evaluation metrics for question generation must contend with
the fact that there are in general multiple possible valid questions for a given predicate-argument pair.",4.2 Question Generation,[0],[0]
"For instance, the question “Who did someone blame something on?” may be rephrased as “Who was blamed for something?”",4.2 Question Generation,[0],[0]
"However, due to the constrained space of possible questions defined by QA-SRL’s slot format, accuracy-based metrics can still be informative.",4.2 Question Generation,[0],[0]
"In particular, we report the rate at which the predicted question exactly matches the gold question, as well as a relaxed match where we only count the question word (WH), subject (SBJ), object (OBJ) and Miscellaneous (Misc) slots (see Table 1).",4.2 Question Generation,[0],[0]
"Finally, we report average slot-level accuracy.
",4.2 Question Generation,[0],[0]
Results Table 5 shows the results for question generation on the development set.,4.2 Question Generation,[0],[0]
"The sequential model’s exact match accuracy is significantly higher, while word-level accuracy is roughly comparable, reflecting the fact that the local model learns the slot-level posteriors.",4.2 Question Generation,[0],[0]
"Table 6 shows precision and recall for joint span detection and question generation, using exact
match for both.",4.3 Joint results,[0],[0]
"This metric is exceedingly hard, but it shows that almost 40% of predictions are exactly correct in both span and question.",4.3 Joint results,[0],[0]
"In Section 6, we use human evaluation to get a more accurate assessment of our model’s accuracy.",4.3 Joint results,[0],[0]
"Since our trained parser can produce full QASRL annotations, its predictions can be validated by the same process as in our original annotation pipeline, allowing us to focus annotation efforts towards filling potential data gaps.
",5 Data Expansion,[0],[0]
"By detecting spans at a low probability cutoff, we over-generate QA pairs for already-annotated sentences.",5 Data Expansion,[0],[0]
"Then, we filter out QA pairs whose answers overlap with answer spans in the existing annotations, or whose questions match existing questions.",5 Data Expansion,[0],[0]
What remains are candidate QA pairs which fill gaps in the original annotation.,5 Data Expansion,[0],[0]
"We pass these questions to the validation step of our crowdsourcing pipeline with n = 3 validators, resulting in new labels.
",5 Data Expansion,[0],[0]
We run this process on the training and development partitions of our dataset.,5 Data Expansion,[0],[0]
"For the development set, we use the trained model described in the previous section.",5 Data Expansion,[0],[0]
"For the training set, we use a relaxed version of jackknifing, training 5 models over 5 different folds.",5 Data Expansion,[0],[0]
"We generate 92,080 questions at a threshold of τ = 0.2.",5 Data Expansion,[0],[0]
"Since in this case many sentences have only one question, we restructure the pay to a 2c base rate with a 2c bonus per question after the first (still paying no less than 2c per question).
",5 Data Expansion,[0],[0]
"Data statistics 46,017 (50%) of questions run through the expansion step were considered valid by all three annotators.",5 Data Expansion,[0],[0]
"In total, after filtering, the expansion step increased the number of valid questions in the train and dev partitions by 20%.",5 Data Expansion,[0],[0]
"However, for evaluation, since our recall metric identifies a single question for each answer span (via bipartite matching), we filter out likely question paraphrases by removing questions in the ex-
panded development set whose answer spans have two overlaps with the answer spans of one question in the original annotations.",5 Data Expansion,[0],[0]
"After this filtering, the expanded development set we use for evaluation has 11.5% more questions than the original development set.
",5 Data Expansion,[0],[0]
"The total cost including MTurk fees was $8,210.66, for a cost of 8.9c per question, or 17.8c per valid question.",5 Data Expansion,[0],[0]
"While the cost per valid question was comparable to the initial annotation, we gathered many more negative examples (which may serve useful in future work), and this method allowed us to focus on questions that were missed in the first round and improve the exhaustiveness of the annotation (whereas it is not obvious how to make fully crowdsourced annotation more exhaustive at a comparable cost per question).
",5 Data Expansion,[0],[0]
"Retrained model We retrained our final model on the training set extended with the new valid questions, yielding modest improvements on both span detection and question generation in the development set (see Table 7).",5 Data Expansion,[0],[0]
"The span detection numbers are higher than on the original dataset, because the expanded development data captures true positives produced by the original model (and the resulting increase in precision can be traded off for recall as well).",5 Data Expansion,[0],[0]
We use the crowdsourced validation step to do a final human evaluation of our models.,6 Final Evaluation,[0],[0]
"We test 3 parsers: the span-based span detection model paired with each of the local and sequential question generation models trained on the initial dataset, and our final model (span-based span detection and sequential question generation) trained with the expanded data.
",6 Final Evaluation,[0],[0]
"Methodology On the 5,205 sentence densely annotated subset of dev and test, we generate QASRL labels with all of the models using a span detection threshold of τ = 0.2 and combine the questions with the existing data.",6 Final Evaluation,[0],[0]
"We filter out questions that fail the autocomplete grammaticality check (counting them invalid) and pass the data into the validation step, annotating each question to a total of 6 validator judgments.",6 Final Evaluation,[0],[0]
"We then compute question and span accuracy as follows: A question is considered correct if 5 out of 6 annotators consider it valid, and a span is considered correct if its generated question is correct and the span is among those selected for the question by validators.",6 Final Evaluation,[0],[0]
"We rank all questions and spans by the threshold at which they are generated, which allows us to compute accuracy at different levels of recall.
",6 Final Evaluation,[0],[0]
Results Figure 3 shows the results.,6 Final Evaluation,[0],[0]
"As expected, the sequence-based question generation models are much more accurate than the local model; this is largely because the local model generated many questions that failed the grammaticality check.",6 Final Evaluation,[0],[0]
"Furthermore, training with our expanded data results in more questions and spans generated at the same threshold.",6 Final Evaluation,[0],[0]
"If we choose a threshold value which gives a similar number of questions per sentence as were labeled in the original data annotation (2 questions / verb), question and span accuracy are 82.64% and 77.61%, respectively.
",6 Final Evaluation,[0],[0]
Table 8 shows the output of our best system on 3 randomly selected sentences from our development set (one from each domain).,6 Final Evaluation,[0],[0]
"The model was overall highly accurate—only one question and 3 spans are considered incorrect, and each mistake is nearly correct,6 even when the sentence contains a negation.
6The incorrect question “When did someone appear?” would be correct if the Prep and Misc slots were corrected to read “When did someone appear to do something?”",6 Final Evaluation,[0],[0]
"Resources and formalisms for semantics often require expert annotation and underlying syntax (Palmer et al., 2005; Baker et al., 1998; Banarescu et al., 2013).",7 Related Work,[0],[0]
"Some more recent semantic resources require less annotator training, or can be crowdsourced (Abend and Rappoport, 2013; Reisinger et al., 2015; Basile et al., 2012; Michael et al., 2018).",7 Related Work,[0],[0]
"In particular, the original QA-SRL (He et al., 2015) dataset is annotated by freelancers, while we developed streamlined crowdsourcing approaches for more scalable annotation.
",7 Related Work,[0],[0]
"Crowdsourcing has also been used for indirectly annotating syntax (He et al., 2016; Duan et al., 2016), and to complement expert annotation of SRL (Wang et al., 2018).",7 Related Work,[0],[0]
"Our crowdsourcing approach draws heavily on that of Michael et al.
(2018), with automatic two-stage validation for the collected question-answer pairs.
",7 Related Work,[0],[0]
"More recently, models have been developed for these newer semantic resources, such as UCCA (Teichert et al., 2017) and Semantic Proto-Roles (White et al., 2017).",7 Related Work,[0],[0]
"Our work is the first highquality parser for QA-SRL, which has several unique modeling challenges, such as its highly structured nature and the noise in crowdsourcing.
",7 Related Work,[0],[0]
"Several recent works have explored neural models for SRL tasks (Collobert and Weston, 2007; FitzGerald et al., 2015; Swayamdipta et al., 2017; Yang and Mitchell, 2017), many of which employ a BIO encoding (Zhou and Xu, 2015; He et al., 2017).",7 Related Work,[0],[0]
"Recently, span-based models have proven to be useful for question answering (Lee et al., 2016) and coreference resolution (Lee et al., 2017), and PropBank SRL (He et al., 2018).",7 Related Work,[0],[0]
"In this paper, we demonstrated that QA-SRL can be scaled to large datasets, enabling a new methodology for labeling and producing predicate-argument structures at a large scale.",8 Conclusion,[0],[0]
"We presented a new, scalable approach for crowdsourcing QA-SRL, which allowed us to collect QA-SRL Bank 2.0, a new dataset covering over 250,000 question-answer pairs from over 64,000 sentences, in just 9 days.",8 Conclusion,[0],[0]
We demonstrated the utility of this data by training the first parser which is able to produce high-quality QA-SRL structures.,8 Conclusion,[0],[0]
"Finally, we demonstrated that the validation stage of our crowdsourcing pipeline, in combination with our parser tuned for recall, can be used to add new annotations to the dataset, increasing recall.",8 Conclusion,[0],[0]
The crowdsourcing funds for QA-SRL Bank 2.0 was provided by the Allen Institute for Artificial Intelligence.,Acknowledgements,[0],[0]
This research was supported in part by the ARO (W911NF-16-1-0121),Acknowledgements,[0],[0]
"the NSF (IIS1252835, IIS-1562364), a gift from Amazon, and
an Allen Distinguished Investigator Award.",Acknowledgements,[0],[0]
We would like to thank Gabriel Stanovsky and Mark Yatskar for their helpful feedback.,Acknowledgements,[0],[0]
"We present a new large-scale corpus of Question-Answer driven Semantic Role Labeling (QA-SRL) annotations, and the first high-quality QA-SRL parser.",abstractText,[0],[0]
"Our corpus, QA-SRL Bank 2.0, consists of over 250,000 question-answer pairs for over 64,000 sentences across 3 domains and was gathered with a new crowd-sourcing scheme that we show has high precision and good recall at modest cost.",abstractText,[0],[0]
We also present neural models for two QA-SRL subtasks: detecting argument spans for a predicate and generating questions to label the semantic relationship.,abstractText,[0],[0]
The best models achieve question accuracy of 82.6% and span-level accuracy of 77.6% (under human evaluation) on the full pipelined QASRL prediction task.,abstractText,[0],[0]
"They can also, as we show, be used to gather additional annotations at low cost.",abstractText,[0],[0]
Large-Scale QA-SRL Parsing,title,[0],[0]
"Querying a database to retrieve an answer, telling a robot to perform an action, or teaching a computer to play a game are tasks requiring communication with machines in a language interpretable by them.",1 Introduction,[0],[0]
Semantic parsing addresses the specific task of learning to map natural language (NL) to machine interpretable formal meaning representations.,1 Introduction,[0],[0]
"Traditionally, sentences are converted into logical form grounded in the symbols of some fixed ontology or relational database.
",1 Introduction,[0],[0]
"Approaches for learning semantic parsers have been for the most part supervised, using annotated training data consisting of sentences and their corresponding logical forms (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Kwiatkowski et al., 2010).",1 Introduction,[0],[0]
"More recently, alternative forms of supervision have been proposed to alleviate the annotation burden, e.g., by learning from conversational logs (Artzi and Zettlemoyer, 2011), from sentences paired with system behavior (Chen and Mooney, 2011; Goldwasser and Roth,
2011; Artzi and Zettlemoyer, 2013), via distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), from questions (Goldwasser et al., 2011; Poon, 2013; Fader et al., 2013), and questionanswer pairs (Clarke et al., 2010; Liang et al., 2011).",1 Introduction,[0],[0]
"Indeed, methods which learn from question-answer pairs have been gaining momentum as a means of scaling semantic parsers to large, open-domain problems (Kwiatkowski et al., 2013; Berant et al., 2013; Berant and Liang, 2014; Yao and Van Durme, 2014).",1 Introduction,[0],[0]
"Figure 1 shows an example of a question, its annotated logical form, and answer (or denotation).
",1 Introduction,[0],[0]
"In this paper, we build a semantic parser that does not require example annotations or question-answer pairs but instead learns from a large knowledge base (KB) and web-scale corpora.",1 Introduction,[0],[0]
"Specifically, we exploit Freebase, a large community-authored knowledge base that spans many sub-domains and stores real world facts in graphical format, and parsed sentences from a large corpus.",1 Introduction,[0],[0]
We formulate semantic parsing as a graph matching problem.,1 Introduction,[0],[0]
"We convert the output of an open-domain combinatory categorial grammar (CCG) parser (Clark and Curran, 2007) into a graphical representation and subsequently map it onto Freebase.",1 Introduction,[0],[0]
The parser’s graphs (also called ungrounded graphs) are mapped to all possible Freebase subgraphs (also called grounded graphs) by replacing edges and nodes with relations and types in Freebase.,1 Introduction,[0],[0]
Each grounded graph corresponds to a unique grounded logical query.,1 Introduction,[0],[0]
"During learning, our semantic parser is trained to identify which KB subgraph best corresponds to the NL graph.",1 Introduction,[0],[0]
"Problem-
377
Transactions of the Association for Computational Linguistics, 2 (2014) 377–392.",1 Introduction,[0],[0]
Action Editor: Noah Smith.,1 Introduction,[0],[0]
Submitted 3/2014; Revised 6/2014; Published 10/2014.,1 Introduction,[0],[0]
"c©2014 Association for Computational Linguistics.
capital(Austin)∧UNIQUE(Austin)∧ capital.of.arg1(e,Austin)∧ capital.of.arg2(e,Texas) (a) Semantic parse of the sentence Austin is the capital of Texas.
atically, ungrounded graphs may give rise to many grounded graphs.",1 Introduction,[0],[0]
"Since we do not make use of manual annotations of sentences or question-answer pairs, we do not know which grounded graphs are correct.",1 Introduction,[0],[0]
"To overcome this, we rely on comparisons between denotations of natural language queries and related Freebase queries as a form of weak supervision in order to learn the mapping between NL and KB graphs.
",1 Introduction,[0],[0]
Figure 2 illustrates our approach for the sentence Austin is the capital of Texas.,1 Introduction,[0],[0]
From the CCG syntactic derivation (which we omit here for the sake of brevity) we obtain a semantic parse (Figure 2a) and convert it to an ungrounded graph (Figure 2b).,1 Introduction,[0],[0]
"Next, we select an entity from the graph and replace it with a variable x, creating a graph corresponding to the query What is the capital of Texas?",1 Introduction,[0],[0]
(Figure 2c).,1 Introduction,[0],[0]
"The math function UNIQUE on Austin in Figure 2b indi-
cates Austin is the only value of x which can satisfy the query graph in Figure 2c.",1 Introduction,[0],[0]
"Therefore, the denotation1 of the NL query graph is {AUSTIN}.",1 Introduction,[0],[0]
Figure 2d shows two different groundings of the query graph in the Freebase KB.,1 Introduction,[0],[0]
We obtain these by replacing edges and nodes in the query graph with Freebase relations and types.,1 Introduction,[0],[0]
We use the denotation of the NL query as a form of weak supervision to select the best grounded graph.,1 Introduction,[0],[0]
"Under the constraint that the denotation of a Freebase query should be the same as the denotation of the NL query, the graph on the left hand-side of Figure 2d is chosen as the correct grounding.
",1 Introduction,[0],[0]
Experimental results on two benchmark datasets consisting of questions to Freebase — FREE917,1 Introduction,[0],[0]
"(Cai and Yates, 2013) and WEBQUESTIONS (Berant
1The denotation of a graph is the set of feasible values for the nodes marked with TARGET.
",1 Introduction,[0],[0]
"et al., 2013) — show that our semantic parser improves over state-of-the-art approaches.",1 Introduction,[0],[0]
"Our contributions include: a novel graph-based method to convert natural language sentences to grounded semantic parses which exploits the similarities in the topology of knowledge graphs and linguistic structure, together with the ability to train using a wide range of features; a proposal to learn from a large scale web corpus, without question-answer pairs, based on denotations of queries from natural language statements as weak supervision; and the development of a scalable semantic parser which besides Freebase uses CLUEWEB09 for training, a corpus of 503.9 million webpages.",1 Introduction,[0],[0]
Our semantic parser can be downloaded from http://sivareddy.in/ downloads.,1 Introduction,[0],[0]
Our goal is to build a semantic parser which maps a natural language sentence to a logical form that can be executed against Freebase.,2 Framework,[0],[0]
"We begin with CLUEWEB09, a web-scale corpus automatically annotated with Freebase entities (Gabrilovich et al., 2013).",2 Framework,[0],[0]
We extract the sentences containing at least two entities linked by a relation in Freebase.,2 Framework,[0],[0]
"We parse these sentences using a CCG syntactic parser, and build semantic parses from the syntactic output.",2 Framework,[0],[0]
Semantic parses are then converted to semantic graphs which are subsequently grounded to Freebase.,2 Framework,[0],[0]
Grounded graphs can be easily converted to a KB query deterministically.,2 Framework,[0],[0]
During training we learn which grounded graphs correspond best to the natural language input.,2 Framework,[0],[0]
"In the following, we provide a brief introduction to Freebase and its graph structure.",2 Framework,[0],[0]
"Next, we explain how we obtain semantic parses from CCG (Section 2.2), how we convert them to graphs (Section 2.3), and ground them in Freebase (Section 2.4).",2 Framework,[0],[0]
Section 3 presents our learning algorithm.,2 Framework,[0],[0]
Freebase consists of 42 million entities and 2.5 billion facts.,2.1 The Freebase Knowledge Graph,[0],[0]
A fact is defined by a triple containing two entities and a relation between them.,2.1 The Freebase Knowledge Graph,[0],[0]
"Entities represent real world concepts, and edges represent relations, thus forming a graph-like structure.
",2.1 The Freebase Knowledge Graph,[0],[0]
"A Freebase subgraph is shown in Figure 3 with
rectangles denoting entities.",2.1 The Freebase Knowledge Graph,[0],[0]
"In addition to simple facts, Freebase encodes complex facts, represented by multiple edges (e.g., the edges connecting BARACK OBAMA, COLUMBIA UNIVERSITY and BACHELOR OF ARTS).",2.1 The Freebase Knowledge Graph,[0],[0]
"Complex facts have intermediate nodes called mediator nodes (circles in Figure 3 with the same identifiers e.g., m and n).",2.1 The Freebase Knowledge Graph,[0],[0]
"For reasons of uniformity, we assume that simple facts are also represented via mediator nodes and split single edges into two with each subedge going from the mediator node to the target node (see person.nationality.arg1 and person.nationality.arg2 in Figure 3).",2.1 The Freebase Knowledge Graph,[0],[0]
"Finally, Freebase also has entity types defining is-a relations.",2.1 The Freebase Knowledge Graph,[0],[0]
"In Figure 3 types are represented by rounded rectangles (e.g., BARACK OBAMA is of type US president, and COLUMBIA UNIVERSITY is of type education.university).",2.1 The Freebase Knowledge Graph,[0],[0]
"The graph like structure of Freebase inspires us to create a graph like structure for natural language, and learn a mapping between them.",2.2 Combinatory Categorial Grammar,[0],[0]
"To do this we take advantage of the representational power of Combinatory Categorial Grammar (Steedman, 2000).",2.2 Combinatory Categorial Grammar,[0],[0]
"CCG is a linguistic formalism that tightly couples syntax and semantics, and can be used to model a wide range of language phenom-
1
ena.",2.2 Combinatory Categorial Grammar,[0],[0]
"CCG is well known for capturing long-range dependencies inherent in constructions such as coordination, extraction, raising and control, as well as standard local predicate-argument dependencies (Clark et al., 2002), thus supporting wide-coverage semantic analysis.",2.2 Combinatory Categorial Grammar,[0],[0]
"Moreover, due to the transparent interface between syntax and semantics, it is relatively straightforward to built a semantic parse for a sentence from its corresponding syntactic derivation tree (Bos et al., 2004).
",2.2 Combinatory Categorial Grammar,[0],[0]
"In our case, the choice of syntactic parser is motivated by the scale of our problem; the parser must be broad-coverage and robust enough to handle a web-sized corpus.",2.2 Combinatory Categorial Grammar,[0],[0]
"For these reasons, we rely on the C&C parser (Clark and Curran, 2004), a generalpurpose CCG parser, to obtain syntactic derivations.",2.2 Combinatory Categorial Grammar,[0],[0]
"To our knowledge, we present the first attempt to use a CCG parser trained on treebanks for grounded semantic parsing.",2.2 Combinatory Categorial Grammar,[0],[0]
"Most previous work has induced task-specific CCG grammars (Zettlemoyer and Collins, 2005, 2007; Kwiatkowski et al., 2010).",2.2 Combinatory Categorial Grammar,[0],[0]
"An example CCG derivation is shown in Figure 4.
",2.2 Combinatory Categorial Grammar,[0],[0]
"Semantic parses are constructed from syntactic CCG parses, with semantic composition being guided by the CCG syntactic derivation.2",2.2 Combinatory Categorial Grammar,[0],[0]
"We use a neo-Davidsonian (Parsons, 1990) semantics to represent semantic parses.3 Each word has a semantic category based on its syntactic category and part of speech.",2.2 Combinatory Categorial Grammar,[0],[0]
"For example, the syntactic category for directed is (S\NP)/NP, i.e., it
2See Bos et al. (2004) for a detailed introduction to semantic representation using CCG.",2.2 Combinatory Categorial Grammar,[0],[0]
"3Neo-Davidsonian semantics is a form of first-order logic that uses event identifiers (e) to connect verb predicates and their subcategorized arguments through conjunctions.
",2.2 Combinatory Categorial Grammar,[0],[0]
"(a) Ungrounded graph
(b) Grounded graph
Figure 5: Graph representations for the sentence Cameron directed Titanic in 1997.
takes two argument NPs and becomes S. To represent its semantic category, we use a lambda term λyλx.",2.2 Combinatory Categorial Grammar,[0],[0]
"directed.arg1(e,x)∧ directed.arg2(e,y), where e identifies the event of directed, and x and y are arguments corresponding to the NPs in the syntactic category.
",2.2 Combinatory Categorial Grammar,[0],[0]
We obtain semantic categories automatically using the indexed syntactic categories provided by the C&C parser.,2.2 Combinatory Categorial Grammar,[0],[0]
The latter reveal the bindings of basic constituent categories in more complex categories.,2.2 Combinatory Categorial Grammar,[0],[0]
"For example, in order to convert ((S\NP)\(S\NP))/NP to its semantic category, we must know whether all NPs have the same referent and thus use the same variable name.",2.2 Combinatory Categorial Grammar,[0],[0]
"The indexed category ((Se\NPx)\(Se\NPx))/NPy reveals that there are only two different NPs, x and y, and that one of them (i.e., x) is shared across two subcategories.",2.2 Combinatory Categorial Grammar,[0],[0]
"We discuss the details of semantic category construction in the Appendix.
",2.2 Combinatory Categorial Grammar,[0],[0]
"Apart from n-ary predicates representing events (mostly verbs), we also use unary predicates representing types in language (mostly common nouns and noun modifiers).",2.2 Combinatory Categorial Grammar,[0],[0]
"For example, capital(Austin) indicates Austin is of type capital.",2.2 Combinatory Categorial Grammar,[0],[0]
"Prepositions, adjectives and adverbs are represented by predicates lexicalized with their head words to provide more information (see capital.of.arg1 instead of of.arg1 in Figure 2a).",2.2 Combinatory Categorial Grammar,[0],[0]
We will now illustrate how we create ungrounded semantic graphs from CCG-derived semantic parses.,2.3 Ungrounded Semantic Graphs,[0],[0]
"Figure 5a displays the ungrounded graph for the sen-
tence Cameron directed Titanic in 1997.",2.3 Ungrounded Semantic Graphs,[0],[0]
"In order to construct ungrounded graphs topologically similar to Freebase, we define five types of nodes:
Word Nodes (Ovals)",2.3 Ungrounded Semantic Graphs,[0],[0]
Word nodes are denoted by ovals.,2.3 Ungrounded Semantic Graphs,[0],[0]
"They represent natural language words (e.g., directed in Figure 5a, capital and state in Figure 6b).",2.3 Ungrounded Semantic Graphs,[0],[0]
Word nodes are connected to other word nodes via syntactic dependencies.,2.3 Ungrounded Semantic Graphs,[0],[0]
"For readability, we do not show inter-word dependencies.
",2.3 Ungrounded Semantic Graphs,[0],[0]
"Entity Nodes (Rectangles) Entity nodes are denoted by rectangles and represent entities e.g., Cameron in Figure 5a.",2.3 Ungrounded Semantic Graphs,[0],[0]
"In cases where an entity is not known, we use variables e.g., x in Figure 6a.",2.3 Ungrounded Semantic Graphs,[0],[0]
"Entity variables are connected to their corresponding word nodes from which they originate by dotted links e.g., x in Figure 6a is connected to the word node who.
",2.3 Ungrounded Semantic Graphs,[0],[0]
Mediator Nodes (Circles) Mediator nodes are denoted by circles and represent events in language.,2.3 Ungrounded Semantic Graphs,[0],[0]
"They connect pairs of entities which participate in an event forming a clique (see the entities Cameron, Titanic and 1997 in Figure 5a).",2.3 Ungrounded Semantic Graphs,[0],[0]
We define an edge as a link that connects any two entities via a mediator.,2.3 Ungrounded Semantic Graphs,[0],[0]
"The subedge of an edge i.e., the link between a mediator and an entity, corresponds to the predi-
cate denoting the event and taking the entity as its argument (e.g. directed.arg1 links e and Cameron in Figure 5a).",2.3 Ungrounded Semantic Graphs,[0],[0]
"Mediator nodes are connected to their corresponding word nodes from which they originate by dotted links e.g. mediators in Figure 5a are connected to word node directed.
",2.3 Ungrounded Semantic Graphs,[0],[0]
Type nodes (Rounded rectangles),2.3 Ungrounded Semantic Graphs,[0],[0]
Type nodes are denoted by rounded rectangles.,2.3 Ungrounded Semantic Graphs,[0],[0]
They represent unary predicates in natural language.,2.3 Ungrounded Semantic Graphs,[0],[0]
In Figure 6b type nodes capital and capital.state are attached to Austin denoting Austin is of type capital and capital.state.,2.3 Ungrounded Semantic Graphs,[0],[0]
"Type nodes are also connected to their corresponding word nodes from which they originate by dotted links e.g. type node capital.state and word node state in Figure 6b.
",2.3 Ungrounded Semantic Graphs,[0],[0]
Math nodes (Diamonds) Math nodes are denoted by diamonds.,2.3 Ungrounded Semantic Graphs,[0],[0]
They describe functions to be applied on the nodes/subgraphs they attach to.,2.3 Ungrounded Semantic Graphs,[0],[0]
The function TARGET attaches to the entity variable of interest.,2.3 Ungrounded Semantic Graphs,[0],[0]
"For example, the graph in Figure 6a represents the question Who directed The Nutty Professor?.",2.3 Ungrounded Semantic Graphs,[0],[0]
"Here, TARGET attaches to x representing the word who.",2.3 Ungrounded Semantic Graphs,[0],[0]
UNIQUE attaches to the entity variable modified by the definite article the.,2.3 Ungrounded Semantic Graphs,[0],[0]
"In Figure 6b, UNIQUE attaches to Austin implying that only Austin satisfies the graph.",2.3 Ungrounded Semantic Graphs,[0],[0]
"Finally, COUNT attaches to entity nodes which have to be counted.",2.3 Ungrounded Semantic Graphs,[0],[0]
"For the sentence Julie Andrews has appeared in 40 movies in Figure 7, the KB could either link Julie Andrews and 40, with type node movies matching the grounded type integer, or it could link Julie Andrews to each movie she acted in and the count of these different movies add to 40.",2.3 Ungrounded Semantic Graphs,[0],[0]
"In anticipation of this ambiguity, we generate two semantic parses resulting in two ungrounded graphs (see Figures 7a and 7b).",2.3 Ungrounded Semantic Graphs,[0],[0]
"We generate all possible grounded graphs corresponding to each ungrounded graph, and leave it up to the learning to decide which ones the KB prefers.",2.3 Ungrounded Semantic Graphs,[0],[0]
"We ground semantic graphs in Freebase by mapping edge labels to relations, type nodes to entity types, and entity nodes to Freebase entities.",2.4 Grounded Semantic Graphs,[0],[0]
Math nodes remain unchanged.,2.4 Grounded Semantic Graphs,[0],[0]
"Though word nodes are not present in Freebase, we retain them in our grounded graphs to extract sophisticated features based on words and grounded predicates.
",2.4 Grounded Semantic Graphs,[0],[0]
"appeared movies movies
Julie Andrews
e 40
appeared .arg1",2.4 Grounded Semantic Graphs,[0],[0]
"appeared.in
typ e
appeared.arg1(e, JulieAndrews) ∧ appeared.in(e, 40) ∧ movies(40)
(a) Ungrounded Graph
appeared movies movies
Julie Andrews
e z count 40
appeared .arg1
appeared .in
",2.4 Grounded Semantic Graphs,[0],[0]
"typ e
appeared.arg1(e, JulieAndrews) ∧ appeared.in(e, z) ∧ movies(z) ∧ count(z, 40)
(b) Alternate Ungrounded Graph
appeared film movies
Julie Andrews
m z count 40
performance .actor performance .film
typ e
performance.actor(m, JulieAndrews)",2.4 Grounded Semantic Graphs,[0],[0]
"∧ performance.film(m, z) ∧ film(z) ∧ count(z, 40)
(c) Grounded graph
Figure 7: Graph representations for the sentence Julie Andrews has appeared in 40 movies.",2.4 Grounded Semantic Graphs,[0],[0]
"Ungrounded graph (a) directly connects Julie Andrews and 40, whereas graph (b) uses the math function COUNT.",2.4 Grounded Semantic Graphs,[0],[0]
"Ungrounded graph (b) and grounded graph (c) have similar topology.
",2.4 Grounded Semantic Graphs,[0],[0]
"Entity nodes Previous approaches (Cai and Yates, 2013; Berant et al., 2013; Kwiatkowski et al., 2013) use a manual lexicon or heuristics to ground named entities to Freebase entities.",2.4 Grounded Semantic Graphs,[0],[0]
"Fortunately, CLUEWEB09 sentences have been automatically annotated with Freebase entities, so we use these annotations to ground proper names to Freebase entities (denoted by uppercase words)",2.4 Grounded Semantic Graphs,[0],[0]
"e.g., Cameron in Figure 5a is grounded to Freebase entity CAMERON in Figure 5b.",2.4 Grounded Semantic Graphs,[0],[0]
"Common nouns like movies (see Figure 7b) are left as variables to be instantiated by the entities satisfying the graph.
",2.4 Grounded Semantic Graphs,[0],[0]
Type nodes Type nodes are grounded to Freebase entity types.,2.4 Grounded Semantic Graphs,[0],[0]
"Type nodes capital and capital.state in Figure 6b are grounded to all possible types of Austin (e.g., location.city, location.capital city, book.book subject, broadcast.genre).",2.4 Grounded Semantic Graphs,[0],[0]
"In cases where entity nodes are not grounded, (e.g., z in Figure 7b),
employees employees 120000
e
Alcoa has e
e
2007
type
has .ar
g1
ha s.a rg2
h a s.in
h a s. ar g 2
has.arg1
has.in
has.arg1(e,Alcoa)",2.4 Grounded Semantic Graphs,[0],[0]
"∧ has.arg2(e, 120000)",2.4 Grounded Semantic Graphs,[0],[0]
"∧ has.in(e, 2007)",2.4 Grounded Semantic Graphs,[0],[0]
"∧ employees(120000)
(a) Ungrounded Graph
employees type.int 119000
m
Alcoa has m
m
2007
type
em plo
yer .nu
mb er
of em
plo yee
s
.in",2.4 Grounded Semantic Graphs,[0],[0]
"ver
se
m ea su rem
en t u
nit
.d at ed
int eg er
.n",2.4 Grounded Semantic Graphs,[0],[0]
"um
be r
m",2.4 Grounded Semantic Graphs,[0],[0]
"ea su re m en
t u n",2.4 Grounded Semantic Graphs,[0],[0]
"it
.d a te d in te",2.4 Grounded Semantic Graphs,[0],[0]
g,2.4 Grounded Semantic Graphs,[0],[0]
er .y,2.4 Grounded Semantic Graphs,[0],[0]
"ea r
m",2.4 Grounded Semantic Graphs,[0],[0]
"ea su re m en
t u n",2.4 Grounded Semantic Graphs,[0],[0]
"it
.d a te d in te",2.4 Grounded Semantic Graphs,[0],[0]
g,2.4 Grounded Semantic Graphs,[0],[0]
"er .n u m b er
employer.number
of employees .inverse
measurement unit .dated integer .year
employer.number of employees.inverse(m,Alcoa) ∧ measurement unit.dated integer.number(m, 119000)",2.4 Grounded Semantic Graphs,[0],[0]
"∧ measurement unit.dated integer.year(m, 2007)",2.4 Grounded Semantic Graphs,[0],[0]
"∧
type.int(119000)
(b) Grounded Graph
Figure 8: Graph representations for Alcoa has 120000 employees in 2007.
",2.4 Grounded Semantic Graphs,[0],[0]
"we use an automatically constructed lexicon which maps ungrounded types to grounded ones (see Section 4.2 for details).
",2.4 Grounded Semantic Graphs,[0],[0]
Edges An edge between two entities is grounded using all edges linking the two entities in the knowledge graph.,2.4 Grounded Semantic Graphs,[0],[0]
"For example, to ground the edge between Titanic and Cameron in Figure 5, we use the following edges linking TITANIC and CAMERON in Freebase: (film.directed by.arg1, film.directed by.arg2), (film.produced by.arg1, film.produced by.arg2).",2.4 Grounded Semantic Graphs,[0],[0]
"If only one entity is grounded, we use all possible edges from this grounded entity.",2.4 Grounded Semantic Graphs,[0],[0]
"If no entity is grounded, we use a mapping lexicon which is automatically created as described in Section 4.2.",2.4 Grounded Semantic Graphs,[0],[0]
"Given an ungrounded graph with n edges, there are O((k+ 1)n) possible grounded graphs, with k being the grounded edges in the knowledge graph for each ungrounded edge together with an additional empty (no) edge.
",2.4 Grounded Semantic Graphs,[0],[0]
"Mediator nodes In an ungrounded graph, mediator nodes represent semantic event identifiers.",2.4 Grounded Semantic Graphs,[0],[0]
"In the grounded graph, they represent Freebase fact identifiers.",2.4 Grounded Semantic Graphs,[0],[0]
"Fact identifiers help distinguish if neighboring edges belong to a single complex fact, which may or may not be coextensive with an ungrounded event.",2.4 Grounded Semantic Graphs,[0],[0]
"In Figure 8a, the edges corresponding to the event identifier e are grounded to a single complex fact in Figure 8b, with the fact identifier m. However, in Figure 5a, the edges of the ungrounded event e are grounded to different Freebase facts, distinguished in Figure 5b by the identifiers m and",2.4 Grounded Semantic Graphs,[0],[0]
"n. Furthermore,
the edge in 5a between CAMERON and 1997 is not grounded in 5b, since no Freebase edge exists between the two entities.
",2.4 Grounded Semantic Graphs,[0],[0]
"We convert grounded graphs to SPARQL queries, but for readability we only show logical expressions.",2.4 Grounded Semantic Graphs,[0],[0]
The conversion is deterministic and is exactly the inverse of the semantic parse to graph conversion (Section 2.3).,2.4 Grounded Semantic Graphs,[0],[0]
"Wherever a node/edge is instantiated with a grounded entity/type/relation in Freebase, we use them in the grounded parse (e.g., type node capital.state in Figure 6b becomes location.capital city).",2.4 Grounded Semantic Graphs,[0],[0]
Math function TARGET is useful in retrieving instantiations of entity variables of interest (see Figure 6a).,2.4 Grounded Semantic Graphs,[0],[0]
A natural language sentence may give rise to several grounded graphs.,3 Learning,[0],[0]
But only one (or a few) of them will be a faithful representation of the sentence in Freebase.,3 Learning,[0],[0]
"We next describe our algorithm for finding the best Freebase graph for a given sentence, our learning model, and the features it uses.",3 Learning,[0],[0]
"Freebase has a large number of relations and entities, and as a result there are many possible grounded graphs g for each ungrounded graph u. We construct and score graphs incrementally, traversing each node in the ungrounded graph and matching its edges and types in Freebase.",3.1 Algorithm,[0],[0]
"Given a NL sentence s, we construct from its CCG syntactic derivation all corresponding ungrounded graphs u. Using a beam search procedure (described in Section 4.2), we find the best scoring graphs (ĝ, û), maximizing over different graph configurations (g,u) of s:
(ĝ, û) =",3.1 Algorithm,[0],[0]
"argmax g,u
Φ(g,u,s,K B) ·θ (1)
We define the score of (ĝ, û) as the dot product between a high dimensional feature representation Φ = (Φ1, . .",3.1 Algorithm,[0],[0]
.Φm),3.1 Algorithm,[0],[0]
"and a weight vector θ (see Section 3.3 for details on the features we employ).
",3.1 Algorithm,[0],[0]
"We estimate the weights θ using the averaged structured perceptron algorithm (Collins, 2002).",3.1 Algorithm,[0],[0]
"As shown in Algorithm 1, the perceptron makes several passes over sentences, and in each iteration it computes the best scoring (ĝ, û) among the candidate graphs for a given sentence.",3.1 Algorithm,[0],[0]
"In line 6, the algorithm updates θ with the difference (if any) be-
Algorithm 1: Averaged Structured Perceptron Input: Training sentences: {si}Ni=1
1 θ← 0 2 for t← 1 . .",3.1 Algorithm,[0],[0]
.T do 3 for i← 1 . .,3.1 Algorithm,[0],[0]
".N do 4 (ĝi, ûi) = argmax
gi,ui Φ(gi,ui,si,K B) ·θ
5 if (u+i ,g + i ) 6=",3.1 Algorithm,[0],[0]
"(ûi, ĝi) then 6 θ← θ+Φ(g+i ,u+i ,si,K B)−Φ(ĝi, ûi,si,K B) 7 return 1T ∑ T t=i 1 N ∑ N i=1",3.1 Algorithm,[0],[0]
"θit
tween the feature representations of the best scoring graph (ĝ, û) and the gold standard graph (g+,u+).",3.1 Algorithm,[0],[0]
The goal of the algorithm is to rank gold standard graphs higher than the any other graphs.,3.1 Algorithm,[0],[0]
The final weight vector θ is the average of weight vectors over T iterations and N sentences.,3.1 Algorithm,[0],[0]
"This averaging procedure avoids overfitting and produces more stable results (Collins, 2002).
",3.1 Algorithm,[0],[0]
"As we do not make use of question-answer pairs or manual annotations of sentences, gold standard graphs (g+,u+) are not available.",3.1 Algorithm,[0],[0]
"In the following, we explain how we approximate them by relying on graph denotations as a form of weak supervision.",3.1 Algorithm,[0],[0]
"Let u be an ungrounded semantic graph of s. We select an entity E in u, replace it with a variable x, and make it a target node.",3.2 Selecting Surrogate Gold Graphs,[0],[0]
Let u+ represent the resulting ungrounded graph.,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"Next, we obtain all grounded graphs g+ which correspond to u+ such that the denotations",3.2 Selecting Surrogate Gold Graphs,[0],[0]
[[u+]]K B =,3.2 Selecting Surrogate Gold Graphs,[0],[0]
[[g+]]N L .,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"We use these surrogate graphs g+as gold standard, and the pairs (u+,g+) for model training.",3.2 Selecting Surrogate Gold Graphs,[0],[0]
There is considerable latitude in choosing which entity E to replace.,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"This can be done randomly, according to entity frequency, or some other criterion.",3.2 Selecting Surrogate Gold Graphs,[0],[0]
We found that substituting the entity with the most connections to other entities in the sentence works well in practice.,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"All the entities that can replace x in u+ to constitute a valid fact in Freebase will be the denotation of u+, [[u+]]N L .",3.2 Selecting Surrogate Gold Graphs,[0],[0]
While it is straightforward to compute,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"[[g+]]K B , it is hard to compute",3.2 Selecting Surrogate Gold Graphs,[0],[0]
[[u+]]N L because of the mismatch between our natural language semantic language and the Freebase query language.,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"To ensure that graphs u+ and g+ have the same denotations, we impose the following constraints:
Constraint 1 If the math function UNIQUE is attached to the entity being replaced in the ungrounded graph, we assume the denotation of u+ contains only that entity.",3.2 Selecting Surrogate Gold Graphs,[0],[0]
"For example, in Figure 2b, we replace Austin by x, and thus assume [[u+]]N L = {AUSTIN}.4 Any grounded graph which results in [[g+]]K B = {AUSTIN} will be considered a surrogate gold graph.",3.2 Selecting Surrogate Gold Graphs,[0],[0]
"This allows us to learn entailment relations, e.g., capital.of should be grounded to location.capital (left hand-side graph in Figure 2d) and not to location.containedby which results in all locations in Texas (right hand-side graph in Figure 2d).
",3.2 Selecting Surrogate Gold Graphs,[0],[0]
Constraint 2,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"If the target entity node is a number, we select the Freebase graphs with denotation close to this number.",3.2 Selecting Surrogate Gold Graphs,[0],[0]
"For example, in Figure 8a if 120,000 is replaced by x, and we assume",3.2 Selecting Surrogate Gold Graphs,[0],[0]
"[[u+]]N L = {120,000}.",3.2 Selecting Surrogate Gold Graphs,[0],[0]
"However, the grounded graph 8b retrieves",3.2 Selecting Surrogate Gold Graphs,[0],[0]
"[[g+]]K B = {119,000}.",3.2 Selecting Surrogate Gold Graphs,[0],[0]
We treat this as correct if βγ ∈,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"[0.9,1.1] where β ∈",3.2 Selecting Surrogate Gold Graphs,[0],[0]
[[u+]]N L and γ ∈,3.2 Selecting Surrogate Gold Graphs,[0],[0]
[[g+]]K B .,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"Integers can either occur directly in relation with an entity as in Figure 8b, or must be enumerated as in Figure 7c.
",3.2 Selecting Surrogate Gold Graphs,[0],[0]
Constraint 3,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"If the target entity node is a date, we select the grounded graph which results in the smallest set containing the date based on the intuition that most sentences in the data describe specific rather than general events.
",3.2 Selecting Surrogate Gold Graphs,[0],[0]
Constraint 4,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"If none of the above constraints apply to the target entity E, we know E ∈",3.2 Selecting Surrogate Gold Graphs,[0],[0]
"[[u+]]N L , and hence we select the grounded graphs which satisfy E ∈",3.2 Selecting Surrogate Gold Graphs,[0],[0]
[[g+]]K B as surrogate gold graphs.,3.2 Selecting Surrogate Gold Graphs,[0],[0]
"Our feature vector Φ(g,u,s,K B) denotes the features extracted from a sentence s and its corresponding graphs u and g with respect to a knowledge base K B .",3.3 Features,[0],[0]
"The elements of the vector (φ1, φ2, . . . )",3.3 Features,[0],[0]
take integer values denoting the number of times a feature appeared.,3.3 Features,[0],[0]
"We devised the following broad feature classes:
Lexical alignments Since ungrounded graphs are similar in topology to grounded graphs, we extract ungrounded and grounded edge 4We also remove UNIQUE attached to x to exactly mimic the test time setting.
and type alignments.",3.3 Features,[0],[0]
"So, from graphs 5a and 5b, we obtain the edge alignment φedge(directed.arg1, directed.arg2, film.directed by.arg2, film.directed by.arg1) and the subedge alignments φedge(directed.arg1,film.directed by.arg2) and φedge(directed.arg2,film.directed by.arg1).",3.3 Features,[0],[0]
"In a similar fashion we extract type alignments (e.g., φtype(capital,location.city)).
",3.3 Features,[0],[0]
"Contextual features In addition to lexical alignments, we also use contextual features which essentially record words or word combinations surrounding grounded edge labels.",3.3 Features,[0],[0]
"Feature φevent records an event word and its grounded predicates (e.g., in Figure 7c we extract features φevent(appear,performance.film) and φevent(appear,performance.actor).",3.3 Features,[0],[0]
"Feature φarg records a predicate and its argument words (e.g., φarg(performance.film,movie) in Figure 7c).",3.3 Features,[0],[0]
Word combination features are extracted from the parser’s dependency output.,3.3 Features,[0],[0]
"The feature φdep records a predicate and the dependencies of its event word (e.g., from the grounded version of Figure 6b we extract features φdep(location.state.capital.arg1,capital,state) and φdep(location.state.capital.arg2,capital,state)).",3.3 Features,[0],[0]
"Using such features, we are able to handle multiword predicates.
",3.3 Features,[0],[0]
"Lexical similarity We count the number of word stems5 shared by grounded and ungrounded edge labels e.g., in Figure 5 directed.arg1 and film.directed by.arg2 have one stem overlap (ignoring the argument labels arg1 and arg2).",3.3 Features,[0],[0]
"For a grounded graph, we compute φstem, the aggregate stem overlap count over all its grounded and ungrounded edge labels.",3.3 Features,[0],[0]
We did not incorporate WordNet/Wiktionarybased lexical similarity features but these were found fruitful in Kwiatkowski et al. (2013).,3.3 Features,[0],[0]
"We also have a feature for stem overlap count between the grounded edge labels and the context words.
",3.3 Features,[0],[0]
Graph connectivity features These features penalize graphs with non-standard topologies.,3.3 Features,[0],[0]
"For example, we do not want a final graph with no edges.",3.3 Features,[0],[0]
The feature value φhasEdge is one if there exists at least one edge in the graph.,3.3 Features,[0],[0]
"We also have a feature φnodeCount for counting the number of connected 5We use the Porter stemmer.
nodes in the graph.",3.3 Features,[0],[0]
"Finally, feature φcolloc captures the collocation of grounded edges (e.g., edges belonging to a single complex fact are likely to cooccur; see Figure 8b).",3.3 Features,[0],[0]
In this section we present our experimental set-up for assessing the performance of the semantic parser described above.,4 Experimental Setup,[0],[0]
"We present the datasets on which our model was trained and tested, discuss implementation details, and briefly introduce the models used for comparison with our approach.",4 Experimental Setup,[0],[0]
"We evaluated our approach on the FREE917 (Cai and Yates, 2013) and WEBQUESTIONS (Berant et al., 2013) datasets.",4.1 Data,[0],[0]
"FREE917 consists of 917 questions and their meaning representations (written in a variant of lambda calculus) which we, however, do not use.",4.1 Data,[0],[0]
"The dataset represents 81 domains covering 635 Freebase relations, with most domains containing fewer than 10 questions.",4.1 Data,[0],[0]
"We report results on three domains, namely film, business, and people as these are relatively large in both FREE917 and Freebase.",4.1 Data,[0],[0]
"WEBQUESTIONS consists of 5,810 question-answer pairs, 2,780 of which are reserved for testing.",4.1 Data,[0],[0]
Our experiments used a subset of WEBQUESTIONS representing the three target domains.,4.1 Data,[0],[0]
We extracted domain-specific queries semi-automatically by identifying questionanswer pairs with entities in target domain relations.,4.1 Data,[0],[0]
"In both datasets, named entities were disambiguated to Freebase entities with a named entity lexicon.6
Table 1 presents descriptive statistics for each domain.",4.1 Data,[0],[0]
Evaluating on all domains in Freebase would 6FREE917 comes with a named entity lexicon.,4.1 Data,[0],[0]
"For WEBQUESTIONS we hand-coded this lexicon.
generate a very large number of queries for which denotations would have to be computed (the number of queries is linear in the number of domains and the size of training data).",4.1 Data,[0],[0]
Our system loads Freebase using Virtuoso7 and queries it with SPARQL.,4.1 Data,[0],[0]
"Virtuoso is slow in dealing with millions of queries indexed on the entire Freebase, and is the only reason we did not work with the complete Freebase.",4.1 Data,[0],[0]
"To train our model, we extracted sentences from CLUEWEB09 which contain at least two entities associated with a relation in Freebase, and have an edge between them in the ungrounded graph.",4.2 Implementation,[0],[0]
These were further filtered so as to remove sentences which do not yield at least one semantic parse without an uninstantiated entity variable.,4.2 Implementation,[0],[0]
"For example, the sentence Avatar is directed by Cameron would be used for training, whereas Avatar directed by Cameron received a critical review wouldn’t.",4.2 Implementation,[0],[0]
"In the latter case, any semantic parse will have an uninstantiated entity variable for review.",4.2 Implementation,[0],[0]
"Table 1 (Train) shows the number of sentences we obtained.
",4.2 Implementation,[0],[0]
"In order to train our semantic parser, we initialized the alignment and type features (φedge and φtype, respectively) with the alignment lexicon weights.",4.2 Implementation,[0],[0]
These weights are computed as follows.,4.2 Implementation,[0],[0]
"Let count(r′,r) denote the number of pairs of entities which are linked with edge r′ in Freebase and edge r in CLUEWEB09 sentences.",4.2 Implementation,[0],[0]
"We then estimate the probability distribution P(r′/r) = count(r
′,r) ∑i count(r′i,r)
.",4.2 Implementation,[0],[0]
"Analogously, we created a type alignment lexicon.",4.2 Implementation,[0],[0]
"The counts were collected from CLUEWEB09 sentences containing pairs of entities linked with an edge in Freebase (business 390k, film 130k, and people 490k).",4.2 Implementation,[0],[0]
Contextual features were initialized to−1 since most word contexts and grounded predicates/types do not appear together.,4.2 Implementation,[0],[0]
"All other features were set to 0.
",4.2 Implementation,[0],[0]
We used a beam-search algorithm to convert ungrounded graphs to grounded ones.,4.2 Implementation,[0],[0]
The edges and types of each ungrounded graph are placed in a priority queue.,4.2 Implementation,[0],[0]
Priority is based on edge/type tf-idf scores collected over CLUEWEB09.,4.2 Implementation,[0],[0]
"At each step, we pop an element from the queue and ground it in Freebase.",4.2 Implementation,[0],[0]
"We rank the resulting grounded graphs us-
7http://virtuoso.openlinksw.com
ing the perceptron model, and pick the n-best ones, where n is the beam size.",4.2 Implementation,[0],[0]
We continue until the queue is empty.,4.2 Implementation,[0],[0]
In our experiments we used a beam size of 100.,4.2 Implementation,[0],[0]
We trained a single model for all the domains combined together.,4.2 Implementation,[0],[0]
We ran the perceptron for 20 iterations (around 5–10 million queries).,4.2 Implementation,[0],[0]
"At each training iteration we used 6,000 randomly selected sentences from the training corpus.",4.2 Implementation,[0],[0]
We compared our graph-based semantic parser (henceforth GRAPHPARSER) against two state-ofthe-art systems both of which are open-domain and work with Freebase.,4.3 Comparison Systems,[0],[0]
"The semantic parser developed by Kwiatkowski et al. (2013) (henceforth KCAZ13) is learned from question-answer pairs and follows a two-stage procedure: first, a natural language sentence is converted to a domain-independent semantic parse and then grounded onto Freebase using a set of logical-type equivalent operators.",4.3 Comparison Systems,[0],[0]
The operators explore possible ways sentential meaning could be expressed in Freebase and essentially transform logical form to match the target ontology.,4.3 Comparison Systems,[0],[0]
"Our approach also has two steps (i.e., we first generate multiple ungrounded graphs and then ground them to different Freebase graphs).",4.3 Comparison Systems,[0],[0]
"We do not use operators to perform structure matching, rather we create multiple graphs and leave it up to the learner to find an appropriate grounding using a rich feature space.",4.3 Comparison Systems,[0],[0]
"To give a specific example, their operator literal to constant is equivalent to having named entities for larger text chunks in our case.",4.3 Comparison Systems,[0],[0]
Their operator split literal explores different edge possibilities in an event whereas we start with a clique and remove unwanted edges.,4.3 Comparison Systems,[0],[0]
"Our approach has (almost) similar expressive power but is conceptually simpler.
",4.3 Comparison Systems,[0],[0]
Our second comparison system was the semantic parser of Berant and Liang (2014) (henceforth PARASEMPRE) which also uses QA pairs for training and makes use of paraphrasing.,4.3 Comparison Systems,[0],[0]
"Given an input NL sentence, they first construct a set of logical forms based on hand-coded rules, and then generate sentences from each logical form (using generation templates and a lexicon).",4.3 Comparison Systems,[0],[0]
Pairs of logical forms and natural language are finally scored using a paraphrase model consisting of two components.,4.3 Comparison Systems,[0],[0]
"An association model determines whether they contain phrase pairs likely to be paraphrases
and a vector space model assigns a vector representation for each sentence, and learns a scoring function that ranks paraphrase candidates.",4.3 Comparison Systems,[0],[0]
"Our semantic parser employs a graph-based representation as a means of handling the mismatch between natural language, whereas PARASEMPRE opts for a textbased one through paraphrasing.
",4.3 Comparison Systems,[0],[0]
"Finally, we compared our semantic parser against a baseline which is based on graphs but employs no learning.",4.3 Comparison Systems,[0],[0]
"The baseline converts an ungrounded graph to a grounded one by replacing each ungrounded edge/type with the highest weighted grounded label creating a maximum weighted graph, henceforth MWG.",4.3 Comparison Systems,[0],[0]
Both GRAPHPARSER and the baseline use the same alignment lexicon (a weighted mapping from ungrounded to grounded labels).,4.3 Comparison Systems,[0],[0]
Table 2 summarizes our results on FREE917.,5 Results,[0],[0]
"As described earlier, we evaluated GRAPHPARSER on a subset of the dataset representing three domains (business, film, and people).",5 Results,[0],[0]
"Since this subset contains a relatively small number of instances (124 in total), we performed 10-fold cross validation with 9 folds as development data8, and one fold as test data.",5 Results,[0],[0]
We report results averaged over all test folds.,5 Results,[0],[0]
"With respect to KCAZ13, we present results with their cross-domain trained models, where training data from multiple domains is used to test foreign domains.9 KCAZ13 used generic features like string similarity and knowledge base features which apply across domains and do not require indomain training data.",5 Results,[0],[0]
We do not report results with PARASEMPRE as the small number of training instances would put their method at a disadvantage.,5 Results,[0],[0]
"We treat a predicted query as correct if its denota-
8The development data is only used for model selection and for determining the optimal training iteration.",5 Results,[0],[0]
"9We are grateful to Tom Kwiatkowski for supplying us with the output of their system.
",5 Results,[0],[0]
"tion is exactly equal to the denotation of the manually annotated gold query.
",5 Results,[0],[0]
"As can be seen, GRAPHPARSER outperforms KCAZ13",5 Results,[0],[0]
and the MWG baseline by a wide margin.,5 Results,[0],[0]
This is an encouraging result bearing in mind that our model does not use question-answer pairs.,5 Results,[0],[0]
We should also point out that our domain relation set is larger compared to KCAZ13.,5 Results,[0],[0]
"We do not prune any of the relations in Freebase, whereas KCAZ13 use only 112 relations and 83 types from our three domains (see Table 1).",5 Results,[0],[0]
We further performed a feature ablation study to examine the contribution of different feature classes.,5 Results,[0],[0]
"As shown in Table 3, the most important features are those based on lexical similarity, as also observed in KCAZ13.",5 Results,[0],[0]
Graph connectivity and lexical alignments are equally important (these features are absent from KCAZ13).,5 Results,[0],[0]
Contextual features are not very helpful over and above alignment features which also encode contextual information.,5 Results,[0],[0]
"Overall, generic features like lexical similarity are helpful only to a certain extent; the performance of GRAPHPARSER improves considerably when additional graph-related features are taken into account.
",5 Results,[0],[0]
We also analyzed the errors GRAPHPARSER makes.,5 Results,[0],[0]
25% of these are caused by the C&C parser and are cases where it either returns no syntactic analysis or a wrong one.,5 Results,[0],[0]
19% of the errors are due to Freebase inconsistencies.,5 Results,[0],[0]
"For example, our system answered the question How many stores are in Nittany mall?",5 Results,[0],[0]
with 65 using the relation shopping center.number of stores whereas the gold standard provides the answer 25 counting all stores using the relation shopping center.store.,5 Results,[0],[0]
"Around 15% of errors include structural mismatches between natural language and Freebase; for the question Who is the president of Gap Inc?, our method grounds president to a grounded type whereas in Freebase it is represented as a relation employment.job.title.",5 Results,[0],[0]
"The remain-
ing errors are miscellaneous.",5 Results,[0],[0]
"For example, the question What are some films on Antarctica? receives two interpretations, i.e., movies filmed in Antarctica or movies with Antarctica as their subject.
",5 Results,[0],[0]
We next discuss our results on WEBQUESTIONS.,5 Results,[0],[0]
"PARASEMPRE was trained with 1,115 QA pairs (corresponding to our target domains) together with question paraphrases obtained from the PARALEX corpus (Fader et al., 2013).10 While training PARASEMPRE, out-of-domain Freebase relations and types were removed.",5 Results,[0],[0]
Both GRAPHPARSER and PARASEMPRE were tested on the same set of 570 in-domain QA pairs with exact answer match as the evaluation criterion.,5 Results,[0],[0]
"For development purposes, GRAPHPARSER uses 200 QA pairs.",5 Results,[0],[0]
Table 4 displays our results.,5 Results,[0],[0]
We observe that GRAPHPARSER obtains a higher F1 against MWG and PARASEMPRE.,5 Results,[0],[0]
Differences in performance among these systems are less pronounced compared to FREE917.,5 Results,[0],[0]
This is for a good reason.,5 Results,[0],[0]
"WEBQUESTIONS is a challenging dataset, created by non-experts.",5 Results,[0],[0]
"The questions are not tailored to Freebase in any way, they are more varied and display a wider vocabulary.",5 Results,[0],[0]
"As a result the mismatch between natural language and Freebase is greater and the semantic parsing task harder.
",5 Results,[0],[0]
Error analysis further revealed that parsing errors are responsible for 13% of the questions GRAPHPARSER fails to answer.,5 Results,[0],[0]
Another cause of errors is mismatches between natural language and Freebase.,5 Results,[0],[0]
"Around 7% of the questions are of the type Where did X come from?, and our model answers with the individual’s nationality, whereas annotators provide the birthplace (city/town/village) as the right answer.",5 Results,[0],[0]
"Moreover, 8% of the questions are of the type What does X do?, which the annotators answer with the individual’s profession.",5 Results,[0],[0]
"In natural language, we rarely attest constructions 10We used the SEMPRE package (http://www-nlp. stanford.edu/software/sempre/) which does not use any hand-coded entity disambiguation lexicon.
",5 Results,[0],[0]
like X does dentist/researcher/actor.,5 Results,[0],[0]
"The proposed framework assumes that Freebase and natural language are somewhat isomorphic, which is not always true.",5 Results,[0],[0]
An obvious future direction would be to paraphrase the questions so as to increase the number of grounded and ungrounded graphs.,5 Results,[0],[0]
"As an illustration, we rewrote questions like Where did X come from to What is X’s birth place, and What did X do to What is X’s profession and evaluated our model GRAPHPARSER + PARA.",5 Results,[0],[0]
"As shown in Table 4, even simple paraphrasing can boost performance.
",5 Results,[0],[0]
"Finally, Table 3 (third column) examines the contribution of different features on the WEBQUESTIONS development dataset.",5 Results,[0],[0]
"Interestingly, we observe that contextual features are not useful and in fact slightly harm performance.",5 Results,[0],[0]
We hypothesize that this is due to the higher degree of mismatch between natural language and Freebase in this dataset.,5 Results,[0],[0]
"Features based on similarity, graph connectivity, and lexical alignments are more robust and generally useful across datasets.",5 Results,[0],[0]
"In this paper, we introduce a new semantic parsing approach for Freebase.",6 Discussion,[0],[0]
A key idea in our work is to exploit the structural and conceptual similarities between natural language and Freebase through a common graph-based representation.,6 Discussion,[0],[0]
We formalize semantic parsing as a graph matching problem and learn a semantic parser without using annotated question-answer pairs.,6 Discussion,[0],[0]
We have shown how to obtain graph representations from the output of a CCG parser and subsequently learn their correspondence to Freebase using a rich feature set and their denotations as a form of weak supervision.,6 Discussion,[0],[0]
Our parser yields state-of-the art performance on three large Freebase domains and is not limited to question answering.,6 Discussion,[0],[0]
"We can create semantic parses for any type of NL sentences.
",6 Discussion,[0],[0]
Our work brings together several strands of research.,6 Discussion,[0],[0]
"Graph-based representations of sentential meaning have recently gained some attention in the literature (Banarescu et al., 2013), and attempts to map sentences to semantic graphs have met with good inter-annotator agreement.",6 Discussion,[0],[0]
"Our work is also closely related to Kwiatkowski et al. (2013) and Berant and Liang (2014) who present open-domain se-
mantic parsers based on Freebase and trained on QA pairs.",6 Discussion,[0],[0]
"Despite differences in formulation and model structure, both approaches have explicit mechanisms for handling the mismatch between natural language and the KB (e.g., using logical-type equivalent operators or paraphrases).",6 Discussion,[0],[0]
The mismatch is handled implicitly in our case via our graphical representation which allows for the incorporation of all manner of powerful features.,6 Discussion,[0],[0]
"More generally, our method is based on the assumption that linguistic structure has a correspondence to Freebase structure which does not always hold (e.g., in Who is the grandmother of Prince William?, grandmother is not directly expressed as a relation in Freebase).",6 Discussion,[0],[0]
"Additionally, our model fails when questions are too short without any lexical clues (e.g., What did Charles Darwin do? ).",6 Discussion,[0],[0]
Supervision from annotated data or paraphrasing could improve performance in such cases.,6 Discussion,[0],[0]
"In the future, we plan to explore cluster-based semantics (Lewis and Steedman, 2013) to increase the robustness on unseen NL predicates.
",6 Discussion,[0],[0]
Our work joins others in exploiting the connections between natural language and open-domain knowledge bases.,6 Discussion,[0],[0]
"Recent approaches in relation extraction use distant supervision from a knowledge base to predict grounded relations between two target entities (Mintz et al., 2009; Hoffmann et al., 2011; Riedel et al., 2013).",6 Discussion,[0],[0]
"During learning, they aggregate sentences containing the target entities, ignoring richer contextual information.",6 Discussion,[0],[0]
"In contrast, we learn from each individual sentence taking into account all entities present, their relations, and how they interact.",6 Discussion,[0],[0]
"Krishnamurthy and Mitchell (2012) formalize semantic parsing as a distantly supervised relation extraction problem combined with a manually specified grammar to guide semantic parse composition.
",6 Discussion,[0],[0]
"Finally, our approach learns a model of semantics guided by denotations as a form of weak supervision.",6 Discussion,[0],[0]
"Beyond semantic parsing (Artzi and Zettlemoyer, 2013; Liang et al., 2011; Clarke et al., 2010), feedback-based learning has been previously used for interpreting and following NL instructions (Branavan et al., 2009; Chen and Mooney, 2011), playing computer games (Branavan et al., 2012), and grounding language in the physical world (Krishnamurthy and Kollar, 2013; Matuszek et al., 2012).
",6 Discussion,[0],[0]
"Appendix
We use a handful of rules to divide words into semantic classes.",6 Discussion,[0],[0]
"Based on a word’s semantic class and indexed syntactic category, we construct its semantic category automatically.",6 Discussion,[0],[0]
"For example, directed is a member of the EVENT class, and its indexed syntactic category is ((Se\NPx<1>)/NPy<2>)",6 Discussion,[0],[0]
"(here, <1> and <2> indicate that x",6 Discussion,[0],[0]
and y are the first and second arguments of e).,6 Discussion,[0],[0]
"We then generate its semantic category as λQλPλe.∃x∃y.directed.arg1(e,x)∧ directed.arg2(e,y) ∧ P(x) ∧Q(y).",6 Discussion,[0],[0]
"Please refer to Appendix B of Clark and Curran (2007) for a list of their indexed syntactic categories.
",6 Discussion,[0],[0]
The rules are described in Table 5.,6 Discussion,[0],[0]
Syntactic categories are not shown for the sake of brevity.,6 Discussion,[0],[0]
Most rules will match any syntactic category.,6 Discussion,[0],[0]
"Exceptions are copula-related rules (see be in the sixth row) which apply only to the syntactic category (S\NP)/NP, and rules pertaining to wh -words (see the last two rows in the table).",6 Discussion,[0],[0]
"When more than one
rule apply, we end up with multiple semantic parses.",6 Discussion,[0],[0]
"There are a few cases like passives, question words, and prepositional phrases where we modified the original indexed categories for better interpretation of the semantics (these are not displayed here).",6 Discussion,[0],[0]
We also handle non-standard CCG operators involving unary and binary rules as described in Appendix A of Clark and Curran (2007).,6 Discussion,[0],[0]
We are grateful to the anonymous reviewers for their valuable feedback on an earlier version of this paper.,Acknowledgements,[0],[0]
Thanks to Mike Lewis and the members of ILCC for helpful discussions and comments.,Acknowledgements,[0],[0]
We acknowledge the support of EU ERC Advanced Fellowship 249520 GRAMPLUS and EU IST Cognitive Systems IP EC-FP7-270273 “Xperience”.,Acknowledgements,[0],[0]
In this paper we introduce a novel semantic parsing approach to query Freebase in natural language without requiring manual annotations or question-answer pairs.,abstractText,[0],[0]
Our key insight is to represent natural language via semantic graphs whose topology shares many commonalities with Freebase.,abstractText,[0],[0]
"Given this representation, we conceptualize semantic parsing as a graph matching problem.",abstractText,[0],[0]
Our model converts sentences to semantic graphs using CCG and subsequently grounds them to Freebase guided by denotations as a form of weak supervision.,abstractText,[0],[0]
Evaluation experiments on a subset of the FREE917 and WEBQUESTIONS benchmark datasets show our semantic parser improves over the state of the art.,abstractText,[0],[0]
Large-scale Semantic Parsing without Question-Answer Pairs,title,[0],[0]
"Consider the problem of estimating an n × n covariance matrix Σ (or its inverse Σ−1) of a n-variate probability distribution from N independently and identically distributed samples x1,x2, . . .",1. Introduction,[0],[0]
",xN drawn from the same probability distribution.",1. Introduction,[0],[0]
"In applications spanning from computer vision, natural language processing, to economics (Li, 1994; Manning & Schütze, 1999; Durlauf, 1993), the matrix Σ−1 is often sparse, meaning that its matrix elements are mostly
MATLAB source code: http://alum.mit.edu/www/ ryz. 1Department of Industrial Engineering and Operations Research, University of California, Berkeley, USA. 2Department of Electrical Engineering and Computer Science, University of California, Berkeley, USA.. Correspondence to:",1. Introduction,[0],[0]
"R.Y. Zhang <ryz@berkeley.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
zero.,1. Introduction,[0],[0]
"For Gaussian distributions, the statistical interpretation of sparsity in Σ−1 is that most of the variables are pairwise conditionally independent (Meinshausen & Bühlmann, 2006; Yuan & Lin, 2007; Friedman et al., 2008; Banerjee et al., 2008).
",1. Introduction,[0],[0]
Imposing sparsity upon Σ−1 can regularize the associated estimation problem and greatly reduce the number of samples required.,1. Introduction,[0],[0]
"This is particularly important in highdimensional settings where n is large, often significantly larger than the number of samples N n.",1. Introduction,[0],[0]
"One popular approach regularizes the associated maximum likelihood estimation (MLE) problem by a sparsity-promoting `1 term, as in
minimize X 0",1. Introduction,[0],[0]
trCX − log detX + λ n∑ i=1,1. Introduction,[0],[0]
"n∑ j=1 |Xi,j |.",1. Introduction,[0],[0]
"(1)
Here, C = 1N ∑N i=1(xi",1. Introduction,[0],[0]
− x̄)(xi,1. Introduction,[0],[0]
"− x̄)T is the sample
covariance matrix with sample mean x̄",1. Introduction,[0],[0]
= 1N ∑N i=1,1. Introduction,[0],[0]
"xi, and X is the resulting estimator for Σ−1.",1. Introduction,[0],[0]
"This approach, commonly known as the graphical lasso (Friedman et al., 2008), is known to enjoy a number of statistical guarantees (Rothman et al., 2008; Ravikumar et al., 2011), some of which are direct extensions of earlier work on the classical lasso (Obozinski et al., 2008; Negahban & Wainwright, 2008; Wainwright, 2009; Huang & Zhang, 2010).",1. Introduction,[0],[0]
"A variation on this theme is to only impose the `1 penalty on the off-diagonal elements of X , or to place different weights λ on the elements of the matrix X , as in the classical weighted lasso.
",1. Introduction,[0],[0]
"While the `1-regularized problem (1) is technically convex, it is commonly considered intractable for large-scale datasets.",1. Introduction,[0],[0]
"The decision variable is an n×nmatrix, so simply fitting all O(n2) variables into memory is already a significant issue.",1. Introduction,[0],[0]
General-purpose algorithms have either prohibitively high complexity or slow convergence.,1. Introduction,[0],[0]
"In practice, (1) is solved using problem-specific algorithms.",1. Introduction,[0],[0]
"The state-of-the-art include GLASSO (Friedman et al., 2008), QUIC (Hsieh et al., 2014), and its “big-data” extension BIG-QUIC (Hsieh et al., 2013).",1. Introduction,[0],[0]
"These algorithms use between O(n) and O(n3) time and between O(n2) and O(n) memory per iteration, but the number of iterations needed to converge to an accurate solution can be very large.",1. Introduction,[0],[0]
"The high practical cost of graphical lasso has inspired a number of heuristics, which enjoy less guarantees but are significantly cheaper to use.","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Indeed, heuristics are often the only viable option once n exceeds the order of a few tens of thousands.
","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
One simple idea is to threshold the sample covariance matrix C: to examine all of its elements and keep only the ones whose magnitudes exceed some threshold.,"1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"In a recent line of work (Mazumder & Hastie, 2012; Sojoudi, 2016; Fattahi & Sojoudi, 2017; Fattahi et al., 2018), this simple heuristic was shown to enjoy some surprising guarantees.","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"In particular, (Sojoudi, 2016; Fattahi & Sojoudi, 2017) proved that when the lasso weight is imposed over only the off-diagonal elements of X that—under some assumptions—the sparsity pattern of the associated graphical lasso estimator can be recovered by performing a softthresholding operation on C, as in
(Cλ)i,j =  Ci,j i = j,
Ci,j − λ Ci,j > λ, i 6= j, 0 |Ci,j | ≤ λ","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
i 6=,"1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"j, Ci,j + λ −λ ≤ Ci,j i 6= j,
(2)
and recovering the sparsity pattern
G = {(i, j) ∈ {1, . . .","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
", n}2 : (Cλ)i,j 6= 0}.","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"(3)
The associated graph (also denoted as G when there is no ambiguity) is obtained by viewing each nonzero element (i, j) in G as an edge between the i-th and j-th vertex in an undirected graph on n nodes.","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Moreover, they showed that the estimator X can be recovered by solving a version of (1) in which the sparsity pattern G is explicitly imposed, as in
minimize X 0","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"trCλX − log detX (4)
subject to Xi,j = 0 ∀(i, j) /∈","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"G.
Recovering the exact value of X (and not just its sparsity pattern) is important because it provides a shrinkage MLE when the true MLE is ill-defined; for Gaussian fields, its nonzero values encode the partial correlations between variables.","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Problem (4) is named the maximum determinant matrix completion (MDMC) in the literature, for reasons explained below.","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"The problem has a recursive closed-form solution whenever the graph of G is acyclic (i.e. a tree or forest) (Fattahi & Sojoudi, 2017), or more generally, if it is chordal (Fattahi et al., 2018).","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"It is worth emphasizing that the closed-form solution is extremely fast to evaluate: a chordal example in (Fattahi et al., 2018) with 13,659 variables took just ≈ 5 seconds to solve on a laptop computer.
","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"The assumptions needed for graphical lasso to be equivalent to thresolding are hard to check but relatively mild.
","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Indeed, (Fattahi & Sojoudi, 2017) proves that they are automatically satisfied whenever λ is sufficiently large relative to the sample covariance matrix.","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Their numerical study found “sufficiently large” to be a fairly loose criterion in practice, particularly in view of the fact that large values of λ are needed to induce a sufficiently sparse estimate of Σ−1, e.g. with ≈ 10n nonzero elements.
","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"However, the requirement for G to be chordal is very strong.","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Aside from trivial chordal graphs like trees and cliques, thresholding will produce a chordal graph with probability zero.","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"When G is nonchordal, no closed-form solution exists, and one must resort to an iterative algorithm.","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
"The state-of-the-art for nonchordal MDMC is to embed the nonchordal graph within a chordal graph, and to solve the resulting problem as a semidefinite program using an interior-point method.","1.1. Graphical lasso, soft-thresholding, and MDMC",[0],[0]
The purpose of this paper is two-fold.,1.2. Main results,[0],[0]
"First, we derive an extension of the guarantees derived by (Mazumder & Hastie, 2012; Sojoudi, 2016; Fattahi & Sojoudi, 2017; Fattahi et al., 2018) for a slightly more general version of the problem that we call restricted graphical lasso (RGL):
X̂ = minimize X 0",1.2. Main results,[0],[0]
"trCX − log detX (5)
+ n∑ i=1",1.2. Main results,[0],[0]
"n∑ j=i+1 λi,j |Xi,j |.
subject to Xi,j = 0 ∀(i, j) /∈",1.2. Main results,[0],[0]
"H.
In other words, RGL is (1) penalized by a weighted lasso penalty λi,j on the off-diagonals, and with an a priori sparsity pattern H imposed as an additional constraint.",1.2. Main results,[0],[0]
We use the sparsity pattern H to incorporate prior information on the structure of the graphical model.,1.2. Main results,[0],[0]
"For example, if the sample covariance C is collected over a graph, such as a communication system or a social network, then far-away variables can be assumed as pairwise conditionally independent (Park & Rilett, 1999; Honorio et al., 2009; Croft et al., 2010).",1.2. Main results,[0],[0]
"Including these neighborhood relationships into H can regularize the statistical problem, as well as reduce the numerical cost for a solution.
",1.2. Main results,[0],[0]
"In Section 2, we describe a procedure to transform RGL (5) into MDMC (4), in the same style as prior results by (Fattahi & Sojoudi, 2017; Fattahi et al., 2018) for graphical lasso.",1.2. Main results,[0],[0]
"More specifically, we soft-threshold the sample covariance C and then project this matrix onto the sparsity pattern H .",1.2. Main results,[0],[0]
We give conditions for the resulting sparsity pattern to be equivalent to the one obtained by solving (5).,1.2. Main results,[0],[0]
"Furthermore, we prove that the resulting estimator X can be recovered by solving the same MDMC problem (4) with Cλ appropriately modified.
",1.2. Main results,[0],[0]
"The second purpose is to describe an efficient algorithm to solve MCDC when the graph G is nonchordal, based on the chordal embedding approach of (Dahl et al., 2008; Andersen et al., 2010; 2013b).",1.2. Main results,[0],[0]
"We embed G within a chordal G̃ ⊃ G, to result in a convex optimization problem over Sn G̃
, the space of real symmetric matrices with sparsity pattern G̃.",1.2. Main results,[0],[0]
"This way, the constraint X ∈ Sn
G̃ is implicitly
imposed, meaning that we simply ignore the nonzero elements not in G̃.",1.2. Main results,[0],[0]
"Next, we solve an optimization problem on Sn
G̃ using a custom Newton-CG method.",1.2. Main results,[0],[0]
The main idea is to use an inner conjugate gradients (CG) loop to solve the Newton subproblem of an outer Newton’s method.,1.2. Main results,[0],[0]
"The actual algorithm has a number of features designed to exploit problem structure, including the sparse chordal property of G̃, duality, and the ability for CG and Newton to converge superlinearly; these are outlined in Section 3.
",1.2. Main results,[0],[0]
"Assuming that the chordal embedding is sparse with |G̃| = O(n) nonzero elements, we prove in Section 3.4, that our algorithm converges to an -accurate solution of MDMC (4) in
O(n · log −1 · log log −1) time and O(n) memory.",1.2. Main results,[0],[0]
"(6)
Most importantly, the algorithm is highly efficient in practice.",1.2. Main results,[0],[0]
"In Section 4, we present computation results on a suite of test cases.",1.2. Main results,[0],[0]
Both synthetic and real-life graphs are considered.,1.2. Main results,[0],[0]
"Using our approach, we solve sparse inverse covariance estimation problems containing as many as 200,000 variables, in less than an hour on a laptop computer.",1.2. Main results,[0],[0]
Graphical lasso with prior information.,1.3. Related Work,[0],[0]
A number of approaches are available in the literature to introduce prior information to graphical lasso.,1.3. Related Work,[0],[0]
"The weighted version of graphical lasso mentioned before is an example, though RGL will generally be more efficient to solve due to a reduction in the number of variables.",1.3. Related Work,[0],[0]
"(Egilmez et al., 2017) introduced a class of graphical lasso in which the true graphical model is assumed to have Laplacian structure.",1.3. Related Work,[0],[0]
"This structure commonly appears in signal and image processing (Milanfar, 2013).",1.3. Related Work,[0],[0]
"For the a priori graph-based correlation structure described above, (Grechkin et al., 2015) introduced a pathway graphical lasso method similar to RGL.
",1.3. Related Work,[0],[0]
Algorithms for graphical lasso.,1.3. Related Work,[0],[0]
"Algorithms for graphical lasso are usually based on some mixture of Newton (Oztoprak et al., 2012), proximal Newton (Hsieh et al., 2013; 2014), iterative thresholding (Rolfs et al., 2012), and (block) coordinate descent (Friedman et al., 2008; Treister & Turek, 2014).",1.3. Related Work,[0],[0]
All of these suffer fundamentally from the need to keep track and act on allO(n2) elements in the matrix X decision variable.,1.3. Related Work,[0],[0]
"Even if the final solution matrix were sparse with O(n) nonzeros, it is still possible for the
algorithm to traverse through a “dense region” in which the iterateX must be fully dense.",1.3. Related Work,[0],[0]
"Thresholding heuristics have been proposed to address issue, but these may adversely affect the outer algorithm and prevent convergence.",1.3. Related Work,[0],[0]
"It is generally impossible to guarantee a figure lower than O(n2) time per-iteration, even if the solution contains only O(n) nonzeros.",1.3. Related Work,[0],[0]
"Most of the algorithms mentioned above actually have worst-case per-iteration costs of O(n3).
",1.3. Related Work,[0],[0]
Graphical lasso via thresholding.,1.3. Related Work,[0],[0]
"The elementary estimator for graphical models (EE-GM) (Yang et al., 2014) is another thresholding-based low-complexity method that is able to recover the actual graphical lasso estimator.",1.3. Related Work,[0],[0]
"Both EE-GM and our algorithm have a similar level of performance in practice, because both algorithm are bottlenecked by the initial thresholding step, which is a quadratic O(n2) time operation.
",1.3. Related Work,[0],[0]
Algorithms for MDMC.,1.3. Related Work,[0],[0]
"Our algorithm is inspired by a line of results (Dahl et al., 2008; Andersen et al., 2010; 2013b; Li et al., 2017) for minimizing the log-det penalty on chordal sparsity patterns, culminating in the CVXOPT package (Andersen et al., 2013a).",1.3. Related Work,[0],[0]
"These algorithms all solve the Newton subproblem by explicitly forming and factoring the fully-dense Newton matrix in O(nm2 +m3) time, where m = |G̃\G| is the number of edges added during chordal embedding.",1.3. Related Work,[0],[0]
"By comparison, our algorithm solves the Newton subproblem iteratively using CG, in O(n+m) time to machine precision (see Section 3.4).
",1.3. Related Work,[0],[0]
"Notations
Let Rn and Sn be the set of n×1 real vectors, and n×n real symmetric matrices.",1.3. Related Work,[0],[0]
We endow Sn with the usual matrix inner product X • Y = trXY and Euclidean (i.e. Frobenius) norm ‖X‖2F,1.3. Related Work,[0],[0]
= X •X .,1.3. Related Work,[0],[0]
Let Sn+ ⊂,1.3. Related Work,[0],[0]
Sn and Sn++ ⊂ Sn+ be the associated set of positive semidefinite and positive definite matrices.,1.3. Related Work,[0],[0]
We will frequently write X 0,1.3. Related Work,[0],[0]
to mean X ∈ Sn+ and write X 0,1.3. Related Work,[0],[0]
to mean X ∈ Sn++.,1.3. Related Work,[0],[0]
"Given a sparsity pattern G, we define SnG ⊆ Sn as the set of n × n real symmetric matrices with this sparsity pattern.",1.3. Related Work,[0],[0]
"Let PH(X) denote the projection operator from Sn onto SnH , i.e. by setting all Xi,j = 0","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"if (i, j) /∈","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
H .,"2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Let Cλ be the sample covariance matrix C individually soft-thresholded by [λi,j ], as in
(Cλ)i,j =  Ci,j i = j,
Ci,j − λi,j Ci,j > λi,j , i 6= j, 0 |Ci,j | ≤ λi,j i 6= j, Ci,j + λi,j −λi,j ≤ Ci,j i 6= j, (7)
","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"In this section, we state the conditions for PH(Cλ)—the projection of the soft-thresholded matrix Cλ in (7) onto H—to have the same sparsity pattern as the RGL estimator X̂ in (5).","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Furthermore, the estimator X̂ can be explicitly recovered by solving the MDMC problem (4) while replacing Cλ ← PH(Cλ) and G ← PH(G).","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"For brevity, all proofs and remarks are omitted; these can be found in the supplementary materials.
","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Before we state the exact conditions, we begin by adopting the some definitions and notations from the literature.
","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
Definition 1.,"2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"(Fattahi & Sojoudi, 2017)","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Given a matrix M ∈ Sn, define GM = {(i, j) : Mi,j 6= 0} as its sparsity pattern.","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Then M is called inverse-consistent if there exists a matrix N ∈ Sn such that
M +N 0 (8a) N = 0 ∀(i, j) ∈ GM (8b) (M +N)−1 ∈ SnGM (8c)
","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
The matrix N is called an inverse-consistent complement of M and is denoted by M (c).,"2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Furthermore, M is called sign-consistent if for every (i, j) ∈ GM , the (i, j)-th elements of M and (M +M (c))−1 have opposite signs.
","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Moreover, we take the usual matrix max-norm to exclude the diagonal, as in ‖M‖max = maxi 6=j |Mij |, and adopt the β(G,α) function defined with respect to the sparsity pattern G and scalar α > 0
β(G,α) = max M 0","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"‖M (c)‖max
s.t. M ∈ SnG and ‖M‖max ≤","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"α Mi,i = 1 ∀i ∈ {1, . . .","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
", n} M is inverse-consistent.
","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"We are now ready to state the conditions for softthresholding to be equivalent to RGL.
","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
Theorem 2.,"2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Define Cλ as in (7), define CH = PH(Cλ) and let GH = {(i, j) : (CH)i,j 6= 0} be its sparsity pattern.","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Then GH coincides with sparsity pattern of the optimal solution X̂ of RGL (5) if the normalized matrix C̃ = D−1/2CHD
−1/2 where D = diag(CH) satisfies the following conditions:
1.","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"C̃ is positive definite,
2.","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"C̃ is sign-consistent, 3.","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
Let βH = β,"2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"( GH , ‖C̃‖max ) .","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Then
βH ≤ min (k,l)/∈GH λk,l − |(CH)k,l|√ (CH)k,k · (CH)l,l
(9)
Proof.","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"See supplementary materials.
","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Theorem 2 leads to the following corollary, which asserts that the optimal solution of RGL can be obtained by maximum determinant matrix completion: computing the matrix Z 0 with the largest determinant that “fills-in” the zero elements of PH(Cλ).
","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
Corollary 3.,"2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
Suppose that the conditions in Theorem 2 are satisfied.,"2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Define Ẑ as the solution to the following
Ẑ = maximize Z 0 log detZ (10)
subject to Zi,j = PH(Cλ) for all (i, j)
where [PH(Cλ)]i,j 6= 0
Then Ẑ = X̂−1, where X̂ is the solution of (5).
","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
Proof.,"2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"See supplementary materials.
","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
"Standard manipulations show that (10) is the Lagrangian dual of (4), thus explaining the etymology of (4) as MDMC.","2. Restricted graphical lasso, soft-thresholding, and MDMC",[0],[0]
This section describes an efficient algorithm to solve MDMC (4) in which the sparsity pattern G is nonchordal.,3. Proposed Algorithm,[0],[0]
"If we assume that the input matrix Cλ is sparse, and that sparse Cholesky factorization is able to solve Cλx = b in O(n) time, then our algorithm is guaranteed to compute an -accurate solution in O(n log −1) time and O(n) memory.
",3. Proposed Algorithm,[0],[0]
"The algorithm is fundamentally a Newton-CG method, i.e. Newton’s method in which the Newton search directions are computed using conjugate gradients (CG).",3. Proposed Algorithm,[0],[0]
"It is developed from four key insights:
1.",3. Proposed Algorithm,[0],[0]
Chordal embedding is easy via sparse matrix heuristics.,3. Proposed Algorithm,[0],[0]
State-of-the-art algorithms for (4) begin by computing a chordal embedding G̃ forG.,3. Proposed Algorithm,[0],[0]
"The optimal chordal embedding with the fewest number of nonzeros |G̃| is NP-hard to compute, but a good-enough embedding with O(n)",3. Proposed Algorithm,[0],[0]
nonzeros is sufficient for our purposes.,3. Proposed Algorithm,[0],[0]
Computing a good G̃ with |G̃| = O(n) is exactly the same problem as finding a sparse Cholesky factorization Cλ = LLT with O(n) fillin.,3. Proposed Algorithm,[0],[0]
"Using heuristics developed for numerical linear algebra, we are able to find sparse chordal embeddings for graphs containing millions of edges and hundreds of thousands of nodes in seconds.
",3. Proposed Algorithm,[0],[0]
2.,3. Proposed Algorithm,[0],[0]
Optimize directly on the sparse matrix cone.,3. Proposed Algorithm,[0],[0]
"Using log-det barriers for sparse matrix cones (Dahl et al., 2008; Andersen et al., 2010; 2013b; Vandenberghe et al., 2015), we can optimize directly in the space Sn
G̃ , while ignoring
all matrix elements outside of G̃. If |G̃| = O(n), then only O(n) decision variables must be explicitly optimized.
",3. Proposed Algorithm,[0],[0]
"Moreover, each function evaluation, gradient evaluation, and matrix-vector product with the Hessian can be performed in O(n) time, using the numerical recipes in (Andersen et al., 2013b).
3.",3. Proposed Algorithm,[0],[0]
The dual is easier to solve than the primal.,3. Proposed Algorithm,[0],[0]
"The primal problem starts with a feasible point X ∈ Sn
G̃ and seeks
to achieve first-order optimality.",3. Proposed Algorithm,[0],[0]
The dual problem starts with an infeasible optimal point X /∈,3. Proposed Algorithm,[0],[0]
"Sn
G̃ satisfying first-
order optimality, and seeks to make it feasible.",3. Proposed Algorithm,[0],[0]
"Feasibility is easier to achieve than optimality, so the dual problem is easier to solve than the primal.
",3. Proposed Algorithm,[0],[0]
4.,3. Proposed Algorithm,[0],[0]
Conjugate gradients (CG) converges in O(1) iterations.,3. Proposed Algorithm,[0],[0]
"Our main result (Theorem 6) bounds the condition number of the Newton subproblem to be O(1), independent of the problem dimension n and the current accuracy .",3. Proposed Algorithm,[0],[0]
It is therefore cheaper to solve this subproblem using CG to machine precision δmach,3. Proposed Algorithm,[0],[0]
"inO(n log δ−1mach) time than it is to solve for it directly in O(nm2 + m3) time using Cholesky factorization (Dahl et al., 2008; Andersen et al., 2010; 2013b).",3. Proposed Algorithm,[0],[0]
"Moreover, CG is an optimal Krylov subspace method, and as such, it is often able to exploit clustering in the eigenvalues to converge superlinearly.",3. Proposed Algorithm,[0],[0]
"Finally, computing the Newton direction to high accuracy further allows the outer Newton method to also converge quadratically.
",3. Proposed Algorithm,[0],[0]
The remainder of this section describes each consideration in further detail.,3. Proposed Algorithm,[0],[0]
We state the algorithm explicitly in Section 3.5.,3. Proposed Algorithm,[0],[0]
"Following (Dahl et al., 2008), we begin by reformulating (4) into a sparse chordal matrix program
X̂ = minimize trCX − log detX (11) subject to Xi,j = 0 ∀(i, j) ∈",3.1. Efficient chordal embedding,[0],[0]
"G̃\G.
X ∈ Sn G̃ .
in which G̃ is a chordal embedding forG: a sparsity pattern G̃ ⊃ G whose graph contains no induced cycles greater than three.",3.1. Efficient chordal embedding,[0],[0]
"This can be implemented using standard algorithms for large-and-sparse linear equations, due to the following result.",3.1. Efficient chordal embedding,[0],[0]
Proposition 4.,3.1. Efficient chordal embedding,[0],[0]
Let C ∈ SnG be a positive definite matrix with sparsity pattern G. Compute its unique lowertriangular Cholesky factor L satisfying C = LLT .,3.1. Efficient chordal embedding,[0],[0]
"Ignoring perfect numerical cancellation, the sparsity pattern of L+ LT is a chordal embedding G̃ ⊃ G.
Proof.",3.1. Efficient chordal embedding,[0],[0]
"The original proof is due to (Rose, 1970); see also (Vandenberghe et al., 2015).
",3.1. Efficient chordal embedding,[0],[0]
"Note that G̃ can be determined directly from G using a
symbolic Cholesky algorithm, which simulates the steps of Gaussian elimination using Boolean logic.",3.1. Efficient chordal embedding,[0],[0]
"Moreover, we can substantially reduce the number of edges added toG by reordering the columns and rows of C using a fill-reducing ordering.
",3.1. Efficient chordal embedding,[0],[0]
Corollary 5.,3.1. Efficient chordal embedding,[0],[0]
Let Π be a permutation matrix.,3.1. Efficient chordal embedding,[0],[0]
"For the same C ∈ SnG in Proposition 4, compute the unique Cholesky factor satisfying ΠCΠT = LLT .",3.1. Efficient chordal embedding,[0],[0]
"Ignoring perfect numerical cancellation, the sparsity pattern of Π(L + LT )ΠT is a chordal embedding G̃ ⊃",3.1. Efficient chordal embedding,[0],[0]
"G.
The problem of finding the best choice of Π is known as the fill-minimizing problem, and is NP-complete (Yannakakis, 1981).",3.1. Efficient chordal embedding,[0],[0]
"However, good orderings are easily found using heuristics developed for numerical linear algebra, like minimum degree ordering (George & Liu, 1989) and nested dissection (Gilbert, 1988; Agrawal et al., 1993).",3.1. Efficient chordal embedding,[0],[0]
"If G admits sparse chordal embeddings, then a good-enough |G̃| = O(n) will usually be found using a simple minimum degree ordering; see the MATLAB code snippet in Figure 1.",3.1. Efficient chordal embedding,[0],[0]
"Define the cone of sparse positive semidefinite matrices K, and the cone of sparse matrices with positive semidefinite completions K∗, as the following
K = Sn+ ∩ SnG̃, K∗ = {S •X ≥ 0 :",3.2. Logarithmic barriers for sparse matrix cones,[0],[0]
"S ∈ SG̃} = PG̃(S n +).
",3.2. Logarithmic barriers for sparse matrix cones,[0],[0]
"Then (11) can be posed as the primal-dual pair:
arg min X∈K {C •X + f(X) : AT (X) = 0}, (12)
arg max S∈K∗,y∈Rm
{−f∗(S) : S = C −A(y)}, (13)
where the linear map A : Rm → Sn G̃\G converts a list of m variables into the corresponding matrix in G̃\G, and f and f∗ are the “log-det” barrier functions onK andK∗ as introduced by (Dahl et al., 2008; Andersen et al., 2010; 2013b)
f(X) =",3.2. Logarithmic barriers for sparse matrix cones,[0],[0]
"− log detX, f∗(S) =",3.2. Logarithmic barriers for sparse matrix cones,[0],[0]
"− min X∈K {S •X + f(X)}.
",3.2. Logarithmic barriers for sparse matrix cones,[0],[0]
"Assuming that G̃ is sparse and chordal, the functions f and f∗, their gradient evaluations, and Hessian matrixvector products can all be efficiently evaluated in O(n) time and O(n) memory, using the numerical recipes described in (Andersen et al., 2013b).",3.2. Logarithmic barriers for sparse matrix cones,[0],[0]
"Our algorithm actually solves the dual problem (13), which can be rewritten as an unconstrained optimization problem
ŷ ≡ arg min y∈Rm g(y) ≡",3.3. Solving the dual problem,[0],[0]
f∗(Cλ −A(y)).,3.3. Solving the dual problem,[0],[0]
"(14)
After the solution ŷ is found, we can recover the optimal estimator for the primal problem via X̂ = −∇f∗(Cλ−A(y)).",3.3. Solving the dual problem,[0],[0]
"The dual problem (13) is easier to solve than the primal (12) because the origin y = 0 often lies very close to the solution ŷ. To see this, note that y = 0 produces a candidate estimator X̃ = −∇f∗(Cλ) that solves the chordal matrix completion problem
X̃ = arg min{trCλX − log detX : X ∈ SnG̃},
which is a relaxation of the nonchordal problem posed over SnG.",3.3. Solving the dual problem,[0],[0]
"As observed by previous authors (Dahl et al., 2008), this relaxation is a high quality guess, and X̃ is often “almost feasible” for the original nonchordal problem posed over SnG, as in X̃ ≈ PG(X̃).",3.3. Solving the dual problem,[0],[0]
"Some simple algebra shows that ‖∇g(0)‖ = ‖X̃ −PG(X̃)‖F , so if X̃ ≈ PG(X̃) holds true, then the origin y = 0 is close to optimal.",3.3. Solving the dual problem,[0],[0]
"Starting from this point, we can expect Newton’s method to rapidly converge at a quadratic rate.
3.4.",3.3. Solving the dual problem,[0],[0]
"CG converges in O(1) iterations
The most computationally expensive part of Newton’s method is the solution of the Newton direction ∆y via the m×m system of equations
∇2g(y)∆y = −∇g(y).",3.3. Solving the dual problem,[0],[0]
"(15)
The Hessian matrix ∇2g(y) is fully dense, but matrixvector products are linear O(n) time using the algorithms in Section 3.2.",3.3. Solving the dual problem,[0],[0]
"This insight motivates solving (15) using an iterative Krylov subspace method like conjugate gradients (CG), which is a matrix-free method that requires a single matrix-vector product with ∇2g(y) at each iteration (Barrett et al., 1994).",3.3. Solving the dual problem,[0],[0]
"Starting from the origin p = 0, the method converges to an -accurate search direction p satisfying
(p−∆y)T∇2g(y)(p−∆y) ≤ |∆yT∇g(y)|
in at most ⌈√ κg log(2/ ) ⌉ CG iterations, (16)
where κg = ‖∇2g(y)‖‖∇2g(y)−1‖ is the condition number of the Hessian matrix (Greenbaum, 1997; Saad, 2003).
",3.3. Solving the dual problem,[0],[0]
"Below, we state our main result, which says that the condition number κg depends polynomially on the problem data and the quality of the initial point, but is independent of the problem dimension n and the accuracy of the current iterate .
",3.3. Solving the dual problem,[0],[0]
Theorem 6.,3.3. Solving the dual problem,[0],[0]
"At any y satisfying g(y) ≤ g(y0) and ∇g(y)T (y − y0) ≤ φmax, the condition number κg of the Hessian matrix∇2g(y) is bound
κg ≤ 4 ( 1 + φ2maxλmax(X0)
λmin(X̂)
)2 .",3.3. Solving the dual problem,[0],[0]
"(17)
where φmax = g(y0)− g(ŷ) is the initial infeasibility, A = [vecA1, . . .",3.3. Solving the dual problem,[0],[0]
", vecAm] is the vectorized data matrix, X0 = −∇f∗(C −A(y0)), and X̂ =",3.3. Solving the dual problem,[0],[0]
"−∇f∗(C −A(ŷ)).
",3.3. Solving the dual problem,[0],[0]
Proof.,3.3. Solving the dual problem,[0],[0]
"See supplementary materials.
",3.3. Solving the dual problem,[0],[0]
Remark 7.,3.3. Solving the dual problem,[0],[0]
"Newton’s method is a descent method, so its kth iterate yk trivially satisfies g(yk) ≤ g(y0).",3.3. Solving the dual problem,[0],[0]
"Technically, the condition∇g(yk)T (yk−y0) ≤ φmax can be guaranteed by enclosing Newton’s method within an outer auxillary path-following loop; see Section 4.3.5 of (Nesterov, 2013).",3.3. Solving the dual problem,[0],[0]
"In practice, naive Newton’s method will usually satisfy the condition on its own; see our numerical experiments in Section 4.
",3.3. Solving the dual problem,[0],[0]
Applying Theorem 6 to (16) shows that CG solves each Newton subproblem to -accuracy in O(log −1) iterations.,3.3. Solving the dual problem,[0],[0]
Multiplying this figure by the O(log log −1),3.3. Solving the dual problem,[0],[0]
Newton steps to converge yields a global iteration bound of O(log −1,3.3. Solving the dual problem,[0],[0]
·log log −1),3.3. Solving the dual problem,[0],[0]
≈ O(1) CG iterations.,3.3. Solving the dual problem,[0],[0]
Multiplying this figure by theO(n) cost of each CG iteration proves the claimed time complexity in (6).,3.3. Solving the dual problem,[0],[0]
"In practice, CG typically converges much faster than this worst-case bound, due to its ability to exploit the clustering of eigenvalues in ∇2g(y); see (Greenbaum, 1997; Saad, 2003).",3.3. Solving the dual problem,[0],[0]
"Moreover, accurate Newton directions are only needed to guarantee quadratic convergence close to the solution.",3.3. Solving the dual problem,[0],[0]
"During the initial Newton steps, we may loosen the error tolerance for CG for a significant speed-up.",3.3. Solving the dual problem,[0],[0]
Inexact Newton steps can be used to obtain a speed-up of a factor of 2-3.,3.3. Solving the dual problem,[0],[0]
"To summarize, we begin by computing a chordal embedding G̃ for the sparsity pattern G of Cλ, using the code snippet in Figure 1.",3.5. The full algorithm,[0],[0]
"We use the embedding to reformulate (4) as (11), and solve the unconstrained problem ŷ = miny g(y) defined in (14), using Newton’s method
yk+1 = yk + αk∆yk, ∆yk ≡ −∇2g(yk)−1∇g(yk)
starting at the origin y0 = 0.",3.5. The full algorithm,[0],[0]
"The function value g(y), gradient ∇g(y) and Hessian matrix-vector products are all
evaluated using the numerical recipes described by (Andersen et al., 2013b).
",3.5. The full algorithm,[0],[0]
"At each k-th Newton step, we compute the Newton search direction ∆yk using conjugate gradients.",3.5. The full algorithm,[0],[0]
"A loose tolerance is used when the Newton decrement δk = |∆yTk∇g(yk)| is large, and a tight tolerance is used when the decrement is small, implying that the iterate is close to the true solution.",3.5. The full algorithm,[0],[0]
"Once a Newton direction ∆yk is computed with a sufficiently large Newton decrement δk, we set the step-size αk to be the first instance of the sequence {1, ρ, ρ2, ρ3, . . .",3.5. The full algorithm,[0],[0]
},3.5. The full algorithm,[0],[0]
"that satisfies the Armijo–Goldstein condition
g(y + α∆y) ≤ g(y) + γα∆yT∇g(y),
in which γ ∈ (0, 0.5) and ρ ∈ (0, 1) are line search parameters.",3.5. The full algorithm,[0],[0]
Our implementation used γ = 0.01 and ρ = 0.5.,3.5. The full algorithm,[0],[0]
"We complete the step and repeat the process, until convergence.
",3.5. The full algorithm,[0],[0]
We terminate the outer Newton’s method if the Newton decrement δk falls below a threshold.,3.5. The full algorithm,[0],[0]
"This implies either that the solution has been reached, or that CG is not converging to a good enough ∆yk to make significant progress.",3.5. The full algorithm,[0],[0]
The associated estimator for Σ−1 is recovered by evaluating X̂ = −∇f∗(Cλ −A(ŷ)).,3.5. The full algorithm,[0],[0]
"Finally, we benchmark our algorithm against QUIC (Hsieh et al., 2014), commonly considered the fastest solver for graphical lasso or RGL1.",4. Numerical Results,[0],[0]
We consider two case studies.,4. Numerical Results,[0],[0]
The first case study numerically verifies the claimed O(n) complexity of our MDMC algorithm on problems with a nearly-banded structure.,4. Numerical Results,[0],[0]
"The second case study performs the full threshold-MDMC procedure for graphical lasso and RGL, on graphs collected from real-life applications.",4. Numerical Results,[0],[0]
All experiments are performed on a laptop computer with an Intel Core i7 quad-core 2.50 GHz CPU and 16GB RAM.,4. Numerical Results,[0],[0]
The reported results are based on a serial implementation in MATLAB-R2017b.,4. Numerical Results,[0],[0]
Both our Newton decrement threshold and QUIC’s convergence threshold are 10−7.,4. Numerical Results,[0],[0]
The first case study aims to verify the claimed O(n) complexity of our algorithm for MDMC.,4.1. Case Study 1: Banded Patterns,[0],[0]
"Here, we avoid the proposed thresholding step, and focus solely on the MDMC (4) problem.",4.1. Case Study 1: Banded Patterns,[0],[0]
Each sparsity pattern G is a corrupted banded matrices with bandwidth 101.,4.1. Case Study 1: Banded Patterns,[0],[0]
"The off-diagonal nonzero elements of C are selected from the uniform distribution in [−2, 0) and then corrupted to zero with probability 0.3.",4.1. Case Study 1: Banded Patterns,[0],[0]
The diagonal elements are fixed to 5.,4.1. Case Study 1: Banded Patterns,[0],[0]
"Our numerical experiments fix the bandwidth and vary the number of variables n from 1,000 to 200,000.",4.1. Case Study 1: Banded Patterns,[0],[0]
"A time limit of 2 hours is set for both algorithms.
",4.1. Case Study 1: Banded Patterns,[0],[0]
Figure 2 compares the running time of both algorithms.,4.1. Case Study 1: Banded Patterns,[0],[0]
"A log-log regression results in an empirical time complexity ofO(n1.1) for our algorithm, andO(n2) for QUIC.",4.1. Case Study 1: Banded Patterns,[0],[0]
The extra 0.1 in the exponent is most likely an artifact our MATLAB implementation.,4.1. Case Study 1: Banded Patterns,[0],[0]
"In either case, QUIC’s quadratic complexity limits it to n = 1.5 × 104.",4.1. Case Study 1: Banded Patterns,[0],[0]
"By contrast, our algorithm solves an instance with n = 2× 105 in less than 33 minutes.",4.1. Case Study 1: Banded Patterns,[0],[0]
"The resulting solutions are extremely accurate, with optimality and feasibility gaps of less than 10−16 and 10−7, respectively.",4.1. Case Study 1: Banded Patterns,[0],[0]
The second case study aims to benchmark the full thresholding-MDMC procedure for sparse inverse covariance estimation on real-life graphs.,4.2. Case Study 2: Real-Life Graphs,[0],[0]
"The actual graphs (i.e. the sparsity patterns) for Σ−1 are chosen from SuiteSparse Matrix Collection (Davis & Hu, 2011)—a publicly available dataset for large-and-sparse matrices collected from real-world applications.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"Our chosen graphs vary in size from n = 3918 to n = 201062, and are taken from ap-
1Two other widely-used algorithms are GLASSO (Friedman et al., 2008) and BIGQUIC (Hsieh et al., 2013).",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"On a serial machine and for the problem sizes that we consider, we found both to be slower than QUIC.
",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"plications in chemical processes, material science, graph problems, optimal control and model reduction, thermal processes and circuit simulations.
",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"For each sparsity pattern G, we design a corresponding Σ−1 as follows.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"For each (i, j) ∈ G, we select (Σ−1)i,j = (Σ−1)j,i from the uniform distribution in [−1, 1], and then corrupt it to zero with probability 0.3.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"Then, we set each diagonal to (Σ−1)i,i = 1 + ∑ j |(Σ−1)i,j |.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"Using this Σ, we generate N = 5000 samples i.i.d.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"as x1, . .",4.2. Case Study 2: Real-Life Graphs,[0],[0]
.,4.2. Case Study 2: Real-Life Graphs,[0],[0]
",xN ∼ N (0,Σ).",4.2. Case Study 2: Real-Life Graphs,[0],[0]
This results in a sample covariance matrix C = 1 N ∑N i=1,4.2. Case Study 2: Real-Life Graphs,[0],[0]
"xix T i .
",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"We solve graphical lasso and RGL with the C described above using our proposed soft-thresholding-MDMC algorithm and QUIC, in order to estimate Σ−1.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"In the case of RGL, we assume that the graph G is known a priori, while noting that 30% of the elements of Σ−1 have been corrupted to zero.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
Our goal here is to discover the location of these corrupted elements.,4.2. Case Study 2: Real-Life Graphs,[0],[0]
"In all of our simulations, the threshold λ is set so that the number of nonzero elements in the the estimator is roughly the same as the ground truth.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"We limit both algorithms to 3 hours of CPU time.
",4.2. Case Study 2: Real-Life Graphs,[0],[0]
Figure 3 compares the CPU time of both two algorithms for this case study; the specific details are provided in Table 1.,4.2. Case Study 2: Real-Life Graphs,[0],[0]
"A log-log regression results in an empirical time complexity of O(n1.64) and O(n1.55) for graphical lasso and RGL using our algorithm, and O(n2.46) and O(n2.52) for the same using QUIC.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"The exponents of our algorithm are ≥ 1 due to the initial soft-thresholding step, which is quadratic-time on a serial computer, but ≤ 2 because procedure is dominated by the solution of the MDMC.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"Both algorithms solve graphs with n ≤ 1.5 × 104 within the allotted time limit, though our algorithm is 11 times faster on average.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
Only our algorithm is able to solve the estimation problem with n,4.2. Case Study 2: Real-Life Graphs,[0],[0]
"≈ 2× 105 in a little more than an hour.
",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"To check whether thresholding-MDMC really does solve graphical lasso and RGL, we substitute the two sets of estimators back into their original problems (1) and (5).",4.2. Case Study 2: Real-Life Graphs,[0],[0]
"The corresponding objective values have a relative difference ≤ 4 × 10−4, suggesting that both sets of estimators are about equally optimal.",4.2. Case Study 2: Real-Life Graphs,[0],[0]
This observation verifies our claims in Theorem 2 and Corollary 3 that (1) and (5): thresholding-MDMC does indeed solve graphical lasso and RGL.,4.2. Case Study 2: Real-Life Graphs,[0],[0]
Graphical lasso is a widely-used approach for estimating a covariance matrix with a sparse inverse from limited samples.,5. Conclusions,[0],[0]
"In this paper, we consider a slightly more general formulation called restricted graphical lasso (RGL), which additionally enforces a prior sparsity pattern to the estimation.",5. Conclusions,[0],[0]
"We describe an efficient approach that substantially reduces the cost of solving RGL: 1) soft-thresholding the sample covariance matrix and projecting onto the prior pattern, to recover the estimator’s sparsity pattern; and 2) solving a maximum determinant matrix completion (MDMC) problem, to recover the estimator’s numerical values.",5. Conclusions,[0],[0]
The first step is quadratic O(n2) time and memory but embarrassingly parallelizable.,5. Conclusions,[0],[0]
"If the resulting sparsity pattern is sparse and chordal, then the second step can be performed using the Newton-CG algorithm described in this paper in linear O(n) time and memory.",5. Conclusions,[0],[0]
"The algorithm is tested on both synthetic and real-life data, solving instances with as many as 200,000 variables to 7-9 digits of accuracy within an hour on a standard laptop computer.
",5. Conclusions,[0],[0]
Acknowledgements.,5. Conclusions,[0],[0]
"This work was supported by the ONR grants N00014-17-1-2933 and N00014-15-1-2835, DARPA grant D16AP00002, and AFOSR grant FA955017-1-0163.",5. Conclusions,[0],[0]
"The sparse inverse covariance estimation problem is commonly solved using an `1-regularized Gaussian maximum likelihood estimator known as “graphical lasso”, but its computational cost becomes prohibitive for large data sets.",abstractText,[0],[0]
A recent line of results showed–under mild assumptions–that the graphical lasso estimator can be retrieved by soft-thresholding the sample covariance matrix and solving a maximum determinant matrix completion (MDMC) problem.,abstractText,[0],[0]
"This paper proves an extension of this result, and describes a Newton-CG algorithm to efficiently solve the MDMC problem.",abstractText,[0],[0]
"Assuming that the thresholded sample covariance matrix is sparse with a sparse Cholesky factorization, we prove that the algorithm converges to an -accurate solution in O(n log(1/ )) time and O(n) memory.",abstractText,[0],[0]
"The algorithm is highly efficient in practice: we solve the associated MDMC problems with as many as 200,000 variables to 7-9 digits of accuracy in less than an hour on a standard laptop computer running MATLAB.",abstractText,[0],[0]
Large-Scale Sparse Inverse Covariance Estimation via Thresholding and Max-Det Matrix Completion,title,[0],[0]
"Recurrent neural networks (RNNs) have shown impressive results in modeling generation tasks that have a sequential structured output form, such as machine translation (Sutskever et al., 2014; Bahdanau et al., 2015), caption generation (Karpathy & Fei-Fei, 2015; Xu et al., 2015), and natural language generation (Wen et al., 2015; Kiddon et al., 2016).",1. Introduction,[0],[0]
"These discriminative models are trained to learn only a conditional output distribution over strings and despite the sophisticated architectures and condition-
*Equal contribution 1Department of Engineering, University of Cambridge, Cambridge, United Kingdom 2Department of Computer Science, University of Oxford, Oxford, United Kingdom.",1. Introduction,[0],[0]
"Correspondence to: Tsung-Hsien Wen <thw28@cam.ac.uk>, Yishu Miao",1. Introduction,[0],[0]
"<yishu.miao@cs.ox.ac.uk>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, 2017.",1. Introduction,[0],[0]
JMLR: W&CP.,1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"ing mechanisms used to ensure salience, they are not able to model the underlying actions needed to generate natural dialogues.",1. Introduction,[0],[0]
"As a consequence, these sequence-to-sequence models are limited in their ability to exhibit the intrinsic variability and stochasticity of natural dialogue.",1. Introduction,[0],[0]
"For example both goal-oriented dialogue systems (Wen et al., 2017; Bordes & Weston, 2017) and sequence-to-sequence learning chatbots (Vinyals & Le, 2015; Shang et al., 2015; Serban et al., 2015) struggle to generate diverse yet causal responses (Li et al., 2016a; Serban et al., 2016).",1. Introduction,[0],[0]
"In addition, there is often insufficient training data for goal-oriented dialogues which results in over-fitting which prevents deterministic models from learning effective and scalable interactions.",1. Introduction,[0],[0]
"In this paper, we propose a latent variable model – Latent Intention Dialogue Model (LIDM) – for learning the complex distribution of communicative intentions in goaloriented dialogues.",1. Introduction,[0],[0]
"Here, the latent variable representing dialogue intention can be considered as the autonomous decision-making center of a dialogue agent for composing appropriate machine responses.
",1. Introduction,[0],[0]
"Recent advances in neural variational inference (Kingma & Welling, 2014; Mnih & Gregor, 2014) have sparked a series of latent variable models applied to NLP (Bowman et al., 2015; Serban et al., 2016; Miao et al., 2016; Cao & Clark, 2017).",1. Introduction,[0],[0]
"For models with continuous latent variables, the reparameterisation trick (Kingma & Welling, 2014) is commonly used to build an unbiased and low-variance gradient estimator for updating the models.",1. Introduction,[0],[0]
"However, since a continuous latent space is hard to interpret, the major benefits of these models are the stochasticity and the regularisation brought by the latent variable.",1. Introduction,[0],[0]
"In contrast, models with discrete latent variables are able to not only produce interpretable latent distributions but also provide a principled framework for semi-supervised learning (Kingma et al., 2014).",1. Introduction,[0],[0]
"This is critical for NLP tasks, especially where additional supervision and external knowledge can be utilized for bootstrapping (Faruqui et al., 2015; Miao & Blunsom, 2016; Kočiský et al., 2016).",1. Introduction,[0],[0]
"However, variational inference with discrete latent variables is relatively difficult due to the problem of high variance during sampling.",1. Introduction,[0],[0]
"Hence we introduce baselines, as in the REINFORCE (Williams, 1992) algorithm, to mitigate the high variance problem, and carry out efficient neural variational inference (Mnih & Gregor, 2014) for the latent variable model.",1. Introduction,[0],[0]
ar X iv :1 70 5.,1. Introduction,[0],[0]
"10 22 9v 1
[ cs
.C",1. Introduction,[0],[0]
"L
] 2
9 M
ay 2
01 7
In the LIDM, the latent intention is inferred from user input utterances.",1. Introduction,[0],[0]
"Based on the dialogue context, the agent draws a sample as the intention which then guides the natural language response generation.",1. Introduction,[0],[0]
"Firstly, in the framework of neural variational inference (Mnih & Gregor, 2014), we construct an inference network to approximate the posterior distribution over the latent intention.",1. Introduction,[0],[0]
"Then, by sampling the intentions for each response, we are able to directly learn a basic intention distribution on a human-human dialogue corpus by optimising the variational lower bound.",1. Introduction,[0],[0]
"To further reduce the variance, we utilize a labeled subset of the corpus in which the labels of intentions are automatically generated by clustering.",1. Introduction,[0],[0]
"Then, the latent intention distribution can be learned in a semi-supervised fashion, where the learning signals are either from the direct supervision (labeled set) or the variational lower bound (unlabeled set).
",1. Introduction,[0],[0]
"From the perspective of reinforcement learning, the latent intention distribution can be interpreted as the intrinsic policy that reflects human decision-making under a particular conversational scenario.",1. Introduction,[0],[0]
"Based on the initial policy (latent intention distribution) learnt from the semi-supervised variational inference framework, the model can refine its strategy easily against alternative objectives using policy gradient-based reinforcement learning.",1. Introduction,[0],[0]
"This is somewhat analagous to the training process used in AlphaGo (Silver et al., 2016) for the game of Go.",1. Introduction,[0],[0]
"Based on LIDM, we show that different learning paradigms can be brought together under the same framework to bootstrap the development of a dialogue agent (Li et al., 2016c; Weston, 2016).
",1. Introduction,[0],[0]
"In summary, the contribution of this paper is two-fold: firstly, we show that the neural variational inference framework is able to discover discrete, interpretable intentions from data to form the decision-making basis of a dialogue agent; secondly, the agent is capable of revising its conversational strategy based on an external reward within the same framework.",1. Introduction,[0],[0]
This is important because it provides a stepping stone towards building an autonomous dialogue agent that can continuously improve itself through interaction with users.,1. Introduction,[0],[0]
The experimental results demonstrate the effectiveness of our latent intention model which achieves state-of-the-art performance on both automatic corpus-based evaluation and human evaluation.,1. Introduction,[0],[0]
"Goal-oriented dialogue1 (Young et al., 2013) aims at building models that can help users to complete certain tasks via natural language interaction.",2. Latent Intention Dialogue Model for Goal-oriented Dialogue,[0],[0]
"Given a user input utterance ut at turn t and a knowledge base (KB), the model needs to
1Like most of the goal-oriented dialogue research, we focus on information seek type dialogues.
",2. Latent Intention Dialogue Model for Goal-oriented Dialogue,[0],[0]
parse the input into actionable commands Q and access the KB to search for useful information in order to answer the query.,2. Latent Intention Dialogue Model for Goal-oriented Dialogue,[0],[0]
"Based on the search result, the model needs to summarise its findings and reply with an appropriate response mt in natural language.",2. Latent Intention Dialogue Model for Goal-oriented Dialogue,[0],[0]
"The LIDM is based on the end-to-end system architecture described in (Wen et al., 2017).",2.1. Model,[0],[0]
"It comprises three components: (1) Representation Construction; (2) Policy Network; and (3) Generator, as shown in Figure 1.",2.1. Model,[0],[0]
"To capture the user’s intent and match it against the system’s knowledge, a dialogue state vector st = ut ⊕ bt ⊕ xt is derived from the user input ut and the knowledge base KB: ut is the distributed utterance representation, which is formed by encoding the user utterance2 ut with a bidirectional LSTM (Hochreiter & Schmidhuber, 1997) and concatenating the final stage hidden states together,
ut = biLSTMΘ(ut).",2.1. Model,[0],[0]
"(1)
The belief vector bt, which is a concatenation of a set of probability distributions over domain specific slot-value pairs, is extracted by a set of pre-trained RNN-CNN belief trackers (Wen et al., 2017; Mrkšić et al., 2017), in which ut and mt−1 are processed by two different CNNs as shown in Figure 1,
bt = RNN-CNN(ut,mt−1,bt−1) (2)
where mt−1 is the preceding machine response and bt−1 is the preceding belief vector.",2.1. Model,[0],[0]
"They are included to model the current turn of the discourse and the long-term dialogue context, respectively.",2.1. Model,[0],[0]
"Based on the belief vector, a query Q is formed by taking the union of the maximum values of each slot.",2.1. Model,[0],[0]
Q is then used to search the internal KB and return a vector xt representing the degree of matching in the KB.,2.1. Model,[0],[0]
This is produced by counting all the matching venues and re-structuring it into a six-bin one-hot vector.,2.1. Model,[0],[0]
"Among the three vectors that comprise the dialogue state st, ut is completely trainable from data, bt is pre-trained using a separate objective function, and xt is produced by a discrete database accessing operation.",2.1. Model,[0],[0]
"For more details about the belief trackers and database operation refer to Wen et al (2016; 2017).
",2.1. Model,[0],[0]
"Conditioning on the state st, the policy network parameterises the latent intention zt by a single layer MLP,
πΘ(zt|st) =",2.1. Model,[0],[0]
softmax(Wᵀ2,2.1. Model,[0],[0]
·,2.1. Model,[0],[0]
"tanh(W ᵀ 1st +b1) +b2) (3)
where W1, b1, W2, b2 are model parameters.",2.1. Model,[0],[0]
"Since πΘ(zt|st) is a discrete conditional probability distribution
2All sentences are pre-processed by delexicalisation (Henderson et al., 2014) where slot-value specific words are replaced with their corresponding generic tokens based on an ontology.
",2.1. Model,[0],[0]
"based on dialogue state, we can also interpret the policy network here as a latent dialogue management component in the traditional POMDP-based framework (Young et al., 2013; Gašić et al., 2013).",2.1. Model,[0],[0]
"A latent intention z(n)t (or an action in the reinforcement learning literature) can then be sampled from the conditional distribution,
z (n) t ∼ πΘ(zt|st).",2.1. Model,[0],[0]
"(4)
",2.1. Model,[0],[0]
This sampled intention (or action),2.1. Model,[0],[0]
"z(n)t and the state vector st can then be combined into a control vector dt, which is used to govern the generation of the system response based on a conditional LSTM language model,
dt = W ᵀ 4zt ⊕ [sigmoid(W ᵀ 3zt + b3)",2.1. Model,[0],[0]
·W ᵀ,2.1. Model,[0],[0]
5st],2.1. Model,[0],[0]
"(5)
pΘ(mt|st, zt) = ∏ j p(wtj+1|wtj ,htj−1,dt) (6)
where b3 and W3∼5 are parameters, zt is the 1-hot representation of z(n)t , w t j is the last output token (i.e. a word, a delexicalised2 slot name or a delexicalised2 slot value), and htj−1 is the decoder’s last hidden state.",2.1. Model,[0],[0]
Note in Equation 5 the degree of information flow from the state vector is controlled by a sigmoid gate whose input signal is the sampled intention z(n)t .,2.1. Model,[0],[0]
This prevents the decoder from overfitting to the deterministic state information and forces it to take the sampled stochastic intention into account.,2.1. Model,[0],[0]
"The LIDM can then be formally written down in its parame-
terised form with parameter set Θ, pΘ(mt|st) = ∑ zt pΘ(mt|zt, st)πΘ(zt|st).",2.1. Model,[0],[0]
(7),2.1. Model,[0],[0]
"To carry out inference for the LIDM, we introduce an inference network qΦ(zt|st,mt) to approximate the posterior distribution p(zt|st,mt) so that we can optimise the variational lower bound of the joint probability in a neural variational inference framework (Miao et al., 2016).",2.2. Inference,[0],[0]
"We can then derive the variational lower bound as,
L = EqΦ(zt)[log pΘ(mt|zt, st)]− λDKL(qΦ(zt)||πΘ(zt|st)) ≤ log ∑ zt pΘ(mt|zt, st)πΘ(zt|st)
= log pΘ(mt|st) (8)
where qΦ(zt) is a shorthand for qΦ(zt|st,mt).",2.2. Inference,[0],[0]
"Note that we use a modified version of the lower bound here by incorporating a trade-off factor λ (Higgins et al., 2017).",2.2. Inference,[0],[0]
"The inference network qΦ(zt|st,mt) is then constructed by
qΦ(zt|st,mt) = Multi(ot) = softmax(W6ot) (9)
ot = MLPΦ(bt,xt,ut,mt) (10)
",2.2. Inference,[0],[0]
"ut = biLSTMΦ(ut),mt = biLSTMΦ(mt) (11)
where ot is the joint representation, and both ut and mt are modeled by a bidirectional LSTM network.",2.2. Inference,[0],[0]
"Although both
qΦ(zt|st,mt) and πΘ(zt|st) are modelled as parameterised multinomial distributions, the approximation qΦ(zt|st,mt) only functions during inference by producing samples to compute the stochastic gradients, while πΘ(zt|st) is the generative distribution that generates the required samples for composing the machine response.
",2.2. Inference,[0],[0]
"Based on the samples z(n)t ∼ qΦ(zt|st,mt), we use different strategies to alternately optimise the parameters Θ and Φ against the variational lower bound (Equation 8).",2.2. Inference,[0],[0]
"To do this, we further divide Θ into two sets Θ = {Θ1,Θ2}.",2.2. Inference,[0],[0]
"Parameters Θ1 on the decoder side are directly updated by back-propagating the gradients,
∂L ∂Θ1 = EqΦ(zt|st,mt)[ ∂ log pΘ1(mt|zt, st) ∂Θ1 ]
",2.2. Inference,[0],[0]
"≈ 1 N ∑ n ∂ log pΘ1(mt|z (n) t , st) ∂Θ1 .",2.2. Inference,[0],[0]
"(12)
Parameters Θ2 in the generative network, however, are updated by minimising the KL divergence,
∂L ∂Θ2 = −∂λDKL(qΦ(zt|st,mt)||πΘ2(zt|st))",2.2. Inference,[0],[0]
"∂Θ2
= −λ ∑ zt qΦ(zt|st,mt) ∂ log πΘ2(zt|st) ∂Θ2 (13)
where the entropy derivative ∂H[qΦ(zt|st,mt)]/∂Θ2 = 0 and therefore can be ignored.",2.2. Inference,[0],[0]
"Finally, for the parameters Φ in the inference network, we firstly define the learning signal r(mt, z (n) t , st),
r(mt,z (n) t , st) = log pΘ1(mt|z (n) t , st)−
λ(log qΦ(z (n) t |st,mt)− log πΘ2(z (n) t |st)).",2.2. Inference,[0],[0]
"(14)
Then the parameters Φ are updated by,
∂L ∂Φ = EqΦ(at|st,mt)[r(mt, at, st) ∂ log qΦ(at|st,mt) ∂Φ ]
≈ 1 N ∑ n r(mt, z (n) t , st) ∂ log qΦ(z (n) t |st,mt) ∂Φ .",2.2. Inference,[0],[0]
"(15)
However, this gradient estimator has a large variance because the learning signal r(mt, z (n) t , st) relies on samples from the proposal distribution qΦ(zt|st,mt).",2.2. Inference,[0],[0]
"To reduce the variance during inference, we follow the REINFORCE algorithm (Mnih et al., 2014; Mnih & Gregor, 2014) and introduce two baselines b and b(st), the centered learning signal and input dependent baseline respectively to help reduce the variance.",2.2. Inference,[0],[0]
b is a learnable constant and b(st) = MLP(st).,2.2. Inference,[0],[0]
"During training, the two baselines are updated by minimising the distance,
Lb = [ r(mt, z (n) t , st)− b− b(st)",2.2. Inference,[0],[0]
"]2 (16)
and the gradient w.r.t.",2.2. Inference,[0],[0]
"Φ can be rewritten as
∂L ∂Φ ≈ 1 N ∑ n",2.2. Inference,[0],[0]
"[r(mt, z (n) t , st)−b−b(st)] ∂ log qΦ(z (n) t |st,mt) ∂Φ .
",2.2. Inference,[0],[0]
(17),2.2. Inference,[0],[0]
"Despite the steps described above for reducing the variance, there remain two major difficulties in learning latent intentions in a completely unsupervised manner: (1) the high variance of the inference network prevents it from generating sensible intention samples in the early stages of training, and (2) the overly strong discriminative power of the LSTM language model is prone to the disconnection phenomenon between the LSTM decoder and the rest of the components whereby the decoder learns to ignore the samples and focuses solely on optimising the language model.",2.3. Semi-Supervision,[0],[0]
"To ensure more stable training and prevent disconnection, a semi-supervised learning technique is introduced.
",2.3. Semi-Supervision,[0],[0]
Inferring the latent intentions underlying utterances is similar to an unsupervised clustering task.,2.3. Semi-Supervision,[0],[0]
"Standard clustering algorithms can therefore be used to pre-process the corpus and generate automatic labels ẑt for part of the training examples (mt, st, ẑt) ∈",2.3. Semi-Supervision,[0],[0]
L.,2.3. Semi-Supervision,[0],[0]
"Then when the model is trained on the unlabeled examples (mt, st) ∈ U, we optimise it against the modified variational lower bound given in Equation 8
L1 = ∑
(mt,st)∈U
Eqφ(zt|st,mt) [log pθ(mt|zt, st)]
− λDKL(qφ(zt|st,mt)||πθ(zt|st))",2.3. Semi-Supervision,[0],[0]
"(18)
However, when the model is updated based on examples from the labeled set (mt, st, ẑt) ∈ L, we treat the labeled intention ẑt as an observed variable and train the model by maximising the joint log-likelihood,
L2 = ∑
(mt,ẑt,st)∈L
log [pΘ(mt|ẑt, st)πΘ(ẑt|st)qΦ(ẑt|st,mt)]
(19) The final joint objective function can then be written as L′ = αL1 + L2, where α controls the trade-off between the supervised and unsupervised examples.",2.3. Semi-Supervision,[0],[0]
"One of the main purposes of learning interpretable, discrete latent intention inside a dialogue system is to be able to control and refine the model’s behaviour with operational experience.",2.4. Reinforcement Learning,[0],[0]
The learnt generative network πΘ(zt|st) encodes the policy discovered from the underlying data distribution but this is not necessarily optimal for any specific task.,2.4. Reinforcement Learning,[0],[0]
"Since πΘ(zt|st) is a parameterised policy network itself, any policy gradient-based reinforcement learning algorithm (Williams, 1992; Konda & Tsitsiklis, 2003) can be
used to fine-tune the initial policy against other objective functions that we are more interested in.
",2.4. Reinforcement Learning,[0],[0]
"Based on the initial policy πΘ(zt|st), we revisit the training dialogues and update parameters based on the following strategy: when encountering unlabeled examples U at turn t the system samples an action from the learnt policy z
(n) t ∼ πΘ(zt|st) and receives a reward r (n) t .",2.4. Reinforcement Learning,[0],[0]
"Conditioning on these, we can directly fine-tune a subset of the model parameters Θ′ by the policy gradient method,
∂J ∂Θ′",2.4. Reinforcement Learning,[0],[0]
≈ 1 N ∑ n r (n) t ∂ log πΘ(z (n) t |st) ∂Θ′,2.4. Reinforcement Learning,[0],[0]
"(20)
where Θ′ = {W1,b1,W2,b2} is the MLP that parameterises the policy network (Equation 3).",2.4. Reinforcement Learning,[0],[0]
"However, when a labeled example ∈ L is encountered we force the model to take the labeled action z(n)t = ẑt and update the parameters by Equation 20 as well.",2.4. Reinforcement Learning,[0],[0]
"Unlike Li et al (2016c) where the whole model is refined end-to-end using RL, updating only Θ′ effectively allows us to refine only the decision-making of the system and avoid the problem of over-fitting.",2.4. Reinforcement Learning,[0],[0]
"We explored the properties of the LIDM model3 using the CamRest676 corpus4 collected by Wen et al (2017), in which the task of the system is to assist users to find a restaurant in the Cambridge, UK area.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"The corpus was collected based on a modified Wizard of Oz (Kelley, 1984) online data collection.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"Workers were recruited on Amazon Mechanical Turk and asked to complete a task by carrying out a conversation, alternating roles between a user and a wizard.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"There are three informable slots (food, pricerange, area) that users can use to constrain the search and six requestable slots (address, phone, postcode plus the three informable slots) that the user can ask a value for once a restaurant has been offered.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
There are 676 dialogues in the dataset (including both finished and unfinished dialogues) and approximately 2750 conversational turns in total.,3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"The database contains 99 unique restaurants.
",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
To make a direct comparison with prior work we follow the same experimental setup as in Wen et al (2016; 2017).,3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"The corpus was partitioned into training, validation, and test sets in the ratio 3:1:1.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"The LSTM hidden layer sizes were set to 50, and the vocabulary size is around 500 after pre-processing, to remove rare words and words that can be delexicalised2.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"All the system components were trained jointly by fixing the pre-trained belief trackers and the discrete database operator with the model’s latent intention
3Will be available at https://github.com/shawnwun/NNDIAL 4https://www.repository.cam.ac.uk/handle/1810/260970
size I set to 50, 70, and 100, respectively.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
The trade-off constants λ and α were both set to 0.1.,3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"To produce selflabeled response clusters for semi-supervised learning of the intentions, we firstly removed function words from all the responses and clustered them according to their content words.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
We then assigned the responses in the i-th frequent cluster to the i-th latent dimension as its supervised set.,3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
This results in about 35% (I = 50) to 43% (I = 100) labeled responses across the whole dataset.,3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
An example of the resulting seed set is shown in Table 1.,3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
During inference we carried out stochastic estimation by taking one sample for estimating the stochastic gradients.,3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"The model is trained by Adam (Kingma & Ba, 2014) and tuned (early stopping, hyper-parameters) on the held-out validation set.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"We alternately optimised the generative model and the inference network by fixing the parameters of one while updating the parameters of the other.
",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"During reinforcement fine-tuning, we generated a sentence mt from the model to replace the ground truth m̂t at each turn and define an immediate reward as whether mt can improve the dialogue success (Su et al., 2015) relative to m̂t, plus the sentence BLEU score (Auli & Gao, 2014),
rt = η · sBLEU(mt, m̂t) +  1 mt improves −1 mt degrades 0",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"otherwise
(21)
where the constant η was set to 0.5.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
We fine-tuned the model parameters using RL for only 3 epochs.,3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"During testing, we greedily selected the most probable intention and applied beam search with the beamwidth set to 10 when decoding the response.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
The decoding criterion was the average log-probability of tokens in the response.,3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
"We then evaluated our model on task success rate (Su et al., 2015) and BLEU score (Papineni et al., 2002) as in Wen et al (2016; 2017) in which the model is used to predict each system response in the held-out test set.",3.1. Dataset & Setup for Goal-oriented Dialogue,[0],[0]
Table 2 presents the results of the corpus-based evaluation.,3.2. Experiments on Goal-oriented Dialogue,[0],[0]
The Ground Truth block shows the two metrics when we compute them on the human-authored responses.,3.2. Experiments on Goal-oriented Dialogue,[0],[0]
This sets a gold standard for the task.,3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"In the Published Models block, the results for the three baseline models were borrowed from Wen et al (2016), they are: (1) the vanilla neural dialogue model (NDM), (2) NDM plus an attention mechanism on the belief trackers, and (3) the attentive NDM with self-supervised sub-task neurons.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"The results of the LIDM model with and without RL fine-tuning are shown in the LIDM Models and the LIDM Models + RL blocks, respectively.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"As can be seen, the initial policy learned by fitting the latent intention to the underlying data distribution yielded reasonably good results on BLEU but did not perform well on task success when compared to their deterministic counterparts (block 2 v.s. 3).",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
This may be due to the fact that the variational lower bound of the dataset was optimised rather than task success during variational inference.,3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"However, once RL was applied to optimise the success rate as part of the reward function (Equation 21) during the fine-tuning phase, the resulting LIDM+RL models outperformed the three baselines in terms of task success without significantly sacrificing BLEU (block 2 v.s. 4)5.
",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"In order to assess the human perceived performance, we evaluated the three models (1) NDM, (2) LIDM, and (3) LIDM+RL by recruiting paid subjects on Amazon Mechanical Turk.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
Each judge was asked to follow a task and carried out a conversation with the machine.,3.2. Experiments on Goal-oriented Dialogue,[0],[0]
At the end of each conversation the judges were asked to rate and compare the model’s performance.,3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"We assessed the subjective
5Note that both NDM+Att+SS and LIDM use self-supervised information
success rate, the perceived comprehension ability and the naturalness of responses on a scale of 1 to 5.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"For each model, we collected 200 dialogues and averaged the scores.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"During human evaluation, we sampled from the top-5 intentions of the LIDM models and decoded a response based on the sample.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
The result is shown in Table 3.,3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"One interesting fact to note is that although the LIDM did not perform well on the corpus-based task success metric, the human judges rated its subjective success almost indistinguishably from the others.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
This discrepancy between the two experiments arises mainly from a flaw in the corpus-based success metric in that it favors greedy policies because the user side behaviours are fixed rather than interactional6.,3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"Despite the fact that LIDMs are considered only marginally better than NDM on subjective success, the LIDMs do outperform NDM on both comprehension and naturalness scores.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"This is because the proposed LIDM models can better capture multiple modes in the communicative intention and thereby respond more naturally by sampling from the latent intention variable.
",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"Three example conversations are shown between a human judge and a machine, one from LIDM in Table 4 and two from LIDM+RL in Table 5, respectively.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
The results are displayed one exchange per block.,3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"Each induced latent intention is shown by a tuple (index, probability) followed by a decoded response, and the sample dialogues were produced by following the responses highlighted in bold.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"As can be seen, the LIDM shown in Table 4 clearly has multiple modes in the distribution over the learned intention latent variable, and what it represents can be easily interpreted by the response generated.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"However, some intentions (such as intent 0) can result in very different responses under different dialogue states even though they were supervised by a small response set as shown in Table 1.",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
This is mainly because of the variance introduced during variational inference.,3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"Finally, when comparing Table 4 and Table 5, we can observe the difference between the two dialogue strategies: the LIDM, by inferring its policy from the supervised dataset, reflects the diverse set of modes in the underlying distribution; whereas the LIDM+RL, which
6The system tries to provide as much information as possible in the early turns, in case the fixed user side behaviours a few turns later do not fit the scenario the system originally planned.
",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
"refined its strategy using RL, exhibits a much greedier behavior in achieving task success (e.g. in Table 5 in block 2 & 4 the LIDM+RL agent provides the address and phone number even before the user asks).",3.2. Experiments on Goal-oriented Dialogue,[0],[0]
This is also supported by the human evaluation in Table 3 where LIDM+RL has much shorter dialogues on average compared to the other two models.,3.2. Experiments on Goal-oriented Dialogue,[0],[0]
Learning an end-to-end dialogue system is appealing but challenging because of the credit assignment problem.,4. Discussion,[0],[0]
Discrete latent variable dialogue models such as LIDM are attractive because the latent variable can serve as an interface for decomposing the learning of language and the internal dialogue decision-making.,4. Discussion,[0],[0]
This decomposition can effectively help us resolve the credit assignment problem where different learning signals can be applied to different sub-modules to update the parameters.,4. Discussion,[0],[0]
"In variational inference for discrete latent variables, the latent distribution is basically updated by the reward from the variational lower bound.",4. Discussion,[0],[0]
"While in reinforcement learning, the latent distribution (i.e. policy network) is updated by the rewards from dialogue success and sentence BLEU score.",4. Discussion,[0],[0]
"Hence, the latent variable bridges the different learning paradigms such as Bayesian learning and reinforcement learning and brings them together under the same framework.",4. Discussion,[0],[0]
"This framework provides a more robust neural network-based approach than previous approaches because it does not depend solely on sequence-to-sequence learning but instead
explicitly models the hidden dialogue intentions underlying the user’s utterances and allows the agent to directly learn a dialogue policy through interaction.",4. Discussion,[0],[0]
"Modeling chat-based dialogues (Serban et al., 2015; Shang et al., 2015) as a sequence-to-sequence learning (Sutskever et al., 2014) problem is a common theme in the deep learning community.",5. Related work,[0],[0]
Vinyals and Le (2015) has demonstrated a seq2seq-based model trained on a huge amount of conversation corpora which learns interesting replies conditioned on different user queries.,5. Related work,[0],[0]
"However, due to an inability to model dialogue context, these models generally suffer from the generic response problem (Li et al., 2016a; Serban et al., 2016).",5. Related work,[0],[0]
"Several approaches have been proposed to mitigate this issue, such as modeling the persona (Li et al., 2016b), reinforcement learning (Li et al., 2016c), and introducing continuous latent variables (Serban et al., 2016; Cao & Clark, 2017).",5. Related work,[0],[0]
"While in our case, we not only make use of the latent variable to inject stochasticity for generating natural and diverse machine responses but also model the hidden dialogue intentions explicitly.",5. Related work,[0],[0]
"This combines the merits of reinforcement learning and generative models.
",5. Related work,[0],[0]
"At the other end of the spectrum, goal-oriented dialogue systems typically adopt the POMDP framework (Young et al., 2013) and break down the development of the dialogue systems into a pipeline of modules: natural language understanding (Henderson, 2015), dialogue manage-
ment (Gašić et al., 2013), and natural language generation (Wen et al., 2015).",5. Related work,[0],[0]
"These system modules communicate through a dialogue act formalism (Traum, 1999), which in effect constitute a fixed set of handcrafted intentions.",5. Related work,[0],[0]
This limits the ability of such systems to scale to more complex tasks.,5. Related work,[0],[0]
"In contrast, the LIDM directly infers all underlying dialogue intentions from data and can handle intention distributions with long tails by measuring similarities against the existing ones during variational inference.",5. Related work,[0],[0]
"Modeling of end-to-end goal-oriented dialogue systems has also been studied recently (Wen et al., 2016; 2017; Bordes & Weston, 2017), however, these models are typically deterministic and rely on decoder supervision signals to finetune a large set of model parameters.
",5. Related work,[0],[0]
Much research has focused on combining different learning paradigms and signals to bootstrap performance.,5. Related work,[0],[0]
"For example, semi-supervised learning (Kingma et al., 2014) has been applied in the sample-based neural variational inference framework as a way to reduce sample variance.",5. Related work,[0],[0]
"In practice, this relies on a discrete latent variable (Miao & Blunsom, 2016; Kočiský et al., 2016) as the vehicle for the supervision labels.",5. Related work,[0],[0]
"As in reinforcement learning, which has been a very common learning paradigm in dialogue systems (Gašić et al., 2013; Su et al., 2016; Li et al., 2017), the policy is also parameterised by a discrete set of actions.",5. Related work,[0],[0]
"As a consequence, the LIDM, which parameterises the intention space via a discrete latent variable, can automatically enjoy the benefit of bootstrapping from signals coming from different learning paradigms.",5. Related work,[0],[0]
"In addition, selfsupervised learning (Snow et al., 2004) (or distant, weak
supervision) as a simple way to generate automatic labels by heuristics is popular in many NLP tasks and has been applied to memory networks (Hill et al., 2016) and neural dialogue systems (Wen et al., 2016) recently.",5. Related work,[0],[0]
"Since there is no additional effort required in labeling, it can also be viewed as a method for bootstrapping.",5. Related work,[0],[0]
"In this paper, we have proposed a framework for learning dialogue intentions via discrete latent variable models and introduced the Latent Intention Dialogue Model (LIDM) for goal-oriented dialogue modeling.",6. Conclusion,[0],[0]
We have shown that the LIDM can discover an effective initial policy from the underlying data distribution and is capable of revising its strategy based on an external reward using reinforcement learning.,6. Conclusion,[0],[0]
We believe this is a promising step forward for building autonomous dialogue agents since the learnt discrete latent variable interface enables the agent to perform learning using several differing paradigms.,6. Conclusion,[0],[0]
The experiments showed that the proposed LIDM is able to communicate with human subjects and outperforms previous published results.,6. Conclusion,[0],[0]
"Tsung-Hsien Wen is supported by Toshiba Research Europe Ltd, Cambridge Research Laboratory.",Acknowledgements,[0],[0]
The authors would like to thank the members of the Cambridge Dialogue Systems Group for their valuable comments.,Acknowledgements,[0],[0]
Developing a dialogue agent that is capable of making autonomous decisions and communicating by natural language is one of the long-term goals of machine learning research.,abstractText,[0],[0]
Traditional approaches either rely on hand-crafting a small state-action set for applying reinforcement learning that is not scalable or constructing deterministic models for learning dialogue sentences that fail to capture natural conversational variability.,abstractText,[0],[0]
"In this paper, we propose a Latent Intention Dialogue Model (LIDM) that employs a discrete latent variable to learn underlying dialogue intentions in the framework of neural variational inference.",abstractText,[0],[0]
"In a goal-oriented dialogue scenario, these latent intentions can be interpreted as actions guiding the generation of machine responses, which can be further refined autonomously by reinforcement learning.",abstractText,[0],[0]
"The experimental evaluation of LIDM shows that the model out-performs published benchmarks for both corpus-based and human evaluation, demonstrating the effectiveness of discrete latent variable models for learning goal-oriented dialogues.",abstractText,[0],[0]
Latent Intention Dialogue Models,title,[0],[0]
"Sequential data prediction is an important problem in machine learning spanning over a diverse set of applications ranging from text (Mikolov et al., 2010) to user behavior (Köck & Paramythis, 2011).",1. Introduction,[0],[0]
"For example, when applied to statistical language modeling, the goal is to predict the next word in textual data given context, very similar to that in user activity modeling where the aim is to predict the next
1Carnegie Mellon University, Pittsburgh PA – work done while at Google 2Google Inc, Mountain View CA.",1. Introduction,[0],[0]
"Correspondence to: Manzil Zaheer <manzil@cmu.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
activity of the user given the history.",1. Introduction,[0],[0]
"Accurate user activity modeling is very important for serving relevant, personalized, and useful contents to the user.",1. Introduction,[0],[0]
"A good model of sequential data should be accurate, sparse, and interpretable.",1. Introduction,[0],[0]
"Unfortunately, none of the existing techniques for user or language modeling satisfy all of these requirements.
",1. Introduction,[0],[0]
"The state-of-the-art for modeling sequential data is to employ recurrent neural networks (RNN) (Lipton et al., 2015), such as LSTMs (Long-Short Term Memory) (Hochreiter & Schmidhuber, 1997).",1. Introduction,[0],[0]
"Such RNNs have been shown to be effective at capturing long and short patterns in data, e.g. token-level semantic as well as syntactic regularities in language (Jozefowicz et al., 2016).",1. Introduction,[0],[0]
"However, the neural network representations are generally uninterpretable and inaccessible to humans (Strobelt et al., 2016).",1. Introduction,[0],[0]
"Moreover, the number of parameters of the model is proportional to the number of observed word types or action types, which can grow to tens or hundreds of millions.",1. Introduction,[0],[0]
"Note that for user modeling task, character level RNN is not feasible because user actions are often not words but hash indices or URLs.
",1. Introduction,[0],[0]
"On the other hand of the spectrum, latent variable models with multi-task learning, such as LDA (Blei et al., 2002) and other topic model variants, which are strictly not sequence models, proved to be powerful tools for uncovering latent structure in both text and user data (Aly et al., 2012) with good commercial success (Hu et al., 2014).",1. Introduction,[0],[0]
Topic models are popular for their ability to organize the data into a smaller set of prominent themes or topics through statistical strength sharing across users or documents.,1. Introduction,[0],[0]
"These topic representations are generally accessible to humans and easily lend themselves to being interpreted.
",1. Introduction,[0],[0]
"In this paper, we propose Latent LSTM Allocation (LLA), a model that bridges the gap between the sequential RNN’s and the non-sequential LDA.",1. Introduction,[0],[0]
"LLA borrows graph-
ical model techniques to infer topics (groups of related word or user activities) by sharing statistical strength across users/documents and recurrent deep networks to model the dynamics of topic evolution inside each sequence (document or user activities) rather than at user action/word level (Sec. 3.1).",1. Introduction,[0],[0]
"LLA inherits sparsity and interpretability from LDA, while borrowing accuracy from LSTM.",1. Introduction,[0],[0]
We provide various variants of LLA that trade model size vs. accuracy without sacrificing interpretability (Sec. 3.3).,1. Introduction,[0],[0]
"As shown in Figure 1, for the task of language modeling on the Wikipedia dataset, LLA achieves comparable accuracy to LSTM while being as sparse as LDA in terms of models size.",1. Introduction,[0],[0]
We give an efficient inference algorithm for parameter inference in LLA (Sec. 3.2) and show is efficacy and interpretability over several datasets (Sec. 4).,1. Introduction,[0],[0]
"In this section, we provide a brief review of user/language modeling and LSTMs.",2. Background,[0],[0]
"User activity modeling and language modeling amounts to learning a function that computes the log probability, log p(w|model), of a user activity or sentence w = (w1, . . .",2.1. User/Language Modeling,[0],[0]
", wn).",2.1. User/Language Modeling,[0],[0]
"Subsequently, this function can be used to predict the next set of actions or words.",2.1. User/Language Modeling,[0],[0]
This function can be decomposed and learned in different ways under various assumptions.,2.1. User/Language Modeling,[0],[0]
Imposing a bag of words assumption - as used in LDA - leads to ignoring the sequence information and yields ∑n i=1 log p(wi|model).,2.1. User/Language Modeling,[0],[0]
"Alternatively, one could decompose according to the chain rule into sum of the conditional log probabilities∑n i=1 log p(wi | w1, . . .",2.1. User/Language Modeling,[0],[0]
", wi−1,model), thereby preserving temporal information and use some RNN to model log p(wi | w1, . . .",2.1. User/Language Modeling,[0],[0]
", wi−1,model) (Mikolov et al., 2010; Sundermeyer et al., 2012).",2.1. User/Language Modeling,[0],[0]
Temporal aspect is very important for user activity modeling.,2.2. Long Short-Term Memories,[0],[0]
"LSTM, a type of RNN, is well suited for the task as it can learn from experience to classify, process, and predict time series when there are very long time lags of unknown size between important events.",2.2. Long Short-Term Memories,[0],[0]
"LSTM is designed to cope with the vanishing gradient problem inherent in simple RNNs (Hochreiter & Schmidhuber, 1997).",2.2. Long Short-Term Memories,[0],[0]
"This is one of the main reasons why LSTMs outperform simple RNNs, hidden Markov models, and other sequence learning methods in numerous application.
",2.2. Long Short-Term Memories,[0],[0]
"In general, a RNN is a triplet (Σ, S, δ): • Σ ⊆ RD is the input alphabet •",2.2. Long Short-Term Memories,[0],[0]
S ⊆ RH is the set of states • δ,2.2. Long Short-Term Memories,[0],[0]
": S × Σ → S is the state transition function made
up of a neural network.",2.2. Long Short-Term Memories,[0],[0]
"RNN maintains an internal state and at each time step take
an input xt and updates its state st by applying the transition function made up of neural network δ",2.2. Long Short-Term Memories,[0],[0]
"the previous time step’s state st−1 and the input.
",2.2. Long Short-Term Memories,[0],[0]
Often the input is not available directly as elements of Σ and the output desired is not the state of the RNN.,2.2. Long Short-Term Memories,[0],[0]
"In such cases, input is appropriately transformed and desired output is produced at each time step from the state st:
yt = g(st),
where g is an arbitrary differentiable function.
",2.2. Long Short-Term Memories,[0],[0]
"For example, in a regular recurrent language model (RRLM) (Mikolov et al., 2010) a document is treated as a sequence and an LSTM is trained to predict directly the next word conditioned on the sequence of words before it, i.e. maximize p(wt|wt−1|, wt−2, ..., w0; model).",2.2. Long Short-Term Memories,[0],[0]
"In this case, the input transformation is done by using a word lookup table from word to a vector in Σ.",2.2. Long Short-Term Memories,[0],[0]
This word representation is used to update the state of the LSTM.,2.2. Long Short-Term Memories,[0],[0]
The output transformation is the projection of st into a vector of size of the vocabulary V followed by a softmax.,2.2. Long Short-Term Memories,[0],[0]
"However, this method will require two large matrices of dimension V ×H and cannot handle out of vocabulary words.
",2.2. Long Short-Term Memories,[0],[0]
"To overcome above mentioned shortcomings, another input transformation has been proposed, which looks at characters directly instead of words (Ling et al., 2015).",2.2. Long Short-Term Memories,[0],[0]
On the spelling of the words another LSTM is run having characters as the input and the final state is used as the word representation.,2.2. Long Short-Term Memories,[0],[0]
"In this case, the memory requirement is reduced to half and the model can handle out-of-vocabulary words like typographical errors or new words made from composing existing ones.",2.2. Long Short-Term Memories,[0],[0]
"To use character level embedding, we can simply replace the word lookup table with the representation obtained from character-level LSTM.",2.2. Long Short-Term Memories,[0],[0]
"In case of natural languages, a similar trick of using a character-level LSTM to emit words can be applied as the output transformation as well.",2.2. Long Short-Term Memories,[0],[0]
"However, user modeling outputs (hash indices and URLs) lack morphological structure, and hence cannot leverage the technique.",2.2. Long Short-Term Memories,[0],[0]
"In this section, we provide a detailed description of the proposed LLA model and its variant for performing joint clustering and modeling non-linear dynamics.",3. Latent LSTM Allocation,[0],[0]
An ideal model for such a task should have three characteristics.,3. Latent LSTM Allocation,[0],[0]
"First, it should have a low number of parameters.",3. Latent LSTM Allocation,[0],[0]
"Second, it should be interpretable, allowing human analysis of the components.",3. Latent LSTM Allocation,[0],[0]
"Lastly and most importantly, the model should be accurate in terms of predicting future events.",3. Latent LSTM Allocation,[0],[0]
We show how LLA satisfies all of these requirements.,3. Latent LSTM Allocation,[0],[0]
"In this model, we try to marry LDA with its strong interpretability capabilities with LSTM having excellent track record in capturing temporal information.",3.1. Generative model,[0],[0]
"In this regard,
we propose a factored model, i.e. we use the LSTM to model sequence of topics p(zt|zt−1, zt−2, ..., z1) and multinomial-Dirichlet to model word emissions p(wi|zi), similar to LDA.",3.1. Generative model,[0],[0]
"Suppose we have K topics, vocabulary size V , and a document collectionD where each document d ∈ D is composed of Nd words.",3.1. Generative model,[0],[0]
"With these notations, the complete generative process can be illustrated as in Figure 2a and can be described as:
1.",3.1. Generative model,[0],[0]
for k = 1 to K (a) Choose topic φk ∼ Dir(β) 2.,3.1. Generative model,[0],[0]
"for each document d in corpus D (a) Initialize LSTM with s0 = 0 (b) for each word index t from 1 to Nd
i. Update st = LSTM(zd,t−1, st−1) ii.",3.1. Generative model,[0],[0]
"Get topic proportions at time t from the
LSTM state, θ = softmaxK(Wpst + bp) iii.",3.1. Generative model,[0],[0]
"Choose a topic zd,t ∼ Categorical(θ) iv.",3.1. Generative model,[0],[0]
"Choose word wd,t ∼ Categorical(φzd,t)
",3.1. Generative model,[0],[0]
"Under this model, the marginal probability of observing a given document d can be written as:
p(wd|LSTM,φ) =",3.1. Generative model,[0],[0]
"∑ zd p(wd, zd|LSTM,φ)
= ∑ zd ∏ t p(wd,t|zd,t;φ)p(zd,t|zd,1:t−1; LSTM).
",3.1. Generative model,[0],[0]
"Here p(zd,t|zd,1:t−1; LSTM) is the probability of generating topic for the next word in the document given topics of previous words and p(wd,t|zd,t;φ) is the probability of generating word given the topic, illustrating the simple modification of LSTM and LDA based language models.
",3.1. Generative model,[0],[0]
The advantage of this modification is two fold.,3.1. Generative model,[0],[0]
"Firstly, we obtain a factored model as shown in Figure 3, thereby the number of parameters is reduced significantly compared to RRLM.",3.1. Generative model,[0],[0]
"This is because, unlike RRLM we operate at topic level instead of words directly and the number of topics is much smaller than the vocabulary size, i.e., K << V .
",3.1. Generative model,[0],[0]
This allows us to get rid of large V ×H word embedding look-up table and V × H matrix used in softmax over the entire vocabulary.,3.1. Generative model,[0],[0]
"Instead we map from hidden to state to topics first using a K ×H matrix, which will be dense and then from topics to words using a V ×K matrix under the Dirichlet-multinomial model similar to LDA which will be very sparse.",3.1. Generative model,[0],[0]
"Secondly, this model is highly interpretable.",3.1. Generative model,[0],[0]
We recover global themes present in the documents as φ.,3.1. Generative model,[0],[0]
The LSTM output represents topic proportions for document/user at time t. The LSTM input over topics can capture semantic notion of topics.,3.1. Generative model,[0],[0]
"As the computation of the true posterior of LLA as described above is intractable, we have to resort to an approximate inference technique like mean field variational inference (Wainwright & Jordan, 2008) or stochastic EM (SEM) (Zaheer et al., 2016).",3.2. Inference,[0],[0]
Below we describe the generic aspects of the inference algorithm for LLA.,3.2. Inference,[0],[0]
Model specific aspects are relegated to the appendix.,3.2. Inference,[0],[0]
"1
Given a document collection, the inference task is to find the LSTM weights and word|topic probability matrix φ.",3.2. Inference,[0],[0]
This can be carried out using SEM.,3.2. Inference,[0],[0]
"We begin by writing out the likelihood and lower bounding it as,∑
d
log p(wd|LSTM,φ)
≥ ∑ d ∑ zd q(zd) log p(zd; LSTM)",3.2. Inference,[0],[0]
"∏ t p(wd,t|zd,t;φ) q(zd) ,
(1) for any distribution q.",3.2. Inference,[0],[0]
Then the goal is to ensure an increase in this evidence lower bound (ELBO) with each iteration in expectation.,3.2. Inference,[0],[0]
"Following the suit of most EM based inference methods, each iteration involves two phases, each of which is described below:
SE-step: For fixed LSTM parameters andφ, we sample the topic assignments",3.2. Inference,[0],[0]
z. This acts as an unbiased sample estimate of the expectation with respect to the conditional distribution of z required in traditional EM.,3.2. Inference,[0],[0]
"This sampled estimate not only enjoys similar statistical convergence guarantees (Nielsen, 2000) but also provides many computational benefits like speed-up and reduced memory bandwidth requirements (Zaheer et al., 2016).
",3.2. Inference,[0],[0]
"Under LLA, the conditional probability for topic at time step t given word at time t and past history of topics is, p(zd,t = k|wd,t, zd,1:t−1; LSTM,φ)
∝",3.2. Inference,[0],[0]
"p(zd,t = k|zd,1:t−1; LSTM)p(wd,t|zd.t = k;φ) (2)
",3.2. Inference,[0],[0]
The first term represents probability of various topics predicted by LSTM dynamics after final softmax and second term comes from multinomial-Dirichlet word emission model given the topic.,3.2. Inference,[0],[0]
"Naı̈vely sampling from this distribution would cost O(KH +H2) per word.
1Available at http://manzil.ml/lla.html
Optionally, one could speed up this sampling.",3.2. Inference,[0],[0]
Note that the second term in (2) has a sparse structure.,3.2. Inference,[0],[0]
For sampling from (2) the computation of the normalizer is not essential.,3.2. Inference,[0],[0]
"To elaborate, let us define nwk as the number of times word w currently assigned to topic k and nk as the number of tokens assigned to topic k. Explicitly writing down first term:
p(wd,t = w|zd,t = k,φ) = φwk = nwk + β
nk + V β
= nwk
nk + V β︸ ︷︷ ︸ sparse
+ β
nk + V β︸ ︷︷ ︸ dense
(3)
",3.2. Inference,[0],[0]
"There is an inherent sparsity present in nwk, as a given word would be typically about only a handful of topics, Kw K.",3.2. Inference,[0],[0]
"The second term represents the global count of tokens in the topic and will be dense, regardless of the number of documents, words or topics.
",3.2. Inference,[0],[0]
"Following (Li et al., 2014), we devise an optional fast sampling strategy for exploiting this sparsity and construct a Metropolis-Hastings sampler.",3.2. Inference,[0],[0]
"The idea is to replace the low weight dense term by a cheap approximation, while keeping the high weight sparse term exact.",3.2. Inference,[0],[0]
"This leads to a proposal distribution that is close to (2), while at the same time allowing us to draw from it efficiently: • First draw a biased coin to decide whether to draw from
the sparse nwk term or from the dense term.",3.2. Inference,[0],[0]
"The bias is
b = p
p+ q , where p = ∑
k:nwk 6=0
nwk nk + V β p(zd,t = k|zd,1:t−1; LSTM)
q = ∑ k
β
nk + V β (pre-computed).
",3.2. Inference,[0],[0]
"• If we draw from the sparse term, the cost is O(KwH + H2), else the cost is O(H2) using the alias trick.",3.2. Inference,[0],[0]
"• Finally, perform a MH accept/reject move by comparing the approximation with the true distribution.
",3.2. Inference,[0],[0]
"M-step: For fixed topic assignment z, update the φ and LSTM so as to improve the likelihood in expectation.",3.2. Inference,[0],[0]
"As
the dependence of likelihood on LSTM parameters and φ are independent given z, we can update them independently and in parallel.",3.2. Inference,[0],[0]
"For the former, we use the closed form expression for the maximizer,
φwk = #{wd,t = w and zd,t = k}+ β",3.2. Inference,[0],[0]
#{nwk = k}+ V β = nwk,3.2. Inference,[0],[0]
"+ β nk + V β ,
and for the latter we resort to stochastic gradient ascent which will increase the likelihood in expectation.
",3.2. Inference,[0],[0]
The execution of the whole inference and learning process includes several iterations involving the above mentioned two phases as outlined in Algorithm 1.,3.2. Inference,[0],[0]
"This inference procedure is not an ad-hoc method, but an instantiation of the well studied SEM method.",3.2. Inference,[0],[0]
We ensure that in each iteration we increase the ELBO in expectation.,3.2. Inference,[0],[0]
"Also, it is just a coincidence that for all such latent variable models the equations for SE-step looks like Gibbs sampling.",3.2. Inference,[0],[0]
"(Exploiting this coincidence, in fact, one can prove that parallel Gibbs update will work for such models, cf (Tassarotti & Steele Jr, 2015; Zaheer et al., 2016)",3.2. Inference,[0],[0]
whereas in general parallel Gibbs sampling fails miserably e.g. for Ising models.),3.2. Inference,[0],[0]
"Moreover, we found empirically that augmenting the SEM inference with a beam search improved the performance.
",3.2. Inference,[0],[0]
"Automatic differentiation software packages such as TensorFlow (Abadi et al., 2015) significantly speed up development time, but have limited control structures and indexing.",3.2. Inference,[0],[0]
"Whereas random sampling requires varied control statements, thus was implemented separately on the CPU.",3.2. Inference,[0],[0]
"Furthermore, the SEM saved us precious GPU-CPU bandwidth by transmitting only an integer per token instead of a K-dimensional variational parameter.",3.2. Inference,[0],[0]
"Utilizing the word or user action, wd,t, directly would be more informative to model the dynamics and predict the next topic.",3.3. Adding Context,[0],[0]
"For example, rather than only knowing the previous action belonged to “electronics purchase” topic, knowing exactly that a camera was bought, makes it easier to predict user’s next interest, e.g. camera lenses.
",3.3. Adding Context,[0],[0]
"Algorithm 1 Stochastic EM for LLA Input: Document corpus D. 1: Initialize φ and LSTM with a few iterations of LDA 2: repeat
SE-Step: 3: for all document d ∈ D in parallel do 4: for t← 1 to Nd (possibly with padding)",3.3. Adding Context,[0],[0]
"do 5: ∀k ∈ {1, · · · ,K}, i.e., for every topic index
obtain by LSTM forward pass:",3.3. Adding Context,[0],[0]
"πk = φwd,tkp(zd,t = k|zd,1:t−1;LSTM).
",3.3. Adding Context,[0],[0]
"6: Sample zd,t ∼ Categorical(π) 7: end for 8: end for
M-Step: 9: Collect sufficient statistics to obtain:
φwk = nwk + β
nk + V β , ∀w, k
10: for mini-batch of documents B ⊂ D do 11: Compute the gradient by LSTM backward pass
∂L ∂LSTM = ∑ d∈B Nd∑ t=1 ∂ log p(zd,t|zd,1:t−1;LSTM) ∂LSTM
12:",3.3. Adding Context,[0],[0]
"Update LSTM parameters by stochastic gradient descent methods such as Adam (Kingma & Ba, 2014).",3.3. Adding Context,[0],[0]
"13: end for 14: until Convergence
In order to incorporate the exact context, we construct a variant of LLA, called word LLA, where the LSTM is provided with an embedding of previous word wd,t−1 directly instead of zd,t−1.",3.3. Adding Context,[0],[0]
"The corresponding graphical model is shown in Figure 2b and the joint likelihood is:∑
d
log p(wd|LSTM, φ)
= ∑ d ∑ t log ∑ zd,t p(wd,t|zd,t;φ)p(zd,t|wd,1:t−1; LSTM)
",3.3. Adding Context,[0],[0]
"A SEM inference strategy can be devised similar to that of topic LLA as presented in section 3.2.
",3.3. Adding Context,[0],[0]
"However, this modification brings back the model to the dense and high number of parameter regime as a large trainable V ×H lookup table for the word embeddings is needed for the input transformation.",3.3. Adding Context,[0],[0]
This problem can be mitigated by using char-level LSTM (char LSTM for short) to construct the input transformation.,3.3. Adding Context,[0],[0]
"Such character-level LSTM have recently shown promising results in generating structured text (Karpathy et al., 2015) as well as in producing semantically valid word embeddings with a model we will refer to as char-LSTM)",3.3. Adding Context,[0],[0]
"(Ling et al., 2015).",3.3. Adding Context,[0],[0]
"The characterlevel models do not need the huge lookup table for words, as they operate directly on the characters and the number of distinct characters is extremely small.",3.3. Adding Context,[0],[0]
"We chose the latter as our input transformation and briefly describe it below.
",3.3. Adding Context,[0],[0]
"The input word w is decomposed into a sequence of characters c1, . . .",3.3. Adding Context,[0],[0]
", cm, where m is the length of w.",3.3. Adding Context,[0],[0]
Each character ci is transformed using a lookup table and fed into a bidirectional LSTM The forward LSTM evolves on the character sequence and produces a final state hfm.,3.3. Adding Context,[0],[0]
"While
the backward LSTM receives as input the reverse sequence, and yields its own final state hb0.",3.3. Adding Context,[0],[0]
Both LSTMs use a different set of parameters.,3.3. Adding Context,[0],[0]
"The representation ecw of word w is obtained by combining forward and backward final states:
eCw = D fsfm + D bsb0 + bd, (4)
where Df , Db and bd are parameters that determine how the states are combined.",3.3. Adding Context,[0],[0]
This ecw is provided to the topic level LSTM as the input providing information about the word.,3.3. Adding Context,[0],[0]
Thus we are able to incorporate more context information by providing some information about the previous word without the need to have great number of parameters.,3.3. Adding Context,[0],[0]
"We call this model, char LLA.
",3.3. Adding Context,[0],[0]
The different variants of LLA and LSTM as language model can be unified and thought of having different input and out transformations over LSTM for capturing the dynamics.,3.3. Adding Context,[0],[0]
The possible combinations are listed in Table 1.,3.3. Adding Context,[0],[0]
We will study each of them empirically next.,3.3. Adding Context,[0],[0]
"We perform a comprehensive evaluation of our model against several deep models, dynamic models, and topic models.",4. Experimental Results,[0],[0]
"For reproducibility we focus on the task of language modeling over the publicly available Wikipedia dataset, and for generality, we show additional experiments on the less-structured domain of user modeling.",4. Experimental Results,[0],[0]
"For all experiments we follow the standard setup for evaluating temporal models, i.e. divide each document (user history) into 60% for training and 40% for testing.",4.1. Setup,[0],[0]
The task is to predict the remaining 40% of the document (user data) based on the representation inferred from the first 60% of the document.,4.1. Setup,[0],[0]
"We use perplexity as our metric (lower values are better) and compare our models (topic-LLA, wordLLA, and char-LLA) against the following baselines:",4.1. Setup,[0],[0]
"• Autoencoder: A feed forward neural network that com-
prises of encoder and decoder.",4.1. Setup,[0],[0]
The encoder projects the input data into a low-dimensional representation and the decoder reconstructs the input from this representation.,4.1. Setup,[0],[0]
"The model is trained to minimize reconstruction error.
",4.1. Setup,[0],[0]
"• LSTMs: We consider both word-level LSTM language model (word-LSTM) and character-level hierarchical LSTM (char-LSTM) language model.
",4.1. Setup,[0],[0]
"(a) Wikipedia (b) User search click history
Figure 4.",4.1. Setup,[0],[0]
Test perplexity and number of parameters of various models.,4.1. Setup,[0],[0]
Bars represent model sizes and the solid curve represents perplexity over testset (lower is better).,4.1. Setup,[0],[0]
"Wikipedia
Figure 5.",4.1. Setup,[0],[0]
"The effect of the number of topics over the performance of LDA and LLA.
",4.1. Setup,[0],[0]
• LDA:,4.1. Setup,[0],[0]
"The vanilla version trained using collapsed Gibbs sampling over the bag of word representation.
",4.1. Setup,[0],[0]
• ddLDA:,4.1. Setup,[0],[0]
Distance-dependent LDA is a variant of LDA incorporating the word sequence.,4.1. Setup,[0],[0]
"It is based on a fixeddimensional approximaiton of the distance-dependent Dirichlet process (Blei & Frazier, 2011).",4.1. Setup,[0],[0]
In this model a word is assigned to a topic based on the popularity of the topics assigned to nearby words.,4.1. Setup,[0],[0]
"Note that this model subsumes other LDA-based temporal models such as hidden Markov topic Model (Andrews & Vigliocco, 2010) and RCRP based models (Ahmed & Xing, 2008).
",4.1. Setup,[0],[0]
"We trained all deep models using stochastic gradient decent with Adam (Kingma & Ba, 2014).",4.1. Setup,[0],[0]
"All LSTM and LLA based models used the sampled softmax method for efficiency (Cho et al., 2015).",4.1. Setup,[0],[0]
"Finally, all hyper-parameters of the models were tuned over a development set.",4.1. Setup,[0],[0]
We used the publicly available Wikipedia dataset to evaluate the models on the task of sequence prediction.,4.2. Language modeling,[0],[0]
"Extremely short documents, i.e. documents having length less than 500 words were excluded.",4.2. Language modeling,[0],[0]
The dataset contains ~0.7 billion tokens and ~1 million documents.,4.2. Language modeling,[0],[0]
The most frequent 50k word-types were retained as our vocabulary.,4.2. Language modeling,[0],[0]
"Unless otherwise stated, we used 1000 topics for LLA and LDA variants.",4.2. Language modeling,[0],[0]
"For LSTM and LLA variants, we selected the dimensions of the input embedding (word or topic) and evolving latent state (over words or topics) in the range of {50, 150, 250}.",4.2. Language modeling,[0],[0]
"In case of character-based models, we tuned the dimensions of the character embedding and latent state (over characters) in the range of {50, 100, 150}.
",4.2. Language modeling,[0],[0]
Accuracy vs model size Figure 4(a) compares model size in terms of number of parameters with model accuracy in terms of test perplexity.,4.2. Language modeling,[0],[0]
"As shown in the figure, LDA yields the smallest model size due to the sparsity bias implicit in the Dirichlet prior over the topic|word distributions.",4.2. Language modeling,[0],[0]
"On the other hand, word-LSTM gives the best accuracy due to its ability to utilize word level statistics; however, the model size is order of magnitudes larger than LDA.",4.2. Language modeling,[0],[0]
Char-LSTM achieves almost 50% reduction in model size over word-LSTM at the expense of a slightly worse perplexity.,4.2. Language modeling,[0],[0]
"The figure also shows that LLA variants (topicLLA, word-LLA, and char-LLA) can trade accuracy vs model size while still maintaining interpretability since the output of the LSTM component is always at the topic level.
",4.2. Language modeling,[0],[0]
"Note that the figure depicts the smallest word-LSTM at this perplexity level, as our goal is not to beat LSTM in terms of accuracy, but rather to provide a tuning mechanism that can trade-off perplexity vs model size while still maintaining interpretability.",4.2. Language modeling,[0],[0]
"Finally, compared to LDA, which is a widely used tool, LLA variants achieve a significant perplexity reduction at a modest increase in model size while still maintaining topic sparsity.",4.2. Language modeling,[0],[0]
"As shown in Figure 1, the autoencoder model performs poorly in terms of model size and perplexity thus we eliminated it from Figure 4(a) and the following figures to avoid cluttering the display.
",4.2. Language modeling,[0],[0]
"Convergence over time At first glance, LLA seems to be more involved than both LDA and LSTM.",4.2. Language modeling,[0],[0]
"So, we raise the question whether the added complexity leads to a slower training.",4.2. Language modeling,[0],[0]
"Figure 8 shows that compared to LSTM based models, LLA variants achieve comparable convergence speed.",4.2. Language modeling,[0],[0]
"Moreover, compared to fast LDA samplers (Zaheer et al., 2017), our LLA variants introduce only a modest increase in training time.",4.2. Language modeling,[0],[0]
"The figure also shows that character based models (char-LSTM and char-LLA) are slightly slower to train compared to word level variants due to their nested nature and the need to propagate gradients over both word and character level LSTMs.
",4.2. Language modeling,[0],[0]
"Ablation study Since both LDA and LLA result in interpretable models, we want to explore if LDA can achieve a perplexity similar to a given LLA model by just increasing the number of topics in LDA.",4.2. Language modeling,[0],[0]
Figure 5 shows the performance of LDA and variants of LLA for different number of topics.,4.2. Language modeling,[0],[0]
"As can be seen from the figure, even with 250 topics, all LLA based models achieve much lower perplexity than LDA with 1000 topics.",4.2. Language modeling,[0],[0]
"In other words, LLA improves over LDA not because it uses a slightly larger model, but rather because it models the sequential order in the data.
",4.2. Language modeling,[0],[0]
"Interpretability Last but not least, we demonstrate the interpretability of our models.",4.2. Language modeling,[0],[0]
"Similar to LDA, the proposed LLA also uncovers global themes, a.k.a topics prevalent in the dataset.",4.2. Language modeling,[0],[0]
We found qualitatively the topics produced by LLA to be cleaner.,4.2. Language modeling,[0],[0]
"For example, in Table 2 we show a topic about funding, charity, and campaigns recovered by both.",4.2. Language modeling,[0],[0]
LDA includes spurious words like Iowa in the topic just because it co-occurs in the same documents.,4.2. Language modeling,[0],[0]
"Whereas modeling the temporal aspect allows LLA to correctly switch topics at different parts of the sentence producing cleaner topic regarding the same subject.
",4.2. Language modeling,[0],[0]
Modeling based on only co-occurrences in LDA leads to further issues.,4.2. Language modeling,[0],[0]
"For example, strikes among mine workers are common, so the two words will co-occur heavily but it does not imply that strikes and mining should be in the same topic.",4.2. Language modeling,[0],[0]
LDA assign both the words in the same topic as shown in Table 3.,4.2. Language modeling,[0],[0]
Modeling sentences as an ordered sequence allows distinction between the subjects and objects in the sentence.,4.2. Language modeling,[0],[0]
"In the previous example, this leads to factoring into two separate topics of strikes and mine workers.
",4.2. Language modeling,[0],[0]
The topic LLA provides embedding of the topics in a Euclidean metric space.,4.2. Language modeling,[0],[0]
This embedding allows us to understand the temporal structure learned by the model: topics close in this space are expected to appear in close sequential proximity in documents.,4.2. Language modeling,[0],[0]
"To understand this, we built a topic hierarchy using the embeddings which uncovers interesting facts about the data.",4.2. Language modeling,[0],[0]
"For example in Figure 6, we show a portion of the topic hierarchy discovered by topic-LLA with 1000 topics.",4.2. Language modeling,[0],[0]
For each topic we list the top few words.,4.2. Language modeling,[0],[0]
The theme of the figure is countries in Asia.,4.2. Language modeling,[0],[0]
It groups topics relating to one country together and puts topics related to neighboring countries close by.,4.2. Language modeling,[0],[0]
Three prominent clusters are shown form top to bottom which corresponds to moving from west to east on the map of Asia.,4.2. Language modeling,[0],[0]
"Top cluster is about Arab world, second one represent the Indian sub-continent, and the third one starts with southeast Asia like Philippines.",4.2. Language modeling,[0],[0]
(The topic abs gma cbn represents TV station in south-east Asia.),4.2. Language modeling,[0],[0]
The complete hierarchy of topic is very meaningful and can be viewed at http://manzil.ml/lla.html.,4.2. Language modeling,[0],[0]
We use an anonymized sample of user search click history to measure the accuracy of different models on predicting users’ future clicks.,4.3. User modeling,[0],[0]
An accurate model would enable better user experience by presenting the user with relevant content.,4.3. User modeling,[0],[0]
"The dataset is anonymized by removing all items appearing less than a given threshold, this results in a dataset of ~50 million tokens, and 40K vocabulary size.",4.3. User modeling,[0],[0]
This domain is less structured than the language modeling task since users’ click patterns are less predictable than the sequence of words which follow definite syntactic rules.,4.3. User modeling,[0],[0]
"We used a setup similar to the one used in the experiments over the Wikipedia dataset for parameters ranges and selections.
Figure 4(b) gives the same conclusion as Figure 4(a): LLA variants achieve significantly lower perplexity compared to LDA and at the same time they are considerably smaller models compared to LSTM.",4.3. User modeling,[0],[0]
"Furthermore, even compared
to ddLDA, an improved variant of LDA, our proposed LLA achieves better perplexity.",4.3. User modeling,[0],[0]
"ddLDA models time by introducing smoothness constraints that bias future actions to be generated from recent topics; however, it does not possess a predictive action model.",4.3. User modeling,[0],[0]
"As a result, it can neither model the fact that “booking a flight” topic should not be repeated over a short course of time nor that “booking a hotel” topic would likely follow shortly, but not necessarily immediately, after “booking a flight” topic.",4.3. User modeling,[0],[0]
"LLA, on the other hand, is capable of capturing this intricate dynamics by modeling the evolution of user topics via an LSTM – an extremely powerful dynamic model.",4.3. User modeling,[0],[0]
"This point is more evident if we consider the following hand-crafted2 user click trace in context of the topics depicted in Figure 7:
theknot.com zola.com weddingwire.com www.bridalguide.com pinterest.com",4.3. User modeling,[0],[0]
"food.com doityourself.com .....
There are four topics represented and color-coded (best viewed in color): wedding (sixth topic from top), social media (fourth from top), food (third form bottom) and home improvement (second form top) – all in Figure 7.",4.3. User modeling,[0],[0]
We asked each model to predict what would be the three most likely topics that would appear next in current user’s session.,4.3. User modeling,[0],[0]
LDA predicted wedding as the top topic followed by a tie for the remaining topics.,4.3. User modeling,[0],[0]
"ddLDA, whose output is based on exponential decay, yields wedding as most likely, followed by doityourself topic, and then the food topic as expected.",4.3. User modeling,[0],[0]
"In contrast, LLA ranks the most likely three topics as: doityourself topic, houzz topic (top topic in Figure 7), and the wedding topic.",4.3. User modeling,[0],[0]
"This is indicative of LLA learning that once a user starts in the doitourself topic, the user will stay longer in this part of the tree for the task and wander in the nearby topics for a while.",4.3. User modeling,[0],[0]
"Moreover, LLA still remembers the wedding topic, and unlike other models, LLA did not erroneously pick neighbors of the wedding topic among the three most likely topics to follow.
",4.3. User modeling,[0],[0]
"Finally, to demonstrate the interpretability of our model, in Figure 7, we show a portion of the topic hierarchy discovered by topic-LLA with 250 topics.",4.3. User modeling,[0],[0]
For each topic we list the top few clicked items.,4.3. User modeling,[0],[0]
The theme of the figure is wedding and various house chores.,4.3. User modeling,[0],[0]
Three prominent clusters are shown from top to bottom.,4.3. User modeling,[0],[0]
The top cluster is about house renovations and wedding.,4.3. User modeling,[0],[0]
"Second cluster captures
2For privacy concerns, we construct an artificial example manually for illustration purposes.
",4.3. User modeling,[0],[0]
Figure 6.,4.3. User modeling,[0],[0]
"Topic embedding discovered form the Wikipedia dataset
Figure 7.",4.3. User modeling,[0],[0]
"Topic embedding discovered form the user search click history
Figure 8.",4.3. User modeling,[0],[0]
"Convergence speed for various models.
",4.3. User modeling,[0],[0]
"makeup, designer shoes, and fashion.",4.3. User modeling,[0],[0]
"The bottom cluster capture kitchen, cooking and gardening.",4.3. User modeling,[0],[0]
It is clear form the hierarchy that LLA groups topics into the embedding space based on sequential proximity in the search click history.,4.3. User modeling,[0],[0]
One might wonder what would happen if we first train LDA and then simply train LSTM over the topic assignments from the LDA.,4.4. Effect of Joint Training,[0],[0]
We refer to this baseline as “independent learner” since LDA and LSTM are trained independently.,4.4. Effect of Joint Training,[0],[0]
"In Table 4, we compare its performance against LLA, which jointly learns the topics and the evolution dynamics.",4.4. Effect of Joint Training,[0],[0]
"As we can see, joint training is significantly better, since the LSTM will fit the random errors introduced by the topic assignments inferred form the LDA model, and in fact LSTM will learn to be as good as the sequence produced by an LDA model (which is time-oblivious to start with).",4.4. Effect of Joint Training,[0],[0]
The effect is more pronounced in the user history data due to the unstructured nature of this domain.,4.4. Effect of Joint Training,[0],[0]
In this paper we present LLA:,5. Related Works & Discussions,[0],[0]
Latent LSTM allocation.,5. Related Works & Discussions,[0],[0]
LLA leverages the powerful dynamic modeling capability of LSTM without blowing up the number of parameters while adding interpretability to the model.,5. Related Works & Discussions,[0],[0]
We achieve this by shifting from modeling the temporal dynamics at the observed word level to modeling the dynamics at a higher level of abstraction: topics.,5. Related Works & Discussions,[0],[0]
"As the number of topics K is much smaller than the number of words V , it can act as a knob that can trade-off accuracy vs model size.",5. Related Works & Discussions,[0],[0]
"In the extreme case, if we allow K → V in LLA then we recover LSTM.",5. Related Works & Discussions,[0],[0]
"Furthermore, the topics provide an informative embedding that can reveal interesting temporal relationship as shown in Figure 6 and 7 – which is a novel contribution to the best of our knowledge.
",5. Related Works & Discussions,[0],[0]
"Our work is related to various dynamic topic models, however, previous works like ddLDA (ddCRP in general) or hidden Markov topic models provide only limited modeling capabilities of the temporal dynamics.",5. Related Works & Discussions,[0],[0]
"Specifically, they impose smoothness constraints: i.e. topic of a word is biased toward nearby topics.",5. Related Works & Discussions,[0],[0]
"This constraint cannot learn a predictive action model, e.g. after “booking a flight” topic, the “booking a hotel” topic is likely to follow.",5. Related Works & Discussions,[0],[0]
"Moreover, Internet users often wander between related activities, e.g “booking a hotel” topic will happen shortly after “booking a flight”, but not necessarily immediately as the user might have been interrupted by something else.",5. Related Works & Discussions,[0],[0]
Thus we need a much richer temporal model such as an LSTM.,5. Related Works & Discussions,[0],[0]
"Our quantitative results against ddLDA confirm this claim.
",5. Related Works & Discussions,[0],[0]
"Another similar work would be lda2vec (Moody, 2016), where LDA is combined with local context in a fixed window size.",5. Related Works & Discussions,[0],[0]
"This provides a sparse, interpretable model but lacks modeling the temporal aspect.",5. Related Works & Discussions,[0],[0]
The model cannot be used in a predictive-action setting.,5. Related Works & Discussions,[0],[0]
"Also the sparsity is only in terms of per document parameters, whereas it suffers from huge dense of size vocabulary times embedding size.
",5. Related Works & Discussions,[0],[0]
Another relevant recent work is Sentence Level Recurrent Topic Model (SLRTM),5. Related Works & Discussions,[0],[0]
"(Tian et al., 2016).",5. Related Works & Discussions,[0],[0]
"However, this model cannot capture long-range temporal dependencies, as the topic for each sentence is still decided using an exchangeable (non-sequential) Dirichlet-multinomial scheme similar to the LDA.",5. Related Works & Discussions,[0],[0]
"It might be able to preserve local sentence structure or grammar, but that is particularly not very useful for the task of user modeling.",5. Related Works & Discussions,[0],[0]
"Furthermore, as it contains RNN that operates on the entire vocabulary (not topic as in our case), the SLTRM has lots of parameters.
",5. Related Works & Discussions,[0],[0]
"Finally our work is related to recent work in recurrent latent variable models (Chung et al., 2015; Gemici et al., 2017) where a recurrent model is endowed with latent variables to model variability in the input data.",5. Related Works & Discussions,[0],[0]
"However, they mainly focused on continuous input space such as images and speech data which enables the use of variational autoencoder techniques to learn the model parameters.",5. Related Works & Discussions,[0],[0]
"Whereas in this paper, we focus on discrete data that are not amenable to the standard variational autoencoder techniques and as such we developed an efficient SEM algorithm instead.",5. Related Works & Discussions,[0],[0]
"Recurrent neural networks, such as long-short term memory (LSTM) networks, are powerful tools for modeling sequential data like user browsing history (Tan et al., 2016; Korpusik et al., 2016) or natural language text (Mikolov et al., 2010).",abstractText,[0],[0]
"However, to generalize across different user types, LSTMs require a large number of parameters, notwithstanding the simplicity of the underlying dynamics, rendering it uninterpretable, which is highly undesirable in user modeling.",abstractText,[0],[0]
The increase in complexity and parameters arises due to a large action space in which many of the actions have similar intent or topic.,abstractText,[0],[0]
"In this paper, we introduce Latent LSTM Allocation (LLA) for user modeling combining hierarchical Bayesian models with LSTMs.",abstractText,[0],[0]
"In LLA, each user is modeled as a sequence of actions, and the model jointly groups actions into topics and learns the temporal dynamics over the topic sequence, instead of action space directly.",abstractText,[0],[0]
"This leads to a model that is highly interpretable, concise, and can capture intricate dynamics.",abstractText,[0],[0]
We present an efficient Stochastic EM inference algorithm for our model that scales to millions of users/documents.,abstractText,[0],[0]
Our experimental evaluations show that the proposed model compares favorably with several state-of-the-art baselines.,abstractText,[0],[0]
Latent LSTM Allocation  Joint Clustering and Non-Linear Dynamic Modeling of Sequential Data,title,[0],[0]
Coreference resolution is the task of determining which mentions in a text are used to refer to the same real-world entity.,1 Introduction,[0],[0]
"The era of statistical natural language processing saw the shift from rule-based approaches (Hobbs, 1976; Lappin and Leass, 1994) to increasingly sophisticated machine learning models.",1 Introduction,[0],[0]
"While early approaches cast the problem as binary classification of mention pairs (Soon et al., 2001), recent approaches make use of complex structures to represent coreference relations (Yu and Joachims, 2009; Fernandes et al., 2014).
",1 Introduction,[0],[0]
The aim of this paper is to devise a framework for coreference resolution that leads to a unified representation of different approaches to coreference resolution in terms of the structure they operate on.,1 Introduction,[0],[0]
"Previous work in other areas of natural language processing such as parsing (Klein and Manning, 2001) and machine translation (Lopez, 2009)
has shown that providing unified representations of approaches to a problem deepens its understanding and can also lead to empirical improvements.",1 Introduction,[0],[0]
"By implementing popular approaches in this framework, we can highlight structural differences and similarities between them.",1 Introduction,[0],[0]
"Furthermore, this establishes a setting to systematically analyze the contribution of the underlying structure to performance, while fixing parameters such as preprocessing and features.
",1 Introduction,[0],[0]
"In particular, we analyze approaches to coreference resolution and point out that they mainly differ in the structures they operate on.",1 Introduction,[0],[0]
We then note that these structures are not annotated in the training data (Section 2).,1 Introduction,[0],[0]
"Motivated by this observation, we develop a machine learning framework for structured prediction with latent variables for coreference resolution (Section 3).",1 Introduction,[0],[0]
"We formalize the mention pair model (Soon et al., 2001; Ng and Cardie, 2002), mention ranking architectures (Denis and Baldridge, 2008; Chang et al., 2012) and antecedent trees (Fernandes et al., 2014) in our framework and highlight key differences and similarities (Section 4).",1 Introduction,[0],[0]
"Finally, we present an extensive comparison and analysis of the implemented approaches, both quantitative and qualitative (Sections 5 and 6).",1 Introduction,[0],[0]
"Our analysis shows that a mention ranking architecture with latent antecedents performs best, mainly due to its ability to structurally model determining anaphoricity.",1 Introduction,[0],[0]
"Finally, we briefly describe how entity-centric approaches fit into our framework (Section 7).
",1 Introduction,[0],[0]
"An open source toolkit which implements the machine learning framework and the approaches discussed in this paper is available for download1.
1http://smartschat.de/software
405
Transactions of the Association for Computational Linguistics, vol. 3, pp.",1 Introduction,[0],[0]
"405–418, 2015.",1 Introduction,[0],[0]
Action Editor: Mark Johnson.,1 Introduction,[0],[0]
"Submission batch: 3/2015; Revision batch 6/2015; Published 7/2015.
",1 Introduction,[0],[0]
c©2015 Association for Computational Linguistics.,1 Introduction,[0],[0]
Distributed under a CC-BY 4.0 license.,1 Introduction,[0],[0]
The aim of automatic coreference resolution is to predict a clustering of mentions such that each cluster contains all mentions that are used to refer to the same entity.,2 Modeling Coreference Resolution,[0],[0]
"However, most coreference resolution models reduce the problem to predicting coreference between pairs of mentions, and jointly or cascadingly consolidating these predictions.",2 Modeling Coreference Resolution,[0],[0]
"Approaches differ in the scope (pairwise, per anaphor, per document, ...)",2 Modeling Coreference Resolution,[0],[0]
"they employ while learning a scoring function for these pairs, and the way the consolidating is handled.
",2 Modeling Coreference Resolution,[0],[0]
"The different ways to employ the scope and to consolidate decisions can be understood as operating on latent structures: as pairwise links are not annotated in the data, coreference approaches create structures (either heuristically or data-driven) that guide the learning of the pairwise scoring function.
",2 Modeling Coreference Resolution,[0],[0]
"To understand this better, let us consider two examples.",2 Modeling Coreference Resolution,[0],[0]
"Mention pair models (Soon et al., 2001; Ng and Cardie, 2002) cast the problem as first creating a list of mention pairs, and deciding for each pair whether the two mentions are coreferent.",2 Modeling Coreference Resolution,[0],[0]
Afterwards the decisions are consolidated by a clustering algorithm such as best-first or closest-first.,2 Modeling Coreference Resolution,[0],[0]
We therefore can consider this approach to operate on a list of mention pairs where each pair is handled individually.,2 Modeling Coreference Resolution,[0],[0]
"In contrast, antecedent tree models (Fernandes et al., 2014; Björkelund and Kuhn, 2014) consider the whole document at once and predict a tree consisting of anaphor-antecedent pairs.",2 Modeling Coreference Resolution,[0],[0]
In this section we introduce a structured prediction framework for learning coreference predictors with latent variables.,3 A Structured Prediction Framework,[0],[0]
"When devising the framework, we focus on accounting for the latent structures underlying coreference resolution approaches.",3 A Structured Prediction Framework,[0],[0]
"The framework is a generalization of previous work on latent antecedents and trees for coreference resolution (Yu and Joachims, 2009; Chang et al., 2012; Fernandes et al., 2014).",3 A Structured Prediction Framework,[0],[0]
"In all prediction tasks, the goal is to learn a mapping f from inputs x ∈ X to outputs y ∈",3.1 Setting,[0],[0]
Yx.,3.1 Setting,[0],[0]
A prediction task is structured if the output elements y ∈,3.1 Setting,[0],[0]
"Yx
exhibit some structure.",3.1 Setting,[0],[0]
"As we work in a latent variable setting, we assume that Yx = Hx × Zx, and therefore y = (h, z) ∈",3.1 Setting,[0],[0]
Hx × Zx.,3.1 Setting,[0],[0]
"We call h the hidden or latent part, which is not observed in the data, and z the observed part (during training).",3.1 Setting,[0],[0]
"We assume that z can be inferred from h, and that in a pair (h, z), h and z are always consistent.
",3.1 Setting,[0],[0]
We first define the input space X and the output spacesHx and Zx for x ∈ X .,3.1 Setting,[0],[0]
The input space consists of documents.,3.2 The Input Space X,[0],[0]
We represent a document x ∈ X as follows.,3.2 The Input Space X,[0],[0]
Let us assume that Mx is the set of mentions (expressions which may be used to refer to entities) in the document.,3.2 The Input Space X,[0],[0]
"We write Mx = {m1, . . .",3.2 The Input Space X,[0],[0]
",mk}, where the mi are in ascending order with respect to their position in the document.",3.2 The Input Space X,[0],[0]
"We then consider M0x = {m0} ∪ Mx, where m0 precedes every mi ∈ Mx (Chang et al., 2012; Fernandes et al., 2014).",3.2 The Input Space X,[0],[0]
"m0 plays the role of a dummy mention for anaphoricity detection: if m0 is chosen as the antecedent, the corresponding mention is deemed as non-anaphoric.",3.2 The Input Space X,[0],[0]
"This enables joint coreference resolution and anaphoricity determination.
3.3",3.2 The Input Space X,[0],[0]
The Latent SpaceHx for an Input x Let x ∈ X be some document.,3.2 The Input Space X,[0],[0]
"As we saw in the previous section, approaches to coreference resolution predict a latent structure which is not annotated in the data but is used to infer coreference information.",3.2 The Input Space X,[0],[0]
"Inspired by previous work on coreference (Bengtson and Roth, 2008; Fernandes et al., 2014; Martschat and Strube, 2014), we now develop a graph-based representation for these structures.
",3.2 The Input Space X,[0],[0]
"A valid latent structure for the document x is a labeled directed graph h = (V,A,LA) where • the set of nodes are the mentions, V =M0x , • the set of edges A consists of links between
mentions pointing back in the text,
A ⊆ {(mj ,mi) |",3.2 The Input Space X,[0],[0]
"j > i} ⊆Mx ×M0x .
",3.2 The Input Space X,[0],[0]
• LA : A → L assigns a label ` ∈ L to each edge.,3.2 The Input Space X,[0],[0]
"L is a finite set of labels, for example signaling coreference or non-coreference.
",3.2 The Input Space X,[0],[0]
"We split h into subgraphs (called substructures from now on), which we notate as h = h1⊕. .",3.2 The Input Space X,[0],[0]
".⊕hn,
with hi = (Vi, Ai, LAi) ∈",3.2 The Input Space X,[0],[0]
"Hx,i, where Hx,i is the latent space for an input x restricted to the mentions appearing in hi. hi encodes coreference decisions for a subset of mentions in x.
Figure 1 depicts a graph that captures the latent structure underlying the mention pair model.",3.2 The Input Space X,[0],[0]
Mention pairs are represented as node connected by an edge.,3.2 The Input Space X,[0],[0]
The edge either has label “+” (if the mentions are coreferent) or “−” (otherwise).,3.2 The Input Space X,[0],[0]
"As the mention pair model considers each mention pair individually, each edge is one substructure of the latent structure (expressed via the dashed box).",3.2 The Input Space X,[0],[0]
We describe this representation in more detail in Section 4.1.,3.2 The Input Space X,[0],[0]
Let x ∈ X be some document.,3.4 The Observed Output Space Zx for an Input x,[0],[0]
The observed output space consists of all functions ex : Mx → N that map mentions to entity identifiers.,3.4 The Observed Output Space Zx for an Input x,[0],[0]
"Two mi,",3.4 The Observed Output Space Zx for an Input x,[0],[0]
mj ∈ Mx are coreferent if and only if ex(mi) = ex(mj).,3.4 The Observed Output Space Zx for an Input x,[0],[0]
"ex is inferred from the latent structure, e.g. by taking the transitive closure over coreference decisions.
",3.4 The Observed Output Space Zx for an Input x,[0],[0]
This representation corresponds to the way coreference is annotated in corpora.,3.4 The Observed Output Space Zx for an Input x,[0],[0]
Let us write H = ∪x∈XHx for the full latent space (analogously Z).,3.5 Linear Models,[0],[0]
Our goal is to learn the mapping f :,3.5 Linear Models,[0],[0]
X → H × Z .,3.5 Linear Models,[0],[0]
"We assume that the mapping is parametrized by a weight vector θ ∈ Rd, and therefore write f = fθ.",3.5 Linear Models,[0],[0]
We restrict ourselves to linear models.,3.5 Linear Models,[0],[0]
"That is,
fθ(x) =",3.5 Linear Models,[0],[0]
"argmax (h,z)∈Hx×Zx
〈θ, φ(x, h, z)〉,
where φ : X ×H×Z → Rd is a joint feature function for inputs and candidate outputs.
",3.5 Linear Models,[0],[0]
Since h = h1 ⊕ . .,3.5 Linear Models,[0],[0]
.⊕,3.5 Linear Models,[0],[0]
"hn, we have
fθ(x) =",3.5 Linear Models,[0],[0]
"argmax (h,z)∈Hx×Zx
〈θ, φ(x, h, z)〉
= n⊕
i=1
",3.5 Linear Models,[0],[0]
"argmax (hi,z)∈Hx,i×Zx
〈θ, φ(x, hi, z)〉.
",3.5 Linear Models,[0],[0]
"In this paper, we only consider feature functions which factor with respect to the edges in hi = (Vi, Ai, LAi), i.e. φ(x, hi, z) = ∑ a∈Ai φ(x, a, z).",3.5 Linear Models,[0],[0]
"Hence, the features examine properties of mention pairs, such as head word of each mention, number of each mention, or the existence of a string match.",3.5 Linear Models,[0],[0]
We describe the feature set used for all approaches represented in our framework in Section 5.2.,3.5 Linear Models,[0],[0]
"Given an input x ∈ X and a weight vector θ ∈ Rd, we obtain the prediction by solving the argmax equation described in the previous subsection.",3.6 Decoding,[0],[0]
"This can be viewed as searching the output spaceHx×Zx for the highest scoring output pair (h, z).
",3.6 Decoding,[0],[0]
The details of the search procedure depend on the space Hx of latent structures and the factorization into substructures.,3.6 Decoding,[0],[0]
"For the structures we consider in this paper, the maximization can be solved exactly via greedy search.",3.6 Decoding,[0],[0]
"For structures with complex constraints like transitivity, more complex or even approximate search methods need to be used (Klenner, 2007; Finkel and Manning, 2008).",3.6 Decoding,[0],[0]
"We assume a supervised learning setting with latent variables, i.e., we have a training set of documents
D = {( x(i), z(i) )",3.7 Learning,[0],[0]
"| i = 1, . . .",3.7 Learning,[0],[0]
",m }
at our disposal.",3.7 Learning,[0],[0]
"Note that the latent structures are not encoded in this training set.
",3.7 Learning,[0],[0]
In principle we would like to directly optimize for the evaluation metric we are interested in.,3.7 Learning,[0],[0]
"Unfortunately, the evaluation metrics used in coreference do not allow for efficient optimization based on mention pairs, since they operate on the entity level.",3.7 Learning,[0],[0]
"For example, the CEAFe metric (Luo, 2005) needs to compute optimal entity alignments between gold and system entities.",3.7 Learning,[0],[0]
These alignments do not factor with respect to mention pairs.,3.7 Learning,[0],[0]
"We therefore have to use some surrogate loss.
",3.7 Learning,[0],[0]
Algorithm 1 Structured latent perceptron with costaugmented inference.,3.7 Learning,[0],[0]
"Input: Training set D, a cost function c, number of
epochs n. function PERCEPTRON(D, c, n)
set θ = (0, . . .",3.7 Learning,[0],[0]
", 0) for epoch = 1, . . .",3.7 Learning,[0],[0]
", n do
for (x, z) ∈ D do for each substructure do ĥopt,i = argmax
hi∈const(Hx,z,i) 〈θ, φ(x, hi, z)〉
(ĥi, ẑ) =",3.7 Learning,[0],[0]
"argmax (hi,z)∈Hx,i×Zx
(〈θ, φ(x, hi, z)〉
+ c(x, hi, ĥopt,i, z))
",3.7 Learning,[0],[0]
"if ĥi does not partially encode z then set θ = θ + φ(x, ĥopt,i, z)
−φ(x, ĥi, ẑ)",3.7 Learning,[0],[0]
"Output: A weight vector θ.
",3.7 Learning,[0],[0]
"We employ a structured latent perceptron (Sun et al., 2009) extended with cost-augmented inference (Crammer et al., 2006) to learn the parameters of the models we discuss.",3.7 Learning,[0],[0]
"While this restricts us to a particular objective to optimize, it comes with various advantages: the implementation is simple and fast, we can incorporate error functions via costaugmentation, the structures are plug-and-play if we provide a decoder, and the (structured) perceptron with cost-augmented inference has exhibited good performance for coreference resolution (Chang et al., 2012; Fernandes et al., 2014).
",3.7 Learning,[0],[0]
"To describe the algorithm, we need some additional terminology.",3.7 Learning,[0],[0]
"Let (x, z) be a training example.",3.7 Learning,[0],[0]
"Let (ĥ, ẑ) = fθ(x) be the prediction under the model parametrized by θ.",3.7 Learning,[0],[0]
"Let Hx,z be the space of all latent structures for an input x that are consistent with a coreference output z. Structures in Hx,z provide substitutes for gold structures in training.",3.7 Learning,[0],[0]
"Some approaches restrict Hx,z , for example by learning only from the closest antecedent of a mention (Denis and Baldridge, 2008).",3.7 Learning,[0],[0]
"Hence, we consider the constrained space const(Hx,z)",3.7 Learning,[0],[0]
"⊆ Hx,z , where const is a function that depends on the approach in focus.
",3.7 Learning,[0],[0]
"ĥopt = argmax h∈const(Hx,z)
〈θ, φ(x, h, z)〉
is the optimal constrained latent structure under the
current model which is consistent with z. We write ĥi and ĥopt,i for the ith substructure of the latent structure.
",3.7 Learning,[0],[0]
"To estimate θ, we iterate over the training data.",3.7 Learning,[0],[0]
"For each input, we compute the optimal constrained prediction consistent with the gold information, ĥopt,i.",3.7 Learning,[0],[0]
"We then compute the optimal prediction (ĥi, ẑ), but also include the cost function c in our maximization problem.",3.7 Learning,[0],[0]
"This favors solutions with high cost, which leads to a large margin approach.
",3.7 Learning,[0],[0]
"If ĥi does not partially encode the gold data, we update the weight vector.",3.7 Learning,[0],[0]
This is repeated for a given number of epochs2.,3.7 Learning,[0],[0]
Algorithm 1 gives a more formal description.,3.7 Learning,[0],[0]
In the previous section we developed a machine learning framework for coreference resolution.,4 Latent Structures,[0],[0]
It is flexible with respect to •,4 Latent Structures,[0],[0]
"the latent structure h ∈ Hx for an input x, • the substructures of h ∈ Hx, • the constrained space of latent structures con-
sistent with a gold solution const(Hx,z), and • the cost function c and its factorization.
",4 Latent Structures,[0],[0]
"In this paper, we focus on giving a unified representation and in-depth analysis of prevalent coreference models from the literature.",4 Latent Structures,[0],[0]
"Future work should investigate devising and analyzing novel representations for coreference resolution in the framework.
",4 Latent Structures,[0],[0]
"We express three main coreference models in our framework, the mention pair model (Soon et al., 2001), the mention ranking model (Denis and Baldridge, 2008; Chang et al., 2012) and antecedent trees (Yu and Joachims, 2009; Fernandes et al., 2014; Björkelund and Kuhn, 2014).",4 Latent Structures,[0],[0]
We characterize each approach by the latent structure it operates on during learning and inference (we assume that all approaches we consider share the same features).,4 Latent Structures,[0],[0]
"Furthermore, we also discuss the factorization into substructures and typical cost functions used in the literature.",4 Latent Structures,[0],[0]
We first consider the mention pair model.,4.1 Mention Pair Model,[0],[0]
"In its original formulation, it extracts mention pairs from the
2We also shuffle the data before each epoch and use averaging (Collins, 2002).
data and labels these as positive or negative.",4.1 Mention Pair Model,[0],[0]
"During testing, all pairs are extracted and some clustering algorithm such as closest-first or best-first is applied to the list of pairs.",4.1 Mention Pair Model,[0],[0]
"During training, some heuristic is applied to help balancing positive and negative examples.",4.1 Mention Pair Model,[0],[0]
"The most popular heuristic is to take the closest antecedent of an anaphor as a positive example, and all pairs in between as negative examples.
",4.1 Mention Pair Model,[0],[0]
Latent Structure.,4.1 Mention Pair Model,[0],[0]
"In our framework, we can represent the mention pair model as a labeled graph.",4.1 Mention Pair Model,[0],[0]
"In particular, let the set of edges be all backwardpointing edges, i.e. A = {(mj ,mi) |",4.1 Mention Pair Model,[0],[0]
j,4.1 Mention Pair Model,[0],[0]
>,4.1 Mention Pair Model,[0],[0]
i}.,4.1 Mention Pair Model,[0],[0]
"In the testing phase, we operate on the whole set A.",4.1 Mention Pair Model,[0],[0]
"During training, we consider only a subset of edges, as defined by the heuristic used by the approach.
",4.1 Mention Pair Model,[0],[0]
"The labeling function maps a pair of mentions to a positive (“+”) or a negative label (“−”) via
LA(mj ,mi) = {",4.1 Mention Pair Model,[0],[0]
"+ mj ,mi are coreferent,",4.1 Mention Pair Model,[0],[0]
"− otherwise.
",4.1 Mention Pair Model,[0],[0]
One such graph is depicted in Figure 1 (Section 3).,4.1 Mention Pair Model,[0],[0]
"A clustering algorithm (like closest-first or bestfirst) is then employed to infer the coreference information from this latent structure.
",4.1 Mention Pair Model,[0],[0]
Substructures.,4.1 Mention Pair Model,[0],[0]
"In the mention pair model, the parts of the substructures are the individual edges: each pair of mentions is considered as an instance from which the model learns and which the model predicts individually.
",4.1 Mention Pair Model,[0],[0]
Cost Function.,4.1 Mention Pair Model,[0],[0]
"As discussed above, mention pair approaches employ heuristics to resample the training data.",4.1 Mention Pair Model,[0],[0]
"This is a common method to introduce cost-sensitivity into classification (Elkan, 2001; Geibel and Wysotzk, 2003).",4.1 Mention Pair Model,[0],[0]
"Hence, mention pair approaches do not use cost functions in addition to the resampling.",4.1 Mention Pair Model,[0],[0]
"The mention ranking model captures competition between antecedents: for each anaphor, the highestscoring antecedent is selected.",4.2 Mention Ranking Model,[0],[0]
"For training, this approach needs gold antecedents to compare to.",4.2 Mention Ranking Model,[0],[0]
"There are two main approaches to determine these: first, they are heuristically extracted similarly to the mention pair model (Denis and Baldridge, 2008; Rahman and Ng, 2011).",4.2 Mention Ranking Model,[0],[0]
"Second, latent antecedents are employed (Chang et al., 2012): in such models, the
highest-scoring preceding coreferent mention of an anaphor under the current model is selected as the gold antecedent.
",4.2 Mention Ranking Model,[0],[0]
Latent Structure.,4.2 Mention Ranking Model,[0],[0]
The mention ranking approach can be represented as an unlabeled graph.,4.2 Mention Ranking Model,[0],[0]
"In particular, we allow any graph with edges A ⊆ {(mj ,mi) |",4.2 Mention Ranking Model,[0],[0]
j,4.2 Mention Ranking Model,[0],[0]
>,4.2 Mention Ranking Model,[0],[0]
"i} such that for all j there is exactly one i with (mj ,mi) ∈",4.2 Mention Ranking Model,[0],[0]
A (each anaphor has exactly one antecedent).,4.2 Mention Ranking Model,[0],[0]
"Figure 2 shows an example graph.
",4.2 Mention Ranking Model,[0],[0]
"We can represent heuristics for creating training data by constraining the latent structures consistent with the gold information Hx,z .",4.2 Mention Ranking Model,[0],[0]
"Again, the most popular heuristic is to consider the closest antecedent of a mention as the gold antecedent during training (Denis and Baldridge, 2008).",4.2 Mention Ranking Model,[0],[0]
"This corresponds to constraining Hx,z such that const(Hx,z) = {h} with h = (V,A,LA) and (mj ,mi) ∈",4.2 Mention Ranking Model,[0],[0]
A if and only if mi is the closest antecedent of mj .,4.2 Mention Ranking Model,[0],[0]
"When learning from latent antecedents, the unconstrained space Hx,z is considered.
",4.2 Mention Ranking Model,[0],[0]
"To infer coreference information from this latent structure, we take the transitive closure over all anaphor-antecedent decisions encoded in the graph.
Substructures.",4.2 Mention Ranking Model,[0],[0]
"The distinctive feature of the mention ranking approach is that it considers each anaphor in isolation, but all candidate antecedents at once.",4.2 Mention Ranking Model,[0],[0]
We therefore define substructures as follows.,4.2 Mention Ranking Model,[0],[0]
"The jth substructure is the graph hj with nodes Vj = {m0, . . .",4.2 Mention Ranking Model,[0],[0]
",mj} and Aj = {(mj ,mi) | there is i with j > i s.t.",4.2 Mention Ranking Model,[0],[0]
"(mj ,mi) ∈ A}.",4.2 Mention Ranking Model,[0],[0]
Aj contains the antecedent decision for mj .,4.2 Mention Ranking Model,[0],[0]
"One such substructure encoding the antecedent decision for m3 is colored black in Figure 2.
",4.2 Mention Ranking Model,[0],[0]
Cost Function.,4.2 Mention Ranking Model,[0],[0]
Cost functions for the mention ranking model can reward the resolution of specific classes.,4.2 Mention Ranking Model,[0],[0]
"The most sophisticated cost function was proposed by Durrett and Klein (2013), who distinguish between three errors: finding an antecedent for a non-anaphoric mention, misclassifying an anaphoric mention as non-anaphoric, and finding a wrong antecedent for an anaphoric mention.",4.2 Mention Ranking Model,[0],[0]
We will use a variant of this cost function in our experiments (described in Section 5.3).,4.2 Mention Ranking Model,[0],[0]
"Finally, we consider antecedent trees.",4.3 Antecedent Trees,[0],[0]
This structure encodes all antecedent decisions for all anaphors.,4.3 Antecedent Trees,[0],[0]
In our framework they can be understood as an extension of the mention ranking approach to the document level.,4.3 Antecedent Trees,[0],[0]
"So far, research did not investigate constraints on the space of latent structures consistent with the gold annotation.
",4.3 Antecedent Trees,[0],[0]
Latent Structure.,4.3 Antecedent Trees,[0],[0]
"Antecedent trees are based on the same structure as the mention ranking approach.
Substructures.",4.3 Antecedent Trees,[0],[0]
"In the antecedent tree approach, the latent structure does not factor in parts: the whole graph encoding all antecedent information for all mentions is treated as an instance.
",4.3 Antecedent Trees,[0],[0]
Cost Function.,4.3 Antecedent Trees,[0],[0]
The cost function from the mention ranking model naturally extends to the tree case by summing over all decisions.,4.3 Antecedent Trees,[0],[0]
"Furthermore, in principle we can take the structure into account.",4.3 Antecedent Trees,[0],[0]
"However, we are not aware of any approaches which go beyond (variations of) Hamming loss (Hamming, 1950).",4.3 Antecedent Trees,[0],[0]
We now evaluate model variants based on different latent structures on a large benchmark corpus.,5 Experiments,[0],[0]
"The aim of this section is to compare popular approaches to coreference only in terms of the structure they operate on, fixing preprocessing and feature set.",5 Experiments,[0],[0]
In Section 6 we complement this comparison with a qualitative analysis of the influence of the structures on the output.,5 Experiments,[0],[0]
"The aim of our evaluation is to assess the effectiveness and competitiveness of the models implemented in our framework in a realistic coreference setting, i.e. without using gold information such as
gold mentions.",5.1 Data and Evaluation Metrics,[0],[0]
"As all models we consider share the same preprocessing and features, this allows for a fair comparison of the individual structures.
",5.1 Data and Evaluation Metrics,[0],[0]
"We train, evaluate and analyze the models on the English data of the CoNLL-2012 shared task on multilingual coreference resolution (Pradhan et al., 2012).",5.1 Data and Evaluation Metrics,[0],[0]
The shared task organizers provide the training/development/ test split.,5.1 Data and Evaluation Metrics,[0],[0]
"We use the 2802 training documents for training the models, and evaluate and analyze the models on the development set containing 343 documents.",5.1 Data and Evaluation Metrics,[0],[0]
"The 349 test set documents are only used for final evaluation.
",5.1 Data and Evaluation Metrics,[0],[0]
"We work in a setting that corresponds to the shared task’s closed track (Pradhan et al., 2012).",5.1 Data and Evaluation Metrics,[0],[0]
"That is, we make use of the automatically created annotation layers (parse trees, NE information, ...) shipped with the data.",5.1 Data and Evaluation Metrics,[0],[0]
"As additional resources we use only WordNet 3.0 (Fellbaum, 1998) and the number/gender data of Bergsma and Lin (2006).
",5.1 Data and Evaluation Metrics,[0],[0]
"For evaluation we follow the practice of the CoNLL-2012 shared task and employ the reference implementation of the CoNLL scorer (Pradhan et al., 2014) which computes the popular evaluation metrics MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), CEAFe (Luo, 2005) and their average.",5.1 Data and Evaluation Metrics,[0],[0]
"The average is the metric for ranking the systems in the CoNLL shared tasks on coreference resolution (Pradhan et al., 2011; Pradhan et al., 2012).",5.1 Data and Evaluation Metrics,[0],[0]
"We employ a rich set of features frequently used in the literature (Ng and Cardie, 2002; Bengtson and Roth, 2008; Björkelund and Kuhn, 2014).",5.2 Features,[0],[0]
"The set consists of the following features: • the mention type (name, def. noun, indef.",5.2 Features,[0],[0]
"noun,
citation form of pronoun, demonstrative) of anaphor, antecedent and both, • gender, number, semantic class, named en-
tity class, grammatical function and length in words of anaphor, antecedent and both, • semantic head, first/last/preceding/next token
of anaphor, antecedent and both, • distance between anaphor and antecedent in
sentences, • modifier agreement, • whether anaphor and antecedent embed each
other, • whether there is a string match, head match or
an alias relation, • whether anaphor and antecedent have the same
speaker.",5.2 Features,[0],[0]
"If the antecedent in the pair under consideration is m0, i.e. the dummy mention, we do not extract any feature (Chang et al., 2012).
",5.2 Features,[0],[0]
State-of-the-art models greatly benefit from feature conjunctions.,5.2 Features,[0],[0]
"Approaches for building such conjunctions include greedy extension (Björkelund and Kuhn, 2014), entropy-guided induction (Fernandes et al., 2014) and linguistically motivated heuristics (Durrett and Klein, 2013).",5.2 Features,[0],[0]
We follow Durrett and Klein (2013) and conjoin every feature with each mention type feature.,5.2 Features,[0],[0]
We now consider several instantiations of the approaches discussed in the previous section in order of increasing complexity.,5.3 Model Variants,[0],[0]
These instantiations correspond to specific coreference models proposed in the literature.,5.3 Model Variants,[0],[0]
"With the framework described in this paper, we are able to give a unified account of representing and learning these models.",5.3 Model Variants,[0],[0]
"We always train on automatically predicted mentions.
",5.3 Model Variants,[0],[0]
We start with the mention pair model.,5.3 Model Variants,[0],[0]
"To create training graphs, we employ a slight modification of the closest pair heuristic (Soon et al., 2001), which worked best in preliminary experiments.",5.3 Model Variants,[0],[0]
"For each mention mj which is in some coreference chain and has an antecedent mi, we add an edge to mi with label “+”.",5.3 Model Variants,[0],[0]
For all k with i < k,5.3 Model Variants,[0],[0]
"< j, we add an edge from mj to mk with label “−”.",5.3 Model Variants,[0],[0]
"If mj does not have an antecedent, we add edges from mj to mk with label “−” for all 0 <",5.3 Model Variants,[0],[0]
k < j.,5.3 Model Variants,[0],[0]
"Compared to the heuristic of Soon et al. (2001), who only learn from anaphoric mentions, this improves precision.",5.3 Model Variants,[0],[0]
"During testing, if for a mentionmj no pair (mj ,mi) is deemed as coreferent, we consider the mention as not anaphoric.",5.3 Model Variants,[0],[0]
"Otherwise, we employ best-first clustering and take the mention in the highest scoring pair as the antecedent of mj (Ng and Cardie, 2002).
",5.3 Model Variants,[0],[0]
The mention ranking model tries to improve the mention pair model by capturing the competition between antecedents.,5.3 Model Variants,[0],[0]
"We consider two variants of the mention ranking model, where each employs dummy mentions for anaphoricity determination.",5.3 Model Variants,[0],[0]
"The first variant Closest (Denis and Baldridge, 2008) constrains the latent structures consistent with
the gold annotation: for each mention, the closest antecedent is chosen as the gold antecedent.",5.3 Model Variants,[0],[0]
"If the mention does not have any antecedent, we take the dummy mention m0 as the antecedent.",5.3 Model Variants,[0],[0]
"The second variant Latent (Chang et al., 2012) aims to learn from more meaningful antecedents by dropping the constraints, and therefore selecting the best-scoring antecedent (which may also be m0) under the current model during training.
",5.3 Model Variants,[0],[0]
"We view the antecedent tree model (Fernandes et al., 2014) as a natural extension of the mention ranking model.",5.3 Model Variants,[0],[0]
"Instead of predicting an antecedent for each mention, we predict an entire tree of anaphorantecedent pairs.",5.3 Model Variants,[0],[0]
This should yield more consistent entities.,5.3 Model Variants,[0],[0]
"As in previous work we only consider the latent variant.
",5.3 Model Variants,[0],[0]
"For the mention ranking model and for antecedent trees we use a cost function similar to previous work (Durrett and Klein, 2013; Fernandes et al., 2014).",5.3 Model Variants,[0],[0]
"For a pair of mentions (mj ,mi), we consider
cpair(mj ,mi) =    λ",5.3 Model Variants,[0],[0]
i > 0,5.3 Model Variants,[0],[0]
"and mj ,mi are not coreferent,
2λ i = 0",5.3 Model Variants,[0],[0]
"and mj is anaphoric, 0",5.3 Model Variants,[0],[0]
"otherwise,
where λ > 0 will be tuned on development data.",5.3 Model Variants,[0],[0]
"Let ĥi = (Vi, Ai, LAi).",5.3 Model Variants,[0],[0]
"cpair is extended to a cost function for the whole latent structure ĥi by
c(x, ĥi, ĥopt,i, z) = ∑
(mj ,mk)∈Ai cpair(mj ,mk).
",5.3 Model Variants,[0],[0]
"The use of such a cost function is necessary to learn reasonable weights, since most automatically extracted mentions in the data are not anaphoric.",5.3 Model Variants,[0],[0]
We evaluate the models on the development and the test sets.,5.4 Experimental Setup,[0],[0]
"When evaluating on the test set, we train on the concatenation of the training and development set.",5.4 Experimental Setup,[0],[0]
"After preliminary experiments with the ranking model with closest antecedents on the development set, we set the number of perceptron epochs to 5 and set λ = 100 in the cost function.
",5.4 Experimental Setup,[0],[0]
"We assess statistical significance of the difference in F1 score for two approaches via an approximate randomization test (Noreen, 1989).",5.4 Experimental Setup,[0],[0]
We say an improvement is statistically significant if p < 0.05.,5.4 Experimental Setup,[0],[0]
Table 1 shows the result of all model configurations discussed in the previous section on CoNLL’12 English development and test data.,5.5 Results,[0],[0]
"In order to put the numbers into context, we also report the results of Björkelund and Kuhn (2014), who present a system that implements an antecedent tree model with non-local features.",5.5 Results,[0],[0]
Their system is the highestperforming system on the CoNLL data which operates in a closed track setting.,5.5 Results,[0],[0]
"We also compare with Fernandes et al. (2014), the winning system of the CoNLL-2012 shared task (Pradhan et al., 2012)3.",5.5 Results,[0],[0]
"Both systems were trained on training data for evaluating on the development set, and on the concatena-
3We do not compare with the system of Durrett and Klein (2014) since it uses Wikipedia as an additional resource, and therefore does not work under the closed track setting.",5.5 Results,[0],[0]
"Its performance is 61.71 average F1 (71.24 MUC F1, 58.71 B3 F1 and 55.18 CEAFe F1) on CoNLL-2012 English test data.
",5.5 Results,[0],[0]
"tion of training and development data for evaluating on the test set.
",5.5 Results,[0],[0]
"Despite its simplicity, the mention pair model yields reasonable performance.",5.5 Results,[0],[0]
"The gap to Björkelund and Kuhn (2014) is roughly 2.8 points in average F1 score on test data.
",5.5 Results,[0],[0]
"Compared to the mention pair model, the variants of the mention ranking model improve the results for all metrics, largely due to increased precision.",5.5 Results,[0],[0]
Switching from regarding the closest antecedent as the gold antecedent to latent antecedents yields an improvement of roughly 0.5 points in average F1.,5.5 Results,[0],[0]
All improvements of the mention ranking model with closest antecedents compared to the mention pair model are statistically significant.,5.5 Results,[0],[0]
"Furthermore, with the exception of the differences in MUC F1, all improvements are significant when switching from closest antecedents to latent antecedents.
",5.5 Results,[0],[0]
"The mention ranking model with latent an-
tecedents outperforms the state-of-the-art system by Björkelund and Kuhn (2014) by more than 0.8 points average F1.",5.5 Results,[0],[0]
These results show the competitiveness of a simple mention ranking architecture.,5.5 Results,[0],[0]
"Regarding the individual F1 scores compared to Björkelund and Kuhn (2014), the improvements in the MUC and CEAFe metrics on development data are statistically significant.",5.5 Results,[0],[0]
"The improvements on test data are not statistically significant.
",5.5 Results,[0],[0]
Using antecedent trees yields higher precision than using the mention ranking model.,5.5 Results,[0],[0]
"However, recall is much lower.",5.5 Results,[0],[0]
The performance is similar to the antecedent tree models of Fernandes et al. (2014) and Björkelund and Kuhn (2014).,5.5 Results,[0],[0]
The numbers discussed in the previous section do not give insights into where the models make different decisions.,6 Analysis,[0],[0]
Are there specific linguistic classes of mention pairs where one model is superior to the other?,6 Analysis,[0],[0]
How do the outputs differ?,6 Analysis,[0],[0]
"How can these differences be explained by different structures employed by the models?
",6 Analysis,[0],[0]
"In order to answer these questions, we need to perform a qualitative analysis of the differences in system output for the approaches.",6 Analysis,[0],[0]
"To do so, we employ the error analysis method presented in Martschat and Strube (2014).",6 Analysis,[0],[0]
"In this method, recall errors are extracted via comparing spanning trees of reference entities with system output.",6 Analysis,[0],[0]
Edges in the spanning tree missing from the output are extracted as errors.,6 Analysis,[0],[0]
"For extracting precision errors, the roles of reference and system entities are switched.",6 Analysis,[0],[0]
"To define the spanning trees, we follow Martschat and Strube (2014) and use a notion based on Ariel’s accessibility theory (Ariel, 1990) for reference entities, while we take system antecedent decisions for system entities.",6 Analysis,[0],[0]
"We extracted all errors of the model variants described in the previous section on CoNLL-2012 English development data.
",6.1 Overview,[0],[0]
Table 2 gives an overview of all recall and precision errors.,6.1 Overview,[0],[0]
"For each model variant the table shows the number of recall and precision errors, and the maximum number of errors4.",6.1 Overview,[0],[0]
"The numbers confirm the findings obtained from Table 1: the ranking models beat the mention pair model largely due to fewer precision errors.
",6.1 Overview,[0],[0]
"The antecedent tree model outputs more precise entities by establishing fewer coreference links: it makes fewer decisions and fewer precision errors than the other configurations, but at the expense of an increased number of recall errors.
",6.1 Overview,[0],[0]
The more sophisticated models make consistently fewer linking decisions than the mention pair model.,6.1 Overview,[0],[0]
We therefore hypothesize that the improvements in the numbers mainly stem from improved anaphoricity determination.,6.1 Overview,[0],[0]
"The mention pair model handles anaphoricity determination implicitly: if for a mention mj no pair (mj ,mi) is deemed as coreferent, the model does not select an antecedent for mj5.",6.1 Overview,[0],[0]
"Since the mention ranking model allows to include the search for the best antecedent during prediction, we can explicitly model the anaphoricity decision, via including the dummy mention during search.
",6.1 Overview,[0],[0]
We now examine the errors in more detail to investigate this hypothesis.,6.1 Overview,[0],[0]
"To do so, we will investi-
4For",6.1 Overview,[0],[0]
"recall, the maximum number of errors is the number of errors made by a system that assigns each mention to its own entity.",6.1 Overview,[0],[0]
"For precision, the maximum number of errors is the total number of anaphor-antecedent decisions made by the model.
5Initial experiments which included the dummy mention during learning for the mention pair model yielded worse results.",6.1 Overview,[0],[0]
"This is arguably due to the large number of non-anaphoric mentions, which causes highly imbalanced training data.
gate error classes, and compare the models in terms of how they handle these error classes.",6.1 Overview,[0],[0]
"This is a practice common in the analysis of coreference resolution approaches (Stoyanov et al., 2009; Martschat and Strube, 2014).",6.1 Overview,[0],[0]
"We distinguish between errors where both mentions are a proper name or a common noun, errors where the anaphor is a pronoun and the remaining errors.
",6.1 Overview,[0],[0]
Tables 3 and 4 summarize recall and precision errors for subcategories of these classes6.,6.1 Overview,[0],[0]
We now compare individual models.,6.1 Overview,[0],[0]
"For pairs of proper names and pairs of common nouns, employing the ranking model instead of the mention pair model leads to a large decrease in precision errors, but an increase in recall errors.",6.2 Mention Ranking vs. Mention Pair,[0],[0]
"For pronouns and mixed pairs, we can observe decreases in recall errors and slight increases in precision errors, except for it/they, where both recall precision errors decrease.
",6.2 Mention Ranking vs. Mention Pair,[0],[0]
"We can attribute the largest differences to determining anaphoricity: in 82% of all precision errors
6For the pronoun subcategories, we map each pronoun to its canonical form.",6.2 Mention Ranking vs. Mention Pair,[0],[0]
"For example, we map him to he.
",6.2 Mention Ranking vs. Mention Pair,[0],[0]
"between two proper names made by the mention pair model, but not by the ranking model, the mention appearing later in the text is non-anaphoric.",6.2 Mention Ranking vs. Mention Pair,[0],[0]
The ranking model correctly determines this.,6.2 Mention Ranking vs. Mention Pair,[0],[0]
"Similar numbers hold for common noun pairs.
",6.2 Mention Ranking vs. Mention Pair,[0],[0]
"While most nouns and names are not anaphoric, most pronouns are.",6.2 Mention Ranking vs. Mention Pair,[0],[0]
"Hence, determining anaphoricity is less of an issue here.",6.2 Mention Ranking vs. Mention Pair,[0],[0]
"From the resolved it/they recall errors of the ranking model compared to the mention pair model, we can attribute 41% to better antecedent selection: the mention pair model decided on a wrong antecedent.",6.2 Mention Ranking vs. Mention Pair,[0],[0]
"The ranking model, however, was able to leverage the competition between the antecedents to decide on a correct antecedent.",6.2 Mention Ranking vs. Mention Pair,[0],[0]
The remaining 59% stem from selecting a correct antecedent for pronouns that were classified as non-anaphoric by the mention pair model.,6.2 Mention Ranking vs. Mention Pair,[0],[0]
"We observe similar trends for the other pronoun classes.
",6.2 Mention Ranking vs. Mention Pair,[0],[0]
"Overall, the majority of error reduction can be attributed to improved determination of anaphoricity, which can be modeled structurally in the mention ranking model (we do not use any features when a dummy mention is involved, therefore nonanaphoricity decisions always get the score 0).",6.2 Mention Ranking vs. Mention Pair,[0],[0]
"However, for pronoun resolution, where there are
many competing compatible antecedents for a mention, the model is able to learn better weights by leveraging the competition.",6.2 Mention Ranking vs. Mention Pair,[0],[0]
These findings suggest that extending the mention pair model to explicitly determine anaphoricity should improve results especially for non-pronominal coreference.,6.2 Mention Ranking vs. Mention Pair,[0],[0]
Using latent instead of closest antecedents leads to fewer recall errors and more precision errors for non-pronominal coreference.,6.3 Latent Antecedent vs. Closest Antecedent,[0],[0]
"Pronoun resolution recall errors slightly increase, while precision errors slightly decrease.
",6.3 Latent Antecedent vs. Closest Antecedent,[0],[0]
"While these changes are minor, there is a large reduction in the remaining precision errors.",6.3 Latent Antecedent vs. Closest Antecedent,[0],[0]
"Most of these correspond to predictions which are considered very difficult, such as links between a proper name anaphor and a pronoun antecedent (Bengtson and Roth, 2008).",6.3 Latent Antecedent vs. Closest Antecedent,[0],[0]
"Via latent antecedents, the model can avoid learning from the most unreliable pairs.",6.3 Latent Antecedent vs. Closest Antecedent,[0],[0]
"Compared to the ranking model with latent antecedents, the antecedent tree model commits consistently more recall errors and fewer precision errors.",6.4 Antecedent Trees vs. Ranking,[0],[0]
This is partly due to the fact that the antecedent tree model also predicts fewer links between mentions than the other models.,6.4 Antecedent Trees vs. Ranking,[0],[0]
"The only exception is he/she, where there is not much of a difference.
",6.4 Antecedent Trees vs. Ranking,[0],[0]
"The only difference between the ranking model with latent antecedents and the antecedent tree model is that weights are updated document-wise for antecedent trees, while they are updated per anaphor for the ranking model.",6.4 Antecedent Trees vs. Ranking,[0],[0]
"This leads to more precise predictions, at the expense of recall.",6.4 Antecedent Trees vs. Ranking,[0],[0]
Our analysis shows that the mention ranking model mostly improves precision over the mention pair model.,6.5 Summary,[0],[0]
"For non-pronominal coreference, the improvements can be mainly attributed to improved anaphoricity determination.",6.5 Summary,[0],[0]
"For pronoun resolution, both anaphoricity determination and capturing antecedent competition lead to improved results.",6.5 Summary,[0],[0]
Employing latent antecedents during training mainly helps in resolving very difficult cases.,6.5 Summary,[0],[0]
"Due to the update strategy, employing antecedent trees leads to
a more precision-oriented approach, which significantly improves precision at the expense of recall.",6.5 Summary,[0],[0]
"In this paper we concentrated on representing and analyzing the most prevalent approaches to coreference resolution, which are based on predicting whether pairs of mentions are coreferent.",7 Beyond Pairwise Predictions,[0],[0]
"Hence, we choose graphs as latent structures and let the feature functions factor over edges in the graph, which correspond to pairs of mentions.
",7 Beyond Pairwise Predictions,[0],[0]
"However, entity-based approaches (Rahman and Ng, 2011; Stoyanov and Eisner, 2012; Lee et al., 2013, inter alia) obtain coreference chains by predicting whether sets of mentions are coreferent, going beyond pairwise predictions.",7 Beyond Pairwise Predictions,[0],[0]
"While a detailed discussion of such approaches is beyond the scope of this paper, we now briefly describe how we can generalize the proposed framework to accommodate for such approaches.
",7 Beyond Pairwise Predictions,[0],[0]
"When viewing coreference resolution as prediction of latent structures, entity-based models operate on structures that relate sets of mentions to each other.",7 Beyond Pairwise Predictions,[0],[0]
"This can be expressed by hypergraphs, which are graphs where edges can link more than two nodes.",7 Beyond Pairwise Predictions,[0],[0]
"Hypergraphs have already been used to model coreference resolution (Cai and Strube, 2010; Sapena, 2012).
",7 Beyond Pairwise Predictions,[0],[0]
"To model entity-based approaches, we extend the valid latent structures to labeled directed hypergraphs.",7 Beyond Pairwise Predictions,[0],[0]
"These are tuples h = (V,A,LA), where • the set of nodes are the mentions, V =M0x , • the set of edges A ⊆ 2V × 2V consists of di-
rected hyperedges linking two sets of mentions, • LA : A → L assigns a label ` ∈ L to each
edge.",7 Beyond Pairwise Predictions,[0],[0]
L is a finite set of labels.,7 Beyond Pairwise Predictions,[0],[0]
"For example, the entity-mention model (Yang et al., 2008) predicts coreference in a left-to-right fashion.",7 Beyond Pairwise Predictions,[0],[0]
"For each anaphor mj , it considers the set
Ej ⊆ 2{m0,...,mj−1}
of preceding partial entities that have been established so far (such as e = {m1,m3,m6}).",7 Beyond Pairwise Predictions,[0],[0]
"In terms of our framework, substructures for this approach are hypergraphs with hyperedges ({mj} , e) for e ∈ Ej , encoding the decision to which partial entity mj refers.
",7 Beyond Pairwise Predictions,[0],[0]
The definitions of features and the decoding problem carry over from the graph-based framework (we drop the edge factorization assumption for features).,7 Beyond Pairwise Predictions,[0],[0]
Learning requires adaptations to cope with the dependency between coreference decisions.,7 Beyond Pairwise Predictions,[0],[0]
"For example, for the entity-mention model, establishing that an anaphor mj refers to a partial entity e influences the search space for decisions for anaphors mk with k > j.",7 Beyond Pairwise Predictions,[0],[0]
We leave a more detailed discussion to future work.,7 Beyond Pairwise Predictions,[0],[0]
"The main contributions of this paper are a framework for representing coreference resolution approaches and a systematic comparison of main coreference approaches in this framework.
",8 Related Work,[0],[0]
"Our representation framework generalizes approaches to coreference resolution which employed specific latent structures for representation, such as latent antecedents (Chang et al., 2012) and antecedent trees (Fernandes et al., 2014).",8 Related Work,[0],[0]
"We give a unified representation of such approaches and show that seemingly disparate approaches such as the mention pair model also fit in a framework based on latent structures.
",8 Related Work,[0],[0]
Only few studies systematically compare approaches to coreference resolution.,8 Related Work,[0],[0]
"Most previous work highlights the improved expressive power of the presented model by a comparison to a mention pair baseline (Culotta et al., 2007; Denis and Baldridge, 2008; Cai and Strube, 2010).
",8 Related Work,[0],[0]
"Rahman and Ng (2011) consider a series of models with increasing expressiveness, ranging from a mention pair to a cluster-ranking model.",8 Related Work,[0],[0]
"However, they do not develop a unified framework for comparing approaches, and their analysis is not qualitative.",8 Related Work,[0],[0]
"Fernandes et al. (2014) compare variations of antecedent tree models, including different loss functions and a version with a fixed structure.",8 Related Work,[0],[0]
They only consider antecedent trees and also do not provide a qualitative analysis.,8 Related Work,[0],[0]
"Kummerfeld and Klein (2013) and Martschat and Strube (2014) present a largescale qualitative comparison of coreference systems, but they do not investigate the influence of the latent structures the systems operate on.",8 Related Work,[0],[0]
"Furthermore, the systems in their studies differ in terms of mention extraction and feature sets.",8 Related Work,[0],[0]
We observed that many approaches to coreference resolution can be uniformly represented by the latent structure they operate on.,9 Conclusions,[0],[0]
"We devised a framework that accounts for such structures, and showed how we can express the mention pair model, the mention ranking model and antecedent trees in this framework.
",9 Conclusions,[0],[0]
An evaluation of the models on CoNLL-2012 data showed that all models yield competitive results.,9 Conclusions,[0],[0]
"While antecedent trees give results with the highest precision, a mention ranking model with latent antecedent performs best, obtaining state-of-the-art results on CoNLL-2012 data.
",9 Conclusions,[0],[0]
"An analysis based on the method of Martschat and Strube (2014) highlights the strengths of the mention ranking model compared to the mention pair model: it is able to structurally model anaphoricity determination and antecedent competition, which leads to improvements in precision for non-pronominal coreference resolution, and in recall for pronoun resolution.",9 Conclusions,[0],[0]
"The effect of latent antecedents is negligible and has a large effect only on very difficult cases of coreference.
",9 Conclusions,[0],[0]
"The flexibility of the framework, toolkit and analysis methods presented in this paper helps researchers to devise, analyze and compare representations for coreference resolution.",9 Conclusions,[0],[0]
"This work has been funded by the Klaus Tschira Foundation, Heidelberg, Germany.",Acknowledgments,[0],[0]
The first author has been supported by a HITS PhD scholarship.,Acknowledgments,[0],[0]
"We thank the anonymous reviewers and our colleagues Benjamin Heinzerling, Yufang Hou and Nafise Moosavi for feedback on earlier drafts of this paper.",Acknowledgments,[0],[0]
"Furthermore, we are grateful to Anders Björkelund for helpful comments on cost functions.",Acknowledgments,[0],[0]
"Machine learning approaches to coreference resolution vary greatly in the modeling of the problem: while early approaches operated on the mention pair level, current research focuses on ranking architectures and antecedent trees.",abstractText,[0],[0]
We propose a unified representation of different approaches to coreference resolution in terms of the structure they operate on.,abstractText,[0],[0]
We represent several coreference resolution approaches proposed in the literature in our framework and evaluate their performance.,abstractText,[0],[0]
"Finally, we conduct a systematic analysis of the output of these approaches, highlighting differences and similarities.",abstractText,[0],[0]
Latent Structures for Coreference Resolution,title,[0],[0]
"ar X
iv :1
61 0.
05 12
0v 4
[ cs
.D S]
5 S",text,[0],[0]
Convex optimization is an important technique both from a theoretical and an applications perspective.,1 Introduction,[0],[0]
Gradient descent based methods are widely used due to their simplicity and easy applicability to many real-world problems.,1 Introduction,[0],[0]
"We are interested in solving constraint convex optimization problems of the form
min x∈P
f (x), (1)
where f is a smooth convex function and P is a polytope, with access to f being limited to first-order information, i.e., we can obtain ∇ f (x) and f (x) for a given x ∈ P and access to P via a linear minimization oracle, which returns LPP(c) = argminx∈P cx for a given linear objective c.
Algorithm 1",1 Introduction,[0],[0]
Frank-Wolfe Algorithm,1 Introduction,[0],[0]
"[Frank and Wolfe, 1956] Input: smooth convex function f with curvature C, start vertex x1 ∈ P, linear minimization oracle LPP Output: points xt in P
1: for t = 1 to T − 1 do 2: vt ← LPP(∇ f (xt )) 3: xt+1",1 Introduction,[0],[0]
"← (1 − γt )xt + γtvt with γt ≔ 2t+2 4: end for
When solving Problem (1) using gradient descent approaches in order to maintain feasibility, typically a projection step is required.",1 Introduction,[0],[0]
"This projection back into the feasible region P is potentially computationally
1
expensive, especially for complex feasible regions in very large dimensions.",1 Introduction,[0],[0]
"As such, projection-freemethods gained a lot of attention recently, in particular the Frank-Wolfe algorithm",1 Introduction,[0],[0]
"[Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012] due to their simplicity.",1 Introduction,[0],[0]
We recall the basic Frank-Wolfe algorithm in Algorithm 1.,1 Introduction,[0],[0]
These methods eschew the projection step and rather use a linear optimization oracle to stay within the feasible region.,1 Introduction,[0],[0]
"While convergence rates and regret bounds are often suboptimal, in many cases the gain due to only having to solve a single linear optimization problem over the feasible region in every iteration still leads to significant computational advantages (see e.g., [Hazan and Kale, 2012, Section 5]).",1 Introduction,[0],[0]
"This led to conditional gradient algorithms being used for e.g., online optimization and more generally machine learning.",1 Introduction,[0],[0]
Also the property that these algorithms naturally generate sparse distributions over the extreme points of the feasible region is often helpful.,1 Introduction,[0],[0]
"Further increasing the relevance of these methods, it was shown recently that conditional gradient methods can also achieve linear convergence (see e.g., Garber and Hazan [2013], Lacoste-Julien and Jaggi [2015], Garber and Meshi [2016]) as well as that the number of total gradient evaluations can be reduced while maintaining the optimal number of oracle calls as shown in Lan and Zhou",1 Introduction,[0],[0]
"[2014].
",1 Introduction,[0],[0]
"Unfortunately, for complex feasible regions even solving the linear optimization problem might be timeconsuming and as such the cost of solving the LP might be non-negligible.",1 Introduction,[0],[0]
"This could be the case, e.g., when linear optimization over the feasible region is a hard problem or when solving large-scale optimization or learning problems.",1 Introduction,[0],[0]
"As such it is natural to ask the following questions:
(i) Does the linear optimization oracle have to be called in every iteration?
(ii) Does one need approximately optimal solutions for convergence?
(iii) Can one reuse information across iterations?
",1 Introduction,[0],[0]
"We will answer these questions in this work, showing that (i) the LP oracle is not required to be called in every iteration, (ii) much weaker guarantees are sufficient, and (iii) we can reuse information.",1 Introduction,[0],[0]
"To significantly reduce the cost of oracle calls while maintaining identical convergence rates up to small constant factors, we replace the linear optimization oracle by a (weak) separation oracle (Oracle 1) which approximately solves
Oracle 1 Weak Separation Oracle LPsepP(c, x,Φ,K) Input:",1 Introduction,[0],[0]
"linear objective c ∈ Rn, point x ∈ P, accuracy K ≥ 1, objective value",1 Introduction,[0],[0]
Φ > 0; Output: Either (1) vertex y ∈ P with c(x − y) >,1 Introduction,[0],[0]
"Φ/K , or (2) false: c(x − z) ≤",1 Introduction,[0],[0]
"Φ for all z ∈ P.
a separation problem within a multiplicative factor and returns improving vertices.",1 Introduction,[0],[0]
"We stress that the weak separation oracle is significantly weaker than approximate minimization, which has been already considered in Jaggi [2013].",1 Introduction,[0],[0]
"In fact, there is no guarantee that the improving vertices returned by the oracle are near to the optimal solution to the linear minimization problem.",1 Introduction,[0],[0]
It is this relaxation of dual bounds and approximate optimality that will provide a significant speedup as we will see later.,1 Introduction,[0],[0]
"However, if the oracle does not return an improving vertex (returns false), then this fact can be used to derive a reasonably small dual bound of the form: f (xt )",1 Introduction,[0],[0]
− f (x∗) ≤ ∇,1 Introduction,[0],[0]
f (xt )(xt − x∗) ≤,1 Introduction,[0],[0]
Φt for some Φt > 0.,1 Introduction,[0],[0]
"While the accuracy K is presented here as a formal argument of the oracle, an oracle implementation might restrict to a fixed value K > 1, which often makes implementation easier.",1 Introduction,[0],[0]
We point out that the cases (1) and (2) potentially overlap if K > 1.,1 Introduction,[0],[0]
"This is intentional and in this case it is unspecified which of the cases the oracle should choose (and it does not matter for the algorithms).
",1 Introduction,[0],[0]
"This new oracle encapsulates the smart use of the original linear optimization oracle, even though for some problems it could potentially be implemented directly without relying on a linear programming oracle.
2
Concretely, a weak separation oracle can be realized by a single call to a linear optimization oracle and as such is no more complex than the original oracle.",1 Introduction,[0],[0]
However it has two important advantages: it allows for caching and early termination.,1 Introduction,[0],[0]
"Caching refers to storing previous solutions, and first searching among them to satisfy the oracle’s separation condition.",1 Introduction,[0],[0]
"The underlying linear optimization oracle is called only, when none of the cached solutions satisfy the condition.",1 Introduction,[0],[0]
Algorithm 2 formalizes this process.,1 Introduction,[0],[0]
"Early termination is the technique to stop the linear optimization algorithm before it finishes at an appropriate stage, when from its internal data a suitable oracle answer can be easily recovered; this is clearly an implementation dependent technique.",1 Introduction,[0],[0]
"The two techniques can be combined, e.g., Algorithm 2 could use an early terminating linear oracle or other implementation of the weak separation oracle in line 4.
",1 Introduction,[0],[0]
"Algorithm 2 LPsepP(c, x,Φ,K) via LP oracle Input: linear objective c ∈ Rn, point x ∈ P, accuracy K ≥ 1, objective value",1 Introduction,[0],[0]
Φ > 0; Output: Either (1) vertex y ∈ P with c(x − y) >,1 Introduction,[0],[0]
"Φ/K , or (2) false: c(x − z) ≤",1 Introduction,[0],[0]
"Φ for all z ∈ P.
1: if y ∈ P cached with c(x − y) >",1 Introduction,[0],[0]
Φ/K exists then 2: return y {Cache call} 3: else 4: y ← argmaxx∈P,1 Introduction,[0],[0]
cx {LP call} 5: if c(x − y) >,1 Introduction,[0],[0]
"Φ/K then 6: add y to cache 7: return y
8: else
9: return false
10: end if
11: end if
We call lazification the technique of replacing a linear programming oracle with a much weaker one, and we will demonstrate significant speedups in wall-clock performance (see e.g., Figure 25), while maintaining identical theoretical convergence rates.
",1 Introduction,[0],[0]
"To exemplify our approachwe provide conditional gradient algorithmsemploying the weak separation oracle for the standard Frank-Wolfe algorithm as well as the variants in [Hazan and Kale, 2012, Garber and Meshi, 2016, Garber and Hazan, 2013], which have been chosen due to requiring modified convergence arguments that go beyond those required for the vanilla Frank-Wolfe algorithm.",1 Introduction,[0],[0]
"Complementing the theoretical analysis we report computational results demonstrating effectiveness of our approach via a significant reduction in wall-clock time compared to their linear optimization counterparts.
",1 Introduction,[0],[0]
"Related Work
There has been extensive work on Frank-Wolfe algorithms and conditional gradient algorithms, so we will restrict to review work most closely related to ours.",1 Introduction,[0],[0]
"The Frank-Wolfe algorithm was originally introduced in [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966] and has been intensely studied in particular in terms of achieving stronger convergence guarantees as well as affineinvariant versions.",1 Introduction,[0],[0]
We demonstrate our approach for the vanilla Frank-Wolfe algorithm,1 Introduction,[0],[0]
"[Frank and Wolfe, 1956] (see also [Jaggi, 2013]) as an introductory example.",1 Introduction,[0],[0]
We then consider more complicated variants that require non-trivial changes to the respective convergence proofs to demonstrate the versatility of our approach.,1 Introduction,[0],[0]
"This includes the linearly convergent variant via local linear optimization [Garber and Hazan, 2013] as well as the pairwise conditional gradient variant of Garber and Meshi [2016], which is especially
3
efficient in terms of implementation.",1 Introduction,[0],[0]
"However, our technique also applies to the Away-Step Frank-Wolfe algorithm, the Fully-Corrective Frank-Wolfe algorithm, the Pairwise Conditional Gradient algorithm, as well as the Block-Coordinate Frank-Wolfe algorithm.",1 Introduction,[0],[0]
"Recently, in Freund and Grigas [2016] guarantees for arbitrary step-size rules were provided and an analogous analysis can be also performed for our approach.",1 Introduction,[0],[0]
"On the other hand, the analysis of the inexact variants, e.g., with approximate linear minimization does not apply to our case as our oracle is significantly weaker than approximate minimization as pointed out earlier.",1 Introduction,[0],[0]
"For more information, we refer the interested reader to the excellent overview in [Jaggi, 2013] for Frank-Wolfe methods in general as well as Lacoste-Julien and Jaggi [2015] for an overview with respect to global linear convergence.
",1 Introduction,[0],[0]
It was also recently shown in Hazan and Kale [2012] that the Frank-Wolfe algorithm can be adjusted to the online learning setting and in this work we provide a lazy version of this algorithm.,1 Introduction,[0],[0]
"Combinatorial convex online optimization has been investigated in a long line of work (see e.g., [Kalai and Vempala, 2005, Audibert et al., 2013, Neu and Bartók, 2013]).",1 Introduction,[0],[0]
"It is important to note that our regret bounds hold in the structured online learning setting, i.e., our bounds depend on the ℓ1-diameter or sparsity of the polytope, rather than its ambient dimension for arbitrary convex functions (see e.g., [Cohen and Hazan, 2015, Gupta et al., 2016]).",1 Introduction,[0],[0]
"We refer the interested reader to [Hazan, 2016] for an extensive overview.
",1 Introduction,[0],[0]
"A key component of the new oracle is the ability to cache and reuse old solutions, which accounts for the majority of the observed speed up.",1 Introduction,[0],[0]
"The idea of caching of oracle calls was already explored in various other contexts such as cutting plane methods (see e.g., Joachims et al. [2009]) as well as the Block-Coordinate Frank-Wolfe algorithm in Shah et al. [2015], Osokin et al. [2016].",1 Introduction,[0],[0]
"Our lazification approach (which uses caching) is however much more lazy, requiring no multiplicative approximation guarantee; see [Osokin et al., 2016, Proof of Theorem 3.",1 Introduction,[0],[0]
"Appendix F] and Lacoste-Julien et al. [2013] for comparison to our setup.
",1 Introduction,[0],[0]
"Contribution
The main technical contribution of this paper is a new approach, whereby instead of finding the optimal solution, the oracle is used only to find a good enough solution or a certificate that such a solution does not exist, both ensuring the desired convergence rate of the conditional gradient algorithms.
",1 Introduction,[0],[0]
"Our contribution can be summarized as follows:
(i) Lazifying approach.",1 Introduction,[0],[0]
We provide a general method to lazify conditional gradient algorithms.,1 Introduction,[0],[0]
"For this we replace the linear optimization oracle with a weak separation oracle, which allows us to reuse feasible solutions from previous oracle calls, so that in many cases the oracle call can be skipped.",1 Introduction,[0],[0]
"In fact, once a simple representation of the underlying feasible region is learned no further oracle calls are needed.",1 Introduction,[0],[0]
"We also demonstrate how parameter-free variants can be obtained.
(ii) Lazified conditional gradient algorithms.",1 Introduction,[0],[0]
"We exemplify our approach by providing lazy versions of the vanilla Frank-Wolfe algorithm as well as of the conditional gradient methods in [Hazan and Kale, 2012, Garber and Hazan, 2013, Garber and Meshi, 2016].
(iii) Weak separation through augmentation.",1 Introduction,[0],[0]
We show in the case of 0/1 polytopes how to implement a weak separation oracle with at most k calls to an augmentation oracle that on input c ∈,1 Introduction,[0],[0]
"Rn and x ∈ P provides either an improving solution x ∈ P with cx < cx or ensures optimality, where k denotes the ℓ1-diameter of P.",1 Introduction,[0],[0]
"This is useful when the solution space is sparse.
",1 Introduction,[0],[0]
(iv) Computational experiments.,1 Introduction,[0],[0]
We demonstrate computational superiority by extensive comparisons of the weak separation based versions with their original versions.,1 Introduction,[0],[0]
"In all cases we report significant speedups in wall-clock time often of several orders of magnitude.
",1 Introduction,[0],[0]
"4
It is important to note that in all cases, we inherit the same requirements, assumptions, and properties of the baseline algorithm that we lazify.",1 Introduction,[0],[0]
"This includes applicable function classes, norm requirements, as well as smoothness and (strong) convexity requirements.",1 Introduction,[0],[0]
"We also maintain identical convergence rates up to (small) constant factors.
",1 Introduction,[0],[0]
"A previous version of this work appeared as extended abstract in Braun et al. [2017]; this version has been significantly revised over the conference version including a representative subset of more extensive computational results, full proofs for all described variants, as well as a variant that uses an augmentation oracle instead of linear optimization oracle (see Section 6).
",1 Introduction,[0],[0]
"Outline
We briefly recall notation and notions in Section 2 and consider conditional gradient algorithms in Section 3.",1 Introduction,[0],[0]
"In Section 4 we consider parameter-free variants of the proposed algorithms, and in Section 5 we examine online versions.",1 Introduction,[0],[0]
"Finally, in Section 6 we show a realization of a weak separation oracle with an even weaker oracle in the case of combinatorial problem and we provide extensive computational results in Section 7.",1 Introduction,[0],[0]
"Let ‖·‖ be an arbitrary norm on Rn, and let ‖·‖∗ denote the dual norm of ‖·‖. A function f is L-Lipschitz if | f (y)",2 Preliminaries,[0],[0]
"− f (x)| ≤ L‖y − x‖ for all x, y ∈ dom f .",2 Preliminaries,[0],[0]
"A convex function f is smooth with curvature at most C if
f (γy + (1 − γ)x) ≤",2 Preliminaries,[0],[0]
f (x) + γ∇ f (x)(y,2 Preliminaries,[0],[0]
− x),2 Preliminaries,[0],[0]
"+ Cγ2/2
for all x, y ∈ dom f and 0 ≤ γ ≤ 1.",2 Preliminaries,[0],[0]
"A function f is S-strongly convex if
f (y)",2 Preliminaries,[0],[0]
− f (x) ≥ ∇ f (x)(y,2 Preliminaries,[0],[0]
− x),2 Preliminaries,[0],[0]
+,2 Preliminaries,[0],[0]
S 2 ‖y,2 Preliminaries,[0],[0]
"− x‖2
for all x, y ∈ dom f .",2 Preliminaries,[0],[0]
Unless stated otherwise Lipschitz continuity and strong convexity will be measured in the norm ‖·‖.,2 Preliminaries,[0],[0]
"Moreover, let Br (x) ≔ {y | ‖x",2 Preliminaries,[0],[0]
− y‖ ≤ r} be the ball around x with radius r with respect to ‖.‖.,2 Preliminaries,[0],[0]
"In the following, P will denote the feasible region, a polytope and the vertices of P will be denoted by v1, . . .",2 Preliminaries,[0],[0]
", vN .",2 Preliminaries,[0],[0]
We start with the most basic Frank-Wolfe algorithm as a simple example for lazifying by means of a weak separation oracle.,3 Lazy Conditional Gradient,[0],[0]
We then lazify more complex Frank-Wolfe algorithms in Garber and Hazan [2013] and Garber and Meshi [2016].,3 Lazy Conditional Gradient,[0],[0]
Throughout this section ‖·‖ denotes the ℓ2-norm.,3 Lazy Conditional Gradient,[0],[0]
"We start with lazifying the original Frank-Wolfe algorithm (arguably the simplest Conditional Gradient algorithm), adapting the baseline argument from [Jaggi, 2013, Theorem 1].",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"While the vanilla version has suboptimal convergence rate O(1/T ), its simplicity makes it an illustrative example of the main idea of lazification.",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"The lazy algorithm (Algorithm 3) maintains an upper boundΦt on the convergence rate, guiding its eagerness for progress when searching for an improving vertex vt .",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"If the weak separation oracle provides
5
Algorithm 3 Lazy Conditional Gradient Input: smooth convex function f with curvature C, start vertex x1 ∈ P, weak linear separation oracle LPsepP, accuracy K ≥ 1, step sizes γt , initial upper bound Φ0 Output: points xt in P 1: for t = 1 to T − 1 do 2:",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"Φt ← Φt−1+ Cγ2t 2
1+ γt K
3: vt ← LPsepP(∇ f",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"(xt ), xt,Φt,K) 4: if vt = false then 5: xt+1 ← xt 6: else",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"7: xt+1 ← (1 − γt )xt + γtvt 8: end if
9: end for
an improving vertex vt we refer to this as a positive call and if the oracle claims there are no improving vertices we call it a negative call.
",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"The step size γt is chosen to (approximately) minimize Φt in Line 2; roughly Φt−1/KC.
Theorem 3.1.",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
Assume f is convex and smooth with curvature,3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"C. Then Algorithm 3 with γt = 2(K2+1)
K(t+K2+2) and
f (x1)",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"− f (x∗) ≤ Φ0 has convergence rate
f (xt )",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"− f (x∗) ≤ 2 max{C,Φ0}(K2 + 1)
t + K2 + 2 ,
where x∗ is a minimum point of f over P.
Proof.",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
We prove by induction that f (xt ),3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"− f (x∗) ≤ Φt−1.
",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
The claim is clear for t = 1 by the choice of Φ0.,3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"Assuming the claim is true for t, we prove it for t + 1.",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"We distinguish two cases depending on the return value of the weak separation oracle in Line 3.
",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"In case of a positive call, i.e., when the oracle returns an improving solution vt , then ∇ f (xt )(xt − vt ) ≥",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"Φt/K , which is used in the second inequality below.",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"The first inequality follows by smoothness of f , and the second inequality by the induction hypothesis and the fact that vt is an improving solution:
f (xt+1)",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
− f (x∗) ≤ f (xt ),3.1 Lazy Conditional Gradient: a basic example,[0],[0]
− f (x∗)︸ ︷︷ ︸ ≤Φt−1 +γt ∇,3.1 Lazy Conditional Gradient: a basic example,[0],[0]
f,3.1 Lazy Conditional Gradient: a basic example,[0],[0]
(xt )(vt − xt )︸,3.1 Lazy Conditional Gradient: a basic example,[0],[0]
︷︷ ︸ ≤−Φt /K,3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"+
Cγ2t
2
≤",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
Φt−1,3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"− γt Φt
K +
Cγ2t
2 = Φt,
In case of a negative call, i.e., when the oracle returns no improving solution, then in particular∇ f (xt )(xt− x∗) ≤",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"Φt , hence by Line 5
f (xt+1)",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
− f (x∗) = f (xt ),3.1 Lazy Conditional Gradient: a basic example,[0],[0]
− f (x∗) ≤ ∇,3.1 Lazy Conditional Gradient: a basic example,[0],[0]
f (xt )(xt − x∗) ≤,3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"Φt .
6
Finally, using the specific values of γt we prove the upper bound
Φt−1 ≤ 2 max{C,Φ0}(K2 + 1)
",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"t + K2 + 2
by induction on t.",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
The claim is obvious for t = 1.,3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"The induction step is an easy computation relying on the definition of Φt on Line 2:
",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"Φt = Φt−1 +
Cγ2t 2
1 + γt K
≤ 2 max{C,Φ0 }(K2+1) t+K2+2 + max{C,Φ0 }γ2t 2
1 + γt K
≤ 2 max{C,Φ0}(K 2 + 1)
t + K2 + 3 .
",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"Here the last inequality follows from the concrete value of γt .
",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"Note that by design, the algorithm converges at the worst-case rate that we postulate due to the negative calls when it does not move.",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"Clearly, this is highly undesirable, therefore the algorithm should be understood as the textbook variant of lazy conditional gradient.",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"We will present an improved, parameter-free variant of Algorithm 3 in Section 4 that converges at the best possible rate that the non-lazy variant would achieve (up to a small constant factor).",3.1 Lazy Conditional Gradient: a basic example,[0],[0]
"In this section we provide a lazy variant (Algorithm 4) of the Pairwise Conditional Gradient algorithm from Garber and Meshi [2016], using separation instead of linear optimization.",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"We make identical assumptions: the feasible region is a 0/1 polytope, i.e., all vertices of P have only 0/1 entries, and moreover it is given in the form P = {x ∈",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Rn | 0 ≤ x ≤ 1, Ax = b}, where 1 denotes the all-one vector.
",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Algorithm 4 Lazy Pairwise Conditional Gradient (LPCG) Input: polytope P, smooth and S-strongly convex function f with curvature C, accuracy K ≥ 1, nonincreasing step-sizes ηt , eagerness ∆t",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
Output: points xt 1: x1 ∈ P arbitrary and Φ0 ≥ f (x1),3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"− f (x∗) 2: for t = 1, . . .",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
",T do
3: ∇̃",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
f (xt )i ≔ { ∇ f (xt ),3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"i if xt,i > 0 −∞ if xt,i = 0 4:",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Φt ← 2Φt−1+η 2 tC
2+ ηtK∆t
5: ct ← ( ∇ f (xt ),−∇̃ f (xt ) ) 6: (v+t , v−t )",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"← LPsepP×P ( ct, (xt, xt ), Φt∆t , K ) 7: if (v+t , v−t )",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
= false then 8: xt+1,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"← xt 9: else
10: η̃t ← max{2−δ | δ ∈ Z≥0, 2−δ ≤ ηt } 11: xt+1 ← xt",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"+ η̃t (v+t − v−t ) 12: end if
13: end for
7
Observe that Algorithm 4 calls the linear separation oracle LPsep on the cartesian product of P with itself.",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Choosing the objective function as in Line 5 allows us to simultaneously find an improving direction and an away-step direction.
",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Let card x denote the number of non-zero entries of the vector x.
Theorem 3.2.",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Let x∗ be a minimum point of f in P, and Φ0 an upper bound of f (x1)",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
− f (x∗).,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Furthermore, let card(x∗) ≤ α, M1 ≔ √ S 8α , κ ≔ min { M1 KC , 1/ √ Φ0 } , ηt ≔ κ √ Φt−1 and ∆t ≔ √ 2αΦt−1 S , then Algorithm 4 has convergence rate
f (xt+1)",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
− f (x∗) ≤,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Φt ≤ Φ0 ( 1 + B
1 + 2B
) t ,
where B ≔ κ · M12K .
",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"We recall a technical lemma for the proof.
",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Lemma 3.3 ([Garber and Meshi, 2016, Lemma 2]).",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Let x, y ∈",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
P. Then x is a liner combination x = ∑ki=1,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"λivi of some vertices vi of P (in particular, ∑k i=1",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
λi = 1) with x − y = ∑k i=1,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
γi(vi,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"− z) for some 0 ≤ γi ≤ λi and
z ∈ P such that ∑ki=1 γi ≤ √ card(y)‖x",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"− y‖.
Proof of Theorem 3.2.",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"The feasibility of the iterates xt is ensured by Line 10 and the monotonicity of the sequence {ηt }t≥1 with the same argument as in [Garber and Meshi, 2016, Lemma 1 and Observation 2].
",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
We first show by induction that f (xt+1),3.2 Lazy Pairwise Conditional Gradient,[0],[0]
− f (x∗) ≤,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Φt .
",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
For t = 0 we have Φ0 ≥ f (x1),3.2 Lazy Pairwise Conditional Gradient,[0],[0]
− f (x∗).,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
Now assume the statement for some t ≥ 0.,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"In case of a negative call (Line 8), we use the guarantee of Oracle 1 to get
ct",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"[(xt, xt )",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"− (z1, z2)] ≤",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Φt
∆t
for all z1, z2 ∈ P, which is equivalent to (as ct (xt, xt ) = 0)
∇̃",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
f (xt )z2 − ∇,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
f (xt )z1 ≤,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Φt
∆t
and therefore
∇ f (xt )(z̃2 − z1) ≤",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Φt
∆t , (2)
for all z̃2, z1 ∈ P with supp(z̃2) ⊆ supp(xt ), where supp(x) denotes the set of non-zero coordinates of x. We use Lemma 3.3 for the decompositions xt = ∑k i=1 λivi and xt",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
− x∗ = ∑k i=1 γi(vi,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"− z) with 0 ≤ γi ≤ λi, z ∈ P and k∑
i=1
γi ≤ √ card(x∗)‖xt − x∗‖ ≤",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"√
2 card(x∗)Φt−1 S ≤ ∆t,
using the induction hypothesis and strong convexity in the second inequality.",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Then
f (xt+1)",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
− f (x∗) = f (xt ),3.2 Lazy Pairwise Conditional Gradient,[0],[0]
− f (x∗) ≤ ∇,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"f (xt )(xt − x∗) = k∑
i=1",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
γi · ∇,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
f (xt )(vi − z)︸ ︷︷ ︸ ≤Φt /∆t ≤,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Φt,
8
where we used Equation (2) for the last inequality.",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"In case of a positive call (Lines 10 and 11) we get, using first smoothness of f , then ηt/2 < η̃t ≤ ηt and ∇ f (xt )(v+t − v−t )",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"≤ −Φt/(K∆t ), and finally the definition of Φt :
f (xt+1)",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
− f (x∗) = f (xt ),3.2 Lazy Pairwise Conditional Gradient,[0],[0]
− f (x∗) + f (xt + η̃t (v+t − v−t )),3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"− f (xt )
≤",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
Φt−1 + η̃t∇,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"f (xt )(v+t − v−t ) + η̃2t C
2
≤",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
Φt−1,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
− ηt 2 ·,3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Φt K∆t +
η2t C
2 = Φt .
",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Plugging in the values of ηt and ∆t to the definition of Φt gives the desired bound.
",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Φt = 2Φt−1 + η2t C
2 + ηt K∆t
= Φt−1 1 + κ2C/2 1 + κM1/K ≤",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
"Φt−1 1 + B 1 + 2B ≤ Φ0
( 1 + B
1 + 2B
) t .",3.2 Lazy Pairwise Conditional Gradient,[0],[0]
In this section we provide a lazy version (Algorithm 5) of the conditional gradient algorithmfromGarber and Hazan [2013].,3.3 Lazy Local Conditional Gradient,[0],[0]
"Let P ⊆ Rn be any polytope, D denote an upper bound on the ℓ2-diameter of P, and µ ≥ 1 be an affine invariant parameter of P satisfying Lemma 3.4 below, see [Garber and Hazan, 2013, Section 2] for a possible definition.",3.3 Lazy Local Conditional Gradient,[0],[0]
"As the algorithm is not affine invariant by nature, we need a non-invariant version of smoothness: Recall that a convex function f is β-smooth if
f (y)",3.3 Lazy Local Conditional Gradient,[0],[0]
− f (x) ≤ ∇,3.3 Lazy Local Conditional Gradient,[0],[0]
f,3.3 Lazy Local Conditional Gradient,[0],[0]
(x)(y − x) + β‖y,3.3 Lazy Local Conditional Gradient,[0],[0]
"− x‖2/2.
Algorithm 5 Lazy Local Conditional Gradient (LLCG)
",3.3 Lazy Local Conditional Gradient,[0],[0]
"Input: feasible polytope P, β-smooth and S-strongly convex function f , parameters K , S, β, µ; diameter D Output: points xt
1: x1 ∈ P arbitrary and Φ0",3.3 Lazy Local Conditional Gradient,[0],[0]
≥ f,3.3 Lazy Local Conditional Gradient,[0],[0]
(x1),3.3 Lazy Local Conditional Gradient,[0],[0]
"− f (x∗) 2: α← S
2Kβnµ2
3: for t = 1, . . .",3.3 Lazy Local Conditional Gradient,[0],[0]
",T do 4: rt ← √ 2Φt−1 S
5:",3.3 Lazy Local Conditional Gradient,[0],[0]
"Φt ← Φt−1+
β 2 α 2 min{nµ2r2t ,D2 } 1+α/K
6: pt ← LLPsepP (∇ f (xt ), xt, rt,Φt,K) 7: if pt = false then 8: xt+1",3.3 Lazy Local Conditional Gradient,[0],[0]
"← xt 9: else
10: xt+1 ← xt + α(pt − xt ) 11: end if
12: end for
As an intermediary step, we first implement a local weak separation oracle in Algorithm 6, a local version of Oracle 1, which finds improving points only in a small neighbourhood of the original point, analogously to the local linear optimization oracle in Garber and Hazan",3.3 Lazy Local Conditional Gradient,[0],[0]
[2013].,3.3 Lazy Local Conditional Gradient,[0],[0]
"To this end, we recall a technical lemma from Garber and Hazan [2013].
9
Algorithm 6",3.3 Lazy Local Conditional Gradient,[0],[0]
"Weak Local Separation LLPsepP(c, x, r,Φ,K) Input: polytope P together with invariant µ,",3.3 Lazy Local Conditional Gradient,[0],[0]
"linear objective c ∈ Rn, point x ∈ P, radius r > 0, objective
value",3.3 Lazy Local Conditional Gradient,[0],[0]
"Φ > 0, accuracy K ≥ 1 Output: Either (1) y ∈ P with ‖x",3.3 Lazy Local Conditional Gradient,[0],[0]
− y‖ ≤ √ nµr and c(x − y) >,3.3 Lazy Local Conditional Gradient,[0],[0]
"Φ/K , or (2) false: c(x − z) ≤",3.3 Lazy Local Conditional Gradient,[0],[0]
"Φ for all
z ∈ P ∩",3.3 Lazy Local Conditional Gradient,[0],[0]
Br (x).,3.3 Lazy Local Conditional Gradient,[0],[0]
"1: ∆← min {√ nµ
D r, 1
}
2: Decompose x: x = ∑M j=1 λjvj , λj > 0, ∑
j λj = 1. 3: Sort vertices: i1, . . .",3.3 Lazy Local Conditional Gradient,[0],[0]
", iM cvi1 ≥ · · · ≥ cviM .",3.3 Lazy Local Conditional Gradient,[0],[0]
4: k ← min{k : ∑kj=1 λij ≥ ∆} 5: p− ← ∑k−1 j=1 λij vij + ( ∆ −∑k−1j=1 λij ),3.3 Lazy Local Conditional Gradient,[0],[0]
vik 6: v∗ ← LPsepP,3.3 Lazy Local Conditional Gradient,[0],[0]
"( c, p− ∆ , Φ ∆ ) 7: if v∗ = false then 8: return false
9: else
10: return y ← x − p− + ∆v∗ 11: end if
Lemma 3.4.",3.3 Lazy Local Conditional Gradient,[0],[0]
"[Garber and Hazan, 2013, Lemma 7] Let P ⊆ Rn be a polytope and v1, . . .",3.3 Lazy Local Conditional Gradient,[0],[0]
", vN be its vertices.",3.3 Lazy Local Conditional Gradient,[0],[0]
"Let x, y ∈ P and x = ∑Ni=1 λivi a convex combination of the vertices of P. Then there are numbers 0 ≤ γi ≤ λi and z ∈ P satisfying
x",3.3 Lazy Local Conditional Gradient,[0],[0]
"− y = ∑
i∈[N] γi(z",3.3 Lazy Local Conditional Gradient,[0],[0]
"− vi)
∑
i∈[N] γi ≤
√ nµ
D ‖x",3.3 Lazy Local Conditional Gradient,[0],[0]
"− y‖.
Now we prove the correctness of the weak local separation algorithm.
",3.3 Lazy Local Conditional Gradient,[0],[0]
Lemma 3.5.,3.3 Lazy Local Conditional Gradient,[0],[0]
Algorithm 6 is correct.,3.3 Lazy Local Conditional Gradient,[0],[0]
"In particular LLPsepP(c, x, r,Φ,K)
(i) returns either an y ∈ P with ‖x",3.3 Lazy Local Conditional Gradient,[0],[0]
"− y‖ ≤ √ nµr and c(x − y) ≥ Φ/K ,
(ii) or returns false, and then c(x − z) ≤",3.3 Lazy Local Conditional Gradient,[0],[0]
Φ for all z ∈ P ∩,3.3 Lazy Local Conditional Gradient,[0],[0]
"Br (x).
",3.3 Lazy Local Conditional Gradient,[0],[0]
Proof.,3.3 Lazy Local Conditional Gradient,[0],[0]
We first consider the case when the algorithm exits in Line 10.,3.3 Lazy Local Conditional Gradient,[0],[0]
Observe that y ∈ P since y is a convex combination of vertices of by construction: y = ∑M j=1(λij,3.3 Lazy Local Conditional Gradient,[0],[0]
"− γj )vij + ∆v∗ with ∆ = ∑M j=1 γj ≤ √ nµ D r, where γj = λij for j < k, and γk = ∆",3.3 Lazy Local Conditional Gradient,[0],[0]
"− ∑k−1 j=1 λij , and γj = 0 for j > k. Therefore
‖x",3.3 Lazy Local Conditional Gradient,[0],[0]
"− y‖ =
M∑
j=1
γj (vij − v∗) ≤
M∑
j=1
γj ‖vij",3.3 Lazy Local Conditional Gradient,[0],[0]
"− v∗‖ ≤ √ nµr .
",3.3 Lazy Local Conditional Gradient,[0],[0]
"Finally using the guarantee of LPsepP we get
c(x − y) =",3.3 Lazy Local Conditional Gradient,[0],[0]
∆c ( p− ∆,3.3 Lazy Local Conditional Gradient,[0],[0]
"− v∗ ) ≥ Φ K .
10
",3.3 Lazy Local Conditional Gradient,[0],[0]
"If the algorithm exits in Line 8, we use Lemma 3.4 to decompose any y ∈ P ∩",3.3 Lazy Local Conditional Gradient,[0],[0]
"Br (x):
x",3.3 Lazy Local Conditional Gradient,[0],[0]
"− y = M∑
i=1
γi(vi",3.3 Lazy Local Conditional Gradient,[0],[0]
"− z),
with z ∈ P and ∑Mi=1 γi ≤ √ nµ D ‖x",3.3 Lazy Local Conditional Gradient,[0],[0]
− y‖ ≤,3.3 Lazy Local Conditional Gradient,[0],[0]
"∆. Since ∑Mi=1 λi = 1 ≥ ∆, there are numbers γi ≤ η−i ≤ λi with∑M
i=1",3.3 Lazy Local Conditional Gradient,[0],[0]
η,3.3 Lazy Local Conditional Gradient,[0],[0]
"− i = ∆. Let
p̃− ≔ M∑
i=1
η−i vi,
p̃+ ≔",3.3 Lazy Local Conditional Gradient,[0],[0]
y,3.3 Lazy Local Conditional Gradient,[0],[0]
"− x + p̃− = M∑
i=1
(η−i − γi)vi + M∑
i=1
γiz,
so that p̃+/∆ ∈ P.",3.3 Lazy Local Conditional Gradient,[0],[0]
To bound the function value we first observe that the choice of p− in the algorithm assures that cu ≤ cp− for all u = ∑M i=1,3.3 Lazy Local Conditional Gradient,[0],[0]
ηivi with ∑M i=1,3.3 Lazy Local Conditional Gradient,[0],[0]
ηi = ∆ and all 0 ≤ ηi ≤ λi.,3.3 Lazy Local Conditional Gradient,[0],[0]
"In particular, cp̃− ≤ cp−.",3.3 Lazy Local Conditional Gradient,[0],[0]
"The function value of the positive part p̃+ can be bounded with the guarantee of LPsepP:
c ( p− ∆",3.3 Lazy Local Conditional Gradient,[0],[0]
− p̃+ ∆ ) ≤,3.3 Lazy Local Conditional Gradient,[0],[0]
"Φ ∆ ,
i.e., c(p−",3.3 Lazy Local Conditional Gradient,[0],[0]
− p̃+) ≤,3.3 Lazy Local Conditional Gradient,[0],[0]
"Φ. Finally combining these bounds gives
c(x − y) = c",3.3 Lazy Local Conditional Gradient,[0],[0]
(p̃− − p̃+) ≤ c(p−,3.3 Lazy Local Conditional Gradient,[0],[0]
− p̃+) ≤,3.3 Lazy Local Conditional Gradient,[0],[0]
"Φ
as desired.
",3.3 Lazy Local Conditional Gradient,[0],[0]
"We are ready to examine the Conditional Gradient Algorithm based on LLPsepP:
Theorem 3.6.",3.3 Lazy Local Conditional Gradient,[0],[0]
"Algorithm 5 converges with the following rate:
f (xt+1)",3.3 Lazy Local Conditional Gradient,[0],[0]
− f (x∗) ≤,3.3 Lazy Local Conditional Gradient,[0],[0]
"Φt ≤ Φ0 ( 1 + α/(2K)
1 + α/K
) t .
",3.3 Lazy Local Conditional Gradient,[0],[0]
Proof.,3.3 Lazy Local Conditional Gradient,[0],[0]
The proof is similar to the proof of Theorem 3.2.,3.3 Lazy Local Conditional Gradient,[0],[0]
We prove this rate by induction.,3.3 Lazy Local Conditional Gradient,[0],[0]
For t = 0,3.3 Lazy Local Conditional Gradient,[0],[0]
the choice of Φ0 guarantees that f (x1),3.3 Lazy Local Conditional Gradient,[0],[0]
− f (x∗) ≤ Φ0.,3.3 Lazy Local Conditional Gradient,[0],[0]
Now assume the theorem holds for t ≥ 0.,3.3 Lazy Local Conditional Gradient,[0],[0]
"With strong convexity and the induction hypothesis we get
‖xt",3.3 Lazy Local Conditional Gradient,[0],[0]
"− x∗‖2 ≤ 2
S ( f (xt )",3.3 Lazy Local Conditional Gradient,[0],[0]
− f (x∗)),3.3 Lazy Local Conditional Gradient,[0],[0]
"≤
2 S Φt−1 = r 2 t ,
i.e., x∗ ∈ P ∩",3.3 Lazy Local Conditional Gradient,[0],[0]
Brt (xt ).,3.3 Lazy Local Conditional Gradient,[0],[0]
"In case of a negative call, i.e., when pt = false, then case (ii) of Lemma 3.5 applies:
f (xt+1)",3.3 Lazy Local Conditional Gradient,[0],[0]
− f (x∗) = f (xt ),3.3 Lazy Local Conditional Gradient,[0],[0]
− f (x∗) ≤ ∇,3.3 Lazy Local Conditional Gradient,[0],[0]
f (xt )(xt − x∗) ≤,3.3 Lazy Local Conditional Gradient,[0],[0]
"Φt .
",3.3 Lazy Local Conditional Gradient,[0],[0]
"In case of a positive call, i.e., when Line 10 is executed, we get the same inequality via:
f (xt+1)",3.3 Lazy Local Conditional Gradient,[0],[0]
− f (x∗) ≤,3.3 Lazy Local Conditional Gradient,[0],[0]
Φt−1 + α∇,3.3 Lazy Local Conditional Gradient,[0],[0]
f (xt )(pt − xt ),3.3 Lazy Local Conditional Gradient,[0],[0]
+,3.3 Lazy Local Conditional Gradient,[0],[0]
"β
2 α2‖xt",3.3 Lazy Local Conditional Gradient,[0],[0]
"− pt ‖2
≤",3.3 Lazy Local Conditional Gradient,[0],[0]
Φt−1,3.3 Lazy Local Conditional Gradient,[0],[0]
"− α Φt
K +
β 2 α2 min{nµ2r2t ,D2}
=",3.3 Lazy Local Conditional Gradient,[0],[0]
"Φt .
11
Therefore using the definition of α and rt we get the desired bound:
",3.3 Lazy Local Conditional Gradient,[0],[0]
Φt ≤,3.3 Lazy Local Conditional Gradient,[0],[0]
Φt−1,3.3 Lazy Local Conditional Gradient,[0],[0]
"+
β 2α 2r2t nµ 2 1 + α/K = Φt−1 ( 1 + α/(2K) 1 + α/K ) ≤",3.3 Lazy Local Conditional Gradient,[0],[0]
Φ0 ( 1 + α/(2K) 1 + α/K ) t .,3.3 Lazy Local Conditional Gradient,[0],[0]
"In this section we provide a parameter-free variant of the Lazy Frank-Wolfe Algorithm, which is inspired by Pokutta [2017] and which exhibits a very favorable behavior in computations; the same technique applies to all other variants from Section 3 as well.",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"The idea is that instead of using predetermined values for progress parameters, like Φt and γt in Algorithm 3, to optimize worst-case progress, the parameters are adjusted adaptively, using data encountered by the algorithm, and avoiding hard-to-estimate parameters, like the curvature C. In practice, this leads to faster convergence, as usual for adaptive methods, while the theoretical convergence rate is worse only by a small constant factor.",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"See Figures 26 and 28 for a comparison and Section 7.1.1 for more experimental results.
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"The occasional halving of the Φt is reminiscent of an adaptive restart strategy, considering successive iterates with the same Φt as an epoch.",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"It ensures that Φt is always at least half of the primal gap, while quickly reducing it if it is too large for the algorithm to make progress, and as such it represents a reasonable amount of expected progress throughout the whole run of the algorithm, not just at the initial iterates.
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Algorithm 7 Parameter-free Lazy Conditional Gradient (LCG) Input: smooth convex function f , start vertex x1 ∈ P, weak linear separation oracle LPsepP, accuracy K ≥ 1 Output: points xt in P 1: Φ0 ← maxx∈P ∇",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"f (x1)(x1 − x)/2 {Initial bound} 2: for t = 1 to T − 1 do 3: vt ← LPsepP(∇ f (xt ), xt,Φt−1,K) 4: if vt = false then
5: xt+1 ← xt 6:",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Φt ← Φt−12 {UpdateΦ} 7: else 8: γt ← argmin0≤γ≤1 f ((1 − γ)xt + γvt ) {Line search} 9: xt+1,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"← (1 − γt )xt + γtvt {Update iterate}
10:",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Φt ← Φt−1 11: end if
12: end for
Remark 4.1 (Additional LP call for initial bound).",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Note that Algorithm 7 finds a tight initial bound Φ0 with a single extra LP call.,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"If this is undesired, this can be also done approximately as long as Φ0 is a valid upper bound, for example by means of binary search via the weak separation oracle.
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Theorem 4.2.,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Let f be a smooth convex function with curvature C. Algorithm 7 converges at a rate proportional to 1/t.,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
In particular to achieve a bound f (xt ),4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"− f (x∗) ≤ ε, given an initial upper bound f (x1)",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"− f (x∗) ≤ 2Φ0, the number of required steps is upper bounded by
t ≤ ⌈ log Φ0
ε
⌉ + 1 + 4K ⌈ log Φ0
KC
⌉ + 16K2C
ε .
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"12
Proof.",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
The main idea of the proof is to maintain an approximate upper bound on the optimality gap.,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"We then show that negative calls halve the upper bound 2Φt and positive oracle calls make significant objective function improvement.
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
We analyze iteration t of the algorithm.,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"If Oracle 1 in Line 3 returns a negative answer (i.e., false, case (2)), then this guarantees∇ f (xt )(xt− x) ≤",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Φt−1 for all x ∈ P, in particular, using convexity, f (xt+1)− f (x∗) = f (xt )",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
− f (x∗) ≤ ∇,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
f (xt )(xt − x∗) ≤,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Φt−1 = 2Φt .
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"If Oracle 1 returns a positive answer (case (1)), then we have f (xt )",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
− f (xt+1),4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
≥ γtΦt−1/K − (C/2)γ2t by smoothness of f .,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"By minimality of γt , therefore f (xt )",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
− f (xt+1),4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"≥ min0≤γ≤1(γΦt−1/K − (C/2)γ2), which is Φ2
t−1/(2CK2) if Φt−1 < KC, and Φt−1/K − C/2 ≥",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"C 2 if Φt−1 ≥ KC.
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Now we bound the number t ′ of consecutive positive oracle calls immediately following an iteration t with a negative oracle call.,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Note that the same argument bounds the number of initial consecutive positive oracle calls with the choice t = 0, as we only use f (xt+1)",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"− f (x∗) ≤ 2Φt below.
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Note that Φt = Φt+1,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
= · · · = Φt+t′.,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Therefore
2Φt ≥ f (xt+1)",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"− f (x∗) ≥ t+t′∑
τ=t+1 ( f (xτ)",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
− f (xτ+1)),4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
≥   t ′,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Φ 2 t 2CK2 if Φt < KC t ′,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
( Φt K − C2 ),4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"if Φt ≥ KC ,
which gives in the case Φt < KC that t ′",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
≤ 4CK2/,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Φt , and in the case",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Φt ≥ KC,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"that
t ′",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
≤ 2Φt,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Φt
K − C2
= 4KΦt 2Φt",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
− KC ≤,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
4KΦt 2Φt,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"−Φt = 4K .
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Thus iteration t is followed by at most 4K consecutive positive oracle calls as long as Φt ≥ KC, and 4CK2/",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Φt < 2ℓ+1 · 4K ones for 2−ℓ−1KC <,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Φt ≤ 2−ℓKC with ℓ ≥ 0.
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Adding up the number of oracle calls gives the desired rate: in addition to the positive oracle calls we also have at most ⌈log(Φ0/ε)⌉ + 1 negative oracle calls, where log(·) is the binary logarithm and ε is the (additive) accuracy.",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Thus after a total of
⌈ log Φ0
ε
⌉ + 1 + 4K ⌈ log Φ0
KC
⌉ + ⌈log(KC/ε)⌉∑
ℓ=0
2ℓ+1 · 4K ≤ ⌈ log Φ0
ε
⌉ + 1 + 4K ⌈ log Φ0
KC
⌉ + 16K2C
ε
iterations (or equivalently oracle calls) we have f (xt )",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"− f (x∗) ≤ ε.
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"As seen from the proof, the algorithm receives few negative oracle calls by design; these are usually more expensive than positive ones as the oracle has to compute a certificate by, e.g., executing a full linear optimization oracle call.
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Corollary 4.3.,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Algorithm 7 receives at most ⌈logΦ0/ε⌉,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"+ 1 negative oracle answers.
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Remark 4.4 (Improved use of Linear Optimization oracle).,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
A possible improvement to Line 6 is Φt ← maxx∈P ∇,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"f (xt )(xt−x)/2, assuming that at a negative call the oracle also provides the dual gap maxx∈P ∇",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
f (xt )(xt− x) as well as the minimizer x̄ ∈ P of the oracle call.,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"This is the case e.g., when the weak separation oracle is implemented as in Algorithm 2.",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"Clearly, the minimizer x̄ can be also used to perform a progress step; albeit without guarantee w.r.t. to Φt .
",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
Remark 4.5 (Line Search).,4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"If line search is too expensive we can choose γt = min{1,Φt/KC} in Algorithm 7.",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
"In this case an estimate of the curvature C is required.
13",4 Parameter-free Conditional Gradient via Weak Separation,[0],[0]
In this section we lazify the online conditional gradient algorithm of Hazan and Kale [2012] over arbitrary polytopes P = {x ∈,5 Lazy Online Conditional Gradient,[0],[0]
"Rn | Ax ≤ b}, resulting in Algorithm 8.",5 Lazy Online Conditional Gradient,[0],[0]
"We slightly improve constant factors by replacing [Hazan and Kale, 2012, Lemma 3.1] with a better estimation via solving a quadratic inequality arising from strong convexity.",5 Lazy Online Conditional Gradient,[0],[0]
"In this section the norm ‖·‖ can be arbitrary.
",5 Lazy Online Conditional Gradient,[0],[0]
"Algorithm 8 Lazy Online Conditional Gradient (LOCG) Input: functions ft , start vertex x1 ∈ P, weak linear separation oracle LPsepP, parameters K , C, b, S, s; diameter D Output: points xt 1: for t = 1 to T",5 Lazy Online Conditional Gradient,[0],[0]
"− 1 do 2: ∇t ← ∇ ft (xt ) 3: if t = 1 then 4: h1 ← min{‖∇1‖∗ D, 2 ‖∇1‖∗2 /S} 5: else
6: ht ← Φt−1 +min { ‖∇t ‖∗",5 Lazy Online Conditional Gradient,[0],[0]
"D, ‖∇t ‖ ∗2
St1−s + 2 √ ‖∇t ‖∗2 2St1−s",5 Lazy Online Conditional Gradient,[0],[0]
"( ‖∇t ‖∗2 2St1−s + Φt−1 )}
7: end if
8:",5 Lazy Online Conditional Gradient,[0],[0]
"Φt ← ht+
Ct1−bγ2t 2(1−b) 1+ γt K
9: vt ← LPsepP( ∑t
i=1 ∇ fi(xt ), xt,Φt,K) 10: if vt = false then 11: xt+1 ← xt 12: else",5 Lazy Online Conditional Gradient,[0],[0]
13: xt+1 ← (1 − γt )xt + γtvt 14:,5 Lazy Online Conditional Gradient,[0],[0]
Φt ← ht − ∑t i=1,5 Lazy Online Conditional Gradient,[0],[0]
fi(xt ),5 Lazy Online Conditional Gradient,[0],[0]
+,5 Lazy Online Conditional Gradient,[0],[0]
∑t i=1,5 Lazy Online Conditional Gradient,[0],[0]
"fi(xt+1) 15: end if
16: end for
Theorem 5.1.",5 Lazy Online Conditional Gradient,[0],[0]
"Let 0 ≤ b, s < 1.",5 Lazy Online Conditional Gradient,[0],[0]
Let K ≥ 1 be an accuracy parameter.,5 Lazy Online Conditional Gradient,[0],[0]
"Assume ft is L-Lipschitz, and smooth with curvature at most Ct−b.",5 Lazy Online Conditional Gradient,[0],[0]
"Let D ≔ maxy1,y2∈P ‖y1",5 Lazy Online Conditional Gradient,[0],[0]
− y2‖ denote the diameter of P in norm ‖·‖.,5 Lazy Online Conditional Gradient,[0],[0]
Then the following hold for the points xt computed by Algorithm 8 where x ∗ T is the minimizer of ∑T t=1,5 Lazy Online Conditional Gradient,[0],[0]
"ft :
(i) With the choice
γt = t −(1−b)/2,
the xt satisfy
1
T
T∑
t=1
( ft (xT )",5 Lazy Online Conditional Gradient,[0],[0]
− ft (x∗T )) ≤,5 Lazy Online Conditional Gradient,[0],[0]
"AT−(1−b)/2,
where
A ≔ CK
2(1 − b) +",5 Lazy Online Conditional Gradient,[0],[0]
"L(K + 1)D.
(ii)",5 Lazy Online Conditional Gradient,[0],[0]
"Moreover, if all the ft are St −s-strongly convex, then with the choice
γt = t (b+s−2)/3,
14
the xt satisfy
1
T
T∑
t=1
( ft (xT )",5 Lazy Online Conditional Gradient,[0],[0]
− ft (x∗T )),5 Lazy Online Conditional Gradient,[0],[0]
"≤ AT−(2(1+b)−s)/3, (3)
where
A ≔ 2",5 Lazy Online Conditional Gradient,[0],[0]
( (K + 1)(K + 2),5 Lazy Online Conditional Gradient,[0],[0]
"L 2
S +
CK
2(1 − b)
) .
",5 Lazy Online Conditional Gradient,[0],[0]
Proof.,5 Lazy Online Conditional Gradient,[0],[0]
"We prove only Claim (ii), as the proof of Claim (i) is similar and simpler.",5 Lazy Online Conditional Gradient,[0],[0]
Let FT ≔ ∑T t=1 ft .,5 Lazy Online Conditional Gradient,[0],[0]
"Furthermore, let hT ≔ AT1−(2(1+b)−s)/3 be T times the right-hand side of Equation (3).",5 Lazy Online Conditional Gradient,[0],[0]
"In particular, FT is ST -strongly convex, and smooth with curvature at most CFT where
CFT ≔ CT1−b 1",5 Lazy Online Conditional Gradient,[0],[0]
"− b ≥ C T∑
t=1
t−b, ST ≔ ST 1−s ≤",5 Lazy Online Conditional Gradient,[0],[0]
"S
T∑
t=1
t−s .
",5 Lazy Online Conditional Gradient,[0],[0]
We prove Ft (xt ),5 Lazy Online Conditional Gradient,[0],[0]
− Ft (x∗t ) ≤,5 Lazy Online Conditional Gradient,[0],[0]
ht ≤ ht by induction on t. The case t = 1 is clear.,5 Lazy Online Conditional Gradient,[0],[0]
"Let Φt denote the value of Φt in Line 8, while we reserveΦt to denote its value as used in Line 6.",5 Lazy Online Conditional Gradient,[0],[0]
We start by showing Ft (xt+1),5 Lazy Online Conditional Gradient,[0],[0]
− Ft (x∗t ) ≤,5 Lazy Online Conditional Gradient,[0],[0]
Φt ≤,5 Lazy Online Conditional Gradient,[0],[0]
Φt .,5 Lazy Online Conditional Gradient,[0],[0]
We distinguish two cases depending on the oracle answer vt from Line 9.,5 Lazy Online Conditional Gradient,[0],[0]
"For a negative oracle answer (vt = false), we have Φt = Φt and the weak separation oracle asserts maxy∈P ∇Ft (xt )(xt − y) ≤",5 Lazy Online Conditional Gradient,[0],[0]
"Φt , which combined with the convexity of Ft provides
Ft (xt+1)",5 Lazy Online Conditional Gradient,[0],[0]
− Ft (x∗t ),5 Lazy Online Conditional Gradient,[0],[0]
= Ft (xt ) − Ft (x∗t ) ≤ ∇Ft,5 Lazy Online Conditional Gradient,[0],[0]
(xt )(xt − xt∗) ≤,5 Lazy Online Conditional Gradient,[0],[0]
"Φt = Φt .
",5 Lazy Online Conditional Gradient,[0],[0]
"Otherwise, for a positive oracle answer, Line 14 and the induction hypothesis provides Ft (xt+1)",5 Lazy Online Conditional Gradient,[0],[0]
− Ft (x∗t ) ≤,5 Lazy Online Conditional Gradient,[0],[0]
ht +,5 Lazy Online Conditional Gradient,[0],[0]
Ft (xt+1),5 Lazy Online Conditional Gradient,[0],[0]
− Ft (xt ),5 Lazy Online Conditional Gradient,[0],[0]
=,5 Lazy Online Conditional Gradient,[0],[0]
Φt .,5 Lazy Online Conditional Gradient,[0],[0]
To prove Φt ≤,5 Lazy Online Conditional Gradient,[0],[0]
"Φt , we apply the smoothness of Ft followed by the inequality provided by the choice of vt :
Ft (xt+1)",5 Lazy Online Conditional Gradient,[0],[0]
− Ft (xt ),5 Lazy Online Conditional Gradient,[0],[0]
− CFt,5 Lazy Online Conditional Gradient,[0],[0]
"γ
2 t
2 ≤ ∇Ft (xt )(xt+1 − xt ) = γt∇Ft",5 Lazy Online Conditional Gradient,[0],[0]
(xt )(vt − xt ) ≤,5 Lazy Online Conditional Gradient,[0],[0]
"−
γtΦt
K .
",5 Lazy Online Conditional Gradient,[0],[0]
"Rearranging provides the inequality:
",5 Lazy Online Conditional Gradient,[0],[0]
Φt = ht + Ft (xt+1),5 Lazy Online Conditional Gradient,[0],[0]
− Ft (xt ) ≤,5 Lazy Online Conditional Gradient,[0],[0]
"ht − γtΦt
K +
CFt γ 2 t
2 =",5 Lazy Online Conditional Gradient,[0],[0]
"Φt .
",5 Lazy Online Conditional Gradient,[0],[0]
"For later use, we bound the difference between ht and Φt using the value of parameters, ht ≤ ht , and γt ≤ 1:
ht −Φt ≥ ht",5 Lazy Online Conditional Gradient,[0],[0]
"− ht +
CFt γ 2 t
2
1 + γt K
=
htγt K",5 Lazy Online Conditional Gradient,[0],[0]
"− CFt γ
2 t
2
1 + γt K
≥ htγt K",5 Lazy Online Conditional Gradient,[0],[0]
"− CFt γ
2 t
2
1 + 1 K
= A − CK2(1−b) K",5 Lazy Online Conditional Gradient,[0],[0]
"+ 1 t[2s−(1+b)]/3.
",5 Lazy Online Conditional Gradient,[0],[0]
We now apply Ft (xt+1),5 Lazy Online Conditional Gradient,[0],[0]
− Ft (x∗t ) ≤,5 Lazy Online Conditional Gradient,[0],[0]
"Φt , together with convexity of ft+1, and the minimality Ft (x∗t ) ≤",5 Lazy Online Conditional Gradient,[0],[0]
"Ft (x∗t+1) of x∗t , followed by strong convexity of Ft+1:
Ft+1(xt+1)",5 Lazy Online Conditional Gradient,[0],[0]
− Ft+1(x∗t+1) ≤,5 Lazy Online Conditional Gradient,[0],[0]
(Ft (xt+1),5 Lazy Online Conditional Gradient,[0],[0]
− Ft (x ∗ t )),5 Lazy Online Conditional Gradient,[0],[0]
"+ ( ft+1(xt+1) − ft+1(x∗t+1))
≤",5 Lazy Online Conditional Gradient,[0],[0]
Φt + ‖∇t+1‖∗ · ‖xt+1,5 Lazy Online Conditional Gradient,[0],[0]
− x∗t+1‖ ≤,5 Lazy Online Conditional Gradient,[0],[0]
"Φt + ‖∇t+1‖∗ √ 2
St+1 (Ft+1(xt+1)",5 Lazy Online Conditional Gradient,[0],[0]
"− Ft+1(x∗t+1)).
(4)
15
Solving the quadratic inequality provides
Ft+1(xt+1)",5 Lazy Online Conditional Gradient,[0],[0]
− Ft+1(x∗t+1) ≤,5 Lazy Online Conditional Gradient,[0],[0]
"Φt + ‖∇t+1‖∗2
St+1 + 2
√√ ‖∇t+1‖∗2
2St+1
( ‖∇t+1‖∗2
2St+1",5 Lazy Online Conditional Gradient,[0],[0]
"+Φt
) .",5 Lazy Online Conditional Gradient,[0],[0]
"(5)
From Equation (4), ignoring the last line, we also obtain Ft+1(xt+1)",5 Lazy Online Conditional Gradient,[0],[0]
− Ft+1(x∗t+1) ≤,5 Lazy Online Conditional Gradient,[0],[0]
"Φt + ‖∇t+1‖ ∗
D via the estimate ‖xt+1",5 Lazy Online Conditional Gradient,[0],[0]
− x∗t+1‖ ≤,5 Lazy Online Conditional Gradient,[0],[0]
D. Thus Ft+1(xt+1),5 Lazy Online Conditional Gradient,[0],[0]
− Ft+1(x ∗ t+1) ≤,5 Lazy Online Conditional Gradient,[0],[0]
"ht+1, by Line 6, as claimed.
",5 Lazy Online Conditional Gradient,[0],[0]
"Now we estimate the right-hand side of Equation (5) by using the actual value of the parameters, the estimate ‖∇t+1‖∗ ≤ L, and the inequality s+ b ≤ 2.",5 Lazy Online Conditional Gradient,[0],[0]
"In fact, we estimate a proxy for the right-hand side.",5 Lazy Online Conditional Gradient,[0],[0]
"Note that A was chosen to satisfy the second inequality:
L2
St+1 + 2
√ L2
2St+1 ht ≤
L2
St1−s + 2
√ L2
2St1−s ht ≤
L2
S t[2s−(1+b)]/3 + 2
√ L2
2St1−s ht
=
( L2
S +
√ 2 L2
S A
) t[2s−(1+b)]/3 ≤
A − CK2(1−b)",5 Lazy Online Conditional Gradient,[0],[0]
"K + 1 t[2s−(1+b)]/3
≤",5 Lazy Online Conditional Gradient,[0],[0]
ht −Φt ≤,5 Lazy Online Conditional Gradient,[0],[0]
"ht −Φt .
",5 Lazy Online Conditional Gradient,[0],[0]
"In particular, L 2
2St+1 +",5 Lazy Online Conditional Gradient,[0],[0]
"Φt ≤ ht hence combining with Equation (5) we obtain
ht+1 ≤",5 Lazy Online Conditional Gradient,[0],[0]
"Φt + L2
St+1 + 2
√ L2
2St+1
( L2
2St+1 +",5 Lazy Online Conditional Gradient,[0],[0]
"Φt
)
≤",5 Lazy Online Conditional Gradient,[0],[0]
"Φt + L2
St+1 + 2
√ L2
2St+1",5 Lazy Online Conditional Gradient,[0],[0]
"ht
≤ ht ≤ ht+1.",5 Lazy Online Conditional Gradient,[0],[0]
"Complementing the offline algorithms from Section 3, we will now derive various online versions.",5.1 Stochastic and Adversarial Versions,[0],[0]
"The presented cases here are similar to those in Hazan and Kale [2012] and thus we state them without proof.
",5.1 Stochastic and Adversarial Versions,[0],[0]
"For stochastic cost functions ft , we obtain bounds from Theorem 5.1 (i) similar to [Hazan and Kale, 2012, Theorems 4.1 and 4.3] (with δ replaced by δ/T in the bound to correct an inaccuracy in the original argument).",5.1 Stochastic and Adversarial Versions,[0],[0]
"The proof is analogous and hence omitted, but note that ‖y1",5.1 Stochastic and Adversarial Versions,[0],[0]
− y2‖2 ≤ √ ‖y1 − y2‖1‖y1 − y2‖∞ ≤,5.1 Stochastic and Adversarial Versions,[0],[0]
"√ k for all y1, y2 ∈",5.1 Stochastic and Adversarial Versions,[0],[0]
"P.
Corollary 5.2.",5.1 Stochastic and Adversarial Versions,[0],[0]
Let ft be convex functions sampled i.i.d.,5.1 Stochastic and Adversarial Versions,[0],[0]
"with expectation E [ ft ] = f ∗, and δ > 0.",5.1 Stochastic and Adversarial Versions,[0],[0]
"Assume that the ft are L-Lipschitz in the 2-norm.
",5.1 Stochastic and Adversarial Versions,[0],[0]
(i),5.1 Stochastic and Adversarial Versions,[0],[0]
"If all the ft are smooth with curvature at most C, then Algorithm 8 applied to the ft (with b = 0) yields with probability 1 − δ
T∑
t=1
f ∗(xt ) −min",5.1 Stochastic and Adversarial Versions,[0],[0]
"x∈P
T∑
t=1
f ∗(x) ≤",5.1 Stochastic and Adversarial Versions,[0],[0]
O ( C √ T +,5.1 Stochastic and Adversarial Versions,[0],[0]
"Lk √ nT log(nT2/δ) logT ) .
",5.1 Stochastic and Adversarial Versions,[0],[0]
"16
(ii) Without any smoothness assumption, Algorithm 8 (applied to smoothenings of the ft ) provides with
probability 1 − δ
T∑
t=1
f ∗(xt ) −min",5.1 Stochastic and Adversarial Versions,[0],[0]
"x∈P
T∑
t=1
f ∗(x) ≤",5.1 Stochastic and Adversarial Versions,[0],[0]
O (√ nLkT2/3 +,5.1 Stochastic and Adversarial Versions,[0],[0]
"Lk √ nT log(nT2/δ) logT ) .
",5.1 Stochastic and Adversarial Versions,[0],[0]
"Similar to [Hazan and Kale, 2012, Theorem 4.4], from Theorem 5.1 (ii) we obtain the following regret bound for adversarial cost functions with an analogous proof.
",5.1 Stochastic and Adversarial Versions,[0],[0]
Corollary 5.3.,5.1 Stochastic and Adversarial Versions,[0],[0]
"For any L-Lipschitz convex cost functions ft , Algorithm 8 applied to the functions f̃t (x) ≔ ∇",5.1 Stochastic and Adversarial Versions,[0],[0]
ft (xt )x,5.1 Stochastic and Adversarial Versions,[0],[0]
"+ 2L√
k t−1/4‖x",5.1 Stochastic and Adversarial Versions,[0],[0]
"− x1‖22 (with b = s = 1/4, C = L
√ k, S = L/",5.1 Stochastic and Adversarial Versions,[0],[0]
"√ k, and Lipschitz constant 3L) achieving
regret T∑
t=1
ft (xt ) −min",5.1 Stochastic and Adversarial Versions,[0],[0]
"x∈P
T∑
t=1
ft (x) ≤ O(L √ kT3/4)
with at most T calls to the weak separation oracle.
Note that the gradient of the f̃t are easily computed via the formula∇ f̃t (x) = ∇ ft (xt )+4Lt−1/4(x−x1)/ √
k , particularly because the gradient of the ft need not be recomputed, so that we obtain a weak separation-based stochastic gradient descent algorithm, where we only have access to the ft through a stochastic gradient oracle, while retaining all the favorable properties of the Frank-Wolfe algorithm with a convergence rate O(T−1/4)",5.1 Stochastic and Adversarial Versions,[0],[0]
"(c.f., Garber and Hazan [2013]).",5.1 Stochastic and Adversarial Versions,[0],[0]
So far we realized the weak separation oracle via lazy optimization.,6 Weak Separation through Augmentation,[0],[0]
"We will now create a (weak) separation oracle for integral polytopes, employing an even weaker, so-called augmentation oracle, which only provides an improving solution but provides no guarantee with respect to optimality.",6 Weak Separation through Augmentation,[0],[0]
We call this approach lazy augmentation.,6 Weak Separation through Augmentation,[0],[0]
"This is especially useful when a fast augmentation oracle is available or the vertices of the underlying polytope P are particularly sparse, i.e., ‖y1",6 Weak Separation through Augmentation,[0],[0]
"− y2‖1 ≤ k ≪ n for all y1, y2 ∈ P, where n is the ambient dimension of P. As before theoretical convergence rates are maintained.
",6 Weak Separation through Augmentation,[0],[0]
For simplicity of exposition we restrict to 0/1 polytopes P here.,6 Weak Separation through Augmentation,[0],[0]
"For general integral polytopes, one considers a so-called directed augmentation oracle, which can be similarly linearized after splitting variables in positive and negative parts; we refer the interested reader to see [Schulz and Weismantel, 2002, Bodic et al., 2015] for an in-depth discussion.
",6 Weak Separation through Augmentation,[0],[0]
"Let k denote the ℓ1-diameter of P. Upon presentation with a 0/1 solution x and a linear objective c ∈ Rn, an augmentation oracle either provides an improving 0/1 solution x̄ with cx̄ < cx or asserts optimality for c:
Oracle 2 Linear Augmentation Oracle AUGP(c, x)",6 Weak Separation through Augmentation,[0],[0]
Input: linear objective,6 Weak Separation through Augmentation,[0],[0]
"c ∈ Rn, vertex x ∈ P Output: vertex x̄ ∈ P with cx̄ < cx when exists, otherwise x̄ = x
Such an oracle is significantly weaker than a linear optimization oracle but also significantly easier to implement and much faster; we refer the interested reader to [Grötschel and Lovász, 1993, Schulz et al., 1995, Schulz and Weismantel, 2002] for an extensive list of examples.",6 Weak Separation through Augmentation,[0],[0]
"While augmentation and optimization are
17
polynomially equivalent (even for convex integer programming",6 Weak Separation through Augmentation,[0],[0]
"[Oertel et al., 2014]) the current best linear optimization algorithms based on an augmentation oracle are slow for general objectives.",6 Weak Separation through Augmentation,[0],[0]
"While optimizing an integral objective c ∈ Rn needs O(k log‖c‖∞) calls to an augmentation oracle (see [Schulz et al., 1995, Schulz and Weismantel, 2002, Bodic et al., 2015]), a general objective function, such as the gradient in Frank–Wolfe algorithms has only an O(kn3) guarantee in terms of required oracle calls (e.g., via simultaneous diophantine approximations [Frank and Tardos, 1987]), which is not desirable for large n.",6 Weak Separation through Augmentation,[0],[0]
"In contrast, here we use an augmentation oracle to perform separation, without finding the optimal solution.",6 Weak Separation through Augmentation,[0],[0]
"Allowing a multiplicative error K > 1, we realize an augmentation-based weak separation oracle (see Algorithm 9), which decides given a linear objective function",6 Weak Separation through Augmentation,[0],[0]
"c ∈ Rn, an objective value",6 Weak Separation through Augmentation,[0],[0]
"Φ > 0, and a starting point x ∈ P, whether there is a y ∈ P with c(x − y) > Φ/K or c(x − y) ≤",6 Weak Separation through Augmentation,[0],[0]
Φ for all y ∈,6 Weak Separation through Augmentation,[0],[0]
P.,6 Weak Separation through Augmentation,[0],[0]
"In the former case, it actually provides a certifying y ∈ P, i.e., with c(x − y) >",6 Weak Separation through Augmentation,[0],[0]
Φ/K .,6 Weak Separation through Augmentation,[0],[0]
"Note that a constant accuracy K requires a linear number of oracle calls in the diameter k, e.g., K = (1 − 1/e)−1 ≈ 1.582 needs at most N ≤",6 Weak Separation through Augmentation,[0],[0]
"k oracle calls, which can be much smaller than the ambient dimension of the polytope.
",6 Weak Separation through Augmentation,[0],[0]
"At the beginning, in Line 2, the algorithm has to replace the input point x with an integral point x0.",6 Weak Separation through Augmentation,[0],[0]
"If the point x is given as a convex combination of integral points, then a possible solution is to evaluate the objective c on these integral points, and choose x0 the first one with cx0 ≤ cx.",6 Weak Separation through Augmentation,[0],[0]
"This can be easily arranged for Frank–Wolfe algorithms as they maintain convex combinations.
",6 Weak Separation through Augmentation,[0],[0]
"Algorithm 9 Augmenting Weak Separation LPsepP(c, x,Φ,K) Input: linear objective c ∈ Rn, point x ∈ P, objective value",6 Weak Separation through Augmentation,[0],[0]
Φ > 0; accuracy K > 1 Output: Either (1) y ∈ P vertex with c(x − y) >,6 Weak Separation through Augmentation,[0],[0]
"Φ/K , or (2) false: c(x − z) ≤",6 Weak Separation through Augmentation,[0],[0]
"Φ for all z ∈ P.
1: N ← ⌈log(1 −",6 Weak Separation through Augmentation,[0],[0]
1/K)/log(1,6 Weak Separation through Augmentation,[0],[0]
− 1/k)⌉ 2: Choose x0 ∈ P vertex with cx0 ≤,6 Weak Separation through Augmentation,[0],[0]
cx. 3: for i = 1 to N do 4: if c(x − xi−1) ≥,6 Weak Separation through Augmentation,[0],[0]
"Φ then 5: return xi−1 6: end if 7: xi ← AUGP(c + Φ−c(x−xi−1)k (1 − 2xi−1), xi−1) 8: if xi = xi−1 then 9: return false
10: end if
11: end for
12: return xN
Proposition 6.1.",6 Weak Separation through Augmentation,[0],[0]
Assume ‖y1,6 Weak Separation through Augmentation,[0],[0]
"− y2‖1 ≤ k for all y1, y2 ∈",6 Weak Separation through Augmentation,[0],[0]
"P. Then Algorithm 9 is correct, i.e., it outputs either (1) y ∈ P with c(x − y) >",6 Weak Separation through Augmentation,[0],[0]
"Φ/K , or (2) false.",6 Weak Separation through Augmentation,[0],[0]
In the latter case c(x − y) ≤ Φ for all y ∈ P holds.,6 Weak Separation through Augmentation,[0],[0]
The algorithm calls AUGP at most N ≤ ⌈log(1 − 1/K)/log(1,6 Weak Separation through Augmentation,[0],[0]
"− 1/k)⌉ many times.
",6 Weak Separation through Augmentation,[0],[0]
Proof.,6 Weak Separation through Augmentation,[0],[0]
First note that (1 − 2x)v + ‖x‖1,6 Weak Separation through Augmentation,[0],[0]
= ‖v,6 Weak Separation through Augmentation,[0],[0]
"− x‖1 for x, v ∈ {0, 1}n, hence Line 7 is equivalent to xi ← AUGP(c + Φ−c(x−xi−1)k ‖· − xi−1‖1, xi−1).
",6 Weak Separation through Augmentation,[0],[0]
"The algorithm obviously calls the oracle at most N times by design, and always returns a value, so we need to verify only the correctness of the returned value.",6 Weak Separation through Augmentation,[0],[0]
"We distinguish cases according to the output.
",6 Weak Separation through Augmentation,[0],[0]
"Clearly, Line 5 always returns an xi−1 with c(x − xi−1)",6 Weak Separation through Augmentation,[0],[0]
≥,6 Weak Separation through Augmentation,[0],[0]
Φ >,6 Weak Separation through Augmentation,[0],[0]
[1 − (1 − 1/k)N,6 Weak Separation through Augmentation,[0],[0]
],6 Weak Separation through Augmentation,[0],[0]
"Φ. When Line 9 is executed, the augmentation oracle just returned xi = xi−1, i.e., for all y ∈ P
cxi−1 ≤",6 Weak Separation through Augmentation,[0],[0]
cy,6 Weak Separation through Augmentation,[0],[0]
+,6 Weak Separation through Augmentation,[0],[0]
"Φ − c(x − xi−1)
",6 Weak Separation through Augmentation,[0],[0]
k ‖y,6 Weak Separation through Augmentation,[0],[0]
− xi−1‖1 ≤,6 Weak Separation through Augmentation,[0],[0]
cy +,6 Weak Separation through Augmentation,[0],[0]
Φ − c(x − xi−1),6 Weak Separation through Augmentation,[0],[0]
k k = c(y,6 Weak Separation through Augmentation,[0],[0]
− x),6 Weak Separation through Augmentation,[0],[0]
+,6 Weak Separation through Augmentation,[0],[0]
cxi−1,6 Weak Separation through Augmentation,[0],[0]
"+Φ,
18
so that c(x − y) ≤",6 Weak Separation through Augmentation,[0],[0]
"Φ, as claimed.",6 Weak Separation through Augmentation,[0],[0]
"Finally, when Line 12 is executed, the augmentation oracle has found an improving vertex xi at every iteration, i.e.,
cxi−1 > cxi + Φ − c(x − xi−1)
",6 Weak Separation through Augmentation,[0],[0]
k ‖xi − xi−1‖1,6 Weak Separation through Augmentation,[0],[0]
≥ cxi +,6 Weak Separation through Augmentation,[0],[0]
"Φ − c(x − xi−1) k ,
using ‖xi − xi−1‖1",6 Weak Separation through Augmentation,[0],[0]
≥ 1 by integrality.,6 Weak Separation through Augmentation,[0],[0]
"Rearranging provides the convenient form
Φ − c(x − xi) <",6 Weak Separation through Augmentation,[0],[0]
"( 1 − 1
k
)",6 Weak Separation through Augmentation,[0],[0]
"[Φ − c(x − xi−1)],
which by an easy induction provides
Φ − c(x − xN )",6 Weak Separation through Augmentation,[0],[0]
"< ( 1 − 1
k
)N",6 Weak Separation through Augmentation,[0],[0]
[Φ − c(x − x0)] ≤,6 Weak Separation through Augmentation,[0],[0]
"( 1 − 1
K
)",6 Weak Separation through Augmentation,[0],[0]
"Φ,
i.e., c(x − xN )",6 Weak Separation through Augmentation,[0],[0]
"≥ ΦK , finishing the proof.",6 Weak Separation through Augmentation,[0],[0]
"We implemented and compared the parameter-free variant of LCG (Algorithm 7) to the standard FrankWolfe algorithm (CG), then Algorithm 4 (LPCG) to the Pairwise Conditional Gradient algorithm (PCG) of Garber and Meshi [2016], as well as Algorithm 8 (LOCG) to the Online Frank-Wolfe algorithm (OCG) of Hazan and Kale [2012].",7 Experiments,[0],[0]
While we did implement the Local Conditional Gradient algorithm ofGarber and Hazan,7 Experiments,[0],[0]
"[2013] as well, the very large constants in the original algorithms made it impractical to run.",7 Experiments,[0],[0]
"Unless stated otherwise the weak separation oracle is implemented as sketched in Algorithm 2 through caching and early termination of the original LP oracle.
",7 Experiments,[0],[0]
We have used K = 1.1 and K = 1 as multiplicative factors for the weak separation oracle; for the impact of the choice of K see Section 7.2.2.,7 Experiments,[0],[0]
"For the baseline algorithms we use inexact variants, i.e., we solve linear optimization problems only approximately.",7 Experiments,[0],[0]
"This is a significant speedup in favor of non-lazy algorithms at the (potential) cost of accuracy, while neutral to lazy optimization as it solves an even more relaxed problem anyways.",7 Experiments,[0],[0]
"To put things in perspective, the non-lazy baselines could not complete even a single iteration for a significant fraction of the considered problems in the given time frame if we were to exactly solve the linear optimization problems.",7 Experiments,[0],[0]
"In terms of using line search, for all tests we treated all algorithms equally: either all or none used line search.",7 Experiments,[0],[0]
"If not stated otherwise, we used (simple backtracking) line search.
",7 Experiments,[0],[0]
The linear optimization oracle over P × P for LPCG was implemented by calling the respective oracle over P twice: once for either component.,7 Experiments,[0],[0]
"Contrary to the non-lazy version, the lazy algorithms depend on the initial upper bound Φ0.",7 Experiments,[0],[0]
"For the instances that need a very long time to solve the (approximate) linear optimization even once, we used a binary search for Φ0 for the lazy algorithms: starting from a conservative initial value, using the update rule Φ0 ← Φ0/2 until the separation oracle returns an improvement for the first time",7 Experiments,[0],[0]
"and then we start the algorithm with 2Φ0, which is an upper bound on the Wolfe gap and hence also on the primal gap.",7 Experiments,[0],[0]
This initial phase is also included in the reported wall-clock time.,7 Experiments,[0],[0]
"Alternatively, if the linear optimization was less time consuming we used a single (approximate) linear optimization at the start to obtain an initial bound on Φ0 (see e.g., Section 4).
",7 Experiments,[0],[0]
"In some cases, especially when the underlying feasible region has a high dimension and the (approximate) linear optimization can be solved relatively fast compared to the cost of computing an inner product, we observed that the costs of maintaining the cache was very high.",7 Experiments,[0],[0]
"In these cases we reduced the cache size
19
every 100 steps by keeping only the 100 points that were used the most so far.",7 Experiments,[0],[0]
"Both the number of steps and the approximate size of the cache were chosen arbitrarily, however 100 for both worked very well for all our examples.",7 Experiments,[0],[0]
"Of course there are many different strategies for maintaining the cache, which could be used here and which could lead to further improvements in performance.
",7 Experiments,[0],[0]
The stopping criteria for each of the experiments was a given wall clock time limit in seconds.,7 Experiments,[0],[0]
"The time limit was enforced separately for the main code and the oracle code, so in some cases the actual time used can be larger, when the last oracle call started before the time limit was reached and took longer than the time left.
",7 Experiments,[0],[0]
We implemented all algorithms in Python 2.7 with critical functions cythonized for performance employing Numpy.,7 Experiments,[0],[0]
We used these packages from the Anaconda 4.2.0 distribution as well as Gurobi 7.0,7 Experiments,[0],[0]
"[Gurobi Optimization, 2016] as a black box solver for the linear optimization oracle.",7 Experiments,[0],[0]
The weak separation oracle was implemented via a callback function to stop linear optimization as soon as a good enough feasible solution has been found in a schema as outlined in Algorithm 2.,7 Experiments,[0],[0]
"The parameters for Gurobi were kept at their default settings except for enforcing the time limit of the tests and setting the acceptable duality gap to 10%, allowing Gurobi to terminate the linear optimization early avoiding the expensive proof of optimality.",7 Experiments,[0],[0]
This is used to realize the inexact versions of the baseline algorithms.,7 Experiments,[0],[0]
All experiments were performed on a 16-core machine with Intel Xeon E5-2630 v3 @ 2.40GHz CPUs and 128GB of main memory.,7 Experiments,[0],[0]
"While our code does not explicitly use multiple threads, both Gurobi and the numerical libraries use multiple threads internally.",7 Experiments,[0],[0]
"We performed computational tests on a large variety of different problems that are instances of the three machine learning tasks video colocalization, matrix completion, and structured regression.
",7.1 Computational results,[0],[0]
Video colocalization.,7.1 Computational results,[0],[0]
Video colocalization is the problem of identifying objects in a sequence of multiple frames in a video.,7.1 Computational results,[0],[0]
"In Joulin et al. [2014] it is shown that video colocalization can be reduced to optimizing a quadratic objective function over a flow or a path polytope, which is the problem we are going to solve.",7.1 Computational results,[0],[0]
"The resulting linear program is an instance of the minimum-cost network flow problem, see [Joulin et al., 2014, Eq. (3)] for the concrete linear program and more details.",7.1 Computational results,[0],[0]
"The quadratic functions are of the form ‖Ax − b‖2 where we choose the non-zero entries in A according to a density parameter at random and then each of these entries to be [0, 1]-uniformly distributed, while b is chosen as a linear combination of the columns of A with random multipliers from [0, 1].",7.1 Computational results,[0],[0]
For some of the instances we also use ‖x − b‖2 as the objective function with bi ∈,7.1 Computational results,[0],[0]
"[0, 1] uniformly at random.
",7.1 Computational results,[0],[0]
Matrix completion.,7.1 Computational results,[0],[0]
"The formulationof the matrix completion problem we are going to use is the following:
min X
∑
(i, j)∈Ω |Xi, j − Ai, j |2 s.t. ‖X ‖∗",7.1 Computational results,[0],[0]
≤,7.1 Computational results,[0],[0]
"R, (6)
",7.1 Computational results,[0],[0]
"where ‖·‖∗ denotes the nuclear norm, i.e., ‖A‖∗ =",7.1 Computational results,[0],[0]
"Tr( √
At A).",7.1 Computational results,[0],[0]
"The set Ω, the matrix A and R are given parameters.",7.1 Computational results,[0],[0]
Similarly to Lan and Zhou,7.1 Computational results,[0],[0]
[2014] we generate the m × n matrix A as the product of AL of size m × r and AR of size,7.1 Computational results,[0],[0]
r × n.,7.1 Computational results,[0],[0]
The entries in AL and AR are chosen from a standard Gaussian distribution.,7.1 Computational results,[0],[0]
The set Ω is chosen uniformly of size s = min{5r(m + n,7.1 Computational results,[0],[0]
"− r), ⌈0.99mn⌉}.",7.1 Computational results,[0],[0]
The linear optimization oracle is implemented in this case by a singular value decomposition of the linear objective function and we essentially solve the LP to (approximate) optimality.,7.1 Computational results,[0],[0]
"The matrix completion tests will only demonstrate the impact of
20
caching solutions.",7.1 Computational results,[0],[0]
"Note that this test is also informative as due to the ‘roundness’ of the feasible region the solution of the actual LP oracle will induce a direction that is equal to the true gradient and as such it provides insight into how much per-iteration progress is lost due to working with gradient approximations from the weak separation oracle.
",7.1 Computational results,[0],[0]
Structured regression.,7.1 Computational results,[0],[0]
"The structured regression problem consists of solving a quadratic function of the form ‖Ax − b‖2 over some structured feasible set or a polytope P, i.e., we solve minx∈P ‖Ax − b‖2.",7.1 Computational results,[0],[0]
"We construct the objective functions in the same way as for the video colocalization problem.
Tests.",7.1 Computational results,[0],[0]
In the following two sections we will present our results for various problems grouped by the versions of the considered algorithms.,7.1 Computational results,[0],[0]
"Every figure contains two columns, each containing one experiment.",7.1 Computational results,[0],[0]
"We use different measures to report performance: we report progress of loss or function value in wall-clock time in the first row (including time spent by the oracle), in the number of iterations in the second row, and in the number of linear optimization calls in the last row.",7.1 Computational results,[0],[0]
"Obviously, the latter only makes sense for the lazy algorithms.",7.1 Computational results,[0],[0]
In some other cases we report in another row the dual bound or Wolfe gap in wall-clock time.,7.1 Computational results,[0],[0]
The red line denotes the non-lazy algorithm and the green line denotes the lazy variants.,7.1 Computational results,[0],[0]
"For each experiment we also report the cache hit rate, which is the number of oracle calls answered with a point from the cache over all oracle calls given in percent.
",7.1 Computational results,[0],[0]
"While we found convergence rates in the number of iterations quite similar (as expected!), we consistently observe a significant speedup in wall-clock time.",7.1 Computational results,[0],[0]
"In particular for many large-scale or hard combinatorial problems, lazy algorithms performed several thousand iterations whereas the non-lazy versions completed only a handful of iterations due to the large time spent approximately solving the linear optimization problem.",7.1 Computational results,[0],[0]
"The observed cache hit rate was at least 90% in most cases, and often even above 99%.",7.1 Computational results,[0],[0]
"We describe the considered instances in the offline case separately for the vanilla Frank-Wolfe method and the Pairwise Conditional Gradient method.
",7.1.1 Offline Results,[0],[0]
"Vanilla Frank-Wolfe Method We tested the vanilla Frank-Wolfe algorithm on the six video colocalization instances with underlying path polytopes from http://lime.cs.elte.hu/~kpeter/data/mcf/netgen/ (Figures 1, 2 and 3).",7.1.1 Offline Results,[0],[0]
In these instances we additionally report the dual bound or Wolfe gap in wall clock time.,7.1.1 Offline Results,[0],[0]
"We further tested the vanilla Frank-Wolfe algorithm on eight instances of the matrix completion problem generated as described above, for which we did not use line search; the parameter-free lazy variant is run with approximate minimization as described in Remark 4.5, the others use their respective standard step sizes.",7.1.1 Offline Results,[0],[0]
"We provide the used parameters for each example in the figures below (Figures 4, 5, 6 and 7).",7.1.1 Offline Results,[0],[0]
"The last tests for this version were performed on three instances of the structured regression problem, two with the feasible region containing flow-based formulations of Hamiltonian cycles in graphs (Figure 8), and further tests on two cut polytope instances (Figure 9) and on two spanning tree instances of different size (Figure 10).
",7.1.1 Offline Results,[0],[0]
"We observed a significant speedup of LCG compared to CG, due to the faster iteration of the lazy algorithm.
",7.1.1 Offline Results,[0],[0]
"Pairwise Conditional Gradient Algorithm As we inherit structural restrictions of PCG on the feasible region, the problem repertoire is limited in this case.",7.1.1 Offline Results,[0],[0]
"We tested the Pairwise Conditional Gradient algorithm on the structured regression problem with feasible regions from the MIPLIB instances eil33-2, air04, eilB101, nw04, disctom, m100n500k4r1 (Figures 11, 12 and 13).
21
Again similarly to the vanilla Frank-Wolfe algorihtm, we observed a significant improvement in wall-clock time of LPCG compared to CG, due to the faster iteration of the lazy algorithm.",7.1.1 Offline Results,[0],[0]
Additionally to the quadratic objective functions above we tested the online version on random linear functions,7.1.2 Online Results,[0],[0]
cx + b with c ∈,7.1.2 Online Results,[0],[0]
"[−1,+1]n and b ∈",7.1.2 Online Results,[0],[0]
"[0, 1].",7.1.2 Online Results,[0],[0]
"For online algorithms, each experiment used a random sequence of 100 different random loss functions.",7.1.2 Online Results,[0],[0]
"In every figure the left column uses linear loss functions, while the right one uses quadratic loss functions over the same polytope.",7.1.2 Online Results,[0],[0]
"As customary, we did not use line search here but used the respective prescribed step sizes.
",7.1.2 Online Results,[0],[0]
"As an instance of the structured regression problem we used the flow-based formulation for Hamiltonian cycles in graphs, i.e., the traveling salesman problem (TSP) for graphs with 11 and 16 nodes (Figures 14 and 15).",7.1.2 Online Results,[0],[0]
"For these small instances, the oracle problem can be solved in reasonable time.",7.1.2 Online Results,[0],[0]
Another instance of the structured regression problem uses the standard formulation of the cut polytope for graphs with 23 and 28 nodes as the feasible region (Figures 16 and 17).,7.1.2 Online Results,[0],[0]
"We also tested our algorithm on are the quadratic unconstrained boolean optimization (QUBO) instances defined on Chimera graphs [Dash, 2013], which are available athttp://researcher.watson.ibm.com/researcher/files/us-sanjeebd/chimera-data.zip.",7.1.2 Online Results,[0],[0]
The instances are relatively hard albeit their rather small size and in general the problem is NP-hard.,7.1.2 Online Results,[0],[0]
"(Figure 18 and 19).
",7.1.2 Online Results,[0],[0]
One instance of the video colocalization problem uses a path polytope fromhttp://lime.cs.elte.hu/~kpeter/data/mcf/netgen/ that was generated with the netgen graph generator (Figure 20).,7.1.2 Online Results,[0],[0]
"Most of these instances are very large-scale minimum cost flow instances with several tens of thousands nodes in the underlying graphs, therefore solving still takes considerable time despite the problem being in P. We tested on the structured regression problems with the MIPLIB",7.1.2 Online Results,[0],[0]
"[Achterberg et al., 2006, Koch et al., 2011]) instances eil33-2 (Figure 21) and air04 (Figure 22) as feasible regions.",7.1.2 Online Results,[0],[0]
"Finally, for the spanning tree problem, we used the well-known extended formulation with O(n3) inequalities for an n-node graph.",7.1.2 Online Results,[0],[0]
"We considered graphs with 10 and 25 nodes (Figures 23 and 24).
",7.1.2 Online Results,[0],[0]
"We observed that similarly to the offline case while OCG and LOCG converge comparably in the number of iterations, the lazy LOCG performed significantly more iterations; for hard problems, where linear optimization is costly and convergence requires a large number of iterations, this led LOCG converging much faster in wall-clock time.",7.1.2 Online Results,[0],[0]
In extreme cases OCG could not complete even a single iteration.,7.1.2 Online Results,[0],[0]
"This is due to LOCG only requiring some good enough solution, whereas OCG requires a stronger guarantee.",7.1.2 Online Results,[0],[0]
This is reflected in faster oracle calls for LOCG.,7.1.2 Online Results,[0],[0]
"As mentioned before, lazy algorithms have two improvements: caching and early termination.",7.2.1 Effect of caching,[0],[0]
"Here we depict the effect of caching in Figure 25, comparing OCG (no caching, no early termination), LOCG (caching and early termination) and LOCG (only early termination) (see Algorithm 8).",7.2.1 Effect of caching,[0],[0]
"We did not include a caching-only OCG variant, because caching without early termination does not make much sense: in each iteration a new linear optimization problem has to be solved; previous solutions can hardly be reused as they are unlikely to be optimal for the new linear optimization problem.
22",7.2.1 Effect of caching,[0],[0]
"If the parameter K of the oracle can be chosen, which depends on the actual oracle implementation, then we can increase K to bias the algorithm towards performing more positive calls.",7.2.2 Effect of K,[0],[0]
At the same time the steps get shorter.,7.2.2 Effect of K,[0],[0]
As such there is a natural trade-off between the cost of many positive calls vs. a negative call.,7.2.2 Effect of K,[0],[0]
We depict the impact of the parameter choice for K in Figure 30.,7.2.2 Effect of K,[0],[0]
"For illustrative purposes, we compare the textbook variant of the lazy conditional gradient (Algorithm 3) with its parameter-free counterpart (Algorithm 7) in Figure 31.",7.2.3 Paramter-free vs. textbook variant,[0],[0]
"The parameter-free variant outperforms the textbook variant due to the active management of Φ combined with line search.
",7.2.3 Paramter-free vs. textbook variant,[0],[0]
Similar parameter-free variants can be derived for the other algorithms; see discussion in Section 4.,7.2.3 Paramter-free vs. textbook variant,[0],[0]
"If a given baseline algorithm works over general compact convex sets P, then so does the lazified version.",8 Final Remarks,[0],[0]
"In fact, as the lazified algorithm runs, it produces a polyhedral approximation of the set P with very few vertices (subject to optimality vs. sparsity tradeoffs; see [Jaggi, 2013, Appendix C]).
",8 Final Remarks,[0],[0]
"Moreover, the weak separation oracle does not need to return extreme points.",8 Final Remarks,[0],[0]
"All algorithms also work with maximal solutions that are not necessarily extremal (e.g., lying in a higher-dimensional face).",8 Final Remarks,[0],[0]
"However, in that case we lose the desirable property that the final solution is a sparse convex combination of extreme points (typically vertices in the polyhedral setup).
",8 Final Remarks,[0],[0]
We would also like to briefly address potential downsides of our approach.,8 Final Remarks,[0],[0]
"In fact, we believe the right perspective is the following: when using the lazy oracle over the LP oracle, we obtain potentially weaker approximations vt − xt of the true gradient ∇ f (xt ) compared to solving the actual LP, but the computation might be much faster.",8 Final Remarks,[0],[0]
This is the tradeoff that one has to consider: working with weaker approximations (which implies potentially less progress per iteration) vs. potentially significantly faster computation of the approximations.,8 Final Remarks,[0],[0]
"If solving the LP is expensive than lazification will be usually very beneficial, if the LP is very cheap as in the case of P =",8 Final Remarks,[0],[0]
"[0, 1]n or P = ∆n being the probability simplex, then lazification might be slower.
",8 Final Remarks,[0],[0]
"A related remark in this context is that once the lazified algorithm has obtained vertices x1, . . .",8 Final Remarks,[0],[0]
", xm of P, so that the minimizer x∗ of f satisfies x∗ ∈ conv{x1, . . .",8 Final Remarks,[0],[0]
", xm}, then from that point onwards no actual calls to the true LP oracle have to be performed anymore for primal progress and the algorithm will only use cache calls; the only remaining true LP calls are at most a logarithmic number for dual progress updates of the Φt .",8 Final Remarks,[0],[0]
"We are indebted to Alexandre D’Aspremont,Simon Lacoste-Julien, and George Lan for the helpful discussions and for providing us with relevant references.",Acknowledgements,[0],[0]
"Research reported in this paper was partially supported by NSF CAREER award CMMI-1452463.
23",Acknowledgements,[0],[0]
Conditional gradient algorithms (also often called Frank-Wolfe algorithms) are popular due to their simplicity of only requiring a linear optimization oracle and more recently they also gained significant traction for online learning.,abstractText,[0],[0]
"While simple in principle, in many cases the actual implementation of the linear optimization oracle is costly.",abstractText,[0],[0]
"We show a general method to lazify various conditional gradient algorithms, which in actual computations leads to several orders of magnitude of speedup in wall-clock time.",abstractText,[0],[0]
"This is achieved by using a faster separation oracle instead of a linear optimization oracle, relying only on few linear optimization oracle calls.",abstractText,[0],[0]
Lazifying Conditional Gradient Algorithms,title,[0],[0]
"For computational problems of major practical interest (satisfiability, planning, etc.)",1. Introduction,[0],[0]
the computing science community has developed a large number of highly configurable “solvers.”,1. Introduction,[0],[0]
"The reason is that while the hardest problem instances take a long time to solve by any of the solvers, the instances that one encounters in practical applications may exhibit specific properties so that the appropriate solver
1DeepMind, London, UK.",1. Introduction,[0],[0]
"2On leave from Imperial College London, London, UK.",1. Introduction,[0],[0]
"3On leave from University of Alberta, Edmonton, AB, Canada.",1. Introduction,[0],[0]
"Correspondence to: Gellért Weisz <gellert@google.com>, András",1. Introduction,[0],[0]
"György <agyorgy@google.com>, Csaba Szepesvári <szepi@google.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
with an appropriate configuration may finish much faster.",1. Introduction,[0],[0]
"The plethora of solvers and their configurations, which for simplicity of presentation we will just treat as configurations from this point on, is explained by the diversity of applications.",1. Introduction,[0],[0]
"Which configuration to use in a specific application can then be treated as a learning problem, where an application is identified with an unknown distribution over problem instances that one can sample from, the learning algorithm can run any configuration on any sampled instance until a timeout of its choice, and the goal is to find a configuration with nearly optimal expected runtime while using the least amount of time during the search.1 There has been much practical success on designing such blackbox configuration search methods, especially in the context of satisfiability problems.",1. Introduction,[0],[0]
"Examples of successful methods include ParamILS (Hutter, 2007; Hutter et al., 2009), SMAC (Hutter et al., 2011; 2013), irace (Birattari et al., 2002; López-Ibánez et al., 2011), and GGA (Ansótegui et al., 2009; 2015).",1. Introduction,[0],[0]
"These methods themselves rely on many heuristics and as such lack theoretical guarantees.
",1. Introduction,[0],[0]
"Recently, Kleinberg et al. (2017) explored this problem, presenting a general-purpose configuration optimizer called Structured Procrastination, with guarantees on both (i) how close to the optimal configuration the algorithm’s result is, and (ii) how long it takes to find such a configuration.",1. Introduction,[0],[0]
"For (ii), Kleinberg et al. (2017) prove that the expected runtime of their algorithm is within a logarithmic factor of the optimal runtime in a worst-case sense.",1. Introduction,[0],[0]
"Furthermore, they show that the gap between worst-case runtimes of existing algorithms (SMAC, ROAR, ParamILS, GGA, irace) and their solution can be arbitrarily large.",1. Introduction,[0],[0]
"Structured Procrastination attempts to refine the runtime guarantee for the empirically fastest solver and solves tasks in increasing order of difficulty, postponing difficult tasks until all simpler tasks have been solved.",1. Introduction,[0],[0]
"The main novelty of their work is that it comes with theoretical guarantees (lower and upper bounds on the runtime), but no empirical illustration is provided.
",1. Introduction,[0],[0]
"This paper builds on the results of Kleinberg et al. (2017), and our problem statement closely follows theirs.",1. Introduction,[0],[0]
"Our
1Related, but different problems are considered, e.g., by Luby et al. (1993); Adam (2001); Mnih et al. (2008); Audibert & Bubeck (2010); György & Kocsis (2011); Li et al. (2016).
",1. Introduction,[0],[0]
"main technical contributions are as follows: We present an (arguably simpler) algorithm (LEAPSANDBOUNDS) that finds an approximately optimal configuration with a worstcase runtime bound that improves upon that of Kleinberg et al. (2017), while we consider a broader class of problems (we don not need their global runtime cap).",1. Introduction,[0],[0]
We also present instance-dependent runtime bounds that show that LEAPSANDBOUNDS finishes faster if the runtime of the configurations over different problem instances has small variance.,1. Introduction,[0],[0]
Experiments were carried out to assess practical performance of both Structured Procrastination and LEAPSANDBOUNDS on configuring the open-source minisat solver.,1. Introduction,[0],[0]
"LEAPSANDBOUNDS runs every configuration for less time than Structured Procrastination, and returns significantly faster.",1. Introduction,[0],[0]
"Finally, to facilitate further research and enable direct comparison to our results, our large-scale measurements on running times of the minisat solver are published together with the paper.2
The rest of the paper is organized as follows:",1. Introduction,[0],[0]
The problem is introduced formally in Section 2.,1. Introduction,[0],[0]
"For clarity, the most basic version of our algorithm is presented first in Section 3, and its performance is analyzed in Section 4.",1. Introduction,[0],[0]
"Improvements to our method, together with their analyses, are presented in Section 5.",1. Introduction,[0],[0]
"Experimental results are presented in Section 6, followed by some notes on parallel implementation in Section 7.",1. Introduction,[0],[0]
"Finally, conclusions are drawn in Section 8.",1. Introduction,[0],[0]
"Following Kleinberg et al. (2017), the algorithm configuration problem is defined by a tuple (N ,Γ, R, κ0) as follows:3 Here, N is a family of configurations and Γ is a distribution over input instances.4 For now, we consider the case when N is a finite set.",2. Problem Statement,[0],[0]
"If we have a benchmark set of instances, we let Γ be the uniform distribution over these benchmark instances.",2. Problem Statement,[0],[0]
"For configuration i ∈ N and instance j, R(i, j) ∈",2. Problem Statement,[0],[0]
"[0,∞] is the execution time of configuration",2. Problem Statement,[0],[0]
"i on instance j. Finally, κ0 > 0 is the minimum runtime:",2. Problem Statement,[0],[0]
"For all i, j pairs, R(i, j) ≥ κ0.
",2. Problem Statement,[0],[0]
We let R(i) = EJ∼Γ,2. Problem Statement,[0],[0]
"[R(i, J)] denote the average runtime of configuration i on instances distributed according to Γ, and define OPT = miniR(i) as the mean runtime of an optimal configuration.",2. Problem Statement,[0],[0]
"Our goal is to find such an optimal, or at least nearly optimal configuration while spending as little time as possible–proportional to the runtime of the optimal configuration–on this task.",2. Problem Statement,[0],[0]
"For this, a search algorithm can (i) sample instances J at random from Γ; (ii) enumerate
2https://github.com/deepmind/ leaps-and-bounds
3Compared to their problem statement, we removed the global runtime cap from the definition as it is not required for our results.
",2. Problem Statement,[0],[0]
"4For randomized solvers, input instances can mean (input instance, random seed) pairs.
",2. Problem Statement,[0],[0]
"the configurations in N ; (iii) run a configuration i on an instance j until it finishes, or the execution time exceeds a fixed timeout τ",2. Problem Statement,[0],[0]
"≥ 0, chosen by the search algorithm.",2. Problem Statement,[0],[0]
"Practically, this means observing R(i, j, τ) .=",2. Problem Statement,[0],[0]
"min(R(i, j), τ) after time R(i, j, τ), and also whether the calculation has finished with a solution or it timed out.
",2. Problem Statement,[0],[0]
"The main difficulty in organizing the search is that some configurations may take a long, or even infinite time to execute on some instances.",2. Problem Statement,[0],[0]
"Since an algorithm that claims to find a near-optimal configuration must verify that no other configuration can finish significantly faster than the chosen configuration, the total runtime is at least proportional to n×OPT, where n = |N",2. Problem Statement,[0],[0]
| is the number of configurations to be tested.,2. Problem Statement,[0],[0]
"Since knowing the mean runtime up to a multiplicative accuracy of (1 + ε) requires Ω(1/ε2) samples even when the runtime distributions are light-tailed, relaxing the requirement to find a configuration i with runtime R(i) ≤ (1 + ε)OPT, we get that the total runtime is at least Ω(n × OPT/ε2).",2. Problem Statement,[0],[0]
"The situation worsens for heavy-tailed runtime distributions: If the runtime of an algorithm is b > 1 with probability 1/b and 0 otherwise, with b unknown, all sampling methods need to see at least one positive runtime to estimate the expected runtime up to any fixed accuracy.",2. Problem Statement,[0],[0]
"Thus, any sampling method needs to use at least Ω(b) time, despite that the expected runtime is constant 1 (independently of b).",2. Problem Statement,[0],[0]
"This implies that in the face of heavy-tailed runtime distributions, the runtime of any sound configuration search algorithm would be unbounded in the worst-case, regardless the value of OPT, n and ε.",2. Problem Statement,[0],[0]
"Since heavy tailed runtime distributions are quite common in practice, rather than constraining the problem by ruling these out, following Kleinberg et al. (2017), we relax the search criterion to that of finding an (ε, δ)-optimal configuration.",2. Problem Statement,[0],[0]
Introducing the τ -capped version of R(i) as Rτ (i) =,2. Problem Statement,[0],[0]
EJ∼Γ,2. Problem Statement,[0],[0]
"[R(i, J, τ)], we have the following definition for (ε, δ)-optimality:
Definition 1 ((ε, δ)-optimality).",2. Problem Statement,[0],[0]
"A configuration i∗ is (ε, δ)optimal if there exists some threshold τ such that Rτ (i∗) ≤ (1 + ε)OPT, and PrJ∼Γ (R(i∗, J) > τ) ≤ δ.",2. Problem Statement,[0],[0]
"Otherwise, we say i∗ is (ε, δ)-suboptimal.
",2. Problem Statement,[0],[0]
"In words, given (ε, δ), a sound configuration search algorithm must find a configuration i whose τ -capped mean runtime is at most (1 + ε)OPT, with a τ larger than the δquantile of the runtime distribution of configuration i.",2. Problem Statement,[0],[0]
"This is a reasonable criterion when OPT is reasonably small.5
In this paper we introduce the algorithm LEAPSANDBOUNDS that identifies an (ε, δ)-optimal configuration with
5If some problem instances are hopelessly hard, the expected runtime of even an optimal configuration can be infinite, in which case any configuration becomes (ε, δ)-optimal.",2. Problem Statement,[0],[0]
"To alleviate this problem, it would be more meaningful to define (ε, δ)-optimality with respect to the optimal capped runtime; this is left for future work (see Section 8 for more details).
",2. Problem Statement,[0],[0]
probability 1,2. Problem Statement,[0],[0]
− ζ for a failure parameter ζ,2. Problem Statement,[0],[0]
and has an expected runtime of O ( OPT nε2δ log ( n log OPT ζ )) .,2. Problem Statement,[0],[0]
The method of Kleinberg et al. (2017) has an additional assumption that all runtimes of any configuration on any instance sampled from Γ are below a maximum κ̄ that must also be known by the algorithm.,2. Problem Statement,[0],[0]
"While this renders the runtime distributions light-tailed, a nice feature of their method is that its runtime O ( OPT nε2δ log ( n log κ̄ ζδε2 )) has only a mild dependence on κ̄. LEAPSANDBOUNDS does not require a runtime cap and we shave off a few terms from their bound: We replace the doubly logarithmic dependence on κ̄ with an identical dependence on the practically much smaller OPT, and remove logarithmic terms that depend on δ−1 and ε−2.",2. Problem Statement,[0],[0]
"Kleinberg et al. (2017) also prove that the minimum worstcase runtime for any algorithm is Ω ( OPT nε2δ ) , so both methods are within a logarithmic factor of the optimum.
",2. Problem Statement,[0],[0]
The above results make sense when n = |N,2. Problem Statement,[0],[0]
| is small enough to allow running each algorithm configuration.,2. Problem Statement,[0],[0]
"Similarly to Kleinberg et al. (2017), LEAPSANDBOUNDS can be extended to the case of an arbitrarily large number of configurations: by sampling n configurations randomly from the set of all configurations, the probability that none of the fastest γ fraction of configurations have been sampled is at most Ce−nγ for a universal constant C > 0.",2. Problem Statement,[0],[0]
"Thus, by letting n = ⌈ 1 γ log(C/ζ) ⌉ , with probability 1− 2ζ, LEAPSANDBOUNDS returns an (ε, δ)-optimal configuration with respect to a configuration from the fastest γ fraction of configurations from the entire space.",2. Problem Statement,[0],[0]
The main problem in finding a near-optimal solver configuration is that solving some instances may take arbitrarily long.,3. Algorithm,[0],[0]
"To alleviate the problem, (ε, δ)-optimality only considers the mean of runtimes capped at a timeout, ensuring that at most a δ fraction of the worst instances run longer than this timeout.",3. Algorithm,[0],[0]
This makes estimating the average runtime of a configuration (over random instances) possible through sampling.,3. Algorithm,[0],[0]
The main issue with sampling is that computing the average runtime over the samples can be slowed down arbitrarily if we accidentally select a problem instance with a very large running time.,3. Algorithm,[0],[0]
"This could be avoided if an oracle told us the runtime threshold τ in the definition of (ε, δ)optimality, but this is not available of course.",3. Algorithm,[0],[0]
"To solve the problem, we present a configuration optimization algorithm called LEAPSANDBOUNDS (Algorithm 1).
",3. Algorithm,[0],[0]
"LEAPSANDBOUNDS attempts to guess a rough value of OPT, starting from a low value.",3. Algorithm,[0],[0]
"Calling its guess θ, the algorithm then tries to find a configuration with a mean runtime less than θ.",3. Algorithm,[0],[0]
"If this succeeds, it returns the configuration with the smallest mean found.",3. Algorithm,[0],[0]
"Otherwise, θ is doubled and a new phase is started.",3. Algorithm,[0],[0]
"The simplest way of measuring
Algorithm 1 LEAPSANDBOUNDS 1: Inputs:
Set N of n algorithm configurations Precision parameter ε ∈ (0, 13 )",3. Algorithm,[0],[0]
"Quantile parameter δ ∈ (0, 1)",3. Algorithm,[0],[0]
"Failure probability parameter ζ ∈ (0, 1) Lower runtime bound κ0 > 0",3. Algorithm,[0],[0]
"Instance distribution Γ
2: Initialize: θ ← 167 κ0, k ← 0, J ← empty list 3: while True do 4: k ← k + 1 .",3. Algorithm,[0],[0]
"phase count 5: b← ⌈ 44 log ( 6nk(k+1)
ζ
)",3. Algorithm,[0],[0]
"1 δε2 ⌉ . instance bound
6: Add b− |J",3. Algorithm,[0],[0]
| new instances sampled from Γ to J 7: for i ∈ N,3. Algorithm,[0],[0]
"do 8: Q̄i ←RUNTIMEEST (i,J , δ, θ) 9: end for
10:",3. Algorithm,[0],[0]
"if mini Q̄i < θ then 11: return argmini Q̄i 12: end if 13: θ ← 2θ 14: end while
the mean runtime while guaranteeing (ε, δ)-optimality is to take runtime samples with timeout θδ and reject any algorithm that times out for any instance.",3. Algorithm,[0],[0]
"Then, a concentration bound on the measurements could be used to ensure that the mean is close to the empirical mean.",3. Algorithm,[0],[0]
"If the mean is less than θ, Markov’s inequality can be used to bound the tail probability for (ε, δ)-optimality.",3. Algorithm,[0],[0]
"However, by rejecting any configuration that ever times out, we fail to measure the capped mean–which could be significantly lower–, and thus the algorithm may not stop at the right time.",3. Algorithm,[0],[0]
"To fix this, we would ideally allow a δ fraction of runs to time out, but we use 34δ instead, to achieve a high-confidence tail bound with a Chernoff bound (replacing Markov’s inequality).",3. Algorithm,[0],[0]
"Still, the measurements could take a long time: if we perform b measurements for a reliable mean estimation with timeout τ , then we spend up to bτ time.",3. Algorithm,[0],[0]
"A key observation is that if we spend more than bθ time on measurements, the average would have to be above θ, and we would reject the configuration.",3. Algorithm,[0],[0]
"Thus, we can specify an overall time budget of T = bθ, and reject any configuration early if they run over this limit.",3. Algorithm,[0],[0]
These ideas are embodied in our algorithm (RUNTIMEEST).,3. Algorithm,[0],[0]
In this section we explore the theoretical properties of LEAPSANDBOUNDS.,4. Theoretical Analysis,[0],[0]
We show that the estimates computed by the algorithm are reliable with high probability.,4. Theoretical Analysis,[0],[0]
"Then we prove that if the estimates are reliable, the running time cannot be too large and the algorithm returns an (ε, δ)-optimal
Algorithm 2",4. Theoretical Analysis,[0],[0]
"The RUNTIMEEST subroutine 1: Inputs:
Configuration i Instance list J = (J1, . . .",4. Theoretical Analysis,[0],[0]
", Jb) of length b Quantile parameter δ ∈",4. Theoretical Analysis,[0],[0]
"(0, 1) Average runtime bound θ
2: Initialize: T ← bθ .",4. Theoretical Analysis,[0],[0]
overall runtime budget τ,4. Theoretical Analysis,[0],[0]
← 4θ3δ .,4. Theoretical Analysis,[0],[0]
"individual runtime budget j ← 1 . instance index 3: while True do 4: Run configuration i on Jj with timeout min{T, τ} 5: Qj ← R(i, Jj ,min{T, τ}) 6: T ← T −Qj 7: // Stopping rules: 8: if T = 0 then .",4. Theoretical Analysis,[0],[0]
Stop if overall budget zero 9: return θ 10: else if j = b then .,4. Theoretical Analysis,[0],[0]
Stop after b = |J,4. Theoretical Analysis,[0],[0]
| samples 11: return Q̄ = 1/b ∑b m=1Qm .,4. Theoretical Analysis,[0],[0]
"Return mean 12: end if 13: j ← j + 1 14: end while
solution.",4. Theoretical Analysis,[0],[0]
"We start with a few important observations about RUNTIMEEST.
4.1.",4. Theoretical Analysis,[0],[0]
"Guarantees for algorithm RUNTIMEEST
Consider the execution of RUNTIMEEST with the inputs (i,J , θ, b).",4. Theoretical Analysis,[0],[0]
"Noting that the loop is stopped if the budget T0 = bθ gets exhausted, it follows that the total runtime of the (optimized) algorithm is bounded by bθ:
Lemma 2.",4. Theoretical Analysis,[0],[0]
"The runtime of one call to RUNTIMEEST is O(bθ).
",4. Theoretical Analysis,[0],[0]
"With T0 = bθ, for j ≥ 1, define Tj = Tj−1 − Qj = bθ",4. Theoretical Analysis,[0],[0]
− (Q1 + · · · + Qj).,4. Theoretical Analysis,[0],[0]
"If the budget bθ is not exhausted (i.e., Tb = bθ",4. Theoretical Analysis,[0],[0]
"− (Q1 + · · · + Qb) > 0), each instance Jj runs within its min{Tj−1, τ} ≤ τ individual budget, and so Qj = R(i, Jj) = R(i, Jj , τ) =:",4. Theoretical Analysis,[0],[0]
Rj .,4. Theoretical Analysis,[0],[0]
"Clearly, Tb > 0 is equivalent to Q̄ < θ.",4. Theoretical Analysis,[0],[0]
"Furthermore, in any case, Qj = R(i, Jj ,min(Tj−1, τ)) ≤",4. Theoretical Analysis,[0],[0]
Rj .,4. Theoretical Analysis,[0],[0]
"Defining R̄ = (R1 + · · · + Rb)/b, we can summarize these findings as follows:
Lemma 3.",4. Theoretical Analysis,[0],[0]
"If RUNTIMEEST returns with Q̄<θ, then ∀j,Qj=Rj and Q̄=R̄. Otherwise, ∀j,Qj≤Rj and Q̄≤R̄.
Let us now turn to analyzing Algorithm 1.",4. Theoretical Analysis,[0],[0]
"For this, we need some extra notation.",4. Theoretical Analysis,[0],[0]
"Let θk, τk and bk denote the respective values of θ, τ and b in phase k",4.2. Notation,[0],[0]
(,4.2. Notation,[0],[0]
"Line 6 of Algorithm 1), noting that τk = 4θk3δ .",4.2. Notation,[0],[0]
"Let Jj denote the jth instance (ever) sampled in Line 6 of
Algorithm 1.",4.2. Notation,[0],[0]
"Note that for k large enough so that bk ≥ j, Jj is the jth instance that is passed on to RUNTIMEEST by Algorithm 1 in phase k (for any configuration i).",4.2. Notation,[0],[0]
"Let Ri,j,k = R(i, Jj , τk) be the τk-capped runtime of configuration i on instance Jj and let R̄i,k be the average of these values: R̄i,k = 1bk ∑bk",4.2. Notation,[0],[0]
"j=1Ri,j,k. Similarly, let Q̄i,k be the return value of algorithm RUNTIMEEST in phase k for configuration i, which is also the mean of (Qi,j,k)j , the runtimes observed at Line 5 of RUNTIMEEST.",4.2. Notation,[0],[0]
"Let σ̂2i,k be the empirical variance of (Ri,j,k)j : σ̂2i,k = 1 bk ∑bk j=1(Ri,j,k − R̄i,k)2.",4.2. Notation,[0],[0]
"Let pi,k = PrJ∼Γ (R(i, J) > τk) denote the probability that configuration i does not finish on instance j in time τk.",4.3. Good events,[0],[0]
Next we define two events that ensure that the algorithm works well.,4.3. Good events,[0],[0]
"First, let
E1,i,k = {Q̄i,k = θk} ∪ {pi,k ≤ δ};
if E1,i,k holds then if Algorithm 1 returns, the probability that the corresponding configuration fails to solve a random task within τk time is small (note that Q̄i,k ≤ θk).
",4.3. Good events,[0],[0]
"The next event guarantees that the average capped running time is close to its expectation: let
E2,i,k = {|R̄i,k −Rτk(i)| ≤ Ci,k} with
Ci,k = σ̂i,k
√ 2 log(6nk(k+1)ζ )
bk +
3τk log( 6nk(k+1)
ζ )
bk .
",4.3. Good events,[0],[0]
"The main result of this section is to show that E1,i,k and E2,i,k hold with high probability for all i and k simultaneously:
Lemma 4.",4.3. Good events,[0],[0]
"Let E = ⋂ i∈{1,...,n},k∈Z+ (E1,i,k ∩ E2,i,k).",4.3. Good events,[0],[0]
"Then, Pr(E) ≥ 1− ζ.
",4.3. Good events,[0],[0]
"To prove the lemma, we individually bound the probabilities that the events do not hold:
Lemma 5.",4.3. Good events,[0],[0]
"Pr(Ec1,i,k) ≤",4.3. Good events,[0],[0]
"ζ 2nk(k+1) .
",4.3. Good events,[0],[0]
Proof.,4.3. Good events,[0],[0]
"If pi,k ≤ δ, then Pr(Ec1,i,k) = 0 and the statement holds trivially.",4.3. Good events,[0],[0]
"For the rest of this proof, we assume that pi,k > δ.",4.3. Good events,[0],[0]
"From the algorithm, we have that bk ≥ 32δ log( 2nk(k+1) ζ ).",4.3. Good events,[0],[0]
"Define Bi,j,k as the Bernoulli random variable indicating whether configuration i on input Jj takes more time than τk to finish (value 1), or not (value 0).",4.3. Good events,[0],[0]
"For δ̂i,k = 1bk ∑bk",4.3. Good events,[0],[0]
"j=1Bi,j,k, observe that E(δ̂i,k) = pi,k.",4.3. Good events,[0],[0]
"If the algorithm returns with Q̄i,k < θ, as necessary for event Ec1,i,k, then R̄i,k = Q̄i,k according to Lemma 3.",4.3. Good events,[0],[0]
"Noting that Bi,j,k =",4.3. Good events,[0],[0]
I,4.3. Good events,[0],[0]
"[Ri,j ≥ τk], we have 4θ3δ ∑ j Bi,j,k ≤ ∑",4.3. Good events,[0],[0]
"j Ri,j (since τk = 4θ3δ ).",4.3. Good events,[0],[0]
"Therefore, 4θ 3δ δ̂i,k ≤ R̄i,k = Q̄i,k < θ, so δ̂i,k ≤ 34δ.
",4.3. Good events,[0],[0]
"Applying a Chernoff bound on the bk independent Bernoulli random variables Bi,j,k, the probability of the latter event can be bounded, giving
Pr(Ec1,i,k) =",4.3. Good events,[0],[0]
"Pr(Q̄i,k < θ) ≤",4.3. Good events,[0],[0]
"Pr ( δ̂i,k ≤ 3
4 δ ) ≤",4.3. Good events,[0],[0]
"Pr ( δ̂i,k ≤ 3
4 E(δ̂i,k)
) ≤ exp ( −E(δ̂i,k)bk
32
)
< exp ( − 1
32 δbk
) ≤ ζ
2nk(k + 1) ,
where the second and second to last inequalities follow from E(δ̂i,k)",4.3. Good events,[0],[0]
"> δ.
",4.3. Good events,[0],[0]
Lemma 6.,4.3. Good events,[0],[0]
"Pr(Ec2,i,k) ≤ ζ 2nk(k+1) .
",4.3. Good events,[0],[0]
Proof.,4.3. Good events,[0],[0]
"The samples (Ri,j,k)j are independent and identically distributed with mean R̄i,k and expectation Rτk(i).",4.3. Good events,[0],[0]
"Thus, the lemma holds by the empirical Bernstein bound (cf.",4.3. Good events,[0],[0]
"Audibert et al., 2009, Theorem 1 and Appendix A).
",4.3. Good events,[0],[0]
Now Lemma 4 follows from Lemmas 5 and 6 and the union bound (details are given in Appendix B).,4.3. Good events,[0],[0]
"Note that when the algorithm finishes, Q̄i,k = R̄i,",4.4. Bounding the average runtime,[0],[0]
"k. Hence, in this section we focus on R̄i,k and its deviation from its mean.",4.4. Bounding the average runtime,[0],[0]
"In particular, we show that |Rτk(i) − R̄i,k| ≤ 3 7εRτk(i) holds on event E when phase k is preterm.",4.4. Bounding the average runtime,[0],[0]
"Here, a phase k is called preterm if miniRτk(i) ≥ 716θk.",4.4. Bounding the average runtime,[0],[0]
The idea is that if a phase is preterm then the best capped expected runtime is large compared to the guess on the optimal runtime.,4.4. Bounding the average runtime,[0],[0]
"We then show that on E, any phase executed by the algorithm is preterm.
",4.4. Bounding the average runtime,[0],[0]
"Since on E, |Rτk(i) − R̄i,k| ≤ Ci,k by the definition of E, we need to bound Ci,k.",4.4. Bounding the average runtime,[0],[0]
"We start with a bound on the empirical variance σ̂2i,k. Lemma 7.",4.4. Bounding the average runtime,[0],[0]
"For any preterm phase k, σ̂2i,k ≤ 3221δ (R̄i,k + Rτk(i)) 2.
",4.4. Bounding the average runtime,[0],[0]
Proof.,4.4. Bounding the average runtime,[0],[0]
"First we show that for any c > 0, σ̂2i,k ≤ c ( R̄i,k +
τk 2c
)2 .",4.4. Bounding the average runtime,[0],[0]
"(1)
Notice that σ̂2i,k = 1 bk ∑bk j=1(Ri,j,k − R̄i,k)2 ≤
1 bk ∑bk",4.4. Bounding the average runtime,[0],[0]
j=1R 2,4.4. Bounding the average runtime,[0],[0]
"i,j,k ≤ 1bk ∑bk",4.4. Bounding the average runtime,[0],[0]
j=1 τk,4.4. Bounding the average runtime,[0],[0]
"Ri,j,k = τk R̄i,k because R̄i,k ≤ τk by definition.",4.4. Bounding the average runtime,[0],[0]
"Now (1) follows from the obvious R̄i,kτk ≤ c",4.4. Bounding the average runtime,[0],[0]
"( R̄i,k + τk 2c )2 .
",4.4. Bounding the average runtime,[0],[0]
"By the assumption on k, θk ≤ 167 Rτk(i).",4.4. Bounding the average runtime,[0],[0]
"Since τk = 4θk 3δ , this means that τk ≤ 64 21δRτk(i).",4.4. Bounding the average runtime,[0],[0]
"Thus, applying (1) with c = 3221δ completes the proof as σ̂ 2 i,k ≤
32 21δ ( R̄i,k + 21δ 64 τk )2 ≤ 3221δ",4.4. Bounding the average runtime,[0],[0]
"(R̄i,k +Rτk(i))2.
",4.4. Bounding the average runtime,[0],[0]
"Combining the above result with the upper bound τk = 4θk 3δ ≤ 64 21δRτk(i), which holds for any preterm phase k, simple algebra yields the following bound on Ci,k (the full proof is given in Appendix C):6
Lemma 8.",4.4. Bounding the average runtime,[0],[0]
"For any preterm phase k, it holds that Ci,k ≤ ε 3 (R̄i,k +Rτk(i)).
",4.4. Bounding the average runtime,[0],[0]
"Now we give the promised bound on |Rτk(i)− R̄i,k|.",4.4. Bounding the average runtime,[0],[0]
Lemma 9.,4.4. Bounding the average runtime,[0],[0]
"Assume E holds and Ci,k ≤ ε3 (R̄i,k +Rτk(i)).",4.4. Bounding the average runtime,[0],[0]
"Then, |Rτk(i)− R̄i,k| ≤ 37εRτk(i) for all configurations i.
Proof.",4.4. Bounding the average runtime,[0],[0]
"Let us define x such that R̄i,k = (1 + x)Rτk(i).",4.4. Bounding the average runtime,[0],[0]
"Because E2,i,k holds, |x|Rτk(i) = |Rτk(i)− R̄i,k| ≤ Ci,k ≤ ε 3 (R̄i,k +Rτk(i))",4.4. Bounding the average runtime,[0],[0]
=,4.4. Bounding the average runtime,[0],[0]
ε 3 (1 + 2x)Rτk(i).,4.4. Bounding the average runtime,[0],[0]
So |x| ≤ ε 3 (1 + 2x).,4.4. Bounding the average runtime,[0],[0]
"If x < 0, then x ≥ − ε/31+2ε/3 >",4.4. Bounding the average runtime,[0],[0]
− 3 7ε.,4.4. Bounding the average runtime,[0],[0]
"If x ≥ 0, then x ≤ ε/31−2ε/3 ≤ 3 7ε because ε ≤ 1 3 .
",4.4. Bounding the average runtime,[0],[0]
"In the analysis of the correctness and the running time of the algorithm, we only need the slightly weaker corollary of Lemma 8 and Lemma 9 (which also holds for another variant of our algorithm, as opposed to Lemma 8):
Corollary 10.",4.4. Bounding the average runtime,[0],[0]
Assume E holds and phase k is preterm.,4.4. Bounding the average runtime,[0],[0]
"Then, for each i, if R̄i,k < θk, then |Rτk(i) − R̄i,k| ≤ 3 7εRτk(i); otherwise, if R̄i,k≥θk, then θk< (1+ 3 7ε)Rτk(i).",4.4. Bounding the average runtime,[0],[0]
"In this section we show that Algortihm 1 returns an (ε, δ)optimal configuration, and give an upper bound on its running time.",4.5. Correctness and runtime,[0],[0]
"First we show the following result promised earlier:
Lemma 11.",4.5. Correctness and runtime,[0],[0]
"If E holds then every phase k executed is preterm.
",4.5. Correctness and runtime,[0],[0]
Proof.,4.5. Correctness and runtime,[0],[0]
The first phase is preterm as 716θ1 = κ0 ≤ Rτ1(i).,4.5. Correctness and runtime,[0],[0]
"For a phase k ≥ 2 that is executed, since the algorithm did not return in phase k",4.5. Correctness and runtime,[0],[0]
"− 1, by Lemma 3, R̄i,k−1 ≥ Q̄i,k−1 = θk−1.",4.5. Correctness and runtime,[0],[0]
If E holds and phase k,4.5. Correctness and runtime,[0],[0]
"− 1 was preterm, by Corollary 10, θk−1 < (1 + 37ε)Rτk−1(i).",4.5. Correctness and runtime,[0],[0]
"Moreover,
7 16θk = 7 8θk−1 ≤ 7 8 (1+ 3 7ε)Rτk−1(i) ≤ Rτk−1(i) ≤ Rτk(i),
since ε ≤ 13 .",4.5. Correctness and runtime,[0],[0]
"By induction, any phase executed is preterm.
",4.5. Correctness and runtime,[0],[0]
Lemma 12.,4.5. Correctness and runtime,[0],[0]
"If E holds and Algorithm 1 returns with a configuration I in phase K, then I is (ε, δ)-optimal.
Proof.",4.5. Correctness and runtime,[0],[0]
We prove the statement by contradiction.,4.5. Correctness and runtime,[0],[0]
"Thus, assume I is (ε, δ)-suboptimal.",4.5. Correctness and runtime,[0],[0]
"At stopping, Q̄I,K < θK , hence on E, pI,K = PrJ∼Γ(R(I, J) > τK) ≤ δ must hold.
6The multiplicative constant in the proof is not optimized carefully to promote simplicity.",4.5. Correctness and runtime,[0],[0]
"Nevertheless, in our experiments the empirical effect of this constant is negligible.
",4.5. Correctness and runtime,[0],[0]
"Since I is (ε, δ)-suboptimal, it follows that there exists an instance j such thatRτK (I) >",4.5. Correctness and runtime,[0],[0]
(1+ε)R(j) >,4.5. Correctness and runtime,[0],[0]
(1+ε)RτK (j).,4.5. Correctness and runtime,[0],[0]
"Take such an index j. Since Algorithm 1 returned I instead of j, Q̄I,K ≤ Q̄j,K .",4.5. Correctness and runtime,[0],[0]
"By Lemma 3, θk > Q̄I,K = R̄I,K and R̄j,K ≥ Q̄j,K .",4.5. Correctness and runtime,[0],[0]
"Applying Corollary 10 and Lemma 11, if R̄j,K < θk, then (1+ 37ε)RτK (j) ≥ R̄j,K ≥ Q̄j,K ≥ Q̄I,K .",4.5. Correctness and runtime,[0],[0]
"Otherwise, (1 + 37ε)Rτk(i) ≥ θk ≥ Q̄I,K .",4.5. Correctness and runtime,[0],[0]
"Using this,
RτK (j)(1 + 3 7ε) ≥",4.5. Correctness and runtime,[0],[0]
"Q̄I,K = R̄I,K > RτK (I)(1− 3 7ε)
>",4.5. Correctness and runtime,[0],[0]
"RτK (j)(1 + ε)(1− 37ε).
",4.5. Correctness and runtime,[0],[0]
"Therefore, 1 + 37ε >",4.5. Correctness and runtime,[0],[0]
"(1 + ε)(1 − 3 7ε) which leads to a contradiction since ε ≤ 13 .
",4.5. Correctness and runtime,[0],[0]
Theorem 13.,4.5. Correctness and runtime,[0],[0]
"Algorithm 1 identifies an (ε, δ)-optimal solution in time",4.5. Correctness and runtime,[0],[0]
O ( OPT nε2δ log( n log OPT ζ ) ),4.5. Correctness and runtime,[0],[0]
"with probability at least 1− ζ, where OPT = miniR(i).
",4.5. Correctness and runtime,[0],[0]
Proof.,4.5. Correctness and runtime,[0],[0]
"By Lemma 4, E holds with probability at least 1− ζ .",4.5. Correctness and runtime,[0],[0]
"The rest of the proof assumes that E holds.
",4.5. Correctness and runtime,[0],[0]
Let i∗ = argminiR(i).,4.5. Correctness and runtime,[0],[0]
"If θk ≥ (1 + 37ε)OPT ≥ (1 + 3 7ε)Rτk(i
∗), then only the first case of Corollary 10 can hold.",4.5. Correctness and runtime,[0],[0]
"Together with Lemma 11, we have that Q̄i∗,k ≤ R̄i∗,k ≤ (1 + 37ε)Rτk(i
∗) ≤ θk, so Algorithm 1 terminates for θk ≥ (1 + 37ε)OPT.",4.5. Correctness and runtime,[0],[0]
"Let the total number of phases of the outer loop of Algorithm 1 be L. Then L = O(log OPT).
",4.5. Correctness and runtime,[0],[0]
The for loop on Line 7 of Algorithm 1 adds a factor of n to the runtime.,4.5. Correctness and runtime,[0],[0]
"By Lemma 2, calling algorithm RUNTIMEEST on Line 8 adds a factor of bkθk to the runtime.",4.5. Correctness and runtime,[0],[0]
Now bk ≤ ⌈,4.5. Correctness and runtime,[0],[0]
"( 44 log(6nL(L+1)ζ ) 1 δε2 )⌉ =
O (
1 ε2δ log( 6n log2 OPT ζ )
)",4.5. Correctness and runtime,[0],[0]
"= O ( 1 ε2δ log( 6n log OPT ζ ) ) , so
substituting θk = 167 κ02 k, the total runtime becomes
O  ⌈ log2 ( (1+ 37 ε) OPT κ0 )⌉∑ k=1 κ02 k · n ε2δ log ( 6n log OPT ζ ) =",4.5. Correctness and runtime,[0],[0]
"O ( OPT n
ε2δ log
( n log OPT
ζ
)) .
",4.5. Correctness and runtime,[0],[0]
"By Lemma 12, when the algorithm returns, it returns with an (ε, δ)-optimal configuration.
5.",4.5. Correctness and runtime,[0],[0]
Optimizing RUNTIMEEST,4.5. Correctness and runtime,[0],[0]
"Our runtime analysis presented in the previous section used a worst-case upper bound for σ̂i,k.",4.5. Correctness and runtime,[0],[0]
Some instances may allow faster runtimes if we modify RUNTIMEEST to stop earlier in scenarios where the empirical variance is lower than this worst case bound.,4.5. Correctness and runtime,[0],[0]
"To do this, building on the approach of Mnih et al. (2008), we change the stopping rules of algorithm RUNTIMEEST and add two more rules as
Algorithm 3 Stopping rules 1: Q̄← 1j ∑j m=1Qm
2: σ̂2 ← 1j ∑j m=1",4.5. Correctness and runtime,[0],[0]
( Qm − Q̄ ),4.5. Correctness and runtime,[0],[0]
"2 3: dj,k ← 4nk(k + 1)j(j + 1)/ζ 4: c←",4.5. Correctness and runtime,[0],[0]
"√ σ̂2
2 log(3dj,k) j + 3τ log(3dj,k) j
5: LB← Q̄− c 6: if T = 0 then .",4.5. Correctness and runtime,[0],[0]
Stop if overall budget zero 7: return θ 8: end if 9: if j = b then .,4.5. Correctness and runtime,[0],[0]
Stop after b = |J,4.5. Correctness and runtime,[0],[0]
"| samples
10: return Q̄ .",4.5. Correctness and runtime,[0],[0]
Return mean of Q 11: end if 12: if (1 + 37ε)LB ≥ θ and Q̄ > θ then .,4.5. Correctness and runtime,[0],[0]
"LB too large 13: return θ 14: end if 15: if j ≥ ⌈ 32 δ log dj,k ⌉ and c ≤ ε3 ( Q̄+ LB ) then 16: return Q̄ .",4.5. Correctness and runtime,[0],[0]
"Return mean of Q 17: end if
given in Algorithm 3.",4.5. Correctness and runtime,[0],[0]
"The code shown here should replace Lines 8–12 of RUNTIMEEST.
",4.5. Correctness and runtime,[0],[0]
We outline a proof sketch that this algorithm is still correct and has the same runtime bound.,4.5. Correctness and runtime,[0],[0]
"We define the running averages in iteration j of RUNTIMEEST as Q̄i,j,k and R̄i,j,k.",4.5. Correctness and runtime,[0],[0]
"As before, we define an event, as a union of other events, that guarantees that the empirical estimates behave well.",4.5. Correctness and runtime,[0],[0]
"We keep the previously defined events E1,i,k and E2,i,k; note that E1,i,k corresponds to the estimate Q̄i,b,k.",4.5. Correctness and runtime,[0],[0]
"However, we need a similar event to E1,i,k for all iterations j: E′i,j,k = {Q̄i,k ≥ θk} ∪ {pi,k ≤ δ} ∪ {j < ⌈ 32 δ log dj,k ⌉ }.
",4.5. Correctness and runtime,[0],[0]
"Let E = ⋂ i∈{1,...,n},j,k∈Z+ ( E1,i,k ∩ E2,i,k ∩ E′i,j,k ) .",4.5. Correctness and runtime,[0],[0]
"Similarly to the previous section, it is easy to show that Pr(E) ≥ 1 − 3ζ/2.",4.5. Correctness and runtime,[0],[0]
"If E holds and the algorithm returns with an average runtime less than θk, then E1,i,k and E′i,j,k guarantee that Pr(R(i, j) > τk) ≤ δ",4.5. Correctness and runtime,[0],[0]
(independently of which stopping condition was activated).,4.5. Correctness and runtime,[0],[0]
"Since the original stopping rule is still in place, the runtime of algorithm RUNTIMEEST with the additional stopping rules is still O(bkθk).",4.5. Correctness and runtime,[0],[0]
"Similarly, it is easy to verify that Lemma 3 still holds.
",4.5. Correctness and runtime,[0],[0]
"Furthermore, by a slight modification of Theorem 2 of Mnih (2008), one can show that with probability at least 1− ζ/2, |Rτk(i) − R̄i,j,k| ≤ ci,j,k holds for all i, j, k, and ci,j,k ≤ ε 3 ( Q̄i,j,k + LBi,j,k ) ≤ ε3 ( R̄i,j,k +Rτk(i) )",4.5. Correctness and runtime,[0],[0]
holds7,4.5. Correctness and runtime,[0],[0]
"for all
j ≥ C·max
( σ2i,k
ε2R2τk(i) , τk εRτk(i)
)( log 1
ζ ′",4.5. Correctness and runtime,[0],[0]
"+ log
1
εRτk(i)
)",4.5. Correctness and runtime,[0],[0]
",
whereC is a universal constant, and Q̄i,j,k ≤ R̄i,j,k. Denote 7Here, Lemma 3 was used additionally in the last inequality.
",4.5. Correctness and runtime,[0],[0]
"this event by E′; then Pr(E′) ≥ 1− ζ/2.8
Applying Lemma 9, E′ also implies that
|Rτk(i)− R̄i,j,k| ≤ 37εRτk(i).
",4.5. Correctness and runtime,[0],[0]
"Thus, if E ∪ E′ holds, then Corollary 10 holds: if Algorithm 3 returns either because it went through all the bk samples or because of Line 12, then |Rτk(i) − R̄i,k| ≤ 3 7εRτk(i), which implies the first part of the corollary; otherwise Algorithm 3 returns in line 10, implying that the algorithm returns with θk and (1 + 37ε)Rτk > θk.",4.5. Correctness and runtime,[0],[0]
"Then the runtime bound and the correctness guarantee of Theorem 13 follows as before.
",4.5. Correctness and runtime,[0],[0]
"On the other hand, if the variances of the runtimes over instances are low enough, it is possible to prove an improved runtime bound for the whole algorithm.",4.5. Correctness and runtime,[0],[0]
For ζ ′,4.5. Correctness and runtime,[0],[0]
"= ζ4nk(k+1) , there exists a constant C such that if
j ≥ C · 1δ ( log 1δ + log 1 ζ′ ) , then j ≥ ⌈ 32 δ log dj,k ⌉ holds.",4.5. Correctness and runtime,[0],[0]
"Together with the previous lower bound on j and by upper bounding τk ≤ 6421δRτk(i), by the definition of a preterm phase (see Lemma 8), with probability at least 1− 2ζ , RUNTIMEEST evaluates at most
C·max
( σ2i,k
ε2R2τk(i) ,
1
εδ ,
1 δ log 1 δ
)( log 1
ζ ′",4.5. Correctness and runtime,[0],[0]
"+ log
1
εRτk(i) )",4.5. Correctness and runtime,[0],[0]
samples in any phase k for configuration i before the stopping conditions on Line 15 are be satisfied.,4.5. Correctness and runtime,[0],[0]
"This bound is usually much lower than the previous bk =⌈ 44 log ( 6nk(k+1)
ζ
)",4.5. Correctness and runtime,[0],[0]
"1 δε2 ⌉ : if the variance of runtimes is
sufficiently low, this scales as ε−1 rather than ε−2 (the δ−1 log δ−1 term is negligible).
",4.5. Correctness and runtime,[0],[0]
"Mnih et al. (2008) also describe EBGStop, a slightly improved version of empirical Bernstein stopping, which applies Bernstein inequalities to bound the means of an exponentially increasing number of samples.",4.5. Correctness and runtime,[0],[0]
This allows us to effectively replace log,4.5. Correctness and runtime,[0],[0]
1εRτk (i) with log log,4.5. Correctness and runtime,[0],[0]
1εRτk (i) in the bound presented above.,4.5. Correctness and runtime,[0],[0]
We use this version of the algorithm in our experiments.,4.5. Correctness and runtime,[0],[0]
"For completeness, the pseudocode of this version is given in Appendix D.",4.5. Correctness and runtime,[0],[0]
"To run experiments, we gathered a benchmark set of runtimes of different configurations on generated SAT problems.",6. Experiments,[0],[0]
We used minisat9,6. Experiments,[0],[0]
"(Sorensson & Een, 2005)",6. Experiments,[0],[0]
as the SAT solver.,6. Experiments,[0],[0]
"The SAT problems were generated using CNFuzzDD,10 of which only those 20118 were kept that
8The original event behind E′ guarantees, via Bernstein’s inequality, that the estimates for the means and variances are accurate enough.
",6. Experiments,[0],[0]
9We used version 2013/09/25.,6. Experiments,[0],[0]
http://minisat.se/,6. Experiments,[0],[0]
"10http://fmv.jku.at/cnfuzzdd/
took at least about a second to solve for minisat with the default parameters.",6. Experiments,[0],[0]
This was done so that the data reflects what happens when instances are nontrivial to solve.,6. Experiments,[0],[0]
"972 different configurations were tested for minisat, which are described in Appendix E. The solver minisat was run with each configuration and instance combination.",6. Experiments,[0],[0]
"The unit of computation, κ0, is one second of CPU time, and the experiments were ran with a timeout of 15 CPU minutes.11 To get a sense of this data, the capped mean runtimes",6. Experiments,[0],[0]
Rτ (i) for each configuration are shown in Fig. 1 in a sorted order.,6. Experiments,[0],[0]
"Here, the timeout τ was set separately for each configuration so that the tail probability PrJ∼Γ(R(i, J) > τ) was approximately δ; the running times are shown for different values of δ (δ = 0 corresponds to the mean runtimes).",6. Experiments,[0],[0]
"From this, we can see a large difference between configurations.",6. Experiments,[0],[0]
"For a particularly “fast” configuration, Fig. 2 shows the distribution of runtimes on different instances.",6. Experiments,[0],[0]
"Note that because of the global time limit for executions, the final bucket includes runs that may take arbitrarily long.
",6. Experiments,[0],[0]
"The benchmark set of runtimes is used to quickly simulate runs of Structured Procrastination and LEAPSANDBOUNDS, as follows.",6. Experiments,[0],[0]
"A simulated environment acts as an oracle,
11Our measurements have been scaled such that the unit of computation roughly corresponds to a second on commodity hardware as of 2018 rather than our machines.",6. Experiments,[0],[0]
"In this unit, about 83 CPU years were spent in total to generate this data.
returning precomputed values of R(i, j, τ) when queried, accumulating the total time the algorithm under test would have run for.
",6. Experiments,[0],[0]
Both LEAPSANDBOUNDS and Structured Procrastination often run the same configuration on the same instance with an increased time limit.,6. Experiments,[0],[0]
"Thus, both algorithms can benefit largely when the environment allows pausing and resuming of executions.",6. Experiments,[0],[0]
"This can be implemented either by saving the state of the execution when the actual runtime limit is reached, or by reloading the state from automatically saved checkpoints.",6. Experiments,[0],[0]
"However, resuming execution comes with an additional memory requirement, and may not always be feasible or preferable to restarts.",6. Experiments,[0],[0]
"Thus, we report our experiments for both cases.
",6. Experiments,[0],[0]
"After each phase, in Line 13 of LEAPSANDBOUNDS, we double θ.",6. Experiments,[0],[0]
"In fact, this multiplier is arbitrary, and changing it only affects the worst-case runtime up to a constant factor.",6. Experiments,[0],[0]
"In practice, a smaller multiplier, making smaller steps in θ, typically overshoots the best average runtime less, thereby decreasing the total runtime for environments that allow resuming runs.",6. Experiments,[0],[0]
"On the other hand, a smaller multiplier leads to more phases, introducing more overheads in resuming jobs and increasing the total runtime if resuming is not allowed by rerunning portions of jobs more frequently.",6. Experiments,[0],[0]
"The value of the multiplier can be optimized by taking these effects into account, e.g., by measuring the overheads related to switching and resuming jobs.",6. Experiments,[0],[0]
"For simplicity, and since this information is not included in our benchmark dataset, in the experiments below the value of the multiplier was set to 1.25 (see Appendix F for more details).
",6. Experiments,[0],[0]
"We simulated LEAPSANDBOUNDS and Structured Procrastination on our benchmark dataset with parameters ε = 0.2, δ = 0.2, and ζ = 0.1.",6. Experiments,[0],[0]
Fig. 3 shows that LEAPSANDBOUNDS runs every configuration for a significantly shorter amount of time than Structured Procrastination.,6. Experiments,[0],[0]
"The configurations are sorted in the same order as in Fig. 1, for δ = 0.2.",6. Experiments,[0],[0]
"Paradoxically, both algorithms run the faster configurations significantly longer.",6. Experiments,[0],[0]
"This is because both algorithms quickly
reject slow configurations, whereas they both run fast configurations many more times to ensure (ε, δ)-optimality.",6. Experiments,[0],[0]
"In total, LEAPSANDBOUNDS runs for 933.50 CPU days in the environment that does not support resuming execution, and 368.50 days in one that does.",6. Experiments,[0],[0]
"The corresponding runtime measurements for Structured Procrastination are 1850.46 and 1169.36, respectively.",6. Experiments,[0],[0]
"Both algorithms return with configuration 898, which has the best average runtime below a δ = 0.2 quantile, out of all configurations.",6. Experiments,[0],[0]
One benefit of the simplicity of LEAPSANDBOUNDS is that it is embarrassingly parallel.,7. Parallelization,[0],[0]
This is due to the fact that there is little dependency between the runtime measurements that need to be carried out.,7. Parallelization,[0],[0]
"In phase k, when θk = 167 κ02 k, runs
of the form R ( i, j, κ02 k+6
21δ
) are carried out.",7. Parallelization,[0],[0]
"The core of
our argument is that this parallelizes over i, j, and k, but there are three further considerations.",7. Parallelization,[0],[0]
"First, to implement the overall runtime bound of RUNTIMEEST, for any fixed i and k, the runs of R ( i, j, κ02 k+6
21δ
) should be terminated
once the summed running times of these reach the overall budget bkθk.",7. Parallelization,[0],[0]
This could be implemented either via interprocess communication or by starting these runs at once on p processors and terminating them after bkθk/p time.,7. Parallelization,[0],[0]
"Second, a new phase k of Algorithm 1 should only be started once Q̄i,k is available for all i ∈ N .",7. Parallelization,[0],[0]
"Thus, runs should be started in increasing order of k, for each i. Third, the optional empirical Bernstein stopping, as described in Section 5, adds a dependency between runs of different j. This could be resolved either by not parallelizing over j, or by running only a small number of parallel runs over j and checking the stopping conditions after they finish.",7. Parallelization,[0],[0]
"We have introduced an algorithm applying empirical Bernstein stopping with the goal of finding approximately optimal configurations, and provided guarantees for its worstcase runtime as well as correctness.",8. Conclusions and Future Work,[0],[0]
"Our runtime guarantee is tighter than that of Structured Procrastination, which, to our knowledge, is the only other method solving this problem.",8. Conclusions and Future Work,[0],[0]
"Empirical evaluations suggest that LEAPSANDBOUNDS outperforms Structured Procrastination in realistic, non-adversarial scenarios too, which depends crucially on leveraging the gap between worst-case and realistic scenarios by using empirical Bernstein stopping.
",8. Conclusions and Future Work,[0],[0]
"The optimality of the configuration returned by LEAPSANDBOUNDS is, in fact, with respect to configurations with timeout τK for the final phase K. An important direction of future work is to get guarantees with respect to the best configuration for the fastest (1− δ′)-proportion of instances for any δ′ < δ.",8. Conclusions and Future Work,[0],[0]
We consider the problem of configuring generalpurpose solvers to run efficiently on problem instances drawn from an unknown distribution.,abstractText,[0],[0]
"The goal of the configurator is to find a configuration that runs fast on average on most instances, and do so with the least amount of total work.",abstractText,[0],[0]
It can run a chosen solver on a random instance until the solver finishes or a timeout is reached.,abstractText,[0],[0]
"We propose LEAPSANDBOUNDS, an algorithm that tests configurations on randomly selected problem instances for longer and longer time.",abstractText,[0],[0]
"We prove that the capped expected runtime of the configuration returned by LEAPSANDBOUNDS is close to the optimal expected runtime, while our algorithm’s running time is near-optimal.",abstractText,[0],[0]
"Our results show that LEAPSANDBOUNDS is more efficient than the recent algorithm of Kleinberg et al. (2017), which, to our knowledge, is the only other algorithm configuration method with non-trivial theoretical guarantees.",abstractText,[0],[0]
Experimental results on configuring a public SAT solver on a new benchmark dataset also stand witness to the superiority of our method.,abstractText,[0],[0]
LEAPSANDBOUNDS: A Method for Approximately Optimal Algorithm Configuration,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2377–2382, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"Most of the world’s languages are dying out and have little recorded data or linguistic documentation (Austin and Sallabank, 2011).",1 Introduction,[0],[0]
It is important to adequately document languages while they are alive so that they may be investigated in the future.,1 Introduction,[0],[0]
Language documentation traditionally involves one-onone elicitation of speech from native speakers in order to produce lexicons and grammars that describe the language.,1 Introduction,[0],[0]
"However, this does not scale: linguists must first transcribe the speech phonemically as most of these languages have no standardized orthography.",1 Introduction,[0],[0]
"This is a critical bottleneck since it takes a trained linguist about 1 hour to transcribe the phonemes of 1 minute of speech (Do et al., 2014).
",1 Introduction,[0],[0]
"Smartphone apps for rapid collection of bilingual data have been increasingly investigated (De Vries et al., 2011; De Vries et al., 2014; Reiman, 2010; Bird et al., 2014; Blachon et al., 2016).",1 Introduction,[0],[0]
"It is common for these apps to collect speech segments paired with spoken translations in another language, making spoken translations quicker to obtain than phonemic transcriptions.
",1 Introduction,[0],[0]
"We present a method to improve automatic phoneme transcription by harnessing such bilingual data to learn a lexicon and translation model directly from source phoneme lattices and their written target translations, assuming that the target side is a major language that can be efficiently transcribed.1 A Bayesian non-parametric model expressed with a weighted finite-state transducer (WFST) framework represents the joint distribution of source acoustic features, phonemes and latent source words given the target words.",1 Introduction,[0],[0]
"Sampling of alignments is used to learn source words and their target translations, which are then used to improve transcription of the source audio they were learnt from.",1 Introduction,[0],[0]
"Importantly, the model assumes no prior lexicon or translation model.
",1 Introduction,[0],[0]
"This method builds on work on phoneme translation modeling (Besacier et al., 2006; Stüker et al., 2009; Stahlberg et al., 2012; Stahlberg et al., 2014; Adams et al., 2015; Duong et al., 2016), speech translation (Casacuberta et al., 2004; Matusov et al., 2005), computer-aided translation, (Brown et al., 1994; Vidal et al., 2006; Khadivi and Ney, 2008; Reddy and Rose, 2010; Pelemans et al., 2015), translation modeling from automatically transcribed
1Code is available at https://github.com/oadams/latticetm.
2377
speech (Paulik and Waibel, 2013), word segmentation and translation modeling (Chang et al., 2008; Dyer, 2009; Nguyen et al., 2010; Chen and Xu, 2015), Bayesian word alignment (Mermer et al., 2013; Zezhong et al., 2013) and language model learning from lattices (Neubig et al., 2012).",1 Introduction,[0],[0]
"While we previously explored learning a translation model from word lattices (Adams et al., 2016), in this paper we extend the model to perform unsupervised word segmentation over phoneme lattices in order to improve phoneme recognition.
",1 Introduction,[0],[0]
"Experiments demonstrate that our method significantly reduces the phoneme error rate (PER) of transcriptions compared with a baseline recogniser and a similar model that harnesses only monolingual information, by up to 17% and 5% respectively.",1 Introduction,[0],[0]
We also find that the model learns meaningful bilingual lexical items.,1 Introduction,[0],[0]
"Our model extends the standard automatic speech recognition (ASR) problem by seeking the best phoneme transcription φ̂ of an utterance in a joint probability distribution that incorporates acoustic features x, phonemes φ, latent source words f and observed target transcriptions e:
φ̂ = argmax φ,f
P (x|φ)P (φ|f)P (f |e) , (1)
assuming a Markov chain of conditional independence relationships (bold symbols denote utterances as opposed to tokens).",2 Model description,[0],[0]
"Deviating from standard ASR, we replace language model probabilities with those of a translation model, and search for phonemes instead of words.",2 Model description,[0],[0]
"Also, no lexicon or translation model are given in training.",2 Model description,[0],[0]
"We use a WFST framework to express the factors of (1) since it offers computational tractability and simple inference in a clear, modular framework.",2.1 Expression of the distribution using finite-state transducers,[0],[0]
"Figure 1 uses a toy German–English error resolution example to illustrate the components of the framework: a phoneme lattice representing phoneme uncertainty according to P (x|φ); a lexicon that transduces phoneme substrings φs of φ to source tokens f according to P (φs|f); and a lexical translation
model representing P (f |e) for each e in the written translation.",2.1 Expression of the distribution using finite-state transducers,[0],[0]
"The composition of these components is also shown at the bottom of Figure 1, illustrating how would-be transcription errors can be resolved.",2.1 Expression of the distribution using finite-state transducers,[0],[0]
This framework is reminiscent of the WFST framework used by Neubig et al. (2012) for lexicon and language model learning from monolingual data.,2.1 Expression of the distribution using finite-state transducers,[0],[0]
"Because we do not have knowledge of the source language, we must learn the lexicon and translation model from the phoneme lattices and their written translation.",2.2 Learning the lexicon and translation model,[0],[0]
We model lexical translation probabilities using a Dirichlet process.,2.2 Learning the lexicon and translation model,[0],[0]
Let A be both the transcription of each source utterance f and its word alignments to the translation e that generated them.,2.2 Learning the lexicon and translation model,[0],[0]
"The conditional posterior can be expressed as:
P (f |e;A) = cA(f, e) + αP0(f) cA(e)",2.2 Learning the lexicon and translation model,[0],[0]
+,2.2 Learning the lexicon and translation model,[0],[0]
"α , (2)
where cA(f, e) is a count of how many times f has aligned to e in A and cA(e) is a count of how many times e has been aligned to; P0 is a base distribution that influences how phonemes are clustered; and α determines the emphasis on the base distribution.
",2.2 Learning the lexicon and translation model,[0],[0]
"In order to express the Dirichlet process using the WFST components, we take the union of the lexicon with a spelling model base distribution that consumes phonemes φi . . .",2.2 Learning the lexicon and translation model,[0],[0]
φj and produces a special 〈unk〉 token with probability P0(φi . . .,2.2 Learning the lexicon and translation model,[0],[0]
φj).,2.2 Learning the lexicon and translation model,[0],[0]
"This 〈unk〉 token is consumed by a designated arc in the translation model WFST with probability αcA(e)+α , yielding a composed probability of αP0(f)cA(e)+α .",2.2 Learning the lexicon and translation model,[0],[0]
"Other arcs in the translation model express the probability cA(f,e) cA(e)+α
of entries already in the lexicon.",2.2 Learning the lexicon and translation model,[0],[0]
"The sum of these two probabilities equates to (2).
",2.2 Learning the lexicon and translation model,[0],[0]
"As for the spelling model P0, we consider three distributions and implement WFSTs to represent them: a geometric distribution, Geometric(γ), a Poisson distribution, Poisson(λ),2 and a ‘shifted’ geometric distribution, Shifted(α, γ).",2.2 Learning the lexicon and translation model,[0],[0]
The shifted geometric distribution mitigates a shortcoming of the geometric distribution whereby words of length 1 have the highest probability.,2.2 Learning the lexicon and translation model,[0],[0]
"It does so by having
2While the geometric distribution can be expressed recursively, we cap the number of states in the Poisson WFST to 100.
another parameter α that specifies the probability of a word of length 1, with the remaining probability mass distributed geometrically.",2.2 Learning the lexicon and translation model,[0],[0]
"All phonemes types are treated the same in these distributions, with uniform probability.",2.2 Learning the lexicon and translation model,[0],[0]
"In order to determine the translation model parameters as described above, we require the alignments A.",2.3 Inference,[0],[0]
"We sample these proportionally to their probability given the data and our prior, in effect integrating over all parameter configurations T :
P (A|X ;α, P0) = ∫
T P (A|X , T )P (T ;α, P0)dT ,
(3) where X is our dataset of source phoneme lattices paired with target sentences.
",2.3 Inference,[0],[0]
"This is achieved using blocked Gibbs sampling, with each utterance constituting one block.",2.3 Inference,[0],[0]
"To sample from WFSTs, we use forwardfiltering/backward-sampling (Scott, 2002; Neubig et al., 2012), creating forward probabilities using the forward algorithm for hidden Markov models before backward-sampling edges proportionally to the product of the forward probability and the edge weight.3
3No Metropolis-Hastings rejection step was used.",2.3 Inference,[0],[0]
"We evaluate the lexicon and translation model by their ability to improve phoneme recognition, measuring phoneme error rate (PER).",3 Experimental evaluation,[0],[0]
"We used less than 10 hours of English–Japanese data from the BTEC corpus (Takezawa et al., 2002), comprised of spoken utterances paired with textual translations.",3.1 Experimental setup,[0],[0]
This allows us to assess the approach assuming quality acoustic models.,3.1 Experimental setup,[0],[0]
We used acoustic models similar to Heck et al. (2015) to obtain source phoneme lattices.,3.1 Experimental setup,[0],[0]
"Gold phoneme transcriptions were obtained by transforming the text with pronunciation lexicons and, in the Japanese case, first segmenting the text into tokens using KyTea (Neubig et al., 2011).
",3.1 Experimental setup,[0],[0]
"We run experiments in both directions: English– Japanese and Japanese–English (en–ja and ja–en), while comparing against three settings: the ASR 1- best path uninformed by the model (ASR); a monolingual version of our model that is identical except without conditioning on the target side (Mono); and the model applied using the source language sentence as the target (Oracle).
",3.1 Experimental setup,[0],[0]
"We tuned on the first 1,000 utterences (about 1 hour) of speech and trained on up to 9 hours of the
remaining data.4",3.1 Experimental setup,[0],[0]
"Only the oracle setup was used for tuning, with Geometric(0.01)",3.1 Experimental setup,[0],[0]
"(taking the form of a vague prior), Shifted(10−5, 0.25) and Poisson(7) performing best.",3.1 Experimental setup,[0],[0]
Table 1 shows en–ja and ja–en results for all methods with the full training data.,3.2 Results and Discussion,[0],[0]
"Figure 2 shows improvements of ja–en over both the ASR baseline and the Mono method as the training data increases, with translation modeling gaining an increasing advantage with more training data.
",3.2 Results and Discussion,[0],[0]
"Notably, English recognition gains less from using Japanese as the target side (en–ja) than the other way around, while the ‘oracle’ approach for Japanese recognition, which also uses Japanese as the target, underperforms ja–en.",3.2 Results and Discussion,[0],[0]
"These observations suggest that using the Japanese target is less helpful, likely explained by the fine-grained morphological segmentation we used, making it harder for the model to relate source phonemes to target tokens.
",3.2 Results and Discussion,[0],[0]
The vague geometric prior significantly underperforms the other priors.,3.2 Results and Discussion,[0],[0]
"In the en–ja/vague case, the
4A 1 hour subset was used for PER evaluation.
model actually underperforms its monolingual counterpart.",3.2 Results and Discussion,[0],[0]
"The vague prior biases slightly towards finegrained English source segmentation, with words of length 1 most common.",3.2 Results and Discussion,[0],[0]
"In this case, fine-grained Japanese is also used as the target which results in most lexical entries arising from uninformative alignments between single English phonemes and Japanese syllables, such as [t]⇔す.",3.2 Results and Discussion,[0],[0]
"For similar reasons, the shifted geometric prior gains an advantage over Poisson, likely because of its ability to even further penalize single-phoneme lexical items, which regularly end up in all lexicons anyway due to their combinatorical advantage when sampling.
",3.2 Results and Discussion,[0],[0]
"While many bilingual lexical entries are correct, such as [w2n]⇔一 (‘one’), most are not.",3.2 Results and Discussion,[0],[0]
Some have segmentation errors,3.2 Results and Discussion,[0],[0]
"[li:z]⇔くださ (‘please’); some are correctly segmented but misaligned to commonly co-occurring words [w2t]⇔時 (‘what’ aligned to ‘time’); others do not constitute individual words, but",3.2 Results and Discussion,[0],[0]
morphemes aligned to common Japanese syllables,3.2 Results and Discussion,[0],[0]
[i:N]⇔く (‘-ing’); others still align multi-word units correctly,3.2 Results and Discussion,[0],[0]
[haUm2tS]⇔いく ら (‘how much’).,3.2 Results and Discussion,[0],[0]
Note though that entries such as those listed above capture information that may nevertheless help to reduce phoneme transcription errors.,3.2 Results and Discussion,[0],[0]
"We have demonstrated that a translation model and lexicon can be learnt directly from phoneme lattices in order to improve phoneme transcription of those very lattices.
",4 Conclusion and Future Work,[0],[0]
One of the appealing aspects of this modular framework is that there is much room for extension and improvement.,4 Conclusion and Future Work,[0],[0]
"For example, by using adaptor grammars to encourage syllable segmentation (Johnson, 2008), or incorporating language model probabilities in addition to our translation model probabilities (Neubig et al., 2012).
",4 Conclusion and Future Work,[0],[0]
We assume a good acoustic model with phoneme error rates between 20 and 25%.,4 Conclusion and Future Work,[0],[0]
"In a language documentation scenario, acoustic models for the lowresource source language won’t exist.",4 Conclusion and Future Work,[0],[0]
"Future work should use a universal phoneme recognizer or acoustic model of a similar language, thus making a step towards true generalizability.",4 Conclusion and Future Work,[0],[0]
We gratefully acknowledge support from the DARPA LORELEI program.,Acknowledgments,[0],[0]
Language documentation begins by gathering speech.,abstractText,[0],[0]
"Manual or automatic transcription at the word level is typically not possible because of the absence of an orthography or prior lexicon, and though manual phonemic transcription is possible, it is prohibitively slow.",abstractText,[0],[0]
"On the other hand, translations of the minority language into a major language are more easily acquired.",abstractText,[0],[0]
We propose a method to harness such translations to improve automatic phoneme recognition.,abstractText,[0],[0]
"The method assumes no prior lexicon or translation model, instead learning them from phoneme lattices and translations of the speech being transcribed.",abstractText,[0],[0]
Experiments demonstrate phoneme error rate improvements against two baselines and the model’s ability to learn useful bilingual lexical entries.,abstractText,[0],[0]
Learning a Lexicon and Translation Model from Phoneme Lattices,title,[0],[0]
In this paper we study the problem of learning a uniform mixture of two multinomial logistic models from data.,1. Introduction,[0],[0]
Our work is situated in the literature of discrete choice as follows.,1. Introduction,[0],[0]
"The most well-studied class of “rational” choice behavior is the class of Random Utility Models, introduced by Marschak (1960), and described below.",1. Introduction,[0],[0]
"Mixtures of multinomial logistic models have been widely used in discrete choice since 1980 (Boyd & Mellman, 1980; Cardell & Dunbar, 1980), and are of particular interest because they are known to -approximate any Random Utility Model (McFadden & Train, 2000).",1. Introduction,[0],[0]
"However, despite a long history of study and broad use in practice, there are
*Equal contribution 1Sapienza University, Rome, Italy 2Google, Mountain View, CA.",1. Introduction,[0],[0]
"Correspondence to: Flavio Chierichetti <flavio@di.uniroma1.it>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
no known polynomial-time algorithms to learn (exactly or approximately) any non-trivial mixture of multinomial logistic models.,1. Introduction,[0],[0]
We give the first such result: an algorithm to learn uniform mixtures of two multinomial logistic models.,1. Introduction,[0],[0]
"We now give a little more background.
",1. Introduction,[0],[0]
A multinomial logistic model (usually called an MNL) over a universe U of items provides a specific mapping from any non-empty subset S ⊆ U to a distribution over S. The model requires a weight function,1. Introduction,[0],[0]
w : U → R+ that gives a positive weight to each item in the universe.,1. Introduction,[0],[0]
"The model then assigns probability to each u ∈ S proportional to its weight: Pr[u | S] = w(u)/ ∑ v∈S w(v).
",1. Introduction,[0],[0]
"These models are frequently employed in the setting of discrete choice, in which a user must select exactly one item from a set of alternatives.",1. Introduction,[0],[0]
"If S ⊆ U gives the alternatives, the MNL then provides a distribution representing the likelihood that each item in S will be selected.",1. Introduction,[0],[0]
"Such models are employed in many settings: selection of a piece of music, a mode of transportation, a brand of toothpaste, and so forth.",1. Introduction,[0],[0]
We note in passing that the weight function may be generalized in many ways.,1. Introduction,[0],[0]
"Rather than mapping from u to w(u), it may instead be defined in terms of features of u (allowing easy generalization to unseen objects) or in terms of features of the particular situation (for instance depending on properties of the user making the choice).",1. Introduction,[0],[0]
"In our work we do not consider such generalizations; we assume that w simply maps an item to a positive real-valued weight.
",1. Introduction,[0],[0]
"Given sufficient examples of subsets S with resulting choices of a particular u ∈ S, it is possible to estimate the weight function w using maximum likelihood estimation.",1. Introduction,[0],[0]
The estimation is convex and is easily solved at large scale by gradient ascent methods.,1. Introduction,[0],[0]
"As a result, MNL is widely used in practice.",1. Introduction,[0],[0]
"Furthermore, in the context of the rapid changes underway in machine learning due to deep networks, it is the standard top layer of multiclass classification networks, where it goes by the name softmax layer.
",1. Introduction,[0],[0]
A problematic example.,1. Introduction,[0],[0]
"The definition of MNL posits a single fixed weight function, which imposes certain restrictions on the behavior of the model across related subsets.",1. Introduction,[0],[0]
"For example, consider a distribution of authors, each of whom wishes to submit a paper to a conference.",1. Introduction,[0],[0]
"The slate of available options is {ICML, CVPR}, and based on the distribution, 60% of authors work in vision, and submit
to CVPR.",1. Introduction,[0],[0]
"Now imagine that a new ML conference called ICLR is introduced, so the new universe is {ICML, ICLR, CVPR}.",1. Introduction,[0],[0]
"Here, we expect that—on each slate containing CVPR and at least another conference—CVPR will still be preferred by roughly 60% of the authors, and that—on each slate containing both ICML and ICLR—a random author will prefer ICML with roughly the same probability of preferring ICLR.",1. Introduction,[0],[0]
These two constraints are incompatible with an MNL.,1. Introduction,[0],[0]
"Indeed, in an MNL, for CVPR to win with probability 60% on the full slate, it must be that its weight is 60% of the total weight of the three conferences.",1. Introduction,[0],[0]
"Thus, for ICML and ICLR to be chosen with the same probability it must be that they have the same weight of 20%; but, if that is the case, then the slate {ICML, CVPR} will let CVPR win with probability 75%.",1. Introduction,[0],[0]
This is a direct consequence of the definition of MNL: any new alternative introduced to a slate of options must decrease the likelihood of every other option by the same fraction.,1. Introduction,[0],[0]
"As in the example, this may result in undesirable restrictions in model behavior.
",1. Introduction,[0],[0]
Mixture of MNLs.,1. Introduction,[0],[0]
"In the previous example, the issue is that theoreticians and vision researchers represent two distinct populations.",1. Introduction,[0],[0]
Modeling the union with a single MNL results in the problem described above.,1. Introduction,[0],[0]
"On the other hand, allowing a mixture of these two populations, each represented by a population-specific MNL, will result in the correct behavior: vision researchers will employ an MNL that selects CVPR no matter what ML conferences are available, while theoreticians will employ an MNL that selects from among whatever ML conferences are present.",1. Introduction,[0],[0]
"Introducing ICLR will now cause theoreticians to move from 100% ICML to some mixture of the two ML conferences, while all the vision researchers who used to submit to CVPR will continue to do so.",1. Introduction,[0],[0]
"The mixture of two MNLs is no longer bound by the restriction that a new item in the slate must “cannibalize” equally from all other items.
",1. Introduction,[0],[0]
"In fact, moving from a single MNL to a mixture of MNLs is surprisingly powerful, as we now describe.",1. Introduction,[0],[0]
"We introduced MNL as a particular function family mapping any S ⊂ U to a distribution over S, based on the specification of a weight function.",1. Introduction,[0],[0]
We may broaden the function family by removing the restriction that the likelihood of each item is always proportional to its fixed weight.,1. Introduction,[0],[0]
"The Random Utility Model mentioned above (Marschak, 1960) is defined, not by a weight function, but by a distribution over value vectors, where each value vector assigns a value to each item of U .",1. Introduction,[0],[0]
A user draws a value vector i.i.d.,1. Introduction,[0],[0]
"from the distribution, then behaves rationally by choosing the item of S with maximum value.",1. Introduction,[0],[0]
"The distribution over value vectors induces a distribution over any subset S. It is easy to show that any Random Utility Model may be approximated arbitrarily closely by a mixture of MNLs (McFadden & Train, 2000).",1. Introduction,[0],[0]
"Hence, the problem of learning mixtures of MNLs is equivalent to the problem of learning the large family of
Random Utility Models.
",1. Introduction,[0],[0]
"For this reason, mixtures of MNLs are commonly employed in discrete choice settings.",1. Introduction,[0],[0]
"Unfortunately, the model learning is performed using heuristic techniques with no guarantees of optimality.",1. Introduction,[0],[0]
"Other than degenerate mixtures of a single MNL, to our knowledge, there are no results (positive or negative) regarding optimal learning of mixtures of MNLs, despite these models being well-studied in expressive power and commonly employed by practitioners with numerous libraries available to perform learning by heuristic approaches.",1. Introduction,[0],[0]
"We take a first step towards remedying this situation by resolving positively the question of learning uniform mixtures of two MNLs.
",1. Introduction,[0],[0]
Our results.,1. Introduction,[0],[0]
"Let a, b : U → R+ be two weight functions.",1. Introduction,[0],[0]
"The uniform 2-MNL (a, b) assigns to item u in subset S ⊆ U the probability 12 · a(u)∑ v∈S a(v) + 12 · b(u)∑ v∈S b(v) .",1. Introduction,[0],[0]
"We show the following:
• Uniqueness: If |U| ≥ 3 and 2-MNLs (a, b) and (a′, b′) agree on every S ⊆ U satisfying |S| ≤ 3, then either a = a′, b = b′ or a′ = b, a = b′.",1. Introduction,[0],[0]
• Identifiability:,1. Introduction,[0],[0]
"There is an algorithm that learns any 2-MNL (a, b) in time O(|U|).
",1. Introduction,[0],[0]
The algorithm for identifiability builds on a reconstruction oracle derived from the uniqueness.,1. Introduction,[0],[0]
"This oracle, when presented with any slate of size at most 3, returns the distribution over items of the slate induced by the mixture.",1. Introduction,[0],[0]
In contrast we show that slates of size 2 alone are insufficient for reconstruction and hence the oracle is optimal in terms of the slate size.,1. Introduction,[0],[0]
"If the oracle can be queried adaptively, we show an algorithm that makes O(|U|) queries, which we show to be optimal.",1. Introduction,[0],[0]
"For the non-adaptive case, we show an algorithm that makes O(|U|2) queries, also optimal.
",1. Introduction,[0],[0]
"Establishing the uniqueness for slates of size at most 3, while seemingly a simple “finite” problem, turns out to be technically challenging.",1. Introduction,[0],[0]
"The underlying question involves studying the uniqueness of solution to a system of quartic multivariate polynomials, derived from the unknown parameters of the mixture model.",1. Introduction,[0],[0]
"Through a series of reductions and delicate case analyses, we obtain several structural properties of this polynomial system, which we use to prove uniqueness.",1. Introduction,[0],[0]
"The tools we develop for showing uniqueness could be of independent interest and might have applications in other algorithmic discrete choice settings.
",1. Introduction,[0],[0]
Roadmap.,1. Introduction,[0],[0]
In Section 2 we discuss related work and in Section 3 we introduce the notation.,1. Introduction,[0],[0]
"In Section 4, we prove lower bounds on the slate sizes that must be queried to allow reconstruction.",1. Introduction,[0],[0]
"In Section 5.1, we show lower bounds on the numbers of adaptive and non-adaptive queries for reconstruction and in Section 5.2 we show algorithms with matching query complexity.",1. Introduction,[0],[0]
"These algorithms are based
on the uniqueness result that we mentioned above, which we prove in Section 6.",1. Introduction,[0],[0]
"In the Supplementary Material we discuss relaxations of the sampling oracle (Section A), and k-MNLs with lower bounds for their reconstruction (Section B), and the missing proofs (Section C).",1. Introduction,[0],[0]
"Multinomial logit (MNL) was initially introduced in the context of two-item slates by Bradley & Terry (1952), and was then extended to its current form by Luce (1959).",2. Related Work,[0],[0]
"However, the idea behind the formulation may be traced back to the earlier work by Zermelo (1928) in scoring of chess players.",2. Related Work,[0],[0]
The extension from MNL to mixtures of MNL (also known as mixed logit) was developed in the choice literature jointly in 1980 by Boyd & Mellman (1980) and Cardell & Dunbar (1980).,2. Related Work,[0],[0]
"McFadden & Train (2000) show that mixed logit models are capable of approximating any random utility model, although the construction they apply may result in mixed logits of exponential size.",2. Related Work,[0],[0]
"Recently, Chierichetti et al. (2018) study choice models that are represented by distributions over permutations of the items in the universe; they show a series of lower bounds in that model.",2. Related Work,[0],[0]
"Train (2009) provides an overview of the body of motivations for studying mixtures of multinomial logits in the theory of discrete choice.
",2. Related Work,[0],[0]
"Learning of mixture models is well-studied in the machine learning community, dating back to early work of Pearson (1894) in a biological setting, studying the evolution of populations of crabs.",2. Related Work,[0],[0]
"Computational models for mixtures may be traced back to the classical k-means clustering algorithm (MacQueen, 1967), which represents data using a mixture of clusters, each represented by a centroid.",2. Related Work,[0],[0]
"More generally, the EM algorithm (Dempster et al., 1977) provides a heuristic to learn general forms of mixture models, with no guarantees on correctness or convergence rate.",2. Related Work,[0],[0]
"Much literature has appeared on the related problem of learning mixtures of Gaussians, under various separation assumptions; see for example the papers of Kalai et al. (2010); Moitra & Valiant (2010).
",2. Related Work,[0],[0]
"With respect to mixtures of MNLs, there are many works discussing heuristic approaches based on simulation (Train, 2009; Guevara & Ben-Akiva, 2013; Hurn et al., 2003; Ge, 2008).",2. Related Work,[0],[0]
"However, work in Computer Science is less common.",2. Related Work,[0],[0]
Rusmevichientong et al. (2014) study a problem of selecting products to offer in order to maximize revenue over users defined by a mixture of MNLs.,2. Related Work,[0],[0]
They show this problem is NP-hard even for mixtures of 2 MNLs.,2. Related Work,[0],[0]
"Blanchet et al. (2016) again study revenue optimization in a discrete choice setting, and present a Markov Chain-based solution that generalizes mixtures of MNLs.",2. Related Work,[0],[0]
"In fact, Oh & Shah (2014) characterizes the problem of learning a 2-MNL as “infeasible in general” given current techniques.
",2. Related Work,[0],[0]
"Recall that in our case, the oracle returns the distribution of choosing items in a given slate; as we show in Appendix A, this oracle can be well approximated from choice processes by sampling.",2. Related Work,[0],[0]
Some work on learning mixtures of MNLs assume an oracle more powerful and less realistic than ours.,2. Related Work,[0],[0]
"For instance, Oh & Shah (2014) study the problem of learning a k-MNL using an oracle that returns the relative ordering of a number of (disjoint and/or partially overlapping) pairs of objects, as sampled from the same (random) MNL.",2. Related Work,[0],[0]
"With this oracle, one can use some of the pairs to get clues about which of the k MNLs produced a given sample, and the remaining pairs to estimate the relative weights of their elements in that specific MNL.",2. Related Work,[0],[0]
Oh & Shah (2014) study the sample complexity of this problem in various pairsselecting random models.,2. Related Work,[0],[0]
Zhao et al. (2016) also study the problem of learning a k-MNL.,2. Related Work,[0],[0]
"They focus on the necessary and sufficient conditions for identifiability, but they assume that the oracle returns the probability of observing a particular permutation of the slate.",2. Related Work,[0],[0]
"This oracle is stronger than both the one in (Oh & Shah, 2014) and ours.",2. Related Work,[0],[0]
"Ammar et al. (2014) also study learning a k-MNL, but they introduce a requirement that the weights in each MNL be well-separated, with each weight larger than the previous by some multiplicative constant.
",2. Related Work,[0],[0]
"Other models that originated in machine learning and that have been the object of active theoretical investigation include LDA-like topic models, e.g., the work of Arora et al. (2012; 2013; 2016).",2. Related Work,[0],[0]
"The goal there is to approximate the topics supporting the model, given samples (i.e., documents) from the model’s distribution; note that the model cannot be queried.",2. Related Work,[0],[0]
"Another difference is that, in topic reconstruction models, the algorithm usually gets more than one sample from the unknown topic (i.e., more than one word per document) whereas, in our case the algorithm gets a single sample from the unknown MNL.",2. Related Work,[0],[0]
"Let [n] = {1, . . .",3. Preliminaries,[0],[0]
", n} be the universe of items.",3. Preliminaries,[0],[0]
A slate is any non-empty subset of [n].,3. Preliminaries,[0],[0]
"An s-slate is a slate of size s.
A multinomial logit (1-MNL, or simply, MNL) model is fully specified by a weight function a : [n] → R+, where R+ is the set of positive real numbers.",3. Preliminaries,[0],[0]
"In this choice model, given a slate T ⊆",3. Preliminaries,[0],[0]
"[n], the probability that the item i ∈ T is chosen is given by
DaT (i) =",3. Preliminaries,[0],[0]
"ai∑
j∈T aj ,
where for convenience we use ai to denote a(i).",3. Preliminaries,[0],[0]
We can think of DaT (i) as the probability that item i wins in the slate T .,3. Preliminaries,[0],[0]
"Clearly, without loss of generality, ∑n i=1 ai = 1.
",3. Preliminaries,[0],[0]
"A 2-MNL A = (a, b, µ) consists of weight functions a, b and a mixing weight µ ∈ (0, 1).",3. Preliminaries,[0],[0]
Given a slate T ⊆,3. Preliminaries,[0],[0]
"[n], A
first chooses the weight function a with probability µ and b with probability 1−µ, and then behaves as the MNL corresponding to the chosen weight function.",3. Preliminaries,[0],[0]
"We use DAT (i) to denote the probability that the mixture model A chooses i, given the slate T .",3. Preliminaries,[0],[0]
We drop the superscript when A is clear from the context.,3. Preliminaries,[0],[0]
"If µ = 1/2, we call the mixture a uniform 2-MNL and denote it using the notation (a, b).
",3. Preliminaries,[0],[0]
"The goal of the learning problem is to understand the precise conditions for identifiability and unique reconstruction of the parameters of the mixture model, i.e., the weight functions and the mixing weight.",3. Preliminaries,[0],[0]
"We assume an oracle access to A that, given a slate T and an item",3. Preliminaries,[0],[0]
"i, returns the value DAT (i), i.e., the probability i wins in the slate T .",3. Preliminaries,[0],[0]
The computational quantities of interest are then the number of queries to this oracle and the size of the slates queried.,3. Preliminaries,[0],[0]
In this section we present a flavor of the reconstruction problem by first considering the simple 1-MNL case.,4. Warmup,[0],[0]
"For the 1-MNL case, we observe that a linear number of 2- slate queries is sufficient to uniquely identify and learn the weight function.
",4. Warmup,[0],[0]
Observation 1.,4. Warmup,[0],[0]
"A 1-MNL can be reconstructed using (n− 1) 2-slate queries.
",4. Warmup,[0],[0]
Proof.,4. Warmup,[0],[0]
For each i ∈,4. Warmup,[0],[0]
"[n − 1], we query the MNL using the slate {i, n} to obtain
D{i,n}(n) = an
ai + an .
",4. Warmup,[0],[0]
"This, along with ∑n
i=1 ai = 1, yields a system of linear equations in ai whose solution yields the weight function a of the 1-MNL.
",4. Warmup,[0],[0]
"In contrast, we next show that reconstructing a 2-MNL requires queries to larger slates.",4. Warmup,[0],[0]
"Specifically, we first show that reconstructing uniform 2-MNLs needs at least 3-slate queries.
",4. Warmup,[0],[0]
Theorem 2.,4. Warmup,[0],[0]
"For each n ≥ 3, there exist a 1-MNL A and two uniform 2-MNLs A(1) and A(2), such that DAT = DA (1)
T = D A(2) T = 1/|T",4. Warmup,[0],[0]
"| for each T with |T | ≤ 2, but there
is a T with |T | = 3 such that DA(1)T 6=",4. Warmup,[0],[0]
"DA (2) T .
",4. Warmup,[0],[0]
Proof.,4. Warmup,[0],[0]
Note that each item in T has the same chance of winning.,4. Warmup,[0],[0]
"Therefore, the 1-MNL with a constant weight function a satisfies DaT (i) = 1/|T",4. Warmup,[0],[0]
"| for i ∈ T .
",4. Warmup,[0],[0]
"Given some real number t > 1, we define two uniform 2- MNLs A(1) =",4. Warmup,[0],[0]
"(a(1), b(1)),A(2) = (a(2), b(2)) such that DA (1)
T (i) = D A(2)",4. Warmup,[0],[0]
T (i) = 1/|T,4. Warmup,[0],[0]
"| for each |T | ≤ 2, and such
that there exists a 3-slate T such thatDA (1) T (i) 6=",4. Warmup,[0],[0]
"DA (2) T (i).
",4. Warmup,[0],[0]
"The weight functions are defined as:
• a(1)1 = a (1) 2 = t, b (1) 1 = b (1) 2 = 1/t, and a (1) i = b (1) i =
1 for each i ∈ {3, . . .",4. Warmup,[0],[0]
",",4. Warmup,[0],[0]
"n} and • a(2)1 = b (2) 2 = t, b (2) 1 = a (2) 2 = 1/t, and a (2) i = b (2) i =
1 for each i ∈ {3, . . .",4. Warmup,[0],[0]
", n}.
",4. Warmup,[0],[0]
We begin with the statement about 2-slates.,4. Warmup,[0],[0]
"Let T = {i, j}.",4. Warmup,[0],[0]
"If {i, j} ∩ {1, 2} = ∅, then both A(1) and A(2) clearly induce the uniform distribution on T .",4. Warmup,[0],[0]
"If T = {1, 2} then, since the mixture is uniform, the probability that 1 gets selected is 1/2 with A(1) and is 12 · t t+1/t",4. Warmup,[0],[0]
+ 1 2 · 1/t t+1/t = 1 2 with A(2).,4. Warmup,[0],[0]
"Finally, if T = {1, i} or T = {2, i}, for some i ∈ {3, . . .",4. Warmup,[0],[0]
",",4. Warmup,[0],[0]
"n}, then the probability of selecting i is equal, with both A(1) and A(2), to 12 1 1+t + 1 2 1 1+1/t",4. Warmup,[0],[0]
"= 1 2 1 1+t + 1 2 t t+1 = 1 2 .
",4. Warmup,[0],[0]
"On the other hand, consider the 3-slate T = {1, 2, i}, for any i ∈ {3, . . .",4. Warmup,[0],[0]
", n}.",4. Warmup,[0],[0]
"In this case, we have DA(1)T (i) = 1 2 · 1 2t+1 + 1 2 · 1 2/t+1 = 1 2 − O ( 1 t ) , while DA (2) T (i) = 1 2 ·
1 t+1+1/t + 1 2 · 1 t+1+1/t = O ( 1 t ) .",4. Warmup,[0],[0]
"Thus, limt→∞DA (1)
T (i)− DA (2)
T (i) = 1 2 .
",4. Warmup,[0],[0]
We next consider non-uniform 2-MNLs and show that even 3-slates are not enough for unique reconstruction.,4. Warmup,[0],[0]
"For ease of exposition, we will use a weight function where exactly one of the weights is zero; this can be easily modified so that the construction has only positive weights.
",4. Warmup,[0],[0]
Theorem 3.,4. Warmup,[0],[0]
"For each n ≥ 3, there exists two 2-MNLsA(1) and A(2), each with mixing weight 2/3 such that DA(1)T = DA (2)
T for each T with |T | ≤ 3, but there is a T with |T | = 4 such that DA (1)
",4. Warmup,[0],[0]
T 6=,4. Warmup,[0],[0]
"DA (2) T .
",4. Warmup,[0],[0]
Proof.,4. Warmup,[0],[0]
For i ∈,4. Warmup,[0],[0]
"[2], let A(i) =",4. Warmup,[0],[0]
"(a(i), b(i), 2/3).",4. Warmup,[0],[0]
Let a(i)j,4. Warmup,[0],[0]
=,4. Warmup,[0],[0]
b,4. Warmup,[0],[0]
(i) j = 1 for j ∈,4. Warmup,[0],[0]
[n] \ {1}.,4. Warmup,[0],[0]
"Let a (1) 1 = 4/9, a (2) 1 = 64 and b(1)1 = 4, b (1) 1 = 0.",4. Warmup,[0],[0]
"For both the 2-MNLs, the mixing weight µ = 2/3.
",4. Warmup,[0],[0]
"By the definition of a(·) and b(·), all the slates that do not contain item 1 will have their winner chosen uniformly at random, i.e., DA (1)
T (i) = D A(2)",4. Warmup,[0],[0]
T (i) = 1/|T,4. Warmup,[0],[0]
"| for each i ∈
T ⊆",4. Warmup,[0],[0]
"[n] \ {1}.
",4. Warmup,[0],[0]
"We now focus on 2- and 3-slates T, T 3 1.",4. Warmup,[0],[0]
For each i ∈,4. Warmup,[0],[0]
"[2], by construction, DA (i)
T (j) = D A(i) T (j ′) for any j, j′ 6=",4. Warmup,[0],[0]
1.,4. Warmup,[0],[0]
"Moreover,
• if |T | = 2, then DA(1)T (1) = 23 · 4/9 4/9+1 + 1 3 · 64 64+1 =
8 15 = 2 3 · 4 4+1 + 1 3 · 0 0+1 = D A(2) T (1);
",4. Warmup,[0],[0]
"• if |T | = 3, then DA(1)T (1) = 23 · 4/9 4/9+2 + 1 3 · 64 64+2 =
4 9 = 2 3 · 4 4+2 + 1 3 · 0 0+2 = D A(2) T (1).
",4. Warmup,[0],[0]
"On the other hand, if T = {1, 2, 3, 4}, then DA(1)T (1) = 2 3 · 4/9 4/9+3 + 1 3 · 64 64+3 = 840 2077 6= 8 21 = 2 3 · 4 4+3 + 1 3 · 0 0+3 = DA (2)
T (1).
",4. Warmup,[0],[0]
In the next sections we complement these lower bounds by developing an algorithm for learning uniform 2-MNLs that uses 2-slate and 3-slate queries.,4. Warmup,[0],[0]
"In this section we obtain algorithms to learn 2-MNLs using only 2-slate and 3-slate queries, complementing the slatesize lower bound in Theorem 2.",5. Learning 2-MNLs,[0],[0]
Our algorithms use O(n) adaptive queries or O(n2) non-adaptive queries; we will also show these query bounds are optimal for any algorithm that uses constant-sized slates.,5. Learning 2-MNLs,[0],[0]
"To illustrate our algorithms better, we first present query lower bounds for adaptive and non-adaptive algorithms.",5.1. Query Lower Bounds,[0],[0]
In particular we ask how many slates of bounded size must be examined to reconstruct the weights of a 2-MNL.,5.1. Query Lower Bounds,[0],[0]
"We show that any adaptive (resp., non-adaptive) algorithm querying only slates of constant size has to perform at least Ω(n) (resp., Ω(n2)) queries to reconstruct.
",5.1. Query Lower Bounds,[0],[0]
Theorem 4.,5.1. Query Lower Bounds,[0],[0]
"Any algorithm for 2-MNL that queries using c-slates needs Ω(n/c) queries to reconstruct; the query lower bound for non-adaptive algorithms is Ω(n2/c2).
",5.1. Query Lower Bounds,[0],[0]
Proof.,5.1. Query Lower Bounds,[0],[0]
"Let i, j be two distinct items in [n] chosen u.a.r.",5.1. Query Lower Bounds,[0],[0]
"We will construct two different uniform 2-MNLs, A(i) =",5.1. Query Lower Bounds,[0],[0]
"(a(i), b(i))",5.1. Query Lower Bounds,[0],[0]
for i ∈,5.1. Query Lower Bounds,[0],[0]
"[2], as follows.",5.1. Query Lower Bounds,[0],[0]
"Let each MNL give a weight of 1 to each item except for i and j. Let a(1)i = a
(1) j = 2, b (1)",5.1. Query Lower Bounds,[0],[0]
"i = b (1) j = 1, and a (2) i = b (2) j = 2,
a (2) j = b (2) i = 1.
",5.1. Query Lower Bounds,[0],[0]
"If an algorithm performs no query to a slate containing both items i and j, then it cannot distinguish between A(1) and A(2), and is therefore unable to learn the weights of the MNLs.",5.1. Query Lower Bounds,[0],[0]
"Indeed, for any slate S ⊆",5.1. Query Lower Bounds,[0],[0]
"[n] \ {i, j}, we have that DA (1)
S = D A(2) S , D A(1) {i}∪S = D A(2) {i}∪S , and D A(1) {j}∪S =
DA (2)
{j}∪S .
",5.1. Query Lower Bounds,[0],[0]
Any algorithm performing queries to slates of size at most c will need to perform Ω(n/c) queries to query at least once item i with constant probability.,5.1. Query Lower Bounds,[0],[0]
This proves the adaptive lower bound.,5.1. Query Lower Bounds,[0],[0]
"In the non-adaptive case, observe that each query performed by the algorithm will cover at most ( c 2
) different pairs.",5.1. Query Lower Bounds,[0],[0]
"Since we need the algorithm to query i and j together to distinguish between A(1) and A(2), and since there are ( n 2 ) many pairs of items, the algorithm will need to
perform Ω(n2/c2) queries to succeed with constant probability.",5.1. Query Lower Bounds,[0],[0]
We now present adaptive and non-adaptive algorithms that match the above query complexity and slate lower bounds.,5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
Our algorithms are based on a reduction to the 3-item universe case that we will present in Section 6.,5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"This constanttime algorithm uniquely reconstructs the weights of a 2- MNL on a universe of size 3, given the winning probabilities for all subsets of sizes 2 and 3, of the 3 items, i.e., using a total of 4 queries.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"For the remainder of this section we will refer to this as the 3-items algorithm.
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
The main idea behind the algorithms is to invoke the 3- items algorithm on chosen 3-slates and “patch” the weights returned by this algorithm to construct the weight functions a and b.,5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"However, one has to be careful given the lower bound construction in Theorem 4.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"For example, consider a naive algorithm that chooses the 3-slates {1, n",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"− 1, n}, {2, n",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"− 1, n}, . . .",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
", {n − 2, n",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"− 1, n}.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Note that the items n − 1 and n − 2 are fixed in all the slates that are queried and hence, if the two special items {i, j} of the lower bound construction do not satisfy {i, j}∩{n− 1, n} 6= ∅, that items i and j will never be queried together.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"From the lower bound construction, the algorithm will fail since it will be unable to tell whether items i and j have their larger weight in the same of the two MNLs, or in different MNLs.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"To circumvent this, one has to get hold of a pair of items that have different behavior in the mixture and use them as “anchors” to infer the weights of the remaining items.
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"We first present the algorithm that uses adaptive queries.
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
Theorem 5.,5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"We can reconstruct the weights of a uniform 2-MNL using O(n) adaptive queries with 2- and 3-slates.
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
Proof.,5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Let Mn be an arbitrary pairing of the items in [n] \ {1}, if n is odd.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"If n is even, let Mn = Mn−1 ∪ {{2, n}}.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Clearly, |Mn| = dn/2e.
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"We run the 3-items algorithm on each of the triples {1, i, j}, for all {i, j} ∈ Mn.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Since each call to the 3- items algorithm performs at most 4 queries, this will cost at most (n/2) · 4 + O(1) = 2n + O(1) queries.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"For a given {i, j} ∈Mn, and for x ∈ {1, i, j}, let ax({i, j}) and bx({i, j}) be the weights of x in a and b, as returned by the 3-items algorithm when run on {1, i, j}.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"We abbreviate ax = ax({i, j}), bx = bx({i, j}).
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Suppose the algorithm finds that for any two distinct items s, t ∈",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"[n], it holds that as/at = bs/bt, i.e., all the items have the same ratio in both the components of the mixture.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"This means that the 2-MNL is actually a 1-MNL and hence Observation 1 completes the argument.
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Otherwise, there is a triple {1, i, j} that contains two distinct items s, t such that, wlog, as/at > bs/bt.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
We use this pair of items as “anchors” to infer the rest of the weights.,5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Indeed, we run the 3-items algorithm on each triple {s, t, i} for each i ∈",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"[n] \ {s, t}.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"For x ∈ {i, s, t}, let ax({i}) and bx({i}) be the weights of x in a and b, as returned by the 3-items algorithm when run on the triple {s, t, i}.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"This step uses at most 4n+O(1) queries.
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"We then reorder the a({i}), b({i}) weights it returns on {s, t, i} so that as({i})/at({i}) > bs({i})/bt({i}).",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Then, we set ai = ai({i}) · as/as({i}) and bi = bi({i}) · bs/bs({i}).",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Given the guarantees of the 3-item algorithm, it is easy to see that the 2-MNL is correctly reconstructed (up to normalization).
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"The total number of queries used in the algorithm is at most 6n+O(1).
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
We next present a non-adaptive algorithm.,5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"As the lower bound in Theorem 4 suggests, the difficulty arises specifically due to the possible existence of very many pairs of items having exactly the same ratio of weights in the two MNLs; this may be viewed as a form of degeneracy.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"We present the algorithm below.
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
Theorem 6.,5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"We can reconstruct the weights of a uniform 2-MNL on n items with O(n2) non-adaptive queries with 2- and 3-slates.
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
Proof.,5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"We run the 3-items algorithm on the slate {1, i, j} for each {i, j} ∈
( [n]\{1}
2
) .",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"As in the proof of Theorem 5,
if there are no pairs such that as/at 6= bs/bt, then the 2- MNL is actually a 1-MNL and Observation 1 can be used to reconstruct.
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Otherwise, we can identify two items s, t such that as/at 6= bs/bt.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
It must be that either a1/as 6= b1/bs or a1/at 6= b1/bt,5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"(indeed, if a1/as = b1/bs and a1/at = b1/bt, then as/at = bs/bt).",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Suppose, wlog, that a1/as 6= b1/bs.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"This allows us to obtain the weights of items 1 and s. Moreover, for each i ∈",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"[n] \ {1, s}, the 3-items algorithm has been run on {1, s, i}.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Therefore, we can compute the weights of item i, as in the proof of Theorem 5, hence reconstructing the 2-MNL.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"The non-adaptive algorithm that we described performs 4 ( n−1
2
) = 2n2 −O(n) queries.
",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"Note that if noise is added to the weights, or if the MNL’s are otherwise guaranteed to have no equiweighted items for any triple, then the linear-time bound will also apply in the non-adaptive case.",5.2. Adaptive and Non-Adaptive Algorithms,[0],[0]
"In this section we focus our attention on a universe of size 3, i.e., n = 3.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"As we saw before, our algorithms use this as a building block to work for all n.
At first glance, this problem is apparently simple, for example, there are only four unknowns in a uniform 2-MNL on n = 3 and there are five known free quantities (one free winning probability from each of the three 2-slates, and two free winning probabilities from the 3-slate) to possibly pin down the unknowns.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"However, such arguments can be deceptive and fallacious.1 The number of unknowns and the number of available quantities do not have a simple relationship since the system, as we will see, is nonlinear.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"Furthermore, the uniqueness of the solution, given the known quantities, is not obvious and establishing it is crucial to solving the reconstruction problem.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"Trying to do this through automatic symbolic methods quickly runs into computational issues, as we found.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"This forces an analytic approach to study the multivariate polynomial system, which also yields interesting insights into the structure of the system implied by the uniform 2-MNL.
",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"To make the exposition simpler, let the items of the universe be indexed by {i, j, k}.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"Again, without loss of generality, ai + aj + ak = 1 = bi + bj + bk.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"Note that
D{x,y}(x) = 1
2
( ax
ax + ay",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"+ bx bx + by
) ,
D{x,y,z}(x) = ax +",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"bx
2 ,
for {x, y, z} = {i, j, k}.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"In this section we show that the sequence of functions D =( D{i,j,k}(·), D{i,j}(·), D{j,k}(·), D{i,k}(·) ) uniquely determines ai, aj , ak, bi, bj , bk (up to reordering) and present an algorithm to find them.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"As we saw in Section 5, this implies we can reconstruct the 2-MNL by querying 2-slates and 3-slates.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
This proof of uniqueness requires a few steps that we will sketch out now as a roadmap of this section.,6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
We first introduce some key notions.,6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"We say the uniform 2-MNL ((ai, aj , ak), (bi, bj , bk)) is consistent with D, if it gives the same winning probabilities as D. Definition 7 (Equiweightedness).",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"For a given triple {i, j, k} such that ai +aj +ak = 1 = bi + bj + bk, and for ` ∈ {i, j, k}, we say the item ` is equiweighted if a` = b`.
1To appreciate how misleading the problem difficulty can be, the case of non-uniform 2-MNL is only marginally more complex (i.e., it has only one extra unknown representing the mixing weight), but we do not currently know how to solve uniqueness in this case.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"In fact, as we proved in Theorem 3, queries on 2-slates and 3-slates are not sufficient to reconstruct the weights of a nonuniform 2-MNL on n = 3 elements, regardless of the facts that those slates give 5 known quantities, and that there are exactly 5 unknowns in a non-uniform 2-MNL.
",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"We begin by showing in Lemma 8 how to find two items of {i, j, k} that are ordered consistently in a and",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"b. Next, in Lemma 9, we extend this analysis to find items that are equiweighted.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"From here, we perform a delicate case analysis.
",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"If all the items are equiweighted, then the 2-MNL is actually a 1-MNL, which we recover via Observation 1.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"If exactly one item is equiweighted (Section 6.2), we prove uniqueness in Lemma 10.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
We then proceed to the hardest case (Section 6.3) in which no item is equiweighted.,6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"Per Lemma 8 we may order the items {i, j, k}, and the weights a, b, such that aj > bj and ak > bk.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"Lemma 11 then shows a bijection from aj to ak, and another bijection from ak to aj .",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
The remainder of the proof proceeds by contradiction.,6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
Corollary 12 employs the form of the bijections to develop ordering constraints on the weights of items of two hypothesized distinct 2-MNLs generating the same slate probabilities.,6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"Theorem 13 then shows that the existence of two distinct 2-MNLs yields a contradiction.
",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"In Appendix 6.4, we discuss the algorithmic implications of the uniqueness result.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"In particular, we show that the weights of a uniform 2-MNL on 3 elements can be found efficiently if one has access to the sequence of functions D. Finally, in Appendix A, we show that, under a mild separation assumption on the weights, having access to a sample oracle (instead of to the exact winning probabilities in D) is still sufficient for polynomial-time reconstruction.",6. Learning a 2-MNL on a 3-Item Universe,[0],[0]
"We start by proving two technical statements that allow us to evaluate the relation between a` and b`, for ` ∈ {i, j, k}, using just the winning probabilities on the subslates of {i, j, k}.",6.1. Ordering and Equiweightedness of Items,[0],[0]
"The first result allows us to pinpoint the two items in {i, j, k} that order their a and bweights in the same manner.
",6.1. Ordering and Equiweightedness of Items,[0],[0]
"Given x, y ∈ {i, j, k}, x 6= y, define the predicate Px,y ∆ =",6.1. Ordering and Equiweightedness of Items,[0],[0]
"[D{x,y}(x) ·D{x,y,z}(y) ≥ D{x,y}(y) ·D{x,y,z}(x)].
",6.1. Ordering and Equiweightedness of Items,[0],[0]
Lemma 8. (ax−bx) ·(ay−by) ≥ 0,6.1. Ordering and Equiweightedness of Items,[0],[0]
iff,6.1. Ordering and Equiweightedness of Items,[0],[0]
"Px,z∧Py,z , i.e., the relative ordering of ax, bx matches the relative ordering of ay, by iff Px,z ∧ Py,z .
",6.1. Ordering and Equiweightedness of Items,[0],[0]
"The next statement characterizes equiweighted items in terms of the predicates, which will allow us to identify equiweighted items, if any.",6.1. Ordering and Equiweightedness of Items,[0],[0]
Lemma 9.,6.1. Ordering and Equiweightedness of Items,[0],[0]
z is equiweighted,6.1. Ordering and Equiweightedness of Items,[0],[0]
"iff Px,y ∧Py,x ∧Pz,x ∧Pz,y .
Note that obtaining the weight of an equiweighted item i is trivial: indeed, if i is equiweighted, then ai = bi = D{i,j,k}(i).",6.1. Ordering and Equiweightedness of Items,[0],[0]
"Now, if two items of {i, j, k} are equiweighted, then all of them are equiweighted, and therefore the 2-MNL is indeed a 1-MNL and can be learned using Observation 1.",6.1. Ordering and Equiweightedness of Items,[0],[0]
"In the following we consider the
remaining two cases: when {i, j, k} contains exactly one equiweighted item and when no item in {i, j, k} is equiweighted.",6.1. Ordering and Equiweightedness of Items,[0],[0]
"We now show that if there is a single equiweighted item in {i, j, k}, then the uniqueness follows.",6.2. Uniqueness if Exactly One Item is Equiweighted,[0],[0]
Lemma 10.,6.2. Uniqueness if Exactly One Item is Equiweighted,[0],[0]
"Suppose i is the only equiweighted item of {i, j, k}.",6.2. Uniqueness if Exactly One Item is Equiweighted,[0],[0]
"Then, there is a unique 2-MNL A (up to reordering) that is consistent with D.",6.2. Uniqueness if Exactly One Item is Equiweighted,[0],[0]
"We now consider the remaining case where no item in {i, j, k} is equiweighted, i.e., ai 6= bi, aj 6= bj , and ak 6= bk.",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Lemma 8 can be used to find the two indices in {i, j, k} that order the weights in the two MNLs in the same manner.",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"We assume wlog that the two indices are j, k, i.e., we assume that (aj − bj)(ak− bk) > 0.",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Wlog, by reordering, we also assume that aj > bj and ak > bk.
",6.3. Uniqueness With No Equiweighted Items,[0],[0]
The first result in this section relates the value of aj to the value of ak and vice versa.,6.3. Uniqueness With No Equiweighted Items,[0],[0]
Lemma 11.,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Suppose that ((ai, aj , ak), (bi, bj , bk)) is consistent with D. Suppose further that the functions in D satisfy Pj,i ∧",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Pk,i, Pi,k ∧",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Pj,k, and Pi,j ∧ Pk,j .2",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Then,
aj = ( D{i,j}(j)+
D{i,j}(j)D{i,j,k}(i)−D{i,j}(i)D{i,j,k}(j) ak −D{i,j,k}(k) ) · (1− ak) ∆ = fj(ak), (1)
and
ak= ( D{i,k}(k)+
D{i,k}(k)D{i,j,k}(i)−D{i,k}(i)D{i,j,k}(k) aj −D{i,j,k}(j) ) ·",6.3. Uniqueness With No Equiweighted Items,[0],[0]
(1− aj) ∆ = fk(aj).,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"(2)
Moreover, fj(ak) is decreasing for ak ∈ (D{i,j,k}(k), 1), and fk(aj) is decreasing for aj ∈ (D{i,j,k}(j), 1).
",6.3. Uniqueness With No Equiweighted Items,[0],[0]
Proof.,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Let us consider the expression for D{i,j}(j):
1
2 aj ai + aj + 1 2 bj bi + bj = D{i,j}(j).",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"(3)
Using D{i,j,k}(j) =",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"(aj + bj)/2, (3) can be rewritten as
aj(ak−bk) 2
=D{i,j}(j)(1−ak)(1−bk)−D{i,j,k}(j)(1−ak).",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"(4)
Since ak 6= bk, we can divide (4) by ak − bk to obtain
1 2 aj = (1− ak) D{i,j}(j)(1− bk)−D{i,j,k}(j) ak − bk .",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"(5)
2By Lemmas 8 and 9, this is equivalent to requiring each compatible solution ((ai, aj , ak), (bi, bj , bk)), with aj ≥ bj , to satisfy aj > bj and ak > bk.
",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Now, we use 2(D{i,j,k}(k)−bk)",6.3. Uniqueness With No Equiweighted Items,[0],[0]
= 2 ( 1 2ak + 1 2bk − bk ) =,6.3. Uniqueness With No Equiweighted Items,[0],[0]
ak − bk in (5) to obtain (1).,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"The derivation of (2) is analogous.
",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"For the monotonicity claim, recall that Pj,i ⇐⇒",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"[D{i,j}(j)D{i,j,k}(i)",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"− D{i,j}(i)D{i,j,k}(j) ≥ 0].",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Thus by our Pj,i assumption, the numerator of the fraction in (1) is non-negative (see Lemma 8).",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"For any ak ∈ (D{i,j,k}(k), 1), the denominator of that fraction is positive, and it increases with ak.",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Since D{i,j}(j) is also positive, fj(ak) decreases as ak increase.",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"The monotonicity of fj(ak) can be proved symmetrically.
",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"We then get the following consequence relating the orderings of the aj’s, bj’s, ak’s, and bk’s.",6.3. Uniqueness With No Equiweighted Items,[0],[0]
Corollary 12.,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Suppose the functions in D satisfy Pj,i ∧",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Pk,i ∧ Pi,k ∧",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Pj,k ∧ Pi,j ∧ Pk,j .",6.3. Uniqueness With No Equiweighted Items,[0],[0]
Then,6.3. Uniqueness With No Equiweighted Items,[0],[0]
", if ((a′i, a′j , a′k), (b′i, b ′ j , b ′ k)) 6= ((a′′i , a′′j , a′′k), (b′′i , b′′j , b′′k)) are weights consistent with D and assuming wlog that a′j",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"≥ b′j , a′′j ≥ b′′j , it must hold that either:
• a′j",6.3. Uniqueness With No Equiweighted Items,[0],[0]
>,6.3. Uniqueness With No Equiweighted Items,[0],[0]
a′′j > b′′j > b′j and a′′k >,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"a′k > b′k > b′′k , or • a′′j > a′j",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"> b′j > b′′j and a′k > a′′k > b′′k > b′k.
",6.3. Uniqueness With No Equiweighted Items,[0],[0]
Proof.,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"By the properties of the functions in D, and Lemmas 8 and 9, we must have a′j > b ′",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"j , a ′′ j > b ′′ j , a ′",6.3. Uniqueness With No Equiweighted Items,[0],[0]
k > b ′,6.3. Uniqueness With No Equiweighted Items,[0],[0]
k and a′′k > b ′′ k .,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Thus, max(b ′ j , b ′′ j ) < D{i,j,k}(j) < min(a ′ j , a ′′ j ).
",6.3. Uniqueness With No Equiweighted Items,[0],[0]
Suppose that a′j = a ′′ j .,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Then, by Lemma 11, it must be that a′k = fk(a ′ j) and a ′′ k = fk(a ′′ j ), and thus a ′ k = a ′′ k .",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"By the consistency of the D{i,j,k}(j) winning probability, it must also hold that b′j = b ′′ j and b ′",6.3. Uniqueness With No Equiweighted Items,[0],[0]
k = b ′′ k .,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Therefore, ((a′i, a ′ j , a ′ k), (b ′",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"i, b ′ j , b ′ k))",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"= ((a ′′ i , a ′′ j , a ′′ k), (b ′′",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"i , b ′′ j , b ′′ k)), and we get a contradiction.
",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Otherwise we have two cases.
",6.3. Uniqueness With No Equiweighted Items,[0],[0]
•,6.3. Uniqueness With No Equiweighted Items,[0],[0]
If a′j >,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"a′′j , then a′k = fk(a′j) < fk(a′′j ) =",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"a′′k , by the decreasing property of fk(·) proved in Lemma 11.",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Then, by the consistency of the winning probabilities D{i,j,k}(j) and D{i,j,k}(k), we must have a′j + b ′",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"j =
a′′j + b ′′ j and a ′ k",6.3. Uniqueness With No Equiweighted Items,[0],[0]
+ b ′,6.3. Uniqueness With No Equiweighted Items,[0],[0]
k = a ′′ k + b ′′ k .,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Thus, b ′ j < b ′′ j and b′k >",6.3. Uniqueness With No Equiweighted Items,[0],[0]
b ′′ k .,6.3. Uniqueness With No Equiweighted Items,[0],[0]
•,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"If a′j < a′′j , then symmetrically we get a′k = fk(a′j) >",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"fk(a ′′ j ) = a ′′ k , and b ′ j > b ′′",6.3. Uniqueness With No Equiweighted Items,[0],[0]
j and b ′,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"k < b ′′ k .
",6.3. Uniqueness With No Equiweighted Items,[0],[0]
We are now ready to prove uniqueness in the no equiweighted items case.,6.3. Uniqueness With No Equiweighted Items,[0],[0]
Theorem 13.,6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Suppose the functions in D satisfy Pj,i ∧",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Pk,i ∧ Pi,k ∧",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Pj,k ∧ Pi,j ∧ Pk,j .",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Then, there is a unique ((ai, aj , ak), (bi, bj , bk)), up to reordering, consistent with D.",6.3. Uniqueness With No Equiweighted Items,[0],[0]
"Having established the uniqueness of a 2-MNL given D, we show how to determine its weights.",6.4. Reconstructing the Weights,[0],[0]
"First, observe that,
having access to the functions in D, we can write down a system of polynomial inequalities having the unknown weights of the 2-MNL A as its solution: ai ai+aj + bi bi+bj = 2DA{i,j}(i) ai ai+ak + bi bi+bk = 2DA{i,k}(i) aj aj+ak + bj bj+bk = 2DA{j,k}(j) ai ai+aj+ak + bi bi+bj+bk = 2DA{i,j,k}(i) aj ai+aj+ak + bj bi+bj+bk = 2DA{i,j,k}(j)
ai",6.4. Reconstructing the Weights,[0],[0]
"+ aj + ak = 1 bi + bj + bk = 1 ai, aj , ak, bi, bj , bk > 0
(6)
",6.4. Reconstructing the Weights,[0],[0]
"For a given choice of D, the system can be solved in constant (but very large) time using, e.g., Buchberger’s algorithm (Buchberger, 1976) for computing the Gröbner Bases.",6.4. Reconstructing the Weights,[0],[0]
"Thus, we get the following.
",6.4. Reconstructing the Weights,[0],[0]
Theorem 14.,6.4. Reconstructing the Weights,[0],[0]
"There is a constant-time algorithm that given the D induced by a 2-MNL on a universe of size 3, infers the unique 2-MNL consistent with D.
From a practical perspective, computing the weights using the Gröbner bases of the system is computationally expensive.",6.4. Reconstructing the Weights,[0],[0]
"However, one could use Lemmas 8 and 9 to obtain, in a very efficient manner, the relative ordering and the equiweightedness of the 3 items.",6.4. Reconstructing the Weights,[0],[0]
"Then, if there are 3 equiweighted items, the solution can be computed efficiently using Observation 1.",6.4. Reconstructing the Weights,[0],[0]
"If there is exactly 1 equiweighted item, then the solution can be obtained using the proof of Lemma 10.",6.4. Reconstructing the Weights,[0],[0]
"Otherwise, there are no equiweighted items, and one could use a one-dimensional grid search suggested by the bijections of Lemma 11.",6.4. Reconstructing the Weights,[0],[0]
"In this paper, we have proposed the first algorithm for (provably) learning exactly uniform mixtures of two multinomial logits over a universe of n items.",7. Conclusions,[0],[0]
"Our algorithms run in time O(n) for adaptive queries, and in time O(n2) for non-adaptive queries; we have shown that our algorithms are optimal, query-wise, in the class of algorithms that perform queries to slates of constant size.
",7. Conclusions,[0],[0]
"There are significant technical challenges in extending our methods to either non-uniform mixtures or mixtures of more than two components, but parts of our proof structure do generalize.",7. Conclusions,[0],[0]
We hope that the existence of our algorithm is a first step towards finding more general provable results for this important problem.,7. Conclusions,[0],[0]
Part of this work was done while the first author was visiting Google.,Acknowledgements,[0],[0]
"The first author was supported in part by a Google Focused Research Award, by the ERC Starting Grant DMAP 680153, by the SIR Grant RBSI14Q743,
and by the “Dipartimenti di Eccellenza 2018-2022” grant awarded to the Dipartimento di Informatica at Sapienza.",Acknowledgements,[0],[0]
The classical Multinomial Logit (MNL) is a behavioral model for user choice.,abstractText,[0],[0]
"In this model, a user is offered a slate of choices (a subset of a finite universe of n items), and selects exactly one item from the slate, each with probability proportional to its (positive) weight.",abstractText,[0],[0]
"Given a set of observed slates and choices, the likelihoodmaximizing item weights are easy to learn at scale, and easy to interpret.",abstractText,[0],[0]
"However, the model fails to represent common real-world behavior.",abstractText,[0],[0]
"As a result, researchers in user choice often turn to mixtures of MNLs, which are known to approximate a large class of models of rational user behavior.",abstractText,[0],[0]
"Unfortunately, the only known algorithms for this problem have been heuristic in nature.",abstractText,[0],[0]
In this paper we give the first polynomialtime algorithms for exact learning of uniform mixtures of two MNLs.,abstractText,[0],[0]
"Interestingly, the parameters of the model can be learned for any n by sampling the behavior of random users only on slates of sizes 2 and 3; in contrast, we show that slates of size 2 are insufficient by themselves.",abstractText,[0],[0]
Learning a Mixture of Two Multinomial Logits,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 963–973 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1089
We present an approach to rapidly and easily build natural language interfaces to databases for new domains, whose performance improves over time based on user feedback, and requires minimal intervention. To achieve this, we adapt neural sequence models to map utterances directly to SQL with its full expressivity, bypassing any intermediate meaning representations. These models are immediately deployed online to solicit feedback from real users to flag incorrect queries. Finally, the popularity of SQL facilitates gathering annotations for incorrect predictions using the crowd, which is directly used to improve our models. This complete feedback loop, without intermediate representations or database specific engineering, opens up new ways of building high quality semantic parsers. Experiments suggest that this approach can be deployed quickly for any new target domain, as we show by learning a semantic parser for an online academic database from scratch.",text,[0],[0]
"Existing semantic parsing approaches for building natural language interfaces to databases (NLIDBs) either use special-purpose intermediate meaning representations that lack the full expressivity of database query languages or require extensive feature engineering, making it difficult to deploy them in new domains.",1 Introduction,[1.0],"['Existing semantic parsing approaches for building natural language interfaces to databases (NLIDBs) either use special-purpose intermediate meaning representations that lack the full expressivity of database query languages or require extensive feature engineering, making it difficult to deploy them in new domains.']"
"We present a robust approach to quickly and easily learn and deploy semantic parsers from scratch, whose performance
Work done partly during an internship at the Allen Institute for Artificial Intelligence.
improves over time based on user feedback, and requires very little expert intervention.
",1 Introduction,[0],[0]
"To learn these semantic parsers, we (1) adapt neural sequence models to map utterances directly to SQL thereby bypassing intermediate representations and taking full advantage of SQL’s querying capabilities, (2) immediately deploy the model online to solicit questions and user feedback on results to reduce SQL annotation efforts, and (3) use crowd workers from skilled markets to provide SQL annotations that can directly be used for model improvement, in addition to being easier and cheaper to obtain than logical meaning representations.",1 Introduction,[1.0],"['To learn these semantic parsers, we (1) adapt neural sequence models to map utterances directly to SQL thereby bypassing intermediate representations and taking full advantage of SQL’s querying capabilities, (2) immediately deploy the model online to solicit questions and user feedback on results to reduce SQL annotation efforts, and (3) use crowd workers from skilled markets to provide SQL annotations that can directly be used for model improvement, in addition to being easier and cheaper to obtain than logical meaning representations.']"
"We demonstrate the effectiveness of the complete approach by successfully learning a semantic parser for an academic domain by simply deploying it online for three days.
",1 Introduction,[0],[0]
"This type of interactive learning is related to a number of recent ideas in semantic parsing, in-
963
cluding batch learning of models that directly produce programs (e.g., regular expressions (Locascio et al., 2016)), learning from paraphrases (often gathered through crowdsourcing (Wang et al., 2015)), data augmentation (e.g. based on manually engineered semantic grammars (Jia and Liang, 2016)) and learning through direct interaction with users (e.g., where a single user teaches the model new concepts (Wang et al., 2016)).",1 Introduction,[1.0000000265016737],"['This type of interactive learning is related to a number of recent ideas in semantic parsing, in- 963 cluding batch learning of models that directly produce programs (e.g., regular expressions (Locascio et al., 2016)), learning from paraphrases (often gathered through crowdsourcing (Wang et al., 2015)), data augmentation (e.g. based on manually engineered semantic grammars (Jia and Liang, 2016)) and learning through direct interaction with users (e.g., where a single user teaches the model new concepts (Wang et al., 2016)).']"
"However, there are unique advantages to our approach, including showing (1) that non-linguists can write SQL to encode complex, compositional computations (see Fig 1 for an example), (2) that external paraphrase resources and the structure of facts from the target database itself can be used for effective data augmentation, and (3) that actual database users can effectively drive the overall learning by simply providing feedback about what the model is currently getting correct.
",1 Introduction,[0],[0]
"Our experiments measure the performance of these learning advances, both in batch on existing datasets and through a simple online experiment for the full interactive setting.",1 Introduction,[0],[0]
"For the batch evaluation, we use sentences from the benchmark GeoQuery and ATIS domains, converted to contain SQL meaning representations.",1 Introduction,[0],[0]
"Our neural learning with data augmentation achieves reasonably high accuracies, despite the extra complexities of mapping directly to SQL.",1 Introduction,[0],[0]
"We also perform simulated interactive learning on this data, showing that with perfect user feedback our full approach could learn high quality parsers with only 55% of the data.",1 Introduction,[0],[0]
"Finally, we do a small scale online experiment for a new domain, academic paper metadata search, demonstrating that actual users can provide useful feedback and our full approach is an effective method for learning a high quality parser that continues to improve over time as it is used.",1 Introduction,[0],[0]
"Although diverse meaning representation languages have been used with semantic parsers – such as regular expressions (Kushman and Barzilay, 2013; Locascio et al., 2016), Abstract Meaning Representations (AMR) (Artzi et al., 2015; Misra and Artzi, 2016), and systems of equations (Kushman et al., 2014; Roy et al., 2016) – parsers for querying databases have typically used either logic programs (Zelle and Mooney, 1996), lambda calculus (Zettlemoyer and Collins, 2005), or λDCS (Liang et al., 2013) as the meaning represen-
tation language.",2 Related Work,[0],[0]
All three of these languages are modeled after natural language to simplify parsing.,2 Related Work,[0],[0]
"However, none of them is used to query databases outside of the semantic parsing literature; therefore, they are understood by few people and not supported by standard database implementations.",2 Related Work,[0],[0]
"In contrast, we parse directly to SQL, which is a popular database query language with wide usage and support.",2 Related Work,[0],[0]
"Learning parsers directly from SQL queries has the added benefit that we can potentially hire programmers on skilled-labor crowd markets to provide labeled examples, such as UpWork1, which we demonstrate in this work.
",2 Related Work,[0],[0]
"A few systems have been developed to directly generate SQL queries from natural language (Popescu et al., 2003; Giordani and Moschitti, 2012; Poon, 2013).",2 Related Work,[0],[0]
"However, all of these systems make strong assumptions on the structure of queries: they use manually engineered rules that can only generate a subset of SQL, require lexical matches between question tokens and table/column names, or require questions to have a certain syntactic structure.",2 Related Work,[0],[0]
"In contrast, our approach can generate arbitrary SQL queries, only uses lexical matching for entity names, and does not depend on syntactic parsing.
",2 Related Work,[0],[0]
We use a neural sequence-to-sequence model to directly generate SQL queries from natural language questions.,2 Related Work,[0],[0]
"This approach builds on recent work demonstrating that such models are effective for tasks such as machine translation (Bahdanau et al., 2015) and natural language generation (Kiddon et al., 2016).",2 Related Work,[0],[0]
"Recently, neural models have been successfully applied to semantic parsing with simpler meaning representation languages (Dong and Lapata, 2016; Jia and Liang, 2016) and short regular expressions (Locascio et al., 2016).",2 Related Work,[0],[0]
Our work extends these results to the task of SQL generation.,2 Related Work,[0],[0]
"Finally, Ling et al. (2016) generate Java/Python code for trading cards given a natural language description; however, this system suffers from low overall accuracy.
",2 Related Work,[0],[0]
A final direction of related work studies methods for reducing the annotation effort required to train a semantic parser.,2 Related Work,[0],[0]
"Semantic parsers have been trained from various kinds of annotations, including labeled queries (Zelle and Mooney, 1996; Wong and Mooney, 2007; Zettlemoyer and Collins, 2005), question/answer pairs (Liang et al., 2013; Kwiatkowski et al., 2013; Berant et al.,
1http://www.upwork.com
2013), distant supervision (Krishnamurthy and Mitchell, 2012; Choi et al., 2015), and binary correct/incorrect feedback signals (Clarke et al., 2010; Artzi and Zettlemoyer, 2013).",2 Related Work,[0],[0]
"Each of these schemes presents a particular trade-off between annotation effort and parser accuracy; however, recent work has suggested that labeled queries are the most effective (Yih et al., 2016).",2 Related Work,[0],[0]
"Our approach trains on fully labeled SQL queries to maximize accuracy, but uses binary feedback from users to reduce the number of queries that need to be labeled.",2 Related Work,[0],[0]
"Annotation effort can also be reduced by using crowd workers to paraphrase automatically generated questions (Wang et al., 2015); however, this approach may not generate the questions that users actually want to ask the database – an experiment in this paper demonstrated that 48% of users’ questions in a calendar domain could not be generated.",2 Related Work,[0],[0]
Our feedback-based learning approach can be used to quickly deploy semantic parsers to create NLIDBs for any new domain.,3 Feedback-based Learning,[0],[0]
"It is a simple interactive learning algorithm that deploys a preliminary semantic parser, then iteratively improves this parser using user feedback and selective query annotation.",3 Feedback-based Learning,[0],[0]
A key requirement of this algorithm is the ability to cheaply and efficiently annotate queries for chosen user utterances.,3 Feedback-based Learning,[0],[0]
"We address this requirement by developing a model that directly outputs SQL queries (Section 4), which can also be produced by crowd workers.
",3 Feedback-based Learning,[0],[0]
"Our algorithm alternates between stages of training the model and making predictions to gather user feedback, with the goal of improving performance in each successive stage.",3 Feedback-based Learning,[0],[0]
The procedure is described in Algorithm 1.,3 Feedback-based Learning,[0],[0]
"Our neural model N is initially trained on synthetic data T generated by domain-independent schema templates (see Section 4), and is then ready to answer new user questions, n. The results R of executing the predicted SQL query q are presented to the user who provides a binary correct/incorrect feedback signal.",3 Feedback-based Learning,[1.0],"['Our neural model N is initially trained on synthetic data T generated by domain-independent schema templates (see Section 4), and is then ready to answer new user questions, n. The results R of executing the predicted SQL query q are presented to the user who provides a binary correct/incorrect feedback signal.']"
"If the user marks the result correct, the pair (n, q) is added to the training set.",3 Feedback-based Learning,[0],[0]
"If the user marks the result incorrect, the algorithm asks a crowd worker to annotate the utterance with the correct query, q̂, and adds (n, q̂) to the training set.",3 Feedback-based Learning,[0],[0]
"This procedure can be repeated indefinitely, ideally increasing parser accuracy and requesting
fewer annotations in each successive stage.
",3 Feedback-based Learning,[0],[0]
"1 Procedure LEARN(schema) 2 T ← initial data(schema) 3 while true do 4 T ← T ∪ paraphrase(T ) 5 N ← train model(T ) 6 for n ∈ new utterances do 7 q ← predict(N , n)",3 Feedback-based Learning,[0],[0]
"8 R ← execute(q) 9 f ← feedback(R) 10 if f = correct then 11 T ← T ∪ (n, q) 12 else if f = wrong then 13 q̂ ← annotate(n) 14 T ← T ∪ (n, q̂) 15 end 16 end 17 end 18 end
Algorithm 1: Feedback-based learning.",3 Feedback-based Learning,[0],[0]
"We use a neural sequence-to-sequence model for mapping natural language questions directly to SQL queries and this allows us to scale our feedback-based learning approach, by easily crowdsourcing labels when necessary.",4 Semantic Parsing to SQL,[0],[0]
We further present two data augmentation techniques which use content from the database schema and external paraphrase resources.,4 Semantic Parsing to SQL,[0],[0]
"We use an encoder-decoder model with global attention, similar to Luong et al. (2015), where the anonymized utterance (see Section 4.2) is encoded using a bidirectional LSTM network, then decoded to directly predict SQL query tokens.",4.1 Model,[1.0],"['We use an encoder-decoder model with global attention, similar to Luong et al. (2015), where the anonymized utterance (see Section 4.2) is encoded using a bidirectional LSTM network, then decoded to directly predict SQL query tokens.']"
"Fixed pre-trained word embeddings from word2vec (Mikolov et al., 2013) are concatenated to the embeddings that are learned for source tokens from the training data.",4.1 Model,[0],[0]
"The decoder predicts a conditional probability distribution over possible values for the next SQL token given the previous tokens using a combination of the previous SQL token embedding, attention over the hidden states of the encoder network, and an attention signal from the previous time step.
",4.1 Model,[1.000000005333513],"['The decoder predicts a conditional probability distribution over possible values for the next SQL token given the previous tokens using a combination of the previous SQL token embedding, attention over the hidden states of the encoder network, and an attention signal from the previous time step.']"
"Formally, if qi represents an embedding for the
ith SQL token qi, the decoder distribution is
p(qi|q1, . . .",4.1 Model,[0],[0]
", qi−1) ∝ exp (W tanh(Ŵ[hi : ci]))",4.1 Model,[0],[0]
"where hi represents the hidden state output of the decoder LSTM at the ith timestep, ci represents the context vector generated using an attention weighted sum of encoder hidden states based on hi, and, W and Ŵ are linear transformations.",4.1 Model,[0],[0]
"If sj is the hidden representation generated by the encoder for the jth word in the utterance (k words long), then the context vectors are defined to be:
ci = k∑
j=1
αi,j · sj
The attention weights αi,j are computed using an inner product between the decoder hidden state for the current timestep hi, and the hidden representation of the jth source token sj:
αi,j = exp(hiTFsj)∑k j=1 exp(hi TFsj)
where F is a linear transformation.",4.1 Model,[0],[0]
"The decoder LSTM cell f computes the next hidden state hi, and cell state, mi, based on the previous hidden and cell states, hi−1,mi−1, the embeddings of the previous SQL token qi−1 and the context vector of the previous timestep, ci−1
hi,mi = f(hi−1,mi−1,qi−1, ci−1)
We apply dropout on non-recurrent connections for regularization, as suggested by Pham et al. (2014).",4.1 Model,[0],[0]
Beam search is used for decoding the SQL queries after learning.,4.1 Model,[0],[0]
"We handle entities in the utterances and SQL by replacing them with their types, using incremental numbering to model multiple entities of the same type (e.g., CITY NAME 1).",4.2 Entity Anonymization,[0],[0]
"During training, when the SQL is available, we infer the type from the associated column name; for example, Boston is a city in city.city name = ’Boston’.",4.2 Entity Anonymization,[0],[0]
"To recognize entities in the utterances at test time, we build a search engine on all entities from the target database.",4.2 Entity Anonymization,[0],[0]
"For every span of words (starting with a high span size and progressively reducing it), we query the search engine using a TF-IDF scheme to retrieve the entity that most closely matches the span, then replace the span with the entity’s type.",4.2 Entity Anonymization,[0],[0]
We store these mappings and apply them to the generated SQL to fill in the entity names.,4.2 Entity Anonymization,[0],[0]
"TF-IDF matching allows some flexibility in matching en-
tity names in utterances, for example, a user could say Donald Knuth instead of Donald E. Knuth.",4.2 Entity Anonymization,[0],[0]
"We present two data augmentation strategies that either (1) provide the initial training data to start the interactive learning, before more labeled examples become available, or (2) use external paraphrase resources to improve generalization.
",4.3 Data Augmentation,[0],[0]
"Schema Templates To bootstrap the model to answer simple questions initially, we defined 22 language/SQL templates that are schema-agnostic, so they can be applied to any database.",4.3 Data Augmentation,[0],[0]
These templates contain slots whose values are populated given a database schema.,4.3 Data Augmentation,[0],[0]
An example template is shown in Figure 2a.,4.3 Data Augmentation,[0],[0]
"The <ENT> types represent tables in the database schema, <ENT>.<COL> represents a column in the particular table and <ENT>.<COL>.<TYPE> represents the type associated with the particular column.",4.3 Data Augmentation,[0],[0]
A template is instantiated by first choosing the entities and attributes.,4.3 Data Augmentation,[0],[0]
"Next, join conditions, i.e., JOIN FROM and JOIN WHERE clauses, are generated from the tables on the shortest path between the chosen tables in the database schema graph, which connects tables (graph nodes) using foreign key constraints.",4.3 Data Augmentation,[0],[0]
Figure 2b shows an instantiation of a template using the path author - writes - paper - paperdataset - dataset.,4.3 Data Augmentation,[0],[0]
SQL queries generated in this manner are guaranteed to be executable on the target database.,4.3 Data Augmentation,[0],[0]
"On the language side, an English name of each entity is plugged into the template to generate an utterance for the query.
",4.3 Data Augmentation,[0],[0]
"Paraphrasing The second data augmentation strategy uses the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013) to automatically generate paraphrases of training utterances.",4.3 Data Augmentation,[0],[0]
"Such methods have been recently used to improve performance for parsing to logical forms (Chen et al., 2016).",4.3 Data Augmentation,[0],[0]
PPDB contains over 220 million paraphrase pairs divided into 6 sets (small to XXXL) based on precision of the paraphrases.,4.3 Data Augmentation,[1.0],['PPDB contains over 220 million paraphrase pairs divided into 6 sets (small to XXXL) based on precision of the paraphrases.']
We use the one-one and one-many paraphrases from the large version of PPDB.,4.3 Data Augmentation,[0],[0]
"To paraphrase a training utterance, we pick a random word in the utterance that is not a stop word or entity and replace it with a random paraphrase.",4.3 Data Augmentation,[0],[0]
"We perform paraphrase expansion on all examples labeled during learning, as well as the initial seed examples from schema templates.
",4.3 Data Augmentation,[0],[0]
Get all <ENT1>.<NAME> having <ENT2>.<COL1>.<NAME>,4.3 Data Augmentation,[0],[0]
"as <ENT2>.<COL1>.<TYPE>
SELECT <ENT1>.<DEF> FROM JOIN_FROM(<ENT1>, <ENT2>)",4.3 Data Augmentation,[0],[0]
"WHERE JOIN_WHERE(<ENT1>, <ENT2>) AND <ENT2>.<COL1> =",4.3 Data Augmentation,[0],[0]
<ENT2>.<COL1>.<TYPE>,4.3 Data Augmentation,[0],[0]
"Our first set of experiments demonstrates that our semantic parsing model has comparable accuracy to previous work, despite the increased difficulty of directly producing SQL.",5 Benchmark Experiments,[0],[0]
"We demonstrate this result by running our model on two benchmark datasets for semantic parsing, GEO880 and ATIS.",5 Benchmark Experiments,[0],[0]
"GEO880 is a collection of 880 utterances issued to a database of US geographical facts (Geobase), originally in Prolog format.",5.1 Data sets,[0],[0]
Popescu et al. (2003) created a relational database schema for Geobase together with SQL queries for a subset of 700 utterances.,5.1 Data sets,[0],[0]
"To compare against prior work on the full corpus, we annotated the remaining utterances and used the standard 600/280 training/test split (Zettlemoyer and Collins, 2005).
",5.1 Data sets,[0],[0]
"ATIS is a collection of 5,418 utterances to a flight booking system, accompanied by a relational database and SQL queries to answer the questions.",5.1 Data sets,[0],[0]
"We use 4,473 utterances for training, 497 for development and 448 for test, following Kwiatkowski et al. (2011).",5.1 Data sets,[0],[0]
"The original SQL queries were very inefficient to execute due to the use of IN clauses, so we converted them to joins (Ramakrishnan and Gehrke, 2003) while verifying that the output of the queries was unchanged.
",5.1 Data sets,[0],[0]
Table 1 shows characteristics of both data sets.,5.1 Data sets,[0],[0]
"GEO880 has shorter queries but is more compositional: almost 40% of the SQL queries have at
least one nested subquery.",5.1 Data sets,[0],[0]
"ATIS has the longest utterances and queries, with an average utterance length of 11 words and an average SQL query length of 67 tokens.",5.1 Data sets,[1.0],"['ATIS has the longest utterances and queries, with an average utterance length of 11 words and an average SQL query length of 67 tokens.']"
They also operate on approximately 6 tables per query on average.,5.1 Data sets,[0],[0]
We will release our processed versions of both datasets.,5.1 Data sets,[0],[0]
We follow a standard train/dev/test methodology for our experiments.,5.2 Experimental Methodology,[0],[0]
"The training set is augmented using schema templates and 3 paraphrases per training example, as described in Section 4.",5.2 Experimental Methodology,[0],[0]
Utterances were anonymized by replacing them with their corresponding types and all words that occur only once were replaced by UNK symbols.,5.2 Experimental Methodology,[0],[0]
The development set is used for hyperparameter tuning and early stopping.,5.2 Experimental Methodology,[0],[0]
"For GEO880, we use cross validation on the training set to tune hyperparameters.",5.2 Experimental Methodology,[0],[0]
"We used a minibatch size of 100 and used Adam (Kingma and Ba, 2015) with a learning rate of 0.001 for 70 epochs for all our experiments.",5.2 Experimental Methodology,[0],[0]
We used a beam size of 5 for decoding.,5.2 Experimental Methodology,[0],[0]
We report test set accuracy of our SQL query predictions by executing them on the target database and comparing the result with the true result.,5.2 Experimental Methodology,[0],[0]
"Tables 2 and 3 show test accuracies based on denotations for our model on GEO880 and ATIS respectively, compared with previous work.2",5.3 Results,[0],[0]
"To our knowledge, this is the first result on directly parsing to SQL to achieve comparable performance to prior work without using any database-specific feature engineering.",5.3 Results,[0],[0]
Popescu et al. (2003) and Giordani and Moschitti (2012) also directly produce SQL queries but on a subset of 700 examples from GEO880.,5.3 Results,[0],[0]
"The former only works on semantically tractable utterances where words can be un-
2Note that 2.8% of GEO880 and 5% ATIS gold test set SQL queries (before any processing) produced empty results.
ambiguously mapped to schema elements, while the latter uses a reranking approach that also limits the complexity of SQL queries that can be handled.",5.3 Results,[0],[0]
"GUSP (Poon, 2013) creates an intermediate representation that is then deterministically converted to SQL to obtain an accuracy of 74.8% on ATIS, which is boosted to 83.5% using manually introduced disambiguation rules.",5.3 Results,[0],[0]
"However, it requires a lot of SQL specific engineering (for example, special nodes for argmax) and is hard to extend to more complex SQL queries.
",5.3 Results,[0],[0]
"On both datasets, our SQL model achieves reasonably high accuracies approaching that of the best non-SQL results.",5.3 Results,[1.0],"['On both datasets, our SQL model achieves reasonably high accuracies approaching that of the best non-SQL results.']"
Most relevant to this work are the neural sequence based approaches of Dong and Lapata (2016) and Jia and Liang (2016).,5.3 Results,[0],[0]
"We note that Jia and Liang (2016) use a data recombination technique that boosts accuracy from 85.0 on GEO880 and 76.3 on ATIS; this technique is also compatible with our model and we hope to experi-
ment with this in future work.",5.3 Results,[0],[0]
Our results demonstrate that these models are powerful enough to directly produce SQL queries.,5.3 Results,[0],[0]
"Thus, our methods enable us to utilize the full expressivity of the SQL language without any extensions that certain logical representations require to answer more complex queries.",5.3 Results,[0],[0]
"More importantly, it can be immediately deployed for users in new domains, with a large programming community available for annotation, and thus, fits effectively into a framework for interactive learning.
",5.3 Results,[0.9999999861100516],"['More importantly, it can be immediately deployed for users in new domains, with a large programming community available for annotation, and thus, fits effectively into a framework for interactive learning.']"
We perform ablation studies on the development sets (see Table 4) and find that paraphrasing using PPDB consistently helps boost performance.,5.3 Results,[0],[0]
"However, unlike in the interactive experiments (Section 6), data augmentation using schema templates does not improve performance in the fully supervised setting.",5.3 Results,[1.0],"['However, unlike in the interactive experiments (Section 6), data augmentation using schema templates does not improve performance in the fully supervised setting.']"
"In this section, we learn a semantic parser for an academic domain from scratch by deploying an online system using our interactive learning algorithm (Section 3).",6 Interactive Learning Experiments,[0],[0]
"After three train-deploy cycles, the system correctly answered 63.51% of user’s questions.",6 Interactive Learning Experiments,[0],[0]
"To our knowledge, this is the first effort to learn a semantic parser using a live system, and is enabled by our models that can directly parse language to SQL without manual intervention.",6 Interactive Learning Experiments,[0],[0]
"We developed a web interface for accepting natural language questions to an academic database from users, using our model to generate a SQL query, and displaying the results after execution.",6.1 User Interface,[1.0],"['We developed a web interface for accepting natural language questions to an academic database from users, using our model to generate a SQL query, and displaying the results after execution.']"
Several example utterances are also displayed to help users understand the domain.,6.1 User Interface,[0],[0]
"Together with the results of the generated SQL query, users are prompted to provide feedback which is used for
interactive learning.",6.1 User Interface,[0],[0]
"Screenshots of our interface are included in our Supplementary Materials.
",6.1 User Interface,[0],[0]
Collecting accurate user feedback on predicted queries is a key challenge in the interactive learning setting for two reasons.,6.1 User Interface,[1.0],['Collecting accurate user feedback on predicted queries is a key challenge in the interactive learning setting for two reasons.']
"First, the system’s results can be incorrect due to poor entity identification or incompleteness in the database, neither of which are under the semantic parser’s control.",6.1 User Interface,[0],[0]
"Second, it can be difficult for users to determine if the presented results are in fact correct.",6.1 User Interface,[1.0],"['Second, it can be difficult for users to determine if the presented results are in fact correct.']"
"This determination is especially challenging if the system responds with the correct type of result, for example, if the user requests “papers at ACL 2016” and the system responds with all ACL papers.
",6.1 User Interface,[0],[0]
"We address this challenge by providing users with two assists for understanding the system’s behavior, and allowing users to provide more granular feedback than simply correct/incorrect.",6.1 User Interface,[0],[0]
"The first assist is type highlighting, which highlights entities identified in the utterance, for example, “paper by Michael I. Jordan (AUTHOR) in ICRA (VENUE) in 2016 (YEAR).”",6.1 User Interface,[0],[0]
This assist is especially helpful because the academic database contains noisy keyword and dataset tables that were automatically extracted from the papers.,6.1 User Interface,[0],[0]
"The second assist is utterance paraphrasing, which shows the user another utterance that maps to the same SQL query.",6.1 User Interface,[1.0],"['The second assist is utterance paraphrasing, which shows the user another utterance that maps to the same SQL query.']"
"For example, for the above query, the system may show “what papers does Michael I. Jordan (AUTHOR) have in ICRA (VENUE) in 2016 (YEAR).”",6.1 User Interface,[0],[0]
"This assist only appears if a matching query (after entity anonymization) exists in the model’s training set.
",6.1 User Interface,[0],[0]
"Using these assists and the predicted results, users are asked to select from five feedback options: Correct, Wrong Types, Incomplete Result, Wrong Result and Can’t Tell.",6.1 User Interface,[1.0],"['Using these assists and the predicted results, users are asked to select from five feedback options: Correct, Wrong Types, Incomplete Result, Wrong Result and Can’t Tell.']"
"The Correct and Wrong Result options represent scenarios when the user is satisfied with the result, or the result is identifiably wrong, respectively.",6.1 User Interface,[0],[0]
"Wrong Types indicates incorrect entity identification, which can be determined from type highlighting.",6.1 User Interface,[0],[0]
Incomplete Result indicates that the query is correct but the result is not; this outcome can occur because the database is incomplete.,6.1 User Interface,[0],[0]
Can’t Tell indicates that the user is unsure about the feedback to provide.,6.1 User Interface,[1.0],['Can’t Tell indicates that the user is unsure about the feedback to provide.']
"In this experiment, using our developed user interface, we use Algorithm 1 to learn a semantic parser from scratch.",6.2 Three-Stage Online Experiment,[1.0],"['In this experiment, using our developed user interface, we use Algorithm 1 to learn a semantic parser from scratch.']"
"The experiment had three
stages; in each stage, we recruited 10 new users (computer science graduate students) and asked them to issue at least 10 utterances each to the system and to provide feedback on the results.",6.2 Three-Stage Online Experiment,[0.9999999994477606],"['The experiment had three stages; in each stage, we recruited 10 new users (computer science graduate students) and asked them to issue at least 10 utterances each to the system and to provide feedback on the results.']"
We considered results marked as either Correct or Incomplete Result as correct queries for learning.,6.2 Three-Stage Online Experiment,[1.0],['We considered results marked as either Correct or Incomplete Result as correct queries for learning.']
The remaining incorrect utterances were sent to a crowd worker for annotation and were used to retrain the system for the next stage.,6.2 Three-Stage Online Experiment,[0],[0]
The crowd worker had prior experience in writing SQL queries and was hired from Upwork after completing a short SQL test.,6.2 Three-Stage Online Experiment,[1.0],['The crowd worker had prior experience in writing SQL queries and was hired from Upwork after completing a short SQL test.']
The worker was also given access to the database to be able to execute the queries and ensure that they are correct.,6.2 Three-Stage Online Experiment,[1.0],['The worker was also given access to the database to be able to execute the queries and ensure that they are correct.']
"For the first stage, the system was trained using 640 examples generated using templates, that were augmented to 1746 examples using paraphrasing (see Section 4.3).",6.2 Three-Stage Online Experiment,[0],[0]
"The complexity of the utterances issued in each of the three phases were comparable, in that, the average length of the correct SQL query for the utterances, and the number of tables required to be queried, were similar.
",6.2 Three-Stage Online Experiment,[1.0000000878620168],"['The complexity of the utterances issued in each of the three phases were comparable, in that, the average length of the correct SQL query for the utterances, and the number of tables required to be queried, were similar.']"
Table 5 shows the percent of utterances judged by users as either Correct or Incomplete Result in each stage.,6.2 Three-Stage Online Experiment,[1.0],['Table 5 shows the percent of utterances judged by users as either Correct or Incomplete Result in each stage.']
"In the first stage, we do not have any labeled examples, and the model is trained using only synthetically generated data from schema templates and paraphrases (see Section 4.3).",6.2 Three-Stage Online Experiment,[1.0],"['In the first stage, we do not have any labeled examples, and the model is trained using only synthetically generated data from schema templates and paraphrases (see Section 4.3).']"
"Despite the lack of real examples, the system correctly answers 25% of questions.",6.2 Three-Stage Online Experiment,[0],[0]
The system’s accuracy increases and annotation effort decreases in each successive stage as additional utterances are contributed and incorrect utterances are labeled.,6.2 Three-Stage Online Experiment,[1.0],['The system’s accuracy increases and annotation effort decreases in each successive stage as additional utterances are contributed and incorrect utterances are labeled.']
"This result demonstrates that we can successfully build semantic parsers for new domains by using neural models to generate SQL with crowdsourced annotations driven by user feedback.
",6.2 Three-Stage Online Experiment,[1.0000000225424774],['This result demonstrates that we can successfully build semantic parsers for new domains by using neural models to generate SQL with crowdsourced annotations driven by user feedback.']
We analyzed the feedback signals provided by the users in the final stage of the experiment to measure the quality of feedback.,6.2 Three-Stage Online Experiment,[0],[0]
We found that 22.3% of the generated queries did not execute (and hence were incorrect).,6.2 Three-Stage Online Experiment,[0],[0]
6.1% of correctly generated queries were marked wrong by users (see Table 6).,6.2 Three-Stage Online Experiment,[0],[0]
This erroneous feedback results in redundant annotation of already correct examples.,6.2 Three-Stage Online Experiment,[0],[0]
"The main cause of this erroneous feedback was incomplete data for aggregation queries, where users chose Wrong instead of Incomplete.",6.2 Three-Stage Online Experiment,[0],[0]
6.3% of incorrect queries were erroneously deemed correct by users.,6.2 Three-Stage Online Experiment,[0],[0]
"It is important that this fraction be low, as these queries become incorrectly-labeled exam-
ples in the training set that may contribute to the deterioration of model accuracy over time.",6.2 Three-Stage Online Experiment,[0],[0]
"This quality of feedback is already sufficient for our neural models to improve with usage, and creating better interfaces to make feedback more accurate is an important task for future work.",6.2 Three-Stage Online Experiment,[0],[0]
We release a new semantic parsing dataset for academic database search using the utterances gathered in the user study.,6.3 SCHOLAR dataset,[0],[0]
We augment these labeled utterances with additional utterances labeled by crowd workers.,6.3 SCHOLAR dataset,[0],[0]
(Note that these additional utterances were not used in the online experiment).,6.3 SCHOLAR dataset,[0],[0]
"The final dataset comprises 816 natural language utterances labeled with SQL, divided into a 600/216 train/test split.",6.3 SCHOLAR dataset,[0],[0]
"We also provide a database on which to execute these queries containing academic papers with their authors, citations, journals, keywords and datasets used.",6.3 SCHOLAR dataset,[0],[0]
Table 1 shows statistics of this dataset.,6.3 SCHOLAR dataset,[0],[0]
Our parser achieves an accuracy of 67% on this train/test split in the fully supervised setting.,6.3 SCHOLAR dataset,[0],[0]
"In comparison, a nearest neighbor strategy that uses the cosine similarity metric using a TF-IDF representation for the utterances yields an accuracy of 52.75%.
",6.3 SCHOLAR dataset,[0],[0]
"We found that 15% of the predicted queries did not execute, predominantly owing to (1) accessing table columns without joining with those tables, and (2) generating incorrect types that could not be deanonymized using the utterance.",6.3 SCHOLAR dataset,[0],[0]
"The main types of errors in the remaining well-formed queries that produced incorrect results were (1) portions of the utterance (such as ‘top’ and ‘cited
by both’) were ignored, and (2) some types from the utterance were not transferred to the SQL query.",6.3 SCHOLAR dataset,[0],[0]
"We conducted additional simulated interactive learning experiments using GEO880 and ATIS to better understand the behavior of our train-deploy feedback loop, the effects of our data augmentation approaches, and the annotation effort required.",6.4 Simulated Interactive Experiments,[0],[0]
We randomly divide each training set into K batches and present these batches sequentially to our interactive learning algorithm.,6.4 Simulated Interactive Experiments,[0],[0]
"Correctness feedback is provided by comparing the result of the predicted query to the gold query, i.e., we assume that users are able to perfectly distinguish correct results from incorrect ones.
",6.4 Simulated Interactive Experiments,[0],[0]
Figure 3 shows accuracies on GEO880 and ATIS respectively of each batch when the model is trained on all previous batches.,6.4 Simulated Interactive Experiments,[0],[0]
"As in the live experiment, accuracy improves with successive batches.",6.4 Simulated Interactive Experiments,[0],[0]
"Data augmentation using templates helps in the initial stages of GEO880, but its advantage
is reduced as more labeled data is obtained.",6.4 Simulated Interactive Experiments,[0],[0]
"Templates did not improve accuracy on ATIS, possibly because most ATIS queries involve two entities, i.e., a source city and a destination city, whereas our templates only generate questions with a single entity type.",6.4 Simulated Interactive Experiments,[0],[0]
"Nevertheless, templates are important in a live system to motivate users to interact with it in early stages.",6.4 Simulated Interactive Experiments,[0],[0]
"As observed before, paraphrasing improves performance at all stages.
",6.4 Simulated Interactive Experiments,[0],[0]
Table 7 shows the percent of examples that require annotation using various batch sizes for GEO880.,6.4 Simulated Interactive Experiments,[0],[0]
"Smaller batch sizes reduce annotation effort, with a batch size of 50 requiring only 54.3% of the examples to be annotated.",6.4 Simulated Interactive Experiments,[0],[0]
This result demonstrates that more frequent deployments of improved models leads to fewer mistakes.,6.4 Simulated Interactive Experiments,[0],[0]
We describe an approach to rapidly train a semantic parser as a NLIDB that iteratively improves parser accuracy over time while requiring minimal intervention.,7 Conclusion,[0],[0]
"Our approach uses an attentionbased neural sequence-to-sequence model, with data augmentation from the target database and paraphrasing, to parse utterances to SQL.",7 Conclusion,[0],[0]
"This model is deployed in an online system, where user feedback on its predictions is used to select utterances to send for crowd worker annotation.
",7 Conclusion,[0],[0]
"We find that the semantic parsing model is comparable in performance to previous systems that either map from utterances to logical forms, or generate SQL, on two benchmark datasets, GEO880 and ATIS.",7 Conclusion,[0],[0]
We further demonstrate the effectiveness of our online system by learning a semantic parser from scratch for an academic domain.,7 Conclusion,[0],[0]
"A key advantage of our approach is that it is not language-specific, and can easily be ported to other commonly used query languages, such as SPARQL or ElasticSearch.",7 Conclusion,[0],[0]
"Finally, we also release a new dataset of utterances and SQL queries for an academic domain.",7 Conclusion,[0],[0]
"The research was supported in part by DARPA, under the DEFT program through the AFRL (FA8750-13-2-0019), the ARO (W911NF-16-10121), the NSF (IIS-1252835, IIS-1562364, IIS1546083, IIS-1651489, CNS-1563788), the DOE (DE-SC0016260), an Allen Distinguished Investigator Award, and gifts from NVIDIA, Adobe, and Google.",Acknowledgments,[0],[0]
The authors thank Rik Koncel-Kedziorski and the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
"We present an approach to rapidly and easily build natural language interfaces to databases for new domains, whose performance improves over time based on user feedback, and requires minimal intervention.",abstractText,[0],[0]
"To achieve this, we adapt neural sequence models to map utterances directly to SQL with its full expressivity, bypassing any intermediate meaning representations.",abstractText,[0],[0]
These models are immediately deployed online to solicit feedback from real users to flag incorrect queries.,abstractText,[0],[0]
"Finally, the popularity of SQL facilitates gathering annotations for incorrect predictions using the crowd, which is directly used to improve our models.",abstractText,[0],[0]
"This complete feedback loop, without intermediate representations or database specific engineering, opens up new ways of building high quality semantic parsers.",abstractText,[0],[0]
"Experiments suggest that this approach can be deployed quickly for any new target domain, as we show by learning a semantic parser for an online academic database from scratch.",abstractText,[0],[0]
Learning a Neural Semantic Parser from User Feedback,title,[0],[0]

0	66	Intelligent personal digital assistants (IPDAs) are one of the most advanced and successful artificial intelligence applications that have spoken language understanding (SLU).
1	49	Many IPDAs have recently emerged in industry including Amazon Alexa, Google Assistant, Apple Siri, and Microsoft Cortana (Sarikaya, 2017).
2	69	IPDAs have traditionally supported only dozens of well-separated domains, each defined in terms of a specific ap- plication or functionality such as calendar and local search (Tur and de Mori, 2011; Sarikaya et al., 2016).
3	64	To rapidly increase domain coverage and extend capabilities, some IPDAs have released Software Development Toolkits (SDKs) to allow third-party developers to quickly build and integrate new domains, which we refer to as skills henceforth.
4	21	Amazon’s Alexa Skills Kit (Kumar et al., 2017a), Google’s Actions and Microsoft’s Cortana Skills Kit are all examples of such SDKs.
10	18	Largescale IPDAs should be able to accommodate new skills efficiently without compromising performance.
11	61	Third, unlike traditional built-in domains that are carefully designed to be disjoint by a central team, skills are built independently by different developers and can cover overlapping functionalities.
38	43	The emergence of self-service SLU results in a large number of potentially mutually overlapping SLU domains.
46	64	P (si|µ) the probability of a skill being valid for an utterance is approximated by simple functions that act as candidate data generators λg ∈ Λg based on recognitions produced by a family of query patterns λq ∈ Λq.
48	26	We apply the technique to the query logs of a popular IPDA, which has support for personalized third party domains.
49	40	Looking at the structure of utterances that match query pattern λq, each utterance of form ”Ask {Uber} to {get me a car}” can be considered as being parametrized by the underlying latent command µz , that is ”Get me a car”, a target domain corresponding to service st, which in this case is Uber and the query recognition pattern λq, in this case ”Ask {st} to {µz}”.
54	18	Related to P (µ) in the noisy channel in the spell correction context, we defined a small family of heuristic noise detection functions λn ∈ Λn that discards training data instances that are not likely to be well formed.
67	19	Our model can efficiently accommodate new domains not seen during initial training by keeping the shared encoder frozen, bootstrapping a domain embedding based on existing ones, then optimizing a small number of network parameters corresponding to domain-specific classifier, which is orders of magnitude faster and more data efficient than retraining the full classifier.
69	12	We avoid expensive large vocabulary matrix multiplications on both the input and output stages, and instead use a combination of character embeddings and word embeddings in the input stage.2 The output matrix is lightweight because each domain-specific classifier is a matrix of only 201×2 parameters.
91	15	5Θd̃ denotes the additional parameters in the classification layer for domain d̃.
123	68	A random sample of 12,428 utterances from the test partition of users were presented to 300 human judges, who were asked to produce two natural ways to issue the same command.
133	15	For top-1 results on the Weak dataset, using a separate binary classifier for each domain (Binary) shows a prediction accuracy at 78.29% and using a softmax layer on top of the shared encoder (MultiClass) shows a comparable accuracy at 78.58%.
136	12	At 94.83% accuracy, attention resulted in 35.6% relative error reduction over the 1-bit baseline 91.97% on the Weak validation set and 23.25% relative on the MTurk test set.
137	72	We hypothesize that this may be because the attention mechanism allows the model to focus on complementary features in case of overlapping domains as well as learning domain co-occurrence statistics, both of which are not possible with the simple 1-bit flag.
138	48	When both personalization representations were combined, the performance peaked at 95.19% for the Weak dataset and a more modest 89.65% for the MTurk dataset.
140	51	The disambiguation task is complex due to similar and overlapping skills, but the results suggest that incorporating personalization signals equip the models with much better discriminative power.
141	31	The results also suggest that the two mechanisms for encoding personalization provide a small amount of complementary information since combining them together is better than using them individually.
143	17	Rapid Bootstrapping of New Skills We show the results when new domains are added to an IPDA and the model needs to efficiently accommodate them with a limited number of data samples.
150	83	Adapting a new skill is two orders of magnitude faster (30.34 seconds) than retraining the model (5300.18 seconds) while achieving 94.03% accuracy which is comparable to 94.58% accuracy of full retraining.
152	25	Behavior of Attention Mechanism Our expectation is that the model is able to learn to attend the relevant skills during the inference process.
161	27	15 human judges (male=12, female=3) rated the system responses, 1 judge per utterance, on a 5-point Likert scale with 1 being Terrible and 5 being Perfect.
164	149	The discrepancy between this score and the score produced on MTurk dataset indicates that even in cases in which the model makes classification mistakes, some of these interpretations remain perceptually meaningful to humans.
165	23	We have described a neural model architecture to address large-scale skill classification in an IPDA used by tens of millions of users every day.
166	143	We have described how personalization features and an attention mechanism can be used for handling ambiguity between domains.
167	33	We have also shown that the model can be extended efficiently and incrementally for new domains, saving multiple orders of magnitude in terms of training time.

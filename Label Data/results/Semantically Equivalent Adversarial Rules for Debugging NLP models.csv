0,1,label2,summary_sentences
"Given a dataset, similarity relationship between examples can be represented by a graph in which each example is represented by a vertex.",1. Introduction,[0],[0]
"While pairwise relationship between two vertices can be represented by an edge in a normal graph, a higher order relationship involving multiple vertices can be captured by a hyperedge, which means that all the corresponding examples are similar to one another.",1. Introduction,[0],[0]
"Hypergraphs have been used in several learning applications such as clustering of categorical data (Gibson et al., 1998), multi-label classification (Sun et al., 2008), Laplacian sparse coding (Gao et al., 2013), image classification (Yu et al., 2012), image retrieval (Huang et al., 2010), mapping users across different social networks (Tan et al., 2014) and predicting edge labels in hypernode graphs (Ricatte et al., 2014).
",1. Introduction,[0],[0]
"*Equal contribution 1University of Hong Kong, Hong Kong.",1. Introduction,[0],[0]
2This research was partially supported by the Hong Kong RGC under the grant 17200214.,1. Introduction,[0],[0]
"Correspondence to: T-H. Hubert Chan <hubert@cs.hku.hk>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"In this paper, we consider semi-supervised learning on an edge-weighted hypergraph H = (V,E,w), with a set L of labeled vertices, whose labels are given by f∗L ∈ {−1,+1}L. The task is to predict the labels of the unlabeled vertices N , with the working principle that vertices contained in a hyperedge e ∈ E are more similar to one another if the edge weight we is larger.",1. Introduction,[0],[0]
"This problem is also known as transductive inference and has been studied in (Zhou et al., 2006) and (Hein et al., 2013).
",1. Introduction,[0],[0]
"However, the methods in (Zhou et al., 2006) have been criticized by (Agarwal et al., 2006), because essentially a hypergraph is converted into a normal graph.",1. Introduction,[0],[0]
"For instance, given a hyperedge e containing vertices S, either (i) a clique is added between the vertices in S, or (ii) a star is formed by adding a new vertex ve connecting every vertex in S to ve.",1. Introduction,[0],[0]
"Then, a standard convex program using a regularization potential function for normal graphs can be applied (Zhu et al., 2003).",1. Introduction,[0],[0]
"By choosing appropriate edge weights, it was shown in (Agarwal et al., 2006) that the two approaches are equivalent to the following convex program relaxation:
min Φold(f) := 1
2 ∑ e∈E we ∑
{u,v}∈(e2)
(fu − fv)2
subject to fu ∈",1. Introduction,[0],[0]
"[−1, 1], ∀u ∈ V fu = f ∗ u , ∀u ∈",1. Introduction,[0],[0]
"L.
On the other hand, it was proposed in (Hein et al., 2013) that the following regularization function is more suitable to capture hyperedge expansion:
Φnew(f) := 1
2 ∑ e∈E we · (max u∈e fu −min v∈e fv) 2.
",1. Introduction,[0],[0]
"Indeed, it was shown in (Hein et al., 2013) that their approach outperforms (Zhou et al., 2006) on several datasets from the UCI Machine Learning Repository (Lichman, 2013).
",1. Introduction,[0],[0]
Loss Function.,1. Introduction,[0],[0]
"In (Hein et al., 2013), a squared loss function was added by considering the convex program with objective function Φnew(f) + µ ‖f − f∗‖22 on f ∈",1. Introduction,[0],[0]
"[−1, 1]V , where µ > 0 is a parameter to be tuned, f∗L is given by the labeled vertices L, and for the unlabeled vertices f∗N = 0.
",1. Introduction,[0],[0]
"The loss function allows errors in the labeled vertices, and also ensures that the minimizer is unique.",1. Introduction,[0],[0]
"However, as a result, unlabeled vertices have a tendency to acquire f values close to 0.",1. Introduction,[0],[0]
"This might remove useful information as illustrated in the following example.
",1. Introduction,[0],[0]
Example.,1. Introduction,[0],[0]
"In Figure 1.1, vertices a, b ∈ L are labeled as +1 and c ∈ L is labeled as −1.",1. Introduction,[0],[0]
"Vertices x, y ∈ N are unlabeled.",1. Introduction,[0],[0]
"There are three (undirected) edges: {a, x}, {b, x} and {x, y, c}, each with unit weight.
",1. Introduction,[0],[0]
"By choosing µ = 12 for squared loss function, the unique minimizer gives fx = 15 and fy = 0.",1. Introduction,[0],[0]
"Hence, this solution gives no useful information regarding the label for vertex y.
On the other hand, if we just use the objective function Φnew(f) with the constraints fL = f∗L, then in an optimal solution, fx = 13 , but fy could be anywhere in the confidence interval",1. Introduction,[0],[0]
"[−1, 13 ].",1. Introduction,[0],[0]
"Hence, in this case, we could use the average value − 13 to predict −1 for vertex y.
Our Contributions.",1. Introduction,[0],[0]
"In this paper, we revisit the approach used in (Hein et al., 2013) and consider several extensions and simplifications.",1. Introduction,[0],[0]
"We summarize our results and give an outline of the paper as follows.
1.",1. Introduction,[0],[0]
Unified Framework for Directed Hypergraphs.,1. Introduction,[0],[0]
"Inspired also from the recent result on Laplacians for directed normal graphs (Yoshida, 2016), we introduce a semisupervised learning framework using directed hypergraphs that can capture higher order causal relationships.",1. Introduction,[0],[0]
"This notion of directed hypergraph was first introduced in (Gallo et al., 1993), who considered applications in propositional logic, analyzing dependency in relational database, and traffic analysis.",1. Introduction,[0],[0]
"On a high level, a directed hyperedge e consists of a tail set Te pointing to a head set He such that a vertex in Te labeled +1 implies that a vertex in He is more likely to be labeled +1.",1. Introduction,[0],[0]
"(Equivalently in terms of its contrapositive, a vertex in He labeled −1 implies that a vertex in Te is more likely to be labeled −1.)",1. Introduction,[0],[0]
"In Section 2, we formally define the model and the corresponding potential function Φ. An additional advantage of our potential function is that there is no need to tune any parameters.
2.",1. Introduction,[0],[0]
Confidence Interval for Unlabeled Vertices.,1. Introduction,[0],[0]
Observe that the minimizer for our convex program might not be unique.,1. Introduction,[0],[0]
"In Section 3, we introduce the concept of confidence interval for each unlabeled vertex that can be useful for predicting its label.",1. Introduction,[0],[0]
"Furthermore, we provide an algorithm to calculate the confidence interval given an optimal solution.
3.",1. Introduction,[0],[0]
Simpler Subgradient Method.,1. Introduction,[0],[0]
"Since the new potential function is not everywhere differentiable but still convex, we use the subgradient method (Shor et al., 1985) to obtain an estimated minimizer for label prediction.",1. Introduction,[0],[0]
"Inspired by the diffusion processes used for defining Laplacians in hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), in Section 4, we define a simple Markov operator that returns a subgradient for Φ, which is used to solve the underlying convex program.",1. Introduction,[0],[0]
"We remark that our framework is very easy to understand, because it is a variation on the well-known gradient descent.
",1. Introduction,[0],[0]
"In contrast, the primal-dual approach in (Hein et al., 2013) considers the convex conjugate of the primal objective and involves complicated update operations on the primal and dual variables.",1. Introduction,[0],[0]
"The subgradient used in our approach gives the update direction, and we can actually solve exactly the same convex program with a much simpler method.",1. Introduction,[0],[0]
"Section 5, we revisit some datasets in the UCI Machine Learning Repository (Lichman, 2013), and experiments confirm that our prediction model based on confidence interval gives better accuracy than that in (Hein et al., 2013).",4. Experimental Results on Real-World Datasets. In,[0],[0]
"Our simpler subgradient method takes more iterations than the primal-dual method (Hein et al., 2013), but each iteration is much faster.",4. Experimental Results on Real-World Datasets. In,[0],[0]
"Experiments show that overall both methods have similar running times, and the subgradient method has an advantage when the number of vertices is much larger than the number of edges.
",4. Experimental Results on Real-World Datasets. In,[0],[0]
"Moreover, using the DBLP dataset (Ley, 2009), our experiments also support that using directed hypergraphs to capture causal relationships can improve the prediction accuracy.",4. Experimental Results on Real-World Datasets. In,[0],[0]
The experiments for directed hypergraphs are described in the full version.,4. Experimental Results on Real-World Datasets. In,[0],[0]
"We consider an edge-weighted directed hypergraph H = (V,E,w) with vertex set V (with n = |V |), edge set E and weight function",2. Preliminaries,[0],[0]
w : E → R+.,2. Preliminaries,[0],[0]
Each hyperedge e ∈ E consists of a tail set Te ⊆ V and a head set He ⊆ V (which are not necessarily disjoint); we use the convention that the direction is from tail to head.,2. Preliminaries,[0],[0]
"For x ∈ R, we denote [x]+ := max{x, 0}.
",2. Preliminaries,[0],[0]
"In our application, each vertex v ∈ V is supposed to have a label in {−1,+1}.",2. Preliminaries,[0],[0]
"Intuitively, the directed hypergraph attempts to capture the rule that for each edge e ∈ E, if there is a vertex in Te having label +1, then it is more likely for vertices in He to receive label +1.",2. Preliminaries,[0],[0]
"In terms of its contrapositive, if there is a vertex in He having label −1, then it is more likely for vertices in Te to receive label −1.
",2. Preliminaries,[0],[0]
"We use f ∈ RV to denote a vector, where the coordi-
nates are labeled by vertices in V .",2. Preliminaries,[0],[0]
"For U ⊆ V , we use fU ∈ RU to denote the vector restricting f to coordinates inU .",2. Preliminaries,[0],[0]
"In semi-supervised learning, we consider a setL ⊆ V of labeled vertices, which have labels f∗L ∈",2. Preliminaries,[0],[0]
"{−1,+1}L. Typically, |L| |V | and the task is to assign a label in {−1,+1} to each unlabeled vertex in N := V \ L, using information from the directed hypergraph H .
",2. Preliminaries,[0],[0]
"By relaxing labels to be in the interval [−1, 1], we consider the following regularization potential function Φ : RV → R:
Φ(f)",2. Preliminaries,[0],[0]
"= 1
2 ∑ e∈E we · ([∆e(f)]+)2,
where ∆e(f) := max(u,v)∈Te×He(fu − fv) = maxu∈Te fu −minv∈He fv .
",2. Preliminaries,[0],[0]
"In particular, there is a penalty due to edge e only if some vertex in Te receives a label larger than that of some vertex in He.",2. Preliminaries,[0],[0]
"The convexity of Φ is proved in the full version.
",2. Preliminaries,[0],[0]
Our approach is to consider the following convex program to obtain an estimated minimizer f ∈,2. Preliminaries,[0],[0]
"[−1, 1]V , which can be rounded to an integer solution for labeling all vertices.
min Φ(f) (CP1) subject to fu ∈",2. Preliminaries,[0],[0]
"[−1, 1], ∀u ∈ V
fu = f ∗ u , ∀u",2. Preliminaries,[0],[0]
"∈ L
Since the f values for the labeled vertices L are fixed in (CP1), we also view Φ : RN → R as a function on the f values of unlabeled vertices N .",2. Preliminaries,[0],[0]
"We use OPT ⊂ RV to denote the set of optimal solutions to (CP1).
",2. Preliminaries,[0],[0]
Trivial Edges.,2. Preliminaries,[0],[0]
An edge e ∈ E is trivial if there exist vertices u ∈ Te ∩ L and v ∈,2. Preliminaries,[0],[0]
He ∩ L such that f∗u = +1 and f∗v = −1.,2. Preliminaries,[0],[0]
"As trivial edges contribute constant towards the objective function Φ, we shall assume that there are no trivial edges in the convex program (CP1).
",2. Preliminaries,[0],[0]
Special Cases.,2. Preliminaries,[0],[0]
"Our directed hypergraph model can capture other graph models as follows.
1.",2. Preliminaries,[0],[0]
Undirected Hypergraphs.,2. Preliminaries,[0],[0]
"For each hyperedge e, we can set Te = He to the corresponding subset of vertices.",2. Preliminaries,[0],[0]
2.,2. Preliminaries,[0],[0]
Undirected Normal Graphs.,2. Preliminaries,[0],[0]
"For each edge e = {u, v}, we can set Te = He = e. Observe that in this case, the potential function becomes Φ(f) =∑
(u,v)∈E wuv(fu− fv)2, which is differentiable, and hence, (CP1) can be solved by standard techniques like gradient descent.
",2. Preliminaries,[0],[0]
Soft Constraints.,2. Preliminaries,[0],[0]
"In (Hein et al., 2013), each labeled vertex u ∈ L can also have some weight µu ∈ R+, which can, for instance, indicate how trustworthy the label
f∗u ∈ {−1,+1} is.",2. Preliminaries,[0],[0]
"The following relaxation is considered.
",2. Preliminaries,[0],[0]
"min Φ̂(f) := Φ(f) + 1
2 ∑ u∈L µu(fu",2. Preliminaries,[0],[0]
"− f∗u)2 (CP2)
subject to fu ∈",2. Preliminaries,[0],[0]
"[−1, 1],∀u ∈ V.
Observe that (CP2) can also be expressed in the framework of (CP1).",2. Preliminaries,[0],[0]
"We simply consider an augmented hypergraph Ĥ such that all vertices V are treated as unlabeled, and for each u ∈ L, we add a new vertex û with label f∗u and a new undirected edge {u, û} with weight µu.",2. Preliminaries,[0],[0]
"Then, it follows that the convex program (CP1) for the augmented instance for Ĥ is exactly the same as (CP2).
",2. Preliminaries,[0],[0]
Challenges Ahead.,2. Preliminaries,[0],[0]
"We next outline how we resolve the encountered challenges when we use (CP1) for semisupervised learning.
",2. Preliminaries,[0],[0]
"• Unlike the case for normal graphs, the set OPT can contain more than one optimal solution for (CP1).",2. Preliminaries,[0],[0]
"In Section 3, we prove some structural properties of the convex program, and illustrate that each u ∈ N has some confidence interval from which we can predict its label.",2. Preliminaries,[0],[0]
• The function Φ is not everywhere differentiable.,2. Preliminaries,[0],[0]
"Hence, we use the subgradient method (Shor et al., 1985).",2. Preliminaries,[0],[0]
"In Section 4, we give a method to generate a subgradient, which is inspired by the continuous diffusion processes for hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), and our method can in fact be viewed as a discretized version.",2. Preliminaries,[0],[0]
"In general, a minimizer for (CP1) might not be unique.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Hence, we introduce the concept of confidence interval.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Definition 3.1 (Confidence Interval),3. Confidence Interval for Semi-supervised Learning,[0],[0]
"For each u ∈ V , we define its confidence interval to be [mu,Mu], where mu := minf∈OPT fu and Mu := maxf∈OPT fu.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"The confidence intervals induce the lower and the upper confidence vectors, ~m and ~M ∈ RV , respectively.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"In Section 3.1, we give the proof of the following lemma, which states that the confidence vectors ~m and ~M are optimal solutions, and so are their convex combinations.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Lemma 3.1 (Confidence Vectors Give Optimal Solutions),3. Confidence Interval for Semi-supervised Learning,[0],[0]
For any λ ∈,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1], the convex combination λ~m + (1− λ) ~M",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"∈ OPT is optimal for (CP1).
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Semi-supervised Learning via Confidence Interval.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
Lemma 3.1 suggests what one can do when (CP1) has more than one optimal solution.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Specifically, in Algorithm 1, the
average vector 12 (~m + ~M) ∈ OPT can be used for label prediction.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"We show that the confidence vectors ~m and ~M can be recovered from any optimal solution f ∈ OPT, which in turn can be estimated by the subgradient method described in Section 4.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Algorithm 1 Semi-Supervised Learning
1: Input: Directed hypergraph H = (V,E,w), labels f∗L for labeled vertices L 2: Compute (estimated) confidence vectors (~m, ~M) ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"RN × RN , either by Algorithm 2 or 3.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
3: Compute average vector fN ← 12 (~m+ ~M).,3. Confidence Interval for Semi-supervised Learning,[0],[0]
4: Compute threshold θ ← 1|N | ∑ u∈N fu.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"5: for each u ∈ N do 6: if fu ≥ θ then 7: f̂u ← +1; 8: else 9: f̂u ← −1;
10: end if 11: end for 12: return f̂N
Fine-Tuning Parameters.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"In view of Lemma 3.1, one could further optimize the choice of λ ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1] in defining fN ← λ~m+ (1−λ) ~M in Line 3.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Similarly, one could pick the threshold θ to be the ϑ-percentile of the sorted coordinates of fN , for some choice of ϑ ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1].",3. Confidence Interval for Semi-supervised Learning,[0],[0]
The parameters λ and ϑ can be tuned using standard techniques like cross-validation.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"However, to illustrate our concepts, we keep the description simple without introducing too many free parameters.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
We derive some properties of the confidence vectors to prove Lemma 3.1.,3.1. Properties of Confidence Vectors,[0],[0]
"The full proofs of Lemma 3.2 and 3.3 are given in the full version.
",3.1. Properties of Confidence Vectors,[0],[0]
"Given a feasible solution f ∈ RV to (CP1), we define the following:
1. Se(f) := arg maxu∈Te fu ⊆ Te and Ie(f) := arg minv∈He fv ⊆ He.",3.1. Properties of Confidence Vectors,[0],[0]
2. f(Se),3.1. Properties of Confidence Vectors,[0],[0]
:= maxu∈Te fu and f(Ie) := minv∈He fv .,3.1. Properties of Confidence Vectors,[0],[0]
"Hence, we have ∆e(f) = f(Se)− f(Ie).",3.1. Properties of Confidence Vectors,[0],[0]
3.,3.1. Properties of Confidence Vectors,[0],[0]
"The set of active edges with respect to f is E(f) := {e ∈ E : ∆e(f) > 0}.
",3.1. Properties of Confidence Vectors,[0],[0]
"The following lemma states even though a minimizer for (CP1) might not be unique, there are still some structural properties for any optimal solution.
",3.1. Properties of Confidence Vectors,[0],[0]
Lemma 3.2 (Active Edges in an Optimal Solution) Suppose f and g are optimal solutions to (CP1).,3.1. Properties of Confidence Vectors,[0],[0]
"Then, for all e ∈ E, [∆e(f)]+ = [∆e(g)]+.",3.1. Properties of Confidence Vectors,[0],[0]
"In particular, this implies that the set of active edges E∗",3.1. Properties of Confidence Vectors,[0],[0]
":= E(f) = E(g) in any op-
timal solution is uniquely determined.",3.1. Properties of Confidence Vectors,[0],[0]
"Hence, for e ∈ E∗, we can define the corresponding ∆∗e = ∆e(f).
",3.1. Properties of Confidence Vectors,[0],[0]
"Definition 3.2 (Pinned Vertex) An unlabeled vertex u is pinned in a solution f ∈ RV if there exist active edges e and e′ ∈ E(f) such that u ∈ Se(f)∩ Ie′(f), in which case we say that the edges e and e′ pin the vertex u under f .
",3.1. Properties of Confidence Vectors,[0],[0]
Lemma 3.3 (Extending an Active Edge),3.1. Properties of Confidence Vectors,[0],[0]
Suppose edge e ∈ E(f) is active in an optimal solution f .,3.1. Properties of Confidence Vectors,[0],[0]
"If He does not contain a vertex labeled with −1, then there exist u ∈ Ie(f) and another active edge e′ ∈ E(f) such that the following holds.
",3.1. Properties of Confidence Vectors,[0],[0]
(a) The edges e and e′,3.1. Properties of Confidence Vectors,[0],[0]
"pin u under f , i.e., u ∈ Se′(f).",3.1. Properties of Confidence Vectors,[0],[0]
(b),3.1. Properties of Confidence Vectors,[0],[0]
"If g is an optimal solution, then Ie(f) ∩ Se′(f) =
Ie(g) ∩ Se′(g) and fu = gu.",3.1. Properties of Confidence Vectors,[0],[0]
vertex labeled with +1.,An analogous result holds when Te does not contain any,[0],[0]
∗(Ie),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
":= minu∈He fu are uniquely determined by any optimal solution f .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Corollary 3.1 (Pinned Vertices),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"In any optimal solution, the set of pinned vertices is uniquely determined.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
We use L∗ to denote the set of labeled or pinned vertices in an optimal solution.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Then, for each u ∈ L∗, its value f∗u in any optimal solution is also uniquely determined.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"From Corollary 3.1, the confidence interval for any u ∈ L∗ contains exactly one value, namely the unique value f∗u in any optimal solution.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The following lemma gives a characterization of an optimal solution.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Lemma 3.4 Characterization of Optimal Solutions,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"A solution f to (CP1) is optimal iff the following conditions hold.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"(a) For each u ∈ L∗, fu = f∗u .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"(b) For each active edge e ∈ E∗, both the maximum
maxu∈Te fu and the minimum minv∈He fv are attained by vertices in L∗. (c) For each inactive edge e /∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"E∗,","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
for all u ∈ Te and v ∈,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He, fu ≤ fv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Proof: We first observe that Corollary 3.1 states that the values of the vertices in L∗ are uniquely determined in any optimal solution.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, any optimal solution must satisfy the three conditions.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We next show that the three conditions implies that the objective value is optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Once the values for vertices in L∗ are fixed, Lemma 3.3 and condition (b) implies that the contribution of all active edges E∗ are determined and are the same as any optimal solution.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Finally, condition (c) implies that edges not in E∗ do not have any contribution towards the objective function.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, any solution satisfying the three conditions must be optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Deriving Confidence Vectors.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"To prove Lemma 3.5, we define a procedure that returns a vector ~m ∈ V R such that for any optimal f ∈ OPT, we have f ≥ ~m.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, we shall show that ~m ∈ OPT and hence ~m is the lower confidence vector.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The argument for the upper confidence vector ~M is similar.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For the special case of undirected hypergraphs, the procedure can be simplified to Algorithm 2 in Section 3.2.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Lemma 3.5 (Confidence Vectors are Optimal: Proof of Lemma 3.1),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The confidence vectors ~m and ~M defined in Definition 3.1 are optimal solutions to (CP1).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This implies that any of their convex combination is also optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Proof: We give a procedure that returns a vector ~m such that at any moment during the procedure, the following invariant is maintained: for any f ∈ OPT, f ≥ ~m.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The following steps correspond to maintaining the conditions in Lemma 3.4.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(a) Initialization.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For v ∈ L∗, set mv := f∗v ; for v /∈ L∗, set mv := −1.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This satisfies the invariant, because for any f ∈ OPT and any v ∈ L∗, fv = f∗v .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(b) Preserving Active Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For each v /∈ L∗, set mv ← max{mv,maxe∈E∗:v∈He f∗(Ie)}.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Observe that Lemma 3.4(b) implies that for any optimal f ∈ OPT, any e ∈ E∗ and any v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He, fv ≥ f∗(Ie).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, the invariant is maintained.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(c) Preserving Inactive Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
While there is an inactive edge e /∈ E∗,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"such that u ∈ Te, v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He and mu > mv , set mv ← mu.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
We argue why each such update preserves the invariant.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Consider any optimal f ∈ OPT.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Before this update, the invariant holds.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, we have mu ≤ fu.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, Lemma 3.4 implies that fu ≤ fv .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Therefore, after setting mv ← mu, we still have mv ≤ fv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Finally, observe that after step (b), the coordinates of ~m can take at most n distinct values.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, after each update in step (c), one coordinate of ~m must increase strictly.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, this procedure will terminate.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We next argue that ~m is an optimal solution by checking that it satisfies the conditions in Lemma 3.4.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Condition (a).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Observe that for each v ∈ L∗, mv is initialized to f∗v .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Afterwards the value mv could only be increased.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"However, because the invariant holds when the procedure terminates, it must be the case that mv = f∗v at the end.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Condition (b).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The procedure makes sure that at the end of
step (b), for every active edge e ∈ E∗, minv∈He mv can be attained by some vertex in L∗. Since only mv for v /∈ L∗ can be increased in step (c), it follows that in the end, the minimum can still be attained by some vertex in L∗.
Next, consider u ∈ Te, where e ∈ E∗. For any optimal solution f , Lemma 3.3 implies that fu ≤ f∗(Se).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, the invariant implies thatmu ≤ fu ≤ f∗(Se).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Since condition (a) holds, this means that maxv∈Te mv can be attained by some vertex in L∗.
Condition (c).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This is clearly satisfied because of the while-termination condition.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Therefore, we have ~m ∈ OPT, as required.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The proof for the upper confidence vector ~M is similar.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We omit the detailed proof and just give the corresponding procedure to return ~M .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(a) Initialization.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For v ∈ L∗, set Mv := f∗v ; for v /∈ L∗, set Mv := +1.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(b) Preserving Active Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For each v /∈ L∗, set Mv ← min{Mv,mine∈E∗:v∈Te f∗(Se)}.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(c) Preserving Inactive Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
While there is an inactive edge e /∈ E∗,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"such that u ∈ Te, v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He and Mu > Mv , set Mu ←Mv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The same argument can show that for any optimal f ∈ OPT, we have f ≤ ~M .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, we also have ~M ∈ OPT.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"As mentioned before, the proof of Lemma 3.5 implicitly gives a procedure to compute the confidence vectors from any optimal solution.",3.2. Computing the Confidence Interval,[0],[0]
"For the special case of undirected hypergraphs, a simplified version of the procedure is given in Algorithm 2.
",3.2. Computing the Confidence Interval,[0],[0]
"Alternatively, we can try to solve the convex program (CP1), for example using Algorithm 5 in Section 4, from two initial feasible solutions to heuristically estimate the confidence vectors.",3.2. Computing the Confidence Interval,[0],[0]
"In Algorithm 3, one instance approaches an optimal solution from high f values and the other from low f values.",3.2. Computing the Confidence Interval,[0],[0]
Resolving Ties.,4. Subgradient Method via Markov Operator,[0],[0]
Observe that Φ : RN → R is differentiable at fN ∈ RN that has distinct coordinates.,4. Subgradient Method via Markov Operator,[0],[0]
"For the purpose of computing a subgradient, we assume that there is some global ordering π on V to resolve ties among coordinates with the same value.",4. Subgradient Method via Markov Operator,[0],[0]
"In particular, the vertices in L having label +1 are the highest, and those in L labeled −1 are the lowest.",4. Subgradient Method via Markov Operator,[0],[0]
"Hence, in this section, we may assume that any arg max or arg min operator over a subset of vertices
Algorithm 2 Confidence Intervals for Undirected Hypergraphs
1: Input: Undirected hypergraph H = (V,E,w), label vector f∗L and tolerance ≥ 0.",4. Subgradient Method via Markov Operator,[0],[0]
"2: Let f be a solution of (CP1), either by Algorithm 5 or by PDHG method (Hein et al., 2013) 3: For all v ∈ V , set p(v)← v, mv ← −1, Mv ← +1.",4. Subgradient Method via Markov Operator,[0],[0]
"4: Ê := {e ∈ E : ∆e(f) ≤ } 5: while ∃e1 6= e2 ∈ Ê, e1 ∩ e2 6= ∅",4. Subgradient Method via Markov Operator,[0],[0]
"do 6: Ê ← (Ê \ {e1, e2}) ∪ {e1 ∪ e2} 7: end while 8: for each e ∈ Ê do 9: x← an arbitrary vertex in e
10: for each vertex v ∈ e do 11: p(v)← p(x) 12: end for 13: end for 14: for each vertex v ∈ L do 15: mp(v) ← f∗v , Mp(v) ← f∗v 16: end for 17: for each edge e ∈ E such that ∆e(f) >",4. Subgradient Method via Markov Operator,[0],[0]
do 18: for each vertex v ∈,4. Subgradient Method via Markov Operator,[0],[0]
e,4. Subgradient Method via Markov Operator,[0],[0]
"do 19: mp(v) ← max{mp(v), f(Ie)} 20: Mp(v) ← min{Mp(v), f(Se)} 21: end for 22: end for 23: for each vertex v ∈ V do 24: mv ← mp(v), Mv ←Mp(v) 25: end for 26: return vectors (~m, ~M)
will return a unique vertex.
",4. Subgradient Method via Markov Operator,[0],[0]
"We next define a Markov operator that is inspired from the diffusion processes on hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016) in the context of defining Laplacians.",4. Subgradient Method via Markov Operator,[0],[0]
"We denote the projection operator ΠN : RV → RN that takes f ∈ RV and returns the restricted vector fN ∈ RN .
",4. Subgradient Method via Markov Operator,[0],[0]
Lemma 4.1 For f ∈,4. Subgradient Method via Markov Operator,[0],[0]
"[−1, 1]V that is feasible in (CP1), the Markov operator Mf given in Algorithm 4 returns a subgradient of Φ : RN → R at fN .
",4. Subgradient Method via Markov Operator,[0],[0]
"Proof: (Sketch) Observe that if fN ∈ RN has distinct coordinates, then Φ is differentiable at fN , and Mf gives exactly the gradient (which is the only possible subgradient in this case).",4. Subgradient Method via Markov Operator,[0],[0]
"Observe that in our subgradient method application, we could imagine that at every iteration, infinitesimal perturbation is performed on the current solution to ensure that all coordinates are distinct, and ties are resolved according to our global ordering π.
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 3 Estimate confidence interval 1: Input: Directed hypergraph H = (V,E,w), labels f∗L
for labeled vertices L 2: Construct feasible f (0,+)N ← +1 ∈ RN with all entries
being +1; 3: Construct feasible f (0,−)N ← −1 ∈",4. Subgradient Method via Markov Operator,[0],[0]
"RN with all entries
being −1; 4: ~M ← SGM(f (0,+)N ); 5: ~m← SGM(f (0,−)N ); 6: return the vectors (~m, ~M)
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 4 Markov Operator M : RV → RN
1: Input: Directed hypergraph H = (V,E,w), feasible f ∈ RV for (CP1) 2: Construct symmetric matrix A ∈ RV×V ; set A← 0.",4. Subgradient Method via Markov Operator,[0],[0]
3: for each e ∈ E such that ∆e(f) > 0,4. Subgradient Method via Markov Operator,[0],[0]
do 4: u← arg maxu∈Te fu; 5: v ← arg minv∈He fv; 6: Auv ← Auv + we; 7: (The same is done forAvu becauseA is symmetric.),4. Subgradient Method via Markov Operator,[0],[0]
"8: end for 9: Construct diagonal matrix W ∈ RN×N ; set W ← 0.
10: for each u ∈ N",4. Subgradient Method via Markov Operator,[0],[0]
do 11:,4. Subgradient Method via Markov Operator,[0],[0]
"Wuu ← ∑ v∈V Auv; 12: end for 13: return (WΠN −ΠNA)f
Hence, as the magnitude of the perturbation tends to zero, if the global ordering π is preserved, then the gradient remains the same, which implies that the gradient is also the subgradient when the perturbation reaches 0.
",4. Subgradient Method via Markov Operator,[0],[0]
"Using the Markov operator M as a subroutine to generate a subgradient, we have the following subgradient method (SGM) (Shor et al., 1985).
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 5 Subgradient Method SGM(f (0)N ∈ RN ) 1: Input: Directed hypergraph H = (V,E,w) with la-
bels f∗L for labeled vertices L, initial feasible solution f (0) N ∈",4. Subgradient Method via Markov Operator,[0],[0]
"RN , step size {ηt := 1 t }t≥1
2: t← 1; 3: (Throughout the algorithm, f (t)L = f ∗ L is given by the
labeled vertices.)",4. Subgradient Method via Markov Operator,[0],[0]
4: while Solution f (t)N has not “stabilized” do 5: g(t)N ← Mf (t−1) ∈ RN ; 6: f (t)N = f (t−1) N,4. Subgradient Method via Markov Operator,[0],[0]
"− ηt ·
g (t)",4. Subgradient Method via Markov Operator,[0],[0]
"N∥∥∥g(t)N ∥∥∥
2
;
7: t← t+ 1; 8: end while 9: return f (t)
",4. Subgradient Method via Markov Operator,[0],[0]
Stabilizing Condition.,4. Subgradient Method via Markov Operator,[0],[0]
"Our experiments in Section 5 suggest that it suffices to run the solver for a short time, after which a better feasible solution f does not improve the prediction accuracy.",4. Subgradient Method via Markov Operator,[0],[0]
Our experiments are run on a standard PC.,5. Experimental Results,[0],[0]
"In our graphs, each point refers to a sample mean, and the height of the vertical bar is the standard error of the mean.",5. Experimental Results,[0],[0]
"We show that our treatment of hypergraphs performs better than the previously best method in (Hein et al., 2013).
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Hypergraph Model.,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We use three datasets from the UCI Machine Learning Repository (Lichman, 2013): mushroom, covertype45 and covertype67.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"As in (Hein et al., 2013), each dataset fits into the hypergraph learning model in the following way.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Each entry in the dataset corresponds to a vertex, which is labeled either +1 or −1.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Moreover, each entry has some categorical attributes.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each attribute and each realized value for that attribute, we form a unit-weight hyperedge containing all the vertices corresponding to entries having that attribute value.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"To summarize, below are the properties of the resulting hypergraphs.
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Dataset mushroom covertype45 covertype67
n = |V",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"| 8124 12240 37877 m = |E| 112 104 123 k =∑
e∈E |e| m
1523 1412 3695
Semi-supervised Learning Framework.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We compare our semi-supervised learning framework with that in (Hein et al., 2013), which was previously the best (compared to (Zhou et al., 2006), for instance).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0.9563325181765007],"['With increasing complexity of models for tasks like classification (Joulin et al., 2016), machine comprehension (Rajpurkar et al., 2016; Seo et al., 2017), and visual question answering (Zhu et al., 2016), models are becoming increasingly challenging to debug, and to determine whether they are ready for deployment.']"
"Specifically, we compare the prediction accuracy of the following two prediction algorithms.
1.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Confidence Interval (CI).,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We use hard constraints (CP1) and confidence intervals for prediction, as described in Algorithm 1 in Section 3. 2.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Hein et al. We implement the method described in (Hein et al., 2013), which uses soft constraints (regularized version), plus 5-fold cross validation to determine the regularization parameter.
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Testing Methodology.,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Since we focus on prediction accuracy, using either subgradient method or PDHG (Hein et al., 2013) for solving the underlying convex programs in each algorithm produces the same results.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each algorithm candidate, we try different sizes of labeled vertices L, where l = |L| ranges from 20 to 200.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each size l
of labeled vertices, we randomly pick l vertices from the dataset to form the set L and treat the rest as unlabeled vertices; we re-sample if only one label (+1 or −1) appears in L. For each size",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"l, we perform 100 trials to report the average error rate together with its standard error.
Results.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Our experiment can recover the results reported in (Hein et al., 2013).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"The test error for the two algorithms on the three datasets is presented in Figure 5.1, which shows that our CI method consistently has lower test error than the one in (Hein et al., 2013).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Different Solvers.,5.2. Comparing Running Times of Solvers,[0],[0]
"We compare the running times of the following two convex program solvers:
• Subgradient Method (SG), proposed by us.",5.2. Comparing Running Times of Solvers,[0],[0]
"Empirically, the step size ηt := 1
(t+1) min( 0.16t 105 ,1)
gives good
performance.",5.2. Comparing Running Times of Solvers,[0],[0]
"For large t, ηt grows like 1t and so the method converges; however, for small t, we would like a larger step size to speed up convergence.",5.2. Comparing Running Times of Solvers,[0],[0]
"• Primal-Dual Hybrid Gradient (PDHG), proposed in (Hein et al., 2013).",5.2. Comparing Running Times of Solvers,[0],[0]
"We choose σ = τ = 1√
1+d ,
where d is the maximum degree.
",5.2. Comparing Running Times of Solvers,[0],[0]
Theoretical Analysis.,5.2. Comparing Running Times of Solvers,[0],[0]
"Given a hypergraph with n vertices and m edges, where the average size of an edge is k, each vertex on average appears in mkn edges.",5.2. Comparing Running Times of Solvers,[0],[0]
"For SG, we use a heap-based data structure to maintain the vertices within a hyperedge.",5.2. Comparing Running Times of Solvers,[0],[0]
"Vertices attaining the maximum and the minimum value within a hyperedge can be retrieved in O(1) time, and a value update takes O(log k) time.",5.2. Comparing Running Times of Solvers,[0],[0]
"In each iteration, at most 2m vertices will have their values updated.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, in each iteration, SG takes time 2m·mkn ·O(log k) = O(m
2k n log k).",5.2. Comparing Running Times of Solvers,[0],[0]
"In the description of PDHG in (Hein et al., 2013), each iteration takesO(mk log k) time.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, when n m, each iteration of SG will be significantly faster, although in general, the number of iterations required by the subgradient method can be larger than that for PDHG.
",5.2. Comparing Running Times of Solvers,[0],[0]
Testing Methodology.,5.2. Comparing Running Times of Solvers,[0],[0]
"In each experiment, we consider the hypergraph from one of the above three datasets.",5.2. Comparing Running Times of Solvers,[0],[0]
"We pick l = 160 vertices at random as the labeled vertices L, and form the corresponding convex program (CP1) for the two solvers, where the initial values for unlabeled vertices are chosen independently to be uniformly at random from [−1, 1].",5.2. Comparing Running Times of Solvers,[0],[0]
"To compare the performance, we run the two solvers on the same convex program, and record each trajectory of the objective value versus the time duration.",5.2. Comparing Running Times of Solvers,[0],[0]
"According to experience, 100 seconds is good enough for either solver to reach an almost optimal solution, and we use the minimum value achieved by the two solvers after 100 seconds as an estimate for the true optimal value OPT.",5.2. Comparing Running Times of Solvers,[0],[0]
"Then, we scan each trajectory, and for each relative gap
∈ {10−i : i = 1, 2, . . .",5.2. Comparing Running Times of Solvers,[0],[0]
", 6}, we find the smallest time T ( ) after which the objective value is at most OPT away from the estimate OPT.",5.2. Comparing Running Times of Solvers,[0],[0]
Each instance of the experiment is repeated 100 times (with different sets of labeled vertices) to obtain an average of those T ( )’s and their standard error.,5.2. Comparing Running Times of Solvers,[0],[0]
"For each relative gap , we also report the test error for using a feasible solution that is OPT away from the presumed optimal value OPT.
Results.",5.2. Comparing Running Times of Solvers,[0],[0]
Both solvers have similar performance.,5.2. Comparing Running Times of Solvers,[0],[0]
"As predicted by our theoretical analysis, we see in Figure 5.2 that SG has an advantage when the number n of vertices is much larger than the number m of edges, which is the case for the the last dataset covertype67.",5.2. Comparing Running Times of Solvers,[0],[0]
"Moreover, in Figure 5.3, we see that achieving a relative gap smaller than 10−4 has almost no effect on improving the prediction accuracy.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, we can conclude that for either solver, it takes roughly 10 to 20 seconds to produce a solution for the underlying convex program that can give good predic-
tion accuracy.",5.2. Comparing Running Times of Solvers,[0],[0]
DBLP Dataset.,5.3. Directed Hypergraph: More Powerful,[0],[0]
"We use the DBLP (Ley, 2009) dataset.",5.3. Directed Hypergraph: More Powerful,[0],[0]
Each paper is represented by a vertex.,5.3. Directed Hypergraph: More Powerful,[0],[0]
"We include papers from year 2000 to 2015 from conferences belonging to the following research areas to conduct our experiments:
• 7049 papers from machine learning (ML): NIPS, ICML • 2539 papers from theoretical computer science (TCS): STOC, FOCS • 3374 papers from database (DB): VLDB, SIGMOD
We perform the following prediction tasks: (a) ML (+1) vs TCS (-1), and (b) ML (+1) vs DB (-1).
",5.3. Directed Hypergraph: More Powerful,[0],[0]
The details of the experiment setup and the results are given in the full version.,5.3. Directed Hypergraph: More Powerful,[0],[0]
We revisit semi-supervised learning on hypergraphs.,abstractText,[0],[0]
"Same as previous approaches, our method uses a convex program whose objective function is not everywhere differentiable.",abstractText,[0],[0]
"We exploit the non-uniqueness of the optimal solutions, and consider confidence intervals which give the exact ranges that unlabeled vertices take in any optimal solution.",abstractText,[0],[0]
"Moreover, we give a much simpler approach for solving the convex program based on the subgradient method.",abstractText,[0],[0]
"Our experiments on real-world datasets confirm that our confidence interval approach on hypergraphs outperforms existing methods, and our sub-gradient method gives faster running times when the number of vertices is much larger than the number of edges.",abstractText,[0],[0]
Re-revisiting Learning on Hypergraphs:  Confidence Interval and Subgradient Method,title,[0],[0]
"The Fisher Information Metric (FIM) I(Θ) = (Iij) of a statistical parametric model p(x |Θ) of order D is defined by a D×D positive semidefinite (psd) matrix (I(Θ) 0) with coefficients Iij = Ep [ ∂l ∂Θi ∂l ∂Θj ] , where l(Θ) denotes the log-density function log p(x |Θ).",1. Fisher Information Metric,[0],[0]
"Under light regularity conditions, FIM can be rewritten equivalently as
Iij = −Ep",1. Fisher Information Metric,[0],[0]
"[ ∂2l
∂Θi∂Θj
] = 4 ∫ ∂ √ p(x |Θ) ∂Θi ∂ √ p(x |Θ) ∂Θj dx.
",1. Fisher Information Metric,[0],[0]
"As its empirical counterpart, the observed FIM (Efron & Hinkley, 1978) with respect to (wrt) a sample set Xn = {xk}nk=1 is Î(Θ |Xn) = −∇2l(Θ",1. Fisher Information Metric,[0],[0]
"|Xn), which is often evaluated at the maximum likelihood estimate Θ = Θ̂(Xn).",1. Fisher Information Metric,[0],[0]
"By the law of large numbers, Î(Θ) converges to the (expected) FIM I(Θ) as n→∞.
1King Abdullah University of Science and Technology (KAUST), Saudi Arabia 2École Polytechnique, France 3Sony Computer Science Laboratories Inc., Japan.",1. Fisher Information Metric,[0],[0]
"Correspondence to: Ke Sun <sunk@ieee.org>, Frank Nielsen <Frank.Nielsen@acm.org>.
",1. Fisher Information Metric,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Fisher Information Metric,[0],[0]
"Copyright 2017 by the author(s).
",1. Fisher Information Metric,[0],[0]
The FIM is not invariant and depends on the parameterization.,1. Fisher Information Metric,[0],[0]
We can optionally write I(Θ) as IΘ(Θ) to emphasize the coordinate system.,1. Fisher Information Metric,[0],[0]
"By definition, IΘ(Θ) = JᵀIΛ(Λ)J where J = (Jij), Jij = ∂Λi∂Θj is the Jacobian matrix.",1. Fisher Information Metric,[0],[0]
"For example, the FIM of regular natural exponential families (NEFs) l(Θ) = Θᵀt(x)",1. Fisher Information Metric,[0],[0]
− F (Θ) (loglinear models with sufficient statistics t(x)) is I(Θ),1. Fisher Information Metric,[0],[0]
"= ∇2F (Θ) 0, the Hessian of the log-normalizer function F (Θ).",1. Fisher Information Metric,[0],[0]
"Although exponential families can approximate arbitrarily any smooth density (Cobb et al., 1983), the lognormalizer function may not be available in closed-form nor computationally tractable (Montanari, 2015).
",1. Fisher Information Metric,[0],[0]
The FIM is an important concept for statistical machine learning.,1. Fisher Information Metric,[0],[0]
"It gives a Riemannian metric (Hotelling, 1929; Rao, 1945) of the learning parameter space which is unique (Čencov, 1982; Dowty, 2017).",1. Fisher Information Metric,[0],[0]
"Hence any learning is in a space that is intrinsically curved based on the FIM, regardless of the choice of the coordinate system.",1. Fisher Information Metric,[0],[0]
"It also gives a bound (Fréchet, 1943; Cramér, 1946; Nielsen, 2013) of learning efficiency saying that the variance of any unbiased learning of Θ is at least I−1(Θ)/n, where n is the i.i.d. sample size.",1. Fisher Information Metric,[0],[0]
"The FIM is applied to neural network optimization (Amari, 1997), metric learning (Lebanon, 2005), reinforcement learning (Thomas, 2014) and manifold learning (Sun & Marchand-Maillet, 2014).
",1. Fisher Information Metric,[0],[0]
However computing the FIM is expensive.,1. Fisher Information Metric,[0],[0]
"Besides the fact that learning machines have often singularities (Watanabe, 2009) (|I(Θ)| = 0, not full rank) characterized by plateaux in gradient learning, computing/estimating the FIM of a large neuron system (e.g. one with millions of parameters, Szegedy, Christian et al. 2015) is very challenging due to the finiteness of data, and the huge number D(D+1)2 of matrix coefficients to evaluate.",1. Fisher Information Metric,[0.9511602279467766],"['We turn instead to paraphrasing based on neural machine translation (Lapata et al., 2017), where P (x′|x) (the probability of a paraphrase x′ given original sentence x) is proportional to translating x into multiple pivot languages and then taking the score of back-translating the translations into the original language.']"
"Furthermore, gradient descent techniques require inverting this large matrix and tuning the learning rate.
",1. Fisher Information Metric,[0],[0]
"To tackle this problem, past works mainly focus on how to approximate the FIM with a block diagonal form (Kurita, 1994; Le Roux et al., 2008; Martens, 2010; Pascanu & Bengio, 2014; Martens & Grosse, 2015) or quasi-diagonal form (Ollivier, 2013; Marceau-Caron & Ollivier, 2016).",1. Fisher Information Metric,[0],[0]
"This global approach faces increasing approximation error and increasing computational cost as the system scales up
and as complex and dynamic structures (Looks et al., 2017) emerge.
",1. Fisher Information Metric,[0],[0]
This work aims at a different local approach.,1. Fisher Information Metric,[0],[0]
"The idea is to accurately describe the information geometry (IG) in a subsystem of the large learning system, which is invariant to the scaling up and structural change of the global system, so that the local machinery, including optimization, can be discussed regardless of the other parts.
",1. Fisher Information Metric,[0],[0]
"For this purpose, a novel concept, the Relative Fisher Information Metric (RFIM), is defined.",1. Fisher Information Metric,[0],[0]
"Unlike the traditional geometric view of a high-dimensional parameter manifold, RFIMs defines multiple projected low-dimensional geometries of subsystems.",1. Fisher Information Metric,[0],[0]
This geometry is correlated to the parameters beyond the subsystem and is therefore considered dynamic.,1. Fisher Information Metric,[0],[0]
It can be used to characterize the efficiency of a local learning process.,1. Fisher Information Metric,[0],[0]
Taking this stance has potential in deep learning because a deep neural network can be decomposed into many local components such as neurons or layers.,1. Fisher Information Metric,[0],[0]
The RFIM is well suited to the compositional block structures of neural networks.,1. Fisher Information Metric,[0],[0]
"The RFIM can be used for out-of-core learning.
",1. Fisher Information Metric,[0],[0]
The paper is organized as follows.,1. Fisher Information Metric,[0],[0]
Sec. 2 reviews natural gradient within the context of Multi-Layer Perceptrons (MLPs).,1. Fisher Information Metric,[0],[0]
"Sec. 3 formally defines the RFIM, and gives a table of RFIMs of several commonly used subsystems.",1. Fisher Information Metric,[0],[0]
Sec. 4 discusses the advantages of using the RFIM as compared to the FIM. Sec. 5 gives an algorithmic framework and proof-of-concept experiments on neural network optimization.,1. Fisher Information Metric,[0],[0]
Sec. 6 presents related works on parameter diagonalization.,1. Fisher Information Metric,[0],[0]
Sec. 7 concludes this work and further hints at perspectives.,1. Fisher Information Metric,[0],[0]
"Consider a MLP x θ1−→ h1 · · ·hL−1 θL−−→ y, whose statistical model is the following conditional distribution
p(y |x,Θ) = ∑
h1,··· ,hL−1
p(h1 |x,θ1) · · · p(y |hL−1,θL).
",2. Natural Gradient: Review and Insights,[0],[0]
"The often intractable sum over h1, · · · ,hL−1 can be get rid off by deteriorating p(h1 |x,θ1), · · · , p(hL−1 |hL−2,θL−1) to Dirac’s deltas δ, and letting merely the last layer p(y |hL−1,θL) be stochastic.",2. Natural Gradient: Review and Insights,[0],[0]
"Other models such as restricted Boltzmann machines (Nair & Hinton, 2010; Montavon & Müller, 2012), deep belief networks (Hinton et al., 2006), dropout (Wager et al., 2013), and variational autoencoders (Kingma & Welling, 2014) do consider the hi’s to be stochastic.
",2. Natural Gradient: Review and Insights,[0],[0]
"The tensor metric of the neuromanifold (Amari, 1995) M, consisting of all MLPs with the same architecture but different parameter values, is locally defined by the FIM.",2. Natural Gradient: Review and Insights,[0],[0]
"Because a MLP corresponds to a con-
ditional distribution, its FIM is a function of the input x. By taking an empirical average over the input samples {xk}nk=1, the FIM of a MLP can be expressed as IΘ(Θ) = 1n",2. Natural Gradient: Review and Insights,[0],[0]
"∑n k=1Ep(y |xk,Θ) [ ∂lk ∂Θ ∂lk ∂Θᵀ ] , where lk(Θ) = log p(y |xk, Θ) denotes the conditional log-likelihood function wrt xk.
",2. Natural Gradient: Review and Insights,[0],[0]
"To understand the meaning of the Riemannian metric IΘ(Θ), it measures the intrinsic difference between two nearby neural networks around Θ ∈ M. A learning step can be regarded as a tiny displacement δΘ",2. Natural Gradient: Review and Insights,[0],[0]
onM.,2. Natural Gradient: Review and Insights,[0],[0]
"According to the FIM, the infinitesimal square distance
〈δΘ, δΘ〉IΘ(Θ) = 1
n n∑ k=1 Ep(y |xk,Θ)
[( δΘᵀ
∂lk ∂Θ )",2. Natural Gradient: Review and Insights,[0],[0]
"2] (1)
measures how much δΘ",2. Natural Gradient: Review and Insights,[0],[0]
"(with a radius constraint) is statistically along ∂l∂Θ , or equivalently how much δΘ affects intrinsically the conditional distribution p(y |x, Θ).
",2. Natural Gradient: Review and Insights,[0],[0]
Consider the negative log-likelihood function L(Θ) =,2. Natural Gradient: Review and Insights,[0],[0]
"− ∑n k=1 log p(yk |xk,Θ) wrt the observed pairs {(xk,yk)}nk=1, we try to minimize the loss while maintaining a small learning step size 〈δΘ, δΘ〉IΘ(Θ) on M. At Θt ∈ M, the target is to minimize wrt δΘ",2. Natural Gradient: Review and Insights,[0],[0]
"the Lagrange function
L(Θt + δΘ)",2. Natural Gradient: Review and Insights,[0],[0]
"+ 1
2γ 〈δΘ, δΘ〉IΘ(Θt)
",2. Natural Gradient: Review and Insights,[0],[0]
"≈ L(Θt) + δΘᵀ 5Θ L(Θt) + 1
2γ δΘᵀIΘ(Θt)δΘ,
where γ > 0 is a learning rate.",2. Natural Gradient: Review and Insights,[0],[0]
"The optimal solution of the above quadratic optimization gives a learning step
δΘt = −γI−1Θ (Θt)5Θ L(Θt).
",2. Natural Gradient: Review and Insights,[0],[0]
"In this update procedure, ∇̃ΘL(Θ) = I−1Θ (Θ)5Θ L(Θ) replaces the role of the usual gradient ∇ΘL(Θ) and is called the natural gradient (Amari, 1997).
",2. Natural Gradient: Review and Insights,[0],[0]
"Although the FIM depends on the chosen parameterization, the natural gradient is invariant to reparameterization.",2. Natural Gradient: Review and Insights,[0],[0]
Let Λ be another coordinate system and J be the Jacobian matrix of the mapping,2. Natural Gradient: Review and Insights,[0],[0]
"Θ→ Λ. Then we have
I−1Θ (Θ)5Θ L(Θ) =",2. Natural Gradient: Review and Insights,[0],[0]
"(J ᵀIΛ(Λ)J)−1 Jᵀ 5Λ L(Λ)
",2. Natural Gradient: Review and Insights,[0],[0]
"= J−1I−1Λ (Λ)5Λ L(Λ),
showing that ∇̃ΘL(Θ) and ∇̃ΛL(Λ) are the same dynamic up to coordinate transformation.",2. Natural Gradient: Review and Insights,[0],[0]
"As the learning rate γ is not infinitesimal in practice, natural gradient descent actually depends on the coordinate system (see e.g. Martens 2014).",2. Natural Gradient: Review and Insights,[0],[0]
"Other intriguing properties of natural gradient optimization lie in being free from getting trapped in plateaux of the error surface, and attaining Fisher efficiency in online learning (see Sec. 4 Amari 1998).
",2. Natural Gradient: Review and Insights,[0],[0]
"MΘ
Θ yx
Mθ1
x
x+ ∆x
θ1x
Mθ2h1
h1 + ∆h1
θ2h1
Mθ3
h2
h2 + ∆h2
θ3h2",2. Natural Gradient: Review and Insights,[0],[0]
"y
Model:
Manifold:
Computational graph:
Metric:
Θ
Θ I(Θ)
θ3 h2
θ3
h2
gy(θ3)
",2. Natural Gradient: Review and Insights,[0],[0]
"θ2 h1
θ2
h1
gh2(θ2)
θ1
θ1 gh1(θ1)
p(y |Θ,x) =",2. Natural Gradient: Review and Insights,[0],[0]
"∑ h1 ∑ h2 p(h1 |θ1,x) p(h2 |θ2,h1) p(y |θ3,h2)
",2. Natural Gradient: Review and Insights,[0],[0]
Figure 1.,2. Natural Gradient: Review and Insights,[0],[0]
(left),2. Natural Gradient: Review and Insights,[0],[0]
The traditional global geometry of a MLP; (right) information geometry of subsystems.,2. Natural Gradient: Review and Insights,[0],[0]
The gray and blue meshes show that the subsystem geometry is dynamic when the reference variable makes a tiny move.,2. Natural Gradient: Review and Insights,[0],[0]
"The square under the (sub-)system means the (R-)FIM is computed by (i) computing the FIM in the traditional way wrt all free parameters that affect the system output; (ii) choosing a sub-block that contains only the internal parameters of the (sub-)system and regarding the remaining variables as the reference.
",2. Natural Gradient: Review and Insights,[0],[0]
"For the sake of simplicity, we do not discuss singular FIMs with a subset of parameters having zero metric.",2. Natural Gradient: Review and Insights,[0],[0]
"This set of parameters forms an analytic variety (Watanabe, 2009), and technically the MLP as a statistical model is said to be non-regular (and the parameter Θ is not identifiable).",2. Natural Gradient: Review and Insights,[0],[0]
"The natural gradient has been extended (Thomas, 2014) to cope with singular FIMs having positive semi-definite matrices by taking the Moore-Penrose pseudo-inverse (that coincides with the inverse matrix for full rank matrices).
",2. Natural Gradient: Review and Insights,[0],[0]
"In the family of 2nd-order optimization methods, a fuzzy line can be drawn from the natural gradient and alternative methods such as the Hessian-free optimization (Martens, 2010).",2. Natural Gradient: Review and Insights,[0],[0]
"By definition, the FIM is a property of the parameter space which is independent or weakly dependent on the input samples.",2. Natural Gradient: Review and Insights,[0],[0]
"For example, the FIM of a MLP is independent of {yi}.",2. Natural Gradient: Review and Insights,[0],[0]
"In contrast, the Hessian (or related concepts such as the Gauss-Newton matrix, Martens 2014) is a property of the learning cost function wrt the input samples.
",2. Natural Gradient: Review and Insights,[0],[0]
"Bonnabel (Bonnabel, 2013) proposed to use the Riemannian exponential map to define a gradient descent step, thus ensuring to stay on the manifold for any chosen learning rate.",2. Natural Gradient: Review and Insights,[0],[0]
Convergence is proven for Hadamard manifolds (of negative curvatures).,2. Natural Gradient: Review and Insights,[0],[0]
"However, it is not mathematically tractable to express the exponential map of hierarchical model manifolds like the neuromanifold.",2. Natural Gradient: Review and Insights,[0],[0]
"In general, for large parametric systems, it is impossible to diagonalize or decorrelate all the parameters, so that we split instead all random variables into three parts θf , θ and h.",3. RFIM: Definition and Expressions,[0],[0]
We examine their intuitive meanings before giving the formal definition.,3. RFIM: Definition and Expressions,[0],[0]
"The reference, θf , consists of the majority of the random variables that are considered fixed (therefore allowing us to simplify the analysis).",3. RFIM: Definition and Expressions,[0.9513519570797673],"['For each rule, we display two example questions with the corresponding SEA, the prediction (with corresponding change) and the percentage of “flips” - instances previously predicted correctly on the validation data, but predicted incorrectly after the application of the rule.']"
This is in analogy to the notion of a reference frame in physics.,3. RFIM: Definition and Expressions,[0],[0]
"θ is the
subsystem parameters, resembling the long-term memory adapting slowly to the observations (e.g. neural network weights).",3. RFIM: Definition and Expressions,[0],[0]
The response h is a random variable that reacts to the variations of θ.,3. RFIM: Definition and Expressions,[0],[0]
"Usually, h is the output of the subsystem that is connected to neighbour subsystems (e.g. hidden layer outputs).",3. RFIM: Definition and Expressions,[0],[0]
"Formally, a subsystem which factorizes the learning machine is characterized by the conditional distribution p(h |θ,θf ), where θ can be estimated based on h and θf .",3. RFIM: Definition and Expressions,[0],[0]
We make the following definition.,3. RFIM: Definition and Expressions,[0],[0]
Definition 1 (RFIM).,3. RFIM: Definition and Expressions,[0],[0]
"Given θf , the RFIM 1 of θ wrt h is
gh (θ |θf )",3. RFIM: Definition and Expressions,[0],[0]
"def = Ep(h | θ, θf ) [ ∂
∂θ log p(h |θ, θf )
∂
∂θᵀ log p(h |θ, θf )
] ,
or simply gh (θ), corresponding to the estimation of θ based on observations of h given θf .
",3. RFIM: Definition and Expressions,[0],[0]
"For example, consider a MLP.",3. RFIM: Definition and Expressions,[0],[0]
"If we choose θf to be the input features x, choose h to be the final output y, and choose θ to be all the network weights Θ, then the RFIM becomes the FIM: I(Θ) = gy(Θ |x).
",3. RFIM: Definition and Expressions,[0],[0]
"More generally, we can choose the response h to be other than the observables to compute the Fisher information of subsystems, especially dynamically during the learning of the global machine.",3. RFIM: Definition and Expressions,[0.9621216848894449],"['On both datasets, the automated method or humans were able to generate adversaries at the exclusion of the other roughly one third of the time, which indicates that they do not generate the same adversaries.']"
"To see the meaning of the RFIM, similar to eq.",3. RFIM: Definition and Expressions,[0],[0]
"(1), the infinitesimal square distance 〈δθ, δθ〉gh(θ) =",3. RFIM: Definition and Expressions,[0],[0]
"Ep(h | θ, θf ) [( δθᵀ ∂∂θ log p(h |θ, θf )
)2] measures how much δθ impacts intrinsically the stochastic mapping θ → h which features the subsystem.",3. RFIM: Definition and Expressions,[0],[0]
"We have the following proposition following definition 1.
",3. RFIM: Definition and Expressions,[0],[0]
Proposition 2 (Relative Geometry Consistency).,3. RFIM: Definition and Expressions,[0],[0]
"If θ1 consists of a subset of θ2 so that θ2 = (θ1, θ̃1), then ∀θ̃1, Mθ1 with the metric gh(θ1 | θ̃1) has exactly the same Rie-
1We use the same term “relative FIM” (Zegers, 2015) with a different definition.
",3. RFIM: Definition and Expressions,[0],[0]
"mannian metric with the sub-manifold {θ2 ∈ Mθ2 : θ̃1 is fixed} induced by the ambient metric gh (θ2).
",3. RFIM: Definition and Expressions,[0],[0]
"When the response h is chosen, then different splits of (θ,θf ) are consistent with the same ambient geometry.
",3. RFIM: Definition and Expressions,[0],[0]
"Figure 1 shows the traditional global geometry of a learning system, where the curvature is defined by the learner’s parameter sensitivity to the external environment (x and y), as compared to the information geometry of subsystems, where the curvature is defined by the parameter sensitivity wrt hidden interface variables h.",3. RFIM: Definition and Expressions,[0],[0]
"The two-colored meshes show that the geometry structure is dynamic and varies with the reference variable θf .
",3. RFIM: Definition and Expressions,[0],[0]
"One should not confuse the RFIM with the diagonal blocks of the FIM (Kurita, 1994).",3. RFIM: Definition and Expressions,[0],[0]
Both their meanings and expressions are different.,3. RFIM: Definition and Expressions,[0],[0]
The RFIM is computed by integrating out the hidden response variables h.,3. RFIM: Definition and Expressions,[0],[0]
The FIM is always computed by integrating out the observables x and y.,3. RFIM: Definition and Expressions,[0],[0]
Hence the RFIM is a more general concept and includes the FIM as a special case.,3. RFIM: Definition and Expressions,[0],[0]
"This highlights a main difference with the backpropagated metric (Ollivier, 2013), which essentially considers parameter sensitivity wrt the final output.",3. RFIM: Definition and Expressions,[0],[0]
"Despite the fact that the FIMs of small parametric structures such as single neurons was studied (Amari, 1997), we are not looking at a small single-component system but a component embedded in a large system, targeting at improving the large system.
",3. RFIM: Definition and Expressions,[0],[0]
"In the following we provide a short table of commonly used RFIMs for future reference (the RFIMs listed are mostly straightforward from definition 1, with detailed derivations given in the supplementary material).",3. RFIM: Definition and Expressions,[0],[0]
This is meaningful since the RFIM is a new concept.,3. RFIM: Definition and Expressions,[0],[0]
We also want to demonstrate these simple closed form expressions without any approximations.,3. RFIM: Definition and Expressions,[0],[0]
We start from the RFIM of single neuron models.,3.1. RFIMs of One Neuron,[0],[0]
"Consider a stochastic neuron with input x and weights w. After a nonlinear activation function f , the output y is randomized surrounding the mean f(wᵀx̃) with a variance.",3.1. RFIMs of One Neuron,[0],[0]
"Throughout this paper x̃ = (xᵀ, 1)ᵀ denotes the augmented vector of x (homogeneous coordinates) so that wᵀx̃ contains a bias term, and a general linear transformation can be written simply asAx̃.
Using x as the reference, the RFIM of w with respect to y has a common form gy(w |x)",3.1. RFIMs of One Neuron,[0],[0]
"= νf (w,x)x̃x̃ᵀ, where νf (w,x) is a positive coefficient with large values in the linear region, or the effective learning zone of the neuron.",3.1. RFIMs of One Neuron,[0],[0]
"This agrees with early studies on single neuron FIMs (Amari, 1997; Kurita, 1994).
",3.1. RFIMs of One Neuron,[0],[0]
"If f(t) = tanh(t) is the hyperbolic tangent func-
tion, then νf (w,x) = sech2(wᵀx̃), where sech(t) = 2 exp(t)+exp(−t) is the hyperbolic secant function.",3.1. RFIMs of One Neuron,[0],[0]
"Similarly, if f(t) = sigm(t) is the sigmoid function, then νf (w,x) = sigm (w ᵀx̃)",3.1. RFIMs of One Neuron,[0],[0]
"[ 1− sigm (wᵀx̃) ] .
",3.1. RFIMs of One Neuron,[0],[0]
"If f is defined by Parametric Rectified Linear Unit (PReLU) (He et al., 2015), which includes Rectified Linear Unit (ReLU) (Nair & Hinton, 2010) as a special case, so that f(t) = t (t ≥ 0), f(t) = ιt (t < 0), 0 ≤ ι < 1, then under certain approximations (see supplementary material)
",3.1. RFIMs of One Neuron,[0],[0]
"νf (w,x) =
[ ι+ (1− ι)sigm",3.1. RFIMs of One Neuron,[0],[0]
"( 1− ι ω wᵀx̃ )]2 ,
where ω > 0 is a hyper-parameter (e.g. ω = 1).
",3.1. RFIMs of One Neuron,[0],[0]
"For the exponential linear unit (ELU) (Clevert et al., 2015), f(t) = t (t ≥ 0), f(t) = α (exp(t)− 1) (t < 0), where α > 0 is a hyper-parameter.",3.1. RFIMs of One Neuron,[0],[0]
"We get
νf (w,x) =",3.1. RFIMs of One Neuron,[0],[0]
{ 1 if wᵀx̃ ≥ 0 α2 exp (2wᵀx̃),3.1. RFIMs of One Neuron,[0],[0]
if wᵀx̃ < 0.,3.1. RFIMs of One Neuron,[0],[0]
Let D denote the dimensionality of the corresponding variable.,3.2. RFIM of One Layer,[0],[0]
"A linear layer with input x, connection weights W =",3.2. RFIM of One Layer,[0],[0]
"[ w1, · · · ,wDy ] , and stochastic output y can be represented by y ∼ G(W ᵀx̃, σ2I), where I is the identity matrix, and σ is the scale of the observation noise, and G(µ,Σ) is a multivariate Gaussian distribution with mean µ and covariance matrix Σ. We vectorize W by stacking its columns {wi}.",3.2. RFIM of One Layer,[0],[0]
"Then gy(W |x) is a tensor of size (Dx + 1)Dy× (Dx + 1)Dy , given by gy(W |x)",3.2. RFIM of One Layer,[0],[0]
"= diag [x̃x̃ᵀ, · · · , x̃x̃ᵀ], where diag(·) means the (block) diagonal matrix constructed by the given matrix entries.
",3.2. RFIM of One Layer,[0],[0]
"A nonlinear layer increments a linear layer by adding an element-wise activation function applied on W ᵀx̃, and then randomized wrt the choice of the neuron.",3.2. RFIM of One Layer,[0],[0]
"By definition 1, its RFIM is given by
gy (",3.2. RFIM of One Layer,[0],[0]
W |x) =,3.2. RFIM of One Layer,[0],[0]
"diag [ νf (w1,x)x̃x̃ ᵀ, · · · , νf (wm,x)x̃x̃ᵀ ] , (2)
where νf (wi,x) is given in Subsec.",3.2. RFIM of One Layer,[0],[0]
"3.1.
",3.2. RFIM of One Layer,[0],[0]
"A softmax layer, which often appears as the last layer of a MLP, is given by y ∈ {1, . . .",3.2. RFIM of One Layer,[0],[0]
",m}, where p(y) = ηy = exp(wyx̃)∑m i=1 exp(wix̃) .",3.2. RFIM of One Layer,[0],[0]
"Its RFIM is a dense matrix given by
gy(W )",3.2. RFIM of One Layer,[0],[0]
=  (η1 − η21)x̃x̃ᵀ · · · −η1ηmx̃x̃ᵀ −η2η1x̃x̃ᵀ · · · −η2ηmx̃x̃ᵀ ... . .,3.2. RFIM of One Layer,[0],[0]
".
...",3.2. RFIM of One Layer,[0],[0]
−ηmη1x̃x̃ᵀ · · · (ηm − η2m)x̃x̃ᵀ  .,3.2. RFIM of One Layer,[0],[0]
Notice that its i’th diagonal block (ηi − η2i ),3.2. RFIM of One Layer,[0],[0]
x̃x̃ᵀ resembles the RFIM of a single sigm neuron.,3.2. RFIM of One Layer,[0],[0]
"By eq. (2), the one-layer RFIM is a product metric (Jost, 2011) and does not consider the inter-neuron correlations, which must be obtained by looking at a larger subsystem.",3.3. RFIM of Two Layers,[0],[0]
"Consider a two-layer model with stochastic output y around the mean vector f(Cᵀh̃), where h = f (W ᵀx̃).",3.3. RFIM of Two Layers,[0],[0]
"For simplicity, we ignore inter-layer correlations between the first layer and the second layer and focus on the interneuron correlations within the first layer.",3.3. RFIM of Two Layers,[0],[0]
"To do this, both x and C are considered as references to compute the RFIM of W .",3.3. RFIM of Two Layers,[0],[0]
"By definition 1, gy(W |x,C) =",3.3. RFIM of Two Layers,[0],[0]
"[Gij ]Dh×Dh and each block has the form
Gij = Dy∑ l=1 cilcjlνf (cl,h)νf (wi,x)νf (wj ,x)x̃x̃ ᵀ.
Now that we have the one-layer and two-layer RFIMs, we can either split a given feed-forward neural network into one-layer subsystems or into two-layer subsystems.",3.3. RFIM of Two Layers,[0],[0]
"A trade-off is that using a larger subsystem entails greater analytical and computational difficulty, although it could more accurately model the global system dynamics.",3.3. RFIM of Two Layers,[0],[0]
"In the extreme case, the FIM is obtained if the whole system is considered as one single subsystem.",3.3. RFIM of Two Layers,[0],[0]
This section discusses the theoretical advantages of the RFIM over the FIM.,4. RFIM: Key Advantages,[0],[0]
"Consider wlog a MLP with Bernoulli outputs y ∈ {0, 1}m, whose mean µ is a deterministic function depending on the input x and the network parameters Θ. By Sec. 2, the FIM of the MLP can be computed as (see supplementary for proof)
I(Θ)",4. RFIM: Key Advantages,[0],[0]
= 1 n n∑ i=1,4. RFIM: Key Advantages,[0],[0]
"m∑ j=1
1 µj(xi)(1− µj(xi))",4. RFIM: Key Advantages,[0],[0]
"∂µj(xi) ∂Θ ∂µj(xi) ∂Θᵀ .
",4. RFIM: Key Advantages,[0],[0]
(3) Therefore rank(I(Θ)),4. RFIM: Key Advantages,[0],[0]
≤,4. RFIM: Key Advantages,[0],[0]
nm.,4. RFIM: Key Advantages,[0],[0]
The rank of a diagonal block of I(Θ) corresponding to one layer is even smaller.,4. RFIM: Key Advantages,[0],[0]
"In a deep neural network (e.g. Szegedy, Christian et al. 2015), if the sample size n < dim(Θ)/m, then I(Θ) is doomed to be singular.",4. RFIM: Key Advantages,[0],[0]
All methods trying to approximate the FIM suffer from this problem and therefore rely on proper regularizations.,4. RFIM: Key Advantages,[0],[0]
"If the network is decomposed into layers, the RFIM of each subsystem (layer) is given by eq.",4. RFIM: Key Advantages,[0],[0]
(2).,4. RFIM: Key Advantages,[0],[0]
Each sample can contribute maximally 1 to the rank of the neuron-RFIM and can contribute maximally Dy to the rank of the layer-RFIM.,4. RFIM: Key Advantages,[0],[0]
"It only requires maxi{dim(wi)} (the maximum layer width) observations to have a full rank RFIM, where wi is the weight vector of the i’th neuron.",4. RFIM: Key Advantages,[0],[0]
The RFIM is expected to have a much higher rank than the FIM.,4. RFIM: Key Advantages,[0],[0]
Higher rank means less singularity and more information is captured.,4. RFIM: Key Advantages,[0],[0]
"Models that can
be distinguished by the RFIM may be identical in the sense of the FIM.",4. RFIM: Key Advantages,[0],[0]
"Essentially, the RFIM integrates the internal randomness (Bengio, 2013) of the neural system by considering the output of each layer as a random variable.",4. RFIM: Key Advantages,[0],[0]
"In theory, the FIM should also consider stochastic neurons.",4. RFIM: Key Advantages,[0],[0]
"However it requires marginalizing the joint distribution of h1, h2, · · · , y. This makes the already infeasible computation even more challenging.
",4. RFIM: Key Advantages,[0],[0]
"The RFIM is not an approximation of the FIM but is an accurate metric, defining the geometry of θ wrt to its direct response h in the system, or adjacent nodes in a graphical model.",4. RFIM: Key Advantages,[0],[0]
By the example in fig.,4. RFIM: Key Advantages,[0],[0]
"1, gy(θL) of the last layer is exactly the corresponding block in I(Θ): they both characterize how θL affects the mapping hL−1",4. RFIM: Key Advantages,[0],[0]
→ y. They start to diverge from the second to last layer.,4. RFIM: Key Advantages,[0],[0]
"To compute the geometry of θL−1, the RFIM looks at how θL−1 affects the local mapping hL−2 → hL−1, which can be measured reliably regardless of the rest of the system (think of a “debugging” process to separate and measure a single component).",4. RFIM: Key Advantages,[0],[0]
"In contrast, the FIM examines how θL−1 affects the non-local mapping hL−2 → y.",4. RFIM: Key Advantages,[0],[0]
This is a difficult task because it must consider the correlation between different layers.,4. RFIM: Key Advantages,[0],[0]
"As an approximation, the block diagonalized version of the FIM ignores such correlations and therefore faces the loss of accuracy.
",4. RFIM: Key Advantages,[0],[0]
The RFIM makes it possible to maintain global system stability so that the intrinsic variations of different subsystems are balanced during learning.,4. RFIM: Key Advantages,[0],[0]
Consider a set of interconnected subsystems with internal parameters {θl} and the corresponding response variables {hl}.,4. RFIM: Key Advantages,[0],[0]
The RFIM ghl(θl) measures how much the likelihood surface of hl is curved wrt a small learning step δθl.,4. RFIM: Key Advantages,[0],[0]
"By constraining the squared Riemannian distance δθᵀl g
hl(θl)δθl having similar scales, different subsystems will present similar variations during learning.",4. RFIM: Key Advantages,[0],[0]
"Within one subsystem, the learning along sensitive parameter directions is penalized.",4. RFIM: Key Advantages,[0],[0]
"Among different subsystems, the learning of sensitive subsystems is penalized.",4. RFIM: Key Advantages,[0],[0]
"Globally, the inter-subsystem stochastic connections have similar variance, maintaining a stable reference system and achieving efficient learning.",4. RFIM: Key Advantages,[0],[0]
"This is similar to the idea of batch normalization (BN) (Ioffe & Szegedy, 2015) but has a deeper theoretical foundation.
",4. RFIM: Key Advantages,[0],[0]
"Formally, we have the following theorem.
",4. RFIM: Key Advantages,[0],[0]
Theorem 3.,4. RFIM: Key Advantages,[0],[0]
"Consider a learning system represented by a joint distribution p(x,h) of x (observables) and h (hidden variables which connect subsystems).",4. RFIM: Key Advantages,[0],[0]
"The joint FIM J (Θ) = Ep ( log p(x,h |Θ) ∂Θ",4. RFIM: Key Advantages,[0],[0]
"log p(x,h |Θ) ∂Θᵀ ) has a block diagonal form.",4. RFIM: Key Advantages,[0],[0]
"Each block isEp(gh(θ)), where θ is the parameters within a subsystem and h is its response variables to neighour subsystems.
",4. RFIM: Key Advantages,[0],[0]
"The global correspondence of the local RFIM is the joint
FIM.",4. RFIM: Key Advantages,[0],[0]
"By theorem 3, the square distance dΘᵀJ (Θ)dΘ = Ep( ∑ l dθ ᵀ l g hl(θl)dθl) measures the system variance, including both the observables x and the hidden variables h.",4. RFIM: Key Advantages,[0],[0]
An intrinsic trade-off between the RFIM and the FIM is learning system stability versus efficiency.,4. RFIM: Key Advantages,[0],[0]
"Normalizing the FIM is more efficient because it helps to achieve Fisher efficiency (Amari, 1998).",4. RFIM: Key Advantages,[0],[0]
"Normalizing the RFIM is more stable since the hidden variations are bounded, which only guarantees subsystem Fisher efficiency characterized by the Cramér-Rao lower bound of local parameters.",4. RFIM: Key Advantages,[0],[0]
The traditional non-parametric way of applying natural gradient requires re-calculating the FIM and solving a large linear system in each learning step.,5. Relative Natural Gradient Descent,[0],[0]
"Besides the huge computational cost, it has a large approximation error.",5. Relative Natural Gradient Descent,[0],[0]
"For example during online learning, a mini-batch of samples cannot faithfully reflect the “true” geometry, which has to integrate the risk of sample variations.",5. Relative Natural Gradient Descent,[0],[0]
"That is, the FIM of a mini-batch is likely to be singular or poorly conditioned.
",5. Relative Natural Gradient Descent,[0],[0]
"A recent series of efforts (Montavon & Müller, 2012; Raiko et al., 2012; Desjardins et al., 2015) are gearing towards a parametric approach to applying natural gradient, which memorizes and learns a geometry.",5. Relative Natural Gradient Descent,[0],[0]
"For example, natural neural networks (Desjardins et al., 2015) augment each layer with a redundant linear layer, and let these linear layers parametrize the geometry of the neural manifold.
",5. Relative Natural Gradient Descent,[0],[0]
"By dividing the learning system into subsystems, the RFIM potentially gives a systematical implementation of parametric natural gradient descent.",5. Relative Natural Gradient Descent,[0],[0]
"The memory complexity of storing the Riemannian metric has been reduced from O(D2) to O( ∑ iD 2 i ), where Di = dim(wi) is the size of the i’th neuron.",5. Relative Natural Gradient Descent,[0],[0]
"Consider there are M neurons in total, then the memory cost is reduced by a factor of M .",5. Relative Natural Gradient Descent,[0],[0]
"The computational complexity has been reduced from O(D%) (% ≈ 2.373, Williams 2012) to O( ∑ iD % i ).",5. Relative Natural Gradient Descent,[0],[0]
"Optimization based on RFIM is called Relative Natural Gradient Descent (RNGD).
",5. Relative Natural Gradient Descent,[0],[0]
"The good performance of batch normalization (Ioffe & Szegedy, 2015) provides an empirical support for the RFIM.",5. Relative Natural Gradient Descent,[0],[0]
"Basically, BN uses an inter-sample normalization layer to transform the layer input x to z with zero mean and unit variance and thus reduces “internal covariate shift”.",5. Relative Natural Gradient Descent,[0],[0]
"In a typical case, above this normalization layer is a linear layer given by y = W ᵀz̃.",5. Relative Natural Gradient Descent,[0],[0]
"If each dimension of z is normalized, then the diagonal blocks of the linear layer RFIM gy(W )",5. Relative Natural Gradient Descent,[0],[0]
"= diag[z̃z̃ᵀ, · · · , z̃z̃ᵀ] become a covariance matrix with identity diagonal entries (after taking an empirical average).",5. Relative Natural Gradient Descent,[0],[0]
"This gives the coordinate system W a well conditioned RFIM for efficient learning.
5.1.",5. Relative Natural Gradient Descent,[0],[0]
"RNGD with a relu MLP
",5. Relative Natural Gradient Descent,[0],[0]
This subsection builds a proof-of-concept experiment on MLP optimization.,5. Relative Natural Gradient Descent,[0],[0]
We partition the MLP into layers (one layer consists of a linear layer plus an element-wise nonlinear activation function) as the subsystems.,5. Relative Natural Gradient Descent,[0],[0]
"By eq. (2), the RFIM of layer l (l = 1, · · · , L) with input hl−1 (h0 = x) and weights {wl1, · · · ,wlml} is
diag [ νf (wl1,hl−1)h̃l−1h̃ ᵀ l−1, · · · , νf (wlml ,hl−l)h̃l−1h̃ ᵀ l−1 ] .
",5. Relative Natural Gradient Descent,[0],[0]
The subsystem stability during one learning step δw can be measured geometrically by∑L l=1 ∑ml i=1,5. Relative Natural Gradient Descent,[0],[0]
"νf (wli,hl−1)(δw ᵀ lih̃l−1)
2.",5. Relative Natural Gradient Descent,[0],[0]
"Using this term as the geometric cost (the Lagrange term) in the trust region approach in Sec. 2, we get the following RNGD method.",5. Relative Natural Gradient Descent,[0],[0]
"In a stochastic gradient descent scenario, each neuron i in layer l is updated by
wnewli ← woldli −G−1li ∂E
∂wli ,
where E is the cost function and Gli is a learned metric.",5. Relative Natural Gradient Descent,[0],[0]
"The consideration is that a mini-batch of samples do not contain enough information to compute the RFIM, which should be averaged over all training samples.",5. Relative Natural Gradient Descent,[0],[0]
"Therefore, for the i’th neuron in layer l, Gli is initialized to identity, and is updated based on
Gnewli ← (1− λ)Goldli + λνf (wli,hl−1)h̃l−1h̃ ᵀ",5. Relative Natural Gradient Descent,[0],[0]
l−1,5. Relative Natural Gradient Descent,[0],[0]
+,5. Relative Natural Gradient Descent,[0],[0]
"I,
where > 0 is a hyper-parameter to avoid singularity caused by small sample size, and the average is taken over all samples in a mini-batch, and λ is a learning rate.",5. Relative Natural Gradient Descent,[0],[0]
"In theory, λ should be gradually reduced to zero to guarantee the convergence of this geometry learning.",5. Relative Natural Gradient Descent,[0],[0]
"To avoid solving a linear system in each iteration, every T iterations we recompute and store G−1li based on the most updated Gli.",5. Relative Natural Gradient Descent,[0],[0]
"In the next T iterations, this G−1li will be used as an approximation of the inverse RFIM.",5. Relative Natural Gradient Descent,[0],[0]
"For the input layer which scales with the number of input features, and the final softmax layer, we apply instead the RFIM of the corresponding linear layer to improve the computational efficiency.
",5. Relative Natural Gradient Descent,[0],[0]
We compare different optimizers on classifying MNIST digits.,5. Relative Natural Gradient Descent,[0],[0]
"The network has shape 784-80-80-80-10, with relu activation units, a final soft-max layer, and uses the persample average cross-entropy with L2-regularization as the learning cost function.",5. Relative Natural Gradient Descent,[0],[0]
"We experiment on two different architectures: one is a plain MLP (PLAIN); the other has a batch normalization layer after each hidden layer (BNA), where a rescaling parameter is applied to ensure enough flexibility of the parametric structure (Ioffe & Szegedy, 2015).",5. Relative Natural Gradient Descent,[0],[0]
"For simplicity, the architecture, mini-batch size (50), and L2 regularization strength (10−3) are fixed to be the same for all compared methods.",5. Relative Natural Gradient Descent,[0],[0]
"The observations are consistent when these configurations vary.
",5. Relative Natural Gradient Descent,[0],[0]
Figure 2 shows the learning curves of different methods.,5. Relative Natural Gradient Descent,[0],[0]
SGD is stochastic gradient descent.,5. Relative Natural Gradient Descent,[0],[0]
"ADAM is the Adam optimizer (Kingma & Ba, 2014) with β1 = 0.9, β2 = 0.999 and = 10−8.",5. Relative Natural Gradient Descent,[0],[0]
"Our RNGD is implemented by modifying TensorFlow’s (Abadi, Martı́n",5. Relative Natural Gradient Descent,[0],[0]
"et al., 2015) SGD optimizer.",5. Relative Natural Gradient Descent,[0],[0]
"We set empirically T = 100, λ = 0.005 and ω = 1.
RNGD presents a sharper learning curve and better generalization, especially when it is combined with BN.",5. Relative Natural Gradient Descent,[0],[0]
"In this case, the final tranining error of RNGD is slightly larger than ADAM because by validation it favors a larger learning rate, which is applied on the neural network weights (based on RNGD) and BN parameters (based on SGD).",5. Relative Natural Gradient Descent,[0],[0]
"For the ReLU activation, νf (wi,x) is approximately binary, emphasizing such informative samples with wᵀi x̃ > 0, which are the ones contributing to the learning of wi with non-zero gradient values.",5. Relative Natural Gradient Descent,[0],[0]
Each output neuron has a different subset of informative samples.,5. Relative Natural Gradient Descent,[0],[0]
"RNGD normalizes x differently wrt different output neurons, so that the in-
formative samples for each output neuron are centered and decorrelated.
",5. Relative Natural Gradient Descent,[0],[0]
"In the above experiment, RNGD’s computational time per each epoch is roughly 4 ∼ 10 times more than SGD and ADAM on a modern graphic card.",5. Relative Natural Gradient Descent,[0],[0]
Therefore in terms of wall clock time RNGD does not show advantages.,5. Relative Natural Gradient Descent,[0],[0]
This can be improved by more efficient implementations with low rank approximation techniques and early stopping.,5. Relative Natural Gradient Descent,[0],[0]
Our RNGD prototype hints at a promising direction to develop scalable 2nd-order deep learning optimizers based on the RFIM.,5. Relative Natural Gradient Descent,[0],[0]
One may ponder whether we can always find a suitable parameterization that yields a diagonal FIM that is straightforward to invert.,6. Related Works on FIM Diagonalization,[0],[0]
This fundamental problem of parameter orthogonalization was first investigated by Jeffreys (1998) for decorrelating the parameters of interest from the nuisance parameters.,6. Related Works on FIM Diagonalization,[0],[0]
"Fisher diagonalization yields parameter orthogonalization (Cox & Reid, 1987), and is proved useful when estimating Θ̂ using a maximum likelihood estimator (MLE) that is asymptotically normally distributed, Θ̂n ∼ G(Θ, I−1(Θ)/n), and efficient since the variance of the estimator matches the Cramér-Rao lower bound.",6. Related Works on FIM Diagonalization,[0],[0]
"Using the chain rule, this amounts to find a suitable parameterization Ω = Ω(Θ) satisfying∑
",6. Related Works on FIM Diagonalization,[0],[0]
"i,j
E
[ ∂2l
∂Θi∂Θj ] ∂Θi",6. Related Works on FIM Diagonalization,[0],[0]
"∂Ωk ∂Θj ∂Ωl = 0, ∀k 6=",6. Related Works on FIM Diagonalization,[0],[0]
"l.
Thus in general, we end up with ( D 2 ) = D(D−1)2 (nonlinear) partial differential equations to satisfy (Huzurbazar, 1950).",6. Related Works on FIM Diagonalization,[0],[0]
"Therefore, in general there is no solution when( D 2 )",6. Related Works on FIM Diagonalization,[0],[0]
"> D, that is when D > 3.",6. Related Works on FIM Diagonalization,[0],[0]
"When D = 2, the single differential equation is usually solvable and tractable, and the solution may not be unique: For example, Huzurbazar (1950) reports two orthogonalization schemes for the location-scale families { 1σp0( x−µ σ )} that include the Gaussian family and the Cauchy family.",6. Related Works on FIM Diagonalization,[0],[0]
"Sometimes, the structure of the differential equation system yields a solution: For example, Jeffreys (1998) reported a parameter orthogonalization for Pearson’s distributions of type I which is of orderD = 4.",6. Related Works on FIM Diagonalization,[0],[0]
"Cox and Reid (1987) further investigated this topic with application to conditional inference, and provide examples (including the Weibull distribution).
",6. Related Works on FIM Diagonalization,[0],[0]
"From the viewpoint of geometry, the FIM induces a Riemannian manifold with metric tensor g(Θ) = I(Θ).",6. Related Works on FIM Diagonalization,[0],[0]
"When the FIM may be degenerate, this yields a pseudoRiemannian manifold (Thomas, 2014).",6. Related Works on FIM Diagonalization,[0],[0]
"In differential geometry, orthogonalization amounts to transforming the square length infinitesimal element gijdΘiΘj of a Riemannian geometry into an orthogonal system ω with match-
ing square length infinitesimal element ΩiidΩ2i .",6. Related Works on FIM Diagonalization,[0],[0]
"However, such a global orthogonal metric does not exist (Huzurbazar, 1950)",6. Related Works on FIM Diagonalization,[0],[0]
"when D > 3 for an arbitrary metric tensor, although interesting Riemannian parameterization structures may be derived in Riemannian 4D geometry (Grant & Vickers, 2009).
",6. Related Works on FIM Diagonalization,[0],[0]
"For NEFs, the FIM can be made block-diagonal easily by using the mixed coordinate system (Amari, 2016) (Θ1:k,Hk+1:D), where H = Ep[t(x)] = ∇F (Θ) is the moment parameter, for any k ∈ {1, ..., D − 1}, where vb:e denotes the subvector (vb, ..., ve)ᵀ of v. The geometry of NEFs is a dually flat structure (Amari, 2016) induced by the convex mgf, the potential function.",6. Related Works on FIM Diagonalization,[0],[0]
"It defines a dual affine coordinate systems ei = ∂i = ∂∂Hi and ej = ∂
j = ∂∂Θj that are orthogonal: 〈ei, ej〉 = δij , where δij = 1 iff i = j and δij = 0 otherwise.",6. Related Works on FIM Diagonalization,[0],[0]
Hence the FIM has two diagonal blocks.,6. Related Works on FIM Diagonalization,[0],[0]
"Those dual affine coordinate systems are defined up to an affine invertible transformation: Θ̃ = AΘ + b, H̃ = A−1H + c.",6. Related Works on FIM Diagonalization,[0],[0]
"In particular, for any order-2 NEF (D = 2), we can always obtain two mixed parameterizations (Θ1, H2) or (H1,Θ2).
",6. Related Works on FIM Diagonalization,[0],[0]
The RFIM contributes another line of thought in parameter diagonalization.,6. Related Works on FIM Diagonalization,[0],[0]
"We investigate the Fisher information of hidden variables, or internal interfaces in the learning machine.",6. Related Works on FIM Diagonalization,[0],[0]
"This is novel since the majority of previous works concentrate on the FIM of the observables, or the external interface of the machine.",6. Related Works on FIM Diagonalization,[0],[0]
"From a causality perspective, we factor out the main cause (parameters within the subsystem) of the response variable with a direct action-reaction relationship, and regard the remaining parameters as a reference that can be easily estimated by the empirical distribution.",6. Related Works on FIM Diagonalization,[0],[0]
"This simplification may lead to broader applications of Fisher information in machine learning.
",6. Related Works on FIM Diagonalization,[0],[0]
"The particular case of a mixed coordinate system (that is not an affine coordinate system) induces in information geometry (Amari, 2016) a dual pair of orthogonal e- and morthogonal foliations.",6. Related Works on FIM Diagonalization,[0],[0]
"Our splits in RFIMs consider general non-orthogonal foliations that provide the factorization decompositions of the whole manifold into submanifolds, that are the leaves of the foliation (see section 3.7 of Amari & Nagaoka 2000).",6. Related Works on FIM Diagonalization,[0],[0]
We investigate local structures of large learning systems using the new concept of Relative Fisher Information Metric.,7. Conclusion and Discussions,[0],[0]
The key advantage of this approach is that the local learning dynamics can be analyzed in an accurate way without approximation.,7. Conclusion and Discussions,[0],[0]
"We present a core list of such local structures in neural networks, and give their corresponding RFIMs.",7. Conclusion and Discussions,[0],[0]
"This list of recipes can be used to provide guiding principles to design new optimizers for deep learning.
",7. Conclusion and Discussions,[0],[0]
"Our work applies to mirror descent as well since natural gradient is related to mirror descent (Raskutti & Mukherjee, 2015) as follows:",7. Conclusion and Discussions,[0],[0]
"In mirror descent to minimize a cost function E(Θ), given a strictly convex distance function D(·, ·) in the first argument (playing the role of the proximity function), we express the gradient descent step as:
Θt+1 = arg min Θ
{ Θ>∇E(Θt) + 1
γ D(Θ,Θt)
} .
",7. Conclusion and Discussions,[0],[0]
"When D(Θ,Θ′) is chosen as a Bregman divergence BF (Θ,Θ
′) = F (Θ)− F (Θ′)− (Θ−Θ′)>∇F (Θ′) wrt to a convex function F , it has been proved that the mirror descent on the Θ-parameterization is equivalent (Raskutti & Mukherjee, 2015) to the natural gradient optimization on the induced Riemannian manifold with metric tensor (∇2F (Θ)) parameterized by the dual coordinate system H = ∇F (Θ).
",7. Conclusion and Discussions,[0],[0]
"In general, to perform a Riemannian gradient descent for minimizing a real-valued function f(Θ) on the manifold, one needs to choose a proper metric tensor given in matrix form G(Θ).",7. Conclusion and Discussions,[0],[0]
Thomas (2014) constructed a toy example showing that the natural gradient may diverge while the ordinary gradient (for G = I) converges.,7. Conclusion and Discussions,[0],[0]
"Recently, Thomas et al. (2016) proposed a new kind of descent method based on what they called the Energetic Natural Gradient that generalizes the natural gradient.",7. Conclusion and Discussions,[0],[0]
"The energy distance DE(p(Θ1), p(Θ2))2 = E[2dp(Θ1)(X,Y )",7. Conclusion and Discussions,[0],[0]
"− dp(Θ1)(X,X
′)",7. Conclusion and Discussions,[0],[0]
"− dp(Θ1)(Y, Y ′)] where X,X ′ ∼ p(Θ1) and Y, Y ′ ∼ p(Θ2), where dp(Θ1)(·, ·) is a distance metric over the support.",7. Conclusion and Discussions,[0],[0]
"Using a Taylor’s expansion on their energy distance, they get the Energy Information Matrix (in a way similar to recovering the FIM from a Taylor’s expansion of any f -divergence like the Kullback-Leibler divergence).",7. Conclusion and Discussions,[0],[0]
Their idea is to incorporate prior knowledge on the structure of the support (observation space) to define energy distance.,7. Conclusion and Discussions,[0],[0]
"Twisting the geometry of the support (say, Wasserstein’s optimal transport) with the geometry of the parametric distributions (Fisher-Rao geodesic distances) is indeed important (Chizat et al., 2015).",7. Conclusion and Discussions,[0],[0]
"In information geometry, invariance on the support is provided by a Markov morphism that is a probabilistic mapping of the support to itself (Čencov, 1982).",7. Conclusion and Discussions,[0],[0]
There is no neighbourhood structure on the support in IG.,7. Conclusion and Discussions,[0],[0]
Markov morphism includes deterministic transformation of a random variable by a statistic.,7. Conclusion and Discussions,[0],[0]
It is well-known that IT (Θ) IX(Θ) with equality iff.,7. Conclusion and Discussions,[0],[0]
T = T (X) is a sufficient statistic of X .,7. Conclusion and Discussions,[0],[0]
"Thus to get the same invariance for the energy distance (Thomas et al., 2016), one shall further require dp(Θ)(T (X), T (Y ))",7. Conclusion and Discussions,[0],[0]
"= dp(Θ)(X,Y ).
",7. Conclusion and Discussions,[0],[0]
We believe that RFIMs will provide a sound methodology to build further efficient systems for deep learning.,7. Conclusion and Discussions,[0],[0]
The full source codes to reproduce the experimental results are available at https://www.lix.polytechnique.,7. Conclusion and Discussions,[0],[0]
fr/˜nielsen/RFIM.,7. Conclusion and Discussions,[0],[0]
The authors would like to thank the anonymous reviewers and Yann Ollivier for the helpful comments.,Acknowledgements,[0],[0]
This work was mainly conducted when the first author was a postdoctoral researcher at École Polytechnique.,Acknowledgements,[0],[0]
Fisher information and natural gradient provided deep insights and powerful tools to artificial neural networks.,abstractText,[0],[0]
However related analysis becomes more and more difficult as the learner’s structure turns large and complex.,abstractText,[0],[0]
This paper makes a preliminary step towards a new direction.,abstractText,[0],[0]
"We extract a local component from a large neural system, and define its relative Fisher information metric that describes accurately this small component, and is invariant to the other parts of the system.",abstractText,[0],[0]
This concept is important because the geometry structure is much simplified and it can be easily applied to guide the learning of neural networks.,abstractText,[0],[0]
"We provide an analysis on a list of commonly used components, and demonstrate how to use this concept to further improve optimization.",abstractText,[0],[0]
1.,abstractText,[0],[0]
Fisher Information Metric The Fisher Information Metric (FIM) I(Θ) =,abstractText,[0],[0]
"(Iij) of a statistical parametric model p(x |Θ) of order D is defined by a D×D positive semidefinite (psd) matrix (I(Θ) 0) with coefficients Iij = Ep [ ∂l ∂Θi ∂l ∂Θj ] , where l(Θ) denotes the log-density function log p(x |Θ).",abstractText,[0],[0]
"Under light regularity conditions, FIM can be rewritten equivalently as Iij = −Ep [ ∂l ∂Θi∂Θj ]",abstractText,[0],[0]
Relative Fisher Information and Natural Gradient for Learning Large Modular Models,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 44–54, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.
Our model is evaluated both for accuracy in predicting target order, and for its impact on translation quality. We report significant performance gains over phrase reordering, and over two known preordering baselines for English-Japanese.",text,[0],[0]
"Preordering (Collins et al., 2005) aims at permuting the words of a source sentence s into a new order ś, hopefully close to a plausible target word order.",1 Introduction,[0],[0]
"Preordering is often used to bridge long distance reorderings (e.g., in Japanese- or GermanEnglish), before applying phrase-based models (Koehn et al., 2007).",1 Introduction,[0],[0]
"Preordering is often broken down into two steps: finding a suitable tree structure, and then finding a transduction function over it.",1 Introduction,[0],[0]
"A common approach is to use monolingual syntactic trees and focus on finding a transduction function of the sibling subtrees under the nodes (Lerner and Petrov, 2013; Xia and Mccord, 2004).",1 Introduction,[0],[0]
"The (direct correspondence) assumption
underlying this approach is that permuting the siblings of nodes in a source syntactic tree can produce a plausible target order.",1 Introduction,[0],[0]
"An alternative approach creates reordering rules manually and then learns the right structure for applying these rules (Katz-Brown et al., 2011).",1 Introduction,[0],[0]
"Others attempt learning the transduction structure and the transduction function in two separate, consecutive steps (DeNero and Uszkoreit, 2011).",1 Introduction,[0],[0]
"Here we address the challenge of learning both the trees and the transduction functions jointly, in one fell swoop, from word-aligned parallel corpora.
",1 Introduction,[0],[0]
Learning both trees and transductions jointly raises two questions.,1 Introduction,[0],[0]
How to obtain suitable trees for the source sentence and how to learn a distribution over random variables specifically aimed at reordering in a hierarchical model?,1 Introduction,[0],[0]
"In this work we solve both challenges by using the factorizations of permutations into Permutation Trees (PETs) (Zhang and Gildea, 2007).",1 Introduction,[0],[0]
"As we explain next, PETs can be crucial for exposing the hierarchical reordering patterns found in wordalignments.
",1 Introduction,[0],[0]
We obtain permutations in the training data by segmenting every word-aligned source-target pair into minimal phrase pairs; the resulting alignment between minimal phrases is written as a permutation (1:1 and onto) on the source side.,1 Introduction,[0],[0]
"Every permutation can be factorized into a forest of PETs (over the source sentences) which we use as a latent treebank for training a Probabilistic ContextFree Grammar (PCFG) tailor made for preordering as we explain next.
",1 Introduction,[0],[0]
Figure 1 shows two alternative PETs for the same permutation over minimal phrases.,1 Introduction,[0],[0]
"The nodes have labels (like P3142) which stand for local permutations (called prime permutation) over the child nodes; for example, the root label P3142 stands for prime permutation 〈3, 1, 4, 2〉, which says that the first child of the root becomes 3rd on the target side, the second becomes 1st, the third
44
becomes 4th and the fourth becomes 2nd.",1 Introduction,[0],[0]
"The prime permutations are non-factorizable permutations like 〈1, 2〉, 〈2, 1〉 and 〈2, 4, 1, 3〉.
",1 Introduction,[0],[0]
We think PETs are suitable for learning preordering for two reasons.,1 Introduction,[0],[0]
"Firstly, PETs specify exactly the phrase pairs defined by the permutation.",1 Introduction,[0],[0]
"Secondly, every permutation is factorizable into prime permutations only (Albert and Atkinson, 2005).",1 Introduction,[0],[0]
"Therefore, PETs expose maximal sharing between different permutations in terms of both phrases and their reordering.",1 Introduction,[0],[0]
"We expect this to be advantageous for learning hierarchical reordering.
",1 Introduction,[0],[0]
"For learning preordering, we first extract an initial PCFG from the latent treebank of PETs over the source sentences only.",1 Introduction,[0],[0]
We initialize the nonterminal set of this PCFG to the prime permutations decorating the PET nodes.,1 Introduction,[0],[0]
"Subsequently we split these coarse labels in the same way as latent variable splitting is learned for treebank parsing (Matsuzaki et al., 2005; Prescher, 2005; Petrov et al., 2006; Saluja et al., 2014).",1 Introduction,[0],[0]
"Unlike treebank parsing, however, our training treebank is latent because it consists of a whole forest of PETs per training instance (s).
",1 Introduction,[0],[0]
"Learning the splits on a latent treebank of PETs results in a Reordering PCFG which we use to parse input source sentences into split-decorated trees, i.e., the labels are the splits of prime permutations.",1 Introduction,[0],[0]
"After parsing s, we map the splits back on their initial prime permutations, and then retrieve a reordered version ś of s.",1 Introduction,[0],[0]
"In this sense, our latent splits are dedicated to reordering.
",1 Introduction,[0],[0]
We face two technical difficulties alien to work on latent PCFGs in treebank parsing.,1 Introduction,[0],[0]
"Firstly, as mentioned above, permutations may factorize into more than one PET (a forest) leading to a latent training treebank.1",1 Introduction,[0],[0]
"And secondly, after we parse a source string s, we are interested in ś, the permuted version of s, not in the best derivation/PET.",1 Introduction,[0],[0]
"Exact computation is a known NP-Complete problem (Sima’an, 2002).",1 Introduction,[0],[0]
"We solve this by a new Minimum-Bayes Risk decoding approach using Kendall reordering score as loss function, which is an efficient measure over permutations (Birch and Osborne, 2011; Isozaki et al., 2010a).
",1 Introduction,[0],[0]
"In summary, this paper contributes: • A novel latent hierarchical source reordering
model working over all derivations of PETs
1All PETs for the same permutation share the same set of prime permutations but differ only in bracketing structure (Zhang and Gildea, 2007).
•",1 Introduction,[0],[0]
"A label splitting approach based on PCFGs over minimal phrases as terminals, learned from an ambiguous treebank, where the label splits start out from prime permutations.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"A fast Minimum Bayes Risk decoding over
Kendall τ reordering score for selecting ś. We report results for extensive experiments on English-Japanese showing that our Reordering PCFG gives substantial improvements when used as preordering for phrase-based models, outperforming two existing baselines for this task.",1 Introduction,[0],[0]
"We aim at learning a PCFG which we will use for parsing source sentences s into synchronous trees, from which we can obtain a reordered source version ś. Since PCFGs are non-synchronous grammars, we will use the nonterminal labels to encode reordering transductions, i.e., this PCFG is implicitly an SCFG.",2 PETs and the Hidden Treebank,[0],[0]
"We can do this because s and ś are over the same alphabet.
",2 PETs and the Hidden Treebank,[0],[0]
"Here, we have access only to a word-aligned parallel corpus, not a treebank.",2 PETs and the Hidden Treebank,[0],[0]
"The following steps summarize our approach for acquiring a latent treebank and how it is used for learning a Reordering PCFG:
1.",2 PETs and the Hidden Treebank,[0],[0]
Obtain a permutation over minimal phrases from every word-alignment.,2 PETs and the Hidden Treebank,[0],[0]
2.,2 PETs and the Hidden Treebank,[0],[0]
Obtain a latent treebank of PETs by factorizing the permutations.,2 PETs and the Hidden Treebank,[0],[0]
3. Extract a PCFG from the PETs with initial nonterminals taken from the PETs.,2 PETs and the Hidden Treebank,[0],[0]
4.,2 PETs and the Hidden Treebank,[0],[0]
"Learn to split the initial nonterminals and estimate rule probabilities.
",2 PETs and the Hidden Treebank,[0],[0]
"These steps are detailed in the next section, but we will start out with an intuitive exposition of PETs, the latent treebank and the Reordering Grammar.
",2 PETs and the Hidden Treebank,[0],[0]
"Figure 1 shows examples of how PETs look like – see (Zhang and Gildea, 2007) for algorithmic details.",2 PETs and the Hidden Treebank,[0],[0]
Here we label the nodes with nonterminals which stand for prime permutations from the operators on the PETs.,2 PETs and the Hidden Treebank,[0],[0]
"For example, nonterminals P12, P21 and P3142 correspond respectively to reordering transducers 〈1, 2〉, 〈2, 1〉 and 〈3, 1, 4, 2〉.",2 PETs and the Hidden Treebank,[0],[0]
"A prime permutation on a source node µ is a transduction dictating how the children of µ are reordered at the target side, e.g., P21 inverts the child order.",2 PETs and the Hidden Treebank,[0],[0]
"We must stress that any similarity with ITG (Wu, 1997) is restricted to the fact that the straight and inverted operators of ITG are the binary case of prime permutations
in PETs (P12 and P21).",2 PETs and the Hidden Treebank,[0],[0]
"ITGs recognize only the binarizable permutations, which is a major restriction when used on the data: there are many nonbinarizable permutations in actual data (Wellington et al., 2006).",2 PETs and the Hidden Treebank,[0],[0]
"In contrast, our PETs are obtained by factorizing permutations obtained from the data, i.e., they exactly fit the range of prime permutations in the parallel corpus.",2 PETs and the Hidden Treebank,[0],[0]
"In practice we limit them to maximum arity 5.
",2 PETs and the Hidden Treebank,[0],[0]
"We can extract PCFG rules from the PETs, e.g., P21 → P12 P2413.",2 PETs and the Hidden Treebank,[0],[0]
"However, these rules are decorated with too coarse labels.",2 PETs and the Hidden Treebank,[0],[0]
"A similar problem was encountered in non-lexicalized monolingual parsing, and one solution was to lexicalize the productions (Collins, 2003) using head words.",2 PETs and the Hidden Treebank,[0],[0]
"But linguistic heads do not make sense for PETs, so we opt for the alternative approach (Matsuzaki et al., 2005), which splits the nonterminals and softly percolates the splits through the trees gradually fitting them to the training data.",2 PETs and the Hidden Treebank,[0],[0]
"Splitting has a shadow side, however, because it leads to combinatorial explosion in grammar size.
",2 PETs and the Hidden Treebank,[0],[0]
Suppose for example node P21 could split into P211 and P212 and similarly P2413 splits into P24131 and 24132.,2 PETs and the Hidden Treebank,[0],[0]
"This means that rule P21 → P12 P2413 will form eight new rules:
P211 → P121 P24131",2 PETs and the Hidden Treebank,[0],[0]
P211 → P121 P24132 P211,2 PETs and the Hidden Treebank,[0],[0]
→ P122 P24131,2 PETs and the Hidden Treebank,[0],[0]
P211 → P122 P24132 P212 → P121 P24131,2 PETs and the Hidden Treebank,[0],[0]
P212 → P121 P24132 P212 → P122 P24131,2 PETs and the Hidden Treebank,[0],[0]
"P212 → P122 P24132
Should we want to split each nonterminal into 30 subcategories, then an n-ary rule will split into 30n+1 new rules, which is prohibitively large.",2 PETs and the Hidden Treebank,[0],[0]
Here we use the “unary trick” as in Figure 2.,2 PETs and the Hidden Treebank,[0],[0]
The superscript on the nonterminals denotes the child position from left to right.,2 PETs and the Hidden Treebank,[0],[0]
"For example P2121 means that this node is a second child, and the
mother nonterminal label is P211.",2 PETs and the Hidden Treebank,[0],[0]
"For the running example rule, this gives the following rules:
P211 → P2111 P2121 P212",2 PETs and the Hidden Treebank,[0],[0]
→ P2112 P2122,2 PETs and the Hidden Treebank,[0],[0]
P2111,2 PETs and the Hidden Treebank,[0],[0]
→ P121 P2121 → P24131,2 PETs and the Hidden Treebank,[0],[0]
P2111,2 PETs and the Hidden Treebank,[0],[0]
→ P122 P2121 → P24132 P2112 → P121 P2122 → P24131,2 PETs and the Hidden Treebank,[0],[0]
P2112 → P122 P2122,2 PETs and the Hidden Treebank,[0],[0]
"→ P24132
",2 PETs and the Hidden Treebank,[0],[0]
"The unary trick leads to substantial reduction in grammar size, e.g., for arity 5 rules and 30 splits we could have had 306 = 729000000 split-rules, but with the unary trick we only have 30+302∗5 = 4530 split rules.",2 PETs and the Hidden Treebank,[0],[0]
"The unary trick was used in early lexicalized parsing work (Carroll and Rooth, 1998).2 This split PCFG constitutes a latent PCFG because the splits cannot be read of a treebank.",2 PETs and the Hidden Treebank,[0],[0]
"It must be learned from the latent treebank of PETs, as described next.",2 PETs and the Hidden Treebank,[0],[0]
"Obtaining permutations Given a source sentence s and its alignment a to a target sentence
2After applying the unary trick, we add a constraint on splitting: all nonterminals on an n-ary branching rule must be split simultaneously.
",3 Details of Latent Reordering PCFG,[0],[0]
"t in the training corpus, we segment 〈s,a, t〉 into a sequence of minimal phrases sm (maximal sequence) such that the reordering between these minimal phrases constitutes a permutation πm.",3 Details of Latent Reordering PCFG,[0],[0]
"We do not extract non-contiguous or non-minimal phrases because reordering them often involves complicated transductions which could hamper the performance of our learning algorithm.3
Unaligned words Next we describe the use of the factorization of permutations into PET forests for training a PCFG model.",3 Details of Latent Reordering PCFG,[0],[0]
But first we need to extend the PETs to allow for unaligned words.,3 Details of Latent Reordering PCFG,[0],[0]
"An unaligned word is joined with a neighboring phrase to the left or the right, depending on the source language properties (e.g., whether the language is head-initial or -final (Chomsky, 1970)).",3 Details of Latent Reordering PCFG,[0],[0]
"Our experiments use English as source language (head-initial), so the unaligned words are joined to phrases to their right.",3 Details of Latent Reordering PCFG,[0],[0]
This modifies a PET by adding a new binary branching node µ (dominating the unaligned word and the phrase it is joined to) which is labeled with a dedicated nonterminal: P01 if the unaligned word joins to the right and P10 if it joins to the left.,3 Details of Latent Reordering PCFG,[0],[0]
"We decompose the permutation πm into a forest of permutation trees PEF (πm) in O(n3), following algorithms in (Zhang et al., 2008; Zhang and Gildea, 2007) with trivial modifications.",3.1 Probability model,[0],[0]
Each PET ∆ ∈ PEF (πm) is a different bracketing (differing in binary branching structure only).,3.1 Probability model,[0],[0]
"We consider the bracketing hidden in the latent treebank, and apply unsupervised learning to induce a distribution over possible bracketings.",3.1 Probability model,[0],[0]
Our probability model starts from the joint probability of a sequence of minimal phrases sm and a permutation πm over it.,3.1 Probability model,[0],[0]
"This demands summing over all PETs ∆ in the forest PEF (πm), and for every PET also over all its label splits, which are given by the grammar derivations",3.1 Probability model,[0],[0]
"d:
P (sm, πm) = ∑
∆∈PEF (πm) ∑ d∈∆ P (d, sm) (1)
",3.1 Probability model,[0],[0]
"The probability of a derivation d is a product of probabilities of all the rules r that build it:
P (sm, πm) = ∑
∆∈PEF (πm) ∑ d∈∆ ∏ r∈d P (r) (2)
3Which differs from (Quirk and Menezes, 2006).
",3.1 Probability model,[0],[0]
"As usual, the parameters of this model are the PCFG rule probabilities which are estimated from the latent treebank using EM as explained next.",3.1 Probability model,[0],[0]
"For training the latent PCFG over the latent treebank, we resort to EM (Dempster et al., 1977) which estimates PCFG rule probabilities to maximize the likelihood of the parallel corpus instances.",3.2 Learning Splits on Latent Treebank,[0],[0]
"Computing expectations for EM is done efficiently using Inside-Outside (Lari and Young, 1990).",3.2 Learning Splits on Latent Treebank,[0],[0]
"As in other state splitting models (Matsuzaki et al., 2005), after splitting the nonterminals, we distribute the probability uniformly over the new rules, and we add to each new rule some random noise to break the symmetry.",3.2 Learning Splits on Latent Treebank,[0],[0]
"We split the non-terminals only once as in (Matsuzaki et al., 2005) (unlike (Petrov et al., 2006)).",3.2 Learning Splits on Latent Treebank,[0],[0]
For estimating the distribution for unknown words we replace all words that appear ≤ 3 times with the “UNKNOWN” token.,3.2 Learning Splits on Latent Treebank,[0],[0]
"We use CKY+ (Chappelier and Rajman, 1998) to parse a source sentence s into a forest using the learned split PCFG.",3.3 Inference,[0],[0]
"Unfortunately, computing the most-likely permutation (or alternatively ś) as in
argmax π∈Π ∑ ∆∈PEF (π) ∑ d∈∆ P (d, πm)
from a lattice of permutations Π using a PCFG is NP-complete (Sima’an, 2002).",3.3 Inference,[0],[0]
"Existing techniques, like variational decoding or MinimumBayes Risk (MBR), used for minimizing loss over trees as in (Petrov and Klein, 2007), are not directly applicable here.",3.3 Inference,[0],[0]
"Hence, we opt for minimizing the risk of making an error under a loss function over permutations using the MBR decision rule (Kumar and Byrne, 2004):
π̂ = argmin π ∑ πr Loss(π, πr)P (πr) (3)
",3.3 Inference,[0],[0]
The loss function we minimize is Kendall τ,3.3 Inference,[0],[0]
"(Birch and Osborne, 2011; Isozaki et al., 2010a) which is a ratio of wrongly ordered pairs of words (including gapped pairs) to the total number of pairs.",3.3 Inference,[0],[0]
We do Monte Carlo sampling of 10000 derivations from the chart of the s and then find the least risky permutation in terms of this loss.,3.3 Inference,[0],[0]
"We sample from the true distribution by sampling edges recursively
using their inside probabilities.",3.3 Inference,[0],[0]
"An empirical distribution over permutations P (π) is given by the relative frequency of π in the sample.
",3.3 Inference,[0],[0]
With large samples it is hard to efficiently compute expected Kendall τ loss for each sampled hypothesis.,3.3 Inference,[0],[0]
For sentence of length k and sample of size n the complexity of a naive algorithm is O(n2k2).,3.3 Inference,[0],[0]
Computing Kendall τ alone takes O(k2).,3.3 Inference,[0],[0]
"We use the fact that Kendall τ decomposes as a linear function over all skip-bigrams b that could be built for any permutation of length k:
Kendall(π, πr) = ∑ b 1− δ(π, b) k(k−1) 2 δ(πr, b) (4)
",3.3 Inference,[0],[0]
"Here δ returns 1 if permutation π contains the skip bigram b, otherwise it returns 0.",3.3 Inference,[0],[0]
"With this decomposition we can use the method from (DeNero et al., 2009) to efficiently compute the MBR hypothesis.",3.3 Inference,[0],[0]
"Combining Equations 3 and 4 we get:
π̂ = argmin π ∑ πr ∑ b 1− δ(π, b) k(k−1) 2 δ(πr, b)P (πr) (5)
",3.3 Inference,[0],[0]
"We can move the summation inside and reformulate the expected Kendall τ loss as expectation over the skip-bigrams of the permutation.
",3.3 Inference,[0],[0]
= argmin π ∑ b,3.3 Inference,[0],[0]
"(1− δ(π, b))",3.3 Inference,[0],[0]
"[∑ πr δ(πr, b)P (πr) ] (6)
= argmin π ∑ b (1− δ(π, b))EP (πr)δ(πr, b) (7)
= argmax π ∑ b δ(π, b)EP (πr)δ(πr, b) (8)
This means we need to pass through the sampled list only twice: (1) to compute expectations over skip bigrams and (2) to compute expected loss of each sampled permutation.",3.3 Inference,[0],[0]
The time complexity is O(nk2) which is quite fast in practice.,3.3 Inference,[0],[0]
We conduct experiments with three baselines:,4 Experiments,[0],[0]
• Baseline A: No preordering.,4 Experiments,[0],[0]
"• Baseline B: Rule based preordering (Isozaki
et al., 2010b), which first obtains an HPSG parse tree using Enju parser 4 and after that swaps the children by moving the syntactic head to the final position to account for different head orientation in English and Japanese.
",4 Experiments,[0],[0]
"4http://www.nactem.ac.uk/enju/
• Baseline C: LADER (Neubig et al., 2012): latent variable preordering that is based on ITG and large-margin training with latent variables.",4 Experiments,[0],[0]
"We used LADER in standard settings without any linguistic features (POS tags or syntactic trees).
",4 Experiments,[0],[0]
And we test four variants of our model:,4 Experiments,[0],[0]
• RGleft - only canonical left branching PET •,4 Experiments,[0],[0]
"RGright - only canonical right branching PET • RGITG-forest - all PETs that are binary (ITG) • RGPET-forest - all PETs.
",4 Experiments,[0],[0]
We test these models on English-Japanese NTCIR-8 Patent Translation (PATMT) Task.,4 Experiments,[0],[0]
For tuning we use all NTCIR-7 dev sets and for testing the test set from NTCIR-9 from both directions.,4 Experiments,[0],[0]
All used data was tokenized (English with Moses tokenizer and Japanese with KyTea 5) and filtered for sentences between 4 and 50 words.,4 Experiments,[0],[0]
"A subset of this data is used for training the Reordering Grammar, obtained by filtering out sentences that have prime permutations of arity > 5, and for the ITG version arity > 2.",4 Experiments,[0],[0]
Baseline C was trained on 600 sentences because training is prohibitively slow.,4 Experiments,[0],[0]
"Table 1 shows the sizes of data used.
",4 Experiments,[0],[0]
The Reordering Grammar was trained for 10 iterations of EM on train RG data.,4 Experiments,[0],[0]
We use 30 splits for binary non-terminals and 3 for non-binary.,4 Experiments,[0],[0]
Training on this dataset takes 2 days and parsing tuning and testing set without any pruning takes 11 and 18 hours respectively.,4 Experiments,[0],[0]
We test how well our model predicts gold reorderings before translation by training the alignment model using MGIZA++ 6 on the training corpus and using it to align the test corpus.,4.1 Intrinsic evaluation,[0],[0]
"Gold reorderings for the test corpus are obtained by sorting words by their average target position and (unaligned words follow their right neighboring
5http://www.phontron.com/kytea/ 6http://www.kyloo.net/software/doku.php/mgiza:overview
word).",4.1 Intrinsic evaluation,[0],[0]
"We use Kendall τ score for evaluation (note the difference with Section 3.3 where we defined it as a loss function).
",4.1 Intrinsic evaluation,[0],[0]
Table 2 shows that our models outperform all baselines on this task.,4.1 Intrinsic evaluation,[0],[0]
"The only strange result here is that rule-based preordering obtains a lower score than no preordering, which might be an artifact of the Enju parser changing the tokenization of its input, so the Kendall τ of this system might not really reflect the real quality of the preordering.",4.1 Intrinsic evaluation,[0],[0]
All other systems use the same tokenization.,4.1 Intrinsic evaluation,[0],[0]
"The reordered output of all the mentioned baselines and versions of our model are translated with phrase-based MT system (Koehn et al., 2007) (distortion limit set to 6 with distance based reordering model) that is trained on gold preordering of the training data 7 ś − t.",4.2 Extrinsic evaluation in MT,[0],[0]
"The only exception is Baseline A which is trained on original s− t.
We use a 5-gram language model trained with KenLM 8, tune 3 times with kb-mira (Cherry and Foster, 2012) to account for tuner instability and evaluated using Multeval 9 for statistical significance on 3 metrics: BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014) and TER (Snover et al., 2006).",4.2 Extrinsic evaluation in MT,[0],[0]
"We additionally report RIBES score (Isozaki et al., 2010a) that concentrates on word order more than other metrics.
",4.2 Extrinsic evaluation in MT,[0],[0]
Single or all PETs?,4.2 Extrinsic evaluation in MT,[0],[0]
In Table 3 we see that using all PETs during training makes a big impact on performance.,4.2 Extrinsic evaluation in MT,[0],[0]
"Only the all PETs variants
7Earlier work on preordering applies the preordering model to the training data to obtain a parallel corpus of guessed ś − t pairs, which are the word re-aligned and then used for training the back-end MT system (Khalilov and Sima’an, 2011).",4.2 Extrinsic evaluation in MT,[0],[0]
"We skip this, we take the risk of mismatch between the preordering and the back-end system, but this simplifies training and saves a good amount of training time.
8http://kheafield.com/code/kenlm/ 9https://github.com/jhclark/multeval
(RGITG-forest and RGPET-forest) significantly outperform all baselines.",4.2 Extrinsic evaluation in MT,[0],[0]
"If we are to choose a single PET per training instance, then learning RG from only left-branching PETs (the one usually chosen in other work, e.g. (Saluja et al., 2014)) performs slightly worse than the right-branching PET.",4.2 Extrinsic evaluation in MT,[0],[0]
This is possibly because English is mostly rightbranching.,4.2 Extrinsic evaluation in MT,[0],[0]
"So even though both PETs describe the same reordering, RGright captures reordering over English input better than RGleft.
",4.2 Extrinsic evaluation in MT,[0],[0]
All PETs or binary only?,4.2 Extrinsic evaluation in MT,[0],[0]
RGPET-forest performs significantly better than RGITG-forest (p < 0.05).,4.2 Extrinsic evaluation in MT,[0],[0]
"Non-ITG reordering operators are predicted rarely (in only 99 sentences of the test set), but they make a difference, because these operators often appear high in the predicted PET.",4.2 Extrinsic evaluation in MT,[0],[0]
"Furthermore, having these operators during training might allow for better fit to the data.
",4.2 Extrinsic evaluation in MT,[0],[0]
How much reordering is resolved by the Reordering Grammar?,4.2 Extrinsic evaluation in MT,[0],[0]
"Obviously, completely factorizing out the reordering from the translation process is impossible because reordering depends to a certain degree on target lexical choice.",4.2 Extrinsic evaluation in MT,[0],[0]
"To quantify the contribution of Reordering Grammar, we tested decoding with different distortion limit values in the SMT system.",4.2 Extrinsic evaluation in MT,[0],[0]
"We compare the phrase-based (PB) system with distance based cost function for reordering (Koehn et al., 2007) with and without preordering.
",4.2 Extrinsic evaluation in MT,[0],[0]
Figure 3 shows that Reordering Grammar gives substantial performance improvements at all distortion limits (both BLEU and RIBES).,4.2 Extrinsic evaluation in MT,[0],[0]
RGPET-forest is less sensitive to changes in decoder distortion limit than standard PBSMT.,4.2 Extrinsic evaluation in MT,[0],[0]
"The perfor-
mance of RGPET-forest varies only by 1.1 BLEU points while standard PBSMT by 4.3 BLEU points.",4.2 Extrinsic evaluation in MT,[0],[0]
Some local reordering in the decoder seems to help RGPET-forest but large distortion limits seem to degrade the preordering choice.,4.2 Extrinsic evaluation in MT,[0],[0]
"This shows also that the improved performance of RGPET-forest is not only a result of efficiently exploring the full space of permutations, but also a result of improved scoring of permutations.
",4.2 Extrinsic evaluation in MT,[0],[0]
Does the improvement remain for a decoder with MSD reordering model?,4.2 Extrinsic evaluation in MT,[0],[0]
"We compare the RGPET-forest preordered model against a decoder that uses the strong MSD model (Tillmann, 2004; Koehn et al., 2007).",4.2 Extrinsic evaluation in MT,[0],[0]
Table 4 shows that using Reordering Grammar as front-end to MSD reordering (full Moses) improves performance by 2.8 BLEU points.,4.2 Extrinsic evaluation in MT,[0],[0]
"The improvement is confirmed by METEOR, TER and RIBES.",4.2 Extrinsic evaluation in MT,[0],[0]
"Our preordering model and MSD are complementary – the Reordering Grammar captures long distance reordering, while MSD possibly does better local reorderings, especially reorderings conditioned on the lexical part of translation units.
",4.2 Extrinsic evaluation in MT,[0],[0]
"Interestingly, the MSD model (BLEU 29.6) improves over distance-based reordering (BLEU 27.8) by (BLEU 1.8), whereas the difference between these systems as back-ends to Reordering Grammar (respectively BLEU 32.4 and 32.0) is
far smaller (0.4 BLEU).",4.2 Extrinsic evaluation in MT,[0],[0]
This suggests that a major share of reorderings can be handled well by preordering without conditioning on target lexical choice.,4.2 Extrinsic evaluation in MT,[0],[0]
"Furthermore, this shows that RGPET-forest preordering is not very sensitive to the decoder’s reordering model.
",4.2 Extrinsic evaluation in MT,[0],[0]
Comparison to a Hierarchical model (Hiero).,4.2 Extrinsic evaluation in MT,[0],[0]
"Hierarchical preordering is not intended for a hierarchical model as Hiero (Chiang, 2005).",4.2 Extrinsic evaluation in MT,[0],[0]
"Yet, here we compare our preordering system (PB MSD+RG) to Hiero for completeness, while we should keep in mind that Hiero’s reordering model has access to much richer training data.",4.2 Extrinsic evaluation in MT,[0],[0]
"We will discuss these differences shortly.
",4.2 Extrinsic evaluation in MT,[0],[0]
"Table 4 shows that the difference in BLEU is not statistically significant, but there is more difference in METEOR and TER. RIBES, which concentrates more on reordering, prefers Reordering Grammar over Hiero.",4.2 Extrinsic evaluation in MT,[0],[0]
It is somewhat surprising that a preordering model combined with a phrase-based model succeeds to rival Hiero’s performance on English-Japanese.,4.2 Extrinsic evaluation in MT,[0],[0]
"Especially when looking at the differences between the two:
1.",4.2 Extrinsic evaluation in MT,[0],[0]
"Reordering Grammar uses only minimal phrases, while Hiero uses composite (longer) phrases which encapsulate internal reorderings, but also non-contiguous phrases.",4.2 Extrinsic evaluation in MT,[0],[0]
2.,4.2 Extrinsic evaluation in MT,[0],[0]
"Hiero conditions its reordering on the lexical target side, whereas the Reordering Grammar does not (by definition).",4.2 Extrinsic evaluation in MT,[0],[0]
3.,4.2 Extrinsic evaluation in MT,[0],[0]
"Hiero uses a range of features, e.g., a language model, while Reordering Grammar is a mere generative PCFG.",4.2 Extrinsic evaluation in MT,[0],[0]
"The advantages of Hiero can be brought to bear upon Reordering Grammar by reformulating it as a discriminative model.
",4.2 Extrinsic evaluation in MT,[0],[0]
Which structure is learned?,4.2 Extrinsic evaluation in MT,[0],[0]
"Figure 4 shows an example PET output showing how our model learns: (1) that the article “the” has no equivalent in Japanese, (2) that verbs go after their object, (3) to use postpositions instead of prepositions, and (4) to correctly group certain syntactic units, e.g. NPs and VPs.",4.2 Extrinsic evaluation in MT,[0],[0]
"The majority of work on preordering is based on syntactic parse trees, e.g., (Lerner and Petrov, 2013; Khalilov and Sima’an, 2011; Xia and Mccord, 2004).",5 Related work,[0],[0]
Here we concentrate on work that has common aspects with this work.,5 Related work,[0],[0]
"Neubig et
al (2012) trains a latent non-probabilistic discriminative model for preordering as an ITG-like grammar limited to binarizable permutations.",5 Related work,[0],[0]
Tromble and Eisner (2009) use ITG but do not train the grammar.,5 Related work,[0],[0]
They only use it to constrain the local search.,5 Related work,[0],[0]
DeNero and Uszkoreit (2011) present two separate consecutive steps for unsupervised induction of hierarchical structure (ITG) and the induction of a reordering function over it.,5 Related work,[0],[0]
"In contrast, here we learn both the structure and the reordering function simultaneously.",5 Related work,[0],[0]
"Furthermore, at test time, our inference with MBR over a measure of permutation (Kendall) allows exploiting both structure and reordering weights for inference, whereas test-time inference in (DeNero and Uszkoreit, 2011) is also a two step process – the parser forwards to the next stage the best parse.
",5 Related work,[0],[0]
Dyer and Resnik (2010) treat reordering as a latent variable and try to sum over all derivations that lead not only to the same reordering but also to the same translation.,5 Related work,[0],[0]
"In their work they consider all permutations allowed by a given syntactic tree.
",5 Related work,[0],[0]
"Saers et al (2012) induce synchronous grammar for translation by splitting the non-terminals, but unlike our approach they split generic nonterminals and not operators.",5 Related work,[0],[0]
Their most expressive grammar covers only binarizable permutations.,5 Related work,[0],[0]
The decoder that uses this model does not try to sum over many derivations that have the same yield.,5 Related work,[0],[0]
They do not make independence assumption like our “unary trick” which is probably the reason they do not split more than 8 times.,5 Related work,[0],[0]
"They do not compare their results to any other SMT system and test on a very small dataset.
",5 Related work,[0],[0]
"Saluja et al (2014) attempts inducing a refined Hiero grammar (latent synchronous CFG) from Normalized Decomposition Trees (NDT) (Zhang et al., 2008).",5 Related work,[0],[0]
"While there are similarities with
the present work, there are major differences.",5 Related work,[0],[0]
"On the similarity side, NDTs are decomposing alignments in ways similar to PETs, and both Saluja’s and our models refine the labels on the nodes of these decompositions.",5 Related work,[0],[0]
"However, there are major differences between the two:
• Our model is completely monolingual and unlexicalized (does not condition its reordering on the translation) in contrast with the Latent SCFG used in (Saluja et al., 2014), • Our Latent PCFG label splits are defined
as refinements of prime permutations, i.e., specifically designed for learning reordering, whereas (Saluja et al., 2014) aims at learning label splitting that helps predicting NDTs from source sentences, • Our model exploits all PETs and all deriva-
tions, both during training (latent treebank) and during inferences.",5 Related work,[0],[0]
"In (Saluja et al., 2014) only left branching NDT derivations are used for learning the model.",5 Related work,[0],[0]
•,5 Related work,[0],[0]
"The training data used by (Saluja et al., 2014)
is about 60 times smaller in number of words than the data used here; the test set of (Saluja et al., 2014) also consists of far shorter sentences where reordering could be less crucial.
",5 Related work,[0],[0]
"A related work with a similar intuition is presented in (Maillette de Buy Wenniger and Sima’an, 2014), where nodes of a tree structure similar to PETs are labeled with reordering patterns obtained by factorizing word alignments into Hierarchical Alignment Trees.",5 Related work,[0],[0]
These patterns are used for labeling the standard Hiero grammar.,5 Related work,[0],[0]
"Unlike this work, the labels extracted by (Maillette de Buy Wenniger and Sima’an, 2014) are clustered manually into less than a dozen labels without the possibility of fitting the labels to the training data.",5 Related work,[0],[0]
We present a generative Reordering PCFG model learned from latent treebanks over PETs obtained by factorizing permutations over minimal phrase pairs.,6 Conclusion,[0],[0]
Our Reordering PCFG handles non-ITG reordering patterns (up to 5-ary branching) and it works with all PETs that factorize a permutation (rather than a single PET).,6 Conclusion,[0],[0]
To the best of our knowledge this is the first time both extensions are shown to improve performance.,6 Conclusion,[0],[0]
"The empirical results on English-Japanese show that (1) when used for preordering, the Reordering PCFG helps particularly with relieving the phrase-based model from long range reorderings, (2) combined with a state-of-the-art phrase model, Reordering PCFG shows performance not too different from Hiero, supporting the common wisdom of factorizing long range reordering outside the decoder, (3) Reordering PCFG generates derivations that seem to coincide well with linguistically-motivated reordering patterns for English-Japanese.",6 Conclusion,[0],[0]
"There are various direction we would like to explore, the most obvious of which are integrating the learned reordering with other feature functions in a discriminative setting, and extending the model to deal with non-contiguous minimal phrases.",6 Conclusion,[0],[0]
This work is supported by STW grant nr. 12271 and NWO VICI grant nr. 277-89-002.,Acknowledgments,[0],[0]
We thank Wilker Aziz for comments on earlier version of the paper and discussions about MBR and sampling.,Acknowledgments,[0],[0]
"We present a novel approach for unsupervised induction of a Reordering Grammar using a modified form of permutation trees (Zhang and Gildea, 2007), which we apply to preordering in phrase-based machine translation.",abstractText,[0],[0]
"Unlike previous approaches, we induce in one step both the hierarchical structure and the transduction function over it from word-aligned parallel corpora.",abstractText,[0],[0]
"Furthermore, our model (1) handles non-ITG reordering patterns (up to 5-ary branching), (2) is learned from all derivations by treating not only labeling but also bracketing as latent variable, (3) is entirely unlexicalized at the level of reordering rules, and (4) requires no linguistic annotation.",abstractText,[0],[0]
"Our model is evaluated both for accuracy in predicting target order, and for its impact on translation quality.",abstractText,[0],[0]
"We report significant performance gains over phrase reordering, and over two known preordering baselines for English-Japanese.",abstractText,[0],[0]
Reordering Grammar Induction,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2401–2410 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Deep neural models are known to be computationally expensive to train even with fast hardware (Sutskever et al., 2014; Wu et al., 2016).",1 Introduction,[0],[0]
"For example, it takes three weeks to train a deep neural machine translation system on 100 Graphics Processing Units (GPUs) (Wu et al., 2016).",1 Introduction,[0],[0]
"Furthermore, a large amount of data is usually required to train effective neural models (Goodfellow et al., 2016; Hirschberg and Manning, 2015).
",1 Introduction,[0],[0]
Bengio et al. (2009) and Kumar et al. (2010) developed training paradigms which are inspired by the learning principle that humans can learn more effectively when training starts with easier concepts and gradually proceeds with more difficult concepts.,1 Introduction,[0],[0]
"Since these approaches are motivated by
1Our code is available at scholar.harvard.edu/ hadi/RbF/
a “starting small” strategy they are called curriculum or self-paced learning.
",1 Introduction,[0],[0]
"In this paper, we present a novel training paradigm which is inspired by the broad evidence in psychology that shows human ability to retain information improves with repeated exposure and exponentially decays with delay since last exposure (Cepeda et al., 2006; Averell and Heathcote, 2011).",1 Introduction,[0],[0]
"Spaced repetition was presented in psychology (Dempster, 1989) and forms the building block of many educational devices, including flashcards, in which small pieces of information are repeatedly presented to a learner on a schedule determined by a spaced repetition algorithm.",1 Introduction,[0],[0]
"Such algorithms show that human learners can learn efficiently and effectively by increasing intervals of time between subsequent reviews of previously learned materials (Dempster, 1989; Novikoff et al., 2012).
",1 Introduction,[0],[0]
"We investigate the analogy between training neural models and findings in psychology about human memory model and develop a spaced repetition algorithm (named Repeat before Forgetting, RbF) to efficiently and effectively train neural models.",1 Introduction,[0],[0]
The core part of our algorithm is a scheduler that ensures a given neural network spends more time working on difficult training instances and less time on easier ones.,1 Introduction,[0],[0]
"Our scheduler is inspired by factors that affect human memory retention, namely, difficulty of learning materials, delay since their last review, and strength of memory.",1 Introduction,[0],[0]
The scheduler uses these factors to lengthen or shorten review intervals with respect to individual learners and training instances.,1 Introduction,[0],[0]
"We evaluate schedulers based on their scheduling accuracy, i.e., accuracy in estimating network memory retention with respect to previously-seen instances, as well as their effect on the efficiency and effectiveness of downstream neural networks.2
2 In this paper, we use the terms memory retention, recall, and learning interchangeably.
2401
The contributions of this paper are: (1) we show that memory retention in neural networks is affected by the same (known) factors that affect memory retention in humans, (2) we present a novel training paradigm for neural networks based on spaced repetition, and (3) our approach can be applied without modification to any neural network.
",1 Introduction,[0],[0]
"Our best RbF algorithm uses 34-50% of training data per epoch while producing similar results to state-of-the-art systems on three tasks, namely sentiment classification, image categorization, and arithmetic addition.3",1 Introduction,[0],[0]
"It also runs 2.9-4.8 times faster than standard training, and outperforms competing state-of-the-art baselines.",1 Introduction,[0],[0]
"Research in psychology describes the following memory model for human learning: the probability that a human recalls a previously-seen item (e.g., the Korean translation of a given English word) depends on the difficulty of the item, delay since last review of the item, and the strength of the human memory.",2 Neural and Brain Memory Models,[0],[0]
"The relation between these indicators and memory retention has the following functional form (Reddy et al., 2016; Ebbinghaus, 1913):
Pr(recall) = exp(−difficulty × delay strength ).",2 Neural and Brain Memory Models,[0],[0]
"(1)
An accurate memory model enables estimating the time by which an item might be forgotten by a learner so that a review can be scheduled for the learner before that time.
",2 Neural and Brain Memory Models,[0],[0]
We investigate the analogy between the above memory model and memory model of artificial neural networks.,2 Neural and Brain Memory Models,[0],[0]
"Our intuition is that if the probability that a network recalls an item (e.g., correctly predicts its category) depends on the same factors (difficulty of the item, delay since last review of the item, or strength of the network), then we can develop spaced repetition algorithms to efficiently and effectively train neural networks.",2 Neural and Brain Memory Models,[0],[0]
We design a set of preliminarily experiments to directly evaluate the effect of the aforementioned factors (recall indicators) on memory retention in neural networks.,2.1 Recall Indicators,[0],[0]
"For this purpose, we use a set of training instances that are partially made available to the network during training.",2.1 Recall Indicators,[0],[0]
"This scheme
3We obtained similar results on QA tasks (Weston et al., 2016) but they are excluded due to space limit.
will allow us to intrinsically examine the effect of recall indicators on memory retention in isolation from external effects such as size of training data, number of training epochs, etc.
",2.1 Recall Indicators,[0],[0]
"We first define the following concepts to ease understanding the experiments (see Figure 1):
• First and Last review points (fRev and lRev) of a training instance are the first and last epochs in which the instance is used to train the network respectively,
• Recall point (Rec) is the epoch in which network retention is computed against some training instances; network retention is the probability that a neural network recalls (i.e. correctly classifies) a previously-seen training instance, and
• Delay since last review of a training instance is the difference between the recall point and the last review point of the training instance.
",2.1 Recall Indicators,[0],[0]
"Given training data and a neural network, we uniformly at random divide the data into three disjoint sets: a base set A, a review set B, and a replacement set C that respectively contain 80%, 10%, and 10% of the data.",2.1 Recall Indicators,[0],[0]
"As depicted in Figure 1, instances of A are used for training at every epoch, while those in B and C are partially used for training.",2.1 Recall Indicators,[0],[0]
The network initially starts to train with {A ∪ C} instances.,2.1 Recall Indicators,[0],[0]
"Then, starting from the first review point, we inject the review set B and remove C, training with {A ∪ B} instances at every epoch until the last review point.",2.1 Recall Indicators,[0],[0]
The network will then continue training with {A ∪ C} instances until the recall point.,2.1 Recall Indicators,[0],[0]
"At this point, network retention is computed against set B instances, with delay defined as the number of epochs since last review point.",2.1 Recall Indicators,[0],[0]
"The intuition behind using review and replacement sets, B and C respectively, is to avoid external effects (e.g.
size of data or network generalization and learning capability) for our intrinsic evaluation purpose.
",2.1 Recall Indicators,[0],[0]
"To conduct these experiments, we identify different neural models designed for different tasks.4 For each network, we fix the recall point to either the epoch in which the network is fully trained (i.e., obtains its best performance based on standard or “rote” training in which all instances are used for training at every iteration), or partially trained (i.e., obtains half of its best performance based on rote training).",2.1 Recall Indicators,[0],[0]
We report average results across these networks for each experiment.,2.1 Recall Indicators,[0],[0]
"As aforementioned, delay since last review of a training instance is the difference between the recall point (Rec) and the last review point (lRev) of the training instance.",2.1.1 Delay since Last Review,[0],[0]
We evaluate the effect of delay on network retention (against set B instances) by keeping the recall point fixed while moving the sliding window in Figure 1.,2.1.1 Delay since Last Review,[0],[0]
Figures 2(a) and 2(b) show average network retention across networks for the fully and partially trained recall points respectively.,2.1.1 Delay since Last Review,[0],[0]
The results show an inverse relationship between network retention and delay since last review in neural networks.,2.1.1 Delay since Last Review,[0],[0]
We define difficulty of training instances by the loss values generated by a network for the instances.,2.1.2 Item Difficulty,[0],[0]
Figure 2(c) shows the difficulty of set B instances at the last review point against average network retention on these instances at recall point.,2.1.2 Item Difficulty,[0],[0]
"We normalize loss values to unit vectors (to make them com-
4See section 4, we use Addition and CIFAR10 datasets and their corresponding neural networks for these experiments.
",2.1.2 Item Difficulty,[0],[0]
parable across networks) and then average them across networks for both fully and partially trained recall points.,2.1.2 Item Difficulty,[0],[0]
"As the results show, network retention decreases as item difficulty increases.",2.1.2 Item Difficulty,[0],[0]
We define strength of a network by its performance on validation data.,2.1.3 Network Strength,[0],[0]
"To understand the effect of network strength on its retention, we use the same experimental setup as before except that we keep the delay (difference between recall point and last review point) fixed while gradually increasing the recall point; this will make the networks stronger by training them for more epochs.",2.1.3 Network Strength,[0],[0]
"Then, at every recall point, we record network retention on set B instances and network accuracy on validation data.",2.1.3 Network Strength,[0],[0]
Average results across networks for two sets of 10 consecutive recall points (before fully and partially trained recall points) are shown in Figure 2(d).,2.1.3 Network Strength,[0],[0]
"As the results show, network retention increases as memory strength increases.
",2.1.3 Network Strength,[0],[0]
"The above experiments show that memory retention in neural networks is affected by the same factors that affect memory retention in humans: (a) neural networks forget training examples after a certain period of intervening training data (b): the period of recall is shorter for more difficult examples, and (c): recall improves as networks achieve better overall performance.",2.1.3 Network Strength,[0],[0]
"We conclude that delay since last review, item difficulty (loss values of training instances), and memory strength (network performance on validation data) are key indicators that affect network retention and propose to design spaced repetition algorithms that take such indicators into account in training neural networks.",2.1.3 Network Strength,[0],[0]
"We present two spaced repetition-based algorithms: a modified version of the Leitner system developed in (Reddy et al., 2016) and our Repeat before Forgetting (RbF) model respectively.",3 Spaced Repetition,[0],[0]
"Suppose we have n queues {q0, q1, . . .",3.1 Leitner System,[0],[0]
", qn−1}.",3.1 Leitner System,[0],[0]
"The Leitner system initially places all training instances in the first queue, q0.",3.1 Leitner System,[0],[0]
"As Algorithm 1 shows, at each training iteration, the Leitner scheduler chooses some queues to train a downstream neural network.",3.1 Leitner System,[0],[0]
Only instances in the selected queues will be used for training the network.,3.1 Leitner System,[0],[0]
"During training, if an instance from qi is recalled (e.g. correctly classified) by the network, the instance will be “promoted” to qi+1, otherwise it will be “demoted” to the first queue, q0.5
The Leitner scheduler reviews instances of qi at every 2i iterations.",3.1 Leitner System,[0],[0]
"Therefore, instance in lower queues (difficult/forgotten instances) are reviewed more frequently than those in higher queues (easy/recalled ones).",3.1 Leitner System,[0],[0]
Figure 3 (bottom) provides examples of queues and their processing epochs.,3.1 Leitner System,[0],[0]
"Note that the overhead imposed on training by
5 Note that in (Reddy et al., 2016) demoted instances are moved to qi−1.",3.1 Leitner System,[0],[0]
"We observed significant improvement in Leitner system by moving such instances to q0 instead of qi−1.
the Leitner system is O(|current batch|) at every epoch for moving instances between queues.",3.1 Leitner System,[0],[0]
The challenge in developing memory models is to estimate the time by which a training instance should be reviewed before it is forgotten by the network.,3.2.1 RbF Memory Models,[0],[0]
Accurate estimation of the review time leads to efficient and effective training.,3.2.1 RbF Memory Models,[0],[0]
"However, a heuristic scheduler such as Leitner system is suboptimal as its hard review schedules (i.e. only 2iiteration delays) may lead to early or late reviews.
",3.2.1 RbF Memory Models,[0],[0]
We develop flexible schedulers that take recall indicators into account in the scheduling process.,3.2.1 RbF Memory Models,[0],[0]
Our schedulers lengthen or shorten inter-repetition intervals with respect to individual training instances.,3.2.1 RbF Memory Models,[0],[0]
"In particular, we propose using density kernel functions to estimate the latest epoch in which a given training instance can be recalled.",3.2.1 RbF Memory Models,[0],[0]
"We aim to investigate how much improvement (in terms of efficiency and effectiveness) can be achieved using more flexible schedulers that utilize the recall indicators.
",3.2.1 RbF Memory Models,[0],[0]
"We propose considering density kernels as schedulers that favor (i.e., more confidently delay) less difficult training instances in stronger networks.",3.2.1 RbF Memory Models,[0],[0]
"As a kernel we can use any non-increasing function of the following quantity:
xi = di × ti se , (2)
where di indicates the loss of network for a training instance hi ∈ H, ti indicates the number of epochs to next review of hi, and se indicates the performance of network— on validation data— at epoch e. We investigate the Gaussian, Laplace, Linear, Cosine, Quadratic, and Secant kernels as described below respectively:
fgau(x, τ) = exp(−τx2), (3) flap(x, τ) = exp(−τx), (4)
flin(x, τ) = { 1− τx x < 1τ 0",3.2.1 RbF Memory Models,[0],[0]
"otherwise , (5)
fcos(x, τ) =
{ 1 2 cos(τπx)",3.2.1 RbF Memory Models,[0],[0]
"+ 1 x < 1 τ
0 otherwise ,
(6)
fqua(x, τ) = { 1− τx2",3.2.1 RbF Memory Models,[0],[0]
x2 < 1τ 0,3.2.1 RbF Memory Models,[0],[0]
"otherwise , (7)
fsec(x, τ) = 2
exp(−τx2) + exp(τx2) , (8)
where τ is a learning parameter.",3.2.1 RbF Memory Models,[0],[0]
Figure 4 depicts these kernels with τ = 1.,3.2.1 RbF Memory Models,[0],[0]
"As we will discuss in the next section, we use these kernels to optimize delay with respect to item difficulty and network strength for each training instance.",3.2.1 RbF Memory Models,[0],[0]
"Our Repeat before Forgetting (RbF) model is a spaced repetition algorithm that takes into account the previously validated recall indicators to train neural networks, see Algorithm 2.",3.2.2 RbF Algorithm,[0],[0]
RbF divides training instances into current and delayed batches based on their delay values at each iteration.,3.2.2 RbF Algorithm,[0],[0]
Instances in the current batch are those that RbF is less confident about their recall and therefore are reviewed (used to re-train the network) at current iteration.,3.2.2 RbF Algorithm,[0],[0]
"On the other hand, instances in the delayed batch are those that are likely to be recalled by the network in the future and therefore are not reviewed at current epoch.",3.2.2 RbF Algorithm,[0],[0]
"At each iteration, the RbF scheduler estimates the optimum delay (number of epochs to next review) for each training instance in the current batch.",3.2.2 RbF Algorithm,[0],[0]
"RbF makes such item-specific estimations as follows:
Given the difficulty of a training instance di, the memory strength of the neural network at epoch e, se, and an RbF memory model f (see section 3.2.1), RbF scheduler estimates the maximum delay t̂i for the instance such that it can be recalled with a confidence greater than the given threshold η ∈",3.2.2 RbF Algorithm,[0],[0]
"(0, 1) at time e+ t̂i.",3.2.2 RbF Algorithm,[0],[0]
"As described before, di and se can be represented by the current loss of the network for the instance and the current performance of the network on validation data respectively.",3.2.2 RbF Algorithm,[0],[0]
"Therefore, the maximum delay between the current (epoch e) and next reviews of the instance can be estimated as follows:
t̂i = arg min ti
( f(xi, τ̂)− η )2 , (9)
",3.2.2 RbF Algorithm,[0],[0]
s.t 1 ≤,3.2.2 RbF Algorithm,[0],[0]
ti ≤ k,3.2.2 RbF Algorithm,[0],[0]
"− e
where τ̂ is the optimum value for the learning parameter obtained from validation data, see Equation (10).",3.2.2 RbF Algorithm,[0],[0]
"In principle, reviewing instances could be delayed for any number of epochs; in practice however, delay is bounded both below and above (e.g., by queues in the Leitner system).",3.2.2 RbF Algorithm,[0],[0]
"Thus, we assume that, at each epoch e, instances could be delayed for at least one iteration and at most k − e iterations where k is the total number of training epochs.",3.2.2 RbF Algorithm,[0],[0]
"We also note that ti is a lower bound of the maximum delay as se is expected to increase and di is expected to decrease as the network trains in next iterations.
",3.2.2 RbF Algorithm,[0],[0]
Algorithm 2 shows the outline of the proposed RbF model.,3.2.2 RbF Algorithm,[0],[0]
We estimate the optimum value of τ (line 5 of Algorithm 2) for RbF memory models using validation data.,3.2.2 RbF Algorithm,[0],[0]
"In particular, RbF uses the loss values of validation instances and strength of the network obtained at the previous epoch to estimate network retention for validation instances at the current epoch (therefore ti = 1 for every validation instance).",3.2.2 RbF Algorithm,[0],[0]
"The parameter τ for each memory model is computed as follows:
τ̂ = arg min τ
( f(xj , τ)− aj )2 ,∀hj ∈ V, aj ≥ η,
(10) where aj ∈ (0, 1) is the current accuracy of the model for the validation instance hj .",3.2.2 RbF Algorithm,[0],[0]
RbF then predicts the delay for current batch instances and reduces the delay for those in the delayed batch by one epoch.,3.2.2 RbF Algorithm,[0],[0]
The overhead of RbF is O(|H|) to compute delays and O(|V|) to compute τ̂ .,3.2.2 RbF Algorithm,[0],[0]
Note that (9) and (10) have closed form solutions.,3.2.2 RbF Algorithm,[0],[0]
"Table 1 describes the tasks, datasets, and models that we consider in our experiments.",4 Experiments,[0],[0]
It also reports the training epochs for which the models produce their best performance on validation data (based on rote training).,4 Experiments,[0],[0]
"We note that the Addition dataset is randomly generated and contains numbers with at most 4 digits.6
We consider three schedulers as baselines: a slightly modified version of the Leitner scheduler (Lit) developed in Reddy et al. (2016) for human learners (see Footnote 5), curriculum learning (CL) in which training instances are scheduled with respect to their easiness (Jiang et al., 2015), and the uniform scheduler of rote training (Rote) in which all instances are used for training at every epoch.",4 Experiments,[0],[0]
"For Lit, we experimented with different queue lengths, n = {3, 5, 7}, and set n = 5 in the experiments as this value led to the best performance of this scheduler across all datasets.
",4 Experiments,[0],[0]
Curriculum learning starts training with easy instances and gradually introduces more complex instances for training.,4 Experiments,[0],[0]
"Since easiness information is not readily available in most datasets, previous approaches have used heuristic techniques (Spitkovsky et al., 2010; Basu and Christensen, 2013) or optimization algorithms (Jiang et al., 2015, 2014) to quantify easiness of training instances.",4 Experiments,[0.958449898017634],"['Other paraphrase limitations: Paraphrase models based on neural machine translation are biased towards maintaining the sentence structure, and thus do not produce certain adversaries (e.g. Table 5b), which recent work on paraphrasing (Iyyer et al., 2018) or generation using GANs (Zhao et al., 2018) may address.']"
These approaches consider an instance as easy if its loss is smaller than a threshold (λ).,4 Experiments,[0],[0]
"We adopt this technique as follows: at each iteration e, we divide the entire training data into easy and hard sets using iteration-specific λe and the loss values of instances, obtained from the current partially-trained network.",4 Experiments,[0],[0]
All easy instances in conjunction with αe ∈,4 Experiments,[0],[0]
"[0, 1] fraction of easiest hard instances (those with smallest loss values greater than λe) are used for training at",4 Experiments,[0],[0]
"iteration e. We set
6https://github.com/fchollet/keras/ blob/master/examples/addition_rnn.py
each λe to the average loss of training instances that are correctly classified by the current partiallytrained network.",4 Experiments,[0],[0]
"Furthermore, at each iteration e, we set αe = e/k to gradually introduce complex instances at every new iteration.7 Note that we treat all instances as easy at e = 0.
",4 Experiments,[0],[0]
Performance values reported in experiments are averaged over 10 runs of systems and the confidence parameter η is always set to 0.5 unless otherwise stated.,4 Experiments,[0],[0]
"In these experiments, we evaluate memory schedulers with respect to their accuracy in predicting network retention for delayed instances.",4.1 Evaluation of Memory Models,[0],[0]
"Since curriculum learning does not estimate delay for training instances, we only consider Leitner and RbF schedulers in these experiments.
",4.1 Evaluation of Memory Models,[0],[0]
"For this evaluation, if a scheduler predicts a delay t for a training instance h at epoch e, we evaluate network retention with respect to h at epoch e+ t. If the network recalls (correctly classifies) the instance at epoch e+ t, the scheduler has correctly predicted network retention for h, and otherwise, it has made a wrong prediction.",4.1 Evaluation of Memory Models,[0],[0]
We use this binary outcome to evaluate the accuracy of each scheduler.,4.1 Evaluation of Memory Models,[0],[0]
Note that the performance of schedulers on instances that have not been delayed is not a major concern.,4.1 Evaluation of Memory Models,[0],[0]
"Although failing to delay an item inversely affects efficiency, it makes the network stronger by providing more instances to train from.",4.1 Evaluation of Memory Models,[0],[0]
"Therefore, we consider a good scheduler as the one that accurately delays more items.
",4.1 Evaluation of Memory Models,[0],[0]
Figure 6 depicts the average accuracy of schedulers in predicting networks’ retention versus the average fraction of training instances that they delayed per epoch.,4.1 Evaluation of Memory Models,[0],[0]
"As the results show, all schedulers
7k is the total number of iterations.
",4.1 Evaluation of Memory Models,[0],[0]
delay substantial amount of instances per epoch.,4.1 Evaluation of Memory Models,[0],[0]
"In particular, Cos and Qua outperform Lit in both predicting network retention and delaying items, delaying around 50% of training instances per epoch.",4.1 Evaluation of Memory Models,[0],[0]
This is while Gau and Sec show comparable accuracy to Lit but delay more instances.,4.1 Evaluation of Memory Models,[0],[0]
"On the other hand, Lap, which has been found effective in Psychology, and Lin are less accurate in predicting network retention.",4.1 Evaluation of Memory Models,[0],[0]
This is because of the tradeoff between delaying more instances and creating stronger networks.,4.1 Evaluation of Memory Models,[0],[0]
"Since these schedulers are more flexible in delaying greater amount of instances, they might not provide networks with enough data to fully train.
",4.1 Evaluation of Memory Models,[0],[0]
"Figure 7 shows the performance of RbF schedulers with respect to the recall confidence parameter η, see Equation (9).",4.1 Evaluation of Memory Models,[0],[0]
"As the results show, schedulers have poor performance with smaller values of η.",4.1 Evaluation of Memory Models,[0],[0]
This is because smaller values of η make schedulers very flexible in delaying instances.,4.1 Evaluation of Memory Models,[0],[0]
"However, the performance of schedulers are not dramatically low even with very small ηs.",4.1 Evaluation of Memory Models,[0],[0]
"Our further analyses on the delay patterns show that although a smaller η leads to more delayed instances, the delays are significantly shorter.",4.1 Evaluation of Memory Models,[0],[0]
"Therefore, most delayed instances will be “reviewed” shortly in next epochs.",4.1 Evaluation of Memory Models,[0],[0]
"These bulk reviews make the network stronger and help it to recall most delayed instance in future iterations.
",4.1 Evaluation of Memory Models,[0],[0]
"On the other hand, greater ηs lead to more accurate schedulers at the cost of using more training data.",4.1 Evaluation of Memory Models,[0],[0]
"In fact, we found that larger ηs do not delay most training instances in the first few iterations.",4.1 Evaluation of Memory Models,[0],[0]
"However, once the network obtains a reasonably high performance, schedulers start delaying instances for longer durations.",4.1 Evaluation of Memory Models,[0],[0]
We will further study this effect in the next section.,4.1 Evaluation of Memory Models,[0],[0]
We compare RbF against Leitner and curriculum learning in terms of efficiency of training and effectiveness of trained models.,4.2 Efficiency and Effectiveness,[0],[0]
"We define effectiveness as the accuracy of a trained network on balanced test data, and efficiency as (a): fraction of instances used for training per epoch, and (b): required time for training the networks.",4.2 Efficiency and Effectiveness,[0],[0]
"For RbF schedulers, we set η to 0.5 and consider the best performing kernel Cosine with η = 0.9 based on results in Figure 7.
",4.2 Efficiency and Effectiveness,[0],[0]
The results in Table 2 show that all training paradigms have comparable effectiveness (Accuracy) to that of rote training (Rote).,4.2 Efficiency and Effectiveness,[0],[0]
Our RbF schedulers use less data per epoch (34-50% of data) and run considerably faster than Rote (2.90-4.78 times faster for η = 0.5).,4.2 Efficiency and Effectiveness,[0],[0]
"The results also show that Lit is slightly less accurate but runs 2.87 time faster than Rote; note that, as a scheduler, Lit is less accurate than RbF models, see Figures 6 and 7.
",4.2 Efficiency and Effectiveness,[0],[0]
"In addition, CL leads to comparable performance to RbF but is considerably slower than other schedulers.",4.2 Efficiency and Effectiveness,[0],[0]
This is because this scheduler has to identify easier instances and sort the harder ones to sample training data at each iteration.,4.2 Efficiency and Effectiveness,[0],[0]
"Overall, the performance of Lit, CL, Cos η = .5 and Cos η = .9 are only 2.76, 1.90, 1.88, and 0.67 absolute values lower than that of Rote respectively.",4.2 Efficiency and Effectiveness,[0],[0]
"Considering the achieved efficiency, these differences are negligible (see the overall gain in Table 2).
",4.2 Efficiency and Effectiveness,[0],[0]
Figure 8 reports detailed efficiency and effectiveness results across datasets and networks.,4.2 Efficiency and Effectiveness,[0],[0]
"For clear illustration, we report accuracy at iterations 2i ∀i in which Lit is trained on the entire data, and consider Cos η = .5",4.2 Efficiency and Effectiveness,[0],[0]
as RbF scheduler.,4.2 Efficiency and Effectiveness,[0],[0]
"In terms of efficiency (first row of Figure 8), CL starts with (small set of)
easier instances and gradually increases the amount of training data by adding slightly harder instances into its training set.",4.2 Efficiency and Effectiveness,[0],[0]
"On the other hand, Lit and RbF start big and gradually delay reviewing (easy) instances that the networks have learned.",4.2 Efficiency and Effectiveness,[0],[0]
"The difference between these two training paradigms is apparent in Figures 8(a)-8(c).
",4.2 Efficiency and Effectiveness,[0],[0]
The results also show that the efficiency of a training paradigm depends on the initial effectiveness of the downstream neural network.,4.2 Efficiency and Effectiveness,[0],[0]
"For CL to be efficient, the neural network need to initially have low performance (accuracy) so that the scheduler works on smaller set of easy instances.",4.2 Efficiency and Effectiveness,[0],[0]
"For example, in case of Addition, Figures 8(b) and 8(e), the initial network accuracy is only 35%, therefore most instances are expected to be initially treated as hard instances and don’t be used for training.",4.2 Efficiency and Effectiveness,[0],[0]
"On the other hand, CL shows a considerably lower efficiency for networks with slightly high initial accuracy, e.g. in case of IMDb or CIFAR10 where the initial network accuracy is above 56%, see Figures 8(a) and 8(d), and 8(c) and 8(f) respectively.
",4.2 Efficiency and Effectiveness,[0],[0]
"In contrast to CL, Lit and RbF are more efficient when the network has a relatively higher initial performance.",4.2 Efficiency and Effectiveness,[0],[0]
"A higher initial performance helps the
schedulers to more confidently delay “reviewing” most instances and therefore train with a much smaller set of instances.",4.2 Efficiency and Effectiveness,[0],[0]
"For example, since the initial network accuracy in IMDb or CIFAR10 is above 56%, Lit and RbF are considerably more efficient from the beginning of the training process.",4.2 Efficiency and Effectiveness,[0],[0]
"However, in case of low initial performance, Lit and RbF tend to avoid delaying instances at lower iterations which leads to poor efficiency at the beginning.",4.2 Efficiency and Effectiveness,[0],[0]
"This is the case for the Addition dataset in which instances are gradually delayed by these two schedulers even at epoch 8 when the performance of the network reaches above 65%, see Figures 8(e) and 8(b).",4.2 Efficiency and Effectiveness,[0],[0]
"However, Lit gains its true efficiency after iteration 12, see Figure 8(b), while RbF still gradually improves the efficiency.",4.2 Efficiency and Effectiveness,[0],[0]
"This might be because of the lower bound delays that RbF estimates, see Equation (9).
",4.2 Efficiency and Effectiveness,[0],[0]
"Furthermore, the effectiveness results in Figure 8 (bottom) show that all schedulers produce comparable accuracy to the Rote scheduler throughout the training process, not just at specific iterations.",4.2 Efficiency and Effectiveness,[0],[0]
"This indicates that these training paradigms can much faster achieve the same generalizability as standard training, see Figures 8(b) and 8(e).",4.2 Efficiency and Effectiveness,[0],[0]
We investigate the effect of spaced repetition on overtraining.,4.3 Robustness against Overtraining,[0],[0]
The optimal number of training epochs required to train fastText on the IMDb dataset is 8 epochs (see Table 1).,4.3 Robustness against Overtraining,[0],[0]
"In this experiment, we run fastText on IMDb for greater number of iterations to investigate the robustness of different schedulers against overtraining.",4.3 Robustness against Overtraining,[0],[0]
The results in Figure 9 show that Lit and RbF (Cos η = 0.5) are more robust against overtraining.,4.3 Robustness against Overtraining,[0],[0]
"In fact, the performance of Lit and RbF further improve at epoch 16 while CL and Rote overfit at epoch 16 (note that CL and Rote also require considerably more amount of time to reach to higher iterations).",4.3 Robustness against Overtraining,[0],[0]
We attribute the robustness of Lit and RbF to the scheduling mechanism which helps the networks to avoid retraining with easy instances.,4.3 Robustness against Overtraining,[0],[0]
"On the other hand, overtraining affects Lit and RbF at higher training iterations, compare performance of each scheduler at epochs 8 and 32.",4.3 Robustness against Overtraining,[0],[0]
This might be because these training paradigms overfit the network by paying too much training attention to very hard instances which might introduce noise to the model.,4.3 Robustness against Overtraining,[0.9501989089453128],"['This is what we asked the subjects to maximize, and all the rules were ones deemed to be semantic equivalent by the subjects themselves.']"
"Ebbinghaus (1913, 2013), and recently Murre and Dros (2015), studied the hypothesis of the exponential nature of forgetting, i.e. how information is lost over time when there is no attempt to retain it.",5 Related Work,[0],[0]
"Previous research identified three critical indicators that affect the probability of recall: repeated exposure to learning materials, elapsed time since their last review (Ebbinghaus, 1913; Wixted, 1990; Dempster, 1989), and more recently item difficulty (Reddy et al., 2016).",5 Related Work,[0],[0]
We based our investigation on these findings and validated that these indicators indeed affect memory retention in neural networks.,5 Related Work,[0],[0]
"We then developed training paradigms that utilize the above indicators to train networks.
",5 Related Work,[0],[0]
Bengio et al. (2009) and Kumar et al. (2010) also developed cognitively-motivated training paradigms which are inspired by the principle that learning can be more effective when training starts with easier concepts and gradually proceeds with more difficult ones.,5 Related Work,[0],[0]
"Our idea is motivated by the spaced repetition principle which indicates learning improves with repeated exposure and decays with delay since last exposure (Ebbinghaus, 1913; Dempster, 1989).",5 Related Work,[0],[0]
"Based on this principle, we developed schedulers that space the reviews of training instances over time for efficient and effective training of neural networks.",5 Related Work,[0],[0]
We developed a cognitively-motivated training paradigm (scheduler) that space instances over time for efficient and effective training of neural networks.,6 Conclusion and Future Work,[0],[0]
Our scheduler only uses a small fraction of training data per epoch but still effectively train neural networks.,6 Conclusion and Future Work,[0],[0]
It achieves this by estimating the time (number of epochs) by which training could be delayed for each instance.,6 Conclusion and Future Work,[0],[0]
"Our work was inspired by three recall indicators that affect memory retention in humans, namely difficulty of learning materials, delay since their last review, and memory strength of the learner, which we validated in the context of neural networks.
",6 Conclusion and Future Work,[0],[0]
There are several avenues for future work including the extent to which our RbF model and its kernels could be combined with curriculum learning or Leitner system to either predict easiness of novel training instances to inform curriculum learning or incorporate Leitner’s queueing mechanism to the RbF model.,6 Conclusion and Future Work,[0],[0]
"Other directions include extending RbF to dynamically learn the recall confidence parameter with respect to network behavior, or developing more flexible delay functions with theoretical analysis on their lower and upper bounds.",6 Conclusion and Future Work,[0],[0]
We thank Mitra Mohtarami for her constructive feedback during the development of this paper and anonymous reviewers for their thoughtful comments.,Acknowledgments,[0],[0]
This work was supported by National Institutes of Health (NIH) grant R01GM114355 from the National Institute of General Medical Sciences (NIGMS).,Acknowledgments,[0],[0]
The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.,Acknowledgments,[0],[0]
We present a novel approach for training artificial neural networks.,abstractText,[0],[0]
Our approach is inspired by broad evidence in psychology that shows human learners can learn efficiently and effectively by increasing intervals of time between subsequent reviews of previously learned materials (spaced repetition).,abstractText,[0],[0]
We investigate the analogy between training neural models and findings in psychology about human memory model and develop an efficient and effective algorithm to train neural models.,abstractText,[0],[0]
The core part of our algorithm is a cognitively-motivated scheduler according to which training instances and their “reviews” are spaced over time.,abstractText,[0],[0]
"Our algorithm uses only 34-50% of data per epoch, is 2.9-4.8 times faster than standard training, and outperforms competing state-of-the-art baselines.1",abstractText,[0],[0]
Repeat before Forgetting: Spaced Repetition for Efficient and Effective Training of Neural Networks,title,[0],[0]
"With the ever growing amount of textual data from a large variety of languages, domains, and genres, it has become standard to evaluate NLP algorithms on multiple datasets in order to ensure a consistent performance across heterogeneous setups. However, such multiple comparisons pose significant challenges to traditional statistical analysis methods in NLP and can lead to erroneous conclusions. In this paper we propose a Replicability Analysis framework for a statistically sound analysis of multiple comparisons between algorithms for NLP tasks. We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction. 1",text,[0.9540858637548688],"['In this section, we address the problem of generalizing local adversaries into Semantically Equivalent Adversarial Rules for Text (SEARs), search and replace rules that produce semantic adversaries with little or no change in semantics, when applied to a corpus of sentences.']"
The field of Natural Language Processing (NLP) is going through the data revolution.,1 Introduction,[0],[0]
"With the persistent increase of the heterogeneous web, for the first time in human history, written language from multiple languages, domains, and genres is now abundant.",1 Introduction,[0],[0]
"Naturally, the expectations from NLP algorithms also grow and evaluating a new algorithm on as many languages, domains, and genres as possible is becoming a de-facto standard.
",1 Introduction,[0],[0]
"1Our code is at: https://github.com/rtmdrr/replicabilityanalysis-NLP .
",1 Introduction,[0],[0]
"For example, the phrase structure parsers of Charniak (2000) and Collins (2003) were mostly evaluated on the Wall Street Journal Penn Treebank (Marcus et al., 1993), consisting of written, edited English text of economic news.",1 Introduction,[0],[0]
"In contrast, modern dependency parsers are expected to excel on the 19 languages of the CoNLL 2006-2007 shared tasks on multilingual dependency parsing (Buchholz and Marsi, 2006; Nilsson et al., 2007), and additional challenges, such as the shared task on parsing multiple English Web domains (Petrov and McDonald, 2012), are continuously proposed.
",1 Introduction,[0],[0]
"Despite the growing number of evaluation tasks, the analysis toolbox employed by NLP researchers has remained quite stable.",1 Introduction,[0],[0]
"Indeed, in most experimental NLP papers, several algorithms are compared on a number of datasets where the performance of each algorithm is reported together with per-dataset statistical significance figures.",1 Introduction,[0],[0]
"However, with the growing number of evaluation datasets, it becomes more challenging to draw comprehensive conclusions from such comparisons.",1 Introduction,[0],[0]
"This is because although the probability of drawing an erroneous conclusion from a single comparison is small, with multiple comparisons the probability of making one or more false claims may be very high.
",1 Introduction,[0],[0]
"The goal of this paper is to provide the NLP community with a statistical analysis framework, which we term Replicability Analysis, which will allow us to draw statistically sound conclusions in evaluation setups that involve multiple comparisons.",1 Introduction,[0.9521476172227328],"['The second rule uncovers a bug with respect to simple question rephrasing, while the third and fourth rules show that the model is not robust to a more conversational style of asking questions.']"
"The classical goal of replicability analysis is to examine the consistency of findings across studies in order to address the basic dogma of science, that a find-
471
Transactions of the Association for Computational Linguistics, vol. 5, pp.",1 Introduction,[0],[0]
"471–486, 2017.",1 Introduction,[0],[0]
Action Editor: Brian Roark.,1 Introduction,[0],[0]
"Submission batch: 3/2017; Revision batch: 7/2017; Published 11/2017.
",1 Introduction,[0],[0]
c©2017 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
",1 Introduction,[0],[0]
"ing is more convincingly true if it is replicated in at least one more study (Heller et al., 2014; Patil et al., 2016).",1 Introduction,[0],[0]
"We adapt this goal to NLP, where we wish to ascertain the superiority of one algorithm over another across multiple datasets, which may come from different languages, domains, and genres.",1 Introduction,[0],[0]
"Finding that one algorithm outperforms another across domains gives a sense of consistency to the results and positive evidence that the better performance is not specific to a selected setup.2
In this work we address two questions: (1) Counting: For how many datasets does a given algorithm outperform another?",1 Introduction,[0],[0]
"and (2) Identification: What are these datasets?
",1 Introduction,[0],[0]
"When comparing two algorithms on multiple datasets, NLP papers often answer informally the questions we address in this work.",1 Introduction,[0],[0]
"In some cases this is done without any statistical analysis, by simply declaring better performance of a given algorithm for datasets where its performance measure is better than that of another algorithm, and counting these datasets.",1 Introduction,[0],[0]
In other cases answers are based on the p-values from statistical tests performed for each dataset: declaring better performance for datasets with p-value below the significance level (e.g. 0.05) and counting these datasets.,1 Introduction,[0],[0]
"While it is clear that the first approach is not statistically valid, it seems that our community is not aware of the fact that the second approach, which may seem statistically sound, is not valid as well.",1 Introduction,[0],[0]
"This may lead to erroneous conclusions, which result in adopting new (and probably complicated) algorithms, while they are not better than previous (probably more simple) ones.
",1 Introduction,[0],[0]
"In this work, we demonstrate this problem and show that it becomes more severe as the number of evaluation sets grows, which seems to be the current trend in NLP.",1 Introduction,[0],[0]
"We adopt a known general statistical methodology for addressing the counting (question (1)) and identification (question (2)) problems, by choosing the tests and procedures which are valid for
2“Replicability” is sometimes referred to as “reproducibility”.",1 Introduction,[0],[0]
"In recent NLP work the term reproducibility was used when trying to get identical results on the same data (Névéol et al., 2016; Marrese-Taylor and Matsuo, 2017).",1 Introduction,[0],[0]
"In this paper, we adopt the meaning of “replicability” and its distinction from “reproducibility” from Peng (2011) and Leek and Peng (2015) and refer to replicability analysis as the effort to show that a finding is consistent over different datasets from different domains or languages, and is not idiosyncratic to a specific scenario.
situations encountered in NLP problems, and giving specific recommendations for such situations.
",1 Introduction,[0],[0]
"Particularly, we first demonstrate (Section 3) that the current prominent approach in the NLP literature, identifying the datasets for which the difference between the performance of the algorithms reaches a predefined significance level according to some statistical significance test, does not guarantee to bound the probability to make at least one erroneous claim.",1 Introduction,[0.9631003964346305],"['The third condition (HSEA) is a collaboration between our method and humans: we take the top 5 adversaries ranked by S(x, x′), and ask workers to pick the one closest to the original instance, rather than asking them to generate the adversaries.']"
Hence this approach is error-prone when the number of participating datasets is large.,1 Introduction,[0],[0]
We thus propose an alternative approach (Section 4).,1 Introduction,[0],[0]
"For question (1), we adopt the approach of Benjamini et al. (2009) to replicability analysis of multiple studies, based on the partial conjunction framework of Benjamini and Heller (2008).",1 Introduction,[0],[0]
This analysis comes with a guarantee that the probability of overestimating the true number of datasets with effect is upper bounded by a predefined constant.,1 Introduction,[0],[0]
"For question (2), we motivate a multiple testing procedure which guarantees that the probability of making at least one erroneous claim on the superiority of one algorithm over another is upper bounded by a predefined constant.
",1 Introduction,[0],[0]
"In Sections 5 and 6 we demonstrate how to apply the proposed frameworks to two synthetic data toy examples and four NLP applications: multidomain dependency parsing, multilingual POS tagging, cross-domain sentiment classification, and word similarity prediction with word embedding models.",1 Introduction,[0],[0]
"Our results demonstrate that the current practice in NLP for addressing our questions is error-prone, and illustrate the differences between it and the proposed statistically sound approach.
",1 Introduction,[0],[0]
"We hope that this work will encourage our community to increase the number of standard evaluation setups per task when appropriate (e.g. including additional languages and domains), possibly paving the way to hundreds of comparisons per study.",1 Introduction,[0],[0]
This is due to two main reasons.,1 Introduction,[0],[0]
"First, replicability analysis is a statistically sound framework that allows a researcher to safely draw valid conclusions with well defined statistical guarantees.",1 Introduction,[0],[0]
"Moreover, this framework provides a means of summarizing a large number of experiments with a handful of easily interpretable numbers (e.g., see Table 1).",1 Introduction,[0],[0]
"This allows researchers to report results over a large number of comparisons in a concise manner, delving into details of particular comparisons when necessary.",1 Introduction,[0],[0]
"Our work recognizes the current trend in the NLP community where, for many tasks and applications, the number of evaluation datasets constantly increases.",2 Previous Work,[0],[0]
We believe this trend is inherent to language processing technology due to the multiplicity of languages and of linguistic genres and domains.,2 Previous Work,[0],[0]
"In order to extend the reach of NLP algorithms, they have to be designed so that they can deal with many languages and with the various domains of each.",2 Previous Work,[0],[0]
"Having a sound statistical framework that can deal with multiple comparisons is hence crucial for the field.
",2 Previous Work,[0],[0]
This section is hence divided into two.,2 Previous Work,[0],[0]
"We start by discussing representative examples for multiple comparisons in NLP, focusing on evaluations across multiple languages and multiple domains.",2 Previous Work,[0],[0]
"We then discuss existing analysis frameworks for multiple comparisons, both in the NLP and in the machine learning literatures, pointing to the need for establishing new standards for our community.
",2 Previous Work,[0],[0]
"Multiple Comparisons in NLP Multiple comparisons of algorithms over datasets from different languages, domains and genres have become a de-facto standard in many areas of NLP.",2 Previous Work,[0],[0]
Here we survey a number of representative examples.,2 Previous Work,[0],[0]
"A full list of NLP tasks is beyond the scope of this paper.
",2 Previous Work,[0],[0]
"A common multilingual example is, naturally, machine translation, where it is customary to compare algorithms across a large number of sourcetarget language pairs.",2 Previous Work,[0],[0]
"This is done, for example, with the Europarl corpus consisting of 21 European languages (Koehn, 2005; Koehn and Schroeder, 2007) and with the datasets of the WMT workshop series with its multiple domains (e.g. news and biomedical in 2017), each consisting of several language pairs (7 and 14, respectively, in 2017).
",2 Previous Work,[0],[0]
Multiple dataset comparisons are also abundant in domain adaptation work.,2 Previous Work,[0],[0]
"Representative tasks include named entity recognition (Guo et al., 2009), POS tagging (Daumé III, 2007), dependency parsing (Petrov and McDonald, 2012), word sense disambiguation (Chan and Ng, 2007) and sentiment classification (Blitzer et al., 2006; Blitzer et al., 2007).
",2 Previous Work,[0],[0]
"More recently, with the emergence of crowdsourcing that makes data collection cheap and fast (Snow et al., 2008), an ever growing number of datasets is being created.",2 Previous Work,[0],[0]
"This is particularly notice-
able in lexical semantics tasks that have become central in NLP research due to the prominence of neural networks.",2 Previous Work,[0],[0]
"For example, it is customary to compare word embedding models (Mikolov et al., 2013; Pennington et al., 2014; Ó",2 Previous Work,[0],[0]
"Séaghdha and Korhonen, 2014; Levy and Goldberg, 2014; Schwartz et al., 2015) on multiple datasets where word pairs are scored according to the degree to which different semantic relations, such as similarity and association, hold between the members of the pair (Finkelstein et al., 2001a; Bruni et al., 2014; Silberer and Lapata, 2014; Hill et al., 2015).",2 Previous Work,[0],[0]
"In some works (e.g., Baroni et al. (2014))",2 Previous Work,[0],[0]
"these embedding models are compared across a large number of simple tasks.
",2 Previous Work,[0],[0]
"As discussed in Section 1, the outcomes of such comparisons are often summarized in a table that presents numerical performance values, usually accompanied by statistical significance figures and sometimes also with cross-comparison statistics such as average performance figures.",2 Previous Work,[0],[0]
"Here, we analyze the conclusions that can be drawn from this information and suggest that with the growing number of comparisons, a more intricate analysis is required.
",2 Previous Work,[0],[0]
"Existing Analysis Frameworks Machine learning work on multiple dataset comparisons dates back to Dietterich (1998) who raised the question: “given two learning algorithms and datasets from several domains, which algorithm will produce more accurate classifiers when trained on examples from new domains?”.",2 Previous Work,[0],[0]
The seminal work that proposed practical means for this problem is that of Demšar (2006).,2 Previous Work,[0],[0]
"Given performance measures for two algorithms on multiple datasets, the authors test whether there is at least one dataset on which the difference between the algorithms is statistically significant.",2 Previous Work,[0],[0]
"For this goal they propose methods such as a paired t-test, a nonparametric sign-rank test and a wins/losses/ties count, all computed across the results collected from all participating datasets.",2 Previous Work,[0],[0]
"In contrast, our goal is to count and identify the datasets for which one algorithm significantly outperforms the other, which provides more intricate information, especially when the datasets come from different sources.
",2 Previous Work,[0],[0]
"In NLP, several studies addressed the problem of measuring the statistical significance of results on a single dataset (e.g., Berg-Kirkpatrick et al. (2012); Søgaard (2013); Søgaard et al. (2014)).",2 Previous Work,[0],[0]
"Søgaard
(2013) is, to the best of our knowledge, the only work that addressed the statistical properties of evaluation with multiple datasets.",2 Previous Work,[0],[0]
"For this aim he modified the statistical tests proposed in Demšar (2006) to use a Gumbel distribution assumption on the test statistics, which he considered to suit NLP better than the original Gaussian assumption.",2 Previous Work,[0],[0]
"However, while this procedure aims to estimate the effect size across datasets, it answers neither the counting nor the identification question of Section 1.
",2 Previous Work,[0],[0]
In the next section we provide the preliminary knowledge from the field of statistics that forms the basis for the proposed framework and then proceed with its description.,2 Previous Work,[0],[0]
We start by formulating a general hypothesis testing framework for a comparison between two algorithms.,3 Preliminaries,[0],[0]
"This is a common type of hypothesis testing framework applied in NLP, its detailed formulation will help us develop our ideas.",3 Preliminaries,[0],[0]
"We wish to compare between two algorithms, A and B. Let X be a collection of datasets X = {X1, X2, . . .",3.1 Hypothesis Testing,[0],[0]
", XN}, where for all i ∈ {1, . . .",3.1 Hypothesis Testing,[0],[0]
", N}, Xi = {xi,1, . . .",3.1 Hypothesis Testing,[0],[0]
", xi,ni} .",3.1 Hypothesis Testing,[0],[0]
Each dataset Xi can be of a different language or a different domain.,3.1 Hypothesis Testing,[0],[0]
"We denote by xi,k the granular unit on which results are being measured, that, in most NLP tasks, is a word or a sequence of words.",3.1 Hypothesis Testing,[0],[0]
"The difference in performance between the two algorithms is measured using one or more of the evaluation measures in the setM = {M1, . . .",3.1 Hypothesis Testing,[0],[0]
",Mm}.3
Let us denoteMj(ALG,Xi) as the value of the measureMj when algorithmALG is applied on the dataset Xi.",3.1 Hypothesis Testing,[0],[0]
"Without loss of generality, we assume that higher values of the measure are better.",3.1 Hypothesis Testing,[0],[0]
"We define the difference in performance between two algorithms, A and B, according to the measure",3.1 Hypothesis Testing,[0],[0]
"Mj on the dataset Xi as:
δj(X i) =Mj(A,Xi)−Mj(B,Xi).
",3.1 Hypothesis Testing,[0],[0]
"3To keep the discussion concise, throughout this paper we assume that only one evaluation measure is used.",3.1 Hypothesis Testing,[0],[0]
"Our framework can be easily extended to deal with multiple measures.
",3.1 Hypothesis Testing,[0],[0]
"Finally, using this notation we formulate the following statistical hypothesis testing problem:
H0i(j) :δj(X i) ≤ 0
H1i(j) :δj(X i) > 0.
(1)
The null hypothesis, stating that there is no difference between the performance of algorithm A and algorithmB, or thatB performs better, is tested versus the alternative statement thatA is superior.",3.1 Hypothesis Testing,[0],[0]
"If the statistical test results in rejecting the null hypothesis, one concludes that A outperforms B in this setup.",3.1 Hypothesis Testing,[0],[0]
"Otherwise, there is not enough evidence in the data to make this conclusion.
",3.1 Hypothesis Testing,[0],[0]
"Rejection of the null hypothesis when it is true is termed type I error, and non-rejection of the null hypothesis when the alternative is true is termed type II error.",3.1 Hypothesis Testing,[0],[0]
"The classical approach to hypothesis testing is to find a test that guarantees that the probability of making a type I error is upper bounded by a predefined constant α, the test significance level, while achieving as low probability of type II error as possible, a.k.a “achieving as high power as possible”.
",3.1 Hypothesis Testing,[0],[0]
We next turn to the case where the difference between two algorithms is tested across multiple datasets.,3.1 Hypothesis Testing,[0],[0]
Equation 1 defines a multiple hypothesis testing problem when considering the formulation for all N datasets.,3.2 The Multiplicity Problem,[0],[0]
"If N is large, testing each hypothesis separately at the nominal significance level may result in a high number of erroneously rejected null hypotheses.",3.2 The Multiplicity Problem,[0],[0]
"In our context, when the performance of algorithm A is compared to that of algorithm B across multiple datasets, and for each dataset algorithm A is declared as superior, based on a statistical test at the nominal significance level α, the expected number of erroneous claims may grow as N grows.
",3.2 The Multiplicity Problem,[0],[0]
"For example, if a single test is performed with a significance level of α = 0.05, there is only a 5% chance of incorrectly rejecting the null hypothesis.",3.2 The Multiplicity Problem,[0],[0]
"On the other hand, for 100 tests where all null hypotheses are true, the expected number of incorrect rejections is 100 · 0.05 = 5.",3.2 The Multiplicity Problem,[0],[0]
"Denoting the total number of type I errors as V , we can see below that if the test statistics are independent then the probability of
making at least one incorrect rejection is 0.994:
P(V > 0)",3.2 The Multiplicity Problem,[0],[0]
"= 1− P(V = 0) =
1− 100∏
i=1
P(no type I error in i)",3.2 The Multiplicity Problem,[0],[0]
"=1− (1− 0.05)100.
",3.2 The Multiplicity Problem,[0],[0]
This demonstrates that the naive method of counting the datasets for which significance was reached at the nominal level is error-prone.,3.2 The Multiplicity Problem,[0],[0]
"Similar examples can be constructed for situations where some of the null hypotheses are false.
",3.2 The Multiplicity Problem,[0],[0]
"The multiple testing literature proposes various procedures for bounding the probability of making at least one type I error, as well as other, less restrictive error criteria (see a survey in Farcomeni (2007)).",3.2 The Multiplicity Problem,[0],[0]
"In this paper, we address the questions of counting and identifying the datasets for which algorithm A outperforms B, with certain statistical guarantees regarding erroneous claims.",3.2 The Multiplicity Problem,[0],[0]
"While identifying the datasets gives more information when compared to just declaring their number, we consider these two questions separately.",3.2 The Multiplicity Problem,[0],[0]
"As our experiments show, according to the statistical analysis we propose the estimated number of datasets with effect (question 1) may be higher than the number of identified datasets (question 2).",3.2 The Multiplicity Problem,[0],[0]
We next present the fundamentals of the partial conjunction framework which is at the heart of our proposed methods.,3.2 The Multiplicity Problem,[0],[0]
We start by reformulating the set of hypothesis testing problems of Equation 1 as a unified hypothesis testing problem.,3.3 Partial Conjunction Hypotheses,[0],[0]
This problem aims to identify whether algorithm A is superior to B across all datasets.,3.3 Partial Conjunction Hypotheses,[0],[0]
"The notation for the null hypothesis in this problem is HN/N0 since we test if N out of N alternative hypotheses are true:
H N/N 0",3.3 Partial Conjunction Hypotheses,[0],[0]
":
N⋃
i=1
H0i is true vs. H N/N 1 :
N⋂
i=1
H1i is true.
",3.3 Partial Conjunction Hypotheses,[0],[0]
"Requiring the rejection of the disjunction of all null hypotheses is often too restrictive for it involves observing a significant effect on all datasets, i ∈ {1, . . .",3.3 Partial Conjunction Hypotheses,[0],[0]
", N}.",3.3 Partial Conjunction Hypotheses,[0],[0]
"Instead, one can require a rejection of the global null hypothesis stating that all individual null hypotheses are true, i.e., evidence that
at least one alternative hypothesis is true.",3.3 Partial Conjunction Hypotheses,[0],[0]
"This hypothesis testing problem is formulated as follows:
H 1/N 0",3.3 Partial Conjunction Hypotheses,[0],[0]
":
N⋂
i=1
H0i is true vs. H 1/N 1 :
N⋃
i=1
H1i is true.
",3.3 Partial Conjunction Hypotheses,[0],[0]
"Obviously, rejecting the global null may not provide enough information: it only indicates that algorithm A outperforms B on at least one dataset.",3.3 Partial Conjunction Hypotheses,[0],[0]
"Hence, this claim does not give any evidence for the consistency of the results across multiple datasets.
",3.3 Partial Conjunction Hypotheses,[0],[0]
"A natural compromise between the above two formulations is to test the partial conjunction null, which states that the number of false null hypotheses is lower than u, where 1 ≤ u ≤ N is a pre-specified integer constant.",3.3 Partial Conjunction Hypotheses,[0],[0]
"The partial conjunction test contrasts this statement with the alternative statement that at least u out of the N null hypotheses are false.
",3.3 Partial Conjunction Hypotheses,[0],[0]
Definition 1 (Benjamini and Heller (2008)).,3.3 Partial Conjunction Hypotheses,[0],[0]
"Consider N ≥ 2 null hypotheses: H01, H02, . . .",3.3 Partial Conjunction Hypotheses,[0],[0]
",H0N , and let p1, . . .",3.3 Partial Conjunction Hypotheses,[0],[0]
", pN be their associated p−values.",3.3 Partial Conjunction Hypotheses,[0],[0]
"Let k be the true unknown number of false null hypotheses, then our question “Are at least u out of N null hypotheses false?” can be formulated as follows:
H u/N 0",3.3 Partial Conjunction Hypotheses,[0],[0]
:,3.3 Partial Conjunction Hypotheses,[0],[0]
"k < u vs. H u/N 1 : k ≥ u.
",3.3 Partial Conjunction Hypotheses,[0],[0]
"In our context, k is the number of datasets where algorithm A is truly better, and the partial conjunction test examines whether algorithmA outperforms algorithm B in at least u of N cases.
",3.3 Partial Conjunction Hypotheses,[0],[0]
Benjamini and Heller (2008) developed a general method for testing the above hypothesis for a given u. They also showed how to extend their method in order to answer our counting question.,3.3 Partial Conjunction Hypotheses,[0],[0]
"We next describe their framework and advocate a different, yet related method for dataset identification.",3.3 Partial Conjunction Hypotheses,[0],[0]
"Referred to as the cornerstone of science (Moonesinghe et al., 2007), replicability analysis is of predominant importance in many scientific fields including psychology (Collaboration, 2012), genomics (Heller et al., 2014), economics (Herndon et al., 2014) and medicine (Begley and Ellis, 2012), among others.",4 Replicability Analysis for NLP,[0],[0]
"Findings are usually considered as replicated if they are obtained in two or more
studies that differ from each other in some aspects (e.g. language, domain or genre in NLP).
",4 Replicability Analysis for NLP,[0],[0]
"The replicability analysis framework we employ (Benjamini and Heller, 2008; Benjamini et al., 2009) is based on partial conjunction testing.",4 Replicability Analysis for NLP,[0],[0]
"Particularly, these authors have shown that a lower bound on the number of false null hypotheses with a confidence level of 1 − α can be obtained by finding the largest u for which we can reject the partial conjunction null hypothesis Hu/N0 along with H
1/N 0 , . . .",4 Replicability Analysis for NLP,[0],[0]
",H (u−1)/N 0 at a significance levelα.",4 Replicability Analysis for NLP,[0],[0]
"Since rejecting Hu/N0 means that we see evidence in at least u out of N datasets, algorithm",4 Replicability Analysis for NLP,[0],[0]
"A is superior to B. This lower bound on k is taken as our answer to the Counting question of Section 1.
",4 Replicability Analysis for NLP,[0],[0]
"In line with the hypothesis testing framework of Section 3, the partial conjunction null, Hu/N0 , is rejected at level α if pu/N ≤ α, where pu/N is the partial conjunction p-value.",4 Replicability Analysis for NLP,[0],[0]
"Based on the known methods for testing the global null hypothesis (see, e.g., Loughin (2004)), Benjamini and Heller (2008) proposed methods for combining the p−values p1, . . .",4 Replicability Analysis for NLP,[0],[0]
", pN of H01, H02, . . .",4 Replicability Analysis for NLP,[0],[0]
",H0N in order to obtain pu/N .",4 Replicability Analysis for NLP,[0],[0]
"Below, we describe two such methods and their properties.",4 Replicability Analysis for NLP,[0],[0]
"The methods we focus on were developed by Benjamini and Heller (2008), and are based on Fisher’s and Bonferroni’s methods for testing the global null hypothesis.",4.1 The Partial Conjunction p−value,[0],[0]
"For brevity, we name them Bonferroni and Fisher.",4.1 The Partial Conjunction p−value,[0],[0]
"We choose them because they are valid in different setups that are frequently encountered in NLP (Section 6): Bonferroni for dependent datasets and both Fisher and Bonferroni for independent datasets.4
Bonferroni’s method does not make any assumptions about the dependencies between the participating datasets and it is hence applicable in NLP tasks, since in NLP it is most often hard to determine the type of dependence between the datasets.",4.1 The Partial Conjunction p−value,[0],[0]
"Fisher’s method, while assuming independence across the
4For simplicity we refer to dependent/independent datasets as those for which the test statistics are dependent/independent.",4.1 The Partial Conjunction p−value,[0],[0]
"We assume the test statistics are independent if the corresponding datasets do not have mutual samples, and one dataset is not a transformation of the other.
participating datasets, is often more powerful than Bonferroni’s method (see Loughin (2004) and Benjamini and Heller (2008) for other methods and a comparison between them).",4.1 The Partial Conjunction p−value,[0],[0]
"Our recommendation is hence to use the Bonferroni’s method when the datasets are dependent and to use the more powerful Fisher’s method when the datasets are independent.
",4.1 The Partial Conjunction p−value,[0],[0]
"Let p(i) be the i-th smallest p−value among p1, . . .",4.1 The Partial Conjunction p−value,[0],[0]
", pN .",4.1 The Partial Conjunction p−value,[0],[0]
"The partial conjunction p−values are:
p u/N Bonferroni = (N − u+ 1)p(u) (2)
p u/N Fisher = P ( χ22(N−u+1) ≥ −2",4.1 The Partial Conjunction p−value,[0],[0]
"N∑
i=u
ln p(i)
) (3)
where χ22(N−u+1) denotes a chi-squared random variable with 2(N − u+ 1) degrees of freedom.
",4.1 The Partial Conjunction p−value,[0],[0]
"To understand the reasoning behind these methods, let us consider first the above p−values for testing the global null, i.e., for the case of u = 1.",4.1 The Partial Conjunction p−value,[0],[0]
Rejecting the global null hypothesis requires evidence that at least one null hypothesis is false.,4.1 The Partial Conjunction p−value,[0],[0]
"Intuitively, we would like to see one or more small p−values.
",4.1 The Partial Conjunction p−value,[0],[0]
Both of the methods above agree with this intuition.,4.1 The Partial Conjunction p−value,[0],[0]
"Bonferroni’s method rejects the global null if p(1) ≤ α/N , i.e. if the minimum p−value is small enough, where the threshold guarantees that the significance level of the test is α for any dependency among the p−values p1, . . .",4.1 The Partial Conjunction p−value,[0],[0]
", pN .",4.1 The Partial Conjunction p−value,[0],[0]
"Fisher’s method rejects the global null for large values of −2∑Ni=1 ln p(i), or equivalently for small values of∏N i=1",4.1 The Partial Conjunction p−value,[0],[0]
pi.,4.1 The Partial Conjunction p−value,[0],[0]
"That is, while both these methods are intuitive, they are different.",4.1 The Partial Conjunction p−value,[0],[0]
Fisher’s method requires a small enough product of p−values as evidence that at least one null hypothesis is false.,4.1 The Partial Conjunction p−value,[0],[0]
"Bonferroni’s method, on the other hand, requires as evidence at least one small enough p−value.
",4.1 The Partial Conjunction p−value,[0],[0]
"For the case u = N , i.e., when the alternative states that all null hypotheses are false, both methods require that the maximal p−value is small enough for rejection of HN/N0 .",4.1 The Partial Conjunction p−value,[0],[0]
This is also intuitive because we expect that all the p−values will be small when all the null hypotheses are false.,4.1 The Partial Conjunction p−value,[0],[0]
"For other cases, where 1 < u < N , the reasoning is more complicated and is beyond the scope of this paper.
",4.1 The Partial Conjunction p−value,[0],[0]
The partial conjunction test for a specific u answers the question “Does algorithm A perform better than B on at least u datasets?”,4.1 The Partial Conjunction p−value,[0],[0]
"The next step is
the estimation of the number of datasets for which algorithm A performs better than B.",4.1 The Partial Conjunction p−value,[0],[0]
Recall that the number of datasets where algorithm A outperforms algorithm B (denoted with k in Definition 1) is the true number of false null hypotheses in our problem.,4.2 Dataset Counting (Question 1),[0],[0]
"Benjamini and Heller (2008) proposed to estimate k to be the largest u for which H u/N 0 , along with H 1/N 0 , . . .",4.2 Dataset Counting (Question 1),[0],[0]
",H (u−1)/N 0 is rejected.",4.2 Dataset Counting (Question 1),[0],[0]
"Specifically, the estimator k̂ is defined as follows:
k̂ = max{u : pu/N∗ ≤",4.2 Dataset Counting (Question 1),[0],[0]
"α}, (4)
where pu/N∗ = max{p(u−1)/N∗ , pu/N}, p1/N = p1/N∗",4.2 Dataset Counting (Question 1),[0],[0]
and α is the desired upper bound on the probability to overestimate the true k.,4.2 Dataset Counting (Question 1),[0],[0]
"It is guaranteed that P(k̂ > k) ≤ α as long as the p−value combination method used for constructing pu/N is valid for the given dependency across the test statistics.5 When k̂ is based on pu/NBonferroni it is denoted with k̂Bonferroni; when it is based on p u/N Fisher, it is denoted with k̂Fisher.",4.2 Dataset Counting (Question 1),[0],[0]
"A crucial practical consideration, when choosing between k̂Bonferroni and k̂Fisher, is the assumed dependency between the datasets.",4.2 Dataset Counting (Question 1),[0],[0]
"As discussed in Section 4.1, pu/NFisher is recommended when the participating datasets are assumed to be independent; when this assumption cannot be made, only pu/NBonferroni is appropriate.",4.2 Dataset Counting (Question 1),[0],[0]
"As the k̂ estimators are based on the respective pu/N s, the same considerations hold when choosing between them.
",4.2 Dataset Counting (Question 1),[0],[0]
"With the k̂ estimators, one can answer the counting question of Section 1, reporting that algorithm",4.2 Dataset Counting (Question 1),[0],[0]
A is better than algorithm B in at least k̂ out of N datasets with a confidence level of 1 − α.,4.2 Dataset Counting (Question 1),[0],[0]
"Regarding the identification question, a natural approach would be to declare the k̂ datasets with the smallest p−values as those for which the effect holds.",4.2 Dataset Counting (Question 1),[0],[0]
"However, with k̂Fisher this approach does not guarantee control over type I errors.",4.2 Dataset Counting (Question 1),[0],[0]
"In contrast, for k̂Bonferroni, the above approach comes with such guarantees, as described in the next section.
",4.2 Dataset Counting (Question 1),[0],[0]
5This result is a special case of Theorem 4 in Benjamini and Heller (2008).,4.2 Dataset Counting (Question 1),[0],[0]
"As demonstrated in Section 3.2, identifying the datasets with p−value below the nominal significance level and declaring them as those where algorithm A is better than B may lead to a very high number of erroneous claims.",4.3 Dataset Identification (Question 2),[0],[0]
A variety of methods exist for addressing this problem.,4.3 Dataset Identification (Question 2),[0],[0]
"A classical and very simple method for addressing this problem is named the Bonferroni’s procedure, which compensates for the increased probability of making at least one type I error by testing each individual hypothesis at a significance level of α′ = α/N , where α is the predefined bound on this probability and N is the number of hypotheses tested.6 While Bonferroni’s procedure is valid for any dependency among the p−values, the probability of detecting a true effect using this procedure is often very low, because of its strict p−value threshold.
",4.3 Dataset Identification (Question 2),[0],[0]
"Many other procedures controlling the above or other error criteria, and having less strict p−value thresholds, have been proposed.",4.3 Dataset Identification (Question 2),[0],[0]
"Below we advocate one of these methods: the Holm procedure (Holm, 1979).",4.3 Dataset Identification (Question 2),[0],[0]
This is a simple p−value based procedure that is concordant with the partial conjunction analysis when pu/NBonferroni is used in that analysis.,4.3 Dataset Identification (Question 2),[0],[0]
"Importantly for NLP applications, Holm controls the probability of making at least one type I error for any type of dependency between the participating datasets (see a demonstration in Section 6).
",4.3 Dataset Identification (Question 2),[0],[0]
"Let α be the desired upper bound on the probability that at least one false rejection occurs, let p(1) ≤",4.3 Dataset Identification (Question 2),[0],[0]
p(2) ≤ . . .,4.3 Dataset Identification (Question 2),[0],[0]
≤,4.3 Dataset Identification (Question 2),[0],[0]
p(N) be the ordered p−values and let the associated hypotheses be H(1) . . .,4.3 Dataset Identification (Question 2),[0],[0]
H(N).,4.3 Dataset Identification (Question 2),[0],[0]
"The Holm procedure for identifying the datasets with a significant effect is given below.
",4.3 Dataset Identification (Question 2),[0],[0]
Procedure Holm 1),4.3 Dataset Identification (Question 2),[0],[0]
"Let k be the minimal index such that
p(k)",4.3 Dataset Identification (Question 2),[0],[0]
> α N+1−k . 2) Reject the null hypotheses H(1) . . .,4.3 Dataset Identification (Question 2),[0],[0]
H(k−1),4.3 Dataset Identification (Question 2),[0],[0]
"and
do not reject H(k) . . .",4.3 Dataset Identification (Question 2),[0],[0]
H(N).,4.3 Dataset Identification (Question 2),[0],[0]
"If no such k exists, then reject all null hypotheses.
",4.3 Dataset Identification (Question 2),[0],[0]
The output of the Holm procedure is a rejection 6Bonferroni’s correction is based on similar considerations as pu/NBonferroni for u = 1 (Eq. 2).,4.3 Dataset Identification (Question 2),[0],[0]
"The partial conjunction framework (Sec. 4.1) extends this idea for other values of u.
list of null hypotheses; the corresponding datasets are those we return in response to the identification question of Section 1.",4.3 Dataset Identification (Question 2),[0],[0]
Note that the Holm procedure rejects a subset of hypotheses with p-value below α.,4.3 Dataset Identification (Question 2),[0],[0]
Each p-value is compared to a threshold which is smaller or equal to α and depends on the number of evaluation datasets N.,4.3 Dataset Identification (Question 2),[0],[0]
"The dependence of the thresholds on N can be intuitively explained as follows: the probability of making one or more erroneous claims may increase with N, as demonstrated in Section 3.2.",4.3 Dataset Identification (Question 2),[0],[0]
"Therefore, in order to bound this probability by a pre-specified level α, the thresholds for p-values should depend on N.
It can be shown that the Holm procedure at level α always rejects the k̂Bonferroni hypotheses with the smallest p−values, where k̂Bonferroni is the lower bound for k with a confidence level of 1 − α.",4.3 Dataset Identification (Question 2),[0],[0]
"Therefore, k̂Bonferroni corresponding to a confidence level of 1 − α is always smaller or equal to the number of datasets for which the difference between the compared algorithms is significant at level α.",4.3 Dataset Identification (Question 2),[0],[0]
"This is not surprising in view of the fact that, without making any assumptions on the dependencies among the datasets, k̂Bonferroni guarantees that the probability of making a too optimistic claim (k̂ > k) is bounded by α, when simply counting the number of datasets with p-value below α, the probability of making a too optimistic claim may be close to 1, as demonstrated in Section 5.
",4.3 Dataset Identification (Question 2),[0],[0]
Framework Summary Following Section 4.2 we answer the counting question of Section 1 by reporting either k̂Fisher (when all datasets can be assumed to be independent) or k̂Bonferroni (when such an independence assumption cannot be made).,4.3 Dataset Identification (Question 2),[0],[0]
"Based on Section 4.3 we suggest to answer the identification question of Section 1 by reporting the rejection list returned by the Holm procedure.
",4.3 Dataset Identification (Question 2),[0],[0]
Our proposed framework is based on certain assumptions regarding the experiments conducted in NLP setups.,4.3 Dataset Identification (Question 2),[0],[0]
The most prominent of these assumptions states that for dependent datasets the type of dependency cannot be determined.,4.3 Dataset Identification (Question 2),[0],[0]
"Indeed, to the best of our knowledge, the nature of the dependency between dependent test sets in NLP work has not been analyzed before.",4.3 Dataset Identification (Question 2),[0],[0]
In Section 7 we revisit our assumptions and point to alternative methods for answering our questions.,4.3 Dataset Identification (Question 2),[0],[0]
"These methods may be ap-
propriate under other assumptions that may become relevant in future.
",4.3 Dataset Identification (Question 2),[0],[0]
We next demonstrate the value of the proposed replicability analysis through toy examples with synthetic data (Section 5) as well as analysis of state-of-the-art algorithms for four major NLP applications (Section 6).,4.3 Dataset Identification (Question 2),[0],[0]
"Our point of reference is the standard, yet statistically unjustified, counting method that sets its estimator, k̂count, to the number of datasets for which the difference between the compared algorithms is significant with p−value ≤ α (i.e. k̂count = #{i : pi ≤ α}).7",4.3 Dataset Identification (Question 2),[0],[0]
"For the examples of this section we synthesize p−values to emulate a test with N = 100 hypotheses (domains), and set α to 0.05.",5 Toy Examples,[0],[0]
"We start with a simulation of a scenario where algorithmA is equivalent to B for each domain, and the datasets representing these domains are independent.",5 Toy Examples,[0.959302630485018],"['Assuming that humans have limited time, and are thus willing to look at B rules, we propose a method for selecting such a set of rules given a reference dataset X .']"
"We sample the 100 p−values from a standard uniform distribution, which is the p−value distribution under the null hypothesis, repeating the simulation 1,000 times.
",5 Toy Examples,[0],[0]
"Since all the null hypotheses are true then k, the number of false null hypotheses, is 0.",5 Toy Examples,[0],[0]
"Figure 1 presents the histogram of k̂ values from all 1,000 iterations according to k̂Bonferroni, k̂Fisher and k̂count.
",5 Toy Examples,[0],[0]
The figure clearly demonstrates that k̂count provides an overestimation of k while k̂Bonferroni and k̂Fisher do much better.,5 Toy Examples,[0],[0]
"Indeed, the histogram yields the following probability estimates: P̂ (k̂count >
7We use α in two different contexts: the significance level of an individual test and the bound on the probability to overestimate k.",5 Toy Examples,[0],[0]
"This is the standard notation in the statistical literature.
",5 Toy Examples,[0],[0]
"k) = 0.963, P̂ (k̂Bonferroni > k) = 0.001 and P̂ (k̂Fisher > k) = 0.021 (only the latter two are lower than 0.05).",5 Toy Examples,[0],[0]
"This simulation strongly supports the theoretical results of Section 4.2.
",5 Toy Examples,[0],[0]
"To consider a scenario where a dependency between the participating datasets does exist, we consider a second toy example.",5 Toy Examples,[0],[0]
"In this example we generate N = 100 p−values corresponding to 34 independent normal test statistics, and two other groups of 33 positively correlated normal test statistics with ρ = 0.2 and ρ = 0.5, respectively.",5 Toy Examples,[0],[0]
"We again assume that all null hypotheses are true and thus all the p−values are distributed uniformly, repeating the simulation 1,000 times.",5 Toy Examples,[0],[0]
"To generate positively dependent p−values, we followed the process described in Section 6.1 of Benjamini et al. (2006).
",5 Toy Examples,[0],[0]
We estimate the probability that k̂ > k,5 Toy Examples,[0],[0]
= 0,5 Toy Examples,[0],[0]
"for the three k̂ estimators based on the 1000 repetitions and get the values of: P̂ (k̂count > k) = 0.943, P̂ (k̂Bonferroni > k) = 0.046 and P̂ (k̂Fisher > k) = 0.234.",5 Toy Examples,[0],[0]
"This simulation demonstrates the importance of using Bonferroni’s method rather than Fisher’s method when the datasets are dependent, even if some of the datasets are independent.",5 Toy Examples,[0],[0]
In this section we demonstrate the potential impact of replicability analysis on the way experimental results are analyzed in NLP setups.,6 NLP Applications,[0],[0]
We explore four NLP applications: (a) two where the datasets are independent: multi-domain dependency parsing and multilingual POS tagging; and (b) two where dependency between the datasets does exist: cross-domain sentiment classification and word similarity prediction with word embedding models.,6 NLP Applications,[0],[0]
"Dependency Parsing We consider a multidomain setup, analyzing the results reported in Choi et al. (2015).",6.1 Data,[0],[0]
"The authors compared ten state-of-the-art parsers from which we pick three: (a) Mate (Bohnet, 2010)8 that performed best on the majority of datasets; (b) Redshift (Honnibal et al., 2013)9 which demonstrated comparable, still somewhat lower, performance compared to Mate;
8code.google.com/p/mate-tools.",6.1 Data,[0],[0]
"9github.com/syllog1sm/Redshift.
",6.1 Data,[0],[0]
"and (c) SpaCy (Honnibal and Johnson, 2015) that was substantially outperformed by Mate.
",6.1 Data,[0],[0]
"All parsers were trained and tested on the English portion of the OntoNotes 5 corpus (Weischedel et al., 2011; Pradhan et al., 2013), a large multigenre corpus consisting of the following 7 genres: broadcasting conversations (BC), broadcasting news (BN), news magazine (MZ), newswire (NW), pivot text (PT), telephone conversations (TC) and web text (WB).",6.1 Data,[0],[0]
"Train and test set size (in sentences) range from 6672 to 34,492 and from 280 to 2327, respectively (see Table 1 of Choi et al. (2015)).",6.1 Data,[0],[0]
"We copy the test set UAS results of Choi et al. (2015) and compute p−values using the data downloaded from http://amandastent.com/dependable/.
POS Tagging We consider a multilingual setup, analyzing the results reported in (Pinter et al., 2017).",6.1 Data,[0],[0]
"The authors compare their MIMICK model with the model of Ling et al. (2015), denoted with CHAR→TAG.",6.1 Data,[0],[0]
"Evaluation is performed on 23 of the 44 languages shared by the Polyglot word embedding dataset (Al-Rfou et al., 2013) and the universal dependencies (UD) dataset (De Marneffe et al., 2014).",6.1 Data,[0],[0]
"Pinter et al. (2017) choose their languages so that they reflect a variety of typological, and particularly morphological, properties.",6.1 Data,[0],[0]
The training/test split is the standard UD split.,6.1 Data,[0],[0]
"We copy the word level accuracy figures of Pinter et al. (2017) for the low resource training set setup, the focus setup of that paper.",6.1 Data,[0],[0]
"The authors kindly sent us their p-values.
",6.1 Data,[0],[0]
"Sentiment Classification In this task, an algorithm is trained on reviews from one domain and should classify the sentiment of reviews from another domain to the positive and negative classes.",6.1 Data,[0],[0]
For replicability analysis we explore the results of Ziser and Reichart (2017) for the cross-domain sentiment classification task of Blitzer et al. (2007).,6.1 Data,[0],[0]
"The data in this task consists of Amazon product reviews from 4 domains: books (B), DVDs (D), electronic items (E), and kitchen appliances (K), for the total of 12 domain pairs, each domain having a 2000 review test set.10 Ziser and Reichart (2017) compared the accuracy of their AE-SCL-SR model to MSDA (Chen et al., 2011), a well known domain adaptation
10http://www.cs.jhu.edu/˜mdredze/ datasets/sentiment
method, and kindly sent us the required p-values.
",6.1 Data,[0],[0]
Word Similarity We compare two state-of-the-art word embedding collections: (a) word2vec,6.1 Data,[0],[0]
"CBOW (Mikolov et al., 2013) vectors, generated by the model titled the best “predict” model in Baroni et al. (2014);11 and (b) GloVe (Pennington et al., 2014) vectors generated by a model trained on a 42B token common web crawl.12 We employed the demo of Faruqui and Dyer (2014) to perform a Spearman correlation evaluation of these vector collections on 12 English word pair datasets: WS-353 (Finkelstein et al., 2001b), WS-353-SIM (Agirre et al., 2009), WS-353-REL (Agirre et al., 2009), MC-30 (Miller and Charles, 1991), RG-65 (Rubenstein and Goodenough, 1965), Rare-Word (Luong et al., 2013), MEN (Bruni et al., 2012), MTurk-287 (Radinsky et al., 2011), MTurk-771",6.1 Data,[0],[0]
"(Halawi et al., 2012), YP-130 (Yang and Powers, ), SimLex-999 (Hill et al., 2016), and Verb-143 (Baker et al., 2014).",6.1 Data,[0],[0]
"We first calculate the p−values for each task and dataset according to the principals of p−values computation for NLP as discussed in Yeh (2000), BergKirkpatrick et al. (2012) and Søgaard et al. (2014).
",6.2 Statistical Significance Tests,[0],[0]
"For dependency parsing, we employ the aparametric paired bootstrap test (Efron and Tibshirani, 1994) that does not assume any distribution on the test statistics.",6.2 Statistical Significance Tests,[0],[0]
We chose this test because the distribution of the values for the measures commonly applied in this task is unknown.,6.2 Statistical Significance Tests,[0],[0]
"We implemented the test as in (Berg-Kirkpatrick et al., 2012) with a bootstrap size of 500 and with 105 repetitions.
",6.2 Statistical Significance Tests,[0],[0]
"For multilingual POS tagging, we employ the Wilcoxon signed-rank test (Wilcoxon, 1945) on the differences of the sentence level accuracy scores of the two compared models.",6.2 Statistical Significance Tests,[0],[0]
"This test is a nonparametric test for differences in measure, testing the null hypothesis that the difference has a symmetric distribution around zero.",6.2 Statistical Significance Tests,[0],[0]
"It is appropriate for tasks with paired continuous measures for each observation, which is the case when comparing sentence level accuracies.
",6.2 Statistical Significance Tests,[0],[0]
11http://clic.cimec.unitn.it/composes/ semantic-vectors.html.,6.2 Statistical Significance Tests,[0],[0]
"Parameters: 5-word context window, 10 negative samples, subsampling, 400 dimensions.
",6.2 Statistical Significance Tests,[0],[0]
"12http://nlp.stanford.edu/projects/glove/. 300 dimensions.
",6.2 Statistical Significance Tests,[0],[0]
"For sentiment classification we employ the McNemar test for paired nominal data (McNemar, 1947).",6.2 Statistical Significance Tests,[0],[0]
"This test is appropriate for binary classification tasks and since we compare the results of the algorithms when applied on the same datasets, we employ its paired version.",6.2 Statistical Significance Tests,[0],[0]
"Finally, for word similarity with its Spearman correlation evaluation, we choose the Steiger test (Steiger, 1980) for comparing elements in a correlation matrix.
",6.2 Statistical Significance Tests,[0],[0]
We consider the case of α = 0.05 for all four applications.,6.2 Statistical Significance Tests,[0],[0]
"For the dependent datasets experiments (sentiment classification and word similarity prediction) with their generally lower p−values (see below), we also consider the case where α = 0.01.",6.2 Statistical Significance Tests,[0],[0]
"Table 1 summarizes the replicability analysis results while Table 2 – 5 present task specific performance measures and p−values.
",6.3 Results,[0],[0]
"Independent Datasets Dependency parsing (Table 2) and multilingual POS tagging (Table 3) are our example tasks for this setup, where k̂Fisher is our recommended valid estimator for the number of cases where one algorithm outperforms another.
",6.3 Results,[0],[0]
"For dependency parsing, we compare two scenarios: (a) where in most domains the differences between the compared algorithms are quite large and the p−values are small (Mate vs. SpaCy); and (b)
where in most domains the differences between the compared algorithms are smaller and the p−values are higher (Mate vs. Redshift).",6.3 Results,[0],[0]
"Our multilingual POS tagging scenario (MIMICK vs. Char→Tag) is more similar to scenario (b) in terms of the differences between the participating algorithms.
",6.3 Results,[0],[0]
Table 1 demonstrates the k̂ estimators for the various tasks and scenarios.,6.3 Results,[0],[0]
"For dependency parsing, as expected, in scenario (a) where all the p−values are small, all estimators, even the error-prone k̂count, provide the same information.",6.3 Results,[0],[0]
"In case (b) of dependency parsing, however, k̂Fisher estimates the number of domains where Mate outperforms Redshift to be 5, while k̂count estimates this number to be 2.",6.3 Results,[0],[0]
This is a substantial difference given that the number of domains is 7.,6.3 Results,[0],[0]
"The k̂Bonferroni estimator, that is valid under arbitrary dependencies, is even more conservative than k̂count and its estimation is only 1.
",6.3 Results,[0],[0]
"Perhaps not surprisingly, the multilingual POS
tagging results are similar to case (b) of dependency parsing.",6.3 Results,[0],[0]
"Here, again, k̂count is too conservative, estimating the number of languages with effect to be 11 (out of 23) while k̂Fisher estimates this number to be 16 (an increase of 5/23 in the estimated number of languages with effect).",6.3 Results,[0],[0]
"k̂Bonferroni is again more conservative, estimating the number of languages with effect to be only 6, which is not very surprising given that it does not exploit the independence between the datasets.",6.3 Results,[0],[0]
"These two examples of case (b) demonstrate that when the differences between the algorithms are quite small, k̂Fisher may be more sensitive than the current practice in NLP for discovering the number of datasets with effect.
",6.3 Results,[0],[0]
"To complete the analysis, we would like to name the datasets with effect.",6.3 Results,[0],[0]
"As discussed in Section 4.2, while this can be straightforwardly done by naming the datasets with the k̂ smallest p−values, in general, this approach does not control the probability of identifying at least one dataset erroneously.",6.3 Results,[0],[0]
"We thus employ the Holm procedure for the identification task, noticing that the number of datasets it identifies should be equal to the value of the k̂Bonferroni estimator (Section 4.3).
",6.3 Results,[0],[0]
"Indeed, for dependency parsing in case (a), the Holm procedure identifies all seven domains as cases where Mate outperforms SpaCy, while in case (b) it identifies only the MZ domain as a case where Mate outperforms Redshift.",6.3 Results,[0],[0]
"For multilingual POS
tagging the Holm procedure identifies Tamil, Hungarian, Basque, Indonesian, Chinese and Czech as languages where MIMICK outperforms Char→Tag.",6.3 Results,[0],[0]
"This analysis demonstrates that when the performance gap between two algorithms becomes narrower, inquiring for more information (i.e. identifying the domains with effect rather than just estimating their number), may result in weaker results.13
Dependent Datasets In cross-domain sentiment classification (Table 4) and word similarity prediction (Table 5), the involved datasets manifest mutual dependence.",6.3 Results,[0],[0]
"Particularly, each sentiment setup shares its test dataset with 2 other setups, while in word similarity WS-353 is the union of WS-353REL and WS-353-SIM.",6.3 Results,[0],[0]
"As discussed in Section 4, k̂Bonferroni is the appropriate estimator of the number of cases one algorithm outperforms another.
",6.3 Results,[0],[0]
"The results in Table 1 manifest the phenomenon demonstrated by the second toy example in Section 5, which shows that when the datasets are dependent, k̂Fisher as well as the error-prone k̂count may be too optimistic regarding the number of datasets with effect.",6.3 Results,[0],[0]
"This stands in contrast to k̂Bonferroni which controls the probability to overestimate the number of such datasets.
",6.3 Results,[0],[0]
"Indeed, k̂Bonferroni is much more conservative, yielding values of 6 (α = 0.05) and 2 (α = 0.01) for sentiment, and of 6 (α = 0.05) and 4 (α = 0.01) for word similarity.",6.3 Results,[0],[0]
The differences from the conclusions that might have been drawn by k̂count are again quite substantial.,6.3 Results,[0],[0]
"The difference between k̂Bonferroni and k̂count in sentiment classification is 4, which accounts to 1/3 of the 12 test setups.",6.3 Results,[0],[0]
"Even for word similarity, the difference between the two methods, which account to 2 for both α values, represents 1/6 of the 12 test setups.",6.3 Results,[0],[0]
"The domains identified by the Holm procedure are marked in the tables.
",6.3 Results,[0],[0]
"Results Overview Our goal in this section is to demonstrate that the approach of simply looking at the number of datasets for which the difference between the performance of the algorithms reaches a predefined significance level, gives different results
13For completeness, we also performed the analysis for the independent dataset setups with α = 0.01.",6.3 Results,[0],[0]
"The results are (k̂count, k̂Bonferroni, k̂Fisher): Mate vs. SpaCy: (7,7,7); Mate vs. Redshift (1,0,2); MIMICK vs. Char→Tag: (7,5,13).",6.3 Results,[0],[0]
"The patterns are very similar to those discussed in the text.
from our suggested statistically sound analysis.",6.3 Results,[0],[0]
This approach is denoted here with k̂count and shown to be statistically not valid in Sections 3.2 and 5.,6.3 Results,[0],[0]
We observe that this happens especially in evaluation setups where the differences between the algorithms are small for most datasets.,6.3 Results,[0],[0]
"In some cases, when the datasets are independent, our analysis has the power to declare a larger number of datasets with effect than the number of individual significant test values (k̂count).",6.3 Results,[0],[0]
"In other cases, when the datasets are interdependent, k̂count is much too optimistic.
",6.3 Results,[0],[0]
Our proposed analysis changes the observations that might have been made based on the papers where the results analyzed here were originally reported.,6.3 Results,[0],[0]
"For example, for the Mate-Redshift comparison (independent evaluation sets), we show that there is evidence that the number of datasets with effect is much higher than one would assume based on counting the significant sets (5 vs. 2 out of 7 evaluation sets), giving a stronger claim regarding the superiority of Mate.",6.3 Results,[0],[0]
"In multilingual POS tagging (again, a setup of independent evaluation sets) our analysis shows evidence for 16 sets with effect compared to only 11 of the erroneous count method - a difference in 5 out of 23 evaluation sets (21.7%).",6.3 Results,[0],[0]
"Finally, in the cross-domain sentiment classification and the word similarity judgment tasks (dependent evaluation sets), the unjustified counting method may be too optimistic (e.g. 10 vs. 6 out of 12 evaluation sets, for α = 0.05 in the sentiment task), in favor of the new algorithms.",6.3 Results,[0],[0]
We proposed a statistically sound replicability analysis framework for cases where algorithms are compared across multiple datasets.,7 Discussion and Future Directions,[0],[0]
"Our main contributions are: (a) analyzing the limitations of the current practice in NLP work; and (b) proposing a framework that addresses both the estimation of the number of datasets with effect and their identification.
",7 Discussion and Future Directions,[0],[0]
The framework we propose addresses two different situations encountered in NLP: independent and dependent datasets.,7 Discussion and Future Directions,[0],[0]
"For dependent datasets, we assumed that the type of dependency cannot be determined.",7 Discussion and Future Directions,[0],[0]
One could use more powerful methods if certain assumptions on the dependency between the test statistics could be made.,7 Discussion and Future Directions,[0],[0]
"For example, one could use
the partial conjunction p-value based on Simes test for the global null hypothesis (Simes, 1986), which was proposed by Benjamini and Heller (2008) for the case where the test statistics satisfy certain positive dependency properties (see Theorem 1 in (Benjamini and Heller, 2008)).",7 Discussion and Future Directions,[0],[0]
"Using this partial conjunction p-value rather than the one based on Bonferroni, one may obtain higher values of k̂ with the same statistical guarantee.",7 Discussion and Future Directions,[0],[0]
"Similarly, for the identification question, if certain positive dependency properties hold, Holm’s procedure could be replaced by Hochberg’s or Hommel’s procedures (Hochberg, 1988; Hommel, 1988) which are more powerful.
",7 Discussion and Future Directions,[0],[0]
"An alternative, more powerful multiple testing procedure for identification of datasets with effect, is the method in Benjamini and Hochberg (1995), that controls the false discovery rate (FDR), a less strict error criterion than the one considered here.",7 Discussion and Future Directions,[0],[0]
"This method is more appropriate in cases where one may tolerate some errors as long as the proportion of errors among all the claims made is small, as expected to happen when the number of datasets grows.
",7 Discussion and Future Directions,[0],[0]
We note that the increase in the number of evaluation datasets may have positive and negative aspects.,7 Discussion and Future Directions,[0],[0]
"As noted in Section 2, we believe that multiple comparisons are integral to NLP research when aiming to develop algorithms that perform well across languages and domains.",7 Discussion and Future Directions,[0],[0]
"On the other hand, experimenting with multiple evaluation sets that reflect very similar linguistic phenomena may only complicate the comparison between alternative algorithms.
",7 Discussion and Future Directions,[0],[0]
"In fact, our analysis is useful mostly where the datasets are heterogeneous, coming from different languages or domains.",7 Discussion and Future Directions,[0],[0]
"When they are just technically different but could potentially be just combined into a one big dataset, then we believe the question of Demšar (2006), whether at least one dataset shows evidence for effect, is more appropriate.",7 Discussion and Future Directions,[0],[0]
The research of M. Bogomolov was supported by the Israel Science Foundation grant No. 1112/14.,Acknowledgement,[0],[0]
We thank Yuval Pinter for his great help with the multilingual experiments and for his useful feedback.,Acknowledgement,[0],[0]
"We also thank Ruth Heller, Marten van Schijndel, Oren Tsur, Or Zuk and the ie@technion NLP group members for their useful comments.",Acknowledgement,[0],[0]
"With the ever growing amount of textual data from a large variety of languages, domains, and genres, it has become standard to evaluate NLP algorithms on multiple datasets in order to ensure a consistent performance across heterogeneous setups.",abstractText,[0],[0]
"However, such multiple comparisons pose significant challenges to traditional statistical analysis methods in NLP and can lead to erroneous conclusions.",abstractText,[0],[0]
In this paper we propose a Replicability Analysis framework for a statistically sound analysis of multiple comparisons between algorithms for NLP tasks.,abstractText,[0],[0]
"We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction.",abstractText,[0],[0]
1,abstractText,[0],[0]
Replicability Analysis for Natural Language Processing: Testing Significance with Multiple Datasets,title,[0],[0]
Graphs are a ubiquitous structure that widely occurs in data analysis problems.,1. Introduction,[0],[0]
"Real-world graphs such as social networks, financial networks, biological networks and citation networks represent important rich information which is not seen from the individual entities alone, for example, the communities a person is in, the functional role of a molecule, and the sensitivity of the assets of an enterprise to external shocks.",1. Introduction,[0],[0]
"Therefore, representation learning of nodes in graphs aims to extract high-level features from a node as well as its neighborhood, and has proved extremely useful for many applications, such as node classification, clustering, and link prediction (Perozzi et al., 2014; Monti et al.,
1Massachusetts Institute of Technology (MIT) 2National Institute of Informatics, Tokyo.",1. Introduction,[0],[0]
Correspondence to: Keyulu Xu,1. Introduction,[0],[0]
"<keyulu@mit.edu>, Stefanie Jegelka <stefje@mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
2017; Grover & Leskovec, 2016; Tang et al., 2015).
",1. Introduction,[0],[0]
Recent works focus on deep learning approaches to node representation.,1. Introduction,[0],[0]
"Many of these approaches broadly follow a neighborhood aggregation (or “message passing” scheme), and those have been very promising (Kipf & Welling, 2017; Hamilton et al., 2017; Gilmer et al., 2017; Veličković",1. Introduction,[0],[0]
"et al., 2018; Kearnes et al., 2016).",1. Introduction,[0],[0]
"These models learn to iteratively aggregate the hidden features of every node in the graph with its adjacent nodes’ as its new hidden features, where an iteration is parametrized by a layer of the neural network.",1. Introduction,[0],[0]
"Theoretically, an aggregation process of k iterations makes use of the subtree structures of height k rooted at every node.",1. Introduction,[0],[0]
"Such schemes have been shown to generalize the Weisfeiler-Lehman graph isomorphism test (Weisfeiler & Lehman, 1968) enabling to simultaneously learn the topology as well as the distribution of node features in the neighborhood (Shervashidze et al., 2011; Kipf & Welling, 2017; Hamilton et al., 2017).
",1. Introduction,[0],[0]
"Yet, such aggregation schemes sometimes lead to surprises.",1. Introduction,[0],[0]
"For example, it has been observed that the best performance with one of the state-of-the-art models, Graph Convolutional Networks (GCN), is achieved with a 2-layer model.",1. Introduction,[0],[0]
"Deeper versions of the model that, in principle, have access to more information, perform worse (Kipf & Welling, 2017).",1. Introduction,[0],[0]
"A similar degradation of learning for computer vision problems is resolved by residual connections (He et al., 2016a) that greatly aid the training of deep models.",1. Introduction,[0],[0]
"But, even with residual connections, GCNs with more layers do not perform as well as the 2-layer GCN on many datasets, e.g. citation networks.
",1. Introduction,[0],[0]
"Motivated by observations like the above, in this paper, we address two questions.",1. Introduction,[0],[0]
"First, we study properties and resulting limitations of neighborhood aggregation schemes.",1. Introduction,[0],[0]
"Second, based on this analysis, we propose an architecture that, as opposed to existing models, enables adaptive, structure-aware representations.",1. Introduction,[0],[0]
"Such representations are particularly interesting for representation learning on large complex graphs with diverse subgraph structures.
",1. Introduction,[0],[0]
Model analysis.,1. Introduction,[0],[0]
"To better understand the behavior of different neighborhood aggregation schemes, we analyze the effective range of nodes that any given node’s representation draws from.",1. Introduction,[0],[0]
"We summarize this sensitivity analysis by what
we name the influence distribution of a node.",1. Introduction,[0],[0]
This effective range implicitly encodes prior assumptions on what are the “nearest neighbors” that a node should draw information from.,1. Introduction,[0],[0]
"In particular, we will see that this influence is heavily affected by the graph structure, raising the question whether “one size fits all”, in particular in graphs whose subgraphs have varying properties (such as more tree-like or more expander-like).
",1. Introduction,[0],[0]
"In particular, our more formal analysis connects influence distributions with the spread of a random walk at a given node, a well-understood phenomenon as a function of the graph structure and eigenvalues (Lovász, 1993).",1. Introduction,[0.9556412841976127],"['A rule takes the form r = (a→c), where the first instance of the antecedent a is replaced by the consequent c for every instance that includes a, as we previously illustrated in Figure 2a.']"
"For instance, in some cases and applications, a 2-step random walk influence that focuses on local neighborhoods can be more informative than higher-order features where some of the information may be “washed out” via averaging.
",1. Introduction,[0],[0]
Changing locality.,1. Introduction,[0],[0]
"To illustrate the effect and importance of graph structure, recall that many real-world graphs possess locally strongly varying structure.",1. Introduction,[0],[0]
"In biological and citation networks, the majority of the nodes have few connections, whereas some nodes (hubs) are connected to many other nodes.",1. Introduction,[0],[0]
"Social and web networks usually consist of an expander-like core part and an almost-tree (bounded treewidth) part, which represent well-connected entities and the small communities respectively (Leskovec et al., 2009; Maehara et al., 2014; Tsonis et al., 2006).
",1. Introduction,[0],[0]
"Besides node features, this subgraph structure has great impact on the result of neighborhood aggregation.",1. Introduction,[0],[0]
"The speed of expansion or, equivalently, growth of the influence radius, is characterized by the random walk’s mixing time, which changes dramatically on subgraphs with different structures (Lovász, 1993).",1. Introduction,[0],[0]
"Thus, the same number of iterations (layers) can lead to influence distributions of very different locality.",1. Introduction,[0],[0]
"As an example, consider the social network in Figure 1 from GooglePlus (Leskovec & Mcauley, 2012).",1. Introduction,[0],[0]
The figure illustrates the expansions of a random walk starting at the square node.,1. Introduction,[0],[0]
The walk (a) from a node within the core rapidly includes almost the entire graph.,1. Introduction,[0],[0]
"In contrast, the walk (b) starting at a node in the tree part includes only a very small fraction of all nodes.",1. Introduction,[0],[0]
"After 5 steps, the same walk has reached the core and, suddenly, spreads quickly.",1. Introduction,[0],[0]
"Translated to graph representation models, these spreads become the influence distributions or, in other words, the averaged features yield the new feature of the walk’s starting node.",1. Introduction,[0],[0]
"This shows that in the same graph, the same number of steps can lead to very different effects.",1. Introduction,[0],[0]
"Depending on the application, wide-range or smallrange feature combinations may be more desirable.",1. Introduction,[0],[0]
"A too rapid expansion may average too broadly and thereby lose information, while in other parts of the graph, a sufficient neighborhood may be needed for stabilizing predictions.
",1. Introduction,[0],[0]
JK networks.,1. Introduction,[0],[0]
"The above observations raise the question
whether it is possible to adaptively adjust (i.e., learn) the influence radii for each node and task.",1. Introduction,[0],[0]
"To achieve this, we explore an architecture that learns to selectively exploit information from neighborhoods of differing locality.",1. Introduction,[0],[0]
"This architecture selectively combines different aggregations at the last layer, i.e., the representations “jump” to the last layer.",1. Introduction,[0],[0]
"Hence, we name the resulting networks Jumping Knowledge Networks (JK-Nets).",1. Introduction,[0],[0]
"We will see that empirically, when adaptation is an option, the networks indeed learn representations of different orders for different graph substructures.",1. Introduction,[0],[0]
"Moreover, in Section 6, we show that applying our framework to various state-of-the-art neighborhood-aggregation models consistently improves their performance.",1. Introduction,[0],[0]
"We begin by summarizing some of the most common neighborhood aggregation schemes and, along the way, introduce our notation.",2. Background and Neighborhood aggregation schemes,[0],[0]
"Let G = (V,E) be a simple graph with node features Xv ∈",2. Background and Neighborhood aggregation schemes,[0],[0]
Rdi for v ∈ V .,2. Background and Neighborhood aggregation schemes,[0],[0]
Let G̃ be the graph obtained by adding a self-loop to every v ∈ V .,2. Background and Neighborhood aggregation schemes,[0],[0]
The hidden feature of node v learned by the l-th layer of the model is denoted by h (l) v ∈,2. Background and Neighborhood aggregation schemes,[0],[0]
Rdh .,2. Background and Neighborhood aggregation schemes,[0],[0]
"Here, di is the dimension of the input features and dh is the dimension of the hidden features, which, for simplicity of exposition, we assume to be the same across layers.",2. Background and Neighborhood aggregation schemes,[0],[0]
We also use h(0)v = Xv for the node feature.,2. Background and Neighborhood aggregation schemes,[0],[0]
"The neighborhood N(v) = {u ∈ V | (v, u) ∈ E} of node v is the set of adjacent nodes of v. The analogous neighborhood Ñ(v) = {v} ∪ {u ∈ V | (v, u) ∈ E} on G̃ includes v.
A typical neighborhood aggregation scheme can generically be written as follows: for a k-layer model, the l-th layer (l = 1..k) updates h(l)v for every v ∈ V simultaneously as
h(l)v = σ",2. Background and Neighborhood aggregation schemes,[0],[0]
"( Wl · AGGREGATE ({ h(l−1)u ,∀u ∈ Ñ(v) }))",2. Background and Neighborhood aggregation schemes,[0],[0]
"(1)
where AGGREGATE is an aggregation function defined by the specific model, Wl is a trainable weight matrix on the lth layer shared by all nodes, and σ is a non-linear activation function, e.g. a ReLU.
",2. Background and Neighborhood aggregation schemes,[0],[0]
Graph Convolutional Networks (GCN).,2. Background and Neighborhood aggregation schemes,[0],[0]
"Graph Convolutional Networks (GCN) (Kipf & Welling, 2017), initially motivated by spectral graph convolutions (Hammond et al., 2011; Defferrard et al., 2016), are a specific instantiation of this framework (Gilmer et al., 2017), of the form
h(l)v = ReLU ( Wl · ∑ u∈Ñ(v) (deg(v)deg(u))−1/2 h(l−1)u ) (2)
where deg(v) is the degree of node v in G. Hamilton et al. (2017) derived a variant of GCN that also works in inductive settings (previously unseen nodes), by using a different normalization to average:
h(l)v",2. Background and Neighborhood aggregation schemes,[0],[0]
"= ReLU ( Wl · 1
d̃eg(v) ∑ u∈Ñ(v) h(l−1)u ) (3)
where d̃eg(v) is the degree of node v in G̃.
Neighborhood Aggregation with Skip Connections.",2. Background and Neighborhood aggregation schemes,[0],[0]
Instead of aggregating a node and its neighbors at the same time as in Eqn.,2. Background and Neighborhood aggregation schemes,[0],[0]
"(1), a number of recent approaches aggregate the neighbors first and then combine the resulting neighborhood representation with the node’s representation from the last iteration.",2. Background and Neighborhood aggregation schemes,[0],[0]
"More formally, each node is updated as
h (l) N(v) = σ",2. Background and Neighborhood aggregation schemes,[0],[0]
"( Wl · AGGREGATEN ( {h(l−1)u ,∀u ∈ N(v)} )) h(l)v =",2. Background and Neighborhood aggregation schemes,[0],[0]
"COMBINE ( h(l−1)v , h (l) N(v)
) where AGGREGATEN and COMBINE are defined by the specific model.",2. Background and Neighborhood aggregation schemes,[0],[0]
The COMBINE step is key to this paradigm and can be viewed as a form of a ”skip connection” between different layers.,2. Background and Neighborhood aggregation schemes,[0],[0]
"For COMBINE, GraphSAGE (Hamilton et al., 2017) uses concatenation after a feature transform.",2. Background and Neighborhood aggregation schemes,[0],[0]
"Column Networks (Pham et al., 2017) interpolate the neighborhood representation and the node’s previous representation, and Gated GNN (Li et al., 2016) uses the Gated Recurrent Unit (GRU) (Cho et al., 2014).",2. Background and Neighborhood aggregation schemes,[0],[0]
"Another wellknown variant of skip connections, residual connections, use the identity mapping to help signals propagate (He et al., 2016a;b).
",2. Background and Neighborhood aggregation schemes,[0],[0]
"These skip connections are input- but not output-unit specific: If we ”skip” a layer for h(l)v (do not aggregate) or use a certain COMBINE, all subsequent units using this representation will be using this skip implicitly.",2. Background and Neighborhood aggregation schemes,[0],[0]
It is impossible that a certain higher-up representation h(l+j)u uses the skip and another one does not.,2. Background and Neighborhood aggregation schemes,[0],[0]
"As a result, skip connections cannot adaptively adjust the neighborhood sizes of the final-layer representations independently.
",2. Background and Neighborhood aggregation schemes,[0],[0]
Neighborhood Aggregation with Directional Biases.,2. Background and Neighborhood aggregation schemes,[0],[0]
"Some recent models, rather than treating the features of
adjacent nodes equally, weigh “important” neighbors more.",2. Background and Neighborhood aggregation schemes,[0],[0]
"This paradigm can be viewed as neighborhood-aggregation with directional biases because a node will be influenced by some directions of expansion more than the others.
",2. Background and Neighborhood aggregation schemes,[0],[0]
"Graph Attention Networks (GAT) (Veličković et al., 2018) and VAIN (Hoshen, 2017) learn to select the important neighbors via an attention mechanism.",2. Background and Neighborhood aggregation schemes,[0],[0]
"The max-pooling operation in GraphSAGE (Hamilton et al., 2017) implicitly selects the important nodes.",2. Background and Neighborhood aggregation schemes,[0],[0]
"This line of work is orthogonal to ours, because it modifies the direction of expansion whereas our model operates on the locality of expansion.",2. Background and Neighborhood aggregation schemes,[0],[0]
Our model can be combined with these models to add representational power.,2. Background and Neighborhood aggregation schemes,[0],[0]
"In Section 6, we demonstrate that our framework works with not only simple neighborhood-aggregation models (GCN), but also with skip connections (GraphSAGE) and directional biases (GAT).",2. Background and Neighborhood aggregation schemes,[0],[0]
"Next, we explore some important properties of the above aggregation schemes.",3. Influence Distribution and Random Walks,[0],[0]
"Related to ideas of sensitivity analysis and influence functions in statistics (Koh & Liang, 2017) that measure the influence of a training point on parameters, we study the range of nodes whose features affect a given node’s representation.",3. Influence Distribution and Random Walks,[0],[0]
"This range gives insight into how large a neighborhood a node is drawing information from.
",3. Influence Distribution and Random Walks,[0],[0]
"We measure the sensitivity of node x to node y, or the influence of y on x, by measuring how much a change in the input feature of y affects the representation of x in the last layer.",3. Influence Distribution and Random Walks,[0],[0]
"For any node x, the influence distribution captures the relative influences of all other nodes.
",3. Influence Distribution and Random Walks,[0],[0]
Definition 3.1 (Influence score and distribution).,3. Influence Distribution and Random Walks,[0],[0]
"For a simple graph G = (V,E), let h(0)x be the input feature and h
(k) x be the learned hidden feature of node x ∈ V at the k-th (last) layer of the model.",3. Influence Distribution and Random Walks,[0],[0]
"The influence score I(x, y) of node x by any node y ∈ V is the sum of the absolute values
of the entries of the Jacobian matrix [ ∂h(k)x ∂h (0) y ] .",3. Influence Distribution and Random Walks,[0],[0]
"We define the influence distribution Ix of x ∈ V by normalizing the influence scores: Ix(y) = I(x, y)/ ∑ z I(x, z), or
Ix(y) = e T
[ ∂h (k) x
∂h (0) y
] e /(∑
z∈V eT
[ ∂h (k) x
∂h (0) z
] e )
where e is the all-ones vector.
",3. Influence Distribution and Random Walks,[0],[0]
"Later, we will see connections of influence distributions with random walks.",3. Influence Distribution and Random Walks,[0],[0]
"For completeness, we also define random walk distributions.
",3. Influence Distribution and Random Walks,[0],[0]
Definition 3.2.,3. Influence Distribution and Random Walks,[0],[0]
"Consider a random walk on G̃ starting at a node v0; if at the t-th step we are at a node vt, we move to any neighbor of vt (including vt) with equal probability.
",3. Influence Distribution and Random Walks,[0],[0]
"The t-step random walk distribution Pt of v0 is
Pt (i) =",3. Influence Distribution and Random Walks,[0],[0]
Prob (vt = i) .,3. Influence Distribution and Random Walks,[0],[0]
"(4)
Analogous definitions apply for random walks with nonuniform transition probabilities.
",3. Influence Distribution and Random Walks,[0],[0]
An important property of the random walk distribution is that it becomes more spread out as t increases and converges to the limit distribution if the graph is non-bipartite.,3. Influence Distribution and Random Walks,[0],[0]
"The rate of convergence depends on the structure of the subgraph and can be bounded by the spectral gap (or the conductance) of the random walk’s transition matrix (Lovász, 1993).",3. Influence Distribution and Random Walks,[0],[0]
The influence distribution for different aggregation models and nodes can give insights into the information captured by the respective representations.,3.1. Model Analysis,[0],[0]
The following results show that the influence distributions of common aggregation schemes are closely connected to random walk distributions.,3.1. Model Analysis,[0],[0]
"This observation hints at specific implications – strengths and weaknesses – that we will discuss.
",3.1. Model Analysis,[0],[0]
"With a randomization assumption of the ReLU activations similar to that in (Kawaguchi, 2016; Choromanska et al., 2015), we can draw connections between GCNs and random walks:
Theorem 1.",3.1. Model Analysis,[0],[0]
"Given a k-layer GCN with averaging as in Equation (3), assume that all paths in the computation graph of the model are activated with the same probability of success ρ.",3.1. Model Analysis,[0],[0]
"Then the influence distribution Ix for any node
x ∈ V is equivalent, in expectation, to the k-step random walk distribution on G̃ starting at node x.
We prove Theorem 1 in the appendix.
",3.1. Model Analysis,[0],[0]
It is straightforward to modify the proof of Theorem 1 to show a nearly equivalent result for the version of GCN in Equation (2).,3.1. Model Analysis,[0],[0]
"The only difference is that each random walk path v0p, v 1 p, ..., v k p from node x (v 0 p) to y (v k p), in-
stead of probability ρ ∏k l=1 1
d̃eg(vlp) , now has probability
ρ Q ∏k−1 l=1 1
d̃eg(vlp) · (d̃eg(x)d̃eg(y))−1/2, where Q is a nor-
malizing factor.",3.1. Model Analysis,[0],[0]
"Thus, the difference in probability is small, especially when the degree of x and y are close.
",3.1. Model Analysis,[0],[0]
"Similarly, we can show that neighborhood aggregation schemes with directional biases resemble biased random walk distributions.",3.1. Model Analysis,[0],[0]
"This follows by substituting the corresponding probabilities into the proof of Theorem 1.
",3.1. Model Analysis,[0],[0]
"Empirically, we observe that, despite somewhat simplifying assumptions, our theory is close to what happens in practice.",3.1. Model Analysis,[0],[0]
"We visualize the heat maps of the influence distributions for a node (labeled square) for trained GCNs, and compare with the random walk distributions starting at the same node.",3.1. Model Analysis,[0],[0]
Figure 2 shows example results.,3.1. Model Analysis,[0],[0]
Darker colors correspond to higher influence probabilities.,3.1. Model Analysis,[0],[0]
"To show the effect of skip connections, Figure 3 visualizes the analogous heat maps for one example—GCN with residual connections.",3.1. Model Analysis,[0],[0]
"Indeed, we observe that the influence distributions of networks with residual connections approximately correspond to lazy random walks: each step has a higher probability of staying at
the current node.",3.1. Model Analysis,[0],[0]
Local information is retained with similar probabilities for all nodes in each iteration; this cannot adapt to diverse needs of specific upper-layer nodes.,3.1. Model Analysis,[0],[0]
"Further visualizations may be found in the appendix.
",3.1. Model Analysis,[0],[0]
Fast Collapse on Expanders.,3.1. Model Analysis,[0],[0]
"To better understand the implication of Theorem 1 and the limitations of the corresponding neighborhood aggregation algorithms, we revisit the scenario of learning on a social network shown in Figure 1.",3.1. Model Analysis,[0],[0]
"Random walks starting inside an expander converge rapidly in O(log |V |) steps to an almost-uniform distribution (Hoory et al., 2006).",3.1. Model Analysis,[0],[0]
"After O(log |V |) iterations of neighborhood aggregation, by Theorem 1 the representation of every node is influenced almost equally by any other node in the expander.",3.1. Model Analysis,[0],[0]
"Thus, the node representations will be representative of the global graph and carry limited information about individual nodes.",3.1. Model Analysis,[0],[0]
"In contrast, random walks starting at the bounded tree-width (almost-tree) part converge slowly, i.e., the features retain more local information.",3.1. Model Analysis,[0],[0]
"Models that impose a fixed random walk distribution inherit these discrepancies in the speed of expansion and influence neighborhoods, which may not lead to the best representations for all nodes.",3.1. Model Analysis,[0],[0]
"The above observations raise the question whether the fixed but structure-dependent influence radius size induced by
common aggregation schemes really achieves the best representations for all nodes and tasks.",4. Jumping Knowledge Networks,[0],[0]
"Large radii may lead to too much averaging, while small radii may lead to instabilities or insufficient information aggregation.",4. Jumping Knowledge Networks,[0],[0]
"Hence, we propose two simple yet powerful architectural changes – jump connections and a subsequent selective but adaptive aggregation mechanism.
",4. Jumping Knowledge Networks,[0],[0]
"Figure 4 illustrates the main idea: as in common neighborhood aggregation networks, each layer increases the size of the influence distribution by aggregating neighborhoods from the previous layer.",4. Jumping Knowledge Networks,[0],[0]
"At the last layer, for each node, we carefully select from all of those itermediate representations (which “jump” to the last layer), potentially combining a few.",4. Jumping Knowledge Networks,[0],[0]
"If this is done independently for each node, then the model can adapt the effective neighborhood size for each node as needed, resulting in exactly the desired adaptivity.
",4. Jumping Knowledge Networks,[0],[0]
Our model permits general layer-aggregation mechanisms.,4. Jumping Knowledge Networks,[0],[0]
We explore three approaches; others are possible too.,4. Jumping Knowledge Networks,[0],[0]
"Let h (1) v , ..., h (k) v be the jumping representations of node v (from k layers) that are to be aggregated.
",4. Jumping Knowledge Networks,[0],[0]
Concatenation.,4. Jumping Knowledge Networks,[0],[0]
"A concatenation [ h (1) v , ..., h (k) v ] is the
most straightforward way to combine the layers, after which we may perform a linear transformation.",4. Jumping Knowledge Networks,[0],[0]
"If the transformation weights are shared across graph nodes, this approach is not node-adaptive.",4. Jumping Knowledge Networks,[0],[0]
"Instead, it optimizes the weights to combine the subgraph features in a way that works best for the dataset overall.",4. Jumping Knowledge Networks,[0],[0]
"One may expect concatenation to be suitable for small graphs and graphs with regular structure that require less adaptivity; also because weight-sharing helps reduce overfitting.
",4. Jumping Knowledge Networks,[0],[0]
Max-pooling.,4. Jumping Knowledge Networks,[0],[0]
"An element-wise max ( h (1) v , ..., h (k) v ) selects the most informative layer for each feature coordinate.",4. Jumping Knowledge Networks,[0],[0]
"For example, feature coordinates that represent more local properties can use the feature coordinates learned from the close neighbors and those representing global status would favor features from the higher-up layers.",4. Jumping Knowledge Networks,[0],[0]
"Max-pooling is adaptive and has the advantage that it does not introduce any additional parameters to learn.
",4. Jumping Knowledge Networks,[0],[0]
LSTM-attention.,4. Jumping Knowledge Networks,[0],[0]
"An attention mechanism identifies the most useful neighborhood ranges for each node v by computing an attention score s(l)v for each layer l (∑ l s (l) v = 1 ) , which represents the importance of the feature learned on the l-th layer for node v. The aggregated representation for node v is a weighted average of the layer features∑ l s (l) v · h(l)v .",4. Jumping Knowledge Networks,[0],[0]
"For LSTM attention, we input h(1)v , ..., h(k)v into a bi-directional LSTM (Hochreiter & Schmidhuber, 1997) and generate the forward-LSTM and backward-LSTM",4. Jumping Knowledge Networks,[0],[0]
hidden features f (l)v and b (l) v for each layer l.,4. Jumping Knowledge Networks,[0],[0]
A linear mapping of the concatenated features [f (l)v ||b(l)v ] yields the scalar importance score s(l)v .,4. Jumping Knowledge Networks,[0],[0]
"A Softmax layer applied to {s(l)v }kl=1
yields the attention of node v on its neighborhood in different ranges.",4. Jumping Knowledge Networks,[0],[0]
Finally we take the sum of [f (l)v ||b(l)v ] weighted by SoftMax({s(l)v }kl=1) to get the final layer representation.,4. Jumping Knowledge Networks,[0],[0]
Another possible implementation combines LSTM with max-pooling.,4. Jumping Knowledge Networks,[0],[0]
LSTM-attention is node adaptive because the attention scores are different for each node.,4. Jumping Knowledge Networks,[0],[0]
"We shall see that the this approach shines on large complex graphs, although it may overfit on small graphs (fewer training nodes) due to its relatively higher complexity.",4. Jumping Knowledge Networks,[0],[0]
"The key idea for the design of layer-aggregation functions is to determine the importance of a node’s subgraph features at different ranges after looking at the learned features on all layers, rather than to optimize and fix the same weights for all nodes.",4.1. JK-Net Learns to Adapt,[0],[0]
"Under the same assumption on the ReLU activation distribution as in Theorem 1, we show below that layer-wise max-pooling implicitly learns the influence locality adaptively for different nodes.",4.1. JK-Net Learns to Adapt,[0],[0]
"The proof for layerwise attention follows similarly.
",4.1. JK-Net Learns to Adapt,[0],[0]
Proposition 1.,4.1. JK-Net Learns to Adapt,[0],[0]
Assume that paths of the same length in the computation graph are activated with the same probability.,4.1. JK-Net Learns to Adapt,[0],[0]
"The influence score I(x, y) for any x, y ∈ V under a k-layer JK-Net with layer-wise max-pooling is equivalent in expectation to a mixture of 0, .., k-step random walk distributions on G̃ at y starting at x, the coefficients of which depend on the values of the layer features h(l)x .
",4.1. JK-Net Learns to Adapt,[0],[0]
We prove Proposition 1 in the appendix.,4.1. JK-Net Learns to Adapt,[0],[0]
"Contrasting this result with the influence distributions of other aggregation mechanisms, we see that JK-networks indeed differ in their node-wise adaptivity of neighborhood ranges.
",4.1. JK-Net Learns to Adapt,[0],[0]
Figure 5 illustrates how a 6-layer JK-Net with max-pooling aggregation learns to adapt to different subgraph structures on a citation network.,4.1. JK-Net Learns to Adapt,[0],[0]
"Within a tree-like structure, the influence stays in the “small community” the node belongs to.",4.1. JK-Net Learns to Adapt,[0],[0]
"In contrast, 6-layer models whose influence distributions follow random walks, e.g. GCNs, would reach out too far into irrelevant parts of the graph, and models with few layers may not be able to cover the entire “community”, as illustrated in Figure 1, and Figures 7, 8 in the appendix.",4.1. JK-Net Learns to Adapt,[0],[0]
"For
a node affiliated to a “hub”, which presumably plays the role of connecting different types of nodes, JK-Net learns to put most influence on the node itself and otherwise spreads out the influence.",4.1. JK-Net Learns to Adapt,[0],[0]
"GCNs, however, would not capture the importance of the node’s own features in such a structure because the probability at an affiliate node is small after a few random walk steps.",4.1. JK-Net Learns to Adapt,[0],[0]
"For hubs, JK-Net spreads out the influence across the neighboring nodes in a reasonable range, which makes sense because the nodes connected to the hubs are presumably as informative as the hubs’ own features.",4.1. JK-Net Learns to Adapt,[0],[0]
"For comparison, Table 6 in the appendix includes more visualizations of how models with random walk priors behave.",4.1. JK-Net Learns to Adapt,[0],[0]
"Looking at Figure 4, one may wonder whether the same inter-layer connections could be drawn between all layers.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"The resulting architecture is approximately a graph correspondent of DenseNets, which were introduced for computer vision problems (Huang et al., 2017), if the layer-wise concatenation aggregation is applied.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"This version, however, would require many more features to learn.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"Viewing the DenseNet setting (images) from a graph-theoretic perspective, images correspond to regular, in fact, near-planar graphs.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"Such graphs are far from being expanders, and do not pose the challenges of graphs with varying subgraph structures.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"Indeed, as we shall see, models with concatenation aggregation perform well on graphs with more regular structures such as images and well-structured communities.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"As a more general framework, JK-Net admits general layerwise aggregation models and enables better structure-aware representations on graphs with complex structures.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"Spectral graph convolutional neural networks apply convolution on graphs by using the graph Laplacian eigenvectors as the Fourier atoms (Bruna et al., 2014; Shuman et al., 2013; Defferrard et al., 2016).",5. Other Related Work,[0],[0]
"A major drawback of the spectral methods, compared to spatial approaches like neighborhoodaggregation, is that the graph Laplacian needs to be known in advance.",5. Other Related Work,[0],[0]
"Hence, they cannot generalize to unseen graphs.",5. Other Related Work,[0],[0]
We evaluate JK-Nets on four benchmark datasets.,6. Experiments,[0],[0]
(I),6. Experiments,[0],[0]
"The task on citation networks (Citeseer, Cora) (Sen et al., 2008) is to classify academic papers into different subjects.",6. Experiments,[0],[0]
The dataset contains bag-of-words features for each document (node) and citation links (edges) between documents.,6. Experiments,[0],[0]
"(II) On Reddit (Hamilton et al., 2017), the task is to predict the community to which different Reddit posts belong.",6. Experiments,[0],[0]
Reddit is an online discussion forum where users comment in different topical communities.,6. Experiments,[0],[0]
Two posts (nodes) are connected if some user commented on both posts.,6. Experiments,[0],[0]
The dataset contains word vectors as node features.,6. Experiments,[0],[0]
"(III) For protein-protein interaction networks (PPI) (Hamilton et al., 2017), the task is to classify protein functions.",6. Experiments,[0],[0]
"PPI consists of 24 graphs, each corresponds to a human tissue.",6. Experiments,[0],[0]
"Each node has positional gene sets, motif gene sets and immunological signatures as features and gene ontology sets as labels.",6. Experiments,[0],[0]
"20 graphs are used for training, 2 graphs are used for validation and the rest for testing.",6. Experiments,[0],[0]
"Statistics of the datasets are summarized in Table 1.
",6. Experiments,[0],[0]
Settings.,6. Experiments,[0],[0]
"In the transductive setting, we are only allowed to access a subset of nodes in one graph as training data, and validate/test on others.",6. Experiments,[0],[0]
"Our experiments on Citeseer, Cora and Reddit are transductive.",6. Experiments,[0],[0]
"In the inductive setting, we use a number of full graphs as training data and use other completely unseen graphs as validation/testing data.",6. Experiments,[0],[0]
"Our experiments on PPI are inductive.
",6. Experiments,[0],[0]
"We compare against three baselines: Graph Convolutional Networks (GCN) (Kipf & Welling, 2017), GraphSAGE (Hamilton et al., 2017) and Graph Attention Networks (GAT) (Veličković et al., 2018).",6. Experiments,[0],[0]
"For experiments on Citeseer and Cora, we choose GCN as the base model since on our data split, it is outperforming GAT.",6.1. Citeseer & Cora,[0],[0]
"We construct JK-Nets by choosing MaxPooling (JKMaxPool), Concatenation (JK-Concat), or LSTM-attention (JK-LSTM) as final aggregation layer.",6.1. Citeseer & Cora,[0],[0]
"When taking the final aggregation, besides normal graph convolutional layers, we also take the first linear-transformed representation into account.",6.1. Citeseer & Cora,[0],[0]
The final prediction is done via a fully connected layer on top of the final aggregated representation.,6.1. Citeseer & Cora,[0],[0]
"We split nodes in each graph into 60%, 20% and 20% for training, validation and testing.",6.1. Citeseer & Cora,[0],[0]
"We vary the number of layers from 1
to 6 for each model and choose the best performing model with respect to the validation set.",6.1. Citeseer & Cora,[0],[0]
"Throughout the experiments, we use the Adam optimizer (Kingma & Ba, 2014) with learning rate 0.005.",6.1. Citeseer & Cora,[0],[0]
"We fix the dropout rate to be 0.5, the dimension of hidden features to be within {16, 32}, and add an L2 regularization of 0.0005 on model parameters.",6.1. Citeseer & Cora,[0],[0]
"The results are shown in Table 2.
Results.",6.1. Citeseer & Cora,[0],[0]
We observe in Table 2 that JK-Nets outperform both GCN and GAT baselines in terms of prediction accuracy.,6.1. Citeseer & Cora,[0],[0]
"Though JK-Nets perform well in general, there is no consistent winner and performance varies slightly across datasets.
",6.1. Citeseer & Cora,[0],[0]
"Taking a closer look at results on Cora, both GCN and GAT achieve their best accuracies with only 2 or 3 layers, suggesting that local information is a stronger signal for classification than global ones.",6.1. Citeseer & Cora,[0],[0]
"However, the fact that JKNets achieve the best performance with 6 layers indicates that global together with local information will help boost performance.",6.1. Citeseer & Cora,[0],[0]
This is where models like JK-Nets can be particularly beneficial.,6.1. Citeseer & Cora,[0],[0]
LSTM-attention may not be suitable for such small graphs because of its relatively high complexity.,6.1. Citeseer & Cora,[0],[0]
The Reddit data is too large to be handled well by current implementations of GCN or GAT.,6.2. Reddit,[0],[0]
"Hence, we use the more scalable GraphSAGE as the base model for JK-Net.",6.2. Reddit,[0],[0]
It has skip connections and different modes of node aggregation.,6.2. Reddit,[0],[0]
"We experiment with Mean and MaxPool node aggregators, which take mean and max-pooling of a linear transformation of representations of the sampled neighbors.",6.2. Reddit,[0],[0]
"Combining each of GraphSAGE modes with MaxPooling, Concatenation or LSTM-attention as the last aggregation layer gives 6 JK-Net variants.",6.2. Reddit,[0],[0]
"We follow exactly the same setting of GraphSAGE as in the original paper (Hamilton et al., 2017), where the model consists of 2 hidden layers, each with 128 hidden units and is trained with Adam with learning rate of 0.01 and no weight decay.",6.2. Reddit,[0],[0]
"Results are shown in Table 3.
Results.",6.2. Reddit,[0],[0]
"With MaxPool as node aggregator and Concat as layer aggregator, JK-Net achieves the best Micro-F1 score
among GarphSAGE and JK-Net variants.",6.2. Reddit,[0],[0]
Note that the original GraphSAGE already performs fairly well with a Micro-F1 of 0.95.,6.2. Reddit,[0],[0]
JK-Net reduces the error by 30%.,6.2. Reddit,[0],[0]
"The communities in the Reddit dataset were explicitly chosen from the well-behaved middle-sized communities to avoid the noisy cores and tree-like small communities (Hamilton et al., 2017).",6.2. Reddit,[0],[0]
"As a result, this graph is more regular than the original Reddit data, and hence not exhibit the problems of varying subgraph structures.",6.2. Reddit,[0],[0]
"In such a case, the added flexibility of the node-specific neighborhood choices may not be as relevant, and the stabilizing properties of concatenation instead come into play.",6.2. Reddit,[0],[0]
"We demonstrate the power of adaptive JK-Nets, e.g., JKLSTM, with experiments on the PPI data, where the subgraphs have more diverse and complex structures than those in the Reddit community detection dataset.",6.3. PPI,[0],[0]
We use both GraphSAGE and GAT as base models for JK-Net.,6.3. PPI,[0],[0]
"The implementation of GraphSAGE and GAT are quite different: GraphSAGE is sample-based, where neighbors of a node are sampled to be a fixed number, while GAT considers all neighbors.",6.3. PPI,[0],[0]
Such differences cause large gaps in terms of both scalability and performances.,6.3. PPI,[0],[0]
"Given that GraphSAGE scales to much larger graphs, it appears particularly valuable to evaluate how much JK-Net can improve upon GraphSAGE.
",6.3. PPI,[0],[0]
"For GraphSAGE we follow the setup as in the Reddit experiments, except that we use 3 layers when possible, and compare the performance after 10 and 30 epochs of training.",6.3. PPI,[0],[0]
The results are shown in Table 4.,6.3. PPI,[0],[0]
"For GAT and its JK-Net variants we stack two hidden layers with 4 attention heads computing 256 features (for a total of 1024 features), and a final prediction layer with 6 attention heads computing 121 features each.",6.3. PPI,[0],[0]
They are further averaged and input into sigmoid activations.,6.3. PPI,[0],[0]
We employ skip connections across intermediate attentional layers.,6.3. PPI,[0],[0]
These models are trained with Batch-size 2 and Adam optimizer with learning rate of 0.005.,6.3. PPI,[0],[0]
"The results are shown in Table 5.
Results.",6.3. PPI,[0],[0]
"JK-Nets with the LSTM-attention aggregators outperform the non-adaptive models GraphSAGE, GAT and JK-Nets with concatenation aggregators.",6.3. PPI,[0],[0]
"In particular, JKLSTM outperforms GraphSAGE by 0.128 in terms of micro-
F1 score after 30 epochs of training.",6.3. PPI,[0],[0]
Structure-aware node adaptive models are especially beneficial on such complex graphs with diverse structures.,6.3. PPI,[0],[0]
"Motivated by observations that reveal great differences in neighborhood information ranges for graph node embeddings, we propose a new aggregation scheme for node representation learning that can adapt neigborhood ranges to nodes individually.",7. Conclusion,[0],[0]
"This JK-network can improve representations in particular for graphs that have subgraphs of diverse local structure, and may hence not be well captured by fixed numbers of neighborhood aggregations.",7. Conclusion,[0],[0]
Interesting directions for future work include exploring other layer aggregators and studying the effect of the combination of various layer-wise and node-wise aggregators on different types of graph structures.,7. Conclusion,[0],[0]
"This research was supported by NSF CAREER award 1553284, and JST ERATO Kawarabayashi Large Graph Project, Grant Number JPMJER1201, Japan.",Acknowledgements,[0],[0]
Recent deep learning approaches for representation learning on graphs follow a neighborhood aggregation procedure.,abstractText,[0],[0]
"We analyze some important properties of these models, and propose a strategy to overcome those.",abstractText,[0],[0]
"In particular, the range of “neighboring” nodes that a node’s representation draws from strongly depends on the graph structure, analogous to the spread of a random walk.",abstractText,[0],[0]
"To adapt to local neighborhood properties and tasks, we explore an architecture – jumping knowledge (JK) networks – that flexibly leverages, for each node, different neighborhood ranges to enable better structure-aware representation.",abstractText,[0],[0]
"In a number of experiments on social, bioinformatics and citation networks, we demonstrate that our model achieves state-of-the-art performance.",abstractText,[0],[0]
"Furthermore, combining the JK framework with models like Graph Convolutional Networks, GraphSAGE and Graph Attention Networks consistently improves those models’ performance.",abstractText,[0],[0]
Representation Learning on Graphs with Jumping Knowledge Networks ,title,[0],[0]
"Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 912–921, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics
Methods of deep neural networks (DNNs) have recently demonstrated superior performance on a number of natural language processing tasks. However, in most previous work, the models are learned based on either unsupervised objectives, which does not directly optimize the desired task, or singletask supervised objectives, which often suffer from insufficient training data. We develop a multi-task DNN for learning representations across multiple tasks, not only leveraging large amounts of cross-task data, but also benefiting from a regularization effect that leads to more general representations to help tasks in new domains. Our multi-task DNN approach combines tasks of multiple-domain classification (for query classification) and information retrieval (ranking for web search), and demonstrates significant gains over strong baselines in a comprehensive set of domain adaptation.",text,[0],[0]
"Recent advances in deep neural networks (DNNs) have demonstrated the importance of learning vector-space representations of text, e.g., words and sentences, for a number of natural language processing tasks.",1 Introduction,[0],[0]
"For example, the study reported in (Collobert et al., 2011) demonstrated significant accuracy gains in tagging, named entity recognition, and semantic role labeling when using vector space word
∗This research was conducted during the author’s internship at Microsoft Research.
representations learned from large corpora.",1 Introduction,[0],[0]
"Further, since these representations are usually in a lowdimensional vector space, they result in more compact models than those built from surface-form features.",1 Introduction,[0],[0]
"A recent successful example is the parser by (Chen and Manning, 2014), which is not only accurate but also fast.
",1 Introduction,[0],[0]
"However, existing vector-space representation learning methods are far from optimal.",1 Introduction,[0],[0]
"Most previous methods are based on unsupervised objectives such as word prediction for training (Mikolov et al., 2013c; Pennington et al., 2014).",1 Introduction,[0],[0]
"Other methods use supervised training objectives on a single task, e.g. (Socher et al., 2013), and thus are often constrained by limited amounts of training data.",1 Introduction,[0],[0]
"Motivated by the success of multi-task learning (Caruana, 1997), we propose in this paper a multi-task DNN approach for representation learning that leverages supervised data from many tasks.",1 Introduction,[0],[0]
"In addition to the benefit of having more data for training, the use of multi-task also profits from a regularization effect, i.e., reducing overfitting to a specific task, thus making the learned representations universal across tasks.
",1 Introduction,[0],[0]
"Our contributions are of two-folds: First, we propose a multi-task deep neural network for representation learning, in particular focusing on semantic classification (query classification) and semantic information retrieval (ranking for web search) tasks.",1 Introduction,[0],[0]
Our model learns to map arbitrary text queries and documents into semantic vector representations in a low dimensional latent space.,1 Introduction,[0],[0]
"While the general concept of multi-task neural nets is not new, our model is novel in that it successfully combines tasks as disparate as operations necessary for classifica-
912
tion or ranking.",1 Introduction,[0],[0]
"Second, we demonstrate strong results on query classification and web search.",1 Introduction,[0],[0]
Our multi-task representation learning consistently outperforms stateof-the-art baselines.,1 Introduction,[0],[0]
"Meanwhile, we show that our model is not only compact but it also enables agile deployment into new domains.",1 Introduction,[0],[0]
This is because the learned representations allow domain adaptation with substantially fewer in-domain labels.,1 Introduction,[0],[0]
Our multi-task model combines classification and ranking tasks.,2.1 Preliminaries,[0],[0]
"For concreteness, throughout this paper we will use query classification as the classification task and web search as the ranking task.",2.1 Preliminaries,[0],[0]
"These are important tasks in commercial search engines:
Query Classification:",2.1 Preliminaries,[0],[0]
"Given a search query Q, the model classifies in the binary fashion as to whether it belongs to one of the domains of interest.",2.1 Preliminaries,[0],[0]
"For example, if the query Q is “Denver sushi”, the classifier should decide that it belongs to the “Restaurant” domain.",2.1 Preliminaries,[0],[0]
"Accurate query classification enables a richer personalized user experience, since the search engine can tailor the interface and results.",2.1 Preliminaries,[0],[0]
"It is however challenging because queries tend to be short (Shen et al., 2006).",2.1 Preliminaries,[0],[0]
"Surface-form word features that are common in traditional document classification problems tend to be too sparse for query classification, so representation learning is a promising solution.",2.1 Preliminaries,[0],[0]
"In this study, we classify queries into four domains of interest: (“Restaurant”, “Hotel”, “Flight”, “Nightlife”).",2.1 Preliminaries,[0],[0]
Note that one query can belong to multiple domains.,2.1 Preliminaries,[0],[0]
"Therefore, a set of binary classifiers are built, one for each domain, to perform the classification.",2.1 Preliminaries,[0],[0]
We frame the problem as four binary classification tasks.,2.1 Preliminaries,[0],[0]
"Thus, for domain Ct, our goal is binary classification based on P (Ct| Q) (Ct = {0, 1} ).",2.1 Preliminaries,[0],[0]
"For each domain t, we assume supervised data (Q, yt = {0, 1} with yt as binary labels.1
Web Search:",2.1 Preliminaries,[0],[0]
"Given a search queryQ and a document list L, the model ranks documents in the order
1One could frame the problem as a a single multi-class classification task, but our formulation is more practical as it allows adding new domains without retraining existing classifiers.",2.1 Preliminaries,[0],[0]
"This will be relevant in domain adaptation (§3.3).
of relevance.",2.1 Preliminaries,[0],[0]
"For example, if the queryQ is ”Denver sushi”, model returns a list of documents that satisfies such information need.",2.1 Preliminaries,[0],[0]
"Formally, we estimate P (D1|Q), P (D2|Q), . . .",2.1 Preliminaries,[0],[0]
for each document Dn and rank according to these probabilities.,2.1 Preliminaries,[0],[0]
"We assume that supervised data exist; I.e., there is at least one relevant document Dn for each query Q.",2.1 Preliminaries,[0],[0]
"Briefly, our proposed model maps any arbitrary queries Q or documents D into fixed lowdimensional vector representations using DNNs.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
These vectors can then be used to perform query classification or web search.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"In contrast to existing representation learning methods which employ either unsupervised or single-task supervised objectives, our model learns these representations using multi-task objectives.
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
The architecture of our multi-task DNN model is shown in Figure 1.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"The lower layers are shared across different tasks, whereas the top layers represent task-specific outputs.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Importantly, the input X (either a query or document), initially represented as a bag of words, is mapped to a vector (l2) of dimension 300.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
This is the shared semantic representation that is trained by our multi-task objectives.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"In the following, we elaborate the model in detail:
Word Hash Layer (l1): Traditionally, each word is represented by a one-hot word vector, where the dimensionality of the vector is the vocabulary size.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"However, due to the large size of vocabulary in realworld tasks, it is very expensive to learn such kind of models.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"To alleviate this problem, we adopt the word hashing method (Huang et al., 2013).",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"We map a one-hot word vector, with an extremely high dimensionality, into a limited letter-trigram space (e.g., with the dimensionality as low as 50k).",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"For example, word cat is hashed as the bag of letter trigram {#-c-a, c-a-t, a-t-#}, where # is a boundary symbol.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Word hashing complements the one-hot vector representation in two aspects: 1) out of vocabulary words can be represented by letter-trigram vectors; 2) spelling variations of the same word can be mapped to the points that are close to each other in the letter-trigram space.
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
Semantic-Representation Layer (l2):,2.2 The Proposed Multi-Task DNN Model,[0],[0]
This is a shared representation learned across different tasks.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"this layer maps the letter-trigram inputs into a 300-
1
dimensional vector by
l2 = f(W1 · l1) (1)
where f(·) is the tanh nonlinear activation f(z) = 1−e−2z 1+e−2z .",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"This 50k-by-300 matrix W1 is responsible for generating the cross-task semantic representation for arbitrary text inputs (e.g., Q or D).
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Task-Specific Representation (l3): For each task, a nonlinear transformation maps the 300- dimension semantic representation l2 into the 128- dimension task-specific representation by
l3 = f(Wt2 · l2) (2)
where, t denotes different tasks (query classification or web search).
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
Query Classification Output: Suppose QC1 ≡ l3 = f(Wt=C12 · l2) is the 128-dimension taskspecific representation for a query Q.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"The probability that Q belongs to class C1 is predicted by a logistic regression, with sigmoid g(z)",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"= 1
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"1+e−z :
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"P (C1|Q) = g(Wt=C13 ·QC1) (3)
Web Search Output: For the web search task, both the query Q and the document D are mapped into 128-dimension task-specific representations QSq and DSd .",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Then, the relevance score is
Algorithm 1: Training a Multi-task DNN Initialize model Θ : {W1,Wt2,Wt3} randomly for iteration in 0...∞ do
1.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
Pick a task t randomly 2.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Pick sample(s) from task t
(Q, yt = {0, 1}) for query classification (Q,L) for web search
3.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
Compute loss: L(Θ) L(Θ)=Eq.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
5 for query classification L(Θ)=Eq.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
6 for web search 4.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
Compute gradient: ∇(Θ) 5.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Update model: Θ = Θ− ∇(Θ)
end The task t is one of the query classification tasks or web search task, as shown in Figure 1.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"For query classification, each training sample includes one query and its category label.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"For web search, each training sample includes query and document list.
computed by cosine similarity as:
R(Q,D) = cos(QSq , DSd)",2.2 The Proposed Multi-Task DNN Model,[0],[0]
= QSq ·DSd ||QSq,2.2 The Proposed Multi-Task DNN Model,[0],[0]
||||DSd || (4),2.2 The Proposed Multi-Task DNN Model,[0],[0]
"In order to learn the parameters of our model, we use mini-batch-based stochastic gradient descent (SGD) as shown in Algorithm 1.",2.3 The Training Procedure,[0],[0]
"In each iteration, a task t is selected randomly, and the model is updated ac-
cording to the task-specific objective.",2.3 The Training Procedure,[0],[0]
This approximately optimizes the sum of all multi-task objectives.,2.3 The Training Procedure,[0],[0]
"For query classification of class Ct, we use the cross-entropy loss as the objective: −{yt lnP (Ct|Q)+(1−yt) ln(1−P (Ct|Q))}",2.3 The Training Procedure,[0],[0]
"(5)
where yt = {0, 1} is the label and the loss is summed over all samples in the mini-batch (1024 samples in experiments).
",2.3 The Training Procedure,[0],[0]
"The objective for web search used in this paper follows the pair-wise learning-to-rank paradigm outlined in (Burges et al., 2005).",2.3 The Training Procedure,[0],[0]
"Given a query Q, we obtain a list of documents L that includes a clicked document D+ (positive sample), and J randomlysampled non-clicked documents {D−j }j=1,.,J .",2.3 The Training Procedure,[0],[0]
"We then minimize the negative log likelihood of the clicked document (defined in Eq. 7) given queries across the training data
− log ∏
(Q,D+)
P (D+|Q) (6)
where the probability of a given document D+ is computed
P (D+|Q) =",2.3 The Training Procedure,[0],[0]
"exp(γR(Q,D +))",2.3 The Training Procedure,[0],[0]
"∑
D′∈L exp(γR(Q,D′)) (7)
",2.3 The Training Procedure,[0],[0]
"here, γ is a tuning factor determined on held-out data.",2.3 The Training Procedure,[0],[0]
"Additional training details: (1) Model parameters are initialized with uniform distribution in the range (−√6/(fanin + fanout),√6/(fanin + fanout))",2.3 The Training Procedure,[0],[0]
"(Montavon et al., 2012).",2.3 The Training Procedure,[0],[0]
"Empirically, we have not observed better performance by initialization with layer-wise pre-training.",2.3 The Training Procedure,[0],[0]
"(2) Moment methods and AdaGrad training (Duchi et al., 2011) speed up the convergence speed but gave similar results as plain SGD.",2.3 The Training Procedure,[0],[0]
The SGD learning rate is fixed at = 0.1/1024.,2.3 The Training Procedure,[0],[0]
"(3) We run Algorithm 1 for 800K iterations, taking 13 hours on an NVidia K20 GPU.",2.3 The Training Procedure,[0],[0]
"Our proposed multi-task DNN (Figure 1) can be viewed as a combination of a standard DNN for classification and a Deep Structured Semantic Model (DSSM) for ranking, shown in Figure 2.",2.4 An Alternative View of the Multi-Task Model,[0],[0]
Other ways to merge the models are possible.,2.4 An Alternative View of the Multi-Task Model,[0],[0]
"Figure 3 shows an alternative multi-task architecture, where only the query part is shared among all tasks and the DSSM
retains independent parameters for computing the document representations.",2.4 An Alternative View of the Multi-Task Model,[0],[0]
This is more similar to the original DSSM.,2.4 An Alternative View of the Multi-Task Model,[0],[0]
"We have attempted training this model using Algorithm 1, but it achieves good results on query classification at the expense of web search.",2.4 An Alternative View of the Multi-Task Model,[0],[0]
"This is likely due to unbalanced updates (i.e. parameters for queries are updated more often than that of documents), and implying that the amount of sharing is an important design choice in multi-task models.
",2.4 An Alternative View of the Multi-Task Model,[0],[0]
3,2.4 An Alternative View of the Multi-Task Model,[0],[0]
"We employ large-scale, real data sets in our evaluation.",3.1 Data Sets and Evaluation Metrics,[0],[0]
See Table 1 for statistics.,3.1 Data Sets and Evaluation Metrics,[0],[0]
The test data for query classification were sampled from one-year log files of a commercial search engine with labels (yes or no) judged by humans.,3.1 Data Sets and Evaluation Metrics,[0],[0]
"The test data for web search contains 12,071 English queries, where each query-document pair has a relevance label manually annotated on a 5-level relevance scale: bad, fair,
good, excellent and perfect.",3.1 Data Sets and Evaluation Metrics,[0],[0]
"The evaluation metric for query classification is the Area under of Receiver Operating Characteristic (ROC) curve (AUC) score (Bradley, 1997).",3.1 Data Sets and Evaluation Metrics,[0],[0]
"For web search, we employ the Normalized Discounted Cumulative Gain (NDCG) (Järvelin and Kekäläinen, 2000).",3.1 Data Sets and Evaluation Metrics,[0],[0]
"First, we evaluate whether our model can robustly improve performance, measured as accuracy across multiple tasks.
",3.2 Results on Accuracy,[0],[0]
"Table 2 summarizes the AUC scores for query classification, comparing the following classifiers: • SVM-Word: a SVM model2 with unigram, bi-
gram and trigram surface-form word features.
",3.2 Results on Accuracy,[0],[0]
• SVM-Letter: a SVM model with letter trigram features (i.e. l1 in Figure 1 as input to SVM).,3.2 Results on Accuracy,[0],[0]
• DNN:,3.2 Results on Accuracy,[0],[0]
single-task deep neural net (Figure 2).,3.2 Results on Accuracy,[0],[0]
• MT-DNN: our multi-task proposal (Figure 1).,3.2 Results on Accuracy,[0],[0]
The results show that the proposed MT-DNN performs best in all four domains.,3.2 Results on Accuracy,[0],[0]
"Further, we observe:
1.",3.2 Results on Accuracy,[0],[0]
"MT-DNN outperforms DNN, indicating the usefulness of the multi-task objective (that includes web search) over the single-task objective of query classification.
2.",3.2 Results on Accuracy,[0],[0]
"Both DNN and MT-DNN outperform SVMLetter, which initially uses the same input features (l1).",3.2 Results on Accuracy,[0],[0]
"This indicates the importance of learning a semantic representation l2 on top of these letter trigrams.
3.",3.2 Results on Accuracy,[0],[0]
"Both DNN and MT-DNN outperform a strong SVM-Word baseline, which has a large feature set that consists of 3 billion features.
",3.2 Results on Accuracy,[0],[0]
"Table 3 summarizes the NDCG results on web search, comparing the following models:",3.2 Results on Accuracy,[0],[0]
"2In this paper, we use the liblinear to build SVM classifiers and optimize the corresponding parameter C by using 5-fold cross-validation in training data.",3.2 Results on Accuracy,[0],[0]
"http://www.csie.ntu.edu.tw/ cjlin/liblinear/
• Popular baselines in the web search literature, e.g. BM25, Language Model, PLSA
• DSSM: single-task ranking model (Figure 2) • MT-DNN:",3.2 Results on Accuracy,[0],[0]
"our multi-task proposal (Figure 1)
",3.2 Results on Accuracy,[0],[0]
"Again, we observe that MT-DNN performs best.",3.2 Results on Accuracy,[0],[0]
"For example, MT-DNN achieves NDCG@1=0.334, outperforming the current state-of-the-art single-task DSSM (0.327) and the classic methods like PLSA (0.308) and BM25 (0.305).",3.2 Results on Accuracy,[0],[0]
"This is a statistically significant improvement (p < 0.05) over DSSM and other baselines.
",3.2 Results on Accuracy,[0],[0]
"To recap, our MT-DNN robustly outperforms strong baselines across all web search and query classification tasks.",3.2 Results on Accuracy,[0],[0]
"Further, due to the use of larger training data (from different domains) and the regularization effort as we discussed in Section 1, we confirm the advantage of multi-task models over than single-task ones.3",3.2 Results on Accuracy,[0],[0]
Important criteria for building practical systems are agility of deployment and small memory footprint and fast run-time.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Our model satisfies both with 3We have also trained SVM using Word2Vec (Mikolov et al., 2013b; Mikolov et al., 2013a) features.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Unfortunately, the results are poor at 60-70 AUC, indicating the sub-optimality of unsupervised representation learning objectives for actual prediction tasks.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"We optimized the Word2Vec features in the SVM baseline by scaling and normalizing as well, but did not observe much improvement.
high model compactness.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
The key to the compactness is the aggressive compression from the 500kdimensional bag-of-words input to 300-dimensional semantic representation l2.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
This significantly reduces the memory/run-time requirements compared to systems that rely on surface-form features.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"The most expensive portion of the model is storage of the 50k-by-300 W1 and its matrix multiplication with l1, which is sparse: this is trivial on modern hardware.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Our multi-task DNN takes < 150KB in memory whereas e.g. SVM-Word takes about 200MB.
",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Compactness is particularly important for query classification, since one may desire to add new domains after discovering new needs from the query logs of an operational system.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"On the other hand, it is prohibitively expensive to collect labeled training data for new domains.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Very often, we only have very small training data or even no training data.
",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"To evaluate the models using the above criteria, we perform domain adaptation experiments on query classification using the following procedure: (1) Select one query classification task t∗.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Train MTDNN on the remaining tasks (including Web Search
task) to obtain a semantic representation (l2); (2) Given a fixed l2, train an SVM on the training data t∗, using varying amounts of labels; (3) Evaluate the AUC on the test data of t∗
We compare three SVM classifiers trained using different feature representations: (1) SemanticRepresentation uses the l2 features generated according to the above procedure.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"(2) Word3gram uses unigram, bigram and trigram word features.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
(3) Letter3gram uses letter-trigrams.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Note that Word3gram and Letter3gram correspond to SVMWord and SVM-Letter respectively in Table 2.
",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
The AUC results for different amounts of t∗ training data are shown in Figure 4.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"In the Hotel, Flight and Restaurant domains, we observe that our semantic representation dominated the other two feature representations (Word3gram and Letter3gram) in all cases except the extremely large-data regime (more than 1 million training samples in domain t∗).",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Given sufficient labels, SVM is able to train well on Word3gram sparse features, but for most cases Se-
manticRepresentation is recommended.4
In a further experiment, we compare the following two DNNs using the same domain adaptation procedure: (1) DNN1: DNN where W1 is randomly initialized and parameters W1,W2,Wt ∗ 3 are trained on varying amounts of data in t∗;",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"(2) DNN2: DNN where W1 is obtained from other tasks (i.e. SemanticRepresentation) and fixed, while parameters W2,Wt ∗ 3 are trained on varying amounts of data in t∗.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
The purpose is to see whether shared semantic representation is useful even under a DNN architecture.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Figure 5 show the AUC results of DNN1 vs. DNN2 (the results SVM denotes the same system as SemanticRepresentation in Figure 4, plotted here for reference).",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"We observe that when the training data is extremely large (millions of samples), one does best by training all parameters from scratch (DNN1).",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Otherwise, one is better off using a shared semantic representation trained by multitask objectives.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Comparing DNN2 and SVM with SemanticRepresentation, we note that SVM works best for training data of several thousand samples; DNN2 works best in the medium data range.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"There is a large body of work on representation learning for natural language processing, sometimes using different terminologies for similar concepts; e.g., feature generation, dimensionality reduction, and vector space models.",4 Related Work,[0],[0]
"The main motivation is similar: to abstract away from surface forms in words, sentences, or documents, in order to alleviate sparsity and approximate semantics.",4 Related Work,[0],[0]
"Traditional techniques include LSA (Deerwester et al., 1990), ESA (Gabrilovich and Markovitch, 2007), PCA (Karhunen, 1998), and non-linear kernel variants (Schölkopf et al., 1998).",4 Related Work,[0],[0]
"Recently, learningbased approaches inspired by neural networks, especially DNNs, have gained in prominence, due to their favorable performance (Huang et al., 2013; Baroni et al., 2014; Milajevs et al., 2014).
",4 Related Work,[0],[0]
"Popular methods for learning word representations include (Collobert et al., 2011; Mikolov et al., 2013c; Mnih and Kavukcuoglu, 2013; Pennington et al., 2014): all are based on unsupervised objec-
4The trends differ slightly in the Nightlife domain.",4 Related Work,[0],[0]
"We believe this may be due to data bias on test data (only 298 samples).
tives of predicting words or word frequencies from raw text.",4 Related Work,[0],[0]
"End-to-end neural network models for specific tasks (e.g. parsing) often use these word representations as initialization, which are then iteratively improved by optimizing a supervised objective (e.g. parsing accuracy).",4 Related Work,[0],[0]
"A selection of successful applications of this approach include sequence labeling (Turian et al., 2010), parsing (Chen and Manning, 2014), sentiment (Socher et al., 2013), question answering (Iyyer et al., 2014) and translation modeling (Gao et al., 2014a).
",4 Related Work,[0],[0]
"Our model takes queries and documents as input, so it learns sentence/document representations.",4 Related Work,[0],[0]
"This is currently an open research question, the challenge being how to properly model semantic compositionality of words in vector space (Huang et al., 2013; M. Baroni and Zamparelli, 2013; Socher et al., 2013).",4 Related Work,[0],[0]
"While we adopt a bag-of-words approach for practical reasons (memory and run-time), our multi-task framework is extensible to other methods for sentence/document representations, such as those based on convolutional networks (Kalchbrenner et al., 2014; Shen et al., 2014; Gao et al., 2014b), parse tree structure (Irsoy and Cardie, 2014), and run-time inference (Le and Mikolov, 2014).
",4 Related Work,[0],[0]
"The synergy between multi-task learning and neural nets is quite natural; the general idea dates back to (Caruana, 1997).",4 Related Work,[0],[0]
The main challenge is in designing the tasks and the network structure.,4 Related Work,[0],[0]
"For example, (Collobert et al., 2011) defined part-of-speech tagging, chunking, and named entity recognition as multiple tasks in a single sequence labeler; (Bordes et al., 2012) defined multiple data sources as tasks in their relation extraction system.",4 Related Work,[0],[0]
"While conceptually similar, our model is novel in that it combines tasks as disparate as classification and ranking.",4 Related Work,[0],[0]
"Further, considering that multi-task models often exhibit mixed results (i.e. gains in some tasks but degradation in others), our accuracy improvements across all tasks is a very satisfactory result.",4 Related Work,[0],[0]
"In this work, we propose a robust and practical representation learning algorithm based on multi-task objectives.",5 Conclusion,[0],[0]
"Our multi-task DNN model successfully combines tasks as disparate as classification and ranking, and the experimental results demon-
strate that the model consistently outperforms strong baselines in various query classification and web search tasks.",5 Conclusion,[0],[0]
"Meanwhile, we demonstrated compactness of the model and the utility of the learned query/document representation for domain adaptation.
",5 Conclusion,[0],[0]
Our model can be viewed as a general method for learning semantic representations beyond the word level.,5 Conclusion,[0],[0]
"Beyond query classification and web search, we believe there are many other knowledge sources (e.g. sentiment, paraphrase) that can be incorporated either as classification or ranking tasks.",5 Conclusion,[0],[0]
A comprehensive exploration will be pursued as future work.,5 Conclusion,[0],[0]
"We thank Xiaolong Li, Yelong Shen, Xinying Song, Jianshu Chen, Byungki Byun, Bin Cao and the anonymous reviewers for valuable discussions and comments.",Acknowledgments,[0],[0]
Methods of deep neural networks (DNNs) have recently demonstrated superior performance on a number of natural language processing tasks.,abstractText,[0],[0]
"However, in most previous work, the models are learned based on either unsupervised objectives, which does not directly optimize the desired task, or singletask supervised objectives, which often suffer from insufficient training data.",abstractText,[0],[0]
"We develop a multi-task DNN for learning representations across multiple tasks, not only leveraging large amounts of cross-task data, but also benefiting from a regularization effect that leads to more general representations to help tasks in new domains.",abstractText,[0],[0]
"Our multi-task DNN approach combines tasks of multiple-domain classification (for query classification) and information retrieval (ranking for web search), and demonstrates significant gains over strong baselines in a comprehensive set of domain adaptation.",abstractText,[0],[0]
Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval,title,[0],[0]
"Recently, hyperbolic embeddings have been proposed as a way to capture hierarchy information for network and natural language processing tasks (Nickel & Kiela, 2017; Chamberlain et al., 2017).",1. Introduction,[0],[0]
"This approach is an exciting way to fuse structural information (for example, from knowledge graphs or synonym hierarchies) with the continuous representations favored by modern machine learning methods.
",1. Introduction,[0],[0]
"To understand the intuition behind hyperbolic embeddings’ superior capacity, note that trees can be embedded with arbitrarily low distortion into the Poincaré disk, a twodimensional model of hyperbolic space (Sarkar, 2011).",1. Introduction,[0],[0]
"In contrast, Bourgain’s theorem (Linial et al., 1995) shows that Euclidean space cannot achieve comparably low distortion
1Department of Computer Science, Stanford University 2Department of Computer Science, Cornell University.",1. Introduction,[0],[0]
"Correspondence to: Frederic Sala <fredsala@stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
for trees—even using an unbounded number of dimensions.
",1. Introduction,[0],[0]
"Many graphs, such as complex networks (Krioukov et al., 2010), the Internet (Krioukov et al., 2009), and social networks (Verbeek & Suri, 2016), are known to have tree-like or hyperbolic structure and thus befit hyperbolic embeddings.",1. Introduction,[0],[0]
"Indeed, recent works show that hyperbolic representations are suitable for many hierarchies (e.g. the question answering (Q/A) system HyperQA in Tay et al. (2018), vertex classifiers in Chamberlain et al. (2017), and link prediction (Nickel & Kiela, 2017)).",1. Introduction,[0],[0]
"However, the optimization problems underlying the embedding techniques in these works are challenging, motivating us to seek fundamental insights and to understand the subtle tradeoffs involved.
",1. Introduction,[0],[0]
"We begin by considering the case where we are given an input graph that is a tree or nearly tree-like, and our goal is to produce a low-dimensional hyperbolic embedding that preserves all distances.",1. Introduction,[0],[0]
This leads to a simple combinatorial strategy that directly places points instead of minimizing a surrogate loss function.,1. Introduction,[0],[0]
It is both fast (nearly linear time) and has formal quality guarantees.,1. Introduction,[0],[0]
"The approach proceeds in two phases: we (1) produce an embedding of a graph into a weighted tree, and (2) embed that tree into the hyperbolic disk.",1. Introduction,[0],[0]
"In particular, we consider an extension of an elegant embedding of trees into the Poincaré disk by Sarkar (2011) and work on low-distortion graph embeddings into tree metrics (Abraham et al., 2007).",1. Introduction,[0],[0]
"For trees, this approach has nearly perfect quality.",1. Introduction,[0],[0]
"On the WordNet hypernym graph reconstruction, it obtains a nearly perfect mean average precision (MAP) of 0.989 using just 2 dimensions.",1. Introduction,[0],[0]
"The best published numbers for WordNet in Nickel & Kiela (2017) range between 0.823 and 0.87 for 5 to 200 dimensions.
",1. Introduction,[0],[0]
We analyze this construction to extract fundamental tradeoffs.,1. Introduction,[0],[0]
"One tradeoff involves the embedding dimension, the properties of the graph, and the number of bits of precision used to represent components of embedded points—an important hidden cost.",1. Introduction,[0],[0]
"We show that for a fixed precision, the dimension required scales linearly with the length of the longest path.",1. Introduction,[0],[0]
"On the other hand, the dimension scales logarithmically with the maximum degree of the tree.",1. Introduction,[0],[0]
"This suggests that hyperbolic embeddings should have high quality on hierarchies like WordNet but require large dimensions or high precision on graphs with long chains.
",1. Introduction,[0],[0]
"To understand how hyperbolic embeddings perform for met-
rics that are far from tree-like, we consider a more general problem: given a matrix of distances that arise from points that are embeddable in hyperbolic space of dimension d (not necessarily from a graph), find a set of points that produces these distances.",1. Introduction,[0],[0]
"In Euclidean space, the problem is known as multidimensional scaling (MDS) and is solvable using PCA.",1. Introduction,[0],[0]
"A key step is a transformation that effectively centers the points, without knowledge of their exact coordinates.",1. Introduction,[0],[0]
"It is not obvious how to center points in hyperbolic space, which is curved.",1. Introduction,[0],[0]
"We show that in hyperbolic space, a centering operation is still possible with respect to a non-standard mean.",1. Introduction,[0],[0]
"In turn, this allows us to reduce the hyperbolic MDS problem (h-MDS) to a standard eigenvalue problem that can be solved with power methods.",1. Introduction,[0],[0]
"We also extend classical PCA perturbation analysis (Sibson, 1978; 1979).",1. Introduction,[0],[0]
"When applied to distances from graphs induced by real data, h-MDS obtains low distortion on far from tree-like graphs.",1. Introduction,[0],[0]
"However, we observe that these solutions may require high precision, which is not surprising in light of our previous analysis.
",1. Introduction,[0],[0]
"Finally, we handle increasing amounts of noise in the model, leading naturally into new SGD-based formulations.",1. Introduction,[0],[0]
"Like in traditional PCA, the underlying problem is nonconvex.",1. Introduction,[0],[0]
"In contrast to PCA, there are local minima that are not global minima—an additional challenge.",1. Introduction,[0],[0]
Our main technical result is that an SGD-based algorithm initialized with an h-MDS solution can recover the submanifold the data is on—even in some cases in which the data is perturbed by noise that can be full dimensional.,1. Introduction,[0],[0]
Our algorithm essentially provides new recovery results for convergence of Principal Geodesic Analysis (PGA) in hyperbolic space.,1. Introduction,[0],[0]
We implemented the resulting SGD-based algorithm using PyTorch.,1. Introduction,[0],[0]
"Finally, we note that all of our algorithms can handle incomplete distance information through standard techniques.",1. Introduction,[0],[0]
"We provide intuition connecting hyperbolic space and tree distances, discuss the metrics used to measure embedding fidelity, and discuss the relationship between the reconstruction and learning problems for graph embeddings.
",2. Background,[0],[0]
"Hyperbolic spaces The Poincaré disk H2 is a twodimensional model of hyperbolic geometry with points located in the interior of the unit disk, as shown in Figure 1.",2. Background,[0],[0]
"A natural generalization of H2 is the Poincaré ball Hr, with elements inside the unit ball.",2. Background,[0],[0]
"The Poincaré models offer several useful properties, chief among which is mapping conformally to Euclidean space.",2. Background,[0],[0]
"That is, angles are preserved between hyperbolic and Euclidean space.",2. Background,[0],[0]
"Distances, on the other hand, are not preserved, but are given by
dH(x, y) = acosh ( 1 + 2 ‖x− y‖2
(1− ‖x‖2)(1− ‖y‖2)
) .
",2. Background,[0],[0]
"There are some potentially unexpected consequences of this formula, and a simple example gives intuition about a key technical property that allows hyperbolic space to embed trees.",2. Background,[0],[0]
"Consider three points inside the unit disk: the origin 0, and points x and y with ‖x‖ = ‖y‖ = t for some t > 0.",2. Background,[0],[0]
"As shown on the right of Figure 1, as t → 1 (i.e., the points move towards the outside of the disk), in flat Euclidean space, the ratio dE(x,y)dE(x,0)+dE(0,y) is constant with respect to t (blue curve).",2. Background,[0],[0]
"In contrast, the ratio
dH(x,y) dH(x,0)+dH(0,y) approaches 1, or, equivalently, the distance dH(x, y) approaches dH(x, 0) +",2. Background,[0],[0]
"dH(0, y) (red and pink curves).",2. Background,[0],[0]
"That is, the shortest path between x and y is almost the same as the path through the origin.",2. Background,[0],[0]
This is analogous to the property of trees in which the shortest path between two sibling nodes is the path through their parent.,2. Background,[0],[0]
This tree-like nature of hyperbolic space is the key property exploited by embeddings.,2. Background,[0],[0]
"Moreover, this property holds for arbitrarily small angles between x and y.
Lines and geodesics There are two types of geodesics (shortest paths) in the Poincaré disk model: segments of circles that are orthogonal to the disk surface, and disk diameters (Brannan et al., 2012).",2. Background,[0],[0]
"Our algorithms and proofs make use of a simple geometric fact: isometric reflection across geodesics (preserving hyperbolic distances) is represented in this Euclidean model as a circle inversion.
",2. Background,[0],[0]
Embeddings and fidelity measures An embedding is a mapping f :,2. Background,[0],[0]
"U → V for spaces U, V with distances dU , dV .",2. Background,[0],[0]
"We measure the quality of embeddings with several fidelity measures, presented here from most local to most global.
",2. Background,[0],[0]
"Recent work (Nickel & Kiela, 2017) proposes using the mean average precision (MAP).",2. Background,[0],[0]
"For a graph G = (V,E), let a ∈ V have neighborhood Na = {b1, b2, . . .",2. Background,[0],[0]
", bdeg(a)}, where deg(a) denotes the degree of a.",2. Background,[0],[0]
"In the embedding f , consider the points closest to f(a), and define Ra,bi to be the smallest set of such points that contains bi (that is, Ra,bi is the smallest set of nearest points required to retrieve the ith neighbor of a in f ).",2. Background,[0],[0]
"Then, the MAP is defined to be
MAP(f) = 1 |V | ∑ a∈V
1
deg(a) |Na|∑ i=1",2. Background,[0],[0]
"|Na ∩Ra,bi | |Ra,bi | .
",2. Background,[0],[0]
"We have MAP(f) ≤ 1, with 1 as the best case.",2. Background,[0],[0]
"MAP is not concerned with explicit distances, but only ranks between the distances of immediate neighbors.",2. Background,[0],[0]
"It is a local metric.
",2. Background,[0],[0]
"The standard metric for graph embeddings is distortion D. For an n point embedding,
D(f)",2. Background,[0],[0]
"= 1( n 2 )  ∑ u,v∈U :u6=v |dV",2. Background,[0],[0]
"(f(u),",2. Background,[0],[0]
"f(v))− dU (u, v)| dU (u, v)  .
",2. Background,[0],[0]
"The best distortion isD(f) = 0, preserving the edge lengths exactly.",2. Background,[0],[0]
"This is a global metric, as it depends directly on the underlying distances rather than the local relationships between distances.",2. Background,[0],[0]
"A variant is the worst-case distortion Dwc, defined by
Dwc(f) =",2. Background,[0],[0]
"maxu,v∈U :u6=v dV (f(u), f(v))/dU (u, v)
minu,v∈U :u6=v dV (f(u), f(v))/dU (u, v) .
",2. Background,[0],[0]
"That is, the wost-case distortion is the ratio of the maximal expansion and the minimal contraction of distances.",2. Background,[0],[0]
Note that scaling the unit distance does not affect Dwc.,2. Background,[0],[0]
"The best worst-case distortion is Dwc(f) = 1.
",2. Background,[0],[0]
"Reconstruction and learning If we lack a full set of distances, we can either use the triangle inequality to recover the missing distances, or we can access the scaled Euclidean distances (the inside of the acosh in dH(x, y)), and apply standard matrix completion techniques (Candes & Tao, 2010).",2. Background,[0],[0]
Then we compute an embedding using any of the approaches discussed in this paper.,2. Background,[0],[0]
We quantify the error introduced by this process experimentally in Section 5.,2. Background,[0],[0]
We first focus on hyperbolic tree embeddings—a natural approach considering the tree-like behavior of hyperbolic space.,3. Combinatorial Constructions,[0],[0]
We review the embedding of Sarkar (2011).,3. Combinatorial Constructions,[0],[0]
"We then provide novel analysis on the precision, revealing fundamental limits of hyperbolic embeddings.",3. Combinatorial Constructions,[0],[0]
"In particular, we characterize the bits of precision needed for hyperbolic representations.",3. Combinatorial Constructions,[0],[0]
"We extend the construction to r dimensions, and propose to use Steiner nodes to better embed general graphs as trees, building on Abraham et al. (2007).
",3. Combinatorial Constructions,[0],[0]
Embedding trees The nature of hyperbolic space lends itself towards excellent tree embeddings.,3. Combinatorial Constructions,[0],[0]
"In fact, it is possible to embed trees into the Poincaré disk H2 with arbitrarily low distortion (Sarkar, 2011).",3. Combinatorial Constructions,[0],[0]
"Remarkably, trees cannot be embedded into Euclidean space with arbitrarily low distortion for any number of dimensions.",3. Combinatorial Constructions,[0],[0]
"These notions motivate the following two-step process for embedding hierarchies
into hyperbolic space: (1) embed the graphG = (V,E) into a tree T , and (2) embed T into the Poincaré ball",3. Combinatorial Constructions,[0],[0]
Hd.,3. Combinatorial Constructions,[0],[0]
We refer to this process as the combinatorial construction.,3. Combinatorial Constructions,[0],[0]
Note that we are not required to minimize a loss function.,3. Combinatorial Constructions,[0],[0]
"We begin by describing the second stage, where we extend an elegant construction from Sarkar (2011).",3. Combinatorial Constructions,[0],[0]
Algorithm 1 performs an embedding of trees into H2.,3.1. Sarkar’s Construction,[0],[0]
The inputs are a scaling factor τ and a node a (of degree deg(a)) from the tree with parent node b. Say a and b have already been embedded into f(a) and f(b) in H2.,3.1. Sarkar’s Construction,[0],[0]
"The algorithm places the children c1, c2, . . .",3.1. Sarkar’s Construction,[0],[0]
", cdeg(a)−1 into H2.
",3.1. Sarkar’s Construction,[0],[0]
A two-step process is used.,3.1. Sarkar’s Construction,[0],[0]
"First, f(a) and f(b) are reflected across a geodesic (using circle inversion) so that f(a) is mapped onto the origin 0 and f(b) is mapped onto some point",3.1. Sarkar’s Construction,[0],[0]
"z. Next, we place the children nodes to vectors y1, . . .",3.1. Sarkar’s Construction,[0],[0]
", yd−1 equally spaced around a circle with radius eτ−1 eτ+1 (which is a circle of radius τ in the hyperbolic metric), and maximally separated from the reflected parent node embedding z.",3.1. Sarkar’s Construction,[0],[0]
"Lastly, we reflect all of the points back across the geodesic.",3.1. Sarkar’s Construction,[0],[0]
The isometric properties of reflections imply that all children are now at hyperbolic distance exactly τ from f(a).,3.1. Sarkar’s Construction,[0],[0]
"To embed the entire tree, we place the root at the origin O and its children in a circle around it (as in Step 5 of Algorithm 1), then recursively place their children until all nodes have been placed.",3.1. Sarkar’s Construction,[0],[0]
This process runs in linear time.,3.1. Sarkar’s Construction,[0],[0]
Sarkar’s construction works by separating children sufficiently in hyperbolic space.,3.2. Analyzing Sarkar’s Construction,[0],[0]
A key technical idea is to scale all the edges by a factor τ before embedding.,3.2. Analyzing Sarkar’s Construction,[0],[0]
We can then recover the original distances by dividing by τ .,3.2. Analyzing Sarkar’s Construction,[0],[0]
This transformation exploits the fact that hyperbolic space is not scale invariant.,3.2. Analyzing Sarkar’s Construction,[0],[0]
"Sarkar’s construction always captures neighbors perfectly, but Figure 1 implies that increasing the scale preserves the distances between farther nodes better.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Indeed, if one sets τ = 1+εε ( 2 log degmaxπ/2 ) , then the worst-case distortion D of the resulting embedding is no more than
Algorithm 1 Sarkar’s Construction 1: Input: Node a with parent b, children to place c1, c2, . . .",3.2. Analyzing Sarkar’s Construction,[0],[0]
", cdeg(a)−1, partial embedding f containing an embedding for a and b, scaling factor τ
2: (0, z)← reflectf(a)→0(f(a), f(b))",3.2. Analyzing Sarkar’s Construction,[0],[0]
"3: θ ← arg(z) {angle of z from x-axis in the plane} 4: for i ∈ {1, . . .",3.2. Analyzing Sarkar’s Construction,[0],[0]
",deg(a)− 1} do 5: yi ← e τ−1 eτ+1 · ( cos ( θ + 2πideg(a) ) , sin ( θ + 2πideg(a)
))",3.2. Analyzing Sarkar’s Construction,[0],[0]
"6: (f(a), f(b), f(c1), . . .",3.2. Analyzing Sarkar’s Construction,[0],[0]
", f(cdeg(a)−1))",3.2. Analyzing Sarkar’s Construction,[0],[0]
"←
reflect0→f(a)(0, z, y1, . . .",3.2. Analyzing Sarkar’s Construction,[0],[0]
", ydeg(x)−1) 7: Output: Embedded H2 vectors f(c1), f(c2), . . .",3.2. Analyzing Sarkar’s Construction,[0],[0]
", f(cdeg(a)−1)
1 + ε.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"For trees, Sarkar’s construction has arbitrarily high fidelity.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"However, this comes at a cost: the scaling τ affects the bits of precision required.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"In fact, we will show that the precision scales logarithmically with the degree of the tree—but linearly with the maximum path length.
",3.2. Analyzing Sarkar’s Construction,[0],[0]
How many bits of precision do we need to represent points in H2?,3.2. Analyzing Sarkar’s Construction,[0],[0]
"If x ∈ H2, then ‖x‖ < 1, so we need sufficiently many bits so that 1− ‖x‖ will not be rounded to zero.",3.2. Analyzing Sarkar’s Construction,[0],[0]
This requires roughly − log(1− ‖x‖) = log 11−‖x‖ bits.,3.2. Analyzing Sarkar’s Construction,[0],[0]
"Say we are embedding two points x, y at distance d. As described in the background, there is an isometric reflection that takes a pair of points (x, y) in H2 to (0, z) while preserving their distance, so without loss of generality we have that
d = dH(x, y) = dH(0, z) = acosh
( 1 + 2 ‖z‖2
1− ‖z‖2
) .
",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Rearranging the terms, we have (cosh(d) + 1)/2 = (1 − ‖z‖2)−1 ≥ (1 − ‖z‖)−1/2.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Thus, the number of bits we want so that 1 − ‖z‖ will not be rounded to zero is log(cosh(d)+1).",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Since cosh(d) = (exp(d)+exp(−d))/2, this is roughly d bits.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"That is, in hyperbolic space, we need about d bits to express distances of d (rather than log d in Euclidean space).1 This result will be of use below.
",3.2. Analyzing Sarkar’s Construction,[0],[0]
Consider the largest distance in the embeddings produced by Algorithm 1.,3.2. Analyzing Sarkar’s Construction,[0],[0]
"If the longest path length in the tree is `, and each edge has length τ = 1ε ( 2 log degmax π/2 ) , the largest distance is O( `ε log degmax), and we require this number of bits for the representation.
Let us interpret this expression.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Note that degmax is inside the log term, so that a bushy tree is not penalized much in precision.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"On the other hand, the longest path length ` is not, so that hyperbolic embeddings struggle with long paths.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Moreover, by selecting an explicit graph, we derive a matching lower bound, concluding that to achieve a dis-
1Although it is particularly easy to bound precision in the Poincaré model, this fact holds generally for hyperbolic space independent of model (shown in the appendix).
",3.2. Analyzing Sarkar’s Construction,[0],[0]
"tortion ε, any construction requires Ω ( ` ε log(degmax) ) bits.",3.2. Analyzing Sarkar’s Construction,[0],[0]
The argument follows from selecting a graph consisting of m(degmax+1) nodes in a tree with a single root and degmax chains each of length m (shown in the appendix).,3.2. Analyzing Sarkar’s Construction,[0],[0]
Our next contribution is a generalization of the construction from the disk H2 to the ball Hr.,3.3. Improving the Construction,[0],[0]
"Our construction follows the same line as Algorithm 1, but since we have r dimensions, the step where we place children spaced out on a circle around their parent now uses a hypersphere.
",3.3. Improving the Construction,[0],[0]
"Spacing out points on the hypersphere is a classic problem known as spherical coding (Conway & Sloane, 1999).",3.3. Improving the Construction,[0],[0]
"As we shall see, the number of children that we can place for a particular angle grows with the dimension.",3.3. Improving the Construction,[0],[0]
"Since the required scaling factor τ gets larger as the angle decreases, we can reduce τ for a particular embedding by increasing the dimension.",3.3. Improving the Construction,[0],[0]
"Note that increasing the dimension helps with bushy trees (large degmax), but has limited effect on tall trees with small degmax.",3.3. Improving the Construction,[0],[0]
"We show
Proposition 3.1.",3.3. Improving the Construction,[0],[0]
"The generalized Hr combinatorial construction has distortion at most 1 + ε and requires at most O( 1ε ` r log degmax) bits to represent a node component for r ≤ (log degmax) + 1, and O( 1ε `) bits for r > (log degmax) + 1.
To generalize to Hr, we replace Step 5 in Algorithm 1 with a node placement step based on coding theory.",3.3. Improving the Construction,[0],[0]
The children are placed at the vertices of a hypercube inscribed into the unit hypersphere (and then scaled by τ ).,3.3. Improving the Construction,[0],[0]
"Each component of a hypercube vertex has the form ±1√
r .",3.3. Improving the Construction,[0],[0]
"We index these
points using binary sequences a ∈ {0, 1}r in the following way: xa = ( (−1)a1√ r , (−1) a2 √ r , . . .",3.3. Improving the Construction,[0],[0]
", (−1) ar √ r ) .",3.3. Improving the Construction,[0],[0]
We space out the children by controlling the distances by selecting a set of binary sequences a with a prescribed minimum Hamming distance—a binary error-correcting code—and placing the children at the resulting hypercube vertices.,3.3. Improving the Construction,[0],[0]
"We provide more details, including our choice of code in the appendix.",3.3. Improving the Construction,[0],[0]
We revisit the first step of the construction: embedding graphs into trees.,3.4. Embedding into Trees,[0],[0]
"There are fundamental limits to how well graphs can be embedded into trees; in general, breaking long cycles inevitably adds distortion, as shown in Figure 2.",3.4. Embedding into Trees,[0],[0]
"We are inspired by a measure of this limit, the δ-4 points condition introduced in Abraham et al. (2007).",3.4. Embedding into Trees,[0],[0]
A graph on n nodes that satisfies the δ-4 points condition has distortion at most (1 + δ)c1 logn for some constant c1.,3.4. Embedding into Trees,[0],[0]
"This result enables our end-to-end embedding to achieve a distortion of at most D(f) ≤ (1 + δ)c1 logn(1 + ε).
",3.4. Embedding into Trees,[0],[0]
"The result in Abraham et al. (2007) builds a tree with Steiner
nodes.",3.4. Embedding into Trees,[0],[0]
These additional nodes can help control the distances in the resulting weighted tree (Figure 2).,3.4. Embedding into Trees,[0],[0]
"Note that Algorithm 1 readily extends to the case of weighted trees.
",3.4. Embedding into Trees,[0],[0]
"In summary, the key takeaways of our analysis are:
•",3.4. Embedding into Trees,[0],[0]
"There is a fundamental tension between precision and quality in hyperbolic embeddings.
",3.4. Embedding into Trees,[0],[0]
"• Hyperbolic embeddings have an exponential advantage in space compared to Euclidean embeddings for short, bushy hierarchies, but will have less of an advantage for graphs that contain long paths.
",3.4. Embedding into Trees,[0],[0]
• Choosing an appropriate scaling factor τ is critical for quality.,3.4. Embedding into Trees,[0],[0]
"Later, we will propose to learn this scale factor automatically for computing embeddings in PyTorch.
",3.4. Embedding into Trees,[0],[0]
• Steiner nodes can help improve embeddings of graphs.,3.4. Embedding into Trees,[0],[0]
"In this section, we explore a fundamental and more general question than we did in the previous section: if we are given the pairwise distances arising from a set of points in hyperbolic space, can we recover the points?",4. Hyperbolic Multidimensional Scaling,[0],[0]
This enables us to produce an embedding for a desired distance metric.,4. Hyperbolic Multidimensional Scaling,[0],[0]
The equivalent problem for Euclidean distances is solved with multidimensional scaling (MDS).,4. Hyperbolic Multidimensional Scaling,[0],[0]
The goal of this section is to analyze the hyperbolic MDS (h-MDS) problem.,4. Hyperbolic Multidimensional Scaling,[0],[0]
"We describe and overcome the additional technical challenges imposed by hyperbolic distances, and show that exact recovery is possible and interpretable.",4. Hyperbolic Multidimensional Scaling,[0],[0]
Afterwards we propose a technique for dimensionality reduction using principal geodesics analysis (PGA) that provides optimization guarantees.,4. Hyperbolic Multidimensional Scaling,[0],[0]
"In particular, this addresses the shortcomings of h-MDS when recovering points that do not exactly lie on a hyperbolic manifold.",4. Hyperbolic Multidimensional Scaling,[0],[0]
"Suppose that there is a set of hyperbolic points x1, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn ∈ Hr, embedded in the Poincaré ball and written X ∈ Rn×r in matrix form.",4.1. Exact Hyperbolic MDS,[0],[0]
"We observe all the pairwise distances di,j = dH(xi, xj), but do not observe X: our goal is to use the observed di,j’s to recover X (or some other set of points with the same pairwise distances di,j).
",4.1. Exact Hyperbolic MDS,[0],[0]
The MDS algorithm in the Euclidean setting makes an important centering2 assumption: the points have mean 0.,4.1. Exact Hyperbolic MDS,[0],[0]
"If an exact embedding for the distances exists, it can be recovered from a matrix factorization.",4.1. Exact Hyperbolic MDS,[0],[0]
"In other words, Euclidean MDS always recovers a centered embedding.
",4.1. Exact Hyperbolic MDS,[0],[0]
"In hyperbolic space, the same algorithm does not work, but we show that it is possible to find an embedding centered at a different mean.",4.1. Exact Hyperbolic MDS,[0],[0]
"More precisely, we introduce a new mean which we call the pseudo-Euclidean mean, that behaves like the Euclidean mean in that it enables recovery through matrix factorization.",4.1. Exact Hyperbolic MDS,[0],[0]
"Once the points are recovered in hyperbolic space, they can be recentered around a more canonical mean by translating it to the origin.
",4.1. Exact Hyperbolic MDS,[0],[0]
"Algorithm 2 is our complete algorithm, and for the remainder of this section we will describe how and why it works.",4.1. Exact Hyperbolic MDS,[0],[0]
"We first describe the hyperboloid model, an alternate but equivalent model of hyperbolic geometry in which h-MDS is simpler.",4.1. Exact Hyperbolic MDS,[0],[0]
"Of course, we can easily convert between the hyperboloid model and the Poincaré ball model.",4.1. Exact Hyperbolic MDS,[0],[0]
"Next, we show how to reduce the problem to a standard PCA problem, which recovers an embedding centered at the points’ pseudo-Euclidean mean.",4.1. Exact Hyperbolic MDS,[0],[0]
"Finally, we discuss the meaning and implications of centering and prove that the algorithm preserves submanifolds as well—that is, if there is an exact embedding in k < r dimensions centered at their canonical mean, then our algorithm will recover it.
",4.1. Exact Hyperbolic MDS,[0],[0]
The hyperboloid model Define Q to be the diagonal matrix in Rr+1 where Q00 = 1 and Qii = −1 for i > 0.,4.1. Exact Hyperbolic MDS,[0],[0]
"For a vector x ∈ Rr+1, xTQx is called the Minkowski quadratic form.",4.1. Exact Hyperbolic MDS,[0],[0]
"The hyperboloid model is defined as
Mr = { x ∈ Rr+1 ∣∣xTQx = 1 ∧ x0 > 0} , which is endowed with a distance measure dH(x, y) = acosh(xTQy).",4.1. Exact Hyperbolic MDS,[0],[0]
"For convenience, for x ∈Mr let x0 denote 0th coordinate eT0 x, and ~x ∈",4.1. Exact Hyperbolic MDS,[0],[0]
Rr denote the rest of the coordinates3.,4.1. Exact Hyperbolic MDS,[0],[0]
"With this notation, the Minkowski bilinear form can be written xTQy =",4.1. Exact Hyperbolic MDS,[0],[0]
x0y0,4.1. Exact Hyperbolic MDS,[0],[0]
"− ~xT~y.
2We say that points are centered at a particular mean if this mean is at 0.",4.1. Exact Hyperbolic MDS,[0],[0]
"The act of centering refers to applying an isometry that makes the mean of the points 0.
",4.1. Exact Hyperbolic MDS,[0],[0]
"3Since x0 = √
1 + ‖~x‖2 is just a function of ~x, we can equivalently consider just ~x as being a member of a model of hyperbolic space: This representation is sometimes known as the Gans model.
",4.1. Exact Hyperbolic MDS,[0],[0]
"A new mean Given points x1, x2, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn",4.1. Exact Hyperbolic MDS,[0],[0]
"∈Mr in hyperbolic space, define a variance term
Ψ(z;x1, x2, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn) = n∑ i=1",4.1. Exact Hyperbolic MDS,[0],[0]
"sinh2(dH(xi, z)).
",4.1. Exact Hyperbolic MDS,[0],[0]
We define a pseudo-Euclidean mean to be any local minimum of this expression.,4.1. Exact Hyperbolic MDS,[0],[0]
"Notice that this is independent of any particular model of hyperbolic space, since it is defined only through the hyperbolic distance function dH .",4.1. Exact Hyperbolic MDS,[0],[0]
Lemma 4.1.,4.1. Exact Hyperbolic MDS,[0],[0]
Define X ∈ Rn×r such that XT ei = ~xi and u ∈,4.1. Exact Hyperbolic MDS,[0],[0]
"Rn such that ui = x0,i.",4.1. Exact Hyperbolic MDS,[0],[0]
"Then
∇~zΨ(z;x1, x2, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn)|~z=0 = −2 n∑ i=1",4.1. Exact Hyperbolic MDS,[0],[0]
"x0,i~xi = −2XTu.
",4.1. Exact Hyperbolic MDS,[0],[0]
This means that 0 is a pseudo-Euclidean mean if and only if 0 = XTu.,4.1. Exact Hyperbolic MDS,[0],[0]
"Call some hyperbolic points x1, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn pseudoEuclidean centered if their average is 0 in this sense: i.e. if XTu = 0.",4.1. Exact Hyperbolic MDS,[0],[0]
"We can always center a set of points without affecting their pairwise distances by simply finding their average, and then sending it to 0 through an isometry.
",4.1. Exact Hyperbolic MDS,[0],[0]
"Recovery via matrix factorization Suppose we observe the pairwise distances dH(xi, xj) of points x1, x2, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn ∈Mr.",4.1. Exact Hyperbolic MDS,[0],[0]
"This gives the matrix Y such that
Yi,j = cosh (dH(xi, xj))",4.1. Exact Hyperbolic MDS,[0],[0]
"= x0,ix0,j",4.1. Exact Hyperbolic MDS,[0],[0]
− ~xiT ~xj .,4.1. Exact Hyperbolic MDS,[0],[0]
"(1)
DefiningX and u as in Lemma 4.1, then in matrix form Y = uuT−XXT .",4.1. Exact Hyperbolic MDS,[0],[0]
"Without loss of generality, suppose that the xi are centered at their pseudo-Euclidean mean, so thatXTu = 0 by Lemma 4.1.",4.1. Exact Hyperbolic MDS,[0],[0]
"This implies that u is an eigenvector of Y with positive eigenvalue, and the rest of Y ’s eigenvalues are negative.",4.1. Exact Hyperbolic MDS,[0],[0]
"Therefore an eigendecomposition of Y will find u, X̂ such that Y = uuT − X̂X̂T , i.e. it will directly recover X up to rotation.
",4.1. Exact Hyperbolic MDS,[0],[0]
"In fact, running PCA on −Y = XTX − uuT to find the n most significant non-negative eigenvectors will recover X up to rotation, and then u can be found by leveraging the fact that x0 = √ 1 + ‖~x‖2.",4.1. Exact Hyperbolic MDS,[0],[0]
"This leads to Algorithm 2, with optional post-processing steps for converting the embedding to the Poincaré ball model and for re-centering the points.
",4.1. Exact Hyperbolic MDS,[0],[0]
"A word on centering The MDS algorithm in Euclidean geometry returns points centered at their Karcher mean z, which is a point minimizing ∑ d2(z, xi) (where d is the distance metric).",4.1. Exact Hyperbolic MDS,[0],[0]
"The Karcher center is important for interpreting dimensionality reduction; we use the analogous hyperbolic Karcher mean for PGA in Section 4.2.
",4.1. Exact Hyperbolic MDS,[0],[0]
"Although Algorithm 2 returns points centered at their pseudo-Euclidean mean instead of their Karcher mean, they can be easily recentered by finding their Karcher mean and
Algorithm 2 1: Input: Distance matrix di,j and rank r 2: Compute scaled distance matrix Yi,j = cosh(di,j) 3: X → PCA(−Y, r) 4: Project X from hyperboloid model to Poincaré model: x→ x
1+ √ 1+‖x‖2
5:",4.1. Exact Hyperbolic MDS,[0],[0]
"If desired, centerX at a different mean (e.g. the Karcher mean) 6: return X
reflecting it onto the origin.",4.1. Exact Hyperbolic MDS,[0],[0]
"Furthermore, Algorithm 2 preserves the dimension of the embedding:
Lemma 4.2.",4.1. Exact Hyperbolic MDS,[0],[0]
"If a set of points lie in a dimension-k geodesic submanifold, then both their Karcher mean and their pseudo-Euclidean mean lie in the same submanifold.
",4.1. Exact Hyperbolic MDS,[0],[0]
"This implies that centering with the pseudo-Euclidean mean preserves geodesic submanifolds: If it is possible to embed distances in a dimension-k geodesic submanifold centered and rooted at a Karcher mean, then it is also possible to embed the distances in a dimension-k submanifold centered and rooted at a pseudo-Euclidean mean, and vice versa.",4.1. Exact Hyperbolic MDS,[0],[0]
"Given a high-rank embedding (resulting from h-MDS, for example), we may wish to find a lower-rank version.",4.2. Reducing Dimensionality with PGA,[0],[0]
"In Euclidean space, one can get the optimal lower rank embedding by simply discarding components.",4.2. Reducing Dimensionality with PGA,[0],[0]
"However, this may not be the case in hyperbolic space.",4.2. Reducing Dimensionality with PGA,[0],[0]
"Motivated by this, we study dimensionality reduction in hyperbolic space.
",4.2. Reducing Dimensionality with PGA,[0],[0]
"As hyperbolic space does not have a linear subspace structure like Euclidean space, we need to define what we mean by lower-dimensional.",4.2. Reducing Dimensionality with PGA,[0],[0]
"We follow Principal Geodesic Analysis (Fletcher et al., 2004), (Huckemann et al., 2010).",4.2. Reducing Dimensionality with PGA,[0],[0]
"Consider an initial embedding with points x1, . . .",4.2. Reducing Dimensionality with PGA,[0],[0]
", xn ∈ H2 and let dH :",4.2. Reducing Dimensionality with PGA,[0],[0]
H2 × H2 → R+ be the hyperbolic distance.,4.2. Reducing Dimensionality with PGA,[0],[0]
Suppose we want to map this embedding onto a one-dimensional subspace.,4.2. Reducing Dimensionality with PGA,[0],[0]
"(Note that we are considering a two-dimensional embedding and one-dimensional subspace here for simplicity, and these results immediately extend to higher dimensions.)",4.2. Reducing Dimensionality with PGA,[0],[0]
"In this case, the goal of PGA is to find a geodesic γ :",4.2. Reducing Dimensionality with PGA,[0],[0]
"[0, 1] → H2 that passes through the mean of the points and that minimizes the squared error (or variance): f(γ) = ∑n i=1 mint∈[0,1] dH(γ(t), xi) 2.
",4.2. Reducing Dimensionality with PGA,[0],[0]
This expression can be simplified significantly and reduced to a minimization in Euclidean space.,4.2. Reducing Dimensionality with PGA,[0],[0]
"First, we find the mean of the points, the point x̄ which minimizes∑n i=1",4.2. Reducing Dimensionality with PGA,[0],[0]
"dH(x̄, xi)
2.4",4.2. Reducing Dimensionality with PGA,[0],[0]
"Next, we reflect all the points xi so that their mean is 0 in the Poincaré disk model; we can
4The derivative of the hyperbolic distance has a singularity, that is, limy→x ∂x|dH(x, y)| → ∞ for any x ∈ H.",4.2. Reducing Dimensionality with PGA,[0],[0]
"This issue can
do this using a circle inversion that maps x̄ onto 0",4.2. Reducing Dimensionality with PGA,[0],[0]
"Since reflections are isometric, if γ is a line through 0 and Rγ is the reflection across γ, we have that dH(γ, x) = mint∈[0,1] dH(γ(t), x) = 1 2dH(Rlx, x).
",4.2. Reducing Dimensionality with PGA,[0],[0]
"Combining this with the Euclidean reflection formula and the hyperbolic metric produces
f(γ) = 1
4 n∑ i=1 acosh2",4.2. Reducing Dimensionality with PGA,[0],[0]
"( 1 + 8dE(γ, xi) 2 (1− ‖xi‖2)2 ) ,
in which dE is the Euclidean distance from a point to a line.",4.2. Reducing Dimensionality with PGA,[0],[0]
If we define wi = √ 8xi/(1,4.2. Reducing Dimensionality with PGA,[0],[0]
− ‖xi‖2),4.2. Reducing Dimensionality with PGA,[0],[0]
this reduces to the simplified expression f(γ),4.2. Reducing Dimensionality with PGA,[0],[0]
"= 1 4 ∑n i=1 acosh 2 ( 1 + dE(γ,wi) 2 ) .
",4.2. Reducing Dimensionality with PGA,[0],[0]
Notice that the loss function is not convex.,4.2. Reducing Dimensionality with PGA,[0],[0]
"We observe that there can be multiple local minima that are attractive and stable, in contrast to PCA.",4.2. Reducing Dimensionality with PGA,[0],[0]
Figure 3 illustrates this nonconvexity on a simple dataset in H2 with only four examples.,4.2. Reducing Dimensionality with PGA,[0],[0]
"This makes globally optimizing the objective difficult.
",4.2. Reducing Dimensionality with PGA,[0],[0]
"Nevertheless, there will always be a region Ω containing a global optimum γ∗ that is convex and admits an efficient projection, and where f is convex when restricted to Ω.",4.2. Reducing Dimensionality with PGA,[0],[0]
"Thus it is possible to build a gradient descent-based algorithm to recover lower-dimensional subspaces: for example, we built a simple optimizer in PyTorch.",4.2. Reducing Dimensionality with PGA,[0],[0]
"We also give a sufficient condition on the data for f above to be convex.
",4.2. Reducing Dimensionality with PGA,[0],[0]
Lemma 4.3.,4.2. Reducing Dimensionality with PGA,[0],[0]
"For hyperbolic PGA if for all i,
acosh2 ( 1 + dE(γ,wi) 2 ) < min ( 1, 1
3 ‖wi‖2 ) then f is locally convex at γ.
be mitigated by minimizing d2H , which does have a continuous derivative throughout H. The use of dH(x, y) is a minor instability in Nickel & Kiela (2017); Chamberlain et al. (2017)’s formulation, necessitating guarding against NANs.",4.2. Reducing Dimensionality with PGA,[0],[0]
"We discuss this further in the appendix.
",4.2. Reducing Dimensionality with PGA,[0],[0]
"As a result, if we initialize in and optimize over a region that contains γ∗ and where the condition of Lemma 4.3 holds, then gradient descent will be guaranteed to converge to γ∗.",4.2. Reducing Dimensionality with PGA,[0],[0]
"We can turn this result around and read it as a recovery result: if the noise is bounded in this regime, then we are able to provably recover the correct low-dimensional embedding.",4.2. Reducing Dimensionality with PGA,[0],[0]
We evaluate the proposed approaches and compare against existing methods.,5. Experiments,[0],[0]
"We hypothesize that for tree-like data, the combinatorial construction offers the best performance.",5. Experiments,[0],[0]
"For general data, we expect h-MDS to produce the lowest distortion, while it may have low MAP due to precision limitations.",5. Experiments,[0],[0]
We anticipate that dimension is a critical factor (outside of the combinatorial construction).,5. Experiments,[0],[0]
"In the appendix, we report on additional datasets, combinatorial construction parameters, and the effect of hyperparameters.
",5. Experiments,[0],[0]
"Datasets We consider trees, tree-like hierarchies, and graphs that are not tree-like.",5. Experiments,[0],[0]
"Trees include fully-balanced and phylogenetic trees expressing genetic heritage (Hofbauer et al., 2016), available at Sanderson et al. (1994).",5. Experiments,[0],[0]
"Nearly tree-like hierarchies include the WordNet hypernym graph (the largest connected component from Nickel & Kiela (2017)) and a graph of Ph.D. advisor-advisee relationships (De Nooy et al., 2011).",5. Experiments,[0],[0]
"Also included are datasets
that vary in their tree nearness, such as disease relationships (Goh et al., 2007) and protein interactions (Jeong et al., 2001), both available from Rossi & Ahmed (2015).",5. Experiments,[0],[0]
"We also include the general relativity and quantum cosmology (GrQC) arXiv collaboration network (Leskovec et al., 2007).
",5. Experiments,[0],[0]
Approaches Combinatorial embeddings into H2 use the ε = 0.1 precision setting; others are considered in the Appendix.,5. Experiments,[0],[0]
We performed h-MDS in floating point precision.,5. Experiments,[0],[0]
"We include results for our PyTorch implementation (PT) of an SGD-based algorithm (described later), and a warm start version (PWS) initialized with the high-dimensional combinatorial construction.",5. Experiments,[0],[0]
"We compare against classical MDS (i.e., PCA), and the optimization-based approach Nickel & Kiela (2017), which we call FB.",5. Experiments,[0],[0]
"The experiments for h-MDS, PyTorch SGD, PCA, and FB used dimensions of 2,5,10,50,100,200; we recorded the best resulting MAP and distortion.",5. Experiments,[0],[0]
"Due to the large scale, we did not replicate the best FB numbers on large graphs (i.e., Gr-QC and WordNet); we report their best published MAP numbers (their work does not report distortion).",5. Experiments,[0],[0]
These entries are marked with an asterisk.,5. Experiments,[0],[0]
"For the WordNet graph, FB uses the transitive closure; a weighted version of the graph captures the ancestor relationships.",5. Experiments,[0],[0]
"The full details are in appendix.
",5. Experiments,[0],[0]
"Quality In Table 3 (left), we report the distortion.",5. Experiments,[0],[0]
"As expected, for tree or tree-like graphs, the combinatorial construction has exceedingly low distortion.",5. Experiments,[0],[0]
"Because h-MDS is meant to recover points exactly, we hypothesized that h-MDS would offer very low distortion on these datasets.",5. Experiments,[0],[0]
"Table 3 confirms this: among h-MDS, PCA, and FB, hMDS consistently offers the lowest distortion, producing, for example, a distortion of 0.039 on the phylogenetic tree.",5. Experiments,[0],[0]
We observe that floating point h-MDS struggles with MAP.,5. Experiments,[0],[0]
"We separately confirmed that this is due to precision (by
using a high-precision solver).",5. Experiments,[0],[0]
"The optimization-based approach is bolstered by appropriate initialization from the combinatorial construction.
",5. Experiments,[0],[0]
"Table 3 (right) reports the MAP measure (we additionally include WordNet results in Table 2), which is a local measure.",5. Experiments,[0],[0]
"We confirm that the combinatorial construction performs well for tree-like hierarchies, where MAP is close to 1.",5. Experiments,[0],[0]
The construction improves on approaches such as FB that rely on optimization.,5. Experiments,[0],[0]
"On larger graphs like WordNet, our approach yields a MAP of 0.989—while their WordNet MAP result is 0.870 at 200 dimensions.",5. Experiments,[0],[0]
"This is exciting, as our approach is deterministic and linear-time.
",5. Experiments,[0],[0]
A refined understanding of hyperbolic embeddings may be used to improve the quality and runtime of extant algorithms.,5. Experiments,[0],[0]
"Indeed, we embedded WordNet entity-relationship-entity triples (Socher et al., 2013) using the combinatorial construction in 10 dimensions, accurately preserving relationship knowledge (Table 4).",5. Experiments,[0],[0]
"This suggests that hyperbolic embeddings are effective at compressing knowledge and may useful for knowledge base completion and Q/A tasks.
SGD-Based Algorithm We built an SGD-based algorithm implemented in PyTorch.",5. Experiments,[0],[0]
"The loss function is equivalent to the PGA loss, and so is continuously differentiable.
",5. Experiments,[0],[0]
"To evaluate our algorithm’s ability to deal with incomplete information, we sample the distance matrix at a ratio of nonedges to edges at 10 : 1 following Nickel & Kiela (2017).",5. Experiments,[0],[0]
"In Figure 4, we recover a good solution for the phylogenetic tree with a small fraction of the entries; for example, we sampled approximately 4% of the graph for a MAP of 0.74 and distortion of 0.6.",5. Experiments,[0],[0]
We also considered learning the scale of the embedding (details in the appendix).,5. Experiments,[0],[0]
"Finally, all of our techniques scale to graphs with millions of nodes.",5. Experiments,[0],[0]
Hyperbolic embeddings embed hierarchical information with high fidelity and few dimensions.,6. Conclusion and Future Work,[0],[0]
"We explored the limits of this approach by describing scalable, high quality algorithms.",6. Conclusion and Future Work,[0],[0]
We hope the techniques here encourage more follow-on work on the exciting techniques of Nickel & Kiela (2017); Chamberlain et al. (2017).,6. Conclusion and Future Work,[0],[0]
Thanks to Alex Ratner and Avner May for helpful discussion and to Beliz Gunel and Sen Wu for assistance with experiments.,Acknowledgements,[0],[0]
"We gratefully acknowledge the support of DARPA under No. FA87501720095 and FA87501320039, ONR under No. N000141712266, the Moore Foundation, Okawa Research Grant, American Family Insurance, Accenture, Toshiba, the Secure Internet of Things Project, Google, VMware, Qualcomm, Ericsson, Analog Devices, and members of the Stanford DAWN project: Intel, Microsoft, Teradata, and VMware.",Acknowledgements,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon.,Acknowledgements,[0],[0]
"Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of DARPA, DOE, NIH, ONR, or the U.S. Government.",Acknowledgements,[0],[0]
Hyperbolic embeddings offer excellent quality with few dimensions when embedding hierarchical data structures.,abstractText,[0],[0]
We give a combinatorial construction that embeds trees into hyperbolic space with arbitrarily low distortion without optimization.,abstractText,[0],[0]
"On WordNet, this algorithm obtains a meanaverage-precision of 0.989 with only two dimensions, outperforming existing work by 0.11 points.",abstractText,[0],[0]
We provide bounds characterizing the precisiondimensionality tradeoff inherent in any hyperbolic embedding.,abstractText,[0],[0]
"To embed general metric spaces, we propose a hyperbolic generalization of multidimensional scaling (h-MDS).",abstractText,[0],[0]
"We show how to perform exact recovery of hyperbolic points from distances, provide a perturbation analysis, and give a recovery result that enables us to reduce dimensionality.",abstractText,[0],[0]
"Finally, we extract lessons from the algorithms and theory above to design a scalable PyTorch-based implementation that can handle incomplete information.",abstractText,[0],[0]
Representation Tradeoffs for Hyperbolic Embeddings,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 613–622 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1057",text,[0],[0]
Speech recognition is one of the success stories of language technology.,1 Introduction,[0],[0]
It works remarkably well in a range of practical settings.,1 Introduction,[0],[0]
"However, this success relies on the use of very heavy supervision where the machine is fed thousands of hours of painstakingly transcribed audio speech signal.",1 Introduction,[0],[0]
Humans are able to learn to recognize and understand speech from notably weaker and noisier supervision: they manage to learn to extract structure and meaning from speech by simply being exposed to utterances situated and grounded in their daily sensory experience.,1 Introduction,[0],[0]
"Modeling and emulating this remarkable skill has been the goal of numerous studies; however in the overwhelming majority of cases researchers used severely simplified settings where either the language input or the extralinguistic sensory input, or both, are small scale and symbolically represented.",1 Introduction,[0],[0]
"Section 2 provides a brief overview of this research.
",1 Introduction,[0],[0]
More recently several lines of work have moved towards more realistic inputs while modeling or emulating language acquisition in a grounded setting.,1 Introduction,[0],[0]
"Gelderloos and Chrupała (2016) use the image captioning dataset MS COCO (Lin et al., 2014) to mimic the setting of grounded language learning: the sensory input consists of images of natural scenes, while the language input are phonetically transcribed descriptions of these scenes.",1 Introduction,[0],[0]
"The use of such moderately large and low-level data allows the authors to train a multi-layer recurrent neural network model, and to explore the nature and localization of the emerging hierarchy of linguistic representations learned in the process.",1 Introduction,[0],[0]
"Furthermore, in a series of recent studies Harwath and Glass (2015); Harwath et al. (2016); Harwath and Glass (2017) use image captioning datasets to model learning to understand spoken language from visual context with convolutional neural network models.",1 Introduction,[0],[0]
"Finally, there is a small but growing body of work dedicated to elucidating the nature of representations learned by neural networks from language data (see Section 2.2 for a brief overview).",1 Introduction,[0],[0]
"In the current work we build on these three strands of research and contribute the following advances:
• We use a multi-layer gated recurrent neural network to properly model the temporal nature of speech signal and substantially improve performance compared to the convolutional architecture from Harwath and Glass (2015); • We carry out an in-depth analysis of the representations used by different components of the trained model and correlate them to representations learned by a text-based model and to human patterns of judgment on linguistic stimuli.",1 Introduction,[0],[0]
"This analysis is especially novel for a model with speech signal as input.
",1 Introduction,[0],[0]
"The general pattern of findings in our analysis is
613
as follows:",1 Introduction,[0],[0]
"The model learns to extract from the acoustic input both form-related and semanticsrelated information, and encodes it in the activations of the hidden layers.",1 Introduction,[0],[0]
Encoding of semantic aspects tends to become richer as we go up the hierarchy of layers.,1 Introduction,[0],[0]
"Meanwhile, encoding of formrelated aspects of the language input, such as utterance length or the presence of specific words, tends to initially increase and then decay.
",1 Introduction,[0],[0]
"We release the code for our models and analyses as open source, available at https://github.com/gchrupala/visually-groundedspeech.",1 Introduction,[0],[0]
"We also release a dataset of synthetically spoken image captions based on MS COCO, available at https://doi.org/10.5281/zenodo.400926.",1 Introduction,[0],[0]
Children learn to recognize and assign meaning to words from continuous perceptual data in extremely noisy context.,2 Related work,[0],[0]
"While there have been many computational studies of human word meaning acquisition, they typically make strong simplifying assumptions about the nature of the input.",2 Related work,[0],[0]
"Often language input is given in the form of word symbols, and the context consists of a set of symbols representing possible referents (e.g. Siskind, 1996; Frank et al., 2007; Fazly et al., 2010).",2 Related work,[0],[0]
"In contrast, several studies presented models that learn from sensory rather than symbolic input, which is rich with regards to the signal itself, but very limited in scale and variation (e.g. Roy and Pentland, 2002; Yu and Ballard, 2004; Lazaridou et al., 2016).",2 Related work,[0],[0]
Chrupała et al. (2015) introduce a model that learns to predict the visual context from image captions.,2.1 Multimodal language acquisition,[0],[0]
"The model is trained on image-caption pairs from MSCOCO (Lin et al., 2014), capturing both rich visual input as well as larger scale input, but the language input still consists of word symbols.",2.1 Multimodal language acquisition,[0],[0]
"Gelderloos and Chrupała (2016) propose a similar architecture that instead takes phonemelevel transcriptions as language input, thereby incorporating the word segmentation problem into the learning task.",2.1 Multimodal language acquisition,[0],[0]
"In this work, we introduce an architecture that learns from continuous speech and images directly.
",2.1 Multimodal language acquisition,[0],[0]
This work is related to research on visual grounding of language.,2.1 Multimodal language acquisition,[0],[0]
"The field is large and growing, with most work dedicated to the ground-
ing of written text, particularly in image captioning tasks (see Bernardi et al. (2016) for an overview).",2.1 Multimodal language acquisition,[0],[0]
"However, learning to ground language to visual information is also interesting from an automatic speech recognition point of view.",2.1 Multimodal language acquisition,[0],[0]
"Potentially, ASR systems could be trained from naturally co-occurring visual context information, without the need for extensive manual annotation – a particularly promising prospect for speech recognition in low-resource languages.",2.1 Multimodal language acquisition,[0],[0]
There have been several attempts along these lines.,2.1 Multimodal language acquisition,[0],[0]
Synnaeve et al. (2014) present a method of learning to recognize spoken words in isolation from cooccurrence with image fragments.,2.1 Multimodal language acquisition,[0],[0]
"Harwath and Glass (2015) present a model that learns to map pre-segmented spoken words in sequence to aspects of the visual context, while in Harwath and Glass (2017)",2.1 Multimodal language acquisition,[0],[0]
"the model also learns to recognize words in the unsegmented signal.
",2.1 Multimodal language acquisition,[0],[0]
"Most closely related to our work is that of Harwath et al. (2016), as it presents an architecture that learns to project images and unsegmented spoken captions to the same embedding space.",2.1 Multimodal language acquisition,[0],[0]
The sentence representation is obtained by feeding the spectrogram to a convolutional network.,2.1 Multimodal language acquisition,[0],[0]
"The architecture is trained on crowd-sourced spoken captions for images from the Places dataset (Zhou et al., 2014), and evaluated on image search and caption retrieval.",2.1 Multimodal language acquisition,[0],[0]
Unfortunately this dataset is not currently available and we were thus unable to directly compare the performance of our model to Harwath et al. (2016).,2.1 Multimodal language acquisition,[0],[0]
We do compare to Harwath and Glass (2015) which was tested on a public dataset.,2.1 Multimodal language acquisition,[0],[0]
"We make different architectural choices, as our models are based on recurrent highway networks (Zilly et al., 2016).",2.1 Multimodal language acquisition,[0],[0]
"As in human cognition, speech is processed incrementally.",2.1 Multimodal language acquisition,[0],[0]
This also allows our architecture to integrate information sequentially from speech of arbitrary duration.,2.1 Multimodal language acquisition,[0],[0]
"While analysis of neural methods in NLP is often limited to evaluation of the performance on the training task, recently methods have been introduced to peek inside the black box and explore what it is that enables the model to perform the task.",2.2 Analysis of neural representations,[0],[0]
"One approach is to look at the contribution of specific parts of the input, or specific units in the model, to final representations or decisions.",2.2 Analysis of neural representations,[0],[0]
"Kádár et al. (2016) propose omission scores, a method to estimate the contribution of input tokens to the fi-
nal representation by removing them from the input and comparing the resulting representations to the ones generated by the original input.",2.2 Analysis of neural representations,[0],[0]
"In a similar approach, Li et al. (2016) study the contribution of individual input tokens as well as hidden units and word embedding dimensions by erasing them from the representation and analyzing how this affects the model.
",2.2 Analysis of neural representations,[0],[0]
Miao et al. (2016) and Tang et al. (2016) use visualization techniques for fine-grained analysis of GRU and LSTM models for ASR.,2.2 Analysis of neural representations,[0],[0]
"Visualization of input and forget gate states allows Miao et al. (2016) to make informed adaptations to gated recurrent architectures, resulting in more efficiently trainable models.",2.2 Analysis of neural representations,[0],[0]
"Tang et al. (2016) visualize qualitative differences between LSTM- and GRUbased architectures, regarding the encoding of information, as well as how it is processed through time.
",2.2 Analysis of neural representations,[0],[0]
We specifically study linguistic properties of the information encoded in the trained model.,2.2 Analysis of neural representations,[0],[0]
"Adi et al. (2016) introduce prediction tasks to analyze information encoded in sentence embeddings about word order, sentence length, and the presence of individual words.",2.2 Analysis of neural representations,[0],[0]
We use related techniques to explore encoding of aspects of form and meaning within components of our stacked architecture.,2.2 Analysis of neural representations,[0],[0]
"We use a multi-layer, gated recurrent neural network (RHN) to model the temporal nature of speech signal.",3 Models,[0],[0]
"Recurrent neural networks are designed for modeling sequential data, and gated variants (GRUs, LSTMs) are widely used with speech and text in both cognitive modeling and engineering contexts.",3 Models,[0],[0]
"RHNs are a simple generalization of GRU networks such that the transform between time points can consist of several steps.
",3 Models,[0],[0]
Our multimodal model projects spoken utterances and images to a joint semantic space.,3 Models,[0],[0]
The idea of projecting different modalities to a shared semantic space via a pair of encoders has been used in work on language and vision (among them Vendrov et al. (2015)).,3 Models,[0],[0]
"The core idea is to encourage inputs representing the same meaning in different modalities to end up nearby, while maintaining a distance from unrelated inputs.
",3 Models,[0],[0]
"The model consists of two parts: an utterance encoder, and an image encoder.",3 Models,[0],[0]
"The utterance encoder starts from MFCC speech features, while
the image encoder starts from features extracted with a VGG-16 pre-trained on ImageNet.",3 Models,[0],[0]
"Our loss function attempts to make the cosine distance between encodings of matching utterances and images greater than the distance between encodings of mismatching utterance/image pairs, by a margin:
(1)
∑
u,i
(∑
u′ max[0, α+d(u, i)−d(u′, i)]
+ ∑
i′ max[0, α+ d(u, i)− d(u, i′)]
)
where d(u, i) is the cosine distance between the encoded utterance u and encoded image i. Here (u, i) is the matching utterance-image pair, u′ ranges over utterances not describing i and i′ ranges over images not described by u.",3 Models,[0],[0]
"The image encoder enci is a simple linear projection, followed by normalization to unit L2 norm:
enci(i) = unit(Ai+ b) (2)
where unit(x) = x (xT x)0.5 and with (A, b) as learned parameters.",3 Models,[0],[0]
"The utterance encoder encu consists of a 1-dimensional convolutional layer of length s, size d and stride z, whose output feeds into a Recurrent Highway Network with k layers and L microsteps, whose output in turn goes through an attention-like lookback operator, and finally L2 normalization:
encu(u) = unit(Attn(RHNk,L(Convs,d,z(u))))",3 Models,[0],[0]
"(3)
The main function of the convolutional layer Convs,d,z is to subsample the input along the temporal dimension.",3 Models,[0],[0]
We use a 1-dimensional convolution with full border mode padding.,3 Models,[0],[0]
"The attention operator simply computes a weighted sum of the RHN activation at all timesteps:
Attn(x) = ∑
t
αtxt (4)
where the weights αt are determined by learned parameters U and W, and passed through the timewise softmax function:
αt = exp(U tanh(Wxt))∑ t′ exp(U tanh(Wxt′))
(5)
",3 Models,[0],[0]
"The main component of the utterance encoder is a recurrent network, specifically a Recurrent Highway Network (Zilly et al., 2016).",3 Models,[0],[0]
"The idea behind
RHN is to increase the depth of the transform between timesteps, or the recurrence depth.",3 Models,[0],[0]
Otherwise they are a type of gated recurrent networks.,3 Models,[0],[0]
"The transition from timestep t − 1 to t is then defined as:
rhn(xt, s (L) t−1) = s (L) t (6)
where xt stands for input at time t, and s (l) t denotes the state at time t at recurrence layer l, with L being the top layer of recurrence.",3 Models,[0],[0]
"Furthermore,
s (l) t = h (l) t t (l) t + s (l−1) t ( 1− t(l)t ) (7)
where is elementwise multiplication, and
h (l) t = tanh ( I[l = 1]WHxt +UHls (l−1) t ) (8)
t (l) t = σ",3 Models,[0],[0]
"( I[l = 1]WTxt +UTls (l−1) )
(9)
",3 Models,[0],[0]
Here I is the indicator function: input is only included in the computation for the first layer of recurrence l = 1.,3 Models,[0],[0]
"By applying the rhn function repeatedly, an RHN layer maps a sequence of inputs to a sequence of states:
(10) RHN(X, s0)
= rhn(xn, . . .",3 Models,[0],[0]
", rhn(x2, rhn(x1, s (L) 0 )))
",3 Models,[0],[0]
"Two or more RHN layers can be composed into a stack:
RHN2(RHN1(X, s1 (L) 0 ), s2 (L) 0 ), (11)
where sn (l) t stands for the state vector of layer n of the stack, at layer l of recurrence, at time t.",3 Models,[0],[0]
"In our version of the Stacked RHN architecture we use residualized layers:
RHNres(X, s0) = RHN(X, s0) +X (12)
",3 Models,[0],[0]
This formulation tends to ease optimization in multi-layer models (cf.,3 Models,[0],[0]
"He et al., 2015; Oord et al., 2016).
",3 Models,[0],[0]
"In addition to the speech model described above, we also define a comparable text model.",3 Models,[0],[0]
"As it takes a sequence of words as input, we replace the convolutional layer with a word embedding lookup table.",3 Models,[0],[0]
"We found the text model did not benefit from the use of the attention mechanism, and thus the sentence embedding is simply the L2-normalized activation vector of the topmost layer, at the last timestep.",3 Models,[0],[0]
Our main goal is to analyze the emerging representations from different components of the model and to examine the linguistic knowledge they encode.,4 Experiments,[0],[0]
"For this purpose, we employ a number of tasks that cover the spectrum from fully formbased to fully semantic.
",4 Experiments,[0],[0]
In Section 4.2 we assess the effectiveness of our architecture by evaluating it on the task of ranking images given an utterance.,4 Experiments,[0],[0]
Sections 4.3 to 4.6 present our analyses.,4 Experiments,[0],[0]
In Sections 4.3 and 4.4 we define auxiliary tasks to investigate to what extent the network encodes information about the surface form of an utterance from the speech input.,4 Experiments,[0],[0]
In Section 4.5 and 4.6 we focus on where semantic information is encoded in the model.,4 Experiments,[0],[0]
"In the analyses, we use the following features: Utterance embeddings: the weighted sum of the
unit activations on the last layer, as calculated by Equation (3).
",4 Experiments,[0],[0]
Average unit activations: hidden layer activations averaged over time and L2-normalized for each hidden layer.,4 Experiments,[0],[0]
Average input vectors: the MFCC vectors averaged over time.,4 Experiments,[0],[0]
We use this feature to examine how much information can be extracted from the input signal only.,4 Experiments,[0],[0]
For the experiments reported in the remainder of the paper we use two datasets of images with spoken captions.,4.1 Data,[0],[0]
"The Flickr8k Audio Caption Corpus was constructed by having crowdsource workers read aloud the captions in the original Flickr8K corpus (Hodosh et al., 2013).",4.1.1 Flickr8K,[0],[0]
For details of the data collection procedure refer to Harwath and Glass (2015).,4.1.1 Flickr8K,[0],[0]
"The datasets consist of 8,000 images, each image with five descriptions.",4.1.1 Flickr8K,[0],[0]
"One thousand images are held out for validation, and another one thousand for the final test set.",4.1.1 Flickr8K,[0],[0]
"We use the splits provided by (Karpathy and Fei-Fei, 2015).",4.1.1 Flickr8K,[0],[0]
"The image features come from the final fully connect layer of VGG-16 (Simonyan and Zisserman, 2014) pre-trained on Imagenet (Russakovsky et al., 2014).
",4.1.1 Flickr8K,[0],[0]
We generate the input signal as follows: we extract 12-dimensional mel-frequency cepstral coefficients (MFCC) plus log of the total energy.,4.1.1 Flickr8K,[0],[0]
"We
then compute and add first order and second order differences (deltas) for a total of 37 dimensions.",4.1.1 Flickr8K,[0],[0]
"We use 25 milisecond windows, sampled every 10 miliseconds.1",4.1.1 Flickr8K,[0],[0]
"We generated synthetic speech for the captions in the MS COCO dataset (Lin et al., 2014) via the Google Text-to-Speech API.2 The audio and the corresponding MFCC features are released as Chrupała et al. (2017)3.",4.1.2 Synthetically spoken COCO,[0],[0]
This TTS system we used produces high-quality realistic-sounding speech.,4.1.2 Synthetically spoken COCO,[0],[0]
"It is nevertheless much simpler than real human speech as it uses a single voice, and lacks tempo variation or ambient noise.",4.1.2 Synthetically spoken COCO,[0],[0]
"The data consists of over 300,000 images, each with five spoken captions.",4.1.2 Synthetically spoken COCO,[0],[0]
Five thousand images each are held out for validation and test.,4.1.2 Synthetically spoken COCO,[0],[0]
"We use the splits and image features provided by Vendrov et al. (2015).4 The image features also come from the VGG-16 network, but are averages of feature vectors for ten crops of each image.",4.1.2 Synthetically spoken COCO,[0],[0]
"For the MS COCO captions we extracted only plain MFCC and total energy features, and did not add deltas in order to keep the amount of computation manageable given the size of the dataset.",4.1.2 Synthetically spoken COCO,[0],[0]
"We evaluate our model on the task of ranking images given a spoken utterance, such that highly ranked images contain scenes described by the utterance.",4.2 Image retrieval,[0],[0]
The performance on this task on validation data is also used to choose the best variant of the model architecture and to tune the hyperparameters.,4.2 Image retrieval,[0],[0]
We compare the speech models to models trained on written sentences split into words.,4.2 Image retrieval,[0],[0]
"The best settings found for the four models were the following: Flickr8K Text RHN 300-dimensional word em-
beddings, 1 hidden layer with 1024 dimensions, 1 microstep, initial learning rate 0.001.
",4.2 Image retrieval,[0],[0]
"Flick8K Speech RHN convolutional layer with length 6, size 64, stride 2, 4 hidden layers with 1024 dimensions, 2 microsteps, atten-
1We noticed that for a number of utterances the audio signal was very long: on inspection it turned out that most of these involved failure to switch off the microphone on the part of the workers, and the audio contained ambient noise or unrelated speech.",4.2 Image retrieval,[0],[0]
"We thus trucated all audio for this dataset at 10,000 miliseconds.
2Available at https://github.com/pndurette/gTTS.",4.2 Image retrieval,[0],[0]
3Available at https://doi.org/10.5281/zenodo.400926.,4.2 Image retrieval,[0],[0]
"4See https://github.com/ivendrov/order-embedding.
tion MLP with 128 hidden units, initial learning rate 0.0002
COCO Text RHN 300-dimensional word embeddings, 1 hidden layer with 1024 dimensions, 1 microstep, initial learning rate 0.001 COCO Speech RHN convolutional layer with length 6, size 64, stride 3, 5 hidden layers with 512 dimensions, 2 microsteps, attention MLP with 512 hidden units, initial learning rate 0.0002
All models were optimized with Adam (Kingma and Ba, 2014) with early stopping: we kept the parameters for the epoch which showed the best recall@10 on validation data.
",4.2 Image retrieval,[0],[0]
Table 1 shows the results for the human speech from the Flickr8K dataset.,4.2 Image retrieval,[0],[0]
The Speech RHN model scores substantially higher than model of Harwath and Glass (2015) on the same data.,4.2 Image retrieval,[0],[0]
However the large gap between its perfomance and the scores of the text model suggests that Flickr8K is rather small for the speech task.,4.2 Image retrieval,[0],[0]
In Table 2 we present the results on the dataset of synthetic speech from MS COCO.,4.2 Image retrieval,[0],[0]
"Here the text model is still better, but the gap is much smaller than for Flickr8K. We attribute this to the much larger size of dataset, and to the less noisy and less variable synthetic speech.
",4.2 Image retrieval,[0],[0]
"While the MS COCO text model is overall better than the speech model, there are cases where it outperforms the text model.",4.2 Image retrieval,[0],[0]
"We listed the top hundred cases where the ratio of the ranks of the correct image according to the two models was the smallest, as well as another hundred cases where it was the largest.",4.2 Image retrieval,[0],[0]
"Manual inspection did not turn
up any obvious patterns for the cases of text being better than speech.",4.2 Image retrieval,[0],[0]
"For the cases where speech outperformed text, two patterns stood out: (i) sentences with spelling mistakes, (ii) unusually long sentences.",4.2 Image retrieval,[0],[0]
"For example for the sentence a yellow
and white birtd is in flight the text model misses the misspelled word birtd and returns an irrelevant image, while the speech model seems robust to some degree of variation in pronunciation and returns the target image at rank 1 (see Figure 1).",4.2 Image retrieval,[0],[0]
"In an attempt to quantify this effect we counted the number of unique words with training set frequencies below 5 in the top 100 utterances with lowest and highest rank ratio: for the utterances where text was better there were 16 such words; for utterances where speech was better there were 28, among them misspellings such as streeet, scears (for skiers), contryside, scull, birtd, devise.
",4.2 Image retrieval,[0],[0]
The distribution of utterance lengths in Figure 2 confirms pattern (ii): the set of 100 sentences where speech beats text by a large margin are longer on average and there are extremely long outliers among them.,4.2 Image retrieval,[0],[0]
"One of them is the 36-word-
long utterance depicted in Figure 3, with ranks 470 and 2 for text and speech respectively.",4.2 Image retrieval,[0],[0]
"We suspect that the speech model’s attention mechanism enables it to cherry pick key fragments of such monster utterances, while the text model lacking this mechanism may struggle.",4.2 Image retrieval,[0],[0]
"Figure 3 shows the plot of the attention weights for this utterance from the
speech model.",4.2 Image retrieval,[0],[0]
"Our first auxiliary task is to predict the length of the utterance, using the features explained at the beginning of Section 4.",4.3 Predicting utterance length,[0],[0]
"Since the length of an utterance directly corresponds to how long it takes to articulate, we also use the number of time steps5 as a feature and expect it to provide the upper bound for our task, especially for synthetic speech.",4.3 Predicting utterance length,[0],[0]
We use a Ridge Regression model for predicting utterance length using each set of features.,4.3 Predicting utterance length,[0],[0]
"The model is trained on 80% of the sentences in the validation set, and tested on the remaining 20%.",4.3 Predicting utterance length,[0],[0]
"For all features regularization penalty α = 1.0 gave the best results.
",4.3 Predicting utterance length,[0],[0]
Figure 4 shows the results for this task on human speech from Flickr8K and synthetic speech from COCO.,4.3 Predicting utterance length,[0],[0]
"With the exception of the average input vectors for Flickr8K, all features can explain a high proportion of variance in the predicted utterance length.",4.3 Predicting utterance length,[0],[0]
"The pattern observed for the two datasets is slightly different: due to the systematic conversion of words to synthetic speech in COCO, using the number of time steps for this dataset yields the highest R2.",4.3 Predicting utterance length,[0],[0]
"However, this feature is not as informative for predicting the utterance length in Flickr8K due to noise and variation in human speech, and is in fact outperformed by some of the features extracted from the model.",4.3 Predicting utterance length,[0],[0]
"Also, the input vectors from COCO are much more informative than Flickr8K due to larger quantity and simpler structure of the speech signal.",4.3 Predicting utterance length,[0],[0]
"However, in both datasets the best (non-ceiling) performance is obtained by using average unit activations from the hidden layers (layer 2 for COCO, and layers 3 and 4 for Flickr8K).",4.3 Predicting utterance length,[0],[0]
"These features outperform utterance embeddings, which are optimized according to the visual grounding objective of the model and most probably learn to ignore the superficial characteristics of the utterance that do not contribute to matching the corresponding image.
",4.3 Predicting utterance length,[0],[0]
"Note that the performance on COCO plateaus after the second layer, which might suggest that form-based knowledge is learned by lower layers.",4.3 Predicting utterance length,[0],[0]
"Since Flickr8K is much smaller in size, the stabilising happens later in layer 3.
",4.3 Predicting utterance length,[0],[0]
5This is approximately duration in milliseconds 10×stride .,4.3 Predicting utterance length,[0],[0]
Results from the previous experiment suggest that our model acquires information about higher level building blocks (words) in the continuous speech signal.,4.4 Predicting word presence,[0],[0]
Here we explore whether it can detect the presence or absence of individual words in an utterance.,4.4 Predicting word presence,[0],[0]
"We formulate detecting a word in an utterance as a binary classification task, for which we use a multi-layer perceptron with a single hidden layer of size 1024, optimized by Adam.",4.4 Predicting word presence,[0],[0]
The input to the model is a concatenation of the feature vector representing an utterance and the one representing a target word.,4.4 Predicting word presence,[0],[0]
"We again use utterance embeddings, average unit activations on each layer, and average input vectors as features, and represent each target word as a vector of MFCC features extracted from the audio signal synthetically produced for that word.
",4.4 Predicting word presence,[0],[0]
"For each utterance in the validation set, we randomly pick one positive and one negative target (i.e., one word that does and one that does not appear in the utterance) that is not a stop word.",4.4 Predicting word presence,[0],[0]
"To balance the probability of a word being positive or negative, we use each positive target as a negative target for another utterance in the validation
set.",4.4 Predicting word presence,[0],[0]
"The MLP model is trained on the positive and negative examples corresponding to 80% of the utterances in the validation set of each dataset, and evaluated on the remaining 20%.
",4.4 Predicting word presence,[0],[0]
Figure 5 shows the mean accuracy of the MLP on Flickr8K and COCO.,4.4 Predicting word presence,[0],[0]
"All results using features extracted from the model are above chance (0.5), with the average unit activations of the hidden layers yielding the best results (0.65 for Flickr8K on layer 3, and 0.79 for COCO on layer 4).",4.4 Predicting word presence,[0],[0]
These numbers show that the speech model infers reliable information about word-level blocks from the low-level audio features it receives as input.,4.4 Predicting word presence,[0],[0]
"The observed trend is similar to the previous task: average unit activations on the higher-level hidden layers are more informative for this task than the utterance embeddings, but the performance plateaus before the topmost layer.",4.4 Predicting word presence,[0],[0]
Next we explore to what extent the model’s representations correspond to those of humans.,4.5 Sentence similarity,[0],[0]
"We employ the Sentences Involving Compositional Knowledge (SICK) dataset (Marelli et al., 2014).",4.5 Sentence similarity,[0],[0]
"SICK consists of image descriptions taken from
Flickr8K and video captions from the SemEval 2012 STS MSRVideo Description data set (STS) (Agirre et al., 2012).",4.5 Sentence similarity,[0],[0]
"Captions were paired at random, as well as modified to obtain semantically similar and contrasting counterparts, and the resulting pairs were rated for semantic similarity.
",4.5 Sentence similarity,[0],[0]
"For all sentence pairs in SICK, we generate synthetic spoken sentences and feed them to the COCO Speech RHN, and calculate the cosine similarity between the averaged MFCC input vectors, the averaged hidden layer activation vectors, and the sentence embeddings.",4.5 Sentence similarity,[0],[0]
Z-score transformation was applied before calculating the cosine similarities.,4.5 Sentence similarity,[0],[0]
"We then correlate these cosine similarities with
• semantic relatedness according to human ratings • cosine similarities according to z-score transformed embeddings from COCO Text RHN • edit similarities, a measure of how similar the sentences are in form, specifically, 1−normalized Levenshtein distance over character sequences
Figure 6 shows a boxplot over 10,000 bootstrap samples for all correlations.",4.5 Sentence similarity,[0],[0]
"We observe that (i) correlation with edit similarity initially increases, then decreases; (ii) correlation with human relatedness scores and text model embeddings increases until layer 4, but decreases for hidden layer 5.",4.5 Sentence similarity,[0],[0]
The initially increasing and then decreasing correlation with edit similarity is consistent with the findings that information about form is encoded by lower layers.,4.5 Sentence similarity,[0],[0]
"The overall growing correlation with both human semantic similarity ratings and
the COCO Text RHN indicate that higher layers learn to represent semantic knowledge.",4.5 Sentence similarity,[0],[0]
We were somewhat surprised by the pattern for the correlation with human ratings and the Text model similarities which drops for layer 5.,4.5 Sentence similarity,[0],[0]
We suspect it may be caused by the model at this point in the layer hierarchy being strongly tuned to the specifics of the COCO dataset.,4.5 Sentence similarity,[0],[0]
"To test this, we checked the correlations with COCO Text embeddings on validation sentences from the COCO dataset instead of SICK.",4.5 Sentence similarity,[0],[0]
"These increased monotonically, in support of our conjecture.",4.5 Sentence similarity,[0],[0]
"Next we simulate the task of distinguishing between pairs of homonyms, i.e. words with the same acoustic form but different meaning.",4.6 Homonym disambiguation,[0],[0]
We group the words in the union of the training and validation data of the COCO dataset by their phonetic transcription.,4.6 Homonym disambiguation,[0],[0]
"We then pick pairs of words which have the same pronunciation but different spelling, for example suite/sweet.",4.6 Homonym disambiguation,[0],[0]
"We impose the following conditions: (a) both forms appear more than 20 times, (b) the two forms have different meaning (i.e. they are not simply variant spellings like theater/theatre), (c) neither form is a function word, and (d) the more frequent form constitutes less than 95% of the occurrences.",4.6 Homonym disambiguation,[0],[0]
"This
gives us 34 word pairs.",4.6 Homonym disambiguation,[0],[0]
"For each pair we generate a binary classification task by taking all the utterances where either form appears, using average input vectors, utterance embeddings, and average unit activations as features.",4.6 Homonym disambiguation,[0],[0]
"Instances for all feature sets are normalized to unit L2 norm.
",4.6 Homonym disambiguation,[0],[0]
For each task and feature set we run stratified 10-fold cross validation using Logistic Regression to predict which of the two words the utterance contains.,4.6 Homonym disambiguation,[0],[0]
"Figure 7 shows, for each pair, the relative error reduction of each feature set with respect to the majority baseline.",4.6 Homonym disambiguation,[0],[0]
"There is substantial variation across word pairs, but overall the task becomes easier as the features come from higher layers in the network.",4.6 Homonym disambiguation,[0],[0]
"Some forms can be disambiguated with very high accuracy (e.g. sale/sail, cole/coal, pairs/pears), while some others cannot be distinguished at all (peaking/peeking, great/grate, mantle/mantel).",4.6 Homonym disambiguation,[0],[0]
"We examined the sentences containing the failing forms, and found out that almost all occurrences of peaking and mantle were misspellings of peeking and mantel, which explains the impossibility of disambiguating these cases.",4.6 Homonym disambiguation,[0],[0]
We present a multi-layer recurrent highway network model of language acquisition from visually grounded speech signal.,5 Conclusion,[0],[0]
"Through detailed analysis we uncover how information in the input signal is transformed as it flows through the network: formal aspects of language such as word identities that not directly present in the input are discovered and encoded low in the layer hierarchy, while semantic information is most strongly expressed in the topmost layers.
",5 Conclusion,[0],[0]
Going forward we would like to compare the representations learned by our model to the brain activity of people listening to speech in order to determine to what extent the patterns we found correspond to localized processing in the human cortex.,5 Conclusion,[0],[0]
This will hopefully lead to a better understanding of language learning and processing by both artificial and neural networks.,5 Conclusion,[0],[0]
We would like to thank David Harwath for making the Flickr8k Audio Caption Corpus publicly available.,Acknowledgements,[0],[0]
We present a visually grounded model of speech perception which projects spoken utterances and images to a joint semantic space.,abstractText,[0],[0]
"We use a multi-layer recurrent highway network to model the temporal nature of spoken speech, and show that it learns to extract both form and meaningbased linguistic knowledge from the input signal.",abstractText,[0],[0]
"We carry out an in-depth analysis of the representations used by different components of the trained model and show that encoding of semantic aspects tends to become richer as we go up the hierarchy of layers, whereas encoding of formrelated aspects of the language input tends to initially increase and then plateau or decrease.",abstractText,[0],[0]
Representations of language in a model of visually grounded speech signal,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1499–1509, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
Representing information about real-world entities and their relations in structured knowledge base (KB) form enables numerous applications.,1 Introduction,[0],[0]
"Large, collaboratively created knowledge bases have recently become available e.g., Freebase (Bollacker et al., 2008), YAGO (Suchanek et al., 2007), and DBPedia (Auer et al., 2007), but even though they are impressively large, their coverage is far from complete.",1 Introduction,[0],[0]
"This has motivated research in automatically deriving new facts to extend a manually built knowledge base, by using information from the existing knowledge base, textual mentions of entities, and semi-structured data such as tables and web forms (Nickel et al., 2015).
",1 Introduction,[0],[0]
"In this paper we build upon the work of Riedel et al. (2013), which jointly learns continuous representations for knowledge base and textual relations.",1 Introduction,[0],[0]
"This common representation in the same vector space can serve as a kind of “universal schema” which admits joint inferences among
∗This research was conducted during the author’s internship at Microsoft Research.
KBs and text.",1 Introduction,[0],[0]
The textual relations represent the relationships between entities expressed in individual sentences (see Figure 1 for an example).,1 Introduction,[0],[0]
Riedel et al. (2013) represented each textual mention of an entity pair by the lexicalized dependency path between the two entities (see Figure 2).,1 Introduction,[0],[0]
Each such path is treated as a separate relation in a combined knowledge graph including both KB and textual relations.,1 Introduction,[0],[0]
"Following prior work in latent feature models for knowledge base completion, every textual relation receives its own continuous representation, learned from the pattern of its co-occurrences in the knowledge graph.
",1 Introduction,[0],[0]
"However, largely synonymous textual relations often share common sub-structure, and are composed of similar words and dependency arcs.",1 Introduction,[0],[0]
"For example, Table 1 shows a collection of dependency paths co-occurring with the person/organizations founded relation.
",1 Introduction,[0],[0]
"In this paper we model this sub-structure and share parameters among related dependency paths, using a unified loss function learning entity and relation representations to maximize performance on the knowledge base link prediction task.
",1 Introduction,[0],[0]
"We evaluate our approach on the FB15k-237 dataset, a knowledge base derived from the Free-
1499
base subset FB15k (Bordes et al., 2013) and filtered to remove highly redundant relations (Toutanova and Chen, 2015).",1 Introduction,[0],[0]
"The knowledge base is paired with textual mentions for all entity pairs derived from ClueWeb121 with Freebase entity mention annotations (Gabrilovich et al., 2013).
",1 Introduction,[0],[0]
"We show that using a convolutional neural network to derive continuous representations for textual relations boosts the overall performance on link prediction, with larger improvement on entity pairs that have textual mentions.",1 Introduction,[0],[0]
There has been a growing body of work on learning to predict relations between entities without requiring sentence-level annotations of textual mentions at training time.,2 Related Work,[0],[0]
"We group such related work into three groups based on whether KB, text, or both sources of information are used.",2 Related Work,[0],[0]
"Additionally, we discuss related work in the area of supervised relation extraction using continuous representations of text, even though we do not use supervision at the level of textual mentions.",2 Related Work,[0],[0]
"Nickel et al. (2015) provide a broad overview of machine learning models for knowledge graphs, including models based on observed graph features such as the path ranking algorithm (Lao et al., 2011), models based on continuous representations (latent features), and model combinations (Dong et al., 2014).",Knowledge base completion,[0],[0]
"These models predict new facts in a given knowledge base, based on information from existing entities and relations.",Knowledge base completion,[0],[0]
"From this line of work, most relevant to our study is prior work evaluating continuous representation models on the FB15k dataset.",Knowledge base completion,[0],[0]
"Yang et al. (2015) showed that a simple variant of a bilinear model DISTMULT outperformed TRANSE (Bordes et al., 2013) and more richly parameterized models on this dataset.",Knowledge base completion,[0],[0]
"We therefore build upon the best performing prior model DISTMULT from this line of work, as well as additional models E and F developed in the context of text-augmented knowledge graphs (Riedel et al., 2013), and extend them to incorporate compositional representations of textual relations.
",Knowledge base completion,[0],[0]
"1http://lemurproject.org/clueweb12/ FACC1/
Relation extraction using distant supervision
A number of works have focused on extracting new instances of relations using information from textual mentions, without sophisticated modeling of prior knowledge from the knowledge base.",Knowledge base completion,[0],[0]
"Mintz et al. (2009) demonstrated that both surface context and dependency path context were helpful for the task, but did not model the compositional sub-structure of this context.",Knowledge base completion,[0],[0]
"Other work proposed more sophisticated models that reason about sentence-level hidden variables (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) or model the noise arising from the incompleteness of knowledge bases and text collections (Ritter et al., 2013), inter alia.",Knowledge base completion,[0],[0]
"Our work focuses on representing the compositional structure of sentential context for learning joint continuous representations of text and knowledge bases.
",Knowledge base completion,[0],[0]
"Combining knowledge base and text information
A combination of knowledge base and textual information was first shown to outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012).",Knowledge base completion,[0],[0]
"To alleviate the sparsity of textual relations arising in such a combined graph, (Gardner et al., 2013; Gardner et al., 2014) showed how to incorporate clusters or continuous representations of textual relations.",Knowledge base completion,[0],[0]
Note that these vector representations are based on the co-occurrence patterns for the textual relations and not on their compositional structure.,Knowledge base completion,[0],[0]
"Cooccurrence based textual relation representations were also learned in (Neelakantan et al., 2015).",Knowledge base completion,[0],[0]
"Wang et al. (2014a) combined knowledge base and text information by embedding knowledge base entities and the words in their names in the same vector space, but did not model the textual cooccurrences of entity pairs and the expressed textual relations.",Knowledge base completion,[0],[0]
Weston et al. (2013) combined continuous representations from a knowledge base and textual mentions for prediction of new relations.,Knowledge base completion,[0],[0]
"The two representations were trained independently of each other and using different loss functions, and were only combined at inference time.",Knowledge base completion,[0],[0]
"Additionally, the employed representations of text were non-compositional.
",Knowledge base completion,[0],[0]
"In this work we train continuous representations of knowledge base and textual relations jointly, which allows for deeper interactions between the
sources of information.",Knowledge base completion,[0],[0]
"We directly build on the universal schema approach of Riedel et al. (2013) as well as the universal schema extension of the DISTMULT model mentioned previously, to improve the representations of textual relations by capturing their compositional structure.",Knowledge base completion,[0],[0]
"Additionally, we evaluate the approach on a dataset that contains rich prior information from the training knowledge base, as well as a wealth of textual information from a large document collection.
",Knowledge base completion,[0],[0]
"Continuous representations for supervised relation extraction
In contrast to the work reviewed so far, work on sentence-level relation extraction using direct supervision has focused heavily on representing sentence context.",Knowledge base completion,[0],[0]
"Models using hand-crafted features have evolved for more than a decade, and recently, models using continuous representations have been found to achieve new state-of-the-art performance (Zeng et al., 2014; Gormley et al., 2015).",Knowledge base completion,[0],[0]
"Compared to work on representation learning for sentence-level context, such as this recent work using LSTM models on constituency or dependency trees (Tai et al., 2015), our approach using a one-hidden-layer convolutional neural network is relatively simple.",Knowledge base completion,[0],[0]
"However, even such a simple approach has been shown to be very competitive (Kim, 2014).",Knowledge base completion,[0],[0]
"We begin by introducing notation to define the task, largely following the terminology in Nickel et al. (2015).",3 Models for knowledge base completion,[0],[0]
"We assume knowledge bases are represented using RDF triples, in the form (subject, predicate, object), where the subject and object are entities and the predicate is the type of relation.",3 Models for knowledge base completion,[0],[0]
"For example, the KB fragment shown in Figure 1 is shown as a knowledge graph, where the entities are the nodes, and the relations are shown as directed labeled edges: we see three entities participating in three relation instances indicated by the edges.",3 Models for knowledge base completion,[0],[0]
"For brevity, we will denote triples by (es, r, eo), where es and eo denote the subject and object entities, respectively.
",3 Models for knowledge base completion,[0],[0]
"The task is, given a training KB consisting of entities with some relations between them, to predict new relations (links) that do not appear in the training KB.",3 Models for knowledge base completion,[0],[0]
"More specifically, we will build models that rank candidate entities for given queries (es, r, ?) or (?, r, eo), which ask about the object
1
or subject of a given relation.",3 Models for knowledge base completion,[0],[0]
"This task setting has been used in models for KB completion previously, e.g. (Dong et al., 2014; Gardner et al., 2014), even though it has not been standard in evaluations of distant supervision for relation extraction (Mintz et al., 2009; Riedel et al., 2013).",3 Models for knowledge base completion,[0],[0]
"The advantage of this evaluation setting is that it enables automatic evaluation without requiring humans to label candidate extractions, while making only a local closed world assumption for the completeness of the knowledge base — i.e., if one object eo for a certain subject / relation pair (es, r) is present in the knowledge base, it is assumed likely that all other objects (es, r, e′o) will be present.",3 Models for knowledge base completion,[0],[0]
"Such an assumption is particularly justified for nearly functional relations.
",3 Models for knowledge base completion,[0],[0]
"To incorporate textual information, we follow prior work (Lao et al., 2012; Riedel et al., 2013) and represent both textual and knowledge base relations in a single graph of “universal” relations.",3 Models for knowledge base completion,[0],[0]
"The textual relations are represented as full lexicalized dependency paths, as illustrated in Figure 2.",3 Models for knowledge base completion,[0],[0]
"An instance of the textual relation SUBJECT nsubj←−−− president prep−−→ of obj−→OBJECT connecting the entities BARACK OBAMA and UNITED STATES, is added to the knowledge graph based on this sentential occurrence.
",3 Models for knowledge base completion,[0],[0]
"To present the models for knowledge base completion based on such combined knowledge graphs, we first introduce some notation.",3 Models for knowledge base completion,[0],[0]
Let E denote the set of entities in the knowledge graph and let R denote the set of relation types.,3 Models for knowledge base completion,[0],[0]
"We denote each possible triple as T = (es, r, eo) where es, eo ∈ E , r ∈ R, and model its presence with a binary random variable yT ∈ {0, 1} which indicates whether the triple exists.",3 Models for knowledge base completion,[0],[0]
"The models we build score possible triples (es, r, eo) using continuous representations (latent features) of the three elements of the triple.",3 Models for knowledge base completion,[0],[0]
"The models use scoring function f(es, r, eo) to represent the model’s confidence in the existence of the triple.",3 Models for knowledge base completion,[0],[0]
"We present the models and then the loss function used to train
1
their parameters.",3 Models for knowledge base completion,[0],[0]
We begin with presenting the three models from prior work that this research builds upon.,3.1 Basic Models,[0],[0]
"They all learn latent continuous representations of relations and entities or entity pairs, and score possible triples based on the learned continuous representations.",3.1 Basic Models,[0],[0]
"Each of the models can be defined on a knowledge graph containing entities and KB relations only, or on a knowledge graph additionally containing textual relations.",3.1 Basic Models,[0],[0]
"We use models F and E from (Riedel et al., 2013) where they were used for a combined KB+text graph, and model DISTMULT from (Yang et al., 2015), which was originally used for a knowledge graph containing only KB relations.
",3.1 Basic Models,[0],[0]
"As shown in Figure 3, model F learns a Kdimensional latent feature vector for each candidate entity pair (es, eo), as well as a samedimensional vector for each relation r, and the scoring function is simply defined as their inner product: f(es, r, eo) = v(r)ᵀv(es, eo).",3.1 Basic Models,[0],[0]
"Therefore, different pairs sharing the same entity would not share parameters in this model.
",3.1 Basic Models,[0],[0]
"Model E does not have parameters for entity pairs, and instead has parameters for individual entities.",3.1 Basic Models,[0],[0]
"It aims to capture the compatibility be-
tween entities and the subject and object positions of relations.",3.1 Basic Models,[0],[0]
"For each relation type r, the model learns two latent feature vectors v(rs) and v(ro) of dimension K. For each entity (node) ei, the model also learns a latent feature vector of the same dimensionality.",3.1 Basic Models,[0],[0]
"The score of a candidate triple (es, r, eo) is defined as f(es, r, eo) = v(rs)ᵀv(es) + v(ro)ᵀv(eo).",3.1 Basic Models,[0],[0]
"It can be seen that when a subject entity is fixed in a query (es, r, ?), the ranking of candidate object entity fillers according to f does not depend on the subject entity but only on the relation type r.
The third model DISTMULT, is a special form of a bilinear model like RESCAL (Nickel et al., 2011), where the non-diagonal entries in the relation matrices are assumed to be zero.",3.1 Basic Models,[0],[0]
This model was proposed in Yang et al. (2015) and was shown to outperform prior work on the FB15k dataset.,3.1 Basic Models,[0],[0]
"In this model, each entity ei and each relation r is assigned a latent feature vector of dimensionK. The score of a candidate triple (es, r, eo) is defined as f(es, r, eo)",3.1 Basic Models,[0],[0]
"= v(r)ᵀ (v(es) ◦ v(eo)), where ◦ denotes the element-wise vector product.",3.1 Basic Models,[0],[0]
"In this model, entity pairs which share an entity also share parameters, and the ranking of candidate objects for queries (es, r, ?) depends on the subject entity.
",3.1 Basic Models,[0],[0]
"Denote Ne = |E|, Nr = |R|, and K = dimension of latent feature vectors, then model E has KNe +",3.1 Basic Models,[0],[0]
2KNr parameters and model DISTMULT has KNe + KNr parameters.,3.1 Basic Models,[0],[0]
"Model F has KN2e + KNr parameters, although most entity pairs will not co-occur in the knowledge base or text.
",3.1 Basic Models,[0],[0]
"In the basic models, knowledge base and textual relations are treated uniformly, and each textual relation receives its own latent representation of dimensionality K. When textual relations are added to the training knowledge graph, the total number of relations |R| grows substantially (it increases from 237 to more than 2.7 million for the dataset in this study), resulting in a substantial increase in the total number of independent parameters.
",3.1 Basic Models,[0],[0]
"Note that in all of these models queries about the arguments of knowledge base relations (es, r, ?) are answered by scoring functions looking only at the entity and KB relation representations, without using representations of textual mentions.",3.1 Basic Models,[0],[0]
The textual mention information and representations are only used at training time to improve the learned representations of KB relations and entities.,3.1 Basic Models,[0],[0]
"In the standard latent feature models discussed above, each textual relation is treated as an atomic unit receiving its own set of latent features.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"However, many textual relations differ only slightly in the words or dependency arcs used to express the relation.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"For example, Table 1 shows several textual patterns that co-occurr with the relation person/organizations founded in the training KB.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"While some dependency paths occur frequently, many very closely related ones have been observed only once.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
The statistical strength of the model could be improved if similar dependency paths have a shared parameterization.,3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"We build on work using similar intuitions for other tasks and learn compositional representations of textual relations based on their internal structure, so that the derived representations are accurate for the task of predicting knowledge base relations.
",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
We use a convolutional neural network applied to the lexicalized dependency paths treated as a sequence of words and dependency arcs with direction.,3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
Figure 4 depicts the neural network architecture.,3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"In the first layer, each word or directed labeled arc is mapped to a continuous representation using an embedding matrix V. In the hidden layer, every window of three elements is mapped to a hidden vector using position-specific maps W, a bias vector b, and a tanh activation function.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"A max-pooling operation over the sequence is applied to derive the final continuous representation for the dependency path.
",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
The CONV representation of textual relations can be used to augment any of the three basic models.,3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
The difference between a basic model and its CONV-augmented variant is in the parameterization of textual mentions.,3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"The basic models learn distinct latent feature vectors of dimensionality K for all textual relation types, whereas the CONV models derive the K-dimensional latent feature vectors for textual relation types as the activation at the top layer of the convolutional network in Figure 4, given the corresponding lexicalized dependency path as input.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
All basic and CONV-augmented models use the same training loss function.,3.3 Training loss function,[0],[0]
Our loss function is motivated by the link prediction task and the performance measures used.,3.3 Training loss function,[0],[0]
"As previously men-
tioned, the task is to predict the subject or object entity for given held-out triples (es, r, eo), i.e., to rank all entities with respect to their likelihood of filling the respective position in the triple2.",3.3 Training loss function,[0],[0]
"We would thus like the model to score correct triples (es, r, eo) higher than incorrect triples (e′, r, eo) and (es, r, e′) which differ from the correct triple by one entity.",3.3 Training loss function,[0],[0]
"Several approaches (Nickel et al., 2015) use a margin-based loss function.",3.3 Training loss function,[0],[0]
We use an approximation to the negative loglikelihood of the correct entity filler instead3.,3.3 Training loss function,[0],[0]
"We define the conditional probabilities p(eo|es, r) and p(es|r, eo) for object and subject entities given the relation and the other argument as follows:
p(eo|es, r; Θ) = e f(es,r,eo;Θ)∑
e′∈Neg(es,r,?)",3.3 Training loss function,[0],[0]
"e f(es,r,e′;Θ)
",3.3 Training loss function,[0],[0]
"Conditional probabilities for subject entities p(es|eo, r; Θ) are defined analogously.",3.3 Training loss function,[0],[0]
Here Θ denotes all the parameters of latent features.,3.3 Training loss function,[0],[0]
"The denominator is defined using a set of entities that do not fill the object position in any relation triple (es, r, ?) in the training knowledge graph.",3.3 Training loss function,[0],[0]
"Since the number of such entities is impractically large, we sample negative triples from the full set.",3.3 Training loss function,[0],[0]
"We also limit the candidate entities to ones that have types consistent with the position in the relation triple (Chang et al., 2014; Yang et al., 2015), where the types are approximated following Toutanova and Chen (2015).",3.3 Training loss function,[0],[0]
"Additionally, since the task of predicting textual relations is auxiliary to the main task, we use a weighting factor τ for the loss on predicting the arguments of textual relations (Toutanova and Chen, 2015).
",3.3 Training loss function,[0],[0]
"Denote T as a set of triples, we define the loss L(T ; Θ) as:
L(T ; Θ) =",3.3 Training loss function,[0],[0]
"− ∑
(es,r,eo)∈T log p(eo|es, r; Θ)
− ∑
(es,r,eo)∈T log p(es|eo, r; Θ)
Let TKB and Ttext represent the set of knowledge base triples and textual relation triples respectively.",3.3 Training loss function,[0],[0]
"The final training loss function is de-
2Our experimental comparison focuses on predicting object entities only, but we consider both argument types in the training loss function.
3Note that both margin-based and likelihood-based loss functions are susceptible to noise from potential selection of false negative examples.",3.3 Training loss function,[0],[0]
"An empirical comparison of training loss functions would be interesting.
fined as:
L(TKB; Θ) + τL(Ttext; Θ) + λ‖Θ‖2,
where λ is the regularization parameter, and τ is the weighing factor of the textual relations.
",3.3 Training loss function,[0],[0]
The parameters of all models are trained using a batch training algorithm.,3.3 Training loss function,[0],[0]
"The gradients of the basic models are straightforward to compute, and the gradients of the convolutional network parameters for the CONV-augmented models are also not hard to derive using back-propagation.",3.3 Training loss function,[0],[0]
"We use the FB15k-237 4 dataset, which is a subset of FB15k (Bordes et al., 2013) that excludes redundant relations and direct training links for held-out triples, with the goal of making the task more realistic (Toutanova and Chen, 2015).",Dataset and Evaluation Protocol,[0],[0]
"The FB15k dataset has been used in multiple studies on knowledge base completion (Wang et al., 2014b; Yang et al., 2015).",Dataset and Evaluation Protocol,[0],[0]
"Textual relations for
4Check the first author’s website for a release of the dataset.
1504
FB15k-237 are extracted from 200 million sentences in the ClueWeb12 corpus coupled with Freebase mention annotations (Gabrilovich et al., 2013), and include textual links of all co-occurring entities from the KB set.",Dataset and Evaluation Protocol,[0],[0]
"After pruning5, there are 2.7 million unique textual relations that are added to the knowledge graph.",Dataset and Evaluation Protocol,[0],[0]
"The set of textual relations is larger than the set used in Toutanova and Chen (2015) (25,000 versus 2.7 million), leading to improved performance.
",Dataset and Evaluation Protocol,[0],[0]
"The number of relations and triples in the training, validation and test portions of the data are given in Table 2.",Dataset and Evaluation Protocol,[0],[0]
The two rows list statistics for the KB and text portions of the data separately.,Dataset and Evaluation Protocol,[0],[0]
The 2.7 million textual relations occur in 3.9 million text triples.,Dataset and Evaluation Protocol,[0],[0]
"Almost all entities occur in textual relations (13,937 out of 14,541).",Dataset and Evaluation Protocol,[0],[0]
The numbers of triples for textual relations are shown as zero for the validation and test sets because we don’t evaluate on prediction of textual relations (all text triples are used in training).,Dataset and Evaluation Protocol,[0],[0]
"The percentage of KB triples that have textual relations for their pair of entities is 40.5% for the training, 26.6% for the validation, and 28.1% for the test set.",Dataset and Evaluation Protocol,[0],[0]
"While 26.6% of the validation set triples have textual mentions, the percentage with textual relations that have been seen in the training set is 18.4%.",Dataset and Evaluation Protocol,[0],[0]
"Having a mention increases the chance that a random entity pair has a relation from 0.1% to 5.0% — a fifty-fold increase.
",Dataset and Evaluation Protocol,[0],[0]
"Given a set of triples in a set disjoint from a training knowledge graph, we test models on predicting the object of each triple, given the subject and relation type.",Dataset and Evaluation Protocol,[0],[0]
We rank all entities in the training knowledge base in order of their likelihood of filling the argument position.,Dataset and Evaluation Protocol,[0],[0]
"We report the mean reciprocal rank (MRR) of the correct entity, as well as HITS@10 — the percentage of test triples for which the correct entity is ranked in the top 10.",Dataset and Evaluation Protocol,[0],[0]
"We use filtered measures following the protocol proposed in Bordes et al. (2013) — that is, when we rank entities for a given position, we remove all other entities that are known to be part of an existing triple in the training, validation, or test set.",Dataset and Evaluation Protocol,[0],[0]
"This avoids penalizing the model for ranking other correct fillers higher than the tested entity.
",Dataset and Evaluation Protocol,[0],[0]
"5The full set of 37 million textual patterns connecting the entity pairs of interest was pruned based on the count of patterns and their tri-grams, and their precision in indicating that entity pairs have KB relations.",Dataset and Evaluation Protocol,[0],[0]
"We used a value of λ = 1 for the weight of the L2 penalty for the main results in Table 3, and present some results on the impact of λ at the end of this section.",Implementation details,[0],[0]
We used batch optimization after initial experiments with AdaGrad showed inferior performance.,Implementation details,[0],[0]
"L-BFGS (Liu and Nocedal, 1989) and RProp (Riedmiller and Braun, 1993) were found to converge to similar function values, with RProp converging significantly faster.",Implementation details,[0],[0]
We thus used RProp for optimization.,Implementation details,[0],[0]
"We initialized the KB+text models from the KB-only models and also from random initial values (sampled from a Gaussian distribution), and stopped optimization when the overall MRR on the validation set decreased.",Implementation details,[0],[0]
"For each model type, we chose the better of random and KB-only initialization.",Implementation details,[0],[0]
"The word embeddings in the CONV models were initialized using the 50-dimensional vectors from Turian et al. (2010) in the main experiments, with a slight positive impact.",Implementation details,[0],[0]
"The effect of initialization is discussed at the end of the section.
",Implementation details,[0],[0]
The number of negative examples for each triple was set to 200.,Implementation details,[0],[0]
Performance improved substantially when the number of negative examples was increased and reached a plateau around 200.,Implementation details,[0],[0]
"We chose the optimal number of latent feature dimensions via a grid search to optimize MRR on the validation set, testing the values 5, 10, 15, 35, 50, 100, 200 and 500.",Implementation details,[0],[0]
"We also performed a grid search over the values of the parameter τ , testing values in the set {0.01, 0.1, 0.25, 0.5, 1}.",Implementation details,[0],[0]
"The best dimension for latent feature vectors was 10 for most KBonly models (not including model F), and 5 for the two model configurations including F. We used K = 10 for all KB+text models, as higher dimension was also not helpful for them.",Implementation details,[0],[0]
"In Table 3 we show the performance of different models and their combinations6, both when using textual mentions (KB+text), and when using only knowledge base relations (KB only).",Experimental results,[0],[0]
"In the KB+text setting, we evaluate the contribution of the CONV representations of the textual relations.",Experimental results,[0],[0]
"The upper portion of the Table shows the performance of models that have been trained using knowledge graphs including only knowledge
6Different models are combined by simply defining a combined scoring function which adds the scores from individual models.",Experimental results,[0],[0]
"Combined models are trained jointly.
base relations, and are not using any information from textual mentions.",Experimental results,[0],[0]
The lower portion of the Table shows the performance when textual relations are added to the training knowledge graph and the corresponding training loss function.,Experimental results,[0],[0]
"Note that all models predict based on the learned knowledge base relation and entity representations, and the textual relations are only used at training time when they can impact these representations.
",Experimental results,[0],[0]
"The performance of all models is shown as an overall MRR (scaled by 100) and HITS@10, as well as performance on the subset of triples that have textual mentions (column With mentions), and ones that do not (column Without mentions).",Experimental results,[0],[0]
"Around 28% of the test triples have mentions and contribute toward the measures in the With mentions column, and the other 72% of the test triples contribute to the Without mentions column.
",Experimental results,[0],[0]
"For the KB-only models, we see the performance of each individual model F, E, and DISTMULT.",Experimental results,[0],[0]
"Model F was the best performing single model from (Riedel et al., 2013), but it does not perform well when textual mentions are not used.",Experimental results,[0],[0]
"In our implementation of model F, we created entity pair parameters only for entity pairs that cooccur in the text data (Riedel et al. (2013) also trained pairwise vectors for co-occuring entities
only, but all of the training and test tuples in their study were co-occurring)7.",Experimental results,[0],[0]
"Without textual information, model F is performing essentially randomly, because entity pairs in the test sets do not occur in training set relations (by construction of the dataset).",Experimental results,[0],[0]
"Model E is able to do surprisingly well, given that it is making predictions for each object position of a relation without considering the given subject of the relation.",Experimental results,[0],[0]
DISTMULT is the best performing single model.,Experimental results,[0],[0]
"Unlike model F, it is able to share parameters among entity pairs with common subject or object entities, and, unlike model E, it captures some dependencies between the subject and object entities of a relation.",Experimental results,[0],[0]
"The combination of models E+DISTMULT improves performance, but combining model F with the other two is not helpful.
",Experimental results,[0],[0]
The lower portion of Table 3 shows results when textual relations are added to the training knowledge graph.,Experimental results,[0],[0]
The basic models treat the textual relations as atomic and learn a separate latent feature vector for each textual relation.,Experimental results,[0],[0]
"The CONV- models use the compositional representations of tex-
7Learning entity pair parameters for all entity pairs would result in 2.2 billion parameters for vectors with dimensionality 10 for our dataset.",Experimental results,[0],[0]
"This was infeasible and was also not found useful based on experiments with vectors of lower dimensionality.
",Experimental results,[0],[0]
tual relations learned using the convolutional neural network architecture shown in Figure 4.,Experimental results,[0],[0]
We show the performance of each individual model and its corresponding variant with a CONV parameterization.,Experimental results,[0],[0]
"For each model, we also show the optimal value of τ , the weight of the textual relations loss.",Experimental results,[0],[0]
"Model F is able to benefit from textual relations and its performance increases by 2.5 points in MRR, with the gain in performance being particularly large on test triples with textual mentions.",Experimental results,[0],[0]
Model F is essentially limiting its space of considered argument fillers to ones that have cooccurred with the given subject entity.,Experimental results,[0],[0]
"This gives it an advantage on test triples with textual mentions, but model F still does relatively very poorly overall when taking into account the much more numerous test triples without textual mentions.",Experimental results,[0],[0]
"The CONV parameterization performs slightly worse in MRR, but slightly better in HITS@10, compared to the atomic parameterization.",Experimental results,[0],[0]
"For model E and its CONV variant, we see that text does not help as its performance using text is the same as that when not using text and the optimal weight of the text is zero.",Experimental results,[0],[0]
"Model DISTMULT benefits from text, and its convolutional text variant CONVDISTMULT outperforms the basic model, with the gain being larger on test triples with mentions.
",Experimental results,[0],[0]
"The best model overall, as in the KB-only case, is E+DISTMULT.",Experimental results,[0],[0]
"The basic model benefits from text slightly and the model with compositional representations of textual patterns CONVE+CONV-DISTMULT, improves the performance further, by 2.4 MRR overall, and by 5 MRR on triples with textual mentions.",Experimental results,[0],[0]
It is interesting that the text and the compositional representations helped most for this combined model.,Experimental results,[0],[0]
"One hypothesis is that model E, which provides a prior over relation arguments, is needed in combination with DISTMULT to prevent the prediction of unlikely arguments based on noisy inference from textual patterns and their individual words and dependency links.",Experimental results,[0],[0]
"To gain insight into the sensitivity of the model to hyper-parameters and initialization, we report on experiments starting with the best model CONVE + CONV-DISTMULT from Table 3 and varying one parameter at a time.",Hyperparameter Sensitivity,[0],[0]
"This model has weight of the textual relations loss τ = 0.25, weight of the L2 penalty λ = 1, convolution window size of
three, and is initialized randomly for the entity and KB relation vectors, and from pre-trained embeddings for word vectors (Turian et al., 2010).",Hyperparameter Sensitivity,[0],[0]
"The overall MRR of the model is 40.4 on the validation set (test results are shown in the Table).
",Hyperparameter Sensitivity,[0],[0]
"When the weight of τ is changed to 1 (i.e., equal contribution of textual and KB relations), the overall MRR goes down to 39.6 from 40.4, indicating the usefulness of weighting the two kinds of relations non-uniformly.",Hyperparameter Sensitivity,[0],[0]
"When λ is reduced to 0.04, MRR is 40.0 and when λ is increased to 25, MRR goes down to 38.9.",Hyperparameter Sensitivity,[0],[0]
This indicates the L2 penalty hyper-parameter has a large impact on performance.,Hyperparameter Sensitivity,[0],[0]
"When we initialize the word embeddings randomly instead of using pre-trained word vectors, performance drops only slightly to 40.3.",Hyperparameter Sensitivity,[0],[0]
"If we initialize from a model trained using KBonly information, performance goes down substantially to 38.7.",Hyperparameter Sensitivity,[0],[0]
This indicates that initialization is important and there is a small gain from using pre-trained word embeddings.,Hyperparameter Sensitivity,[0],[0]
"There was a drop in performance to MRR 40.2 when using a window size of one for the convolutional architecture in Figure 4, and an increase to 40.6 when using a window size of five.",Hyperparameter Sensitivity,[0],[0]
Here we explored an alternative representation of textual relations for latent feature models that learn to represent knowledge base and textual relations in the same vector space.,5 Conclusion and Future Work,[0],[0]
"We showed that given the large degree of sharing of sub-structure in the textual relations, it was beneficial to compose their continuous representations out of the representations of their component words and dependency arc links.",5 Conclusion and Future Work,[0],[0]
"We applied a convolutional neural network model and trained it jointly with a model mapping entities and knowledge base relations to the same vector space, obtaining substantial improvements over an approach that treats the textual relations as atomic units having independent parameterization.",5 Conclusion and Future Work,[0],[0]
"We would like to thank the anonymous reviewers for their suggestions, and Jianfeng Gao, Scott Wen-tau Yih, and Wei Xu for useful discussions.",Acknowledgements,[0],[0]
"Models that learn to represent textual and knowledge base relations in the same continuous latent space are able to perform joint inferences among the two kinds of relations and obtain high accuracy on knowledge base completion (Riedel et al., 2013).",abstractText,[0],[0]
"In this paper we propose a model that captures the compositional structure of textual relations, and jointly optimizes entity, knowledge base, and textual relation representations.",abstractText,[0],[0]
The proposed model significantly improves performance over a model that does not share parameters among textual relations with common sub-structure.,abstractText,[0],[0]
Representing Text for Joint Embedding of Text and Knowledge Bases,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1257–1266 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1257",text,[0],[0]
"The construction of large-scale Knowledge Bases (KBs) like Freebase (Bollacker et al., 2008) and Wikidata (Vrandečić and Krötzsch, 2014) has proven to be useful in many natural language processing (NLP) tasks like question-answering, web search, etc.",1 Introduction,[0],[0]
"However, these KBs are not exhaustive.",1 Introduction,[0],[0]
Relation Extraction (RE) attempts to fill this gap by extracting semantic relationships between entity pairs from plain text.,1 Introduction,[0],[0]
This task can be modeled as a simple classification problem after the entity pairs are specified.,1 Introduction,[0],[0]
"Formally, given an entity pair (e1,e2) from the KB and an entity annotated sentence (or instance), we aim to predict the
∗Research internship at Indian Institute of Science.
relation r, from a predefined relation set, that exists between e1 and e2.",1 Introduction,[0],[0]
"If no relation exists, we simply label it NA.
",1 Introduction,[0],[0]
Most supervised relation extraction methods require large labeled training data which is expensive to construct.,1 Introduction,[0],[0]
"Distant Supervision (DS) (Mintz et al., 2009) helps with the construction of this dataset automatically, under the assumption that if two entities have a relationship in a KB, then all sentences mentioning those entities express the same relation.",1 Introduction,[0],[0]
"While this approach works well in generating large amounts of training instances, the DS assumption does not hold in all cases.",1 Introduction,[0],[0]
Riedel et al. (2010); Hoffmann et al. (2011); Surdeanu et al. (2012) propose multi-instance based learning to relax this assumption.,1 Introduction,[0],[0]
"However, they use NLP tools to extract features, which can be noisy.
",1 Introduction,[0],[0]
"Recently, neural models have demonstrated promising performance on RE.",1 Introduction,[0],[0]
"Zeng et al. (2014, 2015) employ Convolutional Neural Networks (CNN) to learn representations of instances.",1 Introduction,[0],[0]
"For alleviating noise in distant supervised datasets, attention has been utilized by (Lin et al., 2016; Jat et al., 2018).",1 Introduction,[0],[0]
"Syntactic information from dependency parses has been used by (Mintz et al., 2009; He et al., 2018) for capturing long-range dependencies between tokens.",1 Introduction,[0],[0]
"Recently proposed Graph Convolution Networks (GCN) (Defferrard et al., 2016) have been effectively employed for encoding this information (Marcheggiani and Titov, 2017; Bastings et al., 2017).",1 Introduction,[0],[0]
"However, all the above models rely only on the noisy instances from distant supervision for RE.
",1 Introduction,[0],[0]
Relevant side information can be effective for improving RE.,1 Introduction,[0],[0]
"For instance, in the sentence, Microsoft was started by Bill Gates., the type information of Bill Gates (person) and Microsoft (organization) can be helpful in predicting the correct relation founderOfCompany.",1 Introduction,[0],[0]
"This is because every relation constrains the type of its target en-
tities.",1 Introduction,[0],[0]
"Similarly, relation phrase “was started by” extracted using Open Information Extraction (Open IE) methods can be useful, given that the aliases of relation founderOfCompany, e.g., founded, co-founded, etc., are available.",1 Introduction,[0],[0]
"KBs used for DS readily provide such information which has not been completely exploited by current models.
",1 Introduction,[0],[0]
"In this paper, we propose RESIDE, a novel distant supervised relation extraction method which utilizes additional supervision from KB through its neural network based architecture.",1 Introduction,[0],[0]
"RESIDE makes principled use of entity type and relation alias information from KBs, to impose soft constraints while predicting the relation.",1 Introduction,[0],[0]
"It uses encoded syntactic information obtained from Graph Convolution Networks (GCN), along with embedded side information, to improve neural relation extraction.",1 Introduction,[0],[0]
"Our contributions can be summarized as follows:
• We propose RESIDE, a novel neural method which utilizes additional supervision from KB in a principled manner for improving distant supervised RE.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"RESIDE uses Graph Convolution Networks
(GCN) for modeling syntactic information and has been shown to perform competitively even with limited side information.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Through extensive experiments on benchmark
datasets, we demonstrate RESIDE’s effectiveness over state-of-the-art baselines.
RESIDE’s source code and datasets used in the paper are available at http://github.com/ malllabiisc/RESIDE.",1 Introduction,[0],[0]
Distant supervision: Relation extraction is the task of identifying the relationship between two entity mentions in a sentence.,2 Related Work,[0],[0]
"In supervised paradigm, the task is considered as a multi-class classification problem but suffers from lack of large labeled training data.",2 Related Work,[0],[0]
"To address this limitation, (Mintz et al., 2009) propose distant supervision (DS) assumption for creating large datasets, by heuristically aligning text to a given Knowledge Base (KB).",2 Related Work,[0],[0]
"As this assumption does not always hold true, some of the sentences might be wrongly labeled.",2 Related Work,[0],[0]
"To alleviate this shortcoming, Riedel et al. (2010) relax distant supervision for multi-instance single-label learning.",2 Related Work,[0],[0]
"Subsequently, for handling overlapping relations between entities (Hoffmann et al., 2011; Surdeanu et al., 2012) propose multi-instance multi-label learning paradigm.
",2 Related Work,[0],[0]
Neural Relation Extraction: The performance of the above methods strongly rely on the quality of hand engineered features.,2 Related Work,[0],[0]
"Zeng et al. (2014)
propose an end-to-end CNN based method which could automatically capture relevant lexical and sentence level features.",2 Related Work,[0],[0]
"This method is further improved through piecewise max-pooling by (Zeng et al., 2015).",2 Related Work,[0],[0]
"Lin et al. (2016); Nagarajan et al. (2017) use attention (Bahdanau et al., 2014) for learning from multiple valid sentences.",2 Related Work,[0],[0]
"We also make use of attention for learning sentence and bag representations.
",2 Related Work,[0],[0]
"Dependency tree based features have been found to be relevant for relation extraction (Mintz et al., 2009).",2 Related Work,[0],[0]
He et al. (2018) use them for getting promising results through a recursive tree-GRU based model.,2 Related Work,[0],[0]
"In RESIDE, we make use of recently proposed Graph Convolution Networks (Defferrard et al., 2016; Kipf and Welling, 2017), which have been found to be quite effective for modelling syntactic information (Marcheggiani and Titov, 2017; Nguyen and Grishman, 2018; Vashishth et al., 2018a).
",2 Related Work,[0],[0]
"Side Information in RE: Entity description from KB has been utilized for RE (Ji et al., 2017), but such information is not available for all entities.",2 Related Work,[0],[0]
Type information of entities has been used by Ling and Weld (2012); Liu et al. (2014) as features in their model.,2 Related Work,[0],[0]
Yaghoobzadeh et al. (2017) also attempt to mitigate noise in DS through their joint entity typing and relation extraction model.,2 Related Work,[0],[0]
"However, KBs like Freebase readily provide reliable type information which could be directly utilized.",2 Related Work,[0],[0]
"In our work, we make principled use of entity type and relation alias information obtained from KB.",2 Related Work,[0],[0]
"We also use unsupervised Open Information Extraction (Open IE) methods (Mausam et al., 2012; Angeli et al., 2015), which automatically discover possible relations without the need of any predefined ontology, which is used as a side information as defined in Section 5.2.",2 Related Work,[0],[0]
"In this section, we provide a brief overview of Graph Convolution Networks (GCN) for graphs with directed and labeled edges, as used in (Marcheggiani and Titov, 2017).",3 Background: Graph Convolution Networks (GCN),[0],[0]
"For a directed graph, G = (V, E), where V and E represent the set of vertices and edges respectively, an edge from node u to node v with label luv is represented as (u, v, luv).",3.1 GCN on Labeled Directed Graph,[0],[0]
"Since, informa-
tion in directed edge does not necessarily propagate along its direction, following (Marcheggiani and Titov, 2017) we define an updated edge set E ′ which includes inverse edges (v, u, l−1uv ) and",3.1 GCN on Labeled Directed Graph,[0],[0]
"selfloops (u, u,>) along with the original edge set E , where > is a special symbol to denote self-loops.",3.1 GCN on Labeled Directed Graph,[0],[0]
"For each node v in G, we have an initial representation",3.1 GCN on Labeled Directed Graph,[0],[0]
"xv ∈ Rd, ∀v ∈ V .",3.1 GCN on Labeled Directed Graph,[0],[0]
"On employing GCN, we get an updated d-dimensional hidden representation hv ∈ Rd, ∀v ∈ V , by considering only its immediate neighbors (Kipf and Welling, 2017).",3.1 GCN on Labeled Directed Graph,[0],[0]
"This can be formulated as:
hv = f  ∑ u∈N (v) (Wluvxu + bluv)  .",3.1 GCN on Labeled Directed Graph,[0],[0]
"Here, Wluv ∈ Rd×d and bluv ∈ Rd are label dependent model parameters which are trained based on the downstream task.",3.1 GCN on Labeled Directed Graph,[0],[0]
N (v) refers to the set of neighbors of v based on E ′,3.1 GCN on Labeled Directed Graph,[0],[0]
and f is any non-linear activation function.,3.1 GCN on Labeled Directed Graph,[0],[0]
"In order to capture multihop neighborhood, multiple GCN layers can be stacked.",3.1 GCN on Labeled Directed Graph,[0],[0]
"Hidden representation of node v in this case after kth GCN layer is given as:
hk+1v = f  ∑ u∈N (v) ( W kluvh k u + b k luv ) .",3.1 GCN on Labeled Directed Graph,[0],[0]
"In automatically constructed graphs, some edges might be erroneous and hence need to be discarded.",3.2 Integrating Edge Importance,[0],[0]
"Edgewise gating in GCN by (Bastings et al., 2017; Marcheggiani and Titov, 2017) allows us to alleviate this problem by subduing the noisy edges.",3.2 Integrating Edge Importance,[0],[0]
This is achieved by assigning a relevance score to each edge in the graph.,3.2 Integrating Edge Importance,[0],[0]
"At kth layer, the importance of an edge (u, v, luv) is computed as:
gkuv = σ",3.2 Integrating Edge Importance,[0],[0]
"( hku · ŵkluv + b̂ k luv ) , (1)
Here, ŵkluv ∈ R m and b̂kluv ∈ R are parameters which are trained and σ(·) is the sigmoid function.",3.2 Integrating Edge Importance,[0],[0]
"With edgewise gating, the final GCN embedding for a node v after kth layer is given as:
hk+1v = f  ∑ u∈N (v) gkuv × ( W kluvh k u + b k luv ) .",3.2 Integrating Edge Importance,[0],[0]
(2),3.2 Integrating Edge Importance,[0],[0]
"In multi-instance learning paradigm, we are given a bag of sentences (or instances) {s1, s2, ...sn} for a given entity pair, the task is to predict the relation between them.",4 RESIDE Overview,[0],[0]
"RESIDE consists of three components for learning a representation of a given bag, which is fed to a softmax classifier.",4 RESIDE Overview,[0],[0]
We briefly present the components of RESIDE below.,4 RESIDE Overview,[0],[0]
Each component will be described in detail in the subsequent sections.,4 RESIDE Overview,[0],[0]
"The overall architecture of RESIDE is shown in Figure 1.
1.",4 RESIDE Overview,[0],[0]
Syntactic Sentence Encoding: RESIDE uses a Bi-GRU over the concatenated positional and word embedding for encoding the local context of each token.,4 RESIDE Overview,[0],[0]
"For capturing long-range dependencies, GCN over dependency tree is employed and its encoding is appended to the representation of each token.",4 RESIDE Overview,[0],[0]
"Finally, attention over tokens is used to subdue irrelevant tokens and get an embedding for the entire sentence.",4 RESIDE Overview,[0],[0]
"More details in Section 5.1.
2.",4 RESIDE Overview,[0],[0]
Side Information Acquisition:,4 RESIDE Overview,[0],[0]
"In this module, we use additional supervision from KBs and utilize Open IE methods for getting relevant side information.",4 RESIDE Overview,[0],[0]
"This information is later utilized by the model as described in Section 5.2.
3.",4 RESIDE Overview,[0],[0]
Instance Set Aggregation:,4 RESIDE Overview,[0],[0]
"In this part, sentence representation from syntactic sentence encoder is concatenated with the matched relation embedding obtained from the previous step.",4 RESIDE Overview,[0],[0]
"Then, using attention over sentences, a representation for the entire bag is learned.",4 RESIDE Overview,[0],[0]
This is then concatenated with entity type embedding before feeding into the softmax classifier for relation prediction.,4 RESIDE Overview,[0],[0]
Please refer to Section 5.3 for more details.,4 RESIDE Overview,[0],[0]
"In this section, we provide the detailed description of the components of RESIDE.",5 RESIDE Details,[0],[0]
"For each sentence in the bag si with m tokens {w1, w2, ...wm}, we first represent each token by k-dimensional GloVe embedding (Pennington et al., 2014).",5.1 Syntactic Sentence Encoding,[0],[0]
"For incorporating relative position of tokens with respect to target entities, we use p-dimensional position embeddings, as used by
(Zeng et al., 2014).",5.1 Syntactic Sentence Encoding,[0],[0]
The combined token embeddings are stacked together to get the sentence representationH ∈ Rm×(k+2p).,5.1 Syntactic Sentence Encoding,[0],[0]
"Then, using Bi-GRU (Cho et al., 2014) over H, we get the new sentence representationHgru ∈ Rm×dgru , where dgru is the hidden state dimension.",5.1 Syntactic Sentence Encoding,[0],[0]
"Bi-GRUs have been found to be quite effective in encoding the context of tokens in several tasks (Sutskever et al., 2014; Graves et al., 2013).
",5.1 Syntactic Sentence Encoding,[0],[0]
"Although Bi-GRU is capable of capturing local context, it fails to capture long-range dependencies which can be captured through dependency edges.",5.1 Syntactic Sentence Encoding,[0],[0]
"Prior works (Mintz et al., 2009; He et al., 2018) have exploited features from syntactic dependency trees for improving relation extraction.",5.1 Syntactic Sentence Encoding,[0],[0]
"Motivated by their work, we employ Syntactic Graph Convolution Networks for encoding this information.",5.1 Syntactic Sentence Encoding,[0],[0]
"For a given sentence, we generate its dependency tree using Stanford CoreNLP",5.1 Syntactic Sentence Encoding,[0],[0]
"(Manning et al., 2014).",5.1 Syntactic Sentence Encoding,[0],[0]
"We then run GCN over the dependency graph and use Equation 2 for updating the embeddings, taking Hgru as the input.",5.1 Syntactic Sentence Encoding,[0],[0]
"Since dependency graph has 55 different edge labels, incorporating all of them overparameterizes the model significantly.",5.1 Syntactic Sentence Encoding,[0],[0]
"Therefore, following (Marcheggiani and Titov, 2017; Nguyen and Grishman, 2018; Vashishth et al., 2018a) we use only three edge labels based on the direction of the edge {forward (→), backward (←), selfloop (>)}.",5.1 Syntactic Sentence Encoding,[0],[0]
"We define the new edge label Luv for an edge (u, v, luv) as follows:
",5.1 Syntactic Sentence Encoding,[0],[0]
"Luv =  → if edge exists in dependency parse ← if edge is an inverse edge > if edge is a self-loop
For each token wi, GCN embedding h gcn ik+1 ∈",5.1 Syntactic Sentence Encoding,[0],[0]
"Rdgcn after kth layer is defined as:
hgcnik+1 =",5.1 Syntactic Sentence Encoding,[0],[0]
f,5.1 Syntactic Sentence Encoding,[0],[0]
"( ∑ u∈N (i) gkiu × ( W kLiuh gcn uk + bkLiu )) .
",5.1 Syntactic Sentence Encoding,[0],[0]
"Here, gkiu denotes edgewise gating as defined in Equation 1 and Liu refers to the edge label defined above.",5.1 Syntactic Sentence Encoding,[0],[0]
"We use ReLU as activation function f , throughout our experiments.",5.1 Syntactic Sentence Encoding,[0],[0]
"The syntactic graph encoding from GCN is appended to Bi-GRU output to get the final token representation, hconcati as [hgrui ;h gcn ik+1
].",5.1 Syntactic Sentence Encoding,[0],[0]
"Since, not all tokens are equally relevant for RE task, we calculate the degree of relevance of each token using attention as used in
(Jat et al., 2018).",5.1 Syntactic Sentence Encoding,[0],[0]
"For token wi in the sentence, attention weight αi is calculated as:
αi = exp(ui)∑m j=1 exp(uj) where, ui = hconcati ·",5.1 Syntactic Sentence Encoding,[0],[0]
"r.
where r is a random query vector and ui is the relevance score assigned to each token.",5.1 Syntactic Sentence Encoding,[0],[0]
Attention values {αi} are calculated by taking softmax over {ui}.,5.1 Syntactic Sentence Encoding,[0],[0]
"The representation of a sentence is given as a weighted sum of its tokens, s =∑m
j=1 αih concat i .",5.1 Syntactic Sentence Encoding,[0],[0]
"Relevant side information has been found to improve performance on several tasks (Ling and Weld, 2012; Vashishth et al., 2018b).",5.2 Side Information Acquisition,[0],[0]
"In distant supervision based relation extraction, since the entities are from a KB, knowledge about them can be utilized to improve relation extraction.",5.2 Side Information Acquisition,[0],[0]
"Moreover, several unsupervised relation extraction methods (Open IE) (Angeli et al., 2015; Mausam et al., 2012) allow extracting relation phrases between target entities without any predefined ontology and thus can be used to obtain relevant side information.",5.2 Side Information Acquisition,[0],[0]
"In RESIDE, we employ Open IE methods and additional supervision from KB for improving neural relation extraction.
",5.2 Side Information Acquisition,[0],[0]
"Relation Alias Side Information RESIDE uses Stanford Open IE (Angeli et al., 2015) for extracting relation phrases between target entities, which we denote by P .",5.2 Side Information Acquisition,[0],[0]
"As shown in Figure 2, for the sentence Matt Coffin, executive of
lowermybills, a company.., Open IE methods extract “executive of” between Matt Coffin and lowermybills.",5.2 Side Information Acquisition,[0],[0]
"Further, we extend P by including tokens at one hop distance in dependency path from target entities.",5.2 Side Information Acquisition,[0],[0]
"Such features from dependency parse have been exploited in the past by (Mintz et al., 2009; He et al., 2018).",5.2 Side Information Acquisition,[0],[0]
The degree of match between the extracted phrases in P and aliases of a relation can give important clues about the relevance of that relation for the sentence.,5.2 Side Information Acquisition,[0],[0]
"Several KBs like Wikidata provide such relation aliases, which can be readily exploited.",5.2 Side Information Acquisition,[0],[0]
"In RESIDE, we further expand the relation alias set using Paraphrase database (PPDB) (Pavlick et al., 2015).",5.2 Side Information Acquisition,[0],[0]
"We note that even for cases when aliases for relations are not available, providing only the names of relations give competitive performance.",5.2 Side Information Acquisition,[0],[0]
"We shall explore this point further in Section 7.3.
",5.2 Side Information Acquisition,[0],[0]
"For matching P with the PPDB expanded relation alias setR, we project both in a d-dimensional space using GloVe embeddings (Pennington et al., 2014).",5.2 Side Information Acquisition,[0],[0]
"Projecting phrases using word embeddings helps to further expand these sets, as semantically similar words are closer in embedding space (Mikolov et al., 2013; Pennington et al., 2014).",5.2 Side Information Acquisition,[0.9588829445116317],"['Producing such adversarial examples systematically can significantly aid in debugging ML models, as it allows users to detect problems that happen in the real world, instead of oversensitivity only to malicious attacks such as intentionally scrambling, misspelling, or removing words (Bansal et al., 2014; Ebrahimi et al., 2018; Li et al., 2016).']"
"Then, for each phrase p ∈ P , we calculate its cosine distance from all relation aliases inR and take the relation corresponding to the closest relation alias as a matched relation for the sentence.",5.2 Side Information Acquisition,[0],[0]
We use a threshold on cosine distance to remove noisy aliases.,5.2 Side Information Acquisition,[0],[0]
"In RESIDE, we define a kr-dimensional embedding for each relation which we call as matched relation embedding (hrel).",5.2 Side Information Acquisition,[0],[0]
"For a given sentence, hrel is concatenated with its representa-
tion s, obtained from syntactic sentence encoder (Section 5.1) as shown in Figure 1.",5.2 Side Information Acquisition,[0],[0]
"For sentences with |P| > 1, we might get multiple matched relations.",5.2 Side Information Acquisition,[0],[0]
"In such cases, we take the average of their embeddings.",5.2 Side Information Acquisition,[0],[0]
"We hypothesize that this helps in improving the performance and find it to be true as shown in Section 7.
Entity Type Side Information Type information of target entities has been shown to give promising results on relation extraction (Ling and Weld, 2012; Yaghoobzadeh et al., 2017).",5.2 Side Information Acquisition,[0],[0]
Every relation puts some constraint on the type of entities which can be its subject and object.,5.2 Side Information Acquisition,[0],[0]
"For example, the relation person/place of birth can only occur between a person and a location.",5.2 Side Information Acquisition,[0],[0]
"Sentences in distance supervision are based on entities in KBs, where the type information is readily available.
",5.2 Side Information Acquisition,[0],[0]
"In RESIDE, we use types defined by FIGER (Ling and Weld, 2012) for entities in Freebase.",5.2 Side Information Acquisition,[0],[0]
"For each type, we define a kt-dimensional embedding which we call as entity type embedding (htype).",5.2 Side Information Acquisition,[0],[0]
"For cases when an entity has multiple types in different contexts, for instance, Paris may have types government and location, we take the average over the embeddings of each type.",5.2 Side Information Acquisition,[0],[0]
We concatenate the entity type embedding of target entities to the final bag representation before using it for relation classification.,5.2 Side Information Acquisition,[0],[0]
"To avoid over-parameterization, instead of using all fine-grained 112 entity types, we use 38 coarse types which form the first hierarchy of FIGER types.",5.2 Side Information Acquisition,[0],[0]
"For utilizing all valid sentences, following (Lin et al., 2016; Jat et al., 2018), we use attention over sentences to obtain a representation for the entire bag.",5.3 Instance Set Aggregation,[0],[0]
"Instead of directly using the sentence representation si from Section 5.1, we concatenate the embedding of each sentence with matched relation embedding hreli as obtained from Section 5.2.",5.3 Instance Set Aggregation,[0],[0]
"The attention score αi for ith sentence is formulated as:
αi = exp(ŝi · q)∑n j=1 exp(ŝj · q) where, ŝi =",5.3 Instance Set Aggregation,[0],[0]
"[si;hreli ].
here q denotes a random query vector.",5.3 Instance Set Aggregation,[0],[0]
"The bag representation B, which is the weighted sum of its sentences, is then concatenated with the entity type embeddings of the subject (htypesub ) and object
(htypeobj ) from Section 5.2 to obtain B̂.
B̂ = [B;htypesub ;h type obj ] where, B = n∑ i=1 αiŝi.
",5.3 Instance Set Aggregation,[0],[0]
"Finally, B̂ is fed to a softmax classifier to get the probability distribution over the relations.
p(y) =",5.3 Instance Set Aggregation,[0],[0]
Softmax(W · B̂ + b).,5.3 Instance Set Aggregation,[0],[0]
"In our experiments, we evaluate the models on Riedel and Google Distant Supervision (GIDS) dataset.",6.1 Datasets,[0],[0]
Statistics of the datasets is summarized in Table 1.,6.1 Datasets,[0],[0]
"Below we described each in detail1.
1.",6.1 Datasets,[0],[0]
Riedel:,6.1 Datasets,[0],[0]
"The dataset is developed by (Riedel et al., 2010) by aligning Freebase relations with New York Times (NYT) corpus, where sentences from the year 2005-2006 are used for creating the training set and from the year 2007 for the test set.",6.1 Datasets,[0],[0]
"The entity mentions are annotated using Stanford NER (Finkel et al., 2005) and are linked to Freebase.",6.1 Datasets,[0],[0]
"The dataset has been widely used for RE by (Hoffmann et al., 2011; Surdeanu et al., 2012) and more recently by (Lin et al., 2016; Feng et al.;",6.1 Datasets,[0],[0]
"He et al., 2018).
2.",6.1 Datasets,[0],[0]
GIDS:,6.1 Datasets,[0],[0]
Jat et al. (2018) created Google Distant Supervision (GIDS) dataset by extending the Google relation extraction corpus2 with additional instances for each entity pair.,6.1 Datasets,[0],[0]
"The dataset assures that the at-least-one assumption of multi-instance learning, holds.",6.1 Datasets,[0],[0]
"This makes automatic evaluation more reliable and thus removes the need for manual verification.
",6.1 Datasets,[0],[0]
1Data splits and hyperparameters are in supplementary.,6.1 Datasets,[0],[0]
"2https://research.googleblog.com/2013/04/50000-
lessons-on-how-to-read-relation.html",6.1 Datasets,[0],[0]
"For evaluating RESIDE, we compare against the following baselines:
• Mintz: Multi-class logistic regression model proposed by (Mintz et al., 2009) for distant supervision paradigm.",6.2 Baselines,[0],[0]
"• MultiR: Probabilistic graphical model for multi
instance learning by (Hoffmann et al., 2011)",6.2 Baselines,[0],[0]
"• MIMLRE: A graphical model which jointly
models multiple instances and multiple labels.",6.2 Baselines,[0],[0]
"More details in (Surdeanu et al., 2012).",6.2 Baselines,[0],[0]
• PCNN:,6.2 Baselines,[0],[0]
"A CNN based relation extraction model
by (Zeng et al., 2015) which uses piecewise max-pooling for sentence representation.",6.2 Baselines,[0],[0]
• PCNN+ATT,6.2 Baselines,[0],[0]
": A piecewise max-pooling over
CNN based model which is used by (Lin et al., 2016) to get sentence representation followed by attention over sentences.",6.2 Baselines,[0],[0]
"• BGWA: Bi-GRU based relation extraction
model with word and sentence level attention (Jat et al., 2018).",6.2 Baselines,[0],[0]
•,6.2 Baselines,[0],[0]
RESIDE:,6.2 Baselines,[0],[0]
"The method proposed in this paper,
please refer Section 5 for more details.",6.2 Baselines,[0],[0]
"Following the prior works (Lin et al., 2016; Feng et al.), we evaluate the models using held-out evaluation scheme.",6.3 Evaluation Criteria,[0],[0]
This is done by comparing the relations discovered from test articles with those in Freebase.,6.3 Evaluation Criteria,[0],[0]
We evaluate the performance of models with Precision-Recall curve and top-N precision (P@N) metric in our experiments.,6.3 Evaluation Criteria,[0],[0]
"In this section we attempt to answer the following questions:
Q1.",7 Results,[0],[0]
Is RESIDE more effective than existing approaches for distant supervised RE?,7 Results,[0],[0]
"(7.1)
Q2.",7 Results,[0],[0]
What is the effect of ablating different components on RESIDE’s performance?,7 Results,[0],[0]
"(7.2)
Q3.",7 Results,[0],[0]
How is the performance affected in the absence of relation alias information?,7 Results,[0],[0]
(7.3),7 Results,[0],[0]
"For evaluating the effectiveness of our proposed method, RESIDE, we compare it against the baselines stated in Section 6.2.",7.1 Performance Comparison,[0],[0]
We use only the neural baselines on GIDS dataset.,7.1 Performance Comparison,[0],[0]
The Precision-Recall curves on Riedel and GIDS are presented in Figure 3.,7.1 Performance Comparison,[0],[0]
"Overall, we find that RESIDE achieves higher precision over the entire recall range on both the datasets.",7.1 Performance Comparison,[0],[0]
All the non-neural baselines could not perform well as the features used by them are mostly derived from NLP tools which can be erroneous.,7.1 Performance Comparison,[0],[0]
RESIDE outperforms PCNN+ATT and BGWA which indicates that incorporating side information helps in improving the performance of the model.,7.1 Performance Comparison,[0],[0]
The higher performance of BGWA and PCNN+ATT over PCNN shows that attention helps in distant supervised RE.,7.1 Performance Comparison,[0],[0]
"Following (Lin et al., 2016; Liu et al., 2017), we also evaluate our method with different number of sentences.",7.1 Performance Comparison,[0],[0]
"Results summarized in Table 2, show the improved precision of RESIDE in all test settings, as compared to the neural baselines, which demonstrates
the efficacy of our model.",7.1 Performance Comparison,[0],[0]
"In this section, we analyze the effect of various components of RESIDE on its performance.",7.2 Ablation Results,[0],[0]
"For this, we evaluate various versions of our model with cumulatively removed components.",7.2 Ablation Results,[0],[0]
The experimental results are presented in Figure 4.,7.2 Ablation Results,[0],[0]
"We observe that on removing different components from RESIDE, the performance of the model degrades drastically.",7.2 Ablation Results,[0],[0]
The results validate that GCNs are effective at encoding syntactic information.,7.2 Ablation Results,[0],[0]
"Further, the improvement from side information shows that it is complementary to the features extracted from text, thus validating the central thesis of this paper, that inducing side information leads to improved relation extraction.",7.2 Ablation Results,[0],[0]
"In this section, we test the performance of the model in setting where relation alias information is not readily available.",7.3 Effect of Relation Alias Side Information,[0],[0]
"For this, we evaluate the performance of the model on four different settings:",7.3 Effect of Relation Alias Side Information,[0],[0]
"• None: Relation aliases are not available.
",7.3 Effect of Relation Alias Side Information,[0],[0]
• One: The name of relation is used as its alias.,7.3 Effect of Relation Alias Side Information,[0],[0]
"• One+PPDB: Relation name extended using
Paraphrase Database (PPDB).",7.3 Effect of Relation Alias Side Information,[0],[0]
•,7.3 Effect of Relation Alias Side Information,[0],[0]
"All: Relation aliases from Knowledge Base3
The overall results are summarized in Figure 5.",7.3 Effect of Relation Alias Side Information,[0],[0]
We find that the model performs best when aliases are provided by the KB itself.,7.3 Effect of Relation Alias Side Information,[0],[0]
"Overall, we find that RESIDE gives competitive performance even when very limited amount of relation alias information is available.",7.3 Effect of Relation Alias Side Information,[0],[0]
We observe that performance improves further with the availability of more alias information.,7.3 Effect of Relation Alias Side Information,[0],[0]
"In this paper, we propose RESIDE, a novel neural network based model which makes principled use of relevant side information, such as entity type and relation alias, from Knowledge Base, for improving distant supervised relation extraction.",8 Conclusion,[0],[0]
"RESIDE employs Graph Convolution Networks for
3Each relation in Riedel dataset is manually mapped to corresponding Wikidata property for getting relation aliases.",8 Conclusion,[0],[0]
"Few examples are presented in supplementary material.
encoding syntactic information of sentences and is robust to limited side information.",8 Conclusion,[0],[0]
"Through extensive experiments on benchmark datasets, we demonstrate RESIDE’s effectiveness over stateof-the-art baselines.",8 Conclusion,[0],[0]
We have made RESIDE’s source code publicly available to promote reproducible research.,8 Conclusion,[0],[0]
We thank the anonymous reviewers for their constructive comments.,Acknowledgements,[0],[0]
"This work is supported in part by the Ministry of Human Resource Development (Government of India), CAIR (DRDO) and by a gift from Google.",Acknowledgements,[0],[0]
Distantly-supervised Relation Extraction (RE) methods train an extractor by automatically aligning relation instances in a Knowledge Base (KB) with unstructured text.,abstractText,[0],[0]
"In addition to relation instances, KBs often contain other relevant side information, such as aliases of relations (e.g., founded and co-founded are aliases for the relation founderOfCompany).",abstractText,[0],[0]
RE models usually ignore such readily available side information.,abstractText,[0],[0]
"In this paper, we propose RESIDE, a distantly-supervised neural relation extraction method which utilizes additional side information from KBs for improved relation extraction.",abstractText,[0],[0]
It uses entity type and relation alias information for imposing soft constraints while predicting relations.,abstractText,[0],[0]
RESIDE employs Graph Convolution Networks (GCN) to encode syntactic information from text and improves performance even when limited side information is available.,abstractText,[0],[0]
"Through extensive experiments on benchmark datasets, we demonstrate RESIDE’s effectiveness.",abstractText,[0],[0]
We have made RESIDE’s source code available to encourage reproducible research.,abstractText,[0],[0]
RESIDE: Improving Distantly-Supervised Neural Relation Extraction using Side Information,title,[0],[0]
"The spread of data-driven decision making to civic institutions, spurred by the empirical success of machine learning and the growing availability of individual-level data, raises
This material is based upon work supported by the National Science Foundation under Grant No. 1656996.",1. Introduction,[0],[0]
Angela Zhou is supported through the National Defense Science & Engineering Graduate Fellowship Program.,1. Introduction,[0],[0]
"1Cornell University, and Cornell Tech, New York 2Cornell University, Ithaca, New York.",1. Introduction,[0],[0]
Correspondence to: Angela Zhou,1. Introduction,[0],[0]
"<az434@cornell.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
new questions about the possible harms of learning from data which is subject to historical bias.,1. Introduction,[0],[0]
"Unlike clean-cut prediction problems in other domains, datasets of individuals and their historical outcomes may reflect systematic bias due to previously prejudiced decisions (Barocas & Selbst, 2014).",1. Introduction,[0],[0]
"Recent work on fairness in machine learning proposes and analyzes competing criteria for assessing the fairness of machine learning algorithms, where some adjustments attempt to equalize accuracy metrics across groups (Corbett-Davies et al., 2017; Kleinberg et al., 2017; Hardt et al., 2016).",1. Introduction,[0],[0]
"Other work studies how historical prejudices may be reflected in training data such that algorithmic systems might replicate historical biases (Angwin et al., 2016; Lum & Isaac, 2016; Kilbertus et al., 2017).",1. Introduction,[0],[0]
We consider a model of biased data where systematic censoring affects whether or not entire observations appear in the training dataset.,1. Introduction,[0],[0]
"In such cases, the available data are not representative of the eventual realworld “test” population to which any resulting learned policy will be applied.",1. Introduction,[0],[0]
"Our paper formalizes and characterizes how systematic under- or over-representation of groups in the dataset can hamper attempts to correct for fairness, leading to residual unfairness on the target population of interest.
",1. Introduction,[0],[0]
"This important issue arises in almost all settings where fair machine learning has been studied:
(1) Data on loan default can only be collected on those loan applicants who were historically approved but is used to learn approval policies applied to all applicants.",1. Introduction,[0],[0]
"(2) Arrest data help build predictive policing models but these data are disproportionately collected on individuals in highly patrolled areas and may be subject to further prejudice at the individual level, including racial (Lum & Isaac, 2016).",1. Introduction,[0],[0]
"(3) Risk assessment and intervention tools in child welfare agencies are trained on cases which have been “screened in” by caseworkers based on external reports (Chouldechova et al., 2018).",1. Introduction,[0],[0]
"(4) Defendants may only flee and fail to appear if not detained, so any flight risk score used for setting bail can only be learned from data on defendants who were not detained.",1. Introduction,[0],[0]
"(5) Convict recidivism is impacted by sentence applied but learned risk scores are applied to all convicts.
",1. Introduction,[0],[0]
"In these applications, systematic censoring screens out ob-
servations of individuals and their outcomes from a training dataset.",1. Introduction,[0],[0]
"Such censoring may reflect historical decisions made with limited access to information, heterogeneous decision-makers, or the application of statistically discriminatory rules (Arrow, 1973).",1. Introduction,[0],[0]
"Despite the intermediate screening, domain-level restrictions may require ensuring fairness of any decision or prediction policy with respect to the original population.",1. Introduction,[0],[0]
"We formalize this mechanism as a data setting (Fig. 1) where a historical decision policy Z 2 {0, 1} specifies whether an instance will be included in the dataset.",1. Introduction,[0],[0]
"Systematic censoring may induce covariate shift on population-level estimands, such as true positive rate, as outcomes are observed in the training data only where Z = 1.",1. Introduction,[0],[0]
"Notably, predictive tools built on these censored datasets are actively being deployed: there is an opportunity to improve upon standards of practice, but the structural implications of systematically censored data ought to be accounted for (Angwin et al., 2016; Capatosto, 2017; LJAF, 2015).",1. Introduction,[0],[0]
"Our contributions are as follows:
• We characterize when systematic censoring induces residual unfairness in terms of the distributions of the conditional Bayes-optimal risk score across censored and target groups.",1. Introduction,[0],[0]
"• When benchmark data is available, we show how to use sample re-weighting techniques to estimate accuracy metrics to adjust for fairness on the target population.",1. Introduction,[0],[0]
We show how the sample weights indicate what groups remain disadvantaged by residual unfairness.,1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
"We demonstrate how systematic inclusion can affect fairness adjustments on an empirical example with data from the application of the Stop, Question, and Frisk (SQF) policy of the City of New York Police Department (NYPD).
",1. Introduction,[0],[0]
"In settings where datasets can be subject to historical prejudice and decision policies ought to be truly fair on the general population, we argue it is paramount to carefully consider and account for the sampling process to ensure fairness on the true population.",1. Introduction,[0],[0]
"We consider the problem of learning a fair decision policy (classifier or threshold rule on a regressor) from a dataset
where each decision instance is characterized by observed covariates X 2 X (e.g., predictors of creditworthiness, criminality, etc), protected class A 2 [m] = {1, . . .",2. Problem Setting,[0],[0]
",m} (e.g., sex, race, etc), and label Y 2 {0, 1} (where Y = 1 is generally interpreted as the favorable label, e.g., “will pay back loan” or “will not reoffend”).
",2. Problem Setting,[0],[0]
Fig. 1 illustrates the construction of a biased training dataset in this setting.,2. Problem Setting,[0],[0]
"The indicator Z 2 {0, 1} specifies whether an instance is included in the post-censoring training data (e.g., “approved for a loan”) and another indicator T 2 {0, 1} specifying whether an instance belongs to the population to which the learned policy will be applied.",2. Problem Setting,[0],[0]
"For example, if T is the constant 1, the target population is that of all loan applicants.",2. Problem Setting,[0],[0]
"We sometimes call Z = 1 the logging policy in analogy to logged-bandit learning (Kallus, 2017; Swaminathan & Joachims, 2015), where the implementation of a (often unknown) historical policy resulted in limited bandit feedback on outcomes.",2. Problem Setting,[0],[0]
"Because a random sample from the target population is generally not available, the target population is different from the notion of a held-out “test” dataset used to evaluate predictive accuracy .
",2. Problem Setting,[0],[0]
"We consider the problem of determining a policy assigning labels Ŷ 2 {0, 1} that depends only on X,A but may be randomized (so Ŷ ?",2. Problem Setting,[0],[0]
"(Y, Z, T )",2. Problem Setting,[0],[0]
"| X,A).",2. Problem Setting,[0],[0]
"Labeled training data (X,A, Y ) is available from the Z = 1 population, so that only the conditional joint distribution of X,A, Y | Z",2. Problem Setting,[0],[0]
= 1 is characterized by this data.,2. Problem Setting,[0],[0]
"We may or may not also have unlabeled data from the T = 1 population, X,A | T = 1.
",2. Problem Setting,[0],[0]
"For concreteness, when discussing fairness criteria, we consider the specific fairness criterion of equality of opportunity or equalized odds introduced by Hardt et al. (2016).",2. Problem Setting,[0],[0]
The adjustment determines a fair policy Ŷ from a (possibly discriminatory) black-box binary predictor or score R̂ without access to the original training data.,2. Problem Setting,[0],[0]
"They identify two particular types of fairness, equal opportunity and equalized odds, which require that a fairness-adjusted policy Ŷ be independent of class A given a positive label Y = 1 or given any label Y , respectively.",2. Problem Setting,[0],[0]
"For loan approval, equality of opportunity requires that the policy treat truly creditworthy individuals the same, independent of protected class membership.",2. Problem Setting,[0],[0]
"Equalized odds prohibits abusing class membership as an unfair proxy for Y (e.g., via stereotyping or racial profiling).",2. Problem Setting,[0],[0]
"For our setting, to be explicit, we define these relative to an event: Definition 1.",2. Problem Setting,[0],[0]
"A policy Ŷ satisfies equalized odds with respect to (wrt) class variable A and event E if
Ŷ ?",2. Problem Setting,[0],[0]
"A | Y = y,E (1)
holds for y 2 {0, 1}.",2. Problem Setting,[0],[0]
"A policy satisfies equal opportunity wrt A and E if eq. (1) holds for y = 1.
",2. Problem Setting,[0],[0]
"For brevity, we will say a policy is simply fair to mean either equal opportunity or equalized odds.",2. Problem Setting,[0],[0]
"Hardt et al.
(2016) determine such a policy by a post-processing step given a score R̂ using a constrained optimization problem over group-specific thresholds (potentially randomized), enforcing the constraints in eq. (1) on the true positive rate and/or false positive rate across groups while optimizing a given classification loss.",2. Problem Setting,[0],[0]
"Specifically, define F E
a (✓) =",2. Problem Setting,[0],[0]
"Pr[R̂  ✓ | Y = 1, A = a,E] as the conditional CDF (cumulative distribution function) of the score given the event E and Y = 1.",2. Problem Setting,[0],[0]
"For a given true positive rate ⇢, the corresponding derived equal opportunity classifier at rate ⇢ is given by Ŷ = I[R̂ >",2. Problem Setting,[0],[0]
"✓
A ], where ✓ a = (F a ) 1(1 ⇢) is the threshold corresponding to group a so that it has true positive rate ⇢.",2. Problem Setting,[0],[0]
"Note that FZ=1
a
, F T=1 a are the false negative rates for a threshold classifier as evaluated on the censored and target population, respectively.",2. Problem Setting,[0],[0]
"Naturally, a policy is actually fair if it is fair on the population to which it is applied (here, T = 1).",2. Problem Setting,[0],[0]
"So, in seeking a fair policy per these definitions, we seek a policy that satisfies equal opportunity or equalized odds on the target population wrt class variable A and the event T = 1, while the approach of Hardt et al. (2016) applied directly to training data achieves fairness wrt A and the event Z = 1.",2. Problem Setting,[0],[0]
"Throughout, we assume R̂ 2 [0, 1].",2. Problem Setting,[0],[0]
Fairness and Missing Data.,3. Related Work,[0],[0]
Research on fairness and machine learning has considered some subcomponents of the overall problem we study of learning fair policies from biased datasets.,3. Related Work,[0],[0]
Hardt et al. (2016) formalize the criteria of equal opportunity and equalized odds.,3. Related Work,[0],[0]
"Lum & Isaac (2016) show that a predictive policing algorithm for drug enforcement in Oakland, trained on police records, will perpetuate disparate enforcement.",3. Related Work,[0],[0]
"Ensign et al. (2017) consider a discrete model of how beliefs of crime rates in different areas adjust after observing arrest rates, and propose implementing the Horvitz-Thompson estimator via rejection sampling of arrest observations in an “online” fashion.",3. Related Work,[0],[0]
Lakkaraju et al. (2017) identify a similar structural setting with “selective labels” where they learn a decision rule for pre-trial risk assessment from the decisions made from judges (which affect whether or not the outcome of interest will be observed).,3. Related Work,[0],[0]
"They leverage the heterogeneity of heterogeneous decision makers using different decision thresholds to identify subpopulations for comparison but do not consider the subsequent fairness of the learned policy.
",3. Related Work,[0],[0]
Sampling Adjustment and Superpopulations.,3. Related Work,[0],[0]
"Sampling adjustment and re-weighting is commonly used in the social sciences, medicine, and epidemiology for ensuring the validity of population-level inference where there is population mismatch between studies and the population of interest (Thompson, 2012; Freedman & Berk, 2008).",3. Related Work,[0],[0]
"The classic Horvitz-Thompson estimator uses the inverse probability of sampling probability weights and is unbiased for
population level estimates (Horvitz & Thompson, 1952).",3. Related Work,[0],[0]
"Much of the work on fairness in machine learning has used population-level statistics such as accuracy metrics (true positive rate, false negative rate) as metrics for identifying disparate impact.",3. Related Work,[0],[0]
"The case of sample selection bias was studied in Zadrozny (2004) for classifier evaluation, without regard for fairness impacts.",3. Related Work,[0],[0]
"We study how prejudicial biases in a dataset can lead to residual unfairness, which persists even after fairness adjustment if error parity metrics assessed from the censored dataset are used.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"We show that the residual unfairness that remains even after adjustment will disadvantage the same group that was prejudiced against before, in the training data.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"This proves that even after fairness adjustment, fair machine learning still has a “bias in, bias out” property.
","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
An Illustrative Synthetic Example:,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"Loan Application To illustrate the potential impact of population mismatch on fairness adjustments in a controlled setting, we consider a synthetic example for loan approval.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"Suppose there are two classes, with half of the population of loan applicants in class 0 and the other half in class 1.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
We let T = 1 be constant as we wish to consider the impact of our policy on the whole population of loan applicants.,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"We denote by X1 the (normalized) number of bank accounts and by X2 the (normalized) number of delinquent payments on record, including those for subprime loans.1
Suppose X is distributed as a standard bivariate normal conditioned on class, with a mean of (1, 0) among individuals
1The setting is motivated by systematic associations found in studies of the credit scores suggesting disadvantages for younger applicants and recent immigrants due to policies incorporating number of accounts (Board of Governors of the Federal Reserve System, 1997; Rice & Swesnik, 2014).
in the class A = 0 and a mean of (0, 1) among individuals in the underprivileged class A = 1.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"Consider Y 2 {0, 1} indicating whether the individual will pay back the loan if it were approved.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"Suppose Y is logistic in X conditioned on class with P (Y = 1 | X,A) =","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"( T
A X), where (t) =","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"1/(1 + e t) and 0 = (1, 1), 1 = (1.25, 1) so that X2 is predictive of creditworthiness in both classes but X1 is slightly more predictive in class A = 1 than in A = 0.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
Suppose the training data comes from historically approved loans where loans were approved based on X in such a way that P (Z = 1 | X) =,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"( T
a
X).
","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"In Figs. 2a–2b we consider deriving a fair classifier for loan approval from the class-blind Bayes optimal score R̂ = P (Y = 1 | X,T = 1) =","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"P (Y = 1 | X,Z = 1), which is the same in training and target populations by construction and which we assume is given (e.g., it can be identified from the training data regardless of any covariate shift between Z = 1 and T = 1; see Sec. 4.2).","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"We simulate n = 100000 data points and censor the outcome for those with Z
i = 0.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
First we consider deriving an adjusted predictor from the Bayes-optimal classifier Ŷ = I[R̂ 0.5] by naı̈vely applying the method of Hardt et al. (2016).,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
Fig.,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"2a shows the space of achievable FPR-TPR in the training (censored) and target (full) populations along with the optimal equalized odds and equal opportunity rates corresponding to the symmetric loss `(y, y0) =","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
I[y 6= y0].,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"As can be seen, there is a significant discrepancy between the regions in the censored vs. full population.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"Next, we consider deriving optimal equal opportunity policies from the score","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
R̂. Fig.,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"2b shows the range of optimal policies, which is given by class-based thresholds, as we range the exchange rate between typeI and -II errors (false positives vs. false negatives).","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
We also show the result from using a reweighting approach that we discuss in Sec. 5.,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"We note that a naı̈ve application of fairness adjustment provides insufficient compensation for the unfairness toward the underprivileged class A = 1: for every threshold on class A = 0, the corresponding threshold on class A = 1 is always higher for the policy derived in the naı̈ve manner compared to that derived either using the full data or using our reweighting approach, such that the spuriously fair policy is systematically and uniformly harsher than necessary on the disadvantaged class.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
We now formalize the phenomenon illustrated in the example as residual unfairness and study why and when it arises in terms of the biases in training data due to existing prejudiced policies.,4.1. Disparate Benefit of the Doubt,[0],[0]
"For concreteness, we focus on the equality of opportunity criterion.",4.1. Disparate Benefit of the Doubt,[0],[0]
Many of our results can be easily extended to other observational fairness criteria.,4.1. Disparate Benefit of the Doubt,[0],[0]
"To quantify the extent to which the criterion is satisfied or violated, and in which direction, we define the inequity of opportunity.",4.1. Disparate Benefit of the Doubt,[0],[0]
Definition 2 (Inequity of Opportunity).,4.1. Disparate Benefit of the Doubt,[0],[0]
"The inequity of
opportunity between classes A = a and A = b wrt to event E under policy Ŷ is defined as
✏
E
a,b = P(Ŷ = 1 | E,A=a, Y=1 )",4.1. Disparate Benefit of the Doubt,[0],[0]
"P(Ŷ = 1 | E,A=b, Y=1 )
",4.1. Disparate Benefit of the Doubt,[0],[0]
"Positive values in the target population, ✏T=1 a,b > 0, indicate unfairness against group b. Zero inequity between all groups corresponds to equality of opportunity.",4.1. Disparate Benefit of the Doubt,[0],[0]
"A policy that is adjusted to be equal-opportunity or equalized-odds fair on the training data has ✏Z=1
a,b = 0.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Thus, any nonzero value of ✏T=1
a,b for such a policy constitutes a residual unfairness corresponding to the additional unadjusted-for inequity introduced by going from the Z = 1 to the T = 1 population.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"Intuitively, if censoring induces a spuriously higher or lower overall distribution of scores than in the true population, we might learn a higher or lower threshold from the training data.",4.1. Disparate Benefit of the Doubt,[0],[0]
"If the true distribution will have more people with comparatively lower scores, the rate of false negatives will increase in the true population.",4.1. Disparate Benefit of the Doubt,[0],[0]
"This is to be expected if the censoring decision Z = 1 has itself an associated risk or cost, such as giving a loan.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Differences in the extent and effects of this censoring between groups, which is what we will define as disparate benefit of the doubt, can then give rise to non-zero residual inequity.",4.1. Disparate Benefit of the Doubt,[0],[0]
"This may occur if the censoring mechanism subjects the disadvantaged group to harsher screening than the advantaged group, so that disadvantaged screened-in individuals have higher probabilities of being positive (e.g., innocent or creditworthy) given the observables X,A.
We next derive three sufficient conditions for residual unfairness.",4.1. Disparate Benefit of the Doubt,[0],[0]
We explain how these can be interpreted in terms of the logging policy Z = 1 bestowing disparate benefit of the doubt with respect to the positive outcome Y,4.1. Disparate Benefit of the Doubt,[0],[0]
= 1 on the different groups.,4.1. Disparate Benefit of the Doubt,[0],[0]
"This disparate benefit of the doubt would be directly reflected in the distribution of risk scores in the training and target populations, which we will show necessarily leads to residual unfairness that disadvantages the same group that received comparatively lesser benefit of the doubt (or comparatively heightened suspicion), thus perpetuating historical prejudices.
",4.1. Disparate Benefit of the Doubt,[0],[0]
We first state a simple rephrasing of the residual inequity of opportunity left by a fairness adjustment.,4.1. Disparate Benefit of the Doubt,[0],[0]
"Recall that F
Z=1 a (✓), FT=1 a (✓) correspond to the false negative rate (FNR) when thresholding at ✓ on the training (censored) and test populations, respectively.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Let
a (✓) = FZ=1 a
(✓) F
T=1",4.1. Disparate Benefit of the Doubt,[0],[0]
a (✓) denote the difference between true positive rates in the test population and training (censored) population.,4.1. Disparate Benefit of the Doubt,[0],[0]
Recall that Ŷ is an optimal derived equal opportunity classifier based on the training data if Ŷ = I[R̂ >,4.1. Disparate Benefit of the Doubt,[0],[0]
"✓
A ] and F
Z=1 a (✓ a ) = FZ=1 b",4.1. Disparate Benefit of the Doubt,[0],[0]
"(✓ b ) for every two groups a, b.2",4.1. Disparate Benefit of the Doubt,[0],[0]
"For short we refer to such a classifier as a derived equal oppor-
2Specifically, that the set of derived equal opportunity classi-
tunity classifier.
",4.1. Disparate Benefit of the Doubt,[0],[0]
Proposition 1.,4.1. Disparate Benefit of the Doubt,[0],[0]
Let Ŷ = I[R̂,4.1. Disparate Benefit of the Doubt,[0],[0]
>,4.1. Disparate Benefit of the Doubt,[0],[0]
✓ A ] be a derived equal opportunity classifier.,4.1. Disparate Benefit of the Doubt,[0],[0]
"Then ✏T=1
a,b
= a (✓ a ) b (✓ b ).
",4.1. Disparate Benefit of the Doubt,[0],[0]
"Next, we define first-order stochastic dominance, which we use to express our first characterization of disparate benefit of the doubt.
",4.1. Disparate Benefit of the Doubt,[0],[0]
Definition 3 (First-order stochastic dominance).,4.1. Disparate Benefit of the Doubt,[0],[0]
"Let F , G be two CDFs.",4.1. Disparate Benefit of the Doubt,[0],[0]
"We write F G whenever F (✓) G(✓) 8✓.
CDFs describe the distribution of a population of real values.",4.1. Disparate Benefit of the Doubt,[0],[0]
"The stochastic dominance F G means that the population described by F has overall smaller values than the population described by G. Specifically, F G is equivalent to saying that for each unit in the population described by F we can find a nonnegative number such that, when added to each unit, the whole population looks like that described by G (Mas-Colell et al., 1997).",4.1. Disparate Benefit of the Doubt,[0],[0]
"That is, each unit from F can be uniquely paired with a unit from G such that the former has a smaller or equal value than the latter (allowing fractional or infinitesimal “units”).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Alternatively, F G holds if and only if the average of every increasing function in the F population is smaller than or equal to the corresponding average in the G population (Fishburn, 1980).",4.1. Disparate Benefit of the Doubt,[0],[0]
"This says that any rational actor with an increasing utility function would gain utility in choosing G over F and lose utility in choosing F over G (or get the same utility).
",4.1. Disparate Benefit of the Doubt,[0],[0]
Proposition 2 (Strong disparate benefit of the doubt).,4.1. Disparate Benefit of the Doubt,[0],[0]
"Suppose that
F Z=1",4.1. Disparate Benefit of the Doubt,[0],[0]
a FT=1 a and FZ=1 b ⌫ FT=1,4.1. Disparate Benefit of the Doubt,[0],[0]
"b
(2)
while not both are equalities, i.e., either FZ=1",4.1. Disparate Benefit of the Doubt,[0],[0]
a 6= FT=1,4.1. Disparate Benefit of the Doubt,[0],[0]
a or FZ=1 b 6= FT=1,4.1. Disparate Benefit of the Doubt,[0],[0]
"b
(or both).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Then every derived equal opportunity classifier has nonnegative inequity of opportunity for group b relative to group a (✏T=1
a,b 0) and at least one derived equal opportunity classifier will have a strictly positive inequity of opportunity disadvantaging group b relative to group a (✏T=1
a,b
> 0).
",4.1. Disparate Benefit of the Doubt,[0],[0]
"The condition in eq. (2) requires that the distribution of scores among positive group-a members is overall smaller in the training data than in the target population, while the opposite is true for group b. Recall that scores represent the probability of having the positive, favorable label (more on this in Sec. 4.2).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Thus, the condition says that positive group-a members received more benefit of the doubt when
fiers that are optimal with respect to some trade off between type-I and -II errors is exactly equal to the set of all such thresholding classifiers requires only that we assume that, in each group A = a, R̂ is not worse than random guessing and that the ROC is convex.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Neither is without loss of generality as seen by only improving R̂ by conditionally (on A) negating R̂ and/or randomizing its value in nonconvex intervals between the endpoints.
being screened-in into the training data than positive groupb members.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Prop. 2 shows that this will necessarily lead to group-b being further disadvantaged in the future even after correcting for equality of opportunity.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"In the context of loan application, where we can think about the score as a credit score, eq. (2) means that the logging policy (i.e., historical loan approval practice) effectively dug deeper into the pile of creditworthy group-a applicants than for group-b applicants, giving the former more benefit of the doubt as to their creditworthiness based on their credit scores than it gave the latter.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Seen via the equivalent utility-based interpretation of stochastic dominance, given any increasing utility function, if eq. (2) holds then the logging policy is losing utility on group-a via lax screening while gaining utility on group-b by being less lax.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"The complement (or, negative) of the score can be thought of as a risk score: the probability of the unfavorable label.",4.1. Disparate Benefit of the Doubt,[0],[0]
Eq. (2) can equivalently be written as the opposite ordering on risk scores rather than positivity scores.,4.1. Disparate Benefit of the Doubt,[0],[0]
"Thus, in either a judicial bail- or sentence-setting context or in a predictive policing context, eq. (2) means that the logging policy (i.e., historical criminal justice or policing practice) was harsher on group b than on group a, screening-in lower risk scores for innocent group-b members compared to the group-b population while screening-in only higher risk scores for group-a members, giving them more benefit of the doubt as to their innocence based on observables.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"If the CDFs are nowhere equal except for at 0 and 1 (where they are always equal) then a strict version of Prop. 2 shows that every derived equal opportunity classifier will be unfair.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"Proposition 3 (Strong disparate benefit of the doubt, strict).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Suppose eq. (2) holds and that FZ=1
a (✓) 6=",4.1. Disparate Benefit of the Doubt,[0],[0]
"F
T=1 a (✓), FZ=1 b (✓) 6=",4.1. Disparate Benefit of the Doubt,[0],[0]
"FT=1 b (✓) for all ✓ 2 (0, 1).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Then every nontrivial derived equal opportunity classifier will have strictly positive inequity of opportunity disadvantaging group b relative to group a.
A nontrivial classifier is any classifier that is neither the constant Ŷ = 0 nor the constant Ŷ = 1.
",4.1. Disparate Benefit of the Doubt,[0],[0]
The conditions in Props.,4.1. Disparate Benefit of the Doubt,[0],[0]
2 and 3 are easy to interpret via stochastic dominance but may be too strong to hold in practice.,4.1. Disparate Benefit of the Doubt,[0],[0]
"In particular, suppose the decision Z = 1 itself has a benefit or risk related to whether Y = 1, as in the case of giving a loan (benefit of earning the full interest over loan term compared to risk of a default) or a police stop (benefit of curtailing crime compared to costs, including societal, of aggressive policing).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Then, if the decision Z = 1 is exercised rationally, then we would expect that the distribution of scores is either overall higher (e.g., for loans) or overall lower (e.g., for police stops) in the training population regardless of group, i.e., both FZ=1
a
⌫ FT=1 a and FZ=1 b ⌫ F
T=1 b or both FZ=1 a
FT=1 a and FZ=1 b
FT=1 b .",4.1. Disparate Benefit of the Doubt,[0],[0]
"(Al-
though, prejudice in Z = 1 can be so overt and/or irrational for this not to hold.)",4.1. Disparate Benefit of the Doubt,[0],[0]
"If this is the case, then the conditions of Props.",4.1. Disparate Benefit of the Doubt,[0],[0]
"2 and 3 cannot hold and we must relax them.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"The next result shows that even if the stochastic dominance holds in the same direction for both groups, if the magnitude of the dominance is overall larger in one group compared to the other for a large swath of thresholds then most derived equal opportunity classifiers will actually be unfair and disadvantage the historically disadvantaged.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Proposition 4 (Weak disparate benefit of the doubt, strict).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Let ✓, ✓ be such that
a (✓) >",4.1. Disparate Benefit of the Doubt,[0],[0]
"b
(✓0) 8✓, ✓0 2 (✓, ✓).",4.1. Disparate Benefit of the Doubt,[0],[0]
"(3)
Let Ŷ = I[R̂ >",4.1. Disparate Benefit of the Doubt,[0],[0]
✓ A ] be a derived equal opportunity classifier.,4.1. Disparate Benefit of the Doubt,[0],[0]
"If ✓
a
, ✓
b 2 (✓, ✓), then Ŷ induces a strictly positive inequality of opportunity disadvantaging group b relative to group a.
Note that, since A (0) =",4.1. Disparate Benefit of the Doubt,[0],[0]
"A (1) = 0, we have that eq.",4.1. Disparate Benefit of the Doubt,[0],[0]
"(3) holds for (✓, ✓) = (0, 1) if and only if the conditions of Prop. 3 hold.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Therefore, for general (✓, ✓) the former can be understood as a relaxation of the latter.
",4.1. Disparate Benefit of the Doubt,[0],[0]
We can illustrate the conditions of Prop. 4 in the synthetic loan application example from the beginning of this section.,4.1. Disparate Benefit of the Doubt,[0],[0]
In Fig.,4.1. Disparate Benefit of the Doubt,[0],[0]
"3b, we plot the two
A functions and shade a large interval where eq.",4.1. Disparate Benefit of the Doubt,[0],[0]
(3) holds.,4.1. Disparate Benefit of the Doubt,[0],[0]
"In Fig. 3a, we plot the CDFs F E
A and further shade the corresponding regions of false negative rates for which both ✓0 and ✓1 lie the previously shaded interval.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Taking complements, this shows that any derived equal opportunity classifier adjusted to have equal true positive rates of 0.58–0.95 on the training data will disadvantage the underprivileged class despite one’s attempt to adjust against this situation.
",4.1. Disparate Benefit of the Doubt,[0],[0]
We can slightly relax the condition in eq.,4.1. Disparate Benefit of the Doubt,[0],[0]
"(3) whenever dealing with groups that have disparate endowments of scores, as in the example above where the scores of group 0 are overall larger than those of group 1 in terms of stochastic dominance.
",4.1. Disparate Benefit of the Doubt,[0],[0]
Proposition 5 (Weak disparate benefit of the doubt on disparately endowed groups).,4.1. Disparate Benefit of the Doubt,[0],[0]
"Let ✓, ✓ be such that
a (✓) >",4.1. Disparate Benefit of the Doubt,[0],[0]
"b
(✓0) 8✓, ✓0 2 (✓, ✓) : ✓ ✓0.",4.1. Disparate Benefit of the Doubt,[0],[0]
"(4)
Suppose FZ=1 a ⌫ FZ=1 b .",4.1. Disparate Benefit of the Doubt,[0],[0]
Let Ŷ = I[R̂,4.1. Disparate Benefit of the Doubt,[0],[0]
>,4.1. Disparate Benefit of the Doubt,[0],[0]
✓ A ] be a derived equal opportunity classifier.,4.1. Disparate Benefit of the Doubt,[0],[0]
"If ✓
a
, ✓
b 2 (✓, ✓), then Ŷ induces a strictly positive inequality of opportunity disadvantaging group b relative to group a.
In the supplemental Sec.",4.1. Disparate Benefit of the Doubt,[0],[0]
B we also include an illustration of weak disparate benefit of the doubt in a real dataset of credit card applications and payment defaults.,4.1. Disparate Benefit of the Doubt,[0],[0]
"In addition to making more concrete our crediting example, this also serves to illustrate the weaker condition in eq. (4).
",4.1. Disparate Benefit of the Doubt,[0],[0]
"All of our results in this section can be equivalently stated for true negative rates instead of true positive rates, in which case the corresponding conditions such as that in eq.",4.1. Disparate Benefit of the Doubt,[0],[0]
"(2) can instead be interpreted as disparate suspicion, i.e., the disparate scrutiny of truly criminal or credit-unworthy individuals.",4.1. Disparate Benefit of the Doubt,[0],[0]
"So, whereas our notion of disparate benefit of the doubt corresponds to the phenomenon of “driving while black” (Lamberth, 1998), our notion of disparate suspicion would correspond to the phenomenon of “criming while white” (Goldfarb, 2014).",4.1. Disparate Benefit of the Doubt,[0],[0]
"If either disparate benefit of the doubt or disparate suspicion is present, a derived equalized odds classifier will in fact violate equalized odds in a way that disadvantages the same group that was disadvantaged by the disparate benefit of the doubt or suspicion.",4.1. Disparate Benefit of the Doubt,[0],[0]
In the above we interpreted the conditions in our results as disparities in the distributions of positivity or risk scores among different groups in the training and target populations.,4.2. Interpretation of Scores Under MAR,[0],[0]
"Specifically, we interpreted these scores as corresponding to the probabilities of having a positive or negative label given observables.",4.2. Interpretation of Scores Under MAR,[0],[0]
"In full generality, however, this probability might actually be different in the training and target populations, i.e., P (Y = 1 | X,A,Z = 1) 6=",4.2. Interpretation of Scores Under MAR,[0],[0]
"P (Y = 1 | X,A, T = 1).",4.2. Interpretation of Scores Under MAR,[0],[0]
"Since naturally only the training data is available at training we can consider the trainingpopulation Bayes score R̂ = P (Y = 1 | X,A,Z = 1) and interpret disparities as disparities in benefit of the doubt of positivity given this score.",4.2. Interpretation of Scores Under MAR,[0],[0]
"This is consistent with our interpretation above.
",4.2. Interpretation of Scores Under MAR,[0],[0]
"However, whenever censoring Z = 1 is itself based on observables, the data will be missing conditionally at random (MAR) and these probabilities will actually be the same so that we can interpret the scores as simply the probability of positivity given observables generally.",4.2. Interpretation of Scores Under MAR,[0],[0]
Assumption 1.,4.2. Interpretation of Scores Under MAR,[0],[0]
(MAR) Z ?,4.2. Interpretation of Scores Under MAR,[0],[0]
"Y | X,A and T ?",4.2. Interpretation of Scores Under MAR,[0],[0]
"Y | X,A.
Under MAR, it is immediate that the Bayes score satisfies R̂ = P (Y = 1 | X,A) = P (Y = 1 | X,A,Z = 1) =
P (Y = 1 | X,A, T = 1), which can be consistently estimated from training data.",4.2. Interpretation of Scores Under MAR,[0],[0]
"In fact, under MAR, the optimal (unrestricted) decision function in X,A minimizing the average over Z = 1 of any loss in Y is the same as that minimizing the average loss over T = 1.
MAR requires that the missingness is unrelated to outcome after controlling for the observables.",4.2. Interpretation of Scores Under MAR,[0],[0]
"This assumption is clearly satisfied in the common case when T = 1 is constant and only X,A (or just X) were taken into consideration for a randomized inclusion policy Z. In the examples laid out in Sec. 1, this is an appropriate assumption because the censoring mechanism does not observe outcomes Y a priori, only observable characteristics (including the protected attribute).",4.2. Interpretation of Scores Under MAR,[0],[0]
"However, violations of MAR may occur, for example in the loan case if applicants may choose an outside option, selfcensoring the observation of a default while the availability of these options is related to creditworthiness.",4.2. Interpretation of Scores Under MAR,[0],[0]
"In rare situations, we may have additional information about the target population such as an unlabeled dataset.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"We next show how we can use such data to evaluate accuracy metrics on the target population, as long as data is MAR.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"This will allow us to assess the residual unfairness of fairness adjusted classifiers, as we will do in our study of SQF, and to correctly adjust for fairness, as we have done in Fig. 2b.
",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Let p(x, a) = P(T=1|X=x,A=a)P(Z=1|X=x,A=a) be the propensity score ratio between the target and training populations.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"This ratio is a standard way to adjust for systematic covariate shift for evaluating averages in the target (Horvitz & Thompson, 1952; Bottou et al., 2012).",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
We next state how a weighting score that’s equal to it up to proportionality in a can be used for evaluating true positive rates.,5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
Proposition 6.,5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Suppose p̃(x, a) = r(a)p(x, a) for some r(a) and Ŷ ?",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"(Y, Z, T )",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"| X,A.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Then, under Assumption 1, P(Ŷ = 1 | Y = y,A = a, T = 1) is equal to
E[I[Ŷ=1,Y=y,A=a]p̃(X,A)|Z=1]P ŷ2{0,1} E[I[Ŷ=ŷ,Y=y,Z=1,A=a]p̃(X,A)|Z=1]
(5)
",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Given p̃(x, a), the quantity in eq. (5) involves only the distribution of the training data.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"In practice, the expectations in it can be estimated using empirical averages over the training data.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Therefore, if we can compute an appropriate weighting function p̃(x, a), Prop. 6 provides a remedy to the problem of biased data: we may simply replace the condition in Def. 1, which involves an unknown distribution X,A, Y | T = 1, with the condition that eq. (5) is constant over a (for y 2 {0, 1} or for y = 1).",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"In particular, to apply the equality of opportunity adjustment on the target population, we need only compute the TPRs and/or FPRs of
any blackbox predictor using the adjustment of eq.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"(5) and proceed with the adjustment as usual.
",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Next we address when can we find an appropriate reweighting score p̃(x, a).",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
We consider two cases.,5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"If Z = 1 is a subpopulation of T = 1 and our data consists of iid draws from the target population population but where, naturally, only the Z = 1 units are labeled, then may simply let p̃(x, a) be the reciprocal of the conditional probability of being labeled, which may be estimated using a probabilistic classification algorithm such as logistic regression.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"This case applies, for example, in the loan approval policy example if the data includes the full loan applications, whether they were approved, and whether the approved loans defaulted or were paid back.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"If, however, our data consists only of the labeled examples, as in the case of arrest and SQF data, which contain only the arrests or stops made and, naturally, never any information on those not made, then this case does not apply.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"But, if we have an unlabeled dataset from the target population, then we can separately estimate the distribution of X,A in the training and target distributions.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Then we may let p̃(x, a) be either the ratio of densities of X,A in T = 1 and Z = 1 or the ratio of densities of X in T = 1, A = a and Z = 1, A = a.
In supplemental Sec.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"C we provide additional results characterizing residual unfairness under MAR in terms of p̃(x, a).",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"We next study the Stop, Question, and Frisk dataset to illustrate how residual unfairness may occur with real data.","6. Case Study: Stop, Question, and Frisk",[0],[0]
We consider learning a predictor of criminal possession of a weapon from this dataset using logistic regression and then adjusting the policy to be fair on the training population.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
"The trained policy will be applied to the target population of New York City at large, where it will be shown to in fact be unfair.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"This residual unfairness can be explained by disparities between the training population (SQF stops) and the target population (NYC), which is evident from the divergent geographic distributions of these two as seen in Fig. 4.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"(Further details about SQF and the dataset are provided in the supplemental Sec. D.)
Table 2: Residual unfairness in SQF predictive targeting
Goel et al. (2016) considered learning predictors from this data as a way to assess the implied decision thresholds used for determining pedestrian stops related to the criteria of “reasonable suspicion.”","6. Case Study: Stop, Question, and Frisk",[0],[0]
"While the authors suggest that a logistic regression predictor of criminal possession of a weapon could be used as a secondary filter applied on those individuals targeted by officers, we instead consider training such a predictive model to guide whom to target for a stop and search and adjusting this targeting policy for fairness.
","6. Case Study: Stop, Question, and Frisk",[0],[0]
"We consider race to be the protected class A, with values Black, Black Hispanic, White, White Hispanic, and Other.3 Arrest data or SQF data only contain the arrests or stops made and, naturally, never any information on those not made.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"Since biases in the demographics of stop data arise from disproportionate policing by location and potential racial biases, we define the target population with respect to demographic data about NYC precincts.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"Letting X1 denote the precinct-encoding portion of the covariates and X2 denote all other covariates (which include 30 indicators of reasons for suspicion, sex, and location or stop), we set P(X1, A | T = 1) to be the same distribution as that of the population of NYC.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"We further assume that, once we condition on the main sources of bias, (X1, A), the covariates X2 are not disproportionate between the training and target distribution: we set P(X2 | A,X1, T = 1) = P(X2 | A,X1, Z = 1).","6. Case Study: Stop, Question, and Frisk",[0],[0]
"That is, the main sources of systematic bias with respect to censored data are contained in X1 and A, while ancillary covariates X2 are not proxies for discrimination.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"We then have that p̃(X,A) = P(A,X1|T=1)P(A,X1|Z=1) satisfies the conditions of Prop. 6","6. Case Study: Stop, Question, and Frisk",[0],[0]
"so we need only estimate P(A,X1 | Z = 1), P(A,X1 | T = 1).","6. Case Study: Stop, Question, and Frisk",[0],[0]
We estimate the former from the SQF data and the latter from the 2010 American Community Survey data by matching census blocks to precincts and using Laplace smoothing.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
"We clip the ratio weights at 10.
","6. Case Study: Stop, Question, and Frisk",[0],[0]
"Using the SQF data as is, we fit a logistic regression R̂ to predict the probability of innocence, that a search would not recover a weapon from those suspected of criminal possess-
3Due to the relative size of the Asian/Pacific Islander and Native American classes included in the original SQF dataset, we combine them with the Other (U) class.
","6. Case Study: Stop, Question, and Frisk",[0],[0]
ing one based on the covariates X .,"6. Case Study: Stop, Question, and Frisk",[0],[0]
Fig. 5 shows the FNR discrepancies between training and target and the ROCs in each.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
"We consider deriving both an equal opportunity classifier and an equalized odds classifier for a stop and search based on the SQF data to minimize false negatives and false positives at an exchange rate of 25:1.
","6. Case Study: Stop, Question, and Frisk",[0],[0]
"In Table 2, we report the estimated true positive and false positive rates achieved by these classifiers both in the training and in the target population.","6. Case Study: Stop, Question, and Frisk",[0],[0]
The latter is computed using Prop. 6.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
FNRs quantify the percent of innocents wrongly targeted and FPRs quantify the percent of criminals undetected.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
"By construction, the adjusted-for rates are equal in the training population (Z = 1).","6. Case Study: Stop, Question, and Frisk",[0],[0]
"However, in practice, residual unfairness remains in the target population even after adjustment, and both of these supposedly fair classifiers will systematically disadvantage the same groups that were previously disparately targeted.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"For the equal-opportunity-adjusted classifier, whereas only 11% of white-non-Hispanic innocents are wrongly targeted, up to 20% of white-Hispanic, 16% of other, and 14–15% of black innocents are wrongly targeted and harassed.","6. Case Study: Stop, Question, and Frisk",[0],[0]
Similar disparities exist for the equalized-odds-adjusted classifier.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
"The equalized odds policy, having been subject to additional constraints that require more randomization and hence less dependence on observables, induces smaller but still significant disparities and Hispanics remain particularly disproportionately burdened.
","6. Case Study: Stop, Question, and Frisk",[0],[0]
"In all cases, after fairness adjustment, non-white individuals were still unfairly disadvantaged in practice relative to white individuals, thus perpetuating the same biases that SQF is notorious for under the guise of a policy adjusted to be fair.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"Our work characterizes the problem of residual unfairness, which arises when policies learned from biased datasets are adjusted for fairness but remain unfair in practice.",7. Conclusion,[0],[0]
"We study a general setting where the dataset is generated under a prejudiced historical policy, which captures the structure of many problem settings where fairness has been considered.",7. Conclusion,[0],[0]
We prove that the same prejudices will be reflected in the supposedly-fairness-adjusted policy.,7. Conclusion,[0],[0]
Recent work in fairness in machine learning has proposed adjusting for fairness by equalizing accuracy metrics across groups and has also studied how datasets affected by historical prejudices may lead to unfair decision policies.,abstractText,[0],[0]
We connect these lines of work and study the residual unfairness that arises when a fairness-adjusted predictor is not actually fair on the target population due to systematic censoring of training data by existing biased policies.,abstractText,[0],[0]
This scenario is particularly common in the same applications where fairness is a concern.,abstractText,[0],[0]
We characterize theoretically the impact of such censoring on standard fairness metrics for binary classifiers and provide criteria for when residual unfairness may or may not appear.,abstractText,[0],[0]
"We prove that, under certain conditions, fairnessadjusted classifiers will in fact induce residual unfairness that perpetuates the same injustices, against the same groups, that biased the data to begin with, thus showing that even state-of-theart fair machine learning can have a “bias in, bias out” property.",abstractText,[0],[0]
"When certain benchmark data is available, we show how sample reweighting can estimate and adjust fairness metrics while accounting for censoring.",abstractText,[0],[0]
"We use this to study the case of Stop, Question, and Frisk (SQF) and demonstrate that attempting to adjust for fairness perpetuates the same injustices that the policy is infamous for.",abstractText,[0],[0]
Residual Unfairness in Fair Machine Learning from Prejudiced Data,title,[0],[0]
"Objective: This paper develops a novel tree-based algorithm, called Bonsai, which can be trained on a laptop, or the cloud, and can then be shipped onto severely resource constrained Internet of Things (IoT) devices.
",1. Introduction,[0],[0]
"Resource constrained devices: The Arduino Uno board has an 8 bit ATmega328P microcontroller operating at 16 MHz with 2 KB SRAM and 32 KB read-only flash mem-
1Microsoft Research, Bangalore, India 2CSE Department, IIT Delhi, India.",1. Introduction,[0],[0]
"Correspondence to: <manik@microsoft.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
ory.,1. Introduction,[0],[0]
The BBC Micro:Bit has a 32 bit ARM Cortex M0 microcontroller operating at 16 MHz with 16 KB SRAM and 256 KB read-only flash.,1. Introduction,[0],[0]
Neither provides hardware support for floating point operations.,1. Introduction,[0],[0]
"Billions of such tiny IoT microcontrollers have been deployed in the world (Meunier et al., 2014).",1. Introduction,[0],[0]
"Before deployment, the OS and all application code and data are burnt onto flash, leaving only a few KB for storing the trained ML model, prediction code, feature extraction code and associated data and parameters.",1. Introduction,[0],[0]
"After deployment, the only writable memory available is the 2 KB (Uno) or 16 KB (Micro:Bit) of SRAM which might not be sufficient to hold even a single feature vector.
",1. Introduction,[0],[0]
"The Internet of Things: A number of applications have been developed for consumer, enterprise and societal IoT including predictive maintenance, intelligent healthcare, smart cities and housing, etc.",1. Introduction,[0],[0]
"The dominant paradigm for these applications, given the severe resource constraints of IoT devices, has been that the IoT device is dumb – it just senses its environment and transmits the sensor readings to the cloud where all the decision making happens.
",1. Introduction,[0],[0]
Motivating scenarios: This paper proposes an alternative paradigm where the IoT device can make predictions locally without necessarily connecting to the cloud.,1. Introduction,[0],[0]
"This enables many scenarios, beyond the pale of the traditional paradigm, where it is not possible to transmit data to the cloud due to latency, bandwidth, privacy and energy concerns.",1. Introduction,[0],[0]
"For instance, consider a microcontroller implanted in the brain which warns patients about impending seizures so that they can call for help, pull over if they are driving, etc.",1. Introduction,[0],[0]
Making predictions locally would allow the device to work everywhere irrespective of cloud connectivity.,1. Introduction,[0],[0]
"Furthermore, alerts could be raised more quickly with local predictions than if all the sensor readings had to be first transmitted to the cloud.",1. Introduction,[0],[0]
"In addition, since the energy required for executing an instruction might be much lower than the energy required to transmit a byte, making predictions locally would extend battery life significantly thereby avoiding repeated brain surgery and might also prevent brain tissue damage due to excess heat dissipation from the communicating radio.",1. Introduction,[0],[0]
"Finally, people might not be willing to transmit such sensitive data to the cloud.",1. Introduction,[0],[0]
"These characteristics are shared by many other scenarios including implants in the heart, precision agriculture on disconnected farms, smart spectacles for the visually impaired, etc.
Tree algorithms: Tree algorithms are general and can be used for classification, regression, ranking and other problems commonly found in the IoT setting.",1. Introduction,[0],[0]
"Even more importantly, they are ideally suited to IoT applications as they can achieve good prediction accuracies with prediction times and energies that are logarithmic in the number of training points.",1. Introduction,[0],[0]
"Unfortunately, they do not directly fit on tiny IoT devices as their space complexity is linear rather than logarithmic.",1. Introduction,[0],[0]
"In particular, learning shallow trees, or aggressively pruning deep trees or large ensembles, to fit in just a few KB often leads to poor prediction accuracy.
",1. Introduction,[0],[0]
Bonsai:,1. Introduction,[0],[0]
"This paper develops a novel tree learner, called Bonsai, designed specifically for severely resource constrained IoT devices based on the following contributions.",1. Introduction,[0],[0]
"First, Bonsai learns a single, shallow, sparse tree so as to reduce model size but with powerful nodes for accurate prediction.",1. Introduction,[0],[0]
"Second, both internal and leaf nodes in Bonsai make non-linear predictions.",1. Introduction,[0],[0]
Bonsai’s overall prediction for a point is the sum of the individual node predictions along the path traversed by the point.,1. Introduction,[0],[0]
Path based prediction allows Bonsai to accurately learn non-linear decision boundaries while sharing parameters along paths to further reduce model size.,1. Introduction,[0],[0]
"Third, Bonsai learns a sparse matrix which projects all data points into a low-dimensional space in which the tree is learnt.",1. Introduction,[0],[0]
This allows Bonsai to fit in a few KB of flash.,1. Introduction,[0],[0]
"Furthermore, the sparse projection is implemented in a streaming fashion thereby allowing Bonsai to tackle IoT applications where even a single feature vector might not fit in 2 KB of RAM.",1. Introduction,[0],[0]
"Fourth, rather than learning the Bonsai tree node by node in a greedy fashion, all nodes are learnt jointly, along with the sparse projection matrix, so as to optimally allocate memory budgets to each node while maximising prediction accuracy.
",1. Introduction,[0],[0]
Implementation: Another contribution is an efficient implementation of Bonsai which reduces its prediction costs on the Arduino and Micro:Bit to be even lower than that of an unoptimized linear classifier.,1. Introduction,[0],[0]
This allows Bonsai to enjoy the prediction accuracy of a non-linear classifier while paying less than linear costs.,1. Introduction,[0],[0]
"This paper does not focus on the system and implementation details due to space limitations but the interested reader is referred to the publically available source code (BonsaiCode).
",1. Introduction,[0],[0]
"Results: These contributions allow Bonsai to make predictions in milliseconds even on slow microcontrollers, fit in a few KB of flash and extend battery life beyond all other algorithms.",1. Introduction,[0],[0]
"Furthermore, it is demonstrated on multiple benchmark datasets that Bonsai’s prediction accuracies can approach those of uncompressed kNN classifiers, RBFSVMs, single hidden layer neural networks and gradient boosted decision tree ensembles whose models might take many MB of RAM.",1. Introduction,[0],[0]
"It is also demonstrated that Bonsai’s prediction accuracies for a given model size can be as much
as 30% higher than state-of-the-art methods for resourceefficient machine learning.",1. Introduction,[0],[0]
"Finally, Bonsai is shown to generalize to other resource constrained settings beyond IoT by producing significantly better search results than Bing’s L3 ranker when the model size is restricted to 300 bytes.",1. Introduction,[0],[0]
"The literature on resource-efficient machine learning is vast and specialized solutions have been developed for reducing the prediction costs of kNN algorithms (Kusner et al., 2014b; Wang et al., 2016), SVMs (Hsieh et al., 2014; Jose et al., 2013; Le et al., 2013; Li et al., 2016), deep learning (Iandola et al., 2016; Han et al., 2016; Yang et al., 2015; Denton et al., 2014; Wu et al., 2016; Rastegari et al., 2016; Hubara et al., 2016; Shankar et al., 2016; Ioannou et al., 2016a), model compression (Bucilua et al., 2006; Ba & Caruana, 2014), feature selection (Kusner et al., 2014a; Xu et al., 2013; 2012; Nan et al., 2015; Wang et al., 2015) and applications such as face detection (Viola & Jones, 2004).
",2. Related Work,[0],[0]
Resource-efficient tree classifiers are particularly germane to this paper.,2. Related Work,[0],[0]
The standard approach is to greedily grow the decision tree ensemble node by node until the prediction budget is exhausted.,2. Related Work,[0],[0]
"A popular alternative is to first learn the random forest or gradient boosted decision tree ensemble to maximize prediction accuracy and then use pruning techniques to meet the budget constraints (Duda et al., 2002; Dekel et al., 2016; Nan et al., 2016; Li, 2001; Breiman et al., 1984; Zhang & Huei-chuen, 2005; Sherali et al., 2009; Kulkarni & Sinha, 2012; Rokach & Maimon, 2014; Joly et al., 2012).",2. Related Work,[0],[0]
"Unfortunately, such techniques are fundamentally limited as they attempt to approximate complex non-linear decision boundaries using a small number of axis-aligned hyperplanes.",2. Related Work,[0],[0]
"This can lead to poor prediction accuracies as observed in Section 5.
",2. Related Work,[0],[0]
Tree models have also been developed to learn more complex decision boundaries by moving away from learning axis-aligned hyperplanes at internal nodes and constant predictors at the leaves.,2. Related Work,[0],[0]
"For instance, (Breiman, 2001; Murthy et al., 1994; Kontschieder et al., 2015) learnt more powerful branching functions at internal nodes based on oblique cuts and full hyperplanes while (Utgoff, 1989; Hsieh et al., 2014) learnt more powerful leaf node predictors based on linear classifiers, kernelized SVMs, etc.",2. Related Work,[0],[0]
"Bonsai achieves better budget utilization than such models by learning shorter trees, typically depth 4 or lower, and by sharing the parameters between leaf node predictors.
",2. Related Work,[0],[0]
"The models closest to Bonsai are Decision Jungles (Shotton et al., 2013) and LDKL (Jose et al., 2013).",2. Related Work,[0],[0]
"Bonsai improves upon LDKL by learning its tree in a lowdimensional space, learning sparse branching functions and predictors and generalizing the model to multi-class classi-
fication, ranking, etc.",2. Related Work,[0],[0]
Decision Jungles are similar to Bonsai in that they share node parameters using a DAG structure.,2. Related Work,[0],[0]
"Unfortunately, Decision Jungles need to learn deep tree ensembles with many nodes as they use weak constant classifiers as leaf node predictors.",2. Related Work,[0],[0]
"Bonsai can have lower model size and higher accuracy as it learns a single, shallow tree in a low-dimensional space with non-linear predictors.
",2. Related Work,[0],[0]
"Note that while tree based cost-sensitive feature selection methods are not directly relevant, their performance is nevertheless empirically compared to Bonsai’s in Section 5.",2. Related Work,[0],[0]
Overview:,3. The Bonsai Model for Efficient Prediction,[0],[0]
"Bonsai learns a single, shallow sparse tree whose predictions for a point x are given by
y(x) =",3. The Bonsai Model for Efficient Prediction,[0],[0]
∑ k Ik(x)W > k,3. The Bonsai Model for Efficient Prediction,[0],[0]
Zx ◦,3. The Bonsai Model for Efficient Prediction,[0],[0]
"tanh(σV>k Zx) (1)
where ◦ denotes the elementwise Hadamard product, σ is a user tunable hyper-parameter, Z is a sparse projection matrix and Bonsai’s tree is parameterized by Ik, Wk and Vk where Ik(x) is an indicator function taking the value 1 if node k lies along the path traversed by x and 0 otherwise and Wk and Vk are sparse predictors learnt at node k.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"The prediction function is designed to minimize the model size, prediction time and prediction energy, while maintaining prediction accuracy, even at the expense of increased training costs.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"The function is also designed to minimize the working memory required as the Uno provides only 2 KB of writeable memory for storing the feature vector, programme variables and intermediate computations.
",3. The Bonsai Model for Efficient Prediction,[0],[0]
"Streaming sparse projection: Bonsai projects each D-dimensional input feature vector x into a low D̂dimensional space using a learnt sparse projection matrix ZD̂×D. Bonsai uses fixed point arithmetic for all math computation, including Zx, when implemented on the IoT device so as to avoid floating point overheads.",3. The Bonsai Model for Efficient Prediction,[0],[0]
Note that D̂ could be as low as 5 for many binary classification applications.,3. The Bonsai Model for Efficient Prediction,[0],[0]
This has the following advantages.,3. The Bonsai Model for Efficient Prediction,[0],[0]
"First, it reduces Bonsai’s model size as all tree parameters are now learnt in the low-dimensional space.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"Second, when D̂ is small, Zx could be stored directly in the microcontroller’s registers thereby reducing prediction time and energy.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"Third, learning the projection matrix jointly with the tree parameters improves prediction accuracy.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"Fourth, since Zx can be computed in a streaming fashion, this allows Bonsai to tackle IoT applications where even a single feature vector cannot fit in 2 KB of SRAM.",3. The Bonsai Model for Efficient Prediction,[0],[0]
This is critical since standard tree implementations are unable to handle a streaming feature vector – the entire feature vector needs to be streamed for the root node to determine whether to pass the point down to the left or right child and therefore the vector is unavailable for processing at subsequent nodes.,3. The Bonsai Model for Efficient Prediction,[0],[0]
"Some
implementations work around this limitation by simultaneously evaluating the branching function at all nodes as the vector is streamed but this increases the prediction costs from logarithmic to linear which might not be acceptable.
",3. The Bonsai Model for Efficient Prediction,[0],[0]
Branching function at internal nodes: Bonsai computes Ik by learning a sparse vector θ at each internal node such that the sign of θ>Zx determines whether point x should be branched to the node’s left or right child.,3. The Bonsai Model for Efficient Prediction,[0],[0]
Using more powerful branching functions than the axis-aligned hyperplanes in standard decision trees allows Bonsai to learn shallow trees which can fit in a few KB.,3. The Bonsai Model for Efficient Prediction,[0],[0]
"Of course, this is not a novel idea, and is insufficient in itself to allow a single, shallow decision tree to make accurate predictions.
",3. The Bonsai Model for Efficient Prediction,[0],[0]
"Node predictors: Decision trees, random forests and boosted tree ensembles are limited to making constant predictions at just the leaf nodes.",3. The Bonsai Model for Efficient Prediction,[0],[0]
This restricts their prediction accuracy when there are very few leaves.,3. The Bonsai Model for Efficient Prediction,[0],[0]
"In contrast, for a multi-class, multi-label or regression problem with L targets, Bonsai learns matrices WD̂×L and VD̂×L at both leaf and internal nodes so that each node predicts the vector W>Zx◦tanh(σV>Zx).",3. The Bonsai Model for Efficient Prediction,[0],[0]
Note that the functional form of the node predictor was chosen as it was found to work well empirically (other forms could be chosen if found to be more appropriate).,3. The Bonsai Model for Efficient Prediction,[0],[0]
"Further note that W and V will reduce to vectors for binary classification, ranking and singletarget regression.",3. The Bonsai Model for Efficient Prediction,[0],[0]
Bonsai’s overall predicted vector is given by (1) and is the sum of the individual vectors predicted by the nodes lying along the path traversed by x. This allows Bonsai to accurately learn non-linear decision boundaries using shallow trees with just a few nodes.,3. The Bonsai Model for Efficient Prediction,[0],[0]
"Furthermore, path based prediction allows parameter sharing and therefore reduces model size as compared to putting independent classifiers of at least equal complexity in the leaf nodes alone.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"For instance, a depth 4 Bonsai tree with 15 internal and 16 leaf nodes stores 31 W and 31 V matrices with overall predictions being the sum of 4 terms depending on the path taken.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"If parameters were not shared and each leaf node independently learnt 4 W and 4 V matrices to make predictions of at least equal complexity, then a total of 16× 4 = 64 W and 64 V matrices would need to be stored thereby exceeding the memory budget.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"As an implementation detail, note that Bonsai uses the approximation tanh(x)",3. The Bonsai Model for Efficient Prediction,[0],[0]
≈ x,3. The Bonsai Model for Efficient Prediction,[0],[0]
if |x| < 1 and signum(x) otherwise in order to avoid floating point computation.,3. The Bonsai Model for Efficient Prediction,[0],[0]
Notation: Bonsai learns a balanced tree of user specified height h with 2h − 1 internal nodes and 2h leaf nodes.,4. Training Bonsai,[0],[0]
The parameters that need to be learnt include: (a) Z: the sparse projection matrix; (b) θ =,4. Training Bonsai,[0],[0]
"[θ1, . . .",4. Training Bonsai,[0],[0]
",θ2h−1]: the parameters of the branching function at each internal node; and (c) W =",4. Training Bonsai,[0],[0]
"[W1, . . .",4. Training Bonsai,[0],[0]
",W2h+1−1] and V =",4. Training Bonsai,[0],[0]
"[V1, . . .",4. Training Bonsai,[0],[0]
",V2h+1−1]:
the predictor parameters at each node.",4. Training Bonsai,[0],[0]
Let Θ =,4. Training Bonsai,[0],[0]
"[θ,W,V] denote a matrix obtained by stacking all the parameters together except for Z. Finally, it is assumed that N training points {(xi, y
¯i )Ni=1} have been provided and that bud-
get constraints BZ and BΘ on the projection matrix and tree parameters have been specified depending on the flash memory available on the IoT device.
",4. Training Bonsai,[0],[0]
"Optimization problem: Bonsai’s parameters are learnt as
min Z,Θ J (Z,Θ) = λθ 2 Tr(θ>θ) + λW 2 Tr(W>W)
+ λV 2 Tr(V>V) + λZ 2 Tr(ZZ>)
+ 1
N N∑ i=1",4. Training Bonsai,[0],[0]
"L(xi,yi,y(xi);Z,Θ)
s. t. ‖Z‖0 ≤",4. Training Bonsai,[0],[0]
"BZ, ‖Θ‖0 ≤ BΘ
(2)
where y(xi) is Bonsai’s prediction for point xi as given in (1) and L is an appropriately chosen loss function for classification, regression, ranking, etc.",4. Training Bonsai,[0],[0]
"For instance, L = max(0, 1 − yiy(xi))",4. Training Bonsai,[0],[0]
"with yi ∈ {−1,+1} for binary classification and L = maxy∈Y((yi − y)>y(xi) +",4. Training Bonsai,[0],[0]
"1 − y>i y) with Y = {y|y ∈ {0, 1}L,1>y = 1} and yi ∈ Y for multi-class classification.",4. Training Bonsai,[0],[0]
It is worth emphasizing that the optimization problem is formulated such that all parameters are learnt jointly subject to the budget constraints.,4. Training Bonsai,[0],[0]
"This leads to significantly higher prediction accuracies than if Z were first learnt independently, say using sparse PCA, and then Θ was learnt afterwards (see Section 5).
",4. Training Bonsai,[0],[0]
"Algorithm: Optimizing (2) over the space of all balanced trees of height h is a hard, non-convex problem.",4. Training Bonsai,[0],[0]
Tree growing algorithms typically optimize such problems by greedily growing the tree a node at a time starting from the root.,4. Training Bonsai,[0],[0]
"Unfortunately, this leads to a suboptimal utilization of the memory budget in Bonsai’s case as it is not clear a priori how much budget to allocate to each node.",4. Training Bonsai,[0],[0]
"For instance, it is not apparent whether the budget should be distributed equally between all nodes or whether the root node should be allocated more budget and, if so, by how much.
",4. Training Bonsai,[0],[0]
Algorithm - Joint learning of nodes: Bonsai therefore learns all node parameters jointly with the memory budget for each node being determined automatically as part of the optimization.,4. Training Bonsai,[0],[0]
The difficulty with joint learning is that a node’s ancestors need to be learnt before it can be determined which training points will reach the node.,4. Training Bonsai,[0],[0]
"Furthermore, the path traversed by a training point is a sharply discontinuous function of θ and Z thereby rendering gradient based techniques ineffective.",4. Training Bonsai,[0],[0]
"Various approaches have been proposed in the literature for tackling these difficulties (Jose et al., 2013; Kontschieder et al., 2015; Norouzi et al., 2015; Xu et al., 2013; Ioannou et al., 2016b).",4. Training Bonsai,[0],[0]
"Bonsai follows the approach of (Jose et al., 2013)
and smooths the objective function by initially allowing points to traverse multiple paths in the tree.",4. Training Bonsai,[0],[0]
"In particular, the indicator function Ik(x) is relaxed to Ik>1(x) = 1 2Ij(x) ( 1 + (−1)k−2j tanh(σIθ>j Zx) ) where j = ⌊ k 2 ⌋ is k’s parent node in a balanced tree, I1(x)",4. Training Bonsai,[0],[0]
= 1 and the parameter σI controls the fidelity of the approximation.,4. Training Bonsai,[0],[0]
"Gradients can now be computed as
∇θlIk(x) = σIIk(x)P lk(x)Zx (3) ∇ZIk(x) =",4. Training Bonsai,[0],[0]
∑ l σIIk(x)P,4. Training Bonsai,[0],[0]
"l k(x)θlx > (4)
where P lk(x) = δ l k((−1)Ck(l)",4. Training Bonsai,[0],[0]
"− tanh(σIθ>l Zx)), δlk = 1 if node l is an ancestor of node k and 0 otherwise and Ck(l) = 1 if node k is in the right subtree of node l and 0 otherwise.",4. Training Bonsai,[0],[0]
"Of course, allowing a point to traverse multiple paths increases prediction costs.",4. Training Bonsai,[0],[0]
"Some approaches therefore allow multiple paths during training but select a single path during prediction (Xu et al., 2013; Ioannou et al., 2016b).",4. Training Bonsai,[0],[0]
"At each node, a point x is greedily branched to the child node having the greatest Ik(x).",4. Training Bonsai,[0],[0]
"Unfortunately, this can lead to a drop in accuracy as the model learnt during training is different from the one used for prediction.
",4. Training Bonsai,[0],[0]
Bonsai therefore follows an alternative strategy where σI is tuned during training to ensure that points gradually start traversing at most a single path as optimization progresses.,4. Training Bonsai,[0],[0]
"In particular, σI is initialized to a small value, such as 0.01, so as to ensure that tanh values are not saturated.",4. Training Bonsai,[0],[0]
"As optimization progresses, σI is gradually increased so that tanh tends to the signum function and Ik(x) goes back to being an indicator function by the time convergence is reached.",4. Training Bonsai,[0],[0]
"This allows Bonsai to directly use the learnt model for prediction and was found to empirically lead to good results.
",4. Training Bonsai,[0],[0]
"Algorithm - Gradient descent with iterative hard thresholding: Various gradient based approaches, including those based on alternating minimization, were tried for optimizing (2).",4. Training Bonsai,[0],[0]
A gradient descent based algorithm with iterative hard thresholding (IHT) was empirically found to yield the best solutions.,4. Training Bonsai,[0],[0]
"Gradient descent was chosen over stochastic gradient descent as it removed the burden of step size tuning, led to slightly better prediction accuracies while keeping training time acceptable.",4. Training Bonsai,[0],[0]
"For instance, training times range from 2 minutes for USPS-2 to 15 minutes for MNIST-2 on a single core of a laptop with an Intel Core i7-3667U processor at 2 GHz with 8 GB of RAM.",4. Training Bonsai,[0],[0]
Stochastic gradient descent could be utilized for larger datasets or if training costs also needed to be minimized.,4. Training Bonsai,[0],[0]
"The algorithm proceeds iteratively based on the following gradient and IHT steps in each iteration.
",4. Training Bonsai,[0],[0]
Algorithm - Gradient step:,4. Training Bonsai,[0],[0]
"Given feasible Zt and Θt with a feasible allocation of the memory budget to various nodes at time step t, Bonsai applies M updates of gradient descent keeping the support of Z and Θ fixed so that
the budget allocations to nodes remain unchanged and the memory constraints are never violated.",4. Training Bonsai,[0],[0]
"The update equations at each time step are
Zt+1 =",4. Training Bonsai,[0],[0]
"Zt − ηtZ∇ZJ (Zt,Θt)|supp(Zt) (5) Θt+1",4. Training Bonsai,[0],[0]
=,4. Training Bonsai,[0],[0]
Θt − ηtΘ∇ΘJ,4. Training Bonsai,[0],[0]
"(Zt,Θt)|supp(Θt) (6)
with step sizes ηZ and ηΘ being chosen according to the Armijo rule and |supp indicating that the gradient was being computed only for the non-zero entries.",4. Training Bonsai,[0],[0]
M = 5 and M = 15 iterations were found to work well for binary and multi-class classification respectively.,4. Training Bonsai,[0],[0]
"This allows Bonsai to decrease the objective function value without changing the budget allocation of various nodes.
",4. Training Bonsai,[0],[0]
"Algorithm - IHT step: In order to improve the budget allocation, Bonsai performs a single gradient update with unrestricted support.",4. Training Bonsai,[0],[0]
"This violates the memory constraints and Bonsai therefore projects the solution onto the feasible set by retaining the parameters with the largest magnitudes
Zt+M+1 = TBZ(Z t+M − ηt+MZ",4. Training Bonsai,[0],[0]
"∇ZJ (Z t+M ,Θt+M ))",4. Training Bonsai,[0],[0]
"Θt+M+1 = TBΘ(Θ t+M − ηt+MΘ ∇ΘJ (Z t+M ,Θt+M ))
where Tk is an operator returning k of its arguments which have the largest magnitudes while setting the rest to 0.",4. Training Bonsai,[0],[0]
"This allows Bonsai to move to another feasible solution with even lower objective function value by improving the memory budget distribution across nodes.
",4. Training Bonsai,[0],[0]
Algorithm - Convergence:,4. Training Bonsai,[0],[0]
"In general, projected gradient descent based algorithms might oscillate for non-convex problems.",4. Training Bonsai,[0],[0]
"However, (Blumensath & Davies, 2008) prove that for smooth objective functions, gradient descent algorithms with IHT do indeed converge to a saddle point solution.",4. Training Bonsai,[0],[0]
"Furthermore, if the objective function satisfies the Restricted Strong Convexity (RSC) property in a local region, then projected gradient descent with IHT will converge to the local minimum in that region (Jain et al., 2014).",4. Training Bonsai,[0],[0]
"In practice, it was observed that the algorithm generally converged to a good solution soon and therefore was terminated after T = 300 iterations were reached.
",4. Training Bonsai,[0],[0]
Algorithm - Initialization & re-training: Z0 and Θ0 could be set randomly.,4. Training Bonsai,[0],[0]
Prediction accuracy gains of up to 1.5% could be observed if Bonsai was initialized by taking T steps of gradient descent without any budget constraints followed by a hard thresholding step.,4. Training Bonsai,[0],[0]
Further gains of 1.5% could be observed by taking another T steps of gradient descent with fixed support after termination.,4. Training Bonsai,[0],[0]
"This helped in fine-tuning Bonsai’s parameters once the memory budget allocation had been finalized across the tree nodes.
",4. Training Bonsai,[0],[0]
More details about the optimization can be found in the supplementary material by clicking here.,4. Training Bonsai,[0],[0]
"Datasets: Experiments were carried out on a number of publically available binary and multi-class datasets including Chars4K (Campos et al., 2009), CIFAR10 (Krizhevsky, 2009), MNIST (LeCun et al., 1998), WARD (Yang et al., 2009), USPS (Hull, 1994), Eye (Kasprowski & Ober, 2004), RTWhale (RTW), and CUReT (Varma & Zisserman, 2005).",5. Experiments,[0],[0]
"Binary versions of these datasets were downloaded from (Jose et al., 2013).",5. Experiments,[0],[0]
Bing’s L3 Ranking is a proprietary dataset where ground truth annotations specifying the relevance of query-document pairs have been provided on a scale of 0-4.,5. Experiments,[0],[0]
"Table 1 lists these datasets’ statistics.
",5. Experiments,[0],[0]
"Baseline algorithms: Bonsai was compared to stateof-the-art algorithms for resource-efficient ML spanning tree, kNN, SVM and single hidden layer neural network algorithms including Decision Jungles (Shotton et al., 2013; Pohlen), Feature Budgeted Random Forests (BudgetRF) (Nan et al., 2015),",5. Experiments,[0],[0]
"Gradient Boosted Decision Tree Ensemble Pruning (Tree Pruning) (Dekel et al., 2016), Pruned Random Forests (BudgetPrune) (Nan et al., 2016), Local Deep Kernel Learning (LDKL) (Jose et al., 2013), Neural Network Pruning (NeuralNet Pruning) (Han et al., 2016) and Stochastic Neighbor Compression (SNC) (Kusner et al., 2014b).",5. Experiments,[0],[0]
The differences between some of these algorithms and Bonsai is briefly discussed in Section 2.,5. Experiments,[0],[0]
Publically available implementations of all algorithms were used taking care to ensure that published results could be reproduced thereby verifying the code and hyper-parameter settings.,5. Experiments,[0],[0]
Note that Bonsai is not compared to deep convolutional neural networks as they have not yet been demonstrated to fit on such tiny IoT devices.,5. Experiments,[0],[0]
"In particular, convolutions are computationally expensive, drain batteries and produce intermediate results which do not fit in 2 KB RAM.",5. Experiments,[0],[0]
"Implementing them on tiny microcontrollers is still
0 50 100 10
20
30
40
50
60 Chars4K−62
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
",5. Experiments,[0],[0]
BonsaiOpt Bonsai NeuralNet Pruning SNC,5. Experiments,[0],[0]
"Decision Jungle BudgetPrune BudgetRF
0 50 100 70
80
90
CUReT−61
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
",5. Experiments,[0],[0]
BonsaiOpt Bonsai NeuralNet Pruning SNC,5. Experiments,[0],[0]
"Decision Jungle BudgetPrune BudgetRF
0 50 100 80
85
90
95
MNIST−10
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
",5. Experiments,[0],[0]
BonsaiOpt Bonsai NeuralNet Pruning SNC,5. Experiments,[0],[0]
"Decision Jungle BudgetPrune BudgetRF
0.2 0.4 0.6 0.8 1 42
44
46
48
50
52
L3 Ranking
Model Size (KB)
nD",5. Experiments,[0],[0]
"C
G @
1
Bonsai FastRank
0 5 10 15 50
Model Size (KB)
0 5 10 15 80
Model Size (KB)
0 5 10 15 90
Model Size (KB)
0 5 10 15 88
Model Size (KB)
0 5 10 15 66
68
70
72
74
76
78 Chars4K−2
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
0 5 10 15 68
70
72
74
76
CIFAR10−2
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
0 5 10 15 90
92
94
96
USPS−2
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
",5. Experiments,[0],[0]
"Legend
−
−
BonsaiOpt Bonsai GBDT",5. Experiments,[0],[0]
Tree Pruning LDKL LDKL−L1 NeuralNet Pruning SNC,5. Experiments,[0],[0]
"Decision Jungle BudgetPrune BudgetRF
Figure 2: Binary Datasets - Bonsai dominates over state-of-the-art resource-efficient ML algorithms with gains of 8.6% on RTWhale-2 and 8.2% on Eye-2 in the 0-2 KB range.",5. Experiments,[0],[0]
BonsaiOpt’s gains are even higher.,5. Experiments,[0],[0]
"Figure best viewed magnified.
",5. Experiments,[0],[0]
an open research problem.,5. Experiments,[0],[0]
"Bonsai’s performance was however compared to that of uncompressed single hidden layer neural networks without convolutions, Gradient Boosted Decision Trees (GBDT), kNN classifiers and RBF-SVMs.
",5. Experiments,[0],[0]
Hyper-parameters: The publically provided training set for each dataset was subdivided into 80% for training and 20% for validation.,5. Experiments,[0],[0]
The hyper-parameters of all algorithms were tuned on the validation set.,5. Experiments,[0],[0]
"Once the hyperparameters had been fixed, the algorithms were trained on the full training set and results were reported on the publically available test set.
",5. Experiments,[0],[0]
Evaluation: IoT applications would like to maximize their prediction accuracies using the best model that might fit within the available flash memory while minimizing their prediction times and energies.,5. Experiments,[0],[0]
Accuracies of all algorithms are therefore presented for a range of model sizes.,5. Experiments,[0],[0]
"Some
of the algorithms were implemented on the Uno and their prediction times and energies were compared to Bonsai’s.
",5. Experiments,[0],[0]
Implementation: Results are presented throughout for an unoptimized implementation of Bonsai for a fair comparison with the other methods.,5. Experiments,[0],[0]
"For instance, 4 bytes were used to store floating point numbers for all algorithms, all floating point operations were simulated in software, etc.",5. Experiments,[0],[0]
"However, results are also presented for an optimized implementation of Bonsai, called BonsaiOpt, where numbers were stored in a 1 byte fixed point format, tanh was approximated, all floating point operations were avoided, etc.
",5. Experiments,[0],[0]
"Comparison to uncompressed methods: The results in Tables 2 and 3 demonstrate that Bonsai’s prediction accuracies could compete with those of uncompressed kNN, GBDT, RBF-SVM and neural network classifiers with significantly larger model sizes.",5. Experiments,[0],[0]
"On RTWhale-2, Chars4K-62
and Chars4K-2, Bonsai’s accuracies were higher than all other methods by 4.8%, 3.2% and 1.1% while its model size was lower by 977x, 13x and 157x respectively.",5. Experiments,[0],[0]
Bonsai’s accuracies were lower by 1.0% - 5.0% on the other datasets with model size gains varying from 55x to 3996x.,5. Experiments,[0],[0]
"Note that, while BonsaiOpt’s accuracies were similar to Bonsai’s, its model sizes would be even lower.
",5. Experiments,[0],[0]
Comparison to resource-efficient ML algorithms: The results in Figures 2 and 3 demonstrate that Bonsai’s prediction accuracies dominate those of state-of-the-art resourceefficient ML algorithms for all model sizes.,5. Experiments,[0],[0]
"In fact, Bonsai could outperform all other algorithms, including tree algorithms by as much as 30.7% on Char4K-62 and 28.9% on CUReT-61 for a given model size.",5. Experiments,[0],[0]
"For binary datasets, the largest gains were observed in the 0-2 KB regime including 8.6% on RTWhale-2 and 8.2% on Eye-2.",5. Experiments,[0],[0]
"Of course, BonsaiOpt’s gains were even higher on both binary and
multi-class datasets.",5. Experiments,[0],[0]
"These results validate Bonsai’s model, showing it to be accurate and compact and demonstrate that Bonsai’s optimization algorithm yields good solutions.
L3 ranking: Bonsai was shown to generalise to other resource-constrained scenarios beyond IoT by ranking documents in response to queries on Bing.",5. Experiments,[0],[0]
"Bonsai was trained by replacing the classification gradients with rank-sensitive gradients approximating nDCG (Burges, 2010).",5. Experiments,[0],[0]
"As can be seen in Figure 1, using a 300 byte model, Bonsai could outperform Bing’s FastRank L3 ranker by 8.3%.",5. Experiments,[0],[0]
"In fact, Bonsai could achieve almost the same ranking accuracy as FastRank but with a 660x smaller model.
",5. Experiments,[0],[0]
Prediction on the Arduino Uno: Table 5 presents the prediction costs per test point for the highest accuracy models with size less than 2 KB for a few methods that were implemented on the Arduino Uno.,5. Experiments,[0],[0]
The BonsaiOpt model was a more efficient implementation of the chosen Bonsai model.,5. Experiments,[0],[0]
"The results indicate that BonsaiOpt could be significantly more accurate, faster and energy-efficient as compared to other algorithms including an unoptimized linear classifier.",5. Experiments,[0],[0]
"Transmitting the test feature vector to the cloud, whenever possible, and running uncompressed GBDT might sometimes yield higher accuracies but would also consume 47x497x more energy which might not be feasible.
Bonsai’s components: The contribution of Bonsai’s components on the Chars4K-2 dataset is presented in Table 4.",5. Experiments,[0],[0]
Modest reductions in accuracy were observed without proper initialization or re-training.,5. Experiments,[0],[0]
Learning a projection matrix independently via sparse PCA before training reduced accuracy significantly as compared to Bonsai’s joint training of the projection matrix and tree parameters.,5. Experiments,[0],[0]
Other tree and uncompressed methods also did not benefit much by training in the sparse PCA space.,5. Experiments,[0],[0]
"This paper proposed an alternative IoT paradigm, centric to the device rather than the cloud, where ML models run on tiny IoT devices without necessarily connecting to the cloud thereby engendering local decision making capabilities.",6. Conclusions,[0],[0]
"The Bonsai tree learner was developed towards this end and demonstrated to be fast, accurate, compact and energy-efficient at prediction time.",6. Conclusions,[0],[0]
"Bonsai was deployed on the Arduino Uno board as it could fit in a few KB of flash, required only 70 bytes of writable memory for binary classification and 500 bytes for a 62 class problem, handled streaming features and made predictions in milliseconds taking only milliJoules of energy.",6. Conclusions,[0],[0]
"Bonsai’s prediction accuracies could be as much as 30% higher as com-
pared to state-of-the-art resource-efficient ML algorithms for a fixed model size and could even approach and outperform those of uncompressed models taking many MB of RAM.",6. Conclusions,[0],[0]
"Bonsai achieved these gains by developing a novel model based on a single, shallow, sparse tree learnt in a low-dimensional space.",6. Conclusions,[0],[0]
Predictions made by both internal and leaf nodes and the sharing of parameters along paths allowed Bonsai to learn complex non-linear decision boundaries using a compact representation.,6. Conclusions,[0],[0]
Bonsai’s code is available from (BonsaiCode) and is part of Microsoft’s ELL machine learning compiler for IoT devices.,6. Conclusions,[0],[0]
"We are grateful to Yeshwanth Cherapanamjeri, Ofer Dekel, Chirag Gupta, Prateek Jain, Ajay Manchepalli, Nagarajan Natarajan, Praneeth Netrapalli, Bhargavi Paranjape, Suresh Parthasarathy, Vivek Seshadri, Rahul Sharma, Harsha Vardhan Simhadri, Manish Singh and Raghavendra Udupa for many helpful discussions and feedback.",Acknowledgements,[0],[0]
"This paper develops a novel tree-based algorithm, called Bonsai, for efficient prediction on IoT devices – such as those based on the Arduino Uno board having an 8 bit ATmega328P microcontroller operating at 16 MHz with no native floating point support, 2 KB RAM and 32 KB read-only flash.",abstractText,[0],[0]
"Bonsai maintains prediction accuracy while minimizing model size and prediction costs by: (a) developing a tree model which learns a single, shallow, sparse tree with powerful nodes; (b) sparsely projecting all data into a low-dimensional space in which the tree is learnt; and (c) jointly learning all tree and projection parameters.",abstractText,[0],[0]
"Experimental results on multiple benchmark datasets demonstrate that Bonsai can make predictions in milliseconds even on slow microcontrollers, can fit in KB of memory, has lower battery consumption than all other algorithms while achieving prediction accuracies that can be as much as 30% higher than stateof-the-art methods for resource-efficient machine learning.",abstractText,[0],[0]
Bonsai is also shown to generalize to other resource constrained settings beyond IoT by generating significantly better search results as compared to Bing’s L3 ranker when the model size is restricted to 300 bytes.,abstractText,[0],[0]
Bonsai’s code can be downloaded from (BonsaiCode).,abstractText,[0],[0]
Resource-efficient Machine Learning in 2 KB RAM for the Internet of Things,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 925–930 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
925",text,[0],[0]
"Natural language to code generation, a subtask of semantic parsing, is the problem of converting natural language (NL) descriptions to code (Ling et al., 2016; Yin and Neubig, 2017; Rabinovich et al., 2017).",1 Introduction,[0],[0]
"This task is challenging because it has a well-defined structured output and the input structure and output structure are in different forms.
",1 Introduction,[0],[0]
A number of neural network approaches have been proposed to solve this task.,1 Introduction,[0],[0]
"Sequential approaches (Ling et al., 2016; Jia and Liang, 2016; Locascio et al., 2016) convert the target code into a sequence of symbols and apply a sequence-tosequence model, but this approach does not ensure that the output will be syntactically correct.
",1 Introduction,[0],[0]
"1Code available at https://github.com/ sweetpeach/ReCode
Tree-based approaches (Yin and Neubig, 2017; Rabinovich et al., 2017) represent code as Abstract Syntax Trees (ASTs), which has proven effective in improving accuracy as it enforces the well-formedness of the output code.",1 Introduction,[0],[0]
"However, representing code as a tree is not a trivial task, as the number of nodes in the tree often greatly exceeds the length of the NL description.",1 Introduction,[0],[0]
"As a result, tree-based approaches are often incapable of generating correct code for phrases in the corresponding NL description that have low frequency in the training data.
",1 Introduction,[0],[0]
"In machine translation (MT) problems (Zhang et al., 2018; Gu et al., 2018; Amin Farajian et al., 2017; Li et al., 2018), hybrid methods combining retrieval of salient examples and neural models have proven successful in dealing with rare words.",1 Introduction,[0],[0]
"Following the intuition of these models, we hypothesize that our model can benefit from querying pairs of NL descriptions and AST structures from training data.
",1 Introduction,[0],[0]
"In this paper, we propose RECODE, and adaptation of Zhang et al. (2018)’s retrieval-based approach neural MT method to the code generation problem by expanding it to apply to generation of tree structures.",1 Introduction,[0],[0]
Our main contribution is to introduce the use of retrieval methods in neural code generation models.,1 Introduction,[0],[0]
We also propose a dynamic programming-based sentence-tosentence alignment method that can be applied to similar sentences to perform word substitution and enable retrieval of imperfect matches.,1 Introduction,[0],[0]
These contributions allow us to improve on previous stateof-the-art results.,1 Introduction,[0],[0]
"Given an NL description q, our purpose is to generate code (e.g. Python) represented as an AST a.",2 Syntactic Code Generation,[0],[0]
"In this work, we start with the syntactic code gen-
eration model by Yin and Neubig (2017), which uses sequences of actions to generate the AST before converting it to surface code.",2 Syntactic Code Generation,[0],[0]
"Formally, we want to find the best generated AST â given by:
â = argmax a
p(a|q)
p(a|q) = T∏ t=1 p(yt|y<t, q)
where yt is the action taken at time step t and y<t = y1...",2 Syntactic Code Generation,[0],[0]
"yt−1 and T is the number of total time steps of the whole action sequence resulting in AST a.
We have two types of actions to build an AST: APPLYRULE and GENTOKEN.",2 Syntactic Code Generation,[0],[0]
APPLYRULE(r) expands the current node in the tree by applying production rule r from the abstract syntax grammar2 to the current node.,2 Syntactic Code Generation,[0],[0]
GENTOKEN(v) populates terminal nodes with the variable v which can be generated from vocabulary or by COPYing variable names or values from the NL description.,2 Syntactic Code Generation,[0],[0]
The generation process follows a preorder traversal starting with the root node.,2 Syntactic Code Generation,[0],[0]
"Figure 1 shows an action tree for the example code: the nodes correspond to actions per time step in the construction of the AST.
",2 Syntactic Code Generation,[0],[0]
"Interested readers can reference Yin and Neubig (2017) for more detail of the neural model, which consists of a bidirectional LSTM (Hochreiter and Schmidhuber, 1997) encoder-decoder with action embeddings, context vectors, parent feeding, and a copy mechanism using pointer networks.",2 Syntactic Code Generation,[0],[0]
"We propose RECODE, a method for retrievalbased neural syntactic code generation, using retrieved action subtrees.",3 RECODE: Retrieval-Based Neural Code Generation,[0],[0]
"Following Zhang et al. (2018)’s method for neural machine translation, these retrieved subtrees act as templates that bias the generation of output code.",3 RECODE: Retrieval-Based Neural Code Generation,[0],[0]
"Our pipeline at test time is as follows: • retrieve from the training set NL descriptions
that are most similar with our input sentence (§3.1), • extract n-gram action subtrees from these
retrieved sentences’ corresponding target ASTs (§3.2),
2https://docs.python.org/2/library/ ast.html
• alter the copying actions in these subtrees, by substituting words of the retrieved sentence with corresponding words in the input sentence (§3.3), and • at every decoding step, increase the probabil-
ity of actions that would lead to having these subtrees in the produced tree (§3.4).",3 RECODE: Retrieval-Based Neural Code Generation,[0],[0]
"For every retrieved NL description qm from training set (or retrieved sentence for short), we compute its similarity with input q, using a sentence similarity formula (Gu et al., 2016; Zhang et al., 2018):
sim(q, qm) = 1−",3.1 Retrieval of Training Instances,[0],[0]
"d(q, qm)
max(|q| ,|qm|)
where d is the edit distance.",3.1 Retrieval of Training Instances,[0],[0]
We retrieve only the top M sentences according to this metric where M is a hyperparameter.,3.1 Retrieval of Training Instances,[0],[0]
These scores will later be used to increase action probabilities accordingly.,3.1 Retrieval of Training Instances,[0],[0]
"In Zhang et al. (2018), they collect n-grams from the output side of the retrieved sentences and encourage the model to generate these n-grams.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"Word n-grams are obvious candidates when generating a sequence of words as output, as in NMT.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"However, in syntax-based code generation, the generation target is ASTs with no obvious linear structure.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"To resolve this problem, we instead use retrieved pieces of n-gram subtrees from the target code corresponding to the retrieved NL descriptions.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"Though we could select successive nodes in the AST as retrieved pieces, such as [assign; expr*(targets); expr] from Figure 1, we would miss important structural information from the rules that are used.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"Thus, we choose to exploit actions in the generation model rather than AST nodes themselves to be candidates for our retrieved pieces.
",3.2 Extracting N -gram Action Subtrees,[0],[0]
"In the action tree (Figure 1), we considered only successive actions, such as subtrees where each node has one or no children, to avoid overly rigid structures or combinatorial explosion of the number of retrieved pieces the model has to consider.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"For example, such an action subtree would be given by [assign → expr*(targets), expr(value) ; expr(value) → List; List → epsilon].
",3.2 Extracting N -gram Action Subtrees,[0],[0]
"As the node in the action tree holds structural information about its children, we set the subtrees
to have a fixed depth, linear in the size of the tree.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"These can be considered “n-grams of actions”, emphasizing the comparison with machine translation which uses n-grams of words.",3.2 Extracting N -gram Action Subtrees,[0],[0]
n is a hyperparameter to be tuned.,3.2 Extracting N -gram Action Subtrees,[0],[0]
Using the retrieved subtree without modification is problematic if it contains at least one node corresponding to a COPY action because copied tokens from the retrieved sentence may be different from those in the input.,3.3 Word Substitution in Copy Actions,[0],[0]
"Figure 1 shows an example when the input and retrieved sentence have four common words, but the object names are different.",3.3 Word Substitution in Copy Actions,[0],[0]
"The extracted action n-gram would contain the rule that copies the second word (“lst”) of the retrieved sentence while we want to copy the first word (“params”) from the input.
",3.3 Word Substitution in Copy Actions,[0],[0]
"By computing word-based edit distance between the input description and the retrieved sentence, we implement a one-to-one sentence alignment method that infers correspondences between uncommon words.",3.3 Word Substitution in Copy Actions,[0],[0]
"For unaligned words, we alter all COPY rules in the extracted n-grams to copy tokens by their aligned counterpart, such as replace “params” with “lst”, and delete the n-gram subtree, as it is not likely to be relevant in the predicted tree.",3.3 Word Substitution in Copy Actions,[0],[0]
"Thus, in the example in Figure 1, the GENTOKEN(LST) action in t5 will not be executed.",3.3 Word Substitution in Copy Actions,[0],[0]
"N -gram subtrees from all retrieved sentences are assigned a score, based on the best similarity score
of all instances where they appeared.",3.4 Retrieval-Guided Code Generation,[0],[0]
"We normalize the scores for each input sentence by subtracting the average over the training dataset.
",3.4 Retrieval-Guided Code Generation,[0],[0]
"At decoding time, incorporate these retrievalderived scores into beam search: for a given time step, all actions that would result in one of the retrieved n-grams u to be in the prediction tree has its log probability log(p(yt | yt−11 )) increased by λ ∗ score(u) where λ is a hyperparameter, and score(u) is the maximal sim(q, qm) from which u is extracted.",3.4 Retrieval-Guided Code Generation,[0],[0]
The probability distribution is then renormalized.,3.4 Retrieval-Guided Code Generation,[0],[0]
"We evaluate RECODE with the Hearthstone (HS) (Ling et al., 2016) and Django (Oda et al., 2015) datasets, as preprocessed by Yin and Neubig (2017).",4 Datasets and Evaluation Metrics,[0],[0]
HS consists of Python classes that implement Hearthstone card descriptions while Django contains pairs of Python source code and English pseudo-code from Django web framework.,4 Datasets and Evaluation Metrics,[0],[0]
"Table 1 summarizes dataset statistics.
",4 Datasets and Evaluation Metrics,[0],[0]
"For evaluation metrics, we use accuracy of exact match and the BLEU score following Yin and Neubig (2017).",4 Datasets and Evaluation Metrics,[0],[0]
"For the neural code generation model, we use the settings explained in Yin and Neubig (2017).",5 Experiments,[0],[0]
"For the retrieval method, we tuned hyperparameters and achieved best result when we set nmax = 4 and λ = 3 for both datasets3.",5 Experiments,[0],[0]
"For HS, we set M = 3 and M = 10 for Django.
",5 Experiments,[0],[0]
"We compare our model with Yin and Neubig (2017)’s model that we call YN17 for brevity, and a sequence-to-sequence (SEQ2SEQ) model that we implemented.",5 Experiments,[0],[0]
"SEQ2SEQ is an attentionenabled encoder-decoder model (Bahdanau et al., 2015).",5 Experiments,[0],[0]
The encoder is a bidirectional LSTM and the decoder is an LSTM.,5 Experiments,[0],[0]
"Table 2 shows that RECODE outperforms the baselines in both BLEU and accuracy, providing ev-
3n-gram subtrees are collected up to nmax-gram
idence for the effectiveness of incorporating retrieval methods into tree-based approaches.
.
",5.1 Results,[0],[0]
"We ran statistical significance tests for RECODE and YN17, using bootstrap resampling with N = 10,000.",5.1 Results,[0],[0]
"For the BLEU scores of both datasets, p < 0.001.",5.1 Results,[0],[0]
"For the exact match accuracy, p < 0.001 for Django dataset, but for Hearthstone, p > 0.3, showing that the retrieval-based model is on par with YN17.",5.1 Results,[0],[0]
"It is worth noting, though, that HS consists of long and complex code, and that generating exact matches is very difficult, making exact match accuracy a less reliable metric.
",5.1 Results,[0],[0]
We also compare RECODE with Rabinovich et al. (2017)’s Abstract Syntax Networks with supervision (ASN+SUPATT) which is the state-of-the-art system for HS.,5.1 Results,[0],[0]
RECODE exceeds ASN without extra supervision though ASN+SUPATT has a slightly better result.,5.1 Results,[0],[0]
"However, ASN+SUPATT is trained with supervised attention extracted through heuristic exact word matches while our attention is unsupervised.",5.1 Results,[0],[0]
"From our observation and as mentioned in Rabinovich et al. (2017), HS contains classes with similar structure, so the code generation task could be simply matching the tree structure and filling the terminal tokens with correct variables and values.",5.2 Discussion and Analysis,[0],[0]
"However, when the code consists of complex logic, partial implementation errors occur, leading to low exact match accuracy (Yin and Neubig, 2017).",5.2 Discussion and Analysis,[0],[0]
"Analyzing our result, we find this intuition to be true not only for HS but also for Django.
",5.2 Discussion and Analysis,[0],[0]
"Examining the generated output for the Django dataset in Table 3, we can see that in the first example, our retrieval model can successfully generate the correct code when YN17 fails.",5.2 Discussion and Analysis,[0],[0]
This difference suggests that our retrieval model benefits from the action subtrees from the retrieved sentences.,5.2 Discussion and Analysis,[0],[0]
"In the second example, although our generated code does not perfectly match the reference code, it has a higher BLEU score compared
to the output of YN17 because our model can predict part of the code (timesince(d, now, reversed)) correctly.",5.2 Discussion and Analysis,[0],[0]
The third example shows where our method fails to apply the correct action as it cannot cast s to str type while YN17 can at least cast s into a type (bool).,5.2 Discussion and Analysis,[0],[0]
"Another common type of error that we found RECODE’s generated outputs is incorrect variable copying, similarly to what is discussed in Yin and Neubig (2017) and Rabinovich et al. (2017).
",5.2 Discussion and Analysis,[0],[0]
Table 4 presents a result on the HS dataset4.,5.2 Discussion and Analysis,[0],[0]
We can see that our retrieval model can handle complex code more effectively.,5.2 Discussion and Analysis,[0],[0]
"Several works on code generation focus on domain specific languages (Raza et al., 2015; Kushman and Barzilay, 2013).",6 Related Work,[0],[0]
"For general purpose code generation, some data-driven work has been
4More example of HS code is provided in the supplementary material.
done for predicting input parsers (Lei et al., 2013) or a set of relevant methods (Raghothaman et al., 2016).",6 Related Work,[0],[0]
"Some attempts using neural networks have used sequence-to-sequence models (Ling et al., 2016) or tree-based architectures (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017).",6 Related Work,[0],[0]
Ling et al. (2016); Jia and Liang (2016); Locascio et al. (2016) treat semantic parsing as a sequence generation task by linearizing trees.,6 Related Work,[0],[0]
The closest work to ours are Yin and Neubig (2017) and Rabinovich et al. (2017) which represent code as an AST.,6 Related Work,[0],[0]
"Another close work is Dong and Lapata (2018), which uses a two-staged structure-aware neural architecture.",6 Related Work,[0],[0]
"They initially generate a lowlevel sketch and then fill in the missing information using the NL and the sketch.
",6 Related Work,[0],[0]
Recent works on retrieval-guided neural machine translation have been presented by Gu et al. (2018); Amin Farajian et al. (2017); Li et al. (2018); Zhang et al. (2018).,6 Related Work,[0],[0]
Gu et al. (2018) use the retrieved sentence pairs as extra inputs to the NMT model.,6 Related Work,[0],[0]
Zhang et al. (2018) employ a simpler and faster retrieval method to guide neural MT where translation pieces are n-grams from retrieved target sentences.,6 Related Work,[0],[0]
"We modify Zhang et al. (2018)’s method from textual n-grams to n-grams over subtrees to exploit the code structural similarity, and propose methods to deal with complex statements and rare words.
",6 Related Work,[0],[0]
"In addition, some previous works have used subtrees in structured prediction tasks.",6 Related Work,[0],[0]
"For example, Galley et al. (2006) used them in syntaxbased translation models.",6 Related Work,[0],[0]
"In Galley et al. (2006), subtrees of the input sentence’s parse tree are associated with corresponding words in the output sentence.",6 Related Work,[0],[0]
We proposed an action subtree retrieval method at test time on top of an AST-driven neural model for generating general-purpose code.,7 Conclusion,[0],[0]
"The predicted surface code is syntactically correct, and the retrieval component improves the performance of a previously state-of-the-art model.",7 Conclusion,[0],[0]
Our successful result suggests that our idea of retrieval-based generation can be potentially applied to other treestructured prediction tasks.,7 Conclusion,[0],[0]
"We are grateful to Lucile Callebert for insightful discussions, Aldrian Obaja Muis for helpful
input on early version writing, and anonymous reviewers for useful feedback.",Acknowledgements,[0],[0]
This material is based upon work supported by the National Science Foundation under Grant No. 1815287.,Acknowledgements,[0],[0]
"In models to generate program source code from natural language, representing this code in a tree structure has been a common approach.",abstractText,[0],[0]
"However, existing methods often fail to generate complex code correctly due to a lack of ability to memorize large and complex structures.",abstractText,[0],[0]
"We introduce RECODE, a method based on subtree retrieval that makes it possible to explicitly reference existing code examples within a neural code generation model.",abstractText,[0],[0]
"First, we retrieve sentences that are similar to input sentences using a dynamicprogramming-based sentence similarity scoring method.",abstractText,[0],[0]
"Next, we extract n-grams of action sequences that build the associated abstract syntax tree.",abstractText,[0],[0]
"Finally, we increase the probability of actions that cause the retrieved n-gram action subtree to be in the predicted code.",abstractText,[0],[0]
We show that our approach improves the performance on two code generation tasks by up to +2.6 BLEU.1,abstractText,[0],[0]
Retrieval-Based Neural Code Generation,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 152–161 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
152",text,[0],[0]
The exponentially growing online information has necessitated the development of effective automatic summarization systems.,1 Introduction,[0],[0]
"In this paper, we focus on an increasingly intriguing task, i.e., abstractive sentence summarization (Rush et al., 2015a), which generates a shorter version of a given sentence while attempting to preserve its original meaning.",1 Introduction,[0],[0]
It can be used to design or refine appealing headlines.,1 Introduction,[0],[0]
"Recently, the application of the attentional sequence-to-sequence (seq2seq) framework has attracted growing attention and achieved state-of-the-art performance on this task (Rush et al., 2015a; Chopra et al., 2016; Nallapati et al., 2016).
",1 Introduction,[0],[0]
Most previous seq2seq models purely depend on the source text to generate summaries.,1 Introduction,[0],[0]
"However, as reported in many studies (Koehn and Knowles, 2017), the performance of a seq2seq model deteriorates quickly with the increase of the length of generation.",1 Introduction,[0],[0]
Our experiments also show that seq2seq models tend to “lose control” sometimes.,1 Introduction,[0],[0]
"For example, 3% of summaries contain less than 3 words, while there are 4 summaries repeating a word for even 99 times.",1 Introduction,[0],[0]
These results largely reduce the informativeness and readability of the generated summaries.,1 Introduction,[0],[0]
"In addition, we find seq2seq models usually focus on copying source words in order, without any actual “summarization”.",1 Introduction,[0],[0]
"Therefore, we argue that, the free generation based on the source sentence is not enough for a seq2seq model.
",1 Introduction,[0],[0]
"Template based summarization (e.g., Zhou and Hovy (2004)) is a traditional approach to abstractive summarization.",1 Introduction,[0],[0]
"In general, a template is an incomplete sentence which can be filled with the input text using the manually defined rules.",1 Introduction,[0],[0]
"For instance, a concise template to conclude the stock market quotation is: [REGION] shares [open/close]",1 Introduction,[0],[0]
"[NUMBER] percent [lower/higher], e.g., “hong kong shares close #.",1 Introduction,[0],[0]
# percent lower”.,1 Introduction,[0],[0]
"Since the templates are written by humans, the produced summaries are usually fluent and informative.",1 Introduction,[0],[0]
"However, the construction of templates is extremely time-consuming and requires a plenty of domain knowledge.",1 Introduction,[0],[0]
"Moreover, it is impossible to develop all templates for summaries in various domains.
",1 Introduction,[0],[0]
"Inspired by retrieve-based conversation systems (Ji et al., 2014), we assume the golden summaries of the similar sentences can provide a reference point to guide the input sentence summarization process.",1 Introduction,[0],[0]
"We call these existing summaries soft templates since no actual rules are nee-
ded to build new summaries from them.",1 Introduction,[0],[0]
"Due to the strong rewriting ability of the seq2seq framework (Cao et al., 2017a), in this paper, we propose to combine the seq2seq and template based summarization approaches.",1 Introduction,[0],[0]
"We call our summarization system Re3Sum, which consists of three modules: Retrieve, Rerank and Rewrite.",1 Introduction,[0],[0]
We utilize a widely-used Information Retrieval (IR) platform to find out candidate soft templates from the training corpus.,1 Introduction,[0],[0]
"Then, we extend the seq2seq model to jointly learn template saliency measurement (Rerank) and final summary generation (Rewrite).",1 Introduction,[0],[0]
"Specifically, a Recurrent Neural Network (RNN) encoder is applied to convert the input sentence and each candidate template into hidden states.",1 Introduction,[0],[0]
"In Rerank, we measure the informativeness of a candidate template according to its hidden state relevance to the input sentence.",1 Introduction,[0],[0]
The candidate template with the highest predicted informativeness is regarded as the actual soft template.,1 Introduction,[0],[0]
"In Rewrite, the summary is generated according to the hidden states of both the sentence and template.
",1 Introduction,[0],[0]
"We conduct extensive experiments on the popular Gigaword dataset (Rush et al., 2015b).",1 Introduction,[0],[0]
"Experiments show that, in terms of informativeness, Re3Sum significantly outperforms the state-ofthe-art seq2seq models, and even soft templates themselves demonstrate high competitiveness.",1 Introduction,[0],[0]
"In addition, the import of high-quality external summaries improves the stability and readability of generated summaries.
",1 Introduction,[0],[0]
"The contributions of this work are summarized as follows:
• We propose to introduce soft templates as additional input to improve the readability and stability of seq2seq summarization systems.",1 Introduction,[0],[0]
Code and results can be found at http://www4.comp.polyu.,1 Introduction,[0],[0]
"edu.hk/˜cszqcao/
• We extend the seq2seq framework to conduct template reranking and template-aware summary generation simultaneously.
",1 Introduction,[0],[0]
"• We fuse the popular IR-based and seq2seqbased summarization systems, which fully utilize the supervisions from both sides.",1 Introduction,[0],[0]
"As shown in Fig. 1, our summarization system consists of three modules, i.e., Retrieve, Rerank
and Rewrite.",2 Method,[0],[0]
"Given the input sentence x, the Retrieve module filters candidate soft templates C = {ri} from the training corpus.",2 Method,[0],[0]
"For validation and test, we regard the candidate template with the highest predicted saliency (a.k.a informativeness) score as the actual soft template r. For training, we choose the one with the maximal actual saliency score in C, which speeds up convergence and shows no obvious side effect in the experiments.
",2 Method,[0],[0]
"Then, we jointly conduct reranking and rewriting through a shared encoder.",2 Method,[0],[0]
"Specifically, both the sentence x and the soft template r are converted into hidden states with a RNN encoder.",2 Method,[0],[0]
"In the Rerank module, we measure the saliency of r according to its hidden state relevance to x.",2 Method,[0],[0]
"In the Rewrite module, a RNN decoder combines the hidden states of x and r to generate a summary y. More details will be described in the rest of this section",2 Method,[0],[0]
The purpose of this module is to find out candidate templates from the training corpus.,2.1 Retrieve,[0],[0]
We assume that similar sentences should hold similar summary patterns.,2.1 Retrieve,[0],[0]
"Therefore, given a sentence x, we find out its analogies in the corpus and pick their summaries as the candidate templates.",2.1 Retrieve,[0],[0]
"Since the size of our dataset is quite large (over 3M), we leverage the widely-used Information Retrieve (IR) system Lucene1 to index and search efficiently.",2.1 Retrieve,[0],[0]
We keep the default settings of Lucene2 to build the IR system.,2.1 Retrieve,[0],[0]
"For each input sentence, we select top 30 searching results as candidate templates.",2.1 Retrieve,[0],[0]
"To conduct template-aware seq2seq generation (rewriting), it is a necessary step to encode both the source sentence x and soft template r into hidden states.",2.2 Jointly Rerank and Rewrite,[0],[0]
"Considering that the matching networks based on hidden states have demonstrated the strong ability to measure the relevance of two pieces of texts (e.g., Chen et al. (2016)), we propose to jointly conduct reranking and rewriting through a shared encoding step.",2.2 Jointly Rerank and Rewrite,[0],[0]
"Specifically, we employ a bidirectional Recurrent Neural Network (BiRNN) encoder (Cho et al., 2014) to read x and r. Take the sentence x as an example.",2.2 Jointly Rerank and Rewrite,[0],[0]
"Its hidden state of the forward RNN at timestamp i can be
1https://lucene.apache.org/ 2TextField with EnglishAnalyzer
represented by:
−→ h xi = RNN(xi, −→ h xi−1) (1)
The BiRNN consists of a forward RNN and a backward RNN.",2.2 Jointly Rerank and Rewrite,[0],[0]
"Suppose the corresponding outputs are [ −→ h x1 ; · · · ; −→ h x−1] and [ ←− h x1 ; · · · ; ←− h x−1], respectively, where the index “−1” stands for the last element.",2.2 Jointly Rerank and Rewrite,[0],[0]
"Then, the composite hidden state of a word is the concatenation of the two RNN representations, i.e., hxi =",2.2 Jointly Rerank and Rewrite,[0],[0]
[ −→ h xi ; ←− h xi ].,2.2 Jointly Rerank and Rewrite,[0],[0]
The entire representation for the source sentence is [hx1 ; · · · ;hx−1].,2.2 Jointly Rerank and Rewrite,[0],[0]
"Since a soft template r can also be regarded as a readable concise sentence, we use the same BiRNN encoder to convert it into hidden states [hr1; · · · ;hr−1].",2.2 Jointly Rerank and Rewrite,[0],[0]
"In Retrieve, the template candidates are ranked according to the text similarity between the corresponding indexed sentences and the input sentence.",2.2.1 Rerank,[0],[0]
"However, for the summarization task, we expect the soft template r resembles the actual summary y∗ as much as possible.",2.2.1 Rerank,[0],[0]
"Here we use the widely-used summarization evaluation metrics ROUGE (Lin, 2004) to measure the actual saliency s∗(r,y∗) (see Section 3.2).",2.2.1 Rerank,[0],[0]
We utilize the hidden states of x and r to predict the saliency s of the template.,2.2.1 Rerank,[0],[0]
"Specifically, we regard the output of the BiRNN as the representation of the sentence or template:
hx =",2.2.1 Rerank,[0],[0]
[ ←− h x1 ; −→ h x−1] (2) hr =,2.2.1 Rerank,[0],[0]
[ ←− h r1; −→ h r−1],2.2.1 Rerank,[0],[0]
"(3)
Next, we use Bilinear network to predict the saliency of the template for the input sentence.
",2.2.1 Rerank,[0],[0]
"s(r,x) = sigmoid(hrWshTx + bs), (4)
where Ws and bs are parameters of the Bilinear network, and we add the sigmoid activation function to make the range of s consistent with the actual saliency s∗.",2.2.1 Rerank,[0],[0]
"According to Chen et al. (2016), Bilinear outperforms multi-layer forward
neural networks in relevance measurement.",2.2.1 Rerank,[0],[0]
"As shown later, the difference of s and s∗ will provide additional supervisions for the seq2seq framework.",2.2.1 Rerank,[0],[0]
The soft template r selected by the Rerank module has already competed with the state-of-the-art method in terms of ROUGE evaluation (see Table 4).,2.2.2 Rewrite,[0],[0]
"However, r usually contains a lot of named entities that does not appear in the source (see Table 5).",2.2.2 Rewrite,[0],[0]
"Consequently, it is hard to ensure that the soft templates are faithful to the input sentences.",2.2.2 Rewrite,[0],[0]
"Therefore, we leverage the strong rewriting ability of the seq2seq model to generate more faithful and informative summaries.",2.2.2 Rewrite,[0],[0]
"Specifically, since the input of our system consists of both the sentence and soft template, we use the concatenation function3 to combine the hidden states of the sentence and template:
Hc =",2.2.2 Rewrite,[0],[0]
"[h x 1 ; · · · ;hx−1;hr1; · · · ;hr−1] (5)
",2.2.2 Rewrite,[0],[0]
"The combined hidden states are fed into the prevailing attentional RNN decoder (Bahdanau et al., 2014) to generate the decoding hidden state at the position t:
st = Att-RNN(st−1, yt−1,Hc), (6)
where yt−1 is the previous output summary word.",2.2.2 Rewrite,[0],[0]
"Finally, a softmax layer is introduced to predict the current summary word:
ot = softmax(stWo), (7)
where Wo is a parameter matrix.",2.2.2 Rewrite,[0],[0]
There are two types of costs in our system.,2.3 Learning,[0],[0]
"For Rerank, we expect the predicted saliency s(r,x) close to the actual saliency s∗(r,y∗).",2.3 Learning,[0],[0]
"Therefore,
3We also attempted complex combination approaches such as the gate network Cao et al. (2017b) but failed to achieve obvious improvement.",2.3 Learning,[0],[0]
"We assume the Rerank module has partially played the role of the gate network.
",2.3 Learning,[0],[0]
"we use the cross entropy (CE) between s and s∗ as the loss function:
JR(θ) = CE(s(r,x), s ∗(r,y∗)) (8)
= −s∗ log s− (1− s∗) log(1− s),
where θ stands for the model parameters.",2.3 Learning,[0],[0]
"For Rewrite, the learning goal is to maximize the estimated probability of the actual summary y∗.",2.3 Learning,[0],[0]
"We adopt the common negative log-likelihood (NLL) as the loss function:
JG(θ)",2.3 Learning,[0],[0]
=,2.3 Learning,[0],[0]
"− log(p(y∗|x, r))",2.3 Learning,[0],[0]
(9) =,2.3 Learning,[0],[0]
"− ∑
t log(ot[y
∗ t ])
To make full use of supervisions from both sides, we combine the above two costs as the final loss function:
J(θ) = JR(θ)",2.3 Learning,[0],[0]
+ JG(θ),2.3 Learning,[0],[0]
"(10)
We use mini-batch Stochastic Gradient Descent (SGD) to tune model parameters.",2.3 Learning,[0],[0]
The batch size is 64.,2.3 Learning,[0],[0]
"To enhance generalization, we introduce dropout (Srivastava et al., 2014) with probability p = 0.3 for the RNN layers.",2.3 Learning,[0],[0]
"The initial learning rate is 1, and it will decay by 50% if the generation loss does not decrease on the validation set.",2.3 Learning,[0],[0]
"We conduct experiments on the Annotated English Gigaword corpus, as with (Rush et al., 2015b).",3.1 Datasets,[0],[0]
This parallel corpus is produced by pairing the first sentence in the news article and its headline as the summary with heuristic rules.,3.1 Datasets,[0],[0]
"All the training, development and test datasets can be downloaded at https://github.",3.1 Datasets,[0],[0]
com/harvardnlp/sent-summary.,3.1 Datasets,[0],[0]
The statistics of the Gigaword corpus is presented in Table 1.,3.1 Datasets,[0],[0]
"We adopt ROUGE (Lin, 2004) for automatic evaluation.",3.2 Evaluation Metrics,[0],[0]
ROUGE has been the standard evaluation metric for DUC shared tasks since 2004.,3.2 Evaluation Metrics,[0],[0]
"It measures the quality of summary by computing the overlapping lexical units between the candidate summary and actual summaries, such as unigram, bi-gram and longest common subsequence (LCS).",3.2 Evaluation Metrics,[0],[0]
"Following the common practice, we report ROUGE-1 (uni-gram), ROUGE-2 (bi-gram) and ROUGE-L (LCS) F1 scores4 in the following experiments.",3.2 Evaluation Metrics,[0],[0]
"We also measure the actual saliency of a candidate template r with its combined ROUGE scores given the actual summary y∗:
s∗(r,y∗) = RG(r,y∗) +",3.2 Evaluation Metrics,[0],[0]
"RG(r,y∗), (11)
where “RG” stands for ROUGE for short.",3.2 Evaluation Metrics,[0],[0]
ROUGE mainly evaluates informativeness.,3.2 Evaluation Metrics,[0],[0]
"We also introduce a series of metrics to measure the summary quality from the following aspects: LEN DIF The absolute value of the length diffe-
rence between the generated summaries and the actual summaries.",3.2 Evaluation Metrics,[0],[0]
We use mean value ± standard deviation to illustrate this item.,3.2 Evaluation Metrics,[0],[0]
"The average value partially reflects the readability and informativeness, while the standard deviation links to stability.
",3.2 Evaluation Metrics,[0],[0]
"4We use the ROUGE evaluation option: -m -n 2 -w 1.2
LESS 3",3.2 Evaluation Metrics,[0],[0]
"The number of the generated summaries, which contains less than three tokens.",3.2 Evaluation Metrics,[0],[0]
These extremely short summaries are usually unreadable.,3.2 Evaluation Metrics,[0],[0]
COPY,3.2 Evaluation Metrics,[0],[0]
The proportion of the summary words (without stopwords) copied from the source sentence.,3.2 Evaluation Metrics,[0],[0]
A seriously large copy ratio indicates that the summarization system pays more attention to compression rather than required abstraction.,3.2 Evaluation Metrics,[0],[0]
NEW NE,3.2 Evaluation Metrics,[0],[0]
The number of the named entities that do not appear in the source sentence or actual summary.,3.2 Evaluation Metrics,[0],[0]
"Intuitively, the appearance of new named entities in the summary is likely to bring unfaithfulness.",3.2 Evaluation Metrics,[0],[0]
We use Stanford CoreNLP,3.2 Evaluation Metrics,[0],[0]
"(Manning et al., 2014) to recognize named entities.",3.2 Evaluation Metrics,[0],[0]
We use the popular seq2seq framework OpenNMT5 as the starting point.,3.3 Implementation Details,[0],[0]
"To make our model more general, we retain the default settings of OpenNMT to build the network architecture.",3.3 Implementation Details,[0],[0]
"Specifically, the dimensions of word embeddings and RNN are both 500, and the encoder and decoder structures are two-layer bidirectional Long Short Term Memory Networks (LSTMs).",3.3 Implementation Details,[0],[0]
The only difference is that we add the argument “- share embeddings” to share the word embeddings between the encoder and decoder.,3.3 Implementation Details,[0],[0]
This practice largely reduces model parameters for the monolingual task.,3.3 Implementation Details,[0],[0]
"On our computer (GPU: GTX 1080, Memory: 16G, CPU: i7-7700K), the training spends about 2 days.
",3.3 Implementation Details,[0],[0]
"During test, we use beam search of size 5 to generate summaries.",3.3 Implementation Details,[0],[0]
We add the argument “- replace unk” to replace the generated unknown words with the source word that holds the highest attention weight.,3.3 Implementation Details,[0],[0]
"Since the generated summaries are often shorter than the actual ones, we introduce an additional length penalty argument “- alpha 1” to encourage longer generation, like Wu et al. (2016).",3.3 Implementation Details,[0],[0]
"We compare our proposed model with the following state-of-the-art neural summarization systems: ABS Rush et al. (2015a) used an attentive CNN
encoder and a NNLM decoder to summarize 5https://github.com/OpenNMT/OpenNMT-py
the sentence.",3.4 Baselines,[0],[0]
ABS+,3.4 Baselines,[0],[0]
"Rush et al. (2015a) further tuned the ABS
model with additional hand-crafted features to balance between abstraction and extraction.
",3.4 Baselines,[0],[0]
"RAS-Elman As the extension of the ABS model, it used a convolutional attention-based encoder and a RNN decoder (Chopra et al., 2016).",3.4 Baselines,[0],[0]
"Featseq2seq Nallapati et al. (2016) used a complete seq2seq RNN model and added the hand-crafted features such as POS tag and NER, to enhance the encoder representation.",3.4 Baselines,[0],[0]
Luong-NMT Chopra et al. (2016) implemented the neural machine translation model of Luong et al. (2015) for summarization.,3.4 Baselines,[0],[0]
This model contained two-layer LSTMs with 500 hidden units in each layer.,3.4 Baselines,[0],[0]
OpenNMT,3.4 Baselines,[0],[0]
We also implement the standard attentional seq2seq model with OpenNMT.,3.4 Baselines,[0],[0]
All the settings are the same as our system.,3.4 Baselines,[0],[0]
It is noted that OpenNMT officially examined the Gigaword dataset.,3.4 Baselines,[0],[0]
We distinguish the official result6 and our experimental result with suffixes “O” and “I” respectively.,3.4 Baselines,[0],[0]
"FTSum Cao et al. (2017b) encoded the facts extracted from the source sentence to improve both the faithfulness and informativeness of generated summaries.
",3.4 Baselines,[0],[0]
"In addition, to evaluate the effectiveness of our joint learning framework, we develop a baseline named “PIPELINE”.",3.4 Baselines,[0],[0]
Its architecture is identical to Re3Sum.,3.4 Baselines,[0],[0]
"However, it trains the Rerank module and Rewrite module in pipeline.",3.4 Baselines,[0],[0]
Let’s first look at the final cost values (Eq. 9) on the development set.,3.5 Informativeness Evaluation,[0],[0]
"From Table 2, we can
6http://opennmt.net/Models/
see that our model achieves much lower perplexity compared against the state-of-the-art systems.",3.5 Informativeness Evaluation,[0],[0]
It is also noted that PIPELINE slightly outperforms Re3Sum.,3.5 Informativeness Evaluation,[0],[0]
"One possible reason is that Re3Sum additionally considers the cost derived from the Rerank module.
",3.5 Informativeness Evaluation,[0],[0]
The ROUGE F1 scores of different methods are then reported in Table 3.,3.5 Informativeness Evaluation,[0],[0]
"As can be seen, our model significantly outperforms most other approaches.",3.5 Informativeness Evaluation,[0],[0]
"Note that, ABS+ and Featseq2seq have utilized a series of hand-crafted features, but our model is completely data-driven.",3.5 Informativeness Evaluation,[0],[0]
"Even though, our model surpasses Featseq2seq by 22% and ABS+ by 60% on ROUGE-2.",3.5 Informativeness Evaluation,[0],[0]
"When soft templates are ignored, our model is equivalent to the standard at-
tentional seq2seq model OpenNMTI .",3.5 Informativeness Evaluation,[0],[0]
"Therefore, it is safe to conclude that soft templates have great contribute to guide the generation of summaries.
",3.5 Informativeness Evaluation,[0],[0]
We also examine the performance of directly regarding soft templates as output summaries.,3.5 Informativeness Evaluation,[0],[0]
We introduce five types of different soft templates:,3.5 Informativeness Evaluation,[0],[0]
Random An existing summary randomly selected from the training corpus.,3.5 Informativeness Evaluation,[0],[0]
First The top-ranked candidate template given by the Retrieve module.,3.5 Informativeness Evaluation,[0],[0]
"Max The template with the maximal actual
ROUGE scores among the 30 candidate templates.
",3.5 Informativeness Evaluation,[0],[0]
Optimal An existing summary in the training corpus which holds the maximal ROUGE scores.,3.5 Informativeness Evaluation,[0],[0]
Rerank The template with the maximal predicted ROUGE scores among the 30 candidate templates.,3.5 Informativeness Evaluation,[0],[0]
"It is the actual soft template we adopt.
",3.5 Informativeness Evaluation,[0],[0]
"As shown in Table 4, the performance of Random is terrible, indicating it is impossible to use one summary template to fit various actual summaries.",3.5 Informativeness Evaluation,[0],[0]
"Rerank largely outperforms First, which verifies the effectiveness of the Rerank module.",3.5 Informativeness Evaluation,[0],[0]
"However, according to Max and Rerank, we find the Rerank performance of Re3Sum is far from perfect.",3.5 Informativeness Evaluation,[0],[0]
"Likewise, comparing Max and First, we observe that the improving capacity of the Retrieve module is high.",3.5 Informativeness Evaluation,[0],[0]
Notice that Optimal greatly exceeds all the state-of-the-art approaches.,3.5 Informativeness Evaluation,[0],[0]
This finding strongly supports our practice of using existing summaries to guide the seq2seq models.,3.5 Informativeness Evaluation,[0],[0]
"We also measure the linguistic quality of generated summaries from various aspects, and the results are present in Table 5.",3.6 Linguistic Quality Evaluation,[0],[0]
"As can be seen from the rows “LEN DIF” and “LESS 3”, the performance of Re3Sum is almost the same as that of soft templates.",3.6 Linguistic Quality Evaluation,[0],[0]
The soft templates indeed well guide the summary generation.,3.6 Linguistic Quality Evaluation,[0],[0]
"Compared with
Re3Sum, the standard deviation of LEN DF is 0.7 times larger in OpenNMT, indicating that OpenNMT works quite unstably.",3.6 Linguistic Quality Evaluation,[0],[0]
"Moreover, OpenNMT generates 53 extreme short summaries, which seriously reduces readability.",3.6 Linguistic Quality Evaluation,[0],[0]
"Meanwhile, the copy ratio of actual summaries is 36%.",3.6 Linguistic Quality Evaluation,[0],[0]
"Therefore, the copy mechanism is severely overweighted in OpenNMT.",3.6 Linguistic Quality Evaluation,[0],[0]
"Our model is encouraged to generate according to human-written soft templates, which relatively diminishes copying from the source sentences.",3.6 Linguistic Quality Evaluation,[0],[0]
Look at the last row “NEW NE”.,3.6 Linguistic Quality Evaluation,[0],[0]
"A number of new named entities appear in the soft templates, which makes them quite unfaithful to source sentences.",3.6 Linguistic Quality Evaluation,[0],[0]
"By contrast, this index in Re3Sum is close to the OpenNMT’s.",3.6 Linguistic Quality Evaluation,[0],[0]
It highlights the rewriting ability of our seq2seq framework.,3.6 Linguistic Quality Evaluation,[0],[0]
"In this section, we investigate how soft templates affect our model.",3.7 Effect of Templates,[0],[0]
"At the beginning, we feed different types of soft templates (refer to Table 4) into the Rewriting module of Re3Sum.",3.7 Effect of Templates,[0],[0]
"As illustrated in Table 6, the more high-quality templates are provided, the higher ROUGE scores are achieved.",3.7 Effect of Templates,[0],[0]
"It is interesting to see that,while the ROUGE-2 score of Random templates is zero, our model can still generate acceptable summaries with Random templates.",3.7 Effect of Templates,[0],[0]
It seems that Re3Sum can automatically judge whether the soft templates are trustworthy and ignore the seriously irrelevant ones.,3.7 Effect of Templates,[0],[0]
"We believe that the joint learning with the Rerank model plays a vital role here.
",3.7 Effect of Templates,[0],[0]
"Next, we manually inspect the summaries generated by different methods.",3.7 Effect of Templates,[0],[0]
"We find the outputs of Re3Sum are usually longer and more flu-
ent than the outputs of OpenNMT.",3.7 Effect of Templates,[0],[0]
Some illustrative examples are shown in Table 7.,3.7 Effect of Templates,[0],[0]
"In Example 1, there is no predicate in the source sentence.",3.7 Effect of Templates,[0],[0]
"Since OpenNMT prefers selecting source words around the predicate to form the summary, it fails on this sentence.",3.7 Effect of Templates,[0],[0]
"By contract, Re3Sum rewrites the template and produces an informative summary.",3.7 Effect of Templates,[0],[0]
"In Example 2, OpenNMT deems the starting part of the sentences are more important, while our model, guided by the template, focuses on the second part to generate the summary.
",3.7 Effect of Templates,[0],[0]
"In the end, we test the ability of our model to generate diverse summaries.",3.7 Effect of Templates,[0],[0]
"In practice, a system that can provide various candidate summaries is probably more welcome.",3.7 Effect of Templates,[0],[0]
"Specifically, two candidate templates with large text dissimilarity are manually fed into the Rewriting module.",3.7 Effect of Templates,[0],[0]
The corresponding generated summaries are shown in Table 8.,3.7 Effect of Templates,[0],[0]
"For the sake of comparison, we also present the 2-best results of OpenNMT with beam search.",3.7 Effect of Templates,[0],[0]
"As can be seen, with different templates given, our model is likely to generate dissimilar summaries.",3.7 Effect of Templates,[0],[0]
"In contrast, the 2-best results of OpenNMT is almost the same, and often a shorter summary is only a piece of the other one.",3.7 Effect of Templates,[0],[0]
"To sum up, our model demonstrates promising prospect in generation diversity.",3.7 Effect of Templates,[0],[0]
"Abstractive sentence summarization aims to produce a shorter version of a given sentence while preserving its meaning (Chopra et al., 2016).",4 Related Work,[0],[0]
"This task is similar to text simplification (Saggion, 2017) and facilitates headline design and refine.",4 Related Work,[0],[0]
"Early studies on sentence summariza-
tion include template-based methods (Zhou and Hovy, 2004), syntactic tree pruning (Knight and Marcu, 2002; Clarke and Lapata, 2008) and statistical machine translation techniques (Banko et al., 2000).",4 Related Work,[0],[0]
"Recently, the application of the attentional seq2seq framework has attracted growing attention and achieved state-of-the-art performance on this task (Rush et al., 2015a; Chopra et al., 2016; Nallapati et al., 2016).
",4 Related Work,[0],[0]
"In addition to the direct application of the general seq2seq framework, researchers attempted to integrate various properties of summarization.",4 Related Work,[0],[0]
"For example, Nallapati et al. (2016) enriched the encoder with hand-crafted features such as named entities and POS tags.",4 Related Work,[0],[0]
These features have played important roles in traditional feature based summarization systems.,4 Related Work,[0],[0]
Gu et al. (2016) found that a large proportion of the words in the summary were copied from the source text.,4 Related Work,[0],[0]
"Therefore, they proposed CopyNet which considered the copying mechanism during generation.",4 Related Work,[0],[0]
"Recently, See et al. (2017) used the coverage mechanism to discourage repetition.",4 Related Work,[0],[0]
Cao et al. (2017b) encoded facts extracted from the source sentence to enhance the summary faithfulness.,4 Related Work,[0],[0]
There were also studies to modify the loss function to fit the evaluation metrics.,4 Related Work,[0],[0]
"For instance, Ayana et al. (2016) applied the Minimum Risk Training strategy to maximize the ROUGE scores of generated sum-
maries.",4 Related Work,[0],[0]
"Paulus et al. (2017) used the reinforcement learning algorithm to optimize a mixed objective function of likelihood and ROUGE scores.
",4 Related Work,[0],[0]
Guu et al. (2017) also proposed to encode human-written sentences to improvement the performance of neural text generation.,4 Related Work,[0],[0]
"However, they handled the task of Language Modeling and randomly picked an existing sentence in the training corpus.",4 Related Work,[0],[0]
"In comparison, we develop an IR system to find proper existing summaries as soft templates.",4 Related Work,[0],[0]
"Moreover, Guu et al. (2017) used a general seq2seq framework while we extend the seq2seq framework to conduct template reranking and template-aware summary generation simultaneously.",4 Related Work,[0],[0]
This paper proposes to introduce soft templates as additional input to guide the seq2seq summarization.,5 Conclusion and Future Work,[0],[0]
We use the popular IR platform Lucene to retrieve proper existing summaries as candidate soft templates.,5 Conclusion and Future Work,[0],[0]
Then we extend the seq2seq framework to jointly conduct template reranking and template-aware summary generation.,5 Conclusion and Future Work,[0],[0]
"Experiments show that our model can generate informative, readable and stable summaries.",5 Conclusion and Future Work,[0],[0]
"In addition, our model demonstrates promising prospect in generation diversity.
",5 Conclusion and Future Work,[0],[0]
"We believe our work can be extended in vari-
ous aspects.",5 Conclusion and Future Work,[0],[0]
"On the one hand, since the candidate templates are far inferior to the optimal ones, we intend to improve the Retrieve module, e.g., by indexing both the sentence and summary fields.",5 Conclusion and Future Work,[0],[0]
"On the other hand, we plan to test our system on the other tasks such as document-level summarization and short text conversation.
",5 Conclusion and Future Work,[0],[0]
"Acknowledgments
The work described in this paper was supported by Research Grants Council of Hong Kong (PolyU 152036/17E), National Natural Science Foundation of China (61672445 and 61572049) and The Hong Kong Polytechnic University (G-YBP6, 4- BCDV).",5 Conclusion and Future Work,[0],[0]
"Most previous seq2seq summarization systems purely depend on the source text to generate summaries, which tends to work unstably.",abstractText,[0],[0]
"Inspired by the traditional template-based summarization approaches, this paper proposes to use existing summaries as soft templates to guide the seq2seq model.",abstractText,[0],[0]
"To this end, we use a popular IR platform to Retrieve proper summaries as candidate templates.",abstractText,[0],[0]
"Then, we extend the seq2seq framework to jointly conduct template Reranking and templateaware summary generation (Rewriting).",abstractText,[0],[0]
"Experiments show that, in terms of informativeness, our model significantly outperforms the state-of-the-art methods, and even soft templates themselves demonstrate high competitiveness.",abstractText,[0],[0]
"In addition, the import of high-quality external summaries improves the stability and readability of generated summaries.",abstractText,[0],[0]
"Retrieve, Rerank and Rewrite: Soft Template Based Neural Summarization",title,[0],[0]
Revealing common statistical behaviors among a group of subjects is fundamental to neuroscience and bio-medical data analysis.,1. Introduction,[0],[0]
"For example, in functional magnetic resonance imaging (fMRI) research (Bullmore et al., 1996; Smith et al., 2011; Varoquaux & Craddock, 2013), group level analyses are used for detecting brain networks from resting-state recordings (Fox et al., 2005), for detecting activities of specific regions in response to various stimuli (Haxby et al., 2001), for studying the connectivity of a specific brain region to other regions through seed based
1Electrical Engineering Dept., Technion, Israel.",1. Introduction,[0],[0]
"Correspondence to: Andrey Zhitnikov <andreyz@campus.technion.ac.il>, Rotem Mulayoff <smulayof@campus.technion.ac.il>, Tomer Michaeli <tomer.m@ee.technion.ac.il>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"analysis (Hagler et al., 2006), etc.",1. Introduction,[0],[0]
Group analyses often rely on the assumption that all subjects in the group behave according to the same statistical model.,1. Introduction,[0],[0]
"For example, to estimate the covariance (or partial covariance) matrix of several variables, a popular approach is to average the covariance matrices estimated for each of the individual subjects in the group (Power et al., 2011).",1. Introduction,[0],[0]
"This is done using either the Euclidean mean (arithmetic average) or the intrinsic (Riemannian) mean (Förstner & Moonen, 2003), (Fletcher & Joshi, 2007), which respects the geometry of the manifold of positive definite matrices (Varoquaux et al., 2010a).
",1. Introduction,[0],[0]
"Real data, however, rarely conform to this assumption.",1. Introduction,[0],[0]
"Often times, each subject in a group deviates from the common model in a different way.",1. Introduction,[0],[0]
"For example, it has been shown that estimates of connectivity patterns from fMRI scans, tend to vary significantly between subjects (Moussa et al., 2012).",1. Introduction,[0],[0]
Subject-specific deviations may even be more dominant than the common model itself.,1. Introduction,[0],[0]
"Therefore, if ignored, these deviations may severely degrade the quality of the estimate of the common model.",1. Introduction,[0],[0]
This phenomenon is illustrated in Fig. 1 in the context of nonparametric density estimation of two variables (brain regions).,1. Introduction,[0],[0]
"In this example, the deviations from the common model are additive and have a different distribution for each subject.",1. Introduction,[0],[0]
"Thus, as can be seen on the right, kernel density estimation (KDE) applied to the entire group, fails to reveal the common behavior.
",1. Introduction,[0],[0]
Approaches for accounting for subject-specific deviations often make limiting assumptions.,1. Introduction,[0],[0]
"For example, in the context of covariance estimation, (Varoquaux et al., 2010b) assumed that the precision matrices of all subjects in the group have the same sparsity pattern, and proposed a modified graph Lasso technique (Friedman et al., 2008) for simultaneously estimating those matrices.",1. Introduction,[0],[0]
"In (Marrelec et al., 2006), the authors assumed that each subject’s samples follow a Gaussian distribution with a covariance matrix that follows an inverse Wishart distribution around the group covariance.",1. Introduction,[0],[0]
"In the context of regression, a popular strategy is to use a linear mixed-effects model (Friston et al., 2005; Chen et al., 2013), which relies on a Gaussian distribution assumption for the subject specific factors.",1. Introduction,[0],[0]
"Similar lines of work include grouplevel independent component analysis (ICA) (Calhoun et al., 2001; Beckmann & Smith, 2005; Varoquaux et al., 2010c), dictionary learning (Varoquaux et al., 2011; Mensch et al., 2016), and causal structure estimation (Ramsey et al., 2010).
",1. Introduction,[0],[0]
In this paper we present non-parametric methods for estimating a common model in the presence of subject-specific noise factors.,1. Introduction,[0],[0]
"Specifically, we present a common-covariance estimation algorithm and a common probability density function (pdf) estimation method, both of which do not assume any particular form for the underlying distributions.",1. Introduction,[0],[0]
Our only assumption is that the subject-specific noise factors are additive and have diverse distributions (otherwise they could be considered part of the common model).,1. Introduction,[0],[0]
"In this setting, the Euclidean and Riemannian mean estimates do not approach the true covariance matrix as the number of subjects grows.",1. Introduction,[0],[0]
"In contrast, we prove that our estimate does converge to the true covariance under very mild assumptions.",1. Introduction,[0],[0]
We verify the advantages of our approach through extensive experiments on simulated and on real data.,1. Introduction,[0],[0]
"Let u ∈ Rd be a random vector, which represents the common source of variability across a group of subjects.",2. Problem formulation,[0],[0]
"For example, in Fig. 1, u ∈ R2 is distributed according to the ‘ground truth’ density function (top right).",2. Problem formulation,[0],[0]
"Let xj ∈ Rd be a random vector, which represents the jth subject in the group (in Fig. 1, the jth scatter plot shows realizations of xj).",2. Problem formulation,[0],[0]
"We assume the additive model
xj = u+ vj , (1)
where {vj} are random vectors that are independent of u and represent subject-specific factors.",2. Problem formulation,[0],[0]
"Generally, each vj has a different distribution (had they been distributed identically, they would have been part of the common model).
",2. Problem formulation,[0],[0]
"Given realizations of xj , for j = 1 . .",2. Problem formulation,[0],[0]
".m, our goal is to estimate statistical properties of the common component u.
In particular, we are interested in estimating either the covariance matrix Σu or the full pdf pu of u.
Obviously, the performance in those estimation tasks will generally depend on both the number of subjects m and the number of samples per subject.",2. Problem formulation,[0],[0]
"However, here, we are interested in the common situation in which the number of samples per subject suffices to obtain reasonably accurate estimates for Σxj or pxj (e.g., when the dimension d is relatively small).",2. Problem formulation,[0],[0]
Our assumption is thus that the covariances (or pdfs) of the subjects xj are known and our focus is on the problem of recovering the common covariance (or pdf) from them.,2. Problem formulation,[0],[0]
"To apply our algorithms in practice, one has to plug in estimates of the covariances (or pdfs) of the subjects (obtained using, e.g., KDE).",2. Problem formulation,[0],[0]
"Since u and vj are independent, we have from (1) that
Σxj = Σu + Σvj (2)
for every j = 1, . . .",3. Common covariance estimation,[0],[0]
",m. We would like to estimate the covariance matrix Σu of the common component, given the covariance matrices {Σxj} of the subjects.",3. Common covariance estimation,[0],[0]
"To avoid ambiguity, we define the common component Σu to be the largest one satisfying such a decomposition.",3. Common covariance estimation,[0],[0]
"In particular, this means that the smallest eigenvalue of (at least some of) the subject-specific factors {Σvj} must be arbitrarily small.",3. Common covariance estimation,[0],[0]
"Indeed, otherwise there would exist some α > 0",3. Common covariance estimation,[0],[0]
such that Σvj αI for every j so that αI would be common to all {Σvj} and not subject-specific.,3. Common covariance estimation,[0],[0]
"In other words, the common component in this case is in fact Σu + αI and the noise covariances are Σvj − αI .
",3. Common covariance estimation,[0],[0]
"Let us first informally describe the key idea underlying
our method, and then provide a formal “group consistency” result.",3. Common covariance estimation,[0],[0]
Denote the eigenvalues of Σu by λ1 ≤ λ2 ≤ . . .,3. Common covariance estimation,[0],[0]
", λd and the corresponding eigenvectors by q1, q2, . . .",3. Common covariance estimation,[0],[0]
", qd.",3. Common covariance estimation,[0],[0]
"We will begin by estimating the smallest eigenvalue, λ1, and its associated eigenvector, q1.",3. Common covariance estimation,[0],[0]
"By definition,
λ1 = min ‖q‖=1
qTΣuq. (3)
Now, observe that
qTΣuq ≤ qTΣxjq, ∀j,∀q (4)
since qTΣxjq = q TΣuq + q TΣvjq and q TΣvjq ≥ 0.",3. Common covariance estimation,[0],[0]
"Our assumption, which we formalize mathematically below, is that the subject-specific noise covariances Σvj are diverse in the sense that their bottom eigenvectors tend to point in different directions.",3. Common covariance estimation,[0],[0]
"This, together with the fact their smallest eigenvalue can be arbitrarily small, implies that as the number of subjects grows, it becomes increasingly likely that for every direction q, at least one of the values {qTΣvjq}mj=1 be small.",3. Common covariance estimation,[0],[0]
"This motivates us to estimate λ1 and q1 as
q̂1 = arg min ‖q‖=1 min j∈{1,...,m}
qTΣxjq, (5)
λ̂1 = min ‖q‖=1 min j∈{1,...,m}
qTΣxjq. (6)
That is, we minimize over the pointwise minimum of the quadratic functions of the individual subjects.",3. Common covariance estimation,[0],[0]
Figure 2 visualizes this objective for the case of 2× 2 matrices.,3. Common covariance estimation,[0],[0]
"Here, the thick blue curve corresponds to the desired objective function (3), which we cannot directly minimize (as it involves the unknown Σu).",3. Common covariance estimation,[0],[0]
"The thin curves correspond to
Algorithm 1 Common covariance estimation Input: Covariance matrices Σx1 , . . .",3. Common covariance estimation,[0],[0]
",Σxm in Rd×d.",3. Common covariance estimation,[0],[0]
Output: Common covariance estimate Σ̂u.,3. Common covariance estimation,[0],[0]
for k = 1 . . .,3. Common covariance estimation,[0],[0]
"d do
Using (14), compute q̂k and λ̂k as
q̂k = arg min q∈Sk min j∈{1,...,m}
qTΣxjq, (11)
",3. Common covariance estimation,[0],[0]
"λ̂k = min q∈Sk min j∈{1,...,m}
qTΣxjq, (12)
where
Sk = { q : ‖q‖ = 1, q ⊥ span{q̂1, . . .",3. Common covariance estimation,[0],[0]
", q̂k−1} } .
(13)
end for Construct Σ̂u from {q̂k}mk=1 and {λ̂k}mk=1 as in (10).
",3. Common covariance estimation,[0],[0]
the quadratic functions of the subjects (involving the known matrices {Σxj}).,3. Common covariance estimation,[0],[0]
"As can be seen, the pointwise minimum of the thin curves (dotted curve) is close to the thick curve when the number of subjects is large.
",3. Common covariance estimation,[0],[0]
"Next, we turn to estimate λ2 and q2.",3. Common covariance estimation,[0],[0]
"Note that
λ2 = min {q:‖q‖=1,q⊥q1}
qTΣuq
≤ min {q:‖q‖=1,q⊥q1} qTΣxjq, ∀j.",3. Common covariance estimation,[0],[0]
"(7)
Therefore, following the logic above, and replacing q1 by its estimate q̂1, we propose to calculate q̂2 and λ̂2 as
q̂2 = arg min {q:‖q‖=1,q⊥q̂1} min j∈{1,...,m}
qTΣxjq, (8)
λ̂2 = min {q:‖q‖=1,q⊥q̂1} min j∈{1,...,m}
qTΣxjq. (9)
",3. Common covariance estimation,[0],[0]
"This process can be repeated, where at the kth step, we constrain the search to the subspace orthogonal to span{q̂1, . . .",3. Common covariance estimation,[0],[0]
", q̂k−1}.",3. Common covariance estimation,[0],[0]
"The last eigenvector, q̂d, is completely determined by q̂1, . . .",3. Common covariance estimation,[0],[0]
", q̂d−1 and thus does not involve an optimization problem.",3. Common covariance estimation,[0],[0]
"The associated eigenvalue is estimated as λ̂d = minj∈{1,...,m} q̂ T d Σxj q̂d.
",3. Common covariance estimation,[0],[0]
"Having estimated all the eigenvalues and eigenvectors, we construct our estimate of Σu as
Σ̂u = d∑ k=1 λ̂kq̂kq̂",3. Common covariance estimation,[0],[0]
T k .,3. Common covariance estimation,[0],[0]
"(10)
",3. Common covariance estimation,[0],[0]
This is summarized in Alg. 1.,3. Common covariance estimation,[0],[0]
"The objective in Problems (11),(12) is the pointwise minimum of a finite set of continuous (quadratic) functions over
a compact set.",3.1. Practical implementation,[0],[0]
"Therefore, the minimum is attained at the minimum of one of those functions, each of which has a closed form.",3.1. Practical implementation,[0],[0]
"Specifically, when k = 1, we only have the constraint ‖q‖ = 1, and the minimum of the jth problem is the smallest eigenvalue of Σxj (attained by the corresponding eigenvector).",3.1. Practical implementation,[0],[0]
"When k > 1, we have an additional set of linear constraints, which can be written asQkq = 0, where Qk = ∑k−1 i=1",3.1. Practical implementation,[0],[0]
q̂iq̂ T i .,3.1. Practical implementation,[0],[0]
"In this case, the minimizer is given by the top eigenvector of (I −Qk)(cI −Σxj )(I −Qk), which we denote by vkj , where c is any constant such that cI −Σxj 0",3.1. Practical implementation,[0],[0]
"(Blau & Michaeli, 2017).",3.1. Practical implementation,[0],[0]
"Thus, in summary,
q̂k = v k j∗ , λ̂k = (v k j∗) TΣxjv k j∗ , (14)
where j∗ = arg minj∈{1,...,m}(v k j )",3.1. Practical implementation,[0],[0]
"TΣxjv k j .
",3.1. Practical implementation,[0],[0]
"In the Supplementary Material, we discuss ways to speed up the estimation on parallel platforms.",3.1. Practical implementation,[0],[0]
To analyze the behavior of Alg.,3.2. Group consistency,[0],[0]
"1 as the number of subjects m increases, one must assume something regarding the variability of the subject-specific noise covariances Σvj .",3.2. Group consistency,[0],[0]
"A rather general assumption is that they are independent draws from some distribution over PSD matrices, namely
Σvj ∼ pΣv .",3.2. Group consistency,[0],[0]
"(15)
The next theorem shows that under very mild conditions on pΣv , our estimate Σ̂u converges to Σu almost surely (a.s.).",3.2. Group consistency,[0],[0]
"We refer to this as group consistency.
",3.2. Group consistency,[0],[0]
Theorem 1 (Group consistency).,3.2. Group consistency,[0],[0]
"Assume that
P (λmax(Σv) ≤ α) = 1 (16)
for some α > 0 and that P ( qTΣvq ≤ )",3.2. Group consistency,[0],[0]
"> 0 (17)
for every > 0 and every unit-norm q. Let Σ̂ m
u denote the estimate produced by Alg. 1 using m subjects.",3.2. Group consistency,[0],[0]
"Then
P (
lim m→∞ ∥∥∥Σ̂mu −Σu∥∥∥ = 0) = 1. (18) Assumption (16) merely states that the noise factors are not arbitrarily large.",3.2. Group consistency,[0],[0]
Assumption (17) is a condition on the distribution of the smallest eigenvalue of Σv and its associated eigenvector.,3.2. Group consistency,[0],[0]
"Roughly speaking, it requires that there be a positive probability for the smallest eigenvalue to be arbitrarily small and, simultaneously, for the corresponding eigenvector to point in any direction (i.e., this eigenvector can have any distribution on the unit sphere as long as it does not vanish on a set of nonzero Lebesgue measure).",3.2. Group consistency,[0],[0]
"Recall that the condition on the smallest eigenvalue is actually
part of the definition of the common covariance estimation problem, and therefore not a limiting assumption.
",3.2. Group consistency,[0],[0]
"To prove the theorem, let us denote ψ(q) , qTΣuq, gj(q) , qTΣvjq, and hm(q) , minj∈{1,...,m} gj(q).",3.2. Group consistency,[0],[0]
Note that ψ(q) is a deterministic function (as Σu is deterministic) whereas {gj(q)} and {hm(q)} are sequences of random functions (as {Σvj} are random).,3.2. Group consistency,[0],[0]
"We will need the following lemmas (see proofs in the Supplementary).
",3.2. Group consistency,[0],[0]
Lemma 1.,3.2. Group consistency,[0],[0]
"For every q, the sequence of random variables {hm(q)} converges to zero almost surely.",3.2. Group consistency,[0],[0]
"Furthermore, for any sequence of vectors {qm}∞m=1 that converges to some vector q∗, the sequence of random variables {hm(qm)} converges to zero almost surely.
",3.2. Group consistency,[0],[0]
Lemma 2.,3.2. Group consistency,[0],[0]
"Let φ(q) be a continuous bounded function on a compact set C, which achieves a strict global minimum at q∗ ∈ C. Let {fn(q)}∞n=1 be a sequence of continuous bounded nonnegative functions on C satisfying fn(q∗)→ 0, and let wn(q) = φ(q) + fn(q).",3.2. Group consistency,[0],[0]
"Then any sequence of the form qn ∈ arg minq∈C wn(q) converges to q∗, and the sequence wn(qn) converges to φ(q ∗).
proof of Theorem 1.",3.2. Group consistency,[0],[0]
"For simplicity, we prove the theorem for d = 2.",3.2. Group consistency,[0],[0]
"The extension to higher dimensions is similar.
",3.2. Group consistency,[0],[0]
"Since problem (11) is symmetric, we can divide the unit circle into two disjoint half circles A and B such that A is closed, and restrict the search for the minimum to A. Let us first assume that λ1 6= λ2.",3.2. Group consistency,[0],[0]
"In this case, the minimum of ψ(q) over the unit circle is achieved at the points q1 and −q1.",3.2. Group consistency,[0],[0]
"Without loss of generality, we assume that q1 ∈",3.2. Group consistency,[0],[0]
A and −q1 ∈,3.2. Group consistency,[0],[0]
B.,3.2. Group consistency,[0],[0]
The objective in (11) can be written as ψ(q) + hm(q).,3.2. Group consistency,[0],[0]
"Since hm(q) is continuous for every m and hm(q1)
",3.2. Group consistency,[0],[0]
a.s.→ 0,3.2. Group consistency,[0],[0]
"(Lemma 1), the conditions of Lemma 2 hold a.s.",3.2. Group consistency,[0],[0]
"Therefore, our estimate of the bottom eigenvector, q̂m1 , converges a.s.",3.2. Group consistency,[0],[0]
"to the true eigenvector q1, namely
q̂m1 a.s.→ q1.",3.2. Group consistency,[0],[0]
"(19)
Our estimate (12) of the bottom eigenvalue, λ̂m1 , can be written as ψ(q̂m1 ) +",3.2. Group consistency,[0],[0]
hm(q̂ m 1 ).,3.2. Group consistency,[0],[0]
"Since q̂ m 1
a.s.→ q1, we have from Lemma 1 that hm(q̂ m 1 )",3.2. Group consistency,[0],[0]
"a.s.→ 0, and therefore λ̂m1 a.s.→ ψ(q1)",3.2. Group consistency,[0],[0]
"= λ1 as well.
",3.2. Group consistency,[0],[0]
"The top eigenvector is given by q2 = Rq1, where R is a 90◦ rotation matrix, and our estimate of this eigenvector is simply q̂2 = Rq̂1.",3.2. Group consistency,[0],[0]
"Therefore, (19) implies that also
q̂m2 a.s.→ q2.",3.2. Group consistency,[0],[0]
"(20)
The convergence of λ̂m2 to λ2 follows similarly by Lemma 1.
",3.2. Group consistency,[0],[0]
Let us now treat the case where λ1 = λ2.,3.2. Group consistency,[0],[0]
"In this setting, the vectors q̂m1 , q̂ m 2 do not necessarily converge.",3.2. Group consistency,[0],[0]
"However, for the matrix Σ̂ m
u to converge to Σu, it suffices that only
the eigenvalue estimates λ̂m1 , λ̂ m 2 converge to λ1, λ2 (in that case, the vectors q̂m1 , q̂ m 2 have no effect in (10)).",3.2. Group consistency,[0],[0]
"To see that the eigenvalues converge, note that the solution of (12) is bounded from below by minq∈S1 ψ(q) = λ1, because hm(q) ≥ 0.",3.2. Group consistency,[0],[0]
"Additionally, we have that
λ̂m1 = min q∈S1 min j∈{1,...,m} qTΣxjq
= λ1 + min q∈S1 hm(q) ≤",3.2. Group consistency,[0],[0]
"λ1 + hm(q̄) a.s.→ λ1, (21)
where q̄ is an arbitrary point in S1, and the convergence is due to Lemma 1.",3.2. Group consistency,[0],[0]
Therefore λ̂m1 converges to λ1.,3.2. Group consistency,[0],[0]
"Similar arguments can be invoked to show that λ̂m2 converges to λ2.
",3.2. Group consistency,[0],[0]
"Since the eigenvectors and eigenvalues converge, Σ̂ m
u converges to Σu, and the proof is complete.",3.2. Group consistency,[0],[0]
"Next, we address the problem of estimating the pdf pu of the common component, given the pdfs {pxj} of the subjects in the group.
",4. Common density function estimation,[0],[0]
"Since u and xj are statistically independent, we have that pxj (α) =",4. Common density function estimation,[0],[0]
( pu ∗ pvj ),4. Common density function estimation,[0],[0]
"(α), (22)
where ‘∗’ denotes convolution.",4. Common density function estimation,[0],[0]
"Furthermore,
ϕxj (t) = ϕu(t)ϕvj (t), (23)
where ϕz(t) =",4. Common density function estimation,[0],[0]
"E[ejt T z] denotes the characteristic function of a random vector z. We will focus on estimating ϕu(t), from which pu can be retrieved by a Fourier transform.
",4. Common density function estimation,[0],[0]
"A well known property of characteristic functions is that |ϕz(t)| ≤ 1 for every t. Therefore, we have from (23) that |ϕu(t)| ≥ |ϕxj (t)| for every j and for all t. In particular,
|ϕu(t)|",4. Common density function estimation,[0],[0]
"≥ max j∈{1,...,m} ∣∣ϕxj (t)∣∣ , ∀t. (24) Based on this observation, we propose to take the maximum among the values {|ϕxj (t)|}mj=1 as our estimate of |ϕu(t)|, for every t.",4. Common density function estimation,[0],[0]
"The idea is that if the noise characteristic functions {ϕvj (t)} are diverse, then for every t, it is likely that at least one of them attain a value close to 1 (in absolute value).",4. Common density function estimation,[0],[0]
"Namely, at least one of the values {|ϕxj (t)|} is close to |ϕu(t)|, which justifies our estimator.",4. Common density function estimation,[0],[0]
"To estimate the phase of ϕu(t), we take the phase of the characteristic function ϕxj (t) that attains the maximum.",4. Common density function estimation,[0],[0]
"That is, we construct our estimate as
k(t) = arg max j∈{1,...,m} |ϕxj (t)|,
ϕ̂u(t) = ϕxk(t)(t).",4. Common density function estimation,[0],[0]
"(25)
Algorithm 2 Common density estimation",4. Common density function estimation,[0],[0]
"Input: Density functions px1 , . . .",4. Common density function estimation,[0],[0]
", pxm .",4. Common density function estimation,[0],[0]
Output: Common density estimate p̂u. for j = 1 . .,4. Common density function estimation,[0],[0]
.m,4. Common density function estimation,[0],[0]
"do
Set ϕxj ← IDFT{pxj}.",4. Common density function estimation,[0],[0]
"for all t do
Set k as the index of the largest value in {ϕxj (t)}.",4. Common density function estimation,[0],[0]
"Set ϕ̂u(t)← ϕxk(t).
end for end for Set p̂u ← DFT{ϕ̂u}.",4. Common density function estimation,[0],[0]
"Truncate the negative values of p̂u and normalize it to have unit area.
",4. Common density function estimation,[0],[0]
"Note that our phase estimate is accurate when the pdfs {pvj} are symmetric (e.g., when {vj} are zero-mean Gaussian random vectors).",4. Common density function estimation,[0],[0]
"Indeed, in that case the phase of ϕvj is zero, so that the phase of ϕu equals the phase of ϕxj .",4. Common density function estimation,[0],[0]
"Our common pdf estimation algorithm is summarized in Alg. 2.
",4. Common density function estimation,[0],[0]
"It is interesting to note that Alg. 2 has been proposed in the Image Processing community, as a way of removing blur from several blurry images the of same scene (Delbracio & Sapiro, 2015).",4. Common density function estimation,[0],[0]
The analogy to our setting is quite natural.,4. Common density function estimation,[0],[0]
"The functions pxj in our context can be thought of as “blurry” versions of the function pu, where the “blur kernels” are the functions pvj (see (22)).",4. Common density function estimation,[0],[0]
"In this section we verify the effectiveness of our methods, first on simulated data and then on real data.",5. Experiments,[0],[0]
"In our first experiment, we study the behavior of our common covariance estimator as a function of the number of subjects and the signal to noise ratio (SNR).",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"We take the common component u to be a two-dimensional random vector with covariance matrix
Σu =
( 1 0.5
0.5 1
) .",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"(26)
Our goal is to estimate the Pearson correlation coefficient between u(1) and u(2) (which is ρ = 0.5 in this case) from the perturbed versions Σxj = Σu + Σvj .",5.1. Estimation of Pearson correlation coefficient,[0],[0]
This can be done by first estimating Σu and then normalizing the offdiagonal entry by the square-roots of the diagonal entries.,5.1. Estimation of Pearson correlation coefficient,[0],[0]
"We compare our estimator (Alg. 1) with naive averaging of {Σxj} using either Euclidean or Riemannian mean.
",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"We generate the matrices {Σvj} as
Σvj = M jΛjM T j , (27)
",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"whereM j are random rotation matrices whose angles are distributed uniformly in [0, 2π], and Λj are random diagonal matrices",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"Λj = diag{βj1, β j 2} with β j 1 ∼ U [0, b] and βj2 ∼ U [b, 2b] for some b > 0.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"We draw {M j}, {β j 1}, {β j 2} independently.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"The SNR, which we define as SNR = Tr{Σu}/E{Tr{Σv}}, is 1/b in this case.
",5.1. Estimation of Pearson correlation coefficient,[0],[0]
Figures 3 and 4 visualize the mean and variance of our estimator as well as of the naive Euclidean and Riemanian mean estimators (using 200 trials per setting) as functions of the number of subjects and the SNR.,5.1. Estimation of Pearson correlation coefficient,[0],[0]
"As can be seen, while the variance of our estimator is slightly larger than the variances of the naive estimators, its bias is significantly smaller.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"Therefore, overall, it attains a substantially lower mean square error.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
Figure 3 also indicates that our estimator is asymptotically (in the number of subjects) unbiased.,5.1. Estimation of Pearson correlation coefficient,[0],[0]
"The naive estimators, on the other hand, have severe biases, which do not decrease with the number of subjects.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"Figure 4 further illustrates that the performance of the naive
estimators degrades rapidly as the SNR decreases, while our estimator remains relatively accurate even at low SNRs.
",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"In this example, the poor performance of the naive estimators is mainly rooted in their over-estimation of the diagonal entries of Σu.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"This happens because the contributions of the noise matrices {Σvj} are only positive on the diagonal, so that averaging does not cancel them out.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"In most practical cases, the advantage of our approach is not confined to the diagonal elements of Σu.",5.2. Clustered subject-specific noise covariances,[0],[0]
"Specifically, although our algorithm relies on the diversity of the noise covariances, it does not require their eigenvectors to be uniformly distributed on the unit sphere.",5.2. Clustered subject-specific noise covariances,[0],[0]
"Therefore, our technique can even handle cases in which the noise covariances tend to cluster around a certain matrix.",5.2. Clustered subject-specific noise covariances,[0],[0]
"As long as there exists a nonzero probability to encounter matrices away from the cluster, our algorithm is guaranteed to produce an accurate estimate as the number of subjects grows.",5.2. Clustered subject-specific noise covariances,[0],[0]
"This is in contrast to naive averaging, which typically produces estimates with severe bias in all matrix entries.
",5.2. Clustered subject-specific noise covariances,[0],[0]
"To illustrate this, we next perform a 3× 3 common covariance estimation experiment.",5.2. Clustered subject-specific noise covariances,[0],[0]
"We generate Σvj as in (27), where now we construct the unitary matrixM j assin(θ1) cos(θ2) sin(θ1) sin(θ2) cos(θ1)cos(θ1)",5.2. Clustered subject-specific noise covariances,[0],[0]
"cos(θ2) cos(θ1) sin(θ2) − sin(θ1)
− sin(θ2) cos(θ2) 0  , (28) with θ1 and θ2 being two independent random variables with a normal distribution N (1, 1) truncated to [0, π] and
[0, 2π], respectively (Chopin, 2011).
",5.2. Clustered subject-specific noise covariances,[0],[0]
"Figure 5 depicts the estimation results obtained with Alg. 1 and with naive averaging, using 1000 subjects.",5.2. Clustered subject-specific noise covariances,[0],[0]
We show results for three different common covariance matrices.,5.2. Clustered subject-specific noise covariances,[0],[0]
"These include a zero matrix (first row), an identity matrix (second row), and a random PSD matrix (third row).",5.2. Clustered subject-specific noise covariances,[0],[0]
"As can be seen, the Euclidean and Riemannian means produce inaccurate estimates in all entries of the matrix while our estimator produces accurate results.",5.2. Clustered subject-specific noise covariances,[0],[0]
This is despite the preference of the noise covariances towards specific patterns.,5.2. Clustered subject-specific noise covariances,[0],[0]
"Next, we applied our covariance estimation algorithm on the ADHD200-preprocessed dataset (Bellec et al., 2017).",5.3. FMRI data,[0],[0]
We used the Athena pipeline.,5.3. FMRI data,[0],[0]
"In particular, we used preprocessed resting state fMRI data, written into MNI space at
4mm×4mm×4mm voxel resolution.",5.3. FMRI data,[0],[0]
"We removed nuisance variance (Lund, 2001; Fox et al., 2005), applied a temporal bandpass filter (0.009 Hz < f < 0.08 Hz) (Fox et al., 2005; Biswal et al., 1995; Cordes et al., 2001) and a spatial Gaussian filter (6mm FWHM), and removed linear trend from the extracted time-courses.",5.3. FMRI data,[0],[0]
"We took the 458 control subjects from the published training set (for results on 141 subjects with ADHD, please see the Supplementary).",5.3. FMRI data,[0],[0]
"From each subject, we extracted time-courses of 39 regions of interest (ROI) of the MSDL atlas (Varoquaux et al., 2011) and estimated their covariance using the Ledoit-Wolf estimator (Ledoit & Wolf, 2004).",5.3. FMRI data,[0],[0]
This gave us a 39× 39 covariance matrix per subject.,5.3. FMRI data,[0],[0]
"We estimated the common covariance matrix using Alg. 1, using Geometric (Riemannian) mean (Varoquaux et al., 2010a), and using Euclidean mean.",5.3. FMRI data,[0],[0]
"From the estimated covariances, we calculated correlation matrices.",5.3. FMRI data,[0],[0]
"We used the nilearn and scikit-learn python packages
(Abraham et al., 2014; Pedregosa et al., 2011; Buitinck et al., 2013).",5.3. FMRI data,[0],[0]
The running time of Alg. 1 was about 10s on an 8 core Intel i7-6700 with 16GB of RAM working at 3.40GHz.,5.3. FMRI data,[0],[0]
"The results are depicted in Fig. 6.
",5.3. FMRI data,[0],[0]
"It has been shown that estimates of connectivity patterns often vary significantly between subjects (Moussa et al., 2012).",5.3. FMRI data,[0],[0]
"As can be seen in Fig. 6, our estimator detects activity within known networks despite the large variability between subjects.",5.3. FMRI data,[0],[0]
"In particular, our estimator detects stronger correlations than the Euclidean and Riemannian mean estimators within the Default Mode Network, the Right Ventral Attention network, the Left Ventral Attention network, and the Cingulate Insula (connectivity between cingulate cortex and insula) (Moussa et al., 2012).",5.3. FMRI data,[0],[0]
Zoomed versions of those networks are shown in Fig. 7.,5.3. FMRI data,[0],[0]
Note that the Euclidean mean estimator shows very low correlations within some of those regions.,5.3. FMRI data,[0],[0]
"In our last experiment, we used Alg. 2 to estimate the joint density function of arterial blood pressure (ABP) and photoplethysmogram (PPG) recordings.",5.4. Common density of PPG and ABP,[0],[0]
"We used measurements from 25 subjects in critical care taken from the MIMIC 2 dataset (Kachuee et al., 2015).",5.4. Common density of PPG and ABP,[0],[0]
"As a preprocessing step, we normalized the signals to have zero mean and unit variance.
",5.4. Common density of PPG and ABP,[0],[0]
"For each subject, we then estimated the 2D pdf of ABP and PPG using Gaussian KDE with bandwidth 0.08.",5.4. Common density of PPG and ABP,[0],[0]
"From the resulting 25 pdfs, we estimated the common pdf using Alg. 2.",5.4. Common density of PPG and ABP,[0],[0]
"As can be seen in Fig. 8, our algorithm manages to reveal delicate structures in the common pdf, which are not seen when applying KDE on all the data from all the subjects.",5.4. Common density of PPG and ABP,[0],[0]
"In the Supplementary, we show that these structures are not detected with naive KDE with any bandwidth.",5.4. Common density of PPG and ABP,[0],[0]
This illustrates again the ability of our approach to suppress subject-specific noise factors that have different distributions.,5.4. Common density of PPG and ABP,[0],[0]
"We presented algorithms for estimating the covariance and the pdf of the common component of a group of subjects, when noise has a different distribution for each subject.",6. Conclusion,[0],[0]
Our algorithms take advantage of the diversity of the subjectspecific noise distributions in order to efficiently suppress them.,6. Conclusion,[0],[0]
"In contrast to previous approaches, we did not assume any parametric model for the underlying distributions.",6. Conclusion,[0],[0]
"We proved that under rather mild assumptions, our common covariance estimate tends to the covariance of the common component as the number of subjects grows.",6. Conclusion,[0],[0]
"We presented experiments on simulated and on real data, which confirmed the advantages of our methods over alternative approaches.",6. Conclusion,[0],[0]
"In many areas of neuroscience and biological data analysis, it is desired to reveal common patterns among a group of subjects.",abstractText,[0],[0]
"Such analyses play important roles e.g., in detecting functional brain networks from fMRI scans and in identifying brain regions which show increased activity in response to certain stimuli.",abstractText,[0],[0]
"Group level techniques usually assume that all subjects in the group behave according to a single statistical model, or that deviations from the common model have simple parametric forms.",abstractText,[0],[0]
"Therefore, complex subject-specific deviations from the common model severely impair the performance of such methods.",abstractText,[0],[0]
"In this paper, we propose nonparametric algorithms for estimating the common covariance matrix and the common density function of several variables in a heterogeneous group of subjects.",abstractText,[0],[0]
"Our estimates converge to the true model as the number of subjects tends to infinity, under very mild conditions.",abstractText,[0],[0]
We illustrate the effectiveness of our methods through extensive simulations as well as on real-data from fMRI scans and from arterial blood pressure and photoplethysmogram measurements.,abstractText,[0],[0]
Revealing Common Statistical Behaviors in Heterogeneous Populations,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4295–4305 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4295",text,[0],[0]
Neural Machine Translation (NMT) has largely replaced the complex pipeline of Phrase-Based MT with a single model that is trained end-to-end.,1 Introduction,[0],[0]
"However, NMT systems still typically rely on preand post-processing operations such as tokenization and word fragmentation through byte-pair encoding (BPE; Sennrich et al., 2016).",1 Introduction,[0],[0]
"Although these are effective, they involve hyperparameters
∗*Equal contributions
that should ideally be tuned for each language pair and corpus, an expensive step that is frequently omitted.",1 Introduction,[0],[0]
"Even when properly tuned, the representation of the corpus generated by pipelined external processing is likely to be sub-optimal.",1 Introduction,[0],[0]
"For instance, it is easy to find examples of word fragmentations, such as fling → fl + ing, that are linguistically implausible.",1 Introduction,[0],[0]
"NMT systems are generally robust to such infelicities—and can be made more robust through subword regularization (Kudo, 2018)—but their effect on performance has not been carefully studied.",1 Introduction,[0],[0]
"The problem of finding optimal segmentations becomes more complex when an NMT system must handle multiple source and target languages, as in multilingual translation or zero-shot approaches (Johnson et al., 2017).
",1 Introduction,[0],[0]
"Translating characters instead of word fragments avoids these problems, and gives the system access to all available information about source and target sequences.",1 Introduction,[0],[0]
"However, it presents significant modeling and computational challenges.",1 Introduction,[0],[0]
"Longer sequences incur linear per-layer cost and quadratic attention cost, and require information to be retained over longer temporal spans.",1 Introduction,[0],[0]
"Finer temporal granularity also creates the potential for attention jitter (Gulcehre et al., 2017).",1 Introduction,[0],[0]
"Perhaps most significantly, since the meaning of a word is not a compositional function of its characters, the system must learn to memorize many character sequences, a different task from the (mostly) compositional operations it performs at higher levels of linguistic abstraction.
",1 Introduction,[0],[0]
"In this paper, we show that a standard LSTM sequence-to-sequence model works very well for characters, and given sufficient depth, consistently outperforms identical models operating over word fragments.",1 Introduction,[0],[0]
"This result suggests that a productive line of research on character-level models is to seek architectures that approximate standard sequence-to-sequence models while being compu-
tationally cheaper.",1 Introduction,[0],[0]
One approach to this problem is temporal compression: reducing the number of state vectors required to represent input or output sequences.,1 Introduction,[0],[0]
"We evaluate various approaches for performing temporal compression, both according to a fixed schedule; and, more ambitiously, learning compression decisions with a Hierarchical Multiscale architecture (Chung et al., 2017).",1 Introduction,[0],[0]
"Following recent work by Lee et al. (2017), we focus on compressing the encoder.
",1 Introduction,[0],[0]
"Our contributions are as follows:
• The first large-scale empirical investigation of the translation quality of standard LSTM sequence-to-sequence architectures operating at the character level, demonstrating improvements in translation quality over word fragments, and quantifying the effect of corpus size and model capacity.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"A comparison of techniques to compress
character sequences, assessing their ability to trade translation quality for increased speed.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"A first attempt to learn how to compress the
source sequence during NMT training by using the Hierarchical Multiscale LSTM to dynamically shorten the source sequence as it passes through the encoder.",1 Introduction,[0],[0]
"Early work on modeling characters in NMT focused on solving the out-of-vocabulary and softmax bottleneck problems associated with wordlevel models (Ling et al., 2015; Costa-jussà and Fonollosa, 2016; Luong and Manning, 2016).",2 Related Work,[0],[0]
"These took the form of word-boundary-aware hierarchical models, with word-level models delegating to character-level models to generate representations in the encoder and words in the decoder.",2 Related Work,[0],[0]
"Our work will not assume fixed word boundaries are given in advance.
",2 Related Work,[0],[0]
"With the advent of word-fragment approaches, interest in character-level processing fell off, but has recently been reignited with the work of Lee et al. (2017).",2 Related Work,[0],[0]
"They propose a specialized character-level encoder, connected to an unmodified character-level RNN decoder.",2 Related Work,[0],[0]
"They address the modeling and efficiency challenges of long character sequences using a convolutional layer, max-pooling over time, and highway layers.",2 Related Work,[0],[0]
"We agree with their conclusion that character-level translation is effective, but revisit the question
of whether their specific encoder produces a desirable speed-quality tradeoff in the context of a much stronger baseline translation system.",2 Related Work,[0],[0]
"We draw inspiration from their pooling solution for reducing sequence length, along with similar ideas from the speech community (Chan et al., 2016), when devising fixed-schedule reduction strategies in Section 3.3.
",2 Related Work,[0],[0]
One of our primary contributions is an extensive invesigation of the efficacy of a typical LSTM-based NMT system when operating at the character-level.,2 Related Work,[0],[0]
The vast majority of existing studies compare a specialized character-level architecture to a distinct word-level one.,2 Related Work,[0],[0]
"To the best of our knowledge, only a small number of papers have explored running NMT unmodified on character sequences; these include: Luong and Manning (2016) on WMT’15 English-Czech, Wu et al. (2016) on WMT’14 English-German, and Bradbury et al. (2016) on IWSLT German-English.",2 Related Work,[0],[0]
All report scores that either trail behind or reach parity with word-level models.,2 Related Work,[0],[0]
"Only Wu et al. (2016) compare to word fragment models, which they show to outperform characters by a sizeable margin.",2 Related Work,[0],[0]
"We revisit the question of character- versus fragment-level NMT here, and reach quite different conclusions.",2 Related Work,[0],[0]
We adopt a simplified version of the LSTM architecture of Chen et al. (2018) that achieves state-ofthe-art performance on the competitive WMT14 English-French and English-German benchmarks.,3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"This incorporates bidirectional LSTM (BiLSTM) layers in the encoder, concatenating the output from forward and backward directions before feeding the next layer.",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
Output from the top encoder layer is projected down to the decoder dimension and used in an additive attention mechanism computed over the bottom decoder layer.,3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"The decoder consists of unidirectional layers, all of which use the encoder context vectors computed from attention weights over the bottom layer.",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"For both encoder and decoder we use layer normalization (Ba et al., 2016) and residual connections beginning at the third layer.",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
We do not apply a non-linearity to LSTM output.,3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"We regularize with dropout applied to embeddings and to the output of each LSTM layer.
",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"In the interests of simplicity and reproducibil-
ity, we depart from Chen et al. (2018) in several ways: we do not use multi-headed attention, feed encoder context vectors to the softmax, regularize with label smoothing or weight decay, nor apply dropout to the attention mechanism.
",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"Our baseline character models and BPE models both use this architecture, differing only in whether the source and target languages are tokenized into sequences of characters or BPE word fragments.",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
We describe BPE briefly below.,3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"Byte-Pair Encoding (BPE) offers a simple interpolation between word- and character-level representations (Sennrich et al., 2016).",3.2 Byte-Pair Encoding,[0],[0]
It creates a vocabulary of frequent words and word fragments in an iterative greedy merging process that begins with characters and ends when a desired vocabulary size is reached.,3.2 Byte-Pair Encoding,[0],[0]
The source and target language are typically processed together in order to exploit lexical similarities.,3.2 Byte-Pair Encoding,[0],[0]
"Given a vocabulary, BPE re-tokenizes the corpus into word fragments in a greedy left-to-right fashion, selecting the longest possible vocabulary match, and backing off to characters when necessary.
",3.2 Byte-Pair Encoding,[0],[0]
"Since each BPE token consists of one or more characters, BPE-tokenized sequences will be shorter than character sequences.",3.2 Byte-Pair Encoding,[0],[0]
"Viewed as a mechanism to reduce sequence length, BPE differs from the solutions we will discuss subsequently in that it increases the vocabulary size, delegating the task of creating representations for word fragments to the embedding table.",3.2 Byte-Pair Encoding,[0],[0]
"Also, despite being data-driven, its segmentation decisions are fixed before NMT training begins.",3.2 Byte-Pair Encoding,[0],[0]
We explore using fixed stride temporal pooling within the encoder to compress the source character sequence.,3.3 Fixed stride Temporal Pooling,[0],[0]
"These solutions are characterized by pooling the contents of two or more contiguous timesteps to create a single vector that summarizes them, and will replace them to shorten the sequence in the next layer.",3.3 Fixed stride Temporal Pooling,[0],[0]
"These approaches can learn to interpret the raw character sequence in service to their translation objective, but any such interepretation must fit into the pooling schedule that was specified during network construction.",3.3 Fixed stride Temporal Pooling,[0],[0]
"We evaluate two methods in this family: a reimplementation of Lee et al. (2017), and a version of our baseline with interspersed pooling layers.
",3.3 Fixed stride Temporal Pooling,[0],[0]
"As mentioned earlier, Lee et al. (2017) propose a specialized character encoder that combines convolutional layers to accumulate local context, max-pooling layers to reduce sequence lengths, highway layers to increase network capacity, followed by bidirectional GRU layers to generate globally aware contextual source representations.",3.3 Fixed stride Temporal Pooling,[0],[0]
This strategy is particularly efficient because all reductions happen before the first recurrent layer.,3.3 Fixed stride Temporal Pooling,[0],[0]
"We re-implement their approach faithfully, with the exceptions of using LSTMs in place of GRUs,1 and modifying the batch sizes to accomodate our multi-GPU training scheme.
",3.3 Fixed stride Temporal Pooling,[0],[0]
"While pooling based approaches are typically employed in association with convolutional layers, we can also intersperse pooling layers into our high capacity baseline encoder.",3.3 Fixed stride Temporal Pooling,[0],[0]
"This means that after each BiLSTM layer, we have the option to include a fixed-stride pooling layer to compress the sequence before it is processed by the next BiLSTM layer.",3.3 Fixed stride Temporal Pooling,[0],[0]
"This is similar to the pyramidal LSTM encoders used for neural speech recognition (Chan et al., 2016).",3.3 Fixed stride Temporal Pooling,[0],[0]
"This general strategy affords considerable flexibility to the network designer, leaving the type of pooling (concatenation, max, mean), and the strides with which to pool as design decisions that can be tuned to fit the task.",3.3 Fixed stride Temporal Pooling,[0],[0]
"It is unsatisfying to compress a sequence on a fixed schedule; after all, the characters in a sentence do not each carry an identical amount of information.",3.4 Learned Temporal Compression,[0],[0]
"The goal of this section is to explore data-driven reduction methods that are optimized to the NMT system’s objective, and which learn to compress as a part of training.
",3.4 Learned Temporal Compression,[0],[0]
"Any strategy for performing temporal compression will necessarily make discrete decisions, since sentence length is discrete.",3.4 Learned Temporal Compression,[0],[0]
"Examples of such strategies include sparse attention (Raffel et al., 2017) and discrete auto-encoders (Kaiser et al., 2018).",3.4 Learned Temporal Compression,[0],[0]
"For our initial exploration, we chose the hierarchical multiscale (HM) architecture of Chung et al. (2017), which we briefly describe.",3.4 Learned Temporal Compression,[0],[0]
"The HM is a bottom-up temporal subsampling approach, with each layer selecting the timesteps that will survive to the layer above.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"At a given timestep t and layer `, the network makes a binary decision,
1 Development experiments indicated that using LSTMs over GRUs resulted in a slight improvement.
",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"z`t , to determine whether or not it should send its output up to layer `+ 1.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"The preactivation for this decision, z̃`t , is a function of the current node’s inputs from below and from the previous hidden state, similar to an LSTM gate.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"However, z`t ’s activation is a binary step function in the forward pass, to enable discrete decisions, and a hard sigmoid in the backward pass, to allow gradients to flow through the decision point.2",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"The z`t decision affects both the layer above, and the next timestep of the current layer:
• z`t = 1, flow up: the node above (t, `+1) performs a normal LSTM update; the node to the right (t+1, `) performs a modified update called a flush, which ignores the LSTM internal cell at (t, `), and redirects the incoming LSTM hidden state from (t, `) to (t, `+ 1).
",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"• z`t = 0, flow right: the node above (t, `+1) simply copies the cell and hidden state values from (t−1, `+1); the node to the right (t+1, `) performs a normal LSTM update.
",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"Conceptually, when z`t = 0, the node above it becomes a placeholder and is effectively removed from the sequence for that layer.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"Shorter upper layers save computation and facilitate the left-toright flow of information for the surviving nodes.
",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"Typically, one uses the top hidden state hLt from a stack of L RNNs to provide the representation for a timestep t. But for the HM, the top layer may be updated much less frequently than the layers below it.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"To enable tasks that need a distinct representation for each timestep, such as language modeling, the HM employs a gated output module to mix hidden states across layers.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"This learned module combines the states h1t , h 2 t , . .",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
.,3.4.1 Hierarchical Multiscale LSTM,[0],[0]
", h L t using scaling and projection operators to produce a single output ht.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
We would like sequences to become progressively shorter as we move upward through the layers.,3.4.2 Modifying the HM for NMT,[0],[0]
"As originally specified, the HM calculates z`t independently for every t and `, including copied nodes, meaning that a “removed” timestep could reappear in a higher layer when a copied node (t, `) sets z`t = 1.",3.4.2 Modifying the HM for NMT,[0],[0]
"This is easily addressed by locking z ` t = 0 for copied nodes, creating a hierarchical structure
2This disconnect between forward and backward activations is known as a straight-through estimator (Bengio et al., 2013).
in which upper layers never increase the amount of computation.
",3.4.2 Modifying the HM for NMT,[0],[0]
"We also found that the flush component of the original architecture, which modifies the LSTM update at (t+1, `) to discard the LSTM’s internal cell, provided too much incentive to leave z`t at 0, resulting in degenerate configurations which collapsed to having very few tokens in their upper layers.",3.4.2 Modifying the HM for NMT,[0],[0]
We addressed this by removing the notion of a flush from our architecture.,3.4.2 Modifying the HM for NMT,[0],[0]
"The node to the right (t+1, `) always performs a normal LSTM update, regardless of z`t .",3.4.2 Modifying the HM for NMT,[0],[0]
"This modification is similar to one proposed independently by Kádár et al. (2018), who simplified the flush operation by removing the connection to (t, `+ 1).
",3.4.2 Modifying the HM for NMT,[0],[0]
"We found it useful to change the initial value of the bias term used in the calculation of z̃`t , which we refer to as the z-bias.",3.4.2 Modifying the HM for NMT,[0],[0]
"Setting z-bias to 1, which is the saturation point for the hard sigmoid with slope 1, improves training stability by encouraging the encoder to explore configurations where most timesteps survive through all layers, before starting to discard them.
",3.4.2 Modifying the HM for NMT,[0],[0]
"Even with these modifications, we observed degenerate behavior in some settings.",3.4.2 Modifying the HM for NMT,[0],[0]
"To discourage this, we added a compression loss component similar to that of Ke et al. (2018) to penalize z activation rates outside a specified range α1, α2:",3.4.2 Modifying the HM for NMT,[0],[0]
"Lc = ∑ l max(0, Z
l − α1T, α2T − Z l), where T is source sequence length and Z l = ∑T t=1 z",3.4.2 Modifying the HM for NMT,[0],[0]
"l t.
To incorporate the HM into our NMT encoder, we replace the lowest BiLSTM layer with unidirectional HM",3.4.2 Modifying the HM for NMT,[0],[0]
layers.3 We adapt any remaining BiLSTM layers to copy or update according to the z-values calculated by the top HM layer.,3.4.2 Modifying the HM for NMT,[0],[0]
"We adopt the corpora used by Lee et al (2017), with the exception of WMT15 Russian-English.4 To measure performance on an “easy” language pair, and to calibrate our results against recent benchmarks, we also included WMT14 EnglishFrench.",4.1 Corpora,[0],[0]
Table 1 gives details of the corpora used.,4.1 Corpora,[0],[0]
"All corpora are preprocessed using Moses tools.5
3The flush operation makes the original HM inherently left-to-right.",4.1 Corpora,[0],[0]
"Since we have dropped flushes from our current version, it should be straightforward to devise a bidirectional variant, which we leave to future work.
",4.1 Corpora,[0],[0]
4Due,4.1 Corpora,[0],[0]
to licence restrictions.,4.1 Corpora,[0],[0]
"5 Scripts and arguments:
remove-non-printing-char.perl
Dev and test corpora are tokenized, but not filtered or cleaned.",4.1 Corpora,[0],[0]
"Our character models use only the most frequent 496 characters across both source and target languages; similarly, BPE is run across both languages, with a vocabulary size of 32k.",4.1 Corpora,[0],[0]
"Except where noted below, we used 6 bidirectional layers in the encoder, and 8 unidirectional layers in the decoder.","4.2 Model sizes, training, and inference",[0],[0]
"All vector dimensions were 512.
","4.2 Model sizes, training, and inference",[0],[0]
Models were trained using sentence-level crossentropy loss.,"4.2 Model sizes, training, and inference",[0],[0]
"Batch sizes are capped at 16,384 tokens, and each batch is divided among 16 NVIDIA P100s running synchronously.
","4.2 Model sizes, training, and inference",[0],[0]
Parameters were initialized with a uniform (0.04) distribution.,"4.2 Model sizes, training, and inference",[0],[0]
"We use the Adam optimizer, with β1 = 0.9, β2 = 0.999, and = 10−6 (Kingma and Ba, 2014).","4.2 Model sizes, training, and inference",[0],[0]
Gradient norm is clipped to 5.0.,"4.2 Model sizes, training, and inference",[0],[0]
"The initial learning rate is 0.0004, and we halve it whenever dev set perplexity has not decreased for 2k batches, with at least 2k batches between successive halvings.","4.2 Model sizes, training, and inference",[0],[0]
"Training stops when dev set perplexity has not decreased for 8k batches.
","4.2 Model sizes, training, and inference",[0],[0]
"Inference uses beam search with 8 hypotheses, coverage penalty of 0.2 (Tu et al., 2016), and length normalization of 0.2 (Wu et al., 2016).","4.2 Model sizes, training, and inference",[0],[0]
"When comparing character-level and BPE models, we tuned dropout independently for each setting, greedily exploring increments of 0.1 in the range 0.1–0.5, and selecting based on dev-set BLEU.",4.3 Tuning and Evalution,[0],[0]
"This expensive strategy is crucial to obtaining valid conclusions, since optimal dropout values tend to be lower for character models.
",4.3 Tuning and Evalution,[0],[0]
Our main evaluation metric is Moses-tokenized case-sensitive BLEU score.,4.3 Tuning and Evalution,[0],[0]
We report test-set scores on the checkpoints having highest dev-set BLEU.,4.3 Tuning and Evalution,[0],[0]
"To facilitate comparison with future work
tokenize.perl clean-corpus-n.perl -ratio 9 1 100
we also report SacreBLEU scores (Post, 2018) for key results, using the Moses detokenizer.",4.3 Tuning and Evalution,[0],[0]
"We begin with experiments to compare the standard RNN architecture from Section 3.1 at the character and BPE levels, using our full-scale model with 6 bidirectional encoder layers and 8 decoder layers.",5.1 Character-level translation,[0],[0]
"The primary results of our experiments are presented in Table 2, while Table 3 positions the same results with respect to recent points from the literature.
",5.1 Character-level translation,[0],[0]
There are a number of observations we can draw from this data.,5.1 Character-level translation,[0],[0]
"First, from the EnFr results in Table 3, we are in line with GNMT (Wu et al., 2016), and within 2 BLEU points of the RNN and Transformer models investigated by Chen et al. (2018).",5.1 Character-level translation,[0],[0]
"So, while we are not working at the exact state-ofthe-art, we are definitely in a range that should be relevant to most practitioners.
",5.1 Character-level translation,[0],[0]
"Also from Table 3, we compare quite favorably with Lee et al. (2017), exceeding their reported scores by 3-6 points, which we attribute to having employed much higher model capacity, as they use a single bidirectional layer in the encoder and a two-layer decoder.",5.1 Character-level translation,[0],[0]
"We investigate the impact of model capacity in Section 5.1.1.
",5.1 Character-level translation,[0],[0]
"Finally, Table 2 clearly shows the characterlevel systems outperforming BPE for all language pairs.",5.1 Character-level translation,[0],[0]
"The dominance of character-level methods in Table 2 indicates that RNN-based NMT architectures are not only capable of translating charac-
ter sequences, but actually benefit from them.",5.1 Character-level translation,[0],[0]
"This is in direct contradiction to the few previously reported results on this matter, which can in most cases be explained by our increased model capacity.",5.1 Character-level translation,[0],[0]
"The exception is GNMT (Wu et al., 2016), which had similar depth.",5.1 Character-level translation,[0],[0]
"In this case, possible explanations for the discrepancy include our use of a fully bidirectional encoder, our translating into English instead of German, and our modelspecific tuning of dropout.",5.1 Character-level translation,[0],[0]
"Character-level NMT systems have a more difficult sequence-modeling task, as they need to infer the meaning of words from their constituent characters, where models with larger tokens instead delegate this task to the embedding table.",5.1.1 Effect of model capacity,[0],[0]
"Therefore, we hypothesize that increasing the model’s capacity by adding layers will have a greater impact on character-level models.",5.1.1 Effect of model capacity,[0],[0]
Figure 1 tests this hypothesis by measuring the impact of three model sizes on test BLEU score.,5.1.1 Effect of model capacity,[0],[0]
"For each of our four language pairs, the word-fragment model starts out ahead, and quickly loses ground as architecture size increases.",5.1.1 Effect of model capacity,[0],[0]
"For the languages with greater morphological complexity—German, Czech and Finnish—the slope of the character model’s curve is notably steeper than that of the BPE system, indicating that these systems could benefit from yet more modeling capacity.",5.1.1 Effect of model capacity,[0],[0]
"One of the most compelling arguments for working with characters (and to a lesser extent, wordfragments) is improved generalization.",5.1.2 Effect of corpus size,[0],[0]
"Through morphological generalizations, the system can better handle low-frequency and previously unseen words.",5.1.2 Effect of corpus size,[0],[0]
"It stands to reason that as the training corpus increases in size, the importance of these generalization capabilities will decrease.",5.1.2 Effect of corpus size,[0],[0]
"We test this hypothesis by holding the language pair constant, and varying the training corpus size by downsampling the full training corpus.",5.1.2 Effect of corpus size,[0],[0]
We choose EnFr because it has by far the most available data.,5.1.2 Effect of corpus size,[0],[0]
"We compare four sizes: 2M, 4M, 14M and 40M.
The results are shown in Figure 2.",5.1.2 Effect of corpus size,[0],[0]
"As expected, the gap between character and word-fragment modeling decreases as corpus size increases.",5.1.2 Effect of corpus size,[0],[0]
"From the slopes of the curves, we can infer that the advantage of character-level modeling will disappear completely as we reach 60-70M sentence pairs.",5.1.2 Effect of corpus size,[0],[0]
"However, there is reason to expect this break-even
point to be much higher for more morphologically complex languages.",5.1.2 Effect of corpus size,[0],[0]
It is also important to recall that relatively few language-pairs can assemble parallel corpora of this size.,5.1.2 Effect of corpus size,[0],[0]
The performance advantage of working with characters comes at a significant computational cost.,5.1.3 Speed,[0],[0]
"With our full-sized architecture, character models trained roughly 8x more slowly than BPE models.6 Figure 3 shows that training time grows linearly with number of layers in the model, and that character models have a much higher per-layer cost: roughly 0.38 msec/sentence versus 0.04 for BPE.",5.1.3 Speed,[0],[0]
"We did not directly measure the difference in attention cost, but it cannot be greater than the difference in total cost for the smallest number of layers.",5.1.3 Speed,[0],[0]
"Therefore, we can infer from Figure 3 that processing 5 layers in a character model incurs roughly the same time cost as attention.",5.1.3 Speed,[0],[0]
"This is surprising given the quadratic cost of attention, and indicates that efforts to speed up character models cannot focus exclusively on attention.",5.1.3 Speed,[0],[0]
"To make a qualitative comparison between word fragments (BPE) and characters for NMT, we examined 100 randomly selected sentence pairs from the DeEn test set.",5.1.4 Qualitative comparison,[0],[0]
"One author examined the sentences, using a display that showed the source7 and the reference, along with the output of BPE and character models.",5.1.4 Qualitative comparison,[0],[0]
Any differences between the two outputs were highlighted.,5.1.4 Qualitative comparison,[0],[0]
"They then assigned tags to both system outputs indicating broad error categories, such as lexical choice, word order and German compound handling.8",5.1.4 Qualitative comparison,[0],[0]
"Tags were restricted to cases where one system made a mistake that the other did not.
",5.1.4 Qualitative comparison,[0],[0]
"Of the 100 sentences, 47 were annotated as being identical or of roughly the same quality.",5.1.4 Qualitative comparison,[0],[0]
The remaining 53 exhibited a large variety of differences.,5.1.4 Qualitative comparison,[0],[0]
Table 4 summarizes the errors that were most easily characterized.,5.1.4 Qualitative comparison,[0],[0]
"BPE and character sys-
6Recall that we use batches containing 16,384 tokens— corresponding to a fixed memory budget—for both character and BPE models.",5.1.4 Qualitative comparison,[0],[0]
"Thus character models are slowed not only by having longer sentences, but also by parallelizing across fewer sentences in each batch.
",5.1.4 Qualitative comparison,[0],[0]
7The annotating author does not speak German.,5.1.4 Qualitative comparison,[0],[0]
8Our,5.1.4 Qualitative comparison,[0],[0]
"annotator also looked specifically for agreement and negation errors, as studied by Sennrich (2017) for English-toGerman character-level NMT.",5.1.4 Qualitative comparison,[0],[0]
"However, neither system exhibited these error types with sufficient frequency to draw meaningful conclusions.
tems differ most in the number of lexical choice errors, and in the extent to which they drop content.",5.1.4 Qualitative comparison,[0],[0]
"The latter is surprising, and appears to be a side-effect of a general tendency of the character models to be more faithful to the source, verging on being overly literal.",5.1.4 Qualitative comparison,[0],[0]
"An example of dropped content is shown in Table 5 (top).
",5.1.4 Qualitative comparison,[0],[0]
"Regarding lexical choice, the two systems differ not only in the number of errors, but in the nature of those errors.",5.1.4 Qualitative comparison,[0],[0]
"In particular, the BPE model had more trouble handling German compound nouns.",5.1.4 Qualitative comparison,[0],[0]
"Table 5 (bottom) shows an example which exhibits two compound errors, includ-
ing one where the character system is a strict improvement, translating Bunsenbrenner into bunsen burner instead of bullets.",5.1.4 Qualitative comparison,[0],[0]
"The second error follows another common pattern, where both systems mishandle the German compound (Chemiestunden / chemistry lessons), but the character system fails in a more useful way.
",5.1.4 Qualitative comparison,[0],[0]
We also found that both systems occasionally mistranslate proper names.,5.1.4 Qualitative comparison,[0],[0]
"Both fail by attempting to translate when they should copy over, but the BPE system’s errors are harder to understand as they involve semantic translation, rendering Britta Hermann as Sir Leon, and Esme Nussbaum as smiling walnut.9",5.1.4 Qualitative comparison,[0],[0]
"The character system’s one observed error in this category was phonetic rather than semantic, rendering Schotten as Scottland.
",5.1.4 Qualitative comparison,[0],[0]
"Interestingly, we also observed several instances where the model correctly translates the German 24-hour clock into the English 12-hour clock; for example, 19.30 becomes 7:30 p.m..",5.1.4 Qualitative comparison,[0],[0]
"This deterministic transformation is potentially in reach for both models, but we observed it only for the character system in this sample.
9",5.1.4 Qualitative comparison,[0],[0]
The BPE segmentations for these names were: _Britt a _,5.1.4 Qualitative comparison,[0],[0]
Herr mann and _Es me _,5.1.4 Qualitative comparison,[0],[0]
N uss baum,5.1.4 Qualitative comparison,[0],[0]
"At this point we have established that characterlevel NMT benefits translation quality, but incurs a large computational cost.",5.2 Compressing the Source Sequence,[0],[0]
"In this section, we evaluate the speed-quality tradeoffs of various techniques for reducing the number of state vectors required to represent the source sentence.",5.2 Compressing the Source Sequence,[0],[0]
"All experiments are conducted on our DeEn language pair, chosen for having a good balance of morphological complexity and training corpus size.",5.2 Compressing the Source Sequence,[0],[0]
Recall that BPE interpolates between word- and character-level processing by tokenizing consecutive characters into word fragments; larger BPE vocabulary sizes result in larger fragments and shorter sequences.,5.2.1 Optimizing the BPE vocabulary,[0],[0]
"If character-level models outperform BPE with a vocabulary size of 32k, then is there a smaller BPE vocabulary size that reaps the benefits of character-level processing, while still substantially reducing the sequence length?
",5.2.1 Optimizing the BPE vocabulary,[0],[0]
"To answer this question, we test a number of BPE vocabularies, as shown in Table 6.",5.2.1 Optimizing the BPE vocabulary,[0],[0]
"For each vocabulary, we measure BLEU and sequence compression rate, defined as the average size of the source sequence in characters divided by its size in word fragments (the ratio for the target sequence was similar).",5.2.1 Optimizing the BPE vocabulary,[0],[0]
"Unfortunately, even at just 1k vocabulary items, BPE has already lost a BLEU point with respect to the character model.",5.2.1 Optimizing the BPE vocabulary,[0],[0]
"When comparing these results to the other methods in this section, it is important to recall that BPE is compressing both the source and target sequence (by approximately the same amount), doubling its effective compression rate.",5.2.1 Optimizing the BPE vocabulary,[0],[0]
The goal of these experiments is to determine whether using fixed schedule compression is a feasible alternative to BPE.,5.2.2 Fixed Stride Compression,[0],[0]
"We evaluate our reimplementation of the pooling model of Lee et al. (2017) and our pooled BiLSTM encoder, both described in Section 3.3.",5.2.2 Fixed Stride Compression,[0],[0]
"For the pooled BiLSTM encoder, development experiments led us to introduce two mean-pooling layers, a stride 3 layer after the second BiLSTM, and a stride 2 layer after the third.",5.2.2 Fixed Stride Compression,[0],[0]
"Therefore, the final output of the encoder is compressed by a factor of 6.
",5.2.2 Fixed Stride Compression,[0],[0]
The results are also shown in Table 6.,5.2.2 Fixed Stride Compression,[0],[0]
"Note that for the pooled BiLSTM, different encoder layers have different lengths: 2 full length layers, followed by 1 at 13 length and 3 at 1 6 length.",5.2.2 Fixed Stride Compression,[0],[0]
"Therefore, we report the average compression across layers here and for the HM in Section 5.2.3.
",5.2.2 Fixed Stride Compression,[0],[0]
"Our implementation of Lee et al. (2017) outperforms the original results by more than 2 BLEU
points.",5.2.2 Fixed Stride Compression,[0],[0]
We suspect most of these gains result from better optimization of the model with large batch training.,5.2.2 Fixed Stride Compression,[0],[0]
"However, our attempts to scale this encoder to larger depths, and therfore to the level of performance exhibited by our other systems, did not result in any significant improvements.",5.2.2 Fixed Stride Compression,[0],[0]
"This is possibly due to difficulties with optimizing a deeper stack of diverse layers.
",5.2.2 Fixed Stride Compression,[0],[0]
"Comparing the performance of our Pooled BiLSTM model against BPE, we notice that for a comparable level of compression (BPE size of 1k), BPE out-performs the pooled model by around 0.5 BLEU points.",5.2.2 Fixed Stride Compression,[0],[0]
"At a similar level of performance (BPE size of 4k), BPE has significantly shorter sequences.",5.2.2 Fixed Stride Compression,[0],[0]
"Although fixed-stride pooling does not yet match the performance of BPE, we remain optimistic about its potential.",5.2.2 Fixed Stride Compression,[0],[0]
"The appeal of these models derives from their simplicity; they are easy to optimize, perform reasonably well, and remove the complication of BPE preprocessing.",5.2.2 Fixed Stride Compression,[0],[0]
"We experimented with using the Hierarchical Multiscale (HM; Section 3.4.1) architecture to learn compression decisions for the encoder.
",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"For initial exploration, we used a scaled-down architecture consisting of 3 unidirectional HM encoder layers and 2 LSTM decoder layers, attending over the HM’s gated output module.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
Comparisons to an equivalent LSTM are shown in table 7.,5.2.3 Hierarchical Multiscale Compression,[0],[0]
"The first two HM lines justify the no-flush and hierarchical modifications described in Section 3.4.1, yielding incremental gains of 27.3 (the flush variant failed to converge), and 1.2 respectively.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"Initializing z-bias to 1 and annealing the slope of the hard binarizer from 1.0 to 5.0 over 80k minibatches gave further small gains, bringing the HM to parity with the LSTM while saving approximately 35% of layer-wise computations.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"Interestingly, we found that, over a wide range of training conditions, each layer tended to reduce computa-
tion by roughly 60% relative to the layer below.10
For full-scale experiments, we stacked 5 BiLSTM layers on top of 2 or 3 HM layers, as described in section 3.4.1, using only the top HM layer (rather than the gated output module) as input to the lowest BiLSTM layer.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"To stabilize the 3- HM configuration we used a compression penalty with a weight of 2, and α1 and α2 of 0.1 and 0.9.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"Given the tendency of HM layers to reduce computation by a roughly constant proportion, we expect fewer z-gates to be open in the 3-HM configuration, but this is achieved at the cost of one extra layer relative to our standard 12-layer encoder.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"As shown in table 6, the 3-HM configuration achieves much better compression even when this is accounted for, and also gives slightly better performance than 2-HM.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"In general, HM gating results in less compression but better performance than the fixed-stride techniques.
",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"Although these preliminary results are promising, it should be emphasized that the speed gains they demonstrate are conceptual, and that realizing them in practice comes with significant engineering challenges.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
We have demonstrated the translation quality of standard NMT architectures operating at the character-level.,6 Conclusion,[0],[0]
"Our experiments show the surprising result that character NMT can substantially out-perform BPE tokenization for all but the largest training corpora sizes, and the less surprising result that doing so incurs a large computational cost.",6 Conclusion,[0],[0]
"To address this cost, we have explored a number of methods for source-sequence compression, including the first application of the Hierarchical Multiscale LSTM to NMT, which allows us to learn to dynamically compress the source sequence.
",6 Conclusion,[0],[0]
We intend this paper as a call to action.,6 Conclusion,[0],[0]
"Character-level translation is well worth doing, but we do not yet have the necessary techniques to benefit from this quality boost without suffering a disproportionate reduction in speed.",6 Conclusion,[0],[0]
"We hope that these results will spur others to revisit the question of character-level translation as an interesting testbed for methods that can learn to process, summarize or compress long sequences.
",6 Conclusion,[0],[0]
"10For instance, the 2nd and 3rd layer of the best configuration shown had on average 60% and 36% of z gates open, yielding the computation ratio of (1+0.6+0.36)/3 = 0.65.",6 Conclusion,[0],[0]
"Translating characters instead of words or word-fragments has the potential to simplify the processing pipeline for neural machine translation (NMT), and improve results by eliminating hyper-parameters and manual feature engineering.",abstractText,[0],[0]
"However, it results in longer sequences in which each symbol contains less information, creating both modeling and computational challenges.",abstractText,[0],[0]
"In this paper, we show that the modeling problem can be solved by standard sequence-to-sequence architectures of sufficient depth, and that deep models operating at the character level outperform identical models operating over word fragments.",abstractText,[0.9540463096752144],"['We illustrate this process in Figure 3, where we generate SEAs for a VQA model by generating paraphrases around the question, and checking when the model prediction changes.']"
This result implies that alternative architectures for handling character input are better viewed as methods for reducing computation time than as improved ways of modeling longer sequences.,abstractText,[0],[0]
"From this perspective, we evaluate several techniques for characterlevel NMT, verify that they do not match the performance of our deep character baseline model, and evaluate the performance versus computation time tradeoffs they offer.",abstractText,[0],[0]
"Within this framework, we also perform the first evaluation for NMT of conditional computation over time, in which the model learns which timesteps can be skipped, rather than having them be dictated by a fixed schedule specified before training begins.",abstractText,[0],[0]
Revisiting Character-Based Neural Machine Translation with Capacity and Compression,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4743–4751 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4743",text,[0],[0]
"In this paper, we explore the effectiveness of methods designed to improve sentiment classification (positive vs. negative) of sentences that contain complex syntactic structures.",1 Introduction,[0],[0]
"While simple bag-of-words or lexicon-based methods (Pang and Lee, 2005; Wang and Manning, 2012; Iyyer et al., 2015) achieve good performance on this task, they are unequipped to deal with syntactic structures that affect sentiment, such as contrastive conjunctions (i.e., sentences of the form “A-but-B”) or negations.",1 Introduction,[0],[0]
"Neural models that explicitly encode word order (Kim, 2014), syntax (Socher et al., 2013; Tai et al., 2015) and semantic features (Li et al., 2017) have been proposed with the aim of improving performance on these more complicated sentences.",1 Introduction,[0],[0]
"Recently, Hu et al. (2016) incorporate logical rules into a neural model and
show that these rules increase the model’s accuracy on sentences containing contrastive conjunctions, while Peters et al. (2018a) demonstrate increased overall accuracy on sentiment analysis by initializing a model with representations from a language model trained on millions of sentences.
",1 Introduction,[0],[0]
"In this work, we carry out an in-depth study of the effectiveness of the techniques in Hu et al. (2016) and Peters et al. (2018a) for sentiment classification of complex sentences.",1 Introduction,[0],[0]
"Part of our contribution is to identify an important gap in the methodology used in Hu et al. (2016) for performance measurement, which is addressed by averaging the experiments over several executions.",1 Introduction,[0],[0]
"With the averaging in place, we obtain three key findings: (1) the improvements in Hu et al. (2016) can almost entirely be attributed to just one of their two proposed mechanisms and are also less pronounced than previously reported; (2) contextualized word embeddings (Peters et al., 2018a) incorporate the “A-but-B” rules more effectively without explicitly programming for them; and (3) an analysis using crowdsourcing reveals a bigger picture where the errors in the automated systems have a striking correlation with the inherent sentiment-ambiguity in the data.",1 Introduction,[0],[0]
Here we briefly review background from Hu et al. (2016) to provide a foundation for our reanalysis in the next section.,2 Logic Rules in Sentiment Classification,[0],[0]
We focus on a logic rule for sentences containing an “A-but-B” structure (the only rule for which Hu et al. (2016) provide experimental results).,2 Logic Rules in Sentiment Classification,[0],[0]
"Intuitively, the logic rule for such sentences is that the sentiment associated with the whole sentence should be the same as the sentiment associated with phrase “B”.1
1The rule is vacuously true if the sentence does not have this structure.
",2 Logic Rules in Sentiment Classification,[0],[0]
"More formally, let pθ(y|x) denote the probability assigned to the label y ∈ {+,−} for an input x by the baseline model using parameters θ.",2 Logic Rules in Sentiment Classification,[0],[0]
"A logic rule is (softly) encoded as a variable rθ(x, y) ∈",2 Logic Rules in Sentiment Classification,[0],[0]
"[0, 1] indicating how well labeling x with y satisfies the rule.",2 Logic Rules in Sentiment Classification,[0],[0]
"For the case of A-but-B sentences, rθ(x, y) = pθ(y|B) if x has the structure A-but-B (and 1 otherwise).",2 Logic Rules in Sentiment Classification,[0],[0]
"Next, we discuss the two techniques from Hu et al. (2016) for incorporating rules into models: projection, which directly alters a trained model, and distillation, which progressively adjusts the loss function during training.
Projection.",2 Logic Rules in Sentiment Classification,[0],[0]
"The first technique is to project a trained model into a rule-regularized subspace, in a fashion similar to Ganchev et al. (2010).",2 Logic Rules in Sentiment Classification,[0],[0]
"More precisely, a given model pθ is projected to a model qθ defined by the optimum value of q in the following optimization problem:2
min q,ξ≥0 KL(q(X,Y )||pθ(X,Y ))",2 Logic Rules in Sentiment Classification,[0],[0]
+,2 Logic Rules in Sentiment Classification,[0],[0]
C ∑,2 Logic Rules in Sentiment Classification,[0],[0]
"x∈X ξx
s.t.",2 Logic Rules in Sentiment Classification,[0],[0]
"(1− Ey←q(·|x)[rθ(x, y)]) ≤",2 Logic Rules in Sentiment Classification,[0],[0]
"ξx
Here q(X,Y ) denotes the distribution of (x, y) when x is drawn uniformly from the set X and y is drawn according to q(·|x).
",2 Logic Rules in Sentiment Classification,[0],[0]
Iterative Rule Knowledge Distillation.,2 Logic Rules in Sentiment Classification,[0],[0]
The second technique is to transfer the domain knowledge encoded in the logic rules into a neural network’s parameters.,2 Logic Rules in Sentiment Classification,[0],[0]
"Following Hinton et al. (2015), a “student” model pθ can learn from the “teacher” model qθ, by using a loss function πH(pθ, Ptrue)+ (1− π)H(pθ, qθ) during training, where Ptrue denotes the distribution implied by the ground truth, H(·, ·) denotes the cross-entropy function, and π is a hyperparameter.",2 Logic Rules in Sentiment Classification,[0],[0]
"Hu et al. (2016) computes qθ after every gradient update by projecting the current pθ, as described above.",2 Logic Rules in Sentiment Classification,[0],[0]
"Note that both mechanisms can be combined: After fully training pθ using the iterative distillation process above, the projection step can be applied one more time to obtain qθ which is then used as the trained model.
",2 Logic Rules in Sentiment Classification,[0],[0]
Dataset.,2 Logic Rules in Sentiment Classification,[0],[0]
"All of our experiments (as well as those in Hu et al. (2016)) use the SST2 dataset, a
2The formulation in Hu et al. (2016) includes another hyperparameter λ per rule, to control its relative importance; when there is only one rule, as in our case, this parameter can be absorbed into C.
binarized subset of the popular Stanford Sentiment Treebank (SST) (Socher et al., 2013).",2 Logic Rules in Sentiment Classification,[0],[0]
"The dataset includes phrase-level labels in addition to sentence-level labels (see Table 1 for detailed statistics); following Hu et al. (2016), we use both types of labels for the comparisons in Section 3.2.",2 Logic Rules in Sentiment Classification,[0],[0]
"In all other experiments, we use only sentencelevel labels, and our baseline model for all experiments is the CNN architecture from Kim (2014).",2 Logic Rules in Sentiment Classification,[0],[0]
In this section we reanalyze the effectiveness of the techniques of Hu et al. (2016) and find that most of the performance gain is due to projection and not knowledge distillation.,3 A Reanalysis,[0],[0]
The discrepancy with the original analysis can be attributed to the relatively small dataset and the resulting variance across random initializations.,3 A Reanalysis,[0],[0]
We start by analyzing the baseline CNN by Kim (2014) to point out the need for an averaged analysis.,3 A Reanalysis,[0],[0]
"We run the baseline CNN by Kim (2014) across 100 random seeds, training on sentence-level la-
bels.",3.1 Importance of Averaging,[0],[0]
"We observe a large amount of variation from run-to-run, which is unsurprising given the small dataset size.",3.1 Importance of Averaging,[0],[0]
"The inset density plot in Figure 1 shows the range of accuracies (83.47 to 87.20) along with 25, 50 and 75",3.1 Importance of Averaging,[0],[0]
"percentiles.3 The figure also shows how the variance persists even after the average converges: the accuracies of 100 models trained for 20 epochs each are plotted in gray, and their average is shown in red.
",3.1 Importance of Averaging,[0],[0]
"We conclude that, to be reproducible, only averaged accuracies should be reported in this task and dataset.",3.1 Importance of Averaging,[0],[0]
This mirrors the conclusion from a detailed analysis by Reimers and Gurevych (2017) in the context of named entity recognition.,3.1 Importance of Averaging,[0],[0]
We carry out an averaged analysis of the publicly available implementation4 of Hu et al. (2016).,3.2 Performance of Hu et al. (2016),[0],[0]
Our analysis reveals that the reported performance of their two mechanisms (projection and distillation) is in fact affected by the high variability across random seeds.,3.2 Performance of Hu et al. (2016),[0],[0]
"Our more robust averaged analysis yields a somewhat different conclusion of their effectiveness.
",3.2 Performance of Hu et al. (2016),[0],[0]
"In Figure 2, the first two columns show the reported accuracies in Hu et al. (2016) for models trained with and without distillation (corresponding to using values π = 1 and π = 0.95t in the tth epoch, respectively).",3.2 Performance of Hu et al. (2016),[0],[0]
The two rows show the results for models with and without a final projection into the rule-regularized space.,3.2 Performance of Hu et al. (2016),[0],[0]
"We keep our hyper-parameters identical to Hu et al. (2016).5
The baseline system (no-project, no-distill) is identical to the system of Kim (2014).",3.2 Performance of Hu et al. (2016),[0],[0]
"All the systems are trained on the phrase-level SST2 dataset
3We use early stopping based on validation performance for all models in the density plot.
",3.2 Performance of Hu et al. (2016),[0],[0]
"4https://github.com/ZhitingHu/logicnn/ 5In particular, C = 6 for projection.
with early stopping on the development set.",3.2 Performance of Hu et al. (2016),[0],[0]
The number inside each arrow indicates the improvement in accuracy by adding either the projection or the distillation component to the training algorithm.,3.2 Performance of Hu et al. (2016),[0],[0]
"Note that the reported figures suggest that while both components help in improving accuracy, the distillation component is much more helpful than the projection component.
",3.2 Performance of Hu et al. (2016),[0],[0]
"The next two columns, which show the results of repeating the above analysis after averaging over 100 random seeds, contradict this claim.",3.2 Performance of Hu et al. (2016),[0],[0]
"The averaged figures show lower overall accuracy increases, and, more importantly, they attribute these improvements almost entirely to the projection component rather than the distillation component.",3.2 Performance of Hu et al. (2016),[0],[0]
"To confirm this result, we repeat our averaged analysis restricted to only “A-but-B” sentences targeted by the rule (shown in the last two columns).",3.2 Performance of Hu et al. (2016),[0],[0]
"We again observe that the effect of projection is pronounced, while distillation offers little or no advantage in comparison.",3.2 Performance of Hu et al. (2016),[0],[0]
"Traditional context-independent word embeddings like word2vec (Mikolov et al., 2013) or GloVe (Pennington et al., 2014) are fixed vectors for every word in the vocabulary.",4 Contextualized Word Embeddings,[0],[0]
"In contrast, contextualized embeddings are dynamic representations, dependent on the current context of the word.",4 Contextualized Word Embeddings,[0],[0]
We hypothesize that contextualized word embeddings might inherently capture these logic rules due to increasing the effective context size for the CNN layer in Kim (2014).,4 Contextualized Word Embeddings,[0],[0]
"Following the recent success of ELMo (Peters et al., 2018a) in sentiment analysis, we utilize the TensorFlow Hub implementation of ELMo6 and feed these contextualized embeddings into our CNN model.",4 Contextualized Word Embeddings,[0],[0]
"We
6https://tfhub.dev/google/elmo/1
fine-tune the ELMo LSTM weights along with the CNN weights on the downstream CNN task.",4 Contextualized Word Embeddings,[0],[0]
"As in Section 3, we check performance with and without the final projection into the rule-regularized space.",4 Contextualized Word Embeddings,[0],[0]
"We present our results in Table 2.
",4 Contextualized Word Embeddings,[0],[0]
"Switching to ELMo word embeddings improves performance by 2.9 percentage points on an average, corresponding to about 53 test sentences.",4 Contextualized Word Embeddings,[0],[0]
"Of these, about 32 sentences (60% of the improvement) correspond to A-but-B and negation style sentences, which is substantial when considering that only 24.5% of test sentences include these discourse relations (Table 1).",4 Contextualized Word Embeddings,[0],[0]
"As further evidence that ELMo helps on these specific constructions, the non-ELMo baseline model (no-project, no-distill) gets 255 sentences wrong in the test corpus on average, only 89 (34.8%) of which are A-but-B style or negations.
",4 Contextualized Word Embeddings,[0],[0]
"Statistical Significance: Using a two-sided Kolmogorov-Smirnov statistic (Massey Jr, 1951) with α = 0.001 for the results in Table 2, we find that ELMo and projection each yield statistically significant improvements, but distillation does not.",4 Contextualized Word Embeddings,[0],[0]
"Also, with ELMo, projection is not significant.",4 Contextualized Word Embeddings,[0],[0]
"Specific comparisons have been added in the Appendix, in Table A3.
KL Divergence Analysis: We observe no significant gains by projecting a trained ELMo model into an A-but-B rule-regularized space, unlike the other models.",4 Contextualized Word Embeddings,[0],[0]
"We confirm that ELMo’s predictions are much closer to the A-but-B rule’s manifold than those of the other models by computing KL(qθ||pθ) where pθ and qθ are the original and projected distributions: Averaged across all A-butB sentences and 100 seeds, this gives 0.27, 0.26 and 0.13 for the Kim (2014), Hu et al. (2016) with distillation and ELMo systems respectively.
",4 Contextualized Word Embeddings,[0],[0]
"Intra-sentence Similarity: To understand the information captured by ELMo embeddings for A-but-B sentences, we measure the cosine similarity between the word vectors of every pair of words within the A-but-B sentence (Peters et al., 2018b).",4 Contextualized Word Embeddings,[0],[0]
"We compare the intra-sentence similarity for fine-tuned word2vec embeddings (baseline), ELMo embeddings without fine-tuning and finally fine-tuned ELMo embeddings in Figure 3.",4 Contextualized Word Embeddings,[0],[0]
"In the fine-tuned ELMo embeddings, we notice the words within the A and within the B part of the A-but-B sentence share the same part of the vector space.",4 Contextualized Word Embeddings,[0],[0]
"This pattern is less visible in the
ELMo embeddings without fine-tuning and absent in the word2vec embeddings.",4 Contextualized Word Embeddings,[0],[0]
This observation is indicative of ELMo’s ability to learn specific rules for A-but-B sentences in sentiment classification.,4 Contextualized Word Embeddings,[0],[0]
More intra-sentence similarity heatmaps for A-but-B sentences are in Figure A1.,4 Contextualized Word Embeddings,[0],[0]
We conduct a crowdsourced analysis that reveals that SST2 data has significant levels of ambiguity even for human labelers.,5 Crowdsourced Experiments,[0],[0]
"We discover that ELMo’s performance improvements over the baseline are robust across varying levels of ambiguity, whereas the advantage of Hu et al. (2016) is reversed in sentences of low ambiguity (restricting to A-but-B style sentences).
",5 Crowdsourced Experiments,[0],[0]
"Our crowdsourced experiment was conducted on Figure Eight.8 Nine workers scored the sentiment of each A-but-B and negation sentence in the test SST2 split as 0 (negative), 0.5 (neutral) or 1 (positive).",5 Crowdsourced Experiments,[0],[0]
(SST originally had three crowdworkers choose a sentiment rating from 1 to 25 for every phrase.),5 Crowdsourced Experiments,[0],[0]
More details regarding the crowd experiment’s parameters have been provided in,5 Crowdsourced Experiments,[0],[0]
"Appendix A.
We average the scores across all users for each sentence.",5 Crowdsourced Experiments,[0],[0]
"Sentences with a score in the range (x, 1] are marked as positive (where x ∈",5 Crowdsourced Experiments,[0],[0]
"[0.5, 1)), sentences in [0, 1 − x) marked as negative, and sentences in [1 − x, x] are marked as neutral.",5 Crowdsourced Experiments,[0],[0]
"For instance, “flat , but with a revelatory performance by michelle williams” (score=0.56) is neutral when x",5 Crowdsourced Experiments,[0],[0]
= 0.6.9,5 Crowdsourced Experiments,[0],[0]
We present statistics of our dataset10 in Table 3.,5 Crowdsourced Experiments,[0],[0]
"Inter-annotator agree-
7Trained on sentences and not phrase-level labels for a fair comparison with baseline and ELMo, unlike Section 3.2.
",5 Crowdsourced Experiments,[0],[0]
"8 https://www.figure-eight.com/ 9More examples of neutral sentences have been provided in the Appendix in Table A1, as well as a few “flipped” sentences receiving an average score opposite to their SST2 label (Table A2).
",5 Crowdsourced Experiments,[0],[0]
"10The dataset along with source code can be found in
ment was computed using Fleiss’ Kappa (κ).",5 Crowdsourced Experiments,[0],[0]
"As expected, inter-annotator agreement is higher for higher thresholds (less ambiguous sentences).",5 Crowdsourced Experiments,[0],[0]
"According to Landis and Koch (1977), κ ∈ (0.2, 0.4] corresponds to “fair agreement”, whereas κ ∈ (0.4, 0.6] corresponds to “moderate agreement”.
",5 Crowdsourced Experiments,[0],[0]
We next compute the accuracy of our model for each threshold by removing the corresponding neutral sentences.,5 Crowdsourced Experiments,[0],[0]
Higher thresholds correspond to sets of less ambiguous sentences.,5 Crowdsourced Experiments,[0],[0]
Table 3 shows that ELMo’s performance gains in Table 2 extends across all thresholds.,5 Crowdsourced Experiments,[0],[0]
In Figure 4 we compare all the models on the A-but-B sentences in this set.,5 Crowdsourced Experiments,[0],[0]
"Across all thresholds, we notice trends similar to previous sections: 1) ELMo performs the best among all models on A-but-B style sentences, and projection results in only a slight improvement; 2) models in Hu et al. (2016) (with and without distillation) benefit considerably from projection; but 3) distillation offers little improvement (with or without projection).",5 Crowdsourced Experiments,[0],[0]
"Also, as the ambiguity threshold increases, we see decreasing gains from projection on all models.",5 Crowdsourced Experiments,[0],[0]
"In fact, beyond the 0.85 threshold, projection degrades the average performance, indicating that projection is useful for more ambiguous sentences.",5 Crowdsourced Experiments,[0],[0]
We present an analysis comparing techniques for incorporating logic rules into sentiment classification systems.,6 Conclusion,[0],[0]
"Our analysis included a metastudy highlighting the issue of stochasticity in performance across runs and the inherent ambiguity in the sentiment classification task itself, which was tackled using an averaged analysis and
https://github.com/martiansideofthemoon/ logic-rules-sentiment.
a crowdsourced experiment identifying ambiguous sentences.",6 Conclusion,[0],[0]
"We present evidence that a recently proposed contextualized word embedding model (ELMo) (Peters et al., 2018a) implicitly learns logic rules for sentiment classification of complex sentences like A-but-B sentences.",6 Conclusion,[0],[0]
Future work includes a fine-grained quantitative study of ELMo word vectors for logically complex sentences along the lines of Peters et al. (2018b).,6 Conclusion,[0],[0]
"Crowd workers residing in five English-speaking countries (United States, United Kingdom, New Zealand, Australia and Canada) were hired.",A Crowdsourcing Details,[0],[0]
"Each crowd worker had a Level 2 or higher rating on Figure Eight, which corresponds to a “group of more experienced, higher accuracy contributors”.",A Crowdsourcing Details,[0],[0]
Each contributor had to pass a test questionnaire to be eligible to take part in the experiment.,A Crowdsourcing Details,[0],[0]
Test questions were also hidden throughout the task and untrusted contributions were removed from the final dataset.,A Crowdsourcing Details,[0],[0]
"For greater quality control, an upper limit of 75 judgments per contributor was enforced.",A Crowdsourcing Details,[0],[0]
Crowd workers were paid a total of $1 for 50 judgments.,A Crowdsourcing Details,[0],[0]
"An internal unpaid workforce (including the first and second author of the paper) of 7 contributors was used to speed up data collection.
",A Crowdsourcing Details,[0],[0]
"# Judgments Average Sentence Positive Negative Neutral
1 1 7 0.50 the fight scenes are fun , but it grows tedious
3 2 4 0.56 it ’s not exactly a gourmet meal but the fare is fair , even coming from the drive thru
2 3 4 0.44 propelled not by characters but by caricatures
4 2 3 0.61 not everything works , but the average is higher than in mary and most other recent comedies
Table A1:",A Crowdsourcing Details,[0],[0]
"Examples of neutral sentences for a threshold of 0.66
# Judgments Average Original Sentence Positive Negative Neutral
1 5 3 0.28 Positive de niro and mcdormand give solid performances , but their screen time is sabotaged by the story ’s inability to create interest
6 0 3 0.83 Negative son of the bride may be a good half hour too long but comes replete with a flattering sense of mystery and quietness
0 5 4 0.22 Positive wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of hubert ’s punches ) , but it should go down smoothly enough with popcorn
Table A2: Examples of flipped sentiment sentences, for a threshold of 0.66
Model 1 vs Model 2 Significant
distill no-project distill project",A Crowdsourcing Details,[0],[0]
"Yes no-distill no-project no-distill project Yes
ELMo no-project ELMo project No
no-distill no-project distill no-project No no-distill project distill project",A Crowdsourcing Details,[0],[0]
"No
no-distill no-project ELMo no-project",A Crowdsourcing Details,[0],[0]
Yes distill no-project ELMo no-project,A Crowdsourcing Details,[0],[0]
Yes no-distill project ELMo project,A Crowdsourcing Details,[0],[0]
"Yes distill project ELMo project Yes
Table A3: Statistical significance using a two-sided Kolmogorov-Smirnov statistic (Massey Jr, 1951) with α = 0.001.
",A Crowdsourcing Details,[0],[0]
"al l en ds we ll , so rt of , bu t th e fre nz
ie d
co m ic m
om en ts ne ve r cli ck
all ends well
, sort
of ,
but the frenzied comic
moments never click 0.1
0.0
0.1
",A Crowdsourcing Details,[0],[0]
"0.2
0.3
0.4
al l en ds we ll , so rt of , bu t th e fre nz
ie d
co m ic m
om en ts ne ve r cli ck
all ends well
, sort
of ,
but the frenzied comic
moments never click 0.1
0.2
0.3
0.4
0.5
0.6
al l en ds we ll , so rt of , bu t th e fre nz
ie d
co m ic m
om en ts ne ve r cli ck
all ends well
, sort
of ,
but the frenzied comic
moments never click
0.1
0.2
0.3
0.4
0.5
m ar isa to m ei is go od ,",A Crowdsourcing Details,[0],[0]
"bu t ju st a ki ss is ju st a m es s
marisa tomei
is good
, but just
a kiss
is just
a mess 0.1
0.0
0.1
0.2
0.3
0.4
m ar isa to m ei is go od , bu t ju st a ki ss is ju st a m es s marisa tomei
is good
, but just
a kiss
is just
a mess
0.2
0.3
0.4
",A Crowdsourcing Details,[0],[0]
"0.5
0.6
m ar isa to m ei is go",A Crowdsourcing Details,[0],[0]
od,A Crowdsourcing Details,[0],[0]
", bu t ju st a ki ss is ju st a m es s
marisa tomei
is good
, but just
a kiss
is just
a mess 0.0
0.1
0.2
0.3
0.4
0.5
0.6
",A Crowdsourcing Details,[0],[0]
"th e irw in s em
er ge
un sc
at he d ,",A Crowdsourcing Details,[0],[0]
"bu t th e fic tio na l fo ot ag e is un co nv
in cin g",A Crowdsourcing Details,[0],[0]
an d cr,A Crowdsourcing Details,[0],[0]
"im in al ly ba dl y ac te d
the irwins emerge unscathed
, but the fictional footage
is unconvincing
and criminally
badly acted
0.1
0.0
0.1
0.2
0.3
th e irw in s em
er ge
un sc
at he d ,",A Crowdsourcing Details,[0],[0]
"bu t th e fic tio na l fo ot ag e is un co nv
in cin g",A Crowdsourcing Details,[0],[0]
an d cr,A Crowdsourcing Details,[0],[0]
"im in al ly ba dl y ac te d
the irwins emerge unscathed
, but the fictional footage
is unconvincing
and criminally
badly acted 0.1
0.2
0.3
0.4
0.5
0.6
th e irw in s em
er ge
un sc
at he d , bu t th e fic tio",A Crowdsourcing Details,[0],[0]
na,A Crowdsourcing Details,[0],[0]
"l fo ot ag e is un co nv
in cin g",A Crowdsourcing Details,[0],[0]
an d cr,A Crowdsourcing Details,[0],[0]
"im in al ly ba dl y ac te d
the irwins emerge unscathed
, but the fictional footage
is unconvincing
and criminally
badly acted
0.1
0.2
0.3
0.4
0.5
Figure A1:",A Crowdsourcing Details,[0],[0]
Heat map showing the cosine similarity between pairs of word vectors within a single sentence.,A Crowdsourcing Details,[0],[0]
"The leftmost column has word2vec (Mikolov et al., 2013) embeddings, fine-tuned on the downstream task (SST2).",A Crowdsourcing Details,[0],[0]
"The middle column contains the original ELMo embeddings (Peters et al., 2018a) without any fine-tuning.",A Crowdsourcing Details,[0],[0]
The representations from the three layers (token layer and two LSTM layers) have been averaged.,A Crowdsourcing Details,[0],[0]
The rightmost column contains ELMo embeddings fine-tuned on the downstream task.,A Crowdsourcing Details,[0],[0]
"For better visualization, the cosine similarity between identical words has been set equal to the minimum value in the map.",A Crowdsourcing Details,[0],[0]
We analyze the performance of different sentiment classification models on syntacticallycomplex inputs like A-but-B sentences.,abstractText,[0],[0]
"The first contribution of this analysis addresses reproducible research: to meaningfully compare different models, their accuracies must be averaged over far more random seeds than what has traditionally been reported.",abstractText,[0],[0]
"With proper averaging in place, we notice that the distillation model described in Hu et al. (2016), which incorporates explicit logic rules for sentiment classification, is ineffective.",abstractText,[0],[0]
"In contrast, using contextualized ELMo embeddings (Peters et al., 2018a) instead of logic rules yields significantly better performance.",abstractText,[0],[0]
"Additionally, we provide analysis and visualizations that demonstrate ELMo’s ability to implicitly learn logic rules.",abstractText,[0],[0]
"Finally, a crowdsourced analysis reveals how ELMo outperforms baseline models even on sentences with ambiguous sentiment labels.",abstractText,[0],[0]
Revisiting the Importance of Encoding Logic Rules in Sentiment Classification,title,[0],[0]
"Back-propagation through time (BPTT) (Werbos, 1990) is nowadays the standard approach for training recurrent neural networks (RNNs).",1. Introduction,[0],[0]
"However, the computation and memory cost of BPTT scale linearly with the number of steps which makes BPTT impractical for applications where long sequences are common (Sutskever et al., 2014; Goodfellow
*Equal contribution 1Department of Computer Science, University of Toronto 2Uber ATG Toronto 3Vector Institute 4Department of Electrical and Computer Engineering, Rice University 5Department of Neuroscience, Baylor College of Medicine 6Canadian Institute for Advanced Research.",1. Introduction,[0],[0]
"Correspondence to: Renjie Liao <rjliao@cs.toronto.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"et al., 2016).",1. Introduction,[0],[0]
"Moreover, as the number of unrolling steps increases, the numerical error accumulates which may render the algorithm useless in some applications, e.g., gradientbased hyperparameter optimization (Maclaurin et al., 2015).",1. Introduction,[0],[0]
This issue is often solved in practice by using truncated back-propagation through time (TBPTT),1. Introduction,[0],[0]
"(Williams & Peng, 1990; Sutskever, 2013) which has constant computation and memory cost, is simple to implement, and effective in some applications.",1. Introduction,[0],[0]
"However, the quality of the TBPTT approximate gradient is not well understood.",1. Introduction,[0],[0]
"A natural question to ask is, can we get better gradient approximations while still using the same computational cost as TBPTT?
",1. Introduction,[0],[0]
"Here will show that under certain conditions on the underlying model, the answer is positive.",1. Introduction,[0],[0]
"In particular, we consider a class of RNNs whose hidden state converges to a steady state.",1. Introduction,[0],[0]
"For this class of RNNs, we can bypass BPTT and compute the exact gradient using an algorithm called recurrent back-propagation (RBP) (Almeida, 1987; Pineda, 1987).",1. Introduction,[0],[0]
The key observation exploited by RBP is that the gradient of the steady state w.r.t.,1. Introduction,[0],[0]
"the learnable parameters can be directly computed using the implicit function theorem, alleviating the need to unroll the entire forward pass.",1. Introduction,[0],[0]
The main computational cost of RBP is in solving a linear system which has constant memory and computation time w.r.t.,1. Introduction,[0],[0]
the number of unrolling steps.,1. Introduction,[0],[0]
"However, due to the strong assumptions that RBP imposes, TBPTT has become the standard approach used in practice and RBP did not get much attention for many years.
",1. Introduction,[0],[0]
"In this paper, we first revisit RBP in the context of modern deep learning.",1. Introduction,[0],[0]
"We discuss the original algorithm, the assumptions it imposes and how to satisfy them for deep neural networks.",1. Introduction,[0],[0]
"Second, we notice that although the fixed point iteration method used in (Almeida, 1987; Pineda, 1987) is guaranteed to converge if the steady hidden state is achievable, in practice it can fail to do so within a reasonable amount of steps.",1. Introduction,[0],[0]
This may be caused by the fact that there are many fixed points and the algorithm is sensitive to initialization.,1. Introduction,[0],[0]
We try to overcome the instability issue by proposing two variants of RBP based on conjugate gradient on normal equations (CG-RBP) and Neumann series (Neumann-RBP).,1. Introduction,[0],[0]
We show a connection between NeumannRBP and TBPTT which sheds some new light on the approximation quality of TBPTT.,1. Introduction,[0],[0]
"In the experiments, we show
several important applications which are naturally amenable to RBP.",1. Introduction,[0],[0]
"For example, we show how RBP can be used to back propagate thorough the optimization of deep neural networks in order to tune hyperparameters.",1. Introduction,[0],[0]
"Throughout our experiments, we found that Neumann-RBP not only inherits the advantages of original RBP but also remains consistently stable across different applications.",1. Introduction,[0],[0]
"In the context of neural networks, RBP was independently discovered by Almeida (Almeida, 1987) and Pineda (Pineda, 1987) in 1987, which is why this algorithm is sometimes called the Almeida-Pineda algorithm.",2. Related Work,[0],[0]
"Back then, RBP was shown to be useful in learning content-addressable memory (CAM) models (Hopfield, 1982; 1984) and other computational neurodynamic models (Lapedes & Farber, 1986; Haykin, 1993; Chauvin & Rumelhart, 1995).",2. Related Work,[0],[0]
These models are special RNNs in a sense that their inference stage is a convergent dynamic system by design.,2. Related Work,[0],[0]
"For these systems, one can construct a Lyapunov function for the underlying dynamics which further guarantees the asymptotic stability.",2. Related Work,[0],[0]
"We refer readers to chapter 13 of (Haykin, 1993) for more details on neurodynamic models.",2. Related Work,[0],[0]
"The goal of learning in these models is to manipulate the attractors, i.e. steady states, such that they are close to the input data.",2. Related Work,[0],[0]
"Therefore, during inference stage, even if the input data is corrupted, the corresponding correct attractor or “memory“ can still be retrieved.",2. Related Work,[0],[0]
"Instead of computing gradient via BPTT, RBP provides an more efficient alternative for manipulating the attractors.
",2. Related Work,[0],[0]
"RBP was later applied to learning graph neural networks (GNNs) (Scarselli et al., 2009), which are generalizations of RNNs that handle graph-structured input data.",2. Related Work,[0],[0]
"Specifically, the inference of GNNs is essentially a propagation process which spreads information along the graph.",2. Related Work,[0],[0]
"One can force the propagation process to converge by either constructing a contraction map explicitly, or by regularizing the Jacobian of the update function.",2. Related Work,[0],[0]
"Similarly, the goal is to push the converged inference solution close to the target.",2. Related Work,[0],[0]
RBP is naturally applicable here and demonstrated to save both computation time and memory.,2. Related Work,[0],[0]
"A recent investigation (Scellier & Bengio, 2017a) shows that RBP is related to equilibrium propagation (Scellier & Bengio, 2017b) which is motivated from the perspective of biological plausibility.",2. Related Work,[0],[0]
"Another recent related work in deep learning is OptNet (Amos & Kolter, 2017) where the gradient of the optimized solution of a quadratic programming problem w.r.t.",2. Related Work,[0],[0]
"parameters is obtained by analytically differentiating the KKT system.
",2. Related Work,[0],[0]
"In the probabilistic graphical models (PGMs) literature, similar techniques to RBP have been developed as well.",2. Related Work,[0],[0]
"For example, an efficient gradient-based method to learn the hyperparameters of log-linear models is provided in (Foo et al.,
2008) where the core contribution is to use the implicit differentiation trick to compute the gradient of the optimized inference solution w.r.t.",2. Related Work,[0],[0]
the hyperparameters.,2. Related Work,[0],[0]
"A similar implicit differentiation technique is used in (Samuel & Tappen, 2009) to optimize the maximum a posterior (MAP) solution of continuous MRFs, since the MAP solution can be regarded as the steady state of the inference process.",2. Related Work,[0],[0]
"An implicit-differentiation-based optimization method for generic energy models is proposed in (Domke, 2012) where the gradient of the optimal state (steady state) of the energy w.r.t.",2. Related Work,[0],[0]
"the parameters can be efficiently computed given the fast matrix-vector product implementation (Pearlmutter, 1994).",2. Related Work,[0],[0]
"If one regards the inference algorithms from aforementioned applications as unrolled RNNs, the implicit differentiation technique is essentially equivalent to RBP.
",2. Related Work,[0],[0]
Other efforts have been made to develop alternatives to BPTT.,2. Related Work,[0],[0]
"NoBackTrack (Ollivier et al., 2015) maintains an online estimate of the gradient via the random rank-one reduction technique.",2. Related Work,[0],[0]
"ARTBP (Tallec & Ollivier, 2017) introduces a probability distribution over the truncation points in the sequence and compensates the truncated gradient based on the distribution.",2. Related Work,[0],[0]
Both approaches provide an unbiased estimation of the gradient although their variances differ.,2. Related Work,[0],[0]
"In this section, we review the original RBP algorithm and discuss its assumptions.",3. Revisiting Recurrent Back-Propagation,[0],[0]
We denote the input data and initial hidden state as x and h0.,3.1. Recurrent Back-Propagation,[0],[0]
"During inference, the hidden state at time t is computed as follows,
ht+1 = F (x,wF , ht), (1)
where F is the update function parameterized by wF .",3.1. Recurrent Back-Propagation,[0],[0]
"A typical instantiation of F is an LSTM (Hochreiter & Schmidhuber, 1997) cell function.",3.1. Recurrent Back-Propagation,[0],[0]
"This RNN formulation differs from the one commonly used in language modeling, as the input is not time-dependent.",3.1. Recurrent Back-Propagation,[0],[0]
We restrict our attention to RNNs with fixed inputs for now as it requires fewer assumptions.,3.1. Recurrent Back-Propagation,[0],[0]
"Assuming the dynamical system, (i.e., the forward pass of the RNN), reaches steady state before time step T , we have the following equation,
h∗ = F (x,wF , h ∗), (2)
where h∗ is the steady hidden state.",3.1. Recurrent Back-Propagation,[0],[0]
"We compute the predicted output y based on the steady hidden state as follows,
y = G(x,wG, h ∗), (3)
where G is the output function parameterized by wG. Typically, a loss function L = l(ȳ, y) measures the closeness
between ground truth ȳ and predicted output y. Since the input data x is fixed for all time steps, we can construct a function Ψ of wF and h as follows,
Ψ(wF , h) = h− F (x,wF , h).",3.1. Recurrent Back-Propagation,[0],[0]
"(4)
At the fixed point, we have Ψ(wF , h∗) = 0.",3.1. Recurrent Back-Propagation,[0],[0]
"Assuming some proper conditions on F , e.g., continuous differentiability, we can take the derivative w.r.t.",3.1. Recurrent Back-Propagation,[0],[0]
wF at h∗ on both sides.,3.1. Recurrent Back-Propagation,[0],[0]
"Using the total derivative and the dependence of h∗ on wF we obtain,
∂Ψ(wF , h ∗)
∂wF =
∂h∗
∂wF − dF",3.1. Recurrent Back-Propagation,[0],[0]
"(x,wF , h
∗)
dwF
= (I − JF,h∗) ∂h∗
∂wF − ∂F (x,wF , h
∗)
∂wF = 0, (5)
where JF,h∗ = ∂F (x,wF ,h ∗)",3.1. Recurrent Back-Propagation,[0],[0]
∂h is the Jacobian matrix of F evaluated at h∗ and d is the total derivative operator.,3.1. Recurrent Back-Propagation,[0],[0]
"Assuming that I − JF,h∗ is invertible, we rearrange Eq.",3.1. Recurrent Back-Propagation,[0],[0]
"(5) to get,
∂h∗ ∂wF = (I − JF,h∗)−1 ∂F (x,wF , h ∗) ∂wF .",3.1. Recurrent Back-Propagation,[0],[0]
"(6)
In fact, Equations (4- 6) are an application of the Implicit Function Theorem (Rudin, 1964), which guarantees the existence and uniqueness of an implicit function φ such that h∗ = φ(wF ) if two conditions hold: I, Ψ is continuously differentiable and II, I − JF,h∗ is invertible.",3.1. Recurrent Back-Propagation,[0],[0]
"Although we do not know the analytic expression of the function φ, we can still compute its gradient at the fixed point.
",3.1. Recurrent Back-Propagation,[0],[0]
Based on Eq.,3.1. Recurrent Back-Propagation,[0],[0]
"(6), we now turn our attention towards computing the gradient of the loss w.r.t.",3.1. Recurrent Back-Propagation,[0],[0]
the parameters of the RNN.,3.1. Recurrent Back-Propagation,[0],[0]
"By using the total derivative and the chain rule, we have
∂L ∂wG = ∂L ∂y
∂G(x,wG, h ∗)
",3.1. Recurrent Back-Propagation,[0],[0]
"∂wG (7)
∂L ∂wF = ∂L ∂y ∂y ∂h∗",3.1. Recurrent Back-Propagation,[0],[0]
(,3.1. Recurrent Back-Propagation,[0],[0]
"I − JF,h∗)−1
∂F (x,wF , h ∗)
∂wF .",3.1. Recurrent Back-Propagation,[0],[0]
"(8)
Since the gradient of the loss w.r.t. wG can be easily obtained by back-propagation, we focus our exposition on the computation of ∂L∂wF .",3.1. Recurrent Back-Propagation,[0],[0]
"The original RBP algorithm (Pineda, 1987; Almeida, 1987) introduces an auxiliary variable z such that,
z =",3.1. Recurrent Back-Propagation,[0],[0]
"( I − J>F,h∗ )−1(∂L ∂y ∂y ∂h∗ )> , (9)
where z is a column vector.",3.1. Recurrent Back-Propagation,[0],[0]
"If we managed to compute z, then we can substitute it into Eq.",3.1. Recurrent Back-Propagation,[0],[0]
(8) to get the gradient.,3.1. Recurrent Back-Propagation,[0],[0]
"Note that the Jacobian matrix JF,h∗ is nonsymmetric for
Algorithm 1 : Original RBP 1: Initialization: initial guess z0, e.g., draw uniformly
from [0, 1], i = 0, threshold 2: repeat 3: i = i+ 1
4: zi = J>F,h∗zi−1 +",3.1. Recurrent Back-Propagation,[0],[0]
( ∂L ∂y ∂y ∂h∗ )> 5: until ‖zi − zi−1‖,3.1. Recurrent Back-Propagation,[0],[0]
< 6: ∂L∂wF =,3.1. Recurrent Back-Propagation,[0],[0]
z >,3.1. Recurrent Back-Propagation,[0],[0]
"i ∂F (x,wF ,h ∗) ∂wF 7:",3.1. Recurrent Back-Propagation,[0],[0]
"Return ∂L∂wF
general RNNs which renders direct solvers of linear system impractical.",3.1. Recurrent Back-Propagation,[0],[0]
"To compute z, the original RBP algorithm uses fixed point iteration.",3.1. Recurrent Back-Propagation,[0],[0]
"In particular, we multiply ( I − J>F,h∗ ) on the left hand of both sides of Eq.",3.1. Recurrent Back-Propagation,[0],[0]
"(9) and rearrange the terms as follows,
z = J>F,h∗z +
( ∂L
∂y
∂y
∂h∗
)> .",3.1. Recurrent Back-Propagation,[0],[0]
"(10)
If we view the right hand side of the above equation as a function of z, then applying the fixed point iteration results in the Algorithm 1.",3.1. Recurrent Back-Propagation,[0],[0]
"Note that the most expensive operation in this algorithm is the matrix-vector product J>F,h∗z, which is the same operator as back-propagation.",3.1. Recurrent Back-Propagation,[0],[0]
"In this section, we discuss how to satisfy the assumptions of RBP.",3.2. Assumptions of RBP,[0],[0]
"Recall that in order to apply the implicit function theorem, Ψ(wF , h) has to satisfy two assumptions: I, Ψ is continuously differentiable.",3.2. Assumptions of RBP,[0],[0]
"II, I − JF,h∗ is invertible.",3.2. Assumptions of RBP,[0],[0]
"Condition I requires the derivative of F to be continuous, a condition satisfied by many RNNs, like LSTM and GRU (Cho et al., 2014).",3.2. Assumptions of RBP,[0],[0]
"Condition II is equivalent to requiring the determinant of I − JF,h∗ to be nonzero, i.e., det(I − JF,h∗) 6= 0.",3.2. Assumptions of RBP,[0],[0]
"One sufficient but not necessary condition to ensure this is to force F to be a contraction map, as in Scarselli et al. (2009).",3.2. Assumptions of RBP,[0],[0]
"Recall that F is a contraction map on Banach space B, i.e., a complete normed vector space, iff, ∀h1, h2 ∈ B, ‖F (h1)− F (h2)‖ ≤ µ‖h1",3.2. Assumptions of RBP,[0],[0]
− h2‖ where 0 ≤ µ < 1.,3.2. Assumptions of RBP,[0],[0]
Banach fixed point theorem guarantees the uniqueness of the fix point of the contraction map F in B. Note that here we drop the dependency of F on w for readability.,3.2. Assumptions of RBP,[0],[0]
"Based on the first order Taylor approximation, F (h) = F (h∗) + JF,h∗(h− h∗), we have,
‖F (h)− F (h∗)‖ ‖h− h∗‖ = ‖JF,h∗(h− h∗)‖",3.2. Assumptions of RBP,[0],[0]
‖h− h∗‖ .,3.2. Assumptions of RBP,[0],[0]
"(11)
Note that if we use L2 vector norm, then the induced matrix norm, a.k.a., operator norm, is,
‖JF,h∗‖ = sup { ‖JF,h∗h‖ ‖h‖ : ∀h 6= 0",3.2. Assumptions of RBP,[0],[0]
"} = σmax(JF,h∗), (12)
",3.2. Assumptions of RBP,[0],[0]
where σmax is the largest singular value.,3.2. Assumptions of RBP,[0],[0]
"Therefore, relying on the contraction map definition, we have,
‖JF,h∗‖ ≤ µ < 1, (13)
",3.2. Assumptions of RBP,[0],[0]
"Moreover, since the minimum singular value of I − JF,h∗ is 1− σmax(JF,h∗), we have
|det(I − JF,h∗)| = ∏",3.2. Assumptions of RBP,[0],[0]
i |σi(I,3.2. Assumptions of RBP,[0],[0]
"− JF,h∗)|
≥",3.2. Assumptions of RBP,[0],[0]
"[1− σmax(JF,h∗)]d > 0.",3.2. Assumptions of RBP,[0],[0]
"(14)
Thus our second condition holds following Eq.",3.2. Assumptions of RBP,[0],[0]
"(14).
",3.2. Assumptions of RBP,[0],[0]
"Scarselli et al. (2009) use L1 vector norm which results in a looser inequality since ‖JF,h∗‖2 ≤ √ d‖JF,h∗‖1.",3.2. Assumptions of RBP,[0],[0]
"They obtain an easier to compute regularization term maxi(‖JF,h∗(: , i)‖1 − η)2 where (:, i) denotes the i-th column and η ∈ (0, 1) is the desired contraction constant.",3.2. Assumptions of RBP,[0],[0]
"We note, however, that this work makes a claim that the contraction map assumption can be achieved by regularizing the local Jacobian JF,h∗ of a general neural network.",3.2. Assumptions of RBP,[0],[0]
"This is problematic because the contraction map property is a global property of F that requires regularizing every h in the spaceB, not just h∗. Nevertheless, this regularization evaluated at h∗ encourages local contraction at the fixed point h∗, which is sufficient for satisfying condition II.",3.2. Assumptions of RBP,[0],[0]
"Another way to enforce condition II to hold is directly formalizing the Lagrangian of equality constraint Ψ(wF , h∗) = 0.",3.2. Assumptions of RBP,[0],[0]
"Since all applications we considered in this paper have converged dynamic systems in practice, we leave further discussions of condition II to the appendix.",3.2. Assumptions of RBP,[0],[0]
"In this section, we present our newly proposed variants of RBP, CG-RBP and Neumann-RBP, in detail.",4. New Recurrent Back-Propagation Variants,[0],[0]
"Facing the system of linear equations like Eq. (9) in the derivation of original RBP, one would naturally think of the most common iterative solver, i.e., conjugate gradient method (Hestenes & Stiefel, 1952).",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"In particular, multiplying I − J>F,h∗ on both sides, we obtain the following equations,
( I − J>F,h∗ ) z",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"=
( ∂L
∂y
∂y
∂h∗
)> .",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"(15)
Unfortunately, for general RNNs, the Jacobian matrix JF,h∗ of the update function, e.g., a cell function of LSTM, is non-symmetric in general.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
This increases the difficulty of solving the system.,4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"One simple yet sometimes effective way to approach this problem is to exploit the conjugate
gradient method on the normal equations (CGNE) (Golub & Van Loan, 2012).",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"Specifically, we multiply I − JF,h∗ on both sides of Eq.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"(15) which results in,
(I − JF,h∗) ( I − J>F,h∗ ) z =",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"(I − JF,h∗)
( ∂L
∂y
∂y
∂h∗
)> .
",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"Having a symmetric matrix multiplying z on the left hand side, we can now use the conjugate gradient method.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
The detailed algorithm is easily obtained by instantiating the standard conjugate gradient (CG) template.,4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"The most expensive operation used in CGNE is JF,h∗J>F,h∗z, which can be implemented by successive matrix-vector products similarly for computing the Fisher information product of the natural gradient method (Schraudolph, 2002).",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"Once we solve z via K-step CGNE, we obtain the final gradient by substituting the solution into Eq.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
(8).,4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"Since the condition number of the current system is the square of the original one, the system may be slower to converge in practice.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"Exploring more advanced and faster convergent numerical methods under this setting, like LSQR (Paige & Saunders, 1982), is left for future work.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"We now develop a new RBP variant called Neumann-RBP, which uses Neumann series from functional analysis and is efficient in terms of computation and memory.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
We then show its connections to BPTT and TBPTT.,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"A Neumann series is a mathematical series of the form∑∞ t=0A
t where A is an operator.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"In matrix theory, it is also known as the geometric series of a matrix.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"A convergent Neumann series has the following property,
(I −A)−1 = ∞∑ k=0 Ak. (16)
",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"One sufficient condition of convergence is that the spectral radius (i.e., the largest absolute eigenvalue value) ofA is less than 1.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"This convergence criterion applied to A = JF,h∗ implies condition II.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
Other cases where the convergence hold is beyond the scope of this paper.,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"If the Neumann series ∑∞ t=0 J t F,h∗ converges, we can use it to replace the term (I − JF,h∗)−1 in E.q.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
(8).,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Furthermore, the gradient of RBP can be approximated with the K-th order truncation of Neumann series as below,
∂L ∂wF ≈ ∂L ∂y K∑ k=0 ∂y ∂h∗ JkF,h∗ ∂F (x,wF , h ∗) ∂wF .",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"(17)
There is a rich body of literature on how to compute Neumann series efficiently using binary or ternary decomposition (Westreich, 1989; Vassil & Diego, 2017).",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"However,
Algorithm 2 : Neumann-RBP 1: Initialization: v0 = g0 = ( ∂L ∂y ∂y ∂h∗ )> 2: for step t = 1, 2, . . .",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
",K do 3: vt = J>vt−1",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
4: gt = gt−1 + vt 5: end for 6: ∂L∂wF = (gK) > ∂F,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"(x,wF ,h∗) ∂wF
7: Return ∂L∂wF
these decomposition based approaches are inapplicable in our context since we cannot compute the Jacobian matrix JF,h∗ efficiently for general neural networks.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Fortunately, we can instead efficiently compute the matrix-vector product J>F,h∗u and JF,h∗u (u is a proper sized vector) by using reverse and forward mode auto-differentiation (Pearlmutter, 1994).",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Relying on this technique, we summarize the Neumann series based RBP algorithm in Algorithm 2.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"In practice, we can obtain further memory efficiency by performing updates within the for loops in-place (please refer to the example code in appendix), so that memory usage need not scale with the number of truncation steps.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Moreover, since the algorithm does not rely on hidden states except the fixed point h∗, we no longer need to store the hidden states in the forward pass of the RNN.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Besides the computational benefit, we now have the following proposition to connect Neumann-RBP to BPTT and TBPTT.
",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
Proposition 1.,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Assume that there exists some step K where 0 < K ≤ T such that for the convergent sequence of hidden states h0, h1, . . .",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
", hT of an RNN, we have h∗ = hT = hT−1 = · · · = hT−K where h∗ is the fixed point.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"If the Neumann series ∑∞ t=0 J t F,h∗ converges, then the full and K-step Neumann-RBP are equivalent to BPTT and K-step TBPTT respectively.
",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Moreover, the following proposition bounds the error of K-step Neumann-RBP.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
Proposition 2.,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"If the Neumann series ∑∞ t=0 J t F,h∗ converges, then the error between K-step and full Neumann series is as follows,∥∥∥∥∥ K∑ t=0 JtF,h∗",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"− (I − JF,h∗)−1 ∥∥∥∥∥ ≤ ∥∥(I",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"− JF,h∗)−1∥∥ ‖JF,h∗‖K+1
We leave all proofs in appendix.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"In this section, we thoroughly study all RBP variants on diverse applications.",5. Experiments,[0],[0]
Our implementation based on PyTorch is publicly available1.,5. Experiments,[0],[0]
"Note that our Neumann-RBP is very
1https://github.com/lrjconan/RBP
simple to implement using automatic differentiation and we provide a very short example program in the appendix.",5. Experiments,[0],[0]
"The classical testbed for RBP is the associative memory (Hopfield, 1982).",5.1. Associative Memory,[0],[0]
Several images or patterns are presented to the neural network which learns to store or memorize the images.,5.1. Associative Memory,[0],[0]
"After the learning process, the network is subsequently presented with a corrupted or noisy version of the original image.",5.1. Associative Memory,[0],[0]
The task is then to retrieve the corresponding original image.,5.1. Associative Memory,[0],[0]
"We consider a simplified continuous Hopfield network as described in (Haykin, 1993).",5.1. Associative Memory,[0],[0]
"Specifically, the system of nonlinear first-order differential equations is,
d dt hi(t) =",5.1. Associative Memory,[0],[0]
− hi(t),5.1. Associative Memory,[0],[0]
a + N∑ j=1 wijφ(b · hj(t)),5.1. Associative Memory,[0],[0]
"+ Ii, (18)
where subscript i denotes the index of the neuron.",5.1. Associative Memory,[0],[0]
wij is the learnable weight between a pair of neurons.,5.1. Associative Memory,[0],[0]
hi is the hidden state of the i-th neuron.,5.1. Associative Memory,[0],[0]
φ is a nonlinear activate function which is a sigmoid function in our experiments.,5.1. Associative Memory,[0],[0]
"a, b are positive constants and are set to 1 and 0.5.",5.1. Associative Memory,[0],[0]
"The set of neurons consists of three parts: observed, hidden and output neurons, of size 784, 1024 and 784 respectively.",5.1. Associative Memory,[0],[0]
"For observed neuron, the state hi is clamped to observed pixel value Ii.",5.1. Associative Memory,[0],[0]
"For hidden and output neurons, the observed pixel value Ii = 0 and their states hi are updated according to Eq.",5.1. Associative Memory,[0],[0]
(18).,5.1. Associative Memory,[0],[0]
"During inference, the output neurons return xi = φ(b · hi) and we further binarize it for visualization.",5.1. Associative Memory,[0],[0]
"An important property of continuous Hopfield networks is
that by updating the states according to Eq.",5.1. Associative Memory,[0],[0]
"(18) until convergence (which corresponds to the forward pass of RNNs), we are guaranteed to minimize the following (Lyapunov) energy function.
",5.1. Associative Memory,[0],[0]
E = N∑ i=1,5.1. Associative Memory,[0],[0]
( 1 a ∫ xi 0 φ−1(x)dx− Iixi ),5.1. Associative Memory,[0],[0]
− N∑ i=1,5.1. Associative Memory,[0],[0]
"N∑ j=1 wijxixj 2 ,
where we drop the dependency on time t for simplicity.",5.1. Associative Memory,[0],[0]
"Instead of adopting the Hebbian learning rule as in (Hopfield, 1982), we directly formulate the learning objective as minimizing ∑ i∈I ‖xi− Ii‖1 where I is the set of observed neurons.",5.1. Associative Memory,[0],[0]
"In our experiments, we train and test on 10 MNIST images.",5.1. Associative Memory,[0],[0]
"In training we feed clean data, and during testing we randomly corrupt 50% of the non-zero pixel values to zero.",5.1. Associative Memory,[0],[0]
"The number of updates for one inference pass is 50.
",5.1. Associative Memory,[0],[0]
Fig. 1 shows the training and validation curves of continuous Hopfield network with different optimization methods.,5.1. Associative Memory,[0],[0]
"Here truncation steps for TBPTT, RBP, CG-RBP and Neumann-RBP are all set to 20.",5.1. Associative Memory,[0],[0]
"From the figure, we can see that CG-RBP and Neumann-RBP match BPTT under this setting which verifies that their gradients are accurate.",5.1. Associative Memory,[0],[0]
"Nevertheless, we can see that training curve of the original RBP blows up which validates its instability issue.",5.1. Associative Memory,[0],[0]
The hidden state of Hopfield network becomes steady within 10 steps.,5.1. Associative Memory,[0],[0]
"However, we notice that if we set the truncation step to 10, original RBP exhibits behaviors which fails to converge.",5.1. Associative Memory,[0],[0]
We also show some visualizations of retrieved images of the Hopfield network under different optimization methods in Fig. 2.,5.1. Associative Memory,[0],[0]
More visual results are provided in the appendix.,5.1. Associative Memory,[0],[0]
We investigate RBPs on semi-supervised document classification with citation networks.,5.2. Semi-supervised Document Classification,[0],[0]
A node of a network represents a document associated with a bag-of-words feature.,5.2. Semi-supervised Document Classification,[0],[0]
Nodes are connected based on the citation links.,5.2. Semi-supervised Document Classification,[0],[0]
"Given a portion of nodes labeled with subject categories, e.g., science, history, the task is to predict the categories for unlabeled nodes within the same network.",5.2. Semi-supervised Document Classification,[0],[0]
"We use two citation networks from (Yang et al., 2016), i.e., Cora, Pubmed, of which the statistics are summarized in the appendix.",5.2. Semi-supervised Document Classification,[0],[0]
"We adopt graph neural networks (GNNs) (Scarselli et al., 2009) model and employ the GRU as the update function similarly as (Li et al., 2016).",5.2. Semi-supervised Document Classification,[0],[0]
"We refer to (Li et al., 2016; Liao et al., 2018) for more details.",5.2. Semi-supervised Document Classification,[0],[0]
We compare different optimization methods with the same GNN.,5.2. Semi-supervised Document Classification,[0],[0]
We also add a logistic regression model as a baseline which is applied to every node independently.,5.2. Semi-supervised Document Classification,[0],[0]
"The labeled documents are randomly split into 1%, 49% and 50% for training, validation and testing.",5.2. Semi-supervised Document Classification,[0],[0]
We run all experiments with 10 different random seeds and report the average results.,5.2. Semi-supervised Document Classification,[0],[0]
"The training, validation and difference norm curves of BPTT, TBPTT and all RBPs are shown in Fig. 3.",5.2. Semi-supervised Document Classification,[0],[0]
We can see that the hidden states of GNNs with different optimization methods become steady during inference from Fig. 3 (c).,5.2. Semi-supervised Document Classification,[0],[0]
"As shown in Fig. 3 (a) and (b), Neumann-RBP is on par with TBPTT on both datasets.",5.2. Semi-supervised Document Classification,[0],[0]
This matches our analysis in proposition 1 since the changes of successive hidden states of TBPTT and Neumann-RBP are almost zero as shown in Fig. 3 (c).,5.2. Semi-supervised Document Classification,[0],[0]
"Moreover, they outperform other variants and the baseline model.",5.2. Semi-supervised Document Classification,[0],[0]
"On the other hand, BPTT on both datasets encounter issues in learning which may be attributable to the accumulation of errors in
the many steps of unrolling.",5.2. Semi-supervised Document Classification,[0],[0]
"Note that CG-RBP sometimes performs significantly worse than Neumann-RBP, e.g., on Cora.",5.2. Semi-supervised Document Classification,[0],[0]
This may be caused by the fact that the underlying linear system of CG-RBP is ill-conditioned in some applications as the condition number is squared in CGNE.,5.2. Semi-supervised Document Classification,[0],[0]
The test accuracy of different methods are summarized in Table 1.,5.2. Semi-supervised Document Classification,[0],[0]
It generally matches the behavior in the validation curves.,5.2. Semi-supervised Document Classification,[0],[0]
"In our next experiment, we test the abilities of RBP to perform hyperparameter optimization.",5.3. Hyperparameter Optimization,[0],[0]
"In this experiment, we view the optimization process as a RNN.",5.3. Hyperparameter Optimization,[0],[0]
"When training a neural network, the model parameters, e.g., weights and bias, are regarded as the hidden states of the RNN.",5.3. Hyperparameter Optimization,[0],[0]
Hyperparameters such as learning rate and momentum are learnable parameters of this ‘meta-learning’ RNN.,5.3. Hyperparameter Optimization,[0],[0]
"Here we focus on the gradient based hyperparameter optimization rather than the gradient-free one (Snoek et al., 2012).",5.3. Hyperparameter Optimization,[0],[0]
"We adopt the same experiment setting as in (Maclaurin et al., 2015), using an initial learning rate of exp(−1) and momentum 0.5.",5.3. Hyperparameter Optimization,[0],[0]
"The optimization is on a fully connected network with 4 layers, of sizes 784, 50, 50, and 50.",5.3. Hyperparameter Optimization,[0],[0]
"For each layer, we associate one learning rate and one momentum with weight and bias respectively which results in 16 hyperparameters in total.",5.3. Hyperparameter Optimization,[0],[0]
"We use tanh non-linearities and train on 10, 000 examples on MNIST.",5.3. Hyperparameter Optimization,[0],[0]
"At each forward step of the RNN, i.e., at each optimization step, a different mini-batch of images is fed to the model.",5.3. Hyperparameter Optimization,[0],[0]
This is different from the previous setting where input data is fixed.,5.3. Hyperparameter Optimization,[0],[0]
"However, since the minibatches are assumed to be i.i.d., the sequential input data can be viewed as sampled from a stationary distribution.",5.3. Hyperparameter Optimization,[0],[0]
We can thus safely apply RBP as the steady state holds in expectation.,5.3. Hyperparameter Optimization,[0],[0]
"In terms of implementation, we just need to average the meta gradient returned by RBPs or TBPTT across multiple mini-batches at the end of one meta step.",5.3. Hyperparameter Optimization,[0],[0]
"We use Adam (Kingma & Ba, 2014) as the meta optimizer and set the learning rate to 0.05.",5.3. Hyperparameter Optimization,[0],[0]
"The initialization of the
fully connected network at each meta step is controlled to be the same.
",5.3. Hyperparameter Optimization,[0],[0]
Fig. 5 shows the meta training losses under different training and truncation steps.,5.3. Hyperparameter Optimization,[0],[0]
"For better understanding, one can consider the training step as the unrolling step of the RNN.",5.3. Hyperparameter Optimization,[0],[0]
Truncation step is the the number of steps that TBPTT and RBPs execute.,5.3. Hyperparameter Optimization,[0],[0]
"From the figure, we can see that as the number of training steps increases (e.g., from (a) to (d)), the meta loss becomes smoother.",5.3. Hyperparameter Optimization,[0],[0]
This makes sense since more steps make the training per meta step closer to convergence.,5.3. Hyperparameter Optimization,[0],[0]
Another surprising phenomenon we found is the meta loss of TBPTT becomes worse when the training step increases.,5.3. Hyperparameter Optimization,[0],[0]
"One possible explanation is that the initial meta training loss of small training steps (e.g., (a)) is still very high as you can see from the log y-axis whereas the one with large training step, e.g., (d) is much lower.",5.3. Hyperparameter Optimization,[0],[0]
The probability of using incorrect gradients to decrease the meta loss in case (a) is most likely higher than that of (d) since it is farther from convergence.,5.3. Hyperparameter Optimization,[0],[0]
"On the other hand, our Neumann-RBP performs consistently better than the original RBP and TBPTT which empirically validates that Neumann-RBP provides better estimation of the gradient in this case.",5.3. Hyperparameter Optimization,[0],[0]
The potential reason why RBP performs poorly is that the stochasticity of mini-batches worsen the instability issue.,5.3. Hyperparameter Optimization,[0],[0]
Training losses under similar settings at the last meta step are also provided in Fig. 6.,5.3. Hyperparameter Optimization,[0],[0]
"We can see that at the end of hyperparameter optimization, our Neumann-RBP generally matches the performance of BPTT and outperforms the other methods.",5.3. Hyperparameter Optimization,[0],[0]
"Fig. 4 depicts the trajectories of hidden states in 2D space via t-SNE (Maaten & Hinton, 2008).",5.3. Hyperparameter Optimization,[0],[0]
"From the figure, we can see that as the meta training goes on, TBPTT tends to oscillate whereas Neumann-RBP converges, which matches the finding in the train loss curves in Fig. 6.
",5.3. Hyperparameter Optimization,[0],[0]
"We also compare the running time and memory cost of our unoptimized Neumann-RBP implementation with the standard BPTT, i.e., using autograd of PyTorch.",5.3. Hyperparameter Optimization,[0],[0]
"With 1000 training steps, one meta step of BPTT cost 310.4s and 4061MB GPU memory in average.",5.3. Hyperparameter Optimization,[0],[0]
"We take BPTT as the reference cost and report the ratio BPTT’s cost divided by Neumann-
RBP’s in Table 2.",5.3. Hyperparameter Optimization,[0],[0]
All results are reported as the average of 10 runs.,5.3. Hyperparameter Optimization,[0],[0]
"Even without optimizing the code, the practical runtime and memory footprint advantages of Neumann-RBP over BPTT is still significant.",5.3. Hyperparameter Optimization,[0],[0]
"In this paper, we revisit the RBP algorithm and discuss its assumptions and how to satisfy them for deep learning.",6. Conclusion,[0],[0]
"Moreover, we propose two variants of RBP based on conjugate gradient on normal equations and Neumann series.",6. Conclusion,[0],[0]
Connections between Neumann-RBP and TBPTT are established which sheds some light on analyzing the approximation quality of the gradient of TBPTT.,6. Conclusion,[0],[0]
Experimental results on diverse tasks demonstrate that Neumann-RBP is a stable and efficient alternative to original RBP and is promising for several practical problems.,6. Conclusion,[0],[0]
"In the future, we would like to explore RBP on hyperparameter optimization with large scale deep neural networks.",6. Conclusion,[0],[0]
We thank Barak Pearlmutter for the enlightening discussion and anonymous ICML reviewers for valuable comments.,Acknowledgements,[0],[0]
R.L. was supported by Connaught International Scholarships.,Acknowledgements,[0],[0]
"R.L., E.F., L.Z., K.Y., X.P., R.U. and R.Z. were supported in part by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DoI/IBC) contract number D16PC00003.",Acknowledgements,[0],[0]
K.Y. and X.P. were supported in part by BRAIN Initiative grant NIH 5U01NS094368.,Acknowledgements,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.,Acknowledgements,[0],[0]
"Disclaimer: the views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoI/IBC, or the U.S. Government.",Acknowledgements,[0],[0]
"In this paper, we revisit the recurrent backpropagation (RBP) algorithm (Almeida, 1987; Pineda, 1987), discuss the conditions under which it applies as well as how to satisfy them in deep neural networks.",abstractText,[0],[0]
We show that RBP can be unstable and propose two variants based on conjugate gradient on the normal equations (CG-RBP) and Neumann series (Neumann-RBP).,abstractText,[0],[0]
We further investigate the relationship between Neumann-RBP and back propagation through time (BPTT) and its truncated version (TBPTT).,abstractText,[0],[0]
"Our NeumannRBP has the same time complexity as TBPTT but only requires constant memory, whereas TBPTT’s memory cost scales linearly with the number of truncation steps.",abstractText,[0],[0]
"We examine all RBP variants, along with BPTT and TBPTT, in three different application domains: associative memory with continuous Hopfield networks, document classification in citation networks using graph neural networks, and hyperparameter optimization for fully connected networks.",abstractText,[0],[0]
"All experiments demonstrate that RBPs, especially the Neumann-RBP variant, are efficient and effective for optimizing convergent recurrent neural networks.",abstractText,[0],[0]
Reviving and Improving Recurrent Back-Propagation,title,[0],[0]
"A widely used machine learning technique is the transfer of a representation learned from a source task, for which labeled data is abundant, to a target task, for which labeled data is scarce.",1. Introduction,[0],[0]
This may be effective if the tasks approximately share an intermediate representation.,1. Introduction,[0],[0]
"For example:
• features learned from an image of a human face to predict age may also be useful for predicting gender
• word embeddings learned to predict word contexts may also be useful for part of speech tagging
• features learned from financial data to predict loan default may also be useful for predicting insurance fraud.
",1. Introduction,[0],[0]
"Often a representation is learned by a different organization that may have greater access to data, computational and human resources.",1. Introduction,[0],[0]
"Examples are the Google word2vec package (Mikolov et al., 2013), and downloadable pre-trained
1The Australian National University and Data61, Canberra, ACT, Australia 2Carnegie Mellon University, Pittsburgh, PA, USA.",1. Introduction,[0],[0]
"Correspondence to: Daniel McNamara <daniel.mcnamara@anu.edu.au>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"neural networks.1 Under this ‘representation-as-a-service’ model, a user may expect to access the representation itself, as well as information about its performance on the source task data on which it was trained.",1. Introduction,[0],[0]
"We aim to convert this into a guarantee of the usefulness of the representation on other tasks, which is known in advance without the effort or cost of testing the representation on the target task(s).",1. Introduction,[0],[0]
"Our analysis also covers the case where the source task is constructed from unlabeled data, as in neural network unsupervised pre-training.
",1. Introduction,[0],[0]
"We consider two approaches to transferring a representation learned from a source task to a target task, as shown in Figure 1.",1. Introduction,[0],[0]
"We may either treat the representation as fixed, or we may narrow the class of representations considered on the target task, which we refer to as fine-tuning.",1. Introduction,[0],[0]
"The fixed option may be attractive when very little labeled target task data is available and hence overfitting is a strong concern, while the advantage of fine-tuning is relatively greater hypothesis class expressiveness.
",1. Introduction,[0],[0]
"Let X,Y and Z be sets known as the input, output and feature spaces respectively.",1. Introduction,[0],[0]
"Let F be a class of representations, where f : X → Z for f ∈ F .",1. Introduction,[0],[0]
"Let G be a class of specialized classifiers, where g : Z → Y for g ∈ G.",1. Introduction,[0],[0]
"Let the hypothesis class H := {h : ∃f ∈ F, g ∈ G such that h",1. Introduction,[0],[0]
= g,1. Introduction,[0],[0]
◦ f}.,1. Introduction,[0],[0]
"Let hS , hT : X → Y be the labeling functions and PS , PT be the input distributions for source task S and target task T respectively.",1. Introduction,[0],[0]
"We consider the setting Y = {−1, 1}.",1. Introduction,[0],[0]
Let the risk of a hypothesis h on S and T be RS(h),1. Introduction,[0],[0]
:= Ex∼PS [hS(x) 6= h(x)] and RT (h) :,1. Introduction,[0],[0]
= Ex∼PT [hT (x) 6= h(x)] respectively.,1. Introduction,[0],[0]
Let R̂S(h) and R̂T (h) be the corresponding empirical (i.e. training set) risks.,1. Introduction,[0],[0]
We have mS labelled points for S and mT labelled points for T .,1. Introduction,[0],[0]
"Let dH be the VC dimension of H .
",1. Introduction,[0],[0]
The remainder of the paper is structured as follows.,1. Introduction,[0],[0]
In Section 2 we introduce related work.,1. Introduction,[0],[0]
In Sections 3 and 4 we analyze the cases where the transferred representation is fixed and fine-tuned respectively.,1. Introduction,[0],[0]
In Section 5 we apply the results and use them to motivate and test a practical approach to weight transfer in neural networks.,1. Introduction,[0],[0]
"We conclude in Section 6 and defer more involved proofs to Section 7.
1See http://code.google.com/archive/p/ word2vec, http://caffe.berkeleyvision.org/ model_zoo and http://vlfeat.org/matconvnet/ pretrained for examples.",1. Introduction,[0],[0]
"Empirical studies have shown the success of transferring representations between tasks (Donahue et al., 2014; Hoffman et al., 2014; Girshick et al., 2014; Socher et al., 2013; Bansal et al., 2014).",2. Background,[0],[0]
"Word embeddings learned on a source task have been shown (Qu et al., 2015) to perform better than unigram features on target tasks such as part of speech tagging, and comparably or better than embeddings finetuned on the target task.",2. Background,[0],[0]
"Yosinski et al. (2014) learned neural network weights using half of the ImageNet classes, and then learned the other classes with a neural network initialized with these weights, finding a benefit compared to random initialization only with target task fine-tuning.",2. Background,[0],[0]
"The transfer of representations, both with and without finetuning, is widely and successfully used.
",2. Background,[0],[0]
"Previous work on domain adaptation (Ben-David et al., 2010; Mansour et al., 2009; Germain et al., 2013) has considered learning a hypothesis h on S and re-using it on T , bounding RT (h) using RS(h) (measured with labeled source data) and some notion of similarity between PS and PT (measured with additional unlabeled target data).",2. Background,[0],[0]
"Such results motivate a joint optimization using labeled source and unlabeled target data (Ganin et al., 2016; Long et al., 2015) to learn separate mappings fS , fT : X → Z which make the induced distributions in the feature space Z similar, and a hypothesis g : Z → Y learned from the source labels which can be re-used on T .",2. Background,[0],[0]
This approach assumes the tasks become the same if their input distributions can be aligned.,2. Background,[0],[0]
We consider a relaxation where the tasks are more weakly related but some representation step can be transferred.,2. Background,[0],[0]
"We consider learning f : X → Z on S, re-using it on T , and then learning gT :",2. Background,[0],[0]
Z → Y from a small amount of labeled target data.,2. Background,[0],[0]
"Given the widespread use of ‘downloadable’ representations, where f and gT are learned separately and there is no joint optimization over source and target data, this is a realistic setting.
",2. Background,[0],[0]
Work on lifelong learning relates the past performance of a representation over many tasks to its expected future performance.,2. Background,[0],[0]
For a representation f ∈ F we construct G ◦ f,2. Background,[0],[0]
:= {g ◦ f,2. Background,[0],[0]
: g ∈ G}.,2. Background,[0],[0]
"Suppose there is a distribution over tasks, known as an environment.",2. Background,[0],[0]
"Assume several tasks from this environment have been sampled, and that for each task some hypothesis in G ◦ f has been selected and its empirical risk evaluated.",2. Background,[0],[0]
Previous work has provided bounds on the difference between the average empirical risk and the expected risk of the best hypothesis in G ◦ f for a new task drawn from the environment.,2. Background,[0],[0]
"Such bounds have been given by measuring the complexity of F and G using covering numbers (Baxter, 2000), a variant of the growth function (Galanti et al., 2016), and a distribution-dependent measure known as Gaussian complexity (Maurer et al., 2016).",2. Background,[0],[0]
"All of these bounds rely on
known past performance on a large number of tasks.2 In practice, however, representations such as neural network weights or word embeddings are often learned using only a single source task, which is the setting we consider.",2. Background,[0],[0]
"Suppose labeled source data is abundant, labeled target data is scarce, and we believe the tasks share a representation.",3. Representation Fixed by Source Task,[0],[0]
"A natural approach to leveraging the source data is to learn ĝS ◦ f̂ ∈ H on S, from which we assume we may extract f̂ ∈ F ,3 then conduct empirical risk minimization over G ◦ f̂ := {g ◦ f̂ : g ∈ G} on T yielding ĝT ◦ f̂ .",3. Representation Fixed by Source Task,[0],[0]
"Theorem 1 upper-bounds RT (ĝT ◦ f̂) using four terms: a function ω measuring a transferrability property obtained analytically from the problem setting, the empirical risk R̂S(ĝS ◦ f̂), the generalization error of a hypothesis in H learned from mS samples, and the generalization error of a hypothesis in G learned from mT samples.",3. Representation Fixed by Source Task,[0],[0]
"The value of the theorem is that if ω(R) = O(R), R̂S(ĝS ◦ f̂) is a small constant, mS mT and dH dG,4 we improve on the VC dimension-based bound for learning T from scratch by avoiding the generalization error of a hypothesis in H learned from mT samples.",3. Representation Fixed by Source Task,[0],[0]
"Furthermore, we do not settle for bounding RT (ĝT ◦ f̂) in terms of R̂T (ĝT ◦ f̂), which may be large.",3. Representation Fixed by Source Task,[0],[0]
"The theorem can be used to select S given
2Pentina & Lampert (2014) extend this analysis to stochastic hypotheses (i.e. distributions over deterministic hypotheses), where for each task we learn a posterior given a prior and training data.",3. Representation Fixed by Source Task,[0],[0]
The quality of the prior affects the learner’s performance.,3. Representation Fixed by Source Task,[0],[0]
"The study proposes using source tasks to learn a ‘hyperposterior’, a distribution over priors which is sampled to give a prior for each task.",3. Representation Fixed by Source Task,[0],[0]
Such a hyperposterior may focus the learner on a representation shared across tasks.,3. Representation Fixed by Source Task,[0],[0]
"The study gives a PAC-Bayes bound on the expected risk of using a hyperposterior to learn a new task drawn from the environment, in terms of the average empirical risk obtained using the hyperposterior to learn the source tasks.
",3. Representation Fixed by Source Task,[0],[0]
"3This is not possible with knowledge of ĝS ◦ f̂ alone, but in the case of feedforward neural networks which we focus on, f̂ is known if the weights learned on S are known.
",3. Representation Fixed by Source Task,[0],[0]
"4We have mS mT if labeled source task data is abundant while labeled target task data is scarce, and dH dG",3. Representation Fixed by Source Task,[0],[0]
"if we simplify target task learning by substantially reducing the hypothesis space to be searched.
several options.",3. Representation Fixed by Source Task,[0],[0]
"While we refer to ω in a general form, we give an example in Section 3.1 and expect that others exist.5
Theorem 1.",3. Representation Fixed by Source Task,[0],[0]
Let ω : R → R be a non-decreasing function.,3. Representation Fixed by Source Task,[0],[0]
"Suppose PS , PT , hS , hT , f̂ , G have the property that ∀ĝS ∈ G, min
g∈G RT",3. Representation Fixed by Source Task,[0],[0]
(g ◦ f̂) ≤ ω(RS(ĝS ◦ f̂)).,3. Representation Fixed by Source Task,[0],[0]
"Let ĝT :=
arg min g∈G
R̂T (g ◦ f̂).",3. Representation Fixed by Source Task,[0],[0]
"Then with probability at least 1 − δ
over pairs of training sets for tasks S and T , RT (ĝT ◦ f̂) ≤ ω(R̂S(ĝS ◦ f̂)",3. Representation Fixed by Source Task,[0],[0]
"+ 2
",3. Representation Fixed by Source Task,[0],[0]
"√ 2dH log(2emS/dH)+2 log(8/δ)
mS ) + 4 √
2dG log(2emT /dG)+2 log(8/δ) mT .
",3. Representation Fixed by Source Task,[0],[0]
Proof.,3. Representation Fixed by Source Task,[0],[0]
Let g∗T :,3. Representation Fixed by Source Task,[0],[0]
= arg min g∈G RT,3. Representation Fixed by Source Task,[0],[0]
(g ◦ f̂).,3. Representation Fixed by Source Task,[0],[0]
"With probability at least 1− δ,
RT (ĝT ◦ f̂) ≤ R̂T (ĝT ◦ f̂) + 2 √
2dG log(2emT /dG)+2 log(8/δ) mT
≤ R̂T (g∗T ◦ f̂) + 2 √ 2dG log(2emT /dG)+2 log(8/δ) mT
≤",3. Representation Fixed by Source Task,[0],[0]
RT,3. Representation Fixed by Source Task,[0],[0]
"(g∗T ◦ f̂) + 4 √ 2dG log(2emT /dG)+2 log(8/δ) mT
≤ ω(RS(ĝS ◦ f̂))",3. Representation Fixed by Source Task,[0],[0]
"+ 4 √
2dG log(2emT /dG)+2 log(8/δ) mT
≤ ω(R̂S(ĝS ◦ f̂) + 2 √
2dH log(2emS/dH)+2 log(8/δ) mS ) + 4 √
2dG log(2emT /dG)+2 log(8/δ) mT .
",3. Representation Fixed by Source Task,[0],[0]
"Using m training points and a hypothesis class of VC dimension d, with probability at least 1 − δ, for all hypotheses h simultaneously, the riskR(h) and empirical risk R̂(h)
satisfy |R(h)−R̂(h)| ≤ 2 √
2d log(2em/d)+2 log(4/δ) m",3. Representation Fixed by Source Task,[0],[0]
"(Mohri
et al., 2012).",3. Representation Fixed by Source Task,[0],[0]
ForG this yields the first and third inequalities with probability at least 1 − δ2 .,3. Representation Fixed by Source Task,[0],[0]
"For H , because ω is nondecreasing, this yields the fifth inequality with probability at least 1 − δ2 .",3. Representation Fixed by Source Task,[0],[0]
Applying the union bound achieves the desired result.,3. Representation Fixed by Source Task,[0],[0]
The second inequality is by the definition of ĝT and the fourth inequality follows from our assumption.,3. Representation Fixed by Source Task,[0],[0]
"In Theorem 2, we give an example of the property required by Theorem 1 which is specific to a particular problem setting.",3.1. Neural Network Example with Fixed Representation,[0],[0]
We consider a neural network with a single hidden layer (see Figure 2).,3.1. Neural Network Example with Fixed Representation,[0],[0]
"We propose transferring the lowerlevel weights (corresponding to f̂ ) learned on S, so that only the upper-level weights (corresponding to G) have to be learned on T .",3.1. Neural Network Example with Fixed Representation,[0],[0]
"We want to show f̂ is also useful for T .
",3.1. Neural Network Example with Fixed Representation,[0],[0]
"5We define ω by relating RS(ĝS ◦ f̂) to min g∈G RT (g ◦ f̂), since we expect this may be feasible analytically as in our example in Section 3.1.",3.1. Neural Network Example with Fixed Representation,[0],[0]
"However, because we only observe R̂S(ĝS ◦ f̂), in Theorem 1 we use this to bound RS(ĝS ◦ f̂) and then apply ω.
",3.1. Neural Network Example with Fixed Representation,[0],[0]
"To do this, we assume that some lower-level weights perform well on both tasks, which is clearly a necessary condition for the specific f̂ we are transferring to perform well on both tasks.",3.1. Neural Network Example with Fixed Representation,[0],[0]
We also assume PS and PT have the relative rotation invariance property and that the upper-level weights have fixed magnitude.,3.1. Neural Network Example with Fixed Representation,[0],[0]
"This is so that a point x for which f̂(x) contributes to the risk on T cannot be ‘hidden’ from the risk of using f̂ on S, either through low PS(x) or low magnitude upper-level weights.",3.1. Neural Network Example with Fixed Representation,[0],[0]
"Hence RS(ĝS ◦ f̂) reliably indicates the usefulness of f̂ on T .
",3.1. Neural Network Example with Fixed Representation,[0],[0]
LetX = Rn and Z = Rk.,3.1. Neural Network Example with Fixed Representation,[0],[0]
Let F be the function class such that f(x) =,3.1. Neural Network Example with Fixed Representation,[0],[0]
"[a(w1 · x), . . .",3.1. Neural Network Example with Fixed Representation,[0],[0]
", a(wk · x)], where wi ∈ Rn for 1 ≤",3.1. Neural Network Example with Fixed Representation,[0],[0]
"i ≤ k,",3.1. Neural Network Example with Fixed Representation,[0],[0]
a : R → R is an odd function6 and · is the dot product.,3.1. Neural Network Example with Fixed Representation,[0],[0]
"Let G be the function class such that g(z) = sign(v · z), where v ∈ {−1, 1}k.",3.1. Neural Network Example with Fixed Representation,[0],[0]
"Suppose ∃f ∈ F, gS , gT ∈",3.1. Neural Network Example with Fixed Representation,[0],[0]
"G such that max[RS(gS ◦f), RT (gT ◦f)] ≤ .",3.1. Neural Network Example with Fixed Representation,[0],[0]
Let f̂(x) :=,3.1. Neural Network Example with Fixed Representation,[0],[0]
"[a(ŵ1 · x), . . .",3.1. Neural Network Example with Fixed Representation,[0],[0]
", a(ŵk · x)].",3.1. Neural Network Example with Fixed Representation,[0],[0]
"Given wi and ŵi, pick nonzero constants αi and βi such that ||wi|| = ||αiŵi",3.1. Neural Network Example with Fixed Representation,[0],[0]
− βiwi|| and wi · (αiŵi − βiwi) = 0.,3.1. Neural Network Example with Fixed Representation,[0],[0]
"Let M be a 2k×nmatrix with rowsw1, α1ŵ1−β1w1, . . .",3.1. Neural Network Example with Fixed Representation,[0],[0]
", wk, αkŵk− βkwk.",3.1. Neural Network Example with Fixed Representation,[0],[0]
"Suppose M is full rank.7 Suppose ∀x, x′ such that ||Mx|| = ||Mx′||, PT (x) ≤ cPS(x′) for some c ≥ 1, which we call relative rotation invariance and implies PS and PT have the same support.",3.1. Neural Network Example with Fixed Representation,[0],[0]
"If M is an orthogonal matrix then ∀x, x′ such that ||x|| = ||x′||, PT (x) ≤ cPS(x′).8
Theorem 2.",3.1. Neural Network Example with Fixed Representation,[0],[0]
Let ω(R) := cR + (1 + c).,3.1. Neural Network Example with Fixed Representation,[0],[0]
"Then ∀ĝS ∈ G, min g∈G
RT (g ◦ f̂) ≤ ω(RS(ĝS ◦ f̂)).",3.1. Neural Network Example with Fixed Representation,[0],[0]
6i.e. a(−x),3.1. Neural Network Example with Fixed Representation,[0],[0]
= −a(x).,3.1. Neural Network Example with Fixed Representation,[0],[0]
"Examples are tanh, sign and identity.",3.1. Neural Network Example with Fixed Representation,[0],[0]
"7To see that this condition is necessary, consider the following example where M is not full rank.",3.1. Neural Network Example with Fixed Representation,[0],[0]
"Let n = 4, k = 2, hS = sign(x1) and hT = sign(x2).",3.1. Neural Network Example with Fixed Representation,[0],[0]
For f(x) =,3.1. Neural Network Example with Fixed Representation,[0],[0]
"[x1 + x2, x1 − x2], gS(z) = sign(z1 + z2) and gT",3.1. Neural Network Example with Fixed Representation,[0],[0]
"(z) = sign(z1 − z2), we have RS(gS ◦ f) = RT (gT ◦ f) = 0.",3.1. Neural Network Example with Fixed Representation,[0],[0]
On S we learn f̂(x) =,3.1. Neural Network Example with Fixed Representation,[0],[0]
"[x1 + x3, x1−x3] and ĝS(z)",3.1. Neural Network Example with Fixed Representation,[0],[0]
"= sign(z1 +z2), so thatRS(ĝS ◦ f̂) = 0",3.1. Neural Network Example with Fixed Representation,[0],[0]
"but in general min
g∈G",3.1. Neural Network Example with Fixed Representation,[0],[0]
RT (g ◦ f̂),3.1. Neural Network Example with Fixed Representation,[0],[0]
> 0,3.1. Neural Network Example with Fixed Representation,[0],[0]
"since f̂ ignores x2.
",3.1. Neural Network Example with Fixed Representation,[0],[0]
"8For example, PS and PT are spherical Gaussians.",3.1. Neural Network Example with Fixed Representation,[0],[0]
"For a zeromean multivariate Gaussian distribution this is achieved by the whitening transformation x → Λ−1/2UTx, where the columns of U and entries of the diagonal matrix Λ are the eigenvectors and eigenvalues of the distribution’s covariance matrix respectively.",3.1. Neural Network Example with Fixed Representation,[0],[0]
"Consider learning ĝS ◦ f̂ on S, and then using f̂ and RS(ĝS ◦ f̂) to find F̂ ⊆ F , as in Figure 1.",4. Representation Fine-Tuned on Target Task,[0],[0]
Let h̃g◦f be a stochastic hypothesis (i.e. a distribution over H) associated with g ◦ f,4. Representation Fine-Tuned on Target Task,[0],[0]
(e.g. g ◦ f is the mode of h̃g◦f ).,4. Representation Fine-Tuned on Target Task,[0],[0]
"We propose learning T with the hypothesis class H̃G◦F̂ := {h̃g◦f : f ∈ F̂ , g ∈ G} and the prior h̃ĝS◦f̂ .",4. Representation Fine-Tuned on Target Task,[0],[0]
"Learning T from scratch we assume that we would instead use H̃G◦F := {h̃g◦f : f ∈ F, g ∈ G} and some fixed prior h̃0 ∈ H̃G◦F .",4. Representation Fine-Tuned on Target Task,[0],[0]
"Let RT (h̃) := Ex∼PT ,h∼h̃[hT (x) 6= h(x)] and compute R̂T (h̃) on the training set distribution of T .
",4. Representation Fine-Tuned on Target Task,[0],[0]
"In Theorem 3 we show that if F̂ is ‘small enough’ so that all h̃ ∈ H̃G◦F̂ have a small KL divergence from h̃ĝS◦f̂ , we may apply a PAC-Bayes bound to the generalization error of hypotheses in H̃G◦F̂ involving four terms: a function ω measuring a transferrability property, the empirical risk R̂S(ĝS ◦ f̂), the generalization error of a hypothesis in H learned from mS points, and a weak dependence on mT .",4. Representation Fine-Tuned on Target Task,[0],[0]
"The value of the theorem is that if ω(R) = O(R), R̂S(ĝS◦f̂) is a small constant, andmS mT , we improve on the PAC-Bayes bound for H̃G◦F and h̃0.9 F̂ is useful if it is also ‘large enough’ in the sense that ∃h̃gT ◦f ∈",4. Representation Fine-Tuned on Target Task,[0],[0]
H̃G◦F̂ such that RT (h̃gT ◦f ) ≤ .,4. Representation Fine-Tuned on Target Task,[0],[0]
"Here ω quantifies how large the F̂ we search on T must be in order to be ‘large enough’, in terms of RS(ĝS ◦ f̂).",4. Representation Fine-Tuned on Target Task,[0],[0]
"While in general such an F̂ and ω may not exist, we give an example in Section 4.1.
",4. Representation Fine-Tuned on Target Task,[0],[0]
Theorem 3.,4. Representation Fine-Tuned on Target Task,[0],[0]
Let ω : R → R be non-decreasing.,4. Representation Fine-Tuned on Target Task,[0],[0]
"Suppose given f̂ ∈ F and RS(ĝS ◦ f̂) estimated from S, it is possible to construct F̂ with the property ∀h̃ ∈ H̃G◦F̂ , KL(h̃||h̃ĝS◦f̂ ) ≤ ω(RS(ĝS ◦ f̂)).",4. Representation Fine-Tuned on Target Task,[0],[0]
"Then with probability at least 1 − δ over pairs of training sets for tasks S and T , ∀h̃ ∈ H̃G◦F̂ , RT (h̃) ≤ R̂T (h̃) +√
ω(R̂S(ĝS◦",4. Representation Fine-Tuned on Target Task,[0],[0]
f̂)+2 √ 2dH log(2emS/dH ),4. Representation Fine-Tuned on Target Task,[0],[0]
"+2 log(8/δ)
mS )+log 2mT /δ
2(mT−1) .
",4. Representation Fine-Tuned on Target Task,[0],[0]
Proof.,4. Representation Fine-Tuned on Target Task,[0],[0]
"With probability at least 1− δ,
RT (h̃) ≤ R̂T (h̃) + √ KL(h̃||h̃ĝS◦f̂ )+log 2mT /δ 2(mT−1)
≤",4. Representation Fine-Tuned on Target Task,[0],[0]
"R̂T (h̃) + √
ω(RS(ĝS◦f̂))+log 2mT /δ 2(mT−1) .
",4. Representation Fine-Tuned on Target Task,[0],[0]
"The first inequality holds with probability at least 1 − δ2 (Shalev-Shwartz & Ben-David, 2014).",4. Representation Fine-Tuned on Target Task,[0],[0]
The second inequality holds by assumption.,4. Representation Fine-Tuned on Target Task,[0],[0]
"Furthermore, RS(ĝS ◦ f̂) ≤",4. Representation Fine-Tuned on Target Task,[0],[0]
"R̂S(ĝS ◦ f̂) + 2 √ 2dH log(2emS/dH)+2 log(8/δ)
mS with prob-
ability at least 1 − δ2 (Mohri et al., 2012) and ω is nondecreasing.",4. Representation Fine-Tuned on Target Task,[0],[0]
"The result follows from the union bound.
",4. Representation Fine-Tuned on Target Task,[0],[0]
9Using the restricted deterministic hypothesis class G ◦ F̂,4. Representation Fine-Tuned on Target Task,[0],[0]
":= {h : ∃f ∈ F̂ , g ∈ G such that h",4. Representation Fine-Tuned on Target Task,[0],[0]
"= g ◦ f} and a VC dimensionbased bound may not improve on H , since possibly dG◦F̂ = dH .",4. Representation Fine-Tuned on Target Task,[0],[0]
We transfer and fine-tune weights in a feedforward neural network with one hidden layer to instantiate the property required by Theorem 3.,4.1. Neural Network Example with Fine-Tuning,[0],[0]
We learn a deterministic hypothesis of this type on S and obtain k estimated lowerlevel weight vectors ŵi.,4.1. Neural Network Example with Fine-Tuning,[0],[0]
"Learning T we now consider only lower-level weights near ŵi, corresponding to F̂ .",4.1. Neural Network Example with Fine-Tuning,[0],[0]
On T we learn a stochastic hypothesis formed by taking a deterministic network and adding independent sources of spherical Gaussian noise to the lower-level weights and sign-flipping noise to the upper-level weights.,4.1. Neural Network Example with Fine-Tuning,[0],[0]
"The KL divergence between two of the stochastic hypotheses is expressed using the angles between their lower-level weights10 and a quantity computable from their upper-level weights.
",4.1. Neural Network Example with Fine-Tuning,[0],[0]
We want to prove that we can construct such an F̂ to successfully learn T .,4.1. Neural Network Example with Fine-Tuning,[0],[0]
"To do this, we assume some lower-level weights wi perform well on both S and T .",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"We make F̂ ‘small enough’ by only including lower-level weights with small angles to ŵi, and ‘large enough’ by using the risk observed using ŵi on S to provide an upper bound on the angle between each pair wi and ŵi.",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"Our assumptions ensure that poor ŵi cannot be ‘hidden’ from the risk on S, either through low PS density in the region of disagreement between wi and ŵi, or through low magnitude higher-level weights.",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"Hence we know that searching F̂ will include wi.
",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"Let X = Rn and Z = Rk, where k is odd.",4.1. Neural Network Example with Fine-Tuning,[0],[0]
Let F be the function class such that f(x) =,4.1. Neural Network Example with Fine-Tuning,[0],[0]
"[sign(w1 · x), . . .",4.1. Neural Network Example with Fine-Tuning,[0],[0]
", sign(wk · x)], where wi ∈ Rn for 1 ≤",4.1. Neural Network Example with Fine-Tuning,[0],[0]
i ≤ k.,4.1. Neural Network Example with Fine-Tuning,[0],[0]
Let G be the function class such that g(z),4.1. Neural Network Example with Fine-Tuning,[0],[0]
"= sign(v · z), where v ∈ {−1, 1}k.",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"Let Bv be a distribution on {−1, 1}k such that for
v′ ∼",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"Bv , Pr(v′) = k∏ j=1 p1(v ′",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"j=vj)(1 − p)1(v ′ j=−vj), where p ∈",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"[0.5, 1].",4.1. Neural Network Example with Fine-Tuning,[0],[0]
Let h̃g◦f := g′ ◦f ′,4.1. Neural Network Example with Fine-Tuning,[0],[0]
"such that v′, w′1, . . .",4.1. Neural Network Example with Fine-Tuning,[0],[0]
", w′k",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"∼
",4.1. Neural Network Example with Fine-Tuning,[0],[0]
Bv k∏ i=1,4.1. Neural Network Example with Fine-Tuning,[0],[0]
"N (wi, σ2I).",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"Suppose ∃f ∈ F, gS , gT ∈",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"G such that max[RS(gS ◦ f), RT (h̃gT ◦f )] ≤ .",4.1. Neural Network Example with Fine-Tuning,[0],[0]
Let f̂(x) :=,4.1. Neural Network Example with Fine-Tuning,[0],[0]
"[sign(ŵ1 · x), . . .",4.1. Neural Network Example with Fine-Tuning,[0],[0]
", sign(ŵk · x)], θ(wi, ŵi) be the angle between wi and ŵi, and assume ∀i, ||ŵi|| = 1.",4.1. Neural Network Example with Fine-Tuning,[0],[0]
Define M as in Section 3.1.,4.1. Neural Network Example with Fine-Tuning,[0],[0]
"Let PS have the rotation invariance property ∀x, x′ such that ||Mx|| = ||Mx′||, PS(x) ≤ cPS(x′) for some c ≥ 1.
",4.1. Neural Network Example with Fine-Tuning,[0],[0]
Theorem 4.,4.1. Neural Network Example with Fine-Tuning,[0],[0]
"Given f̂ and RS(ĝS ◦ f̂) estimated from S, let θmax := π √ 2(k",4.1. Neural Network Example with Fine-Tuning,[0],[0]
− 1)c(RS(ĝS ◦ f̂) + ) and F̂ := {f ∈,4.1. Neural Network Example with Fine-Tuning,[0],[0]
"F : ∀i, ||wi|| = 1 ∧ |θ(wi, ŵi)| ≤ θmax}.",4.1. Neural Network Example with Fine-Tuning,[0],[0]
Let ω(R) := kσ2,4.1. Neural Network Example with Fine-Tuning,[0],[0]
[1−cos θmax]+k[2p−1+(1−p) k] log2 p 1−p .,4.1. Neural Network Example with Fine-Tuning,[0],[0]
"Then ∃h̃gT ◦f ∈ H̃G◦F̂ such that RT (h̃gT ◦f ) ≤ and ∀h̃ ∈ H̃G◦F̂ , KL(h̃||h̃ĝS◦f̂ ) ≤ ω(RS(ĝS ◦ f̂)).
",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"10Assuming that the lower-level weight vectors are of fixed magnitude, which is no loss of model expressiveness since we use the sign activation function at the hidden layer.",4.1. Neural Network Example with Fine-Tuning,[0],[0]
"We show the utility of the risk bounds, and present a novel technique and experiments motivated by our theorems.",5. Applications,[0],[0]
"The results described yield tighter bounds on risk when transferring representations from S, compared to learning T from scratch.",5.1. Using the Risk Bounds,[0],[0]
"Examples are shown in Figure 3.11
We set δ = 0.05.",5.1. Using the Risk Bounds,[0],[0]
"For the top part, we use the example from Section 3.1 and set n = 10, k = 5.",5.1. Using the Risk Bounds,[0],[0]
"Learning T from scratch with H , we use the bound from Mohri et al. (2012) used previously.",5.1. Using the Risk Bounds,[0],[0]
"The VC dimension of a network of |E| edges using the sign activation is O(|E| log |E|) (Shalev-Shwartz & Ben-David, 2014), where in our case |E| = nk+k.",5.1. Using the Risk Bounds,[0],[0]
We use dH = |E| log |E| in the chart.,5.1. Using the Risk Bounds,[0],[0]
"Transferring a representation from S to T without fine-tuning, we consider the limit → 0, R̂S(ĝS ◦ f̂) → 0, mS → ∞, and hence ω(·) → 0 by Theorem 2.",5.1. Using the Risk Bounds,[0],[0]
"Furthermore, dG ≤",5.1. Using the Risk Bounds,[0],[0]
k,5.1. Using the Risk Bounds,[0],[0]
"since G is finite and hence dG ≤ log2 |G| (Shalev-Shwartz & Ben-David, 2014).",5.1. Using the Risk Bounds,[0],[0]
"We use the bound from Theorem 1.
",5.1. Using the Risk Bounds,[0],[0]
"For the bottom part, we use the example from Section 4.1 and set σ2 = 110 , k = 499, p = 2 3 .",5.1. Using the Risk Bounds,[0],[0]
Learning T from scratch we use the stochastic hypothesis class {h̃g◦f :,5.1. Using the Risk Bounds,[0],[0]
"f ∈ F such that ∀i||wi|| = 1, g ∈ G} and a prior h̃0 where ∀i wi = 0 and v ∈ {−1, 1}k is arbitrary.12 Hence we have the bound KL(h̃||h̃0) ≤ 10k + k3 , which becomes tight for large k.",5.1. Using the Risk Bounds,[0],[0]
"We apply the PAC-Bayes bound (ShalevShwartz & Ben-David, 2014) used previously.",5.1. Using the Risk Bounds,[0],[0]
"Transferring a representation from S and fine-tuning on T , we consider the limit → 0, R̂S(ĝS ◦ f̂) → 0, mS → ∞. We have KL(h̃||h̃ĝS◦f̂ ) ≤",5.1. Using the Risk Bounds,[0],[0]
k 3 by Theorem 4.,5.1. Using the Risk Bounds,[0],[0]
We use the bound from Theorem 3.,5.1. Using the Risk Bounds,[0],[0]
"We relax the hard constraint on F̂ from Section 4.1 by using a modified loss function, which we find performs better in practice.",5.2. Fine-Tuning through Regularization,[0],[0]
Let yi and ŷi be the label and prediction respectively for the ith training point.,5.2. Fine-Tuning through Regularization,[0],[0]
"In a fully-connected feedforward neural network with l layers of weights, let W (j) be the jth weight matrix, Ŵ (j) be its estimate from S (excluding weights for bias units in both cases), and ||·||2 be the entry-wise 2 norm.",5.2. Fine-Tuning through Regularization,[0],[0]
"A typical loss function (1) used for training is composed of the sum of training set log loss and L2 regularization on the weights.
",5.2. Fine-Tuning through Regularization,[0],[0]
"11Note that VC dimension risk bounds are known for being rather loose, while PAC-Bayesian bounds are tighter and hence yield non-trivial results in higher dimensions with fewer samples.
",5.2. Fine-Tuning through Regularization,[0],[0]
"12This class is as expressive as H̃G◦F but by setting ||wi|| = 1 the KL divergence of all hypotheses from any prior is bounded, allowing a fair comparison to H̃G◦F̂ .",5.2. Fine-Tuning through Regularization,[0],[0]
"The choice of h̃0 minimizes worst case KL divergence to a hypothesis in the class.
",5.2. Fine-Tuning through Regularization,[0],[0]
"m∑
i=1",5.2. Fine-Tuning through Regularization,[0],[0]
[−yi log ŷi,5.2. Fine-Tuning through Regularization,[0],[0]
− (1− yi) log(1− ŷi)],5.2. Fine-Tuning through Regularization,[0],[0]
"+ λ 2
l∑
j=1 (||W (j)||22)
(1)
We replace the regularization penalty with (2).13
l∑ j=1",5.2. Fine-Tuning through Regularization,[0],[0]
"[ λ1(j) 2 ||W (j) − Ŵ (j)||22 + λ2(j) 2 ||W (j)||22] (2) This penalizes estimates of W far from the representation learned on S. Since we expect the tasks to share a lowlevel representation (e.g. edge detectors for vision, word embeddings for text) but be distinct at higher levels (e.g. image components for vision, topics for text), we set λ1(·) to be a decreasing function, while λ2(·) controls standard L2 regularization.",5.2. Fine-Tuning through Regularization,[0],[0]
"The technique is novel to our knowledge, although other approaches to transferring regularization between tasks exist (Evgeniou & Pontil, 2004; Raina et al., 2006; Argyriou et al., 2008; Ghifary et al., 2014).",5.2. Fine-Tuning through Regularization,[0],[0]
We experiment on basic image and text classification tasks.14,5.3. Experiments,[0],[0]
We show that learning algorithms motivated by our theoretical results can help to overcome a scarcity of labeled target task data.,5.3. Experiments,[0],[0]
"Note that we do not replicate the conditions specified in our theorems, nor do we attempt extensive tuning to achieve state-of-the-art performance.
",5.3. Experiments,[0],[0]
"13Basing our approach on (1), we follow the convention that weights connected to bias units are excluded from the regularization penalty.",5.3. Experiments,[0],[0]
"However, the inclusion of these weights in the ||W (j) − Ŵ (j)|| term of (2) is a plausible variant.
",5.3. Experiments,[0],[0]
"14The MNIST and 20 Newgroups datasets are available at http://yann.lecun.com/exdb/mnist and http:// qwone.com/˜jason/20Newsgroups respectively.
",5.3. Experiments,[0],[0]
"We randomly partition label classes into sets S+ and S−, where |S+| =",5.3. Experiments,[0],[0]
"|S−|.15 We construct T+ by randomly picking from S+ up to γ :=
|S+∩T+| |S+| , then randomly picking
from S− such that |T+| = |T−|.",5.3. Experiments,[0],[0]
"We let S be the task of distinguishing between S+ and S− and T be that of distinguishing T+ and T−. Constructing S+ and T+ as disjunctions of classes means that the class labels are a perfect representation shared between S and T .
",5.3. Experiments,[0],[0]
"We compare the accuracy on T of four options:
• learn T from scratch (BASE)
• transfer f̂ from S, fine-tune f and train g on T using (2) (FINE-TUNE f̂ )
• transfer f̂ from S and fix, train g on T (FIX f̂ )16
• transfer ĝS ◦ f̂ from S and fix (FIX ĝS ◦ f̂ ).17
We use λ1(1) = λ2(2) = λ",5.3. Experiments,[0],[0]
":= 1,18 λ1(2) = λ2(1) = 0, mT = 500 and the sigmoid activation function.",5.3. Experiments,[0],[0]
"For MNIST we use raw pixel intensities, a 784 × 50 × 1 network andmS = 50000.",5.3. Experiments,[0],[0]
"For NEWSGROUPS we use TF-IDF weighted counts of most frequent words, a 2000 × 50 × 1 network and mS = 15000.",5.3. Experiments,[0],[0]
"We use conjugate gradient optimization with 200 iterations.
",5.3. Experiments,[0],[0]
"The results are shown in Table 1.19 When the tasks are nonidentical, FINE-TUNE f̂ is mostly the strongest but performs better on MNIST.",5.3. Experiments,[0],[0]
FIX f̂ outperforms BASE when γ ≥ 0.8 and hence the tasks are similar.,5.3. Experiments,[0],[0]
"While FIX f̂ outperforms FIX ĝS ◦ f̂ when the tasks are non-identical on MNIST, on NEWSGROUPS there is no evidence of benefit.",5.3. Experiments,[0],[0]
"When the tasks are identical, FIX ĝS ◦ f̂ is the strongest.
",5.3. Experiments,[0],[0]
"It appears that learning an MNIST digit requires a dense weight vector and so Ŵ (1) tends to encode single digits, which helps transferrability.",5.3. Experiments,[0],[0]
"However, it appears that since we may learn a newsgroup with a sparse weight vector, Ŵ (1) tends to encode disjunctions of newsgroups which somewhat reduces transferrability.",5.3. Experiments,[0],[0]
"When transferring representations does work, fine-tuning using the regularization penalty proposed in (2) improves performance.
",5.3. Experiments,[0],[0]
15For MNIST there are 10 label classes and for 20 Newgroups there are 20.,5.3. Experiments,[0],[0]
In both cases the classes are approximately balanced.,5.3. Experiments,[0],[0]
"Note that we ignore the hierarchical structure of the 20 Newsgroups classes, which likely contributes to the lower accuracies reported for all methods for this dataset relative to MNIST.
",5.3. Experiments,[0],[0]
16i.e.,5.3. Experiments,[0],[0]
logistic regression with L2 regularization and f̂ fixed.,5.3. Experiments,[0],[0]
17Used to isolate the benefit of transferring f̂ rather than ĝS ◦ f̂ .,5.3. Experiments,[0],[0]
"18We explored tuning λ to lift the performance of BASE on MNIST, but found that the results did not materially improve.",5.3. Experiments,[0],[0]
"Potentially λ1(j) and λ2(j) in (2) could be tuned with cross validation on the target task.
",5.3. Experiments,[0],[0]
"19For γ = 1, hS = hT .",5.3. Experiments,[0],[0]
"We do not consider γ < 0.5, since that is equivalent to 1−γ with the definitions of T+ and T− swapped.",5.3. Experiments,[0],[0]
We developed sufficient conditions for the successful transfer of representations both with and without fine-tuning.,6. Conclusion,[0],[0]
This is a step towards a principled explanation of the empirical success achieved by such techniques.,6. Conclusion,[0],[0]
A promising direction for future work is generalizing the neural network architectures considered (e.g. using multiple hidden layers) and relaxing the distributional assumptions required.,6. Conclusion,[0],[0]
"Furthermore, in the fine-tuning case it may be possible to upper bound the target task generalization error of hypotheses in G ◦ F̂",6. Conclusion,[0],[0]
":= {h : ∃f ∈ F̂ , g ∈ G such that h",6. Conclusion,[0],[0]
"= g ◦ f} using another measure such as the Rademacher complexity of G ◦ F̂ , eliminating the need for stochastic hypotheses.
",6. Conclusion,[0],[0]
"We proposed a novel form of regularization for neural network training motivated by our theoretical results, which penalizes divergence from source task weights and is stricter for lower-level weights.",6. Conclusion,[0],[0]
We validated this technique through applications to image and text classification.,6. Conclusion,[0],[0]
Future directions include experiments on more challenging tasks using deeper and more tailored network architectures (e.g. convolutional neural networks).,6. Conclusion,[0],[0]
We provide complete proofs of Theorems 2 and 4.,7. Additional Proofs,[0],[0]
"For brevity, we drop the explicit dependence of f , f̂ , hS and hT on x in our notation where the meaning is clear.",7. Additional Proofs,[0],[0]
Proof.,7.1. Proof of Theorem 2,[0],[0]
Let gS(z),7.1. Proof of Theorem 2,[0],[0]
":= sign(vS · z), gT (z) :",7.1. Proof of Theorem 2,[0],[0]
"= sign(vT · z), ĝS(z) := sign(v̂S · z), ĝT (z) := sign(d ∗ v̂S · z), where d := vS ∗vT ∈ {−1, 1}k and ∗ is the elementwise product.",7.1. Proof of Theorem 2,[0],[0]
"It is sufficient to showRT (ĝT ◦f̂) ≤ cRS(ĝS◦f̂)+ (1+c).
",7.1. Proof of Theorem 2,[0],[0]
"RT (ĝT ◦ f̂)
=",7.1. Proof of Theorem 2,[0],[0]
"Prx∼PT (hT d ∗ v̂S · f̂ ≤ 0)
≤",7.1. Proof of Theorem 2,[0],[0]
"Prx∼PT (hT d ∗ vS · f ≤ 0, d ∗ vS · fd ∗ v̂S · f̂ ≥ 0)",7.1. Proof of Theorem 2,[0],[0]
"+ Prx∼PT (hT d ∗ vS · f ≥ 0, d ∗ vS · fd ∗ v̂S · f̂ ≤ 0)
≤",7.1. Proof of Theorem 2,[0],[0]
Prx∼PT (hT d ∗ vS · f ≤,7.1. Proof of Theorem 2,[0],[0]
"0)+ Prx∼PT (d ∗ vS · fd ∗ v̂S · f̂ ≤ 0)
≤",7.1. Proof of Theorem 2,[0],[0]
"+ Prx∼PT (d ∗ vS · fd ∗ v̂S · f̂ ≤ 0)
≤ + cPrx∼PS (vS · fv̂S · f̂ ≤ 0)
≤",7.1. Proof of Theorem 2,[0],[0]
"+ c[Prx∼PS (hS v̂S · f̂ ≤ 0, hSvS · f ≥ 0)+ Prx∼PS (hS v̂S · f̂ ≥ 0, hSvS · f ≤ 0)]
≤ + c[Prx∼PS (hS v̂S · f̂ ≤ 0)",7.1. Proof of Theorem 2,[0],[0]
"+Prx∼PS (hSvS · f ≤ 0)]
≤ cRS(ĝS ◦ f̂) + (1 + c).
",7.1. Proof of Theorem 2,[0],[0]
The third and final inequalities are due to the shared representation assumption in the problem statement.,7.1. Proof of Theorem 2,[0],[0]
The fourth inequality holds by Lemma 1.,7.1. Proof of Theorem 2,[0],[0]
"The remaining lines apply simple rules of probability.
",7.1. Proof of Theorem 2,[0],[0]
Lemma 1.,7.1. Proof of Theorem 2,[0],[0]
"Suppose ∀x, x′ such that ||Mx|| = ||Mx′||, PT (x) ≤ cPS(x′).",7.1. Proof of Theorem 2,[0],[0]
"Let f, f̂ ∈ F , v, v̂, d ∈ {−1, 1}k.",7.1. Proof of Theorem 2,[0],[0]
"Then Prx∼PT (d∗v ·fd∗ v̂ · f̂ ≤ 0) ≤ cPrx∼PS (v · fv̂ · f̂ ≤ 0).
",7.1. Proof of Theorem 2,[0],[0]
Proof.,7.1. Proof of Theorem 2,[0],[0]
"Suppose there is an invertible map Rn → Rn yielding x′ on input x, such that ∀x, ||Mx|| = ||Mx′|| and d ∗ v · f(x)d ∗ v̂ · f̂(x) = v · f(x′)v̂ · f̂(x′).",7.1. Proof of Theorem 2,[0],[0]
Then the result follows since PT (x) ≤ cPS(x′) by assumption.,7.1. Proof of Theorem 2,[0],[0]
"Furthermore, if M is an orthogonal matrix, ||x|| = ||x′||.
",7.1. Proof of Theorem 2,[0],[0]
"Such a map is x′ := (MTM)−1MT d̃ ∗ (Mx), where d̃ :=",7.1. Proof of Theorem 2,[0],[0]
"[d1, d1, . . .",7.1. Proof of Theorem 2,[0],[0]
", dk, dk].",7.1. Proof of Theorem 2,[0],[0]
"We have ∀i, wi · x′ = diwi · x and (αiŵi−βiwi)·x′ = di(αiŵi−βiwi)·x, and hence ŵi ·x′ = diŵi · x for αi, βi 6= 0.",7.1. Proof of Theorem 2,[0],[0]
"Therefore:
d ∗ v · f(x)d ∗ v̂ · f̂(x)
= v · d ∗ f(x)v̂ · d ∗ f̂(x)
= v · f(x′)v̂ · d ∗ f̂(x)
= v · f(x′)v̂ · f̂(x′).
",7.1. Proof of Theorem 2,[0],[0]
The first equality is a property of the elementwise and dot products.,7.1. Proof of Theorem 2,[0],[0]
"For the second equality, a(wi·x′) = a(diwi·x) = dia(wi · x) since a is an odd function.",7.1. Proof of Theorem 2,[0],[0]
"Similarly, for the third equality a(ŵi · x′) = a(diŵi · x) = dia(ŵi · x).",7.1. Proof of Theorem 2,[0],[0]
Proof of ∃h̃gT ◦f ∈,7.2. Proof of Theorem 4,[0],[0]
H̃G◦F̂ such that RT (h̃gT ◦f ) ≤ .,7.2. Proof of Theorem 4,[0],[0]
Recall that wi are the weight vectors for f and ŵi are those for f̂ .,7.2. Proof of Theorem 4,[0],[0]
"Observe that for any wi such that wi · ŵi < 0, we have −wi · ŵi > 0 and −visign(−wi · x) =",7.2. Proof of Theorem 4,[0],[0]
visign(wi · x).,7.2. Proof of Theorem 4,[0],[0]
"Combining this with the assumption
min f∈F,gS ,gT∈G max[RS(gS ◦ f), RT (gT ◦",7.2. Proof of Theorem 4,[0],[0]
"f)] ≤ , we conclude ∃f ∈ F, gS , gT ∈ G such that ∀i, wi · ŵi ≥ 0 and max[RS(gS ◦ f), RT (h̃gT ◦f )] ≤ .
",7.2. Proof of Theorem 4,[0],[0]
Let gS(z),7.2. Proof of Theorem 4,[0],[0]
:= sign(vS · z) and ĝS(z) := sign(v̂S · z).,7.2. Proof of Theorem 4,[0],[0]
Let P be a rotation invariant distribution for c = 1.,7.2. Proof of Theorem 4,[0],[0]
"To prove h̃gT ◦f ∈ H̃G◦F̂ , by the definition of H̃G◦F̂ it is sufficient to show ∀i, |θ(wi, ŵi)| ≤ π",7.2. Proof of Theorem 4,[0],[0]
√ 2(k,7.2. Proof of Theorem 4,[0],[0]
"− 1)c(RS(ĝS ◦ f̂) + ).
max i |θ(wi,ŵi)|
π √ 2(k−1)
≤ Prx∼P",7.2. Proof of Theorem 4,[0],[0]
"(vS · fvS · f̂ ≤ 0)
≤ Prx∼P",7.2. Proof of Theorem 4,[0],[0]
"(vS · fv̂S · f̂ ≤ 0)
≤ cPrx∼PS (vS · fv̂S · f̂ ≤ 0)
≤ c[Prx∼PS (hSvS · f ≤ 0, hS v̂S · f̂ ≥ 0)+ Prx∼PS (hSvS · f ≥ 0, hS v̂S · f̂ ≤ 0)]
≤ c[Prx∼PS (hSvS · f ≤ 0) + Prx∼PS (hS v̂S · f̂ ≤ 0)]
≤ c",7.2. Proof of Theorem 4,[0],[0]
"[ +RS(ĝS ◦ f̂)].
",7.2. Proof of Theorem 4,[0],[0]
The first inequality holds by Lemma 2.,7.2. Proof of Theorem 4,[0],[0]
"The second inequality holds by Lemma 3, using the fact ∀i, wi · ŵi ≥ 0.",7.2. Proof of Theorem 4,[0],[0]
The third inequality uses the rotation invariance of PS .,7.2. Proof of Theorem 4,[0],[0]
The following two lines use basic laws of probability.,7.2. Proof of Theorem 4,[0],[0]
"The final inequality uses the assumption RS(gS ◦ f) ≤ .
",7.2. Proof of Theorem 4,[0],[0]
"Proof of ∀h̃ ∈ H̃G◦F̂ ,KL(h̃||h̃ĝS◦f̂ ) ≤ ω(RS(ĝS ◦ f̂)).",7.2. Proof of Theorem 4,[0],[0]
"For any h̃g◦f ∈ H̃G◦F̂ , KL(h̃g◦f ||h̃ĝS◦f̂ ) = k∑ i=1",7.2. Proof of Theorem 4,[0],[0]
"[KL(N (wi, σ2I)||N (ŵi, σ2I))]",7.2. Proof of Theorem 4,[0],[0]
"+KL(Bv||Bv̂S ).
",7.2. Proof of Theorem 4,[0],[0]
The KL divergence of a product distribution is the sum of the KL divergences of its component distributions.,7.2. Proof of Theorem 4,[0],[0]
We upper bound both terms and apply the definition of ω.,7.2. Proof of Theorem 4,[0],[0]
k∑ i=1,7.2. Proof of Theorem 4,[0],[0]
"KL(N (wi, σ2I)||N (ŵi, σ2I))",7.2. Proof of Theorem 4,[0],[0]
= 12σ2 k∑ i=1,7.2. Proof of Theorem 4,[0],[0]
||wi,7.2. Proof of Theorem 4,[0],[0]
− ŵi||2 = 12σ2 k∑ i=1,7.2. Proof of Theorem 4,[0],[0]
"(||wi||2 + ||ŵi||2 − 2||wi||||ŵi|| cos |θ(wi, ŵi)|)",7.2. Proof of Theorem 4,[0],[0]
= 1σ2 k∑ i=1,7.2. Proof of Theorem 4,[0],[0]
"(1− cos |θ(wi, ŵi)|)
≤ kσ2",7.2. Proof of Theorem 4,[0],[0]
[1− cos(π √ 2(k,7.2. Proof of Theorem 4,[0],[0]
"− 1)c(RS(ĝS ◦ f̂) + ))].
",7.2. Proof of Theorem 4,[0],[0]
The first equality uses the KL divergence of Gaussian distributions.,7.2. Proof of Theorem 4,[0],[0]
The second equality uses the law of cosines.,7.2. Proof of Theorem 4,[0],[0]
"The third equality is because ∀i, ||wi|| = ||ŵi|| = 1 by construction.",7.2. Proof of Theorem 4,[0],[0]
The inequality follows by the definition of F̂ and the fact that 1− cos |θ| is non-decreasing for |θ| ∈,7.2. Proof of Theorem 4,[0],[0]
"[0, π].
KL(Bv||Bv̂S )",7.2. Proof of Theorem 4,[0],[0]
≤ k∑ i=1,7.2. Proof of Theorem 4,[0],[0]
"( k i ) pi(1− p)k−i log2 pi(1−p)k−i (1−p)ipk−i
= k[2p− 1 + (",7.2. Proof of Theorem 4,[0],[0]
"1− p)k] log2 p 1−p .
",7.2. Proof of Theorem 4,[0],[0]
The first inequality uses the definition of Bv to express KL(Bv||Bv̂S ).,7.2. Proof of Theorem 4,[0],[0]
"The equality is a simplification.
",7.2. Proof of Theorem 4,[0],[0]
Lemma 2.,7.2. Proof of Theorem 4,[0],[0]
"Suppose k is odd, v ∈ {−1, 1}k, f, f̂ ∈ F such that ∀i, wi · ŵi ≥ 0 and P is rotation invariant with c = 1.",7.2. Proof of Theorem 4,[0],[0]
"Then max i |θ(wi,ŵi)|
π √ 2(k−1) ≤ Prx∼P (v · fv · f̂ ≤ 0).
",7.2. Proof of Theorem 4,[0],[0]
Proof.,7.2. Proof of Theorem 4,[0],[0]
"Let v−j := [v1, . . .",7.2. Proof of Theorem 4,[0],[0]
", vj−1, vj+1, . . .",7.2. Proof of Theorem 4,[0],[0]
", vk] and define f−j and f̂−j similarly.",7.2. Proof of Theorem 4,[0],[0]
"Let Pr(·) := Prx∼P (·).
",7.2. Proof of Theorem 4,[0],[0]
"Pr(v · fv · f̂ ≤ 0)
",7.2. Proof of Theorem 4,[0],[0]
"≥ Pr(v · fv · f̂ < 0)
≥ Pr(v−j ·",7.2. Proof of Theorem 4,[0],[0]
"f−j = 0)Pr(v · fv · f̂ < 0|v−j · f−j = 0)
",7.2. Proof of Theorem 4,[0],[0]
= Pr(v−j · f−j = 0) Pr(vjfjv−j · f̂−j + fj,7.2. Proof of Theorem 4,[0],[0]
"f̂j < 0|v−j · f−j = 0)
= Pr(v−j · f−j = 0)",7.2. Proof of Theorem 4,[0],[0]
"[Pr(vjfjv−j · f̂−j < −1, fj",7.2. Proof of Theorem 4,[0],[0]
"f̂j = 1|v−j · f−j = 0)+ Pr(vjfjv−j · f̂−j < 1, fj f̂j = −1|v−j · f−j = 0)]
≥ Pr(v−j · f−j = 0)",7.2. Proof of Theorem 4,[0],[0]
"[Pr(vjfjv−j · f̂−j < −1, fj",7.2. Proof of Theorem 4,[0],[0]
"f̂j = −1|v−j · f−j = 0)+ Pr(vjfjv−j · f̂−j < 1, fj f̂j = −1|v−j · f−j = 0)]
= Pr(v−j · f−j = 0)",7.2. Proof of Theorem 4,[0],[0]
"[Pr(vjfjv−j · f̂−j < −1, fj",7.2. Proof of Theorem 4,[0],[0]
"f̂j = −1|v−j · f−j = 0)+ Pr(vjfjv−j · f̂−j > −1, fj f̂j = −1|v−j · f−j = 0)]
= Pr(v−j · f−j = 0)Pr(fj f̂j = −1|v−j · f−j = 0)
= Pr(v−j · f−j = 0)Pr(fj f̂j = −1) = (k−1 k−1 2 ) ( 12 ) k−1 |θ(wj ,ŵj)| π
≥ 2 k−1√
2(k−1) ( 12 ) k−1 |θ(wj ,ŵj)| π
≥ max i |θ(wi,ŵi)|
π √ 2(k−1) .
",7.2. Proof of Theorem 4,[0],[0]
The third inequality follows since P is rotation invariant and wj · ŵj ≥ 0.,7.2. Proof of Theorem 4,[0],[0]
The third and fifth equalities use rotation invariance.,7.2. Proof of Theorem 4,[0],[0]
The final equality uses rotation invariance and the fact that k is odd.,7.2. Proof of Theorem 4,[0],[0]
The fourth inequality is a standard lower bound for the central binomial coefficient.,7.2. Proof of Theorem 4,[0],[0]
"The other lines use basic simplifications and laws of probability.
",7.2. Proof of Theorem 4,[0],[0]
Lemma 3.,7.2. Proof of Theorem 4,[0],[0]
"Suppose k is odd, v, v̂ ∈ {−1, 1}k, f, f̂ ∈ F such that ∀i, wi · ŵi ≥ 0",7.2. Proof of Theorem 4,[0],[0]
and P is rotation invariant with c = 1.,7.2. Proof of Theorem 4,[0],[0]
Then Prx∼P,7.2. Proof of Theorem 4,[0],[0]
(v · fv · f̂ ≤ 0) ≤ Prx∼P,7.2. Proof of Theorem 4,[0],[0]
(v · fv̂ · f̂ ≤ 0).,7.2. Proof of Theorem 4,[0],[0]
Proof.,7.2. Proof of Theorem 4,[0],[0]
Let Pr(·) := Prx∼P (·) and E[·] := Ex∼P,7.2. Proof of Theorem 4,[0],[0]
[·].,7.2. Proof of Theorem 4,[0],[0]
Let Pr(f̃) := Prx∼P,7.2. Proof of Theorem 4,[0],[0]
"([f1(x)f̂1(x), . . .",7.2. Proof of Theorem 4,[0],[0]
", fk(x)f̂k(x)]",7.2. Proof of Theorem 4,[0],[0]
= f̃).,7.2. Proof of Theorem 4,[0],[0]
Let d := v̂ ∗ v and ∆(x) :,7.2. Proof of Theorem 4,[0],[0]
= 1(v · f(x)v̂ · f̂(x) ≤ 0),7.2. Proof of Theorem 4,[0],[0]
− 1(v · f(x)v · f̂(x) ≤ 0).,7.2. Proof of Theorem 4,[0],[0]
"Assume v̂ 6= v (if v̂ = v then
the lemma clearly holds).",7.2. Proof of Theorem 4,[0],[0]
Let a(f̃) := k∑ i=1,7.2. Proof of Theorem 4,[0],[0]
1(f̃i = 1) and let l :=,7.2. Proof of Theorem 4,[0],[0]
min i:di=−1 i.,7.2. Proof of Theorem 4,[0],[0]
Let,7.2. Proof of Theorem 4,[0],[0]
"F̃ := {f̃ ∈ {−1, 1}k :",7.2. Proof of Theorem 4,[0],[0]
"a(f̃) > a(d ∗ f̃) ∨ (a(f̃) = a(d ∗ f̃) ∧ f̃l = 1)}.
",7.2. Proof of Theorem 4,[0],[0]
Let Φ(a) := 1 2k−1 bk/2c∑ b=0 b∑ j=da/2+b/2−k/4e ( a j )( k−a b−j ) .,7.2. Proof of Theorem 4,[0],[0]
"The
term b counts coordinates where vif̂i = sign(v · f), while j counts those where vifi = sign(v · f) and fi = f̂i.
Pr(v · fv̂ · f̂ ≤ 0)− Pr(v · fv · f̂ ≤ 0)
= E[1(v · fv̂ · f̂ ≤ 0)]− E[1(v · fv · f̂ ≤ 0)]
= E[∆]",7.2. Proof of Theorem 4,[0],[0]
= ∑̃ f∈F̃,7.2. Proof of Theorem 4,[0],[0]
Pr(f̃)E[∆|f̃ ] + Pr(d ∗,7.2. Proof of Theorem 4,[0],[0]
"f̃)E[∆|d ∗ f̃ ]
= ∑̃ f∈F̃",7.2. Proof of Theorem 4,[0],[0]
"[Pr(f̃)− Pr(d ∗ f̃)]E[∆|f̃ ]
= ∑̃ f∈F̃",7.2. Proof of Theorem 4,[0],[0]
"[Pr(f̃)− Pr(d ∗ f̃)]
",7.2. Proof of Theorem 4,[0],[0]
[Pr(v · fv · f̂ ≤ 0|d ∗ f̃)− Pr(v · fv · f̂ ≤ 0|f̃)],7.2. Proof of Theorem 4,[0],[0]
= ∑̃ f∈F̃,7.2. Proof of Theorem 4,[0],[0]
"[Pr(f̃)− Pr(d ∗ f̃)][Φ(a(d ∗ f̃))− Φ(a(f̃))]
≥ 0.
",7.2. Proof of Theorem 4,[0],[0]
The second equality uses linearity of expectation.,7.2. Proof of Theorem 4,[0],[0]
"The third equality uses the law of total expectation and the definition of F̃ .
",7.2. Proof of Theorem 4,[0],[0]
"The fourth equality holds since E[∆|d ∗ f̃ ] = ∑ f∈{−1,1}k Pr(f |d ∗",7.2. Proof of Theorem 4,[0],[0]
"f̃)E[∆|d ∗ f̃ , f ]
=",7.2. Proof of Theorem 4,[0],[0]
"− ∑
f∈{−1,1}k Pr(f |d ∗ f̃)E[∆|f̃ , f ]
= − ∑
f∈{−1,1}k Pr(f |f̃)E[∆|f̃ , f ]",7.2. Proof of Theorem 4,[0],[0]
=,7.2. Proof of Theorem 4,[0],[0]
"−E[∆|f̃ ] due to the
rotation invariance of P .
",7.2. Proof of Theorem 4,[0],[0]
"The fifth equality holds by expanding ∆, linearity of expectation, and a similar argument to the previous equality to show Pr(v · fv̂ · f̂ ≤ 0|f̃) = Pr(v · fv · f̂ ≤ 0|d ∗ f̃).
",7.2. Proof of Theorem 4,[0],[0]
"The sixth equality holds by the rotation invariance of P and the fact that k is odd.
",7.2. Proof of Theorem 4,[0],[0]
"For the final inequality, the right hand term is non-negative since a(f̃) ≥ a(d ∗ f̃) and Φ is non-increasing.",7.2. Proof of Theorem 4,[0],[0]
"The left hand term is also non-negative due to the rotation invariance assumption and the fact that ∀i, wi · ŵi ≥ 0.",7.2. Proof of Theorem 4,[0],[0]
"Daniel McNamara was a visitor at Carnegie Mellon University during the period of this research, supported by a Fulbright Postgraduate Scholarship.
",Acknowledgements,[0],[0]
"This work was supported in part by NSF grants CCF1422910, CCF-1535967, IIS-1618714, and a Microsoft Research Faculty Fellowship.
",Acknowledgements,[0],[0]
We thank the anonymous reviewers for their useful comments.,Acknowledgements,[0],[0]
A popular machine learning strategy is the transfer of a representation (i.e. a feature extraction function) learned on a source task to a target task.,abstractText,[0],[0]
Examples include the re-use of neural network weights or word embeddings.,abstractText,[0],[0]
We develop sufficient conditions for the success of this approach.,abstractText,[0],[0]
"If the representation learned from the source task is fixed, we identify conditions on how the tasks relate to obtain an upper bound on target task risk via a VC dimension-based argument.",abstractText,[0],[0]
"We then consider using the representation from the source task to construct a prior, which is fine-tuned using target task data.",abstractText,[0],[0]
We give a PAC-Bayes target task risk bound in this setting under suitable conditions.,abstractText,[0],[0]
We show examples of our bounds using feedforward neural networks.,abstractText,[0],[0]
"Our results motivate a practical approach to weight transfer, which we validate with experiments.",abstractText,[0],[0]
Risk Bounds for Transferring Representations With and Without Fine-Tuning,title,[0],[0]
"1Massachusetts Host-Microbiome Center, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, USA. Correspondence to: TE Gibson <tgibson@mit.edu>, GK Gerber <ggerber@bwh.harvard.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).",text,[0],[0]
"The human microbiome constitutes all the microorganisms that live in and on our bodies (The Human Microbiome Project Consortium, 2012).",1. Introduction,[0],[0]
"There is strong evidence that the microbiome plays an important role in a variety of human diseases, including: infections, arthritis, food allergy, cancer, inflammatory bowel disease, neurological diseases, and obesity/diabetes (Hall et al., 2017; Youngster et al., 2014; Stefka et al., 2014; Schwabe & Jobin, 2013; Kostic et al., 2015; Wlodarska et al., 2015).",1. Introduction,[0],[0]
"Given the microbiome’s profound role, there is now a concerted effort to design bacteriotherapies, which are cocktails of multiple bacteria working in concert to achieve specific therapeutic effects.",1. Introduction,[0],[0]
"Multiple strains are often needed in bacteriotherpies both because multiple host pathways must be targeted, and because additional bacteria may provide stability or robustness to the community as a whole.",1. Introduction,[0],[0]
An important step toward designing bacteriotherapies is mapping out microbial interactions and predicting population dynamics of this ecosystem.,1. Introduction,[0],[0]
"One approach toward this goal, and arguably the most popular, is to learn dynamical systems models from time series measurements of microbiome abundance data.",1. Introduction,[0],[0]
"That is, one takes as input time series of microbiome abundances as depicted in Figure 1A and infers a dynamical systems model of microbial interactions as in Figure 1B. These data typically consist of two separate measurements: (1) high-throughput next generation sequencing counts of a marker gene (16S rRNA) mapped back to different microbial species or other taxonomic units (often 300+), to determine relative abundances of each unit, and (2) quantitative PCR (qPCR) measurements to determine the total concentration of bacteria in the ecosystem.
",1. Introduction,[0],[0]
Inferring dynamical systems models from microbiome time series data presents several challenges.,1. Introduction,[0],[0]
"The biggest challenge arises from the fact that the data is high-dimensional, yet temporally sparse and non-uniformly sampled.",1. Introduction,[0],[0]
"With 300 or more bacterial species in the gut, the resulting differential equation models can have more than 90,000 possible interaction parameters.",1. Introduction,[0],[0]
"However, unlike other biomedical domains where almost continuous temporal sampling is feasible (e.g., electrical recordings of cardiac activity), this is not currently possible for the gut microbiome.",1. Introduction,[0],[0]
"Instead, we must rely on fecal samples (or even more invasive processes, such as colonoscopy), which means that we are quite lim-
ited in terms of the frequency and total number of samples.",1. Introduction,[0],[0]
"Further, the techniques used to obtain estimates of microbial abundance are noisy, and with multiple technologies being combined (i.e., next generation sequencing and qPCR), the resulting measurement error models are relatively complex.",1. Introduction,[0],[0]
"Finally, the microbiome exhibits nonlinear and physically nonnegative dynamics, which introduce additional inference issues.",1. Introduction,[0],[0]
We now briefly review previous work in inferring dynamical systems from microbiome time-series data.,1.1. Prior work,[0],[0]
"The authors of (Stein et al., 2013) model microbial dynamics using continuous time deterministic generalized Lotka-Volterra (gLV) equations, transform to a discrete time linear model via a log transform to enable efficient inference, and then use L2 penalized linear regression to infer model parameters.",1.1. Prior work,[0],[0]
"The transformation performed in (Stein et al., 2013) is common in the ecological literature, and provides a point of comparison to our model, so we present it in detail now.",1.1. Prior work,[0],[0]
"Deterministic gLV dynamics can be written compactly as the Ordinary Differential Equation (ODE) ẋ(t) = x(t) (r + Ax(t)), where is the element wise product for vectors, r is a vector of growth rates and A is a matrix of interaction coefficients.",1.1. Prior work,[0],[0]
"Using for element wise division, the following representation of the ODE also holds: ẋ(t) x(t) = r + Ax(t).",1.1. Prior work,[0],[0]
The left hand side of the equivalent ODE can then be integrated resulting in the following identity: ∫ t2 t1 ẋ(t) x(t),1.1. Prior work,[0],[0]
dt = log(x(t2))− log(x(t1)).,1.1. Prior work,[0],[0]
This property of the logarithm can then be used to approximate the continuous time nonlinear ODE as a discrete time linear dynamical system.,1.1. Prior work,[0],[0]
There are a variety of both theoretical and practical issues with using this approximation.,1.1. Prior work,[0],[0]
"For instance, the transformation does not readily apply for stochastic dynamics.",1.1. Prior work,[0],[0]
"Additionally, the transform essentially assumes normally distributed error, which is inherently false, since data typically consist of sequences of counts.",1.1. Prior work,[0],[0]
"Further, we often encounter measurements of zero for microbial abundance, i.e., below the limit of detection, which would lead to taking the log of zero or adding an artificial small number.
",1.1. Prior work,[0],[0]
"Other work on inferring dynamical systems models from microbiome data includes (Fisher & Mehta, 2014), which takes a similar approach to (Stein et al., 2013), but instead of L2 penalized regression, use a sparse linear regression with bootstrap aggregation approach.",1.1. Prior work,[0],[0]
No regularization is performed and sparsity is introduced into the model by adding and removing interaction coefficients one at a time with step-wise regression.,1.1. Prior work,[0],[0]
"Several inference techniques are presented in (Bucci et al., 2016), two being extensions of the model proposed in (Stein et al., 2013) and two being new Bayesian models.",1.1. Prior work,[0],[0]
"The Bayesian models in (Bucci et al., 2016) are based on ODE gradient matching, in which
Bayesian spline smoothing is first performed to filter the experimental measurements, and then a Bayesian adaptive lasso or Bayesian variable selection method is used to infer model parameters.",1.1. Prior work,[0],[0]
"These methods do incorporate nonnormally distributed measurement error models, but errors are not propagated throughout the model, i.e., smoothing and filtering are separate steps.",1.1. Prior work,[0],[0]
"Finally, in (Alshawaqfeh et al., 2017) an Extended Kalman Filter (EKF) is applied to a stochastic gLV model, which incorporates filtering directly, unlike the aforementioned references; however, noise is assumed to be normally distributed.
",1.1. Prior work,[0],[0]
"Beyond microbiome specific dynamical systems inference approaches, there is an extensive body of work on Bayesian inference of nonlinear dynamical systems, which remains an active area of research (Ionides et al., 2006; Carlin et al., 1992; Aguilar et al., 1998; Geweke & Tanizaki, 2001).",1.1. Prior work,[0],[0]
"An interesting line of recent work leverages Gaussian Processes (GP) as a means for efficient filtering for both ordinary differential equations and partial differential equations (Chkrebtii et al., 2016).",1.1. Prior work,[0],[0]
"One of the catalysts for this line of work came from (Calderhead et al., 2009), in which a GP is used to infer the latent state variables, which in turn are used to infer parameters of an ODE.",1.1. Prior work,[0],[0]
"Extending that work, (Dondelinger et al., 2013) apply a gradient matching approach (marginalizing over state derivatives) and perform joint inference on the ODE parameters and latent state variables.",1.1. Prior work,[0],[0]
"However, several subsequent papers pointed out identifiability and efficiency issues with these approaches (Barber & Wang, 2014; Macdonald et al., 2015).",1.1. Prior work,[0],[0]
"More recently, (Gorbach et al., 2017; Bauer et al., 2017) presented a variational inference approach that addresses some of these issues.",1.1. Prior work,[0],[0]
"While we do not explore GPs in this work, they are an interesting and promising direction within the broader domain of Bayesian inference for nonlinear dynamical systems.",1.1. Prior work,[0],[0]
"Dynamic Bayesian Networks (DBN) also represent a broad class of state-space models leveraged for inference of dynamical systems given time series data (Murphy, 2002).",1.1. Prior work,[0],[0]
"Our model differs from a standard DBN, in that it learns the conditional independence structure in a latent temporal space,
and clusters the nodes in the graph nonparametrically.
",1.1. Prior work,[0],[0]
"Also related to our work are models that learn clustered representations of interacting systems, both for purposes of enhancing interpretability and for increasing efficiency of inference.",1.1. Prior work,[0],[0]
"Related approaches include Stochastic Block Models (SBM), in particular (Kemp et al., 2006), which model redundant interaction structure as probabilistic linkages between individual actors that are influenced by the blocks/groups that the actors belong to.",1.1. Prior work,[0],[0]
"SBMs typically directly model observed, non-temporal data, whereas our approach models latent temporal signals; further, our approach enforces identical interaction structure on variables in the same cluster, whereas SBMs assume a probabilistic interaction structure.",1.1. Prior work,[0],[0]
"Dependent groups/clusters have also been explored in the context of Topic Models (e.g., (Mimno et al., 2007)).",1.1. Prior work,[0],[0]
"There is also an extensive literature on Dependent Dirichlet Processes (MacEachern, 2000), which can be used to capture complex interactions between clusters, and also simpler structures (e.g., hierarchies as in (Teh et al., 2006)).",1.1. Prior work,[0],[0]
In this work we present a Bayesian nonparametric model and associated efficient inference algorithm that addresses the key conceptual and practical challenges of learning microbial dynamics from time series microbe abundance data.,1.2. Contributions,[0],[0]
"Our main contributions are:
• A new type of dynamical systems model for microbial dynamics based on what we term interaction modules, or probabilistic clusters of latent variables with redundant interaction structure.",1.2. Contributions,[0],[0]
"The aggregated concentrations of microbes in a module act as consolidated inputs to other modules, with structural learning of the network of interactions among modules.
",1.2. Contributions,[0],[0]
• A fully Bayesian formulation of the stochastic dynamical systems model that propagates measurement and latent state uncertainty throughout the model.,1.2. Contributions,[0],[0]
"This integrated approach improves on the previous work described for microbiome dynamics (which assumed deterministic dynamics and separated learning of latent states and ODE parameters).
",1.2. Contributions,[0],[0]
• Introduction of a temporally varying auxiliary variable technique to enable efficient inference by relaxing the hard non-negativity constraint on states.,1.2. Contributions,[0],[0]
"Introduction of the auxiliary variable not only allows for efficient inference with respect to filtering the latent state, it also allows for collapsed Gibbs sampling for module assignments and for the structural network learning component.
",1.2. Contributions,[0],[0]
The remainder of this paper is organized as follows.,1.2. Contributions,[0],[0]
"In Sec-
tion 2 we present the complete model.",1.2. Contributions,[0],[0]
Section 3 describes our inference algorithm.,1.2. Contributions,[0],[0]
Section 4 contains experimental validation on simulated and real data.,1.2. Contributions,[0],[0]
Section 5 contains our concluding remarks.,1.2. Contributions,[0],[0]
"Before moving on, a quick comment regarding notation: random variable are written in bold as α,β,γ, a,b, c with regular parameters denoted as α, β, γ, a, b, c.",1.2. Contributions,[0],[0]
"Our model of dynamics is based on a stochastic version of the gLV equations, widely used in ecological system modeling:
dxt,i = xt,i ( ai,1 + ai,2xt,i + ∑ j 6=i bijxt,j )",2.1. Model of dynamics,[0],[0]
"dt+ dwt,i
i ∈",2.1. Model of dynamics,[0],[0]
"{1, 2, . . .",2.1. Model of dynamics,[0],[0]
", n} where xt,i ∈ R≥0 is the abundance of microbial species i at time t ∈ R,",2.1. Model of dynamics,[0],[0]
"ai,1 ∈ R is the growth rate of microbial species i and ai,2 is the “self interaction term” and",2.1. Model of dynamics,[0],[0]
"together ai,1 and ai,2 determine the carrying capacity of the environment when species i is not interacting with any other species.",2.1. Model of dynamics,[0],[0]
The coefficients bij,2.1. Model of dynamics,[0],[0]
when i 6= j are then the microbial interaction terms.,2.1. Model of dynamics,[0],[0]
"The term wt,i ∈ R represents a stochastic disturbance.",2.1. Model of dynamics,[0],[0]
"Note that, while not shown explicitly, the disturbance must be conditioned on the state to prevent negative state values.",2.1. Model of dynamics,[0],[0]
"Overloading the first subscript in x, a discrete-time approximation to the gLV dynamics above is:
x(k+1),i−xk,i ≈ xk,i ( ai,1+ai,2xk,i+ ∑ j 6=i bijxk,j ) ∆k
+ √ ∆k(wk+1,i −wk,i) (1)
",2.1. Model of dynamics,[0],[0]
where k ∈,2.1. Model of dynamics,[0],[0]
"N>0 indexes time as tk and ∆k , tk+1 − tk.
",2.1. Model of dynamics,[0],[0]
The accuracy of this approximation will depend on a sufficiently dense discretization relative to time-scales of the dynamics of interest.,2.1. Model of dynamics,[0],[0]
"Higher order integration methods are possible for Stochastic Differential Equations (SDE), but quickly become very complicated without straightforward gains in accuracy seen with ODEs.",2.1. Model of dynamics,[0],[0]
"Our experience has been that Euler methods behave well for the gLV model in real microbial ecosystems, which are inherently stable.",2.1. Model of dynamics,[0],[0]
"However, Euler integration may be sub-optimal for strongly perturbed systems (e.g., antibiotics).",2.1. Model of dynamics,[0],[0]
"We note that Euler integration is indeed an advance over the state-of-the-art, which uses gradient-matching methods that don’t perform any integration.",2.1. Model of dynamics,[0],[0]
"An interesting area for future work would be to leverage Bayesian Probabilistic Numerical Methods (Cockayne et al., 2017) to incorporate step-size adaptation directly into our model.",2.1. Model of dynamics,[0],[0]
"We incorporate a Dirichlet Process (DP)-based clustering technique (Neal, 2000; Rasmussen, 2000) to learn redundant
interaction structures among bacterial species, which we term interaction modules.",2.2. Interaction modules,[0],[0]
"In the context of our dynamical systems model, this means that only interaction coefficients between modules need to be learned, rather than interactions between each pair of microbes.",2.2. Interaction modules,[0],[0]
"Without modules, the number of possible interaction coefficients scales as O(n2), where n is the number of microbial species.",2.2. Interaction modules,[0],[0]
"Since we are using DPs, where the expected number of clusters is O(log n)",2.2. Interaction modules,[0],[0]
"(Antoniak, 1974), the expected number of interaction coefficients is O((log n)2).",2.2. Interaction modules,[0],[0]
"For purposes of interpretability, we specifically assume no interactions within each module, corresponding to the biologically important scenario of redundant functionality among sets of microbes.",2.2. Interaction modules,[0],[0]
"An example of interaction module structure is visualized in Figure 1C: while Figures 1B and 1C both contain 10 microbes, there are only 6 interactions to learn in 1C (between modules), versus 90 microbe-microbe interactions in 1B without the module structure.
",2.2. Interaction modules,[0],[0]
Figure 2 depicts our interaction module model as a generative model.,2.2. Interaction modules,[0],[0]
"Starting with the Dirichlet Process, ci ∈ Z+ represents the cluster assignment for bacterial species i.",2.2. Interaction modules,[0],[0]
"If species i and species j are in different clusters, and thus ci 6= cj , then bci,cj ∈ R is the coefficient representing the (interaction) effect that the module containing species j has on species i.",2.2. Interaction modules,[0],[0]
"If species `, different from species i, is in the same cluster as species j, then bci,cj = bci,c` by definition (i.e., species in the same cluster share interaction coefficients).",2.2. Interaction modules,[0],[0]
"Note that no interactions are assumed to occur within a cluster, as discussed.
",2.2. Interaction modules,[0],[0]
"For each element in b there is a corresponding element in z, which is an indicator variable (0 or 1) that chooses whether an interaction exists between two modules.",2.2. Interaction modules,[0],[0]
"Thus, our model automatically adapts the interaction network by structurally adding or removing edges (analogous to approaches for standard Bayesian Networks e.g., (George & McCulloch, 1993; Heckerman, 2008)), which we refer to as Edge Se-
lection (ES).",2.2. Interaction modules,[0],[0]
"This approach allows us to easily compute Bayes factors (Kass & Raftery, 1995), enabling principled determination of the evidence for or against each interaction occurring.
",2.2. Interaction modules,[0],[0]
"The terms ai,1 and ai,2 correspond to the growth rate and self interaction term for species i, respectively.",2.2. Interaction modules,[0],[0]
Note that these variables are not part of our clustering scheme and do not have indicator variables associated with them.,2.2. Interaction modules,[0],[0]
"We now discuss one of our technical contributions, which is to relax the strict non-negativity assumption on x in Equation (1) and thereby enable efficient inference while maintaining (approximate) physically realistic non-negative dynamics.",2.3. Modeling non-negative dynamics,[0],[0]
"To accomplish this, we introduce an auxiliary trajectory variable q such that qk,i ∼ Uniform[0, L), with L > 0 and much larger than any of the measured values.",2.3. Modeling non-negative dynamics,[0],[0]
Microbial abundance data y are assumed to be generated from q through some model of measurement noise y,2.3. Modeling non-negative dynamics,[0],[0]
"| q (discussed below).
",2.3. Modeling non-negative dynamics,[0],[0]
"We couple the latent trajectory x to the auxiliary variable q through a conditional distribution q | x, which we assume to be Gaussian with small variance.",2.3. Modeling non-negative dynamics,[0],[0]
"This effectively introduces a momentum term into the model of dynamics (1) (proportional to the difference between x and q), which softly constrains x to be in the range",2.3. Modeling non-negative dynamics,[0],[0]
"[0, L).",2.3. Modeling non-negative dynamics,[0],[0]
"This renders the posterior distributions for x and gLV parameters a,b Gaussians rather than their being truncated Gaussians if strict non-negativity were imposed.",2.3. Modeling non-negative dynamics,[0],[0]
"Our technique has connections to several approaches that break or relax dependencies in a model to improve inference efficiency, such as Variational Inference (Blei et al., 2017) and distributed/parallel Bayesian inference approaches (Angelino et al., 2016).
",2.3. Modeling non-negative dynamics,[0],[0]
"Our approach can also be thought of as a product of experts: one expert is a uniform distribution confining q to
the positive orthant, and the other is a normal distribution enforcing closeness to the actual trajectory x. With either interpretation, q acts as a “restoring force” that pulls the posterior of x toward the positive orthant.",2.3. Modeling non-negative dynamics,[0],[0]
"With the introduction of q, the posterior a | x is now simply a multivariate Gaussian.",2.3. Modeling non-negative dynamics,[0],[0]
"Practically, this makes efficient inference feasible, since sampling from the posterior is now easy and we can also perform closed-form marginalizations.",2.3. Modeling non-negative dynamics,[0],[0]
"Further, the measurement model is decoupled from the dynamics, allowing for efficient inference with flexible measurement noise models, such as negative binomial distributions for modeling sequencing counts (Paulson et al., 2013; Love et al., 2014).",2.3. Modeling non-negative dynamics,[0],[0]
This is explored in detail in the subsequent subsection.,2.3. Modeling non-negative dynamics,[0],[0]
"In the Appendix, we provide a detailed analysis of the issues that ensue with a naive model that directly enforces non-negativity through the dynamics.",2.3. Modeling non-negative dynamics,[0],[0]
"Our measurement model handles two experimental technologies, sequencing counts of a marker gene (16S rRNA) mapped back to different microbial species or other taxonomic units, and qPCR measurements to determine total microbial concentration in the sample.",2.4. Measurement Model,[0],[0]
"The variable yk,i denotes the number of counts (sequencing reads) associated with bacterial species i at time k and Qk is the total bacterial concentration at time",2.4. Measurement Model,[0],[0]
k.,2.4. Measurement Model,[0],[0]
Our complete sensor model combining the two measurements is illustrated in Figure 2.,2.4. Measurement Model,[0],[0]
"The counts measurements yk,i are sampled from a Negative Binomial distribution with mean and dispersion parameters defined as:
yk,i | qk ∼ NegBin(φ(qk, rk), (qk, a0, a1))
φ(qk, rk) =",2.4. Measurement Model,[0],[0]
"rk qk,i∑ i qk,i
(2)
(qk, a0, a1) = a0 qk,i/ ∑ i qk,i + a1 (3)
where rk is the total number of sequencing reads for the sample at time k (often referred to as the read depth of the sample).",2.4. Measurement Model,[0],[0]
"The form of this model follows that of (Bucci et al., 2016; Love et al., 2014); see these references for detailed discussions on the validity of, and the empirical evidence for, using this error model for next generation sequencing
counts data.
",2.4. Measurement Model,[0],[0]
"The Negative Binomial dispersion scaling parameters a0, a1 are pre-trained on raw reads, and are not learned jointly with the rest of the model.",2.4. Measurement Model,[0],[0]
"Similarly, measurement variance, σ2Qk is estimated directly from technical replicates for each measurement.",2.4. Measurement Model,[0],[0]
"For completeness, we also give our specific parameterization of the Negative Binomial Probability Density Function (PDF):
NegBin(y;φ, ) = Γ(r + y)
y! Γ(r)
( φ
r + φ
)y ( r
r + φ )",2.4. Measurement Model,[0],[0]
"r r = 1
With this parameterization of the Negative Binomial distribution, the mean is φ and the variance is φ+ φ2.",2.4. Measurement Model,[0],[0]
"To complete the model description, we describe higher-level priors not shown in Figure 2.",2.5. Additional priors not specified in Figure 2,[0],[0]
"For the three variance random variables (σ2a ,σ 2 b ,σ 2 w) Inverse-Chi-squared priors are used.",2.5. Additional priors not specified in Figure 2,[0],[0]
The concentration parameter α for the DP is given a Gamma prior.,2.5. Additional priors not specified in Figure 2,[0],[0]
"Hyperparameters were set using a technique similar to (Bucci et al., 2016), where means of distributions were empirically calibrated based on the data and variances were set to large values to produce diffuse priors.",2.5. Additional priors not specified in Figure 2,[0],[0]
"We briefly describe our Markov Chain Monte Carlo inference algorithm, which leverages efficient collapsed Gibbs sampling steps.",3. Inference,[0],[0]
"As described in Section 2.5, we use conjugate priors on many variables (e.g., the variance terms (σ2a ,σ 2 b ,σ 2 w)), which allows straight-forward Gibbs sampling.",3. Inference,[0],[0]
"The module assignments, c, are also updated by a standard Gibbs sampling approach for Dirichlet Processes (Neal, 2000).",3. Inference,[0],[0]
"For the concentration parameter α, which has a Gamma prior on α, we use the sampling method described by (Escobar & West, 1995).
",3. Inference,[0],[0]
"Our auxiliary trajectory variables q allow us to marginalize out in closed form the interaction coefficients b, and thus perform collapsed Gibbs sampling, both during sampling assignments of species to modules and when structurally learning the network of interactions between modules.",3. Inference,[0],[0]
"Collapsed Gibbs steps have been shown to improve mixing substantially for DP inference (Neal, 2000).
",3. Inference,[0],[0]
Sampling of the auxiliary variables q and latent trajectories x require Metropolis-Hastings (MH) steps.,3. Inference,[0],[0]
"Briefly, for q, the MH proposal is based on a Generalized-Linear Model approximation.",3. Inference,[0],[0]
"For x, we use a one time-step ahead proposal similar to that described in (Geweke & Tanizaki, 2001).",3. Inference,[0],[0]
"Our proposal uses the previous time point latent abundance, the gLV coefficients, and the auxiliary trajectory (which is di-
rectly coupled to the observations) to propose the next time point abundance giving the proposal the form pxk+1|xk,q,Ω, where Ω = ai,b, z, c,σw.",3. Inference,[0],[0]
"Thus, our proposal is essentially the forward pass of a Kalman filter (which we color coded in Figure 3).",3. Inference,[0],[0]
"Our proposal uses the information from the blue nodes, to propose for the green node.",3. Inference,[0],[0]
"The future state information (orange node) is not used for the proposal, for efficiency of computation (i.e., we exploit conjugacy for the forward pass).",3. Inference,[0],[0]
"The future state information comes into the target distribution, so we sample from the true posterior.",3. Inference,[0],[0]
"Note that this is different from a standard Extended Kalman Filtering approach, which linearizes around estimated mean
and covariance and can deviate substantially from the true posterior.",3. Inference,[0],[0]
In this section we present results applying our model to both simulated and real microbiome data.,4. Results,[0],[0]
"Our goal with simulated data is to illustrate the utility of our model (and specifically Module Learning) when inferring microbial dynamics from time series data with limited biological replicates and temporal resolution, which is the reality for in vivo microbiome experiments.",4. Results,[0],[0]
"Figures 4A-4C depict our
results, comparing inference both with and without interaction module learning.",4. Results,[0],[0]
"Simulated data was constructed to mimic state-of-the-art experiments for developing and testing bacteriotherapies (Bucci et al., 2016).",4. Results,[0],[0]
"In these experiments, germ-free mice (animals raised in self-contained bacteria-free environments) were inoculated with defined collections of 13 bacterial species and serial fecal samples were collected to analyze dynamics of microbial colonization over time.",4. Results,[0],[0]
"Due to costs and logistic constraints, such experiments use relatively small numbers of biological replicates (≈ 5 mice) and limited temporal sampling (e.g., 10-30 time-points per mouse).",4. Results,[0],[0]
"To simulate these experiments, we generated data with 5 biological replicates (5 different time series simulated from the same dynamics, but with different initial conditions), 11 time-points per replicate, and assumed gLV dynamics with the following module and interaction structure:
1, 5, 7 9, 11
2, 4, 6, 8 10, 12
3, 13
2
−4
3
−1 (4)
where the numbers inside the nodes represent bacterial species in the same module and the edge weights are the module interaction coefficients bci,cj in our model in Figure 2.",4. Results,[0],[0]
"Note that this graph in (4) is just another representation of the weighted adjacency matrix in Figure 4C.
With module learning (Figure 4A), our algorithm recovers the module structure as expected, almost completely correctly, and also recovers the interaction coefficients well.",4. Results,[0],[0]
"While the algorithm incorrectly places species 6 in its own cluster, it properly learns that no other species contribute to the dynamics of species 6 (i.e. elements in the row associated with species 6, other than the self interaction term, are zero).",4. Results,[0],[0]
Our algorithm also forecasts trajectories of microbial abundances quite accurately.,4. Results,[0],[0]
"Without module learning enabled (Figure 4B), the algorithm still forecasts trajectories fairly accurately (although slightly worse than with module learning), but does much worse in inferring the interaction coefficients, and indeed the actual structure of the dynamical system is not at all evident.",4. Results,[0],[0]
"The ability to forecast trajectories relatively accurately, but not recover the underlying structure of the system well, highlights the issues with identifiability of nonlinear dynamical systems models from limited data: without additional structural constraints in the model, it is too easy to overfit, because many different settings of ODE parameters can result in exactly the same trajectories.
",4. Results,[0],[0]
"To investigate this issue further, we performed additional simulations using the same setup with varying numbers of biological replicates (Figure 4D).",4. Results,[0],[0]
"Results using 20 initial
conditions were run and aggregate statistics are presented.",4. Results,[0],[0]
"For forecasting trajectories, module learning clearly helps, although performance is relatively good without module learning with 4 or more biological replicates.",4. Results,[0],[0]
"However, as can be seen, for identification of the actual ODE parameters, module learning has a much larger advantage.
",4. Results,[0],[0]
"It is worth noting that module learning also resulted in significant improvements in wall-clock runtime, by a factor of about 10.",4. Results,[0],[0]
"We did not test this empirical observation extensively, but it is consistent with theory, in that the additional time to learn module structure with our inference algorithm is (in expectation) nO(log n), whereas the time to learn interaction coefficients is reduced from O(n2) to O((log n)2).
",4. Results,[0],[0]
"We next applied our algorithm to real data from (Bucci et al., 2016), which investigated developing a bacteriotherapy for Clostridium difficile, a pathogenic bacteria that causes serious diarrhea and is the most common cause of hospital acquired infection in the U.S. Five germ-free mice were colonized with a collection of 13 commensal (beneficial) bacterial species, termed the GnotoComplex microbiota, and monitored for 28 days (Figure 5A).",4. Results,[0],[0]
"Then, mice were infected with Clostridium difficile and monitored for another 28 days.",4. Results,[0],[0]
"All mice developed diarrhea, but recovered within about a week, indicating that some combination of the 13 bacterial species protect against the pathogen (in a germ-free mouse, the infection causes death in 24-48 hours).",4. Results,[0],[0]
"Over the course of the experiment, 26 serial fecal samples per mouse were collected and interrogated via sequencing and qPCR to determine concentrations of the commensal microbes and the pathogen.",4. Results,[0],[0]
"We removed one species from our analysis, Clostridium hiranonis, because it appeared to inconsistently colonize the mice, but otherwise used all data from the original study.
",4. Results,[0],[0]
"Figure 5 shows the results of applying our model to the data from (Bucci et al., 2016).",4. Results,[0],[0]
"Our model found a median of 4 interaction modules (5,000 MCMC samples with 1,000 burnin).",4. Results,[0],[0]
"Seven microbes formed a large and consistent module, with the remaining six microbes aggregating into smaller modules.",4. Results,[0],[0]
Figure 5B shows the module structure of a representative sample from the posterior.,4. Results,[0],[0]
"The module structure identifies groups of microbes that putatively inhibit the pathogen, and does so more clearly than in the original study, which presented a dense network of microbial interactions.",4. Results,[0],[0]
"The fine structure of this dense network is indeed still recapitulated in the posterior summary of interaction coefficients (Figure 5C), but our model also has the advantage of providing a compact module structure that is much easier to interpret biologically.",4. Results,[0],[0]
"Interestingly, the strongest interaction identified by our model (which the analysis from the original study detected relatively weakly), with Clostridium scindens inhibiting the pathogen, is in fact the only
Day 1 Day 28 Day 56
C. difficileGnotoComplex",4. Results,[0],[0]
"A
13 samples 13 samples
C. scindens B. ovatusP. distasonis
A. muciniphila R. hominis C. difficile + rest
B
−2.1 −0.13
−0.05
1 2 3 4 5 6 7 8 9 10 11 12 13
Microbe Co-cluster Proportions
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Klebsiella oxytoca 13 Ruminococcus obeum 12
Bacteroides vulgatus 11 Bacteroides fragilis 10
Escherichia coli 9 Proteus mirabilis 8
Clostridium ramosum 7 Clostridium difficile 6 Roseburia hominis 5
Akkermansia muciniphila 4 Parabacteroides distasonis 3
Bacteroides ovatus 2 Clostridium scindens 1
1 2 3 4 5 6 7 8 9 10 11 12 13
Microbe Interaction Strength
-14
-13
-12
-11
-10
-9
-8
Klebsiella oxytoca 13 Ruminococcus obeum 12
Bacteroides vulgatus 11 Bacteroides fragilis 10
Escherichia coli 9 Proteus mirabilis 8
Clostridium ramosum 7 Clostridium difficile 6 Roseburia hominis 5
Akkermansia muciniphila 4 Parabacteroides distasonis 3
Bacteroides ovatus 2 Clostridium scindens 1 -
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - + + +",4. Results,[0],[0]
+ + + - + + + + + + + + + +,4. Results,[0],[0]
"+ + - - - - + + - + + + + + + + + - + + + + + + + + + + + + + - + + + + + + + + + + + + + - + + - - - - - - - - - - - - - - + + + + + + + + + + + -
gr am
/(C",4. Results,[0],[0]
"FU
da y)
log10",4. Results,[0],[0]
"C
Figure 5.",4. Results,[0],[0]
"Inference applied to in vivo experiments from (Bucci et al., 2016), illustrating the ability of interaction module learning to produce interpretable interaction structures that agree with biologically validated and plausible interactions.",4. Results,[0],[0]
(A) Experimental timeline (performed with 5 germ-free mice).,4. Results,[0],[0]
"GnotoComplex microbes, a defined collection of beneficial gut bacteria, is introduced on day one with Clostridium difficile introduced on day 28.",4. Results,[0],[0]
(B) Module structure of a representative sample from the posterior with interaction strengths shown (interaction scale is 10−9).,4. Results,[0],[0]
"(C) Co-cluster proportions illustrating the probability that two microbes appear in the same module and expected values for interaction coefficients, log10 scale with interaction signs illustrated.
biologically validated result in their study.",4. Results,[0],[0]
"Our analysis also discovered additional putative inhibitors of the pathogen, including the commensal Akkermansia munciniphila.",4. Results,[0],[0]
"This microbe lives in the mucous layer in the gut, and has been associated positively with mucosal integrity in several studies (see e.g., (Belzer et al., 2017)), and thus suggests an interesting and biologically plausible candidate for inclusion in a bacteriotherapy against the pathogen.",4. Results,[0],[0]
We have presented a Bayesian nonparametric model and associated inference algorithm for tackling key challenges in analyzing dynamics of the microbiome.,5. Conclusions,[0],[0]
"Our method introduces several innovations, including a new type of modular dynamical systems model, uncertainty propagation throughout the model, and an efficient technique for approximating physically realistic non-negative dynamics.",5. Conclusions,[0],[0]
Applications of our method to simulated data show the ability to accurately identify the underlying dynamical system even with limited data.,5. Conclusions,[0],[0]
"Application to real data highlights the ability of our model to infer compact, biologically interpretable representations that correctly find known relationships and suggest new, biologically plausible relationships.
",5. Conclusions,[0],[0]
There are several areas for future work.,5. Conclusions,[0],[0]
"Other Bayesian clustering approaches, which are more flexible than DPs, such as mixtures of finite mixtures (Miller & Harrison, 2017), would be interesting to investigate as alternate priors for interaction modules.",5. Conclusions,[0],[0]
"The gLV dynamical systems model has been widely used in microbial ecology, but has limitations
including modeling only pairwise interactions and quadratic nonlinearities.",5. Conclusions,[0],[0]
"Our inference method is quite flexible, and could readily accommodate other dynamical systems models, although nonlinearities in coefficients would cause difficulties (gLV is linear in the coefficients) in efficiency with our current algorithm.",5. Conclusions,[0],[0]
"Another interesting avenue is using other forms of approximate inference to accelerate our algorithm, including approximate parallel MCMC and Variational Bayesian techniques.",5. Conclusions,[0],[0]
"Incorporating prior biological knowledge, such as phylogenetic relationships between microbes, is another interesting area to investigate; because our model is fully Bayesian, incorporating prior knowledge is conceptually straight forward.",5. Conclusions,[0],[0]
"Designing in vivo experiments with sufficient richness to identify dynamical systems is a very important topic, and applying our model within a formal experimental design framework would thus be very interesting.",5. Conclusions,[0],[0]
"On the application side, we plan to apply our model to additional bacteriotherapy design problems, which is an active and growing area of research.",5. Conclusions,[0],[0]
"In this regard, our goal is to apply our model to upcoming human microbiome bacteriotherapy trials, which will measure the abundances of hundreds of gut commensal bacterial species per person.",5. Conclusions,[0],[0]
We thank the reviewers for their many helpful comments and suggestions.,Acknowledgements,[0],[0]
They greatly improved the final paper.,Acknowledgements,[0],[0]
"This work was supported by NIH 5T32HL007627-33, DARPA BRICS HR0011-15-C-0094 and the BWH Precision Medicine Initiative.",Acknowledgements,[0],[0]
"Microbes are everywhere, including in and on our bodies, and have been shown to play key roles in a variety of prevalent human diseases.",abstractText,[0],[0]
"Consequently, there has been intense interest in the design of bacteriotherapies or “bugs as drugs,” which are communities of bacteria administered to patients for specific therapeutic applications.",abstractText,[0],[0]
Central to the design of such therapeutics is an understanding of the causal microbial interaction network and the population dynamics of the organisms.,abstractText,[0],[0]
In this work we present a Bayesian nonparametric model and associated efficient inference algorithm that addresses the key conceptual and practical challenges of learning microbial dynamics from time series microbe abundance data.,abstractText,[0],[0]
"These challenges include high-dimensional (300+ strains of bacteria in the gut) but temporally sparse and non-uniformly sampled data; high measurement noise; and, nonlinear and physically nonnegative dynamics.",abstractText,[0],[0]
"Our contributions include a new type of dynamical systems model for microbial dynamics based on what we term interaction modules, or learned clusters of latent variables with redundant interaction structure (reducing the expected number of interaction coefficients from O(n) to O((log n))); a fully Bayesian formulation of the stochastic dynamical systems model that propagates measurement and latent state uncertainty throughout the model; and introduction of a temporally varying auxiliary variable technique to enable efficient inference by relaxing the hard non-negativity constraint on states.",abstractText,[0],[0]
"We apply our method to simulated and real data, and demonstrate the utility of our technique for system identification from limited data, and for gaining new biological insights into bacteriotherapy design.",abstractText,[0],[0]
"Massachusetts Host-Microbiome Center, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, USA.",abstractText,[0],[0]
"Correspondence to: TE Gibson <tgibson@mit.edu>, GK Gerber <ggerber@bwh.harvard.edu>.",abstractText,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",abstractText,[0],[0]
Copyright 2018 by the author(s).,abstractText,[0],[0]
Robust and Scalable Models of Microbiome Dynamics,title,[0],[0]
"The optimal allocation of resources for maximizing influence, spread of information or coverage, has gained attention in the past few years, in particular in machine learning and data mining (Domingos & Richardson, 2001; Kempe et al., 2003; Chen et al., 2009; Gomez Rodriguez & Schölkopf, 2012; Borgs et al., 2014).
",1. Introduction,[0],[0]
"In the Budget Allocation Problem, one is given a bipartite influence graph between channels S and people T , and the task is to assign a budget y(s) to each channel s in S with the goal of maximizing the expected number of influenced people I(y).",1. Introduction,[0],[0]
"Each edge (s, t) 2 E between channel s and
1Massachusetts Institute of Technology.",1. Introduction,[0],[0]
"Correspondence to: Matthew Staib <mstaib@mit.edu>, Stefanie Jegelka <stefje@mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"person t is weighted with a probability pst that, e.g., an advertisement on radio station s will influence person t to buy some product.",1. Introduction,[0],[0]
The budget y(s) controls how many independent attempts are made via the channel s to influence the people in T .,1. Introduction,[0],[0]
"The probability that a customer t is influenced when the advertising budget is y is
It(y) = 1 Y (s,t)2E [1 pst]y(s), (1)
and hence the expected number of influenced people is I(y) = P
t2T It(y).",1. Introduction,[0],[0]
We write I(y; p) = I(y) to make the dependence on the probabilities pst explicit.,1. Introduction,[0],[0]
"The total budget y must remain within some feasible set Y which may encode e.g. a total budget limit P
s2S y(s)  ",1. Introduction,[0],[0]
"C. We allow the budgets y to be continuous, as in (Bian et al., 2017).
",1. Introduction,[0],[0]
"Since its introduction by Alon et al. (2012), several works have extended the formulation of Budget Allocation and provided algorithms (Bian et al., 2017; Hatano et al., 2015; Maehara et al., 2015; Soma et al., 2014; Soma & Yoshida, 2015).",1. Introduction,[0],[0]
"Budget Allocation may also be viewed as influence maximization on a bipartite graph, where information spreads as in the Independent Cascade model.",1. Introduction,[0],[0]
"For integer y, Budget Allocation and Influence Maximization are NPhard.",1. Introduction,[0],[0]
"Yet, constant-factor approximations are possible, and build on the fact that the influence function is submodular in the binary case, and DR-submodular in the integer case (Soma et al., 2014; Hatano et al., 2015).",1. Introduction,[0],[0]
"If y is continuous, the problem is a concave maximization problem.
",1. Introduction,[0],[0]
The formulation of Budget Allocation assumes that the transmission probabilities are known exactly.,1. Introduction,[0],[0]
But this is rarely true in practice.,1. Introduction,[0],[0]
"Typically, the probabilities pst, and possibly the graph itself, must be inferred from observations (Gomez Rodriguez et al., 2010; Du et al., 2013; Narasimhan et al., 2015; Du et al., 2014; Netrapalli & Sanghavi, 2012).",1. Introduction,[0],[0]
In Section 4 we will see that a misspecification or point estimate of parameters pst can lead to much reduced outcomes.,1. Introduction,[0],[0]
A more realistic assumption is to know confidence intervals for the pst.,1. Introduction,[0],[0]
"Realizing this severe deficiency, recent work studied robust versions of Influence Maximization, where a budget y must be chosen that maximizes the worst-case approximation ratio over a set of possible influence functions (He & Kempe, 2016; Chen et al., 2016; Lowalekar et al., 2016).",1. Introduction,[0],[0]
"The resulting optimization problem is hard but admits bicriteria approximations.
",1. Introduction,[0],[0]
"In this work, we revisit Budget Allocation under uncertainty from the perspective of robust optimization (Bertsimas et al., 2011; Ben-Tal et al., 2009).",1. Introduction,[0],[0]
"We maximize the worst-case influence – not approximation ratio – for p in a confidence set centered around the “best guess” (e.g., posterior mean).",1. Introduction,[0],[0]
"This avoids pitfalls of the approximation ratio formulation (which can be misled to return poor worst-case budgets, as demonstrated in Appendix A), while also allowing us to formulate the problem as a max-min game:
max y2Y min p2P I(y; p), (2)
where an “adversary” can arbitrarily manipulate p within the confidence set P .",1. Introduction,[0],[0]
"With p fixed, I(y; p) is concave in y.",1. Introduction,[0],[0]
"However, the influence function I(y; p) is not convex, and not even quasiconvex, in the adversary’s variables pst.
",1. Introduction,[0],[0]
"The new, key insight we exploit in this work is that I(y; p) has the property of continuous submodularity in p – in contrast to previously exploited submodular maximization in y – and can hence be minimized by generalizing techniques from discrete submodular optimization (Bach, 2015).",1. Introduction,[0],[0]
"The techniques in (Bach, 2015), however, are restricted to box constraints, and do not directly apply to our confidence sets.",1. Introduction,[0],[0]
"In fact, general constrained submodular minimization is hard (Svitkina & Fleischer, 2011; Goel et al., 2009; Iwata & Nagano, 2009).",1. Introduction,[0],[0]
"We make the following contributions:
1.",1. Introduction,[0],[0]
"We present an algorithm with optimality bounds for Robust Budget Allocation in the nonconvex adversarial scenario (2).
2.",1. Introduction,[0],[0]
"We provide the first results for continuous submodular minimization with box constraints and one more “nice” constraint, and conditions under which the algorithm is guaranteed to return a global optimum.",1. Introduction,[0],[0]
"We begin with some background material and, along the way, discuss related work.",1.1. Background and Related Work,[0],[0]
Submodularity is perhaps best known as a property of set functions.,1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
A function F : 2V !,1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"R defined on subsets S ✓ V of a ground set V is submodular if for all sets S, T ✓ V , it holds that F (S) +",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
F (T ) F (S \ T ) + F (S[T ).,1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"A similar definition extends to functions defined over a distributive lattice L, e.g. the integer lattice.",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"Such a function f is submodular if for all x, y 2 L, it holds that
f(x) + f(y) f(x _",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
y),1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
+ f(x ^ y).,1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"(3)
For the integer lattice and vectors x, y, x _ y denotes the coordinate-wise maximum and x ^",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"y the coordinate-wise
minimum.",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"Submodularity has also been considered on continuous domains X ⇢ Rd, where, if f is also twicedifferentiable, the property of submodularity means that all off-diagonal entries of the the Hessian are nonpositive, i.e., @f(x) @xi@xj
 0 for all i 6=",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"j (Topkis, 1978, Theorem 3.2).",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"These functions may be convex, concave, or neither.
",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"Submodular functions on lattices can be minimized by a reduction to set functions, more precisely, ring families (Birkhoff, 1937).",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"Combinatorial algorithms for submodular optimization on lattices are discussed in (Khachaturov et al., 2012).",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"More recently, Bach (2015) extended results based on the convex Lovász extension, by building on connections to optimal transport.",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"The subclass of L\-convex functions admits strongly polynomial time minimization (Murota, 2003; Kolmogorov & Shioura, 2009; Murota & Shioura, 2014), but does not apply in our setting.
",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"Similarly, results for submodular maximization extend to integer lattices, e.g. (Gottschalk & Peis, 2015).",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
Stronger results are possible if the submodular function also satisfies diminishing returns: for all x  y (coordinate-wise) and,1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"i such that y+ei 2 X , it holds that f(x+ei) f(x) f(y+ei) f(y).",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"For such DR-submodular functions, many approximation results for the set function case extend (Bian et al., 2017; Soma & Yoshida, 2015; Soma et al., 2014).",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"In particular, Ene & Nguyen (2016) show a generic reduction to set function optimization that they apply to maximization.",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"In fact, it also applies to minimization:
Proposition 1.1.",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"A DR-submodular function f defined on
Qn i=1[ki] can be minimized in strongly polynomial time O(n4 log4 k · log2(n log k) ·",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"EO + n4 log4 k · log O(1) (n log k)), where k = maxi ki and EO is the time complexity of evaluating f .",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"Here, [ki] = {0, 1, . . .",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
", ki 1}.
",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"In particular, the time complexity is logarithmic in k. For general lattice submodular functions, this is not possible without further assumptions.",1.1.1. SUBMODULARITY OVER THE INTEGER LATTICE AND CONTINUOUS DOMAINS,[0],[0]
"A sister problem of Budget Allocation is Influence Maximization on general graphs, where a set of seed nodes is selected to start a propagation process.",1.1.2. RELATED PROBLEMS,[0],[0]
"The influence function is still monotone submodular and amenable to the greedy algorithm (Kempe et al., 2003), but it cannot be evaluated explicitly and requires approximation (Chen et al., 2010).",1.1.2. RELATED PROBLEMS,[0],[0]
"Stochastic Coverage (Goemans & Vondrák, 2006) is a version of Set Cover where the covering sets Si ⇢ V are random.",1.1.2. RELATED PROBLEMS,[0],[0]
A variant of Budget Allocation can be written as stochastic coverage with multiplicity.,1.1.2. RELATED PROBLEMS,[0],[0]
"Stochastic Coverage has mainly been studied in the online or adaptive setting, where logarithmic approximation factors can be achieved (Golovin & Krause, 2011; Deshpande et al., 2016; Adamczyk et al., 2016).
",1.1.2. RELATED PROBLEMS,[0],[0]
"Our objective function (2) is a signomial in p, i.e., a linear combination of monomials of the form",1.1.2. RELATED PROBLEMS,[0],[0]
"Q
i x ci",1.1.2. RELATED PROBLEMS,[0],[0]
i .,1.1.2. RELATED PROBLEMS,[0],[0]
"Gen-
",1.1.2. RELATED PROBLEMS,[0],[0]
"eral signomial optimization is NP-hard (Chiang, 2005), but certain subclasses are tractable: posynomials with all nonnegative coefficients can be minimized via Geometric Programming (Boyd et al., 2007), and signomials with a single negative coefficient admit sum of squares-like relaxations (Chandrasekaran & Shah, 2016).",1.1.2. RELATED PROBLEMS,[0],[0]
"Our problem, a constrained posynomial maximization, is not in general a geometric program.",1.1.2. RELATED PROBLEMS,[0],[0]
"Some work addresses this setting via monomial approximation (Pascual & Ben-Israel, 1970; Ecker, 1980), but, to our knowledge, our algorithm is the first that solves this problem to arbitrary accuracy.",1.1.2. RELATED PROBLEMS,[0],[0]
Two prominent strategies of addressing uncertainty in parameters of optimization problems are stochastic and robust optimization.,1.1.3. ROBUST OPTIMIZATION,[0],[0]
"If the distribution of the parameters is known (stochastic optimization), formulations such as value-at-risk (VaR) and conditional value-at-risk (CVaR) (Rockafellar & Uryasev, 2000; 2002) apply.",1.1.3. ROBUST OPTIMIZATION,[0],[0]
"In contrast, robust optimization (Ben-Tal et al., 2009; Bertsimas et al., 2011) assumes that the parameters (of the cost function and constraints) can vary arbitrarily within a known confidence set U , and the aim is to optimize the worst-case setting, i.e.,
min y sup u,A,b2U {g(y;u) s.t.",1.1.3. ROBUST OPTIMIZATION,[0],[0]
Ay  b}.,1.1.3. ROBUST OPTIMIZATION,[0],[0]
"(4)
Here, we will only have uncertainty in the cost function.
",1.1.3. ROBUST OPTIMIZATION,[0],[0]
"In this paper we are principally concerned with robust maximization of the continuous influence function I(y), but mention some results for the discrete case.",1.1.3. ROBUST OPTIMIZATION,[0],[0]
"While there exist results for robust and CVaR optimization of modular (linear) functions (Nikolova, 2010; Bertsimas & Sim, 2003), submodular objectives do not in general admit such optimization (Maehara, 2015), but variants admit approximations (Zhang et al., 2014).",1.1.3. ROBUST OPTIMIZATION,[0],[0]
"The brittleness of submodular optimization under noise has been studied in (Balkanski et al., 2016; 2017; Hassidim & Singer, 2016).
",1.1.3. ROBUST OPTIMIZATION,[0],[0]
"Approximations for robust submodular and influence optimization have been studied in (Krause et al., 2008; He & Kempe, 2016; Chen et al., 2016; Lowalekar et al., 2016), where an adversary can pick among a finite set of objective functions or remove selected elements (Orlin et al., 2016).",1.1.3. ROBUST OPTIMIZATION,[0],[0]
The unknown parameters in Budget Allocation are the transmission probabilities pst or edge weights in a graph.,2. Robust and Stochastic Budget Allocation,[0],[0]
"If these are estimated from data, we may have posterior distributions or, a weaker assumption, confidence sets for the parameters.",2. Robust and Stochastic Budget Allocation,[0],[0]
"For ease of notation, we will work with the failure probabilities",2. Robust and Stochastic Budget Allocation,[0],[0]
xst,2. Robust and Stochastic Budget Allocation,[0],[0]
"= 1 pst instead of the pst
directly, and write I(y;x) instead of I(y; p).",2. Robust and Stochastic Budget Allocation,[0],[0]
"If a (posterior) distribution of the parameters is known, a simple strategy is to use expectations.",2.1. Stochastic Optimization,[0],[0]
"We place a uniform prior on xst, and observe nst independent observations drawn from Ber(xst).",2.1. Stochastic Optimization,[0],[0]
"If we observe ↵st failures and and st successes, the resulting posterior distribution on the variable Xst is Beta(1 + ↵st, 1 + st).",2.1. Stochastic Optimization,[0],[0]
"Given such a posterior, we may optimize
max y2Y I(y;E[X]), or (5)
max y2Y E[I(y;X)].",2.1. Stochastic Optimization,[0],[0]
"(6)
Proposition 2.1.",2.1. Stochastic Optimization,[0],[0]
"Problems (5) and (6) are concave maximization problems over the (convex) set Y and can be solved exactly.
",2.1. Stochastic Optimization,[0],[0]
"Concavity of (6) follows since it is an expectation over concave functions, and the problem can be solved by stochastic gradient ascent or by explicitly computing gradients.
",2.1. Stochastic Optimization,[0],[0]
Merely maximizing expectation does not explicitly account for volatility and hence risk.,2.1. Stochastic Optimization,[0],[0]
"One option is to include variance (Ben-Tal & Nemirovski, 2000; Bertsimas et al., 2011; Atamtürk & Narayanan, 2008):
min y2Y E[I(y;X)]",2.1. Stochastic Optimization,[0],[0]
"+ ""
p
Var(I(y;X)), (7)
but in our case this CVaR formulation seems difficult: Fact 2.1.",2.1. Stochastic Optimization,[0],[0]
"For y in the nonnegative orthant, the term p
Var(I(y;X)) need not be convex or concave, and need not be submodular or supermodular.
",2.1. Stochastic Optimization,[0],[0]
"This observation does not rule out a solution, but the apparent difficulties further motivate a robust formulation that, as we will see, is amenable to optimization.",2.1. Stochastic Optimization,[0],[0]
"The focus of this work is the robust version of Budget Allocation, where we allow an adversary to arbitrarily set the parameters x within an uncertainty set X .",2.2. Robust Optimization,[0],[0]
"This uncertainty set may result, for instance, from a known distribution, or simply assumed bounds.",2.2. Robust Optimization,[0],[0]
"Formally, we solve
max y2Y min x2X I(y;x), (8)
where Y ⇢ RS + is a convex set with an efficient projection oracle, and X is an uncertainty set containing an estimate x̂.",2.2. Robust Optimization,[0],[0]
"In the sequel, we use uncertainty sets X = {x 2 Box(l, u) : R(x)  B}, where R is a distance (or divergence) from the estimate x̂, and Box(l, u) is the box Q
(s,t)2E [lst, ust].",2.2. Robust Optimization,[0],[0]
"The intervals [lst, ust] can be thought of
as either confidence intervals around x̂, or, if [lst, ust] =",2.2. Robust Optimization,[0],[0]
"[0, 1], enforce that each xst is a valid probability.
",2.2. Robust Optimization,[0],[0]
"Common examples of uncertainty sets used in Robust Optimization are Ellipsoidal and D-norm uncertainty sets (Bertsimas et al., 2011).",2.2. Robust Optimization,[0],[0]
"Our algorithm in Section 3.1 applies to both.
",2.2. Robust Optimization,[0],[0]
Ellipsoidal uncertainty.,2.2. Robust Optimization,[0],[0]
"The ellipsoidal or quadratic uncertainty set is defined by
XQ( ) = {x 2 Box(0, 1) : (x x̂)T⌃ 1(x x̂)  },
where ⌃ is the covariance of the random vector X of probabilities distributed according to our Beta posteriors.",2.2. Robust Optimization,[0],[0]
"In our case, since the distributions on each xst are independent, ⌃ 1 is actually diagonal.",2.2. Robust Optimization,[0],[0]
"Writing ⌃ = diag( 2), we have
XQ( ) = n x 2 Box(0, 1) : X
(s,t)2E
Rst(xst)  o ,
where Rst(x) =",2.2. Robust Optimization,[0],[0]
"(xst x̂st)2 2st .
",2.2. Robust Optimization,[0],[0]
D-norm uncertainty.,2.2. Robust Optimization,[0],[0]
"The D-norm uncertainty set is similar to an `
1
-ball around x̂, and is defined as
XD( ) = n x",2.2. Robust Optimization,[0],[0]
": 9c 2 Box(0, 1) s.t.
xst = x̂st +",2.2. Robust Optimization,[0],[0]
"(ust x̂st)cst, X
(s,t)2E
cst  o .
",2.2. Robust Optimization,[0],[0]
"Essentially, we allow an adversary to increase x̂st up to some upper bound ust, subject to some total budget across all terms xst.",2.2. Robust Optimization,[0],[0]
"The set XD( ) can be rewritten as
XD( ) = n x 2 Box(x̂, u) : X
(s,t)2E
Rst(xst)  o ,
where Rst(xst) =",2.2. Robust Optimization,[0],[0]
(xst x̂st)/(ust x̂st) is the fraction of the interval,2.2. Robust Optimization,[0],[0]
"[x̂st, ust] we have used up in increasing xst.
",2.2. Robust Optimization,[0],[0]
The min-max formulation maxy2Y minx2X,2.2. Robust Optimization,[0],[0]
I(y;x) has several merits: the model is not tied to a specific learning algorithm for the probabilities x as long as we can choose a suitable confidence set.,2.2. Robust Optimization,[0],[0]
"Moreover, this formulation allows to fully hedge against a worst-case scenario.",2.2. Robust Optimization,[0],[0]
"As noted above, the function I(y;x) is concave as a function of y for fixed x. As a pointwise minimum of concave functions, F (y) := minx2X I(y;x) is concave.",3. Optimization Algorithm,[0],[0]
"Hence, if we can compute subgradients of F (y), we can solve our max-min-problem via the subgradient method, as outlined in Algorithm 1.
",3. Optimization Algorithm,[0],[0]
A subgradient gy 2,3. Optimization Algorithm,[0],[0]
"@F (y) at y is given by the gradient of I(y;x⇤) for the minimizing x⇤ 2 argminx2X I(y;x), i.e.,
Algorithm 1 Subgradient Ascent Input: suboptimality tolerance "" > 0, initial feasible budget y(0) 2 Y Output: ""-optimal budget y for Problem (8) repeat x(k) argminx2X I(y(k);x) g(k) ryI(y(k);x(k))",3. Optimization Algorithm,[0],[0]
L(k) I(y(k);x(k)),3. Optimization Algorithm,[0],[0]
U (k) maxy2Y I(y;x(k)),3. Optimization Algorithm,[0],[0]
"(k) (U (k) L(k))/kg(k)k2
2
y(k+1) projY(y(k)",3. Optimization Algorithm,[0],[0]
+ (k)g(k)),3. Optimization Algorithm,[0],[0]
"k k + 1
until U (k) L(k)  ""
gy = ryI(y;x⇤).",3. Optimization Algorithm,[0],[0]
"Hence, we must be able to compute x⇤ for any y.",3. Optimization Algorithm,[0],[0]
"We also obtain a duality gap: for any x0, y0 we have
min",3. Optimization Algorithm,[0],[0]
x2X I(y0;x)  max y2Y min x2X I(y;x)  max y2Y I(y;x0).,3. Optimization Algorithm,[0],[0]
"(9)
",3. Optimization Algorithm,[0],[0]
"This means we can estimate the optimal value I⇤ and use it in Polyak’s stepsize rule for the subgradient method (Polyak, 1987).
",3. Optimization Algorithm,[0],[0]
"But I(y;x) is not convex in x, and not even quasiconvex.",3. Optimization Algorithm,[0],[0]
"For example, standard methods (Wainwright & Chiang, 2004, Chapter 12) imply that f(x
1 , x 2 , x 3
) = 1 x 1 x 2 px 3 is not quasiconvex on R3 +
.",3. Optimization Algorithm,[0],[0]
"Moreover, the above-mentioned signomial optimization techniques do not apply for an exact solution either.",3. Optimization Algorithm,[0],[0]
"So, it is not immediately clear that we can solve the inner optimization problem.
",3. Optimization Algorithm,[0],[0]
"The key insight we will be using is that I(y;x) has a different beneficial property: while not convex, I(y;x) as a function of x is continuous submodular.",3. Optimization Algorithm,[0],[0]
Lemma 3.1.,3. Optimization Algorithm,[0],[0]
"Suppose we have n 1 differentiable functions fi : R! R+, for i = 1, . . .",3. Optimization Algorithm,[0],[0]
", n, either all nonincreasing or all nondecreasing.",3. Optimization Algorithm,[0],[0]
"Then, f(x) =
Qn i=1 fi(xi) is a
continuous supermodular function from Rn to R + .
",3. Optimization Algorithm,[0],[0]
Proof.,3. Optimization Algorithm,[0],[0]
"For n = 1, the resulting function is modular and therefore supermodular.",3. Optimization Algorithm,[0],[0]
"In the case n 2, we simply need to compute derivatives.",3. Optimization Algorithm,[0],[0]
"The mixed derivatives are
@f
@xi@xj = f 0i(xi)f 0 j(xj) ·
Y
k 6=i,j fk(xk).",3. Optimization Algorithm,[0],[0]
"(10)
By monotonicity, f 0i and f 0j have the same sign, so their product is nonnegative, and since each fk is nonnegative, the entire expression is nonnegative.",3. Optimization Algorithm,[0],[0]
"Hence, f(x) is continuous supermodular by Theorem 3.2 of (Topkis, 1978).
",3. Optimization Algorithm,[0],[0]
Corollary 3.1.,3. Optimization Algorithm,[0],[0]
"The influence function I(y;x) defined in Section 2 is continuous submodular in x over the nonnegative orthant, for each y 0.
Proof.",3. Optimization Algorithm,[0],[0]
"Since submodularity is preserved under summation, it suffices to show that each function It(y) is continuous submodular.",3. Optimization Algorithm,[0],[0]
"By Lemma 3.1, since fs(z) = zy(s) is nonnegative and monotone nondecreasing for y(s) 0, the product Q
(s,t)2E x y(s) st is continuous supermodular in x.
Flipping the sign and adding a constant term yields It(y), which is hence continuous submodular.
",3. Optimization Algorithm,[0],[0]
Conjecture 3.1.,3. Optimization Algorithm,[0],[0]
"Strong duality holds, i.e.
max y2Y min x2X I(y;x) =",3. Optimization Algorithm,[0],[0]
min x2X max y2Y I(y;x).,3. Optimization Algorithm,[0],[0]
"(11)
",3. Optimization Algorithm,[0],[0]
"If strong duality holds, then the duality gap maxy2Y I(y;x⇤) minx2X I(y⇤;x)",3. Optimization Algorithm,[0],[0]
in Equation (9) is zero at optimality.,3. Optimization Algorithm,[0],[0]
"If I(y;x) were quasiconvex in x, strong duality would hold by Sion’s min-max theorem, but this is not the case.",3. Optimization Algorithm,[0],[0]
"In practice, we observe that the duality gap always converges to zero.
",3. Optimization Algorithm,[0],[0]
"Bach (2015) demonstrates how to minimize a continuous submodular function H(x) subject to box constraints x 2 Box(l, u), up to an arbitrary suboptimality gap "" > 0.",3. Optimization Algorithm,[0],[0]
"The constraint set X in our Robust Budget Allocation problem, however, has box constraints with an additional constraint R(x)  ",3. Optimization Algorithm,[0],[0]
B. This case is not addressed in any previous work.,3. Optimization Algorithm,[0],[0]
"Fortunately, for a large class of functions R, there is still an efficient algorithm for continuous submodular minimization, which we present in the next section.",3. Optimization Algorithm,[0],[0]
"We next address an algorithm for minimizing a monotone continuous submodular function H(x) subject to box constraints x 2 Box(l, u) and a constraint R(x)  ",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"B:
minimize H(x) s.t. R(x)  ",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"B
x 2 Box(l, u).",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"(12)
If H and R were convex, the constrained problem would be equivalent to solving, with the right Lagrange multipler ⇤ 0:
minimize H(x) + ⇤R(x) s.t. x 2",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Box(l, u).",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"(13)
Although H and R are not necessarily convex here, it turns out that a similar approach indeed applies.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"The main idea of our approach bears similarity with (Nagano et al., 2011) for the set function case, but our setting with continuous functions and various uncertainty sets is more general, and requires more argumentation.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"We outline our theoretical results here, and defer further implementation details and proofs to the appendix.
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Following (Bach, 2015), we discretize the problem; for a sufficiently fine discretization, we will achieve arbitrary accuracy.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Let A be an interpolation mapping that maps the
discrete set Qn i=1[ki] into Box(l, u) = Qn
i=1[li, ui] via the componentwise interpolation functions Ai : [ki]!",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"[li, ui].",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"We say Ai is -fine if Ai(xi + 1) Ai(xi)  for all xi 2 {0, 1, . . .",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
", ki 2}, and we say the full interpolation function A is -fine if each Ai is -fine.
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
This mapping yields functions H :,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
Qn i=1[ki] !,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"R and R :
Qn i=1[ki] !",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"R via H (x) = H(A(x)) and R (x) =
R(A(x)).",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
H is lattice submodular (on the integer lattice).,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"This construction leads to a reduction of Problem (12) to a submodular minimization problem over the integer lattice:
minimize H (x) +",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"R (x) s.t. x 2
Qn i=1[ki].
(14)
Ideally, there should then exist a such that the associated minimizer x( ) yields a close to optimal solution for the constrained problem.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Theorem 3.1 below states that this is indeed the case.
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Moreover, a second benefit of submodularity is that we can find the entire solution path for Problem (14) by solving a single optimization problem.
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
Lemma 3.2.,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Suppose H is continuous submodular, and suppose the regularizer R is strictly increasing and separable: R(x) =
Pn i=1",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
Ri(xi).,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Then we can recover a min-
imizer x( ) for the induced discrete Problem (14) for any 2 R by solving a single convex optimization problem.
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
The problem in question arises from a relaxation h# that extends H in each coordinate i to a function on distributions over the domain [ki].,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"These distributions are represented via their inverse cumulative distribution functions ⇢i, which take the coordinate xi as input, and output the probability of exceeding xi.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"The function h# is an analogue of the Lovász extension of set functions to continuous submodular functions (Bach, 2015), it is convex and coincides with H on lattice points.
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Formally, this resulting single optimization problem is:
minimize h#(⇢) +",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Pn
i=1",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Pki 1 ji=1 aixi(⇢i(xi))
s.t. ⇢ 2",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
Qn i=1,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"R ki 1 #
(15)
where Rk# refers to the set of ordered vectors z 2 Rk that satisfy z
1 z 2 · · · zk, the notation ⇢i(xi) denotes the xi-th coordinate of the vector ⇢i, and the aixi are strictly convex functions given by
aixi(t) = 1
2
t2 ·",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
[R i (xi) R i (xi 1)].,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"(16)
Problem (15) can be solved by Frank-Wolfe methods (Frank & Wolfe, 1956; Dunn & Harshbarger, 1978; Lacoste-Julien, 2016; Jaggi, 2013).",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"This is because the greedy algorithm for computing subgradients of the Lovász
extension can be generalized, and yields a linear optimization oracle for the dual of Problem (15).",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"We detail the relationship between Problems (14) and (15), as well as how to implement the Frank-Wolfe methods, in Appendix C.
Let ⇢⇤ be the optimal solution for Problem (15).",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"For any , we obtain a rounded solution x( ) for Problem (14) by thresholding: we set x( )i = max{j | 1  j  ki 1, ⇢⇤i (j) }, or zero if ⇢⇤i (j) < for all j. Each x( 0) is the optimal solution for Problem (14) with = 0.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"We use the largest parameterized solution x( ) that is still feasible, i.e. the solution x( ⇤) where ⇤ solves
min H (x( ))",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"s.t. 0
R (x( ))  ",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"B. (17)
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
This ⇤ can be found efficiently via binary search or a linear scan.,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
Theorem 3.1.,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Let H be continuous submodular and monotone decreasing, with `1-Lipschitz constant G, and let R be strictly increasing and separable.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
Assume all entries ⇢⇤i (j) of the optimal solution ⇢⇤ of Problem (15) are distinct.,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Let x0 = A(x( ⇤)) be the thresholding corresponding to the optimal solution ⇤ of Problem (17), mapped back into the original continuous domain X .",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Then x0 is feasible for the continuous Problem (12), and is a 2G - approximate solution:
H(x0)  2G + min",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"x2Box(l,u), R(x)B H(x).
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Theorem 3.1 implies an algorithm for solving Problem (12) to ""-optimality: (1) set = ""/G, (2) compute ⇢⇤ which solves Problem (15), (3) find the optimal thresholding of ⇢⇤ by determining the smallest ⇤ for which R (x( ⇤))  B, and (4) map",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"x( ⇤) back into continuous space via the interpolation mapping A.
Optimality Bounds.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Theorem 3.1 is proved by comparing x0 and x⇤ to the optimal solution on the discretized mesh
x⇤d 2 argmin x2",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Qn i=1[ki]:R (x)B H (x).
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"Beyond the theoretical guarantee of Theorem 3.1, for any problem instance and candidate solution x0, we can compute a bound on the gap between H(x0) and H (x⇤d).",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"The following two bounds are proved in the appendix:
1.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
We can generate a discrete point x( + ),3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"satisfying
H(x0)  ",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
[H(x0) H (x( + ))],3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"+H (x⇤d).
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
2.,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"The Lagrangian yields the bound
H(x0)  ",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
⇤(B R(x0)),3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"+H (x⇤d).
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
Improvements.,3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"The requirement in Theorem 3.1 that the elements of ⇢⇤ be distinct may seem somewhat restrictive, but as long as ⇢⇤ has distinct elements in the neighborhood of our particular ⇤, this bound still holds.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"We see in Section 4.1.1 that in practice, ⇢⇤ almost always has distinct elements in the regime we care about, and the bounds of Remark 3.1 are very good.
",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"If H is DR-submodular and R is affine in each coordinate, then Problem (14) can be represented more compactly via the reduction of Ene & Nguyen (2016), and hence problem (12) can be solved more efficiently.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
"In particular, the influence function I(y;x) is DR-submodular in x when for each s, y(s) = 0 or y(s) 1.",3.1. Constrained Continuous Submodular Function Minimization,[0],[0]
The above algorithm directly applies to Robust Allocation with the uncertainty sets in Section 2.2.,3.2. Application to Robust Budget Allocation,[0],[0]
"The ellipsoidal uncertainty set XQ corresponds to the constraint that P
(s,t)2E Rst(xst)  with Rst(x) =",3.2. Application to Robust Budget Allocation,[0],[0]
"(xst x̂st)2 2 st , and x 2 Box(0, 1).",3.2. Application to Robust Budget Allocation,[0],[0]
"By the monotonicity of I(x, y), there is never incentive to reduce any xst below x̂st, so we can replace Box(0, 1) with Box(x̂, 1).",3.2. Application to Robust Budget Allocation,[0],[0]
"On this interval, each Rst is strictly increasing, and Theorem 3.1 applies.
",3.2. Application to Robust Budget Allocation,[0],[0]
"For D-norm sets, we have Rst(xst) =",3.2. Application to Robust Budget Allocation,[0],[0]
(xst x̂st)/(ust x̂st).,3.2. Application to Robust Budget Allocation,[0],[0]
"Since each Rst is monotone, Theorem 3.1 applies.
",3.2. Application to Robust Budget Allocation,[0],[0]
Runtime and Alternatives.,3.2. Application to Robust Budget Allocation,[0],[0]
"Since the core algorithm is Frank-Wolfe, it is straightforward to show that Problem (15) can be solved to ""-suboptimality in time",3.2. Application to Robust Budget Allocation,[0],[0]
"O("" 1n2 3↵ 1|T |2 log n 1), where ↵ is the minimum derivative of the functions Ri.",3.2. Application to Robust Budget Allocation,[0],[0]
"If ⇢⇤ has distinct elements separated by ⌘, then choosing "" = ⌘2↵ /8 results in an exact solution to (14) in time O(⌘ 2n2 4↵ 2|T |2 log n 1).
",3.2. Application to Robust Budget Allocation,[0],[0]
"Noting that H + R is submodular for all , one could instead perform binary search over , each time converting the objective into a submodular set function via Birkhoff’s theorem and solving submodular minimization e.g. via one of the recent fast methods (Chakrabarty et al., 2017; Lee et al., 2015).",3.2. Application to Robust Budget Allocation,[0],[0]
"However, we are not aware of a practical implementation of the algorithm in (Lee et al., 2015).",3.2. Application to Robust Budget Allocation,[0],[0]
"The algorithm in (Chakrabarty et al., 2017) yields a solution in expectation.",3.2. Application to Robust Budget Allocation,[0],[0]
"This approach also requires care in the precision of the search over , whereas our approach searches directly over the O(n 1) elements of ⇢⇤.",3.2. Application to Robust Budget Allocation,[0],[0]
We evaluate our Robust Budget Allocation algorithm on both synthetic test data and a real-world bidding dataset from,4. Experiments,[0],[0]
Yahoo! Webscope (yah) to demonstrate that our method yields real improvements.,4. Experiments,[0],[0]
"For all experiments, we
used Algorithm 1 as the outer loop.",4. Experiments,[0],[0]
"For the inner submodular minimization step, we implemented the pairwise Frank-Wolfe algorithm of (Lacoste-Julien & Jaggi, 2015).",4. Experiments,[0],[0]
"In all cases, the feasible set of budgets Y is {y 2 RS
+
:
P
s2S y(s)  C} where the specific budget C depends on the experiment.",4. Experiments,[0],[0]
Our code is available at git.io/vHXkO.,4. Experiments,[0],[0]
"On the synthetic data, we probe two questions: (1) how often does the distinctness condition of Theorem 3.1 hold, so that we are guaranteed an optimal solution; and (2) what is the gain of using a robust versus non-robust solution in an adversarial setting?",4.1. Synthetic,[0],[0]
"For both settings, we set |S| = 6 and |T | = 2 and discretize with = 0.001.",4.1. Synthetic,[0],[0]
"We generated true probabilties pst, created Beta posteriors, and built both Ellipsoidal uncertainty sets XQ( ) and D-norm sets XD( ).",4.1. Synthetic,[0],[0]
"Theorem 3.1 and Remark 3.1 demand that the values ⇢⇤i (j) be distinct at our chosen Lagrange multiplier ⇤ and, under this condition, guarantee optimality.",4.1.1. OPTIMALITY,[0],[0]
"We illustrate this in four examples: for Ellipsoidal or a D-norm uncertainty set, and a total influence budget C 2 {0.4, 4}.",4.1.1. OPTIMALITY,[0],[0]
"Figure 3 shows all elements of ⇢⇤ in sorted order, as well as a horizontal line indicating our Lagrange multiplier ⇤ which serves as a threshold.",4.1.1. OPTIMALITY,[0],[0]
"Despite some plateaus, the entries ⇢⇤i (j) are distinct in most regimes, in particular around ⇤, the regime that is needed for our results.",4.1.1. OPTIMALITY,[0],[0]
"Moreover, in practice (on the Yahoo data) we observe later in Figure 3 that both solutiondependent bounds from Remark 3.1 are very good, and all solutions are optimal within a very small gap.",4.1.1. OPTIMALITY,[0],[0]
"Next, we probe the effect of a robust versus non-robust solution for different uncertainty sets and budgets of the adversary.",4.1.2. ROBUSTNESS AND QUALITY,[0],[0]
"We compare our robust solution with using a point estimate for x, i.e., y
nom 2 argmaxy2Y I(y; x̂), treating estimates as ground truth, and the stochastic solution y
expect 2 argmaxy2Y E[I(y;X)] as per Section 2.1.",4.1.2. ROBUSTNESS AND QUALITY,[0],[0]
"These two optimization problems were solved via standard first-order methods using TFOCS (Becker et al., 2011).
",4.1.2. ROBUSTNESS AND QUALITY,[0],[0]
"Figure 2 demonstrates that indeed, the alternative budgets are sensitive to the adversary and the robustly-chosen budget y
robust performs better, even in cases where the other budgets achieve zero influence.",4.1.2. ROBUSTNESS AND QUALITY,[0],[0]
"When the total budget C is large, y
expect performs nearly as well as y robust , but when resources are scarce (C is small) and the actual choice seems to matter more, y
robust
performs far better.",4.1.2. ROBUSTNESS AND QUALITY,[0],[0]
"To evaluate our method on real-world data, we formulate a Budget Allocation instance on advertiser bidding data from Yahoo! Webscope (yah).",4.2. Yahoo! data,[0],[0]
This dataset logs bids on 1000 different phrases by advertising accounts.,4.2. Yahoo! data,[0],[0]
"We map the phrases to channels S and the accounts to customers T , with an edge between s and t if a corresponding bid was made.",4.2. Yahoo! data,[0],[0]
"For each pair (s, t), we draw the associated transmission probability pst uniformly from [0, 0.4].",4.2. Yahoo! data,[0],[0]
We bias these towards zero because we expect people not to be easily influenced by advertising in the real world.,4.2. Yahoo! data,[0],[0]
"We then generate an estimate p̂st and build up a posterior by gener-
ating nst samples from Ber(pst), where nst is the number of bids between s and t in the dataset.
",4.2. Yahoo! data,[0],[0]
"This transformation yields a bipartite graph with |S| = 1000, |T | = 10475, and more than 50,000 edges that we use for Budget Allocation.",4.2. Yahoo! data,[0],[0]
"In our experiments, the typical gap between the naive y
nom and robust y robust was 100- 500 expected influenced people.",4.2. Yahoo! data,[0],[0]
"We plot convergence of the outer loop in Figure 3, where we observe fast convergence of both primal influence value and the dual bound.",4.2. Yahoo! data,[0],[0]
"Given the success of first-order methods on nonconvex problems in practice, it is natural to compare these to our method for finding the worst-case vector x. On one of our Yahoo problem instances with D-norm uncertainty set, we compared our submodular minimization scheme to FrankWolfe with fixed stepsize as in (Lacoste-Julien, 2016), implementing the linear oracle using MOSEK (MOSEK ApS, 2015).",4.3. Comparison to first-order methods,[0],[0]
"Interestingly, from various initializations, FrankWolfe finds an optimal solution, as verified by comparing to the guaranteed solution of our algorithm.",4.3. Comparison to first-order methods,[0],[0]
"Note that, due to non-convexity, there are no formal guarantees for FrankWolfe to be optimal here, motivating the question of global convergence properties of Frank-Wolfe in the presence of submodularity.
",4.3. Comparison to first-order methods,[0],[0]
It is important to note that there are many cases where firstorder methods are inefficient or do not apply to our setup.,4.3. Comparison to first-order methods,[0],[0]
"These methods require either a projection oracle (PO) onto or linear optimization oracle (LO) over the feasible set X defined by `, u and R(x).",4.3. Comparison to first-order methods,[0],[0]
"The D-norm set admits a LO via linear programming, but we are not aware of any efficient LO for Ellipsoidal uncertainty, nor PO for either set, that does not require quadratic programming.",4.3. Comparison to first-order methods,[0],[0]
"Even more, our algorithm applies for nonconvex functions R(x) which induce nonconvex feasible sets X .",4.3. Comparison to first-order methods,[0],[0]
"Such nonconvex sets may not even admit a unique projection, while our algorithm achieves provable solutions.",4.3. Comparison to first-order methods,[0],[0]
"We address the issue of uncertain parameters (or, model misspecification) in Budget Allocation or Bipartite Influence Maximization (Alon et al., 2012) from a robust optimization perspective.",5. Conclusion,[0],[0]
The resulting Robust Budget Allocation is a nonconvex-concave saddle point problem.,5. Conclusion,[0],[0]
"Although the inner optimization problem is nonconvex, we show how continuous submodularity can be leveraged to solve the problem to arbitrary accuracy "", as can be verified with the proposed bounds on the duality gap.",5. Conclusion,[0],[0]
"In particular, our approach extends continuous submodular minimization methods (Bach, 2015) to more general constraint sets, introducing a mechanism to solve a new class of constrained nonconvex optimization problems.",5. Conclusion,[0],[0]
"We confirm on synthetic and real data that our method finds high-quality solutions that are robust to parameters varying arbitrarily in an uncertainty set, and scales up to graphs with over 50,000 edges.
",5. Conclusion,[0],[0]
There are many compelling directions for further study.,5. Conclusion,[0],[0]
"The uncertainty sets we use are standard in the robust optimization literature, but have not been applied to e.g. Robust Influence Maximization; it would be interesting to generalize our ideas to general graphs.",5. Conclusion,[0],[0]
"Finally, despite the inherent nonconvexity of our problem, first-order methods are often able to find a globally optimal solution.",5. Conclusion,[0],[0]
Explaining this phenomenon requires further study of the geometry of constrained monotone submodular minimization.,5. Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful suggestions.,Acknowledgements,[0],[0]
We also thank MIT Supercloud and the Lincoln Laboratory Supercomputing Center for providing computational resources.,Acknowledgements,[0],[0]
"This research was conducted with Government support under and awarded by DoD, Air Force Office of Scientific Research, National Defense Science and Engineering Graduate (NDSEG) Fellowship, 32 CFR 168a, and also supported by NSF CAREER award 1553284.",Acknowledgements,[0],[0]
"The optimal allocation of resources for maximizing influence, spread of information or coverage, has gained attention in the past years, in particular in machine learning and data mining.",abstractText,[0],[0]
"But in applications, the parameters of the problem are rarely known exactly, and using wrong parameters can lead to undesirable outcomes.",abstractText,[0],[0]
"We hence revisit a continuous version of the Budget Allocation or Bipartite Influence Maximization problem introduced by Alon et al. (2012) from a robust optimization perspective, where an adversary may choose the least favorable parameters within a confidence set.",abstractText,[0],[0]
The resulting problem is a nonconvex-concave saddle point problem (or game).,abstractText,[0],[0]
"We show that this nonconvex problem can be solved exactly by leveraging connections to continuous submodular functions, and by solving a constrained submodular minimization problem.",abstractText,[0],[0]
"Although constrained submodular minimization is hard in general, here, we establish conditions under which such a problem can be solved to arbitrary precision ✏.",abstractText,[0],[0]
Robust Budget Allocation via Continuous Submodular Functions,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 607–618 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Translation helps identify correspondences in bilingual texts, but other asymmetric semantic relationships can improve language understanding when translations are not exactly equivalent.",1 Introduction,[0],[0]
"One such relationship is cross-lingual hypernymy – identifying that écureuil (“squirrel” in French) is a kind of rodent, or ворона (“crow” in Russian) is a kind of bird.",1 Introduction,[0],[0]
"The ability to detect hypernyms across languages serves as a building block in a range of cross-lingual tasks, including Recognizing Textual Entailment (RTE) (Negri et al., 2012,
∗ These authors contributed equally.",1 Introduction,[0],[0]
"1https://github.com/yogarshi/
bisparse-dep/
2013), constructing multilingual taxonomies (Fu et al., 2014), event coreference across multilingual news sources (Vossen et al., 2015), and evaluating Machine Translation output (Padó et al., 2009).
",1 Introduction,[0],[0]
"Building models that can robustly identify hypernymy across the spectrum of human languages is a challenging problem, that is further compounded in low resource settings.",1 Introduction,[0],[0]
"At first glance, translating words to English and then identifying hypernyms in a monolingual setting may appear to be a sufficient solution.",1 Introduction,[0],[0]
"However, this approach cannot capture many phenomena.",1 Introduction,[0],[0]
"For instance, the English words cook, leader and supervisor can all be hypernyms of the French word chef, as the French word does not have a exact translation in English covering its possible usages.",1 Introduction,[0],[0]
"However, translating chef to cook and then determining hypernymy monolingually precludes identifying leader or supervisor as a hypernyms of chef.",1 Introduction,[0],[0]
"Similarly, language-specific usage patterns can also influence hypernymy decisions.",1 Introduction,[0],[0]
"For instance, the French word chroniqueur translates to chronicler in English, but is more frequently used in French to refer to journalists (making journalist its hypernym).2
This motivates approaches that directly detect hypernymy in the cross-lingual setting by extending distributional methods for detecting monolingual hypernymy, as in our prior work (Vyas and Carpuat, 2016).",1 Introduction,[0],[0]
"State-of-the-art distributional approaches (Roller and Erk, 2016; Shwartz et al., 2017) for detecting monolingual hypernymy require syntactic analysis (eg. dependency parsing), which may not available for many languages.",1 Introduction,[0],[0]
"Additionally, limited training resources make unsupervised methods more desirable than supervised hypernymy detection approaches (Roller and Erk,
2All examples are from our dataset.
",1 Introduction,[0],[0]
"607
2016)",1 Introduction,[0],[0]
.,1 Introduction,[0],[0]
"Furthermore, monolingual distributional approaches cannot be applied directly to the crosslingual task, because the vector spaces of two languages need to be aligned using a cross-lingual resource (a bilingual dictionary, for instance).
",1 Introduction,[0],[0]
"We tackle these challenges by proposing BISPARSE-DEP - a family of robust, unsupervised approaches for identifying cross-lingual hypernymy.",1 Introduction,[0],[0]
BISPARSE-DEP uses a cross-lingual word embedding model learned from a small bilingual dictionary and a variety of monolingual syntactic context extracted from a dependency parsed corpus.,1 Introduction,[0],[0]
BISPARSE-DEP exhibits robust behavior along multiple dimensions.,1 Introduction,[0],[0]
"In the absence of a dependency treebank for a language, it can learn embeddings using a parser trained on related languages.",1 Introduction,[0],[0]
"When exposed to less monolingual data, or a lower quality bilingual dictionary, BISPARSEDEP degrades only marginally.",1 Introduction,[0],[0]
"In all these cases, it compares favorably with models that have been supplied with all necessary resources, showing promise for low-resource settings.",1 Introduction,[0],[0]
"We extensively evaluate BISPARSE-DEP on a new crowd-sourced cross-lingual dataset, with over 2900 hypernym pairs, spanning four languages from distinct families – French, Russian, Arabic and Chinese – and release the datasets for future evaluations.",1 Introduction,[0],[0]
"Cross-lingual Distributional Semantics Cross-lingual word embeddings have been shown to encode semantics across languages in tasks such as word similarity (Faruqui and Dyer, 2014) and lexicon induction (Vulić and Moens, 2015).",2 Related Work,[0],[0]
"Our works stands apart in two aspects (1) In contrast to tasks involving similarity and synonymy (symmetric relations), the focus of our work is on detecting asymmetric relations across languages, using cross-lingual embeddings.",2 Related Work,[0],[0]
"(2) Unlike most previous work, we use dependency context instead of lexical context to induce crosslingual embeddings, which allows us to abstract away from language specific word order, and (as we show) improves hypernymy detection.
",2 Related Work,[0],[0]
"More closely related is our prior work (Vyas and Carpuat, 2016) where we used lexical context based embeddings to detect cross-lingual lexical entailment.",2 Related Work,[0],[0]
"In contrast, the focus of this work is on hypernymy, a more well-defined relation than entailment.",2 Related Work,[0],[0]
"Also, we improve upon our previous approach by using dependency based embeddings (§6.1), and show that the improvements hold even when exposed to data scarce settings (§6.3).
",2 Related Work,[0],[0]
"We also do a more comprehensive evaluation on four languages paired with English, instead of just French.
",2 Related Work,[0],[0]
"Dependency Based Embeddings In monolingual settings, dependency based embeddings have been shown to outperform window based embeddings on many tasks (Bansal et al., 2014; Hill et al., 2014; Melamud et al., 2016).",2 Related Work,[0],[0]
"Roller and Erk (2016) showed that dependency embeddings can help in recovering Hearst patterns (Hearst, 1992) like “animals such as cats”, which are known to be indicative of hypernymy.",2 Related Work,[0],[0]
Shwartz et al. (2017) demonstrated that dependency based embeddings are almost always superior to window based embeddings for identifying hypernyms in English.,2 Related Work,[0],[0]
"Our work uses dependency based embeddings in a cross-lingual setting, a less explored research direction.",2 Related Work,[0],[0]
A key novelty of our work also lies in its use of syntactic transfer to derive dependency contexts.,2 Related Work,[0],[0]
"This scenario is more relevant in a cross-lingual setting, where treebanks might not be available for many languages.
",2 Related Work,[0],[0]
"3 Our Approach – BISPARSE-DEP
We propose BISPARSE-DEP, a family of approaches that uses sparse, bilingual, dependency based word embeddings to identify cross-lingual hypernymy.
",2 Related Work,[0],[0]
Figure 1 shows an overview of the end-toend pipeline of BISPARSE-DEP.,2 Related Work,[0],[0]
"The two key components of this pipeline are: (1) Dependency based contexts (§3.1), which help us generalize across languages with minimal customization by abstracting away language-specific word order.",2 Related Work,[0],[0]
We also discuss how to extract such contexts in the absence of a treebank in the language (§3.2) using a (weak) dependency parser trained on related languages.,2 Related Work,[0],[0]
"(2) Bilingual sparse coding (§3.3), which allows us to align dependency based word embeddings in a shared semantic space using a small bilingual dictionary.",2 Related Work,[0],[0]
The resulting sparse bilingual embeddings can then be used with a unsupervised entailment scorer (§3.4) to predict hypernymy for cross-lingual word pairs.,2 Related Work,[0],[0]
The context of a word can be described in multiple ways using its syntactic neighborhood in a dependency graph.,3.1 Dependency Based Context Extraction,[0],[0]
"For instance, in Figure 2, we describe the context for a target word (traveler) in the following two ways:
• FULL context (Padó and Lapata, 2007; Baroni and Lenci, 2010; Levy and Goldberg, 2014): Children and parent words, concatenated with the label and direction of the relation (eg. roamed#nsubj−1 and tired#amod are contexts for traveler).",3.1 Dependency Based Context Extraction,[0],[0]
•,3.1 Dependency Based Context Extraction,[0],[0]
"JOINT context (Chersoni et al., 2016): Par-
ent concatenated with each of its siblings (eg. roamed#desert and roamed#seeking are contexts for traveler).
",3.1 Dependency Based Context Extraction,[0],[0]
"These two contexts exploit different amounts of syntactic information – JOINT does not require labeled parses, unlike FULL.",3.1 Dependency Based Context Extraction,[0],[0]
"The JOINT context combines parent and sibling information, while FULL keeps them as distinct contexts.",3.1 Dependency Based Context Extraction,[0],[0]
"Both encode directionality into the context, either through label direction or through sibling-parent relations.
",3.1 Dependency Based Context Extraction,[0],[0]
We use word-context co-occurrences generated using these contexts in a distributional semantic model (DSM) in lieu of window based contexts to generate dependency based embeddings.,3.1 Dependency Based Context Extraction,[0],[0]
"Using dependency contexts in multilingual settings may not always be possible, as dependency treebanks are not available for many languages.",3.2 Dependency Contexts without a Treebank,[0],[0]
"To circumvent this issue, we use related languages to train a weak dependency parser.
",3.2 Dependency Contexts without a Treebank,[0],[0]
"We train a delexicalized parser using treebanks of related languages, where the word form based
features are turned off, so that the parser is trained on purely non-lexical features (e.g. POS tags).",3.2 Dependency Contexts without a Treebank,[0],[0]
"The rationale behind this is that related languages show common syntactic structure that can be transferred to the original language, with delexicalized parsing (Zeman and Resnik, 2008; McDonald et al., 2011, inter alia) being one popular approach.3",3.2 Dependency Contexts without a Treebank,[0],[0]
"Given a dependency based co-occurrence matrix described in the previous section(s), we generate BISPARSE-DEP embeddings using the framework from our prior work (Vyas and Carpuat, 2016), which we henceforth call BISPARSE.",3.3 Bilingual Sparse Coding,[0],[0]
"BISPARSE generates sparse, bilingual word embeddings using a dictionary learning objective with a sparsity inducing l1 penalty.",3.3 Bilingual Sparse Coding,[0],[0]
"We give a brief overview of this approach, the full details of which can be found in our prior work.
",3.3 Bilingual Sparse Coding,[0],[0]
"For two languages with vocabularies ve and vf , and monolingual dependency embeddings",3.3 Bilingual Sparse Coding,[0],[0]
"Xe and Xf , BISPARSE solves the following objective:
argmin Ae,De,Af ,Df
ve∑
i=1
1 2 ||AeiDeT",3.3 Bilingual Sparse Coding,[0],[0]
−Xei||22,3.3 Bilingual Sparse Coding,[0],[0]
"+λe||Aei||1
+
vf∑
j=1
1 2 ||Af jDfT −Xf j ||22 +λf ||Af j ||1
+ ∑
i,j
1 2 λxSij ||Aei −Af j ||22 (1)
s.t.",3.3 Bilingual Sparse Coding,[0],[0]
Ak > 0,3.3 Bilingual Sparse Coding,[0],[0]
"‖Dki‖22≤ 1 k ∈ {e, f}
where S is a translation matrix, and Ae and Af 3More sophisticated techniques for transferring syntactic knowledge have been proposed (Ammar et al., 2016; Rasooli and Collins, 2017), but we prioritize simplicity and show that a simple delexicalized parser is effective.
are sparse matrices which are bilingual representations in a shared semantic space.",3.3 Bilingual Sparse Coding,[0],[0]
The translation matrix S (of size ve×vf ) captures correspondences between the vocabularies (of size ve and vf ) of two languages.,3.3 Bilingual Sparse Coding,[0],[0]
"For instance, each row of S can be a one-hot vector that identifies the word in f that is most frequently aligned with the e word for that row in a large parallel corpus, thus building a one-to-many mapping between the two languages.",3.3 Bilingual Sparse Coding,[0],[0]
"A variety of scorers can be used to quantify the directional relationship between two words, given feature representations of these words (Lin, 1998; Weeds and Weir, 2003; Lenci and Benotto, 2012).",3.4 Unsupervised Entailment Scorer,[0],[0]
"Once the BISPARSE-DEP embeddings are constructed, we use BalAPinc",3.4 Unsupervised Entailment Scorer,[0],[0]
"(Kotlerman et al., 2009) to score word pairs for hypernymy.",3.4 Unsupervised Entailment Scorer,[0],[0]
"BalAPinc is based on the distributional inclusion hypothesis (Geffet and Dagan, 2005) and computes the geometric mean of 1) LIN (Lin, 1998), a symmetric score that captures similarity, and 2) APinc, an asymmetric score based on average precision.",3.4 Unsupervised Entailment Scorer,[0],[0]
There is no publicly available dataset to evaluate models of hypernymy detection across multiple languages.,4 Crowd-Sourcing Annotations,[0],[0]
"While ontologies like Open Multilingual WordNet (OMW) (Bond and Foster, 2013) and BabelNet (Navigli and Ponzetto, 2012) contain cross-lingual links, these resources are semiautomatically generated and hence contain noisy edges.",4 Crowd-Sourcing Annotations,[0],[0]
"Thus, to get reliable and high-quality test beds, we collect evaluation datasets using CrowdFlower4.",4 Crowd-Sourcing Annotations,[0],[0]
"Our datasets span four languages from distinct families - French (Fr), Russian (Ru), Arabic (Ar) and Chinese (Zh) - paired with English.
",4 Crowd-Sourcing Annotations,[0],[0]
"To begin the annotation process, we first pool candidate pairs using hypernymy edges across languages from OMW and BabelNet, along with translations from monolingual hypernymy datasets (Baroni and Lenci, 2011; Baroni et al., 2012; Kotlerman et al., 2010).",4 Crowd-Sourcing Annotations,[0],[0]
The annotation task requires annotators to be fluent in both English and the non-English language.,4.1 Annotation Setup,[0],[0]
"To ensure only fluent speakers perform the task, for each language, we provide task instructions in the non-English language itself.",4.1 Annotation Setup,[0],[0]
"Also, we restrict the task to annotators verified by CrowdFlower to have those language skills.",4.1 Annotation Setup,[0],[0]
"Finally, annotators also
4http://crowdflower.com
need to pass a quiz based on a small amount of gold standard data to gain access to the task.
",4.1 Annotation Setup,[0],[0]
"Annotators choose between three options for each word pair (pf , qe), where pf is a non-English word and qe is a English word : “pf is a kind of qe”, “qe is a part of pf” and “none of the above”.",4.1 Annotation Setup,[0],[0]
Word pairs labeled with the first option are considered as positive examples while those labeled as “none of the above” are considered as negative.5 The second option was included to filter out meronymy examples that were part of the noisy pool.,4.1 Annotation Setup,[0],[0]
"We leave it to the annotator to infer whether the relation holds between any senses of pf or qe, if either of them are polysemous.
",4.1 Annotation Setup,[0],[0]
"For every candidate hypernym pair (pf , qe), we also ask annotators to judge its reversed and translated hyponym pair (qf , pe).",4.1 Annotation Setup,[0],[0]
"For instance, if (citron, food) is a hypernym candidate, we also show annotators (aliments, lemon) which is a potential hyponym candidate (potential, because as mentioned in §1, translation need not preserve semantic relationships).",4.1 Annotation Setup,[0],[0]
"The purpose of presenting the hyponym pair, (qf , pe), is two-fold.",4.1 Annotation Setup,[0],[0]
"First, it emphasizes the directional nature of the task.",4.1 Annotation Setup,[0],[0]
"Second, it identifies hyponym pairs, which we use as negative examples.",4.1 Annotation Setup,[0],[0]
"The hyponym pairs are challenging since differentiating them from hypernyms truly requires detecting asymmetry.
",4.1 Annotation Setup,[0],[0]
"Each pair was judged by at least 5 annotators, and judgments with 80% agreement (at least 4 annotators agree) are considered for the final dataset.",4.1 Annotation Setup,[0],[0]
"This is a stricter condition than certain monolingual hypernymy datasets - for instance, EVALution (Santus et al., 2015) - where agreement by 3 annotators is deemed sufficient.",4.1 Annotation Setup,[0],[0]
"Inter-annotator agreement measured using Fleiss’ Kappa (Fleiss, 1971) was 58.1 (French), 53.7 (Russian), 53.2 (Arabic) and 55.8 (Chinese).",4.1 Annotation Setup,[0],[0]
"This indicates moderate agreement, on par with agreement obtained on related fine-grained semantic tasks (Pavlick et al., 2015).",4.1 Annotation Setup,[0],[0]
"We cannot compare with monolin-
5We collected more negative pairs than positive, but sampled so as to keep a balanced dataset for ease of evaluation.",4.1 Annotation Setup,[0],[0]
"We will release all annotated pairs along with the dataset.
gual hypernymy annotator agreement as, to the best of our knowledge, such numbers are not available for existing test sets.",4.1 Annotation Setup,[0],[0]
"Dataset statistics are shown in Table 1.
",4.1 Annotation Setup,[0],[0]
We observed that annotators were able to agree on pairs containing polysemous words where hypernymy holds for some sense.,4.1 Annotation Setup,[0],[0]
"For instance, for the French-English pair (avocat, professional), the French word avocat can either mean lawyer or avocado, but the pair was annotated as a positive example.",4.1 Annotation Setup,[0],[0]
"Hence, we leave it to the annotators to handle polysemy by choosing the most appropriate sense.",4.1 Annotation Setup,[0],[0]
To verify if the crowdsourced hyponyms are challenging negative examples we create two evaluation sets.,4.2 Two Evaluation Test Sets,[0],[0]
"Both share the (crowdsourced) positive examples, but differ in their negatives:
• HYPER-HYPO – negative examples are the crowdsourced hyponyms.",4.2 Two Evaluation Test Sets,[0],[0]
"• HYPER-COHYPO – negative examples are
cohyponyms drawn from OMW.
",4.2 Two Evaluation Test Sets,[0],[0]
Cohyponyms are words sharing a common hypernym.,4.2 Two Evaluation Test Sets,[0],[0]
"For instance, bière (“beer” in French) and vodka are cohyponyms since they share a common hypernym in alcool/alcohol.",4.2 Two Evaluation Test Sets,[0],[0]
We choose cohyponyms for the second test set because: (a) They require differentiating between similarity (a symmetric relation) and hypernymy (an asymmetric relation).,4.2 Two Evaluation Test Sets,[0],[0]
"For instance, bière and vodka are highly similar yet, they do not have a hypernymy relationship.",4.2 Two Evaluation Test Sets,[0],[0]
"(b) Cohyponyms are a popular choice of negative examples in many entailment datasets (Baroni and Lenci, 2011).",4.2 Two Evaluation Test Sets,[0],[0]
"Training BISPARSE-DEP requires a dependency parsed monolingual corpus, and a translation matrix for jointly aligning the monolingual vectors.",5.1 Data and Evaluation Setup,[0],[0]
We compute the translation matrix using word alignments derived from parallel corpora (see corpus statistics in Table ??).,5.1 Data and Evaluation Setup,[0],[0]
"While we use parallel corpora to generate the translation matrix to be comparable to baselines (§5.2), we can obtain the matrix from any bilingual dictionary.
",5.1 Data and Evaluation Setup,[0],[0]
"The monolingual corpora are parsed using Yara Parser (Rasooli and Tetreault, 2015), trained on the corresponding treebank from the Universal Dependency Treebank (McDonald et al., 2013) (UDT-v1.4).",5.1 Data and Evaluation Setup,[0],[0]
"Yara Parser was
chosen as it is fast, and competitive with stateof-the-art parsers (Choi et al., 2015).",5.1 Data and Evaluation Setup,[0],[0]
"The monolingual corpora was POS-tagged using TurboTagger (Martins et al., 2013).",5.1 Data and Evaluation Setup,[0],[0]
"We induce dependency contexts for words by first thresholding the language vocabulary to the top 50,000 nouns, verbs and adjectives.",5.1 Data and Evaluation Setup,[0],[0]
A co-occurrence matrix is computed over this vocabulary using the context types in §3.1.,5.1 Data and Evaluation Setup,[0],[0]
"Inducing Dependency Contexts The entries of the word-context co-occurrence matrix are reweighted using Positive Pointwise Mutual Information (Bullinaria and Levy, 2007).",5.1 Data and Evaluation Setup,[0],[0]
"The resulting matrix is reduced to 1000 dimensions using SVD (Golub and Kahan, 1965).6 These vectors are used as Xe,Xf in the setup from §3.3 to generate 100 dimensional sparse bilingual vectors.
",5.1 Data and Evaluation Setup,[0],[0]
"Evaluation We use accuracy as our evaluation metric, as it is easy to interpret when the classes are balanced (Turney and Mohammad, 2015).",5.1 Data and Evaluation Setup,[0],[0]
Both evaluation datasets – HYPER-HYPO and HYPER-COHYPO – are split into 1:2 dev/test splits.,5.1 Data and Evaluation Setup,[0],[0]
"BalAPinc has two tunable parameters - 1) a threshold that indicates the BalAPinc score above which all examples are labeled as positive, 2) the maximum number of features to consider for each word.",5.1 Data and Evaluation Setup,[0],[0]
We use the tuning set to tune the two parameters as well as the various hyper-parameters associated with the models.,5.1 Data and Evaluation Setup,[0],[0]
"We compare our BISPARSE-DEP embeddings with the following approaches:
MONO-DEP (Translation baseline) For word pair (pf , qe) in test data, we translate pf to English using the most common translation in the translation matrix.",5.2 Contrastive Approaches,[0],[0]
"Hypernymy is then determined using sparse, dependency based embeddings in English.
",5.2 Contrastive Approaches,[0],[0]
"BISPARSE-LEX (Window context) Predecessor of the BISPARSE-DEP model from our previous work (Vyas and Carpuat, 2016).",5.2 Contrastive Approaches,[0],[0]
"This model induces sparse, cross-lingual embeddings using window based context.
BIVEC+ (Window context)",5.2 Contrastive Approaches,[0],[0]
Our extension of the BIVEC model of Luong et al. (2015).,5.2 Contrastive Approaches,[0],[0]
"BIVEC generates dense, cross-lingual embeddings using window based context, by substituting aligned word pairs within a window in parallel sentences.",5.2 Contrastive Approaches,[0],[0]
"By default, BIVEC only trains using parallel data,
6Chosen based on preliminary experiments with {500,1000,2000,3000} dimensional vectors for En-Fr.
and so we initialize it with monolingually trained window based embeddings to ensure fair comparison.
",5.2 Contrastive Approaches,[0],[0]
CL-DEP (Dependency context),5.2 Contrastive Approaches,[0],[0]
"The model from Vulić (2017), which induces dense, dependency based cross-lingual embeddings by translating syntactic word-context pairs using the most common translation, and jointly training a word2vecf7 model for both languages.",5.2 Contrastive Approaches,[0],[0]
Vulić (2017) showed improvements for word similarity and bilingual lexicon induction.,5.2 Contrastive Approaches,[0],[0]
"We report the first results using CL-DEP on this task.
",5.2 Contrastive Approaches,[0],[0]
"5.3 Evaluating Robustness of BISPARSE-DEP
We investigate how robust BISPARSE-DEP is when exposed to data scarce settings.",5.2 Contrastive Approaches,[0],[0]
Evaluating on a truly low resource language is complicated by the fact that obtaining an evaluation dataset for such a language is difficult.,5.2 Contrastive Approaches,[0],[0]
"Therefore, we simulate such settings for the languages in our dataset in multiple ways.
",5.2 Contrastive Approaches,[0],[0]
No Treebank,5.2 Contrastive Approaches,[0],[0]
"If a treebank is not available for a language, dependency contexts have to be induced using treebanks from other languages (§3.2), which can affect the quality of the dependencybased embeddings.",5.2 Contrastive Approaches,[0],[0]
"To simulate this, we train a delexicalized parser for the languages in our dataset.",5.2 Contrastive Approaches,[0],[0]
"We use treebanks from Slovenian, Ukrainian, Serbian, Polish, Bulgarian, Slovak and Czech (40k sentences) for training the Russian parser, and treebanks from English, Spanish, German, Portuguese, Swedish and Italian (66k sentences) for training the French parser.",5.2 Contrastive Approaches,[0],[0]
"UDT does not (yet) have languages in the same family as Arabic or Chinese, so for the sake of completeness, we train Arabic and Chinese parsers on delexicalized treebanks of the language itself.",5.2 Contrastive Approaches,[0],[0]
"Af-
7bitbucket.org/yoavgo/word2vecf/
ter delexicalized training, the Labeled Attachment Score (LAS) on the UDT test set dropped by several points for all languages – from 76.6% to 60.0% for Russian, 83.7% to 71.1% for French, from 76.3% to 62.4% for Arabic and from 80.3% to 53.3% for Chinese.",5.2 Contrastive Approaches,[0],[0]
"The monolingual corpora are then parsed with these weaker parsers, and coocurrences and dependency contexts are computed as before.
",5.2 Contrastive Approaches,[0],[0]
"Subsampling Monolingual Data To simulate low-resource behavior along another axis, we subsample the monolingual corpora used by BISPARSE-DEP to induce monolingual vectors, Xe,Xf .",5.2 Contrastive Approaches,[0],[0]
"Specifically, we learn Xe and Xf using progressively smaller corpora.
",5.2 Contrastive Approaches,[0],[0]
Quality of Bilingual Dictionary We study the impact of the quality of the bilingual dictionary used to create the translation matrix S.,5.2 Contrastive Approaches,[0],[0]
This experiment involves using increasingly smaller parallel corpora to induce the translation dictionary.,5.2 Contrastive Approaches,[0],[0]
We aim to answer the following questions – (a) Are dependency based embeddings superior to window based embeddings for identifying crosslingual hypernymy?,6 Experiments,[0],[0]
(§6.1) (b) Does directionality in the dependency context help cross-lingual hypernymy identification?,6 Experiments,[0],[0]
(§6.2) (c) Are our models robust in data scarce settings (§6.3)?,6 Experiments,[0],[0]
(d) Is the answer to (a) predicated on the choice of entailment scorer?,6 Experiments,[0],[0]
(§6.4)?,6 Experiments,[0],[0]
We compare the performance of models described in §5.2 with the BISPARSE-DEP (FULL and JOINT) models.,6.1 Dependency v/s Window Contexts,[0],[0]
"We evaluate the models on the two test splits described in §4.2 – HYPERHYPO and HYPER-COHYPO.
",6.1 Dependency v/s Window Contexts,[0],[0]
Hyper-Hypo Results Table 3a shows the results on HYPER-HYPO.,6.1 Dependency v/s Window Contexts,[0],[0]
"First, the benefit of crosslingual modeling (as opposed to translation) is evident in that almost all models (except CL-DEP on French) outperform the translation baseline.",6.1 Dependency v/s Window Contexts,[0],[0]
"Among dependency based models, BISPARSEDEP (FULL) and CL-DEP consistently outperform both window models, while BISPARSE-DEP (JOINT) outperforms them on all except Russian.",6.1 Dependency v/s Window Contexts,[0],[0]
"BISPARSE-DEP (JOINT) is the best model overall for two languages (French and Chinese), CL-DEP for one (Arabic), with no statistically significant differences between BISPARSE-DEP (JOINT) and CL-DEP for Russian.",6.1 Dependency v/s Window Contexts,[0],[0]
"This confirms that dependency context is more useful than window context for cross-lingual hypernymy detection.
",6.1 Dependency v/s Window Contexts,[0],[0]
"Hyper-Cohypo Results The trends observed on HYPER-HYPO also hold on HYPER-COHYPO i.e. dependency based models continue to outperform window based models (Table 3b).
",6.1 Dependency v/s Window Contexts,[0],[0]
"Overall, BISPARSE-DEP (FULL) performs best in this setting, followed closely by BISPARSEDEP (JOINT).",6.1 Dependency v/s Window Contexts,[0],[0]
"This suggests that the sibling information encoded in JOINT is useful to distinguish hypernyms from hyponyms (HYPER-HYPO results), while the dependency labels encoded in FULL help to distinguish hypernyms from cohyponyms.",6.1 Dependency v/s Window Contexts,[0],[0]
"Also note that all models improve significantly on the HYPER-COHYPO set, suggesting that discriminating hypernyms from cohyponyms is easier than discriminating them from hyponyms.
",6.1 Dependency v/s Window Contexts,[0],[0]
"While the BISPARSE-DEP models were generally performing better than window models on both test sets, CL-DEP was not as consistent (e.g.,
it was worse than the best window model on HYPER-COHYPO).",6.1 Dependency v/s Window Contexts,[0],[0]
"As shown by Turney and Mohammad (2015), BalAPinc is designed for sparse embeddings and is likely to perform poorly with dense embeddings.",6.1 Dependency v/s Window Contexts,[0],[0]
"This explains the relatively inconsistent performance of CL-DEP.
",6.1 Dependency v/s Window Contexts,[0],[0]
"Besides establishing the challenging nature of our crowd-sourced set, the experiments on HYPER-COHYPO and HYPER-HYPO also demonstrate the ability of the BISPARSE-DEP models to discriminate between different lexical semantic relations (viz. hypernymy and cohyponymy) in a cross-lingual setting.",6.1 Dependency v/s Window Contexts,[0],[0]
We will investigate this ability more carefully in future work.,6.1 Dependency v/s Window Contexts,[0],[0]
"The context described by the FULL and JOINT BISPARSE models encodes directional information (§3.1) either in the form of label direction (FULL), or using sibling information (JOINT).",6.2 Ablating Directionality in Context,[0],[0]
Does such directionality in the context help to capture the asymmetric relationship inherent to hypernymy?,6.2 Ablating Directionality in Context,[0],[0]
"To answer this, we evaluate a third BISPARSE-DEP model which uses UNLABELED dependency contexts.",6.2 Ablating Directionality in Context,[0],[0]
"This is similar to the FULL context, except we do not concatenate the label of the relation to the context word (parent or children).",6.2 Ablating Directionality in Context,[0],[0]
"For instance, for traveler in Fig. 2, contexts will be roamed and tired.
",6.2 Ablating Directionality in Context,[0],[0]
"Experiments on both HYPER-HYPO and HYPER-COHYPO (bottom row, Tables 3a and 3b) highlight that directional information is indeed essential - UNLABELED almost always performs worse than FULL and JOINT, and in many cases worse than even window based models.
",6.2 Ablating Directionality in Context,[0],[0]
"6.3 Evaluating Robustness of BISPARSE-DEP
No Treebank We run experiments (Table 4) for all languages with a version of BISPARSE-DEP that use the FULL context type for both English and the non-English (target) language, but the target language contexts are derived from a corpus parsed using a delexicalized parser (§5.3).
",6.2 Ablating Directionality in Context,[0],[0]
This model compares favorably on all language pairs against the best window based and the best dependency based model.,6.2 Ablating Directionality in Context,[0],[0]
"In fact, it almost consistently outperforms the best window based model by several points, and is only slightly worse than the best dependency-based model.
",6.2 Ablating Directionality in Context,[0],[0]
Further analysis revealed that the good performance of the delexicalized model is due to the relative robustness of the delexicalized parser on frequent contexts in the co-occurrence matrix.,6.2 Ablating Directionality in Context,[0],[0]
"Specifically, we found that in French and Russian, the most frequent contexts were derived from amod, nmod, nsubj and dobj edges.8",6.2 Ablating Directionality in Context,[0],[0]
"For instance, the nmod edge appears in 44% of Russian contexts and 33% of the French contexts.",6.2 Ablating Directionality in Context,[0],[0]
The delexicalized parser predicts both the label and direction of the nmod edge correctly with an F1 of 68.6 for Russian and 69.6 for French.,6.2 Ablating Directionality in Context,[0],[0]
"In contrast, a fully-trained parser achieves a F1 of 76.7 for Russian and 76.8 for French for the same edge.
",6.2 Ablating Directionality in Context,[0],[0]
"Small Monolingual Corpus In Figure 4, we use increasingly smaller monolingual corpora (10%, 20%, 40%, 60% and 80%) sampled at random to induce the monolingual vectors for BISPARSEDEP (FULL) model.",6.2 Ablating Directionality in Context,[0],[0]
"Trends (Figure 4) indicate that BISSPARSE-DEP models that use only 40% of the original data remain competitive with the BISSPARSE-LEX model that has access to the full
8Together they make up at least 70% of the contexts.
data.",6.2 Ablating Directionality in Context,[0],[0]
"Robust performance with smaller monolingual corpora is helpful since large-enough monolingual corpora are not always easily available.
",6.2 Ablating Directionality in Context,[0],[0]
Quality of Bilingual Dictionary Bilingual dictionaries derived from smaller amounts of parallel data are likely to be of lower quality than those derived from larger corpora.,6.2 Ablating Directionality in Context,[0],[0]
"Hence, to analyze the impact of dictionary quality on BISPARSE-DEP (FULL), we use increasingly smaller parallel corpora to induce bilingual dictionaries used as the score matrix S (§3.3).",6.2 Ablating Directionality in Context,[0],[0]
"We use the top 10%, 20%, 40%, 60% and 80% sentences from the parallel corpora.",6.2 Ablating Directionality in Context,[0],[0]
"The trends in Figure 4 show that even with a lower quality dictionary, BISPARSE-DEP performs better than BISPARSE-LEX.",6.2 Ablating Directionality in Context,[0],[0]
"We change the entailment scorer from BalAPinc to SLQS (Santus et al., 2014) and redo experiments from §6.1 to see if the conclusions drawn depend
on the choice of the entailment scorer.",6.4 Choice of Entailment Scorer,[0],[0]
"SLQS is based on the distributional informativeness hypothesis, which states that hypernyms are less “informative” than hyponyms, because they occur in more general contexts.",6.4 Choice of Entailment Scorer,[0],[0]
"The informativeness Eu of a word u is defined to be the median entropy of its top N dimensions, Eu = medianNk=1H(ck), where H(ci) denotes the entropy of dimension ci.",6.4 Choice of Entailment Scorer,[0],[0]
"The SLQS score for a pair (u, v) is the relative difference in entropies,
SLQS(u→ v) = 1− Eu Ev
Recent work (Shwartz et al., 2017) has found SLQS to be more successful than other metrics in monolingual hypernymy detection.
",6.4 Choice of Entailment Scorer,[0],[0]
The trends observed in these experiments are consistent with those in §6.1 – both BISPARSEDEP models still outperform window-based models.,6.4 Choice of Entailment Scorer,[0],[0]
"Also, the delexicalized version of BISPARSEDEP outperforms the window-based models, showing that the robust behavior demonstrated in §6.3 is also invariant across metrics.
",6.4 Choice of Entailment Scorer,[0],[0]
We also found that using BalAPinc led to better results than SLQS .,6.4 Choice of Entailment Scorer,[0],[0]
"For both BISPARSE-DEP models, BalAPinc wins across the board for two languages (Russian and Chinese), and wins half the time for the other two languages compared to SLQS .",6.4 Choice of Entailment Scorer,[0],[0]
We leave detailed comparison of these and other scores to future work.,6.4 Choice of Entailment Scorer,[0],[0]
"We introduced BISPARSE-DEP, a new distributional approach for identifying cross-lingual hypernymy, based on cross-lingual embeddings derived from dependency contexts.",7 Conclusion,[0],[0]
"We showed that using BISPARSE-DEP is superior for the crosslingual hypernymy detection task, when compared to standard window based models and a translation baseline.",7 Conclusion,[0],[0]
Further analysis also showed that BISPARSE-DEP is robust to various low-resource settings.,7 Conclusion,[0],[0]
"In principle, BISPARSE-DEP can be used for any language that has a bilingual dictionary with English and a “related” language with a treebank.",7 Conclusion,[0],[0]
"We also introduced crowd-sourced crosslingual hypernymy datasets for four languages for future evaluations.
",7 Conclusion,[0],[0]
"Our approach has the potential to complement existing work on creating cross-lingual ontologies such as BabelNet and the Open Multilingual Wordnet, which are noisy because they are compiled semi-automatically, and have limited language coverage.",7 Conclusion,[0],[0]
"In general, distributional approaches can help refine ontology construction for
any language where sufficient resources are available.
",7 Conclusion,[0],[0]
It remains to be seen how our approach performs for other language pairs beyond simluated low-resource settings.,7 Conclusion,[0],[0]
"We anticipate that replacing our delexicalized parser with more sophisticated transfer strategies (Rasooli and Collins, 2017; Aufrant et al., 2016) might be beneficial in such settings.",7 Conclusion,[0],[0]
"While our delexicalized parsing based approach exhibits robustness, it can benefit from more sophisticated approaches for transfer parsing (Rasooli and Collins, 2017; Aufrant et al., 2016) to improve parser performance.",7 Conclusion,[0],[0]
We aim to explore these and other directions in the future.,7 Conclusion,[0],[0]
"The authors would like to thank the members of the CLIP lab at the University of Maryland, members of the Cognitive Computation Group at the University of Pennsylvania, and the anonymous reviewers from EMNLP/CoNLL 2017 and NAACL 2018 for their constructive feedback.",Acknowledgments,[0],[0]
"YV and MC were funded in part by research awards from Amazon, Google, and the Clare Boothe Luce Foundation.",Acknowledgments,[0],[0]
SU and DR were supported by Contract HR0011-15-2-0025 with the US Defense Advanced Research Projects Agency (DARPA).,Acknowledgments,[0],[0]
Cross-lingual Hypernymy Detection involves determining if a word in one language (“fruit”) is a hypernym of a word in another language (“pomme” i.e. apple in French).,abstractText,[0],[0]
The ability to detect hypernymy cross-lingually can aid in solving cross-lingual versions of tasks such as textual entailment and event coreference.,abstractText,[0],[0]
"We propose BISPARSE-DEP, a family of unsupervised approaches for cross-lingual hypernymy detection, which learns sparse, bilingual word embeddings based on dependency contexts.",abstractText,[0],[0]
"We show that BISPARSE-DEP can significantly improve performance on this task, compared to approaches based only on lexical context.",abstractText,[0],[0]
"Our approach is also robust, showing promise for low-resource settings: our dependency-based embeddings can be learned using a parser trained on related languages, with negligible loss in performance.",abstractText,[0],[0]
"We also crowd-source a challenging dataset for this task on four languages – Russian, French, Arabic, and Chinese.",abstractText,[0],[0]
Our embeddings and datasets are publicly available.1,abstractText,[0],[0]
Robust Cross-lingual Hypernymy Detection using Dependency Context,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 2137–2147 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
2137",text,[0],[0]
Relation extraction is a core task in information extraction and natural language understanding.,1 Introduction,[0],[0]
"The goal of relation extraction is to predict relations for entities in a sentence (Zelenko et al., 2003; Bunescu and Mooney, 2005; GuoDong et al., 2005).",1 Introduction,[0],[0]
"For example, given a sentence
“Barack Obama is married to Michelle Obama.”, a relation classifier aims at predicting the relation of “spouse”.",1 Introduction,[0],[0]
"In downstream applications, relation extraction is the key module for constructing knowledge graphs, and it is a vital component of many natural language processing applications such as structured search, sentiment analysis, question answering, and summarization.
",1 Introduction,[0],[0]
"A major issue encountered in the early development of relation extraction algorithms is the data sparsity issue—It is extremely expensive, and almost impossible for human annotators to go through a large corpus of millions of sentences to provide a large amount of labeled training instances.",1 Introduction,[0],[0]
"Therefore, distant supervision relation extraction (Mintz et al., 2009; Hoffmann et al., 2011; Surdeanu et al., 2012) becomes popular, because it uses entity pairs from knowledge bases to select a set of noisy instances from unlabeled data.",1 Introduction,[0],[0]
"In recent years, neural network approaches (Zeng et al., 2014, 2015) have been proposed to train the relation extractor under these noisy conditions.",1 Introduction,[0],[0]
"To suppress the noisy(Roth et al., 2013), recent stud-
ies (Lin et al., 2016) have proposed the use of attention mechanisms to place soft weights on a set of noisy sentences, and select samples.",1 Introduction,[0],[0]
"However, we argue that only selecting one example or based on soft attention weights are not the optimal strategy: To improve the robustness, we need a systematic solution to make use of more instances, while removing false positives and placing them in the right place.
",1 Introduction,[0],[0]
"In this paper, we investigate the possibility of using dynamic selection strategies for robust distant supervision.",1 Introduction,[0],[0]
"More specifically, we design a deep reinforcement learning agent, whose goal is to learn to choose whether to remove or remain the distantly supervised candidate instance based on the performance change of the relation classifier.",1 Introduction,[0],[0]
"Intuitively, our agent would like to remove false positives, and reconstruct a cleaned set of distantly supervised instances to maximize the reward based on the classification accuracy.",1 Introduction,[0],[0]
"Our proposed method is classifier-independent, and it can be applied to any existing distant supervision model.",1 Introduction,[0],[0]
"Empirically, we show that our method has brought consistent performance gains in various deep neural network based models, achieving strong performances on the widely used New York Times dataset (Riedel et al., 2010).",1 Introduction,[0],[0]
"Our contributions are three-fold:
• We propose a novel deep reinforcement learning framework for robust distant supervision relation extraction.
",1 Introduction,[0],[0]
"• Our method is model-independent, meaning that it could be applied to any state-of-the-art relation extractors.
",1 Introduction,[0],[0]
"• We show that our method can boost the performances of recently proposed neural relation extractors.
",1 Introduction,[0],[0]
"In Section 2, we will discuss related works on distant supervision relation extraction.",1 Introduction,[0],[0]
"Next, we will describe our robust distant supervision framework in Section 3.",1 Introduction,[0],[0]
"In Section 4, empirical evaluation results are shown.",1 Introduction,[0],[0]
"And finally, we conclude in Section 5.",1 Introduction,[0],[0]
Mintz et al. (2009) is the first study that combines dependency path and feature aggregation for distant supervision.,2 Related Work,[0],[0]
"However, this approach would
introduce a lot of false positives, as the same entity pair might have multiple relations.",2 Related Work,[0],[0]
"To alleviate this issue, Hoffmann et al. (2011) address this issue, and propose a model to jointly learn with multiple relations.",2 Related Work,[0],[0]
Surdeanu et al. (2012) further propose a multi-instance multi-label learning framework to improve the performance.,2 Related Work,[0],[0]
"Note that these early approaches do not explicitly remove noisy instances, but rather hope that the model would be able to suppress the noise.
",2 Related Work,[0],[0]
"Recently, with the advance of neural network techniques, deep learning methods (Zeng et al., 2014, 2015) are introduced, and the hope is to model noisy distant supervision process in the hidden layers.",2 Related Work,[0],[0]
"However, their approach only selects one most plausible instance per entity pair, inevitably missing out a lot of valuable training instances.",2 Related Work,[0],[0]
"Recently, Lin et al. (2016) propose an attention mechanism to select plausible instances from a set of noisy instances.",2 Related Work,[0],[0]
"However, we believe that soft attention weight assignment might not be the optimal solution, since the false positives should be completely removed and placed in the negative set.",2 Related Work,[0],[0]
"Ji et al. (2017) combine the external knowledge to rich the representation of entity pair, in which way to improve the accuracy of attention weights.",2 Related Work,[0],[0]
"Even though these above-mentioned methods can select high-quality instances, they ignore the false positive case: all the sentences of one entity pair belongs to the false positives.",2 Related Work,[0],[0]
"In this work, we take a radical approach to solve this problem—We will make use of the distantly labeled resources as much as possible, while learning a independent false-positive indicator to remove false positives, and place them in the right place.",2 Related Work,[0],[0]
"After our ACL submission, we notice that a contemporaneous study Feng et al. (2018) also adopts reinforcement learning to learn an instance selector, but their reward is calculated from the prediction probabilities.",2 Related Work,[0],[0]
"In contrast, while in our method, the reward is intuitively reflected by the performance change of the relation classifier.",2 Related Work,[0],[0]
"Our approach is also complement to most of the approaches above, and can be directly applied on top of any existing relation extraction classifiers.",2 Related Work,[0],[0]
"We introduce a performance-driven, policy-based reinforcement learning method to heuristically recognize false positive samples.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Comparing to
a prior study that has underutilized the distantlysupervised samples (Lin et al., 2016), we consider an RL agent for robust distant supervision relation extraction.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"We first describe the definitions of our RL method, including the policy-based agent, external environment, and pre-training strategy.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Next, we describe the retraining strategy for our RL agent.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"The goal of our agent is to determine whether to retain or remove a distantlysupervised sentence, based on the performance change of relation classifier.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Finally, we describe the noisy-suppression method, where we teach our policy-based agent to make a redistribution for a cleaner distant supervision training dataset.
",3 Reinforcement Learning for Distant Supervision,[0],[0]
Distant supervision relation extraction is to predict the relation type of entity pair under the automatically-generated training set.,3 Reinforcement Learning for Distant Supervision,[0],[0]
"However, the issue is that these distantly-supervised sentences that mention this entity pair may not express the desired relation type.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Therefore, what our RL agent should do is to determine whether the distantly-supervised sentence is a true positive instance for this relation type.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"For reinforcement learning, external environment and RL agent are two necessary components, and a robust agent is trained from the dynamic interaction between these two parts (Arulkumaran et al., 2017).",3 Reinforcement Learning for Distant Supervision,[0],[0]
"First, the prerequisite of reinforcement learning is that the external environment should be modeled as a Markov decision process (MDP).",3 Reinforcement Learning for Distant Supervision,[0],[0]
"However, the traditional setting of relation extraction cannot satisfy this condition: the input sentences are independent of each other.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"In other words, we cannot merely use the information of the sentence being processed as the state.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Thus, we add the information from the early states into the representation of the current state, in which way to model our task as a MDP problem (Fang et al., 2017).",3 Reinforcement Learning for Distant Supervision,[0],[0]
"The other component, RL agent, is parameterized with a policy network πθ(s, a) = p(a|s; θ).",3 Reinforcement Learning for Distant Supervision,[0],[0]
"The probability distribution of actions A = {aremove, aremain} is calculated by policy network based on state vectors.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"What needs to be noted is that, Deep Q Network (DQN) (Mnih et al., 2013) is also a widelyused RL method; however, it is not suitable for our case, even if our action space is small.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"First, we cannot compute the immediate reward for every operation; In contrast, the accurate reward can only be obtained after finishing processing the whole training dataset.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Second, the stochastic policy of the policy network is capable of prevent-
ing the agent from getting stuck in an intermediate state.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"The following subsections detailedly introduce the definitions of the fundamental components in the proposed RL method.
",3 Reinforcement Learning for Distant Supervision,[0],[0]
States,3 Reinforcement Learning for Distant Supervision,[0],[0]
"In order to satisfy the condition of MDP, the state s includes the information from the current sentence and the sentences that have been removed in early states.",3 Reinforcement Learning for Distant Supervision,[0],[0]
The semantic and syntactic information of sentence is represented by a continuous real-valued vector.,3 Reinforcement Learning for Distant Supervision,[0],[0]
"According to some state-of-the-art supervised relation extraction approaches (Zeng et al., 2014; Nguyen and Grishman, 2015), we utilize both word embedding and position embedding to convert sentence into vector.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"With this sentence vector, the current state is the concatenation of the current sentence vector and the average vector of the removed sentences in early states.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"We give relatively larger weight for the vector of the current sentence, in which way to magnify the dominating influence of the current sentence information for the decision of action.
",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Actions At each step, our agent is required to determine whether the instance is false positive for target relation type.",3 Reinforcement Learning for Distant Supervision,[0],[0]
Each relation type has a agent1.,3 Reinforcement Learning for Distant Supervision,[0],[0]
There are two actions for each agent: whether to remove or retain the current instance from the training set.,3 Reinforcement Learning for Distant Supervision,[0],[0]
"With the initial distantlysupervised dataset that is blended with incorrectlylabeled instances, we hope that our agent is capable of using the policy network to filter noisy instances; Under this cleaned dataset, distant supervision is then expected to achieve better performance.
",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Rewards As previously mentioned, the intuition of our model is that, when the incorrectly-labeled instances are filtered, the better performance of relation classifier will achieve.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Therefore, we use the change of performance as the result-driven reward for a series of actions decided by the agent.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Compared to accuracy, we adopt the F1 score as the evaluation criterion, since accuracy might not be an indicative metric in a multi-class classification setting where the data distribution could be imbalanced.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Thus, the reward can be formulated as the
1We also tried the strategy that just builds a single agent for all relation types: a binary classifier(TP/FP) or a multiclass classifier(rela1/rela2/.../FP).",3 Reinforcement Learning for Distant Supervision,[0],[0]
"But, it has the limitation in the performance.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"We found that our one-agent-for-onerelation strategy obtained better performance than the single agent strategy.
v ; their corresponding negative
part are represented asNorit andN ori v .",3 Reinforcement Learning for Distant Supervision,[0],[0]
"In each epoch i, the agent performs a series of actions to recognize the false positive samples from P orit and treat them as negative samples.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Then, a new relation classifier is trained under the new dataset {P it , N it}.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"With this relation classifier, F1 score is calculated from the new validation set {P iv, N iv}, where P iv is also filtered by the current agent.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"After that, the current reward is measured as the difference of F1 between the adjacent epochs.
",3 Reinforcement Learning for Distant Supervision,[0],[0]
"difference between the adjacent epochs:
Ri = α(F",3 Reinforcement Learning for Distant Supervision,[0],[0]
i 1,3 Reinforcement Learning for Distant Supervision,[0],[0]
"− F i−11 ) (1)
",3 Reinforcement Learning for Distant Supervision,[0],[0]
"As this equation shows, in step i, our agent is given a positive reward only if F1 gets improved; otherwise, the agent will receive a negative reward.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Under this setting, the value of reward is proportional to the difference of F1, and α is used to convert this difference into a rational numeric range.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Naturally, the value of the reward is in a continuous space, which is more reasonable than a binary reward (−1 and 1), because this setting can reflect the number of wrong-labeled instance that the agent has removed.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"In order to avoid the randomness of F1, we use the average F1 of last five epochs to calculate the reward.
",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Policy Network For each input sentence, our policy network is to determine whether it expresses the target relation type and then make removal action if it is irrelevant to the target relation type.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Thus, it is analogous to a binary relation classifier.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"CNN is commonly used to construct relation classification system (Santos et al., 2015; Xu et al., 2015; Shen and Huang, 2016), so we adopt a simple CNN with window size cw and kernel size ck, to model policy network π(s; θ).",3 Reinforcement Learning for Distant Supervision,[0],[0]
"The reason why we do not choice the variants of CNN (Zeng et al., 2015; Lin et al., 2016)
that are well-designed for distant supervision is that these two models belong to bag-level models (dealing with a bag of sentences simultaneously) and deal with the multi-classification problem; We just need a model to do binary sentencelevel classification.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Naturally, the simpler network is adopted.",3 Reinforcement Learning for Distant Supervision,[0],[0]
"Unlike the goal of distant supervision relation extraction, our agent is to determine whether an annotated sentence expresses the target relation type rather than predict the relationship of entity pair, so sentences are treated independently despite belonging to the same entity pair.",3.1 Training Policy-based Agent,[0],[0]
"In distant supervision training dataset, one relation type contains several thousands or ten thousands sentences; moreover, reward R can only be calculated after processing the whole positive set of this relation type.",3.1 Training Policy-based Agent,[0],[0]
"If we randomly initialize the parameters of policy network and train this network by trial and errors, it will waste a lot of time and be inclined to poor convergence properties.",3.1 Training Policy-based Agent,[0],[0]
"In order to overcome this problem, we adopt a supervised learning procedure to pre-train our policy network, in which way to provide a general learning direction for our policy-based agent.",3.1 Training Policy-based Agent,[0],[0]
"The pre-training strategy, inspired from AlphaGo (Silver et al., 2016), is a common strategy in RL related works to accelerate the training of RL agents.",3.1.1 Pre-training Strategy,[0],[0]
"Normally, they utilize a small part of the annotated dataset to train policy networks before reinforcement learning.",3.1.1 Pre-training Strategy,[0],[0]
"For example, AlphaGo uses the collected experts moves to do a supervised learning for Go RL agent.",3.1.1 Pre-training Strategy,[0],[0]
"However, in distant supervision relation extraction task, there is not any supervised information that can be used unless let linguistic experts to do some manual annotations for part of the entity pairs.",3.1.1 Pre-training Strategy,[0],[0]
"However, this is expensive, and it is not the original intention of distant supervision.",3.1.1 Pre-training Strategy,[0],[0]
"Under this circumstance, we propose a compromised solution.",3.1.1 Pre-training Strategy,[0],[0]
"With well-aligned corpus, the true positive samples should have evident advantage in quantity compared with false positive samples in the distantly-supervised dataset.",3.1.1 Pre-training Strategy,[0],[0]
"So, for a specific relation type, we directly treat the distantly-supervised positive set as the positive set, and randomly extract part of distantly-supervised negative set as the negative set.",3.1.1 Pre-training Strategy,[0],[0]
"In order to better consider prior information during this pre-training procedure, the amount of negative samples is 10 times of the number of positive samples.",3.1.1 Pre-training Strategy,[0],[0]
"It is because, when learning with massive negative samples, the agent is more likely to develop toward a better direction.",3.1.1 Pre-training Strategy,[0],[0]
"Cross-entropy cost function is used to train this binary classifier, where the negative label corresponds to the removing action, and the positive label corresponds to the retaining action.
",3.1.1 Pre-training Strategy,[0],[0]
(2) J(θ) =,3.1.1 Pre-training Strategy,[0],[0]
"∑ i yilog[π(a = yi|si; θ)]
+ (1− yi)log[1− π(a",3.1.1 Pre-training Strategy,[0],[0]
"= yi|si; θ)]
Due to the noisy nature of the distantly-labeled instances, if we let this pre-training process overfit this noisy dataset, the predicted probabilities of most samples tend to be close to 0 or 1, which is difficult to be corrected and unnecessarily increases the training cost of reinforcement learning.",3.1.1 Pre-training Strategy,[0],[0]
"So, we stop this training process when the accuracy reaches 85% ∼ 90%.",3.1.1 Pre-training Strategy,[0],[0]
"Theoretically, our approach can be explained as increasing the entropy of the policy gradient agent, and preventing the entropy of the policy being too low, which means that the lack of exploration may be a concern.",3.1.1 Pre-training Strategy,[0],[0]
"As shown in Figure 2, in order to discover incorrectly-labeled instances without any supervised information, we introduce a policy-based RL method.",3.1.2 Retraining Agent with Rewards,[0],[0]
What our agent tries to deal with is the noisy samples from the distantly-supervised positive dataset; Here we call it as the DS positive dataset.,3.1.2 Retraining Agent with Rewards,[0],[0]
"We split it into the training positive set P orit and the validation positive set P ori v ; naturally, both of these two set are noisy.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Correspondingly, the training negative set Norit and the validation negative setNoriv are constructed by randomly selected from the DS negative dataset.",3.1.2 Retraining Agent with Rewards,[0],[0]
"In every epoch, the agent removes a noisy sample set Ψi from P orit according to the stochastic policy π(a|s), and we obtain a new positive set Pt = P ori",3.1.2 Retraining Agent with Rewards,[0],[0]
t,3.1.2 Retraining Agent with Rewards,[0],[0]
− Ψi.,3.1.2 Retraining Agent with Rewards,[0],[0]
"Because Ψi is recognized as the wrong-labeled samples, we redistribute it into the negative set Nt = Norit + Ψi.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Under this setting, the scale of training set is constant for each epoch.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Now we utilize the cleaned data {Pt, Nt} to train a relation classifier.",3.1.2 Retraining Agent with Rewards,[0],[0]
The desirable situation is that RL agent has the capacity to increase the performance of relation classifier through relocating incorrectly-labeled false positive instances.,3.1.2 Retraining Agent with Rewards,[0],[0]
"Therefore, we use the validation set {P oriv , Noriv } to measure the performance of the current agent.",3.1.2 Retraining Agent with Rewards,[0],[0]
"First, this validation set is filtered and redistributed by the current agent as {Pv, Nv}; the F1 score of the current relation classifier is calculated from it.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Finally, the difference of F1 scores between the current and previous epoch is used to calculate reward.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Next, we will introduce several strategies to train a more robust RL agent.
",3.1.2 Retraining Agent with Rewards,[0],[0]
"Removing the fixed number of sentences in each epoch In every epoch, we let the RL agent to remove a fixed number of sentences or less (when the number of the removed sentences in one epoch does not reach this fixed number during training), in which way to prevent the case that the agent tries to remove more false positive instances by removing more instances.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Under the restriction of fixed number, if the agent decides to remove the current state, it means the chance of removing other states decrease.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Therefore, in order to obtain a better reward, the agent should try to remove a instance set that includes more negative instances.
",3.1.2 Retraining Agent with Rewards,[0],[0]
Loss function The quality of the RL agent is reflected by the quality of the removed part.,3.1.2 Retraining Agent with Rewards,[0],[0]
"After the pre-training process, the agent just possesses
Algorithm 1 Retraining agent with rewards for relation k.",3.1.2 Retraining Agent with Rewards,[0],[0]
"For a clearer expression, k is omitted in the following algorithm.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Require: Positive set {P orit , P oriv }, Negative set {Norit , Noriv }, the fixed number of removal γt, γv
1: Load parameters θ from pre-trained policy network 2: Initialize s∗ as the all-zero vector with the same dimension of sj 3: for epoch",3.1.2 Retraining Agent with Rewards,[0],[0]
"i = 1→ N do 4: for sj ∈ P orit do 5: s̃j = concatenation(sj , s
∗) 6: Randomly sample aj ∼ π(a|s̃j ; θ); compute pj = π(a = 0|s̃j ; θ) 7: if aj == 0 then 8: Save tuple tj = (s̃j , pj) in T and recompute the average vector of removed sentences s∗
9: end if 10: end for 11: Rank T based on pj from high to low, obtain Trank 12: for ti in Trank[: γt] do 13: Add ti[0] into Ψi 14: end for 15: P it = P ori",3.1.2 Retraining Agent with Rewards,[0],[0]
t,3.1.2 Retraining Agent with Rewards,[0],[0]
"− Ψi, N it = Norit + Ψi, and generate the new validation set {P iv, N iv} with current
agent 16: Train the relation classifier based on {P it , N it} 17: Calculate F i1 on the new validation set {P iv, N iv}, and Save F i1,",3.1.2 Retraining Agent with Rewards,[0],[0]
"Ψi 18: R = α(F i1 − F i−1 1 ) 19: Ωi−1 = Ψi−1 −Ψi ∩Ψi−1; Ωi = Ψi −Ψi ∩Ψi−1 20:
21: Updata θ:",3.1.2 Retraining Agent with Rewards,[0],[0]
"g ∝ 5θ ∑Ωi log π(a|s; θ)R+5θ∑Ωi−1 log π(a|s; θ)(−R) 22: end for
the ability to distinguish the obvious false positive instances, which means the discrimination of the indistinguishable wrong-labeled instances are still ambiguous.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Particularly, this indistinguishable part is the criterion to reflect the quality of the agent.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Therefore, regardless of these easydistinguished instances, the different parts of the removed parts in different epochs are the determinant of the change of F1 scores.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Therefore, we definite two sets:
Ωi−1 = Ψi−1",3.1.2 Retraining Agent with Rewards,[0],[0]
− (Ψi ∩Ψi−1) (3) Ωi =,3.1.2 Retraining Agent with Rewards,[0],[0]
"Ψi − (Ψi ∩Ψi−1) (4)
where Ψi is the removed part of epoch i. Ωi−1 and Ωi are represented with the different colors in Figure 2.",3.1.2 Retraining Agent with Rewards,[0],[0]
"If F1 score increases in the epoch i, it means the actions of the epoch i is more reasonable than that in the epoch i− 1.",3.1.2 Retraining Agent with Rewards,[0],[0]
"In other words, Ωi is more negative than Ωi−1.",3.1.2 Retraining Agent with Rewards,[0],[0]
"Thus, we assign the positive reward to Ωi and the negative reward to Ωi−1, and vice versa.",3.1.2 Retraining Agent with Rewards,[0],[0]
"In summary, the ultimate loss function
is formulated as follow:
(5) J(θ)",3.1.2 Retraining Agent with Rewards,[0],[0]
"=
Ωi∑ log π(a|s; θ)R
+ Ωi−1∑ log π(a|s; θ)(−R)",3.1.2 Retraining Agent with Rewards,[0],[0]
"Through the above reinforcement learning procedure, for each relation type, we obtain a agent as the false-positive indicator.",3.2 Redistributing Training Dataset with Policy-based Agents,[0],[0]
These agents possess the capability of recognizing incorrectly-labeled instances of the corresponding relation types.,3.2 Redistributing Training Dataset with Policy-based Agents,[0],[0]
We adopt these agents as classifiers to recognize false positive samples in the noisy distantly-supervised training dataset.,3.2 Redistributing Training Dataset with Policy-based Agents,[0],[0]
"For one entity pair, if all the sentence aligned from corpus are classified as false positive, then this entity pair is redistributed into the negative set.",3.2 Redistributing Training Dataset with Policy-based Agents,[0],[0]
"We adopt a policy-based RL method to generate a series of relation indicators and use them to re-
distribute training dataset by moving false positive samples to negative sample set.",4 Experiments,[0],[0]
"Therefore, our experiments are intended to demonstrate that our RL agents possess this capability.",4 Experiments,[0],[0]
"We evaluate the proposed method on a commonlyused dataset2, which is first presented in Riedel et al. (2010).",4.1 Datast and Evaluation Metrics,[0],[0]
This dataset is generated by aligning entity pairs from Freebase with New York Times corpus(NYT).,4.1 Datast and Evaluation Metrics,[0],[0]
"Entity mentions of NYT corpus are recognized by the Stanford named entity recognizer (Finkel et al., 2005).",4.1 Datast and Evaluation Metrics,[0],[0]
The sentences from the years 2005-2006 are used as the training corpus and sentences from 2007 are used as the testing corpus.,4.1 Datast and Evaluation Metrics,[0],[0]
There are 52 actual relations and a special relation NA which indicates there is no relation between the head and tail entities.,4.1 Datast and Evaluation Metrics,[0],[0]
"The sentences of NA are from the entity pairs that exist in the same sentence of the actual relations but do not appear in the Freebase.
",4.1 Datast and Evaluation Metrics,[0],[0]
"Similar to the previous works, we adopt the held-out evaluation to evaluate our model, which can provide an approximate measure of the classification ability without costly human evaluation.",4.1 Datast and Evaluation Metrics,[0],[0]
"Similar to the generation of the training set, the entity pairs in test set are also selected from Freebase, which will be predicted under the sentences discovered from the NYT corpus.",4.1 Datast and Evaluation Metrics,[0],[0]
The action space of our RL agent just includes two actions.,4.2.1 Policy-based Agent,[0],[0]
"Therefore, the agent can be modeled as a binary classifier.",4.2.1 Policy-based Agent,[0],[0]
We adopt a single-window CNN as this policy network.,4.2.1 Policy-based Agent,[0],[0]
The detailed hyperparameter settings are presented in Table 1.,4.2.1 Policy-based Agent,[0],[0]
"As for word embeddings, we directly use the word embedding file released by Lin et al. (2016)3, which just keeps the words that appear more than 100 times in NYT.",4.2.1 Policy-based Agent,[0],[0]
"Moreover, we have the same dimension setting of the position embedding, and the maximum length of relative distance is −30 and 30 (“-” and “+” represent the left and right side of the entities).",4.2.1 Policy-based Agent,[0],[0]
The learning rate of reinforcement learning is 2e−5.,4.2.1 Policy-based Agent,[0],[0]
"For each relation type, the fixed number γt, γv are according to the pre-trained agent.",4.2.1 Policy-based Agent,[0],[0]
"When one relation type has too many distantsupervised positive sentences (for example, /lo-
2http://iesl.cs.umass.edu/riedel/ecml/ 3https://github.com/thunlp/NRE
cation/location/contains has 75768 sentences), we sample a subset of size 7,500 sentences to train the agent.",4.2.1 Policy-based Agent,[0],[0]
"For the average vector of the removed sentences, in the pre-training process and the first state of the retraining process, it is set as all-zero vector.",4.2.1 Policy-based Agent,[0],[0]
"In order to evaluate a series of actions by agent, we use a simple CNN model, because the simple network is more sensitive to the quality of the training set.",4.2.2 Relation Classifier for Calculating Reward,[0],[0]
"The proportion between P orit and P ori v is 2:1, and they are all derived from the training set of Riedel dataset; the corresponding negative sample setsNorit andN ori v are randomly selected from the Riedel negative dataset, whose size is twice that of their corresponding positive sets.",4.2.2 Relation Classifier for Calculating Reward,[0],[0]
"In Table 2, we list the F1 scores before and after adopting the proposed RL method.",4.3 The Effectiveness of Reinforcement Learning,[0],[0]
"Even though there are 52 actual relation types in Riedel dataset, only 10 relation types have more than 1000 pos-
itive instances4.",4.3 The Effectiveness of Reinforcement Learning,[0],[0]
"Because of the randomness of deep neural network on the small-scale dataset, we just train policy-based agents for these 10 relation types.",4.3 The Effectiveness of Reinforcement Learning,[0],[0]
"First, compared with Original case, most of the Pretrain agents yield obvious improvements: It not only demonstrates the rationality of our pretraining strategy, but also verifies our hypothesis that most of the positive samples in Riedel dataset are true positive.",4.3 The Effectiveness of Reinforcement Learning,[0],[0]
"More significantly, after retraining with the proposed policy-based RL method, the F1 scores achieve further improvement, even for the case the Pretrain agents perform bad.",4.3 The Effectiveness of Reinforcement Learning,[0],[0]
"These comparable results illustrate that the proposed policy-based RL method is capable of making agents develop towards a good direction.
4The supervised relation classification task Semeval-2010 Task 8 (Hendrickx et al., 2009) annotates nearly 1,000 instances for each relation type.",4.3 The Effectiveness of Reinforcement Learning,[0],[0]
Zeng et al. (2015) and Lin et al. (2016) are both the robust models to solve wrong labeling problem of distant supervision relation extraction.,4.4 Impact of False Positive Samples,[0],[0]
"Zeng et al. (2015) combine at-least-one multi-instance learning with deep neural network to extract only one active sentence to predict the relation between entity pair; Lin et al. (2016) combine all sentences of one entity pair and assign soft attention weights to them, in which way to generate a compositive relation representation for this entity pair.",4.4 Impact of False Positive Samples,[0],[0]
"However, the false positive phenomenon also includes the case that all the sentences of one entity pair are wrong, which is because the corpus is not completely aligned with the knowledge base.",4.4 Impact of False Positive Samples,[0],[0]
This phenomenon is also common between Riedel dataset and Freebase through our manual inspection.,4.4 Impact of False Positive Samples,[0],[0]
"Obviously, there is nothing the above two methods can do in this case.
",4.4 Impact of False Positive Samples,[0],[0]
The proposed RL method is to tackle this problem.,4.4 Impact of False Positive Samples,[0],[0]
We adopt our RL agents to redistribute Riedel dataset by moving false positive samples into the negative sample set.,4.4 Impact of False Positive Samples,[0],[0]
"Then we use Zeng et al. (2015) and Lin et al. (2016) to predict relations on this cleaned dataset, and compare the performance with that on the original Riedel dataset.",4.4 Impact of False Positive Samples,[0],[0]
"As shown in Figure 3 and Figure 4, under the assistant of our RL agent, the same model can achieve obvious improvement with more reasonable training dataset.",4.4 Impact of False Positive Samples,[0],[0]
"In order to give the more intuitive comparison, we calculate the AUC value of each PR curve, which reflects the area size under these curves.",4.4 Impact of False Positive Samples,[0],[0]
These comparable results also indicate the effectiveness of our policy-based RL method.,4.4 Impact of False Positive Samples,[0],[0]
"Moreover, as can be seen from the result of t-test evaluation, all the p-values are less than 5e-02, so the improvements are significant.",4.4 Impact of False Positive Samples,[0],[0]
"Figure 5 indicates that, for different relations, the scale of the detected false positive samples is not
proportional to the original scale, which is in accordance with the actual accident situation.",4.5 Case Study,[0],[0]
"At the same time, we analyze the correlation between the false positive phenomenon and the number of sentences of entity pairs : With this the number ranging from 1 to 5, the corresponding percentages are [55.9%, 32.0%, 3.7%, 4.4%, 0.7%].",4.5 Case Study,[0],[0]
This distribution is consistent with our assumption.,4.5 Case Study,[0],[0]
"Because Freebase is, to some extent, not completely aligned with the NYT corpus, entity pairs with fewer sentences are more likely to be false positive, which is the major factor hindering the performance of the previous systems.",4.5 Case Study,[0],[0]
"In Table 4, we present some false positive examples selected by our agents.",4.5 Case Study,[0],[0]
"Taking entity pair (Sami Moubayed, Syria) as an example, it is obvious that there is not any valuable information reflecting relation /people/person/place of birth.",4.5 Case Study,[0],[0]
Both of these sentences talks about the situation analysis of Syria from the political analyst Sami Moubayed.,4.5 Case Study,[0],[0]
"We also found that, for some entity pairs, even though there are multiple sentences, all of them are identical.",4.5 Case Study,[0],[0]
This phenomenon also increases the probability of the appearance of false positive samples.,4.5 Case Study,[0],[0]
"In this work, we propose a deep reinforcement learning framework for robust distant supervision.",5 Conclusion,[0],[0]
"The intuition is that, in contrast to prior works that utilize only one instance per entity pair and use soft attention weights to select plausible distantly supervised examples, we describe a policy-based framework to systematically learn to relocate the false positive samples, and better utilize the unlabeled data.",5 Conclusion,[0],[0]
"More specifically, our goal is to
teach the reinforcement agent to optimize the selection/redistribution strategy that maximizes the reward of boosting the performance of relation classification.",5 Conclusion,[0],[0]
"An important aspect of our work is that our framework does not depend on a specific form of the relation classifier, meaning that it is a plug-and-play technique that could be potentially applied to any relation extraction pipeline.",5 Conclusion,[0],[0]
"In experiments, we show that our framework boosts the performance of distant supervision relation extraction of various strong deep learning baselines on the widely used New York Times - Freebase dataset.
",5 Conclusion,[0],[0]
"Acknowledge
This work was supported by National Natural Science Foundation of China (61702047), Beijing Natural Science Foundation (4174098), the Fundamental Research Funds for the Central Universities (2017RC02) and National Natural Science Foundation of China (61703234)",5 Conclusion,[0],[0]
Distant supervision has become the standard method for relation extraction.,abstractText,[0],[0]
"However, even though it is an efficient method, it does not come at no cost—The resulted distantly-supervised training samples are often very noisy.",abstractText,[0],[0]
"To combat the noise, most of the recent state-of-theart approaches focus on selecting onebest sentence or calculating soft attention weights over the set of the sentences of one specific entity pair.",abstractText,[0],[0]
"However, these methods are suboptimal, and the false positive problem is still a key stumbling bottleneck for the performance.",abstractText,[0],[0]
"We argue that those incorrectly-labeled candidate sentences must be treated with a hard decision, rather than being dealt with soft attention weights.",abstractText,[0],[0]
"To do this, our paper describes a radical solution—We explore a deep reinforcement learning strategy to generate the false-positive indicator, where we automatically recognize false positives for each relation type without any supervised information.",abstractText,[0],[0]
"Unlike the removal operation in the previous studies, we redistribute them into the negative examples.",abstractText,[0],[0]
The experimental results show that the proposed strategy significantly improves the performance of distant supervision comparing to state-of-the-art systems.,abstractText,[0],[0]
Robust Distant Supervision Relation Extraction via Deep Reinforcement Learning,title,[0],[0]
"2 for each variable satisfies n
2 . pn/plog d, where n is the sample size and d is the number of variables, the proposed robust precision matrix estimator attains the same statistical rate as the standard estimator for Gaussian graphical models. In addition, we propose a hypothesis testing procedure to assess the uncertainty of our robust estimator. We demonstrate the effectiveness of our method through extensive experiments on both synthetic data and real-world genomic data.",text,[0],[0]
"Gaussian graphical models (GGMs) have attracted increasing attention in recent years, especially in the field of high-dimensional statistical learning.",1 Introduction,[0],[0]
"In Gaussian graphical models, a d-dimensional random vector X = (X
1 , . . .",1 Introduction,[0],[0]
", Xd)> follows a multivariate normal distribution Nd(0,⌃⇤).",1 Introduction,[0],[0]
"It corresponds to the vertex set V = {1, . . .",1 Introduction,[0],[0]
", d} of an undirected graph G = (V,E), where the edge set E describes the conditional independence relationships between nodes X
1 , . . .",1 Introduction,[0],[0]
", Xd.",1 Introduction,[0],[0]
It is well-known that the graph G is encoded by the sparsity pattern of the precision matrix ⇥,1 Introduction,[0],[0]
"⇤ = ⌃
⇤ 1.",1 Introduction,[0],[0]
"More specifically, no edge connects Xi and Xj if and only if ⇥⇤ij = 0.",1 Introduction,[0],[0]
"Consequently, estimation of
1Department of Computer Science, University of Virginia, Charlottesville, Virginia, USA.",1 Introduction,[0],[0]
"Correspondence to: Quanquan Gu <qg5w@virginia.edu>.
",1 Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1 Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1 Introduction,[0],[0]
the precision matrix ⇥,1 Introduction,[0],[0]
"⇤ corresponds to parameter estimation, and specifying the non-zero set of ⇥⇤ corresponds to graphical model selection (Cox & Wermuth, 1996).
",1 Introduction,[0],[0]
"In the high-dimensional settings, where the number of variables d can exceed the number of observations n, a large body of literature has studied the problem of precision matrix estimation in Gaussian graphical models and their variants (Meinshausen & Bühlmann, 2006; Yuan & Lin, 2007; Friedman et al., 2008; Banerjee et al., 2008; Yuan, 2010; Cai et al., 2011; Wang et al., 2016; Xu & Gu, 2016; Xu et al., 2016; 2017).",1 Introduction,[0],[0]
"For instance, Meinshausen & Bühlmann (2006) developed a neighborhood pursuit approach for estimating conditional independence relationship separately for each node in the graph.",1 Introduction,[0],[0]
This method estimates the precision matrix by solving a collection of sparse regression problems using Lasso in parallel.,1 Introduction,[0],[0]
"Yuan & Lin (2007); Friedman et al. (2008); Banerjee et al. (2008) proposed a `
1 norm regularized Gaussian negative log-likelihood method, which called Graphical Lasso (GLasso), to directly estimate the precision matrix.",1 Introduction,[0],[0]
"More recently, Yuan (2010); Cai et al. (2011) proposed the graphical Dantzig selector and CLIME, respectively.",1 Introduction,[0],[0]
"Both of these methods can be solved by linear programming and have more favorable theoretical properties than GLasso.
",1 Introduction,[0],[0]
Note that most of the aforementioned methods rely on the assumption that the observations follow a Gaussian distribution.,1 Introduction,[0],[0]
"There also exists some work, such as Ravikumar et al. (2011), studied sub-Gaussian data under bounded higher order moments.",1 Introduction,[0],[0]
"However, in many real-word applications, the data can follow a heavy-tailed distribution, or may even be corrupted arbitrarily.",1 Introduction,[0],[0]
"In such cases, conventional methods yield inaccurate graph estimation even if there are only a few contaminated observations due to the lack of robustness.",1 Introduction,[0],[0]
"In order to address this issue, a large body of literature (Liu et al., 2012; Finegold & Drton, 2011; Hirose & Fujisawa, 2015; Sun & Li, 2012; Yang & Lozano, 2015; Balmand & Dalalyan, 2015; Öllerer & Croux, 2015; Loh & Tan, 2015; Chen et al., 2015; Tarr et al., 2016) has focused on providing more robust estimators for precision matrices in the past years.",1 Introduction,[0],[0]
"However, most of these estimators were established under some specific contamination models, thus they are not good at dealing with the situation when data are arbitrarily corrupted.
",1 Introduction,[0],[0]
"In this paper, we propose a robust estimator to estimate the precision matrix in high-dimensional GGMs with arbitrarily corrupted data.",1 Introduction,[0],[0]
"More specifically, we consider the situation that the corrupted data can appear in any coordinates of the observations.",1 Introduction,[0],[0]
This includes situations that some observations are outliers or data follow some specific contamination models as special cases.,1 Introduction,[0],[0]
The definition of the arbitrary corruption model will be presented in section 3.,1 Introduction,[0],[0]
"The key idea of our method is to use a robust covariance matrix estimator, which remains accurate provided a controlled number of arbitrarily corrupted coordinates.",1 Introduction,[0],[0]
"Our theory provides not only the spectral norm based estimation error of the proposed estimator, but also the model selection consistency guarantee.",1 Introduction,[0],[0]
"More importantly, we show that provided that the number of corrupted samples n
2 for each variable satisfies n
2 .",1 Introduction,[0],[0]
"pn/plog d, where n is the sample size and d is the number of variables, the proposed robust precision matrix estimator attains the same statistical rate as the standard estimator for Gaussian graphical models.",1 Introduction,[0],[0]
"Beyond point estimation, we also propose a hypothesis testing procedure to assess the uncertainty of our robust estimator with corrupted observations, and construct the confidence interval for the point estimate.",1 Introduction,[0],[0]
"Thorough experiments on both synthetic data and real-world genomic data corroborate the effectiveness of our method.
",1 Introduction,[0],[0]
"The remainder of this paper is organized as follows: In Section 2, we discuss some more related work about the robust precision matrix estimation.",1 Introduction,[0],[0]
Section 3 summarizes our proposed estimation method and testing procedure in general and also introduces some necessary backgrounds.,1 Introduction,[0],[0]
Section 4 presents our main results including estimation error bound and inference property.,1 Introduction,[0],[0]
"Section 5 provides numerical results, for our method and a number of other methods, of some simulated datasets and a real example on gene expression data.",1 Introduction,[0],[0]
"Section 6 concludes with discussion.
",1 Introduction,[0],[0]
Notation Let A = [Aij ] 2 Rd⇥d be a d ⇥ d matrix and x =,1 Introduction,[0],[0]
"[x
1 , . . .",1 Introduction,[0],[0]
", xd]> 2 Rd be a d-dimensional vector.",1 Introduction,[0],[0]
"For 0 < q < 1, we define the `
0 , `q and `1 vector norms as kxk
0
= Pd i=1",1 Introduction,[0],[0]
"1{xi 6= 0}, kxkq =
( Pd i=1 |xi|q) 1 q , kxk1 = max1id |xi|, where 1{·} represents the indicator function.",1 Introduction,[0],[0]
"We use the following notations for the matrix `q , `max, `1,1 and `F norms: kAkq = maxkxkq=1 kAxkq, kAk1,1 = maxij |Aij",1 Introduction,[0],[0]
"|, kAk1,1 = Pd
i=1",1 Introduction,[0],[0]
Pd j=1,1 Introduction,[0],[0]
"|Aij |, kAkF =",1 Introduction,[0],[0]
( P ij |Aij |2)1/2.,1 Introduction,[0],[0]
"We use A⇤j = (A1j , . . .",1 Introduction,[0],[0]
", Adj)> to denote the j-th column vector of A and A⇤\j to denote the submatrix of A with the jth column A⇤j removed.",1 Introduction,[0],[0]
"We also denote by max(A) and min
(A) the largest and smallest eigenvalues of matrix A, respectively.",1 Introduction,[0],[0]
"Furthermore, for a matrix ⇥ and sets of tuples S, S
1 , ⇥S1,S denotes the set of numbers (⇥jk)j2S1,k2S .",1 Introduction,[0],[0]
"We define the maximum degree of a graph or row cardinality as s = max
1in |{j 2 V | ⇥⇤ij 6= 0}|, where
V = {1, . . .",1 Introduction,[0],[0]
", d} is the vertex set.",1 Introduction,[0],[0]
"Finally, for a sequence of random variables Xn, we write Xn
d !",1 Introduction,[0],[0]
"X , for some random variable X , if Xn converges in distribution to X .",1 Introduction,[0],[0]
"In recent years, some attempts have been made toward the robust estimation of high-dimensional GGMs under different corruption models.",2 Related Work,[0],[0]
"For example, to deal with heavy tailed distributions, Liu et al. (2012) developed a semiparametric approach called the nonparanormal SKEPTIC.",2 Related Work,[0],[0]
Finegold & Drton (2011) proposed a penalized likelihood approach based on multivariate t-distributions.,2 Related Work,[0],[0]
They also proposed an alternative t-model which requires the use of variational EM or Markov chain Monte Carlo algorithms.,2 Related Work,[0],[0]
"Hirose & Fujisawa (2015) introduced a robust estimation procedure for sparse precision matrices based on the penalized negative -likelihood function.
",2 Related Work,[0],[0]
"In order to address outliers, Sun & Li (2012) proposed a robust estimation of GGMs via a robustified likelihood function with `
1 penalization.",2 Related Work,[0],[0]
"In particular, they first use coordinate descent to efficiently estimate the structure of the precision matrix.",2 Related Work,[0],[0]
"Then, based on the estimated structure, they re-estimate the parameters of the precision matrix using iterative proportional fitting algorithm to ensure the positive definiteness of their estimator.",2 Related Work,[0],[0]
Yet their method does not have any theoretical guarantee.,2 Related Work,[0],[0]
Yang & Lozano (2015) proposed a trimmed Graphical Lasso method.,2 Related Work,[0],[0]
"Specifically, by adding weights to different data points, they improved upon the original graphical Lasso such that it is more robust to outliers.",2 Related Work,[0],[0]
"However, they did not provide any model selection consistency guarantee.",2 Related Work,[0],[0]
Balmand & Dalalyan (2015) also studied the problem of robustly estimating the covariance matrix when data are corrupted by outliers.,2 Related Work,[0],[0]
"In particular, they proposed to use a modified scaled lasso procedure for covariance matrix estimation and provided the theoretical guarantee of their method.
",2 Related Work,[0],[0]
"Another line of related work is Öllerer & Croux (2015); Loh & Tan (2015); Chen et al. (2015); Tarr et al. (2016), which studied the problem of robust precision matrix estimation in high dimensions under the ✏-contamination model.",2 Related Work,[0],[0]
"In particular, under the cell-wise contamination model, Tarr et al. (2016) evaluated the performance of the Glasso and CLIME estimators together with a U-statistic based robust covariance estimator for sparse precision matrix estimation.",2 Related Work,[0],[0]
"Under the same contamination model, Öllerer & Croux (2015) provided an analysis for the robustness of these estimators in terms of breakdown behavior.",2 Related Work,[0],[0]
"Later on, from the point of statistical consistency, Loh & Tan (2015) established the statistical error bounds for these estimators.",2 Related Work,[0],[0]
"However, these methods (Öllerer & Croux, 2015; Loh & Tan, 2015; Tarr et al., 2016) highly
depend on the specific cell-wise contamination structure on the data matrix.",2 Related Work,[0],[0]
"Recently, inspired by Tukey’s depth estimator (Tukey, 1975) for vector estimation, Chen et al. (2015) introduced the concept of matrix depth and proposed a robust covariance matrix estimator using empirical depth function.",2 Related Work,[0],[0]
They showed that their proposed estimator can achieve minimax optimal statistical rate under Huber’s ✏-contamination model.,2 Related Work,[0],[0]
"However, it is computationally very expensive to compute the deepest depth of a matrix even in a moderate dimension, which makes such method infeasible in the high-dimensional regime.
",2 Related Work,[0],[0]
All the aforementioned methods are limited to data with heavy tails and outliers.,2 Related Work,[0],[0]
"Therefore, they are not suitable to deal with data that are arbitrarily corrupted.",2 Related Work,[0],[0]
"In this section, we first introduce the setup of our problem, then we present our proposed estimation method and hypothesis testing procedure.",3 Problem Setup and Estimation Method,[0],[0]
"Let X = (X 1 , . . .",3.1 Problem Setup,[0],[0]
", Xd)> be a d-dimensional multivariate Gaussian random vector with zero mean and covariance matrix ⌃⇤.",3.1 Problem Setup,[0],[0]
"It is associated with an undirected graph G = (V,E) with vertex set V = (1, . . .",3.1 Problem Setup,[0],[0]
", d) corresponding to random variables and edge set E = {(j, k) | j 6= k,⇥⇤jk 6= 0} describing the connections of nodes, where ⇥",3.1 Problem Setup,[0],[0]
⇤ = ⌃,3.1 Problem Setup,[0],[0]
"⇤ 1 is the precision matrix.
",3.1 Problem Setup,[0],[0]
Suppose we have n i.i.d.,3.1 Problem Setup,[0],[0]
"observations X 1 , . . .",3.1 Problem Setup,[0],[0]
",Xn, each of which is drawn from the multivariate Gaussian distribution Nd(0,⌃⇤).",3.1 Problem Setup,[0],[0]
Let X =,3.1 Problem Setup,[0],[0]
"[X1, . . .",3.1 Problem Setup,[0],[0]
",Xn]> 2 Rn⇥d be the data matrix and there may exist arbitrary corruption of the data matrix X. More specifically, for each variable/column of data matrix X, we allow at most n
2 coordinates to be arbitrarily corrupted, and we call this kind of corruption model as the arbitrary corruption model.",3.1 Problem Setup,[0],[0]
"Note that under the arbitrary corruption model, we do not require the corrupted entries lie in the same n
2 rows.",3.1 Problem Setup,[0],[0]
"Clearly, a special case of the arbitrary corruption model is the outlier model where the corruption appears in n
2 observations.",3.1 Problem Setup,[0],[0]
"Under the arbitrary corruption model, n
2 is the upper bound on the number of corruptions for each variable, and under the outlier model, n
2 is the upper bound on the number of outliers.",3.1 Problem Setup,[0],[0]
"Specifically, under the outlier model, the set of row indices {1, . . .",3.1 Problem Setup,[0],[0]
", n} of the data matrix X is divided into two disjoint subsets A and O with |A| = n
1 , |O| = n 2 , and n = n
1 + n 2 .",3.1 Problem Setup,[0],[0]
XA denotes samples drawn from the authentic distribution.,3.1 Problem Setup,[0],[0]
XO denotes samples that are outliers.,3.1 Problem Setup,[0],[0]
"In general, there is no constraint on the type of corruptions in our setting except an upper bound on the number of corruptions, i.e., n
2 .",3.1 Problem Setup,[0],[0]
"For example, these corruptions could be drawn from other distributions or even be deterministic.",3.1 Problem Setup,[0],[0]
"Before we introduce our estimation method, we first introduce the truncated inner product which was proposed by Chen et al. (2013).",3.2 Estimation Method,[0],[0]
"The truncated inner product hu,vin2 is defined as follows: given two n-dimensional vectors u,v 2 Rn, and the truncation number n
2 satisfying n 2
 n, we first compute the quantity qi = uivi, for i = 1, . . .",3.2 Estimation Method,[0],[0]
",",3.2 Estimation Method,[0],[0]
"n. Then we sort {|qi|}ni=1 and select the smallest (n n
2 ) ones.",3.2 Estimation Method,[0],[0]
"Let ⌦ be the set of selected indices with cardinality |⌦| = n n
2 , then we have the truncated inner product as hu,vin2 = P i2⌦ qi.
",3.2 Estimation Method,[0],[0]
The main idea of our estimation method is to use a robust covariance matrix estimator which can mitigate the impact of arbitrary corruptions.,3.2 Estimation Method,[0],[0]
"More specifically, given a data matrix X 2 Rn⇥d, which is arbitrarily corrupted, we obtain the robust covariance matrix estimator b⌃ through a truncation procedure that each element b⌃jk is calculated via truncated inner product hX⇤j ,X⇤kin2/n1.",3.2 Estimation Method,[0],[0]
"The motivation of this truncation procedure is that the corrupted coordinates with large magnitude may heavily affect the precision of our estimation results, and this simple truncation procedure can reduce such impact.",3.2 Estimation Method,[0],[0]
"Next, we introduce our robust estimator, which is based on the robust covariance matrix estimator and CLIME: b
⇥ = argmin ⇥2Rd⇥d k⇥k 1,1 subject to kb⌃⇥ Ik1,1  ,
(3.1)
where b⌃ is the robust covariance matrix estimator obtained through truncation, > 0 is a constraint parameter.",3.2 Estimation Method,[0],[0]
We refer to (3.1) as Robust CLIME (RCLIME).,3.2 Estimation Method,[0],[0]
Note that here we do not consider the Glasso type estimator since it requires the stringent incoherence condition on the covariance matrix to guarantee the model selection consistency.,3.2 Estimation Method,[0],[0]
Let ✓⇤i = ⇥⇤⇤i denote the i-th column of ⇥⇤.,3.2 Estimation Method,[0],[0]
"To estimate the precision matrix more efficiently, instead of solving (3.1), we can estimate each column of ⇥⇤ as follows:
b✓ = argmin ✓2Rd k✓k 1 subject to kb⌃✓ eik1  ,
(3.2)
for i = 1, . . .",3.2 Estimation Method,[0],[0]
", d, and ei 2 Rd denotes a column vector that the i-th element is 1 and others are 0.",3.2 Estimation Method,[0],[0]
"Note that the combined solution b⇥1 = [b✓1
1 , . . .",3.2 Estimation Method,[0],[0]
", b✓1d] of (3.2) is equivalent to the solution of (3.1) (Cai et al., 2011).",3.2 Estimation Method,[0],[0]
"In addition, since b ⇥
1 is not symmetric, we need the following symmetrization procedure to get our robust estimator
b ⇥ = arginf ⇥2Sd++ k⇥",3.2 Estimation Method,[0],[0]
"b⇥1k 1 , (3.3)
where",3.2 Estimation Method,[0],[0]
"Sd ++ = {A 2 Rd⇥d | A = A>,A 0} denotes all d ⇥",3.2 Estimation Method,[0],[0]
d symmetric positive definite matrices.,3.2 Estimation Method,[0],[0]
"The symmetrization procedure in (3.3) can be solved by the projected gradient descent method, and in practice, we can use
many simple symmetrization methods, such as the method provided in Cai et al. (2011).",3.2 Estimation Method,[0],[0]
"Based on the proposed robust estimator (3.1), we are interested in testing whether there is an edge between node j and node k in GGMs (Jankova et al., 2015; Neykov et al., 2015; Gu et al., 2015; Xu et al., 2016).",3.3 Hypothesis Test,[0],[0]
"More specifically, we want to develop a procedure for the hypothesis test that H
0
: ⇥",3.3 Hypothesis Test,[0],[0]
⇤ jk = 0 versus H1 : ⇥,3.3 Hypothesis Test,[0],[0]
⇤ jk 6= 0.,3.3 Hypothesis Test,[0],[0]
"Let us assume that the k-th column of the precision matrix ⇥⇤ to be the vector ✓⇤k = (↵
⇤, ⇤>)> where ↵⇤ is the j-th element of the vector ✓⇤k and
⇤ 2 Rd 1 is the remaining (d 1)-dimensional vector.",3.3 Hypothesis Test,[0],[0]
"Thus it is equivalent to test the one dimensional component H
0 : ↵⇤ = 0 versus the non-restricted alternative H
1 : ↵⇤ 6= 0.",3.3 Hypothesis Test,[0],[0]
"In this case, ⇤ are nuisance parameters.",3.3 Hypothesis Test,[0],[0]
"To this end, we first introduce the following estimation equation projected (EEP) along the direction",3.3 Hypothesis Test,[0],[0]
"bw:
bS(✓) = bw> b
⌃✓ ek , (3.4)
where b⌃ is the the robust covariance matrix estimator and b
w is the solution of the optimization problem (3.2) with i = j.",3.3 Hypothesis Test,[0],[0]
The motivation of projecting the estimation equation to a sparse direction (3.4) is to help us construct a test statistic which has a tractable limiting distribution in the high-dimensional regime.,3.3 Hypothesis Test,[0],[0]
"In high-dimensional settings, b ⌃ is not positive definite, we cannot solve the equation b ⌃
b✓ ek = 0 by taking the inverse of b⌃ directly.",3.3 Hypothesis Test,[0],[0]
"Therefore, given the sparsity assumption on ✓⇤, the estimator in (3.2) can address such ill-posed problem for solving the estimation equation b⌃b✓ ek = 0 in high-dimensional settings.",3.3 Hypothesis Test,[0],[0]
"Furthermore, projecting the estimation equation to a certain direction (3.4) makes the limiting distribution of b✓ = (b↵, b >)",3.3 Hypothesis Test,[0],[0]
> in (3.2) tractable.,3.3 Hypothesis Test,[0],[0]
"More specifically, if we choose the bw as the projection direction, then due to the fact that bw is a consistent estimator of w⇤ := ⇥⇤⇤j , the estimator b of the high-dimensional nuisance parameters in (3.2) is asymptotically ignorable along this direction.",3.3 Hypothesis Test,[0],[0]
"Therefore, we can solve the projected estimation equation bS(↵, b ) = 0 to get an debiased estimator of ↵⇤ as follows:
e↵ = b↵ b w
>",3.3 Hypothesis Test,[0],[0]
"( b ⌃
b✓ ek) b w > b ⌃⇤j , (3.5)
where b✓ = (b↵, b >)",3.3 Hypothesis Test,[0],[0]
"> is the estimator of ⇥⇤⇤k, and bw is the estimator of ⇥⇤⇤j .",3.3 Hypothesis Test,[0],[0]
"Thus we define the following test statistic built upon the debiased estimator e↵
bTn = p n 1",3.3 Hypothesis Test,[0],[0]
"(e↵ ↵⇤)/b , (3.6)
where n is the number of observations, n 2 is the upper bound on the number of corruptions, n
1 = n n 2 , and b 2 = bwjb",3.3 Hypothesis Test,[0],[0]
"✓k + bwkb✓j , where bwj , b✓j denote the j-th elements of bw and b✓ respectively.",3.3 Hypothesis Test,[0],[0]
Note that b 2 is a consistent estimator to 2 = w⇤j ✓⇤k + w ⇤,3.3 Hypothesis Test,[0],[0]
k,3.3 Hypothesis Test,[0],[0]
"✓ ⇤ j under the Gaussian
assumption of the data, where w⇤j , ✓⇤k are the j-th and kth columns of w⇤ and ✓⇤ respectively.",3.3 Hypothesis Test,[0],[0]
"We will show in the next section that the proposed debiased estimator e↵ is consistent to ↵⇤, and the test statistic bTn is asymptotically normal p n 1
(e↵ ↵⇤)/b d !",3.3 Hypothesis Test,[0],[0]
"N(0, 1) under the null hypothesis.",3.3 Hypothesis Test,[0],[0]
"Therefore, our asymptotic level-↵ test is given by
n =
(
0 (⌘ accept H 0 )",3.3 Hypothesis Test,[0],[0]
"if | bTn|  C↵, 1 (⌘ reject H
0 ) if | bTn| > C↵, (3.7)
where C↵ = 1(1 ↵/2) is the (1 ↵/2)-quantile of the standard normal distribution N(0, 1).",3.3 Hypothesis Test,[0],[0]
"Furthermore, we can construct asymptotic level-↵ confidence intervals of ↵⇤ as e↵± 1(1 ↵/2)b / p n. Note that in practice, although we have no idea about the exact upper bound on the number of corruptions, i.e., n
2 , we can use techniques such as crossvalidation to choose the best truncation number n
2
.",3.3 Hypothesis Test,[0],[0]
"In this section, we present our main results and discuss connections with some related works.",4 Main Results,[0],[0]
"We start by stating some assumptions, which are required in our analysis.",4 Main Results,[0],[0]
We impose an important eigenvalue condition on the population covariance matrix.,4 Main Results,[0],[0]
Assumption 4.1.,4 Main Results,[0],[0]
"There exist a constant  > 0 such that
0 < 1/  min (⌃ ⇤ )  ",4 Main Results,[0],[0]
max (⌃ ⇤ )   ,4 Main Results,[0],[0]
"< 1.
",4 Main Results,[0],[0]
"This assumption can exclude singular or nearly singular covariance matrices, thus guarantee the uniqueness of ⇥⇤.
",4 Main Results,[0],[0]
"In this paper, we consider the precision matrix ⇥⇤ that belongs to a class of matrices U(s), i.e., U(s) =
⌦ 2 Rd⇥d ⌦ 0, k⌦k 1  M,max 1id Pd j=1 1{⌦ij 6= 0}  s
, where ⌦ 0 means ⌦ is positive definite and s corresponds to the row cardinality.",4 Main Results,[0],[0]
Note that this sparse precision matrix class has been previously considered in Cai et al. (2011); Liu & Wang (2012); Zhao & Liu (2013).,4 Main Results,[0],[0]
"In addition, it immediately implies that k⇥⇤⇤jk1  k⇥⇤k
1  M , where ⇥⇤⇤j is the jth column vector of ⇥⇤.
",4 Main Results,[0],[0]
"Now, we are ready to provide our main results.",4 Main Results,[0],[0]
The first one characterizes the performance of our robust estimator under the arbitrary corruption model.,4 Main Results,[0],[0]
"It shows that even if the upper bound on the number of corruptions n
2 scales with p n, where n is the number of observations, our robust estimator can still recover the correct support.",4 Main Results,[0],[0]
Note that our results are derived under the arbitrary corruption model.,4 Main Results,[0],[0]
"Since the outlier model is a special case of the arbitrary corruption model, our results can directly apply to the outlier case.",4 Main Results,[0],[0]
Theorem 4.2.,4 Main Results,[0],[0]
"Under the arbitrary corruption model, suppose ⇥⇤ 2 U(s) and Assumption 4.1 is satisfied.",4 Main Results,[0],[0]
"In addition, assume the upper bound on the number of corruptions n
2 satisfies n 2  a p n for some constant a 0.",4 Main Results,[0],[0]
"If
n 4a2, and we choose the regularization parameter satisfying = CM2 p
log d/n",4 Main Results,[0],[0]
+,4 Main Results,[0],[0]
"n 2 log d/n , then, with probability at least 1 C
1 /d, the estimator b⇥ in (3.1) satisfies
k b⇥ ⇥",4 Main Results,[0],[0]
"⇤k 2  C 2 M22 ✓ s
r
log d
n",4 Main Results,[0],[0]
"+
n 2 s log d
n
◆
.",4 Main Results,[0],[0]
"(4.1)
Furthermore, if the nonzero entries of ⇥⇤ satisfy
min i 6=j,⇥⇤ij 6=0 |⇥⇤ij | C3M22
✓
r
log d
n",4 Main Results,[0],[0]
"+
n 2 log d
n
◆
,
then the Robust CLIME can correctly identify nonzero entries of ⇥⇤.",4 Main Results,[0],[0]
Remark 4.3.,4 Main Results,[0],[0]
"According to (4.1), the estimation error of our robust estimator consists of two terms.",4 Main Results,[0],[0]
"The first one O(s p
log d/n) corresponds to the estimation error without corruptions.",4 Main Results,[0],[0]
"The second extra term O(sn
2 log d/n), which is linear in n
2 , is due to the effect of arbitrary corruption.",4 Main Results,[0],[0]
"More specifically, if there is no corruption in our data, then the second term becomes zero since n
2 = 0.",4 Main Results,[0],[0]
"Therefore, the estimation error of our method reduces to O(s p
log d/n), which matches the minimax optimal rate for sparse precision matrix estimation without corruptions in terms of spectral norm (Yuan, 2010; Cai et al., 2011; Ravikumar et al., 2011).",4 Main Results,[0],[0]
"In addition, (4.1) in Theorem 4.2 indicates that our robust estimator can correctly recover the support of ⇥⇤ even if the upper bound on the number of corruptions n
2
scales with p
n/ log d, where n is the number of observations.",4 Main Results,[0],[0]
"In addition, under the outlier model, this estimation result is comparable to the result provided by Yang & Lozano (2015).",4 Main Results,[0],[0]
"In their study, they proved that the proposed estimator can successfully recover the true parameter provided that the upper bound of the number of outliers is O( p n).",4 Main Results,[0],[0]
"However, Yang & Lozano (2015) does not consider the case when the data is arbitrarily corrupted.
",4 Main Results,[0],[0]
"Furthermore, if the upper bound on the number of corruptions n
2 satisfies n 2 .",4 Main Results,[0],[0]
"pn/plog d, our robust estimator can achieve the same statistical rate as the standard estimator for Gaussian graphical models.",4 Main Results,[0],[0]
This is summarized in the following corollary.,4 Main Results,[0],[0]
Corollary 4.4.,4 Main Results,[0],[0]
"Under the same conditions of Theorem 4.2, if we further assume that the upper bound on the number of corruptions n
2 satisfies n 2 .",4 Main Results,[0],[0]
"pn/plog d, then for the robust estimator b⇥ in (3.1), we have, with probability at least 1 C/d, that
k b⇥ ⇥",4 Main Results,[0],[0]
"⇤k 2  C 1 M22s
r
log d
n .
",4 Main Results,[0],[0]
"Furthermore, if the nonzero entries of ⇥⇤ satisfy
min i 6=j,⇥⇤ij 6=0 |⇥⇤ij | C2M22
p
log d/n,
then the Robust CLIME can correctly identify the nonzero entries of ⇥⇤.
",4 Main Results,[0],[0]
Remark 4.5.,4 Main Results,[0],[0]
"Compared with Theorem 4.2, Corollary 4.4 implies that under a slightly stricter condition on the upper bound of the number of corruptions n
2
= O( p n/ p log d), our robust estimator can successfully recover the true parameter ⇥⇤ with guaranteed estimation error O(s p
log d/n).",4 Main Results,[0],[0]
"Note that this error bound exactly recover the spectral norm error bound for the case without corruptions (Yuan, 2010; Cai et al., 2011; Ravikumar et al., 2011), which demonstrates the superiority of our estimator.
",4 Main Results,[0],[0]
"Next, we present the asymptotic results of our proposed test statistics in (3.6), which verifies the effectiveness of our testing procedure.",4 Main Results,[0],[0]
"Note that we consider the case that the true observations are drawn from a Gaussian distribution.
",4 Main Results,[0],[0]
Theorem 4.6.,4 Main Results,[0],[0]
"Suppose Assumption 4.1 is satisfied andp n 1 sM24( p log d/n 1 + n 2 log d/n 1 ) 2
= o(1), where n 1 = n n 2
.",4 Main Results,[0],[0]
"If we choose regularization parameter satisfying = CM2( p
log d/n 1 +n 2 log d/n 1 ), then the test statistic in (3.6) is asymptotically normal
p n 1
(e↵ ↵⇤) b d !",4 Main Results,[0],[0]
"N(0, 1),
where b 2 = bwjb✓k + bwkb✓j , and e↵ is defined in (3.5).
",4 Main Results,[0],[0]
Remark 4.7.,4 Main Results,[0],[0]
"Theorem 4.6 provides us an efficient test for the existence of an edge in GGMs, and gives us an efficient interval estimation of ↵⇤ = ⇥⇤ij .",4 Main Results,[0],[0]
"In addition, Theorem 4.6 implies that if the upper bound on the number of corruptions n
2 satisfies n 2 .",4 Main Results,[0],[0]
"pn/plog d and the quantity M is a constant, then the assumptionp n 1",4 Main Results,[0],[0]
"sM24( p log d/n 1 + n 2 log d/n 1 ) 2
= o(1) reduces to s log d/ p n = o(1), which gives us the sparsity assumption that s =",4 Main Results,[0],[0]
O( p n log d).,4 Main Results,[0],[0]
"This requirement on sparsity matches the best-known results for edge testing in GGMs (Liu et al., 2013; Ren et al., 2015).",4 Main Results,[0],[0]
"More importantly, Theorem 4.6 suggests that even when n
2
=",4 Main Results,[0],[0]
"O( p n/ p log d) out of n observations of each variable are arbitrarily corrupted, our testing procedure is still efficient.",4 Main Results,[0],[0]
"In this section, we compare our robust estimator with some existing methods, including trimmed Graphical Lasso (tGLasso) (Yang & Lozano, 2015), t⇤-Lasso (tLasso) (Finegold & Drton, 2011), robust `
1 penalized likelihood (RLL) (Sun & Li, 2012), nonparanormal SKEPTIC (Liu et al., 2012), and pairwise based covariance estimator (spearC) (Loh & Tan, 2015) on some synthetic datasets.",5 Experiments,[0],[0]
Our comparisons focus on their performance in both graph recovery and parameter estimation.,5 Experiments,[0],[0]
The implementation of tLasso and RLL is based on the code provided by authors.,5 Experiments,[0],[0]
"The implementation of other baseline algo-
rithms is based on R package huge1.",5 Experiments,[0],[0]
We conduct some simulations to investigate the performance of our proposed hypothesis testing procedure.,5 Experiments,[0],[0]
"Furthermore, we compare our method with GLasso on a gene expression data.",5 Experiments,[0],[0]
"In our numerical simulations, we consider the following two settings: (i) n = 100, d = 100; and (ii) n = 200, d = 400.",5.1 Synthetic Data,[0],[0]
We generate the true precision matrices based on two graph structures: cluster and band.,5.1 Synthetic Data,[0],[0]
"More specifically, the precision matrices ⇥⇤ are generated by huge package, and the magnitude of correlations is the default value (0.3) in the huge generator.",5.1 Synthetic Data,[0],[0]
"In order to incorporate corruptions, we generate our observations by the following procedure.
",5.1 Synthetic Data,[0],[0]
"For the arbitrary corruption model, we first generate the n by d data matrix X from the Gaussian distribution Nd(0,⇥⇤ 1).",5.1 Synthetic Data,[0],[0]
"Then, for each column of the data matrix, we let np coordinates be arbitrarily corrupted, where we consider the corruption rate p = 0.1 for small number of corruptions and p = 0.2 for large number of corruptions.",5.1 Synthetic Data,[0],[0]
"In addition, each corrupted coordinate is generated by normal distributions N(µ, ) as follows:
MA 1 : µ = 1, = 1, MA 2 : µ = 2, = 1.",5.1 Synthetic Data,[0],[0]
"(5.1)
For the outlier model, we use the setup similar to Sun & Li (2012); Yang & Lozano (2015).",5.1 Synthetic Data,[0],[0]
"Specifically, we generate each observation from the mixture model as follows:
Xi ⇠ (1 p)Nd(0,⇥⇤ 1) +",5.1 Synthetic Data,[0],[0]
"p
2
Nd(µ,⇥ 0 1 )
",5.1 Synthetic Data,[0],[0]
"+
p
2
Nd( µ,⇥0 1) for i = 1, . . .",5.1 Synthetic Data,[0],[0]
", n,
where we consider the corruption rate p = 0.1 for small number of corruptions and p = 0.2 for large number of corruptions.",5.1 Synthetic Data,[0],[0]
"Furthermore, each outlier is generated by normal distributions Nd(µ,⇥0 1 ) as follows
MO 1 : µ = (1, . . .",5.1 Synthetic Data,[0],[0]
", 1)>, ⇥0 = Id, (5.2)
MO 2 : µ = (2, . . .",5.1 Synthetic Data,[0],[0]
", 2)>, ⇥0 = Id. (5.3)
Note that under both corruption models, we set the corruption rate p 2 {0.1, 0.2}.",5.1 Synthetic Data,[0],[0]
"In other words, we choose the number of corruptions to be 10% and 20% of all observations.",5.1 Synthetic Data,[0],[0]
"This is due to the threshold of the number of corruptions n
2
=",5.1 Synthetic Data,[0],[0]
"O( p n) suggested in our theorem.
",5.1 Synthetic Data,[0],[0]
Point Estimation: We choose tuning parameters of each method as follow.,5.1 Synthetic Data,[0],[0]
"For tGLasso, we choose n
2 /n from [0.5, 1], which is suggested by Yang & Lozano (2015).",5.1 Synthetic Data,[0],[0]
"For RLL, we choose 2 {0.005, 0.01, 0.02}, which is suggested by Sun & Li (2012).",5.1 Synthetic Data,[0],[0]
"And for Robust CLIME, we choose n
2 around 15 (±5).",5.1 Synthetic Data,[0],[0]
"Since the performance of t⇤1http://cran.r-project.org/web/packages/huge
Lasso is similar to t-Lasso, we just show the results of t⇤Lasso.",5.1 Synthetic Data,[0],[0]
"All results we reported are their best performance based on these parameters.
",5.1 Synthetic Data,[0],[0]
"First, we use receiver operating characteristic (ROC) curves to compare the overall performance of our method with others in model selection over the full paths.",5.1 Synthetic Data,[0],[0]
"For the arbitrary corruption model, the ROC curves on cluster graphs averaged over 50 simulations are shown in Figure 1.",5.1 Synthetic Data,[0],[0]
"We can observe that under the arbitrary corruption model, as the number of corruptions increase, the advantage of our approach becomes more significant.",5.1 Synthetic Data,[0],[0]
"For the outlier model, we also observe similar good performance of our method, especially for outliers with large magnitude.",5.1 Synthetic Data,[0],[0]
"Due to space limit, the ROC curves for the outlier model can be found in the longer version of this paper.",5.1 Synthetic Data,[0],[0]
"These results indicate that our method is very competitive in the graph recovery problem with arbitrary corruptions.
",5.1 Synthetic Data,[0],[0]
"Then, we evaluate the performance of our method and some existing approaches in parameter estimation.",5.1 Synthetic Data,[0],[0]
"For model settings mentioned above, we choose the corruption rate p = 0.1 for the purpose of comparisons.",5.1 Synthetic Data,[0],[0]
"We generate a dataset as the training sample, and an independent dataset from the same distribution as the test set.",5.1 Synthetic Data,[0],[0]
"We set n 2 /n = 0.9 for tGLasso, = 0.01 for RLL, and n 2
= np for Robust CLIME.",5.1 Synthetic Data,[0],[0]
We also choose the tuning parameter by grid search based on its performance on the training sample and evaluate those estimators on the test set.,5.1 Synthetic Data,[0],[0]
Here we use Spectral norm error k b⇥ ⇥,5.1 Synthetic Data,[0],[0]
"⇤k
2 and Frobenius norm error k b⇥ ⇥",5.1 Synthetic Data,[0],[0]
⇤kF to compare the performance of different methods in parameter estimation.,5.1 Synthetic Data,[0],[0]
Tables 1 and 2 summarize estimation error results in term of Spectral norm averaged over 50 simulations.,5.1 Synthetic Data,[0],[0]
These results demonstrate the advantage of our method in parameter estimation.,5.1 Synthetic Data,[0],[0]
"Other comparison results in terms of Frobenius norm error are deferred to the longer version of this paper.
",5.1 Synthetic Data,[0],[0]
Hypothesis Test: We investigate the finite sample performance of our proposed hypothesis testing procedure through some simulation studies.,5.1 Synthetic Data,[0],[0]
"We use the data generating process similar to Jankova et al. (2015); Neykov et al. (2015), and we consider the case that there are some corruptions in our data.",5.1 Synthetic Data,[0],[0]
"More specifically, for the aforementioned two settings, we consider the band graph structure with band width 1 with the corresponding precision matrix ⇥⇤ generated by R package huge.",5.1 Synthetic Data,[0],[0]
The magnitude of correlations is the default value in the huge generator.,5.1 Synthetic Data,[0],[0]
"In order to incorporate corruptions, we use the same approach described above to generate observations.",5.1 Synthetic Data,[0],[0]
"Specifically, for the arbitrary corruption model, we generate samples through model MA
2 in (5.1) with p = 0.1, 0.2.",5.1 Synthetic Data,[0],[0]
"For the outlier model, we generate samples through model MO
2
in (5.2) with p = 0.1, 0.2.
",5.1 Synthetic Data,[0],[0]
"To check the validity of the type I error of our test, we run
500 simulations.",5.1 Synthetic Data,[0],[0]
The detail of our hypothesis testing procedure is described in Section 3.3.,5.1 Synthetic Data,[0],[0]
"In the two different settings, we set n
2 = 10 and n 2 = 20 respectively, and we choose the tuning parameters by cross-validations.",5.1 Synthetic Data,[0],[0]
Table 3 summarizes the empirical type I errors of our test in different settings.,5.1 Synthetic Data,[0],[0]
"We can observe that the empirical type I
errors are close to the significance level.",5.1 Synthetic Data,[0],[0]
Figure 2 shows the Q-Q plots of our test statistic bTn in (3.6) based on 500 simulations.,5.1 Synthetic Data,[0],[0]
These plots corroborate the asymptotic normality of our test statistic.,5.1 Synthetic Data,[0],[0]
All these results demonstrate the advantage of our hypothesis testing procedure under the arbitrary corruption model.,5.1 Synthetic Data,[0],[0]
"In this subsection, we use the gene expression data of Arabidopsis thaliana, which was analyzed by Wille et al. (2004) and later on by Finegold & Drton (2011); Hirose & Fujisawa (2015), to illustrate the advantage of our method.",5.2 Gene Expression Data,[0],[0]
This data set includes n = 118 observations with 39 gene expression levels.,5.2 Gene Expression Data,[0],[0]
"For this gene expression dataset, we preprocess it through R package limma3.",5.2 Gene Expression Data,[0],[0]
Figure 6 in Appendix illustrates the histogram of some rescaled gene expression data.,5.2 Gene Expression Data,[0],[0]
"It shows that some rescaled gene expressions contain some expression levels with extreme large magnitude, which may be outliers.",5.2 Gene Expression Data,[0],[0]
"Therefore, we want to apply our method to construct a network among these genes.",5.2 Gene Expression Data,[0],[0]
"For Robust CLIME, we set n
2 = 10 and adopt 5-fold crossvalidation to choose the tuning parameter .
",5.2 Gene Expression Data,[0],[0]
The graph estimated by our method is given in Figure 3.,5.2 Gene Expression Data,[0],[0]
"The dotted arrows and the solid undirected edges correspond to the known metabolic pathway and the graph estimated by Robust CLIME, respectively.",5.2 Gene Expression Data,[0],[0]
We can see that our approach identifies a similar graph to that obtained by previous analysis of Wille et al. (2004) but with fewer ”crosstalk” edges between two pathways.,5.2 Gene Expression Data,[0],[0]
"For example, our approach finds the important connection between AACT2 and
3Available on http://bioconductor.org/packages/limma
the group MK, MPDC1, and FFPS2 in MAV pathway.",5.2 Gene Expression Data,[0],[0]
"And in MEP path way, it also identifies the connection among DXR, MCT, CMK and MECPS.",5.2 Gene Expression Data,[0],[0]
Other methods such as GLasso tends to estimate more links between two pathways in order to identify these important relationships.,5.2 Gene Expression Data,[0],[0]
These edges between two pathways provided by GLasso might be inaccurate relationships due to the lack of robustness.,5.2 Gene Expression Data,[0],[0]
The graph recovered by GLasso and the graph established by Wille et al. (2004) can be found in the longer version of this paper.,5.2 Gene Expression Data,[0],[0]
"In this paper, for the Gaussian graphical model estimation with arbitrary corruptions, we proposed a new estimator for high-dimensional precision matrices based on the robust covariance matrix estimator.",6 Conclusions and Future Work,[0],[0]
"We not only provide the estimation error bound of our robust estimator, but also propose a hypothesis testing procedure to assess the uncertainty of our robust estimator with corrupted observations, and construct the confidence interval for the point estimate.",6 Conclusions and Future Work,[0],[0]
"However, most of the robust high dimensional estimators as well as our proposed estimator are not invariant under the group action (Davies et al., 2005; Draisma et al., 2013), we will study this problem in our future work.",6 Conclusions and Future Work,[0],[0]
We would like to thank the anonymous reviewers for their helpful comments.,Acknowledgment,[0],[0]
This research was sponsored in part by the National Science Foundation IIS-1618948 and IIS1652539.,Acknowledgment,[0],[0]
The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies.,Acknowledgment,[0],[0]
We study the problem of estimating the highdimensional Gaussian graphical model where the data are arbitrarily corrupted.,abstractText,[0],[0]
We propose a robust estimator for the sparse precision matrix in the highdimensional regime.,abstractText,[0],[0]
"At the core of our method is a robust covariance matrix estimator, which is based on truncated inner product.",abstractText,[0],[0]
We establish the statistical guarantee of our estimator on both estimation error and model selection consistency.,abstractText,[0],[0]
"In particular, we show that provided that the number of corrupted samples n",abstractText,[0],[0]
Robust Gaussian Graphical Model Estimation with Arbitrary Corruption,title,[0],[0]
In this paper we study the guarantees of stochastic optimization algorithms for submodular maximization.,1. Introduction,[0],[0]
A function f : 2N → R is submodular if it exhibits a diminishing returns property.,1. Introduction,[0],[0]
"That is, for any S ⊆ T ⊆ N and any a /∈ T , the function respects:
fS(a) ≥ fT (a)
where fH(x) denotes the marginal contribution of an element x ∈ N to a set H ⊆ N , i.e. fH(x) = f(H ∪ x) −
*Equal contribution 1Bar Ilan University and Google 2Harvard University.",1. Introduction,[0],[0]
"Correspondence to: Avinatan Hassidim <avinatan@cs.biu.ac.il>, Yaron Singer <yaron@seas.harvard.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
f(H).",1. Introduction,[0],[0]
"Many fundamental measures such as entropy, diversity, and clustering can be modeled as submodular functions, and as a result submodular optimization is heavily studied in machine learning for well over a decade now.
",1. Introduction,[0],[0]
"It is well known that for the problem of maximizing a monotone (S ⊆ T =⇒ f(S) ≤ f(T )) submodular function under a cardinality constraint, the celebrated greedy algorithm which iteratively adds the element whose marginal contribution is maximal, obtains an approximation guarantee of 1−1/",1. Introduction,[0],[0]
"e (Nemhauser et al., 1978).",1. Introduction,[0],[0]
"This is optimal unless P=NP (Feige) or alternatively, assuming polynomiallymany function evaluations (Nemhauser & Wolsey, 1978).
",1. Introduction,[0],[0]
"In recent years, there have been various adaptations of the classic greedy algorithm to allow for scalable, distributed, and noise-resilient optimization.",1. Introduction,[0],[0]
"Most notably, the STOCHASTIC-GREEDY algorithm recently proposed by (Mirzasoleiman et al., 2015) is a linear-time algorithm which at every step takes an element, which approximates in expectation the element with the maximal marginal contribution.",1. Introduction,[0],[0]
"Mirzasoleiman et al. show that STOCHASTICGREEDY gives an approximation guarantee which is arbitrarily close to 1 − 1/e in expectation, and does very well in practice (Mirzasoleiman et al., 2015; Lucic et al., 2016).",1. Introduction,[0],[0]
"Variants of this algorithm are used in clustering (Malioutov et al., 2016), sparsification (Lindgren et al., 2016), Gaussian RBF kernels (Sharma et al., 2015), sensing (Li et al., 2016), and social data analysis (Zhuang et al., 2016).
",1. Introduction,[0],[0]
"More generally, a greedy algorithm that iteratively adds elements that are only approximately maximal in expectation, may not necessarily be due to a design decision, but rather an artifact of its application on large and noisy data sets (see e.g. (Azaria et al., 2013)).",1. Introduction,[0],[0]
"One can model this uncertainty with a probability distribution D: at every iteration, a value ξ ∼ D is being sampled, and the greedy algorithm adds an element whose marginal contribution is a ξ-approximation to the maximal marginal contribution.
",1. Introduction,[0],[0]
"In general, we refer to an algorithm that iteratively adds an element whose marginal contribution is approximately optimal in expectation as a stochastic greedy algorithm.",1. Introduction,[0],[0]
"It is easy to show that stochastic greedy algorithms give an approximation ratio of 1 − 1/eµ in expectation, where µ is the mean of the distribution modeling the uncertainty.",1. Introduction,[0],[0]
"This however is a weak guarantee as it leaves a non-negligible
likelihood that the algorithm terminates with a solution with a poor approximation guarantee.",1. Introduction,[0],[0]
"Indeed, as we later show, there are cases where stochastic greedy algorithms have desirable guarantees in expectation, but with constant probability have arbitrarily bad approximation guarantees.",1. Introduction,[0],[0]
"We prove the following results:
• Optimization under cardinality constraints.",1.1. Our results,[0],[0]
"For the problem of maximizing a monotone submodular function under cardinality constraint k, with uncertainty distributionD with expectation µ, we show that for any ε ∈",1.1. Our results,[0],[0]
"[0, 1], when k ≥ 1µε2 a stochastic greedy algorithm obtains an approximation of 1 − 1/e(1−ε)µ w.p. at least 1−e−µkε2/2.",1.1. Our results,[0],[0]
"Furthermore, we prove that this bound is optimal by showing that for any δ > 0",1.1. Our results,[0],[0]
no algorithm can obtain an approximation ratio better than 1− 1/e(1−ε)µ w.p. 1− δ.,1.1. Our results,[0],[0]
"For the special case in which the function is modular, we prove an improved bound of (1− ε)µ w.p. at least 1− e−µkε2/2;
• Optimization under matroid constraints.",1.1. Our results,[0],[0]
"To further study the difference between guarantees that occur in expectation and guarantees which appear w.h.p, we study a generalization, where the greedy algorithm is used to maximize a monotone submodular function under intersection of matroid constraints, where a distribution D with mean µ generates uncertainty.",1.1. Our results,[0],[0]
"We show that in this case, with P matroids the algorithm obtains an approximation ratio of µ/(P +1) in expectation.",1.1. Our results,[0],[0]
"However, we show that even for a single matroid no algorithm can give a finite approximate guarantee w.p. at least 1−µ−o(1), implying that in general stochastic greedy algorithms cannot obtain high probability guarantees under general matroid constraints;
• Stochastic local search.",1.1. Our results,[0],[0]
"Finally, a natural alternative to greedy is local search.",1.1. Our results,[0],[0]
"We show that even for cardinality constraints local search performs poorly, and does not give any meaningful approximation guarantees when there is probabilistic uncertainty about the quality of the elements.",1.1. Our results,[0],[0]
"We contrast this with the case where there is deterministic uncertainty about the quality of the elements, in which we get an approximation ratio of (1 + 1/µ)−1, where µ is our uncertainty.",1.1. Our results,[0],[0]
This implies that local search does not enjoy the same robustness guarantees of the greedy algorithms under uncertainty of the quality of elements.,1.1. Our results,[0],[0]
"The above results have several immediate consequences:
• Fast algorithms for submodular optimization.",1.2. Applications,[0],[0]
"Our analysis applies to the STOCHASTIC-GREEDY algorithm (Mirzasoleiman et al., 2015), thus showing its approximation guarantee holds with high probability, implying it is the optimal algorithm in terms of running time and approximation guarantee for the problem of maximizing a submodular function under a cardinality constraint; 1 The same guarantee holds for the variants studied in (Malioutov et al., 2016; Lindgren et al., 2016; Sharma et al., 2015; Li et al., 2016);
• Submodular optimization under noise.",1.2. Applications,[0],[0]
"In (Hassidim & Singer, 2017) the problem of maximization of submodular functions under a cardinality constraint is considered when given access to a noisy oracle.",1.2. Applications,[0],[0]
"Our result simplifies the analysis of one of the algorithms in this setting, and gives high probability results for the inconsistent noise model (Singla et al., 2016).",1.2. Applications,[0],[0]
"We describe the results for general monotone submodular functions in Section 2, and the improved analysis for modular functions in Section 3.",1.3. Organization of the paper,[0],[0]
"In Section 4 we consider the more general problem of maximizing a submodular function under matroid constraints, and show the inapproximabilities of stochastic local search algorithms in Section 5.",1.3. Organization of the paper,[0],[0]
"Finally, we discuss experiments in Section 6.",1.3. Organization of the paper,[0],[0]
In this section we analyze the stochastic greedy algorithm for general monotone submodular functions.,2. Submodular Functions,[0],[0]
"We first analyze the algorithm, and then show the bound is tight.",2. Submodular Functions,[0],[0]
"For a given cardinality constraint k, the standard greedy algorithm begins with the empty set as its solution and at each step {1, . . .",2.1. Upper bound,[0],[0]
", k} adds the element whose marginal contribution to the existing solution is largest.",2.1. Upper bound,[0],[0]
"In the stochastic version, the algorithm may no longer add the element whose marginal contribution is largest.",2.1. Upper bound,[0],[0]
"Rather, the algorithm adds the element whose marginal contribution is at least a factor of ξ from the maximal marginal contribution, where ξ is drawn i.i.d from some distribution D with mean µ.",2.1. Upper bound,[0],[0]
"We give a formal description below.
",2.1. Upper bound,[0],[0]
"1Formally, the algorithm in (Mirzasoleiman et al., 2015) does not assume that the expected marginal contribution of the element selected is approximately optimal, but rather that in expectation its marginal contribution approximates that of some element in the optimal solution.",2.1. Upper bound,[0],[0]
"Nevertheless our analysis still applies.
",2.1. Upper bound,[0],[0]
"Algorithm 1 STOCHASTIC-GREEDY input k
1: S ← ∅ 2:",2.1. Upper bound,[0],[0]
while |S| < k do 3: ξ ∼ D 4: S ← S ∪ arbitrary a s.t. fS(a),2.1. Upper bound,[0],[0]
"≥ ξmaxx∈N fS(x) 5: end while
output S
The following lemma shows that when the sampled mean of the distribution is close to 1, stochastic greedy algorithms obtain a near optimal performance guarantee.
",2.1. Upper bound,[0],[0]
Lemma 1.,2.1. Upper bound,[0],[0]
Let S be the set of k elements selected by a stochastic greedy algorithm s.t. in each iteration,2.1. Upper bound,[0],[0]
i ∈,2.1. Upper bound,[0],[0]
"[k] the algorithm selects an element whose marginal contribution is an ξi approximation to the marginal contribution of the element with the largest marginal contribution at that stage, and let µ̂ = 1k ∑k i=1",2.1. Upper bound,[0],[0]
ξi.,2.1. Upper bound,[0],[0]
"Then:
f(S) ≥ ( 1− 1
eµ̂
) OPT.
",2.1. Upper bound,[0],[0]
Proof.,2.1. Upper bound,[0],[0]
"Let Si = {a1, . . .",2.1. Upper bound,[0],[0]
", ai}, and let the optimal solution be O, i.e. O ∈ argmaxT :|T |≤k f(T ).",2.1. Upper bound,[0],[0]
Note that for any i,2.1. Upper bound,[0],[0]
< k,2.1. Upper bound,[0],[0]
"we have that:
f(Si+1)− f(Si) = fSi(ai+1) ≥ ξi+1",2.1. Upper bound,[0],[0]
"max
o∈O fSi(o)
≥",2.1. Upper bound,[0],[0]
ξi+1 k fSi(O) = ξi+1 k (f(O ∪ Si)− f(Si)),2.1. Upper bound,[0],[0]
≥ ξi+1 k,2.1. Upper bound,[0],[0]
"(f(O)− f(Si))
",2.1. Upper bound,[0],[0]
"Rearranging, we get:
f(Si+1) ≥ ξi+1",2.1. Upper bound,[0],[0]
"k
( f(O)− f(Si) )",2.1. Upper bound,[0],[0]
+ f(Si),2.1. Upper bound,[0],[0]
"(1)
We will show by induction that in every iteration i ∈",2.1. Upper bound,[0],[0]
"[k]:
f(Si)",2.1. Upper bound,[0],[0]
≥ 1− i∏ j=1 ( 1− ξj k ),2.1. Upper bound,[0],[0]
"f(O) The base case is when i = 1, and S0 = ∅ and by (1):
f(S1) ≥ ξi+1 k
( f(O)− f(S0) )",2.1. Upper bound,[0],[0]
= 1−,2.1. Upper bound,[0],[0]
"( 1− ξ1
k
)",2.1. Upper bound,[0],[0]
"f(O)
For a general iteration i+1, applying (1) for iteration i+1
and using the inductive hypothesis:
f(Si+1)
≥ ξi+1 k f(O) +
( 1− ξi+1
k
) f(Si)
≥ ξi+1 k f(O) +
( 1− ξi+1
k )",2.1. Upper bound,[0],[0]
1− i∏ j=1 ( 1− ξj k ),2.1. Upper bound,[0],[0]
f(O),2.1. Upper bound,[0],[0]
"=
1− i+1∏ j=1 ( 1− ξj k ) f(O) Since 1− x ≤ e−x, the above inequality implies:
f(S) = f(Sk)
= 1− k∏ j=1 ( 1− ξj k ) f(O) ≥ ( 1− e− 1k ∑k i=1 ξi )",2.1. Upper bound,[0],[0]
"f(O)
= ( 1− e−µ̂ ) f(O).
",2.1. Upper bound,[0],[0]
"We can now apply concentration bounds on the previous lemma and prove the main theorem.
Theorem 2.",2.1. Upper bound,[0],[0]
"Let f be a monotone submodular function, which is evaluated with uncertainty coming from a distribution D with mean µ. For any ε ∈ (0, 1), suppose a stochastic greedy algorithm is being used with k ≥ 2ε2µ .",2.1. Upper bound,[0],[0]
"Then, w.p. 1− e− εµ·k 2 the algorithm returns S s.t.:
f(S) ≥ ( 1− 1
e(1−ε)µ
) OPT
Proof.",2.1. Upper bound,[0],[0]
"Consider an application of the stochastic greedy algorithm with mean µ, and let ξ1, . . .",2.1. Upper bound,[0],[0]
", ξk be the approximations to the marginal contributions made by i.i.d samples from a distribution in all iterations 1, . . .",2.1. Upper bound,[0],[0]
", k.",2.1. Upper bound,[0],[0]
"Since all the values {ξi}ki=1 drawn from the distribution are bounded from above by 1, by the Chernoff bound we have:
Pr
[ 1
k k∑ i=1",2.1. Upper bound,[0],[0]
ξi,2.1. Upper bound,[0],[0]
<,2.1. Upper bound,[0],[0]
"(1− ε)µ
] < e εµ·k 2
By applying Lemma 1 we get our result.",2.1. Upper bound,[0],[0]
Claim 3.,2.2. Tight lower bound,[0],[0]
For any δ ∈,2.2. Tight lower bound,[0],[0]
"[0, 1) the competitive ratio of stochastic greedy with mean µ is at most (1−1/eµ)+o(1) with probability",2.2. Tight lower bound,[0],[0]
"at least 1− δ.
",2.2. Tight lower bound,[0],[0]
Proof.,2.2. Tight lower bound,[0],[0]
"Consider maximizing a submodular function when the oracle has probability µ of returning the element with
the largest marginal contribution, and probability 1 − µ to return a random element.",2.2. Tight lower bound,[0],[0]
We present an instance where greedy returns an approximation ratio of at most 1−1/eµ+ o(1) with probability at least 1−1/,2.2. Tight lower bound,[0],[0]
k.,2.2. Tight lower bound,[0],[0]
"We use the same bad instance regardless of µ.
The construction is as follows.",2.2. Tight lower bound,[0],[0]
"There are k special elements, m = 4k3 plain elements and n = 4(m + k)k2 dummy elements (note that the total number of elements is not n).",2.2. Tight lower bound,[0],[0]
"The value f(S) depends only on the number of special elements, plain elements and dummy elements contained in S (all special elements are identical).",2.2. Tight lower bound,[0],[0]
"Moreover, dummy elements contribute nothing to f , and hence, we can write f(S) = f(i, j), where i is the number of special elements in S, and j is the number of plain elements.
",2.2. Tight lower bound,[0],[0]
"For i ≥ 1, the value of f depends on j as follows:
f(i, j) =  kk-(k-1)jkk-j-1(k-i) 0",2.2. Tight lower bound,[0],[0]
≤ j ≤ k-1,2.2. Tight lower bound,[0],[0]
kk-(k-1)k-2((k-i)(2k-2-j)),2.2. Tight lower bound,[0],[0]
k ≤,2.2. Tight lower bound,[0],[0]
j ≤ 2k-3 kk-(k-1)k-2(3k-i-j-3) 2k-2 ≤,2.2. Tight lower bound,[0],[0]
j ≤,2.2. Tight lower bound,[0],[0]
3k-3-i kk 3k,2.2. Tight lower bound,[0],[0]
− i,2.2. Tight lower bound,[0],[0]
"− 2 ≤ j
Note that for i = 0, we have f(0, j) =",2.2. Tight lower bound,[0],[0]
"f(1, j − 1), and f(0, 0) = 0.",2.2. Tight lower bound,[0],[0]
"Also, one can verify, by case-by-case analysis that this function is indeed monotone and submodular.
",2.2. Tight lower bound,[0],[0]
"Since f(0, j) = f(1, j − 1) for every j ≥ 1, as long as the greedy algorithm did not choose any special element yet, the marginal contribution of a special elements is equal to the marginal contribution of a plain element.
",2.2. Tight lower bound,[0],[0]
Let t be the number of times in which the oracle supplied the greedy algorithm with the element with the maximal marginal contribution.,2.2. Tight lower bound,[0],[0]
"By an additive version of the Chernoff bound we have that with probability at least 1− 24 log k = 1− k4:
",2.2. Tight lower bound,[0],[0]
t < kµ+ 2 √ k log,2.2. Tight lower bound,[0],[0]
"k
We condition on this event.",2.2. Tight lower bound,[0],[0]
"Next, we argue that with probability at least 1 − 1/3k all the elements for which the algorithm selected a random element (i.e. did not take an element whose marginal contribution is a µ approximation to the largest marginal contribution) are dummy elements.",2.2. Tight lower bound,[0],[0]
Consider one of the times in which greedy was given a random element.,2.2. Tight lower bound,[0],[0]
The probability that it was not a dummy element is at most m+k4(m+k)k2−k .,2.2. Tight lower bound,[0],[0]
"Applying a union bound, the probability that in the k − t cases in which greedy was supplied with a random element it was always a dummy element is at least 1− 1/3k.",2.2. Tight lower bound,[0],[0]
"We condition on this event.
",2.2. Tight lower bound,[0],[0]
We will now argue that with probability at least 1−1/3k all the non-dummy elements selected are plain.,2.2. Tight lower bound,[0],[0]
Consider the first non dummy element chosen by the algorithm.,2.2. Tight lower bound,[0],[0]
With probability at least 1 − k/4k3 it is a plain element.,2.2. Tight lower bound,[0],[0]
"We
condition on this event.",2.2. Tight lower bound,[0],[0]
"Assuming by induction that the last i − 1 non dummy elements which were chosen by greedy were plain, the probability that i’th non dummy element is plain is 1 − k4k3−1 .",2.2. Tight lower bound,[0],[0]
"Taking a union bound over all t such elements, gives that with probability 1 − 1/3k all t nondummy elements chosen by greedy were plain.
",2.2. Tight lower bound,[0],[0]
"Combining this together with a union bound, we get that with probability at least 1 − 1/k greedy chose no special elements, at most t = µk + 4 √ k log k plain elements, and the rest are dummy elements that do not contribute to the value of the function.",2.2. Tight lower bound,[0],[0]
"This means that the value of the solution is at most kk− (k−1)tkk−t, and thus with probability at least 1 − 1/k the ratio between the value of greedy and the optimal value is at least:
kk − (k − 1)tkk−t
kk = 1−",2.2. Tight lower bound,[0],[0]
"( k − 1 k )t
≥ 1− (( 1− 1
k )",2.2. Tight lower bound,[0],[0]
k)µ+ 4 log k√k ≥,2.2. Tight lower bound,[0],[0]
1−,2.2. Tight lower bound,[0],[0]
"e−(µ+4 log k/ √ k)
",2.2. Tight lower bound,[0],[0]
"= 1− e−µ + o(1)
Choosing k = 1/δ",2.2. Tight lower bound,[0],[0]
we get our desired bound.,2.2. Tight lower bound,[0],[0]
In this section we show a tight upper bound for the special case in which the function is modular.,3. Modular Functions,[0],[0]
Recall that a function f : 2N → R is modular if for every set S ⊆ N,3. Modular Functions,[0],[0]
we have that f(S) = ∑ a∈S f(a).,3. Modular Functions,[0],[0]
Note that in this case fS(a) = f(a) for all S ⊆ N and a ∈ N .,3. Modular Functions,[0],[0]
Theorem 4.,3. Modular Functions,[0],[0]
Let S ⊆ N be the set returned when applying a stochastic greedy algorithm with mean µ ∈,3. Modular Functions,[0],[0]
"[0, 1] on a modular function f : 2N → R. Then, for any ε ∈",3. Modular Functions,[0],[0]
"[0, 1], when k ≥ 2ε2µ w.p. 1− e −µkε2/2:
f(S) ≥ (1− ε)µOPT.
",3. Modular Functions,[0],[0]
Proof.,3. Modular Functions,[0],[0]
Suppose that at every stage i ∈,3. Modular Functions,[0],[0]
[k] element ai ∈ N,3. Modular Functions,[0],[0]
is selected and its marginal contribution is at least ξi of the optimal marginal contribution at that stage.,3. Modular Functions,[0],[0]
Let O be the optimal solution and o? ∈ argmaxo∈O\S,3. Modular Functions,[0],[0]
"f(o), where S is the solution retuned by the algorithm, i.e. S = {a1, . .",3. Modular Functions,[0],[0]
.,3. Modular Functions,[0],[0]
", ak}.",3. Modular Functions,[0],[0]
"The basic idea in this proof is to observe that since o? is not in the solution and throughout the iterations of the algorithm is always a feasible candidate, this implies that every element ai in the solution S\O has value at least as large as ξif(o?).",3. Modular Functions,[0],[0]
"Intuitively, if there are enough elements in S \",3. Modular Functions,[0],[0]
"O for concentration bounds to kick in, we have that 1|S\O| ∑ j∈S\O ξj = (1 − ε)µ",3. Modular Functions,[0],[0]
and we would be done since f(S) = f(S \O)+f(O∩S),3. Modular Functions,[0],[0]
"≥ (1− ε)µf(O).
",3. Modular Functions,[0],[0]
"The problem is that S \O may not be sufficiently large, and we therefore need slightly more nuanced arguments.
",3. Modular Functions,[0],[0]
We will partition O∩S to two disjoint sets of low and high valued elements: L = {o ∈,3. Modular Functions,[0],[0]
O ∩,3. Modular Functions,[0],[0]
S : f(o) < f(o?)} and H = {o ∈ O ∩,3. Modular Functions,[0],[0]
S : f(o) ≥ f(o?)}.,3. Modular Functions,[0],[0]
"Notice that:
f(O)
= f(O \ S) + f(L) + f(H) = ∑ o∈O\S f(o) + ∑ o∈L f(o) + ∑ o∈H f(o)
≤ ∑ o∈O\S f(o?)",3. Modular Functions,[0],[0]
+,3. Modular Functions,[0],[0]
∑ o∈L f(o?),3. Modular Functions,[0],[0]
+ ∑ o∈H f(o?) +,3. Modular Functions,[0],[0]
( f(o)-f(o?) ),3. Modular Functions,[0],[0]
"= k · f(o?) +
∑ o∈H (f(o)-f(o?))
",3. Modular Functions,[0],[0]
Since o? ∈,3. Modular Functions,[0],[0]
"O \S, it is a feasible choice for the algorithm at every stage, and therefore by the definition of the stochastic greedy algorithm, for every element ai ∈ S",3. Modular Functions,[0],[0]
"we have that:
f(ai) ≥ ξimax a∈N fS(a)",3. Modular Functions,[0],[0]
"= ξi max a∈N\S f(a) ≥ ξif(o?)
",3. Modular Functions,[0],[0]
"Thus, for k ≥ 2/ε2 with probability 1− e− kµε2 2 :
f(S)
= f(S \O) + f(H) + f(L) = ∑
ai∈S\O f(ai) + ∑ ai∈L f(ai) + ∑ o∈H f(o)
≥ ∑
ai∈S\O
ξif(o ?)",3. Modular Functions,[0],[0]
+ ∑ ai∈L ξif(o ?),3. Modular Functions,[0],[0]
"+ ∑ o∈H f(o)
= f(o?)  ",3. Modular Functions,[0],[0]
∑ ai∈(S\O)∪L,3. Modular Functions,[0],[0]
"ξi +∑ o∈H f(o)
= f(o?)  ",3. Modular Functions,[0],[0]
∑ ai∈(S\O)∪L,3. Modular Functions,[0],[0]
"ξi +∑ o∈H ( f(o?) + f(o)-f(o?) )
",3. Modular Functions,[0],[0]
≥ f(o?)  ,3. Modular Functions,[0],[0]
∑ ai∈(S\O)∪L∪H ξi +∑ o∈H ( f(o)-f(o?) ),3. Modular Functions,[0],[0]
"(2)
≥ (1− ε)µ · kf(o?)",3. Modular Functions,[0],[0]
+ ∑ o∈H ( f(o)-f(o?) ),3. Modular Functions,[0],[0]
"(3)
≥ (1− ε)µ ( kf(o?)",3. Modular Functions,[0],[0]
"+
∑ o∈H ( f(o)-f(o?) ))",3. Modular Functions,[0],[0]
"≥ (1− ε)µf(O)
where inequality (2) is due to the fact that f(o?) ≥ ξif(o?)",3. Modular Functions,[0],[0]
"since ξi ≤ 1; inequality (3) is an application of the Chernoff bound for k ≥ 2/ε2µ; the last inequality is due to the upper bound we established on f(O).
",3. Modular Functions,[0],[0]
The upper bound is tight.,3. Modular Functions,[0],[0]
An obvious lower bound holds for the degenerate case where in every stage the marginal contribution of the element returned is a µ ∈,3. Modular Functions,[0],[0]
"[0, 1] approximation to the maximal marginal contribution with probability 1.",3. Modular Functions,[0],[0]
"Clearly in this case, the approximation ratio is no better than µ (consider n = 2k elements where k elements have value 1 and k elements have value µ).",3. Modular Functions,[0],[0]
In this section we consider the more general problem of maximizing a monotone submodular function under matroid constraints.,4. General Matroid Constraints,[0],[0]
"Recall that a matroid is a pair (N, I) where N is the ground set and I is a family of subsets of N called independent that respects two axioms: (1) A ∈ I, A′ ⊂",4. General Matroid Constraints,[0],[0]
A =⇒ A′ ∈,4. General Matroid Constraints,[0],[0]
"I and (2) if A,B ∈ I and |B| < |A| then ∃x ∈",4. General Matroid Constraints,[0],[0]
"A \ B, s.t. B ∪ {x} ∈ I.",4. General Matroid Constraints,[0],[0]
"The rank of the matroid is the size of the largest set in I. The cardinality constraint, is a special case of optimization under matroid constraints, where the matroid is uniform.
",4. General Matroid Constraints,[0],[0]
Submodular maximization under matroid constraints.,4. General Matroid Constraints,[0],[0]
The greedy algorithm for maximization under matroid constraints is a simple generalization of the uniform case: the algorithm iteratively identifies the element whose marginal contribution is maximal and adds it to the solution if it does not not violate the matroid constraint (i.e. if adding the element to the set keeps the set in the family of feasible sets I).,4. General Matroid Constraints,[0],[0]
This algorithm obtains an approximation ratio of 1/2.,4. General Matroid Constraints,[0],[0]
"2 More generally, for an intersection of P matroids, this algorithm obtains an approximation guarantee of 1/(1 + P ).
",4. General Matroid Constraints,[0],[0]
Stochastic greedy under intersection of matroids.,4. General Matroid Constraints,[0],[0]
"Consider an intersection of matroids, a monotone submodular function f defined over the independent sets, and an uncertainty distribution D with mean µ. The stochastic greedy algorithm begins with the solution S = ∅ and set of elements not yet considered X = N .",4. General Matroid Constraints,[0],[0]
In every iteration the algorithm maintains a solution S of elements that are in the intersection of the P matroids and a value ξ ∼ D is sampled.,4. General Matroid Constraints,[0],[0]
"The algorithm then considers an arbitrary element a ∈ X whose marginal contribution is ξmaxx∈X fS(x), and adds a to S if S ∪ a is independent in all P matroids, and discards a from X .",4. General Matroid Constraints,[0],[0]
"We first show that unlike the special case of uniform matroids, even for a single matroid, it is generally impossible to obtain high probability guarantees for maximization un-
2We note that unlike the uniform case, here greedy is not optimal.",4.1. Stochastic greedy fails with high probability,[0],[0]
"The optimal guarantee of 1 − 1/e can be obtained via an algorithm based on a continuous relaxation (Vondrák, 2008) or through local search (Filmus & Ward, 2012).
",4.1. Stochastic greedy fails with high probability,[0],[0]
"der matroid constraints, even when the function is modular and the rank of the matroid is sufficiently large.",4.1. Stochastic greedy fails with high probability,[0],[0]
Claim 5.,4.1. Stochastic greedy fails with high probability,[0],[0]
"Even for a modular function and arbitrarily large k, a stochastic greedy algorithm with mean µ cannot obtain an approximation better than 0 with probability greater than µ+ o(1), for maximization under matroid of rank k.
Proof.",4.1. Stochastic greedy fails with high probability,[0],[0]
"Consider the following example, where the ground set has two types of elements A = {a1, . . .",4.1. Stochastic greedy fails with high probability,[0],[0]
", am}, and B = {b1, . . .",4.1. Stochastic greedy fails with high probability,[0],[0]
", bk−1} where m = k2.",4.1. Stochastic greedy fails with high probability,[0],[0]
"The rank of the matroid is k, and a set is independent as long as it contains just a single ai ∈ A. Define a modular function: f(a1) = 1, but f(aj) = 0 for j 6= 1, and also f(bj) = 0 for any j ∈",4.1. Stochastic greedy fails with high probability,[0],[0]
[k−1].,4.1. Stochastic greedy fails with high probability,[0],[0]
"The distribution returns 1 w.p. p < 1/2 and 0 otherwise.
",4.1. Stochastic greedy fails with high probability,[0],[0]
"In the first iteration of the algorithm, the element a1 is correctly evaluated with probability p, and with probability 1 − p",4.1. Stochastic greedy fails with high probability,[0],[0]
"it is evaluated as having value 0, in which case we may assume that a random element is selected instead.",4.1. Stochastic greedy fails with high probability,[0],[0]
"Therefore, w.p. p the algorithm takes a1, and obtains the optimal solution.",4.1. Stochastic greedy fails with high probability,[0],[0]
"However, if this is not the case, then w.p. m−1/(m+k) = (k2−1)/(k2+k) the algorithm chooses an element from A whose value is 0.",4.1. Stochastic greedy fails with high probability,[0],[0]
"In this case, even if a1 is later correctly evaluated it could not be considered into the solution since its inclusion violates independence.",4.1. Stochastic greedy fails with high probability,[0],[0]
"Hence, while the expected value of greedy is slightly larger than p, with probability at least (1− p)− o(1) the value of the solution would be 0.",4.1. Stochastic greedy fails with high probability,[0],[0]
"Although the approximation guarantee cannot hold with high probability, we now show that in expectation stochastic greedy algorithms achieves the approximation guarantee of non-stochastic greedy when maximizing a monotone submodular functions under an intersection of P matroids.",4.2. The guarantee holds in expectation,[0],[0]
Theorem 6.,4.2. The guarantee holds in expectation,[0],[0]
"Let F denote the intersection of P ≥ 1 matroids on the ground setN , and f : 2N → R be a monotone submodular function.",4.2. The guarantee holds in expectation,[0],[0]
"The stochastic greedy algorithm returns a solution S ∈ F s.t.:
E[f(S)]",4.2. The guarantee holds in expectation,[0],[0]
"≥ µ (P + 1) OPT
.
",4.2. The guarantee holds in expectation,[0],[0]
An equivalent algorithm.,4.2. The guarantee holds in expectation,[0],[0]
"To simplify the analysis, it will be useful to consider the equivalent algorithm, which at every iteration when the existing solution is S, discards all elements x for which S ∪ x /∈",4.2. The guarantee holds in expectation,[0],[0]
F .,4.2. The guarantee holds in expectation,[0],[0]
"The following claim due to Nemhauser et al. is later employed in our analysis: Claim 7 (Prop. 2.2 in (Nemhauser et al., 1978)).",4.2. The guarantee holds in expectation,[0],[0]
If for ∀t ∈,4.2. The guarantee holds in expectation,[0],[0]
"[k] ∑t−1 i=0 σi ≤ t and pi−1 ≥ pi, with σi, pi ≥ 0",4.2. The guarantee holds in expectation,[0],[0]
"then:
k−1∑ i=0 piσi ≤ k−1∑ i=0 pi.
",4.2. The guarantee holds in expectation,[0],[0]
"Algorithm 2 STOCHASTIC-MATROID-GREEDY 1: S ← ∅, X ← N 2:",4.2. The guarantee holds in expectation,[0],[0]
while X 6= S do 3: X ← X \ {x : S ∪ {x} /∈ F} 4: ξ ∼ D. 5: S ← S ∪ arbitrary a s.t. fS(a),4.2. The guarantee holds in expectation,[0],[0]
"≥ ξmaxx∈X fS(x) 6: end while
Proof of Lemma 6.",4.2. The guarantee holds in expectation,[0],[0]
Consider the value obtained by the following procedure.,4.2. The guarantee holds in expectation,[0],[0]
"An adversary chooses some maximal independent set a1, . . .",4.2. The guarantee holds in expectation,[0],[0]
ak.,4.2. The guarantee holds in expectation,[0],[0]
"Let Si = {a1, a2, . . .",4.2. The guarantee holds in expectation,[0],[0]
", ai} with S0 = ∅, and for every i ∈",4.2. The guarantee holds in expectation,[0],[0]
"[k] let a?i be the element that maximizes the marginal contribution given Si, where the maximization is over elements a such that Si ∪ {a} is independent in all P matroids.",4.2. The guarantee holds in expectation,[0],[0]
"That is a?i is defined as:
max Si∪{a}∈F fSi(a)
",4.2. The guarantee holds in expectation,[0],[0]
"The value of the procedure is then:
k−1∑ i=0 fSi(a ?",4.2. The guarantee holds in expectation,[0],[0]
"i )
",4.2. The guarantee holds in expectation,[0],[0]
"We will bound the value obtained by the procedure against that of the optimal solution, and then argue that the value obtained by the stochastic greedy is equivalent.
",4.2. The guarantee holds in expectation,[0],[0]
Let O denote the optimal solution.,4.2. The guarantee holds in expectation,[0],[0]
"We have that:
f(O) ≤ f(O ∪ Sk) ≤ f(Sk) + ∑
x∈O\Sk
fSk(x) (4)
For a set S and a matroid Mp in the family F , we define rp(S), called the rank of S in Mp to be the cardinality of the largest subset of S which is independent in Mp, and define spp(S), called the span of S in Mp by:
spp(S) = {a ∈ N : rp(S ∪ a) = rp(S)}
If S is independent in Mp, we have that rp(spp(S))",4.2. The guarantee holds in expectation,[0],[0]
= rp(S) = |S|.,4.2. The guarantee holds in expectation,[0],[0]
"In particular, we have that rp(spp(Si))",4.2. The guarantee holds in expectation,[0],[0]
= i for every Si.,4.2. The guarantee holds in expectation,[0],[0]
"Now in each 1 ≤ p ≤ P , since O is an independent set in Mp we have:
rp(spp(Si) ∩ (O))",4.2. The guarantee holds in expectation,[0],[0]
"= |spp(Si) ∩ (O)|
which implies that |spp(Si) ∩ (O)| ≤ i.
Define Ui = ∪Pp=1spp(Si), to be the set of elements which are not part of the maximization in step i+ 1 of the procedure, and hence cannot give value at that stage.",4.2. The guarantee holds in expectation,[0],[0]
We have: |Ui∩O| = |(∪Pp=1spp(Si))∩O| ≤ P∑ p=1,4.2. The guarantee holds in expectation,[0],[0]
"|spp(Si)∩O| ≤ iP
Let Vi = (Ui \ Ui−1) ∩ O be the elements of O which are not part of the maximization in step i, but were part of the maximization in step i− 1.",4.2. The guarantee holds in expectation,[0],[0]
"If x ∈ Vi then it must be that:
fSk(x) ≤ fSi(x) ≤ fSi(a?i )
since x was not chosen in step i.",4.2. The guarantee holds in expectation,[0],[0]
"Hence, we can upper bound:
∑ x∈O\Sk fSk(x) ≤ k∑ i=1",4.2. The guarantee holds in expectation,[0],[0]
∑ x∈Vi fSi(a ?,4.2. The guarantee holds in expectation,[0],[0]
"i )
",4.2. The guarantee holds in expectation,[0],[0]
"=
k∑ i=1",4.2. The guarantee holds in expectation,[0],[0]
|Vi|fSi(a?),4.2. The guarantee holds in expectation,[0],[0]
≤ P k∑ i=1,4.2. The guarantee holds in expectation,[0],[0]
"fSi(a ?)
",4.2. The guarantee holds in expectation,[0],[0]
"where the last inequality uses ∑i t=1 |Vt| = |Ui ∩ O| ≤ Pi and the arithmetic claim proven in Claim 7 due to (Nemhauser et al., 1978).",4.2. The guarantee holds in expectation,[0],[0]
"Together with (4), we get:
f(O) ≤",4.2. The guarantee holds in expectation,[0],[0]
(P + 1) k∑ i=1,4.2. The guarantee holds in expectation,[0],[0]
fSi(a ?,4.2. The guarantee holds in expectation,[0],[0]
"i )
",4.2. The guarantee holds in expectation,[0],[0]
"Finally, note that STOCHASTIC-MATROID-GREEDY obtains a µ = Eξ∼D[ξ] approximation of the value of the procedure, in expectation.",4.2. The guarantee holds in expectation,[0],[0]
"In each stage, one can add the element chosen by the algorithm to the procedure.",4.2. The guarantee holds in expectation,[0],[0]
"Hence, at each stage STOCHASTIC-MATROID-GREEDY and the procedure have the same set of elements available, and the same a?i which maximizes the marginal contribution.",4.2. The guarantee holds in expectation,[0],[0]
In this section we consider variants of stochastic local search algorithms.,5. Inapproximability of Local Search,[0],[0]
"We show that unlike the greedy algorithm, stochastic local search algorithms can end up with arbitrarily bad approximation guarantees.
",5. Inapproximability of Local Search,[0],[0]
Local search for submodular maximization.,5. Inapproximability of Local Search,[0],[0]
"For N = {a1, . . .",5. Inapproximability of Local Search,[0],[0]
", an}, given a set of elements T ⊆ N we will use T−i to denote the set without element ai, i.e. T−i = T \ {ai}.",5. Inapproximability of Local Search,[0],[0]
A solution S is a local maximum if no single element ai in S can be exchanged for another element aj not in S whose marginal contribution to S−i is greater.,5. Inapproximability of Local Search,[0],[0]
"That is, S is a local maximum if for every ai ∈ S",5. Inapproximability of Local Search,[0],[0]
"we have that:
fS−i(ai) ≥ max x/∈S fS−i(x).
",5. Inapproximability of Local Search,[0],[0]
"It is not hard to show that for any monotone submodular function, if S is a local maximum it is a 1/2 approximation to the optimal solution.",5. Inapproximability of Local Search,[0],[0]
"A local search algorithm begins with an arbitrarily set of size k, and at every stage exchanges one of its elements with the element whose marginal contribution is maximal to the set, until it reaches a local maximum.",5. Inapproximability of Local Search,[0],[0]
"To guarantee that local
search algorithms converge in polynomial time, the convention is to seek approximate local maxima.",5. Inapproximability of Local Search,[0],[0]
A solution S is an α-approximate local maximum if no element ai in S can be exchanged for another element aj not in S whose marginal contribution to S−i is greater by a factor of α.,5. Inapproximability of Local Search,[0],[0]
"It is easy to show that an α-approximate local maximum is a (1 + 1/α)−1 approximation (Filmus & Ward, 2012).
",5. Inapproximability of Local Search,[0],[0]
Stochastic local search.,5. Inapproximability of Local Search,[0],[0]
A natural question is whether local search enjoys the same robustness guarantees as the greedy algorithm.,5. Inapproximability of Local Search,[0],[0]
We say that a solution S is a stochastic local maximum up to approximation µ if no single element in S can be exchanged for another element not in S whose expected marginal contribution is greater by a factor µ.,5. Inapproximability of Local Search,[0],[0]
"That is, S is a stochastic local maximum with mean µ if for every ai ∈ S",5. Inapproximability of Local Search,[0],[0]
"we have that:
E[fS−i(ai)] ≥ µ ·max x/∈S fS−i(x)
",5. Inapproximability of Local Search,[0],[0]
If we have uncertaintiy modeled by a distribution D ⊆,5. Inapproximability of Local Search,[0],[0]
"[0, 1], a solution is a stochastic local maximum w.r.t D if for every element ai in S we draw ξi ∼ D s.t.
fS−i(ai) ≥ ξi ·max b/∈S fS−i(b)
",5. Inapproximability of Local Search,[0],[0]
"A stochastic local search algorithm will therefore begin from an arbitrary solution S of size k, and at every iteration swap an element from the solution with an element outside the solution if S is not a stochastic local maximum w.r.t.",5. Inapproximability of Local Search,[0],[0]
"D. More specifically, the stochastic local search algorithm selects an element ai from S and replaces it with another element aj whose expected marginal contribution to S−i is at least fS−i(ai)/ξi, and repeats this process until no such elements are found.",5. Inapproximability of Local Search,[0],[0]
"This is a similar abstraction of stochastic greedy algorithms, applicable in settings when one cannot evaluate the optimal marginal contribution exactly, but approximately well in expectation.
",5. Inapproximability of Local Search,[0],[0]
Consistent and inconsistent stochasticity.,5. Inapproximability of Local Search,[0],[0]
"We consider two approaches to model the way in which the random variables ξi are assigned to an element ai in the solution:
1.",5. Inapproximability of Local Search,[0],[0]
"Consistent: For each element ai ∈ N , ξi is a random variable drawn independently from D ⊆",5. Inapproximability of Local Search,[0],[0]
"[0, 1], and fixed for the entire run of the algorithm;
2.",5. Inapproximability of Local Search,[0],[0]
Inconsistent:,5. Inapproximability of Local Search,[0],[0]
"At each step of the algorithm, for every element ai ∈ S, ξi is a random variable drawn independently from D.
Note that the solution converges, as the distribution D makes the algorithm more conservative.
",5. Inapproximability of Local Search,[0],[0]
Inapproximability of stochastic local search.,5. Inapproximability of Local Search,[0],[0]
"We show that in both consistent and inconsistent models, stochastic local search performs poorly, even for modular functions.",5. Inapproximability of Local Search,[0],[0]
"Consider a setting where there are n elements, and a modular function.",5. Inapproximability of Local Search,[0],[0]
"For every i > 1, we have f(ai) = ε/i for some negligible ε > 0",5. Inapproximability of Local Search,[0],[0]
"(e.g. ε = 2−n), but f(a1)",5. Inapproximability of Local Search,[0],[0]
= 1.,5. Inapproximability of Local Search,[0],[0]
"As for D, w.p. 0.99 it returns 1, and 0 o.w.",5. Inapproximability of Local Search,[0],[0]
Assume k = 1.,5. Inapproximability of Local Search,[0],[0]
Lemma 8.,5. Inapproximability of Local Search,[0],[0]
"The expected approximation guarantee of stochastic local search is at most 2−O(n) + ε.
",5. Inapproximability of Local Search,[0],[0]
Proof.,5. Inapproximability of Local Search,[0],[0]
"At the first iteration, local search chooses an.",5. Inapproximability of Local Search,[0],[0]
"If ξ = 0, we are done, and this is a local maxima.",5. Inapproximability of Local Search,[0],[0]
"Otherwise, local search chooses an−1.",5. Inapproximability of Local Search,[0],[0]
"At iteration i local search starts with ai, halts w.p. 0.01 (the probability that D outputs 0), and otherwise continues.",5. Inapproximability of Local Search,[0],[0]
"The probability that it will not halt for n steps and reach ai is 0.99n = 2−O(n).
",5. Inapproximability of Local Search,[0],[0]
We note that in the above proof we assumed that the local search algorithm chooses an arbitrary element at every iteration.,5. Inapproximability of Local Search,[0],[0]
If one allows the stochastic local search to randomly choose an element in every iteration a similar construction shows an inapproximability of O( lognn ) + ε.,5. Inapproximability of Local Search,[0],[0]
"We applied the algorithms to an ego-network from (Leskovec & Krevl, 2014).",6. Experiments,[0],[0]
This network has 333 nodes and 5038 edges.,6. Experiments,[0],[0]
"The submodular function we used is coverage, which models influence in social networks.",6. Experiments,[0],[0]
"In order to emphasize the implications of having results w.h.p, the graphs do not depict the average of many runs, but instead each graph is a single run of the algorithm.",6. Experiments,[0],[0]
"In greedy, we present the value of the solution at each iteration k.",6. Experiments,[0],[0]
"In local search and in random we sort elements of the solution according to marginal contributions.
",6. Experiments,[0],[0]
We start with greedy and describe the different distributions we used to model uncertainty.,6. Experiments,[0],[0]
The same distributions were used for local search.,6. Experiments,[0],[0]
"Both left panes include the greedy algorithm without uncertainty (greedy, blue line), and choosing a random set (random, black line).",6. Experiments,[0],[0]
"When running stochastic greedy, we first sample a value ξ ∈ D,
and then pick a random element out of the elements that have marginal contribution at least ξmaxa fS(a).",6. Experiments,[0],[0]
The distribution D varies between the different lines.,6. Experiments,[0],[0]
"In the leftmost pane, APX (red line) depicts a D which is the constant distribution 0.5.",6. Experiments,[0],[0]
"In Stochastic greedy with mean 0.75, D is the uniform distribution on [0.5, 1] (purple line), and in Stochastic greedy with mean 0.5, D is the uniform distribution on [0, 1].",6. Experiments,[0],[0]
"It is expected that APX will behave smoothly, as D is a degenerate distribution in this case (note that there is still randomization in which element to choose at every stage out of the eligible elements).",6. Experiments,[0],[0]
"However, we see that the h.p. result kicks in, and the APX line is similar (across many values of k) to stochastic greedy with mean 0.5.",6. Experiments,[0],[0]
"Raising the mean to 0.75 makes stochastic greedy behave almost like greedy when k gets large, so in some cases stochastic greedy makes the same choice greedy would make.
",6. Experiments,[0],[0]
"In the second pane, The purple line (exponential) depicts D as an exponential distribution with λ = 4, which gives a mean of 0.25.",6. Experiments,[0],[0]
"The red line is uniform in [0, 5], and the yellow is a Gaussian with µ = 0.25 and σ = 0.1.",6. Experiments,[0],[0]
"We see that all graphs are further away from Greedy compared to the leftmost pane, and that higher variance is generally not a good thing, although the differences are small.
",6. Experiments,[0],[0]
"The two right panes depict the same noise distributions as the two left panes, but this time we use local search (or stochastic local search) instead of greedy.",6. Experiments,[0],[0]
It is easy to see that D affects local search more than it affects greedy.,6. Experiments,[0],[0]
"The plateau is caused since we sort the final solution and then plot the elements, and since if some elements have a low value of ξi they are likely to stay in the solution even if they contribute very little, as in Lemma 8.",6. Experiments,[0],[0]
"A.H. was supported by ISF 1394/16; Y.S. was supported by NSF grant CCF-1301976, CAREER CCF-1452961, a Google Faculty Research Award, and a Facebook Faculty Gift.",7. Acknowledgements,[0],[0]
"We thank Andreas Krause for pointing the connection between our result and (Mirzasoleiman et al., 2015).",7. Acknowledgements,[0],[0]
In this paper we analyze the robustness of stochastic variants of the greedy algorithm for submodular maximization.,abstractText,[0],[0]
"Our main result shows that for maximizing a monotone submodular function under a cardinality constraint, iteratively selecting an element whose marginal contribution is approximately maximal in expectation is a sufficient condition to obtain the optimal approximation guarantee with exponentially high probability, assuming the cardinality is sufficiently large.",abstractText,[0],[0]
"One consequence of our result is that the linear-time STOCHASTIC-GREEDY algorithm recently proposed in (Mirzasoleiman et al., 2015) achieves the optimal running time while maintaining an optimal approximation guarantee.",abstractText,[0],[0]
"We also show that high probability guarantees cannot be obtained for stochastic greedy algorithms under matroid constraints, and prove an approximation guarantee which holds in expectation.",abstractText,[0],[0]
"In contrast to the guarantees of the greedy algorithm, we show that the approximation ratio of stochastic local search is arbitrarily bad, with high probability, as well as in expectation.",abstractText,[0],[0]
Robust Guarantees of Stochastic Greedy Algorithms,title,[0],[0]
Probabilistic modeling is a powerful approach to discovering hidden patterns in data.,1. Introduction,[0],[0]
We begin by expressing assumptions about the class of patterns we expect to discover; this is how we design a probability model.,1. Introduction,[0],[0]
We follow by inferring the posterior of the model; this is how we discover the specific patterns manifest in an observed data set.,1. Introduction,[0],[0]
"Advances in automated inference (Hoffman & Gelman, 2014; Mansinghka et al., 2014; Kucukelbir et al., 2017) enable easy development of new models for machine learning and artificial intelligence (Ghahramani, 2015).
",1. Introduction,[0],[0]
"In this paper, we present a recipe to robustify probabilistic models.",1. Introduction,[0],[0]
What do we mean by “robustify”?,1. Introduction,[0],[0]
Departure from a model’s assumptions can undermine its inference and prediction performance.,1. Introduction,[0],[0]
"This can arise due to corrupted
1Columbia University, New York City, USA.",1. Introduction,[0],[0]
"Correspondence to: Yixin Wang <yixin.wang@columbia.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"observations, or in general, measurements that do not belong to the process we are modeling.",1. Introduction,[0],[0]
"Robust models should perform well in spite of such mismatch with reality.
",1. Introduction,[0],[0]
Consider a movie recommendation system.,1. Introduction,[0],[0]
We gather data of people watching movies via the account they use to log in.,1. Introduction,[0],[0]
"Imagine a situation where a few observations are corrupted For example, a child logs in to her account and regularly watches popular animated films.",1. Introduction,[0],[0]
"One day, her parents use the same account to watch a horror movie.",1. Introduction,[0],[0]
"Recommendation models, like Poisson factorization (PF), struggle with this kind of corrupted data (see Section 4): it begins to recommend horror movies.
",1. Introduction,[0],[0]
What can be done to detect and mitigate this effect?,1. Introduction,[0],[0]
"One strategy is to design new models that are less sensitive to corrupted data, such as by replacing a Gaussian likelihood with a heavier-tailed t distribution (Huber, 2011; Insua & Ruggeri, 2012).",1. Introduction,[0],[0]
Most probabilistic models we use have more sophisticated structures; these template solutions for specific distributions are not readily applicable.,1. Introduction,[0],[0]
"Other classical robust techniques act mostly on distances between observations (Huber, 1973); these approaches struggle with high-dimensional data.",1. Introduction,[0],[0]
"How can we still make use of our favorite probabilistic models while making them less sensitive to the messy nature of reality?
",1. Introduction,[0],[0]
Main idea.,1. Introduction,[0],[0]
We propose reweighted probabilistic models (RPM).,1. Introduction,[0],[0]
The idea is simple.,1. Introduction,[0],[0]
"First, posit a probabilistic model.",1. Introduction,[0],[0]
Then adjust the contribution of each observation by raising each likelihood term to its own (latent) weight.,1. Introduction,[0],[0]
"Finally, infer these weights along with the latent variables of the original probability model.",1. Introduction,[0],[0]
"The posterior of this adjusted model identifies observations that match its assumptions; it downweights observations that disagree with its assumptions.
",1. Introduction,[0],[0]
"0 1 2
Figure 1 depicts this tradeoff.",1. Introduction,[0],[0]
"The dataset includes cor-
rupted measurements that undermine the original model; Bayesian data reweighting automatically trades off the low likelihood of the corrupted data near 1.5 to focus on the uncorrupted data near zero.",1. Introduction,[0],[0]
"The RPM (green curve) detects this mismatch and mitigates its effect compared to the poor fit of the original model (red curve).
",1. Introduction,[0],[0]
"Formally, consider a dataset of N independent observations y D .y1; : : : ; yN /.",1. Introduction,[0],[0]
"The likelihood factorizes as a productQN
nD1 `.yn",1. Introduction,[0],[0]
"j ˇ/, where ˇ is a set of latent variables.",1. Introduction,[0],[0]
"Posit a prior distribution pˇ .ˇ/.
Bayesian data reweighting follows three steps:
1.",1. Introduction,[0],[0]
"Define a probabilistic model pˇ .ˇ/ QN
nD1 `.yn",1. Introduction,[0],[0]
j ˇ/. 2.,1. Introduction,[0],[0]
"Raise each likelihood to a positive latent weight wn.
",1. Introduction,[0],[0]
"Then choose a prior on the weights pw.w/, where w D .w1; : : : ; wN /.",1. Introduction,[0],[0]
"This gives a reweighted probabilistic model (RPM)
p.y; ˇ; w/ D 1 Z pˇ .ˇ/pw.w/ NY nD1 `.yn j ˇ/wn ;
where Z is the normalizing factor.
3.",1. Introduction,[0],[0]
Infer the posterior of both the latent variables ˇ,1. Introduction,[0],[0]
"and the weights w, p.ˇ; w j y/.
",1. Introduction,[0],[0]
The latent weights w allow an RPM to automatically explore which observations match its assumptions and which do not.,1. Introduction,[0],[0]
"Writing out the logarithm of the RPM gives some intuition; it is equal (up to an additive constant) to
log pˇ .ˇ/",1. Introduction,[0],[0]
"C log pw.w/ C X
n
wn log `.yn",1. Introduction,[0],[0]
"j ˇ/: (1)
Posterior inference, loosely speaking, seeks to maximize the above with respect to ˇ and",1. Introduction,[0],[0]
"w. The prior on the weights pw.w/ plays a critical role: it trades off extremely low likelihood terms, caused by corrupted measurements, while encouraging the weights to be close to one.",1. Introduction,[0],[0]
"We study three options for this prior in Section 2.
",1. Introduction,[0],[0]
How does Bayesian data reweighting induce robustness?,1. Introduction,[0],[0]
"First, consider how the weights w affect Equation (1).",1. Introduction,[0],[0]
The logarithm of our priors are dominated by the log wn term: this is the price of moving wn from one towards zero.,1. Introduction,[0],[0]
"By shrinking wn, we gain an increase in wn log `.yn",1. Introduction,[0],[0]
j ˇ/ while paying a price in a log wn.,1. Introduction,[0],[0]
The gain outweighs the price we pay if log `.yn,1. Introduction,[0],[0]
j ˇ/ is very negative.,1. Introduction,[0],[0]
"Our priors are set to prefer wn to stay close to one; an RPM only shrinks wn for very unlikely (e.g., corrupted) measurements.
",1. Introduction,[0],[0]
Now consider how the latent variables ˇ,1. Introduction,[0],[0]
affect Equation (1).,1. Introduction,[0],[0]
"As the weights of unlikely measurements shrink, the likelihood term can afford to assign low mass to those corrupted measurements and focus on the rest of the dataset.
",1. Introduction,[0],[0]
"Jointly, the weights and latent variables work together to automatically identify unlikely measurements and focus on observations that match the original model’s assumptions.
",1. Introduction,[0],[0]
"Section 2 presents these intuitions in full detail, along with theoretical corroboration.",1. Introduction,[0],[0]
"In Section 3, we study four models under various forms of mismatch with reality, including missing modeling assumptions, misspecified nonlinearities, and skewed data.",1. Introduction,[0],[0]
RPMs provide better parameter inference and improved predictive accuracy across these models.,1. Introduction,[0],[0]
"Section 4 presents a recommendation system example, where we improve on predictive performance and identify atypical film enthusiasts in the Movielens 1M dataset.
",1. Introduction,[0],[0]
Related work.,1. Introduction,[0],[0]
"Jerzy Neyman elegantly motivates the main idea behind robust probabilistic modeling, a field that has attracted much research attention in the past century.
",1. Introduction,[0],[0]
Every attempt to use mathematics to study some real phenomena must begin with building a mathematical model of these phenomena.,1. Introduction,[0],[0]
"Of necessity, the model simplifies matters to a greater or lesser extent and a number of details are ignored.",1. Introduction,[0],[0]
[...],1. Introduction,[0],[0]
The solution of the mathematical problem may be correct and yet it may be in violent conflict with realities simply because the original assumptions of the mathematical model diverge essentially from the conditions of the practical problem considered.,1. Introduction,[0],[0]
"(Neyman, 1949, p.22).
",1. Introduction,[0],[0]
"Our work draws on three themes around robust modeling.
",1. Introduction,[0],[0]
"The first is a body of work on robust statistics and machine learning (Provost & Fawcett, 2001; Song et al., 2002; Yu et al., 2012; McWilliams et al., 2014; Feng et al., 2014; Shafieezadeh-Abadeh et al., 2015).",1. Introduction,[0],[0]
"These developments focus on making specific models more robust to imprecise measurements.
",1. Introduction,[0],[0]
One strategy is popular: localization.,1. Introduction,[0],[0]
"To localize a probabilistic model, allow each likelihood to depend on its own “copy” of the latent variable ˇn.",1. Introduction,[0],[0]
"This transforms the model into
p.y; ˇ; ˛/ D p˛.˛/ NY
nD1 `.yn",1. Introduction,[0],[0]
j ˇn/pˇ .ˇn,1. Introduction,[0],[0]
"j ˛/; (2)
where a top-level latent variable ˛ ties together all the ˇn variables (de Finetti, 1961; Wang & Blei, 2015).1 Localization decreases the effect of imprecise measurements.",1. Introduction,[0],[0]
"RPMs present a broader approach to mitigating mismatch, with improved performance over localization (Sections 3 and 4).
",1. Introduction,[0],[0]
"The second theme is robust Bayesian analysis, which studies sensitivity with respect to the prior (Berger et al., 1994).
",1. Introduction,[0],[0]
"1 Localization also relates to James-Stein shrinkage; Efron (2010) connects these dots.
",1. Introduction,[0],[0]
"Recent advances directly focus on sensitivity of the posterior (Minsker et al., 2014; Miller & Dunson, 2015) or the posterior predictive distribution (Kucukelbir & Blei, 2015).",1. Introduction,[0],[0]
"We draw connections to these ideas throughout this paper.
",1. Introduction,[0],[0]
The third theme is data reweighting.,1. Introduction,[0],[0]
This involves designing individual reweighting schemes for specific tasks and models.,1. Introduction,[0],[0]
Consider robust methods that toss away “outliers.”,1. Introduction,[0],[0]
"This strategy involves manually assigning binary weights to datapoints (Huber, 2011).",1. Introduction,[0],[0]
"Another example is covariate shift adaptation/importance sampling where reweighting transforms data to match another target distribution (Veach & Guibas, 1995; Sugiyama et al., 2007; Shimodaira, 2000; Wen et al., 2014).",1. Introduction,[0],[0]
"In contrast, RPMs treat weights as latent variables.",1. Introduction,[0],[0]
The weights are automatically inferred; no custom design is required.,1. Introduction,[0],[0]
"RPMs also connect to ideas around ensemble learning and boosting (Schapire & Freund, 2012).",1. Introduction,[0],[0]
"Boosting procedures reweight datapoints to build an ensemble of predictors for supervised learning, whereas RPMs apply to Bayesian models in general.",1. Introduction,[0],[0]
Reweighted probabilistic models (RPM) offer a new approach to robust modeling.,2. Reweighted Probabilistic Models,[0],[0]
The idea is to automatically identify observations that match the assumptions of the model and to base posterior inference on these observations.,2. Reweighted Probabilistic Models,[0],[0]
"An RPM scaffolds over a probabilistic model, pˇ .ˇ/ QN nD1 `.yn",2.1. Definitions,[0],[0]
j ˇ/. Raise each likelihood to a latent weight and posit a prior on the weights.,2.1. Definitions,[0],[0]
"This gives the reweighted joint density
p.y; ˇ; w/ D 1 Z pˇ .ˇ/pw.w/ NY nD1",2.1. Definitions,[0],[0]
`.yn j ˇ/wn ; (3) where Z D R pˇ .ˇ/pw.w/QNnD1 `.yn,2.1. Definitions,[0],[0]
"j ˇ/wn dy dˇ dw is the normalizing factor.
",2.1. Definitions,[0],[0]
The reweighted density integrates to one when the normalizing factor Z is finite.,2.1. Definitions,[0],[0]
This is always true when the likelihood `.,2.1. Definitions,[0],[0]
"j ˇ/ is an exponential family distribution with Lesbegue base measure (Bernardo & Smith, 2009); this is the class of models we study in this paper.2
RPMs apply to likelihoods that factorize over the observations.",2.1. Definitions,[0],[0]
(We discuss non-exchangeable models in Section 5.),2.1. Definitions,[0],[0]
Figure 2 depicts an RPM as a graphical model.,2.1. Definitions,[0],[0]
"Specific models may have additional structure, such as a separation of local and global latent variables (Hoffman et al., 2013), or fixed parameters; we omit these in this figure.
2Heavy-tailed likelihoods and Bayesian nonparametric priors may violate this condition; we leave these for future analysis.
ˇ ynpˇ
N
(a) Original probabilistic model
The reweighted model introduces a set of weights; these are latent variables, each with support wn 2 R>0.",2.1. Definitions,[0],[0]
"To gain intuition, consider how these weights affect the posterior, which is proportional to the product of the likelihood of every measurement.",2.1. Definitions,[0],[0]
A weight wn that is close to zero flattens out its corresponding likelihood `.yn,2.1. Definitions,[0],[0]
j ˇ/wn ; a weight that is larger than one makes its likelihood more peaked.,2.1. Definitions,[0],[0]
"This, in turn, enables the posterior to focus on some measurements more than others.",2.1. Definitions,[0],[0]
"The prior pw.w/ ensures that not too many likelihood terms get flattened; in this sense, it plays an important regularization role.
",2.1. Definitions,[0],[0]
"We study three options for this prior on weights: a bank of Beta distributions, a scaled Dirichlet distribution, and a bank of Gamma distributions.
",2.1. Definitions,[0],[0]
Bank of Beta priors.,2.1. Definitions,[0],[0]
"This option constrains each weight as wn 2 .0; 1/. We posit an independent prior for each weight
pw.w/ D NY
nD1",2.1. Definitions,[0],[0]
"Beta.wn I a; b/ (4)
and use the same parameters a and b for all weights.",2.1. Definitions,[0],[0]
"This is the most conservative option for the RPM; it ensures that none of the likelihoods ever becomes more peaked than it was in the original model.
",2.1. Definitions,[0],[0]
"The parameters a, b offer an expressive language to describe different attitudes towards the weights.",2.1. Definitions,[0],[0]
"For example, setting both parameters less than one makes the Beta act like a “two spikes and a slab” prior, encouraging weights to be close to zero or one, but not in between.",2.1. Definitions,[0],[0]
"As another example, setting a greater than b encourages weights to lean towards one.
",2.1. Definitions,[0],[0]
Scaled Dirichlet prior.,2.1. Definitions,[0],[0]
This option ensures the sum of the weights equals N .,2.1. Definitions,[0],[0]
"We posit a symmetric Dirichlet prior on all the weights
w D",2.1. Definitions,[0],[0]
"Nv pv.v/ D Dirichlet.a1/ (5)
where a is a scalar parameter and 1 is a .N ⇥",2.1. Definitions,[0],[0]
1/ vector of ones.,2.1. Definitions,[0],[0]
"In the original model, where all the weights are one, then the sum of the weights is N .",2.1. Definitions,[0],[0]
"The Dirichlet option maintains this balance; while certain likelihoods may become more peaked, others will flatten to compensate.
",2.1. Definitions,[0],[0]
The concentration parameter a gives an intuitive way to configure the Dirichlet.,2.1. Definitions,[0],[0]
Small values for a allow the model to easily up- or down-weight many data observations; larger values for a prefer a smoother distribution of weights.,2.1. Definitions,[0],[0]
"The Dirichlet option connects to the bootstrap approaches in Rubin et al. (1981); Kucukelbir & Blei (2015), which also preserves the sum of weights as N .
",2.1. Definitions,[0],[0]
Bank of Gamma priors.,2.1. Definitions,[0],[0]
"Here we posit an independent Gamma prior for each weight
pw.w/ D NY
nD1 Gamma.wn",2.1. Definitions,[0],[0]
"I a; b/ (6)
and use the same parameters a and b for all weights.",2.1. Definitions,[0],[0]
"We do not recommend this option, because observations can be arbitrarily up- or down-weighted.",2.1. Definitions,[0],[0]
"In this paper, we only consider Equation (6) for our theoretical analysis in Section 2.2.
",2.1. Definitions,[0],[0]
The bank of Beta and Dirichlet options perform similarly.,2.1. Definitions,[0],[0]
"We prefer the Beta option as it is more conservative, yet find the Dirichlet to be less sensitive to its parameters.",2.1. Definitions,[0],[0]
We explore these options in the empirical study (Section 3).,2.1. Definitions,[0],[0]
How can theory justify Bayesian data reweighting?,2.2. Theory and intuition,[0],[0]
Here we investigate its robustness properties.,2.2. Theory and intuition,[0],[0]
These analyses intend to confirm our intuition from Section 1.,2.2. Theory and intuition,[0],[0]
"Appendices B and C present proofs in full technical detail.
",2.2. Theory and intuition,[0],[0]
Intuition.,2.2. Theory and intuition,[0],[0]
Recall the logarithm of the RPM joint density from Equation (1).Now compute the maximum-a-posterior (MAP) estimate of the weights w.,2.2. Theory and intuition,[0],[0]
"The partial derivative is
@ log p.y; ˇ; w/ @wn D d log pw.wn/ dwn C log `.yn",2.2. Theory and intuition,[0],[0]
"j ˇ/ (7)
for all n D 1; : : : ; N .",2.2. Theory and intuition,[0],[0]
Plug the Gamma prior from Equation (6) into the partial derivative in Equation (7) and set it equal to zero.,2.2. Theory and intuition,[0],[0]
"This gives the MAP estimate of wn,
bwn D a 1 b log `.yn",2.2. Theory and intuition,[0],[0]
"j ˇ/ : (8)
The MAP estimate bwn is an increasing function of the log likelihood of yn when a > 1.",2.2. Theory and intuition,[0],[0]
"This reveals that bwn shrinks the contribution of observations that are unlikely under the log likelihood; in turn, this encourages the MAP estimate for b̌ to describe the majority of the observations.",2.2. Theory and intuition,[0],[0]
"This is how an RPM makes a probabilistic model more robust.
",2.2. Theory and intuition,[0],[0]
A similar argument holds for other exponential family priors on w with log wn as a sufficient statistic.,2.2. Theory and intuition,[0],[0]
"We formalize this intuition and generalize it in the following theorem, which establishes sufficient conditions where a RPM improves the inference of its latent variables ˇ.
Theorem 1",2.2. Theory and intuition,[0],[0]
Denote the true value of ˇ as ˇ⇤.,2.2. Theory and intuition,[0],[0]
Let the posterior mean of ˇ under the weighted and unweighted model be Ňw and Ňu respectively.,2.2. Theory and intuition,[0],[0]
"Assume mild conditions on pw , ` and the corruption level, and that j`.yn j Ňw/ `.yn",2.2. Theory and intuition,[0],[0]
j ˇ⇤/j <,2.2. Theory and intuition,[0],[0]
✏ holds 8n with high probability.,2.2. Theory and intuition,[0],[0]
"Then, there exists an N ⇤ such that for N > N",2.2. Theory and intuition,[0],[0]
"⇤, we have j Ňu ˇ⇤j ⌫2 j",2.2. Theory and intuition,[0],[0]
"Ňw ˇ⇤j, where ⌫2 denotes second order stochastic dominance.",2.2. Theory and intuition,[0],[0]
"(Details in Appendix B.)
",2.2. Theory and intuition,[0],[0]
The likelihood bounding assumption is common in robust statistics theory; it is satisfied for both likely and unlikely (corrupted) measurements.,2.2. Theory and intuition,[0],[0]
How much of an improvement does it give?,2.2. Theory and intuition,[0],[0]
We can quantify this through the influence function (IF) of Ňw .,2.2. Theory and intuition,[0],[0]
"Consider a distribution G and a statistic T .G/ to be a function of data that comes iid from G. Take a fixed distribution, e.g., the population distribution, F .",2.2. Theory and intuition,[0],[0]
"Then, IF.zI T; F / measures how much an additional observation at z affects the statistic T .F /.",2.2. Theory and intuition,[0],[0]
"Define
IF.zI T; F / D lim t!0C T .tız",2.2. Theory and intuition,[0],[0]
C .1,2.2. Theory and intuition,[0],[0]
"t /F / T .F / t
for z where this limit exists.",2.2. Theory and intuition,[0],[0]
"Roughly, the IF measures the asymptotic bias on T .F / caused by a specific observation z that does not come from F .",2.2. Theory and intuition,[0],[0]
"We consider a statistic T to be robust if its IF is a bounded function of z, i.e., if outliers can only exert a limited influence (Huber, 2011).",2.2. Theory and intuition,[0],[0]
"Here, we study the IF of the posterior mean T D Ňw under the true data generating distribution F D `.",2.2. Theory and intuition,[0],[0]
j ˇ⇤/.,2.2. Theory and intuition,[0],[0]
Say a value z has likelihood `.z,2.2. Theory and intuition,[0],[0]
j ˇ⇤/ that is nearly zero; we think of this z as corrupted.,2.2. Theory and intuition,[0],[0]
"Now consider the weight function induced by the prior pw.w/. Rewrite it as a function of the log likelihood, like w.log `.",2.2. Theory and intuition,[0],[0]
j ˇ⇤// as in Equation (8).,2.2. Theory and intuition,[0],[0]
Theorem 2,2.2. Theory and intuition,[0],[0]
If lima! 1 w.a/ D 0 and lima!,2.2. Theory and intuition,[0],[0]
"1 a w.a/ < 1, then IF.zI Ňw ; `.",2.2. Theory and intuition,[0],[0]
j ˇ⇤// ! 0,2.2. Theory and intuition,[0],[0]
as `.z,2.2. Theory and intuition,[0],[0]
j ˇ⇤/ ! 0,2.2. Theory and intuition,[0],[0]
":
This result shows that an RPM is robust in that its IF goes to zero for unlikely measurements.",2.2. Theory and intuition,[0],[0]
This is true for all three priors.,2.2. Theory and intuition,[0],[0]
(Details in Appendix C.),2.2. Theory and intuition,[0],[0]
"We now turn to inferring the posterior of an RPM, p.ˇ; w j y/.",2.3. Inference and computation,[0],[0]
"The posterior lacks an analytic closed-form expression for all but the simplest of models; even if the original model admits such a posterior for ˇ, the reweighted posterior may take a different form.
",2.3. Inference and computation,[0],[0]
"To approximate the posterior, we appeal to probabilistic programming.",2.3. Inference and computation,[0],[0]
A probabilistic programming system enables a user to write a probability model as a computer program and then compile that program into an inference executable.,2.3. Inference and computation,[0],[0]
"Automated inference is the backbone of such systems: it takes in a probability model, expressed as a program, and outputs an efficient algorithm for inference.",2.3. Inference and computation,[0],[0]
"We use automated inference in Stan, a probabilistic programming system (Carpenter et al., 2015).
",2.3. Inference and computation,[0],[0]
"In the empirical study that follows, we highlight how RPMs detect and mitigate various forms of model mismatch.",2.3. Inference and computation,[0],[0]
"As a common metric, we compare the predictive accuracy on held out data for the original, localized, and reweighted model.
",2.3. Inference and computation,[0],[0]
The posterior predictive likelihood of a new datapoint yé is poriginal.yé j y/,2.3. Inference and computation,[0],[0]
D R `.yé j ˇ/p.ˇ j y/,2.3. Inference and computation,[0],[0]
dˇ:,2.3. Inference and computation,[0],[0]
"Localization couples each observation with its own copy of the latent variable; this gives plocalized.yé j y/ D’
`.yé j ˇé/p.ˇé j",2.3. Inference and computation,[0],[0]
˛/p.˛ j y/ d˛ dˇé where ˇé is the localized latent variable for the new datapoint.,2.3. Inference and computation,[0],[0]
The prior p.ˇé j ˛/ has the same form as pˇ in Equation (2).,2.3. Inference and computation,[0],[0]
Bayesian data reweighting gives the following posterior predictive likelihood pRPM.yé j y/ D “ p.yé j ˇ; wé/pRPM.ˇ j y/p.wé/,2.3. Inference and computation,[0],[0]
"dwé dˇ;
where pRPM.ˇ j y/ is the marginal posterior, integrating out the inferred weights of the training dataset, and the prior p.wé/ has the same form as pw in Equation (3).",2.3. Inference and computation,[0],[0]
We study RPMs under four types of mismatch with reality.,3. Empirical Study,[0],[0]
This section involves simulations of realistic scenarios; the next section presents a recommendation system example using real data.,3. Empirical Study,[0],[0]
"We default to No-U-Turn sampler (NUTS) (Hoffman & Gelman, 2014) for inference in all experiments, except for Sections 3.5 and 4 where we leverage variational inference (Kucukelbir et al., 2017).",3. Empirical Study,[0],[0]
The additional computational cost of inferring the weights is unnoticeable relative to inference in the original model.,3. Empirical Study,[0],[0]
A router receives packets over a network and measures the time it waits for each packet.,3.1. Outliers: a network wait-time example,[0],[0]
Suppose we typically observe wait-times that follow a Poisson distribution with rate ˇ D 5.,3.1. Outliers: a network wait-time example,[0],[0]
We model each measurement using a Poisson likelihood `.yn,3.1. Outliers: a network wait-time example,[0],[0]
j ˇ/ D Poisson.ˇ/ and posit a Gamma prior on the rate pˇ .ˇ/,3.1. Outliers: a network wait-time example,[0],[0]
D,3.1. Outliers: a network wait-time example,[0],[0]
Gam.a D 2; b D 0:5/.,3.1. Outliers: a network wait-time example,[0],[0]
"Imagine that F % percent of the time, the network fails.",3.1. Outliers: a network wait-time example,[0],[0]
"During these failures, the wait-times come from a Poisson with much higher rate ˇ D 50.",3.1. Outliers: a network wait-time example,[0],[0]
"Thus, the data actually contains a mixture of two Poisson distributions; yet, our model only assumes one.",3.1. Outliers: a network wait-time example,[0],[0]
"(Details in Appendix D.1.)
",3.1. Outliers: a network wait-time example,[0],[0]
How do we expect an RPM to behave in this situation?,3.1. Outliers: a network wait-time example,[0],[0]
Suppose the network failed 25% of the time.,3.1. Outliers: a network wait-time example,[0],[0]
Figure 3a shows the posterior distribution on the rate ˇ.,3.1. Outliers: a network wait-time example,[0],[0]
"The original posterior is centered at 18; this is troubling, not only because the rate is wrong but also because of how confident the posterior fit is.",3.1. Outliers: a network wait-time example,[0],[0]
"Localization introduces greater uncertainty, yet still estimates a rate around 15.",3.1. Outliers: a network wait-time example,[0],[0]
The RPM correctly identifies that the majority of the observations come from ˇ D 5.,3.1. Outliers: a network wait-time example,[0],[0]
Observations from when the network failed are down-weighted.,3.1. Outliers: a network wait-time example,[0],[0]
"It gives a confident posterior centered at five.
",3.1. Outliers: a network wait-time example,[0],[0]
Figure 3b shows posterior 95% credible intervals of ˇ under failure rates up to F D 45%.,3.1. Outliers: a network wait-time example,[0],[0]
"The RPM is robust to corrupted measurements; instead it focuses on data that it can
explain within its assumptions.",3.1. Outliers: a network wait-time example,[0],[0]
"When there is no corruption, the RPM performs just as well as the original model.
",3.1. Outliers: a network wait-time example,[0],[0]
Visualizing the weights elucidates this point.,3.1. Outliers: a network wait-time example,[0],[0]
Figure 4 shows the posterior mean estimates of w for F D 25%.,3.1. Outliers: a network wait-time example,[0],[0]
"The weights are sorted into two groups, for ease of viewing.",3.1. Outliers: a network wait-time example,[0],[0]
"The weights of the corrupted observations are essentially zero; this downweighting is what allows the RPM to shift its posterior on ˇ towards five.
",3.1. Outliers: a network wait-time example,[0],[0]
"Despite this downweighting, the RPM posteriors on ˇ are not overdispersed, as in the localized case.",3.1. Outliers: a network wait-time example,[0],[0]
This is due to the interplay we described in the introduction.,3.1. Outliers: a network wait-time example,[0],[0]
"Downweighting observations should lead to a smaller effective sample size, which would increase posterior uncertainty.",3.1. Outliers: a network wait-time example,[0],[0]
"But the downweighted datapoints are corrupted observations; including them also increases posterior uncertainty.
",3.1. Outliers: a network wait-time example,[0],[0]
The RPM is insensitive to the prior on the weights; both Beta and Dirichlet options perform similarly.,3.1. Outliers: a network wait-time example,[0],[0]
"From here on, we focus on the Beta option.",3.1. Outliers: a network wait-time example,[0],[0]
We let the shape parameter a scale with the data size N such that N=a ⇡ 103; this encodes a mild attitude towards unit weights.,3.1. Outliers: a network wait-time example,[0],[0]
We now move on to other forms of mismatch with reality.,3.1. Outliers: a network wait-time example,[0],[0]
"Color blindness is unevenly hereditary: it is much higher for men than for women (Boron & Boulpaep, 2012).",3.2. Missing latent groups: predicting color blindness,[0],[0]
Suppose we are not aware of this fact.,3.2. Missing latent groups: predicting color blindness,[0],[0]
We have a dataset of both genders with each individual’s color blindness status and his/her relevant family history.,3.2. Missing latent groups: predicting color blindness,[0],[0]
No gender information is available.,3.2. Missing latent groups: predicting color blindness,[0],[0]
Consider analyzing this data using logistic regression.,3.2. Missing latent groups: predicting color blindness,[0],[0]
It can only capture one hereditary group.,3.2. Missing latent groups: predicting color blindness,[0],[0]
"Thus, logistic regression misrepresents both groups, even though men exhibit strong heredity.",3.2. Missing latent groups: predicting color blindness,[0],[0]
"In contrast, an RPM can detect and mitigate the missing group effect by focusing on the dominant hereditary trait.",3.2. Missing latent groups: predicting color blindness,[0],[0]
"Here we consider men as the dominant group.
",3.2. Missing latent groups: predicting color blindness,[0],[0]
We simulate this scenario by drawing binary indicators of color blindness yn ⇠ Bernoulli.1=1 C exp. pn// where the pn’s come from two latent groups: men exhibit a stronger dependency on family history (pn D 0:5xn) than women (pn D 0:01xn).,3.2. Missing latent groups: predicting color blindness,[0],[0]
"We simulate family history as
xn ⇠ Unif. 10; 10/. Consider a Bayesian logistic regression model without intercept.",3.2. Missing latent groups: predicting color blindness,[0],[0]
Posit a prior on the slope as pˇ .ˇ/ D N .0; 10/ and assume a Beta.0:1; 0:01/ prior on the weights.,3.2. Missing latent groups: predicting color blindness,[0],[0]
"(Details in Appendix D.2.)
",3.2. Missing latent groups: predicting color blindness,[0],[0]
Figure 5 shows the posterior 95% credible intervals of ˇ as we vary the percentage of females from F D 0% to 40%.,3.2. Missing latent groups: predicting color blindness,[0],[0]
"A horizontal line indicates the correct slope for the dominant group, ˇmen D 0:5.",3.2. Missing latent groups: predicting color blindness,[0],[0]
"As the size of the missing latent group (women) increases, the original model quickly shifts its credible interval away from 0:5.",3.2. Missing latent groups: predicting color blindness,[0],[0]
"The reweighted and localized posteriors both contain ˇmen D 0:5 for all percentages, but the localized model exhibits much higher variance in its estimates.
",3.2. Missing latent groups: predicting color blindness,[0],[0]
This analysis shows how RPMs can mitigate the effect of missing latent groups.,3.2. Missing latent groups: predicting color blindness,[0],[0]
"While the original logistic regression model would perform equally poorly on both groups, an RPM is able to automatically focus on the dominant group.
",3.2. Missing latent groups: predicting color blindness,[0],[0]
"0 1
Ep.wjy/Œwç
D en
si ty Corrupted (F D 25%)
",3.2. Missing latent groups: predicting color blindness,[0],[0]
"Clean (F D 0%)
Figure 6.",3.2. Missing latent groups: predicting color blindness,[0],[0]
Kernel density estimate of the distribution of weights across all measurements in the missing latent groups study.,3.2. Missing latent groups: predicting color blindness,[0],[0]
The percentage of females is denoted by F .,3.2. Missing latent groups: predicting color blindness,[0],[0]
"A hypothetical clean dataset receives weights that concentrate around one; the actual corrupted dataset exhibits a two-hump distribution of weights.
",3.2. Missing latent groups: predicting color blindness,[0],[0]
An RPM also functions as a diagnostic tool to detect mismatch with reality.,3.2. Missing latent groups: predicting color blindness,[0],[0]
The distribution of the inferred weights indicates the presence of datapoints that defy the assumptions of the original model.,3.2. Missing latent groups: predicting color blindness,[0],[0]
Figure 6 shows a kernel density estimate of the inferred posterior weights.,3.2. Missing latent groups: predicting color blindness,[0],[0]
A hypothetical dataset with no corrupted measurements receives weights close to one.,3.2. Missing latent groups: predicting color blindness,[0],[0]
"In contrast, the actual dataset with measurements from a missing latent group exhibit a bimodal distribution of weights.",3.2. Missing latent groups: predicting color blindness,[0],[0]
Testing for bimodality of the inferred weights is one way in which an RPM can be used to diagnose mismatch with reality.,3.2. Missing latent groups: predicting color blindness,[0],[0]
Consider a study of lung cancer risk.,3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
"While tobacco usage exhibits a clear connection, other factors may also contribute.",3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
"For instance, obesity and tobacco usage appear to interact, with evidence towards a quadratic dependence on obesity (Odegaard et al., 2010).
",3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
Denote tobacco usage as x1 and obesity as x2.,3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
We study three models of lung cancer risk dependency on these covariates.,3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
"We are primarily interested in understanding the effect of tobacco usage; thus we focus on ˇ1, the regression coefficient for tobacco.",3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
"In each model, some form of covariance misspecification discriminates the true structure from the assumed structure.
",3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
"For each model, we simulate a dataset of size N D 100 with random covariates x1 ⇠ N .10; 52/ and x2 ⇠ N .0; 102/ and regression coefficients ˇ0;1;2;3 ⇠ Unif. 10; 10/. Consider a Bayesian linear regression model with prior pˇ .ˇ/",3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
D N .0;,3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
10/. (Details in Appendix D.3.),3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
Table 1 summarizes the misspecification and shows absolute differences on the estimated ˇ1 regression coefficient.,3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
The RPM yields better estimates of ˇ1 in the first two models.,3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
These highlight how the RPM leverages datapoints useful for estimating ˇ1.,3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
The third model is particularly challenging because obesity is ignored in the misspecified model.,3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
"Here, the RPM gives similar results to the original model; this highlights that RPMs can only use available information.",3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
"Since the original model lacks dependence on x2, the RPM cannot compensate for this.",3.3. Covariate dependence misspecification: a lung cancer risk study,[0],[0]
Table 2 shows how RPMs also improve predictive accuracy.,3.4. Predictive likelihood results,[0],[0]
"In all the above examples, we simulate test data with and without their respective types of corruption.",3.4. Predictive likelihood results,[0],[0]
"RPMs improve prediction for both clean and corrupted data, as they focus on data that match the assumptions of the original model.",3.4. Predictive likelihood results,[0],[0]
"Finally, we show how RPMs handle skewed data.",3.5. Skewed data: cluster selection in a mixture model,[0],[0]
"The Dirichlet process mixture model (DPMM) is a versatile model for density estimation and clustering (Bishop, 2006;
Murphy, 2012).",3.5. Skewed data: cluster selection in a mixture model,[0],[0]
"While real data may indeed come from a finite mixture of clusters, there is no reason to assume each cluster is distributed as a Gaussian.",3.5. Skewed data: cluster selection in a mixture model,[0],[0]
"Inspired by the experiments in Miller & Dunson (2015), we show how a reweighted DPMM reliably recovers the correct number of components in a mixture of skewnormals dataset.
",3.5. Skewed data: cluster selection in a mixture model,[0],[0]
"A standard Gaussian mixture model (GMM) with large K and a sparse Dirichlet prior on the mixture proportions is an approximation to a DPMM (Ishwaran & James, 2012).",3.5. Skewed data: cluster selection in a mixture model,[0],[0]
We simulate three clusters from two-dimensional skewnormal distributions and fit a GMM with maximum K D 30.,3.5. Skewed data: cluster selection in a mixture model,[0],[0]
"Here we use automatic differentiation variational inference (ADVI), as NUTS struggles with inference of mixture models (Kucukelbir et al., 2017).",3.5. Skewed data: cluster selection in a mixture model,[0],[0]
"(Details in Appendix D.4.)
",3.5. Skewed data: cluster selection in a mixture model,[0],[0]
Figure 7 shows posterior mean estimates from the original GMM; it incorrectly finds six clusters.,3.5. Skewed data: cluster selection in a mixture model,[0],[0]
"In contrast, the RPM identifies the correct three clusters.",3.5. Skewed data: cluster selection in a mixture model,[0],[0]
Datapoints in the tails of each cluster get down-weighted; these are datapoints that do not match the Gaussianity assumption of the model.,3.5. Skewed data: cluster selection in a mixture model,[0],[0]
We now turn to a study of real data: a recommendation system.,4. Case Study: Poisson factorization for recommendation,[0],[0]
Consider a video streaming service; data comes as a binary matrix of users and the movies they choose to watch.,4. Case Study: Poisson factorization for recommendation,[0],[0]
How can we identify patterns from such data?,4. Case Study: Poisson factorization for recommendation,[0],[0]
"Poisson factorization (PF) offers a flexible solution (Cemgil, 2009; Gopalan et al., 2015).",4. Case Study: Poisson factorization for recommendation,[0],[0]
"The idea is to infer a K-dimensional
latent space of user preferences ✓ and movie attributes ˇ.",4. Case Study: Poisson factorization for recommendation,[0],[0]
The inner product ✓>ˇ determines the rate of a Poisson likelihood for each binary measurement; Gamma priors on ✓ and ˇ promote sparse patterns.,4. Case Study: Poisson factorization for recommendation,[0],[0]
"As a result, PF finds interpretable groupings of movies, often clustered according to popularity or genre.",4. Case Study: Poisson factorization for recommendation,[0],[0]
"(Full model in Appendix E.)
How does classical PF compare to its reweighted counterpart?",4. Case Study: Poisson factorization for recommendation,[0],[0]
"As input, we use the MovieLens 1M dataset, which contains one million movie ratings from 6 000 users on 4 000 movies.",4. Case Study: Poisson factorization for recommendation,[0],[0]
We place iid Gamma.1; 0:001/ priors on the preferences and attributes.,4. Case Study: Poisson factorization for recommendation,[0],[0]
"Here, we have the option of reweighting users or items.",4. Case Study: Poisson factorization for recommendation,[0],[0]
We focus on users and place a Beta.100; 1/,4. Case Study: Poisson factorization for recommendation,[0],[0]
prior on their weights.,4. Case Study: Poisson factorization for recommendation,[0],[0]
"For this model, we use MAP estimation.",4. Case Study: Poisson factorization for recommendation,[0],[0]
"(Localization is computationally challenging for PF; it requires a separate “copy” of ✓ for each movie, along with a separate ˇ for each user.",4. Case Study: Poisson factorization for recommendation,[0],[0]
"This dramatically increases computational cost.)
",4. Case Study: Poisson factorization for recommendation,[0],[0]
We begin by analyzing the original (clean) dataset.,4. Case Study: Poisson factorization for recommendation,[0],[0]
"Reweighting improves the average held-out log likelihood from 1:68 of the original model to 1:53 of the corre-
sponding RPM.",4. Case Study: Poisson factorization for recommendation,[0],[0]
The boxplot in Figure 8a shows the inferred weights.,4. Case Study: Poisson factorization for recommendation,[0],[0]
"The majority of users receive weight one, but a few users are down-weighted.",4. Case Study: Poisson factorization for recommendation,[0],[0]
These are film enthusiasts who appear to indiscriminately watch many movies from many genres.,4. Case Study: Poisson factorization for recommendation,[0],[0]
(Appendix F shows an example.),4. Case Study: Poisson factorization for recommendation,[0],[0]
"These users do not contribute towards identifying movies that go together; this explains why the RPM down-weights them.
",4. Case Study: Poisson factorization for recommendation,[0],[0]
Recall the example from our introduction.,4. Case Study: Poisson factorization for recommendation,[0],[0]
"A child typically watches popular animated films, but her parents occasionally use her account to watch horror films.",4. Case Study: Poisson factorization for recommendation,[0],[0]
We simulate this by corrupting a small percentage of users.,4. Case Study: Poisson factorization for recommendation,[0],[0]
"We replace a ratio R D .0:1; 0:5; 1/ of these users’ movies with randomly selected movies.
",4. Case Study: Poisson factorization for recommendation,[0],[0]
"The boxplot in Figure 8b shows the weights we infer for these corrupted users, based on how many of their movies we randomly replace.",4. Case Study: Poisson factorization for recommendation,[0],[0]
The weights decrease as we corrupt more movies.,4. Case Study: Poisson factorization for recommendation,[0],[0]
Table 3 shows how this leads to higher heldout predictive accuracy; down-weighting these corrupted users leads to better prediction.,4. Case Study: Poisson factorization for recommendation,[0],[0]
Reweighted probabilistic models (RPM) offer a systematic approach to mitigating various forms of mismatch with reality.,5. Discussion,[0],[0]
The idea is to raise each data likelihood to a weight and to infer the weights along with the hidden patterns.,5. Discussion,[0],[0]
"We demonstrate how this strategy introduces robustness and improves prediction accuracy across four types of mismatch.
RPMs also offer a way to detect mismatch with reality.",5. Discussion,[0],[0]
The distribution of the inferred weights sheds light onto datapoints that fail to match the original model’s assumptions.,5. Discussion,[0],[0]
"RPMs can thus lead to new model development and deeper insights about our data.
RPMs can also work with non-exchangeable data, such as time series.",5. Discussion,[0],[0]
"Some time series models admit exchangeable likelihood approximations (Guinness & Stein, 2013).",5. Discussion,[0],[0]
"For other models, a non-overlapping windowing approach would also work.",5. Discussion,[0],[0]
"The idea of reweighting could also extend to structured likelihoods, such as Hawkes process models.",5. Discussion,[0],[0]
"We thank Adji Dieng, Yuanjun Gao, Inchi Hu, Christian Naesseth, Rajesh Ranganath, Francisco Ruiz, and Dustin Tran for their insightful comments.",Acknowledgements,[0],[0]
"This work is supported by NSF IIS-1247664, ONR N00014-11-1-0651, DARPA PPAML FA8750-14-2-0009, DARPA SIMPLEX N6600115-C-4032, and the Alfred P. Sloan Foundation.",Acknowledgements,[0],[0]
Probabilistic models analyze data by relying on a set of assumptions.,abstractText,[0],[0]
Data that exhibit deviations from these assumptions can undermine inference and prediction quality.,abstractText,[0],[0]
Robust models offer protection against mismatch between a model’s assumptions and reality.,abstractText,[0],[0]
We propose a way to systematically detect and mitigate mismatch of a large class of probabilistic models.,abstractText,[0],[0]
The idea is to raise the likelihood of each observation to a weight and then to infer both the latent variables and the weights from data.,abstractText,[0],[0]
Inferring the weights allows a model to identify observations that match its assumptions and down-weight others.,abstractText,[0],[0]
This enables robust inference and improves predictive accuracy.,abstractText,[0],[0]
"We study four different forms of mismatch with reality, ranging from missing latent groups to structure misspecification.",abstractText,[0],[0]
A Poisson factorization analysis of the Movielens 1M dataset shows the benefits of this approach in a practical scenario.,abstractText,[0],[0]
Robust Probabilistic Modeling with Bayesian Data Reweighting,title,[0],[0]
"In machine learning and statistics, a linear model of the form y = ⟨θ∗,x⟩+ϵ is widely used to find the relationship between feature and response, which has gained overwhelming popularity for a very long time.",1. Introduction,[0],[0]
Here y ∈ R and x ∈,1. Introduction,[0],[0]
"Rp is the pair of observed response and feature/measurement vector, ϵ is a zero-mean noise, and θ∗ ∈",1. Introduction,[0],[0]
Rp is the unknown parameter to be estimated.,1. Introduction,[0],[0]
"The simplicity of linear model leads to its great interpretability and computational efficiency, which are often favored in practical applications.",1. Introduction,[0],[0]
"On theoretical side, even in high-dimensional regime where sample size is smaller than the problem dimension p, strong statistical guarantees have been established under mild assumptions for various estimators, such as Lasso (Tibshirani, 1996) and Dantzig selector (Candes & Tao, 2007).",1. Introduction,[0],[0]
"Despite its attractive merits, one main drawback of linear models is the stringent assumption of linear relationship between x and y, which may fail to hold in com-
1Department of Computer Science & Engineering, University of Minnesota-Twin Cities, Minnesota, USA.",1. Introduction,[0],[0]
"Correspondence to: Sheng Chen <shengc@cs.umn.edu>, Arindam Banerjee <banerjee@cs.umn.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
plicated scenarios.",1. Introduction,[0],[0]
"To introduce more flexibility, one option is to consider the general single-index models (SIMs) (Ichimura, 1993; Horowitz & Hardle, 1996),
E[y|x] = f∗(⟨θ∗,x⟩) , (1)
",1. Introduction,[0],[0]
where f∗ :,1. Introduction,[0],[0]
R 7→ R is an unknown univariate transfer function (a.k.a. link function).,1. Introduction,[0],[0]
"This class of models enjoys rich modeling power in the sense that it encompasses several useful models as special cases, which are briefly described below:
• One-bit Compressed Sensing: In one-bit compressed sensing (1-bit CS) (Boufounos & Baraniuk, 2008; Plan & Vershynin, 2013), the response y is restricted to be binary, i.e., y ∈ {+1,−1}, and the range of transfer function f∗ is [−1, 1].",1. Introduction,[0],[0]
"Given the measurement vector x, one can generate y from the Bernoulli model,
y + 1
2 ∼ Ber
( f∗(⟨θ∗,x⟩) + 1
2
) .",1. Introduction,[0],[0]
"(2)
In the noiseless case, f∗(z) = sign(z) and y always reflects the true sign of ⟨θ∗,x⟩, while y can be incorrect for other f∗ whose shape determines the noise level in some way.",1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
Generalized Linear Models:,1. Introduction,[0],[0]
"In generalized linear models (GLMs) (McCullagh, 1984), the transfer function is assumed to be monotonically increasing and conditional distribution of y|x belongs to exponential family.",1. Introduction,[0],[0]
Different choices of f∗ give rise to different members in GLMs.,1. Introduction,[0],[0]
If f∗ is identity function f∗(z),1. Introduction,[0],[0]
"= z, one has the simple linear models, while the sigmoid function f∗(z) =",1. Introduction,[0],[0]
11+e−z results in the logistic model for binary classification.,1. Introduction,[0],[0]
"In this work, however, we have no access to exact f∗ other than knowing it is monotonic.",1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
"Noise in Monotone Transfer: Instead of having the general expectation form of y as GLMs, one could directly introduce the noise inside monotone transfer f̃ to model the randomness of y (Plan et al., 2016),
y = f̃ (⟨θ∗,x⟩+ ϵ) .",1. Introduction,[0],[0]
"(3)
In this setting, the transfer function f̃ is slightly different from the f∗ in (1), which are related by f∗(z) = Eϵ[f̃(z + ϵ)|z].
",1. Introduction,[0],[0]
A key advantage of SIM is its robustness.,1. Introduction,[0],[0]
"First, allowing unknown f∗ prevents the mis-specification of transfer function, which could otherwise lead to a poor estimate of θ∗.",1. Introduction,[0],[0]
"Secondly, the model in (1) makes minimal assumption on the distribution of y, thus being able to tolerate potentially heavy-tailed noise.
",1. Introduction,[0],[0]
"In order to estimate θ∗, we are given n measurements of (x, y) ∈",1. Introduction,[0],[0]
"Rp × R, denoted by {(xi, yi)}ni=1.",1. Introduction,[0],[0]
"In this work, we focus on the n < p regime.",1. Introduction,[0],[0]
"In such high-dimensional setting, the recovery of θ∗ is quite challenging as the problem is ill-posed even when f∗ is given.",1. Introduction,[0],[0]
"Over the last decade, substantial progress has been made to address the challenge by exploiting the apriori structure of parameter θ∗, like sparsity (Tibshirani, 1996).",1. Introduction,[0],[0]
"For simple linear models or GLMs with known transfer, extensive studies have shown that sparse θ∗ can be consistently estimated under mild assumptions, with much lower sample complexity than p (Candes & Tao, 2007; Wainwright, 2009; Bickel et al., 2009; Kakade et al., 2010; Negahban et al., 2012; Yang et al., 2016).",1. Introduction,[0],[0]
"Recently the notion of structure has been suitably generalized beyond the unstructured sparsity (Bach et al., 2012), and Gaussian width (Gordon, 1985) has emerged as a useful measure to characterize the structural complexity which further determines the recovery guarantee of θ∗ (Chandrasekaran et al., 2012; Rao et al., 2012; Oymak et al., 2013; Amelunxen et al., 2014; Banerjee et al., 2014; Chatterjee et al., 2014; Vershynin, 2015; Tropp, 2015; Chen & Banerjee, 2016).
",1. Introduction,[0],[0]
"In the absence of exact f∗, though 1-bit CS and related variants were well-studied in recent years (Boufounos & Baraniuk, 2008; Jacques et al., 2013; Plan & Vershynin, 2013; Gopi et al., 2013; Zhang et al., 2014; Chen & Banerjee, 2015a; Zhu & Gu, 2015; Yi et al., 2015; Slawski & Li, 2015; Li, 2016; Slawski & Li, 2016), the exploration of general SIMs or the cases with monotone transfers is relatively limited, especially in the high-dimensional regime.",1. Introduction,[0],[0]
"Kalai & Sastry (2009) and Kakade et al. (2011) investigated the low-dimensional SIMs with monotone transfers, and they proposed perceptron-type algorithms to estimate both f∗ and θ∗, with provable guarantees on prediction error.",1. Introduction,[0],[0]
"In high dimension, general SIMs were studied by Alquier & Biau (2013) and Radchenko (2015), in which only unstructured sparsity of θ∗ is considered.",1. Introduction,[0],[0]
"The algorithm developed in (Alquier & Biau, 2013) relies on reversible jump MCMC, which could be slow.",1. Introduction,[0],[0]
"In Radchenko (2015), a path fitting algorithm is designed to recover f∗ and θ∗, but only asymptotic guarantees are provided.",1. Introduction,[0],[0]
"Ganti et al. (2015) considered the high-dimensional setting with monotone transfer, and their iterative algorithm is based on non-convex optimization, for which it is hard to establish the convergence.",1. Introduction,[0],[0]
"Besides, the prediction error bound they derived is also weak (in the sense that it
is even worse than the initialization of the algorithm).",1. Introduction,[0],[0]
"Recently Oymak & Soltanolkotabi (2016) proposed a constrained least-squares method to estimate θ∗, with recovery error characterized by Gaussian width and related quantities.",1. Introduction,[0],[0]
"Though their analysis considered the general structure of θ∗, it only holds for noiseless setting where y = f(⟨θ∗,x⟩).",1. Introduction,[0],[0]
General structure of θ∗ was also explored in Vershynin (2015) and Plan et al. (2016).,1. Introduction,[0],[0]
"Other types of statistical guarantees for high-dimensional SIMs is also available, such as support recovery of θ∗ in Neykov et al. (2016).",1. Introduction,[0],[0]
"It is worth noting that all the aforementioned statistical analyses rely on sub-Gaussian noise or the transfer function being bounded or Lipschitz, which indicates that none of the results can immediately hold for heavy-tailed noise (or without Lipschitzness and boundedness).
",1. Introduction,[0],[0]
"In this paper, we focus on the parameter estimation of θ∗ instead of the prediction of y given new x.",1. Introduction,[0],[0]
"In particular, we propose two families of generalized estimators, constrained and regularized, for model (1) under Gaussian measurement.",1. Introduction,[0],[0]
"The parameter θ∗ is assumed to possess certain lowcomplexity structure, which can be either captured by a constraint θ∗ ∈ K or a norm regularization term ∥θ∗∥.",1. Introduction,[0],[0]
"Our general approach is inspired by U -statistics and the advances in 1-bit CS, and subsumes several existing 1-bit CS algorithms as special cases.",1. Introduction,[0],[0]
"Similar to those algorithms, our estimator is simple and often admits closed-form solutions.",1. Introduction,[0],[0]
"Regarding the recovery analysis, there are two appealing aspects.",1. Introduction,[0],[0]
"First our results work for general structure, with error bound characterized by Gaussian width and some other easy-to-compute geometric measures.",1. Introduction,[0],[0]
"Instantiating our results with specific structure of θ∗ recovers previously established error bounds for 1-bit CS (Zhang et al., 2014; Chen & Banerjee, 2015a), which are sharper than those yielded by the general analysis in Plan & Vershynin (2013).",1. Introduction,[0],[0]
"Second, our analysis works with limited assumptions on the condition distribution of y.",1. Introduction,[0],[0]
"In particular, our estimator is robust to heavy-tailed noise and permit unbounded transfer functions f∗ as well as non-Lipschitz ones.",1. Introduction,[0],[0]
"At the heart of our analysis is the generic chaining method (Talagrand, 2014), an advanced tool in probability theory, which has been successfully applied to sparse recovery (Koltchinskii, 2011) and dimensionality reduction (Dirksen, 2016), etc.",1. Introduction,[0],[0]
"Another key ingredient in our proof is a Hoeffding-type concentration inequality for U -statistics (Lee, 1990) with sub-Gaussian tails, which is less known yet generalizes the popular one for bounded U -statistics (Hoeffding, 1963).",1. Introduction,[0],[0]
"Apart from 1-bit CS, we particularly investigate the model (3), for which the generalized estimator is specialized in a novel way.",1. Introduction,[0],[0]
"The resulting estimator better leverages the monotonicity of the transfer function, which is also demonstrated through experiments.",1. Introduction,[0],[0]
"For the ease of exposition, whenever we say “monotone”, it means “monotonically increasing” by default.",1. Introduction,[0],[0]
"Throughout the
paper, we will use c, C,C ′, C0, C1 and so on to denote absolute constants, which may differ from context to context.",1. Introduction,[0],[0]
"Detailed proofs are deferred to the supplementary material due to page limit.
",1. Introduction,[0],[0]
The rest of the paper is organized as follows.,1. Introduction,[0],[0]
"In Section 2, we introduce our estimators for SIMs along with their recovery guarantees.",1. Introduction,[0],[0]
We also provide a few examples in 1-bit CS for illustration.,1. Introduction,[0],[0]
"Section 3 is focused on model (3), for which we instantiate the general results in a new way.",1. Introduction,[0],[0]
Other structures of θ∗ beyond unstructured sparsity are also discussed.,1. Introduction,[0],[0]
Section 4 provides the proof of our main results and the related lemmas.,1. Introduction,[0],[0]
"In Section 5, we complement our theoretical developments with some experiment results.",1. Introduction,[0],[0]
The final section is dedicated to conclusions.,1. Introduction,[0],[0]
"For the sake of identifiability, we assume w.l.o.g.",2.1. Assumptions and Preliminaries,[0],[0]
that ∥θ∗∥2 = 1 throughout the paper.,2.1. Assumptions and Preliminaries,[0],[0]
"At the first glimpse of model (1), we may realize that it is difficult to recover θ∗ due to unknown f∗.",2.1. Assumptions and Preliminaries,[0],[0]
"In contrast, when f∗ is given, the recovery guarantees of θ∗ can be established under mild assumptions of x and y, such as boundedness or subGaussianity.",2.1. Assumptions and Preliminaries,[0],[0]
"If we know certain properties of the transfer function like the monotonicity introduced in GLMs and (3), the structure of f∗ is largely restricted, and it is tempting to expect that similar results will continue to hold.",2.1. Assumptions and Preliminaries,[0],[0]
"Unfortunately, we first have the following claim, which indicates that without other constraints on f∗ beyond strict monotonicity, θ∗ cannot be consistently estimated under general sub-Gaussian (or bounded) measurement, even in the noiseless setting of (3).
",2.1. Assumptions and Preliminaries,[0],[0]
Claim 1 Suppose that each element xi of x is sampled i.i.d.,2.1. Assumptions and Preliminaries,[0],[0]
"from Rademacher distribution, i.e., P(xi = 1)",2.1. Assumptions and Preliminaries,[0],[0]
=,2.1. Assumptions and Preliminaries,[0],[0]
P(xi = −1) = 0.5.,2.1. Assumptions and Preliminaries,[0],[0]
"Under model (3) with noise ϵ = 0, there exists a θ̄ ∈ Sp−1 together with a monotone f̄ , such that supp(θ̄) = supp(θ∗) and yi = f̄(⟨θ̄,xi⟩) for data {(xi, yi)}ni=1 with arbitrarily large sample size n, while ∥θ̄ − θ∗∥2",2.1. Assumptions and Preliminaries,[0],[0]
>,2.1. Assumptions and Preliminaries,[0],[0]
δ,2.1. Assumptions and Preliminaries,[0],[0]
"for some constant δ.
",2.1. Assumptions and Preliminaries,[0],[0]
"Now that consistent estimation of θ∗ is not possible for general sub-Gaussian measurement, it might be reasonable to focus on certain special cases.",2.1. Assumptions and Preliminaries,[0],[0]
"For this work, we assume that x is standard Gaussian N (0, I).",2.1. Assumptions and Preliminaries,[0],[0]
"For SIM (1), we additionally assume that the distribution of y depends on x only through the value of ⟨θ∗,x⟩, i.e., the distribution of y|x is fixed if ⟨θ∗,x⟩ is given (no matter what the exact x is).",2.1. Assumptions and Preliminaries,[0],[0]
"This assumption is quite minimal, and it turns out that the examples we provide in Section 1 all satisfy it (if noise ϵ is independent of x in (3)).",2.1. Assumptions and Preliminaries,[0],[0]
"The same assumption is used
in Plan et al. (2016) as well.
",2.1. Assumptions and Preliminaries,[0],[0]
"Under the assumptions above, given m i.i.d. observations (x1, y1), . . .",2.1. Assumptions and Preliminaries,[0],[0]
", (xm, ym), we define
u ((x1, y1), . . .",2.1. Assumptions and Preliminaries,[0],[0]
", (xm, ym))",2.1. Assumptions and Preliminaries,[0],[0]
=,2.1. Assumptions and Preliminaries,[0],[0]
"m∑ i=1 qi (y1, . . .",2.1. Assumptions and Preliminaries,[0],[0]
", ym) ·",2.1. Assumptions and Preliminaries,[0],[0]
"xi ,
(4) where all qi :",2.1. Assumptions and Preliminaries,[0],[0]
"Rm 7→ R are bounded functions with |qi| ≤ 1, which are chosen along with m based on the properties of the transfer function.",2.1. Assumptions and Preliminaries,[0],[0]
"In Section 2.4 and 3.1, we will see examples for their choices.",2.1. Assumptions and Preliminaries,[0],[0]
The vector u ∈,2.1. Assumptions and Preliminaries,[0],[0]
"Rp is critical due to the key observation below.
",2.1. Assumptions and Preliminaries,[0],[0]
"Lemma 1 Suppose the distribution of y in model (1) depends on x through ⟨θ∗,x⟩",2.1. Assumptions and Preliminaries,[0],[0]
"and we define accordingly
bi (z1, . . .",2.1. Assumptions and Preliminaries,[0],[0]
", zm;θ ∗) = (5)
E",2.1. Assumptions and Preliminaries,[0],[0]
"[qi (y1, . .",2.1. Assumptions and Preliminaries,[0],[0]
.,2.1. Assumptions and Preliminaries,[0],[0]
", ym) |⟨θ∗,x1⟩ = z1, . . .",2.1. Assumptions and Preliminaries,[0],[0]
", ⟨θ∗,xm⟩ = zm] .
",2.1. Assumptions and Preliminaries,[0],[0]
"With x being standard Gaussian N (0, I), u defined in (4) satisfies
E",2.1. Assumptions and Preliminaries,[0],[0]
"[u ((x1, y1), . . .",2.1. Assumptions and Preliminaries,[0],[0]
", (xm, ym))]",2.1. Assumptions and Preliminaries,[0],[0]
"= βθ∗ , (6)
where β = ∑m i=1 E[bi (g1, . . .",2.1. Assumptions and Preliminaries,[0],[0]
", gm;θ∗) · gi], and g1, . . .",2.1. Assumptions and Preliminaries,[0],[0]
", gm are i.i.d.",2.1. Assumptions and Preliminaries,[0],[0]
"standard Gaussian.
",2.1. Assumptions and Preliminaries,[0],[0]
"Note that Lemma 1 is true for all choices of qi, and the proof is given in the supplement.",2.1. Assumptions and Preliminaries,[0],[0]
"This lemma presents an insight towards the design of our estimator, that is, the direction of θ∗ can be approximated if we have a good sense about Eu.",2.1. Assumptions and Preliminaries,[0],[0]
"As we will see in the sequel, the scalar β plays a key role in the estimation error bound, which can give us clues to the choice of qi.",2.1. Assumptions and Preliminaries,[0],[0]
We can assume w.l.o.g.,2.1. Assumptions and Preliminaries,[0],[0]
that β ≥ 0,2.1. Assumptions and Preliminaries,[0],[0]
"since we can flip the sign of each qi.
",2.1. Assumptions and Preliminaries,[0],[0]
"The recovery analysis is built on the notion of Gaussian width (Gordon, 1985), which is defined for any A ⊆ Rp as w(A) = E[supv∈A⟨g,v⟩], where g is a standard Gaussian random vector.",2.1. Assumptions and Preliminaries,[0],[0]
"Roughly speaking, w(A) measures the scaled width of set A averaged over each direction.",2.1. Assumptions and Preliminaries,[0],[0]
"Inspired by Lemma 1, we define the vector û for the observed data {(xi, yi)}ni=1,
û = (n−m)!
n!
∑ 1≤i1,...,im≤n i1 ̸=...",2.2. Generalized Estimator,[0],[0]
"̸=im u ((xi1 , yi1), . . .",2.2. Generalized Estimator,[0],[0]
", (xim , yim)) ,
(7) which is an unbiased estimator of Eu, meaning that Eû = Eu = βθ∗. When m = 2, we essentially have
û = 1 n(n− 1) ∑
1≤i,j≤n i ̸=j
u ((xi, yi), (xj , yj)) (8)
In fact, û can be treated as a vector version of U -statistics with order m.",2.2. Generalized Estimator,[0],[0]
"Given û, a naive way to estimate θ∗ is to simply normalize û, i.e., θ̂ = û/∥û∥2.",2.2. Generalized Estimator,[0],[0]
"In highdimensional setting, θ∗ is often structured, but the naive estimator fails to take such information into account, which would lead to large error.",2.2. Generalized Estimator,[0],[0]
"To incorporate the prior knowledge on θ∗, we design two types of estimator, the constrained one and the regularized one.
",2.2. Generalized Estimator,[0],[0]
Constrained Estimator:,2.2. Generalized Estimator,[0],[0]
"If we assume that θ∗ belongs to some structured set K ⊆ Sp−1, then the estimation of θ∗ is carried out via the constrained optimization
θ̂ = argmin θ∈Rp
− ⟨û,θ⟩ s.t. θ ∈ K .",2.2. Generalized Estimator,[0],[0]
"(9)
Here the set K can be non-convex, as long as the optimization can be solved globally.",2.2. Generalized Estimator,[0],[0]
"Since the objective function is very simple, we can often end up with a global minimizer.",2.2. Generalized Estimator,[0],[0]
"Similar estimator has been used in Plan et al. (2016), but they only focused on specific û.
Regularized Estimator: If we assume that the structure of θ∗ can be captured by certain norm ∥ · ∥, we may alternatively use the regularized estimator to find θ∗,
θ̂ = argmin θ∈Rp
− ⟨û,θ⟩+",2.2. Generalized Estimator,[0],[0]
λ∥θ∥ s.t. ∥θ∥2 ≤ 1 .,2.2. Generalized Estimator,[0],[0]
"(10)
",2.2. Generalized Estimator,[0],[0]
"The optimization is convex, thus the global minimum is always attained.",2.2. Generalized Estimator,[0],[0]
"Previously this estimator was used in 1-bit CS scenario with L1 norm (Zhang et al., 2014).",2.2. Generalized Estimator,[0],[0]
"Regarding the constrained estimator, the recovery of θ∗ relies on the geometry of θ̂, which is described by
AK(θ∗) = cone { v ∣∣∣ v = θ̂ − θ∗, θ̂ ∈ K} ∩",2.3. Recovery Analysis,[0],[0]
"Sp−1
(11)",2.3. Recovery Analysis,[0],[0]
The set AK(θ∗) essentially contains all possible directions that error θ̂,2.3. Recovery Analysis,[0],[0]
− θ∗ could lie in.,2.3. Recovery Analysis,[0],[0]
"The following theorem characterizes the error of θ̂.
Theorem 1 Suppose that the optimization (9) can be solved to global minimum.",2.3. Recovery Analysis,[0],[0]
"Then the following error bound holds for the minimizer θ̂ with probability at least 1 − C ′′ exp ( −w2 (AK(θ∗)) ) ,
∥∥∥θ̂",2.3. Recovery Analysis,[0],[0]
− θ∗∥∥∥ 2 ≤,2.3. Recovery Analysis,[0],[0]
Cκm 3 2 β · w(AK(θ ∗)),2.3. Recovery Analysis,[0],[0]
"+ C ′√ n , (12)
where κ is the sub-Gaussian norm of a standard Gaussian random variable, and C, C ′, C ′′ are all absolute constant.
",2.3. Recovery Analysis,[0],[0]
Remark: Note that estimator is consistent as long as β ̸= 0.,2.3. Recovery Analysis,[0],[0]
"The error bound inversely depends on the scale of β,
which implies that we should construct suitable qi such that β is large according to its definition in Lemma 1.",2.3. Recovery Analysis,[0],[0]
"The choice of qi further depends on the assumed property of f∗. Though dependency on m may prevent us from using higher-order u, m is typically small in practice and can be treated as constant.
",2.3. Recovery Analysis,[0],[0]
"For regularized estimator, we can similarly establish the recovery guarantee in terms of Gaussian width.
",2.3. Recovery Analysis,[0],[0]
"Theorem 2 Define the following set for any ρ > 1, Aρ (θ∗) = cone { v ∣∣∣",2.3. Recovery Analysis,[0],[0]
"∥v + θ∗∥ ≤ ∥θ∗∥+ ∥v∥
ρ
} ∩",2.3. Recovery Analysis,[0],[0]
"Sp−1
If we set λ = ρ ∥û− βθ∗∥∗ = O(ρm3/2w(B∥·∥)/ √ n) and it satisfies λ",2.3. Recovery Analysis,[0],[0]
<,2.3. Recovery Analysis,[0],[0]
"∥û∥∗, then with probability at least 1− C ′ exp ( −w2 ( B∥·∥
)) , θ̂ in (10) satisfies∥∥∥θ̂",2.3. Recovery Analysis,[0],[0]
"− θ∗∥∥∥
2 ≤ C(1 + ρ)κm
3 2 β · Ψ(Aρ(θ∗)) ·",2.3. Recovery Analysis,[0],[0]
"w
( B∥·∥ )",2.3. Recovery Analysis,[0],[0]
"√ n ,
(13) where Ψ(Aρ(θ∗)) = supv∈Aρ(θ∗) ∥v∥ and B∥·∥ = {v | ∥v∥ ≤ 1} is the unit ball of norm ∥ · ∥.
Remark: The geometry of the regularized estimator is slightly different from the constrained one.",2.3. Recovery Analysis,[0],[0]
"Instead of having AK(θ∗), here the set Aρ(θ∗) depends on the choice of the regularization parameter λ.",2.3. Recovery Analysis,[0],[0]
"The same phenomenon also appears in the (Banerjee et al., 2014).",2.3. Recovery Analysis,[0],[0]
"The geometric measure Ψ(Aρ(θ∗)) is called restricted norm compatibility, which is non-random.",2.3. Recovery Analysis,[0],[0]
"For many interesting cases, it is easy to calculate (Negahban et al., 2012; Chen & Banerjee, 2015b).",2.3. Recovery Analysis,[0],[0]
"For 1-bit CS problem (2), the u defined in (4) can be chosen with m = 1 and qi = yi, ending up with
u ((x, y))",2.4. Application to 1-bit CS,[0],[0]
"= yx and û = 1
n n∑ i=1",2.4. Application to 1-bit CS,[0],[0]
yixi .,2.4. Application to 1-bit CS,[0],[0]
"(14)
By such choice of u, the β defined in Lemma 1 is simply β = E[f∗(g)g] with g being standard Gaussian random vector.",2.4. Application to 1-bit CS,[0],[0]
"Under reasonably mild noise, y is likely to take the sign of the linear measurement, which means that f∗(g) should be close to 1 (or -1)",2.4. Application to 1-bit CS,[0],[0]
if g is positive (or negative).,2.4. Application to 1-bit CS,[0],[0]
Thus we expect f∗(g)g to be positive most of time and β to be large.,2.4. Application to 1-bit CS,[0],[0]
"Given the choice of u, we can specialize our generalized constrained/regularized estimator to obtain previous results.",2.4. Application to 1-bit CS,[0],[0]
"If θ∗ is assumed to be s-sparse, for constrained estimator, we can choose a straightforward K = {θ | ∥θ∥0 ≤ s}∩Sp−1, which results in the k-support norm estimator (Chen & Banerjee, 2015a),
θ̂ks = argmin θ∈Rp",2.4. Application to 1-bit CS,[0],[0]
"− ⟨û,θ⟩ s.t. ∥θ∥0 ≤ s, ∥θ∥2 = 1 (15)
",2.4. Application to 1-bit CS,[0],[0]
"Though K is non-convex, the global minimizer can actually be obtained in closed form,
θ̂ksj =
{ ûj / ∥|û|↓1:s∥2 , if |ûj | is in |û| ↓",2.4. Application to 1-bit CS,[0],[0]
"1:s
0 , otherwise (16)
where |û|↓ is the absolute-value counterpart of û with entries sorted in descending order, and the subscript takes the top s entries.",2.4. Application to 1-bit CS,[0],[0]
"Similarly if the regularized estimator is instantiated with L1 norm ∥ · ∥1, we obtain the so-called passive algorithm introduced in Zhang et al. (2014),
θ̂ps = argmin θ∈Rp",2.4. Application to 1-bit CS,[0],[0]
"− ⟨û,θ⟩+",2.4. Application to 1-bit CS,[0],[0]
"λ∥θ∥1 s.t. ∥θ∥2 ≤ 1 , (17)
whose solution is given by θ̂ps = S (û, λ) /∥S",2.4. Application to 1-bit CS,[0],[0]
"(û, λ) ∥2, where S(·, ·) is the elementwise soft-thresholding operator, Si(û, λ) = max{sign(ûi)(|ûi|−λ), 0}.",2.4. Application to 1-bit CS,[0],[0]
"Based on Theorem 1 and 2, we can easily obtain the error bound for both ksupport norm estimator and passive algorithm.
",2.4. Application to 1-bit CS,[0],[0]
"Corollary 1 Assume that {(xi, yi)}ni=1 follow 1-bit CS model in (2) and û is given as (14).",2.4. Application to 1-bit CS,[0],[0]
"For any s-sparse θ∗, with high probability, θ̂ produced by both (15) and (17) (i.e., θ̂ks and θ̂ps) satisfy
∥∥∥θ̂",2.4. Application to 1-bit CS,[0],[0]
− θ∗∥∥∥ 2 ≤,2.4. Application to 1-bit CS,[0],[0]
O (√ s log p n ),2.4. Application to 1-bit CS,[0],[0]
"(18)
",2.4. Application to 1-bit CS,[0],[0]
The proof is included in the supplementary material.,2.4. Application to 1-bit CS,[0],[0]
"The above result was shown by Slawski & Li (2015) and Zhang et al. (2014), but their analyses do not consider the general structure.",2.4. Application to 1-bit CS,[0],[0]
"Compared with O( 4 √ s log p/n) yielded by the general result in Plan & Vershynin (2013), our bound is much sharper.",2.4. Application to 1-bit CS,[0],[0]
"In this section, we specifically study model (3).",3. A New Estimator for Monotone Transfer,[0],[0]
Here we further assume that f̃ is strictly increasing.,3. A New Estimator for Monotone Transfer,[0],[0]
What is worth mentioning is that the estimator we develop here can be applied to GLMs as well.,3. A New Estimator for Monotone Transfer,[0],[0]
"To avoid the confusion with u and û defined previously, we instead use new notations h and ĥ respectively in this section.",3. A New Estimator for Monotone Transfer,[0],[0]
"To motivate the design of h, it is helpful to rewrite model (3) by applying the inverse of f̃ on both sides,
f̃−1(y) = ⟨θ∗,x⟩+ ϵ .",3.1. Estimator with Second-Order ĥ,[0],[0]
"(19)
Note that the new formulation resembles the linear model except that we have no access to the value of f̃−1(y).",3.1. Estimator with Second-Order ĥ,[0],[0]
"Instead, all we know about r = [f̃−1(y1), . . .",3.1. Estimator with Second-Order ĥ,[0],[0]
", f̃−1(yn)]T ∈",3.1. Estimator with Second-Order ĥ,[0],[0]
Rn is that it preserves the ordering of y =,3.1. Estimator with Second-Order ĥ,[0],[0]
"[y1, . . .",3.1. Estimator with Second-Order ĥ,[0],[0]
", yn]T .
",3.1. Estimator with Second-Order ĥ,[0],[0]
"Put in another way, r needs to satisfy the constraint that ri > rj iff.",3.1. Estimator with Second-Order ĥ,[0],[0]
yi > yj and ri < rj iff.,3.1. Estimator with Second-Order ĥ,[0],[0]
yi < yj .,3.1. Estimator with Second-Order ĥ,[0],[0]
"To move one step further, it is equivalent to sign(yi − yj) = sign(ri−rj) = sign(⟨θ∗,xi−xj⟩+ϵi−ϵj) based on model assumption.",3.1. Estimator with Second-Order ĥ,[0],[0]
"Hence the information contained in sample {(xi, yi)}ni=1 can be interpreted from the perspective of 1- bit CS, where sign(yi − yj) reflects the perturbed sign of linear measurement ⟨θ∗,xi",3.1. Estimator with Second-Order ĥ,[0],[0]
"− xj⟩. Inspired by the u for 1-bit CS, we may choose m = 2 and define h, ĥ as
h ((x1, y1), (x2, y2))",3.1. Estimator with Second-Order ĥ,[0],[0]
"= sign(y1 − y2) · (x1 − x2) , (20)
ĥ = 1 n(n− 1) ∑
1≤i,j≤n i ̸=j
h ((xi, yi), (xj , yj)) , (21)
",3.1. Estimator with Second-Order ĥ,[0],[0]
"Given the definition of ĥ, Lemma 1 directly implies the following corollary.
",3.1. Estimator with Second-Order ĥ,[0],[0]
"Corollary 2 Suppose that (x1, y2) and (x2, y2) are generated by model (3), where x1,x2 follow Gaussian distribution N (0, I), and the noise ϵ1, ϵ2 are independent of x1,x2 and identically (but arbitrarily) distributed.",3.1. Estimator with Second-Order ĥ,[0],[0]
"Then the expectation of h ((x1, y1), (x2, y2)) satisfies
E",3.1. Estimator with Second-Order ĥ,[0],[0]
"[h ((x1, y1), (x2, y2))]",3.1. Estimator with Second-Order ĥ,[0],[0]
"= √ 2β′θ∗ , (22)
where β′ = Eg∼N (0,1) [ sign ( g + (ϵ1 − ϵ2)/ √ 2 ) · g ] .
",3.1. Estimator with Second-Order ĥ,[0],[0]
"Remark: The scalar √ 2β′ serves as the role of β in Lemma 1, and β′ is always guaranteed to be strictly positive regardless how the noise is distributed, which keeps θ∗ distinguishable all the time.",3.1. Estimator with Second-Order ĥ,[0],[0]
"To see this, let ξ = (ϵ1− ϵ2)/ √ 2.",3.1. Estimator with Second-Order ĥ,[0],[0]
"Note that ξ is symmetric, thus εξ has the same distribution as ξ, where ε is a Rademacher random variable.",3.1. Estimator with Second-Order ĥ,[0],[0]
"Therefore
β′",3.1. Estimator with Second-Order ĥ,[0],[0]
= E,3.1. Estimator with Second-Order ĥ,[0],[0]
"[sign (g + ξ) · g] = Eg,ξEε [sign (g + εξ) ·",3.1. Estimator with Second-Order ĥ,[0],[0]
"g] = EξEg [
sign (g − ξ) + sign (g + ξ) 2
· g ]
Since g(g − ξ) + g(g + ξ) = 2g2 ≥ 0, it follows that sign(g(g− ξ))+",3.1. Estimator with Second-Order ĥ,[0],[0]
sign(g(g+ ξ)) =,3.1. Estimator with Second-Order ĥ,[0],[0]
(sign(g− ξ)+ sign(g+ ξ)) ·,3.1. Estimator with Second-Order ĥ,[0],[0]
"sign(g) ≥ 0, thus (sign(g − ξ) + sign(g + ξ)) · g is always nonnegative.",3.1. Estimator with Second-Order ĥ,[0],[0]
"Find a large enough M > 0 such that P(|ξ| ≤ M) = 0.5 > 0, and we have
β′",3.1. Estimator with Second-Order ĥ,[0],[0]
= E,3.1. Estimator with Second-Order ĥ,[0],[0]
[sign (g + ξ) ·,3.1. Estimator with Second-Order ĥ,[0],[0]
"g] ≥ EξEg [|g| · I{|g| > |ξ|}]
≥ 0.5Eg [|g| · I{|g|",3.1. Estimator with Second-Order ĥ,[0],[0]
"> M}] = M
2 · P(|g| > M) > 0 .
",3.1. Estimator with Second-Order ĥ,[0],[0]
"In the ideal noiseless case, β′ achieve its maximum, β′max = E[sign(g)g] = E[|g|] = √ 2/π.",3.1. Estimator with Second-Order ĥ,[0],[0]
"In the worst case, if ϵ1 and ϵ2 are heavy-tailed and dominate g, then β′",3.1. Estimator with Second-Order ĥ,[0],[0]
≈ E [ sign ( (ϵ1 − ϵ2)/ √ 2 ) ·,3.1. Estimator with Second-Order ĥ,[0],[0]
g ],3.1. Estimator with Second-Order ĥ,[0],[0]
"≈ 0.
",3.1. Estimator with Second-Order ĥ,[0],[0]
Now we can instantiate the generalized estimator based on ĥ.,3.1. Estimator with Second-Order ĥ,[0],[0]
"For example, if θ∗ is s-sparse, we estimate it by
θ̂ = argmin θ∈Rp
− ⟨ĥ,θ⟩ s.t. ∥θ∥0 ≤ s, ∥θ∥2 = 1 (23)
which enjoys O (√ s log p/n )
error rate as shown in Corollary 1.",3.1. Estimator with Second-Order ĥ,[0],[0]
The regularized estimator can also be obtained with the same ĥ according to (17).,3.1. Estimator with Second-Order ĥ,[0],[0]
The bottleneck of computing θ̂ lies in the calculation of ĥ.,3.1. Estimator with Second-Order ĥ,[0],[0]
"A simple proposition below enables us to get ĥ in a fast manner.
",3.1. Estimator with Second-Order ĥ,[0],[0]
Proposition 1,3.1. Estimator with Second-Order ĥ,[0],[0]
"Given {(xi, yi)}ni=1, let π↓ be the permutation of {1, . . .",3.1. Estimator with Second-Order ĥ,[0],[0]
", n} such that yπ↓1",3.1. Estimator with Second-Order ĥ,[0],[0]
> yπ↓2,3.1. Estimator with Second-Order ĥ,[0],[0]
> .,3.1. Estimator with Second-Order ĥ,[0],[0]
. .,3.1. Estimator with Second-Order ĥ,[0],[0]
> yπ↓n .,3.1. Estimator with Second-Order ĥ,[0],[0]
"Then we have
ĥ = 2
n(n− 1) n∑ i=1",3.1. Estimator with Second-Order ĥ,[0],[0]
(n+ 1− 2i) · xπ↓i,3.1. Estimator with Second-Order ĥ,[0],[0]
"(24)
Remark: Based on the proposition above, ĥ can be efficiently computed in O(np+ n log n) time, i.e., O(n log n) time for sorting y and O(np) time for the weighted sum of all xi.",3.1. Estimator with Second-Order ĥ,[0],[0]
"This is a significant improvement compared with the the naive calculation using (21), which takes O(n2p) time.",3.1. Estimator with Second-Order ĥ,[0],[0]
"So far we have illustrated the Gaussian width based error bounds, viz (12) and (13), only through unstructured sparsity of θ∗.",3.2. Beyond Unstructured Sparsity,[0],[0]
"Here we provide two more examples, nonoverlapping group sparsity and fused sparsity.
",3.2. Beyond Unstructured Sparsity,[0],[0]
"Non-Overlapping Group Sparsity: Suppose the coordinates of θ∗ has been partitioned into K predefined disjoint groups G1, . . .",3.2. Beyond Unstructured Sparsity,[0],[0]
",GK ⊆ {1, 2, . . .",3.2. Beyond Unstructured Sparsity,[0],[0]
", p}, out of which only k groups are non-zero.",3.2. Beyond Unstructured Sparsity,[0],[0]
"If we use the regularized estimator with L2,1 norm ∥θ∥2,1 = ∑K i=1 ∥θGi∥2, the optimal solution can be similarly obtained as (17), with elementwise soft-thresholding replaced by the groupwise one.",3.2. Beyond Unstructured Sparsity,[0],[0]
"The related geometric measures that appears in (13) can be found in Banerjee et al. (2014), which are given by
Ψ(Aρ(θ∗)) ≤",3.2. Beyond Unstructured Sparsity,[0],[0]
"O( √ k) (25)
w",3.2. Beyond Unstructured Sparsity,[0],[0]
"( B∥·∥2,1 ) ≤",3.2. Beyond Unstructured Sparsity,[0],[0]
"O( √ logK + √ G) (26)
Fused Sparsity: θ∗ is said to be s-fused-sparse if the cardinality of the set F(θ∗) =",3.2. Beyond Unstructured Sparsity,[0],[0]
{1 ≤,3.2. Beyond Unstructured Sparsity,[0],[0]
i < p,3.2. Beyond Unstructured Sparsity,[0],[0]
"| θ∗i ̸= θ∗i+1} is smaller than s. If we resort to the constrained estimator (9) with K = {θ | |F(θ)| ≤ s, ∥θ∥2 = 1}, the associated optimization can be solved by dynamic programming (Bellman, 1961).",3.2. Beyond Unstructured Sparsity,[0],[0]
"The proposition below upper bounds the corresponding Gaussian width w(AK(θ∗)) in (12).
",3.2. Beyond Unstructured Sparsity,[0],[0]
"Proposition 2 For s-fused-sparse θ∗, the Gaussian width of set AK(θ∗) with K = {θ | |F(θ)| ≤ s, ∥θ∥2 = 1} satisfies
w(AK(θ∗))",3.2. Beyond Unstructured Sparsity,[0],[0]
"≤ O( √ s log p) (27)
",3.2. Beyond Unstructured Sparsity,[0],[0]
"The proof can be found in (Slawski & Li, 2016), and we provide a different one in supplementary material.",3.2. Beyond Unstructured Sparsity,[0],[0]
Here we first present the important technical lemmas that will be used in the proof of Theorem 1.,4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
The first one is the Hoeffding-type inequality for sub-Gaussian U -statistics.,4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"In the literature, most of the studies are centered around bounded U -statistics, for which the celebrated concentration is established by Hoeffding (1963).",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
Yet it is not easy to locate the counterpart for sub-Gaussian case.,4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"Therefore we provide the following result and attach a proof in the supplementary material.
",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"Lemma 2 (Concentration for sub-Gaussian U -statistics) Define the U -statistic
Un,m(h) = (n−m)!
n!
∑ 1≤i1,...,im≤n i1 ̸=i2 ̸=...",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"̸=im h (zi1 , . . .",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
", zim) (28)
with order m and kernel h :",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"Rd×m 7→ R based on n independent copies of random vector z ∈ Rd, denoted by z1, · · · , zn.",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"If h(·, . . .",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
", ·) is sub-Gaussian with ∥h∥ψ2 ≤ κ, then the following inequality holds for Un,m(h) with any δ > 0,
P (|Un,m(h)− EUn,m(h)| > δ) ≤ 2 exp ( −C ⌊ n m ⌋ ·",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"δ 2 κ2 ) , (29) in which C is an absolute constant.
",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"As mentioned earlier in Section 1, generic chaining is the key tool that our analysis relies on.",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"Specifically we utilize Theorem 2.2.27 from (Talagrand, 2014).
",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
Lemma 3 (Generic chaining concentration),4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"Given metric space (T , s), if an associated stochastic process {Zt}t∈T has sub-Gaussian incremental, i.e., satisfies the condition
P (|Zu − Zv| ≥ δ) ≤ C exp ( − C ′δ2
s2(u,v)
) , ∀ u,v ∈ T ,
(30) then the following inequality holds
P (
sup u,v∈T
",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"|Zu − Zv| ≥ C1 (γ2(T , s) + δ · diam (T , s)) )
",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"≤ C2 exp ( −δ2 ) , (31)
where C,C ′, C1 and C2 are all absolute constants.
",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"The definition of the above γ2-functional γ2(·, ·) is complicated, and is not of great importance.",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"We refer interested
reader to the books, Talagrand (2005; 2014).",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"Loosely speaking, γ2(T , s) can be thought of as a measure for the size of set T under metric s. What really matters is the following relationship between γ2-functional and Gaussian width.",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"(see Theorem 2.4.1 in Talagrand (2014))
",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"Lemma 4 (Majorizing measures theorem) For any set T ⊆ Rp, the γ2-functional w.r.t. L2-metric and Gaussian width satisfy the following inequality with an absolute constant C0,
γ2 (T , ∥ · ∥2) ≤ C0 · w(T ) (32)
Equipped with these lemmas, we are ready to present the proof sketch of Theorem 1.",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"A complete proof is deferred to the supplementary material.
",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
Proof Sketch of Theorem 1: We use the shorthand notation AK for the set AK(θ∗).,4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"As θ̂ attains the global minimum of (9), we have
⟨θ̂ − θ∗, û⟩ ≥ 0 ⇐⇒ ⟨ θ̂ − θ∗, û
β − θ∗ + θ∗
⟩ ≥ 0
=⇒ ⟨θ̂,θ∗⟩",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
≥ 1− ∥θ̂,4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"− θ∗∥2 · sup v∈AK∪{0}
⟨ v, û
β − θ∗ ⟩",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"In order to bound the supremum above, we use the result from generic chaining.",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"We define the stochastic process {Zv = ⟨v, û/β − θ∗⟩}v∈AK∪{0}.",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"First, we need to check the process has sub-Gaussian incremental.",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"For simplicity, we denote u ((xi1 , yi1), . . .",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
", (xim , yim)) by ui1,...,im .",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"By the definitions and properties of sub-Gaussian norm (Vershynin, 2012), it is not difficult to show that ∥⟨ui1,...,im ,v −w⟩∥ψ2 ≤",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"κm · ∥v −w∥2 for any v,w ∈ AK ∪ {0}.",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"By Lemma 2, we have
P (|Zv",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"− Zw| > δ) ≤ 2 exp ( −C ′ · nβ 2δ2
m3κ2 · ∥v −w∥22
) .
",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
Therefore we can conclude that {Zv} has sub-Gaussian incremental w.r.t.,4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"the metric s(v,w) , κm 32 ·",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
∥v − w∥2/β √ n.,4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"Now applying Lemma 3 to {Zv} with a bit calculation, we can obtain
P (
sup v∈AK∪{0}
|Zv| ≥ C1κm
3 2
β √ n
· ( γ2 (AK ∪ {0}, ∥ · ∥2)
+ 2δ ))",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"≤ C2 exp ( −δ2 ) Using γ2 (AK ∪ {0}, ∥ · ∥2) ≤",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
C0 ·w (AK ∪ {0}) implied by Lemma 4 and taking δ = w,4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"(AK ∪ {0}), we get
sup v∈AK∪{0}
⟨ v, û
β − θ∗
⟩ ≤",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"C3κm 3 2
β · w",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
(AK) + C4√,4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"n
with probability at least 1 − C2 exp ( −w2 (AK) ) .",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
The inequality also uses the fact that w (AK ∪ {0}) ≤,4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"w (AK) +
C4, which is a result of Lemma 2 in Maurer et al. (2014) (See Lemma A in supplementary material).",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"Lastly we turn to the quantity ∥θ̂ − θ∗∥2,
∥θ̂",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"− θ∗∥2 ≤ √ 2− 2⟨θ̂,θ∗⟩ ≤ 2C3κm 3 2
β · w (AK) + C4√",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"n .
",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"We finish the proof by letting C = 2C3, C ′ = C4 and C ′′ = C2.",4. Lemmas and Proof Sketch of Theorem 1,[0],[0]
"In the experiment, we focus on model (3) with sparse θ∗.",5. Experiment,[0],[0]
"The problem dimension is fixed as p = 1000, and the sparsity of θ∗ is set to 10.",5. Experiment,[0],[0]
"Essentially we generate our data (x, y) from
y = f̃ (⟨θ∗,x⟩+ ϵ) ,
where x ∼ N (0, I) and ϵ",5. Experiment,[0],[0]
"∼ N (0, σ2).",5. Experiment,[0],[0]
σ ranges from 0.3 to 1.5.,5. Experiment,[0],[0]
"We choose three monotonically increasing f̃ , f̃(z) = 1/(1 + exp(−z)) (which is bounded and Lipschitz), f̃(z) = z3 (which is unbounded and non-Lipschitz), and f̃(z) = log(1 + exp(z)) (which is unbounded but Lipschitz).",5. Experiment,[0],[0]
The sample size n varies from 200 to 1000.,5. Experiment,[0],[0]
We use the estimator (23) in Section 3.,5. Experiment,[0],[0]
"The baselines we compare with is the SILO and iSILO algorithm introduced in (Ganti et al., 2015).",5. Experiment,[0],[0]
SILO does not quite take the monotonicity in account.,5. Experiment,[0],[0]
"In fact, it is the special case of our generalized constrained estimator which uses the same choice of u as 1-bit CS.",5. Experiment,[0],[0]
"The original SILO use the constraint set {θ | ∥θ∥1 ≤ √ s, ∥θ∥2 ≤ 1}, which is computationally less efficient and statistically no better than K = {θ | ∥θ∥0 ≤ s} ∩",5. Experiment,[0],[0]
"Sp−1 (Zhang et al., 2014; Chen & Banerjee, 2015a).",5. Experiment,[0],[0]
Hence we also use K in SILO for a fair comparison.,5. Experiment,[0],[0]
iSILO relies on a specific implementation of isotonic regression which explicitly restricts the Lipschitz constant of f̃ to be one.,5. Experiment,[0],[0]
"To fit iSILO into our setting, we remove the Lipschitzness constraint and perform the standard isotonic regression.",5. Experiment,[0],[0]
"Since the convergence is not guaranteed for the iterative procedure of iSILO, the number of its iterations is fixed to 100.",5. Experiment,[0],[0]
"The best tuning parameter of iSILO is obtained by grid search.
",5. Experiment,[0],[0]
The experiment results are shown in Figure 1.,5. Experiment,[0],[0]
"Overall the iSILO algorithm works well under small noise, while our estimator has better performance when the variance of noise increases.",5. Experiment,[0],[0]
"To better demonstrate the robustness of our estimator to heavy-tailed noise, instead of Gaussian noise, we sample ϵ",5. Experiment,[0],[0]
from the Student’s t distribution with degrees of freedom equal to 3.,5. Experiment,[0],[0]
"We repeat the experiments for f̃(z) = z3, and obtain the plots in Figure 2.",5. Experiment,[0],[0]
We can see that the error of our estimator consistently decreases for all choice of σ as n increases.,5. Experiment,[0],[0]
"For SILO and iSILO, the errors are relatively large, and unable to shrink for large σ even when more data are provided.",5. Experiment,[0],[0]
"In this paper, we study the parameter estimation for the high-dimensional single-index models.",6. Conclusion,[0],[0]
"We propose two classes of robust estimators, which generalize previous works in two aspects.",6. Conclusion,[0],[0]
"First we allow the diverse structure (e.g., binary, monotone and etc.) of the transfer function, which can help us customize the estimators.",6. Conclusion,[0],[0]
"Secondly the structure of the true parameter can be general, either encoded by a constraint or a norm.",6. Conclusion,[0],[0]
"With limited assumption on the noise, we can show that the estimation error can be bounded by simple geometric measures under Gaussian
measurement, which subsumes the existing results for specific settings.",6. Conclusion,[0],[0]
The experiment results also validate our theoretical analyses.,6. Conclusion,[0],[0]
We thank Sreangsu Acharyya for helpful discussions related to the paper.,Acknowledgements,[0],[0]
"The research was supported by NSF grants IIS-1563950, IIS-1447566, IIS-1447574, IIS1422557, CCF-1451986, CNS- 1314560, IIS-0953274, IIS-1029711, NASA grant NNX12AQ39A, and gifts from Adobe, IBM, and Yahoo.",Acknowledgements,[0],[0]
"In this paper, we investigate general single-index models (SIMs) in high dimensions.",abstractText,[0],[0]
"Based on U -statistics, we propose two types of robust estimators for the recovery of model parameters, which can be viewed as generalizations of several existing algorithms for one-bit compressed sensing (1-bit CS).",abstractText,[0],[0]
"With minimal assumption on noise, the statistical guarantees are established for the generalized estimators under suitable conditions, which allow general structures of underlying parameter.",abstractText,[0],[0]
"Moreover, the proposed estimator is novelly instantiated for SIMs with monotone transfer function, and the obtained estimator can better leverage the monotonicity.",abstractText,[0],[0]
Experimental results are provided to support our theoretical analyses.,abstractText,[0],[0]
Robust Structured Estimation with Single-Index Models,title,[0],[0]
"p k).
In this paper, we solve a key open problem raised therein, presenting a new Partitioned Robust (PRO) submodular maximization algorithm that achieves the same guarantee for more general ⌧ = o(k). Our algorithm constructs partitions consisting of buckets with exponentially increasing sizes, and applies standard submodular optimization subroutines on the buckets in order to construct the robust solution. We numerically demonstrate the performance of PRO in data summarization and influence maximization, demonstrating gains over both the greedy algorithm and the algorithm of (Orlin et al., 2016).",text,[0],[0]
"Discrete optimization problems arise frequently in machine learning, and are often NP-hard even to approximate.",1. Introduction,[0],[0]
"In the case of a set function exhibiting submodularity, one can efficiently perform maximization subject to cardinality constraints with a 1 1
e
-factor approximation guarantee.",1. Introduction,[0],[0]
"Ap-
plications include influence maximization (Kempe et al., 2003), document summarization (Lin & Bilmes, 2011), sensor placement (Krause & Guestrin, 2007), and active learning (Krause & Golovin, 2012), just to name a few.
1LIONS, EPFL, Switzerland 2LTHC, EPFL, Switzerland.",1. Introduction,[0],[0]
"Correspondence to: Ilija Bogunovic <ilija.bogunovic@epfl.ch>, Slobodan Mitrović <slobodan.mitrovic@epfl.ch>, Jonathan Scarlett <jonathan.scarlett@epfl.ch>, Volkan Cevher <volkan.cevher@epfl.ch>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"In many applications of interest, one requires robustness in the solution set returned by the algorithm, in the sense that the objective value degrades as little as possible when some elements of the set are removed.",1. Introduction,[0],[0]
"For instance, (i) in influence maximization problems, a subset of the chosen users may decide not to spread the word about a product; (ii) in summarization problems, a user may choose to remove some items from the summary due to their personal preferences; (iii) in the problem of sensor placement for outbreak detection, some of the sensors might fail.
",1. Introduction,[0],[0]
"In situations where one does not have a reasonable prior distribution on the elements removed, or where one requires robustness guarantees with a high level of certainty, protecting against worst-case removals becomes important.",1. Introduction,[0],[0]
"This setting results in the robust submodular function maximization problem, in which we seek to return a set of cardinality k that is robust with respect to the worst-case removal of ⌧ elements.
",1. Introduction,[0],[0]
"The robust problem formulation was first introduced in (Krause et al., 2008), and was further studied in (Orlin et al., 2016).",1. Introduction,[0],[0]
"In fact, (Krause et al., 2008) considers a more general formulation where a constant-factor approximation guarantee is impossible in general, but shows that one can match the optimal (robust) objective value for a given set size at the cost of returning a set whose size is larger by a logarithmic factor.",1. Introduction,[0],[0]
"In contrast, (Orlin et al., 2016) designs an algorithm that obtains the first constant-factor approximation guarantee to the above problem when ⌧ = o( p k).",1. Introduction,[0],[0]
"A key difference between the two frameworks is that the algorithm complexity is exponential in ⌧ in (Krause et al., 2008), whereas the algorithm of (Orlin et al., 2016) runs in polynomial time.
",1. Introduction,[0],[0]
Contributions.,1. Introduction,[0],[0]
"In this paper, we solve a key open problem posed in (Orlin et al., 2016), namely, whether a constantfactor approximation guarantee is possible for general ⌧ = o(k), as opposed to only ⌧ = o( p k).",1. Introduction,[0],[0]
"We answer this question in the affirmative, providing a new Partitioned Robust (PRO) submodular maximization algorithm that attains a constant-factor approximation guarantee; see Table 1 for comparison of different algorithms for robust monotone submodular optimization with a cardinality constraint.
",1. Introduction,[0],[0]
"Achieving this result requires novelty both in the algorithm and its mathematical analysis: While our algorithm bears some similarity to that of (Orlin et al., 2016), it uses a novel structure in which the constructed set is arranged into partitions consisting of buckets whose sizes increase exponentially with the partition index.",1. Introduction,[0],[0]
"A key step in our analysis provides a recursive relationship between the objective values attained by buckets appearing in adjacent partitions.
",1. Introduction,[0],[0]
"In addition to the above contributions, we provide the first empirical study beyond what is demonstrated for ⌧ = 1 in (Krause et al., 2008).",1. Introduction,[0],[0]
"We demonstrate several scenarios in which our algorithm outperforms both the greedy algorithm and the algorithm of (Orlin et al., 2016).",1. Introduction,[0],[0]
"Let V be a ground set with cardinality |V | = n, and let",2. Problem Statement,[0],[0]
f : 2V !,2. Problem Statement,[0],[0]
R 0 be a set function defined on V .,2. Problem Statement,[0],[0]
"The function f is said to be submodular if for any sets X ✓ Y ✓ V and any element e 2 V \ Y , it holds that
f(X [ {e}) f(X) f(Y",2. Problem Statement,[0],[0]
[ {e}) f(Y ).,2. Problem Statement,[0],[0]
"We use the following notation to denote the marginal gain in the function value due to adding the elements of a set Y to the set X:
f(Y |X) := f(X [ Y ) f(X).",2. Problem Statement,[0],[0]
"In the case that Y is a singleton of the form {e}, we adopt the shorthand f(e|X).",2. Problem Statement,[0],[0]
"We say that f is monotone if for any sets X ✓ Y ✓ V we have f(X)  f(Y ), and normalized if f(;) = 0.",2. Problem Statement,[0],[0]
"The problem of maximizing a normalized monotone submodular function subject to a cardinality constraint, i.e.,
max S✓V,|S|k f(S), (1)
has been studied extensively.",2. Problem Statement,[0],[0]
"A celebrated result of (Nemhauser et al., 1978) shows that a simple greedy algorithm that starts with an empty set and then iteratively adds elements with highest marginal gain provides a (1 1/e)-approximation.
",2. Problem Statement,[0],[0]
"In this paper, we consider the following robust version of (1), introduced in (Krause et al., 2008):
max S✓V,|S|k min Z✓S,|Z|⌧
f(S \ Z) (2)
We refer to ⌧ as the robustness parameter, representing the size of the subset Z that is removed from the selected set S. Our goal is to find a set S such that it is robust upon the worst possible removal of ⌧ elements, i.e., after the removal, the objective value should remain as large as possible.",2. Problem Statement,[0],[0]
"For ⌧ = 0, our problem reduces to Problem (1).
",2. Problem Statement,[0],[0]
"The greedy algorithm, which is near-optimal for Problem (1) can perform arbitrarily badly for Problem (2).",2. Problem Statement,[0],[0]
"As an elementary example, let us fix ✏ 2 [0, n 1) and n 0, and consider the non-negative monotone submodular function given in Table 2.",2. Problem Statement,[0],[0]
"For k = 2, the greedy algorithm selects {s1, s2}.",2. Problem Statement,[0],[0]
"The set that maximizes mins2S f(S\s) (i.e., ⌧ = 1) is {s1, s3}.",2. Problem Statement,[0],[0]
"For this set, min
s2{s 1 ,s 2 } f({s1, s2} \ s) = n 1, while for the greedy set the robust objective value is ✏.",2. Problem Statement,[0],[0]
"As a result, the greedy algorithm can perform arbitrarily worse.
",2. Problem Statement,[0],[0]
"In our experiments on real-world data sets (see Section 5), we further explore the empirical behavior of the greedy solution in the robust setting.",2. Problem Statement,[0],[0]
"Among other things, we observe that the greedy solution tends to be less robust when the objective value largely depends on the first few elements selected by the greedy rule.
",2. Problem Statement,[0],[0]
Related work.,2. Problem Statement,[0],[0]
"(Krause et al., 2008) introduces the following generalization of (2):
max S✓V,|S|k min i2{1,··· ,n} f i (S), (3)
",2. Problem Statement,[0],[0]
where f i are normalized monotone submodular functions.,2. Problem Statement,[0],[0]
"The authors show that this problem is inapproximable in general, but propose an algorithm SATURATE which, when applied to (2), returns a set of size k(1+⇥(log(⌧k log n)))",2. Problem Statement,[0],[0]
whose robust objective is at least as good as the optimal size-k set.,2. Problem Statement,[0],[0]
"SATURATE requires a number of function evaluations that is exponential in ⌧ , making it very expensive to run even for small values.",2. Problem Statement,[0],[0]
"The work of (Powers et al., 2016) considers the same problem for different types of submodular constraints.
",2. Problem Statement,[0],[0]
"Recently, robust versions of submodular maximization have been applied to influence maximization.",2. Problem Statement,[0],[0]
"In (He & Kempe, 2016), the formulation (3) is used to optimize a worst-case approximation ratio.",2. Problem Statement,[0],[0]
"The confidence interval setting is considered in (Chen et al., 2016), where two runs of the GREEDY algorithm (one pessimistic and one optimistic) are used to optimize the same ratio.",2. Problem Statement,[0],[0]
"By leveraging connections to continuous submodular optimization, (Staib & Jegelka, 2017) studies a related continuous robust budget allocation problem.
",2. Problem Statement,[0],[0]
"(Orlin et al., 2016) considers the formulation in (2), and provides the first constant 0.387-factor approximation result, valid for ⌧ = o( p k).",2. Problem Statement,[0],[0]
"The algorithm proposed therein, which we refer to via the authors surnames as OSU, uses the greedy algorithm (henceforth referred to as GREEDY) as a sub-routine ⌧ +1 times.",2. Problem Statement,[0],[0]
"On each iteration, GREEDY is applied on the elements that are not yet selected on previous iterations, with these previously-selected elements ignored in the objective function.",2. Problem Statement,[0],[0]
"In the first ⌧ runs, each solution is of size ⌧ log k, while in the last run, the solution is of size k ⌧2 log k.",2. Problem Statement,[0],[0]
The union of all the obtained disjoint solutions leads to the final solution set.,2. Problem Statement,[0],[0]
"In this section, we provide several examples of applications where the robustness of the solution is favorable.",3. Applications,[0],[0]
"The objective functions in these applications are non-negative, monotone and submodular, and are used in our numerical experiments in Section 5.
",3. Applications,[0],[0]
Robust influence maximization.,3. Applications,[0],[0]
"The goal in the influence maximization problem is to find a set of k nodes (i.e., a targeted set) in a network that maximizes some measure of influence.",3. Applications,[0],[0]
"For example, this problem appears in viral marketing, where companies wish to spread the word of a new product by targeting the most influential individuals in a social network.",3. Applications,[0],[0]
"Due to poor incentives or dissatisfaction with the product, for instance, some of the users from the
targeted set might make the decision not to spread the word about the product.
",3. Applications,[0],[0]
"For many of the existing diffusion models used in the literature (e.g., see (Kempe et al., 2003)), given the targeted set S, the expected number of influenced nodes at the end of the diffusion process is a monotone and submodular function of S (He & Kempe, 2016).",3. Applications,[0],[0]
"For simplicity, we consider a basic model in which all of the neighbors of the users in S become influenced, as well as those in S itself.
",3. Applications,[0],[0]
"More formally, we are given a graph G = (V,E), where V stands for nodes and E are the edges.",3. Applications,[0],[0]
"For a set S, let N (S) denote all of its neighboring nodes.",3. Applications,[0],[0]
"The goal is to solve the robust dominating set problem, i.e., to find a set of nodes S of size k that maximizes
min |RS |⌧,RS✓S
|(S \R S )",3. Applications,[0],[0]
"[N (S \R S )|, (4)
where R S ✓ S represents the users that decide not to spread the word.",3. Applications,[0],[0]
"The non-robust version of this objective function has previously been considered in several different works, such as (Mirzasoleiman et al., 2015b) and (NorouziFard et al., 2016).
",3. Applications,[0],[0]
Robust personalized image summarization.,3. Applications,[0],[0]
"In the personalized image summarization problem, a user has a collection of images, and the goal is to find k images that are representative of the collection.
",3. Applications,[0],[0]
"After being presented with a solution, the user might decide to remove a certain number of images from the representative set due to various reasons (e.g., bad lighting, motion blur, etc.).",3. Applications,[0],[0]
"Hence, our goal is to find a set of images that remain good representatives of the collection even after the removal of some number of them.
",3. Applications,[0],[0]
"One popular way of finding a representative set in a massive dataset is via exemplar based clustering, i.e., by minimizing the sum of pairwise dissimilarities between the exemplars S and the elements of the data set V .",3. Applications,[0],[0]
"This problem can be posed as a submodular maximization problem subject to a cardinality constraint; cf., (Lucic et al., 2016).
",3. Applications,[0],[0]
"Here, we are interested in solving the robust summarization problem, i.e., we want to find a set of images S of size k that maximizes
min |RS |⌧,RS✓S
f({e0}) f((S \RS)",3. Applications,[0],[0]
"[ {e0}), (5)
where e0 is a reference element and f(S) = 1
|V | P
v2V mins2S d(s, v) is the k-medoid loss function, and where d(s, v) measures the dissimilarity between images s and v.
Further potential applications not covered here include robust sensor placement (Krause et al., 2008), robust protection of networks (Bogunovic & Krause, 2012), and robust feature selection (Globerson & Roweis, 2006).",3. Applications,[0],[0]
"Our algorithm, which we call the Partitioned Robust (PRO) submodular maximization algorithm, is presented in Algorithm 1.",4.1. The algorithm,[0],[0]
"As the input, we require a non-negative monotone submodular function f : 2V !",4.1. The algorithm,[0],[0]
"R 0, the ground set of elements V , and an optimization subroutine A.",4.1. The algorithm,[0],[0]
"The subroutine A(k0, V 0) takes a cardinality constraint k0 and a ground set of elements V 0.",4.1. The algorithm,[0],[0]
"Below, we describe the properties of A that are used to obtain approximation guarantees.
",4.1. The algorithm,[0],[0]
The output of the algorithm is a set S ✓ V of size k that is robust against the worst-case removal of ⌧ elements.,4.1. The algorithm,[0],[0]
"The returned set consists of two sets S0 and S1, illustrated in Figure 1.",4.1. The algorithm,[0],[0]
"S1 is obtained by running the subroutine A on V \ S0 (i.e., ignoring the elements already placed into S0), and is of size k |S0|.",4.1. The algorithm,[0],[0]
"We refer to the set S0 as the robust part of the solution set S. It consists of dlog ⌧e + 1 partitions, where every partition i 2 {0, · · · , dlog ⌧e} consists of d⌧/2ie buckets B
j , j 2 {1, · · · , d⌧/2ie}.",4.1. The algorithm,[0],[0]
"In partition i, every bucket contains 2i⌘ elements, where ⌘ 2 N+ is a parameter that is arbitrary for now; we use ⌘ = log2 k in our asymptotic theory, but our numerical studies indicate that even ⌘ = 1 works well in practice.",4.1. The algorithm,[0],[0]
"Each bucket B
j is created afresh by using the subroutine A on V \ S0,prev, where S0,prev contains all elements belonging to the previous buckets.
",4.1. The algorithm,[0],[0]
"The following proposition bounds the cardinality of S0, and is proved in the supplementary material.
",4.1. The algorithm,[0],[0]
Proposition 4.1 Fix k ⌧ and ⌘ 2 N+.,4.1. The algorithm,[0],[0]
"The size of the robust part S0 constructed in Algorithm 1 is
|S0| = dlog ⌧eX
i=0
d⌧/2ie2i⌘  3⌘⌧(log k + 2).
",4.1. The algorithm,[0],[0]
"This proposition reveals that the feasible values of ⌧ (i.e., those with |S0|  k) can be as high as O k
⌘⌧
.",4.1. The algorithm,[0],[0]
"We will
later set ⌘ = O(log2 k), thus permitting all ⌧ = o(k) up to a few logarithmic factors.",4.1. The algorithm,[0],[0]
"In contrast, we recall that the algorithm OSU proposed in (Orlin et al., 2016) adopts a simpler approach where a robust set is used consisting of ⌧ buckets of equal size ⌧ log k, thereby only permitting the scaling ⌧ = o",4.1. The algorithm,[0],[0]
"( p k).
",4.1. The algorithm,[0],[0]
"We provide the following intuition as to why PRO succeeds despite having a smaller size for S0 compared to the algorithm given in (Orlin et al., 2016).",4.1. The algorithm,[0],[0]
"First, by the design of the partitions, there always exists a bucket in partition i that at most 2i items are removed from.",4.1. The algorithm,[0],[0]
The bulk of our analysis is devoted to showing that the union of these buckets yields a sufficiently high objective value.,4.1. The algorithm,[0],[0]
"While the earlier
Algorithm 1 Partitioned Robust Submodular optimization algorithm (PRO)
Require: Set V , k, ⌧ , ⌘ 2 N+, algorithm A Ensure: Set S ✓ V such that |S|  k
1: S0, S1 ; 2: for i 0 to dlog ⌧e do 3: for j 1 to d⌧/2ie do 4: B
j A (2i⌘, (V \ S0)) 5: S0 S0",4.1. The algorithm,[0],[0]
"[Bj 6: S1 A (k |S0|, (V \ S0)) 7",4.1. The algorithm,[0],[0]
": S S0 [ S1 8: return S
buckets have a smaller size, they also have a higher objective value per item due to diminishing returns, and our analysis quantifies and balances this trade-off.",4.1. The algorithm,[0],[0]
"Similarly, our analysis quantifies the trade-off between how much the adversary can remove from the (typically large) set S1 and the robust part S0.",4.1. The algorithm,[0],[0]
PRO accepts a subroutine A as the input.,4.2. Subroutine and assumptions,[0],[0]
"We consider a class of algorithms that satisfy the -iterative property, defined below.",4.2. Subroutine and assumptions,[0],[0]
"We assume that the algorithm outputs the final set in some specific order (v1, . . .",4.2. Subroutine and assumptions,[0],[0]
", vk), and we refer to vi as the i-th output element.
",4.2. Subroutine and assumptions,[0],[0]
"Definition 4.2 Consider a normalized monotone submodular set function f on a ground set V , and an algorithm A.",4.2. Subroutine and assumptions,[0],[0]
"Given any set T ✓ V and size k, suppose that A outputs an ordered set (v1, . . .",4.2. Subroutine and assumptions,[0],[0]
", vk) when applied to T , and define A
i (T ) = {v1, . . .",4.2. Subroutine and assumptions,[0],[0]
", vi} for i  k.",4.2. Subroutine and assumptions,[0],[0]
"We say that A satisfies the -iterative property if
f(A i+1(T ))",4.2. Subroutine and assumptions,[0],[0]
f(Ai(T )),4.2. Subroutine and assumptions,[0],[0]
"1
max v2T
f(v|A i (T )).",4.2. Subroutine and assumptions,[0],[0]
"(6)
Intuitively, (6) states that in every iteration, the algorithm adds an element whose marginal gain is at least a 1/ fraction of the maximum marginal.",4.2. Subroutine and assumptions,[0],[0]
This necessarily requires that 1.,4.2. Subroutine and assumptions,[0],[0]
Examples.,4.2. Subroutine and assumptions,[0],[0]
"Besides the classic greedy algorithm, which satisfies (6) with = 1, a good candidate for our subroutine is THRESHOLDING-GREEDY (Badanidiyuru & Vondrák, 2014), which satisfies the -iterative property with = 1/(1 ✏).",4.2. Subroutine and assumptions,[0],[0]
This decreases the number of function evaluations to O(n/✏ log n/✏).,4.2. Subroutine and assumptions,[0],[0]
"STOCHASTIC-GREEDY (Mirzasoleiman et al., 2015a) is another potential subroutine candidate.",4.2. Subroutine and assumptions,[0],[0]
"While it is unclear whether this algorithm satisfies the -iterative property, it requires an even smaller number of function eval-
uations, namely, O(n log 1/✏).",4.2. Subroutine and assumptions,[0],[0]
We will see in Section 5 that PRO performs well empirically when used with this subroutine.,4.2. Subroutine and assumptions,[0],[0]
"We henceforth refer to PRO used along with its appropriate subroutine as PRO-GREEDY, PRO-THRESHOLDING-GREEDY, and so on.
Properties.",4.2. Subroutine and assumptions,[0],[0]
"The following lemma generalizes a classical property of the greedy algorithm (Nemhauser et al., 1978; Krause & Golovin, 2012) to the class of algorithms satisfying the -iterative property.",4.2. Subroutine and assumptions,[0],[0]
"Here and throughout the paper, we use OPT(k, V ) to denote the following optimal set for non-robust maximization:
OPT(k, V ) 2 argmax S✓V,|S|=k f(S),
Lemma 4.3 Consider a normalized monotone submodular function f : 2V !",4.2. Subroutine and assumptions,[0],[0]
"R 0 and an algorithm A(T ), T ✓ V , that satisfies the -iterative property in (6).",4.2. Subroutine and assumptions,[0],[0]
"Let A
l (T ) denote the set returned by the algorithm A(T ) after l iterations.",4.2. Subroutine and assumptions,[0],[0]
"Then for all k, l 2 N+
f(A l (T )) ⇣ 1 e l k ⌘ f(OPT(k, T )).",4.2. Subroutine and assumptions,[0],[0]
"(7)
We will also make use of the following property, which is implied by the -iterative property.
",4.2. Subroutine and assumptions,[0],[0]
Proposition 4.4 Consider a submodular set function f : 2V !,4.2. Subroutine and assumptions,[0],[0]
R 0 and an algorithm A that satisfies the - iterative property for some 1.,4.2. Subroutine and assumptions,[0],[0]
"Then, for any T ✓ V and element e 2 V \ A(T ), we have
f(e|A(T ))  f(A(T ))",4.2. Subroutine and assumptions,[0],[0]
k .,4.2. Subroutine and assumptions,[0],[0]
"(8)
Intuitively, (8) states that the marginal gain of any nonselected element cannot be more than times the average objective value of the selected elements.",4.2. Subroutine and assumptions,[0],[0]
"This is one of the rules used to define the -nice class of algorithms in (Mirrokni & Zadimoghaddam, 2015); however, we note that in general, neither the -nice nor -iterative classes are a subset of one another.",4.2. Subroutine and assumptions,[0],[0]
"For the robust maximization problem, we let OPT(k, V, ⌧) denote the optimal set:
OPT(k, V, ⌧) 2 argmax S✓V,|S|=k min E✓S,|E|⌧ f(S \ E).
",4.3. Main result: Approximation guarantee,[0],[0]
"Moreover, for a set S, we let E⇤ S denote the minimizer
E⇤ S 2 argmin E✓S,|E|⌧ f(S \ E).",4.3. Main result: Approximation guarantee,[0],[0]
"(9)
With these definitions, the main theoretical result of this paper is as follows.
",4.3. Main result: Approximation guarantee,[0],[0]
"Theorem 4.5 Let f be a normalized monotone submodular function, and let A be a subroutine satisfying the - iterative property.",4.3. Main result: Approximation guarantee,[0],[0]
"For a given budget k and parameters 2  ⌧  k3⌘(log k+2) and ⌘ 4(log k + 1), PRO returns a set S of size k such that
f(S",4.3. Main result: Approximation guarantee,[0],[0]
"\ E⇤ S
) ⌘ 5 3dlog ⌧e+⌘
⇣ 1 e k |S0| (k ⌧) ⌘
1 + ⌘5 3dlog ⌧e+⌘
⇣ 1 e k |S0| (k ⌧) ⌘
⇥ f(OPT(k, V, ⌧) \",4.3. Main result: Approximation guarantee,[0],[0]
"E⇤OPT(k,V,⌧)), (10) where E⇤
S and E⇤OPT(k,V,⌧) are defined as in (9).
",4.3. Main result: Approximation guarantee,[0],[0]
"In addition, if ⌧ = o ⇣ k
⌘ log k
⌘ and ⌘ log2 k, then we
have the following as k !1:
f(S",4.3. Main result: Approximation guarantee,[0],[0]
\ E⇤ S ),4.3. Main result: Approximation guarantee,[0],[0]
"✓ 1 e 1/ 2 e 1/ + o(1) ◆
⇥ f(OPT(k, V, ⌧)",4.3. Main result: Approximation guarantee,[0],[0]
\,4.3. Main result: Approximation guarantee,[0],[0]
"E⇤OPT(k,V,⌧)).",4.3. Main result: Approximation guarantee,[0],[0]
"(11) In particular, PRO-GREEDY achieves an asymptotic approximation factor of at least 0.387, and PROTHRESHOLDING-GREEDY with parameter ✏ achieves an asymptotic approximation factor of at least 0.387(1 ✏).
",4.3. Main result: Approximation guarantee,[0],[0]
"This result solves an open problem raised in (Orlin et al., 2016), namely, whether a constant-factor approximation guarantee can be obtained for ⌧ = o(k) as opposed to
only ⌧ = o p k .",4.3. Main result: Approximation guarantee,[0],[0]
"In the asymptotic limit, our constant factor of 0.387 for the greedy subroutine matches that of (Orlin et al., 2016), but our algorithm permits significantly “higher robustness” in the sense of allowing larger ⌧ values.",4.3. Main result: Approximation guarantee,[0],[0]
"To achieve this, we require novel proof techniques, which we now outline.",4.3. Main result: Approximation guarantee,[0],[0]
The proof of Theorem 4.5 is provided in the supplementary material.,4.4. High-level overview of the analysis,[0],[0]
"Here we provide a high-level overview of the main challenges.
",4.4. High-level overview of the analysis,[0],[0]
Let E denote a cardinality-⌧ subset of the returned set S that is removed.,4.4. High-level overview of the analysis,[0],[0]
"By the construction of the partitions, it is easy to verify that each partition i contains a bucket from which at most 2i items are removed.",4.4. High-level overview of the analysis,[0],[0]
"We denote these by B0, . . .",4.4. High-level overview of the analysis,[0],[0]
", Bdlog ⌧e, and write EBi := E \Bi.",4.4. High-level overview of the analysis,[0],[0]
"Moreover, we define E0 := E \ S0 and E1 := E \ S1.",4.4. High-level overview of the analysis,[0],[0]
"We establish the following lower bound on the final objective function value:
f(S \E) max ⇢ f(S0 \E0), f(S1) f(E1|(S \E)),
f
✓ dlog ⌧e[
i=0
(B i \ E Bi)
◆ .",4.4. High-level overview of the analysis,[0],[0]
"(12)
",4.4. High-level overview of the analysis,[0],[0]
"The arguments to the first and third terms are trivially seen to be subsets of S \ E, and the second term represents the utility of the set S1 subsided by the utility of the elements removed from S1.
",4.4. High-level overview of the analysis,[0],[0]
The first two terms above are easily lower bounded by convenient expressions via submodular and the -iterative property.,4.4. High-level overview of the analysis,[0],[0]
The bulk of the proof is dedicated to bounding the third term.,4.4. High-level overview of the analysis,[0],[0]
"To do this, we establish the following recursive relations with suitably-defined “small” values of ↵
j
:
f
j[
i=0
(B i \ E Bi)
!",4.4. High-level overview of the analysis,[0],[0]
"1 1
1 + 1 ↵j
!",4.4. High-level overview of the analysis,[0],[0]
"f(B
j
)
f E
Bj
j 1",4.4. High-level overview of the analysis,[0],[0]
"[
i=0
(B i \ E Bi)
!  ",4.4. High-level overview of the analysis,[0],[0]
"↵
j
f
j 1[
i=0
(B i \ E Bi)
! .
",4.4. High-level overview of the analysis,[0],[0]
"Intuitively, the first equation shows that the objective value from buckets i = 0, . . .",4.4. High-level overview of the analysis,[0],[0]
", j with removals cannot be too much smaller than the objective value in bucket j without removals, and the second equation shows that the loss in bucket j due to the removals is at most a small fraction of the objective value from buckets 0, . . .",4.4. High-level overview of the analysis,[0],[0]
",",4.4. High-level overview of the analysis,[0],[0]
j 1.,4.4. High-level overview of the analysis,[0],[0]
"The proofs of both the base case of the induction and the inductive step make use of submodularity properties and the -iterative property (cf., Definition 4.2).
",4.4. High-level overview of the analysis,[0],[0]
"Once the suitable lower bounds are obtained for the terms in (12), the analysis proceeds similarly to (Orlin et al.,
2016).",4.4. High-level overview of the analysis,[0],[0]
"Specifically, we can show that as the second term increases, the third term decreases, and accordingly lower bound their maximum by the value obtained when the two are equal.",4.4. High-level overview of the analysis,[0],[0]
"A similar balancing argument is then applied to the resulting term and the first term in (12).
",4.4. High-level overview of the analysis,[0],[0]
"The condition ⌧  k3⌘(log k+2) follows directly from Proposition 4.1; namely, it is a sufficient condition for |S0|  k, as is required by PRO.",4.4. High-level overview of the analysis,[0],[0]
"In this section, we numerically validate the performance of PRO and the claims given in the preceding sections.",5. Experiments,[0],[0]
"In particular, we compare our algorithm against the OSU algorithm proposed in (Orlin et al., 2016) on different datasets and corresponding objective functions (see Table 3).",5. Experiments,[0],[0]
"We demonstrate matching or improved performance in a broad range of settings, as well as observing that PRO can be implemented with larger values of ⌧ , corresponding to a greater robustness.",5. Experiments,[0],[0]
"Moreover, we show that for certain realworld data sets, the classic GREEDY algorithm can perform badly for the robust problem.",5. Experiments,[0],[0]
"We do not compare against SATURATE (Krause et al., 2008), due to its high computational cost for even a small ⌧ .
Setup.",5. Experiments,[0],[0]
"Given a solution set S of size k, we measure the performance in terms of the minimum objective value upon the worst-case removal of ⌧ elements, i.e. min
Z✓S,|Z|⌧ f(S\ Z).",5. Experiments,[0],[0]
"Unfortunately, for a given solution set S, finding such a set Z is an instance of the submodular minimization problem with a cardinality constraint,1 which is known to be NP-hard with polynomial approximation factors (Svitkina & Fleischer, 2011).",5. Experiments,[0],[0]
"Hence, in our experiments, we only implement the optimal “adversary” (i.e., removal of items) for small to moderate values of ⌧ and k, for which we use a fast C++ implementation of branch-and-bound.
",5. Experiments,[0],[0]
"Despite the difficulty in implementing the optimal adversary, we observed in our experiments that the greedy adversary, which iteratively removes elements to reduce the objective value as much as possible, has a similar impact on the objective compared to the optimal adversary for the data sets considered.",5. Experiments,[0],[0]
"Hence, we also provide a larger-scale experiment in the presence of a greedy adversary.",5. Experiments,[0],[0]
"Throughout, we write OA and GA to abbreviate the optimal adversary and greedy adversary, respectively.
",5. Experiments,[0],[0]
"In our experiments, the size of the robust part of the solution set (i.e., |S0|) is set to ⌧2 and ⌧ log ⌧ for OSU and PRO, respectively.",5. Experiments,[0],[0]
"That is, we set ⌘ = 1 in PRO, and similarly ignore constant and logarithmic factors in OSU, since both appear to be unnecessary in practice.",5. Experiments,[0],[0]
"We show
1This can be seen by noting that for submodular f and any Z ✓ X ✓ V , f 0(Z) = f(X \ Z) remains submodular.
both the “raw” objective values of the solutions, as well as the objective values after the removal of ⌧ elements.",5. Experiments,[0],[0]
"In all experiments, we implement GREEDY using the LAZYGREEDY implementation given in (Minoux, 1978).
",5. Experiments,[0],[0]
The objective functions shown in Table 3 are given in Section 3.,5. Experiments,[0],[0]
"For the exemplar objective function, we use d(s, v) = ks vk2, and let the reference element e0 be the zero vector.",5. Experiments,[0],[0]
"Instead of using the whole set V , we approximate the objective by considering a smaller random subset of V for improved computational efficiency.",5. Experiments,[0],[0]
"Since the objective is additively decomposable and bounded, standard concentration bounds (e.g., the Chernoff bound) ensure that the empirical mean over a random subsample can be made arbitrarily accurate.
Data sets.",5. Experiments,[0],[0]
"We consider the following datasets, along with the objective functions given in Section 3:
Results.",5. Experiments,[0],[0]
"In the first set of experiments, we compare PROGREEDY (written using the shorthand PRO-GR in the legend) against GREEDY and OSU on the EGO-FACEBOOK and EGO-TWITTER datasets.",5. Experiments,[0],[0]
"In this experiment, the dominating set selection objective in (4) is considered.",5. Experiments,[0],[0]
Figure 2 (a) and (c) show the results before and after the worst-case removal of ⌧ = 7 elements for different values of k.,5. Experiments,[0],[0]
"In Figure 2 (b) and (d), we show the objective value for fixed k = 50 and k = 100, respectively, while the robustness parameter ⌧ is varied.
",5. Experiments,[0],[0]
"GREEDY achieves the highest raw objective value, followed by PRO-GREEDY and OSU.",5. Experiments,[0],[0]
"However, after the worst-case removal, PRO-GREEDY-OA outperforms both OSU-OA and GREEDY-OA.",5. Experiments,[0],[0]
"In Figure 2 (a) and (b), GREEDY-OA performs poorly due to a high concentration of the objective value on the first few elements selected by GREEDY.",5. Experiments,[0],[0]
"While OSU requires k ⌧2, PRO only requires k ⌧ log ⌧ , and hence it can be run for larger values of ⌧ (e.g., see Figure 2 (b) and (c)).",5. Experiments,[0],[0]
"Moreover, in Figure 2 (a) and (b), we can observe that although PRO uses a smaller number of elements to build the robust part of the solution set, it has better robustness in comparison with OSU.
",5. Experiments,[0],[0]
"In the second set of experiments, we perform the same type of comparisons on the TINY10 and CM-MOLECULES datasets.",5. Experiments,[0],[0]
The exemplar based clustering in (5) is used as the objective function.,5. Experiments,[0],[0]
"In Figure 2 (e) and (h), the robustness parameter is fixed to ⌧ = 7 and ⌧ = 6, respectively, while the cardinality k is varied.",5. Experiments,[0],[0]
"In Figure 2 (f) and (h), the cardinality is fixed to k = 100 and k = 50, respectively, while the robustness parameter ⌧ is varied.
",5. Experiments,[0],[0]
"Again, GREEDY achieves the highest objective value.",5. Experiments,[0],[0]
"On the TINY10 dataset, GREEDY-OA (Figure 2 (e) and (f)) has a large gap between the raw and final objective, but it still slightly outperforms PRO-GREEDY-OA.",5. Experiments,[0],[0]
"This demonstrates that GREEDY can work well in some cases, despite failing in others.",5. Experiments,[0],[0]
We observed that it succeeds here because the objective value is relatively more uniformly spread across the selected elements.,5. Experiments,[0],[0]
"On the same dataset, PRO-GREEDY-OA outperforms OSU-OA.",5. Experiments,[0],[0]
"On our second dataset CM-MOLECULES (Figure 2 (g) and (h)), PROGREEDY-OA achieves the highest robust objective value, followed by OSU-OA and GREEDY-OA.
",5. Experiments,[0],[0]
"In our final experiment (see Figure 2 (i)), we compare the performance of PRO-GREEDY against two instances of PRO-STOCHASTIC-GREEDY with ✏ = 0.01 and ✏ = 0.08 (shortened to PRO-ST in the legend), seeking to understand to what extent using the more efficient stochastic subroutine impacts the performance.",5. Experiments,[0],[0]
We also show the performance of OSU.,5. Experiments,[0],[0]
"In this experiment, we fix k = 100 and vary ⌧ .",5. Experiments,[0],[0]
"We use the greedy adversary instead of the optimal one, since the latter becomes computationally challenging for larger values of ⌧ .
",5. Experiments,[0],[0]
"In Figure 2 (i), we observe a slight decrease in the objective value of PRO-STOCHASTIC-GREEDY due to the stochastic optimization.",5. Experiments,[0],[0]
"On the other hand, the gaps between the robust and non-robust solutions remain similar, or even shrink.",5. Experiments,[0],[0]
"Overall, we observe that at least in this example, the stochastic subroutine does not compromise the quality of the solution too significantly, despite having a lower computational complexity.",5. Experiments,[0],[0]
"We have provided a new Partitioned Robust (PRO) submodular maximization algorithm attaining a constantfactor approximation guarantee for general ⌧ = o(k), thus
resolving an open problem posed in (Orlin et al., 2016).",6. Conclusion,[0],[0]
"Our algorithm uses a novel partitioning structure with partitions consisting of buckets with exponentially decreasing size, thus providing a “robust part” of size O(⌧poly log ⌧).",6. Conclusion,[0],[0]
We have presented a variety of numerical experiments where PRO outperforms both GREEDY and OSU.,6. Conclusion,[0],[0]
"A potentially interesting direction for further research is to understand the linear regime, in which ⌧ = ↵k for some constant ↵ 2 (0, 1), and in particular, to seek a constant-factor guarantee for this regime.
",6. Conclusion,[0],[0]
Acknowledgment.,6. Conclusion,[0],[0]
"This work was supported in part by the European Commission under Grant ERC Future Proof, SNF 200021-146750 and SNF CRSII2-147633, and ‘EPFL Fellows’ (Horizon2020 665667).",6. Conclusion,[0],[0]
"We study the problem of maximizing a monotone submodular function subject to a cardinality constraint k, with the added twist that a number of items ⌧ from the returned set may be removed.",abstractText,[0],[0]
"We focus on the worst-case setting considered in (Orlin et al., 2016), in which a constant-factor approximation guarantee was given for ⌧ = o( p k).",abstractText,[0],[0]
"In this paper, we solve a key open problem raised therein, presenting a new Partitioned Robust (PRO) submodular maximization algorithm that achieves the same guarantee for more general ⌧ = o(k).",abstractText,[0],[0]
"Our algorithm constructs partitions consisting of buckets with exponentially increasing sizes, and applies standard submodular optimization subroutines on the buckets in order to construct the robust solution.",abstractText,[0],[0]
"We numerically demonstrate the performance of PRO in data summarization and influence maximization, demonstrating gains over both the greedy algorithm and the algorithm of (Orlin et al., 2016).",abstractText,[0],[0]
Robust Submodular Maximization:  A Non-Uniform Partitioning Approach,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 264–272, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
264
tant for chatbots if we want them to be believable. Typically, many questionanswer pairs are prepared by hand for achieving consistent responses; however, the creation of such pairs is costly. In this study, our goal is to collect a large number of question-answer pairs for a particular character by using role playbased question-answering in which multiple users play the roles of certain characters and respond to questions by online users. Focusing on two famous characters, we conducted a large-scale experiment to collect question-answer pairs by using real users. We evaluated the effectiveness of role play-based questionanswering and found that, by using our proposed method, the collected pairs lead to good-quality chatbots that exhibit consistent personalities.",text,[0],[0]
"Having a consistent personality is important for chatbots if we want them to be believable (Li et al., 2016; Gordon et al., 2016; Curry and Rieser, 2016; Sugiyama et al., 2017; Akama et al., 2017).",1 Introduction,[0],[0]
"Although neural networkbased methods are emerging for achieving consistent personalities, their quality is not that high (Li et al., 2016).",1 Introduction,[0],[0]
"Therefore, in many systems, question-answer pairs are prepared by hand for consistent responses (Takeuchi et al., 2007; Leuski et al., 2009; Traum et al., 2015).",1 Introduction,[0],[0]
"However, the creation of such pairs is costly.
",1 Introduction,[0],[0]
"In this study, our aim is to collect a large number of question-answer pairs for a particular character by using role play-based questionanswering (Higashinaka et al., 2013a) in which
multiple users play the roles of certain characters and respond to questions by online users.",1 Introduction,[0],[0]
The concept is shown in Figure 1.,1 Introduction,[0],[0]
The main idea is that role players collectively represent a single character and that a question is broadcast via a character to all role players.,1 Introduction,[0],[0]
"In this way, questionanswer pairs can be efficiently collected because there is less burden on people responding, and the entertaining nature of role playing makes people likelier to participate (Ments, 1999).",1 Introduction,[0],[0]
"In a smallscale experiment, Higashinaka et al. found that question-answer pairs of a character can be efficiently collected by multiple users and that users are highly motivated to provide questions and answers.
",1 Introduction,[0],[0]
There were two limitations to their work.,1 Introduction,[0],[0]
"One was that the experiment was conducted using only a small number of people, who were recruited by the authors.",1 Introduction,[0],[0]
"It was not clear if the scheme would work with real users (i.e., users who are not recruited nor paid by researchers).",1 Introduction,[0],[0]
The other limitation was that the applicability of the collected data to the creation of chatbots was not verified.,1 Introduction,[0],[0]
"In their small-scale experiment, the maximum number of question-answer pairs for a character was only about 80.",1 Introduction,[0],[0]
"This was because users were allowed to register any of their favorite characters, resulting in a small amount of data per character.",1 Introduction,[0],[0]
"It was difficult to create a chatbot with such little data.
",1 Introduction,[0],[0]
"In this paper, we tackle these limitations by using role play-based question-answering for collecting question-answer pairs from real users.",1 Introduction,[0],[0]
"Regarding the second limitation, we limited the characters to two famous ones so as to collect a large number of question-answer pairs per character and create workable chatbots.",1 Introduction,[0],[0]
We conducted a subjective evaluation of the chatbots by using human participants.,1 Introduction,[0],[0]
"Our contributions are as follows:
•",1 Introduction,[0],[0]
"We verified that role play-based question-
answering works with real users, collecting a large number of question-answer pairs per character in a short period.
",1 Introduction,[0],[0]
"• We proposed a method to create chatbots from collected question-answer pairs and
verified that it can lead to good-quality chatbots exhibiting consistent personalities.
",1 Introduction,[0],[0]
We first describe our data collection by using role play-based question-answering with real users.,1 Introduction,[0],[0]
"Then, we propose our method for creating chatbots using the collected question-answer pairs.",1 Introduction,[0],[0]
"Next, we describe the experiment we conducted to evaluate the quality of the chatbots by using human participants.",1 Introduction,[0],[0]
"After covering related work, we summarize the paper and mention future work.",1 Introduction,[0],[0]
"To collect a large number of question-answer pairs per character, we focused on two characters: a real person called Max Murai and a fictional character in a novel, Ayase Aragaki.",2 Data collection by real users,[0],[0]
They are popular characters in Japan and have a large number of fans.,2 Data collection by real users,[0],[0]
We created Web sites in their fan communities so that fans could try role play-based questionanswering.,2 Data collection by real users,[0],[0]
We first describe the two characters in more detail and then briefly go over the Web sites.,2 Data collection by real users,[0],[0]
"Finally, we present the statistics of the data and look at the results from several aspects.",2 Data collection by real users,[0],[0]
Max Murai,2.1 Characters,[0],[0]
"His real name is Tomotake Murai
(Max Murai is his stage name).",2.1 Characters,[0],[0]
"Born in 1981, Murai is a CEO of the IT company AppBank but also a YouTuber who specializes in the live coverage of TV games.",2.1 Characters,[0],[0]
"He is known to have a frank personality.
",2.1 Characters,[0],[0]
Ayase Aragaki,2.1 Characters,[0],[0]
"A fictional character in the novel
“Ore no imouto ga konnnai kawaii wakega
nai” (My Little Sister Can’t Be This Cute), which has sold more than five million copies in Japan in its series.",2.1 Characters,[0],[0]
Ayase is not a main character but plays a supporting role.,2.1 Characters,[0],[0]
Her character is often referred to as a “Yandere”.,2.1 Characters,[0],[0]
"According to Wikipedia, Yandere characters are mentally unstable, incredibly deranged, and use extreme violence or brutality as an outlet for their emotions.",2.1 Characters,[0],[0]
"On the Japanese streaming service NICONICO Douga1, each character has a channel for their fans.",2.2 Web sites,[0],[0]
The channel is limited to subscribers.,2.2 Web sites,[0],[0]
"Through the generosity of this service, we were allowed to establish our Web sites for role playbased question-answering on their channels.",2.2 Web sites,[0],[0]
"Murai has more than 10,000 subscribers; the number of subscribes for Ayase is not disclosed.
",2.2 Web sites,[0],[0]
"We opened the Web sites in March and October 2017 for Murai and Ayase, respectively.",2.2 Web sites,[0],[0]
Figures 2 and 3 show screenshots of the sites.,2.2 Web sites,[0],[0]
The appearances of the sites were adjusted to the characters.,2.2 Web sites,[0],[0]
"The users can ask the characters questions by
1 http://www.nicovideo.jp/
means of a text-field interface, and users who want to play the role of the characters can post answers.",2.2 Web sites,[0],[0]
"To stimulate interaction, the Web sites show the rankings of users by their number of posts.",2.2 Web sites,[0],[0]
"In addition, a “like” button is placed beside each answer so that when a user thinks the answer sounds very much “like” the character in question, this opinion can be reflected in the number of “likes”.",2.2 Web sites,[0],[0]
The sites were primarily for collecting one-shot questionanswer pairs.,2.2 Web sites,[0],[0]
"It was also possible for the Murai site to collect follow-up question-answer pairs, but this function was rarely utilized by users.",2.2 Web sites,[0],[0]
The statistics of the postings (at the time of submission) are listed in Table 1.,2.3 Statistics,[0],[0]
"We obtained a total of 12,959 and 15,112 question-answer pairs for Murai and Ayase, respectively.",2.3 Statistics,[0],[0]
The size of the data is quite large.,2.3 Statistics,[0],[0]
We want to emphasize that the users were not paid for their participation; they did so voluntarily.,2.3 Statistics,[0],[0]
This indicates that role play-based question-answering works well with real users.,2.3 Statistics,[0],[0]
"As seen in the table, more than 300 users participated for each character.",2.3 Statistics,[0],[0]
The questions/answers for Ayase were longer and contained more words and letters.,2.3 Statistics,[0],[0]
Table 2 shows the times when the number of question-answer pairs exceeded certain thresholds.,2.4 Efficiency,[0],[0]
We can see how fast we could collect a few thousand question-answer pairs.,2.4 Efficiency,[0],[0]
"For both characters, it took just about a couple of days to reach 2,000 question-answer pairs.",2.4 Efficiency,[0],[0]
"For Ayase, the pace was much faster than for Murai, reaching 10,000 question-answer pairs in 18 days.",2.4 Efficiency,[0],[0]
"After a cer-
tain period, the pace of the postings slowed.",2.4 Efficiency,[0],[0]
"Although role play-based question-answering is certainly entertaining, we may need to consider ways to keep users engaged in the interaction.",2.4 Efficiency,[0],[0]
Enabling more sustainable collection of questionanswer pairs is future work.,2.4 Efficiency,[0],[0]
We also evaluated the answers given by the users through subjective evaluation (see GOLD in Tables 4 and 5).,2.5 Quality of the postings,[0],[0]
"We obtained the average naturalness/character-ness scores of around 3.5– 4.0 on a five-point Likert scale, indicating that the answers collected through role play-based question-answering were good.",2.5 Quality of the postings,[0],[0]
"However, it was surprising that human users also struggled to obtain scores over 4.0, indicating that generating utterances for a particular character is difficult, even for humans.",2.5 Quality of the postings,[0],[0]
We asked users of the channels to participate in a survey to determine their user satisfaction.,2.6 Satisfaction of users,[0],[0]
"We used the same questionnaire as in (Higashinaka et al., 2013a).",2.6 Satisfaction of users,[0],[0]
"It consisted of three questions: (Q1) How do you rate the usability of the Web site?, (Q2) Would you be willing to use the Web site again?, and (Q3) Did you enjoy role playing on the Web site?",2.6 Satisfaction of users,[0],[0]
"The users answered based on a five-point Likert scale, with one being the lowest score and five the highest.",2.6 Satisfaction of users,[0],[0]
"Twenty-three and 36 participants took part in the survey for Murai and Ayase, respectively.
",2.6 Satisfaction of users,[0],[0]
Table 3 shows the results of the questionnaire averaged over all participants.,2.6 Satisfaction of users,[0],[0]
"Since these results were obtained from volunteers, they may not reflect the view of all site users.",2.6 Satisfaction of users,[0],[0]
"However, the results are encouraging: at the very least, they indicate that there are real users who feel very positively about the experience of role play-based questionanswering.",2.6 Satisfaction of users,[0],[0]
"Now that we have successfully collected a large number of question-answer pairs for our two characters, the next step is to determine if the collected pairs can be useful for creating chatbots that exhibit the personalities of the characters in question; namely, Murai and Ayase.",3 Creating chatbots from collected question-answer pairs,[0],[0]
"Since the size of the data was not large enough to train neural-generation models (Vinyals and Le, 2015), we opted for a retrieval-based approach in which relevant question-answer pairs are retrieved using an input question as a query and the answer part of the most relevant pair is returned as a chatbot’s response.",3 Creating chatbots from collected question-answer pairs,[0],[0]
"One of the methods we used is a simple application of an off-the-shelf text search engine, and the other is our proposed method, which is more sophisticated and uses neural-translation models for ranking.",3 Creating chatbots from collected question-answer pairs,[0],[0]
This method uses the text search engine LUCENE2 for retrieval.,3.1 Simple retrieval-based method,[0],[0]
Questions and answers are first indexed with LUCENE.,3.1 Simple retrieval-based method,[0],[0]
We use a built-in Japanese analyzer for morphological analysis.,3.1 Simple retrieval-based method,[0],[0]
"Given an input question, the BM25 algorithm (Walker et al., 1997) is used to search for a similar question using the content words of the input question.",3.1 Simple retrieval-based method,[0],[0]
The answers for the retrieved questions are used as the output of this method.,3.1 Simple retrieval-based method,[0],[0]
"Although simple, this method is quite competitive with other methods when there are many question-answer pairs because it is likely that we will be able to find a similar question by word matching.",3.1 Simple retrieval-based method,[0],[0]
Only using word-matching may not be sufficient.,3.2 Proposed method,[0],[0]
"Therefore, we developed a more elaborate method that re-ranks the results retrieved from LUCENE.",3.2 Proposed method,[0],[0]
"Our idea comes from cross-lingual question answering (CLQA) (Leuski et al., 2009) and recent advances in neural conversational models (Vinyals and Le, 2015).",3.2 Proposed method,[0],[0]
"We also conducted semantic and intent-level matching between ques-
2 https://lucene.apache.org/
tions so that appropriate answer candidates could be ranked higher.",3.2 Proposed method,[0],[0]
Figure 4 shows the flow of this method.,3.2 Proposed method,[0],[0]
"Given an input question Q, the method outputs answers in the following steps.",3.2 Proposed method,[0],[0]
"The details of some of the key models/modules used in the steps are described later.
1.",3.2 Proposed method,[0],[0]
"Given Q, LUCENE retrieves top-N questionanswer pairs (Q′1, A ′ 1) . . .",3.2 Proposed method,[0],[0]
"(Q ′ N , A′ N ), as de-
scribed in Section 3.1.
2.",3.2 Proposed method,[0],[0]
"The question-type estimation and extended
named entity recognition modules estimate the question types of Q and Q′ and extract extended named entities (Sekine et al., 2002) contained in A′.",3.2 Proposed method,[0],[0]
"The question-type match score is calculated by using the match of the question type and the number of extended named entities in A′ requested by Q. See Section 3.3 for details.
",3.2 Proposed method,[0],[0]
3.,3.2 Proposed method,[0],[0]
"The center-word extraction module extracts
center-words (noun phrases (NPs) that represent foci/topics) from both Q and Q′. The center-word score is 1.0 if one of the centerwords of Q is included in those of Q′; otherwise it is 0.0.
4.",3.2 Proposed method,[0],[0]
"The translation model is used to calculate the
probability that each A′ is translated from Q, that is, p(A′|Q).",3.2 Proposed method,[0],[0]
"We also calculate the probability bi-directionally, that is, p(Q|A′), which has been shown to be effective in CLQA (Leuski et al., 2009).",3.2 Proposed method,[0],[0]
The probabilities are normalized by dividing them by the number of words on the target side.,3.2 Proposed method,[0],[0]
"Since the raw probabilities are difficult to integrate with other scores, we sort the question-answer pairs by their probabilities and use their ranks
to obtain the translation scores.",3.2 Proposed method,[0],[0]
"That is, if the rank is r, its score is calculated by
1.0 − (r − 1)/max rank, (1)
where max rank is the maximum number of elements to be ranked.
5.",3.2 Proposed method,[0],[0]
"The semantic similarity model is used to cal-
culate the semantic similarity score between Q and Q′. We use Word2vec (Mikolov et al., 2013) to calculate this score.",3.2 Proposed method,[0],[0]
"First, we obtain word vectors (trained from Wikipedia) for each word in Q and Q′ and then calculate the cosine similarity between the averaged word vectors.
6.",3.2 Proposed method,[0],[0]
"The score calculation module integrates the
above scores to obtain a final score:
score(Q, (Q′, A′))
",3.2 Proposed method,[0],[0]
"= w1 ∗ search score
+ w2 ∗ qtypes match score
+ w3 ∗ center-word score
+ w4 ∗ translation score
+ w5 ∗ rev translation score
+ w6 ∗ semantic similarity score (2)
Here, search score indicates the score converted from the rank of the search results from LUCENE.",3.2 Proposed method,[0],[0]
The conversion is done using Eq.,3.2 Proposed method,[0],[0]
(1).,3.2 Proposed method,[0],[0]
rev translation score indicates the translation score derived from p(Q|A′).,3.2 Proposed method,[0],[0]
The w1 . . .,3.2 Proposed method,[0],[0]
"w6 denote the weights of the scores.
7.",3.2 Proposed method,[0],[0]
"The question-answer pairs are sorted by their
scores, and top-M answers are returned as output.",3.2 Proposed method,[0],[0]
"We describe some of the models/modules used in the above steps.
",3.3 Modules,[0],[0]
Question-type estimation and extended named entity recognition We estimated four question types for a question.,3.3 Modules,[0],[0]
One is a general question type.,3.3 Modules,[0],[0]
"We used the taxonomy described in (Higashinaka et al., 2014), which has 16 question subtypes.",3.3 Modules,[0],[0]
We trained a logistic-regression based question-type classifier that classifies a question into one of the 16 question types.,3.3 Modules,[0],[0]
The other three question types come from an extended named entity taxonomy proposed by Sekine (2002).,3.3 Modules,[0],[0]
"The taxonomy has three layers ranging from abstract
(e.g., Product, Location) to more concrete entities (e.g., Car, Spa, City).",3.3 Modules,[0],[0]
We trained a logisticregression-based classifier that classifies which of the named entity types is requested in a question.,3.3 Modules,[0],[0]
"We trained a classifier for each layer; thus, we had three classifiers.",3.3 Modules,[0],[0]
"Using our in-house data, by two-fold cross-validation, the classification accuracies are 86.0%, 84.9%, 76.9%, and 73.5% for the general question type, layer-1, layer-2, and layer-3 question types, respectively.",3.3 Modules,[0],[0]
"We also extract extended named entities from an answer candidate (A′) by using our extended named entity recognizer (Higashinaka et al., 2013b) and check whether the extended named entities corresponding to the layer-1, layer-2, and layer-3 question types of a question (Q) are included in A′.
The qtypes match score is calculated as follows: if there is a match of the general question type between Q and Q′, the score of one is obtained.",3.3 Modules,[0],[0]
"Then, the number of extended-namedentity question types covered by the answer candidate is added to this score.",3.3 Modules,[0],[0]
"Finally, this score is divided by four for normalization.
",3.3 Modules,[0],[0]
Center-word extraction We define a centerword as an NP that denotes the topic of a conversation.,3.3 Modules,[0],[0]
"To extract such NPs from an utterance, we used conditional random fields (CRFs) (Lafferty et al., 2001).",3.3 Modules,[0],[0]
"For the training and testing, we prepared about 20K sentences with centerword annotation.",3.3 Modules,[0],[0]
The sentences were those randomly sampled from our in-house open-domain conversation corpus.,3.3 Modules,[0],[0]
"The feature template uses words, part-of-speech (POS) tags, and semantic categories of current and neighboring words.",3.3 Modules,[0],[0]
"The extraction accuracy is 76% in F-measure with our in-house test set.
",3.3 Modules,[0],[0]
Translation model We trained a translation model by using a seq2seq model.,3.3 Modules,[0],[0]
We trained the model by using the OpenNMT Toolkit3 with default settings.,3.3 Modules,[0],[0]
The translation model learns to translate a question into an answer.,3.3 Modules,[0],[0]
"By using the trained model, we can obtain the generative probability of an answer given a question; namely p(A′|Q).",3.3 Modules,[0],[0]
"Since the amount of question-answer pairs was limited, we first trained a model by using our in-house question-answering data comprising 0.5 million pairs.",3.3 Modules,[0],[0]
The data were collected using crowd-sourcing.,3.3 Modules,[0],[0]
We then adapted the model to our question-answer pairs.,3.3 Modules,[0],[0]
"The model for p(Q|A′) was trained in the same manner by swapping the
3 http://opennmt.net/
source and target data.",3.3 Modules,[0],[0]
"To reflect the number of “likes” associated with the answers (see Section 2.2), we augmented the number of samples by their number of “likes”; that is, if a questionanswer pair has n “likes”, n samples of such a question-answer pair are included in the training data.",3.3 Modules,[0],[0]
"When developing our method, we noticed that, in some cases, top-N search results do not contain good candidates because of the lack of question coverage.",3.4 Extending question-answer pairs,[0],[0]
"When the top-N questions do not semantically match reasonably with the input question, the answers are likely to be inappropriate.",3.4 Extending question-answer pairs,[0],[0]
"To have a wider coverage of questions, we extended our question-answer pairs by using Twitter.",3.4 Extending question-answer pairs,[0],[0]
"Our methodology was simple: for each answer A that occurred twice or more in our questionanswer pairs, we searched for tweets that resemble A with a Levenshtein distance (normalized by the sentence length) below 0.1.",3.4 Extending question-answer pairs,[0],[0]
"Then, if the tweets had an in-reply-to relationship to other tweets, they were retrieved and coupled with A to form extended question-answer pairs.",3.4 Extending question-answer pairs,[0],[0]
"The reason we focused on an answer that occurred twice or more is mainly due to the efficiency of crawling, but such answers that occur multiple times are likely to be characteristics of the characters in question.",3.4 Extending question-answer pairs,[0],[0]
"We obtained 2,607,658 and 1,032,492 extended question-answer pairs for Murai and Ayase, respectively.",3.4 Extending question-answer pairs,[0],[0]
We conducted a subjective evaluation to determine the quality of chatbots created from our collected question-answer pairs.,4 Experiments,[0],[0]
We first describe how we prepared the data for evaluation and how we recruited participants.,4 Experiments,[0],[0]
We then describe the evaluation criteria.,4 Experiments,[0],[0]
"Next, we describe the methods for comparison, in which we compared the methods presented in the previous section with a rulebased baseline and gold data (human-generated data).",4 Experiments,[0],[0]
"Finally, we explain the results and present our analyses.",4 Experiments,[0],[0]
"To create the data for testing, we first randomly split the question-answer pairs into train, development, and test sets with the ratios of 0.8, 0.1, and 0.1, respectively.",4.1 Data,[0],[0]
The splits were made so that the same question would not be included over multiple sets.,4.1 Data,[0],[0]
"We used the train and development
sets to train the translation models.",4.1 Data,[0],[0]
"In addition, the question-answer pairs used by LUCENE for retrieval consisted only of train and development data.",4.1 Data,[0],[0]
"For each character, 50 questions were randomly sampled from the test set and used as input questions for this experiment.",4.1 Data,[0],[0]
We recruited 26 participants each for Murai and Ayase.,4.2 Procedure,[0],[0]
The participants were recruited mainly from the subscribers of the channels for the two characters.,4.2 Procedure,[0],[0]
"Before taking part in the experiment, they self-declared their levels of knowledge about the characters.",4.2 Procedure,[0],[0]
"Then, they rated the top-1 output of the five methods (shown below) for the 50 questions; they rated at maximum 250 answers (since some methods output duplicate answers, such answers were only rated once).",4.2 Procedure,[0],[0]
We compensated for their time by giving Amazon gift cards worth about 20 US dollars.,4.2 Procedure,[0],[0]
"The participants rated each output answer by their degree of agreement to the following statements on a five-point Likert scale (1: completely disagree, 5: completely agree).
",4.3 Evaluation criteria,[0],[0]
"Naturalness Not knowing who’s speaking, the
answer is appropriate to the input question.
",4.3 Evaluation criteria,[0],[0]
"Character-ness Knowing that the character in
question is speaking, the answer is appropriate to the input question.
",4.3 Evaluation criteria,[0],[0]
"The first criterion evaluates the interaction from a general point of view, while the second from the character point of view.",4.3 Evaluation criteria,[0],[0]
"Ideally, we want the character-ness to be high, but we want to maintain at least reasonable naturalness when considering the deployment of the chatbots.",4.3 Evaluation criteria,[0],[0]
"Note that an utterance can be rated low in terms of naturalness but high in character-ness, or vice-versa: for example, some general utterances, such as greetings, can never be uttered by particular characters.",4.3 Evaluation criteria,[0],[0]
We compared five methods.,4.4 Methods for comparison,[0],[0]
"A rule-based baseline written in Artificial Intelligence Markup Language (AIML) (Wallace, 2009) was used.",4.4 Methods for comparison,[0],[0]
The aim of having this baseline is to emulate when we do not have any question-answer pairs available.,4.4 Methods for comparison,[0],[0]
"Although this is a simple rule-based baseline, it is a competitive one because it uses one of the largest rule sets in Japanese.
",4.4 Methods for comparison,[0],[0]
Rule-based baseline (AIML),4.4 Methods for comparison,[0],[0]
"The typical ap-
proach to implement a chatbot is by using rules.",4.4 Methods for comparison,[0],[0]
We used the rules written in AIML created by Higashinaka et al (2015).,4.4 Methods for comparison,[0],[0]
There are roughly 300K rules.,4.4 Methods for comparison,[0],[0]
"In Japanese, sentence-end expressions are key factors to exhibit personality.",4.4 Methods for comparison,[0],[0]
"Therefore, following the method by Miyazaki et al. (2016), we created sentence-end conversion rules so that the output of this method would have the sentence-end expressions that match the characters in question.
",4.4 Methods for comparison,[0],[0]
Retrieval-based method (LUCENE),4.4 Methods for comparison,[0],[0]
"The
retrieval-based method described in Section 3.1.
",4.4 Methods for comparison,[0],[0]
Proposed method 1 (PROP WO EXDB),4.4 Methods for comparison,[0],[0]
"The
proposed method described in Section 3.2.",4.4 Methods for comparison,[0],[0]
This method does not use the extended question-answer pairs from Twitter.,4.4 Methods for comparison,[0],[0]
The weights w1 . . .,4.4 Methods for comparison,[0],[0]
w6 are all set to 1.0.,4.4 Methods for comparison,[0],[0]
"We used 10 for N for document retrieval.
",4.4 Methods for comparison,[0],[0]
Proposed method 2 (PROP),4.4 Methods for comparison,[0],[0]
"The proposed
method with extended question-answer pairs from Twitter, as described in Section 3.4.",4.4 Methods for comparison,[0],[0]
We retrieved 10 candidates from collected question-answer pairs and 10 from extended ones.,4.4 Methods for comparison,[0],[0]
The weights w1 . . .,4.4 Methods for comparison,[0],[0]
"w6 are all set to 1.0.
",4.4 Methods for comparison,[0],[0]
Upper bound (GOLD),4.4 Methods for comparison,[0],[0]
"The gold responses by
the online users to the test questions.",4.4 Methods for comparison,[0],[0]
"When multiple answers are given to a question, one is randomly selected.",4.4 Methods for comparison,[0],[0]
"Tables 4 and 5 list the results for Murai and Ayase, respectively.",4.5 Results,[0],[0]
The topmost row indicates the level of knowledge about the characters.,4.5 Results,[0],[0]
"‘All’ indicates the results of all participants, ‘High’ those who self-declared as being very knowledgeable, and ‘Low’ those who self-declared otherwise.",4.5 Results,[0],[0]
"We had 26 High and 6 Low participants for Murai, and 23 High and 3 Low participants for Ayase.
",4.5 Results,[0],[0]
"The tendencies were the same for the two characters, although the scores for Ayase were generally lower than those of Murai.",4.5 Results,[0],[0]
AIML performed the worst followed by LUCENE.,4.5 Results,[0],[0]
It was surprising that AIML’s score was low; this is probably because of the peculiarities of the input questions for the characters.,4.5 Results,[0],[0]
PROP WO EXDB and PROP performed better than AIML and LUCENE with statistical significance in many cases.,4.5 Results,[0],[0]
GOLD was always the best-performing method.,4.5 Results,[0],[0]
"PROP was significantly better than PROP WO EXDB for naturalness but not for character-ness.
",4.5 Results,[0],[0]
"These results indicate that simple text-based retrieval is not sufficient, and we need more elaborate methods.",4.5 Results,[0],[0]
The effectiveness of the extended question-answer pairs seems to be limited.,4.5 Results,[0],[0]
"It can be useful to make the interaction seem natural, but this does not necessarily improve character-ness, although we believe that having the ability to converse naturally is a requirement for chatbots.
",4.5 Results,[0],[0]
"When we focus on the results as they relate to the knowledge levels, we see large differences between High and Low.",4.5 Results,[0],[0]
"The High participants are likely to differentiate the answers more than Low
participants.",4.5 Results,[0],[0]
"For example, for Murai, there were only few cases in which there was statistical significance between the proposed methods when the knowledge level was low.",4.5 Results,[0],[0]
The tendency was the same for Ayase.,4.5 Results,[0],[0]
"This highlights the difficulty in evaluating for characters.
",4.5 Results,[0],[0]
"Tables 6 and 7 show examples of answers for Murai and Ayase, respectively.",4.5 Results,[0],[0]
"Overall, since the proposed methods achieved character-ness scores well over 3 (which is the middle point in the scale), we conclude that we can create chatbots with consistent personalities by means of role play-based question-answering.",4.5 Results,[0],[0]
"Although there have not been any studies involving role play-based question-answering for data collection, there is a large body of research for creating chatbots that show consistent personalities.
",5 Related Work,[0],[0]
"There have been several studies on characters by generating or rewriting utterances reflecting the underlying personality traits (Mairesse and Walker, 2007; Sugiyama et al., 2014; Miyazaki et al., 2016).",5 Related Work,[0],[0]
"In addition, there has been extensive research on extending neural conversational models to reflect personal profiles (Li et al., 2016).",5 Related Work,[0],[0]
"Although such neural networkbased methods show promising results, they still suffer from sparsity of data and non-informative utterances (Li et al., 2015).",5 Related Work,[0],[0]
This paper proposed increasing the source data for character building; the data can be useful for neural models.,5 Related Work,[0],[0]
Our goal for this study was to verify the effectiveness of role play-based question-answering for creating chatbots.,6 Summary and future work,[0],[0]
"Focusing on two famous char-
acters in Japan, we successfully collected a large volume of question-answer pairs for two characters by using real users.",6 Summary and future work,[0],[0]
We then created chatbots using the question-answer pairs.,6 Summary and future work,[0],[0]
"Subjective evaluation showed that although a simple textretrieval based method does not work well, our proposed method that uses translation models as well as question-type matching and center-word extraction works well, showing reasonable scores in terms of naturalness and character-ness.
",6 Summary and future work,[0],[0]
"For future work, we need to consider approaches to improve the quality of the proposed method.",6 Summary and future work,[0],[0]
"For example, we are currently using equal weights for scoring.",6 Summary and future work,[0],[0]
We believe that they can be optimized using training data.,6 Summary and future work,[0],[0]
"We also want to incorporate other pieces of information that may contribute to the ranking of answers, such as sentence embeddings (Kiros et al., 2015), discourse relations (Lin et al., 2009; Otsuka et al., 2017), and external knowledge about the characters.",6 Summary and future work,[0],[0]
"Although we used two very different characters in this paper, we want to use additional types of characters as targets for role play-based question-answering.",6 Summary and future work,[0],[0]
We also want to incorporate the chatbots into the Web sites so that the users can feel they are training up the characters.,6 Summary and future work,[0],[0]
"We thank the developers of DWANGO Co., Ltd. for creating the role play-based questionanswering Web sites.",Acknowledgments,[0],[0]
We also thank the subscribers of the Max Murai and Tukasa Fushimi channels on NICONICO Douga for their cooperation.,Acknowledgments,[0],[0]
"We thank the members of the Service Innovation Department at NTT DOCOMO, especially Yuiko Tsunomori, for helpful discussions and suggestions.",Acknowledgments,[0],[0]
Having consistent personalities is important for chatbots if we want them to be believable.,abstractText,[0],[0]
"Typically, many questionanswer pairs are prepared by hand for achieving consistent responses; however, the creation of such pairs is costly.",abstractText,[0],[0]
"In this study, our goal is to collect a large number of question-answer pairs for a particular character by using role playbased question-answering in which multiple users play the roles of certain characters and respond to questions by online users.",abstractText,[0],[0]
"Focusing on two famous characters, we conducted a large-scale experiment to collect question-answer pairs by using real users.",abstractText,[0],[0]
"We evaluated the effectiveness of role play-based questionanswering and found that, by using our proposed method, the collected pairs lead to good-quality chatbots that exhibit consistent personalities.",abstractText,[0],[0]
Role play-based question-answering by real users for building chatbots with consistent personalities,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 12–22, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"Tree transducers are general and solid theoretical models that have been applied to a variety of NLP tasks, such as machine translation (Knight and Graehl, 2005), text summarization (Cohn and Lapata, 2009), question answering (Jones et al., 2012), paraphrasing and textual entailment (Wu, 2005).",1 Introduction,[0],[0]
"One strategy to obtain transducer rules is by exhaustive enumeration; however, this method is ineffective when there is a high structural language variability and we wish to have an expressive model.",1 Introduction,[0],[0]
"Another strategy is to heuristically extract rules from a corpus of tree/string pairs and word-alignments, as
GHKM algorithm does (Galley et al., 2004); however, word-alignments are difficult to estimate when the corpus is small.",1 Introduction,[0],[0]
"This would be the case, for example, of machine translation for low-resourced languages where there is often small numbers of parallel sentences, or in Question Answering (QA) tasks where the number of Knowledge Base (KB) identifiers (concepts) is much larger than QA datasets.
",1 Introduction,[0],[0]
"Our main contribution is an algorithm that formulates the rule extraction as a cost minimization problem, where the search for the best rules is guided by an ensemble of cost functions over pairs of tree fragments.",1 Introduction,[0],[0]
"In GHKM, a tree fragment and a sequence of words are extracted together if they are minimal and their word alignments do not fall outside of their respective boundaries.",1 Introduction,[0],[0]
"However, given that alignment violations are not allowed, the quality of the extracted rules degrades as the rate of misaligned words increases.",1 Introduction,[0],[0]
"In our framework, we can mimic GHKM by assigning an infinite cost to pairs of tree fragments that violate such conditions on word alignments and by adding a cost regularizer on the size of the tree fragments.",1 Introduction,[0],[0]
"Smoother cost functions, however, would permit controlled misalignments, contributing to generalization.",1 Introduction,[0],[0]
"Given the generality of these cost functions, we believe that the applicability of tree transducers will be extended.
",1 Introduction,[0],[0]
"A by-product of introducing these cost functions is that some of them may act as rule back-offs, where transducer rules are built “on-the-fly” when the transducer is at a predefined back-off state but there is no rule whose left-hand-side (lhs) matches the input subtree.",1 Introduction,[0],[0]
"These back-off states can be seen as functions that are capable of generating right-
12
hand-sides (rhs) for unseen input subtrees.",1 Introduction,[0],[0]
"Our rule extraction algorithm and back-off scheme are general, in the sense that they can be applied to any tree transformation task.",1 Introduction,[0],[0]
"However, in this paper, we extrinsically evaluate the quality of the extracted rules in a QA task, where the objective is to transform syntactic trees of questions into constituent trees that represent Sparql queries on Freebase, a large Knowledge Base.",1 Introduction,[0],[0]
"Implementing all components of a QA system at a sufficient level is out of the scope of this paper; for that reason, in order to evaluate our contribution in isolation, we use the FREE917 corpus released by Cai and Yates (2013), for which an entity and predicate lexicon is available1.",1 Introduction,[0],[0]
"We show that a tree-to-tree transducer induced using our rule extraction and back-off scheme is accurate and generalizes well, which was not previously achieved with tree transducers in semantic parsing tasks such as QA over large KBs.",1 Introduction,[0],[0]
"Tree transducers were first proposed by Rounds (1970) and Thatcher (1970), and have been greatly developed recently (Knight and Graehl, 2005).",2 Related Work,[0],[0]
"Jones et al. (2012) used tree transducers to semantically parse narrow-domain questions into Prolog queries for GeoQuery (Wong and Mooney, 2006), a small database of 700 geographical facts.",2 Related Work,[0],[0]
"Rules were exhaustively enumerated, which was possible given the small size of the database and low variability of questions.",2 Related Work,[0],[0]
"Another strategy is that of Li et al. (2013), where they used a variant of GHKM to induce tree transducers that parse into λ-SCFG.",2 Related Work,[0],[0]
"Wordto-node alignments could be reliably estimated with the IBM models (Brown et al., 1993) given, again, the small vocabulary and database size of GeoQuery.",2 Related Work,[0],[0]
"In such small-scale tasks, our rule extraction and back-off scheme offers no obvious advantage.",2 Related Work,[0],[0]
"However, when doing QA over larger and more realistic KBs (and other tasks with similar characteristics), exhaustive enumeration of rules or reliable estimations of alignments are not possible, which prevents the application of tree transducers.",2 Related Work,[0],[0]
"Thus, it is on the latter type of tasks where we focus our contribution.
",2 Related Work,[0],[0]
"A similar problem has been considered in the tree
1The entity lexicon was released by the authors of FREE917, and the predicate lexicon is ours.
mapping literature in the form of the tree-to-tree edit distance.",2 Related Work,[0],[0]
"In that formulation, three edit operations are defined, namely, deleting and inserting single nodes, and replacing the label of a node.",2 Related Work,[0],[0]
"These edit operations have a cost associated to them, and the task consists of finding the minimum edit cost and its corresponding edit script2 that transforms a source into a target tree.",2 Related Work,[0],[0]
"The problem was first solved by Tai (1979), and later Zhang and Shasha (1989) proposed a simpler and faster dynamic programming algorithm that operates in polynomial time, and that has inspired multiple variations (Bille, 2005).
",2 Related Work,[0],[0]
"However, we need edit operations that involve tree fragments (e.g., noun phrases or parts of verb phrases), rather than single nodes, when searching for the best mappings.",2 Related Work,[0],[0]
"We address this problem by searching for non-isomorphic tree mappings, in line with Eisner (2003), except that our rule extraction algorithm is guided by an ensemble of cost functions over pairs of tree fragments.",2 Related Work,[0],[0]
This algorithm is capable of extracting rules more robustly than GHKM by permitting misalignments in a controlled manner.,2 Related Work,[0],[0]
"Finding a tree mapping solves simultaneously the alignment and the rule extraction problem.
",2 Related Work,[0],[0]
"There is a wide array of tree transducers with different expressive capabilities (Knight and Graehl, 2005).",2 Related Work,[0],[0]
"We consider extended3 root-to-frontier4 linear5 transducers (Maletti et al., 2009), possibly with deleting6 operations.",2 Related Work,[0],[0]
"In this paper, we syntactically parse the natural language question and transform it into a meaning representation, similarly to Ge and Mooney (2005).",2 Related Work,[0],[0]
"But instead of using Prolog formulae or λ-SCFG, we use constituent representations of λ−DCS expressions (Liang, 2013), which is a formal language convenient to represent Sparql queries where variables are eliminated by making existential quantifications implicit (see example in Figure 1).
",2 Related Work,[0],[0]
"Another challenge is to construct transducers with sufficient rule coverage, which would require billions of lexical rules that map question phrases to database entities or relations.",2 Related Work,[0],[0]
"Even if those rules were available, estimating their rule probabilities would be difficult given the small data sets of ques-
2Sequence of edit operations.",2 Related Work,[0],[0]
3lhs may have depth larger than 1. 4Top-down transformations.,2 Related Work,[0],[0]
5lhs variables appear at most once in the rhs.,2 Related Work,[0],[0]
"6Some variables on the lhs may not appear in the rhs.
tions paired with their logical representations.",2 Related Work,[0],[0]
"We solve the problem by constructing lexical rules “onthe-fly” at the decoding stage, similarly to the candidate generation stage of entity linking systems (Ling et al., 2015).",2 Related Work,[0],[0]
Rule weights are also predicted on-thefly given rule features and model parameters similar to Cohn and Lapata (2009).,2 Related Work,[0],[0]
"Tree transducers apply to general tree transformation problems, but for illustrative purposes, we use the tree pair s and t in Figure 1 (from FREE917) as a running example.",3 Background,[0],[0]
"s is the syntactic constituent tree of the question “how many teams participate in the uefa”, whereas t is a constituent tree of an executable meaning representation in the λ−DCS formalism:
count(Team.",3 Background,[0],[0]
League.,3 Background,[0],[0]
"Uefa)
Its corresponding lambda expression is
count(λx.∃a.Team(x, a) ∧ League(a, Uefa))
which can be converted into a Sparql KB query:
SELECT COUNT(?x) WHERE { ?a Team ?x .
?",3 Background,[0],[0]
"a League Uefa . }
",3 Background,[0],[0]
"Following the terminology of Graehl and Knight (2004), we define a tree-to-tree transducer as a 5- tuple (Q,Σ,∆, qstart,R) where Q is the set of states, Σ and ∆ are the sets of symbols of the input and output languages, qstart is the initial state, and R is the set of rules.",3 Background,[0],[0]
"For convenience, define TΣ as the set of trees with symbols in Σ, TΣ(A) the set of trees with symbols in Σ ∪ A where symbols in A only appear in the leaves, X as the set of variables {x1, . . .",3 Background,[0],[0]
", xn}, and A.B for the cross-product of two sets A and B. A rule r ∈ R has the form q.ti
s→ to, where q ∈ Q is a state, ti ∈ TΣ(X ) is the left-hand-side (lhs) tree pattern (or elementary tree), to ∈ T∆(Q.X )",3 Background,[0],[0]
"the right-hand-side (rhs), and s ∈ R",3 Background,[0],[0]
"the rule score.
",3 Background,[0],[0]
Tree-to-tree transducers apply a sequence of rules to transform a source s into a target t tree.,3 Background,[0],[0]
"A root-tofrontier transducer starts at the root of the source tree and searches R for a rule whose i) tree pattern ti on the lhs matches the root of the source tree, and ii) the
state q of the rule is the initial state of the transducer.",3 Background,[0],[0]
An incipient target tree is created by copying the rhs of the rule.,3 Background,[0],[0]
"Then, the transducer recursively and independently visits the subtrees of the source tree at the lhs variable positions of the rule from their new states, and copies the results into the same variable on the target tree.
",3 Background,[0],[0]
"In Figure 1, the sequential application of rules r1 to r5 is a derivation that transforms the question s into the query t.",3 Background,[0],[0]
"For example, rule r1 consumes a tree fragment of s (e.g. “how”, “many”, “WRB”, etc.) and produces a tree fragment with terminals (“COUNT”, x1, x2) and non-terminals (“ID”) with
a specific structure.",3 Background,[0],[0]
Rules r2 and r3 only consume but do not produce symbols (other than variables).,3 Background,[0],[0]
The rhs of rules are target tree fragments that connect to each other at the frontier nodes (those with variables).,3 Background,[0],[0]
"Rules r4 and r5 are terminal rules, where r4 produces the predicate Team and rule r5 produces the entity Uefa and a disambiguating predicate League that has no lexical support on the source side, similarly to the role that bridging predicates play in Berant et al. (2013).
",3 Background,[0],[0]
"Given a corpus of source and target tree pairs, the learning stage aims to obtain rules such as r1−r5 in Figure 1 and their associated probabilities or scores.",3 Background,[0],[0]
We discuss our novel approach to rule extraction in Section 5.,3 Background,[0],[0]
"For the assignment of rule scores, we adopt the latent variable averaged structured perceptron, a discriminative procedure similar to Tsochantaridis et al. (2005) and Cohn and Lapata (2009).",3 Background,[0],[0]
"Here, we instantiate feature values f for every rule, and reward the weights w of rules that participate in a derivation (latent variable) that transforms a training source tree into a meaning representation that retrieves the correct answer.
",3 Background,[0],[0]
"At decoding stage, rule scores can be predicted as s = w · f .",3 Background,[0],[0]
"However, we cannot expect to have extracted all necessary rules at the training stage given the small training data and large-scale KB.",3 Background,[0],[0]
"For that reason, we propose in Section 4 a novel rule back-off scheme to alleviate coverage problems.",3 Background,[0],[0]
"As an illustrative example, consider the question “how many teams participate in the nba”, and the rules r1 to r5 in Figure 1.",4 Back-off rules,[0],[0]
"When the transducer attempts to transform the noun phrase (NP (DT the) (NN nba)), no rule’s lhs matches it.",4 Back-off rules,[0],[0]
"However, since the transducer is at state bridge (as specified by the rhs of r3), it should be able to produce a list of bridged entities, among which the target subtree (ID League NBA) will be hopefully included.",4 Back-off rules,[0],[0]
"Thus, the following rule should be created for the occasion:
This mechanism produces rules “on-the-fly”, allowing us to compensate low rule coverage by consuming and producing tree fragments that were not nec-
essarily observed in the training data.",4 Back-off rules,[0],[0]
"Back-off rules are produced when the transducer is at a back-off state qb ∈ Qb ⊂ Q, similarly as the back-off mechanisms in finite-state language models where we produce estimates (probabilities) of input structures (sequences) under less conditioning.",4 Back-off rules,[0],[0]
"In our scheme, a back-off state (or function) qb produces estimates that are target structures t2 ∈ T∆ with score s ∈ R, given some information of the source tree fragment t1 ∈ TΣ.",4 Back-off rules,[0],[0]
"That is, a function qb :",4 Back-off rules,[0],[0]
"TΣ → {(T∆,R), . . .}.",4 Back-off rules,[0],[0]
"In our QA application, we only use the leaves of the input subtree t1 and use lexicons or entity/predicate linkers to retrieve KB entities, KB relations or a compound of a disambiguating relation and an entity from backoff states ent, pred and bridge, respectively.",4 Back-off rules,[0],[0]
"Other back-off functions would transliterate the leaves of the input tree in machine translation, or produce synonyms/hypernyms in a paraphrasing application.
",4 Back-off rules,[0],[0]
"We associate a score s to these newly created rules, which we learn to predict using the discriminative training procedure suggested by Tsochantaridis et al. (2005), as described in Section 3.
",4 Back-off rules,[0],[0]
"Back-off rules are then constructed on-demand as qb.t1
s→ t2, and the discrete set of rules R is augmented with them.",4 Back-off rules,[0],[0]
"It remains now to recognize those back-off states when inducing tree transducer grammars, which is covered in Section 5.1.",4 Back-off rules,[0],[0]
"Given a pair of trees, our rule extraction algorithm finds a tree mapping that implicitly describes the rules that transform a source into a target tree.",5 Rule Extraction,[0],[0]
"In the search of the best mapping, we need to explore the space of edit operations, which are substitutions of source by target tree fragments.",5 Rule Extraction,[0],[0]
"We define cost functions for these edit operations, and formulate the tree mapping as a cost minimization problem.",5 Rule Extraction,[0],[0]
"Whereas our tree mapping algorithm and back-off scheme are generic and can be used in any tree transformation task, cost functions depend on the application.",5 Rule Extraction,[0],[0]
"In general, cost functions are defined over edit operations, which are pairs of source and target tree fragments, cost : TΣ(X )",5.1 Cost functions,[0],[0]
"× T∆(Q.X ) → R≥0, and they are equivalent to feature functions.",5.1 Cost functions,[0],[0]
"Some cost
functions are defined over all pairs of tree fragments.",5.1 Cost functions,[0],[0]
"For this QA application, these are:
csize(t1, t2) = |nodes(t1)|2 + |nodes(t2)|2
which acts as a tree size regularizer, returning a cost quadratic to the size of the tree fragments, thus encouraging small rules.",5.1 Cost functions,[0],[0]
"The cost function ccount assigns zero cost if (i) “how” and “many” appear in t1, and (ii) “COUNT” appears in t2.",5.1 Cost functions,[0],[0]
"If only either (i) or (ii), the cost is a positive constant.",5.1 Cost functions,[0],[0]
"Similarly, other operators (max, min, argmax, etc.) could be recognized, but this dataset did not require them.
",5.1 Cost functions,[0],[0]
Other cost functions only apply to some pairs of tree fragments.,5.1 Cost functions,[0],[0]
"These are the back-off functions described in Section 4, but instead of returning scores for every target tree fragment, they return a cost, e.g. cent :",5.1 Cost functions,[0],[0]
TΣ × T∆ → R≥0.,5.1 Cost functions,[0],[0]
"An ensemble will produce up to three different costs for every pair of tree fragments, depending on what back-off functions were triggered.",5.1 Cost functions,[0],[0]
"In the case of the entity cost function:
γent(t1, t2) = λ1 · csize(t1, t2) + λ2 · ccount(t1, t2) + λ3 · cent(t1, t2)
(1)
where λi ∈ R≥0 are scaling factors.",5.1 Cost functions,[0],[0]
"In the search of the lowest-cost mapping, the labels of the cost functions that are derived from the back-off functions (e.g. γent, γpred) are memorized for the pairs (t1, t2) for which they were defined and for which they outputted a cost.",5.1 Cost functions,[0],[0]
These labels are then used as back-off rule state names when constructing rules.,5.1 Cost functions,[0],[0]
"Intuitively, the cost of mapping a source node ns to a target node nt is equal to the cost of transforming a tree fragment TΣ(X ) rooted at node ns into a tree fragment T∆(Q.X ) rooted at node nt, plus the sum of costs of mapping the frontier nodes rooted at the variables.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"In order to formalize our tree mapping, we need a more precise definition of a tree fragment where the locations of variables X are specified by paths.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"The notation to specify subtrees is taken from (Graehl and Knight, 2004), and we introduce the ⊥ operator for convenience.
",5.2 Tree Mapping: Optimization Problem,[0],[0]
"A path p is a tuple, equivalent to a Gorn address, that uniquely identifies the node of a tree by specifying the sequence of child indices to the node from
the root.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"In the tree s of Figure 1, the path to the VP node is (1, 0), whereas in t, the path to League is (1, 1, 0).",5.2 Tree Mapping: Optimization Problem,[0],[0]
The path p = () refers to the root of a tree.,5.2 Tree Mapping: Optimization Problem,[0],[0]
We denote by s ↓ p the subtree of tree s that is rooted at path p and that has no variables.,5.2 Tree Mapping: Optimization Problem,[0],[0]
"In Figure 1, the left-hand-side (lhs) of r5 is the subtree s ↓",5.2 Tree Mapping: Optimization Problem,[0],[0]
"(1, 0, 1, 1).",5.2 Tree Mapping: Optimization Problem,[0],[0]
"In order to introduce variables, we generalize the notion of subtree into a tree pattern s ↓ p ⊥ {p1, . . .",5.2 Tree Mapping: Optimization Problem,[0],[0]
", pn}, where n variables replace subtrees s ↓ pi at subpaths pi ∈ {p1, . . .",5.2 Tree Mapping: Optimization Problem,[0],[0]
", pn}.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"For example, the lhs of r1 can be represented with the tree pattern s ↓ () ⊥ {(0, 1), (1)}, and r2 with s ↓ (1) ⊥ {(1, 0, 1)}.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"Note that the order of subpaths {p1, . . .",5.2 Tree Mapping: Optimization Problem,[0],[0]
", pn} matters.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"A tree pattern with no subpaths s ↓ p ⊥ {} is simply a subtree s ↓ p, such as the lhs of rules r4 and r5; a tree pattern with only one subpath equal to its path s ↓ p ⊥ {p} is a single variable, such as the rhs of rules r2 and r3.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"Note that in s ↓ p ⊥ {p1, . . .",5.2 Tree Mapping: Optimization Problem,[0],[0]
", pn}, all paths pi to variables are prefixed by p, and that no variables are descendants of any other variable in the same tree pattern.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"In other words, p = {p1, . . .",5.2 Tree Mapping: Optimization Problem,[0],[0]
", pn} are disjoint subpaths given p, where p denotes a list of paths.
",5.2 Tree Mapping: Optimization Problem,[0],[0]
We can now formalize the tree mapping algorithm as an optimization problem.,5.2 Tree Mapping: Optimization Problem,[0],[0]
"Let γ (s ↓ ps ⊥ p, t ↓ pt ⊥ p′) be the cost to transform a source into a target tree pattern, as defined in Equation 1.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"To transform s ↓ ps into t ↓ pt, we need to find the best combination of source subtrees rooted at {p1, . . .",5.2 Tree Mapping: Optimization Problem,[0],[0]
", pn} that can be transformed at minimum cost to the best combination of target subtrees at {p′1, . . .",5.2 Tree Mapping: Optimization Problem,[0],[0]
", p′n}.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"The transformation cost of a certain tree pattern s ↓ ps ⊥ {p1, . . .",5.2 Tree Mapping: Optimization Problem,[0],[0]
", pn} into t ↓ pt ⊥ {p′1, . . .",5.2 Tree Mapping: Optimization Problem,[0],[0]
", p′n} is equal to the cost of transforming the source tree pattern into the target tree pattern, plus the minimum cost to transform s ↓ pi into t ↓",5.2 Tree Mapping: Optimization Problem,[0],[0]
"p′i, for i ≥ 1.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"That is:
C (s ↓ ps, t ↓ pt) =",5.2 Tree Mapping: Optimization Problem,[0],[0]
"min p,p′ {γ ( s ↓ ps ⊥ p, t ↓ pt ⊥ p′ )",5.2 Tree Mapping: Optimization Problem,[0],[0]
"+
|p|∑
i=1
C ( s ↓ pi, t ↓ p′i ) } (2)
subject to |p| = |p′|, that is, source and target tree patterns having the same number of variables.",5.2 Tree Mapping: Optimization Problem,[0],[0]
"Then, the cost of transforming the source into the target tree would be given by the expression
C (s ↓ (), t ↓ ()).",5.2 Tree Mapping: Optimization Problem,[0],[0]
"Since we are only interested in the pairs of source and target tree patterns that lead to the minimum cost, we keep track of subpaths p and p′ of tree pattern pairs that minimize the cost.",5.2 Tree Mapping: Optimization Problem,[0],[0]
This problem can be solved for small depths of tree patterns and a small number of variables by storing intermediate results in the computation of Eq. 2.,5.3.1 Overview,[0],[0]
"However, an exact implementation needs to enumerate all pairs of source and target disjoint subpaths (p and p′), which has a computational complexity that grows combinatorially with |p| (variable permutations), and exponentially with the number of descendant nodes of ps and pt (powerset of variables).
",5.3.1 Overview,[0],[0]
"Instead, we use a beam search algorithm (see Algorithm 1)7 that constructs source and target disjoint paths (p and p′) hierarchically (function GENERATEDISJOINT) in a bottom-up order, for any given path pair (ps, pt).",5.3.1 Overview,[0],[0]
"First, n-best solutions (pairs of disjoint paths) are computed for children; then those partial solutions are combined into their parent using the cross-product.",5.3.1 Overview,[0],[0]
"Solutions (with their associated cost) for every pair of paths (ps, pt) are stored in a weighted hypergraph, from which we can extract n-best derivations (sequences of rules).",5.3.1 Overview,[0],[0]
"In the pseudocode, we use a helper function, paths(s ↓ ps), which denotes the list of subtree paths in bottom-up order: from the leaves up to ps (including the latter).",5.3.1 Overview,[0],[0]
"For a certain path pair (ps, pt), there are three cases.",5.3.2 Detailed Description,[0],[0]
"The first case (line 34-35) considers a pair of empty disjoint subpaths (p,p′) =",5.3.2 Detailed Description,[0],[0]
"({}, {}), where the cost c of transforming s ↓ ps ⊥ {} into t ↓ pt ⊥ {} is evaluated and the empty disjoint subpaths are added to the priority queue P , indexed with ps.",5.3.2 Detailed Description,[0],[0]
"Such indexing is useful to retrieve the n-best pairs of disjoint subpaths accumulated at every tree node.
",5.3.2 Detailed Description,[0],[0]
The second case (line 28 to 31) evaluates the cost of transforming single-variable tree patterns: s ↓ ps ⊥ {pc} into t ↓ pt ⊥ {p′c}.,5.3.2 Detailed Description,[0],[0]
"In this case, variables substitute entire subtrees rooted at paths pc and p′c on the source and target tree patterns, respectively.",5.3.2 Detailed Description,[0],[0]
"Note that pc ranges over all node
7https://github.com/pasmargo/t2t-qa
Algorithm 1 Extraction of optimal sequence of rules to transform a source s into a target tree t. Input: Trees s and t, and ensemble of cost functions γ.",5.3.2 Detailed Description,[0],[0]
"Output: Sequence of optimal rules for s⇒∗ t.
1: let H = (V,E) be a hypergraph of solutions with V ← {} vertices and E ← {} hyperedges.",5.3.2 Detailed Description,[0],[0]
"2: for (ps, pt) ∈ paths(s)× paths(t) do 3: add vertex v = (ps, pt) to V 4: PP ← GENERATEDISJOINT(s ↓",5.3.2 Detailed Description,[0],[0]
"ps, t ↓ pt, γ) 5: for (p,p′) ∈ PP do 6: .",5.3.2 Detailed Description,[0],[0]
Get cost of tree pattern pair.,5.3.2 Detailed Description,[0],[0]
"7: c← γ (s ↓ ps ⊥ p, t ↓ pt ⊥ p′) 8: add edge (ps, pt)
c→ (p,p′) to E 9: end for
10: end for 11: return HYPERGRAPHSEARCH(H)
12: function GENERATEDISJOINT(s ↓ ps, t ↓ pt, γ) 13: P ← {} a priority queue of partial disjoint paths.",5.3.2 Detailed Description,[0],[0]
14: for every pc ∈ paths(s ↓ ps) do 15: .,5.3.2 Detailed Description,[0],[0]
Costs when variables combined from children.,5.3.2 Detailed Description,[0],[0]
16: for every pic immediate child of pc (if any) do 17: .,5.3.2 Detailed Description,[0],[0]
Retrieve n-best subpaths p and p′ from pic.,5.3.2 Detailed Description,[0],[0]
"18: C ← arg minn(p,p′){c | (pic,p,p′, c) ∈ P} 19: .",5.3.2 Detailed Description,[0],[0]
Combine subpaths with those accumulated 20: .,5.3.2 Detailed Description,[0],[0]
"from previous siblings and stored at path pc. 21: A← arg minn(p,p′){c | (pc,p,p′, c) ∈ P} 22: for (p,p′) ∈ (C ∪ (C.A)) do 23: c← γ (s ↓ ps ⊥ p, t ↓ pt ⊥ p′) 24: add (pc,p,p′, c) to priority queue P 25: end for 26: end for 27: .",5.3.2 Detailed Description,[0],[0]
Cost of tree patterns with one variable.,5.3.2 Detailed Description,[0],[0]
28: for every p′c ∈ paths(t ↓ pt) do 29: c←,5.3.2 Detailed Description,[0],[0]
"γ (s ↓ ps ⊥ {pc}, t ↓ pt ⊥ {p′c}) 30: add (pc, {pc}, {p′c}, c) to priority queue P 31: end for 32: end for 33: .",5.3.2 Detailed Description,[0],[0]
Cost of tree patterns with no variables.,5.3.2 Detailed Description,[0],[0]
"34: c← γ (s ↓ ps ⊥ {}, t ↓ pt ⊥ {}) 35: add (ps, {}, {}, c) to priority queue P 36: return arg minn(p,p′){c | (ps,p,p′, c) ∈ P} 37: end function
addresses that are descendant of ps (including ps), and similarly for p′c.",5.3.2 Detailed Description,[0],[0]
"The pairs of disjoint subpaths (p,p′) =",5.3.2 Detailed Description,[0],[0]
"({pc}, {p′c}) are added into the priority queue, indexed by pc.
",5.3.2 Detailed Description,[0],[0]
"The third case (line 16 to 26) performs the combination of subpaths hierarchically from children to parents, and incrementally across children.",5.3.2 Detailed Description,[0],[0]
"For every path pc ∈ paths(s ↓ ps), it visits its imme-
diate children pic one by one, and retrieves into C the n-best disjoint subpaths (line 18) that have already been obtained during previous iterations for pic.",5.3.2 Detailed Description,[0],[0]
"Then, we retrieve into A the n-best disjoint subpaths indexed at pc, which is a list of the best subpaths that were combined from previous immediate children (the list is empty if this is the first immediate child that we visit).",5.3.2 Detailed Description,[0],[0]
"The cross-product of disjoint subpaths in C and A, that is C.A, is then evaluated and the best combinations are stored in the priority queue indexed at pc.
",5.3.2 Detailed Description,[0],[0]
"As an example of a cross-product between two lists C and A of pairs of disjoint paths, let C = {(p1,p1′), (p2,p2′)} and A = {(p3,p3′)}.",5.3.2 Detailed Description,[0],[0]
"Then the cross-product C.A would be:
C.A = {(p1 · p3,p′1 · p′3), (p2 · p3,p′2 · p′3)}
where p1 · p3 = {(0, 1), (0, 2), (0, 3), (0, 4)} if p1 = {(0, 1), (0, 2)} and p3 = {(0, 3), (0, 4)}.",5.3.2 Detailed Description,[0],[0]
"At this stage, subpaths pi or p′i that are not disjoint are discarded, together with disjoint paths that produce tree patterns with depth larger than a certain userdefined threshold, or whose number of subpaths is larger than the number of variables allowed.
",5.3.2 Detailed Description,[0],[0]
"In line 24, the disjoint subpaths of C (in addition to their cross-product C.A) are also evaluated and added to the priority queue indexed by pc, to propagate upwards in the hierarchy of solutions the decision of not combining disjoint subpaths.
",5.3.2 Detailed Description,[0],[0]
"Finally, GENERATEDISJOINT returns the n-best pairs of disjoint subpaths of minimum cost (p, p′) that accumulated in the priority queue P for path ps.",5.3.2 Detailed Description,[0],[0]
"The n-best source and target pairs of disjoint subpaths are stored at every pair of source and target paths (ps, pt) (lines 2-10), forming a hypergraph, as in Figure 2.",5.3.3 Other Considerations,[0],[0]
"Then, with a hypergraph search (Huang and Chiang, 2007) we can retrieve at least n-best sequences of rules (derivations) that transform the source into the target tree (line 11).
",5.3.3 Other Considerations,[0],[0]
"To maintain diversity of partial disjoint subpaths, we divide P into a matrix of buckets with as many rows and columns as the number of non-variable terminals of the source and target tree patterns, trading memory for more effective search (Koehn, 2015).",5.3.3 Other Considerations,[0],[0]
"This operation is implicit in lines 24, 30 and 35.",5.3.3 Other Considerations,[0],[0]
Data,6.1 Experiment Settings,[0],[0]
The training data is a corpus of questions annotated with their logical forms that can be executed on Freebase to obtain a precise answer.,6.1 Experiment Settings,[0],[0]
"For an unseen set of questions, the task is to obtain automatically their logical forms and retrieve the correct answer.",6.1 Experiment Settings,[0],[0]
Our objective is to evaluate the generalization capabilities of a transducer induced using our rule extraction on an unseen open-domain test set.,6.1 Experiment Settings,[0],[0]
"We parsed questions from FREE917 into source constituent trees using the Stanford caseless model (Klein and Manning, 2003).",6.1 Experiment Settings,[0],[0]
Target constituent (meaning) representations were obtained by a simple heuristic conversion from the λ−DCS expressions released by Berant et al. (2013).,6.1 Experiment Settings,[0],[0]
We evaluate on the same training and testing split as in Berant et al. (2013).,6.1 Experiment Settings,[0],[0]
"Tree pairs (2.9%) for which the gold executable meaning representation did not retrieve valid results were filtered out.
",6.1 Experiment Settings,[0],[0]
Baselines We compared to two baselines.,6.1 Experiment Settings,[0],[0]
"The first one is SEMPRE (Berant et al., 2013), a stateof-the-art semantic parser that uses a target language grammar to over-generate trees, and a log-linear model to estimate the parameters that guide the decoder towards trees that generate correct answers.",6.1 Experiment Settings,[0],[0]
"For FREE917, SEMPRE uses a manually-created entity lexicon released by (Cai and Yates, 2013), but an automatically generated predicate lexicon.",6.1 Experiment Settings,[0],[0]
"In-
stead, our system and the second baseline use manually created entity and predicate lexicons, where the latter was created by selecting all words from every question that relate to the target predicate.",6.1 Experiment Settings,[0],[0]
"For example, for the question “what olympics has egypt participated in”, we created an entry that maps the discontinuous phrase “olympics participated in” to the predicate OlympicsParticipatedIn.
",6.1 Experiment Settings,[0],[0]
"The second baseline is a tree-to-tree transducer whose rules are extracted using a straightforward adaptation of the GHKM algorithm (Galley et al., 2004) for pairs of trees.",6.1 Experiment Settings,[0],[0]
"Word-to-concept alignments are extracted using three different strategies: i) ghkm-g uses the IBM models (Brown et al., 1993) as implemented in GIZA++",6.1 Experiment Settings,[0],[0]
"(Och and Ney, 2003), ii) ghkm-m maps KB concepts (target leaves) to as many source words as present in the entity/predicate lexicons, and iii) ghkm-c maps KB concepts as in ii) but only retaining the longest contiguous sequence of source words (or right-most sequence if there is a tie).",6.1 Experiment Settings,[0],[0]
Bridging predicates are assumed when a KB concept does not align (according to the lexicon) to any source word.,6.1 Experiment Settings,[0],[0]
"Finally, rule state names are set according to the mechanism described in Section 5.
",6.1 Experiment Settings,[0],[0]
"Our ent, pred and bridge cost/back-off functions assign a low cost (or high score) to source and target tree patterns with no variables whose leaves appear in either the entity or the predicate lexicons.",6.1 Experiment Settings,[0],[0]
Scaling factors λi (see Eq. 1) were subjectively tuned on 20 training examples.,6.1 Experiment Settings,[0],[0]
"When used as back-off functions, they generate as many rhs as entities or predicates can be retrieved from the lexicons by at least one of the words in the source tree pattern.",6.1 Experiment Settings,[0],[0]
Bridging predicates are dispreferred by adding an extra constant cost.,6.1 Experiment Settings,[0],[0]
"At back-off, this score function generates a variable predicate, acting as a wildcard in Sparql.
",6.1 Experiment Settings,[0],[0]
"Our system t2t For the rule extraction, we use a beam size of 10, and we output 100 derivations for every tree pair.",6.1 Experiment Settings,[0],[0]
"We do not impose any limit in the depth of lhs or rhs, or in the number of variables.",6.1 Experiment Settings,[0],[0]
"To increase the coverage of our rules, we produce deleting tree transducers by replacing fully lexicalized branches that are directly attached to the root of a lhs with a deleting variable.
",6.1 Experiment Settings,[0],[0]
"For the parameter estimation, we used 3 iterations of the latent variable averaged structured perceptron, where the number of iterations was selected on 20% of held-out training data.",6.1 Experiment Settings,[0],[0]
"To assess the equality be-
tween the gold and the decoded tree, we compare their denotations.",6.1 Experiment Settings,[0],[0]
"The features for the discriminative training were the lhs and rhs roots, the number of variables, deleting variables and leaves, the presence of entities or predicates in the rhs, the rule state and children states, and several measures of character overlaps between the leaves of the source and information associated to leaves in target tree patterns.
",6.1 Experiment Settings,[0],[0]
"For decoding, we used standard techniques (Graehl and Knight, 2004) to constrain and prune weighted regular tree grammars given a tree transducer and a source tree, and used the cube-growing algorithm to generate 10, 000 derivations, converted them to Sparql queries, and retained those that were valid (either syntactically correct or that retrieved any result).",6.1 Experiment Settings,[0],[0]
"We compute the accuracy of the system as the percentage of questions for which the 1-best output tree retrieves the correct answer, and the coverage as the percentage for which the correct answer is within the 10, 000 best derivations.",6.1 Experiment Settings,[0],[0]
"The average rule extraction time per tree pair when using beam size 1 was 0.46 seconds (median 0.35, maximum 2.94 seconds).",6.1 Experiment Settings,[0],[0]
"When using beam size 10, the average was 4.7 seconds (median 2.02, maximum 104.4 seconds), which gives us a glimpse of how the beam size influences the computational complexity for the typical tree size of FREE917 questions.",6.1 Experiment Settings,[0],[0]
Results are in Table 1.,6.2 Results,[0],[0]
"Note that although we compare our results to those obtained with SEMPRE (Berant et al., 2013), the systems cannot really be compared since Berant et al. (2013) did not have access to a manually created lexicon of predicates.",6.2 Results,[0],[0]
"When comparing the average number of entity and predicate rules that the back-off functions generate, we see that the number of predicate rules is much larger, implying a higher ambiguity.",6.2 Results,[0],[0]
"Despite this, our base system still produces promising results in terms of accuracy and coverage.
",6.2 Results,[0],[0]
We also carried out several ablation experiments to investigate what are the characteristics of the system that contribute the most to the accuracy:,6.2 Results,[0],[0]
"In no nbest, we only extract one sequence of rules that transform a source into a target tree.",6.2 Results,[0],[0]
"In no del, we do not introduce deleting variables.",6.2 Results,[0],[0]
"In beam 1, we use beam size 1 in rule extraction.",6.2 Results,[0],[0]
"In no size, no tree size regularizer cost function is used.",6.2 Results,[0],[0]
"And in
no back, no rule back-offs are used.",6.2 Results,[0],[0]
"As we see, removing the back-off rule capabilities is critical in this setting and makes the QA task unfeasible.",6.2 Results,[0],[0]
"We also studied the impact of the size of the training data in the generalization of our system, by training the system in {100, 200, . . .",6.2 Results,[0],[0]
", 600} examples.",6.2 Results,[0],[0]
"We found that the accuracy saturates at only 400 training instances, which might be advantageous in tasks where training resources are scarce.",6.2 Results,[0],[0]
"Finally, in order to estimate the upper bound in the coverage and accuracy of our approach on FREE917, we also run our pipeline t2t-e with a refined version of Cai and Yates (2013)’s entity lexicon, where 65 missing entities are added (7.8% of the total).",6.2 Results,[0],[0]
"We can observe a significant increase in the accuracy and coverage of the system, suggesting that the bottleneck may lie in the entity/predicate linking procedures.",6.2 Results,[0],[0]
One step further in the generalization of the rule extraction is to remove the necessity of explicitly providing cost functions such as word-to-word hardalignments or costs between tree fragments.,7 Future Work,[0],[0]
This would allow us to remove the bias introduced by engineered cost functions and to obtain rules that are globally optimal.,7 Future Work,[0],[0]
"In this setup, the parameters of the cost functions are to be learned with the objective to maximize the likelihood on the training data or
a downstream application performance.",7 Future Work,[0],[0]
"However, since rules (or tree mappings) would become hidden variables, this generalized rule extraction may require faster methods to enumerate plausible rules.",7 Future Work,[0],[0]
"Another extension would be to make the rule extraction more robust against parsing errors, using pairs of forests instead of pairs of trees, similarly as in Liu et al. (2009).
",7 Future Work,[0],[0]
"Regarding the QA application, there are two natural extensions that we want to address, namely to develop general and automatic entity and predicate linking mechanisms for large knowledge bases, and to test our approach in datasets that require higher levels of compositionality such as the QALD challenges (Unger et al., 2015) or those datasets produced by Wang et al. (2015).",7 Future Work,[0],[0]
"We proposed to induce tree to tree transducers using a rule extraction algorithm that uses cost functions over pairs of tree fragments (instead of wordalignments), which increases the applicability of these models.",8 Conclusion,[0],[0]
"Some cost functions may act as rule back-offs, generating new rhs given unseen lhs, thus producing transducer rules “on-the-fly”.",8 Conclusion,[0],[0]
The scores of these rules are obtained on demand using a discriminative training procedure that estimates weights for rule features.,8 Conclusion,[0],[0]
"This strategy was useful to compensate the lack of rule coverage when inducing tree transducers from small tree corpora.
",8 Conclusion,[0],[0]
"As a proof-of-concept, we tested the tree transducer induced with our algorithm on a QA task over a large KB, a domain in which tree transducers have not been effective before.",8 Conclusion,[0],[0]
"In this task, lexicon mappings were naturally introduced as cost functions and rule back-offs, without loss of generality.",8 Conclusion,[0],[0]
"Despite using a manually created lexicon of predicates, we showed a high accuracy and coverage of nonfinal rules, which are promising results.",8 Conclusion,[0],[0]
"This paper is based on results obtained from a project commissioned by the New Energy and Industrial Technology Development Organization (NEDO), and is also supported by JSPS KAKENHI Grant Number 16K16111.",Acknowledgments,[0],[0]
"We thank Yoshimasa Tsuruoka, Yo Ehara and the anonymous reviewers for their helpful comments.",Acknowledgments,[0],[0]
Tree transducers that model expressive linguistic phenomena often require wordalignments and a heuristic rule extractor to induce their grammars.,abstractText,[0],[0]
"However, when the corpus of tree/string pairs is small compared to the size of the vocabulary or the complexity of the grammar, word-alignments are unreliable.",abstractText,[0],[0]
"We propose a general rule extraction algorithm that uses cost functions over tree fragments, and formulate the extraction as a cost minimization problem.",abstractText,[0],[0]
"As a by-product, we are able to introduce back-off states at which some cost functions generate right-hand-sides of previously unseen lefthand-sides, thus creating transducer rules “on-the-fly”.",abstractText,[0],[0]
"We test the generalization power of our induced tree transducers on a QA task over a large Knowledge Base, obtaining a reasonable syntactic accuracy and effectively overcoming the typical lack of rule coverage.",abstractText,[0],[0]
Rule Extraction for Tree-to-Tree Transducers by Cost Minimization,title,[0],[0]
"This paper considers the general learning problem in which we have m observation vectors X1, . . .",1. Motivation and Overview,[0],[0]
", Xm ∈ Rn, with matching response values y1, . . .",1. Motivation and Overview,[0],[0]
", ym ∈ R.",1. Motivation and Overview,[0],[0]
Each response yi is a possibly noisy evaluation of an unknown function f :,1. Motivation and Overview,[0],[0]
"Rn → R at Xi, that is, yi = f(Xi) +",1. Motivation and Overview,[0],[0]
"ei, where ei ∈ R represents the noise or measurement error.",1. Motivation and Overview,[0],[0]
"The goal is to estimate f by some f̂ : Rn → R such that f̂(Xi) is a good fit for yi, that is, |f̂(Xi) − yi| tends to be small.",1. Motivation and Overview,[0],[0]
The estimate f̂ may then be used to predict the response value y corresponding to a newly encountered observation x ∈ Rn through the prediction ŷ = f̂(x).,1. Motivation and Overview,[0],[0]
A classical linear regression model is one simple example of the many possible techniques one might employ for constructing f̂ .,1. Motivation and Overview,[0],[0]
"The classical regression approach to this problem is to posit
1Management Science and Information Systems, Rutgers University, Piscataway, NJ, USA 2Department of Management, Bar-Ilan University, Ramat Gan, Israel 3Doctoral Program in Operations Research, Rutgers University, Piscataway, NJ, USA.",1. Motivation and Overview,[0],[0]
"Correspondence to: Jonathan Eckstein <jeckstei@business.rutgers.edu>.
",1. Motivation and Overview,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Motivation and Overview,[0],[0]
"Copyright 2017 by the author(s).
",1. Motivation and Overview,[0],[0]
"a particular functional form for f̂(x) (for example, an affine function of x) and then use an optimization procedure to estimate the parameters in this functional form.
",1. Motivation and Overview,[0],[0]
"Here, we are interested in cases in which a concise candidate functional form for f̂ is not readily apparent, and we wish to estimate f̂ by searching over a very highdimensional space of parameters.",1. Motivation and Overview,[0],[0]
"For example, Breiman (2001) proposed the method of random forests, which constructs f̂ by training regression trees on multiple random subsamples of the data, and then averaging the resulting predictors.",1. Motivation and Overview,[0],[0]
"Another proposal is the RuleFit algorithm (Friedman & Popescu, 2008), which enhances L1regularized regression by generating box-based rules to use as additional explanatory variables.",1. Motivation and Overview,[0],[0]
"Given a, b ∈ Rn with a ≤ b, the rule function r(a,b) :",1. Motivation and Overview,[0],[0]
"Rn → {0, 1} is given by
r(a,b)(x) = I ( ∧j∈{1,...,n}(aj ≤ xj ≤ bj) ) , (1)
that is r(a,b)(x) = 1 if a ≤ x ≤ b (componentwise) and r(a,b)(x) = 0 otherwise.",1. Motivation and Overview,[0],[0]
"RuleFit generates rules through a two-phase procedure: first, it determines a regression tree ensemble, and then decomposes these trees into rules and determines the regression model coefficients (including for the rules).
",1. Motivation and Overview,[0],[0]
"The approach of Dembczyński et al. (2008a) generates rules more directly (without having to rely on an initial ensemble of decision trees) within gradient boosting (Friedman, 2001) for non-regularized regression.",1. Motivation and Overview,[0],[0]
"In this scheme, a greedy procedure generates the rules within a gradient descent method runs that for a predetermined number of iterations.",1. Motivation and Overview,[0],[0]
Aho et al. (2012) extended the RuleFit method to solve more general multi-target regression problems.,1. Motivation and Overview,[0],[0]
"For the special case of single-target regression, however, their experiments suggest that random forests and RuleFit outperform several other methods, including their own extended implementation and the algorithm of Dembczyński et al. (2008a).",1. Motivation and Overview,[0],[0]
"Compared with random forests and other popular learning approaches such as kernel-based methods and neural networks, rule-based approaches have the advantage of generally being considered more accessible and easier to interpret by domain experts.",1. Motivation and Overview,[0],[0]
"Rule-based methods also have a considerable history in classification settings, as in for example Weiss & Indurkhya (1993), Cohen & Singer
(1999), and Dembczyński et al. (2008b).
",1. Motivation and Overview,[0],[0]
"Here, we propose an iterative optimization-based regression procedure called REPR (Rule-Enhanced Penalized Regression).",1. Motivation and Overview,[0],[0]
"Its output models resemble those of RuleFit, but our methodology draws more heavily on exact optimization techniques from the field of mathematical programming.",1. Motivation and Overview,[0],[0]
"While it is quite computationally intensive, its prediction performance appears promising.",1. Motivation and Overview,[0],[0]
"As in RuleFit, we start with a linear regression model (in this case, with L1-penalized coefficients to promote sparsity), and enhance it by synthesizing rules of the form (1).",1. Motivation and Overview,[0],[0]
We incrementally adjoin such rules to our (penalized) linear regression model as if they were new observation variables.,1. Motivation and Overview,[0],[0]
"Unlike RuleFit, we control the generation of new rules using the classical mathematical programming technique of column generation.",1. Motivation and Overview,[0],[0]
"Our employment of column generation roughly resembles its use in the LPBoost ensemble classification method of Demiriz et al. (2002).
",1. Motivation and Overview,[0],[0]
Column generation involves cyclical alternation between optimization of a restricted master problem (in our case a linear or convex quadratic program) and a pricing problem that finds the most promising new variables to adjoin to the formulation.,1. Motivation and Overview,[0],[0]
"In our case, the pricing problem is equivalent to an NP-hard combinatorial problem we call Rectangular Maximum Agreement (RMA), which generalizes the Maximum Mononial Agreement (MMA) problem as formulated and solved by Eckstein & Goldberg (2012).",1. Motivation and Overview,[0],[0]
"We solve the RMA problem by a similar branch-and-bound method procedure, implemented using parallel computing techniques.
",1. Motivation and Overview,[0],[0]
"To make our notation below more concise, we let X denote the matrix whose rows are X>1 , . . .",1. Motivation and Overview,[0],[0]
", X > m, and also let y = (y1, . . .",1. Motivation and Overview,[0],[0]
", ym) ∈ Rm.",1. Motivation and Overview,[0],[0]
"We may then express a problem instance by the pair (X, y).",1. Motivation and Overview,[0],[0]
"We also let xij denote the (i, j)th element of this matrix, that is, the value of variable j in observation i.",1. Motivation and Overview,[0],[0]
"Let K be a set of pairs (a, b) ∈",2. A Penalized Regression Model with Rules,[0],[0]
"Rn × Rn with a ≤ b, constituting a catalog of all the possible rules of the form (1) that we wish to be available to our regression model.",2. A Penalized Regression Model with Rules,[0],[0]
"The set K will typically be extremely large: restricting each aj and bj to values that appear as xij for some i, which is sufficient to describe all possible distinct behaviors of rules of the form (1) on the dataset X , there are still∏n j=1 `j(`j + 1)/2 ≥ 3n possible choices for (a, b), where
`j = | ⋃m i=1{xij}| is the number of distinct values for xij .
",2. A Penalized Regression Model with Rules,[0],[0]
"The predictors f̂ that our method constructs are of the form
f̂(x) =",2. A Penalized Regression Model with Rules,[0],[0]
"β0 + n∑ j=1 βjxj + ∑ k∈K γkrk(x) (2)
for some β0, β1, . . .",2. A Penalized Regression Model with Rules,[0],[0]
", βn, (γk)k∈K ∈ R. Finding an f̂ of this form is a matter of linear regression, but with the regression coefficients in a space with the potentially very high dimension of 1 +n+ |K|.",2. A Penalized Regression Model with Rules,[0],[0]
"As is now customary in regression models in which the number of explanatory variables potentially outnumbers the number of observations, we employ a LASSO-class model in which all explanatory variables except the constant term have L1 penalties.",2. A Penalized Regression Model with Rules,[0],[0]
Letting β =,2. A Penalized Regression Model with Rules,[0],[0]
"(β1, . . .",2. A Penalized Regression Model with Rules,[0],[0]
", βn) ∈ Rn and γ ∈ R|K|, let fβ0,β,γ( · ) denote the predictor function in (2).",2. A Penalized Regression Model with Rules,[0],[0]
"We then propose to estimate β0, β, γ by solving
min β0,β,γ { m∑ i=1 |fβ0,β,γ(Xi)− yi| p + C ‖β‖1 + E ‖γ‖1 } ,
(3) where p ∈ {1, 2} and C,E ≥ 0 are scalar parameters.",2. A Penalized Regression Model with Rules,[0],[0]
"For p = 2 and C = E > 0, this model is essentially the classic LASSO as originally proposed by Tibshirani (1996).
",2. A Penalized Regression Model with Rules,[0],[0]
"To put (3) into a more convenient form for our purposes, we split the regression coefficient vectors into positive and negative parts, so β = β+",2. A Penalized Regression Model with Rules,[0],[0]
"− β− and γ = γ+ − γ−, with β+, β− ∈ Rn+ and γ+, γ− ∈ R |K| + .",2. A Penalized Regression Model with Rules,[0],[0]
"Introducing one more vector of variables ∈ Rm, the model shown as (4) in Figure 1 is equivalent to (3).",2. A Penalized Regression Model with Rules,[0],[0]
"The model is constructed so that i = |fβ0,β,γ(Xi)− yi| for i = 1, . . .",2. A Penalized Regression Model with Rules,[0],[0]
",m. If p = 1, the model is a linear program, and if p = 2 it is a convex, linearly constrained quadratic program.",2. A Penalized Regression Model with Rules,[0],[0]
"In either case, there are 2m constraints (other than nonnegativity), but the number of variables is 1 +m+ 2n+ 2 |K|.
",2. A Penalized Regression Model with Rules,[0],[0]
"Because of this potentially unwieldy number of variables, we propose to solve (4) by using the classical technique of column generation, which dates back to Ford & Fulkerson (1958) and Gilmore & Gomory (1961); see for example Section 7.3 of Griva et al. (2009) for a recent textbook treatment.",2. A Penalized Regression Model with Rules,[0],[0]
"In brief, column generation cycles between solving two optimization problems, the restricted master problem and the pricing problem.",2. A Penalized Regression Model with Rules,[0],[0]
"In our case, the restricted master problem is the same as (4), but with K replaced by some (presumably far smaller) K ′",2. A Penalized Regression Model with Rules,[0],[0]
⊆ K.,2. A Penalized Regression Model with Rules,[0],[0]
We initially choose K ′ = ∅.,2. A Penalized Regression Model with Rules,[0],[0]
Solving the restricted master problem yields optimal Lagrange multipliers ν ∈ Rm+ and µ ∈ Rm+ (for the constraints other than simple nonnegativity).,2. A Penalized Regression Model with Rules,[0],[0]
"For each rule k ∈ K, these Lagrange multipliers yield respective reduced costs rc[γ+k",2. A Penalized Regression Model with Rules,[0],[0]
"], rc[γ",2. A Penalized Regression Model with Rules,[0],[0]
"− k ] for the variables γ + k ,",2. A Penalized Regression Model with Rules,[0],[0]
"γ − k that are in the master problem, but not the restricted master.",2. A Penalized Regression Model with Rules,[0],[0]
"One then solves the pricing problem, whose job is to identify the smallest of these reduced costs.",2. A Penalized Regression Model with Rules,[0],[0]
The reduced cost rc[v] of a variable v indicates the rate of change of the objective function as one increases v away from 0.,2. A Penalized Regression Model with Rules,[0],[0]
"If the smallest reduced
m∑ n∑ ∑
cost is nonnegative, then clearly all the reduced costs are nonnegative, which means that the current restricted master problem yields an optimal solution to the master problem by setting γ+k =",2. A Penalized Regression Model with Rules,[0],[0]
"γ − k = 0 for all k ∈ K\K ′, and the process terminates.",2. A Penalized Regression Model with Rules,[0],[0]
"If the smallest reduced cost is negative, we adjoin elements to K ′, including at least one corresponding to a variable γ+k or γ − k with a negative reduced cost, and we repeat the process, re-solving the expanded restricted master problem.
",2. A Penalized Regression Model with Rules,[0],[0]
"In our case, the reduced costs take the form
rc[γ+k ]",2. A Penalized Regression Model with Rules,[0],[0]
= E − m∑ i=1,2. A Penalized Regression Model with Rules,[0],[0]
rk(xi)νi,2. A Penalized Regression Model with Rules,[0],[0]
+,2. A Penalized Regression Model with Rules,[0],[0]
m∑ i=1,2. A Penalized Regression Model with Rules,[0],[0]
"rk(xi)µi
rc[γ−k ]",2. A Penalized Regression Model with Rules,[0],[0]
= E + m∑ i=1,2. A Penalized Regression Model with Rules,[0],[0]
rk(xi)νi,2. A Penalized Regression Model with Rules,[0],[0]
"− m∑ i=1 rk(xi)µi
and hence we have for each k ∈ K that
min { rc[γ+k",2. A Penalized Regression Model with Rules,[0],[0]
"], rc[γ",2. A Penalized Regression Model with Rules,[0],[0]
− k ] },2. A Penalized Regression Model with Rules,[0],[0]
= E,2. A Penalized Regression Model with Rules,[0],[0]
− ∣∣∣∣∣,2. A Penalized Regression Model with Rules,[0],[0]
m∑ i=1 rk(xi)(νi,2. A Penalized Regression Model with Rules,[0],[0]
− µi) ∣∣∣∣∣ .,2. A Penalized Regression Model with Rules,[0],[0]
"(5) Therefore, the pricing problem may be solved by maximizing the second term on the right-hand side of (5), that is, finding
z∗ = max k∈K ∣∣∣∣∣",2. A Penalized Regression Model with Rules,[0],[0]
m∑ i=1 rk(xi)(νi,2. A Penalized Regression Model with Rules,[0],[0]
− µi) ∣∣∣∣∣,2. A Penalized Regression Model with Rules,[0],[0]
", (6) and the stopping condition for the column generation procedure is z∗ ≤",2. A Penalized Regression Model with Rules,[0],[0]
E.,2. A Penalized Regression Model with Rules,[0],[0]
"This problem turns out to be equivalent to the RMA problem, whose formulation and solution we now describe.",2. A Penalized Regression Model with Rules,[0],[0]
"Suppose we have m observations and n explanatory variables, expressed using a matrix X ∈ Rm×n as above.",3.1. Formulation and Input Data,[0],[0]
"Each observation i ∈ {1, . . .",3.1. Formulation and Input Data,[0],[0]
",m} is assigned a nonegative weight wi ∈",3.1. Formulation and Input Data,[0],[0]
R+.,3.1. Formulation and Input Data,[0],[0]
"For any set S ⊆ {1, . . .",3.1. Formulation and Input Data,[0],[0]
",m},
let w(S) = ∑ i∈S wi.",3.1. Formulation and Input Data,[0],[0]
"We also assume we are given a partition of the observations into two subsets, a “positive” subset Ω+ ⊂ {1, . . .",3.1. Formulation and Input Data,[0],[0]
",m} and a “negative” subset Ω− = {1, . . .",3.1. Formulation and Input Data,[0],[0]
",m}\Ω+.
",3.1. Formulation and Input Data,[0],[0]
"Given two vectors a, b ∈ Rn, let B(a, b) denote the “box” {x ∈ Zn | a ≤ x ≤ b}.",3.1. Formulation and Input Data,[0],[0]
"Given the input data X , the coverage CvrX(a, b) of B(a, b) consists of the indices of the observations from X falling within B(a, b), that is,
CvrX(a, b)",3.1. Formulation and Input Data,[0],[0]
=,3.1. Formulation and Input Data,[0],[0]
"{i ∈ {1, . . .",3.1. Formulation and Input Data,[0],[0]
",m} | a ≤ Xi ≤ b} .
",3.1. Formulation and Input Data,[0],[0]
"The rectangular maximum agreement (RMA) problem is
max ∣∣w(Ω+ ∩",3.1. Formulation and Input Data,[0],[0]
"CvrX(a, b))− w(Ω− ∩",3.1. Formulation and Input Data,[0],[0]
"CvrX(a, b))∣∣ s.t.",3.1. Formulation and Input Data,[0],[0]
"a, b ∈ Rn, (7) with decision variables a, b ∈ Rn.",3.1. Formulation and Input Data,[0],[0]
"Essentially implicit in this formulation is the constraint that a ≤ b, since if a 6≤ b then CvrX(a, b) = ∅ and the objective value is 0.",3.1. Formulation and Input Data,[0],[0]
"The previously mentioned MMA problem is the special case of RMA in which all the observations are binary, X ∈ {0, 1}m×n.",3.1. Formulation and Input Data,[0],[0]
"Since the MMA problem is NPhard (Eckstein & Goldberg, 2012), so is RMA.
",3.1. Formulation and Input Data,[0],[0]
"If we take K to be the set of all possible boxes on Rn, the pricing problem (6) may be reduced to RMA by setting
(∀ i = 1, . . .",3.1. Formulation and Input Data,[0],[0]
",m) :",3.1. Formulation and Input Data,[0],[0]
"wi = |νi − µi| (8)
Ω+",3.1. Formulation and Input Data,[0],[0]
"= {i ∈ {1, . . .",3.1. Formulation and Input Data,[0],[0]
",m} | νi ≥ µi } , (9)
and thus Ω− = {i ∈",3.1. Formulation and Input Data,[0],[0]
"{1, . . .",3.1. Formulation and Input Data,[0],[0]
",m} | νi",3.1. Formulation and Input Data,[0],[0]
< µi }.,3.1. Formulation and Input Data,[0],[0]
Any RMA problem instance may be converted to an equivalent instance in which all the observation data are integer.,3.2. Preprocessing and Restriction to N,[0],[0]
"Essentially, for each coordinate j = 1, . . .",3.2. Preprocessing and Restriction to N,[0],[0]
", n, one may simply record the distinct values of xij and replace each xij with its ordinal position among these values.",3.2. Preprocessing and Restriction to N,[0],[0]
"Algorithm 1, with its parameter δ set to 0, performs exactly this procedure, outputing a equivalent data matrix X ∈ Nm×n and a vector ` ∈",3.2. Preprocessing and Restriction to N,[0],[0]
"Nn whose jth element is `j = | ⋃m i=1{xij}|
Algorithm 1",3.2. Preprocessing and Restriction to N,[0],[0]
Preprocessing discretization algorithm 1,3.2. Preprocessing and Restriction to N,[0],[0]
": Input: X ∈ Rm×n, δ ≥ 0 2: Output: X ∈",3.2. Preprocessing and Restriction to N,[0],[0]
"Nm×n, ` ∈",3.2. Preprocessing and Restriction to N,[0],[0]
"Nn 3: ProcessData 4: for j = 1 to n do 5: `j ← 0 6: Sort x1j , . . .",3.2. Preprocessing and Restriction to N,[0],[0]
", xmj and set (k1, . . .",3.2. Preprocessing and Restriction to N,[0],[0]
", km) such that
xk1j ≤ xk2j ≤ · · · ≤ xkmj 7: x̄k1,j ← 0 8: for i = 1 to m− 1 do 9: if xki+1j",3.2. Preprocessing and Restriction to N,[0],[0]
"− xkij > δ · (xkmj − xk1j) then
10: `j ← `j + 1 11: end if 12: x̄ki+1j",3.2. Preprocessing and Restriction to N,[0],[0]
"← `j 13: end for 14: `j ← `j + 1 15: end for 16: return (X, `)
as defined in the previous section.",3.2. Preprocessing and Restriction to N,[0],[0]
"Algorithm 1’s output values x̄ij for attribute j vary between 0 and `j − 1.
",3.2. Preprocessing and Restriction to N,[0],[0]
The number of distinct values `j of each explanatory variable j directly influences the difficulty of RMA instances.,3.2. Preprocessing and Restriction to N,[0],[0]
"To obtain easier instances, Algorithm 1 can combine its “integerization” process with some binning of nearby values.",3.2. Preprocessing and Restriction to N,[0],[0]
"Essentially, if the parameter δ is positive, the algorithm bins together consecutive values xij that are within relative tolerance δ, resulting in a smaller number of distinct values `j for each explanatory variable j.
Some datasets contain both categorical and numerical data.",3.2. Preprocessing and Restriction to N,[0],[0]
"In addition to Algorithm 1, we also convert each k-way categorical attribute into k − 1 binary attributes.
",3.2. Preprocessing and Restriction to N,[0],[0]
"Within the context of our REPR regression method, we set the RMA weight vector and data partition as in (8)-(9), integerize the data X using Algorithm 1 with some (small) parameter value δ, solve the RMA problem, and then translate the resulting boxes back to the original, pre-integerized coordinate system.",3.2. Preprocessing and Restriction to N,[0],[0]
"We perform this translation by expanding box boundaries to lie halfway between the boundaries of the clusters of points grouped by Algorithm 1, except when the lower boundary of the box has the lowest possible value or the upper boundary has the largest possible value.",3.2. Preprocessing and Restriction to N,[0],[0]
"In these cases, we expand the box boundaries to −∞ or +∞, respectively.",3.2. Preprocessing and Restriction to N,[0],[0]
"More precisely, for each observation variable j and v ∈ {0, . . .",3.2. Preprocessing and Restriction to N,[0],[0]
", `j − 1}, let xminj,v be the smallest value of xij assigned to the integer value v by Algorithm 1, and xmaxj,v be the largest.",3.2. Preprocessing and Restriction to N,[0],[0]
"If â, b̂ ∈ Nn, â ≤ b̂ describe an integerized box arising from the solution of the preprocessed RMA problem, we choose the corresponding box boundaries a, b ∈ Rn in the original coordinate system
to be given by, for j = 1, . . .",3.2. Preprocessing and Restriction to N,[0],[0]
",",3.2. Preprocessing and Restriction to N,[0],[0]
"n,
aj = { −∞, if âj = 0 1 2 (x max j,âj−1 + x min j,âj ), otherwise
bj = { +∞, if b̂j = `j − 1 1 2 (x max j,b̂j + xmin j,b̂j+1 ), otherwise.
",3.2. Preprocessing and Restriction to N,[0],[0]
"Overall, our procedure is equivalent to solving the pricing problem (6) over some set of boxes K = Kδ(X).",3.2. Preprocessing and Restriction to N,[0],[0]
"For δ = 0, the resulting set of boxesK0(X) is such that the corresponding set of rules {rk | k ∈ K0(X)} comprises every box-based rule distinguishable on the dataset X .",3.2. Preprocessing and Restriction to N,[0],[0]
"For small positive values of δ, the set of boxes Kδ(X) excludes those corresponding to rules that “cut” between very closely spaced observations.",3.2. Preprocessing and Restriction to N,[0],[0]
"In this and the following two subsections, we describe the key elements of our branch-and-bound procedure for solving the RMA problem, assuming that the data X have already been preprocessed as above.",3.3. Branch-and-Bound Subproblems,[0],[0]
"For brevity, we omit some details which will instead be covered in a forthcoming publication.",3.3. Branch-and-Bound Subproblems,[0],[0]
"For general background on branch-andbound algorithms, Morrison et al. (2016) provide a recent survey with numerous citations.
",3.3. Branch-and-Bound Subproblems,[0],[0]
"Branch-and-bound methods search a tree of subproblems, each describing some subset of the search space.",3.3. Branch-and-Bound Subproblems,[0],[0]
"In our RMA method, each subproblem P is characterized by four vectors a(P ), a(P ), b(P ), b(P",3.3. Branch-and-Bound Subproblems,[0],[0]
") ∈ Nn, and represents search space subset consisting of vector pairs (a, b) for which a(P ) ≤ a ≤ a(P ) and b(P ) ≤ b ≤ b(P ).",3.3. Branch-and-Bound Subproblems,[0],[0]
"Any valid subproblem conforms to a(P ) ≤ a(P ), b(P ) ≤ b(P ), a(P ) ≤ b(P ), and a(P ) ≤ b(P ).",3.3. Branch-and-Bound Subproblems,[0],[0]
"The root problem R of the branch-and-bound tree is R = (0, ` − 1,0, ` − 1), where where ` ∈ Nn is as output from Algorithm 1, and 0 and 1 respectively denote the vectors (0, 0, . . .",3.3. Branch-and-Bound Subproblems,[0],[0]
", 0) ∈",3.3. Branch-and-Bound Subproblems,[0],[0]
"Nn and (1, 1, . . .",3.3. Branch-and-Bound Subproblems,[0],[0]
", 1) ∈",3.3. Branch-and-Bound Subproblems,[0],[0]
Nn.,3.3. Branch-and-Bound Subproblems,[0],[0]
"In branch-and-bound methods, the bounding function provides an upper bound (when maximizing) on the best possible objective value in the region of the search space corresponding to a subproblem.",3.4. Inseparability and the Bounding Function,[0],[0]
Our bounding function is based on an extension of the notion of inseparability developed by Eckstein & Goldberg (2012).,3.4. Inseparability and the Bounding Function,[0],[0]
"Consider any subproblem P = (a, a, b, b) and two observations i and i′.",3.4. Inseparability and the Bounding Function,[0],[0]
"If xij = xi′j or aj ≤ xij , xi′j ≤ bj for each j = 1, . . .",3.4. Inseparability and the Bounding Function,[0],[0]
", n, then xi, xi′ ∈",3.4. Inseparability and the Bounding Function,[0],[0]
"Nn are inseparable with respect to a, b ∈ Nn, in the sense that any box B(a, b) with a ≤ a and b ≥ b must either cover both of xi, xi′ or neither of them.
",3.4. Inseparability and the Bounding Function,[0],[0]
"Inseparability with respect to a, b is an equivalence relation,
and we denote the equivalence classes it induces among the observation indices 1, . . .",3.4. Inseparability and the Bounding Function,[0],[0]
",m by E(a, b).",3.4. Inseparability and the Bounding Function,[0],[0]
"That is, observation indices i and i′ are in the same equivalence class of E(a, b) if xi and xi′ are inseparable with respect to a, b.
Our bounding function β(a, a, b, b) for each subproblem P = (a, a, b, b) is shown in (10) in Figure 2.",3.4. Inseparability and the Bounding Function,[0],[0]
"The reasoning behind this bound is that each possible box in the set specified by (a, a, b, b) must either cover or not cover the entirety of each C ∈ E(a, b).",3.4. Inseparability and the Bounding Function,[0],[0]
"The first argument to the “max” operation reflects the situation that every equivalence class C with a positive net weight is covered, and no classes with negative net weight are covered; this is the best possible situation if the box ends up covering a higher weight of positive observations than of negative.",3.4. Inseparability and the Bounding Function,[0],[0]
"The second “max” argument reflects the opposite situation, the best possible case in which the box covers a greater weight of negative observations than of positive ones.",3.4. Inseparability and the Bounding Function,[0],[0]
The branching scheme of a branch-and-bound algorithm divides subproblems into smaller ones in order to improve their bounds.,3.5. Branching,[0],[0]
"In our case, branching a subproblem P = (a, a, b, b) involves choosing an explanatory variable j ∈ {1, . . .",3.5. Branching,[0],[0]
", n} and a cutpoint v ∈ {aj , . . .",3.5. Branching,[0],[0]
", bj − 1} ∈ Nn.
",3.5. Branching,[0],[0]
"There are three possible cases, the first of which is when bj < aj and v ∈ {bj , . . .",3.5. Branching,[0],[0]
", aj − 1}.",3.5. Branching,[0],[0]
"In this case, our scheme creates three children based on the disjunction that either bj ≤ v",3.5. Branching,[0],[0]
"− 1 (the box lies below v), aj ≤ v ≤ bj (the box straddles v), or aj ≥ v+ 1 (the box lies above v).",3.5. Branching,[0],[0]
"The next case is that v ∈ { aj , . . .",3.5. Branching,[0],[0]
",min{aj , bj} − 1 } , in which case the box cannot lie below v",3.5. Branching,[0],[0]
and we split P into two children based on the disjunction that either aj ≤ v,3.5. Branching,[0],[0]
(the box straddles v) or aj ≥ v + 1 (the box is above v).,3.5. Branching,[0],[0]
"The third case occurs when v ∈ { max{aj , bj}, . . .",3.5. Branching,[0],[0]
", bj−1 } , in which case we split P into two children based on the disjunction that either bj ≤ v",3.5. Branching,[0],[0]
(the box is does not extend above v) or bj ≥ v+ 1 (the box extends above v).,3.5. Branching,[0],[0]
"If no v falling under one of these three cases exists for any dimension j, then the subproblem represents a single possible box, that is, a = a and b = b.",3.5. Branching,[0],[0]
"Such a subproblem is a terminal node of the branch-and-bound tree, and in this case we simply compute the RMA objective value for a = a = a and b = b = b as the subproblem bound.
",3.5. Branching,[0],[0]
"When more than one possible variable-cutpoint pair (j, v) exists, as is typically the case, our algorithm must select one.",3.5. Branching,[0],[0]
We use two related procedures for branching selection: strong branching and cutpoint caching.,3.5. Branching,[0],[0]
"In strong branching, we simply experiment with all applicable variable-cutpoint pairs (j, v), and select one that the maximizes the minimum bound of the resulting two or three children.",3.5. Branching,[0],[0]
"This is a standard technique in branch-and-bound algorithms, and involves evaluating the bounds of all the potential children of the current search node.",3.5. Branching,[0],[0]
"To make this process as efficient as possible, we have developed specialized data structures for manipulating equivalence classes, and we analyze the branching possibilities in a particular order.",3.5. Branching,[0],[0]
"In cutpoint caching, some subproblems use strong branching, while others select from a list of cutpoints that were chosen by strong branching for previously processed search nodes.",3.5. Branching,[0],[0]
The details of these procedures will be covered in a forthcoming companion publication.,3.5. Branching,[0],[0]
"The pseudocode in Algorithm 2 describes our full REPR column generation procedure for solving (4), using the RMA preprocessing and branch-and-bound methods described above to solve the pricing problem.",4. Full Algorithm and Implementation,[0],[0]
"Several points bear mentioning: first, the nonnegative scalar parameter θ allows us to incorporate a tolerance into the column generation stopping criterion, so that we terminate when all reduced costs exceed −θ instead of when all reduced costs are nonnegative.",4. Full Algorithm and Implementation,[0],[0]
This kind of tolerance is customary in column generation methods.,4. Full Algorithm and Implementation,[0],[0]
"The tolerance δ, on the other hand, controls the space of columns searched over.",4. Full Algorithm and Implementation,[0],[0]
"Furthermore, our implementation of the RMA branch-and-bound algorithm can identify any desired number t ≥ 1 of the best possible RMA solutions, as opposed to just one value of k attaining the maximum in (11).",4. Full Algorithm and Implementation,[0],[0]
"This t is also a parameter to our procedure, so at each iteration of Algorithm 2 we may adjoin up to t new rules to K ′. Adding multiple columns per iteration is a common technique in column generation methods.",4. Full Algorithm and Implementation,[0],[0]
"Finally, the algorithm has a parameter S specifying a limit on the number of column generation iterations, meaning that at the output model will contain at most St rules.
",4. Full Algorithm and Implementation,[0],[0]
"We implemented the algorithm in C++, using the GuRoBi
Algorithm 2 REPR:",4. Full Algorithm and Implementation,[0],[0]
Rule-enhanced penalized regression 1: Input: data X ∈,4. Full Algorithm and Implementation,[0],[0]
"Rm×n, y ∈ Rm, penalty parameters C,E ≥ 0, column generation tolerance θ ≥ 0, integer t ≥ 1, aggregation tolerance δ",4. Full Algorithm and Implementation,[0],[0]
"≥ 0, iteration limit S
2: Output: β0 ∈ R,",4. Full Algorithm and Implementation,[0],[0]
"β ∈ Rn,K ′ ⊂ Kδ(X), γ ∈ R|K ′| 3: REPR 4: K ′",4. Full Algorithm and Implementation,[0],[0]
←,4. Full Algorithm and Implementation,[0],[0]
"∅ 5: for s = 1, . . .",4. Full Algorithm and Implementation,[0],[0]
", S do 6: Solve the restricted master problem to obtain opti-
mal primal variables (β0, β+, β−, γ+, γ−) and dual variables (ν, µ)
7: Use the RMA branch-and-bound algorithm, with preprocessing as in Algorithm 1, to identify a t-best solution k1, . . .",4. Full Algorithm and Implementation,[0],[0]
", kt to
max k∈Kδ(X) ∣∣∣∣∣",4. Full Algorithm and Implementation,[0],[0]
m∑ i=1 rk(xi)(νi,4. Full Algorithm and Implementation,[0],[0]
− µi) ∣∣∣∣∣,4. Full Algorithm and Implementation,[0],[0]
", (11) with k1, . . .",4. Full Algorithm and Implementation,[0],[0]
", kt having respective objective values z1 ≥ z2 ≥ · · ·",4. Full Algorithm and Implementation,[0],[0]
"≥ zt
8: if z1 ≤ E + θ break 9: for each l ∈ {1, . . .",4. Full Algorithm and Implementation,[0],[0]
", t} with zl > E",4. Full Algorithm and Implementation,[0],[0]
"+ θ do
10: K ′",4. Full Algorithm and Implementation,[0],[0]
← K ′,4. Full Algorithm and Implementation,[0],[0]
"∪ {kl} 11: end for 12: end for 13: return (β0, β := β+",4. Full Algorithm and Implementation,[0],[0]
"− β−,K ′, γ := γ+ − γ−)
commercial optimizer (Gurobi Optimization, 2016) to solve the restricted master problems.",4. Full Algorithm and Implementation,[0],[0]
"We implemented the RMA algorithm using using the PEBBL C++ class library (Eckstein et al., 2015), an open-source C++ framework for parallel branch and bound.",4. Full Algorithm and Implementation,[0],[0]
"PEBBL employs MPIbased parallelism (Gropp et al., 1994).",4. Full Algorithm and Implementation,[0],[0]
"Since solving the RMA pricing problem is by far the most time-consuming part of Algorithm 2, we used true parallel computing only in that portion of the algorithm.",4. Full Algorithm and Implementation,[0],[0]
"The remainder of the algorithm, including solving the restricted master problems, was executed in serial and redundantly on all processors.",4. Full Algorithm and Implementation,[0],[0]
"For preliminary testing of REPR, we selected 8 datasets from the UCI repository (Lichman, 2013), choosing small datasets with continuous response variables.",5. Preliminary Testing of REPR,[0],[0]
"The first four columns of Table 1 summarize the number of observations m, the number of attributes n, and the maximum number of distinguishable box-based rules |K0(X)| for these data sets.
",5. Preliminary Testing of REPR,[0],[0]
"In our initial testing, we focused on the p = 2 case in which fitting errors are penalized quadratically, and set t = 1, that is, we added one model rule per REPR iteration.",5. Preliminary Testing of REPR,[0],[0]
"We set the iteration limit S to 100 and effectively set the termination
tolerance θ so that REPR terminated when z1 ≤ max { 0, E · ( |E[y]| − 0.1σ[y] )} + 0.001,
where E[y] denotes the sample mean of the response variable and σ[y] its sample standard deviation.",5. Preliminary Testing of REPR,[0],[0]
"We found this rule of thumb to work well in pracice, but it likely merits further study.",5. Preliminary Testing of REPR,[0],[0]
We also chose C = 1 and E = 1.,5. Preliminary Testing of REPR,[0],[0]
"We used δ = 0 for SERVO, YACHT, and MPG, and δ = 0.005 for the remaining datasets.
",5. Preliminary Testing of REPR,[0],[0]
"With the fixed parameters given above, we tested REPR and some competing regression procedures on ten different randomly-chosen partitions of each dataset; each partition consists of 80% training data and 20% testing data.",5. Preliminary Testing of REPR,[0],[0]
"The competing procedures are RuleFit, random forests, LASSO, and classical linear regression.",5. Preliminary Testing of REPR,[0],[0]
The penalty parameter in LASSO is the same as the value of C chosen for REPR.,5. Preliminary Testing of REPR,[0],[0]
"To implement RuleFit and random forests, we used their publicly available R packages.",5. Preliminary Testing of REPR,[0],[0]
Table 2 shows the averages of the resulting mean square errors and Table 3 shows their standard deviations.,5. Preliminary Testing of REPR,[0],[0]
"REPR has the smallest average MSE for 5 of the 8 datasets and has the second smallest average MSE on the remaining 3 datasets, coming very close to random forests on MPG.",5. Preliminary Testing of REPR,[0],[0]
"For the standard deviation of the MSE, which we take as a general measure of prediction stability, REPR has the lowest values for 6 of the 8 datasets.",5. Preliminary Testing of REPR,[0],[0]
"The box plots in Figures 3 and 4 visualize these results in more detail for HEAT and MACHINE, respectively.",5. Preliminary Testing of REPR,[0],[0]
"Figure 5 displays the average MSEs in a bar-chart format, with the MSE of REPR normalized to 1.
",5. Preliminary Testing of REPR,[0],[0]
Figures 6-9 give more detailed information for specific datasets.,5. Preliminary Testing of REPR,[0],[0]
"Figure 6 and 7 respectively show how REPR’s prediction MSEs for HEAT and CONCRETE evolve with each iteration, with each data point averaged over the 10 different REPR runs; the horizontal lines indicate the average MSE level for the competing procedures.",5. Preliminary Testing of REPR,[0],[0]
"MSE generally declines as REPR adds rules, although some diminish-
ing returns are evident for CONCRETE.",5. Preliminary Testing of REPR,[0],[0]
"Interestingly, neither of these figures shows appreciable evidence of overfitting by REPR, even when large numbers of rules are incorporated into the model.",5. Preliminary Testing of REPR,[0],[0]
"Figures 8 and 9 display testing-set predictions for specific (arbitrarily chosen) partitions of the MACHINE and CONCRETE datasets, respectively, with the observations sorted by response value.",5. Preliminary Testing of REPR,[0],[0]
"REPR seems to outperform the other methods in predicting extreme response values, although it is somewhat worse than the other methods at predicting non-extreme values for MACHINE.
",5. Preliminary Testing of REPR,[0],[0]
"The last two columns of Table 1 show, for a 16-core Xeon E5-2660 workstation, REPR’s average total run time per data partition and the average number of search node per invocation of RMA.",5. Preliminary Testing of REPR,[0],[0]
The longer runs could likely be accelerated by the application of more parallel processors.,5. Preliminary Testing of REPR,[0],[0]
"The results presented here suggest that REPR has significant potential as a regression tool, at least for small datasets.",6. Conclusions and Future Research,[0],[0]
"Clearly, it should be tested on more datasets and larger datasets.
",6. Conclusions and Future Research,[0],[0]
"Here, we have tested REPR using fixed values of most of its parameters, and we expect we should be able to improve its performance by using intelligent heuristics or crossvalidation procedures to select key parameters such as C andE. Improved preprocessing may also prove helpful: judicious normalization of the input data (X, y) should assist in finding good parameter choices, and we are also working on more sophisticated discretization technique for preprocessing the RMA solver input, as well as branch selection heuristics that are more efficient for large `j .
",6. Conclusions and Future Research,[0],[0]
It would be interesting to see how well REPR performs if the pricing problems are solved less exactly.,6. Conclusions and Future Research,[0],[0]
"For example, one could use various techniques for truncating the branchand-bound search, such as setting a limit on the number of subproblems explored or loosening the conditions for pruning unpromising subtrees.",6. Conclusions and Future Research,[0],[0]
"Or one could use, perhaps selectively, some entirely heuristic procedure to identify rules to add to the restricted master problem.
",6. Conclusions and Future Research,[0],[0]
"For problems with large numbers of observations m, it is conceivable that solving the restricted master problems could become a serial bottleneck in our current implementation strategy.",6. Conclusions and Future Research,[0],[0]
"If this phenomenon is observed in practice, it could be worth investigating parallel solution strategies for the restricted master.",6. Conclusions and Future Research,[0],[0]
We describe a procedure enhancingL1-penalized regression by adding dynamically generated rules describing multidimensional “box” sets.,abstractText,[0],[0]
Our rule-adding procedure is based on the classical column generation method for highdimensional linear programming.,abstractText,[0],[0]
The pricing problem for our column generation procedure reduces to the NP-hard rectangular maximum agreement (RMA) problem of finding a box that best discriminates between two weighted datasets.,abstractText,[0],[0]
We solve this problem exactly using a parallel branch-and-bound procedure.,abstractText,[0],[0]
"The resulting rule-enhanced regression method is computation-intensive, but has promising prediction performance.",abstractText,[0],[0]
1.,abstractText,[0],[0]
"Motivation and Overview This paper considers the general learning problem in which we have m observation vectors X1, . . .",abstractText,[0],[0]
", Xm ∈ R, with matching response values y1, . . .",abstractText,[0],[0]
", ym ∈ R.",abstractText,[0],[0]
Each response yi is a possibly noisy evaluation of an unknown function f :,abstractText,[0],[0]
"R → R at Xi, that is, yi = f(Xi) +",abstractText,[0],[0]
"ei, where ei ∈ R represents the noise or measurement error.",abstractText,[0],[0]
"The goal is to estimate f by some f̂ : R → R such that f̂(Xi) is a good fit for yi, that is, |f̂(Xi) − yi| tends to be small.",abstractText,[0],[0]
The estimate f̂ may then be used to predict the response value y corresponding to a newly encountered observation x ∈ R through the prediction ŷ = f̂(x).,abstractText,[0],[0]
A classical linear regression model is one simple example of the many possible techniques one might employ for constructing f̂ .,abstractText,[0],[0]
"The classical regression approach to this problem is to posit Management Science and Information Systems, Rutgers University, Piscataway, NJ, USA Department of Management, Bar-Ilan University, Ramat Gan, Israel Doctoral Program in Operations Research, Rutgers University, Piscataway, NJ, USA.",abstractText,[0],[0]
Correspondence to: Jonathan Eckstein <jeckstei@business.rutgers.edu>.,abstractText,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",abstractText,[0],[0]
Copyright 2017 by the author(s).,abstractText,[0],[0]
"a particular functional form for f̂(x) (for example, an affine function of x) and then use an optimization procedure to estimate the parameters in this functional form.",abstractText,[0],[0]
"Here, we are interested in cases in which a concise candidate functional form for f̂ is not readily apparent, and we wish to estimate f̂ by searching over a very highdimensional space of parameters.",abstractText,[0],[0]
"For example, Breiman (2001) proposed the method of random forests, which constructs f̂ by training regression trees on multiple random subsamples of the data, and then averaging the resulting predictors.",abstractText,[0],[0]
"Another proposal is the RuleFit algorithm (Friedman & Popescu, 2008), which enhances L1regularized regression by generating box-based rules to use as additional explanatory variables.",abstractText,[0],[0]
"Given a, b ∈ R with a ≤ b, the rule function r(a,b) : R → {0, 1} is given by r(a,b)(x) =",abstractText,[0],[0]
"I ( ∧j∈{1,...,n}(aj ≤ xj ≤ bj) ) , (1) that is r(a,b)(x) = 1 if a ≤ x ≤ b",abstractText,[0],[0]
"(componentwise) and r(a,b)(x) = 0",abstractText,[0],[0]
otherwise.,abstractText,[0],[0]
"RuleFit generates rules through a two-phase procedure: first, it determines a regression tree ensemble, and then decomposes these trees into rules and determines the regression model coefficients (including for the rules).",abstractText,[0],[0]
"The approach of Dembczyński et al. (2008a) generates rules more directly (without having to rely on an initial ensemble of decision trees) within gradient boosting (Friedman, 2001) for non-regularized regression.",abstractText,[0],[0]
"In this scheme, a greedy procedure generates the rules within a gradient descent method runs that for a predetermined number of iterations.",abstractText,[0],[0]
Aho et al. (2012) extended the RuleFit method to solve more general multi-target regression problems.,abstractText,[0],[0]
"For the special case of single-target regression, however, their experiments suggest that random forests and RuleFit outperform several other methods, including their own extended implementation and the algorithm of Dembczyński et al. (2008a).",abstractText,[0],[0]
"Compared with random forests and other popular learning approaches such as kernel-based methods and neural networks, rule-based approaches have the advantage of generally being considered more accessible and easier to interpret by domain experts.",abstractText,[0],[0]
"Rule-based methods also have a considerable history in classification settings, as in for example Weiss & Indurkhya (1993), Cohen & Singer Rule-Enhanced Penalized Regression by Column Generation using Rectangular Maximum Agreement (1999), and Dembczyński et al. (2008b).",abstractText,[0],[0]
"Here, we propose an iterative optimization-based regression procedure called REPR (Rule-Enhanced Penalized Regression).",abstractText,[0],[0]
"Its output models resemble those of RuleFit, but our methodology draws more heavily on exact optimization techniques from the field of mathematical programming.",abstractText,[0],[0]
"While it is quite computationally intensive, its prediction performance appears promising.",abstractText,[0],[0]
"As in RuleFit, we start with a linear regression model (in this case, with L1-penalized coefficients to promote sparsity), and enhance it by synthesizing rules of the form (1).",abstractText,[0],[0]
We incrementally adjoin such rules to our (penalized) linear regression model as if they were new observation variables.,abstractText,[0],[0]
"Unlike RuleFit, we control the generation of new rules using the classical mathematical programming technique of column generation.",abstractText,[0],[0]
Our employment of column generation roughly resembles its use in the LPBoost ensemble classification method of Demiriz et al. (2002).,abstractText,[0],[0]
Column generation involves cyclical alternation between optimization of a restricted master problem (in our case a linear or convex quadratic program) and a pricing problem that finds the most promising new variables to adjoin to the formulation.,abstractText,[0],[0]
"In our case, the pricing problem is equivalent to an NP-hard combinatorial problem we call Rectangular Maximum Agreement (RMA), which generalizes the Maximum Mononial Agreement (MMA) problem as formulated and solved by Eckstein & Goldberg (2012).",abstractText,[0],[0]
"We solve the RMA problem by a similar branch-and-bound method procedure, implemented using parallel computing techniques.",abstractText,[0],[0]
"To make our notation below more concise, we let X denote the matrix whose rows are X 1 , . . .",abstractText,[0],[0]
", X > m, and also let y = (y1, . . .",abstractText,[0],[0]
", ym) ∈ R.",abstractText,[0],[0]
"We may then express a problem instance by the pair (X, y).",abstractText,[0],[0]
"We also let xij denote the (i, j)th element of this matrix, that is, the value of variable j in observation i. 2.",abstractText,[0],[0]
"A Penalized Regression Model with Rules Let K be a set of pairs (a, b) ∈ R × R with a ≤ b, constituting a catalog of all the possible rules of the form (1) that we wish to be available to our regression model.",abstractText,[0],[0]
"The set K will typically be extremely large: restricting each aj and bj to values that appear as xij for some i, which is sufficient to describe all possible distinct behaviors of rules of the form (1) on the dataset X , there are still ∏n j=1 `j(`j + 1)/2 ≥ 3 possible choices for (a, b), where `j = | ⋃m i=1{xij}| is the number of distinct values for xij .",abstractText,[0],[0]
The predictors f̂ that our method constructs are of the form f̂(x) = β0 + n ∑,abstractText,[0],[0]
Rule-Enhanced Penalized Regression by Column Generation  using Rectangular Maximum Agreement,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1980–1989 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1980",text,[0],[0]
Rumors have always been a social disease.,1 Introduction,[0],[0]
"In recent years, it has become unprecedentedly convenient for the “evil-doers” to create and disseminate rumors in massive scale with low cost thanks to the popularity of social media outlets on Twitter, Facebook, etc.",1 Introduction,[0],[0]
"The worst effect of false rumors could be devastating to individual and/or society.
",1 Introduction,[0],[0]
"Research pertaining rumors spans multiple disciplines, such as philosophy and humanities (DiFonzo and Bordia, 2007; Donovan, 2007), social psychology (Allport and Postman, 1965; Jaeger et al., 1980; Rosnow and Foster, 2005), political studies (Allport and Postman, 1946; Berinsky, 2017), management science (DiFonzo et al., 1994; Kimmel, 2004) and recently computer science and artificial intelligence (Qazvinian et al., 2011; Ratkiewicz et al., 2011; Castillo et al., 2011; Hannak et al., 2014; Zhao et al., 2015; Ma et al.,
2015).",1 Introduction,[0],[0]
"Rumor is commonly defined as information that emerge and spread among people whose truth value is unverified or intentionally false (DiFonzo and Bordia, 2007; Qazvinian et al., 2011).",1 Introduction,[0],[0]
"Analysis shows that people tend to stop spreading a rumor if it is known as false (Zubiaga et al., 2016b).",1 Introduction,[0],[0]
"However, identifying such misinformation is non-trivial and needs investigative journalism to fact check the suspected claim, which is labor-intensive and time-consuming.",1 Introduction,[0],[0]
The proliferation of social media makes it worse due to the ever-increasing information load and dynamics.,1 Introduction,[0],[0]
"Therefore, it is necessary to develop automatic and assistant approaches to facilitate real-time rumor tracking and debunking.
",1 Introduction,[0],[0]
"For automating rumor detection, most of the previous studies focused on text mining from sequential microblog streams using supervised models based on feature engineering (Castillo et al., 2011; Kwon et al., 2013; Liu et al., 2015; Ma et al., 2015), and more recently deep neural models (Ma et al., 2016; Chen et al., 2017; Ruchansky et al., 2017).",1 Introduction,[0],[0]
These methods largely ignore or oversimplify the structural information associated with message propagation which however has been shown conducive to provide useful clues for identifying rumors.,1 Introduction,[0],[0]
"Kernel-based method (Wu et al., 2015; Ma et al., 2017) was thus proposed to model the structure as propagation trees in order to differentiate rumorous and non-rumorous claims by comparing their tree-based similarities.",1 Introduction,[0],[0]
"But such kind of approach cannot directly classify a tree without pairwise comparison with all other trees imposing unnecessary overhead, and it also cannot automatically learn any high-level feature representations out of the noisy surface features.
",1 Introduction,[0],[0]
"In this paper, we present a neural rumor detection approach based on recursive neural networks (RvNN) to bridge the content semantics and propagation clues.",1 Introduction,[0],[0]
"RvNN and its variants
were originally used to compose phrase or sentence representation for syntactic and semantic parsing (Socher et al., 2011, 2012).",1 Introduction,[0],[0]
"Unlike parsing, the input into our model is a propagation tree rooted from a source post rather than the parse tree of an individual sentence, and each tree node is a responsive post instead of an individual words.",1 Introduction,[0],[0]
"The content semantics of posts and the responsive relationship among them can be jointly captured via the recursive feature learning process along the tree structure.
",1 Introduction,[0],[0]
"So, why can such neural model do better for the task?",1 Introduction,[0],[0]
"Analysis has generally found that Twitter could “self-correct” some inaccurate information as users share opinions, conjectures and evidences (Zubiaga et al., 2017).",1 Introduction,[0],[0]
"To illustrate our intuition, Figure 1 exemplifies the propagation trees of two rumors in our dataset, one being false and the other being true1.",1 Introduction,[0],[0]
Structure-insensitive methods basically relying on the relative ratio of different stances in the text cannot do well when such clue is unclear like this example.,1 Introduction,[0],[0]
"However, it can be seen that when a post denies the false rumor, it tends to spark supportive or affirmative replies confirming the denial; in contrast, denial to a true rumor tends to trigger question or denial in its replies.",1 Introduction,[0],[0]
"This observation may suggest a more general hypothesis that the repliers tend to disagree with (or question) who support a false rumor or deny a true rumor, and also they tend to agree with who deny a false rumor or support a true rumor.",1 Introduction,[0],[0]
"Meanwhile, a reply, rather than directly responding to the source tweet (i.e., the root), is usually responsive to its immediate ancestor (Lukasik et al., 2016; Zubiaga et al., 2016a), suggesting obvious local characteristic of the interaction.",1 Introduction,[0],[0]
"The recursive network naturally models such structures for learning to capture the rumor indicative signals and enhance the representation by recursively aggregating the signals from different branches.
",1 Introduction,[0],[0]
"To this end, we extend the standard RvNN into two variants, i.e., a bottom-up (BU) model and a top-down (TD) model, which represent the propagation tree structure from different angles, in order to visit the nodes and combine their representations following distinct directions.",1 Introduction,[0],[0]
"The important merit of such architecture is that the node features can be selectively refined by the recursion given the connection and direction of all paths of the
1False (true) rumor means the veracity of the rumorous claim is false (true).
tree.",1 Introduction,[0],[0]
"As a result, it can be expected that the discriminative signals are better embedded into the learned representations.
",1 Introduction,[0],[0]
We evaluate our proposed approach based on two public Twitter datasets.,1 Introduction,[0],[0]
"The results show that our method outperforms strong rumor detection baselines with large margin and also demonstrate much higher effectiveness for detection at early stage of propagation, which is promising for realtime intervention and debunking.",1 Introduction,[0],[0]
"Our contributions are summarized as follows in three folds:
•",1 Introduction,[0],[0]
"This is the first study that deeply integrates both structure and content semantics based on tree-structured recursive neural networks for detecting rumors from microblog posts.
",1 Introduction,[0],[0]
"• We propose two variants of RvNN models based on bottom-up and top-down tree structures to generate better integrated representations for a claim by capturing both structural and textural properties signaling rumors.
",1 Introduction,[0],[0]
• Our experiments based on real-world Twitter datasets achieve superior improvements over state-of-the-art baselines on both rumor classification and early detection tasks.,1 Introduction,[0],[0]
We make the source codes in our experiments publicly accessible 2.,1 Introduction,[0],[0]
"Most previous automatic approaches for rumor detection (Castillo et al., 2011; Yang et al., 2012; Liu
2https://github.com/majingCUHK/Rumor_",2 Related Work,[0],[0]
"RvNN
et al., 2015) intended to learn a supervised classifier by utilizing a wide range of features crafted from post contents, user profiles and propagation patterns.",2 Related Work,[0],[0]
"Subsequent studies were then conducted to engineer new features such as those representing rumor diffusion and cascades (Friggeri et al., 2014; Hannak et al., 2014) characterized by comments with links to debunking websites.",2 Related Work,[0],[0]
Kwon et al. (2013) introduced a time-series-fitting model based on the volume of tweets over time.,2 Related Work,[0],[0]
Ma et al. (2015) extended their model with more chronological social context features.,2 Related Work,[0],[0]
"These approaches typically require heavy preprocessing and feature engineering.
",2 Related Work,[0],[0]
"Zhao et al. (2015) alleviated the engineering effort by using a set of regular expressions (such as “really?”, “not true”, etc) to find questing and denying tweets, but the approach was oversimplified and suffered from very low recall.",2 Related Work,[0],[0]
Ma et al. (2016) used recurrent neural networks (RNN) to learn automatically the representations from tweets content based on time series.,2 Related Work,[0],[0]
"Recently, they studied to mutually reinforce stance detection and rumor classification in a neural multi-task learning framework (Ma et al., 2018).",2 Related Work,[0],[0]
"However, the approaches cannot embed features reflecting how the posts are propagated and requires careful data segmentation to prepare for time sequence.
",2 Related Work,[0],[0]
Some kernel-based methods were exploited to model the propagation structure.,2 Related Work,[0],[0]
Wu et al. (2015) proposed a hybrid SVM classifier which combines a RBF kernel and a random-walk-based graph kernel to capture both flat and propagation patterns for detecting rumors on Sina Weibo.,2 Related Work,[0],[0]
Ma et al. (2017) used tree kernel to capture the similarity of propagation trees by counting their similar substructures in order to identify different types of rumors on Twitter.,2 Related Work,[0],[0]
"Compared to their studies, our model can learn the useful features via a more natural and general approach, i.e., the tree-structured neural network, to jointly generate representations from both structure and content.
",2 Related Work,[0],[0]
"RvNN has demonstrated state-of-the-art performances in a variety of tasks, e.g., images segmentation (Socher et al., 2011), phrase representation from word vectors (Socher et al., 2012), and sentiment classification in sentences (Socher et al., 2013).",2 Related Work,[0],[0]
"More recently, a deep RvNN was proposed to model the compositionality in natural language for fine-grained sentiment classification by stacking multiple recursive layers (Irsoy
and Cardie, 2014).",2 Related Work,[0],[0]
"In order to avoid gradient vanishing, some studies integrated Long Short Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) to RvNN (Zhu et al., 2015; Tai et al., 2015).",2 Related Work,[0],[0]
Mou et al. (2015) used a convolutional network over tree structures for syntactic tree parsing of natural language sentences.,2 Related Work,[0],[0]
"We define a Twitter rumor detection dataset as a set of claims C = {C1, C2, · · · , C|C|}, where each claim Ci corresponds to a source tweet ri which consists of ideally all its relevant responsive tweets in chronological order, i.e., Ci = {ri, xi1, xi2, · · · , xim}where each xi∗ is a responsive tweet of the root ri.",3 Problem Statement,[0],[0]
"Note that although the tweets are notated sequentially, there are connections among them based on their reply or repost relationships, which can form a propagation tree structure (Wu et al., 2015; Ma et al., 2017) with ri being the root node.
",3 Problem Statement,[0],[0]
"We formulate this task as a supervised classification problem, which learns a classifier f from labeled claims, that is f : Ci → Yi, where Yi takes one of the four finer-grained classes: non-rumor, false rumor, true rumor, and unverified rumor that are introduced in the literature (Ma et al., 2017; Zubiaga et al., 2016b).
",3 Problem Statement,[0],[0]
"An important issue of the tree structure is concerned about the direction of edges, which can result in two different architectures of the model: 1) a bottom-up tree; 2) a top-down tree, which are defined as follows:
• Bottom-up tree takes the similar shape as shown in Figure 1, where responsive nodes always point to their responded nodes and leaf nodes not having any response are laid out at the furthest level.",3 Problem Statement,[0],[0]
"We represent a tree as Ti = 〈Vi, Ei〉, where Vi = Ci which consists of all relevant posts as nodes, and Ei denotes a set of all directed links, where for any u, v ∈",3 Problem Statement,[0],[0]
"Vi, u ← v exists if v responses to u.",3 Problem Statement,[0],[0]
"This structure is similar to a citation network where a response mimics a reference.
",3 Problem Statement,[0],[0]
"• Top-down tree naturally conforms to the direction of information propagation, in which a link u → v means the information flows from u to v and v sees it and provides a response to u. This structure reverses bottomup tree and simulates how information cas-
cades from a source tweet, i.e., the root, to all its receivers, i.e., the decedents, which is similar as (Wu et al., 2015; Ma et al., 2017).",3 Problem Statement,[0],[0]
The core idea of our method is to strengthen the high-level representation of tree nodes by the recursion following the propagation structure over different branches in the tree.,4 RvNN-based Rumor Detection,[0],[0]
"For instance, the responsive nodes confirming or supporting a node (e.g., “I agree”, “be right”, etc) can further reinforce the stance of that node while denial or questioning responses (e.g., “disagree, “really?!)",4 RvNN-based Rumor Detection,[0],[0]
otherwise weaken its stance.,4 RvNN-based Rumor Detection,[0],[0]
"Compared to the kernelbased method using propagation tree (Wu et al., 2015; Ma et al., 2017), our method does not need pairwise comparison among large number of subtrees, and can learn much stronger representation of content following the response structure.
",4 RvNN-based Rumor Detection,[0],[0]
"In this section, we will describe our extension to the standard RvNN for modeling rumor detection based on the bottom-up and top-down architectures presented in Section 3.",4 RvNN-based Rumor Detection,[0],[0]
RvNN is a type of tree-structured neural networks.,4.1 Standard Recursive Neural Networks,[0],[0]
"The original version of RvNN utilized binarized sentence parse trees (Socher et al., 2012), in which the representation associated with each node of a parse tree is computed from its direct children.",4.1 Standard Recursive Neural Networks,[0],[0]
"The overall structure of the standard RvNN is illustrated as the right side of Figure 2, corresponding to the input parse tree at the left side.
",4.1 Standard Recursive Neural Networks,[0],[0]
"Leaf nodes are the words in an input sentence, each represented by a low-dimensional word embedding.",4.1 Standard Recursive Neural Networks,[0],[0]
"Non-leaf nodes are sentence constituents, computed by recursion based on the presentations of child nodes.",4.1 Standard Recursive Neural Networks,[0],[0]
"Let p be the feature vector of a parent node whose children are c1 and c2, the representation of the parent is computed by p = f(W ·[c1; c2]+b), where f(·) is the activation
function withW and b as parameters.",4.1 Standard Recursive Neural Networks,[0],[0]
This computation is done recursively over all tree nodes; the learned hidden vectors of the nodes can then be used for various classification tasks.,4.1 Standard Recursive Neural Networks,[0],[0]
The core idea of bottom-up model is to generate a feature vector for each subtree by recursively visiting every node from the leaves at the bottom to the root at the top.,4.2 Bottom-up RvNN,[0],[0]
"In this way, the subtrees with similar contexts, such as those subtrees having a denial parent and a set of supportive children, will be projected into the proximity in the representation space.",4.2 Bottom-up RvNN,[0],[0]
"And thus such local rumor indicative features are aggregated along different branches into some global representation of the whole tree.
",4.2 Bottom-up RvNN,[0],[0]
"For this purpose, we make a natural extension to the original RvNN.",4.2 Bottom-up RvNN,[0],[0]
"The overall structure of our proposed bottom-up model is illustrated in Figure 3(b), taking a bottom-up tree (see Figure 3(a)) as input.",4.2 Bottom-up RvNN,[0],[0]
"Different from the standard RvNN, the input of each node in the bottom-up model is a post represented as a vector of words in the vocabulary in terms of tfidf values.",4.2 Bottom-up RvNN,[0],[0]
"Here, every node has an input vector, and the number of children of nodes varies significantly3.
",4.2 Bottom-up RvNN,[0],[0]
"In rumor detection, long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) and gated recurrent units (GRU) (Cho et al., 2014) were used to learn textual representation, which adopts memory units to store information over long time steps (Ma et al., 2016).",4.2 Bottom-up RvNN,[0],[0]
"In this paper, we choose to extend GRU as hidden unit to model long-distance interactions over the tree nodes because it is more efficient due to fewer parameters.",4.2 Bottom-up RvNN,[0],[0]
"Let S(j) denote the set of direct children of the node j. The transition equations of node j in the bottom-up model are formulated as follows:
x̃j = xjE hS = ∑
s∈S(j)
hs
rj = σ",4.2 Bottom-up RvNN,[0],[0]
"(Wrx̃j + UrhS)
zj = σ",4.2 Bottom-up RvNN,[0],[0]
"(Wzx̃j + UzhS)
h̃j = tanh (Whx̃j + Uh(hS",4.2 Bottom-up RvNN,[0],[0]
rj)),4.2 Bottom-up RvNN,[0],[0]
hj =,4.2 Bottom-up RvNN,[0],[0]
"(1− zj) hS + zj h̃j
(1)
3In",4.2 Bottom-up RvNN,[0],[0]
"standard RvNN, since an input instance is the parse tree of a sentence, only leaf nodes have input vector, each node representing a word of the input sentence, and the nonleaf nodes are constituents of the sentence, and thus the number of children of a node is limited.
",4.2 Bottom-up RvNN,[0],[0]
"where xj is the original input vector of node j, E denotes the parameter matrix for transforming this input post, x̃j is the transformed representation of j, [W∗, U∗] are the weight connections inside GRU, and hj and hs refer to the hidden state of j and its s-th child.",4.2 Bottom-up RvNN,[0],[0]
"Thus hS denotes the sum of the hidden state of all the children of j assuming that all children are equally important to j. As with the standard GRU, denotes element-wise multiplication; a reset gate rj determines how to combine the current input x̃j with the memory of children, and an update gate zj defines how much memory from the children is cascaded into the current node; and h̃j denotes the candidate activation of the hidden state of the current node.",4.2 Bottom-up RvNN,[0],[0]
"Different from the standard GRU unit, the gating vectors in our variant of GRU are dependent on the states of many child units, allowing our model to incorporate representations from different children.
",4.2 Bottom-up RvNN,[0],[0]
"After recursive aggregation from bottom to up, the state of root node (i.e., source tweet) can be regard as the representation of the whole tree which is used for supervised classification.",4.2 Bottom-up RvNN,[0],[0]
"So, an output layer is connected to the root node for predicting the class of the tree using a softmax function:
ŷ = Softmax(Vh0 + b) (2)
where h0 is the learned hidden vector of root node; V and b are the weights and bias in output layer.",4.2 Bottom-up RvNN,[0],[0]
"This model is designed to leverage the structure of top-down tree to capture complex propagation patterns for classifying rumorous claims, which is shown in Figure 3(c).",4.3 Top-down RvNN,[0],[0]
"It models how the informa-
tion flows from source post to the current node.",4.3 Top-down RvNN,[0],[0]
"The idea of this top-down approach is to generate a strengthened feature vector for each post considering its propagation path, where rumor-indicative features are aggregated along the propagation history in the path.",4.3 Top-down RvNN,[0],[0]
"For example, if current post agree with its parent’s stance which denies the source post, the denial stance from the root node down to the current node on this path should be reinforced.",4.3 Top-down RvNN,[0],[0]
"Due to different branches of any non-leaf node, the top-down visit to its subtree nodes is also recursive.",4.3 Top-down RvNN,[0],[0]
"However, the nature of top-down tree lends this model different from the bottom-up one.",4.3 Top-down RvNN,[0],[0]
The representation of each node is computed by combining its own input and its parent node instead of its children nodes.,4.3 Top-down RvNN,[0],[0]
"This process proceeds recursively from the root node to its children until all leaf nodes are reached.
",4.3 Top-down RvNN,[0],[0]
Suppose that the hidden state of a non-leaf node can be passed synchronously to all its child nodes without loss.,4.3 Top-down RvNN,[0],[0]
Then the hidden state hj of a node j can be computed by combining the hidden state hP(j) of its parent node P(j) and its own input vector xj .,4.3 Top-down RvNN,[0],[0]
"Therefore, the transition equations of node j can be formulated as a standard GRU:
x̃j = xjE rj",4.3 Top-down RvNN,[0],[0]
= σ,4.3 Top-down RvNN,[0],[0]
( Wrx̃j + UrhP(j) ),4.3 Top-down RvNN,[0],[0]
zj = σ,4.3 Top-down RvNN,[0],[0]
"( Wzx̃j + UzhP(j)
) h̃j = tanh",4.3 Top-down RvNN,[0],[0]
"( Whx̃j + Uh(hP(j) rj)
)",4.3 Top-down RvNN,[0],[0]
hj = (1− zj) hP(j),4.3 Top-down RvNN,[0],[0]
"+ zj h̃j (3)
Through the top-down recursion, the learned representations are eventually embedded into the hidden vector of all the leaf nodes.",4.3 Top-down RvNN,[0],[0]
"Since the num-
ber of leaf nodes varies, the resulting vectors cannot be directly fed into a fixed-size neural layer for output.",4.3 Top-down RvNN,[0],[0]
"Therefore, we add a max-pooling layer to take the maximum value of each dimension of the vectors over all the leaf nodes.",4.3 Top-down RvNN,[0],[0]
"This can also help capture the most appealing indicative features from all the propagation paths.
",4.3 Top-down RvNN,[0],[0]
"Based on the pooling result, we finally use a softmax function in the output layer to predict the label of the tree:
ŷ = Softmax(Vh∞ + b) (4)
where h∞ is the pooling vector over all leaf nodes, V and b are parameters in the output layer.
",4.3 Top-down RvNN,[0],[0]
"Although both of the two RvNN models aim to capture the structural properties by recursively visiting all nodes, we can conjecture that the topdown model would be better.",4.3 Top-down RvNN,[0],[0]
"The hypothesis is that in the bottom-up case the final output relies on the representation of single root, and its information loss can be larger than the top-down one since in the top-down case the representations embedded into all leaf nodes along different propagation paths can be incorporated via pooling holistically.",4.3 Top-down RvNN,[0],[0]
"The model is trained to minimize the squared error between the probability distributions of the predictions and the ground truth:
L(y, ŷ) = N∑ n=1 C∑ c=1",4.4 Model Training,[0],[0]
"(yc − ŷc)2 + λ||θ||22 (5)
where yc is the ground truth and ŷc is the prediction probability of a class, N is the number of training claims, C is the number of classes, ||.||2 is the L2 regularization term over all model parameters θ, and λ is the trade-off coefficient.
",4.4 Model Training,[0],[0]
"During training, all the model parameters are updated using efficient back-propagation through structure (Goller and Kuchler, 1996; Socher et al., 2013), and the optimization is gradient-based following the Ada-grad update rule (Duchi et al., 2011) to speed up the convergence.",4.4 Model Training,[0],[0]
"We empirically initialize the model parameters with uniform distribution and set the vocabulary size as 5,000, the size of embedding and hidden units as 100.",4.4 Model Training,[0],[0]
We iterate over all the training examples in each epoch and continue until the loss value converges or the maximum epoch number is met.,4.4 Model Training,[0],[0]
"For experimental evaluation, we use two publicly available Twitter datasets released by Ma et al. (2017), namely Twitter15 and Twitter164, which respectively contains 1,381 and 1,181 propagation trees (see (Ma et al., 2017) for detailed statistics).",5.1 Datasets,[0],[0]
"In each dataset, a group of wide spread source tweets along with their propagation threads, i.e., replies and retweets, are provided in the form of tree structure.",5.1 Datasets,[0],[0]
"Each tree is annotated with one of the four class labels, i.e., non-rumor, false rumor, true rumor and unverified rumor.",5.1 Datasets,[0],[0]
We remove the retweets from the trees since they do not provide any extra information or evidence contentwise.,5.1 Datasets,[0],[0]
"We build two versions for each tree, one for the bottom-up tree and the other for the top-down tree, by flipping the edges’ direction.",5.1 Datasets,[0],[0]
"We make comprehensive comparisons between our models and some state-of-the-art baselines on rumor classification and early detection tasks.
- DTR: Zhao et al. (2015) proposed a DecisionTree-based Ranking model to identify trending rumors by searching for inquiry phrases.
- DTC: The information credibility model using a Decision-Tree Classifier (Castillo et al., 2011) based on manually engineering various statistical features of the tweets.
- RFC:",5.2 Experimental Setup,[0],[0]
"The Random Forest Classier using 3 fitting parameters as temporal properties and a set of handcrafted features on user, linguistic and structural properties (Kwon et al., 2013).
- SVM-TS: A linear SVM classifier that uses time-series to model the variation of handcrafted social context features (Ma et al., 2015).
- SVM-BOW: A naive baseline we built by representing text content using bag-of-words and using linear SVM for rumor classification.
- SVM-TK and SVM-HK: SVM classifier uses a Tree Kernel (Ma et al., 2017) and that uses a Hybrid Kernel (Wu et al., 2015), respectively, both of which model propagation structures with kernels.
- GRU-RNN: A detection model based on recurrent neural networks (Ma et al., 2016) with GRU units for learning rumor representations by modeling sequential structure of relevant posts.
4https://www.dropbox.com/s/ 7ewzdrbelpmrnxu/rumdetect2017.zip?dl=0
- BU-RvNN and TD-RvNN: Our bottom-up and top-down RvNN models, respectively.
",5.2 Experimental Setup,[0],[0]
"We implement DTC and RFC using Weka5, SVM-based models using LibSVM6 and all neural-network-based models with Theano7.",5.2 Experimental Setup,[0],[0]
We conduct 5-fold cross-validation on the datasets and use accuracy over all the four categories and F1 measure on each class to evaluate the performance of models.,5.2 Experimental Setup,[0],[0]
"As shown in Table 1, our proposed models basically yield much better performance than other methods on both datasets via the modeling of interaction structures of posts in the propagation.
",5.3 Rumor Classification Performance,[0],[0]
"It is observed that the performance of the 4 baselines in the first group based on handcrafted features is obviously poor, varying between 0.409 and 0.585 in accuracy, indicating that they fail to generalize due to the lack of capacity capturing helpful features.",5.3 Rumor Classification Performance,[0],[0]
"Among these baselines, SVMTS and RFC perform relatively better because they
5www.cs.waikato.ac.nz/ml/weka 6www.csie.ntu.edu.tw/˜cjlin/libsvm 7deeplearning.net/software/theano
use additional temporal traits, but they are still clearly worse than the models not relying on feature engineering.",5.3 Rumor Classification Performance,[0],[0]
DTR uses a set of regular expressions indicative of stances.,5.3 Rumor Classification Performance,[0],[0]
"However, only 19.6% and 22.2% tweets in the two datasets contain strings covered by these regular expressions, rendering unsatisfactory result.
",5.3 Rumor Classification Performance,[0],[0]
"Among the two kernel methods that are based on comparing propagation structures, we observe that SVM-TK is much more effective than SVMHK.",5.3 Rumor Classification Performance,[0],[0]
"There are two reasons: 1) SVM-HK was originally proposed and experimented on Sina Weibo (Wu et al., 2015), which may not be generalize well on Twitter.",5.3 Rumor Classification Performance,[0],[0]
"2) SVM-HK loosely couples two separate kernels: a RBF kernel based on handcrafted features, plus a random walk-based kernel which relies on a set of pre-defined keywords for jumping over the nodes probabilistically.",5.3 Rumor Classification Performance,[0],[0]
This under utilizes the propagation information due to such oversimplified treatment of tree structure.,5.3 Rumor Classification Performance,[0],[0]
"In contrast, SVM-TK is an integrated kernel and can fully utilize the structure by comparing the trees based on both textual and structural similarities.
",5.3 Rumor Classification Performance,[0],[0]
It appears that using bag-of-words is already a decent model evidenced as the fairly good performance of SVM-BOW which is even better than SVM-HK.,5.3 Rumor Classification Performance,[0],[0]
"This is because the features of SVMHK are handcrafted for binary classification (i.e., non-rumor vs rumor), ignoring the importance of indicative words or units that benefit finer-grained classification which can be captured more effectively by SVM-BOW.
",5.3 Rumor Classification Performance,[0],[0]
"The sequential neural model GRU-RNN performs slightly worse than SVM-TK, but much worse than our recursive models.",5.3 Rumor Classification Performance,[0],[0]
This is because it is a special case of the recursive model where each non-leaf node has only one child.,5.3 Rumor Classification Performance,[0],[0]
"It has to rely on a linear chain as input, which missed out valuable structural information.",5.3 Rumor Classification Performance,[0],[0]
"However, it does learn high-level features from the post content via hidden units of the neural model while SVM-TK cannot which can only evaluates similarities based on the overlapping words among subtrees.",5.3 Rumor Classification Performance,[0],[0]
"Our recursive models are inherently tree-structured and take advantages of representation learning following the propagation structure, thus beats SVM-TK.
",5.3 Rumor Classification Performance,[0],[0]
"In the two recursive models, TD-RvNN outperforms BU-RvNN, which indicates that the bottomup model may suffer from larger information loss than the top-down one.",5.3 Rumor Classification Performance,[0],[0]
"This verifies the hypothesis we made in Section 4.3 that the pooling layer
in the top-down model can effectively select important features embedded into the leaf nodes.
",5.3 Rumor Classification Performance,[0],[0]
"For only the non-rumor class, it seems that our method does not perform so well as some featureengineering baselines.",5.3 Rumor Classification Performance,[0],[0]
"This can be explained by the fact that these baselines are trained with additional features such as user information (e.g., profile, verification status, etc) which may contain clues for differentiating non-rumors from rumors.",5.3 Rumor Classification Performance,[0],[0]
"Also, the responses to non-rumors are usually much more diverse with little informative indication, making identification of non-rumors more difficult based on content even with the structure.",5.3 Rumor Classification Performance,[0],[0]
Detecting rumors at early state of propagation is important so that interventions can be made in a timely manner.,5.4 Early Rumor Detection Performance,[0],[0]
We compared different methods in term of different time delays measured by either tweet count received or time elapsed since the source tweet is posted.,5.4 Early Rumor Detection Performance,[0],[0]
"The performance is evaluated by the accuracy obtained when we incrementally add test data up to the check point given the targeted time delay or tweets volume.
",5.4 Early Rumor Detection Performance,[0],[0]
Figure 4 shows that the performance of our recursive models climbs more rapidly and starts to supersede the other models at the early stage.,5.4 Early Rumor Detection Performance,[0],[0]
"Although all the methods are getting to their best per-
formance in the end, TD-RvNN and BU-RvNN only need around 8 hours or about 90 tweets to achieve the comparable performance of the best baseline model, i.e., SVM-TK, which needs about 36 hours or around 300 posts, indicating superior early detection performance of our method.
",5.4 Early Rumor Detection Performance,[0],[0]
Figure 5 shows a sample tree at the early stage of propagation that has been correctly classified as a false rumor by both recursive models.,5.4 Early Rumor Detection Performance,[0],[0]
"We can see that this false rumor demonstrates typical patterns in subtrees and propagation paths indicative of the falsehood, where a set of responses supporting the parent posts that deny or question the source post are captured by our bottom-up model.",5.4 Early Rumor Detection Performance,[0],[0]
"Similarly, some patterns of propagation from the root to leaf nodes like “support→deny→support” are also seized by our top-down model.",5.4 Early Rumor Detection Performance,[0],[0]
"In comparison, sequential models may be confused because the supportive key terms such as “be right”, “yeah”, “exactly!” dominate the responses, and the SVM-TK may miss similar subtrees by just comparing the surface words.",5.4 Early Rumor Detection Performance,[0],[0]
We propose a bottom-up and a top-down treestructured model based on recursive neural networks for rumor detection on Twitter.,6 Conclusions and Future Work,[0],[0]
"The inher-
ent nature of recursive models allows them using propagation tree to guide the learning of representations from tweets content, such as embedding various indicative signals hidden in the structure, for better identifying rumors.",6 Conclusions and Future Work,[0],[0]
"Results on two public Twitter datasets show that our method improves rumor detection performance in very large margins as compared to state-of-the-art baselines.
",6 Conclusions and Future Work,[0],[0]
"In our future work, we plan to integrate other types of information such as user properties into the structured neural models to further enhance representation learning and detect rumor spreaders at the same time.",6 Conclusions and Future Work,[0],[0]
We also plan to use unsupervised models for the task by exploiting structural information.,6 Conclusions and Future Work,[0],[0]
"This work is partly supported by Innovation and Technology Fund (ITF) Project No. 6904333, and General Research Fund (GRF) Project",Acknowledgment,[0],[0]
No. 14232816 (12183516).,Acknowledgment,[0],[0]
We would like to thank anonymous reviewers for the insightful comments.,Acknowledgment,[0],[0]
Automatic rumor detection is technically very challenging.,abstractText,[0],[0]
"In this work, we try to learn discriminative features from tweets content by following their non-sequential propagation structure and generate more powerful representations for identifying different type of rumors.",abstractText,[0],[0]
"We propose two recursive neural models based on a bottom-up and a top-down tree-structured neural networks for rumor representation learning and classification, which naturally conform to the propagation layout of tweets.",abstractText,[0],[0]
Results on two public Twitter datasets demonstrate that our recursive neural models 1) achieve much better performance than state-of-the-art approaches; 2) demonstrate superior capacity on detecting rumors at very early stage.,abstractText,[0],[0]
Rumor Detection on Twitter with Tree-structured Recursive Neural Networks,title,[0],[0]
"Submodular Functions (Fujishige, 2005) are a special class of set functions, which have rich structures and a lot of links
1Tencent AI Lab 2State Key Lab of CAD&CG, Zhejiang University.",1. Introduction,[0],[0]
Correspondence to: Weizhong Zhang,1. Introduction,[0],[0]
<zhangweizhongzju@gmail.com,1. Introduction,[0],[0]
">, Bin Hong <hongbinzju@gmail.com>, Lin Ma <forest.linma@gmail.com>, Wei Liu <wl2223@columbia.edu>, Tong Zhang <tongzhang@tongzhang-ml.org>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
with convex functions.",1. Introduction,[0],[0]
"They arise naturally in many domains, such as clustering (Narasimhan & Bilmes, 2007), image segmentation (Kolmogorov & Zabin, 2004; Cevher et al., 2009), document summarization (Lin & Bilmes, 2011a), etc.",1. Introduction,[0],[0]
"Most of these applications can be finally deduced to a Submodular Function Minimization (SFM) problem:
min A⊆V F (A), (SFM)
where F (A) is a submodular function defined on a set V .",1. Introduction,[0],[0]
"The problem of SFM has been extensively studied for several decades in the literatures (Edmonds, 1970; Lovász, 1983; McCormick, 2005; Wu et al., 2016; Ene et al., 2017), in which many algorithms have been developed from the perspectives of combinatorial optimization and convex optimization.",1. Introduction,[0],[0]
"The most well-known conclusion is that SFM is solvable in strongly polynomial time (Iwata et al., 2001).",1. Introduction,[0],[0]
"Unfortunately, due to the high-degree polynomial dependence, the applications of submodular functions on the large scale problems remain challenging, such as image segmentation (Cevher et al., 2009) and speech analysis (Lin & Bilmes, 2011b), which both involve a huge number of variables.
",1. Introduction,[0],[0]
"Screening (El Ghaoui et al., 2012) is an emerging technique, which has been proved to be effective in accelerating large-scale sparse model training.",1. Introduction,[0],[0]
It is motivated by the well-known feature of sparse models that a significant portion of the coefficients in the optimal solutions of them (resp.,1. Introduction,[0],[0]
"their dual problems) are zeros, that is, the corresponding features (resp. samples) are irrelevant with the final learned models.",1. Introduction,[0],[0]
Screening methods aim to quickly identify these irrelevant features and/or samples and remove them from the datasets before or during the training process.,1. Introduction,[0],[0]
"Thus, the problem size can be reduced dramatically, leading to substantial savings in the computational cost.",1. Introduction,[0],[0]
The framework of these methods is given in Algorithm 1.,1. Introduction,[0],[0]
"Since screening methods are always independent of the training algorithms, they can be integrated with all the algorithms flexibly.",1. Introduction,[0],[0]
"In the recent few years, specific screening methods for most of the traditional sparse models have been developed, such as Lasso (Tibshirani et al., 2012; Wang et al., 2013; Wang & Ye, 2015), sparse logistic regression (Wang et al., 2014), multi-task learning (Ndiaye et al., 2015) and SVM (Ogawa et al., 2013; Zhang et al., 2017).",1. Introduction,[0],[0]
"Empirical studies indicate that the speedups they achieved can be orders of magnitudes.
",1. Introduction,[0],[0]
"Algorithm 1 Framework of screening in sparse learning 1: Estimate the dual (resp. primal) optimum of the sparse
model.",1. Introduction,[0],[0]
"2: Based on the estimation above, infer which components
of the primal (resp.",1. Introduction,[0],[0]
dual ) optimum are zeros from the KKT conditions.,1. Introduction,[0],[0]
3: Remove the features (resp. samples) corresponding to the identified components.,1. Introduction,[0],[0]
"4: Train the model on the reduced dataset.
",1. Introduction,[0],[0]
The binary attribute (each element in V must be either in or not in the optimal solution) of SFM motivates us to introduce the key idea of screening into SFM to accelerate its optimization process.,1. Introduction,[0],[0]
The most intuitive approach is to identify the elements that are guaranteed to be included or excluded in the minimizer A∗ of SFM prior to or during actually solving it.,1. Introduction,[0],[0]
"Then, by fixing the identified active elements and removing the inactive ones, we just need to solve a small-scale problem.",1. Introduction,[0],[0]
"However, we note that existing screening methods are all developed for convex models and they cannot be applied to SFM directly.",1. Introduction,[0],[0]
"The reason is that they all heavily depend on KKT conditions (see Algorithm 1), which do not exist in SFM problems.
",1. Introduction,[0],[0]
"In this paper, to improve the efficiency of SFM algorithms, we propose a novel Inactive and Active Element Screening (IAES) framework for SFM, which consists of two kinds of screening rules, i.e., Inactive Elements Screening (IES) and Active Elements Screening (AES).",1. Introduction,[0],[0]
"As we analyze above, the major challenge in developing IAES is the absence of KKT conditions.",1. Introduction,[0],[0]
"We bypass this obstacle by carefully studying the relationship between SFM and convex optimization, which can be regarded as another form of KKT conditions.",1. Introduction,[0],[0]
"We find that SFM is closely related to a particular convex primal and dual problem pair Q-P and Q-D (see Section 2), that is, the minimizer of SFM can be obtained from the positive components of the optimum of problem Q-P. Hence, the proposed IAES identifies the active and inactive elements by estimating the lower and upper bounds of the components of the optimum of problem Q-P. Thus, one of our major technical contributions is a novel framework (Section 3)—developed by carefully studying the strong convexity of the corresponding primal and dual objective functions, the structure of the base polyhedra, and the optimality conditions of the SFM problem—for deriving accurate optimum estimation of problem Q-P. We integrate IAES with the solver for problems Q-P and Q-D. As the solver goes on, and the estimation becomes more and more accurate, IAES can identify more and more elements.",1. Introduction,[0],[0]
"By fixing the active elements and removing the inactive ones, the problem size can be reduced gradually.",1. Introduction,[0],[0]
IAES is safe in the sense that it would never sacrifice any accuracy on the final output.,1. Introduction,[0],[0]
"To the best of our knowledge, IAES is the first screening
method in the domain of SFM or even combinatorial optimization.",1. Introduction,[0],[0]
"Moreover, compared with the screening methods for sparse models, an outstanding feature of IAES is that it has no theoretical limit in reducing the problem size.",1. Introduction,[0],[0]
"That is, we can finally reduce the problem size to zero, leading to substantial savings in the computational cost.",1. Introduction,[0],[0]
"The reason is that as the optimization proceeds, our estimation will be accurate enough to infer the affiliations of all the elements with the optimizer A∗.",1. Introduction,[0],[0]
"While in sparse models, screening methods can never reduce the problem size to zero since the features (resp. samples) with nonzero coefficients in the primal (resp. dual) optimum can never be removed.",1. Introduction,[0],[0]
Experiments (see Section 4) on both synthetic and real datasets demonstrate the significant speedups gained by IAES.,1. Introduction,[0],[0]
"For the convenience of presentation, we postpone the detailed proofs of theoretical results in the main text to the supplementary materials.
Notations: We consider a set V = {1, ..., p}, and denote its power set by 2V , which is composed of 2p subsets of V .",1. Introduction,[0],[0]
"|A| is the cardinality of a set A. A∪B and A∩B are the union and intersection of the sets A and B, respectively.",1. Introduction,[0],[0]
"A ⊆ B means that A is a subset of B, potentially being equal to B. Moreover, for w ∈",1. Introduction,[0],[0]
"Rp and α ∈ R, we let [w]k be the k-th component of w and {w ≥ α} (resp.",1. Introduction,[0],[0]
{w > α}) be the weak (resp.,1. Introduction,[0],[0]
"strong) α-sup-level set of w defined as {k : k ∈ V,",1. Introduction,[0],[0]
[w]k ≥ α} (resp.,1. Introduction,[0],[0]
"{k : k ∈ V, [w]k > α}).",1. Introduction,[0],[0]
"At last, for s ∈ Rp, we define a set function by s(A) = ∑ k∈A[s]k.",1. Introduction,[0],[0]
"This section is composed of two parts: a) briefly review some basics of submodular functions, SFM, and their relations with convex optimization; b) motivate our screening method IAES.
",2. Basics and Motivations,[0],[0]
"The followings are the definitions of submodular function, submodular polyhedra and base polyhedra, which play an important role in submodular analysis.",2. Basics and Motivations,[0],[0]
Definition 1.,2. Basics and Motivations,[0],[0]
"[Submodular Function (McCormick, 2005)]",2. Basics and Motivations,[0],[0]
"A set function F : 2V → R is submodular if and only if for all subsets A,B ⊆ V we have:
F (A) + F (B) ≥",2. Basics and Motivations,[0],[0]
F (A ∪B) + F,2. Basics and Motivations,[0],[0]
"(A ∩B).
",2. Basics and Motivations,[0],[0]
Definition 2.,2. Basics and Motivations,[0],[0]
"[Submodular and Base Polyhedra (Fujishige, 2005)] Let F be a submodular function such that F (∅) = 0.",2. Basics and Motivations,[0],[0]
"The submodular polyhedra P (F ) and the base polyhedra B(F ) are defined as:
P (F )={",2. Basics and Motivations,[0],[0]
"s∈ Rp : ∀A ⊆ V, s(A) ≤",2. Basics and Motivations,[0],[0]
"F (A)}, B(F )={",2. Basics and Motivations,[0],[0]
"s∈ Rp : s(V ) = F (V ),∀A ⊆ V, s(A) ≤",2. Basics and Motivations,[0],[0]
"F (A)}.
",2. Basics and Motivations,[0],[0]
"Below we give the definition of Lovász extension, which works as the bridge that connects submodular functions and convex functions.
",2. Basics and Motivations,[0],[0]
Definition 3.,2. Basics and Motivations,[0],[0]
"[Lovász Extension (Fujishige, 2005)]",2. Basics and Motivations,[0],[0]
"Given a set-function F such that F (∅) = 0, the Lovász extension f :",2. Basics and Motivations,[0],[0]
Rp → R is defined as follows: for w ∈,2. Basics and Motivations,[0],[0]
"Rp, order the components in a decreasing order [w]j1 ≥ ...",2. Basics and Motivations,[0],[0]
≥,2. Basics and Motivations,[0],[0]
"[w]jp , and define f(w) through the equation below,
f(w) = p∑",2. Basics and Motivations,[0],[0]
k=1,2. Basics and Motivations,[0],[0]
"[w]jk ( F ({j1, ..., jk})− F ({j1, ..., jk−1}) ) .
Lovász extension f(w) is convex if and only if F is submodular (see (Fujishige, 2005)).
",2. Basics and Motivations,[0],[0]
"We focus on the generic submodular function minimization problem SFM defined in Section 1 and denote its minimizer as A∗. To reveal the relationship between SFM and convex optimization and finally motivate our method, we need the following theorems.",2. Basics and Motivations,[0],[0]
Theorem 1.,2. Basics and Motivations,[0],[0]
"Let ψ1, ..., ψp be p convex functions on R, ψ∗1 , ..., ψ ∗ p be their Fenchel-conjugates (Borwein & Lewis, 2010), and f be the Lovász extension of a submodular function F .",2. Basics and Motivations,[0],[0]
Denote the subgradient of ψk(·) by ∂ψk(·).,2. Basics and Motivations,[0],[0]
"Then, the followings hold: (i)",2. Basics and Motivations,[0],[0]
"The problems below are dual of each other:
min w∈Rp f(w) + p∑ j=1 ψj([w]j), (P)
max s∈B(F )",2. Basics and Motivations,[0],[0]
− p∑ j=1 ψ∗j (−[s]j).,2. Basics and Motivations,[0],[0]
"(D)
(ii)",2. Basics and Motivations,[0],[0]
"The pair (w∗, s∗) is optimal for problems (P) and (D) if and only if{
(a): [s]∗k ∈ −∂ψk([w]∗k),∀k ∈ V, (b): w∗ ∈",2. Basics and Motivations,[0],[0]
"NB(F )(s∗),
(Opt)
where NB(F )(s∗) is the normal cone (see Chapter 2 of (Borwein & Lewis, 2010)) of B(F ) at s∗.
When ψj(·) is differentiable, we consider a sequence of set optimization problems parameterized by α ∈ R:
min A⊆V F (A) +",2. Basics and Motivations,[0],[0]
"∑ j∈A ∇ψj(α), (SFM’)
",2. Basics and Motivations,[0],[0]
where ∇ψj(·) is the gradient of ψk(·).,2. Basics and Motivations,[0],[0]
The problem SFM’ has tight connections with the convex optimization problem P (see the theorem below).,2. Basics and Motivations,[0],[0]
Theorem 2.,2. Basics and Motivations,[0],[0]
"[Submodular function minimization from the proximal problem, Proposition 8.4 in (Bach et al., 2013)]",2. Basics and Motivations,[0],[0]
"Under the same assumptions in Theorem 1, if ψj(·) is differentiable for all j ∈ V and w∗ is the unique minimizer of problem P, then for all α ∈ R, the minimal minimizer of problem SFM’ is {u > α} and the maximal minimizer is {u ≥ α}, that is, for any minimizers",2. Basics and Motivations,[0],[0]
"A∗α we have:
{w∗ > α} ⊆",2. Basics and Motivations,[0],[0]
A∗α ⊆ {w∗ ≥ α}.,2. Basics and Motivations,[0],[0]
"(1)
By choosing ψj(x) = 12x 2 and α = 0 in SFM’, combining Theorems 1 and 2, we can see that SFM can be reduced to the following primal and dual problems, one is a quadratic optimization problem and the other is equivalent to finding the minimum norm point in the base polytope B(F ):
min w∈Rp
P (w) := f(w) + 1
2 ‖w‖22, (Q-P)
max s∈B(F ) D(s) :",2. Basics and Motivations,[0],[0]
= −1 2 ‖s‖22.,2. Basics and Motivations,[0],[0]
"(Q-D)
",2. Basics and Motivations,[0],[0]
"According to (1), we can define two index sets:
E := {j ∈ V :",2. Basics and Motivations,[0],[0]
"[w]∗j > 0}, and G := {j ∈ V :",2. Basics and Motivations,[0],[0]
"[w]∗j < 0},
which imply that
(i): j ∈ E ⇒ j ∈ A∗, (R1) (ii): j ∈ G ⇒",2. Basics and Motivations,[0],[0]
j /∈,2. Basics and Motivations,[0],[0]
"A∗. (R2)
",2. Basics and Motivations,[0],[0]
"We call the j-th element active if j ∈ E and the ones in G inactive.
",2. Basics and Motivations,[0],[0]
"Suppose that we are given two subsets of E and G, by rules R1 and R2, we can see that many affiliations between A∗ and the elements of V can be deduced.",2. Basics and Motivations,[0],[0]
"Thus, we have less unknowns to solve in SFM and its size can be dramatically reduced.",2. Basics and Motivations,[0],[0]
We formalize this idea in Lemma 1.,2. Basics and Motivations,[0],[0]
Lemma 1.,2. Basics and Motivations,[0],[0]
"Given two subsets Ĝ ⊆ G and Ê ⊆ E , the followings hold:
(i): Ê ⊆ A∗, and for all j ∈ Ĝ we have j /∈",2. Basics and Motivations,[0],[0]
"A∗.
(ii):",2. Basics and Motivations,[0],[0]
"The problem SFM can be reduced to the following scaled problem:
min C⊆V/(Ê∪Ĝ)
F̂ (C) := F (Ê ∪ C)− F (Ê), (scaled-SFM)
which is also an SFM problem.
",2. Basics and Motivations,[0],[0]
"(iii): A∗ can be recovered by A∗ = Ê ∪ C∗, where C∗ is the minimizer of scaled-SFM.
",2. Basics and Motivations,[0],[0]
"Lemma 1 indicates that, if we can identify the active set Ê and inactive set Ĝ, we only need to solve a scaled problem scaled-SFM, which may have much smaller size than the original problem SFM, to exactly recover the optimal solution A∗ without sacrificing any accuracy.
",2. Basics and Motivations,[0],[0]
"However, since w∗ is unknown, we cannot directly apply rules R1 and R2 to identify the active set Ê and inactive set Ĝ.",2. Basics and Motivations,[0],[0]
"Inspired by the ideas in the gap safe screening methods ((Fercoq et al., 2015; Ndiaye et al., 2016; Shibagaki et al., 2016)) for convex problems, we can first estimate the region W that contains w∗ and then relax the rules R1 and R2 to the practicable versions.",2. Basics and Motivations,[0],[0]
"Specifically, we first denote
Ê := {j ∈ V : min w∈W",2. Basics and Motivations,[0],[0]
"[w]j > 0}, (2)
Ĝ := {j ∈ V : max w∈W",2. Basics and Motivations,[0],[0]
[w]j < 0}.,2. Basics and Motivations,[0],[0]
"(3)
It is obvious that Ê ⊆ E and Ĝ",2. Basics and Motivations,[0],[0]
"⊆ G. Hence, the rules R1 and R2 can be relaxed as follows:
(i): j ∈ Ê ⇒",2. Basics and Motivations,[0],[0]
"j ∈ A∗, (R1’) (ii): j ∈ Ĝ ⇒",2. Basics and Motivations,[0],[0]
j /∈,2. Basics and Motivations,[0],[0]
"A∗. (R2’)
",2. Basics and Motivations,[0],[0]
"In view of the rules R1’ and R2’, we sketch the development of IAES as follows: Step 1: Derive the estimationW such that w∗ ∈ W .",2. Basics and Motivations,[0],[0]
Step 2: Develop IAES via deriving the detailed screening rules R1’ and R2’.,2. Basics and Motivations,[0],[0]
"In this section, we first present the accurate optimum estimation by carefully studying the strong convexity of the functions P (w) andD(s), the optimality conditions of SFM and its relationship with the convex problem pair (see Section 3.1).",3. The Proposed Element Screening Method,[0],[0]
"Then, in Section 3.2, we develop our inactive and active element screening rules IES and AES step by step.",3. The Proposed Element Screening Method,[0],[0]
"At last, in Section 3.3, we develop the screening framework IAES by an alternating application of IES and AES.",3. The Proposed Element Screening Method,[0],[0]
"Let Ê and Ĝ be the active and inactive sets identified by the previous IAES steps (before applying IAES for the first time, they are ∅).",3.1. Optimum Estimation,[0],[0]
"From Lemma 1, we know that the problem SFM then can be reduced to the following scaled problem:
min C⊆V̂
F̂ (C)",3.1. Optimum Estimation,[0],[0]
":= F (Ê ∪ C)− F (Ê),
where V̂ = V/(Ê ∪ Ĝ).",3.1. Optimum Estimation,[0],[0]
The second term−F (Ê) at the right side of the equation above is added to make F̂ (∅) = 0.,3.1. Optimum Estimation,[0],[0]
"Thus, the corresponding problems Q-P and Q-D then become:
min ŵ∈Rp̂
P̂ (ŵ) := f̂(ŵ) + 1
2 ‖ŵ‖22, (Q-P’)
",3.1. Optimum Estimation,[0],[0]
max ŝ∈B(F̂ ),3.1. Optimum Estimation,[0],[0]
D̂(ŝ),3.1. Optimum Estimation,[0],[0]
":= −1 2 ‖ŝ‖22, (Q-D’)
where f̂(ŵ) is the Lovász extension of F̂ and p̂ = |V/(Ê ∪ Ĝ)|.",3.1. Optimum Estimation,[0],[0]
"Now, we turn to estimate the minimizer ŵ∗ of the problem Q-P’.",3.1. Optimum Estimation,[0],[0]
"The result is presented in the theorem below.
",3.1. Optimum Estimation,[0],[0]
Theorem 3.,3.1. Optimum Estimation,[0],[0]
"For any ŵ ∈ domP̂ (ŵ), ŝ ∈ B(F̂ ) and C ⊆ V̂ , we denote the dual gap as G(ŵ, ŝ) = P̂ (ŵ)",3.1. Optimum Estimation,[0],[0]
"− D̂(ŝ), and then we have
ŵ∗ ∈",3.1. Optimum Estimation,[0],[0]
"W = B ∩ Ω ∩ P,
where B = { w : ‖w − ŵ‖ ≤",3.1. Optimum Estimation,[0],[0]
"√ 2G(ŵ, ŝ) } , Ω = { w :
F̂ (V̂ ) − 2F̂ (C) ≤ ‖w‖1 ≤ ‖ŝ‖1 } , and P = { w :
〈w,1〉 = −F̂ (V̂ ) } .
",3.1. Optimum Estimation,[0],[0]
"From the theorem above, we can see that the estimation W is the intersection of three sets: the ball B, the `1-norm equipped spherical shell Ω and the planeP .",3.1. Optimum Estimation,[0],[0]
"As the optimizer goes on, the dual gapG(ŵ, ŝ) becomes smaller, and F̂ (V̂ )",3.1. Optimum Estimation,[0],[0]
"− 2F̂ (C) and ‖ŵ‖1 would converge to ‖ŵ∗‖1 (see Chapter 7 of (Bach et al., 2013)).",3.1. Optimum Estimation,[0],[0]
"Thus, the volumes of B and Ω become smaller and smaller during the optimization process, and the estimationW would be more and more accurate.",3.1. Optimum Estimation,[0],[0]
"We now turn to develop the screening rules IES and AES based on the estimation of the optimum ŵ∗.
From (2) and (3), we can see that, to develop the screening rules we need to solve two problems: minw∈W",3.2. Inactive and Active Element Screening,[0],[0]
[w]j and maxw∈W,3.2. Inactive and Active Element Screening,[0],[0]
[w]j .,3.2. Inactive and Active Element Screening,[0],[0]
"However, since W is highly non-convex and has a complex structure, it is very hard to solve these two problems efficiently.",3.2. Inactive and Active Element Screening,[0],[0]
"Hence, we rewrite the estimation W asW =",3.2. Inactive and Active Element Screening,[0],[0]
(B ∩ P) ∩,3.2. Inactive and Active Element Screening,[0],[0]
"(B ∩ Ω), and develop two different screening rules on B ∩ P and B ∩ Ω, respectively.",3.2. Inactive and Active Element Screening,[0],[0]
"Given the estimation B ∩ P , we derive the screening rules by solving the following problems
min w∈B∩P",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
[w]j and max w∈B∩P,3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"[w]j .
We show that both of the two problems above admit closedform solutions.",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
Lemma 2.,3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"Given the estimation ball B, the plane P and the active and inactive sets Ê and Ĝ, which are identified in the previous IAES steps, for all j ∈ [p̂] we denote
bj = 2 (∑ i 6=j [ŵ]i + F̂ (V̂ )− (p̂− 1)[ŵ]j ) ,
cj =",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
(∑ i 6=j [ŵ]i + F̂ (V̂ ) )2,3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"− (p̂− 1) ( 2G(ŵ, ŝ)− [ŵ]2j ) .
",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"Then the followings hold:
(i): min w∈B∩P",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"[w]j = [w] min j :=
−bj",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"− √ b2j − 4p̂cj
2p̂",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
",
(ii): max w∈B∩P",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"[w]j = [w] max j :=
−bj + √ b2j − 4p̂cj
2p̂ .
",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
We are now ready to present the active and inactive screening rules AES-1 and IES-1.,3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
Theorem 4.,3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"Given the active and inactive sets Ê and Ĝ, which are identified in the previous IAES steps, we have
(i): The active element screening rule takes the form of
[w]minj > 0⇒ j ∈ A∗,∀j ∈ V/(Ê ∪ Ĝ).",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"(AES-1)
(ii): The inactive element screening rule takes the form of
[w]maxj < 0⇒ j /∈",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"A∗,∀j ∈ V/(Ê ∪ Ĝ).",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"(IES-1)
(iii): The active and inactive sets Ê and Ĝ can be updated by
Ê ← Ê ∪∆Ê , (4) Ĝ ← Ĝ ∪∆Ĝ, (5)
where ∆Ê and ∆Ĝ are the newly identified active and inactive sets defined as
∆Ê := {j ∈ V/(Ê ∪ Ĝ) :",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"[w]minj > 0},
∆Ĝ := {j ∈ V/(Ê ∪ Ĝ) :",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"[w]maxj < 0}.
From the theorem above, we can see that our rules AES-1 and IES-1 are safe in the sense that the detected elements are guaranteed to be included or excluded in A∗.",3.2.1. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ P,[0],[0]
"We now derive the second screening rule pair based on the estimation B ∩ Ω.
Due to the high non-convexity and complex structure of B ∩ Ω, directly solving problems minw∈B∩Ω[w]j and maxw∈B∩Ω[w]j is time consuming.",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"Notice that, to derive IAS and IES, we only need to judge whether the inequalities minw∈B∩Ω[w]j > 0 and maxw∈B∩Ω[w]j < 0 are satisfied or not, instead of calculating minw∈B∩Ω[w]j and maxw∈B∩Ω[w]j .",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"Hence, we only need to infer the hypotheses { w : w ∈ B,",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
[w]j ≤ 0 } ∩ Ω = ∅,3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"and{
w : w ∈ B,",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
[w]j ≥ 0 } ∩ Ω = ∅ are true or false.,3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"Thus, from the formulation of Ω (see Theorem 3), the problems boil down to calculating the minimum and the maximum of ‖w‖1 with { w : w ∈ B,",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"[w]j ≥ 0 } or{
w : w ∈ B,",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"[w]j ≤ 0 }
, which admit closed-form solutions.",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"The results are presented in the lemma below.
",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
Lemma 3.,3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"Given the estimation ball B and the active and inactive sets Ê and Ĝ, which are identified in the previous IAES steps, then the followings hold:
(i): ∀j ∈ p̂, if |[ŵ]j | > √
2G(ŵ, ŝ), then the element j can be identified by rule AES-1 or IES-1 to be active or inactive.",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"(ii): ∀j ∈ p̂, if 0 <",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"[ŵ]j ≤ √ 2G(ŵ, ŝ), we have
min w∈B,[w]j≤0
‖w‖1 < ‖ŵ‖1,
max w∈B,[w]j≤0
‖w‖1
= ‖ŵ‖1−2[ŵ]j+ √ 2p̂G(ŵ,ŝ), if [ŵ]j− √ 2G(ŵ,ŝ) p̂ <0,
‖ŵ‖1−[ŵ]j+ √ p̂−1 √ 2G(ŵ,ŝ)−[ŵ]2j , otherwise.
",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"(iii): ∀j ∈ p̂, if − √ 2G(ŵ, ŝ) ≤",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"[ŵ]j < 0, we have
min w∈B,[w]j≥0
‖w‖1 < ‖ŵ‖1,
max w∈B,[w]j≥0
‖w‖1
= ‖ŵ‖1+2[ŵ]j+ √ 2p̂G(ŵ,ŝ), if [ŵ]j+ √ 2G(ŵ,ŝ) p̂",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
">0,
‖ŵ‖1+[ŵ]j+ √ p̂−1 √ 2G(ŵ,ŝ)−[ŵ]2j , otherwise.
",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
We are now ready to present the second active and inactive screening rule pair AES-2 and IES-2.,3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"From the lemma above, we can see that the element j with |[ŵ]j | >√
2G(ŵ, ŝ) can be screened by rules AES-1 and IES-1.",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"Hence, we now only need to consider the cases when |[ŵ]j | ≤",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"√ 2G(ŵ, ŝ).
",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
Theorem 5.,3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"Given a set C ⊆ V̂ and the active and inactive sets Ê and Ĝ identified in the previous IAES steps, then,
(i): The active element screening rule takes the form of{ 0 <",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"[ŵ]j ≤ √ 2G(ŵ, ŝ)
maxw∈B,[w]j≤0 ‖w‖1 < F̂ (V̂ )− 2F̂ (C)
⇒j ∈ A∗,∀j ∈ V/(Ê ∪ Ĝ).",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"(AES-2)
(ii): The inactive element screening rule takes the form of{ − √
2G(ŵ, ŝ) ≤",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
[ŵ]j < 0,3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"maxw∈B,[w]j≥0 ‖w‖1 < F̂ (V̂ )− 2F̂ (C)
⇒j /∈",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"A∗,∀j ∈ V/(Ê ∪ Ĝ).",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"(IES-2)
(iii): The active and inactive sets Ê and Ĝ can be updated by
Ê ← Ê ∪∆Ê , (6) Ĝ ← Ĝ ∪∆Ĝ, (7)
where ∆Ê and ∆Ĝ are the newly identified active and inactive sets defined as
∆Ê := { j ∈ V/(Ê ∪ Ĝ) :",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
0 <,3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"[ŵ]j ≤ √ 2G(ŵ, ŝ),
max w∈B,[w]j≤0
‖w‖1 < F̂ (V̂ )− 2F̂ (C) } ,
∆Ĝ",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
:= { j ∈ V/(Ê ∪ Ĝ) :,3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"− √ 2G(ŵ, ŝ) ≤",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"[ŵ]j < 0,
max w∈B,[w]j≥0
‖w‖1 < F̂ (V̂ )− 2F̂ (C) } .
",3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
Theorem 5 verifies the safety of AES-2 and IES-2.,3.2.2. INACTIVE AND ACTIVE ELEMENT SCREENING BASED ON B ∩ Ω,[0],[0]
"To reinforce the capability of the proposed screening rules, we develop a novel framework IAES in Algorithm 2, which
applies the active element screening rules (AES-1 and AES2) and the inactive element screening rules (IES-1 and IES2) in an alternating manner during the optimization process.",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"Specifically, we integrate our screening rules AES-1, AES-2, IES-1 and IES-2 with the optimization algorithm A for the problems Q-P’ and Q-D’.",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"During the optimization process, we trigger the screening rules AES-1, AES-2, IES-1 and IES-2 every time when the dual gap is 1− ρ times smaller than itself in the last triggering of IAES.",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"As the solver A goes on, the volumes of Ω and B would decrease to zeros quickly, IAES can thus identify more and more inactive and active elements.
",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"Compared with the existing screening methods for convex sparse models, an appealing feature of IAES is that it has no theoretical limit in identifying the inactive and active elements and reducing the problem size.",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"The reason is that, in convex sparse models, screening models can never rule out the features and samples whose corresponding coefficients in the optimal solution are nonzero.",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"While in our case, as the optimizer A goes on, our estimation will be accurate enough for us to infer the affiliation of each element with A∗. Hence, we can finally identify all the inactive and active elements and the problem size can be reduced to zero.",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"This nice feature can lead to significant speedups in the computation time.
",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
Remark 1.,3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
The setC in Algorithm 2 is updated by choosing one of the super-level sets of ŵ with the smallest value F̂ (C).,3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
It is free to obtain it.,3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"The reason is that most of the existing methods A for the problems Q-P’ and Q-D’ need to calculate f̂(ŵ) in each iteration, in which they need to calculate the value F̂ at all of the super-level sets of ŵ (see the greedy algorithm in (Bach et al., 2013) for details).
",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
Remark 2.,3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"The algorithm A can be all the methods for the problems Q-P’ and Q-D’, such as minimum-norm point algorithm (Wolfe, 1976) and conditional gradient descent (Dunn & Harshbarger, 1978).",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"Although some algorithms only update s, in IAES, we can update w in each iteration by letting w = −s and refining it by the algorithm named pool adjacent violators (Best & Chakravarti, 1990).
",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
Remark 3.,3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"Due to Lemma 1 and the safety of AES-1, AES-2, IES-1 and IES-2, we can see that IAES would never sacrifice any accuracy.
",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
Remark 4.,3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"Although step 14 in Algorithm 2 may increase the dual gap slightly, it is worthwhile because of the reduced problem size.",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"This is verified by the speedups gained by IAES in the experiments.
",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
Remark 5.,3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
The parameter ρ in Algorithm 2 controls the frequency how often we trigger IAES.,3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"The larger value, the higher frequency to trigger IAES but more computational time consumed by IAES.",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"In our experiment, we set ρ = 0.5 and it achieves a good performance.
",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
Algorithm 2 Inactive and Active Element Screening 1: Input: an optimization algorithm,3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"A for problems (Q-
P’) and (Q-D’), > 0, 0 <",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
ρ < 1.,3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"2: Initialize: Ê = Ĝ = ∅, C = ∅, g = ∞, choose ŝ ∈ B(F ) and ŵ =",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"−ŝ. 3: repeat 4: Run A on problems (Q-P’) and (Q-D’) to update ŵ, ŝ and C. 5: if dual gap",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"G(ŵ, ŝ)",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"< ρg then 6: Run the active element screening rules AES-1 and AES-2 based on (ŵ, ŝ) and C. 7: Update the active set Ê by (4) and (6).",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"8: Run the inactive element screening rules IES-1 and IES-2 based on (ŵ, ŝ) and C. 9: Update the inactive set Ĝ by (5) and (7).
10: if V/(Ê ∪ Ĝ) = ∅ then 11: Return: Ê .",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"12: else 13: Update F̂ , Q-P’, Q-D’ according to Ê and Ĝ. 14: Update ŵ and ŝ by:
ŵ←",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"[ŵ]V/(Ê∪Ĝ),
ŝ← arg max s∈B(F̂ ) 〈ŵ, s〉.
15: Update g ← G(ŵ, ŝ).",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
"16: end if 17: end if 18: until G(ŵ, ŝ) < .",3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
19: Return: Ê ∪ {ŵ > 0}.,3.3. The Proposed IAES Framework by An Alternating Execution of AES and IES,[0],[0]
We evaluate IAES through numerical experiments on both synthetic and real datasets by two measurements.,4. Experiments,[0],[0]
"The first one is the rejection ratios of IAES over iterations: mi+nim∗+n∗ , where mi and ni are the numbers of the active and inactive elements identified by IAES after the i-th iteration, and m∗ and n∗ are the numbers of the active and inactive elements in A∗. We notice that in our experiments m∗ + n∗ = p, so the rejection ratio presents the problem size reduced by IAES.",4. Experiments,[0],[0]
"The second measurement is speedup, i.e., the ratio of the running times of the solver without IAES and with IAES.",4. Experiments,[0],[0]
We set the accuracy tolerance to be 10−6.,4. Experiments,[0],[0]
"Recall that, IAES can be integrated with all the solvers for the problems Q-P and Q-D. In this experiment, we use one of the most widely used algorithms minimum-norm point algorithm (MinNorm) (Wolfe, 1976) as the solver.",4. Experiments,[0],[0]
"The function F (A) varies according to the datasets, whose detailed definitions will be given in the subsequent subsections.
",4. Experiments,[0],[0]
"We write the code in Matlab and perform all the computations on a single core of Intel(R) Core(TM) i7-5930K 3.50GHz, 32GB MEM.",4. Experiments,[0],[0]
We perform experiments on a synthetic dataset named twomoons with different sample sizes (see Figure 2 for an example).,4.1. Experiments on Synthetic Datasets,[0],[0]
All the data points are sampled from two different semicircles.,4.1. Experiments on Synthetic Datasets,[0],[0]
"Specifically, each point can be represented as x = ci",4.1. Experiments on Synthetic Datasets,[0],[0]
+ γ ∗,4.1. Experiments on Synthetic Datasets,[0],[0]
"[cos(θi), sin(θi)], where i = 1, 2 stands for the two semicircles, c1 =",4.1. Experiments on Synthetic Datasets,[0],[0]
"[−0.5, 1],",4.1. Experiments on Synthetic Datasets,[0],[0]
c2 =,4.1. Experiments on Synthetic Datasets,[0],[0]
"[0.5,−1], γ is generated from a normal distribution N(2, 0.52), and θ1 and θ2 are sampled from two uniform distributions [−π2 , π 2 ] and [π2 , 3π 2 ], respectively.",4.1. Experiments on Synthetic Datasets,[0],[0]
We first sample p data points from these two semicircles with equal probability.,4.1. Experiments on Synthetic Datasets,[0],[0]
"Then, we randomly choose p0 = 16 samples and label each of them as positive if it is from the first semicircle and otherwise label it as negative.",4.1. Experiments on Synthetic Datasets,[0],[0]
"We generate five datasets by varying the sample size p in [200, 400, 600, 800, 1000].",4.1. Experiments on Synthetic Datasets,[0],[0]
"We perform semi-supervised clustering on each dataset and the objective function F (A) is defined as:
F (A) = I(fA, fV/A)− ∑ j∈A log ηj − ∑ j∈V/A log(1− ηj),
where I(fA, fV/A) is the mutual information between two Gaussian processes with a Gaussian kernel k(x, y) = exp(−α‖x− y‖2), α = 1.5, and ηj ∈ {0, 1} if j is labeled and otherwise ηj = 12 (see Chapter 6 of (Bach et al., 2013) for more details).",4.1. Experiments on Synthetic Datasets,[0],[0]
"The kernel matrix is dense with the size p× p, leading to a big computational cost when p is large.
",4.1. Experiments on Synthetic Datasets,[0],[0]
Figure 1 displays the rejection ratios of IAES on two-moons.,4.1. Experiments on Synthetic Datasets,[0],[0]
We can see that IAES can find the active and inactive elements incrementally during the optimization process.,4.1. Experiments on Synthetic Datasets,[0],[0]
"It can
finally identify almost all of the elements and reduce the problem size to nearly zero in no more than 400 iterations, which is consistent with our theoretical analysis in Section 3.3.",4.1. Experiments on Synthetic Datasets,[0],[0]
Figure 3 visualizes the screening process of IAES on two-moons when p = 400.,4.1. Experiments on Synthetic Datasets,[0],[0]
"It shows that, during the optimization process, IAES identifies the elements that are easy to be classified first and then identifies the rest.
",4.1. Experiments on Synthetic Datasets,[0],[0]
"Table 1 reports the running time of MinNorm without and with AES (AES-1 + AES-2), IES (IES-1 + IES-2) and IAES for solving the problem SFM on two-moons.",4.1. Experiments on Synthetic Datasets,[0],[0]
We can see that the speedup of IAES can be up to 10 times.,4.1. Experiments on Synthetic Datasets,[0],[0]
"In all the datasets, IAES is significantly faster than MinNorm, MinNorm with AES or IES.",4.1. Experiments on Synthetic Datasets,[0],[0]
"At last, we can see that the time costs of AES, IES and IAES are negligible.",4.1. Experiments on Synthetic Datasets,[0],[0]
"In this experiment, we evaluate the performance of IAES on an image segmentation task.",4.2. Experiments on Real Datasets,[0],[0]
"We use five images (included in the supplemental material) in (Rother et al., 2004) to evaluate IAES.",4.2. Experiments on Real Datasets,[0],[0]
"The objective function F (A) is the sum of the unary potentials for all individual pixels and the pairwise potentials of a 8-neighbor grid graph:
F (A) = u(A) + ∑
i∈A,j∈V/A
d(i, j),
where V presents all the pixels, u ∈ RV is the unary potential derived from the Gaussian Mixture model (Rother et al., 2004), and d(i, j)",4.2. Experiments on Real Datasets,[0],[0]
= exp{−‖xi,4.2. Experiments on Real Datasets,[0],[0]
"− xj‖2} (xi and xj are the values of two pixels) if i, j are neighbors, otherwise d(i, j) = 0.",4.2. Experiments on Real Datasets,[0],[0]
"Table 3 provides the statistics of the resulting image segmentation problems, including the numbers of the pixels and the edges in the 8-neighbor grid graph.
",4.2. Experiments on Real Datasets,[0],[0]
The rejection ratios in Figure 4 show that IAES can identify the active and inactive elements during the optimization process incrementally until all of them are identified.,4.2. Experiments on Real Datasets,[0],[0]
"This implies that IAES can lead to a significant speedup in the time cost.
",4.2. Experiments on Real Datasets,[0],[0]
"Table 2 reports the detailed time cost of MinNorm without and with AES, IES and IAES for solving the image segmentation problems.",4.2. Experiments on Real Datasets,[0],[0]
"We can see that IAES leads to significant speedups, which are up to 30.7 times.",4.2. Experiments on Real Datasets,[0],[0]
"In addition, we notice that the speedup gained by AES is small.",4.2. Experiments on Real Datasets,[0],[0]
"The reason is that AES is used to identify the pixels of the foreground, which is a small region in the image, and thus the problem size cannot be reduced dramatically even if all the active elements are identified.
",4.2. Experiments on Real Datasets,[0],[0]
"At last, from Table 2, we can also see that the speedup we achieve is supper-additive (speedup of AES + speedup of IES < speedup of IAES).",4.2. Experiments on Real Datasets,[0],[0]
"This can usually be expected, which comes from the super linear computational complexity of each iteration in MinNorm, leading to a super-additive saving in the computational cost.",4.2. Experiments on Real Datasets,[0],[0]
We notice that the speedup we achieve on some of the two-moon datasets is not superadditive.,4.2. Experiments on Real Datasets,[0],[0]
"The reason is that we cannot identify a lot of
elements in the early stage (Figure 1).",4.2. Experiments on Real Datasets,[0],[0]
"Thus, the early stage takes up too much time cost.",4.2. Experiments on Real Datasets,[0],[0]
"In this paper, we proposed a novel safe element screening method IAES for SFM to accelerate its optimization process by simultaneously identifying the active and inactive elements.",5. Conclusion,[0],[0]
"Our major contribution is a novel framework for accurately estimating the optimum of the corresponding primal problem of SFM developed by carefully studying the strong convexity of the primal and dual problems, the structure of the base polyhedra, and the optimality conditions of SFM.",5. Conclusion,[0],[0]
"To the best of our knowledge, IAES is the first screening method in the fields of SFM and even combinatorial optimization.",5. Conclusion,[0],[0]
The extensive experimental results demonstrate that IAES can achieve significant speedups.,5. Conclusion,[0],[0]
"Submodular functions are discrete analogs of convex functions, which have applications in various fields, including machine learning and computer vision.",abstractText,[0],[0]
"However, in large-scale applications, solving Submodular Function Minimization (SFM) problems remains challenging.",abstractText,[0],[0]
"In this paper, we make the first attempt to extend the emerging technique named screening in large-scale sparse learning to SFM for accelerating its optimization process.",abstractText,[0],[0]
"We first conduct a careful studying of the relationships between SFM and the corresponding convex proximal problems, as well as the accurate primal optimum estimation of the proximal problems.",abstractText,[0],[0]
"Relying on this study, we subsequently propose a novel safe screening method to quickly identify the elements guaranteed to be included (we refer to them as active) or excluded (inactive) in the final optimal solution of SFM during the optimization process.",abstractText,[0],[0]
"By removing the inactive elements and fixing the active ones, the problem size can be dramatically reduced, leading to great savings in the computational cost without sacrificing any accuracy.",abstractText,[0],[0]
"To the best of our knowledge, the proposed method is the first screening method in the fields of SFM and even combinatorial optimization, thus pointing out a new direction for accelerating SFM algorithms.",abstractText,[0],[0]
Experiment results on both synthetic and real datasets demonstrate the significant speedups gained by our approach.,abstractText,[0],[0]
Safe Element Screening for Submodular Function Minimization,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2805–2811 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2805",text,[0],[0]
The hashtag #MeToo1 has been prevalent on various social media platforms as a campaign centered around sharing stories of sexual harassment in an act of solidarity with other victims and spreading awareness of a widespread and endemic issue.,1 Introduction,[0],[0]
"With vast amounts of personal stories on the internet, it is important that we make scientific use of this data to push these movements forward and enable real-world change.",1 Introduction,[0],[0]
"Manually sorting and comprehending the information shared in these stories is an arduous task, and the power of natural language processing (NLP) can serve as the missing link between online activism and real change.
",1 Introduction,[0],[0]
"We present several neural NLP models that allow us to automatically classify, aggregate, and analyze vast amounts of harassment data found on social media, becoming an effective tool for
1https://metoomvmt.org
spreading awareness, increasing understanding, and allowing faster action.",1 Introduction,[0],[0]
"This large-scale automatic categorization, summarization, and analysis of personal abuse stories can help activist groups enlighten the public and advocate for social change in a timely manner.
",1 Introduction,[0],[0]
"We present single-label and multi-label classification of diverse forms of sexual harassment present in abuse stories shared online through the forum SafeCity, a crowd-sourcing platform for personal stories of sexual harassment and abuse.",1 Introduction,[0],[0]
"Each story includes one or more tagged forms of sexual harassment, along with a description of the occurrence.",1 Introduction,[0],[0]
"For example, the description “My college was nearby.",1 Introduction,[0],[0]
This happened all the time.,1 Introduction,[0],[0]
"Guys passing comments, staring, trying to touch.",1 Introduction,[0],[0]
"Frustrating” is positive for three classes: commenting, ogling/staring, and touching/groping.
",1 Introduction,[0],[0]
We use CNN-RNN architectures (with character-level CNN embeddings and bidirectional RNNs) to classify the three forms of sexual harassment mentioned above using both singleand multi-label setups.,1 Introduction,[0],[0]
Our models achieve strong performances of 80-86% on these setups.,1 Introduction,[0],[0]
"This automatic classification of different forms of sexual harassment can help victims and authorities to partially automate and speed up the process of filling online sexual violence reporting forms (see Figure 1), which usually requires the victim to detail each form of sexual harassment that took place.",1 Introduction,[0],[0]
"The act of partially filling out the report
(by our classifier) in itself makes it more likely for the victim to file a report.",1 Introduction,[0],[0]
"A study by the Bureau of Justice found that victims who report sexual assault are more likely to seek medical treatment for injuries, which also allows for more immediate prosecution and a better chance of finding DNA evidence to convict the offender (Rennison, 2002).",1 Introduction,[0],[0]
"Further, it can also be used to fulfill the need to automatically categorize and summarize large numbers of online testimonials describing or reporting sexual harassment.
",1 Introduction,[0],[0]
"Next, in order to further utilize these stories as an important tool for harassment understanding and to help prevent similar situations from happening to others, we present interpretability analysis of our neural classification results in the forms of LIME analysis, first-derivative saliency heatmaps, activation clustering, and t-SNE embedding visualization.",1 Introduction,[0],[0]
"We show how these analysis techniques hold promise as avenues for future work and can potentially provide insightful clues towards building (1) a tool to analyze the most common circumstances around each distinct form of harassment to provide more detailed and accurate safety advice, (2) a map of unsafe areas to help others avoid dangerous spaces, and 3) an unofficial sex offender registry that marks frequentlymentioned offenders to warn potential victims.",1 Introduction,[0],[0]
"This paper seeks to provide an avenue to utilize the millions of stories shared on social media describing instances of sexual harassment, including #MeToo, #WhyILeft, and #YesAllWomen.",1 Introduction,[0],[0]
"With this task and analysis, we hope that these stories can be used to prevent future sexual harassment.",1 Introduction,[0],[0]
"Analyzing personal sexual harassment stories from online social forums is fairly unexplored, to the best of our knowledge.",2 Related Work,[0],[0]
"However, recent works in a similar vein include detecting the presence of domestic abuse stories on social media sites (Schrading et al., 2015a; Schrading, 2015; Schrading et al., 2015b).",2 Related Work,[0],[0]
"In more distantly related work, NLP has been used for various sociallydriven tasks, such as detecting the presence of cyberbullying or incivility (Ziegele et al., 2018; Founta et al., 2018; Chen et al., 2012; Zhao et al., 2016; Agrawal and Awekar, 2018; Van Hee et al., 2018), and detecting and providing aid for signs of depression or suicidal thoughts (Pestian et al., 2010; Yazdavar et al., 2017; Stepanov et al., 2017; Fitzpatrick et al., 2017).",2 Related Work,[0],[0]
"For our single-label binary classification task, the two output classes can be [commenting, noncommenting], [ogling, non-ogling], or [groping, non-groping].",3 Classification Models,[0],[0]
"For our multi-label scenario, there are a total of 8 combinations (true or false for three types of sexual harassment), including a label for none of the three classes present in the description.",3 Classification Models,[0],[0]
CNN:,3 Classification Models,[0],[0]
"For each input description, an embedding and convolutional layer are applied.",3 Classification Models,[0],[0]
"This is followed by a max-pooling layer (Collobert et al., 2011).",3 Classification Models,[0],[0]
"Filters of varying window sizes are applied to each window of word vectors, the result of which is then passed through a softmax layer to produce probabilities over the output classes.",3 Classification Models,[0],[0]
"LSTM-RNN: As CNNs are not designed to capture sequential relationships (Pascanu et al., 2014), we adopted an RNN model that consisted of word vectors fed into LSTM layer, the final state of which was fed into a fully-connected layer.",3 Classification Models,[0],[0]
The result is passed through a softmax layer to output the probability over all output classes.,3 Classification Models,[0],[0]
CNN-RNN:,3 Classification Models,[0],[0]
"As both models have strengths and weaknesses, we experimented with a hybrid architecture in which our LSTM-RNN model after the embedding layer is laid on top of our CNN model before the max-pooling (related to Zhou et al. (2015)).",3 Classification Models,[0],[0]
"For single-label models, the final fully-connected layer is fed into a softmax to give final output probabilities.",3 Classification Models,[0],[0]
"Multi-Label Classification We also present multi-label classification (Boutell et al., 2004; Tsoumakas and Katakis, 2006; Katakis et al., 2008), which allows for models to predict multiple categories simultaneously for the same input.",3 Classification Models,[0],[0]
"We further utilized CNN-based character embeddings in addition to word embeddings, and also employed bidirectional RNNs (see Figure 2).",3 Classification Models,[0],[0]
"The
outputs of the final fully-connected layer (F) are fed into a sigmoid function.",3 Classification Models,[0],[0]
"The classification for each category (C) are seen as positive (1) if the output is above threshold t and negative (0) if the output is below threshold t, a hyperparameter, giving the equation: C = 1(σ(F ) ≥ t).",3 Classification Models,[0],[0]
"SafeCity2 is, to the best of our knowledge, the largest publicly-available online forum for reporting sexual harassment.",4.1 Dataset,[0],[0]
Its motto is “pin the creeps”.,4.1 Dataset,[0],[0]
"Victims of sexual harassment share personal stories, with the objective of spreading awareness of ongoing sexual harassment and showcasing location-based trends.",4.1 Dataset,[0],[0]
"The language styles of SafeCity forums are very diverse, and therefore can potentially be used for a variety of test cases, such as emails or tweets.
",4.1 Dataset,[0],[0]
"Each of the 9,892 stories includes a description of the incident, the location, and tagged forms of harassment, with all identifying information removed.",4.1 Dataset,[0],[0]
SafeCity has explicitly given us permission to use this data.,4.1 Dataset,[0],[0]
"The dataset3 contains descriptions of text submitted by forum users, along with tags of 13 forms of sexual harassment.",4.1 Dataset,[0],[0]
"We chose the top three most dense categories—groping/touching, staring/ogling, and commenting—to use as our dataset, as the others were more sparse.",4.1 Dataset,[0],[0]
"Each description may fall into none, some, or all of the categories.",4.1 Dataset,[0],[0]
The single-label models were evaluated using accuracy.,4.2 Evaluation,[0],[0]
The multi-label models were evaluated using exact match ratio and Hamming score (calculated as the complement of Hamming loss).,4.2 Evaluation,[0],[0]
Hamming loss was used as detailed by Tsoumakas and Katakis (2006).,4.2 Evaluation,[0],[0]
"Hamming loss (y) is equal to 1 over |D| (number of multi-label samples), multiplied by the sum of the symmetric differences between the predictions (Z) and the true labels (Y), divided by the number of labels (L), giving
y = 1|D| |D|∑ i=1",4.2 Evaluation,[0],[0]
"|Yi∆Zi| |L| .
2http://safecity.in 3We release our dataset splits at https://github.",4.2 Evaluation,[0],[0]
com/swkarlekar/safecity.,4.2 Evaluation,[0],[0]
Please follow SafeCity guidelines for usage.,4.2 Evaluation,[0],[0]
"All models have vocabulary size of 10, 000, and use AdamOptimizer (Kingma and Ba, 2015) with a learning rate of 1e−4.",4.3 Training Details,[0],[0]
"All gradient norms are clipped to 2.0 (Pascanu et al., 2013; Graves, 2013).",4.3 Training Details,[0],[0]
"For each model, the hyperparameters are tuned using the development set.",4.3 Training Details,[0],[0]
CNN We use a 2-D CNN.,4.3 Training Details,[0],[0]
"Filter sizes of [3, 4, 5] are used with 128 filters per filter size.",4.3 Training Details,[0],[0]
"Batch size is set to 128, and a dropout (Srivastava et al., 2014) of 0.80 is applied.",4.3 Training Details,[0],[0]
LSTM Our LSTM has 2 layers with 60 hidden units.,4.3 Training Details,[0],[0]
Batch size is 64 with a dropout of 0.75.,4.3 Training Details,[0],[0]
CNN-LSTM Our CNN-LSTM model consists of an LSTM on top of a CNN.,4.3 Training Details,[0],[0]
"The CNN has 100 filters per filter size of [3, 4, 5].",4.3 Training Details,[0],[0]
Embedding dimensions of 300 are used.,4.3 Training Details,[0],[0]
An LSTM with 300 hidden units is used.,4.3 Training Details,[0],[0]
"For the character level embeddings, we use an additional CNN with 100 filters per filter size of [3, 4, 5].",4.3 Training Details,[0],[0]
Bidirectional RNNs of 300 units are used.,4.3 Training Details,[0],[0]
"See Table 1 for single-label results on the selected harassment categories, where CNN-RNN was the best performing model compared to several nonneural and neural baselines.",5 Results,[0],[0]
"See Table 2 for multi-label classification results, where the Hamming score for the multi-label CNN-RNN model is 82.5%, showing potential for real-world use as well as substantial future research scope.",5 Results,[0],[0]
We provide various visualization techniques to analyze our models.,6 Analysis,[0],[0]
Each of these techniques employs a different approach and offers new information or supports previous findings.,6 Analysis,[0],[0]
"We selected seed words that corresponded to class labels and found the nearest neighbors of each seed word’s vector by reducing the dimensionality of the word embeddings using t-SNE (see Table 3) (Maaten and Hinton, 2008).",6.1 Word Embedding Visualization,[0],[0]
"This form of visualization not only ensures that our model has learned appropriate word embeddings, but also demonstrates that each form of sexual harassment has a unique and distinct context.",6.1 Word Embedding Visualization,[0],[0]
"Furthermore, this shows that our model learns related words and concepts for each type of harassment.",6.1 Word Embedding Visualization,[0],[0]
"LIME analysis (Ribeiro et al., 2016), or Local Interpretable Model-Agnostic Explanation, interprets the local reasoning of a model around an instance.",6.2 LIME Analysis,[0],[0]
"Results of LIME (ξ) are found by taking the minimum of L, which is the measure of how unfaithful the interpretable model (g) is to approximating the probability that an input (x) belongs to a certain class (f ) in the locally defined area (πx) summed with complexity measures Ω, giving ξ(x) = argmin L(f, g, πx) + Ω(g).",6.2 LIME Analysis,[0],[0]
"In Figure 3 (left), the words “touch”, “man”, and the collective words “indecently till pushed away” are the most important to the local classification of “groping”.",6.2 LIME Analysis,[0],[0]
"Furthermore, the word “metro” has importance in the classification, suggesting that this may be a fre-
quent location in which groping takes place.",6.2 LIME Analysis,[0],[0]
"In Figure 3 (middle), the words with the most importance are “comments” and “staring”, indicating that ogling may coincide with commenting very frequently.",6.2 LIME Analysis,[0],[0]
"In Figure 3 (right), the words “ogling”, “sexual”, and “commenting” had the most importance, which further supports the notion that ogling and commenting often occur together.",6.2 LIME Analysis,[0],[0]
"As verified by the data, ogling and commenting together is more common than ogling alone.",6.2 LIME Analysis,[0],[0]
"Saliency heatmaps (Simonyan et al., 2014; Li et al., 2016) illustrate which words of an input have the biggest impact on the final classification by taking the gradient of the final scores outputted by the neural network (S) with respect to the embedding (E), given the true label (L), giving ∂SL(E)
∂E .",6.3 First Derivative Saliency,[0],[0]
"While LIME analysis and first derivative saliency are both used to find word-level contributions, first derivative saliency is model-dependent and gives reasoning behind classification based on the whole model, in contrast to the locally-faithful, model-agnostic LIME analysis technique.
",6.3 First Derivative Saliency,[0],[0]
"In Figure 4 (left), the word “commenting” and the words “one boy” have the most influence on the classification.",6.3 First Derivative Saliency,[0],[0]
The influence of the word “lighting” indicates poor lighting is often present in situations where sexual harassment takes place.,6.3 First Derivative Saliency,[0],[0]
"In Figure 4 (middle), the classification of “commenting” was most influenced by the word “commenting”, followed by the word “age”.",6.3 First Derivative Saliency,[0],[0]
This suggests the possibility of using descriptors of offenders as a classification tool.,6.3 First Derivative Saliency,[0],[0]
Figure 4 (right) is an incorrectly classified example.,6.3 First Derivative Saliency,[0],[0]
"We see that the word “body”, followed by “language”, had the most influence on the classification of this exam-
ple as “commenting”.",6.3 First Derivative Saliency,[0],[0]
Our model identifies synonyms and hyponyms like the word “language” in relation to the category of commenting.,6.3 First Derivative Saliency,[0],[0]
"However, the true label was “non-commenting”, as the word was not used in a context of sexual language, but rather as “vague language” and “body language”.",6.3 First Derivative Saliency,[0],[0]
"Activation clustering (Girshick et al., 2014; Aubakirova and Bansal, 2016) accesses the activation values of all n neurons and treats the activation values per input as coordinates in ndimensional space.",6.4 Activation Clustering,[0],[0]
K-means clustering was performed to group activation clusters and find common themes in these reports.,6.4 Activation Clustering,[0],[0]
Activation clustering is distinct from both LIME analysis and first derivative saliency in that it finds patterns and clusterings at a description-level.,6.4 Activation Clustering,[0],[0]
Circumstances of Harassment: One of the clusters was classified as “ogling”: {‘a group of boys was standing near us and were making weird expressions and as we moved away they started following’; ‘a group of guys lurking around the theater...’}.,6.4 Activation Clustering,[0],[0]
"Another cluster was classified as “commenting”: {’a group of men were standing who commented on every girl who passed by the’, ’a group of boys were standing there... as we started moving one of them commented on us’}",6.4 Activation Clustering,[0],[0]
"Both of these clusters contained examples describing circumstances of the harassment, following the pattern of “a group of boys/men were standing/lurking and...”",6.4 Activation Clustering,[0],[0]
It can be inferred that certain forms of sexual harassment are more likely to happen with large groups of men.,6.4 Activation Clustering,[0],[0]
"Activation clustering can identify the circumstances of harassment, helping potential victims to be better prepared.",6.4 Activation Clustering,[0],[0]
"Location and Time of Harassment: Some clusters contain examples that point to specific locations of harassment, e.g., a groping cluster: {‘i was in the bus and there was this man who purposely fell on me and touched me inappropriately’; ‘while traveling in a crowded bus most of the time men try to grind their intimate part over my body’; ‘i was in the bus when a man standing tried to put his d**k on my hand’}.",6.4 Activation Clustering,[0],[0]
"Specific locations can also be found: {‘the gurgaon sohna road is very unsafe at night especially if you are alone with no street lights’; ‘kurla station really gets scary at night once i was trying to get a train from kurla station around 10’; ‘mathura highway , not enough lights on the way during nights so is not safe for a individual to journey’}.",6.4 Activation Clustering,[0],[0]
"Notice
that the second cluster examples also contain the word “night”.",6.4 Activation Clustering,[0],[0]
"With data that contains more specific locations or times of day, activation clusters can serve as an automatic way to map out unsafe areas based on location and time of day.",6.4 Activation Clustering,[0],[0]
Identifying Offenders: Examples from another groping cluster include: {‘...her step father abused her physically for a year’; ‘one of the girl of about 6 years got raped by her own father’; ‘it happened at my house my brother harassed me and also misbehaved with me one night its been six months’}.,6.4 Activation Clustering,[0],[0]
This shows that clusters can point to common relationships or titles for offenders.,6.4 Activation Clustering,[0],[0]
This phenomenon can be presumed to happen with names of offenders as well.,6.4 Activation Clustering,[0],[0]
"If many reports have been filed around this offender, clusters will form around his/her name.",6.4 Activation Clustering,[0],[0]
"Instead of a case of “he said, she said”, activation clustering provides an avenue towards “he said, they said”, as clusters form when multiple reports have been filed around the same name.
",6.4 Activation Clustering,[0],[0]
"The main purpose of our visualization techniques is to explain what the black-box deep learning models are learning, such as locations, offenders, or times of day.",6.4 Activation Clustering,[0],[0]
"With more detailed data in the future, we may be able to uncover more nuanced circumstances behind harassment.",6.4 Activation Clustering,[0],[0]
We presented the novel task of identifying various forms of sexual harassment in personal stories.,7 Conclusion,[0],[0]
Our accurate multi-label classification models illustrate the plausibility of automatically filling out incident reports.,7 Conclusion,[0],[0]
"Using visualization techniques, we found circumstances surrounding forms of harassment and the possibility of automatically identifying safe areas and repeat offenders.",7 Conclusion,[0],[0]
"In future work, we hope to experiment with the transferability of our model to other datasets to encompass the diverse mediums through which these personal stories are shared.",7 Conclusion,[0],[0]
"Honoring the courage that these victims demonstrated in sharing their stories online, we use these descriptions not only to help summarize online testimonials and provide more detailed safety advice, but also to help others report similar occurrences to hopefully prevent future sexual harassment from occurring.",7 Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
"This work was supported by a Google Faculty Research Award, a Bloomberg Data Science Research Grant, an IBM Faculty Award, and NVidia GPU awards.",Acknowledgments,[0],[0]
"With the recent rise of #MeToo, an increasing number of personal stories about sexual harassment and sexual abuse have been shared online.",abstractText,[0],[0]
"In order to push forward the fight against such harassment and abuse, we present the task of automatically categorizing and analyzing various forms of sexual harassment, based on stories shared on the online forum SafeCity.",abstractText,[0],[0]
"For the labels of groping, ogling, and commenting, our single-label CNN-RNN model achieves an accuracy of 86.5%, and our multi-label model achieves a Hamming score of 82.5%.",abstractText,[0],[0]
"Furthermore, we present analysis using LIME, first-derivative saliency heatmaps, activation clustering, and embedding visualization to interpret neural model predictions and demonstrate how this helps extract features that can help automatically fill out incident reports, identify unsafe areas, avoid unsafe practices, and ‘pin the creeps’.",abstractText,[0],[0]
SafeCity: Understanding Diverse Forms of Sexual Harassment Personal Stories,title,[0],[0]
"1Departments of Statistics and Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, USA 2Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, USA. Correspondence to: Aaditya Ramdas <aramdas@eecs.berkeley.edu>, Tijana Zrnic <tijana@eecs.berkeley.edu>, Martin J. Wainwright <wainwrig@eecs.berkeley.edu>, Michael I. Jordan <jordan@eecs.berkeley.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).",text,[0],[0]
It is now commonplace in science and technology to make thousands or even millions of related decisions based on data analysis.,1. Introduction,[0],[0]
"As a simplified example, to discover which genes may be related to diabetes, we can formulate the decision-making problem in terms of hypotheses that take the form “gene X is not associated with diabetes,” for many different genes X, and test for which of these null hypotheses can be confidently rejected by the data.",1. Introduction,[0],[0]
"As first identified by Tukey in a seminal 1953 manuscript (1953), the central difficulty when testing a large number of null hypotheses is that several of them may appear to be false, purely by chance.",1. Introduction,[0],[0]
"Arguably, we would like the set of rejected null hypothesesR to have high precision, so that most discovered genes are indeed truly correlated with diabetes and further investigations are not fruitless.",1. Introduction,[0],[0]
"Unfortunately, separately controlling the false positive rate for each individual test actually does not provide any guarantee on the precision.",1. Introduction,[0],[0]
"This motivated the development of procedures that can provide guarantees on an error metric called the false discovery rate (FDR) (Benjamini & Hochberg, 1995), defined as:
FDR ≡ E",1. Introduction,[0],[0]
[FDP(R)],1. Introduction,[0],[0]
"= E [ |H0 ∩R| |R| ] ,
whereH0 is the unknown set of truly null hypotheses, and 0/0 ≡ 0.",1. Introduction,[0],[0]
"Here the FDP represents the ratio of falsely rejected nulls to the total number of rejected nulls, and since the set of discoveries R is data-dependent, the FDR takes an expectation over the underlying randomness.",1. Introduction,[0],[0]
"The evidence from a hypothesis test can typically be summarized in terms of a p-value, and so offline multiple testing algorithms take a set of p-values {Pi} as their input, and a target FDR level α ∈ (0, 1), and produce a rejected set R that is guaranteed to have FDR ≤ α.",1. Introduction,[0],[0]
"Of course, one also desires a high recall, or equivalently a low false negative rate, but without assumptions on many uncontrollable factors like the frequency and strength of signals, additional guarantees on the recall are impossible.
",1. Introduction,[0],[0]
"While the offline paradigm previously described is the classical setting for multiple decision-making, the corresponding online problem is emerging as a major area of its own.",1. Introduction,[0],[0]
"For example, large information technology companies run thou-
sands of A/B tests every week of the year, and decisions about whether or not to reject the corresponding null hypothesis must be made without knowing the outcomes of future tests; indeed, future null hypotheses may depend on the outcome of the current test.",1. Introduction,[0],[0]
The current standard of setting all thresholds αk to a fixed quantity such as 0.05 does not provide any control of the FDR.,1. Introduction,[0],[0]
"Hence, the following hypothetical scenario is entirely plausible: a company conducts 1000 tests in one week, each with a target false positive rate of 0.05; it happens to make 80 discoveries in total of which 50 are accidental false discoveries, ending up with an FDP of 5/8.",1. Introduction,[0],[0]
"Such uncontrolled error rates can have severe financial and social consequences.
",1. Introduction,[0],[0]
"The first method for online control of the FDR was the alpha-investing algorithm of Foster and Stine (2008), later extended to generalized alpha-investing (GAI) algorithms by Aharoni and Rosset (2014).",1. Introduction,[0],[0]
"Recently, Javanmard and Montanari (2017) proposed variants of GAI algorithms that control the FDR (as opposed to the modified FDR controlled in the original paper (Foster & Stine, 2008)), including a new algorithm called LORD.",1. Introduction,[0],[0]
"The GAI++ algorithms by Ramdas et al. (2017) improved the earlier GAI algorithms (uniformly), and the improved LORD++ (henceforth LORD) method arguably represents the current state-of-the-art in online multiple hypothesis testing.
",1. Introduction,[0],[0]
The current paper’s central contribution is the derivation and analysis of a powerful new class of online FDR algorithms called “SAFFRON” (Serial estimate of the Alpha Fraction that is Futilely Rationed On true Null hypotheses).,1. Introduction,[0],[0]
"As an instance of the GAI framework, the SAFFRON method starts off with an error budget, referred to as alphawealth, that it allocates to different tests over time, earning back some alpha-wealth whenever it makes a new discovery.",1. Introduction,[0],[0]
"However, unlike earlier work in the online setting, SAFFRON is an adaptive method, meaning that it is based on an estimate of the proportion of true nulls.",1. Introduction,[0],[0]
"In the offline setting, adaptive methods were proposed by Storey (2002; 2004), who showed that they are more powerful than the Benjamini-Hochberg (BH) procedure (1995) under independence assumptions; this advantage usually increases with the proportion of non-nulls and the signal strength.",1. Introduction,[0],[0]
"Thus, the SAFFRON method can be viewed as an online analogue of Storey’s adaptive version of the BH procedure.",1. Introduction,[0],[0]
"As shown in Figure 1, our simulations show that SAFFRON demonstrates the same types of advantages over its non-adaptive counterparts, such as LORD and alpha-investing.",1. Introduction,[0],[0]
"Furthermore, the ideas behind SAFFRON’s derivation can provide a natural template for the design and analysis of a suite of other adaptive online methods.
",1. Introduction,[0],[0]
The rest of this paper is organized as follows.,1. Introduction,[0],[0]
"In Section 2, we derive the SAFFRON algorithm from first principles, leaving the precise statement and the proof of a central tech-
nical lemma for Section 3.",1. Introduction,[0],[0]
"In Section 4, we investigate the practical choice of tuning parameters, and demonstrate the effectiveness of our recommended choice using simulations.",1. Introduction,[0],[0]
We end with a summary in Section 5.,1. Introduction,[0],[0]
"Before deriving the SAFFRON algorithm, it is useful to recap a few concepts.",2. Deriving the SAFFRON Algorithm,[0],[0]
"By definition of a p-value, if the hypothesis Hi is truly null, then the corresponding p-value is stochastically larger than the uniform distribution (“superuniformly distributed,” for short), meaning that:
If the null hypothesis Hi is true, then Pr{Pi ≤ u} ≤ u for all u ∈",2. Deriving the SAFFRON Algorithm,[0],[0]
"[0, 1].
(1)
For any online FDR procedure, let the rejected set after t steps be denoted byR(t).",2. Deriving the SAFFRON Algorithm,[0],[0]
"More precisely, this set consists of all p-values among the first t ones for which the indicator for rejection is equal to 1; i.e., Rj : = 1 {Pj ≤ αj} = 1, for all j ≤ t.",2. Deriving the SAFFRON Algorithm,[0],[0]
"While we have already defined the classical FDP and FDR in the introduction, several authors, including Foster and Stine (2008), have considered a modified FDR, defined as:
mFDR(t) :",2. Deriving the SAFFRON Algorithm,[0],[0]
= E [ |H0 ∩R(t)| ],2. Deriving the SAFFRON Algorithm,[0],[0]
E,2. Deriving the SAFFRON Algorithm,[0],[0]
[|R(t)|] .,2. Deriving the SAFFRON Algorithm,[0],[0]
"(2)
In the sequel, we provide guarantees for both mFDR and FDR.",2. Deriving the SAFFRON Algorithm,[0],[0]
Our guarantees on mFDR hold under the following weakening of (1).,2. Deriving the SAFFRON Algorithm,[0],[0]
"Define the filtration formed by the sequence of sigma-fields F t : = σ(R1, . . .",2. Deriving the SAFFRON Algorithm,[0],[0]
", Rt), and let αt : = ft(R1, . . .",2. Deriving the SAFFRON Algorithm,[0],[0]
", Rt−1), where ft is an arbitrary function of the first t−1 indicators for rejection.",2. Deriving the SAFFRON Algorithm,[0],[0]
"Then, we say that the null p-values are conditionally super-uniformly distributed if the following holds:
If the null hypothesis Ht is true, then Pr { Pt ≤",2. Deriving the SAFFRON Algorithm,[0],[0]
αt ∣∣,2. Deriving the SAFFRON Algorithm,[0],[0]
F t−1} ≤ αt. (3),2. Deriving the SAFFRON Algorithm,[0],[0]
"To understand the motivation behind the new procedure, it is necessary to expand on an perspective on existing online FDR procedures, recently suggested by Ramdas et al. (2017).",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"We begin by defining an oracle estimate of the FDP as:
FDP∗(t) :",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"=
∑ j≤t,j∈H0 αj
|R(t)| .
",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"The word oracle indicates that FDP∗ cannot be calculated by the scientist, since H0 is unknown.",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"Intuitively, the numerator ∑ j≤t,j∈H0 αj overestimates the number of false discoveries, and FDP∗(t) overestimates the FDP, as formalized in the claim below:
Proposition 1.",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"If the null p-values are conditionally superuniformly distributed (3), then we have:
(a) E [ ∑ j≤t,j∈H0 αj ] ≥",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"E [ |H0 ∩R(t)| ] ;
(b)",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"If FDP∗(t) ≤ α for all t ∈ N, then mFDR(t) ≤ α for all t ∈ N.
Further, if the null p-values are independent of each other and of the non-nulls, and {αt} is a monotone function of past rejections, then:
(c) E [FDP∗(t)]",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
≥ E [FDP(t)] ≡,2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"FDR(t) for all t ∈ N;
(d)",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"The condition FDP∗(t) ≤ α for all t ∈ N implies that FDR(t) ≤ α for all t ∈ N.
To clarify, the word monotone means that αt is a coordinatewise non-decreasing function of the vector R1, . . .",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
", Rt−1.",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"Proposition 1 follows from the results of Ramdas et al. (2017), and we prove it in Subsection 3.1 for completeness.",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"Even though FDP∗(t) cannot be directly calculated and used, Proposition 1 is a useful way to identify what would be ideally possible.
",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"One natural way to convert FDP∗(t) to a truly empirical overestimate of FDP(t) is to define:
F̂DPLORD(t) : =
∑ j≤t αj
|R(t)| .
",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"Since it is trivially true that F̂DPLORD(t) ≥ FDP∗(t), we immediately obtain that Proposition 1 also holds with FDP∗(t) replaced by F̂DPLORD(t).",2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
The subscript LORD is used because Ramdas et al. (2017) point out that their variant of the LORD algorithm of Javanmard and Montanari (2017) can be derived by simply assigning αj in an online fashion to ensure that the condition F̂DPLORD(t) ≤ α is met for all times t.,2.1. An Oracle FDP Estimate and a Naive Overestimate,[0],[0]
"The main drawback of F̂DPLORD is that if the underlying (unknown) truth is such that the proportion of non-nulls (true signals) is non-negligible, then F̂DPLORD(t) is a very crude and overly conservative overestimate of FDP∗(t), and hence also of the true unknown FDP.",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"With this drawback in mind, and knowing that we would expect non-nulls to typically have smaller p-values, we propose the following novel estimator:
F̂DPSAFFRON(λ)(t) ≡ F̂DPλ(t) : = ∑ j≤t αj 1{Pj>λj} 1−λj
|R(t)| ,
where {λj}∞j=1 is a predictable sequence of user-chosen parameters in the interval (0, 1).",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"Here the term predictable means that λj is a deterministic function of the information available from time 1 to j − 1, which will be formalized later.",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"For simplicity, when λj is chosen to be a constant for all j, we will drop the subscript and just write λ, and we will consider λ = 1/2 as our default choice.",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"SAFFRON is based on the idea that the numerator of F̂DPλ is a much better estimator of the quantity ∑ j≤t,j∈H0 αj than LORD’s
naive estimate ∑ j≤t αj .
",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"So as to provide some intuition for why we expect F̂DPλ to be a fairly tight estimate of FDP∗, note that 1{Pj>λj}1−λj has a unit expectation whenever Pj is uniformly distributed (null), but would typically have a much smaller expectation whenever Pj is stochastically much smaller than uniform (non-null).",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"The following theorem shows that, even though F̂DPλ(t) is not necessarily always larger than FDP∗(t), a direct analog of Proposition 1 is nonetheless valid.",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"In order to state this claim formally, we need to slightly modify the assumption (3).",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"As before, denote by Rj : = 1 {Pj ≤ αj} the indicator for rejection, and let Cj := 1 {Pj ≤ λj} be the indicator for candidacy.",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"Accordingly, we refer to the p-values for which Cj = 1 as candidates.",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"Moreover, we let αt : = ft(R1, . . .",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
", Rt−1, C1, . . .",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
", Ct−1), where ft denotes an arbitrary function of the first t − 1 indicators for rejection and candidacy, and define the filtration generated from sigma-fields F t : = σ(R1, . . .",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
", Rt, C1, . . .",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
", Ct).",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"With respect to this filtration, we introduce a conditional superuniformity condition on the null p-values similar to (3):
If the null hypothesis Ht is true, then Pr { Pt ≤",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
αt ∣∣,2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"F t−1} ≤ αt, (4) which can be rephrased as:
E [ 1 {Pt > αt}
1− αt ························ ∣∣∣∣ F t−1] ≥ 1 ≥ E",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"[1 {Pt ≤ αt}αt························ ∣∣∣∣ F t−1] .
",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"Note that again marginal super-uniformity (1) implies this condition, provided that the p-values are independent.
",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
Theorem 1.,2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"If the null p-values are conditionally superuniformly distributed (4), then we have:
(a) E [ ∑ j≤t,j∈H0 αj 1{Pj>λj} 1−λj ]",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"≥ E [ |H0 ∩R(t)| ] ;
(b)",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
The condition F̂DPλ(t),2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"≤ α for all t ∈ N implies that mFDR(t) ≤ α for all t ∈ N.
Further, if the null p-values are independent of each other and of the non-nulls, and {αt} is a monotone function of the vector R1, ..., Rt−1, C1, ..., Ct−1, then we additionally have:
(c) E [ F̂DPλ(t) ]",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
≥ E [FDP(t)] ≡,2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"FDR(t) for all t ∈ N;
(d)",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
The condition F̂DPλ(t),2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"≤ α for all t ∈ N implies that FDR(t) ≤ α for all t ∈ N.
The proof of this theorem is given in Section 3.2, and is based on a “reverse super-uniformity lemma” that is discussed in the next section.",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"This lemma, though of a technical nature, may be of independent interest in deriving new algorithms.",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
"The statements on mFDR control allow SAFFRON to be used in place of LORD in applications in which p-values are not independent, but are conditionally super-uniformly distributed, such as the MAB-FDR framework (based on multi-armed bandits) proposed by Yang et al. (2017).",2.2. A Better Estimate of the Alpha-Wealth Spent on Testing Nulls,[0],[0]
We now present the SAFFRON algorithm at a high level.,2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"For simplicity, we consider the constant λ setting, which performs well in experiments, though it may be a useful direction for future work to construct good heuristics for time-varying sequences {λj}∞j=1.
1.",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"Given a target FDR level α, the user first picks a constant λ ∈ (0, 1), an initial wealth W0 < (1− λ)α, and a positive non-increasing sequence {γj}∞j=1 of summing to one.",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"For example, given a parameter s > 1, we might pick γj ∝ j−s for some s > 1.
2.",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"We use the term “candidates” to refer to p-values smaller than λ, since SAFFRON will never reject a p-value larger than λ.",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"Recalling the indicator for candidacy Ct : = 1 {Pt ≤ λ}, and denoting by τj be the time of the j-th rejection (and setting τ0 = 0), define the candidates after the j-th rejection as Cj+ = Cj+(t) = ∑t−1",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"i=τj+1 Ci.
3.",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"SAFFRON begins by allocation α1 = min{γ1W0, λ},
and then at time t = 2, 3, . .",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"., it allocates:
αt : = min{λ, α̃t}, where α̃t : = W0γt−C0++ ((1− λ)α−W0)γt−τ1−C1+ + ∑ j≥2 (1− λ)αγt−τj−Cj+ .
",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"In words, SAFFRON starts off with an alpha-wealth W0 <",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"(1−λ)α, never loses wealth when testing candidate p-values, gains wealth of (1− λ)α on every rejection except the first.",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"If there is a significant fraction of non-nulls, and the signals are fairly strong, then SAFFRON may make more rejections than LORD.
",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"To clarify, SAFFRON guarantees FDR control for any λ ∈ (0, 1) and any chosen sequence {γj}∞j=1, but the algorithm’s power, or ability to detect signals, varies as a function of these parameters.",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"Given the minimal nature of our assumptions, there is no universally optimal constant or sequence: specifically, we do not make assumptions on the frequency of true signals, or on how strong they are, or on their order, all of which are factors that affect the power.",2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
We discuss reasonable default choices in the experimental section.,2.3. The SAFFRON Algorithm for Constant λ,[0],[0]
"Here, we compare SAFFRON to existing procedures in the literature, emphasizing commonalities that allow us to give a unified view of seemingly disparate algorithms.
",2.4. Relationship to Other Procedures,[0],[0]
Alpha-investing.,2.4. Relationship to Other Procedures,[0],[0]
"Even though the motivation that we have presented for SAFFRON relates it to the LORD algorithm, we find it interesting that the original alpha-investing algorithm of Foster and Stine (2008) is recovered by choosing λj = αj in F̂DPλ, and attempting to ensure that F̂DPλ(t) ≤ α for all times t ∈ N.",2.4. Relationship to Other Procedures,[0],[0]
"In order to see this fact, first note that with this choice of λj , the indicator 1 {Pj > λj} simply indicates when the j-th hypothesis is not rejected.",2.4. Relationship to Other Procedures,[0],[0]
"Consequently, the numerator of F̂DPλ reads as ∑ j≤t αj 1−αj 1 {j /∈ R(t)}.",2.4. Relationship to Other Procedures,[0],[0]
"Hence, ensuring that F̂DPλ(t) ≤ α at all times t ∈ N, is equivalent to ensuring that ∑ j≤t αj 1−αj 1 {j /∈ R(t)} never exceeds α(|R(t)| ∨ 1), which, in the language of alpha-investing, is equivalent to ensuring that the algorithm’s wealth never becomes negative.1 Just as Ramdas et al. (2017) were able to reinterpret and rederive LORD in terms of a particular estimate of the FDP, the current work allows us to reinterpret and rederive alpha-investing in terms of SAFFRON’s FDP.",2.4. Relationship to Other Procedures,[0],[0]
"However, our simulations demonstrate that despite this similarity, SAFFRON with λj = 1/2 is typically a more powerful algorithm than both LORD and alpha-investing.
",2.4. Relationship to Other Procedures,[0],[0]
"1Recall that the alpha-investing algorithm starts off with an alpha-wealth of α, reduces its alpha-wealth by αj
1−αj after tests
that fail to reject, and increase the wealth by α on rejections.
",2.4. Relationship to Other Procedures,[0],[0]
Storey-BH.,2.4. Relationship to Other Procedures,[0],[0]
"In offline multiple testing, where all n pvalues are immediately available, the Benjamini-Hochberg (BH) procedure (1995) is a classical method for guaranteeing FDR control.",2.4. Relationship to Other Procedures,[0],[0]
"BH estimates the FDP of the rejection set R(s) := {i : Pi ≤ s} by F̂DPBH(s) : = n·s|R(s)| , which is a conservative estimate of the oracle FDP∗BH(s) : = |H0|·s |R(s)| (details in Supplementary Material).",2.4. Relationship to Other Procedures,[0],[0]
"For independent pvalues, Storey et al. (2002; 2004) improved the BH method, by picking a constant λ ∈ (0, 1), and calculating:
F̂DPStBH(s) : = n · s · π̂0 |R(s)| ,
where π̂0 is an estimate of the unknown proportion of nulls π0 = |H0|/n computed as:
π̂0 : = 1 + ∑n i=1",2.4. Relationship to Other Procedures,[0],[0]
"1 {Pi > λ} n(1− λ) .
",2.4. Relationship to Other Procedures,[0],[0]
"Then, this procedure, which we refer to as “Storey-BH,” calculates ŝStBH : = max{s : F̂DPStBH(s) ≤ α} and rejects the setR(ŝStBH) which satisfies the bound FDR ≤ α.",2.4. Relationship to Other Procedures,[0],[0]
"Procedures such as Storey-BH are known in the multiple testing literature as adaptive procedures, since they automatically adapt to the unknown proportion of nulls.
",2.4. Relationship to Other Procedures,[0],[0]
"Returning to the setting of online FDR, what matters is not the proportion of nulls π0, but instead a running estimate of the amount of alpha-wealth that was spent testing nulls thus far; this difference arises because, unlike the offline setting where all p-values are compared to the same level ŝ, different p-values have to pass different thresholds αi.",2.4. Relationship to Other Procedures,[0],[0]
"In light of the above discussion, it should be apparent that Storey-BH is to BH as SAFFRON is to LORD.",2.4. Relationship to Other Procedures,[0],[0]
"In the offline context, Storey-BH is called an “adaptive method” (it is adaptive to the unknown null proportion) and in this sense, SAFFRON can be seen as an adaptive online FDR method.
",2.4. Relationship to Other Procedures,[0],[0]
Accumulation tests.,2.4. Relationship to Other Procedures,[0],[0]
Note that E [2I(P > 1/2)],2.4. Relationship to Other Procedures,[0],[0]
"≥ 1 for null p-values (with equality when they are exactly uniformly distributed, simply because ∫ 1 0
2I(p > 1/2)dp",2.4. Relationship to Other Procedures,[0],[0]
= 1).,2.4. Relationship to Other Procedures,[0],[0]
One may actually use any non-decreasing function h such that∫ 1 0 h(p)dp in the formula for F̂DPλ.,2.4. Relationship to Other Procedures,[0],[0]
"Such accumulation functions were studied (Li & Barber, 2017) in the (offline) context of ordered testing, and may seamlessly be transferred to the online setting considered here, yielding mFDR control using the same proof.",2.4. Relationship to Other Procedures,[0],[0]
"In initial experiments, the use of other functions does not seem to yield any advantage, and under some additional assumptions in the offline ordered testing setting, the aforementioned authors argued that the step function (1− λ)−1I(I > λ) is asymptotically optimal for power.",2.4. Relationship to Other Procedures,[0],[0]
"In this light, SAFFRON can also be seen as an online analog of adaptive SeqStep (Lei & Fithian, 2016), which is a variant of selective SeqStep (Barber & Candès, 2015) and SeqStep (Li & Barber, 2017).",2.4. Relationship to Other Procedures,[0],[0]
"In this section, we present a lemma that is central to the proof of FDR control for SAFFRON.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
We then use this lemma to prove Proposition 1 and Theorem 1.,3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
Let us first recall and set up some preliminary notation.,3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"In what follows, αt, λt are random variables in (0, 1) that always satisfy αt ≤",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
λt.,3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"We denote the indicator for rejection at the t-th step by Rt : = 1 {Pt ≤ αt}, and recall that since only p-values smaller than λt are candidates for rejection, we had earlier defined the indicator for candidacy as Ct : = 1 {Pt ≤ λt}.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"If we denote C̄t = 1 − Ct, then it is clear that RtC̄t = 0, since Rt = 1 implies C̄t = 0 and C̄t = 1 implies Rt = 0, and it is also possible for Rt and C̄t to both equal 0.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"Also let R1:t : = {R1, . . .",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
", Rt} and C1:t : = {C1, . . .",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
", Ct}.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"As before, we consider the filtration F t : = σ(R1:t, C1:t).",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"In what follows, we insist that the sequences {αt}∞t=1 and {λt}∞t=1 are predictable, meaning that they are functions of the information available from time 1 to t",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"− 1 only; specifically, we insist that αt, λt are measurable with respect to the sigma-field F t−1.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"We will also require that the {αt} sequence is monotone, meaning that αt = ft(R1:t−1, C1:t−1) for some coordinatewise nondecreasing function ft : {0, 1}2(t−1)",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
→,3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"[0, λt].",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"The proof that SAFFRON as described in Subsection 2.3 satisfies this requirement is given in the Supplementary Material.
",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"Recall the definition (4) of conditional super-uniformity, as well as its equivalent rephrased form in the line after definition (4).",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"Lemma 1 guarantees that for independent p-values, this statement holds true more generally.
",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
Lemma 1.,3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"Assume that the p-values P1, P2, . . .",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"are independent and let g : {0, 1}T → R be any coordinatewise non-decreasing function.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"Then, for any index t ≤ T such that Ht ∈ H0, we have:
E [ ft(R1:t−1, C1:t−1)1 {Pt > λt}
(1− λt)g(R1:T ) ∣∣∣∣ F t−1] ≥ E [ ft(R1:t−1, C1:t−1)
g(R1:T ) ∣∣∣∣ F t−1] ≥ E [ 1 {Pt ≤ ft(R1:t−1, C1:t−1)}
g(R1:T )",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
∣∣∣∣ F t−1] .,3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
Proof.,3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"The second inequality is a consequence of superuniformity lemmas from past work (Ramdas et al., 2017; Javanmard & Montanari, 2017), so we only prove the first inequality.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"At a high level, the proof strategy is inverted, and we will hallucinate a vector with one element being set to 1, instead of being set to 0 in the aforementioned works.
",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"Letting P1:T = (P1, . . .",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
", PT ) be the original vector of p-values, we define a “hallucinated” vector of p-values P̃ t→11:T : = (P̃1, . . .",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
", P̃T ) that equals P1:T , except that the
t-th component is set to one:
P̃i",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"= { 1 if i = t Pi if i 6= t.
Define hallucinated candidate and rejection indicators as C̃i = 1 { P̃i ≤ λi } and R̃i =
1 { P̃i ≤",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"fi(R̃1:i−1, C̃1:i−1) } respectively.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"Let
R1:T = (R1, . . .",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
", RT ) and R̃t→11:T = (R̃1, . . .",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
", R̃T ) denote the vector of rejections using P1:T and P̃ t→11:T , respectively.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"Similarly, let C1:T = (C1, . . .",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
", CT ) and C̃t→11:T = (C̃1, . . .",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
", C̃T ) denote the vector of candidates using P1:T and P̃ t→11:T , respectively.
",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"By construction, we have the following properties:
1.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"R̃i = Ri and C̃i = Ci for all i < t, hence fi(R1:i−1, C1:i−1) =",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"fi(R̃1:i−1, C̃1:i−1) for all i ≤ t.
2.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"R̃t = C̃t = 0, and hence R̃i ≤ Ri for all i ≥ t, due to monotonicity of the functions fi.
Hence, on the event {Pt > λt}, we have Rt = R̃t = 0 and Ct = C̃t = 0, and hence also R1:T = R̃t→11:T .",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"This allows us to conclude that:
ft(R1:t−1, C1:t−1)1 {Pt > λt} (1− λt)g(R1:T ) =
ft(R1:t−1, C1:t−1)1 {Pt > λt} (1− λt)g(R̃t→11:T ) .
",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"Since R̃t→11:T is independent of Pt, we may take conditional expectations to obtain:
E",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"[ ft(R1:t−1, C1:t−1)1 {Pt > λt}
(1− λt)g(R1:T ) ∣∣∣∣ F t−1] = E",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"[ ft(R1:t−1, C1:t−1)1 {Pt > λt}
(1− λt)g(R̃t→11:T )
∣∣∣∣∣",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"F t−1 ]
(i) ≥",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"E
[ ft(R1:t−1, C1:t−1)
g(R̃t→11:T )
∣∣∣∣∣",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"F t−1 ]
(ii) ≥ E",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"[ ft(R1:t−1, C1:t−1)
g(R1:T )",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"∣∣∣∣ F t−1] , where inequality (i) follows by taking an expectation only with respect to Pt by invoking the conditional superuniformity property (4); and inequality (ii) follows because g(R1:T ) ≥ g(R̃t→11:T ) since Ri ≥ R̃i for all i by monotonicity of the online FDR rule.",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"This concludes the proof of the lemma.
",3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
We now proceed to using the above lemma to prove Proposition 1 and Theorem 1.,3. Proof of Theorem 1 Using a Reverse Super-Uniformity Lemma,[0],[0]
"Statement (a) is proved by noting that for any time t ∈ N, we have:
E [ |H0 ∩R(t)| ] = ∑ j≤t,j∈H0 E",3.1. Proof of Proposition 1,[0],[0]
"[1 {Pj ≤ αj}]
≤ ∑
j≤t,j∈H0 E",3.1. Proof of Proposition 1,[0],[0]
"[αj ] ,
where the inequality follows after taking iterated expectations by conditioning on F j−1, and then applying the conditional super-uniformity property (3).
",3.1. Proof of Proposition 1,[0],[0]
"If we have FDP∗(t) : = 1|R(t)| ∑
j≤t,j∈H0 αj ≤ α, as assumed
in statement (b), then it follows that:
∑ j≤t,j∈H0 E",3.1. Proof of Proposition 1,[0],[0]
"[αj ] = E  ∑ j≤t,j∈H0 αj  ≤ αE",3.1. Proof of Proposition 1,[0],[0]
"[|R(t)|] ,
using linearity of expectation and the assumption on FDP∗(t).",3.1. Proof of Proposition 1,[0],[0]
"Using part (a) and rearranging yields the inequality mFDR(t) : = E[|H0∩R(t)|]
E[|R(t)|] ≤ α, which concludes the proof of part (b).
",3.1. Proof of Proposition 1,[0],[0]
"If, in addition, the null p-values are independent of each other and of the non-nulls and the sequence {αt} is monotone, we can use the following argument to prove claims (c) and (d).",3.1. Proof of Proposition 1,[0],[0]
These claims establish that the procedure controls the FDR at any time t ∈ N.,3.1. Proof of Proposition 1,[0],[0]
"Still assuming the inequality FDP∗(t) ≤ α, we have:
FDR(t) =",3.1. Proof of Proposition 1,[0],[0]
E [ |H0 ∩R(t)| |R(t)| ],3.1. Proof of Proposition 1,[0],[0]
"=
∑ j≤t,j∈H0 E [ 1 {Pj ≤ αj} |R(t)| ························ ]
≤ ∑ j≤t,j∈H0 E [ αj |R(t)| ············ ] = E [FDP∗(t)] ≤ α,
where the first inequality follows after taking iterated expectations by conditioning on F j−1, and then applying the super-uniformity lemma (Ramdas et al., 2017), the following equality uses linearity of expectation, and the final inequality follows by the assumption on FDP∗(t).",3.1. Proof of Proposition 1,[0],[0]
This concludes the proof of both statements (c) and (d).,3.1. Proof of Proposition 1,[0],[0]
"First note that, for any time t ∈ N, we have: E [ |H0 ∩R(t)| ] = ∑ j≤t,j∈H0 E",3.2. Proof of Theorem 1,[0],[0]
"[1 {Pj ≤ αj}]
(i) ≤ ∑
j≤t,j∈H0 E",3.2. Proof of Theorem 1,[0],[0]
"[αj ]
(ii)
≤",3.2. Proof of Theorem 1,[0],[0]
"E  ∑ j≤t,j∈H0 αj 1 {Pj > λj} 1− λj  , where inequality (i) first uses the law of iterated expectations by conditioning onF j−1, and then both (i) and (ii) apply the conditional super-uniformity property (4), which concludes the proof of part (a).",3.2. Proof of Theorem 1,[0],[0]
"To prove part (b), we drop the condition j ∈ H0 from the last expectation, and use the assumption
that F̂DPλ(t) : = ∑ j≤t αj 1{Pj>λj} 1−λj |R(t)| ≤",3.2. Proof of Theorem 1,[0],[0]
"α to obtain:
E  ∑ j≤t,j∈H0 αj 1 {Pj > λj} 1− λj  ≤ αE",3.2. Proof of Theorem 1,[0],[0]
[|R(t)|] .,3.2. Proof of Theorem 1,[0],[0]
"Combining this inequality with the result of part (a), and rearranging the terms, we reach the conclusion that mFDR(t) ≤ α, as desired.",3.2. Proof of Theorem 1,[0],[0]
"Under the independence and monotonicity assumptions of parts (c, d), we have
FDR(t) = E [ |H0 ∩R(t)| |R(t)| ]",3.2. Proof of Theorem 1,[0],[0]
"=
∑ j≤t,j∈H0 E [ 1 {Pj ≤ αj} |R(t)| ························ ]
(iii) ≤ ∑ j≤t,j∈H0 E [ αj |R(t)| ············ ] (iv)
≤ ∑ j≤t,j∈H0 E",3.2. Proof of Theorem 1,[0],[0]
"[ αj1 {Pj > λj} (1− λj)|R(t)| ····························· ] ,
where inequality (iii) first uses iterated expectations by conditioning on F j−1, and then both (iii) and (iv) apply Lemma 1.",3.2. Proof of Theorem 1,[0],[0]
"Assuming that the inequality F̂DPλ(t) ≤ α holds, it follows that:∑ j≤t,j∈H0 E",3.2. Proof of Theorem 1,[0],[0]
[ αj1 {Pj > λj} (1− λj)|R(t)| ····························· ] (v) ≤,3.2. Proof of Theorem 1,[0],[0]
E,3.2. Proof of Theorem 1,[0],[0]
"[∑ j≤t αj1 {Pj > λj} (1− λj)|R(t)| ········································ ]
(vi) = E [ F̂DPλ(t) ]",3.2. Proof of Theorem 1,[0],[0]
"(vii)
≤ α,
where inequality (v) follows by linearity of expectation and summing over a larger set of indices; equality (vi) simply uses the definition of F̂DPλ(t), and inequality (vii) follows by the assumption, hence proving parts (c,d).",3.2. Proof of Theorem 1,[0],[0]
"In this section, we provide the results of some numerical experiments that compare the performance of SAFFRON with current state-of-the-art algorithms for online FDR control, namely the aforementioned LORD and alpha-investing procedures.2 For each method, we provide empirical evaluations of its power while ensuring that the FDR remains below a chosen value.",4. Numerical Simulations,[0],[0]
"We only run simulations since for real data, we would not know the ground truth and hence which discoveries are true or false.
",4. Numerical Simulations,[0],[0]
"The following two subsections separately analyze two experimental settings - one in which the p-values are computed from Gaussian observations, and another in which the pvalues under the alternative are drawn from a beta distribution.",4. Numerical Simulations,[0],[0]
"In both cases, SAFFRON outperforms the competing algorithms, with the exact level of performance depending on the choice of sequence {γj}.",4. Numerical Simulations,[0],[0]
All experiments use a target FDR of α = 0.05 and estimate the FDR and power by averaging over 200 independent trials.,4. Numerical Simulations,[0],[0]
"As previously mentioned, the constant sequence λj = 1/2 for all j was found to be particularly successful, so this is our default choice, and we drop the index for simplicity.",4. Numerical Simulations,[0],[0]
We use the simple experimental setup of testing the mean of a Gaussian distribution with T = 1000 components.,4.1. Testing with Gaussian Observations,[0],[0]
"More precisely, for each index i ∈ {1, . . .",4.1. Testing with Gaussian Observations,[0],[0]
", T}, the null hypothesis takes the form",4.1. Testing with Gaussian Observations,[0],[0]
Hi : µi = 0.,4.1. Testing with Gaussian Observations,[0],[0]
"The observations consist of independent Gaussian variates Zi ∼ N(µi, 1), which are converted into one-sided p-values using the transform Pi = Φ(−Zi), where Φ is the standard Gaussian CDF.",4.1. Testing with Gaussian Observations,[0],[0]
"The motivation for one-sided conversion lies in A/B testing, where one wishes to detect larger effects, not smaller.",4.1. Testing with Gaussian Observations,[0],[0]
"The parameter µi is chosen according to a mixture model:
µi = { 0 with probability 1− π1 F1 with probability π1,
where the random variable F1 is of the form N(µc, 1) for some constant µc.",4.1. Testing with Gaussian Observations,[0],[0]
"We ran simulations for µc ∈ {2, 3}, thus seeing how changing the distance of the alternative mean to the null mean affects the performance of SAFFRON.
",4.1. Testing with Gaussian Observations,[0],[0]
"In what follows, we compare SAFFRON’s achieved power and FDR to those of LORD and alpha-investing.",4.1. Testing with Gaussian Observations,[0],[0]
"The constant infinite sequence γj ∝ log(j∨2)je√log j , where the proportionality constant is determined so that the sequence sums to one, was shown to be asymptotically optimal for testing Gaussian means via the LORD method in the paper (Javanmard & Montanari, 2017).",4.1. Testing with Gaussian Observations,[0],[0]
"Since SAFFRON loses wealth only when
2The code for all simulations described in this section is available at: https://github.com/tijana-zrnic/SAFFRONcode
testing non-candidates whereas LORD loses wealth at every step, it is expected to behave more conservatively and not use up its wealth at the same rate, conditioned on both using the same sequence {γj}.",4.1. Testing with Gaussian Observations,[0],[0]
"For this reason, informally speaking, it can reuse this leftover wealth, hence the sequence {γj} chosen for SAFFRON is more aggressive, in the sense that more wealth is concentrated around the beginning of the sequence.",4.1. Testing with Gaussian Observations,[0],[0]
"In particular, we choose sequences of the form γj ∝ j−s, where the parameter s > 1 controls the aggressiveness of the procedure; the greater the constant s, the more wealth is concentrated around small values of j. We also consider these sequences for LORD, thus observing the difference in performance resulting from using a more aggressive sequence in the regime of a finite sequence of pvalues.",4.1. Testing with Gaussian Observations,[0],[0]
"Figures showing the power and FDR of SAFFRON and LORD by varying the aggressiveness of sequence {γj} are in the Supplementary Material.
",4.1. Testing with Gaussian Observations,[0],[0]
"In Figure 2 we consider F1 = N(2, 1), and compare the level of performance of alpha-investing, SAFFRON and LORD, the latter two using the highest performing sequence chosen among six possible sequences.",4.1. Testing with Gaussian Observations,[0],[0]
"Figure 1 demonstrates the same comparison for a similar but somewhat easier testing problem, with F1 = N(3, 1).",4.1. Testing with Gaussian Observations,[0],[0]
"Experiments indicate that increasing the fraction of non-null hypotheses allows SAFFRON to achieve a faster increase of power than LORD, thus performing considerably better than both LORD and the alpha-investing procedure in settings with a great number of non-null observations.",4.1. Testing with Gaussian Observations,[0],[0]
"In this setting we generate the p-value sequence according to the following model:
Pi ∼ { Unif[0, 1], with probability 1− π1 Beta(m,n), with probability π1,
where i ∈",4.2. Testing with Beta Alternatives,[0],[0]
"[T ] and T = 1000, as before.",4.2. Testing with Beta Alternatives,[0],[0]
"Again we compare the performance of SAFFRON, alpha-investing and LORD in terms of the achieved power with the FDR controlled under a chosen level.",4.2. Testing with Beta Alternatives,[0],[0]
"For LORD, the asymptotically optimal sequence {γj} was derived in the paper (Javanmard & Montanari, 2017) and is of the form γj ∝",4.2. Testing with Beta Alternatives,[0],[0]
( 1j log j) 1/m for m < 1 and n ≥ 1.,4.2. Testing with Beta Alternatives,[0],[0]
"As in the Gaussian case, for SAFFRON and additionally for LORD we consider the sequence γj ∝ j−s with varying s, which, unlike the aforementioned sequence, does not depend on the parameters of the distribution.",4.2. Testing with Beta Alternatives,[0],[0]
Please refer to the Supplementary Material for plots of achieved power and FDR of SAFFRON and LORD obtained by varying the sequence.,4.2. Testing with Beta Alternatives,[0],[0]
"For the particular distribution of the observed p-values we choose m = 0.5 and n = 5.
Figure 3 compares the performance of SAFFRON, LORD and alpha-investing, the first two using the highest performing sequence {γj} chosen among six considered sequences, as in the setting with Gaussian tests.",4.2. Testing with Beta Alternatives,[0],[0]
"Although simulations show SAFFRON performing similarly to LORD and alphainvesting for small fractions of non-null hypotheses, it significantly outperforms its competitors in terms of power and using up available wealth with a higher number of signals.",4.2. Testing with Beta Alternatives,[0],[0]
"This paper introduces SAFFRON, a new algorithmic framework for online mFDR and FDR control.",5. Summary,[0],[0]
We show empirically that SAFFRON is more powerful than existing algorithms.,5. Summary,[0],[0]
SAFFRON is based on a novel reverse superuniformity lemma that allows us to estimate the fraction of alpha-wealth that an algorithm spends on testing null hypotheses.,5. Summary,[0],[0]
"One may interpret SAFFRON as an adaptive version of LORD, just as Storey-BH is an adaptive version of the Benjamini-Hochberg algorithm.",5. Summary,[0],[0]
"Lastly, the derivation of SAFFRON is rather different from that of earlier generalized alpha-investing (GAI) algorithms, and as such provides a template for the derivation of new algorithms.",5. Summary,[0],[0]
"In the online false discovery rate (FDR) problem, one observes a possibly infinite sequence of pvalues P1, P2, . . .",abstractText,[0],[0]
", each testing a different null hypothesis, and an algorithm must pick a sequence of rejection thresholds α1, α2, . . .",abstractText,[0],[0]
"in an online fashion, effectively rejecting the k-th null hypothesis whenever Pk ≤ αk.",abstractText,[0],[0]
"Importantly, αk must be a function of the past, and cannot depend on Pk or any of the later unseen p-values, and must be chosen to guarantee that for any time t, the FDR up to time t is less than some pre-determined quantity α ∈",abstractText,[0],[0]
"(0, 1).",abstractText,[0],[0]
"In this work, we present a powerful new framework for online FDR control that we refer to as “SAFFRON”.",abstractText,[0],[0]
"Like older alphainvesting algorithms, SAFFRON starts off with an error budget (called alpha-wealth) that it intelligently allocates to different tests over time, earning back some alpha-wealth whenever it makes a new discovery.",abstractText,[0],[0]
"However, unlike older methods, SAFFRON’s threshold sequence is based on a novel estimate of the alpha fraction that it allocates to true null hypotheses.",abstractText,[0],[0]
"In the offline setting, algorithms that employ an estimate of the proportion of true nulls are called “adaptive”, hence SAFFRON can be seen as an online analogue of the offline Storey-BH adaptive procedure.",abstractText,[0],[0]
"Just as Storey-BH is typically more powerful than the Benjamini-Hochberg (BH) procedure under independence, we demonstrate that SAFFRON is also more powerful than its non-adaptive counterparts such as LORD.",abstractText,[0],[0]
"Departments of Statistics and Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, USA Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, USA.",abstractText,[0],[0]
"Correspondence to: Aaditya Ramdas <aramdas@eecs.berkeley.edu>, Tijana Zrnic <tijana@eecs.berkeley.edu>, Martin J. Wainwright <wainwrig@eecs.berkeley.edu>, Michael I. Jordan <jordan@eecs.berkeley.edu>.",abstractText,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",abstractText,[0],[0]
Copyright 2018 by the author(s).,abstractText,[0],[0]
SAFFRON: an Adaptive Algorithm for Online Control of the False Discovery Rate,title,[0],[0]
"Proceedings of the SIGDIAL 2017 Conference, pages 147–157, Saarbrücken, Germany, 15-17 August 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Task-oriented Spoken Dialogue Systems (SDS) aim to assist users to achieve specific goals via speech, such as hotel booking, restaurant information and accessing bus-schedules.",1 Introduction,[0],[0]
"These systems are typically designed according to a structured ontology (or a database schema), which defines the
domain that the system can talk about.",1 Introduction,[0],[0]
The development of a robust SDS traditionally requires a substantial amount of hand-crafted rules combined with various statistical components.,1 Introduction,[0],[0]
"This includes a spoken language understanding module (Chen et al., 2016; Yang et al., 2017), a dialogue belief state tracker (Henderson et al., 2014; Perez and Liu, 2016; Mrkšić et al., 2017) to predict user intent and track the dialogue history, a dialogue policy (Young et al., 2013; Gašić and Young, 2014; Budzianowski et al., 2017) to determine the dialogue flow, and a natural language generator (Rieser and Lemon, 2009; Wen et al., 2015; Hu et al., 2017) to convert conceptual representations into system responses.
",1 Introduction,[0],[0]
"In a task-oriented SDS, teaching a system how to respond appropriately in all situations is nontrivial.",1 Introduction,[0],[0]
"Traditionally, this dialogue management component has been designed manually using flow charts.",1 Introduction,[0],[0]
"More recently, it has been formulated as a planning problem and solved using reinforcement learning (RL) to optimise a dialogue policy through interaction with users (Levin and Pieraccini, 1997; Roy et al., 2000; Williams and Young, 2007; Jurčı́ček et al., 2011).",1 Introduction,[0],[0]
"In this framework, the system learns by a trial and error process governed by a potentially delayed learning objective called the reward.",1 Introduction,[0],[0]
This reward is designed to encapsulate the desired behavioural features of the dialogue.,1 Introduction,[0],[0]
"Typically it provides a positive reward for success plus a per turn penalty to encourage short dialogues (El Asri et al., 2014; Su et al., 2015a; Vandyke et al., 2015; Su et al., 2016b).
",1 Introduction,[0],[0]
"To allow the system to be trained on-line, Bayesian sample-efficient learning algorithms have been proposed (Gašić and Young, 2014; Daubigney et al., 2014) which can learn policies from a minimal number of dialogues.",1 Introduction,[0],[0]
"However, even with such methods, the initial performance is still relatively poor, and this can impact negatively
147
on the user experience.",1 Introduction,[0],[0]
Supervised learning (SL) can also be used for dialogue action selection.,1 Introduction,[0],[0]
"In this case, the policy is trained to produce an appropriate response for any given dialogue state.",1 Introduction,[0],[0]
"Wizard-of-Oz (WoZ) methods (Kelley, 1984; Dahlbäck et al., 1993) have been widely used for collecting domain-specific training corpora.",1 Introduction,[0],[0]
"Recently an emerging line of research has focused on training neural networkbased dialogue models, mostly in text-based systems (Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2015; Wen et al., 2017; Bordes et al., 2017).",1 Introduction,[0],[0]
These systems are directly trained on past dialogues without detailed specification of the internal dialogue state.,1 Introduction,[0],[0]
"However, there are two key limitations of using SL in SDS.",1 Introduction,[0],[0]
"Firstly, the effect of selecting an action on the future course of the dialogue is not considered and this may result in sub-optimal behaviour.",1 Introduction,[0],[0]
"Secondly, there will often be a large number of dialogue states which are not covered by the training data (Henderson et al., 2008; Li et al., 2014).",1 Introduction,[0],[0]
"Moreover, there is no reason to suppose that the recorded dialogue participants are acting optimally, especially in high noise levels.",1 Introduction,[0],[0]
"These problems are exacerbated in larger domains where multi-step planning is needed.
",1 Introduction,[0],[0]
"In this paper, we propose a network-based approach to policy learning which combines the best of both SL- and RL-based dialogue management, and which capitalises on recent advances in deep RL (Mnih et al., 2015), especially off-policy algorithms (Wang et al., 2017).
",1 Introduction,[0],[0]
"The main contribution of this paper is two-fold:
1. improving the sample-efficiency of actorcritic RL: trust region actor-critic with experience replay (TRACER) and episodic natural actor-critic with experience replay (eNACER).
",1 Introduction,[0],[0]
"2. efficient utilisation of demonstration data for improved early stage policy learning.
",1 Introduction,[0],[0]
The first part focusses primarily on increasing the RL learning speed.,1 Introduction,[0],[0]
"For TRACER, trust regions are introduced to standard actor-critic to control the step size and thereby avoid catastrophic model changes.",1 Introduction,[0],[0]
"For eNACER, the natural gradient identifies steepest ascent direction in policy space to ensure fast convergence.",1 Introduction,[0],[0]
Both models exploit the off-policy learning with experience replay (ER) to improve sample-efficiency.,1 Introduction,[0],[0]
"These are compared with various state-of-the-art RL methods.
",1 Introduction,[0],[0]
The second part aims to mitigate the cold start issue by using demonstration data to pre-train an RL model.,1 Introduction,[0],[0]
"This resembles the training procedure adopted in recent game playing applications (Silver et al., 2016; Hester et al., 2017).",1 Introduction,[0],[0]
"A key feature of this framework is that a single model is trained using both SL and RL with different training objectives but without modifying the architecture.
",1 Introduction,[0],[0]
"By combining the above, we demonstrate a practical approach to learning deep RL-based dialogue policies for new domains which can achieve competitive performance without significant detrimental impact on users.",1 Introduction,[0],[0]
"RL-based approaches to dialogue management have been actively studied for some time (Levin et al., 1998; Lemon et al., 2006; Gašić and Young, 2014).",2 Related Work,[0],[0]
"Initially, systems suffered from slow training, but recent advances in data efficient methods such as Gaussian Processes (GP) have enabled systems to be trained from scratch in on-line interaction with real users (Gašić et al., 2011).",2 Related Work,[0],[0]
GP provides an estimate of the uncertainty in the underlying function and a built-in noise model.,2 Related Work,[0],[0]
"This helps to achieve highly sample-efficient exploration and robustness to recognition/understanding errors.
",2 Related Work,[0],[0]
"However, since the computation in GP scales with the number of points memorised, sparse approximation methods such as the kernel span algorithm (Engel, 2005) must be used and this limits the ability to scale to very large training sets.",2 Related Work,[0],[0]
It is therefore questionable as to whether GP can scale to support commercial wide-domain SDS.,2 Related Work,[0],[0]
"Nevertheless, GP provides a good benchmark and hence it is included in the evaluation below.
",2 Related Work,[0],[0]
"In addition to increasing the sample-efficiency of the learning algorithms, the use of reward shaping has also been investigated in (El Asri et al., 2014; Su et al., 2015b) to enrich the reward function in order to speed up dialogue policy learning.
",2 Related Work,[0],[0]
Combining SL with RL for dialogue modelling is not new.,2 Related Work,[0],[0]
"Henderson et al. (2008) proposed a hybrid SL/RL model that, in order to ensure tractability in policy optimisation, performed exploration only on the states in a dialogue corpus.",2 Related Work,[0],[0]
The policy was then defined manually on parts of the space which were not found in the corpus.,2 Related Work,[0],[0]
"A method of initialising RL models using logistic regression was also described (Rieser and Lemon, 2006).",2 Related Work,[0],[0]
"For GPRL in dialogue, rather than using a linear kernel
that imposes heuristic data pair correlation, a preoptimised Gaussian kernel learned using SL from a dialogue corpus has been proposed (Chen et al., 2015).",2 Related Work,[0],[0]
"The resulting kernel was more accurate on data correlation and achieved better performance, however, the SL corpus did not help to initialise a better policy.",2 Related Work,[0],[0]
"Better initialisation of GPRL has been studied in the context of domain adaptation by specifying a GP prior or re-using an existing model which is then pre-trained for the new domain (Gašić et al., 2013).
",2 Related Work,[0],[0]
"A number of authors have proposed training a standard neural-network policy in two stages (Fatemi et al., 2016; Su et al., 2016a; Williams et al., 2017).",2 Related Work,[0],[0]
Asadi and Williams (2016) also explored off-policy RL methods for dialogue policy learning.,2 Related Work,[0],[0]
"All these studies were conducted in simulation, using error-free text-based input.",2 Related Work,[0],[0]
"A similar approach was also used in a conversational model (Li et al., 2016).",2 Related Work,[0],[0]
"In contrast, our work introduces two new sample-efficient actor-critic methods, combines both two-stage policy learning and off-policy RL, and testing at differing noise levels.",2 Related Work,[0],[0]
The proposed framework addresses the dialogue management component in a modular SDS.,3 Neural Dialogue Management,[0],[0]
The input to the model is the belief state b that encodes a distribution over the possible user intents along with the dialogue history.,3 Neural Dialogue Management,[0],[0]
The model’s role is to select the system action a at every turn that will lead to the maximum possible cumulative reward and a successful dialogue outcome.,3 Neural Dialogue Management,[0],[0]
"The system action is mapped into a system reply at the semantic level, and this is subsequently passed to the natural language generator for output to the user.
",3 Neural Dialogue Management,[0],[0]
"The semantic reply consists of three parts: the intent of the response, (e.g. inform), which slots to talk about (e.g. area), and a value for each slot (e.g. east).",3 Neural Dialogue Management,[0],[0]
"To ensure tractability, the policy selects a from a restricted action set which identifies the intent and sometimes a slot, any remaining information required to complete the reply is extracted using heuristics from the tracked belief state.",3 Neural Dialogue Management,[0],[0]
Dialogue policy optimisation can be seen as the task of learning to select the sequence of responses (actions) at each turn which maximises the longterm objective defined by the reward function.,3.1 Training with Reinforcement Learning,[0],[0]
"This can be solved by applying either value-based
or policy-based methods.",3.1 Training with Reinforcement Learning,[0],[0]
"In both cases, the goal is to find an optimal policy π∗ that maximises the discounted total return R = ∑T−1 t=0 γ
trt(bt, at) over a dialogue with T turns where rt(bt, at) is the reward when taking action at in dialogue belief state bt at turn t and γ is the discount factor.
",3.1 Training with Reinforcement Learning,[0],[0]
The main difference between the two categories is that policy-based methods have stronger convergence characteristics than value-based methods.,3.1 Training with Reinforcement Learning,[0],[0]
"The latter often diverge when using function approximation since they optimise in value space and a slight change in value estimate can lead to a large change in policy space (Sutton et al., 2000).
",3.1 Training with Reinforcement Learning,[0],[0]
"Policy-based methods suffer from low sampleefficiency, high variance and often converge to local optima since they typically learn via Monte Carlo estimation (Williams, 1992; Schulman et al., 2016).",3.1 Training with Reinforcement Learning,[0],[0]
"However, they are preferred due to their superior convergence properties.",3.1 Training with Reinforcement Learning,[0],[0]
Hence in this paper we focus on policy-based methods but also include a value-based method as a baseline.,3.1 Training with Reinforcement Learning,[0],[0]
"In a policy-based method, the training objective is to find a parametrised policy πθ(a|b) that maximises the expected reward J(θ) over all possible dialogue trajectories given a starting state.
",3.1.1 Advantage Actor-Critic (A2C),[0],[0]
"Following the Policy Gradient Theorem (Sutton et al., 2000), the gradient of the parameters given the objective function has the form:
∇θJ(θ) =",3.1.1 Advantage Actor-Critic (A2C),[0],[0]
E,3.1.1 Advantage Actor-Critic (A2C),[0],[0]
"[∇θ log πθ(a|b)Qπθ(b, a)] .",3.1.1 Advantage Actor-Critic (A2C),[0],[0]
"(1) Since this form of gradient has a potentially high variance, a baseline function is typically introduced to reduce the variance whilst not changing the estimated gradient (Williams, 1992; Sutton and Barto, 1999).",3.1.1 Advantage Actor-Critic (A2C),[0],[0]
"A natural candidate for this
baseline is the value function V (b).",3.1.1 Advantage Actor-Critic (A2C),[0],[0]
"Equation 2 then becomes:
∇θJ(θ) =",3.1.1 Advantage Actor-Critic (A2C),[0],[0]
E,3.1.1 Advantage Actor-Critic (A2C),[0],[0]
"[∇θ log πθ(a|b)Aw(b, a)] , (2) where Aw(b, a) = Q(b, a) − V (b) is the advantage function.",3.1.1 Advantage Actor-Critic (A2C),[0],[0]
"This can be viewed as a special case of the actor-critic, where πθ is the actor and Aw(b, a) is the critic, defined by two parameter sets θ and w. To reduce the number of required parameters, temporal difference (TD) errors δw = rt",3.1.1 Advantage Actor-Critic (A2C),[0],[0]
"+ γVw(bt+1)− Vw(bt) can be used to approximate the advantage function (Schulman et al., 2016).",3.1.1 Advantage Actor-Critic (A2C),[0],[0]
The left part in Figure 1 shows the architecture and parameters of the resulting A2C policy.,3.1.1 Advantage Actor-Critic (A2C),[0],[0]
"To boost the performance of A2C policy learning, two methods are introduced:
I. Experience replay with off-policy learning for speed-up
On-policy RL methods update the model with the samples collected via the current policy.",3.1.2 The TRACER Algorithm,[0],[0]
"Sample-efficiency can be improved by utilising experience replay (ER) (Lin, 1992), where minibatches of dialogue experiences are randomly sampled from a replay pool P to train the model.",3.1.2 The TRACER Algorithm,[0],[0]
This increases learning efficiency by re-using past samples in multiple updates whilst ensuring stability by reducing the data correlation.,3.1.2 The TRACER Algorithm,[0],[0]
"Since these past experiences were collected from different policies compared to the current policy, the use of ER leads to off-policy updates.
",3.1.2 The TRACER Algorithm,[0],[0]
"When training models with RL, -greedy action selection is often used to trade-off between exploration and exploitation, whereby a random action is chosen with probability otherwise the top-ranking action is selected.",3.1.2 The TRACER Algorithm,[0],[0]
"A policy used to generate a training dialogues (episodes) is referred to as a behaviour policy µ, in contrast to the policy to be optimised which is called the target policy π.
",3.1.2 The TRACER Algorithm,[0],[0]
The basic A2C training algorithm described in §3.1.1 is on-policy since it is assumed that actions are drawn from the same policy as the target to be optimised (µ = π).,3.1.2 The TRACER Algorithm,[0],[0]
"In off-policy learning, since the current policy π is updated with the samples generated from old behaviour policies µ, an importance sampling (IS) ratio is used to rescale each sampled reward to correct for the sampling bias at time-step t: ρt = π(at|bt)/µ(at|bt) (Meuleau et al., 2000).
",3.1.2 The TRACER Algorithm,[0],[0]
"For A2C, the off-policy gradient for the parametrised value function Vw thus has the form:
∆woff = ∑T−1
t=0
( R̄t − V̂w(bt) )",3.1.2 The TRACER Algorithm,[0],[0]
∇wV̂w(bt),3.1.2 The TRACER Algorithm,[0],[0]
"tΠ i=0 ρi, (3)
where R̄t is the off-policy Monte-Carlo return (Precup et al., 2001):
R̄t = rt + γrt+1 1 Π i=1",3.1.2 The TRACER Algorithm,[0],[0]
ρt+i + · · ·+ γT−t−1rT−1 T−1 Π i=1,3.1.2 The TRACER Algorithm,[0],[0]
ρt+i.,3.1.2 The TRACER Algorithm,[0],[0]
"(4)
Likewise, the updated gradient for policy πθ is:
∆θoff = T−1∑ t=0 ρt∇θ log πθ(at|bt)δ̂w, (5)
where δ̂w = rt + γV̂w(bt+1)− V̂w(bt) is the TD error using the estimated value of V̂w.
",3.1.2 The TRACER Algorithm,[0],[0]
"Also, as the gradient correlates strongly with the sampled reward, reward rt and total return R are normalised to lie in [-1,1] to stabilise training.
",3.1.2 The TRACER Algorithm,[0],[0]
II.,3.1.2 The TRACER Algorithm,[0],[0]
"Trust region constraint for stabilisation
To ensure stability in RL, each per-step policy change is often limited by setting a small learning rate.",3.1.2 The TRACER Algorithm,[0],[0]
"However, setting the rate low enough to avoid occasional large destabilising updates is not conducive to fast learning.
",3.1.2 The TRACER Algorithm,[0],[0]
"Here, we adopt a modified Trust Region Policy Optimisation method introduced by Wang et al. (2017).",3.1.2 The TRACER Algorithm,[0],[0]
"In addition to maximising the cumulative reward J(θ), the optimisation is also subject to a Kullback-Leibler (KL) divergence limit between the updated policy θ and an average policy θa to ensure safety.",3.1.2 The TRACER Algorithm,[0],[0]
"This average policy represents a running average of past policies and constrains the updated policy to not deviate far from the average θa ← αθa + (1− α)θ with a weight α.
",3.1.2 The TRACER Algorithm,[0],[0]
"Thus, given the off-policy policy gradient ∆θoff in Equation 5, the modified policy gradient with trust region g is calculated as follows:
minimize g 1 2 ‖∆θoff",3.1.2 The TRACER Algorithm,[0],[0]
"− g‖22, subject to ∇θDKL",3.1.2 The TRACER Algorithm,[0],[0]
"[πθa(bt)‖πθ(bt)]T g ≤ ξ,
where π is the policy parametrised by θ or θa, and ξ controls the magnitude of the KL constraint.",3.1.2 The TRACER Algorithm,[0],[0]
"Since the constraint is linear, a closed form solution to this quadratic programming problem can
be derived using the KKT conditions.",3.1.2 The TRACER Algorithm,[0],[0]
Setting k = ∇θDKL,3.1.2 The TRACER Algorithm,[0],[0]
"[πθa(bt)‖πθ(bt)], we get:
g∗tr = ∆θ off −max { kT∆θoff − ξ ‖k‖22 , 0 } k. (6)
",3.1.2 The TRACER Algorithm,[0],[0]
"When this constraint is satisfied, there is no change to the gradient with respect to θ.",3.1.2 The TRACER Algorithm,[0],[0]
"Otherwise, the update is scaled down along the direction of k and the policy change rate is lowered.",3.1.2 The TRACER Algorithm,[0],[0]
"This direction is also shown to be closely related to the natural gradient (Amari, 1998; Schulman et al., 2015), which is presented in the next section.
",3.1.2 The TRACER Algorithm,[0],[0]
The above enhancements speed up and stabilise A2C. We call it the Trust Region Actor-Critic with Experience Replay (TRACER) algorithm.,3.1.2 The TRACER Algorithm,[0],[0]
"Vanilla gradient descent algorithms are not guaranteed to update the model parameters in the steepest direction due to re-parametrisation (Amari, 1998; Martens, 2014).",3.1.3 The eNACER Algorithm,[0],[0]
"A widely used solution to this problem is to use a compatible function approximation for the advantage function in Equation 2: ∇wAw(b, a) = ∇θ log πθ(a|b), where the update of w is then in the same update direction as θ (Sutton et al., 2000).",3.1.3 The eNACER Algorithm,[0],[0]
"Equation 2 can then be rewritten as:
∇θJ(θ) =",3.1.3 The eNACER Algorithm,[0],[0]
E,3.1.3 The eNACER Algorithm,[0],[0]
"[∇θ log πθ(a|b)∇θ log πθ(a|b)Tw]
= F (θ) · w,
where F (θ) is the Fisher information matrix.",3.1.3 The eNACER Algorithm,[0],[0]
This implies ∆θNG = w = F (θ)−1∇θJ(θ) and it is called the natural gradient.,3.1.3 The eNACER Algorithm,[0],[0]
"The Fisher Matrix can be viewed as a correction term which makes the natural gradient independent of the parametrisation of the policy and corresponds to steepest ascent towards the objective (Martens, 2014).",3.1.3 The eNACER Algorithm,[0],[0]
"Empirically, the natural gradient has been found to significantly speed up convergence.
",3.1.3 The eNACER Algorithm,[0],[0]
"Based on these ideas, the Natural Actor-Critic (NAC) algorithm was developed by Peters and Schaal (2006).",3.1.3 The eNACER Algorithm,[0],[0]
"In its episodic version (eNAC), the Fisher matrix does not need to be explicitly computed.",3.1.3 The eNACER Algorithm,[0],[0]
"Instead, the gradient is estimated by a least squares method given the n-th episode consisting of a set of transition tuples {(bnt , ant , rnt )}Tn−1t=0 :
Rn = [∑Tn−1 t=0 ∇θ log πθ(ait|bit; θ)T ] ·∆θNG + C, (7)
which can be solved analytically.",3.1.3 The eNACER Algorithm,[0],[0]
"C is a constant which is an estimate of the baseline V (b).
",3.1.3 The eNACER Algorithm,[0],[0]
"As in TRACER, eNAC can be enhanced by using ER and off-policy learning, thus called eNACER, whereby Rn in Equation 7 is replaced by the off-policy Monte-Carlo return R̄n0 at timestep t = 0 as in Equation 4.",3.1.3 The eNACER Algorithm,[0],[0]
"For very large models, the inversion of the Fisher matrix can become prohibitively expensive to compute.",3.1.3 The eNACER Algorithm,[0],[0]
"Instead, a truncated variant can be used to calculate the natural gradient (Schulman et al., 2015).
eNACER is structured as a feed forward network with the output π as in the right of Figure 1, updated with natural gradient ∆θNG.",3.1.3 The eNACER Algorithm,[0],[0]
"Note that by using the compatible function approximation, the value function does not need to be explicitly calculated.",3.1.3 The eNACER Algorithm,[0],[0]
This makes eNACER in practice a policygradient method.,3.1.3 The eNACER Algorithm,[0],[0]
"From the user’s perspective, performing RL from scratch will invariably result in unacceptable performance in the early learning stages.",3.2 Learning from Demonstration Data,[0],[0]
This problem can be mitigated by an off-line corpus of demonstration data to bootstrap a policy.,3.2 Learning from Demonstration Data,[0],[0]
This data may come from a WoZ collection or from interactions between users and an existing policy.,3.2 Learning from Demonstration Data,[0],[0]
"It can be used in three ways: A: Pre-train the model, B: Initialise a supervised replay buffer Psup, and C: a combination of the two.
",3.2 Learning from Demonstration Data,[0],[0]
"(A) For model pre-training, the objective is to ‘mimic’ the response behaviour from the corpus.",3.2 Learning from Demonstration Data,[0],[0]
This phase is essentially standard SL.,3.2 Learning from Demonstration Data,[0],[0]
"The input to the model is the dialogue belief state b, and the training objective for each sample is to minimise a joint cross-entropy loss L(θ) = −∑k yk log(pk) between action labels y and model predictions p, where the policy is parametrised by a set θ.
",3.2 Learning from Demonstration Data,[0],[0]
A policy trained by SL on a fixed dataset may not generalise well.,3.2 Learning from Demonstration Data,[0],[0]
"In spoken dialogues, the noise levels may vary across conditions and thus can significantly affect performance.",3.2 Learning from Demonstration Data,[0],[0]
"Moreover, a policy trained using SL does not perform any long-term planning on the conversation.",3.2 Learning from Demonstration Data,[0],[0]
"Nonetheless, supervised pre-training offers a good model starting point which can then be fine-tuned using RL.
(B) For supervised replay initialisation, the demonstration data is stored in a replay pool Psup which is kept separate from the ER pool used for RL and is never over-written.",3.2 Learning from Demonstration Data,[0],[0]
"At each RL update iteration, a small portion of the demonstration data P ′sup is sampled, and the supervised crossentropy loss L(θ) computed on this data is added
to the RL objective J(θ).",3.2 Learning from Demonstration Data,[0],[0]
"Also, an L2 regularisation loss ‖·‖22 is applied to θ to help prevent it from over-fitting on the sampled demonstration dataset.",3.2 Learning from Demonstration Data,[0],[0]
"The total loss to be minimised is thus:
Lall(θ) = −J(θ)+λ1L(θ;P ′sup)+λ2‖θ‖22, (8)
where λ’s are weights.",3.2 Learning from Demonstration Data,[0],[0]
"In this way, the RL policy is guided by the sampled demonstration data while learning to optimise the total return.
",3.2 Learning from Demonstration Data,[0],[0]
(C),3.2 Learning from Demonstration Data,[0],[0]
The learned parameters of the pre-trained model in method A above might distribute differently from the optimal RL policy and this may cause some performance drop in early stages while learning an RL policy from this model.,3.2 Learning from Demonstration Data,[0],[0]
This can be alleviated by using the composite loss proposed in method B. A comparison between the three options is included in the experimental evaluation.,3.2 Learning from Demonstration Data,[0],[0]
"Our experiments utilised the software tool-kit PyDial (Ultes et al., 2017), which provides a platform for modular SDS.",4 Experimental Results,[0],[0]
The target application is a live telephone-based SDS providing restaurant information for the Cambridge (UK) area.,4 Experimental Results,[0],[0]
The task is to learn a policy which manages the dialogue flow and delivers requested information to the user.,4 Experimental Results,[0],[0]
"The domain consists of approximately 100 venues, each with 6 slots out of which 3 can be used by the system to constrain the search (food-type, area and price-range) and 3 are system-informable properties (phone-number, address and postcode) available once a database entity has been found.
",4 Experimental Results,[0],[0]
The input for all models was the full dialogue belief state b of size 268 which includes the last system act and distributions over the user intention and the three requestable slots.,4 Experimental Results,[0],[0]
The output includes 14 restricted dialogue actions determining the system intent at the semantic level.,4 Experimental Results,[0],[0]
"Combining the dialogue belief states and heuristic rules, it is then mapped into a spoken response using a natural language generator.",4 Experimental Results,[0],[0]
Two value-based methods are shown for comparison with the policy-based models described.,4.1 Model Comparison,[0],[0]
"For both of these, the policy is implicitly determined by the action-value (Q) function which estimates the expected total return when choosing action a given belief state b at time-step t. For an optimal policy π∗, the Q-function satisfies the Bellman
equation (Bellman, 1954):
Q∗(bt, at) =",4.1 Model Comparison,[0],[0]
"Eπ∗{rt + γmaxa′ Q∗(bt+1, a′)|bt, at}.",4.1 Model Comparison,[0],[0]
(9),4.1 Model Comparison,[0],[0]
DQN is a variant of the Q-learning algorithm whereby a neural network is used to non-linearly approximate the Q-function.,4.1.1 Deep Q-Network (DQN),[0],[0]
"This suggests a sequential approximation in Equation 9 by minimising the loss:
L(wt)",4.1.1 Deep Q-Network (DQN),[0],[0]
=,4.1.1 Deep Q-Network (DQN),[0],[0]
E,4.1.1 Deep Q-Network (DQN),[0],[0]
"[ (yt −Q(bt, at;wt))2 ] , (10)
where yt = rt + γmaxa′ Q(bt+1, a′;w−t ) is the target to update the parameters w. Note that yt is evaluated by a target network w− which is updated less frequently than the network w to stabilise learning, and the expectation is over the tuples (bt, at, rt+1,bt+1) sampled from the experience replay pool described in §3.1.2.
",4.1.1 Deep Q-Network (DQN),[0],[0]
DQN often suffers from over-estimation on Qvalues as the max operator is used to select an action as well as to evaluate it.,4.1.1 Deep Q-Network (DQN),[0],[0]
"Double DQN (DDQN) (Van Hasselt et al., 2016) is thus used to de-couple the action selection and Q-value estimation to achieve better performance.",4.1.1 Deep Q-Network (DQN),[0],[0]
GPRL is a state-of-the-art value-based RL algorithm for dialogue modelling.,4.1.2 Gaussian Processes (GP) RL,[0],[0]
It is appealing since it can learn from a small number of observations by exploiting the correlations defined by a kernel function and provides an uncertainty measure of its estimates.,4.1.2 Gaussian Processes (GP) RL,[0],[0]
"In GPRL, the Q-function is modelled as a GP with zero mean and kernel:",4.1.2 Gaussian Processes (GP) RL,[0],[0]
"Q(B,A) ∼ GP(0, (k(b, a), k(b, a)).",4.1.2 Gaussian Processes (GP) RL,[0],[0]
"This Qfunction is then updated by calculating the posterior given the collected belief-action pairs (b, a) (dictionary points) and their corresponding rewards (Gašić and Young, 2014).",4.1.2 Gaussian Processes (GP) RL,[0],[0]
The implicit knowledge of the distance between data points in observation space provided by the kernel greatly speeds up learning since it enables Q-values in as yet unexplored space to be estimated.,4.1.2 Gaussian Processes (GP) RL,[0],[0]
Note that GPRL was used by Fatemi et al. (2016) to compare with deep RL but no uncertainty estimate was used to guide exploration and as a result had relatively poor performance.,4.1.2 Gaussian Processes (GP) RL,[0],[0]
Here GPRL with uncertainty estimate is used as the benchmark.,4.1.2 Gaussian Processes (GP) RL,[0],[0]
"The proposed models were first evaluated under 0% semantic error rate with an agenda-based simulator which generates user interactions at the
semantic-level (Schatzmann et al., 2006).",4.2 Reinforcement Learning from Scratch,[0],[0]
"In this case, the user intent is perfectly captured in the dialogue belief state without noise.
",4.2 Reinforcement Learning from Scratch,[0],[0]
"The total return of each dialogue was set to 1(D)− 0.05× T , where T is the dialogue length and 1(D) is the success indicator for dialogue",4.2 Reinforcement Learning from Scratch,[0],[0]
D. The maximum dialogue length was set to 20 turns and γ was 0.99.,4.2 Reinforcement Learning from Scratch,[0],[0]
"All deep RL models (A2C, TRACER, eNACER and DQN) contained two hidden layers of size 130 and 50.",4.2 Reinforcement Learning from Scratch,[0],[0]
"The Adam optimiser was used (Kingma and Ba, 2014) with an initial learning rate of 0.001.",4.2 Reinforcement Learning from Scratch,[0],[0]
"During training, an -greedy policy was used, which was initially set to 0.3 and annealed to 0.0 over 3500 training dialogues.",4.2 Reinforcement Learning from Scratch,[0],[0]
"For GP, a linear kernel was used.
",4.2 Reinforcement Learning from Scratch,[0],[0]
"The ER pool P size was 1000, and the minibatch size was 64.",4.2 Reinforcement Learning from Scratch,[0],[0]
"Once an initial 192 samples had been collected, the model was updated after every 2 dialogues.",4.2 Reinforcement Learning from Scratch,[0],[0]
"Note that for DQN, each sample was a state transition (bt, at, rt,bt+1), whereas in A2C, TRACER and eNACER, each sample comprised the whole dialogue with all its state transitions.",4.2 Reinforcement Learning from Scratch,[0],[0]
"For eNACER, the natural gradient was computed to update the model weights of size ∼ 42000.",4.2 Reinforcement Learning from Scratch,[0],[0]
"For TRACER, αwas set to 0.02, and ξ was 0.01.",4.2 Reinforcement Learning from Scratch,[0],[0]
"Since the IS ratio has a high variance and can occasionally be extremely large, it was clipped between [0.8,1.0] to maintain stable training.
",4.2 Reinforcement Learning from Scratch,[0],[0]
"Figure 2 shows the success rate learning curves of on-policy A2C, A2C with ER, TRACER, DQN with ER, GP and eNACER.",4.2 Reinforcement Learning from Scratch,[0],[0]
All were tested with 600 dialogues after every 200 training dialogues.,4.2 Reinforcement Learning from Scratch,[0],[0]
"As reported in previous studies, the benchmark
GP model learns quickly and is relatively stable.",4.2 Reinforcement Learning from Scratch,[0],[0]
eNACER provides comparable performance.,4.2 Reinforcement Learning from Scratch,[0],[0]
DQN also showed high sample-efficiency but with high instability at some points.,4.2 Reinforcement Learning from Scratch,[0],[0]
This is because an iterative improvement in value space does not guarantee an improvement in policy space.,4.2 Reinforcement Learning from Scratch,[0],[0]
"Although comparably slower to learn, the difference between on-policy A2C and A2C with ER clearly demonstrates the sample-efficiency of reusing past samples in mini-batches.",4.2 Reinforcement Learning from Scratch,[0],[0]
The enhancements incorporated into the TRACER algorithm do make this form of learning competitive although it still lags behind eNACER and GPRL.,4.2 Reinforcement Learning from Scratch,[0],[0]
"Regardless of the choice of model and learning algorithm, training a policy from scratch on-line will always result in a poor user experience until sufficient interactions have been experienced to allow acceptable behaviours to be learned.
",4.2.1 Learning from Demonstration Data,[0],[0]
"As discussed in §3.2, an off-line corpus of demonstration data can potentially mitigate this problem.",4.2.1 Learning from Demonstration Data,[0],[0]
"To test this, a corpus of 720 real user spoken dialogues in the Cambridge restaurant domain was utilised.",4.2.1 Learning from Demonstration Data,[0],[0]
"The corpus was split in a 4:1:1 ratio for training, validation and testing.",4.2.1 Learning from Demonstration Data,[0],[0]
"It contains interactions between real users recruited via the Amazon Mechanical Turk service and a wellbehaved SDS as described in Su et al. (2016b).
",4.2.1 Learning from Demonstration Data,[0],[0]
"For A2C with ER and TRACER, the three ways of exploiting demonstration data in §3.2 were explored.",4.2.1 Learning from Demonstration Data,[0],[0]
The exploration parameter was also set to 0.3 and annealed to 0.0 over 2000 training dialogues.,4.2.1 Learning from Demonstration Data,[0],[0]
"Since TRACER has similar patterns to A2C with ER, we first explored the impact of demonstration data on the A2C with ER results since it provides more headroom for identifying performance gains.
",4.2.1 Learning from Demonstration Data,[0],[0]
Figure 3a shows the different combinations of demonstration data using A2C with ER in noisefree conditions.,4.2.1 Learning from Demonstration Data,[0],[0]
The supervised pre-trained model (SL model) provides reasonable starting performance.,4.2.1 Learning from Demonstration Data,[0],[0]
The A2C ER model with supervised pretraining (A2C ER+SL model) improves on this after only 400 dialogues whilst suffering initially.,4.2.1 Learning from Demonstration Data,[0],[0]
We hypothesise that the optimised SL pre-trained parameters distributed very differently to the optimal A2C ER parameters.,4.2.1 Learning from Demonstration Data,[0],[0]
"Also, the A2C ER model with SL replay (A2C ER+SL replay) shows clearly how the use of a supervised replay buffer can accelerate learning from scratch.",4.2.1 Learning from Demonstration Data,[0],[0]
"Moreover, when SL pre-training is combined with SL replay
(A2C ER+SL model+replay), it achieved the best result.",4.2.1 Learning from Demonstration Data,[0],[0]
Note that λ1 and λ2 in Equation 8 were 10 and 0.01 respectively.,4.2.1 Learning from Demonstration Data,[0],[0]
"In each policy update, 64 demonstration data were randomly sampled from the supervised replay poolPsup, which is the same number of RL samples selected from ER for A2C learning.",4.2.1 Learning from Demonstration Data,[0],[0]
Similar patterns emerge when utilising demonstration data to improve early learning in the TRACER and eNACER algorithms as shown in Figure 3b.,4.2.1 Learning from Demonstration Data,[0],[0]
"However, in this case, eNACER is less able to exploit demonstration data since the training method is different from standard actorcritics.",4.2.1 Learning from Demonstration Data,[0],[0]
"Hence, the supervised loss L cannot be directly incorporated into the RL objective J as in Equation 8.",4.2.1 Learning from Demonstration Data,[0],[0]
One could optimise the model using L separately after every RL update.,4.2.1 Learning from Demonstration Data,[0],[0]
"However, in our experiments, this did not yield improvement.",4.2.1 Learning from Demonstration Data,[0],[0]
"Hence, only eNACER learning from a pre-trained SL model is reported here.",4.2.1 Learning from Demonstration Data,[0],[0]
"Compared to eNACER learning from scratch, eNACER from SL model started with good performance but learned more slowly.",4.2.1 Learning from Demonstration Data,[0],[0]
"Again, this may be because the optimised SL pre-trained parameters distributed very differently from the optimal eNACER parameters and led to sub-optimality.",4.2.1 Learning from Demonstration Data,[0],[0]
"Overall, these results suggest that the proposed SL+RL framework to exploit demonstration data is effective in mitigating the cold start problem and TRACER provides the best solution in terms of avoiding poor initial performance, rapid learning and competitive fully trained performance.
",4.2.1 Learning from Demonstration Data,[0],[0]
"In addition to the noise-free performance, we also investigated the impact of noise on the TRACER algorithm.",4.2.1 Learning from Demonstration Data,[0],[0]
"Figure 4 shows the results after training on 2000 dialogues via interaction with
the user simulator under different semantic error rates.",4.2.1 Learning from Demonstration Data,[0],[0]
The random policy (white bars) uniformly sampled an action from the set of size 14.,4.2.1 Learning from Demonstration Data,[0],[0]
This can be regarded as the average initial performance of any learning system.,4.2.1 Learning from Demonstration Data,[0],[0]
We can see that SL generates a robust model which can be further finetuned using RL over a wide range of error rates.,4.2.1 Learning from Demonstration Data,[0],[0]
"It should be noted, however, that the drop-off in performance at high noise levels is more rapid than might be expected, comparing to the GPRL.",4.2.1 Learning from Demonstration Data,[0],[0]
We believe that deep architectures are prone to overfitting and in consequence do not handle well the uncertainty of the user behaviour.,4.2.1 Learning from Demonstration Data,[0],[0]
We plan to investigate this issue in future work.,4.2.1 Learning from Demonstration Data,[0],[0]
"Overall, these outcomes validate the benefit of the proposed twophased approach where the system can be effectively pre-trained using corpus data and further be refined via user interactions.",4.2.1 Learning from Demonstration Data,[0],[0]
This paper has presented two compatible approaches to tackling the problem of slow learning and poor initial performance in deep reinforcement learning algorithms.,5 Conclusion,[0],[0]
"Firstly, trust region actor-critic with experience replay (TRACER) and episodic natural actor-critic with experience replay (eNACER) were presented, these have been shown to be more sample-efficient than other deep RL models and broadly competitive with GPRL.",5 Conclusion,[0],[0]
"Secondly, it has been shown that demonstration data can be utilised to mitigate poor performance in the early stages of learning.",5 Conclusion,[0],[0]
"To this end, two methods for using off-line corpus data were presented: simple pre-training using SL, and using the corpus data in a replay buffer.",5 Conclusion,[0],[0]
"These were particularly effective when used with TRACER which provided the best overall performance.
",5 Conclusion,[0],[0]
"Experimental results were also presented for mismatched environments, again TRACER demonstrated the ability to avoid poor initial performance when trained only on the demonstration corpus, yet still improve substantially with subsequent reinforcement learning.",5 Conclusion,[0],[0]
"It was noted, however, that performance still falls off rather rapidly in noise compared to GPRL as the uncertainty estimates are not handled well by neural networks architectures.
",5 Conclusion,[0],[0]
"Finally, it should be emphasised that whilst this paper has focused on the early stages of learning a new domain where GPRL provides a benchmark and is hard to beat, the potential of deep RL is its readily scalability to exploit on-line learning with large user populations as the model size is not related with experience replay buffer.",5 Conclusion,[0],[0]
"Pei-Hao Su is supported by Cambridge Trust and the Ministry of Education, Taiwan.",Acknowledgments,[0],[0]
"Paweł Budzianowski is supported by EPSRC Council and Toshiba Research Europe Ltd, Cambridge Research Laboratory.",Acknowledgments,[0],[0]
The authors would like to thank the other members of the Cambridge Dialogue Systems Group for their valuable comments.,Acknowledgments,[0],[0]
Deep reinforcement learning (RL) methods have significant potential for dialogue policy optimisation.,abstractText,[0],[0]
"However, they suffer from a poor performance in the early stages of learning.",abstractText,[0],[0]
This is especially problematic for on-line learning with real users.,abstractText,[0],[0]
Two approaches are introduced to tackle this problem.,abstractText,[0],[0]
"Firstly, to speed up the learning process, two sampleefficient neural networks algorithms: trust region actor-critic with experience replay (TRACER) and episodic natural actorcritic with experience replay (eNACER) are presented.",abstractText,[0],[0]
"For TRACER, the trust region helps to control the learning step size and avoid catastrophic model changes.",abstractText,[0],[0]
"For eNACER, the natural gradient identifies the steepest ascent direction in policy space to speed up the convergence.",abstractText,[0],[0]
Both models employ off-policy learning with experience replay to improve sampleefficiency.,abstractText,[0],[0]
"Secondly, to mitigate the cold start issue, a corpus of demonstration data is utilised to pre-train the models prior to on-line reinforcement learning.",abstractText,[0],[0]
"Combining these two approaches, we demonstrate a practical approach to learning deep RLbased dialogue policies and demonstrate their effectiveness in a task-oriented information seeking domain.",abstractText,[0],[0]
Sample-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management,title,[0],[0]
"We are interested in solving a problem of the form
min w∈Rd  P (w) def=",1. Introduction,[0],[0]
"1n ∑ i∈[n] fi(w)  , (1)",1. Introduction,[0],[0]
"where each fi, i ∈",1. Introduction,[0],[0]
"[n] def = {1, . . .",1. Introduction,[0],[0]
", n}, is convex with a Lipschitz continuous gradient.",1. Introduction,[0],[0]
"Throughout the paper, we assume that there exists an optimal solution w∗ of (1).
1Department of Industrial and Systems Engineering, Lehigh University, USA.",1. Introduction,[0],[0]
"2On leave at The University of Oxford, UK.",1. Introduction,[0],[0]
All authors were supported by NSF Grant CCF-1618717.,1. Introduction,[0],[0]
"Katya Scheinberg was partially supported by NSF Grants DMS 13-19356, CCF-1320137 and CCF1618717.",1. Introduction,[0],[0]
"Correspondence to: Lam M. Nguyen <lamnguyen.mltd@gmail.com>, Jie Liu <jie.liu.2018@gmail.com>, Katya Scheinberg <katyas@lehigh.edu>, Martin Takáč <Takac.MT@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Problems of this type arise frequently in supervised learning applications (Hastie et al., 2009).",1. Introduction,[0],[0]
"Given a training set {(xi, yi)}ni=1 with xi ∈ R
d, yi ∈ R, the least squares regression model, for example, is written as (1) with fi(w) def = (xTi w−yi)2+ λ2 ‖w‖ 2, where ‖·‖ denotes the `2-norm.",1. Introduction,[0],[0]
The `2-regularized logistic regression for binary classification is written with fi(w) def = log(1 + exp(−yixTi w)),1. Introduction,[0],[0]
+,1. Introduction,[0],[0]
"λ2 ‖w‖ 2 (yi ∈ {−1, 1}).
",1. Introduction,[0],[0]
"In recent years, many advanced optimization methods have been developed for problem (1).",1. Introduction,[0],[0]
"While the objective function is smooth and convex, the traditional optimization methods, such as gradient descent (GD) or Newton method are often impractical for this problem, when n – the number of training samples and hence the number of fi’s – is very large.",1. Introduction,[0],[0]
"In particular, GD updates iterates as follows
wt+1 = wt − ηt∇P (wt), t = 0, 1, 2, . . .",1. Introduction,[0],[0]
".
",1. Introduction,[0],[0]
"Under strong convexity assumption on P and with appropriate choice of ηt, GD converges at a linear rate in terms of objective function values P (wt).",1. Introduction,[0],[0]
"However, when n is large, computing ∇P (wt) at each iteration can be prohibitive.
",1. Introduction,[0],[0]
"As an alternative, stochastic gradient descent (SGD)1, originating from the seminal work of Robbins and Monro in 1951 (Robbins & Monro, 1951), has become the method of choice for solving (1).",1. Introduction,[0],[0]
"At each step, SGD picks an index i ∈",1. Introduction,[0],[0]
"[n] uniformly at random, and updates the iterate as wt+1 =",1. Introduction,[0],[0]
"wt − ηt∇fi(wt), which is up-to n times cheaper than an iteration of a full gradient method.",1. Introduction,[0],[0]
"The convergence rate of SGD is slower than that of GD, in particular, it is sublinear in the strongly convex case.",1. Introduction,[0],[0]
"The tradeoff, however, is advantageous due to the tremendous per-iteration savings and the fact that low accuracy solutions are sufficient.",1. Introduction,[0],[0]
"This trade-off has been thoroughly analyzed in (Bottou, 1998).",1. Introduction,[0],[0]
"Unfortunately, in practice SGD method is often too slow and its performance is too sensitive to the variance in the sample gradients∇fi(wt).",1. Introduction,[0],[0]
"Use of mini-batches (averaging multiple sample gradients ∇fi(wt)) was used in (Shalev-Shwartz et al., 2007; Cotter et al., 2011; Takáč
1We mark here that even though stochastic gradient is referred to as SG in literature, the term stochastic gradient descent (SGD) has been widely used in many important works of large-scale learning, including SAG/SAGA, SDCA, SVRG and MISO.
",1. Introduction,[0],[0]
"Method Complexity GD O (n/ )
",1. Introduction,[0],[0]
SGD O ( 1/ 2 ),1. Introduction,[0],[0]
"SVRG O (n+ ( √ n/ ))
",1. Introduction,[0],[0]
SAGA O (n+ (n/ )),1. Introduction,[0],[0]
SARAH O ((n+ (1/ )),1. Introduction,[0],[0]
"log(1/ ))
",1. Introduction,[0],[0]
SARAH (one outer loop),1. Introduction,[0],[0]
"O
( n+ (1/ 2) )",1. Introduction,[0],[0]
"et al., 2013) to reduce the variance and improve convergence rate by constant factors.",1. Introduction,[0],[0]
"Using diminishing sequence {ηt} is used to control the variance (Shalev-Shwartz et al., 2011; Bottou et al., 2016), but the practical convergence of SGD is known to be very sensitive to the choice of this sequence, which needs to be hand-picked.
",1. Introduction,[0],[0]
"Recently, a class of more sophisticated algorithms have emerged, which use the specific finite-sum form of (1) and combine some deterministic and stochastic aspects to reduce variance of the steps.",1. Introduction,[0],[0]
"The examples of these methods are SAG/SAGA (Le Roux et al., 2012; Defazio et al., 2014), SDCA (Shalev-Shwartz & Zhang, 2013), SVRG (Johnson & Zhang, 2013; Xiao & Zhang, 2014), DIAG (Mokhtari et al., 2017), MISO (Mairal, 2013) and S2GD (Konečný & Richtárik, 2013), all of which enjoy faster convergence rate than that of SGD and use a fixed learning rate parameter η.",1. Introduction,[0],[0]
"In this paper we introduce a new method in this category, SARAH, which further improves several aspects of the existing methods.",1. Introduction,[0],[0]
In Table 1 we summarize complexity and some other properties of the existing methods and SARAH when applied to strongly convex problems.,1. Introduction,[0],[0]
"Although SVRG and SARAH have the same convergence rate, we introduce a practical variant of SARAH that outperforms SVRG in our experiments.
",1. Introduction,[0],[0]
"In addition, theoretical results for complexity of the methods or their variants when applied to general convex functions have been derived (Schmidt et al., 2016; Defazio et al., 2014; Reddi et al., 2016; Allen-Zhu & Yuan, 2016; Allen-Zhu, 2017).",1. Introduction,[0],[0]
"In Table 2 we summarize the key complexity results, noting that convergence rate is now sublinear.
",1. Introduction,[0],[0]
Our Contributions.,1. Introduction,[0],[0]
"In this paper, we propose a novel algorithm which combines some of the good properties of existing algorithms, such as SAGA and SVRG, while aiming to improve on both of these methods.",1. Introduction,[0],[0]
"In particular, our algorithm does not take steps along a stochastic gradient direction, but rather along an accumulated direction using past stochastic gradient information (as in SAGA) and occasional exact gradient information (as in SVRG).",1. Introduction,[0],[0]
"We summarize the key properties of the proposed algorithm below.
",1. Introduction,[0],[0]
"• Similarly to SVRG, SARAH’s iterations are divided into the outer loop where a full gradient is computed and the inner loop where only stochastic gradient is computed.",1. Introduction,[0],[0]
"Unlike the case of SVRG, the steps of the inner loop of SARAH are based on accumulated stochastic information.",1. Introduction,[0],[0]
"• Like SAG/SAGA and SVRG, SARAH has a sublinear rate of convergence for general convex functions, and a linear rate of convergence for strongly convex functions.",1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
"SARAH uses a constant learning rate, whose size is larger than that of SVRG.",1. Introduction,[0],[0]
We analyze and discuss the optimal choice of the learning rate and the number of inner loop steps.,1. Introduction,[0],[0]
"However, unlike SAG/SAGA but similar to SVRG, SARAH does not require a storage of n past stochastic gradients.",1. Introduction,[0],[0]
"• We also prove a linear convergence rate (in the strongly convex case) for the inner loop of SARAH, the property that SVRG does not possess.",1. Introduction,[0],[0]
"We show that the variance of the steps inside the inner loop goes to zero, thus SARAH is theoretically more stable and reliable than SVRG.",1. Introduction,[0],[0]
"• We provide a practical variant of SARAH based on the convergence properties of the inner loop, where the simple stable stopping criterion for the inner loop is used (see Section 4 for more details).",1. Introduction,[0],[0]
This variant shows how SARAH can be made more stable than SVRG in practice.,1. Introduction,[0],[0]
"Now we are ready to present our SARAH (Algorithm 1).
",2. Stochastic Recursive Gradient Algorithm,[0],[0]
"The key step of the algorithm is a recursive update of the stochastic gradient estimate (SARAH update)
vt = ∇fit(wt)−∇fit(wt−1) +",2. Stochastic Recursive Gradient Algorithm,[0],[0]
"vt−1, (2)
followed by the iterate update:
wt+1 =",2. Stochastic Recursive Gradient Algorithm,[0],[0]
wt − ηvt.,2. Stochastic Recursive Gradient Algorithm,[0],[0]
"(3)
For comparison, SVRG update can be written in a similar way as
vt = ∇fit(wt)−∇fit(w0) + v0.",2. Stochastic Recursive Gradient Algorithm,[0],[0]
"(4)
Algorithm 1 SARAH Parameters: the learning rate η > 0 and the inner loop size m. Initialize: w̃0 Iterate: for s = 1, 2, . .",2. Stochastic Recursive Gradient Algorithm,[0],[0]
.,2. Stochastic Recursive Gradient Algorithm,[0],[0]
do w0 = w̃s−1 v0 = 1 n,2. Stochastic Recursive Gradient Algorithm,[0],[0]
"∑n i=1∇fi(w0)
",2. Stochastic Recursive Gradient Algorithm,[0],[0]
w1 = w0,2. Stochastic Recursive Gradient Algorithm,[0],[0]
"− ηv0 Iterate: for t = 1, . . .",2. Stochastic Recursive Gradient Algorithm,[0],[0]
",m− 1 do
Sample it uniformly at random from [n] vt = ∇fit(wt)−∇fit(wt−1) +",2. Stochastic Recursive Gradient Algorithm,[0],[0]
vt−1 wt+1 =,2. Stochastic Recursive Gradient Algorithm,[0],[0]
wt,2. Stochastic Recursive Gradient Algorithm,[0],[0]
"− ηvt
end for Set w̃s = wt with t chosen uniformly at random from {0, 1, . . .",2. Stochastic Recursive Gradient Algorithm,[0],[0]
",m}
end for
Observe that in SVRG, vt is an unbiased estimator of the gradient, while it is not true for SARAH.",2. Stochastic Recursive Gradient Algorithm,[0],[0]
"Specifically, 2
E[vt|Ft] = ∇P (wt)−∇P (wt−1)+vt−1 6= ∇P (wt), (5)
where 3 Ft = σ(w0, i1, i2, . . .",2. Stochastic Recursive Gradient Algorithm,[0],[0]
", it−1) is the σ-algebra generated by w0, i1, i2, . . .",2. Stochastic Recursive Gradient Algorithm,[0],[0]
", it−1; F0 = F1 = σ(w0).",2. Stochastic Recursive Gradient Algorithm,[0],[0]
"Hence, SARAH is different from SGD and SVRG type of methods, however, the following total expectation holds, E[vt] = E[∇P (wt)], differentiating SARAH from SAG/SAGA.
",2. Stochastic Recursive Gradient Algorithm,[0],[0]
SARAH is similar to SVRG since they both contain outer loops which require one full gradient evaluation per outer iteration followed by one full gradient descent step with a given learning rate.,2. Stochastic Recursive Gradient Algorithm,[0],[0]
"The difference lies in the inner loop, where SARAH updates the stochastic step direction vt recursively by adding and subtracting component gradients to and from the previous vt−1 (t ≥ 1) in (2).",2. Stochastic Recursive Gradient Algorithm,[0],[0]
Each inner iteration evaluates 2 stochastic gradients and hence the total work per outer iteration isO(n+m) in terms of the number of gradient evaluations.,2. Stochastic Recursive Gradient Algorithm,[0],[0]
"Note that due to its nature, without running the inner loop, i.e., m = 1, SARAH reduces to the GD algorithm.",2. Stochastic Recursive Gradient Algorithm,[0],[0]
"To proceed with the analysis of the proposed algorithm, we will make the following common assumptions.
",3. Theoretical Analysis,[0],[0]
Assumption 1 (L-smooth).,3. Theoretical Analysis,[0],[0]
"Each fi : Rd → R, i ∈",3. Theoretical Analysis,[0],[0]
"[n], is L-smooth, i.e., there exists a constant L > 0",3. Theoretical Analysis,[0],[0]
"such that
‖∇fi(w)−∇fi(w′)‖ ≤ L‖w",3. Theoretical Analysis,[0],[0]
"− w′‖, ∀w,w′ ∈",3. Theoretical Analysis,[0],[0]
Rd.,3. Theoretical Analysis,[0],[0]
2 E[·|Ft] = Eit,3. Theoretical Analysis,[0],[0]
"[·], which is expectation with respect to the random choice of index it (conditioned on w0, i1, i2, . . .",3. Theoretical Analysis,[0],[0]
", it−1).",3. Theoretical Analysis,[0],[0]
"3Ft also contains all the information of w0, . . .",3. Theoretical Analysis,[0],[0]
", wt as well as v0, . . .",3. Theoretical Analysis,[0],[0]
", vt−1.
Note that this assumption implies that P (w) = 1 n",3. Theoretical Analysis,[0],[0]
∑n i=1 fi(w) is also L-smooth.,3. Theoretical Analysis,[0],[0]
"The following strong convexity assumption will be made for the appropriate parts of the analysis, otherwise, it would be dropped.
",3. Theoretical Analysis,[0],[0]
Assumption 2a (µ-strongly convex).,3. Theoretical Analysis,[0],[0]
"The function P : Rd → R, is µ-strongly convex, i.e., there exists a constant µ > 0",3. Theoretical Analysis,[0],[0]
"such that ∀w,w′ ∈ Rd,
P (w) ≥ P (w′) +∇P (w′)T (w − w′) + µ2 ‖w − w ′‖2.
Another, stronger, assumption of µ-strong convexity for (1) will also be imposed when required in our analysis.",3. Theoretical Analysis,[0],[0]
"Note that Assumption 2b implies Assumption 2a but not vice versa.
",3. Theoretical Analysis,[0],[0]
Assumption 2b.,3. Theoretical Analysis,[0],[0]
"Each function fi : Rd → R, i ∈",3. Theoretical Analysis,[0],[0]
"[n], is strongly convex with µ > 0.
",3. Theoretical Analysis,[0],[0]
"Under Assumption 2a, let us define the (unique) optimal solution of (1) as w∗, Then strong convexity of P implies that
2µ[P (w)− P (w∗)] ≤",3. Theoretical Analysis,[0],[0]
"‖∇P (w)‖2, ∀w ∈ Rd. (6)
We note here, for future use, that for strongly convex functions of the form (1), arising in machine learning applications, the condition number is defined as κ def=",3. Theoretical Analysis,[0],[0]
L/µ.,3. Theoretical Analysis,[0],[0]
"Furthermore, we should also notice that Assumptions 2a and 2b both cover a wide range of problems, e.g. l2-regularized empirical risk minimization problems with convex losses.
",3. Theoretical Analysis,[0],[0]
"Finally, as a special case of the strong convexity of all fi’s with µ = 0, we state the general convexity assumption, which we will use for convergence analysis.
",3. Theoretical Analysis,[0],[0]
Assumption 3.,3. Theoretical Analysis,[0],[0]
"Each function fi : Rd → R, i ∈",3. Theoretical Analysis,[0],[0]
"[n], is convex, i.e.,
fi(w) ≥ fi(w′)",3. Theoretical Analysis,[0],[0]
"+∇fi(w′)T (w − w′), ∀i ∈",3. Theoretical Analysis,[0],[0]
"[n].
Again, we note that Assumption 2b implies Assumption 3, but Assumption 2a does not.",3. Theoretical Analysis,[0],[0]
"Hence in our analysis, depending on the result we aim at, we will require Assumption 3 to hold by itself, or Assumption 2a and Assumption 3 to hold together, or Assumption 2b to hold by itself.",3. Theoretical Analysis,[0],[0]
"We will always use Assumption 1.
",3. Theoretical Analysis,[0],[0]
Our iteration complexity analysis aims to bound the number of outer iterations T (or total number of stochastic gradient evaluations) which is needed to guarantee that ‖∇P (wT )‖2 ≤ .,3. Theoretical Analysis,[0],[0]
In this case we will say that wT is an -accurate solution.,3. Theoretical Analysis,[0],[0]
"However, as is common practice for stochastic gradient algorithms, we aim to obtain the bound on the number of iterations, which is required to guarantee the bound on the expected squared norm of a gradient, i.e.,
E[‖∇P (wT )‖2] ≤ .",3. Theoretical Analysis,[0],[0]
(7),3. Theoretical Analysis,[0],[0]
The most important property of the SVRG algorithm is the variance reduction of the steps.,3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"This property holds as the number of outer iteration grows, but it does not hold, if only the number of inner iterations increases.",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"In other words, if we simply run the inner loop for many iterations (without executing additional outer loops), the variance of the steps does not reduce in the case of SVRG, while it goes to zero in the case of SARAH.",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"To illustrate this effect, let us take a look at Figures 1 and 2.
",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"In Figure 1, we applied one outer loop of SVRG and SARAH to a sum of 5 quadratic functions in a twodimensional space, where the optimal solution is at the origin, the black lines and black dots indicate the trajectory of each algorithm and the red point indicates the final iterate.",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"Initially, both SVRG and SARAH take steps along stochastic gradient directions towards the optimal solution.",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"However, later iterations of SVRG wander randomly around the origin with large deviation from it, while SARAH follows a much more stable convergent trajectory, with a final iterate falling in a small neighborhood of the optimal solution.
",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"In Figure 2, the x-axis denotes the number of effective passes which is equivalent to the number of passes through all of the data in the dataset, the cost of each pass being equal to the cost of one full gradient evaluation; and y-axis represents ‖vt‖2.",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"Figure 2 shows the evolution of ‖vt‖2
for SARAH, SVRG, SGD+ (SGD with decreasing learning rate) and FISTA (an accelerated version of GD (Beck & Teboulle, 2009))",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"withm = 4n, where the left plot shows the trend over multiple outer iterations and the right plot shows a single outer iteration4.",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"We can see that for SVRG, ‖vt‖2 decreases over the outer iterations, while it has an increasing trend or oscillating trend for each inner loop.",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"In contrast, SARAH enjoys decreasing trends both in the outer and the inner loop iterations.
",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
We will now show that the stochastic steps computed by SARAH converge linearly in the inner loop.,3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
We present two linear convergence results based on our two different assumptions of µ-strong convexity.,3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
These results substantiate our conclusion that SARAH uses more stable stochastic gradient estimates than SVRG.,3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"The following theorem is our first result to demonstrate the linear convergence of our stochastic recursive step vt.
Theorem 1a.",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"Suppose that Assumptions 1, 2a and 3 hold.",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"Consider vt defined by (2) in SARAH (Algorithm 1) with η < 2/L. Then, for any t ≥ 1,
E[‖vt‖2] ≤",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
[ 1− ( 2 ηL − 1 ) µ2η2 ],3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"E[‖vt−1‖2]
≤",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
[ 1− ( 2 ηL − 1 ) µ2η2,3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"]t E[‖∇P (w0)‖2].
",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"This result implies that by choosing η = O(1/L), we obtain the linear convergence of ‖vt‖2 in expectation with the rate (1− 1/κ2).",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"Below we show that a better convergence rate can be obtained under a stronger convexity assumption.
",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
Theorem 1b.,3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
Suppose that Assumptions 1 and 2b hold.,3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
Consider vt defined by (2) in SARAH (Algorithm 1) with η ≤ 2/(µ+ L).,3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"Then the following bound holds, ∀ t ≥ 1,
E[‖vt‖2] ≤ ( 1− 2µLηµ+L )",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"E[‖vt−1‖2]
≤ ( 1− 2µLηµ+L )t E[‖∇P (w0)‖2].
",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"Again, by setting η = O(1/L), we derive the linear convergence with the rate of (1 − 1/κ), which is a significant improvement over the result of Theorem 1a, when the problem is severely ill-conditioned.",3.1. Linearly Diminishing Step-Size in a Single Inner Loop,[0],[0]
"In this section, we derive the general convergence rate results for Algorithm 1.",3.2. Convergence Analysis,[0],[0]
"First, we present two important Lemmas as the foundation of our theory.",3.2. Convergence Analysis,[0],[0]
"Then, we proceed to prove sublinear convergence rate of a single outer iteration when applied to general convex functions.",3.2. Convergence Analysis,[0],[0]
"In the end, we
4In the plots of Figure 2, since the data for SVRG is noisy, we smooth it by using moving average filters with spans 100 for the left plot and 10 for the right one.
",3.2. Convergence Analysis,[0],[0]
"prove that the algorithm with multiple outer iterations has linear convergence rate in the strongly convex case.
",3.2. Convergence Analysis,[0],[0]
We begin with proving two useful lemmas that do not require any convexity assumption.,3.2. Convergence Analysis,[0],[0]
The first Lemma 1 bounds the sum of expected values of ‖∇P (wt)‖2.,3.2. Convergence Analysis,[0],[0]
"The second, Lemma 2, bounds E[‖∇P (wt)− vt‖2].",3.2. Convergence Analysis,[0],[0]
Lemma 1.,3.2. Convergence Analysis,[0],[0]
Suppose that Assumption 1 holds.,3.2. Convergence Analysis,[0],[0]
Consider SARAH (Algorithm 1).,3.2. Convergence Analysis,[0],[0]
"Then, we have m∑ t=0 E[‖∇P (wt)‖2] ≤ 2 η E[P (w0)− P (w∗)]",3.2. Convergence Analysis,[0],[0]
"(8)
+ m∑ t=0 E[‖∇P (wt)− vt‖2]− (1− Lη) m∑ t=0 E[‖vt‖2].
",3.2. Convergence Analysis,[0],[0]
Lemma 2.,3.2. Convergence Analysis,[0],[0]
Suppose that Assumption 1 holds.,3.2. Convergence Analysis,[0],[0]
Consider vt defined by (2) in SARAH (Algorithm 1).,3.2. Convergence Analysis,[0],[0]
"Then for any t ≥ 1,
E[‖∇P (wt)− vt‖2] = t∑
j=1
E[‖vj − vj−1‖2]
− t∑
j=1
E[‖∇P (wj)−∇P (wj−1)‖2].
",3.2. Convergence Analysis,[0],[0]
Now we are ready to provide our main theoretical results.,3.2. Convergence Analysis,[0],[0]
"Following from Lemma 2, we can obtain the following upper bound for E[‖∇P (wt) − vt‖2] for convex functions fi, i ∈",3.2.1. GENERAL CONVEX CASE,[0],[0]
[n].,3.2.1. GENERAL CONVEX CASE,[0],[0]
Lemma 3.,3.2.1. GENERAL CONVEX CASE,[0],[0]
Suppose that Assumptions 1 and 3 hold.,3.2.1. GENERAL CONVEX CASE,[0],[0]
Consider vt defined as (2) in SARAH (Algorithm 1) with η < 2/L.,3.2.1. GENERAL CONVEX CASE,[0],[0]
"Then we have that for any t ≥ 1,
E[‖∇P (wt)− vt‖2] ≤ ηL
2− ηL
[ E[‖v0‖2]− E[‖vt‖2] ] ≤ ηL
2− ηL E[‖v0‖2].",3.2.1. GENERAL CONVEX CASE,[0],[0]
"(9)
Using the above lemmas, we can state and prove one of our core theorems as follows.",3.2.1. GENERAL CONVEX CASE,[0],[0]
Theorem 2.,3.2.1. GENERAL CONVEX CASE,[0],[0]
Suppose that Assumptions 1 and 3 hold.,3.2.1. GENERAL CONVEX CASE,[0],[0]
"Consider SARAH (Algorithm 1) with η ≤ 1/L. Then for any s ≥ 1, we have
E[‖∇P (w̃s)‖2] ≤ 2
η(m+ 1) E[P (w̃s−1)− P (w∗)]
+ ηL
2− ηL E[‖∇P (w̃s−1)‖2].",3.2.1. GENERAL CONVEX CASE,[0],[0]
"(10)
Proof.",3.2.1. GENERAL CONVEX CASE,[0],[0]
"Since v0 = ∇P (w0) implies ‖∇P (w0)−v0‖2 = 0 then by Lemma 3, we can write∑m
t=0E[‖∇P (wt)− vt‖2] ≤ mηL 2−ηLE[‖v0‖ 2].",3.2.1. GENERAL CONVEX CASE,[0],[0]
"(11)
Hence, by Lemma 1 with η ≤ 1/L, we have∑m t=0E[‖∇P (wt)‖2] ≤ 2ηE[P (w0)− P (w ∗)]",3.2.1. GENERAL CONVEX CASE,[0],[0]
"+ ∑m t=0E[‖∇P (wt)− vt‖2]
(11) ≤ 2ηE[P",3.2.1. GENERAL CONVEX CASE,[0],[0]
(w0)− P (w ∗)],3.2.1. GENERAL CONVEX CASE,[0],[0]
+ mηL2−ηLE[‖v0‖ 2].,3.2.1. GENERAL CONVEX CASE,[0],[0]
"(12)
Since we are considering one outer iteration, with s ≥ 1, then we have v0 = ∇P (w0) = ∇P (w̃s−1) (since w0 = w̃s−1), and w̃s = wt, where t is picked uniformly at random from {0, 1, . . .",3.2.1. GENERAL CONVEX CASE,[0],[0]
",m}.",3.2.1. GENERAL CONVEX CASE,[0],[0]
"Therefore, the following holds,
E[‖∇P (w̃s)‖2] = 1m+1 ∑m t=0E[‖∇P (wt)‖2]
(12) ≤ 2η(m+1)E[P",3.2.1. GENERAL CONVEX CASE,[0],[0]
"(w̃s−1)− P (w ∗)]
+ ηL2−ηLE[‖∇P (w̃s−1)‖ 2].
",3.2.1. GENERAL CONVEX CASE,[0],[0]
"Theorem 2, in the case when η ≤ 1/L implies that
E[‖∇P (w̃s)‖2] ≤ 2η(m+1)E[P (w̃s−1)− P (w ∗)]
+ ηLE[‖∇P",3.2.1. GENERAL CONVEX CASE,[0],[0]
(w̃s−1)‖2].,3.2.1. GENERAL CONVEX CASE,[0],[0]
"By choosing the learning rate η = √
2 L(m+1) (with m such that √
2 L(m+1) ≤ 1/L) we can derive the following con-
vergence result,
E[‖∇P (w̃s)‖2] ≤ √
2L m+1E[P (w̃s−1)− P (w ∗) + ‖∇P (w̃s−1)‖2].
",3.2.1. GENERAL CONVEX CASE,[0],[0]
"Clearly, this result shows a sublinear convergence rate for SARAH under general convexity assumption within a single inner loop, with increasing m, and consequently, we have the following result for complexity bound.",3.2.1. GENERAL CONVEX CASE,[0],[0]
Corollary 1.,3.2.1. GENERAL CONVEX CASE,[0],[0]
Suppose that Assumptions 1 and 3 hold.,3.2.1. GENERAL CONVEX CASE,[0],[0]
"Consider SARAH (Algorithm 1) within a single outer iteration with the learning rate η = √ 2
L(m+1) wherem ≥ 2L−1 is the total number of iterations, then ‖∇P (wt)‖2 converges sublinearly in expectation with a rate of √ 2L m+1 , and therefore, the total complexity to achieve an -accurate solution defined in (7) is O(n+ 1/ 2).
",3.2.1. GENERAL CONVEX CASE,[0],[0]
We now turn to estimating convergence of SARAH with multiple outer steps.,3.2.1. GENERAL CONVEX CASE,[0],[0]
Simply using Theorem 2 for each of the outer steps we have the following result.,3.2.1. GENERAL CONVEX CASE,[0],[0]
Theorem 3.,3.2.1. GENERAL CONVEX CASE,[0],[0]
Suppose that Assumptions 1 and 3 hold.,3.2.1. GENERAL CONVEX CASE,[0],[0]
"Consider SARAH (Algorithm 1) and define
δk = 2 η(m+1)E[P (w̃k)− P (w ∗)], k = 0, 1, . . .",3.2.1. GENERAL CONVEX CASE,[0],[0]
", s− 1,
and δ = max0≤k≤s−1 δk.",3.2.1. GENERAL CONVEX CASE,[0],[0]
"Then we have
E[‖∇P (w̃s)‖2]−∆ ≤ αs(‖∇P",3.2.1. GENERAL CONVEX CASE,[0],[0]
"(w̃0)‖2 −∆), (13) where ∆ = δ",3.2.1. GENERAL CONVEX CASE,[0],[0]
"(
1 + ηL2(1−ηL) ) , and α = ηL2−ηL .
",3.2.1. GENERAL CONVEX CASE,[0],[0]
"Based on Theorem 3, we have the following total complexity for SARAH in the general convex case.
",3.2.1. GENERAL CONVEX CASE,[0],[0]
Corollary 2.,3.2.1. GENERAL CONVEX CASE,[0],[0]
"Let us choose ∆ = /4, α = 1/2 (with η = 2/(3L)), and m = O(1/ ) in Theorem 3.",3.2.1. GENERAL CONVEX CASE,[0],[0]
"Then, the total complexity to achieve an -accuracy solution defined in (7) is O((n+ (1/ ))",3.2.1. GENERAL CONVEX CASE,[0],[0]
log(1/ )).,3.2.1. GENERAL CONVEX CASE,[0],[0]
We now turn to the discussion of the linear convergence rate of SARAH under the strong convexity assumption on P .,3.2.2. STRONGLY CONVEX CASE,[0],[0]
"From Theorem 2, for any s ≥ 1, using property (6) of the µ-strongly convex P , we have
E[‖∇P (w̃s)‖2] ≤ 2η(m+1)E[P (w̃s−1)− P (w ∗)]
+ ηL2−ηLE[‖∇P (w̃s−1)‖ 2] (6) ≤ (
1 µη(m+1) + ηL 2−ηL )",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"E[‖∇P (w̃s−1)‖2],
and equivalently,
E[‖∇P (w̃s)‖2] ≤",3.2.2. STRONGLY CONVEX CASE,[0],[0]
σm E[‖∇P (w̃s−1)‖2].,3.2.2. STRONGLY CONVEX CASE,[0],[0]
"(14)
Let us define σm def = 1µη(m+1) + ηL 2−ηL .",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"Then by choosing η and m such that σm < 1, and applying (14) recursively, we are able to reach the following convergence result.
",3.2.2. STRONGLY CONVEX CASE,[0],[0]
Theorem 4.,3.2.2. STRONGLY CONVEX CASE,[0],[0]
"Suppose that Assumptions 1, 2a and 3 hold.",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"Consider SARAH (Algorithm 1) with the choice of η and m such that
σm def =
1
µη(m+ 1) +
ηL
2− ηL < 1.",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"(15)
Then, we have
E[‖∇P (w̃s)‖2] ≤ (σm)s‖∇P (w̃0)‖2.
",3.2.2. STRONGLY CONVEX CASE,[0],[0]
Remark 1.,3.2.2. STRONGLY CONVEX CASE,[0],[0]
Theorem 4 implies that any η < 1/L will work for SARAH.,3.2.2. STRONGLY CONVEX CASE,[0],[0]
Let us compare our convergence rate to that of SVRG.,3.2.2. STRONGLY CONVEX CASE,[0],[0]
"The linear rate of SVRG, as presented in (Johnson & Zhang, 2013), is given by
αm = 1 µη(1−2Lη)m + 2ηL 1−2ηL < 1.
",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"We observe that it implies that the learning rate has to satisfy η < 1/(4L), which is a tighter restriction than
η < 1/L required by SARAH.",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"In addition, with the same values of m and η, the rate or convergence of (the outer iterations) of SARAH is always smaller than that of SVRG.
σm",3.2.2. STRONGLY CONVEX CASE,[0],[0]
= 1 µη(m+1) + ηL,3.2.2. STRONGLY CONVEX CASE,[0],[0]
"2−ηL = 1 µη(m+1) + 1 2/(ηL)−1
< 1µη(1−2Lη)m + 1 0.5/(ηL)−1 = αm.
Remark 2.",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"To further demonstrate the better convergence properties of SARAH, let us consider following optimization problem
min 0<η<1/L σm, min 0<η<1/4L αm,
which can be interpreted as the best convergence rates for different values of m, for both SARAH and SVRG.",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"After simple calculations, we plot both learning rates and the corresponding theoretical rates of convergence, as shown in Figure 3, where the right plot is a zoom-in on a part of the middle plot.",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"The left plot shows that the optimal learning rate for SARAH is significantly larger than that of SVRG, while the other two plots show significant improvement upon outer iteration convergence rates for SARAH over SVRG.
",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"Based on Theorem 4, we are able to derive the following total complexity for SARAH in the strongly convex case.
",3.2.2. STRONGLY CONVEX CASE,[0],[0]
Corollary 3.,3.2.2. STRONGLY CONVEX CASE,[0],[0]
"Fix ∈ (0, 1), and let us run SARAH with η = 1/(2L) and m = 4.5κ for T iterations where T = dlog(‖∇P (w̃0)‖2/ )/ log(9/7)e, then we can derive an -accuracy solution defined in (7).",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"Furthermore, we can obtain the total complexity of SARAH, to achieve the -accuracy solution, as O ((n+ κ) log(1/ )) .",3.2.2. STRONGLY CONVEX CASE,[0],[0]
"While SVRG is an efficient variance-reducing stochastic gradient method, one of its main drawbacks is the sensitivity of the practical performance with respect to the choice of m.",4. A Practical Variant,[0],[0]
"It is know that m should be around O(κ),5 while it still remains unknown that what the exact best choice is.",4. A Practical Variant,[0],[0]
"In this section, we propose a practical variant of SARAH as
5 In practice, when n is large, P (w) is often considered as a regularized Empirical Loss Minimization problem with regularization parameter λ = 1
n , then κ ∼ O(n).
SARAH+ (Algorithm 2), which provides an automatic and adaptive choice of the inner loop sizem.",4. A Practical Variant,[0],[0]
"Guided by the linear convergence of the steps in the inner loop, demonstrated in Figure 2, we introduce a stopping criterion based on the values of ‖vt‖2 while upper-bounding the total number of steps by a large enough m for robustness.",4. A Practical Variant,[0],[0]
"The other modification compared to SARAH (Algorithm 1) is the more practical choice w̃s = wt, where t is the last index of the particular inner loop, instead of randomly selected intermediate index.
",4. A Practical Variant,[0],[0]
"Algorithm 2 SARAH+ Parameters: the learning rate η > 0, 0",4. A Practical Variant,[0],[0]
< γ ≤ 1 and the maximum inner loop size m. Initialize: w̃0,4. A Practical Variant,[0],[0]
"Iterate: for s = 1, 2, . . .",4. A Practical Variant,[0],[0]
do w0 = w̃s−1 v0 = 1 n,4. A Practical Variant,[0],[0]
"∑n i=1∇fi(w0)
",4. A Practical Variant,[0],[0]
"w1 = w0 − ηv0 t = 1 while ‖vt−1‖2 > γ‖v0‖2 and t < m do
Sample it uniformly at random from [n] vt = ∇fit(wt)−∇fit(wt−1) +",4. A Practical Variant,[0],[0]
vt−1 wt+1 =,4. A Practical Variant,[0],[0]
"wt − ηvt t = t+ 1
end while Set w̃s = wt
end for
Different from SARAH, SARAH+ provides a possibility of earlier termination and unnecessary careful choices of m, and it also covers the classical gradient descent when we set γ = 1 (since the while loop does not proceed).",4. A Practical Variant,[0],[0]
In Figure 4 we present the numerical performance of SARAH+ with different γs on rcv1 and news20 datasets.,4. A Practical Variant,[0],[0]
The size of the inner loop provides a trade-off between the fast sublinear convergence in the inner loop and linear convergence in the outer loop.,4. A Practical Variant,[0],[0]
"From the results, it appears that γ = 1/8 is the optimal choice.",4. A Practical Variant,[0],[0]
"With a larger γ, i.e. γ > 1/8, the iterates in the inner loop do not provide sufficient reduction, before another full gradient computation is required, while with γ < 1/8 an unnecessary number of inner steps is performed without gaining substantial progress.",4. A Practical Variant,[0],[0]
"Clearly γ is another parameter that requires tuning, however, in our experiments, the performance of SARAH+ has been very robust with respect to the choices of γ and did not vary much from one data set to another.
",4. A Practical Variant,[0],[0]
"Similarly to SVRG, ‖vt‖2 decreases in the outer iterations of SARAH+.",4. A Practical Variant,[0],[0]
"However, unlike SVRG, SARAH+ also inherits from SARAH the consistent decrease of ‖vt‖2 in expectation in the inner loops.",4. A Practical Variant,[0],[0]
"It is not possible to apply the same idea of adaptively terminating the inner loop of
SVRG based on the reduction in ‖vt‖2, as ‖vt‖2 may have side fluctuations as shown in Figure 2.",4. A Practical Variant,[0],[0]
"To support the theoretical analyses and insights, we present our empirical experiments, comparing SARAH and SARAH+ with the state-of-the-art first-order methods for `2-regularized logistic regression problems with
fi(w) = log(1 + exp(−yixTi w))",5. Numerical Experiments,[0],[0]
+,5. Numerical Experiments,[0],[0]
"λ2 ‖w‖ 2,
on datasets covtype, ijcnn1, news20 and rcv1 6.",5. Numerical Experiments,[0],[0]
"For ijcnn1 and rcv1 we use the predefined testing and training sets, while covtype and news20 do not have test data, hence we randomly split the datasets with 70% for training and 30% for testing.",5. Numerical Experiments,[0],[0]
"Some statistics of the datasets are summarized in Table 3.
",5. Numerical Experiments,[0],[0]
"The penalty parameter λ is set to 1/n as is common practice (Le Roux et al., 2012).",5. Numerical Experiments,[0],[0]
"Note that like SVRG/S2GD and SAG/SAGA, SARAH also allows an efficient sparse implementation named “lazy updates” (Konečný et al., 2016).",5. Numerical Experiments,[0],[0]
"We conduct and compare numerical results of SARAH with SVRG, SAG, SGD+ and FISTA.",5. Numerical Experiments,[0],[0]
"SVRG (Johnson & Zhang, 2013) and SAG (Le Roux et al., 2012) are classic modern stochastic methods.",5. Numerical Experiments,[0],[0]
SGD+ is SGD with decreasing learning rate η = η0/(k + 1) where k is the number of effective passes and η0 is some initial constant learning rate.,5. Numerical Experiments,[0],[0]
"FISTA (Beck & Teboulle, 2009) is the Fast Iterative Shrinkage-Thresholding Algorithm, well-known as an efficient accelerated version of the gradient descent.",5. Numerical Experiments,[0],[0]
"Even though for each method, there is a theoretical safe learning rate, we compare the results for the best learning rates in hindsight.
",5. Numerical Experiments,[0],[0]
"Figure 5 shows numerical results in terms of loss residuals
6All datasets are available at http://www.csie.ntu.",5. Numerical Experiments,[0],[0]
"edu.tw/˜cjlin/libsvmtools/datasets/.
(top) and test errors (bottom) on the four datasets, SARAH is sometimes comparable or a little worse than other methods at the beginning.",5. Numerical Experiments,[0],[0]
"However, it quickly catches up to or surpasses all other methods, demonstrating a faster rate of decrease across all experiments.",5. Numerical Experiments,[0],[0]
"We observe that on covtype and rcv1, SARAH, SVRG and SAG are comparable with some advantage of SARAH on covtype.",5. Numerical Experiments,[0],[0]
"On ijcnn1 and news20, SARAH and SVRG consistently surpass the other methods.
",5. Numerical Experiments,[0],[0]
"In particular, to validate the efficiency of our practical variant SARAH+, we provide an insight into how important the choices of m and η are for SVRG and SARAH in Table 4 and Figure 6.",5. Numerical Experiments,[0],[0]
"Table 4 presents the optimal choices of m and η for each of the algorithm, while Figure 6 shows the behaviors of SVRG and SARAH with different choices of m for covtype and ijcnn1, where m∗s denote the best choices.",5. Numerical Experiments,[0],[0]
"In Table 4, the optimal learning rates of SARAH vary less among different datasets compared to all the other methods and they approximate the theoretical upper bound for SARAH (1/L); on the contrary, for the other methods the empirical optimal rates can exceed their theoretical limits (SVRG with 1/(4L), SAG with 1/(16L), FISTA with 1/L).",5. Numerical Experiments,[0],[0]
This empirical studies suggest that it is much easier to tune and find the ideal learning rate for SARAH.,5. Numerical Experiments,[0],[0]
"As observed in Figure 6, the behaviors of both SARAH and SVRG are quite sensitive to the choices of m. With improper choices of m, the loss residuals can be increased considerably from 10−15 to 10−3 on both covtype in 40 effective passes and ijcnn1 in 17 effective passes for
SARAH/SVRG.",5. Numerical Experiments,[0],[0]
"We propose a new variance reducing stochastic recursive gradient algorithm SARAH, which combines some of the properties of well known existing algorithms, such as SAGA and SVRG.",6. Conclusion,[0],[0]
"For smooth convex functions, we show a sublinear convergence rate, while for strongly convex cases, we prove the linear convergence rate and the computational complexity as those of SVRG and SAG.",6. Conclusion,[0],[0]
"However, compared to SVRG, SARAH’s convergence rate constant is smaller and the algorithms is more stable both theoretically and numerically.",6. Conclusion,[0],[0]
"Additionally, we prove the linear convergence for inner loops of SARAH which support the claim of stability.",6. Conclusion,[0],[0]
"Based on this convergence we derive a practical version of SARAH, with a simple stopping criterion for the inner loops.",6. Conclusion,[0],[0]
The authors would like to thank the reviewers for useful suggestions which helped to improve the exposition in the paper.,Acknowledgements,[0],[0]
"In this paper, we propose a StochAstic Recursive grAdient algoritHm (SARAH), as well as its practical variant SARAH+, as a novel approach to the finite-sum minimization problems.",abstractText,[0],[0]
"Different from the vanilla SGD and other modern stochastic methods such as SVRG, S2GD, SAG and SAGA, SARAH admits a simple recursive framework for updating stochastic gradient estimates; when comparing to SAG/SAGA, SARAH does not require a storage of past gradients.",abstractText,[0],[0]
The linear convergence rate of SARAH is proven under strong convexity assumption.,abstractText,[0],[0]
"We also prove a linear convergence rate (in the strongly convex case) for an inner loop of SARAH, the property that SVRG does not possess.",abstractText,[0],[0]
Numerical experiments demonstrate the efficiency of our algorithm.,abstractText,[0],[0]
SARAH: A Novel Method for Machine Learning Problems  Using Stochastic Recursive Gradient,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1979–1989 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"“When information is cheap, attention becomes expensive.”",1 Introduction,[0],[0]
"— James Gleick
Satirical news is considered to be entertainment.",1 Introduction,[0],[0]
"However, it is not easy to recognize the satire if the satirical cues are too subtle to be unmasked and the reader lacks the contextual or cultural background.",1 Introduction,[0],[0]
"The example illustrated in Table 1 is a piece of satirical news with subtle satirical cues.
",1 Introduction,[0],[0]
"Assuming readers interpret satirical news as true news, there is not much difference between satirical news and fake news in terms of the consequence, which may hurt the credibility of the media and the trust in the society.",1 Introduction,[0],[0]
"In fact, it is reported in the Guardian that people may believe satirical news and spread them to the public re-
gardless of the ridiculous content1.",1 Introduction,[0],[0]
"It is also concluded that fake news is similar to satirical news via a thorough comparison among true news, fake news, and satirical news (Horne and Adali, 2017).",1 Introduction,[0],[0]
"This paper focuses on satirical news detection to ensure the trustworthiness of online news and prevent the spreading of potential misleading information.
",1 Introduction,[0],[0]
"Some works tackling fake news and misleading information favor to discover the truth (Xiao et al., 2016; Wan et al., 2016) through knowledge base (Dong et al., 2015) and truthfulness estimation (Ge et al., 2013).",1 Introduction,[0],[0]
These approaches may not be feasible for satirical news because there is no ground-truth in the stories.,1 Introduction,[0],[0]
"Another track of works analyze social network activities (Zhao et al., 2015) to evaluate the spreading information (Gupta et al., 2012; Castillo et al., 2011).",1 Introduction,[0],[0]
"This could be ineffective for both fake news and satirical news because once they are distributed on the social network, the damage has been done.",1 Introduction,[0],[0]
"Finally, works evaluating culture difference (PérezRosas and Mihalcea, 2014), psycholinguistic features (Ott et al., 2011), and writing styles (Feng et al., 2012) for deception detection are suitable for satirical news detection.",1 Introduction,[0],[0]
"These works consider features at document level, while we observe that satirical cues are usually located in certain para-
1https://www.theguardian.com/media/2016/nov/17/facebookfake-news-satire
1979
graphs rather than the whole document.",1 Introduction,[0],[0]
"This indicates that many document level features may be superfluous and less effective.
",1 Introduction,[0],[0]
"To understand how paragraph-level features and document-level features are varied towards detection decision when only document level labels are available, we propose a 4-level neural network in a character-word-paragraph-document hierarchy and utilize attention mechanism (Bahdanau et al., 2014) to reveal their relative difference.",1 Introduction,[0],[0]
"We apply psycholinguistic features, writing stylistic features, structural features, and readability features to understand satire.",1 Introduction,[0],[0]
"The paragraph-level features are embedded into attention mechanism for selecting highly attended paragraphs, and the document-level features are incorporated for the final classification.",1 Introduction,[0],[0]
"This is the first work that unveils satirical cues between paragraph-level and document-level through neural networks to our knowledge.
",1 Introduction,[0],[0]
"We make the following contributions in our paper:
• We propose a 4-level hierarchical network for satirical news detection.",1 Introduction,[0],[0]
"The model detects satirical news effectively and incorporates attention mechanism to reveal paragraph-level satirical cues.
",1 Introduction,[0],[0]
"• We show that paragraph-level features are more important than document-level features in terms of the psycholinguistic feature, writing stylistic feature, and structural feature, while the readability feature is more important at the document level.
",1 Introduction,[0],[0]
"• We collect satirical news (16,000+) and true news (160,000+) from various sources and conduct extensive experiments on this corpus2.",1 Introduction,[0],[0]
"We categorize related works into four categories: content-based detection for news genre, truth verification and truthfulness evaluation, deception detection, and identification of highly attended component using attention mechanism.
",2 Related Work,[0],[0]
Content-based detection for news genre.,2 Related Work,[0],[0]
"Content-based methods are considerably effective to prevent satirical news from being recognized as true news and spreading through
2Please contact the first author to obtain the data
social media.",2 Related Work,[0],[0]
"Burfoot and Baldwin (2009) introduce headline features, profanity, and slang to embody satirical news.",2 Related Work,[0],[0]
They consider absurdity as the major device in satirical news and model this feature by comparing entity combination in a given document with Google query results.,2 Related Work,[0],[0]
Rubin et al. (2016) also consider absurdity but model it through unexpected new name entities.,2 Related Work,[0],[0]
"They introduce additional features including humor, grammar, negative affect, and punctuation to empower the detection.",2 Related Work,[0],[0]
"Besides satirical news, Chen et al. (2015) aim to detect click-baits, whose content exaggerates fact.",2 Related Work,[0],[0]
Potthast et al. (2017) report a writing style analysis of hyperpartisan news.,2 Related Work,[0],[0]
"Barbieri et al. (2015) focus on multilingual tweets that advertise satirical news.
",2 Related Work,[0],[0]
It is noteworthy that satirical news used for evaluation in above works are of limited quantity (around 200 articles).,2 Related Work,[0],[0]
Diverse examples of satire may not be included as discussed by Rubin et al. (2016).,2 Related Work,[0],[0]
"This issue inspires us to collect more than 16,000 satirical news for our experiment.
",2 Related Work,[0],[0]
Truth discovery and truthfulness evaluation.,2 Related Work,[0],[0]
"Although truth extraction from inconsistent sources (Ge et al., 2013; Wan et al., 2016; Li et al., 2016) and from conflicting sources (Yin et al., 2008; Li et al., 2014b), truth inference through knowledge base (Dong et al., 2015), and discovering evolving truth (Li et al., 2015) could help identify fact and detect fake news, they cannot favor much for satirical news as the story is entirely made up and the ground-truth is hardly found.",2 Related Work,[0],[0]
"Analyzing user activities (Farajtabar et al., 2017) and interactions (Castillo et al., 2011; Mukherjee and Weikum, 2015) to evaluate the credibility may not be appropriate for satirical news as it cannot prevent the spreading.",2 Related Work,[0],[0]
"Therefore, we utilize content-based features, including psycholinguistic features, writing stylistic features, structural features, and readability features, to address satirical news detection.
",2 Related Work,[0],[0]
Deception detection.,2 Related Work,[0],[0]
"We believe satirical news and opinion spam share similar characteristics of writing fictitious and deceptive content, which can be identified via a psycholinguistic consideration (Mihalcea and Strapparava, 2009; Ott et al., 2011).",2 Related Work,[0],[0]
"Beyond that, both syntactic stylometry (Feng et al., 2012) and behavioral features (Mukherjee et al., 2013b) are effective for detecting deceptive reviews, while stylistic features are practical to deal with obfuscating and imitat-
ing writings (Afroz et al., 2012).",2 Related Work,[0],[0]
"However, deceptive content varies among paragraphs in the same document, and so does satire.",2 Related Work,[0],[0]
We focus on devising and evaluating paragraph-level features to reveal the satire in this work.,2 Related Work,[0],[0]
"We compare them with features at the document level, so we are able to tell what features are important at which level.
",2 Related Work,[0],[0]
Identification of highly attended component using attention mechanism.,2 Related Work,[0],[0]
"Attention mechanism is widely applied in machine translation (Bahdanau et al., 2014), language inference (Rocktäschel et al., 2015), and question answering (Chen et al., 2016a).",2 Related Work,[0],[0]
"In addition, Yang et al. (2016b) propose hierarchical attention network to understand both attended words and sentences for sentiment classification.",2 Related Work,[0],[0]
Chen et al. (2016b) enhance the attention with the support of user preference and product information to comprehend how user and product affect sentiment ratings.,2 Related Work,[0],[0]
"Due to the capability of attention mechanism, we employ the same strategy to show attended component for satirical news.",2 Related Work,[0],[0]
"Different from above works, we further evaluate linguistic features of highly attended paragraphs to analyze characteristics of satirical news, which has not been explored to our knowledge.",2 Related Work,[0],[0]
We first present our 4-level hierarchical neural network and explain how linguistic features can be embedded in the network to reveal the difference between paragraph level and document level.,3 The Proposed Model,[0],[0]
Then we describe the linguistic features.,3 The Proposed Model,[0],[0]
We build the model in a hierarchy of characterword-paragraph-document.,3.1 The 4-Level Hierarchical Model,[0],[0]
The general overview of the model can be viewed in Figure 1 and the notations are listed in Table 2.,3.1 The 4-Level Hierarchical Model,[0],[0]
We use convolutional neural networks (CNN) to encode word representation from characters.,3.1.1 Character-Level Encoder,[0],[0]
"CNN is effective in extracting morphological information and name entities (Ma and Hovy, 2016), both of which are common in news.",3.1.1 Character-Level Encoder,[0],[0]
Each word is presented as a sequence of n characters and each character is embedded into a low-dimension vector.,3.1.1 Character-Level Encoder,[0],[0]
The sequence of characters c is brought to the network.,3.1.1 Character-Level Encoder,[0],[0]
A convolution operation with a filter wc is applied and moved along the sequence.,3.1.1 Character-Level Encoder,[0],[0]
Max pooling is performed to select the most important feature generated by the previous operation.,3.1.1 Character-Level Encoder,[0],[0]
The word representation xc ∈,3.1.1 Character-Level Encoder,[0],[0]
Rf is generated with f filters.,3.1.1 Character-Level Encoder,[0],[0]
Assume a sequence of words of paragraph i arrives at time t.,3.1.2 Word-Level Encoder,[0],[0]
"The current word representation xi,t concatenates xci,t from character level with pretrained word embedding xei,t, as xi,t =",3.1.2 Word-Level Encoder,[0],[0]
"[x c i,t;x",3.1.2 Word-Level Encoder,[0],[0]
"e i,t].",3.1.2 Word-Level Encoder,[0],[0]
Examples are given in Figure 1.,3.1.2 Word-Level Encoder,[0],[0]
"We implement Gated Recurrent Unit (GRU) (Cho et al., 2014) rather than LSTM (Hochreiter and Schmidhuber, 1997) to encode the sequence because GRU has fewer parameters.",3.1.2 Word-Level Encoder,[0],[0]
"The GRU adopts reset gate ri,t and update gate zi,t to control the information flow between the input xi,t and the candidate
state h̃i,t.",3.1.2 Word-Level Encoder,[0],[0]
"The output hidden state hi,t is computed by manipulating previous state hi,t−1 and the candidate state h̃i,t regarding to zi,t as in Equation 4, where denotes element-wise multiplication.
",3.1.2 Word-Level Encoder,[0],[0]
"zi,t = σ(Wzxi,t + Uzhi,t−1 + bz) (1) ri,t = σ(Wrxi,t + Urhi,t−1 + br) (2)
h̃i,t = tanh(Whxi,t + ri,t (Uhhi,t−1 + bh)) (3)
hi,t = (1− zi,t) hi,t−1 + zi,t h̃i,t (4)
To learn a better representation from the past and the future, we use bidirectional-GRU (BiGRU) to read the sequence of words with forward −−→ GRU from xi,1 to xi,t, and backward ←−− GRU from xi,t to xi,1.",3.1.2 Word-Level Encoder,[0],[0]
"The final output of Bi-GRU concatenates the last state of −−→ GRU and ←−− GRU, as [ −→ h i,t; ←− h i,1], to represent the ith paragraph.",3.1.2 Word-Level Encoder,[0],[0]
"We observe that not all paragraphs have satire and some of them are functional to make the article complete, so we incorporate attention mechanism to reveal which paragraphs contribute to decision making.",3.1.3 Paragraph-Level Attention,[0],[0]
"Assuming a sequence of paragraph representations have been constructed from lower levels, another Bi-GRU is used to encode these representations to a series of new states p1:t, so the sequential orders are considered.
",3.1.3 Paragraph-Level Attention,[0],[0]
"To decide how paragraphs should be attended, we calculate satirical degree αi of paragraph i. We first convey pi into hidden states ui as in Equation 5.",3.1.3 Paragraph-Level Attention,[0],[0]
Then we product ui with a learnable satireaware vector va and feed the result into softmax function as in Equation 6.,3.1.3 Paragraph-Level Attention,[0],[0]
"The final document representation d is computed as a weighted sum of αi and pi.
ui = tanh(Wapi + ba) (5) αi =",3.1.3 Paragraph-Level Attention,[0],[0]
exp(u,3.1.3 Paragraph-Level Attention,[0],[0]
">i v
a)∑t j=0",3.1.3 Paragraph-Level Attention,[0],[0]
"exp(u > j va))
(6)
d = t∑
i=0
αipi (7)
Linguistic features are leveraged to support attending satire paragraph.",3.1.3 Paragraph-Level Attention,[0],[0]
"Besides pi, we represent paragraph i based on our linguistic feature set and transform it into a high-level feature vector lpi via
multilayer perceptron (MLP).",3.1.3 Paragraph-Level Attention,[0],[0]
"So ui in Equation 5 is updated to:
ui = tanh(Wapi + Ual p i + b a) (8)",3.1.3 Paragraph-Level Attention,[0],[0]
"Similar to the paragraph level, we represent document j based on our linguistic feature set and transform it into a high-level feature vector ldj via MLP.",3.1.4 Document-Level Classification,[0],[0]
We concatenate dj and ldj together for classification.,3.1.4 Document-Level Classification,[0],[0]
"Suppose yj ∈ (0, 1) is the label of the document j, the prediction ỹj and the loss function L over N documents are:
ỹj = sigmoid(Wddj +",3.1.4 Document-Level Classification,[0],[0]
Udldj + b d),3.1.4 Document-Level Classification,[0],[0]
"(9)
L = − 1 N N∑ j yj log ỹj +",3.1.4 Document-Level Classification,[0],[0]
"(1− yj) log(1− ỹj)
(10)",3.1.4 Document-Level Classification,[0],[0]
"Linguistic features have been successfully applied to expose differences between deceptive and genuine content, so we subsume most of the features in previous works.",3.2 Linguistic Features,[0],[0]
The idea of explaining fictitious content is extended here to reveal how satirical news differs from true news.,3.2 Linguistic Features,[0],[0]
"We divide our linguistic features into four families and compute them separately for paragraph and document.
",3.2 Linguistic Features,[0],[0]
"Psycholinguistic Features: Psychological differences are useful for our problem, because professional journalists tend to express opinion conservatively to avoid unnecessary arguments.",3.2 Linguistic Features,[0],[0]
"On the contrary, satirical news includes aggressive language for the entertainment purpose.",3.2 Linguistic Features,[0],[0]
We additionally observe true news favors clarity and accuracy while satirical news is related to emotional cognition.,3.2 Linguistic Features,[0],[0]
"To capture the above observations, we employ Linguistic Inquiry and Word Count (LIWC) (Pennebaker et al., 2007) as our psycholinguistic dictionary.",3.2 Linguistic Features,[0],[0]
"Each category of LIWC is one independent feature and valued by its frequency3.
",3.2 Linguistic Features,[0],[0]
"Writing Stylistic Features: The relative distribution of part-of-speech (POS) tags reflects informative vs. imaginative writing, which contributes to detecting deceptions (Li et al., 2014a; Mukherjee et al., 2013a).",3.2 Linguistic Features,[0],[0]
We argue that the stories covered by satirical news are based on imagination.,3.2 Linguistic Features,[0],[0]
"In addition, POS tags are hints of the underlying
3Total counts divided by total words.
humor (Reyes et al., 2012), which is common in satirical news.",3.2 Linguistic Features,[0],[0]
"So we utilize POS tags (Toutanova et al., 2003) to apprehend satire.",3.2 Linguistic Features,[0],[0]
"Each tag is regarded as one independent feature and valued by its frequency.
",3.2 Linguistic Features,[0],[0]
"Readability Features: We consider readability of genuine news would differ from satirical news because the former is written by professional journalists and tend to be clearer and more accurate, while satirical news packs numerous clauses to enrich the made-up story as introduced by Rubin et al. (2016).",3.2 Linguistic Features,[0],[0]
"Different from their work, we use readability metrics, including Flesch Reading Ease (Kincaid et al., 1975), Gunning Fog Index (Gunning, 1952), Automated Readability Index (Senter and Smith, 1967), ColemanLiau Index (Coleman and Liau, 1975), and syllable count per word, as features.
",3.2 Linguistic Features,[0],[0]
"Structural Features: To further reflect the structure of news articles, we examine the following features: word count, log word count, number of punctuations, number of digits, number of capital letters, and number of sentences.",3.2 Linguistic Features,[0],[0]
We report satirical news detection results and show high weighted word features.,4 Experiment and Evaluation,[0],[0]
"Then, we provide a thorough analysis between paragraph-level and document-level features.",4 Experiment and Evaluation,[0],[0]
"Finally, we visualize an example of satirical news article to demonstrate the effectiveness of our work.",4 Experiment and Evaluation,[0],[0]
"The satirical news is collected from 14 websites that explicitly declare they are offering satire, so the correct label can be guaranteed.",4.1 Dataset,[0],[0]
"We also notice websites that mix true news, fake news, and satirical news.",4.1 Dataset,[0],[0]
"We exclude these websites in this work because it requires experts to annotate the news articles.
",4.1 Dataset,[0],[0]
"We maintain each satire source in only one of the train/validation/test sets4 as the cross-domain
4Train: Onion, the Spoof.",4.1 Dataset,[0],[0]
"Test: SatireWorld, Beaverton, Ossurworld.",4.1 Dataset,[0],[0]
"Validation: DailyCurrent, DailyReport, EnduringVision, Gomerblog, NationalReport, SatireTribune, SatireWire, Syruptrap, and UnconfirmedSource.
setting in (Li et al., 2014a).",4.1 Dataset,[0],[0]
"Otherwise, the problem may become writing pattern recognition or news site classification.",4.1 Dataset,[0],[0]
"We also combined different sources together5 as a similar setting of leveraging multiple domains (Yang et al., 2016a).",4.1 Dataset,[0],[0]
"The true news is collected from major news outlets6 and Google News using FLORIN (Liu et al., 2015).",4.1 Dataset,[0],[0]
"The satirical news in the corpus is significantly less than true news, reflecting an impressionistic view of the reality.",4.1 Dataset,[0],[0]
"We omit headline, creation time, and author information so this work concentrates on the satire in the article body.",4.1 Dataset,[0],[0]
We realize the corpus may contain different degree of satire.,4.1 Dataset,[0],[0]
"Without the annotation, we only consider binary classification in this work and leave the degree estimation for the future.",4.1 Dataset,[0],[0]
The split and the description of the dataset can be found in Table 3.,4.1 Dataset,[0],[0]
"For SVM, we use the sklearn implementation7.",4.2 Implementation Detail,[0],[0]
We find that using linear kernel and setting “class weight” to “balanced” mostly boost the result.,4.2 Implementation Detail,[0],[0]
"We search soft-margin penalty “C” and find high results occur in range [10−1, 10−4].",4.2 Implementation Detail,[0],[0]
"We use the validation set to tune the model so selecting hyper-parameters is consistent with neural network based model.
",4.2 Implementation Detail,[0],[0]
"For neural network based models, we use the Theano package (Bastien et al., 2012) for implementation.",4.2 Implementation Detail,[0],[0]
"The lengths of words, paragraphs, and documents are fixed at 24, 128, and 16 with necessary padding or truncating.",4.2 Implementation Detail,[0],[0]
Stochastic Gradient Descent is used with initial learning rate of 0.3 and decay rate of 0.9.,4.2 Implementation Detail,[0],[0]
The training is early stopped if the F1 drops 5 times continuously.,4.2 Implementation Detail,[0],[0]
"Word embeddings are initialized with 100- dimension Glove embeddings (Pennington et al., 2014).",4.2 Implementation Detail,[0],[0]
Character embeddings are randomly initialized with 30 dimensions.,4.2 Implementation Detail,[0],[0]
"Specifically for the proposed model, the following hyper-parameters are estimated based on the validation set and used
5The combination is chosen to ensure enough training examples and balanced validation/test sets.
6CNN, DailyMail, WashingtonPost, NYTimes, TheGuardian, and Fox.
7sklearn.svm.",4.2 Implementation Detail,[0],[0]
"SVC
in the final test set.",4.2 Implementation Detail,[0],[0]
The dropout is applied with probability of 0.5.,4.2 Implementation Detail,[0],[0]
The size of the hidden states is set at 60.,4.2 Implementation Detail,[0],[0]
We use 30 filters with window size of 3 for convolution.,4.2 Implementation Detail,[0],[0]
"We report accuracy, precision, recall, and F1 on the validation set and the test set.",4.3 Performance of Satirical News Detection,[0],[0]
All metrics take satirical news as the positive class.,4.3 Performance of Satirical News Detection,[0],[0]
"Both paragraph-level and document-level linguistic features are scaled to have zero mean and unit variance, respectively.",4.3 Performance of Satirical News Detection,[0],[0]
"The compared methods include:
SVM word n-grams: Unigram and bigrams of the words as the baseline.",4.3 Performance of Satirical News Detection,[0],[0]
"We report 1,2-grams because it performs better than other n-grams.
",4.3 Performance of Satirical News Detection,[0],[0]
"SVM word n-grams + LF: 1,2-word grams plus linguistic features.",4.3 Performance of Satirical News Detection,[0],[0]
"We omit comparison with similar work (Ott et al., 2011) as their features are subsumed in ours.
",4.3 Performance of Satirical News Detection,[0],[0]
"SVM word + char n-grams: 1,2-word grams plus bigrams and trigrams of the characters.
",4.3 Performance of Satirical News Detection,[0],[0]
"SVM word + char n-grams + LF: All the proposed features are considered.
",4.3 Performance of Satirical News Detection,[0],[0]
"SVM Rubin et al. (2016): Unigram and bigrams tf-idf with satirical features as proposed in (Rubin et al., 2016).",4.3 Performance of Satirical News Detection,[0],[0]
"We compare with (Rubin et al., 2016) rather than (Burfoot and Baldwin, 2009) as the former claims a better result.
",4.3 Performance of Satirical News Detection,[0],[0]
SVM Rubin et al. (2016) +,4.3 Performance of Satirical News Detection,[0],[0]
"char tf-idf + LF: Include all possible features.
",4.3 Performance of Satirical News Detection,[0],[0]
Bi-GRU: Bi-GRU for document classification.,4.3 Performance of Satirical News Detection,[0],[0]
"The document representation is the average of the hidden state at every time-step.
",4.3 Performance of Satirical News Detection,[0],[0]
SVM Doc2Vec:,4.3 Performance of Satirical News Detection,[0],[0]
"Unsupervised method learning distributed representation for documents (Le and Mikolov, 2014).",4.3 Performance of Satirical News Detection,[0],[0]
"The implementation is based on
Gensim (Řehůřek and Sojka, 2010).",4.3 Performance of Satirical News Detection,[0],[0]
"HAN: Hierarchical Attention Network (Yang et al., 2016b) for document classification with both word-level and sentence-level attention.
",4.3 Performance of Satirical News Detection,[0],[0]
"4LHN: 4-Level Hierarchical Network without any linguistic features.
",4.3 Performance of Satirical News Detection,[0],[0]
"4LHNP: 4-Level Hierarchical Network with Paragraph-level linguistic features.
",4.3 Performance of Satirical News Detection,[0],[0]
"4LHND: 4-Level Hierarchical Network with Document-level linguistic features.
",4.3 Performance of Satirical News Detection,[0],[0]
"4LHNPD: 4-Level Hierarchical Network with both Paragraph-level and Document-level linguistic features.
",4.3 Performance of Satirical News Detection,[0],[0]
"In Table 4, the performances on the test set are generally better than on the validation set due to the cross-domain setting.",4.3 Performance of Satirical News Detection,[0],[0]
"We also explored word-level attention (Yang et al., 2016b), but it performed 2% worse than 4LHN.",4.3 Performance of Satirical News Detection,[0],[0]
The result of Doc2Vec is limited.,4.3 Performance of Satirical News Detection,[0],[0]
"We suspect the reason could be the high imbalanced dataset, as an unsupervised learning method for document representation heavily relies on the distribution of the document.",4.3 Performance of Satirical News Detection,[0],[0]
We report high weighted word-grams in Table 5 based on the SVM model as incorporating word-level attention in our neural hierarchy model reduces the detection performance.,4.4 Word Level Analysis,[0],[0]
"According
to Table 5, we conclude satirical news mimics true news by using news related words, such as “stated” and “reporter”.",4.4 Word Level Analysis,[0],[0]
"However, these words may be over used so they can be detected.",4.4 Word Level Analysis,[0],[0]
"True news may use other evidence to support the credibility, which explains “twitter”, “com”, “video”, and “pictured”.",4.4 Word Level Analysis,[0],[0]
High weight of “ : ” indicates that true news uses colon to list items for clarity.,4.4 Word Level Analysis,[0],[0]
"High weight of “ '' ” indicates that satirical news involves more conversation, which is consistent with our observation.",4.4 Word Level Analysis,[0],[0]
The final interesting note is satirical news favors “washington dc”.,4.4 Word Level Analysis,[0],[0]
"We suspect that satirical news mostly covers politic topics, or satire writers do not spend efforts on changing locations.",4.4 Word Level Analysis,[0],[0]
"We use 4LHNPD to compare paragraph-level and document-level features, as 4LHNPD leverages the two-level features into the same framework and yields the best result.
",4.5 Analysis of Weighted Linguistic Features,[0],[0]
"Because all linguistic features are leveraged into MLP with non-linear functions, it is hard to check which feature indicates satire.",4.5 Analysis of Weighted Linguistic Features,[0],[0]
"Alternatively, we define the importance of linguistic features by summing the absolute value of the weights if directly connected to the feature.",4.5 Analysis of Weighted Linguistic Features,[0],[0]
"For example, the importance I of feature k is given by Ik = 1 M ∑M m=0 |wk,m|, where w ∈ RK×M is the directly connected weight, K is the number of features, and M is the dimension of the output.",4.5 Analysis of Weighted Linguistic Features,[0],[0]
"This metric gives a general idea about how much does a feature contribute to the decision making.
",4.5 Analysis of Weighted Linguistic Features,[0],[0]
We first report the scaled importance of the four linguistic feature sets by averaging the importance of individual linguistic features.,4.5 Analysis of Weighted Linguistic Features,[0],[0]
Then we report individual important features within each set.,4.5 Analysis of Weighted Linguistic Features,[0],[0]
"According to Figure 2, the importance of paragraph-level features is greater than documentlevel features except for the readability feature set.",4.5.1 Comparing the Four Feature Sets,[0],[0]
"It is reasonable to use readability at the document level because readability features evaluate the understandability of a given text, which depends on the content and the presentation.",4.5.1 Comparing the Four Feature Sets,[0],[0]
"The structural feature set is highly weighted for selecting attended paragraph, which inspires us to focus on individual features inside the structural feature set.",4.5.1 Comparing the Four Feature Sets,[0],[0]
"Within each set, we rank features based on the importance score and report their mean and standard deviation before being scaled in Table 6.",4.5.2 Comparing Individual Features,[0],[0]
"At paragraph level, we use top three attended paragraphs for calculating.",4.5.2 Comparing Individual Features,[0],[0]
"The respective p-values of all features in the table are less than 0.01 based on the t-test, indicating satirical news is statistically significantly different from true news.
",4.5.2 Comparing Individual Features,[0],[0]
"Comparing Table 6 and Table 3, we find that the word count, capital letters, and punctuations in true news are larger than in satirical news at the document level, while at paragraph level these
features in true news are less than in satirical news.",4.5.2 Comparing Individual Features,[0],[0]
This indicates satire paragraph could be more complex locally.,4.5.2 Comparing Individual Features,[0],[0]
"It also could be referred as “sentence complexity”, that “satirical articles tend to pack a great number of clauses into a sentence for comedic effect” (Rubin et al., 2016).",4.5.2 Comparing Individual Features,[0],[0]
"Accordingly, we hypothesize top complex paragraphs could represent the entire satire document for classification, which we leave for future examination.
",4.5.2 Comparing Individual Features,[0],[0]
"In Table 6, psycholinguistic feature “Humans” is more related to emotional writing than control writing (Pennebaker et al., 2007), which indicates satirical news is emotional and unprofessional compared to true news.",4.5.2 Comparing Individual Features,[0],[0]
"The same reason also applies to “Social” and “Leisure”, where the former implies emotional and the latter implies control writing.",4.5.2 Comparing Individual Features,[0],[0]
"The “Past” and “VBN” both have higher frequencies in true news, which can be explained by the fact that true news covers what happened.",4.5.2 Comparing Individual Features,[0],[0]
"A similar reason that true news reports what happened to others explains a low “Self” and a high “VBZ” in true news.
",4.5.2 Comparing Individual Features,[0],[0]
"For writing stylistic features, it is suggested that informative writing has more nouns, adjectives, prepositions and coordinating conjunctions, while imaginative writing has more verbs, adverbs, pronouns, and pre-determiners (Rayson et al., 2001).",4.5.2 Comparing Individual Features,[0],[0]
"This explains higher frequencies of “RB” and “PRP” in satirical news, and higher frequency of “NN” and “CC” in true news.",4.5.2 Comparing Individual Features,[0],[0]
"One exception is “JJ”, adjectives, which receives the highest weight in this feature set and indicates a higher frequency
in satirical news.",4.5.2 Comparing Individual Features,[0],[0]
"We suspect adjective could also be related to emotional writing, but more experiments are required.
",4.5.2 Comparing Individual Features,[0],[0]
Readability suggests satirical news is easier to be understood.,4.5.2 Comparing Individual Features,[0],[0]
"Considering satirical news is also deceptive (as the story is not true), this is consistent with works (Frank et al., 2008; Afroz et al., 2012) showing deceptive writings are more easily comprehended than genuine writings.",4.5.2 Comparing Individual Features,[0],[0]
"Finally, true news has more digits and a higher “CD”(Cardinal number) frequency, even at the paragraph level, because they tend to be clear and accurate.",4.5.2 Comparing Individual Features,[0],[0]
"To explore the attention, we sample one example in the validation set and present it in Figure 3.",4.6 Visualization of Attended Paragraph,[0],[0]
The value at the right represents the scaled attention score.,4.6 Visualization of Attended Paragraph,[0],[0]
The high attended paragraphs are longer and have more capital letters as they are referring different entities.,4.6 Visualization of Attended Paragraph,[0],[0]
"They have more double quotes, as multiple conversations are involved.
",4.6 Visualization of Attended Paragraph,[0],[0]
"Moreover, we subjectively feel the attended paragraph with score 0.98 has a sense of humor while the paragraph with score 0.86 has a sense of sarcasm, which are common in satire.",4.6 Visualization of Attended Paragraph,[0],[0]
"The paragraph with score 1.0 presents controversial topics, which could be misleading if the reader cannot understand the satire.",4.6 Visualization of Attended Paragraph,[0],[0]
This is what we expect from the attention mechanism.,4.6 Visualization of Attended Paragraph,[0],[0]
"Based on the visualization, we also feel this work could be generalized to detect figurative languages.",4.6 Visualization of Attended Paragraph,[0],[0]
"In this paper, we proposed a 4-level hierarchical network and utilized attention mechanism to understand satire at both paragraph level and document level.",5 Conclusion,[0],[0]
"The evaluation suggests readability features support the final classification while psycholinguistic features, writing stylistic features, and structural features are beneficial at the paragraph level.",5 Conclusion,[0],[0]
"In addition, although satirical news is shorter than true news at the document level, we find satirical news generally contain paragraphs which are more complex than true news at the paragraph level.",5 Conclusion,[0],[0]
"The analysis of individual features reveals that the writing of satirical news tends to be emotional and imaginative.
",5 Conclusion,[0],[0]
"We will investigate efforts to model satire at the paragraph level following our conclusion and theoretical backgrounds, such as (Ermida, 2012).",5 Conclusion,[0],[0]
We plan to go beyond the binary classification and explore satire degree estimation.,5 Conclusion,[0],[0]
"We will generalize our approach to reveal characteristics of figurative language (Joshi et al., 2016), where different paragraphs or sentences may reflect different degrees of sarcasm, irony, and humor.",5 Conclusion,[0],[0]
The authors would like to thank the anonymous reviewers for their comments.,Acknowledgments,[0],[0]
This work was support in part by the U.S. NSF grants 1546480 and 1527364.,Acknowledgments,[0],[0]
"Satirical news is considered to be entertainment, but it is potentially deceptive and harmful.",abstractText,[0],[0]
"Despite the embedded genre in the article, not everyone can recognize the satirical cues and therefore believe the news as true news.",abstractText,[0],[0]
We observe that satirical cues are often reflected in certain paragraphs rather than the whole document.,abstractText,[0],[0]
"Existing works only consider documentlevel features to detect the satire, which could be limited.",abstractText,[0],[0]
We consider paragraphlevel linguistic features to unveil the satire by incorporating neural network and attention mechanism.,abstractText,[0],[0]
"We investigate the difference between paragraph-level features and document-level features, and analyze them on a large satirical news dataset.",abstractText,[0],[0]
The evaluation shows that the proposed model detects satirical news effectively and reveals what features are important at which level.,abstractText,[0],[0]
Satirical News Detection and Analysis using Attention Mechanism and Linguistic Features,title,[0],[0]
In many biological and physical experiments it is necessary to track the movement of many isolated particles in a video datastream.,1. Introduction,[0],[0]
"This is an essential task in biomedical research, for example, to reveal the biophysical properties of both the imaged particles (e.g., single molecules) and the biological substrate (e.g., cell membrane) that the particles are traversing.",1. Introduction,[0],[0]
"Effective particle tracking algorithms have wide
1Department of Biological Sciences; 2Departments of Statistics and Neuroscience; Grossman Center for the Statistics of Mind; Center for Theoretical Neuroscience; Columbia University.",1. Introduction,[0],[0]
"Correspondence to: Liam Paninski <liam@stat.columbia.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
applications in both fundamental and applied biology, and more generally in chemistry and physical applications.
",1. Introduction,[0],[0]
Previous scalable approaches to this task have largely involved non-Bayesian methods aiming at estimating a single “best” path of the underlying particles.,1. Introduction,[0],[0]
"However, in many applications particles have indistinguishable shapes under light microscopic resolution.",1. Introduction,[0],[0]
This leads to a fundamental non-identifiability: if two particles pass close by each other (“meet”) then it is impossible to deterministically link the pre-meeting paths with the correct post-meeting paths (see Figure 1 below for an illustration).,1. Introduction,[0],[0]
"This motivates a Bayesian approach for assigning posterior probabilities over all the possible sets of particle paths consistent with the observed data.
",1. Introduction,[0],[0]
"Formally, at each timestep we observe a noisy, blurry image recording the particles’ current positions.",1. Introduction,[0],[0]
"In the simplest case, we can cast the tracking task in a factorial hidden Markov Model (HMM) framework, where each particle evolves according to a Markov process and thus multiple HMMs (one per particle) jointly determine the observed image data.",1. Introduction,[0],[0]
"The classic HMM inference approach is the forward-backward algorithm (Rabiner, 1990), but the complexity of forward-backward scales superlinearly with the number of particles here.
",1. Introduction,[0],[0]
"In this work, we propose an amortized inference approach utilizing a specialized recurrent neural network architecture to approximate the posterior particle transition densities inferred by forward-backward.",1. Introduction,[0],[0]
"After network training, posterior inference can be performed very quickly: given a new video dataset, the network outputs the conditional particle initialization and transition densities, and then we can simply sample forward from the resulting Markov chain to draw samples from the posterior particle paths.
",1. Introduction,[0],[0]
We apply the method to simulated and real data.,1. Introduction,[0],[0]
"We show that the method robustly performs approximate Bayesian inference on the observed data, and provides more accurate results than competing methods that output just a single “best” path.",1. Introduction,[0],[0]
"Our approach is much more scalable than previously proposed Bayesian approaches, scaling linearly in the number of frames and in the number of observed pixels.",1. Introduction,[0],[0]
To set the stage we describe the simplest concrete model for particle tracking data; we will generalize this model below.,2. Model,[0],[0]
We have J indistinguishable particles: each particle j appears at some time tappearj and disappears at some later time tdisappearj .,2. Model,[0],[0]
"The particles move according to independent Gauss-Markov processes, with no interactions between particles.",2. Model,[0],[0]
On each frame t we observe a blurred noisy sum of the particles that are visible at time t.,2. Model,[0],[0]
The observation likelihood depends on the details of the experimental setup; the most common model is the Gaussian blur +,2. Model,[0],[0]
"Poisson noise model:
Y (t, x) ∼ Poisson[λ(t, x) + λ0] λ(t, x) = ∑ j G[x− sj(t)],
where Y (t, x) denotes the image data observed at pixel x at time t, λ0 is a background “dark noise” Poisson intensity, G[.] is a Gaussian point spread function (psf), sj(t) represents the location of particle j at time t, and the sum is over all particles that are alive at time",2. Model,[0],[0]
"t.
The model described above is a factorial HMM (Ghahramani & Jordan, 1996).",2. Model,[0],[0]
"However, this simple model can be generalized significantly.",2. Model,[0],[0]
There may be multiple distinguishable classes of particles that have different shapes or colors.,2. Model,[0],[0]
"In many datasets particles can interact: they might merge, collide, split, etc.",2. Model,[0],[0]
"Individual particles often move in a non-Markovian manner (e.g., switching between several different latent dynamical modes).",2. Model,[0],[0]
"There may be strong dependencies between the motion of different particles, due e.g. to substrate motion.",2. Model,[0],[0]
"Finally, the observation noise may be highly non-Poisson, with correlations and strong inhomogeneities across the field of view.",2. Model,[0],[0]
Thus it is critical to develop flexible inference approaches that do not depend on strong factorial HMM assumptions.,2. Model,[0],[0]
"The literature on particle tracking methods is vast, and dates back to early physics studies of Brownian motion in fluids; see e.g. (Manzo & Garcia-Parajo, 2015) for a review, and (Chenouard et al., 2014) for a quantitative comparison of many algorithms.",3. Related work on particle tracking,[0],[0]
"We will not attempt to review all of these methods here, but note that many algorithms split the tracking problem into a “detect” followed by a “link” step.",3. Related work on particle tracking,[0],[0]
The “detect” step outputs estimated particle locations given each image Yt.,3. Related work on particle tracking,[0],[0]
"Various nonlinear filtering, thresholding, deconvolution, and neural network approaches have been employed for this task (Chenouard et al., 2014).",3. Related work on particle tracking,[0],[0]
"Most such detection algorithms take just single frames Yt as input, and therefore they do not integrate useful information across multiple frames to perform detection; (Newby et al., 2017)
is a recent counterexample that demonstrates that better performance can be achieved if multiple frames Yt are utilized in the detection step.
",3. Related work on particle tracking,[0],[0]
"The “link” step then attempts to fuse these detected locations, to estimate the tracks that each visible particle took over the length of the observed movie.",3. Related work on particle tracking,[0],[0]
"This linkage step is solved by some matching algorithm; see e.g. (Jaqaman et al., 2008) for an influential example of this approach, and (Chenouard et al., 2014; Turner et al., 2014; Wilson et al., 2016) for discussion of some other linking methods.
",3. Related work on particle tracking,[0],[0]
"As we emphasized in the introduction, deterministic detection and linking approaches are statistically suboptimal, since they ignore the irreducible uncertainty of the tracking problem that results when two or more visibly indistinguishable particles pass closer than a fraction of a psf-width of each other.",3. Related work on particle tracking,[0],[0]
"Ignoring this uncertainty leads to non-robust results, in which tiny changes to the data can lead to discontinuous changes in the estimated particle tracks.",3. Related work on particle tracking,[0],[0]
"Moreover, it is clear that the linkage and detection should not be separated: if we know the tracks of particles at times (1 : t− 1) and (t+ 1 : T ), then we have very strong prior information about the locations of particles at time t, and ignoring this useful prior information will lead to suboptimal results.",3. Related work on particle tracking,[0],[0]
"(See e.g. (Sun et al., 2017), where similar points were made in the context of a related super-resolution application.)
",3. Related work on particle tracking,[0],[0]
"Similar points have been made in the Bayesian signal processing literature; for example, sequential Monte Carlo (particle filtering) methods have been applied to perform probabilistic inference in this setting (Smal et al., 2008).",3. Related work on particle tracking,[0],[0]
"These approaches have the advantage of a proper grounding in standard Bayesian computational methodology, but scale poorly in the number of visible particles.
",3. Related work on particle tracking,[0],[0]
"Finally, there is also a very large literature on “multi-target tracking,” e.g., tracking multiple people visible on security cameras.",3. Related work on particle tracking,[0],[0]
"In this literature the different targets are typically distinguishable (e.g., different people visible on a camera will have different faces, gaits, clothing, etc.), whereas in this paper we focus on the case that the particles to be tracked are indistinguishable.",3. Related work on particle tracking,[0],[0]
"Of course a middle ground exists in which particles have some distinguishing features but some posterior uncertainty about particle identity remains due to noisy or incomplete observations; however, to keep our presentation simple we focus exclusively on the most challenging fully-indistinguishable case here.",3. Related work on particle tracking,[0],[0]
"Our conceptual starting point is the standard filter-backwardsample-forward algorithm for sampling from the posterior distribution p(Q|Y ) of the hidden state Q = {qt} of an
HMM conditional on the observed data Y (Rabiner, 1990).",4.1. Overview,[0],[0]
"This algorithm has two steps: (1) combine the observed data Y with the prior distribution p(Q) of the hidden Markov state Q to obtain a new Markov chain p(Q|Y ), and (2) sample forward from this new Markov chain.",4.1. Overview,[0],[0]
"Once (1) is complete, we can call (2) as often as we like to generate new sample paths from p(Q|Y ).",4.1. Overview,[0],[0]
"This approach is attractive in our setting because sampling forward from a Markov chain is a fast operation once the conditional initial and transition densities (p(q1|Y ) and p(qt|Y, qt−1), respectively) are in hand, where the hidden state qt is the configuration of the locations and identities of all of the particles alive at time",4.1. Overview,[0],[0]
"t. Thus in principle we can simply run (2) repeatedly to compute probabilities of any quantity we care about (e.g., the probability that a particle is in location x at time t, or the probability that particle i in frame s should be linked with particle j in frame t).
",4.1. Overview,[0],[0]
"Unfortunately, as emphasized above, computing (1) exactly is intractable in our context; thus we need to approximate the conditional initial and transition densities.",4.1. Overview,[0],[0]
"Our strategy is to train neural networks to approximate these probabilities.
",4.1. Overview,[0],[0]
"This approach is highly flexible; given enough training data, we can handle a wide variety of non-standard data, well beyond the simplest Gaussian blur +",4.1. Overview,[0],[0]
"Poisson noise factorial HMM described above, since the learned probabilities do not lean heavily on special assumptions about e.g. the noise model or the precise details of the graphical model underlying the data1.",4.1. Overview,[0],[0]
"In turn, we can generate as much training data as we need by simulating ground truth particle tracks along with the resulting observed data videos Y .
",4.1. Overview,[0],[0]
It is convenient to split the network into three parts: the conditional transition density that governs how samples move from timestep t to t+ 1; the conditional birth density that governs the probability that a new particle appears at time t; and the conditional initial density that governs the positions of the particles at timestep 1.,4.1. Overview,[0],[0]
"We describe each of these in turn below.
",4.1. Overview,[0],[0]
"1The main assumption we make is that the posterior p(Q|Y ) can be well-approximated as Markovian, so that our resulting Markovian sampler can provide good approximations to true samples from the posterior.",4.1. Overview,[0],[0]
This assumption is reasonable in the majority of particle-tracking applications we have in mind.,4.1. Overview,[0],[0]
This network is illustrated in Figure 1.,4.2. Conditional transition density network,[0],[0]
The task of this network is to combine the observed data Y with the previous particle configuration qt−1 and to output probabilities that govern the particle configuration qt in the next time step.,4.2. Conditional transition density network,[0],[0]
"This is a nontrivial task, since the dimensionality of qt can be large and varies with time t as particles appear or disappear.",4.2. Conditional transition density network,[0],[0]
"Similarly, the observed image Yt is often large (hundreds of pixels on a side), and in principle we need to observe multiple frames before and after time t to perform optimal inference.
",4.2. Conditional transition density network,[0],[0]
"Thus, for scalability, we break the problem up into a sequence of smaller pieces and work convolutionally.",4.2. Conditional transition density network,[0],[0]
We begin by choosing a random ordering of the particles in qt−1.,4.2. Conditional transition density network,[0],[0]
"Then, for each of these particles indexed by i, we input three types of data: (1) a local patch of the observed movie data (in a spatial neighborhood around the i-th particle location sit−1, and in a temporal context of M frames before and after the current frame t; (2) a binary mask indicating the locations of the particles at time t − 1 in the same spatial neighborhood as particle i; and (3) a second binary mask indicating the locations of the particles j that have been sampled at time t prior to sampling particle i2.",4.2. Conditional transition density network,[0],[0]
"The network is then trained to output a probability map p(sit|qt−1, {qjt }j<i, Y ) indicating the likely location sit, along with an auxiliary probability that the particle disappears (and is therefore no longer present at time t).",4.2. Conditional transition density network,[0],[0]
"Once these transition probabilities are learned, we can sample forward one particle and time-step at a time, as illustrated in the sampling process video and detailed in Algorithm 1; thus at test time inference scales linearly in the number of particles and time steps in the movie.
",4.2. Conditional transition density network,[0],[0]
"Note that we have slightly diverged from the vanilla filterbackward-sample-forward algorithm, which propagates information all the way back from the final observation YT to determine the state qt.",4.2. Conditional transition density network,[0],[0]
"Instead, we exploit the fact that only a local context around time t is necessary to infer qt, and thus we restrict our attention at time t to the local context Yt−M :t+M .",4.2. Conditional transition density network,[0],[0]
(We use M = 2 throughout this paper.),4.2. Conditional transition density network,[0],[0]
"The network described above moves particles forward from timestep t− 1 to t, and decides which particles should disappear at time t. However, new particles can enter the field
2This input lets the network avoid placing two particles to explain a single observed bump in Yt; if a previously-sampled particle j already explains the bump well, then the network will prefer to put particle i elsewhere.",4.3. New birth networks and initialization,[0],[0]
"Also note that the input data Y and output probability maps don’t need to have the same number of pixels (i.e., we could attempt to resolve the particle locations at higher spatial resolution than the observed data), but we have not pursued this direction in detail.
",4.3. New birth networks and initialization,[0],[0]
"Algorithm 1 Conditional sampling network Initialize: S1 = Initializer(Y1:M+1,",4.3. New birth networks and initialization,[0],[0]
[]) # Sec.,4.3. New birth networks and initialization,[0],[0]
"4.3 # Sec. 4.2 for t = 2, 3, 4... do St =",4.3. New birth networks and initialization,[0],[0]
"[] for i in Permutation{St−1} do pi = ConditionalProbability(Yt−M :t+M , St−1, St, i) particle i disappears with prob.",4.3. New birth networks and initialization,[0],[0]
"1− ∫ pi
otherwise i′ is sampled from pi Insert i′ to St
end for Nt = NewBirth(Yt−M :t+M , St−1, St) #",4.3. New birth networks and initialization,[0],[0]
Sec.,4.3. New birth networks and initialization,[0],[0]
"4.3 Insert Nt to St St−1 = St
end for
of view at any time, and therefore we need a method for adding new particles to qt.",4.3. New birth networks and initialization,[0],[0]
"Thus after running the update described above to qt, we run a second convolutional network that takes the same inputs as above (i.e., the local context of qt−1, qt, and Y , now at each location in the image instead of just at the previously-sampled particle locations) and outputs the probability that a new particle is born at each location at time t.",4.3. New birth networks and initialization,[0],[0]
"Then we iteratively sample from this density and update qt until no further particles are added.
",4.3. New birth networks and initialization,[0],[0]
The same strategy can be used to initialize q1; the only difference is that the inputs now don’t include qt−1 or the context of Y prior to Y1.,4.3. New birth networks and initialization,[0],[0]
"To handle the temporal and spatial dependencies in this data, we chose a combination of bi-directional 2D convolution LSTM and 3D convolutional layers; see Appendix.",4.4. Network architecture and training,[0],[0]
"Overall, when the network is sampling forward, we can think of the resulting algorithm as a recurrent neural network (since the sampled output is then read back into the network to define the next state transition), with the somewhat non-standard feature that the network remains at timestep t for a random number of iterations (depending on how many particles need to be updated and how many particles are born at each timestep).
",4.4. Network architecture and training,[0],[0]
To train the network we generated simulated ground truth particle tracks qt and corresponding observed movies Y .,4.4. Network architecture and training,[0],[0]
(We will discuss the training data in more detail in the following section.),4.4. Network architecture and training,[0],[0]
"Then we formed minibatches of training data, where each data sample included the inputs to the network (the local context of Y , qt−1, and a random subset of qt) along with the true particle location sit, which served as the target output of the network.",4.4. Network architecture and training,[0],[0]
"We trained the network (using default learning rate settings in Keras) to minimize the binary cross-entropy between the target mask (zero ex-
cept at sit, or all zeros if all the particles in qt were already sampled and no further particles should be added) and the network’s output probability mask.",4.4. Network architecture and training,[0],[0]
Code is available here.,4.4. Network architecture and training,[0],[0]
We begin with a simple simulated experiment in which the particles are restricted to move in the horizontal direction only.,5.1. One-dimensional example,[0],[0]
"This makes it easier to view and understand the results, by simply plotting the horizontal positions of the (true vs. inferred) particles as a function of time.",5.1. One-dimensional example,[0],[0]
"The results are illustrated in Figure 2; the same data are shown in Figure 1 and the sampling process video.
",5.1. One-dimensional example,[0],[0]
"In this example we see the appearance and disappearance of a couple particles, and two “meeting” events in which one particle overlaps significantly with another particle.",5.1. One-dimensional example,[0],[0]
"Since in this example all the particles have identical shapes and are undergoing independent and identically distributed Brownian motions, there is no way to deterministically “link” particles before and after these meeting events; i.e., the “correct” linker here must output a probabilistic answer.
",5.1. One-dimensional example,[0],[0]
In panels 2-4 of Figure 2 we display three conditional sample paths drawn by our algorithm.,5.1. One-dimensional example,[0],[0]
Sample 0,5.1. One-dimensional example,[0],[0]
"(panel 2) recovers the ground truth accurately, and Sample 1 and 2 (panels 3 and 4) give different — but also valid — sets of tracks.",5.1. One-dimensional example,[0],[0]
"Panel 5 shows an average of 100 samples overlaid together, with the colors indicating relative probabilities of the chosen tracks.",5.1. One-dimensional example,[0],[0]
"Note that at the beginning of the trial, where the two visible particles are well-isolated, the sampler essentially outputs a deterministic estimate, with all samples assigned to the left (red) or the right (blue).",5.1. One-dimensional example,[0],[0]
"However, after the “meeting” near t = 15, the colors blend, indicating probabilistic assignment of tracks following this event, as desired.
",5.1. One-dimensional example,[0],[0]
"For comparison, we also show the output of two existing particle tracking methods, both of which output deterministic particle identities.",5.1. One-dimensional example,[0],[0]
"Our approach provides visibly more robust outputs on this example, with fewer dropped particle detections and false particle appearances or disappearances.",5.1. One-dimensional example,[0],[0]
"Next we turn to a small-scale simulated two-dimensional example; the results are illustrated in the moving particles video, Figure 3, and the 3D view video.",5.2. Two-dimensional example,[0],[0]
"As in the previous one-dimensional example, we find that our proposed approach accurately detects the particle locations and appearance/disappearance times, and successfully assigns identities probabilistically following particle meetings.",5.2. Two-dimensional example,[0],[0]
"To establish a more quantitative evaluation, we compared against two baseline methods: the popular Utrack approach (Jaqaman et al., 2008) and the method proposed in (Wilson et al., 2016), which performed well on the performance metrics established in the review / competition paper (Chenouard et al., 2014).",5.3. Large scale examples and evaluation,[0],[0]
"We generated large-scale twodimensional simulated data whose parameters matched a pair of challenging datasets in (Chenouard et al., 2014), and then computed the suite of performance metrics (measuring various facets of detection accuracy, linking quality, etc.) introduced in the same paper (averaging over 100 draws from our sampler for each dataset).",5.3. Large scale examples and evaluation,[0],[0]
"Results are shown in Table 1: we find that our proposed method outperforms the
baselines on both datasets examined, on all the performance metrics computed here.
",5.3. Large scale examples and evaluation,[0],[0]
"It is worth emphasizing that these performance metrics were designed for deterministic tracking algorithms, and therefore entirely miss one of the major advantages of our approach (the fact that it outputs not just a single “best” track estimate but instead estimates the posterior distribution over all tracks).",5.3. Large scale examples and evaluation,[0],[0]
How can we evaluate the quality of our approximation to the posterior here (and quantitatively compare between different algorithms that attempt to approximate this posterior)?,5.3. Large scale examples and evaluation,[0],[0]
One natural approach is to estimate the Kullback-Leibler divergence DKL[f(Q); p(Q|Y )] between our approximate posterior f(Q) and the true posterior p(Q|Y ) on the state space Q given the observed data Y .,5.3. Large scale examples and evaluation,[0],[0]
"Of
course, this is not quite tractable, due to the intractability of p(Q|Y ), but we can estimate DKL[f(Q); p(Q|Y )] up to a constant in f(Q) by sampling from f(Q):
DKL[f(Q); p(Q|Y )]",5.3. Large scale examples and evaluation,[0],[0]
"= Ef(Q) log f(Q)
p(Q|Y )
",5.3. Large scale examples and evaluation,[0],[0]
"= Ef(Q) log f(Q)
p(Q)p(Y |Q) + const[f(Q)]
",5.3. Large scale examples and evaluation,[0],[0]
≈ 1 N N∑ i=1,5.3. Large scale examples and evaluation,[0],[0]
log f(Qi) p(Qi)p(Y,5.3. Large scale examples and evaluation,[0],[0]
"|Qi) + const[f(Q)],
where {Qi)}i=1:N are N samples from f(Q).",5.3. Large scale examples and evaluation,[0],[0]
Here p(Qi) and p(Y |Qi) can be evaluated explicitly if the prior p(Q) is e.g. Markovian; for our approach f(Qi) can also be evaluated directly since f(Q) has an explicit Markov form.,5.3. Large scale examples and evaluation,[0],[0]
This provides us a method for scoring any Bayesian particle tracking algorithm for which we can explicitly evaluate the approximate posterior f(Q).,5.3. Large scale examples and evaluation,[0],[0]
"(We do not perform this scoring on the baselines examined here, since for any deterministic algorithm f(Q) is a delta function, leading to an infinite Kullback-Leibler score if we treat qt as a continuous random variable — i.e., the probabilistic approach trivially outperforms deterministic approaches.)",5.3. Large scale examples and evaluation,[0],[0]
"Finally, we tested the performance of our algorithm on real data.",5.4. Real data example,[0],[0]
"The data are TIR-FM imaged clathrin-coated pits in a BSC1 cell (Jaqaman et al., 2008).",5.4. Real data example,[0],[0]
"We trained the network on simulated data whose parameters (signal-to-noise ratio, particle density and speed, psf width, etc.) were coarsely matched to the real data; see the comparison video for details.",5.4. Real data example,[0],[0]
We plot three samples from our algorithm using different colors in Fig. 4 and the real data video.,5.4. Real data example,[0],[0]
"While
ground truth is unavailable in this case, by visual inspection the algorithm seems to effectively follow the particles in the video, without excessive oversegmentation of the tracks; the output here seems consistent with the behavior of the algorithm on the previous simulated datasets.",5.4. Real data example,[0],[0]
"In the introduction we emphasized the importance of the particle tracking problem; we believe that the more robust, accurate, and probabilistic tracking methods developed here will have a significant impact in a wide range of biological and physical applications.
",6.1. Related machine learning work,[0],[0]
"More generally, from a machine learning point of view, the major novelty of our work is the incorporation of neural network methods to provide a flexible and scalable approximation of Bayesian inference via efficient sampling in a large graphical model.
",6.1. Related machine learning work,[0],[0]
"Of course, interactions between Bayesian analysis and neural network methods comprise a very rich thread of research these days.",6.1. Related machine learning work,[0],[0]
"The work of (Snell & Zemel, 2017) is highly relevant: this paper describes a neural network approach to sample multiple segmentations that are consistent with an observed image, much as we use neural networks to sample multiple particle tracks that are consistent with an observed video.
",6.1. Related machine learning work,[0],[0]
"As another example, variational autoencoders (Kingma & Welling, 2013; Rezende et al., 2014) and variants thereof (Johnson et al., 2016; Gao et al., 2016; Fraccaro et al., 2017; Krishnan et al., 2017) have become very popular recently for performing inference in nonlinear HMMs.",6.1. Related machine learning work,[0],[0]
"These methods
are most effective when the latent state variable is lowdimensional.",6.1. Related machine learning work,[0],[0]
"In the particle tracking problem the latent dynamical variable is very high-d (scaling with the number of particles) and more importantly the latent dimensionality is time-varying, as particles are born, die, merge, split, enter, or leave the focal plane.",6.1. Related machine learning work,[0],[0]
"We are not aware of variational autoencoder approaches that would be easily applicable to the particle tracking problem.
",6.1. Related machine learning work,[0],[0]
"Another related thread involves amortized inference using neural networks for sequential Monte Carlo; see e.g. (Paige & Wood, 2016).",6.1. Related machine learning work,[0],[0]
"Again, it is not clear how well these methods would scale to the large-scale multiple-particle tracking problems of interest here.
",6.1. Related machine learning work,[0],[0]
"Finally, our work is an example of a broad theme in the current image processing literature: start with “ground truth” images, then simulate observed data that can be generated as some kind of corruption of this ground truth, and then use this simulated data to train a neural network that can “denoise” (or super-resolve, or deblur, or infill, etc.)",6.1. Related machine learning work,[0],[0]
this corruption.,6.1. Related machine learning work,[0],[0]
"A (highly non-exhaustive) list of recent examples includes: (Parthasarathy et al., 2017), which applies this idea to approximate Bayesian decoding of neuronal spike train data; (Yoon et al., 2017), to segmentation of threedimensional neuronal images; and (Weigert et al., 2017), to denoising of microscopy images.",6.1. Related machine learning work,[0],[0]
"At test time, as emphasized above, the inference approach proposed here is highly scalable, but the network training time is relatively slow (taking on the order of hours for the experiments presented here).",6.2. Future work,[0],[0]
This is typical of “amortized inference” approaches: we pay with relatively long training times for fast test times.,6.2. Future work,[0],[0]
"Thus our proposed approach is most valuable in settings where we have repeated experimental samples from a similar data regime (instead of training a new inference network for each new experimental dataset).
",6.2. Future work,[0],[0]
"We have not expended serious effort optimizing over network architectures here; we could likely find lighter architectures that perform similarly, which would speed up both testing and training.",6.2. Future work,[0],[0]
"Similarly, we could distill/compress the network to further speed up test times, if necessary e.g. for online experimental designs.
",6.2. Future work,[0],[0]
"Similarly, we have not yet attempted to develop automated procedures for choosing parameters for generating training data.",6.2. Future work,[0],[0]
"In practice we have found that these parameters (e.g., the amplitude, density, variance/speed of particles, plus noise levels, point-spread width, etc.) are fairly straightforward to choose, and the inference results are not highly sensitive to small misspecifications of these parameters (recall Figure 4 and the corresponding comparison video).",6.2. Future work,[0],[0]
"It would be useful to develop a simple interface that would allow experimentalists to easily generate training data, followed by generation of a network trained to perform inference on their data.
",6.2. Future work,[0],[0]
An alternative approach would be to include data parameters as extra inputs for the network.,6.2. Future work,[0],[0]
Then in principle there would be no need to train a new network for each new type of data; instead we could perhaps just train a single big network on many different data types (with the corresponding data parameters included as inputs to the network) and then when presented with a new datatype we just provide the network with the required parameters and let it perform inference.,6.2. Future work,[0],[0]
"This is an ambitious but important direction for future work3.
3Note that a slightly different philosophy is espoused in (Newby et al., 2017), who trained a single deterministic network for particle detection that can be applied to a wide range of data, but without including any parameters describing the data generation mechanism as inputs to the network.",6.2. Future work,[0],[0]
"This approach makes it easy for experimentalists to use the network (since no training or parameter estimation is required), but likely sacrifices some accuracy compared to a network that is provided information about the parameters governing the generation of the data.",6.2. Future work,[0],[0]
We hope to run more detailed comparisons of these approaches in the future.,6.2. Future work,[0],[0]
"This work was funded by Army Research Office W911NF12-1-0594 (MURI), the Simons Foundation Collaboration on the Global Brain, and by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DoI/IBC) contract number D16PC00008.",Acknowledgements,[0],[0]
"The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.",Acknowledgements,[0],[0]
"Many important datasets in physics, chemistry, and biology consist of noisy sequences of images of multiple moving overlapping particles.",abstractText,[0],[0]
"In many cases, the observed particles are indistinguishable, leading to unavoidable uncertainty about nearby particles’ identities.",abstractText,[0],[0]
"Exact Bayesian inference is intractable in this setting, and previous approximate Bayesian methods scale poorly.",abstractText,[0],[0]
Non-Bayesian approaches that output a single “best” estimate of the particle tracks (thus discarding important uncertainty information) are therefore dominant in practice.,abstractText,[0],[0]
Here we propose a flexible and scalable amortized approach for Bayesian inference on this task.,abstractText,[0],[0]
We introduce a novel neural network method to approximate the (intractable) filter-backward-sample-forward algorithm for Bayesian inference in this setting.,abstractText,[0],[0]
"By varying the simulated training data for the network, we can perform inference on a wide variety of data types.",abstractText,[0],[0]
"This approach is therefore highly flexible and improves on the state of the art in terms of accuracy; provides uncertainty estimates about the particle locations and identities; and has a test run-time that scales linearly as a function of the data length and number of particles, thus enabling Bayesian inference in arbitrarily large particle tracking datasets.",abstractText,[0],[0]
Scalable Approximate Bayesian Inference for Particle Tracking Data,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 321–331 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1030",text,[0],[0]
"Language modeling is a fundamental task, used for example to predict the next word or character in a text sequence given the context.",1 Introduction,[0],[0]
"Recently, recurrent neural networks (RNNs) have shown promising performance on this task (Mikolov et al., 2010; Sutskever et al., 2011).",1 Introduction,[0],[0]
"RNNs with Long Short-Term Memory (LSTM) units (Hochreiter and Schmidhuber, 1997) have emerged as a popular architecture, due to their representational power and effectiveness at capturing long-term dependencies.
",1 Introduction,[0],[0]
"RNNs are usually trained via back-propagation through time (Werbos, 1990), using stochastic op-
∗Equal contribution.",1 Introduction,[0],[0]
"†Corresponding author.
",1 Introduction,[0],[0]
"timization methods such as stochastic gradient descent (SGD) (Robbins and Monro, 1951); stochastic methods of this type are particularly important for training with large data sets.",1 Introduction,[0],[0]
"However, this approach often provides a maximum a posteriori (MAP) estimate of model parameters.",1 Introduction,[0],[0]
"The MAP solution is a single point estimate, ignoring weight uncertainty (Blundell et al., 2015; HernándezLobato and Adams, 2015).",1 Introduction,[0],[0]
"Natural language often exhibits significant variability, and hence such a point estimate may make over-confident predictions on test data.
",1 Introduction,[0],[0]
"To alleviate overfitting RNNs, good regularization is known as a key factor to successful applications.",1 Introduction,[0],[0]
"In the neural network literature, Bayesian learning has been proposed as a principled method to impose regularization and incorporate model uncertainty (MacKay, 1992; Neal, 1995), by imposing prior distributions on model parameters.",1 Introduction,[0],[0]
"Due to the intractability of posterior distributions in neural networks, Hamiltonian Monte Carlo (HMC) (Neal, 1995) has been used to provide sample-based approximations to the true posterior.",1 Introduction,[0],[0]
"Despite the elegant theoretical property of asymptotic convergence to the true posterior, HMC and other conventional Markov Chain Monte Carlo methods are not scalable to large training sets.
",1 Introduction,[0],[0]
"This paper seeks to scale up Bayesian learning of RNNs to meet the challenge of the increasing amount of “big” sequential data in natural language processing, leveraging recent advances in stochastic gradient Markov Chain Monte Carlo (SG-MCMC) algorithms (Welling and Teh, 2011; Chen et al., 2014; Ding et al., 2014; Li et al., 2016a,b).",1 Introduction,[0],[0]
"Specifically, instead of training a single network, SG-MCMC is employed to train an ensemble of networks, where each network has its parameters drawn from a shared posterior distribution.",1 Introduction,[0],[0]
"This is implemented by adding additional
321
gradient noise during training and utilizing model averaging when testing.
",1 Introduction,[0],[0]
"This simple procedure has the following salutary properties for training neural networks: (i) When training, the injected noise encourages model-parameter trajectories to better explore the parameter space.",1 Introduction,[0],[0]
This procedure was also empirically found effective in Neelakantan et al. (2016).,1 Introduction,[0],[0]
"(ii) Model averaging when testing alleviates overfitting and hence improves generalization, transferring uncertainty in the learned model parameters to subsequent prediction.",1 Introduction,[0],[0]
"(iii) In theory, both asymptotic and non-asymptotic consistency properties of SG-MCMC methods in posterior estimation have been recently established to guarantee convergence (Chen et al., 2015a; Teh et al., 2016).",1 Introduction,[0],[0]
"(iv) SG-MCMC is scalable; it shares the same level of computational cost as SGD in training, by only requiring the evaluation of gradients on a small mini-batch.",1 Introduction,[0],[0]
"To the authors’ knowledge, RNN training using SG-MCMC has not been investigated previously, and is a contribution of this paper.",1 Introduction,[0],[0]
"We also perform extensive experiments on several natural language processing tasks, demonstrating the effectiveness of SG-MCMC for RNNs, including character/word-level language modeling, image captioning and sentence classification.",1 Introduction,[0],[0]
Several scalable Bayesian learning methods have been proposed recently for neural networks.,2 Related Work,[0],[0]
"These come in two broad categories: stochastic variational inference (Graves, 2011; Blundell et al., 2015; Hernández-Lobato and Adams, 2015) and
SG-MCMC methods (Korattikara et al., 2015; Li et al., 2016a).",2 Related Work,[0],[0]
"While prior work focuses on feed-forward neural networks, there has been little if any research reported for RNNs using SGMCMC.
",2 Related Work,[0],[0]
"Dropout (Hinton et al., 2012; Srivastava et al., 2014) is a commonly used regularization method for training neural networks.",2 Related Work,[0],[0]
"Recently, several works have studied how to apply dropout to RNNs (Pachitariu and Sahani, 2013; Bayer et al., 2013; Pham et al., 2014; Zaremba et al., 2014; Bluche et al., 2015; Moon et al., 2015; Semeniuta et al., 2016; Gal and Ghahramani, 2016b).",2 Related Work,[0],[0]
"Among them, naive dropout (Zaremba et al., 2014) can impose weight uncertainty only on encoding weights (those that connect input to hidden units) and decoding weights (those that connect hidden units to output), but not the recurrent weights (those that connect consecutive hidden states).",2 Related Work,[0],[0]
"It has been concluded that noise added in the recurrent connections leads to model instabilities, hence disrupting the RNN’s ability to model sequences.
",2 Related Work,[0],[0]
"Dropout has been recently shown to be a variational approximation technique in Bayesian learning (Gal and Ghahramani, 2016a; Kingma et al., 2015).",2 Related Work,[0],[0]
"Based on this, (Gal and Ghahramani, 2016b) proposed a new variant of dropout that can be successfully applied to recurrent layers, where the same dropout masks are shared along time for encoding, decoding and recurrent weights, respectively.",2 Related Work,[0],[0]
"Alternatively, we focus on SG-MCMC, which can be viewed as the Bayesian interpretation of dropout from the perspective of posterior sampling (Li et al., 2016c); this also allows imposition of model uncertainty on recurrent layers, enhancing performance.",2 Related Work,[0],[0]
A comparison of naive dropout and SG-MCMC is illustrated in Fig. 1.,2 Related Work,[0],[0]
"Consider data D = {D1, · · · ,DN}, where Dn , (Xn,Yn), with input Xn and output Yn.",3.1 RNN as Bayesian Predictive Models,[0],[0]
"Our goal is to learn model parameters θ to best characterize the relationship from Xn to Yn, with corresponding data likelihood p(D|θ) =∏N n=1 p(Dn|θ).",3.1 RNN as Bayesian Predictive Models,[0],[0]
"In Bayesian statistics, one sets a prior on θ via distribution p(θ).",3.1 RNN as Bayesian Predictive Models,[0],[0]
The posterior p(θ|D) ∝ p(θ)p(D|θ) reflects the belief concerning the model parameter distribution after observing the data.,3.1 RNN as Bayesian Predictive Models,[0],[0]
"Given a test input X̃ (with missing output Ỹ), the uncertainty learned in training
is transferred to prediction, yielding the posterior predictive distribution:
p(Ỹ|X̃,D)= ∫
θ p(Ỹ|X̃,θ)p(θ|D)dθ .",3.1 RNN as Bayesian Predictive Models,[0],[0]
"(1)
When the input is a sequence, RNNs may be used to parameterize the input-output relationship.",3.1 RNN as Bayesian Predictive Models,[0],[0]
"Specifically, consider input sequence X = {x1, . . .",3.1 RNN as Bayesian Predictive Models,[0],[0]
",xT }, where xt is the input data vector at time t.",3.1 RNN as Bayesian Predictive Models,[0],[0]
"There is a corresponding hidden state vector ht at each time t, obtained by recursively applying the transition function ht = H(ht−1,xt) (specified in Section 3.2; see Fig. 1).",3.1 RNN as Bayesian Predictive Models,[0],[0]
"The output Y differs depending on the application: a sequence {y1, . . .",3.1 RNN as Bayesian Predictive Models,[0],[0]
",yT } in language modeling or a discrete label in sentence classification.",3.1 RNN as Bayesian Predictive Models,[0],[0]
"In RNNs the corresponding decoding function is p(y|h), described in Section 3.3.",3.1 RNN as Bayesian Predictive Models,[0],[0]
"The transition function H(·) can be implemented with a gated activation function, such as Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) or a Gated Recurrent Unit (GRU) (Cho et al., 2014).",3.2 RNN Architectures,[0],[0]
"Both the LSTM and GRU have been proposed to address the issue of learning long-term sequential dependencies.
",3.2 RNN Architectures,[0],[0]
"Long Short-Term Memory The LSTM architecture addresses the problem of learning longterm dependencies by introducing a memory cell, that is able to preserve the state over long periods of time.",3.2 RNN Architectures,[0],[0]
"Specifically, each LSTM unit has a cell containing a state ct at time t. This cell can be viewed as a memory unit.",3.2 RNN Architectures,[0],[0]
"Reading or writing the cell is controlled through sigmoid gates: input gate it, forget gate ft, and output gate ot.",3.2 RNN Architectures,[0],[0]
"The hidden units ht are updated as
it = σ(Wixt +Uiht−1 + bi) ,
ft = σ(Wfxt",3.2 RNN Architectures,[0],[0]
"+Ufht−1 + bf ) ,
ot = σ(Woxt",3.2 RNN Architectures,[0],[0]
"+Uoht−1 + bo) ,
",3.2 RNN Architectures,[0],[0]
"c̃t = tanh(Wcxt +Ucht−1 + bc) ,
ct = ft ct−1 + it c̃t , ht = ot tanh(ct) ,
where σ(·) denotes the logistic sigmoid function, and represents the element-wise matrix multiplication operator.",3.2 RNN Architectures,[0],[0]
"W{i,f,o,c} are encoding weights, and U{i,f,o,c} are recurrent weights, as shown in Fig. 1.",3.2 RNN Architectures,[0],[0]
"b{i,f,o,c} are bias terms.
",3.2 RNN Architectures,[0],[0]
"Variants Similar to the LSTM unit, the GRU also has gating units that modulate the flow of information inside the hidden unit.",3.2 RNN Architectures,[0],[0]
"It has been shown that a GRU can achieve similar performance to an LSTM in sequence modeling (Chung et al., 2014).",3.2 RNN Architectures,[0],[0]
"We specify the GRU in the Supplementary Material.
",3.2 RNN Architectures,[0],[0]
The LSTM can be extended to the bidirectional LSTM and multilayer LSTM.,3.2 RNN Architectures,[0],[0]
A bidirectional LSTM consists of two LSTMs that are run in parallel: one on the input sequence and the other on the reverse of the input sequence.,3.2 RNN Architectures,[0],[0]
"At each time step, the hidden state of the bidirectional LSTM is the concatenation of the forward and backward hidden states.",3.2 RNN Architectures,[0],[0]
"In multilayer LSTMs, the hidden state of an LSTM unit in layer ` is used as input to the LSTM unit in layer `",3.2 RNN Architectures,[0],[0]
"+ 1 at the same time step (Graves, 2013).",3.2 RNN Architectures,[0],[0]
"The proposed Bayesian framework can be applied to any RNN model; we focus on the following tasks to demonstrate the ideas.
",3.3 Applications,[0],[0]
"Language Modeling In word-level language modeling, the input to the network is a sequence of words, and the network is trained to predict the next word in the sequence with a softmax classifier.",3.3 Applications,[0],[0]
"Specifically, for a length-T sequence, denote yt = xt+1 for t = 1, . . .",3.3 Applications,[0],[0]
", T − 1.",3.3 Applications,[0],[0]
"x1 and yT are always set to a special START and END token, respectively.",3.3 Applications,[0],[0]
"At each time t, there is a decoding function p(yt|ht) = softmax(Vht) to compute the distribution over words, where V are the decoding weights (the number of rows of V corresponds to the number of words/characters).",3.3 Applications,[0],[0]
"We also extend this basic language model to consider other applications: (i) a character-level language model can be specified in a similar manner by replacing words with characters (Karpathy et al., 2016).",3.3 Applications,[0],[0]
"(ii) Image captioning can be considered as a conditional language modeling problem, in which we learn a generative language model of the caption conditioned on an image (Vinyals et al., 2015; Gan et al., 2017).
",3.3 Applications,[0],[0]
Sentence Classification Sentence classification aims to assign a semantic category label y to a whole sentence X.,3.3 Applications,[0],[0]
This is usually implemented through applying the decoding function once at the end of sequence: p(y|hT ) =,3.3 Applications,[0],[0]
"softmax(VhT ), where the final hidden state of a RNN hT is often considered as the summary of the sentence (here
the number of rows of V corresponds to the number of classes).",3.3 Applications,[0],[0]
"Typically there is no closed-form solution for the posterior p(θ|D), and traditional Markov Chain Monte Carlo (MCMC) methods (Neal, 1995) scale poorly for largeN .",4.1 The Pitfall of Stochastic Optimization,[0],[0]
"To ease the computational burden, stochastic optimization is often employed to find the MAP solution.",4.1 The Pitfall of Stochastic Optimization,[0],[0]
"This is equivalent to minimizing an objective of regularized loss function U(θ) that corresponds to a (non-convex) model of interest: θMAP = argminU(θ), U(θ) =",4.1 The Pitfall of Stochastic Optimization,[0],[0]
− log p(θ|D).,4.1 The Pitfall of Stochastic Optimization,[0],[0]
"The expectation in (1) is approximated as:
p(Ỹ|X̃,D)= p(Ỹ|X̃,θMAP) .",4.1 The Pitfall of Stochastic Optimization,[0],[0]
"(2)
Though simple and effective, this procedure largely loses the benefit of the Bayesian approach, because the uncertainty on weights is ignored.",4.1 The Pitfall of Stochastic Optimization,[0],[0]
"To more accurately approximate (1), we employ stochastic gradient (SG) MCMC (Welling and Teh, 2011).",4.1 The Pitfall of Stochastic Optimization,[0],[0]
"The negative log-posterior is
U(θ) , − log p(θ)− N∑
n=1
log p(Dn|θ).",4.2 Large-scale Bayesian Learning,[0],[0]
"(3)
In optimization,E = −∑Nn=1 log p(Dn|θ) is typically referred to as the loss function, and R ∝",4.2 Large-scale Bayesian Learning,[0],[0]
"− log p(θ) as a regularizer.
",4.2 Large-scale Bayesian Learning,[0],[0]
"For large N , stochastic approximations are often employed:
Ũt(θ),− log p(θ)− N
M
M∑
m=1
log p(Dim |θ), (4)
where Sm = {i1, · · · , iM} is a random subset of the set {1, 2, · · · , N}, with M N .",4.2 Large-scale Bayesian Learning,[0],[0]
"The gradient on this mini-batch is denoted as f̃t = ∇Ũt(θ), which is an unbiased estimate of the true gradient.",4.2 Large-scale Bayesian Learning,[0],[0]
"The evaluation of (4) is cheap even when N is large, allowing one to efficiently collect a sufficient number of samples in large-scale Bayesian learning, {θs}Ss=1, where S is the number of samples (this will be specified later).",4.2 Large-scale Bayesian Learning,[0],[0]
"These samples are used to construct a sample-based estimation to the expectation in (1):
The finite-time estimation errors of SG-MCMC methods are bounded (Chen et al., 2015a), which guarantees (5) is an unbiased estimate of (1) asymptotically under appropriate decreasing stepsizes.",4.2 Large-scale Bayesian Learning,[0],[0]
"SG-MCMC and stochastic optimization are parallel lines of work, designed for different purposes; their relationship has recently been revealed in the context of deep learning.",4.3 SG-MCMC Algorithms,[0],[0]
"The most basic SG-MCMC algorithm has been applied to Langevin dynamics, and is termed SGLD (Welling and Teh, 2011).",4.3 SG-MCMC Algorithms,[0],[0]
"To help convergence, a momentum term has been introduced in SGHMC (Chen et al., 2014), a “thermostat” has been devised in SGNHT (Ding et al., 2014; Gan et al., 2015) and preconditioners have been employed in pSGLD (Li et al., 2016a).",4.3 SG-MCMC Algorithms,[0],[0]
"These SG-MCMC algorithms often share similar characteristics with their counterpart approaches from the optimization literature such as the momentum SGD, Santa (Chen et al., 2016) and RMSprop/Adagrad (Tieleman and Hinton, 2012; Duchi et al., 2011).",4.3 SG-MCMC Algorithms,[0],[0]
"The interrelationships between SG-MCMC and optimizationbased approaches are summarized in Table 1.
",4.3 SG-MCMC Algorithms,[0],[0]
"SGLD Stochastic Gradient Langevin Dynamics (SGLD) (Welling and Teh, 2011) draws posterior samples, with updates
θt = θt−1 − ηtf̃t−1 + √ 2ηtξt , (6)
where ηt is the learning rate, and ξt ∼ N (0, Ip) is a standard Gaussian random vector.",4.3 SG-MCMC Algorithms,[0],[0]
"SGLD is the SG-MCMC analog to stochastic gradient descent (SGD), whose parameter updates are given by:
θt = θt−1 − ηtf̃t−1 .",4.3 SG-MCMC Algorithms,[0],[0]
"(7)
Algorithm 1:",4.3 SG-MCMC Algorithms,[0],[0]
"pSGLD Input: Default hyperparameter settings:
ηt = 1×10−3, λ = 10−8, β1 = 0.99.",4.3 SG-MCMC Algorithms,[0],[0]
"Initialize: v0 ← 0, θ1 ∼ N (0, I) ; for t = 1, 2, . . .",4.3 SG-MCMC Algorithms,[0],[0]
", T do
% Estimate gradient from minibatch St f̃t = ∇Ũt(θ);",4.3 SG-MCMC Algorithms,[0],[0]
"% Preconditioning vt ← β1vt−1 + (1− β1)f̃t f̃t; G−1t ← diag ( 1 ( λ1+ v 1 2 t )) ;
% Parameter update ξt ∼ N",4.3 SG-MCMC Algorithms,[0],[0]
"(0, ηtG−1t ); θt+1← θt + ηt2",4.3 SG-MCMC Algorithms,[0],[0]
"G−1t f̃t+ ξt;
end
SGD is guaranteed to converge to a local minimum under mild conditions (Bottou, 2010).",4.3 SG-MCMC Algorithms,[0],[0]
"The additional Gaussian term in SGLD helps the learning trajectory to explore the parameter space to approximate posterior samples, instead of obtaining a local minimum.
",4.3 SG-MCMC Algorithms,[0],[0]
"pSGLD Preconditioned SGLD (pSGLD) (Li et al., 2016a) was proposed recently to improve the mixing of SGLD.",4.3 SG-MCMC Algorithms,[0],[0]
"It utilizes magnitudes of recent gradients to construct a diagonal preconditioner to approximate the Fisher information matrix, and thus adjusts to the local geometry of parameter space by equalizing the gradients so that a constant stepsize is adequate for all dimensions.",4.3 SG-MCMC Algorithms,[0],[0]
"This is important for RNNs, whose parameter space often exhibits pathological curvature and saddle points (Pascanu et al., 2013), resulting in slow mixing.",4.3 SG-MCMC Algorithms,[0],[0]
"There are multiple choices of preconditioners; similar ideas in optimization include Adagrad (Duchi et al., 2011), Adam (Kingma and Ba, 2015) and RMSprop (Tieleman and Hinton, 2012).",4.3 SG-MCMC Algorithms,[0],[0]
"An efficient version of pSGLD, adopting RMSprop as the preconditioner G, is summarized in Algorithm 1, where denotes elementwise matrix division.",4.3 SG-MCMC Algorithms,[0],[0]
"When the preconditioner is fixed as the identity matrix, the method reduces to SGLD.",4.3 SG-MCMC Algorithms,[0],[0]
"To further understand SG-MCMC, we show its close connection to dropout/dropConnect (Srivastava et al., 2014; Wan et al., 2013).",4.4 Understanding SG-MCMC,[0],[0]
"These methods improve the generalization ability of deep models, by randomly adding binary/Gaussian noise to the
local units or global weights.",4.4 Understanding SG-MCMC,[0],[0]
"For neural networks with the nonlinear function q(·) and consecutive layers h1 and h2, dropout and dropConnect are denoted as:
Dropout: h2 = ξ0 q(θh1), DropConnect: h2 = q((ξ0 θ)h1),
where the injected noise ξ0 can be binary-valued with dropping rate p or its equivalent Gaussian form (Wang and Manning, 2013):
Binary noise: ξ0 ∼ Ber(p), Gaussian noise: ξ0 ∼ N (1, p
1− p).
",4.4 Understanding SG-MCMC,[0],[0]
"Note that ξ0 is defined as a vector for dropout, and a matrix for dropConnect.",4.4 Understanding SG-MCMC,[0],[0]
"By combining dropConnect and Gaussian noise from the above, we have the update rule (Li et al., 2016c):
θt+1 = ξ0 θt",4.4 Understanding SG-MCMC,[0],[0]
"− η
2 f̃t = θt −
",4.4 Understanding SG-MCMC,[0],[0]
"η 2 f̃t + ξ ′ 0 , (8)
where ξ′0 ∼ N ( 0, p(1−p)diag(θ 2 t ) )
",4.4 Understanding SG-MCMC,[0],[0]
"; (8) shows that dropout/ dropConnect and SGLD in (6) share the same form of update rule, with the distinction being that the level of injected noise is different.",4.4 Understanding SG-MCMC,[0],[0]
"In practice, the noise injected by SGLD may not be enough.",4.4 Understanding SG-MCMC,[0],[0]
A better way that we find to improve the performance is to jointly apply SGLD and dropout.,4.4 Understanding SG-MCMC,[0],[0]
"This method can be interpreted as using SGLD to sample the posterior distribution of a mixture of RNNs, with mixture probability controlled by the dropout rate.",4.4 Understanding SG-MCMC,[0],[0]
"We present results on several tasks, including character/word-level language modeling, image captioning, and sentence classification.",5 Experiments,[0],[0]
We do not perform any dataset-specific tuning other than early stopping on validation sets.,5 Experiments,[0],[0]
"When dropout is utilized, the dropout rate is set to 0.5.",5 Experiments,[0],[0]
"All experiments are implemented in Theano (Theano Development Team, 2016), using a NVIDIA GeForce GTX TITAN X GPU with 12GB memory.
",5 Experiments,[0],[0]
"The hyper-parameters for the proposed algorithm include step size, minibatch size, thinning interval, number of burn-in epochs and variance of the Gaussian priors.",5 Experiments,[0],[0]
We list the specific values used in our experiments in Table 2.,5 Experiments,[0],[0]
"The explanation of these hyperparameters, the initialization of model parameters and model specifications on each dataset are provided in the Supplementary Material.",5 Experiments,[0],[0]
We first test character-level and word-level language modeling.,5.1 Language Modeling,[0],[0]
"The setup is as follows.
",5.1 Language Modeling,[0],[0]
"• Following Karpathy et al. (2016), we test character-level language modeling on the War and Peace (WP) novel.",5.1 Language Modeling,[0],[0]
"The training/validation/test sets contain 260/32/33 batches, in which there are 100 characters.",5.1 Language Modeling,[0],[0]
"The vocabulary size is 87, and we consider a 2-hidden-layer RNN of dimension 128.",5.1 Language Modeling,[0],[0]
"• The Penn Treebank (PTB) corpus (Marcus
et al., 1993) is used for word-level language modeling.",5.1 Language Modeling,[0],[0]
"The dataset adopts the standard split (929K training words, 73K validation words, and 82K test words) and has a vocabulary of size 10K. We train LSTMs of three sizes; these are denoted the small/medium/large LSTM.",5.1 Language Modeling,[0],[0]
All LSTMs have two layers and are unrolled for 20 steps.,5.1 Language Modeling,[0],[0]
"The small, medium and large LSTM has 200, 650 and 1500 units per layer, respectively.
",5.1 Language Modeling,[0],[0]
We consider two types of training schemes on PTB corpus: (i) Successive minibatches:,5.1 Language Modeling,[0],[0]
"Following Zaremba et al. (2014), the final hidden states of the current minibatch are used as the initial hidden states of the subsequent minibatch (successive minibatches sequentially traverse the training set).",5.1 Language Modeling,[0],[0]
"(ii) Random minibatches: The initial hidden states of each minibatch are set to zero vectors, hence we can randomly sample minibatches in each update.
",5.1 Language Modeling,[0],[0]
"We study the effects of different types of architecture (LSTM/GRU/Vanilla RNN (Karpathy et al., 2016)) on the WP dataset, and effects of different learning algorithms on the PTB dataset.",5.1 Language Modeling,[0],[0]
The comparison of test cross-entropy loss on WP is shown in Table 3.,5.1 Language Modeling,[0],[0]
We observe that pSGLD consistently outperforms RMSprop.,5.1 Language Modeling,[0],[0]
Table 4 summarizes the test set performance on PTB1.,5.1 Language Modeling,[0],[0]
"It is clear
1The results reported here do not match Zaremba et al. (2014) due to the implementation details.",5.1 Language Modeling,[0],[0]
"However, we pro-
that our sampling-based method consistently outperforms the optimization counterpart, where the performance gain mainly comes from adding gradient noise and model averaging.",5.1 Language Modeling,[0],[0]
"When compared with dropout, SGLD performs better on the small LSTM model, but worse on the medium and large LSTM model.",5.1 Language Modeling,[0],[0]
"This may imply that dropout is suitable to regularizing large networks, while SGLD exhibits better regularization ability on small networks, partially due to the fact that dropout may inject a higher level of noise during training than SGLD.",5.1 Language Modeling,[0],[0]
"In order to inject a higher level of noise into SGLD, we empirically apply SGLD and dropout jointly, and found that this provided the best performace on the medium and large LSTM model.
",5.1 Language Modeling,[0],[0]
"We study three strategies to do model averaging, i.e., forward collection, backward collection and thinned collection.",5.1 Language Modeling,[0],[0]
"Given samples (θ1, · · · ,θK) and the number of samples S used for averaging, forward collection refers to using (θ1, · · · ,θS) for the evaluation of a test function, backward collection refers to using (θK−S+1, · · · ,θK), while thinned collection chooses samples from θ1 to θK with interval K/S. Fig. 2 plots the effects of these strategies, where Fig. 2(a) plots the perplexity of every single sample, Fig. 2(b) plots the perplexities using the three schemes.",5.1 Language Modeling,[0],[0]
"Only after 20
vide a fair comparison to all methods.
samples is a converged perplexity achieved in the thinned collection, while it requires 30 samples for forward collection or 60 samples for backward collection.",5.1 Language Modeling,[0],[0]
"This is unsurprising, because thinned collection provides a better way to select samples.",5.1 Language Modeling,[0],[0]
"Nevertheless, averaging of samples provides significantly lower perplexity than using single samples.",5.1 Language Modeling,[0],[0]
"Note that the overfitting problem in Fig. 2(a) is also alleviated by model averaging.
",5.1 Language Modeling,[0],[0]
"To better illustrate the benefit of model averaging, we visualize in Fig. 3 the probabilities of each word in a randomly chosen test sentence.",5.1 Language Modeling,[0],[0]
"The first 3 rows are the results predicted by 3 distinctive model samples, respectively; the bottom row is the result after averaging.",5.1 Language Modeling,[0],[0]
Their corresponding perplexities for the test sentence are also shown on the right of each row.,5.1 Language Modeling,[0],[0]
The 3 individual samples provide reasonable probabilities.,5.1 Language Modeling,[0],[0]
"For example, the consecutive words “New York”, “stock exchange” and “did not” are assigned with a higher probability.",5.1 Language Modeling,[0],[0]
"After averaging, we can see a much lower perplexity, as the samples can complement each other.",5.1 Language Modeling,[0],[0]
"For example, though the second sample can yield the lowest single-model perplexity, its prediction on word “York” is still benefited from the other two via averaging.",5.1 Language Modeling,[0],[0]
"We next consider the problem of image caption generation, which is a conditional RNN model, where image features are extracted by residual network (He et al., 2016), and then fed into the RNN to generate the caption.",5.2 Image Caption Generation,[0],[0]
"We present results on two benchmark datasets, Flickr8k (Hodosh et al., 2013) and Flickr30k (Young et al., 2014).",5.2 Image Caption Generation,[0],[0]
"These
25.55the new york stock exchange did not fall apart 22.24the new york stock exchange did not fall apart 29.83the new york stock exchange did not fall apart
21.98the new york stock exchange did not fall apart 0
0.2
0.4
0.6
0.8
Figure 3: Predictive probabilities obtained by 3 samples and their average.",5.2 Image Caption Generation,[0],[0]
Colors indicate normalized probability of each word.,5.2 Image Caption Generation,[0],[0]
"Best viewed in color.
",5.2 Image Caption Generation,[0],[0]
"a""tan""dog""is""playing""in""the""grass a""tan""dog""is""playing""with""a""red""ball""in""the""grass a""tan""dog""with""a""red""collar""is""running""in""the""grass
a""yellow""dog""runs""through""the""grass a""yellow""dog""is""running""through""the""grass a""brown""dog""is""running""through""the""grass
a""group""of""people""stand""in""front""of""a""building a""group""of""people""stand""in""front""of""a""white""building a""group""of""people""stand""in""front""of""a""large""building
a""man""and""a""woman""walking""on""a""sidewalk",5.2 Image Caption Generation,[0],[0]
"a""man""and""a""woman""stand""on""a""balcony a""man""and""a""woman""standing""on""the""ground
Figure 4: Image captioning with different samples.",5.2 Image Caption Generation,[0],[0]
"Left are the given images, right are the corresponding captions.",5.2 Image Caption Generation,[0],[0]
"The captions in each box are from the same model sample.
",5.2 Image Caption Generation,[0],[0]
"datasets contain 8,000 and 31,000 images, respectively.",5.2 Image Caption Generation,[0],[0]
Each image is annotated with 5 sentences.,5.2 Image Caption Generation,[0],[0]
"A single-layer LSTM is employed with the number of hidden units set to 512.
",5.2 Image Caption Generation,[0],[0]
"The widely used BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), ROUGEL (Lin, 2004), and CIDEr-D (Vedantam et al., 2015) metrics are used to evaluate the performance.",5.2 Image Caption Generation,[0],[0]
"All the metrics are computed by using the code released by the COCO evaluation server (Chen et al., 2015b).
",5.2 Image Caption Generation,[0],[0]
"Table 5 presents results for pSGLD/RMSprop
Table 5: Performance on Flickr8k & Flickr30k:",5.2 Image Caption Generation,[0],[0]
"BLEU’s, METEOR, CIDEr, ROUGE-L and perplexity.
",5.2 Image Caption Generation,[0],[0]
Methods B-1 B-2 B-3 B-4 METEOR CIDEr ROUGE-L Perp.,5.2 Image Caption Generation,[0],[0]
Results on Flickr8k RMSprop 0.640 0.427 0.288 0.197 0.205 0.476 0.500 16.64 RMSprop + Dropout 0.647 0.444 0.305 0.209 0.208 0.514 0.510 15.72,5.2 Image Caption Generation,[0],[0]
"RMSprop + Gal’s Dropout 0.651 0.443 0.305 0.209 0.206 0.501 0.509 14.70 pSGLD 0.669 0.463 0.321 0.224 0.214 0.535 0.522 14.29 pSGLD + Dropout 0.656 0.450 0.309 0.211 0.209 0.512 0.512 14.26 Results on Flickr30k RMSprop 0.644 0.422 0.279 0.184 0.180 0.372 0.476 17.80 RMSprop + Dropout 0.656 0.435 0.295 0.200 0.185 0.396 0.481 18.05 RMSprop + Gal’s Dropout 0.636 0.429 0.290 0.197 0.190 0.408 0.480 17.27 pSGLD 0.657 0.438 0.300 0.206 0.192 0.421 0.490 15.61 pSGLD + Dropout 0.666 0.448 0.308 0.209 0.189 0.419 0.487 17.05
with or without dropout.",5.2 Image Caption Generation,[0],[0]
"In addition to (naive) dropout, we further compare pSGLD with the Gal’s dropout, recently proposed in Gal and Ghahramani (2016b), which is shown to be applicable to recurrent layers.",5.2 Image Caption Generation,[0],[0]
"Consistent with the results in the basic language modeling, pSGLD yields improved performance compared to RMSprop.",5.2 Image Caption Generation,[0],[0]
"For example, pSGLD provides 2.7 BLEU-4 score improvement over RMSprop on the Flickr8k dataset.",5.2 Image Caption Generation,[0],[0]
"By comparing pSGLD with RMSprop with dropout, we conclude that pSGLD exhibits better regularization ability than dropout on these two datasets.
",5.2 Image Caption Generation,[0],[0]
"Apart from modeling weight uncertainty, different samples from our algorithm may capture different aspects of the input image.",5.2 Image Caption Generation,[0],[0]
"An example with two images is shown in Fig. 4, where 2 randomly chosen model samples are considered for each image.",5.2 Image Caption Generation,[0],[0]
"For each model sample, the top 3 generated captions are presented.",5.2 Image Caption Generation,[0],[0]
"We use the beam search approach (Vinyals et al., 2015) to generate captions, with a beam of size 5.",5.2 Image Caption Generation,[0],[0]
"In Fig. 4, the two samples for the first image mainly differ in the color and activity of the dog, e.g., “tan” or “yellow”, “playing” or “running”, whereas for the second image, the two samples reflect different understanding of the image content.",5.2 Image Caption Generation,[0],[0]
"We study the task of sentence classification on 5 datasets as in Kiros et al. (2015): MR (Pang and Lee, 2005), CR (Hu and Liu, 2004), SUBJ (Pang and Lee, 2004), MPQA (Wiebe et al., 2005) and TREC (Li and Roth, 2002).",5.3 Sentence Classification,[0],[0]
A single-layer bidirectional LSTM is employed with the number of hidden units set to 400.,5.3 Sentence Classification,[0],[0]
"Table 6 shows the test-
5 10 15 #Epoch
0.00
0.05
0.10
0.15
0.20
0.25
Er ro
r
Train RMSprop RMSprop + Dropout pSGLD pSGLD +",5.3 Sentence Classification,[0],[0]
"Dropout
5 10 15 #Epoch
0.10
0.12
0.14
0.16
0.18
0.20
0.22
0.24
0.26
Er ro
r
Validation
5 10 15 #Epoch
0.10
0.15
0.20
",5.3 Sentence Classification,[0],[0]
"Er ro
r
Test
Figure 5:",5.3 Sentence Classification,[0],[0]
"Learning curves on TREC dataset.
",5.3 Sentence Classification,[0],[0]
ing classification errors.,5.3 Sentence Classification,[0],[0]
"10-fold cross-validation is used for evaluation on the first 4 datasets, while TREC has a pre-defined training/test split, and we run each algorithm 10 times on TREC.",5.3 Sentence Classification,[0],[0]
"The combination of pSGLD and dropout consistently provides the lowest errors.
",5.3 Sentence Classification,[0],[0]
"In the following, we focus on the analysis of TREC.",5.3 Sentence Classification,[0],[0]
"Each sentence of TREC is a question, and the goal is to decide which topic type the question is most related to: location, human, numeric, abbreviation, entity or description.",5.3 Sentence Classification,[0],[0]
"Fig. 5 plots the learning curves of different algorithms on the training, validation and testing sets of the TREC dataset.",5.3 Sentence Classification,[0],[0]
"pSGLD and dropout have similar behavior: they explore the parameter space during learning, and thus coverge slower than RMSprop on the training dataset.",5.3 Sentence Classification,[0],[0]
"However, the learned uncertainty alleviates overfitting and results in lower errors on the validation and testing datasets.
",5.3 Sentence Classification,[0],[0]
"To further study the Bayesian nature of the proposed approach, in Fig. 6 we choose two testing sentences with high uncertainty (i.e., standard derivation in prediction) from the TREC dataset.",5.3 Sentence Classification,[0],[0]
"Interestingly, after embedding to 2d-space with tSNE (Van der Maaten and Hinton, 2008), the two
Table 6: Sentence classification errors on five benchmark datasets.
Methods MR CR SUBJ MPQA TREC RMSprop 21.86±1.19 20.20±1.35 8.13±1.19 10.60±1.28 8.14±0.63 RMSprop + Dropout 20.52±0.99 19.57±1.79 7.24±0.86 10.66±0.74 7.48±0.47 RMSprop + Gal’s Dropout 20.22±1.12 19.29±1.93 7.52±1.17 10.59±1.12 7.34±0.66 pSGLD 20.36±0.85",5.3 Sentence Classification,[0],[0]
18.72±1.28,5.3 Sentence Classification,[0],[0]
7.00±0.89 10.54±0.99 7.48±0.82 pSGLD +,5.3 Sentence Classification,[0],[0]
"Dropout 19.33±1.10 18.18±1.32 6.61±1.06 10.22±0.89 6.88±0.65
sentences correspond to points lying on the boundary of different classes.",5.3 Sentence Classification,[0],[0]
We use 20 model samples to estimate the prediction mean and standard derivation on the true type and predicted type.,5.3 Sentence Classification,[0],[0]
"The classifier yields higher probability on the wrong types, associated with higher standard derivations.",5.3 Sentence Classification,[0],[0]
"One can leverage the uncertainty information to make decisions: either manually make a human judgement when uncertainty is high, or automatically choose the one with lower standard derivations when both types exhibits similar prediction means.",5.3 Sentence Classification,[0],[0]
A more rigorous usage of the uncertainty information is left as future work.,5.3 Sentence Classification,[0],[0]
Ablation Study We investigate the effectivenss of each module in the proposed algorithm in Table 7 on two datasets: TREC and PTB.,5.4 Discussion,[0],[0]
The small network size is used on PTB.,5.4 Discussion,[0],[0]
"Let M1 denote only gradient noise, and M2 denote only model averaging.",5.4 Discussion,[0],[0]
"As can be seen, The last sample in pSGLD (M1) does not necessarily bring better results than RMSprop, but the model averaging over the samples of pSGLD indeed provide better results than model averaging of RMSprop (M2).",5.4 Discussion,[0],[0]
"This indicates that both gradient noise and model averaging are crucial for good performance in pSGLD.
",5.4 Discussion,[0],[0]
Running Time We report the training and testing time for image captioning on the Flickr30k dataset in Table 8.,5.4 Discussion,[0],[0]
"For pSGLD, the extra cost in training comes from adding gradient noise, and the extra cost in testing comes from model averaging.",5.4 Discussion,[0],[0]
"However, the cost in model averaging can be alleviated via the distillation methods: learning a single neural network that approximates the results of either a large model or an ensemble of models (Korattikara et al., 2015; Kim and Rush, 2016; Kuncoro et al., 2016).",5.4 Discussion,[0],[0]
"The idea can be incorporated with our SG-MCMC technique to achieve the same goal, which we leave for our future work.",5.4 Discussion,[0],[0]
"We propose a scalable Bayesian learning framework using SG-MCMC, to model weight uncertainty in recurrent neural networks.",6 Conclusion,[0],[0]
"The learning framework is tested on several tasks, including language models, image caption generation and sentence classification.",6 Conclusion,[0],[0]
"Our algorithm outperforms stochastic optimization algorithms, indicating the importance of learning weight uncertainty in recurrent neural networks.",6 Conclusion,[0],[0]
"Our algorithm requires little additional computational overhead in training, and multiple times of forward-passing for model averaging in testing.
",6 Conclusion,[0],[0]
"Acknowledgments This research was supported by ARO, DARPA, DOE, NGA, ONR and NSF.",6 Conclusion,[0],[0]
We acknowledge Wenlin Wang for the code on language modeling experiment.,6 Conclusion,[0],[0]
Recurrent neural networks (RNNs) have shown promising performance for language modeling.,abstractText,[0],[0]
"However, traditional training of RNNs using back-propagation through time often suffers from overfitting.",abstractText,[0],[0]
One reason for this is that stochastic optimization (used for large training sets) does not provide good estimates of model uncertainty.,abstractText,[0],[0]
This paper leverages recent advances in stochastic gradient Markov Chain Monte Carlo (also appropriate for large training sets) to learn weight uncertainty in RNNs.,abstractText,[0],[0]
"It yields a principled Bayesian learning algorithm, adding gradient noise during training (enhancing exploration of the model-parameter space) and model averaging when testing.",abstractText,[0],[0]
Extensive experiments on various RNN models and across a broad range of applications demonstrate the superiority of the proposed approach relative to stochastic optimization.,abstractText,[0],[0]
Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling,title,[0],[0]
"Our goal is to build a competitor for decision tree and rule learning algorithms in terms of accuracy, interpretability, and computational speed.",1. Introduction,[0],[0]
"Decision trees are widely used, particularly in industry, because of their interpretability.",1. Introduction,[0],[0]
Their logical IF-THEN structure allows predictions to be explained to users.,1. Introduction,[0],[0]
"However, decision tree algorithms have the serious flaw that they are constructed using greedy splitting from the top down.",1. Introduction,[0],[0]
They also use greedy pruning of nodes.,1. Introduction,[0],[0]
"They do not globally optimize any function, instead they are composed entirely of local optimization heuristics.",1. Introduction,[0],[0]
"If the algorithm makes a mistake in the splitting near the
1Massachusetts Institute of Technology, Cambridge, Massachusetts, USA 2Duke University, Durham, North Carolina, USA 3Harvard University, Cambridge, Massachusetts, USA.",1. Introduction,[0],[0]
Correspondence to: Hongyu Yang,1. Introduction,[0],[0]
"<hongyuy@mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"top of the tree, it is difficult to undo it, and consequently the trees become long and uninterpretable, unless they are heavily pruned, in which case accuracy suffers.",1. Introduction,[0],[0]
"In general, decision tree algorithms are computationally tractable, not particularly accurate, and less sparse and interpretable than they could be.",1. Introduction,[0],[0]
"This leaves users with no good alternative if they desire an accurate yet sparse logical classifier.
",1. Introduction,[0],[0]
"Several important ingredients provide the underpinning for our method including:
(i) A principled objective, which is the posterior distribution for the Bayesian Rule List (BRL) model (see Letham et al., 2015).",1. Introduction,[0],[0]
We optimize this objective over rule lists.,1. Introduction,[0],[0]
"Our algorithm is called Scalable Bayesian Rule Lists (SBRL).
",1. Introduction,[0],[0]
(ii) A useful statistical approximation that narrows the search space.,1. Introduction,[0],[0]
We assume that each rule in the rule list contains (“captures”) a number of observations that is bounded below.,1. Introduction,[0],[0]
"Because of this approximation, the set of conditions defining each leaf is a frequent pattern.",1. Introduction,[0],[0]
This means the antecedents within the rule list are all frequent patterns.,1. Introduction,[0],[0]
All of the possible frequent patterns can be pre-mined from the dataset using one of the standard frequent pattern mining methods.,1. Introduction,[0],[0]
"This leaves us with a much smaller optimization problem: we optimize over the set of possible pre-mined antecedents and their order to create the rule list.
",1. Introduction,[0],[0]
(iii) High performance language libraries to achieve computational efficiency.,1. Introduction,[0],[0]
Optimization over rule lists is done through repeated low level computations.,1. Introduction,[0],[0]
"At every iteration, we make a change to the rule list and need to evaluate the new rule list on the data.",1. Introduction,[0],[0]
"High performance calculations (novel to this problem) speed up this evaluation.
",1. Introduction,[0],[0]
(iv) Computational reuse.,1. Introduction,[0],[0]
"When we evaluate a rule list on the data that has been modified from a previous rule list, we need only to change the evaluation of points below the change in the rule list.",1. Introduction,[0],[0]
"Thus we can reuse the computation above the change.
",1. Introduction,[0],[0]
"(v) Analytical bounds on BRL’s posterior that are tight enough to be used in practice for screening association
Through a series of controlled experiments, we show that SBRL is over two orders of magnitude faster than the previous best code for this problem.
",1. Introduction,[0],[0]
"For example, Table 1 presents a rule list that we learned for the UCI Mushroom dataset (see Bache & Lichman, 2013).",1. Introduction,[0],[0]
This rule list is a predictive model for whether a mushroom is edible.,1. Introduction,[0],[0]
It was created in about 9 seconds on a laptop and achieves perfect out-of-sample accuracy.,1. Introduction,[0],[0]
Scalable Bayesian Rule Lists maximizes the posterior distribution of the Bayesian Rule Lists algorithm.,2. Review of Bayesian Rule Lists,[0],[0]
"Our training set is {(xi, yi)}ni=1 where the xi ∈ X encode features, and yi are labels, which in our case are binary, either 0 or 1.",2. Review of Bayesian Rule Lists,[0],[0]
"A Bayesian rule list has the following form:
if x obeys a1 then y ∼ Binom(θ1), θ1 ∼ Beta(α+ N1) else if x obeys a2 then y ∼ Binom(θ2), θ2 ∼ Beta(α+ N2) ... else if x obeys am then y ∼ Binom(θm), θm ∼ Beta(α+ Nm) else y ∼ Binom(θ0), θ0 ∼ Beta(α+ N0).
",2. Review of Bayesian Rule Lists,[0],[0]
"Here, the antecedents {aj}mj=1 are conditions on the x’s that are either true or false, for instance, if x is a patient, aj is true when x’s age is above 60 years old and x has diabetes, otherwise false.",2. Review of Bayesian Rule Lists,[0],[0]
The vector α =,2. Review of Bayesian Rule Lists,[0],[0]
"[α1, α0] has a prior parameter for each of the two labels.",2. Review of Bayesian Rule Lists,[0],[0]
"Values α1 and α0 are prior parameters, in the sense that each rule’s prediction y ∼ Binomial(θj), and θj |α ∼ Beta(α).",2. Review of Bayesian Rule Lists,[0],[0]
"The notation Nj is the vector of counts, where Nj,l is the number of observations xi that satisfy condition aj but none of the previous
conditions a1, ..., aj−1, and that have label yi = l, where l is either 1 or 0.",2. Review of Bayesian Rule Lists,[0],[0]
Nj is added to the prior parameters α from the usual derivation of the posterior for the Beta-binomial.,2. Review of Bayesian Rule Lists,[0],[0]
"The default rule is at the bottom, which makes predictions for observations that are not satisfied by any of the conditions.",2. Review of Bayesian Rule Lists,[0],[0]
"When an observation satisfies condition aj but not a1, ..., aj−1 we say that the observation is captured by rule j. Formally:
Definition 1 Rule j captures observation i, denoted Captr(i)",2. Review of Bayesian Rule Lists,[0],[0]
"= j, when j = argmin j′ such that aj′(xi) =",2. Review of Bayesian Rule Lists,[0],[0]
"True.
",2. Review of Bayesian Rule Lists,[0],[0]
"Bayesian Rule Lists is an associative classification method, in the sense that the antecedents are first mined from the database, and then the set of rules and their order are learned.",2. Review of Bayesian Rule Lists,[0],[0]
"The rule mining step is fast, and there are fast parallel implementations available.",2. Review of Bayesian Rule Lists,[0],[0]
"Any frequent pattern mining method will suffice, since the method needs only to produce those conditions with sufficiently high support in the database.",2. Review of Bayesian Rule Lists,[0],[0]
"The support of antecedent aj is denoted supp(aj), which is the number of observations that obey condition aj .",2. Review of Bayesian Rule Lists,[0],[0]
"A condition is a conjunction of expressions “feature∈values,” e.g., age∈[40,50] and color=white.",2. Review of Bayesian Rule Lists,[0],[0]
"The hard part is learning the rule list, which is what this paper focuses on.",2. Review of Bayesian Rule Lists,[0],[0]
"It is an optimization over subsets of rules and their permutations.
",2. Review of Bayesian Rule Lists,[0],[0]
"The likelihood for the model discussed above is:
Likelihood = p(y|x, d, α) ∝",2. Review of Bayesian Rule Lists,[0],[0]
"∏m j=0 Γ(Nj,0+α0)Γ(Nj,1+α1) Γ(Nj,0+Nj,1+α0+α1) ,
where d denotes the rules in the list and their order, d = (m, {aj , θj}mj=0).",2. Review of Bayesian Rule Lists,[0],[0]
"Intuitively, one can see that having more of one class and less of the other class will make the likelihood larger.",2. Review of Bayesian Rule Lists,[0],[0]
"To see this, note that if Nj,0 is large and Nj,1 is small (or vice versa) the likelihood for rule j is large.
",2. Review of Bayesian Rule Lists,[0],[0]
We next discuss the prior.,2. Review of Bayesian Rule Lists,[0],[0]
"It has three terms, one governing the number of rules m in the list, one governing the size cj of each antecedent j, and one governing the choice of antecedent condition aj of rule j given its size.",2. Review of Bayesian Rule Lists,[0],[0]
"Specifically, cj is the cardinality of antecedent aj , also written |aj",2. Review of Bayesian Rule Lists,[0],[0]
"|, the number of conjunctive clauses in antecedent aj .",2. Review of Bayesian Rule Lists,[0],[0]
"E.g, if a is ‘x1=green’ and ‘x2<50’, this has cardinality 2.",2. Review of Bayesian Rule Lists,[0],[0]
"Notation a<j includes the antecedents before j in the rule list, if there are any, e.g. a<4 = {a1, a2, a3}.",2. Review of Bayesian Rule Lists,[0],[0]
c<j includes the cardinalities of the antecedents before j in the rule list.,2. Review of Bayesian Rule Lists,[0],[0]
Notation A is the set of pre-mined antecedents.,2. Review of Bayesian Rule Lists,[0],[0]
"The prior is:
p(d|A, λ, η) = p(m|A, λ) ∏m j=1 p(cj |c<j ,A, η)p(aj |a<j , cj ,A).
",2. Review of Bayesian Rule Lists,[0],[0]
The first term is the prior for the number of rules in the list.,2. Review of Bayesian Rule Lists,[0],[0]
"Here, the number of rules m is Poisson, truncated at the
total number of pre-selected antecedents:
p(m|A, λ) =",2. Review of Bayesian Rule Lists,[0],[0]
"(λ m/m!)∑|A|
j=0(λ j/j!)
, m = 0, . . .",2. Review of Bayesian Rule Lists,[0],[0]
", |A|,
where λ is a hyper-parameter.",2. Review of Bayesian Rule Lists,[0],[0]
The second term in the prior governs the number of conditions in each rule.,2. Review of Bayesian Rule Lists,[0],[0]
"The size of rule j is cj which is Poisson, truncated to remove values for which no rules are available with that cardinality:
p(cj |c<j ,A, η) =",2. Review of Bayesian Rule Lists,[0],[0]
(η cj /cj !),2. Review of Bayesian Rule Lists,[0],[0]
"∑
k∈Rj−1(c<j,A) (ηk/k!)
, cj ∈",2. Review of Bayesian Rule Lists,[0],[0]
"Rj−1(c<j ,A),
where Rj−1(c<j ,A) is the set of cardinalities available after removing the first j−1 rules, and η is a hyperparameter.",2. Review of Bayesian Rule Lists,[0],[0]
"The third term in the prior governs the choice of antecedent, given that we have determined its size through the second term.",2. Review of Bayesian Rule Lists,[0],[0]
"We have aj selected from a uniform distribution over antecedents in A of size cj , excluding those in a<j .
p(aj |a<j , cj ,A) ∝ 1, aj ∈ Qcj",2. Review of Bayesian Rule Lists,[0],[0]
= {a ∈,2. Review of Bayesian Rule Lists,[0],[0]
"A \ {a1, a2, ..., aj−1} : |a| = cj}.
",2. Review of Bayesian Rule Lists,[0],[0]
"As usual, the posterior is the likelihood times the prior.
",2. Review of Bayesian Rule Lists,[0],[0]
"p(d|x,y,A, α, λ, η) ∝",2. Review of Bayesian Rule Lists,[0],[0]
"p(y|x, d, α)p(d|A, λ, η).
",2. Review of Bayesian Rule Lists,[0],[0]
"This is the full model, and the posterior p(d|x,y,A, α, λ, η) is what we optimize to obtain the best rule lists.
",2. Review of Bayesian Rule Lists,[0],[0]
"The hyperparameter λ is chosen by the user to be the desired size of the rule list, and η is chosen as the desired number of terms in each rule.",2. Review of Bayesian Rule Lists,[0],[0]
"The parameters α0 and α1 are usually chosen to be 1 to avoid favoring one class label over another.
",2. Review of Bayesian Rule Lists,[0],[0]
"Given the prior parameters λ, η, and α, along with the set of pre-mined rulesA, the algorithm must select which rules from A to use, along with their order.",2. Review of Bayesian Rule Lists,[0],[0]
"We use an MCMC scheme: at each time t, we choose a neighboring rule list at random by adding, removing, or swapping rules, starting with the basic algorithm of Letham et al. (2015) as a starting point.",3. Representation,[0],[0]
"However, to optimize performance we use a more efficient rule list representation that is amenable to fast computation.
",3. Representation,[0],[0]
Expressing computation as bit vectors: The vast majority of the computational time spent constructing rule sets lies in determining which rules capture which observations in a particular rule ordering.,3. Representation,[0],[0]
"The naı̈ve implementation of these operations calls for various set operations – checking whether a set contains an element, adding an element to a set, and removing an element from a set.",3. Representation,[0],[0]
"However, set operations are typically slow, and hardware does little to help with efficiency.
",3. Representation,[0],[0]
"We convert all set operations to logical operations on bit vectors, for which hardware support is readily available.",3. Representation,[0],[0]
The bit vector representation is efficient in terms of both memory and computation.,3. Representation,[0],[0]
"Before beginning the algorithm, for each rule, we compute the bit vector representing the samples for which the rule generates a true value.",3. Representation,[0],[0]
"For a one million sample data set (or more precisely up to 1,048,576 observations) each rule carries with it a 128 KB vector (since a byte consists of 8 bits), which fits comfortably in most L2 caches.
",3. Representation,[0],[0]
"Representing intermediate state as bit vectors: For each rule list we consider, we maintain similarly sized vectors for each rule in the set indicating which (unique) rule in the set captures which observation.",3. Representation,[0],[0]
"Representing the rules and rule lists this way allows us to explore the rule list state space, reusing significant computation.",3. Representation,[0],[0]
"For example, consider a rule list containing n rules.",3. Representation,[0],[0]
Imagine that we wish to delete rule k from the set.,3. Representation,[0],[0]
The naı̈ve implementation recomputes the “captures” vector for every rule in the set.,3. Representation,[0],[0]
"Our implementation updates only rules j > k, using logical operators acting upon the rule list “captures” vector for k, and the rule’s “captures” vector for each rule j > k.",3. Representation,[0],[0]
"This shortens the run time of the algorithm in practice by approximately 50%.
",3. Representation,[0],[0]
A fast algebra for computational reuse: Our use of bit vectors transforms the large number of set operations (performed in a traditional implementation) into a set of boolean operations on bit vectors.,3. Representation,[0],[0]
"We have custom implementations (discussed in the full version of this work, Yang et al., 2017) for the following: (i) Remove rule k uses boolean operations on bit vectors to redistribute the observations captured by rule k to the rules below it in the list.",3. Representation,[0],[0]
"(ii) Insert rule k shifts the rules below k down one position, determines which observations are captured by the new rule, and removes those observations from the rules below it.",3. Representation,[0],[0]
(iii) Swap consecutive rules updates only which observations were captured for the two swapped rules.,3. Representation,[0],[0]
(iv) Generalized swap subroutine updates only observations captured for all rules between the two rules to be swapped.,3. Representation,[0],[0]
"All operations use only bit vector computations.
",3. Representation,[0],[0]
"Ablation study: Having transformed expensive set operations into bit vector operations, we can now leverage both hardware vector instructions and optimized software libraries.",3. Representation,[0],[0]
"We investigated four alternative implementations, each improving efficiency from the previous one.",3. Representation,[0],[0]
(i),3. Representation,[0],[0]
"First, we have the original python implementation here for comparison.",3. Representation,[0],[0]
(ii),3. Representation,[0],[0]
"Next, we retained our python implementation but converted from set operations to bit operations.",3. Representation,[0],[0]
"(iii) Then, we used the python gmpy library to perform the bit operations.",3. Representation,[0],[0]
"(iv) Finally, we moved the implementation from Python to C, represented the bit vectors as multiprecision integers, used the GMP library, which is faster on
large data sets, and implemented the algebra for computational reuse outlined above.",3. Representation,[0],[0]
"To evaluate how each of these steps improved the computation time of the algorithm, we conducted a controlled experiment where each version of the algorithm (corresponding to the four steps above) was given the same data (the UCI adult dataset, divided into three folds), same set of rules, and same number of MCMC iterations (20,000) to run.",3. Representation,[0],[0]
"We created boxplots for the log10 of the run time over the different folds, which are shown in Figure 1.",3. Representation,[0],[0]
"The final code is over two orders of magnitude faster than the original optimized python code (that of Letham et al., 2015).",3. Representation,[0],[0]
We prove two bounds.,4. Bounds,[0],[0]
First we provide an upper bound on the number of rules in a maximum a posteriori rule list.,4. Bounds,[0],[0]
This allows us to narrow our search space to rule lists below a certain size.,4. Bounds,[0],[0]
Second we provide a constraint that eliminates certain prefixes of rule lists.,4. Bounds,[0],[0]
This prevents our algorithm from searching in regions of the space that provably do not contain the maximum a posteriori rule list.,4. Bounds,[0],[0]
"Given the number of features, the parameter λ for the size of the list, and parameters α0 and α1, we can derive an upper bound for the size of a maximum a posteriori rule list.",4.1. Upper bound on the number of rules in the list,[0],[0]
"This formalizes how the prior on the number of rules is strong enough to overwhelm the likelihood.
",4.1. Upper bound on the number of rules in the list,[0],[0]
"We are considering binary antecedents and binary features (e.g., aj is true if female), so the total number of possible
Algorithm 1",4.1. Upper bound on the number of rules in the list,[0],[0]
"Calculating bj’s Initialization: index=0, b0 = 1 for c = 0 to ⌊ P 2 ⌋ do
for j = ( P c ) downto 1",4.1. Upper bound on the number of rules in the list,[0],[0]
"do
index = index + 1 bindex = j
end for if c+ c 6= p then
for j = ( P P−c ) downto 1",4.1. Upper bound on the number of rules in the list,[0],[0]
"do
index = index + 1 bindex = j
end for end if
end for
antecedents of each size can be calculated directly.",4.1. Upper bound on the number of rules in the list,[0],[0]
"When creating the upper bound, within the proof, we hypothetically exhaust antecedents from each size category in turn, starting with the smallest sizes.",4.1. Upper bound on the number of rules in the list,[0],[0]
"We discuss this further below.
",4.1. Upper bound on the number of rules in the list,[0],[0]
Let |Qc| be the number of antecedents that remain in the pile that have c logical conditions.,4.1. Upper bound on the number of rules in the list,[0],[0]
The sequence of b’s that we define next is a lower bound for the possible sequence of |Qc|’s.,4.1. Upper bound on the number of rules in the list,[0],[0]
"In particular, b0, b1, b2, etc. represents the sequence of sizes of rules that would provide the smallest possible |Qc|’s.",4.1. Upper bound on the number of rules in the list,[0],[0]
"Intuitively, the sequence of b’s arises when we deplete the antecedents of size 1, then deplete all of size 2, etc.",4.1. Upper bound on the number of rules in the list,[0],[0]
"The number of ways to do this is given by the bindex values, computed as Algorithm 1, where P is the number of features, and b = {b0, b1, ...b2P−1} is a vector of length 2P .",4.1. Upper bound on the number of rules in the list,[0],[0]
We will use b within the theorem below.,4.1. Upper bound on the number of rules in the list,[0],[0]
"In our notation, rule list d is defined by the antecedents and the probabilities on the right side of the rules, d = (m, {al, θl}ml=1).
",4.1. Upper bound on the number of rules in the list,[0],[0]
Theorem 1,4.1. Upper bound on the number of rules in the list,[0],[0]
"The size m∗ of any MAP rule list d∗ (with parameters λ, η, and α = (α0, α1)) obeys m∗ ≤ mmax, where
mmax = min
{ 2P",4.1. Upper bound on the number of rules in the list,[0],[0]
"− 1,max { m′ ∈ Z+",4.1. Upper bound on the number of rules in the list,[0],[0]
: λ m′,4.1. Upper bound on the number of rules in the list,[0],[0]
m′!,4.1. Upper bound on the number of rules in the list,[0],[0]
"≥ Γ(N−+α0)Γ(N++α1)
Γ(N+α0+α1) m′∏ j=1 bj
}} .
",4.1. Upper bound on the number of rules in the list,[0],[0]
"With parameters α0 = 1 and α1 = 1, this reduces to:
mmax = min
{ 2P − 1,max { m′ ∈",4.1. Upper bound on the number of rules in the list,[0],[0]
Z+ :,4.1. Upper bound on the number of rules in the list,[0],[0]
λ m′ m′!,4.1. Upper bound on the number of rules in the list,[0],[0]
≥ Γ(N−+1)Γ(N++1) Γ(N+2),4.1. Upper bound on the number of rules in the list,[0],[0]
"m′∏ j=1 bj }} .
",4.1. Upper bound on the number of rules in the list,[0],[0]
"The proof is in the longer version of this paper (Yang et al., 2017).",4.1. Upper bound on the number of rules in the list,[0],[0]
Theorem 1 tends to significantly reduce the size of the space.,4.1. Upper bound on the number of rules in the list,[0],[0]
"Without this bound, it is possible that the search would consider extremely long lists, without knowing that they are provably non-optimal.",4.1. Upper bound on the number of rules in the list,[0],[0]
We next provide a bound that eliminates certain regions of the rule space from consideration.,4.2. Prefix Bound,[0],[0]
"Consider a rule list beginning with antecedents a1, .., ap.",4.2. Prefix Bound,[0],[0]
"If the best possible rule list starting with a1, .., ap cannot beat the posterior of the best rule list we have found so far, then we know any rule list starting with a1, .., ap is suboptimal.",4.2. Prefix Bound,[0],[0]
"In that case, we should stop exploring rule lists that start with a1, .., ap.",4.2. Prefix Bound,[0],[0]
"This is a type of branch and bound strategy, in that we have now eliminated (bounded) the entire set of lists starting with a1, .., ap.",4.2. Prefix Bound,[0],[0]
"We formalize this intuition below.
",4.2. Prefix Bound,[0],[0]
"Denote the rule list antecedents at iteration t by dt = (at1, a t 2, ..., a t mt , a0).",4.2. Prefix Bound,[0],[0]
"The current best posterior probability has value v∗t , that is
v∗t = max t′≤t Posterior(dt ′",4.2. Prefix Bound,[0],[0]
", {(xi, yi)}ni=1).
",4.2. Prefix Bound,[0],[0]
"Let us consider a rule list with antecedents d = (a1, a2, ...am, a0).",4.2. Prefix Bound,[0],[0]
"Let dp denote a prefix of length p of the rule list d, i.e., dp = (a1, a2, ...ap), where a1, a2, ..., ap are the same as the first p antecedents in d. We want to determine whether a rule list starting with dp could be better than the best we have seen so far.
",4.2. Prefix Bound,[0],[0]
"Define Υ(dp, {(xi, yi)}ni=1)",4.2. Prefix Bound,[0],[0]
"as follows:
Υ(dp, {(xi, yi)}ni=1)",4.2. Prefix Bound,[0],[0]
":= λmax (p,λ)/(max (p,λ))!∑|A|
j=0(λ j/j!)
",4.2. Prefix Bound,[0],[0]
"(∏p j=1 p(cj |c<j ,A, η)
1 |Qcj | ) × (∏m
j=0 Γ(Nj,0+1)Γ(Nj,1+1)
Γ(Nj,0+Nj,1+2)
)",4.2. Prefix Bound,[0],[0]
"×
Γ(1+N0−",4.2. Prefix Bound,[0],[0]
"∑p j=1Nj,0)
Γ(2+N0−",4.2. Prefix Bound,[0],[0]
"∑p j=1Nj,0)
Γ(1+N1−",4.2. Prefix Bound,[0],[0]
"∑p j=1Nj,1)
Γ(2+N1−",4.2. Prefix Bound,[0],[0]
"∑p j=1Nj,1) .
",4.2. Prefix Bound,[0],[0]
"Here, Nj,0 is the number of points captured by rule j with label 0, and Nj,1 is the number of points captured by rule j with label 1,
Nj,0 = |{i : Captr(i) = j and yi = 0}|, Nj,1 = |{i : Captr(i) = j and yi = 1}|.
",4.2. Prefix Bound,[0],[0]
"The result states that for a rule list with prefix dp, if the upper bound on the posterior, Υ(dp), is not as high as the posterior of the best rule list we have seen so far, then dp is a bad prefix, which cannot lead to a MAP solution.",4.2. Prefix Bound,[0],[0]
"It tells us we no longer need to consider rule lists starting with dp.
",4.2. Prefix Bound,[0],[0]
Theorem 2,4.2. Prefix Bound,[0],[0]
"For rule list d = {dp, ap+1, ..., am, a0}, if
Υ(dp, {(xi, yi)}ni=1)",4.2. Prefix Bound,[0],[0]
<,4.2. Prefix Bound,[0],[0]
"v∗t ,
then for α0 = 1 and α1 = 1, we have
d 6∈ argmaxd′Posterior(d′, {(xi, yi)}ni=1).",4.2. Prefix Bound,[0],[0]
"(1)
Theorem 2 is implemented in our code in the following way: for each random restart, the initial rule in the list is checked against the bound of Theorem 2.",4.2. Prefix Bound,[0],[0]
If the condition Υ(d1) <,4.2. Prefix Bound,[0],[0]
"v ∗ t holds, we throw out this initial rule and choose a new one, because that rule provably cannot be the first rule in an optimal rule list.",4.2. Prefix Bound,[0],[0]
Theorem 2 provides a substantial computational speedup in finding high quality or optimal solutions.,4.2. Prefix Bound,[0],[0]
"In some cases, it provides a full order of magnitude speedup.",4.2. Prefix Bound,[0],[0]
"The proofs are lengthy and contained in the longer version of this work (Yang et al., 2017).",4.2. Prefix Bound,[0],[0]
"We provide a comparison of algorithms along three dimensions: solution quality (AUC - area under the ROC curve), sparsity, and scalability.",5. Experiments,[0],[0]
"As baselines, we chose popular algorithms to represent the sets of uninterpretable methods and the set of “interpretable” methods.",5. Experiments,[0],[0]
"To represent uninterpretable methods, we chose logistic regression, SVM RBF, random forests (RF), and boosted decision trees (ADA).",5. Experiments,[0],[0]
"To represent the class of “interpretable” algorithms, we chose CART, C4.5, RIPPER (Cohen, 1995), CBA (Liu et al., 1998), and CMAR (Li et al., 2001).",5. Experiments,[0],[0]
"Other works (see Letham et al., 2015; Wang & Rudin, 2015a) have accuracy/interpretability comparisons to Bayesian Rule Lists and Falling Rule Lists, so our main effort here will be to study the scalability component.",5. Experiments,[0],[0]
"Implementation details are in the full version (Yang et al., 2017).
",5. Experiments,[0],[0]
"We benchmark using publicly available datasets (see Bache & Lichman, 2013) that have interpretable features: the Tic Tac Toe dataset, where the goal is to determine whether the “X” player wins; the Adult dataset, where we aim to predict whether an individual makes over $50K peryear; the Mushroom dataset, where the goal is to predict whether a mushroom is edible; the Nursery dataset, where the goal is to predict whether a child’s application to nursery school will be in either the “very recommended” or “special priority” categories; and the Telco customer churn dataset (see WatsonAnalytics, 2015), where the goal is to predict whether a customer will leave the service provider.
",5. Experiments,[0],[0]
"Evaluations of prediction quality, sparsity, and timing were done using 10-fold cross validation.",5. Experiments,[0],[0]
"The prior parameters were fixed at η = 1, and α = (1, 1).",5. Experiments,[0],[0]
"For the λ for each dataset, we first let λ be 5 and ran SBRL once with the above parameters.",5. Experiments,[0],[0]
Then we fixed λ at the length of the returned rule list for that dataset.,5. Experiments,[0],[0]
It is possible that the solution quality would increase if SBRL ran for a larger number of iterations.,5. Experiments,[0],[0]
"For the purpose of providing a controlled experiment, the number of iterations was fixed at 5,000 for each of the 20 chains of SBRL, which we ran in series on a laptop.",5. Experiments,[0],[0]
"Every time SBRL started a new rule list, we checked the initial rule in the list to see whether the upper-bound on its posterior (by Theorem 2) was greater
than the best rule list we had found so far.",5. Experiments,[0],[0]
"If not, the rule was replaced until the condition was satisfied.
",5. Experiments,[0],[0]
Tic Tac Toe: Each observation in this dataset is a tic tac toe board after the game has finished.,5. Experiments,[0],[0]
"If there are 3 X’s in a row, the label of the board is 1, otherwise 0.",5. Experiments,[0],[0]
This should not be a difficult learning problem since there are solutions with perfect accuracy on the training set that generalize to the test set.,5. Experiments,[0],[0]
"Figure 2 shows a scatter plot of AUC vs. number of leaves (sparsity), where each triangular marker represents an evaluation of one algorithm, on one fold, with one parameter setting.",5. Experiments,[0],[0]
"We tried many different parameter settings for CART (in blue), and many different parameter settings for C4.5 (in gray), none of which were able to achieve points on the efficient frontier defined by SBRL.",5. Experiments,[0],[0]
"SBRL’s run time was on average 0.759 (± .02) seconds.
",5. Experiments,[0],[0]
Adult:,5. Experiments,[0],[0]
"For the Adult dataset, results are in Figure 3, Figure 4 and Table 2.",5. Experiments,[0],[0]
"Adult contains 45,121 observations and 12 features, where each observation is an individual, and the features are census data, including demographics, income levels, and other financial information.",5. Experiments,[0],[0]
"Here, SBRL, which was untuned and forced to be sparse, performed only slightly worse than several of the uninterpretable methods.",5. Experiments,[0],[0]
Its AUC performance dominated those of the CART and C4.5 algorithms.,5. Experiments,[0],[0]
"As the scatter plot shows, even if CART were tuned on the test set, it would have performed at around the same level, perhaps slightly worse than SBRL.",5. Experiments,[0],[0]
"The timing for SBRL was competitive, at about 18 seconds, where 14 seconds were MCMC iterations.",5. Experiments,[0],[0]
"If the chains were computed in parallel rather than in series, it would speed up computation further.
",5. Experiments,[0],[0]
Mushroom:,5. Experiments,[0],[0]
Table 1 contains an SBRL rule list for Mushroom; other results are in Yang et al. (2017).,5. Experiments,[0],[0]
"SBRL attains perfect test accuracy on this dataset.
",5. Experiments,[0],[0]
Nursery: Results from the Nursery dataset are shown in Figure 5.,5. Experiments,[0],[0]
"A similar story holds as for the previous datasets: SBRL is on the optimal frontier of accuracy/sparsity without tuning and with reasonable run time.
",5. Experiments,[0],[0]
Telco:,5. Experiments,[0],[0]
"Figure 6, Figure 7 and Table 3 show the results for the Telco dataset, which contains 7043 observations and 18 features.",5. Experiments,[0],[0]
Similar observations hold for this dataset.,5. Experiments,[0],[0]
The model from one of the ten folds is provided in Table 4.,5. Experiments,[0],[0]
"We used the USCensus1990 data (see Bache & Lichman, 2013) to test the scalability of SBRL on large datasets.",6. Scalability,[0],[0]
"We used 1,000,000 observations and set SBRL’s parameter to extract ≈1000 rules as problem (A) and about 50,000 observations with 50,000 rules as problem (B).",6. Scalability,[0],[0]
The runtime comparison with CART is shown in Table 5.,6. Scalability,[0],[0]
"For problem (A), the run times are similar; for (B); SBRL is slower (2.5 hours), which is not prohibitive for important problems.",6. Scalability,[0],[0]
"One can see why CART does not perform as well in high dimensions, as it often spends less time on harder problems than on easier ones; details are in (Yang et al.,
Table 3.",6. Scalability,[0],[0]
"Run Time on Telco dataset
RUN TIME LR SVM RF ADA CART C4.5 RIPPER CBA CMAR SBRL
MEAN 0.267 7.468 3.703 7.839 0.168 0.250 37.14 8.028 1.679 5.239 MEDIAN 0.272 7.550 3.695 8.726 0.168 0.252 37.63 8.050 1.705 5.271 STD 0.009 0.207 0.183 0.111 0.008 0.017 3.202 0.400 0.161 0.149
2017).",6. Scalability,[0],[0]
"Rule lists are a type of one-sided decision tree, and any decision tree can be written as a rule list by enumerating the leaves.",7. Related Works and Discussion,[0],[0]
"Thus SBRL is a competitor for CART (Breiman et al., 1984).",7. Related Works and Discussion,[0],[0]
CART is currently still popular in industry.,7. Related Works and Discussion,[0],[0]
"CART and other decision tree methods (also decision list methods and associative classification methods) form trees from the top down using greedy splitting and greedy pruning (see, e.g., Quinlan, 1983; Clark & Niblett, 1989; Cendrowska, 1987; Rivest, 1987; Quinlan, 1993; Liu et al., 1998; Li et al., 2001; Yin & Han, 2003; Marchand & Sokolova, 2005; Vanhoof & Depaire, 2010; Rudin et al., 2013).",7. Related Works and Discussion,[0],[0]
"Since our work does not use greedy splitting and pruning, it is closer to Bayesian tree models (Dension et al., 1998; Chipman et al., 2002; 2010), which are built greedily from the top down, but then the trees change according to an MCMC scheme, which allows for more exploration of the search space.",7. Related Works and Discussion,[0],[0]
"However even with MCMC, the chains tend to center on local optima.",7. Related Works and Discussion,[0],[0]
"It may be possible to use our techniques to build trees, where one would mine rules and create a globally optimal tree.
",7. Related Works and Discussion,[0],[0]
"There are a series of works from the mid-1990’s onwards on finding optimal decision trees using dynamic programming and search techniques (e.g., Bennett & Blue, 1996; Auer et al., 1995; Dobkin et al., 1996; Boros et al., 2000; Garofalakis et al., 2000; Farhangfar et al., 2008), mainly working with fixed depth trees.",7. Related Works and Discussion,[0],[0]
"The number of trees of a
fixed depth is much larger than the number of rule lists of a fixed depth and are therefore more difficult to optimize.",7. Related Works and Discussion,[0],[0]
"Nijssen & Fromont (2010) use pre-mined rules to form trees, but in a different way than our method.",7. Related Works and Discussion,[0],[0]
"There, the user premines all possible leaves, enumerating all conditions leading to that leaf.",7. Related Works and Discussion,[0],[0]
"(By contrast, in associative classification, we mine only small conjunctions, and their ordered combination creates leaves.)",7. Related Works and Discussion,[0],[0]
"As as result, Nijssen & Fromont (2010) warn about issues related to running out of memory.
",7. Related Works and Discussion,[0],[0]
"An extension of this work (CORELS - Angelino et al., 2017) does not provide probabilistic predictions, but is able to provide a certificate of optimality to a globally optimal rule list.",7. Related Works and Discussion,[0],[0]
"This indicates that SBRL is probably also achieving optimality; however, because SBRL is probabilistic, the proof of optimality is much more difficult.",7. Related Works and Discussion,[0],[0]
"To clarify: finding the optimal solution for both methods should be approximately equally difficult, but proving optimality for SBRL is much more difficult.",7. Related Works and Discussion,[0],[0]
"However, there is a clear practical benefit to having probabilistic predictions like those of SBRL.",7. Related Works and Discussion,[0],[0]
"One can post-process CORELS to have probabilistic predictions by computing P (Y = 1|x ∈ leaf) for each leaf, but this is not the same as optimizing likelihood and obtaining these probabilities directly like SBRL.
",7. Related Works and Discussion,[0],[0]
"There are several subfields that produce disjunctive normal form (DNF) classifiers rather than rule lists, including rule learning/induction, and associative classification, which stemmed possibly from work in the 1960s (Michalski, 1969), and throughout the 1980’s and 90’s (Cendrowska, 1987; Clark & Niblett, 1989; Cohen, 1995).",7. Related Works and Discussion,[0],[0]
"The vast majority of these techniques are not probabilistic, and aim for covering the positive class without covering the negative class.",7. Related Works and Discussion,[0],[0]
"Rijnbeek & Kors (2010) aim to produce globally op-
timal DNF models.",7. Related Works and Discussion,[0],[0]
"There is recent work on probabilistic DNF’s that is similar to SBRL (Wang et al., 2016; 2017).
",7. Related Works and Discussion,[0],[0]
"Teleo-reactive programs (Nilsson, 1994) use a rule list structure and could benefit from learning this structure from data.
",7. Related Works and Discussion,[0],[0]
SBRL aims to produce interpretable models.,7. Related Works and Discussion,[0],[0]
"Interpretability has been a fundamental topic in artificial intelligence for a long time (see Rüping, 2006; Bratko, 1997; Dawes, 1979; Vellido et al., 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huysmans et al., 2011; Freitas, 2014).",7. Related Works and Discussion,[0],[0]
"Because the rule lists created by our method are designed to be interpretable, one would probably not want to boost them using AdaBoost to form more complicated models.",7. Related Works and Discussion,[0],[0]
"This contrasts with, for instance, Friedman & Popescu (2008), who linearly combine pre-mined rules.
",7. Related Works and Discussion,[0],[0]
"Rule lists and their variants are currently being used for text processing (King et al., 2017), discovering treatment regimes (Zhang et al., 2015; Lakkaraju & Rudin, 2017; Wang & Rudin, 2015b), and creating medical risk assessments (Letham et al., 2015), among other applications.
",7. Related Works and Discussion,[0],[0]
Conclusion We finish by stating why/when one would want to use this particular method.,7. Related Works and Discussion,[0],[0]
"SBRL is not meant as a competitor for black box classifiers such as neural networks, support vector machines, gradient boosting or random forests.",7. Related Works and Discussion,[0],[0]
"It is useful when machine learning tools are used as a decision aid to humans, who need to understand the model in order to trust it and make data-driven decisions.",7. Related Works and Discussion,[0],[0]
"SBRL does not use a greedy splitting/pruning procedure like decision tree algorithms (CART, C4.5), which means that it more reliably computes high quality solutions, at the possible expense of additional computation time.",7. Related Works and Discussion,[0],[0]
"Many of the decision tree methods do not compute sparse or interpretable trees, as we have seen with C4.5.",7. Related Works and Discussion,[0],[0]
Our code is a strict improvement over the original Bayesian Rule Lists algorithm if one is looking for a maximum a posteriori solution.,7. Related Works and Discussion,[0],[0]
"It is faster because of careful use of low-level computations and theoretical bounds.
",7. Related Works and Discussion,[0],[0]
"Code
Code for SBRL is available at the following link: https://github.com/Hongyuy/sbrlmod Link to R package SBRL on CRAN: https: //cran.r-project.org/web/packages/sbrl/ index.html",7. Related Works and Discussion,[0],[0]
"The authors would like to acknowledge partial funding provided by NSF, Philips, Wistron, and Siemens.",Acknowledgement,[0],[0]
We present an algorithm for building probabilistic rule lists that is two orders of magnitude faster than previous work.,abstractText,[0],[0]
Rule list algorithms are competitors for decision tree algorithms.,abstractText,[0],[0]
"They are associative classifiers, in that they are built from pre-mined association rules.",abstractText,[0],[0]
"They have a logical structure that is a sequence of IF-THEN rules, identical to a decision list or one-sided decision tree.",abstractText,[0],[0]
"Instead of using greedy splitting and pruning like decision tree algorithms, we aim to fully optimize over rule lists, striking a practical balance between accuracy, interpretability, and computational speed.",abstractText,[0],[0]
"The algorithm presented here uses a mixture of theoretical bounds (tight enough to have practical implications as a screening or bounding procedure), computational reuse, and highly tuned language libraries to achieve computational efficiency.",abstractText,[0],[0]
"Currently, for many practical problems, this method achieves better accuracy and sparsity than decision trees, with practical running times.",abstractText,[0],[0]
The predictions in each leaf are probabilistic.,abstractText,[0],[0]
Scalable Bayesian Rule Lists,title,[0],[0]
"It has long been known that solutions obtained from optimization methods can demonstrate striking sensitivity to the parameters of the problem (Bertsimas et al., 2011).",1. Introduction,[0],[0]
"Robust optimization, in contrast, is a paradigm in the mathematical programming community with the aim of safeguarding the solutions from the changes in the underlying parameters.
",1. Introduction,[0],[0]
"In this paper, we consider submodular maximization, a very well studied discrete optimization problem defined over a finite set of items (e.g., images, videos, blog posts, sensors, etc).",1. Introduction,[0],[0]
"Submodularity formalizes the notion of diminishing returns, stating (informally) that selecting an item earlier results in a higher utility than selecting it later.",1. Introduction,[0],[0]
"This notion has found far-reaching applications in machine learning
1Department of Computer Science, Yale University, New Haven, Connecticut, USA 2Google Research, Zurich, Switzerland.",1. Introduction,[0],[0]
"Correspondence to: Ehsan Kazemi <ehsan.kazemi@yale.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"(Bach et al., 2013), web search and mining (Borodin et al., 2017), social network (Kempe et al., 2003), crowdsourcing (Singla et al., 2016), and user modeling (Yue & Guestrin, 2011), to name a few.",1. Introduction,[0],[0]
"However, almost all the existing methods for submodular maximization, ranging from centralized (Nemhauser et al., 1978; Feldman et al., 2017) to streaming (Badanidiyuru et al., 2014; Feldman et al., 2018), to distributed (Mirzasoleiman et al., 2013; Mirrokni & Zadimoghaddam, 2015; Barbosa et al., 2015), rely on greedy selection of elements.",1. Introduction,[0],[0]
"As a result, the returned solution of such methods are remarkably sensitive to even a single deletion from the set of items.
",1. Introduction,[0],[0]
The need for efficient deletion-robust optimization methods is wide-spread across many data-driven applications.,1. Introduction,[0],[0]
"With access to big and massive data (usually generated by millions of users), along with strong machine learning techniques, many service providers have been able to exploit these new resources in order to improve the accuracy of their data analytics.",1. Introduction,[0],[0]
"At the same time, it has been observed that many such inference tasks may leak very sensitive information about the data providers (i.e., personally identifiable information, protected health information, legal or financial data, etc).",1. Introduction,[0],[0]
"Similarly these algorithms can encode hidden biases that disproportionately and adversely impact members with certain characteristics (e.g., gender and race).
",1. Introduction,[0],[0]
"In order to reduce the effect of information extraction on privacy and fairness, one needs to be able to remove sensitive data points (e.g., geolocations) or discard sensitive data features (e.g., skin color) from the dataset without incurring too much loss in performance.",1. Introduction,[0],[0]
"For instance, Article 17 of European “General Data Protection Regulation” states obligations with respect to providing individuals with the “Right to erasure (or Right to be forgotten)”.",1. Introduction,[0],[0]
"By exercising this right, individuals may enforce the service providers to delete their personal data or put restrictions from using part of it.",1. Introduction,[0],[0]
"Similarly, Title VII of the Civil Rights Act of American anti-discrimination law prohibits employment discrimination against certain characteristics (such as color and sex).",1. Introduction,[0],[0]
"Thus, to obtain fairer machine learning algorithms, we need to reduce the bias inherent in the training examples due to the lack of certain types of information, not being representative, or reflecting historical biases.",1. Introduction,[0],[0]
"This can be done by either removing protected attributes from training data
(Zemel et al., 2013) or train them separately for different protected groups (Chayes, 2017), among other procedures.",1. Introduction,[0],[0]
"Unfortunately, sensitive features or biased data usually are not known a priori and we might be aware of their existence just after training our models (Beutel et al., 2017).",1. Introduction,[0],[0]
"Retraining a machine learning model from scratch, after removing sensitive features and biased data, is quite expensive for large datasets.",1. Introduction,[0],[0]
Deletion-robust submodular maximization can save a lot of time and computational resources in these scenarios.,1. Introduction,[0],[0]
"In this paper, we provide a computationally feasible way of rerunning the algorithms should some attributes or data points be discarded.
",1. Introduction,[0],[0]
"Most existing submodular maximization methods, often used for data extraction (Mirzasoleiman et al., 2013) and informative subset selection (Wei et al., 2015), do not provide such guarantees.",1. Introduction,[0],[0]
"In this paper, we develop the first scalable and memory-efficient algorithms for maximizing a submodular function subject to a cardinality constraint that are robust against any number of adversarial deletions.",1. Introduction,[0],[0]
"This is in sharp contrast to previous methods that could only handle a fixed number of deletions (Orlin et al., 2016; Bogunovic et al., 2017) or otherwise their memory requirement scales multiplicatively with the number of deletions (Mirzasoleiman et al., 2017).
",1. Introduction,[0],[0]
"Our contributions: For a monotone submodular function with a cardinality constraint k, we develop the following randomized algorithms that are robust against any d deletions: 1.",1. Introduction,[0],[0]
Centralized:,1. Introduction,[0],[0]
We propose ROBUST-CENTRALIZED that achieves (1/2 )-approximation guarantee (in expectation) with the memory requirement O (k + d log k/ 2).,1. Introduction,[0],[0]
"Note that the memory complexity is only a logarithmic factor (e.g., log k) away from a trivial lower bound O(k + d).",1. Introduction,[0],[0]
2.,1. Introduction,[0],[0]
"Streaming: We propose ROBUST-STREAMING that achieves (1/2 )-approximation guarantee (in expectation) with the memory requirement O k log k/ + d log2 k/ 3 .
3.",1. Introduction,[0],[0]
Distributed: We propose ROBUST-DISTRIBUTED that achieves (0.218 )-approximation,1. Introduction,[0],[0]
"guarantee (in expectation) with the memory requirement O (m(k + d log k/ 2)), where m is the number of machines.",1. Introduction,[0],[0]
"We also introduce COMPACT-DISTRIBUTED, a variant of ROBUSTDISTRIBUTED, where its memory requirement is independent of number of machines.
",1. Introduction,[0],[0]
Table 1 compares our proposed methods with previous algorithms.,1. Introduction,[0],[0]
The proofs of all the theoretical results are deferred to the Supplementary Material.,1. Introduction,[0],[0]
"Monotone submodular maximization under cardinality constraints is studied extensively in centralized, streaming and distributed scenarios.",2. Related Work,[0],[0]
"The classical result of Nemhauser et al. (1978) proves that the simple GREEDY algorithm that starts with an empty set and iteratively adds elements with
the highest marginal gain provides (1 1/e)-approximation guarantee.",2. Related Work,[0],[0]
"To scale to large datasets, several streaming algorithms with constant factor approximations have recently been proposed (Badanidiyuru et al., 2014; Kumar et al., 2015; Buchbinder et al., 2015).",2. Related Work,[0],[0]
"Also, different distributed submodular maximization algorithms have been developed lately (Mirzasoleiman et al., 2013; Mirrokni & Zadimoghaddam, 2015; Barbosa et al., 2015).
",2. Related Work,[0],[0]
"Krause et al. (2008) introduced the robust formulation of the classical cardinality constrained submodular maximization for the first time and gave a bi-criterion approximation to the problem of max|A|k mini2{1,··· ,`} fi(A), where fi is normalized monotone submodular for every i. Note that submodular maximization of function f that is robust to the deletion of d items can be modeled as a special case of this problem: max|A|k min|D|d f(A \D).",2. Related Work,[0],[0]
Krause et al. (2008) guaranteed a robust solution by returning a set whose size is k(1 + ⇥(log(dk log n)).,2. Related Work,[0],[0]
"There are two main drawbacks with this approach when applied to deletions: first, the size of final solution is logarithmically larger than k, and second, the running time is exponential in d. Orlin et al. (2016) designed a centralized algorithm that outputs a set of cardinality k in a polynomial time.",2. Related Work,[0],[0]
Their algorithm is robust to the deletion of only o( p k) elements.,2. Related Work,[0],[0]
Bogunovic et al. (2017) further improved the result of Orlin et al. (2016) to o(k) deletions.,2. Related Work,[0],[0]
The approximation guarantees for both of these algorithms are 0.387.,2. Related Work,[0],[0]
The aforementioned methods try to construct a solution without allowing to update the answer after deletion.,2. Related Work,[0],[0]
"In contrast, Mirzasoleiman et al. (2017) developed a streaming algorithm which is robust to the deletion of any number of d elements.",2. Related Work,[0],[0]
"They keep a set of size O(kd log k/ ), and after each deletion they find a feasible solution of size at most k from this set.",2. Related Work,[0],[0]
They also improved the approximation guarantee to 1/2 .,2. Related Work,[0],[0]
"The main drawback of this algorithm is the memory requirement, which is quite impractical for large values of d and k; e.g., for k = O( p n) and d = O( p n)",2. Related Work,[0],[0]
"the memory requirement is even larger than n. Independently and concurrently with our work, Mitrovic et al. (2017) presented a robust to deletion streaming algorithm.",2. Related Work,[0],[0]
"Also, there are several recent works on robust optimization of non-submodular functions (Bogunovic et al., 2018; Tzoumas et al., 2018).
",2. Related Work,[0],[0]
"Submodular maximization has been widely used in classical machine learning and data mining applications, including extracting representative elements with exemplar based clustering (Krause & Gomes, 2010), data summarization through active set selection (Herbrich et al., 2003; Seeger, 2004), feature selection (Krause & Guestrin, 2005) and document summarization (Lin & Bilmes, 2011).",2. Related Work,[0],[0]
Assume we have a set function f : 2V !,3. Problem Definition,[0],[0]
R 0.,3. Problem Definition,[0],[0]
"We define the marginal gain of an element e 2 V to the set A ✓ V
by f (e|A) = f(A",3. Problem Definition,[0],[0]
[ {e}) f(A).,3. Problem Definition,[0],[0]
"The function f is submodular if for all A ✓ B ✓ V and e 2 V \ B, we have f (e|A) f (e|B).",3. Problem Definition,[0],[0]
"A submodular function f is monotone if for every A ✓ B ✓ V , we have f(A)  f(B).
",3. Problem Definition,[0],[0]
"In many submodular optimization applications, a subset of items of the ground set V may be removed at different points in time.",3. Problem Definition,[0],[0]
"For this reason, we require to find solutions which are robust to the deletion.",3. Problem Definition,[0],[0]
"Indeed, the goal is to maximize a submodular function f over a set V of items under a cardinality constraint k, where it is robust to the deletion of any subset D ⇢ V of size |D|  d. More precisely, we are interested in solving the following problem for each possible (and unknown a priori) instance of D:
S ⇤ = argmax
S✓V \D,|S|k f(S).",3. Problem Definition,[0],[0]
"(1)
We also define OPT = f(S⇤).",3. Problem Definition,[0],[0]
The most straightforward approach to this problem is to solve Eq.,3. Problem Definition,[0],[0]
"(1) for each instance of D. Unfortunately, solving Eq. (1), for large datasets, is computationally prohibitive.",3. Problem Definition,[0],[0]
"Also, deletion of elements from the set V can happen at different stages in real time applications.",3. Problem Definition,[0],[0]
This makes the problem even harder.,3. Problem Definition,[0],[0]
"Our solution to this problem is to maintain a small set A ⇢ V, called a core-set of V, where for each set D we can efficiently find a subset B ✓ A \D that provides an acceptable approximation for Eq.",3. Problem Definition,[0],[0]
(1).,3. Problem Definition,[0],[0]
"Note that set A is constructed without knowing set D. For this reason, next we define the notion of (↵, d)-robust randomized core-set.",3. Problem Definition,[0],[0]
Definition 1.,3. Problem Definition,[0],[0]
"A random subset of A ✓ V is an (↵, d)-robust randomized core-set for a set V, if for any subset D ✓ V of size |D|  ",3. Problem Definition,[0],[0]
"d, there exists a B ✓ A \D, |B|  k such that
E[f(B)]",3. Problem Definition,[0],[0]
"↵ · max S✓V \D,|S|k f(S),
where expectation is taken over the randomization of set A.",3. Problem Definition,[0],[0]
"In this section, we present three fast and scalable randomized algorithms.",4. Robustness and Cardinality Constraint,[0],[0]
"These algorithms solve the problem of robust submodular maximization in centralized, streaming and distributed scenarios.",4. Robustness and Cardinality Constraint,[0],[0]
"Our algorithms provide, in expectation, constant factor approximation guarantees, where they
are robust to the (even adversarial) deletion of any d items from the set V. In our setting, an adversary might try to find a set of inputs for which our algorithms fail to provide good results.",4. Robustness and Cardinality Constraint,[0],[0]
"In order to make the optimization robust to the adversarial deletions, we introduce randomness in the selection process.",4. Robustness and Cardinality Constraint,[0],[0]
"We assume that the adversary does not have access to the random bits of the randomized algorithms.
",4. Robustness and Cardinality Constraint,[0],[0]
The proposed algorithms are designed based on a general idea that the elements are chosen randomly from a large enough pool of similar items.,4. Robustness and Cardinality Constraint,[0],[0]
"This idea is useful because the adversary is not aware of the random bits of the algorithms, which makes the deletion probability of elements we have chosen negligible.",4. Robustness and Cardinality Constraint,[0],[0]
"Therefore, we can bound the expected value of each selected set.
",4. Robustness and Cardinality Constraint,[0],[0]
Our solution consists of two steps.,4. Robustness and Cardinality Constraint,[0],[0]
"In the first step, we find a small core-set of elements (in comparison to the whole dataset).",4. Robustness and Cardinality Constraint,[0],[0]
"We prove that after the deletion of at most d arbitrary elements, we can still find a good approximation for the optimization problem in this small set.",4. Robustness and Cardinality Constraint,[0],[0]
"In the second step, we choose at most k elements from the core-set we have found in the first step.",4. Robustness and Cardinality Constraint,[0],[0]
We prove a constant approximation factor for our algorithm in expectation.,4. Robustness and Cardinality Constraint,[0],[0]
"This guarantees that the core-set is (↵, d)-robust randomized for a constant ↵ and arbitrary d.
In the optimization procedure, we use a thresholding idea to select elements.",4. Robustness and Cardinality Constraint,[0],[0]
"Similar ideas have been used previously for designing streaming algorithms (Badanidiyuru et al., 2014; Buchbinder et al., 2015; Chekuri et al., 2015).",4. Robustness and Cardinality Constraint,[0],[0]
"In those algorithms, when an element of the stream arrives, if this element has sufficiently large marginal value it is kept; otherwise it is discarded.",4. Robustness and Cardinality Constraint,[0],[0]
"In the robust submodular maximization, we keep a large enough pool of elements with sufficient marginal values before adding or discarding them.",4. Robustness and Cardinality Constraint,[0],[0]
We randomly pick an element when the size of pool is at least d/✏.,4. Robustness and Cardinality Constraint,[0],[0]
Thus the element picked at each step is deleted with a probability at most ✏.,4. Robustness and Cardinality Constraint,[0],[0]
"This is true because the size of deleted items is at most d. To guarantee the quality of the chosen elements after the deletion (i.e., we want the expected value of f over the set of picked elements does
not change a lot after deletion), not only they should have been picked from a large pool of elements, the elements of pool should have almost the same marginal gains.",4. Robustness and Cardinality Constraint,[0],[0]
"To explain, in more details, why we need this property consider the example in Appendix A.",4. Robustness and Cardinality Constraint,[0],[0]
"In this section we outline a centralized algorithm, called ROBUST-CORESET-CENTRALIZED, to find an (↵, d)-robust core-set.",4.1. Centralized Algorithm,[0],[0]
"We also present the ROBUST-CENTRALIZED algorithm which is able to find a good solution from the core-set.
",4.1. Centralized Algorithm,[0],[0]
Badanidiyuru et al. (2014) showed that one way to obtain a constant factor approximation to the classical submodular maximization problem is to use a thresholding idea.,4.1. Centralized Algorithm,[0],[0]
They proved that choosing elements with marginal gain at least ⌧ ⇤ = OPT2k from a stream until a maximum of k elements are chosen returns a set with an approximation factor of 1/2.,4.1. Centralized Algorithm,[0],[0]
The main problem with this primary idea is that the value of OPT is not known by the algorithm.,4.1. Centralized Algorithm,[0],[0]
"Badanidiyuru et al. (2014) pointed out that, from the submodularity of f , we have 0  OPT  k 0 where 0 is the largest value in set {f({e})|e 2 V }.",4.1. Centralized Algorithm,[0],[0]
"By dividing the range [ 0, k 0] into intervals of [⌧i, ⌧i+1) (where ⌧i+1/⌧i is close to 1) it is possible to find a good enough approximation for OPT.
",4.1. Centralized Algorithm,[0],[0]
"We should first note that due to the deletion process, the relevant maximum singleton value is not 0 anymore, and it is 00 = maxe2V \D f({e}).",4.1. Centralized Algorithm,[0],[0]
"The algorithm is unaware of set D, therefore 00 could be anywhere in the range [ d, 0] where d is the (d+ 1)-th largest value in the set {f({e})|e 2 V }.",4.1. Centralized Algorithm,[0],[0]
The lower bound of d is implied by the fact that at most d elements will be deleted.,4.1. Centralized Algorithm,[0],[0]
"So ⌧⇤ = OPT2k could fall anywhere in the range [ d/2k, 0].",4.1. Centralized Algorithm,[0],[0]
"Unlike the deletion free case, the upper and lower limits of this range do not differ only by a multiplicative factor of k, thus a naive approach makes us try arbitrarily large number of different choices to find a good estimate of ⌧⇤.",4.1. Centralized Algorithm,[0],[0]
"We resolve this issue by the following observation.
",4.1. Centralized Algorithm,[0],[0]
We reserve a set B of elements that might be valuable after the deletion process.,4.1. Centralized Algorithm,[0],[0]
"Let Vd be the (d + 1) largest singleton value elements, i.e., the top d + 1 elements in the set {f({e})|e 2 V }.",4.1. Centralized Algorithm,[0],[0]
"We preserve all elements of Vd for the next round by inserting them to B. This way, we do not have to worry about thresholds above d as all elements that might have marginal value above d to any set should be in set Vd",4.1. Centralized Algorithm,[0],[0]
"and they are added to B. Therefore, we consider all thresholds in the set T = {(1 + ✏)i| d2k  (1 + ✏)
i  d}.",4.1. Centralized Algorithm,[0],[0]
"Starting from the largest ⌧ 2 T to the smallest, we iteratively construct two sets A⌧ and B⌧ .",4.1. Centralized Algorithm,[0],[0]
"At the end of the algorithm, the set B is defined as the union of Vd and [⌧2TB⌧ .",4.1. Centralized Algorithm,[0],[0]
"We output set B, along with all sets {A⌧}⌧2T, as the core-set.
",4.1. Centralized Algorithm,[0],[0]
We initialize A⌧ to ?.,4.1. Centralized Algorithm,[0],[0]
"We let B⌧ to be the set of elements whose marginal values to the set [⌧ 0 ⌧A⌧ 0 is in the range
Algorithm 1 ROBUST-CORESET-CENTRALIZED
1: d the (d+ 1)-th largest value of {f({e})|e 2 V } 2: Vd all the d+ 1 elements with the largest values in
set {f({e})|e 2 V } 3: T = {(1 + ✏)i| d2(1+✏)k  (1 + ✏)
i  d} 4: For each ⌧ 2 T : {A⌧} ?",4.1. Centralized Algorithm,[0],[0]
and {B⌧} ?,4.1. Centralized Algorithm,[0],[0]
"5: V V \ Vd 6: for ⌧ 2 T from the highest to the lowest do 7: while |B⌧ | d/✏ for B⌧ = {e 2 V : ⌧ 
f (e|[⌧ 0 ⌧ A⌧ 0) <",4.1. Centralized Algorithm,[0],[0]
(1+ ✏)⌧} and |[⌧ 0 ⌧ A⌧ 0,4.1. Centralized Algorithm,[0],[0]
| < k,4.1. Centralized Algorithm,[0],[0]
"do
8: Randomly pick an element e from B⌧ and add it to A⌧ , i.e., A⌧ A⌧ [ {e}
9: V V \",4.1. Centralized Algorithm,[0],[0]
"(A⌧ [B⌧ ) 10: B {[B⌧} [ Vd 11: Return {A⌧}, B
[⌧, (1 + ✏)⌧).",4.1. Centralized Algorithm,[0],[0]
"We note that this is a dynamic definition and whenever we add an element to any of A⌧ sets, the related B⌧ set might change as well.",4.1. Centralized Algorithm,[0],[0]
Elements in the set B⌧ are similar to each other in terms of their marginal values.,4.1. Centralized Algorithm,[0],[0]
"Without deletions, we can choose any element from B⌧ and add it to our solution.",4.1. Centralized Algorithm,[0],[0]
"However, if B⌧ has only a few elements, the adversary can delete all of them, and we will be left with an arbitrary poor solution.",4.1. Centralized Algorithm,[0],[0]
"To make the selection process robust, we select a random element from B⌧ and add it to A⌧ only if there are at least d/✏ elements in B⌧ .",4.1. Centralized Algorithm,[0],[0]
"This way even if all the deleted elements are from the set B⌧ , the probability of each selected element being deleted is at most ✏.",4.1. Centralized Algorithm,[0],[0]
We also know that all elements added to A⌧ have similar marginal values and are interchangeable.,4.1. Centralized Algorithm,[0],[0]
We keep adding elements to A⌧ until either [⌧ 0 ⌧A⌧ 0 has k elements or the size of set B⌧ becomes smaller than d/✏.,4.1. Centralized Algorithm,[0],[0]
"At this stage, we keep both sets A⌧ and B⌧ as a part of the output core-set.",4.1. Centralized Algorithm,[0],[0]
We also remove them from the ground set V and move on to the next lower threshold.,4.1. Centralized Algorithm,[0],[0]
"The pseudo code of ROBUSTCORESET-CENTRALIZED is given in Algorithm 1.
",4.1. Centralized Algorithm,[0],[0]
The sets {A⌧} and B are the outputs (core-set) of ROBUSTCORESET-CENTRALIZED.,4.1. Centralized Algorithm,[0],[0]
"In Appendix B , we show how ROBUST-CENTRALIZED (with pseudo code given in Algorithm 2) returns a solution for submodular maximization problem after the deletion of set D.
Theorem 1.",4.1. Centralized Algorithm,[0],[0]
"For any > 0, by setting ✏ = 2 3 , ROBUSTCORESET-CENTRALIZED and ROBUST-CENTRALIZED satisfy the following properties:
• ROBUST-CENTRALIZED outputs a set S such that |S|  k and E[f(S)]",4.1. Centralized Algorithm,[0],[0]
"(1/2 ) · OPT.
• ROBUST-CORESET-CENTRALIZED outputs at most O (k + d log k/ 2) elements as the core-set.
",4.1. Centralized Algorithm,[0],[0]
•,4.1. Centralized Algorithm,[0],[0]
The query complexities of ROBUST-CORESETCENTRALIZED and ROBUST-CENTRALIZED are O ((k + log k/ )|V,4.1. Centralized Algorithm,[0],[0]
"|) and O ((k + d log k/ 2)(log k/ )).
",4.1. Centralized Algorithm,[0],[0]
"Algorithm 2 ROBUST-CENTRALIZED
1: Input: {A0 ⌧ } and B0 {A0 ⌧ and B0 contain ele-
ments of A⌧ and B (outputs of ROBUST-CORESETCENTRALIZED) after deletion.}
2: Output: Set S of cardinality at most k 3: 00 the largest value of {f({e})|e 2 {[A0⌧} [B0} 4: T0 = {(1 + ✏)i| 0 0
2(1+✏)k  (1 + ✏) i  00}
5: for ⌧ 2 T0 from the highest to the lowest do 6: S⌧ S ⌧ 02T0,⌧ 0 ⌧ A 0 ⌧ 0 7: for all e 2 B0 do 8: if f (e|S⌧ ) ⌧ and |S⌧ | < k then 9: S⌧ S⌧ [ e
10: Return argmaxS⌧ f(S⌧ )",4.1. Centralized Algorithm,[0],[0]
"In many applications, the dataset does not fit in the main memory of a single machine or even the data itself arrives as a stream.",4.2. Streaming Algorithm,[0],[0]
So it is not possible to use centralized algorithms which need random access to the whole data.,4.2. Streaming Algorithm,[0],[0]
"In this section, we present a streaming algorithm with a limited available memory.",4.2. Streaming Algorithm,[0],[0]
We first use the thresholding idea of Section 4.1 in order to find a core-set for V. Then we show that it is possible to find a good solution from this core-set when deletion happens.,4.2. Streaming Algorithm,[0],[0]
"Recall that for ROBUST-CORESETCENTRALIZED, the maximum singleton element and the thresholds are fixed while in the streaming setting, they may change as new elements arrive.",4.2. Streaming Algorithm,[0],[0]
"To apply ideas of the centralized algorithm, we should overcome the following challenges: (i) it is not possible to make several passes over the data for different thresholds (i.e., we cannot start from the largest possible marginal gain to the lowest), and (ii) the value of 0 and d are not known a priori.
",4.2. Streaming Algorithm,[0],[0]
We show that it is possible to maintain a good approximation of OPT even with a single pass over the data.,4.2. Streaming Algorithm,[0],[0]
"From now on, let 0 and d, respectively, denote the largest and the (d+ 1)-th largest singleton values in the stream of data at time step t. First, note that d  OPT and the marginal gain of all the currently received elements is at most 0.",4.2. Streaming Algorithm,[0],[0]
"Therefore, it is enough to consider thresholds in the range [ d2k , 0].",4.2. Streaming Algorithm,[0],[0]
A new threshold is instantiated when the maximum singleton element is changed.,4.2. Streaming Algorithm,[0],[0]
These new (increasing) thresholds are between the current maximum and the previous one.,4.2. Streaming Algorithm,[0],[0]
"Therefore, all the elements with marginal gains larger than the new threshold will appear after its instantiation.
",4.2. Streaming Algorithm,[0],[0]
"ROBUST-CORESET-STREAMING, for each threshold ⌧ , keeps two sets A⌧ and B⌧ = [⌧ 0 ⌧B⌧,⌧ 0 .",4.2. Streaming Algorithm,[0],[0]
All the elements with marginal gains at least ⌧ to set A⌧ are good enough to be picked by this instance of the algorithm.,4.2. Streaming Algorithm,[0],[0]
"In order to make the selected elements robust to deletions, we should put all good enough elements in different B⌧,⌧ 0 sets, with thresholds ⌧ 0 in the range [⌧, 0], based on their marginal values.",4.2. Streaming Algorithm,[0],[0]
"Whenever a set B⌧,⌧ 0 becomes large, we pick one
Algorithm 3 ROBUST-CORESET-STREAMING
1: T = {(1 + e)i|i 2 Z} 2: For each ⌧, ⌧ 0 2 T : {A⌧} ?",4.2. Streaming Algorithm,[0],[0]
"and {B⌧,⌧ 0} ?",4.2. Streaming Algorithm,[0],[0]
"3: for every arriving element et do 4: d the (d + 1)-th largest element of {f{e1}, · · · , {f{et}} 5: 0 the largest element of {f{e1}, · · · , {f{et}} 6: Tt = {(1 + ✏)i|",4.2. Streaming Algorithm,[0],[0]
"d2(1+✏)k  (1 + ✏)
i  d} 7: Delete all A⌧ and B⌧,⌧ 0 such the ⌧ or ⌧ 0 /2",4.2. Streaming Algorithm,[0],[0]
"Tt 8: for ⌧ 2 Tt do 9: if |A⌧ | < k and ⌧  f (e|A⌧ ) then
10: Add et to B⌧,⌧ 0 such that for ⌧ 0  ",4.2. Streaming Algorithm,[0],[0]
f (et|A⌧ ) <,4.2. Streaming Algorithm,[0],[0]
"⌧ 0(1 + ✏) 11: while 9⌧ 00 such that |B⌧,⌧ 00",4.2. Streaming Algorithm,[0],[0]
"| d/✏ do 12: Randomly pick an element e from B⌧,⌧ 00 and add it to A⌧ , i.e., A⌧ A⌧ [ {e} 13: For all e 2
S ⌧ 002Ti,⌧ 00 ⌧ B⌧,⌧ 00 recompute
f (e|A⌧ ) and re-place them in correct bins 14: for ⌧ 2 Tn do 15: B⌧ S ⌧ 02Tn,⌧ 0 ⌧ B⌧,⌧ 0 16: Return {A⌧}, {B⌧}
element of it randomly to add to A⌧ .",4.2. Streaming Algorithm,[0],[0]
This ensures that an element is picked from a large pool of almost similar elements.,4.2. Streaming Algorithm,[0],[0]
"Formally, all the elements with a marginal gain in the range [⌧ 0, ⌧ 0(1 + ✏)) are added to the set B⌧,⌧ 0 .",4.2. Streaming Algorithm,[0],[0]
"When the size of a B⌧,⌧ 0 is at least d/✏, we randomly pick an element from B⌧,⌧ 0 and add it to A⌧ .",4.2. Streaming Algorithm,[0],[0]
"Adding an element to A⌧ may decrease the marginal gains of elements in B⌧,⌧ 0 sets.",4.2. Streaming Algorithm,[0],[0]
"So we recompute their marginal gains and put them in the right B⌧,⌧ 00 set (they are kept if their marginal gains are at least ⌧ , otherwise they are discarded).",4.2. Streaming Algorithm,[0],[0]
"These changes may make another set large, so we keep adding elements to A⌧ while we find a large B⌧,⌧ 00 set.",4.2. Streaming Algorithm,[0],[0]
This process continues until a maximum of k elements are added to A⌧ or the stream of data ends.,4.2. Streaming Algorithm,[0],[0]
"Note that there are at most d elements with marginal gains in the range ( d, 0]; we can simply keep these elements (refer to it as set Vd).",4.2. Streaming Algorithm,[0],[0]
"For all d < ⌧  0, we have A⌧ = ?, because there is no pool of size at least d/✏ elements to pick from it.",4.2. Streaming Algorithm,[0],[0]
"Also, for B⌧,⌧ 0 sets, we do not need to cover the range ( d, 0] with too many thresholds.",4.2. Streaming Algorithm,[0],[0]
"Indeed, when d changes (it can only increase), we can update the set Vd and locate the removed elements from Vd into a correct B⌧,⌧ 0 .",4.2. Streaming Algorithm,[0],[0]
"Therefore, it is sufficient to consider only thresholds in the range[ d2k , d].",4.2. Streaming Algorithm,[0],[0]
"The pseudo code of ROBUST-CORESET-STREAMING is given in Algorithm 3.
",4.2. Streaming Algorithm,[0],[0]
"In Appendix D, we introduce another algorithm (called ROBUST-STREAMING) such that after deletion of any set D from the core-set finds a solution with an expected approximation guarantee of 1 3✏2 to the optimum solution.
",4.2. Streaming Algorithm,[0],[0]
Theorem 2.,4.2. Streaming Algorithm,[0],[0]
"For any > 0, by setting ✏ = 2 3 , ROBUSTCORESET-STREAMING and ROBUST-STREAMING satisfy the following properties:
Algorithm 4 ROBUST-DISTRIBUTED 1: for e 2 V do 2: Assign e to a machine i chosen uniformly at random; 3: Let Vi be the elements assigned to machine i 4: Run ROBUST-CORESET-CENTRALIZED (Algorithm 1)
on each machine to obtain {Ai ⌧ } and Bi
5: Run ROBUST-CENTRALIZED (Algorithm 2) on each {Ai
⌧ 0} and Bi0 to get the set Si of cardinality at most k from each machine {{Ai
⌧ 0} and Bi0 are elements of {Ai
⌧ } and Bi after deletion of set D.}
6: S argmaxSi{f(Si)} 7: T GREEDY({ S i S ⌧2Ti",4.2. Streaming Algorithm,[0],[0]
"A i ⌧ 0} S { S i B
i0}) 8: Return argmax{f(T ), f(S)}
• ROBUST-STREAMING outputs a set S such that |S|  k and E[f(S)]",4.2. Streaming Algorithm,[0],[0]
"(1/2 ) · OPT.
• ROBUST-CORESET-STREAMING makes one pass over the dataset.
",4.2. Streaming Algorithm,[0],[0]
"• ROBUST-CORESET-STREAMING outputs at most O k log k/ + d log2 k/ 3 elements as the core-set.
",4.2. Streaming Algorithm,[0],[0]
•,4.2. Streaming Algorithm,[0],[0]
The query complexities of ROBUST-CORESETSTREAMING and ROBUST-STREAMING are O |V,4.2. Streaming Algorithm,[0],[0]
| log k/ + dk log2 k/ 3 and,4.2. Streaming Algorithm,[0],[0]
O,4.2. Streaming Algorithm,[0],[0]
d log3 k/ 4 .,4.2. Streaming Algorithm,[0],[0]
"In this section, build upon ideas from (Mirzasoleiman et al., 2013; Mirrokni & Zadimoghaddam, 2015; Barbosa et al., 2015), we present a robust distributed submodular maximization algorithm, called ROBUST-DISTRIBUTED.",4.3. Distributed Algorithm,[0],[0]
"We prove that our distributed algorithm finds an (↵, d)-robust randomized core-set with a constant ↵ and any arbitrary d.
ROBUST-DISTRIBUTED is a two-round distributed algorithm within a MapReduce framework.",4.3. Distributed Algorithm,[0],[0]
It first randomly partitions dataset between m machines.,4.3. Distributed Algorithm,[0],[0]
"Each machine i runs ROBUST-CORESET-CENTRALIZED on its data and passes the result (i.e., sets {Ai
⌧ } and Bi) to a central machine.",4.3. Distributed Algorithm,[0],[0]
"Af-
ter the deletion of the set D, this single central machine runs m instances of ROBUST-CENTRALIZED on the outputs received from each machine",4.3. Distributed Algorithm,[0],[0]
i and finds solutions Si.,4.3. Distributed Algorithm,[0],[0]
"In addition, it runs the classical GREEDY on the union of sets received from all machines (i.e., union of all sets {Ai
⌧ 0} and B
i0) to find another solution T .",4.3. Distributed Algorithm,[0],[0]
The final solution is the best answer among T and sets Si.,4.3. Distributed Algorithm,[0],[0]
ROBUST-DISTRIBUTED is outlined in Algorithm 4.,4.3. Distributed Algorithm,[0],[0]
Theorem 3.,4.3. Distributed Algorithm,[0],[0]
"For any > 0, by setting ✏ = /2, ROBUSTDISTRIBUTED outputs a set S, |S|  k such that E[f(S)]",4.3. Distributed Algorithm,[0],[0]
"↵ /(↵+ ) · OPT, where ↵ = 1/3 and = 1 1/e.",4.3. Distributed Algorithm,[0],[0]
This results in an approximation factor of 0.218 .,4.3. Distributed Algorithm,[0],[0]
Corollary 1.,4.3. Distributed Algorithm,[0],[0]
Running ROBUST-CORESET-CENTRALIZED on the output of ROBUST-DISTRIBUTED produces a compact core-set of size O (k + d log k/ 2).,4.3. Distributed Algorithm,[0],[0]
"Also, ROBUSTCENTRALIZED finds a solution with (0.109 )-
approximation guarantee from this compact core-set.",4.3. Distributed Algorithm,[0],[0]
"We refer to this version of our distributed algorithm as COMPACTDISTRIBUTED.
",4.3. Distributed Algorithm,[0],[0]
The main motivation of COMPACT-DISTRIBUTED is that the memory complexity does not increase with the number of machines m (while it still provides a constant factor approximation).,4.3. Distributed Algorithm,[0],[0]
"In this section, we extensively evaluate the performance of our algorithms on several publicly available real-world datasets.",5. Experimental Results,[0],[0]
We consider algorithms that can be robust to the deletion of any number of items and return k elements after deletion.,5. Experimental Results,[0],[0]
"Note that both OSU (Orlin et al., 2016) and PRO-GREEDY (Bogunovic et al., 2017) are robust to the deletion of only o(k) items.",5. Experimental Results,[0],[0]
"For this reason, we compare our proposed methods with three other baselines: (i) ROBUST (Mirzasoleiman et al., 2017), (ii) STAR-T-GREEDY (Mitrovic et al., 2017), and (iii) the stochastic greedy algorithm (Mirzasoleiman et al., 2015) (SG), where we first obtain a solution S of size r = 6k (we set r > k to make the solution robust to deletion), and then we report GREEDY(S \D) as the final answer.
",5. Experimental Results,[0],[0]
"In our experiments, we evaluate the effect of three parameters: (i) d where an algorithm is designed to be robust to d deletions; (ii) cardinality constraint k of the final solution; and (iii) number of deleted elements r.",5. Experimental Results,[0],[0]
The objective value of all algorithms are normalized to the utility obtained from a classical greedy algorithm that knows the set of deleted items D beforehand.,5. Experimental Results,[0],[0]
"Note that we are able to guarantee the performance of our algorithms (also this is true for ROBUST (Mirzasoleiman et al., 2017) and STAR-T-GREEDY (Mitrovic et al., 2017))",5. Experimental Results,[0],[0]
"only when the number of deletions r is less than d. While the theoretical improvements of our algorithms for larger values of d is more significant (see Table 1), for a fair comparison, we used the experimental setting of Mirzasoleiman et al. (2017).",5. Experimental Results,[0],[0]
"In these experiments, we also evaluate the effect of larger number of deletions, i.e., where r d.",5. Experimental Results,[0],[0]
"We observe, even though our algorithms are not designed for such higher number of deletions, they demonstrate a gracefully robust behavior.",5. Experimental Results,[0],[0]
"In a wide range of applications, data can be represented as a kernel matrix K, which encodes the similarity between different items in the database.",5.1. Location Privacy,[0],[0]
"In order to find a representative set S of cardinality k, a common objective function is
f(S) = log det(I + ↵KS,S), (2)
where KS,S is the principal sub-matrix of K indexed by S and ↵ > 0 is a regularization parameter (Herbrich et al., 2003; Seeger, 2004; Krause & Guestrin, 2005).",5.1. Location Privacy,[0],[0]
"This function is monotone submodular.
",5.1. Location Privacy,[0],[0]
"In this section, we analyze a dataset of 10,000 geolocations.
",5.1. Location Privacy,[0],[0]
"Each data entry is longitude and latitude coordinates of Uber pickups in Manhattan, New York in April 2014 (UberDataset).",5.1. Location Privacy,[0],[0]
Our goal is to find k representative samples using the objective function described in Eq.,5.1. Location Privacy,[0],[0]
(2).,5.1. Location Privacy,[0],[0]
"The similarity of two location samples i and j is defined by a Gaussian kernel Ki,j = exp( d2i,j/h2), where the distance di,j (in meters) is calculated from the coordinates and h is set to 5000.",5.1. Location Privacy,[0],[0]
"We set d = 5, i.e., we make algorithms (theoretically) robust to deletion of at most five elements.",5.1. Location Privacy,[0],[0]
"To compare the effect of deletions on the performance of algorithms, we use two strategies to choose the deleted items: (i) classical greedy algorithm, and (ii) the stochastic greedy algorithm.
",5.1. Location Privacy,[0],[0]
"In the first experiment, we study the effect of deleting different number of items on the normalized objective values.",5.1. Location Privacy,[0],[0]
"To refer to an algorithm with a specific deletion strategy, we use the name of algorithm followed by the deletion strategy, e.g., Rob-Stream-G refers to ROBUST-STREAMING where the deleted items are picked by greedy strategy.",5.1. Location Privacy,[0],[0]
"From Fig. 1a, we observe that ROBUST-STREAMING and ROBUST-CENTRALIZED are more robust to deletion than ROBUST and SG.",5.1. Location Privacy,[0],[0]
The effect of deleting by greedy strategy on the performance of algorithms is more pronounced than SG strategy.,5.1. Location Privacy,[0],[0]
"It can be seen that, even by deleting more than d = 5 items, our algorithms maintain their performance.",5.1. Location Privacy,[0],[0]
"Also, SG (which is not designed to be robust to deletions) shows the worst performance.
",5.1. Location Privacy,[0],[0]
"Other than normalized objective values, the memory requirement of each algorithm is quite important.",5.1. Location Privacy,[0],[0]
"Indeed, we are interested in deletion-robust algorithms that do not keep many items.",5.1. Location Privacy,[0],[0]
Fig.,5.1. Location Privacy,[0],[0]
1b compares the memory complexity of algorithms.,5.1. Location Privacy,[0],[0]
We observe that ROBUST-CENTRALIZED needs to keep the least number of items.,5.1. Location Privacy,[0],[0]
"For ROBUST algorithm, the memory complexity increases super linear in k (it is O(k log k)), which makes it quite impractical for large values of k and d. Also, we observe ROBUST-STREAMING outperforms STAR-T-GREEDY in both objective function and memory requirement.",5.1. Location Privacy,[0],[0]
"To sum-up, we observe that our algorithms provide the best of two worlds: while their normalized objective values are clearly better than other baselines, they need to keep much fewer number of items.",5.1. Location Privacy,[0],[0]
One of the challenges in learning from high dimensional data is to select a subset of relevant features in a computationally feasible way.,5.2. Submodular Feature Selection,[0],[0]
"For this reason, the quality of a subset of features S can be captured by the mutual information between attributes in S and the class variable Y (Krause & Guestrin, 2005).",5.2. Submodular Feature Selection,[0],[0]
"More specifically,
I(Y ;XS) = X
y2Y
X
x2XS
p(x, y) log2
✓ p(x, y)
p(x)p(y)
◆ ,
where XS is a random variable that represents the set S of k features.",5.2. Submodular Feature Selection,[0],[0]
"The joint distribution on (Y,X1, · · · , Xk),
under the Naive Bayes assumption, is defined by p(y, x1, · · · , xk) = p(y) Q k
i=1 p(xi|y).",5.2. Submodular Feature Selection,[0],[0]
This assumption makes the computation of joint distribution tractable.,5.2. Submodular Feature Selection,[0],[0]
"In our experiments, we estimate each p(xi|y) by counting frequencies in the dataset.",5.2. Submodular Feature Selection,[0],[0]
"In the feature selection problem, the goal is to choose k features such that maximizing f(S) = I(Y ;XS).",5.2. Submodular Feature Selection,[0],[0]
"It is known that the function f(S) = I(Y ;XS), under the Naive Bayes assumption, is monotone submodular (Krause & Guestrin, 2005).
",5.2. Submodular Feature Selection,[0],[0]
"In this section and Appendix G, we use this feature selection method on two real datasets.",5.2. Submodular Feature Selection,[0],[0]
"We first show that our algorithms, after the deletion of sensitive features (i.e., features that might cause unfairness in the final classifier) provide results with near optimal quality (based on mutual information).",5.2. Submodular Feature Selection,[0],[0]
"Second, we demonstrate that classifiers that are trained on these selected features perform very well.
",5.2. Submodular Feature Selection,[0],[0]
"In the first experiment, we use the Adult Income dataset from UCI Repository (Blake & Merz, 1998).",5.2. Submodular Feature Selection,[0],[0]
"This dataset contains information about 32,561 individuals and whether income of those individuals is over 50K a year.",5.2. Submodular Feature Selection,[0],[0]
We extract 113 binary features from this dataset.,5.2. Submodular Feature Selection,[0],[0]
"The goal of the classification task is to predict the income status of 16,281 test cases.",5.2. Submodular Feature Selection,[0],[0]
"For the deletions, we remove sensitive features that might result in the unfairness, e.g., features about sex, race, nationality, marital status and relationship status.",5.2. Submodular Feature Selection,[0],[0]
Fig.,5.2. Submodular Feature Selection,[0],[0]
1c compares algorithms based on different number of deletions for k = 5 and k = 10.,5.2. Submodular Feature Selection,[0],[0]
"We observe that for both values of k, ROBUST-CENTRALIZED considerably outperforms ROBUST (Mirzasoleiman et al., 2017) and SG.",5.2. Submodular Feature Selection,[0],[0]
"Also, the performance of ROBUST is better than SG.
To further investigate the effect of deletions, we compare accuracy of different classifiers, where each is trained on the features found by our algorithms and baselines.",5.2. Submodular Feature Selection,[0],[0]
"We train two type of classifiers: (i) Naive Bayes (Zhang, 2004) and (ii) SVM (Smola & Schölkopf, 2004).",5.2. Submodular Feature Selection,[0],[0]
"From Table 2, we observe that a SVM classifier, which is trained over all features, results in an accuracy of 83.0%.",5.2. Submodular Feature Selection,[0],[0]
"If we use a greedy algorithm to find the best 5 features and train SVM classifier on those features, the accuracy will drop to 79.6% (clearly there is a trade off between the number of features and accuracy).",5.2. Submodular Feature Selection,[0],[0]
"After deleting 10 features that might result in unfairness in classification (e.g., race and sex), we again use the greedy algorithm to find the best five features (referred to as GREEDYD).",5.2. Submodular Feature Selection,[0],[0]
The accuracy in this case is 79.3%.,5.2. Submodular Feature Selection,[0],[0]
"Interestingly, we observe that the accuracies of classifiers which are trained on the features found by ROBUST-CENTRALIZED and ROBUST-STREAMING drop only by 0.2%.",5.2. Submodular Feature Selection,[0],[0]
"Also, for Naive Bayes classifier, we do not observe any decrease on the accuracy when we train on the features found by our algorithms.",5.2. Submodular Feature Selection,[0],[0]
"Finally, both Centralized (22) and Streaming (29) algorithms need to keep fewer number of items than ROBUST (39) and STAR-T-GREEDY (50).",5.2. Submodular Feature Selection,[0],[0]
"To evaluate the performance of ROBUST-DISTRIBUTED on large datasets, we consider the Census1990 dataset from UCI Repository (Blake & Merz, 1998).",5.3. Large Data Summarization,[0],[0]
"This dataset consists of 2,458,285 data points with 68 features.",5.3. Large Data Summarization,[0],[0]
We are going to find k representative samples from this large dataset.,5.3. Large Data Summarization,[0],[0]
We apply the set selection objective function described in Eq.,5.3. Large Data Summarization,[0],[0]
(2).,5.3. Large Data Summarization,[0],[0]
"The similarity between two entries x and x0 is defined by 1 kx x
0kp 68 , where kx x0k is the Euclidean distance between feature vectors of x and x0.
",5.3. Large Data Summarization,[0],[0]
We randomly split the dataset into m = 12 partitions.,5.3. Large Data Summarization,[0],[0]
"For each instance of ROBUST-CORESET-CENTRALIZED, we set d = 25 with an ✏ = 0.1.",5.3. Large Data Summarization,[0],[0]
"As a baseline, we consider a distributed version of stochastic greedy algorithm (refer to it as SG-DISTRIBUTED).",5.3. Large Data Summarization,[0],[0]
"For this algorithm, we first run stochastic greedy on each partitions to select Si = 6k items.",5.3. Large Data Summarization,[0],[0]
"After deletion of D, we report f(GREEDY([Si \D))",5.3. Large Data Summarization,[0],[0]
as the final result.,5.3. Large Data Summarization,[0],[0]
"Also, we normalize the utility of functions to the objective value of an instance of SG-DISTRIBUTED that knows the set of deleted items D in advance.",5.3. Large Data Summarization,[0],[0]
"For deletions, we propose four different strategies: D1 randomly deletes 50% of items, D2 randomly deletes 80% of items, D3 deletes all men in the dataset, and D4 deletes all women.
",5.3. Large Data Summarization,[0],[0]
"We investigate the effect of different deletion strategies for
two values of k 2 {50, 100}.",5.3. Large Data Summarization,[0],[0]
In Figs.,5.3. Large Data Summarization,[0],[0]
"2a and 2b, we observe that ROBUST-DISTRIBUTED clearly outperforms SGDISTRIBUTED in all cases.",5.3. Large Data Summarization,[0],[0]
"Furthermore, we observe that the objective value of ROBUST-DISTRIBUTED in all scenarios is even better than our reference function for normalization (normalized objective values are larger than 1).",5.3. Large Data Summarization,[0],[0]
Each machine on average stores 209.3 (for k = 50) and 348.3 (for k = 100) items.,5.3. Large Data Summarization,[0],[0]
"The standard deviations of memory complexities are 36.9 and 26.5, respectively.",5.3. Large Data Summarization,[0],[0]
"To conclude, ROBUST-DISTRIBUTED enables us to robustly summarize a dataset of size 2,458,285 with storing only ⇡4500 items.",5.3. Large Data Summarization,[0],[0]
Our experimental results confirm that this core-set is robust to the deletion of even 80% of items.,5.3. Large Data Summarization,[0],[0]
"In this paper, we considered the problem of deletion-robust submodular maximization.",6. Conclusion,[0],[0]
"We provided the first scalable and memory-efficient solutions in different optimization settings, namely, centralized, streaming, and distributed models of computation.",6. Conclusion,[0],[0]
We rigorously proved that our methods enjoy constant factor approximations with respect to the optimum algorithm that is also aware of the deleted set of elements.,6. Conclusion,[0],[0]
We showcased the effectiveness of our algorithms on real-word problems where part of data should be deleted due to privacy and fairness constraints.,6. Conclusion,[0],[0]
Amin Karbasi was supported by a DARPA Young Faculty Award (D16AP00046) and a AFOSR Young Investigator Award (FA9550-18-1-0160).,Acknowledgements,[0],[0]
Ehsan Kazemi was supported by the Swiss National Science Foundation (Early Postdoc.,Acknowledgements,[0],[0]
Mobility) under grant number 168574.,Acknowledgements,[0],[0]
Can we efficiently extract useful information from a large user-generated dataset while protecting the privacy of the users and/or ensuring fairness in representation?,abstractText,[0],[0]
We cast this problem as an instance of a deletion-robust submodular maximization where part of the data may be deleted or masked due to privacy concerns or fairness criteria.,abstractText,[0],[0]
"We propose the first memory-efficient centralized, streaming, and distributed methods with constant-factor approximation guarantees against any number of adversarial deletions.",abstractText,[0],[0]
"We extensively evaluate the performance of our algorithms on real-world applications, including (i) Uber-pick up locations with location privacy constraints; (ii) feature selection with fairness constraints for income prediction and crime rate prediction; and (iii) robust to deletion summarization of census data, consisting of 2,458,285 feature vectors.",abstractText,[0],[0]
Our experiments show that our solution is robust against even 80% of data deletion.,abstractText,[0],[0]
Scalable Deletion-Robust Submodular Maximization: Data Summarization with Privacy and Fairness Constraints,title,[0],[0]
"Multi-label learning (Gibaja & Ventura, 2015; 2014) is the problem of assigning to an object a subset of labels from a potentially very large label vocabulary (Prabhu & Varma, 2014; Jain et al., 2016; Babbar & Schölkopf, 2017).",1. Introduction,[0],[0]
"In contrast to binary or multi-class classification, in multilabel learning, each example is associated with a binary label vector (potentially very large), denoting the presence/absence (relevance/irrelevance) of each label.",1. Introduction,[0],[0]
"Multilabel learning has applications in several domains such as computer vision (Wang et al., 2016), computational adver-
*Equal contribution 1Department of Computer Science and Enginerring, IIT Kanpur, Kanpur 208016, UP, India.",1. Introduction,[0],[0]
"Correspondence to: Vikas Jain <vikasj@iitk.ac.in>, Nirbhay Modhe <nirbhaym@iitk.ac.in>, Piyush Rai <piyush@cse.iitk.ac.in>
Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
tising and recommender systems (Prabhu & Varma, 2014; Jain et al., 2016), etc.
",1. Introduction,[0],[0]
Several state-of-the-art methods for multi-label learning are based on certain structural assumptions on the binary label matrix.,1. Introduction,[0],[0]
"Some of the key structural assumptions that have been used in prior work include low-rank assumption (Yu et al., 2014), locally low-rank assumption (Bhatia et al., 2015), and low-rank plus sparse assumption (Xu et al., 2016), and clusters/topics of labels assumption (Cissé et al., 2016; Rai et al., 2015).",1. Introduction,[0],[0]
"Models based on these assumptions are broadly dubbed as embedding based methods for multi-label learning and offer two key advantages: (1) The relatedness/correlation among labels can be easily modeled/captured, and (2) the label vector for each example can be represented as a low-dimensional embedding, which faciliates developing computationally scalable models for multi-label learning.",1. Introduction,[0],[0]
"A more detailed discussion of prior work is provided in the Related Work section.
",1. Introduction,[0],[0]
"Despite the considerable recent interest and progress on the problem of multi-label learning (Yu et al., 2014; Bhatia et al., 2015; Wang et al., 2016; Cissé et al., 2016), a number of important issues still remain.",1. Introduction,[0],[0]
"One of such issues, especially for the embdding based methods, is the ambiguity regarding the zeros vs unobserved (missing) entries in the binary label vector of each example.",1. Introduction,[0],[0]
"Since, in practice, the true value (0/1) for only a small subset of all the labels can be obtained, the zeros in the label vector do not necessarily represent negative labels.",1. Introduction,[0],[0]
"A typical heuristic employed by multi-label learning algorithms is to simply treat all such the zeros in the label vector as are true negatives (Yu et al., 2014).",1. Introduction,[0],[0]
"Another heuristic is to assign different weights to the zeros and ones in the binary label matrix (Yu et al., 2017), which is inspired by matrix factorization based collaborative filtering models that learn from implicit (binary) feedback data (Hu et al., 2008).",1. Introduction,[0],[0]
"However, a more principled strategy to address this issue is highly desirable.
",1. Introduction,[0],[0]
"Another important desideratum is scalability, especially in the case of extreme multi-label learning problems (Prabhu & Varma, 2014; Jain et al., 2016; Babbar & Schölkopf, 2017), which are characterized by a massive number of labels, features, and examples.",1. Introduction,[0],[0]
"Although a number of recent multi-label learning models have been proposed that can scale to large-scale problems, these models usually require
large computational resources to truly scale to massive data sets (Babbar & Schölkopf, 2017; Bhatia et al., 2015; Jain et al., 2016).",1. Introduction,[0],[0]
"Moreover, most of the scalable multi-label learning algorithms only operate in batch setting and are usually not designed to work (Prabhu & Varma, 2014; Bhatia et al., 2015; Jain et al., 2016) in online settings with continuous stream of training examples.
",1. Introduction,[0],[0]
"In this paper, we present a scalable, generative framework for multi-label learning, that not only bring to bear the modeling flexibility of probabilistic, generative models for the multi-label learning problem (Kapoor et al., 2012; Rai et al., 2015), but is also designed to handle the abovementioned challenges in a principled way.",1. Introduction,[0],[0]
"Our framework is based on a latent factor model for the binary label matrix, and has the following distinguishing aspects: (1) It naturally handles the issue of missing vs negative labels via a principled generative model with a exposure model (Liang et al., 2016) for the label matrix; (2) It is accompanied by a simple and scalable inference procedure (both via Gibbs sampling and via fast point estimation); and (3) Inference can also be easily performed in an online fashion, enabling us to apply it on large-scale problems, even when using moderate computational resources.",1. Introduction,[0],[0]
"In the multi-label learning problem, we assume that we are givenN training examples {(x1,y1), . . .",2. The Model,[0],[0]
", (xN ,yN )}",2. The Model,[0],[0]
"with xn ∈ RD and yn ∈ {0, 1}L, n = 1, . . .",2. The Model,[0],[0]
", N .",2. The Model,[0],[0]
"We will denote X = {x1, . . .",2. The Model,[0],[0]
",xN} ∈ RN×D to be the feature matrix and Y = {y1, . . .",2. The Model,[0],[0]
",yN} ∈ {0, 1}N×L to be the label matrix.",2. The Model,[0],[0]
"Given training data {X,Y}, the goal in multi-label learning is to learn a model that can predict the label vector y∗ ∈ {0, 1}L for a new test input x∗ ∈ RD.
",2. The Model,[0],[0]
Note that an entry yn` = 0 in the label matrix Y may not necessarily mean a negative label but could simply mean that this label is missing (and its true value could be 0 or 1).,2. The Model,[0],[0]
"As we shall show, our generative model can infer the missingness of a label yn` = 0 by associating another binary latent variable ξn` (called exposure variable).",2. The Model,[0],[0]
These exposure variables will be incorporated in a latent factor model (Sec. 2.1) for the label matrix Y and are jointly learned along with the rest of the model parameters.,2. The Model,[0],[0]
We model the binary label matrix Y using a latent factor model.,2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"Specifically, we assume that each training example n = 1, . . .",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
", N is associated with a latent factor un ∈ RK and each label ` = 1, . . .",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
", L is associated with a latent factor v` ∈ RK .",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
We further condition un on the feature vector xn ∈,2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
RD of example n,2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"by as-
suming that the prior distribution of un is conditioned on xn, as p(un|xn) = N (un|Wxn, λ−1u IK).",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"Here, W =",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"[w1, . . .",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
",wK ]
> ∈ RK×D which denotes the matrix of regression weights that map the feature vectorxn to the mean of the Gaussian prior on un.",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"We further assume a zeromean Gaussian prior p(v`) = N (v`|0, λ−1v IK) on label latent factors v`, ` = 1, . . .",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
", L. Note that, although we do not consider it here, our model can also be easily extended to incorporate label features (if available) by conditioning Gaussian prior on v` on those label features, in the same manner we condition the prior on un on input features.
",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"The complete generative story for each label yn` of the binary label matrix Y is given by
un|xn ∼ N (un|Wxn, λ−1u IK) (1) v` ∼ N (v`|0, λ−1v IK) (2) ξn` ∼ Bernoulli(µn`) (3)
yn` ∼
{ Bernoulli ( yn`|σ(u>n v`) ) , if ξn` = 1
δ0, if ξn` = 0 (4)
where σ(z) = 1/(1 + exp(−z))",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
denotes the logistic function.,2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"Note that we have associated a binary exposure latent variable ξn` with each label yn` such that ξn` = 0 implies that yn` is 0 because it is missing (not exposed), and ξn` = 1 implies that yn` is exposed (and could be 0 or 1 depending on the outcome of the Bernoulli draw).",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"In Eq. 4, δ0 denotes a point-mass at zero, which means that, if ξn` = 0, then yn` is zero with probability 1.",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"Otherwise, we draw the observed label yn` from a Bernoulli distribution as yn` ∼ Bernoulli(yn`|σ(u>n v`)).",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"Note that, effectively, each yn` is being modeled using a mixture of two distributions - a Bernoulli with probability given by the sigmoid σ(u>n v`)) and a point-mass at 0.
",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
yn` ∼ ξn`Bern ( yn`|σ(u>n v`) ),2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"+ (1− ξn`)I[yn` = 0] (5)
Note that the latent variable ξn` decides which of the two distributions from this mixture generates yn`.",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
Figure 1 shows our model in the plate notation.,2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"Also note that if yn` = 1 then ξn` = 1 with probability 1 and therefore ξn` only needs to be inferred for entries for which yn` = 0.
",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
The generative model specified in Eq (1)-(4) has two additional parameters: W =,2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"[w1, . . .",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
",wK ]> ∈ RK×D which denotes the matrix of regression weights that map each input feature vector xn to the corresponding latent factor un ∈ RK , and a probability parameter µn` ∈ (0, 1) which denotes the probability of the label yn` being exposed (but note that yn` can be 0 or 1, depending on the outcome of Bernoulli(yn`|σ(u>n v`))).",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"We refer to µn` as the exposure probability of label ` for example n.
We assume each regression weight vector wk to have a Gaussian prior, i.e., wk ∼ N (wk|0, λ−1w ID).",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"Note that the spherical covariance of this prior can also be replaced by a more flexible diagonal covariance, which will give the model ability to perform feature selection.
",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"For the exposure probability µn`, we consider two types of priors.",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"In the first case, we simply assume µn` = µ`, ∀n, which means that the probability that a label ` is observed is the same for all the examples (i.e., the label exposure for the label ` is global, not example specific).",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"In this case, we assume a Beta prior on µ`, i.e., µ` ∼ Beta(α1, α2).",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"In the second case, we assume access to some contexual information (often available in applications such as recommender systems) that we may have for each example-label pair (n, `), in form of some given covariates φn` ∈ RM .",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"Given these covariates, we model the label exposure probability as µn` = σ(β>φn`), where β ∈ RM is a vector of regression coefficients.",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"We assume a Gaussian prior on β, i.e., β ∼ N (β|0, λ−1β IM )",2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix,[0],[0]
"Although the generative model specified in Eq. 1-4 is not readily conjugate because the logistic-Bernoulli likelihood is not conjugate to the Gaussian prior on the latent factors, we can leverage data-augmentation techniques (Polson et al., 2013) to make the model locally conjugate.",3. Inference,[0],[0]
This enables us to develop a simple Gibbs sampling algorithm for doing inference in our model.,3. Inference,[0],[0]
"The conjugacy also allows us to design an online expectation maximization (EM) algorithm (Cappé & Moulines, 2009), which enables us to apply our model on large-scale problems.
",3. Inference,[0],[0]
"We handle the non-conjugate logistic-Bernoulli likelihood using the Pólya-gamma augmentation technique (Polson et al., 2013), which is based on the following identity
(exp(ψ)a
(1 + exp(ψ))b = 2−b exp (κψ) ∫ ∞ 0",3. Inference,[0],[0]
exp ( −ωψ2/2 ),3. Inference,[0],[0]
"p(ω)dω
where κ = a − b/2 and p(ω) = PG(b, 0) denotes the Pólya-gamma distribution (Polson et al., 2013).",3. Inference,[0],[0]
"This identity allows us to write any likelihood of the form
(exp(ψ)a
(1+exp(ψ))b (e.g., Bernoulli, binomial, negative-binomial) as a Gaussian distribution, when conditioned on a PG random variable ω|ψ ∼ PG(b, ψ).",3. Inference,[0],[0]
"Specifically, using PG augmentation, we can write the logistic-Bernoulli likelihood
from Eq. 4 as a Gaussian when conditioned on ωn` ∼ PG(1,u>n v`).",3. Inference,[0],[0]
"In particular, ψn` = u > n v`, conditioned on ωn`, becomes a Gaussian p(ψn`|ωn`) ∝",3. Inference,[0],[0]
"exp ( κn`ψn` − 1
2 ωn`ψ
2 n`
) (6)
where κn` = yn` − 0.5.",3. Inference,[0],[0]
This likelihood with the Gaussian priors on the latent factors un and v` results in Gaussian posteriors onun and v`.,3. Inference,[0],[0]
"When doing EM, this also leads to subproblems that are like least square regression problems.",3. Inference,[0],[0]
"Using the PG augmentation, we can derive the posterior distributions of all the latent variables in our model, and perform Gibbs sampling for doing inference in our model.",3.1. Gibbs Sampling,[0],[0]
"Due to conjugacy, the inference updates are straightforward to derive as are summarized below.
",3.1. Gibbs Sampling,[0],[0]
"Sampling ξn`: Note that if yn` = 1 then ξn` = 1 with probability one, and therefore need not be inferred.",3.1. Gibbs Sampling,[0],[0]
"For yn` = 0, we sample ξn` from the posterior
p(ξn` = 1|.) ∝",3.1. Gibbs Sampling,[0],[0]
µn`σ(−u,3.1. Gibbs Sampling,[0],[0]
>,3.1. Gibbs Sampling,[0],[0]
n v,3.1. Gibbs Sampling,[0],[0]
`) (7) p(ξn` = 0|.),3.1. Gibbs Sampling,[0],[0]
∝,3.1. Gibbs Sampling,[0],[0]
"(1− µn`)× 1 (8)
Sampling µn`: For the case when µn` = µ`, ∀n, with Beta(α1, α2) prior on each µ`, the posterior will be
p(µn`|.)",3.1. Gibbs Sampling,[0],[0]
= Beta(α1 + N∑ n=1,3.1. Gibbs Sampling,[0],[0]
"ξn`, α2 +N",3.1. Gibbs Sampling,[0],[0]
"− N∑ n=1 ξn`) (9) Note that, if we parameterize each µn` as µn` = σ(β>φn`) where φn` is the interaction feature vector for the examplelabel pair, and the regresssion weight β is assumed to have a Gaussian prior, the model is not conjugate.",3.1. Gibbs Sampling,[0],[0]
"However, using the PG augmentation allows us to easily derive a closed-form Gaussian posterior for β.
",3.1. Gibbs Sampling,[0],[0]
Sampling un:,3.1. Gibbs Sampling,[0],[0]
"Given the PG variables Ωn,: = {ωn`}L`=1 and the other latent variables, the posterior of un will be un ∼ N (un|µun ,Σun) where the covariance is given by Σun = ( ∑L `=1 ξn`ωn`v`v >",3.1. Gibbs Sampling,[0],[0]
"` + λuIK)
−1",3.1. Gibbs Sampling,[0],[0]
and the mean is given by µun = Σun( ∑L `=1 ξn`κn`v` + λuWxn).,3.1. Gibbs Sampling,[0],[0]
"Note that if a label ` is inferred as not exposed for example n, i.e., ξn` = 0, it does not contribute to the update of un.
",3.1. Gibbs Sampling,[0],[0]
"Sampling v`: Given Ω:,` = {ωn`}Nn=1 and the other latent variables, the posterior v` will be v` ∼ N (v`|µv` ,Σv`) where covariance Σv` = ( ∑N n=1 ξn`ωn`unu > n",3.1. Gibbs Sampling,[0],[0]
"+λvIK) −1
and the mean µv` = Σv`( ∑N n=1 ξn`κn`un).",3.1. Gibbs Sampling,[0],[0]
"Note that if an example n is inferred as not exposed to label `, i.e., ξn` = 0, it does not contribute to the update of v`.
",3.1. Gibbs Sampling,[0],[0]
Sampling W:,3.1. Gibbs Sampling,[0],[0]
Each row {wk}Kk=1 of the regression weights matrix W =,3.1. Gibbs Sampling,[0],[0]
"[w1, . . .",3.1. Gibbs Sampling,[0],[0]
",wK ]> ∈ RK×D will have a Gaussian posterior given by wk ∼ N",3.1. Gibbs Sampling,[0],[0]
"(wk|µwk ,Σwk) where covariance Σwk = (X >X + λwID) −1, the mean µwk = Σwk(X >U), and U =",3.1. Gibbs Sampling,[0],[0]
"[u1, . . .",3.1. Gibbs Sampling,[0],[0]
",uN ] ∈ RK×N .",3.1. Gibbs Sampling,[0],[0]
"Although the Gibbs sampler (Sec. 3.1) is easy to derive and implement in practice, sampling tends to be slow in practice and convergence may be slow.",3.2. Scalable Inference via EM and Online EM,[0],[0]
"We therefore present an online expectation maximization algorithm (Cappé & Moulines, 2009) for doing efficient inference in our model.",3.2. Scalable Inference via EM and Online EM,[0],[0]
"We first show the batch EM updates for our model parameters and then describe the online EM algorithm which can process the training data in small mini-batches of examples, and results in faster convergence in practice.",3.2. Scalable Inference via EM and Online EM,[0],[0]
"The EM algorithm for our model alternates between computing the expectations of the local latent variables, namely the Pólya-gamma variables {ωn`} and the binary exposure latent variables {ξn`} in the E step, and then using these expectations to estimate the other model parameters un, v`, W, and exposure probabilities {µn`} in the M step.
",3.2.1. THE EM ALGORITHM,[0],[0]
The E Step:,3.2.1. THE EM ALGORITHM,[0],[0]
"The E step involves computing the expectations of the latent variables {ωn`} and {ξn`}, given the current values of the other model parameters un, v`, W, and µn` estimated in the previous M step.",3.2.1. THE EM ALGORITHM,[0],[0]
"The E step update equations are given below:
• Expectations of Pólya-gamma variables {ωn`}, ∀n, ` are known to be available in closed form (Scott & Sun, 2013), and are given by
ηn` = E[ωn`|ψn`] = 1
2ψn` tanh ( ψn` 2 ) (10)
",3.2.1. THE EM ALGORITHM,[0],[0]
where ψn` = u>n v` is computed using the estimates of un and vm from the previous M step.,3.2.1. THE EM ALGORITHM,[0],[0]
"• Expectations of each of the binary exposure variables ξn`, ∀n, `, are given by
pn` = E[ξn`|ψn`] = µn`σ(−ψn`)
µn`σ(−ψn`)",3.2.1. THE EM ALGORITHM,[0],[0]
"+ (1− µn`) (11)
",3.2.1. THE EM ALGORITHM,[0],[0]
The M Step:,3.2.1. THE EM ALGORITHM,[0],[0]
"Given the expectations of the latent variables computed in the E step, the M step maximizes the following expected complete data log-likelihood plus logprior terms, which we denote as Q(U,V,W,µ), where U = {un}Nn=1, V = {v`}L`=1, W, and µ = {µn`}, ∀n, `
Q(U,V,W,µ) =",3.2.1. THE EM ALGORITHM,[0],[0]
"− 1
2 ∑ n,` pn` (κn` − ηn`u>n v`) 2 ηn`
+ ∑ n,` log Bernoulli(pn`|µn`)− λu N∑ n=1 ||un −Wxn||2 − λv L∑
`=1 ||v`||2 − λw||W||2 + ∑ n,` log Beta(µn`|α1, α2) (12)
Note that the first term in the objective function given in Eq. 12 is due to the logistic likelihood transformed into a Gaussian (using PG augmentation).",3.2.1. THE EM ALGORITHM,[0],[0]
"This term is akin to a weighted least squares objective where each label being
associated with a weight pn` = E[ξn`|ψn`].",3.2.1. THE EM ALGORITHM,[0],[0]
"Intuitively, in the first term, the contribution of each label yn` to the loglikelihood gets modulated based on its expected exposure.
",3.2.1. THE EM ALGORITHM,[0],[0]
"Maximizing Q(U,V,W,µ) w.r.t.",3.2.1. THE EM ALGORITHM,[0],[0]
"each of the model parameters U,V,W,µ, fixing the rest, yields closed-form updates for each of these.",3.2.1. THE EM ALGORITHM,[0],[0]
"The updates are as follows: • Estimating each of the latent factors {un}Nn=1 is a
weighted ridge-regression problem with solution
un = Σun ( L∑ `=1 pn`κn`v` + λuWxn ) (13)
where Σun = ( ∑L `=1 pn`ηn`v`v >",3.2.1. THE EM ALGORITHM,[0],[0]
"` + λuIK)
−1.",3.2.1. THE EM ALGORITHM,[0],[0]
"Note that the updates for {un}Nn=1 are all independent of each other and are easily parallelizable.
",3.2.1. THE EM ALGORITHM,[0],[0]
"• Estimating each of the label latent factors {v`}L`=1 is a weighted ridge-regression problem with solution
v` = Σv` ( N∑ n=1 pn`κn`un ) (14)
where Σv` = (∑N n=1 pn`ηn`unu > n",3.2.1. THE EM ALGORITHM,[0],[0]
+ λvIK )−1 .,3.2.1. THE EM ALGORITHM,[0],[0]
"Again, note that the updates for {vn}L`=1 are all independent of each other and are easily parallelizable.
",3.2.1. THE EM ALGORITHM,[0],[0]
"• Estimating the regression weight matrix W is equivalent to solving a vector-valued linear regression problem un ≈Wxn, ∀n, with the following updates
W> = (X>X + λwID) −1(X",3.2.1. THE EM ALGORITHM,[0],[0]
">U) (15)
Note that solving Eq.",3.2.1. THE EM ALGORITHM,[0],[0]
"(15) exactly requires inverting a D × D matrix which will be expensive for large D. However, the EM algorithm does not require solving for W exactly in each M step.",3.2.1. THE EM ALGORITHM,[0],[0]
"We therefore solve for W efficient using gradient based methods, such as conjugate-gradient (CG) method (Bertsekas, 1999), which allows us to also leverage the sparsity in the feature matrix X. Typically, a small number of CG iterations are sufficient in practice.
",3.2.1. THE EM ALGORITHM,[0],[0]
•,3.2.1. THE EM ALGORITHM,[0],[0]
"Given pn` from the E step, the updates for µn` for the case when µn` = µ`, ∀n, is simply the MAP solution
µ` = α1 +
∑N n=1",3.2.1. THE EM ALGORITHM,[0],[0]
"pn` − 1
α1 + α2 +N",3.2.1. THE EM ALGORITHM,[0],[0]
"− 2 (16)
",3.2.1. THE EM ALGORITHM,[0],[0]
"For the other case when each µn` in modeled as µn` = σ(β>φn`) with a Gaussian prior on β, estimating β reduces to solving a regression problem with the training data being {φn`, pn`}, ∀n, `, where φn` is the given feature vector for the input-label pair n, ` and pn` is estimated in the E step.",3.2.1. THE EM ALGORITHM,[0],[0]
"Ignoring the prior term (equivalent to `2 regularizer on β), we can estimate β iteratively using gradient-descent updates
β = β",3.2.1. THE EM ALGORITHM,[0],[0]
"− τ NL ∑ n,` (σ(β>φn`)− pn`)φn` (17)
where τ denotes the learning rate.",3.2.1. THE EM ALGORITHM,[0],[0]
The EM algorithm described in Section 3.2.1 is more efficient than the Gibbs sampler described in Section 3.1.,3.2.2. ONLINE EM,[0],[0]
"It is also highly parallelizable since the updates for {u}Nn=1 and {v`}L`=1 can be easily parallelized, and solve for W efficiently using CG updates.",3.2.2. ONLINE EM,[0],[0]
"However, it is a batch procedure and requires going over the entire training data in every iteration.",3.2.2. ONLINE EM,[0],[0]
"For large-scale multi-label learning problems, which are characterized by large N , D, and L, the batch setting may not be feasible in practice, especially when having access to moderate computational resources and storage.
",3.2.2. ONLINE EM,[0],[0]
We therefore present an efficient online version of the EM algorithm for our model which allows it to scale up to massive-sized data sets even on machines with moderate hardware.,3.2.2. ONLINE EM,[0],[0]
"As we show in our experiments, this enables us to apply our model to be run efficiently on massive data sets (e.g., one of the data sets we experiment with has more than 600k examples with about 50k features per example) even on a standard laptop with very moderate hardware.
",3.2.2. ONLINE EM,[0],[0]
The online EM algorithm works by maintaining sufficient statistics of all the model parameters and updates these sufficient statistics with every mini-batch of data.,3.2.2. ONLINE EM,[0],[0]
"For each mini-batch of training examples, the E step computes the relevant expectations associated with these observations and then uses the expectations to update the sufficient statistics of the parameters to be estimated in the M step.
",3.2.2. ONLINE EM,[0],[0]
"For example, noting that the sufficient statistics for updating the label latent factors v` = A−1b are given by A =∑N n=1 pn`ηn`unu > n",3.2.2. ONLINE EM,[0],[0]
"+λvIK and b = ∑N n=1 pn`κn`un, we can update A and b using a small mini-batch containingNb examples as {(xn,yn)}",3.2.2. ONLINE EM,[0],[0]
"Nb n=1 as follows
A(t+1)",3.2.2. ONLINE EM,[0],[0]
=,3.2.2. ONLINE EM,[0],[0]
(1− γt)A(t),3.2.2. ONLINE EM,[0],[0]
+ γtA(new) (18) b(t+1) =,3.2.2. ONLINE EM,[0],[0]
"(1− γt)b(t) + γtb(new) (19)
where A(new) = ( ∑Nb n=1 pn`ηn`unu > n",3.2.2. ONLINE EM,[0],[0]
"+ λvIK), and
b(new) = ∑Nb n=1 pn`κn`un are computing using only the current mini-batch.",3.2.2. ONLINE EM,[0],[0]
The sufficient statistics of the other model parameters can also be updated in the same manner.,3.2.2. ONLINE EM,[0],[0]
"Here γt is a decaying learning rate (or a forgetting factor), which also acts as a trade-off between the contribution from the old sufficient statistics computed thus far and the sufficient statistics contribution from the new minibatch of data.",3.2.2. ONLINE EM,[0],[0]
"We set γt = (a0 + t)− with a0 = 1 and to be close to 0.5 (Cappé & Moulines, 2009).",3.2.2. ONLINE EM,[0],[0]
"Given a new test input x∗, we first predict its latent factor u∗ ∈ RK as Wx∗ and then predict each entry of its label vector y∗ as E[y∗`|u∗,v`] = σ(u>∗ v`).",3.2.3. PREDICTION,[0],[0]
"If we are only interested in the top few labels, fast search methods such as maximum inner product search (Fraccaro et al., 2016) can be used to reduce the computational cost at test time.",3.2.3. PREDICTION,[0],[0]
"A prominent line of work on multi-label learning has been based on models that learn a low-dimensional embedding of the label vectors (Chen & Lin, 2012; Yu et al., 2014; Rai et al., 2015; Bhatia et al., 2015).",4. Related Work,[0],[0]
"Note that this amounts to assuming that the label matrix is low-rank.
",4. Related Work,[0],[0]
"Since many real-world data sets have a large number of rare labels, sometimes the low-rank assumption may not be appropriate.",4. Related Work,[0],[0]
"To address this issue, (Bhatia et al., 2015) proposed a method which assumes the label matrix to be locally low-rank.",4. Related Work,[0],[0]
One way to impose this assumption is to learn embeddings that only try to preserve distances in a small neighborhood of each example.,4. Related Work,[0],[0]
"Another approach to handle the rare labels is to assume that the label matrix is a sum of a low-rank and a sparse matrix (Xu et al., 2016).
",4. Related Work,[0],[0]
"Note that our latent factor model is equivalent to imposing a low-rank assumption on the label matrix, and is therefore similar in spirit to the label-embedding approaches.",4. Related Work,[0],[0]
"However, unlike the existing label-embedding based approaches, our generative framework has a principled mechanism to handle/infer the unobserved labels.",4. Related Work,[0],[0]
"Moreover, none of the existing label-embedding methods can work in online fashion, and scaling up these methods to largescale problems requires large computational resources.",4. Related Work,[0],[0]
"In addition, our model readily allows incorporating the label features (if available) by a simple modification to the prior on the label latent factors.
",4. Related Work,[0],[0]
"Apart from the label-embedding based multi-label learning methods, tree-based methods for multi-label learning (Agrawal et al., 2013; Prabhu & Varma, 2014; Jain et al., 2016) are also popular due to being fast at test time, especially when the number of labels is large.",4. Related Work,[0],[0]
"However, these models usually have high training costs and cannot be trained easily in an online fashion, unlike our model.",4. Related Work,[0],[0]
"On the other hand, for faster predictions at test time, our framework model can easily be adapting by replacing the Gaussian prior on the label latent factors v` by a von MisesFisher prior (Fraccaro et al., 2016), which naturally facilitates using maximum inner-product search techniques, without the requirement of any post-processing.
",4. Related Work,[0],[0]
"Among other models to address the missing labels problem in multi-label learning, recently, (Kanehira & Harada, 2016) proposed a ranking based framework for learning from positive and unlabeled data in the context of multilabel learning.",4. Related Work,[0],[0]
"Although this is similar in spirit to our model in terms of not treating the unobserved labels as zeros, the approach in (Kanehira & Harada, 2016) is fundamentally different than ours.",4. Related Work,[0],[0]
"Moreover, their setting is not amenable to online learning, nor does it leverage the lowrank structure of label matrices with a huge number of labels.",4. Related Work,[0],[0]
"Other approaches that try to handle missing labels in-
clude (Bucak et al., 2011) which uses group LASSO adaptation of a multi-label ranking objective, and (Kong et al., 2014), which learns a model using a positive and unlabeled (PU) stochastic gradient descent procedure.",4. Related Work,[0],[0]
"However, it works in batch setting, uses stacking to leverage label correlations, and does not scale to large number of labels.
",4. Related Work,[0],[0]
"One-class matrix factorization (OCMF) is also an approach (Yu et al., 2017) to solve the missing labels problem by assigning different (but fixed) weights to the ones and zeros.",4. Related Work,[0],[0]
"In contrast to this method, our generative framework can learn the weight for each label by modeling these weights as latent variables.",4. Related Work,[0],[0]
"In another recent work, (Liang et al., 2016) proposed an exposure model for recommender system problems posed as matrix factorization of implicit feedback data.",4. Related Work,[0],[0]
"Their approach of modeling the exposure similar in spirit to our framework.
",4. Related Work,[0],[0]
"Some of the early works on generative models for multilabel learning problems include models specifically designed for image annotation problems (Barnard et al., 2003; Feng et al., 2004).",4. Related Work,[0],[0]
"Other recent attempts on doing multilabel learning in more general problem settings include models such as Bayesian compressive sensing (Kapoor et al., 2012) and multi-label learning using Bayesian nonnegative matrix factorization (Rai et al., 2015).",4. Related Work,[0],[0]
"However, these models do not have a mechanism to distinguish between unobserved and negative labels, have complicated inference, and do not scale to large-scale problems.
",4. Related Work,[0],[0]
Our generative framework is also amenable for various interesting extensions.,4. Related Work,[0],[0]
"For example, it can be be extended to a mixture of latent factor models, which can handle the situation when the label matrix is not low-rank but a mixture of several low-rank matrices.",4. Related Work,[0],[0]
"Note that such an extension would be a fully generative counter-part of the model in (Bhatia et al., 2015) which learns a locally low-rank model but has to rely on an ad-hoc clustering step beforehand, which is known to be unstable in practice (Bhatia et al., 2015).",4. Related Work,[0],[0]
"Another nice aspect of our framework is that is naturally allows active learning (Kapoor et al., 2012; Vasisht et al., 2014) where we can selectively ask for most informative labels for an unannotated example.",4. Related Work,[0],[0]
"Moreover, our framework is flexible and inference in our model can be performed in a fully Bayesian manner (e.g., MCMC or variational inference) as well as fast point estimation methods such as (online)",4. Related Work,[0],[0]
"EM, that we used in this work.
",4. Related Work,[0],[0]
"To summarize, our generative framework offers a flexible way to model the label generation mechanism for real-world multi-label data sets, which most of the existing models currently lack.",4. Related Work,[0],[0]
We can model label missingness/observability rigorously under our framework and infer the model parameters easily using a simple inference procedure.,4. Related Work,[0],[0]
"Moreover, the simplicity of the inference procedure makes it easy to design scalable inference algorithms,
such as online EM for our model, which enables updating the model whenever fresh training data is available.",4. Related Work,[0],[0]
"This is in contrast to some of the other state-of-the-art multi-label learning methods, which although scalable (Bhatia et al., 2015; Prabhu & Varma, 2014; Jain et al., 2016), are not suitable to be applied in such online settings.",4. Related Work,[0],[0]
We evaluate our framework on a number of benchmark data sets and compare it with several state-of-the-art methods.,5. Experiments,[0],[0]
Our baselines include both label-embedding methods as well as tree-based methods.,5. Experiments,[0],[0]
"The statistics of data sets we use in our experiments are summarized in Table 1.
",5. Experiments,[0],[0]
"We report both quantitative results (in terms of label prediction accuracies) as well as some qualitative results, namely looking at the relationship of empirical label frequencies and label exposure.",5. Experiments,[0],[0]
"Note that the label frequency for a given label denotes how many examples had this label as 1, while label exposure µ` ∈ (0, 1) in general refers to how popular the label ` is.
",5. Experiments,[0],[0]
"In our experiments, we compare with the following stateof-the-art baselines.
",5. Experiments,[0],[0]
• LEML:,5. Experiments,[0],[0]
"This is a low-rank embedding based multilabel learning model (Yu et al., 2014).",5. Experiments,[0],[0]
LEML assumes the label matrix Y to be modeled as Y ≈ UV where U = XW,5. Experiments,[0],[0]
". LEML considers various types of loss functions such as squared loss, logistic loss, hinge loss, etc.",5. Experiments,[0],[0]
"Interestingly, note that LEML with logistic loss can be seen as a special non-probabilistic case of our model when also considering λu → ∞, and the label exposure model turned off.
",5. Experiments,[0],[0]
"• BCS: Bayesian Compressive Sensing (BCS) is a generative model (Kapoor et al., 2012) for the label vector.",5. Experiments,[0],[0]
"It assumes a compressive sensing model for the label vectors and is essentially a low-rank model.
",5. Experiments,[0],[0]
• FastXML,5. Experiments,[0],[0]
": This is a fast tree-based multi-label learning model which uses an ensemble of trees (Prabhu & Varma, 2014).
",5. Experiments,[0],[0]
• PfasterXML,5. Experiments,[0],[0]
:,5. Experiments,[0],[0]
"This is an extension of FastXML and uses propensity-weighted scores to improve performance on rare labels (Jain et al., 2016).
",5. Experiments,[0],[0]
"• PD-Sparse: This model takes a different approach as compared to label-embedding methods and uses a margin-maximizing loss for the multi-label learning problem (Yen et al., 2016).
",5. Experiments,[0],[0]
"For the baselines, the reported results are either obtained using publicly available implementations (with the recommended hyperparameter settings), or the publicly known best results.",5. Experiments,[0],[0]
"We refer to our model as GenEML (for Generative Exposure-based model for Multi-label Learning)
",5. Experiments,[0],[0]
"Hyperparameter Settings: For our model, we set the hyperparameters λu and λv to 0.001, which works well on all the data sets we experimented with.",5. Experiments,[0],[0]
We select the other two hyperparameters λw and K (number of latent factors) using cross-validation.,5. Experiments,[0],[0]
"On small-/medium-scale data, both EM and online EM perform comparably and we only report the results using online EM.",5. Experiments,[0],[0]
"On large data sets, we only use online EM.",5. Experiments,[0],[0]
"On the small and medium-scale data, we however also show a separate experiment comparing EM and online EM for our model in terms of convergence speed versus accuracy.",5. Experiments,[0],[0]
"For the conjugate gradient (CG) method used by the M step of our inference algorithm, we run 5 iterations, which was found to be sufficient.",5. Experiments,[0],[0]
"For online EM, for each data set, we use mini-batch sizes of 1024 and 4096 and report the one which gives better results.",5. Experiments,[0],[0]
"In our first experiment, we assess the benefit of using the exposure model.",5.1.1. BENEFIT OF EXPOSURE MODEL,[0],[0]
"For this, we apply our model with and without exposure on a synthetic data set.",5.1.1. BENEFIT OF EXPOSURE MODEL,[0],[0]
"For this experiment, we generate a synthetic data set with N=500, D=100, and L=20 and use varying degrees of exposure probabilities µ` ∈ {0.01, 0.05, 0.1, 0.3, 0.5, 0.9} for the different labels ` = 1, . . .",5.1.1. BENEFIT OF EXPOSURE MODEL,[0],[0]
", 20.",5.1.1. BENEFIT OF EXPOSURE MODEL,[0],[0]
"We also create a test set with 500 test examples.
",5.1.1. BENEFIT OF EXPOSURE MODEL,[0],[0]
The results are shown in Table 2.,5.1.1. BENEFIT OF EXPOSURE MODEL,[0],[0]
"As the results show, our model with exposure turned on outperforms the model when the exposure is turned off.",5.1.1. BENEFIT OF EXPOSURE MODEL,[0],[0]
"This clearly demonstrate the benefit of the exposure model when a significant fraction of labels are missing (i.e., not exposed).",5.1.1. BENEFIT OF EXPOSURE MODEL,[0],[0]
Our model also outperforms LEML which does not have a mechanism to model label exposure.,5.1.1. BENEFIT OF EXPOSURE MODEL,[0],[0]
"In our next set of experiments, in Table 3 we compare our model (with exposure on) with the other baselines, in terms of Precision@1, Precision@3, and Precision@5 scores.",5.1.2. PREDICTION ACCURACIES,[0],[0]
"As Table 3 shows, our model outperforms the other baselines in most of the cases, except for the RCV and Wikipedia data, on which our model is outperformed by LEML and/or PfasterXML.",5.1.2. PREDICTION ACCURACIES,[0],[0]
"Note, however, that these stateof-the-art baselines use batch inference methods whereas we only ran our model in the online setting on a moderate 4 core processor with 8GB RAM.",5.1.2. PREDICTION ACCURACIES,[0],[0]
"Moreover, our results may further improve with a more careful hyperparameter tuning (including selection of minibatch size).",5.1.2. PREDICTION ACCURACIES,[0],[0]
"The point of the large-scale data experiment was to mainly show that the our model can be feasibly run on such large-scale data sets, on standard machines with moderate computational resources.",5.1.2. PREDICTION ACCURACIES,[0],[0]
Most of the other existing models for multi-label learning are infeasible to run under such restrictive settings.,5.1.2. PREDICTION ACCURACIES,[0],[0]
The online version of our EM algorithm is scalable and faster than its batch counterpart.,5.1.3. BATCH EM VS ONLINE EM,[0],[0]
"Fig 2 shows that online EM converges faster and to a precision score which is very similar to the batch EM on Bibtex and Mediamill datasets.
",5.1.3. BATCH EM VS ONLINE EM,[0],[0]
"Furthermore, online inference is also more effecient, storage-wise, due the need of maintaining just the sufficient statistics as in Eq 19 for the updates of each latent factor un and v`.",5.1.3. BATCH EM VS ONLINE EM,[0],[0]
"For very large datasets, the size of the the sufficient statistics (a D ×D covariance matrix) for updating the regression weight matrix W might not be feasible to store and update.",5.1.3. BATCH EM VS ONLINE EM,[0],[0]
"Therefore, we use cheap, first-order gradient based updates for finding an approximate solution to the update equation of W in each iteration of the EM algorithm (note that we need not solve for W exactly; the EM algorithm just requires a few steps of updates for W in the M step).",5.1.3. BATCH EM VS ONLINE EM,[0],[0]
"This further reduces the memory requirement of our model, while also speeding up inference due to faster computation of gradients as compared to CG updates.",5.1.3. BATCH EM VS ONLINE EM,[0],[0]
"Finally, we do some qualitative analyses of our model’s behavior.",5.2. Qualitative Results,[0],[0]
"We investigate whether the global frequency of a label necessarily correlates to its exposure probability.
",5.2. Qualitative Results,[0],[0]
"While it may be the case for some data sets where high label frequency implies a high inferred label exposure probability (e.g., see Fig. 3 for Bibtex and Mediamill data), it need not be the case with other data sets.",5.2. Qualitative Results,[0],[0]
"For example, for Movielens data, each user-movie (example-label) pair has an some context information (user and movie features) available for it.",5.2. Qualitative Results,[0],[0]
"As we show in Fig 4, the inferred exposure probability (which depends on the context features) of the same movie (label) indeed turns out to be different for different users (examples).
",5.2. Qualitative Results,[0],[0]
"Fig. 4 shows the plot of inferred exposure probabilities µnl for two users (one female, one male) plotted against the label frequencies (movie popularities).
",5.2. Qualitative Results,[0],[0]
"As Fig. 4 shows, our model infers that, a popular movie (shown in red dot in Fig 4) has a high exposure probability for the left user (Female, 25, Healthcare/Doctor) while it has a low exposure probability for the right user (Male, 35, artist).",5.2. Qualitative Results,[0],[0]
"This example illustrates that a high label frequency does not necessarily imply a high exposure probability, which can be context (user in this case) dependent.",5.2. Qualitative Results,[0],[0]
We presented a flexible and scalable generative framework for multi-label learning.,6. Conclusion,[0],[0]
"Our framework is based on a latent
factor model for the label matrix and does not assume that the zeros in the label matrix are necessarily negative labels.",6. Conclusion,[0],[0]
"We use a set of label exposure latent variables to model this, and infer these exposure probabilities from data.",6. Conclusion,[0],[0]
"Incorporating these latent variables leads to improve multi-label classification accuracies, and also enables doing interesting qualitative analyses.",6. Conclusion,[0],[0]
Our model admits a simple inference procedure which can be implemeted using Gibbs sampling or EM.,6. Conclusion,[0],[0]
"We further develop a highly scalable online EM algorithm for performing inference in our model, which allows our model to be applied on large-scale data sets, even on standard machines with moderate hardware.",6. Conclusion,[0],[0]
The generative framework makes it easy to extend our model in many interesting ways.,6. Conclusion,[0],[0]
"For example, it can be extended to a mixture of latent factor models, which will allow handling the cases where a single low-rank model does not adequately capture the structure of the label matrix.
",6. Conclusion,[0],[0]
"Acknowledgements: PR acknowledges support from Extreme Classification research grant from Microsoft Research India, DST-SERB Early Career Research Award, Dr. Deep Singh and Daljeet Kaur Fellowship, and Research-I Foundation, IIT Kanpur.",6. Conclusion,[0],[0]
"We present a scalable, generative framework for multi-label learning with missing labels.",abstractText,[0],[0]
"Our framework consists of a latent factor model for the binary label matrix, which is coupled with an exposure model to account for label missingness (i.e., whether a zero in the label matrix is indeed a zero or denotes a missing observation).",abstractText,[0],[0]
The underlying latent factor model also assumes that the low-dimensional embeddings of each label vector are directly conditioned on the respective feature vector of that example.,abstractText,[0],[0]
"Our generative framework admits a simple inference procedure, such that the parameter estimation reduces to a sequence of simple weighted leastsquare regression problems, each of which can be solved easily, efficiently, and in parallel.",abstractText,[0],[0]
"Moreover, inference can also be performed in an online fashion using mini-batches of training examples, which makes our framework scalable for large data sets, even when using moderate computational resources.",abstractText,[0],[0]
"We report both quantitative and qualitative results for our framework on several benchmark data sets, comparing it with a number of state-of-the-art methods.",abstractText,[0],[0]
Scalable Generative Models for Multi-label Learning with Missing Labels,title,[0],[0]
"Gaussian processes (GPs) are non-parametric models that can be used to address multi-class classification problems (Rasmussen & Williams, 2006).",1. Introduction,[0],[0]
These models become more expressive as the number of data instances N grows.,1. Introduction,[0],[0]
"They are also very useful to introduce prior knowledge in the learning problem, as many properties of the model are specified by a covariance function.",1. Introduction,[0],[0]
"Moreover, GPs provide an estimate of the uncertainty in the predictions made which may be critical in some applications.",1. Introduction,[0],[0]
"Neverthe-
*Equal contribution 1Universidad Autónoma de Madrid, Madrid, Spain.",1. Introduction,[0],[0]
"Correspondence to: Carlos Villacampa-Calvo <carlos.villacampa@uam.es>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
less, in spite of these advantages, GPs scale poorly to large datasets because their training cost is O(N3), where N is the number of instances.",1. Introduction,[0],[0]
"An additional challenge is that exact inference in these models is generally intractable and one has to resort to approximate methods in practice.
",1. Introduction,[0],[0]
"Traditionally, GP classification has received more attention in the binary case than in the multi-class setting (Kuss & Rasmussen, 2005; Nickisch & Rasmussen, 2008).",1. Introduction,[0],[0]
The reason is that approximate inference is more challenging in the multi-class case where there is one latent function per class.,1. Introduction,[0],[0]
"To this one has to add more complicated likelihood factors, which often have the form of softmax functions or intractable Gaussian integrals.",1. Introduction,[0],[0]
"In spite of these difficulties, there have been several works addressing multi-class GP classification (Williams & Barber, 1998; Kim & Ghahramani, 2006; Girolami & Rogers, 2006; Chai, 2012; Riihimäki et al., 2013).",1. Introduction,[0],[0]
"Nevertheless, most of the proposed methods do not scale well with the size of the training set.
",1. Introduction,[0],[0]
In the literature there have been some efforts to scale up GPs.,1. Introduction,[0],[0]
These techniques often introduce a set of M N inducing points whose location is learnt alongside with the other model hyper-parameters.,1. Introduction,[0],[0]
"The use of inducing points in the model can be understood as an approximate GP prior with a low-rank covariance structure (Quiñonero-Candela & Rasmussen, 2005).",1. Introduction,[0],[0]
"When inducing points are considered, the training cost can be reduced to O(NM2).",1. Introduction,[0],[0]
"This allows to address datasets with several thousands of instances, but not millions.",1. Introduction,[0],[0]
"The reason is the difficulty of estimating the model hyper-parameters, which is often done by maximizing an estimate of the log-marginal-likelihood.",1. Introduction,[0],[0]
"Because such an estimate does not involve a sum across the data instances, one cannot rely on efficient methods for optimization based on stochastic gradients and mini-batches.
",1. Introduction,[0],[0]
"A notable exception is the work of (Hensman et al., 2015a) which uses variational inference to approximate the calculations.",1. Introduction,[0],[0]
Such a method allows for stochastic optimization and can address datasets with millions of instances.,1. Introduction,[0],[0]
"In this work we propose an alternative based on expectation propagation (EP) (Minka, 2001) and recent advances on binary GP classification (Hernández-Lobato & HernándezLobato, 2016).",1. Introduction,[0],[0]
The proposed approach also allows for efficient training using mini-batches.,1. Introduction,[0],[0]
"This leads to a training
cost that is O(CM3), where C is the number of classes.",1. Introduction,[0],[0]
An experimental comparison with the variational approach and related methods from the literature shows that the proposed approach has benefits both in terms of the training speed and the accuracy of the predictive distribution.,1. Introduction,[0],[0]
Here we describe multi-class Gaussian process classification and the proposed method.,2. Scalable Multi-class Classification,[0],[0]
Such a method uses the expectation propagation algorithm whose original description is modified to be more efficient both in terms of memory and computational costs.,2. Scalable Multi-class Classification,[0],[0]
"For this, we consider stochastic gradients to update the hyper-parameters and an approximate likelihood that avoids one-dimensional quadratures.",2. Scalable Multi-class Classification,[0],[0]
"We consider a dataset of N instances in the form of a matrix of attributes X = (x1, . . .",2.1. Multi-class Gaussian Process Classification,[0],[0]
",xN )T with labels y = (y1, . . .",2.1. Multi-class Gaussian Process Classification,[0],[0]
", yN )
T, where yi ∈ {1, . . .",2.1. Multi-class Gaussian Process Classification,[0],[0]
", C} and C > 2 is the total number of different classes.",2.1. Multi-class Gaussian Process Classification,[0],[0]
"The task of interest is to predict the class label of a new data instance x?.
",2.1. Multi-class Gaussian Process Classification,[0],[0]
"A typical approach in multi-class Gaussian process (GP) classification is to assume the following labeling rule for yi given xi: yi = arg maxk f
k(xi), for k = 1, . . .",2.1. Multi-class Gaussian Process Classification,[0],[0]
", C, where each fk(·) is a non-linear latent function (Kim & Ghahramani, 2006).",2.1. Multi-class Gaussian Process Classification,[0],[0]
"Define fk = (fk(x1), . . .",2.1. Multi-class Gaussian Process Classification,[0],[0]
", f k(xN ))",2.1. Multi-class Gaussian Process Classification,[0],[0]
"T ∈ RN and fi = (f1(xi), . . .",2.1. Multi-class Gaussian Process Classification,[0],[0]
", f C(xi))
",2.1. Multi-class Gaussian Process Classification,[0],[0]
T ∈ RC .,2.1. Multi-class Gaussian Process Classification,[0],[0]
"The likelihood of f = (f1, . . .",2.1. Multi-class Gaussian Process Classification,[0],[0]
", fC)T ∈ RN×C , p(y|f) = ∏N i=1 p(yi|fi), is then a product of N factors of the form:
p(yi|fi) =",2.1. Multi-class Gaussian Process Classification,[0],[0]
"∏ k 6=yi Θ ( fyi(xi)− fk(xi) ) , (1)
where Θ(·) is the Heaviside step function.",2.1. Multi-class Gaussian Process Classification,[0],[0]
This likelihood takes value one if f can explain the observed data and zero otherwise.,2.1. Multi-class Gaussian Process Classification,[0],[0]
Potential classification errors can be easily introduced in (1) by considering that each fk has been contaminated with Gaussian noise with variance σ2k.,2.1. Multi-class Gaussian Process Classification,[0],[0]
"That is, fk(xi) = f̂ k(xi) +",2.1. Multi-class Gaussian Process Classification,[0],[0]
"k i , where k i ∼ N (0, σ2k).
",2.1. Multi-class Gaussian Process Classification,[0],[0]
"In multi-class GP classification a GP prior is assumed for each function fk(·) (Rasmussen & Williams, 2006).",2.1. Multi-class Gaussian Process Classification,[0],[0]
"Namely, fk ∼ GP(0, c(·, ·; ξ)), where c(·, ·; ξk) is some covariance function with hyper-parameters ξk.",2.1. Multi-class Gaussian Process Classification,[0],[0]
Often these priors are assumed to be independent.,2.1. Multi-class Gaussian Process Classification,[0],[0]
"That is, p(f) =∏C
k=1 p(f k), where each p(fk) is a multivariate Gaussian distribution.",2.1. Multi-class Gaussian Process Classification,[0],[0]
"The task of interest is to make inference about f and for that Bayes’ rule is used: p(f |y) = p(y|f)p(f)/p(y), where p(y) is a normalization constant (the marginal likelihood) which can be maximized to find good hyper-parameters ξk, for k = 1, . . .",2.1. Multi-class Gaussian Process Classification,[0],[0]
", C. However, because the likelihood in (1) is non-Gaussian, evaluating p(y)
and p(f |y) is intractable.",2.1. Multi-class Gaussian Process Classification,[0],[0]
"Thus, these computations must be approximated.",2.1. Multi-class Gaussian Process Classification,[0],[0]
"Often, one computes a Gaussian approximation to p(f |y) (Kim & Ghahramani, 2006).",2.1. Multi-class Gaussian Process Classification,[0],[0]
"This results in a non-parametric classifier with training cost O(N3), where N is the number of data instances.
",2.1. Multi-class Gaussian Process Classification,[0],[0]
To reduce the computational cost of the method described a typical approach is to consider a sparse representation for each GP.,2.1. Multi-class Gaussian Process Classification,[0],[0]
"With this goal, one can introduce C datasets of M N inducting points",2.1. Multi-class Gaussian Process Classification,[0],[0]
"Xk = (x1, . . .",2.1. Multi-class Gaussian Process Classification,[0],[0]
",xkM )T, with associated values f k",2.1. Multi-class Gaussian Process Classification,[0],[0]
"= (fk(xk1), . . .",2.1. Multi-class Gaussian Process Classification,[0],[0]
", f k(xkM ))",2.1. Multi-class Gaussian Process Classification,[0],[0]
"T for k = 1, . . .",2.1. Multi-class Gaussian Process Classification,[0],[0]
", C (Snelson & Ghahramani, 2006; NaishGuzman & Holden, 2008).",2.1. Multi-class Gaussian Process Classification,[0],[0]
"Given each X k the prior for
fk is approximated as p(fk) = ∫ p(fk|fk)p(fk|Xk)dfk ≈∫
[ ∏N
i=1",2.1. Multi-class Gaussian Process Classification,[0],[0]
p(f k,2.1. Multi-class Gaussian Process Classification,[0],[0]
"i (xi)|f
k )]",2.1. Multi-class Gaussian Process Classification,[0],[0]
"p(f k|Xk)dfk = pFITC(fk|X k ), in
which the conditional Gaussian distribution p(fk|fk) has been approximated by the factorizing distribution∏N
i=1",2.1. Multi-class Gaussian Process Classification,[0],[0]
p(f k,2.1. Multi-class Gaussian Process Classification,[0],[0]
"i (xi)|f
k ).",2.1. Multi-class Gaussian Process Classification,[0],[0]
"This approximation is known as the
full independent training conditional (FITC) (QuiñoneroCandela & Rasmussen, 2005), and it leads to a Gaussian prior pFITC(fk|X k ) with a low-rank covariance matrix.",2.1. Multi-class Gaussian Process Classification,[0],[0]
This allows for approximate inference with costO(NM2).,2.1. Multi-class Gaussian Process Classification,[0],[0]
The inducing points {Xk}Ck=1 can be regarded as hyperparameters and can be learnt by maximizing the estimate of the marginal likelihood p(y).,2.1. Multi-class Gaussian Process Classification,[0],[0]
The formulation of the previous section is limited because the estimate of the log-marginal-likelihood log p(y) cannot be expressed as a sum across the data instances.,2.2. Method Specification and Expectation Propagation,[0],[0]
"This makes infeasible the use of efficient methods based on stochastic optimization for finding the model hyper-parameters.
",2.2. Method Specification and Expectation Propagation,[0],[0]
"A recent work focusing on the binary case has shown that it is possible to obtain an estimate of log p(y) that involves a sum across the data instances if the values f k associated to the inducing points are not marginalized (HernándezLobato & Hernández-Lobato, 2016).",2.2. Method Specification and Expectation Propagation,[0],[0]
We follow that work and consider the posterior approximation p(f |y) ≈∫,2.2. Method Specification and Expectation Propagation,[0],[0]
"p(f |f)q(f)df , where f = (f1, . . .",2.2. Method Specification and Expectation Propagation,[0],[0]
", fC)T, p(f |f) =∏C k=1 p(f k|fk), we have defined p(f) = ∏C k=1 p(f k|Xk), and q is a Gaussian approximation to p(f |y).",2.2. Method Specification and Expectation Propagation,[0],[0]
This distribution q is obtained in three steps.,2.2. Method Specification and Expectation Propagation,[0],[0]
"First, we use on the exact posterior the FITC approximation:
p(f |y) = ∫ p(y|f)p(f |f)dfp(f)
p(y)",2.2. Method Specification and Expectation Propagation,[0],[0]
"≈ ∫ p(y|f)pFITC(f |f)dfp(f)
p(y) =",2.2. Method Specification and Expectation Propagation,[0],[0]
"[ ∏N i=1 φi(f)]p(f)
p(y) , (2)
where we have defined pFITC(f |f) = ∏N
i=1",2.2. Method Specification and Expectation Propagation,[0],[0]
"∏C k=1 p(f k(xi)
|fk)",2.2. Method Specification and Expectation Propagation,[0],[0]
"≈ p(f |f) = ∏C
k=1 p(f k|fk) and
φi(f) = ∫",2.2. Method Specification and Expectation Propagation,[0],[0]
[ ∏ k 6=yi Θ ( fyi(xi)− fk(xi) ),2.2. Method Specification and Expectation Propagation,[0],[0]
"]
× [ ∏C
k=1 p(f k(xi)|f k )]",2.2. Method Specification and Expectation Propagation,[0],[0]
"dfi , (3)
with p(fk(xi)|f k ) = N (fk(xi)|mki , vki ), where
mki = (k k
xiX k) T(Kk X k X k) −1f k , (4)
ski = κ k",2.2. Method Specification and Expectation Propagation,[0],[0]
xixi,2.2. Method Specification and Expectation Propagation,[0],[0]
"− (k k
xiX k) T(Kk X k X k) −1kk xiX k .",2.2. Method Specification and Expectation Propagation,[0],[0]
"(5)
",2.2. Method Specification and Expectation Propagation,[0],[0]
"In the previous expressions N (·|µ, σ2) is the p.d.f. of a Gaussian with mean µ and variance σ2.",2.2. Method Specification and Expectation Propagation,[0],[0]
"Furthermore, kk
xiX k
is a vector with the covariances between fk(xi) and f k; Kk XkXk
is a M ×M matrix with the cross covariances between fk; and, finally, κkxixi is the prior variance of f k(xi).
",2.2. Method Specification and Expectation Propagation,[0],[0]
A practical difficulty is that the integral in (3) is intractable.,2.2. Method Specification and Expectation Propagation,[0],[0]
"Although it can be evaluated using one-dimensional quadrature techniques (Hernández-Lobato et al., 2011), in this paper we follow a different approach.",2.2. Method Specification and Expectation Propagation,[0],[0]
"For that, we note that (3) is simply the probability that fyi(xi) > fk(xi) for k 6= yi, given f .",2.2. Method Specification and Expectation Propagation,[0],[0]
Let fyii = fyi(xi) and fki = fk(xi).,2.2. Method Specification and Expectation Propagation,[0],[0]
"The second step consists in approximating (3) as follows:
p( ⋂ k 6=yi f yi > fk) =p(fyi > f1|S1)×",2.2. Method Specification and Expectation Propagation,[0],[0]
"p(fyi > f2|S2)×
· · · × p(fyi > fyi−1|Syi−1)× p(f yi > fyi+1|Syi+1)× · · ·",2.2. Method Specification and Expectation Propagation,[0],[0]
"≈ ∏ k 6=yip(f yi > fk) = ∏ k 6=yi Φ(α k i ) , (6)
where Sj = ⋂
k/∈{1,...,j}∪{yi} f yi > fk, Φ(·) is the c.d.f. of a standard Gaussian and αki = (myii − m k i )/",2.2. Method Specification and Expectation Propagation,[0],[0]
"√ syii + s k i , with myii , m k i , s yi i and s k i defined in (5).",2.2. Method Specification and Expectation Propagation,[0],[0]
We have omitted in (6) the dependence on f to improve the readability.,2.2. Method Specification and Expectation Propagation,[0],[0]
The quality of this approximation is supported by the good experimental results obtained in Section 4.,2.2. Method Specification and Expectation Propagation,[0],[0]
"When (6) is replaced in (2) we get an approximate posterior distribution in which we can evaluate all the likelihood factors:
p(f |y)",2.2. Method Specification and Expectation Propagation,[0],[0]
≈ [ ∏N i=1,2.2. Method Specification and Expectation Propagation,[0],[0]
∏,2.2. Method Specification and Expectation Propagation,[0],[0]
k 6=yk φ k,2.2. Method Specification and Expectation Propagation,[0],[0]
"i (f)]p(f)
p(y) , (7)
where we have defined φki (f) =",2.2. Method Specification and Expectation Propagation,[0],[0]
"Φ(α k i ).
",2.2. Method Specification and Expectation Propagation,[0],[0]
The r.h.s.,2.2. Method Specification and Expectation Propagation,[0],[0]
of (7) is intractable due to the non-Gaussian form of the likelihood factors.,2.2. Method Specification and Expectation Propagation,[0],[0]
"The third and last step uses expectation propagation (EP) (Minka, 2001) to get a Gaussian approximation q to (7).",2.2. Method Specification and Expectation Propagation,[0],[0]
This approximation is obtained by replacing each φki with an approximate Gaussian factor,2.2. Method Specification and Expectation Propagation,[0],[0]
φ̃ k,2.2. Method Specification and Expectation Propagation,[0],[0]
"i :
φ̃ki (f) = s̃i,k exp { − 12 (",2.2. Method Specification and Expectation Propagation,[0],[0]
"f yi )TṼyii,kf yi + (f yi )Tm̃yii,k } ×
exp { − 12 (f k )",2.2. Method Specification and Expectation Propagation,[0],[0]
"TṼi,kf k + (f k )",2.2. Method Specification and Expectation Propagation,[0],[0]
"Tm̃i,k } , (8)
where Ṽyii,k = C",2.2. Method Specification and Expectation Propagation,[0],[0]
"1,yi",2.2. Method Specification and Expectation Propagation,[0],[0]
"i,k υ yi",2.2. Method Specification and Expectation Propagation,[0],[0]
"i (υ yi i ) T, m̃yii,k = C 2,yi",2.2. Method Specification and Expectation Propagation,[0],[0]
"i,k υ yi",2.2. Method Specification and Expectation Propagation,[0],[0]
"i , Ṽi,k = C1i,kυ k",2.2. Method Specification and Expectation Propagation,[0],[0]
"i (υ k i ) T, m̃i,k = C2i,kυ k",2.2. Method Specification and Expectation Propagation,[0],[0]
"i , and we have defined υ",2.2. Method Specification and Expectation Propagation,[0],[0]
k,2.2. Method Specification and Expectation Propagation,[0],[0]
i = (kk xiX k ) T(Kk X k X k ) −1.,2.2. Method Specification and Expectation Propagation,[0],[0]
"In (8) C1,yii,k , C 2,yi",2.2. Method Specification and Expectation Propagation,[0],[0]
"i,k , C 1 i,k, C 2",2.2. Method Specification and Expectation Propagation,[0],[0]
"i,k and s̃i,k are free parameters adjusted by EP.",2.2. Method Specification and Expectation Propagation,[0],[0]
"Because the precision matrices in (8) are one-rank (see the supplementary material for details), we only have to store in memory O(M) parameters for each φ̃ki .",2.2. Method Specification and Expectation Propagation,[0],[0]
"The posterior approximation q is obtained by replacing in (7) each exact factor φi,k by the corresponding approximate factor φ̃i,k.",2.2. Method Specification and Expectation Propagation,[0],[0]
"That is, q(f) = ∏N i=1",2.2. Method Specification and Expectation Propagation,[0],[0]
"∏ k 6=yi φ̃ k i (f)p(f)/Zq , where Zq is a normalization constant that approximates the marginal likelihood p(y).",2.2. Method Specification and Expectation Propagation,[0],[0]
"Because all the factors involved in the computation of q are Gaussian, and we assume independence among the latent functions of different classes in (8), q is a product of C multivariate Gaussians (on per class) on M dimensions.
",2.2. Method Specification and Expectation Propagation,[0],[0]
"In EP each φ̃ki is updated until convergence as follows: First, φki is removed from q by computing q
\i,k ∝ q/φ̃ki .",2.2. Method Specification and Expectation Propagation,[0],[0]
"Because the Gaussian family is closed under the product and division operations, q\i,k is also Gaussian with parameters given by the equations in (Roweis, 1999).",2.2. Method Specification and Expectation Propagation,[0],[0]
"Then, the Kullback-Leibler divergence between Z−1i,k φ k",2.2. Method Specification and Expectation Propagation,[0],[0]
"i q \i,k and q, i.e, KL[Z−1i,k φ k",2.2. Method Specification and Expectation Propagation,[0],[0]
"i q \i,k|q], is minimized with respect to q, where Zi,k is the normalization constant of φki q \i,k.",2.2. Method Specification and Expectation Propagation,[0],[0]
"This is done by matching the moments of Z−1i,k φ k",2.2. Method Specification and Expectation Propagation,[0],[0]
"i q \i,k. These moments can be obtained from the derivatives of Zi,k with respect to the parameters of q\i,k",2.2. Method Specification and Expectation Propagation,[0],[0]
"(Seeger, 2006).",2.2. Method Specification and Expectation Propagation,[0],[0]
"After updating q, the new approximate factor is φ̃i,k = Zi,kq/q\i,k.",2.2. Method Specification and Expectation Propagation,[0],[0]
"We update all the approximate factors at the same time, and reconstruct q afterwards by computing the product of all the φ̃ki and the prior, as in (Hernández-Lobato et al., 2011).
",2.2. Method Specification and Expectation Propagation,[0],[0]
"The EP approximation to the marginal likelihood is the normalization constant of q, Zq .",2.2. Method Specification and Expectation Propagation,[0],[0]
"The log of its value is:
logZq = g(θ)− g(θprior) +",2.2. Method Specification and Expectation Propagation,[0],[0]
"∑N
i=1 ∑ k 6=yk log s̃i,k , (9)
where log s̃i,k = logZi,k + g(θ\i,k)− g(θ); θ, θ\i,k, and θprior are the natural parameters of q, q\i,k and the prior, respectively; and g(θ) is the log-normalizer of a multi-variate Gaussian distribution with natural parameters θ.
",2.2. Method Specification and Expectation Propagation,[0],[0]
"It is possible to show that if EP converges, the gradient of logZq w.r.t the parameters of each φ̃i,k is zero.",2.2. Method Specification and Expectation Propagation,[0],[0]
"Thus, the gradient of logZq w.r.t.",2.2. Method Specification and Expectation Propagation,[0],[0]
"a hyper-parameter ξkj of the k-th covariance function (including the inducing points) is:
∂ logZq ∂ξkj = (ηT − ηTprior) ∂θprior ∂ξkj + N∑ i=1",2.2. Method Specification and Expectation Propagation,[0],[0]
"∑ k 6=yi logZi,k ∂ξkj , (10)
",2.2. Method Specification and Expectation Propagation,[0],[0]
"where η and ηprior are the expected sufficient statistics under q and the prior, respectively.",2.2. Method Specification and Expectation Propagation,[0],[0]
"Importantly, only the direct dependency of logZi,k on ξkj has to be taken into account.",2.2. Method Specification and Expectation Propagation,[0],[0]
"See (Seeger, 2006).",2.2. Method Specification and Expectation Propagation,[0],[0]
"The dependency through θ\i,k, i.e., the natural parameters of q\i,k can be ignored.
",2.2. Method Specification and Expectation Propagation,[0],[0]
"After obtaining q and finding the model hyper-parameters by maximizing logZq , one can get an approximate predictive distribution for the label y? of a new instance",2.2. Method Specification and Expectation Propagation,[0],[0]
"x?:
p(y?|x?,y) = ∫ p(y?|f?, f)q(f)dfdf? , (11)
where we have defined f? =",2.2. Method Specification and Expectation Propagation,[0],[0]
"(f1(x?), . . .",2.2. Method Specification and Expectation Propagation,[0],[0]
", fC(x?))T, and∫ p(y?|f?, f)df? has the same form as the likelihood factor in (3).",2.2. Method Specification and Expectation Propagation,[0],[0]
The resulting integral in (11) is again intractable.,2.2. Method Specification and Expectation Propagation,[0],[0]
"However, it can be approximated using a one-dimensional quadrature.",2.2. Method Specification and Expectation Propagation,[0],[0]
"See the supplementary material.
",2.2. Method Specification and Expectation Propagation,[0],[0]
"Because some simplifications occur when computing the derivatives of logZq w.r.t the inducing points, the total training time of EP is O(NM2) while the total memory cost is O(NMC) (Snelson, 2007).",2.2. Method Specification and Expectation Propagation,[0],[0]
"Traditionally, for finding the model hyper-parameters with EP one re-runs EP until convergence (using the previous solution as the starting point), after each gradient ascent update of the hyper-parameters.",2.3. Scalable Expectation Propagation,[0],[0]
"The reason for this is that (10) is only true if EP has converged (i.e., the approximate factors do not change any more).",2.3. Scalable Expectation Propagation,[0],[0]
"This approach is particularly inefficient initially, when there are strong changes to the model hyper-parameters, and EP may require several iterations to converge.",2.3. Scalable Expectation Propagation,[0],[0]
"Recently, a more efficient method has been proposed in (Hernández-Lobato & HernándezLobato, 2016).",2.3. Scalable Expectation Propagation,[0],[0]
In that work the authors suggest to update both the approximate factors and the model hyperparameters at the same time.,2.3. Scalable Expectation Propagation,[0],[0]
"Because we do not wait for EP to converge, one should ideally add to (10) extra terms to get the gradient.",2.3. Scalable Expectation Propagation,[0],[0]
"These terms account for the mismatch between the moments of Z−1i,k φ k",2.3. Scalable Expectation Propagation,[0],[0]
"i q \i,k and q.",2.3. Scalable Expectation Propagation,[0],[0]
"However, according to (Hernández-Lobato & Hernández-Lobato, 2016) these extra terms can be ignored and one can simply use (10) for an inner update of the hyper-parameters.
",2.3. Scalable Expectation Propagation,[0],[0]
"Figure 1 shows, for the Vehicle dataset from UCI repository (Lichman, 2013), the estimate of the marginal likelihood logZq with respect to the training time, for 250 updates of the hyper-parameters, and M = N/5.",2.3. Scalable Expectation Propagation,[0],[0]
"We compare three
methods: (i) re-running EP until convergence each time and using (10) to update the hyper-parameters (EP-outer); (ii) updating at the same time the approximate factors φ̃ki and the hyper-parameters with (10) (EP-inner-approx); and (iii) the same approach as the previous one, but using the exact gradient for the update instead of (10) (EP-inner-exact).",2.3. Scalable Expectation Propagation,[0],[0]
All approaches successfully maximize logZq .,2.3. Scalable Expectation Propagation,[0],[0]
"However, the inner updates are more efficient as they do not wait until EP converges.",2.3. Scalable Expectation Propagation,[0],[0]
"Moreover, using the approximate gradient is faster (it is cheaper to compute), and it gives almost the same results as the exact gradient.",2.3. Scalable Expectation Propagation,[0],[0]
"The memory cost of EP can be significantly reduced by a technique called stochastic EP (SEP) (Li et al., 2015).",2.3.1. STOCHASTIC EXPECTATION PROPAGATION,[0],[0]
In SEP all the approximate factors φ̃ki are tied.,2.3.1. STOCHASTIC EXPECTATION PROPAGATION,[0],[0]
"This means that instead of storing their individual parameters, what is stored is their product, i.e., φ̃ = ∏N i=1",2.3.1. STOCHASTIC EXPECTATION PROPAGATION,[0],[0]
∏ k 6=yk φ̃ k,2.3.1. STOCHASTIC EXPECTATION PROPAGATION,[0],[0]
i .,2.3.1. STOCHASTIC EXPECTATION PROPAGATION,[0],[0]
A consequence of this is that we no longer have direct access to their individual parameters.,2.3.1. STOCHASTIC EXPECTATION PROPAGATION,[0],[0]
"This only affects the computation of the cavity distribution q\i,k which now is obtained in an approximate way q\i,k ∝ q/φ̃ 1n , where n is the total number of factors and φ̃ 1 n approximates each individual factor.",2.3.1. STOCHASTIC EXPECTATION PROPAGATION,[0],[0]
"Thus, SEP reduces the memory costs of EP by a factor of n. All the other steps are carried out as in the original EP algorithm, including the computation of logZq and its gradients.",2.3.1. STOCHASTIC EXPECTATION PROPAGATION,[0],[0]
Figure 2 shows the differences between EP and SEP on a toy example.,2.3.1. STOCHASTIC EXPECTATION PROPAGATION,[0],[0]
"When SEP is used in the proposed method, the memory cost is reduced to O(CM2).",2.3.1. STOCHASTIC EXPECTATION PROPAGATION,[0],[0]
Both the estimate of the log-marginal-likelihood in (9) and its gradient in (10) contain a sum across the data instances.,2.3.2. TRAINING USING MINI-BATCHES,[0],[0]
"This allows to write an EP algorithm that processes mini-batches of data, as in (Hernández-Lobato & Hernández-Lobato, 2016).",2.3.2. TRAINING USING MINI-BATCHES,[0],[0]
"For this, the data are split in mini-batchesMj of size S N , where N is the number of instances.",2.3.2. TRAINING USING MINI-BATCHES,[0],[0]
"Given a mini-batch Mj , we process all the approximate factors corresponding to that mini-batch, i.e., {{φ̃ki }k 6=yi : (xi, yi) ∈",2.3.2. TRAINING USING MINI-BATCHES,[0],[0]
Mj}.,2.3.2. TRAINING USING MINI-BATCHES,[0],[0]
"Then, we update the model hyper-parameters using a stochastic approximation of (10): ∂ logZq ∂ξkj ≈ (ηT − ηTprior) ∂θprior ∂ξkj + ρ ∑ i∈Mj ∑ k 6=yi logZi,k ∂ξkj , (12)
where ρ = N/|Mj |.",2.3.2. TRAINING USING MINI-BATCHES,[0],[0]
"We reconstruct q after each update of the approximate factors and each update of the hyper-
parameters.",2.3.2. TRAINING USING MINI-BATCHES,[0],[0]
"When using mini-batches of data, we update more frequently q and the hyper-parameters.",2.3.2. TRAINING USING MINI-BATCHES,[0],[0]
"The consequence is that the training cost is O(CM3), assuming a constant number of updates until convergence.",2.3.2. TRAINING USING MINI-BATCHES,[0],[0]
This training scheme can handle datasets with millions of instances.,2.3.2. TRAINING USING MINI-BATCHES,[0],[0]
"The likelihood used in (1) was first considered for multiclass Gaussian process classification in (Kim & Ghahramani, 2006).",3. Related Work,[0],[0]
"That work considers full non-parametric GP priors, which lead to a training cost that is O(CN3).",3. Related Work,[0],[0]
The consequence is that it can only address small classification problems.,3. Related Work,[0],[0]
"It is, however, straight forward to replace the non-parametric GP priors with the FITC approximate priors pFITC(fk|X k ) (Quiñonero-Candela & Rasmussen, 2005).",3. Related Work,[0],[0]
"These priors are obtained by marginalizing the latent variables f k associated to the inducing points X k , as indicated in Section 2.1.",3. Related Work,[0],[0]
This allows to address datasets with a few thousand instances.,3. Related Work,[0],[0]
"This is precisely the approach followed in (Naish-Guzman & Holden, 2008) to address binary GP classification problems.",3. Related Work,[0],[0]
We refer to such an approach as the generalized FITC approximation (GFITC).,3. Related Work,[0],[0]
"Nevertheless, such an approach cannot use stochastic optimization.",3. Related Work,[0],[0]
The reason is that the estimate of the log-marginal-likelihood (needed for hyper-parameter estimation) does not contain a sum across the instances.,3. Related Work,[0],[0]
"Thus, GFITC cannot scale well to very large datasets.",3. Related Work,[0],[0]
"Nevertheless, unlike the proposed approach, it can run expectation propagation over the exact likelihood factors in (1).",3. Related Work,[0],[0]
"In GFITC we follow the traditional approach and run EP until convergence before updating the hyper-parameters.
",3. Related Work,[0],[0]
"Multi-class GP classification for potentially huge datasets has also been considered in (Hensman et al., 2015b) using variational inference (VI).",3. Related Work,[0],[0]
"However, such an approach cannot use the likelihood in (1) since its logarithm is not well defined (note that it takes value zero for some values of fi).",3. Related Work,[0],[0]
"As an alternative, Hensman et al. (2015b) have considered the robust likelihood of (Hernández-Lobato et al., 2011):
p(yi|fi) =",3. Related Work,[0],[0]
(1− ),3. Related Work,[0],[0]
∏,3. Related Work,[0],[0]
k 6=yi Θ ( fyi(xi)− fk(xi) ),3. Related Work,[0],[0]
"+ C , (13)
where is the probability of a labeling error (in that case, yi is chosen at random from the potential class labels).",3. Related Work,[0],[0]
"In (Hensman et al., 2015b)",3. Related Work,[0],[0]
"it is suggested to set = 10−3.
",3. Related Work,[0],[0]
We now describe the VI approach in detail.,3. Related Work,[0],[0]
"Using (13) and the definitions of Section 2, we know that p(y|f) =∫ p(y|f)p(f |f)df .",3. Related Work,[0],[0]
If we take the log and use Jensen’s inequality we get the bound log p(y|f) ≥ Ep(f |f)[log p(y|f)].,3. Related Work,[0],[0]
Consider now a Gaussian approximation q to p(f |y).,3. Related Work,[0],[0]
"Then,
log p(y) = ∫ q(f)p(y|f)p(f)/q(f)df ≥",3. Related Work,[0],[0]
"Eq(f)[log p(y|f)]− KL[q(f)||p(f)] , (14)
where we have used Jensen’s inequality and KL is the Kull-
back Leibler divergence.",3. Related Work,[0],[0]
"If we use the first bound we get
log p(y) ≥ Eq(f)[Ep(f |f)[log p(y|f)]]KL[q(f)||p(f)]
≥ Eq(f)[log p(y|f)]− KL[q(f)||p(f)]",3. Related Work,[0],[0]
"≥ ∑N i=1Eq(fi)[log p(yi|fi)]− KL[q(f)||p(f)] , (15)
where q(f) = ∫ p(f |f)q(f)df and the corresponding marginal over fi = (f1(xi), . . .",3. Related Work,[0],[0]
", fC(xi))T is q(fi) =∏C k=1N (fk(xi)|m̂ki , ŝki ).",3. Related Work,[0],[0]
Note that q(fi) is Gaussian because q(f) involves a Gaussian convolution.,3. Related Work,[0],[0]
"As in the proposed approach, q(f) is assumed to be a Gaussian factorizing over the latent functions f 1 , . . .",3. Related Work,[0],[0]
", f C .",3. Related Work,[0],[0]
"However, its mean and covariance parameters, i.e., {mk}Ck=1 and {Sk}Ck=1 are found by maximizing (15).",3. Related Work,[0],[0]
"The parameters of q(fi) are:
m̂ki =",3. Related Work,[0],[0]
"(k k
xiX k ) T(Kk X k X k ) −1mk , (16)
ŝki = κ k",3. Related Work,[0],[0]
xixi,3. Related Work,[0],[0]
"− (k k
xiX k ) T(Kk X k X k ) −1kk xiX",3. Related Work,[0],[0]
"k
+ (kk xiX k )",3. Related Work,[0],[0]
T(Kk X k X k ),3. Related Work,[0],[0]
−1Sk(Kk X k X k ) −1kk xiX k .,3. Related Work,[0],[0]
"(17)
Hensman et al. (2015b) consider Markov chain Monte Carlo (MCMC) to sample the hyper-parameters.",3. Related Work,[0],[0]
Here we simply maximize (15) to find the hyper-parameters and the inducing points.,3. Related Work,[0],[0]
The reason for this is that in very large datasets MCMC is not expected to give much better results.,3. Related Work,[0],[0]
We refer to the described approach as VI.,3. Related Work,[0],[0]
The objective in (15) contains a sum across the data instances.,3. Related Work,[0],[0]
"Thus, VI also allows for stochastic optimization and it results in the same cost as the proposed approach.",3. Related Work,[0],[0]
"However, the expectations in (15) must be approximated using one-dimensional quadratures.",3. Related Work,[0],[0]
This is a drawback with respect to the proposed method which is free of any quadrature.,3. Related Work,[0],[0]
"Finally, there are some methods related to the VI approach just described.",3. Related Work,[0],[0]
"Dezfouli & Bonilla (2015) assume that q can be a mixture of Gaussians, and Chai (2012) uses a soft-max likelihood (but does not consider stochastic optimization).",3. Related Work,[0],[0]
"Both works need to introduce extra approximations.
",3. Related Work,[0],[0]
In the literature there are other research works addressing multi-class Gaussian process classification.,3. Related Work,[0],[0]
"Some examples include (Williams & Barber, 1998; Girolami & Rogers, 2006; Hernández-Lobato et al., 2011; Henao & Winther, 2012; Riihimäki et al., 2013).",3. Related Work,[0],[0]
"These works employ expectation propagation, variational inference or the Laplace approximation to approximate the computations.",3. Related Work,[0],[0]
"Nevertheless, the corresponding estimate of the logmarginal-likelihood cannot be expressed as a sum across the data instances.",3. Related Work,[0],[0]
This avoids using efficient techniques for optimization based on stochastic gradients.,3. Related Work,[0],[0]
"Thus, one cannot address very large datasets with these methods.",3. Related Work,[0],[0]
We evaluate the performance of the method proposed in Section 2.2.,4. Experiments,[0],[0]
We consider two versions of it.,4. Experiments,[0],[0]
"A first
one, using expectation propagation (EP).",4. Experiments,[0],[0]
"A second, using the memory efficient stochastic EP (SEP).",4. Experiments,[0],[0]
EP and SEP are compared with the methods described in Section 3.,4. Experiments,[0],[0]
"Namely, GFITC and VI.",4. Experiments,[0],[0]
"All methods are codified in the R language (the source code is in the supplementary material), and they consider the same initial values for the model hyper-parameters (including the inducing points, that are chosen at random from the training instances).",4. Experiments,[0],[0]
The hyperparameters are optimized by maximizing the estimate of the marginal likelihood.,4. Experiments,[0],[0]
"A Gaussian covariance function with automatic relevance determination, an amplitude parameter and an additive noise parameter is employed.",4. Experiments,[0],[0]
"We evaluate the performance of each method on 8 datasets from the UCI repository (Lichman, 2013).",4.1. Performance on Datasets from the UCI Repository,[0],[0]
The characteristics of the datasets are displayed in Table 4.1.,4.1. Performance on Datasets from the UCI Repository,[0],[0]
"We use batch training in each method (i.e., we go through all the data to compute the gradients).",4.1. Performance on Datasets from the UCI Repository,[0],[0]
Batch training does not scale to large datasets.,4.1. Performance on Datasets from the UCI Repository,[0],[0]
"However, it is preferred on small datasets like the ones considered here.",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"We use 90% of the data for training and 10% for testing, expect for Satellite which is fairly big, where we use 20% for training and 80% for testing.",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"In Waveform, which is synthetic, we generate 1000 instances and split them in 30% for training and 70% for testing.",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"Finally, in Vowel we consider only the points that belong to the 6 first classes.",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"All methods are trained for 250 iterations using gradient ascent (GFITC and VI use lBFGS, EP and SEP use an adaptive learning rate described in the supplementary material).",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"We consider three values for M , the number of inducing points.",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"Namely 5%, 10% and 20% of the number of training instances.",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"We report averages over 20 repetitions of the experiments.
",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"Table 2 shows, for each value of M , the average negative test log-likelihood of each method with the corresponding error bars (test errors are shown in the supplementary material).",4.1. Performance on Datasets from the UCI Repository,[0],[0]
The average training time of each method is also displayed.,4.1. Performance on Datasets from the UCI Repository,[0],[0]
The best method (the lower the better) for each dataset is highlighted in bold face.,4.1. Performance on Datasets from the UCI Repository,[0],[0]
"We observe that the proposed approach, EP, obtains very similar results to those of GFITC, and sometimes it obtains the best results.",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"The memory efficient version of EP, SEP, seems to provide similar results without reducing the performance.",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"Regarding the computational cost, SEP is the
fastest method (between 2 and 3 times faster than GFITC).",4.1. Performance on Datasets from the UCI Repository,[0],[0]
VI is slower as a consequence of the quadratures required by this method.,4.1. Performance on Datasets from the UCI Repository,[0],[0]
"VI also gives much worse results in some datasets, e.g., Glass, Svmguide2 and Waveform.",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"This is related to the optimization of Eq(fi)[log p(yi|fi)] in (15), instead of logEq(fi)[p(yi|fi)], which is closer to the data loglikelihood.",4.1. Performance on Datasets from the UCI Repository,[0],[0]
"In the EP objective in (9), ∑ k 6=yi logZi,k is probably more similar to logEq(fi)[p(yi|fi)].",4.1. Performance on Datasets from the UCI Repository,[0],[0]
This explains the much better results obtained by EP and SEP.,4.1. Performance on Datasets from the UCI Repository,[0],[0]
"We generate a synthetic two dimensional problem with three classes by sampling the latent functions from the GP prior and applying the rule yi = arg maxk f
k(xi).",4.2. Analysis of Inducing Point Learning,[0],[0]
The distribution of xi is uniform in the box,4.2. Analysis of Inducing Point Learning,[0],[0]
"[−2.5, 2.5] ×",4.2. Analysis of Inducing Point Learning,[0],[0]
"[−2.5, 2.5].",4.2. Analysis of Inducing Point Learning,[0],[0]
"We consider 1000 training instances and a growing number of inducing points, i.e., M = 1 to M = 256.",4.2. Analysis of Inducing Point Learning,[0],[0]
The initial location of the inducing points is chosen at random,4.2. Analysis of Inducing Point Learning,[0],[0]
and it is the same for all the methods.,4.2. Analysis of Inducing Point Learning,[0],[0]
We are interested in the location of the inducing points after training.,4.2. Analysis of Inducing Point Learning,[0],[0]
"Thus, we set the other hyper-parameters to their true values (specified before generating the data) and we keep them fixed.",4.2. Analysis of Inducing Point Learning,[0],[0]
All methods but VI are trained using batch methods during 2000 iterations.,4.2. Analysis of Inducing Point Learning,[0],[0]
VI is trained using stochastic gradients for 2000 epochs (the batch version often gets stuck in local optima).,4.2. Analysis of Inducing Point Learning,[0],[0]
"We use ADAM with the default settings (Kingma & Ba, 2015), and 100 as the mini-batch size.
",4.2. Analysis of Inducing Point Learning,[0],[0]
Figure 3 shows the location learnt by each method for the inducing points.,4.2. Analysis of Inducing Point Learning,[0],[0]
"Blue, red and green points represent the training data, black lines are decision boundaries and black border points are the inducing points.",4.2. Analysis of Inducing Point Learning,[0],[0]
As we increase the number of inducing points the methods become more accurate.,4.2. Analysis of Inducing Point Learning,[0],[0]
"However, GFITC, EP and SEP identify decision boundaries that are better with a smaller number of inducing points.",4.2. Analysis of Inducing Point Learning,[0],[0]
VI fails in this task.,4.2. Analysis of Inducing Point Learning,[0],[0]
This is probably because VI updates the inducing-points with a bad estimate of q during the initial iterations.,4.2. Analysis of Inducing Point Learning,[0],[0]
"VI uses gradient steps to update q, which is less efficient than the EP updates (free of any learning rate).",4.2. Analysis of Inducing Point Learning,[0],[0]
"GFITC, EP and SEP overlap the inducing points, which can be seen as a pruning mechanism (if two inducing points are equal, it is like having only one).",4.2. Analysis of Inducing Point Learning,[0],[0]
"This has already been observed in regression problems (Bauer et al., 2016).",4.2. Analysis of Inducing Point Learning,[0],[0]
"By contrast, VI places the inducing points near the decision boundaries.",4.2. Analysis of Inducing Point Learning,[0],[0]
"This agrees with previous results on binary classification (Hensman et al., 2015a).",4.2. Analysis of Inducing Point Learning,[0],[0]
Figure 4 shows the negative test log-likelihood of each method as a function of the training time on the Satellite dataset (EP results are not shown since it performs equal to SEP).,4.3. Performance as a Function of the Training Time,[0],[0]
Training is done as in Section 4.1.,4.3. Performance as a Function of the Training Time,[0],[0]
"We consider a growing number of inducing points M = 4, 20, 100 and report averages over 100 repetitions of the experiments.",4.3. Performance as a Function of the Training Time,[0],[0]
In all methods we use batch training.,4.3. Performance as a Function of the Training Time,[0],[0]
We observe that SEP is the method with the best performance at the lowest cost.,4.3. Performance as a Function of the Training Time,[0],[0]
"Again, it is faster than GFITC because it optimizes q and the hyper-parameters at the same time, while GFITC waits until EP has converged to update the hyper-parameters.",4.3. Performance as a Function of the Training Time,[0],[0]
"VI is not very efficient for small values of M , due to the quadratures.",4.3. Performance as a Function of the Training Time,[0],[0]
"It also takes more time to get a good estimate of q, which is updated by gradient descent and is less ef-
ficient than the EP updates.",4.3. Performance as a Function of the Training Time,[0],[0]
Similar results are obtained in terms of the test error.,4.3. Performance as a Function of the Training Time,[0],[0]
See the supplementary material.,4.3. Performance as a Function of the Training Time,[0],[0]
"However, in that case VI does not overfit the training data.",4.3. Performance as a Function of the Training Time,[0],[0]
"In very large datasets batch training is infeasible, and one must use mini-batches to update q and to approximate the required gradients.",4.4. Performance When Using Stochastic Gradients,[0],[0]
"We evaluate the performance of each method on the MNIST dataset (LeCun et al., 1998) with M = 200 inducing points and mini-batches with 200 instances.",4.4. Performance When Using Stochastic Gradients,[0],[0]
"This dataset has 60, 000 instances for training and 10, 000 for testing.",4.4. Performance When Using Stochastic Gradients,[0],[0]
"The learning rate of each method is set using ADAM with the default parameters (Kingma & Ba, 2015).",4.4. Performance When Using Stochastic Gradients,[0],[0]
GFITC does not allow for stochastic optimization.,4.4. Performance When Using Stochastic Gradients,[0],[0]
"Thus, it is ignored in the comparison.",4.4. Performance When Using Stochastic Gradients,[0],[0]
The test error and the negative test log-likelihood of each method is displayed in Figure 5 (top) as a function of the training time.,4.4. Performance When Using Stochastic Gradients,[0],[0]
In this larger dataset all methods perform similarly.,4.4. Performance When Using Stochastic Gradients,[0],[0]
"However, EP and SEP take less time to converge than VI.",4.4. Performance When Using Stochastic Gradients,[0],[0]
SEP obtains a test error that is 2.08% and average negative test log-likelihood that is 0.0725.,4.4. Performance When Using Stochastic Gradients,[0],[0]
"The results of VI are 2.02% and 0.0686, respectively.",4.4. Performance When Using Stochastic Gradients,[0],[0]
"These results are similar to the
ones reported in (Hensman et al., 2015a) using M = 500.
",4.4. Performance When Using Stochastic Gradients,[0],[0]
A last experiment considers all flights within the USA between 01/2008 and 04/2008 (http://stat-computing.,4.4. Performance When Using Stochastic Gradients,[0],[0]
org/dataexpo/2009).,4.4. Performance When Using Stochastic Gradients,[0],[0]
The task is to classify the flights according to their delay using three classes:,4.4. Performance When Using Stochastic Gradients,[0],[0]
"On time, more than 5 minutes of delay, or more than 5 minutes before time.",4.4. Performance When Using Stochastic Gradients,[0],[0]
"We consider 8 attributes: age of the aircraft, distance covered, airtime, departure time, arrival time, day of the week, day of the month and month.",4.4. Performance When Using Stochastic Gradients,[0],[0]
"After removing all instances with missing data 2, 127, 068 instances remain, from which 10, 000 are used for testing and the rest for training.",4.4. Performance When Using Stochastic Gradients,[0],[0]
We use the same settings as on the MNIST dataset and evaluate each method.,4.4. Performance When Using Stochastic Gradients,[0],[0]
The results obtained are shown in Figure 5 (bottom).,4.4. Performance When Using Stochastic Gradients,[0],[0]
We also report the performance of a logistic regression classifier.,4.4. Performance When Using Stochastic Gradients,[0],[0]
"Again, all methods perform similarly in terms of test error.",4.4. Performance When Using Stochastic Gradients,[0],[0]
"However, EP and SEP converge faster and quickly outperform the linear model.",4.4. Performance When Using Stochastic Gradients,[0],[0]
"Importantly, the negative test log-likelihood of VI starts increasing at some point, which is again probably due to the optimization of Eq(fi)[log p(yi|fi)] in (15).",4.4. Performance When Using Stochastic Gradients,[0],[0]
The supplementary material has further evidence supporting this.,4.4. Performance When Using Stochastic Gradients,[0],[0]
"We have proposed the first method for multi-class classification with Gaussian processes, based on expectation propagation (EP), that scales well to very large datasets.",5. Conclusions,[0],[0]
"Such a method uses the FITC approximation to reduce the number of latent variables in the model from O(N) to O(M), whereM N , andN is the number of data instances.",5. Conclusions,[0],[0]
"For this,M inducing points are introduced for each latent function in the model.",5. Conclusions,[0],[0]
"Importantly, the proposed method allows for stochastic optimization as the estimate of the log-
marginal-likelihood involves a sum across the data.",5. Conclusions,[0],[0]
"Moreover, we have also considered a stochastic version of EP (SEP) to reduce the memory usage.",5. Conclusions,[0],[0]
"When mini-batches and stochastic gradients are used for training, the computational cost of the proposed approach is O(CM3), with C the number of classes.",5. Conclusions,[0],[0]
"The memory cost is O(CM2).
",5. Conclusions,[0],[0]
"We have compared the proposed method with other approaches from the literature based on variational inference (VI) (Hensman et al., 2015b), and with the model considered by Kim & Ghahramani (2006), which has been combined with FITC approximate priors (GFITC) (QuiñoneroCandela & Rasmussen, 2005).",5. Conclusions,[0],[0]
"The proposed approach outperforms GFITC in large datasets as this method does not allow for stochastic optimization, and in small datasets it produces similar results.",5. Conclusions,[0],[0]
"The proposed method, SEP, is slightly faster than VI which also allows for stochastic optimization.",5. Conclusions,[0],[0]
"In particular, VI requires one-dimensional quadratures which in small datasets are expensive.",5. Conclusions,[0],[0]
We have also observed that SEP converges faster than VI.,5. Conclusions,[0],[0]
"This is probably because the EP updates, free of any learning rate, are more efficient for finding a good posterior approximation than the gradient ascent updates employed by VI.
",5. Conclusions,[0],[0]
An important conclusion of this work is that VI sometimes gives bad predictive distributions in terms of the test loglikelihood.,5. Conclusions,[0],[0]
The EP and SEP methods do not seem to have this problem.,5. Conclusions,[0],[0]
"Thus, if one cares about accurate predictive distributions, VI should be avoided in favor of the proposed methods.",5. Conclusions,[0],[0]
"In our experiments we have also observed that the proposed approaches tend to place the inducing points one on top of each other, which can be seen as an inducing point pruning technique (Bauer et al., 2016).",5. Conclusions,[0],[0]
"By contrast, VI tends to place them near the decision boundaries.",5. Conclusions,[0],[0]
The authors gratefully acknowledge the use of the facilities of Centro de Computación Cientı́fica (CCC) at Universidad Autónoma de Madrid.,Acknowledgements,[0],[0]
"The authors also acknowledge financial support from Spanish Plan Nacional I+D+i, Grants TIN2013-42351-P, TIN2016-76406P, TIN2015-70308-REDT and TEC2016-81900-REDT (MINECO/FEDER EU), and from Comunidad de Madrid, Grant S2013/ICE-2845.",Acknowledgements,[0],[0]
This paper describes an expectation propagation (EP) method for multi-class classification with Gaussian processes that scales well to very large datasets.,abstractText,[0],[0]
In such a method the estimate of the log-marginal-likelihood involves a sum across the data instances.,abstractText,[0],[0]
This enables efficient training using stochastic gradients and mini-batches.,abstractText,[0],[0]
"When this type of training is used, the computational cost does not depend on the number of data instances N .",abstractText,[0],[0]
"Furthermore, extra assumptions in the approximate inference process make the memory cost independent of N .",abstractText,[0],[0]
The consequence is that the proposed EP method can be used on datasets with millions of instances.,abstractText,[0],[0]
We compare empirically this method with alternative approaches that approximate the required computations using variational inference.,abstractText,[0],[0]
"The results show that it performs similar or even better than these techniques, which sometimes give significantly worse predictive distributions in terms of the test log-likelihood.",abstractText,[0],[0]
"Besides this, the training process of the proposed approach also seems to converge in a smaller number of iterations.",abstractText,[0],[0]
Scalable Multi-Class Gaussian Process Classification  using Expectation Propagation,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1–7 New Orleans, Louisiana, June 1 - 6, 2018. c©2017 Association for Computational Linguistics
In recent years the use of electronic medical records has accelerated resulting in large volumes of medical data when a patient visits a healthcare facility. As a first step towards reimbursement healthcare institutions need to associate ICD-10 billing codes to these documents. This is done by trained clinical coders who may use a computer assisted solution for shortlisting of codes. In this work, we present our work to build a machine learning based scalable system for predicting ICD-10 codes from electronic medical records. We address data imbalance issues by implementing two system architectures using convolutional neural networks and logistic regression models. We illustrate the pros and cons of those system designs and show that the best performance can be achieved by leveraging the advantages of both using a system combination approach.",text,[0],[0]
"Medical classification, also called medical coding, plays a vital role for healthcare providers.",1 Introduction,[0],[0]
Medical coding is the process of assigning ICD-10 codes (2018) to a patient’s visit in a healthcare facility.,1 Introduction,[0],[0]
"In the inpatient case these ICD-10 codes are further combined into Diagnosis-Related Groups (DRG) which classify inpatient stays into billing groups for the purposes of reimbursement.
",1 Introduction,[0],[0]
"Traditionally, medical coding is a manual process which involves a medical coder.",1 Introduction,[0],[0]
"The medical coder examines the complete encounter of a patient – the set of all associated Electronic Medical Records (EMRs) – and assigns the relevant ICD-10
1 Authors are listed in alphabetic order with respect to their family names.
codes.",1 Introduction,[0],[0]
Medical classification is a complex task in many dimensions though.,1 Introduction,[0],[0]
In the inpatient case the ICD-10 codes split into the Clinical Modification Coding System ICD-10-CM for diagnosis coding and the Procedure Coding System ICD-10-PCS for procedure coding.,1 Introduction,[0],[0]
"As of January 2018, there are 71704 ICD-10-CM codes and 78705 ICD-10-PCS codes (ICD-10, 2018).
",1 Introduction,[0],[0]
"Besides the sheer amount of possible codes, the coding process is further hampered by the unstructured nature of EMRs.",1 Introduction,[0],[0]
"Dependent on the individual encounter the set of associated EMRs can be very diverse (Scheurwegs et al., 2015).",1 Introduction,[0],[0]
"The EMRs may be composed out of discharge summaries, emergency room notes, imaging diagnoses, anesthesia process notes, laboratory reports, etcetera.",1 Introduction,[0],[0]
"In addition, EMRs typically stem from different physicians and laboratories.",1 Introduction,[0],[0]
"This results in large amounts of redundant information yet presented in different writing styles but without guarantee to be complete (Weiskopf et al., 2013; Cohen et al., 2013).",1 Introduction,[0],[0]
"Some of the EMRs may be composed out of free form written text whereas others contain dictated text, tables or a mixture of tables and text.",1 Introduction,[0],[0]
"Overall, when working with EMRs one is faced with severe data quality issues (Miotto et al., 2016).
",1 Introduction,[0],[0]
To reduce the complexity of the medical coding task Computer Assisted Coding (CAC) was introduced.,1 Introduction,[0],[0]
"CAC is meant to automatically predict the relevant ICD-10 codes from the EMRs (Perotte et al., 2014; Scheurwegs et al., 2017; Shi et al., 2018; Pakhomov et al., 2006).",1 Introduction,[0],[0]
Ideally CAC comes up with the exact set of codes which describe an encounter.,1 Introduction,[0],[0]
"However, due to the complexity of the task this is hardly possible.",1 Introduction,[0],[0]
"Instead CAC is typically designed to assist the medical coder by providing a list of most probable codes.
",1 Introduction,[0],[0]
"1
In the paper on hand we present our work to design such a CAC system.",1 Introduction,[0],[0]
The emphasis lies on industrial aspects as the scale and the scaling of the system.,1 Introduction,[0],[0]
We describe the design of a system which models 3000 ICD-10-CM codes and applies up to 234k encounters to build the model.,1 Introduction,[0],[0]
"To address data imbalance issues a system combination approach was followed combining a wide and a deep modeling strategy (Heng et al., 2016).",1 Introduction,[0],[0]
"Finally, scaling aspects were examined by increasing the number of encounters used for training and development from 81k to 234k.
",1 Introduction,[0],[0]
This paper is organized as follows.,1 Introduction,[0],[0]
In Section 2 we state the problem under investigation.,1 Introduction,[0],[0]
"Section 3 gives a detailed description of the data, and Section 4 describes the methods we apply to approach the problem.",1 Introduction,[0],[0]
"Section 5 provides experiments and results, and Section 6 closes with the conclusions.",1 Introduction,[0],[0]
The presented work studies the case of diagnosis code prediction for the inpatient case which corresponds to the prediction of ICD-10-CM codes.,2 Problem description,[0],[0]
"Typically, there are several ICD-10-CM codes which apply to an encounter making ICD-10-CM code prediction a multi-label classification task (Zhang and Zhou, 2014).",2 Problem description,[0],[0]
"Ultimately, the task consists in mapping a patient’s encounter to all or a subset of the 71704 possible ICD-10-CM codes.
",2 Problem description,[0],[0]
"Traditionally, rule-based approaches which leverage linguistic expertise were used to address this problem (Farkas and Szarvas, 2008; Goldstein et al., 2007).",2 Problem description,[0],[0]
Rule based methods don’t rely on training data.,2 Problem description,[0],[0]
"Yet, this advantage is dearly bought by a lack of scalability and the need for linguistic expert knowledge which results in an expensive development phase and high maintenance costs.
",2 Problem description,[0],[0]
The work on hand investigates the use of statistical methods for the CAC task.,2 Problem description,[0],[0]
Statistical approaches have the advantage that they offer ways of continued learning.,2 Problem description,[0],[0]
"This can be leveraged to scale and improve the system over time which are
important features in the dynamic environment healthcare providers are faced with.",2 Problem description,[0],[0]
The data used for this work stems from ten healthcare providers and covers 17 months of data.,3 Data and data preparation,[0],[0]
"For the analysis of scalability aspects, the data was split into two partitions.",3 Data and data preparation,[0],[0]
Partition A covers 6 months of data and partition B covers additional 10 months of data.,3 Data and data preparation,[0],[0]
The remaining one month of data served as test set.,3 Data and data preparation,[0],[0]
"For both partitions, 5% of the data was segregated and used as development (dev) set.",3 Data and data preparation,[0],[0]
"The dev set is meant for threshold tuning, the generation of early stopping metrics and the estimation of interpolation weights.",3 Data and data preparation,[0],[0]
"Table 1 provides some key statistics of the data.
",3 Data and data preparation,[0],[0]
"One peculiarity of the data are encounters which are quite long, see Figure 1.",3 Data and data preparation,[0],[0]
"The average and the median encounter length was found to be 11676 and 7238 tokens, respectively.",3 Data and data preparation,[0],[0]
"In addition, the encounter length distribution exhibits a long tail.",3 Data and data preparation,[0],[0]
"At the upper end there are 1422 encounters (0.63%) with more than 100k tokens and the maximum encounter length reaches 857k tokens.
",3 Data and data preparation,[0],[0]
Figure 2 shows the ranked frequency distribution over the target codes.,3 Data and data preparation,[0],[0]
From Figure 2 it is apparent that out of the 18846 codes seen in the data about two-thirds appear less than ten times.,3 Data and data preparation,[0],[0]
"This code sparsity issue had a direct impact on the system design as many of the codes can hardly be modeled.
",3 Data and data preparation,[0],[0]
Data preprocessing was kept at a minimum.,3 Data and data preparation,[0],[0]
After concatenating all EHRs of one encounter into one document lowercasing was applied.,3 Data and data preparation,[0],[0]
"Date and time expressions as well as URLs, phone numbers and other numerical expressions were
canonicalized.",3 Data and data preparation,[0],[0]
"Finally, after applying some shallow normalization (hyphens, underscores) tokenization was done using whitespace as token separators.",3 Data and data preparation,[0],[0]
As mentioned in Section 3 we had to operate over a set of codes with a wide range of occurrence probabilities.,4 Models and methods,[0],[0]
For some of the target codes training material was abundant whereas for others we were faced by severe data sparsity.,4 Models and methods,[0],[0]
"To address this issue, we followed a system combination strategy combining a set of Logistic Regression (LR) classifiers, with a Convolutional Neural Network (CNN).
",4 Models and methods,[0],[0]
"To cope with the multi-label nature of the classification problem we applied a first-order modeling strategy tackling the task in a code-by-code manner thus ignoring the coexistence of other codes (Zhang and Zhou, 2014).",4 Models and methods,[0],[0]
"In case of LR this modeling strategy was strict, meaning that one LR model was built per target code.",4 Models and methods,[0],[0]
In the CNN case a relaxed version of this strategy was applied.,4 Models and methods,[0],[0]
"One common CNN was built, with the target codes modeled conditionally independent by the loss function.
",4 Models and methods,[0],[0]
Regularized binary cross-entropy was applied for both the LR and the CNN objective function.,4 Models and methods,[0],[0]
In all cases model training was followed by a threshold tuning step to determine optimal decision thresholds.,4 Models and methods,[0],[0]
"Finally, all test results are presented in terms of micro-F1 (Wu and Zhou, 2017).",4 Models and methods,[0],[0]
LR is a well understood and robust classification method.,4.1 Logistic regression,[0],[0]
It is expected to perform well even for low frequency classes.,4.1 Logistic regression,[0],[0]
"The problem is convex and typically applied in conjunction with a L1 or a L2
regularization, the ‖𝑤‖ term in the LR objective function (1).
",4.1 Logistic regression,[0],[0]
"min 𝑤
𝐶‖𝑤‖ + ∑ log(1 + 𝑒−𝑦𝑖𝑤 𝑇𝑥𝑖)𝑙𝑖=1 (1)
",4.1 Logistic regression,[0],[0]
"For solving the LR problem we used LibLinear (Fan et al., 2008) which is a large-scale linear classification library.",4.1 Logistic regression,[0],[0]
"The LibLinear solver exhibits the advantage that there is only one free hyperparameter to tune, namely the regularization weight 𝐶.",4.1 Logistic regression,[0],[0]
Compared to LR a CNN features an increased complexity.,4.2 Convolutional neural networks,[0],[0]
"This higher modeling capability comes though with the need for more training data which makes it more suited for high frequency classes.
",4.2 Convolutional neural networks,[0],[0]
The CNN design we applied for this work follows the work described in Kalchbrenner et al. (2014) and Conneau et al. (2016).,4.2 Convolutional neural networks,[0],[0]
The basic architecture consists of one convolutional layer which is followed by max-pooling resulting in one feature per convolutional filter and document.,4.2 Convolutional neural networks,[0],[0]
"As input to the convolutional layer word embeddings apply which were pre-trained using word2vec (Mikolov et al., 2013).",4.2 Convolutional neural networks,[0],[0]
The feature extraction layer is succeeded by the classification part of the network consisting of a feed-forward network of one fullyconnected hidden layer and the final output layer.,4.2 Convolutional neural networks,[0],[0]
"The output layer is formed by one node with sigmoid activation for each ICD-10 code, effectively modeling the code’s probability.
",4.2 Convolutional neural networks,[0],[0]
Additional convolutional layers are added in conjunction with highway layers connecting each convolutional layer directly with the classification part of the network.,4.2 Convolutional neural networks,[0],[0]
The highway connections and the output of the last convolutional layer are followed by the same max-pooling operation described above.,4.2 Convolutional neural networks,[0],[0]
The convolutional layers are connected by a sliding-window max-pooling operation.,4.2 Convolutional neural networks,[0],[0]
For each filter of the lower convolutional layer a max-pooling operator of kernel-width 3 is applied to the stream of filter output values.,4.2 Convolutional neural networks,[0],[0]
"With a stride of one the layer’s output consists of a vector-feature stream which is of the same length as the input token sequence and a vector-dimension equal to the number of filters of the lower convolutional layer.
",4.2 Convolutional neural networks,[0],[0]
For our CNN implementation Theano (2017) was used.,4.2 Convolutional neural networks,[0],[0]
All CNNs were built using a NVIDIA P6000 GPU with 22GByte GPU-memory.,4.2 Convolutional neural networks,[0],[0]
System combination was implemented by linearly interpolating the hypothesized predictions from the LR system and the CNN system.,4.3 System combination,[0],[0]
The interpolation weights were optimized maximizing dev set microF1.,4.3 System combination,[0],[0]
In case of codes which were not modeled by the CNN the LR predictions were directly used.,4.3 System combination,[0],[0]
For practical reasons it was not possible to model all ICD-10-CM codes.,5 Experiments and results,[0],[0]
"Most of the 71704 ICD-10CM codes are never seen in the available data and even many of the seen codes are too rare to be modeled, see Figure 2.",5 Experiments and results,[0],[0]
We therefore restricted our models to the most frequent codes seen within the first seven month of data.,5 Experiments and results,[0],[0]
For the LR systems we used the most frequent 3000 codes.,5 Experiments and results,[0],[0]
The CNN was restricted to model only the most frequent 1000 codes which reflects the data sparsity issues discussed in Section 3.,5 Experiments and results,[0],[0]
With these settings a code coverage of >95% for the LR systems and >87 % for the CNN systems was obtained.,5 Experiments and results,[0],[0]
"Table 2 gives detailed code coverage statistics of the training data.
",5 Experiments and results,[0],[0]
"Model testing was directly affected by the target
code restrictions.",5 Experiments and results,[0],[0]
"Out of the 143k running codes of the test set 6189 instances are not covered by the 3000 modeled codes and 71 of the 3000 modeled codes do even not appear in the test set.
",5 Experiments and results,[0],[0]
"The following experiments give results for the most frequent (top) 200, 1000, and 3000 codes and all codes seen in the test set.",5 Experiments and results,[0],[0]
"Note that for the case of 1000 codes and the case of 3000 codes there are 17653 and 6189 code instances, respectively, which are not modeled.",5 Experiments and results,[0],[0]
These instances always entered the F1 calculation as false negatives when scored on all seen codes.,5 Experiments and results,[0],[0]
This phase of the project focused on basic system design question.,5.1 Basic system development,[0],[0]
"All experiments were carried out using data-partition A.
",5.1 Basic system development,[0],[0]
In case of the LR system we model a document as a ‘bag-of-ngrams’ up to an ngram-length of three.,5.1 Basic system development,[0],[0]
With a frequency cutoff of 20 this gave 4.1M features.,5.1 Basic system development,[0],[0]
Using higher order ngram-features or a smaller cutoff value didn’t provide any improvements.,5.1 Basic system development,[0],[0]
"For all LR experiments described in this work indicator features apply.
",5.1 Basic system development,[0],[0]
Table 3 lists the results of two LR systems.,5.1 Basic system development,[0],[0]
Both systems apply the same feature file which is used for all 3000 code specific classifiers.,5.1 Basic system development,[0],[0]
The basic LRa system applies a common regularization weight 𝐶 for all codes.,5.1 Basic system development,[0],[0]
In case of system LRa2 the regularization weight 𝐶 was tuned individually for each code using 4-fold cross-validation over the training set.,5.1 Basic system development,[0],[0]
Tuning the regularization weights resulted in micro-F1 gains of ~0.8% absolute.,5.1 Basic system development,[0],[0]
"Using an increased fold number didn’t provide any improvements.
",5.1 Basic system development,[0],[0]
For the CNN experiments we first used the CNN design with one convolutional layer described in Section 4.,5.1 Basic system development,[0],[0]
After some initial experiments the convolutional layer of the network was fixed to 900 filters with a filter width of five tokens.,5.1 Basic system development,[0],[0]
The hidden layer was fixed to 1024 nodes and the output layer models the most frequent 1000 ICD-10-CM codes.,5.1 Basic system development,[0],[0]
"Max-pooling was followed by Relu-activations.
",5.1 Basic system development,[0],[0]
All models were trained with RMSPROB.,5.1 Basic system development,[0],[0]
The convolutional layer used L2-regularization and L1regularization was used for the hidden layer and the output layer.,5.1 Basic system development,[0],[0]
Dropout was applied to the output of the max-pool operation.,5.1 Basic system development,[0],[0]
"Best results were achieved with a batch size (encounter level) of 32.
",5.1 Basic system development,[0],[0]
"The result named CNa1 in Table 3 follows the
design with one convolutional layer.",5.1 Basic system development,[0],[0]
"The CNa1 system was initialized with 50-dimensional word embeddings which were pre-trained on the training data with word2vec (Mikolov et al., 2013).",5.1 Basic system development,[0],[0]
These embeddings were further refined during network training.,5.1 Basic system development,[0],[0]
This gave a final micro-F1 of 66.31% absolute when scored over the 1000 modeled codes.,5.1 Basic system development,[0],[0]
"Best results were obtained with 50-dimensional embeddings and without batch normalization within the convolutional layer.
",5.1 Basic system development,[0],[0]
In a second step some initial experiments with the two convolutional layers CNN design were carried out.,5.1 Basic system development,[0],[0]
"This network featured 300 filters and 900 filters in the first and second convolutional layer, respectively.",5.1 Basic system development,[0],[0]
"The filter width was set to five and Relu-activations were used for the first layer.
",5.1 Basic system development,[0],[0]
Table 3 shows that the two convolutional layers system CNa2 achieves the best performance of a single system with an absolute increase in microF1 of ~0.9% over the CNa1 system with its one convolutional layer.,5.1 Basic system development,[0],[0]
In contrast to the setup with one convolutional layer the use of batch normalization turned out to be essential in the two-convolutional layer setup.,5.1 Basic system development,[0],[0]
"Dropping it gave worse results compared to the one-convolutional layer design.
",5.1 Basic system development,[0],[0]
"Finally, we explored the combination of the LR approach with the CNN approach.",5.1 Basic system development,[0],[0]
"Linearly interpolating the LRa2 system with the CNa2 system gave the best results with 64.44% micro-F1 (65.37% precision, 63.53% recall) clearly outperforming the underlying individual systems.",5.1 Basic system development,[0],[0]
We also examined other system combination strategies following the work from Heng et al. (2016).,5.1 Basic system development,[0],[0]
"However, the linear interpolation approach described in this work turned out to work best.
",5.1 Basic system development,[0],[0]
"Investigating the performance of the LRa2 system and the CNa2 system on code level, we found our assumption confirmed that the CNN is more suited to model high frequency codes whereas the LR system does better for low frequency codes.",5.1 Basic system development,[0],[0]
Figure 3 shows that the CNN does better for the most frequent 200 codes.,5.1 Basic system development,[0],[0]
"However, after a transition region covering roughly the next 300 codes, the LR system starts to outperform the CNN sys-
tem consistently, starting approximately from code position 500 on, see Figure 4.
",5.1 Basic system development,[0],[0]
These finding were reconfirmed when checking for the relative improvements of the combined LRa2 & CNa2 system over the CNa2 system.,5.1 Basic system development,[0],[0]
"Comparing the scores for the most frequent 200 codes and the most frequent 1000 codes one finds 0.75% and 2.02% relative improvements, respectively.",5.1 Basic system development,[0],[0]
"The LR system also fills up the 2000 codes not modeled by the CNN giving in a relative microF1 win of 2.19% when scoring over 3000 codes.
",5.1 Basic system development,[0],[0]
An integral part of the model building process was the tuning of the decision thresholds.,5.1 Basic system development,[0],[0]
Though individual thresholds per code are possible best micro-F1 results were always achieved with a common decision threshold over all codes.,5.1 Basic system development,[0],[0]
This behavior reflects again the data sparsity issues as not all modeled codes appear in the dev set and many other codes are so sparse that no robust threshold estimation was possible.,5.1 Basic system development,[0],[0]
In this phase of the project we focused on improved training recipes and the use of more training data given by data-partition B. We kept on modeling the same set of codes as used in Section 5.2.,5.2 System refinements,[0],[0]
"This lead
to a slight reduction in code coverage, see Table 2, but guaranteed the comparability of the results.
",5.2 System refinements,[0],[0]
For LR a bootstrapping approach was followed aiming to refine the system step-by-step from one model to the next model.,5.2 System refinements,[0],[0]
"We built up on the training recipe used to build system LRa2, see Section 5.1, i.e. L1 regularized LR with per-code tuned regularization constants 𝐶.",5.2 System refinements,[0],[0]
"First, we switched to the larger data-partition B which added additional 10 months of data to the original 6 months of data.",5.2 System refinements,[0],[0]
"Comparing the resulting LRb1 system with the LRa2 system, see Table 4, we found that the additional data improved micro-F1 by ~1.2% absolute.
",5.2 System refinements,[0],[0]
The use of more data increased the features space from 4.1M features to 9.2M features.,5.2 System refinements,[0],[0]
"To ease subsequent development work, we applied a feature reduction approach taking advantage of the feature selection property of the L1 regularization (Andrew Ng, 2004).",5.2 System refinements,[0],[0]
Reducing the feature space of the LRb1 system to all features with none-zero model weights reduced the features space by a factor of 62 giving 149k features.,5.2 System refinements,[0],[0]
"This feature selection step also improved system performance by ~0.2% absolute micro-F1, see LRb2 in Table 4.
",5.2 System refinements,[0],[0]
LR is a linear classification method fitting a hyperplane as decision boundary into feature space.,5.2 System refinements,[0],[0]
"To leverage the increased modeling capabilities of a none-linear modeling regime, we applied a quadratic kernel to the feature space.",5.2 System refinements,[0],[0]
With a features dimension of 149k this is yet a prohibitive endeavor.,5.2 System refinements,[0],[0]
Instead we used code specific reduced features spaces.,5.2 System refinements,[0],[0]
Based on the most prominent 400 features per code the quadratic kernel was applied which gave up to 80.2k squared features per code.,5.2 System refinements,[0],[0]
"After model building these features spaces were reduced again to all features with none-zero model weights.
",5.2 System refinements,[0],[0]
"2 At the time of writing this paper the results for the 2-convolutional layer CNN which was built on the partition B data was still not available.
",5.2 System refinements,[0],[0]
Table 4 lists the corresponding results as LRb3.,5.2 System refinements,[0],[0]
For the most frequent 200 codes absolute micro-F1 improvements of ~0.7% are observed with respect to the LRb2 system.,5.2 System refinements,[0],[0]
"For the less frequent codes this effect is nearly washed out though.
",5.2 System refinements,[0],[0]
The partition B data was also applied to the CNN.,5.2 System refinements,[0],[0]
Table 5 compares the corresponding 1-convolutional layer system built on the partition B data with the CNNs built on the partition A data2.,5.2 System refinements,[0],[0]
We found that the additional 10 month of training data provide a ~0.2% - ~1% improvement in absolute micro-F1.,5.2 System refinements,[0],[0]
"Note that system CNb1 outperforms system CNa2 when soring over all 1000 modeled codes but that system CNa2 is better when scoring only over the top 200 codes, see Table 5.",5.2 System refinements,[0],[0]
"We attribute this behavior to the change in the code distribution when switching from partition A to partition B.
Finally, the best LR system, LRb3, was combined with the CNa2 system giving the best overall results with a micro-F1 of 64.60% (68.10% precision, 61.60% recall).",5.2 System refinements,[0],[0]
"Compared to the best single systems, CNa2 and CNb1, absolute micro-F1 improvements of ~1.8% - ~1.9% are observed.",5.2 System refinements,[0],[0]
In this work we have presented our work on building a machine learnable CAC system.,6 Conclusions,[0],[0]
The focus lies on aspects developers are faced with in practice.,6 Conclusions,[0],[0]
"Data peculiarities like data amount, imbalances in code frequencies or sample length were discussed.",6 Conclusions,[0],[0]
We provide evidence that the imbalance issues are best addressed by a dedicated modeling approach for each datatype.,6 Conclusions,[0],[0]
"Finally, with our combined LR-CNN system which models 3000 ICD-10-CM codes we achieved a micro-",6 Conclusions,[0],[0]
In recent years the use of electronic medical records has accelerated resulting in large volumes of medical data when a patient visits a healthcare facility.,abstractText,[0],[0]
As a first step towards reimbursement healthcare institutions need to associate ICD-10 billing codes to these documents.,abstractText,[0],[0]
This is done by trained clinical coders who may use a computer assisted solution for shortlisting of codes.,abstractText,[0],[0]
"In this work, we present our work to build a machine learning based scalable system for predicting ICD-10 codes from electronic medical records.",abstractText,[0],[0]
We address data imbalance issues by implementing two system architectures using convolutional neural networks and logistic regression models.,abstractText,[0],[0]
We illustrate the pros and cons of those system designs and show that the best performance can be achieved by leveraging the advantages of both using a system combi-,abstractText,[0],[0]
Scalable Wide and Deep Learning for Computer Assisted Coding,title,[0],[0]
"Keywords: screening, SVM, dual problem, optimization, classification
∗. The first two authors contribute equally. †. Corresponding author.
c©2019 Bin Hong, Weizhong Zhang, Wei Liu, Jieping Ye, Deng Cai, Xiaofei He and Jie Wang.
License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided at http://jmlr.org/papers/v20/17-723.html.
ar X
iv :1
60 7.",text,[0],[0]
"Sparse support vector machine (SVM) (Bi et al., 2003; Wang et al., 2006) is a powerful technique that can simultaneously perform classification by margin maximization and variable selection via `1-norm penalty.",1. Introduction,[0],[0]
"The last few years have witnessed many successful applications of sparse SVMs, such as text mining (Joachims, 1998; Yoshikawa et al., 2014), bioinformatics (Narasimhan and Agarwal, 2013), and image processing (Mohr and Obermayer, 2004; Kotsia and Pitas, 2007).",1. Introduction,[0],[0]
"Many algorithms (Hastie et al., 2004; Fan et al., 2008; Catanzaro et al., 2008; Hsieh et al., 2008; Shalev-Shwartz et al., 2011) have been proposed to efficiently solve sparse SVM problems.",1. Introduction,[0],[0]
"However, the applications of sparse SVMs to large-scale learning problems, which involve a huge number of samples and extremely high-dimensional features, still remain challenging.
",1. Introduction,[0],[0]
"An emerging technique, called screening (El Ghaoui et al., 2012), has been shown to be promising in accelerating the training processes of large-scale sparse learning models.",1. Introduction,[0],[0]
The essential idea of screening is to quickly identify the zero coefficients in the sparse solutions without solving any optimization problems such that the corresponding features or samples—that are called inactive features or samples—can be removed from the training phase.,1. Introduction,[0],[0]
"Then, we only need to perform optimization on the reduced data sets instead of the full data sets, leading to a substantial saving in the computational cost.",1. Introduction,[0],[0]
"Here, we need to emphasize that screening differs greatly from feature selection, although they look similar at the first glance.",1. Introduction,[0],[0]
"To be precise, screening is devoted to accelerating the training processes of many sparse models including Lasso, sparse SVMs, etc., while feature selection is the goal of these models.",1. Introduction,[0],[0]
"In the past few years, many screening methods are proposed for a large set of sparse learning techniques, such as Lasso (Tibshirani et al., 2012; Xiang and Ramadge, 2012; Wang et al., 2015), group Lasso (Ndiaye et al., 2016), `1-regularized logistic regression (Wang et al., 2014b), and SVMs (Ogawa et al., 2013).",1. Introduction,[0],[0]
"Most of the existing methods are in the same framework, i.e., estimating the optimum of the dual (resp. primal) problem and then developing the screening rules based on the estimations to infer which components of the primal (resp. dual) optimum are zero from the KKT conditions.",1. Introduction,[0],[0]
The main differences among them are the techniques they use to develop their optima estimations and rules and the different sparse models they focus on.,1. Introduction,[0],[0]
"For example, SAFE (El Ghaoui et al., 2012) estimates the dual optimum by calculating the optimal value’s lower bound of the dual problem.",1. Introduction,[0],[0]
"The Lasso screening method (Wang et al., 2015) estimates the optimum based on the non-expensiveness (Bauschke et al., 2011) of the projection operator by noting that its dual problem boils down to finding the projection of a given point on a convex set.",1. Introduction,[0],[0]
"Moreover, a screening method is called static if it triggers its screening rules before training, and dynamic if during the training process.",1. Introduction,[0],[0]
"Empirical studies indicate that screening methods can lead to orders of magnitude of speedup in computation time.
",1. Introduction,[0],[0]
"However, most existing screening methods study either feature screening or sample screening individually and their applications have very different scenarios.",1. Introduction,[0],[0]
"Specifically, to achieve better performance (say, in terms of speedup), we favor feature screening methods when the number of features p is much larger than the sample size n, while sample screening methods are preferable when n",1. Introduction,[0],[0]
p.,1. Introduction,[0],[0]
"Note that there is another class of sparse learning techniques, like sparse SVMs, which induce sparsities in both feature and sample spaces.",1. Introduction,[0],[0]
"All these screening methods tend to be helpless in accelerating the training process of these
models with large n and p.",1. Introduction,[0],[0]
We cannot address this problem by simply combining the existing feature and sample screening methods either.,1. Introduction,[0],[0]
The reason is that they could mistakenly discard relevant data as they are specifically designed for different sparse models.,1. Introduction,[0],[0]
"Recently, Shibagaki et al. (2016) considered this issue and proposed a method to simultaneously identify the inactive features and samples in a dynamic manner, and they trigger their testing rule when there is a sufficient decrease in the duality gap during the training process.",1. Introduction,[0],[0]
"Thus, the method in Shibagaki et al. 2016 can discard more and more inactive features and samples as the training proceeds and one has small-scale problems to solve in the late stage of the training process.",1. Introduction,[0],[0]
"Nevertheless, the overall speedup is limited as the problems’ size can be large in the early stage of the training process.",1. Introduction,[0],[0]
"To be specific, the method in Shibagaki et al. 2016 depends heavily on the duality gap during the training process.",1. Introduction,[0],[0]
"The duality gap in the early stage can always be large, which makes the dual and primal estimations inaccurate and finally results in ineffective screening rules.",1. Introduction,[0],[0]
"Hence, it is essentially solving a large problem in the early stage.",1. Introduction,[0],[0]
"This will be verified in the experimental comparisons in Section 6 and similar results can also be found in the recent work (Massias et al., 2018), which merely focuses on Lasso.
",1. Introduction,[0],[0]
"In this paper, to address the limitations in the dynamic screening method, we propose a novel screening method that can Simultaneously identify Inactive Features and Samples (SIFS) for sparse SVMs in a static manner, and we only need to perform SIFS once before (instead of during) training.",1. Introduction,[0],[0]
"Thus, we only need to run the training algorithm on small-scale problems.",1. Introduction,[0],[0]
The major technical challenge in developing SIFS is that we need to accurately estimate the primal and dual optima.,1. Introduction,[0],[0]
"The more accurate the estimations are, the more effective SIFS is in detecting inactive features and samples.",1. Introduction,[0],[0]
"Thus, our major technical contribution is a novel framework, which is based on the strong convexity of the primal and dual problems of sparse SVMs for deriving accurate estimations of the primal and dual optima (see Section 3).",1. Introduction,[0],[0]
"Another appealing feature of SIFS is the so-called synergistic effect (Shibagaki et al., 2016).",1. Introduction,[0],[0]
"Specifically, the proposed SIFS consists of two parts, i.e., Inactive Feature Screening (IFS) and Inactive Sample Screening (ISS).",1. Introduction,[0],[0]
We show that discarding inactive features (resp. samples) identified by IFS (resp.,1. Introduction,[0],[0]
"ISS) leads to a more accurate estimation of the primal (resp. dual) optimum, which in turn dramatically enhances the capability of ISS (resp.",1. Introduction,[0],[0]
IFS),1. Introduction,[0],[0]
in detecting inactive samples (resp. features).,1. Introduction,[0],[0]
"Thus, SIFS applies IFS and ISS in an alternating manner until no more inactive features and samples can be identified, leading to much better performance in scaling up large-scale problems than the application of ISS or IFS individually.",1. Introduction,[0],[0]
"Moreover, SIFS (see Section 4) is safe in the sense that the detected features and samples are guaranteed to be absent from the sparse representations.",1. Introduction,[0],[0]
"To the best of our knowledge, SIFS is the first static screening rule for sparse SVMs, which is able to simultaneously detect inactive features and samples.",1. Introduction,[0],[0]
"Experiments (see Section 6) on both synthetic and real data sets demonstrate that SIFS significantly outperforms the state-of-the-art (Shibagaki et al., 2016) in improving the training efficiency of sparse SVMs and the speedup can be orders of magnitude.
",1. Introduction,[0],[0]
"To demonstrate the flexibility of our proposed method SIFS, we extend its idea to multi-class sparse support vector machine (see Section 5), which also induces sparsities in both feature and sample spaces.",1. Introduction,[0],[0]
"Although multi-class sparse SVM has a very different structure and is more complex than sparse SVM, we will see that its dual problem has some similar properties (especially the strong convexity) with those of sparse SVM.",1. Introduction,[0],[0]
"Recall that
SIFS we developed for sparse SVMs is mainly based on the strong convexity of the primal and dual problems.",1. Introduction,[0],[0]
"Therefore, the idea of SIFS is also applicable for multi-class sparse SVMs.",1. Introduction,[0],[0]
"Experimental results show that the speedup gained by SIFS in multi-class sparse SVMs can also be orders of magnitude.
",1. Introduction,[0],[0]
"For the convenience of presentation, we postpone the detailed proofs of all the theorems in this paper to the appendix.",1. Introduction,[0],[0]
"At last, we should point out that this journal paper is an extension of our own previous work (Zhang et al., 2017) published at the International Conference on Machine Learning (ICML) 2017.
Notations: Let ‖ · ‖1, ‖ · ‖, and ‖ · ‖∞ be `1, `2, and `∞ norms, respectively.",1. Introduction,[0],[0]
"We denote the inner product between vectors x and y by 〈x,y〉, and the i-th component of x by [x]i.",1. Introduction,[0],[0]
"Let [p] = {1, 2..., p} for a positive integer p.",1. Introduction,[0],[0]
"Given a subset J := {j1, ..., jk} of [p], let |J | be the cardinality of J .",1. Introduction,[0],[0]
"For a vector x, let [x]J = (",1. Introduction,[0],[0]
"[x]j1 , ..., [x]jk)>.",1. Introduction,[0],[0]
"For a matrix X, let [X]J = (xj1 , ...,xjk) and J [X] = ((x j1)>, ..., (xjk)>)",1. Introduction,[0],[0]
">, where xi and xj are the i th row and jth column of X, respectively.",1. Introduction,[0],[0]
"For a scalar t, we denote max{0, t} by [t]+.",1. Introduction,[0],[0]
"Let ek ∈ RK be the index vector, that is, [ek]i = 1 if i = k, otherwise [ek]i = 0.",1. Introduction,[0],[0]
"At last, we denote the set of nonnegative real numbers as R+.",1. Introduction,[0],[0]
"In this section, we briefly review some basics of sparse SVMs and then motivate SIFS via the KKT conditions.",2. Basics and Motivations,[0],[0]
"Specifically, we focus on an `1-regularized SVM with a smoothed hinge loss, which takes the form of
min w∈Rp
P (w;α, β) = 1
n n∑ i=1",2. Basics and Motivations,[0],[0]
"`(1− 〈x̄i,w〉) + α 2 ‖w‖2 + β||w||1, (P∗)
",2. Basics and Motivations,[0],[0]
where w ∈,2. Basics and Motivations,[0],[0]
"Rp is the parameter vector to be estimated, {xi, yi}ni=1 is the training set,",2. Basics and Motivations,[0],[0]
xi ∈,2. Basics and Motivations,[0],[0]
"Rp, yi ∈ {−1,+1}, x̄i = yixi, α and β are two positive parameters, and `(·) :",2. Basics and Motivations,[0],[0]
"R → R+ is the smoothed hinge loss, i.e.,
`(t) =  0, if t < 0, t2
2γ , if 0 ≤ t ≤",2. Basics and Motivations,[0],[0]
"γ, t− γ2 , if t > γ,
(1)
",2. Basics and Motivations,[0],[0]
"where γ ∈ (0, 1).
",2. Basics and Motivations,[0],[0]
Remark 1,2. Basics and Motivations,[0],[0]
"We use the smoothed hinge loss instead of the vanilla one in order to make the objective of the Lagrangian dual problem of (P∗) strongly convex, which is needed in developing our accurate optima estimations.",2. Basics and Motivations,[0],[0]
We should point out that the smoothed hinge loss is a pretty good approximation to the vanilla one with strong theoretical guarantees.,2. Basics and Motivations,[0],[0]
"See Section 5 in Shalev-Shwartz and Zhang 2016 for the details.
",2. Basics and Motivations,[0],[0]
"We present the Lagrangian dual problem of problem (P∗) and the KKT conditions in the following theorem, which play a fundamentally important role in developing our screening rules.",2. Basics and Motivations,[0],[0]
"We will not provide its proof in the appendix since it follows from Fenchel Duality (see Corollary 31.2.1 in Rockafellar, 1970) and a similar result can be found in Shibagaki et al. 2016.
",2. Basics and Motivations,[0],[0]
"Theorem 2 (Rockafellar, 1970) Let X̄ =",2. Basics and Motivations,[0],[0]
(,2. Basics and Motivations,[0],[0]
"x̄1, x̄2, ..., x̄n) and Sβ(·) be the soft-thresholding operator (Hastie et al., 2015), i.e., [Sβ(u)]i = sign([u]i)(|[u]i| − β)+.",2. Basics and Motivations,[0],[0]
"Then, for problem (P∗), the followings hold: (i) the dual problem of (P∗) is
min θ∈[0,1]n
D(θ;α, β) = 1
2α ∥∥∥∥Sβ",2. Basics and Motivations,[0],[0]
( 1nX̄θ ),2. Basics and Motivations,[0],[0]
"∥∥∥∥2 + γ2n‖θ‖2 − 1n〈1, θ〉, (D∗)
where 1 ∈ Rn is a vector with all components equal to 1; (ii) denote the optima of (P∗) and (D∗) by w∗(α, β) and θ∗(α, β), respectively, then,
w∗(α, β) = 1 α",2. Basics and Motivations,[0],[0]
"Sβ ( 1 n X̄θ∗(α, β) ) , (KKT-1)
",2. Basics and Motivations,[0],[0]
"[θ∗(α, β)]i =  0, if 1− 〈x̄i,w∗(α, β)〉 < 0; 1, if 1− 〈x̄i,w∗(α, β)〉 > γ; 1 γ (1− 〈x̄i,w ∗(α, β)〉), otherwise.",2. Basics and Motivations,[0],[0]
"(KKT-2)
",2. Basics and Motivations,[0],[0]
"According to KKT-1 and KKT-2, we define 4 index sets: F = { j ∈",2. Basics and Motivations,[0],[0]
"[p] : 1
n |[X̄θ∗(α, β)]j | ≤",2. Basics and Motivations,[0],[0]
"β
} ,
R = {i ∈",2. Basics and Motivations,[0],[0]
"[n] : 1− 〈w∗(α, β), x̄i〉 < 0}, E = {i ∈",2. Basics and Motivations,[0],[0]
"[n] : 1− 〈w∗(α, β), x̄i〉 ∈",2. Basics and Motivations,[0],[0]
"[0, γ]}, L = {i ∈",2. Basics and Motivations,[0],[0]
"[n] : 1− 〈w∗(α, β), x̄i〉 > γ},
which imply that (i)",2. Basics and Motivations,[0],[0]
i ∈ F ⇒,2. Basics and Motivations,[0],[0]
"[w∗(α, β)]i = 0, (ii) {",2. Basics and Motivations,[0],[0]
i ∈ R ⇒,2. Basics and Motivations,[0],[0]
"[θ∗(α, β)]i = 0, i ∈ L ⇒",2. Basics and Motivations,[0],[0]
"[θ∗(α, β)]i = 1.
(R)
",2. Basics and Motivations,[0],[0]
"Thus, we call the j-th feature inactive if j ∈ F .",2. Basics and Motivations,[0],[0]
"The samples in E are the so-called support vectors and we call the samples in R and L inactive samples.
",2. Basics and Motivations,[0],[0]
"Suppose that we are given subsets of F , R, and L. Then by the rules in (R), we can see that many coefficients of w∗(α, β) and θ∗(α, β) are known.",2. Basics and Motivations,[0],[0]
"Thus, we may have much fewer unknowns to solve and the problem size can be dramatically reduced.",2. Basics and Motivations,[0],[0]
"We formalize this idea in Lemma 3.
",2. Basics and Motivations,[0],[0]
Lemma 3,2. Basics and Motivations,[0],[0]
"Given index sets F̂ ⊆ F , R̂ ⊆ R, and L̂ ⊆ L, the followings hold: (i)",2. Basics and Motivations,[0],[0]
"[w∗(α, β)]F̂ = 0, [θ ∗(α, β)]R̂ = 0, [θ ∗(α, β)]L̂ = 1; (ii) let D̂ = R̂ ∪ L̂, Ĝ1 = F̂c",2. Basics and Motivations,[0],[0]
"[X̄]D̂c , and Ĝ2 = F̂c",2. Basics and Motivations,[0],[0]
"[X̄]L̂, where F̂ c =",2. Basics and Motivations,[0],[0]
"[p] \ F̂ , D̂c =",2. Basics and Motivations,[0],[0]
"[n] \ D̂, and L̂c =",2. Basics and Motivations,[0],[0]
"[n] \ L̂. Then, [θ∗(α, β)]D̂c solves the following scaled dual problem:
min θ̂∈[0,1]|D̂c| { 1 2α ∥∥∥∥Sβ",2. Basics and Motivations,[0],[0]
( 1nĜ1θ̂ + 1nĜ21 ),2. Basics and Motivations,[0],[0]
∥∥∥∥2 + γ2n‖θ̂‖2,2. Basics and Motivations,[0],[0]
"− 1n〈1, θ̂〉}; (scaled-D∗)
(iii) suppose that θ∗(α, β) is known, then,
[w∗(α, β)]F̂c = 1 α",2. Basics and Motivations,[0],[0]
Sβ ( 1 n F̂,2. Basics and Motivations,[0],[0]
c,2. Basics and Motivations,[0],[0]
"[X̄]θ ∗(α, β) ) .
",2. Basics and Motivations,[0],[0]
"Lemma 3 indicates that, if we can identify index sets F̂ and D̂ and the cardinalities of F̂c and D̂c are much smaller than the feature dimension p and the sample size n, we only need to solve problem (scaled-D∗) that may be much smaller than problem (D∗) to exactly recover the optima w∗(α, β) and θ∗(α, β) without sacrificing any accuracy.
",2. Basics and Motivations,[0],[0]
"However, we cannot directly apply Rules in (R) to identify subsets of F , R, and L, as they require the knowledge of w∗(α, β) and θ∗(α, β) that are usually unavailable.",2. Basics and Motivations,[0],[0]
"Inspired by the idea in El Ghaoui et al. 2012, we can first estimate regions W and Θ that contain w∗(α, β) and θ∗(α, β), respectively.",2. Basics and Motivations,[0],[0]
"Then, by denoting
F̂ := { j ∈",2. Basics and Motivations,[0],[0]
[p] :,2. Basics and Motivations,[0],[0]
"max
θ∈Θ {∣∣∣∣ 1n",2. Basics and Motivations,[0],[0]
"[X̄θ]j ∣∣∣∣} ≤ β} , (2)
R̂ := { i ∈",2. Basics and Motivations,[0],[0]
"[n] : max
w∈W {1− 〈w, x̄i〉} < 0
} , (3)
",2. Basics and Motivations,[0],[0]
L̂ := { i ∈,2. Basics and Motivations,[0],[0]
"[n] : min
w∈W {1− 〈w, x̄i〉} >",2. Basics and Motivations,[0],[0]
"γ
} , (4)
since it is easy to know that F̂ ⊂ F , R̂ ⊂ R, and",2. Basics and Motivations,[0],[0]
"L̂ ⊂ L, the rules in (R) can be relaxed as:
(i) j ∈ F̂ ⇒",2. Basics and Motivations,[0],[0]
"[w∗(α, β)]j = 0, (R1)
(ii) { i ∈ R̂ ⇒",2. Basics and Motivations,[0],[0]
"[θ∗(α, β)]i = 0, i ∈ L̂ ⇒",2. Basics and Motivations,[0],[0]
"[θ∗(α, β)]i = 1.
(R2)
",2. Basics and Motivations,[0],[0]
"In view of Rules R1 and R2, we sketch the development of SIFS as follows.
",2. Basics and Motivations,[0],[0]
"Step 1: Derive estimations W and Θ such that w∗(α, β) ∈ W and θ∗(α, β) ∈ Θ, respectively.
",2. Basics and Motivations,[0],[0]
"Step 2: Develop SIFS by deriving the relaxed screening rules R1 and R2, i.e., by solving the optimization problems in Eqs.",2. Basics and Motivations,[0],[0]
"(2), (3) and (4).",2. Basics and Motivations,[0],[0]
"In this section, we first show that the primal and dual optima admit closed-form solutions for specific values of α and β (Section 3.1).",3. Estimate the Primal and Dual Optima,[0],[0]
"Then, in Sections 3.2 and 3.3, we present accurate estimations of the primal and dual optima, respectively.",3. Estimate the Primal and Dual Optima,[0],[0]
"We would like to point out that in order to extend the optimum estimation results below to multi-class sparse SVM and avoid redundancy, we consider the optimum estimations for the primal and dual problems in more general forms.",3. Estimate the Primal and Dual Optima,[0],[0]
Below we show two things.,3.1 Effective Intervals of Parameters α and β,[0],[0]
"One is that if the value of β is sufficiently large, no matter what α is, the primal solution is 0.",3.1 Effective Intervals of Parameters α and β,[0],[0]
"The other is for any β, if α is large enough, the primal and dual optima admit closed-form solutions.
",3.1 Effective Intervals of Parameters α and β,[0],[0]
"Lemma 4 Let βmax = ‖ 1nX̄1‖∞ and αmax(β) = 1 1−γ maxi∈[n] { 〈x̄i,Sβ( 1nX̄1)〉 } .",3.1 Effective Intervals of Parameters α and β,[0],[0]
"Then, (i) for α > 0 and β ≥ βmax, we have
w∗(α, β) = 0, θ∗(α, β) = 1;
(ii) for all α ∈ [max{αmax(β), 0},∞) ∩ (0,∞), we have
w∗(α, β) = 1 α",3.1 Effective Intervals of Parameters α and β,[0],[0]
"Sβ ( 1 n X̄1 ) , θ∗(α, β) = 1. (5)
",3.1 Effective Intervals of Parameters α and β,[0],[0]
"By Lemma 4, we only need to consider the cases where β ∈ (0, βmax] and α ∈ (0, αmax(β)].",3.1 Effective Intervals of Parameters α and β,[0],[0]
"In Section 1, we mention that the proposed SIFS consists of IFS and ISS, which can identify the inactive features and samples, respectively.",3.2 Primal Optimum Estimation,[0],[0]
"We also mention that an alternating application of IFS and ISS can improve the estimation accuracy of the primal and dual optimum estimations, which can in turn make ISS and IFS more effective in identifying inactive samples and features, respectively.",3.2 Primal Optimum Estimation,[0],[0]
"We would like to show that discarding inactive features by IFS leads to a more accurate estimation of the primal optimum.
",3.2 Primal Optimum Estimation,[0],[0]
"We consider the following general problem (g-P∗):
min w∈Rp
P (w;α, β) = L(w) + α
2 ‖w‖2 + β||w||1, (g-P∗)
where L(w) :",3.2 Primal Optimum Estimation,[0],[0]
Rp → R+ is smooth and convex.,3.2 Primal Optimum Estimation,[0],[0]
"Exploiting the strong convexity of the objective function, we obtain the optimum estimation in the following lemma.
",3.2 Primal Optimum Estimation,[0],[0]
"Lemma 5 Suppose that the optimum w∗(α0, β0) of problem (g-P ∗) at (α0, β0) with β0 ∈ (0, βmax] and α0 ∈ (0, αmax(β0)] is known.",3.2 Primal Optimum Estimation,[0],[0]
Consider problem (g-P∗) with parameters α > 0 and β0.,3.2 Primal Optimum Estimation,[0],[0]
"Let F̂ be the index set satisfying [w∗(α, β0)]F̂ = 0 and define
c = α0 + α
2α [w∗(α0, β0)]F̂c , (6)
r2 = (α0 − α)2
4α2 ‖w∗(α0, β0)‖2 −
(α0 + α) 2
4α2 ‖[w∗(α0, β0)]F̂‖ 2.",3.2 Primal Optimum Estimation,[0],[0]
"(7)
Then, the following holds:
[w∗(α, β0)]F̂c ∈ {w : ‖w",3.2 Primal Optimum Estimation,[0],[0]
− c‖ ≤,3.2 Primal Optimum Estimation,[0],[0]
"r}.
",3.2 Primal Optimum Estimation,[0],[0]
"For problem (P∗), let F̂ be the index set of inactive features identified by previous IFS steps.",3.2 Primal Optimum Estimation,[0],[0]
"We have [w∗(α, β0)]F̂ = 0.",3.2 Primal Optimum Estimation,[0],[0]
"Hence, we only need to find an estimation for [w∗(α, β0)]F̂c .",3.2 Primal Optimum Estimation,[0],[0]
"Since problem (P ∗) is a special case of problem (g-P∗), given the reference solution w∗(α0, β0) and the set F̂ , from Lemma 5 we have:
[w∗(α, β0)]F̂c ∈ W",3.2 Primal Optimum Estimation,[0],[0]
:= {w : ‖w − c‖ ≤,3.2 Primal Optimum Estimation,[0],[0]
"r}, (8)
where c and r are defined in Eqs.",3.2 Primal Optimum Estimation,[0],[0]
"(6) and (7), respectively.",3.2 Primal Optimum Estimation,[0],[0]
"It shows that [w∗(α, β0)]F̂c lies in a ball of radius r centered at c. Note that, before we perform IFS, the set F̂ is empty and the second term on the right hand side of Eq.",3.2 Primal Optimum Estimation,[0],[0]
(7) is thus 0.,3.2 Primal Optimum Estimation,[0],[0]
"If we apply IFS multiple times alternatively with ISS, the set F̂ will be monotonically increasing.",3.2 Primal Optimum Estimation,[0],[0]
"Thus, Eq. (7) implies that the radius will be monotonically decreasing, leading to a more accurate primal optimum estimation.",3.2 Primal Optimum Estimation,[0],[0]
"We consider a general dual problem (g-D∗) below:
min θ∈[0,1]n
D(θ;α, β) = 1
2α fβ(θ)",3.3 Dual Optimum Estimation,[0],[0]
"+
",3.3 Dual Optimum Estimation,[0],[0]
γ 2n ‖θ‖2,3.3 Dual Optimum Estimation,[0],[0]
"− 1 n 〈v, θ〉, (g-D∗)
",3.3 Dual Optimum Estimation,[0],[0]
where v ∈,3.3 Dual Optimum Estimation,[0],[0]
Rn and fβ(θ),3.3 Dual Optimum Estimation,[0],[0]
:,3.3 Dual Optimum Estimation,[0],[0]
Rn → R+ is smooth and convex.,3.3 Dual Optimum Estimation,[0],[0]
It is obvious that problem (g-D∗) can be reduced to problem (D∗) by letting fβ(θ) =,3.3 Dual Optimum Estimation,[0],[0]
∥∥Sβ ( 1nX̄θ)∥∥2 and v = 1.,3.3 Dual Optimum Estimation,[0],[0]
"The lemma below gives an optimum estimation of problem (g-D∗) based on the strong convexity of its objective function.
",3.3 Dual Optimum Estimation,[0],[0]
"Lemma 6 Suppose that the optimum θ∗(α0, β0) of problem (g-D ∗) with β0 ∈ (0, βmax] and α0 ∈ (0, αmax(β0)] is known.",3.3 Dual Optimum Estimation,[0],[0]
"Consider problem (g-D∗) at (α, β0) with α > 0",3.3 Dual Optimum Estimation,[0],[0]
"and let R̂ and L̂ be two index sets satisfying [θ∗(α, β0)]R̂ = 0",3.3 Dual Optimum Estimation,[0],[0]
"and [θ ∗(α, β0)]L̂ = 1, respectively.",3.3 Dual Optimum Estimation,[0],[0]
"We denote D̂ = R̂ ∪ L̂ and define
c = α− α0
2γα",3.3 Dual Optimum Estimation,[0],[0]
"[v]D̂c +
α0 + α
2α [θ∗(α0, β0)]D̂c , (9)
r2 =( α− α0
2α )2||θ∗(α0, β0)−
1 γ v||2 − ||1− α− α0 2γα",3.3 Dual Optimum Estimation,[0],[0]
"[v]L̂ − α0 + α 2α [θ∗(α0, β0)]L̂|| 2
− ||α− α0 2γα",3.3 Dual Optimum Estimation,[0],[0]
"[v]R̂ + α0 + α 2α [θ∗(α0, β0)]R̂|| 2. (10)
",3.3 Dual Optimum Estimation,[0],[0]
"Then, the following holds:
[θ∗(α, β0)]D̂c ∈ {θ : ‖θ",3.3 Dual Optimum Estimation,[0],[0]
− c‖ ≤,3.3 Dual Optimum Estimation,[0],[0]
"r}.
",3.3 Dual Optimum Estimation,[0],[0]
We now turn back to problem (D∗).,3.3 Dual Optimum Estimation,[0],[0]
"As it is a special case of problem (g-D∗), given the reference solution θ∗(α0, β0) at (α0, β0) and the index sets of inactive samples identified by the previous ISS steps R̂ and L̂, using Lemma 6, we can obtain:
[θ∗(α",3.3 Dual Optimum Estimation,[0],[0]
", β0)]D̂c ∈ Θ",3.3 Dual Optimum Estimation,[0],[0]
:= {θ : ‖θ − c‖ ≤,3.3 Dual Optimum Estimation,[0],[0]
"r}, (11)
where c and r are defined by Eqs.",3.3 Dual Optimum Estimation,[0],[0]
"(9) and (10) with v = 1, respectively.",3.3 Dual Optimum Estimation,[0],[0]
"Therefore, [θ∗(α, β0)]D̂c lies in the ball Θ.",3.3 Dual Optimum Estimation,[0],[0]
In view of Eq.,3.3 Dual Optimum Estimation,[0],[0]
"(10), the index sets L̂ and R̂ monotonically increase and hence the last two terms on the right hand side of Eq.",3.3 Dual Optimum Estimation,[0],[0]
"(10) monotonically increase when we perform ISS multiple times (alternating with IFS), which implies that the ISS steps can reduce the radius and thus improve the dual optimum estimation.
",3.3 Dual Optimum Estimation,[0],[0]
"In addition, from both Lemmas 5 and 6, we can see that the radii of W and Θ can be potentially large when α is very small, which may affect our estimation accuracy.",3.3 Dual Optimum Estimation,[0],[0]
We can sidestep this issue by letting the ratio α/α0 be a constant.,3.3 Dual Optimum Estimation,[0],[0]
"That is why we space the values of α equally at the logarithmic scale on the parameter value path in the experiments.
",3.3 Dual Optimum Estimation,[0],[0]
"Remark 7 To estimate the optima w∗(α, β0) and θ ∗(α, β0) of problems (P ∗) and (D∗) using Lemmas 5 and 6, we have a free reference solution pair w∗(α0, β0) and θ
∗(α0, β0) with α0 = αmax(β0).",3.3 Dual Optimum Estimation,[0],[0]
"The reason is that w ∗(α0, β0) and θ ∗(α0, β0) admit closed-form solutions in this setting (see Lemma 4).",3.3 Dual Optimum Estimation,[0],[0]
"We first present the IFS and ISS rules in Sections 4.1 and 4.2, respectively.",4. The Proposed SIFS Screening Rule,[0],[0]
"Then, in Section 4.3, we develop the SIFS screening rule by an alternating application of IFS and ISS.",4. The Proposed SIFS Screening Rule,[0],[0]
"Suppose that w∗(α0, β0) and θ ∗(α0, β0) are known, we derive IFS to identify inactive features for problem (P∗) at (α, β0) by solving the optimization problem in Eq.",4.1 Inactive Feature Screening (IFS),[0],[0]
"(2) (see Section A.5 in the appendix):
si(α, β0) = max θ∈Θ
{ 1
n |〈[x̄i]D̂c , θ〉+ 〈[x̄
i]L̂,1〉| } , i ∈ F̂c, (12)
where Θ is given by Eq.",4.1 Inactive Feature Screening (IFS),[0],[0]
"(11) and F̂ and D̂ = R̂ ∪ L̂ are the index sets of inactive features and samples that have been identified in previous screening processes, respectively.",4.1 Inactive Feature Screening (IFS),[0],[0]
"The next result shows the closed-form solution of problem (12).
",4.1 Inactive Feature Screening (IFS),[0],[0]
Lemma 8 Consider problem (12).,4.1 Inactive Feature Screening (IFS),[0],[0]
Let c and r be given by Eq.,4.1 Inactive Feature Screening (IFS),[0],[0]
(9) and Eq. (10) with v = 1.,4.1 Inactive Feature Screening (IFS),[0],[0]
"Then, for all i ∈",4.1 Inactive Feature Screening (IFS),[0],[0]
"F̂c, we have
si(α, β0) = 1
n",4.1 Inactive Feature Screening (IFS),[0],[0]
"(|〈[x̄i]D̂c ,",4.1 Inactive Feature Screening (IFS),[0],[0]
c〉+ 〈,4.1 Inactive Feature Screening (IFS),[0],[0]
"[x̄ i]L̂,1〉|+ ‖[x̄ i]D̂c‖r).
",4.1 Inactive Feature Screening (IFS),[0],[0]
"We are now ready to present the IFS rule.
",4.1 Inactive Feature Screening (IFS),[0],[0]
Theorem 9,4.1 Inactive Feature Screening (IFS),[0],[0]
[Feature screening rule IFS],4.1 Inactive Feature Screening (IFS),[0],[0]
Consider problem (P∗).,4.1 Inactive Feature Screening (IFS),[0],[0]
"We suppose that w∗(α0, β0) and θ∗(α0, β0) are known.",4.1 Inactive Feature Screening (IFS),[0],[0]
"Then:
(1) the feature screening rule IFS takes the form of
si(α, β0) ≤ β0 ⇒",4.1 Inactive Feature Screening (IFS),[0],[0]
"[w∗(α, β0)]i = 0,∀i ∈ F̂c; (IFS)
(2) we can update the index set F̂ by
F̂ ← F̂ ∪∆F̂ with ∆F̂ = {i : si ≤ β0, i ∈ F̂c}.",4.1 Inactive Feature Screening (IFS),[0],[0]
"(13)
Recall that (see Lemma 6) previous sample screening results give us a tighter dual estimation, i.e., a smaller feasible region Θ for problem (12), which results in a smaller si(α, β0).",4.1 Inactive Feature Screening (IFS),[0],[0]
It finally brings about a more powerful feature screening rule IFS.,4.1 Inactive Feature Screening (IFS),[0],[0]
This is the so called synergistic effect.,4.1 Inactive Feature Screening (IFS),[0],[0]
"Similar to IFS, we derive ISS to identify inactive samples by solving the optimization problems in Eq.",4.2 Inactive Sample Screening (ISS),[0],[0]
"(3) and Eq. (4) (see Section A.7 in the appendix for details):
ui(α, β0) = max w∈W
{1− 〈[x̄i]F̂c ,w〉}, i ∈",4.2 Inactive Sample Screening (ISS),[0],[0]
"D̂ c, (14)
li(α, β0) =",4.2 Inactive Sample Screening (ISS),[0],[0]
"min w∈W
{1− 〈[x̄i]F̂c ,w〉}, i ∈",4.2 Inactive Sample Screening (ISS),[0],[0]
"D̂ c, (15)
whereW is given by Eq.",4.2 Inactive Sample Screening (ISS),[0],[0]
(8) and F̂ and D̂ = R̂∪ L̂ are the index sets of inactive features and samples that have been identified in previous screening processes.,4.2 Inactive Sample Screening (ISS),[0],[0]
"We show that problems (14) and (15) admit closed-form solutions.
",4.2 Inactive Sample Screening (ISS),[0],[0]
Lemma 10 Consider problems (14) and (15).,4.2 Inactive Sample Screening (ISS),[0],[0]
Let c and r be given by Eq.,4.2 Inactive Sample Screening (ISS),[0],[0]
(6) and Eq. (7).,4.2 Inactive Sample Screening (ISS),[0],[0]
"Then,
ui(α, β0) = 1− 〈[x̄i]F̂c , c〉+ ‖[x̄i]F̂c‖r, i ∈",4.2 Inactive Sample Screening (ISS),[0],[0]
"D̂ c,
li(α, β0)",4.2 Inactive Sample Screening (ISS),[0],[0]
= 1− 〈,4.2 Inactive Sample Screening (ISS),[0],[0]
"[x̄i]F̂c , c〉 − ‖[x̄i]F̂c‖r, i ∈",4.2 Inactive Sample Screening (ISS),[0],[0]
"D̂ c.
We are now ready to present the ISS rule.
",4.2 Inactive Sample Screening (ISS),[0],[0]
Theorem 11,4.2 Inactive Sample Screening (ISS),[0],[0]
"[Sample screening rule ISS] Consider problem (D∗) and suppose that w∗(α0, β0) and θ∗(α0, β0) are known, then:
(1) the sample screening rule ISS takes the form of
ui(α, β0)",4.2 Inactive Sample Screening (ISS),[0],[0]
< 0⇒,4.2 Inactive Sample Screening (ISS),[0],[0]
"[θ∗(α, β0)]i = 0, li(α, β0) >",4.2 Inactive Sample Screening (ISS),[0],[0]
γ ⇒,4.2 Inactive Sample Screening (ISS),[0],[0]
"[θ∗(α, β0)]i = 1, ∀i ∈ D̂c; (ISS)
(2) we can update the index sets R̂ and L̂ by
R̂ ← R̂ ∪∆R̂ with ∆R̂",4.2 Inactive Sample Screening (ISS),[0],[0]
"= {i : ui(α, β0) < 0, i ∈ D̂c}, (16) L̂ ← L̂ ∪∆L̂ with ∆L̂ = {i : li(α, β0)",4.2 Inactive Sample Screening (ISS),[0],[0]
>,4.2 Inactive Sample Screening (ISS),[0],[0]
"γ, i ∈ D̂c}.",4.2 Inactive Sample Screening (ISS),[0],[0]
"(17)
",4.2 Inactive Sample Screening (ISS),[0],[0]
The synergistic effect also exists here.,4.2 Inactive Sample Screening (ISS),[0],[0]
"Recall that (see Lemma 5), previous feature screening results lead to a smaller feasible region W for problems (14) and (15), which results in smaller ui(α, β0) and larger li(α, β0).",4.2 Inactive Sample Screening (ISS),[0],[0]
It finally leads us to a more accurate sample screening rule ISS.,4.2 Inactive Sample Screening (ISS),[0],[0]
"In real applications, the optimal parameter values of α and β are usually unknown.",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"To determine appropriate parameter values, common approaches, like cross validation and stability selection, need to solve the model over a grid of parameter values {(αi,j , βj) :",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
i ∈,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"[M ], j ∈",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
[N ]} with βmax >,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
β1,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
> ... > βN,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
> 0 and αmax(βj) >,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"α1,j > ... >",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"αM,j > 0.",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
This can be very time-consuming.,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"Inspired by Strong Rule (Tibshirani et al., 2012) and SAFE (El Ghaoui et al., 2012), we develop a sequential version of SIFS in Algorithm 1.",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"Specifically, given the primal and dual optima w∗(αi−1,j , βj) and θ
∗(αi−1,j , βj) at (αi−1,j , βj), we apply SIFS to identify the inactive features and samples for problem (P∗) at (αi,j , βj).",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"Then, we perform training on the reduced data set and solve the primal and dual optima at (αi,j , βj).",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"We repeat this process until we solve problem (P∗) at all pairs of parameter values.
",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"Note that we insert α0,j into every sequence {αi,j :",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
i ∈,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
[M ]} ( see line 1 in Algorithm 1) to obtain a closed-form solution as the first reference solution.,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"In this way, we can avoid solving problem at (α1,j , βj), j ∈",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"[N ] directly (without screening), which is time consuming.",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"At last, we would like to point out that the values {(αi,j , βj) :",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
i ∈,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"[M ], j ∈",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"[N ]} in SIFS can be specified by users arbitrarily.
",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"Algorithm 1 SIFS
1: Input: βmax >",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
β1 > ... > βN,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
> 0 and αmax(βj) =,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"α0,j > α1,j > ...",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
>,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"αM,j > 0.",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"2: for j = 1 to N do 3: Compute the first reference solution w∗(α0,j , βj) and θ
∗(α0,j , βj) using the close-form formulas in Eq.",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"(5).
4: for i = 1 to M do 5: Initialization: F̂ = R̂ = L̂ = ∅. 6: repeat 7: Run sample screening using rule ISS based on w∗(αi−1,j , βj).",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
8: Update the inactive sample sets R̂ and L̂: R̂ ← R̂ ∪∆R̂ and L̂ ← L̂ ∪∆L̂. 9:,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"Run feature screening using rule IFS based on θ∗(αi−1,j , βj).
10: Update the inactive feature set F̂ : F̂ ← F̂ ∪∆F̂ .",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"11: until No new inactive features or samples are identified 12: Compute w∗(αi,j , βj) and θ
∗(αi,j , βj) by solving the scaled problem.",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"13: end for 14: end for 15: Output:w∗(αi,j , βj) and θ ∗(αi,j , βj), i ∈",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"[M ], j ∈",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"[N ].
SIFS applies ISS and IFS in an alternating manner to reinforce their capability in identifying inactive samples and features.",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"In Algorithm 1, we apply ISS first.",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"Of course, we can also apply IFS first.",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"The theorem below demonstrates that the orders have no impact on the performance of SIFS.
",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
Theorem 12,4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"Given the optimal solutions w∗(αi−1,j , βj) and θ ∗(αi−1,j , βj) at (αi−1,j , βj) as the reference solution pair at (αi,j , βj) for SIFS, we assume SIFS with ISS first stops after applying IFS and ISS for s times and denote the identified inactive features and samples as F̂As , R̂As , and L̂As .",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"Similarly, when we apply IFS first, the results are denoted as F̂Bt , R̂Bt , and L̂Bt .",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"Then, the followings hold: (1) F̂As = F̂Bt , R̂As = R̂Bt , and L̂As = L̂Bt .",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"(2) with different orders of applying ISS and IFS, the difference between the times of ISS and IFS we need to apply in SIFS can never be larger than 1, that is, |s− t| ≤ 1.",4.3 The Proposed SIFS Rule by An Alternating Application of IFS and ISS,[0],[0]
"After developing the proposed method SIFS above, we now turn to the related work discussion in order to highlight the differences between SIFS and the existing methods and also the novelty of our method, although we have mentioned some of them in the introduction section.",4.4 Discussion,[0],[0]
"We divide the previous work into two parts: screening for sparse SVM and for other sparse learning models.
",4.4 Discussion,[0],[0]
"To the best of our knowledge, the screening method in Shibagaki et al. 2016 is the only method besides our SIFS, which can simultaneously identify the inactive features and samples for sparse SVM.",4.4 Discussion,[0],[0]
There are mainly three big differences between SIFS and this method.,4.4 Discussion,[0],[0]
"First, the techniques used in the optima estimations of SIFS and Shibagaki
et al. 2016 are quite different.",4.4 Discussion,[0],[0]
"To be specific, the estimations in SIFS are developed by exploiting the reference solution pair and carefully studying the strong convexity of the objective functions and the optimum conditions of problems (P∗) and (D∗) at the current and reference parameter value pairs (see Lemmas 5 and 6 and also their proofs for the details).",4.4 Discussion,[0],[0]
"In contrast, Shibagaki et al. (2016) estimated the optima heavily based on the duality gap.",4.4 Discussion,[0],[0]
"As we mentioned in the introduction section, duality gap is usually large in the early stages and decreases gradually, which weakens its capability in the early stages and leads to a limited overall speedup.",4.4 Discussion,[0],[0]
"Second, algorithmically, Shibagaki et al. (2016) is dynamic while our method is static.",4.4 Discussion,[0],[0]
"In other words, Shibagaki et al. (2016) identifies the inactive features and samples during the training process, and in our method, we do this before the training process (see steps 6 to 11 in Algorithm 1), which means Shibagaki et al. (2016) needs to apply its screening rules for many times while we trigger SIFS only once.",4.4 Discussion,[0],[0]
"These two technical and algorithmic differences make our method outperform Shibagaki et al. (2016), which will be verified in the experimental section.",4.4 Discussion,[0],[0]
"At last, we theoretically prove that in the static scenario the orders of applying the feature and sample screening rules have no impact on the final performance, while Shibagaki et al. (2016) did not give the theoretical result accordingly in dynamic screening.
",4.4 Discussion,[0],[0]
There are mainly three big differences between our SIFS and existing methods for other sparse learning models.,4.4 Discussion,[0],[0]
"First, these existing methods identify either features or samples individually and would be helpless in real applications involving a huge number of samples and extremely high-dimensional features, while SIFS identifies features and samples simultaneously.",4.4 Discussion,[0],[0]
"Second, technically, SIFS can incorporate the feature (resp. sample) screening results of the previous steps as the prior knowledge into the primal (reps. dual) optimum estimation to obtain a more accurate estimation.",4.4 Discussion,[0],[0]
This is verified with a strong theoretical guarantee (see Lemmas 5 and 6).,4.4 Discussion,[0],[0]
"At last, we give a theoretical proof (see Sections 4.1 and 4.2) to show the existence of the synergistic effect between feature and sample screening for the first time in the static scenario.
",4.4 Discussion,[0],[0]
"Finally, we would like to point out that although the key ideas used in some of the screening methods including SIFS seem to be similar, they are developed specifically for the sparse models they focus on, which makes it nontrivial and even very difficult to reduce one method to another by simply resetting the loss and regularizer of the model.",4.4 Discussion,[0],[0]
"For example, SIFS cannot be reduced to Wang et al. (2014b) by setting α = 0 and letting loss be the logistic loss, although both of their dual optimum estimations are based on the strong convexity of the objective.",4.4 Discussion,[0],[0]
"The reason is that they use the strong convexity in quite different ways due to their different dual problems including the feasible regions and the expressions of the dual objectives (see Theorem 2 in Wang et al., 2014b, Lemma 6 above, and their proofs for the details).",4.4 Discussion,[0],[0]
"Moreover, we cannot reduce SIFS to the methods (Ogawa et al., 2013; Wang et al., 2014a) for SVM by setting β to be 0, since they are based on the convexity of the objective while SIFS exploits the strong convexity.",4.4 Discussion,[0],[0]
"In this section, we consider extending SIFS to multi-class sparse SVMs.",5. SIFS for Multi-class Sparse SVMs,[0],[0]
"We will briefly review the basics of multi-class sparse SVMs and then derive a series of theorems as we did
for sparse SVMs above.",5. SIFS for Multi-class Sparse SVMs,[0],[0]
"Finally, we will present the detailed screening rule for multi-class sparse SVMs.",5. SIFS for Multi-class Sparse SVMs,[0],[0]
"We focus on the `1-regularized multi-class SVM with a smoothed hinge loss, which takes the form of
min w∈RKp
P (w;α, β) = 1
n n∑ i=1",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
`i(w) + α 2,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"‖w‖2 + β||w||1, (m-P∗)
",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
where w =,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
[w1; w2; ...; wK ] ∈ RKp is the parameter vector to be estimated with wk ∈,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"Rp, k = 1, ...,K.",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
The loss function `i(w) = ∑ k 6=yi `(w > k,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"xi −w>yixi + 1), with {xi, yi} n i=1 is the training data set of K classes, xi ∈",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"Rp, yi ∈ {1, ...,K}, and `(·) is the smoothed hinge loss defined in Eq.",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"(1).
",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"The following theorem presents the Lagrangian dual problem of (m-P∗) and the KKT conditions, which are essential for developing the screening rules.
",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
Theorem 13,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"For each sample (xi, yi), we define ui = 1−eyi ∈ RK and Xi =",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[X1i ,X2i , ...,XKi ] ∈ RKp×K , where Xki = vec(xi(ek",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
− eyi)>) ∈ RKp.,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
Let u =,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
[u1; ...; un] ∈ RKn and X =,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[X1,X2, ...,Xn] ∈ RKp×Kn.",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"Then, for the problem (m-P∗), the followings hold: (i) the dual problem of (m-P∗) is
min θ∈[0,1]Kn
D(θ;α, β) = 1
2α ∥∥∥∥Sβ",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
( 1nXθ )∥∥∥∥2 + γ2n‖θ‖2,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"− 1n〈u, θ〉, (m-D∗)
where θ = [θ1; ...; θn] with θi ∈",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[0, 1]K , i = 1, ..., n; (ii) denote the optima of problems (m-P∗) and (m-D∗) by w∗(α, β) and θ∗(α, β), respectively, then,
w∗(α, β) = 1 α",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"Sβ ( − 1 n Xθ∗(α, β) ) , (m-KKT-1)
",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[θ∗i (α, β)]k =  0, if 〈Xki ,w∗(α, β)〉+",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[ui]k ≤ 0; 1, if 〈Xki ,w∗(α, β)〉+",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
[ui]k ≥ γ; 1 γ (〈X k,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"i ,w ∗(α, β)〉+",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[ui]k), otherwise; k = 1, 2, ...,K. (m-KKT-2)
",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"As we did in Section 2, we can also define 3 index sets here: F = {
(k, j) ∈",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[K]× [p] : 1 n |[Xθ∗(α, β)]k,j | ≤ β
} ,
R = { (i, k) ∈",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[n]× [K] : 〈Xki ,w∗(α, β)〉+",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[ui]k ≤ 0 } ,
L = { (i, k) ∈",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[n]× [K] : 〈Xki ,w∗(α, β)〉+",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[ui]k ≥ γ } ,
which imply that
(i) (k, j) ∈ F ⇒",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[w∗k(α, β)]j = 0,
(ii) { (i, k) ∈",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
R ⇒,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[θ∗i (α, β)]k = 0, (i, k) ∈ L ⇒",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[θ∗i (α, β)]k = 1.
(m-R)
Suppose that we are given three subsets of F ,R, and L, then we can infer the values of many coefficients of w∗(α, β) and θ∗(α, β) via Rule m-R. The lemma below shows that the rest coefficients of w∗(α, β) and θ∗(α, β) can be recovered by solving a small sized problem.
",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
Lemma 14,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"Given index sets F̂ ⊆ F , R̂ ⊆ R, and",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"L̂ ⊂ L, the followings hold: (i)",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[w∗(α, β)]F̂ = 0, [θ ∗(α, β)]R̂ = 0, [θ ∗(α, β)]L̂ = 1; (ii) let D̂ = R̂ ∪ L̂, Ĝ1 = F̂c",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[X]D̂c, and Ĝ2 = F̂c",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[X]L̂, where F̂ c =",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
[K] ×,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[p] \ F̂ , D̂c =",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[n]× [K] \ D̂, L̂c = [n]× [K] \ L̂ and û = [u]D̂c , then, [θ ∗(α, β)]D̂c solves the following scaled dual problem:
min θ̂∈[0,1]|D̂c| { 1 2α ∥∥∥∥Sβ",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
( 1nĜ1θ̂ + 1nĜ21 ),5.1 Basics of Multi-class Sparse SVMs,[0],[0]
∥∥∥∥2 + γ2n‖θ̂‖2,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"− 1n〈û, θ̂〉}; (m-scaled-D∗)
(iii) suppose that θ∗(α, β) is known, then,
[w∗(α, β)]F̂c = 1 α",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
Sβ ( − 1 n F̂,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
c,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[X]θ ∗(α, β) ) .
",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"Given two estimations W and Θ for w∗(α, β) and θ∗(α, β), we can define three subsets of F ,R, and L below as we did in the binary case to relax Rule m-R into the applicable version:
F̂ = {
(k, j) ∈",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[K]× [p] : max θ∈Θ
{ 1
n |[Xθ]k,j |
} ≤ β } ,
R̂ = {
(i, k) ∈",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[n]× [K] : max w∈W
{ 〈Xki ,w〉+ [ui]k } ≤ 0 } ,
L̂ = {
(i, k) ∈",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"[n]× [K] : min w∈W
{ 〈Xki ,w∗(α, β)〉+",5.1 Basics of Multi-class Sparse SVMs,[0],[0]
[ui]k〉 } ≥ γ } .,5.1 Basics of Multi-class Sparse SVMs,[0],[0]
"We first derive the effective intervals of the parameters α and β.
",5.2 Estimate the Primal and Dual Optima,[0],[0]
"Lemma 15 Let βmax = ‖ 1nXu‖∞ and αmax(β) = 1 1−γ max(i,k)∈[n]×[K]",5.2 Estimate the Primal and Dual Optima,[0],[0]
"{ 〈Xki ,Sβ( 1nXu)〉 } .",5.2 Estimate the Primal and Dual Optima,[0],[0]
"Then: (i) for α > 0 and β ≥ βmax, we have
w∗(α, β) = 0, θ∗(α, β) = u;
(ii) for all α ∈",5.2 Estimate the Primal and Dual Optima,[0],[0]
"[max{αmax(β), 0},∞) ∩ (0,∞), we have
w∗(α, β) = 1 α",5.2 Estimate the Primal and Dual Optima,[0],[0]
"Sβ ( − 1 n Xu ) , θ∗(α, β) = u. (18)
",5.2 Estimate the Primal and Dual Optima,[0],[0]
"Hence, we only need to consider the cases with β ∈ (0, βmax] and α ∈ (0, αmax(β)].",5.2 Estimate the Primal and Dual Optima,[0],[0]
Since problem (m-P∗) is a special case of problem (g-P∗) with L(w) =,5.2 Estimate the Primal and Dual Optima,[0],[0]
1m ∑n i=1,5.2 Estimate the Primal and Dual Optima,[0],[0]
"`i(w), given the reference solution w∗(α0, β0) and the index set F̂ of the inactive features identified by the previous IFS steps, we can apply Lemma 5 to obtain the estimation for w∗(α, β0)]F̂c :
[w∗(α, β0)]F̂c ∈",5.2 Estimate the Primal and Dual Optima,[0],[0]
W := {w : ‖w − c‖ ≤,5.2 Estimate the Primal and Dual Optima,[0],[0]
"r}, (19)
where c and r are defined in Eqs.",5.2 Estimate the Primal and Dual Optima,[0],[0]
"(6) and (7), respectively.",5.2 Estimate the Primal and Dual Optima,[0],[0]
"Moreover, noting that problem (m-D∗) is also a special case of problem (g-D∗), given the reference solution θ∗(α0, β0) and the index sets of inactive samples identified by the previous ISS steps R̂ and L̂, we can obtain an estimation for [θ∗(α, β0)]D̂c from Lemma 6:
[θ∗(α",5.2 Estimate the Primal and Dual Optima,[0],[0]
", β0)]D̂c ∈ Θ",5.2 Estimate the Primal and Dual Optima,[0],[0]
:= {θ : ‖θ − c‖ ≤,5.2 Estimate the Primal and Dual Optima,[0],[0]
"r}, (20)
where c and r are defined by Eqs.",5.2 Estimate the Primal and Dual Optima,[0],[0]
"(9) and (10) with v = u, respectively.",5.2 Estimate the Primal and Dual Optima,[0],[0]
"Given the optima w∗(α0, β0) and θ ∗(α0, β0), to derive the feature screening rule IFS, we need to solve the optimization problem below first:
s(k,j)(α, β0) = max θ∈Θ
{ 1
n |〈[Xk,j ]D̂c , θ〉+ 〈[Xk,j ]L̂,1〉|
} , (k, j) ∈ F̂c, (21)
where Xk,j is the ((k − 1)p+ j)-th row of X, Θ is given by Eq. (20), and F̂ and D̂ = R̂ ∪ L̂ are the index sets of the inactive features and samples identified in the previous screening process.",5.3 Screening Rule SIFS,[0],[0]
We notice that this problem has exactly the same form as problem (12).,5.3 Screening Rule SIFS,[0],[0]
"Hence, from Lemma 8 we can obtain its closed-form solution directly.",5.3 Screening Rule SIFS,[0],[0]
"Now, from Rule m-R, we can obtain our IFS rule below.
",5.3 Screening Rule SIFS,[0],[0]
"• The feature screening rule IFS takes the form of
s(k,j)(α, β0) ≤ β0 ⇒",5.3 Screening Rule SIFS,[0],[0]
"[w∗k(α, β0)]j = 0, ∀(k, j) ∈ F̂c.",5.3 Screening Rule SIFS,[0],[0]
"(IFS)
•",5.3 Screening Rule SIFS,[0],[0]
"The index set F̂ can be updated by
F̂ ← F̂ ∪∆F̂ with ∆F̂",5.3 Screening Rule SIFS,[0],[0]
"= {(k, j) : s(k,j) ≤ β0, (k, j) ∈ F̂c}.",5.3 Screening Rule SIFS,[0],[0]
"(22)
Similarly, we need to solve the following problems to derive our sample screening rule ISS:
u(i,k)(α, β0)",5.3 Screening Rule SIFS,[0],[0]
"= max w∈W
{〈[Xki ]F̂c ,w〉+",5.3 Screening Rule SIFS,[0],[0]
"[ui]k}, (i, k) ∈",5.3 Screening Rule SIFS,[0],[0]
"D̂ c, (23)
l(i,k)(α, β0) =",5.3 Screening Rule SIFS,[0],[0]
"min w∈W
{〈[Xki ]F̂c ,w〉+",5.3 Screening Rule SIFS,[0],[0]
"[ui]k}, (i, k) ∈",5.3 Screening Rule SIFS,[0],[0]
"D̂ c, (24)
where W is given by Eq. (19).",5.3 Screening Rule SIFS,[0],[0]
We find that they can be solved by Lemma 10 directly.,5.3 Screening Rule SIFS,[0],[0]
"Therefore, we can obtain our sample screening rule ISS below.
",5.3 Screening Rule SIFS,[0],[0]
•,5.3 Screening Rule SIFS,[0],[0]
"The sample screening rule ISS takes the form of
u(i,k)(α, β0) ≤ 0⇒",5.3 Screening Rule SIFS,[0],[0]
"[θ∗i (α, β0)]k = 0, l(i,k)(α, β0)",5.3 Screening Rule SIFS,[0],[0]
≥ γ ⇒,5.3 Screening Rule SIFS,[0],[0]
"[θ∗i (α, β0)]k = 1, ∀(i, k) ∈ D̂c.",5.3 Screening Rule SIFS,[0],[0]
"(ISS)
",5.3 Screening Rule SIFS,[0],[0]
"• We can update the index sets R̂ and L̂ by
R̂ ← R̂ ∪∆R̂ with ∆R̂",5.3 Screening Rule SIFS,[0],[0]
"= {(i, k) : u(i,k)(α, β0) ≤ 0, (i, k) ∈ D̂c}, (25) L̂ ← L̂ ∪∆L̂ with ∆L̂ = {(i, k) : l(i,k)(α, β0)",5.3 Screening Rule SIFS,[0],[0]
"≥ γ, (i, k) ∈ D̂c}.",5.3 Screening Rule SIFS,[0],[0]
"(26)
The same as we did sparse SVM, we can also develop SIFS to reinforce the capabilities of ISS and IFS by applying them alternatively.",5.3 Screening Rule SIFS,[0],[0]
"The framework of SIFS for solving the model over a grid of parameter values here is the same as that in the case of sparse SVM, i.e. Algorithm 1, except for the different rules IFS and ISS, and the updates of R̂, L̂, and F̂ .
",5.3 Screening Rule SIFS,[0],[0]
"In this version of SIFS, the order of applying IFS and ISS also has no impact on the final performance.",5.3 Screening Rule SIFS,[0],[0]
"Since the form of the theorem and its proof are nearly the same as that of Theorem 12, to avoid redundancy, we omit them in this section.",5.3 Screening Rule SIFS,[0],[0]
"We evaluate SIFS on both synthetic and real data sets in terms of three measurements: speedup, scaling ratio, and rejection ratio.",6. Experiments,[0],[0]
"Speedup is given by the ratio of the running time of the solver without screening to that with screening.
",6. Experiments,[0],[0]
"For sparse SVMs, scaling ratio is defined as 1 − (n−ñ)(p−p̃)np , where ñ, p̃, n, and p are the numbers of inactive samples and features identified by SIFS, sample size, and feature dimension of the data set.",6. Experiments,[0],[0]
"From steps 6 to 11 in Algorithm 1, we can see that we trigger the rules ISS and IFS repetitively until no new features and samples are identified.",6. Experiments,[0],[0]
"We adopt the rejection ratios of the i-th triggering of ISS and IFS defined as ñin0 and p̃i p0
to evaluate their performances in each triggering, where ñi and p̃i are the numbers of inactive samples and features identified in the i-th triggering of ISS and IFS.",6. Experiments,[0],[0]
"n0 and p0 are the numbers of inactive samples and features.
",6. Experiments,[0],[0]
"For multi-class sparse SVMs, we let scaling ratio be 1− (Kn−ñ)(Kp−p̃) K2np
, where ñ = |R̂∪ L̂|, p̃ = |F̂ |, and n and p are the sample size and the feature dimension of the data set.",6. Experiments,[0],[0]
"The rejection ratios of the i-th triggering of ISS and IFS are ñin0 and p̃i p0 , respectively, where p0 = |F|, n0 = |R ∪ L|, p̃i = |∆F̂ | and ñi = |∆R̂ ∪ ∆L̂| with ∆F̂ ,∆R̂, and ∆L̂ are the increments of F̂ , R̂ and L̂ in the i-th triggering of the rules IFS and ISS.",6. Experiments,[0],[0]
Please see Eqs.,6. Experiments,[0],[0]
"(22), (25), and (26) for the detailed definitions of ∆F̂ ,∆R̂, and ∆L̂.
Recall that, we can integrate SIFS with any solvers for problem (P∗).",6. Experiments,[0],[0]
"In this experiment, we use Accelerated Proximal Stochastic Dual Coordinate Ascent (AProx-SDCA) (ShalevShwartz and Zhang, 2016) as a baseline, as it is one of the state-of-the-arts.",6. Experiments,[0],[0]
"We choose the state-of-art screening method for sparse SVMs in Shibagaki et al. 2016 as another baseline only in the experiments of sparse SVMs, since it cannot be applied in multi-class sparse SVMs.",6. Experiments,[0],[0]
"As we mentioned in the introduction section that screening differs greatly from feature selection methods, it is not appropriate to make comparisons with feature selection methods.
",6. Experiments,[0],[0]
"For each data set, we solve problem (P∗) at a grid of turning parameter values.",6. Experiments,[0],[0]
"Specifically, we first compute βmax by Lemma 4 and then select 10 values of β that are equally spaced at the logarithmic scale of β/βmax from 1 to 0.05.",6. Experiments,[0],[0]
"Then, for each value of β, we first compute αmax(β) by Lemma 4 and then select 100 values of α that are equally spaced at the logarithmic scale of α/αmax(β) from 1 to 0.01.",6. Experiments,[0],[0]
"Thus, for each data set, we solve problem (P∗) at 1, 000 pairs of parameter values in total.",6. Experiments,[0],[0]
We write the code in C++ along with Eigen library for numerical computations.,6. Experiments,[0],[0]
"We perform all the computations on a single core of Intel(R) Core(TM) i7-5930K 3.50GHz, 128GB MEM.",6. Experiments,[0],[0]
"We evaluate SIFS on 3 synthetic data sets named syn1, syn2, and syn3 with sample and feature size (n, p) ∈ {(10000, 1000), (10000, 10000), (1000, 10000)}.",6.1 Simulation Studies with Spare SVMs,[0],[0]
We present each data point as x =,6.1 Simulation Studies with Spare SVMs,[0],[0]
[x1; x2] with x1 ∈ R0.02p and x2 ∈,6.1 Simulation Studies with Spare SVMs,[0],[0]
R0.98p.,6.1 Simulation Studies with Spare SVMs,[0],[0]
"We use Gaussian distributions G1 = N(u, 0.75I),G2 = N(−u, 0.75I), and G3 = N(0, 1) to generate the data points, where u = 1.51 and I ∈ R0.02p×0.02p is the identity matrix.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"To be precise, x1 for positive and negative points are sampled from G1 and G2, respectively.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"For each entry in x2, it has chance η = 0.02 to be sampled from G3 and chance 1− η to be 0.
",6.1 Simulation Studies with Spare SVMs,[0],[0]
"Fig. 1 shows the scaling ratios by ISS, IFS, and SIFS on the synthetic data sets at 1, 000 parameter values.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"We can see that IFS is more effective in scaling problem size than ISS, with scaling ratios roughly 98% against 70− 90%.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"Moreover, SIFS, which is an alternating application of IFS and ISS, significantly outperforms ISS and IFS, with scaling ratios roughly 99.9%.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"This high scaling ratios imply that SIFS can lead to a significant speedup.
",6.1 Simulation Studies with Spare SVMs,[0],[0]
"Due to the space limitation, we only report the rejection ratios of SIFS on syn2.",6.1 Simulation Studies with Spare SVMs,[0],[0]
Other results can be found in the appendix.,6.1 Simulation Studies with Spare SVMs,[0],[0]
Fig. 2 shows that SIFS can identify most of the inactive features and samples.,6.1 Simulation Studies with Spare SVMs,[0],[0]
"However, few features and samples are identified in the second and later triggerings of ISS and IFS.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"The reason may be that the task here is so simple that one triggering is enough.
",6.1 Simulation Studies with Spare SVMs,[0],[0]
"Table 1 reports the running times of solver without and with IFS, ISS and SIFS for solving problem (P∗) at 1, 000 pairs of parameter values.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"We can see that SIFS leads to
significant speedups, that is, up to 76.8 times.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"Taking syn2 for example, without SIFS, the solver takes more than two hours to solve problem (P∗) at 1, 000 pairs of parameter values.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"However, combined with SIFS, the solver only needs less than three minutes for solving the same set of problems.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"From the theoretical analysis in Shalev-Shwartz and Zhang 2016 for AProx-SDCA, we can see that its computational complexity rises proportionately to the sample size n and the feature dimension p.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"From this theoretical result, we can see that the results in Fig. 1 are roughly consistent with the speedups we achieved shown in Table 1.",6.1 Simulation Studies with Spare SVMs,[0],[0]
"In this experiment, we evaluate the performance of SIFS on 5 large-scale real data sets: real-sim, rcv1-train, rcv1-test, url, and kddb, which are all collected from the project page of LibSVM (Chang and Lin, 2011).",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
See Table 2 for a brief summary.,6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"We note that, the kddb data set has about 20 million samples with 30 million features.
",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"Recall that, SIFS detects the inactive features and samples in a static manner, i.e., we perform SIFS only once before the training process and hence the size of the problem we need to perform optimization on is fixed.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"However, the method in Shibagaki et al. 2016 detects inactive features and samples in a dynamic manner (Bonnefoy et al., 2014), i.e.,
they perform their method along with the training process and thus the size of the problem would keep decreasing during the iterations.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"Thus, comparing SIFS with this baseline in terms of the rejection ratios is inapplicable.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"We compare the performance of SIFS with the method in Shibagaki et al. 2016 in terms of speedup, i.e., the speedup gained by these two methods in solving problem (P∗) at 1, 000 pairs of parameter values.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"The code of the method in Shibagaki et al. 2016 is obtained from (https://github.com/husk214/s3fs).
",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
Fig. 3 shows the rejection ratios of SIFS on the real-sim data set (other results are in the appendix).,6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"In Fig. 3, we can see that some inactive features and samples are identified in the 2nd and 3rd triggerings of ISS and IFS, which verifies the necessity of the alternating application of ISS and IFS.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
SIFS is efficient since it always stops in 3 times of triggering.,6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"In addition, most of (> 98%) the inactive features can be identified in the 1st triggering of IFS while identifying inactive samples needs to apply ISS two or more times.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"It may due to two reasons: 1) we run ISS first, which reinforces the capability of IFS due to the synergistic effect (see Sections 4.1 and 4.2), referring to the analysis below for further verification; 2) feature screening here may be easier than sample screening.
",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"Table 3 reports the running times of solver without and with the method in Shibagaki et al. 2016 and SIFS for solving problem (P∗) at 1, 000 pairs of parameter values on real data
sets.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"The speedup gained by SIFS is up to 300 times on real-sim, rcv1-train and rcv1-test.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"Moreover, SIFS significantly outperforms the method in Shibagaki et al. 2016 in terms of speedup—by about 30 to 40 times faster on the aforementioned three data sets.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"For data sets url and kddb, we do not report the results of the solver as the sizes of the data sets are huge and the computational cost is prohibitive.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"Instead, we can see that the solver with SIFS is about 25 times faster than the solver with the method in Shibagaki et al. 2016 on both data sets url and kddb.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
Let us take the data set kddb as an example.,6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"The solver with SIFS takes about 13 hours to solve problem (P∗) for 1, 000 pairs of parameter values, while the solver with the method in Shibagaki et al. 2016 needs 11 days to finish the same task.
",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"Verification of the Synergy Effect In Fig. 3, SIFS performs ISS (sample screening) first, while in Fig. 4, it performs IFS (feature screening) first.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
All the rejection ratios of the 1st triggering of IFS in Fig. 3(a)-3(d) where SIFS performs ISS first are much higher than (at least equal to) those in Fig. 4(a)-4(d) where SIFS performs IFS first.,6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"In turn, all the rejection ratios of the 1st triggering of ISS in Fig. 4(e)-4(h) where SIFS performs IFS
first are also much higher than those in Fig. 3(e)-3(h) where SIFS performs ISS first.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"This demonstrates that the screening result of ISS can reinforce the capability of IFS and vice versa, which is the so called synergistic effect.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"At last, in Fig. 4 and Fig. 3, we can see that the overall rejection ratios at the end of SIFS are exactly the same.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"Hence, no matter which rule (ISS or IFS) we perform first in SIFS, SIFS has the same screening performances in the end, which verifies the conclusion we present in Theorem 12.
",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"Performance in Solving Single Problems In the experiments above, we solve problem (P∗) at a grid of turning parameter values.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"This setting is meaningful and it arises naturally in various cases, such as cross validation (Kohavi, 1995) and feature selection (Meinshausen and Bühlmann, 2010; Yang et al., 2015).",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"Therefore, the results above demonstrate that our method would be helpful in such real applications.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
We notice that sometimes one may be interested in the model at a specific parameter value pair.,6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"To this end, we now evaluate the performance of our method in solving a single problem.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"Due to the space limitation, we solve sparse SVM at 16 specific parameter values pairs on the real-sim data set for examples, To be precise, β ∈ {0.05, 0.10, 0.5, 0.9} and each β has 4 values of α satisfying α/αmax(β) ∈ {0.05, 0.1, 0.5, 0.9}.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"For each (αi, βi), we construct a parameter value path {(αj,i, βi), j = 0, ...,M} with αj,i equally spaced at the logarithmic scale of αj,i/αmax(βi) between 1 and αi/αmax(βi), which implies that αmax(βi) = α0,i > α1,i > ...",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"> αM,i = αi.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
Then we use AProx-SDCA integrated with SIFS to solve problem (P∗) at the parameter value pairs on the path one by one and report the total time cost.,6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"It can be expected that for αi far from αmax(βi), we need more points on the parameter value path in order to obtain higher rejection ratios and more significant speedups of SIFS and otherwise we need fewer ones.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"In this experiment, we fix M = 50 at each αi for convenience.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"For comparison, we solve the problem at (αi, βi) using AProx-SDCA with random initializations, which would be faster than solving all the problems on the path.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
Table 4 reports the speedups achieved by SIFS at these parameter value pairs.,6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
It shows that SIFS can still obtain significant speedups.,6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"In addition, compared with the results in Tables 1 and 3, we can see that our method is much better at solving a problem sequence than solving a single problem.",6.2 Experiments with Sparse SVMs on Real Datasets,[0],[0]
"We evaluate SIFS for multi-class Sparse SVMs on 3 synthetic data sets (syn-multi1, synmulti2, and syn-multi3) and 2 real data sets (news20 and rcv1-multiclass).",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"Their statistics are given in Table 5.
",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
The synthetic data sets are generated in a similar way as we did in Section 6.1.,6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
Each of them has K = 5 classes and each class has n/K samples.,6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
The data points of them can be written as x =,6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"[x1; x2], where x1 =",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
[x 1 1; ...; x K 1 ] ∈ R0.02p with xk1 ∈,6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
R0.02p/Kand x2 ∈ R0.98p.,6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"If x belongs to the k-th class, then xk1 is sampled from a Gaussian distribution
G = N(u, 0.75I) with u = 1.51, I ∈ R(0.02p/K)×(0.02p/K) and other components in x1 are from N(0, 1).",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"Each entry of x2 has chance η = 0.2 to be sampled from distribution N(0, 1) and chance 1− η to be 0.
",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"Fig. 5 shows the scaling ratios of ISS, IFS, and SIFS on the synthetic data sets at 1, 000 pairs of parameter values.",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"Similar to the results in sparse SVMs, SIFS totally surpasses IFS and ISS, with scaling ratios larger than 98% at any parameter value pair against 70− 90%.",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"Thus, we can expect significant speedups by integrating SIFS with the solver.
",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
Fig. 6 and 7 present the rejection ratios of SIFS on the news20 data set (the results of other data sets can be found in the appendix).,6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"It indicates that, by alternatively applying IFS and ISS, we can finally identify most of the inactive samples (> 95%) and features (> 99%).",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"The synergistic effect between IFS and ISS can also be found in these figures.
",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"As a result of excellent performance of SIFS in identifying inactive features and samples, we observe significant speedups gained by SIFS in Table 6, which are up to 200 times on news20 and 300 times on syn-multi3.",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"Specifically, on news20, the solver without any
screening method takes about 97 hours to solve the problem at 1, 000 pairs of parameter values; however, integrated with SIFS, the solver only needs less than 0.5 hour for the same task.",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"Moreover, Table 6 also indicates that the speedup gained by SIFS is much more significant than that gained by IFS and ISS.",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
This demonstrates again the great benefit of alternatively applying IFS and ISS in SIFS.,6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"At last, we notice that the speedup gained by
SIFS and IFS on syn-multi3 is far greater than those gained on syn-multi1 and syn-multi2.",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
The reason is that the convergence rate of the solver in our problem may depend on the condition number of the data matrix.,6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"The dimension of w in syn-multi3 is much larger than its sample size (50, 000 over 1, 000), which leads to a large condition number and a bad convergence rate.",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"However, SIFS and IFS can remove the inactive features from the model, which can greatly improve the convergence rate of the solver by decreasing the condition number.",6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
This point can also be supported by the fact in the experiment on syn-multi3 that the solver with SIFS or IFS needs much fewer iterations to converge to the optima than that without SIFS or IFS.,6.3 Experiments with Multi-class Sparse SVMs,[0],[0]
"In this paper, we proposed a novel data reduction method SIFS to simultaneously identify inactive features and samples for sparse SVMs.",7. Conclusions,[0],[0]
Our major contribution is a novel framework for an accurate estimation of the primal and dual optima based on strong convexity.,7. Conclusions,[0],[0]
"To the best of our knowledge, the proposed SIFS is the first static screening method that is able to simultaneously identify inactive features and samples for sparse SVMs.",7. Conclusions,[0],[0]
An appealing feature of SIFS is that all detected features and samples are guaranteed to be irrelevant to the outputs.,7. Conclusions,[0],[0]
"Thus, the model learned on the reduced data is exactly identical to that learned on the full data.",7. Conclusions,[0],[0]
"To show the flexibility of the proposed SIFS, we extended it to multi-class sparse SVMs.",7. Conclusions,[0],[0]
"The experimental results demonstrate that, for both sparse SVMs and multi-class sparse SVMs, SIFS can dramatically reduce the problem size and the resulting speedup can be orders of magnitude.",7. Conclusions,[0],[0]
"We plan to generalize SIFS to more complicated models, e.g., SVMs with a structured sparsity-inducing penalty.",7. Conclusions,[0],[0]
"This work was supported by the National Basic Research Program of China (973 Program) under Grant 2013CB336500, National Natural Science Foundation of China under Grant 61233011, and National Youth Top-notch Talent Support Program.",Acknowledgments,[0],[0]
"In this appendix, we first present the detailed proofs of all the theorems in the main paper and then report the rest experimental results which are omitted in the experimental section.",Appendix A. Detailed Proofs and More Experimental Results,[0],[0]
Proof of Lemma 3: 1) It is the immediate conclusion of the analysis above.,A.1 Proof for Lemma 3,[0],[0]
"2) After feature screening, the primal problem (P∗) is scaled into:
min w̃∈R|F̂c|
α 2 ||w̃||2 + β||w̃||1",A.1 Proof for Lemma 3,[0],[0]
+ 1 n n∑ i=1,A.1 Proof for Lemma 3,[0],[0]
"`(1− 〈[x̄i]F̂c , w̃〉).",A.1 Proof for Lemma 3,[0],[0]
"(scaled-P ∗-1)
",A.1 Proof for Lemma 3,[0],[0]
"Thus, we can easily derive out the dual problem of (scaled-P ∗-1):
min θ̃∈[0,α] n D̃(θ̃;α, β) =
1
2α ||Sβ(
1 n F̂ c",A.1 Proof for Lemma 3,[0],[0]
[X̄]θ̃)||2 + γ 2n ||θ̃||2,A.1 Proof for Lemma 3,[0],[0]
"− 1 n 〈1, θ̃〉, (scaled-D∗-1)
and the KKT conditions:
w̃∗(α, β) = 1
α",A.1 Proof for Lemma 3,[0],[0]
"Sβ(
1 n F̂",A.1 Proof for Lemma 3,[0],[0]
c,A.1 Proof for Lemma 3,[0],[0]
"[X̄]θ̃ ∗(α, β)), (scaled-KKT-1)
",A.1 Proof for Lemma 3,[0],[0]
"[θ̃∗(α, β)]i =  0, if 1− 〈[x̄i]F̂c , w̃ ∗(α, β)〉 < 0, 1 γ (1− 〈[x̄i]F̂c , w̃ ∗(α, β)), if 0 ≤ 1−",A.1 Proof for Lemma 3,[0],[0]
〈,A.1 Proof for Lemma 3,[0],[0]
"[x̄i]F̂c , w̃ ∗(α, β) ≤",A.1 Proof for Lemma 3,[0],[0]
"γ,
1, if 1− 〈[x̄i]F̂c , w̃ ∗(α, β) >",A.1 Proof for Lemma 3,[0],[0]
"γ,
(scaled-KKT-2)
Then, it is obvious that w̃∗(α, β) =",A.1 Proof for Lemma 3,[0],[0]
"[w∗(α, β)]F̂c , since essentially, problem (scaled-P ∗-1) can be derived by substituting 0 to the weights for the eliminated features in problem (P∗) and optimizing over the rest weights.",A.1 Proof for Lemma 3,[0],[0]
"Since the solutions w∗(α, β) and θ∗(α, β) satisfy the conditions (KKT-1) and (KKT-2) and 〈[x̄i]F̂c , w̃
∗(α, β)〉 = 〈x̄i,w∗(α, β)〉 for all i , we know that w̃∗(α, β) and θ∗(α, β) satisfy the conditions (scaled-KKT-1) and (scaled-KKT-2).",A.1 Proof for Lemma 3,[0],[0]
Thus they are the solutions of problems (scaled-P ∗-1) and (scaled-D∗-1).,A.1 Proof for Lemma 3,[0],[0]
"Then, due to the uniqueness of the solution of problem (scaled-D∗-1), we have
θ∗(α, β) = θ̃∗(α, β).",A.1 Proof for Lemma 3,[0],[0]
"(27)
",A.1 Proof for Lemma 3,[0],[0]
"From 1) we have [θ̃∗(α, β)]R̂c = 0",A.1 Proof for Lemma 3,[0],[0]
"and [θ̃ ∗(α, β)]L̂c = 1.",A.1 Proof for Lemma 3,[0],[0]
"Therefore, from the dual problem
(scaled-D∗), we can see that [θ̃∗(C,α)]D̂c can be recovered from the following problem:
min θ̂∈[0,1] |D̂c|
1
2α ||Sβ(
1 n Ĝ1θ̂",A.1 Proof for Lemma 3,[0],[0]
+ 1 n Ĝ21)||2 +,A.1 Proof for Lemma 3,[0],[0]
"γ 2n ||θ̂||2 − 1 n 〈1, θ̂〉.
",A.1 Proof for Lemma 3,[0],[0]
"Since [θ̃∗(α, β)]D̂c =",A.1 Proof for Lemma 3,[0],[0]
"[θ ∗(α, β)]D̂c , the proof is therefore completed.",A.1 Proof for Lemma 3,[0],[0]
"Proof of Lemma 4:
(i)",A.2 Proof for Lemma 4,[0],[0]
"We prove this lemma by verifying that the solutions w∗(α, β) = 0 and θ∗(α, β) = 1 satisfy the conditions (KKT-1) and (KKT-2).
",A.2 Proof for Lemma 4,[0],[0]
"Firstly, since β ≥ βmax = || 1nX̄1||∞, we have Sβ( 1 nX̄1) = 0.",A.2 Proof for Lemma 4,[0],[0]
"Thus w ∗(α, β) = 0 and θ∗(α, β) = 1 satisfy the condition (KKT-1).
",A.2 Proof for Lemma 4,[0],[0]
"Then, for all i ∈",A.2 Proof for Lemma 4,[0],[0]
"[n], we have
1− 〈x̄i,w∗(α, β)〉 = 1− 0",A.2 Proof for Lemma 4,[0],[0]
"> γ.
",A.2 Proof for Lemma 4,[0],[0]
"Thus, w∗(α, β) = 0 and θ∗(α, β) = 1 satisfy the condition (KKT-2).",A.2 Proof for Lemma 4,[0],[0]
"Hence, they are the solutions of the primal problem (P∗) and the dual problem (D∗), respectively.
(ii) Similar to the proof of (i), we prove this by verifying that the solutions w∗(α, β) = 1 αSβ( 1 nX̄θ ∗(α, β)) and θ∗(α, β) = 1 satisfy the conditions (KKT-1) and (KKT-2).
1.",A.2 Proof for Lemma 4,[0],[0]
Case 1: αmax(β) ≤ 0.,A.2 Proof for Lemma 4,[0],[0]
"Then for all α > 0, we have
min i∈[n] {1− 〈x̄i,w∗(α, β)〉}
= min i∈[n] {1− 1 α 〈x̄i,Sβ( 1 n X̄θ∗(α, β))",A.2 Proof for Lemma 4,[0],[0]
"〉} = min i∈[n] {1− 1 α 〈x̄i,Sβ( 1 n X̄1)〉}
=1− 1 α max i∈[n] 〈x̄i,Sβ( 1 n X̄1)〉 = 1− (1− γ) 1 α αmax(β)
",A.2 Proof for Lemma 4,[0],[0]
"≥1 > γ.
",A.2 Proof for Lemma 4,[0],[0]
"Then, L =",A.2 Proof for Lemma 4,[0],[0]
"[n], and w∗(α, β) = 1αSβ( 1 nX̄θ ∗(α, β)) and θ∗(α, β) =",A.2 Proof for Lemma 4,[0],[0]
1 satisfy the conditions (KKT-1) and (KKT-2).,A.2 Proof for Lemma 4,[0],[0]
"Hence, they are the optimal solution of the primal and dual problems (P∗) and (D∗).
2.",A.2 Proof for Lemma 4,[0],[0]
Case 2: αmax(β) > 0.,A.2 Proof for Lemma 4,[0],[0]
"Then for any α ≥ αmax(β), we have
min i∈[n] {1− 〈x̄i,w∗(α, β)〉}
= min i∈[n] {1− 1 α 〈x̄i,Sβ( 1 n X̄θ∗(α, β))",A.2 Proof for Lemma 4,[0],[0]
"〉} = min i∈[n] {1− 1 α 〈x̄i,Sβ( 1 n X̄1)〉}
=1− 1 α max i∈[n]",A.2 Proof for Lemma 4,[0],[0]
"〈x̄i,Sβ( 1 n X̄1)〉 = 1− (1− γ) 1 α αmax(β) ≥ 1− (1− γ) = γ.
",A.2 Proof for Lemma 4,[0],[0]
"Thus, E ∪ L =",A.2 Proof for Lemma 4,[0],[0]
"[n], and w∗(α, β) = 1αSβ( 1 nX̄θ ∗(α, β)) and θ∗(α, β) =",A.2 Proof for Lemma 4,[0],[0]
1 satisfy the conditions (KKT-1) and (KKT-2).,A.2 Proof for Lemma 4,[0],[0]
"Hence, they are the optimal solution of the primal and dual problems (P∗) and (D∗).
",A.2 Proof for Lemma 4,[0],[0]
The proof is complete.,A.2 Proof for Lemma 4,[0],[0]
"Proof of Lemma 5: Due to the α-strong convexity of the objective P (w;α, β), we have
P (w∗(α0, β0);α, β0) ≥ P (w∗(α, β0);α, β0) + α 2 ||w∗(α0, β0)−w∗(α, β0)||2, P (w∗(α, β0);α0, β0) ≥ P (w∗(α0, β0);α0, β0) + α0 2 ||w∗(α0, β0)−w∗(α, β0)||2,
which are equivalent to
α 2 ||w∗(α0, β0)||2 + β0||w∗(α0, β0)||1 + L(w∗(α0, β0))",A.3 Proof for Lemma 5,[0],[0]
"≥ α 2 ||w∗(α, β0)||2 + β0||w∗(α, β0)||1 + L(w∗(α, β0))",A.3 Proof for Lemma 5,[0],[0]
"+ α 2 ||w∗(α0, β0)−w∗(α, β0)||2, α0 2 ||w∗(α, β0)||2 + β0||w∗(α, β0)||1 + L(w∗(α, β0))",A.3 Proof for Lemma 5,[0],[0]
"≥ α0 2 ||w∗(α0, β0)||2 + β0||w∗(α0, β0)||1 + L(w∗(α0, β0))",A.3 Proof for Lemma 5,[0],[0]
"+ α0 2 ||w∗(α0, β0)−w∗(α, β0)||2.
",A.3 Proof for Lemma 5,[0],[0]
"Adding the above two inequalities together, we obtain
α− α0 2 ||w∗(α0, β0)||2 ≥ α− α0 2 ||w∗(α, β0)||2 + α0 + α 2 ||w∗(α0, β0)−w∗(α, β0)||2 ⇒ ||w∗(α, β0)− α0 + α
2α w∗(α0, β0)||2 ≤
(α− α0)2
4α2 ||w∗(α0, β0)||2.",A.3 Proof for Lemma 5,[0],[0]
"(28)
Substituting the prior that [w∗(α, β0)]F̂ = 0 into Eq.",A.3 Proof for Lemma 5,[0],[0]
"(28), we obtain
||[w∗(α, β0)]F̂c − α0 + α 2α [w∗(α0, β0)]F̂c || 2
≤(α− α0) 2
4α2 ||w∗(α0, β0)||2 −
(α0 + α) 2
4α2 ||[w∗(α0, β0)]F̂ ||",A.3 Proof for Lemma 5,[0],[0]
"2.
",A.3 Proof for Lemma 5,[0],[0]
The proof is complete.,A.3 Proof for Lemma 5,[0],[0]
Proof of Lemma 6:,A.4 Proof for Lemma 6,[0],[0]
"Firstly, we need to extend the definition of D(θ;α, β) to Rn:
D̃(θ;α, β) =
{ D(θ;α, β), if θ ∈",A.4 Proof for Lemma 6,[0],[0]
"[0, 1]n,
+∞, otherwise.",A.4 Proof for Lemma 6,[0],[0]
"(29)
Due to the strong convexity of objective D̃(θ;α, β), we have
D̃(θ∗(α0, β0), α, β0) ≥ D̃(θ∗(α, β0), α, β0)",A.4 Proof for Lemma 6,[0],[0]
+,A.4 Proof for Lemma 6,[0],[0]
"γ 2n ||θ∗(α0, β0)− θ∗(α, β0)||2, D̃(θ∗(α, β0), α0, β0) ≥ D̃(θ∗(α0, β0), α0, β0) +",A.4 Proof for Lemma 6,[0],[0]
"γ
2n ||θ∗(α0, β0)− θ∗(α, β0)||2.
",A.4 Proof for Lemma 6,[0],[0]
"Since θ∗(α0, β0), θ ∗(α, β0) ∈",A.4 Proof for Lemma 6,[0],[0]
"[0, 1]n, the above inequalities are equivalent to
1
2α fβ0(θ
∗(α0, β0))",A.4 Proof for Lemma 6,[0],[0]
"+ γ 2n ||θ∗(α0, β0)||2 − 1 n 〈1, θ∗(α0, β0)〉
≥ 1 2α fβ0(θ ∗(α, β0)) +",A.4 Proof for Lemma 6,[0],[0]
"γ 2n ||θ∗(α, β0)||2 − 1 n 〈1, θ∗(α, β0)〉+ γ 2n ||θ∗(α0, β0)− θ∗(α, β0)||2,
1
2α0 fβ0(θ
∗(α, β0))",A.4 Proof for Lemma 6,[0],[0]
"+ γ 2n ||θ∗(α, β0)||2 − 1 n 〈1, θ∗(α, β0)〉
≥ 1 2α0 fβ0(θ ∗(α0, β0))",A.4 Proof for Lemma 6,[0],[0]
"+ γ 2n ||θ∗(α0, β0)||2 − 1 n 〈1, θ∗(α0, β0)〉+",A.4 Proof for Lemma 6,[0],[0]
"γ 2n ||θ∗(α0, β0)− θ∗(α, β0)||2.
",A.4 Proof for Lemma 6,[0],[0]
"Adding the above two inequalities, we obtain
γ(α− α0) 2n ||θ∗(α0, β0)||2 − α− α0 n 〈1, θ∗(α0, β0)〉 ≥ γ(α− α0) 2n ||θ∗(α, β0)||2 − α− α0 n 〈1, θ∗(α, β0)〉+ γ(α0 + α) 2n ||θ∗(α0, β0)− θ∗(α, β0)||2.
",A.4 Proof for Lemma 6,[0],[0]
"That is equivalent to
||θ∗(α, β0)||2 − 〈 α− α0 γα 1 + α0 + α α θ∗(α0, β0), θ ∗(α, β0)〉
≤ −α0 α ||θ∗(α0, β0)||2 − α− α0 γα 〈1, θ∗(α0, β0)〉.",A.4 Proof for Lemma 6,[0],[0]
"(30)
That is
||θ∗(α, β0)− ( α− α0
2γα 1 +
α0 + α
2α θ∗(α0, β0))||2 ≤ ( α− α0 2α )2||θ∗(α0, β0)− 1 γ 1||2.",A.4 Proof for Lemma 6,[0],[0]
"(31)
Substituting the priors that [θ∗(α, β0)]R̂ = 0 and [θ ∗(α, β0)]L̂ = 1 into Eq.",A.4 Proof for Lemma 6,[0],[0]
"(31), we have
||[θ∗(α, β0)]D̂c",A.4 Proof for Lemma 6,[0],[0]
"− ( α− α0
2γα 1 +
α0 + α
2α [θ∗(α0, β0)]D̂c)|| 2
≤ (α− α0 2α )2||θ∗(α0, β0)− 1 γ 1||2",A.4 Proof for Lemma 6,[0],[0]
− ||(2γ − 1)α+ α0 2γα 1−,A.4 Proof for Lemma 6,[0],[0]
"α0 + α 2α [θ∗(α0, β0)]L̂|| 2 − ||α− α0 2γα 1 + α0 + α 2α [θ∗(α0, β0)]R̂|| 2.
",A.4 Proof for Lemma 6,[0],[0]
The proof is complete.,A.4 Proof for Lemma 6,[0],[0]
"Before the proof of Lemma 8, we should prove that the optimization problem in (2) is equivalent to
si(α, β0) = max θ∈Θ
{ 1
n |〈[x̄i]D̂c , θ〉+ 〈[x̄
i]L̂,1〉| } , i ∈ F̂c.",A.5 Proof for Lemma 8,[0],[0]
"(32)
To avoid notational confusion, we denote the feasible region Θ and θ in Eq.",A.5 Proof for Lemma 8,[0],[0]
"(2) as Θ̃ and θ̃, respectively.",A.5 Proof for Lemma 8,[0],[0]
"Then,
max θ̃∈Θ̃ {∣∣∣∣ 1n",A.5 Proof for Lemma 8,[0],[0]
"[X̄θ̃]i ∣∣∣∣} = max θ̃∈Θ̃ { 1 n ∣∣∣x̄iθ̃∣∣∣} = max
θ̃∈Θ̃
{ 1
n ∣∣∣[x̄i]D̂c",A.5 Proof for Lemma 8,[0],[0]
[θ̃]D̂c +,A.5 Proof for Lemma 8,[0],[0]
[x̄i]L̂[θ̃]L̂ +,A.5 Proof for Lemma 8,[0],[0]
"[x̄i]R̂[θ̃]R̂∣∣∣} = max
θ̃∈Θ̃
{ 1
n |〈[x̄i]D̂c , [θ̃]D̂c〉+ 〈[x̄
i]L̂,1〉| }
= max θ∈Θ
{ 1
n |〈[x̄i]D̂c , θ〉+ 〈[x̄
i]L̂,1〉| } = si(α, β0).
",A.5 Proof for Lemma 8,[0],[0]
"The last two equations hold since [θ]L̂ = 1, [θ]R̂ = 0, and [θD̂c ] ∈",A.5 Proof for Lemma 8,[0],[0]
"Θ. Proof of Lemma 8:
si(α, β0)",A.5 Proof for Lemma 8,[0],[0]
"= max θ∈B(c,r) { 1 n |〈[x̄i]D̂c , θ〉+ 〈[x̄ i]L̂,1〉|}
= max η∈B(0,r) { 1 n |〈[x̄i]D̂c ,",A.5 Proof for Lemma 8,[0],[0]
"c〉+ 〈[x̄ i]L̂,1〉+ 〈[x̄ i]D̂c , η〉|}
= 1
n
( |〈[x̄i]D̂c ,",A.5 Proof for Lemma 8,[0],[0]
c〉+ 〈,A.5 Proof for Lemma 8,[0],[0]
"[x̄ i]L̂,1〉|+ ‖[x̄ i]D̂c‖r ) .
",A.5 Proof for Lemma 8,[0],[0]
The last equality holds since −‖[x̄i]D̂c‖r ≤,A.5 Proof for Lemma 8,[0],[0]
〈,A.5 Proof for Lemma 8,[0],[0]
"[x̄ i]D̂c , η〉 ≤",A.5 Proof for Lemma 8,[0],[0]
‖[x̄ i]D̂c‖r.,A.5 Proof for Lemma 8,[0],[0]
The proof is complete.,A.5 Proof for Lemma 8,[0],[0]
Proof of Theorem 9: (1) It can be obtained from the rule R1.,A.6 Proof for Theorem 9,[0],[0]
(2) It is from the definition of F̂ .,A.6 Proof for Theorem 9,[0],[0]
"Firstly, we need to point out that the optimization problems in Eqs.",A.7 Proof for Lemma 10,[0],[0]
"(3) and (4) are equivalent to the problems:
ui(α, β0)",A.7 Proof for Lemma 10,[0],[0]
"= max w∈W
{1− 〈[x̄i]F̂c ,w〉}, i ∈",A.7 Proof for Lemma 10,[0],[0]
"D̂ c,
li(α, β0) =",A.7 Proof for Lemma 10,[0],[0]
"min w∈W
{1− 〈[x̄i]F̂c ,w〉}, i ∈",A.7 Proof for Lemma 10,[0],[0]
"D̂ c.
They follow from the fact that [w]F̂c ∈ W and
{1− 〈w, x̄i〉} ={1− 〈[w]F̂c , [x̄i]F̂c〉 − 〈[w]F̂ , [x̄i]F̂ 〉} ={1− 〈[w]F̂c , [x̄i]F̂c〉} (since [w]F̂ = 0).
",A.7 Proof for Lemma 10,[0],[0]
"Proof of Lemma 10:
ui(α, β0) = max w∈B(c,r) {1− 〈[x̄i]F̂c ,w〉}
= max η∈B(0,r) {1− 〈[x̄i]F̂c , c〉",A.7 Proof for Lemma 10,[0],[0]
"− 〈[x̄i]F̂c , η〉}
=1− 〈[x̄i]F̂c , c〉+ max η∈B(0,r) {−〈[x̄i]F̂c , η〉}
=1− 〈[x̄i]F̂c , c〉+ ‖[x̄i]F̂c‖r.
li(α, β0) = min w∈B(c,r) {1− 〈[x̄i]F̂c ,w〉}
= min η∈B(0,r) {1− 〈[x̄i]F̂c , c〉 − 〈[x̄i]F̂c , η〉}
=1− 〈[x̄i]F̂c , c〉+ min η∈B(0,r) {−〈[x̄i]F̂c , η〉}
=1− 〈[x̄i]F̂c , c〉 − ‖[x̄i]F̂c‖r.
",A.7 Proof for Lemma 10,[0],[0]
The proof is complete.,A.7 Proof for Lemma 10,[0],[0]
Proof of Theorem 11: (1) It can be obtained from the rule R2.,A.8 Proof for Theorem 11,[0],[0]
(2) It is from the definitions of R̂ and L̂.,A.8 Proof for Theorem 11,[0],[0]
"Proof of Theorem 12: (1) Given the reference solutions pair w∗(αi−1,j , βj) and θ
∗(αi−1,j , βj), if we do ISS first in SIFS and apply ISS and IFS for infinite times.",A.9 Proof for Theorem 12,[0],[0]
"If after s times of triggering, no new inactive features or samples are identified, then we can denote the sequence of F̂ , R̂, and L̂ as:
F̂A0 = R̂A0 = L̂A0 = ∅ ISS−→",A.9 Proof for Theorem 12,[0],[0]
"F̂A1 , R̂A1 , L̂A1 IFS−→ F̂A2 , R̂A2 , L̂A2 ISS−→ ...",A.9 Proof for Theorem 12,[0],[0]
"F̂As , R̂As , L̂As IFS/ISS−→ ...",A.9 Proof for Theorem 12,[0],[0]
"(33) with F̂As = F̂As+1 = F̂As+2 = ..., R̂As = R̂As+1 = R̂As+2 = ...",A.9 Proof for Theorem 12,[0],[0]
and L̂As = L̂As+1 = L̂As+2 = ...,A.9 Proof for Theorem 12,[0],[0]
"(34)
In the same way, if we do IFS first in SIFS and no new inactive features or samples are identified after t times of triggering of ISS and IFS, then the sequence can be denoted as:
F̂B0 = R̂B0 = L̂B0 = ∅",A.9 Proof for Theorem 12,[0],[0]
"IFS−→ F̂B1 , R̂B1 , L̂B1 ISS−→ F̂B2 , R̂B2 , L̂B2 IFS−→ ...",A.9 Proof for Theorem 12,[0],[0]
"F̂Bt , R̂Bt , L̂Bt IFS/ISS−→ ...",A.9 Proof for Theorem 12,[0],[0]
"(35) with F̂Bt = F̂Bt+1 = F̂Bt+2 = ..., R̂Bt = R̂Bt+1 = R̂Bt+2 = ...and L̂Bt = L̂Bt+1 = L̂Bt+2 = ...",A.9 Proof for Theorem 12,[0],[0]
"(36)
We first prove that F̂Bk ⊆ F̂Ak+1, R̂Bk ⊆ R̂Ak+1 and L̂Bk ⊆ L̂Ak+1 hold for all k ≥ 0 by induction.
",A.9 Proof for Theorem 12,[0],[0]
1),A.9 Proof for Theorem 12,[0],[0]
"When k = 0, the equalities F̂B0 ⊆ F̂A1 , R̂B0 ⊆ R̂A1 and L̂B0 ⊆ L̂A1 hold since F̂B0 = R̂B0 = L̂B0 = ∅.
2)",A.9 Proof for Theorem 12,[0],[0]
"If F̂Bk ⊆ F̂Ak+1, R̂Bk ⊆ R̂Ak+1 and L̂Bk ⊆ L̂Ak+1 hold, by the synergistic effect of ISS and IFS, we have that F̂Bk+1 ⊆ F̂Ak+2, R̂Bk+1 ⊆ R̂Ak+2 and L̂Bk+1 ⊆ L̂Ak+2 hold.
",A.9 Proof for Theorem 12,[0],[0]
"Thus, F̂Bk ⊆ F̂Ak+1, R̂Bk ⊆ R̂Ak+1 and L̂Bk ⊆ L̂Ak+1 hold for all k ≥ 0.",A.9 Proof for Theorem 12,[0],[0]
"Similar to the analysis in (1), we can also prove that F̂Ak ⊆ F̂Bk+1, R̂Ak ⊆ R̂Bk+1 and
L̂Ak ⊆ L̂Bk+1 hold for all k ≥ 0.",A.9 Proof for Theorem 12,[0],[0]
"Combining (1) and (2), we can acquire
F̂B0 ⊆ F̂A1",A.9 Proof for Theorem 12,[0],[0]
⊆ F̂B2,A.9 Proof for Theorem 12,[0],[0]
⊆,A.9 Proof for Theorem 12,[0],[0]
F̂A3 ....,A.9 Proof for Theorem 12,[0],[0]
(37) F̂A0 ⊆,A.9 Proof for Theorem 12,[0],[0]
F̂B1 ⊆ F̂A2 ⊆ F̂B3 ....,A.9 Proof for Theorem 12,[0],[0]
(38) R̂B0 ⊆ R̂A1 ⊆ R̂B2 ⊆ R̂A3 ....,A.9 Proof for Theorem 12,[0],[0]
(39) R̂A0 ⊆,A.9 Proof for Theorem 12,[0],[0]
R̂B1 ⊆ R̂A2,A.9 Proof for Theorem 12,[0],[0]
⊆ R̂A3 ....,A.9 Proof for Theorem 12,[0],[0]
(40) L̂B0 ⊆ L̂A1,A.9 Proof for Theorem 12,[0],[0]
⊆ L̂B2 ⊆,A.9 Proof for Theorem 12,[0],[0]
L̂A3 ....,A.9 Proof for Theorem 12,[0],[0]
(41) L̂A0 ⊆,A.9 Proof for Theorem 12,[0],[0]
L̂B1 ⊆ L̂A2 ⊆ L̂B3 ....,A.9 Proof for Theorem 12,[0],[0]
"(42)
By the first equality of Eqs.",A.9 Proof for Theorem 12,[0],[0]
"(34), (37), and (38), we can obtain F̂Ap = F̂Bt .",A.9 Proof for Theorem 12,[0],[0]
"Similarly, we can obtain R̂Ap = R̂Bt and L̂Ap = L̂Bt .
",A.9 Proof for Theorem 12,[0],[0]
"(2) If p is odd, then by Eqs.",A.9 Proof for Theorem 12,[0],[0]
"(37), (39, and (41), we have F̂As ⊆ F̂Bp+1, R̂As ⊆ R̂Bp+1, and L̂As ⊆ L̂Bp+1.",A.9 Proof for Theorem 12,[0],[0]
"Thus q ≤ p+ 1.
",A.9 Proof for Theorem 12,[0],[0]
"Else if p is even, then by Eqs.",A.9 Proof for Theorem 12,[0],[0]
"(38), (40), and (42), we have F̂As ⊆ F̂Bp+1, R̂As ⊆ R̂Bp+1, and L̂As ⊆ L̂Bp+1.",A.9 Proof for Theorem 12,[0],[0]
"Thus q ≤ p+ 1.
",A.9 Proof for Theorem 12,[0],[0]
"Doing the same analysis for q, we can obtain p ≤ q + 1.",A.9 Proof for Theorem 12,[0],[0]
"Hence, |p− q| ≤ 1.",A.9 Proof for Theorem 12,[0],[0]
The proof is complete.,A.9 Proof for Theorem 12,[0],[0]
"Proof of Theorem 13:
We notice (Xki ) >",A.10 Proof for Theorem 13,[0],[0]
w,A.10 Proof for Theorem 13,[0],[0]
= w>k xi−w>yixi.,A.10 Proof for Theorem 13,[0],[0]
By denoting φi(a) = ∑K k=1 `([ui]k +,A.10 Proof for Theorem 13,[0],[0]
"[a]k), it is easy
to verify that `i(w) = φi(X > i w).",A.10 Proof for Theorem 13,[0],[0]
"Thus, the problem (m-P ∗) can be rewritten as:
min w∈RKp
P (w;α, β) = 1
n n∑ i=1",A.10 Proof for Theorem 13,[0],[0]
φi(X > i w) +,A.10 Proof for Theorem 13,[0],[0]
α 2,A.10 Proof for Theorem 13,[0],[0]
"‖w‖2 + β||w||1.
",A.10 Proof for Theorem 13,[0],[0]
Let zi = X,A.10 Proof for Theorem 13,[0],[0]
>,A.10 Proof for Theorem 13,[0],[0]
i w.,A.10 Proof for Theorem 13,[0],[0]
"The primal problem (P ∗) is then equivalent to
min w∈Rp,z∈Rn
α 2 ||w||2 + β||w||1 + 1 n n∑ i=1 φi(zi),
s.t. zi",A.10 Proof for Theorem 13,[0],[0]
= X >,A.10 Proof for Theorem 13,[0],[0]
"i w, i = 1, 2, .., n.
The Lagrangian then becomes
L(w, z, θ) = α
2 ||w||2 + β||w||1",A.10 Proof for Theorem 13,[0],[0]
"+
1
n n∑ i=1 φi(zi)",A.10 Proof for Theorem 13,[0],[0]
+ 1 n n∑ i=1,A.10 Proof for Theorem 13,[0],[0]
"〈X>i w − zi, θi〉
= α
2 ||w||2 + β||w||1 +
1
n 〈Xθ,w〉︸ ︷︷ ︸
:=f1(w)
+ 1
n n∑ i=1
(φi(zi)− 〈zi, θi〉)︸ ︷︷ ︸ :=f2(z) .",A.10 Proof for Theorem 13,[0],[0]
"(43)
We first consider the subproblem minw L(w, z, θ):
0 ∈ ∂wL(w, z, θ) = ∂wf1(w) = αw + 1
n",A.10 Proof for Theorem 13,[0],[0]
"Xθ + β∂||w||1 ⇔
1 n",A.10 Proof for Theorem 13,[0],[0]
Xθ ∈ −αw,A.10 Proof for Theorem 13,[0],[0]
− β∂||w||1 ⇒ w =,A.10 Proof for Theorem 13,[0],[0]
− 1 α Sβ( 1 n Xθ).,A.10 Proof for Theorem 13,[0],[0]
"(44)
",A.10 Proof for Theorem 13,[0],[0]
By substituting Eq.,A.10 Proof for Theorem 13,[0],[0]
"(44) into f1(w), we obtain
f1(w) = α
2 ||w||2 + β||w||1",A.10 Proof for Theorem 13,[0],[0]
"− 〈αw + β∂||w||1,w〉 = −
α 2 ||w||2 = − 1 2α ||Sβ( 1 n Xθ)||2.",A.10 Proof for Theorem 13,[0],[0]
"(45)
Then, we consider the problem minz L(w, z, θ):
0 =∇[zi]kL(w, z, θ) = ∇[zi]kf2(z) =  ",A.10 Proof for Theorem 13,[0],[0]
− 1n,A.10 Proof for Theorem 13,[0],[0]
"[θi]k, if [zi]k +",A.10 Proof for Theorem 13,[0],[0]
"[ui]k < 0, 1 γn([zi]k + [ui]k)− 1 n",A.10 Proof for Theorem 13,[0],[0]
"[θi]k, if 0 ≤",A.10 Proof for Theorem 13,[0],[0]
[zi]k +,A.10 Proof for Theorem 13,[0],[0]
"[ui]k ≤ γ,
1 n",A.10 Proof for Theorem 13,[0],[0]
− 1 n,A.10 Proof for Theorem 13,[0],[0]
"[θi]k, if [zi]k +",A.10 Proof for Theorem 13,[0],[0]
"[ui]k > γ.
⇒[θi]k",A.10 Proof for Theorem 13,[0],[0]
"=  0, if [zi]k +",A.10 Proof for Theorem 13,[0],[0]
"[ui]k < 0, 1 γ ([zi]k +",A.10 Proof for Theorem 13,[0],[0]
"[ui]k), if 0 ≤",A.10 Proof for Theorem 13,[0],[0]
[zi]k +,A.10 Proof for Theorem 13,[0],[0]
"[ui]k ≤ γ,
1, if [zi]k +",A.10 Proof for Theorem 13,[0],[0]
"[ui]k > γ.
(46)
",A.10 Proof for Theorem 13,[0],[0]
"Thus, we have
f2(z) =
{ − γ2n ||θ||
2 + 1n〈u, θ〉, if [θi]k ∈",A.10 Proof for Theorem 13,[0],[0]
"[0, 1], ∀i ∈",A.10 Proof for Theorem 13,[0],[0]
"[n], k ∈",A.10 Proof for Theorem 13,[0],[0]
"[K], −∞, otherwise .",A.10 Proof for Theorem 13,[0],[0]
"(47)
",A.10 Proof for Theorem 13,[0],[0]
"Combining Eqs.(43), (45), and (47), we obtain the dual problem:
min θ∈[0,1] Kn
1
2α ||Sβ(
1 n Xθ)||2 +",A.10 Proof for Theorem 13,[0],[0]
"γ 2n ||θ||2 − 1 n 〈u, θ〉.",A.10 Proof for Theorem 13,[0],[0]
Lemma 14 can be proved quite similarly with Lemma 3.,A.11 Proof for Lemma 14,[0],[0]
"Therefore, we omit this proof here.",A.11 Proof for Lemma 14,[0],[0]
Proof of Lemma 15: (i),A.12 Proof for Lemma 15,[0],[0]
"We prove this lemma by verifying that the solutions w∗(α, β) = 0 and θ∗(α, β) = u satisfy the conditions (m-KKT-1) and (m-KKT-2).",A.12 Proof for Lemma 15,[0],[0]
"Firstly, since β ≥ βmax = || 1nXu||∞, we have Sβ( 1 nXu) = 0.",A.12 Proof for Lemma 15,[0],[0]
"Thus, w
∗(α, β) = 0 and θ∗(α, β) = u satisfy the condition (m-KKT-1).",A.12 Proof for Lemma 15,[0],[0]
"Then, for all i ∈",A.12 Proof for Lemma 15,[0],[0]
"[n], we have
〈Xki ,w∗(α, β)〉+",A.12 Proof for Lemma 15,[0],[0]
"[ui]k = [ui]k = { 1, if k 6= yi; 0, if k = yi; ∀i = 1, ..., n, k = 1, ...,K.
Thus, w∗(α, β) = 0 and θ∗(α, β) = u satisfy the condition (m-KKT-2).",A.12 Proof for Lemma 15,[0],[0]
"Hence, they are the solutions of the primal problem (m-P∗) and the dual problem (m-D∗), respectively.
(ii) Similar to the proof of (i), we prove this by verifying that the solutions w∗(α, β) = 1 αSβ(− 1 nXu) and θ ∗(α, β) = u satisfy the conditions (m-KKT-1) and (m-KKT-2).
1.",A.12 Proof for Lemma 15,[0],[0]
Case 1: αmax(β) ≤ 0.,A.12 Proof for Lemma 15,[0],[0]
"Then for all α > 0, we have
if k = yi, 〈Xki ,w∗(α, β)〉+ uki = uki = 0, if k 6= yi, 〈Xki ,w∗(α, β)〉+ uki = 1− 〈Xki , 1
α Sβ(
1 n Xu)〉
= 1− 1 α 〈Xki ,Sβ( 1 n Xu)〉 ≥ 1 > γ.
",A.12 Proof for Lemma 15,[0],[0]
"Thus, w∗(α, β) = 1αSβ(− 1 nXu) and θ ∗(α, β) = u satisfy the conditions (m-KKT-1) and (m-KKT-2).",A.12 Proof for Lemma 15,[0],[0]
"Hence, they are the optimal solution of problems (m-P∗) and (m-D∗).
2.",A.12 Proof for Lemma 15,[0],[0]
Case 2: αmax(β) > 0.,A.12 Proof for Lemma 15,[0],[0]
"Then for any α ≥ αmax(β), we have
if k = yi, 〈Xki ,w∗(α, β)〉+ uki = uki = 0, if k 6= yi, 〈Xki ,w∗(α, β)〉+ uki = 1− 〈Xki , 1
α Sβ(
1 n Xu)〉
= 1− 1 α 〈Xki ,Sβ( 1 n Xu)〉 ≥ 1− αmax(β) α (1− γ) ≥ 1− (1− γ) = γ.
",A.12 Proof for Lemma 15,[0],[0]
"Thus, w∗(α, β) = 1αSβ(− 1 nXu) and θ ∗(α, β) = u satisfy the conditions (m-KKT-1) and (m-KKT-2).",A.12 Proof for Lemma 15,[0],[0]
"Hence, they are the optimal solutions of the primal and dual problems (m-P∗) and (m-D∗).
",A.12 Proof for Lemma 15,[0],[0]
The proof is complete.,A.12 Proof for Lemma 15,[0],[0]
"Below, we report the rejection ratios of SIFS on syn1 (Fig. 8), syn3 (Fig. 9), rcv1-train (Fig. 10), rcv1-test(Fig. 11), url (Fig. 12), kddb (Fig. 13), syn-multi1 (Fig. 14), syn-multi3 (Fig. 15), and rcv1-multiclass (Fig. 16), which are omitted in the main paper.",A.13 More Experimental Results,[0],[0]
"In all the figures, the first row presents the rejection ratios of feature screening and the second row presents those of sample screening.",A.13 More Experimental Results,[0],[0]
Sparse support vector machine (SVM) is a popular classification technique that can simultaneously learn a small set of the most interpretable features and identify the support vectors.,abstractText,[0],[0]
It has achieved great successes in many real-world applications.,abstractText,[0],[0]
"However, for large-scale problems involving a huge number of samples and ultra-high dimensional features, solving sparse SVMs remains challenging.",abstractText,[0],[0]
"By noting that sparse SVMs induce sparsities in both feature and sample spaces, we propose a novel approach, which is based on accurate estimations of the primal and dual optima of sparse SVMs, to simultaneously identify the inactive features and samples that are guaranteed to be irrelevant to the outputs.",abstractText,[0],[0]
"Thus, we can remove the identified inactive samples and features from the training phase, leading to substantial savings in the computational cost without sacrificing the accuracy.",abstractText,[0],[0]
"Moreover, we show that our method can be extended to multi-class sparse support vector machines.",abstractText,[0],[0]
"To the best of our knowledge, the proposed method is the first static feature and sample reduction method for sparse SVMs and multi-class sparse SVMs.",abstractText,[0],[0]
Experiments on both synthetic and real data sets demonstrate that our approach significantly outperforms state-of-the-art methods and the speedup gained by our approach can be orders of magnitude.,abstractText,[0],[0]
Scaling Up Sparse Support Vector Machines by Simultaneous Feature and Sample Reduction,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 659–669 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Distributed word embeddings represent words as dense, low-dimensional and real-valued vectors that can capture their semantic and syntactic properties.",1 Introduction,[0],[0]
These embeddings are used abundantly by machine learning algorithms in tasks such as text classification and clustering.,1 Introduction,[0],[0]
Traditional bagof-word models that represent words as indices into a vocabulary don’t account for word ordering and long-distance semantic relations.,1 Introduction,[0],[0]
"Representations based on neural network language models
*Represents equal contribution
(Mikolov et al., 2013b) can overcome these flaws and further reduce the dimensionality of the vectors.",1 Introduction,[0],[0]
"The success of the method is recently mathematically explained using the random walk on discourses model (Arora et al., 2016a).",1 Introduction,[0],[0]
"However, there is a need to extend word embeddings to entire paragraphs and documents for tasks such as document and short-text classification.
",1 Introduction,[0],[0]
"Representing entire documents in a dense, lowdimensional space is a challenge.",1 Introduction,[0],[0]
"A simple weighted average of the word embeddings in a large chunk of text ignores word ordering, while a parse tree based combination of embeddings (Socher et al., 2013) can only extend to sentences.",1 Introduction,[0],[0]
"(Le and Mikolov, 2014) trains word and paragraph vectors to predict context but shares wordembeddings across paragraphs.",1 Introduction,[0],[0]
"However, words can have different semantic meanings in different contexts.",1 Introduction,[0],[0]
"Hence, vectors of two documents that contain the same word in two distinct senses need to account for this distinction for an accurate semantic representation of the documents.",1 Introduction,[0],[0]
"(Ling et al., 2015), (Liu et al., 2015a) map word embeddings to a latent topic space to capture different senses in which words occur.",1 Introduction,[0],[0]
"However, they represent complex documents in the same space as words, reducing their expressive power.",1 Introduction,[0],[0]
"These methods are also computationally intensive.
",1 Introduction,[0],[0]
"In this work, we propose the Sparse Composite Document Vector(SCDV) representation learning technique to address these challenges and create efficient, accurate and robust semantic representations of large texts for document classification tasks.",1 Introduction,[0],[0]
"SCDV combines syntax and semantics learnt by word embedding models together with a latent topic model that can handle different senses of words, thus enhancing the expressive power of document vectors.",1 Introduction,[0],[0]
"The topic space is learnt efficiently using a soft clustering technique over embeddings and the final document vectors are made
659
sparse for reduced time and space complexity in tasks that consume these vectors.
",1 Introduction,[0],[0]
The remaining part of the paper is organized as follows.,1 Introduction,[0],[0]
Section 2 discusses related work in document representations.,1 Introduction,[0],[0]
Section 3 introduces and explains SCDV in detail.,1 Introduction,[0],[0]
This is followed by extensive and rigorous experiments together with analysis in section 4 and 5 respectively.,1 Introduction,[0],[0]
"(Le and Mikolov, 2014) proposed two models for distributional representation of a document, namely, Distributed Memory Model Paragraph Vectors (PV-DM) and Distributed BoWs paragraph vectors (PV-DBoW).",2 Related Work,[0],[0]
"In PV-DM, the model is learned to predict the next context word using word and paragraph vectors.",2 Related Work,[0],[0]
"In PV-DBoW, the paragraph vector is directly learned to predict randomly sampled context words.",2 Related Work,[0],[0]
"In both models, word vectors are shared across paragraphs.",2 Related Work,[0],[0]
"While word vectors capture semantics across different paragraphs of the text, documents vectors are learned over context words generated from the same paragraph and potentially capture only local semantics (Singh and Mukerjee, 2015).",2 Related Work,[0],[0]
"Moreover, a paragraph vector is embedded in the same space as word vectors though it can contain multiple topics and words with multiple senses.",2 Related Work,[0],[0]
"As a result, doc2vec (Le and Mikolov, 2014) doesn’t perform well on Information Retrieval as described in (Ai et al., 2016a) and (Roy et al., 2016).",2 Related Work,[0],[0]
"Consequently, we expect a paragraph vector to be embedded in a higher dimensional space.
",2 Related Work,[0],[0]
"A paragraph vector also assumes all words contribute equally, both quantitatively (weight) and qualitatively (meaning).",2 Related Work,[0],[0]
"They ignore the importance and distinctiveness of a word across all documents (Singh and Mukerjee, 2015).",2 Related Work,[0],[0]
"Mukerjee et al. (Singh and Mukerjee, 2015) proposed idfweighted averaging of word vectors to form document vectors.",2 Related Work,[0],[0]
This method tries to address the above problem.,2 Related Work,[0],[0]
"However, it assumes that all words within a document belong to the same semantic topic.",2 Related Work,[0],[0]
"Intuitively, a paragraph often has words originating from several semantically different topics.",2 Related Work,[0],[0]
"In fact, Latent Dirichlet Allocation (Blei et al., 2003) models a document as a distribution of multiple topics.
",2 Related Work,[0],[0]
"These shortcomings are addressed in three novel composite document representations called Topical word embedding (TWE-1,TWE-2 and
TWE-3) by (Liu et al., 2015a).",2 Related Work,[0],[0]
TWE-1 learns word and topic embeddings by considering each topic as a pseudo word and builds the topical word embedding for each word-topic assignment.,2 Related Work,[0],[0]
"Here, the interaction between a word and the topic to which it is assigned is not considered.",2 Related Work,[0],[0]
"TWE-2 learns a topical word embedding for each word-topic assignment directly, by considering each word- topic pair as a pseudo word.",2 Related Work,[0],[0]
"Here, the interaction between a word and its assigned topic is considered but the vocabulary of pseudo-words blows up.",2 Related Work,[0],[0]
"For each word and each topic, TWE-3 builds distinct embeddings for the topic and word and concatenates them for each word-topic assignment.",2 Related Work,[0],[0]
"Here, the word embeddings are influenced by the corresponding topic embeddings, making words in the same topic less discriminative.
",2 Related Work,[0],[0]
"(Liu et al., 2015a) proposed an architecture called Neural tensor skip-gram model (NTSG-1, NTSG-2, NTSG-3, NTSG-4), that learns multiprototype word embeddings and uses a tensor layer to model the interaction of words and topics to capture different senses.",2 Related Work,[0],[0]
NTSG outperforms other embedding methods like TWE−1 on the 20 newsgroup data-set by modeling contextsensitive embeddings in addition to topical-word embeddings.,2 Related Work,[0],[0]
"LTSG (Law et al., 2017) builds on NTSG by jointly learning the latent topic space and context-sensitive word embeddings.",2 Related Work,[0],[0]
"All three, TWE, NTSG and LTSG use LDA and suffer from computational issues like large training time, prediction time and storage space.",2 Related Work,[0],[0]
They also embed document vectors in the same space as terms.,2 Related Work,[0],[0]
"Other works that harness topic modeling likeWTM (Fu et al., 2016),w2v−LDA (Nguyen et al., 2015), TV + MeanWV (Li et al., 2016a), LTSG (Law et al., 2017), Gaussian − LDA (Das et al., 2015), Topic2V ec (Niu et al., 2015), (Moody, 2016) andMvTM",2 Related Work,[0],[0]
"(Li et al., 2016b) also suffer from similar issues.
",2 Related Work,[0],[0]
"(Gupta et al., 2016) proposed a method to form a composite document vector using word embeddings and tf-idf values, called the Bag of Words Vector (BoWV).",2 Related Work,[0],[0]
"In BoWV , each document is represented by a vector of dimensionD = K ∗d+K, where K is the number of clusters and d is the dimension of the word embeddings.",2 Related Work,[0],[0]
The core idea behind BoWV is that semantically different words belong to different topics and their word vectors should not be averaged.,2 Related Work,[0],[0]
"Further, BoWV computes inverse cluster frequency of each clus-
ter (icf) by averaging the idf values of its member terms to capture the importance of words in the corpus.",2 Related Work,[0],[0]
"However,BoWV does hard clustering using K-means algorithm, assigning each word to only one cluster or semantic topic but a word can belong to multiple topics.",2 Related Work,[0],[0]
"For example, the word apple belongs to topic food as a fruit, and belongs to topic Information Technology as an IT company.",2 Related Work,[0],[0]
"Moreover, BoWV is a non-sparse, high dimensional continuous vector and suffers from computational problems like large training time, prediction time and storage requirements.",2 Related Work,[0],[0]
"In this section, we present the proposed Sparse Composite Document Vector (SCDV) representation as a novel document vector learning algorithm.",3 Sparse Composite Document Vectors,[0],[0]
The feature formation algorithm can be divided into three steps.,3 Sparse Composite Document Vectors,[0],[0]
"We begin by learning d dimensional word vector representations for every word in the vocabulary V using the skip-gram algorithm with negative sampling (SGNS) (Mikolov et al., 2013a).",3.1 Word Vector Clustering,[0],[0]
"We then cluster these word embeddings using the Gaussian Mixture Models(GMM) (Reynolds, 2015) soft clustering technique.",3.1 Word Vector Clustering,[0],[0]
"The number of clusters, K, to be formed is a parameter of the SCDV model.",3.1 Word Vector Clustering,[0],[0]
"By inducing soft clusters, we ensure that each word belongs to every cluster with some probability P (ck|wi).
",3.1 Word Vector Clustering,[0],[0]
"p(ck = 1) = πk
p(ck = 1|w) = πkN (w|µk,Σk)ΣKj=1πjN",3.1 Word Vector Clustering,[0],[0]
"(w|µj ,Σj)",3.1 Word Vector Clustering,[0],[0]
"For each word wi, we create K different wordcluster vectors of d dimensions ( ~wcvik) by weighting the word’s embedding with its probability distribution in the kth cluster, P (ck|wi).",3.2 Document Topic-vector Formation,[0],[0]
We then concatenate all K word-cluster vectors ( ~wcvik) into a K×d dimensional embedding and weight it with inverse document frequency of wi to form a word-topics vector ( ~wtvi).,3.2 Document Topic-vector Formation,[0],[0]
"Finally, for all words appearing in document Dn, we sum their wordtopic vectors ~wtvi to obtain the document vector ~dvDn .
",3.2 Document Topic-vector Formation,[0],[0]
"~wcvik = ~wvi × P (ck|wi)
Algorithm 1: Sparse Composite Document Vector Data: Documents Dn, n = 1 . . .",3.2 Document Topic-vector Formation,[0],[0]
N,3.2 Document Topic-vector Formation,[0],[0]
"Result: Document vectors ~SCDVDn , n = 1
. . .",3.2 Document Topic-vector Formation,[0],[0]
N 1,3.2 Document Topic-vector Formation,[0],[0]
"Obtain word vector ( ~wvi), for each word wi; 2 Calculate idf values, idf(wi), i = 1..|V",3.2 Document Topic-vector Formation,[0],[0]
"| ;
/* |V | is vocabulary size */ 3 Cluster word vectors ~wv using GMM
clustering into K clusters; 4 Obtain soft assignment P (ck|wi) for word wi
and cluster ck; /* Loop 5-10 can be
pre-computed */ 5 for each word wi in vocabulary V do 6 for each cluster ck do 7 ~wcvik = ~wvi × P (ck|wi); 8 end 9 ~wtvi = idf(wi) ×",3.2 Document Topic-vector Formation,[0],[0]
"⊕K k=1 ~wcvik ;
/* ⊕ is concatenation */
10 end 11 for n ∈ (1..N) do 12 Initialize document vector ~dvDn = ~0; 13 for word wi in Dn do 14 ~dvDn += ~wtvi; 15 end 16 ~SCDVDn = make-sparse( ~dvDn);
/* as mentioned in sec 3 */
17 end
~wtvi = idf(wi)× K⊕
k=1
~wcvik
where, ⊕ is concatenation",3.2 Document Topic-vector Formation,[0],[0]
"After normalizing the vector, we observed that most values in ~dvDn are very close to zero.",3.3 Sparse Document Vectors,[0],[0]
Figure 3 verifies this observation.,3.3 Sparse Document Vectors,[0],[0]
"We utilize this fact to make the document vector ~dvDn sparse by zeroing attribute values whose absolute value is close to a threshold (specified as a parameter), which results in the Sparse Composite Document Vector ~SCDVDn .",3.3 Sparse Document Vectors,[0],[0]
"In particular, let p be percentage sparsity threshold parameter, ai the value of the ith attribute of the non-Sparse Composite Document Vector and n represent the nth document in the training set:
ai = { ai if |ai| ≥ p100 ∗ t 0",3.3 Sparse Document Vectors,[0],[0]
"otherwise
t = |amin|+ |amax|
2
amin = avgn(mini(ai))
",3.3 Sparse Document Vectors,[0],[0]
"amax = avgn(maxi(ai))
Flowcharts depicting the formation of wordtopics vector and Sparse Composite Document Vectors are shown in figure 1 and figure 2 respectively.",3.3 Sparse Document Vectors,[0],[0]
Algorithm 1 describes SCDV in detail.,3.3 Sparse Document Vectors,[0],[0]
We perform multiple experiments to show the effectiveness of SCDV representations for multiclass and multi-label text classification.,4 Experiments,[0],[0]
"For all experiments and baselines, we use Intel(R) Xeon(R) CPU E5-2670 v2 @ 2.50GHz, 40 working cores, 128GB RAM machine with Linux Ubuntu 14.4.",4 Experiments,[0],[0]
"However, we utilize multiple cores only during Word2Vec training and when we run the one-vsrest classifier for Reuters.",4 Experiments,[0],[0]
"We consider the following baselines: Bag-ofWords (BoW) model (Harris, 1954), Bag of Word Vector (BoWV) (Gupta et al., 2016) model, paragraph vector models (Le and Mikolov, 2014), Topical word embeddings (TWE-1) (Liu et al., 2015b), Neural Tensor Skip-Gram Model (NTSG1 to NTSG-3) (Liu et al., 2015a), tf-idf weighted average word-vector model (Singh and Mukerjee, 2015) and weighted Bag of Concepts (weightBoC) (Kim et al., 2017), where we build topicdocument vectors by counting the member words in each topic.
",4.1 Baselines,[0],[0]
We use the best parameter settings as reported in all our baselines to generate their results.,4.1 Baselines,[0],[0]
"We use 200 dimensions for tf-idf weighted word-vector model, 400 for paragraph vector model, 80 topics and 400 dimensional vectors for TWE, NTSG, LTSG and 60 topics and 200 dimensional word vectors for BOWV.",4.1 Baselines,[0],[0]
"We also compare our results with reported results of other topic modeling based document embedding methods like WTM (Fu et al., 2016), w2v − LDA (Nguyen et al., 2015), LDA (Chen and Liu, 2014), TV + MeanWV (Li et al., 2016a), LTSG (Law et al., 2017), Gaussian−LDA (Das et al., 2015),",4.1 Baselines,[0],[0]
"Topic2V ec (Niu et al., 2015), (Moody, 2016)",4.1 Baselines,[0],[0]
andMvTM,4.1 Baselines,[0],[0]
"(Li et al., 2016b).",4.1 Baselines,[0],[0]
Implementation of SCDV and related experiments is available here 1.,4.1 Baselines,[0],[0]
We run multi-class experiments on 20NewsGroup dataset 2 and multi-label classification experiments on Reuters-21578 dataset 3.,4.2 Text Classification,[0],[0]
We use the script4 for preprocessing the Reuters-21578 dataset.,4.2 Text Classification,[0],[0]
"We use LinearSVM for multi-class classi-
1https://github.com/dheeraj7596/SCDV 2http://qwone.com/∼jason/20Newsgroups/ 3https://goo.gl/NrOfu 4 https://gist.github.com/herrfz/7967781
fication and Logistic regression with OneVsRest setting for multi-label classification in baselines and SCDV.
",4.2 Text Classification,[0],[0]
"For SCDV, we set the dimension of wordembeddings to 200 and the number of mixture components in GMM to 60.",4.2 Text Classification,[0],[0]
All mixture components share the same spherical co-variance matrix.,4.2 Text Classification,[0],[0]
"We learn word vector embedding using SkipGram with window size of 10, Negative Sampling (SGNS) of 10 and minimum word frequency as 20.",4.2 Text Classification,[0],[0]
We use 5-fold cross-validation on F1 score to tune parameter C of SVM and the sparsity threshold for SCDV.,4.2 Text Classification,[0],[0]
"We evaluate classifier performance using standard metrics like accuracy, macro-averaging precision, recall and F-measure.",4.2.1 Multi-class classification,[0],[0]
Table 1 shows a comparison with the current state-of-art (NTSG) document representations on the 20Newsgroup dataset.,4.2.1 Multi-class classification,[0],[0]
We observe that SCDV outperforms all other current models by fair margins.,4.2.1 Multi-class classification,[0],[0]
We also present the classwise precision and recall for 20Newsgroup on an almost balanced dataset with SVM over Bag of Words model and the SCDV embeddings in Table 2 and observe that SCDV improves consistently over all classes.,4.2.1 Multi-class classification,[0],[0]
"We evaluate multi-label classification performance using Precision@K, nDCG@k (Bhatia et al., 2015), Coverage error, Label ranking average precision score (LRAPS)5 and F1-score.",4.2.2 Multi-label classification,[0],[0]
All measures are extensively used for the multilabel classification task.,4.2.2 Multi-label classification,[0],[0]
"However, F1-score is an appropriate metric for multi-label classification as it considers label biases when train-test splits are random.",4.2.2 Multi-label classification,[0],[0]
Table 3 show evaluation results for multi-label text classification on the Reuters21578 dataset.,4.2.2 Multi-label classification,[0],[0]
"SCDV has three parameters: the number of clusters, word vector dimension and sparsity threshold parameter.",4.2.3 Effect of Hyper-Parameters,[0],[0]
We vary one parameter by keeping the other two constant.,4.2.3 Effect of Hyper-Parameters,[0],[0]
Performance on varying all three parameters in shown in Figure 4.,4.2.3 Effect of Hyper-Parameters,[0],[0]
We observe that performance improves as we increase the number of clusters and saturates at 60.,4.2.3 Effect of Hyper-Parameters,[0],[0]
The performance improves until a word vector dimension of 300 after which it saturates.,4.2.3 Effect of Hyper-Parameters,[0],[0]
"Similarly, we observe that the performance improves as we increase p till 4 after which it declines.",4.2.3 Effect of Hyper-Parameters,[0],[0]
"At 4% thresholding, we reduce the storage space by 80% compared to the dense vectors.",4.2.3 Effect of Hyper-Parameters,[0],[0]
"We observe that SCDV is robust to variations in training Word2Vec
5Section 3.3.3.2 of https://goo.gl/4GrR3M
and GMM.",4.2.3 Effect of Hyper-Parameters,[0],[0]
"The performance metrics reported in Tables 1, 3 are the average values obtained across 5 separate runs of SCDV , each run training a different Word2Vec and GMM model with identical hyper-parameters.",4.2.3 Effect of Hyper-Parameters,[0],[0]
We evaluate the topics generated by GMM clustering on 20NewsGroup for quantitative and qualitative analysis.,4.3 Topic Coherence,[0],[0]
"Instead of using perplexity (Chang et al., 2011), which doesn’t correlate with semantic coherence and human judgment of individual topics, we used the popular topic coherence (Mimno et al., 2011), (Arora et al., 2013), (Chen and Liu, 2014) measure.",4.3 Topic Coherence,[0],[0]
"A higher topic coherence score indicates a more coherent topic.
",4.3 Topic Coherence,[0],[0]
"We used Bayes rule to compute the P (wk|ci) for a given topic ci and given word wj and compute the score of the top 10 words for each topic.
P (wk|ci) = P (ci|wk)P (wk) P (ci)
where,
P (ci) = K∑
i=1
P (ci|wk)P (wk)
P (wk) = #(wk)∑V i=1",4.3 Topic Coherence,[0],[0]
"#(wi)
Here, #(wk) denotes the number of times word wk appears in the corpus and V represents vocabulary size.
",4.3 Topic Coherence,[0],[0]
"We calculated the topic coherence score for all topics for SCDV , LDA and LTSG (Law et al., 2017).",4.3 Topic Coherence,[0],[0]
"Averaging the score of all 80 topics, GMM clustering scores -85.23 compared to -108.72 of
LDA and -92.23 of LTSG.",4.3 Topic Coherence,[0],[0]
"Thus, SCDV creates more coherent topics than both LDA and LTSG.
",4.3 Topic Coherence,[0],[0]
"Table 4 shows top 10 words of 3 topics from GMM clustering, LDAmodel and LTSGmodel on 20NewsGroup and SCDV shows higher topic coherence.",4.3 Topic Coherence,[0],[0]
Words are ranked based on their probability distribution in each topic.,4.3 Topic Coherence,[0],[0]
"Our results also support the qualitative results of (Randhawa et al., 2016), (Sridhar, 2015) paper, where kmeans, GMM was used respectively over word vectors to find topics.",4.3 Topic Coherence,[0],[0]
"In order to demonstrate the effects of soft clustering (GMM) during SCDV formation, we select some words (wj) with multiple senses from 20Newsgroup and their soft cluster assignments to find the dominant clusters.",4.4 Context-Sensitive Learning,[0],[0]
We also select top scoring words (wk) from each cluster (ci) to represent the meaning of that cluster.,4.4 Context-Sensitive Learning,[0],[0]
Table 5 shows polysemic words and their dominant clusters with assignment probabilities.,4.4 Context-Sensitive Learning,[0],[0]
This indicates that using soft clustering to learn word vectors helps combine multiple senses into a single embedding vector.,4.4 Context-Sensitive Learning,[0],[0]
"(Arora et al., 2016b) also reported similar results for polysemous words.",4.4 Context-Sensitive Learning,[0],[0]
"(Ai et al., 2016b) used (Mikolov et al., 2013b)’s paragraph vectors to enhance the basic language model based retrieval model.",4.5 Information Retrieval,[0],[0]
"The language model(LM) probabilities are estimated from the corpus and smoothed using a Dirichlet prior (Zhai and Lafferty, 2004).",4.5 Information Retrieval,[0],[0]
"In (Ai et al., 2016b), this language model is then interpolated with the paragraph vector (PV) language model as follows.
P (w|d) = (1− λ)PLM (w|d) + λPPV (w|d)
where,
PPV (w|d) = exp(~w.",4.5 Information Retrieval,[0],[0]
"~d)∑V
i=1",4.5 Information Retrieval,[0],[0]
"exp( ~wi.~d)
and the score for document d and query string Q is given by
score(q, d) = ∑ w∈Q P (w)P (w|d)
where P (w) is obtained from the unigram query model and score(q, d) is used to rank documents.",4.5 Information Retrieval,[0],[0]
"(Ai et al., 2016b) do not directly make use of paragraph vectors for the retrieval task, but improve the document language model.",4.5 Information Retrieval,[0],[0]
"To directly make use of paragraph vectors and make computations more tractable, we directly interpolate the language model query-document score score(q, d) with the similarity score between the normalized query and document vectors to generate scorePV (q, d), which is then used to rank documents.
",4.5 Information Retrieval,[0],[0]
"scorePV (q, d) = (1− λ)score(q, d) + λ~q.~d
Directly evaluating the document similarity score with the query paragraph vector rather than collecting similarity scores for individual words in the query helps avoid confusion amongst distinct query topics and makes the interpolation operation faster.",4.5 Information Retrieval,[0],[0]
"In Table 6, we report Mean Average Precision(MAP) values for four datasets, Associated Press 88-89 (topics 51-200), Wall Street Journal (topics 51-200), San Jose Mercury (topics 51-150) and Disks 4 & 5 (topics 301-450) in the TREC collection.",4.5 Information Retrieval,[0],[0]
We learn λ on a held out set of topics.,4.5 Information Retrieval,[0],[0]
We observe consistent improvement in MAP for all datasets.,4.5 Information Retrieval,[0],[0]
"We marginally improve the MAP reported by (Ai et al., 2016b) on the Robust04 task.",4.5 Information Retrieval,[0],[0]
"In addition, we also report the improvements in MAP score when Model based relevance feedback (Zhai and Lafferty, 2001) is applied over the initially retrieved results from both models.",4.5 Information Retrieval,[0],[0]
"Again, we notice a consistent improvement in MAP.",4.5 Information Retrieval,[0],[0]
"SCDV overcomes several challenges encountered while training document vectors, which we had mentioned above.
3.",5 Analysis and Discussion,[0],[0]
"It is well-known that in higher dimensions, structural regularizers such as sparsity help overcome the curse of dimensionality (Wainwright, 2014).Figure 3 demonstrates this, since majority of the features are close to zero.",5 Analysis and Discussion,[0],[0]
Sparsity also enables linear SVM to scale to large dimensions.,5 Analysis and Discussion,[0],[0]
"On 20NewsGroups, BoWV model takes up 1.1 GB while SCDV takes up only 236MB( 80% decrease).",5 Analysis and Discussion,[0],[0]
"Since GMM assigns a non-zero probability to every topic in the word embedding, noise can accumulate when document vectors are created and tip the scales in favor of an unrelated topic.",5 Analysis and Discussion,[0],[0]
"Sparsity helps to reduce this by zeroing out very small values of probability.
4.",5 Analysis and Discussion,[0],[0]
"SCDV uses Gaussian Mixture Model (GMM) while TWE, NTSG and LTSG use LDA for finding semantic topics respectively.",5 Analysis and Discussion,[0],[0]
GMM time complexity is O(V NT 2) while that of LDA is O(V 2NT ).,5 Analysis and Discussion,[0],[0]
"Here, V = Vocabulary size, N = number of documents and T = number of topics.",5 Analysis and Discussion,[0],[0]
"Since number of topics T < vocabulary size V, GMM is faster.",5 Analysis and Discussion,[0],[0]
"Empirically, compared to TWE, SCDV reduces document vector formation, training and prediction time significantly.",5 Analysis and Discussion,[0],[0]
"Table 7 shows training and prediction times for BoWV, SCDV and TWE models.",5 Analysis and Discussion,[0],[0]
"In this paper, we propose a document feature formation technique for topic-based document representation.",6 Conclusion,[0],[0]
SCDV outperforms state-of-the-art models in multi-class and multi-label classification tasks.,6 Conclusion,[0],[0]
SCDV introduces sparsity in document vectors to handle high dimensionality.,6 Conclusion,[0],[0]
"Table 7 in-
Table 6: Mean average precision (MAP) for IR on four IR datasets
Dataset LM LM+SCDV",6 Conclusion,[0],[0]
"MB MB + SCDV AP 0.2742 0.2856 0.3283 0.3395
SJM 0.2052 0.2105 0.2341 0.2409 WSJ 0.2618 0.2705 0.3027 0.3126 Robust04 0.2516 0.2684 0.2819 0.2933
dicates that SCDV shows considerable improvements in feature formation, training and prediction times for the 20NewsGroups dataset.",6 Conclusion,[0],[0]
We show that fuzzy GMM clustering on word-vectors lead to more coherent topic than LDA and can also be used to detect Polysemic words.,6 Conclusion,[0],[0]
"SCDV embeddings also provide a robust estimation of the query and document language models, thus improving the MAP of language model based retrieval systems.",6 Conclusion,[0],[0]
"In conclusion, SCDV is simple, efficient and creates a more accurate semantic representation of documents.",6 Conclusion,[0],[0]
"The authors want to thank Nagarajan Natarajan (Post-Doc, Microsoft Research, India), Praneeth Netrapalli (Researcher, Microsoft Research, India), Raghavendra Udupa (Researcher, Microsoft Research, India), Prateek Jain (Researcher, Microsoft Research, India) for encouraging and valuable feedback .",Acknowledgments,[0],[0]
We present a feature vector formation technique for documents Sparse Composite Document Vector (SCDV) which overcomes several shortcomings of the current distributional paragraph vector representations that are widely used for text representation.,abstractText,[0],[0]
"In SCDV, word embeddings are clustered to capture multiple semantic contexts in which words occur.",abstractText,[0],[0]
"They are then chained together to form document topic-vectors that can express complex, multi-topic documents.",abstractText,[0],[0]
"Through extensive experiments on multi-class and multi-label classification tasks, we outperform the previous state-of-the-art method, NTSG (Liu et al., 2015a).",abstractText,[0],[0]
"We also show that SCDV embeddings perform well on heterogeneous tasks like Topic Coherence, context-sensitive Learning and Information Retrieval.",abstractText,[0],[0]
"Moreover, we achieve significant reduction in training and prediction times compared to other representation methods.",abstractText,[0],[0]
SCDV achieves best of both worlds better performance with lower time and space complexity.,abstractText,[0],[0]
SCDV : Sparse Composite Document Vectors using soft clustering over distributional representations,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 397–407 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Recent years have witnessed the rise of interest in many tasks at the intersection of computer vision and natural language processing, including semantic image retrieval (Johnson et al., 2015; Vendrov et al., 2015), image captioning (Mao et al., 2014; Karpathy and Li, 2015; Donahue et al., 2015; Liu et al., 2017b), visual question answering (Antol et al., 2015; Zhu et al., 2016; Andreas et al., 2016), and referring expressions (Hu et al., 2016; Mao et al., 2016; Liu et al., 2017a).",1 Introduction,[0],[0]
"The pursuit for these tasks is in line with people’s desire for high level understanding of visual content, in particular, using textual descriptions or questions to help understand or express images and scenes.
",1 Introduction,[0],[0]
"1Code is available at https://github.com/ Yusics/bist-parser/tree/sgparser
What is shared among all these tasks is the need for a common representation to establish connection between the two different modalities.",1 Introduction,[0],[0]
"The majority of recent works handle the vision side with convolutional neural networks, and the language side with recurrent neural networks (Hochreiter and Schmidhuber, 1997; Cho et al., 2014) or word embeddings (Mikolov et al., 2013; Pennington et al., 2014).",1 Introduction,[0],[0]
"In either case, neural networks map original sources into a semantically meaningful (Donahue et al., 2014; Mikolov et al., 2013) vector representation that can be aligned through end-toend training (Frome et al., 2013).",1 Introduction,[0],[0]
"This suggests that the vector embedding space is an appropriate choice as the common representation connecting different modalities (see e.g. Kaiser et al. (2017)).
",1 Introduction,[0],[0]
"While the dense vector representation yields impressive performance, it has an unfortunate limitation of being less intuitive and hard to interpret.",1 Introduction,[0],[0]
"Scene graphs (Johnson et al., 2015), on the other hand, proposed a type of directed graph to encode information in terms of objects, attributes of objects, and relationships between objects (see Figure 1 for visualization).",1 Introduction,[0],[0]
"This is a more structured and explainable way of expressing the knowledge from either modality, and is able to serve as an alternative form of common representation.",1 Introduction,[0],[0]
"In fact, the value of scene graph representation has already been proven in a wide range of visual tasks, including semantic image retrieval (Johnson et al., 2015), caption quality evaluation (Anderson et al., 2016), etc.",1 Introduction,[0],[0]
"In this paper, we focus on scene graph generation from textual descriptions.
",1 Introduction,[0],[0]
"Previous attempts at this problem (Schuster et al., 2015; Anderson et al., 2016) follow the same spirit.",1 Introduction,[0],[0]
"They first use a dependency parser to obtain the dependency relationship for all words in a sentence, and then use either a rule-based or a learned classifier as post-processing to generate the scene graph.",1 Introduction,[0],[0]
"However, the rule-based classifier cannot
397
learn from data, and the learned classifier is rather simple with hand-engineered features.",1 Introduction,[0],[0]
"In addition, the dependency parser was trained on linguistics data to produce complete dependency trees, some parts of which may be redundant and hence confuse the scene graph generation process.
",1 Introduction,[0],[0]
"Therefore, our model abandons the two-stage pipeline, and uses a single, customized dependency parser instead.",1 Introduction,[0],[0]
The customization is necessary for two reasons.,1 Introduction,[0],[0]
First is the difference in label space.,1 Introduction,[0],[0]
"Standard dependency parsing has tens of edge labels to represent rich relationships between words in a sentence, but in scene graphs we are only interested in three types, namely objects, attributes, and relations.",1 Introduction,[0],[0]
Second is whether every word needs a head.,1 Introduction,[0],[0]
"In some sense, the scene graph represents the “skeleton” of the sentence, which suggests that empty words are unlikely to be included in the scene graph.",1 Introduction,[0],[0]
"We argue that in scene graph generation, it is unnecessary to require a parent word for every single word.
",1 Introduction,[0],[0]
"We build our model on top of a neural depen-
dency parser implementation (Kiperwasser and Goldberg, 2016) that is among the state-of-theart.",1 Introduction,[0],[0]
We show that our carefully customized dependency parser is able to generate high quality scene graphs by learning from data.,1 Introduction,[0],[0]
"Specifically, we use the Visual Genome dataset (Krishna et al., 2017), which provides rich amounts of region description - region graph pairs.",1 Introduction,[0],[0]
"We first align nodes in region graphs with words in the region descriptions using simple rules, and then use this alignment to train our customized dependency parser.",1 Introduction,[0],[0]
We evaluate our parser by computing the F-score between the parsed scene graphs and ground truth scene graphs.,1 Introduction,[0],[0]
We also apply our approach to image retrieval to show its effectiveness.,1 Introduction,[0],[0]
"The scene graph representation was proposed in Johnson et al. (2015) as a way to represent the rich, structured knowledge within an image.",2.1 Scene Graphs,[0],[0]
"The nodes in a scene graph represent either an object, an attribute for an object, or a relationship between two objects.",2.1 Scene Graphs,[0],[0]
The edges depict the connection and association between two nodes.,2.1 Scene Graphs,[0],[0]
"This representation is later adopted in the Visual Genome dataset (Krishna et al., 2017), where a large number of scene graphs are annotated through crowd-sourcing.
",2.1 Scene Graphs,[0],[0]
"The scene graph representation has been proved useful in various problems including semantic image retrieval (Johnson et al., 2015), visual question answering (Teney et al., 2016), 3D scene synthesis (Chang et al., 2014), and visual relationship detection (Lu et al., 2016).",2.1 Scene Graphs,[0],[0]
"Excluding Johnson et al. (2015) which used ground truth, scene graphs are obtained either from images (Dai et al., 2017; Xu et al., 2017; Li et al., 2017) or from textual descriptions (Schuster et al., 2015; Anderson et al., 2016).",2.1 Scene Graphs,[0],[0]
"In this paper we focus on the latter.
",2.1 Scene Graphs,[0],[0]
"In particular, parsed scene graphs are used in Schuster et al. (2015) for image retrieval.",2.1 Scene Graphs,[0],[0]
"We show that with our more accurate scene graph parser, performance on this task can be further improved.",2.1 Scene Graphs,[0],[0]
"The goal of dependency parsing (Kübler et al., 2009) is to assign a parent word to every word in a sentence, and every such connection is associated with a label.",2.2 Parsing to Graph Representations,[0],[0]
"Dependency parsing is particularly suitable for scene graph generation because it directly models the relationship between individual
words without introducing extra nonterminals.",2.2 Parsing to Graph Representations,[0],[0]
"In fact, all previous work (Schuster et al., 2015; Anderson et al., 2016) on scene graph generation run dependency parsing on the textual description as a first step, followed by either heuristic rules or simple classifiers.",2.2 Parsing to Graph Representations,[0],[0]
"Instead of running two separate stages, our work proposed to use a single dependency parser that is end-to-end.",2.2 Parsing to Graph Representations,[0],[0]
"In other words, our customized dependency parser generates the scene graph in an online fashion as it reads the textual description once from left to right.
",2.2 Parsing to Graph Representations,[0],[0]
"In recent years, dependency parsing with neural network features (Chen and Manning, 2014; Dyer et al., 2015; Cross and Huang, 2016; Kiperwasser and Goldberg, 2016; Dozat and Manning, 2016; Shi et al., 2017) has shown impressive performance.",2.2 Parsing to Graph Representations,[0],[0]
"In particular, Kiperwasser and Goldberg (2016) used bidirectional LSTMs to generate features for individual words, which are then used to predict parsing actions.",2.2 Parsing to Graph Representations,[0],[0]
"We base our model on Kiperwasser and Goldberg (2016) for both its simplicity and good performance.
",2.2 Parsing to Graph Representations,[0],[0]
"Apart from dependency parsing, Abstract Meaning Representation (AMR) parsing (Flanigan et al., 2014; Werling et al., 2015; Wang et al., 2015; Konstas et al., 2017) may also benefit scene graph generation.",2.2 Parsing to Graph Representations,[0],[0]
"However, as first pointed out in Anderson et al. (2016), the use of dependency trees still appears to be a common theme in the literature, and we leave the exploration of AMR parsing for scene graph generation as future work.
",2.2 Parsing to Graph Representations,[0],[0]
"More broadly, our task also relates to entity and relation extraction, e.g. Katiyar and Cardie (2017), but there object attributes are not handled.",2.2 Parsing to Graph Representations,[0],[0]
"Neural module networks (Andreas et al., 2016) also use dependency parses, but they translate questions into a series of actions, whereas we parse descriptions into their graph form.",2.2 Parsing to Graph Representations,[0],[0]
"Finally, Krishnamurthy and Kollar (2013) connected parsing and grounding by training the parser in a weakly supervised fashion.",2.2 Parsing to Graph Representations,[0],[0]
"In this section, we begin by reviewing the scene graph representation, and show how its nodes and edges relate to the words and arcs in dependency parsing.",3 Task Description,[0],[0]
"We then describe simple yet reliable rules to align nodes in scene graphs with words in textual descriptions, such that customized dependency parsing, described in the next section, may be trained and applied.",3 Task Description,[0],[0]
"There are three types of nodes in a scene graph: object, attribute, and relation.",3.1 Scene Graph Definition,[0],[0]
"Let O be the set of object classes, A be the set of attribute types, and R be the set of relation types.",3.1 Scene Graph Definition,[0],[0]
"Given a sentence s, our goal in this paper is to parse s into a scene graph:
G(s) = 〈O(s), A(s), R(s)〉 (1)
where O(s) = {o1(s), . . .",3.1 Scene Graph Definition,[0],[0]
", om(s)}, oi(s) ∈ O is the set of object instances mentioned in s, A(s) ⊆ O(s)",3.1 Scene Graph Definition,[0],[0]
×,3.1 Scene Graph Definition,[0],[0]
"A is the set of attributes associated with object instances, and R(s) ⊆ O(s)×R×O(s) is the set of relations between object instances.",3.1 Scene Graph Definition,[0],[0]
"G(s) is a graph because we can first create an object node for every element inO(s); then for every (o, a) pair in A(s), we create an attribute node and add an unlabeled edge o→ a; finally for every (o1, r, o2) triplet inR(s), we create a relation node and add two unlabeled edges o1 → r and r → o2.",3.1 Scene Graph Definition,[0],[0]
The resulting directed graph exactly encodes information in G(s).,3.1 Scene Graph Definition,[0],[0]
"We call this the node-centric graph representation of a scene graph.
",3.1 Scene Graph Definition,[0],[0]
"We realize that a scene graph can be equivalently represented by no longer distinguishing between the three types of nodes, yet assigning labels to the edges instead.",3.1 Scene Graph Definition,[0],[0]
"Concretely, this means there is now only one type of node, but we assign a ATTR label for every o→ a edge, a SUBJ label for every o1 → r edge, and a OBJT label for every r → o2 edge.",3.1 Scene Graph Definition,[0],[0]
"We call this the edge-centric graph representation of a scene graph.
",3.1 Scene Graph Definition,[0],[0]
We can now establish a connection between scene graphs and dependency trees.,3.1 Scene Graph Definition,[0],[0]
Here we only consider scene graphs that are acyclic2.,3.1 Scene Graph Definition,[0],[0]
The edgecentric view of a scene graph is very similar to a dependency tree: they are both directed acyclic graphs where the edges/arcs have labels.,3.1 Scene Graph Definition,[0],[0]
"The difference is that in a scene graph, the nodes are the objects/attributes/relations and the edges have label space {ATTR, SUBJ, OBJT}, whereas in a dependency tree, the nodes are individual words in a sentence and the edges have a much larger label space.",3.1 Scene Graph Definition,[0],[0]
We have shown the connection between nodes in scene graphs and words in dependency parsing.,3.2 Sentence-Graph Alignment,[0],[0]
"With alignment between nodes in scene
2In Visual Genome, only 4.8% region graphs have cyclic structures.
graphs and words in the textual description, scene graph generation and dependency parsing becomes equivalent: we can construct the generated scene graph from the set of labeled edges returned by the dependency parser.",3.2 Sentence-Graph Alignment,[0],[0]
"Unfortunately, such alignment is not provided between the region graphs and region descriptions in the Visual Genome (Krishna et al., 2017) dataset.",3.2 Sentence-Graph Alignment,[0],[0]
"Here we describe how we use simple yet reliable rules to do sentence-graph (word-node) alignment.
",3.2 Sentence-Graph Alignment,[0],[0]
"There are two strategies that we could use in deciding whether to align a scene graph node d (whose label space is O ∪ A ∪ R) with a word/phrase w in the sentence:
• Word-by-word match (WBW): d ↔",3.2 Sentence-Graph Alignment,[0],[0]
"w only when d’s label and w match word-for-word.
",3.2 Sentence-Graph Alignment,[0],[0]
• Synonym match (SYN)3:,3.2 Sentence-Graph Alignment,[0],[0]
"d ↔ w when the wordnet synonyms of d’s label contain w.
Obviously WBW is a more conservative strategy than SYN.
",3.2 Sentence-Graph Alignment,[0],[0]
"We propose to use two cycles and each cycle further consists of three steps, where we try to align objects, attributes, relations in that order.",3.2 Sentence-Graph Alignment,[0],[0]
The pseudocode for the first cycle is in Algorithm 1.,3.2 Sentence-Graph Alignment,[0],[0]
"The second cycle repeats line 4-15 immediately afterwards, except that in line 6 we also allow SYN.",3.2 Sentence-Graph Alignment,[0],[0]
"Intuitively, in the first cycle we use a conservative strategy to find “safe” objects, and then scan for their attributes and relations.",3.2 Sentence-Graph Alignment,[0],[0]
"In the second cycle we relax and allow synonyms in aligning object nodes, also followed by the alignment of attribute and relation nodes.
",3.2 Sentence-Graph Alignment,[0],[0]
The ablation study of the alignment procedure is reported in the experimental section.,3.2 Sentence-Graph Alignment,[0],[0]
"In the previous section, we have established the connection between scene graph generation and dependency parsing, which assigns a parent word for every word in a sentence, as well as a label for this directed arc.",4 Customized Dependency Parsing,[0],[0]
"We start by describing our base dependency parsing model, which is neural network based and performs among the state-of-theart.",4 Customized Dependency Parsing,[0],[0]
"We then show why and how we do customization, such that scene graph generation is achieved with a single, end-to-end model.
",4 Customized Dependency Parsing,[0],[0]
"3This strategy is also used in (Denkowski and Lavie, 2014) and (Anderson et al., 2016).
",4 Customized Dependency Parsing,[0],[0]
"Algorithm 1: First cycle of the alignment procedure.
",4 Customized Dependency Parsing,[0],[0]
1 Input: Sentence s; Scene graph G(s) 2 Initialize aligned nodes N as empty set 3 Initialize aligned words W as empty set 4 for o in object nodes of G(s) \N do 5 for w in s \W do 6 if o↔ w according to WBW then 7,4 Customized Dependency Parsing,[0],[0]
"Add (o, w); N = N ∪ {o};
W =W ∪ {w}
8 for a in attribute nodes of G(s) \N do 9 for w in s \W do
10 if a↔ w according to WBW or SYN and a’s object node is in N then 11",4 Customized Dependency Parsing,[0],[0]
"Add (a,w); N = N ∪ {a}; W =W ∪ {w}
12 for r in relation nodes of G(s) \N do 13 for w in s \W do 14 if r ↔ w",4 Customized Dependency Parsing,[0],[0]
"according to WBW or SYN
and r’s subject and object nodes are both in N then
15 Add (r, w); N = N ∪ {r}; W =W ∪ {w}",4 Customized Dependency Parsing,[0],[0]
We base our model on the transition-based parser of Kiperwasser and Goldberg (2016).,4.1 Neural Dependency Parsing Base Model,[0],[0]
"Here we describe its key components: the arc-hybrid system that defines the transition actions, the neural architecture for feature extractor and scoring function, and the loss function.
",4.1 Neural Dependency Parsing Base Model,[0],[0]
"The Arc-Hybrid System In the arc-hybrid system, a configuration consists of a stack σ, a buffer β, and a set T of dependency arcs.",4.1 Neural Dependency Parsing Base Model,[0],[0]
"Given a sentence s = w1, . . .",4.1 Neural Dependency Parsing Base Model,[0],[0]
", wn, the system is initialized with an empty stack σ, an empty arc set T , and β = 1, . . .",4.1 Neural Dependency Parsing Base Model,[0],[0]
", n,ROOT, where ROOT is a special index.",4.1 Neural Dependency Parsing Base Model,[0],[0]
The system terminates when σ is empty and β contains only ROOT.,4.1 Neural Dependency Parsing Base Model,[0],[0]
"The dependency tree is given by the arc set T upon termination.
",4.1 Neural Dependency Parsing Base Model,[0],[0]
"The arc-hybrid system allows three transition actions, SHIFT, LEFTl, RIGHTl, described in Table 1.",4.1 Neural Dependency Parsing Base Model,[0],[0]
The SHIFT transition moves the first element of the buffer to the stack.,4.1 Neural Dependency Parsing Base Model,[0],[0]
"The LEFT(l) transition yields an arc from the first element of the buffer to the top element of the stack, and then removes the top element from the stack.",4.1 Neural Dependency Parsing Base Model,[0],[0]
"The
RIGHT(l) transition yields an arc from the second top element of the stack to the top element of the stack, and then also removes the top element from the stack.
",4.1 Neural Dependency Parsing Base Model,[0],[0]
"The following paragraphs describe how to select the correct transition action (and label l) in each step in order to generate a correct dependency tree.
",4.1 Neural Dependency Parsing Base Model,[0],[0]
"BiLSTM Feature Extractor Let the word embeddings of a sentence s be w1, . . .",4.1 Neural Dependency Parsing Base Model,[0],[0]
",wn.",4.1 Neural Dependency Parsing Base Model,[0],[0]
"An LSTM cell is a parameterized function that takes as input wt, and updates its hidden states:
LSTM cell : (wt,ht−1)→",4.1 Neural Dependency Parsing Base Model,[0],[0]
"ht (2)
As a result, an LSTM network, which simply applies the LSTM cell t times, is a parameterized function mapping a sequence of input vectors w1:t to a sequence of output vectors h1:",4.1 Neural Dependency Parsing Base Model,[0],[0]
"t. In our notation, we drop the intermediate vectors h1:t−1 and let LSTM(w1:t) represent ht.
",4.1 Neural Dependency Parsing Base Model,[0],[0]
"A bidirectional LSTM, or BiLSTM for short, consists of two LSTMs: LSTMF which reads the input sequence in the original order, and LSTMB which reads it in reverse.",4.1 Neural Dependency Parsing Base Model,[0],[0]
"Then
BILSTM(w1:n, i) =
LSTMF (w1:i) ◦",4.1 Neural Dependency Parsing Base Model,[0],[0]
"LSTMB(wn:i) (3)
where ◦ denotes concatenation.",4.1 Neural Dependency Parsing Base Model,[0],[0]
"Intuitively, the forward LSTM encodes information from the left side of the i-th word and the backward LSTM encodes information to its right, such that the vector vi = BILSTM(w1:n, i) has the full sentence as context.
",4.1 Neural Dependency Parsing Base Model,[0],[0]
"When predicting the transition action, the feature function φ(c) that summarizes the current configuration c = (σ, β, T ) is simply the concatenated BiLSTM vectors of the top three elements in the stack and the first element in the buffer:
φ(c) = vs2 ◦",4.1 Neural Dependency Parsing Base Model,[0],[0]
"vs1 ◦ vs0 ◦ vb0 (4)
MLP Scoring Function The score of transition action y under the current configuration c is determined by a multi-layer perceptron with one hidden layer:
f(c, y) =MLP (φ(c))[y] (5)
where
MLP (x) =W2 · tanh(W1 ·",4.1 Neural Dependency Parsing Base Model,[0],[0]
"x+ b1) + b2 (6)
",4.1 Neural Dependency Parsing Base Model,[0],[0]
Hinge Loss Function,4.1 Neural Dependency Parsing Base Model,[0],[0]
The training objective is to raise the scores of correct transitions above scores of incorrect ones.,4.1 Neural Dependency Parsing Base Model,[0],[0]
"Therefore, at each step, we use a hinge loss defined as:
L = max(0, 1− max y+∈Y + f(c, y+)
+ max y−∈Y \Y +
f(c, y−))",4.1 Neural Dependency Parsing Base Model,[0],[0]
"(7)
where Y is the set of possible transitions and Y + is the set of correct transitions at the current step.",4.1 Neural Dependency Parsing Base Model,[0],[0]
"In each training step, the parser scores all possible transitions using Eqn. 5, incurs a loss using Eqn. 7, selects a following transition, and updates the configuration.",4.1 Neural Dependency Parsing Base Model,[0],[0]
"Losses at individual steps are summed throughout the parsing of a sentence, and then parameters are updated using backpropagation.
",4.1 Neural Dependency Parsing Base Model,[0],[0]
"In test time, we simply choose the transition action that yields the highest score at each step.",4.1 Neural Dependency Parsing Base Model,[0],[0]
"In order to generate scene graphs with dependency parsing, modification is necessary for at least two reasons.",4.2 Customization,[0],[0]
"First, we need to redefine the label space of arcs so as to reflect the edge-centric representation of a scene graph.",4.2 Customization,[0],[0]
"Second, not every word in the sentence will be (part of) a node in the scene graph (see Figure 2 for an example).",4.2 Customization,[0],[0]
"In other words, some words in the sentence may not have a parent word, which violates the dependency parsing setting.",4.2 Customization,[0],[0]
"We tackle these two challenges by redesigning the edge labels and expanding the set of transition actions.
",4.2 Customization,[0],[0]
"Redesigning Edge Labels We define a total of five edge labels, so as to faithfully bridge the edgecentric view of scene graphs with dependency parsing models:
• CONT:",4.2 Customization,[0],[0]
This label is created for nodes whose label is a phrase.,4.2 Customization,[0],[0]
"For example, the phrase “in front of” is a single relation node in the scene graph.",4.2 Customization,[0],[0]
"By introducing the CONT label, we expect the parsing result to be either
in CONT−−−→ front CONT−−−→ of (8)
or in CONT←−−− front CONT←−−− of (9)
where the direction of the arcs (left or right) is predefined by hand.
",4.2 Customization,[0],[0]
The leftmost word under the right arc rule or the rightmost word under the left arc rule is called the head of the phrase.,4.2 Customization,[0],[0]
"A single-word node does not need this CONT label, and the head is itself.
",4.2 Customization,[0],[0]
• ATTR:,4.2 Customization,[0],[0]
"The arc label from the head of an object node to the head of an attribute node.
•",4.2 Customization,[0],[0]
SUBJ:,4.2 Customization,[0],[0]
"The arc label from the head of an object node (subject) to the head of a relation node.
",4.2 Customization,[0],[0]
•,4.2 Customization,[0],[0]
OBJT:,4.2 Customization,[0],[0]
"The arc label from the head of a relation node to the head of an object node (object).
• BEGN:",4.2 Customization,[0],[0]
"The arc label from the ROOT index to all heads of object nodes without a parent.
",4.2 Customization,[0],[0]
"Expanding Transition Actions With the three transition actions SHIFT, LEFT(l), RIGHT(l), we only drop an element (from the top of the stack) after it has already been associated with an arc.",4.2 Customization,[0],[0]
This design ensures that an arc is associated with every word.,4.2 Customization,[0],[0]
"However, in our setting for scene graph generation, there may be no arc for some of the words, especially empty words.
",4.2 Customization,[0],[0]
"Our solution is to augment the action set with a REDUCE action, that pops the stack without adding to the arc set (see Table 1).",4.2 Customization,[0],[0]
"This action is often used in other transition-based dependency parsing systems (e.g. arc-eager (Nivre, 2004)).",4.2 Customization,[0],[0]
"More recently, Hershcovich et al. (2017) and Buys and Blunsom (2017) also included this action when parsing sentences to graph structures.
",4.2 Customization,[0],[0]
"We still minimize the loss function defined in Eqn. 7, except that now |Y | increases from 3 to 4.",4.2 Customization,[0],[0]
"During training, we impose the oracle to select the REDUCE action when it is in Y +.",4.2 Customization,[0],[0]
"In terms of loss function, we increment by 1 the loss incurred by the other 3 transition actions if REDUCE incurs zero loss.",4.2 Customization,[0],[0]
"We train and evaluate our scene graph parsing model on (a subset of) the Visual Genome (Krishna et al., 2017) dataset.",5.1 Implementation Details,[0],[0]
"Each image in Visual Genome contains a number of regions, and each region is annotated with both a region description and a region scene graph.",5.1 Implementation Details,[0],[0]
"Our training set is the intersection of Visual Genome and MS COCO (Lin et al., 2014)",5.1 Implementation Details,[0],[0]
"train2014 set, which contains a total of 34027 images/ 1070145 regions.",5.1 Implementation Details,[0],[0]
"We evaluate on the intersection of Visual Genome and MS COCO val2014 set, which contains a total of 17471 images/ 547795 regions.
",5.1 Implementation Details,[0],[0]
"In our experiments, the number of hidden units in BiLSTM is 256; the number of layers in BiLSTM is 2; the word embedding dimension is 200; the number of hidden units in MLP is 100.",5.1 Implementation Details,[0],[0]
"We use fixed learning rate 0.001 and Adam optimizer (Kingma and Ba, 2014) with epsilon 0.01.",5.1 Implementation Details,[0],[0]
"Training usually converges within 4 epochs.
",5.1 Implementation Details,[0],[0]
We will release our code and trained model upon acceptance.,5.1 Implementation Details,[0],[0]
"We use a slightly modified version of SPICE score (Anderson et al., 2016) to evaluate the quality of
scene graph parsing.",5.2 Quality of Parsed Scene Graphs,[0],[0]
"Specifically, for every region, we parse its description using a parser (e.g. the one used in SPICE or our customized dependency parser), and then calculate the F-score between the parsed graph and the ground truth region graph (see Section 3.2 of Anderson et al. (2016) for more details).",5.2 Quality of Parsed Scene Graphs,[0],[0]
"Note that when SPICE calculates the Fscore, a node in one graph could be matched to several nodes in the other, which is problematic.",5.2 Quality of Parsed Scene Graphs,[0],[0]
We fix this and enforce one-to-one matching when calculating the F-score.,5.2 Quality of Parsed Scene Graphs,[0],[0]
"Finally, we report the average F-score across all regions.
",5.2 Quality of Parsed Scene Graphs,[0],[0]
Table 2 summarizes our results.,5.2 Quality of Parsed Scene Graphs,[0],[0]
"We see that our customized dependency parsing model achieves
an average F-score of 49.67%, which significantly outperforms the parser used in SPICE by 5 percent.",5.2 Quality of Parsed Scene Graphs,[0],[0]
"This result shows that our customized dependency parser is very effective at learning from data, and generates more accurate scene graphs than the best previous approach.
",5.2 Quality of Parsed Scene Graphs,[0],[0]
"Ablation Studies First, we study how the sentence-graph alignment procedure affects the final performance.",5.2 Quality of Parsed Scene Graphs,[0],[0]
"Recall that our procedure involves two cycles, each with three steps.",5.2 Quality of Parsed Scene Graphs,[0],[0]
"Of the six steps, synonym match (SYN) is only not used in the first step.",5.2 Quality of Parsed Scene Graphs,[0],[0]
"We tried two more settings, where SYN is either used in all six steps or none of the six steps.",5.2 Quality of Parsed Scene Graphs,[0],[0]
"We can see from Table 2 that the final
F-score drops in both cases, hence supporting the procedure that we chose.
",5.2 Quality of Parsed Scene Graphs,[0],[0]
"Second, we study whether changing the direction of CONT arcs from pointing left to pointing right will make much difference.",5.2 Quality of Parsed Scene Graphs,[0],[0]
"Table 2 shows that the two choices give very similar performance, suggesting that our dependency parser is robust to this design choice.
",5.2 Quality of Parsed Scene Graphs,[0],[0]
"Finally, we report the oracle score, which is the similarity between the aligned graphs that we use during training and the ground truth graphs.",5.2 Quality of Parsed Scene Graphs,[0],[0]
The F-score is relatively high at 69.85%.,5.2 Quality of Parsed Scene Graphs,[0],[0]
"This shows that improving the parser (about 20% margin) and improving the sentence-graph alignment (about 30% margin) are both promising directions for future research.
",5.2 Quality of Parsed Scene Graphs,[0],[0]
Qualitative Examples,5.2 Quality of Parsed Scene Graphs,[0],[0]
We provide one parsing example in Figure 2 and Figure 3.,5.2 Quality of Parsed Scene Graphs,[0],[0]
"This is a sentence that is relatively simple, and the underlying scene graph includes two object nodes, one attribute node, and one compound word relation node.",5.2 Quality of Parsed Scene Graphs,[0],[0]
"In parsing this sentence, all four actions listed in Table 1 are used (see Figure 3) to produce the edge-centric scene graph (bottom left of Figure 2), which is then trivially converted to the node-centric scene graph (bottom right of Figure 2).",5.2 Quality of Parsed Scene Graphs,[0],[0]
"We test if the advantage of our parser can be propagated to computer vision tasks, such as image retrieval.",5.3 Application in Image Retrieval,[0],[0]
"We directly compare our parser with the Stanford Scene Graph Parser (Schuster et al., 2015) on the development set and test set of the image retrieval dataset used in Schuster et al. (2015) (not Visual Genome).
",5.3 Application in Image Retrieval,[0],[0]
"For every region in an image, there is a humanannotated region description and region scene graph.",5.3 Application in Image Retrieval,[0],[0]
The queries are the region descriptions.,5.3 Application in Image Retrieval,[0],[0]
"If the region graph corresponding to the query is a subgraph of the complete graph of another image,
then that image is added to the ground truth set for this query.",5.3 Application in Image Retrieval,[0],[0]
All these are strictly following Schuster et al. (2015).,5.3 Application in Image Retrieval,[0],[0]
"However, since we did not obtain nor reproduce the CRF model used in Johnson et al. (2015) and Schuster et al. (2015), we used F-score similarity instead of the likelihood of the maximum a posteriori CRF solution when ranking the images based on the region descriptions.",5.3 Application in Image Retrieval,[0],[0]
"Therefore the numbers we report in Table 3 are not directly comparable with those reported in Schuster et al. (2015).
",5.3 Application in Image Retrieval,[0],[0]
"Our parser delivers better retrieval performance across all three evaluation metrics: recall@5, recall@10, and median rank.",5.3 Application in Image Retrieval,[0],[0]
We also notice that the numbers in our retrieval setting are higher than those (even with oracle) in Schuster et al. (2015)’s retrieval setting.,5.3 Application in Image Retrieval,[0],[0]
"This strongly suggests that generating accurate scene graphs from images is a very promising research direction in image retrieval, and grounding parsed scene graphs to bounding box proposals without considering visual attributes/relationships (Johnson et al., 2015) is suboptimal.",5.3 Application in Image Retrieval,[0],[0]
"In this paper, we offer a new perspective and solution to the task of parsing scene graphs from textual descriptions.",6 Conclusion,[0],[0]
We begin by moving the labels/types from the nodes to the edges and introducing the edge-centric view of scene graphs.,6 Conclusion,[0],[0]
We further show that the gap between edge-centric scene graphs and dependency parses can be filled with a careful redesign of label and action space.,6 Conclusion,[0],[0]
"This motivates us to train a single, customized, end-to-end neural dependency parser for this task, as opposed to prior approaches that used generic dependency parsing followed by heuristics or simple classifier.",6 Conclusion,[0],[0]
"We directly train our parser on a subset of Visual Genome (Krishna et al., 2017), without transferring any knowledge from Penn Treebank (Marcus et al., 1993) as previous works did.
",6 Conclusion,[0],[0]
"The quality of our trained parser is validated in terms of both SPICE similarity to the ground truth graphs and recall rate/median rank when performing image retrieval.
",6 Conclusion,[0],[0]
We hope our paper can lead to more thoughts on the creative uses and extensions of existing NLP tools to tasks and datasets in other domains.,6 Conclusion,[0],[0]
"In the future, we plan to tackle more computer vision tasks with this improved scene graph parsing technique in hand, such as image region grounding.",6 Conclusion,[0],[0]
"We also plan to investigate parsing scene graph with cyclic structures, as well as whether/how the image information can help boost parsing quality.",6 Conclusion,[0],[0]
The majority of this work was done when YSW and XZ were visiting Johns Hopkins University.,Acknowledgments,[0],[0]
"We thank Peter Anderson, Sebastian Schuster, Ranjay Krishna, Tsung-Yi Lin for comments and help regarding the experiments.",Acknowledgments,[0],[0]
"We also thank Tianze Shi, Dingquan Wang, Chu-Cheng Lin for discussion and feedback on the draft.",Acknowledgments,[0],[0]
"This work was sponsored by the National Science Foundation Center for Brains, Minds, and Machines NSF CCF-1231216.",Acknowledgments,[0],[0]
CL also acknowledges an award from Snap Inc.,Acknowledgments,[0],[0]
"In this paper, we study the problem of parsing structured knowledge graphs from textual descriptions.",abstractText,[0],[0]
"In particular, we consider the scene graph representation (Johnson et al., 2015) that considers objects together with their attributes and relations: this representation has been proved useful across a variety of vision and language applications.",abstractText,[0],[0]
We begin by introducing an alternative but equivalent edgecentric view of scene graphs that connect to dependency parses.,abstractText,[0],[0]
"Together with a careful redesign of label and action space, we combine the two-stage pipeline used in prior work (generic dependency parsing followed by simple post-processing) into one, enabling end-toend training.",abstractText,[0],[0]
"The scene graphs generated by our learned neural dependency parser achieve an F-score similarity of 49.67% to ground truth graphs on our evaluation set, surpassing best previous approaches by 5%.",abstractText,[0],[0]
We further demonstrate the effectiveness of our learned parser on image retrieval applications.1,abstractText,[0],[0]
Scene Graph Parsing as Dependency Parsing,title,[0],[0]
A longstanding ambition of research in artificial intelligence is to efficiently generalize experience in one scenario to other similar scenarios.,1. Introduction,[0],[0]
Such generalization is essential for an embodied agent working to accomplish a variety of goals in a changing world.,1. Introduction,[0],[0]
"Despite remarkable progress on individual tasks like Atari 2600 games (Mnih et al., 2015; Van Hasselt et al., 2016; Mnih et al., 2016) and Go (Silver et al., 2016a), the ability of state-of-the-art models to transfer learning from one environment to the next remains lim-
All authors affiliated with Vicarious AI, California, USA.",1. Introduction,[0],[0]
"Correspondence to: Ken Kansky <ken@vicarious.com>, Tom Silver <tom@vicarious.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
ited.,1. Introduction,[0],[0]
"For instance, consider the variations of Breakout illustrated in Fig. 1.",1. Introduction,[0],[0]
"In these environments the positions of objects are perturbed, but the object movements and sources of reward remain the same.",1. Introduction,[0],[0]
"While humans have no trouble generalizing experience from the basic Breakout to its variations, deep neural network-based models are easily fooled (Taylor & Stone, 2009; Rusu et al., 2016).
",1. Introduction,[0],[0]
The model-free approach of deep reinforcement learning (Deep RL) such as the Deep-Q Network and its descendants is inherently hindered by the same feature that makes it desirable for single-scenario tasks: it makes no assumptions about the structure of the domain.,1. Introduction,[0],[0]
"Recent work has suggested how to overcome this deficiency by utilizing object-based representations (Diuk et al., 2008; Usunier et al., 2016).",1. Introduction,[0],[0]
"Such a representation is motivated by the
well-acknowledged Gestalt principle, which states that the ability to perceive objects as a bounded figure in front of an unbounded background is fundamental to all perception (Weiten, 2012).",1. Introduction,[0],[0]
"Battaglia et al. (2016) and Chang et al. (2016) go further, defining hardcoded relations between objects as part of the input.
",1. Introduction,[0],[0]
"While object-based and relational representations have shown great promise alone, they stop short of modeling causality – the ability to reason about previous observations and explain away alternative causes.",1. Introduction,[0],[0]
"A causal model is essential for regression planning, in which an agent works backward from a desired future state to produce a plan (Anderson, 1990).",1. Introduction,[0],[0]
"Reasoning backward and allowing for multiple causation requires a framework like Probabilistic Graphical Models (PGMs), which can natively support explaining away (Koller & Friedman, 2009).
",1. Introduction,[0],[0]
Here we introduce Schema Networks – a generative model for object-oriented reinforcement learning and planning1.,1. Introduction,[0],[0]
Schema Networks incorporate key desiderata for the flexible and compositional transfer of learned prior knowledge to new settings.,1. Introduction,[0],[0]
1),1. Introduction,[0],[0]
Knowledge is represented with “schemas” – local cause-effect relationships involving one or more object entities; 2),1. Introduction,[0],[0]
"In a new setting, these causeeffect relationships are traversed to guide action selection; and 3) The representation deals with uncertainty, multiplecausation, and explaining away in a principled way.",1. Introduction,[0],[0]
We first describe the representational framework and learning algorithms and then demonstrate how action policies can be generated by treating planning as inference in a factor graph.,1. Introduction,[0],[0]
"We evaluate the end-to-end system on Breakout variations and compare against Asynchronous Advantage Actor-Critic (A3C) (Mnih et al., 2016) and Progressive Networks (PNs) (Rusu et al., 2016), the latter of which extends A3C explicitly to handle transfer.",1. Introduction,[0],[0]
We show that the structure of the Schema Network enables efficient and robust generalization beyond these Deep RL models.,1. Introduction,[0],[0]
The field of reinforcement learning has witnessed significant progress with the recent adaptation of deep learning methods to traditional frameworks like Q-learning.,2. Related Work,[0],[0]
"Since the introduction of the Deep Q-network (DQN) (Mnih et al., 2015), which uses experience replay to achieve human-level performance on a set of Atari 2600 games, several innovations have enabled faster convergence and better performance with less memory.",2. Related Work,[0],[0]
"The asynchronous methods introduced by Mnih et al. (2016) exploit multiple agents acting in copies of the same environment, combining their experiences into one model.",2. Related Work,[0],[0]
"As the Asyn-
1We borrow the term “schema” from Drescher (1991), whose schema mechanism inspired the early development of our model.
",2. Related Work,[0],[0]
"chronous Advantage Actor-Critic (A3C) is the best among these methods, we use it as our primary comparison.
",2. Related Work,[0],[0]
"Model-free Deep RL models like A3C are unable to substantially generalize beyond their training experience (Jaderberg et al., 2016; Rusu et al., 2016).",2. Related Work,[0],[0]
"To address this limitation, recent work has attempted to introduce more structure into neural network-based models.",2. Related Work,[0],[0]
"The Interaction Network (Battaglia et al., 2016) (IN) and the Neural Physics Engine (NPE) (Chang et al., 2016) use object-level and pairwise relational representations to learn models of intuitive physics.",2. Related Work,[0],[0]
"The primary advantage of these models is their amenability to gradient-based methods, though such techniques might be applied to Schema Networks as well.",2. Related Work,[0],[0]
"Schema Networks offer two key advantages: latent physical properties and relations need not be hardcoded, and planning can make use of backward search, since the model can distinguish different causes.",2. Related Work,[0],[0]
"Furthermore, neither INs nor NPEs have been applied in RL domains.",2. Related Work,[0],[0]
"Progress in model-based Deep RL has thus far been limited, though methods like Embed to Control (Watter et al., 2015), Value Iteration Networks (Tamar et al., 2016), and the Predictron (Silver et al., 2016b) demonstrate the promise of this direction.",2. Related Work,[0],[0]
"However, these approaches do not exploit the objectrelational representation of INs or NPEs, nor do they incorporate a backward model for regression planning.
",2. Related Work,[0],[0]
Schema Networks build upon the ideas of the ObjectOriented Markov Decision Process (OO-MDP) introduced by Diuk et al. (2008) (see also Scholz et al. (2014)).,2. Related Work,[0],[0]
"Related frameworks include relational and first-order logical MDPs (Guestrin et al., 2003a).",2. Related Work,[0],[0]
"These formalisms, which harken back to classical AI’s roots in symbolic reasoning, are designed to enable robust generalization.",2. Related Work,[0],[0]
"Recent work by Garnelo et al. (2016) on “deep symbolic reinforcement learning” makes this connection explicit, marrying firstorder logic with deep RL.",2. Related Work,[0],[0]
"This effort is similar in spirit to our work with Schema Networks, but like INs and NPEs, it lacks a mechanism to learn disentangled causes of the same effect and cannot perform regression planning.
",2. Related Work,[0],[0]
"Schema Networks transfer experience from one scenario to other similar scenarios that exhibit repeatable structure and sub-structure (Taylor & Stone, 2009).",2. Related Work,[0],[0]
Rusu et al. (2016) show how A3C can be augmented to similarly exploit common structure between tasks via Progressive Networks (PNs).,2. Related Work,[0],[0]
A PN is constructed by successively training copies of A3C on each task of interest.,2. Related Work,[0],[0]
"With each new task, the existing network is frozen, another copy of A3C is added, and lateral connections between the frozen network and the new copy are established to facilitate transfer of features learned during previous tasks.",2. Related Work,[0],[0]
One obvious limitation of PNs is that the number of network parameters must grow quadratically with the number of tasks.,2. Related Work,[0],[0]
"However, even if this growth rate was improved, the PN would
still be unable to generalize from biased training data without continuing to learn on the test environment.",2. Related Work,[0],[0]
"In contrast, Schema Networks exhibit zero-shot transfer.
",2. Related Work,[0],[0]
"Schema Networks are implemented as probabilistic graphical models (PGMs), which provide practical inference and structure learning techniques.",2. Related Work,[0],[0]
"Additionally, inference with uncertainty and explaining away are naturally supported by PGMs.",2. Related Work,[0],[0]
"We direct the readers to (Koller & Friedman, 2009) and (Jordan, 1998) for a thorough overview of PGMs.",2. Related Work,[0],[0]
"In particular, early work on factored MDPs has demonstrated how PGMs can be applied in RL and planning settings (Guestrin et al., 2003b).",2. Related Work,[0],[0]
The traditional formalism for the Reinforcement Learning problem is the Markov Decision Process (MDP).,3.1. MDPs and Notation,[0],[0]
"An MDP M is a five-tuple (S,A, T,R, γ), where S is a set of states, A is a set of actions, T (s(t+1)|s(t), a(t)) is the probability of transitioning from state s(t) ∈ S to s(t+1) ∈ S after action a(t) ∈",3.1. MDPs and Notation,[0],[0]
"A, R(r(t+1)|s(t), a(t)) is the probability of receiving reward r(t+1) ∈ R after executing action a(t) while in state s(t), and γ ∈",3.1. MDPs and Notation,[0],[0]
"[0, 1] is the rate at which future rewards are exponentially discounted.",3.1. MDPs and Notation,[0],[0]
A Schema Network is a structured generative model of an MDP.,3.2. Model Definition,[0],[0]
We first describe the architecture of the model informally.,3.2. Model Definition,[0],[0]
"An image input is parsed into a list of entities, which may be thought of as instances of objects in the sense of OO-MDPs (Diuk et al., 2008).",3.2. Model Definition,[0],[0]
All entities share the same collection of attributes.,3.2. Model Definition,[0],[0]
"We refer to a specific attribute of a specific entity as an entity-attribute, which is represented as a binary variable to indicate the presence of that attribute for an entity.",3.2. Model Definition,[0],[0]
"An entity state is an assignment of states to all attributes of the entity, and the complete model state is the set of all entity states.
",3.2. Model Definition,[0],[0]
"A grounded schema is a binary variable associated with a particular entity-attribute in the next timestep, whose value depends on the present values of a set of binary entity-attributes.",3.2. Model Definition,[0],[0]
The event that one of these present entityattributes assumes the value 1 is called a precondition of the grounded schema.,3.2. Model Definition,[0],[0]
"When all preconditions of a grounded schema are satisfied, we say that the schema is active, and it predicts the activation of its associated entity-attribute.",3.2. Model Definition,[0],[0]
"Grounded schemas may also predict rewards and may be conditioned on actions, both of which are represented as binary variables.",3.2. Model Definition,[0],[0]
"For instance, a grounded schema might define a distribution over Entity 1’s “position” attribute at time 5, conditioned on Entity 2’s “position” attribute at time 4 and the action “UP” at time 4.",3.2. Model Definition,[0],[0]
"Grounded schemas
are instantiated from ungrounded schemas, which behave like templates for grounded schemas to be instantiated at different times and in different combinations of entities.",3.2. Model Definition,[0],[0]
"For example, an ungrounded schema could predict the “position” attribute of Entity x at time t + 1 conditioned on the “position” of Entity y at time t and the action “UP” at time t; this ungrounded schema could be instantiated at time t = 4 with x = 1 and y = 2 to create the grounded schema described above.",3.2. Model Definition,[0],[0]
"In the case of attributes like “position” that are inherently continuous or categorical, several binary variables may be used to discretely approximate the distribution (see the smaller nodes in Figure 2).",3.2. Model Definition,[0],[0]
"A Schema Network is a factor graph that contains all grounded instantiations of a set of ungrounded schemas over some window of time, illustrated in Figure 2.
",3.2. Model Definition,[0],[0]
We now formalize the Schema Network factor graph.,3.2. Model Definition,[0],[0]
"For simplicity, suppose the number of entities and the number of attributes are fixed at N and M respectively.",3.2. Model Definition,[0],[0]
Let Ei refer to the ith entity and let α (t),3.2. Model Definition,[0],[0]
"i,j refer to the j
th attribute value of the ith entity at time t. We use the notation E
(t) i =",3.2. Model Definition,[0],[0]
"(α (t) i,1, ..., α (t)",3.2. Model Definition,[0],[0]
"i,M ) to refer to the state of the i th en-
tity at time t. The complete state of the MDP modeled by the network at time t is then s(t) =",3.2. Model Definition,[0],[0]
"(E(t)1 , ..., E (t) N ).",3.2. Model Definition,[0],[0]
"Actions and rewards are also represented with sets of binary variables, denoted a(t) and r(t+1) respectively.",3.2. Model Definition,[0],[0]
"A Schema Network for time t will contain the variables in s(t), a(t), s(t+1), and r(t+1).
",3.2. Model Definition,[0],[0]
"Let φk denote the variable for grounded schema k. φk is bound to a specific entity-attribute αi,j and activates it when the schema is active.",3.2. Model Definition,[0],[0]
"Multiple grounded schemas can predict the same attribute, and these predictions are combined through an OR gate.",3.2. Model Definition,[0],[0]
"For binary variables v1, ..., vn, let AND(v1, ..., vn) = ∏n i=1",3.2. Model Definition,[0],[0]
"P (vi = 1),
and OR(v1, ..., vn) = 1",3.2. Model Definition,[0],[0]
"− ∏n
i=1(1 − P (vi = 1)).",3.2. Model Definition,[0],[0]
"A grounded schema is connected to its precondition entity-attributes with an AND factor, written as φk = AND(αi1,j1 , ..., αiH ,jH , a) forH entity-attribute preconditions and an optional action a.",3.2. Model Definition,[0],[0]
"There is no restriction on how many entities or attributes from a single entity can be preconditions of a grounded schema.
",3.2. Model Definition,[0],[0]
"An ungrounded schema (or template) is represented as Φl(Ex1 , ..., ExH ) = AND(αx1,y1 , αx1,y2 ..., αxH ,yH ), where xh determines the relative entity index of the h-th precondition and yh determines which attribute variable is the precondition.",3.2. Model Definition,[0],[0]
"The ungrounded schema is a template that can be bound to multiple specific entities and locations to generate grounded schemas.
",3.2. Model Definition,[0],[0]
A subset of attributes corresponds to discrete positions.,3.2. Model Definition,[0],[0]
"These attributes are treated differently from all others, whose semantic meanings are unknown to the model.",3.2. Model Definition,[0],[0]
"When a schema predicts a movement to a new position, we must inform the previously active position attribute to be inactive unless there is another schema that predicts it to remain active.",3.2. Model Definition,[0],[0]
We introduce a self-transition variable to represent the probability that a position attribute will remain active in the next time step when no schema predicts a change from that position.,3.2. Model Definition,[0],[0]
"We compute the self-transition variable as Λi,j = AND(¬φ1, ...,¬φk, si,j) for entity i and position attribute j, where the set φ1...",3.2. Model Definition,[0],[0]
"φk includes all schemas that predict the future position of the same entity i and include si,j as a precondition.
",3.2. Model Definition,[0],[0]
"With these terms defined, we may now compute the transition function, which can be factorized as T (s(t+1)|s(t), a(t))",3.2. Model Definition,[0],[0]
= ∏N i=1,3.2. Model Definition,[0],[0]
∏M j=1,3.2. Model Definition,[0],[0]
"Ti,j(s (t+1)",3.2. Model Definition,[0],[0]
"i,j |s(t), a(t)).",3.2. Model Definition,[0],[0]
"An entity-attribute is active at the next time step if either a schema predicts it to be active or if its self-transition variable is active: Ti,j(s (t+1)",3.2. Model Definition,[0],[0]
"i,j |s(t))",3.2. Model Definition,[0],[0]
"= OR(φk1 , ..., φkQ ,Λi,j), where k1...kQ are the indices of all grounded schemas that predict si,j .",3.2. Model Definition,[0],[0]
In practice we assume that a vision system is responsible for detecting and tracking entities in an image.,3.3. Construction of Entities and Attributes,[0],[0]
It is therefore largely up to the vision system to determine what constitutes an entity.,3.3. Construction of Entities and Attributes,[0],[0]
"Essentially any trackable image feature could be an entity, which most typically includes objects, their boundaries, and their surfaces.",3.3. Construction of Entities and Attributes,[0],[0]
"Recent work has demonstrated one possible method for unsupervised entity construction using autoencoders (Garnelo et al., 2016).",3.3. Construction of Entities and Attributes,[0],[0]
"Depending on the task, Schema Networks could learn to reason flexibly at different levels of representation.",3.3. Construction of Entities and Attributes,[0],[0]
"For example, using entities from surfaces might be most relevant for predicting collisions, while using one entity per object might be most relevant for predicting whether it can be controlled by an action.",3.3. Construction of Entities and Attributes,[0],[0]
"The experiments in this paper utilize surface entities, described further in Section 5.
",3.3. Construction of Entities and Attributes,[0],[0]
"Similarly, entity attributes can be provided by the vision system, and these attributes typically include: color/appearance, surface/edge orientation, object category, or part-of an object category (e.g. front-left tire).",3.3. Construction of Entities and Attributes,[0],[0]
"For simplicity we here restrict the entities to have fully observable attributes, but in general they could have latent attributes such as “bounciness” or “magnetism.”",3.3. Construction of Entities and Attributes,[0],[0]
"Schema Networks are closely related to Object-Oriented MDPs (OO-MDPs) (Diuk et al., 2008) and Relational MDPs (R-MDPs) (Guestrin et al., 2003a).",3.4. Connections to Existing Models,[0],[0]
"However, neither OO-MDPs nor R-MDPs define a transition function with an explicit OR of possible causes, and traditionally transition functions have not been learned in these models.",3.4. Connections to Existing Models,[0],[0]
"In contrast, Schema Networks provide an explicit OR to reason about multiple causation, which enables regression planning.",3.4. Connections to Existing Models,[0],[0]
"Additionally, the structure of Schema Networks is amenable to efficient learning.
",3.4. Connections to Existing Models,[0],[0]
"Schema Networks are also related to the recently proposed Interaction Network (IN) (Battaglia et al., 2016) and Neural Physics Engine (NPE) (Chang et al., 2016).",3.4. Connections to Existing Models,[0],[0]
"At a high level, INs, NPEs, and Schema Networks are much alike – objects are to entities as relations are to schemas.",3.4. Connections to Existing Models,[0],[0]
"However, neither INs nor NPEs are generative and hence do not support regression planning from a goal through causal chains.",3.4. Connections to Existing Models,[0],[0]
"Because Schema Networks are generative models, they support more flexible inference and search strategies for planning.",3.4. Connections to Existing Models,[0],[0]
"Additionally, the learned structures in Schema Networks are amenable to human interpretation, explicitly factorizing different causes, making prediction errors easier to relate to the learned model parameters.",3.4. Connections to Existing Models,[0],[0]
"In this section we describe how to train Schema Networks (i.e., learn its structure) from interactions with an environment, as well as how they can be used to perform planning.",4. Learning and Planning in Schema Networks,[0],[0]
"Planning is not only necessary at test time to maximize reward, but also can be used to improve exploration during the training procedure.",4. Learning and Planning in Schema Networks,[0],[0]
"Given a series of actions, rewards and images, we represent each possible action and reward with a binary variable, and we convert each image into a set of entity states.",4.1. Training Procedure,[0],[0]
"The number of entities is allowed to vary between adjacent frames, accounting for objects appearing or moving out of view.
",4.1. Training Procedure,[0],[0]
"Given a dataset of entity states over time, we preprocess the entity states into a representation that is more convenient for learning.",4.1. Training Procedure,[0],[0]
"For N entities observed over T timesteps, we wish to predict α(t)i,j on the basis of the attribute values of the ith entity and its spatial neighbors at time t",4.1. Training Procedure,[0],[0]
− 1 (for 1 ≤ i ≤ N and 2 ≤ t ≤ T ).,4.1. Training Procedure,[0],[0]
"The attribute values of E
(t−1) i and its neighbors can be represented as a row vector of length MR, where M is the number of attributes and",4.1. Training Procedure,[0],[0]
R,4.1. Training Procedure,[0],[0]
"− 1 is the number of neighbor positions of each entity, determined by a fixed radius.",4.1. Training Procedure,[0],[0]
"Let X ∈ {0, 1}D×D′ be the arrangement of all such vectors into a binary matrix, with D = NT and D′ = MR.",4.1. Training Procedure,[0],[0]
"Let y ∈ {0, 1}D be a binary vector such that if row r in X refers to E(t−1)i , then yr = α (t) i,j .",4.1. Training Procedure,[0],[0]
"Schemas are then learned to predict y from X using the method described in Section 4.2.
",4.1. Training Procedure,[0],[0]
"While gathering data, actions are chosen by planning using the schemas that have been learned so far.",4.1. Training Procedure,[0],[0]
This planning algorithm is described in Section 4.3.,4.1. Training Procedure,[0],[0]
"We use an ε-greedy approach to encourage exploration, taking a random action at each timestep with small probability.",4.1. Training Procedure,[0],[0]
"We found no need to perform any additional policy learning, and after convergence predictions were accurate enough to allow for successful planning.",4.1. Training Procedure,[0],[0]
"As shown in Section 5, since learning only involves understanding the dynamics of the game, transfer learning is simplified and there is no need for policy adaptation.",4.1. Training Procedure,[0],[0]
"Structure learning in graphical models is a well studied topic in machine learning (Koller & Friedman, 2009; Jordan, 1998).",4.2. Schema Learning,[0],[0]
"To learn the structure of the Schema Network, we cast the problem as a supervised learning problem over a discrete space of parameterizations (the schemas), and then apply a greedy algorithm that solves a sequence of LP relaxations.",4.2. Schema Learning,[0],[0]
"See Jaakkola et al. (2010) for further work on
applying LP relaxations to structure learning.
",4.2. Schema Learning,[0],[0]
"WithX and y defined above, the learning problem is to find a mapping
y = fW",4.2. Schema Learning,[0],[0]
"(X) = XW~1
where all the involved variables are binary and operations follow Boolean logic: addition corresponds to ORing, and overlining to negation.",4.2. Schema Learning,[0],[0]
"W ∈ {0, 1}D′×L is a binary matrix, with each column representing one (ungrounded) schema for at most L schemas.",4.2. Schema Learning,[0],[0]
The elements set to 1 in each schema represent an existing connection between that schema and an input condition (see Fig. 2).,4.2. Schema Learning,[0],[0]
"The outputs of each individual schema are ORed to produce the final prediction.
",4.2. Schema Learning,[0],[0]
We would like to minimize the prediction error of Schema Networks while keeping them as simple as possible.,4.2. Schema Learning,[0],[0]
"A suitable objective function is
min W∈{0,1}D′×L
1 D |y − fW (X)|1 + C|W |1, (1)
where the first term computes the prediction error, the second term estimates the complexity and parameter C controls the trade-off between both.",4.2. Schema Learning,[0],[0]
"This is an NP-hard problem for which we cannot hope to find an exact solution, except for very small environments.
",4.2. Schema Learning,[0],[0]
We consider a greedy solution in which linear programming (LP) relaxations are used to find each new schema.,4.2. Schema Learning,[0],[0]
"Starting from the empty set, we greedily add schemas (columns to W ) that have perfect precision and increase recall for the prediction of y (See Algorithm 1 in the Supplementary).",4.2. Schema Learning,[0],[0]
"In each successive iteration, only the input-output pairs for which the current schema network is predicting an output of zero are passed.",4.2. Schema Learning,[0],[0]
"This procedure monotonically decreases the prediction error of the overall schema network, while increasing its complexity.",4.2. Schema Learning,[0],[0]
The process stops when we hit some predefined complexity limit.,4.2. Schema Learning,[0],[0]
"In our implementation, the greedy schema selection produces very sparse schemas, and we simply set a limit to the number of schemas to add.",4.2. Schema Learning,[0],[0]
"For this algorithm to work, no contradictions can exist in the input data (such as the same input appearing twice with different labels).",4.2. Schema Learning,[0],[0]
"Such contradictions might appear in stochastic environments and would not be artifacts in real environments, so we preprocess the input data to remove them.",4.2. Schema Learning,[0],[0]
The full Schema Network graph (Fig. 2) provides a probabilistic model for the set of rewards that will be achieved by a sequence of actions.,4.3. Planning as Probabilistic Inference,[0],[0]
"Finding the sequence of actions that will result in a given set of rewards becomes then a MAP
inference problem.",4.3. Planning as Probabilistic Inference,[0],[0]
"This problem can be addressed approximately using max-product belief propagation (MPBP) (Attias, 2003).",4.3. Planning as Probabilistic Inference,[0],[0]
Another option is variational inference.,4.3. Planning as Probabilistic Inference,[0],[0]
Cheng et al. (2013) use variational inference for planning but resort to MPBP to optimize the variational free energy functional.,4.3. Planning as Probabilistic Inference,[0],[0]
"We will follow the first approach.
",4.3. Planning as Probabilistic Inference,[0],[0]
"Without loss of generality, we will consider the present time step to be t = 0.",4.3. Planning as Probabilistic Inference,[0],[0]
"The state, action and reward variables for t ≤ 0 are observed, and we will consider inference over the unobserved variables in a look-ahead window of size2 T , {s(t), a(t), r(t)}T−1t=0 .",4.3. Planning as Probabilistic Inference,[0],[0]
"Since the Schema Network is built exclusively of compatibility factors that can take values 0 or 1, any variable assignment is either impossible or equally probable under the joint distribution of the graph.",4.3. Planning as Probabilistic Inference,[0],[0]
"Thus, if we want to know if there exists any global assignment that activates a binary variable (say, variable r(t)(+) signaling positive reward at some future time t > 0), we should look at the max-marginal p̃(r(t)(+) = 1).",4.3. Planning as Probabilistic Inference,[0],[0]
"It will be 0 if no global assignment compatible with both the SN and existing observations can lead to activate the reward, or 1 if it is feasible.",4.3. Planning as Probabilistic Inference,[0],[0]
"Similarly, we will be interested in the max-marginal p̃(r
(t) (−) = 0), i.e., whether it is feasible to find a configura-
tion that avoids a negative reward.
",4.3. Planning as Probabilistic Inference,[0],[0]
"At a high-level, planning proceeds as follows: Identify feasible desirable states (activating positive rewards and deactivating negative rewards), clamp their value to our desires by adding a unary potential to the factor graph, and then find the MAP configuration of the resulting graph.",4.3. Planning as Probabilistic Inference,[0],[0]
The MAP configuration contains the values of the action variables that are required to reach our goal of activating/deactivating a variable.,4.3. Planning as Probabilistic Inference,[0],[0]
We can also look at S to see how the model “imagines” the evolution of the entities until they reach their goal state.,4.3. Planning as Probabilistic Inference,[0],[0]
Then we perform the actions found by the planner and repeat.,4.3. Planning as Probabilistic Inference,[0],[0]
"We now explain each of these stages in more detail.
",4.3. Planning as Probabilistic Inference,[0],[0]
Potential feasibility analysis First we run a feasibility analysis.,4.3. Planning as Probabilistic Inference,[0],[0]
"To this end, a forward pass MPBP from time 0 to time T is performed.",4.3. Planning as Probabilistic Inference,[0],[0]
This provides a (coarse) approximation to the desired max-marginals for every variable.,4.3. Planning as Probabilistic Inference,[0],[0]
"Because the SN graph is loopy, MPBP is not exact and the forward pass can be too optimistic, announcing the feasibility of states that are unfeasible3.",4.3. Planning as Probabilistic Inference,[0],[0]
"Actual feasibility will be verified later, at the backtracking stage.
",4.3. Planning as Probabilistic Inference,[0],[0]
"2In contrast with MDPs, the reward is discounted with a rolling square window instead of an exponentially weighted one.
",4.3. Planning as Probabilistic Inference,[0],[0]
"3To illustrate the problem, consider the case in which it is feasible for an entity to move at time t to position A or position B (but obviously not both) and then some reward is conditioned on that type of entity being in both positions: A single forward pass will not handle the entanglement properly and will incorrectly report that such reward is also feasible.
",4.3. Planning as Probabilistic Inference,[0],[0]
"Choosing a positive reward goal state We will choose the potentially feasible positive reward that happens soonest within our explored window, clamp its state to 1, and backtrack (see below) to find the set of actions that lead to it.",4.3. Planning as Probabilistic Inference,[0],[0]
"If backtracking fails, we will repeat for the remaining potentially feasible positive rewards.
",4.3. Planning as Probabilistic Inference,[0],[0]
"Avoiding negative rewards Keeping the selected positive reward variable clamped to 1 (if it was found in the previous step), we now repeat the same procedure on the negative rewards.",4.3. Planning as Probabilistic Inference,[0],[0]
"Among the negative rewards that have been found as potentially feasible to turn off, we clamp to zero as many negative rewards as we can find a jointly satisfying backtrack.",4.3. Planning as Probabilistic Inference,[0],[0]
"If no positive reward was feasible, we backtrack from the earliest predicted negative reward.
",4.3. Planning as Probabilistic Inference,[0],[0]
"Backtracking This step is akin to Viterbi backtracking, a message passing backward pass that finds a satisfying configuration.",4.3. Planning as Probabilistic Inference,[0],[0]
"Unlike the HMM for which the Viterbi algorithm was designed, our model is loopy, so a standard backward pass is not enough to find a satisfying configuration (although can help to find good candidates).",4.3. Planning as Probabilistic Inference,[0],[0]
We combine the standard backward pass with a depth-first search algorithm to find a satisfying configuration.,4.3. Planning as Probabilistic Inference,[0],[0]
"We compared the performance of Schema Networks, A3C, and PNs (Progressive Networks) on several variations of the game Breakout.",5. Experiments,[0],[0]
"The chosen variations all share similar dynamics, but the layouts change, requiring different policies to achieve high scores.",5. Experiments,[0],[0]
A diverse set of concepts must be learned to correctly predict object movements and rewards.,5. Experiments,[0],[0]
"For example, when predicting why rewards occur, the model must disentangle possible causes to discover that reward depends on the color of a brick but is independent of the ball’s velocity and position where it was hit.",5. Experiments,[0],[0]
"While these causal relationships are straightforward for humans to recover, we have yet to see any existing approach for learning a generative model that can recover all of these dynamics without supervision and transfer them effectively.
",5. Experiments,[0],[0]
"Schema Networks rely on an input of entity states instead of raw images, and we provided the same information to A3C and PNs by augmenting the three color channels of the image with 34 additional channels.",5. Experiments,[0],[0]
"Four of these channels indicated the shape to which each pixel belongs, including shapes for bricks, balls, and walls.",5. Experiments,[0],[0]
"Another 30 channels indicated the positions of parts of the paddle, where each part consisted of a single pixel.",5. Experiments,[0],[0]
"To reduce training time, we did not provide A3C and PN with part channels for objects other than the paddle, since these are not required to learn the dynamics or predict scores.",5. Experiments,[0],[0]
"Removing irrelevant inputs could only give A3C and PN an advantage, since
the input to Schema Networks did not treat any object differently.",5. Experiments,[0],[0]
"Schema Networks were provided separate entities for each part (pixel) of each object, and each entity contained 53 attributes corresponding to the available part labels (21 for bricks, 30 for the paddle, 1 for walls, and 1 for the ball).",5. Experiments,[0],[0]
Only one of these part attributes was active per entity.,5. Experiments,[0],[0]
"Schema Networks had to learn that some attributes, like parts of bricks, were irrelevant for prediction.",5. Experiments,[0],[0]
"This experiment examines how effectively Schema Networks and PNs are able to learn a new Breakout variation after pretraining, which examines how well the two models can transfer existing knowledge to a new task.",5.1. Transfer Learning,[0],[0]
Fig. 3a shows the learning rates during 100k frames of training on Mini Breakout.,5.1. Transfer Learning,[0],[0]
"In a second experiment, we pretrained on Large Breakout for 100k frames and continued training on the Middle Wall variation, shown in Fig.",5.1. Transfer Learning,[0],[0]
1b.,5.1. Transfer Learning,[0],[0]
Fig.,5.1. Transfer Learning,[0],[0]
"3b shows that PNs require significant time to learn in this new environment, while Schema Networks do not learn anything new because the dynamics are the same.",5.1. Transfer Learning,[0],[0]
Many Breakout variations can be constructed that all involve the same dynamics.,5.2. Zero-Shot Generalization,[0],[0]
"If a model correctly learns the dynamics from one variation, in theory the others could be played perfectly by planning using the learned model.
",5.2. Zero-Shot Generalization,[0],[0]
"Rather than comparing transfer with additional training using PNs, in these variations we can compare zero-shot generalization by training A3C only on Standard Breakout.",5.2. Zero-Shot Generalization,[0],[0]
Fig.,5.2. Zero-Shot Generalization,[0],[0]
"1b-e shows some of these variations with the following modifications from the training environment:
• Offset Paddle (Fig.",5.2. Zero-Shot Generalization,[0],[0]
"1d): The paddle is shifted upward by a few pixels.
",5.2. Zero-Shot Generalization,[0],[0]
• Middle Wall (Fig. 1b):,5.2. Zero-Shot Generalization,[0],[0]
"A wall is placed in the middle of the screen, requiring the agent to aim around it to hit the bricks.
",5.2. Zero-Shot Generalization,[0],[0]
• Random Target (Fig. 1e):,5.2. Zero-Shot Generalization,[0],[0]
"A group of bricks is destoyed when the ball hits any of them and then reappears in a new random position, requiring the agent to delibarately aim at the group.
",5.2. Zero-Shot Generalization,[0],[0]
"• Juggling (Fig. 1f, enlarged from actual environment to see the balls): Without any bricks, three balls are launched in such a way that a perfect policy could juggle them without dropping any.
",5.2. Zero-Shot Generalization,[0],[0]
Table 1 shows the average scores per episode in each Breakout variation.,5.2. Zero-Shot Generalization,[0],[0]
These results show that A3C has failed to recognize the common dynamics and adapt its policy accordingly.,5.2. Zero-Shot Generalization,[0],[0]
"This comes as no surprise, as the policy it has learned for Standard Breakout is no longer applicable in these variations.",5.2. Zero-Shot Generalization,[0],[0]
"Simply adding an offset to the paddle is
sufficient to confuse A3C, which has not learned the causal nature of controlling the paddle with actions and controlling the ball with the paddle.",5.2. Zero-Shot Generalization,[0],[0]
"The Middle Wall and Random Target variations illustrate that Schema Networks are aiming to deliberately cause positive rewards from ball-brick collisions, while A3C struggles to adapt its policy accordingly.",5.2. Zero-Shot Generalization,[0],[0]
"The Juggling variation is particularly challenging, since it is not clear which ball to respond to unless the model understands that the lowest downward-moving ball is the most imminent cause of a negative reward.",5.2. Zero-Shot Generalization,[0],[0]
"By learning and transferring the correct causal dynamics, Schema Networks outperform A3C in all variations.",5.2. Zero-Shot Generalization,[0],[0]
"To better evaluate whether these models are truly learning the causes of rewards, we designed one more zero-shot generalization experiment.",5.3. Testing for Learned Causes,[0],[0]
We trained both Schema Networks and A3C on a Mini Breakout variation in which the color of a brick determines whether a positive or negative reward is received when it is destroyed.,5.3. Testing for Learned Causes,[0],[0]
"Six colors of bricks provide +1 reward, and two colors provide -1 reward.",5.3. Testing for Learned Causes,[0],[0]
Negative bricks occurred in random positions 33% of the time during training.,5.3. Testing for Learned Causes,[0],[0]
"Then during testing, the bricks were arranged into two halves, with all positive colored bricks on one half and negative colored bricks on the other (see Fig. 1c).",5.3. Testing for Learned Causes,[0],[0]
"If the causes of rewards have been correctly learned, the agent should prefer to aim for the positive half whenever possible.",5.3. Testing for Learned Causes,[0],[0]
"As Table 1 shows, Schema Networks have correctly learned
from random arrangements which brick colors cause which rewards, preferring to aim for the positive half during testing, while A3C demonstrates no preference for one half or the other, achieving an average score near zero.",5.3. Testing for Learned Causes,[0],[0]
In this work we have demonstrated the promise of Schema Networks with strong performance on a suite of Breakout variations.,6. Discussion and Conclusion,[0],[0]
"Instead of learning policies to maximize rewards, the learning objective for Schema Networks is designed to understand causality within these environments.",6. Discussion and Conclusion,[0],[0]
"The fact that Schema Networks are able to achieve rewards more efficiently than state-of-the-art model-free methods like A3C is all the more notable, since high scores are a byproduct of learning an accurate model of the game.
",6. Discussion and Conclusion,[0],[0]
The success of Schema Networks is derived in part from the entity-based representation of state.,6. Discussion and Conclusion,[0],[0]
Our results suggest that providing Deep RL models like A3C with such a representation as input can improve both training efficiency and generalization.,6. Discussion and Conclusion,[0],[0]
"This finding corroborates recent attempts (Usunier et al., 2016; Garnelo et al., 2016; Chang et al., 2016; Battaglia et al., 2016) to incorporate object and relational structure into neural network-based models.
",6. Discussion and Conclusion,[0],[0]
"The environments considered in this work are conceptually diverse but also simplified in a number of ways with respect to the real world: states, actions, and rewards are all discretized as binary random variables; the dynamics of the environments are deterministic; and there is no uncertainty in the observed entity states.",6. Discussion and Conclusion,[0],[0]
"In future work we plan to address each of these limitations, adapting Schema Networks to continuous, stochastic domains.
",6. Discussion and Conclusion,[0],[0]
Schema Networks have shown promise toward multi-task transfer where Deep RL struggles.,6. Discussion and Conclusion,[0],[0]
"This transfer is enabled by explicit causal structures, which in turn allow for planning in novel tasks.",6. Discussion and Conclusion,[0],[0]
"As progress in RL and planning continues, robust generalization from limited experience will be vital for future intelligent systems.",6. Discussion and Conclusion,[0],[0]
Special thanks to Eric Purdy and Ramki Gummadi for useful insights and discussions during the preparation of this work.,Acknowledgements,[0],[0]
The recent adaptation of deep neural networkbased methods to reinforcement learning and planning domains has yielded remarkable progress on individual tasks.,abstractText,[0],[0]
"Nonetheless, progress on task-to-task transfer remains limited.",abstractText,[0],[0]
"In pursuit of efficient and robust generalization, we introduce the Schema Network, an objectoriented generative physics simulator capable of disentangling multiple causes of events and reasoning backward through causes to achieve goals.",abstractText,[0],[0]
The richly structured architecture of the Schema Network can learn the dynamics of an environment directly from data.,abstractText,[0],[0]
"We compare Schema Networks with Asynchronous Advantage Actor-Critic and Progressive Networks on a suite of Breakout variations, reporting results on training efficiency and zero-shot generalization, consistently demonstrating faster, more robust learning and better transfer.",abstractText,[0],[0]
We argue that generalizing from limited data and learning causal relationships are essential abilities on the path toward generally intelligent systems.,abstractText,[0],[0]
Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 444–449 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
444",text,[0],[0]
Discourse relation depicts how the text spans in a text relate to each other.,1 Introduction,[0],[0]
"These relations can be categorized into different types according to semantics, logic or writer’s intention.",1 Introduction,[0],[0]
"Annotations of such discourse relations can benefit many down-stream NLP tasks including machine translation (Guzmán et al., 2014; Joty et al., 2014) and automatic summarization (Gerani et al., 2014).
",1 Introduction,[0],[0]
"Several discourse corpora have been proposed in previous work, grounded with various discourse theories.",1 Introduction,[0],[0]
"Among them Rhetorical Structure Theory TreeBank (RST-DT) (Carlson et al., 2003) and Penn Discourse TreeBank (PDTB) (Prasad et al., 2007) are the most widely-used resources.",1 Introduction,[0],[0]
PDTB focuses on shallow discourse relations between two arguments and ignores the whole organization.,1 Introduction,[0],[0]
"RST-DT based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) represents a text into a hierarchical discourse tree.",1 Introduction,[0],[0]
"Though
RST-DT provides more comprehensive discourse information, its limitations including the introduction of intermediate nodes and absence of nonprojective structures bring the annotation and parsing complexity.
",1 Introduction,[0],[0]
Li et al. (2014) and Yoshida et al. (2014) both realized the problems of RST-DT and introduced dependency structures into discourse representation.,1 Introduction,[0],[0]
Stede et al. (2016) adopted dependency tree format to compare RST structure and Segmented Discourse Representation Theory(SDRT),1 Introduction,[0],[0]
"(Lascarides and Asher, 2008) structure for a corpus of short texts.",1 Introduction,[0],[0]
"Their discourse dependency framework is adapted from syntactic dependency structure (Hudson, 1984; Böhmová et al., 2003), with words replaced by elementary discourse units (EDUs).",1 Introduction,[0],[0]
"Binary discourse relations are represented from dominant EDU (called “head”) to subordinate EDU (called “dependent”), which makes non-projective structure possible.",1 Introduction,[0],[0]
"However, Li et al. (2014) and Yoshida et al. (2014) mainly focused on the definition of discourse dependency structure and directly transformed constituency trees in RST-DT into dependency trees.",1 Introduction,[0],[0]
"On the one hand, they only simply treated the transformation ambiguity, while constituency structures and dependency structures did not correspond one-toone.",1 Introduction,[0],[0]
"On the other hand, the transformed corpus still did not contain non-projective dependency trees, though “crossed dependencies” actually exist in the real flexible discourse structures (Wolf and Gibson, 2005).",1 Introduction,[0],[0]
"In such case, it is essential to construct a discourse dependency treebank from scratch instead of through automatically converting from the constituency structures.
",1 Introduction,[0],[0]
"In this paper, we construct the discourse dependency corpus SciDTB1.",1 Introduction,[0],[0]
"based on scientific abstracts, with the reference to the discourse de-
1The treebank is available at https://github.com/PKUTANGENT/SciDTB
pendency representation in Li et al. (2014).",1 Introduction,[0],[0]
We choose scientific abstracts as the corpus for two reasons.,1 Introduction,[0],[0]
"First, we observe that when long news articles in RST-DT have several paragraphs, the discourse relations between paragraphs are very loose and their annotations are not so meaningful.",1 Introduction,[0],[0]
"Thus, short texts with obvious logics become our preference.",1 Introduction,[0],[0]
"Here, we choose scientific abstracts from ACL Anthology2 which are usually composed of one passage and have strong logics.",1 Introduction,[0],[0]
"Second, we prefer to conduct domain-specific discourse annotation.",1 Introduction,[0],[0]
"RST-DT and PDTB are both constructed on news articles, which are unspecific in domain coverage.",1 Introduction,[0],[0]
We choose the scientific domain that is more specific and can benefit further academic applications such as automatic summarization and translation.,1 Introduction,[0],[0]
"Furthermore, our treebank SciDTB can be made as a benchmark for evaluating discourse parsers.",1 Introduction,[0],[0]
Three baselines are provided as fundamental work.,1 Introduction,[0],[0]
"In this section, we describe two key aspects of our annotation framework, including elementary discourse units (EDU) and discourse relations.",2 Annotation Framework,[0],[0]
"We first need to divide a passage into nonoverlapping text spans, which are named elementary discourse units (EDUs).",2.1 Elementary Discourse Units,[0],[0]
"We follow the criterion of Polanyi (1988) and Irmer (2011) which treats clauses as EDUs.
",2.1 Elementary Discourse Units,[0],[0]
"However, since a discourse unit is a semantic concept but a clause is defined syntactically, in some cases segmentation by clauses is still not the most proper strategy.",2.1 Elementary Discourse Units,[0],[0]
"In practice, we refer to the guidelines defined by (Carlson and Marcu, 2001).",2.1 Elementary Discourse Units,[0],[0]
"For example, subjective clauses, objective clauses of non-attributive verbs and verb complement clauses are not segmented.",2.1 Elementary Discourse Units,[0],[0]
Nominal postmodifiers with predicates are treated as EDUs.,2.1 Elementary Discourse Units,[0],[0]
Strong discourse cues such as “despite” and “because of ” starts a new EDU,2.1 Elementary Discourse Units,[0],[0]
no matter they are followed by a clause or a phrase.,2.1 Elementary Discourse Units,[0],[0]
"We give an EDU segmentation example as follows.
1.",2.1 Elementary Discourse Units,[0],[0]
"[Despite bilingual embeddings success,][the contextual information][which is of critical
2http://www.aclweb.org/anthology/. SciDTB follows the same CC BY-NC-SA 3.0 and CC BY 4.0 licenses as ACL Anthology.
importance to translation quality,][was ignored in previous work.",2.1 Elementary Discourse Units,[0],[0]
"]
It is noted, as in Example 1, there are EDUs which are broken into two parts (in bold) by relative clauses or nominal postmodifiers.",2.1 Elementary Discourse Units,[0],[0]
"Like RST, we connect the two parts by a pseudo-relation type Same-unit to represent their integrity.",2.1 Elementary Discourse Units,[0],[0]
"A discourse relation is defined as tri-tuple (h, d, r), where h means the head EDU, d is the dependent EDU, and r defines the relation category between h and d. For a discourse relation, head EDU is defined as the unit with essential information and dependent EDU with supportive content.",2.2 Discourse Relations,[0],[0]
"Here, we follow Carlson and Marcu (2001) to adopt deletion test in the determination of head and dependent.",2.2 Discourse Relations,[0],[0]
"If one unit in a binary relation pair is deleted but the whole meaning can still be almost understood from the other unit, the deleted unit is treated as dependent and the other one as the head.
",2.2 Discourse Relations,[0],[0]
"For the relation categories, we mainly refer to the work of (Carlson and Marcu, 2001) and (Bunt and Prasad, 2016).",2.2 Discourse Relations,[0],[0]
"Table 1 presents the discourse relation set of SciDTB, which are not explained detailedly one by one due to space limitation.",2.2 Discourse Relations,[0],[0]
"Through investigation of scientific abstracts, we define 17 coarse-grained relation types and 26 fine-grained relations for SciDTB.
",2.2 Discourse Relations,[0],[0]
It is noted that we make some modifications to adapt to the scientific domain.,2.2 Discourse Relations,[0],[0]
"For example, In SciDTB, Background relation is divided into three
subtypes: Related, Goal and General, because the background description in scientific abstracts usually has more different intents.",2.2 Discourse Relations,[0],[0]
"Meanwhile, for attribution relation we treat the attributive content rather than act as head, which is contrary to that defined in (Carlson and Marcu, 2001), because scientific facts or research arguments mentioned in attributive content are more important in abstracts.",2.2 Discourse Relations,[0],[0]
"For some symmetric discourse relations such as joint and comparison, where two connected EDUs are equally important and have interchangeable semantic roles, we follow the strategy as (Li et al., 2014) and treat the preceding EDU as the head.
",2.2 Discourse Relations,[0],[0]
Another issue on coherence relations is about polynary relations which involve more than two EDUs.,2.2 Discourse Relations,[0],[0]
The first scenario is that one EDU dominates a set of posterior EDUs as its member.,2.2 Discourse Relations,[0],[0]
"In this case, we annotate binary relations from head EDU to each member EDU with the same relation.",2.2 Discourse Relations,[0],[0]
The second scenario is that several EDUs are of equal importance in a polynary relation.,2.2 Discourse Relations,[0],[0]
"For this case, we link each former EDU to its neighboring EDU with the same relation, forming a relation chain similar to “right-heavy” binarization transformation in (Morey et al., 2017).
",2.2 Discourse Relations,[0],[0]
"By assuring that each EDU has one and only one head EDU, we can obtain a dependency tree for each scientific abstract.",2.2 Discourse Relations,[0],[0]
An example of dependency annotation is shown in Figure 1.,2.2 Discourse Relations,[0],[0]
"Following the annotation framework, we collected 798 abstracts from ACL anthology and con-
structed the SciDTB corpus.",3 Corpus Construction,[0],[0]
"The construction details are introduced as follows.
",3 Corpus Construction,[0],[0]
"Annotator Recruitment To select annotators, we put forward two requirements to ensure the annotation quality.",3 Corpus Construction,[0],[0]
"First, we required the candidates to have linguistic knowledge.",3 Corpus Construction,[0],[0]
"Second, each candidate was asked to join a test annotation of 20 abstracts, whose quality was evaluated by experts.",3 Corpus Construction,[0],[0]
"After the judgement, 5 annotators were qualified to participate in our work.
",3 Corpus Construction,[0],[0]
EDU Segmentation We performed EDU segmentation in a semi-automatic way.,3 Corpus Construction,[0],[0]
"First, we did sentence tokenization on raw texts using NLTK 3.2",3 Corpus Construction,[0],[0]
(,3 Corpus Construction,[0],[0]
"Bird and Loper, 2004).",3 Corpus Construction,[0],[0]
"Then we used SPADE (Soricut and Marcu, 2003), a pre-trained EDU segmenter relying on Charniak’s syntactic parser (Charniak, 2000), to automatically cut sentences into EDUs.",3 Corpus Construction,[0],[0]
"Then, we manually checked each segmented abstract to ensure the segmentation quality.",3 Corpus Construction,[0],[0]
"Two annotators conducted the checking task, with one proofreading the output of SPADE, and the other reviewing the proofreading.",3 Corpus Construction,[0],[0]
"The checking process was recorded for statistical analysis.
",3 Corpus Construction,[0],[0]
Tree Annotation Labeling dependency trees was the most labor-intensive work in the corpus construction.,3 Corpus Construction,[0],[0]
798 segmented abstracts were labeled by 5 annotators in 6 months.,3 Corpus Construction,[0],[0]
"506 abstracts were annotated more than twice separately by different annotators, with the purpose of analysing annotation consistency and providing human performance as an upper bound.",3 Corpus Construction,[0],[0]
The annotated trees were stored in JSON format.,3 Corpus Construction,[0],[0]
"For convenience, we
developed an online tool3 for annotating and visualising discourse dependency trees.",3 Corpus Construction,[0],[0]
"SciDTB contains 798 unique abstracts with 63% labeled more than once and 18,978 discourse relations in total.",4 Corpus Statistics,[0],[0]
"Table 2 compares the size of SciDTB with RST-DT and another PDTB-style domainspecific corpus BioDRB (Prasad et al., 2011), we can see SciDTB has a comparable size with RSTDT.",4 Corpus Statistics,[0],[0]
"Moreover, it is relatively easy for SciDTB to augment its size since the dependency structure simplifies the annotation to some extent.",4 Corpus Statistics,[0],[0]
"Compared with BioDRB, SciDTB has larger size and passage-level representations.",4 Corpus Statistics,[0],[0]
EDU Segmentation We use 214 abstracts for analysis.,4.1 Annotation Consistency,[0],[0]
"After the proofreading of the first annotator, the abstracts are composed of totally 2,772 EDUs.",4.1 Annotation Consistency,[0],[0]
"Among these EDUs, only 28 (1.01%) EDUs are disagreed and revised by the second annotator, which means a very high consensus between annotators on EDU segmentation.
",4.1 Annotation Consistency,[0],[0]
"Tree Labeling Here, we evaluate the consistency of two annotators on labeling discourse relations using 3 metrics from different aspects.",4.1 Annotation Consistency,[0],[0]
"When labeling a discourse relation, each non-root EDU must choose its head with a specific relation type.",4.1 Annotation Consistency,[0],[0]
"Thus, the annotation disagreement mainly comes from selecting head or determining relation type.",4.1 Annotation Consistency,[0],[0]
"Similar to syntactic dependency parsing, unlabeled and labeled attachment scores (UAS and
3http://123.56.88.210/demo/depannotate/
LAS) are employed to measure the labeling correspondence.",4.1 Annotation Consistency,[0],[0]
"UAS calculates the proportion of EDUs which are assigned the same head in two annotations, while LAS considers the uniformity of both head and relation label.",4.1 Annotation Consistency,[0],[0]
"Cohen’s Kappa score evaluates the agreement of labeling relation types under the premise of knowing the correct heads.
",4.1 Annotation Consistency,[0],[0]
Table 3 shows the agreement results between two annotators.,4.1 Annotation Consistency,[0],[0]
We can see that most of the LAS values between annotators exceed 0.60.,4.1 Annotation Consistency,[0],[0]
The agreement on tree structure reflected by UAS all reaches 0.75.,4.1 Annotation Consistency,[0],[0]
The Kappa values for relation types agreement keep equal to or greater than 0.7.,4.1 Annotation Consistency,[0],[0]
Non,4.2 Structural Characteristics,[0],[0]
-projection in Treebank One advantage of dependency trees is that they can represent nonprojective structures.,4.2 Structural Characteristics,[0],[0]
"In SciDTB, we annotated 39 non-projective dependency trees, which account for about 3% of the whole corpus.",4.2 Structural Characteristics,[0],[0]
"This phenomenon in our treebank is not so frequent as (Wolf and Gibson, 2005).",4.2 Structural Characteristics,[0],[0]
"We think this may be because scientific abstracts are much shorter and scientific expressions are relatively restricted.
",4.2 Structural Characteristics,[0],[0]
Dependency Distance Here we investigate the distance of two EDUs involved in a discourse relation.,4.2 Structural Characteristics,[0],[0]
The distance is defined as the number of EDUs between head and dependent.,4.2 Structural Characteristics,[0],[0]
"We present the distance distribution of all the relations in SciDTB, as shown in Table 4.",4.2 Structural Characteristics,[0],[0]
It should be noted that ROOT and Same-unit relations are omitted in this analysis.,4.2 Structural Characteristics,[0],[0]
"From Table 4, we find most relations connect near EDUs.",4.2 Structural Characteristics,[0],[0]
"Most relations (61.6%) occur between neighboring EDUs and about 75% relations occur with at most one intermediate EDU.
",4.2 Structural Characteristics,[0],[0]
"Although most dependency relations function intra-sentence, there exist long-range dependency relations in the treebank.",4.2 Structural Characteristics,[0],[0]
"On average, the distance of 8.8% relations is greater than 5.",4.2 Structural Characteristics,[0],[0]
"We summarize that the most frequent 5 fine-grained rela-
tion types of these long-distance relations belong to Evaluation, Aspect, Addition, Process-step and Goal, which tend to appear on higher level in dependency trees.",4.2 Structural Characteristics,[0],[0]
We further apply SciDTB as a benchmark for comparing and evaluating discourse dependency parsers.,5 Benchmark for Discourse Parsers,[0],[0]
"For the 798 unique abstracts in SciDTB, 154 are used for development set and 152 for test set.",5 Benchmark for Discourse Parsers,[0],[0]
The remaining 492 abstracts are used for training.,5 Benchmark for Discourse Parsers,[0],[0]
"We implement two transition-based parsers and a graph-based parser as baselines.
",5 Benchmark for Discourse Parsers,[0],[0]
Vanilla Transition-based Parser We adopt the transition-based method for dependency parsing by Nivre (2003).,5 Benchmark for Discourse Parsers,[0],[0]
"The action set of arc-standard system (Nivre et al., 2004) is employed.",5 Benchmark for Discourse Parsers,[0],[0]
We build an SVM classifier to predict most possible transition action for given configuration.,5 Benchmark for Discourse Parsers,[0],[0]
"We adopt the N-gram features, positional features, length features and dependency features for top-2 EDUs in the stack and top EDU in the buffer, which can be referred from (Li et al., 2014; Wang et al., 2017)
Two-stage Transition-based Parser We implement a two-stage transition-based dependency parser following (Wang et al., 2017).",5 Benchmark for Discourse Parsers,[0],[0]
"First, an unlabeled tree is produced by vanilla transition-based approach.",5 Benchmark for Discourse Parsers,[0],[0]
Then we train a separate SVM classifier to predict relation types on the tree in pre-order.,5 Benchmark for Discourse Parsers,[0],[0]
"For the 2nd-stage, apart from features in the 1ststage, two kinds of features are added, including depth of head and dependent in the tree and the predicted relation between the head and its head.
",5 Benchmark for Discourse Parsers,[0],[0]
"Graph-based Parser We implement a graphbased parser as in (Li et al., 2014).",5 Benchmark for Discourse Parsers,[0],[0]
"For simplicity, we use averaged perceptron rather than MIRA to train weights.",5 Benchmark for Discourse Parsers,[0],[0]
"N-gram, positional, length and dependency features between head and dependent labeled with relation type are considered.
",5 Benchmark for Discourse Parsers,[0],[0]
"Hyper-parameters During training, the hyperparameters of these models are tuned using development set.",5 Benchmark for Discourse Parsers,[0],[0]
"For vanilla transition-based parser, we take linear kernel for the SVM classifier.",5 Benchmark for Discourse Parsers,[0],[0]
The penalty parameter C is set to 1.5.,5 Benchmark for Discourse Parsers,[0],[0]
"For two-stage parser, the 1st-stage classifier follows the same setting as the vanilla parser.",5 Benchmark for Discourse Parsers,[0],[0]
"For 2nd-stage, we use the linear kernel and set C to 0.5.",5 Benchmark for Discourse Parsers,[0],[0]
The averaged perceptron in graph-based parser is trained for 10 epochs on the training set.,5 Benchmark for Discourse Parsers,[0],[0]
"Weights of features are
initialized to be 0 and trained with fixed learning rate.
",5 Benchmark for Discourse Parsers,[0],[0]
Results Table 5 shows the performance of these parsers on development and test data.,5 Benchmark for Discourse Parsers,[0],[0]
We also measure parsing accuracy with UAS and LAS.,5 Benchmark for Discourse Parsers,[0],[0]
The human agreement is presented for comparison.,5 Benchmark for Discourse Parsers,[0],[0]
"With the addition of tree structural features in relation type prediction, the two-stage dependency parser gets better performance on LAS than vanilla system on both development and test set.",5 Benchmark for Discourse Parsers,[0],[0]
"Compared with graph-based model, the two transition-based baselines achieve higher accuracy with regard to UAS and LAS.",5 Benchmark for Discourse Parsers,[0],[0]
Using more effective training strategies like MIRA may improve graph-based models.,5 Benchmark for Discourse Parsers,[0],[0]
"We can also see that human performance is still much higher than the three parsers, meaning there is large space for improvement in future work.",5 Benchmark for Discourse Parsers,[0],[0]
"In this paper, we propose to construct a discourse dependency treebank SciDTB for scientific abstracts.",6 Conclusions,[0],[0]
"It represents passages with dependency tree structure, which is simpler and more flexible for analysis.",6 Conclusions,[0],[0]
"We have presented our annotation framework, construction workflow and statistics of SciDTB, which can provide annotation experience for extending to other domains.",6 Conclusions,[0],[0]
"Moreover, this treebank can serve as an evaluating benchmark of discourse parsers.
",6 Conclusions,[0],[0]
"In the future, we will enlarge our annotation scale to cover more domains and longer passages, and explore how to use SciDTB in some downstreaming applications.",6 Conclusions,[0],[0]
We thank the anonymous reviewers for their insightful comments on this paper.,Acknowledgments,[0],[0]
We especially thank Liang Wang for developing the online annotation tool.,Acknowledgments,[0],[0]
This work was partially supported by National Natural Science Foundation of China (61572049 and 61333018).,Acknowledgments,[0],[0]
The correspondence author of this paper is Sujian Li.,Acknowledgments,[0],[0]
Annotation corpus for discourse relations benefits NLP tasks such as machine translation and question answering.,abstractText,[0],[0]
"In this paper, we present SciDTB, a domainspecific discourse treebank annotated on scientific articles.",abstractText,[0],[0]
"Different from widelyused RST-DT and PDTB, SciDTB uses dependency trees to represent discourse structure, which is flexible and simplified to some extent but do not sacrifice structural integrity.",abstractText,[0],[0]
"We discuss the labeling framework, annotation workflow and some statistics about SciDTB.",abstractText,[0],[0]
"Furthermore, our treebank is made as a benchmark for evaluating discourse dependency parsers, on which we provide several baselines as fundamental work.",abstractText,[0],[0]
SciDTB: Discourse Dependency TreeBank for Scientific Abstracts,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 390–400, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Due to the expanding rate at which articles are being published in each scientific field, it has become difficult for researchers to keep up with the developments in their respective fields.",1 Introduction,[0],[0]
Scientific summarization aims to facilitate this problem by providing readers with concise and informative representation of contributions or findings of an article.,1 Introduction,[0],[0]
"Scientific summarization is different than general summarization in three main aspects (Teufel and Moens, 2002).",1 Introduction,[0],[0]
"First, the length of scientific papers are usually much longer than general articles (e.g newswire).",1 Introduction,[0],[0]
"Second,
in scientific summarization, the goal is typically to provide a technical summary of the paper which includes important findings, contributions or impacts of a paper to the community.",1 Introduction,[0],[0]
"Finally, scientific papers follow a natural discourse.",1 Introduction,[0],[0]
"A common organization for scientific paper is the one in which the problem is first introduced and is followed by the description of hypotheses, methods, experiments, findings and finally results and implications.",1 Introduction,[0],[0]
"Scientific summarization was recently further motivated by TAC2014 biomedical summarization track1 in which they planned to investigate this problem in the domain of biomedical science.
",1 Introduction,[0],[0]
There are currently two types of approaches towards scientific summarization.,1 Introduction,[0],[0]
First is the articles’ abstracts.,1 Introduction,[0],[0]
"While abstracts provide a general overview of the paper, they cannot be considered as an accurate scientific summary by themselves.",1 Introduction,[0],[0]
"That is due to the fact that not all the contributions and impacts of the paper are included in the abstract (Elkiss et al., 2008).",1 Introduction,[0],[0]
"In addition, the stated contributions are those that the authors deem important while they might be less important to the scientific community.",1 Introduction,[0],[0]
"Moreover, contributions are stated in a general and less focused fashion.",1 Introduction,[0],[0]
"These problems motivated the other form of scientific summaries, i.e., citation based summaries.",1 Introduction,[0],[0]
"Citation based summary is a summary which is formed by utilizing a set of citations to a referenced article (Qazvinian and Radev, 2008; Qazvinian et al., 2013).",1 Introduction,[0],[0]
This set of citations has been previously indicated as a good representation of important findings and contributions of the article.,1 Introduction,[0],[0]
"Contributions stated in the citations are usually more focused than the abstract and contain additional information that is not in the abstract (Elkiss et al., 2008).
",1 Introduction,[0],[0]
"However, citations may not accurately represent 1Text Analysis Conference - http://www.nist.gov/ tac/
2014
390
the content of the referenced article as they are biased towards the viewpoint of the citing authors.",1 Introduction,[0],[0]
"Moreover, citations may address a contribution or a finding regarding the referenced article without referring to the assumptions and data under which it was obtained.
",1 Introduction,[0],[0]
"The problem of inconsistency between the degree of certainty of expressing findings between the citing article and referenced article has been also reported (De Waard and Maat, 2012).",1 Introduction,[0],[0]
"Therefore, citations by themselves lack the related “context” from the original article.",1 Introduction,[0],[0]
"We call the textual spans in the reference articles that reflect the citation, the citation-context.",1 Introduction,[0],[0]
"Figure 1 shows an example of the citation-context in the reference article (green color) for a citation in the citing article (blue color).
",1 Introduction,[0],[0]
We propose an approach to overcome the aforementioned shortcomings of existing scientific summaries.,1 Introduction,[0],[0]
"Specifically, we extract citation-context in the reference article for each citation.",1 Introduction,[0],[0]
"Then, by using the discourse facets of the citations as well as community structure of the citation-contexts, we extract candidate sentences for the summary.",1 Introduction,[0],[0]
The final summary is formed by maximizing both novelty and informativeness of the sentences in the summary.,1 Introduction,[0],[0]
We evaluate and compare our methods against several well-known summarization methods.,1 Introduction,[0],[0]
Evaluation results on the TAC2014 dataset show that our proposed methods can effectively improve over the well-known existing summarization approaches.,1 Introduction,[0],[0]
"That is, we obtained greater than 30% improvement over the highest performing baseline in terms of mean ROUGE scores.",1 Introduction,[0],[0]
"Document summarization is a relatively well studied area and various types of approaches for document summarization have been proposed in the past twenty years.
",2 Related work,[0],[0]
"Latent Semantic Analysis (LSA) has been used in text summarization first by (Gong and Liu, 2001).",2 Related work,[0],[0]
"Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010).",2 Related work,[0],[0]
"Summarization approaches based on topic modeling and Bayesian models have also been explored (Vanderwende et al., 2007; Haghighi and Vanderwende, 2009; Celikyilmaz
and Hakkani-Tur, 2010; Ritter et al., 2010; Celikyilmaz and Hakkani-Tür, 2011; Ma and Nakagawa, 2013; Li and Li, 2014).",2 Related work,[0],[0]
"In these approaches, the content/topic distribution in the final summary is estimated using a graphical probabilistic model.",2 Related work,[0],[0]
"Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012).",2 Related work,[0],[0]
Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary.,2 Related work,[0],[0]
"Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014).",2 Related work,[0],[0]
"Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency.
",2 Related work,[0],[0]
Graph based models have shown promising results for text summarization.,2 Related work,[0],[0]
"In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences.",2 Related work,[0],[0]
"Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010).",2 Related work,[0],[0]
"Maximizing the novelty and preventing
the redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010).",2 Related work,[0],[0]
Rhetorical structure of the documents have also been investigated for automatic summarization.,2 Related work,[0],[0]
"In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014).",2 Related work,[0],[0]
Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used.,2 Related work,[0],[0]
"Training the discourse parser requires large amount of training data in the RST framework.
",2 Related work,[0],[0]
"Scientific article summarization was first studied by (Teufel and Moens, 2002) in which they trained a supervised Naive Bayes classifier to select informative content for the summary.",2 Related work,[0],[0]
"Later (Elkiss et al., 2008) argue the benefits of citations to scientific work analysis.",2 Related work,[0],[0]
"(Cohan et al., 2015) use a search oriented approach for finding relevant parts of the reference paper to citations.",2 Related work,[0],[0]
"(Qazvinian and Radev, 2008; Qazvinian et al., 2013) use citations to an article to construct its summary.",2 Related work,[0],[0]
"More specifically, they perform hierarchical agglomerative clustering on citations to maximize purity and select most central sentences from each cluster for the final summary.",2 Related work,[0],[0]
"Our work is closest to (Qazvinian and Radev, 2008) with the difference that they only make use of citations.",2 Related work,[0],[0]
"While citations are useful for summarization, relying solely on them might not accurately capture the original context of the referenced paper.",2 Related work,[0],[0]
"That is, the generated summary lacks the appropriate evidence to reflect the content of the original paper, such as circumstances, data and assumptions under which certain findings were obtained.",2 Related work,[0],[0]
We address this shortcoming by leveraging the citation-context and the inherent discourse model in the scientific articles.,2 Related work,[0],[0]
"Our scientific summary generation algorithm is composed of four steps: (1) Extracting the citation-context, (2) Grouping citation-contexts, (3) Ranking the sentences within each group and (4) Selecting the sentences for final summary.",3 The summarization approach,[0],[0]
"We
assume that the citation text (the text span in the citing article that references another article) in each citing article is already known.",3 The summarization approach,[0],[0]
We describe each step in the following sub-sections.,3 The summarization approach,[0],[0]
Our proposed method generates a summary of an article with the premise that the article has a number of citations to it.,3 The summarization approach,[0],[0]
We call the article that is being referenced the “reference article”.,3 The summarization approach,[0],[0]
"We shall note that we tokenized the articles’ text to sentences by using the punkt unsupervised sentence boundary detection algorithm (Kiss and Strunk, 2006).",3 The summarization approach,[0],[0]
We modified the original sentence boundary detection algorithm to also account for biomedical abbreviations.,3 The summarization approach,[0],[0]
"For the rest of the paper, “sentence” refers to units that are output of the sentence boundary detection algorithm, whereas “text span” or in short “span” can consist of multiple sentences.",3 The summarization approach,[0],[0]
"As described in section 2, one problem with existing citation based summarization approaches is that they lack the context of the referenced paper.",3.1 Extracting the citation-context,[0],[0]
"Therefore, our goal is to leverage citationcontext in the reference article to correctly reflect the reference paper.",3.1 Extracting the citation-context,[0],[0]
"To find citation-contexts, we consider each citation as an n-gram vector and use vector space model for locating the relevant text spans in the reference article.",3.1 Extracting the citation-context,[0],[0]
"More specifically, given a citation c, we return the ranked list of text spans r1, r2, ..., rn which have the highest similarity to c. We call the retrieved text spans reference spans.",3.1 Extracting the citation-context,[0],[0]
These reference spans are essentially forming the context for each citation.,3.1 Extracting the citation-context,[0],[0]
The similarity function is the cosine similarity between the pivoted normalized vectors.,3.1 Extracting the citation-context,[0],[0]
"We evaluated four different approaches for forming the citation vector.
1.",3.1 Extracting the citation-context,[0],[0]
"All terms in citation except for stopwords, numeric values and citation markers i.e., name of authors or numbered citations.",3.1 Extracting the citation-context,[0],[0]
"In figure 1 an example of citation marker is shown.
2.",3.1 Extracting the citation-context,[0],[0]
Terms with high inverted document frequency (idf).,3.1 Extracting the citation-context,[0],[0]
"Idf values of terms have shown to be a good estimate of term informativeness.
3.",3.1 Extracting the citation-context,[0],[0]
"Concepts that are represented through noun phrases in the citation, for example in the following: “ ... typically achieved by introducing DNA tumor virus oncoproteins such a ... ” which is part of a citation, the phrase “DNA tumor virus oncoproteins” is a noun phrase.
4.",3.1 Extracting the citation-context,[0],[0]
Biomedical concepts and noun phrases expanded by related biomedical concepts: This formation is specific to the biomedical domain.,3.1 Extracting the citation-context,[0],[0]
It selects biomedical concepts and noun phrases in the citation and uses related biomedical terminology to expand the citation vector.,3.1 Extracting the citation-context,[0],[0]
We used Metamap1 for extracting biomedical concepts from the citation text (which is a tool for mapping free form text to UMLS2 concepts).,3.1 Extracting the citation-context,[0],[0]
"For expanding the citation vector using the related biomedical terminology, we used SNOMED CT3 ontology by which we added synonyms of the concepts in the citation text to the citation vector.",3.1 Extracting the citation-context,[0],[0]
"After identifying the context for each citation, we use them to form the summary.",3.2 Grouping the citation-contexts,[0],[0]
"To capture various important aspects of the reference article, we form groups of citation-contexts that are about the same topic.",3.2 Grouping the citation-contexts,[0],[0]
"We use the following two approaches for forming these groups:
Community detection - We want to find diverse key aspects of the reference article.",3.2 Grouping the citation-contexts,[0],[0]
We form the graph of extracted reference spans in which nodes are sentences and edges are similarity between sentences.,3.2 Grouping the citation-contexts,[0],[0]
"As for the similarity function, we use cosine similarity between tf-idf vectors of the sentences.",3.2 Grouping the citation-contexts,[0],[0]
"Similar to (Qazvinian and Radev, 2008), we want to find subgraphs or communities whose intra-connectivity is high but inter-connectivity is low.",3.2 Grouping the citation-contexts,[0],[0]
"Such quality is captured by the modularity measure of the graph (Newman, 2006; Newman, 2012).",3.2 Grouping the citation-contexts,[0],[0]
"Graph modularity quantifies the denseness of the subgraphs in comparison with denseness of the graph of randomly distributed edges and is defined as follows:
Q = 1
2m ∑ vw",3.2 Grouping the citation-contexts,[0],[0]
[,3.2 Grouping the citation-contexts,[0],[0]
"Avw − kv × kw2m ] δ(cv, cw)
Where Avw is the weigh of the edge (v, w); kv is the degree of the vertex v; cv is the community of vertex v; δ is the Kronecker’s delta function and m = ∑ vw Avw is the normalization factor.
",3.2 Grouping the citation-contexts,[0],[0]
"While the general problem of precise partitioning of the graph into highly dense communities
1http://metamap.nlm.nih.gov/ 2Unified Medical Language System - a compendium of controlled vocabularies in the biomedical sciences, http:// www.nlm.nih.gov/research/umls
3http://www.nlm.nih.gov/research/umls/Snomed/ snomed main.html
that optimizes the modularity is computationally prohibitive (Brandes et al., 2008), many heuristic algorithms have been proposed with reasonable results.",3.2 Grouping the citation-contexts,[0],[0]
"To extract communities from the graph of reference spans, we use the algorithm proposed by (Blondel et al., 2008) which is a simple yet accurate and efficient community detection algorithm.",3.2 Grouping the citation-contexts,[0],[0]
"Specifically, communities are built in a hierarchical fashion.",3.2 Grouping the citation-contexts,[0],[0]
"At first, each node belongs to a separate community.",3.2 Grouping the citation-contexts,[0],[0]
Then nodes are assigned to new communities if there is a positive gain in modularity.,3.2 Grouping the citation-contexts,[0],[0]
"This process is applied iteratively until no further improvement in modularity is possible.
",3.2 Grouping the citation-contexts,[0],[0]
Discourse model - A natural discourse model is followed in each scientific article.,3.2 Grouping the citation-contexts,[0],[0]
"In this method, instead of finding communities to capture different important aspects of the paper, we try to select reference spans based on the discourse model of the paper.",3.2 Grouping the citation-contexts,[0],[0]
"The discourse model is according to the following facets: “hypothesis”, “method”, “results”, “implication”, “discussion” and “dataset-used”.",3.2 Grouping the citation-contexts,[0],[0]
The goal is to ideally include reference spans from each of these discourse facets of the article in the summary to correctly capture all aspects of the article.,3.2 Grouping the citation-contexts,[0],[0]
We use a one-vs-rest SVM supervised model with linear kernel to classify the reference spans to their respective discourse facets.,3.2 Grouping the citation-contexts,[0],[0]
Training was done on both the citation and reference spans since empirical evaluation showed marginal improvements upon including the reference spans in addition to the citation itself.,3.2 Grouping the citation-contexts,[0],[0]
We use unigram and verb features with tfidf weighting to train the classifier.,3.2 Grouping the citation-contexts,[0],[0]
"To identify the most representative sentences of each group, we require a measure of importance of sentences.",3.3 Ranking model,[0],[0]
We consider the sentences in a group as a graph and rank nodes based on their importance.,3.3 Ranking model,[0],[0]
An important node is a node that has many connections with other nodes.,3.3 Ranking model,[0],[0]
"There are various ways of measuring centrality of nodes such as nodes degree, betweenness, closeness and eigenvectors.",3.3 Ranking model,[0],[0]
"Here, we opt for eigenvectors and we find the most central sentences in each group by using the “power method” (Erkan and Radev, 2004) which iteratively updates the eigenvector until convergence.",3.3 Ranking model,[0],[0]
"After scoring and ranking the sentences in each group which were identified either by discourse model or by community detection algorithm, we employ two strategies for generating the summary within the summary length threshold.",3.4 Selecting the sentences for final summary,[0],[0]
"• Iterative: We select top sentences iteratively from
each group until we reach the summary length threshold.",3.4 Selecting the sentences for final summary,[0],[0]
"That is, we first pick the top sentence from all groups and if the threshold is not met, we select the second sentence and so forth.",3.4 Selecting the sentences for final summary,[0],[0]
"In the discourse based method, the following ordering for selecting sentences from groups is used: “hypothesis”, “method”,“results”, “implication” and “discussion”.",3.4 Selecting the sentences for final summary,[0],[0]
"In the community detection method, no pre-determined order is specified.",3.4 Selecting the sentences for final summary,[0],[0]
"• Novelty: We employ a greedy strategy similar to
MMR (Carbonell and Goldstein, 1998) in which sentences from each group are selected based on the following scoring formula:
score(S) def=λSim1(S, D) − (1− λ)Sim2(S,Summary)
",3.4 Selecting the sentences for final summary,[0],[0]
"Where, for each sentence S, the score is a linear interpolation of similarity of sentence with all other sentences (Sim1) and the similarity of sentence with the sentences already in the summary (Sim2) and λ is a constant.",3.4 Selecting the sentences for final summary,[0],[0]
We empirically set λ = 0.7 and also selected top 3 central sentences from each group as the candidates for the final summary.,3.4 Selecting the sentences for final summary,[0],[0]
We used the TAC2014 biomedical summarization dataset for evaluation of our proposed method.,4.1 Data,[0],[0]
The TAC2014 benchmark contains 20 topics each of which consists of one reference article and several articles that have citations to each reference article (the statistics of the dataset is shown in Table 1).,4.1 Data,[0],[0]
All articles are biomedical papers published by Elsevier.,4.1 Data,[0],[0]
"For each topic, 4 experts in biomedical domain have written a scientific summary of length not exceeding 250 words for the reference article.",4.1 Data,[0],[0]
The data also contains annotated citation texts as well as the discourse facets.,4.1 Data,[0],[0]
The latter were used to build the supervised discourse model.,4.1 Data,[0],[0]
The distribution of discourse facets is shown in Table 2.,4.1 Data,[0],[0]
uses a measure called centrality to find the most representative sentences in given sets of sentences.,4.2 Baselines,[0],[0]
"It finds the most central sentences by updating the score of each sentence using an algorithm based on PageRank random walk ranking model (Page et al., 1999).",4.2 Baselines,[0],[0]
"More specifically, the centrality score of each sentence is represented by a centrality matrix p which is updated iteratively through the following equation using a method called “power method”:
p = AT p
Where matrix A is based on the similarity matrix B of the sentences:
A = [dU + (1− d)B]
In which U is a square matrix with values 1/N and d is a parameter called the damping factor.",4.2 Baselines,[0],[0]
We set d to 0.1 which is the default suggested value.,4.2 Baselines,[0],[0]
"• MMR (Carbonell and Goldstein, 1998) -",4.2 Baselines,[0],[0]
"In
Maximal Marginal Relevance (MMR), sentences are greedily ranked according to a score based on their relevance to the document and the amount of redundant information they carry.",4.2 Baselines,[0],[0]
"It scores sentences based on the maximization of the linear interpolation of the relevance to the document and diversity:
MMR(S,D) def=λSim1(S, D) − (1− λ)Sim2(S,Summary)
Where S is the sentence being evaluated, D is the document being summarized, Sim1 and Sim2 are similarity function, Summary is the summary formed by the previously selected sentences and λ is a parameter.",4.2 Baselines,[0],[0]
"We used cosine similarity as similarity functions and we set λ to 0.3, 0.5 and 0.7 for observing the effect of informativeness vs. novelty.",4.2 Baselines,[0],[0]
"• Citation summary (Qazvinian and Radev, 2008)-
In this approach, a network of citations is built and citations are clustered to maximum purity (Zhao and Karypis, 2001) and mutual information.",4.2 Baselines,[0],[0]
These clusters are then used to generate the final summary by selecting the top central sentences from each cluster in a round-robin fashion.,4.2 Baselines,[0],[0]
Our approach is similar to this work in that they also use centrality scores on citation network clusters.,4.2 Baselines,[0],[0]
"Since they only focus on citations, comparison of our approach with this work gives a better insight into how beneficial our use of citation-context and article’s discourse model can be in generating scientific summaries.",4.2 Baselines,[0],[0]
"We use the ROUGE evaluation metrics which has shown consistent correlation with manually evaluated summarization scores (Lin, 2004).",5.1 Evaluation metrics,[0],[0]
"More specifically, we use ROUGE-L, ROUGE-1 and ROUGE-2 to evaluate and compare the quality of the summaries generated by our system.",5.1 Evaluation metrics,[0],[0]
"While ROUGE-N focuses on n-gram overlaps, ROUGE-L uses the longest common subsequence to measure the quality of the summary.",5.1 Evaluation metrics,[0],[0]
"ROUGE-N where N
is the n-gram order, is defined as follows:
ROUGE-N =
∑ S∈{Gold summaries} ∑ W∈S
fmatch(W )∑ S∈{Gold summaries} ∑ W∈S f(W )
WhereW is the n-gram, f(.) is the count function, fmatch(.)",5.1 Evaluation metrics,[0],[0]
is the maximum number of n-grams cooccurring in the generated summary and in a set of gold summaries.,5.1 Evaluation metrics,[0],[0]
"For a candidate summary C with n words and a gold summary S with u sentences, ROUGE-L is defined as follows:
ROUGE-Lrec =
u∑ i=1
LCS∪(ri, C)∑u i=1",5.1 Evaluation metrics,[0],[0]
"|ri|
ROUGE-Lprec =
u∑ i=1",5.1 Evaluation metrics,[0],[0]
"LCS∪(ri, C)
n
Where LCS∪(., .) is the Longest common subsequence (LCS) score of the union of LCS between gold sentence ri and the candidate summary C. ROUGE-L f score is the harmonic mean between precision and recall.",5.1 Evaluation metrics,[0],[0]
We generated two sets of summaries using the methods and baselines described in previous sections.,5.2 Comparison between summarizers,[0],[0]
We consider short summaries of length 100 words and longer summaries of length 250 words (which corresponds to the length threshold in gold summaries).,5.2 Comparison between summarizers,[0],[0]
We also considered the oracle’s performance by averaging over the ROUGE scores of all human summaries calculated by considering one human summary against others in each topic.,5.2 Comparison between summarizers,[0],[0]
"As far as 100 words summaries, since we did not have gold summaries of that length, we considered the first 100 words from each gold summary.",5.2 Comparison between summarizers,[0],[0]
Figure 2 shows the box-and-whisker plots with ROUGE scores.,5.2 Comparison between summarizers,[0],[0]
"For each metric, the scores of each summarizer in comparison with the baselines for 100 word summaries and 250 words summaries are shown.",5.2 Comparison between summarizers,[0],[0]
"The citation-context for all the methods were identified by the citation text vector method which uses the citation text except for numeric values, stop words and citation markers (first method in section 3.1).",5.2 Comparison between summarizers,[0],[0]
"In section 5.3, we analyze the effect of various citation-context extraction methods that we discussed in section 3
on the final summary.",5.2 Comparison between summarizers,[0],[0]
The name of each of our methods is shortened by the following convention:,5.2 Comparison between summarizers,[0],[0]
[Summarization approach],5.2 Comparison between summarizers,[0],[0]
[Sentence selection strategy].,5.2 Comparison between summarizers,[0],[0]
"Summarization approach is based on either community detection (CitationContext-Comm) or discourse model of the article (Citation-Context-Disc) and sentence selection strategy can be iterative (It) or by relevance and diversification (Div).
",5.2 Comparison between summarizers,[0],[0]
We can clearly observe that our proposed methods achieve encouraging results in comparison with existing baselines.,5.2 Comparison between summarizers,[0],[0]
"Specifically, for 100 words short summaries, the discourse based method (with 34.6% mean ROUGE-L improvement over the best baseline) and for 250 word summaries, the community based method (with 3.5% mean ROUGE-L improvement over the best baseline) are the best performing methods.",5.2 Comparison between summarizers,[0],[0]
We observe relative consistency between different rouge scores for each summarization approach.,5.2 Comparison between summarizers,[0],[0]
Grouping citation-context based on both the discourse structure and the communities show comparable results.,5.2 Comparison between summarizers,[0],[0]
The community detection approach is thus effectively able to identify diverse aspects of the article.,5.2 Comparison between summarizers,[0],[0]
The discourse model of the scientific article is also able to diversify selection of citation contexts for the final summary.,5.2 Comparison between summarizers,[0],[0]
"These results confirm our hypotheses that using the citation context along with the discourse model of the scientific articles can help producing better summaries.
",5.2 Comparison between summarizers,[0],[0]
"Comparison of performance of methods on individual topics showed that the citation-context methods consistently over perform all other methods in most of the topics (65% of all topics).
",5.2 Comparison between summarizers,[0],[0]
"While the discourse approach shows encouraging results, we attribute its limitation in achieving higher ROUGE scores to the classification errors that we observed in intrinsic classification evaluation.",5.2 Comparison between summarizers,[0],[0]
"In evaluating the performance of several classifiers, linear SVM achieved the highest performance with accuracy of 0.788 in comparison with human annotation performance.",5.2 Comparison between summarizers,[0],[0]
Many of the citations cannot exactly belong to only one of the discourse facets of the paper and thus some errors in classification are inevitable.,5.2 Comparison between summarizers,[0],[0]
"This is also observable in disagreements between the annotators in labeling as reported by (Cohan et al., 2014).",5.2 Comparison between summarizers,[0],[0]
"This fact influences the diversification and finally the summarization quality.
",5.2 Comparison between summarizers,[0],[0]
"Among baseline summarization approaches, LexRank performs relatively well.",5.2 Comparison between summarizers,[0],[0]
Its performance is the best for short summaries among other baselines.,5.2 Comparison between summarizers,[0],[0]
This is expected since LexRank tries to find the most central sentences.,5.2 Comparison between summarizers,[0],[0]
"When the length of the summary is short, the main idea in the summary is usually captured by finding the most representative sentence which LexRank can effectively achieve.",5.2 Comparison between summarizers,[0],[0]
"However, the sentences that it chooses are usually about the same topic.",5.2 Comparison between summarizers,[0],[0]
"Hence, the diversity in the gold summaries is not considered.",5.2 Comparison between summarizers,[0],[0]
This becomes more visible when we observe 250 word summaries.,5.2 Comparison between summarizers,[0],[0]
Our discourse based method can overcome this problem by including important contents for diverse discourse facets (34.6% mean ROUGE-L improvement for 100 words summaries and 13.9% improvement for 250 word summaries).,5.2 Comparison between summarizers,[0],[0]
"The community based approach achieves the same diversification effect in an unsupervised fashion by forming citation-context communities (27.16% mean ROUGE-L improvement for 100 words summaries and 14.9% improvement for 250 word summaries).
",5.2 Comparison between summarizers,[0],[0]
The citation based summarization baseline has somewhat average performance among the baseline methods.,5.2 Comparison between summarizers,[0],[0]
This confirms that relying only on the citations can not be optimal for scientific summarization.,5.2 Comparison between summarizers,[0],[0]
"While LSA approach performs relatively well, we observe lower scores for all variations of MMR approaches.",5.2 Comparison between summarizers,[0],[0]
"We attribute the low performance of MMR to its sub optimal greedy selection of sentences from relatively long scientific articles.
",5.2 Comparison between summarizers,[0],[0]
"By comparing the two sentence selection approaches (i.e., iterative and diversificationrelevance), we observe that while for shorter length summaries the method based on diversification performs better, for the longer summaries results for the two methods are comparable.",5.2 Comparison between summarizers,[0],[0]
"This is because when the length threshold is smaller, iterative approach may fail to select best representative sentences from all the groups.",5.2 Comparison between summarizers,[0],[0]
"It essentially selects one sentence from each group until the length threshold is met, and consequently misses some aspects.",5.2 Comparison between summarizers,[0],[0]
"Whereas, the diversification method selects sentences that maximize the gain in informativeness and at the same time contributes to the novelty of the summary.",5.2 Comparison between summarizers,[0],[0]
"In longer summaries, due to larger threshold, iterative approach seems to be able
to select the top sentences from each group, enabling it to reflect different aspect of the paper.",5.2 Comparison between summarizers,[0],[0]
"Therefore, the iterative approach performs comparably well to the diversification approach.",5.2 Comparison between summarizers,[0],[0]
This outcome is expected because the number of groups are small.,5.2 Comparison between summarizers,[0],[0]
"For discourse method, there are 5 different discourse facets and for community method, on average 5.2 communities are detected.",5.2 Comparison between summarizers,[0],[0]
"Hence, iterative selection can select sentences from most of these groups within 250 words limit summaries.",5.2 Comparison between summarizers,[0],[0]
"Figure 3 shows ROUGE-L results for 250 words summaries based on using different citationcontext extraction approaches, described in section 3.1.",5.3 Analysis of strategies for citation-context extraction,[0],[0]
Relatively comparable performance for all the approaches is achieved.,5.3 Analysis of strategies for citation-context extraction,[0],[0]
Using the citation text for extracting the context is almost as effective as other methods.,5.3 Analysis of strategies for citation-context extraction,[0],[0]
Keywords approach which uses the terms with high idf values for locating the context achieves slightly higher Rouge-L precision while it has the lowest recall.,5.3 Analysis of strategies for citation-context extraction,[0],[0]
This is expected since keywords approach chooses only informative terms for extracting citation-contexts.,5.3 Analysis of strategies for citation-context extraction,[0],[0]
This results in missing terms that may not be keywords by themselves but help providing meaning.,5.3 Analysis of strategies for citation-context extraction,[0],[0]
Noun phrases has the highest mean F-score and thus suggests the fact that noun phrases are good indicators of important concepts in scientific text.,5.3 Analysis of strategies for citation-context extraction,[0],[0]
We attribute the high recall of noun phrases to the fact that most important concepts are captured by only selecting noun phrases.,5.3 Analysis of strategies for citation-context extraction,[0],[0]
"Interestingly, introducing biomedical concepts and expanding the citation vector by related concepts does not improve
the performance.",5.3 Analysis of strategies for citation-context extraction,[0],[0]
This approach achieves a relatively higher recall but a lower mean precision.,5.3 Analysis of strategies for citation-context extraction,[0],[0]
"While capturing domain concepts along with noun phrases helps improving the performance, adding related concepts to the citation vector causes drift from the original context as expressed in the reference article.",5.3 Analysis of strategies for citation-context extraction,[0],[0]
Therefore some decline in performance is incurred.,5.3 Analysis of strategies for citation-context extraction,[0],[0]
We proposed a pipeline approach for summarization of scientific articles which takes advantage of the article’s inherent discourse model and citation-contexts extracted from the reference article1.,6 Conclusion,[0],[0]
Our approach focuses on the problem of lack of context in existing citation based summarization approaches.,6 Conclusion,[0],[0]
We effectively achieved improvement over several well known summarization approaches on the TAC2014 biomedical summarization dataset.,6 Conclusion,[0],[0]
"That is, in all cases we improved over the baselines; in some cases we obtained greater than 30% improvement for mean ROUGE scores over the best performing baseline.",6 Conclusion,[0],[0]
"While the dataset we use for evaluation of scientific articles is in biomedical domain, most of our approaches are general and therefore adaptable to other scientific domains.",6 Conclusion,[0],[0]
The authors would like to thank the three anonymous reviewers for their valuable feedback and comments.,Acknowledgments,[0],[0]
"This research was partially supported by National Science Foundation (NSF) under grant CNS-1204347.
1Code can be found at: https://github.com/acohan/ scientific-summ",Acknowledgments,[0],[0]
We propose a summarization approach for scientific articles which takes advantage of citation-context and the document discourse model.,abstractText,[0],[0]
"While citations have been previously used in generating scientific summaries, they lack the related context from the referenced article and therefore do not accurately reflect the article’s content.",abstractText,[0],[0]
Our method overcomes the problem of inconsistency between the citation summary and the article’s content by providing context for each citation.,abstractText,[0],[0]
We also leverage the inherent scientific article’s discourse for producing better summaries.,abstractText,[0],[0]
We show that our proposed method effectively improves over existing summarization approaches (greater than 30% improvement over the best performing baseline) in terms of ROUGE scores on TAC2014 scientific summarization dataset.,abstractText,[0],[0]
"While the dataset we use for evaluation is in the biomedical domain, most of our approaches are general and therefore adaptable to other domains.",abstractText,[0],[0]
Scientific Article Summarization Using Citation-Context and Article's Discourse Structure,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 638–643 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
638",text,[0],[0]
"Standard word embedding models (Mikolov et al., 2013; Pennington et al., 2014; Bojanowski et al., 2017) are based on the distributional hypothesis by Harris (1954).",1 Introduction,[0],[0]
"However, purely distributional models coalesce various lexico-semantic relations (e.g., synonymy, antonymy, hypernymy) into a joint distributed representation.",1 Introduction,[0],[0]
"To address this, previous work has focused on introducing supervision into individual word embeddings, allowing them to better capture the desired lexical properties.",1 Introduction,[0],[0]
"For example, Faruqui et al. (2015) and Wieting et al. (2015) proposed methods for using annotated lexical relations to condition the vector space and bring synonymous words closer together.",1 Introduction,[0],[0]
Mrkšić,1 Introduction,[0],[0]
et al. (2016) and Mrkšić et al. (2017) improved the optimisation function and introduced an additional constraint for pushing antonym pairs further apart.,1 Introduction,[0],[0]
"While these methods integrate hand-crafted features from external lexical resources with distributional information, they improve only the embeddings of words that have annotated lexical relations
in the training resource.",1 Introduction,[0],[0]
"In this work, we propose a novel approach to leveraging external knowledge with generalpurpose unsupervised embeddings, focusing on the directional graded lexical entailment task (Vulić et al., 2017), whereas previous work has mostly investigated simpler non-directional semantic similarity tasks.",1 Introduction,[0],[0]
"Instead of optimising individual word embeddings, our model uses general-purpose embeddings and optimises a separate neural component to adapt these to the specific task.",1 Introduction,[0],[0]
"In particular, our neural Supervised Directional Similarity Network (SDSN) dynamically produces task-specific embeddings optimised for scoring the asymmetric lexical entailment relation between any two words, regardless of their presence in the training resource.",1 Introduction,[0],[0]
"Our results with task-specific embeddings indicate large improvements on the HyperLex dataset, a standard graded lexical entailment benchmark.",1 Introduction,[0],[0]
The model also yields improvements on a simpler nongraded entailment detection task.,1 Introduction,[0],[0]
"In graded lexical entailment, the goal is to make fine-grained assertions regarding the directional hierarchical semantic relationships between concepts (Vulić et al., 2017).",2 The Task of Grading Lexical Entailment,[0],[0]
"The task is grounded in theories of concept (proto)typicality and category vagueness from cognitive science (Rosch, 1975; Kamp and Partee, 1995), and aims at answering the following question: “To what degree is X a type of Y ?”.",2 The Task of Grading Lexical Entailment,[0],[0]
"It quantifies the degree of lexical entailment instead of providing only a binary yes/no decision on the relationship between the concepts X and Y , as done in hypernymy detection tasks (Kotlerman et al., 2010; Weeds et al., 2014; Santus et al., 2014; Kiela et al., 2015; Shwartz et al., 2017).
",2 The Task of Grading Lexical Entailment,[0],[0]
"Graded lexical entailment provides finer-grained
judgements on a continuous scale.",2 The Task of Grading Lexical Entailment,[0],[0]
"For instance, the word pair (girl → person) has been rated highly with 9.85/10 by the HyperLex annotators.",2 The Task of Grading Lexical Entailment,[0],[0]
"The pair (guest→ person) has received a slightly lower score of 7.22, as a prototypical guest is often a person but there can be exceptions.",2 The Task of Grading Lexical Entailment,[0],[0]
"In contrast, the score for the reversed pair (person→ guest) is only judged at 2.88.
",2 The Task of Grading Lexical Entailment,[0],[0]
"As demonstrated by Vulić et al. (2017) and Nickel and Kiela (2017), standard general-purpose representation models trained in an unsupervised way purely on distributional information are unfit for this task and unable to surpass the performance of simple frequency baselines (see also Table 1).",2 The Task of Grading Lexical Entailment,[0],[0]
"Therefore, in what follows, we describe a novel supervised framework for constructing task-specific word embeddings, optimised for the graded entailment task at hand.",2 The Task of Grading Lexical Entailment,[0],[0]
The network architecture can be seen in Figure 1.,3 System Architecture,[0],[0]
The system receives a pair of words as input and predicts a score that represents the strength of the given lexical relation.,3 System Architecture,[0],[0]
"In the graded entailment task, we would like the model to return a high score for (biology→ science), as biology is a type of science, but a low score for (point→ pencil).
",3 System Architecture,[0],[0]
We start by mapping both input words to corresponding word embeddings w1 and w2.,3 System Architecture,[0],[0]
"The
embeddings come from a standard distributional vector space, pre-trained on a large unannotated corpus, and are not fine-tuned during training.",3 System Architecture,[0],[0]
"An element-wise gating operation is then applied to each word, conditioned on the other word:
g1 = σ(Wg1w1 + bg1)",3 System Architecture,[0],[0]
(1) g2 = σ(Wg2w2 + bg2) (2) w̃1,3 System Architecture,[0],[0]
"= w1 g2 (3) w̃2 = w2 g1 (4)
where Wg1 and Wg2 are weight matrices, bg1 and bg2 are bias vectors, σ() is the logistic function and indicates element-wise multiplication.",3 System Architecture,[0],[0]
This operation allows the network to first observe the candidate hypernym w2 and then decide which features are important when analysing the hyponym w1.,3 System Architecture,[0],[0]
"For example, when deciding whether seal is a type of animal, the model is able to first see the word animal and then apply a mask that blocks out features of the word seal that are not related to nature.",3 System Architecture,[0],[0]
"During development we found it best to apply this gating in both directions, therefore we condition each word based on the other.
",3 System Architecture,[0],[0]
"Each of the word representations is then passed through a non-linear layer with tanh activation, mapping the words to a new space that is more suitable for the given task:
m1 = tanh(Wm1w̃1 + bm1)",3 System Architecture,[0],[0]
"(5) m2 = tanh(Wm2w̃2 + bm2) (6)
where Wm1 , Wm2 , bm1 and bm2 are trainable parameters.",3 System Architecture,[0],[0]
"The input embeddings are trained to predict surrounding words on a large unannotated corpus using the skip-gram objective (Mikolov et al., 2013), making the resulting vector space reflect (a broad relation of) semantic relatedness but unsuitable for lexical entailment (Vulić et al., 2017).",3 System Architecture,[0],[0]
The mapping stage allows the network to learn a transformation function from the general skip-gram embeddings to a task-specific space for lexical entailment.,3 System Architecture,[0],[0]
"In addition, the two weight matrices enable asymmetric reasoning, allowing the network to learn separate mappings for hyponyms and hypernyms.
",3 System Architecture,[0],[0]
We then use a supervised composition function for combining the two representations and returning a confidence score as output.,3 System Architecture,[0],[0]
"Rei et al. (2017) described a generalised version of cosine similarity for metaphor detection, constructing a supervised operation and learning individual weights for each
feature.",3 System Architecture,[0],[0]
"We apply a similar approach here and modify it to predict a relation score:
d = m1 m2 (7) h = tanh(Whd+ bh) (8) y = S · σ(a(Wyh+ by))",3 System Architecture,[0],[0]
"(9)
where Wh, bh, a, Wy and by are trainable parameters.",3 System Architecture,[0],[0]
"The annotated labels of lexical relations are generally in a fixed range, therefore we base the output function on logistic regression, which also restricts the range of the predicted scores.",3 System Architecture,[0],[0]
by allows for the function to be shifted as necessary and a controls the slope of the sigmoid.,3 System Architecture,[0],[0]
"S is the value of the maximum score in the dataset, scaling the resulting value to the correct range.",3 System Architecture,[0],[0]
"The output y represents the confidence that the two input words are in a lexical entailment relation.
",3 System Architecture,[0],[0]
We optimise the model by minimising the mean squared distance between the predicted score y and the gold-standard score ŷ,3 System Architecture,[0],[0]
":
L = ∑ i (yi − ŷi)2 (10)
Sparse Distributional Features (SDF).",3 System Architecture,[0],[0]
"Word embeddings are well-suited for capturing distributional similarity, but they have trouble encoding features such as word frequency, or the number of unique contexts the word has appeared in.",3 System Architecture,[0],[0]
"This information becomes important when deciding whether one word entails another, as the system needs to determine when a concept is more general and subsumes the other.
",3 System Architecture,[0],[0]
"We construct classical sparse distributional word vectors and use them to extract 5 unique features for every word pair, to complement the features extracted from neural embeddings:
• Regular cosine similarity between the sparse distributional vectors of both words.
",3 System Architecture,[0],[0]
"• The sparse weighted cosine measure, described by Rei and Briscoe (2014), comparing the weighted ranks of different distributional contexts.",3 System Architecture,[0],[0]
The measure is directional and assigns more importance to the features of the broader term.,3 System Architecture,[0],[0]
"We include this weighted cosine in both directions.
",3 System Architecture,[0],[0]
"• The proportion of shared unique contexts, compared to the number of contexts for one word.",3 System Architecture,[0],[0]
"This measure is able to capture whether
one of the words appears in a subset of the contexts, compared to the other word.",3 System Architecture,[0],[0]
"This feature is also directional and is therefore included in both directions.
",3 System Architecture,[0],[0]
"We build the sparse distributional word vectors from two versions of the British National Corpus (Leech, 1992).",3 System Architecture,[0],[0]
The first counts contexts simply based on a window of size 3.,3 System Architecture,[0],[0]
"The second uses a parsed version of the BNC (Andersen et al., 2008) and extracts contexts based on dependency relations.",3 System Architecture,[0],[0]
"In both cases, the features are weighted using pointwise mutual information.",3 System Architecture,[0],[0]
"Each of the five features is calculated separately for the two vector spaces, resulting in 10 corpus-based features.",3 System Architecture,[0],[0]
"We integrate them into the network by conditioning the hidden layer h on this vector:
h = tanh(Whd+Wxx+ bh) (11)
where x is the feature vector of length 10 and Wx is the corresponding weight matrix.
",3 System Architecture,[0],[0]
Additional Supervision (AS).,3 System Architecture,[0],[0]
"Methods such as retrofitting (Faruqui et al., 2015), ATTRACT-REPEL (Mrkšić et al., 2017) and Poincaré embeddings (Nickel and Kiela, 2017) make use of handannotated lexical relations for optimising word representations such that they capture the desired properties (so-called embedding specialisation).",3 System Architecture,[0],[0]
"We also experiment with incorporating these resources, but instead of adjusting the individual word embeddings, we use them to optimise the shared network weights.",3 System Architecture,[0],[0]
"This teaches the model to find useful regularities in general-purpose word embeddings, which can then be equally applied to all words in the embedding vocabulary.
",3 System Architecture,[0],[0]
"For hyponym detection, we extract examples from WordNet (Miller, 1995) and the Paraphrase Database (PPDB 2.0) (Pavlick et al., 2015).",3 System Architecture,[0],[0]
"We use WordNet synonyms and hyponyms as positive examples, along with antonyms and hypernyms as negative examples.",3 System Architecture,[0],[0]
"In order to prevent the network from biasing towards specific words that have numerous annotated relations, we limit them to a maximum of 10 examples per word.",3 System Architecture,[0],[0]
"From the PPDB we extract the Equivalence relations as positive examples and the Exclusion relations as negative word pairs.
",3 System Architecture,[0],[0]
"The final dataset contains 102,586 positive pairs and 42,958 negative pairs.",3 System Architecture,[0],[0]
"However, only binary labels are attached to all word pairs, whereas the task
requires predicting a graded score.",3 System Architecture,[0],[0]
Initial experiments with optimising the network to predict the minimal and maximal possible score for these cases did not lead to improved performance.,3 System Architecture,[0],[0]
"Therefore, we instead make use of a hinge loss function that optimises the network to only push these examples to the correct side of the decision boundary:
L = ∑ i max((y − ŷ)2",3 System Architecture,[0],[0]
"− (S 2 −R)2, 0) (12)
where S is the maximum score in the range and and R is a margin parameter.",3 System Architecture,[0],[0]
"By minimising Equation 12, the model is only updated based on examples that are not yet on the correct side of the boundary, including a margin.",3 System Architecture,[0],[0]
"This prevents us from penalising the model for predicting a score with slight variations, as the extracted examples are not annotated with sufficient granularity.",3 System Architecture,[0],[0]
"When optimising the model, we first perform one pretraining pass over these additional word pairs before proceeding with the regular training process.",3 System Architecture,[0],[0]
SDSN Training Setup.,4 Evaluation,[0],[0]
As input to the SDSN network we use 300-dimensional dependency-based word embeddings by Levy and Goldberg (2014).,4 Evaluation,[0],[0]
Layers m1 and m2 also have size 300 and layer h has size 100.,4 Evaluation,[0],[0]
"For regularisation, we apply dropout to the embeddings with p = 0.5.",4 Evaluation,[0],[0]
The margin R is set to 1 for the supervised pre-training stage.,4 Evaluation,[0],[0]
"The model is optimised using AdaDelta (Zeiler, 2012) with learning rate 1.0.",4 Evaluation,[0],[0]
"In order to control for random noise, we run each experiment with 10 different random seeds and average the results.",4 Evaluation,[0],[0]
"Our code and detailed configuration files will be made available online.1
Evaluation Data.",4 Evaluation,[0],[0]
"We evaluate graded lexical entailment on the HyperLex dataset (Vulić et al., 2017) which contains 2,616 word pairs in total scored for the asymmetric graded lexical entailment relation.",4 Evaluation,[0],[0]
"Following a standard practice, we report Spearman’s ρ correlation of the model output to the given human-annotated scores.",4 Evaluation,[0],[0]
We conduct experiments on two standard data splits for supervised learning: random split and lexical split.,4 Evaluation,[0],[0]
"In the random split the data is randomly divided into training, validation, and test subsets containing 1831, 130, and 655 word pairs, respectively.",4 Evaluation,[0],[0]
"In the lexical
1http://www.marekrei.com/projects/sdsn
split, proposed by Levy et al. (2015), there is no lexical overlap between training and test subsets.",4 Evaluation,[0],[0]
"This prevents the effect of lexical memorisation, as supervised models tend to learn an independent property of a single concept in the pair instead of learning a relation between the two concepts.",4 Evaluation,[0],[0]
"In this setup training, validation, and test sets contain 1133, 85, and 269 word pairs, respectively.2
Since plenty of related research on lexical entailment is still focused on the simpler binary detection of asymmetric relations, we also run experiments on the large binary detection HypeNet dataset (Shwartz et al., 2016), where the SDSN output is converted to binary decisions.",4 Evaluation,[0],[0]
"We again report scores for both random and lexical split.
Results and Analysis.",4 Evaluation,[0],[0]
"The results on two HyperLex splits are presented in Table 1, along with the best configurations reported by Vulić et al. (2017).",4 Evaluation,[0],[0]
"We refer the interested reader to the original HyperLex paper (Vulić et al., 2017) for a detailed description of the best performing baseline models.
",4 Evaluation,[0],[0]
"The Supervised Directional Similarity Network (SDSN) achieves substantially better scores than all other tested systems, despite relying on a much simpler supervision signal.",4 Evaluation,[0],[0]
"The previous top approaches, including the Paragram+CF embeddings, make use of numerous annotations provided by WordNet or similarly rich lexical resources, while for SDSN and SDSN+SDF only use the designated relation-specific training set and corpus statistics.",4 Evaluation,[0],[0]
"By also including these extra training instances (SDSN+SDF+AS), we can gain additional perfor-
2Note that the lexical split discards all cross-set trainingtest word pairs.",4 Evaluation,[0],[0]
"Consequently, the number of instances in each subset is lower than with the random split.
mance and push the correlation to 0.692 on the random split and 0.544 on the lexical split of HyperLex, an improvement of approximately 25% to the standard supervised training regime.
",4 Evaluation,[0],[0]
In Table 3 we provide some example output from the final SDSN+SDF+AS model.,4 Evaluation,[0],[0]
"It is able to successfully assign a high score to (captain, officer) and also identify with high confidence that wing is not a type of airplane, even though they are semantically related.",4 Evaluation,[0],[0]
"As an example of incorrect output, the model fails to assign a high score to (prince, royalty), possibly due to the usage patterns of these words being different in context.",4 Evaluation,[0],[0]
"In contrast, it assigns an unexpectedly high score to (kid, parent), likely due to the high distributional similarity of these words.
",4 Evaluation,[0],[0]
Glavaš and Ponzetto (2017) proposed a related dual tensor model for the binary detection of asymmetric relations (Dual-T).,4 Evaluation,[0],[0]
"In order to compare our system to theirs, we train our model on HypeNet and convert the output to binary decisions.",4 Evaluation,[0],[0]
"We also compare SDSN to the best reported models of Shwartz et al. (2016) and Roller and Erk (2016), which combine distributional and pattern-based information for hypernymy detection (HypeNethybrid and H-feature, respectively).3 We do not include additional WordNet and PPDB examples in these experiments, as the HypeNet data already subsumes most of them.",4 Evaluation,[0],[0]
"As can be seen in Table 2, our SDSN+SDF model achieves the best results also on the HypeNet dataset, outperforming previous models on both data splits.",4 Evaluation,[0],[0]
We introduce a novel neural architecture for mapping and specialising a vector space based on limited supervision.,5 Conclusion,[0],[0]
"While prior work has focused only on optimising individual word embeddings available in external resources, our model uses
3For more detail on the baseline models, we refer the reader to the original papers.
general-purpose embeddings and optimises a separate neural component to adapt these to the specific task, generalising to unseen data.",5 Conclusion,[0],[0]
The system achieves new state-of-the-art results on the task of scoring graded lexical entailment.,5 Conclusion,[0],[0]
Future work could apply the model to other lexical relations or extend it to cover multiple relations simultaneously.,5 Conclusion,[0],[0]
Daniela Gerz and Ivan Vulić are supported by the ERC Consolidator Grant LEXICAL:,Acknowledgments,[0],[0]
Lexical Acquisition Across Languages (no 648909).,Acknowledgments,[0],[0]
We would like to thank the NVIDIA Corporation for the donation of the Titan GPU that was used for this research.,Acknowledgments,[0],[0]
"We present the Supervised Directional Similarity Network (SDSN), a novel neural architecture for learning task-specific transformation functions on top of generalpurpose word embeddings.",abstractText,[0],[0]
"Relying on only a limited amount of supervision from task-specific scores on a subset of the vocabulary, our architecture is able to generalise and transform a general-purpose distributional vector space to model the relation of lexical entailment.",abstractText,[0],[0]
"Experiments show excellent performance on scoring graded lexical entailment, raising the stateof-the-art on the HyperLex dataset by approximately 25%.",abstractText,[0],[0]
Scoring Lexical Entailment with a Supervised Directional Similarity Network,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1212–1221 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1212
We explore the notion of subjectivity, and hypothesize that word embeddings learnt from input corpora of varying levels of subjectivity behave differently on natural language processing tasks such as classifying a sentence by sentiment, subjectivity, or topic. Through systematic comparative analyses, we establish this to be the case indeed. Moreover, based on the discovery of the outsized role that sentiment words play on subjectivity-sensitive tasks such as sentiment classification, we develop a novel word embedding SentiVec which is infused with sentiment information from a lexical resource, and is shown to outperform baselines on such tasks.",text,[0],[0]
"Distributional analysis methods such as Word2Vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) have been critical for the success of many large-scale natural language processing (NLP) applications (Collobert et al., 2011; Socher et al., 2013; Goldberg, 2016).",1 Introduction,[0],[0]
"These methods employ distributional hypothesis (i.e., words used in the same contexts tend to have similar meaning) to derive distributional meaning via context prediction tasks and produce dense word embeddings.
",1 Introduction,[0],[0]
"While there have been active and ongoing research on improving word embedding methods (see Section 5), there is a relative dearth of study on the impact that an input corpus may have on the quality of the word embeddings.",1 Introduction,[0],[0]
"The previous preoccupation centers around corpus size, i.e., a larger corpus is perceived to be richer in statistical information.",1 Introduction,[0],[0]
"For instance, popular corpora include Wikipedia, Common Crawl, and Google News.
",1 Introduction,[0],[0]
We postulate that there may be variations across corpora owing to factors that affect language use.,1 Introduction,[0],[0]
"Intuitively, the many things we write (a work email, a product review, an academic publication, etc.) may each involve certain stylistic, syntactic, and lexical choices, resulting in meaningfully different distributions of word cooccurrences.",1 Introduction,[0],[0]
"Consequently, such factors may be encoded in the word embeddings, and input corpora may be differentially informative towards various NLP tasks.
",1 Introduction,[0],[0]
"In this work, we are interested in the notion of subjectivity.",1 Introduction,[0],[0]
"Some NLP tasks, such as sentiment classification, revolve around subjective expressions of likes or dislikes.",1 Introduction,[0],[0]
"Others, such as topic classification, revolve around more objective elements of whether a document belongs to a topic (e.g., science, politics).",1 Introduction,[0],[0]
"Our central hypothesis is that word embeddings learnt from input corpora of contrasting levels of subjectivity perform differently when classifying sentences by sentiment, subjectivity, or topic.",1 Introduction,[0],[0]
"As the first contribution, we outline an experimental scheme to explore this hypothesis in Section 2, and conduct a series of controlled experiments in Section 3 establishing that there exists a meaningful difference between word embeddings derived from objective vs. subjective corpora.",1 Introduction,[0],[0]
"We further systematically investigate factors that could potentially explain the differences.
",1 Introduction,[0],[0]
"Upon discovering from the investigation that sentiment words play a particularly important role in subjectivity-sensitive NLP tasks, such as sentiment classification, as the second contribution, in Section 4 we develop SentiVec, a novel word embedding method infused with information from lexical resources such as a sentiment lexicon.",1 Introduction,[0],[0]
"We further identify two alternative lexical objectives: Logistic SentiVec based on discriminative logistic regression, and Spherical SentiVec based on soft clustering effect of von Mises-Fisher distributions.",1 Introduction,[0],[0]
"In Section 6, the proposed word embeddings show
evident improvements on sentiment classification, as compared to the base model Word2Vec and other baselines using the same lexical resource.",1 Introduction,[0],[0]
"We lay out the methodology for generating word embeddings of contrasting subjectivity, whose effects are tested on several text classification tasks.",2 Data and Methodology,[0],[0]
"As it is difficult to precisely quantify the degree of subjectivity of a corpus, we resort to generating word embeddings from two corpora that contrast sharply in subjectivity, referring to them as the Objective Corpus and the Subjective Corpus.
",2.1 Generating Word Embeddings,[0],[0]
"Objective Corpus As virtually all contents are written by humans, an absolutely objective corpus (in the philosophical sense) may prove elusive.",2.1 Generating Word Embeddings,[0],[0]
"There are however exemplars where, by construction, a corpus aspires to be as objective as possible, and probably achieves that in practical terms.",2.1 Generating Word Embeddings,[0],[0]
We postulate that one such corpus is Wikipedia.,2.1 Generating Word Embeddings,[0],[0]
"Its list of policies and guidelines1, assiduously enforced by an editorial team, specify that an article must be written from a neutral point of view, which among other things means “representing fairly, proportionately, and, as far as possible, without editorial bias, all of the significant views that have been published by reliable sources on a topic.”.",2.1 Generating Word Embeddings,[0],[0]
"Moreover, it is a common resource for training distributional word embeddings and adopted widely by the research community to solve various NLP problems.",2.1 Generating Word Embeddings,[0],[0]
"Hence, in this study, we use Wikipedia as the Objective Corpus.
Subjective Corpus By extension, one may then deem a corpus subjective if its content does not at least meet Wikipedia’s neutral point of view requirement.",2.1 Generating Word Embeddings,[0],[0]
"In other words, if the content is replete with personal feelings and opinions.",2.1 Generating Word Embeddings,[0],[0]
We posit that product reviews would be one such corpus.,2.1 Generating Word Embeddings,[0],[0]
"For instance, Amazon’s Community Guideline2 states that “Amazon values diverse opinions”, and that “Content you submit should be relevant and based on your own honest opinions and experience.”.",2.1 Generating Word Embeddings,[0],[0]
"Reviews consist of expressive content written by customers, and may not strive for the neutrality of an encyclopedia.",2.1 Generating Word Embeddings,[0],[0]
"We rely on a
1https://en.wikipedia.org/wiki/ Wikipedia:List_of_policies_and_ guidelines
2https://www.amazon.com/gp/help/ customer/display.html?nodeId=201929730
large corpus of Amazon reviews from various categories (e.g., electronics, jewelry, books, and etc.)",2.1 Generating Word Embeddings,[0],[0]
"(McAuley et al., 2015) as the Subjective Corpus.
",2.1 Generating Word Embeddings,[0],[0]
Word Embeddings,2.1 Generating Word Embeddings,[0],[0]
"For the comparative analysis in Section 3, we employ Word2Vec (reviewed below) to generate word embeddings from each corpus.",2.1 Generating Word Embeddings,[0],[0]
"Later on in Section 4, we will propose a new word embedding method called SentiVec.
",2.1 Generating Word Embeddings,[0],[0]
"For Word2Vec, we use the Skip-gram model to train distributional word embeddings on the Objective Corpus and the Subjective Corpus respectively.",2.1 Generating Word Embeddings,[0],[0]
Skip-gram aims to find word embeddings that are useful for predicting nearby words.,2.1 Generating Word Embeddings,[0],[0]
"The objective is to maximize the context probability:
logL(W ;C) = ∑ w∈W ∑ w′∈C(w) log P(w′|w), (1)
where W is an input corpus and C(w) is the context of token w.",2.1 Generating Word Embeddings,[0],[0]
"The probability of context word w′, given observed word w is defined via softmax:
P(w′|w) = exp (vw ′ · vw)∑
ŵ∈V exp (vŵ · vw) , (2)
where vw and vw′ are corresponding embeddings and V is the corpus vocabulary.",2.1 Generating Word Embeddings,[0],[0]
"Though theoretically sound, the formulation is computationally impractical and requires tractable approximation.
",2.1 Generating Word Embeddings,[0],[0]
Mikolov et al. (2013) propose two efficient procedures to optimize (1): Hierarchical Softmax and Negative Sampling (NS).,2.1 Generating Word Embeddings,[0],[0]
In this work we focus on the widely adopted NS.,2.1 Generating Word Embeddings,[0],[0]
The intuition is that a “good” model should be able to differentiate observed data from noise.,2.1 Generating Word Embeddings,[0],[0]
"The differentiation task is defined using logistic regression; the goal is to tell apart real context-word pair (w′, w) from randomly generated noise pair (ŵ, w).",2.1 Generating Word Embeddings,[0],[0]
"Formally,
logL[w‘,w] = log σ (vw′ · vw) +",2.1 Generating Word Embeddings,[0],[0]
k∑ i=1,2.1 Generating Word Embeddings,[0],[0]
log σ,2.1 Generating Word Embeddings,[0],[0]
"(−vŵi · vw),
(3)
where σ( · ) is a sigmoid function, and {ŵi}ki=1 are negative samples.",2.1 Generating Word Embeddings,[0],[0]
"Summing up all the contextword pairs, we derive the NS Skip-gram objective:
logLword2vec(W ;C) = ∑ w∈W ∑ w′∈C(w) logL[w‘,w].",2.1 Generating Word Embeddings,[0],[0]
"(4)
Training word embeddings with Skip-gram, we keep the same hyperparameters across all the runs: 300 dimensions for embeddings, k = 5 negative samples, and window of 5 tokens.",2.1 Generating Word Embeddings,[0],[0]
"The Objective
and Subjective corpora undergo the same preprocessing, i.e., discarding short sentences (< 5 tokens) and rare words (< 10 occurrences), removing punctuation, normalizing Unicode symbols.",2.1 Generating Word Embeddings,[0],[0]
"To compare word embeddings, we need a common yardstick.",2.2 Evaluation Tasks,[0],[0]
It is difficult to define an inherent quality to word embeddings.,2.2 Evaluation Tasks,[0],[0]
"Instead, we put them through several evaluation tasks that can leverage word embeddings and standardize their formulations as binary classification tasks.",2.2 Evaluation Tasks,[0],[0]
"To boil the comparisons down to the essences of word embeddings (which is our central focus), we rely on standardized techniques so as to attribute as much of the differences as possible to the word embeddings.",2.2 Evaluation Tasks,[0],[0]
"We use logistic regression for classification, and represent a text snippet (e.g., a sentence) in the feature space as the average of the word embeddings of tokens in the snippet (ignoring out-ofvocabulary tokens).",2.2 Evaluation Tasks,[0],[0]
"The evaluation metric is the average accuracy from 10-fold cross validation.
",2.2 Evaluation Tasks,[0],[0]
"There are three evaluation tasks of varying degrees of hypothetical subjectivity, as outlined below.",2.2 Evaluation Tasks,[0],[0]
"Each may involve multiple datasets.
",2.2 Evaluation Tasks,[0],[0]
Sentiment Classification Task This task classifies a sentence into either positive or negative.,2.2 Evaluation Tasks,[0],[0]
"We use two groups of datasets as follows.
",2.2 Evaluation Tasks,[0],[0]
The first group consists of 24 datasets from UCSD Amazon product data3 corresponding to various product categories.,2.2 Evaluation Tasks,[0],[0]
"Each review has a rating from 1 to 5, which is transformed into positive (ratings 4 or 5) or negative (ratings 1 or 2) class.",2.2 Evaluation Tasks,[0],[0]
"For each dataset respectively, we sample 5000 sentences each from the positive and negative reviews.",2.2 Evaluation Tasks,[0],[0]
Note that these sentences used for this evaluation task have not participated in the generation of word embeddings.,2.2 Evaluation Tasks,[0],[0]
"Due to space constraint, in most cases we present the average accuracy across the datasets, but where appropriate we enumerate the results for each dataset.
",2.2 Evaluation Tasks,[0],[0]
"The second is Cornell’s sentence polarity dataset v1.04 (Pang and Lee, 2005), made up of 5331 each of positive and negative sentences from Rotten Tomatoes movie reviews.",2.2 Evaluation Tasks,[0],[0]
"The inclusion of this out-of-domain evaluation dataset is useful for examining whether the performance of word embeddings from the Subjective Corpus on the first
3http://jmcauley.ucsd.edu/data/amazon/ 4http://www.cs.cornell.edu/people/
pabo/movie-review-data/rt-polaritydata.",2.2 Evaluation Tasks,[0],[0]
"README.1.0.txt
group above may inadvertently be affected by indomain advantage arising from its Amazon origin.
",2.2 Evaluation Tasks,[0],[0]
Subjectivity Classification Task This task classifies a sentence into subjective or objective.,2.2 Evaluation Tasks,[0],[0]
"The dataset is Cornell’s subjectivity dataset v1.05, consisting of 5000 subjective sentences derived from Rotten Tomatoes (RT) reviews and 5000 objective sentences derived from IMDB plot summaries (Pang and Lee, 2004).",2.2 Evaluation Tasks,[0],[0]
"This task is probably less sensitive to the subjectivity within word embeddings than sentiment classification, as determining whether a sentence is subjective or objective should ideally be an objective undertaking.
",2.2 Evaluation Tasks,[0],[0]
Topic Classification Task We use the 20 Newsgroups dataset6,2.2 Evaluation Tasks,[0],[0]
"(“bydate” version), whereby the newsgroups are organized into six subject matter groupings.",2.2 Evaluation Tasks,[0],[0]
We extract the message body and split them into sentences.,2.2 Evaluation Tasks,[0],[0]
"Each group’s sentences then form the in-topic class, and we randomly sample an equivalent number of sentences from the remaining newsgroups to form the out-of-topic class.",2.2 Evaluation Tasks,[0],[0]
"This results in six datasets, each corresponding to a binary classification task.",2.2 Evaluation Tasks,[0],[0]
"In most cases, we present the average results, and where appropriate we enumerate the results for each dataset.",2.2 Evaluation Tasks,[0],[0]
"Hypothetically, this task is the least affected by the subjectivity within word embeddings.",2.2 Evaluation Tasks,[0],[0]
We conduct a series of comparative analyses under various setups.,3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"For each, we compare the performance in the evaluation tasks when using the Objective Corpus and the Subjective Corpus.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Table 1 shows the results for this series of analyses.
",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
Initial Condition Setup I seeks to answer whether there is any difference between word embeddings derived from the Objective Corpus and the Subjective Corpus.,3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
The word embeddings were trained on the whole data respectively.,3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
Table 1 shows the corpus statistics and classification accuracies.,3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Evidently, the Subjective word embeddings outperform the Objective word embeddings on all the evaluation tasks.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"The margins are largest for sentiment classification (86.5% vs. 81.5% or +5% Amazon, and 78.2% vs. 75.4% or +2.8% on Rotten Tomatoes or RT).",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"For subjectivity and topic classifications, the differences are smaller.
5http://www.cs.cornell.edu/people/ pabo/movie-review-data/subjdata.README.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"1.0.txt
6http://qwone.com/˜jason/20Newsgroups/
As earlier hypothesized, the sentiment classification task is more sensitive to subjectivity within word embeddings than the other tasks.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Therefore, training word embeddings on a subjective corpus may confer an advantage for such tasks.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"On the other hand, the corpus statistics show a substantial difference in corpus size, which could be an alternative explanation for the outperformance by the Subjective Corpus if the larger corpus contains more informative distributional statistics.
",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Controlling for Corpus Size In Setup II, we keep the number of sentences in both corpora the same, by randomly downsampling sentences in the Subjective Corpus.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"This procedure consequently reduces the number of types and tokens (see Table 1, Setup II, Corpus Statistics).",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Note that the number of tokens in the Subjective corpus is now fewer than in the Objective, the latter suffers no change.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Yet, even after a dramatic reduction in size, the Subjective embeddings still outperform the Objective significantly on both datasets of the sentiment classification task (+4% on Amazon and +2.5% on RT), while showing similar performance on subjectivity and topic classifications.
",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
This bolsters the earlier observation that sentiment classification is more sensitive to subjectivity.,3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"While there is a small effect due to corpus size difference, the gap in performance between Subjective and Objective embeddings on sentiment classification is still significant and cannot be explained away by the corpus size alone.
",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Controlling for Vocabulary While the Subjective Corpus has a much smaller vocabulary (i.e., # types), we turn a critical eye on whether its apparent advantage lies in having access to special word types that do not exist in the Objective Corpus.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"In Setup III, we keep the training vocabulary the same for both, removing the types that are
present in one corpus but not in the other, so that out-of-vocabulary words are ignored in the training phase.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Table 1, Setup III, shows significant reduction in types for both corpora.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Yet, the outperformance by the Subjective embeddings on the sentiment classification task still stands (+3.8% on Amazon and +2.3% on RT).",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Moreover, it is so for both Amazon and Rotten Tomatoes datasets, implying that it is not due to close in-domain similarity between the corpora used for training the word embeddings and the classification tasks.
",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Significant Words To get more insights on the difference between the Subjective and Objective corpora, we analyze the mistakes word embeddings make on the development folds.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"At this point we focus on the sentiment classification task and specifically on the Amazon data, which indicates the largest performance differences in the controlled experiments (see Table 1, Setup III).
",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"As words are still the main unit of information in distributional word embeddings, we extract words strongly associated with misclassified sentences.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
We employed log-odds ratio with informative,3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Dirichlet prior method (Monroe et al., 2008) to quantify this association.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"It is used to contrast the words in misclassified vs. correctly classified sentences, and accounts for the variance of words and their prior counts taken from a large corpus.
",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Table 2 shows the top 25 words most associated with the misclassified sentences, sorted by their association scores.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"On average 50% of the mistakes overlap for both word embeddings, therefore, some of the words are included in both lists.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"40 − 44% of these words carry positive or negative sentiment connotations in general (see the underlined words in Table 2), while other words like return or send may carry sentiment connotation in e-commerce context.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"We check if a word carries sentiment connotation using sentiment lexicon compiled by Hu and Liu (2004), including 6789 words along with positive or negative labels.
",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"We also observe linguistic negations (i.e., not, Don’t).",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"For instance, the word most associated with the Objective-specific mistakes (excluding the Subjective misclassified sentences) is not, which suggests that perhaps Subjective word embedding accommodates better understanding of linguistic negations, which may partially explain the difference.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"However, our methodology as outlined in Section 2.2 permits exchangeable word order and is not intended to analyze structural interaction between words.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"We focus on further analysis of sentiment words, leaving linguistic negations in word embeddings for future investigation.
",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Controlling for Sentiment Words To control for the “amount” of sentiment in the Subjective and Objective corpora, we use sentiment lexicon compiled by Hu and Liu (2004).",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"For each corpus, we create two subcorpora: With Sentiment contains only the sentences with at least one word from the sentiment lexicon, while Without Sentiment is the complement.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"We match the corpora on the number of sentences, downsampling the larger corpus, train word embeddings on each subcorpus, and proceed with the classification experiments.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Table 3 shows the results, including that of random word embeddings for reference.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Sentiment lexicon has a significant impact on the performance of sentiment and subjectivity classifications, and a smaller impact on topic classification.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"Without sentiment, the Subjective embeddings prove more robust, still outperforming the Objective on sentiment classification, while the Objective performs close to random word embeddings on Amazon .
",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"In summary, evidences from the series of controlled experiments support the existence of some X-factor to the Subjective embeddings, which confers superior performance in subjectivity-sensitive tasks such as sentiment classification.",3 Comparative Analyses of Subjective vs. Objective Corpora,[0],[0]
"To leverage the consequential sentiment information, we propose a family of methods, called SentiVec, for training distributional word embeddings that are infused with information on the sentiment polarity of words.",4 Sentiment-Infused Word Embeddings,[0],[0]
"The methods are built upon Word2Vec optimization algorithm and make use of available lexical sentiment resources such as SentiWordNet (Baccianella et al., 2010), sentiment lexicon by Hu and Liu (2004), and etc.
SentiVec seeks to satisfy two objectives, namely context prediction and lexical category prediction:
logL = logLword2vec(W ;C) + λ logLlex(W,L), (5)
where Lword2vec(W ;C) is the Skip-gram objective as in (4); Llex(W,L) is a lexical objective for corpus W and lexical resource L; and λ is a tradeoff parameter.",4 Sentiment-Infused Word Embeddings,[0],[0]
"Lexical resource L = {Xi}ni=1 comprises of n word sets, each Xi contains words of the same category.",4 Sentiment-Infused Word Embeddings,[0],[0]
"For sentiment classification, we consider positive and negative word categories.",4 Sentiment-Infused Word Embeddings,[0],[0]
"Logistic SentiVec admits lexical resource in the form of two disjoint word sets, L = {X1, X2}, X1 ∩X2 = ∅.",4.1 Logistic SentiVec,[0],[0]
"The objective is to tell apart which word set of L word w belongs to:
logLlex(W,L) (6) = ∑ w∈X1 log P(w ∈ X1) +",4.1 Logistic SentiVec,[0],[0]
∑,4.1 Logistic SentiVec,[0],[0]
"w∈X2 log P(w ∈ X2).
",4.1 Logistic SentiVec,[0],[0]
"We further tie these probabilities together, and cast the objective as a logistic regression problem:
P(w ∈ X1) = 1− P(w ∈ X2) = σ(vw · τ), (7)
where vw is a word embedding and τ is a direction vector.",4.1 Logistic SentiVec,[0],[0]
"Since word embeddings are generally invariant to scaling and rotation when used as downstream feature representations, τ can be chosen randomly and fixed during training.",4.1 Logistic SentiVec,[0],[0]
"We
experiment with randomly sampled unit length directions.",4.1 Logistic SentiVec,[0],[0]
"For simplicity, we also scale embedding vw to its unit length when computing vw ·τ , which now equals to cosine similarity between vw and τ .
",4.1 Logistic SentiVec,[0],[0]
"When vw is completely aligned with τ , the cosine similarity between them is 1, which maximizes P(w ∈ X1) and favors words in X1.",4.1 Logistic SentiVec,[0],[0]
"When vw is opposite to τ , the cosine similarity equals to −1, which maximizes P(w ∈ X2) and predicts vectors from X2.",4.1 Logistic SentiVec,[0],[0]
"Orthogonal vectors have cosine similarity of 0, which makes both w ∈ X1 and w ∈ X2 equally probable.",4.1 Logistic SentiVec,[0],[0]
"Optimizing (6) makes the corresponding word embeddings ofX1 andX2 gravitate to the opposite semispaces and simulates clustering effect for the words of the same category, while the Word2Vec objective prevents words from collapsing to the same directions.
",4.1 Logistic SentiVec,[0],[0]
Optimization The objective in (6) permits simple stochastic gradient ascent optimization and can be combined with negative sampling procedure for Skip-gram in (5).,4.1 Logistic SentiVec,[0],[0]
The gradient for unnormalized embedding vw is solved as follows:(,4.1 Logistic SentiVec,[0],[0]
"logL[w∈X1](D,L) )′",4.1 Logistic SentiVec,[0],[0]
vwi =,4.1 Logistic SentiVec,[0],[0]
"(log P (x ∈ X1))′vwi
= 1
‖vw‖2 σ",4.1 Logistic SentiVec,[0],[0]
( −vw · τ ‖vw‖ ),4.1 Logistic SentiVec,[0],[0]
( τi ‖vw‖,4.1 Logistic SentiVec,[0],[0]
"− vwi vw · τ ‖vw‖ ) (8)
The optimization equation for vw, when w ∈ X2, can be derived analogously.",4.1 Logistic SentiVec,[0],[0]
"Spherical SentiVec extends Logistic SentiVec by dealing with any number of lexical categories, L = {Xi}ni=1.",4.2 Spherical SentiVec,[0],[0]
"As such, the lexical objective takes on generic form:
logLlex(W,L)",4.2 Spherical SentiVec,[0],[0]
= n∑ i=1,4.2 Spherical SentiVec,[0],[0]
"∑ w∈Xi log P (w ∈ Xi), (9)
Each P (w ∈ Xi) defines embedding generating process.",4.2 Spherical SentiVec,[0],[0]
We assume each length-normalized vw for w of L is generated w.r.t.,4.2 Spherical SentiVec,[0],[0]
a mixture model of von Mises-Fisher (vMF) distributions.,4.2 Spherical SentiVec,[0],[0]
"vMF is a probability distribution on a multidimensional sphere, characterized by parameters µ (mean direction) and κ (concentration parameter).",4.2 Spherical SentiVec,[0],[0]
"Sampled points are concentrated around µ; the greater the κ, the closer the sampled points are to µ. We consider only unimodal vMF distributions, restricting concentration parameters to be strictly positive.",4.2 Spherical SentiVec,[0],[0]
"Hereby, each Xi ∈ L is assigned to vMF
distribution parameters (µi, κi) and the membership probabilities are defined as follows:
P(w ∈ Xi) =",4.2 Spherical SentiVec,[0],[0]
"P (vw;µi, κi) = 1",4.2 Spherical SentiVec,[0],[0]
"Zκi eκiµi·vw ,
(10)
where Zκ is the normalization factor.",4.2 Spherical SentiVec,[0],[0]
The Spherical SentiVec lexical objective forces words of every Xi ∈ L to gravitate towards and concentrate around their direction mean µi.,4.2 Spherical SentiVec,[0],[0]
"As in Logistic SentiVec, it simulates clustering effect for the words of the same set.",4.2 Spherical SentiVec,[0],[0]
"In comparison to the direction vector of Logistic SentiVec, mean directions of Spherical SentiVec when fixed can substantially influence word embeddings training and must be carefully selected.",4.2 Spherical SentiVec,[0],[0]
We optimize the mean directions along with the word embeddings using alternating procedure resembling K-means clustering algorithm.,4.2 Spherical SentiVec,[0],[0]
"For simplicity, we keep concentration parameters tied, κ1 = κ2 = ... = κn = κ, and treat κ as a hyperparameter of this algorithm.
",4.2 Spherical SentiVec,[0],[0]
Optimization We derive optimization procedure for updating word embeddings assuming fixed direction means.,4.2 Spherical SentiVec,[0],[0]
"Like Logistic SentiVec, Spherical SentiVec can be combined with the negative sampling procedure of Skip-gram.",4.2 Spherical SentiVec,[0],[0]
"The gradient for unnormalized word embedding vw is solved by the following equation:
( logL[w∈Xi] (W,L) )′",4.2 Spherical SentiVec,[0],[0]
"vwj = κi
( µij ‖vw‖",4.2 Spherical SentiVec,[0],[0]
"− vwj vw·µi‖vw‖ ) ‖vw‖2
(11)
",4.2 Spherical SentiVec,[0],[0]
"Once word embedding vw (w ∈ Xi) is updated, we revise direction mean µi w.r.t.",4.2 Spherical SentiVec,[0],[0]
"maximum likelihood estimator:
µi = ∑ w∈Xi vw∥∥∥∑w∈Xi vw∥∥∥ .",4.2 Spherical SentiVec,[0],[0]
"(12)
Updating the direction means in such a way ensures that the lexical objective is non-decreasing.",4.2 Spherical SentiVec,[0],[0]
"Assuming the stochastic optimization procedure for Lword2vec complies with the same nondecreasing property, the proposed alternating procedure converges.",4.2 Spherical SentiVec,[0],[0]
There have been considerable research on improving the quality of distributional word embeddings.,5 Related Work,[0],[0]
Bolukbasi et al. (2016) seek to debias word embeddings from gender stereotypes.,5 Related Work,[0],[0]
"Rothe and Schütze (2017) incorporate WordNet
lexeme and synset information.",5 Related Work,[0],[0]
Mrkšic et al. (2016) encode antonym-synonym relations.,5 Related Work,[0],[0]
Liu et al. (2015) encode ordinal relations such as hypernym and hyponym.,5 Related Work,[0],[0]
"Kiela et al. (2015) augment Skip-gram to enforce lexical similarity or relatedness constraints, Bollegala et al. (2016) modify GloVe optimization procedure for the same purpose.",5 Related Work,[0],[0]
"Faruqui et al. (2015) employ semantic relations of PPDB, WordNet, FrameNet to retrofit word embeddings for various prediction tasks.",5 Related Work,[0],[0]
"We use this Retrofitting method7 as a baseline.
",5 Related Work,[0],[0]
"Socher et al. (2011) derive multi-word embeddings for sentiment distribution prediction, while we focus on lexical distributional analysis.",5 Related Work,[0],[0]
"Maas et al. (2011) and Tang et al. (2016) use documentlevel sentiment annotations to fit word embeddings, but document annotation might not always be available for distributional analysis on neutral corpora such as Wikipedia.",5 Related Work,[0],[0]
SentiVec relies on simple sentiment lexicon instead.,5 Related Work,[0],[0]
"Refining (Yu et al., 2018) aligns the sentiment scores taken from lexical resource and the cosine similarity scores of corresponding word embeddings.",5 Related Work,[0],[0]
"The method generally requires fine-grained sentiment scores for the words, which may not be available in some settings.",5 Related Work,[0],[0]
"We use Refining as a baseline and adopt coarse-grained sentiment lexicon for this method.
",5 Related Work,[0],[0]
"Villegas et al. (2016) compare various distributional word embeddings arising from the same corpus for sentiment classification, whereas we focus on the differentiation in input corpora and propose novel sentiment-infused word embeddings.",5 Related Work,[0],[0]
The objective of experiments is to study the efficacy of Logistic SentiVec and Spherical SentiVec word embeddings on the aforementioned text classification tasks.,6 Experiments,[0],[0]
"One natural baseline is Word2Vec, as SentiVec subsumes its context prediction objective, while further incorporating lexical category prediction.",6 Experiments,[0],[0]
"We include two other baselines that can leverage the same lexical resource but in manners different from SentiVec, namely: Retrofitting (Faruqui et al., 2015) and Refining (Yu et al., 2018).",6 Experiments,[0],[0]
"For these methods, we generate their word embeddings based on Setup III (see Section 3).",6 Experiments,[0],[0]
"All the methods were run multiple times with various hyperparameters, optimized via grid-search; for each we present the best performing setting.
",6 Experiments,[0],[0]
"7Original code is available at: https://github. com/mfaruqui/retrofitting
First, we discuss the sentiment classification task.",6 Experiments,[0],[0]
"Table 4 shows the unfolded results for the 24 classification datasets of Amazon, as well as for Rotten Tomatoes.",6 Experiments,[0],[0]
"For each classification dataset (row), and for the Objective and Subjective embedding corpora respectively, the best word embedding methods are shown in bold.",6 Experiments,[0],[0]
An asterisk indicates statistically significant8 results at 5% in comparison to Word2Vec.,6 Experiments,[0],[0]
Both SentiVec variants outperform Word2Vec in the vast majority of the cases.,6 Experiments,[0],[0]
The degree of outperformance is higher for the Objective than the Subjective word embeddings.,6 Experiments,[0],[0]
This is a reasonable trend given our previous findings in Section 3.,6 Experiments,[0],[0]
"As the Objective Corpus encodes less information than the Subjective Corpus for sentiment classification, the former is more likely to benefit from the infusion of sentiment information from additional lexical resources.",6 Experiments,[0],[0]
"Note that the sentiment infusion into the word embeddings comes from separate lexical resources, and does not involve any sentiment classification label.
",6 Experiments,[0],[0]
SentiVec also outperforms the two baselines that benefit from the same lexical resources.,6 Experiments,[0],[0]
"Retrofitting does not improve upon Word2Vec, with the two embeddings essentially indistinguishable (the difference is only noticeable at the second decimal point).",6 Experiments,[0],[0]
Refining makes the word embeddings perform worse on the sentiment classification task.,6 Experiments,[0],[0]
"One possible explanation is that Refining normally requires fine-grained labeled lexicon, where the words are scored w.r.t.",6 Experiments,[0],[0]
"the sentiment scale, whereas we use sentiment lexicon of two labels (i.e., positive or negative).",6 Experiments,[0],[0]
"SentiVec accepts coarse-grained sentiment lexicons, and potentially could be extended to deal with fine-grained labels.
",6 Experiments,[0],[0]
"As previously alluded to, topic and subjectivity classifications are less sensitive to the subjectivity within word embeddings than sentiment classification.",6 Experiments,[0],[0]
"One therefore would not expect much, if any, performance gain from infusion of sentiment information.",6 Experiments,[0],[0]
"However, such infusion should not subtract or harm the quality of word embeddings either.",6 Experiments,[0],[0]
"Table 5 shows that the unfolded results for topic classification on the six datasets, and the result for subjectivity classification are similar across methods.",6 Experiments,[0],[0]
"Neither the SentiVec variants, nor Retrofitting and Refining, change the subjectivity and topic classification capabilities much, which means that the used sentiment lexicon is targeted only at the sentiment subspace of embeddings.
",6 Experiments,[0],[0]
"8We use paired t-test to compute p-value.
",6 Experiments,[0],[0]
"Illustrative Changes in Embeddings To give more insights on the difference between SentiVec and Word2Vec, we show “flower” diagrams in Figure 1 for Logistic SentiVec and Figure 2 for Spherical SentiVec.",6 Experiments,[0],[0]
"Each is associated with a reference word (e.g., good for Figure 1a), and indicates relative changes in cosine distances between the reference word and the testing words surrounding the “flower”.",6 Experiments,[0],[0]
Every testing word is associated with a “petal” or black axis extending from the center of the circle.,6 Experiments,[0],[0]
"The “petal” length is proportional to the relative distance change in two word embeddings: κ =
dSentiV ec(wref ,wtesting) dword2vec(wref ,wtesting)
, where dSentiV ec and dword2vec are cosine distances between reference wref and testing wtesting words in SentiVec and Word2Vec embeddings correspondingly.",6 Experiments,[0],[0]
"If the distance remains unchanged (κ = 1), then the “petal” points at the circumference; if the reference and testing words are closer in the SentiVec embedding
than they are in Word2Vec (κ < 1), the “petal” lies inside the circle; when the distance increases (κ > 1), the “petal” goes beyond the circle.
",6 Experiments,[0],[0]
The diagrams are presented for Objective Embeddings9.,6 Experiments,[0],[0]
"We use three reference words: good (positive), bad (negative), time (neutral); as well as three groups of testing words: green for words randomly sampled from positive lexicon (Sector I-II), red for words randomly sampled from negative lexicon (Sector II-III), and gray for frequent neutral common nouns (Sector III-I).
",6 Experiments,[0],[0]
Figure 1 shows changes produced by Logistic SentiVec.,6 Experiments,[0],[0]
"For the positive reference word (Figure 1a), the average distance to the green words is shortened, whereas the distance to the red words increases.",6 Experiments,[0],[0]
The reverse is observed for the negative reference word (Figure 1b).,6 Experiments,[0],[0]
"This observation
9The diagrams for Subjective Embeddings show the same trend, with the moderate changes.
",6 Experiments,[0],[0]
"complies with the lexical objective (7) of Logistic SentiVec, which aims to separate the words of two different classes.",6 Experiments,[0],[0]
Note that the gray words suffer only moderate change with respect to positive and negative reference words.,6 Experiments,[0],[0]
"For the neutral reference word (Figure 1c), the distances are only moderately affected across all testing groups.
",6 Experiments,[0],[0]
Figure 2 shows that Spherical SentiVec tends to make embeddings more compact than Logistic SentiVec.,6 Experiments,[0],[0]
"As the former’s lexical objective (9) is designed for clustering, but not for separation, we look at the comparative strength of the clustering effect on the testing words.",6 Experiments,[0],[0]
"For the positive reference word (Figure 2a), the largest clustering effect is achieved for the green words.",6 Experiments,[0],[0]
"For the negative reference word (Figure 2b), as expected, the red words are affected the most.",6 Experiments,[0],[0]
"The gray words suffer the least change for all the reference words.
",6 Experiments,[0],[0]
"In summary, SentiVec effectively provides an advantage for subjectivity-sensitive task such as sentiment classification, while not harming the performance of other text classification tasks.",6 Experiments,[0],[0]
"We explore the differences between objective and subjective corpora for generating word embeddings, and find that there is indeed a difference in the embeddings’ classification task performances.",7 Conclusion,[0],[0]
"Identifying the presence of sentiment words as one key factor for the difference, we propose a novel method SentiVec to train word embeddings that are infused with the sentiment polarity of words derived from a separate sentiment lexicon.",7 Conclusion,[0],[0]
We further identify two lexical objectives: Logistic SentiVec and Spherical SentiVec.,7 Conclusion,[0],[0]
"The proposed word embeddings show improvements in sentiment classification, while maintaining their performance on subjectivity and topic classifications.",7 Conclusion,[0],[0]
"This research is supported by the National Research Foundation, Prime Minister’s Office, Singapore under its NRF Fellowship Programme (Award No.",Acknowledgments,[0],[0]
NRF-NRFF2016-07).,Acknowledgments,[0],[0]
"We explore the notion of subjectivity, and hypothesize that word embeddings learnt from input corpora of varying levels of subjectivity behave differently on natural language processing tasks such as classifying a sentence by sentiment, subjectivity, or topic.",abstractText,[0],[0]
"Through systematic comparative analyses, we establish this to be the case indeed.",abstractText,[0],[0]
"Moreover, based on the discovery of the outsized role that sentiment words play on subjectivity-sensitive tasks such as sentiment classification, we develop a novel word embedding SentiVec which is infused with sentiment information from a lexical resource, and is shown to outperform baselines on such tasks.",abstractText,[0],[0]
Searching for the X-Factor: Exploring Corpus Subjectivity for Word Embeddings,title,[0],[0]
"Many natural language processing (NLP) tasks require human supervision to be useful in practice, be it to collect suitable training material or to meet some desired output quality.",1 Introduction,[0],[0]
"Given the high cost of human intervention, how to minimize the supervision effort is an important research problem.",1 Introduction,[0],[0]
"Previous works in areas such as active learning, post edit-
ing, and interactive pattern recognition have investigated this question with notable success (Settles, 2008; Specia, 2011; González-Rubio et al., 2010).
",1 Introduction,[0],[0]
"The most common framework for efficient annotation in the NLP context consists of training an NLP system on a small amount of baseline data, and then running the system on unannotated data to estimate confidence scores of the system’s predictions (Settles, 2008).",1 Introduction,[0],[0]
Sentences with the lowest confidence are then used as the data to be annotated (Figure 1 (a)).,1 Introduction,[0],[0]
"However, it has been noted that when the NLP system in question already has relatively high accuracy, annotating entire sentences can be wasteful, as most words will already be correct (Tomanek and Hahn, 2009; Neubig et al., 2011).",1 Introduction,[0],[0]
"In these cases, it is possible to achieve much higher benefit per annotated word by annotating sub-sentential units (Figure 1 (b)).
",1 Introduction,[0],[0]
"However, as Settles et al. (2008) point out, simply maximizing the benefit per annotated instance is not enough, as the real supervision effort varies
169
Transactions of the Association for Computational Linguistics, 2 (2014) 169–180.",1 Introduction,[0],[0]
Action Editor: Eric Fosler-Lussier.,1 Introduction,[0],[0]
Submitted 11/2013; Revised 2/2014; Published 4/2014.,1 Introduction,[0],[0]
"c©2014 Association for Computational Linguistics.
greatly across instances.",1 Introduction,[0],[0]
"This is particularly important in the context of choosing segments to annotate, as human annotators heavily rely on semantics and context information to process language, and intuitively, a consecutive sequence of words can be supervised faster and more accurately than the same number of words spread out over several locations in a text.",1 Introduction,[0],[0]
"This intuition can also be seen in our empirical data in Figure 2, which shows that for the speech transcription and word segmentation tasks described later in Section 5, short segments had a longer annotation time per word.",1 Introduction,[0],[0]
"Based on this fact, we argue it would be desirable to present the annotator with a segmentation of the data into easily supervisable chunks that are both large enough to reduce the number of context switches, and small enough to prevent unnecessary annotation (Figure 1 (c)).
",1 Introduction,[0],[0]
"In this paper, we introduce a new strategy for natural language supervision tasks that attempts to optimize supervision efficiency by choosing an appropriate segmentation.",1 Introduction,[0],[0]
"It relies on a user model that, given a specific segment, predicts the cost and the utility of supervising that segment.",1 Introduction,[0],[0]
"Given this user model, the goal is to find a segmentation that minimizes the total predicted cost while maximizing the utility.",1 Introduction,[0],[0]
"We balance these two criteria by defining a constrained optimization problem in which one criterion is the optimization objective, while the other criterion is used as a constraint.",1 Introduction,[0],[0]
"Doing so allows specifying practical optimization goals such as “remove as many errors as possible given a limited time budget,” or “annotate data to obtain some required classifier accuracy in as little time as possible.”
",1 Introduction,[0],[0]
"Solving this optimization task is computationally
difficult, an NP-hard problem.",1 Introduction,[0],[0]
"Nevertheless, we demonstrate that by making realistic assumptions about the segment length, an optimal solution can be found using an integer linear programming formulation for mid-sized corpora, as are common for supervised annotation tasks.",1 Introduction,[0],[0]
"For larger corpora, we provide simple heuristics to obtain an approximate solution in a reasonable amount of time.
",1 Introduction,[0],[0]
"Experiments over two example scenarios demonstrate the usefulness of our method: Post editing for speech transcription, and active learning for Japanese word segmentation.",1 Introduction,[0],[0]
"Our model predicts noticeable efficiency gains, which are confirmed in experiments with human annotators.",1 Introduction,[0],[0]
The goal of our method is to find a segmentation over a corpus of word tokens wN1 that optimizes supervision efficiency according to some predictive user model.,2 Problem Definition,[0],[0]
"The user model is denoted as a set of functions ul,k(wba) that evaluate any possible subsequence wba of tokens in the corpus according to criteria l2L, and supervision modes k2K.
Let us illustrate this with an example.",2 Problem Definition,[0],[0]
"Sperber et al. (2013) defined a framework for speech transcription in which an initial, erroneous transcript is created using automatic speech recognition (ASR), and an annotator corrects the transcript either by correcting the words by keyboard, by respeaking the content, or by leaving the words as is.",2 Problem Definition,[0],[0]
"In this case, we could define K={TYPE, RESPEAK, SKIP}, each constant representing one of these three supervision modes.",2 Problem Definition,[0],[0]
"Our method will automatically determine the appropriate supervision mode for each segment.
",2 Problem Definition,[0],[0]
"The user model in this example might evaluate every segment according to two criteria L, a cost criterion (in terms of supervision time) and a utility criterion (in terms of number of removed errors), when using each mode.",2 Problem Definition,[0],[0]
"Intuitively, respeaking should be assigned both lower cost (because speaking is faster than typing), but also lower utility than typing on a keyboard (because respeaking recognition errors can occur).",2 Problem Definition,[0],[0]
"The SKIP mode denotes the special, unsupervised mode that always returns 0 cost and 0 utility.
",2 Problem Definition,[0],[0]
"Other possible supervision modes include multiple input modalities (Suhm et al., 2001), several human annotators with different expertise and cost
(Donmez and Carbonell, 2008), and correction vs. translation from scratch in machine translation (Specia, 2011).",2 Problem Definition,[0],[0]
"Similarly, cost could instead be expressed in monetary terms, or the utility function could predict the improvement of a classifier when the resulting annotation is not intended for direct human consumption, but as training data for a classifier in an active learning framework.",2 Problem Definition,[0],[0]
"Given this setting, we are interested in simultaneously finding optimal locations and supervision modes for all segments, according to the given criteria.",3 Optimization Framework,[0],[0]
Each resulting segment will be assigned exactly one of these supervision modes.,3 Optimization Framework,[0],[0]
"We denote a segmentation of the N tokens of corpus wN1 into MN segments by specifying segment boundary markers sM+11 =(s1=1, s2, . . .",3 Optimization Framework,[0],[0]
", sM+1=N+1).",3 Optimization Framework,[0],[0]
Setting a boundary marker si=a means that we put a segment boundary before the a-th word token (or the end-of-corpus marker for a=N+1).,3 Optimization Framework,[0],[0]
Thus our corpus is segmented into token sequences,3 Optimization Framework,[0],[0]
"[(wsj , . .",3 Optimization Framework,[0],[0]
.,3 Optimization Framework,[0],[0]
", wsj+1 1)]",3 Optimization Framework,[0],[0]
M j=1.,3 Optimization Framework,[0],[0]
The supervision modes assigned to each segment are denoted by mj .,3 Optimization Framework,[0],[0]
"We favor those segmentations that minimize the cumulative value PM j=1[ul,mj (w sj+1 sj )] for each criterion l. For any criterion where larger values are intuitively better, we flip the sign before defining ul,mj (w sj+1 sj ) to maintain consistency (e.g. negative number of errors removed).",3 Optimization Framework,[0],[0]
"In the case of a single criterion (|L|=1), we obtain a simple, single-objective unconstrained linear optimization problem, efficiently solvable via dynamic programming (Terzi and Tsaparas, 2006).",3.1 Multiple Criteria Optimization,[0],[0]
"However, in practice one usually encounters several competing criteria, such as cost and utility, and here we will focus on this more realistic setting.",3.1 Multiple Criteria Optimization,[0],[0]
"We balance competing criteria by using one as an optimization objective, and the others as constraints.1 Let crite-
1This approach is known as the bounded objective function method in multi-objective optimization literature (Marler and Arora, 2004).",3.1 Multiple Criteria Optimization,[0],[0]
"The very popular weighted sum method merges criteria into a single efficiency measure, but is problematic in our case because the number of supervised tokens is unspecified.",3.1 Multiple Criteria Optimization,[0],[0]
"Unless the weights are carefully chosen, the algorithm might find, e.g., the completely unsupervised or completely su-
rion l0 be the optimization objective criterion, and let Cl denote the constraining constants for the criteria l 2 L l0 = L \ {l0}.",3.1 Multiple Criteria Optimization,[0],[0]
"We state the optimization problem:
min M ;sM+11 ;m M 1
MX
j=1
⇥ ul0,mj",3.1 Multiple Criteria Optimization,[0],[0]
"w sj+1 sj ⇤
s.t.",3.1 Multiple Criteria Optimization,[0],[0]
"MX
j=1
⇥",3.1 Multiple Criteria Optimization,[0],[0]
"ul,mj w sj+1",3.1 Multiple Criteria Optimization,[0],[0]
sj,3.1 Multiple Criteria Optimization,[0],[0]
"⇤  Cl (8l 2 L l0)
",3.1 Multiple Criteria Optimization,[0],[0]
This constrained optimization problem is difficult to solve.,3.1 Multiple Criteria Optimization,[0],[0]
"In fact, the NP-hard multiple-choice knapsack problem (Pisinger, 1994) corresponds to a special case of our problem in which the number of segments is equal to the number of tokens, implying that our more general problem is NP-hard as well.
",3.1 Multiple Criteria Optimization,[0],[0]
"In order to overcome this problem, we reformulate search for the optimal segmentation as a resource-constrained shortest path problem in a directed, acyclic multigraph.",3.1 Multiple Criteria Optimization,[0],[0]
"While still not efficiently solvable in theory, this problem is well studied in domains such as vehicle routing and crew scheduling (Irnich and Desaulniers, 2005), and it is known that in many practical situations the problem can be solved reasonably efficiently using integer linear programming relaxations (Toth and Vigo, 2001).
",3.1 Multiple Criteria Optimization,[0],[0]
"In our formalism, the set of nodes V represents the spaces between neighboring tokens, at which the algorithm may insert segment boundaries.",3.1 Multiple Criteria Optimization,[0],[0]
"A node with index i represents a segment break before the i-th token, and thus the sequence of the indices in a path directly corresponds to sM+11 .",3.1 Multiple Criteria Optimization,[0],[0]
"Edges E denote the grouping of tokens between the respective
pervised segmentation to be most “efficient.”
nodes into one segment.",3.1 Multiple Criteria Optimization,[0],[0]
"Edges are always directed from left to right, and labeled with a supervision mode.",3.1 Multiple Criteria Optimization,[0],[0]
"In addition, each edge between nodes i and j is assigned ul,k(w",3.1 Multiple Criteria Optimization,[0],[0]
"j 1 i ), the corresponding predicted value for each criterion l 2 L and supervision mode k 2 K, indicating that the supervision mode of the j-th segment in a path directly corresponds to mj .
",3.1 Multiple Criteria Optimization,[0],[0]
Figure 3 shows an example of what the resulting graph may look like.,3.1 Multiple Criteria Optimization,[0],[0]
"Our original optimization problem is now equivalent to finding the shortest path between the first and last nodes according to criterion l0, while obeying the given resource constraints.",3.1 Multiple Criteria Optimization,[0],[0]
"According to a widely used formulation for the resource constrained shortest path problem, we can define Eij as the set of competing edges between i and j, and express this optimization problem with the following integer linear program (ILP):
min x
X
i,j2V
X
k2Eij xijkul0,k(s
j 1 i ) (1)
s.t.",3.1 Multiple Criteria Optimization,[0],[0]
"X
i,j2V
X
k2Eij xijkul,k(s
j 1 i )  ",3.1 Multiple Criteria Optimization,[0],[0]
"Cl (8l 2 L l0) (2)
X
i2V k2Eij
xijk = X
i2V k2Eij
xjik
(8j 2 V \{1, n}) (3)
",3.1 Multiple Criteria Optimization,[0],[0]
"X
j2V k2E1j
x1jk",3.1 Multiple Criteria Optimization,[0],[0]
"= 1 (4)
X
i2V k2Ein
xink",3.1 Multiple Criteria Optimization,[0],[0]
"= 1 (5)
xijk 2 {0, 1} (8xijk 2 x) (6)
The variables x={xijk|i, j 2 V , k 2 Eij} denote the activation of the k’th edge between nodes i and j. The shortest path according to the minimization objective (1), that still meets the resource constraints for the specified criteria (2), is to be computed.",3.1 Multiple Criteria Optimization,[0],[0]
"The degree constraints (3,4,5) specify that all but the first and last nodes must have as many incoming as outgoing edges, while the first node must have exactly one outgoing, and the last node exactly one incoming edge.",3.1 Multiple Criteria Optimization,[0],[0]
"Finally, the integrality condition (6) forces all edges to be either fully activated or fully deactivated.",3.1 Multiple Criteria Optimization,[0],[0]
"The outlined problem formulation can solved
directly by using off-the-shelf ILP solvers, here we employ GUROBI (Gurobi Optimization, 2012).",3.1 Multiple Criteria Optimization,[0],[0]
"In general, edges are inserted for every supervision mode between every combination of two nodes.",3.2 Heuristics for Approximation,[0],[0]
The search space can be constrained by removing some of these edges to increase efficiency.,3.2 Heuristics for Approximation,[0],[0]
"In this study, we only consider edges spanning at most 20 tokens.
",3.2 Heuristics for Approximation,[0],[0]
"For cases in which larger corpora are to be annotated, or when the acceptable delay for delivering results is small, a suitable segmentation can be found approximately.",3.2 Heuristics for Approximation,[0],[0]
"The easiest way would be to partition the corpus, e.g. according to its individual documents, divide the budget constraints evenly across all partitions, and then segment each partition independently.",3.2 Heuristics for Approximation,[0],[0]
"More sophisticated methods might approximate the Pareto front for each partition, and distribute the budgets in an intelligent way.",3.2 Heuristics for Approximation,[0],[0]
"While the proposed framework is able to optimize the segmentation with respect to each criterion, it also rests upon the assumption that we can provide user models ul,k(w j 1 i ) that accurately evaluate every segment according to the specified criteria and supervision modes.",4 User Modeling,[0],[0]
"In this section, we discuss our strategies for estimating three conceivable criteria: annotation cost, correction of errors, and improvement of a classifier.",4 User Modeling,[0],[0]
"Modeling cost requires solving a regression problem from features of a candidate segment to annotation cost, for example in terms of supervision time.",4.1 Annotation Cost Modeling,[0],[0]
"Appropriate input features depend on the task, but should include notions of complexity (e.g. a confidence measure) and length of the segment, as both are expected to strongly influence supervision time.
",4.1 Annotation Cost Modeling,[0],[0]
"We propose using Gaussian process (GP) regression for cost prediction, a start-of-the-art nonparametric Bayesian regression technique (Rasmussen and Williams, 2006)2.",4.1 Annotation Cost Modeling,[0],[0]
"As reported on a similar task by Cohn and Specia (2013), and confirmed by our preliminary experiments, GP regression significantly outperforms popular techniques such as sup-
2Code available at http://www.gaussianprocess.org/gpml/
port vector regression and least-squares linear regression.",4.1 Annotation Cost Modeling,[0],[0]
"We also follow their settings for GP, employing GP regression with a squared exponential kernel with automatic relevance determination.",4.1 Annotation Cost Modeling,[0],[0]
"Depending on the number of users and amount of training data available for each user, models may be trained separately for each user (as we do here), or in a combined fashion via multi-task learning as proposed by Cohn and Specia (2013).
",4.1 Annotation Cost Modeling,[0],[0]
It is also crucial for the predictions to be reliable throughout the whole relevant space of segments.,4.1 Annotation Cost Modeling,[0],[0]
"If the cost of certain types of segments is systematically underpredicted, the segmentation algorithm might be misled to prefer these, possibly a large number of times.3 An effective trick to prevent such underpredictions is to predict the log time instead of the actual time.",4.1 Annotation Cost Modeling,[0],[0]
"In this way, errors in the critical low end are penalized more strongly, and the time can never become negative.",4.1 Annotation Cost Modeling,[0],[0]
"As one utility measure, we can use the number of errors corrected, a useful measure for post editing tasks over automatically produced annotations.",4.2 Error Correction Modeling,[0],[0]
"In order to measure how many errors can be removed by supervising a particular segment, we must estimate both how many errors are in the automatic annotation, and how reliably a human can remove these for a given supervision mode.
",4.2 Error Correction Modeling,[0],[0]
Most machine learning techniques can estimate confidence scores in the form of posterior probabilities.,4.2 Error Correction Modeling,[0],[0]
"To estimate the number of errors, we can sum over one minus the posterior for all tokens, which estimates the Hamming distance from the reference annotation.",4.2 Error Correction Modeling,[0],[0]
"This measure is appropriate for tasks in which the number of tokens is fixed in advance (e.g. a part-of-speech estimation task), and a reasonable approximation for tasks in which the number of tokens is not known in advance (e.g. speech transcription, cf.",4.2 Error Correction Modeling,[0],[0]
"Section 5.1.1).
",4.2 Error Correction Modeling,[0],[0]
"Predicting the particular tokens at which a human will make a mistake is known to be a difficult task (Olson and Olson, 1990), but a simplifying constant
3For instance, consider a model that predicts well for segments of medium size or longer, but underpredicts the supervision time of single-token segments.",4.2 Error Correction Modeling,[0],[0]
"This may lead the segmentation algorithm to put every token into its own segment, which is clearly undesirable.
human error rate can still be useful.",4.2 Error Correction Modeling,[0],[0]
"For example, in the task from Section 2, we may suspect a certain number of errors in a transcript segment, and predict, say, 95% of those errors to be removed via typing, but only 85% via respeaking.",4.2 Error Correction Modeling,[0],[0]
Another reasonable utility measure is accuracy of a classifier trained on the data we choose to annotate in an active learning framework.,4.3 Classifier Improvement Modeling,[0],[0]
"Confidence scores have been found useful for ranking particular tokens with regards to how much they will improve a classifier (Settles, 2008).",4.3 Classifier Improvement Modeling,[0],[0]
"Here, we may similarly score segment utility as the sum of its token confidences, although care must be taken to normalize and calibrate the token confidences to be linearly comparable before doing so.",4.3 Classifier Improvement Modeling,[0],[0]
"While the resulting utility score has no interpretation in absolute terms, it can still be used as an optimization objective (cf. Section 5.2.1).",4.3 Classifier Improvement Modeling,[0],[0]
"In this section, we present experimental results examining the effectiveness of the proposed method over two tasks: speech transcription and Japanese word segmentation.4",5 Experiments,[0],[0]
"Accurate speech transcripts are a much-demanded NLP product, useful by themselves, as training material for ASR, or as input for follow-up tasks like speech translation.",5.1 Speech Transcription Experiments,[0],[0]
"With recognition accuracies plateauing, manually correcting (post editing) automatic speech transcripts has become popular.",5.1 Speech Transcription Experiments,[0],[0]
"Common approaches are to identify words (SanchezCortina et al., 2012) or (sub-)sentences (Sperber et al., 2013) of low confidence, and have a human editor correct these.",5.1 Speech Transcription Experiments,[0],[0]
"We conduct a user study in which participants post-edited speech transcripts, given a fixed goal word error rate.",5.1.1 Experimental Setup,[0],[0]
"The transcription setup was such that the transcriber could see the ASR transcript of parts before and after the segment that he was editing, providing context if needed.",5.1.1 Experimental Setup,[0],[0]
"When imprecise time alignment resulted in segment breaks that were
4Software and experimental data can be downloaded from http://www.msperber.com/research/tacl-segmentation/
slightly “off,” as happened occasionally, that context helped guess what was said.",5.1.1 Experimental Setup,[0],[0]
"The segment itself was transcribed from scratch, as opposed to editing the ASR transcript; besides being arguably more efficient when the ASR transcript contains many mistakes (Nanjo et al., 2006; Akita et al., 2009), preliminary experiments also showed that supervision time is far easier to predict this way.",5.1.1 Experimental Setup,[0],[0]
"Figure 4 illustrates what the setup looked like.
",5.1.1 Experimental Setup,[0],[0]
We used a self-developed transcription tool to conduct experiments.,5.1.1 Experimental Setup,[0],[0]
"It presents our computed segments one by one, allows convenient input and playback via keyboard shortcuts, and logs user interactions with their time stamps.",5.1.1 Experimental Setup,[0],[0]
"A selection of TED talks5 (English talks on technology, entertainment, and design) served as experimental data.",5.1.1 Experimental Setup,[0],[0]
"While some of these talks contain jargon such as medical terms, they are presented by skilled speakers, making them comparably easy to understand.",5.1.1 Experimental Setup,[0],[0]
"Initial transcripts were created using the Janus recognition toolkit (Soltau et al., 2001) with a standard, TEDoptimized setup.",5.1.1 Experimental Setup,[0],[0]
"We used confusion networks for decoding and obtaining confidence scores.
",5.1.1 Experimental Setup,[0],[0]
"For reasons of simplicity, and better comparability to our baseline, we restricted our experiment to two supervision modes: TYPE and SKIP.",5.1.1 Experimental Setup,[0],[0]
"We conducted experiments with 3 participants, 1 with several years of experience in transcription, 2 with none.",5.1.1 Experimental Setup,[0],[0]
"Each participant received an explanation on the transcription guidelines, and a short hands-on training to learn to use our tool.",5.1.1 Experimental Setup,[0],[0]
"Next, they transcribed a balanced selection of 200 segments of varying length and quality in random order.",5.1.1 Experimental Setup,[0],[0]
"This data was used to train the user models.
",5.1.1 Experimental Setup,[0],[0]
"Finally, each participant transcribed another 2 TED talks, with word error rate (WER) 19.96% (predicted: 22.33%).",5.1.1 Experimental Setup,[0],[0]
"We set a target (predicted) WER of 15% as our optimization constraint,6 and minimize the predicted supervision time as our objective function.",5.1.1 Experimental Setup,[0],[0]
"Both TED talks were transcribed once using the baseline strategy, and once using the proposed strategy.",5.1.1 Experimental Setup,[0],[0]
"The order of both strategies was reversed between talks, to minimize learning bias due to transcribing each talk twice.
",5.1.1 Experimental Setup,[0],[0]
"The baseline strategy was adopted according to 5www.ted.com 6Depending on the level of accuracy required by our final
application, this target may be set lower or higher.
",5.1.1 Experimental Setup,[0],[0]
"Sperber et al. (2013): We segmented the talk into natural, subsentential units, using Matusov et al. (2006)’s segmenter, which we tuned to reproduce the TED subtitle segmentation, producing a mean segment length of 8.6 words.",5.1.1 Experimental Setup,[0],[0]
"Segments were added in order of increasing average word confidence, until the user model predicted a WER<15%.",5.1.1 Experimental Setup,[0],[0]
"The second segmentation strategy was the proposed method, similarly with a resource constraint of WER<15%.
",5.1.1 Experimental Setup,[0],[0]
"Supervision time was predicted via GP regression (cf. Section 4.1), using segment length, audio duration, and mean confidence as input features.",5.1.1 Experimental Setup,[0],[0]
"The output variable was assumed subject to additive Gaussian noise with zero mean, a variance of 5 seconds was chosen empirically to minimize the mean squared error.",5.1.1 Experimental Setup,[0],[0]
Utility prediction (cf. Section 4.2) was based on posterior scores obtained from the confusion networks.,5.1.1 Experimental Setup,[0],[0]
"We found it important to calibrate them, as the posteriors were overconfident especially in the upper range.",5.1.1 Experimental Setup,[0],[0]
"To do so, we automatically transcribed a development set of TED data, grouped the recognized words into buckets according to their posteriors, and determined the average number of errors per word in each bucket from an alignment with the reference transcript.",5.1.1 Experimental Setup,[0],[0]
The mapping from average posterior to average number of errors was estimated via GP regression.,5.1.1 Experimental Setup,[0],[0]
"The result was summed over all tokens, and multiplied by a constant human confidence, separately determined for each participant.7",5.1.1 Experimental Setup,[0],[0]
"To convey a better understanding of the potential gains afforded by our method, we first present a simulated experiment.",5.1.2 Simulation Results,[0],[0]
"We assume a transcriber who makes no mistakes, and needs exactly the amount of time predicted by a user model trained on the data of a randomly selected participant.",5.1.2 Simulation Results,[0],[0]
"We compare three scenarios: A baseline simulation, in which the baseline segments are transcribed in ascending order of confidence; a simulation using the proposed method, in which we change the WER constraint in small increments; finally, an oracle simulation, which uses
7More elaborate methods for WER estimation exist, such as by Ogawa et al. (2013), but if our method achieves improvements using simple Hamming distance, incorporating more sophisticated measures will likely achieve similar, or even better accuracy.
",5.1.2 Simulation Results,[0],[0]
"the proposed method, but uses a utility model that knows the actual number of errors in each segment.",5.1.2 Simulation Results,[0],[0]
"For each supervised segment, we simply replace the ASR output with the reference, and measure the resulting WER.
",5.1.2 Simulation Results,[0],[0]
"Figure 5 shows the simulation on an example TED talk, based on an initial transcript with 21.9% WER.",5.1.2 Simulation Results,[0],[0]
"The proposed method is able to reduce the WER faster than the baseline, up to a certain point where they converge.",5.1.2 Simulation Results,[0],[0]
"The oracle simulation is even faster, indicating room for improvement through better confidence scores.",5.1.2 Simulation Results,[0],[0]
Table 1 shows the results of the user study.,5.1.3 User Study Results,[0],[0]
"First, we note that the WER estimation by our utility model was off by about 2.5%: While the predicted improvement in WER was from 22.33% to 15.0%, the actual improvement was from 19.96% to about 12.5%.",5.1.3 User Study Results,[0],[0]
"The actual resulting WER was consistent
across all users, and we observe strong, consistent reductions in supervision time for all participants.",5.1.3 User Study Results,[0],[0]
Prediction of the necessary supervision time was accurate:,5.1.3 User Study Results,[0],[0]
"Averaged over participants, 45:41 minutes were predicted for the baseline, 44:22 minutes measured.",5.1.3 User Study Results,[0],[0]
"For the proposed method, 32:11 minutes were predicted, 33:37 minutes measured.",5.1.3 User Study Results,[0],[0]
"On average, participants removed 6.68 errors per minute using the baseline, and 8.93 errors per minute using the proposed method, a speed-up of 25.2%.
",5.1.3 User Study Results,[0],[0]
"Note that predicted and measured values are not strictly comparable: In the experiments, to provide a fair comparison participants transcribed the same talks twice (once using baseline, once the proposed method, in alternating order), resulting in a noticeable learning effect.",5.1.3 User Study Results,[0],[0]
"The user model, on the other hand, is trained to predict the case in which a transcriber conducts only one transcription pass.
",5.1.3 User Study Results,[0],[0]
"As an interesting finding, without being informed about the order of baseline and proposed method, participants reported that transcribing according to the proposed segmentation seemed harder, as they found the baseline segmentation more linguistically reasonable.",5.1.3 User Study Results,[0],[0]
"However, this perceived increase in difficulty did not show in efficiency numbers.",5.1.3 User Study Results,[0],[0]
"Word segmentation is the first step in NLP for languages that are commonly written without word boundaries, such as Japanese and Chinese.",5.2 Japanese Word Segmentation Experiments,[0],[0]
We apply our method to a task in which we domain-adapt a word segmentation classifier via active learning.,5.2 Japanese Word Segmentation Experiments,[0],[0]
"In this experiment, participants annotated whether or not a word boundary occurred at certain positions in a Japanese sentence.",5.2 Japanese Word Segmentation Experiments,[0],[0]
The tokens to be grouped into segments are positions between adjacent characters.,5.2 Japanese Word Segmentation Experiments,[0],[0]
"Neubig et al. (2011) have proposed a pointwise method for Japanese word segmentation that can be trained using partially annotated sentences, which makes it attractive in combination with active learning, as well as our segmentation method.",5.2.1 Experimental Setup,[0],[0]
The authors released their method as a software package “KyTea” that we employed in this user study.,5.2.1 Experimental Setup,[0],[0]
"We used KyTea’s active learning domain adaptation toolkit8 as a baseline.
",5.2.1 Experimental Setup,[0],[0]
"For data, we used the Balanced Corpus of Contemporary Written Japanese (BCCWJ), created by Maekawa (2008), with the internet Q&A subcorpus as in-domain data, and the whitepaper subcorpus as background data, a domain adaptation scenario.",5.2.1 Experimental Setup,[0],[0]
"Sentences were drawn from the in-domain corpus, and the manually annotated data was then used to train KyTea, along with the pre-annotated background data.",5.2.1 Experimental Setup,[0],[0]
"The goal (objective function) was to improve KyTea’s classification accuracy on an indomain test set, given a constrained time budget of 30 minutes.",5.2.1 Experimental Setup,[0],[0]
There were again 2 supervision modes: ANNOTATE and SKIP.,5.2.1 Experimental Setup,[0],[0]
"Note that this is essentially a batch active learning setup with only one iteration.
",5.2.1 Experimental Setup,[0],[0]
"We conducted experiments with one expert with several years of experience with Japanese word segmentation annotation, and three non-expert native speakers with no prior experience.",5.2.1 Experimental Setup,[0],[0]
"Japanese word segmentation is not a trivial task, so we provided non-experts with training, including explanation of the segmentation standard, a supervised test with immediate feedback and explanations, and hands-on training to get used to the annotation software.
",5.2.1 Experimental Setup,[0],[0]
"Supervision time was predicted via GP regression (cf. Section 4.1), using the segment length and mean confidence as input features.",5.2.1 Experimental Setup,[0],[0]
"As before, the output variable was assumed subject to additive Gaussian noise with zero mean and 5 seconds variance.",5.2.1 Experimental Setup,[0],[0]
"To obtain training data for these models, each participant annotated about 500 example instances, drawn from the adaptation corpus, grouped into segments and balanced regarding segment length and difficulty.
",5.2.1 Experimental Setup,[0],[0]
"For utility modeling (cf. Section 4.3), we first normalized KyTea’s confidence scores, which are given in terms of SVM margin, using a sigmoid function (Platt, 1999).",5.2.1 Experimental Setup,[0],[0]
"The normalization parameter was se-
8http://www.phontron.com/kytea/active.html
lected so that the mean confidence on a development set corresponded to the actual classifier accuracy.",5.2.1 Experimental Setup,[0],[0]
We derive our measure of classifier improvement for correcting a segment by summing over one minus the calibrated confidence for each of its tokens.,5.2.1 Experimental Setup,[0],[0]
"To analyze how well this measure describes the actual training utility, we trained KyTea using the background data plus disjoint groups of 100 in-domain instances with similar probabilities and measured the achieved reduction of prediction errors.",5.2.1 Experimental Setup,[0],[0]
The correlation between each group’s mean utility and the achieved error reduction was 0.87.,5.2.1 Experimental Setup,[0],[0]
Note that we ignore the decaying returns usually observed as more data is added to the training set.,5.2.1 Experimental Setup,[0],[0]
"Also, we did not attempt to model user errors.",5.2.1 Experimental Setup,[0],[0]
"Employing a constant base error rate, as in the transcription scenario, would change segment utilities only by a constant factor, without changing the resulting segmentation.
",5.2.1 Experimental Setup,[0],[0]
"After creating the user models, we conducted the main experiment, in which each participant annotated data that was selected from a pool of 1000 in-domain sentences using two strategies.",5.2.1 Experimental Setup,[0],[0]
"The first, baseline strategy was as proposed by Neubig et al. (2011).",5.2.1 Experimental Setup,[0],[0]
Queries are those instances with the lowest confidence scores.,5.2.1 Experimental Setup,[0],[0]
"Each query is then extended to the left and right, until a word boundary is predicted.",5.2.1 Experimental Setup,[0],[0]
"This strategy follows similar reasoning as was the premise to this paper: To decide whether or not a position in a text corresponds to a word boundary, the annotator has to acquire surrounding context information.",5.2.1 Experimental Setup,[0],[0]
"This context acquisition is relatively time consuming, so he might as well label the surrounding instances with little additional effort.",5.2.1 Experimental Setup,[0],[0]
"The second strategy was our proposed, more principled approach.",5.2.1 Experimental Setup,[0],[0]
Queries of both methods were shuffled to minimize bias due to learning effects.,5.2.1 Experimental Setup,[0],[0]
"Finally, we trained KyTea using the results of both methods, and compared the achieved classifier improvement and supervision times.",5.2.1 Experimental Setup,[0],[0]
Table 2 summarizes the results of our experiment.,5.2.2 User Study Results,[0],[0]
"It shows that the annotations by each participant resulted in a better classifier for the proposed method than the baseline, but also took up considerably more time, a less clear improvement than for the transcription task.",5.2.2 User Study Results,[0],[0]
"In fact, the total error for time predictions was as high as 12.5% on average,
where the baseline method tended take less time than predicted, the proposed method more time.",5.2.2 User Study Results,[0],[0]
This is in contrast to a much lower total error (within 1%) when cross-validating our user model training data.,5.2.2 User Study Results,[0],[0]
"This is likely due to the fact that the data for training the user model was selected in a balanced manner, as opposed to selecting difficult examples, as our method is prone to do.",5.2.2 User Study Results,[0],[0]
"Thus, we may expect much better predictions when selecting user model training data that is more similar to the test case.
",5.2.2 User Study Results,[0],[0]
Plotting classifier accuracy over annotation time draws a clearer picture.,5.2.2 User Study Results,[0],[0]
Let us first analyze the results for the expert annotator.,5.2.2 User Study Results,[0],[0]
"Figure 6 (E.1) shows that the proposed method resulted in consistently better results, indicating that time predictions were still effective.",5.2.2 User Study Results,[0],[0]
"Note that this comparison may put the proposed method at a slight disadvantage by comparing intermediate results despite optimizing globally.
",5.2.2 User Study Results,[0],[0]
"For the non-experts, the improvement over the baseline is less consistent, as can be seen in Figure 6 (N.1) for one representative.",5.2.2 User Study Results,[0],[0]
"According to our analysis, this can be explained by two factors: (1) The non-experts’ annotation error (6.5% on average) was much higher than the expert’s (2.7%), resulting in a somewhat irregular classifier learning curve.",5.2.2 User Study Results,[0],[0]
"(2) The variance in annotation time per segment was consistently higher for the nonexperts than the expert, indicated by an average per-segment prediction error of 71% vs. 58% relative to the mean actual value, respectively.",5.2.2 User Study Results,[0],[0]
"Informally speaking, non-experts made more mistakes, and were more strongly influenced by the difficulty of a particular segment (which was higher on average with the proposed method, as indicated by a
lower average confidence).9
In Figures 6 (2-4) we present a simulation experiment in which we first pretend as if annotators made no mistakes, then as if they needed exactly as much time as predicted for each segment, and then both.",5.2.2 User Study Results,[0],[0]
"This cheating experiment works in favor of the proposed method, especially for the non-expert.",5.2.2 User Study Results,[0],[0]
"We may conclude that our segmentation approach is effective for the word segmentation task, but requires more accurate time predictions.",5.2.2 User Study Results,[0],[0]
"Better user models will certainly help, although for the presented scenario our method may be most useful for an expert annotator.
9Note that the non-expert in the figure annotated much faster than the expert, which explains the comparable classification result despite making more annotation errors.",5.2.2 User Study Results,[0],[0]
"This is in contrast to the other non-experts, who were slower.",5.2.2 User Study Results,[0],[0]
"Since our segmentation algorithm does not guarantee polynomial runtime, computational efficiency was a concern, but did not turn out problematic.",5.3 Computational Efficiency,[0],[0]
"On a consumer laptop, the solver produced segmentations within a few seconds for a single document containing several thousand tokens, and within hours for corpora consisting of several dozen documents.",5.3 Computational Efficiency,[0],[0]
Runtime increased roughly quadratically with respect to the number of segmented tokens.,5.3 Computational Efficiency,[0],[0]
"We feel that this is acceptable, considering that the time needed for human supervision will likely dominate the computation time, and reasonable approximations can be made as noted in Section 3.2.",5.3 Computational Efficiency,[0],[0]
"Efficient supervision strategies have been studied across a variety of NLP-related research areas, and received increasing attention in recent years.",6 Relation to Prior Work,[0],[0]
"Examples include post editing for speech recognition (Sanchez-Cortina et al., 2012), interactive machine translation (González-Rubio et al., 2010), active learning for machine translation (Haffari et al., 2009; González-Rubio et al., 2011) and many other NLP tasks (Olsson, 2009), to name but a few studies.
",6 Relation to Prior Work,[0],[0]
"It has also been recognized by the active learning community that correcting the most useful parts first is often not optimal in terms of efficiency, since these parts tend to be the most difficult to manually annotate (Settles et al., 2008).",6 Relation to Prior Work,[0],[0]
"The authors advocate the use of a user model to predict the supervision effort, and select the instances with best “bang-for-thebuck.”",6 Relation to Prior Work,[0],[0]
"This prediction of supervision effort was successful, and was further refined in other NLP-related studies (Tomanek et al., 2010; Specia, 2011; Cohn and Specia, 2013).",6 Relation to Prior Work,[0],[0]
"Our approach to user modeling using GP regression is inspired by the latter.
",6 Relation to Prior Work,[0],[0]
"Most studies on user models consider only supervision effort, while neglecting the accuracy of human annotations.",6 Relation to Prior Work,[0],[0]
"The view on humans as a perfect oracle has been criticized (Donmez and Carbonell, 2008), since human errors are common and can negatively affect supervision utility.",6 Relation to Prior Work,[0],[0]
"Research on human-computer-interaction has identified the modeling of human errors as very difficult (Olson and Olson, 1990), depending on factors such as user experience, cognitive load, user interface design, and
fatigue.",6 Relation to Prior Work,[0],[0]
"Nevertheless, even the simple error model used in our post editing task was effective.
",6 Relation to Prior Work,[0],[0]
The active learning community has addressed the problem of balancing utility and cost in some more detail.,6 Relation to Prior Work,[0],[0]
"The previously reported “bang-for-the-buck” approach is a very simple, greedy approach to combine both into one measure.",6 Relation to Prior Work,[0],[0]
"A more theoretically founded scalar optimization objective is the net benefit (utility minus costs) as proposed by Vijayanarasimhan and Grauman (2009), but unfortunately is restricted to applications where both can be expressed in terms of the same monetary unit.",6 Relation to Prior Work,[0],[0]
Vijayanarasimhan et al. (2010) and Donmez and Carbonell (2008) use a more practical approach that specifies a constrained optimization problem by allowing only a limited time budget for supervision.,6 Relation to Prior Work,[0],[0]
"Our approach is a generalization thereof and allows either specifying an upper bound on the predicted cost, or a lower bound on the predicted utility.
",6 Relation to Prior Work,[0],[0]
"The main novelty of our presented approach is the explicit modeling and selection of segments of various sizes, such that annotation efficiency is optimized according to the specified constraints.",6 Relation to Prior Work,[0],[0]
"While some works (Sassano and Kurohashi, 2010; Neubig et al., 2011) have proposed using subsentential segments, we are not aware of any previous work that explicitly optimizes that segmentation.",6 Relation to Prior Work,[0],[0]
"We presented a method that can effectively choose a segmentation of a language corpus that optimizes supervision efficiency, considering not only the actual usefulness of each segment, but also the annotation cost.",7 Conclusion,[0],[0]
We reported noticeable improvements over strong baselines in two user studies.,7 Conclusion,[0],[0]
"Future user experiments with more participants would be desirable to verify our observations, and allow further analysis of different factors such as annotator expertise.",7 Conclusion,[0],[0]
"Also, future research may improve the user modeling, which will be beneficial for our method.",7 Conclusion,[0],[0]
The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreement n 287658 Bridges Across the Language Divide (EU-BRIDGE).,Acknowledgments,[0],[0]
"In this paper, we study the problem of manually correcting automatic annotations of natural language in as efficient a manner as possible.",abstractText,[0],[0]
"We introduce a method for automatically segmenting a corpus into chunks such that many uncertain labels are grouped into the same chunk, while human supervision can be omitted altogether for other segments.",abstractText,[0],[0]
A tradeoff must be found for segment sizes.,abstractText,[0],[0]
"Choosing short segments allows us to reduce the number of highly confident labels that are supervised by the annotator, which is useful because these labels are often already correct and supervising correct labels is a waste of effort.",abstractText,[0],[0]
"In contrast, long segments reduce the cognitive effort due to context switches.",abstractText,[0],[0]
Our method helps find the segmentation that optimizes supervision efficiency by defining user models to predict the cost and utility of supervising each segment and solving a constrained optimization problem balancing these contradictory objectives.,abstractText,[0],[0]
"A user study demonstrates noticeable gains over pre-segmented, confidence-ordered baselines on two natural language processing tasks: speech transcription and word segmentation.",abstractText,[0],[0]
Segmentation for Efficient Supervised Language Annotation with an Explicit Cost-Utility Tradeoff,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 137–144 New Orleans, Louisiana, June 1 - 6, 2018. c©2017 Association for Computational Linguistics",text,[0],[0]
"In recent years, there has been growing interest in voice-controlled devices, such as Amazon Alexa or Google home.",1 Introduction,[0],[0]
"This success makes the quick bootstrapping of corresponding systems, including NLU models, for new languages a prioritised goal.",1 Introduction,[0],[0]
"However, building a new NLU model for each language from scratch and gathering the necessary annotated corpora implies a significant amount of human time and effort both by annotators and scientists.",1 Introduction,[0],[0]
"In addition, this procedure is not scalable to supporting an increasing number of languages.",1 Introduction,[0],[0]
"On the other hand, a large amount of data is usually available for the language(s) that are already supported.",1 Introduction,[0],[0]
Leveraging this source of data seems an obvious solution.,1 Introduction,[0],[0]
"In this paper,
The author Rajen Chatterjee conducted the work for this paper during an internship at Amazon, Cambridge, UK
we investigate the use of Machine Translation to translate existing data sources to a new target language and use them to bootstrap an NLU system for this target language.
",1 Introduction,[0],[0]
A common procedure for data gathering for a new language starts by some grammar-generated data.,1 Introduction,[0],[0]
Significant time and effort is consumed at this stage by language specialists to build grammars that offer a good coverage needed for a first working system.,1 Introduction,[0],[0]
"Once this first system reaches a certain performance threshold, it can be shared with beta users.",1 Introduction,[0],[0]
This step allows more data that cover real user’s queries to be generated.,1 Introduction,[0],[0]
"All existing data sources are then used to train the system that will be released to the final customers, once a new higher performance threshold is reached.",1 Introduction,[0],[0]
"Finally, when the system is released to the customers, customer data become available.",1 Introduction,[0],[0]
"Beta and customer data better cover the user utterances than grammar-generated data and are, thus, valuable for the development of a good and generalisable NLU system.",1 Introduction,[0],[0]
"However, it takes a significant amount of time and human annotation effort in order to have enough annotated beta, and later customer data, needed to build a good NLU system.",1 Introduction,[0],[0]
"Furthermore, having a system robust to new domains and features is very challenging and requires data with a wide coverage.
",1 Introduction,[0],[0]
Machine Translation can be a useful tool for the quick expansion to new languages by automatically translating customer data from existing resources to new languages.,1 Introduction,[0],[0]
This could decrease significantly the time needed to develop an NLU system that replies well to customer queries and is robust to new features.,1 Introduction,[0],[0]
"In this paper, we work with a large-scale system where around 10 millions annotated customer data are available for US English with a wide coverage of domains and features.",1 Introduction,[0],[0]
We use this corpus to augment the training data of a new language.,1 Introduction,[0],[0]
"In particular, we will present our
137
experiments on applying our technique to bootstrap a German NLU system based on existing US English training data.
",1 Introduction,[0],[0]
"In addition, we explore ways to choose the “good” translations from the translated ones, i.e. the ones that improve the NLU performance.",1 Introduction,[0],[0]
The investigated methods fall in the following categories.,1 Introduction,[0],[0]
"First, we investigate filtering based on MT quality.",1 Introduction,[0],[0]
This method makes use of scores generated by the MT model to assign the quality of translations.,1 Introduction,[0],[0]
The second method explores improving the NLU performance by making sure the filtered translations keep the semantic information required by the NLU system.,1 Introduction,[0],[0]
"In this case, the matching of the NLU labels after a backward translation task is used as the filtering criterion.",1 Introduction,[0],[0]
"Lastly, some language-specific post-processing is applied on the translation output.",1 Introduction,[0],[0]
This includes resampling data with catalogues of the new language.,1 Introduction,[0],[0]
"Another post-processing step applied is to keep the original (EN) version of certain slots that the users tend to leave untranslated.
",1 Introduction,[0],[0]
This paper is organised as follows.,1 Introduction,[0],[0]
"In Section 2, we give an overview of related literature.",1 Introduction,[0],[0]
"In Section 3, we present the methods for MT filtering for bootstrapping a new language while improving NLU performance.",1 Introduction,[0],[0]
"Next, we detail the experimental setup in section 4, including details on the used NLU and MT systems as well as the monolingual and bilingual corpora used.",1 Introduction,[0],[0]
"Afterwards, we present results in Section 5 before concluding the paper in Section 6 .",1 Introduction,[0],[0]
"Many efforts to avoid or minimize this manual work have been made in the last few years using transfer learning, active learning and semisupervised training.",2 Background work,[0],[0]
One of the successful approaches has been making use of an MT system to obtain annotated corpora.,2 Background work,[0],[0]
"The results of such works depend on the availability of an MT system (general-purpose or in-domain), on the quality of the acquired translations and on the precision of NLU label-word alignment when passing from one language to another.",2 Background work,[0],[0]
Garcı́a,2 Background work,[0],[0]
et al. (2012) combine multiple online general-purpose translation systems to achieve transferability between French and Spanish for a dialog system.,2 Background work,[0],[0]
"Jabaian et al. (2011) study phrase-based translation as an alternative to Conditional Random Fields (CRF) to keep NLU label-word alignment info in the
decoding process.",2 Background work,[0],[0]
Lefèvre et al. (2010) propose the Semantic Tuple Classifiers (STC) model without any need for alignment information.,2 Background work,[0],[0]
"Servan et al. (2010) translate the conceptual segments (i.e. NLU labeled) separately to maintain the chunking between source and target language but at the cost of degrading the translation quality.
",2 Background work,[0],[0]
There is a wide literature on assessing the MT quality.,2 Background work,[0],[0]
Evaluating the quality of MT output has been a topic in the Workshop of Machine Translation (WMT) since its beginnings (WMT06) and a separate task since 2008 (“Shared Evaluation Task” (WMT08)).,2 Background work,[0],[0]
Since 2012 a more specific “Quality Estimation Task” (WMT12) appears with a focus on deciding whether a translation is good and how to filter out translations that are not good enough.,2 Background work,[0],[0]
"In addition, in 2017 (WMT17) other related topics appear including post-editing and bandit learning as specific tasks of correcting errors and improving MT quality by learning from feedback.",2 Background work,[0],[0]
A straight-forward method is using human translated data as the true reference and correct MT errors using this ground truth.,2 Background work,[0],[0]
"Automatic Post-Editing (APE) can also improve MT quality by modifying MT output to the correct version (Chatterjee et al., 2017).",2 Background work,[0],[0]
"Bandit learning (Sokolov et al., 2017) replaces human reference and postedits by a weak user’s feedback.",2 Background work,[0],[0]
"This feedback is introduced in the training process in a reinforcement learning framework updating the gradient to maximize the rewards corresponding to user’s feedback.
",2 Background work,[0],[0]
"However, all previous method focus on improving MT quality (i.e. BLEU score) and not the NLU task of interest.",2 Background work,[0],[0]
Jabaian et al. (2011) add noise to translation data and use translation post-editing to increase the robustness of NLU to translation errors.,2 Background work,[0],[0]
"Other methods include measuring the probability of a translated utterance by applying a target language LM, i.e. measuring if a translated utterance is typical, or computing the likelihood that an alignment between the source and the translated utterance is correct, as Klinger and Cimiano (2015) explore for the sentiment analysis task.",2 Background work,[0],[0]
"We will do something similar in this paper by using directly the MT scores (alignment, translation and language model scores) as a measure of MT quality independent of the NLU tasks.",2 Background work,[0],[0]
"In addition, we explore and extend a different approach for filtering which was presented by Misu et al. (2012).",2 Background work,[0],[0]
"In order to select utterances among possibly er-
roneous translation results, the authors use backtranslation results to check whether the translation result maintains the semantic meaning of the original sentence.",2 Background work,[0],[0]
The main difference though is that in the latter paper the method is applied using a very small dataset (less than 3k translated utterances) while we work with around 10 millions.,2 Background work,[0],[0]
"In this paper, we explore bootstrapping of NLU models for a new language by translating training data from an NLU system for a different language.",3 Method,[0],[0]
The training data is representative of user requests to voice-controlled assistants; annotations are projected from source to target utterances during MT decoding.,3 Method,[0],[0]
"Since the quality of NLU models trained on MT data depends heavily on the quality of the MT data, we explore different methods for filtering and post-processing.",3 Method,[0],[0]
"In the following, we describe all approaches in more detail.",3 Method,[0],[0]
"The goal of the filtering approaches is to choose ”good” translations, i.e. we aim to keep primary translations in the training data which are likely to be useful for building NLU models.",3.1 Filtering,[0],[0]
"We explore two approaches for filtering, one based on MT system scores and one based on semantic information.",3.1 Filtering,[0],[0]
Misu et al. (2012) remove erroneous machine translations in the NLU training data by using back-translations to measure whether the semantic information of a source utterance is retained in the translated utterance.,3.1.1 Filtering based on semantic information,[0],[0]
"In particular, they apply the following steps:
1.",3.1.1 Filtering based on semantic information,[0],[0]
"Label the source utterance with an NLU model
2.",3.1.1 Filtering based on semantic information,[0],[0]
Translate the source utterance 3.,3.1.1 Filtering based on semantic information,[0],[0]
"Label the translated utterance by aligning
with the result of step 1 4.",3.1.1 Filtering based on semantic information,[0],[0]
"Translate the translated utterance back into
the source language 5.",3.1.1 Filtering based on semantic information,[0],[0]
"Label the back-translated utterance with an
NLU model 6.",3.1.1 Filtering based on semantic information,[0],[0]
"Keep the target utterance, if the the recog-
nised intents of steps 1 and 5 are the same
The authors present results with Japanese as the source and English as the target language, suggesting improved spoken language understanding results by filtering translations for the training data with their approach.",3.1.1 Filtering based on semantic information,[0],[0]
"Thus, this approach aims to keep translations for which some semantic information of utterances is retained, potentially avoiding errors in the NLU models trained on these data.",3.1.1 Filtering based on semantic information,[0],[0]
"We apply this approach in an adapted form, i.e. instead of the additional alignment step (3), we project labels using the MT system, i.e. we make use of the alignment model trained for the MT system.",3.1.1 Filtering based on semantic information,[0],[0]
"In addition, we extend the approach by 1) determining if the recognised slots are retained in addition to the intent, and 2) making use of the NLU model’s confidence, i.e. we remove utterances retaining the intent, if the confidence of the NLU model is very low (< 0.1 on a scale from 0− 1).",3.1.1 Filtering based on semantic information,[0],[0]
This approach explores the scores returned by the MT system for choosing translations from a training dataset.,3.1.2 Filtering based on MT scores,[0],[0]
"Since annotating the translations for quality judgement by humans is expensive, we considered to use the translation score as a quality metric that can give us relative quality judgement among a list of translations.",3.1.2 Filtering based on MT scores,[0],[0]
"In particular, we computed a threshold for each domain based on translation scores.",3.1.2 Filtering based on MT scores,[0],[0]
"The score we used is the weighted overall translation score as given by Moses MT toolkit and combining the scores of the translation model, the language model, the reordering score and some word penalty.",3.1.2 Filtering based on MT scores,[0],[0]
"To create a domain-wise threshold, given a translated utterance and its score, we first normalised the score by utterance length.",3.1.2 Filtering based on MT scores,[0],[0]
"Afterwards, we computed mean and standard deviation per domain.",3.1.2 Filtering based on MT scores,[0],[0]
We then selected translations that have a score greater than or equal to the threshold.,3.1.2 Filtering based on MT scores,[0],[0]
"In this work, we evaluated different thresholds like mean of the translation scores, mean+stdev (standard deviation), mean+(0.5*stdev), and mean+(0.25*stdev).",3.1.2 Filtering based on MT scores,[0],[0]
"Aiming to improve the quality of slot values in the translated data, we explore two strategies for language-specific post-processing.",3.2 Language-specific post-processing,[0],[0]
"If data are translated from another language, slot values related to the countries in the source lan-
guage might not model those of user requests in the target language.",3.2.1 Slot resampling,[0],[0]
"For example, when requesting a weather forecast, American customers would much more frequently ask for an American city than a German one.",3.2.1 Slot resampling,[0],[0]
"Thus, an utterance ”how is the weather in New York” is likely to be much more frequent in the resulting training data than an utterance ”how is the weather in Berlin”, and consequently it would appear more frequently in the data after translation to German.",3.2.1 Slot resampling,[0],[0]
"This, however, doesn’t seem to model language use by German customers well and can hence potentially degrade performance of statistical models trained on these data.",3.2.1 Slot resampling,[0],[0]
"Aiming to decrease the mismatch in slots values between source language and target language use, we used catalogs to resample slot values for slots where this seemed to be appropriate.",3.2.1 Slot resampling,[0],[0]
"In particular, we replaced slot values in the translated data using target language catalog entries corresponding to the slot.",3.2.1 Slot resampling,[0],[0]
"For instance, a catalog with German cities can be used to replace ”New York” by ”Berlin” in the previously mentioned example.",3.2.1 Slot resampling,[0],[0]
"For catalogs comprising information, which can be used for weighting catalog entities, we made use of it in that we sample entities according to weights, i.e. the higher the weight, the more often the corresponding entity is sampled.",3.2.1 Slot resampling,[0],[0]
"For example, the number of orders can be used to weight albums and population size can be used to weight cities.",3.2.1 Slot resampling,[0],[0]
Machine translation systems might incorrectly translate slot values which should not be translated.,3.2.2 Keeping some original slot values,[0],[0]
"For example, in an utterance ”play we are the champions by queen”, the song title ”we are the champions” and the band name ”queen” should not be translated.",3.2.2 Keeping some original slot values,[0],[0]
"While we can apply slot resampling to ingest existing slot values into such utterances, we also explore a different approach.",3.2.2 Keeping some original slot values,[0],[0]
"In particular, in this approach we post-process the translated utterances to retain the slot values from the source language utterances for certain slots, such as artists or song titles.",3.2.2 Keeping some original slot values,[0],[0]
We ran experiments using US English as the source and German as the target language.,4 Experimental setup,[0],[0]
"Since we are interested in bootstrapping an NLU model for a new language which would first be deployed to beta customers, we evaluate our approach on German beta data.",4 Experimental setup,[0],[0]
"In the following, we first briefly
describe the MT and NLU systems and subsequently the datasets.",4 Experimental setup,[0],[0]
"We used a phrase-based MT system which was built using Moses (Koehn et al., 2007) for a similar task, i.e. Question Answering (QA).",4.1 MT and NLU systems,[0],[0]
"The MT system is a multi-domain model trained on a mixture of internal and external parallel data sources, which are not from the QA domain; overall the out-of-domain data sources comprised 28,733,606 segments.",4.1 MT and NLU systems,[0],[0]
"The system was fine-tuned using a small manually created parallel corpus for QA, comprising 4,000 segments, and 424,921 indomain target language segments were used for the target language model.",4.1 MT and NLU systems,[0],[0]
"Training data were preprocessed, in particular they were converted into spoken form before building the MT system to better match spoken user utterances of an NLU system.",4.1 MT and NLU systems,[0],[0]
"We used an MT system for a similar task rather than an MT system adapted for our data, because we would expect that suitable in-domain data for adaptation might not yet be available for early bootstrapping, i.e. when target language data have not yet been collected.
",4.1 MT and NLU systems,[0],[0]
"For building NLU models, we use Conditional Random Fields (Lafferty et al., 2001; Okazaki, 2007) for Named Entity Recognition and a Maximum Entropy classifier (Berger et al., 1996) for Intent Classification; we keep the sets of features, hyper-parameters and configuration constant for our experiments.",4.1 MT and NLU systems,[0],[0]
We translated 10M of training data utterances from a US English NLU system.,4.2 Datasets,[0],[0]
"Overall, the data cover several domains with a large number of different intents and slots/named entities.",4.2 Datasets,[0],[0]
We translated the data using the previously described MT system.,4.2 Datasets,[0],[0]
NLU labels were kept and aligned during the MT decoding to project them from the English source utterances to the corresponding German translations.,4.2 Datasets,[0],[0]
"The final training dataset comprised 9,963,624 utterances.
",4.2 Datasets,[0],[0]
"For testing, we created a dataset collected from German Beta users; German test data were manually transcribed and annotated with intents and slots/named entities.",4.2 Datasets,[0],[0]
"The resulting test dataset comprised 119,772 utterances.",4.2 Datasets,[0],[0]
"To create a baseline, we used an in-house data collection of 10k utterances, which were manually transcribed and annotated with intents and
slots.",4.2 Datasets,[0],[0]
"While in-house data collections are costly and time-consuming, they constitute a reasonable approach for bootstrapping a model from scratch when customer data are not yet available.
",4.2 Datasets,[0],[0]
"In addition, we created a grammar-based baseline.",4.2 Datasets,[0],[0]
"In particular, we randomly sampled utterances from grammars and created a training dataset from them.",4.2 Datasets,[0],[0]
"For this, we used around 200 grammars written by language experts covering (most) intents and slots supported by the NLU system.",4.2 Datasets,[0],[0]
"However, one of the domains was not covered by grammars, because it supports very diverse features and requests, which are difficult to capture by a grammar.
",4.2 Datasets,[0],[0]
"We report results by means of a semantic error rate (SemER) which is computed based on the number of insertions, deletions and substitutions for slots and the intent in a recognised utterance compared to a reference utterance, i.e.
SemER = # (slot + intent errors)# (slots + intents in reference)",4.2 Datasets,[0],[0]
"First, we compare our approach to the baseline approaches based on grammars and an in-house data collection.",5 Results,[0],[0]
"For this, we trained NLU models on MT data, on the in-house data collection, on grammar-generated data as well as on MT data together with each baseline dataset.",5 Results,[0],[0]
"Subsequently, we evaluated the models on the German beta data test set.",5 Results,[0],[0]
"Results for model trained on the MT dataset and on the baseline datasets are presented in Table 2.
",5 Results,[0],[0]
Training data SemER (%) Grammar-generated data (baseline) 55.44,5 Results,[0],[0]
"In-house collection (baseline) 23.30 MT data 21.38 MT data + grammar-generated data 20.00 MT data + in-house collection 17.20
Table 2:",5 Results,[0],[0]
"Comparison for NLU models trained on MT data to our baseline models, i.e. models trained on grammar-generated data and models trained on an inhouse data collection of 10k utterances.
",5 Results,[0],[0]
"As can be seen, the MT approach outperforms the grammar-based one by a large percentage (i.e. around 33% absolute in SemER), while requiring much less manual effort.",5 Results,[0],[0]
"In addition, training on both MT and grammar-generated data improves performance over training solely on either one of the datasets; the improvement of the joined approach is particularly large over training solely on grammar-generated data (i.e. around 35 % absolute in SemER).",5 Results,[0],[0]
"As noted before, the grammars did not cover one of the domains, yielding errors for its test utterances.",5 Results,[0],[0]
"To get an estimate of this impact, we removed all utterances from this domain from the test set and recomputed SemER for the grammar-based baseline.",5 Results,[0],[0]
"While SemER dropped to 34.23, there is still a large difference in performance compared to training on MT data and one domain is not supported at all, even though it is needed by the system.",5 Results,[0],[0]
"Compared to the grammarbased baseline, training on the in-house data collection yields a lower SemER of 23.3.",5 Results,[0],[0]
"Still, training on MT data outperforms this baseline as well, and combining MT data with the in-house data collection improves further over training solely on either one of the datasets (i.e. 17.2 for both vs 21.38 for MT and 23.3 for the in-house collection).",5 Results,[0],[0]
"Thus, MT data appear to be useful for both bootstrapping an NLU model from scratch and enhancing models trained on grammar-generated data or on an in-house data collection of 10k.
",5 Results,[0],[0]
"In the following, we evaluate whether our filtering and post-processing approaches can improve the quality of the MT training data further.",5 Results,[0],[0]
Table 3 presents the results for our filtering approaches.,5 Results,[0],[0]
"While filtering based on semantic information yields an improvement in SemER over using MT data as they are, filtering based on MT scores only yields a slight improvement in one of the conditions.",5 Results,[0],[0]
"For filtering based on semantic information, our results confirm in a large-scale industry setting that training on utterances for which the intent is retained after back-translation is useful.",5 Results,[0],[0]
"In addition, our results show that performance can be improved further by either additionally removing utterances for which the slots are not retained or by removing utterances for which the confidence is very low.",5 Results,[0],[0]
"Here, removing low confidence utterances yields slightly better results.",5 Results,[0],[0]
"While we tested with 0.1 as a threshold, results might be improved further by optimising this threshold, potentially even per domain.
",5 Results,[0],[0]
"Filtering based on MT scores decreases performance in all considered conditions, except mean+(0.25*stdev), which yields a very slight improvement.",5 Results,[0],[0]
"However, results were not consistent across domains, i.e., while overall SemER as well as SemER for several domains increased in most cases, it decreased for several domains with relative decreases of up to 48.35%.",5 Results,[0],[0]
"Here, manual inspection of the data indicates that this approach is not well-suited for domains comprising very diverse data, since one threshold based on a mean score cannot capture diverse data well.",5 Results,[0],[0]
"In addition, manual inspection revealed that a rather large percentage of the increase in SemER was due to removing ambiguous utterances, as these typically have a rather low MT score, but are sometimes very frequently used and hence need to be captured by the NLU system.",5 Results,[0],[0]
"For example, the German utterance ”weiter” is frequently used, but can mean both ”forward” and ”resume” in English, implying also different user intents.",5 Results,[0],[0]
"Removing only this one utterance from the training data yielded around 2.5k errors, since this utterance is frequent in the test data.",5 Results,[0],[0]
"However, frequent errors could potentially be fixed manually with little effort by a rule-based approach.",5 Results,[0],[0]
"Since the approach based on MT scores yields improvements for certain domains, further investigations on the nature of datasets/domains it works well with could be interesting.",5 Results,[0],[0]
"Since it also yields improved results for some domains compared to the approach based on semantic information, further experiments investigating the combination of both approaches could potentially improve results further.
",5 Results,[0],[0]
"Table 4 shows the results of our languagespecific post-processing approaches.
",5 Results,[0],[0]
The results show that slot resampling has almost no impact on the error rates.,5 Results,[0],[0]
"The reason might be that the statistical model uses catalogs
also as gazetteers, and hence already includes information on German entities during training.",5 Results,[0],[0]
Future work might investigate the effect of slot resampling for models which do not use gazetteers.,5 Results,[0],[0]
Keeping some original slot values degrades performance from 21.38% to 23.82%.,5 Results,[0],[0]
One reason for the decrease in performance might be that keeping a few original slot values decreases the frequency of appearance of some German words that still appear in the test set and are requested by users in German.,5 Results,[0],[0]
"However, it is not consistent that some words or some slots are always in German or English, yielding some mismatches between translated training data and test data.",5 Results,[0],[0]
"Aiming to counterbalance the increase of English words’ frequency, but also consider the original slot values, we combined both approaches.",5 Results,[0],[0]
"As can be seen in the table, the combined approach yields an improvement, i.e. SemER is 20.18% compared to 21.38% for training on MT data as they are.",5 Results,[0],[0]
"With 20.18%, this approach is also performing better than our best-performing filtering approach which yields 20.32% in SemER.",5 Results,[0],[0]
One interesting question for future work will be to explore if combining filtering and language-specific post-processing approaches will improve results further.,5 Results,[0],[0]
"Overall, compared to the grammar-based baseline, the best-performing post-processing approach yields a large improvement in SemER (20.18% vs 55.44%) and also yields results very
similar to the NLU model trained on both the initial MT data and the grammar-generated data (20.18% vs 20.0%).",5 Results,[0],[0]
"However, our proposed postprocessing approach can be applied automatically and quickly, while grammar writing is very costly and time-consuming.",5 Results,[0],[0]
"Aiming to reduce time and costs needed to bootstrap an NLU model for a new language, in this paper we made use of MT data to build NLU models.",6 Conclusion,[0],[0]
"In addition, we compared different techniques to filter and post-process the MT data, aiming to improve NLU performance further.",6 Conclusion,[0],[0]
These methods were evaluated in large-scale experiments for a voice-controlled assistant to bootstrap a German system using English data.,6 Conclusion,[0],[0]
The results when using MT data showed a large improvement in performance compared to a grammar-based baseline and outperformed a baseline using an inhouse data collection.,6 Conclusion,[0],[0]
The applied filtering and post-processing techniques improved results further over using MT data as they are.,6 Conclusion,[0],[0]
"In future work, we plan to apply our approach to further languages and explore bootstrapping new domains for an existing NLU system.",6 Conclusion,[0],[0]
"We thank Steve Sloto, Greg Hanneman, Donna Gates and Patrick Porte for building the MT system and Fabian Triefenbach and Daniel Marcu for valuable comments on this paper.",Acknowledgments,[0],[0]
This paper investigates the use of Machine Translation (MT) to bootstrap a Natural Language Understanding (NLU) system for a new language for the use case of a large-scale voice-controlled device.,abstractText,[0],[0]
"The goal is to decrease the cost and time needed to get an annotated corpus for the new language, while still having a large enough coverage of user requests.",abstractText,[0],[0]
Different methods of filtering MT data in order to keep utterances that improve NLU performance and language-specific postprocessing methods are investigated.,abstractText,[0],[0]
These methods are tested in a large-scale NLU task with translating around 10 millions training utterances from English to German.,abstractText,[0],[0]
"The results show a large improvement for using MT data over a grammar-based and over an in-house data collection baseline, while reducing the manual effort greatly.",abstractText,[0],[0]
Both filtering and postprocessing approaches improve results further.,abstractText,[0],[0]
Selecting Machine-Translated Data for Quick Bootstrapping of a Natural Language Understanding System,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1095–1104 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1101",text,[0],[0]
Sentence summarization aims to shorten a given sentence and produce a brief summary of it.,1 Introduction,[0],[0]
"This is different from document level summarization task since it is hard to apply existing techniques in extractive methods, such as extracting sentence level features and ranking sentences.",1 Introduction,[0],[0]
"Early works propose using rule-based methods (Zajic et al., 2007), syntactic tree pruning methods (Knight and Marcu, 2002), statistical machine translation techniques (Banko et al., 2000) and so on for this task.",1 Introduction,[0],[0]
"We focus on abstractive sentence summarization task in this paper.
",1 Introduction,[0],[0]
"Recently, neural network models have been applied in this task.",1 Introduction,[0],[0]
"Rush et al. (2015) use autoconstructed sentence-headline pairs to train a neu-
∗Contribution during internship at Microsoft Research.
ral network summarization model.",1 Introduction,[0],[0]
They use a Convolutional Neural Network (CNN) encoder and feed-forward neural network language model decoder for this task.,1 Introduction,[0],[0]
Chopra et al. (2016) extend their work by replacing the decoder with Recurrent Neural Network (RNN).,1 Introduction,[0],[0]
"Nallapati et al. (2016) follow this line and change the encoder to RNN to make it a full RNN based sequence-tosequence model (Sutskever et al., 2014).
",1 Introduction,[0],[0]
"All the above works fall into the encodingdecoding paradigm, which first encodes the input sentence to an abstract representation and then decodes the intended output sentence based on the encoded information.",1 Introduction,[0],[0]
"As an extension of the encoding-decoding framework, attentionbased approach (Bahdanau et al., 2015) has been broadly used: the encoder produces a list of vectors for all tokens in the input, and the decoder uses an attention mechanism to dynamically extract encoded information and align with the output tokens.",1 Introduction,[0],[0]
"This approach achieves huge success in tasks like machine translation, where alignment between all parts of the input and output are required.",1 Introduction,[0],[0]
"However, in abstractive sentence summarization, there is no explicit alignment relationship between the input sentence and the summary ex-
1095
cept for the extracted common words.",1 Introduction,[0],[0]
"The challenge here is not to infer the alignment, but to select the highlights while filtering out secondary information in the input.",1 Introduction,[0],[0]
"A desired work-flow for abstractive sentence summarization is encoding, selection, and decoding.",1 Introduction,[0],[0]
"After selecting the important information from an encoded sentence, the decoder produces the output summary using the selected information.",1 Introduction,[0],[0]
"For example, in Figure 1, given the input sentence, the summarization system first selects the important information, and then rephrases or paraphrases to produce a well-organized summary.",1 Introduction,[0],[0]
"Although this is implicitly modeled in the encoding-decoding framework, we argue that abstractive sentence summarization shall benefit from explicitly modeling this selection process.
",1 Introduction,[0],[0]
In this paper we propose Selective Encoding for Abstractive Sentence Summarization (SEASS).,1 Introduction,[0],[0]
"We treat the sentence summarization as a threephase task: encoding, selection, and decoding.",1 Introduction,[0],[0]
"It consists of a sentence encoder, a selective gate network, and a summary decoder.",1 Introduction,[0],[0]
"First, the sentence encoder reads the input words through an RNN unit to construct the first level sentence representation.",1 Introduction,[0],[0]
Then the selective gate network selects the encoded information to construct the second level sentence representation.,1 Introduction,[0],[0]
"The selective mechanism controls the information flow from encoder to decoder by applying a gate network according to the sentence information, which helps improve encoding effectiveness and release the burden of the decoder.",1 Introduction,[0],[0]
"Finally, the attention-equipped decoder generates the summary using the second level sentence representation.",1 Introduction,[0],[0]
"We conduct experiments on English Gigaword, DUC 2004 and Microsoft Research Abstractive Text Compression test sets.",1 Introduction,[0],[0]
"Our SEASS model achieves 17.54 ROUGE-2 F1, 9.56 ROUGE-2 recall and 10.63 ROUGE-2 F1 on these test sets respectively, which improves performance compared to the state-of-the-art methods.",1 Introduction,[0],[0]
"Abstractive sentence summarization, also known as sentence compression and similar to headline generation, is used to help compress or fuse the selected sentences in extractive document summarization systems since they may inadvertently include unnecessary information.",2 Related Work,[0],[0]
The sentence summarization task has been long connected to the headline generation task.,2 Related Work,[0],[0]
"There are some previous
methods to solve this task, such as the linguistic rule-based method (Dorr et al., 2003).",2 Related Work,[0],[0]
"As for the statistical machine learning based methods, Banko et al. (2000) apply statistical machine translation techniques by modeling headline generation as a translation task and use 8000 article-headline pairs to train the system.
",2 Related Work,[0],[0]
"Rush et al. (2015) propose leveraging news data in Annotated English Gigaword (Napoles et al., 2012) corpus to construct large scale parallel data for sentence summarization task.",2 Related Work,[0],[0]
"They propose an ABS model, which consists of an attentive Convolutional Neural Network encoder and an neural network language model (Bengio et al., 2003) decoder.",2 Related Work,[0],[0]
"On this Gigaword test set and DUC 2004 test set, the ABS model produces the state-of-theart results.",2 Related Work,[0],[0]
"Chopra et al. (2016) extend this work, which keeps the CNN encoder but replaces the decoder with recurrent neural networks.",2 Related Work,[0],[0]
Their experiments showes that the CNN encoder with RNN decoder model performs better than Rush et al. (2015).,2 Related Work,[0],[0]
"Nallapati et al. (2016) further change the encoder to an RNN encoder, which leads to a full RNN sequence-to-sequence model.",2 Related Work,[0],[0]
"Besides, they enrich the encoder with lexical and statistic features which play important roles in traditional feature based summarization systems, such as NER and POS tags, to improve performance.",2 Related Work,[0],[0]
"Experiments on the Gigaword and DUC 2004 test sets show that the above models achieve state-of-theart results.
",2 Related Work,[0],[0]
Gu et al. (2016) and Gulcehre et al. (2016) come up similar ideas that summarization task can benefit from copying words from input sentences.,2 Related Work,[0],[0]
"Gu et al. (2016) propose CopyNet to model the copying action in response generation, which also applies for summarization task.",2 Related Work,[0],[0]
Gulcehre et al. (2016) propose a switch gate to control whether to copy from source or generate from decoder vocabulary.,2 Related Work,[0],[0]
Zeng et al. (2016) also propose using copy mechanism and add a scalar weight on the gate of GRU/LSTM for this task.,2 Related Work,[0],[0]
"Cheng and Lapata (2016) use an RNN based encoder-decoder for extractive summarization of documents.
",2 Related Work,[0],[0]
Yu et al. (2016) propose a segment to segment neural transduction model for sequence-tosequence framework.,2 Related Work,[0],[0]
The model introduces a latent segmentation which determines correspondences between tokens of the input sequence and the output sequence.,2 Related Work,[0],[0]
"Experiments on this task show that the proposed transduction model per-
forms comparable to the ABS model.",2 Related Work,[0],[0]
Shen et al. (2016) propose to apply Minimum Risk Training (MRT) in neural machine translation to directly optimize the evaluation metrics.,2 Related Work,[0],[0]
Ayana et al. (2016) apply MRT on abstractive sentence summarization task and the results show that optimizing for ROUGE improves the test performance.,2 Related Work,[0],[0]
"For sentence summarization, given an input sentence x = (x1, x2, . . .",3 Problem Formulation,[0],[0]
", xn), where n is the sentence length, xi ∈",3 Problem Formulation,[0],[0]
"Vs and Vs is the source vocabulary, the system summarizes x by producing y = (y1, y2, . . .",3 Problem Formulation,[0],[0]
", yl), where l ≤ n is the summary length , yi ∈ Vt and Vt is the target vocabulary.
",3 Problem Formulation,[0],[0]
"If |y| ⊆ |x|, which means all words in summary y must appear in given input, we denote this as extractive sentence summarization.",3 Problem Formulation,[0],[0]
"If |y| * |x|, which means not all words in summary come from input sentence, we denote this as abstractive sentence summarization.",3 Problem Formulation,[0],[0]
Table 1 provides an example.,3 Problem Formulation,[0],[0]
We focus on abstracive sentence summarization task in this paper.,3 Problem Formulation,[0],[0]
"As shown in Figure 2, our model consists of a sentence encoder using the Gated Recurrent Unit (GRU) (Cho et al., 2014), a selective gate network and an attention-equipped GRU decoder.",4 Model,[0],[0]
"First, the bidirectional GRU encoder reads the input words x =",4 Model,[0],[0]
"(x1, x2, . . .",4 Model,[0],[0]
", xn) and builds its representation (h1, h2, . . .",4 Model,[0],[0]
", hn).",4 Model,[0],[0]
Then the selective gate selects and filters the word representations according to the sentence meaning representation to produce a tailored sentence word representation for abstractive sentence summarization task.,4 Model,[0],[0]
"Lastly, the GRU decoder produces the output summary with attention to the tailored representation.",4 Model,[0],[0]
"In the following sections, we introduce the sentence encoder, the selective mechanism, and the summary decoder respectively.",4 Model,[0],[0]
The role of the sentence encoder is to read the input sentence and construct the basic sentence representation.,4.1 Sentence Encoder,[0],[0]
"Here we employ a bidirectional GRU (BiGRU) as the recurrent unit, where GRU is defined as:
zi = σ(Wz[xi, hi−1])",4.1 Sentence Encoder,[0],[0]
"ri = σ(Wr[xi, hi−1])
h̃i = tanh(Wh[xi, ri hi−1])",4.1 Sentence Encoder,[0],[0]
"hi = (1− zi) hi−1 + zi h̃i
(1)
(2)
(3)
(4)
where Wz , Wr and Wh are weight matrices.",4.1 Sentence Encoder,[0],[0]
The BiGRU consists of a forward GRU and a backward GRU.,4.1 Sentence Encoder,[0],[0]
"The forward GRU reads the input sentence word embeddings from left to right and gets a sequence of hidden states, (~h1,~h2, . . .",4.1 Sentence Encoder,[0],[0]
",~hn).",4.1 Sentence Encoder,[0],[0]
"The backward GRU reads the input sentence embeddings reversely, from right to left, and results in another sequence of hidden states, ( ~h1, ~h2, . . .",4.1 Sentence Encoder,[0],[0]
", ~hn):
~hi = GRU(xi,~hi−1)",4.1 Sentence Encoder,[0],[0]
"~hi = GRU(xi, ~hi+1)
(5)
(6)
",4.1 Sentence Encoder,[0],[0]
"The initial states of the BiGRU are set to zero vectors, i.e., ~h1 = 0 and ~hn = 0.",4.1 Sentence Encoder,[0],[0]
"After reading the sentence, the forward and backward hidden states are concatenated, i.e., hi =",4.1 Sentence Encoder,[0],[0]
"[~hi; ~hi], to get the basic sentence representation.",4.1 Sentence Encoder,[0],[0]
"In the sequence-to-sequence machine translation (MT) model, the encoder and decoder are responsible for mapping input sentence information to a list of vectors and decoding the sentence representation vectors to generate an output sentence (Bahdanau et al., 2015).",4.2 Selective Mechanism,[0],[0]
"Some previous works apply this framework to summarization generation tasks (Nallapati et al., 2016; Gu et al., 2016; Gulcehre et al., 2016).",4.2 Selective Mechanism,[0],[0]
"However, abstractive sentence summarization is different from MT in two ways.",4.2 Selective Mechanism,[0],[0]
"First, there is no explicit alignment relationship between the input sentence and the output summary except for the common words.",4.2 Selective Mechanism,[0],[0]
"Second, summarization task needs to keep the highlights and remove the unnecessary information, while MT needs to keep all information literally.
",4.2 Selective Mechanism,[0],[0]
"Herein, we propose a selective mechanism to model the selection process for abstractive sentence summarization.",4.2 Selective Mechanism,[0],[0]
"The selective mechanism
extends the sequence-to-sequence model by constructing a tailored representation for abstractive sentence summarization task.",4.2 Selective Mechanism,[0],[0]
"Concretely, the selective gate network in our model takes two vector inputs, the sentence word vector hi and the sentence representation vector s.",4.2 Selective Mechanism,[0],[0]
The sentence word vector hi is the output of the BiGRU encoder and represents the meaning and context information of word xi.,4.2 Selective Mechanism,[0],[0]
The sentence vector s is used to represent the meaning of the sentence.,4.2 Selective Mechanism,[0],[0]
"For each word xi, the selective gate network generates a gate vector sGatei using hi and s, then the tailored representation is constructed, i.e., h′i.
",4.2 Selective Mechanism,[0],[0]
"In detail, we concatenate the last forward hidden state ~hn and backward hidden state ~h1 as the sentence representation s:
s =
[ ~h1
~hn
] (7)
",4.2 Selective Mechanism,[0],[0]
"For each time step i, the selective gate takes the sentence representation s and BiGRU hidden hi as inputs to compute the gate vector sGatei:
sGatei = σ(Wshi +Uss+ b) h′i = hi sGatei (8) (9)
where Ws and Us are weight matrices, b is the bias vector, σ denotes sigmoid activation function, and is element-wise multiplication.",4.2 Selective Mechanism,[0],[0]
"After the selective gate network, we obtain another sequence of vectors (h′1, h ′ 2, . . .",4.2 Selective Mechanism,[0],[0]
", h ′ n).",4.2 Selective Mechanism,[0],[0]
This new sequence is then used as the input sentence representation for the decoder to generate the summary.,4.2 Selective Mechanism,[0],[0]
"On top of the sentence encoder and the selective gate network, we use GRU with attention as the decoder to produce the output summary.
",4.3 Summary Decoder,[0],[0]
"At each decoding time step t, the GRU reads the previous word embedding wt−1 and previous context vector ct−1 as inputs to compute the new hidden state st.",4.3 Summary Decoder,[0],[0]
"To initialize the GRU hidden state, we use a linear layer with the last backward encoder hidden state ~h1 as input:
st = GRU(wt−1, ct−1, st−1)
s0 = tanh(Wd ~h1 + b)
(10)
(11)
where Wd is the weight matrix and b is the bias vector.
",4.3 Summary Decoder,[0],[0]
"The context vector ct for current time step t is computed through the concatenate attention mechanism (Luong et al., 2015), which matches the current decoder state st with each encoder hidden state h′i to get an importance score.",4.3 Summary Decoder,[0],[0]
"The importance scores are then normalized to get the current context vector by weighted sum:
et,i = v >",4.3 Summary Decoder,[0],[0]
"a tanh(Wast−1 +Uah ′ i)
",4.3 Summary Decoder,[0],[0]
"αt,i = exp(et,i)∑n i=1",4.3 Summary Decoder,[0],[0]
"exp(et,i)
ct = n∑
i=1
αt,ih ′",4.3 Summary Decoder,[0],[0]
"i
(12)
(13)
(14)
",4.3 Summary Decoder,[0],[0]
"We then combine the previous word embedding wt−1, the current context vector ct, and the decoder state st to construct the readout state rt.",4.3 Summary Decoder,[0],[0]
"The readout state is then passed through a maxout hidden layer (Goodfellow et al., 2013) to predict the
next word with a softmax layer over the decoder vocabulary.
",4.3 Summary Decoder,[0],[0]
"rt = Wrwt−1 +Urct +Vrst
mt =",4.3 Summary Decoder,[0],[0]
"[max{rt,2j−1, rt,2j}]>j=1,...,d p(yt|y1, . . .",4.3 Summary Decoder,[0],[0]
", yt−1) = softmax(Womt)
(15)
(16)
(17)
where Wa, Ua, Wr, Ur, Vr and Wo are weight matrices.",4.3 Summary Decoder,[0],[0]
"Readout state rt is a 2d-dimensional vector, and the maxout layer (Equation 16) picks the max value for every two numbers in rt and produces a d-dimensional vector mt.",4.3 Summary Decoder,[0],[0]
Our goal is to maximize the output summary probability given the input sentence.,4.4 Objective Function,[0],[0]
"Therefore, we optimize the negative log-likelihood loss function:
J(θ) =",4.4 Objective Function,[0],[0]
"− 1|D| ∑
(x,y)∈D log p(y|x) (18)
where D denotes a set of parallel sentencesummary pairs and θ is the model parameter.",4.4 Objective Function,[0],[0]
We use Stochastic Gradient Descent (SGD) with minibatch to learn the model parameter θ.,4.4 Objective Function,[0],[0]
"In this section we introduce the dataset we use, the evaluation metric, the implementation details, the baselines we compare to, and the performance of our system.",5 Experiments,[0],[0]
"Training Set For our training set, we use a parallel corpus which is constructed from the Annotated English Gigaword dataset (Napoles et al., 2012) as mentioned in Rush et al. (2015).",5.1 Dataset,[0],[0]
The parallel corpus is produced by pairing the first sentence and the headline in the news article with some heuristic rules.,5.1 Dataset,[0],[0]
We use the script1 released by Rush et al. (2015) to pre-process and extract the training and development datasets.,5.1 Dataset,[0],[0]
"The script performs various basic text normalization, including PTB tokenization, lower-casing, replacing all digit characters with #, and replacing word types seen less than 5 times with 〈unk〉.",5.1 Dataset,[0],[0]
"The extracted corpus contains about 3.8M sentence-summary pairs for the training set and 189K examples for the development set.
",5.1 Dataset,[0],[0]
"For our test set, we use the English Gigaword, DUC 2004, and Microsoft Research Abstractive Text Compression test sets.
1https://github.com/facebook/NAMAS
English Gigaword Test Set We randomly sample 8000 pairs from the extracted development set as our development set since it is relatively large.",5.1 Dataset,[0],[0]
"For the test set, we use the same randomly heldout test set of 2000 sentence-summary pairs as Rush et al. (2015).2
We also find that except for the empty titles, this test set has some invalid lines like the input sentence containing only one word.",5.1 Dataset,[0],[0]
"Therefore, we further sample 2000 pairs as our internal test set and release it for future works3.
",5.1 Dataset,[0],[0]
"DUC 2004 Test Set We employ DUC 2004 data for tasks 1 & 2 (Over et al., 2007) in our experiments as one of the test sets since it is too small to train a neural network model on.",5.1 Dataset,[0],[0]
The dataset pairs each document with 4 different human-written reference summaries which are capped at 75 bytes.,5.1 Dataset,[0],[0]
"It has 500 input sentences with each sentence paired with 4 summaries.
",5.1 Dataset,[0],[0]
MSR-ATC Test Set Toutanova et al. (2016) release a new dataset for sentence summarization task by crowdsourcing.,5.1 Dataset,[0],[0]
"This dataset contains approximately 6,000 source text sentences with multiple manually-created summaries (about 26,000 sentence-summary pairs in total).",5.1 Dataset,[0],[0]
"Toutanova et al. (2016) provide a standard split of the data into training, development, and test sets, with 4,936, 448 and 785 input sentences respectively.",5.1 Dataset,[0],[0]
"Since the training set is too small, we only use the test set as one of our test sets.",5.1 Dataset,[0],[0]
"We denote this dataset as MSR-ATC (Microsoft Research Abstractive Text Compression) test set in the following.
",5.1 Dataset,[0],[0]
Table 2 summarizes the statistic information of the three datasets we used.,5.1 Dataset,[0],[0]
"We employ ROUGE (Lin, 2004) as our evaluation metric.",5.2 Evaluation Metric,[0],[0]
"ROUGE measures the quality of summary by computing overlapping lexical units, such as unigram, bigram, trigram, and longest common subsequence (LCS).",5.2 Evaluation Metric,[0],[0]
It becomes the standard evaluation metric for DUC shared tasks and popular for summarization evaluation.,5.2 Evaluation Metric,[0],[0]
"Following previous work, we use ROUGE-1 (unigram), ROUGE-2 (bi-
2Thanks to Rush et al. (2015), we acquired the test set they used.",5.2 Evaluation Metric,[0],[0]
"Following Chopra et al. (2016), we remove pairs with empty titles resulting in slightly different accuracy compared to Rush et al. (2015) for their systems.",5.2 Evaluation Metric,[0],[0]
"The cleaned test set contains 1951 sentence-summary pairs.
",5.2 Evaluation Metric,[0],[0]
"3Our development and test sets can be found at https: //res.qyzhou.me
gram) and ROUGE-L (LCS) as the evaluation metrics in the reported experimental results.",5.2 Evaluation Metric,[0],[0]
"Model Parameters The input and output vocabularies are collected from the training data, which have 119,504 and 68,883 word types respectively.",5.3 Implementation Details,[0],[0]
We set the word embedding size to 300 and all GRU hidden state sizes to 512.,5.3 Implementation Details,[0],[0]
"We use dropout (Srivastava et al., 2014) with probability p = 0.5.
",5.3 Implementation Details,[0],[0]
"Model Training We initialize model parameters randomly using a Gaussian distribution with Xavier scheme (Glorot and Bengio, 2010).",5.3 Implementation Details,[0],[0]
"We use Adam (Kingma and Ba, 2015) as our optimizing algorithm.",5.3 Implementation Details,[0],[0]
"For the hyperparameters of Adam optimizer, we set the learning rate α = 0.001, two momentum parameters β1 = 0.9 and β2 = 0.999 respectively, and = 10−8.",5.3 Implementation Details,[0],[0]
"During training, we test the model performance (ROUGE-2 F1) on development set for every 2,000 batches.",5.3 Implementation Details,[0],[0]
We halve the Adam learning rate α if the ROUGE-2 F1 score drops for twelve consecutive tests on development set.,5.3 Implementation Details,[0],[0]
"We also apply gradient clipping (Pascanu et al., 2013) with range [−5, 5] during training.",5.3 Implementation Details,[0],[0]
"To both speed up the training and converge quickly, we use mini-batch size 64 by grid search.
",5.3 Implementation Details,[0],[0]
Beam Search We use beam search to generate multiple summary candidates to get better results.,5.3 Implementation Details,[0],[0]
"To avoid favoring shorter outputs, we average the ranking score along the beam path by dividing it by the number of generated words.",5.3 Implementation Details,[0],[0]
"To both decode fast and get better results, we set the beam size to
12 in our experiments.",5.3 Implementation Details,[0],[0]
"We compare SEASS model with the following state-of-the-art baselines:
ABS Rush et al. (2015) use an attentive CNN encoder and NNLM decoder to do the sentence summarization task.",5.4 Baseline,[0],[0]
We trained this baseline model with the released code1 and evaluate it with our internal English Gigaword test set and MSR-ATC test set.,5.4 Baseline,[0],[0]
ABS+,5.4 Baseline,[0],[0]
"Based on ABS model, Rush et al. (2015) further tune their model using DUC 2003 dataset, which leads to improvements on DUC 2004 test set.",5.4 Baseline,[0],[0]
CAs2s,5.4 Baseline,[0],[0]
"As an extension of the ABS model, Chopra et al. (2016) use a convolutional attention-based encoder and RNN decoder, which outperforms the ABS model.",5.4 Baseline,[0],[0]
"Feats2s Nallapati et al. (2016) use a full RNN sequence-to-sequence encoder-decoder model and add some features to enhance the encoder, such as POS tag, NER, and so on.",5.4 Baseline,[0],[0]
"Luong-NMT Neural machine translation model of Luong et al. (2015) with two-layer LSTMs for the encoder-decoder with 500 hidden units in each layer implemented in (Chopra et al., 2016).",5.4 Baseline,[0],[0]
s2s+att,5.4 Baseline,[0],[0]
We also implement a sequence-tosequence model with attention as our baseline and denote it as “s2s+att”.,5.4 Baseline,[0],[0]
"We report ROUGE F1, ROUGE recall and ROUGE F1 for English Gigaword, DUC 2004 and MSRATC test sets respectively.",5.5 Results,[0],[0]
We use the official ROUGE script (version 1.5.5) 4 to evaluate the summarization quality in our experiments.,5.5 Results,[0],[0]
"For English Gigaword5 and MSR-ATC6 test sets, the outputs have different lengths so we evaluate the system with F1 metric.",5.5 Results,[0],[0]
"As for the DUC 2004 test set7, the task requires the system to produce a fixed length summary (75 bytes), therefore we employ ROUGE recall as the evaluation metric.",5.5 Results,[0],[0]
"To satisfy the length requirement, we decode the output summary to a roughly expected length following Rush et al. (2015).
",5.5 Results,[0],[0]
"4http://www.berouge.com/ 5The ROUGE evaluation option is the same as Rush et al.
(2015), -m -n 2 -w 1.2 6The ROUGE evaluation option is, -m -n 2 -w 1.2 7The ROUGE evaluation option is, -m -b 75 -n 2 -w 1.2
English Gigaword We acquire the test set from Rush et al. (2015) so we can make fair comparisons to the baselines.
",5.5 Results,[0],[0]
"In Table 3, we report the ROUGE F1 score of our model and the baseline methods.",5.5 Results,[0],[0]
Our SEASS model with beam search outperforms all baseline models by a large margin.,5.5 Results,[0],[0]
"Even for greedy search, our model still performs better than other methods which used beam search.",5.5 Results,[0],[0]
"For the popular ROUGE2 metric, our SEASS model achieves 17.54 F1 score and performs better than the previous works.",5.5 Results,[0],[0]
"Compared to the ABS model, our model has a 6.22 ROUGE-2 F1 relative gain.",5.5 Results,[0],[0]
"Compared to the highest CAs2s baseline, our model achieves 1.57
ROUGE-2 F1 improvement and passes the significant test according to the official ROUGE script.
",5.5 Results,[0],[0]
Table 4 summarizes our results on our internal test set using ROUGE F1 evaluation metrics.,5.5 Results,[0],[0]
"The performance on our internal test set is comparable to our development set, which achieves 24.58 ROUGE-2 F1 and outperforms the baselines.
",5.5 Results,[0],[0]
DUC 2004 We evaluate our model using the ROUGE recall score since the reference summaries of the DUC 2004 test set are capped at 75 bytes.,5.5 Results,[0],[0]
"Therefore, we decode the summary to a fixed length 18 to ensure that the generated summary satisfies the minimum length requirement.",5.5 Results,[0],[0]
"As summarized in Table 5, our SEASS outperforms all the baseline methods and achieves 29.21, 9.56 and 25.51 for ROUGE 1, 2 and L recall.",5.5 Results,[0],[0]
"Compared to the ABS+ model which is tuned using DUC 2003 data, our model performs significantly better by 1.07 ROUGE-2 recall score and is trained only with English Gigaword sentence-summary data without being tuned using DUC data.
",5.5 Results,[0],[0]
MSR-ATC We report the full length ROUGE F1 score on the MSR-ATC test set in Table 6.,5.5 Results,[0],[0]
"To the best of our knowledge, this is the first work that reports ROUGE metric scores on the MSR-ATC dataset.",5.5 Results,[0],[0]
Note that we only compare our model with ABS since the others are not publicly available.,5.5 Results,[0],[0]
Our SEASS achieves 10.63 ROUGE-2 F1 and outperforms the s2s+att baseline by 1.02 points.,5.5 Results,[0],[0]
"In this section, we first compare the performance of SEASS with the s2s+att baseline model to illustrate that the proposed method succeeds in selecting information and building tailored representation for abstractive sentence summarization.",6 Discussion,[0],[0]
"We then analyze selective encoding by visualizing the heat map.
",6 Discussion,[0],[0]
"Effectiveness of Selective Encoding We further test the SEASS model with different sentence lengths on English Gigaword test sets, which are merged from the Rush et al. (2015) test set and our internal test set.",6 Discussion,[0],[0]
The length of sentences in the test sets ranges from 10 to 80.,6 Discussion,[0],[0]
We group the sentences with an interval of 4 and get 18 different groups and we draw the first 14 groups.,6 Discussion,[0],[0]
We find that the performance curve of our SEASS model always appears to be on the top of that of s2s+att with a certain margin.,6 Discussion,[0],[0]
"For the groups of 16, 20, 24, 32, 56 and 60, the SEASS model obtains big improvements compared to the s2s+att model.",6 Discussion,[0],[0]
"Overall, these improvements on all groups indicate that the selective encoding method benefits the abstractive sentence summarization task.
",6 Discussion,[0],[0]
"Saliency Heat Map of Selective Gate Since the output of the selective gate network is a high dimensional vector, it is hard to visualize all the gate values.",6 Discussion,[0],[0]
"We use the method in Li et al. (2016) to visualize the contribution of the selective gate to the final output, which can be approximated by the first derivative.",6 Discussion,[0],[0]
"Given sentence words x with associated output summary y, the trained model associates the pair (x, y) with a score Sy(x).",6 Discussion,[0],[0]
The goal is to decide which gate g associated with a specific word makes the most significant contribution to Sy(x).,6 Discussion,[0],[0]
"We approximate the Sy(g) by computing the first-order Taylor expansion since the score Sy(x) is a highly non-linear function in the deep neural network models:
Sy(g)",6 Discussion,[0],[0]
"≈ w(g)T g + b (19)
where w(g) is first the derivative of Sy with respect to the gate g:
w(g) = ∂(Sy)
∂g",6 Discussion,[0],[0]
"|g (20)
We then draw the Euclidean norm of the first derivative of the output y with respect to the selective gate g associated with each input words.
",6 Discussion,[0],[0]
"Figure 3 shows an example of the first derivative heat map, in which most of the important words are selected by the selective gate such as “europe”, “slammed”, “unacceptable”, “conditions”, and “france”.",6 Discussion,[0],[0]
"We can observe that the selective gate determines the importance of each word before decoder, which releases the burden of it by providing tailored sentence encoding.",6 Discussion,[0],[0]
This paper proposes a selective encoding model which extends the sequence-to-sequence model for abstractive sentence summarization task.,7 Conclusion,[0],[0]
"The selective mechanism mimics one of the human summarizers’ behaviors, selecting important information before writing down the summary.",7 Conclusion,[0],[0]
"With the proposed selective mechanism, we build an end-to-end neural network summarization model which consists of three phases: encoding, selection, and decoding.",7 Conclusion,[0],[0]
"Experimental results show that the selective encoding model greatly improves the performance with respect to the state-of-theart methods on English Gigaword, DUC 2004 and MSR-ATC test sets.",7 Conclusion,[0],[0]
"We thank Chuanqi Tan, Junwei Bao, Shuangzhi Wu and the anonymous reviewers for their helpful comments.",Acknowledgments,[0],[0]
We also thank Alexander M. Rush for providing the dataset for comparison and helpful discussions.,Acknowledgments,[0],[0]
We propose a selective encoding model to extend the sequence-to-sequence framework for abstractive sentence summarization.,abstractText,[0],[0]
"It consists of a sentence encoder, a selective gate network, and an attention equipped decoder.",abstractText,[0],[0]
The sentence encoder and decoder are built with recurrent neural networks.,abstractText,[0],[0]
The selective gate network constructs a second level sentence representation by controlling the information flow from encoder to decoder.,abstractText,[0],[0]
"The second level representation is tailored for sentence summarization task, which leads to better performance.",abstractText,[0],[0]
"We evaluate our model on the English Gigaword, DUC 2004 and MSR abstractive sentence summarization datasets.",abstractText,[0],[0]
The experimental results show that the proposed selective encoding model outperforms the state-ofthe-art baseline models.,abstractText,[0],[0]
Selective Encoding for Abstractive Sentence Summarization,title,[0],[0]
Finding statistically reliable high-order interaction features in predictive modeling has been important challenging task.,1. Introduction,[0],[0]
"For example, in a biomedical study, co-occurrence of multiple mutations in multiple genes may have a significant influence on a response to a drug even if occurrence of single mutation in each of these genes has no influence (Manolio & Collins, 2006; Cordell, 2009).",1. Introduction,[0],[0]
A major challenge in prediction modeling with high-order interaction features is the exponentially expanded feature space.,1. Introduction,[0],[0]
"If one has a dataset with d original variables and takes into account interactions up to order r, the model has D := ∑r ρ=1",1. Introduction,[0],[0]
"( d ρ
) features (e.g., for d = 10, 000, r = 5, D > 1017).",1. Introduction,[0],[0]
"Unless both d and r are fairly small, D is extremely large.",1. Introduction,[0],[0]
"Feature selection and statistical inference in such an extremely high-dimensional model are challenging both computationally and statistically.
",1. Introduction,[0],[0]
"A common approach to high-dimensional modeling is to consider a sparse model, i.e., a model only with a selected
1Nagoya Institute of Technology, Nagoya, Japan 2University of Tokyo, Tokyo, Japan 3RIKEN, Tokyo, Japan.",1. Introduction,[0],[0]
"Correspondence to: Ichiro Takeuchi <takeuchi.ichiro@nitech.ac.jp>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
subset of features.",1. Introduction,[0],[0]
"In the past two decades, considerable amount of studies have been done on sparse modeling and feature selection in high-dimensional models.",1. Introduction,[0],[0]
"In these studies, a variety of feature selection algorithms such as marginal screening (Fan & Lv, 2008), orthogonal matching pursuit (Pati et al., 1993), LASSO (Tibshirani, 1996), and their various extensions have been developed.",1. Introduction,[0],[0]
"On the other hand, statistical inference for sparse models (hypothesis testing or confidence interval computation of the fitted coefficients) have not been deeply studied until very recently.",1. Introduction,[0],[0]
"The main challenge in statistical inference of sparse models is that, if the data is used for selecting a subset of features, this selection event must be taken into account in the following inference stage.",1. Introduction,[0],[0]
"Otherwise, the inference results are distorted by so-called selection bias, and false positive errors cannot be controlled at desired levels.",1. Introduction,[0],[0]
"This problem is refereed to as selective inference or post selection inference (Benjamini & Yekutieli, 2005; Benjamini et al., 2009; Berk et al., 2013).",1. Introduction,[0],[0]
"After the seminal work by Lee et al. (2016), significant progress has been recently made on selective inference for sparse linear models (Fithian et al., 2014b; Lee & Taylor, 2014; Fithian et al., 2015; Tian & Taylor, 2015; Taylor & Tibshirani, 2016; Yang et al., 2016; Barber & Candès, 2016).
",1. Introduction,[0],[0]
"In this paper, we study feature selection and statistical inference for sparse high-order interaction models.",1. Introduction,[0],[0]
"Unfortunately, neither existing feature selection methods nor existing selective inference methods can be applied to sparse high-order interaction models because the computational costs of these existing methods at least linearly depend on the number of features D. The main contribution in this paper is to develop computationally efficient algorithms for these two tasks when the original variables are represented in [0, 1]d.",1. Introduction,[0],[0]
"Our main idea is to exploit the underlying tree structure of high-order interaction features as depicted in
Figure 1.",1. Introduction,[0],[0]
"In feature selection tasks, it allows us to efficiently identify interaction features that have no chance to be selected.",1. Introduction,[0],[0]
"In statistical inference tasks, it allows us to efficiently identify interaction features that do not affect the results of the selective inference.
",1. Introduction,[0],[0]
We demonstrate the effectiveness of the proposed methods through numerical experiments both on synthetic and real datasets.,1. Introduction,[0],[0]
"In the latter, we apply the proposed method to HIV dataset in (Rhee et al., 2003), where the goal is to identify statistically significant high-order interactions of multiple gene mutations that are significantly associated with HIV drug responses.
",1. Introduction,[0],[0]
"Related works and our contributions Methods for efficiently finding high-order interaction features and properly evaluating their statistical significances have long been desired in many scientific studies.
",1. Introduction,[0],[0]
"In the past decade, feature selection for interaction models has been studied in the context of sparse learning (Choi et al., 2010; Hao & Zhang, 2014; Bien et al., 2013).",1. Introduction,[0],[0]
"None of these works have a special computational trick for handling exponentially large number of interaction features, which makes their empirical evaluations restricted up-to second order interactions.",1. Introduction,[0],[0]
"One commonly used heuristic in the context of interaction modeling is to introduce a prior knowledge such as strong heredity assumption where, e.g., an interaction term z1z2 would be selected only when both of z1 and z2 are selected.",1. Introduction,[0],[0]
Such a heuristic restriction is helpful for reducing the number of interaction terms to be considered.,1. Introduction,[0],[0]
"However, in many scientific studies, researchers are primarily interested in finding interactions even when their main effects alone do not have any association with the response.",1. Introduction,[0],[0]
"The idea of considering a tree structure among interaction features has been commonly used n data mining literature (Kudo et al., 2005; Saigo et al., 2006; Nakagawa et al., 2016).",1. Introduction,[0],[0]
"However, it is difficult to properly assess the statistical significances of the selected features by these mining techniques.
",1. Introduction,[0],[0]
One traditional approach to assessing the statistical significances of selected features is multiple testing correction (MTC).,1. Introduction,[0],[0]
"In the context of DNA microarray studies, many MTC procedures for high-dimensional data have been proposed (Tusher et al., 2001; Dudoit et al., 2003).",1. Introduction,[0],[0]
"An MTC approach for statistical evaluation of high-order interaction features was recently studied in (Terada et al., 2013; Llinares-López et al., 2015).",1. Introduction,[0],[0]
A main drawback of MTC is that they are highly conservative when the number of candidate features increases.,1. Introduction,[0],[0]
Another common approach is datasplitting (DS).,1. Introduction,[0],[0]
"(Fithian et al., 2014a).",1. Introduction,[0],[0]
"In DS approach, we split the data into two subsets, and use one for feature selection and another for statistical inference, which enables us to remove the selection bias.",1. Introduction,[0],[0]
"However, performances
of DS approach is clearly weak both in selection and inference stages because only a part of the available data is used in each stage.",1. Introduction,[0],[0]
"In addition, it is quite annoying that different set of features would be selected if data is splitted differently.",1. Introduction,[0],[0]
"Recently, much attention has been paid to selective inference for sparse linear models.",1. Introduction,[0],[0]
The basic idea of selective inference is to make inferences conditional on a feature selection event.,1. Introduction,[0],[0]
"Lee et al. (2016) recently proposed a practical selective inference framework for a class of feature selection algorithms.
",1. Introduction,[0],[0]
The main contribution in this paper is to extend the selective inference framework into sparse high-order interaction models by introducing novel computational algorithms.,1. Introduction,[0],[0]
"To the best of our knowledge, there are no other existing works for sparse high-order interaction models in which the statistical significances of the fitted coefficients are properly evaluated in non-asymptotic sense.
Notations We use the following notations in the remainder.",1. Introduction,[0],[0]
"For any natural number n, we define [n] := {1, . . .",1. Introduction,[0],[0]
", n}.",1. Introduction,[0],[0]
A vector and a matrix is denoted such as v ∈,1. Introduction,[0],[0]
"Rn and M ∈ Rn×m, respectively.",1. Introduction,[0],[0]
"The index function is written as 1{z} which returns 1 if z is true, and 0 otherwise.",1. Introduction,[0],[0]
"The sign function is written as sgn(z) which returns 1 if z ≥ 0, and −1 otherwise.",1. Introduction,[0],[0]
An n × n identity matrix is denoted as In.,1. Introduction,[0],[0]
Consider a regression problem with a response Y ∈ R and d-dimensional original covariates z =,2.1. Problem setup,[0],[0]
"[z1, . . .",2.1. Problem setup,[0],[0]
", zd]> by the following high-order interaction model up to r-th order
Y = ∑ j1∈[d] αj1zj1 + ∑
(j1,j2)∈[d]×[d] j1 6=j2
αj1,j2zj1zj2
+ · · ·+ ∑
(j1,...,jr)∈[d]r j1 6=...6=jr
αj1,...,jrzj1 · · · zjr + ε, (1)
where αs are the coefficients and ε is a random noise.",2.1. Problem setup,[0],[0]
"We assume that each original covariate zj , j ∈",2.1. Problem setup,[0],[0]
"[d] is defined in a domain [0, 1].",2.1. Problem setup,[0],[0]
"Here, values 1 and 0 respectively might be interpreted as the existence and the non-existence of a certain property, and values between them indicate the “degree” of existence.",2.1. Problem setup,[0],[0]
High-order interaction features thus represent co-existence of multiple properties.,2.1. Problem setup,[0],[0]
"For example, if we are interested in interactions among age, body mass index (BMI), and a mutation in a certain gene, we may code
some covariates as
zj1 :=  1 if BMI > 30,(BMI− 15)/(30− 15) if BMI ∈",2.1. Problem setup,[0],[0]
"[15, 30], 0 if BMI < 15,
zj2",2.1. Problem setup,[0],[0]
":= 1{mutation in the gene}.
",2.1. Problem setup,[0],[0]
"Then, e.g., an interaction term zj1zj2 represents the coexistence of high BMI and a mutation in the gene.",2.1. Problem setup,[0],[0]
The high-order interaction model Eq.(1) has in total D :=∑ ρ∈[r],2.1. Problem setup,[0],[0]
( d ρ ) features.,2.1. Problem setup,[0],[0]
Let us write the mapping from the original covariates z,2.1. Problem setup,[0],[0]
:=,2.1. Problem setup,[0],[0]
"[z1, . . .",2.1. Problem setup,[0],[0]
", zd]> ∈ Rd to the highorder interaction features x :=",2.1. Problem setup,[0],[0]
"[x1, . . .",2.1. Problem setup,[0],[0]
", xD]> ∈ RD as φ :",2.1. Problem setup,[0],[0]
"[0, 1]d →",2.1. Problem setup,[0],[0]
"[0, 1]D, z 7→ x,, i.e.,
x := φ(z) =",2.1. Problem setup,[0],[0]
"[z1, . . .",2.1. Problem setup,[0],[0]
", zd, z1z2, . . .",2.1. Problem setup,[0],[0]
", zd−1zd,
. . .",2.1. Problem setup,[0],[0]
", z1 ···zk, . . .",2.1. Problem setup,[0],[0]
", zd−r+1 ···zd]>
Then, the high-order interaction model Eq.(1) is simply written as a D-dimensional linear model
y = β>x = β1x1",2.1. Problem setup,[0],[0]
"+ · · ·+ βDxD,
where β1, . . .",2.1. Problem setup,[0],[0]
", βD are D coefficients corresponding to αj1 , . . .",2.1. Problem setup,[0],[0]
", αj1,...,jr in Eq.(1).",2.1. Problem setup,[0],[0]
"Since a high-order interaction feature is a product of original covariates defined in [0, 1], the range of each feature xj , j ∈",2.1. Problem setup,[0],[0]
"[D] is also [0, 1].
",2.1. Problem setup,[0],[0]
"The original training set is denoted as {(zi, yi) ∈",2.1. Problem setup,[0],[0]
"[0, 1]d × R}i∈[n], while the expanded training set is written as {(xi, yi) ∈",2.1. Problem setup,[0],[0]
"[0, 1]D ×R}i∈[n].",2.1. Problem setup,[0],[0]
"The latter is also denoted as (X,y) ∈",2.1. Problem setup,[0],[0]
"[0, 1]n×D ×Rn where each row of X is xi ∈ Rd and each element of y is yi.",2.1. Problem setup,[0],[0]
"Furthermore, the j-th column of X is written as x·j , j ∈",2.1. Problem setup,[0],[0]
[D].,2.1. Problem setup,[0],[0]
"We denote the pseudo inverse of X as X+ := (X>X)−1X>.
",2.1. Problem setup,[0],[0]
Our goal is to identify statistically significant high-order interaction terms that have large impacts on the response Y by identifying regression coefficients αs which are significantly deviated from zero.,2.1. Problem setup,[0],[0]
"Unfortunately, since the number of coefficients αs to be fitted would be far greater than the sample size n, traditional least-square estimation theory cannot be used for making statistical inferences on the fitted model.",2.1. Problem setup,[0],[0]
We thus consider first to perform feature selection and then to make statistical inference only for the selected features based on selective inference approach.,2.1. Problem setup,[0],[0]
"In this section, we briefly review the selective inference framework for sparse linear models developed by Lee et al. (2016).",2.2. Selective inference for sparse linear models,[0],[0]
"Selective inference is developed for two stage methods, where a subset of features is selected in the first stage, and inferences are made only on the selected features in the second stage.",2.2. Selective inference for sparse linear models,[0],[0]
"A key finding by Lee et al. (2016) is
that, if the first selection stage is described as a linear selection event, then exact statistical inference of the fitted coefficients conditional on the selection event can be done.
",2.2. Selective inference for sparse linear models,[0],[0]
Consider a linear regression model y = Xβ∗,2.2. Selective inference for sparse linear models,[0],[0]
"+ ε, where β∗ ∈ RD is the true coefficients and ε is distributed according to N(0, σ2I) with known variance σ2.
",2.2. Selective inference for sparse linear models,[0],[0]
"Feature selection stage Suppose that, in the first feature selection stage, a subset of features S ⊆",2.2. Selective inference for sparse linear models,[0],[0]
[D] are selected.,2.2. Selective inference for sparse linear models,[0],[0]
The selective inference framework in Lee et al. (2016) can be applied to feature selection algorithms whose selection process can be characterized by a set of linear inequalities in the form of Ay ≤ b with a certain matrix A and a certain vector b that do not depend on y.,2.2. Selective inference for sparse linear models,[0],[0]
This type of selection event is called a linear selection event.,2.2. Selective inference for sparse linear models,[0],[0]
"In the selective inference framework, inferences are made conditional on the selection event.",2.2. Selective inference for sparse linear models,[0],[0]
"It means that, in the case of a linear selection event, we only care about the cases where y is observed in a polytope Pol(S) := {y ∈",2.2. Selective inference for sparse linear models,[0],[0]
Rn | Ay ≤ b}.,2.2. Selective inference for sparse linear models,[0],[0]
"In Lee & Taylor (2014) and Lee et al. (2016), marginal screening, OMP and LASSO are shown to be linear selection events, indicating that the selective inference framework can be applied to statistical testing of the selected features by these algorithms.
",2.2. Selective inference for sparse linear models,[0],[0]
"Statistical inference stage Consider a hypothesis testing for the j-th selected feature in S
H0,j : β ∗ S,j = 0 vs. H1,j : β ∗ S,j 6= 0.",2.2. Selective inference for sparse linear models,[0],[0]
"(2)
The least-square estimator of the linear model only with the selected features S is written as β̂S = (X>S XS) −1X>S y.
",2.2. Selective inference for sparse linear models,[0],[0]
"If we consider the case where S is NOT selected from the data, i.e., independent of y, then, under the null hypothesis H0, the sampling distribution of each fitted coefficient is
β̂S,j ∼ N(0, σ2S,j), where σ2S,j := σ2(X>S XS)−1jj .",2.2. Selective inference for sparse linear models,[0],[0]
"(3)
For two-sided test at level α, if the critical values `α/2 and uα/2 are chosen to be the lower and the upper α/2 points of the sampling distribution in Eq.(3), then the type I error at level α is controlled as
Pr(β̂S,j /∈",2.2. Selective inference for sparse linear models,[0],[0]
"[`α/2, uα/2]) ≤ α (4)
",2.2. Selective inference for sparse linear models,[0],[0]
"On the other hand, when S is selected from the data as we consider here, we would like to control the following selective type I error
Pr(β̂S,j /∈",2.2. Selective inference for sparse linear models,[0],[0]
"[`(S,j)α/2 , u (S,j) α/2 ] | {S is selected})
",2.2. Selective inference for sparse linear models,[0],[0]
"=Pr(β̂S,j /∈",2.2. Selective inference for sparse linear models,[0],[0]
"[`(S,j)α/2 , u (S,j) α/2 ]",2.2. Selective inference for sparse linear models,[0],[0]
"| y ∈ Pol(S)) ≤ α (5)
by appropriately selecting the adjusted critical values `(S,j)α/2 and u(S,j)α/2 , where the selection event {S is selected} is
written as y ∈ Pol(S) in the case of a linear selection event.",2.2. Selective inference for sparse linear models,[0],[0]
"Lee et al. (2016) derived how to compute these adjusted critical values as formally stated in the following lemma.
",2.2. Selective inference for sparse linear models,[0],[0]
Lemma 1.,2.2. Selective inference for sparse linear models,[0],[0]
"If the critical values are computed as
` (S,j) α/2 := (F [L(S,j),U(S,j)] 0,σ2S,j )−1(α/2),",2.2. Selective inference for sparse linear models,[0],[0]
"(6a)
u (S,j) α/2 := (F [L(S,j),U(S,j)] 0,σ2S,j )−1(1− α/2), (6b)
then the selective type I error is controlled as in Eq.",2.2. Selective inference for sparse linear models,[0],[0]
"(5), where F [L,U ]µ,σ2 is the cumulative distribution function of a truncated Normal distribution TN(µ, σ2, L, U), i.e.,
",2.2. Selective inference for sparse linear models,[0],[0]
"F [L,U ] µ,σ2 (x) = Φ((x− µ)/σ)− Φ((L− µ)/σ) Φ((U",2.2. Selective inference for sparse linear models,[0],[0]
"− µ)/σ)− Φ((L− µ)/σ) ,
and the truncation points are obtained, by using the observed β̂S,j and y, as
L(S, j) = β̂S,j + θL(X > S XS) −1",2.2. Selective inference for sparse linear models,[0],[0]
"jj , (7a)
where θL := min θ∈R
θ s.t. y + θ(X+S )",2.2. Selective inference for sparse linear models,[0],[0]
">ej ∈ Pol(S),
U(S, j) = β̂S,j + θU (X > S XS) −1",2.2. Selective inference for sparse linear models,[0],[0]
"jj , (7b)
where θU := max θ∈R
θ s.t. y + θ(X+S )",2.2. Selective inference for sparse linear models,[0],[0]
">ej ∈ Pol(S).
",2.2. Selective inference for sparse linear models,[0],[0]
The proof of Lemma 1 is is presented in Appendix A although it is easily proved by using the results in Lee et al. (2016).,2.2. Selective inference for sparse linear models,[0],[0]
"See Lee et al. (2016) for more general statement about the selective inference framework.
",2.2. Selective inference for sparse linear models,[0],[0]
"Eq.(7) indicates that the truncation points are obtained by considering the interval where the test statistic β̂S,j can move within the polyhedron Pol(S).",2.2. Selective inference for sparse linear models,[0],[0]
"Figure 2 schematically illustrates that, when we make inferences conditional on a linear selection event S, the sampling distribution is defined within the polytope Pol(S), and it follows a truncated normal distribution when y is normally distributed.
",2.2. Selective inference for sparse linear models,[0],[0]
"Unfortunately, we cannot directly apply this selective inference framework to high-order interaction models because the polytope Pol(S) is characterized by extremely large number of linear inequalities, and the optimization problems in Eq.(7) are hard to solve.",2.2. Selective inference for sparse linear models,[0],[0]
"In this section, we present two feature selection algorithms for high-order interaction models.",3. Feature selection for interaction models,[0],[0]
"Since the number of features D is extremely large, existing feature selection algorithms for linear models cannot be directly applied to interaction models.",3. Feature selection for interaction models,[0],[0]
"In this paper, we study marginal screening (MS) and orthogonal matching pursuit (OMP) as examples of feature selection algorithms.",3. Feature selection for interaction models,[0],[0]
Consider selecting the top k interaction features from all the D interaction features that have marginal strong correlations with the response.,3.1. MS for interaction models,[0],[0]
"Noting that each feature is defined in [0, 1] and the value indicates (the degree of) the existence of a certain property, we consider a score x>·jy, j ∈",3.1. MS for interaction models,[0],[0]
"[D] for each of the D features, and select the top k features according to their absolute scores |x>·jy|.",3.1. MS for interaction models,[0],[0]
"We denote the index set of the selected k features by S, and that of the unselected k̄ := D − k features by S̄ := [D] \ S.
Since D is extremely large, we cannot compute the score for each interaction feature.",3.1. MS for interaction models,[0],[0]
"We exploit the tree structure among interaction patterns as depicted in Figure 1.
",3.1. MS for interaction models,[0],[0]
Definition 2.,3.1. MS for interaction models,[0],[0]
(Descendant features),3.1. MS for interaction models,[0],[0]
For each j ∈,3.1. MS for interaction models,[0],[0]
"[D], let Des(j)",3.1. MS for interaction models,[0],[0]
⊆,3.1. MS for interaction models,[0],[0]
"[D] be the set of features corresponding to the descendant nodes in the tree including j itself.
",3.1. MS for interaction models,[0],[0]
Lemma 3.,3.1. MS for interaction models,[0],[0]
"Consider an interaction feature x·j , j ∈",3.1. MS for interaction models,[0],[0]
"[D], whose indices are represented in a tree structure as depicted in Figure1.",3.1. MS for interaction models,[0],[0]
"Then, for any node j ∈",3.1. MS for interaction models,[0],[0]
"[D] in the tree,
|x·j̃y| ≤ max  ∑",3.1. MS for interaction models,[0],[0]
i:,3.1. MS for interaction models,[0],[0]
"yi>0 xijyi,− ∑",3.1. MS for interaction models,[0],[0]
i:,3.1. MS for interaction models,[0],[0]
"yi<0 xijyi  (8) for all j̃ ∈ Des(j).
",3.1. MS for interaction models,[0],[0]
"The proof of Lemma 3 is presented in Appendix A. Lemma 3 tells that, for a descendant feature x·j̃ , (j, j̃) ∈ S × Des(j), an upper bound of the absolute score |x>·j̃y| can be computed based on its parent feature x·j .
",3.1. MS for interaction models,[0],[0]
"We note that this simple upper bound has been used in some data mining studies such as Saigo et al. (2006); Kudo et al.
(2004); Nakagawa et al. (2016).",3.1. MS for interaction models,[0],[0]
"When we search over the tree, if the upper bound in Eq.(8) is smaller than the current k-th largest score at a certain node j, then we can quit searching over its descendant nodes j̃ ∈ Des(j).
",3.1. MS for interaction models,[0],[0]
"As pointed out in Lee & Taylor (2014), feature selection processes of marginal screening is a linear selection event, i.e., characterized by a set of linear constraints.",3.1. MS for interaction models,[0],[0]
"The event that k features in S are selected, and k̄ features in S̄ are not selected is rephrased as |x>·jy| ≥ |x>·j′y|, ∀ (j, j′) ∈ S × S̄. Let sj := sgn(x>·jy),",3.1. MS for interaction models,[0],[0]
j ∈ S.,3.1. MS for interaction models,[0],[0]
"Then, the above feature selection event is rewritten with the sign constraints of the selected features by the following 2kk̄+k constraints
(−sjx·j − x·j′)>y ≤ 0, ∀ (j, j′) ∈ S × S̄, (9a) (−sjx·j + x·j′)>y ≤ 0, ∀ (j, j′) ∈ S × S̄, (9b)
−sjx>·jy ≤ 0, ∀ j ∈ S. (9c)
",3.1. MS for interaction models,[0],[0]
These constraints are written as Ay ≤ 0 with a matrix A ∈ R(2kk̄+k)×n.,3.1. MS for interaction models,[0],[0]
"Unfortunately, finding θmin and θmax by naively solving the optimization problems in Eq.(7) is computationally difficult because the polyhedron Pol(S) is characterized by the extremely large number of constraints.",3.1. MS for interaction models,[0],[0]
"For example, when d = 10, 000, r = 5, k = 10, the number of linear inequalities that defines the polyhedron Pol(S) is 2kk̄ + k > 1019.",3.1. MS for interaction models,[0],[0]
"Orthogonal matching pursuit (OMP) is a well-known iterative feature selection method (Pati et al., 1993).",3.2. OMP for interaction models,[0],[0]
"At each iteration, the most correlated feature with the residual of the current model which is fitted via least-squares method by using the features selected in earlier steps.
",3.2. OMP for interaction models,[0],[0]
Consider again selecting k interaction features by OMP.,3.2. OMP for interaction models,[0],[0]
"Let [(1), . . .",3.2. OMP for interaction models,[0],[0]
", (h)] be the sequence of the indices of the selected features from step 1 to step h for h ∈",3.2. OMP for interaction models,[0],[0]
"[k], and define Sh := {(1), . . .",3.2. OMP for interaction models,[0],[0]
", (h)}.",3.2. OMP for interaction models,[0],[0]
"Before step h + 1, we have already selected h features",3.2. OMP for interaction models,[0],[0]
"x·j , j ∈ Sh.",3.2. OMP for interaction models,[0],[0]
"Using these h features, the current n-dimensional model output is written as∑ j∈[h] β̂Sh,(j)x·(j), where the coefficients β̂Sh,(j), j ∈",3.2. OMP for interaction models,[0],[0]
[h] are estimated by least-squares method.,3.2. OMP for interaction models,[0],[0]
"Denoting by ΓSh the n×hmatrix whose j-th column isx·(j), the least square estimates are written as β̂Sh := [β̂Sh,(1), . . .",3.2. OMP for interaction models,[0],[0]
", β̂Sh,(h)]
> = (ΓSh)
",3.2. OMP for interaction models,[0],[0]
"+y. Then, at the h + 1 step, we consider the correlation between the residual vector rh := y",3.2. OMP for interaction models,[0],[0]
"− ΓSh β̂Sh and a feature x·j′ for j′ ∈ S̄h, and find the one that maximizes the absolute correlation |x>·j′rh| among them.",3.2. OMP for interaction models,[0],[0]
"Here, since the number of remaining features |S̄h| = D",3.2. OMP for interaction models,[0],[0]
"− h is still extremely large, it is hard to compute all these D − h correlations.",3.2. OMP for interaction models,[0],[0]
"To overcome this difficulty, we can simply use Lemma 3 just by replacing y with the current residual rh.",3.2. OMP for interaction models,[0],[0]
"Specifically, for a descendant feature x·j̃ , j̃ ∈ Des(j), an
upper bound of |x>·j̃rh| is given as
|x>·j̃rh| ≤ max  ∑",3.2. OMP for interaction models,[0],[0]
"i:rh,i>0 xijrh,i,− ∑",3.2. OMP for interaction models,[0],[0]
"i:rh,i<0 xijrh,i  .",3.2. OMP for interaction models,[0],[0]
"At each iteration, when we search over the tree, if the upper bound is smaller than the current largest correlation, then, in the same way as the case of MS, we can quit searching over its descendant nodes j′ ∈ Des(j).
",3.2. OMP for interaction models,[0],[0]
It is also pointed out in Lee & Taylor (2014) that a feature selection process of OMP is linear selection event.,3.2. OMP for interaction models,[0],[0]
"At step h, the event that the (h)-th feature is selected is formulated as |x>·(h)rh| ≥ |x",3.2. OMP for interaction models,[0],[0]
>,3.2. OMP for interaction models,[0],[0]
"·j′rh|, for all j′ ∈ S̄h.",3.2. OMP for interaction models,[0],[0]
Let PSh :,3.2. OMP for interaction models,[0],[0]
=,3.2. OMP for interaction models,[0],[0]
"In − ΓShΓ + Sh
.",3.2. OMP for interaction models,[0],[0]
"Then, the above selection event is rewritten as a set of linear inequalities with respect to y
(−s(h)x·(h) − x·j′)>PShy ≤ 0,∀ j′",3.2. OMP for interaction models,[0],[0]
"∈ S̄h, (10a) (−s(h)x·(h) +",3.2. OMP for interaction models,[0],[0]
"x·j′)>PShy ≤ 0,∀ j′",3.2. OMP for interaction models,[0],[0]
"∈ S̄h, (10b)
−s(h)x>·(h)PShy ≤ 0, (10c)
where s(h) = sgn(x>·(h)rh).",3.2. OMP for interaction models,[0],[0]
"By combining all the linear selection events in k steps, the entire selection event of the OMP is characterized by ∑ h∈[k](2(D − h) + 1) linear inequalities in Rn.",3.2. OMP for interaction models,[0],[0]
"In practice, it is computationally intractable to handle these extremely large number of linear inequalities.",3.2. OMP for interaction models,[0],[0]
"In this section, we present an efficient selective inference algorithm for high-order interaction models, which is our main contribution.
",4. Selective inference for interaction models,[0],[0]
The discussion in §3 suggests that it would be hard to compute critical values for selective inference in Eq.(6) because the selection event y ∈ Pol(S) is characterized by extremely large number of inequalities.,4. Selective inference for interaction models,[0],[0]
"Our basic idea for addressing this computational difficulty is to note that most of the inequalities actually do not affect the results of the selective inference, and a large portion of them can be identified by exploiting the anti-monotonicity properties defined in the tree structure among high-order interaction features.",4. Selective inference for interaction models,[0],[0]
We consider k trees for each of the k selected features.,4.1. Marginal screening,[0],[0]
Each tree consists of a set of nodes corresponding to each of the non-selected features j′ ∈ S̄.,4.1. Marginal screening,[0],[0]
"For a pair (j, j′) ∈ S× S̄, the j′-th node in the j-th tree corresponds to the linear inequalities Eqs.(9a) and (9b).",4.1. Marginal screening,[0],[0]
"When we search over these k trees, we introduce a novel pruning strategy by deriving a condition such that, if the j′-th node in the j-th tree satisfies certain conditions, then all the (j, j̃′)-th inequalities for all
j̃′ ∈ Desj(j′) are guaranteed to be irrelevant to the selective inference results because they do not affect the optimal solutions in Eq.(7), where we define Desj(j′) be all the features corresponding to the descendant node of j′ in the j-th tree.",4.1. Marginal screening,[0],[0]
Lemma 4.,4.1. Marginal screening,[0],[0]
Let η := (X+S ) >ej .,4.1. Marginal screening,[0],[0]
"The solutions of the optimization problems in (7) are respectively written as
θL = −min{θ(a)L , θ (b) L , θ (c) L }, θU = −max{θ(a)U , θ (b) U , θ (c) U },
where
θ (a) L := min
(j,j′)∈S×S̄, (sjx·j+x·j′ ) >η>0
(sjx·j + x·j′)>y (sjx·j + x·j′)>η , (11a)
θ (a) U := max
(j,j′)∈S×S̄, (sjx·j+x·j′ )",4.1. Marginal screening,[0],[0]
">η<0
(sjx·j + x·j′)>y (sjx·j + x·j′)>η , (11b)
θ (b) L := min
(j,j′)∈S×S̄, (sjx·j−x·j′ )>η>0
(sjx·j − x·j′)>y (sjx·j − x·j′)>η , (11c)
θ (b) U := max
(j,j′)∈S×S̄, (sjx·j−x·j′ )",4.1. Marginal screening,[0],[0]
">η<0
(sjx·j − x·j′)>y (sjx·j − x·j′)>η , (11d)
θ",4.1. Marginal screening,[0],[0]
"(c) L := min
j∈S, sjx >",4.1. Marginal screening,[0],[0]
"·jη>0
sjx >",4.1. Marginal screening,[0],[0]
"·jy sjx>·jη , θ (c) U := max
j∈S, sjx >",4.1. Marginal screening,[0],[0]
"·jη<0
sjx > ·jy sjx>·jη .
",4.1. Marginal screening,[0],[0]
The proof of Lemma 4 is presented in Appendix A. Lemma 5.,4.1. Marginal screening,[0],[0]
"For any triplet (j, j′, j̃′) ∈ S × S̄ ×Desj(j′),
L (a) E := sjx > ·jy + ∑",4.1. Marginal screening,[0],[0]
i:yi<0 xij′yi ≤ (sjx·j + x·j̃′),4.1. Marginal screening,[0],[0]
">y, (12a)
U (a) E := sjx",4.1. Marginal screening,[0],[0]
>,4.1. Marginal screening,[0],[0]
·jy + ∑,4.1. Marginal screening,[0],[0]
i:yi>0 xij′yi ≥ (sjx·j + x·j̃′),4.1. Marginal screening,[0],[0]
">y, (12b)
L (a) D := sjx >",4.1. Marginal screening,[0],[0]
·jη + ∑ i:ηi<0 xij′ηi ≤ (sjx·j + x·j̃′),4.1. Marginal screening,[0],[0]
">η, (12c)
U (a) D := sjx >",4.1. Marginal screening,[0],[0]
·jη + ∑ i:ηi>0 xij′ηi ≥ (sjx·j + x·j̃′),4.1. Marginal screening,[0],[0]
">η, (12d)
L (b) E := sjx",4.1. Marginal screening,[0],[0]
>,4.1. Marginal screening,[0],[0]
·jy − ∑ i:yi>0 xij′yi ≤ (sjx·j − x·j̃′),4.1. Marginal screening,[0],[0]
">y, (12e)
U (b) E := sjx >",4.1. Marginal screening,[0],[0]
·jy − ∑ i:,4.1. Marginal screening,[0],[0]
yi<0 xij′yi ≥ (sjx·j − x·j̃′),4.1. Marginal screening,[0],[0]
">y, (12f)
L (b) D := sjx",4.1. Marginal screening,[0],[0]
>,4.1. Marginal screening,[0],[0]
·jη − ∑ i:ηi>0 xij′ηi ≤ (sjx·j − x·j̃′),4.1. Marginal screening,[0],[0]
>,4.1. Marginal screening,[0],[0]
"η, (12g)
",4.1. Marginal screening,[0],[0]
U (b) D := sjx >,4.1. Marginal screening,[0],[0]
·jη − ∑ i:ηi<0 xij′ηi ≥ (sjx·j − x·j̃′),4.1. Marginal screening,[0],[0]
>η.,4.1. Marginal screening,[0],[0]
"(12h)
The proof of Lemma 5 is presented in Appendix A.
Theorem 6.",4.1. Marginal screening,[0],[0]
"(i) Consider solving the optimization problem in Eq.(11a), and let θ̂(a)L be the current optimal solution, i.e., we know that the optimal θ(a)L is at least no greater than θ̂(a)L .",4.1. Marginal screening,[0],[0]
"If
{U (a)D < 0} ∪ {L (a) D > 0, L (a) E < 0, L (a) E /L",4.1. Marginal screening,[0],[0]
"(a) D > θ̂ (a) L }
∪ {L(a)D > 0, L (a) E > 0, L (a) E /U",4.1. Marginal screening,[0],[0]
"(a) D > θ̂ (a) L }
is true, then the (j, j̃′)-th constraint in Eq.",4.1. Marginal screening,[0],[0]
"(9a) for any (j, j′, j̃′) ∈ S × S̄ ×Desj(j′) does not affect the optimal solution in Eq.(11a).
",4.1. Marginal screening,[0],[0]
(ii),4.1. Marginal screening,[0],[0]
"Next, consider solving the optimization problem in Eq.(11c), and let θ̂(b)L be the current optimal solution.",4.1. Marginal screening,[0],[0]
"If
{U (b)D < 0} ∪ {L (b) D > 0, L (b) E < 0, L (b) E /L",4.1. Marginal screening,[0],[0]
"(b) D > θ̂ (b) L }
∪ {L(b)D > 0, L (b) E > 0, L (b) E /U",4.1. Marginal screening,[0],[0]
"(b) D > θ̂ (b) L }
is true, then the (j, j̃′)-th constraint in Eq.",4.1. Marginal screening,[0],[0]
"(9b) for any (j, j′, j̃′) ∈ S × S̄ ×Desj(j′) does not affect the optimal solution in Eq.(11c).
",4.1. Marginal screening,[0],[0]
"(iii) Furthermore, consider solving the optimization problem in Eq.(11b), and let θ̂(a)U be the current optimal solution.",4.1. Marginal screening,[0],[0]
"If
{L(a)D > 0} ∪ {U (a) D < 0, L (a) E < 0, L (a) E /U",4.1. Marginal screening,[0],[0]
"(a) D < θ̂ (a) U }
∪ {U (a)D < 0, L (a) E > 0, L (a) E /L",4.1. Marginal screening,[0],[0]
"(a) D < θ̂ (a) U }
is true, then the (j, j̃′)-th constraint in Eq.",4.1. Marginal screening,[0],[0]
"(9a) for any (j, j′, j̃′) ∈ S × S̄ ×Desj(j′) does not affect the optimal solution in Eq.(11b).
",4.1. Marginal screening,[0],[0]
"(iv) Finally, consider solving the optimization problem in Eq.(11d), and let θ̂(b)U be the current optimal solution.",4.1. Marginal screening,[0],[0]
"If
{L(b)D > 0} ∪ {U (b) D > 0, L (b) E < 0, L (b) E /U",4.1. Marginal screening,[0],[0]
"(b) D < θ̂ (b) U }
∪ {U (b)D > 0, L (b) E < 0, L (b) E /L",4.1. Marginal screening,[0],[0]
"(b) D < θ̂ (b) U }
is true, then the (j, j̃′)-th constraint in Eq.",4.1. Marginal screening,[0],[0]
"(9b) for any (j, j′, j̃′) ∈ S × S̄ ×Desj(j′) does not affect the optimal solution in Eq.(11d).
",4.1. Marginal screening,[0],[0]
The proof of Theorem 6 is presented in Appendix.,4.1. Marginal screening,[0],[0]
Note that all the conditions in Theorem 6 can be checked at the j′-th node in each tree.,4.1. Marginal screening,[0],[0]
"If the conditions are satisfied as the j′-th node, then one can skip searching over its subtree.",4.1. Marginal screening,[0],[0]
It allows us to perform selective inference for highorder interaction models even the number of constraints that defines the selection event is extremely large.,4.1. Marginal screening,[0],[0]
"As we demonstrate in the experiment section, these pruning conditions are quite effective in practice.",4.1. Marginal screening,[0],[0]
"For example, we can perform selective inference for an interaction models with d = 10, 000, r = 5, k = 10 in a few seconds.",4.1. Marginal screening,[0],[0]
"As we discuss in the previous section, the selection event at each iteration of OMP has same form as MS.",4.2. Orthogonal matching pursuit (OMP),[0],[0]
"Therefore, we can derive similar pruning conditions as in Theorem 6 for OMP.",4.2. Orthogonal matching pursuit (OMP),[0],[0]
"Due to the space limitation, we deffer the corresponding lemma and the theorem for OMP in Appendix B.",4.2. Orthogonal matching pursuit (OMP),[0],[0]
We demonstrate the performance of the selective inference for high-order sparse interaction models by numerical experiments on synthetic datasets and a real dataset.,5. Experiments,[0],[0]
"First, we compared selective inference (select) with naive (naive) and data-splitting (split) on synthetic datasets.",5.1. Experiments on synthetic datasets,[0],[0]
"In naive, the critical values of the selected k features were naively computed without any selection bias correction mechanisms as in Eq.",5.1. Experiments on synthetic datasets,[0],[0]
(4).,5.1. Experiments on synthetic datasets,[0],[0]
"In split, the dataset was first divided into two equally sized sets, and one of them was used for selection stage, and the other was used for inference stage.",5.1. Experiments on synthetic datasets,[0],[0]
"Note that the errors controlled by these methods are individual false positive rate for each of the selected features (although naive actually cannot control it), we applied Bonferroni correction within the k selected features, i.e., we reject the hypothesis in Eq.",5.1. Experiments on synthetic datasets,[0],[0]
"(2) with the significance level α/k where α = 0.05, and we refer this error as family-wise false positive rates (FW-FPRs).
",5.1. Experiments on synthetic datasets,[0],[0]
The synthetic dataset was generated as follows.,5.1. Experiments on synthetic datasets,[0],[0]
"In the experiments for comparing FW-FPRs, we generated the training instances (zi, yi) ∈",5.1. Experiments on synthetic datasets,[0],[0]
"[0, 1]d×R independently at random for each i ∈",5.1. Experiments on synthetic datasets,[0],[0]
[n].,5.1. Experiments on synthetic datasets,[0],[0]
"The original covariates zi were randomly generated so that it contains d(1− ζ) 1s on average, where ζ ∈",5.1. Experiments on synthetic datasets,[0],[0]
"[0, 1] is an experimental parameter for representing the sparsity of the dataset, while the response yi was randomly generated from a Normal distribution N(0, σ2).",5.1. Experiments on synthetic datasets,[0],[0]
"In the experiments for comparing true positive rates (TPRs) the response yi was randomly generated from a Normal distribution N(µ(X), σ2I), where, for each row of µ(X) is defined as µ(zi) = 2z1z2z3 in the experiments for MS, µ(zi) = 0.5z1",5.1. Experiments on synthetic datasets,[0],[0]
− 2z2z3 + 3z4z5z6 in the experiments for OMP.,5.1. Experiments on synthetic datasets,[0],[0]
We investigated the performances by changing various experimental parameters.,5.1. Experiments on synthetic datasets,[0],[0]
"We set the baseline parameters as n = 100, d = 100, k = 5, r = 5, α = 0.05, σ = 0.5, and ζ = 0.6.",5.1. Experiments on synthetic datasets,[0],[0]
Figure 3 shows the FW-FPRs when varying the number of transactions n ∈,5.1.1. FALSE POSITIVE RATES,[0],[0]
"{50, 100, . .",5.1.1. FALSE POSITIVE RATES,[0],[0]
.,5.1.1. FALSE POSITIVE RATES,[0],[0]
", 250}, the number of original covariates d ∈ {50, 100, . . .",5.1.1. FALSE POSITIVE RATES,[0],[0]
", 250}.",5.1.1. FALSE POSITIVE RATES,[0],[0]
"In all cases, the FW-FPRs of naive were far greater than the desired significance level α = 0.05, indicating that the selection bias
is harmful.",5.1.1. FALSE POSITIVE RATES,[0],[0]
The FW-FPRs of the other two approaches select and split were successfully controlled.,5.1.1. FALSE POSITIVE RATES,[0],[0]
Figure 4 shows the TPRs of select and split (we omit naive because it cannot control FPRs).,5.1.2. TRUE POSITIVE RATES,[0],[0]
"Here, TPRs are defined as the probability of finding truly correlated interaction features.",5.1.2. TRUE POSITIVE RATES,[0],[0]
"In all the setups, the TPRs of select were much greater than split.",5.1.2. TRUE POSITIVE RATES,[0],[0]
Note that the performances of split would be worse than select both in the selection and the inference stages.,5.1.2. TRUE POSITIVE RATES,[0],[0]
The risk of failing to select truly correlated features in split would be higher than select because only half of the data would be used in the selection stage.,5.1.2. TRUE POSITIVE RATES,[0],[0]
"Similarly, the statistical power in the inference stage in split would be smaller than select because the sample size is smaller.",5.1.2. TRUE POSITIVE RATES,[0],[0]
"Table 1 shows the computation times in seconds for the selective inference approach with and without the computational tricks described in §4 for various values of the number of transactions n ∈ {100, . . .",5.1.3. COMPUTATIONAL EFFICIENCY,[0],[0]
", 10, 000}, the number of original covariates d ∈ {100, . . .",5.1.3. COMPUTATIONAL EFFICIENCY,[0],[0]
", 10, 000}, and the sparsity rates ζ ∈ {0.8, 0.9} (we terminated the search if the time exceeds 1 day).",5.1.3. COMPUTATIONAL EFFICIENCY,[0],[0]
"It can be observed from the table that, if we use the computational trick, the selective inferences can be conducted with reasonable computational costs except for d ≥ 5, 000 and ζ = 0.8 cases with OMP.",5.1.3. COMPUTATIONAL EFFICIENCY,[0],[0]
"When the computational trick was not used, the cost was extremely large.",5.1.3. COMPUTATIONAL EFFICIENCY,[0],[0]
"Especially when the number of original covariates d is larger than 100, we could not complete the search within 1 day.",5.1.3. COMPUTATIONAL EFFICIENCY,[0],[0]
"From the results, we conclude that computational trick described in §4 is indispensable for selective inferences for sparse high-order interaction models.",5.1.3. COMPUTATIONAL EFFICIENCY,[0],[0]
"We applied the selective inference approach to HIV-1 sequence data obtained from Stanford HIV Drug Resistance
Database (Rhee et al., 2003).",5.2. Application to HIV drug resistance data,[0],[0]
The goal here is to find statistically significant high-order interactions of multiple mutations (up to r = 5 order interactions) that are highly associated with the drug resistances.,5.2. Application to HIV drug resistance data,[0],[0]
"We selected k = 30 features, and evaluated the statistical significances of these features by the selective inference framework.",5.2. Application to HIV drug resistance data,[0],[0]
"Table 2 shows the numbers of 1st, 2nd, 3rd and 4th order interactions that were statistically significant after Bonferroni correction, i.e., significance level is set to be α/k with α = 0.05.",5.2. Application to HIV drug resistance data,[0],[0]
"(there were no statistically significant 5th order interactions).
",5.2. Application to HIV drug resistance data,[0],[0]
"Figure 5 shows the degree of significances in the form of adjusted p-values after Bonferroni correction in increasing order on idv and d4t datasets by MS and OMP scenario, respectively.",5.2. Application to HIV drug resistance data,[0],[0]
These results indicate that the selective inference approach could successfully identify statistically significant high-order interactions of multiple mutations.,5.2. Application to HIV drug resistance data,[0],[0]
"This work was partially supported by MEXT KAKENHI (17H00758, 16H06538), JST CREST (JPMJCR1302, JPMJCR1502), RIKEN Center for Advanced Intelligence Project, and JST support program for starting up innovation-hub on materials research by information integration initiative.",Acknowledgements,[0],[0]
"Finding statistically significant high-order interactions in predictive modeling is important but challenging task because the possible number of high-order interactions is extremely large (e.g., > 10).",abstractText,[0],[0]
In this paper we study feature selection and statistical inference for sparse highorder interaction models.,abstractText,[0],[0]
Our main contribution is to extend recently developed selective inference framework for linear models to high-order interaction models by developing a novel algorithm for efficiently characterizing the selection event for the selective inference of high-order interactions.,abstractText,[0],[0]
We demonstrate the effectiveness of the proposed algorithm by applying it to an HIV drug response prediction problem.,abstractText,[0],[0]
Selective Inference for Sparse High-Order Interaction Models,title,[0],[0]
"Prediction suffix trees (PST) provide an elegant and effective tool for sequence prediction tasks such as compression, temporal classification, reinforcement learning, and DNA sequencing (Li & Fu, 2014; Majumdar, 2016; Messias & Whiteson, 2017).",1. Introduction,[0],[0]
"The advantage of PSTs over other fixedorder Markov model is that the number of symbols used to predict depends on prediction context through the suffix tree data structure, which provides an efficient way to store and retrieve a set of strings and all their suffixes (Bellemare et al., 2014).
",1. Introduction,[0],[0]
"Many PST algorithms perform exact matching between the suffix of the current sequence and sub-sequences in the previous sequence (Ron et al., 1996).",1. Introduction,[0],[0]
The algorithms then make a prediction based on the previous history of those subsequences.,1. Introduction,[0],[0]
"Although the exact matching explicitly models the context where the same pattern occurred, it is potentially
1Australian National University, Canberra, ACT, Australia 2Data to Decisions CRC, Kent Town, SA, Australia 3Data61 at CSIRO, Canberra, ACT, Australia.",1. Introduction,[0],[0]
"Correspondence to: Dongwoo Kim <dongwoo.kim@anu.edu.au>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
1
vulnerable to variation in a sequence such as substitution noise.",1. Introduction,[0],[0]
"To illustrate the prediction under variation, we present two symbolic music scores in Figure 1.",1. Introduction,[0],[0]
"When a PST model performs a prediction on the first score, it can take advantage of the same pattern between the first and last three symbols, where the latter is the suffix of the current sequence.",1. Introduction,[0],[0]
"On the other hand, the model cannot relate the first and last three symbols given the second score because of the minor variation in the suffix with the same length.
",1. Introduction,[0],[0]
"Another practical assumption made in earlier work is that a shorter suffix has a higher priority than a longer one during prediction (Dekel et al., 2005; Karampatziakis & Kozen, 2009).",1. Introduction,[0],[0]
"This might be an appropriate assumption for some domains where the recently observed symbols are more important than the previous symbols, but this might be inappropriate for other domains.",1. Introduction,[0],[0]
"For example, a longer suffix would be more important than a suffix of length one to predict the next symbol of a music sheet since the temporal pattern in music is often continued over multiple notes.
",1. Introduction,[0],[0]
"In this paper, we provide a novel construction of the prediction suffix tree and its online learning algorithm via approximate string matching.",1. Introduction,[0],[0]
"In that sense, the proposed algorithm can be robust to small variations in a sequence.",1. Introduction,[0],[0]
We also provide a mechanism to control the importance of different suffixes based on their length.,1. Introduction,[0],[0]
"Finally, we derive a selfbounded version of the proposed model that decides the maximum length of suffix based on a trade-off between a confidence of prediction and complexity of algorithm automatically.
",1. Introduction,[0],[0]
"In the next section, we describe a decision theoretic PST model and how to learn the model parameters.",1. Introduction,[0],[0]
"In Section 3, we derive a PST with approximate string matching and its online learning algorithm.",1. Introduction,[0],[0]
We also proof the mistake bound of the proposed algorithm w.r.t.,1. Introduction,[0],[0]
an arbitrary hypothesis.,1. Introduction,[0],[0]
"In Section 4, we enhance our model by letting the model adaptively choose the depth of suffix tree.",1. Introduction,[0],[0]
"In Section 5 and 6, we verify our approach on synthetic datasets and demonstrate the improved predictive performance of our model on three real-world datasets.",1. Introduction,[0],[0]
We start by providing a formal description of a decision theoretic PST model.,2. Background,[0],[0]
"Assume that an input stream is a sequence of vectors x1,x2, ...(xt ∈ Rn), and an output stream is a sequence of binary symbols y1, y2, ...(yt ∈ {−1,+1}).",2. Background,[0],[0]
We will relax the binary assumption in Subsection 5.2.,2. Background,[0],[0]
"We denote a sub-sequence of output yi, yi+1, ..., yj by y j i .",2. Background,[0],[0]
"Our goal is to predict the next symbol yt given the binary sequence yt−11 and the next input vector xt
Dekel et al. propose a provably-correct PST algorithm to predict a sequence of symbols.",2. Background,[0],[0]
"With suffix-closed tree T 1 endowed with a score at each node, the prediction function for symbol yt given yt−11 and xt is
h(xt,y t−1 1 )",2. Background,[0],[0]
"= w · xt + t−1∑ i=1 2−i/2g(yt−1t−i ), (1)
",2. Background,[0],[0]
"where w ∈ Rn is a weight vector, and g(s) is a score of node s in a suffix tree T .",2. Background,[0],[0]
The score of a suffix is zero if the tree does not have the suffix.,2. Background,[0],[0]
We then use the sign of this prediction function as a predicted symbol yt.,2. Background,[0],[0]
The prediction function looks up scores of all possible suffixes of the input stream up to time t,2. Background,[0],[0]
"− 1 from suffix tree T
1T is a suffix-closed if ∀s ∈ T , all suffixes of s are also in T .
and takes a weighted sum of the scores of suffixes with exponential decaying weight 2−i/2 w.r.t.",2. Background,[0],[0]
the length of the suffix.,2. Background,[0],[0]
"Finally, the weighted score is added to the inner product between weight vector w and input vector x to make a prediction.",2. Background,[0],[0]
"The magnitude of h represents the confidence in this prediction.
",2. Background,[0],[0]
Figure 2 shows an example of prediction suffix tree with six suffixes therein.,2. Background,[0],[0]
"The value of node shows the score of a corresponding suffix, e.g., g(−+ +) = 4.",2. Background,[0],[0]
"Assume that we want to predict the next symbol of sequence y41 = −−++, then, with the prediction function given Eq. 1, the predicted symbol of y5 is sign(2−1/2×(−1)+2−2/2×(4)+2−3/2× (−2)).
",2. Background,[0],[0]
There are multiple ways to construct the suffix tree and learn the model parameters.,2. Background,[0],[0]
"In this paper, we focus on the margin-based online learning algorithm and its analysis as per Dekel et al.; Karampatziakis & Kozen.",2. Background,[0],[0]
"In online learning, the model parameters are updated after each round.",2. Background,[0],[0]
"At round t, the model makes a prediction given input xt and the previous sequence yt−11 .",2. Background,[0],[0]
"The predicted symbol ŷt = sign(ht(xt,yt−11 )) is then compared to the revealed correct symbol yt.",2. Background,[0],[0]
"Finally, the prediction function is updated based on the prediction and true symbol.",2. Background,[0],[0]
"More formally, the model computes the hinge loss after each round
`t = max{0, 1− ytht(xt,yt−11 )}.",2. Background,[0],[0]
"(2)
Then the weight vector and node scores are updated based on the loss suffered from the prediction.",2. Background,[0],[0]
"The update rules for w and g for all s ∈ {yt−1t−i } t−1 i=1 are as follows:
wt+1 = wt + ytτtxt",2. Background,[0],[0]
"(3)
gt+1(s) =
{ gt(s) + yt2
−|s|/2τt,",2. Background,[0],[0]
"if s ∈ Tt yt2 −|s|/2τt, otherwise
(4)
where τt depends on the loss `t and can be interpreted as a learning weight at time t, and Tt is a suffix tree at time t. When the updates happen, the unbounded version of this PST learning algorithm adds suffixes of the currently observed sequence into the suffix tree, resulting in the tree having O(t) depth and O(t2) nodes.",2. Background,[0],[0]
The same authors derive a self-bounded PST where the depth of tree is automatically chosen based on the model performance.,2. Background,[0],[0]
We propose a new prediction suffix tree algorithm with approximate string matching (aPST) where the prediction on next symbol depends on the exact matching as well as approximate matching suffixes.,3. PST with Approximate String Matching,[0],[0]
"From the previous section, we observe that the PST algorithm has the following properties:
•",3. PST with Approximate String Matching,[0],[0]
"The model performs exact matching between the current suffix and a node in the suffix tree where each node
represents sub-sequences of the previously observed sequence.
",3. PST with Approximate String Matching,[0],[0]
"• The weight of shorter suffixes is higher than longer suffixes due to the exponential decaying rate.
",3. PST with Approximate String Matching,[0],[0]
"As we have seen in Section 1, the first property prevents the model to take into account similar sub-sequences in the previous sequence, and the second property does not reflect the importance of suffix length.",3. PST with Approximate String Matching,[0],[0]
Our new prediction function takes into account all possible suffixes within - Hamming distance from the original suffixes and provides a controllable weighting scheme.,3. PST with Approximate String Matching,[0],[0]
"Formally, the prediction function of aPST is defined as:
h(xt,y t−1 1 ) =",3. PST with Approximate String Matching,[0],[0]
w >xt + t−1∑ i=1,3. PST with Approximate String Matching,[0],[0]
"∑ k=0 ∑ s:s∈Tt−1,
d(s,yt−1t−i )",3. PST with Approximate String Matching,[0],[0]
"=k
ω(i, k)g(s),
(5)
where ω :",3. PST with Approximate String Matching,[0],[0]
"Z+ × Z → R+ controls the contribution of suffix s, and d(s, s′) computes a distance between s and s′ given some distance metric.",3. PST with Approximate String Matching,[0],[0]
"We use Hamming distance throughout the paper, but the proposed framework may be applied to other distance metrics defined over strings.",3. PST with Approximate String Matching,[0],[0]
"When = 0, the model performs the exact string matching over the suffix tree.",3. PST with Approximate String Matching,[0],[0]
"Hamming distance is only defined when the lengths of two sequences are the same (Robinson, 2003).",3. PST with Approximate String Matching,[0],[0]
"Hence there is no suffix s whose distance k from yt−1t−i is greater than i. We define the contribution function ω as
ω(i, k) =",3. PST with Approximate String Matching,[0],[0]
"( (1− ξ)k λ
i exp(−λ)",3. PST with Approximate String Matching,[0],[0]
"i!
)",3. PST with Approximate String Matching,[0],[0]
"1 2
, λ > 0
1 > ξ > 0 (6)
where λ and ξ are two model parameters.",3. PST with Approximate String Matching,[0],[0]
"Unlike Eq. 1, where shorter sequences get a higher weight than longer ones, the model imposes different weights on different lengths of suffix.",3. PST with Approximate String Matching,[0],[0]
"Specifically, the model gives the highest weight to suffixes of length bλc.",3. PST with Approximate String Matching,[0],[0]
"To reduce the contribution of approximate suffixes, we add an exponentially decaying factor w.r.t the distance from the original suffixes",3. PST with Approximate String Matching,[0],[0]
"k.
The following theorem bounds the cumulative loss of the unbounded aPST online learning method of Algorithm 1 w.r.t.",3. PST with Approximate String Matching,[0],[0]
any fixed hypothesis h?,3. PST with Approximate String Matching,[0],[0]
which could be chosen in hindsight.,3. PST with Approximate String Matching,[0],[0]
"To derive the bound we define the norm of the score function g as ||g||2 = ∑ s∈T g(s) 2.
",3. PST with Approximate String Matching,[0],[0]
Theorem 1 (unbounded aPST).,3. PST with Approximate String Matching,[0],[0]
"Let x1,x2, ...,xT be an input stream and let y1, y2, ..., yT be an output stream, where every ||x||2 ≤ 1",3. PST with Approximate String Matching,[0],[0]
and,3. PST with Approximate String Matching,[0],[0]
"every yt ∈ {−1,+1}.",3. PST with Approximate String Matching,[0],[0]
Let h? =,3. PST with Approximate String Matching,[0],[0]
"(w?, T ?, g?) be an arbitrary hypothesis such that ||g?||2 < ∞ and which attains the loss values `?1, `?2, ... `?T .",3. PST with Approximate String Matching,[0],[0]
"Let `1, ..., `T be the sequence of losses attained by the unbounded online learning algorithm with the -Hamming
Algorithm 1 Online learning algorithm for unbounded aPST.
1: Input: T1 = {∅},w1 = 0, λ > 0, ≥ 0, 1 > ξ > 0 2: Set γ = min{−e−λ + eλ(1−ξ), e
λΓ(1+ ,λ) Γ(1+ ) }
3: for all t = 1, 2, ..., T do 4: Compute ht(xt,yt−11 )",3. PST with Approximate String Matching,[0],[0]
"5: Predict ŷt = sign(ht(xt,yt−11 ))",3. PST with Approximate String Matching,[0],[0]
"6: Receive yt and compute loss `t = max{0, 1− ytht(xt,yt−11 )} 7: Set τt = `t/(||x||2 + 2 + γ) 8: Set dt = t− 1 9: Update weight vector: wt+1 = wt + ytτtxt 10:",3. PST with Approximate String Matching,[0],[0]
"Update tree: 11: Tt+1 = Tt ∪ {yt−1t−i : 1 ≤ i ≤ dt} 12: gt+1(s) = gt(s) + ytτtω(|s|, d(s,yt−1t−i ))",3. PST with Approximate String Matching,[0],[0]
"if {s : s ∈ T , d(s,yt−1t−i ) ≤ } 13: gt+1(s) = ytτtω(|s|, d(s,yt−1t−i ))",3. PST with Approximate String Matching,[0],[0]
"if {s : s /∈ T , d(s,yt−1t−i ) ≤ } 14: end for
distance in Algorithm 1.",3. PST with Approximate String Matching,[0],[0]
"Then it holds that
T∑ t=1 `2t ≤",3. PST with Approximate String Matching,[0],[0]
( 3 + γ )( ||w?||2 + ||g?||2 + 1 2 T∑ t=1,3. PST with Approximate String Matching,[0],[0]
"(`?t ) 2 ) ,
where γ = min{−e−λ + eλ(1−ξ), e λΓ(1+ ,λ) Γ(1+ ) }.
",3. PST with Approximate String Matching,[0],[0]
Proof.,3. PST with Approximate String Matching,[0],[0]
Define ∆t,3. PST with Approximate String Matching,[0],[0]
= ||wt −w?||2 − ||wt+1 −w?||2 and ∆̂t = ∑ s∈Y?,3. PST with Approximate String Matching,[0],[0]
(gt(s)− g?(s))2 − ∑ s∈Y?,3. PST with Approximate String Matching,[0],[0]
"(gt+1(s)− g?(s))2.
(7)
We prove the theorem by using an upper and lower bound of ∑ t(∆t + ∆̂t).",3. PST with Approximate String Matching,[0],[0]
"First, expanding ∑ t(∆t + ∆̂t) by the definition gives∑ t (∆t + ∆̂t)",3. PST with Approximate String Matching,[0],[0]
= ||w1 −w?||2,3. PST with Approximate String Matching,[0],[0]
"− ||wt+1 −w?||2
+ ∑ s∈Y? {",3. PST with Approximate String Matching,[0],[0]
(g1(s)− g?(s))2,3. PST with Approximate String Matching,[0],[0]
− (gt+1(s)− g?(s))2 } .,3. PST with Approximate String Matching,[0],[0]
"(8)
Since w1 = 0 and g1(·) = 0, we can obtain a simple upper bound by omitting the negative terms∑
t
(∆t + ∆̂t) ≤ ||w?||2 + ||g?||2, (9)
where ||g?||2 = ∑
s∈Y?",3. PST with Approximate String Matching,[0],[0]
g ?(s)2.,3. PST with Approximate String Matching,[0],[0]
"To derive the lower bound,
we first rewrite ∆t as ||wt−w?||2−||(wt+1−wt)+(wt− w?)||2 by adding null term wt −wt.",3. PST with Approximate String Matching,[0],[0]
A further derivation gives ∆t = −||wt+1−wt||2− 2(wt+1−wt) · (wt−w?).,3. PST with Approximate String Matching,[0],[0]
"With the update rule wt+1 = wt + ytτtxt, we can obtain
∆t = −τ2t ||xt||2 − 2ytτtxt(wt −w?).",3. PST with Approximate String Matching,[0],[0]
"(10)
We manipulate the second term in Eq. 7 in a similar way by adding null term gt(s)− gt(s) to get
∆̂t = ∑ s∈Y?",3. PST with Approximate String Matching,[0],[0]
{( gt(s)− g?(s) ),3. PST with Approximate String Matching,[0],[0]
2,3. PST with Approximate String Matching,[0],[0]
− ( (gt+1(s)− gt(s)),3. PST with Approximate String Matching,[0],[0]
+ (gt(s)− g?(s)) ),3. PST with Approximate String Matching,[0],[0]
"2}
= ∑ s∈Y? {",3. PST with Approximate String Matching,[0],[0]
− ( gt+1(s)− gt(s) )2 − 2 ( (gt+1(s)− gt(s))(gt(s)− g?(s)) )} .,3. PST with Approximate String Matching,[0],[0]
"(11)
Note that the algorithm updates gt(s) at time t only if s is one of the approximate suffixes of {yt−1t−i } dt i=1 with dt = t− 1.",3. PST with Approximate String Matching,[0],[0]
Therefore gt+1(s)− gt(s) would only have non-zero value if suffix s is within -neighbourhood of yt−1t−|s|.,3. PST with Approximate String Matching,[0],[0]
"Using this fact, ∆̂t can be further simplified as
∆̂t = dt∑ i=1",3. PST with Approximate String Matching,[0],[0]
"∑ k=0 ∑ s:s∈Tt−1,
d(s,yt−1t−i )",3. PST with Approximate String Matching,[0],[0]
"=k
−τ2ω(i, k)2 (12)
",3. PST with Approximate String Matching,[0],[0]
− 2 dt∑ i=1,3. PST with Approximate String Matching,[0],[0]
"∑ k=0 ∑ s:s∈Tt−1,
d(s,yt−1t−i )",3. PST with Approximate String Matching,[0],[0]
"=k
ytτtω(i, k)(gt(s)− g?(s)),
where we have used the update rule gt+1(s) = gt(s) +",3. PST with Approximate String Matching,[0],[0]
"ytτtω(i, k).",3. PST with Approximate String Matching,[0],[0]
"By adding Eq. 10 and Eq. 12, we have that ∆t + ∆̂t",3. PST with Approximate String Matching,[0],[0]
"= −τ2t ( ||xt||2 +
dt∑ i=1",3. PST with Approximate String Matching,[0],[0]
"∑ k=0 ∑ s:s∈Tt−1,
d(s,yt−1t−i )",3. PST with Approximate String Matching,[0],[0]
"=k
ω(i, k)2 )
",3. PST with Approximate String Matching,[0],[0]
− 2τtyt ( wtxt + dt∑ i=1,3. PST with Approximate String Matching,[0],[0]
"∑ k=0 ∑ s:s∈Tt−1,
d(s,yt−1t−i )",3. PST with Approximate String Matching,[0],[0]
"=k
ω(i, k)gt(s)
)
+ 2τtyt ( w?xt + dt∑ i=1",3. PST with Approximate String Matching,[0],[0]
"∑ k=0 ∑ s:s∈Tt−1,
d(s,yt−1t−i )",3. PST with Approximate String Matching,[0],[0]
"=k
ω(i, k)g?(s) ) .
",3. PST with Approximate String Matching,[0],[0]
"(13)
Let γ = min{−e−λ + eλ(1−ξ), eλΓ(1 + , λ)/Γ(1 + )}.",3. PST with Approximate String Matching,[0],[0]
"Combining Corollary 3.1 with the definition of ht and h? leads to
∆t + ∆̂t",3. PST with Approximate String Matching,[0],[0]
≥− τ2t ( ||xt||2 + γ ),3. PST with Approximate String Matching,[0],[0]
"− 2τtytht(xt,yt−11 )",3. PST with Approximate String Matching,[0],[0]
"+ 2τtyth?(xt,y t−1 1 )
",3. PST with Approximate String Matching,[0],[0]
≥− τ2t ( ||xt||2 + γ ) + 2τt(`t − 1) + 2τt(1− `?t ) =,3. PST with Approximate String Matching,[0],[0]
"Ψt. (14)
",3. PST with Approximate String Matching,[0],[0]
"If we subtract a non-negative term (21/2τt−2−1/2`?t )2 from Ψt, then Ψt is lower bounded by
Ψt ≥− τ2t ( ||xt||2 + 2 + γ ) + 2τt`t",3. PST with Approximate String Matching,[0],[0]
"− (`?t )2/2
Let τt = `t/(||x||2 + 2 + γ).",3. PST with Approximate String Matching,[0],[0]
"Using ||x||2 ≤ 1,
Ψt ≥τt`t",3. PST with Approximate String Matching,[0],[0]
"− (`?t ) 2
2 = `2t ||x||2 + 2 + γ",3. PST with Approximate String Matching,[0],[0]
− (` ?,3. PST with Approximate String Matching,[0],[0]
"t ) 2 2
≥ ` 2 t 3 + γ",3. PST with Approximate String Matching,[0],[0]
− (` ?,3. PST with Approximate String Matching,[0],[0]
"t ) 2 2 (15)
",3. PST with Approximate String Matching,[0],[0]
"Combining the sum of lower bounds ∑T t=1(∆t + ∆̂t) with
the upper bound on ∑T t=1(∆t + ∆̂t) in Eq. 9 gives us the bound stated in the theorem
||w?||2 + ||g?||2 ≥ T∑ t=1",3. PST with Approximate String Matching,[0],[0]
( `2t 3 + γ,3. PST with Approximate String Matching,[0],[0]
− (` ?,3. PST with Approximate String Matching,[0],[0]
"t ) 2 2 ) .
",3. PST with Approximate String Matching,[0],[0]
The competitive ratio bound obtained by Theorem 1 depends exponentially on λ but also depends on the other parameter and ξ.,3. PST with Approximate String Matching,[0],[0]
We plot the contour maps of γ within a sensible range of parameters in Figure 3.,3. PST with Approximate String Matching,[0],[0]
The contour suggests a plausible range of parameters to obtain competitive bound against an arbitrary hypothesis.,3. PST with Approximate String Matching,[0],[0]
"For example, ξ needs to be close to 1 if the algorithm gives more weight on long suffixes.",3. PST with Approximate String Matching,[0],[0]
"It is also worth noting that if we set to 0, we can obtain the same competitive ratio provided in the original PST algorithm (Dekel et al., 2005) with more flexible Poisson weighting scheme.
",3. PST with Approximate String Matching,[0],[0]
"The following lemmas used to prove Theorem 1 shows an upper bound on the squared sum of ω(i, k) given sequence yt−11 with respect to λ and ξ.",3. PST with Approximate String Matching,[0],[0]
Lemma 2.,3. PST with Approximate String Matching,[0],[0]
"Let ω(i, k) =",3. PST with Approximate String Matching,[0],[0]
((1 − ξ)kλi exp(−λ)/i!)1/2.,3. PST with Approximate String Matching,[0],[0]
"Given a binary sequence yt−11 and an arbitrary suffix tree T equipped with Hamming distance metric, ∑t−1 i=1",3. PST with Approximate String Matching,[0],[0]
"∑ k=0 ∑ s:s∈T ,d(s,yt−1t−i )",3. PST with Approximate String Matching,[0],[0]
"=k ω2(i, k) ≤",3. PST with Approximate String Matching,[0],[0]
"−e−λ +
eλ(1−ξ)Γ(t,−λ(−2 + ξ))/Γ(t) for all λ > 0, ≥ 0, and 0 < ξ < 1.
",3. PST with Approximate String Matching,[0],[0]
"The proof of the lemma is provided in Appendix A.
The following simplification directly follows from the definition of the gamma function.",3. PST with Approximate String Matching,[0],[0]
Corollary 2.1.,3. PST with Approximate String Matching,[0],[0]
"Under the assumption of Lemma 2,∑t−1 i=1",3. PST with Approximate String Matching,[0],[0]
"∑ k=0 ∑ s:s∈T ,d(s,yt−1t−i )",3. PST with Approximate String Matching,[0],[0]
"=k
ω2(i, k) ≤",3. PST with Approximate String Matching,[0],[0]
"−e−λ + eλ(1−ξ) for all λ > 0, ≥ 0, and 0 < ξ < 1.
",3. PST with Approximate String Matching,[0],[0]
"The bound in Lemma 2 depends on the value of λ, t and ξ.",3. PST with Approximate String Matching,[0],[0]
"We provide an alternative bound depending on λ and .
",3. PST with Approximate String Matching,[0],[0]
Lemma 3.,3. PST with Approximate String Matching,[0],[0]
"Let ω(i, k) =",3. PST with Approximate String Matching,[0],[0]
((1 − ξ)kλi exp(−λ)/i!)1/2.,3. PST with Approximate String Matching,[0],[0]
"Given a binary sequence yt−11 and an arbitrary suffix tree T equipped with the Hamming distance metric, ∑t−1 i=1",3. PST with Approximate String Matching,[0],[0]
"∑ k=0 ∑ s:s∈T ,d(s,yt−1t−i )",3. PST with Approximate String Matching,[0],[0]
"=k
ω2(i, k) ≤ eλΓ(1 + , λ)/Γ(1 + ) for all λ > 0, ≥ 0, and 0 < ξ < 1.
",3. PST with Approximate String Matching,[0],[0]
"The proof of the lemma is also provided in Appendix B.
Finally, combining above lemmas provides the constant ratio used in Theorem 1.
",3. PST with Approximate String Matching,[0],[0]
Corollary 3.1.,3. PST with Approximate String Matching,[0],[0]
"Under the assumption of Corollary 2.1 and Lemma 3, ∑t−1 i=1 ∑ k=0 ∑ s:s∈T ,d(s,yt−1t−i )",3. PST with Approximate String Matching,[0],[0]
"=k ω2(i, k) ≤ min{−e−λ + eλ(1−ξ), e λΓ(1+ ,λ) Γ(1+ )",3. PST with Approximate String Matching,[0],[0]
"} for all λ > 0, ≥ 0, and 0 < ξ < 1.",3. PST with Approximate String Matching,[0],[0]
The unbounded aPST algorithm relaxes the exact matching condition of PST.,4. Self-Bounded aPST,[0],[0]
"However, similarly to the unbounded PST, the depth of a suffix tree in the unbounded aPST also scales linearly in the length of sequence.",4. Self-Bounded aPST,[0],[0]
"In this section, we propose a self-bounded enhancement of the aPST algorithm which automatically grows a bounded-depth aPST.",4. Self-Bounded aPST,[0],[0]
"In each round, the algorithm decides whether to increase the depth of the suffix tree based on the prediction of next symbol.
",4. Self-Bounded aPST,[0],[0]
The self-bounded aPST algorithm is described in Algorithm 2.,4. Self-Bounded aPST,[0],[0]
We introduce tree depth variable dt calculated on every round of online iteration to represent the maximum depth of the suffix tree at time t. The proposed model automatically trades off between the size of suffix tree and confidence of prediction.,4. Self-Bounded aPST,[0],[0]
We set the minimum value of dt to dλ+ e in order to take into account the suffixes around the maximal weight length bλc.,4. Self-Bounded aPST,[0],[0]
Note that the algorithm updates the tree when the loss is greater than 1/2.,4. Self-Bounded aPST,[0],[0]
This relaxed margin prevents the tree growing linearly with respect to the length of observed sequence.,4. Self-Bounded aPST,[0],[0]
"The following theorem provides the loss bound of proposed algorithm in exchange for having a relatively small aPST.
",4. Self-Bounded aPST,[0],[0]
"Algorithm 2 Online learning algorithm for self-bounded aPST.
",4. Self-Bounded aPST,[0],[0]
"1: Input: T = {∅},w1 = 0, P1 = 0, λ > 0, ≥ 0, δ ∈ (0, 1) 2: Set Γ̄ = Γ(1 + , λ)/Γ(1 + )",4. Self-Bounded aPST,[0],[0]
"3: Set γ = min{−e−λ + eλ(1−ξ), eλΓ̄} 4: for all t = 1, 2, ..., T do 5: Compute ht(xt,yt−11 )",4. Self-Bounded aPST,[0],[0]
"6: Predict ŷt = sign(ht(xt,yt−11 ))",4. Self-Bounded aPST,[0],[0]
"7: Receive yt and compute loss `t = max{0, 1− ytht(xt,yt−11 )} 8: if ` > 1/2 then 9: Set τt = `t/(||xt||2 + 2 + γ)
10: Set dt = max{dλ+ e, dt−1} 11: Define function f(d) = edλdd−d
12: while Γ̄f(dt)",4. Self-Bounded aPST,[0],[0]
"> ( (P 2t−1+τt`t)1/2−Pt−1
2τt )2",4. Self-Bounded aPST,[0],[0]
do 13: dt = dt + 1 14: end while 15: Set Pt = Pt−1 + 2τt √ Γ̄f(dt) 16: Update weight vector: wt+1 = wt + ytτtxt 17:,4. Self-Bounded aPST,[0],[0]
"Update suffix tree: 18: gt+1(s) = gt(s) + ytτtω(|s|, d(s,yt−1t−i ))",4. Self-Bounded aPST,[0],[0]
"if {s : s ∈ T , d(s,yt−1t−i ) ≤ } 19: gt+1(s) = ytτtω(|s|, d(s,yt−1t−i ))",4. Self-Bounded aPST,[0],[0]
"if {s : s /∈ T , d(s,yt−1t−i ) ≤ } 20: else 21: Set: τt = 0, Pt = Pt−1 22: end if 23: end for
Theorem 4 (Self-bounded aPST).",4. Self-Bounded aPST,[0],[0]
"Let x1,x2, ...,xT be an input stream and let y1, y2, ..., yT be an output stream, where every ||x||2 ≤ 1",4. Self-Bounded aPST,[0],[0]
and,4. Self-Bounded aPST,[0],[0]
"every yt ∈ {−1,+1}.",4. Self-Bounded aPST,[0],[0]
Let h? =,4. Self-Bounded aPST,[0],[0]
"(w?, T ?, g?) be an arbitrary hypothesis such that ||g?||2 ≤ ∞ and which attains the loss values `?1, `?2, ... `?T .",4. Self-Bounded aPST,[0],[0]
"Let `1, ..., `T be the sequence of losses attained by the self-bounded online learning algorithm with the -Hamming distance in Algorithm 2.",4. Self-Bounded aPST,[0],[0]
"Then the sum of square losses on those rounds where `t > 12 is bounded by
∑ t:`t> 1 2 `2t ≤ λ̄ (1 +√5 2 ||g?||+ ||w?||+ (1 2 T∑ t=1",4. Self-Bounded aPST,[0],[0]
"(`?t ) 2 ) 1 2 )2 ,
where λ̄ = 3 + min{−e−λ + eλ(1−ξ), e λΓ(1+ ,λ) Γ(1+ ) }.
",4. Self-Bounded aPST,[0],[0]
See Appendix C for the detailed proof.,4. Self-Bounded aPST,[0],[0]
Here we provide a sketch of proof.,4. Self-Bounded aPST,[0],[0]
"Again, the proof starts from the upper bound and lower bound on ∆+∆̂ defined in Theorem 1.",4. Self-Bounded aPST,[0],[0]
The upper bound remains the same.,4. Self-Bounded aPST,[0],[0]
"The derivation of the lower bound is the same up to Eq. 13, however, by the definition of h, we need to add null terms consisting scores of the suffixes from dt+ 1 to t−1 in T ?",4. Self-Bounded aPST,[0],[0]
"to formulate the lower bound as a
linear function of ht and h?",4. Self-Bounded aPST,[0],[0]
as done in Eq. 14.,4. Self-Bounded aPST,[0],[0]
Adding null terms results in a remainder after reformulation.,4. Self-Bounded aPST,[0],[0]
The lower bound on this remainder can be obtained by Chernoff bound since the weights of additional term can be bounded by the sum of Poisson tail distribution.,4. Self-Bounded aPST,[0],[0]
The combination of two lower bounds leads to a new lower bound on ∆ + ∆̂.,4. Self-Bounded aPST,[0],[0]
"Given the combination of upper and lower bounds on ∆ + ∆̂ , we further show that if dt satisfies the condition described in Algorithm 2, the sum of squared losses has the lower bound explained in Theorem 4 via mathematical induction.",4. Self-Bounded aPST,[0],[0]
"In this section, we compare the performance of aPST on a sequence prediction task to the classical PST (Dekel et al., 2005) and its variant wPST (Karampatziakis & Kozen, 2009) on a synthetic dataset.",5. Simulation Study,[0],[0]
"We start from a sequence motif, which is frequently occurred subsequences of an original sequence.",5. Simulation Study,[0],[0]
"Many sequences observed in real world applications can be rendered by a small number of motifs (Bailey et al., 2006; Ross et al., 2012).",5. Simulation Study,[0],[0]
"It is known that the PSTs are capable of identifying those motifs from a sequence (Majumdar, 2016).",5. Simulation Study,[0],[0]
"Given a sequence motif, we generate a random sequence with some level of noise, and then, compute predictive accuracies of PST algorithms to compare.",5. Simulation Study,[0],[0]
"Throughout this experiments, we focus on a situation where the input stream is unavailable, i.e. xt = 0 for all t in a sequence, since the modelling on the input stream of aPST algorithm remains the same as those of PST.",5. Simulation Study,[0],[0]
"In other words, we measure and compare a sequence memorisation perspective of both models under a noisy environment in order to emphasise the importance of the approximate matching and weighting scheme.",5. Simulation Study,[0],[0]
"We first synthesise simple sequence from the motif [−1,−1,+1,+1].",5.1. Binary sequence prediction,[0],[0]
"We construct a sequence by repeating the motif multiple times (25, 50, 100, 200 times), and then, we randomly corrupt each entry of input yi via an independent Bernoulli trial with a fixed noise probability.",5.1. Binary sequence prediction,[0],[0]
"Without noise in a final sequence, all three models can predict perfectly after observing a first few entries.",5.1. Binary sequence prediction,[0],[0]
"When a sequence is corrupted by some random noise, PST only relies on an input xt",5.1. Binary sequence prediction,[0],[0]
"if available, while aPST retrieves approximate suffixes to predict the next symbol.
",5.1. Binary sequence prediction,[0],[0]
"For every experiment, we use the first 40% of a sequence to train, the subsequent 20% of the sequence to validate, and the final 40% of sequence to test the models.",5.1. Binary sequence prediction,[0],[0]
"For both parameter λ and , we test all possible configuration of λ = {2, 4, 6, 8, 10, 12}, ξ = (0.5, 0.7, 0.9, 0.99), and = {0, 1} and choose the best model based on the accuracy of validation set.",5.1. Binary sequence prediction,[0],[0]
All the experiments are repeated over 20 times with randomly corrupted entries.,5.1. Binary sequence prediction,[0],[0]
"We report two quantities: accuracy of prediction on the uncorrupted entries and the final depth of the suffix tree.
",5.1. Binary sequence prediction,[0],[0]
Figure 4 (a) and (b) show the prediction accuracy and tree depth of the three different models with respect to varying proportions of noise.,5.1. Binary sequence prediction,[0],[0]
"In general, as the proportion of noise increases, the prediction accuracy of both models decrease.",5.1. Binary sequence prediction,[0],[0]
"The accuracy converges to the random baseline when the sequence is unpredictable, i.e. a half of sequence is corrupted.",5.1. Binary sequence prediction,[0],[0]
"Aside from this unpredictable case, aPST always outperforms PST while keeping similar tree depths.",5.1. Binary sequence prediction,[0],[0]
"Although wPST maintains the shallowest tree depth, it shows the lowest performance among all models.
",5.1. Binary sequence prediction,[0],[0]
Figure 4 (c) and (d) show the prediction accuracy and tree depth of the three different models with respect to varying lengths of sequence.,5.1. Binary sequence prediction,[0],[0]
"The model predicts better when the
sequence length is longer in general.",5.1. Binary sequence prediction,[0],[0]
The tree depth of aPST increases sub-linearly as the length of sequence increases.,5.1. Binary sequence prediction,[0],[0]
"We can also observe that the variance of accuracy decreases as the sequence length increases with aPST.
",5.1. Binary sequence prediction,[0],[0]
We present a more comprehensive analysis of the binary sequence prediction and demonstrate the performance on more complex synthetic sequences in Appendix D.,5.1. Binary sequence prediction,[0],[0]
"To predict on sequences with multiple symbols, we adopt ideas from (Crammer & Singer, 2001) and maintain trees T (1), ...T (k) for each symbol.",5.2. Multi-class sequence prediction,[0],[0]
The decision at time t is,5.2. Multi-class sequence prediction,[0],[0]
"ŷt = arg maxk h (k) t (xt,y t−1 1 ).",5.2. Multi-class sequence prediction,[0],[0]
"If the prediction is wrong, we update the tree parameters of predicted symbol and true symbol with a piecewise margin loss defined as `t = maxk{hkt +1−h yt t } if ŷt 6= yt.",5.2. Multi-class sequence prediction,[0],[0]
"Hence, different trees might have different depth.",5.2. Multi-class sequence prediction,[0],[0]
"Here, we report the maximum depth among the trees.
",5.2. Multi-class sequence prediction,[0],[0]
Note that there might be a combinatorial number of approximate suffixes if we add all approximate suffixes while updating the tree.,5.2. Multi-class sequence prediction,[0],[0]
"To reduce the computational burden, we add the suffixes of the current sequence into the tree if the suffixes are not in the tree and update the approximate suffixes which are already in the suffix tree.",5.2. Multi-class sequence prediction,[0],[0]
Therefore the suffix tree only contains the sub-sequences which have been observed in the past.,5.2. Multi-class sequence prediction,[0],[0]
"The prediction still requires to search the approximate sequences over the suffix tree, but it can be done in an efficient way (Ukkonen, 1993; Giegerich & Kurtz, 1997).
",5.2. Multi-class sequence prediction,[0],[0]
"For the experiment, we generate a random sequence from motif [1, 2, 3, 4, 1, 3].",5.2. Multi-class sequence prediction,[0],[0]
"Again, we inject random noise based on a Bernoulli trial with a fixed probability.",5.2. Multi-class sequence prediction,[0],[0]
The corrupted symbols are then replaced by random symbol with uniform probability over symbols.,5.2. Multi-class sequence prediction,[0],[0]
"We follow the same experimental procedure as used in the binary experiments with the same set of parameters except that we tested up to 2.
",5.2. Multi-class sequence prediction,[0],[0]
Figure 5 shows the result of the synthetic experiments.,5.2. Multi-class sequence prediction,[0],[0]
"In general, aPST outperforms both PST and wPST, and the accuracy increases as increases from 0 to 2.",5.2. Multi-class sequence prediction,[0],[0]
"Again, this results emphasis the importance of approximate matching of PST under some noise in a sequence.",5.2. Multi-class sequence prediction,[0],[0]
"In this section, we conduct some experiments with real datasets to demonstrate the practical effectiveness of the proposed method.",6. Experiments,[0],[0]
"We use three datasets: a symbolic music dataset (Walder, 2016) from which we retain midi onset events only, a system call dataset (Hofmeyr et al., 1998), and human activity dataset (Ordónez et al., 2013).",6. Experiments,[0],[0]
The symbolic music dataset contains four sets of midi music dataset from different sources.,6. Experiments,[0],[0]
"The models predict a sequence of midi note number, which ranges 0-127.",6. Experiments,[0],[0]
"The system call dataset records a set of system call traces made by active processes, which might contain some intrusions of malicious programs.",6. Experiments,[0],[0]
The models predict the next system call given a previous call sequence.,6. Experiments,[0],[0]
The human activity dataset records a sequence of activities from two subjects.,6. Experiments,[0],[0]
"The models predict the next activity of each subject given a trajectory of activities.
",6. Experiments,[0],[0]
We again compare aPST with PST and wPST in terms of prediction accuracy and tree depth.,6. Experiments,[0],[0]
"For every experiment, we use the first 30% of symbols to adjust the model parameters and use remaining 70% to report the model accuracy and tree depth.",6. Experiments,[0],[0]
"We use the same set of parameters used in the previous section.
",6. Experiments,[0],[0]
"Table 1, 2, 3 show the accuracies and final tree depth of PST models on music, system call, human activity datasets, respectively.",6. Experiments,[0],[0]
"For the music and human activity datasets, aPST outperforms the other models in terms of accuracy while using a slightly larger suffix tree.",6. Experiments,[0],[0]
"For the system call dataset, the tree depth of aPST is shallower than those of the other models while having a similar or better accuracies.",6. Experiments,[0],[0]
"The performance gain of aPST against the other models are
significant when the sequence lengths are relatively short.
",6. Experiments,[0],[0]
We plot the histogram of the best λ values for the music dataset and system call dataset in Figure 6.,6. Experiments,[0],[0]
The graph shows a quite distinctive characteristic of these two datasets.,6. Experiments,[0],[0]
"λ values from the musical sequences distribute evenly across range 0 to 8, while λ from system call traces are highly focused on the range",6. Experiments,[0],[0]
"[3, 5).",6. Experiments,[0],[0]
"We conjecture that the songs have a greater variety of relevant motif lengths than the system call traces which have more static transition patterns (Nikolopoulos & Polenakis, 2014), therefore λ values are adjusted according to the nature of a song.",6. Experiments,[0],[0]
"Variants of the PST algorithm have been developed in different scientific communities in different forms such as the variable length Markov models and context tree weighting (Willems et al., 1995; Helmbold & Schapire, 1997; Bühlmann et al., 1999; Bellemare et al., 2014).",7. Related Work,[0],[0]
Most of these algorithms need an a-priori bound on the maximum number of previous symbols.,7. Related Work,[0],[0]
Apostolico & Bejerano show that the upper bound assumption can be relaxed by a linear time prediction tree construction algorithm where the depth of suffix tree can increase up to the length of a training sequence.,7. Related Work,[0],[0]
Dekel et al. propose an alternative self-bounded PST learning algorithm where the depth of prediction tree is bounded automatically based on a number of mistakes made by the algorithm.,7. Related Work,[0],[0]
Karampatziakis & Kozen combine the idea of self-bounded PST and Winnow algorithm and derive a multiplicative update algorithm for online learning.,7. Related Work,[0],[0]
"By using the multiplicative update rules, the suggested algorithm can quickly adopt variation in complex sequence
which exhibit different patterns at various points during life time.",7. Related Work,[0],[0]
Xiao & Eckert further extend the PST to incorporate additional side information.,7. Related Work,[0],[0]
They derive a second order online learning algorithm to take into account the variance of the estimator.,7. Related Work,[0],[0]
We have presented the decision theoretic prediction suffix tree with approximate string matching (aPST) by relaxing the exact matching condition of the PST models.,8. Conclusion,[0],[0]
The depth of the suffix tree generated by the proposed algorithm scales linearly with the length of the input sequence.,8. Conclusion,[0],[0]
"To limit the depth of aPST, we proposed self-bounded version of aPST which automatically determines the depth of suffix tree.",8. Conclusion,[0],[0]
The loss bounds for both unbounded- and bounded-aPST are analysed.,8. Conclusion,[0],[0]
We showed that the applications of aPST to sequence modelling outperform the other PST models under a noisy environment via synthetic datasets.,8. Conclusion,[0],[0]
"Furthermore, we showed the improved predictive performance of aPST on three real world datasets.",8. Conclusion,[0],[0]
Future work on this research will explorer wide range of distance metrics instead of the Hamming distance in order to take into account more complex editing behaviour in sequences.,8. Conclusion,[0],[0]
"We thank Minjeong Shin, Cheng Soon Ong and Lexing Xie for instructive discussions on an early draft of this work.",Acknowledgements,[0],[0]
We also thank the anonymous reviewers for their detailed and thoughtful comments.,Acknowledgements,[0],[0]
Prediction suffix trees (PST) provide an effective tool for sequence modelling and prediction.,abstractText,[0],[0]
Current prediction techniques for PSTs rely on exact matching between the suffix of the current sequence and the previously observed sequence.,abstractText,[0],[0]
We present a provably correct algorithm for learning a PST with approximate suffix matching by relaxing the exact matching condition.,abstractText,[0],[0]
We then present a self-bounded enhancement of our algorithm where the depth of suffix tree grows automatically in response to the model performance on a training sequence.,abstractText,[0],[0]
"Through experiments on synthetic datasets as well as three real-world datasets, we show that the approximate matching PST results in better predictive performance than the other variants of PST.",abstractText,[0],[0]
Self-Bounded Prediction Suffix Tree via Approximate String Matching,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 887–893 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
887",text,[0],[0]
"Deep neural networks are one of the most successful machine learning methods outperforming many state-of-the-art machine learning methods in natural language processing (Sutskever et al., 2014), speech (Hinton et al., 2012) and visual recognition tasks (Krizhevsky et al., 2012).",1 Introduction,[0],[0]
The availability of high performance computing has enabled research in deep learning to focus largely on the development of deeper and more complex network architectures for improved accuracy.,1 Introduction,[0],[0]
"However, the increased complexity of the deep neural networks has become one of the biggest obstacles to deploy deep neural networks ondevice such as mobile phones, smart watches and IoT (Iandola et al., 2016).",1 Introduction,[0],[0]
"The main challenges with developing and deploying deep neural network models on-device are (1) the tiny memory footprint, (2) inference latency and (3) significantly low computational capacity compared
to high performance computing systems such as CPUs, GPUs and TPUs on the cloud.
",1 Introduction,[0],[0]
There are multiple strategies to build lightweight text classification models for ondevice.,1 Introduction,[0],[0]
One can create a small dictionary of common input→ category mapping on the device and use a naive look-up at inference time.,1 Introduction,[0],[0]
"However, such an approach does not scale to complex natural language tasks involving rich vocabularies and wide language variability.",1 Introduction,[0],[0]
"Another strategy is to employ fast sampling techniques (Ahmed et al., 2012; Ravi, 2013) or incorporate deep learning models with graph learning like (Bui et al., 2017, 2018), which result in large models but have proven to be extremely powerful for complex language understanding tasks like response completion (Pang and Ravi, 2012) and Smart Reply (Kannan et al., 2016).
",1 Introduction,[0],[0]
"In this paper, we propose Self-Governing Neural Networks (SGNNs) inspired by projection networks (Ravi, 2017).",1 Introduction,[0],[0]
SGNNs are on-device deep learning models learned via embedding-free projection operations.,1 Introduction,[0],[0]
"We employ a modified version of the locality sensitive hashing (LSH) to reduce input dimension from millions of unique words/features to a short, fixed-length sequence of bits.",1 Introduction,[0],[0]
"This allows us to compute a projection for an incoming text very fast, on-the-fly, with a small memory footprint on the device since we do not need to store the incoming text and word embeddings.",1 Introduction,[0],[0]
"We evaluate the performance of our SGNNs on Dialogue Act classification, because (1) it is an important step towards dialog interpretation and conversational analysis aiming to understand the intent of the speaker at every utterance of the conversation and (2) deep learning methods reached state-of-the-art (Lee and Dernoncourt, 2016; Khanpour et al., 2016; Tran et al., 2017; Ortega and Vu, 2017).
",1 Introduction,[0],[0]
"The main contributions of the paper are:
• Novel Self-Governing Neural Networks (SGNNs) for on-device deep learning for short text classification.
",1 Introduction,[0],[0]
"• Compression technique that effectively captures low-dimensional semantic text representation and produces compact models that save on storage and computational cost.
",1 Introduction,[0],[0]
"• On the fly computation of projection vectors that eliminate the need for large pre-trained word embeddings or vocabulary pruning.
",1 Introduction,[0],[0]
"• Exhaustive experimental evaluation on dialog act datasets, outperforming state-of-theart deep CNN (Lee and Dernoncourt, 2016) and RNN variants (Khanpour et al., 2016; Ortega and Vu, 2017).",1 Introduction,[0],[0]
"We model the Self-Governing network using a projection model architecture (Ravi, 2017).",2 Self-Governing Neural Networks,[0],[0]
The projection model is a simple network with dynamically-computed layers that encodes a set of efficient-to-compute operations which can be performed directly on device for inference.,2 Self-Governing Neural Networks,[0],[0]
The model defines a set of efficient “projection” functions P(~xi) that project each input instance ~xi to a different space ΩP and then performs learning in this space to map it to corresponding outputs ypi .,2 Self-Governing Neural Networks,[0],[0]
"A very simple projection model comprises just few operations where the inputs ~xi are transformed using a series of T projection functions P1, ...,PT followed by a single layer of activations.",2 Self-Governing Neural Networks,[0],[0]
"In this work, we design a Self-Governing Neural Network (SGNN) using multi-layered localitysensitive projection model.",2.1 Model Architecture,[0],[0]
Figure 1 shows the model architecture of the on-device SGNN network.,2.1 Model Architecture,[0],[0]
"The self-governing property of this network stems from its ability to learn a model (e.g., a classifier) without having to initialize, load or store any feature or vocabulary weight matrices.",2.1 Model Architecture,[0],[0]
"In this sense, our method is a truly embedding-free approach unlike majority of the widely-used stateof-the-art deep learning techniques in NLP whose performance depends on embeddings pre-trained on large corpora.",2.1 Model Architecture,[0],[0]
"Instead, we use the projection functions to dynamically transform each input to a low-dimensional representation.",2.1 Model Architecture,[0],[0]
"Furthermore, we
stack this with additional layers and non-linear activations to achieve deep, non-linear combinations of projections that permit the network to learn complex mappings from inputs xi to outputs yi.",2.1 Model Architecture,[0],[0]
"An SGNN network is shown below:
ip =",2.1 Model Architecture,[0],[0]
"[P1(xi), ...,PT (xi)] (1) hp = σ(Wp · ip + bp) (2) ht = σ(Wt · ht−1 + bt) (3) yi = softmax(Wo · hk + bo) (4)
where, ip refers to the output of projection operation applied to input xi, hp is applied to projection output, ht is applied at intermediate layers of the network with depth k followed by a final softmax activation layer at the top.",2.1 Model Architecture,[0],[0]
"In a k-layer SGNN, ht, where t = p, p + 1, ..., p + k",2.1 Model Architecture,[0],[0]
− 1 refers to the k subsequent layers after the projection layer.,2.1 Model Architecture,[0],[0]
"Wp,Wt,Wo and bp, bt, bo represent trainable weights and biases respectively.
",2.1 Model Architecture,[0],[0]
"The projection transformations use precomputed parameterized functions, i.e., they are not trained during the learning process, and their outputs are concatenated to form the hidden units for subsequent operations.",2.1 Model Architecture,[0],[0]
"Each input text xi is converted to an intermediate feature vector (via raw text features such as skip-grams) followed by projections.
",2.1 Model Architecture,[0],[0]
"xi F−→ ~xi P−→ [P1(xi), ...,PT (xi)] (5)
",2.1 Model Architecture,[0],[0]
On-the-fly Computation.,2.1 Model Architecture,[0],[0]
The transformation step F dynamically extracts features from the raw input.,2.1 Model Architecture,[0],[0]
"Text features (e.g., skip-grams) are converted into feature-ids fj (via hashing) to generate a sparse feature representation ~xi of feature-id, weight pairs (fj , wj) .",2.1 Model Architecture,[0],[0]
This intermediate feature representation is passed through projection functions P to construct projection layer ip in SGNN.,2.1 Model Architecture,[0],[0]
"For this last step, a projection vector Pk is first constructed on-the-fly using a hash function with feature ids fj in ~xi and fixed seed as input, then dot product of the two vectors < ~xi,Pk > is computed and transformed into binary representation Pk(~xi) using sgn(.) of the dot product.
",2.1 Model Architecture,[0],[0]
"As shown in Figure 1, both F and P steps are computed on-the-fly, i.e., no word-embedding or vocabulary/feature matrices need to be stored and looked up during training or inference.",2.1 Model Architecture,[0],[0]
Instead feature-ids and projection vectors are dynamically computed via hash functions.,2.1 Model Architecture,[0],[0]
"For intermediate feature weights wj , we use observed counts in
each input text and do not use pre-computed statistics like idf.",2.1 Model Architecture,[0],[0]
"Hence the method is embedding-free.
",2.1 Model Architecture,[0],[0]
Model Optimization.,2.1 Model Architecture,[0],[0]
"The SGNN network is trained from scratch on the task data using a supervised loss defined wrt ground truth ŷi:
L(.)",2.1 Model Architecture,[0],[0]
= ∑ i∈N cross−,2.1 Model Architecture,[0],[0]
"entropy(yi, ŷi) (6)
",2.1 Model Architecture,[0],[0]
"During training, the network learns to choose and apply specific projection operations Pj (via activations) that are more predictive for a given task.",2.1 Model Architecture,[0],[0]
The choice of the type of projection matrix P as well as representation of the projected space ΩP has a direct effect on computation cost and model size.,2.1 Model Architecture,[0],[0]
"We leverage an efficient randomized projection method and use a binary representation {0, 1}d for ΩP.",2.1 Model Architecture,[0],[0]
"This yields a drastically lower memory footprint both in terms of number and size of parameters.
",2.1 Model Architecture,[0],[0]
Computing Projections.,2.1 Model Architecture,[0],[0]
We employ an efficient randomized projection method for the projection step.,2.1 Model Architecture,[0],[0]
"We use locality sensitive hashing (LSH) (Charikar, 2002) to model the underlying projection operations in SGNN.",2.1 Model Architecture,[0],[0]
"LSH is typically used as a dimensionality reduction technique for clustering (Manning et al., 2008).",2.1 Model Architecture,[0],[0]
"LSH allows us to project similar inputs ~xi or interme-
diate network layers into hidden unit vectors that are nearby in metric space.",2.1 Model Architecture,[0],[0]
"We use repeated binary hashing for P and apply the projection vectors to transform the input ~xi to a binary hash representation denoted by Pk(~xi) ∈ {0, 1}, where [Pk(~xi)]",2.1 Model Architecture,[0],[0]
":= sgn[〈~xi,Pk〉].",2.1 Model Architecture,[0],[0]
"This results in a dbit vector representation, one bit corresponding to each projection row Pk=1...",2.1 Model Architecture,[0],[0]
"d.
The same projection matrix P is used for training and inference.",2.1 Model Architecture,[0],[0]
We never need to explicitly store the random projection vector Pk since we can compute them on the fly using hash functions over feature indices with a fixed row seed rather than invoking a random number generator.,2.1 Model Architecture,[0],[0]
"This also permits us to perform projection operations that are linear in the observed feature size rather than the overall feature or vocabulary size which can be prohibitively large for high-dimensional data, thereby saving both memory and computation cost.",2.1 Model Architecture,[0],[0]
"Thus, SGNN can efficiently model highdimensional sparse inputs and large vocabulary sizes common for text applications instead of relying on feature pruning or other pre-processing heuristics employed to restrict input sizes in standard neural networks for feasible training.",2.1 Model Architecture,[0],[0]
"The binary representation is significant since this results in a significantly compact representation for the
projection network parameters that in turn considerably reduces the model size.
SGNN Parameters.",2.1 Model Architecture,[0],[0]
"In practice, we employ T different projection functions Pj=1...T , each resulting in d-bit vector that is concatenated to form the projected vector ip in Equation 5.",2.1 Model Architecture,[0],[0]
T and d vary depending on the projection network parameter configuration specified for P and can be tuned to trade-off between prediction quality and model size.,2.1 Model Architecture,[0],[0]
Note that the choice of whether to use a single projection matrix of size T · d or T separate matrices of d columns depends on the type of projection employed (dense or sparse).,2.1 Model Architecture,[0],[0]
"For the intermediate feature step F in Equation 5, we use skip-gram features (3-grams with skip-size=2) extracted from raw text.",2.1 Model Architecture,[0],[0]
We use the compact bit units to represent the projection in SGNN.,2.2 Training and Inference,[0],[0]
"During training, the network learns to move the gradients for points that are nearby to each other in the projected bit space ΩP in the same direction.",2.2 Training and Inference,[0],[0]
SGNN network is trained end-to-end using backpropagation.,2.2 Training and Inference,[0],[0]
"Training can progress efficiently with stochastic gradient descent with distributed computing on highperformance CPUs or GPUs.
",2.2 Training and Inference,[0],[0]
Complexity.,2.2 Training and Inference,[0],[0]
"The overall complexity for SGNN inference, governed by the projection layer, is O(n · T · d), where n is the observed feature size (*not* overall vocabulary size) which is linear in input size, d is the number of LSH bits specified for each projection vector Pk, and T is the number of projection functions used in P.",2.2 Training and Inference,[0],[0]
"The model size (in terms of number of parameters) and memory storage required for the projection inference step is O(T · d · C), where C is the number of hidden units in hp in the multi-layer projection network and typically smaller than T · d.",2.2 Training and Inference,[0],[0]
"We conduct our experimental evaluation on two dialog act benchmark datasets.
",3.1 Data Description,[0],[0]
• SWDA:,3.1 Data Description,[0],[0]
"Switchboard Dialog Act Corpus (Godfrey et al., 1992; Jurafsky et al., 1997) is a popular open domain dialogs corpus between two speakers with 42 dialogs acts.
",3.1 Data Description,[0],[0]
•,3.1 Data Description,[0],[0]
MRDA:,3.1 Data Description,[0],[0]
"ICSI Meeting Recorder Dialog Act Corpus (Adam et al., 2003; Shriberg et al., 2004) is a dialog corpus of multiparty meetings with 5 tags of dialog acts.
",3.1 Data Description,[0],[0]
Table 1 summarizes dataset statistics.,3.1 Data Description,[0],[0]
"We use the train, validation and test splits as defined in (Lee and Dernoncourt, 2016; Ortega and Vu, 2017).",3.1 Data Description,[0],[0]
"We setup our experimental evaluation, as follows: given a classification task and a dataset, we generate an on-device model.",3.2 Experimental Setup,[0],[0]
"The size of the model can be configured (by adjusting the projection matrix P) to fit in the memory footprint of the device, i.e. a phone has more memory compared to a smart watch.",3.2 Experimental Setup,[0],[0]
"For each classification task, we report Accuracy on the test set.",3.2 Experimental Setup,[0],[0]
"For both datasets we used the following: 2- layer SGNN (PT=80,d=14 × FullyConnected256 × FullyConnected256), mini-batch size of 100, dropout rate of 0.25, learning rate was initialized to 0.025 with cosine annealing decay (Loshchilov and Hutter, 2016).",3.3 Hyperparameter and Training,[0],[0]
"Unlike prior approaches (Lee and Dernoncourt, 2016; Ortega and Vu, 2017) that rely on pre-trained word embeddings, we learn the projection weights on the fly during training, i.e word embeddings (or vocabularies) do not need to be stored.",3.3 Hyperparameter and Training,[0],[0]
"Instead, features are computed on the fly and are dynamically compressed via the projection matrices into projection vectors.",3.3 Hyperparameter and Training,[0],[0]
"These values were chosen via a grid search on development sets, we do not perform any other dataset-specific tuning.",3.3 Hyperparameter and Training,[0],[0]
"Training is performed through stochastic gradient descent over shuffled mini-batches with Nesterov momentum optimizer (Sutskever et al., 2013), run for 1M steps.",3.3 Hyperparameter and Training,[0],[0]
Tables 2 and 3 show results on the SwDA and MRDA dialog act datasets.,4 Results,[0],[0]
"Overall, our SGNN model consistently outperforms the baselines and prior state-of-the-art deep learning models.",4 Results,[0],[0]
"We compare our model against a majority class baseline and Naive Bayes classifier (Lee and Dernoncourt, 2016).",4.1 Baselines,[0],[0]
Our model significantly outperforms both baselines by 12 to 35% absolute.,4.1 Baselines,[0],[0]
"We also compare our performance against prior work using HMMs (Stolcke et al., 2000) and recent deep learning methods like CNN (Lee and Dernoncourt, 2016), RNN (Khanpour et al., 2016) and RNN with gated attention (Tran et al., 2017).
",4.2 Comparison against State-of-art Methods,[0],[0]
"To the best of our knowledge, (Lee and Dernoncourt, 2016; Ortega and Vu, 2017; Tran et al., 2017) are the latest approaches in dialog act classification, which also reported on the same data splits.",4.2 Comparison against State-of-art Methods,[0],[0]
"Therefore, we compare our research against these works.",4.2 Comparison against State-of-art Methods,[0],[0]
"According to (Ortega and Vu, 2017), prior work by (Ji and Bilmes, 2006) achieved promising results on the MRDA dataset, but since the evaluation was conducted on a different data split, it is hard to compare them directly.
",4.2 Comparison against State-of-art Methods,[0],[0]
"For both SwDA and MRDA datasets, our SGNNs obtains the best result of 83.1 and 86.7 accuracy outperforming prior state-of-the-art work.",4.2 Comparison against State-of-art Methods,[0],[0]
This is very impressive given that we work with very small memory footprint and we do not rely on pre-trained word embeddings.,4.2 Comparison against State-of-art Methods,[0],[0]
"Our study also shows that the proposed method is very effective for such natural language tasks compared to more complex neural network architectures such as deep CNN (Lee and Dernoncourt, 2016) and RNN variants (Khanpour et al., 2016; Ortega and Vu, 2017).",4.2 Comparison against State-of-art Methods,[0],[0]
We believe that the compression techniques like locality sensitive projections jointly coupled with non-linear functions are effective at capturing lowdimensional semantic text representations that are useful for text classification applications.,4.2 Comparison against State-of-art Methods,[0],[0]
"LSTMs have millions of parameters, while our on-device architecture has just 300K parameters (order of magnitude lower).",4.3 Discussion on Model Size and Inference,[0],[0]
Most deep learning methods also use large vocabulary size of 10K or higher.,4.3 Discussion on Model Size and Inference,[0],[0]
"Each word embedding is represented as 100-dimensional vector leading to a storage requirement of 10, 000×100 parameter weights just in the first layer of the deep network.",4.3 Discussion on Model Size and Inference,[0],[0]
"In contrast, SGNNs in all our experiments use a fixed 1120-dimensional vector regardless of the vocabulary or feature size, dynamic computation results
in further speed up for high-dimensional feature spaces.",4.3 Discussion on Model Size and Inference,[0],[0]
This amounts to a huge savings in storage and computation cost wrt FLOPs (floating point operations per second).,4.3 Discussion on Model Size and Inference,[0],[0]
We proposed Self-Governing Neural Networks for on-device short text classification.,5 Conclusion,[0],[0]
"Experiments on multiple dialog act datasets showed that our model outperforms state-of-the-art deep leaning methods (Lee and Dernoncourt, 2016; Khanpour et al., 2016; Ortega and Vu, 2017).",5 Conclusion,[0],[0]
We introduced a compression technique that effectively captures low-dimensional semantic representation and produces compact models that significantly save on storage and computational cost.,5 Conclusion,[0],[0]
Our approach does not rely on pre-trained embeddings and efficiently computes the projection vectors on the fly.,5 Conclusion,[0],[0]
"In the future, we are interested in extending this approach to more natural language tasks.",5 Conclusion,[0],[0]
"For instance, we built a multilingual SGNN model for customer feedback classification (Liu et al., 2017) and obtained 73% on Japanese, close to best performing system on the challenge (Plank, 2017).",5 Conclusion,[0],[0]
"Unlike their method, we did not use any pre-processing, tagging, parsing, pre-trained embeddings or other resources.",5 Conclusion,[0],[0]
We would like to thank the anonymous reviewers for their valuable feedback and suggestions.,Acknowledgments,[0],[0]
"Deep neural networks reach state-of-the-art performance for wide range of natural language processing, computer vision and speech applications.",abstractText,[0],[0]
"Yet, one of the biggest challenges is running these complex networks on devices such as mobile phones or smart watches with tiny memory footprint and low computational capacity.",abstractText,[0],[0]
"We propose on-device Self-Governing Neural Networks (SGNNs), which learn compact projection vectors with local sensitive hashing.",abstractText,[0],[0]
The key advantage of SGNNs over existing work is that they surmount the need for pre-trained word embeddings and complex networks with huge parameters.,abstractText,[0],[0]
We conduct extensive evaluation on dialog act classification and show significant improvement over state-of-the-art results.,abstractText,[0],[0]
"Our findings show that SGNNs are effective at capturing low-dimensional semantic text representations, while maintaining high accuracy.",abstractText,[0],[0]
Self-Governing Neural Networks for On-Device Short Text Classification,title,[0],[0]
"Semi-supervised learning (SSL) aims to implement learning on both labeled and unlabeled data through fully considering the supervised knowledge delivered by labeled data and unsupervised data structure under unlabeled ones (Zhu, 2011).",1. Introduction,[0],[0]
"Co-training (Blum & Mitchell, 1998) is one of the most classical and well known SSL approaches that train classifiers on two views and exchanges labels of
1Xi’an Jiaotong University, Xi’an, China 2University of Technology Sydney, Sydney, Australia.",1. Introduction,[0],[0]
"Correspondence to: Deyu Meng <dymeng@xjtu.edu.cn>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
unlabeled instances in an iterative way.",1. Introduction,[0],[0]
"In the recent years, co-training has been attracting much attention attributed to both its wide applications, like web classification and visual detection (Xu et al., 2009), and rational theoretical supports (Blum & Mitchell, 1998; Balcan et al., 2004; Wang & Zhou, 2010; 2013).
",1. Introduction,[0],[0]
"However, there are still some limitations existing in current co-training investigation.",1. Introduction,[0],[0]
"Specifically, although there are multiple theoretical results to support the rationality of the co-training regimes, most of them require a strong pre-assumption that the false pseudo-labeled instances can be correctly recognized during training by classifiers or pseudo labels of unlabeled instances predicted in each iteration are of a high confidence extent.",1. Introduction,[0],[0]
"Based on such high-confidence assumption, most of current co-training algorithms add pseudo-labeled samples into training without replacement.",1. Introduction,[0],[0]
"Nevertheless, in most real cases such assumption is too subjective to be satisfied, especially in the early learning stage of a co-training algorithm.",1. Introduction,[0],[0]
"The learned classifiers might be not able to confidently distinguish certain samples, or precisely pseudo-annotate them with an expected accuracy requirement.",1. Introduction,[0],[0]
"This not only inclines to degenerate the performance of co-training since those false pseudo-labeled involved in training have no chance to be rectified in the latter training process on account of such “draw without replacement” manner, but also might make the basic assumption under theoretical support of cotraining incorrect.
",1. Introduction,[0],[0]
Another critical issue in most of current co-training methods is on their absence of an optimization model that can measure the performance and explain the intrinsic mechanism under the co-training implementation.,1. Introduction,[0],[0]
"As formally defined in (Mitchell, 1997), the performance measure is one of the necessary elements for a machine learning method.",1. Introduction,[0],[0]
"It is thus meaningful to explore whether there exists such an optimization model, which can finely interpret the co-training implementation as the process of solving this model.",1. Introduction,[0],[0]
"Such model also should be helpful in revealing more insights underlying co-training.
",1. Introduction,[0],[0]
"To address the aforementioned issues, a new co-training method, called self-paced co-training (SPaCo) is proposed in this study.",1. Introduction,[0],[0]
"The method differs from the previous cotraining regimes mainly in two aspects: Firstly, it utilizes a
“draw with replacement” learning manner.",1. Introduction,[0],[0]
"In the method, an unlabeled instance having been added into the training pool is likely to be removed if classifiers in later training rounds identify it as a low-confidence annotated one.",1. Introduction,[0],[0]
"Besides, the pseudo label of an unlabeled instance has chance to be rectified based on the prediction knowledge obtained by classifiers in later training rounds.",1. Introduction,[0],[0]
"Secondly, the SPaCo method employs a serial mode to update the classifiers of two views in co-training implementation instead of the parallel mode commonly adopted by previous methods.",1. Introduction,[0],[0]
"Under such amelioration, the new method can be proved to still guarantee the theoretical effectiveness under -expansion assumption in the traditional co-training theory, while more importantly, such series implementation exactly complies with the alternative optimization algorithm on solving a concise optimization model.",1. Introduction,[0],[0]
"Besides, it is substantiated that the new method can attain evidently better performance beyond current state-of-the-art co-training methods on average of our experiments, which further verifies the rationality of the proposed SPaCo algorithm.
",1. Introduction,[0],[0]
"In summary, this work makes the following contributions:
• A new co-training method, called SPaCo, is proposed by adopting the “draw with replacement” learning manner.",1. Introduction,[0],[0]
"Similar to traditional co-training strategies, the theoretical soundness of the new method can also be proved under the commonly specified -expansion assumption for pseudo-label confidence.
",1. Introduction,[0],[0]
• The implementation process of the new method exactly complies with an alternative updating algorithm for a underlying optimization model.,1. Introduction,[0],[0]
"This model corresponds to a self-paced curriculum learning paradigm, which helps reveal more “easy-to-hard” insights under the co-training implementation.
",1. Introduction,[0],[0]
"• Through this derived model, the effectiveness of the proposed SPaCo method can be finely interpreted as: the method implements robust learning regimes in both views under the regularization that the robust loss forms in two views are closely related.",1. Introduction,[0],[0]
"This understanding provides a natural explanation for the effectiveness mechanism under such co-training strategy, without any requirement of subjective assumptions for pseudo-label confidences.
",1. Introduction,[0],[0]
"• Experimental results on multiple text classification and person re-ID data substantiate the superiority of the SPaCo method as compared with current state-ofthe-art co-training methods.
",1. Introduction,[0],[0]
The rest of the paper is organized as follows.,1. Introduction,[0],[0]
"We first briefly introduce related work in Section 2, and then present the proposed SPaCo algorithm and its underlying model in Section 3.",1. Introduction,[0],[0]
"More theoretical explanations on its insights are
also provided in this part.",1. Introduction,[0],[0]
We then present the experimental results and finally give a conclusion remark.,1. Introduction,[0],[0]
"The traditional co-trainig method (Blum & Mitchell, 1998) builds classifiers for different views and exchanges predictions of high-confidence unlabeled data to augment the training set in two views in each training round.",2.1. Co-training methods,[0],[0]
"Afterwards, multiple advancements have been developed.",2.1. Co-training methods,[0],[0]
These co-training variants can be roughly categorized into two paradigms.,2.1. Co-training methods,[0],[0]
"One paradigm is to follow the iterative training process of co-training but to label unlabeled samples using different methods with certain confidence criterion in each iteration (Goldman & Zhou, 2000; Brefeld & Scheffer, 2004; 2006; Zhou et al., 2007; Li & Zhou, 2007; Zhang & Zhou, 2011).",2.1. Co-training methods,[0],[0]
"The other is to embed extra information from other views as a regularization term into the learning objective (Sindhwani et al., 2005; Sindhwani & Rosenberg, 2008; Ye et al., 2015) and turn the semi-supervised multiview problem into a new optimization problem.",2.1. Co-training methods,[0],[0]
"Recently, there are multiple other methods proposed aiming to simultaneously learn classifiers on two different views or multi-views.",2.2. Other methods related to co-learning,[0],[0]
"While different from co-training approaches, these methods directly pseudo-label all unlabeled samples and involve them into the training process.",2.2. Other methods related to co-learning,[0],[0]
"A typical approach along this line is Co-EM (Nigam & Ghani, 2000), which iteratively updates labels of unlabeled data based on the posterior class probability calculated by naive Bayesian learners, and updates the classifiers on all of them.",2.2. Other methods related to co-learning,[0],[0]
"Several other methods directly encode the unknown labels of unlabeled data and classifier parameters on two views into a model, and simultaneously calculate all these variables through solving this model.",2.2. Other methods related to co-learning,[0],[0]
"Typical methods of this category include Co-MR (Sindhwani & Rosenberg, 2008), which deduces a co-regularization kernel by exploiting two Reproducing Kernel Hilbert Spaces defined over the same input space, and RANC (Ye et al., 2015), which assumes predictions for unlabeled data under different views are consistent with each other and enforces an affixed rank constraint on optimization function of each view.",2.2. Other methods related to co-learning,[0],[0]
The rationality of co-training is supported by a series of related theoretical analyses.,2.3. Co-training theory development,[0],[0]
"E.g., (Blum & Mitchell, 1998) showed that class on two views is learnable in the PAC model with classification noise when the features of two views are independent given the class.",2.3. Co-training theory development,[0],[0]
"To further relax the assumption for co-training, (Abney, 2002) provided a
weaker view-independence condition that brings about the success of co-training.",2.3. Co-training theory development,[0],[0]
"Afterwards, (Balcan et al., 2004) introduced the -expansion assumption, which is a confidence assumption on pseudo labeled positive samples, further relaxing the condition of guaranteeing the effectiveness of a co-training strategy.",2.3. Co-training theory development,[0],[0]
"Later, (Wang & Zhou, 2010) made a new analysis of co-training on label propagation strategy designed for co-training.
",2.3. Co-training theory development,[0],[0]
"Despite providing theoretical support for current cotraining methods, all these theories include some subjective assumptions like the independence between classifiers of different views and the confidence extent of pseudo-labels of unlabeled samples obtained by the algorithm.",2.3. Co-training theory development,[0],[0]
"These assumptions, however, are not only hard to be justified in real applications, but also not very intuitive to be easily understood by common co-training users, which might possibly keep it from being more extensively utilized in practice.",2.3. Co-training theory development,[0],[0]
"(Bengio et al., 2009) proposed a learning paradigm called curriculum learning(CL), in which a model is learned by gradually including samples from easy to complex in training so as to increase the entropy of training samples.",2.4. Self-paced learning,[0],[0]
"Afterwards, self-paced learning (Kumar et al., 2010) is proposed to embed curriculum design as a regularization term into the learning objective.",2.4. Self-paced learning,[0],[0]
"Due to its generality, the SPL theory has been widely applied to various tasks, such as object tracking (Supancic & Ramanan, 2013), image classification (Jiang et al., 2015), and multimedia event detection (Jiang et al., 2014a;b).",2.4. Self-paced learning,[0],[0]
"Especially, the SPL paradigm has been integrated into the system developed by CMU Informedia team, and achieved the leading performance in challenging TRECVID MED/MER competition organized by NIST in 2014 (Yu et al., 2014).
",2.4. Self-paced learning,[0],[0]
"Let L(yi, g(xi,w))",2.4. Self-paced learning,[0],[0]
"denote the loss function which calculates the cost between the ground truth label yi and the estimated one g(xi,w).",2.4. Self-paced learning,[0],[0]
"Here w represents the model parameter inside the decision function g. The SPL model considers a weighted loss term for all samples and a general self-paced regularizer with respect to sample weights, expressed as:
min w,v∈[0,1]n E(w,v;λ) = n∑ i=1",2.4. Self-paced learning,[0],[0]
"(viL(yi, g(xi,w))+f(vi, λ)),
(1)
where λ is the age parameter for controlling the learning space, and f(v, λ) represents the self-paced regularizer (SP-regularizer briefly).",2.4. Self-paced learning,[0],[0]
"By jointly learning the model parameter w and the latent weight v using alternative optimization strategy with gradually increasing age parameter, more samples can be automatically included into training from easy to complex in a purely self-paced way.
",2.4. Self-paced learning,[0],[0]
"The recent development of SPL includes that (Jiang et al.,
2015) improved SPL as a more effective self-paced curriculum learning (SPCL) regime by embedding useful loss prior knowledge into the model and analyzed that this regime is analogous to rational instructor-studentcollaborative learning mode of human teaching.",2.4. Self-paced learning,[0],[0]
"And multiple researches (Zhang et al., 2015; Zhao et al., 2015; Pi et al., 2016) showed that SPL worked well when dealing with real data.",2.4. Self-paced learning,[0],[0]
"Besides, (Meng & Zhao, 2015; Ma et al., 2017) proved that the optimization problem of SPL solved by the alternative optimization algorithm is equivalent to a robust loss minimization problem solved by a majorizationminimization algorithm.",2.4. Self-paced learning,[0],[0]
This work first reveals the insightful understanding of the robust learning mechanism under SPL.,2.4. Self-paced learning,[0],[0]
"In this section, we introduce the details of our proposed framework, Self-Paced Co-training (SPaCo) model.",3. Self-paced Co-training,[0],[0]
"We first present the mathematical form of this model, and then introduce the alternative optimization algorithm for solving this model.",3. Self-paced Co-training,[0],[0]
It is then evident that the algorithm finely complies with a co-training strategy in a “draw with replacement” mode and a series implementation manner.,3. Self-paced Co-training,[0],[0]
Some properties of the algorithm will be detailedly analyzed afterwards.,3. Self-paced Co-training,[0],[0]
"We then provide the theoretical support under -expansion assumption, and show that the effectiveness of the algorithm can be proved under the conventional routine of co-training.",3. Self-paced Co-training,[0],[0]
"Finally, a new interpretation on the mechanism of this method will be presented from the viewpoint of self-paced learning.",3. Self-paced Co-training,[0],[0]
"We first present the following SPaCo model, which extends the self-paced learning optimization model (1) to two view scenarios, by introducing importance weights of two views v (1) k , v (2) k , (k = l + 1, · · · , l + u), together with the corresponding hard self-paced regularizer f(v, λ) = λv as proposed in (Jiang et al., 2014a):
min w(j),yk,v (j) k ∈[0,1]
j=1,2;k=l+1,··· ,l+u
E(w(j), v (j) k , yk;λ (j), γ) =
2∑ j=1 l∑ i=1",3.1. SPaCo Model,[0],[0]
"L(yi, g (j)(x (j) i ;w (j)))",3.1. SPaCo Model,[0],[0]
"+ 1 2 2∑ j=1 ||w(j)||2
+ 2∑ j=1 l+u∑ k=l+1 (v (j) k",3.1. SPaCo Model,[0],[0]
"L(yk, g (j)(x (j) k ;w (j)))− λ(j)v(j)k )
",3.1. SPaCo Model,[0],[0]
"− γ(v(1))Tv(2),
(2)
where l and u denote the number of labeled and unlabeled instances, respectively.",3.1. SPaCo Model,[0],[0]
"x(j)i is the i
th sample (i = 1, · · · , l + u) under jth view (j = 1, 2), and yi is the common label of x(j)i for every j. v (j) k denotes the weight of
x (j) k",3.1. SPaCo Model,[0],[0]
"where k = l + 1, ..., l + u. v (j) is an u-dimensional vector preserving all the weights of unlabeled instances under jth view where its kth element is v(j)l+k.",3.1. SPaCo Model,[0],[0]
"w
(j) represents parameters of jth classifier trained on jth view.",3.1. SPaCo Model,[0],[0]
"λ(j) is the age parameter controlling the training scale in each iteration with respect to jth view, and γ is the parameter adjusting influence from the other view when one view is going to add more training samples.
",3.1. SPaCo Model,[0],[0]
The above SPaCo model actually corresponds to the sum of SPL model under two views plus a regularization term (v(1))Tv(2).,3.1. SPaCo Model,[0],[0]
This inner product encodes the relationship of “sample easiness degree” between two views.,3.1. SPaCo Model,[0],[0]
"The new coregularizer delivers the basic assumption under co-training that different views share common knowledge of pseudolabeled sample confidence (an unlabeled sample is likely to be labeled correctly or wrongly simultaneously for both views), and thus this inner product enforces the weight penalizing the loss of one view similar to that of the other view.",3.1. SPaCo Model,[0],[0]
This finely accords to the idea of SPCL and complies with an instructor-student-collaborative learning manner under a specific co-training curriculum.,3.1. SPaCo Model,[0],[0]
The alternative optimization strategy (AOS) can be readily adopted to solve this SPaCo model.,3.2. AOS algorithm for solving (2),[0],[0]
"The optimization process are shown as follows1:
Initialization: The first step is to initialize parameters of model.",3.2. AOS algorithm for solving (2),[0],[0]
v(1) and v(2) are zero vectors in Ru. λ(1) and λ(2) are initialized with small values to allow a few unlabeled instances into training for the first iteration.,3.2. AOS algorithm for solving (2),[0],[0]
γ is set as a specific value in the whole training process.,3.2. AOS algorithm for solving (2),[0],[0]
"Two classifiers are simultaneously trained on labeled samples to get initial losses of both labeled and unlabeled instances.
",3.2. AOS algorithm for solving (2),[0],[0]
Update v(3−j)k,3.2. AOS algorithm for solving (2),[0],[0]
"(j = 1, 2): The physical meaning of this step is to prepare confident unlabeled instances (with nonzero v(3−j)k values) for the training on the j
th view.",3.2. AOS algorithm for solving (2),[0],[0]
This is known as the process of picking confident instances from one view in the traditional co-training algorithm.,3.2. AOS algorithm for solving (2),[0],[0]
By calculating the derivative of Eq.,3.2. AOS algorithm for solving (2),[0],[0]
"(2) with respect to v(3−j)k , we can get
∂E
∂v (3−j)",3.2. AOS algorithm for solving (2),[0],[0]
"k
= L (3−j)",3.2. AOS algorithm for solving (2),[0],[0]
k,3.2. AOS algorithm for solving (2),[0],[0]
− λ (3−j) − γv(j)k .,3.2. AOS algorithm for solving (2),[0],[0]
"(3)
Then we can get the closed-form updating equation for v3−ji as follows:
v (3−j)∗ k =
{ 1, L
(3−j)",3.2. AOS algorithm for solving (2),[0],[0]
"k < λ (3−j) + γvjk,
0, otherwise.",3.2. AOS algorithm for solving (2),[0],[0]
"(4)
1For the ease of description, we only present the optimization process under one view since parameters under the other view are optimized in the same way.
",3.2. AOS algorithm for solving (2),[0],[0]
"In the first iteration, all the v(j)k s are zeros according to the initialization.",3.2. AOS algorithm for solving (2),[0],[0]
Thus unlabeled instances are selected only from the (3−j)th view.,3.2. AOS algorithm for solving (2),[0],[0]
"In other words, unlabeled instances with loss values less than λ(3−j) will be seen as confident instances.
",3.2. AOS algorithm for solving (2),[0],[0]
Update v(j)k :,3.2. AOS algorithm for solving (2),[0],[0]
The goal of this step is to formally define which unlabeled instances will be feeded into the training pool of j(th) view.,3.2. AOS algorithm for solving (2),[0],[0]
"The optimization process for v(j)k is the same as previous step, but unlabeled instances selected in this step will be directly employed for training in jth view.
",3.2. AOS algorithm for solving (2),[0],[0]
From Eq.,3.2. AOS algorithm for solving (2),[0],[0]
"(4), we can easily observe that confident instances from the other view (picked in the previous step) possess higher chance than other instances to be selected for training.
",3.2. AOS algorithm for solving (2),[0],[0]
Update w(j): This step aims to train a classifier by virtue of the labeled and pseudo-labeled samples in the training pool of the jth view.,3.2. AOS algorithm for solving (2),[0],[0]
"By setting the loss as well-known hinge loss, we can directly choose SVM to train the expected classifier.",3.2. AOS algorithm for solving (2),[0],[0]
"In this case, Eq. (2) degenerates to the standard SVM optimization problem as:
min w(j)
1 2 ||w(j)||2 + l∑ i=1",3.2. AOS algorithm for solving (2),[0],[0]
L (j) i + l+u∑ k=l+1 v (j) k L,3.2. AOS algorithm for solving (2),[0],[0]
(,3.2. AOS algorithm for solving (2),[0],[0]
"j) k , (5)
where L(j)t = L(yt, g(x (j) t ,w (j))), t = 1, · · · , l + u.",3.2. AOS algorithm for solving (2),[0],[0]
"This problem can be readily solved by any off-the-shelf SVM toolbox (Jiang et al., 2014a).",3.2. AOS algorithm for solving (2),[0],[0]
"For the cross entropy loss, we can employ deep learning network to train the expected classifier, and thus our model is not constrained within one single classification algorithm.
",3.2. AOS algorithm for solving (2),[0],[0]
"Update yk: The next step is to update pseudo-labels of training samples by solving the following minimization sub-problem:
yk = argmin yk 2∑ j=1 v (j) k",3.2. AOS algorithm for solving (2),[0],[0]
"L(yk, g(x (j) k ;w (j))).",3.2. AOS algorithm for solving (2),[0],[0]
"(6)
It is easy to prove that the global optimum of the above problem can be obtained by directly setting the pseudolabel yi of a training sample as the weighted sum of prediction value under two classifiers.
",3.2. AOS algorithm for solving (2),[0],[0]
"Once pseudo-labels of training samples are refreshed, λ(1), λ(2) are enlarged to allow more instances with lager loss values into the training pool in the next iteration.",3.2. AOS algorithm for solving (2),[0],[0]
"Then we repeat the above optimization process with respect to each variable under different views until there is no more available unlabeled instances or the preset largest iteration number is reached.
",3.2. AOS algorithm for solving (2),[0],[0]
The entire process of this alternative optimization algorithm is summarized in Algorithm 1.,3.2. AOS algorithm for solving (2),[0],[0]
"It can be seen that
such optimization process exactly corresponds to the traditional co-traing algorithm with some reasonable adjustments.",3.2. AOS algorithm for solving (2),[0],[0]
"Assisted by this model, such a co-training algorithm possesses all of the necessary elements a formal machine learning method should have.
",3.2. AOS algorithm for solving (2),[0],[0]
"Algorithm 1 Alternative Optimization Algorithm for Solving SPaCo Model
1: Input: samples x(1)1 , · · · , x (1) l+u, x (2) 1 , · · · , x (2) l+u, labels
y1, ..., yl, parameters λ(1), λ(2), γ, and max round.",3.2. AOS algorithm for solving (2),[0],[0]
"2: Output: w(1),w(2).",3.2. AOS algorithm for solving (2),[0],[0]
"3: Initialize v(1), v(2), λ(1), λ(2), and γ 4: Update w(1),w(2) 5: training round = 1 6: while not converge ||",3.2. AOS algorithm for solving (2),[0],[0]
training round < max round do 7: for j ← 1 to 2 do 8: Update v(3−j)k :,3.2. AOS algorithm for solving (2),[0],[0]
Prepare confident instances from (3− j)th view for training on jth view 9: Update v(j)k :,3.2. AOS algorithm for solving (2),[0],[0]
"Add unlabeled instances into the
training pool of jth view based on L(j)k and γv
(3−j) k
10: Update w(j): Train a classifier (SVM for instance) on training pool of jth view 11: Update yk: Find optimal pseudo label for each of selected unlabeled instances by solving Eq.",3.2. AOS algorithm for solving (2),[0],[0]
"(6) 12: Augment λ(1), λ(2) 13: end for 14: end while 15: Return w(1),w(2)
From Algorithm 1, we can easily observe that it has a very similar implementation scheme as traditional co-training methods.",3.2. AOS algorithm for solving (2),[0],[0]
"Specifically, it also iteratively trains classifiers on two views by exchanging labels of unlabeled instances.",3.2. AOS algorithm for solving (2),[0],[0]
"Yet beyond that, the proposed algorithm complies with an optimization implementation on a underlying self-paced learning model.",3.2. AOS algorithm for solving (2),[0],[0]
"This model thus tends to provide some novel insightful understandings on the intrinsic effectiveness mechanism under the co-training approach, which will be analyzed in Sec. 3.5.",3.2. AOS algorithm for solving (2),[0],[0]
"The standard co-training method (Blum & Mitchell, 1998) requires to simultaneously train classifiers of both views, and then select highly confident samples to label for each view and feed them into the training pool of the other view.",3.3. Algorithm analysis,[0],[0]
"The proposed SPaCo algorithm, as listed in Algorithm 1, mainly differs from traditional co-training methods in the following three-fold aspects.
",3.3. Algorithm analysis,[0],[0]
"First, instead of “draw without replacement” mode as conventional, the SPaCo algorithm utilizes a “draw with re-
placement” manner.",3.3. Algorithm analysis,[0],[0]
"The algorithm does not consistently keep the previously selected training pool unchanged, while a confidence sample in the pool has certain chance to be thrown out from it when the loss value of a sample is larger than a preset threshold γ + λ.",3.3. Algorithm analysis,[0],[0]
"Note that this confidence threshold is larger than that (λ) set for samples not in the training pool, implying that we still more prefer to keep the samples in the pool than those not in it.",3.3. Algorithm analysis,[0],[0]
"Also, when we set γ as an extremely large value, then it is easy to deduce that the algorithm will degenerate to a traditional “draw without replacement” method since the loss values of any samples in the training pool will be smaller than the threshold and will thus be definitely selected in the next round.
",3.3. Algorithm analysis,[0],[0]
"Second, instead of the parallel training way as conventional, the new algorithm uses a serial manner for training the classifiers of two views.",3.3. Algorithm analysis,[0],[0]
"This not only will make this algorithm fully comply with the alternative updating strategy for solving an optimization model, but also leads to better performance than traditional parallel model methods (see experiment part).",3.3. Algorithm analysis,[0],[0]
"This might possibly be due to the fact that the serial way can better guarantee the reliability of added high-confidence pseudo-label samples based on the updated while not the non-updated classifiers as in parallel way.
",3.3. Algorithm analysis,[0],[0]
"Third, when updating the training pool in one view, besides feeding into high-confidence samples justified by the other view, the new algorithm might add into the pool a few high-confidence samples which obtain very small loss values calculated on the current view.",3.3. Algorithm analysis,[0],[0]
This is expected to make the algorithm use more reliable high-confidence knowledge from the predicted knowledge by current classifiers.,3.3. Algorithm analysis,[0],[0]
"Similar to the theoretical support for traditional co-training methods, we want to prove that the SPaCo algorithm is a PAC learning algorithm under the certain -expansion condition as utilized in (Balcan et al., 2004).",3.4. Learnable theory of SPaCo under -expansion assumption,[0],[0]
"First we give the definition of the -expansion condition:
Definition 1 (Balcan et al., 2004) Let X+ denote the positive region and D+ denote the distribution over X+, and Xi(i = 1, 2) is the training data set in the ith view.",3.4. Learnable theory of SPaCo under -expansion assumption,[0],[0]
"For S1 ⊆ X1 and S2 ⊆ X2, the D+ is -expanding if the following inequality holds:
P (S1 ⊕ S2) ≥ min(P (S1 ∧ S2), P (S̄1 ∧ S̄2)), (7)
where P (S1 ∧ S2) denotes the probability of examples for being confident in both views, and P (S1 ⊕ S2) denotes the probability of examples for being confident in only one view.
",3.4. Learnable theory of SPaCo under -expansion assumption,[0],[0]
We can then prove the following theorem for the proposed SPaCo algorithm.,3.4. Learnable theory of SPaCo under -expansion assumption,[0],[0]
"The proof is presented in supplementary material.
",3.4. Learnable theory of SPaCo under -expansion assumption,[0],[0]
Theorem 1 Let fin and δfin be the desired accuracy and confidence parameters.,3.4. Learnable theory of SPaCo under -expansion assumption,[0],[0]
"Suppose that the serial - expanding condition is satisfied in each training round, and then we can achieve the error rate fin with probability 1− δfin by running the SPaCo forN =",3.4. Learnable theory of SPaCo under -expansion assumption,[0],[0]
"O( 1 log
1 fin + 1 · 1 pinit )
rounds, each time running algorithm A1 and algorithm A2 with accuracy and confidence parameters set to · fin8 and δfin 2N , respectively.
",3.4. Learnable theory of SPaCo under -expansion assumption,[0],[0]
"Therefore, the rationality of the new algorithm can also be supported by the traditional theoretical means.",3.4. Learnable theory of SPaCo under -expansion assumption,[0],[0]
"Based on the SPaCo model (2) underlying Algorithm 1, we can get some new insights underlying the co-training regimes.
",3.5. Co-robust-loss interpretation for SPaCo rationality,[0],[0]
"(Meng & Zhao, 2015) has proved that the optimization problem (1) of SPL is closely related to a robust loss minimization problem.",3.5. Co-robust-loss interpretation for SPaCo rationality,[0],[0]
Such understanding can be utilized in this study to present a new understanding for the effectiveness insight underlying this co-training strategy.,3.5. Co-robust-loss interpretation for SPaCo rationality,[0],[0]
"Specifically, in the SPaCo model (2), there is a separate SPL objective function for each view, which means that there implicitly exists a robust loss for training the classifier of each view on pseudo-labeled samples.",3.5. Co-robust-loss interpretation for SPaCo rationality,[0],[0]
"However, such robust losses for different views are not independent while closely related to each other since a sample should be labeled correctly or wrongly for any view of data representation.",3.5. Co-robust-loss interpretation for SPaCo rationality,[0],[0]
"Thus in SPaCo model (2), the co-training curriculum regularization actually encodes such relationship between robustness of different views.",3.5. Co-robust-loss interpretation for SPaCo rationality,[0],[0]
"That is, through consistently exchanging pseudo-labels justified in different views, the robust loss functions of both views are enforced to be related by such regularization term.",3.5. Co-robust-loss interpretation for SPaCo rationality,[0],[0]
"This guarantees a sound learning manner for the co-training process.
",3.5. Co-robust-loss interpretation for SPaCo rationality,[0],[0]
Note that such a explanation for the effectiveness of the SPaCo algorithm can be easily understood and requires no subjective assumptions on pseudo-label confidences or two-view independence.,3.5. Co-robust-loss interpretation for SPaCo rationality,[0],[0]
It is thus expected to facilitate a better extension of co-training paradigms to general users.,3.5. Co-robust-loss interpretation for SPaCo rationality,[0],[0]
"To validate the performance of the proposed SPaCo method, we first employ six text classification data sets derived from three real-world domains, where each data set is associated with two naturally partitioned or artificially generated views.",4. Experimental results,[0],[0]
"Besides, we also apply our method to the person re-identification task, which is a popular research
topic in the field of computer vision.",4. Experimental results,[0],[0]
"Datasets: We employ the following six data sets, all having been used for testing in the previous co-training literatures.
",4.1. Text Classification Experiments,[0],[0]
Course data:,4.1. Text Classification Experiments,[0],[0]
"This data set contains 1,051 home pages collected from web sites of Computer Science departments of Cornell University2.",4.1. Text Classification Experiments,[0],[0]
"These pages are manually labeled as course or noncourse, each with a page-based view (words appearing in the page itself) and a link-based view (words appearing in hyperlinks pointing to it).",4.1. Text Classification Experiments,[0],[0]
"Among all homepages, course homepages (22%) correspond to positive examples while all others are negative examples.
",4.1. Text Classification Experiments,[0],[0]
Advertisement data:,4.1. Text Classification Experiments,[0],[0]
This data set contains advertising images in web pages3.,4.1. Text Classification Experiments,[0],[0]
"Each image is described from multiple views, such as image properties, image caption, words occurring in the image source’s url, words occurring in the affiliated web page’s url and words occurring in the image anchor’s url.",4.1. Text Classification Experiments,[0],[0]
"By using the words of different areas, we create data sets named ads12, ads13 and ads23.
",4.1. Text Classification Experiments,[0],[0]
Newsgroup data: This data set is related to 16 newsgroups postings from the Mini-Newsgroup data4.,4.1. Text Classification Experiments,[0],[0]
Each group consists of 100 postings randomly drawn from the 1000 postings in the original 20-Newsgroup data.,4.1. Text Classification Experiments,[0],[0]
"The 16 chosen newsgropus are divided into four groups, and we create NG1 and NG2 data sets based on a partition strategy (Zhang & Zhou, 2011).
",4.1. Text Classification Experiments,[0],[0]
Each utilized data set contains two classes.,4.1. Text Classification Experiments,[0],[0]
Table 1 summarizes the statistics of these data sets.,4.1. Text Classification Experiments,[0],[0]
"For each data set, 25% of the data are retained as test examples while the rest are used as training examples, i.e., including both labeled and unlabeled examples.",4.1. Text Classification Experiments,[0],[0]
"Three experiments are conducted on these six data sets with different number of labeled in-
2Data available at http://www.cs.cmu.edu/afs/cs/project/theo20/www/data/
3Data available at https://archive.ics.uci.edu/ml/datasets/Internet +Advertisements
4Data available at http://www.cs.cmu.edu/afs/cs/project/theo11/www/ naive-bayes/mini newsgroup.tar.gz.
stances.",4.1. Text Classification Experiments,[0],[0]
"To simulate real-world cases where labeled samples are rarely available, only a small number of instances are randomly selected as labeled data.",4.1. Text Classification Experiments,[0],[0]
"Among the training samples, we choose 2k positive and 3 · 2k negative, k = 1, 2, 3, labeled instances for Course, 2k positive and 6 · 2k negative labeled examples for Advertisement, and 2 · 2k+1 positive and 2 · 2k negative labeled examples for Newsgroup, based on their different data size.",4.1. Text Classification Experiments,[0],[0]
"On each data set, three series of experiments are implemented (i.e., for k = 1, 2, 3), and each experiment series contains 100 trials, with independently sampled labeled samples.
",4.1. Text Classification Experiments,[0],[0]
"Experiment setting: The performance of SPaCo is compared with six current semi-supervised learning algorithms, including: SelfTrain (Scudder, 1965), the most conventional SSL method, the co-training method (Blum & Mitchell, 1998), the most conventional co-training method, CoTrade (Zhang & Zhou, 2011), one state-of-theart co-training method, CoEM (Nigam & Ghani, 2000), CoMR (Sindhwani & Rosenberg, 2008) and RANC (Ye et al., 2015), representing the state-of-the-art for solving two-view co-learning problem.",4.1. Text Classification Experiments,[0],[0]
"SVM is employed as base classifier in text classification task for all the iterative training methods.
",4.1. Text Classification Experiments,[0],[0]
"For SelfTrain, two classifiers expand their training pool by selecting the “most confident” samples they thought by themselves in each training round.",4.1. Text Classification Experiments,[0],[0]
"The standard co-
training and Cotrade select the “most confident” samples justified by the other view.",4.1. Text Classification Experiments,[0],[0]
"To avoid introducing too much noise, each classifier of SelfTrain and standard co-training only selects 1p(ositive) 3n(egative) for the course data, 1p 6n for the ads data, and 2p 2n for the newsgroup data.",4.1. Text Classification Experiments,[0],[0]
These three algorithms terminate when no more examples are available for training.,4.1. Text Classification Experiments,[0],[0]
"Instead of augmenting training pool step by step, CoEM estimates class probability in every training round and employs these pseudo labels to reestimate class probability after each iteration.
",4.1. Text Classification Experiments,[0],[0]
"For CoMR, each data set adpots an unified representation by merging the two views, and the regularization parameters γ1, γ2 varied on a gird of values (10(−6), 10(−4), 10(−2), 1, 10, 100) where the results from optimal configuration are reported.",4.1. Text Classification Experiments,[0],[0]
"RANC embeds the rank constraints into the optimized function of multi-view learning object (Ye et al., 2015) and proposes two different ways to solve the problem.",4.1. Text Classification Experiments,[0],[0]
"The ADMM method (Boyd et al., 2011) is adopted in this paper to get the solution.
",4.1. Text Classification Experiments,[0],[0]
"For our SPaCo algorithm, instead of tuning λ directly, we increase the number of nonzero element of v(j) in each training round.",4.1. Text Classification Experiments,[0],[0]
"Besides, to judge unlabeled instances based on two views, we easily set γ as 1 throughout all our experiments.",4.1. Text Classification Experiments,[0],[0]
"Its setting actually is not sensitive to the final performance of our algorithm.
",4.1. Text Classification Experiments,[0],[0]
"Experimental results: The average accuracy over all 100
trails obtained by each competing method on each data set is shown in Table 2.",4.1. Text Classification Experiments,[0],[0]
"From the table, we can easily observe that the proposed SPaCo method can attain the best (13 out of 18) or the second best (3 out of 18) performance among all competing methods.",4.1. Text Classification Experiments,[0],[0]
"In average, SPaCo acquires an evident better performance than other competing methods under different sizes of initialized labeled examples.",4.1. Text Classification Experiments,[0],[0]
This verifies the superiority of the proposed method on these cotraining problems.,4.1. Text Classification Experiments,[0],[0]
The person re,4.2. Person Re-identification Experiments,[0],[0]
-identification (re-ID),4.2. Person Re-identification Experiments,[0],[0]
"task is usually viewed as an image retrieval problem, aiming to match pedestrians from the gallery (Zheng et al., 2016).",4.2. Person Re-identification Experiments,[0],[0]
"Specifically, given a person-of-interest (query), a person re-ID method aims to determine whether the person has been observed by cameras.
",4.2. Person Re-identification Experiments,[0],[0]
Dataset:,4.2. Person Re-identification Experiments,[0],[0]
We employ the Market-1501 set in our experiment.,4.2. Person Re-identification Experiments,[0],[0]
"This data set contains 32,668 detected person bounding boxes of 1,501 identities (Zheng et al., 2015).",4.2. Person Re-identification Experiments,[0],[0]
"Images of each identity is captured by six cameras at most, and two cameras at least.",4.2. Person Re-identification Experiments,[0],[0]
"According to the data set setting, training set contains 12936 cropped images of 751 identities and testing set contains 19,732 cropped images of 750 identities.",4.2. Person Re-identification Experiments,[0],[0]
"They are directly detected by Deformable Part Model (DPM) instead of hand-drawn bboxs, which is closer to the realistic setting.",4.2. Person Re-identification Experiments,[0],[0]
Each identity may have multiple images under each camera.,4.2. Person Re-identification Experiments,[0],[0]
"We use the provided fixed training and test set, under both the single-query and multi-query evaluation settings.
",4.2. Person Re-identification Experiments,[0],[0]
"In the experiments, 20% instances of training data with their labels are chose with labels, the rest of data are treated as unlabeled instances.",4.2. Person Re-identification Experiments,[0],[0]
"Instead of directly selecting labeled samples from the whole data, we randomly sample 20% labeled samples for each class.",4.2. Person Re-identification Experiments,[0],[0]
"We implemented the experiments two times under two randomly sampled training data, and their average is reported as the final result.
",4.2. Person Re-identification Experiments,[0],[0]
"Experiment setting: Like the state-of-art Person re-ID model proposed by (Zheng et al., 2016), three different deep learning networks, including Alexnet, Googlenet, and Vggnet, respectively, are used to generate multi-view features for Market-1501 data set.",4.2. Person Re-identification Experiments,[0],[0]
"The employed model is a new siamese network that simultaneously computes identification loss and verification loss (Zheng et al., 2016).",4.2. Person Re-identification Experiments,[0],[0]
"We treat this new loss as the optimized loss in our model, and thus the re-ID task can be well handled using the SPaCo algorithm.",4.2. Person Re-identification Experiments,[0],[0]
"Two combinations, Alexnet with Googlenet and Googlenet with Vggnet, are adopted in our experiments.
",4.2. Person Re-identification Experiments,[0],[0]
"Over all experiments, parameters of each model are set following the training setting as (Zheng et al., 2016).
",4.2. Person Re-identification Experiments,[0],[0]
"Via using co-training and self-train algorithms as compar-
ison methods, the effectiveness of SPaCo method is validated.",4.2. Person Re-identification Experiments,[0],[0]
The training process on re-ID task is the same as the process on text classification task.,4.2. Person Re-identification Experiments,[0],[0]
Cotrade is not adopted to re-ID task since it can only handle two class problems.,4.2. Person Re-identification Experiments,[0],[0]
"CoMR and RANC are also not included since they are not trained in an iterative way, and hard to be applied to the re-ID task.",4.2. Person Re-identification Experiments,[0],[0]
"For the SPaCo algorithm, in every iteration, the number of selected unlabeled instances is ranged from 1000 to 2000.",4.2. Person Re-identification Experiments,[0],[0]
"The lower bound is to guarantee sufficient instances for each class and the higher bound is to avoid introducting too many noisy samples.
",4.2. Person Re-identification Experiments,[0],[0]
"Experimental results: From Table 3, it is seen that rank-1 accuracies of all methods are improved since more samples are used for training.",4.2. Person Re-identification Experiments,[0],[0]
"When Alexnet and Googlenet networks are adopted, SPaCo achieves the highest rank1 accuracy not only on final result, but also on two view results, respectively.",4.2. Person Re-identification Experiments,[0],[0]
"Specifically, our model achieves 66.57% rank-1 accuracy, evidently better than other competing methods.",4.2. Person Re-identification Experiments,[0],[0]
"For the Vggnet and Googlenet view experiment, our SPaCo algorithm achieves a 68.26% rank-1 accuracy, which is also the best among all competing methods.",4.2. Person Re-identification Experiments,[0],[0]
We have proposed an improved co-training algorithm which trains the classifiers under two views of data in a serial way and alternatively updates the pseudo labels of unlabeled data to improve the performance of classifiers in each training round.,5. Conclusion and Future Work,[0],[0]
"We represent the algorithm with an self-paced co-training (SPaCo) model, and the optimized strategy for solving this model is consistent with the training process of an improved co-training algorithm.",5. Conclusion and Future Work,[0],[0]
"Experimental results verify the advantage of SPaCo beyond current co-training methods.
",5. Conclusion and Future Work,[0],[0]
Research directions in our future work include designing more self-paced regularizers for SPaCo considering their different capacities on noise data.,5. Conclusion and Future Work,[0],[0]
"Besides, since there are many multi-view other than two view data sets in practice, we need to develop a more general SPaCo regimes to deal with multi-view tasks.",5. Conclusion and Future Work,[0],[0]
"This research was supported by the China NSFC project under Grant No. 61373114, 61661166011, 11690011, 61603292, Macau Science and Technology Development Funds under Grant No. 003/2016/AFJ from the Macau Special Administrative Region of the People’s Republic of China, and the National Grand Fundamental Research 973 Program of China under Grant No. 2013CB329404.",Acknowledgements,[0],[0]
Co-training is a well-known semi-supervised learning approach which trains classifiers on two different views and exchanges labels of unlabeled instances in an iterative way.,abstractText,[0],[0]
"During cotraining process, labels of unlabeled instances in the training pool are very likely to be false especially in the initial training rounds, while the standard co-training algorithm utilizes a “draw without replacement” manner and does not remove these false labeled instances from training.",abstractText,[0],[0]
This issue not only tends to degenerate its performance but also hampers its fundamental theory.,abstractText,[0],[0]
"Besides, there is no optimization model to explain what objective a co-training process optimizes.",abstractText,[0],[0]
"To these issues, in this study we design a new co-training algorithm named self-paced cotraining (SPaCo) with a “draw with replacement” learning mode.",abstractText,[0],[0]
"The rationality of SPaCo can be proved under theoretical assumptions utilized in traditional co-training research, and furthermore, the algorithm exactly complies with the alternative optimization process for an optimization model of self-paced curriculum learning, which can be finely explained in robust learning manner.",abstractText,[0],[0]
Experimental results substantiate the superiority of the proposed method as compared with current state-of-the-art co-training methods.,abstractText,[0],[0]
Self-Paced Co-training,title,[0],[0]
"With the proliferation of microblogging and its wide influence on how information is shared and digested, the studying of microblog sites has gained interest in recent NLP research.",1 Introduction,[0],[0]
Several approaches have been proposed to enable a deep understanding of information on Twitter.,1 Introduction,[0],[0]
"An emerging approach is to use semantic annotation techniques, for instance by mapping Twitter information snippets to canonical entities in a knowledge base or to Wikipedia (Meij et al., 2012; Guo et al., 2013), or by revisiting NLP tasks in the Twitter domain (Owoputi et al., 2013; Ritter et al., 2011).",1 Introduction,[0],[0]
Much of the existing work focuses on annotating a single Twitter message (tweet).,1 Introduction,[0],[0]
"However, information in Twitter is rarely digested in isolation, but rather in a collective manner, with the adoption of special mechanisms such as hashtags.",1 Introduction,[0],[0]
"When put together, the unprecedentedly massive adoption of
a hashtag within a short time period can lead to bursts and often reflect trending social attention.",1 Introduction,[0],[0]
"Understanding the meaning of trending hashtags offers a valuable opportunity for various applications and studies, such as viral marketing, social behavior analysis, recommendation, etc.",1 Introduction,[0],[0]
"Unfortunately, the task of hashtag annotation has been largely unexplored so far.
",1 Introduction,[0],[0]
"In this paper, we study the problem of annotating trending hashtags on Twitter by entities derived from Wikipedia.",1 Introduction,[0],[0]
"Instead of establishing a static semantic connection between hashtags and entities, we are interested in dynamically linking the hashtags to entities that are closest to the underlying topics during burst time periods of the hashtags.",1 Introduction,[0],[0]
"For instance, while ‘#sochi’ refers to a city in Russia, during February 2014, the hashtag was used to report the 2014 Winter Olympics (cf",1 Introduction,[0],[0]
. Figure 1).,1 Introduction,[0],[0]
"Hence, it should be linked more to Wikipedia pages related to the event than to the location.
",1 Introduction,[0],[0]
"Compared to traditional domains of text (e.g., news articles), annotating hashtags poses additional challenges.",1 Introduction,[0],[0]
"Hashtags’ surface forms are
ar X
iv :1
70 1.
03 93
9v 1
[ cs
.I R
] 1
4 Ja
n 20
17
very ad-hoc, as they are chosen not in favor of the text quality, but by the dynamics in attention of the large crowd.",1 Introduction,[0],[0]
"In addition, the evolution of the semantics of hashtags (e.g., in the case of ‘#sochi’) makes them more ambiguous.",1 Introduction,[0],[0]
"Furthermore, a hashtag can encode multiple topics at once.",1 Introduction,[0],[0]
"For example, in March 2014, ‘#oscar’ refers to the 86th Academy Awards, but at the same time also to the Trial of Oscar Pistorius.",1 Introduction,[0],[0]
"Sometimes, it is difficult even for humans to understand a trending hashtag without knowledge about what was happening with the related entities in the real world.
",1 Introduction,[0],[0]
"In this work, we propose a novel solution to these challenges by leveraging temporal knowledge about entity dynamics derived from Wikipedia.",1 Introduction,[0],[0]
"We hypothesize that a trending hashtag is associated with an increase in public attention to certain entities, and this can also be observed on Wikipedia.",1 Introduction,[0],[0]
"As in Figure 1, we can identify 2014 Winter Olympics as a prominent entity for ‘#sochi’ during February 2014, by observing the change of user attention to the entity, for instance via the page view statistics of Wikipedia articles.",1 Introduction,[0],[0]
We exploit both Wikipedia edits and page views for annotation.,1 Introduction,[0],[0]
"We also propose a novel learning method, inspired by the information spreading nature of social media such as Twitter, to suggest the optimal annotations without the need for human labeling.",1 Introduction,[0],[0]
"In summary:
• We are the first to combine the Wikipedia edit history and page view statistics to overcome the temporal ambiguity of Twitter hashtags.
",1 Introduction,[0],[0]
• We propose a novel and efficient learning algorithm based on influence maximization to automatically annotate hashtags.,1 Introduction,[0],[0]
"The idea is generalizable to other social media sites that have a similar information spreading nature.
",1 Introduction,[0],[0]
• We conduct thorough experiments on a realworld dataset and show that our system can outperform competitive baselines by 17-28%.,1 Introduction,[0],[0]
"Entity Linking in Microblogs The task of semantic annotation in microblogs has been recently tackled by different methods, which can be divided into two classes, i.e., content-based and graphbased methods.",2 Related Work,[0],[0]
"While the content-based methods (Meij et al., 2012; Guo et al., 2013; Fang and Chang, 2014) consider tweets independently, the
graph-based methods (Cassidy et al., 2012; Liu et al., 2013) use all related tweets (e.g., posted by a user) together.",2 Related Work,[0],[0]
"However, most of them focus on entity mentions in tweets.",2 Related Work,[0],[0]
"In contrast, we take into account hashtags which reflect the topics discussed in tweets, and leverage external resources from Wikipedia (in particular, the edit history and page view logs) for semantic annotation.
",2 Related Work,[0],[0]
"Analysis of Twitter Hashtags In an attempt to understand the user interest dynamics on Twitter, a rich body of work analyzes the temporal patterns of popular hashtags (Lehmann et al., 2012; Naaman et al., 2011; Tsur and Rappoport, 2012).",2 Related Work,[0],[0]
"Few works have paid attention to the semantics of hashtags, i.e., to the underlying topics conveyed in the corresponding tweets.",2 Related Work,[0],[0]
"Recently, Bansal et al. (2015) attempt to segment a hashtag and link each of its tokens to a Wikipedia page.",2 Related Work,[0],[0]
"However, the authors only aim to retrieve entities directly mentioned within a hashtag, which are very few in practice.",2 Related Work,[0],[0]
The external information derived from the tweets is largely ignored.,2 Related Work,[0],[0]
"In contrast, we exploit both context information from the microblog and Wikipedia resources.
",2 Related Work,[0],[0]
Event Mining Using Wikipedia,2 Related Work,[0],[0]
"Recently some works exploit Wikipedia for detecting and analyzing events on Twitter (Osborne et al., 2012; Tolomei et al., 2013; Tran et al., 2014).",2 Related Work,[0],[0]
"However, most of the existing studies focus on the statistical signals of Wikipedia (such as the edit or page view volumes).",2 Related Work,[0],[0]
We are the first to combine the content of the Wikipedia edit history and the magnitude of page views to handle trending topics on Twitter.,2 Related Work,[0],[0]
"Preliminaries We refer to an entity (denoted by e) as any object described by a Wikipedia article (ignoring disambiguation, lists, and redirect pages).",3 Framework,[0],[0]
The number of times an entity’s article has been requested is called the entity view count.,3 Framework,[0],[0]
The text content of the article is denoted by C(e).,3 Framework,[0],[0]
"In this work, we choose to study hashtags at the daily level, i.e., from the timestamps of tweets we only consider their creation day.",3 Framework,[0],[0]
A hashtag is called trending at a time point (a day) if the number of tweets where it appears is significantly higher than that on other days.,3 Framework,[0],[0]
There are many ways to detect such trendings.,3 Framework,[0],[0]
"(Lappas et al., 2009; Lehmann et al., 2012).",3 Framework,[0],[0]
"Each trending hashtag has one or multiple burst time periods, surrounding the trend-
ing day, where the users’ interest in the underlying topic remains stronger than in other periods.",3 Framework,[0],[0]
"We denote with T (h) (or T for short) one hashtag burst time period, and withDT (h) the set of tweets containing the hashtag h created during T .
",3 Framework,[0],[0]
Task Definition,3 Framework,[0],[0]
"Given a trending hashtag h and the burst time period T of h, identify the top-k most prominent entities to describe h during T .
",3 Framework,[0],[0]
"It is worth noting that not all trending hashtags are mapable to Wikipedia entities, as the coverage of topics in Wikipedia is much lower than on Twitter.",3 Framework,[0],[0]
"This is also the limitation of systems relying on Wikipedia such as entity disambiguation, which can only disambiguate popular entities and not the ones in the long tail.",3 Framework,[0],[0]
"In this study, we focus on the precision and the popular trending hashtags, and leave the improvement of recall to future work.
",3 Framework,[0],[0]
Overview We approach the task in three steps.,3 Framework,[0],[0]
The first step is to identify all entity candidates by checking surface forms of the constituent tweets of the hashtag.,3 Framework,[0],[0]
"In the second step, we compute different similarities between each candidate and the hashtag, based on different types of contexts, which are derived from either side (Wikipedia or Twitter).",3 Framework,[0],[0]
"Finally, we learn a unified ranking function for each (hashtag, entity) pair and choose the top-k entities with the highest scores.",3 Framework,[0],[0]
The ranking function is learned through an unsupervised model and needs no human-defined labels.,3 Framework,[0],[0]
The most obvious resource to identify candidate entities for a hashtag is via its tweets.,3.1 Entity Linking,[0],[0]
"We follow common approaches that use a lexicon to match each textual phrase in a tweet to a potential entity set (Shen et al., 2013; Fang and Chang, 2014).",3.1 Entity Linking,[0],[0]
"Our lexicon is constructed from Wikipedia page titles, hyperlink anchors, redirects, and disambiguation pages, which are mapped to the corresponding entities.",3.1 Entity Linking,[0],[0]
"As for the tweet phrases, we extract all n-grams (n ≤ 5) from the input tweets within T .",3.1 Entity Linking,[0],[0]
"We apply the longest-match heuristic (Meij et al., 2012): We start with the longest n-grams and stop as soon as the entity set is found, otherwise we continue with the smaller constituent n-grams.
Candidate Set Expansion While the lexiconbased linking works well for single tweets, applying it on the hashtag level has subtle implications.",3.1 Entity Linking,[0],[0]
"Processing a huge amount of text, especially during a hashtag burst time period, incurs expen-
sive computational costs.",3.1 Entity Linking,[0],[0]
"Therefore, to guarantee a good recall in this step while still maintaining feasible computation, we apply entity linking only on a random sample of the complete tweet set.",3.1 Entity Linking,[0],[0]
"Then, for each candidate entity e, we include all entities whose Wikipedia article is linked with the article of e by an outgoing or incoming link.",3.1 Entity Linking,[0],[0]
"To rank the entity by prominence, we measure the similarity between each candidate entity and the hashtag.",3.2 Measuring Entity–Hashtag Similarities,[0],[0]
"We study three types of similarities:
Mention Similarity This measure relies on the explicit mentions of entities in tweets.",3.2 Measuring Entity–Hashtag Similarities,[0],[0]
It assumes that entities directly linked from more prominent anchors are more relevant to the hashtag.,3.2 Measuring Entity–Hashtag Similarities,[0],[0]
"It is estimated using both statistics from Wikipedia and tweet phrases, and turns out to be surprisingly effective in practice (Fang and Chang, 2014).
",3.2 Measuring Entity–Hashtag Similarities,[0],[0]
Context Similarity For entities that are not directly linked to mentions (the mention similarity is zero),3.2 Measuring Entity–Hashtag Similarities,[0],[0]
we exploit external resources instead.,3.2 Measuring Entity–Hashtag Similarities,[0],[0]
"Their prominence is perceived by users via external sources, such as web pages linked from tweets, or entity home pages or Wikipedia pages.",3.2 Measuring Entity–Hashtag Similarities,[0],[0]
"By exploiting the content of entities from these external sources, we can complement the explicit similarity metrics based on mentions.
",3.2 Measuring Entity–Hashtag Similarities,[0],[0]
Temporal Similarity The two measures above rely on the textual representation and are degraded by the linguistic difference between the two platforms.,3.2 Measuring Entity–Hashtag Similarities,[0],[0]
"To overcome this drawback, we incorporate the temporal dynamics of hashtags and entities, which serve as a proxy to the change of user interests towards the underlying topics (Ciglan and Nørvåg, 2010).",3.2 Measuring Entity–Hashtag Similarities,[0],[0]
We employ the correlation between the times series of hashtag adoption and the entity view as the third similarity measure.,3.2 Measuring Entity–Hashtag Similarities,[0],[0]
"While each similarity measure captures one evidence of the entity prominence, we need to unify all scores to obtain a global ranking function.",3.3 Ranking Entity Prominence,[0],[0]
"In this work, we propose to combine the individual similarities using a linear function:
f(e, h) = αfm(e, h)+βfc(e, h)+γft(e, h) (1)
where α, β, γ are model weights and fm, fc, ft are the similarity measures based on mentions, context, and temporal information, respectively, be-
tween the entity e and the hashtag h.",3.3 Ranking Entity Prominence,[0],[0]
We further constrain that α + β + γ,3.3 Ranking Entity Prominence,[0],[0]
"= 1,",3.3 Ranking Entity Prominence,[0],[0]
"so that the ranking scores of entities are normalized between 0 and 1, and that our learning algorithm is more tractable.",3.3 Ranking Entity Prominence,[0],[0]
"The algorithm, which automatically learns the parameters without the need of human-labeled data, is explained in detail in Section 5.",3.3 Ranking Entity Prominence,[0],[0]
We now discuss in detail how the similarity measures between hashtags and entities are computed.,4 Similarity Measures,[0],[0]
The similarity of an entity with one individual mention in a tweet can be interpreted as the probabilistic prior in mapping the mention to the entity via the lexicon.,4.1 Link-based Mention Similarity,[0],[0]
"One common way to estimate the entity prior exploits the anchor statistics from Wikipedia links, and has been proven to work well in different domains of text.",4.1 Link-based Mention Similarity,[0],[0]
"We follow this approach and define LP (e|m) = |lm(e)|∑
m′ |lm′ (e)| as the
link prior of the entity e given a mention m, where lm(e) is the set of links with anchor m that point to e. The mention similarity fm is measured as the aggregation of link priors of the entity e over all mentions in all tweets with the hashtag h:
fm(e, h) = ∑ m (LP (e|m) · q(m))",4.1 Link-based Mention Similarity,[0],[0]
"(2)
where q(m) is the frequency of the mentionm over all mentions of e in all tweets of h.",4.1 Link-based Mention Similarity,[0],[0]
"To compute fc, we first construct the contexts for hashtags and entities.",4.1.1 Context Similarity,[0],[0]
The context of a hashtag is built by extracting all words from its tweets.,4.1.1 Context Similarity,[0],[0]
"We tokenize and parse the tweets’ part-of-speech tags (Owoputi et al., 2013), and remove words of Twitter-specific tags (e.g., @-mentions, URLs, emoticons, etc.).",4.1.1 Context Similarity,[0],[0]
"Hashtags are normalized using the word breaking method by Wang et al. (2011).
",4.1.1 Context Similarity,[0],[0]
The textual context of an entity is extracted from its Wikipedia article.,4.1.1 Context Similarity,[0],[0]
"One subtle aspect is that the articles are not created at once, but are incrementally updated over time in accordance with changing information about entities.",4.1.1 Context Similarity,[0],[0]
Texts added in the same time period of a trending hashtag contribute more to the context similarity between the entity and the hashtag.,4.1.1 Context Similarity,[0],[0]
"Based on this observation, we use the Wikipedia revision history – an archive of all revisions of Wikipedia articles – to calculate the
entity context.",4.1.1 Context Similarity,[0],[0]
"We collect the revisions of articles during the time period T , plus one day to acknowledge possible time lags.",4.1.1 Context Similarity,[0],[0]
"We compute the difference between two consecutive revisions, and extract only the added text snippets.",4.1.1 Context Similarity,[0],[0]
"These snippets are accumulated to form the temporal context of an entity e during T , denoted by CT (e).",4.1.1 Context Similarity,[0],[0]
"The distribution of a word w for the entity e is estimated by a mixture between the probability of generating w from the temporal context and from the general context C(e) of the entity:
P̂ (w|e) = λP̂ (w|MCT (e))+(1−λ)P̂ (w|MC(e))
where MCT (e) and MC(e) are the language models of e based on CT (e) and C(e), respectively.",4.1.1 Context Similarity,[0],[0]
"The probability P̂ (w|MC(e)) can be regarded as corresponding to the background model, while P̂ (w|MCT (e)) corresponds to the foreground model in traditional language modeling settings.",4.1.1 Context Similarity,[0],[0]
Here we use a simple maximum likelihood estimation to estimate these probabilities: P̂ (w|MC(e)),4.1.1 Context Similarity,[0],[0]
"= tfw,c |C(e)| and P̂ (w|MCT (e)) = tfw,cT |CT",4.1.1 Context Similarity,[0],[0]
"(e)| , where tfw,c and tfw,cT are the term frequencies of w in the two text sources of C(e) and CT (e), respectively, and |C(e)| and |CT (e)| are the lengths of the two texts, respectively.",4.1.1 Context Similarity,[0],[0]
"We use the same estimation for tweets: P̂ (w|h) = tfw,D(h) |D(h)| , where D(h) is the concatenated text of all tweets of h in T .",4.1.1 Context Similarity,[0],[0]
"We use and normalize the Kullback-Leibler divergence to compare the distributions over all words appearing both in the Wikipedia contexts and the tweets:
KL(e ‖ h) = ∑ w P̂ (w|e) · P̂ (w|e) P̂ (w|h)
fc(e, h) = e −KL(e ‖ h) (3)",4.1.1 Context Similarity,[0],[0]
"The third similarity, ft, is computed using temporal signals from both sources – Twitter and Wikipedia.",4.1.2 Temporal Similarity,[0],[0]
"For the hashtags, we build the time series based on the volume of tweets adopting the hashtag h on each day in T : TSh =",4.1.2 Temporal Similarity,[0],[0]
"[n1, n2, . . .",4.1.2 Temporal Similarity,[0],[0]
", n|T |].",4.1.2 Temporal Similarity,[0],[0]
"Similarly for the entities, we build the time series of view counts for the entity e in T : TSe =",4.1.2 Temporal Similarity,[0],[0]
"[v1, v2, . .",4.1.2 Temporal Similarity,[0],[0]
.,4.1.2 Temporal Similarity,[0],[0]
", v|T |].",4.1.2 Temporal Similarity,[0],[0]
A time series similarity metric is then used to compute ft.,4.1.2 Temporal Similarity,[0],[0]
"Several metrics can be used, however most of them suffer from the time lag and scaling discrepancy, or incur expensive computational costs (Radinsky et al., 2011).",4.1.2 Temporal Similarity,[0],[0]
"In this work, we employ a simple yet
effective metric that is agnostic to the scaling and time lag of time series (Yang and Leskovec, 2011).",4.1.2 Temporal Similarity,[0],[0]
"It measures the distance between two time series by finding optimal shifting and scaling parameters to match the shape of two time series:
ft(e, h) =",4.1.2 Temporal Similarity,[0],[0]
"min q,δ ‖TSh",4.1.2 Temporal Similarity,[0],[0]
"− δdq(TSe)‖ ‖TSh‖
(4)
where dq(TSe) is the time series derived from TSe by shifting q time units, and ‖·‖ is the L2 norm.",4.1.2 Temporal Similarity,[0],[0]
"It has been proven that Equation 4 has a closed-form solution for δ given fixed q, thus we can design an efficient gradient-based optimization algorithm to compute ft (Yang and Leskovec, 2011).",4.1.2 Temporal Similarity,[0],[0]
"To unify the individual similarities into one global metric (Equation 1), we need a guiding premise of what manifest the prominence of an entity to a hashtag.",5.1 Ranking Framework,[0],[0]
"Such a premise can be instructed through manual assessment (Meij et al., 2012; Guo et al., 2013), but it requires human-labeled data and is biased from evaluator to evaluator.",5.1 Ranking Framework,[0],[0]
"Other heuristics assume that entities close to the main topic of a text are also coherent to each other (Ratinov et al., 2011; Liu et al., 2013).",5.1 Ranking Framework,[0],[0]
"Based on this, state-ofthe-art methods in traditional disambiguation estimate entity prominence by optimizing the overall coherence of the entities’ semantic relatedness.",5.1 Ranking Framework,[0],[0]
"However, this coherence does not hold for topics in hashtags: Entities reported in a big topic such as the Olympics vary greatly with different subevents.",5.1 Ranking Framework,[0],[0]
"They are not always coherent to each other,
as they are largely dependent on the users’ diverse attention to each sub-event.",5.1 Ranking Framework,[0],[0]
"This heterogeneity of hashtags calls for a different premise, abandoning the idea of coherence.
",5.1 Ranking Framework,[0],[0]
Influence Maximization (IM) We propose a new approach to find entities for a hashtag.,5.1 Ranking Framework,[0],[0]
"We use an observed behavioral pattern in creating Wikipedia pages for guiding our approach to entity prominence: Wikipedia articles of entities that are prominent for a topic are quickly created or updated,1 and subsequently enriched with links to related entities.",5.1 Ranking Framework,[0],[0]
"This linking process signals the dynamics of editor attention and exposure to the event (Keegan et al., 2011).",5.1 Ranking Framework,[0],[0]
"We argue that the process does not, or to a much lesser degree, happen to more marginal entities or to very general entities.",5.1 Ranking Framework,[0],[0]
"As illustrated in Figure 2, the entities closer to the 2014 Olympics get more updates in the revisions of their Wikipedia articles, with subsequent links pointing to articles of more distant entities.",5.1 Ranking Framework,[0],[0]
"The direction of the links influences the shifting attention of users (Keegan et al., 2011) as they follow the structure of articles in Wikipedia.
",5.1 Ranking Framework,[0],[0]
"We assume that, similar to Wikipedia, the entity prominence also influences how users are exposed and spread the hashtag on Twitter.",5.1 Ranking Framework,[0],[0]
"In particular, the initial spreading of a trending hashtag involves more entities in the focus of the topic.",5.1 Ranking Framework,[0],[0]
"Subsequent exposure and spreading of the hashtag then include other related entities (e.g., discussing background or providing context), driven by interests in different parts of the topic.",5.1 Ranking Framework,[0],[0]
"Based on this assumption,
1Osborne et al. (2012) suggested a time lag of 3 hours.
",5.1 Ranking Framework,[0],[0]
we propose to gauge the entity prominence as its potential in maximizing the information spreading within all entities present in the tweets of the hashtag.,5.1 Ranking Framework,[0],[0]
"In other words, the problem of ranking the most prominent entities becomes identifying the set of entities that lead to the largest number of entities in the candidate set.",5.1 Ranking Framework,[0],[0]
"This problem is known in social network research as influence maximization (Kempe et al., 2003).
",5.1 Ranking Framework,[0],[0]
Iterative Influence-Prominence Learning (IPL),5.1 Ranking Framework,[0],[0]
"IM itself is an NP-hard problem (Kempe et al., 2003).",5.1 Ranking Framework,[0],[0]
"Therefore, we propose an approximation framework, which can jointly learn the influence scores of the entity and the entity prominence together.",5.1 Ranking Framework,[0],[0]
"The framework (called IPL) contains several iterations, each consisting of two steps:(1)",5.1 Ranking Framework,[0],[0]
Pick up a model and use it to compute the entity influence score.,5.1 Ranking Framework,[0],[0]
"(2) Based on the influence scores, update the entity prominence.",5.1 Ranking Framework,[0],[0]
In the sequel we detail our learning framework.,5.1 Ranking Framework,[0],[0]
"Influence Graph To compute the entity influence scores, we first construct the entity influence graph as follows.",5.2 Entity Graph,[0],[0]
"For each hashtag h, we construct a directed graph Gh = (Eh, Vh), where the nodes Eh ⊆ E consist of all candidate entities (cf. Section 3.1), and",5.2 Entity Graph,[0],[0]
"an edge (ei, ej) ∈ Vh indicates that there is a link from ej’s Wikipedia article to ei’s.",5.2 Entity Graph,[0],[0]
"Note that edges of the influence graph are inversed in direction to links in Wikipedia, as such a link gives an “influence endorsement” from the destination entity to the source entity.
",5.2 Entity Graph,[0],[0]
"Entity Relatedness In this work, we assume that an entity endorses more of its influence score to highly related entities than to lower related ones.",5.2 Entity Graph,[0],[0]
"We use a popular entity relatedness measure suggested by Milne and Witten (2008):
MW (e1, e2)",5.2 Entity Graph,[0],[0]
"= 1− log(max(|I1|,|I2|)−log(|I1∩I2|)))log(|E|)−log(min(|I1|,|I2|))
where I1 and I2 are sets of entities having links to e1 and e2, respectively, and E is the set of all entities in Wikipedia.",5.2 Entity Graph,[0],[0]
"The influence transition from ei to ej is defined as the normalized value:
bi,j = MW (ei, ej)∑
(ei,ek)∈V MW (ei, ek) (5)
",5.2 Entity Graph,[0],[0]
Influence Score,5.2 Entity Graph,[0],[0]
Let rh be the influence score vector of entities in Gh.,5.2 Entity Graph,[0],[0]
"We can estimate rh efficiently using random walk models, similarly to the
Algorithm 1: Entity Influence-Prominence Learning Input : h, T,DT (h),B, k, learning rate µ, threshold Output: ω, top-k most prominent entities.
",5.2 Entity Graph,[0],[0]
Initialize: ω,5.2 Entity Graph,[0],[0]
":= ω(0) Calculate fm, fc, ft, fω := fω(0) using Eqs. 1, 2, 3, 4 while true do
f̂ω := normalize fω Set sh := f̂ω, calculate rh using Eq. 6",5.2 Entity Graph,[0],[0]
"Sort rh, get the top-k entities E(h, k) if ∑
e∈E(h,k) L(f(e, h), r(e, h))",5.2 Entity Graph,[0],[0]
"< then Stop
end ω",5.2 Entity Graph,[0],[0]
:= ω,5.2 Entity Graph,[0],[0]
"− µ ∑ e∈E(h,k)∇L(f(e, h), r(e, h))
end return ω,E(h, k)
baseline method suggested by Liu et al. (2014):
rh := τBrh +",5.2 Entity Graph,[0],[0]
"(1− τ)sh (6)
where B is the influence transition matrix, sh are the initial influence scores that are based on the entity prominence model (Step 1 of IPL), and τ is the damping factor.",5.2 Entity Graph,[0],[0]
Now we detail the IPL algorithm.,5.3 Learning Algorithm,[0],[0]
The objective is to learn the model ω,5.3 Learning Algorithm,[0],[0]
=,5.3 Learning Algorithm,[0],[0]
"(α, β, γ) of the global function (Equation 1).",5.3 Learning Algorithm,[0],[0]
"The general idea is that we find an optimal ω such that the average error with respect to the top influencing entities is minimized
ω = argmin ∑ E(h,k) L(f(e, h), r(e, h))
where r(e, h) is the influence score of e and h, E(h, k) is the set of top-k entities with highest r(e, h), and L is the squared error loss function, L(x, y) = (x−y) 2
2 .",5.3 Learning Algorithm,[0],[0]
The main steps are depicted in Algorithm 1.,5.3 Learning Algorithm,[0],[0]
"We start with an initial guess for ω, and compute the similarities for the candidate entities.",5.3 Learning Algorithm,[0],[0]
"Here fm, fc, ft, and fω represent the similarity score vectors.",5.3 Learning Algorithm,[0],[0]
We use matrix multiplication to calculate the similarities efficiently.,5.3 Learning Algorithm,[0],[0]
"In each iteration, we first normalize fω such that the entity scores sum up to 1.",5.3 Learning Algorithm,[0],[0]
A random walk is performed to calculate the influence score rh.,5.3 Learning Algorithm,[0],[0]
Then we update ω using a batch gradient descent method on the top-k influencer entities.,5.3 Learning Algorithm,[0],[0]
"To derive the gradient of the loss function L, we first remark that our random walk Equation 6 is similar to context-sensitive PageRank (Haveliwala, 2002).",5.3 Learning Algorithm,[0],[0]
"Using the linearity property (Fogaras et al., 2005),
we can express r(e, h) as the linear function of influence scores obtained by initializing with the individual similarities fm, fc, and ft instead of fω.",5.3 Learning Algorithm,[0],[0]
"The derivative thus can be written as:
∇L(f(e, h), r(e, h))",5.3 Learning Algorithm,[0],[0]
"= α(rm(e, h)− fm(e, h))+ β(rc(e, h)− fc(e, h))",5.3 Learning Algorithm,[0],[0]
"+ γ(rt(e, h)−",5.3 Learning Algorithm,[0],[0]
"ft(e, h))
where rm(e, h), rc(e, h), rt(e, h) are the components of the three vector solutions of Equation 6, each having sh replaced by fm, fc, ft respectively.
",5.3 Learning Algorithm,[0],[0]
"Since both B and f̂ω are normalized such that their column sums are equal to 1, Equation 6 is convergent (Haveliwala, 2002).",5.3 Learning Algorithm,[0],[0]
"Also, as discussed above, rh is a linear combination of factors that are independent of ω, hence L is a convex function, and the batch gradient descent is also guaranteed to converge.",5.3 Learning Algorithm,[0],[0]
"In practice, we can utilize several indexing techniques to significantly speed up the similarity and influence scores calculation.",5.3 Learning Algorithm,[0],[0]
"Dataset There is no standard benchmark for our problem, since available datasets on microblog annotation (such as the Microposts challenge (Basave et al., 2014))",6.1 Setup,[0],[0]
"do not have global statistics, so we cannot identify the trending hashtags.",6.1 Setup,[0],[0]
"Therefore, we created our own dataset.",6.1 Setup,[0],[0]
"We used the Twitter API to collect from the public stream a sample of 500, 551, 041 tweets from January to April 2014.",6.1 Setup,[0],[0]
"We removed hashtags that were adopted by less than 500 users, having no letters, or having characters repeated more than 4 times (e.g., ‘#oooommgg’).",6.1 Setup,[0],[0]
"We identified trending hashtags by computing the daily time series of hashtag tweet counts, and removing those of which the time series’ variance score is less than 900.",6.1 Setup,[0],[0]
"To identify the hashtag burst time period T , we compute the outlier fraction (Lehmann et al., 2012) for each hashtag h and
day t: pt(h) = |nt−nb|
max (nb,nmin) , where nt is the num-
ber of tweets containing h, nb is the median value of nt over all points in a 2-month time window centered on t, and nmin = 10 is the threshold to filter low activity hashtags.",6.1 Setup,[0],[0]
The hashtag is skipped if its highest outlier fraction score is less than 15.,6.1 Setup,[0],[0]
"Finally, we define the burst time period of a trending hashtag as the time window of size w, centered at day t0 with the highest pt0(h).
",6.1 Setup,[0],[0]
"For the Wikipedia datasets we process the dump from 3rd May 2014, so as to cover all events in the Twitter dataset.",6.1 Setup,[0],[0]
"We have developed Hedera (Tran and Nguyen, 2014), a scalable tool for processing the Wikipedia revision history dataset based on Map-Reduce paradigm.",6.1 Setup,[0],[0]
"In addition, we download the Wikipedia page view dataset that stores how many times a Wikipedia article was requested on an hourly level.",6.1 Setup,[0],[0]
"We process the dataset for the four months of our study and use Hedera to accumulate all view counts of redirects to the actual articles.
",6.1 Setup,[0],[0]
"Sampling From the trending hashtags, we sample 30 distinct hashtags for evaluation.",6.1 Setup,[0],[0]
"Since our study focuses on trending hashtags that are mapable to entities in Wikipedia, the sampling must cover a sufficient number of “popular” topics that are seen in Wikipedia, and at the same time cover rare topics in the long tail.",6.1 Setup,[0],[0]
"To do this, we apply several heuristics in the sampling.",6.1 Setup,[0],[0]
"First, we only consider hashtags where the lexicon-based linking (Section 3.1) results in at least 20 different entities.",6.1 Setup,[0],[0]
"Second, we randomly choose hashtags to cover different types of topics (long-running events, breaking events, endogenous hashtags).",6.1 Setup,[0],[0]
"Instead of inspecting all hashtags in our corpus, we follow Lehmann et al. (2012) and calculate the fraction of tweets published before, during and after the peak.",6.1 Setup,[0],[0]
The hashtags are then clustered in this 3-dimensional vector space.,6.1 Setup,[0],[0]
"Each cluster suggests a group of hashtags with a distinct semantics (Lehmann et al., 2012).",6.1 Setup,[0],[0]
"We then pick up hashtags randomly from each cluster, resulting in 200 hashtags in total.",6.1 Setup,[0],[0]
"From this rough sample, three inspectors carefully checked the tweets and chose 30 hashtags where the meanings and hashtag types were certain to the knowledge of the inspectors.
",6.1 Setup,[0],[0]
Parameter Settings,6.1 Setup,[0],[0]
"We initialize the similarity weights to 13 , the damping factor to τ = 0.85, and the weight for the language model to λ = 0.9.",6.1 Setup,[0],[0]
"The learning rate µ is empirically fixed to µ = 0.003.
",6.1 Setup,[0],[0]
Baseline We compare IPL with other entity annotation methods.,6.1 Setup,[0],[0]
"Our first group of baselines includes entity linking systems in domains of general text, Wikiminer (Milne and Witten, 2008), and short text, Tagme (Ferragina and Scaiella, 2012).",6.1 Setup,[0],[0]
"For each method, we use the default parameter settings, apply them for the individual tweets, and take the average of the annotation confidence scores as the prominence ranking function.",6.1 Setup,[0],[0]
The second group of baselines includes systems specifically designed for microblogs.,6.1 Setup,[0],[0]
"For the contentbased methods, we compare against Meij et al. (2012), which uses a supervised method to rank entities with respect to tweets.",6.1 Setup,[0],[0]
We train the model using the same training data as in the original paper.,6.1 Setup,[0],[0]
"For the graph-based method, we compare against KAURI (Shen et al., 2013), a method which uses user interest propagation to optimize the entity linking scores.",6.1 Setup,[0],[0]
"To tune the parameters, we pick up four hashtags from different clusters, randomly sample 50 tweets for each, and manually annotate the tweets.",6.1 Setup,[0],[0]
"For all baselines, we obtained the implementation from the authors.",6.1 Setup,[0],[0]
"The exception is Meij method, where we implemented ourselves, but we clarified with the authors via emails on several settings.",6.1 Setup,[0],[0]
"In addition, we also compare three variants of our method, using only local functions for entity ranking (referred to as M , C, and T for mention, context, and time, respectively).
",6.1 Setup,[0],[0]
"Evaluation In total, there are 6, 965 entityhashtag pairs returned by all systems.",6.1 Setup,[0],[0]
"We employ five volunteers to evaluate the pairs in the range from 0 to 2, where 0 means the entity is noisy or obviously unrelated, 2 means the entity is strongly tied to the topic of the hashtag, and 1 means that although the entity and hashtag might share some common contexts, they are not involved in a direct relationship (for instance, the entity is a too general concept such as Ice hockey, as in the case illustrated in Figure 2).",6.1 Setup,[0],[0]
"The annotators were advised to use search engines, the Twitter search box or Wikipedia archives whenever applicable to get more background on the stories.",6.1 Setup,[0],[0]
Inter-annotator agreement under Fleiss score is 0.625.,6.1 Setup,[0],[0]
Table 2 shows the performance comparison of the methods using the standard metrics for a ranking system (precision at 5 and 15 and MAP at 15).,6.2 Results and Discussion,[0],[0]
"In general, all baselines perform worse than reported in the literature, confirming the higher complexity of the hashtag annotation task as compared to traditional tasks.",6.2 Results and Discussion,[0],[0]
"Interestingly enough, using our local similarities already produces better results than Tagme and Wikiminer.",6.2 Results and Discussion,[0],[0]
The local model fm significantly outperforms both the baselines in all metrics.,6.2 Results and Discussion,[0],[0]
Combining the similarities improves the performance even more significantly.2,6.2 Results and Discussion,[0],[0]
"Compared to the baselines, IPL improves the performance by 17-28%.",6.2 Results and Discussion,[0],[0]
The time similarity achieves the highest result compared to other content-based mention and context similarities.,6.2 Results and Discussion,[0],[0]
This supports our assumption that lexical matching is not always the best strategy to link entities in tweets.,6.2 Results and Discussion,[0],[0]
"The time seriesbased metric incurs lower cost than others, yet it produces a considerably good performance.",6.2 Results and Discussion,[0],[0]
Context similarity based on Wikipedia edits does not yield much improvement.,6.2 Results and Discussion,[0],[0]
This can be explained in two ways.,6.2 Results and Discussion,[0],[0]
"First, information in Wikipedia is largely biased to popular entities, it fails to capture many entities in the long tail.",6.2 Results and Discussion,[0],[0]
"Second, language models are dependent on direct word representations, which are different between Twitter and Wikipedia.",6.2 Results and Discussion,[0],[0]
"This is another advantage of noncontent measures such as ft.
",6.2 Results and Discussion,[0],[0]
"For the second group of baselines (Kauri and Meij), we also observe the reduction in precision, especially for Kauri.",6.2 Results and Discussion,[0],[0]
"This is because the method relies on the coherence of user interests within a group of tweets to be able to perform well, which does not hold in the context of hashtags.",6.2 Results and Discussion,[0],[0]
One astonishing result is that Meij performs better than IPL in terms of P@15.,6.2 Results and Discussion,[0],[0]
"However, it performs worse in terms of MAP and P@5, suggesting that most of the correctly identified entities are ranked lower in the list.",6.2 Results and Discussion,[0],[0]
"This is reasonable, as Meij attempts to optimize (with human supervision effort) the se-
2All significance tests are done against both Tagme and Wikiminer, with a p-value < 0.01.
mantic agreement between entities and information found in the tweets, instead of ranking their prominence as in our work.",6.2 Results and Discussion,[0],[0]
"To investigate this case further, we re-examined the hashtags and divided them by their semantics, as to whether the hashtags are spurious trends of memes inside social media (endogenous, e.g., “#stopasian2014”), or whether they reflect external events (exogenous, e.g., “#mh370”).",6.2 Results and Discussion,[0],[0]
The performance of the methods in terms of MAP scores is shown in Figure 3.,6.2 Results and Discussion,[0],[0]
"It can be clearly seen that entity linking methods perform well in the endogenous group, but then deteriorate in the exogenous group.",6.2 Results and Discussion,[0],[0]
"The explanation is that for endogenous hashtags, the topical consonance between tweets is very low, thus most of the assessments become just verifying general concepts (such as locations)",6.2 Results and Discussion,[0],[0]
"In this case, topical annotation is trumped by conceptual annotation.",6.2 Results and Discussion,[0],[0]
"However, whenever the hashtag evolves into a meaningful topic, a deeper annotation method will produce a significant improvement, as seen in Figure 3.
",6.2 Results and Discussion,[0],[0]
"Finally, we study the impact of the burst time period on the annotation quality.",6.2 Results and Discussion,[0],[0]
"For this, we expand the window size w (cf. Section 6.1) and examine how different methods perform.",6.2 Results and Discussion,[0],[0]
The result is depicted in Figure 4.,6.2 Results and Discussion,[0],[0]
"It is obvious that within the win-
dow of 2 months (where the hashtag time series is constructed and a trending time is identified), our method is stable and always outperforms the baselines by a large margin.",6.2 Results and Discussion,[0],[0]
"Even when the trending hashtag has been saturated, hence introduced more noise, our method is still able to identify the prominent entities with high quality.",6.2 Results and Discussion,[0],[0]
"In this work, we address the new problem of topically annotating a trending hashtag using Wikipedia entities, which has many important applications in social media analysis.",7 Conclusion and Future Work,[0],[0]
We study Wikipedia temporal resources and find that using efficient time series-based measures can complement content-based methods well in the domain of Twitter.,7 Conclusion and Future Work,[0],[0]
"We propose use similarity measures to model both the local mention-based, as well as the global context- and time-based prominence of entities.",7 Conclusion and Future Work,[0],[0]
We propose a novel strategy of topical annotation of texts using and influence maximization approach and design an efficient learning algorithm to automatically unify the similarities without the need of human involvement.,7 Conclusion and Future Work,[0],[0]
"The experiments show that our method outperforms significantly the established baselines.
",7 Conclusion and Future Work,[0],[0]
"As future work, we aim to improve the efficiency of our entire workflow, such that the annotation can become an end-to-end service.",7 Conclusion and Future Work,[0],[0]
"We also aim to improve the context similarity between entities and the topic, for example by using a deeper distributional semantics-based method, instead of language models as in our current work.",7 Conclusion and Future Work,[0],[0]
"In addition, we plan to extend the annotation framework to other types of trending topics, by including the type of out-of-knowledge entities.",7 Conclusion and Future Work,[0],[0]
"Finally, we are investigating how to apply more advanced influence maximization methods.",7 Conclusion and Future Work,[0],[0]
"We believe that influence maximization has a great potential in NLP research, beyond the scope of annotation for microblogging topics.",7 Conclusion and Future Work,[0],[0]
"This work was funded by the European Commission in the FP7 project ForgetIT (600826) and the ERC advanced grant ALEXANDRIA (339233), and by the German Federal Ministry of Education and Research for the project “Gute Arbeit” (01UG1249C).",Acknowledgments,[0],[0]
We thank the reviewers for the fruitful discussion and Claudia Niederee from L3S for suggestions on improving Section 5.,Acknowledgments,[0],[0]
Trending topics in microblogs such as Twitter are valuable resources to understand social aspects of real-world events.,abstractText,[0],[0]
"To enable deep analyses of such trends, semantic annotation is an effective approach; yet the problem of annotating microblog trending topics is largely unexplored by the research community.",abstractText,[0],[0]
"In this work, we tackle the problem of mapping trending Twitter topics to entities from Wikipedia.",abstractText,[0],[0]
We propose a novel model that complements traditional text-based approaches by rewarding entities that exhibit a high temporal correlation with topics during their burst time period.,abstractText,[0],[0]
"By exploiting temporal information from the Wikipedia edit history and page view logs, we have improved the annotation performance by 17-28%, as compared to the competitive baselines.",abstractText,[0],[0]
Semantic Annotation for Microblog Topics Using Wikipedia Temporal Information,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2787–2792 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2787",text,[0],[0]
"Intelligent personal assistants are now ubiquitous, but modeling the semantics of complex compositional natural language queries remains challenging.",1 Introduction,[0],[0]
"Typical systems classify the intent of a query (e.g. GET DIRECTIONS) and tag the necessary slots (e.g. San Francisco) (Mesnil et al., 2013; Liu and Lane, 2016).",1 Introduction,[0],[0]
"It is difficult for such representations to adequately represent nested queries such as “Driving directions to the Eagles game”, which is composed of GET DIRECTIONS and GET EVENT intents.",1 Introduction,[0],[0]
"We explore a hierarchical representation for such queries, which dramatically improves the expressive power while remaining accurate and efficient to annotate and parse (see Figure 1).
",1 Introduction,[0],[0]
We introduce a Task Oriented Parsing (TOP) representation for intent-slot based dialog systems.,1 Introduction,[0],[0]
"This hierarchical representation is expressive enough to capture the semantics of com-
1http://fb.me/semanticparsingdialog
plex nested queries, but is easier to annotate and parse than alternative representations such as logical forms or dependency graphs.",1 Introduction,[0],[0]
"We show empirically that our representation is expressive enough to model the vast majority of human-generated requests in two domains.
",1 Introduction,[0],[0]
"A key advantage of our representation is that it has a structure similar to standard constituency parses, allowing us to easily adapt algorithms developed for phrase structure parsing for inference.",1 Introduction,[0],[0]
"In particular, we use linear-time Recurrent Neural Network Grammars (RNNG) (Dyer et al., 2016) and show that the inductive bias provided by this model significantly improves the accuracy compared to strong sequence-to-sequence (seq2seq) models based on CNNs, LSTMs and Transformers.
",1 Introduction,[0],[0]
Our contributions in this paper are: 1.,1 Introduction,[0],[0]
"A hierarchical semantic representation for
task oriented dialog systems that can model compositional and nested queries.",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
A publicly available dataset of 44k requests annotated with our representation.,1 Introduction,[0],[0]
"We show that our representation has very high coverage of these requests, and that inter-annotator agreement is high.",1 Introduction,[0],[0]
3.,1 Introduction,[0],[0]
We show that the representation is learnable by standard algorithms.,1 Introduction,[0],[0]
"In particular, we show that the RNNG parsing model outperforms seq2seq baselines.",1 Introduction,[0],[0]
"Designing semantic annotation schemes requires trade-offs between how expressive the representation is on one hand, and how easily can it be annotated, parsed, and executed on the other.",2 Representation,[0],[0]
"Most existing annotations for task oriented dialog systems have fallen on the extremes of non-recursive intent and slot tagging, such as in the ATIS dataset (Mes-
nil et al., 2013; Liu and Lane, 2016), and full logical forms (Zettlemoyer and Collins, 2012).
",2 Representation,[0],[0]
"We introduce a hierarchical representation, similar to a constituency syntax tree, with words as terminals.",2 Representation,[0],[0]
"Non-terminals are either intents or slots, and the root node is an intent.",2 Representation,[0],[0]
"We allow intents to be nested inside a slot, resulting in the ability to compose requests and call multiple APIs.",2 Representation,[0],[0]
"Using this compositional tree representation, we can enable answering compositional queries over multiple domains.
",2 Representation,[0],[0]
We introduce the following constraints in our representation: 1.,2 Representation,[0],[0]
"The top level node must be an intent, 2.",2 Representation,[0],[0]
"An intent can have tokens and/or slots as children, 3.",2 Representation,[0],[0]
"A slot can have either tokens as children or one intent as a child.
",2 Representation,[0],[0]
"Executing queries such as those in Figure 1 is straightforward because of the explicit tagging of the outer location slot: first we fetch ‘the Eagles game’ event (or the relevant coffee shop), extract the location, and pass it as the destination slot to the navigation domain intent.
",2 Representation,[0],[0]
Compositional queries are frequent.,2 Representation,[0],[0]
"In our dataset of crowd-sourced utterances, we found that 30% could not be adequately represented with traditional intent-slot tagging.2 This shows that more expressive representations are often necessary.
",2 Representation,[0],[0]
"While our representation is capable of modeling many complex queries, some utterances are beyond its scope.",2 Representation,[0],[0]
"For example, in Set an alarm at 8 am for Monday and Wednesday, 8 am needs to be associated with both Monday and Wednesday which would require graph-structured repre-
2In our dataset, 35% of queries have depth >2, which means that the traditional intent-slot tagging systems would not have been able to annotate or predict these annotations.",2 Representation,[0],[0]
"In addition, to avoid the depth-based statistic being influenced by our label set specification, we manually performed analysis of 100 samples that showed that 30% of the queries required compositional representation.
sentations.",2 Representation,[0],[0]
"However, we found that just 0.3% of our dataset would require a more expressive representation to model adequately.3 More expressive representations, such as dependency graphs or logical forms, would only bring marginal gains but would add significant challenges for annotation and learning.
",2 Representation,[0],[0]
"Together, these results suggest that our treestructured approach offers a useful compromise between traditional intent-slot tagging and logical forms, by providing very high coverage of queries while avoiding the complexities of annotating and learning more expressive representations.
",2 Representation,[0],[0]
"In summary, our representation has the following attractive properties: • Expressiveness Compared to traditional
intent-slot annotations, it can express complex hierarchical queries, improving coverage of queries by 30%.",2 Representation,[0],[0]
We found that more general representations are required for only 0.3% of queries.,2 Representation,[0],[0]
"• Easy Annotation Annotating our representa-
tion simply requires labeling spans of a sentence, which is much more straightforward than alternatives such as creating a logical form for the sentence, or an arbitrary dependency graph.",2 Representation,[0],[0]
This fact allows us to quickly create a large dataset.,2 Representation,[0],[0]
• Efficient and Accurate Parsing,2 Representation,[0],[0]
"Since our
representation closely resembles syntactic trees, we can easily re-use models from the large literature on constituency parsing.
3Utterances that could not be annotated with the label sets and corresponding instructions were marked as ‘unsupported’ (9.14% of the dataset), including the ones that needed more expressive representation than a tree.",2 Representation,[0],[0]
"Analysis of a random sample of 120 unsupported utterances shows that only four instances cannot be supported because of the tree representation constraint, estimating that there are only 0.3% queries that would require a more general (e.g graph-based) representation.
",2 Representation,[0],[0]
"• Execution Our approach can be seen as a simple generalization of traditional dialog systems, meaning that existing infrastructure can easily be adapted to execute the intents.",2 Representation,[0],[0]
We asked crowdsourced workers to generate natural language sentences that they would ask a system that could assist in navigation and event queries.,3 Dataset,[0],[0]
These requests were then labeled by two annotators.,3 Dataset,[0],[0]
If these annotations weren’t identical then we adjudicated with a third annotator.,3 Dataset,[0],[0]
If all three annotators disagreed then we discarded the utterance and its annotations.,3 Dataset,[0],[0]
63.40% of utterances were resolved with 2 annotations and 94.09% were resolved after getting 3 annotations.,3 Dataset,[0],[0]
"We also compared percentage of utterances that were resolved after 2 annotations for depth ≤ 2 (traditional slot filling) and for depth > 2 (compositional): 68.87% vs 62.03%, noting that the agreement rate is similar.
",3 Dataset,[0],[0]
"We collected a total of 44783 annotations with 25 intents and 36 slots, randomly split into 31279 training, 4462 validation and 9042 test utterances.",3 Dataset,[0],[0]
"The dataset has utterances that are focused on navigation, events, and navigation to events.
",3 Dataset,[0],[0]
"The median (mean) depth of the trees is 2 (2.54), and the median (mean) length of the utterances is 8 (8.93) tokens.",3 Dataset,[0],[0]
35% of trees have depth more than 2.,3 Dataset,[0],[0]
The dataset has 4646 utterances that contain both navigation and event intents.,3 Dataset,[0],[0]
Figure 2 shows the distribution of instances in the full dataset over the utterance length and tree depth.,3 Dataset,[0],[0]
"We experiment with two types of models: standard sequence-to-sequence learning models, and a model adapted from syntactic parsing, Recurrent Neural Network Grammars (Dyer et al., 2016) (RNNG).",4 Models,[0],[0]
RNNG is a top-down transition-based parser and was originally proposed for parsing syntax trees and language modeling.,4 Models,[0],[0]
We trained the RNNG parser discriminatively and not generatively to reduce training time of the model.,4 Models,[0],[0]
"While sequence-to-sequence learning can model arbitrary sequence transduction, we hypothesize that parsing models like RNNG, which can only output well-formed trees, will give better inductive bias and flexibility for predicting compositional and cross-domains scenarios on the fly, particularly for domains with less training data available.
",4 Models,[0],[0]
"We briefly review the RNNG model – The parse tree is constructed using a sequence of transitions, or ‘actions’.",4 Models,[0],[0]
"The transitions are defined as a set of SHIFT, REDUCE, and the generation of intent and slot labels.",4 Models,[0],[0]
"SHIFT action consumes an input token (that is, adds the token as a child of the right most ‘open’ sub-tree node) and REDUCE closes a sub-tree.",4 Models,[0],[0]
The third set of actions is generating non-terminals – the slot and intent labels.,4 Models,[0],[0]
"Note that at each step, there are only a subset of valid actions.",4 Models,[0],[0]
"For examples, if all the input tokens have been added to the tree, the only valid action is REDUCE.",4 Models,[0],[0]
"We compared RNNG with implementations of sequence-to-sequence models using CNNs (Gehring et al., 2017), LSTMs (Wiseman and Rush, 2016) and Transformer networks (Vaswani et al., 2017) in fairseq4.",Baselines,[0],[0]
We used three metrics to evaluate the systems.,Metrics,[0],[0]
Exact match accuracy is defined as the number of utterances whose full trees are correctly predicted.,Metrics,[0],[0]
"The second metric is a commonly used scoring method for syntactic parsing – labeled bracketing F1 scores (Black et al., 1991) (called F1 henceforth).",Metrics,[0],[0]
We used the pre-terminals as well in the calculations.,Metrics,[0],[0]
One downside of this metric is that it only considers the token spans for a given nonterminal but not the internal structure.,Metrics,[0],[0]
Tree substructures are rather important for task completion.,Metrics,[0],[0]
"Thus, we introduce a third metric, Tree-Labeled (TL) F1, which compares the sub-tree structure for a non-terminal, instead of just the token span.",Metrics,[0],[0]
Exact match accuracy is the strictest metric and F1 is the least strict metric.,Metrics,[0],[0]
Tree Validity is the percentage of predictions which formed valid trees (via bracket matching).,Metrics,[0],[0]
"We used the same preprocessing of unknown words as used in (Dyer et al., 2016) and mapped numbers to a constant.",Preprocessing and Hyperparameters,[0],[0]
"We used pre-trained GloVe embeddings (Pennington et al., 2014) and tuned hyperparameters on the validation set.",Preprocessing and Hyperparameters,[0],[0]
"• RNNG - We used 2-layer 164-unit LSTM
with a bidirectional LSTM compositional
4https://github.com/pytorch/fairseq
function, trained with a learning rate of 0.0004, weight decay of 0.00004, dropout of 0.34 with Adam optimizer for 1 epoch with 16 workers using Hogwild updates.",Preprocessing and Hyperparameters,[0],[0]
•,Preprocessing and Hyperparameters,[0],[0]
"seq2seq CNN - We used 3x3 convolutions (9
layers of 512 units, 4 units of 1024 units), followed by 1x1 convolutions (2 layers of 2048 units) with attention, trained with initial learning rate of 0.9, dropout of 0.2, gradient clipping of 0.1 with NAG optimizer for 30 epochs, inferred with beam size 5.",Preprocessing and Hyperparameters,[0],[0]
"• seq2seq Transformer - We used 3 layers of
4 FFN attention heads of embedding dimension 512, trained with initial learning rate of
0.01, dropout of 0.2, gradient clipping of 5 with Adam optimizer for 50 epochs, inferred with beam size 5.",Preprocessing and Hyperparameters,[0],[0]
"• seq2seq LSTM - We used 1-layer 256 unit
LSTMs with attention, trained with initial learning rate of 0.7, dropout of 0.2, gradient clipping of 0.1 with NAG optimizer for 40 epochs, inferred with beam size 5.",Preprocessing and Hyperparameters,[0],[0]
"The experimental results in Table 1 and Figure 3 show that existing approaches for syntactic parsing, such as RNNG, perform well for this task, achieving perfect outputs on over 75% of queries.",Results,[0],[0]
"RNNG performs better than sequence-to-sequence
models, especially in predicting exact trees, which is important for task completion.",Results,[0],[0]
"We present results for the CNN and LSTM models with an output terminal token vocabulary of just a single element (LOTV), which performed better than the regular token vocabulary (exact match accuracy of 75.63% and 68.39%, respectively).",Results,[0],[0]
We believe LOTV makes the models focus on learning to predict the tree structure rather than to reproduce the input tokens.,Results,[0],[0]
"But we observed that this vocabulary reduction resulted in significantly poorer performance for the Transformer model.
",Results,[0],[0]
Below we discuss how varying the beam size during inference affects accuracy.,Results,[0],[0]
The seq2seq results in Table 1 are accuracy for the top prediction when a beam of size 5 was run and the RNNG results are for greedy inference.,Results,[0],[0]
"For RNNG, the accuracy of top prediction did not change much when a beam of size 5 was run.",Results,[0],[0]
"We also measured how often the correct tree annotation was in the top k predictions for the models when a beam of size k was run during inference, called as Topk.",Results,[0],[0]
"For RNNG, Top-3 was 90.21 and Top-5 was 92.48, compared to 78.51 for k=1.",Results,[0],[0]
"For seq2seqCNN, the Top-3 score was 88.08 and Top-5 score was 90.21.",Results,[0],[0]
"For seq2seq-LSTM, Top-3 was 86.55 and Top-5 was 88.76.",Results,[0],[0]
We note that Top-5 is substantially higher than the accuracy of the top prediction.,Results,[0],[0]
"These top-k predictions could be used by a hypothesis ranker downstream, which can take into account agent capabilities.
",Results,[0],[0]
"We also experimented with more minimal representations of the RNNG model (Kuncoro et al., 2017).",Results,[0],[0]
Removing the actions LSTM dropped Exact match score slightly to 78.08.,Results,[0],[0]
"Separately, removing the stack LSTM dropped it to 75.31.",Results,[0],[0]
"Removing the buffer LSTM caused a unusable decrease to 13.78.
",Results,[0],[0]
"While sequence-to-sequence models have shown strong parsing performance when trained on very large amounts of data (Vinyals et al., 2015); in our setting the inductive bias provided by the RNNG model is crucial to achieving high performance.",Results,[0],[0]
"The model has several useful biases, such as guaranteeing a well-formed output tree, and shortening the dependencies between intents and their slots.
",Results,[0],[0]
"A further advantage of RNNG is that inference has linear time complexity, whereas seq2seq models are quadratic because attention is recomputed at every time step.",Results,[0],[0]
Many annotation schemes have previously been proposed for representing the semantics of natural language.,6 Related Work,[0],[0]
"We briefly compare our method with these.
",6 Related Work,[0],[0]
"Most work on task oriented dialog systems has focused on identifying a single user intent and then filling the relevant slots – for example, the representations used on the ATIS dataset (Mesnil et al., 2013; Liu and Lane, 2016; Zhu and Yu, 2017) and in the Dialog State Tracking Challenge (Williams et al., 2016).",6 Related Work,[0],[0]
"We showed that hierarchical representations with nested intents can improve coverage of requests in our domains.
",6 Related Work,[0],[0]
"The semantic parsing literature has focused on representing language with logical forms (Liang, 2016; Zettlemoyer and Collins, 2012; Kwiatkowski et al., 2010).",6 Related Work,[0],[0]
"Logical forms are more expressive than our representation, as they are less tightly coupled to the input query, and can be executed directly.",6 Related Work,[0],[0]
"However, logical forms are difficult to annotate and no large-scale datasets are available.
",6 Related Work,[0],[0]
"While we used a tree-structured representation, others have used arbitrary graphs, such as Abstract Meaning Representation (Banarescu et al., 2013) and Alexa Meaning Representation (Fan et al., 2017).",6 Related Work,[0],[0]
"These approaches can represent complex constructions that are beyond the scope of our approach, but with significantly challenging parsing (Artzi et al., 2015).",6 Related Work,[0],[0]
We showed that such cases are very rare in our data.,6 Related Work,[0],[0]
"Drawing on ideas from slot-filling and semantic parsing, we introduce a hierarchical generalization of traditional intents and slots that allows the representation of complex nested queries, leading to 30% higher coverage of user requests.",7 Conclusions,[0],[0]
We show that the representation can be annotated with high agreement.,7 Conclusions,[0],[0]
We are releasing a large dataset of annotated utterances at http://fb.,7 Conclusions,[0],[0]
me/semanticparsingdialog.,7 Conclusions,[0],[0]
"The representation allows the use of existing constituency parsing algorithms, resulting in higher accuracy than sequence-to-sequence models.",7 Conclusions,[0],[0]
Task oriented dialog systems typically first parse user utterances to semantic frames comprised of intents and slots.,abstractText,[0],[0]
"Previous work on task oriented intent and slot-filling work has been restricted to one intent per query and one slot label per token, and thus cannot model complex compositional requests.",abstractText,[0],[0]
"Alternative semantic parsing systems have represented queries as logical forms, but these are challenging to annotate and parse.",abstractText,[0],[0]
"We propose a hierarchical annotation scheme for semantic parsing that allows the representation of compositional queries, and can be efficiently and accurately parsed by standard constituency parsing models.",abstractText,[0],[0]
"We release a dataset of 44k annotated queries 1, and show that parsing models outperform sequence-to-sequence approaches on this dataset.",abstractText,[0],[0]
Semantic Parsing for Task Oriented Dialog using Hierarchical Representations,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1078–1087, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
We present a novel semi-supervised approach for sequence transduction and apply it to semantic parsing. The unsupervised component is based on a generative model in which latent sentences generate the unpaired logical forms. We apply this method to a number of semantic parsing tasks focusing on domains with limited access to labelled training data and extend those datasets with synthetically generated logical forms.",text,[0],[0]
"Neural approaches, in particular attention-based sequence-to-sequence models, have shown great promise and obtained state-of-the-art performance for sequence transduction tasks including machine translation (Bahdanau et al., 2015), syntactic constituency parsing (Vinyals et al., 2015), and semantic role labelling (Zhou and Xu, 2015).",1 Introduction,[0],[0]
"A key requirement for effectively training such models is an abundance of supervised data.
",1 Introduction,[0],[0]
"In this paper we focus on learning mappings from input sequences x to output sequences y in domains where the latter are easily obtained, but annotation in the form of (x, y) pairs is sparse or expensive to produce, and propose a novel architecture that accommodates semi-supervised training on sequence transduction tasks.",1 Introduction,[0.9511523630976517],"['In order to generate adversaries, we generate a set of paraphrases Πx around x via beam search and get predictions on Πx using the black box model until an adversary is found, or until S(x, x′) < τ .']"
"To this end, we augment the transduction objective (x 7→ y) with an autoencoding objective where the input sequence is treated as a latent variable (y 7→ x 7→ y), enabling training from both labelled pairs and unpaired output sequences.
",1 Introduction,[0],[0]
"This is common in situations where we encode natural language into a logical form governed by some grammar or database.
",1 Introduction,[0],[0]
"While such an autoencoder could in principle be constructed by stacking two sequence transducers, modelling the latent variable as a series of discrete symbols drawn from multinomial distributions creates serious computational challenges, as it requires marginalising over the space of latent sequences Σ∗x.",1 Introduction,[0],[0]
"To avoid this intractable marginalisation, we introduce a novel differentiable alternative for draws from a softmax which can be used with the reparametrisation trick of Kingma and Welling (2014).",1 Introduction,[0],[0]
"Rather than drawing a discrete symbol in Σx from a softmax, we draw a distribution over symbols from a logistic-normal distribution at each time step.",1 Introduction,[0],[0]
"These serve as continuous relaxations of discrete samples, providing a differentiable estimator of the expected reconstruction log likelihood.
",1 Introduction,[0],[0]
"We demonstrate the effectiveness of our proposed model on three semantic parsing tasks: the GEOQUERY benchmark (Zelle and Mooney, 1996; Wong and Mooney, 2006), the SAIL maze navigation task (MacMahon et al., 2006) and the Natural Language Querying corpus (Haas and Riezler, 2016) on OpenStreetMap.",1 Introduction,[0],[0]
"As part of our evaluation, we introduce simple mechanisms for generating large amounts of unsupervised training data for two of these tasks.
",1 Introduction,[0],[0]
"In most settings, the semi-supervised model outperforms the supervised model, both when trained on additional generated data as well as on subsets of the existing data.
1078",1 Introduction,[0],[0]
Our sequential autoencoder is shown in Figure 1.,2 Model,[0],[0]
"At a high level, it can be seen as two sequenceto-sequence models with attention (Bahdanau et al., 2015) chained together.",2 Model,[0],[0]
"More precisely, the model consists of four LSTMs (Hochreiter and Schmidhuber, 1997), hence the name SEQ4.",2 Model,[0],[0]
"The first, a bidirectional LSTM, encodes the sequence y; next, an LSTM with stochastic output, described below, draws a sequence of distributions x̃ over words in vocabulary Σx.",2 Model,[0],[0]
The third LSTM encodes these distributions for the last one to attend over and reconstruct y as ŷ. We now give the details of these parts.,2 Model,[0],[0]
"The first LSTM of the encoder half of the model reads the sequence y, represented as a sequence of one-hot vectors over the vocabulary Σy, using a bidirectional RNN into a sequence of vectors hy1:Ly where Ly is the sequence length of y,
hyt = ( f→y (yt, h y,→ t−1 ); f ← y (yt, h y,← t+1 ) ) , (1)
where f→y , f ← y are non-linear functions applied at each time step to the current token yt and their recurrent states hy,→t−1 , h y,← t+1 , respectively.
",2.1 Encoding y,[0],[0]
"Both the forward and backward functions project the one-hot vector into a dense vector via an embedding matrix, which serves as input to an LSTM.",2.1 Encoding y,[0],[0]
"Subsequently, we wish to predict x.",2.2 Predicting a Latent Sequence x̃,[0],[0]
"Predicting a discrete sequence of symbols through draws from multinomial distributions over a vocabulary is not an option, as we would not be able to backpropagate through this discrete choice.",2.2 Predicting a Latent Sequence x̃,[0],[0]
Marginalising over the possible latent strings or estimating the gradient through naı̈ve Monte Carlo methods would be a prohibitively high variance process because the number of strings is exponential in the maximum length (which we would have to manually specify) with the vocabulary size as base.,2.2 Predicting a Latent Sequence x̃,[0],[0]
"To allow backpropagation, we instead predict a sequence of distributions x̃ over the symbols of Σx with an RNN attending over
y1 y2 y3 y4",2.2 Predicting a Latent Sequence x̃,[0],[0]
"< s >
x̃1 x̃2
µ2, log( 2 )2µ1, log( 2 )1
x̃3
µ3, log( 2)3
✏1 ✏2 ✏3
hx1 h x 2 h x 3
hx̃1",2.2 Predicting a Latent Sequence x̃,[0],[0]
h,2.2 Predicting a Latent Sequence x̃,[0],[0]
x̃ 2 h,2.2 Predicting a Latent Sequence x̃,[0],[0]
x̃,2.2 Predicting a Latent Sequence x̃,[0],[0]
"3h y 1 h y 2 h y 3 h y 4
hŷ1 h ŷ 2 h ŷ 3 h ŷ 4
< s >
",2.2 Predicting a Latent Sequence x̃,[0],[0]
ŷ1 ŷ2 ŷ3,2.2 Predicting a Latent Sequence x̃,[0],[0]
"ŷ4
ŷ1 ŷ2 ŷ3
Figure 2: Unsupervised case of the SEQ4 model.
",2.2 Predicting a Latent Sequence x̃,[0],[0]
hy,2.2 Predicting a Latent Sequence x̃,[0],[0]
"= hy1:Ly , which will later serve to reconstruct y:
x̃ = q(x|y) = Lx∏
t=1
q(x̃t|{x̃1, · · · , x̃t−1}, hy) (2)
where q(x|y) models the mapping y 7→ x.",2.2 Predicting a Latent Sequence x̃,[0],[0]
"We define q(x̃t|{x̃1, · · · , x̃t−1}, hy) in the following way:
Let the vector x̃t be a distribution over the vocabulary Σx drawn from a logistic-normal distribution1, the parameters of which, µt, log(σ2)t ∈ R|Σx|, are predicted by attending by an LSTM attending over the outputs of the encoder (Equation 2), where |Σx| is the size of the vocabulary Σx.",2.2 Predicting a Latent Sequence x̃,[0],[0]
"The use of a logistic normal distribution serves to regularise the model in the semi-supervised learning regime, which is described at the end of this section.",2.2 Predicting a Latent Sequence x̃,[0],[0]
"Formally, this process, depicted in Figure 2, is as follows:
hx̃t = fx̃(x̃t−1, h x̃ t−1, h y) (3)
µt, log(σ 2 t ) =",2.2 Predicting a Latent Sequence x̃,[0],[0]
"l(h x̃ t ) (4)
∼ N (0, I) (5) γt = µt + σt (6)
x̃t = softmax(γt) (7)
where the fx̃ function is an LSTM and l a linear transformation to R2|Σx|.",2.2 Predicting a Latent Sequence x̃,[0],[0]
"We use the reparametrisation trick from Kingma and Welling (2014) to draw from the logistic normal, allowing us to backpropagate through the sampling process.
1The logistic-normal distribution is the exponentiated and normalised (i.e. taking softmax) normal distribution.",2.2 Predicting a Latent Sequence x̃,[0],[0]
"Moving on to the decoder part of our model, in the third LSTM, we embed2 and encode x̃:
hxt = ( f→x (x̃t, h x,→ t−1 ); f ← x (x̃t, h x,← t+1 ) )",2.3 Encoding x,[0],[0]
"(8)
When x is observed, during supervised training and also when making predictions, instead of the distribution x̃ we feed the one-hot encoded x to this part of the model.",2.3 Encoding x,[0],[0]
"In the final LSTM, we decode into y:
p(ŷ|x̃) = Ly∏
t=1
p(ŷt|{ŷ1, · · · , ŷt−1}, hx̃) (9)
",2.4 Reconstructing y,[0],[0]
"Equation 9 is implemented as an LSTM attending over hx̃ producing a sequence of symbols ŷ based on recurrent states hŷ, aiming to reproduce input y:
hŷt = fŷ(ŷt−1, h ŷ t−1, h x̃) (10)
ŷt ∼ softmax(l′(hŷt ))",2.4 Reconstructing y,[0],[0]
"(11)
where fŷ is the non-linear function, and the actual probabilities are given by a softmax function after a linear transformation l′ of hŷ.",2.4 Reconstructing y,[0],[0]
"At training time, rather than ŷt−1 we feed the ground truth yt−1.",2.4 Reconstructing y,[0],[0]
The complete model described in this section gives a reconstruction function y 7→ ŷ.,2.5 Loss function,[0],[0]
"We define a loss on this reconstruction which accommodates the unsupervised case, where x is not observed in the training data, and the supervised case, where (x, y) pairs are available.",2.5 Loss function,[0],[0]
"Together, these allow us to train the SEQ4 model in a semi-supervised setting, which experiments will show provides some benefits over a purely supervised training regime.
",2.5 Loss function,[0],[0]
"Unsupervised case When x isn’t observed, the loss we minimise during training is the reconstruction loss on y, expressed as the negative loglikelihood NLL(ŷ, y) of the true labels y relative to the predictions ŷ. To this, we add as a regularising
2Multiplying the distribution over words and an embedding matrix averages the word embedding of the entire vocabulary weighted by their probabilities.
",2.5 Loss function,[0],[0]
"term the KL divergence KL[q(γ|y)‖p(γ)] which effectively penalises the mean and variance of q(γ|y) from diverging from those of a prior p(γ), which we model as a diagonal Gaussian N (0, I).",2.5 Loss function,[0],[0]
"This has the effect of smoothing the logistic normal distribution from which we draw the distributions over symbols of x, guarding against overfitting of the latent distributions over x to symbols seen in the supervised case discussed below.",2.5 Loss function,[0],[0]
"The unsupervised loss is therefore formalised as
Lunsup = NLL(ŷ, y) + αKL[q(γ|y)‖p(γ)]",2.5 Loss function,[0],[0]
"(12)
with regularising factor α is tuned on validation, and
KL[q(γ|y)‖p(γ)] = Lx∑
i=1
KL[q(γi|y)‖p(γ)]",2.5 Loss function,[0],[0]
"(13)
We use a closed form of these individual KL divergences, described by Kingma and Welling (2014).
",2.5 Loss function,[0],[0]
"Supervised case When x is observed, we additionally minimise the prediction loss on x, expressed as the negative log-likelihoodNLL(x̃, x) of the true labels x relative to the predictions x̃, and do not impose the KL loss.",2.5 Loss function,[0],[0]
"The supervised loss is thus
Lsup = NLL(x̃, x)",2.5 Loss function,[0],[0]
"+NLL(ŷ, y) (14)
In both the supervised and unsupervised case, because of the continuous relaxation on generating x̃ and the reparameterisation trick, the gradient of the losses with regard to the model parameters is well defined throughout SEQ4.
Semi-supervised training and inference We train with a weighted combination of the supervised and unsupervised losses described above.",2.5 Loss function,[0],[0]
"Once trained, we simply use the x 7→ y decoder segment of the model to predict y from sequences of symbols x represented as one-hot vectors.",2.5 Loss function,[0],[0]
"When the decoder is trained without the encoder in a fully supervised manner, it serves as our supervised sequenceto-sequence baseline model under the name S2S.",2.5 Loss function,[0],[0]
We apply our model to three tasks outlined in this section.,3 Tasks and Data Generation,[0],[0]
"Moreover, we explain how we generated additional unsupervised training data for two of these tasks.",3 Tasks and Data Generation,[0],[0]
Examples from all datasets are in Table 1.,3 Tasks and Data Generation,[0],[0]
The first task we consider is the prediction of a query on the GEO corpus which is a frequently used benchmark for semantic parsing.,3.1 GeoQuery,[0],[0]
The corpus contains 880 questions about US geography together with executable queries representing those questions.,3.1 GeoQuery,[0],[0]
We follow the approach established by Zettlemoyer and Collins (2005) and split the corpus into 600 training and 280 test cases.,3.1 GeoQuery,[0],[0]
"Following common practice, we augment the dataset by referring to the database during training and test time.",3.1 GeoQuery,[0.9565519969387641],"['We then augment the training data by applying these rules to it, and retrain the models.']"
"In particular, we use the database to identify and anonymise variables (cities, states, countries and rivers) following the method described in Dong and Lapata (2016).
",3.1 GeoQuery,[0],[0]
Most prior work on the GEO corpus relies on standard semantic parsing methods together with custom heuristics or pipelines for this corpus.,3.1 GeoQuery,[0],[0]
"The recent paper by Dong and Lapata (2016) is of note, as it uses a sequence-to-sequence model for training which is the unidirectional equivalent to S2S, and also to the decoder part of our SEQ4 network.",3.1 GeoQuery,[0],[0]
The second task we tackle with our model is the NLMAPS dataset by Haas and Riezler (2016).,3.2 Open Street Maps,[0],[0]
"The dataset contains 1,500 training and 880 testing instances of natural language questions with corresponding machine readable queries over the geographical OpenStreetMap database.",3.2 Open Street Maps,[0],[0]
"The dataset contains natural language question in both English and German but we focus only on single language semantic parsing, similar to the first task in Haas and Riezler (2016).",3.2 Open Street Maps,[0],[0]
"We use the data as it is, with the only pre-processing step being the tokenization of both natural language and query form3.",3.2 Open Street Maps,[0],[0]
"The SAIL corpus and task were developed to train agents to follow free-form navigational route instructions in a maze environment (MacMahon et al., 2006; Chen and Mooney, 2011).",3.3 Navigational Instructions to Actions,[0],[0]
"It consists of a small number of mazes containing features such as objects, wall and floor types.",3.3 Navigational Instructions to Actions,[0],[0]
"These mazes come together with a large number of human instructions paired with the required actions4 to reach the goal
3We removed quotes, added spaces around (), and separated the question mark from the last word in each question.
",3.3 Navigational Instructions to Actions,[0],[0]
"4There are four actions: LEFT, RIGHT, GO, STOP.
state described in those instructions.",3.3 Navigational Instructions to Actions,[0],[0]
"We use the sentence-aligned version of the SAIL route instruction dataset containing 3,236 sentences (Chen and Mooney, 2011).",3.3 Navigational Instructions to Actions,[0],[0]
"Following previous work, we accept an action sequence as correct if and only if the final position and orientation exactly match those of the gold data.",3.3 Navigational Instructions to Actions,[0],[0]
We do not perform any pre-processing on this dataset.,3.3 Navigational Instructions to Actions,[0],[0]
"As argued earlier, we are focusing on tasks where aligned data is sparse and expensive to obtain, while it should be cheap to get unsupervised, monomodal data.",3.4 Data Generation,[0],[0]
"Albeit that is a reasonable assumption for real world data, the datasets considered have no such component, thus the approach taken here is to generate random database queries or maze paths, i.e. the machine readable side of the data, and train a semi-supervised model.",3.4 Data Generation,[0],[0]
"The alternative not explored here would be to generate natural language questions or instructions instead, but that is more difficult to achieve without human intervention.",3.4 Data Generation,[0],[0]
"For this reason, we generate the machine readable side of the data for GEOQUERY and SAIL tasks5.
",3.4 Data Generation,[0],[0]
"For GEOQUERY, we fit a 3-gram Kneser-Ney (Chen and Goodman, 1999) model to the queries in the training set and sample about 7 million queries from it.",3.4 Data Generation,[0],[0]
"We ensure that the sampled queries are different from the training queries, but do not enforce validity.",3.4 Data Generation,[0],[0]
"This intentionally simplistic approach is to demonstrate the applicability of our model.
",3.4 Data Generation,[0],[0]
The SAIL dataset has only three mazes.,3.4 Data Generation,[0],[0]
"We added a fourth one and over 150k random paths, including duplicates.",3.4 Data Generation,[0],[0]
"The new maze is larger (21× 21 grid) than the existing ones, and seeks to approximately replicate the key statistics of the other three mazes (maximum corridor length, distribution of objects, etc).",3.4 Data Generation,[0],[0]
Paths within that maze are created by randomly sampling start and end positions.,3.4 Data Generation,[0],[0]
We evaluate our model on the three tasks in multiple settings.,4 Experiments,[0],[0]
"First, we establish a supervised baseline to compare the S2S model with prior work.",4 Experiments,[0],[0]
"Next, we
5Our randomly generated unsupervised datasets can be downloaded from http://deepmind.com/ publications
train our SEQ4 model in a semi-supervised setting on the entire dataset with the additional monomodal training data described in the previous section.
",4 Experiments,[0],[0]
"Finally, we perform an “ablation” study where we discard some of the training data and compare S2S to SEQ4.",4 Experiments,[0],[0]
"S2S is trained solely on the reduced data in a supervised manner, while SEQ4 is once again trained semi-supervised on the same reduced data plus the machine readable part of the discarded data (SEQ4-) or on the extra generated data (SEQ4+).
",4 Experiments,[0],[0]
Training We train the model using standard gradient descent methods.,4 Experiments,[0],[0]
"As none of the datasets used here contain development sets, we tune hyperparameters by cross-validating on the training data.",4 Experiments,[0],[0]
"In the case of the SAIL corpus we train on three folds (two mazes for training and validation, one for test each) and report weighted results across the folds following prior work (Mei et al., 2016).",4 Experiments,[0],[0]
The evaluation metric for GEOQUERY is the accuracy of exactly predicting the machine readable query.,4.1 GeoQuery,[0],[0]
"As results in Table 2 show, our supervised S2S baseline model performs slightly better than the comparable model by Dong and Lapata (2016).",4.1 GeoQuery,[0],[0]
"The semi-supervised SEQ4 model with the additional generated queries improves on it further.
",4.1 GeoQuery,[0],[0]
"The ablation study in Table 3 demonstrates a widening gap between supervised and semi-
6Jia and Liang (2016) used hand crafted grammars to generate additional supervised training data.",4.1 GeoQuery,[0],[0]
supervised as the amount of labelled training data gets smaller.,100% 86.5 86.5 87.3,[0],[0]
This suggests that our model can leverage unlabelled data even when only small amount of labelled data is available.,100% 86.5 86.5 87.3,[0],[0]
"We report results for the NLMAPS corpus in Table 4, comparing the supervised S2S model to the results posted by Haas and Riezler (2016).",4.2 Open Street Maps,[0],[0]
"While their model used a semantic parsing pipeline including alignment, stemming, language modelling and CFG inference, the strong performance of the S2S model demonstrates the strength of fairly vanilla attentionbased sequence-to-sequence models.",4.2 Open Street Maps,[0],[0]
"It should be pointed out that the previous work reports the number of correct answers when queries were executed against the dataset, while we evaluate on the strict accuracy of the generated queries.",4.2 Open Street Maps,[0],[0]
"While we expect these numbers to be nearly equivalent, our evaluation is strictly harder as it does not allow for reordering of query arguments and similar relaxations.
",4.2 Open Street Maps,[0],[0]
We investigate the SEQ4 model only via the ablation study in Table 5 and find little gain through the semi-supervised objective.,4.2 Open Street Maps,[0],[0]
"Our attempt at cheaply generating unsupervised data for this task was not successful, likely due to the complexity of the underlying database.",4.2 Open Street Maps,[0],[0]
Model extension The experiments for the SAIL task differ slightly from the other two tasks in that the language input does not suffice for choosing an,4.3 Navigational Instructions to Actions,[0],[0]
action.,100% 78.03 78.03,[0],[0]
"While a simple instruction such as ‘turn left’ can easily be translated into the action sequence LEFT-STOP, more complex instructions such as ‘Walk forward until you see a lamp’ require knowledge of the agent’s position in the maze.
",100% 78.03 78.03,[0],[0]
To accomplish this we modify the model as follows.,100% 78.03 78.03,[0],[0]
"First, when encoding action sequences, we concatenate each action with a representation of the maze at the given position, representing the mazestate akin to Mei et al. (2016) with a bag-of-features vector.",100% 78.03 78.03,[0],[0]
"Second, when decoding action sequences, the RNN outputs an action which is used to update the agent’s position and the representation of that new position is fed into the RNN as its next input.
",100% 78.03 78.03,[0],[0]
Training regime We cross-validate over the three mazes in the dataset and report overall results weighted by test size (cf. Mei et al. (2016)).,100% 78.03 78.03,[0],[0]
"Both our supervised and semi-supervised model perform worse than the state-of-the-art (see Table 6), but the latter enjoys a comfortable margin over the former.",100% 78.03 78.03,[0],[0]
"As the S2S model broadly reimplements the work of Mei et al. (2016), we put the discrepancy in performance down to the particular design choices that we did not follow in order to keep the model here as general as possible and comparable across tasks.
",100% 78.03 78.03,[0],[0]
"The ablation studies (Table 7) show little gain for the semi-supervised approach when only using data from the original training set, but substantial improvement with the additional unsupervised data.",100% 78.03 78.03,[0],[0]
Supervised training The prediction accuracies of our supervised baseline S2S model are mixed with respect to prior results on their respective tasks.,5 Discussion,[0],[0]
"For GEOQUERY, S2S performs significantly better than the most similar model from the literature (Dong and Lapata, 2016), mostly due to the fact",5 Discussion,[0],[0]
that y and x are,5 Discussion,[0],[0]
encoded with bidirectional LSTMs.,100% 49.49 49.49 58.28,[0],[0]
"With a unidirectional LSTM we get similar results to theirs.
",100% 49.49 49.49 58.28,[0],[0]
"On the SAIL corpus, S2S performs worse than the state of the art.",100% 49.49 49.49 58.28,[0],[0]
"As the models are broadly equivalent we attribute this difference to a number of taskspecific choices and optimisations7 made in Mei et al. (2016) which we did not reimplement for the sake of using a common model across all three tasks.
",100% 49.49 49.49 58.28,[0],[0]
"For NLMAPS, S2S performs much better than the state-of-the-art, exceeding the previous best result by 11% despite a very simple tokenization method
7In particular we don’t use beam search and ensembling.
and a lack of any form of entity anonymisation.
",100% 49.49 49.49 58.28,[0],[0]
Semi-supervised training In both the case of GEOQUERY and the SAIL task we found the semisupervised model to convincingly outperform the fully supervised model.,100% 49.49 49.49 58.28,[0],[0]
"The effect was particularly notable in the case of the SAIL corpus, where performance increased from 58.60% accuracy to 63.25% (see Table 6).",100% 49.49 49.49 58.28,[0],[0]
"It is worth remembering that the supervised training regime consists of three folds of tuning on two maps with subsequent testing on the third map, which carries a risk of overfitting to the training maps.",100% 49.49 49.49 58.28,[0],[0]
The introduction of the fourth unsupervised map clearly mitigates this effect.,100% 49.49 49.49 58.28,[0],[0]
"Table 8 shows some examples of unsupervised logical forms being transformed into natural language, which demonstrate how the model can learn to sensibly ground unsupervised data.
",100% 49.49 49.49 58.28,[0],[0]
Ablation performance The experiments with additional unsupervised data prove the feasibility of our approach and clearly demonstrate the usefulness of the SEQ4 model for the general class of sequence-to-sequence tasks where supervised data is hard to come by.,100% 49.49 49.49 58.28,[0],[0]
"To analyse the model further, we also look at the performance of both S2S and SEQ4 when reducing the amount of supervised training data available to the model.",100% 49.49 49.49 58.28,[0],[0]
"We compare three settings: the supervised S2S model with reduced training data, SEQ4- which uses the removed training data in an unsupervised fashion (throwing away the natural language) and SEQ4+ which uses the randomly generated unsupervised data described in Section 3.",100% 49.49 49.49 58.28,[0],[0]
"The S2S model behaves as expected on all three tasks, its performance dropping with the size of the training data.",100% 49.49 49.49 58.28,[0],[0]
"The performance of SEQ4and SEQ4+ requires more analysis.
",100% 49.49 49.49 58.28,[0],[0]
"In the case of GEOQUERY, having unlabelled data from the true distribution (SEQ4-) is a good thing
when there is enough of it, as clearly seen when only 5% of the original dataset is used for supervised training and the remaining 95% is used for unsupervised training.",100% 49.49 49.49 58.28,[0],[0]
"The gap shrinks as the amount of supervised data is increased, which is as expected.",100% 49.49 49.49 58.28,[0],[0]
"On the other hand, using a large amount of extra, generated data from an approximating distribution (SEQ4+) does not help as much initially when compared with the unsupervised data from the true distribution.",100% 49.49 49.49 58.28,[0],[0]
"However, as the size of the unsupervised dataset in SEQ4- becomes the bottleneck this gap closes and eventually the model trained on the extra data achieves higher accuracy.
",100% 49.49 49.49 58.28,[0],[0]
"For the SAIL task the semi-supervised models do better than the supervised results throughout, with the model trained on randomly generated additional data consistently outperforming the model trained only on the original data.",100% 49.49 49.49 58.28,[0],[0]
"This gives further credence to the risk of overfitting to the training mazes already mentioned above.
",100% 49.49 49.49 58.28,[0],[0]
"Finally, in the case of the NLMAPS corpus, the semi-supervised approach does not appear to help much at any point during the ablation.",100% 49.49 49.49 58.28,[0],[0]
"These indistinguishable results are likely due to the task’s complexity, causing the ablation experiments to either have to little supervised data to sufficiently ground the latent space to make use of the unsupervised data, or in the higher percentages then too little unsupervised data to meaningfully improve the model.",100% 49.49 49.49 58.28,[0],[0]
"Semantic parsing The tasks in this paper all broadly belong to the domain of semantic parsing, which describes the process of mapping natural language to a formal representation of its meaning.",6 Related Work,[0],[0]
"This is extended in the SAIL navigation task, where the formal representation is a function of both the language instruction and a given environment.
",6 Related Work,[0],[0]
"Semantic parsing is a well-studied problem with numerous approaches including inductive logic programming (Zelle and Mooney, 1996), stringto-tree (Galley et al., 2004) and string-to-graph (Jones et al., 2012) transducers, grammar induction (Kwiatkowski et al., 2011; Artzi and Zettlemoyer, 2013; Reddy et al., 2014) or machine translation (Wong and Mooney, 2006; Andreas et al., 2013).
",6 Related Work,[0],[0]
"While a large number of relevant literature fo-
cuses on defining the grammar of the logical forms (Zettlemoyer and Collins, 2005), other models learn purely from aligned pairs of text and logical form (Berant and Liang, 2014), or from more weakly supervised signals such as question-answer pairs together with a database (Liang et al., 2011).",6 Related Work,[0],[0]
"Recent work of Jia and Liang (2016) induces a synchronous context-free grammar and generates additional training examples (x, y), which is one way to address data scarcity issues.",6 Related Work,[0],[0]
"The semi-supervised setup proposed here offers an alternative solution to this issue.
",6 Related Work,[0],[0]
"Discrete autoencoders Very recently there has been some related work on discrete autoencoders for natural language processing (Suster et al., 2016; Marcheggiani and Titov, 2016, i.a.)",6 Related Work,[0],[0]
"This work presents a first approach to using effectively discretised sequential information as the latent representation without resorting to draconian assumptions (Ammar et al., 2014) to make marginalisation tractable.",6 Related Work,[0],[0]
"While our model is not exactly marginalisable either, the continuous relaxation makes training far more tractable.",6 Related Work,[0],[0]
"A related idea was recently presented in Gülçehre et al. (2015), who use monolingual data to improve machine translation by fusing a sequence-to-sequence model and a language model.",6 Related Work,[0],[0]
"We described a method for augmenting a supervised sequence transduction objective with an autoencoding objective, thereby enabling semi-supervised training where previously a scarcity of aligned data might have held back model performance.",7 Conclusion,[0],[0]
"Across multiple semantic parsing tasks we demonstrated the effectiveness of this approach, improving model performance by training on randomly generated unsupervised data in addition to the original data.
",7 Conclusion,[0],[0]
Going forward it would be interesting to further analyse the effects of sampling from a logisticnormal distribution as opposed to a softmax in order to better understand how this impacts the distribution in the latent space.,7 Conclusion,[0],[0]
"While we focused on tasks with little supervised data and additional unsupervised data in y, it would be straightforward to reverse the model to train it with additional labelled data in x, i.e. on the natural language side.",7 Conclusion,[0],[0]
"A natural extension would also be a formulation where semisupervised training was performed in both x and y.
",7 Conclusion,[0],[0]
"For instance, machine translation lends itself to such a formulation where for many language pairs parallel data may be scarce while there is an abundance of monolingual data.",7 Conclusion,[0],[0]
We present a novel semi-supervised approach for sequence transduction and apply it to semantic parsing.,abstractText,[0],[0]
The unsupervised component is based on a generative model in which latent sentences generate the unpaired logical forms.,abstractText,[0],[0]
We apply this method to a number of semantic parsing tasks focusing on domains with limited access to labelled training data and extend those datasets with synthetically generated logical forms.,abstractText,[0],[0]
Semantic Parsing with Semi-Supervised Sequential Autoencoders,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3793–3802 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3793",text,[0],[0]
A learner language (interlanguage) is an idiolect developed by a learner of a second or foreign language which may preserve some features of his/her first language.,1 Introduction,[0],[0]
"Previously, encouraging results of automatically building the syntactic analysis of learner languages were reported (Nagata and Sakaguchi, 2016), but it is still unknown how semantic processing performs, while parsing a learner language (L2) into semantic representations is the foundation of a variety of deeper analysis of learner languages, e.g., automatic essay
1In this paper, we call sentences written by non-native speakers (henceforth, “L2 sentences”), aligned to their corrections by native speakers (henceforth, “L1 sentences”)",1 Introduction,[0],[0]
"L2L1 parallel sentences.
scoring.",1 Introduction,[0],[0]
"In this paper, we study semantic parsing for interlanguage, taking semantic role labeling (SRL) as a case task and learner Chinese as a case language.
",1 Introduction,[0],[0]
"Before discussing a computation system, we first consider the linguistic competence and performance.",1 Introduction,[0],[0]
Can human robustly understand learner texts?,1 Introduction,[0],[0]
"Or to be more precise, to what extent, a native speaker can understand the meaning of a sentence written by a language learner?",1 Introduction,[0],[0]
"Intuitively, the answer is towards the positive side.",1 Introduction,[0],[0]
"To validate this, we ask two senior students majoring in Applied Linguistics to carefully annotate some L2-L1 parallel sentences with predicate–argument structures according to the specification of Chinese PropBank (CPB; Xue and Palmer, 2009), which is developed for L1.",1 Introduction,[0],[0]
"A high inter-annotator agreement is achieved, suggesting the robustness of language comprehension for L2.",1 Introduction,[0],[0]
"During the course of semantic annotation, we find a non-obvious fact that we can re-use the semantic annotation specification, Chinese PropBank in our case, which is developed for L1.",1 Introduction,[0],[0]
Only modest rules are needed to handle some tricky phenomena.,1 Introduction,[0],[0]
"This is quite different from syntactic treebanking for learner sentences, where defining a rich set of new annotation heuristics seems necessary (Ragheb and Dickinson, 2012; Nagata and Sakaguchi, 2016; Berzak et al., 2016).
",1 Introduction,[0],[0]
Our second concern is to mimic the human’s robust semantic processing ability by computer programs.,1 Introduction,[0],[0]
The feasibility of reusing the annotation specification for L1 implies that we can reuse standard CPB data to train an SRL system to process learner texts.,1 Introduction,[0],[0]
"To test the robustness of the state-of-the-art SRL algorithms, we evaluate two types of SRL frameworks.",1 Introduction,[0],[0]
"The first one is a traditional SRL system that leverages a syntactic parser and heavy feature engineering to obtain explicit information of semantic roles (Feng et al., 2012).
",1 Introduction,[0],[0]
"Furthermore, we employ two different parsers for comparison: 1) the PCFGLA-based parser, viz.",1 Introduction,[0],[0]
"Berkeley parser (Petrov et al., 2006), and 2) a minimal span-based neural parser (Stern et al., 2017).",1 Introduction,[0],[0]
"The other SRL system uses a stacked BiLSTM to implicitly capture local and non-local information (He et al., 2017).",1 Introduction,[0],[0]
and we call it the neural syntaxagnostic system.,1 Introduction,[0],[0]
All systems can achieve state-ofthe-art performance on L1 texts but show a significant degradation on L2 texts.,1 Introduction,[0],[0]
"This highlights the weakness of applying an L1-sentence-trained system to process learner texts.
",1 Introduction,[0],[0]
"While the neural syntax-agnostic system obtains superior performance on the L1 data, the two syntax-based systems both produce better analyses on the L2 data.",1 Introduction,[0],[0]
"Furthermore, as illustrated in the comparison between different parsers, the better the parsing results we get, the better the performance on L2 we achieve.",1 Introduction,[0],[0]
This shows that syntactic parsing is important in semantic construction for learner Chinese.,1 Introduction,[0],[0]
"The main reason, according to our analysis, is that the syntax-based system may generate correct syntactic analyses for partial grammatical fragments in L2 texts, which provides crucial information for SRL.",1 Introduction,[0],[0]
"Therefore, syntactic parsing helps build more generalizable SRL models that transfer better to new languages, and enhancing syntactic parsing can improve SRL to some extent.
",1 Introduction,[0],[0]
Our last concern is to explore the potential of a large-scale set of L2-L1 parallel sentences to enhance SRL systems.,1 Introduction,[0],[0]
We find that semantic structures of the L2-L1 parallel sentences are highly consistent.,1 Introduction,[0],[0]
This inspires us to design a novel agreement-based model to explore such semantic coherency information.,1 Introduction,[0],[0]
"In particular, we define a metric for comparing predicate–argument structures and searching for relatively good automatic syntactic and semantic annotations to extend the training data for SRL systems.",1 Introduction,[0],[0]
Experiments demonstrate the value of the L2-L1 parallel sentences as well as the effectiveness of our method.,1 Introduction,[0],[0]
"We achieve an F-score of 72.06, which is a 2.02 percentage point improvement over the best neural-parser-based baseline.
",1 Introduction,[0],[0]
"To the best of our knowledge, this is the first time that the L2-L1 parallel data is utilized to enhance NLP systems for learner texts.
",1 Introduction,[0],[0]
"For research purpose, we have released our SRL annotations on 600 sentence pairs and the L2-L1
parallel dataset 2.",1 Introduction,[0],[0]
"An L2-L1 parallel corpus can greatly facilitate the analysis of a learner language (Lee et al., 2017).",2.1 An L2-L1 Parallel Corpus,[0],[0]
"Following Mizumoto et al. (2011), we collected a large dataset of L2-L1 parallel texts of Mandarin Chinese by exploring “language exchange” social networking services (SNS), i.e., Lang-8, a language-learning website where native speakers can freely correct the sentences written by foreign learners.",2.1 An L2-L1 Parallel Corpus,[0],[0]
"The proficiency levels of the learners are diverse, but most of the learners, according to our judgment, is of intermediate or lower level.
",2.1 An L2-L1 Parallel Corpus,[0],[0]
"Our initial collection consists of 1,108,907 sentence pairs from 135,754 essays.",2.1 An L2-L1 Parallel Corpus,[0],[0]
"As there is lots of noise in raw sentences, we clean up the data by (1) ruling out redundant content, (2) excluding sentences containing foreign words or Chinese phonetic alphabet by checking the Unicode values, (3) dropping overly simple sentences which may not be informative, and (4) utilizing a rule-based classifier to determine whether to include the sentence into the corpus.
",2.1 An L2-L1 Parallel Corpus,[0],[0]
"The final corpus consists of 717,241 learner sentences from writers of 61 different native languages, in which English and Japanese constitute the majority.",2.1 An L2-L1 Parallel Corpus,[0],[0]
"As for completeness, 82.78% of the Chinese Second Language sentences on Lang-8 are corrected by native human annotators.",2.1 An L2-L1 Parallel Corpus,[0],[0]
"One sentence gets corrected approximately 1.53 times on average.
",2.1 An L2-L1 Parallel Corpus,[0],[0]
"In this paper, we manually annotate the predicate–argument structures for the 600 L2-L1 pairs as the basis for the semantic analysis of learner Chinese.",2.1 An L2-L1 Parallel Corpus,[0],[0]
It is from the above corpus that we carefully select 600 pairs of L2-L1 parallel sentences.,2.1 An L2-L1 Parallel Corpus,[0],[0]
We would choose the most appropriate one among multiple versions of corrections and recorrect the L1s if necessary.,2.1 An L2-L1 Parallel Corpus,[0],[0]
"Because word structure is very fundamental for various NLP tasks, our annotation also contains gold word segmentation for both L2 and L1 sentences.",2.1 An L2-L1 Parallel Corpus,[0],[0]
"Note that there are no natural word boundaries in Chinese
2The data is collected from Lang-8 (www.lang-8. com) and used as the training data in NLPCC 2018 Shared Task: Grammatical Error Correction (Zhao et al., 2018), which can be downloaded at https://github.com/ pkucoli/srl4il
text.",2.1 An L2-L1 Parallel Corpus,[0],[0]
"We first employ a state-of-the-art word segmentation system to produce initial segmentation results and then manually fix segmentation errors.
",2.1 An L2-L1 Parallel Corpus,[0],[0]
"The dataset includes four typologically different mother tongues, i.e., English (ENG), Japanese (JPN), Russian (RUS) and Arabic (ARA).",2.1 An L2-L1 Parallel Corpus,[0],[0]
Subcorpus of each language consists of 150 sentence pairs.,2.1 An L2-L1 Parallel Corpus,[0],[0]
"We take the mother languages of the learners into consideration, which have a great impact on grammatical errors and hence automatic semantic analysis.",2.1 An L2-L1 Parallel Corpus,[0],[0]
We hope that four selected mother tongues guarantee a good coverage of typologies.,2.1 An L2-L1 Parallel Corpus,[0],[0]
The annotated corpus can be used both for linguistic investigation and as test data for NLP systems.,2.1 An L2-L1 Parallel Corpus,[0],[0]
Semantic role labeling (SRL) is the process of assigning semantic roles to constituents or their head words in a sentence according to their relationship to the predicates expressed in the sentence.,2.2 The Annotation Process,[0],[0]
Typical semantic roles can be divided into core arguments and adjuncts.,2.2 The Annotation Process,[0],[0]
"The core arguments include Agent, Patient, Source, Goal, etc, while the adjuncts include Location, Time, Manner, Cause, etc.
To create a standard semantic-role-labeled corpus for learner Chinese, we first annotate a 50- sentence trial set for each native language.",2.2 The Annotation Process,[0],[0]
Two senior students majoring in Applied Linguistics conducted the annotation.,2.2 The Annotation Process,[0],[0]
"Based on a total of 400 sentences, we adjudicate an initial gold standard, adapting and refining CPB specification as our annotation heuristics.",2.2 The Annotation Process,[0],[0]
Then the two annotators proceed to annotate a 100-sentence set for each language independently.,2.2 The Annotation Process,[0],[0]
"It is on these larger sets that we report the inter-annotator agreement.
",2.2 The Annotation Process,[0],[0]
"In the final stage, we also produce an adjudicated gold standard for all 600 annotated sentences.",2.2 The Annotation Process,[0],[0]
"This was achieved by comparing the anno-
tations selected by each annotator, discussing the differences, and either selecting one as fully correct or creating a hybrid representing the consensus decision for each choice point.",2.2 The Annotation Process,[0],[0]
"When we felt that the decisions were not already fully guided by the existing annotation guidelines, we worked to articulate an extension to the guidelines that would support the decision.
",2.2 The Annotation Process,[0],[0]
"During the annotation, the annotators apply both position labels and semantic role labels.",2.2 The Annotation Process,[0],[0]
"Position labels include S, B, I and E, which are used to mark whether the word is an argument by itself, or at the beginning or in the middle or at the end of a argument.",2.2 The Annotation Process,[0],[0]
"As for role labels, we mainly apply representations defined by CPB (Xue and Palmer, 2009).",2.2 The Annotation Process,[0],[0]
"The predicate in a sentence was labeled as rel, the core semantic roles were labeled as AN and the adjuncts were labeled as AM.",2.2 The Annotation Process,[0],[0]
"For inter-annotator agreement, we evaluate the precision (P), recall (R), and F1-score (F) of the semantic labels given by the two annotators.",2.3 Inter-annotator Agreement,[0],[0]
Table 1 shows that our inter-annotator agreement is promising.,2.3 Inter-annotator Agreement,[0],[0]
"All L1 texts have F-score above 95, and we take this as a reflection that our annotators are qualified.",2.3 Inter-annotator Agreement,[0],[0]
"F-scores on L2 sentences are all above 90, just a little bit lower than those of L1, indicating that L2 sentences can be greatly understood by native speakers.",2.3 Inter-annotator Agreement,[0],[0]
"Only modest rules are needed to handle some tricky phenomena:
1.",2.3 Inter-annotator Agreement,[0],[0]
"The labeled argument should be strictly limited to the core roles defined in the frameset of CPB, though the number of arguments in L2 sentences may be more or less than the number defined.
2.",2.3 Inter-annotator Agreement,[0],[0]
"For the roles in L2 that cannot be labeled as arguments under the specification of CPB, if they provide semantic information such as time, location and reason, we would labeled them as adjuncts though they may not be well-formed adjuncts due to the absence of function words.
3.",2.3 Inter-annotator Agreement,[0],[0]
"For unnecessary roles in L2 caused by mistakes of verb subcategorization (see examples in Figure 3b), we would leave those roles unlabeled.
",2.3 Inter-annotator Agreement,[0],[0]
"Table 2 further reports agreements on each argument (AN) and adjunct (AM) in detail, according
to which the high scores are attributed to the high agreement on arguments (AN).",2.3 Inter-annotator Agreement,[0],[0]
"The labels of A3 and A4 have no disagreement since they are sparse in CPB and are usually used to label specific semantic roles that have little ambiguity.
",2.3 Inter-annotator Agreement,[0],[0]
We also conducted in-depth analysis on interannotator disagreement.,2.3 Inter-annotator Agreement,[0],[0]
"For further details, please refer to Duan et al. (2018).",2.3 Inter-annotator Agreement,[0],[0]
The work on SRL has included a broad spectrum of machine learning and deep learning approaches to the task.,3.1 Three SRL Systems,[0],[0]
"Early work showed that syntactic information is crucial for learning longrange dependencies, syntactic constituency structure and global constraints (Punyakanok et al., 2008; Täckström",3.1 Three SRL Systems,[0],[0]
"et al., 2015), while initial studies on neural methods achieved state-of-the-art results with little to no syntactic input (Zhou and Xu, 2015; Wang et al., 2015; Marcheggiani et al., 2017; He et al., 2017).",3.1 Three SRL Systems,[0],[0]
"However, the question whether fully labeled syntactic structures provide an improvement for neural SRL is still unsettled pending further investigation.
",3.1 Three SRL Systems,[0],[0]
"To evaluate the robustness of state-of-the-art SRL algorithms, we evaluate two representative SRL frameworks.",3.1 Three SRL Systems,[0],[0]
"One is a traditional syntaxbased SRL system that leverages a syntactic parser and manually crafted features to obtain explicit information to find semantic roles (Gildea and Jurafsky, 2000; Xue, 2008)",3.1 Three SRL Systems,[0],[0]
"In particular, we employ the system introduced in Feng et al. (2012).",3.1 Three SRL Systems,[0],[0]
This system first collects all c-commanders of a predicate in question from the output of a parser and puts them in order.,3.1 Three SRL Systems,[0],[0]
"It then employs a first order linear-chain global linear model to perform
semantic tagging.",3.1 Three SRL Systems,[0],[0]
"For constituent parsing, we use two parsers for comparison, one is Berkeley parser3 (Petrov et al., 2006), a well-known implementation of the unlexicalized latent variable PCFG model, the other is a minimal span-based neural parser based on independent scoring of labels and spans (Stern et al., 2017).",3.1 Three SRL Systems,[0],[0]
"As proposed in Stern et al. (2017), the second parser is capable of achieving state-of-the-art single-model performance on the Penn Treebank.",3.1 Three SRL Systems,[0],[0]
"On the Chinese TreeBank (CTB; Xue et al., 2005), it also outperforms the Berkeley parser for the in-domain test.",3.1 Three SRL Systems,[0],[0]
"We call the corresponding SRL systems as the PCFGLA-parser-based and neural-parserbased systems.
",3.1 Three SRL Systems,[0],[0]
"The second SRL framework leverages an endto-end neural model to implicitly capture local and non-local information (Zhou and Xu, 2015; He et al., 2017).",3.1 Three SRL Systems,[0],[0]
"In particular, this framework treats SRL as a BIO tagging problem and uses a stacked BiLSTM to find informative embeddings.",3.1 Three SRL Systems,[0],[0]
We apply the system introduced in He et al. (2017) for experiments.,3.1 Three SRL Systems,[0],[0]
"Because all syntactic information (including POS tags) is excluded, we call this system the neural syntax-agnostic system.
",3.1 Three SRL Systems,[0],[0]
"To train the three SRL systems as well as the supporting parsers, we use the CTB and CPB data 4.",3.1 Three SRL Systems,[0],[0]
"In particular, the sentences selected for the CoNLL 2009 shared task are used here for parameter estimation.",3.1 Three SRL Systems,[0],[0]
"Note that, since the Berkeley parser is based on PCFGLA grammar, it may fail to get the syntactic outputs for some sentences, while the other parser does not have that problem.",3.1 Three SRL Systems,[0],[0]
"In this case, we have made sure that both parsers can parse all 1,200 sentences successfully.",3.1 Three SRL Systems,[0],[0]
The overall performances of the three SRL systems on both L1 and L2 data (150 parallel sentences for each mother tongue) are shown in Table 3.,3.2 Main Results,[0],[0]
"For all systems, significant decreases on different mother languages can be consistently observed, highlighting the weakness of applying L1sentence-trained systems to process learner texts.",3.2 Main Results,[0],[0]
"Comparing the two syntax-based systems with the neural syntax-agnostic system, we find that the overall ∆F, which denotes the F-score drop from L1 to L2, is smaller in the syntax-based framework
3code.google.com/p/berkeleyparser/",3.2 Main Results,[0],[0]
4Here we only use the trees that has semantic role annotations for parser training.,3.2 Main Results,[0],[0]
"This setup keeps us from overestimating the contribution of a parser.
than in the syntax-agnostic system.",3.2 Main Results,[0],[0]
"On English, Japanese and Russian L2 sentences, the syntaxbased system has better performances though it sometimes works worse on the corresponding L1 sentences, indicating the syntax-based systems are more robust when handling learner texts.
",3.2 Main Results,[0],[0]
"Furthermore, the neural-parser-based system achieves the best overall performance on the L2 data.",3.2 Main Results,[0],[0]
"Though performing slightly worse than the neural syntax-agnostic one on the L1 data, it has much smaller ∆F, showing that as the syntactic analysis improves, the performances on both the L1 and L2 data grow, while the gap can be maintained.",3.2 Main Results,[0],[0]
"This demonstrates again the importance of syntax in semantic constructions, especially for learner texts.",3.2 Main Results,[0],[0]
"To better understand the overall results, we further look deep into the output by addressing the questions:
1.",3.3 Analysis,[0],[0]
"What types of error negatively impact both systems over learner texts?
2.",3.3 Analysis,[0],[0]
"What types of error are more problematic for the neural syntax-agnostic one over the L2 data but can be solved by the syntax-based one to some extent?
",3.3 Analysis,[0],[0]
We first carry out a suite of empirical investigations by breaking down error types for more detailed evaluation.,3.3 Analysis,[0],[0]
"To compare two systems, we analyze results on ENG-L2 and JPN-L2 given that they reflect significant advantages of the syntaxbased systems over the neural syntax-agnostic system.",3.3 Analysis,[0],[0]
Note that the syntax-based system here refers to the neural-parser-based one.,3.3 Analysis,[0],[0]
"Finally, a concrete
study on the instances in the output is conducted, as to validate conclusions in the previous step.",3.3 Analysis,[0],[0]
"We employ 6 oracle transformations designed by He et al. (2017) to fix various prediction errors sequentially (see details in Table 4), and observe the relative improvements after each operation, as to obtain fine-grained error types.",3.3.1 Breaking down Error Types,[0],[0]
Figure 1 compares two systems in terms of different mistakes on ENG-L2 and JPN-L2 respectively.,3.3.1 Breaking down Error Types,[0],[0]
"After fixing the boundaries of spans, the neural syntaxagnostic system catches up with the other, illustrating that though both systems handle boundary detection poorly on the L2 sentences, the neural syntax-agnostic one suffers more from this type of errors.
",3.3.1 Breaking down Error Types,[0],[0]
"Excluding boundary errors (after moving, merg-
ing, splitting spans and fixing boundaries), we also compare two systems on L2 in terms of detailed label identification, so as to observe which semantic role is more likely to be incorrectly labeled.",3.3.1 Breaking down Error Types,[0],[0]
Figure 2 shows the confusion matrices.,3.3.1 Breaking down Error Types,[0],[0]
"Comparing (a) with (c) and (b) with (d), we can see that the syntax-based and the neural system often overly label A1 when processing learner texts.",3.3.1 Breaking down Error Types,[0],[0]
"Besides, the neural syntax-agnostic system predicts the adjunct AM more than necessary on L2 sentences by 54.24% compared with the syntax-based one.",3.3.1 Breaking down Error Types,[0],[0]
"On the basis of typical error types found in the previous stage, specifically, boundary detection and incorrect labels, we further conduct an on-the-spot investigation on the output sentences.
",3.3.2 Examples for Validation,[0],[0]
"Boundary Detection Previous work has proposed that the drop in performance of SRL systems mainly occurs in identifying argument boundaries (Màrquez et al., 2008).",3.3.2 Examples for Validation,[0],[0]
"According to our results, this problem will be exacerbated when it comes to L2 sentences, while syntactic structure sometimes helps to address this problem.
",3.3.2 Examples for Validation,[0],[0]
Figure 3a is an example of an output sentence.,3.3.2 Examples for Validation,[0],[0]
"The Chinese word “也” (also) usually serves as an adjunct but is now used for linking the parallel structure “用汉语也说话快” (using Chinese also speaking quickly) in this sentence, which is ill-formed to native speakers and negatively affects the boundary detection of A0 for both systems.
",3.3.2 Examples for Validation,[0],[0]
"On the other hand, the neural system incorrectly takes the whole part before “很难” (very hard) as A0, regardless of the adjunct “对 我 来说” (for me), while this can be figured out by exploiting syntactic analysis, as illustrated in Figure 3c.",3.3.2 Examples for Validation,[0],[0]
"The constituent “对我来说” (for me) has been recognized as a prepositional phrase (PP) attached to the VP, thus labeled as AM.",3.3.2 Examples for Validation,[0],[0]
"This shows that by providing information of some well-formed sub-trees associated with correct semantic roles, the syntactic system can perform better than the neural one on SRL for learner texts.
",3.3.2 Examples for Validation,[0],[0]
Mistaken Labels,3.3.2 Examples for Validation,[0],[0]
"A second common source of errors is wrong labels, especially for A1.",3.3.2 Examples for Validation,[0],[0]
"Based on our quantitative analysis, as reported in Table 5,
these phenomena are mainly caused by mistakes of verb subcategorization, where the systems label more arguments than allowed by the predicates.",3.3.2 Examples for Validation,[0],[0]
"Besides, the deep end-to-end system is also likely to incorrectly attach adjuncts AM to the predicates.
",3.3.2 Examples for Validation,[0],[0]
Figure 3b is another example.,3.3.2 Examples for Validation,[0],[0]
"The Chinese verb “做饭” (cook-meal) is intransitive while this sentence takes it as a transitive verb, which is very common in L2.",3.3.2 Examples for Validation,[0],[0]
"Lacking in proper verb subcategorization, both two systems fail to recognize those verbs allowing only one argument and label the A1 incorrectly.
",3.3.2 Examples for Validation,[0],[0]
"As for AM, the neural system mistakenly adds the adjunct to the predicate, which can be avoided by syntactic information of the sentence shown in Figure 3d.",3.3.2 Examples for Validation,[0],[0]
"The constituent “常常” (often) are adjuncts attached to VP structure governed by the
verb “练习”(practice), which will not be labeled as AM in terms of the verb “做饭”(cook-meal).",3.3.2 Examples for Validation,[0],[0]
"In other words, the hierarchical structure can help in argument identification and assignment by exploiting local information.",3.3.2 Examples for Validation,[0],[0]
We explore the valuable information about the semantic coherency encoded in the L2-L1 parallel data to improve SRL for learner Chinese.,4 Enhancing SRL with L2-L1 Parallel Data,[0],[0]
"In particular, we introduce an agreement-based model to search for high-quality automatic syntactic and semantic role annotations, and then use these annotations to retrain the two parser-based SRL systems.",4 Enhancing SRL with L2-L1 Parallel Data,[0],[0]
"For the purpose of harvesting the good automatic syntactic and semantic analysis, we consider the consistency between the automatically produced analysis of a learner sentence and its corresponding well-formed sentence.",4.1 The Method,[0],[0]
"Determining the measurement metric for comparing predicate– argument structures, however, presents another challenge, because the words of the L2 sentence
and its L1 counterpart do not necessarily match.",4.1 The Method,[0],[0]
"To solve the problem, we use an automatic word aligner.",4.1 The Method,[0],[0]
"BerkeleyAligner5 (Liang et al., 2006), a state-of-the-art tool for obtaining a word alignment, is utilized.
",4.1 The Method,[0],[0]
"The metric for comparing SRL results of two sentences is based on recall of 〈wp, wa, r〉 tuples, where wp is a predicate, wa is a word that is in the argument or adjunct of wp and r is the corresponding role.",4.1 The Method,[0],[0]
"Based on a word alignment, we define the shared tuple as a mutual tuple between two SRL results of an L2-L1 sentence pair, meaning that both the predicate and argument words are aligned respectively, and their role relations are the same.",4.1 The Method,[0],[0]
"We then have two recall values:
• L2-recall is (# of shared tuples) /",4.1 The Method,[0],[0]
"(# of tuples of the result in L2)
• L1-recall is (# of shared tuples) /",4.1 The Method,[0],[0]
"(# of tuples of the result in L1)
",4.1 The Method,[0],[0]
"In accordance with the above evaluation method, we select the automatic analysis of highest scoring sentences and use them to expand the training data.",4.1 The Method,[0],[0]
Sentences whose L1 and L2 recall are both greater than a threshold p are taken as good ones.,4.1 The Method,[0],[0]
A parser-based SRL system consists of two essential modules: a syntactic parser and a semantic classifier.,4.1 The Method,[0],[0]
"To enhance the syntactic parser, the automatically generated syntactic trees of the sentence pairs that exhibit high semantic consistency are directly used to extend training data.",4.1 The Method,[0],[0]
"To improve a semantic classifier, besides the consistent semantic analysis, we also use the outputs of the L1 but not L2 data which are generated by the neural syntax-agnostic SRL system.",4.1 The Method,[0],[0]
Our SRL corpus contains 1200 sentences in total that can be used as an evaluation for SRL systems.,4.2 Experimental Setup,[0],[0]
We separate them into three data sets.,4.2 Experimental Setup,[0],[0]
"The first data set is used as development data, which contains 50 L2-L1 sentence pairs for each language and 200 pairs in total.",4.2 Experimental Setup,[0],[0]
Hyperparameters are tuned using the development set.,4.2 Experimental Setup,[0],[0]
"The second data set contains all other 400 L2 sentences, which is used as test data for L2.",4.2 Experimental Setup,[0],[0]
"Similarly, all other 400 L1 sentences are used as test data for L1.
",4.2 Experimental Setup,[0],[0]
"The sentence pool for extracting retraining annotations includes all English- and Japanese-
5code.google.com/archive/p/ berkeleyaligner/
native speakers’ data along with its corrections.",4.2 Experimental Setup,[0],[0]
Table 6 presents the basic statistics.,4.2 Experimental Setup,[0],[0]
"Around 8.5 – 11.9% of the sentence can be taken as high L1/L2 recall sentences, which serves as a reflection that argument structure is vital for language acquisition and difficult for learners to master, as proposed in Vázquez (2004) and Shin (2010).",4.2 Experimental Setup,[0],[0]
The threshold (p = 0.9) for selecting sentences is set upon the development data.,4.2 Experimental Setup,[0],[0]
"For example, we use additional 156,520 sentences to enhance the Berkeley parser.",4.2 Experimental Setup,[0],[0]
Table 7 summarizes the SRL results of the baseline PCFGLA-parser-based model as well as its corresponding retrained models.,4.3 Main Results,[0],[0]
"Since both the syntactic parser and the SRL classifier can be retrained and thus enhanced, we report the individual impact as well as the combined one.",4.3 Main Results,[0],[0]
"We can clearly see that when the PCFGLA parser is retrained with the SRL-consistent sentence pairs, it is able to provide better SRL-oriented syntactic analysis for the L2 sentences as well as their corrections, which are essentially L1 sentences.",4.3 Main Results,[0],[0]
The outputs of the L1 sentences that are generated by the deep SRL system are also useful for improving the linear SRL classifier.,4.3 Main Results,[0],[0]
A non-obvious fact is that such a retrained model yields better analysis for not only L1 but also L2 sentences.,4.3 Main Results,[0],[0]
"Fortunately, combining both results in further improvement.
",4.3 Main Results,[0],[0]
Table 8 shows the results of the parallel experiments based on the neural parser.,4.3 Main Results,[0],[0]
"Different from the PCFGLA model, the SRL-consistent trees only yield a slight improvement on the L2
data.",4.3 Main Results,[0],[0]
"On the contrary, retraining the SRL classifier is much more effective.",4.3 Main Results,[0],[0]
This experiment highlights the different strengths of different frameworks for parsing.,4.3 Main Results,[0],[0]
"Though for standard in-domain test, the neural parser performs better and thus is more and more popular, for some other scenarios, the PCFGLA model is stronger.
",4.3 Main Results,[0],[0]
Table 9 further shows F-scores for the baseline and the both-retrained model relative to each role type in detail.,4.3 Main Results,[0],[0]
"Given that the F-scores for both models are equal to 0 on A3 and A4, we just omit this part.",4.3 Main Results,[0],[0]
"From the figure we can observe that, all the semantic roles achieve significant improvements in performances.",4.3 Main Results,[0],[0]
Statistical models of annotating learner texts are making rapid progress.,5 Conclusion,[0],[0]
"Although there have been some initial studies on defining annotation specification as well as corpora for syntactic analysis, there is almost no work on semantic parsing for interlanguages.",5 Conclusion,[0],[0]
"This paper discusses this topic, taking Semantic Role Labeling as a case task and learner Chinese as a case language.",5 Conclusion,[0],[0]
"We reveal three unknown facts that are important towards a deeper analysis of learner languages: (1) the robustness of language comprehension for interlanguage, (2) the weakness of applying L1-sentence-
trained systems to process learner texts, and (3) the significance of syntactic parsing and L2-L1 parallel data in building more generalizable SRL models that transfer better to L2.",5 Conclusion,[0],[0]
"We have successfully provided a better SRL-oriented syntactic parser as well as a semantic classifier for processing the L2 data by exploring L2-L1 parallel data, supported by a significant numeric improvement over a number of state-of-the-art systems.",5 Conclusion,[0],[0]
"To the best of our knowledge, this is the first work that demonstrates the effectiveness of large-scale L2-L1 parallel data to enhance the NLP system for learner texts.",5 Conclusion,[0],[0]
"This work was supported by the National Natural Science Foundation of China (61772036, 61331011) and the Key Laboratory of Science, Technology and Standard in Press Industry (Key Laboratory of Intelligent Press Media Technology).",Acknowledgement,[0],[0]
We thank the anonymous reviewers and for their helpful comments.,Acknowledgement,[0],[0]
We also thank Nianwen Xue for useful comments on the final version.,Acknowledgement,[0],[0]
Weiwei Sun is the corresponding author.,Acknowledgement,[0],[0]
"This paper studies semantic parsing for interlanguage (L21), taking semantic role labeling (SRL) as a case task and learner Chinese as a case language.",abstractText,[0],[0]
We first manually annotate the semantic roles for a set of learner texts to derive a gold standard for automatic SRL.,abstractText,[0],[0]
"Based on the new data, we then evaluate three off-the-shelf SRL systems, i.e., the PCFGLA-parser-based, neural-parserbased and neural-syntax-agnostic systems, to gauge how successful SRL for learner Chinese can be.",abstractText,[0],[0]
"We find two non-obvious facts: 1) the L1-sentence-trained systems performs rather badly on the L2 data; 2) the performance drop from the L1 data to the L2 data of the two parser-based systems is much smaller, indicating the importance of syntactic parsing in SRL for interlanguages.",abstractText,[0],[0]
"Finally, the paper introduces a new agreement-based model to explore the semantic coherency information in the large-scale L2-L1 parallel data.",abstractText,[0],[0]
We then show such information is very effective to enhance SRL for learner texts.,abstractText,[0],[0]
"Our model achieves an F-score of 72.06, which is a 2.02 point improvement over the best baseline.",abstractText,[0],[0]
Semantic Role Labeling for Learner Chinese: the Importance of Syntactic Parsing and L2-L1 Parallel Data,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 685–696 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
Text simplification (TS) addresses the translation of an input sentence into one or more simpler sentences.,1 Introduction,[0],[0]
"It is a useful preprocessing step for several NLP tasks, such as machine translation (Chandrasekar et al., 1996; Mishra et al., 2014) and relation extraction (Niklaus et al., 2016), and has also been shown useful in the development of reading aids, e.g., for people with dyslexia (Rello et al., 2013) or non-native speakers (Siddharthan, 2002).
",1 Introduction,[0],[0]
"The task has attracted much attention in the past decade (Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Siddharthan and Angrosh, 2014; Narayan and Gardent, 2014), but has yet to converge on an evaluation protocol that yields comparable results across different methods and strongly correlates with human judgments.",1 Introduction,[0],[0]
"This is in part due to the difficulty to combine the effects of different simplification operations
1All data and code are available in https://github.",1 Introduction,[0],[0]
"com/eliorsulem/SAMSA.
",1 Introduction,[0],[0]
"(e.g., deletion, splitting and substitution).",1 Introduction,[0],[0]
"Xu et al. (2016) has recently made considerable progress towards that goal, and proposed to tackle it both by using an improved reference-based measure, named SARI, and by increasing the number of references.",1 Introduction,[0],[0]
"However, their research focused on lexical, rather than structural simplification, which provides a complementary view of TS quality as this paper will show.
",1 Introduction,[0],[0]
This paper focuses on the evaluation of the structural aspects of the task.,1 Introduction,[0],[0]
"We introduce the semantic measure SAMSA (Simplification Automatic evaluation Measure through Semantic Annotation), the first structure-aware measure for TS in general, and the first to use semantic structure in this context in particular.",1 Introduction,[0],[0]
"SAMSA stipulates that an optimal split of the input is one where each predicate-argument structure is assigned its own sentence, and measures to what extent this assertion holds for the input-output pair in question, by using semantic structure.",1 Introduction,[0],[0]
"SAMSA focuses on the core semantic components of the sentence, and is tolerant towards the deletion of other units.2
For example, SAMSA will assign a high score to the output split “John got home.",1 Introduction,[0],[0]
John gave Mary a call.”,1 Introduction,[0],[0]
"for the input sentence “John got home and gave Mary a call.”, as it splits each of its predicate-argument structures to a different sentence.",1 Introduction,[0],[0]
Splits that alter predicate-argument relations such as “John got home and gave.,1 Introduction,[0],[0]
"Mary called.” are penalized by SAMSA.
SAMSA’s use of semantic structures for TS evaluation has several motivations.",1 Introduction,[0],[0]
"First, it provides means to measure the extent to which the meaning of the source is preserved in the output.",1 Introduction,[0],[0]
"Second, it provides means for measuring whether the input sentence was split to semantic units of
2We do not consider other structural operations, such as passive to active transformations (Canning, 2002), that are currently not treated by corpus-based simplification systems.
",1 Introduction,[0],[0]
"685
the right granularity.",1 Introduction,[0],[0]
"Third, defining a semantic measure that does not require references avoids the difficulties incurred by their non-uniqueness, and the difficulty in collecting high quality references, as reported by Xu et al. (2015) and by Narayan and Gardent (2014) with respect to the Parallel Wikipedia Corpus (PWKP; Zhu et al., 2010).",1 Introduction,[0],[0]
"SAMSA is further motivated by its use of semantic annotation only on the source side, which allows to evaluate multiple systems using same source-side annotation, and avoids the need to parse system outputs, which can be garbled.
",1 Introduction,[0],[0]
"In this paper we use the UCCA scheme for defining semantic structure (Abend and Rappoport, 2013).",1 Introduction,[0],[0]
"UCCA has been shown to be preserved remarkably well across translations (Sulem et al., 2015) and has also been successfully used for machine translation evaluation (Birch et al., 2016) (Section 2).",1 Introduction,[0],[0]
"We note, however, that SAMSA can be adapted to work with any semantic scheme that captures predicate-argument relations, such as AMR (Banarescu et al., 2013) or Discourse Representation Structures (Kamp, 1981), as used by Narayan and Gardent (2014).
",1 Introduction,[0],[0]
"We experiment with SAMSA both where semantic annotation is carried out manually, and where it is carried out by a parser.",1 Introduction,[0],[0]
See Section 4.,1 Introduction,[0],[0]
We conduct human rating experiments and compare the resulting system rankings with those predicted by SAMSA.,1 Introduction,[0],[0]
"We find that SAMSA’s rankings obtain high correlations with human rankings, and compare favorably to existing referencebased measures for TS.",1 Introduction,[0],[0]
"Moreover, our results show that existing measures, which mainly target lexical simplification, are ill-suited to predict human judgments where structural simplification is involved.",1 Introduction,[0],[0]
"Finally, we apply SAMSA to the dataset of the QATS shared task on simplification evaluation (Štajner et al., 2016).",1 Introduction,[0],[0]
"We find that SAMSA obtains comparative correlation with human judgments on the task, despite operating in a more restricted setting, as it does not use human ratings as training data and focuses only on structural aspects of simplicity.",1 Introduction,[0],[0]
Section 2 presents previous work.,1 Introduction,[0],[0]
Section 3 discusses UCCA.,1 Introduction,[0],[0]
Section 4 presents SAMSA.,1 Introduction,[0],[0]
Section 5 details the collection of human judgments.,1 Introduction,[0],[0]
"Our experimental setup for comparing our human and automatic rankings is given in Section 6, and results are given in Section 7, showing superior results for SAMSA.",1 Introduction,[0],[0]
"A discussion on the results is presented in Section 8.
",1 Introduction,[0],[0]
Section 9 presents experiments with SAMSA on the QATS evaluation benchmark.,1 Introduction,[0],[0]
Evaluation Metrics for Text Simplification.,2 Related Work,[0],[0]
"As pointed out by Xu et al. (2016), many of the existing measures for TS evaluation do not generalize across systems, because they fail to capture the combined effects of the different simplification operations.",2 Related Work,[0],[0]
The two main directions pursued are direct human judgments and automatic measures borrowed from machine translation (MT) evaluation.,2 Related Work,[0],[0]
"Human judgments generally include grammaticality (or fluency), meaning preservation (or adequacy) and simplicity.",2 Related Work,[0],[0]
"Human evaluation is usually carried out with a small number of sentences (18 to 20), randomly selected from the test set (Wubben et al., 2012; Narayan and Gardent, 2014, 2016).
",2 Related Work,[0],[0]
"The most commonly used automatic measure for TS is BLEU (Papineni et al., 2002).",2 Related Work,[0],[0]
"Using 20 source sentences from the PWKP test corpus with 5 simplified sentences for each of them, Wubben et al. (2012) investigated the correlation of BLEU with human evaluation, reporting positive correlation for simplicity, but no correlation for adequacy.",2 Related Work,[0],[0]
"Štajner et al. (2014) explored the correlation with human judgments of six automatic metrics: cosine similarity with a bag-of-words representation, METEOR (Denkowski and Lavie, 2011), TERp (Snover et al., 2009), TINE (Rios et al., 2011) and two sub-components of TINE: T-BLEU (a variant of BLEU which uses lower n-grams when no 4- grams are found) and SRL (based on semantic role labeling).",2 Related Work,[0],[0]
"Using 280 pairs of a source sentence and a simplified output with only structural modifications, they found positive correlations for all the metrics except TERp with respect to meaning preservation and positive albeit lower correlations for METEOR, T-BLEU and TINE with respect to grammaticality.",2 Related Work,[0],[0]
Human simplicity judgments were not considered in this experiment.,2 Related Work,[0],[0]
"In this paper we collect human judgments for grammaticality, meaning preservation and structural simplicity.",2 Related Work,[0],[0]
"To our knowledge, this is the first work to target structural simplicity evaluation, and it does so both through elicitation of human judgments and through the definition of SAMSA.
",2 Related Work,[0],[0]
"Xu et al. (2016) were the first to propose two evaluation measures tailored for simplification, focusing on lexical simplification.",2 Related Work,[0],[0]
"The first metric is FKBLEU, a combination of iBLEU (Sun
and Zhou, 2012), originally proposed for evaluating paraphrase generation by comparing the output both to the reference and to the input, and of the Flesch-Kincaid Index (FK), a measure of the readability of the text (Kincaid et al., 1975).",2 Related Work,[0],[0]
"The second one is SARI (System output Against References and against the Input sentence) which compares the n-grams of the system output with those of the input and the human references, separately evaluating the quality of words that are added, deleted and kept by the systems.",2 Related Work,[0],[0]
They found that FKBLEU and even more so SARI correlate better with human simplicity judgments than BLEU.,2 Related Work,[0],[0]
"On the other hand, BLEU (with multiple references) outperforms the other metrics on the dimensions of grammaticality and meaning preservation.
",2 Related Work,[0],[0]
"As the Parallel Wikipedia Corpus (PWKP), usually used in simplification research, has been shown to contain a large portion of problematic simplifications (Xu et al., 2015; Hwang et al., 2015), Xu et al. (2016) further proposed to use multiple references (instead of a single reference) in the evaluation measures.",2 Related Work,[0],[0]
"SAMSA addresses this issue by directly comparing the input and the output of the simplification system, without requiring manually curated references.
",2 Related Work,[0],[0]
Structural Measures for Text-to-text Generation.,2 Related Work,[0],[0]
"Other than measuring the number of splits (Narayan and Gardent, 2014, 2016), which only assesses the frequency of this operation and not its quality, no structural measures were previously proposed for the evaluation of structural simplification.",2 Related Work,[0],[0]
"The need for such a measure is pressing, given recent interest in structural simplification, e.g., in the Split and Rephrase task (Narayan et al., 2017), which focuses on sentence splitting.
",2 Related Work,[0],[0]
"In the task of sentence compression, which is similar to simplification in that they both involve deletion and paraphrasing, Clarke and Lapata (2006) showed that a metric that uses syntactic dependencies better correlates with human evaluation than a metric based on surface sub-strings.",2 Related Work,[0],[0]
"Toutanova et al. (2016) found that structure-aware metrics obtain higher correlation with human evaluation over bigram-based metrics, in particular with grammaticality judgments, but that they do not significantly outperform bigram-based metrics on any parameter.",2 Related Work,[0],[0]
Both Clarke and Lapata (2006) and Toutanova et al. (2016) use reference-based metrics that use syntactic structure on both the output and the references.,2 Related Work,[0],[0]
"SAMSA on the other hand
uses linguistic annotation only on the source side, with semantic structures instead of syntactic ones.
",2 Related Work,[0],[0]
"Semantic structures were used in MT evaluation, for example in the MEANT metric (Lo et al., 2012), which compares the output and the reference sentences, both annotated using SRL (Semantic Role Labeling).",2 Related Work,[0],[0]
"Lo et al. (2014) proposes the XMEANT variant, which compares the SRL structures of the source and output (without using references).",2 Related Work,[0],[0]
"As some frequent constructions like nominal argument structures are not addressed by the SRL annotation, Birch et al. (2016) proposed HUME, a human evaluation metric based on UCCA, using the semantic annotation only on the source side when comparing it to the output.",2 Related Work,[0],[0]
"We differ from HUME in proposing an automatic metric, tackling monolingual text simplification, rather than MT.
",2 Related Work,[0],[0]
The UCCA annotation has also been recently used for the evaluation of Grammatical Error Correction (GEC).,2 Related Work,[0],[0]
"The USIM metric (Choshen and Abend, 2018) measures the semantic faithfulness of the output to the source by comparing their respective UCCA graphs.
",2 Related Work,[0],[0]
Semantic Structures in Text Simplification.,2 Related Work,[0],[0]
"In most of the work investigating the structural operations involved in text simplification, both in rulebased systems (Siddharthan and Angrosh, 2014) and in statistical systems (Zhu et al., 2010; Woodsend and Lapata, 2011), the structures that were considered were syntactic.",2 Related Work,[0],[0]
"Narayan and Gardent (2014, 2016) proposed to use semantic structures in the simplification model, in particular in order to avoid splits and deletions which are inconsistent with the semantic structures.",2 Related Work,[0],[0]
"SAMSA identifies such incoherent splits, e.g., a split of a phrase describing a single event, and penalizes them.
",2 Related Work,[0],[0]
Glavas and Štajner (2013) presented two simplification systems based on event extraction.,2 Related Work,[0],[0]
"One of them, named Event-wise Simplification, transforms each factual event motion into a separate sentence.",2 Related Work,[0],[0]
"This approach fits with SAMSA’s stipulation, that an optimal structural simplification is one where each (UCCA-) event in the input sentence is assigned a separate output sentence.",2 Related Work,[0],[0]
"However, unlike in their model, SAMSA stipulates that not only should multiple events evoked by a verb in the same sentence be avoided in a simplification, but penalizes sentences containing multiple events evoked by a lexical item of any category.",2 Related Work,[0],[0]
"For example, the sentence “John’s un-
expected kick towards the gate saved the game” which has two events, one evoked by “kick” (a noun) and another by “saving” (a verb) can be converted to “John kicked the ball towards the gate.",2 Related Work,[0],[0]
It saved the game.”,2 Related Work,[0],[0]
"In this section we will briefly describe the UCCA scheme, focusing on the concepts of Scenes and Centers which are key in the definition of SAMSA.",3 UCCA’s Semantic Structures,[0],[0]
"UCCA (Universal Cognitive Conceptual Annotation; Abend and Rappoport, 2013) is a semantic annotation scheme based on typological (Dixon, 2010b,a, 2012) and cognitive (Langacker, 2008) theories which aims to represent the main semantic phenomena in the text, abstracting away from syntactic detail.",3 UCCA’s Semantic Structures,[0],[0]
UCCA structures are directed acyclic graphs whose nodes (or units) correspond either to the leaves of the graph (including the words of the text) or to several elements jointly viewed as a single entity according to some semantic or cognitive consideration.,3 UCCA’s Semantic Structures,[0],[0]
"Unlike AMR, UCCA semantic units are directly anchored in the text (Abend and Rappoport, 2017; Birch et al., 2016), which allows easy inclusion of a word-toword alignment in the metric model (Section 4).
",3 UCCA’s Semantic Structures,[0],[0]
UCCA Scenes.,3 UCCA’s Semantic Structures,[0],[0]
"A Scene, which is the most basic notion of the foundational layer of UCCA considered here, describes a movement, an action or a state which persists in time.",3 UCCA’s Semantic Structures,[0],[0]
"Every Scene contains one main relation, which can be either a Process or a State.",3 UCCA’s Semantic Structures,[0],[0]
"The Scene may contain one or more Participants, which are interpreted in a broad sense, including locations and destinations.",3 UCCA’s Semantic Structures,[0],[0]
"For example, the sentence “He ran into the park” has a single Scene whose Process is “ran”.",3 UCCA’s Semantic Structures,[0],[0]
"The two Participants are “He” and “into the park”.
",3 UCCA’s Semantic Structures,[0],[0]
Scenes can have several roles in the text.,3 UCCA’s Semantic Structures,[0],[0]
"First, they can provide additional information about an established entity (Elaborator Scenes) as for example the Scene “who entered the house” in the sentence “The man who entered the house is John”.",3 UCCA’s Semantic Structures,[0],[0]
"They can also be one of the Participants of another Scene, for example, “he will be late” in the sentence: “He said he will be late”.",3 UCCA’s Semantic Structures,[0],[0]
"In the other cases, the Scenes are annotated as parallel Scenes (H) which can be linked by a Linker (L): “WhenL [he will arrive at home]H , [he will call them]H”.
Unit Centers.",3 UCCA’s Semantic Structures,[0],[0]
"With regard to units which are not Scenes, the category Center denotes the semantic
head of the unit.",3 UCCA’s Semantic Structures,[0],[0]
"For example, “dogs” is the center of the expression “big brown dogs” and “box” is the center of “in the box”.",3 UCCA’s Semantic Structures,[0],[0]
"There could be more than one Center in a non-Scene unit, for example in the case of coordination, where all conjuncts are Centers.
4",3 UCCA’s Semantic Structures,[0],[0]
"The SAMSA Metric
SAMSA’s main premise is that a structurally correct simplification is one where: (1) each sentence contains a single event from the input (UCCA Scene), (2) the main relation of each of the events and their participants are retained in the output.
",3 UCCA’s Semantic Structures,[0],[0]
"For example, consider “John wrote a book.",3 UCCA’s Semantic Structures,[0],[0]
I read that book.”,3 UCCA’s Semantic Structures,[0],[0]
as a simplification of “I read the book that John wrote.”,3 UCCA’s Semantic Structures,[0],[0]
.,3 UCCA’s Semantic Structures,[0],[0]
"Each output sentence contains one Scene, which has the same Scene elements as the source, and would thus be deemed correct by SAMSA.",3 UCCA’s Semantic Structures,[0],[0]
"On the other hand, the output “John wrote.",3 UCCA’s Semantic Structures,[0],[0]
I read the book.”,3 UCCA’s Semantic Structures,[0],[0]
"is an incorrect split of that sentence, since a participant of the “writing” Scene, namely “the book” is absent in the split sentence.",3 UCCA’s Semantic Structures,[0],[0]
"SAMSA would indeed penalize such a case.
",3 UCCA’s Semantic Structures,[0],[0]
"Similarly, Scenes which have elements across several sentences receive a zero score by SAMSA.",3 UCCA’s Semantic Structures,[0],[0]
"As an example, consider the sentence “The combination of new weapons and tactics marks this battle as the end of chivalry”, and erroneous split “The combination of new weapons and tactics.",3 UCCA’s Semantic Structures,[0],[0]
It is the end of chivalry.”,3 UCCA’s Semantic Structures,[0],[0]
"(adapted from the output of a recent system on the PWKP corpus), which does not preserve the original meaning.",3 UCCA’s Semantic Structures,[0],[0]
SAMSA is based on two external linguistic resources.,4.1 Matching Scenes to Sentences,[0],[0]
"One is a semantic annotation (UCCA in our experiments) of the source side, which can be carried out either manually or automatically, using the TUPA parser3 (Transition-based UCCA parser; Hershcovich et al., 2017) for UCCA.",4.1 Matching Scenes to Sentences,[0],[0]
"UCCA decomposes each sentence s into a set of Scenes {sc1, sc2, .., scn}, where each scene sci contains a main relation mri (sub-span of sci) and a set of zero or more participants Ai.
",4.1 Matching Scenes to Sentences,[0],[0]
The second resource is a word-to-word alignment A between the words in the input and one or zero words in the output.,4.1 Matching Scenes to Sentences,[0],[0]
"The monolingual alignment thus permits SAMSA not to penalize outputs that involve lexical substitutions (e.g., “com-
3https://github.com/danielhers/tupa
mence” might be aligned with “start”).",4.1 Matching Scenes to Sentences,[0],[0]
"We denote by ninp the number of UCCA Scenes in the input sentence and by nout the number of sentences in the output.
",4.1 Matching Scenes to Sentences,[0],[0]
"Given an input sentence’s UCCA Scenes sc1, . . .",4.1 Matching Scenes to Sentences,[0],[0]
", scninp , a non-annotated output of a simplification system split into sentences s1, . . .",4.1 Matching Scenes to Sentences,[0],[0]
", snout , and their word alignment A, we distinguish between two cases: 1.",4.1 Matching Scenes to Sentences,[0],[0]
"ninp ≥ nout: in this case, we compute the
maximal Many-to-1 correspondence between Scenes and sentences.",4.1 Matching Scenes to Sentences,[0],[0]
A Scene is matched to a sentence in the following way.,4.1 Matching Scenes to Sentences,[0],[0]
"We say that a leaf l in a Scene sc is consistent in a Scenesentence mapping M which maps sc to a sentence s, if there is a word w ∈ s which l aligns to (according to the word alignment A).",4.1 Matching Scenes to Sentences,[0],[0]
The score of matching a Scene sc to a sentence s is then defined to be the total number of consistent leaves in sc.,4.1 Matching Scenes to Sentences,[0],[0]
"We traverse the Scenes in their order of occurrence in the text, selecting for each the sentence that maximizes the score.",4.1 Matching Scenes to Sentences,[0],[0]
"If ninp = nout, once a sentence is matched to a Scene, it cannot be matched to another one.",4.1 Matching Scenes to Sentences,[0],[0]
"Ties between sentences are broken towards the sentence that appeared first in the output.
M∗(sci) = argmaxsscore(sci, s)
s.t. s /∈",4.1 Matching Scenes to Sentences,[0],[0]
"{M∗(sc1), . . .",4.1 Matching Scenes to Sentences,[0],[0]
",M∗(sci−1)} if ninp = nout
2.",4.1 Matching Scenes to Sentences,[0],[0]
ninp < nout:,4.1 Matching Scenes to Sentences,[0],[0]
"In this case, a Scene will necessarily be split across several sentences.",4.1 Matching Scenes to Sentences,[0],[0]
"As this is an undesired result, we assign this instance a score of zero.",4.1 Matching Scenes to Sentences,[0],[0]
Minimal Centers.,4.2 Score Computation,[0],[0]
"The minimal center of a UCCA unit u is UCCA’s notion of a semantic head word, defined through recursive rules not unlike the head propagation rules used for converting constituency structures to dependency structures.",4.2 Score Computation,[0],[0]
"More formally, we define the minimal center of a UCCA unit u (here a Participant or a Main Relation) to be the UCCA graph’s leaf reached by starting from u and iteratively selecting the child tagged as Center.",4.2 Score Computation,[0],[0]
"If a Participant (or a Center inside a Participant) is a Scene, its center is the main relation (Process or State) of the Scene.
",4.2 Score Computation,[0],[0]
"For example, the center of the unit “The previous president of the commission” (u1) is “president of the commission”.",4.2 Score Computation,[0],[0]
"The center of the latter is “president”, which is a leaf in the graph.",4.2 Score Computation,[0],[0]
"So the minimal center of u1 is “president”.
",4.2 Score Computation,[0],[0]
"Given the input sentence Scenes {sc1, ..., scninp}, the output sentences {s1, ..., snout}, and a mapping between them M∗, SAMSA is defined as: nout
ninp
1
2ninp
∑
sci
[ 1M∗(sci)(MRi) + 1
ki
ki∑
j=1
1M∗(sci)(Par (j) i ) ]
where MRi is the minimal center of the main relation (Process or State) of sci, and Par (j) i (j = 1, . . .",4.2 Score Computation,[0],[0]
", ki) are the minimal centers of the Participants of sci.
",4.2 Score Computation,[0],[0]
"For an output sentence s, 1s(u) is a function from the input units to {0, 1}, which returns 1 iff u is aligned (according to A) with a word in s.4
The role of the non-splitting penalty term nout/ninp in the SAMSA formula is to penalize cases where the number of sentences in the output is smaller than the number of Scenes.",4.2 Score Computation,[0],[0]
"In order to isolate the effect of the non-splitting penalty, we experiment with an additional metric SAMSAabl (reads “SAMSA ablated”), which is identical to SAMSA but does not take this term into account.",4.2 Score Computation,[0],[0]
"Corpus-level SAMSA and SAMSAabl scores are obtained by averaging their sentence scores.
",4.2 Score Computation,[0],[0]
"In the case of implicit units i.e. omitted units that do not appear explicitly in the text (Abend and Rappoport, 2013), since the unit preservation cannot be directly captured, the score t for the relevant unit will be set to 0.5.",4.2 Score Computation,[0],[0]
"For example, in the Scene “traveling is fun”, the people who are traveling correspond to an implicit Participant.",4.2 Score Computation,[0],[0]
"As implicit units are not covered by TUPA, this will only be relevant for the semi-automatic implementation of the metric (see Section 6).",4.2 Score Computation,[0],[0]
"For testing the automatic metric, we first build a human evaluation benchmark, using 100 sentences from the complex part of the PWKP corpus and the outputs of six recent simplification systems for these sentences:5 (1) TSM (Zhu et al., 2010) using Tree-Based SMT, (2) RevILP (Woodsend and Lapata, 2011) using Quasi-Synchronous Grammars, (3) PBMT-R (Wubben et al., 2012) using PhraseBased SMT, (4) Hybrid (Narayan and Gardent,
4In some cases, the unit u can be a sequence of centers (if there are several minimal centers).",5.1 Evaluation Protocol,[0],[0]
"In these cases, 1s(u) returns 1 iff the condition holds for all centers.
",5.1 Evaluation Protocol,[0],[0]
"5All the data can be found here: http: //homepages.inf.ed.ac.uk/snaraya2/data/ simplification-2016.tgz.
2014), a supervised system using DRS, (5) UNSUP (Narayan and Gardent, 2016), an unsupervised system using DRS, and (6) Split-Deletion (Narayan and Gardent, 2016), the unsupervised system with only structural operations.
",5.1 Evaluation Protocol,[0],[0]
All these systems explicitly address at least one type of structural simplification operation.,5.1 Evaluation Protocol,[0],[0]
"The last system, Split-Deletion, performs only structural (i.e., no lexical) operations.",5.1 Evaluation Protocol,[0],[0]
It is thus an interesting test case for SAMSA since here the aligner can be replaced by a simple match between identical words.,5.1 Evaluation Protocol,[0],[0]
"In total we obtain 600 system outputs from the six systems, as well as 100 sentences from the simple Wikipedia side of the corpus, which serve as references.",5.1 Evaluation Protocol,[0],[0]
"Five in-house annotators with high proficiency in English evaluated the resulting 700 input-output pairs by answering the questions in Table 1.6
Qa addresses grammaticality, Qb and Qc capture two complementary aspects of meaning preservation (the addition and the removal of information) and Qd addresses structural simplicity.",5.1 Evaluation Protocol,[0],[0]
"Possible answers are: 1 (“no”), 2 (“maybe”) and 3 (“yes”).",5.1 Evaluation Protocol,[0],[0]
"Following Glavas and Štajner (2013), we used a 3 point Likert scale, which has recently been shown to be preferable over a 5 point scale through human studies on sentence compression (Toutanova et al., 2016).
",5.1 Evaluation Protocol,[0],[0]
"Question Qd was accompanied by a negative example 7 showing a case of lexical simplification, where a complex word is replaced by a simple one.",5.1 Evaluation Protocol,[0],[0]
"A positive example was not included so as not to bias the annotators by revealing the nature of the operations our experiments focus on (i.e., splitting and deletion).
",5.1 Evaluation Protocol,[0],[0]
"The PWKP test corpus (Zhu et al., 2010) was selected for our experiments over the development and test sets used in (Xu et al., 2016), as the latter’s selection process was explicitly biased towards input-output pairs that mainly contain lexical simplifications.
",5.1 Evaluation Protocol,[0],[0]
6Each input-output pair was rated by all five annotators.,5.1 Evaluation Protocol,[0],[0]
7Other questions appeared without any example.,5.1 Evaluation Protocol,[0],[0]
"Given the annotator’s answers, we consider the following scores.",5.2 Human Score Computation,[0],[0]
"First, the grammaticality score G is the answer to Qa.",5.2 Human Score Computation,[0],[0]
"By inverting (changing 1 to 3 and 3 to 1) the answer for Qb, we obtain a NonAddition score indicating to which extent no additional information has been added.",5.2 Human Score Computation,[0],[0]
"Similarly, inverting the answer to Qc yields the Non-Removal score.",5.2 Human Score Computation,[0],[0]
"Averaging these two scores, we obtain the meaning preservation score P .",5.2 Human Score Computation,[0],[0]
"Finally, the structural simplicity score S is the answer to Qd.",5.2 Human Score Computation,[0],[0]
Each of these scores is averaged over the five annotators.,5.2 Human Score Computation,[0],[0]
"We further compute an average human score:
AvgHuman = 1
3 (G + P + S)",5.2 Human Score Computation,[0],[0]
Inter-annotator agreement rates are computed in two ways.,5.3 Inter-annotator Agreement,[0],[0]
"Table 2 presents the absolute agreement and Cohen’s quadratic weighted κ (Cohen, 1968).",5.3 Inter-annotator Agreement,[0],[0]
"Table 3 presents Spearman’s correlation (ρ) between the human ratings of the input-output pairs (top row), and between the resulting system scores (bottom row).",5.3 Inter-annotator Agreement,[0],[0]
"In both cases, the agreement between the five annotators is computed as the average agreement over the 10 annotator pairs.",5.3 Inter-annotator Agreement,[0],[0]
We further compute SAMSA for the 100 sentences of the PWKP test set and the corresponding system outputs.,6 Experimental Setup,[0],[0]
"Experiments are conducted in two settings: (1) a semi-automatic setting where
UCCA annotation was carried out manually by a single expert UCCA annotator using the UCCAApp annotation software (Abend et al., 2017), and according to the standard annotation guidelines;8 (2) an automatic setting where the UCCA annotation was carried out by the TUPA parser (Hershcovich et al., 2017).",6 Experimental Setup,[0],[0]
"Sentence segmentation of the outputs was carried out using the NLTK package (Loper and Bird, 2002).",6 Experimental Setup,[0],[0]
"For word alignments, we used the aligner of Sultan et al. (2014).9",6 Experimental Setup,[0],[0]
We compare the system rankings obtained by SAMSA and by the four human parameters.,7 Correlation with Human Evaluation,[0],[0]
We find that the two leading systems according to AvgHuman and SAMSA turn out to be the same: Split-Deletion and RevILP.,7 Correlation with Human Evaluation,[0],[0]
This is the case both for the semi-automatic and the automatic implementations of the metric.,7 Correlation with Human Evaluation,[0],[0]
"A Spearman ρ correlation between the human and SAMSA scores (comparing their rankings) is presented in Table 4.
",7 Correlation with Human Evaluation,[0],[0]
We compare SAMSA and SAMSAabl to the reference-based measures SARI10,7 Correlation with Human Evaluation,[0],[0]
"(Xu et al., 2016) and BLEU, as well as to the negative Levenshtein distance to the reference (-LDSR).",7 Correlation with Human Evaluation,[0],[0]
"We use the only available reference for this corpus, in accordance with the standard practice.",7 Correlation with Human Evaluation,[0],[0]
"SARI is a reference-based measure, based on n-gram overlap between the source, output and reference, and focuses on lexical (rather than structural) simplification.",7 Correlation with Human Evaluation,[0],[0]
"For completeness, we include the other two measures reported in Narayan and Gardent (2016), which are measures of similarity to the input (i.e., they quantify the tendency of the systems to introduce changes to the input): the negative Levenshtein distances between the output and input compared to the original complex corpus (-LDSC), and the number of sentences split by each of the systems.
",7 Correlation with Human Evaluation,[0],[0]
"The highest correlation with AvgHuman and grammaticality is obtained by semi-automatic SAMSA (0.58 and 0.54), a high correlation especially in comparison to the inter-annotator agreement on AvgHuman (0.64, Table 3).",7 Correlation with Human Evaluation,[0],[0]
"The automatic version obtains high correlation with human judgments in these settings, where for struc-
8http://www.cs.huji.ac.il/˜oabend/ ucca.html
9https://github.com/ma-sultan/ monolingual-word-aligner
10Data and code for can be found in https://github.",7 Correlation with Human Evaluation,[0],[0]
"com/cocoxu/simplification.
",7 Correlation with Human Evaluation,[0],[0]
"tural simplicity, it scores somewhat higher than the semi-automatic SAMSA.",7 Correlation with Human Evaluation,[0],[0]
"The highest correlation with structural simplicity is obtained by the number of sentences with splitting, where SAMSA (automatic and semi-automatic) is second and third highest, although when restricted to multiScene sentences, the correlation for SAMSA (semi-automatic) is higher (0.89, p = 0.009 and 0.77, p = 0.04).
",7 Correlation with Human Evaluation,[0],[0]
"The highest correlation for meaning preservation is obtained by SAMSAabl which provides further evidence that the retainment of semantic structures is a strong predictor of meaning preservation (Sulem et al., 2015).",7 Correlation with Human Evaluation,[0],[0]
"SAMSA in itself does not correlate with meaning preservation, probably due to its penalization of under-splitting sentences.
",7 Correlation with Human Evaluation,[0],[0]
"Note that the standard reference-based measures for simplification, BLEU and SARI, obtain low and often negative correlation with human ratings.",7 Correlation with Human Evaluation,[0],[0]
"We believe that this is the case because SARI and BLEU admittedly focus on lexical simplification, and are difficult to use to rank systems which also perform structural simplification.
",7 Correlation with Human Evaluation,[0],[0]
Our results thus suggest that SAMSA provides additional value in predicting the quality of a simplification system and should be reported in tandem with more lexically-oriented measures.,7 Correlation with Human Evaluation,[0],[0]
Human evaluation parameters.,8 Discussion,[0],[0]
The fact that the highest correlations for structural simplicity and meaning preservation are obtained by different metrics (SAMSA and SAMSAabl respectively) highlights the complementarity of these two parameters for evaluating TS quality but also the difficulty of capturing them together.,8 Discussion,[0],[0]
"Indeed, a given sentence-level operation could both change the original meaning by adding or removing information (affecting the P score) and increase simplicity (S).",8 Discussion,[0],[0]
"On the other hand, the identity transformation perfectly preserves the meaning of the original sentence without making it simpler.
",8 Discussion,[0],[0]
"For examining this phenomenon, we compute Spearman’s correlation at the system-level between the simplicity and meaning preservation human scores.",8 Discussion,[0],[0]
We obtain a correlation of -0.77 (p = 0.04) between S and P .,8 Discussion,[0],[0]
"The correlation between S and the two sub-components of P , the Non-Addition and the Non-Removal scores, are -0.43 (p = 0.2) and -0.77 (p = 0.04) respectively.",8 Discussion,[0],[0]
"These negative correlations support our use
of an average human score for assessing the overall quality of the simplification.
",8 Discussion,[0],[0]
Distribution at the sentence level.,8 Discussion,[0],[0]
"In addition to the system-level analysis presented in Section 7, we also investigate the behavior of SAMSA at the sentence level by examining its joint distribution with the human evaluation scores.",8 Discussion,[0],[0]
"Focusing on the AvgHuman score and the automatic implementation of SAMSA and using the same data as in Section 7, we consider a single pair of scores (AvgHumani,SAMSAi), 1 ≤ i ≤ 100, for each of the 100 source sentences, averaging over the SAMSA and human scores obtained for the 6 simplification systems (See Figure 1).
",8 Discussion,[0],[0]
The joint distribution indicates a positive correlation between SAMSA and AvgHuman.,8 Discussion,[0],[0]
The corresponding Pearson correlation is indeed 0.27 (p = 0.03).,8 Discussion,[0],[0]
"In order to provide further validation for SAMSA predictive value for quality of simplification systems, we report SAMSA’s correlation with a recently proposed benchmark, used for the QATS (Quality Assessment for Text Simplification) shared task (Štajner et al., 2016).
",9 Evaluation on the QATS Benchmark,[0],[0]
Setup.,9 Evaluation on the QATS Benchmark,[0],[0]
"The test corpus contains 126 sentences taken from 3 datasets described in Štajner et al. (2016)11: (1) EventS: original sentences from the EMM News-Brief12 and their syntactically simplified versions (with significant content reduction) by the EventSimplify TS system (Glavas
11http://qats2016.github.io/shared.html 12emm.newsbrief.eu/NewsBrief/
clusteredition/en/latest.html
and Štajner, 2013)13 (the test corpus contains 54 pairs from this dataset), (2) EncBrit: original sentences from the Encyclopedia Britannica (Barzilay and Elhadad, 2003) and their automatic simplifications obtained using ATS systems based on several phrase-based statistical MT systems (Štajner et al., 2015) trained on Wikipedia TS corpus (Coster and Kauchak, 2011) (24 pairs), and (3) LSLight: sentences from English Wikipedia and their automatic simplifications (Glavaš and Štajner, 2015) by three different lexical simplification systems (Biran et al., 2011; Horn et al., 2014; Glavaš and Štajner, 2015) (48 pairs).
",9 Evaluation on the QATS Benchmark,[0],[0]
"Human evaluation is also provided by this resource, with scores for overall quality, grammaticality, meaning preservation and simplicity.",9 Evaluation on the QATS Benchmark,[0],[0]
"Importantly, the simplicity score does not explicitly refer to the output’s structural simplicity, but rather to its readability.",9 Evaluation on the QATS Benchmark,[0],[0]
"We focus on the overall human score, and compare it to SAMSA.",9 Evaluation on the QATS Benchmark,[0],[0]
"Since different systems were used to simplify different portions of the input, correlation is taken at the sentence level.
",9 Evaluation on the QATS Benchmark,[0],[0]
We use the same implementations of SAMSA.,9 Evaluation on the QATS Benchmark,[0],[0]
Manual UCCA annotation is here performed by one of the authors of this paper.,9 Evaluation on the QATS Benchmark,[0],[0]
Results.,9 Evaluation on the QATS Benchmark,[0],[0]
We follow Štajner et al. (2016) and report the Pearson correlations (at the sentence level) between the rankings of the metrics and the human evaluation scores.,9 Evaluation on the QATS Benchmark,[0],[0]
Results show that the semi-automatic/automatic SAMSA obtains a Pearson correlation of 0.32 and 0.28 with the human scores.,9 Evaluation on the QATS Benchmark,[0],[0]
"This places these measures in the 3rd and 4th places in the shared task, where the only two systems that surpassed it are marginally better, with scores of 0.33 and 0.34, and where the next
13takelab.fer.hr/data/symplify
system in QATS obtained a correlation of 0.23.",9 Evaluation on the QATS Benchmark,[0],[0]
"This correlation by SAMSA was obtained in more restricted conditions, compared to the measures that competed in QATS.",9 Evaluation on the QATS Benchmark,[0],[0]
"First, SAMSA computes its score by only considering the UCCA structure of the source, and an automatic wordto-word alignment between the source and output.",9 Evaluation on the QATS Benchmark,[0],[0]
"Most QATS systems, including OSVCML and OSVCML2 (Nisioi and Nauze, 2016) which scored highest on the shared task, use an ensemble of classifiers based on bag-of-words, POS tags, sentiment information, negation, readability measures and other resources.",9 Evaluation on the QATS Benchmark,[0],[0]
"Second, the systems participating in the shared task had training data available to them, annotated by the same annotators as the test data.",9 Evaluation on the QATS Benchmark,[0],[0]
This was used to train classifiers for predicting their score.,9 Evaluation on the QATS Benchmark,[0],[0]
"This gives the QATS measures much predictive strength, but hampers their interpretability.",9 Evaluation on the QATS Benchmark,[0],[0]
SAMSA on the other hand is conceptually simple and interpretable.,9 Evaluation on the QATS Benchmark,[0],[0]
"Third, the QATS shared task does not focus on structural simplification, but experiments on different types of systems.",9 Evaluation on the QATS Benchmark,[0],[0]
"Indeed, some of the data was annotated by systems that exclusively perform lexical simplification, which is orthogonal to SAMSA’s structural focus.
",9 Evaluation on the QATS Benchmark,[0],[0]
"Given these factors, SAMSA’s competitive correlation with the participating systems in QATS suggests that structural simplicity, as reflected by the correct splitting of UCCA Scenes, captures a major component in overall simplification quality, underscoring SAMSA’s value.",9 Evaluation on the QATS Benchmark,[0],[0]
These promising results also motivate a future combination of SAMSA with classifier-based metrics.,9 Evaluation on the QATS Benchmark,[0],[0]
"We presented the first structure-aware metric for text simplification, SAMSA, and the first evaluation experiments that directly target the structural simplification component, separately from the lexical component.",10 Conclusion,[0],[0]
"We argue that the structural and lexical dimensions of simplification are loosely related, and that TS evaluation protocols should assess both.",10 Conclusion,[0],[0]
"We empirically demonstrate that strong measures that assess lexical simplification quality (notably SARI), fail to correlate with human judgments when structural simplification is performed by the evaluated systems.",10 Conclusion,[0],[0]
"Our experiments show that SAMSA correlates well with human judgments in such settings, which demonstrates its usefulness for evaluating and tuning statistical simplification systems, and shows that structural evaluation provides a complementary perspective on simplification quality.",10 Conclusion,[0],[0]
"We would like to thank Zhemin Zhu and Sander Wubben for sharing their data, as well as the annotators for participating in our evaluation and UCCA annotation experiments.",Acknowledgments,[0],[0]
We also thank Daniel Hershcovich and the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
"This work was partially supported by the Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI) and by the Israel Science Foundation (grant No. 929/17), as well as by the HUJI Cyber Security Research Center in conjunction with the Israel National Cyber Bureau in the Prime Minister’s Office.",Acknowledgments,[0],[0]
"Current measures for evaluating text simplification systems focus on evaluating lexical text aspects, neglecting its structural aspects.",abstractText,[0],[0]
"In this paper we propose the first measure to address structural aspects of text simplification, called SAMSA.",abstractText,[0],[0]
It leverages recent advances in semantic parsing to assess simplification quality by decomposing the input based on its semantic structure and comparing it to the output.,abstractText,[0],[0]
"SAMSA provides a reference-less automatic evaluation procedure, avoiding the problems that reference-based methods face due to the vast space of valid simplifications for a given sentence.",abstractText,[0],[0]
"Our human evaluation experiments show both SAMSA’s substantial correlation with human judgments, as well as the deficiency of existing reference-based measures in evaluating structural simplification.1",abstractText,[0],[0]
Semantic Structural Evaluation for Text Simplification,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 939–949 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1087",text,[0],[0]
"In distributional vector representations, opposite relations are not fully captured.",1 Introduction,[0],[0]
"Take, for example, words such as “great” and “awful” that can appear with similar frequency in the same sentence structure: “John had a great meeting” and “John had an awful day.”",1 Introduction,[0],[0]
"Word embeddings, which are successful in a wide array of NLP tasks (Turney et al., 2010; Dhillon et al., 2015), fail to capture this antonymy because they follow the distributional hypothesis that similar words are used in similar
contexts (Harris, 1954), thus assigning small cosine or euclidean distances between the vector representations of “great” and “awful”.
",1 Introduction,[0],[0]
"While vector space models (Turney et al., 2010) such as word2vec (Mikolov et al., 2013), Global vectors (GloVe) (Pennington et al., 2014), or Eigenwords (Dhillon et al., 2015) capture relatedness, they do not adequately encode synonymy and semantic similarity (Mohammad et al., 2013; Scheible et al., 2013).",1 Introduction,[0],[0]
Our goal is to create clusters of synonyms or semantically equivalent words and linguistically motivated unified constructs.,1 Introduction,[0],[0]
"Signed graphs, which are graphs with negative edge weights, were first introduced by Cartwright and Harary (1956).",1 Introduction,[0],[0]
"However, signed graph clustering for multiclass normalized cuts (K-clusters) has been largely unexplored until recently.",1 Introduction,[0],[0]
"We present a novel theory and method that extends multiclass normalized cuts (K-cluster) of Yu and Shi (2003) to signed graphs (Gallier, 2016)1 and the work of Kunegis et al. (2010) to K-clustering.",1 Introduction,[0],[0]
"This extension allows the incorporation of knowledge base information, positive and negatively weighted links (see figure 2.1).",1 Introduction,[0],[0]
"Negative edges serve as repellent or opposite relationships between nodes.
",1 Introduction,[0],[0]
"Our signed spectral normalized graph cut algorithm (henceforth, signed clustering) builds negative edge relations into graph embeddings using similarity structure in vector spaces.",1 Introduction,[0],[0]
"It takes as input an initial set of vectors and edge relations, and hence is easy to combine with any word embedding method.",1 Introduction,[0],[0]
"This paper formally improves on the discrete optimization problem of Yu and Shi (2003).
",1 Introduction,[0],[0]
"Signed clustering gives better clusters than spectral clustering (Shi and Malik, 2000) of word embeddings, and it has better coverage and is more robust than thesaurus look-up.",1 Introduction,[0],[0]
"This is because the-
1Gallier (2016) is a full theoretical exposition of our methods with proofs on arXiv.
939
sauri erroneously give equal weight to rare senses of a word – for example, “rich” as a rarely used synonym of “absurd”.",1 Introduction,[0],[0]
"Also, the overlap between thesauri is small, due to their manual creation.",1 Introduction,[0],[0]
Lin (1998) found 17.8397% overlap between synonym sets from Roget’s Thesaurus and WordNet 1.5.,1 Introduction,[0],[0]
"We find similarly small overlap between all three thesauri tested.
",1 Introduction,[0],[0]
"We evaluate our clusters using SimLex-999 (Hill et al., 2014) and SimVerb-3500 (Gerz et al., 2016) as a ground truth for our cluster evaluation.",1 Introduction,[0],[0]
"Finally, we test our method on the sentiment analysis task.",1 Introduction,[0],[0]
"Overall, signed spectral clustering can augment methods using signed information and has broad application for many fields.
",1 Introduction,[0],[0]
"Our main contributions are: the novel extension of signed clustering to the multiclass (K-cluster), and the application of this method to create semantic word clusters that are agnostic to vector space representations and thesauri.",1 Introduction,[0],[0]
"Semantic word cluster and distributional thesauri have been well studied in the NLP literature (Lin, 1998; Curran, 2004).",1.1 Related Work,[0],[0]
Recently there has been a line of research on incorporating synonyms and antonyms into word embeddings.,1.1 Related Work,[0],[0]
Our approach is very much in the line of Vlachos et al. (2009).,1.1 Related Work,[0],[0]
"However, they explicitly made verb clusters using Dirichlet Process Mixture Models and must-link / cannot-link clustering.",1.1 Related Work,[0],[0]
"Furthermore, they note that cannot-link clustering does not improve performance whereas our signed clustering antonyms are key.
",1.1 Related Work,[0],[0]
"Most recent models either attempt to make richer contexts, in order to find semantic similarity, or overlay thesaurus information in a supervised or semi-supervised manner.",1.1 Related Work,[0],[0]
"One line of active research is post processing the word vector embedding by transforming the space using a single or multi-relational objective (Yih et al., 2012; Tang et al., 2014; Chang et al., 2013; Tang et al., 2014; Zhang et al., 2014; Faruqui et al., 2015; Mrkšić et al., 2016).
",1.1 Related Work,[0],[0]
"Alternatively, there are methods to modify the objective function for generating the word embeddings (Ono et al., 2015; Pham et al., 2015; Schwartz et al., 2015).
",1.1 Related Work,[0],[0]
Our approach differs from the aforementioned methods in that we created word clusters using the antonym relationships as negative links.,1.1 Related Work,[0],[0]
"Unlike
the previous approaches using semi-supervised methods, we incorporated the thesauri as a knowledge base.",1.1 Related Work,[0],[0]
Similar to word vector retrofitting and counter-fitting methods described in Faruqui et al. (2015) and Mrkšić,1.1 Related Work,[0],[0]
"et al. (2016), our signed clustering method uses existing vector representations to create word clusters.
",1.1 Related Work,[0],[0]
"To our knowledge, this work is the first theoretical foundation of multiclass signed normalized cuts.2 Zass and Shashua (2005) solved multiclass cluster from another approach, by relaxing the orthogonality assumption and focusing instead on the non-negativity constraint.",1.1 Related Work,[0],[0]
This led to a doubly stochastic optimization problem.,1.1 Related Work,[0],[0]
Negative edges are handled by a constrained hyperparameter.,1.1 Related Work,[0],[0]
"Hou (2005) used positive degrees of nodes in the degree matrix of a signed graph with weights (-1, 0, 1), which was advanced by Kolluri et al. (2004) and Kunegis et al. (2010) using absolute values of weights in the degree matrix.",1.1 Related Work,[0],[0]
"Interestingly, Chiang et al. (2014) presented a theoretical foundation for edge sign prediction and a recursive clustering approach.",1.1 Related Work,[0],[0]
"Mercado et al. (2016) found that using the geometric mean of the graph Laplacian improves performance.
",1.1 Related Work,[0],[0]
"Wang et al. (2016) used semi-supervised polarity induction (Rao and Ravichandran, 2009) to create clusters of words with similar valence and arousal.",1.1 Related Work,[0],[0]
"Must-link and cannot-link soft spectral clustering (Rangapuram and Hein, 2012) share similarities with our method, particularly in the limit where there are no must-link edges present.",1.1 Related Work,[0],[0]
Both must-link and cannot-link clustering as well as polarity induction differ in optimization method.,1.1 Related Work,[0],[0]
"Our method is significantly faster due to the use of randomized SVD (Halko et al., 2011) and can thus be applied to large scale NLP problems.
",1.1 Related Work,[0],[0]
We developed a novel theory and algorithm that extends the clustering of Shi and Malik (2000) and Yu and Shi (2003) to the multiclass signed graph case.,1.1 Related Work,[0],[0]
"Weighted graphs for which the weight matrix is a symmetric matrix in which negative and positive entries are allowed are called signed graphs.
",2.1 Signed Normalized Cut,[0],[0]
"2The full exposition by Gallier (2016) is available on arXiv.
",2.1 Signed Normalized Cut,[0],[0]
"Such graphs (with weights (−1, 0,+1)) were introduced as early as 1953 by (Harary, 1953), to model social relations involving disliking, indifference, and liking.",2.1 Signed Normalized Cut,[0],[0]
The problem of clustering the nodes of a signed graph arises naturally as a generalization of the clustering problem for weighted graphs.,2.1 Signed Normalized Cut,[0],[0]
Figure 1 shows a signed graph of word similarities with a thesaurus overlay.,2.1 Signed Normalized Cut,[0],[0]
"Gallier
(2016) extends normalized cuts to signed graphs in order to incorporate antonym information into word clusters.
",2.1 Signed Normalized Cut,[0],[0]
Definition 2.1.,2.1 Signed Normalized Cut,[0],[0]
"A weighted graph is a pair G = (V,W ), where V = {v1, . .",2.1 Signed Normalized Cut,[0],[0]
.,2.1 Signed Normalized Cut,[0],[0]
", vm} is a set of nodes or vertices, and W is a symmetric matrix called the weight matrix, such that wi j ≥ 0 for all i, j ∈ {1, . . .",2.1 Signed Normalized Cut,[0],[0]
",m}, and wi i = 0 for i = 1, . . .",2.1 Signed Normalized Cut,[0],[0]
",m. We say that a set {vi, vj} is an edge iff wi j > 0.",2.1 Signed Normalized Cut,[0],[0]
"The corresponding (undirected) graph (V,E) with E = {{vi, vj} | wi j > 0}, is called the underlying graph of G.
Given a signed graph G = (V,W ) (where W is a symmetric matrix with zero diagonal entries), the underlying graph of G is the graph with node set V and set of (undirected) edges E = {{vi, vj} | wij 6= 0}.
",2.1 Signed Normalized Cut,[0],[0]
"If (V,W ) is a signed graph, where W is an m × m symmetric matrix with zero diagonal entries and with the other entries wij ∈ R arbitrary, for any node vi ∈ V , the signed degree of vi is defined as
di = d(vi)",2.1 Signed Normalized Cut,[0],[0]
=,2.1 Signed Normalized Cut,[0],[0]
"m∑
j=1
|wij",2.1 Signed Normalized Cut,[0],[0]
"|,
and the signed degree matrix D as
D = diag(d(v1), . .",2.1 Signed Normalized Cut,[0],[0]
.,2.1 Signed Normalized Cut,[0],[0]
", d(vm)).
",2.1 Signed Normalized Cut,[0],[0]
"For any subset A of the set of nodes V , let
vol(A) =",2.1 Signed Normalized Cut,[0],[0]
"∑
vi∈A di =
∑
vi∈A
m∑
j=1
|wij |.
",2.1 Signed Normalized Cut,[0],[0]
"For any two subsets A and B of V and AC which is the complement of A, define links+(A,B), links−(A,B), and cut(A,AC) by
links+(A,B) =",2.1 Signed Normalized Cut,[0],[0]
"∑
vi∈A,vj∈B wij>0
wij
links−(A,B) =",2.1 Signed Normalized Cut,[0],[0]
"∑
vi∈A,vj∈B wij<0
−wij
cut(A,AC) = ∑
vi∈A,vj∈AC wij 6=0
|wij |.
",2.1 Signed Normalized Cut,[0],[0]
"Then, the signed Laplacian L is defined by
L = D −W,
and its normalized version Lsym by
Lsym = D −1/2 LD −1/2 = I −D−1/2WD−1/2.
Kunegis et al. (2010) showed that L is positive semidefinite.",2.1 Signed Normalized Cut,[0],[0]
"For a graph without isolated vertices, we have d(vi) > 0",2.1 Signed Normalized Cut,[0],[0]
"for i = 1, . . .",2.1 Signed Normalized Cut,[0],[0]
",m, so D
−1/2 is well defined.
",2.1 Signed Normalized Cut,[0],[0]
"Given a partition of V into K clusters (A1, . . .",2.1 Signed Normalized Cut,[0],[0]
", AK), if we represent the jth block of this partition by a vector Xj such that
Xji = { aj if vi ∈ Aj 0",2.1 Signed Normalized Cut,[0],[0]
"if vi /∈ Aj ,
for some aj 6= 0.",2.1 Signed Normalized Cut,[0],[0]
"For illustration, suppose m = 5 and A1 = {v1, v3} then (X1)> =",2.1 Signed Normalized Cut,[0],[0]
"[a1, 0, a1, 0, 0].",2.1 Signed Normalized Cut,[0],[0]
Definition 2.2.,2.1 Signed Normalized Cut,[0],[0]
"The signed normalized cut sNcut(A1, . . .",2.1 Signed Normalized Cut,[0],[0]
", AK) of the partition (A1, ..., AK) is defined as
sNcut(A1, . . .",2.1 Signed Normalized Cut,[0],[0]
",AK) =
K∑
j=1
cut(Aj , A C j ) + 2links −(Aj , Aj)
vol(Aj) .
",2.1 Signed Normalized Cut,[0],[0]
"It should be noted that this formulation differs significantly from Kunegis et al. (2010) and even more so from must-link / cannot-link clustering.
",2.1 Signed Normalized Cut,[0],[0]
"Observe that minimizing sNcut(A1, . . .",2.1 Signed Normalized Cut,[0],[0]
", AK) minimizes the number of positive and negative edges between clusters and also the number of negative edges within clusters.",2.1 Signed Normalized Cut,[0],[0]
"Removing the term links−(Aj , Aj) reduces sNcut to normalized cuts.
",2.1 Signed Normalized Cut,[0],[0]
"A linear algebraic formulation is
sNcut(A1, . . .",2.1 Signed Normalized Cut,[0],[0]
", AK) = K∑
j=1
(Xj)>LXj (Xj)>DXj .
where X is the N ×K matrix whose jth column is Xj .",2.1 Signed Normalized Cut,[0],[0]
"We now formulate K-way clustering of a graph using normalized cuts.
",2.2 Optimization Problem,[0],[0]
"If we let X = {
[X1 . .",2.2 Optimization Problem,[0],[0]
.,2.2 Optimization Problem,[0],[0]
"XK ] | Xj = aj(xj1, . . .",2.2 Optimization Problem,[0],[0]
", xjN ),
xji ∈",2.2 Optimization Problem,[0],[0]
"{1, 0}, aj ∈ R, Xj 6= 0 }
",2.2 Optimization Problem,[0],[0]
"our solution set is
K = { X ∈ X",2.2 Optimization Problem,[0],[0]
"| (Xi)>DXj = 0,
1 ≤",2.2 Optimization Problem,[0],[0]
"i, j ≤ K, i 6= j } .
",2.2 Optimization Problem,[0],[0]
"The resulting optimization problem is
minimize
K∑
j=1
(Xj)>LXj (Xj)>DXj
subject to (Xi)>DXj = 0,
1 ≤",2.2 Optimization Problem,[0],[0]
"i, j ≤ K, i 6= j, X ∈ X .",2.2 Optimization Problem,[0],[0]
"The problem can be reformulated to an equiva-
lent optimization problem:
minimize tr(X>LX)
subject to X>DX = I, X ∈ X .",2.2 Optimization Problem,[0],[0]
"We then form a relaxation of the above problem,
dropping the condition that X ∈ X , giving Relaxed Problem
minimize tr(Y >D −1/2 LD −1/2 Y ) subject to Y >Y = I.
The minimum of the relaxed problem is achieved by the K unit eigenvectors associated with the smallest eigenvalues of Lsym.",2.2 Optimization Problem,[0],[0]
"Given a solution Z of the relaxed problem, we look for pairs (X,Q) with X ∈ X and where Q is aK×K matrix with nonzero and pairwise orthogonal columns, with ‖X‖F = ‖Z‖F , that minimize
ϕ(X,Q) =",2.3 Finding an Approximate Discrete Solution,[0],[0]
‖X,2.3 Finding an Approximate Discrete Solution,[0],[0]
"− ZQ‖F .
",2.3 Finding an Approximate Discrete Solution,[0],[0]
"Here, ‖A‖F is the Frobenius norm of A.",2.3 Finding an Approximate Discrete Solution,[0],[0]
"This nonlinear optimization problem involves two unknown matrices X and Q. To solve the relaxed problem, we proceed by alternating between minimizing ϕ(X,Q) =",2.3 Finding an Approximate Discrete Solution,[0],[0]
‖X,2.3 Finding an Approximate Discrete Solution,[0],[0]
"− ZQ‖F with respect to X holding Q fixed (step 5 in algorithm 1), and minimizing ϕ(X,Q) with respect to Q holding X fixed (steps 6 and 7 in algorithm 1).
",2.3 Finding an Approximate Discrete Solution,[0],[0]
"This second stage in which X is held fixed has been studied, but it is still a hard problem for which no closed-form solution is known.",2.3 Finding an Approximate Discrete Solution,[0],[0]
Hence we divide the problem into steps 6 and 7 for which the solution is known.,2.3 Finding an Approximate Discrete Solution,[0],[0]
Since Q is of the form,2.3 Finding an Approximate Discrete Solution,[0],[0]
Q = RΛ,2.3 Finding an Approximate Discrete Solution,[0],[0]
"whereR ∈ O(K) and Λ is a diagonal invertible matrix, we minimize ‖X",2.3 Finding an Approximate Discrete Solution,[0],[0]
− ZRΛ‖F,2.3 Finding an Approximate Discrete Solution,[0],[0]
.,2.3 Finding an Approximate Discrete Solution,[0],[0]
The matrix RΛ is not a minimizer of ‖X,2.3 Finding an Approximate Discrete Solution,[0],[0]
− ZRΛ‖F in general,2.3 Finding an Approximate Discrete Solution,[0],[0]
", but it is an improvement on R alone, and both stages can be solved quite easily.",2.3 Finding an Approximate Discrete Solution,[0],[0]
"In step 6 the problem reduces to minimizing −2tr(Q>Z>X); that is, maximizing tr(Q>Z>X).
",2.3 Finding an Approximate Discrete Solution,[0],[0]
"Algorithm 1 Signed Clustering 1: Input: W the weight matrix (without isolated nodes),
K the number of clusters, and termination threshold .",2.3 Finding an Approximate Discrete Solution,[0],[0]
"2: Using theD the degree matrix, and the signed Laplacian
L, compute Lsym the signed normalized Laplacian.
3: Initialize Λ = I , X = D − 1
2U where U is the matrix of the eigenvectors corresponding to the K smallest eigenvalues of Lsym.",2.3 Finding an Approximate Discrete Solution,[0],[0]
3 4:,2.3 Finding an Approximate Discrete Solution,[0],[0]
while ‖X − ZRΛ‖F,2.3 Finding an Approximate Discrete Solution,[0],[0]
>,2.3 Finding an Approximate Discrete Solution,[0],[0]
do 5: Minimize ‖X,2.3 Finding an Approximate Discrete Solution,[0],[0]
− ZRΛ‖F with respect to X holding Q fixed.,2.3 Finding an Approximate Discrete Solution,[0],[0]
"6: Fix X , Z, and Λ, find R ∈ O(K) that minimizes ‖X",2.3 Finding an Approximate Discrete Solution,[0],[0]
− ZRΛ‖F .,2.3 Finding an Approximate Discrete Solution,[0],[0]
"7: Fix X , Z, and R, find a diagonal invertible matrix Λ that minimizes ‖X",2.3 Finding an Approximate Discrete Solution,[0],[0]
− ZRΛ‖F .,2.3 Finding an Approximate Discrete Solution,[0],[0]
"8: end while 9: Find the discrete solution X∗ by choosing the
largest entry xij on row i set xij = 1 and all other xij = 0 for row i.
10:",2.3 Finding an Approximate Discrete Solution,[0],[0]
"Output: X∗.
Steps 3 through 10 may be replaced by standard Kmeans clustering.",2.3 Finding an Approximate Discrete Solution,[0],[0]
"It should also be noted that by
removing the solution requirement that Xj 6= 0, the algorithm can find k ≤ K clusters.",2.3 Finding an Approximate Discrete Solution,[0],[0]
"The main input to the spectral signed clustering algorithm is the similarity matrixW , which overlays both the distributional properties and thesaurus information.",3 Similarity Calculation,[0],[0]
"Following Belkin and Niyogi (2003), we chose the heat kernel based on the Euclidean distance between word vector representations as our similarity metric, such that
Wij",3 Similarity Calculation,[0],[0]
=    0 if e− ‖wi−wj‖2 σ,3 Similarity Calculation,[0],[0]
"<
",3 Similarity Calculation,[0],[0]
"e− ‖wi−wj‖2 σ otherwise .
",3 Similarity Calculation,[0],[0]
"where σ and are hyperparameters found using grid search (see Supplemental material for more detail).
",3 Similarity Calculation,[0],[0]
"We represented the thesaurus as two matrices where
T synij = { 1 if words i and j are synonyms 0 otherwise .
and
T antij = { −1",3 Similarity Calculation,[0],[0]
if words i and j are antonyms 0,3 Similarity Calculation,[0],[0]
"otherwise .
",3 Similarity Calculation,[0],[0]
T syn is the synonym graph and T ant is the antonym graph.,3 Similarity Calculation,[0],[0]
"The signed graph can then be written in matrix form as Ŵ = γW +βantT ant W+βsynT syn W , where computes Hadamard product (element-wise multiplication).
",3 Similarity Calculation,[0],[0]
"The parameters γ, βsyn, and βant are tuned to the data target dataset using cross validation.",3 Similarity Calculation,[0],[0]
"The reader should note that σ and are not found using a target dataset, but instead using cross validation and grid search to minimize the number of negative edges within clusters and the number of disconnected components in the cluster.",3 Similarity Calculation,[0],[0]
We evaluated the clusters using both intrinsic and extrinsic methods.,4 Evaluation Metrics,[0],[0]
"For intrinsic evaluation, we used thesaurus information for two novel metrics: 1) the number of negative edges (NNE) within the clusters, which in our semantic clusters is the number of antonyms in the same cluster, and 2) the number of disconnected components (NDC) in the synonym graph, so the number of groups of words
that are not connected by a synonym relation in the thesaurus.",4 Evaluation Metrics,[0],[0]
The NDC thus has the disadvantage that it is a function of the thesaurus coverage.,4 Evaluation Metrics,[0],[0]
Our third intrinsic measure uses a gold standard designed to measure how well we capture word similarity: Semantically similar words should be in the same cluster and semantically dissimilar words should not.,4 Evaluation Metrics,[0],[0]
"For extrinsic evaluation, as descibed below, we measure how much our clusters help to identify text polarity.",4 Evaluation Metrics,[0],[0]
We also compare multiple word embeddings and thesauri to demonstrate the stability of our method.,4 Evaluation Metrics,[0],[0]
"In order to evaluate our signed graph clustering method, we first focused on intrinsic measures of cluster quality in synthetic data.",5 Experiments with Synthetic Data,[0],[0]
"To do so, we created random signed graphs with the same proportion of positive and negative edges as in our real dataset.",5 Experiments with Synthetic Data,[0],[0]
"Figure 2 demonstrates that the number of
negative edges within a cluster is minimized using our clustering algorithm on simulated data.",5 Experiments with Synthetic Data,[0],[0]
"As the number of clusters becomes large, the number of disconnected components, which includes clusters of size one, consistently increases.",5 Experiments with Synthetic Data,[0],[0]
Determining the optimal cluster size and similarity parameters requires making a trade off between NDC and NNE.,5 Experiments with Synthetic Data,[0],[0]
"For example, in figure 2 the optimal cluster size is 20.",5 Experiments with Synthetic Data,[0],[0]
"One can see that as the number of clusters increases NNE goes to zero, but the number of disconnected components becomes the number of vertices.",5 Experiments with Synthetic Data,[0],[0]
In the extreme case all clusters contain one vertex.,5 Experiments with Synthetic Data,[0],[0]
"K-means, also shown in figure 2, does not optimize NNE.",5 Experiments with Synthetic Data,[0],[0]
"We used four different word embedding methods for evaluation: Skip-gram vectors (word2vec) (Mikolov et al., 2013), Global vectors (GloVe) (Pennington et al., 2014), Eigenwords (Dhillon et al., 2015), and Global Context (GloCon) (Huang et al., 2012); however, we only report the results for word2vec, which is the most popular word embedding (see the supplemental material for other embeddings).",6.1 Word Embeddings,[0],[0]
We used word2vec 300 dimensional embeddings which were trained on several billion words of English: the Gigaword and the English discussion forum data gathered as part of BOLT.,6.1 Word Embeddings,[0],[0]
Tokenization was performed using CMU’s Twokenize.4,6.1 Word Embeddings,[0],[0]
"Several thesauri were used in order to test the robustness including Roget’s Thesaurus (Roget, 1852), the Microsoft Word English (MS Word) thesaurus from Samsonovic et al. (2010) and WordNet 3.0 (Miller, 1995).
",6.2 Thesauri,[0],[0]
"We chose a subset of 5108 words for the training dataset, which had high overlap between various sources.",6.2 Thesauri,[0],[0]
Changes to the training dataset had minimal effects on the optimal parameters.,6.2 Thesauri,[0],[0]
"Within the training dataset, each of the thesauri had roughly 3700 antonym pairs; combined they had 6680.",6.2 Thesauri,[0],[0]
"However, the number of distinct connected components varied, with Roget’s Thesaurus having the fewest (629), and MS Word Thesaurus (1162) and WordNet (2449) having the most.",6.2 Thesauri,[0],[0]
These ratios were consistent across the full dataset.,6.2 Thesauri,[0],[0]
"SimVerb-3500
Following the analysis of Vlachos et al. (2009), we threshold the semantically similar datasets to find word pairs which should or should not belong to the same cluster.",6.3 Gold Standard SimLex-999 And,[0],[0]
"As ground truth, we extracted 120 semantically similar words from SimLex-999 with a similarity score greater than 8 out of 10.",6.3 Gold Standard SimLex-999 And,[0],[0]
"SimLex-999 is a gold standard resource for semantic similarity, not relatedness, based on ratings by human annotators.
",6.3 Gold Standard SimLex-999 And,[0],[0]
"Our 120 pair subset of SimLex-999 has multiple parts-of-speech including Noun-Noun pairs, VerbVerb pairs and Adjective-Adjective pairs.",6.3 Gold Standard SimLex-999 And,[0],[0]
"Within
4https://github.com/brendano/ ark-tweet-nlp
SimVerb-3500, we used a subset of 318 semantically similar verb pairs.
",6.3 Gold Standard SimLex-999 And,[0],[0]
"The community is attempting to define better gold standards; however, currently these are the best datasets that we are aware of.",6.3 Gold Standard SimLex-999 And,[0],[0]
"We tried to use WordNet, Roget, and the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013) as a gold standard, but manual inspection as well as empirical results showed that none of the automatically generated datasets were a sufficient gold standard.",6.3 Gold Standard SimLex-999 And,[0],[0]
"Possibly the symmetric pattern of (Schwartz et al., 2015) would have been sufficient; we did not have time to validate this.",6.3 Gold Standard SimLex-999 And,[0],[0]
"We also evaluated our clusters by using them as features for predicting sentiment, using sentiment treebank 5 (Socher et al., 2013) with coarsegrained labels on phrases and sentences from movie review excerpts.",6.4 Stanford Sentiment Treebank,[0],[0]
This dataset is widely used for the evaluation of sentiment analysis.,6.4 Stanford Sentiment Treebank,[0],[0]
"We used the standard partition of the treebank into training (6920), development (872), and test (1821) sets.",6.4 Stanford Sentiment Treebank,[0],[0]
"Table 1 shows the four most-associated words with “accept” using different methods.
",7 Cluster Evaluation,[0],[0]
We now turn to quantitative measures of word similarity and synonym cluster quality.,7 Cluster Evaluation,[0],[0]
"In order to assess the model we tested (1) Kmeans, (2) normalized cuts without thesaurus, and (3) signed normalized cuts.",7.1 Comparison with K-means and Normalized Cuts,[0],[0]
"As a baseline, we created clusters using K-means on the original word2vec vector representations where the number of K clusters was set to 750.
",7.1 Comparison with K-means and Normalized Cuts,[0],[0]
Table 2 shows the relative ratios of the different clustering methods of with respect to antonym pair inclusion and the number of disconnected components within the clusters.,7.1 Comparison with K-means and Normalized Cuts,[0],[0]
"For both methods, over twenty percent of the clusters contain antonym pairs even though the median cluster size is six.",7.1 Comparison with K-means and Normalized Cuts,[0],[0]
"Signed clustering radically reduced the number of antonyms within clusters compared to the other methods.
",7.1 Comparison with K-means and Normalized Cuts,[0],[0]
5http://nlp.stanford.edu/sentiment/ treebank.html,7.1 Comparison with K-means and Normalized Cuts,[0],[0]
Tables 3 and 5 present our main result.,8 Empirical Results,[0],[0]
"When using our signed clustering method with similar words, as labeled by SimLex-999 and SimVerb3500, our clustering accuracy increased by 5% on both SimLex-999 and SimVerb-3000.",8 Empirical Results,[0],[0]
"Furthermore, by combining the thesauri lookup with our clustering, we achieved almost perfect accuracy (96%).",8 Empirical Results,[0],[0]
Table 5 shows the sentiment analysis task performance.,8 Empirical Results,[0],[0]
"Our method outperforms all methods with similar complexity; however, we did not reach state-of-the-art results when compared to much more complex models which also use a richer dataset.",8 Empirical Results,[0],[0]
"In a perfect setting, all word pairs rated highly similar by human annotators would be in the same cluster, and all words which were rated dissimilar would be in different clusters.",8.1 Evaluation Using Word Similarity Datasets,[0],[0]
"Since our clustering algorithm produced sets of words, we used this evaluation instead of the more commonly reported correlations.
",8.1 Evaluation Using Word Similarity Datasets,[0],[0]
In table 3 we show the results of the evaluation with SimLex-999.,8.1 Evaluation Using Word Similarity Datasets,[0],[0]
"Combining thesaurus lookup and word2vec+CombThes clusters, labeled as Lookup + SC(W2V), yielded an accuracy of 0.96 (5 errors).",8.1 Evaluation Using Word Similarity Datasets,[0],[0]
Note that clusters using word2vec with normalized cuts does not improve accuracy.,8.1 Evaluation Using Word Similarity Datasets,[0],[0]
"The MSW thesaurus has much lower coverage, but 100 % accuracy, which is why when
combined with the signed clustering the performance is 0.95.",8.1 Evaluation Using Word Similarity Datasets,[0],[0]
In table 3 we state the proportion of clusters containing dissimilar words as a sanity check for cluster size.,8.1 Evaluation Using Word Similarity Datasets,[0],[0]
(See supplemental material for full cluster size optimization information.),8.1 Evaluation Using Word Similarity Datasets,[0],[0]
"Another important result is that the verb accuracy yielded the largest accuracy gains, consistent with the results of Schwartz et al. (2015).
",8.1 Evaluation Using Word Similarity Datasets,[0],[0]
Table 4 clearly shows that the overall performance of all methods is lower for verb similarity.,8.1 Evaluation Using Word Similarity Datasets,[0],[0]
"However, the improvement using both signed clustering as well as thesaurus look is also larger.",8.1 Evaluation Using Word Similarity Datasets,[0],[0]
"We trained an l2-norm regularized logistic regression (Friedman et al., 2001) and simultaneously γ, βsyn, and βant using our word clusters in order to predict the coarse-grained sentiment at the sentence level.",8.2 Sentiment Analysis,[0],[0]
"The γ and β parameters were found using a portion of the data where we iteratively switch between the logistic regression and the parameters, holding each fixed.",8.2 Sentiment Analysis,[0],[0]
"However, hyperparameters σ and , and the number of clusters
K were optimized minimizing error using grid search.",8.2 Sentiment Analysis,[0],[0]
"We compared our model against existing models: Naive Bayes with bag of words (NB) (Socher et al., 2013), sentence word embedding averages (VecAvg), retrofitted sentence word embeddings (RVecAvg) (Faruqui et al., 2015) that incorporate thesaurus information, simple recurrent neural networks (RNN), and two baselines of normalized cuts and signed normalized cuts using only thesaurus information.
",8.2 Sentiment Analysis,[0],[0]
"While the state-of-the art Convolutional Neural Network (CNN) (Kim, 2014) is at 0.881, our model performs quite well with much less information and complexity.",8.2 Sentiment Analysis,[0],[0]
"Table 5 shows that signed clustering outperforms the baselines of Naive Bayes, normalized cuts, and signed cuts using just thesaurus information.",8.2 Sentiment Analysis,[0],[0]
"Furthermore, we outperform comparable models, including retrofitting, which has thesaurus information, and the recurrent neural network, which has access to domain specific context information.
",8.2 Sentiment Analysis,[0],[0]
Signed clustering using only thesaurus information (SC(Thes)) performed significantly worse than all other methods.,8.2 Sentiment Analysis,[0],[0]
This was largely due to low coverage; rare words such as “WOW” and “???” are not covered.,8.2 Sentiment Analysis,[0],[0]
"As expected, because normalized cut clusters include antonyms, the method performs worse than others.",8.2 Sentiment Analysis,[0],[0]
Nonetheless the improvement from 0.79 to 0.836 is quite drastic.,8.2 Sentiment Analysis,[0],[0]
We developed a novel theory for signed normalized cuts and an algorithm for finding their discrete solution.,9 Conclusion,[0],[0]
"We showed that we can find su-
perior semantically similar clusters which do not require new word embeddings but simply overlay thesaurus information on preexisting ones.",9 Conclusion,[0],[0]
The clusters are general and can be used with many out-of-the-box word embeddings.,9 Conclusion,[0],[0]
"By accounting for antonym relationships, our algorithm greatly outperforms simple normalized cuts.",9 Conclusion,[0],[0]
"Finally, we examined our clustering method on the sentiment analysis task from Socher et al. (2013) sentiment treebank dataset and showed that it improved performance versus comparable models.
",9 Conclusion,[0],[0]
Our automatically generated clusters give better coverage than manually constructed thesauri.,9 Conclusion,[0],[0]
Our signed spectral clustering method allows us to incorporate the knowledge contained in these thesauri without modifying the word embeddings themselves.,9 Conclusion,[0],[0]
"We further showed that use of the thesauri can be tuned to the task at hand.
",9 Conclusion,[0],[0]
"Our signed spectral clustering method could be applied to a broad range of NLP tasks, such as prediction of social group clustering, identification of personal versus non-personal verbs, and analyses of clusters which capture positive, negative, and objective emotional content.",9 Conclusion,[0],[0]
"It could also be used to explore multi-view relationships, such as aligning synonym clusters across multiple languages.",9 Conclusion,[0],[0]
Another possibility is to use thesauri and word vector representations together with word sense disambiguation to generate semantically similar clusters for multiple senses of words.,9 Conclusion,[0],[0]
"Furthermore, signed spectral clustering has broader applications such as cellular biology, social networking, and electricity networks.",9 Conclusion,[0],[0]
"Finally, we plan to extend the hard signed clustering presented here to probabilistic soft clustering.",9 Conclusion,[0],[0]
"Vector space representations of words capture many aspects of word similarity, but such methods tend to produce vector spaces in which antonyms (as well as synonyms) are close to each other.",abstractText,[0],[0]
"For spectral clustering using such word embeddings, words are points in a vector space where synonyms are linked with positive weights, while antonyms are linked with negative weights.",abstractText,[0],[0]
"We present a new signed spectral normalized graph cut algorithm, signed clustering, that overlays existing thesauri upon distributionally derived vector representations of words, so that antonym relationships between word pairs are represented by negative weights.",abstractText,[0],[0]
Our signed clustering algorithm produces clusters of words that simultaneously capture distributional and synonym relations.,abstractText,[0],[0]
"By using randomized spectral decomposition (Halko et al., 2011) and sparse matrices, our method is both fast and scalable.",abstractText,[0],[0]
We validate our clusters using datasets containing human judgments of word pair similarities and show the benefit of using our word clusters for sentiment prediction.,abstractText,[0],[0]
Semantic Word Clusters Using Signed Spectral Clustering,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1711–1721, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"The natural language generation (NLG) component provides much of the persona of a spoken dialogue system (SDS), and it has a significant impact on a user’s impression of the system.",1 Introduction,[0],[0]
"As noted in Stent et al. (2005), a good generator usually depends on several factors: adequacy, fluency, readability, and variation.",1 Introduction,[0],[0]
Previous approaches attacked the NLG problem in different ways.,1 Introduction,[0],[0]
"The most common and widely adopted today is the rule-based (or template-based) approach (Cheyer and Guzzoni, 2007; Mirkovic and
Cavedon, 2011).",1 Introduction,[0],[0]
"Despite its robustness and adequacy, the frequent repetition of identical, rather stilted, output forms make talking to a rule-based generator rather tedious.",1 Introduction,[0],[0]
"Furthermore, the approach does not easily scale to large open domain systems(Young et al., 2013; Gašić et al., 2014; Henderson et al., 2014).",1 Introduction,[0],[0]
"Hence approaches to NLG are required that can be readily scaled whilst meeting the above requirements.
",1 Introduction,[0],[0]
"The trainable generator approach exemplified by the HALOGEN (Langkilde and Knight, 1998) and SPaRKy system (Stent et al., 2004) provides a possible way forward.",1 Introduction,[0],[0]
"These systems include specific trainable modules within the generation framework to allow the model to adapt to different domains (Walker et al., 2007), or reproduce certain style (Mairesse and Walker, 2011).",1 Introduction,[0],[0]
"However, these approaches still require a handcrafted generator to define the decision space within which statistics can be used for optimisation.",1 Introduction,[0],[0]
"The resulting utterances are therefore constrained by the predefined syntax and any domain-specific colloquial responses must be added manually.
",1 Introduction,[0],[0]
"More recently, corpus-based methods (Oh and Rudnicky, 2000; Mairesse and Young, 2014; Wen et al., 2015) have received attention as access to data becomes increasingly available.",1 Introduction,[0],[0]
"By defining a flexible learning structure, corpus-based methods aim to learn generation directly from data by adopting an over-generation and reranking paradigm (Oh and Rudnicky, 2000), in which final responses are obtained by reranking a set of candidates generated from a stochastic generator.",1 Introduction,[0],[0]
"Learning from data directly enables the system to mimic human responses more naturally, removes the dependency on predefined rules, and makes the system easier to build and extend to other domains.",1 Introduction,[0],[0]
"As detailed in Sections 2 and 3, however, these existing approaches have weaknesses in the areas of training data efficiency, accuracy and naturalness.
",1 Introduction,[0],[0]
"1711
This paper presents a statistical NLG based on a semantically controlled Long Short-term Memory (LSTM) recurrent network.",1 Introduction,[0],[0]
"It can learn from unaligned data by jointly optimising its sentence planning and surface realisation components using a simple cross entropy training criterion without any heuristics, and good quality language variation is obtained simply by randomly sampling the network outputs.",1 Introduction,[0],[0]
We start in Section 3 by defining the framework of the proposed neural language generator.,1 Introduction,[0],[0]
"We introduce the semantically controlled LSTM (SC-LSTM) cell in Section 3.1, then we discuss how to extend it to a deep structure in Section 3.2.",1 Introduction,[0],[0]
"As suggested in Wen et al. (2015), a backward reranker is introduced in Section 3.3 to improve fluency.",1 Introduction,[0],[0]
"Training and decoding details are described in Section 3.4 and 3.5.
",1 Introduction,[0],[0]
Section 4 presents an evaluation of the proposed approach in the context of an application providing information about venues in the San Francisco area.,1 Introduction,[0],[0]
"In Section 4.2, we first show that our generator outperforms several baselines using objective metrics.",1 Introduction,[0],[0]
"We experimented on two different ontologies to show not only that good performance can be achieved across domains, but how easy and quick the development lifecycle is.",1 Introduction,[0],[0]
"In order to assess the subjective performance of our system, a quality test and a pairwise preference test are presented in Section 4.3.",1 Introduction,[0],[0]
The results show that our approach can produce high quality utterances that are considered to be more natural and are preferred to previous approaches.,1 Introduction,[0],[0]
We conclude with a brief summary and future work in Section 5.,1 Introduction,[0],[0]
Conventional approaches to NLG typically divide the task into sentence planning and surface realisation.,2 Related Work,[0],[0]
"Sentence planning maps input semantic symbols into an intermediary form representing the utterance, e.g. a tree-like or template structure, then surface realisation converts the intermediate structure into the final text (Walker et al., 2002; Stent et al., 2004).",2 Related Work,[0],[0]
"Although statistical sentence planning has been explored previously, for example, generating the most likely context-free derivations given a corpus (Belz, 2008) or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2010), these methods still rely on a pre-existing, handcrafted generator.",2 Related Work,[0],[0]
"To minimise handcrafting, Stent and Molina (2009) proposed learning sentence planning rules
directly from a corpus of utterances labelled with Rhetorical Structure Theory (RST) discourse relations (Mann and Thompson, 1988).",2 Related Work,[0],[0]
"However, the required corpus labelling is expensive and additional handcrafting is still needed to map the sentence plan to a valid syntactic form.
",2 Related Work,[0],[0]
"As noted above, corpus-based NLG aims at learning generation decisions from data with minimal dependence on rules and heuristics.",2 Related Work,[0],[0]
A pioneer in this direction is the class-based n-gram language model (LM) approach proposed by Oh and Rudnicky (2000).,2 Related Work,[0],[0]
Ratnaparkhi (2002) later addressed some of the limitations of class-based LMs in the over-generation phase by using a modified generator based on a syntactic dependency tree.,2 Related Work,[0],[0]
Mairesse and Young (2014) proposed a phrase-based NLG system based on factored LMs that can learn from a semantically aligned corpus.,2 Related Work,[0],[0]
"Although active learning (Mairesse et al., 2010) was also proposed to allow learning online directly from users, the requirement for human annotated alignments limits the scalability of the system.",2 Related Work,[0],[0]
"Another similar approach casts NLG as a template extraction and matching problem, e.g., Angeli et al. (2010) train a set of log-linear models to make a series of generation decisions to choose the most suitable template for realisation.",2 Related Work,[0],[0]
Kondadadi et al. (2013) later show that the outputs can be further improved by an SVM reranker making them comparable to human-authored texts.,2 Related Work,[0],[0]
"However, template matching approaches do not generalise well to unseen combinations of semantic elements.
",2 Related Work,[0],[0]
The use of neural network-based (NN) approaches to NLG is relatively unexplored.,2 Related Work,[0],[0]
"The stock reporter system ANA by Kukich (1987) is perhaps the first NN-based generator, although generation was only done at the phrase level.",2 Related Work,[0],[0]
"Recent advances in recurrent neural network-based language models (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2011a) have demonstrated the value of distributed representations and the ability to model arbitrarily long dependencies.",2 Related Work,[0],[0]
Sutskever et al. (2011) describes a simple variant of the RNN that can generate meaningful sentences by learning from a character-level corpus.,2 Related Work,[0],[0]
"More recently, Karpathy and Fei-Fei (2014) have demonstrated that an RNNLM is capable of generating image descriptions by conditioning the network model on a pre-trained convolutional image feature representation.",2 Related Work,[0],[0]
"Zhang and Lapata (2014) also describes interesting work using RNNs to generate
Chinese poetry.",2 Related Work,[0],[0]
"A forerunner of the system presented here is described in Wen et al. (2015), in which a forward RNN generator, a CNN reranker, and a backward RNN reranker are trained jointly to generate utterances.",2 Related Work,[0],[0]
"Although the system was easy to train and extend to other domains, a heuristic gate control was needed to ensure that all of the attribute-value information in the system’s response was accurately captured by the generated utterance.",2 Related Work,[0],[0]
"Furthermore, the handling of unusual slot-value pairs by the CNN reranker was rather arbitrary.",2 Related Work,[0],[0]
"In contrast, the LSTM-based system described in this paper can deal with these problems automatically by learning the control of gates and surface realisation jointly.
",2 Related Work,[0],[0]
"Training an RNN with long range dependencies is difficult because of the vanishing gradient problem (Bengio et al., 1994).",2 Related Work,[0],[0]
"Hochreiter and Schmidhuber (1997) mitigated this problem by replacing the sigmoid activation in the RNN recurrent connection with a self-recurrent memory block and a set of multiplication gates to mimic the read, write, and reset operations in digital computers.",2 Related Work,[0],[0]
The resulting architecture is dubbed the Long Short-term Memory (LSTM) network.,2 Related Work,[0],[0]
"It has been shown to be effective in a variety of tasks, such as speech recognition (Graves et al., 2013b), handwriting recognition (Graves et al., 2009), spoken language understanding (Yao et al., 2014), and machine translation (Sutskever et al., 2014).",2 Related Work,[0],[0]
Recent work by Graves et al. (2014) has demonstrated that an NN structure augmented with a carefully designed memory block and differentiable read/write operations can learn to mimic computer programs.,2 Related Work,[0],[0]
"Moreover, the ability to train deep networks provides a more sophisticated way of exploiting relations between labels and features, therefore making the prediction more accurate (Hinton et al., 2012).",2 Related Work,[0],[0]
"By extending an LSTM network to be both deep in space and time, Graves (2013) shows the resulting network can used to synthesise handwriting indistinguishable from that of a human.",2 Related Work,[0],[0]
"The generation model proposed in this paper is based on a recurrent NN architecture (Mikolov et al., 2010) in which a 1-hot encoding wt of a token1 wt is input at each time step t conditioned on a re-
1We use token instead of word because our model operates on text for which slot values are replaced by its corresponding slot tokens.",3 The Neural Language Generator,[0],[0]
"We call this procedure delexicalisation.
current hidden layer ht and outputs the probability distribution of the next token wt+1.",3 The Neural Language Generator,[0],[0]
"Therefore, by sampling input tokens one by one from the output distribution of the RNN until a stop sign is generated (Karpathy and Fei-Fei, 2014) or some constraint is satisfied (Zhang and Lapata, 2014), the network can produce a sequence of tokens which can be lexicalised 2 to form the required utterance.",3 The Neural Language Generator,[0],[0]
"Long Short-term Memory (Hochreiter and Schmidhuber, 1997) is a recurrent NN architecture which uses a vector of memory cells ct ∈",3.1 Semantic Controlled LSTM cell,[0],[0]
"Rn and a set of elementwise multiplication gates to control how information is stored, forgotten, and exploited inside the network.",3.1 Semantic Controlled LSTM cell,[0],[0]
"Of the various different connectivity designs for an LSTM cell (Graves, 2013; Zaremba et al., 2014), the architecture used in this paper is illustrated in Figure 3.1 and defined by the following equations,,
it = σ(Wwiwt",3.1 Semantic Controlled LSTM cell,[0],[0]
+,3.1 Semantic Controlled LSTM cell,[0],[0]
Whiht−1) (1) ft = σ(Wwfwt + Whfht−1) (2) ot = σ(Wwowt + Whoht−1) (3) ĉt = tanh(Wwcwt + Whcht−1) (4) ct = ft ct−1 + it ĉt,3.1 Semantic Controlled LSTM cell,[0],[0]
"(5) ht = ot tanh(ct) (6)
2The process of replacing slot token by its value.
",3.1 Semantic Controlled LSTM cell,[0],[0]
"where σ is the sigmoid function, it, ft,",3.1 Semantic Controlled LSTM cell,[0],[0]
ot ∈,3.1 Semantic Controlled LSTM cell,[0],[0]
"[0, 1]n are input, forget, and output gates respectively, and ĉt and ct are proposed cell value and true cell value at time t. Note that each of these vectors has a dimension equal to the hidden layer h.
",3.1 Semantic Controlled LSTM cell,[0],[0]
"In order to ensure that the generated utterance represents the intended meaning, the generator is further conditioned on a control vector d, a 1-hot representation of the dialogue act (DA) type and its slot-value pairs.",3.1 Semantic Controlled LSTM cell,[0],[0]
"Although a related work (Karpathy and Fei-Fei, 2014) has suggested that reapplying this auxiliary information to the RNN at every time step can increase performance by mitigating the vanishing gradient problem (Mikolov and Zweig, 2012; Bengio et al., 1994), we have found that such a model also omits and duplicates slot information in the surface realisation.",3.1 Semantic Controlled LSTM cell,[0],[0]
In Wen et al. (2015) simple heuristics are used to turn off slot feature values in the control vector d once the corresponding slot token has been generated.,3.1 Semantic Controlled LSTM cell,[0],[0]
"However, these heuristics can only handle cases where slot-value pairs can be identified by exact matching between the delexicalised surface text and the slot value pair encoded in d. Cases such as binary slots and slots that take don’t care values cannot be explicitly delexicalised in this way and these cases frequently result in generation errors.
",3.1 Semantic Controlled LSTM cell,[0],[0]
"To address this problem, an additional control cell is introduced into the LSTM to gate the DA as shown in Figure 1.",3.1 Semantic Controlled LSTM cell,[0],[0]
This cell plays the role of sentence planning since it manipulates the DA features during the generation process in order to produce a surface realisation which accurately encodes the input information.,3.1 Semantic Controlled LSTM cell,[0],[0]
We call the resulting architecture Semantically Controlled LSTM (SC-LSTM).,3.1 Semantic Controlled LSTM cell,[0],[0]
"Starting from the original DA 1-hot vector d0, at each time step the DA cell decides what information should be retained for future time steps and discards the others,
rt = σ(Wwrwt + αWhrht−1) (7) dt = rt dt−1 (8)
where rt ∈",3.1 Semantic Controlled LSTM cell,[0],[0]
"[0, 1]d is called the reading gate, and α is a constant.",3.1 Semantic Controlled LSTM cell,[0],[0]
Here Wwr and Whr act like keyword and key phrase detectors that learn to associate certain patterns of generated tokens with certain slots.,3.1 Semantic Controlled LSTM cell,[0],[0]
Figure 3 gives an example of how these detectors work in affecting DA features inside the network.,3.1 Semantic Controlled LSTM cell,[0],[0]
"Equation 5 is then modified so that the
cell value ct also depends on the DA,
ct = ft ct−1 + it ĉt + tanh(Wdcdt) (9)
After updating Equation 6 by Equation 9, the output distribution is formed by applying a softmax function g, and the distribution is sampled to obtain the next token,
P (wt+1|wt, wt−1, ...w0,dt) = g(Whoht) (10)
wt+1 ∼ P (wt+1|wt, wt−1, ...w0,dt).",3.1 Semantic Controlled LSTM cell,[0],[0]
(11),3.1 Semantic Controlled LSTM cell,[0],[0]
"Deep Neural Networks (DNN) enable increased discrimination by learning multiple layers of features, and represent the state-of-the-art for many applications such as speech recognition (Graves et al., 2013b) and natural language processing (Collobert and Weston, 2008).",3.2 The Deep Structure,[0],[0]
The neural language generator proposed in this paper can be easily extended to be deep in both space and time by stacking multiple LSTM cells on top of the original structure.,3.2 The Deep Structure,[0],[0]
"As shown in Figure 2, skip connections are applied to the inputs of all hidden layers as well as between all hidden layers and the outputs (Graves, 2013).",3.2 The Deep Structure,[0],[0]
"This reduces the number of processing steps between the bottom of the network and the top, and therefore mitigates the vanishing gradient problem (Bengio et al., 1994) in the vertical direction.",3.2 The Deep Structure,[0],[0]
"To allow all hidden layer information to influence the reading gate, Equation 7 is changed to
rt = σ(Wwrwt + ∑
l
αlWlhrh l t−1) (12)
where l is the hidden layer index and αl is a layer-wise constant.",3.2 The Deep Structure,[0],[0]
"Since the network tends to overfit when the structure becomes more complex, the dropout technique (Srivastava et al., 2014) is used to regularise the network.",3.2 The Deep Structure,[0],[0]
"As suggested in (Zaremba et al., 2014), dropout was only applied to the non-recurrent connections, as shown in the Figure 2.",3.2 The Deep Structure,[0],[0]
It was not applied to word embeddings since pre-trained word vectors were used.,3.2 The Deep Structure,[0],[0]
"One remaining problem in the structure described so far is that the LSTM generator selects words based only on the preceding history, whereas some sentence forms depend on the backward context.",3.3 Backward LSTM reranking,[0],[0]
"Previously, bidirectional networks (Schuster and
Paliwal, 1997) have been shown to be effective for sequential problems (Graves et al., 2013a; Sundermeyer et al., 2014).",3.3 Backward LSTM reranking,[0],[0]
"However, applying a bidirectional network directly in the SC-LSTM generator is not straightforward since the generation process is sequential in time.",3.3 Backward LSTM reranking,[0],[0]
"Hence instead of integrating the bidirectional information into one network, we trained another SC-LSTM from backward context to choose best candidates from the forward generator outputs.",3.3 Backward LSTM reranking,[0],[0]
"In our experiments, we also found that by tying the keyword detector weights Wwr (see Equations 7 and 12) of both the forward and backward networks together makes the generator less sensitive to random initialisation.",3.3 Backward LSTM reranking,[0],[0]
The forward generator and the backward reranker were both trained by treating each sentence as a mini-batch.,3.4 Training,[0],[0]
The objective function was the cross entropy error between the predicted word distribution pt and the actual word distribution yt in the training corpus.,3.4 Training,[0],[0]
An l2 regularisation term was added to the objective function for every 10 training examples as suggested in Mikolov et al. (2011b).,3.4 Training,[0],[0]
"However, further regularisation was required for the reading gate dynamics.",3.4 Training,[0],[0]
"This resulted in the following modified cost function for each mini-match (ignoring standard l2),
F (θ) = ∑
t p ᵀ t log(yt) +",3.4 Training,[0],[0]
"‖dT ‖+ ∑T−1 t=0 ηξ ‖dt+1−dt‖
(13)
where dT is the DA vector at the last word index T , and η and ξ are constants set to 10−4 and 100, respectively.",3.4 Training,[0],[0]
"The second term is used to penalise generated utterances that failed to render all the required slots, while the third term discourages the network from turning more than one gate off in a single time step.",3.4 Training,[0],[0]
"The forward and backward networks were structured to share the same set of word embeddings, initialised with pre-trained word vectors (Pennington et al., 2014).",3.4 Training,[0],[0]
"The hidden layer size was set to be 80 for all cases, and deep networks were trained with two hidden layers and a 50% dropout rate.",3.4 Training,[0],[0]
All costs and gradients were computed and stochastic gradient descent was used to optimise the parameters.,3.4 Training,[0],[0]
"Both networks were trained with back propagation through time (Werbos, 1990).",3.4 Training,[0],[0]
"In order to prevent overfitting, early stopping was implemented using a held-out validation set.",3.4 Training,[0],[0]
"The decoding procedure is split into two phases: (a) over-generation, and (b) reranking.",3.5 Decoding,[0],[0]
"In the over-generation phase, the forward generator conditioned on the given DA, is used to sequentially generate utterances by random sampling of the predicted next word distributions.",3.5 Decoding,[0],[0]
"In the reranking phase, the cost of the backward reranker Fb(θ) is computed.",3.5 Decoding,[0],[0]
"Together with the cost Ff (θ) from the forward generator, the reranking score R is com-
puted as:
R = −(Ff (θ) + Fb(θ) + λERR) (14) where λ is a tradeoff constant, and the slot error rate ERR is computed by exact matching the slot tokens in the candidate utterances,
ERR = p+ q N
(15)
where N is the total number of slots in the DA, and p, q is the number of missing and redundant slots in the given realisation.",3.5 Decoding,[0],[0]
Note that the ERR reranking criteria cannot handle arbitrary slot-value pairs such as binary slots or slots that take the don’t care value because they cannot be delexicalised and exactly matched.,3.5 Decoding,[0],[0]
λ is set to a large value in order to severely penalise nonsensical outputs.,3.5 Decoding,[0],[0]
The target application for our generation system is a spoken dialogue system providing information about certain venues in San Francisco.,4.1 Experimental Setup,[0],[0]
"In order to demonstrate the scalability of the proposed method and its performance in different domains, we tested on two domains that talk about restaurants and hotels respectively.",4.1 Experimental Setup,[0],[0]
"There are 8 system dialogue act types such as inform to present information about restaurants, confirm to check that a slot value has been recognised correctly, and reject to advise that the user’s constraints cannot be met.",4.1 Experimental Setup,[0],[0]
"Each domain contains 12 attributes (slots), some are common to both domains and the others are domain specific.",4.1 Experimental Setup,[0],[0]
The detailed ontologies for the two domains are provided in Table 1.,4.1 Experimental Setup,[0],[0]
"To form a training corpus for each domain, dialogues collected from a previous user trial (Gašić et al., 2015) of a statistical dialogue manager were randomly sampled and shown to workers recruited via the Amazon Mechanical Turk (AMT) service.",4.1 Experimental Setup,[0],[0]
Workers were shown each dialogue turn by turn and asked to enter an appropriate system response in natural English corresponding to each system DA.,4.1 Experimental Setup,[0],[0]
For each domain around 5K system utterances were collected from about 1K randomly sampled dialogues.,4.1 Experimental Setup,[0],[0]
"Each categorical value was replaced by a token representing its slot, and slots that appeared multiple times in a DA were merged into one.",4.1 Experimental Setup,[0],[0]
"After processing and grouping each utterance according to its delexicalised DA, we obtained 248 distinct DAs in the restaurant domain
and 164 in the hotel domain.",4.1 Experimental Setup,[0],[0]
"The average number of slots per DA for each domain is 2.25 and 1.95, respectively.
",4.1 Experimental Setup,[0],[0]
"The system was implemented using the Theano library (Bergstra et al., 2010; Bastien et al., 2012), and trained by partitioning each of the collected corpus into a training, validation, and testing set in the ratio 3:1:1.",4.1 Experimental Setup,[0],[0]
"The frequency of each action type and slot-value pair differs quite markedly across the corpus, hence up-sampling was used to make the corpus more uniform.",4.1 Experimental Setup,[0],[0]
"Since our generator works stochastically and the trained networks can differ depending on the initialisation, all the results shown below3 were averaged over 5 randomly initialised networks.",4.1 Experimental Setup,[0],[0]
"For each DA, we overgenerated 20 utterances and selected the top 5 realisations after reranking.",4.1 Experimental Setup,[0],[0]
"The BLEU-4 metric was used for the objective evaluation (Papineni et al., 2002).",4.1 Experimental Setup,[0],[0]
"Multiple references for each test DA were obtained by mapping them back to the distinct set of DAs, grouping those delexicalised surface forms that have the same DA specification, and then lexicalising those surface forms back to utterances.",4.1 Experimental Setup,[0],[0]
"In addition, the slot error rate (ERR) as described in Section 3.5 was computed as an auxiliary metric alongside the BLEU score.",4.1 Experimental Setup,[0],[0]
"However, for the experiments it is computed at the corpus level, by averaging slot errors over each of the top 5 realisations in the entire corpus.",4.1 Experimental Setup,[0],[0]
The trade-off weights α between keyword and key phrase detectors as mentioned in Section 3.1 and 3.2 were set to 0.5.,4.1 Experimental Setup,[0],[0]
"We compared the single layer semantically controlled LSTM (sc-lstm) and a deep version with
3Except human evaluation, in which only one set of networks was used.
two hidden layers (+deep) against several baselines: the handcrafted generator (hdc), k-nearest neighbour (kNN), class-based LMs (classlm) as proposed in Oh and Rudnicky (2000), the heuristic gated RNN as described in Wen et al. (2015) and a similar LSTM variant (rnn w/ & lstm w/), and the same RNN/LSTM but without gates (rnn w/o & lstm w/o).",4.2 Objective Evaluation,[0],[0]
"The handcrafted generator was developed over a long period of time and is the standard generator used for trialling end-to-end dialogue systems (for example (Gašić et al., 2014)).",4.2 Objective Evaluation,[0],[0]
"The kNN was implemented by computing the similarity of the test DA 1-hot vector against all of the training DA 1-hot vectors, selecting the nearest and then lexicalising to generate the final surface form.",4.2 Objective Evaluation,[0],[0]
The objective results are shown in Table 2.,4.2 Objective Evaluation,[0],[0]
"As can be seen, none of the baseline systems shown in the first block (hdc, kNN, & classlm) are comparable to the systems described in this paper (sc-lstm & +deep) if both metrics are considered.",4.2 Objective Evaluation,[0],[0]
"Setting aside the difficulty of scaling to large domains, the handcrafted generator’s (hdc) use of predefined rules yields a fixed set of sentence plans, which can differ markedly from the real colloquial human responses collected from AMT, while the class LM approach suffers from inaccurate rendering of information.",4.2 Objective Evaluation,[0],[0]
"Although the kNN method provides reasonable adequacy i.e. low ERR, the BLEU is low, probably because of the errors in the collected corpus which kNN cannot handle but statistical approaches such as LMs can by suppressing unlikely outputs.
",4.2 Objective Evaluation,[0],[0]
"The last three blocks in Table 2 compares the proposed method with previous RNN approaches.
",4.2 Objective Evaluation,[0],[0]
LSTM generally works better than vanilla RNN due to its ability to model long range dependencies more efficiently.,4.2 Objective Evaluation,[0],[0]
"We also found that by using gates, whether learned or heuristic, gave much lower slot error rates.",4.2 Objective Evaluation,[0],[0]
"As an aside, the ability of the SC-LSTM to learn gates is also exemplified in Figure 3.",4.2 Objective Evaluation,[0],[0]
"Finally, by combining the learned gate approach with the deep architecture (+deep), we obtained the best overall performance.",4.2 Objective Evaluation,[0],[0]
"Since automatic metrics may not consistently agree with human perception (Stent et al., 2005), human testing is needed to assess subjective quality.",4.3 Human Evaluation,[0],[0]
"To do this, a set of judges were recruited using AMT.",4.3 Human Evaluation,[0],[0]
"For each task, two systems among the four (classlm, rnn w/, sc-lstm, and +deep) were randomly selected to generate utterances from a set of newly sampled dialogues in the restaurant domain.",4.3 Human Evaluation,[0],[0]
"In order to evaluate system performance in the presence of language variation, each system generated 5 different surface realisations for each input DA and the human judges were asked to score each of them in terms of informativeness and naturalness (rating out of 3), and also asked to state a preference between the two.",4.3 Human Evaluation,[0],[0]
"Here informativeness
is defined as whether the utterance contains all the information specified in the DA, and naturalness is defined as whether the utterance could plausibly have been produced by a human.",4.3 Human Evaluation,[0],[0]
"In order to decrease the amount of information presented to the judges, utterances that appeared identically in both systems were filtered out.",4.3 Human Evaluation,[0],[0]
"We tested 1000 DAs in total, and after filtering there were approximately 1300 generated utterances per system.
",4.3 Human Evaluation,[0],[0]
Table 3 shows the quality assessments which exhibit the same general trend as the objective results.,4.3 Human Evaluation,[0],[0]
The SC-LSTM systems (sc-lstm & +deep) outperform the class-based LMs (classlm) and the RNN with heuristic gates (rnn w/) in both metrics.,4.3 Human Evaluation,[0],[0]
"The deep SC-LSTM system (+deep) is significantly better than the class LMs (classlm) in terms of informativeness, and better than the RNN with heuristic gates (rnn w/) in terms of naturalness.",4.3 Human Evaluation,[0],[0]
The preference test results are shown in Table 4.,4.3 Human Evaluation,[0],[0]
"Again, the SC-LSTM systems (sc-lstm & +deep) were significantly preferred by the judges.",4.3 Human Evaluation,[0],[0]
"Moreover, the judges recorded a strong preference for
the deep approach (+deep) compared to the others, though the preference is not significant when comparing to its shallow counterpart (sc-lstm).",4.3 Human Evaluation,[0],[0]
Example dialogue acts and their top-5 realisations are shown in Table 5.,4.3 Human Evaluation,[0],[0]
"In this paper we have proposed a neural networkbased generator that is capable of generating natural linguistically varied responses based on a deep, semantically controlled LSTM architecture which we call SC-LSTM.",5 Conclusion and Future Work,[0],[0]
The generator can be trained on unaligned data by jointly optimising its sentence planning and surface realisation components using a simple cross entropy criterion without any heuristics or handcrafting.,5 Conclusion and Future Work,[0],[0]
We found that the SCLSTM model achieved the best overall performance on two objective metrics across two different domains.,5 Conclusion and Future Work,[0],[0]
"An evaluation by human judges also confirmed that the SC-LSTM approach is strongly preferred to a variety of existing methods.
",5 Conclusion and Future Work,[0],[0]
"This work represents a line of research that tries
to model the NLG problem in a unified architecture, whereby the entire model is end-to-end trainable from data.",5 Conclusion and Future Work,[0],[0]
We contend that this approach can produce more natural responses which are more similar to colloquial styles found in human conversations.,5 Conclusion and Future Work,[0],[0]
Another key potential advantage of neural network based language processing is the implicit use of distributed representations for words and a single compact parameter encoding of the information to be conveyed.,5 Conclusion and Future Work,[0],[0]
This suggests that it should be possible to further condition the generator on some dialogue features such discourse information or social cues during the conversation.,5 Conclusion and Future Work,[0],[0]
"Furthermore, adopting a corpus based regime enables domain scalability and multilingual NLG to be achieved with less cost and a shorter lifecycle.",5 Conclusion and Future Work,[0],[0]
These latter aspects will be the focus of our future work in this area.,5 Conclusion and Future Work,[0],[0]
"Tsung-Hsien Wen and David Vandyke are supported by Toshiba Research Europe Ltd, Cambridge Research Laboratory.",6 Acknowledgements,[0],[0]
Natural language generation (NLG) is a critical component of spoken dialogue and it has a significant impact both on usability and perceived quality.,abstractText,[0],[0]
Most NLG systems in common use employ rules and heuristics and tend to generate rigid and stylised responses without the natural variation of human language.,abstractText,[0],[0]
They are also not easily scaled to systems covering multiple domains and languages.,abstractText,[0],[0]
This paper presents a statistical language generator based on a semantically controlled Long Short-term Memory (LSTM) structure.,abstractText,[0],[0]
"The LSTM generator can learn from unaligned data by jointly optimising sentence planning and surface realisation using a simple cross entropy training criterion, and language variation can be easily achieved by sampling from output candidates.",abstractText,[0],[0]
"With fewer heuristics, an objective evaluation in two differing test domains showed the proposed method improved performance compared to previous methods.",abstractText,[0],[0]
Human judges scored the LSTM system higher on informativeness and naturalness and overall preferred it to the other systems.,abstractText,[0],[0]
Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 856–865 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
856",text,[0],[0]
"With increasing complexity of models for tasks like classification (Joulin et al., 2016), machine comprehension (Rajpurkar et al., 2016; Seo et al., 2017), and visual question answering (Zhu et al., 2016), models are becoming increasingly challenging to debug, and to determine whether they are ready for deployment.",1 Introduction,[0],[0]
"In particular, these complex models are prone to brittleness: different ways of phrasing the same sentence can often cause the model to
output different predictions.",1 Introduction,[0],[0]
"While held-out accuracy is often useful, it is not sufficient: practitioners consistently overestimate their model’s generalization (Patel et al., 2008) since test data is usually gathered in the same manner as training and validation.",1 Introduction,[0],[0]
"When deployed, these seemingly accurate models encounter sentences that are written very differently than the ones in the training data, thus making them prone to mistakes, and fragile with respect to distracting additions (Jia and Liang, 2017).",1 Introduction,[0],[0]
"These problems are exacerbated by the variability in language, and by cost and noise in annotations, making such bugs challenging to detect and fix.
",1 Introduction,[0],[0]
"A particularly challenging issue is oversensitivity (Jia and Liang, 2017): a class of bugs where models output different predictions for very similar inputs.",1 Introduction,[0],[0]
"These bugs are prevalent in image classifi-
cation (Szegedy et al., 2014), a domain where one can measure the magnitude of perturbations, and many small-magnitude changes are imperceptible to the human eye.",1 Introduction,[0],[0]
"For text, however, a single word addition can change semantics (e.g. adding “not”), or have no semantic impact for the task at hand.
",1 Introduction,[1.0000000044628967],"['For text, however, a single word addition can change semantics (e.g. adding “not”), or have no semantic impact for the task at hand.']"
"Inspired by adversarial examples for images, we introduce semantically equivalent adversaries (SEAs) – text inputs that are perturbed in semantics-preserving ways, but induce changes in a black box model’s predictions (example in Figure 1).",1 Introduction,[1.0],"['Inspired by adversarial examples for images, we introduce semantically equivalent adversaries (SEAs) – text inputs that are perturbed in semantics-preserving ways, but induce changes in a black box model’s predictions (example in Figure 1).']"
"Producing such adversarial examples systematically can significantly aid in debugging ML models, as it allows users to detect problems that happen in the real world, instead of oversensitivity only to malicious attacks such as intentionally scrambling, misspelling, or removing words (Bansal et al., 2014; Ebrahimi et al., 2018; Li et al., 2016).
",1 Introduction,[0],[0]
"While SEAs describe local brittleness (i.e. are specific to particular predictions), we are also interested in bugs that affect the model more globally.",1 Introduction,[0],[0]
"We represent these via simple replacement rules that induce SEAs on multiple predictions, such as in Figure 2, where a simple contraction of “is”after Wh pronouns (what, who, whom) (2b) makes 70 (1%) of the previously correct predictions of the model “flip” (i.e. become incorrect).",1 Introduction,[1.0],"['We represent these via simple replacement rules that induce SEAs on multiple predictions, such as in Figure 2, where a simple contraction of “is”after Wh pronouns (what, who, whom) (2b) makes 70 (1%) of the previously correct predictions of the model “flip” (i.e. become incorrect).']"
"Perhaps more surprisingly, adding a simple “?” induces mistakes in 3% of examples.",1 Introduction,[0],[0]
"We call such rules semantically equivalent adversarial rules (SEARs).
",1 Introduction,[0],[0]
"In this paper, we present SEAs and SEARs, designed to unveil local and global oversensitivity bugs in NLP models.",1 Introduction,[0],[0]
"We first present an approach to generate semantically equivalent adversaries, based on paraphrase generation techniques (Lapata et al., 2017), that is model-agnostic (i.e. works for any black box model).",1 Introduction,[0],[0]
"Next, we generalize SEAs into semantically equivalent rules, and outline the properties for optimal rule sets: semantic equivalence, high adversary count, and non-redundancy.",1 Introduction,[0],[0]
"We frame the problem of finding such a set as a
submodular optimization problem, leading to an accurate yet efficient algorithm.
",1 Introduction,[0],[0]
"Including the human into the loop, we demonstrate via user studies that SEARs help users uncover important bugs on a variety of state-of-the-art models for different tasks (sentiment classification, visual question answering).",1 Introduction,[0],[0]
"Our experiments indicate that SEAs and SEARs make humans significantly better at detecting impactful bugs – SEARs uncover bugs that cause 3 to 4 times more mistakes than human-generated rules, in much less time.",1 Introduction,[0],[0]
"Finally, we show that SEARs are actionable, enabling the human to close the loop by fixing the discovered bugs using a data augmentation procedure.",1 Introduction,[0],[0]
"Consider a black box model f that takes a sentence x and makes a prediction f(x), which we want to debug.",2 Semantically Equivalent Adversaries,[0],[0]
"We identify adversaries by generating paraphrases of x, and getting predictions from f until the original prediction is changed.
",2 Semantically Equivalent Adversaries,[0],[0]
"Given an indicator function SemEq(x, x′) that is 1 if x is semantically equivalent to x′ and 0 otherwise, we define a semantically equivalent adversary (SEA) as a semantically equivalent instance that changes the model prediction in Eq (1).",2 Semantically Equivalent Adversaries,[1.0],"['Given an indicator function SemEq(x, x′) that is 1 if x is semantically equivalent to x′ and 0 otherwise, we define a semantically equivalent adversary (SEA) as a semantically equivalent instance that changes the model prediction in Eq (1).']"
"Such adversaries are important in evaluating the robustness of f , as each is an undesirable bug.
",2 Semantically Equivalent Adversaries,[0],[0]
"SEA(x, x′)=1 [ SemEq(x, x′)∧f(x) 6=f(x′) ] (1)
While there are various ways of scoring semantic similarity between pairs of texts based on embeddings (Le and Mikolov, 2014; Wieting and Gimpel, 2017), they do not explicitly penalize unnatural sentences, and generating sentences requires surrounding context (Le and Mikolov, 2014) or training a separate model.",2 Semantically Equivalent Adversaries,[0],[0]
"We turn instead to paraphrasing based on neural machine translation (Lapata et al., 2017), where P (x′|x) (the probability of a paraphrase x′ given original sentence x) is proportional to translating x into multiple pivot languages
and then taking the score of back-translating the translations into the original language.",2 Semantically Equivalent Adversaries,[0],[0]
"This approach scores semantics and “plausibility” simultaneously (as translation models have “built in” language models) and allows for easy paraphrase generation, by linearly combining the paths of each back-decoder when back-translating.
",2 Semantically Equivalent Adversaries,[0],[0]
"Unfortunately, given source sentences x and z, P (x′|x) is not comparable to P (z′|z), as each has a different normalization constant, and heavily depends on the shape of the distribution around x or z.",2 Semantically Equivalent Adversaries,[0],[0]
"If there are multiple perfect paraphrases near x, they will all share probability mass, while if there is a paraphrase much better than the rest near z, it will have a higher score than the ones near x, even if the paraphrase quality is the same.",2 Semantically Equivalent Adversaries,[0],[0]
"We thus define the semantic score S(x, x′) as a ratio between the probability of a paraphrase and the probability of the sentence itself:
S(x, x′) = min",2 Semantically Equivalent Adversaries,[0],[0]
"( 1, P (x′|x) P (x|x) )",2 Semantically Equivalent Adversaries,[0],[0]
"(2)
We define SemEq(x, x′) = 1[S(x, x′)",2 Semantically Equivalent Adversaries,[0],[0]
"≥ τ ], i.e. x′ is semantically equivalent to x if the similarity score between x and x′ is greater than some threshold τ",2 Semantically Equivalent Adversaries,[0],[0]
(which we crowdsource in Section 5).,2 Semantically Equivalent Adversaries,[0],[0]
"In order to generate adversaries, we generate a set of paraphrases Πx around x via beam search and get predictions on Πx using the black box model until an adversary is found, or until S(x, x′)",2 Semantically Equivalent Adversaries,[0],[0]
< τ .,2 Semantically Equivalent Adversaries,[0],[0]
"We may be interested in the best adversary for a particular instance, i.e. argmaxx′∈Πx S(x, x
′)SEAx(x′), or we may consider multiple SEAs for generalization purposes.",2 Semantically Equivalent Adversaries,[0],[0]
"We illustrate this process in Figure 3, where we generate SEAs for a VQA model by generating paraphrases around the question, and checking when the model prediction changes.",2 Semantically Equivalent Adversaries,[0],[0]
"The first two adversaries with highest S(x, x′) are semantically equivalent, the third maintains the semantics enough for it to be a useful adversary, and the fourth is ungrammatical and thus not useful.",2 Semantically Equivalent Adversaries,[0],[0]
"While finding the best adversary for a particular instance is useful, humans may not have time or patience to examine too many SEAs, and may not be able to generalize well from them in order to understand and fix the most impactful bugs.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"In this section, we address the problem of generalizing local adversaries into Semantically Equivalent
Adversarial Rules for Text (SEARs), search and replace rules that produce semantic adversaries with little or no change in semantics, when applied to a corpus of sentences.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"Assuming that humans have limited time, and are thus willing to look at B rules, we propose a method for selecting such a set of rules given a reference dataset X .
",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"A rule takes the form r = (a→c), where the first instance of the antecedent a is replaced by the consequent c for every instance that includes a, as we previously illustrated in Figure 2a.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"The output after applying rule r on a sentence x is represented as the function call r(x), e.g. if r =(movie→film), r(“Great movie!”) =",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"“Great film!”.
",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"Proposing a set of rules: In order to generalize a SEA x′ into a candidate rule, we must represent the changes that took place from x→ x′.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"We will use x = “What color is it?” and x′ = “Which color is it?” from Figure 4 as a running example.
",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"One approach is exact matching: selecting the minimal contiguous sequence that turns x into x′, (What→Which) in the example.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"Such changes may not always be semantics preserving, so we also propose further rules by including the immediate context (previous and/or next word with respect to the sequence), e.g. (What color→Which color).",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"Adding such context, however, may make rules very specific, thus restricting their value.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"To allow for generalization, we also represent the antecedent of proposed rules by a product of their raw text with coarse and fine-grained Part-of-Speech tags, and allow these tags to happen in the consequent if they match the antecedent.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"In the running example, we would propose rules like (What color→Which color), (What NOUN→Which NOUN ), (WP color→Which color), etc.
We generate SEAs and propose rules for every x ∈ X , which gives us a set of candidate rules (second box in Figure 4, for loop in Algorithm 1).
",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"Selecting a set of rules: Given a set of candidate rules, we want to select a set R such that |R| ≤ B, and the following properties are met:
1.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
Semantic Equivalence:,3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
Application of the rules in the set should produce semantically equivalent instances.,3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"This is equivalent to considering rules that have a high probability of inducing semantically equivalent instances when applied, i.e. E[SemEq(x, r(x))]",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
≥ 1−δ.,3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
This is the Filter step in Algorithm 1.,3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"For example, consider the rule (What→Which) in Fig 4 which produces some semantically equivalent instances, but also produces many instances that are unnatural (e.g. “What is he doing?”",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"→ “Which is he doing?”), and is thus filtered out by this criterion.
2.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
High adversary count: The rules in the set should induce as many SEAs as possible in validation data.,3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"Furthermore, each of the induced SEAs should have as high of a semantic similarity score as possible, i.e. for each rule r ∈ R we want to maximize ∑ x∈X S(x, r(x))SEA(x, r(x)).",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"In Figure 4, r1 induces more and more similar mistakes when compared to r4, and is thus superior to r4.
3.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
Non,3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"-redundancy: Different rules in the set may induce the same SEAs, or may induce different SEAs for the same instances.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"Ideally, rules in the set should cover as many instances in the validation as possible, rather than focus on a small set of fragile predictions.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"Furthermore, rules should not be repetitive to the user.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"In Figure 4 (mid), r1 covers a superset of r2’s adversaries, making r2 completely redundant and thus not included in R.
Properties 2 and 3 combined suggest a weighted coverage problem, where a rule r covers an instance x if SEA(x, r(x)), the weight of the connection being given by S(x, r(x)).",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"We thus want to
Algorithm 1 Generating SEARs for a model Require: Classifier f , Correct instances X Require: Hyperparameters, δ, τ , Budget B R ← {}{Set of rules} for all x ∈ X do X ′",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"= GenParaphrases(X, τ)",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
A ← {x′ ∈ X ′,3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"| f(x) 6= f(x′)} {SEAs; §2} R ← R∪ Rules(A)
end for R ← Filter(R, δ, τ) {Remove low scoring SEARs} R ← SubMod(R, B) {high count / score, diverse } return R
find the set of semantically equivalent rules that:
max R,|R|<B ∑ x∈X max r∈R S(x, r(x))SEA(x, r(x)) (3)
While Eq (3) is NP-hard, the objective is monotone submodular (Krause and Golovin, 2014), and thus a greedy algorithm that iteratively adds the rule with the highest marginal gain offers a constantfactor approximation guarantee of 1 − 1/e to the optimum.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"This is the SubMod procedure in Algorithm 1, represented pictorially in Figure 4, where the output is a set of rules given to a human, who judges if they are really bugs or not.",3 Semantically Equivalent Adversarial Rules (SEARs),[0],[0]
"Before evaluating the utility of SEAs and SEARs with user studies, we show examples in state-of-theart models for different tasks.",4 Illustrative Examples,[0],[0]
"Note that we treat these models as black boxes, not using internals or gradients in any way when discovering these bugs.
",4 Illustrative Examples,[0],[0]
"Machine Comprehension: We take the AllenNLP (Gardner et al., 2017) implementation of BiDaF (Seo et al., 2017) for Machine Comprehension, and display some high coverage SEARs for it in Table 1 (also, Figures 1 and 2a).",4 Illustrative Examples,[0],[0]
"For each rule,
we display two example questions with the corresponding SEA, the prediction (with corresponding change) and the percentage of “flips” - instances previously predicted correctly on the validation data, but predicted incorrectly after the application of the rule.",4 Illustrative Examples,[0.9546157232444682],['We compare expert-generated rules with accepted SEARs (each subject’s rules are compared to the SEARs they accepted) in terms of the percentage of the correct predictions that “flip” when the rules are applied.']
"The rule (What VBZ→What’s) generalizes the SEA on Figure 1, and shows that the model is fragile with respect to contractions (flips 2% of all correctly predicted instances on the validation data).",4 Illustrative Examples,[1.0],"['The rule (What VBZ→What’s) generalizes the SEA on Figure 1, and shows that the model is fragile with respect to contractions (flips 2% of all correctly predicted instances on the validation data).']"
"The second rule uncovers a bug with respect to simple question rephrasing, while the third and fourth rules show that the model is not robust to a more conversational style of asking questions.
",4 Illustrative Examples,[0],[0]
"Visual QA: We show SEARs for a state-of-theart visual question-answering model (Zhu et al., 2016) in Table 2.",4 Illustrative Examples,[0],[0]
"Even though the contexts are different (paragraphs for machine comprehension, images for VQA), it is interesting that both models display similar bugs.",4 Illustrative Examples,[0],[0]
"The fact that VQA is fragile to “Which” questions is because questions of this form are not in the training set, while (color→colour) probably stems from an American bias in data collection.",4 Illustrative Examples,[0],[0]
"Changes induced by these four rules flip more than 10% of the predictions in the validation data, which is of critical concern if the model is being evaluated for production.
",4 Illustrative Examples,[0],[0]
"Sentiment Analysis: Finally, in Table 3 we display SEARs for a fastText (Joulin et al., 2016) model for sentiment analysis trained on movie reviews.",4 Illustrative Examples,[1.0],"['Sentiment Analysis: Finally, in Table 3 we display SEARs for a fastText (Joulin et al., 2016) model for sentiment analysis trained on movie reviews.']"
"Surprisingly, many of its predictions change for perturbations that have no sentiment connotations, even in the presence of polarity-laden words.",4 Illustrative Examples,[0],[0]
"We compare automatically discovered SEAs and SEARs to user-generated adversaries and rules, and propose a way to fix the bugs induced by SEARs.
",5 User Studies,[0],[0]
Our evaluation benchmark includes two tasks: visual question answering (VQA) and sentiment analysis on movie review sentences.,5 User Studies,[0],[0]
"We choose these tasks because a human can quickly look at a prediction and judge if it is correct or incorrect, can easily perturb instances, and judge if two instances in a pair are semantically equivalent or not.",5 User Studies,[0],[0]
"Since our focus is debugging, throughout the experiment we only considered SEAs and SEARs on examples that are originally predicted correctly (i.e. every adversary is also by construction a mistake).",5 User Studies,[0],[0]
The user interfaces for all experiments in this section are included in the supplementary material.,5 User Studies,[0],[0]
"The paraphrasing model (Lapata et al., 2017) requires translation models to and from different languages.",5.1 Implementation Details,[0],[0]
"We train neural machine translation models using the default parameters of OpenNMTpy (Klein et al., 2017) for English↔Portuguese and English↔French models, on 2 million and 1 million parallel sentences (respectively) from EuroParl, news, and other sources (Tiedemann, 2012).",5.1 Implementation Details,[0],[0]
We use the spacy library (http://spacy.io) for POS tagging.,5.1 Implementation Details,[0],[0]
"For SEAR generation, we set δ = 0.1 (i.e. at least 90% equivalence).",5.1 Implementation Details,[0],[0]
"We generate a set of candidate adversaries as described in Section 2, and ask mechanical turkers to judge them
for semantic equivalence.",5.1 Implementation Details,[0],[0]
"Using these evaluations, we identify τ = 0.0008 as the value that minimizes the entropy in the induced splits, and use it for the remaining experiments.",5.1 Implementation Details,[0],[0]
"Source code and pretrained language models are available at https: //github.com/marcotcr/sears.
",5.1 Implementation Details,[0],[0]
"For VQA, we use the multiple choice telling system and dataset of Zhu et al. (2016), using their implementation, with default parameters.",5.1 Implementation Details,[0],[0]
"The training data consists of questions that begin with “What”, “Where”, “When”, “Who”, “Why”, and “How”.",5.1 Implementation Details,[0],[0]
"The task is multiple choice, with four possible answers per instance.",5.1 Implementation Details,[0],[0]
"For sentiment analysis, we train a fastText (Joulin et al., 2016) model with unigrams and bigrams (embedding size of 50) on RottenTomato movie reviews (Pang and Lee, 2005), and evaluate it on IMDB sentence-sized reviews (Kotzias et al., 2015), simulating the common case where a model trained on a public dataset is applied to new data from a similar domain.",5.1 Implementation Details,[0],[0]
"In this experiment, we compare our method for generating SEAs with user’s ability to discover semantic-preserving adversaries.",5.2 Can humans find good adversaries?,[0],[0]
We take a random sample of 100 correctly-predicted instances for each task.,5.2 Can humans find good adversaries?,[0],[0]
"In the first condition (human), we display each instance to 3 Amazon Mechanical
Turk workers, and give them 10 attempts at creating semantically equivalent adversaries (with immediate feedback as to whether or not their attempts changed the prediction).",5.2 Can humans find good adversaries?,[0],[0]
"Next, we ask them to choose the adversary that is semantically closest to the original instance, out of the candidates they generated.",5.2 Can humans find good adversaries?,[0],[0]
"In the second condition (SEA), we generate adversaries for each of the instances, and pick the best adversary according to the semantic scorer.",5.2 Can humans find good adversaries?,[0],[0]
"The third condition (HSEA) is a collaboration between our method and humans: we take the top 5 adversaries ranked by S(x, x′), and ask workers to pick the one closest to the original instance, rather than asking them to generate the adversaries.
",5.2 Can humans find good adversaries?,[0],[0]
"To evaluate whether the proposed adversaries are semantically equivalent, we ask a separate set of workers to evaluate the similarity between each adversary and the original instance (with the image as context for VQA), on a scale of 1 (completely unrelated) to 5 (exactly the same meaning).",5.2 Can humans find good adversaries?,[0],[0]
"Each adversary is evaluated by at least 10 workers, and considered equivalent if the median score ≥ 4.",5.2 Can humans find good adversaries?,[0],[0]
"We thus obtain 300 comparisons between human and SEA, and 300 between human and HSEA.
",5.2 Can humans find good adversaries?,[0],[0]
"The results in Table 4a and 4b are consistent across tasks: both models are susceptible to SEAs for a large fraction of predictions, and our fully automated method is able to produce SEAs as often as humans (left columns).",5.2 Can humans find good adversaries?,[0],[0]
"On the other hand, asking humans to choose from generated SEAs (HSEA) yields much better results than asking humans to generate them (right columns), or using the highest scored SEA.",5.2 Can humans find good adversaries?,[0],[0]
"The semantic scorer does make mistakes, so the top adversary is not always semantically equivalent, but a good quality SEA is often in the top 5, and is easily identified by users.
",5.2 Can humans find good adversaries?,[0],[0]
"On both datasets, the automated method or humans were able to generate adversaries at the exclusion of the other roughly one third of the time, which indicates that they do not generate the same adversaries.",5.2 Can humans find good adversaries?,[0],[0]
"Humans generate paraphrases differently than our method: the average character edit distance of our SEAs is 6.2 for VQA and 9.0 for Sentiment, while for humans it is 18.1 and 43.3, respectively.",5.2 Can humans find good adversaries?,[0],[0]
This is illustrated by examples in Table 5 - in Table 5a we see examples where very compact changes generate adversaries (humans were not able to find these changes though).,5.2 Can humans find good adversaries?,[1.0],['This is illustrated by examples in Table 5 - in Table 5a we see examples where very compact changes generate adversaries (humans were not able to find these changes though).']
"The examples in Table 5b indicate that humans can generate adversaries that: (1) make use of the visual context in VQA, which our method does not, and (2) sig-
Dataset Original SEA
VQA Where are the men?",5.2 Can humans find good adversaries?,[0],[0]
Where are the males?,5.2 Can humans find good adversaries?,[0],[0]
What kind of meat is on the boy’s plate?,5.2 Can humans find good adversaries?,[0],[0]
"What sort of meat is on the boy’s plate?
",5.2 Can humans find good adversaries?,[0],[0]
"Sentiment They are so easy to love,but even more easy to identify with.",5.2 Can humans find good adversaries?,[0],[0]
"They’re so easy to love, but even more easy to identify with.
",5.2 Can humans find good adversaries?,[0],[0]
Today the graphics are crap.,5.2 Can humans find good adversaries?,[0],[0]
"Today, graphics are bullshit.
",5.2 Can humans find good adversaries?,[0],[0]
"(a) Automatically generated adversaries, examples where humans failed to generate SEAs (Only SEA)
",5.2 Can humans find good adversaries?,[0],[0]
"Dataset Original Human-generated SEA
VQA How many suitcases?",5.2 Can humans find good adversaries?,[0],[0]
How many suitcases are sit-ting on the shelf?,5.2 Can humans find good adversaries?,[0],[0]
Where is the blue van?,5.2 Can humans find good adversaries?,[0],[0]
"What is the blue van’s loca-
tion?
",5.2 Can humans find good adversaries?,[0],[0]
Sentiment (very serious spoilers) thismovie was a huge disappointment.,5.2 Can humans find good adversaries?,[0],[0]
"serious spoilers this movie did not deliver what I hoped
Also great directing and photography.",5.2 Can humans find good adversaries?,[0],[0]
"Photography and directing were on point.
",5.2 Can humans find good adversaries?,[0],[0]
"(b) Human generated adversaries, examples where our approach failed to generate SEAs (Only Human)
Table 5:",5.2 Can humans find good adversaries?,[0],[0]
"Examples of generated adversaries
nificantly change the sentence structure, which the translation-based semantic scorer does not.",5.2 Can humans find good adversaries?,[0],[0]
"Here we investigate whether experts are able to detect high-impact global bugs, i.e. devise rules that flip many predictions, and compare them to generated SEARs.",5.3 Can experts find high-impact bugs?,[0],[0]
"Instead of AMT workers, we have 26 expert subjects: students, graduates, or professors who have taken at least a graduate course in machine learning or NLP1.",5.3 Can experts find high-impact bugs?,[0],[0]
"The experiment setup is as follows: for each task, subjects are given an interface where they see examples in the validation data, perturb those examples, and get predictions.",5.3 Can experts find high-impact bugs?,[0],[0]
"The interface also allows them to create search and replace rules, with immediate feedback on how many mistakes are induced by their rules.",5.3 Can experts find high-impact bugs?,[0],[0]
"They also see the list of examples where the rules apply, so they can verify semantic equivalence.",5.3 Can experts find high-impact bugs?,[0],[0]
"Subjects are instructed to try to maximize the number of mistakes induced in the validation data (i.e. maximize “mistake coverage”), but only through semantically equivalent rules.",5.3 Can experts find high-impact bugs?,[0],[0]
"They can try as many rules as they like, and are asked to select the best set of at most 10 rules at the end.",5.3 Can experts find high-impact bugs?,[0],[0]
"This is quite a challenging task for humans (yet another reason to prefer algorithmic approaches), but we are not aware of any existing automated methods.",5.3 Can experts find high-impact bugs?,[0],[0]
"Finally, we in-
1We have an IRB/consent form, and personal information was only collected as needed to compensate subjects
struct subjects they could finish each task in about 15 minutes (some took longer, some ended earlier), in order to keep the total time reasonable.
",5.3 Can experts find high-impact bugs?,[0],[0]
"After creating their rules for VQA and sentiment analysis, the subjects evaluate 20 SEARs (one rule at a time) for each task, and accept only semantically equivalent rules.",5.3 Can experts find high-impact bugs?,[0],[0]
"When a subject rejects a rule, we recompute the remaining set according to Eq (3) in real time.",5.3 Can experts find high-impact bugs?,[0],[0]
"If a subject accepts more than 10 rules, only the first 10 are considered, in order to ensure a fair comparison against the expert-generated rules.
",5.3 Can experts find high-impact bugs?,[0],[0]
We compare expert-generated rules with accepted SEARs (each subject’s rules are compared to the SEARs they accepted) in terms of the percentage of the correct predictions that “flip” when the rules are applied.,5.3 Can experts find high-impact bugs?,[0],[0]
"This is what we asked the subjects to maximize, and all the rules were ones deemed to be semantic equivalent by the subjects themselves.",5.3 Can experts find high-impact bugs?,[0],[0]
We also consider the union of expertgenerated rules and accepted SEARs.,5.3 Can experts find high-impact bugs?,[1.0],['We also consider the union of expertgenerated rules and accepted SEARs.']
"The results in Figure 5 show that on both datasets, the filtered SEARs induce a much higher rate of mistakes than the rules the subjects themselves created, with a small increase when the union of both sets is taken.",5.3 Can experts find high-impact bugs?,[0],[0]
"Furthermore, subjects spent less time evaluating
SEARs than trying to create their own rules (Figure 6).",5.3 Can experts find high-impact bugs?,[0],[0]
"SEARs for sentiment analysis contain fewer POS tags, and are thus easier to evaluate for semantic equivalence than for VQA.
",5.3 Can experts find high-impact bugs?,[0],[0]
"Discovering these bugs is hard for humans (even experts) without SEARs: not only do they need to imagine rules that maintain semantic equivalence, they must also discover the model’s weak spots.",5.3 Can experts find high-impact bugs?,[0],[0]
"Making good use of POS tags is also a challenge: only 50% of subjects attempt rules with POS tags for VQA, 36% for sentiment analysis.
",5.3 Can experts find high-impact bugs?,[1.0000000203545443],"['Making good use of POS tags is also a challenge: only 50% of subjects attempt rules with POS tags for VQA, 36% for sentiment analysis.']"
"Experts accepted 8.69 rules (on average) out of 20 for VQA as semantically equivalent, and 17.32 out of 20 for sentiment analysis.",5.3 Can experts find high-impact bugs?,[0],[0]
"Similar to the previous experiment, errors made by the semantic scorer lead to rules that are not semantically equivalent (e.g. Table 7).",5.3 Can experts find high-impact bugs?,[1.0],"['Similar to the previous experiment, errors made by the semantic scorer lead to rules that are not semantically equivalent (e.g. Table 7).']"
"With minimal human intervention, however, SEARs vastly outperform human experts in finding impactful bugs.",5.3 Can experts find high-impact bugs?,[1.0],"['With minimal human intervention, however, SEARs vastly outperform human experts in finding impactful bugs.']"
"Once such bugs are discovered, it is natural to want to fix them.",5.4 Fixing bugs using SEARs,[1.0],"['Once such bugs are discovered, it is natural to want to fix them.']"
"The global and deterministic nature of SEARs make them actionable, as they represent bugs in a systematic manner.",5.4 Fixing bugs using SEARs,[0],[0]
"Once impactful bugs are identified, we use a simple data augmentation procedure: applying SEARs to the training data, and retraining the model on the original training augmented with the generated examples.
",5.4 Fixing bugs using SEARs,[0],[0]
"We take the rules that are accepted by ≥ 20 subjects as accepted bugs, a total of 4 rules (in Table 2) for VQA, and 16 rules for sentiment (including ones in Table 3).",5.4 Fixing bugs using SEARs,[1.0],"['We take the rules that are accepted by ≥ 20 subjects as accepted bugs, a total of 4 rules (in Table 2) for VQA, and 16 rules for sentiment (including ones in Table 3).']"
"We then augment the training data by applying these rules to it, and retrain the models.",5.4 Fixing bugs using SEARs,[0],[0]
"To check if the bugs are still present, we create a sensitivity dataset by applying these SEARs to instances predicted correctly on the validation.",5.4 Fixing bugs using SEARs,[0],[0]
"A model not prone to the bugs described by these
rules should not change any of its predictions, and should thus have error rate 0% on this sensitivity data.",5.4 Fixing bugs using SEARs,[0],[0]
"We also measure accuracy on the original validation data, to make sure that our bug-fixing procedure is not decreasing accuracy.
",5.4 Fixing bugs using SEARs,[0],[0]
"Table 6 shows that the incidence of these errors is greatly reduced after augmentation, with negligible changes to the validation accuracy (on both tasks, the changes are consistent with the effect of retraining with different seeds).",5.4 Fixing bugs using SEARs,[0],[0]
"These results show that SEARs are useful not only for discovering bugs, but are also actionable through a simple augmentation technique for any model.",5.4 Fixing bugs using SEARs,[1.0],"['These results show that SEARs are useful not only for discovering bugs, but are also actionable through a simple augmentation technique for any model.']"
"Previous work on debugging primarily focuses on explaining predictions in validation data in order to uncover bugs (Ribeiro et al., 2016, 2018; Kulesza et al., 2011), or find labeling errors (Zhang et al., 2018; Koh and Liang, 2017).",6 Related Work,[0],[0]
"Our work is complementary to these techniques, as they provide no mechanism to detect oversensitivity bugs.",6 Related Work,[0],[0]
"We are able to uncover these bugs even when they are not present in the data, since we generate sentences.
",6 Related Work,[0],[0]
"Adversarial examples for image recognition are typically indistinguishable to the human eye (Szegedy et al., 2014).",6 Related Work,[0],[0]
"These are more of a security concern than bugs per se, as images with adversarial noise are not “natural”, and not expected to occur in the real world outside of targeted attacks.",6 Related Work,[0],[0]
"Adversaries are usually specific to predictions, and even universal adversarial perturbations (Moosavi-Dezfooli et al., 2017) are not natural, semantically meaningful to humans, or actionable.",6 Related Work,[0],[0]
"“Imperceptible” adversarial noise does not carry over from images to text, as adding or changing a single word in a sentence can drastically alter its meaning.",6 Related Work,[0],[0]
"Jia and Liang (2017) recognize that a true analog to detect oversensitivity would need semantic-preserving perturbations, but do not pursue an automated solution due to the difficulty of paraphrase generation.",6 Related Work,[0],[0]
"Their adversaries are whole sentence concatenations, generated by manually defined rules tailored to reading comprehension, and each adversary is specific to an individual instance.",6 Related Work,[0],[0]
"Zhao et al. (2018) generate natural text adversaries by projecting the input data to a latent space using a generative adversarial networks (GANs), and searching for adversaries close to the original instance in this latent space.",6 Related Work,[0],[0]
"Apart from the challenge of training GANs to generate high
quality text, there is no guarantee that an example close in the latent space is semantically equivalent.",6 Related Work,[0],[0]
"Ebrahimi et al. (2018), along with proposing character-level changes that are not semanticpreserving, also propose a heuristic that replaces single words adversarially to preserve semantics.",6 Related Work,[0],[0]
"This approach not only depends on having whitebox access to the model, but is also not able to generate many adversaries (only ∼ 1.6% for sentiment analysis, compare to ∼ 33% for SEAs in Table 4b).",6 Related Work,[0],[0]
"Developed concurrently with our work, Iyyer et al. (2018) proposes a neural paraphrase model based on back-translated data, which is able to produce paraphrases that have different sentence structures from the original.",6 Related Work,[0],[0]
"They use paraphrases to generate adversaries and try to post-process nonsensical outputs, but they do not explicitly reject non-semantics preserving ones, nor do they try to induce rules from individual adversaries.",6 Related Work,[0],[0]
"In any case, their adversaries are also useful for data augmentation, in experiments similar to ours.
",6 Related Work,[0],[0]
"In summary, previous work on text adversaries change semantics, only generate local (instancespecific) adversaries (Zhao et al., 2018; Iyyer et al., 2018), or are tailored for white-box models (Ebrahimi et al., 2018) or specific tasks (Jia and Liang, 2017).",6 Related Work,[0],[0]
"In contrast, SEAs expose oversensitivity for specific predictions of black-box models for a variety of tasks, while SEARs are intuitive and actionable global rules that induce a high number of high-quality adversaries.",6 Related Work,[0],[0]
"To our knowledge, we are also the first to evaluate human performance in adversarial generation (semantics-preserving or otherwise), and our extensive evaluation shows that SEAs and SEARs detect individual bugs and general patterns better than humans can.",6 Related Work,[0],[0]
"Having demonstrated the usefulness of SEAs and SEARs in a variety of domains, we now describe their limitations and opportunities for future work.
",7 Limitations and Future Work,[0],[0]
"Semantic scoring errors: Paraphrasing is still an active area of research, and thus our semantic scorer is sometimes incorrect in evaluating rules for semantic equivalence.",7 Limitations and Future Work,[0],[0]
"We show examples of SEARs that are rejected by users in Table 7 – the semantic scorer does not sufficiently penalize preposition changes, and is biased towards common terms.",7 Limitations and Future Work,[0],[0]
"The presence of such errors is why we still need humans in the loop to accept or reject SEARs.
",7 Limitations and Future Work,[0],[0]
"Other paraphrase limitations: Paraphrase models based on neural machine translation are biased towards maintaining the sentence structure, and thus do not produce certain adversaries (e.g. Table 5b), which recent work on paraphrasing (Iyyer et al., 2018) or generation using GANs (Zhao et al., 2018) may address.",7 Limitations and Future Work,[0],[0]
"More critically, existing models are inaccurate for long texts, restricting SEAs and SEARs to sentences.
",7 Limitations and Future Work,[0],[0]
Better bug fixing: Our data augmentation has the human users accept/reject rules based on whether or not they preserve semantics.,7 Limitations and Future Work,[0],[0]
"Developing more effective ways of leveraging the expert’s time to close the loop, and facilitating more interactive collaboration between humans and SEARs are exciting areas for future work.",7 Limitations and Future Work,[0],[0]
"We introduced SEAs and SEARs – adversarial examples and rules that preserve semantics, while causing models to make mistakes.",8 Conclusion,[0],[0]
"We presented examples of such bugs discovered in state-of-theart models for various tasks, and demonstrated via user studies that non-experts and experts alike are much better at detecting local and global bugs in NLP models by using our methods.",8 Conclusion,[0],[0]
We also close the loop by proposing a simple data augmentation solution that greatly reduced oversensitivity while maintaining accuracy.,8 Conclusion,[0],[0]
"We demonstrated that SEAs and SEARs can be an invaluable tool for debugging NLP models, while indicating their current limitations and avenues for future work.",8 Conclusion,[0],[0]
"We are grateful to Dan Weld, Robert L. Logan IV, and to the anonymous reviewers for their feedback.",Acknowledgements,[0],[0]
"This work was supported in part by ONR award #N00014-13-1-0023, in part by NSF award #IIS1756023, and in part by funding from FICO.",Acknowledgements,[0],[0]
The views expressed are of the authors and do not reflect the policy or opinion of the funding agencies.,Acknowledgements,[0],[0]
"Complex machine learning models for NLP are often brittle, making different predictions for input instances that are extremely similar semantically.",abstractText,[0],[0]
"To automatically detect this behavior for individual instances, we present semantically equivalent adversaries (SEAs) – semantic-preserving perturbations that induce changes in the model’s predictions.",abstractText,[0],[0]
"We generalize these adversaries into semantically equivalent adversarial rules (SEARs) – simple, universal replacement rules that induce adversaries on many instances.",abstractText,[0],[0]
"We demonstrate the usefulness and flexibility of SEAs and SEARs by detecting bugs in black-box state-of-the-art models for three domains: machine comprehension, visual questionanswering, and sentiment analysis.",abstractText,[0],[0]
"Via user studies, we demonstrate that we generate high-quality local adversaries for more instances than humans, and that SEARs induce four times as many mistakes as the bugs discovered by human experts.",abstractText,[0],[0]
"SEARs are also actionable: retraining models using data augmentation significantly reduces bugs, while maintaining accuracy.",abstractText,[0],[0]
Semantically Equivalent Adversarial Rules for Debugging NLP models,title,[0],[0]

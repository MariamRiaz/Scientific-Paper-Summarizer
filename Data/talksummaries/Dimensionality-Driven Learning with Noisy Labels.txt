7	14	Such methods often assume the availability of a supplementary labelled dataset containing pre-identified noisy labels which are used to develop a model of the label noise.
9	52	A different approach to tackle noisy labels is to utilize correction methods such as loss correction (Patrini et al., 2017; Ghosh et al., 2017), label correction (Reed et al., 2014), or additional linear correction layers (Sukhbaatar & Fergus, 2014; Goldberger & Ben-Reuven, 2017).
10	56	In this paper, we first investigate the dimensionality of the deep representation subspaces learned by a DNN and provide a dimensionality-driven explanation of DNN generalization behavior in the presence of (class) label noise.
12	23	We show that DNNs follow two-stage of learning in this scenario: 1) an early stage of dimensionality compression, that models low-dimensional subspaces that closely match the underlying data distribution, and 2) a later stage of dimensionality expansion, that steadily increases subspace dimensionality in order to overfit noisy labels.
14	20	Based on this finding, we propose a new training strategy, termed Dimensionality-Driven Learning, that avoids the dimensionality expansion stage of learning by adapting the loss function.
15	102	Our main contributions are: • We show that from a dimensionality perspective, DNNs exhibit distinctive learning styles with clean labels versus noisy labels.
18	32	• We empirically demonstrate on MNIST, SVHN, CIFAR-10 and CIFAR-100 datasets that our Dimensionality-Driven Learning strategy can effectively learn (1) low-dimensional representation subspaces that capture the underlying data distribution, (2) simpler hypotheses, and (3) high-quality deep representations.
57	17	Given a data sample x ∈ X , let r > 0 be a random variable denoting the distance from x to other data samples.
60	15	(3) LIDF describes the relative rate at which its cumulative distance function F (r) increases as the distance r increases.
62	18	Nevertheless, in more general cases, LID also provides a rough indication of the dimension of the submanifold containing x that would best fit the data distribution in the vicinity of x.
65	15	With respect to a dataset X drawn from P , the smallest k nearest neighbor distances from x can be regarded as extreme events associated with the lower tail of the induced distance distribution.
77	18	The resulting LID scores and the train/test accuracies are shown in Figure 1.
78	21	When learning with clean labels, we observe a decreasing trend in LID score and an increasing trend in accuracy as the number of training epochs increases.
86	24	From the above empirical results, we find that DNNs follow two-stage of learning in the presence of label noise: 1) an early stage of dimensionality compression, in which the dimensionalities associated with the underlying data manifold are learned; and 2) a later stage of dimensionality expansion, in which the subspace dimensionalities steadily increase as the learning process overfits to the noisy data.
110	15	This givesm×|XiB | LID estimates, which are then averaged to compute the LID score for the epoch (later, in the experiments, we use m = 10 and |XiB | = 128 To avoid dimensionality expansion during training with noisy labels, we propose to reduce the effect of noisy labels on learning the true data distribution using the following adaptive LID-corrected labels: y∗ = αiy + (1− αi)ŷ, (6) where αi is a LID-based factor that updates at the i-th training epoch: αi = exp ( − λ L̂IDi mini−1j=0 L̂IDj ) , (7) where λ = i/T is a weighting that indicates decreasing confidence in the raw labels when the training proceeds to the dimensionality expansion stage (that is, when LID begins to increase).
113	19	The role of α is an exponential decay factor that allows for interpolation between raw and predicted label assignments according to the degree of dimensional expansion observed over the learning history.
115	28	As the learning enters the dimensional expansion stage, this ratio exceeds 1, and the exponential decay factor begins to favor the current predicted label.
130	24	We first provide an empirical understanding of the proposed D2L learning strategy on subspace learning, hypothesis learning, representation learning and model analysis.
149	44	Note that for the case of 60% label noise, the low test accuracy of the ‘backward’ model, as well as the low dimensionality of the learned subspaces, together show that this competitor suffered from underfitting.
154	21	As shown in Figure 3, the complexity of the learned hypothesis from D2L is significantly lower than that of its competitors.
158	23	For each class, 40% of the samples were assigned correct labels (the ‘clean’ samples), and 60% were assigned incorrect labels chosen uniformly at random from the 9 other classes (the ‘noisy’ samples).
166	14	Finally, we evaluate the robustness of D2L against noisy labels under varying noise rates (0%, 20%, 40%, and 60%) on several benchmark datasets, comparing to state-of-the-art baselines for noisy label learning.
178	14	We also note that as the noise rate increases, the accuracy drop of D2L is the smallest among all models.
179	68	Even with 60% label noise, D2L can still obtain a relatively high classification accuracy, which indicates that D2L may have the potential to be an effective strategy for semi-supervised learning.
180	16	In this paper, we have investigated the generalization behavior of DNNs for noisy labels in terms of the intrinsic dimensionality of local subspaces.
182	41	Employing a simple measure of local intrinsic dimensionality (LID), we proposed a Dimensionality-Driven Learning (D2L) strategy for avoiding overfitting that identifies the learning epoch at which the transition from dimensional compression to dimensional expansion occurs, and then suppresses the subsequent dimensionality expansion.
183	31	D2L delivers very strong classification performance across a range of scenarios with high proportions of noisy labels.
184	119	We believe that dimensionality-based analysis opens up new directions for understanding and enhancing the behavior of DNNs.
185	47	Theoretical formulation of DNN subspace dimensionality, and investigation of the effects of data augmentation and regularization techniques such as batch normalization (Ioffe & Szegedy, 2015) and dropout (Srivastava et al., 2014) are possible directions for future research.
186	127	Another open issue is the investigation of how other forms of noise such as adversarial or corrupted inputs and asymmetric label noise can affect local subspace dimensionality and DNN learning behavior.

0	34	Automated text simplification (ATS) tries to automatically transform (syntactically, lexically and/or semantically) complex sentences into their simpler variants without significantly altering the original meaning.
2	21	However, the state-of-the-art ATS systems still do not reach satisfying performances and require some human post-editing (Štajner and Popović, 2016).
3	8	While the best supervised approaches generally lead to grammatical output with preserved original meaning, they are overcautious, making almost no changes to the input sentences (Specia, 2010; Štajner et al., 2015), probably due to the limited size or bad quality of parallel TS corpora used for training.
4	26	The largest existing sentence-aligned TS dataset for English is the English Wikipedia – Simple English Wikipedia (EW–SEW) dataset, which contains 160-280,000 sentence pairs, depending on whether we want to model only traditional sentence rewritings or also to model content reduction and stronger paraphrasing (Hwang et al., 2015).
5	17	For Spanish, the largest existing parallel TS corpus contains only 1,000 sentence pairs thus impeding the use of fully supervised approaches.
6	51	The best unsupervised lexical simplification (LS) systems for English which leverage word-embeddings (Glavaš and Štajner, 2015; Paetzold and Specia, 2016) seem to perform more lexical substitutions but at the cost of having less grammatical output and more often changed meaning.
8	39	The Newsela corpora1 offers over 2,000 original news articles in English and around 250 in Spanish, manually simplified to 3–4 different complexity levels following strict guidelines (Xu et al., 2015).
9	8	Although it was suggested that it has better quality than the EW–SEW corpus (Xu et al., 2015), Newsela has not yet been used for training end-to-end ATS systems, due to the lack of its sentence (and paragraph) alignments.
10	8	Such alignments, between various text complexity levels, would offer large training datasets for modelling different levels of simplification, i.e. ‘mild’ simplifications (using the alignments from the neighbouring levels) and ‘heavy’ simplifications (using the alignments of level pairs: 0–3, 0–4, 1–4).
11	67	We: (1) provide several methods for paragraph- and sentence alignment of parallel texts, and for assessing similarity level between pairs of text snippets, as freely avail- 97 able software;2 (2) compare the performances of lexically- and semantically-based alignment methods across various text complexity levels; (3) test the hypothesis that the original order of information is preserved during manual simplification (Bott and Saggion, 2011) by offering customized MST-LIS alignment strategy (Section 3.1); and (4) show that the new sentence-alignments lead to the state-of-the-art ATS systems even in a basic phrase-based statistical machine translation (PBSMT) approach to text simplifications.
20	80	Having a set of ‘simple’ text snippets S and a set of ‘complex’ text snippets C, we offer two strategies (Section 3.1) to obtain the alignments (si, cj), where si ∈ S, cj ∈ C. Each alignment strategy, in turn, can use one of the three methods (Section 3.2) to calculate similarity scores between text snippets (either paragraphs or sentences).
21	7	Most Similar Text (MST): Given one of the similarity methods (Section 3.2), MST compares similarity scores of all possible pairs (si, cj), and aligns each si ∈ S with the closest one in C. MST with Longest Increasing Sequence (MSTLIS): MST-LIS uses the hypothesis H1.
22	30	It first uses the MST strategy, and then postprocess the output by extracting – from all obtained alignments – only those alignments li ∈ L, which contain the longest increasing sequence of offsets jk in C. In order to allow for ‘1–n’ alignments (i.e. sentence splitting), we allow for repeated offsets of C (‘complex’ text snippets) in L. The ‘simple’ text snippets not contained in L are included in the set U of unaligned snippets.
26	18	C3G: We employ the Character N -Gram (CNG) (Mcnamee and Mayfield, 2004) similarity model (for n = 3) with log TF-IDF weighting (Salton and McGill, 1986) and compare vectors using the cosine similarity.
31	13	To compare the performances of different alignment methods, we randomly selected 10 original texts (Level 0) and their corresponding simpler versions at Levels 1, 3 and 4.
32	26	Instead of creating a ‘gold standard’ and then automatically evaluating the performances, we asked two annotators to rate each pair of automatically aligned paragraphs and sentences – by each of the possible six alignment methods and the HMM-based method (Bott and Saggion, 2011) – for three pairs of text complexity levels (0–1, 0–4, and 3–4) on a 0–2 scale, where: 0 – no semantic overlap in the content; 1 – partial semantic overlap (partial matches); 2 – same semantic content (good matches).
37	35	We expect that the automatic-alignment task is the easiest between the 0–1 text complexity levels, and much more difficult between the 0-4 levels (Level 4 is obtained after four stages of simplification and thus contains stronger paraphrases and less lexical overlap with Level 0 than Level 1 has).
38	20	We also explore whether the task is equally difficult whenever we align two neighbouring levels, or the difficulty of the task depends on the level complexity (0–1 vs. 3–4).
40	55	The results of the manual analysis (Table 2) showed that: (1) all applied methods significantly (p < 0.001) outperformed the HMM method on both paragraph- and sentence-alignment tasks;5 (2) the methods which do not assume hypothesis H1 (C3G, CWASA, and WAVG) led to (not significantly) higher percentage of correct alignments than their counterparts which do assume H1 (C3G*, CWASA*, WAVG*); (3) the difference in the performances of the lexical approach (C3G) and semantic approaches (CWASA and WAVG) was significant only in the 0–4 sentencealignment task, where CWASA performed significantly worse (p < 0.001) than the other two methods, and in the 0–4 paragraph-alignment task, where WAVG performed significantly worse than C3G; (4) the 2-step C3G alignment-method (C3G-2s), which first aligns paragraphs using the best paragraph-alignment method (C3G) and then within each paragraph align sentences with the best sentence-alignment method (C3G), led to more good+partial alignments than the ‘direct’ sentence-alignment C3G method.
42	23	and for all levels – all) and Newsela sentence-alignments for neighboring levels obtained with HMM-method6 (Bott and Saggion, 2011) in the ATS task using standard PBSMT models7 in the Moses toolkit (Koehn et al., 2007).
43	7	We vary the training dataset and the corpus used to build language models (LMs), while keeping always the same 2,000 sentence pairs for tuning (Xu et al., 2016) and the first 70 sentence pairs of their test set8 for our human evaluation.
45	30	We compare: (1) the performance of the standard PBSMT model which uses only the already available EW–SEW dataset (Hwang et al., 2015) with the performances of the same PBSMT models but this time using the combination of the EW–SEW dataset and our newly-created Newsela datasets; (2) the latter PBSMT models (which use both EW–SEW and new Newsela datasets) against the state-of-the-art supervised ATS system (Xu et al., 2016), and one of the recently proposed unsupervised lexical simplification systems, the LightLS system (Glavaš and Štajner, 2015).9 We perform three types of human evaluation on the outputs of all systems.
47	106	We mark as Correct those changes that preserve the original meaning and grammaticality of the sentence (assessed by two native English speakers) and, at the same time, make the sentence easier to understand (assessed by two non-native fluent English speakers).10 Second, three native English speakers rate the grammaticality (G) and meaning preservation (M) of each sentence with at least one change on a 1–5 Likert scale (1 – very bad; 5 – very good).
49	13	While the correctness of changes takes into account the influence of each individual change on grammaticality, meaning and simplicity of a sentence, the Scores (G and M) and Rank (S) take into account the mutual influence of all changes within a sentence.
52	30	It also significantly outperforms the state-of-the-art ATS systems by simplicity rankings (S), meaning preservation (M), and number of correct changes (Correct), while achieving almost equally good grammaticality (G).
53	15	The level of simplification applied in the training dataset (Newsela neighb.
54	31	C3G-2s vs. Newsela all C3G-2s) significantly influences G and M scores.
56	49	An example of the outputs of different ATS systems is presented in Table 4.
57	66	We provided several methods for paragraphand sentence-alignment from parallel TS corpora, made the software publicly available, and showed that the use of the new sentence-aligned (freely available) Newsela dataset leads to state-of-the-art ATS systems even in a basic PBSMT setup.
58	57	We also showed that lexically-based C3G method is superior to semantically-based methods (CWASA and WAVG) in aligning paraphraphs and sentences with ‘heavy’ simplifications (0–4 alignments), and that 2-step sentence alignment (aligning first paragraphs and then sentences within the paragraphs) lead to more correct alignments than the ‘direct’ sentence alignment.

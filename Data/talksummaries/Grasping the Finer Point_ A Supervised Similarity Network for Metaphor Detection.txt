0	19	Metaphor is pervasive in our everyday communication, enriching it with sophisticated imagery and helping us to reconcile our experience in the world with our conceptual system (Lakoff and Johnson, 1980).
3	28	Such metaphorical associations are broad generalisations that allow us to project knowledge and inferences across domains; and our metaphorical use of language is a reflection of this process.
8	30	In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features (Shutova et al., 2010; Shutova and Sun, 2013) and dense neural word embeddings (Bracewell et al., 2014; Shutova et al., 2016).
11	35	Deep learning methods have already been shown successful in many other semantic tasks (e.g. Hermann et al., 2015; Kumar et al., 2015; Zhao et al., 2015), which suggests that designing a specialised neural network architecture for metaphor detection will lead to improved performance.
49	16	For example, the phrase ‘colourful personality’ receives a score: s = cos(xc, xp) (1) where xc is the embedding for colourful and xp is the embedding for personality.
61	17	The original method uses word embeddings that have been pretrained using the distributional skip-gram objective (Mikolov et al., 2013a).
63	57	In order to address this shortcoming, we allow the model to learn a mapping from the skip-gram vector space to a new metaphor-specific vector space: z1 = tanh(Wz1x1) (4) z2 = tanh(Wz2 x̃2) (5) where Wz1 and Wz2 are weight matrices, z1 and z2 are the new position-specific word representations.
65	16	Furthermore, the adjectives and nouns use separate mapping weights, which allows the model to better distinguish between the different functionalities of these words.
66	16	In contrast, the original cosine similarity is not position-specific and would give the same result regardless of the word order.
67	38	If the vectors x1 and x2 are normalised to unit length, the cosine similarity between them is equal to their dot product, which in turn is equal to their elementwise multiplication followed by a sum over all elements: cos(x1, x2) ∝ ∑ i x1,ix2,i (6) This calculation of cosine similarity can be formulated as a small neural network where the two unit-normalised input vectors are directly multiplied together.
77	45	Based on vector d we can output a prediction for the word pair, showing whether it is literal or metaphorical: y = σ(Wyd) (9) where Wy is a weight matrix, σ is the logistic activation function, and y is a real-valued prediction with values between 0 and 1.
78	21	We optimise the model based on an annotated training dataset, while minimising the following hinge loss function: E = ∑ k qk (10) qk = { (ỹ − y)2 if |ỹ − y| > 0.4 0, otherwise (11) where y is the predicted value, ỹ is the true label, and k iterates over all training examples.
82	19	The true labels ỹ can only take values 0 (literal) or 1 (metaphorical), and the threshold 0.4 is chosen so that datapoints that are on the correct side of the decision boundary by more than 0.1 would be ignored, which helps reduce overfitting and allows the model to focus on the misclassified examples.
84	43	Following Bulat et al. (2017) we experiment with two types of semantic vectors: skip-gram word embeddings and attribute-based representations.
85	30	The word embeddings are 100-dimensional and were trained using the standard log-linear skipgram model with negative sampling of Mikolov et al. (2013b) on Wikipedia for 3 epochs, using a symmetric window of 5 and 10 negative samples per word-context pair.
94	26	This resulted in a dataset of 647 verb–noun pairs (316 metaphorical and 331 literal).
97	21	This is divided into a training set consisting of 884 literal and 884 metaphorical pairs (TSV-TRAIN) and a test set containing 100 literal and 100 metaphorical pairs (TSV-TEST).
111	18	In order to avoid drawing conclusions based on outlier results due to random initialisations, we ran each experiment 25 times with random seeds and present the averaged results in this paper.
113	22	The original Fscore by Tsvetkov et al. (2014) is still the highest, as they used a range of highly-engineered features that require manual annotation, such as the lexical abstractness, imageability scores and the relative number of supersenses for each word in the dataset.
115	18	They also proposed combining the linguistic model with a system using visual word representations and achieved performance improvements.
139	29	While it contains only 23 unique adjectives, the total number of phrases reaches 8,592.
148	16	The architecture in Section 3 also acts as a semantic composition model, extracting the meaning of the phrase by combining the meanings of its component words.
152	47	The visualisation shows that the additive and multiplicative models are both comparable when it comes to semantic clustering of the phrases, but metaphorical examples are mixed together with literal clusters.
155	126	At the same time, this space also retains the general semantic information, as similar phrases with the same label are still positioned close together.
156	75	Future work could investigate models of multi-task training where metaphor detection is trained together with an unsupervised objective, allowing the system to take better advantage of unlabeled data while still learning to separate metaphors.
157	47	In this paper, we introduced the first deep learning architecture designed to capture metaphorical composition and evaluated it on a metaphor identification task.
158	50	Firstly, we demonstrated that the proposed framework outperforms both a metaphor-agnostic baseline (a feed-forward neural network) as well as previous corpus-driven approaches to metaphor identification.
159	29	The results showed that it is beneficial to construct a specialised network architecture for metaphor detection, which includes a gating function for capturing the interaction between the source and target domains, word embeddings mapped to a metaphor-specific space, and optimisation using a hinge loss function.
160	48	Secondly, our qualitative analysis indicates that our supervised similarity network learns phrase representations with a very clear boundary for metaphoricity, in contrast to traditional compositional methods.
161	22	Finally, we show that with a sufficiently large training set our model can also outperform the state-of-the art metaphor identification systems based on hand-coded lexical knowledge.

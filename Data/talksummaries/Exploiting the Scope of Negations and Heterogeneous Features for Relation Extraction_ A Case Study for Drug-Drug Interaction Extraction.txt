11	31	The RE task considered is drug-drug interaction (DDI) extraction.
13	43	The official training and test data of the corpus contain 4,267 and 1,539 sentences, and 2,402 and 755 DDI annotations respectively.
14	10	We propose a two stage RE approach.
15	6	In the first stage, our goal is to exploit the scope of negations to reduce the number of candidate mention pairs by discarding sentences.
16	51	For this purpose, we propose the following features to train a binary classifier: • has2TM: If the sentence has exactly 2 target entity mentions (i.e. drug mentions for DDI extraction).
20	9	• negCue: The negation cue itself.
21	15	• immediateGovernor: The word on which the cue is directly syntactically dependent.
22	9	• nearestVerbGovernor: The nearest verb in the dependency graph on which the cue is syntactically dependent.
28	3	• commaAfterPrevTM: Whether there is a comma in the text between the previous target entity mention before the negation cue and the cue itself.
30	7	The objective of the classifier is to decide whether all of the target entity mentions (i.e. drugs) as well as any possible evidence of the relation of interest (for which we assume the immediate and the nearest verb governors of the negation cue would be good candidates) inside the corresponding sentence fall under the scope of a negation cue in such a way that the sentence is unlikely to contain a DDI.
32	2	Other sentences are considered as negative instances.
33	3	We rule out any sentence (i.e. we do not consider as training/test instance for the classifier that filters less informative sentences) during both training and testing if any of the following conditions holds: • The sentence contains less than two target entity mentions (such sentence would not contain the relation of interest anyway).
42	24	w is a multiplicative constant used for the PET kernel.
44	15	The proposed kernel composition is valid according to the closure properties of kernels.
47	5	2.2.1 Proposed KHF kernel As mentioned earlier, this proposed kernel uses heterogeneous features.
48	5	The first version of the heterogeneous feature set (henceforth, HF v1) combines features proposed by two previous RE works.
49	24	The former is Zhou et al. (2005), which uses 51 different features.
50	1	We select the following 27 of their features for our feature set: WBNULL, WBFL, WBF, WBL, WBO, BM1F, BM1L, AM2F, AM2L, #MB, #WB, CPHBNULL, CPHBFL, CPHBF, CPHBL, CPHBO, CPHBM1F, CPHBM1L, CPHAM2F, CPHAM2F, CPP, CPPH, ET12SameNP, ET12SamePP, ET12SameVP, PTP, PTPH The latter is the TPWF kernel (Chowdhury and Lavelli, 2012a) from which we use following features: HasTriggerWord, Trigger-X, DepPattern-i, ewalk, v-walk The TPWF kernel extracts the HasTriggerWord, Trigger-X and DepPattern-i features from a subgraph called reduced graph.
53	4	Due to space limitation we refer the readers to the corresponding papers for the description of the above mentioned features and the definition of reduced graph.
54	14	In addition, HF v1 also includes surrounding tokens within the window of {-2,+2} for each candidate mention.
57	4	We use a list of 13 negation cues9 to search inside the reduced graph of a candidate pair.
58	14	If the reduced graph contains any of the negation cues or their morphological variants then we add the following features: • negCue: The corresponding negation cue.
60	11	• immediateGovernorIsVerbGovernor: Whether the immediate governor of the negation cue is a verb.
61	6	• nearestVerbGovernor: The closest verb governor (i.e. parent or grandparent inside the dependency graph), if any, of the negation cue.
62	4	We further extend the heterogeneous feature set by adding features related to relevant non-target entities (with respect to the relation of interest; henceforth, HF v3).
63	1	For the purpose of DDI extraction, we deem the presence of DISEASE mentions (which might result as a consequence of a DDI) can provide some clues.
64	38	So, we use a publicly available state-of-the-art disease NER system called BioEnEx (Chowdhury and Lavelli, 2010) to annotate the DDIExtraction-2011 challenge corpus.
66	10	• immediateGovernorIsVerbGovernorOfNTEM: The immediate governor (if any) of the non-target entity mention, only if such governor is also governing a dependency sub-tree that includes both of the target candidate entity mentions.
69	17	We train a linear SVM classifier in Stage 1 and tune the hyper-parameters (by doing 5-fold crossvalidation) for obtaining maximum possible recall.
70	20	In this way we minimize the number of false negatives (i.e. sentences that contain DDIs but are wrongly identified as not having any).

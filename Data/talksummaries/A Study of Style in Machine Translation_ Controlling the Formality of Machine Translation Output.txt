1	17	Consider the sentences “anybody hurt?” and “is someone wounded?”.
2	17	The first one is less formal than the second one, and carries information beyond its literal meaning, such as the situation in which it might be used.
5	22	Human translators translate a document for a specific audience (Nida and Taber Charles, 1969), and often ask what is the expected tone of the content when taking a new translation job.
12	12	When the expected formality matches the reference, we obtain improvement of translation quality evaluated by automatic metrics (BLEU).
15	14	We propose a Formality-Sensitive Machine Translation (FSMT) scenario where the system takes two inputs: (1) text in the source language to be translated, and (2) a desired formality level capturing the intended audience of the translation.
19	39	For each translation hypothesis h, given the formality level ` as a parameter: f(h; `) = |Formality(h)− `| where Formality(h) is the sentence-level formality score for h. f(h; `), along with standard model features, is fed into a standard re-ranking model.
26	31	State-of-the-art lexical formality models (Brooke et al., 2010; Brooke and Hirst, 2014) are based on vector space models of word meaning, and a set of pre-selected seed words that are representative of formal and informal language.
28	15	Intuitively, w is more likely formal if it is semantically closer to formal seed words than to informal seed words.
35	19	SVM As an alternative to the model proposed by Brooke and Hirst (2014), we propose to train an Support Vector Machine (SVM) model to find a hyperplane that separates formal and informal words and define the score function as the distance to the hyperplane.
38	12	One example is training a Principal Component Analysis (PCA) model on word representations of all seeds.
42	13	Before evaluating our FSMT framework, we evaluate the formality models at the sentence level.
48	10	We also compared the term-document association model Latent Semantic Analysis (LSA) (Deerwester et al., 1990) and the term-term association model word2vec (W2V) (Mikolov et al., 2013).
61	25	Set-up We evaluate this approach on a French to English translation task.
62	18	Two parallel FrenchEnglish corpora are used: (1) MultiUN (Eisele and Chen, 2010), which is extracted from the United Nations website, and can be considered to be formal text; (2) OpenSubtitles2016 (Lison and Tiedemann, 2016), which is extracted from movie and TV subtitles, covers a wider spectrum of styles, but overall tends to be informal since it primarily contains conversations.
63	11	Each parallel corpus was split into a training set (100M English tokens), a tuning set (2.5K segments) and a test set (5K segments).
72	27	FSMT In order to evaluate the impact of different input formality (e.g. low/neutral/high) on translation quality, ideally, we would like to have three human reference translations with different formality for each source sentence.
75	59	We therefore set three formality bins – informal [−1,−0.2), neutral formality [−0.2, 0.2], and formal (0.2, 1] – and split the test set into these bins.
76	44	We use DENSIFIER-LSA and training setting described above to translate the entire test set three times, with three different formality levels: low (-0.4), neutral (0) and high (0.4).
77	24	We first report standard automatic evaluation results using the BLEU score to compare FSMT output given different desired formality level on each bins (See Table 2).
78	23	The best BLEU scores for each formality level are obtained when the level of formality given as input to the MT system matches the nature of the text being translated, as can be seen in the scores along the diagonal in Table 2.
86	17	42 translation pairs were randomly selected and were annotated by 15 volunteers.
94	11	To determine whether re-ranking based on formality might have a detrimental effect on quality, we also had annotators rate the fluency and adequacy of the segments.
99	15	This slight difference fits our expectation that more casual language may feel more fluent while more formal language may feel more stilted.
100	26	The adequacy ratings were 0.65 and 0.64 for informal and translations respectively, indicating that adjusting the level of formality had minimal effect on the adequacy of the result.
101	40	Some examples are listed in Table 3.
102	31	Occa- sionally, the n-best list had no translation hypotheses with diverse formality, so the FSMT system dropped necessary words, appended inessential words, or selected improper or even incorrect words to fit the target formality level.
103	29	In the case of ’how do you do’, the translation that was meant to be more casual was rated more formal.
104	16	Because the system measures formality on the lexical level, it was not able to recognize this idiomatically formal phrase made up of words that are not inherently formal.
106	17	We presented a framework for formality-sensitive machine translation, where a system produces translations at a desired formality level.
107	13	Our evaluation shows the effectiveness of this system in controlling language formality without loss in translation quality.

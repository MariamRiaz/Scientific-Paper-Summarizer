{"sections": [{"heading": "1. Introduction", "text": "The problem of estimating heterogeneous (individualized) causal effects of a treatment from observational data is central in many application domains, including public health and drug development (Foster et al., 2011), computational\n1University of California, Los Angeles, USA 2University of Oxford, Oxford, UK 3Alan Turing Institute, London, UK. Correspondence to: Ahmed M. Alaa <ahmedmalaa@ucla.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nadvertising (Bottou et al., 2013), and social sciences (Xie et al., 2012). The increasing availability of observational data in all these domains has encouraged the development of various machine learning algorithms tailored for inferring treatment effects using observational data (e.g. (Li & Fu, 2017; Wager & Athey, 2017; Shalit et al., 2017; Alaa & van der Schaar, 2017)). Due to the peculiarity of the treatment effect estimation problem, these algorithms needed to address various modeling aspects that are foreign to standard supervised learning setups; such aspects include ways to handle sample selection bias (Heckman, 1977), and ways to model treated and untreated data points. Despite a variety of recent algorithmic approaches, principled guidelines for model design are lacking.\nIn this paper, we identify guiding principles for designing practical treatment effect estimation algorithms in the context of Bayesian nonparametric inference, and propose one an algorithm that follows these guidelines. We set these guidelines by characterizing the fundamental limits of estimating treatment effects, and studying the impact of various common modeling choices on the achievability of those limits. In what follows, we provide a brief technical background for the treatment effect estimation problem, along with a summary of our contributions."}, {"heading": "1.1. Background and Summary of Contributions", "text": "Our analysis hinges on the Rubin-Neyman potential outcomes model (Rubin, 2005). That is, we consider an observational dataset with a population of subjects, where each subject i is endowed with a d-dimensional feature Xi \u2208 X . We assume that X = [0, 1]d, but most of our results hold for general compact metric spaces (bounded, closed sets in Rd). A treatment assignment indicator Wi \u2208 {0, 1} is associated with subject i; Wi = 1 if the treatment under study was applied to subject i, and Wi = 0 otherwise. Subject i\u2019s responses with and without the treatment (the potential outcomes) are denoted as Y (1)i and Y (0)\ni , respectively. Treatments are assigned to subjects according to an underlying policy that depends on the subjects\u2019 features, i.e. Wi \u22a5\u0338\u22a5 Xi. This dependence is quantified via the conditional distribution p(x) = P(Wi = 1|Xi = x), also known as the propensity score of subject i (Rosenbaum & Rubin,\n1984). The response Y (Wi)i is the \u201cfactual outcome\u201d which we observe in the data, whereas Y (1 \u2212 Wi)i is the unrealized \u201ccounterfactual outcome\u201d (Bottou et al., 2013). An observational dataset Dn comprises n samples of the form: Dn = {Xi,Wi, Y (Wi)i }ni=1 (1) The causal effect of the treatment on subject i with a feature Xi = x is characterized through the conditional average treatment effect (CATE) function T (x), which is defined as the expected difference between the two potential outcomes (Rubin, 2005), i.e. T (x) = E[Y (1)i \u2212 Y (0)i |Xi = x ] (2) Our goal is to identify a set of guiding principles for building estimators of the CATE T (x) using samples from Dn. Throughout the paper, we will assume that the joint density dP(Xi,Wi, Y (0)i , Y (1)\ni ) supports the assumptions of unconfoundedness and overlap, which are necessary for causal identifiability and consistency. Unconfoundedness requires that (Y (0)i , Y (1)\ni )\u22a5\u22a5 Wi |Xi, whereas overlap requires that 0 < p(x) < 1 (Rosenbaum & Rubin, 1984). Selection bias occurs in Dn since the distribution of the treated/control subjects does not match that of the overall population.\nIn order to come up with principled guidelines for building estimators of T (x), we characterize the fundamental (information-theoretic) limits of estimating the CATE using samples from Dn, and identify the modeling choices that would allow achieving those limits. To this end, in Section 3 we tackle the following question: what are the fundamental limits of CATE estimation? We answer this question by deriving the optimal minimax rate for estimating T (x) using Dn. Interestingly, it turns out that the optimal rate does not depend on selection bias, but rather on the smoothness and sparsity of the more \u201ccomplex\u201d of the functions E[Y (0)i |Xi = x ] and E[Y (1) i |Xi = x ]. We focus our analysis on Bayesian nonparametric methods, since they have the appealing properties of being robust to misspecification and are accessible for theoretical analysis.\nOur analysis reveals that the relative importance of the different modeling aspects vary with the sample size. In particular, in the large-sample regime, selection bias does not pose a serious problem, and the model\u2019s performance would be mainly determined by its structure, i.e. the way the outcomes Y (0)i and Y (1) i are modeled, and the impact of that on variable selection and hyperparameter tuning. On the contrary, selection bias can seriously harm a model\u2019s generalization performance in small-sample regimes. A good model should then be carefully designed so that it operates well in both regimes by possessing the right model structure that would allow learning at a fast rate, and the right model selection (hyperparameter optimization) scheme that would account for selection bias.\nIn Section 4, we build a practical CATE estimation algorithm guided by the results of the analyses in Section 3. We model the outcomes Y (0)i and Y (1) i using a Gaussian process with a non-stationary kernel that captures the different relevant variables and different levels of smoothness of the functions E[Y (0)i |Xi = x ] and E[Y (1) i |Xi = x ]. We prove that this model structure can achieve the optimal rate of CATE estimation when tuned with the right hyperparameters. We also propose a doubly-robust hyperparameter optimization scheme that accounts for selection bias in smallsample regimes, without hindering the model\u2019s minimaxoptimality in the large sample limit. We show that our algorithm outperforms state-of-the-art methods using a wellknown semi-synthetic simulation setup."}, {"heading": "1.2. Related Work", "text": "Very few works have attempted to characterize the limits of CATE estimation, or study the impact of different modeling choices on the CATE estimation performance in a principled manner. (Alaa & van der Schaar, 2018) characterized the asymptotic \u201cinformation rates\u201d for different CATE estimators, but provided no clear guidelines on practical model design or an analysis of the impact of sample selection bias. The study in (Ku\u0308nzel et al., 2017) was rather empirical in nature, comparing the performance of different regression structures for the potential outcomes while ignoring selection bias. A similar study, but focusing only on random forest models, was conducted in (Lu et al., 2017).\nMost of the previous works have been algorithmic in nature, focusing mainly on devising algorithms that correct for selection bias (e.g. (Johansson et al., 2016; Yoon et al., 2018; Wager & Athey, 2017; Li & Fu, 2017)). Some of these works cast the selection bias problem as a problem of covariate shift (Sugiyama et al., 2007), and use techniques from representation learning to learn feature maps that balance the biased data (e.g. (Li & Fu, 2017; Shalit et al., 2017; Johansson et al., 2016)). However, those works report much bigger improvements in CATE estimation when changing their model structure (e.g. architecture of a neural network), as compared to the gains attained by only accounting for bias (see the comparisons between the TARnet and BNN models in (Shalit et al., 2017)). Similar observations are reported in (Alaa & van der Schaar, 2017; Atan et al., 2018), where the selection of the model structure seemed to influence the achieved CATE estimation performance even when selection bias is not accounted for. However, none of these works offer a discussion on whether selection bias is actually the main challenge in CATE estimation, or whether the outcomes\u2019 model structure may have a bigger influence on performance.\nIn contrast to the works above, this paper does not attempt to develop a model by presupposing that particular model-\ning aspects are of greater importance than others, but rather provides a framework for understanding the limits on the achievable performance, and how different modeling aspects influence a model\u2019s chance of achieving those limits. We use our analyses to both reflect on the modeling choices made in the works above, and also devise a novel, principled CATE estimation algorithms that achieves the fundamental performance limits."}, {"heading": "2. Estimating CATE: Problem Setup", "text": ""}, {"heading": "2.1. Potential Outcomes & Propensity Score", "text": "We consider the following random design regression model for the potential outcomes:\nY (w)i = fw(Xi) + \u03b5i,w, w \u2208 {0, 1}, (3)\nwhere \u03b5i,w \u223c N (0, \u03c32w) is a Gaussian noise variable. It follows from (2) that the CATE is T (x) = f1(x) \u2212 f0(x). The response surfaces f1(x) and f0(x) correspond to the subjects\u2019 responses with and without the treatment.\nWe assume that fw(.) : X \u2192 R, w \u2208 {0, 1}, is a totally bounded function that lives in a space of \u201csmooth\u201d or \u201cregular\u201d functions, with an unknown smoothness parameter \u03b1w. We use Ho\u0308lder balls for concreteness, although our results extend to other function spaces. A function fw(.) lies in the Ho\u0308lder ball H\u03b1w , with a Ho\u0308lder exponent \u03b1w > 0, if and only if it is bounded in sup-norm by a constant C > 0, all its partial derivatives up to order \u230a\u03b1w\u230b exist, and all its partial derivatives of order \u230a\u03b1w\u230b are Lipschitz with exponent (\u03b1w \u2212 \u230a\u03b1w\u230b) and constant C. The Ho\u0308lder exponents quantify the complexities of f0 and f1, and hence the hardness of estimating T (x) would depend on \u03b10 and \u03b11."}, {"heading": "2.2. Bayesian Nonparametric Inference", "text": "Nonparametric inference is immune to misspecification of the outcomes\u2019 and propensity models (Kennedy, 2018), and hence we focus on Bayesian nonparametric methods for inferring T (.) on the basis of Dn. Bayesian inference entails specifying a prior distribution \u03a0 over f1(.) and f0(.), i.e.\nf0, f1 \u223c \u03a0(\u03c6\u0304\u03b20 , \u03c6\u0304\u03b21), (4)\nwhere \u03c6\u0304\u03b2w = {\u03c6k\u03b2w} \u221e k=1, w \u2208 {0, 1}, are complete orthonormal bases (indexed by a parameter \u03b2w > 0) with respect to Lebesgue measure in X , fw = \u2211 k f\u0304 k w \u00b7\u03c6k\u03b2w , and f\u0304kw = \u27e8fw, \u03c6k\u03b2w\u27e9. Thus, for given bases \u03c6\u0304\u03b20 and \u03c6\u0304\u03b21 , \u03a0 places a probability distribution on the projections {f\u0304kw}k. Potential choices for the basis \u03c6\u0304\u03b2w that would give rise to implementable Bayesian inference algorithms include regular wavelet basis (Zhang, 1997), radial basis for a reproducing kernel Hilbert space (RKHS) (van der Vaart et al., 2008), etc. In general, the parameter \u03b2w would determine the smoothness of the function space spanned by \u03c6\u0304\u03b2w ."}, {"heading": "2.3. Towards Principled CATE Estimation", "text": "To evaluate the predictive accuracy of the Bayesian inference procedure, we analyze the \u201cfrequentist\u201d loss of point estimators T\u0302 (x) induced by the Bayesian posterior d\u03a0n(T (x) | Dn), assuming that Dn is generated based on fixed, true response surfaces f1(x) and f0(x). (This type of analysis is sometimes referred to as the \u201cFrequentistBayes\u201d analysis (Sniekers et al., 2015).) In particular, we quantify the performance of a point estimator T\u0302 (x) = \u03b4(d\u03a0n(T (x) | Dn)) by its squared-L2(P) error, which was dubbed the precision of estimating heterogeneous effects (PEHE) in (Hill, 2011), and is formally defined as:\n\u03c8(T\u0302 ) , E \u2225 T\u0302 \u2212 T \u22252 L2(P), (5)\nwhere L2(P) is the L2 norm with respect to the feature distribution, i.e. \u2225f(x)\u22252 L2(P) = \u222b f2(x) dP(X = x).\nNot a standard supervised learning problem...\nThe \u201cfundamental problem of causal inference\u201d is that for every subject i in Dn, we only observe the factual outcome Y (Wi)i , whereas the counterfactual Y (1 \u2212 Wi) i remains unknown, which renders empirical evaluation of the PEHE in (5) impossible. Moreover, Dn would generally exhibit sample selection bias (Heckman, 1977), because the treatment assignment mechanism (decided by p(x)) creates a discrepancy between the feature distributions of the treated/control population and the overall population. Thus, standard supervised learning approaches based on empirical risk minimization cannot be used to learn a generalizable model for the CATE from samples in Dn. This gives rise to the following fundamental modeling questions that are peculiar to the CATE estimation problem:\n\u2022 [Q1]: How should the treatment assignment indicator Wi be incorporated into the learning model?\n\u2022 [Q2]: How should selection bias be handled?\nAdequate answers to [Q1] and [Q2] would provide guidelines for selecting the prior \u03a0(\u03c6\u0304\u03b20 , \u03c6\u0304\u03b21). Addressing the modeling questions above requires a profound understanding of the fundamental limits of CATE estimation, in addition to an understanding of the impact of different modeling choices on the achievability of such limits. The next Sections provide principled answers to [Q1] and [Q2] by addressing the following, more fundamental questions:\nSection 3: What are the limits on the performance that can be achieved by any estimator of the CATE?\nSection 4: How can we build practical algorithms that can achieve the performance limits?"}, {"heading": "3. Fundamental Limits of CATE Estimation", "text": "In this Section, we establish an information-theoretic limit on the performance of any CATE estimator. In what follows, we use the standard Bachmann-Landau order notation, and write a\u2228 b = max{a, b}, a\u2227 b = min{a, b}. The notation a . b means that a \u2264 Cb for a universal constant C, and \u224d denotes asymptotic equivalence."}, {"heading": "3.1. Optimal Minimax Rates", "text": "The \u201chardness\u201d of a nonparametric estimation problem is typically characterized by its minimax risk (Stone, 1982), i.e. the minimum worst case risk achieved by any estimator when the estimand is known to live in a given function space (Yang et al., 2015). In the following Theorem, we establish the optimal minimax rate for the PEHE risk in terms of the complexity of the response surfaces f0 and f1.\nTheorem 1. Suppose that X = [0, 1]d, and that fw depends on a subset of dw features with dw \u2264 min{n, d} for w \u2208 {0, 1}. If f0 \u2208 H\u03b10 and f1 \u2208 H\u03b11 , then the optimal minimax rate is:\ninf T\u0302 sup f0,f1\n\u03c8(T\u0302 ) \u224d n\u2212 ( 1+ 1 2 ( d0 \u03b10 \u2228 d1 \u03b11 ))\u22121\ufe38 \ufe37\ufe37 \ufe38 CATE estimation\n\u2228 log ( dd0+d1\nd d0 0 d d1 1\n) 1 n\n.\ufe38 \ufe37\ufe37 \ufe38 Variable selection\nThe above holds for any p(.) \u2208 H\u03b1p , \u03b1p > 0.\nIn Theorem 1, the supremum is taken over \u03b1w-Ho\u0308lder balls (w \u2208 {0, 1}), whereas the infimum is taken over all possible Bayesian estimators. The minimax rate in Theorem 1 corresponds to the fastest rate by which any (Bayesian) estimator T\u0302 (.) can approximate the CATE function T (.). The proof of Theorem 1 (provided in the supplement) uses information-theoretic techniques based on Fano\u2019s method to derive algorithm-independent estimation rates (Yang & Barron, 1999). In the following set of remarks, we revisit [Q1] and [Q2] in the light of the results of Theorem 1.\nHow can Theorem 1 help us address [Q1] & [Q2]?\n\u25c3 Remark 1 (Smoothness & sparsity)\nTheorem 1 says that estimating CATE is as hard as nonparametric regression for functions with additive sparsity (Raskutti et al., 2009; Yang et al., 2015). The minimax rate in Theorem 1 decomposes into a term reflecting the complexity of CATE estimation under correct variable selection for f0 and f1, and a term reflecting the complexity of variable selection. Variable selection complexity remains small as long as log(d) = \u0398(n\u03b6), for some \u03b6 \u2208 (0, 1), and approaches the parametric rates as \u03b6 \u2192 0. The minimax rate will generally be dominated by the complexity of CATE estimation, and will approach the parametric rates only for very smooth response surfaces with small number of relevant dimensions, i.e. d0\u03b10 \u2228 d1 \u03b11 \u2192 0.\nThe main takeaway from Theorem 1 is that the CATE learning rate is determined by the more \u201ccomplex\u201d of the surfaces f0 and f1, where complexity is quantified by the sparsity-to-smoothness ratio dw/\u03b1w for w \u2208 {0, 1}. Thus, a model would achieve the optimal CATE learning rate only if it selects the correct relevant variables for f0 and f1, and tunes its \u201chyperparameters\u201d (i.e. smoothness of the prior) to cope with a complexity of d0\u03b10 \u2228 d1 \u03b11 . When d0\u03b10 and d1 \u03b11\nare very different (e.g. f0 and f1 have different relevant features), rate-optimal estimation is possible only if the model incorporates such differences in \u03a0(\u03c6\u0304\u03b20 , \u03c6\u0304\u03b21).\nThe discussion above provides a concrete answer to [Q1]: the treatment assignment variablew should be incorporated into the model in such a way that it encodes the different relevant dimensions and smoothness levels of f0 and f1 in the bases \u03c6\u0304\u03b20 and \u03c6\u0304\u03b21 . (The simplest way to achieve this is to use two separate models for f0 and f1.) This is not fulfilled by many of the previous models that built a single regression function of the from f : X \u00d7{0, 1} \u2192 R, and estimated the CATE as T\u0302 (x) = f(x, 1)\u2212f(x, 0) (Hill, 2011; Johansson et al., 2016; Powers et al., 2017). This is because such models enforced the smoothness of the prior along all features to be the same for w = 0 and w = 1.\n\u25c3 Remark 2 (Selection bias)\nTheorem 1 gives a rather surprising answer to [Q2]: the optimal learning rate is oblivious to selection bias. Such a finding is consistent with previous results on nonparametric kernel density estimation under selection bias (Borrajo et al., 2017), and parametric Bayesian inference under covariate shift (Shimodaira, 2000; Sugiyama & Storkey, 2007). It shows that many of the recent works have missed the target; the works in (Johansson et al., 2016; Shalit et al., 2017; Alaa & van der Schaar, 2017) cast the problem of CATE estimation as one of covariate shift that results from selection bias. However, Theorem 1 says that selection bias is not a problem when we have a sufficiently large amount of data. This is because selection bias is inherently a misspecification problem, and hence its impact on nonparametric inference is washed away in large-sample regimes.\nRemarks 1 and 2 posit an explanation for various recurrent (empirical) findings reported in previous literature. For instance, (Hahn et al., 2017) found that separate modeling of f0 and f1 via Bayesian additive regression trees (BART) outperforms the well-known single-surface BART model developed in (Hill, 2011). Similar findings were reported for models based on Gaussian processes (Alaa & van der Schaar, 2017), and models based on deep neural networks (Shalit et al., 2017). All such findings can be explained in the light of Remark 1. On the other hand, Remark 2 may provide an explanation as to why the \u201cTARnet\u201d model in (Shalit et al., 2017), which models f0 and f1 using separate neural networks and does not account for selection\nbias, outperformed the \u201cBNN\u201d model in (Johansson et al., 2016), which regularizes for selection bias but fits a singleoutput network for f0 and f1."}, {"heading": "3.2. Backing off from \u201cAsymptopia\u201d", "text": "Theorem 1 shows that selection bias does not hinder the optimal minimax rates, and that it is only the structural properties of the prior \u03a0(\u03c6\u0304\u03b20 , \u03c6\u0304\u03b21) that determine a model\u2019s rate of learning. But does the achieved learning rate suffice as a sole criterion for addressing the modeling questions [Q1] and [Q2]? The answer is \u201cyes\u201d only if Dn comes from a large observational dataset, in which case the learning rate suffices as a descriptor for the large-sample performance. However, if Dn is small, which is typical in posthoc analyses of clinical trials (Foster et al., 2011), then one should make the design choices that would optimize the small-sample performance. In order to give a more complete picture of the performance in large and small-sample regimes, we derive the following bound on the PEHE:\n\u03c8(T\u0302 ) \u2264 C\u0304 \u00b7 exp(D2(Q0 \u2225Q)) \u00b7 \u2225f0 \u2212 f\u03020\u22252L2(P0) + C\u0304 \u00b7 exp(D2(Q1 \u2225Q)\ufe38 \ufe37\ufe37 \ufe38\nRe\u0301yni Divergence ) \u00b7 \u2225f1 \u2212 f\u03021\u22252L2(P1)\ufe38 \ufe37\ufe37 \ufe38 Supervised learning loss , (6)\nfor some C\u0304 > 0, where L2(Pw), for w \u2208 {0, 1}, is the L2 norm with respect to dP(X = x |W = w), Q = dP(X = x), Qw = dP(X = x |W = w), and Dm(p \u2225 q) is the mth order Re\u0301yni divergence. The bound in (6) holds for all n > 0, and is tight (refer to the supplement); it shows that the PEHE is a weighted linear combination of the mean squared losses for the two underlying supervised problems of learning f0 and f1 with no covariate shift, where the weights are determined by the extent of the mismatch between the distributions of the treated and control populations, quantified by the Re\u0301yni divergence measure. If Dn is a dataset obtained from a randomized controlled trial (Q = Q0 = Q1), then we have D2(Q0 \u2225Q) = D2(Q1 \u2225Q) = 0, and the bound boils down to a sum of two supervised learning losses, i.e. \u03c8(T\u0302 ) \u2264 C\u0304 \u00b7 \u2225f0 \u2212 f\u03020\u22252L2(P) + C\u0304 \u00b7 \u2225f1 \u2212 f\u03021\u2225 2 L2(P).\nSince the minimax rate for standard nonparametric regression is \u2225fw \u2212 f\u0302w\u222522 \u224d Cw \u00b7 n \u22122\u03b1w 2\u03b1w+dw (Stone, 1982), when d0/\u03b10 >> d1/\u03b11, the first-order Taylor approximation for the logarithm of the PEHE in (6) is given by:\nlog(\u03c8(T\u0302 )) \u2248D2(Q0\u2225Q)\ufe38 \ufe37\ufe37 \ufe38 Selection\nbias\n+ log(C0)\ufe38 \ufe37\ufe37 \ufe38 Bias\ncorrection\n\u2212 2\u03b10 2\u03b10 + d0\ufe38 \ufe37\ufe37 \ufe38\nLearning rate\nlog(n)\n+O ( n \u22122\u03b11 2\u03b11+d1 + 2\u03b10 2\u03b10+d0 ) . (7)\nThat is, when viewed on a log-log scale, the behavior of the PEHE versus the number of samples can be described\nas follows. log(PEHE) is a linear function of log(n). Selection bias adds a constant offset to log(PEHE), but does not affect its slope, which harms the performance only in the small-sample regime. In the large-sample regime, the slope of log(PEHE), which depends solely on the smoothness and sparsity of the response surfaces, dominates the performance, and selection bias becomes less of a problem. Figure 1 depicts the PEHE in (7) on a log-log scale."}, {"heading": "4. CATE Estimation using Non-Stationary Gaussian Process Regression", "text": "In this Section, we build on the analyses conducted in Section 3 to design a practical algorithm for CATE estimation."}, {"heading": "4.1. Non-Stationary Gaussian Process Priors", "text": "We specify the prior \u03a0(\u03c6\u0304\u03b20 , \u03c6\u0304\u03b21) as a Gaussian process (GP) over functions of the form g : X \u00d7 {0, 1} \u2192 R, with a kernel K\u03b2 , and a hyperparameter set \u03b2 as follows:\ng \u223c GP (0,K\u03b2(z, z\u2032)) , (8)\nwhere z = (x,w) \u2208 X \u00d7 {0, 1}, and fw(x) = g(x,w). The kernel K\u03b2 specifies the bases \u03c6\u0304\u03b20 and \u03c6\u0304\u03b21 through its induced canonical feature map K\u03b2(., z) (Rasmussen & Williams, 2006; Alvarez et al., 2012). As pointed out in remark 1, the treatment assignment variable w should encode the different relevant dimensions and smoothness levels of f0 and f1. Thus, we model K\u03b2 as a non-stationary kernel that depends explicitly on w as follows:\nK\u03b2(z, z \u2032)= \u0393(w,w\u2032) \u00b7 kT\u03b2 (x, x\u2032), k\u03b2(x, x \u2032)= [k\u03b20(x, x \u2032), k\u03b21(x, x \u2032), k\u03b20(x, x \u2032) + k\u03b21(x, x \u2032)],\n\u0393(w,w\u2032)= [\u03930(w,w \u2032), \u03931(w,w \u2032), 1\u2212 \u03930(w,w\u2032)\u2212 \u03931(w,w\u2032)],\nwhere \u03930(w,w\u2032) = (1\u2212 w)(1\u2212 w\u2032), \u03931(w,w\u2032) = w \u00b7 w\u2032, and k\u03b2w(x, x \u2032) is a Mate\u0301rn kernel with a length-scale parameter\n\u03b2w, for w \u2208 {0, 1}. The kernel defined above ensures that any covariance matrix induced by points in X \u00d7 {0, 1} is positive definite. Variable selection is implemented by using the automatic relevance determination version of the Mate\u0301rn kernel (Rasmussen & Williams, 2006). The nonstationarity of K\u03b2 allows setting different length-scales and relevant variables for the marginal priors on f0 and f1 while sharing data between the two surfaces, i.e.\nK\u03b2((x,w), (x \u2032, w))= k\u03b2w (x, x \u2032), w \u2208 {0, 1}, K\u03b2((x,w), (x \u2032, w\u2032))= k\u03b20(x, x \u2032) + k\u03b21(x, x \u2032), w \u0338= w\u2032. (9)\nThat is, all draws from the prior give Mate\u0301rn sample paths with different smoothness levels (\u03b20 and \u03b21) for f0 and f1, respectively, and the correlations between the paths are captured via the kernel mixture k\u03b20(x, x \u2032) + k\u03b21(x, x \u2032). Note that draws from a Mate\u0301rn prior with length-scale \u03b2 are almost surely \u03b2\u0304-Ho\u0308lder for all \u03b2\u0304 \u2264 \u03b2 (Vaart & Zanten, 2011). Thus, GP(0,K\u03b2) specifies a \u03b2w-Ho\u0308lder ball as an a priori regularity class for response surface fw, w \u2208 {0, 1}.\nIn the following Theorem, we show that point estimators induced by the prior GP(0,K\u03b2) can achieve the optimal minimax rate in Theorem 1.\nTheorem 2. Suppose that the dw relevant features for fw are known a priori for w \u2208 {0, 1}. If f0 \u2208 H\u03b10 , f1 \u2208 H\u03b11 , \u03a0 = GP(0,K\u03b2), and T\u0302 = E\u03a0 [T | Dn ], then we have that\n\u03c8(T\u0302 ) . n\u2212 2(\u03b10\u2227\u03b20) 2\u03b20+d0 \u2228 n\u2212 2(\u03b11\u2227\u03b21) 2\u03b21+d1\nwhenever min{\u03b10, \u03b11, \u03b20, \u03b21} \u2265 d/2.\nNote that posterior consistency holds for all combinations of (\u03b10, \u03b11, \u03b20, \u03b21) since the support of the Mate\u0301rn prior is the space of bounded continuous functions1. The bound in Theorem 2 can be shown to be tight using the results in (Castillo, 2008). Theorem 2 says that the posterior induced by the prior GP(0,K\u03b2) contracts around the true CATE function at the optimal rate given in Theorem 1 provided that the following matching condition is met:\n\u03b2v = \u03b1v\n\u03b1v d1\u2212v dv \u2264 \u03b21\u2212v \u2264 \u03b11\u2212v + \u03b11\u2212v \u00b7dv2\u03b1v \u2212 d1\u2212v 2 , (10)\nwhere v = 1 if d1/\u03b11 > d0/\u03b10, and v = 0 otherwise. The condition in (10) implies that achieving the optimal rate (steepest slope in Figure 1) via the non-stationary GP prior in Section 4.1 is only a matter of hyperparameter tuning: the smoothness of the prior needs to match the smoothness of the \u201cmore complex\u201d of the two response surfaces. Note that Theorem 2 implies that we do not need to handle selection bias in order to achieve the optimal rate, which is consistent with the earlier discussion in remark 2.\n1This is because the RKHS associated with the prior lies dense in the space of bounded continuous functions (van der Vaart & van Zanten, 2008; van der Vaart et al., 2008)."}, {"heading": "4.2. Doubly-Robust Hyperparameters", "text": "Theorem 2 says that the optimal minimax rate for CATE estimation can be achieved by satisfying the smoothness matching condition in (10). However, in practice, the smoothness levels of the true response functions are unknown and need to be learned from the data. Moreover, since selection bias is impactful in small-sample regimes, ignoring it may lead to a poor generalization performance when the size of Dn is small. In this Section, we propose a hyperparameter optimization algorithm that accounts for selection bias while ensuring minimax-optimality in the large-sample limit.\nPrevious works tend to adjust for selection bias \u201cmechanically\u201d using variants of importance sampling approaches based on inverse-propensity-weighting (IPW) (Sugiyama et al., 2007; Shimodaira, 2000), and kernel mean matching (Huang et al., 2007), or by learning a \u201cbalanced representation\u201d of treated and control populations (Li & Fu, 2017). We do not attempt to explicitly adjust for selection bias using ad-hoc approaches, and rather seek the \u201cinformationally optimal\u201d estimator of the PEHE. That is, we seek the most efficient (unbiased) estimator \u03c8\u0302\u2217(T\u0302 ) of \u03c8(T\u0302 ), which satisfies an analog of the Crame\u0301r-Rao bound (information-inequality) in parametric estimation, i.e. Var[\u03c8\u0302\u2217(T\u0302 )] \u2264 Var[\u03c8\u0302(T\u0302 )], for any estimator \u03c8\u0302(T\u0302 ).\nClassical Crame\u0301r-Rao bounds do not apply to estimators of the form \u03c8\u0302\u2217(T\u0302 ), since such estimators are functionals of nonparametric objects. There are, however, analogous information inequalities for nonparametric estimation, including Bhattacharyya\u2019s variance bound (Bhattacharyya, 1946), and its generalization due to Bickel (Bickel et al., 1998). We proceed by realizing that the PEHE \u03c8(T\u0302 ) is simply a functional that belongs to the doubly-robust class of functionals analyzed by Robins in (Robins et al., 2008). Thus, one can construct the \u201cmost\u201d efficient estimator of \u03c8(T\u0302 ) using the most efficient influence function of \u03c8(T\u0302 ) as follows (Robins et al., 2008; Robins, 2004):\n\u03c8\u0302\u2217(T\u0302 ) = \u2211n\ni=1\n( Y\n(Wi) i \u2212(Wi\u2212p(Xi))\u00b7T\u0302 (Xi)\np(Xi)\u00b7(1\u2212p(Xi))\n)2 .\nThe derivation of the estimator above can be found in Theorem 9 in (Robins, 2004) and Section 5 in (Robins et al., 2008). When the propensity function p(.) is known, this estimator approximate the PEHE at its optimal minimax rate. We estimate p(.) via standard kernel density estimation methods. It can be easily shown using the results in (Dudoit & van der Laan, 2005) that when using the estimator above to tune the GP hyperparameters via crossvalidation, then the learned length-scale parameters will satisfy the matching condition for minimax optimality."}, {"heading": "5. Experiments", "text": "In this Section, we check the validity of our analyses using a synthetic simulation setup (Subsection 5.1), and then evaluate the performance of our proposed model using data from a real-world clinical trial with simulated potential outcomes (Subsection 5.2). We will use the acronym NSGP to refer to the non-stationary GP model proposed in Section 4."}, {"heading": "5.1. Learning Brownian Response Surfaces", "text": ""}, {"heading": "5.1.1. SYNTHETIC MODEL", "text": "Let X = [0, 1], and define a \u03ba-fold integrated Brownian motion B\u03ba, \u03ba \u2208 N+, on X as follows:\nB\u03ba(x) = \u222b x 0 \u222b x\u03ba 0 \u00b7 \u00b7 \u00b7 \u222b x2 0 B0(x1) dx1 dx2 \u00b7 \u00b7 \u00b7 dxx\u03ba ,\nwhere B0(.) is a standard Brownian motion (Wiener process). Sample paths of B0 are almost surely Ho\u0308lder regular with exponent 1\n2 (Karatzas & Shreve, 2012). Since\nB0(x) is almost surely non-differentiable everywhere in X , then sample paths of B\u03ba(x) are Ho\u0308lder with exponent \u03ba+ 1\n2 , i.e. B\u03ba \u2208 H\u03ba+\n1 2 with probability 1. Therefore, when\nthe true response surfaces are \u03ba-fold integrated Brownian paths, the optimality and achievability results in Theorems 1 and 2 should hold. To this end, we simulate the true response surfaces f0 \u2208 H\u03b10 and f1 \u2208 H\u03b11 as f0 \u223c B\u03b10\u2212 12 , and f1 \u223c B\u03b11\u2212 12 , where we set \u03b10 = 2.5 and \u03b11 = 5.5.\nThe propensity score is modeled as a parametrized logistic function p(x |\u03b7) = (1 + e\u2212\u03b7 (x\u2212 12 ))\u22121, where \u03b7 \u2208 R is a parameter that determines the severity of selection bias. For a pair of fixed Brownian paths f0 and f1, synthetic observational samples (Xi,Wi, Y (Wi)i )i are generated as follows: Xi \u223c Uniform[0,1], Wi \u223c Bernoulli(p(x |\u03b7)), and Y\n(Wi) i \u223c fWi +N (0, \u03c3 2), where \u03c32 = 0.1."}, {"heading": "5.1.2. EXPERIMENTS AND RESULTS", "text": "Using the setup in Section 5.1.1, we conducted the following Monte Carlo simulations to verify our theoretical findings and highlight the merits of our NSGP model.\n\u2022 Verifying Theorems 1 and 2: In order to check the validity of the results of Theorems 1 and 2, we use a NSGP Mate\u0301rn prior GP(0,K\u03b2), with length-scale parameters \u03b20 and \u03b21 that are matched exactly with the regularities of the Brownian paths f0 and f1 (i.e. \u03b20 = 2.5 and \u03b21 = 5.5). According to Theorem 1, the optimal rate for estimating the CATE T = f1 \u2212 f0 is n \u22125 6 , and from Theorem 2, the NSGP with \u03b20 = 2.5 and \u03b21 = 5.5 should achieve that rate.\nFigure 2a provides a scatter-plot for the PEHE achieved by the NSGP with respect to the number of samples on a loglog scale for different settings of \u03b7. We fit a linear regression model that describes the PEHE behavior in the log-log scale. We found the slope of the linear fit to be 0.8437, which is very close2 to the slope of 56 \u2248 0.833 predicted by Theorem 1. Moreover, by changing the magnitude of \u03b7 from 0 to 12 , the PEHE curve did not exhibit any significant change in its slope, and was only moved upwards by a constant offset. On the contrary, Figure 2b shows the PEHE behavior when the NSGP prior is over-smoothed (\u03b20 > \u03b10) for \u03b7 = 0: as predicted by Theorem 2, learning becomes sluggish (slopes become less steep) as \u03b20 increase since the matching condition in (10) does not hold any more.\n\u2022 NSGPs do not leave any money on the table: In this experiment, we show that the different components of the NSGP model allow it to perform well in small and large sample regimes. We set a strong selection bias of \u03b7 = 12 and compare the log(PEHE) characteristic of NSGP with a model that uses the same non-stationary kernel as NSGP, and another model that uses a standard stationary kernel, but both models are tuned using marginal likelihood maximization. As we can see in Figure 2c, the model with the non-stationary kernel achieves the same learning rate as NSGP, but exhibits a large offset as it does not account for selection bias, whereas the stationary model fails to learn the smoothness of the rougher Brownian motion since it assigns the same length-scale to both surfaces, and hence it over-smooths the prior, achieving a suboptimal rate.\n2The minor discrepancy is a result of the residual error in the linear regression fit."}, {"heading": "5.2. The Infant Health and Development Program", "text": "We evaluated the performance of the NSGP model presented in Section 4.1 using the standard semi-synthetic experimental setup designed by Hill in (Hill, 2011). We report a state-of-the-art result in this setup, and draw connections between our experimental results and our analyses."}, {"heading": "5.2.1. DATA AND BENCHMARKS", "text": "The Infant Health and Development Program (IHDP) is an interventional program intended to enhance the health of premature infants (Hill, 2011). (Hill, 2011) extracted features and treatment assignments from a real-world clinical trial, and introduced selection bias to the data artificially by removing a subset of the patients. The potential outcomes are simulated according to the standard non-linear \u201dResponse Surface B\u201d setting in (Hill, 2011). The dataset comprised 747 subjects, with 25 features for each subject. Our experimental setup is identical to (Hill, 2011; Johansson et al., 2016; Shalit et al., 2017; Alaa & van der Schaar, 2017): we run 1000 experiments in which we compute the in-sample and out-of-sample \u221a PEHE (with 80/20 training/testing splits), and report average results in Table 1.\nWe compared the performance of NSGP with a total of 23 CATE estimation benchmarks. We considered: tree-based algorithms (BART (Hill, 2011), Causal forests (Wager & Athey, 2017), Bayesian causal forests (Hahn et al., 2017)), methods based on deep learning (CFR Wass., CFR MMD, BNN, TARnet (Shalit et al., 2017)), multivariate additive regression splines (MARS) (Powers et al., 2017), Gaussian processes (CMGP) (Alaa & van der Schaar, 2017), nearest neighbor matching (k-NN), propensity score matching (PSM), and targeted maximum likelihood (TMLE) (Porter et al., 2011). We also composed a number of T-learners and S-learners as in (Ku\u0308nzel et al., 2017), using a variety of baseline machine learning algorithms (DNN stands for deep networks and OLS stands for linear regression)."}, {"heading": "5.2.2. RESULTS AND CONCLUSIONS", "text": "As we can see in Table 1, the proposed NSGP model significantly outperforms all competing benchmarks. The combined benefit of the two components of an NSGP (nonstationary kernel and doubly-robust hyperparameters) is highlighted by comparing its performance to a vanilla SGP (stationary GP) with marginal likelihood maximization. The gain with respect to such a model is a 2-fold improvement in the PEHE.\nBecause the IHDP dataset has a \u201cmoderate\u201d sample size, both selection bias and learning rate seem to impact the performance. Thus, our method took advantage of having addressed modeling questions [Q1] and [Q2] appropriately by being both \u201crate-optimal\u201d and \u201cbias-aware\u201d.\nThe check marks in columns [Q1] and [Q2] designate methods that address modeling questions [Q1] and [Q2] \u201cappropriately\u201d in the light of the analysis presented in Section 3. Methods with [Q1] checked use a regression structure with \u201coutcome-specific\u201d hyperparameters, and methods with [Q2] checked adjust for selection bias. A general observation is that the structure of the regression model seem to matter much more than the strategy for handling selection bias. This is evident from the fact that the TARnet model (does not handle bias but models outcomes separately) significantly outperforms BNN (handles bias but uses a single-surface model (Shalit et al., 2017)), and that all T-learners (models 2 separate response surfaces) outperformed their S-shaped counterparts (models a single surface). For parametric models, such as OLS, the issue of selecting the right regression structure is even more crucial.\nTo sum up, the results in Table 1 imply that selecting the right regression structure is crucial for rate-optimality in sufficiently large dataset, whereas handling selection bias provides an extra bonus. In Table 1, methods that address both [Q1] and [Q2] (NSGP, CMGP, and CFR. Wass and MMD) displayed a superior performance."}, {"heading": "Acknowledgements", "text": "The authors would like to thank the reviewers for their helpful comments. The research presented in this paper was supported by the Office of Naval Research (ONR) and the NSF (Grant number: ECCS1462245, ECCS1533983, and ECCS1407712)."}], "year": 2018, "references": [{"title": "Bayesian inference of individualized treatment effects using multitask gaussian processes", "authors": ["Alaa", "Ahmed M", "van der Schaar", "Mihaela"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "year": 2017}, {"title": "Bayesian nonparametric causal inference: Information rates and learning algorithms", "authors": ["Alaa", "Ahmed M", "van der Schaar", "Mihaela"], "venue": "Journal on Selected Topics in Signal Processing,", "year": 2018}, {"title": "Deep-treat: Learning optimal personalized treatments from observational data using neural networks", "authors": ["O Atan", "J Jordan", "M. van der Schaar"], "year": 2018}, {"title": "On some analogues of the amount of information and their use in statistical estimation", "authors": ["A. Bhattacharyya"], "venue": "Sankhya\u0304: The Indian Journal of Statistics,", "year": 1946}, {"title": "Efficient and adaptive estimation for semiparametric models, volume 2", "authors": ["Bickel", "Peter J", "Klaassen", "Chris A", "Y Ritov", "J Klaassen", "Wellner", "Jon A", "Ritov", "YA\u2019Acov"], "year": 1998}, {"title": "Bandwidth selection for kernel density estimation with length-biased data", "authors": ["Borrajo", "Mar\u0131a Isabel", "Gonz\u00e1lez-Manteiga", "Wenceslao", "Mart\u0131\u0301nez-Miranda", "Mar\u0131\u0301a Dolores"], "venue": "Journal of Nonparametric Statistics,", "year": 2017}, {"title": "Lower bounds for posterior rates with gaussian process priors", "authors": ["I. Castillo"], "venue": "Electron. J. Stat.,", "year": 2008}, {"title": "Asymptotics of cross-validated risk estimation in estimator selection and performance assessment", "authors": ["Dudoit", "Sandrine", "van der Laan", "Mark J"], "venue": "Statistical Methodology,", "year": 2005}, {"title": "Subgroup identification from randomized clinical trial data", "authors": ["Foster", "Jared C", "Taylor", "Jeremy MG", "Ruberg", "Stephen J"], "venue": "Statistics in medicine,", "year": 2011}, {"title": "Bayesian regression tree models for causal inference: regularization, confounding, and heterogeneous effects", "authors": ["Hahn", "P Richard", "Murray", "Jared S", "Carvalho", "Carlos M"], "year": 2017}, {"title": "Sample selection bias as a specification error (with an application to the estimation of labor supply", "authors": ["Heckman", "James J"], "year": 1977}, {"title": "Bayesian nonparametric modeling for causal inference", "authors": ["Hill", "Jennifer L"], "venue": "Journal of Computational and Graphical Statistics,", "year": 2011}, {"title": "Correcting sample selection bias by unlabeled data", "authors": ["Huang", "Jiayuan", "Gretton", "Arthur", "Borgwardt", "Karsten M", "Sch\u00f6lkopf", "Bernhard", "Smola", "Alex J"], "venue": "In Advances in neural information processing systems,", "year": 2007}, {"title": "Learning representations for counterfactual inference", "authors": ["Johansson", "Fredrik", "Shalit", "Uri", "Sontag", "David"], "venue": "In International Conference on Machine Learning,", "year": 2016}, {"title": "Brownian motion and stochastic calculus, volume 113", "authors": ["Karatzas", "Ioannis", "Shreve", "Steven"], "venue": "Springer Science & Business Media,", "year": 2012}, {"title": "Nonparametric causal effects based on incremental propensity score interventions", "authors": ["Kennedy", "Edward H"], "venue": "Journal of the American Statistical Association,", "year": 2018}, {"title": "Meta-learners for estimating heterogeneous treatment effects using machine learning", "authors": ["K\u00fcnzel", "S\u00f6ren", "Sekhon", "Jasjeet", "Bickel", "Peter", "Yu", "Bin"], "venue": "arXiv preprint arXiv:1706.03461,", "year": 2017}, {"title": "Matching on balanced nonlinear representations for treatment effects estimation", "authors": ["Li", "Sheng", "Fu", "Yun"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2017}, {"title": "Estimating individual treatment effect in observational data using random forest methods", "authors": ["Lu", "Min", "Sadiq", "Saad", "Feaster", "Daniel J", "Ishwaran", "Hemant"], "venue": "Journal of Computational and Graphical Statistics,", "year": 2017}, {"title": "The relative performance of targeted maximum likelihood estimators", "authors": ["Porter", "Kristin E", "Gruber", "Susan", "Van Der Laan", "Mark J", "Sekhon", "Jasjeet S"], "venue": "The International Journal of Biostatistics,", "year": 2011}, {"title": "Some methods for heterogeneous treatment effect estimation in high-dimensions", "authors": ["Powers", "Scott", "Qian", "Junyang", "Jung", "Kenneth", "Schuler", "Alejandro", "Shah", "Nigam H", "Hastie", "Trevor", "Tibshirani", "Robert"], "venue": "arXiv preprint arXiv:1707.00102,", "year": 2017}, {"title": "Lower bounds on minimax rates for nonparametric regression with additive sparsity and smoothness", "authors": ["Raskutti", "Garvesh", "Yu", "Bin", "Wainwright", "Martin J"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2009}, {"title": "Gaussian processes for machine learning, volume 1", "authors": ["Rasmussen", "Carl Edward", "Williams", "Christopher KI"], "venue": "MIT press Cambridge,", "year": 2006}, {"title": "Higher order influence functions and minimax estimation of nonlinear functionals. In Probability and Statistics: Essays in Honor of David A", "authors": ["Robins", "James", "Li", "Lingling", "Tchetgen", "Eric", "van der Vaart", "Aad"], "venue": "Institute of Mathematical Statistics,", "year": 2008}, {"title": "Optimal structural nested models for optimal sequential decisions", "authors": ["Robins", "James M"], "venue": "In Proceedings of the second seattle Symposium in Biostatistics,", "year": 2004}, {"title": "Reducing bias in observational studies using subclassification on the propensity score", "authors": ["Rosenbaum", "Paul R", "Rubin", "Donald B"], "venue": "Journal of the American statistical Association,", "year": 1984}, {"title": "Causal inference using potential outcomes: Design, modeling, decisions", "authors": ["Rubin", "Donald B"], "venue": "Journal of the American Statistical Association,", "year": 2005}, {"title": "Estimating individual treatment effect: generalization bounds and algorithms", "authors": ["Shalit", "Uri", "Johansson", "Fredrik", "Sontag", "David"], "year": 2017}, {"title": "Improving predictive inference under covariate shift by weighting the log-likelihood function", "authors": ["Shimodaira", "Hidetoshi"], "venue": "Journal of statistical planning and inference,", "year": 2000}, {"title": "Adaptive bayesian credible sets in regression with a gaussian process prior", "authors": ["Sniekers", "Suzanne", "van der Vaart", "Aad"], "venue": "Electronic Journal of Statistics,", "year": 2015}, {"title": "Optimal global rates of convergence for nonparametric regression", "authors": ["Stone", "Charles J"], "venue": "The annals of statistics,", "year": 1982}, {"title": "Mixture regression for covariate shift", "authors": ["Sugiyama", "Masashi", "Storkey", "Amos J"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2007}, {"title": "Covariate shift adaptation by importance weighted cross validation", "authors": ["Sugiyama", "Masashi", "Krauledat", "Matthias", "M\u00c3\u017eller", "Klaus-Robert"], "venue": "Journal of Machine Learning Research,", "year": 2007}, {"title": "Information rates of nonparametric gaussian process methods", "authors": ["Vaart", "Aad van der", "Zanten", "Harry van"], "venue": "Journal of Machine Learning Research,", "year": 2011}, {"title": "Rates of contraction of posterior distributions based on gaussian process priors", "authors": ["van der Vaart", "Aad W", "van Zanten", "J Harry"], "venue": "The Annals of Statistics,", "year": 2008}, {"title": "Reproducing kernel hilbert spaces of gaussian priors", "authors": ["van der Vaart", "Aad W", "van Zanten", "J Harry"], "venue": "Institute of Mathematical Statistics,", "year": 2008}, {"title": "Estimation and inference of heterogeneous treatment effects using random forests", "authors": ["Wager", "Stefan", "Athey", "Susan"], "venue": "Journal of the American Statistical Association,", "year": 2017}, {"title": "Estimating heterogeneous treatment effects with observational data", "authors": ["Xie", "Yu", "Brand", "Jennie E", "Jann", "Ben"], "venue": "Sociological methodology,", "year": 2012}, {"title": "Information-theoretic determination of minimax rates of convergence", "authors": ["Yang", "Yuhong", "Barron", "Andrew"], "venue": "Annals of Statistics,", "year": 1999}, {"title": "Minimax-optimal nonparametric regression in high dimensions", "authors": ["Yang", "Yun", "Tokdar", "Surya T"], "venue": "The Annals of Statistics,", "year": 2015}, {"title": "Ganite: Estimation of individualized treatment effects using generative adversarial nets", "authors": ["Yoon", "Jinsung", "Jordon", "James", "van der Schaar", "Mihaela"], "venue": "International Conference on Learning Representations (ICLR),", "year": 2018}, {"title": "Using wavelet network in nonparametric estimation", "authors": ["Zhang", "Qinghua"], "venue": "IEEE Transactions on Neural networks,", "year": 1997}], "id": "SP:badcfae286bbe1882cd7725ea6a5e7fbd4f6cffe", "authors": [{"name": "Ahmed M. Alaa", "affiliations": []}, {"name": "Mihaela van der Schaar", "affiliations": []}], "abstractText": "Estimating heterogeneous treatment effects from observational data is a central problem in many domains. Because counterfactual data is inaccessible, the problem differs fundamentally from supervised learning, and entails a more complex set of modeling choices. Despite a variety of recently proposed algorithmic solutions, a principled guideline for building estimators of treatment effects using machine learning algorithms is still lacking. In this paper, we provide such guidelines by characterizing the fundamental limits of estimating heterogeneous treatment effects, and establishing conditions under which these limits can be achieved. Our analysis reveals that the relative importance of the different aspects of observational data vary with the sample size. For instance, we show that selection bias matters only in small-sample regimes, whereas with a large sample size, the way an algorithm models the control and treated outcomes is what bottlenecks its performance. Guided by our analysis, we build a practical algorithm for estimating treatment effects using a non-stationary Gaussian processes with doubly-robust hyperparameters. Using a standard semi-synthetic simulation setup, we show that our algorithm outperforms the state-of-the-art, and that the behavior of existing algorithms conforms with our analysis.", "title": "Limits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design"}
0,1,label2,summary_sentences
Distributed machine learning is crucial for many settings where the data is possessed by multiple parties or when the quantity of data prohibits processing at a central location.,1. Introduction,[1.0],['Distributed machine learning is crucial for many settings where the data is possessed by multiple parties or when the quantity of data prohibits processing at a central location.']
"It helps to reduce the computational complexity, improve both the robustness and the scalability of data processing.",1. Introduction,[1.0],"['It helps to reduce the computational complexity, improve both the robustness and the scalability of data processing.']"
"In a distributed setting, multiple entities/nodes collaboratively work toward a common optimization objective through an
1Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Xueru Zhang <xueru@umich.edu>, Mohammad Mahdi Khalili <khalili@umich.edu>, Mingyan Liu <mingyan@umich.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
interactive process of local computation and message passing, which ideally should result in all nodes converging to a global optimum.",1. Introduction,[0],[0]
"Existing approaches to decentralizing an optimization problem primarily consist of subgradientbased algorithms (Nedic et al., 2008; Nedic & Ozdaglar, 2009; Lobel & Ozdaglar, 2011), ADMM-based algorithms (Wei & Ozdaglar, 2012; Ling & Ribeiro, 2014; Shi et al., 2014; Zhang & Kwok, 2014; Ling et al., 2016), and composite of subgradient and ADMM (Bianchi et al., 2014).",1. Introduction,[0],[0]
"It has been shown that ADMM-based algorithms can converge at the rate of O( 1k ) while subgradient-based algorithms typically converge at the rate of O( 1√
k ), where k is the number
of iterations (Wei & Ozdaglar, 2012).",1. Introduction,[0],[0]
"In this study, we will solely focus on ADMM-based algorithms.
",1. Introduction,[0],[0]
"The information exchanged over the iterative process gives rise to privacy concerns if the local training data is proprietary to each node, especially when it contains sensitive information such as medical or financial records, web search history, and so on.",1. Introduction,[0],[0]
"It is therefore highly desirable to ensure such iterative processes are privacy-preserving.
",1. Introduction,[0.9999999509010399],['It is therefore highly desirable to ensure such iterative processes are privacy-preserving.']
"A widely used notion of privacy is the ε-differential privacy; it is generally achieved by perturbing the algorithm such that the probability distribution of its output is relatively insensitive to any change to a single record in the input (Dwork, 2006).",1. Introduction,[0],[0]
"Several differentially private distributed algorithms have been proposed, including (Hale & Egerstedty, 2015; Huang et al., 2015; Han et al., 2017; Zhang & Zhu, 2017; Bellet et al., 2017).",1. Introduction,[0],[0]
"While a number of such studies have been done for (sub)gradient-based algorithms, the same is much harder for ADMM-based algorithms due to its computational complexity stemming from the fact that each node is required to solve an optimization problem in each iteration.",1. Introduction,[1.0],"['While a number of such studies have been done for (sub)gradient-based algorithms, the same is much harder for ADMM-based algorithms due to its computational complexity stemming from the fact that each node is required to solve an optimization problem in each iteration.']"
"To the best of our knowledge, only (Zhang & Zhu, 2017) applies differential privacy to ADMM, where the noise is either added to the dual variable (dual variable perturbation) or the primal variable (primal variable perturbation) in ADMM updates.",1. Introduction,[0],[0]
"However, (Zhang & Zhu, 2017) could only bound the privacy loss of a single iteration.",1. Introduction,[0],[0]
"Since an attacker can potentially use all intermediate results to perform inference, the privacy loss accumulates over time through the iterative process.",1. Introduction,[1.0],"['Since an attacker can potentially use all intermediate results to perform inference, the privacy loss accumulates over time through the iterative process.']"
It turns out that the tradeoff between the utility of the algorithm and its privacy preservation over the entire computational process becomes hard using the existing method.,1. Introduction,[0],[0]
"ar X iv :1 80 6.
",1. Introduction,[0],[0]
"02 24
6v 1
[ cs
.L",1. Introduction,[0],[0]
"G
] 6
J un
2 01
8
In this study we propose a perturbation method that could simultaneously improve the accuracy and privacy for ADMM.",1. Introduction,[0],[0]
We start with a modified version of ADMM whereby each node independently decides its own penalty parameter in each iteration; it may also differ from the dual updating step size.,1. Introduction,[0],[0]
For this modified ADMM we establish conditions for convergence and quantify the lower bound of the convergence rate.,1. Introduction,[0],[0]
We then present a penalty perturbation method to provide differential privacy.,1. Introduction,[0],[0]
"Our numerical results show that under this method, by increasing the penalty parameter over iterations, we can achieve stronger privacy guarantee as well as better algorithmic performance, i.e., more stable convergence and higher accuracy.
",1. Introduction,[0],[0]
The remainder of the paper is organized as follows.,1. Introduction,[0],[0]
We present problem formulation and definition of differential privacy and ADMM in Section 2 and a modified ADMM algorithm along with its convergence analysis in Section 3.,1. Introduction,[1.0],['We present problem formulation and definition of differential privacy and ADMM in Section 2 and a modified ADMM algorithm along with its convergence analysis in Section 3.']
A private version of this ADMM algorithm is then introduced in Section 4 and numerical results in Section 5.,1. Introduction,[0],[0]
Discussions are given in Section 6 and Section 7 concludes the paper.,1. Introduction,[0],[0]
"Consider a connected network1 given by an undirected graph G(N ,E ), which consists of a set of nodes N = {1, 2, · · · , N} and a set of edges E = {1, 2, · · · , E}.",2.1. Problem Formulation,[0],[0]
Two nodes can exchange information if and only if they are connected by an edge.,2.1. Problem Formulation,[0],[0]
"Let Vi denote node i’s set of neighbors, excluding itself.",2.1. Problem Formulation,[1.0],"['Let Vi denote node i’s set of neighbors, excluding itself.']"
"A node i contains a dataset Di = {(xni , yni )",2.1. Problem Formulation,[0],[0]
"|n = 1, 2, · · · , Bi}, where xni ∈ Rd is the feature vector representing the n-th sample belonging to i, yni ∈ {−1, 1} the corresponding label, and Bi the size of Di.
Consider the regularized empirical risk minimization (ERM) problems for binary classification defined as follows:
",2.1. Problem Formulation,[0],[0]
"min fc OERM (fc, Dall) =",2.1. Problem Formulation,[0],[0]
N∑ i=1,2.1. Problem Formulation,[0],[0]
C Bi Bi∑ n=1 L (yni,2.1. Problem Formulation,[0],[0]
f T c,2.1. Problem Formulation,[0],[0]
x n,2.1. Problem Formulation,[0],[0]
"i )+ρR(fc) (1) where C ≤ Bi and ρ > 0 are constant parameters of the algorithm, the loss function L (·) measures the accuracy of classifier, and the regularizer R(·) helps to prevent overfitting.",2.1. Problem Formulation,[0],[0]
The goal is to train a (centralized) classifier fc ∈ Rd over the union of all local datasets Dall = ∪i∈N,2.1. Problem Formulation,[0],[0]
"Di in a distributed manner using ADMM, while providing privacy guarantee for each data sample 2.
",2.1. Problem Formulation,[0],[0]
"1A connected network is one in which every node is reachable (via a path) from every other node.
2The proposed penalty perturbation method is not limited to classification problems.",2.1. Problem Formulation,[0],[0]
It can be applied to general ADMM-based distributed algorithms since the convergence and privacy analysis,2.1. Problem Formulation,[0],[0]
"To decentralize (1), let fi be the local classifier of each node i. To achieve consensus, i.e., f1 = f2 = · · · = fN , a set of auxiliary variables {wij |i ∈ N , j ∈ Vi} are introduced for every pair of connected nodes.",2.2. Conventional ADMM,[0],[0]
"As a result, (1) is reformulated equivalently as:
min {fi},{wij} ÕERM ({fi}Ni=1, Dall) =",2.2. Conventional ADMM,[0],[0]
N∑ i=1,2.2. Conventional ADMM,[0],[0]
"O(fi, Di)
",2.2. Conventional ADMM,[0],[0]
"s.t. fi = wij , wij = fj , i ∈ N ,",2.2. Conventional ADMM,[0],[0]
"j ∈ Vi
(2)
where O(fi, Di) = C
Bi
∑Bi n=1 L (y n",2.2. Conventional ADMM,[0],[0]
i f T,2.2. Conventional ADMM,[0],[0]
"i x n i ) + ρ
N R(fi).
",2.2. Conventional ADMM,[0],[0]
The objective in (2) can be solved using ADMM.,2.2. Conventional ADMM,[1.0],['The objective in (2) can be solved using ADMM.']
"Let {fi} be the shorthand for {fi}i∈N ; let {wij , λkij} be the shorthand for {wij , λkij}i∈N ,j∈Vi,k∈{a,b}, where λaij , λbij are dual variables corresponding to equality constraints fi = wij and wij = fj respectively.",2.2. Conventional ADMM,[1.0],"['Let {fi} be the shorthand for {fi}i∈N ; let {wij , λkij} be the shorthand for {wij , λkij}i∈N ,j∈Vi,k∈{a,b}, where λaij , λbij are dual variables corresponding to equality constraints fi = wij and wij = fj respectively.']"
"Then the augmented Lagrangian is as follows:
Lη({fi}, {wij , λkij}) =",2.2. Conventional ADMM,[0],[0]
N∑ i=1,2.2. Conventional ADMM,[0],[0]
"O(fi, Di)
+ N∑ i=1",2.2. Conventional ADMM,[0],[0]
∑ j∈Vi (λaij) T (fi − wij) +,2.2. Conventional ADMM,[0],[0]
N∑ i=1,2.2. Conventional ADMM,[0],[0]
"∑ j∈Vi (λbij) T (wij − fj) (3)
+ N∑ i=1 ∑",2.2. Conventional ADMM,[0],[0]
j∈Vi η 2 (||fi − wij ||22 + ||wij,2.2. Conventional ADMM,[0],[0]
"− fj ||22) .
",2.2. Conventional ADMM,[0],[0]
"In the (t + 1)-th iteration, the ADMM updates consist of the following:
fi(t+ 1) = argmin fi Lη({fi}, {wij(t), λkij(t)}) ; (4)
wij(t+ 1) = argmin wij Lη({fi(t+ 1)}, {wij , λkij(t)}) ; (5)
λaij(t+ 1) = λ a ij(t) + η(fi(t+",2.2. Conventional ADMM,[0],[0]
1)− wij(t+ 1)),2.2. Conventional ADMM,[0],[0]
"; (6)
λbij(t+ 1) = λ b ij(t) +",2.2. Conventional ADMM,[0],[0]
η(wij(t+ 1)− fj(t+ 1)) .,2.2. Conventional ADMM,[0],[0]
"(7)
Using Lemma 3 in (Forero et al., 2010), if dual variables λaij(t) and λ b ij(t) are initialized to zero for all node pairs (i, j), then λaij(t) = λ b ij(t) and λ k ij(t) = −λkji(t) will hold for all iterations with k ∈ {a, b}, i ∈ N , j ∈ Vi.
",2.2. Conventional ADMM,[1.0000000592179004],"['(7) Using Lemma 3 in (Forero et al., 2010), if dual variables λaij(t) and λ b ij(t) are initialized to zero for all node pairs (i, j), then λaij(t) = λ b ij(t) and λ k ij(t) = −λkji(t) will hold for all iterations with k ∈ {a, b}, i ∈ N , j ∈ Vi.']"
Let λi(t) = ∑,2.2. Conventional ADMM,[0],[0]
"j∈Vi λ a ij(t) = ∑ j∈Vi λ b ij(t), then the ADMM iterations (4)-(7) can be simplified as:
fi(t+ 1) = argmin fi {O(fi, Di) + 2λi(t)T fi
+η ∑ j∈Vi ||1 2 (fi(t) + fj(t))− fi||22 } ; (8)
λi(t+ 1) = λi(t) + η
2 ∑ j∈Vi (fi(t+ 1)− fj(t+ 1)) .",2.2. Conventional ADMM,[0.999103721665759],"['Let λi(t) = ∑ j∈Vi λ a ij(t) = ∑ j∈Vi λ b ij(t), then the ADMM iterations (4)-(7) can be simplified as: fi(t+ 1) = argmin fi {O(fi, Di) + 2λi(t)T fi +η ∑ j∈Vi ||1 2 (fi(t) + fj(t))− fi||22 } ; (8) λi(t+ 1) = λi(t) + η 2 ∑ j∈Vi (fi(t+ 1)− fj(t+ 1)) .']"
"(9)
in Section 3 & 4 remain valid.",2.2. Conventional ADMM,[0],[0]
"Differential privacy (Dwork, 2006) can be used to measure the privacy risk of each individual sample in the dataset quantitatively.",2.3. Differential Privacy,[1.0],"['Differential privacy (Dwork, 2006) can be used to measure the privacy risk of each individual sample in the dataset quantitatively.']"
"Mathematically, a randomized algorithm A (·) taking a dataset as input satisfies ε-differential privacy if for any two datasets D, D̂ differing in at most one data point, and for any set of possible outputs S ⊆ range(A ), Pr(A (D) ∈ S) ≤",2.3. Differential Privacy,[0],[0]
exp(ε)Pr(A (D̂) ∈ S) holds.,2.3. Differential Privacy,[0],[0]
We call two datasets differing in at most one data point as neighboring datasets.,2.3. Differential Privacy,[1.0],['We call two datasets differing in at most one data point as neighboring datasets.']
"The above definition suggests that for a sufficiently small ε, an adversary will observe almost the same output regardless of the presence (or value change) of any one individual in the dataset; this is what provides privacy protection for that individual.",2.3. Differential Privacy,[1.0],"['The above definition suggests that for a sufficiently small ε, an adversary will observe almost the same output regardless of the presence (or value change) of any one individual in the dataset; this is what provides privacy protection for that individual.']"
"Two randomizations were proposed in (Zhang & Zhu, 2017): (i) dual variable perturbation, where each node i adds a random noise to its dual variable λi(t) before updating its primal variable fi(t) using (8) in each iteration; and (ii) primal variable perturbation, where after updating primal variable fi(t), each node adds a random noise to it before broadcasting to its neighbors.","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[1.0],"['Two randomizations were proposed in (Zhang & Zhu, 2017): (i) dual variable perturbation, where each node i adds a random noise to its dual variable λi(t) before updating its primal variable fi(t) using (8) in each iteration; and (ii) primal variable perturbation, where after updating primal variable fi(t), each node adds a random noise to it before broadcasting to its neighbors.']"
Both were evaluated for a single iteration for a fixed privacy constraint.,"2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[1.0],['Both were evaluated for a single iteration for a fixed privacy constraint.']
"As we will see later in numerical experiments, the privacy loss accumulates significantly when inspected over multiple iterations.
","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0.9999999523992155],"['As we will see later in numerical experiments, the privacy loss accumulates significantly when inspected over multiple iterations.']"
"In contrast, in this study we will explore the use of the penalty parameter η to provide privacy.","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[1.0],"['In contrast, in this study we will explore the use of the penalty parameter η to provide privacy.']"
"In particular, we will allow this to be private information to every node, i.e., each decides its own η in every iteration and it is not exchanged among the nodes.","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[1.0],"['In particular, we will allow this to be private information to every node, i.e., each decides its own η in every iteration and it is not exchanged among the nodes.']"
Below we will begin by modifying the ADMM to accommodate private penalty terms.,"2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[1.0],['Below we will begin by modifying the ADMM to accommodate private penalty terms.']
"Conventional ADMM (Boyd et al., 2011) requires that the penalty parameter η be fixed and equal to the dual updating step size for all nodes in all iterations.",3.1. Making η a node’s private information,[1.0],"['Conventional ADMM (Boyd et al., 2011) requires that the penalty parameter η be fixed and equal to the dual updating step size for all nodes in all iterations.']"
Varying the penalty parameter to accelerate convergence in ADMM has been proposed in the literature.,3.1. Making η a node’s private information,[0],[0]
"For instance, (He et al., 2002; Magnússon et al., 2014; Aybat & Iyengar, 2015; Xu et al., 2016) vary this penalty parameter in every iteration but keep it the same for different equality constraints in (2).",3.1. Making η a node’s private information,[1.0],"['For instance, (He et al., 2002; Magnússon et al., 2014; Aybat & Iyengar, 2015; Xu et al., 2016) vary this penalty parameter in every iteration but keep it the same for different equality constraints in (2).']"
"In (Song et al., 2016; Zhang & Wang, 2017) this parameter varies in each iteration and is allowed to differ for different equality constraints.",3.1. Making η a node’s private information,[0],[0]
"However, all of these modifications are based on the original ADMM (Eqn. (4)-(7)) and not on the simplified version (Eqn. (8)-(9)); the significance of this difference is discussed below in the context of privacy requirement.",3.1. Making η a node’s private information,[0],[0]
"Moreover, we will decouple ηi(t+1) from the dual updating step size, denoted as θ below.",3.1. Making η a node’s private information,[0],[0]
"For simplicity, θ is fixed for
all nodes in our analysis, but can also be private information as we show in numerical experiments.
",3.1. Making η a node’s private information,[0],[0]
First consider replacing η with ηij(t+ 1) in Eqn.,3.1. Making η a node’s private information,[0],[0]
"(4)-(5) of the original ADMM (as is done in (Song et al., 2016; Zhang & Wang, 2017))",3.1. Making η a node’s private information,[0],[0]
"and replacing η with θ in Eqn. (6)-(7); we obtain the following:
fi(t+ 1) = argmin fi {O(fi, Di) + 2λi(t)T fi
+ ∑ j∈Vi ηij(t+ 1) + ηji(t+ 1) 2 ||1 2 (fi(t) + fj(t))− fi||22} ;
λi(t+ 1) = λi(t) +",3.1. Making η a node’s private information,[0],[0]
"θ
2 ∑ j∈Vi (fi(t+ 1)− fj(t+ 1)) .
",3.1. Making η a node’s private information,[0],[0]
This however violates our requirement that ηji(t) be node j’s private information since this is needed by node i to perform the above computation.,3.1. Making η a node’s private information,[0],[0]
"To resolve this, we instead start from the simplified ADMM, modifying Eqn. (8)-(9):
fi(t+ 1) = argmin fi {O(fi, Di) + 2λi(t)T fi
+ηi(t+ 1) ∑ j∈Vi ||fi − 1 2 (fi(t) + fj(t))||22 } ; (10)
λi(t+ 1) = λi(t) +",3.1. Making η a node’s private information,[0],[0]
"θ
2 ∑ j∈Vi (fi(t+ 1)− fj(t+ 1)) , (11)
where ηi(t+ 1) is now node i’s private information.",3.1. Making η a node’s private information,[0],[0]
Indeed ηi(t+ 1) is no longer purely a penalty parameter related to any equality constraint in the original sense.,3.1. Making η a node’s private information,[0],[0]
We will however refer to it as the private penalty parameter for simplicity.,3.1. Making η a node’s private information,[0],[0]
The above constitutes the M-ADMM algorithm.,3.1. Making η a node’s private information,[0],[0]
We next show that the M-ADMM (Eqn. (10)-(11)) converges to the optimal solution under a set of common technical assumptions.,3.2. Convergence Analysis,[0],[0]
"Our proof is based on the method given in (Ling et al., 2016).
",3.2. Convergence Analysis,[0],[0]
"Assumption 1: Function O(fi, Di) is convex and continuously differentiable in fi, ∀i.
",3.2. Convergence Analysis,[0],[0]
Assumption 2:,3.2. Convergence Analysis,[0],[0]
"The solution set to the original ERM problem (1) is nonempty and there exists at least one bounded element.
",3.2. Convergence Analysis,[0],[0]
"The KKT optimality condition of the primal update (10) is:
0 = ∇O(fi(t+ 1), Di) + 2λi(t)",3.2. Convergence Analysis,[0],[0]
+ηi(t+ 1) ∑ j∈Vi (2fi(t+ 1)− (fi(t) + fj(t))) .,3.2. Convergence Analysis,[0],[0]
"(12)
We next rewrite (11)-(12) in matrix form.",3.2. Convergence Analysis,[0],[0]
"Define the adjacency matrix of the network A ∈ RN×N as
aij = { 1, if node i and node j are connected 0, otherwise .
",3.2. Convergence Analysis,[0],[0]
"Stack the variables fi(t), λi(t) and ∇O(fi(t), Di) for i ∈ N into matrices, i.e.,
f̂(t) =  f1(t) T f2(t) T
...",3.2. Convergence Analysis,[0],[0]
"fN (t) T
 ∈ RN×d , Λ(t) =  λ1(t) T λ2(t) T
... λN",3.2. Convergence Analysis,[0],[0]
"(t) T
 ∈ RN×d
∇Ô(f̂(t), Dall) =  ∇O(f1(t), D1)T ∇O(f2(t), D2)T
...",3.2. Convergence Analysis,[0],[0]
"∇O(fN (t), DN )T  ∈ RN×d",3.2. Convergence Analysis,[0],[0]
"Let Vi = |Vi| be the number of neighbors of node i, and define the degree matrix D = diag([V1;V2; · · · ;VN ]) ∈ RN×N .",3.2. Convergence Analysis,[0],[0]
Define for the t-th iteration a penalty-weighted matrix W (t) = diag([η1(t); η2(t); · · · ; ηN (t)]) ∈ RN×N .,3.2. Convergence Analysis,[0],[0]
"Then the matrix form of (11)-(12) are:
∇Ô(f̂(t+ 1), Dall) + 2Λ(t) + 2W (t+ 1)Df̂(t+ 1) −W (t+ 1)(D +A)f̂(t) = 0N×d ; (13)
2Λ(t+ 1) = 2Λ(t) + θ(D −A)f̂(t+ 1) .",3.2. Convergence Analysis,[0],[0]
"(14)
Note that D −A is the Laplacian matrix and D +A is the signless Laplacian matrix of the network, with the following properties if the network is connected: (i) D ±",3.2. Convergence Analysis,[0],[0]
A 0 is positive semi-definite; (ii),3.2. Convergence Analysis,[0],[0]
Null(D,3.2. Convergence Analysis,[0],[0]
"− A) = c1, i.e., every member in the null space of D −A is a scalar multiple of 1 with 1 being the vector of all 1’s (Kelner, 2007).",3.2. Convergence Analysis,[0],[0]
"Let √ X denote the square root of a symmetric positive semi-definite (PSD) matrix X that is also symmetric PSD, i.e., √ X √ X = X .",3.2. Convergence Analysis,[0],[0]
"Define matrix Y (t) such that 2Λ(t) =√
D −AY (t).",3.2. Convergence Analysis,[0],[0]
"Since Λ(0) = zeros(N, d), which is in the column space of D −A, this together with (14) imply that Λ(t) is in the column space of D − A and √ D −A.",3.2. Convergence Analysis,[0],[0]
This guarantees the existence of Y (t).,3.2. Convergence Analysis,[0],[0]
"This allows us to rewrite (13)-(14) as:
∇Ô(f̂(t+ 1), Dall) + √ D −AY (t+ 1)
+(W (t+ 1)− θI)(D −A)f̂(t+ 1) +W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))",3.2. Convergence Analysis,[0],[0]
"= 0N×d ; (15)
Y (t+ 1) = Y (t) + θ",3.2. Convergence Analysis,[0],[0]
√ D −Af̂(t+ 1) .,3.2. Convergence Analysis,[0],[0]
"(16)
Lemma 3.1 [First-order Optimality Condition (Ling et al., 2016)]",3.2. Convergence Analysis,[0],[0]
"Under Assumptions 1 and 2, the following two statements are equivalent:
• f̂∗ =",3.2. Convergence Analysis,[0],[0]
"[(f∗1 )T ; (f∗2 )T ; · · · ; (f∗N )T ] ∈ RN×d is consensual, i.e., f∗1 = f ∗ 2 = · · · = f∗N = f∗c where f∗c is the
optimal solution to (1).
",3.2. Convergence Analysis,[0],[0]
"• There exists a pair (f̂∗, Y ∗) with Y ∗ = √ D −AX
for some X ∈ RN×d such that
∇Ô(f̂∗, Dall) + √ D −AY ∗ = 0N×d ; (17)√ D −Af̂∗ = 0N×d .",3.2. Convergence Analysis,[0],[0]
"(18)
Lemma 3.1 shows that a pair (Y ∗, f̂∗) satisfying (17)(18) is equivalent to the optimal solution of our problem, hence the convergence of M-ADMM is proved by showing that (Y (t), f̂(t)) converges to a pair (Y ∗, f̂∗) satisfying (17)(18).
",3.2. Convergence Analysis,[0],[0]
Theorem 3.1 Consider the modified ADMM defined by (10)-(11).,3.2. Convergence Analysis,[0],[0]
"Let {Y (t), f̂(t)} be outputs in each iteration and (Y ∗, f̂∗) a pair satisfying (17)-(18).",3.2. Convergence Analysis,[0],[0]
"Denote
Z(t) =
[ Y (t)
f̂(t)
] ∈ R2N×d, Z∗ =",3.2. Convergence Analysis,[0],[0]
"[ Y ∗
f̂∗
] ∈ R2N×d
J(t)",3.2. Convergence Analysis,[0],[0]
=,3.2. Convergence Analysis,[0],[0]
"[ IN×N θ 0 0 W (t)(D +A) ] ∈ R2N×2N
Let 〈·, ·〉F be the Frobenius inner product of two matrices.",3.2. Convergence Analysis,[0],[0]
"We have
〈Z(t+ 1)−Z∗, J(t+ 1)(Z(t+ 1)−Z(t))〉F ≤ 0 .",3.2. Convergence Analysis,[0],[0]
(19),3.2. Convergence Analysis,[0],[0]
"(Y (t), f̂(t)) converges to (Y ∗, f̂∗).","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"To further establish the convergence rate of modified ADMM, an additional assumption is used:
Assumption 3:",3.3. Convergence Rate Analysis,[0],[0]
"For all i ∈ N , O(fi, Di) is strongly convex in fi and has Lipschitz continues gradients, i.e., for any f1i and f 2",3.3. Convergence Rate Analysis,[0],[0]
"i , we have:
(f1i −f2i )T (∇O(f1i , Di)−∇O(f2i , Di))",3.3. Convergence Rate Analysis,[0],[0]
"≥ mi||f1i −f2i ||22
||∇O(f1i , Di)−∇O(f2i , Di)||2 ≤Mi||f1i",3.3. Convergence Rate Analysis,[0],[0]
"− f2i ||2 (20)
where mi > 0 is the strong convexity constant and 0",3.3. Convergence Rate Analysis,[0],[0]
<,3.3. Convergence Rate Analysis,[0],[0]
Mi,3.3. Convergence Rate Analysis,[0],[0]
"< +∞ is the Lipschitz constant.
",3.3. Convergence Rate Analysis,[0],[0]
Theorem 3.2 Define Dm = diag([m1;m2; · · · ;mN ]) ∈,3.3. Convergence Rate Analysis,[0],[0]
RN×N and DM = diag([M21 ;M22 ; · · · ;M2N ]) ∈ RN×N with mi > 0,3.3. Convergence Rate Analysis,[0],[0]
and 0 <,3.3. Convergence Rate Analysis,[0],[0]
Mi < +∞ as given in Assumption 3.,3.3. Convergence Rate Analysis,[0],[0]
"Denote by ||X||2J = 〈X, JX〉F the Frobenius inner product of any matrix X and JX; denote by σmin(·) and σmax(·) the smallest nonzero, and the largest, singular values of a matrix, respectively.
",3.3. Convergence Rate Analysis,[0],[0]
Let σ̃max(t) =,3.3. Convergence Rate Analysis,[0],[0]
"σmax(W (t)(D +A)), σ̄max/min(t) = σmax/min((W",3.3. Convergence Rate Analysis,[0],[0]
(t)− θI)(D −A)) and µ > 1 be an arbitrary constant.,3.3. Convergence Rate Analysis,[0],[0]
"Consider any δ(t) that satisfies (21)(22):
δ(t)µ2σ̃max(t) θσmin(D −A) ≤ 1 (21)
and
δ(t)( µσ̄max(t) 2IN + µ2DM θσmin(D",3.3. Convergence Rate Analysis,[0],[0]
−A)(µ− 1),3.3. Convergence Rate Analysis,[0],[0]
"+W (t)(D +A))
",3.3. Convergence Rate Analysis,[0],[0]
2(W (t)− θI)(D −A) + 2Dm .,3.3. Convergence Rate Analysis,[0],[0]
(22),3.3. Convergence Rate Analysis,[0],[0]
"(Y (t), f̂(t)) converges to (Y ∗, f̂∗) in the following sense:
(1 + δ(t))||Z(t)− Z∗||2J(t) ≤","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
||Z(t−,"If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"1)− Z ∗||2J(t) .
","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Furthermore, a lower bound on δ(t) is:
min{θσmin(D −A) µ2σ̃max(t) , 2mo + 2σ̄min(t) µ2M2O+µσ̄max(t) 2
θσmin(D−A)(µ−1) + σ̃max(t) } (23)
where mo = mini∈N {mi} and MO = maxi∈N {Mi}.
","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Although Theorem 3.2 only gives a lower bound on the convergence rate (1 + δ(t)) of the M-ADMM, it reflects the impact of penalty {ηi(t)}Ni=1 on the convergence.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Since σ̄max(t) = σmax((W (t)− θI)(D −A)) and σ̃max(t) = σmax(W (t)(D +A)), larger penalty results in larger σ̄max(t) and σ̃max(t).","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"By (23), the first term,
θσmin(D−A) µ2σ̃max(t)
is smaller when σ̃max(t) is larger.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"The second term is bounded by θσmin(D−A)(µ−1)(2mo+2σ̄min(t))µσ̄max(t)2 , which is smaller when σ̄max(t) is larger.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Therefore, the convergence rate 1 + δ(t) decreases as {ηi(t)}Ni=1 increase.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
In this section we present a privacy preserving version of MADMM.,4. Private M-ADMM,[0],[0]
"To begin, a random noise i(t+1) with probability density proportional to exp{−αi(t + 1)|| i(t + 1)||2} is added to penalty term in the objective function of (10):
Lprivi (t+ 1) =",4. Private M-ADMM,[0],[0]
"O(fi, Di) + 2λi(t)",4. Private M-ADMM,[0],[0]
T fi +ηi(t+ 1) ∑ j∈Vi ||fi + i(t+,4. Private M-ADMM,[0],[0]
"1)− 1 2 (fi(t) + fj(t))||22
(24)
",4. Private M-ADMM,[0],[0]
"To generate this noisy vector, choose the norm from the gamma distribution with shape d and scale 1αi(t+1) and the direction uniformly, where d is the dimension of the feature space.",4. Private M-ADMM,[0],[0]
"Then node i’s local result is obtained by finding the optimal solution to the private objective function:
fi(t+ 1) = argmin fi
Lprivi (t+ 1), i ∈ N .",4. Private M-ADMM,[0],[0]
"(25)
It is equivalent to (26) below when noise ηi(t+1)Vi i(t+1)
",4. Private M-ADMM,[0],[0]
Algorithm 1 Penalty perturbation (PP) method,4. Private M-ADMM,[0],[0]
Parameter:,4. Private M-ADMM,[0],[0]
"Determine θ such that 2c1 < BiC ( ρ N + 2θVi)
holds for all i. Initialize: Generate fi(0) randomly and λi(0) = 0d×1 for every node i ∈ N , t = 0",4. Private M-ADMM,[0],[0]
"Input: {Di}Ni=1, {αi(1), · · · , αi(T )}Ni=1 for t = 0 to T − 1 do
for i = 1 to N do Generate noise i(t+ 1) ∼ exp(−αi(t+ 1)|| ||2)",4. Private M-ADMM,[0],[0]
"Perturb the penalty term according to (24) Update primal variable via (25) end for for i = 1 to N do
Broadcast fi(t+ 1) to all neighbors",4. Private M-ADMM,[0],[0]
"j ∈ Vi end for for i = 1 to N do
Update dual variable according to (11) end for
end for Output: upper bound of the total privacy loss β
is added to the dual variable λi(t):
argmin fi
L̃privi (",4. Private M-ADMM,[0],[0]
"t+ 1) = C
Bi Bi∑ n=1 L",4. Private M-ADMM,[0],[0]
(,4. Private M-ADMM,[0],[0]
yni f T i x n,4. Private M-ADMM,[0],[0]
i ),4. Private M-ADMM,[0],[0]
"+ ρ N R(fi)
",4. Private M-ADMM,[0],[0]
+2(λi(t) +,4. Private M-ADMM,[0],[0]
ηi(t+,4. Private M-ADMM,[0],[0]
1)Vi i(t+ 1)),4. Private M-ADMM,[0],[0]
"T fi +ηi(t+ 1) ∑ j∈Vi ||fi − 1 2 (fi(t) + fj(t))||22 .
",4. Private M-ADMM,[0],[0]
"Further, if ηi(t+1) = η = θ,∀i, t, then the above is reduced to the dual variable perturbation in (Zhang & Zhu, 2017)3.
",4. Private M-ADMM,[0],[0]
"The complete procedure is shown in Algorithm 1, where the condition used to generate θ helps bound the worst-case privacy loss but is not necessary in guaranteeing convergence.
",4. Private M-ADMM,[0],[0]
"In a distributed and iterative setting, the “output” of the algorithm is not merely the end result, but includes all intermediate results generated and exchanged during the iterative process.",4. Private M-ADMM,[0],[0]
"For this reason, we formally state the differential privacy definition in this setting below.
",4. Private M-ADMM,[0],[0]
"Definition 4.1 Consider a connected network G(N ,E ) with a set of nodes N = {1, 2, · · · , N}.",4. Private M-ADMM,[0],[0]
Let f(t) =,4. Private M-ADMM,[0],[0]
{fi(t)}Ni=1 denote the information exchange of all nodes in the t-th iteration.,4. Private M-ADMM,[0],[0]
"A distributed algorithm is said to satisfy β-differential privacy during T iterations if for any two datasets Dall = ∪iDi and D̂all = ∪iD̂i, differing in at
3Only a single iteration is considered in (Zhang & Zhu, 2017) while imposing a privacy constraint.",4. Private M-ADMM,[0],[0]
"Since we consider the entire iterative process, we don’t impose per-iteration privacy constraint but calculate the total privacy loss.
",4. Private M-ADMM,[0],[0]
"most one data point, and for any set of possible outputs S during T iterations, the following holds:
Pr({f(t)}Tt=0 ∈ S|Dall)",4. Private M-ADMM,[0],[0]
Pr({f(t)}Tt=0 ∈ S|D̂all) ≤,4. Private M-ADMM,[0],[0]
"exp(β)
We now state our main result on the privacy property of the penalty perturbation algorithm using the above definition.",4. Private M-ADMM,[0],[0]
"Additional assumptions on L (·) and R(·) are used.
",4. Private M-ADMM,[0],[0]
Assumption 4: The loss function L is strictly convex and twice differentiable.,4. Private M-ADMM,[0],[0]
|L,4. Private M-ADMM,[0],[0]
"′| ≤ 1 and 0 < L ′′ ≤ c1 with c1 being a constant.
",4. Private M-ADMM,[0],[0]
"Assumption 5: The regularizer R is 1-strongly convex and twice continuously differentiable.
",4. Private M-ADMM,[0],[0]
Theorem 4.1 Normalize feature vectors in the training set such that ||xni ||2 ≤ 1 for all i ∈ N and,4. Private M-ADMM,[0],[0]
"n. Then the private M-ADMM algorithm (PP) satisfies the β-differential privacy with
β ≥ max i∈N { T∑ t=1 C(1.4c1 + αi(t)) ηi(t)ViBi } .",4. Private M-ADMM,[0],[0]
(26),4. Private M-ADMM,[0],[0]
"We use the same dataset as (Zhang & Zhu, 2017), i.e., the Adult dataset from the UCI Machine Learning Repository (Lichman, 2013).",5. Numerical Experiments,[0],[0]
"It consists of personal information of around 48,842 individuals, including age, sex, race, education, occupation, income, etc.",5. Numerical Experiments,[0],[0]
"The goal is to predict whether the annual income of an individual is above $50,000.
",5. Numerical Experiments,[0],[0]
"To preprocess the data, we (1) remove all individuals with missing values; (2) convert each categorical attribute (with m categories) to a binary vector of length m; (3) normalize columns (features) such that the maximum value of each column is 1; (4) normalize rows (individuals) such that its l2 norm is at most 1; and (5) convert labels {≥ 50k,≤ 50k} to {+1,−1}.",5. Numerical Experiments,[0],[0]
"After this preprocessing, the final data includes 45,223 individuals, each represented as a 105-dimensional vector of norm at most 1.
",5. Numerical Experiments,[0],[0]
"We will use as loss function the logistic loss L (z) = log(1 + exp(−z)), with |L ′| ≤ 1 and L ′′ ≤ c1 = 14 .",5. Numerical Experiments,[0],[0]
The regularizer is R(fi),5. Numerical Experiments,[0],[0]
= 12 ||fi|| 2 2.,5. Numerical Experiments,[0],[0]
We will measure the accuracy of the algorithm by the average loss L(t) := 1 N ∑N i=1 1,5. Numerical Experiments,[0],[0]
"Bi ∑Bi n=1 L (y n i fi(t)
",5. Numerical Experiments,[0],[0]
Txni ) over the training set.,5. Numerical Experiments,[0],[0]
"We will measure the privacy of the algorithm by the upper bound P (t) := max i∈N { ∑t r=1 C(1.4c1+αi(r)) ηi(r)ViBi
}.",5. Numerical Experiments,[0],[0]
"The smaller L(t) and P (t), the higher accuracy and stronger privacy guarantee.",5. Numerical Experiments,[0],[0]
"We consider a five-node network and assign each node the following private penalty parameters: ηi(t) = ηi(1)q t−1 i for node i, where [η1(1), · · · , η5(1)] =",5.1. Convergence of M-ADMM,[0],[0]
"[0.55, 0.65, 0.6, 0.55, 0.6] and [q1, · · · , q5] =",5.1. Convergence of M-ADMM,[0],[0]
"[1.01, 1.03, 1.1, 1.2, 1.02].
Figure 1(a) shows the convergence of M-ADMM under these parameters while using a fixed dual updating step size θ = 0.5 across all nodes (blue curve).",5.1. Convergence of M-ADMM,[0],[0]
This is consistent with Theorem 3.1.,5.1. Convergence of M-ADMM,[0],[0]
"As mentioned earlier, this step size can also be non-fixed (black) and different (red) for different nodes.",5.1. Convergence of M-ADMM,[0],[0]
"In
Figure 1(b) we let each node use the same penalty ηi(t) = η(t) = 0.5qt−11 and compare the results by increasing q1, q1 ≥ 1.",5.1. Convergence of M-ADMM,[0],[0]
"We see that increasing penalty slows down the convergence, and larger increase in q1 slows it down even more, which is consistent with Theorem 3.2.",5.1. Convergence of M-ADMM,[0],[0]
"We next inspect the accuracy and privacy of the penalty perturbation (PP) based private M-ADMM (Algorithm 1) and compare it with the dual variable perturbation (DVP) method proposed in (Zhang & Zhu, 2017).",5.2. Private M-ADMM,[0],[0]
"In this set of experiments, for simplicity of presentation we shall fix θ = 0.5, let ηi(t) = η(t) = θqt−11 , and noise αi(t) = α(t) = α(1)qt−12 for all nodes.",5.2. Private M-ADMM,[0],[0]
"We observe similar results when ηi(t) and αi(t) vary from node to node.
",5.2. Private M-ADMM,[0],[0]
"For each parameter setting, we perform 10 independent runs of the algorithm, and record both the mean and the range of their accuracy.",5.2. Private M-ADMM,[0],[0]
"Specifically, Ll(t) denotes the average loss over the training dataset in the t-th iteration of the l-th experiment (1 ≤ l ≤ 10).",5.2. Private M-ADMM,[0],[0]
The mean of average loss is then given by Lmean(t) = 110 ∑10 l=1,5.2. Private M-ADMM,[0],[0]
"L
l(t), and the range Lrange(t)",5.2. Private M-ADMM,[0],[0]
"= max
1≤l≤10 Ll(t)",5.2. Private M-ADMM,[0],[0]
− min 1≤l≤10 Ll(t).,5.2. Private M-ADMM,[0],[0]
"The larger the
range Lrange(t)",5.2. Private M-ADMM,[0],[0]
"the less stable the algorithm, i.e., under the same parameter setting, the difference in performances (convergence curves) of every two experiments is larger.",5.2. Private M-ADMM,[0],[0]
Each parameter setting also has a corresponding upper bound on the privacy loss denoted by P (t).,5.2. Private M-ADMM,[0],[0]
Figures 2(a)2(b) show both Lmean(t) and Lrange(t),5.2. Private M-ADMM,[0],[0]
as vertical bars centered at Lmean(t),5.2. Private M-ADMM,[0],[0]
.,5.2. Private M-ADMM,[0],[0]
Their corresponding privacy upper bound is given in Figures 2(c)2(d).,5.2. Private M-ADMM,[0],[0]
"The pair 2(a)-2(c) (resp. 2(b)2(d)) is for the same parameter setting.
",5.2. Private M-ADMM,[0],[0]
"Figure 2 compares PP (blue & red, with ηi(t) increasing geometrically) with DVP (black & magenta, with ηi(t) = θ, ∀i, t).",5.2. Private M-ADMM,[0],[0]
"We see that in both cases improved accuracy comes at the expense of higher privacy loss (from magenta to black under DVP, from red to blue under PP).",5.2. Private M-ADMM,[0],[0]
"However, we also see that with suitable choices of q1, q2, PP can outperform DVP significantly both in accuracy and in privacy (e.g., red outperforms magenta in both accuracy and privacy, and blue outperforms black in both accuracy and privacy).
",5.2. Private M-ADMM,[0],[0]
We also performed experiments with the same dataset on larger networks with tens and hundreds of nodes and with samples evenly and unevenly spread across nodes.,5.2. Private M-ADMM,[0],[0]
"In both cases, convergence is attained and our algorithm continues to outperform (Zhang & Zhu, 2017) in a large network (see Figures 3 & 4).",5.2. Private M-ADMM,[0],[0]
"Since the privacy loss of the network is dominated by the node with the largest privacy loss and it increases as the number of samples in a node decreases (Theorem 4.1), the loss of privacy in a network with uneven sample size distributions is higher; note that this is a common issue with this type of analysis.",5.2. Private M-ADMM,[0],[0]
Our numerical results show that increasing the penalty {ηi(t)}Ni=1 over iterations can improve the algorithm’s accuracy and privacy simultaneously.,6. Discussion,[0],[0]
Below we provide some insight on why this is the case and discuss possible generalizations of our method.,6. Discussion,[0],[0]
"When the algorithm is perturbed by random noise, which is necessary to achieve privacy, increasing the penalty parameters over iterations makes the algorithm more noise resistant.",6.1. Higher accuracy,[0],[0]
"In particular, for the minimization in (25), larger ηi(t+ 1) results in smaller updates of variables, i.e., smaller distance between fi(t + 1) and fi(t).",6.1. Higher accuracy,[0],[0]
"In the non-private case, since fi(t) always moves toward the optimum, smaller update slows down the process.",6.1. Higher accuracy,[0],[0]
"In the private case, on the other hand, since a random noise is added to each update, fi(t) does not always move toward the optimum in each step.",6.1. Higher accuracy,[0],[0]
"When the overall perturbation has a larger variance, it is more likely that fi(t) could move further away from the optimum in some iterations.",6.1. Higher accuracy,[0],[0]
"Because larger ηi(t) leads to smaller update, it helps prevent fi(t) from moving too far away from the optimum, thus stabilizing the algorithm (smaller Lrange(t)).",6.1. Higher accuracy,[0],[0]
"First of all, more added noise means stronger privacy guarantee.",6.2. Stronger privacy,[0],[0]
"Increasing ηi(t) and αi(t) in such a way that the overall perturbation 2ηi(t)Vi i(t)T fi(t) in (26) is increasing leads to less privacy loss, as shown in Figure 2.",6.2. Stronger privacy,[0],[0]
"The noise resistance provided by an increasing ηi(t) indeed allows larger noises to be added under PP without jeopardizing convergence as observed in Section 6.1.
More interestingly, keeping ηi(t) private further strengthens privacy protection.",6.2. Stronger privacy,[0],[0]
"Consider the following threat model: An attacker knows {(xni , yni )}",6.2. Stronger privacy,[0],[0]
"Bi n=2 and {fj(t)}j∈Vi∪i for all t, i.e., all data points except for the first data point of node i, as well as all intermediate results of node i and its neighbors.",6.2. Stronger privacy,[0],[0]
"If the attacker also knows the dual updating step size θ and penalty parameter {ηi(t)}Tt=1 of node i, it can then infer the unknown data point (x1i , y 1 i ) with high confidence by combining the KKT optimality conditions from all iterations (see supplementary material for details).",6.2. Stronger privacy,[0],[0]
"However, if the penalty parameters {ηi(t)}Tt=1 are private to each node, then it is impossible for the attacker to infer the unknown data.",6.2. Stronger privacy,[0],[0]
"Even if the attacker knows the participation of an individual, it remains hard to infer its features.",6.2. Stronger privacy,[0],[0]
"The main contribution of this paper is the finding that increasing {ηi}Ni=1 improves the algorithm’s ability to resist
noise: even though we increase noise in each iteration to improve privacy, the accuracy does not degrade significantly due to this increasing robustness, which improves the privacy-utility tradeoff.",6.3. Generalization & comparison,[0],[0]
This property holds regardless of the noise distribution.,6.3. Generalization & comparison,[0],[0]
"While the present privacy analysis uses a similar framework as in (Chaudhuri et al., 2011; Zhang & Zhu, 2017) (objective perturbation with added Gamma noise), we can also use methods from other existing (centralized) ERM differentially private algorithms to every iteration in ADMM.",6.3. Generalization & comparison,[0],[0]
"For example, if we allow some probability (δ > 0) of violating -differential privacy and adopt a weaker variant ( , δ)-differential privacy, we can adopt methods from works such as (Kifer et al., 2012; Jain & Thakurta, 2014; Bassily et al., 2014), by adding Gaussian noise to achieve tighter bounds on privacy loss.",6.3. Generalization & comparison,[0],[0]
"However, as noted above, the robustness is improved as {ηi}Ni=1 increases; thus the same conclusion can be reached that both privacy and accuracy can be improved.
",6.3. Generalization & comparison,[0],[0]
This idea can also be generalized to other differentially private iterative algorithms.,6.3. Generalization & comparison,[0],[0]
A key observation of our algorithm is that the overall perturbation (2ηi(t)Vi i(t)T fi(t)) is related to the parameter that controls the updating step size (ηi(t)).,6.3. Generalization & comparison,[0],[0]
"In general, if the algorithm is perturbed in each iteration with a quantity φ( , ξ), which is a function of added noise and some parameter ξ that controls the step size, such that the resulting step size and φ( , ξ) move in opposite directions (i.e., decreasing step size increases the φ( , ξ)), then it is possible to simultaneously improve both accuracy and privacy by varying ξ to decrease the step size over time.
",6.3. Generalization & comparison,[0],[0]
"Interestingly, in a differentially private (sub)gradient-based distributed algorithm (Huang et al., 2015), the step size
and the overall perturbation move in the same direction (i.e., decreasing step size decreases perturbation).",6.3. Generalization & comparison,[0],[0]
"The reason for this difference is that under this subgradient-based algorithm, the sensitivity of the algorithm decreases with decreasing step size, which in turn leads to privacy constraint being satisfied with smaller perturbation.",6.3. Generalization & comparison,[0],[0]
"In contrast, for ADMM the sensitivity of the algorithm is independent of the step size, and the perturbation actually needs to increase to improve privacy guarantee; the decreasing step size acts to compensate for this increase in noise to maintain accuracy, as discussed in Section 6.1.
",6.3. Generalization & comparison,[0],[0]
"This issue of step size never arises in the study of (Zhang & Zhu, 2017) because the analysis is only for a single iteration; however, as we have seen doing so leads to significant total privacy loss over many iterations.",6.3. Generalization & comparison,[0],[0]
This paper presents a penalty-perturbation idea to introduce privacy preservation in iterative algorithms.,7. Conclusions,[0],[0]
We showed how to modify an ADMM-based distributed algorithm to improve privacy without compromising accuracy.,7. Conclusions,[0],[0]
The key idea is to add a perturbation correlated to the step size so that they change in opposite directions.,7. Conclusions,[0],[0]
Applying this idea to other iterative algorithms can be part of the future work.,7. Conclusions,[0],[0]
"This work is supported by the NSF under grants CNS1422211, CNS-1646019, CNS-1739517.",Acknowledgements,[0],[0]
"By KKT condition of (5), there is:
0 =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
λbij(t)− λaij(t) +,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"η(2wij(t+ 1)− fi(t+ 1)− fj(t+ 1))
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Implies:
wij(t+ 1) = 1
2η (λaij(t)− λbij(t))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"+
1 2 (fi(t+ 1) + fj(t+ 1)) (27)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Plug (27) into (6)(7):
λaij(t+ 1) = 1
2 (λaij(t) + λ b ij(t))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"+
η 2 (fi(t+ 1)− fj(t+ 1)) (28)
λbij(t+ 1) = 1
2 (λbij(t) + λ a ij(t))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"+
η 2 (fi(t+ 1)− fj(t+ 1)) (29)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"If initialize λaij(0) = λ b ij(0) to be zero vectors for all node pairs (i, j), (28)(29) imply that λ a ij(t) = λ b ij(t) and λ k ji(t) = −λkij(t), k ∈ {a, b} will hold for all t. (27) becomes:
wij(t+ 1)","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"= 1
2 (fi(t+ 1) + fj(t+ 1)) (30)
Let λij(t) =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
λaij(t),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
= λ,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"b ij(t), (6)(7) can be simplified as:
λij(t+ 1) = λij(t) +","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"η
2 (fi(t+ 1)− fj(t+ 1))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"(31)
Plug (30) into the augmented Lagrangian (3) to simplify it:
Lη({fi}, {wij , λkij}) =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"O(fi, Di) +","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (λij(t)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"T (fi − fj)
+ N∑ i=1","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
j∈Vi η 2 (||fi − 1 2 (fi(t) + fj(t))||22) +,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"j∈Vi η 2 (||1 2 (fi(t) + fj(t))− fj ||22)
(32)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
Since ∑N i=1 ∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
j∈Vi λij(t)fj = ∑N i=1 ∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"j∈Vi λji(t)fi and λij(t) = −λji(t), the second term in (32) can be simplified:
N∑ i=1","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (λij(t)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
T (fi − fj) = 2,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (λij(t)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"T fi
The last term can be expressed as:
N∑ i=1","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
j∈Vi η 2 (||1 2 (fi(t) + fj(t))− fj ||22) =,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"j∈Vi η 2 (||1 2 (fi(t) + fj(t))− fi||22)
Therefore, (32) is simplified as:
Lη({fi}, {wij , λkij}) =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"O(fi, Di) +","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
2 N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi λij(t) T fi + N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"∑ j∈Vi η(||fi − 1 2 (fi(t) + fj(t))||22) (33)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
Define λi(t) = ∑ j∈Vi λij(t).,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Based on (31)(33), the original ADMM updates (4)-(7) are simplified as:
fi(t+ 1) = argmin fi O(fi, Di) + 2λi(t)","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"T fi + η ∑ j∈Vi ||fi − 1 2 (fi(t) + fj(t))||22
λi(t+ 1) = λi(t) + η
2","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (fi(t+ 1)− fj(t+ 1)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Subtract (17) from (15) and (18) from (16):
∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall) + √ D −A(Y (t+ 1)− Y ∗)",B. Proof of Theorem 3.1,[0],[0]
"+ (W (t+ 1)− θI)(D −A)f̂(t+ 1)
+W (t+ 1)(D +",B. Proof of Theorem 3.1,[0],[0]
A)(f̂(t+ 1)− f̂(t)),B. Proof of Theorem 3.1,[0],[0]
"= 0N×d (34)
Y (t+ 1) = Y (t) + θ √ D −A(f̂(t+",B. Proof of Theorem 3.1,[0],[0]
"1)− f̂∗) (35)
",B. Proof of Theorem 3.1,[0],[0]
"By convexity of O(fi, Di), for any f1i and f 2 i , there is:
(f1i − f2i )T (∇O(f1i , Di)−∇O(f2i , Di))",B. Proof of Theorem 3.1,[0],[0]
"≥ 0
Let 〈·, ·〉F be frobenius inner product of two matrices, there is:
〈f̂(t+ 1)− f̂∗,∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall)〉F",B. Proof of Theorem 3.1,[0],[0]
"≥ 0
Substitute ∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall) from (34):
0 ≤ 〈f̂(t+ 1)− f̂∗,−",B. Proof of Theorem 3.1,[0],[0]
"√ D −A(Y (t+ 1)− Y ∗)〉F + 〈f̂(t+ 1)− f̂∗,−(W (t+ 1)− θI)(D −A)f̂(t+ 1)〉F +〈f̂(t+ 1)− f̂∗,−W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))〉F",B. Proof of Theorem 3.1,[0],[0]
"(36)
Consider the right hand side of (36).",B. Proof of Theorem 3.1,[0],[0]
"Since D−A is symmetric and PSD, √ D −A is also a symmetric matrix and by (35),
〈f̂(t+ 1)− f̂∗,− √ D −A(Y (t+ 1)− Y ∗)〉F",B. Proof of Theorem 3.1,[0],[0]
= 〈− √ D −A(f̂(t+,B. Proof of Theorem 3.1,[0],[0]
"1)− f̂∗), (Y (t+ 1)− Y ∗)〉F
= −〈1 θ
(Y (t+ 1)− Y (t)), Y (t+ 1)− Y ∗〉F",B. Proof of Theorem 3.1,[0],[0]
"(37)
Rearrange (36) and use (D −A)f̂∗ = 0N×d
0",B. Proof of Theorem 3.1,[0],[0]
"≥ 〈Z(t+ 1)− Z∗, J(t+ 1)(Z(t+ 1)− Z(t))〉F +",B. Proof of Theorem 3.1,[0],[0]
"〈f̂(t+ 1)− f̂∗, (W (t+ 1)− θI)(D −A)(f̂(t+ 1)− f̂∗)〉F",B. Proof of Theorem 3.1,[0],[0]
"(38)
Suppose ηi(t) ≥ θ for all t, i, i.e., the diagonal matrix W (t)− θI 0 for all t. Since D−A 0, whose eigenvalues are all non-negative, the eigenvalues of (W (t+ 1)− θI)(D −A) are thus also non-negative, i.e., (W (t+ 1)− θI)(D −A) 0.",B. Proof of Theorem 3.1,[0],[0]
"Then for the second term of the RHS of (38), there is:
〈f̂(t+ 1)− f̂∗, (W (t+ 1)− θI)(D −A)(f̂(t+ 1)− f̂∗)〉F",B. Proof of Theorem 3.1,[0],[0]
"≥ 0
Therefore, 〈Z(t+ 1)− Z∗, J(t+ 1)(Z(t+ 1)− Z(t))〉F",B. Proof of Theorem 3.1,[0],[0]
≤ 0,B. Proof of Theorem 3.1,[0],[0]
"(39)
To simplify the notation, for a matrix X , let ||X||2J = 〈X, JX〉F , then (39) can be represented as:
1 2 ||Z(t+ 1)− Z∗||2J(t+1)",B. Proof of Theorem 3.1,[0],[0]
+ 1 2 ||Z(t+ 1)− Z(t)||2J(t+1),B. Proof of Theorem 3.1,[0],[0]
"− 1 2 ||Z(t)− Z∗||2J(t+1) ≤ 0
implies
||Z(t+ 1)− Z(t)||2J(t+1) ≤ −||Z(t+",B. Proof of Theorem 3.1,[0],[0]
1)− Z ∗||2J(t+1) + ||Z(t)− Z ∗||2J(t) + ||Z(t)− Z ∗||2J(t+1),B. Proof of Theorem 3.1,[0],[0]
"− ||Z(t)− Z ∗||2J(t) (40)
",B. Proof of Theorem 3.1,[0],[0]
"Suppose ηi(t+ 1) ≥ ηi(t) for all t and i, i.e., the diagonal matrix W (t+ 1)−W (t) 0 for all t. Since D+A 0, implies (W (t+ 1)−W (t))(D +A) 0.",B. Proof of Theorem 3.1,[0],[0]
"Let U = sup
i,t,k |(fi(t)− f∗c )k| ∈ R be the finite upper bound of all nodes i, all iterations t
and all components k, then
||Z(t)− Z∗||2J(t+1)",B. Proof of Theorem 3.1,[0],[0]
− ||Z(t)− Z ∗||2J(t) = Tr((Z(t)− Z ∗)T,B. Proof of Theorem 3.1,[0],[0]
"(J(t+ 1)− J(t))(Z(t)− Z∗))
= Tr((f̂(t)− f̂∗)T (W (t+ 1)−W (t))(D +A)(f̂(t)− f̂∗))",B. Proof of Theorem 3.1,[0],[0]
"≤ U2(||ones(N, d)||2W (t+1)(D+A)",B. Proof of Theorem 3.1,[0],[0]
"− ones(N, d)|| 2 W (t)(D+A))
(41)
where ones(N, d) is all one’s matrix of size N × d.",B. Proof of Theorem 3.1,[0],[0]
"By (40)(41):
||Z(t+ 1)− Z(t)||2J(t+1) ≤ ||Z(t)− Z ∗||2J(t)",B. Proof of Theorem 3.1,[0],[0]
"− ||Z(t+ 1)− Z ∗||2J(t+1) +U2(||ones(N, d)||2W",B. Proof of Theorem 3.1,[0],[0]
"(t+1)(D+A) − ||ones(N, d)|| 2 W (t)(D+A))
",B. Proof of Theorem 3.1,[0],[0]
"(42)
Sum up (42) over t from 0 to +∞ leads to:
+∞∑ t=0 ||Z(t+ 1)− Z(t)||2J(t+1) ≤ ||Z(0)− Z ∗||2J(0)",B. Proof of Theorem 3.1,[0],[0]
"− ||Z(+∞)− Z ∗||2J(+∞)
+U2(||ones(N, d)||2W (+∞)(D+A) − ||ones(N, d)|| 2 W (0)(D+A))
(43)
Since ηi(t) <",B. Proof of Theorem 3.1,[0],[0]
"+∞, the RHS of (43) is finite, implies that limt→+∞ ||Z(t+ 1)− Z(t)||2J(t+1) = 0 must hold.
",B. Proof of Theorem 3.1,[0],[0]
"By the definition of Z(t), J(t) and ||X||2J = 〈X, JX〉F , the following must hold
lim t→+∞
||f̂(t+ 1)− f̂(t)||2W (t+1)(D+A) = 0",B. Proof of Theorem 3.1,[0],[0]
"(44)
lim t→+∞
||Y (t+ 1)− Y (t)||2F = 0 (45)
(45) shows that Y (t) converges to a stationary point Y s, along with (16) imply limt→+∞ √ D −Af̂(t + 1) = 0.",B. Proof of Theorem 3.1,[0],[0]
"Since Null( √ D −A) = c1, f̂(t+ 1) must lie in the subspace spanned by 1 as t→∞. To satisfy (44), either of the following two statements must hold:
",B. Proof of Theorem 3.1,[0],[0]
• limt→+∞(f̂(t+,B. Proof of Theorem 3.1,[0],[0]
1)− f̂(t)),B. Proof of Theorem 3.1,[0],[0]
"= 0N×d
• limt→+∞W (t+ 1)(D +A)1 = limt→+∞W (t+ 1)A1 + limt→+∞ ∑N i=1",B. Proof of Theorem 3.1,[0],[0]
ηi(t+,B. Proof of Theorem 3.1,[0],[0]
"1)Vi = 0N×1
",B. Proof of Theorem 3.1,[0],[0]
Since ηi(t) ≥,B. Proof of Theorem 3.1,[0],[0]
θ > 0,B. Proof of Theorem 3.1,[0],[0]
"for all t, implies limt→+∞ ∑N i=1",B. Proof of Theorem 3.1,[0],[0]
ηi(t+,B. Proof of Theorem 3.1,[0],[0]
1)Vi > 0.,B. Proof of Theorem 3.1,[0],[0]
The second statement can never be true because all elements of A and W (t+ 1) are non-negative.,B. Proof of Theorem 3.1,[0],[0]
"Hence, f̂(t) should also converge to a stationary point f̂s.
",B. Proof of Theorem 3.1,[0],[0]
"Now show that the stationary point (Y s, f̂s) is (Y ∗, f̂∗).
",B. Proof of Theorem 3.1,[0],[0]
"Take limit of both sides of (15) (16), substitute f̂s, Y s yields
∇Ô(f̂s, Dall) + √ D −AY s",B. Proof of Theorem 3.1,[0],[0]
"+ (W (t+ 1)− θI)(D −A)f̂s = 0N×d (46)
",B. Proof of Theorem 3.1,[0],[0]
"√ D −Af̂s = 0N×d (47)
",B. Proof of Theorem 3.1,[0],[0]
"By (47), (46) turns into: ∇Ô(f̂s, Dall) + √ D −AY s = 0N×d",B. Proof of Theorem 3.1,[0],[0]
"(48)
Compare (47)(48) with (17)(18) in Lemma 3.1 and observe that (Y s, f̂s) satisfies the optimality condition (17)(18) and is thus the optimal point.",B. Proof of Theorem 3.1,[0],[0]
"Therefore, f(t) converges to f̂∗ and Y (t) converges to Y ∗.",B. Proof of Theorem 3.1,[0],[0]
"According to the Assumption 3 that O(fi, Di) is strongly convex and has Lipschitz continues gradients for all i ∈ N , define diagonal matrices Dm = diag([m1;m2; · · · ;mN ]) ∈",C. Proof of Theorem 3.2,[0],[0]
RN×N and DM = diag([M21 ;M22 ; · · · ;M2N ]) ∈,C. Proof of Theorem 3.2,[0],[0]
"RN×N , (20) yield:
〈f̂1 − f̂2,∇Ô(f̂1, Dall)−∇Ô(f̂2, Dall)〉F",C. Proof of Theorem 3.2,[0],[0]
"≥ 〈f̂1 − f̂2, Dm(f̂1",C. Proof of Theorem 3.2,[0],[0]
"− f̂2)〉F (49)
||∇Ô(f̂1, Dall)−∇Ô(f̂2, Dall)||2F ≤ 〈f̂1 − f̂2, DM (f̂1 − f̂2)〉F (50)
",C. Proof of Theorem 3.2,[0],[0]
"Since for any µ > 1 and any matrices C1, C2 with the same dimensions, there is:
||C1 +",C. Proof of Theorem 3.2,[0],[0]
"C2||2F ≤ µ||C1||2F + µ
µ− 1 ||C2||2F
From (34), there is:
||",C. Proof of Theorem 3.2,[0],[0]
"√ D −A(Y (t+ 1)− Y ∗)||2F ≤ µ||∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall) +W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))||2F
+ µ
µ− 1 ||(W (t+ 1)− θI)(D −A)f̂(t+ 1)||2F ≤
µ2
µ− 1 ||∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall)||2F
+µ2||W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))||2F + µ
µ− 1 ||(W (t+ 1)− θI)(D −A)f̂(t+ 1)||2F
(51)
Let σmin(·), σmax(·) denote the smallest nonzero singular value and the largest singular value of a matrix respectively.
",C. Proof of Theorem 3.2,[0],[0]
"For any matrices C1, C2, let C1 = UΣV T be SVD of C1, there is:
||C1C2||2F ≤ σmax(C1)||C2||2CT1
σmin(C1)",C. Proof of Theorem 3.2,[0],[0]
2||C2||2F ≤,C. Proof of Theorem 3.2,[0],[0]
||C1C2||2F ≤,C. Proof of Theorem 3.2,[0],[0]
"σmax(C1)2||C2||2F
Denote σ̄max(t+ 1) = σmax((W (t+ 1)− θI)(D −A))",C. Proof of Theorem 3.2,[0],[0]
"σ̄min(t+ 1) = σmin((W (t+ 1)− θI)(D −A))
",C. Proof of Theorem 3.2,[0],[0]
"σ̃max(t+ 1) = σmax(W (t+ 1)(D +A))
",C. Proof of Theorem 3.2,[0],[0]
"Using (50) and (D −A)f̂∗ = 0, (51) is turned into:
1 θ ||Y (t+ 1)− Y ∗||2F ≤
µ2
θσmin(D −A)(µ− 1) ||f̂(t+ 1)− f̂∗||2DM
+ µ2σ̃max(t+ 1)
θσmin(D −A) ||f̂(t+ 1)− f̂(t)||2W (t+1)(D+A) +
µσ̄max(t+ 1) 2
θσmin(D",C. Proof of Theorem 3.2,[0],[0]
−A)(µ− 1),C. Proof of Theorem 3.2,[0],[0]
"||(f̂(t+ 1)− f̂∗)||2F
Adding ||f̂(t+ 1)− f̂∗||2W (t+1)(D+A) at both sides leads to:
||Z(t+ 1)− Z∗||2J(t+1) ≤ µ2σ̃max(t+ 1)
θσmin(D −A) ||f̂(t+ 1)− f̂(t)||2W (t+1)(D+A)
+||f̂(t+ 1)− f̂∗||2µ2DM+µσ̄max(t+1)2IN θσmin(D−A)(µ−1)",C. Proof of Theorem 3.2,[0],[0]
"+W (t+1)(D+A)
(52)
",C. Proof of Theorem 3.2,[0],[0]
"Since δ(t+ 1)µ2σ̃max(t+ 1)
θσmin(D −A) ≤ 1 (53)
and
δ(t+ 1)( µσ̄max(t+ 1) 2IN + µ2DM θσmin(D −A)(µ− 1)",C. Proof of Theorem 3.2,[0],[0]
+W (t+ 1)(D +A)),C. Proof of Theorem 3.2,[0],[0]
"2(W (t+ 1)− θI)(D −A) + 2Dm (54)
",C. Proof of Theorem 3.2,[0],[0]
"It implies from (52) that:
δ(t+ 1)||Z(t+ 1)− Z∗||2J(t+1) ≤ ||f̂(t+ 1)− f̂(t)||",C. Proof of Theorem 3.2,[0],[0]
"2 W (t+1)(D+A) + ||f̂(t+ 1)− f̂ ∗||22(W (t+1)−θI)(D−A)+2Dm ≤ ||Z(t+ 1)− Z(t)||2J(t+1) + ||f̂(t+ 1)− f̂ ∗||22(W (t+1)−θI)(D−A)+2Dm (55)
",C. Proof of Theorem 3.2,[0],[0]
"Substituting f̂1 with f̂(t+ 1) and f̂2 with f̂∗ and the gradient difference from (34) in (49) leads to:
〈f̂(t+ 1)− f̂∗, √ D −A(Y (t+ 1)− Y ∗)〉F",C. Proof of Theorem 3.2,[0],[0]
"+ 〈f̂(t+ 1)− f̂∗,W (t+ 1)(D +",C. Proof of Theorem 3.2,[0],[0]
"A)(f̂(t+ 1)− f̂(t))〉F
+〈f̂(t+ 1)− f̂∗, (W (t+ 1)− θI)(D −A)f̂(t+ 1)〉F ≤",C. Proof of Theorem 3.2,[0],[0]
"−〈f̂(t+ 1)− f̂∗, Dm(f̂(t+ 1)− f̂∗)〉F
Similar to the proof of Theorem 3.1, using the definition of Z(t+ 1), Z∗, J(t+ 1) and (D −A)f̂∗ = 0, there is:
||Z(t+ 1)− Z∗||2J(t+1) ≤ −||Z(t+",C. Proof of Theorem 3.2,[0],[0]
1)− Z(t)|| 2 J(t+1) + ||Z(t)− Z ∗||2J(t+1),C. Proof of Theorem 3.2,[0],[0]
"− ||f̂(t+ 1)− f̂ ∗||22Dm+2(W (t+1)−θI)(D−A)
(56)
",C. Proof of Theorem 3.2,[0],[0]
"Sum up (55) and (56) gives:
(1 + δ(t+ 1))||Z(t+ 1)− Z∗||2J(t+1) ≤ ||Z(t)−",C. Proof of Theorem 3.2,[0],[0]
"Z ∗||2J(t+1)
",C. Proof of Theorem 3.2,[0],[0]
"Let mo = mini∈N {mi}, MO = maxi∈N {Mi}.",C. Proof of Theorem 3.2,[0],[0]
"One δ(t+ 1) that satisfies (53) and (54) could be:
min{θσmin(D −A) µ2σ̃max(t+",C. Proof of Theorem 3.2,[0],[0]
"1) , 2mo + 2σ̄min(t+ 1) µ2M2O+µσ̄max(t+1) 2
θσmin(D−A)(µ−1) + σ̃max(t+ 1) }",C. Proof of Theorem 3.2,[0],[0]
"In the following proof, use the uppercase letters and lowercase letters to denote random variables and the corresponding realizations.
",D. Proof of Theorem 4.1,[0],[0]
"Since the modified ADMM is randomized, denote Fi(t) as the random variable of the result that node i broadcasts in t-th iteration, of which the realization is fi(t).",D. Proof of Theorem 4.1,[0],[0]
"Define F (t) = {Fi(t)}Ni=1 whose realization is {fi(t)}Ni=1.
",D. Proof of Theorem 4.1,[0],[0]
"Let FF (0:t)(·) be the joint probability distribution of F (0 : t) = {F (r)}tr=0, and FF (t)(·) be the distribution of F (t), by chain rule:
FF (0:T )({f(r)}Tr=0) =",D. Proof of Theorem 4.1,[0],[0]
"FF (0:T−1)({f(r)}T−1r=0 ) ·FF (T )(f(T )|{f(r)} T−1 r=0 ) = · · ·
= FF (0)(f(0)) · T∏ t=1",D. Proof of Theorem 4.1,[0],[0]
"FF (t)(f(t)|{f(r)}t−1r=0)
For two neighboring datasets Dall and D̂all of the network, the ratio of joint probabilities is given by:
FF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D̂all) =",D. Proof of Theorem 4.1,[0],[0]
FF (0)(f(0)|Dall) FF (0)(f(0)|D̂all) · T∏ t=1,D. Proof of Theorem 4.1,[0],[0]
"FF (t)(f(t)|{f(r)}t−1r=0, Dall) FF (t)(f(t)|{f(r)}t−1r=0, D̂all)
(57)
Since fi(0) is randomly selected for all i, which is independent of dataset, there is FF (0)(f(0)|Dall) =",D. Proof of Theorem 4.1,[0],[0]
"FF (0)(f(0)|D̂all).
",D. Proof of Theorem 4.1,[0],[0]
"First only consider t-th iteration, since the primal variable is updated according to (25), by KKT optimality condition, ∇fiL priv i (t)|fi=fi(t) = 0, implies:
i(t) =",D. Proof of Theorem 4.1,[0],[0]
"− 1
2ηi(t)Vi
C
Bi Bi∑ n=1 yni L ′(yni fi(t)",D. Proof of Theorem 4.1,[0],[0]
Txni )x n,D. Proof of Theorem 4.1,[0],[0]
"i −
1 2ηi(t)Vi ( ρ N ∇R(fi(t))",D. Proof of Theorem 4.1,[0],[0]
"+ 2λi(t− 1))
",D. Proof of Theorem 4.1,[0],[0]
− 1 2Vi ∑ j∈Vi (2fi(t)− fi(t− 1)− fj(t− 1)),D. Proof of Theorem 4.1,[0],[0]
"(58)
",D. Proof of Theorem 4.1,[0],[0]
"Given {fi(r)}t−1r=0, Fi(t) and Ei(t) will be bijective:
• For any Fi(t) with the realization fi(t), ∃ an unique Ei(t) = i(t) having the form of (58) such that the KKT condition holds.
",D. Proof of Theorem 4.1,[0],[0]
"• Since the Lagrangian Lprivi (t) is strictly convex (by Assumption 4,5), its minimizer is unique, implies that for any Ei(t) with the realization i(t), ∃ an unique Fi(t) = fi(t) such that the KKT condition holds.
",D. Proof of Theorem 4.1,[0],[0]
"Since each node i generates i(t) independently, fi(t) is also independent from each other.",D. Proof of Theorem 4.1,[0],[0]
"Let FFi(t)(·) be the distribution of Fi(t), there is:
FF (t)(f(t)|{f(r)}t−1r=0, Dall) FF (t)(f(t)|{f(r)}t−1r=0, D̂all) = N∏ v=1 FFv(t)(fv(t)|{fv(r)} t−1 r=0, Dv) FFv(t)(fv(t)|{fv(r)} t−1 r=0, D̂v) = FFi(t)(fi(t)|{fi(r)}",D. Proof of Theorem 4.1,[0],[0]
"t−1 r=0, Di) FFi(t)(fi(t)|{fi(r)} t−1 r=0, D̂i)
(59)
",D. Proof of Theorem 4.1,[0],[0]
"Since two neighboring datasets Dall and D̂all only have at most one data point that is different, the second equality holds is because of the fact that this different data point could only be possessed by one node, say node i.",D. Proof of Theorem 4.1,[0],[0]
"Then there is Dj = D̂j for j 6= i.
",D. Proof of Theorem 4.1,[0],[0]
"Given {fi(r)}t−1r=0, let gt(·, Di) :",D. Proof of Theorem 4.1,[0],[0]
Rd → Rd denote the one-to-one mapping from Ei(t) to Fi(t) using dataset Di.,D. Proof of Theorem 4.1,[0],[0]
"Let FEi(t)(·) be the probability density of Ei(t), by Jacobian transformation, there is4:
FFi(t)(fi(t)|Di)",D. Proof of Theorem 4.1,[0],[0]
"= FEi(t)(g −1 t (fi(t), Di)) ·",D. Proof of Theorem 4.1,[0],[0]
"| det(J(g−1t (fi(t), Di)))| (60)
where g−1t (fi(t), Di) is the mapping from Fi(t) to Ei(t) using data Di as shown in (58) and J(g −1 t (fi(t), Di)) is the Jacobian matrix of it.
",D. Proof of Theorem 4.1,[0],[0]
"Without loss of generality, let Di and D̂i be only different in the first data point, say (x1i , y 1 i ) and (x̂ 1",D. Proof of Theorem 4.1,[0],[0]
"i , ŷ 1 i ) respectively.",D. Proof of Theorem 4.1,[0],[0]
"Then by (59)(60), (57) yields:
FF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D̂all) = T∏ t=1 FEi(t)(g −1 t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), D̂i)) ·",D. Proof of Theorem 4.1,[0],[0]
"T∏ t=1 |det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))|
(61)
4We believe that there is a critical mistake in (Zhang & Zhu, 2017) and the original paper (Chaudhuri et al., 2011) where the objective perturbation method was proposed.",D. Proof of Theorem 4.1,[0],[0]
"A wrong mapping is used in both work:
FFi(t)(fi(t)|Di) = FEi(t)(g −1 t (fi(t), Di)) ·",D. Proof of Theorem 4.1,[0],[0]
"| det(J(g−1t (fi(t), Di)))|−1
Consider the first part, Ei(t) ∼ exp{−αi(t)|| ||}, let ̂i(t) = g−1t (fi(t), D̂i) and i(t) =",D. Proof of Theorem 4.1,[0],[0]
"g−1t (fi(t), Di)
T∏ t=1",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), D̂i))",D. Proof of Theorem 4.1,[0],[0]
= T∏ t=1,D. Proof of Theorem 4.1,[0],[0]
exp(αi(t)(||̂i(t)||,D. Proof of Theorem 4.1,[0],[0]
− || i(t)||)),D. Proof of Theorem 4.1,[0],[0]
"≤ exp( T∑ t=1 αi(t)||̂i(t)− i(t)||) (62)
",D. Proof of Theorem 4.1,[0],[0]
"By (58), Assumptions 4 and the facts that ||xni ||2 ≤ 1 (pre-normalization), yni ∈ {+1,−1}.
",D. Proof of Theorem 4.1,[0],[0]
"||̂i(t)− i(t)|| = 1
2ηi(t)Vi
C Bi · ||y1iL ′(y1i fi(t)Tx1i )",D. Proof of Theorem 4.1,[0],[0]
x1i,D. Proof of Theorem 4.1,[0],[0]
− ŷ1iL ′(ŷ1i fi(t)T x̂1i ),D. Proof of Theorem 4.1,[0],[0]
"x̂1i || ≤
C
ηi(t)ViBi
(62) can be bounded: T∏ t=1 FEi(t)(g −1 t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), D̂i))",D. Proof of Theorem 4.1,[0],[0]
"≤ exp( T∑ t=1 Cαi(t) ηi(t)ViBi ) (63)
Consider the second part, the Jacobian matrix J(g−1t (fi(t), Di)) is:
J(g−1t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
=,D. Proof of Theorem 4.1,[0],[0]
"− 1
2ηi(t)Vi
C
Bi Bi∑ n=1 L ′′(yni fi(t)",D. Proof of Theorem 4.1,[0],[0]
Txni )x n,D. Proof of Theorem 4.1,[0],[0]
i (x n i ) T,D. Proof of Theorem 4.1,[0],[0]
− 1 2ηi(t)Vi ρ N ∇2R(fi(t))−,D. Proof of Theorem 4.1,[0],[0]
"Id
Let G(t) =",D. Proof of Theorem 4.1,[0],[0]
C2ηi(t)ViBi (L ′′(ŷ1i fi(t) T x̂1i )x̂ 1,D. Proof of Theorem 4.1,[0],[0]
i (x̂ 1 i ) T −L ′′(y1i fi(t)Tx1i ),D. Proof of Theorem 4.1,[0],[0]
x1i (x1i )T ) and H(t) =,D. Proof of Theorem 4.1,[0],[0]
"−J(g −1 t (fi(t), Di)), there is:
|det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))| = |det(H(t))| |det(H(t) +G(t))| =
1
|det(I +H(t)−1G(t))| =
1 | ∏r j=1(1 + λj(H(t) −1G(t)))|
where λj(H(t)−1G(t)) denotes the j-th largest eigenvalue of H(t)−1G(t).",D. Proof of Theorem 4.1,[0],[0]
"Since G(t) has rank at most 2, implies H(t)−1G(t) also has rank at most 2.
",D. Proof of Theorem 4.1,[0],[0]
"Because θ is determined such that 2c1 < BiC ( ρ N + 2θVi), and θ ≤ ηi(t) holds for all node i and iteration t, which implies:
c1 Bi C ( ρ N + 2ηi(t)Vi)",D. Proof of Theorem 4.1,[0],[0]
"< 1 2 (64)
",D. Proof of Theorem 4.1,[0],[0]
"By Assumptions 4 and 5, the eigenvalue of H(t) and G(t) satisfy:
λj(H(t))",D. Proof of Theorem 4.1,[0],[0]
"≥ ρ
2ηi(t)ViN + 1 > 0
",D. Proof of Theorem 4.1,[0],[0]
− Cc1 2ηi(t)ViBi ≤,D. Proof of Theorem 4.1,[0],[0]
λj(G(t)),D. Proof of Theorem 4.1,[0],[0]
"≤ Cc1 2ηi(t)ViBi
",D. Proof of Theorem 4.1,[0],[0]
"Implies:
− c1 Bi C ( ρ N + 2ηi(t)Vi)",D. Proof of Theorem 4.1,[0],[0]
≤ λj(H(t)−1G(t)),D. Proof of Theorem 4.1,[0],[0]
"≤ c1 Bi C ( ρ N + 2ηi(t)Vi)
",D. Proof of Theorem 4.1,[0],[0]
"By (64):
−1 2 ≤ λj(H(t)−1G(t))",D. Proof of Theorem 4.1,[0],[0]
"≤ 1 2
Since λmin(H(t)−1G(t))",D. Proof of Theorem 4.1,[0],[0]
"> −1, there is:
1 |1 + λmax(H(t)−1G(t))|2",D. Proof of Theorem 4.1,[0],[0]
"≤ 1 |det(I +H(t)−1G(t))| ≤ 1 |1 + λmin(H(t)−1G(t))|2
Therefore,
T∏ t=1 |det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))| ≤",D. Proof of Theorem 4.1,[0],[0]
"T∏ t=1
1
|1− c1Bi",D. Proof of Theorem 4.1,[0],[0]
"C ( ρ N +2ηi(t)Vi)
|2 = exp(− T∑ t=1 2 ln(1− c1 Bi C",D. Proof of Theorem 4.1,[0],[0]
( ρ N + 2ηi(t)Vi) )),D. Proof of Theorem 4.1,[0],[0]
"(65)
Since for any real number x ∈",D. Proof of Theorem 4.1,[0],[0]
"[0, 0.5], − ln(1 − x) < 1.4x.",D. Proof of Theorem 4.1,[0],[0]
"By condition (64), (65) can be bounded with a simper expression:
T∏ t=1 |det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))| ≤ exp",D. Proof of Theorem 4.1,[0],[0]
( T∑ t=1 2.8c1 Bi C ( ρ N + 2ηi(t)Vi) ),D. Proof of Theorem 4.1,[0],[0]
≤ exp( T∑ t=1 1.4Cc1 ηi(t)ViBi ),D. Proof of Theorem 4.1,[0],[0]
"(66)
Combine (63)(66), (61) can be bounded:
FF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D̂all) ≤ exp( T∑ t=1 ( 1.4Cc1 ηi(t)ViBi + Cαi(t) ηi(t)ViBi ))",D. Proof of Theorem 4.1,[0],[0]
"= exp( T∑ t=1
C
ηi(t)ViBi (1.4c1 + αi(t)))
",D. Proof of Theorem 4.1,[0],[0]
"Therefore, the total privacy loss during T iterations can be bounded by any β:
β ≥ max i∈N { T∑ t=1
C
ηi(t)ViBi (1.4c1 + αi(t))}
E. Inference of Attackers when ηi(t) is Non-private By KKT optimality condition in each iteration, we have:
i(t) +",D. Proof of Theorem 4.1,[0],[0]
"1
2ηi(t)Vi
C Bi y1iL ′(y1i fi(t) Tx1i )",D. Proof of Theorem 4.1,[0],[0]
x 1,D. Proof of Theorem 4.1,[0],[0]
"i = −
1
2ηi(t)Vi
C
Bi",D. Proof of Theorem 4.1,[0],[0]
Bi∑ n=2 yni L ′(yni fi(t),D. Proof of Theorem 4.1,[0],[0]
Txni )x n,D. Proof of Theorem 4.1,[0],[0]
"i
− 1 2ηi(t)Vi ( ρ N ∇R(fi(t))",D. Proof of Theorem 4.1,[0],[0]
+,D. Proof of Theorem 4.1,[0],[0]
"2λi(t− 1))− 1 2Vi ∑ j∈Vi (2fi(t)− fi(t− 1)− fj(t− 1)) .
",D. Proof of Theorem 4.1,[0],[0]
In this case the attacker can compute the RHS of (67) completely.,D. Proof of Theorem 4.1,[0],[0]
"Furthermore, since Ei(t) is zero-mean, over a large number of iterations we will have 1T ∑T t=1 i(t)",D. Proof of Theorem 4.1,[0],[0]
"≈ 0 with high probability, which then allows the attacker to determine the features of the unknown individual up to a scaling factor, i.e., it can determine the second term on the LHS as a scalar multiplied with x1i .",D. Proof of Theorem 4.1,[0],[0]
"Alternating direction method of multiplier (ADMM) is a popular method used to design distributed versions of a machine learning algorithm, whereby local computations are performed on local data with the output exchanged among neighbors in an iterative fashion.",abstractText,[0],[0]
During this iterative process the leakage of data privacy arises.,abstractText,[0],[0]
"A differentially private ADMM was proposed in prior work (Zhang & Zhu, 2017) where only the privacy loss of a single node during one iteration was bounded, a method that makes it difficult to balance the tradeoff between the utility attained through distributed computation and privacy guarantees when considering the total privacy loss of all nodes over the entire iterative process.",abstractText,[0],[0]
We propose a perturbation method for ADMM where the perturbed term is correlated with the penalty parameters; this is shown to improve the utility and privacy simultaneously.,abstractText,[0],[0]
The method is based on a modified ADMM where each node independently determines its own penalty parameter in every iteration and decouples it from the dual updating step size.,abstractText,[0],[0]
The condition for convergence of the modified ADMM and the lower bound on the convergence rate are also derived.,abstractText,[0],[0]
Improving the Privacy and Accuracy of ADMM-Based Distributed Algorithms ,title,[0],[0]

0	23	The analysis of emotions in texts is an important task in NLP.
1	12	Traditional studies treat this task as a pipeline of two separated sub-tasks: emotion classification and emotion cause detection.
2	13	The former identifies the category of an emotion and the latter detects the cause of an emotion.
3	31	This separated framework makes each sub-task more flexible to deal with, but it neglects the relevance between the two sub-tasks.
5	27	To the best of our knowledge, this work is the first attempt to incorporate both emotion classification and emotion cause detection into a unified framework.
6	16	Although emotion classification relies on affective features and emotion cause detection needs event-based features, we propose a joint encoder which uses a unified framework to ex- tract features for both emotion classification instances and emotion cause detection instances.
9	15	In this paper, we use the human-labeled emotion corpus provided by Cheng et al. (2017) as our experimental data (namely Cheng emotion corpus).
11	9	Cheng emotion corpus can be considered as a collection of subtweets.
12	21	For each emotion in a subtweet, all emotion keywords expressing the emotion are selected, and then the class and the cause of the emotion are annotated.
13	12	The emotion categorization used in Huang et al. (2016) is adopted, which includes four basic emotions (i.e., joy, angry, sad and fearful) and three complex emotions (i.e., positive, neutral and negative).
15	10	In this paper, both the emotion classification subtask (namely EClass) and the emotion cause detection sub-task (namely ECause) are clauselevel.
16	13	Given an instance which is a clause in a subtweet, EClass assigns one of seven labels (i.e. six emotion classes and label ‘non-emotion’ which indicates the absence of an emotion) to the instance.
21	7	The previous clause and the following clause provide contextual information for the current clause.
25	20	2, there are two parts in our joint approach which is based on neural networks: a joint encoder (the lower part) which extracts feature representations for both EClass instances and ECause instances, and a linear decoder (the upper part) which assigns labels to instances according to their representations.
30	10	1) and the LSTM network to extract event-based features (e.g. “I found that only I was at home again” in Fig.
36	16	2, there are two sub-encoders in our joint encoder: Encoder EClass (the left part) which provides a representation for an EClass instance, and Encoder ECause (the right part) which extracts a representation for an ECause instance.
38	17	Then, the concatenation of the two representations serves as the final representation for the instance (i.e. hEClass or hECause in Fig.2).
41	10	In order to effectively use these input sequences, a multi-channel structure is chosen, which encodes the input sequences one by one.
52	21	In other words, gradient calculation is disabled along the dashed lines in Fig.
63	20	The two models (JMEClass and JMECause) which are learned by our joint approach are compared with several pipeline models which are learned in a pipeline manner (i.e. either for EClass or for ECause) using one of the following state-of-the-art encoders.
64	7	ATT: the attention network in Fig.2 .
66	9	ATT+LSTM: an hybrid encoder for emotion classification, which applies ATT to CurCL and LSTM to PrevCL and FolCL.
68	12	Table 2 shows the performances of different emotion classification models, where “Sequence” lists the sequences of input words used by each model and each metric is the average performances of six emotion classes.
78	16	Finally, taking the advantage of the event-based features extracted by JMECause, JMEClass out-performs the best pipeline model (ATT+LSTM) by 0.7% in F-scores.
82	6	This indicates that difference in performance is likely linked to differences in the emotional contents of labels rather than differences in data sizes.
89	6	In Table 4, JMECause outperforms the best pipeline model (LSTM) by 0.8% in F-scores.
91	9	Furthermore, the performance improvement of JMECause is from the significant increasing in recalls (5.4%).
93	7	Moreover, among all models, the two models (ATT and LSTM) achieve relatively high precision and relatively low recall, and ConvMS-Memnet obtains the lowest precision and highest recall.
94	18	This means that both ATT and LSTM suffer from the feature coverage problem because some useful features cannot be extracted through their encoders, and ConvMS-Memn suffers from the feature quality problem maybe because its encoder cannot handle the informal writing style used in Chinese microblogs.
99	27	In this paper, we focus on a joint learning approach to emotion classification and emotion cause detection on Chinese microblogs, and the experiments show such a joint approach is very promising.

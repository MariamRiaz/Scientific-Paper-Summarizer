3	13	A popular solution is to go beyond stand-alone unsupervised learning and fine-tune distributional vector spaces by using external knowledge from human- or automaticallyconstructed knowledge bases.
4	24	This is often done as a post-processing step, where distributional vectors are gradually refined to satisfy linguistic constraints extracted from lexical resources such as WordNet (Faruqui et al., 2015; Mrkšić et al., 2016), the Paraphrase Database (PPDB) (Wieting et al., 2015), or BabelNet (Mrkšić et al., 2017; Vulić et al., 2017a).
6	114	A key property of these methods is their ability to transform the vector space by specialising it for a particular relationship between words.1 Prior work has predominantly focused on distinguishing between semantic similarity and conceptual relatedness (Faruqui et al., 2015; Mrkšić et al., 2017; Vulić et al., 2017b).
7	70	In this paper, we introduce a novel post-processing model which specialises vector spaces for the lexical entailment (LE) relation.
11	8	Our novel LE specialisation model, termed LEAR (Lexical Entailment Attract-Repel), is inspired by ATTRACT-REPEL, a state-of-the-art general spe- 1134 and −→ dog or −→ dog and −−−−→ animal); and 2) by imposing an LE ordering using vector norms, adjusting them so that higher-level concepts have larger norms (e.g., |−−−−→animal| > |−→dog| > |−−−−→terrier|).
12	123	cialisation framework (Mrkšić et al., 2017).2 The key idea of LEAR, illustrated by Figure 1, is to pull desirable (ATTRACT) examples described by the constraints closer together, while at the same time pushing undesirable (REPEL) word pairs away from each other.
13	84	Concurrently, LEAR (re-)arranges vector norms so that norm values in the Euclidean space reflect the hierarchical organisation of concepts according to the given LE constraints: put simply, higher-level concepts are assigned larger norms.
14	10	Therefore, LEAR simultaneously captures the hierarchy of concepts (through vector norms) and their similarity (through their cosine distance).
15	11	The two pivotal pieces of information are combined into an asymmetric distance measure which quantifies the LE strength in the specialised space.
17	48	Our specialised vectors yield notable improvements over the strongest baselines for each task, with each input space, demonstrating the effectiveness and robustness of LEAR specialisation.
21	26	The code for the LEAR model is available from: github.com/nmrksic/lear.
22	31	Let V be the vocabulary, A the set of ATTRACT word pairs (e.g., intelligent and brilliant), and R the set of REPEL word pairs (e.g., vacant and occupied).
27	13	, (t k1 l , t k1 r )] and TR = [(t1l , t 1 r), .
39	15	Unlike symmetric similarity, lexical entailment is an asymmetric relation which encodes a hierarchical ordering between concepts.
43	21	This is potentially problematic, as this distance does not impose a limit on the vectors’ norms.
46	49	This means that the cost function no longer has the incentive to increase word vectors’ norms past a certain point, as the magnitudes of norm ratios grow in size much faster than the linear relation defined by the first distance function.
55	8	This decoding function combines the symmetric and the asymmetric cost term, in line with the combination of the two used to perform LEAR specialisation.
56	11	In the evaluation, we show that combining the two cost terms has a synergistic effect, with both terms contributing to stronger performance across all LE tasks used for evaluation.
57	51	Starting Distributional Vectors To test the robustness of LEAR specialisation, we experiment with a variety of well-known, publicly available English word vectors: 1) Skip-Gram with Negative Sampling (SGNS) (Mikolov et al., 2013) trained on the Polyglot Wikipedia (Al-Rfou et al., 2013) by Levy and Goldberg (2014); 2) GLOVE Common Crawl (Pennington et al., 2014); 3) CONTEXT2VEC (Melamud et al., 2016), which replaces CBOW contexts with contexts based on bidirectional LSTMs (Hochreiter and Schmidhuber, 1997); and 4) FASTTEXT (Bojanowski et al., 2017), a SGNS variant which builds word vectors as the sum of their constituent character n-gram vectors.3 Linguistic Constraints We use three groups of linguistic constraints in the LEAR specialisation model, covering three different relation types which are all beneficial to the specialisation process: directed 1) lexical entailment (LE) pairs; 2) synonymy pairs; and 3) antonymy pairs.
60	17	In total, we work with 1,023,082 synonymy pairs (11.7 synonyms per word on average) and 380,873 antonymy pairs (6.5 per word).5 As in prior work (Nguyen et al., 2017; Nickel and Kiela, 2017), LE constraints are extracted from the WordNet hierarchy, relying on the transitivity of the LE relation.
64	14	The models are trained for 5 epochs with the AdaGrad algorithm (Duchi et al., 2011), with batch sizes set to k1 = k2 = k3 = 128 for faster convergence.
67	32	The tasks are evaluated on three datasets used extensively in the LE literature (Roller et al., 2014; Santus et al., 2014; Weeds et al., 2014; Shwartz et al., 2017; Nguyen et al., 2017), compiled into an integrated evaluation set by Kiela et al. (2015b).7 The first task, LE directionality, is conducted on 1,337 LE pairs originating from the BLESS evaluation set (Baroni and Lenci, 2011).
69	53	With LEAR-specialised vectors this is achieved by simply comparing the vector norms of each concept in a pair: the one with the larger norm is the hypernym (see Figure 1).
70	52	The second task, LE detection, involves a binary classification on the WBLESS dataset (Weeds et al., 2014) which comprises 1,668 word pairs standing in a variety of relations (LE, meronymy-holonymy, co-hyponymy, reversed LE, no relation).
77	12	Results and Analysis The original paper of Kiela et al. (2015b) reports the following best scores on each task: 0.88 (BLESS), 0.75 (WBLESS), 0.57 (BIBLESS).
78	62	These scores were recently surpassed by Nguyen et al. (2017), who, instead of post-processing, combine WordNet-based constraints with an SGNS-style objective into a joint model.
79	84	They report the best scores to date: 0.92 (BLESS), 0.87 (WBLESS), and 0.81 (BIBLESS).
84	73	The results show that the two LEAR variants which do not rely on absolute norm values and perform a normalisation step in the asymmetric distance (D2 and D3) have an edge over the D1 variant which operates with unbounded norms.
85	202	The difference in performance between D2/D3 and D1 is even more pronounced in the graded LE task (see Section 4.2).
90	31	Moreover, we have conducted a small experiment to verify that the LEAR method can generalise beyond what is directly coded in pairwise external constraints.

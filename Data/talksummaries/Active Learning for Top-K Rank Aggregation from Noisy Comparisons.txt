8	52	This enables us to select comparison pairs of items in an adaptive manner.
9	11	This way of ranking provides the potential to reduce a large number of blindly collected measurements while maintaining a ranking accuracy (Tschopp et al., 2011).
10	33	This motivates us to examine an adaptive measurement setting, in which pairwise comparisons are gathered interacting with a ranker (termed active ranking).
11	13	In particular, we intend to address the following two questions: (a) how much can active ranking offer performance improvements over passive ranking?
12	35	(b) how does the limit on the sample size for top-K ranking scale with K?
13	51	To answer this question, we consider a general model in which the pairwise comparison probabilities are arbitrary subject to a mild condition (see (5) in Section 2 for details) and thus which includes as special cases various models like the BTL model, Strong Stochastic Transitivity (SST) model (Fishburn, 1973; Shah et al., 2016), and uniform noise model (Braverman & Mossel, 2008).
16	85	The first lies in deriving an upper bound on the sample size: O ( (n+K logK) max(log log n, logK) ∆K ) (1) where1 ∆K = { ∆K,S = min i∈[K] min j:j≥i (Pij−0.5)2, Sorting; ∆K,P = (PK,K+1−0.5)2, Partitioning.
17	111	(2) Here Pij = Pi,j indicates the probability of item i being preferred over item j, and ∆K,S (or ∆K,P) denotes the parameter w.r.t.
18	15	top-K sorting (or partitioning).
19	29	Without loss of generality, we assume that the ground truth ranking is the order of 1 2 · · · n. Notice that the sample complexity bound reads O(n log log n/∆K) for the small K regime (e.g, K = O(log n)), and O(K log2K/∆K) for the large K regime (e.g., K = Θ(n)).
20	20	For the regime K = O(log n) of practical interest, this exhibits significant multiplicative gains of active ranking over passive ranking.
21	55	For instance, in the case of top-K sorting, when specializing our result into the uniform noise model and BTL model, one can demonstrate that the factor gains are Ω ( n2 logn log logn ) and Ω ( logn log logn ) , respectively.
24	19	The algorithm is based on standard algorithms in TCS literature for the noiseless sorting and partitioning, where each pairwise order can be retrieved using a single comparison or the transitive property of the ranking.
29	48	The main idea of identifying top-K items in a dataset of n items is to partition the set of n items into K subsets, and then identify the top item in each subset using single-elimination tournament.
31	15	After that, this item is removed from the system and the max-HEAP is updated by replacing it by the second top item of the subset this top item belongs to.
43	29	Interesingly, for the K = 1 case and under the uniform noise model, their algorithm can achieve the same sample complexity as ours for a certain target error rate.
104	13	See Section 5 for experimental results on this.
111	19	For general K, it is nearly linear in n, i.e., O(n+K logK).
135	14	In each layer items are paired in a ran- Algorithm 1 SELECT(X;m) Input: m Data: X = {x[1], x[2], .
137	16	(Assume |X| is a power of 2 for simplicity) n← |X| for i← 1 to |X| do a(i)← i end for for `← 1 to log n do for i← 1 to n/2` do T ← 0 for t← 1 to m do et ← (a(2i− 1), a(2i)) T ← T + Yt (Yt is defined in Eq.
157	67	The proposed algorithm is built based on the single-elimination algorithm, which can find the the single top item with high probability.
158	36	A trivial generalization is to repeat the SELECT algorithm for K times, which requires a large number of comparisons Algorithm 2 TOP(X;K,m) Input: Integers K and m Data: Array X = {x[1], x[2], .
161	17	Rather, we first split the dataset X of n items into K groups each of size n/K, namely groups C1, C2, .
165	77	Once the top item of the short list is identified and removed from the list, we go back to its home sub-group, identify the second top item in that sub-group, and insert it to the short list.
166	19	We maintain the HEAP structure of the short list during the process, to be able to easily extract the next top item of the list.
168	31	The main algorithm, TOP is presented in Algorithm 2.
170	17	Sample complexity: The sample complexity of the algorithm can be simply evaluated in terms of the input parameters as follows.
172	12	Later, during the iterative phase of the algorithm, we need to repeat SELECT algorithm on the remaining elements of sub-groups for another K iterations, which results in 2K runs of SELECT, each on subgroups of size at most n/K items.
180	21	Plugging this into (18), we can find the sample complexity of the TOP algorithm as SK = O ( (n+K logK) max{logK, log log n} ∆K ) .
184	14	We (randomly) split the items into K groups, and run the single-elimination tournament in each group.

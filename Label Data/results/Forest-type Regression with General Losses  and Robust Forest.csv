0,1,label2,summary_sentences
"Recently, deep learning has emerged as a powerful and popular class of machine learning algorithms.",1. Introduction,[0],[0]
"Well-known examples include the convolutional neural network (LeCun et al., 1998), long short term memory (Hochreiter & Schmidhuber, 1997), memory network (Weston et al., 2014), and deep Q-network (Mnih et al., 2015).",1. Introduction,[0],[0]
"These models have achieved remarkable performance on various difficult tasks such as image classification (He et al., 2016), speech recognition (Graves et al., 2013), natural language understanding (Bahdanau et al., 2015; Sukhbaatar et al., 2015), and game playing (Silver et al., 2016).
",1. Introduction,[0],[0]
"Deep network is a highly nonlinear model with typically millions of parameters (Hinton et al., 2006).",1. Introduction,[0],[0]
"Thus, it is imperative to design scalable and effective solvers.",1. Introduction,[0],[0]
"How-
",1. Introduction,[0],[0]
"1Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong.",1. Introduction,[0],[0]
"Correspondence to: Shuai Zheng <szhengac@cse.ust.hk>, James T. Kwok <jamesk@cse.ust.hk>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
ever, training deep networks is difficult as the optimization can suffer from pathological curvature and get stuck in local minima (Martens, 2010).",1. Introduction,[0],[0]
"Moreover, every critical point that is not a global minimum is a saddle point (Kawaguchi, 2016), which can significantly slow down training.",1. Introduction,[0],[0]
Second-order information is useful in that it reflects local curvature of the error surface.,1. Introduction,[0],[0]
"However, a direct computation of the Hessian is computationally infeasible.",1. Introduction,[0],[0]
"Martens (2010) introduced Hessian-free optimization, a variant of truncated-Newton methods that relies on using the linear conjugate gradient to avoid computing the Hessian.",1. Introduction,[0],[0]
Dauphin et al. (2014) proposed to use the absolute Hessian to escape from saddle points.,1. Introduction,[0],[0]
"However, these methods still require higher computational costs.
",1. Introduction,[0],[0]
"Recent advances in deep learning optimization focus mainly on stochastic gradient descent (SGD) (Bottou, 1998) and its variants (Sutskever et al., 2013).",1. Introduction,[0],[0]
"However, SGD requires careful stepsize tuning, which is difficult as different weights have vastly different gradients (in terms of both magnitude and direction).",1. Introduction,[0],[0]
"On the other hand, online learning (Zinkevich, 2003), which is closely related to stochastic optimization, has been extensively studied in the past decade.",1. Introduction,[0],[0]
"Well-known algorithms include follow the regularized leader (FTRL) (Kalai & Vempala, 2005), follow the proximally-regularized leader (FTPRL) (McMahan & Streeter, 2010) and their variants (Duchi & Singer, 2009; Duchi et al., 2011; Shalev-Shwartz, 2012; Xiao, 2010).",1. Introduction,[0],[0]
"In particular, adaptive gradient descent (Adagrad) (Duchi et al., 2011) uses an adaptive per-coordinate stepsize.",1. Introduction,[0],[0]
"On convex problems, it has been shown both theoretically and empirically that Adagrad is especially efficient on highdimensional data (Duchi et al., 2011; McMahan et al., 2013).",1. Introduction,[0],[0]
"When used on deep networks, Adagrad also demonstrates significantly better performance than SGD (Dean et al., 2012).",1. Introduction,[0],[0]
"However, in Adagrad, the variance estimate underlying the adaptive stepsize is based on accumulating all past (squared) gradients.",1. Introduction,[0],[0]
This becomes infinitesimally small as training proceeds.,1. Introduction,[0],[0]
"In more recent algorithms, such as RMSprop (Tieleman & Hinton, 2012) and Adam (Kingma & Ba, 2015), the variance is estimated by an exponentially decaying average of the squared gradients.
",1. Introduction,[0],[0]
"Another problem with the FTRL family of algorithms is that in each round, the learner has to solve an optimization problem that considers the sum of all previous gradients.
",1. Introduction,[0],[0]
"For highly nonconvex models such as the deep network, the parameter iterate may move from one local basin to another.",1. Introduction,[0],[0]
Gradients that are due to samples in the distant past are less informative than those from the recent ones.,1. Introduction,[0],[0]
"In applications where the data distribution is changing (as in deep reinforcement learning), this may impede parameter adaptation to the environment.
",1. Introduction,[0],[0]
"To alleviate this problem, we propose a FTPRL variant that reweighs the learning subproblems in each iteration.",1. Introduction,[0],[0]
"The proposed algorithm, which will be called follow the moving leader (FTML), shows strong connections with popular deep learning optimizers such as RMSprop and Adam.",1. Introduction,[0],[0]
"Experiments on various deep learning models demonstrate that FTML outperforms or at least has comparable convergence performance with state-of-the-art solvers.
",1. Introduction,[0],[0]
The rest of this paper is organized as follows.,1. Introduction,[0],[0]
Section 2 first gives a brief review on FTRL and other solvers for deep learning.,1. Introduction,[0],[0]
Section 3 presents the proposed FTML.,1. Introduction,[0],[0]
"Experimental results are shown in Section 4, and the last section gives some concluding remarks.
Notation.",1. Introduction,[0],[0]
"For a vector x ∈ Rd, ‖x‖ = √∑d
i=1",1. Introduction,[0],[0]
"x 2 i ,
diag(x) is a diagonal matrix with x on its diagonal, √ x is the element-wise square root of x, x2 denotes the Hadamard (elementwise) product x x, and ‖x‖2Q = xTQx, whereQ is a symmetric matrix.",1. Introduction,[0],[0]
"For any two vectors x and y, x/y, and 〈x, y〉 denote the elementwise division and dot product, respectively.",1. Introduction,[0],[0]
"For a matrix X , X2 = XX , and diag(X) is a vector with the diagonal of X as its elements.",1. Introduction,[0],[0]
"For t vectors {x1, . . .",1. Introduction,[0],[0]
", xt}, x1:",1. Introduction,[0],[0]
t = ∑t i=1,1. Introduction,[0],[0]
"xi, and
x21:",1. Introduction,[0],[0]
t = ∑t i=1,1. Introduction,[0],[0]
"x
2 i .",1. Introduction,[0],[0]
"For t matrices {X1, . . .",1. Introduction,[0],[0]
", Xt}, X1:t =∑t
i=1Xi.",1. Introduction,[0],[0]
"In online learning, the learner observes a sequence of functions fi’s, which can be deterministic, stochastic, or even adversarially chosen.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
Let Θ ⊆ Rd be a convex compact set.,2.1. Follow the Regularized Leader and its Variants,[0],[0]
"At round t, the learner picks a predictor θt−1 ∈ Θ, and the adversary picks a loss ft.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
The learner then suffers a loss ft(θt−1).,2.1. Follow the Regularized Leader and its Variants,[0],[0]
The goal of the learner is to minimize the cumulative loss suffered over the course of T rounds.,2.1. Follow the Regularized Leader and its Variants,[0],[0]
"In online convex learning, ft is assumed to be convex.
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Two popular online learning algorithms are the follow the regularized leader (FTRL) (Kalai & Vempala, 2005; Shalev-Shwartz, 2012), and its variant follow the proximally-regularized leader (FTPRL) (McMahan & Streeter, 2010).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Both achieve the optimal O( √ T ) regret, where T is the number of rounds (Shalev-Shwartz, 2012).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Other FTRL-like algorithms include regularized dual aver-
aging (RDA) (Xiao, 2010) as well as its adaptive variant presented in (Duchi et al., 2011).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"Gradient descent style algorithms like online forward and backward splitting (FOBOS) (Duchi & Singer, 2009) and adaptive gradient descent (Adagrad) (Duchi et al., 2011) can also be expressed as special cases of the FTRL family (McMahan, 2011).
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"At round t, FTRL generates the next iterate θt by solving the optimization problem:
θt = arg min θ∈Θ t∑ i=1",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"( 〈gi, θ〉+ αt 2 ‖θ‖2 ) ,
where gt is a subgradient of ft at θt−1 (usually, θ0 = 0), and αt is the regularization parameter at round t. Note that the regularization is centered at the origin.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"McMahan & Streeter (2010) generalizes this to FTPRL by centering regularization at each iterate θi−1 as in online gradient descent and online mirror descent (Cesa-Bianchi & Lugosi, 2006),
θt = arg min θ∈Θ t∑ i=1",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"( 〈gi, θ〉+ 1 2 ‖θ − θi−1‖2Qi ) , (1)
where Qi is a full or diagonal positive semidefinite matrix, and ‖θ",2.1. Follow the Regularized Leader and its Variants,[0],[0]
− θi−1‖Qi is the corresponding Mahalanobis distance between θ and θi−1.,2.1. Follow the Regularized Leader and its Variants,[0],[0]
"When Qi is diagonal, each of its entries controls the learning rate in the corresponding dimension.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"When Θ = Rd, θt can be obtained in closedform (McMahan, 2011):
θt = θt−1 −Q−11:t gt.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"(2)
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"When
Qt = 1
η diag
(√ g21:t − √ g21:t−1 ) , (3)
where η > 0 is the stepsize, (2) becomes the update rule of Adagrad (Duchi et al., 2011)
θt = θt−1 − diag
( η√
g21:t + 1
) gt.",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"(4)
Here, > 0 (usually a very small number) is used to avoid division by zero, and 1 is the vector of all 1’s.
",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"In general, all these algorithms satisfy (McMahan & Streeter, 2010):
Q1:t = diag ( 1
η
(√ g21:t + 1 )) .",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"(5)
It can be shown that this setting is optimal within a factor of √ 2 of the best possible regret bound for any nonincreasing per-coordinate learning rate schedule (McMahan & Streeter, 2010).",2.1. Follow the Regularized Leader and its Variants,[0],[0]
"In training deep networks, different weights may have vastly different gradients (in terms of both magnitude and direction).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Hence, using a per-coordinate learning rate as in Adagrad can significantly improve performance over standard SGD (Dean et al., 2012).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"However, a caveat is that Adagrad suffers from diminishing stepsize.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"As optimization proceeds, the accumulated squared gradient g21:t in (5) becomes larger and larger, making training difficult.
",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"To alleviate this problem, a number of algorithms have been proposed (Zeiler, 2012; Tieleman & Hinton, 2012; Kingma & Ba, 2015).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Typically, they employ an average of the past squared gradients (i.e., vt = ∑t i=1",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"αi,tg 2",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"i , where αi,t ∈",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"[0, 1]), which is exponentially decaying.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"For example, RMSprop (Tieleman & Hinton, 2012) uses
vi = βvi−1 + (1− β)g2i , (6)
where β is close to 1, and the corresponding αi,t is (1 − β)βt−i.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"This vt can then be used to replace g21:t, and the update in (4) becomes
θt = θt−1 − diag (
η √ vt + 1
) gt.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"(7)
Zeiler (2012) further argues that the parameter and update should have the same unit, and modifies (7) to the Adadelta update rule:
θt = θt−1 − diag (√
ut−1 + 1√ vt + 1
) gt,
where ut−1 = ∑t−1 i=0 αi,t−1(4θi)2, and 4θt = θt − θt−1 with4θ0 = 0.
",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"As v0 in (6) is often initialized to 0, the bias has to be corrected.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Adam (Kingma & Ba, 2015) uses the variance estimate vt/(1 − βt) (which corresponds to αi,t = (1− β)βt−i/(1− βt)).
",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Another recent proposal is the equilibrated stochastic gradient descent (Dauphin et al., 2015).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"It uses the variance estimate vt = vt−1 +(Htζt)2, whereHt is the Hessian and ζt ∼ N (0, 1).",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"It is shown that (Htζt)2 is an unbiased estimator of √ diag(H2t ), which serves as the Jacobi preconditioner of the absolute Hessian.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Computation of the Hessian can be avoided by using the R-operator (Schraudolph, 2002), though it still costs roughly twice that of standard backpropagation.",2.2. Adaptive Learning Rate in Deep Learning,[0],[0]
"Recall that at round t, FTRL generates the next iterate θt as
θt = arg min θ∈Θ t∑ i=1",3. Follow the Moving Leader,[0],[0]
"Pi(θ), (8)
where Pi(θ) = 〈gi, θ〉 + 12‖θ",3. Follow the Moving Leader,[0],[0]
− θi−1‖ 2 Qi .,3. Follow the Moving Leader,[0],[0]
Note that all Pi’s have the same weight.,3. Follow the Moving Leader,[0],[0]
"However, for highly nonconvex models such as the deep network, the parameter iterate may move from one local basin to another.",3. Follow the Moving Leader,[0],[0]
Pi’s that are due to samples in the distant past are less informative than those from the recent ones.,3. Follow the Moving Leader,[0],[0]
"To alleviate this problem, one may consider only Pi’s in a recent window.",3.1. Weighting the Components,[0],[0]
"However, a large memory is needed for its implementation.",3.1. Weighting the Components,[0],[0]
"A simpler alternative is by using an exponential moving average of the Pi’s: Si = β1Si−1 + (1 − β1)Pi, where β1 ∈",3.1. Weighting the Components,[0],[0]
"[0, 1) and S0 = 0.",3.1. Weighting the Components,[0],[0]
This can be easily rewritten as St = (1− β1) ∑t i=1,3.1. Weighting the Components,[0],[0]
β t−i 1 Pi.,3.1. Weighting the Components,[0],[0]
"Instead of minimizing (8), we have
θt = arg min θ∈Θ t∑ i=1",3.1. Weighting the Components,[0],[0]
"wi,tPi(θ), (9)
where the weights
wi,t = (1− β1)βt−i1
1− βt1 (10)
are normalized to sum to 1.",3.1. Weighting the Components,[0],[0]
The denominator 1− βt1 plays a similar role as bias correction in Adam.,3.1. Weighting the Components,[0],[0]
"When β1 = 0, wi,t = 0 for i < t, and wt,t = 1.",3.1. Weighting the Components,[0],[0]
"Thus, (9) reduces to minθ∈Θ Pt(θ).",3.1. Weighting the Components,[0],[0]
"When β1 → 1, the following Lemma shows that all Pi’s are weighted equally, and (8) is recovered.",3.1. Weighting the Components,[0],[0]
Lemma 1.,3.1. Weighting the Components,[0],[0]
"limβ1→1 wi,t = 1/t.
Note that the Hessian of the objective in (8) is Q1:t. This becomes ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi in (9).",3.1. Weighting the Components,[0],[0]
"Recall that Q1:t depends on the accumulated past gradients in (5), which is then refined by an exponential moving average in (6).",3.1. Weighting the Components,[0],[0]
"As in Adam, we define vi = β2vi−1 + (1 − β2)g2i , where β2 ∈",3.1. Weighting the Components,[0],[0]
"[0, 1) and v0 = 0, and then correct its bias by dividing by 1 − βt2.",3.1. Weighting the Components,[0],[0]
"Thus, (5) is changed to
t∑ i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi = diag ( 1 ηt (√ vt 1− βt2 + t1 )) , (11)
where ηt and t are the stepsize and value at time t, respectively.",3.1. Weighting the Components,[0],[0]
"When β2 = 0, (11) reduces to ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi =
diag (
1 ηt ( √ g2t + t1) ) .",3.1. Weighting the Components,[0],[0]
"When β2 → 1, all g2i ’s are
weighted equally and (11) reduces to ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi =
diag (
1 ηt (√ g21:",3.1. Weighting the Components,[0],[0]
t t + t1 )) .,3.1. Weighting the Components,[0],[0]
"Using ηt = η/ √ t and t =
/ √ t, this is further reduced to (5).",3.1. Weighting the Components,[0],[0]
"The following shows
that Qt in (11) has a closed-form expression.
",3.1. Weighting the Components,[0],[0]
Proposition 1.,3.1. Weighting the Components,[0],[0]
"Define dt = 1−βt1 ηt
(√ vt
1−βt2 + t1
) .",3.1. Weighting the Components,[0],[0]
"Then,
Qt = diag ( dt − β1dt−1
1− β1
) .",3.1. Weighting the Components,[0],[0]
"(12)
Algorithm 1 Follow the Moving Leader (FTML).",3.1. Weighting the Components,[0],[0]
"1: Input: ηt > 0, β1, β2 ∈",3.1. Weighting the Components,[0],[0]
"[0, 1), t > 0. 2: initialize θ0 ∈ Θ; d0 ← 0; v0 ← 0; z0 ← 0; 3: for t = 1, 2, . . .",3.1. Weighting the Components,[0],[0]
", T do 4: fetch function ft; 5: gt ← ∂θft(θt−1); 6: vt ← β2vt−1",3.1. Weighting the Components,[0],[0]
"+ (1− β2)g2t ;
7: dt ← 1−β t 1
ηt
(√ vt
1−βt2 + t1
) ;
8: σt ← dt − β1dt−1; 9: zt ← β1zt−1 + (1− β1)gt − σtθt−1;
10: θt ← Π diag(dt/(1−βt1))",3.1. Weighting the Components,[0],[0]
"Θ (−zt/dt); 11: end for 12: Output: θT .
",3.1. Weighting the Components,[0],[0]
"Substituting this back into (9), θt is then equal to
arg min θ∈Θ t∑ i=1",3.1. Weighting the Components,[0],[0]
"wi,t ( 〈gi, θ〉+ 1 2 ‖θ",3.1. Weighting the Components,[0],[0]
"− θi−1‖2diag ( σi 1−β1 )) , (13) where σi ≡",3.1. Weighting the Components,[0],[0]
di − β1di−1.,3.1. Weighting the Components,[0],[0]
"Note that some entries of σi may be negative, and ‖θ− θi−1‖2diag(σi/(1−β1)) is then not a regularizer in the usual sense.",3.1. Weighting the Components,[0],[0]
"Instead, the negative entries of σi encourage the corresponding entries of θ to move away from those of θi−1.",3.1. Weighting the Components,[0],[0]
"Nevertheless, from the definitions of dt, σt and (11), we have ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tdiag(σi/(1 − β1))",3.1. Weighting the Components,[0],[0]
"=∑t
i=1",3.1. Weighting the Components,[0],[0]
"wi,tQi = diag(dt/(1−βt1)), and thus the following: Lemma 2. ∑t i=1",3.1. Weighting the Components,[0],[0]
"wi,tdiag(σi/(1− β1)) 0.
",3.1. Weighting the Components,[0],[0]
"Hence, the objective in (13) is still strongly convex.",3.1. Weighting the Components,[0],[0]
"Moreover, the following Proposition shows that θt in (13) has a simple closed-form solution.
",3.1. Weighting the Components,[0],[0]
Proposition 2.,3.1. Weighting the Components,[0],[0]
"In (13),
θt = Π diag(dt/(1−βt1))",3.1. Weighting the Components,[0],[0]
"Θ (−zt/dt),
where zt = β1zt−1 + (1 − β1)gt − σtθt−1, and ΠAΘ(x) ≡ arg minu∈Θ 1 2‖u−x‖ 2",3.1. Weighting the Components,[0],[0]
"A is the projection onto Θ for a given positive semidefinite matrix A.
The proposed procedure, which will be called follow the moving leader (FTML), is shown in Algorithm 1.",3.1. Weighting the Components,[0],[0]
"Note that though {P1, . . .",3.1. Weighting the Components,[0],[0]
", Pt} are considered in each round, the update depends only the current gradient gt and parameter θt−1.",3.1. Weighting the Components,[0],[0]
"It can be easily seen that FTML is easy to implement, memory-efficient and has low per-iteration complexity.",3.1. Weighting the Components,[0],[0]
"The following Propositions show that we can recover Adagrad in two extreme cases: (i) β1 = 0 with decreasing stepsize; and (ii) β1 → 1 with increasing stepsize.
",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
Proposition 3.,3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"With β1 = 0, β2 → 1, ηt = η/ √ t, and
t = / √ t, θt in (13) reduces to:
Π diag(( √ g21:t+ 1)/η)
",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"Θ
( θt−1 − diag ( η√
g21:t + 1
) gt ) ,
which recovers Adagrad in (4).",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
Proposition 4.,3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"With β1 → 1, β2 → 1, ηt = η √ t, and
t = / √ t, we recover (1) with Qi in (3).",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"If Θ = Rd, it
generates identical updates as Adagrad in (4).",3.2.1. RELATIONSHIP WITH ADAGRAD,[0],[0]
"When Θ = Rd, McMahan (2011) showed that (1) and (2) generate the same updates.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
The following Theorem shows that FTML also has a similar gradient descent update.,3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
Theorem 1.,3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"With Θ = Rd, FTML generates the same updates as:
θt = θt−1 − diag ( 1− β1 1− βt1 ηt√ vt/(1− βt2) + t1 ) gt.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"(14)
When β1 = 0 and bias correction for the variance is not used, (14) reduces to RMSprop in (7).",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"However, recall from Section 3.1 that when β1 = 0, we have wi,t = 0 for i < t, and wt,t = 1.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"Hence, only the current loss component Pt is taken into account, and this may be sensitive to the noise in Pt.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"Moreover, as demonstrated in Adam, bias correction of the variance can be very important.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"When β2 → 1, the variance estimate of RMSprop,∑t i=1(1−β2)β t−i 2 g 2 i , becomes zero and blows up the stepsize, leading to divergence.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"In contrast, FTML’s Qi in (12) recovers that of Adagrad in this case (Proposition 4).",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"In practice, a smaller β2 has to be used for RMSprop.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"However, a larger β2 enables the algorithm to be more robust to the gradient noise in general.",3.2.2. RELATIONSHIP WITH RMSPROP,[0],[0]
"At iteration t, instead of centering regularization at each θi−1 in (13), consider centering all the proximal regularization terms at the last iterate θt−1. θt then becomes:
arg min θ∈Θ t∑ i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,t ( 〈gi, θ〉+ 1 2 ‖θ − θt−1‖2diag ( σi 1−β1 )) .",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"(15) Compared with (13), the regularization in (15) is more aggressive as it encourages θt to be close only to the last iterate θt−1.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
The following Proposition shows that (15) generates the same updates as Adam.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
Proposition 5.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"In (15),
θt = Π At Θ ( θt−1 −A−1t t∑ i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,tgi ) , (16)
where At = diag(( √ vt/(1− βt2) + t1)/ηt).
",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"As in Adam, ∑t i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,tgi in (16) can be obtained as mt/(1−βt1), wheremt is computed as an exponential moving average of gt’s: mt = β1mt−1 +",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"(1− β1)gt.
Note that the θt updates of Adagrad (4), RMSprop (7), and FTML (14) depend only on the current gradient gt.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"On the other hand, the Adam update in (16) involves ∑t i=1",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"wi,tgi, which contains all the past gradients (evaluated at past parameter estimates θi−1’s).",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"This is similar to the use of momentum, which is sometimes helpful in escaping from local minimum.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"However, when the data distribution is changing (as in deep reinforcement learning), the past gradients may not be very informative, and can even impede parameter adaptation to the environment.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"Recently, it is also reported that the use of momentum can make training unstable when the loss is nonstationary (Arjovsky et al., 2017).",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"Indeed, Theorem 4.1 in (Kingma & Ba, 2015) shows that Adam has low regret only when β1 is decreasing w.r.t.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
t.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"When β1 → 0, ∑t i=1 wi,tgi → gt and so only the current gradient is used.
",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
Remark 1.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
(Summary) RMSprop and Adam are improvements over Adagrad in training deep networks.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"However, RMSprop uses β1 = 0 (and thus relies only on the current sample), does not correct the bias of the variance estimate, but centers the regularization at the current iterates θi−1’s.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"On the other hand, Adam uses β1 > 0, bias-corrected variance, but centers all regularization terms at the last iterate θt−1.",3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
The proposed FTML combines the nice properties of the two.,3.2.3. RELATIONSHIP WITH ADAM,[0],[0]
"In this section, experiments are performed on a number of deep learning models, including convolutional neural networks (Section 4.1), deep residual networks (Section 4.2), memory networks (Section 4.3), neural conversational model (Section 4.4), deep Q-network (Section 4.5), and long short-term memory (LSTM) (Section 4.6).",4. Experiments,[0],[0]
"A summary of the empirical performance of the various deep learning optimizers is presented in Section 4.7.
",4. Experiments,[0],[0]
"The following state-of-the-art optimizers for deep learning models will be compared: (i) Adam (Kingma & Ba, 2015); (ii) RMSprop (Tieleman & Hinton, 2012); (iii) Adadelta (Zeiler, 2012); and (iv)",4. Experiments,[0],[0]
"Nesterov accelerated gradient (NAG) (Sutskever et al., 2013).",4. Experiments,[0],[0]
"For FTML, we set β1 = 0.6, β2 = 0.999, and a constant t = = 10−8 for all t. For FTML, Adam, RMSprop, and NAG, η is selected by monitoring performance on the training set (note that Adadelta does not need to set η).",4. Experiments,[0],[0]
"The learning rate is chosen from {0.5, 0.25, 0.1, . . .",4. Experiments,[0],[0]
", 0.00005, 0.000025, 0.00001}.",4. Experiments,[0],[0]
Significantly underperforming learning rates are removed after running the model for 5− 20 epochs.,4. Experiments,[0],[0]
We then pick the rate that leads to the smallest final training loss.,4. Experiments,[0],[0]
"In the section, we perform experiments with the convolutional neural network (CNN) (LeCun et al., 1998).",4.1. Convolutional Neural Networks,[0],[0]
We use the example models on the MNIST and CIFAR-10 data sets from the Keras library1.,4.1. Convolutional Neural Networks,[0],[0]
"For MNIST, the CNN has two alternating stages of 3 × 3 convolution filters (using ReLU activation), followed by a 2 × 2 max-pooling layer and a dropout layer (with a dropout rate of 0.25).",4.1. Convolutional Neural Networks,[0],[0]
"Finally, there is a fully-connected layer with ReLU activation and a dropout rate of 0.5.",4.1. Convolutional Neural Networks,[0],[0]
"For CIFAR-10, the CNN has four alternating stages of 3× 3 convolution filters (using ReLU activation).",4.1. Convolutional Neural Networks,[0],[0]
Every two convolutional layers is followed by a 2×2 maxpooling layer and a dropout layer (with a dropout rate of 0.25).,4.1. Convolutional Neural Networks,[0],[0]
The last stage has a fully-connected layer with ReLU activation and a dropout rate of 0.5.,4.1. Convolutional Neural Networks,[0],[0]
"Features in both data sets are normalized to [0, 1].",4.1. Convolutional Neural Networks,[0],[0]
"Minibatches of sizes 128 and 32 are used for MNIST and CIFAR-10, respectively.
",4.1. Convolutional Neural Networks,[0],[0]
"As the iteration complexities of the various algorithms are comparable and the total cost is dominated by backpropagation, we report convergence of the training cross entropy loss versus the number of epochs.",4.1. Convolutional Neural Networks,[0],[0]
"This setup is also used in (Zeiler, 2012; Kingma & Ba, 2015).
",4.1. Convolutional Neural Networks,[0],[0]
Figure 1 shows the convergence results.,4.1. Convolutional Neural Networks,[0],[0]
"As can be seen, FTML performs best on both data sets.",4.1. Convolutional Neural Networks,[0],[0]
"Adam has comparable performance with FTML on MNIST, but does not perform as well on CIFAR-10.",4.1. Convolutional Neural Networks,[0],[0]
The other methods are much inferior.,4.1. Convolutional Neural Networks,[0],[0]
"In particular, RMSprop is slow on both MNIST and CIFAR-10, and Adadelta tends to diverge on CIFAR-10.",4.1. Convolutional Neural Networks,[0],[0]
"Recently, substantially deeper networks have been popularly used, particularly in computer vision.",4.2. Deep Residual Networks,[0],[0]
"For example, a 152-layer deep residual network (He et al., 2016) achieves state-of-the-art performance on ImageNet classification, and won the first place on the ILSVRC 2015 classification task.
",4.2. Deep Residual Networks,[0],[0]
"In this section, we perform experiments with a 110-layer deep residual network on the CIFAR-10 and CIFAR-100 data sets.",4.2. Deep Residual Networks,[0],[0]
The code is based on its Torch implementation2.,4.2. Deep Residual Networks,[0],[0]
"We leave the architecture and related settings intact, and use the same learning rate schedule.",4.2. Deep Residual Networks,[0],[0]
The default optimizer in the Torch code is NAG.,4.2. Deep Residual Networks,[0],[0]
"Here, we also experiment with Adadelta, RMSprop, Adam and the proposed FTML.",4.2. Deep Residual Networks,[0],[0]
"A minibatch size of 32 is used.
",4.2. Deep Residual Networks,[0],[0]
Convergence of the training cross entropy loss is shown in Figure 2.,4.2. Deep Residual Networks,[0],[0]
"As can been seen, all optimizers, except Adadelta, are very competitive and have comparable per-
1https://github.com/fchollet/keras.",4.2. Deep Residual Networks,[0],[0]
"2https://github.com/facebook/fb.resnet.
torch.
",4.2. Deep Residual Networks,[0],[0]
formance on these two data sets.,4.2. Deep Residual Networks,[0],[0]
"NAG shows slower initial convergence, while FTML converges slightly faster than the others on the CIFAR-10 data set.",4.2. Deep Residual Networks,[0],[0]
"Recently, there has been a lot of attention on combining inference, attention and memory for various machine learning tasks.",4.3. Memory Networks,[0],[0]
"In particular, the memory network (Weston et al., 2014; Sukhbaatar et al., 2015) has been popularly used for natural language understanding.
",4.3. Memory Networks,[0],[0]
"In this section, we use the example model of the end-toend memory network (with LSTM) from the Keras library.",4.3. Memory Networks,[0],[0]
"We consider the question answering task (Sukhbaatar et al., 2015; Weston et al., 2016), and perform experiments on the “single supporting fact” task in the bAbI data set (Weston et al., 2016).",4.3. Memory Networks,[0],[0]
This task consists of questions in which a previously given single sentence provides the answer.,4.3. Memory Networks,[0],[0]
"An
example is shown below.",4.3. Memory Networks,[0],[0]
"We use a single supporting memory, and a minibatch size of 32.
",4.3. Memory Networks,[0],[0]
Single Supporting Fact:,4.3. Memory Networks,[0],[0]
Mary moved to the bathroom.,4.3. Memory Networks,[0],[0]
John went to the hallway.,4.3. Memory Networks,[0],[0]
Where is Mary?,4.3. Memory Networks,[0],[0]
"A: bathroom
Convergence of the training cross entropy loss is shown in Figure 3.",4.3. Memory Networks,[0],[0]
"As can be seen, FTML and RMSprop perform best on this data set.",4.3. Memory Networks,[0],[0]
"Adam is slower, while NAG and Adadelta perform poorly.",4.3. Memory Networks,[0],[0]
"The neural conversational model (Vinyals & Le, 2015) is a sequence-to-sequence model (Sutskever et al., 2014) that is capable of predicting the next sequence given the last or previous sequences in a conversation.",4.4. Neural Conversational Model,[0],[0]
"A LSTM layer en-
codes the input sentence to a thought vector, and a second LSTM layer decodes the thought vector to the response.",4.4. Neural Conversational Model,[0],[0]
"It has been shown that this model can often produce fluent and natural conversations.
",4.4. Neural Conversational Model,[0],[0]
"In this experiment, we use the publicly available Torch implementation3 with a constant stepsize, and its default data set Cornell Movie-Dialogs Corpus (with 50, 000 samples) (Danescu-Niculescu-Mizil & Lee, 2011).",4.4. Neural Conversational Model,[0],[0]
"The number of hidden units is set to 1000, and the minibatch size is 10.
",4.4. Neural Conversational Model,[0],[0]
Convergence of the training cross entropy loss is shown in Figure 4.,4.4. Neural Conversational Model,[0],[0]
"Adadelta is not reported here, since it performs poorly (as in previous experiments).",4.4. Neural Conversational Model,[0],[0]
"As can be seen, FTML outperforms Adam and RMSprop.",4.4. Neural Conversational Model,[0],[0]
"In particular, RMSprop is much inferior.",4.4. Neural Conversational Model,[0],[0]
"NAG is slower than FTML and Adam in the first 21 epochs, but becomes faster towards the end of training.",4.4. Neural Conversational Model,[0],[0]
"In this section, we use the Deep Q-network (DQN) (Mnih et al., 2015) for deep reinforcement learning.",4.5. Deep Q-Network,[0],[0]
Experiments are performed on two computer games on the Atari 2600 platform: Breakout and Asterix.,4.5. Deep Q-Network,[0],[0]
"We use the publicly available Torch implementation with the default network setup4, and a minibatch size of 32.",4.5. Deep Q-Network,[0],[0]
"We only compare FTML with RMSprop and Adam for optimization, as NAG and Adadelta are rarely used in training the DQN.",4.5. Deep Q-Network,[0],[0]
"As in (Mnih et al., 2015), we use = 10−2 for all methods, and performance evaluation is based on the average score per episode.",4.5. Deep Q-Network,[0],[0]
"The higher the score, the better the performance.
",4.5. Deep Q-Network,[0],[0]
Convergence is shown in Figure 5.,4.5. Deep Q-Network,[0],[0]
"On Breakout, RM-
3https://github.com/macournoyer/ neuralconvo.
",4.5. Deep Q-Network,[0],[0]
"4https://github.com/Kaixhin/Atari.
",4.5. Deep Q-Network,[0],[0]
Sprop and FTML are comparable and yield higher scores than Adam.,4.5. Deep Q-Network,[0],[0]
"On Asterix, FTML outperforms all the others.",4.5. Deep Q-Network,[0],[0]
"In particular, the DQN trained with RMSprop fails to learn the task, and its score begins to drop after about 100 epochs.",4.5. Deep Q-Network,[0],[0]
"A similar problem has also been observed in (Hasselt et al., 2016).",4.5. Deep Q-Network,[0],[0]
"Experience replay (Mnih et al., 2015) has been commonly used in deep reinforcement learning to smooth over changes in the data distribution, and avoid oscillations or divergence of the parameters.",4.5. Deep Q-Network,[0],[0]
"However, results here show that Adam still has inferior performance because of its use of all past gradients, many of these are not informative when the data distribution has changed.",4.5. Deep Q-Network,[0],[0]
"To illustrate the problem of Adam in Section 4.5 more clearly, we perform the following timeseries prediction experiment with the LSTM.",4.6. Long Short-Term Memory (LSTM),[0],[0]
We construct a synthetic timeseries of length 1000.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"This is divided into 20 segments, each of length 50.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"At each time point, the sample is 10- dimensional.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"In segment i, samples are generated from a normal distribution with mean ([i, i, . . .",4.6. Long Short-Term Memory (LSTM),[0],[0]
", i] + ζi) ∈ R10 and identity covariance matrix, where the components of ζi are independent standard normal random variables.",4.6. Long Short-Term Memory (LSTM),[0],[0]
Noise from the standard normal distribution is added to corrupt the data.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"The task is to predict the data sample at the next time point t.
We use a one-layer LSTM implemented in (Léonard et al., 2015).",4.6. Long Short-Term Memory (LSTM),[0],[0]
100 hidden units are used.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"We truncate backpropagation through time (BPTT) to 5 timesteps, and input 5 samples to the LSTM in each iteration.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"Thus, the data distribution changes every 10 iterations, as a different normal distribution is then used for data generation.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"Performance evaluation is based on the squared loss ft(θt−1) at time t.
Convergence of the loss is shown in Figure 6(a).",4.6. Long Short-Term Memory (LSTM),[0],[0]
"As can be
seen, Adam has difficulty in adapting to the data.",4.6. Long Short-Term Memory (LSTM),[0],[0]
"In contrast, FTML and RMSprop can adapt more quickly, yielding better and more stable performance.
",4.6. Long Short-Term Memory (LSTM),[0],[0]
"As a baseline, we consider the case where the data distribution does not change (the means of all the segments are fixed to the vector of ones)",4.6. Long Short-Term Memory (LSTM),[0],[0]
Figure 6(b) shows the results.,4.6. Long Short-Term Memory (LSTM),[0],[0]
"As can be seen, Adam now performs comparably to FTML and RMSprop.",4.6. Long Short-Term Memory (LSTM),[0],[0]
The main problem with RMSprop is that its performance is not stable.,4.7. Summary of Results,[0],[0]
"Sometimes, it performs well, but sometimes it can have significantly inferior performance (e.g., as can be seen from Figures 1, 4 and 5(b)).",4.7. Summary of Results,[0],[0]
"The performance of Adam is more stable, though it often lags behind the best optimizer (e.g., Figures 1(b), 3, and 4).",4.7. Summary of Results,[0],[0]
"It is particularly problematic when learning in a changing environment (Fig-
ures 5 and 6(a)).",4.7. Summary of Results,[0],[0]
"In contrast, the proposed FTML shows stable performance on various models and tasks.",4.7. Summary of Results,[0],[0]
"It converges quickly, and is always the best (or at least among the best) in all our experiments.",4.7. Summary of Results,[0],[0]
"In this paper, we proposed a FTPRL variant called FTML, in which the recent samples are weighted more heavily in each iteration.",5. Conclusion,[0],[0]
"Hence, it is able to adapt more quickly when the parameter moves to another local basin, or when the data distribution changes.",5. Conclusion,[0],[0]
FTML is closely related to RMSprop and Adam.,5. Conclusion,[0],[0]
"In particular, it enjoys their nice properties, but avoids their pitfalls.",5. Conclusion,[0],[0]
"Experimental results on a number of deep learning models and tasks demonstrate that FTML converges quickly, and is always the best (or among the best) of the various optimizers.",5. Conclusion,[0],[0]
This research was supported in part by ITF/391/15FX.,Acknowledgments,[0],[0]
Deep networks are highly nonlinear and difficult to optimize.,abstractText,[0],[0]
"During training, the parameter iterate may move from one local basin to another, or the data distribution may even change.",abstractText,[0],[0]
"Inspired by the close connection between stochastic optimization and online learning, we propose a variant of the follow the regularized leader (FTRL) algorithm called follow the moving leader (FTML).",abstractText,[0],[0]
"Unlike the FTRL family of algorithms, the recent samples are weighted more heavily in each iteration and so FTML can adapt more quickly to changes.",abstractText,[0],[0]
"We show that FTML enjoys the nice properties of RMSprop and Adam, while avoiding their pitfalls.",abstractText,[0],[0]
"Experimental results on a number of deep learning models and tasks demonstrate that FTML converges quickly, and outperforms other state-ofthe-art optimizers.",abstractText,[0],[0]
Follow the Moving Leader in Deep Learning,title,[0],[0]
NMT has witnessed promising improvements recently.,1 Introduction,[0],[0]
"Depending on the types of input and output, these efforts can be divided into three categories: string-to-string systems (Sutskever et al., 2014; Bahdanau et al., 2014); tree-to-string systems (Eriguchi et al., 2016, 2017); and string-totree systems (Aharoni and Goldberg, 2017; Nadejde et al., 2017).",1 Introduction,[0],[0]
"Compared with string-to-string systems, tree-to-string and string-to-tree systems (henceforth, tree-based systems) offer some attractive features.",1 Introduction,[0],[0]
"They can use more syntactic information (Li et al., 2017), and can conveniently incorporate prior knowledge (Zhang et al., 2017).
∗ Contribution during internship at National Institute of Information and Communications Technology.
†Corresponding author
Because of these advantages, tree-based methods become the focus of many researches of NMT nowadays.
",1 Introduction,[0],[0]
"Based on how to represent trees, there are two main categories of tree-based NMT methods: representing trees by a tree-structured neural network (Eriguchi et al., 2016; Zaremoodi and Haffari, 2017), representing trees by linearization (Vinyals et al., 2015; Dyer et al., 2016; Ma et al., 2017).",1 Introduction,[0],[0]
"Compared with the former, the latter method has a relatively simple model structure, so that a larger corpus can be used for training and the model can be trained within reasonable time, hence is preferred from the viewpoint of computation.",1 Introduction,[0],[0]
"Therefore we focus on this kind of methods in this paper.
",1 Introduction,[0],[0]
"In spite of impressive performance of tree-based NMT systems, they suffer from a major drawback: they only use the 1-best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors (Quirk and Corston-Oliver, 2006).",1 Introduction,[0],[0]
"For SMT, forest-based methods have employed a packed forest to address this problem (Huang, 2008), which represents exponentially many parse trees rather than just the 1-best one (Mi et al., 2008; Mi and Huang, 2008).",1 Introduction,[0],[0]
"But for NMT, (computationally efficient) forestbased methods are still being explored1.
",1 Introduction,[0],[0]
"Because of the structural complexity of forests, the inexistence of appropriate topological ordering, and the hyperedge-attachment nature of weights (see Section 3.1 for details), it is not trivial to linearize a forest.",1 Introduction,[0],[0]
"This hinders the development of forest-based NMT to some extent.
",1 Introduction,[0],[0]
"Inspired by the tree-based NMT methods based on linearization, we propose an efficient forestbased NMT approach (Section 3), which can en-
1Zaremoodi and Haffari (2017) have proposed a forestbased NMT method based on a forest-structured neural network recently, but it is computationally inefficient (see Section 5).
code the syntactic information of a packed forest on the basis of a novel weighted linearization method for a packed forest (Section 3.1), and can decode the linearized packed forest under the simple sequence-to-sequence framework (Section 3.2).",1 Introduction,[0],[0]
Experiments demonstrate the effectiveness of our method (Section 4).,1 Introduction,[0],[0]
"We first review the general sequence-to-sequence model (Section 2.1), then describe tree-based NMT systems based on linearization (Section 2.2), and finally introduce the packed forest, through which exponentially many trees can be represented in a compact manner (Section 2.3).",2 Preliminaries,[0],[0]
"Current NMT systems usually resort to a simple framework, i.e., the sequence-to-sequence model (Cho et al., 2014; Sutskever et al., 2014).",2.1 Sequence-to-sequence model,[0],[0]
"Given a source sequence (x0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", xT ), in order to find a target sequence (y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yT ′) that maximizes the conditional probability p(y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yT ′",2.1 Sequence-to-sequence model,[0],[0]
"| x0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", xT ), the sequence-to-sequence model uses one RNN to encode the source sequence into a fixed-length context vector c and a second RNN to decode this vector and generate the target sequence.",2.1 Sequence-to-sequence model,[0],[0]
"Formally, the probability of the target sequence can be calculated as follows:
p(y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
",yT ′",2.1 Sequence-to-sequence model,[0],[0]
"| x0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", xT )
",2.1 Sequence-to-sequence model,[0],[0]
"= T ′∏ t=0 p(yt | c, y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yt−1), (1)
where
p(yt | c, y0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", yt−1) = g(yt−1, st, c), (2) st = f(st−1, yt−1, c), (3)
c = q(h0, . . .",2.1 Sequence-to-sequence model,[0],[0]
", hT ), (4)
ht = f(et, ht−1).",2.1 Sequence-to-sequence model,[0],[0]
"(5)
Here, g, f , and q are nonlinear functions; ht and st are the hidden states of the source-side RNN and target-side RNN, respectively, c is the context vector, and et is the embedding of xt.
Bahdanau et al. (2014) introduced an attention mechanism to deal with the issues related to long sequences (Cho et al., 2014).",2.1 Sequence-to-sequence model,[0],[0]
"Instead of encoding the source sequence into a fixed vector c, the attention model uses different ci-s when calculating
the target-side output yi at time step i:
ci = T∑
j=0
αijhj , (6)
αij = exp(a(si−1, hj))∑T k=0",2.1 Sequence-to-sequence model,[0],[0]
"exp(a(si−1, hk))",2.1 Sequence-to-sequence model,[0],[0]
.,2.1 Sequence-to-sequence model,[0],[0]
"(7)
The function a(si−1, hj) can be regarded as representing the soft alignment between the target-side RNN hidden state si−1 and the source-side RNN hidden state hj .
",2.1 Sequence-to-sequence model,[0],[0]
"By changing the format of the source/target sequences, this framework can be regarded as a string-to-string NMT system (Sutskever et al., 2014), a tree-to-string NMT system (Li et al., 2017), or a string-to-tree NMT system (Aharoni and Goldberg, 2017).",2.1 Sequence-to-sequence model,[0],[0]
"Regarding the linearization adopted for tree-tostring NMT (i.e., linearization of the source side), Sennrich and Haddow (2016) encoded the sequence of dependency labels and the sequence of words simultaneously, partially utilizing the syntax information, while Li et al. (2017) traversed the constituent tree of the source sentence and combined this with the word sequence, utilizing the syntax information completely.
",2.2 Linear-structured tree-based NMT systems,[0],[0]
"Regarding the linearization used for string-totree NMT (i.e., linearization of the target side), Nadejde et al. (2017) used a CCG supertag sequence as the target sequence, while Aharoni and Goldberg (2017) applied a linearization method in a top-down manner, generating a sequence ensemble for the annotated tree in the Penn Treebank (Marcus et al., 1993).",2.2 Linear-structured tree-based NMT systems,[0],[0]
"Wu et al. (2017) used transition actions to linearize a dependency tree, and employed the sequence-to-sequence framework for NMT.
",2.2 Linear-structured tree-based NMT systems,[0],[0]
It can be seen all current tree-based NMT systems use only one tree for encoding or decoding.,2.2 Linear-structured tree-based NMT systems,[0],[0]
"In contrast, we hope to utilize multiple trees (i.e., a forest).",2.2 Linear-structured tree-based NMT systems,[0],[0]
"This is not trivial, on account of the lack of a fixed traversal order and the need for a compact representation.",2.2 Linear-structured tree-based NMT systems,[0],[0]
"The packed forest gives a representation of exponentially many parsing trees, and can compactly encode many more candidates than the n-best list
(Huang, 2008).",2.3 Packed forest,[0],[0]
"Figure 1a shows a packed forest, which can be unpacked into two constituent trees (Figure 1b and Figure 1c).
",2.3 Packed forest,[0],[0]
"Formally, a packed forest is a pair 〈V,E〉, where V is the set of nodes and E is the set of hyperedges.",2.3 Packed forest,[0],[0]
"Each v ∈ V can be represented as Xi,j , where X is a constituent label and i, j ∈",2.3 Packed forest,[0],[0]
"[0, n] are indices of words, showing that the node spans the words ranging from i (inclusive) to j (exclusive).",2.3 Packed forest,[0],[0]
"Here, n is the length of the input sentence.",2.3 Packed forest,[0],[0]
"Each e ∈ E is a three-tuple 〈head(e), tails(e), score(e)〉, where head(e) ∈ V is similar to the head node in a constituent tree, and tails(e) ∈ V ∗ is similar to the set of child nodes in a constituent tree.",2.3 Packed forest,[0],[0]
score(e) ∈ R is the logarithm of the probability that tails(e) represents the tails of head(e) calculated by the parser.,2.3 Packed forest,[0],[0]
"Based on score(e), the score of a constituent tree T can be calculated as follows:
score(T ) = −λn+",2.3 Packed forest,[0],[0]
"∑
e∈E(T )
score(e), (8)
where E(T ) is the set of hyperedges appearing in tree T , and λ is a regularization coefficient for the sentence length2.
2Following the configuration of Charniak and Johnson",2.3 Packed forest,[0],[0]
"We first propose a linearization method for the packed forest (Section 3.1), then describe how to encode the linearized forest (Section 3.2), which can then be translated by the conventional decoder (see Section 2.1).",3 Forest-based NMT,[0],[0]
"Recently, several studies have focused on the linearization methods of a syntax tree, both in the area of tree-based NMT (Section 2.2) and in the area of parsing (Vinyals et al., 2015; Dyer et al., 2016; Ma et al., 2017).",3.1 Forest linearization,[0],[0]
"Basically, these methods follow a fixed traversal order (e.g., depthfirst), which does not exist for the packed forest (a directed acyclic graph (DAG)).",3.1 Forest linearization,[0],[0]
"Furthermore, the weights are attached to edges of a packed forest instead of the nodes, which further increase the difficulty.
",3.1 Forest linearization,[0],[0]
"Topological ordering algorithms for DAG (Kahn, 1962; Tarjan, 1976) are not good solutions, because the outputted ordering is not always optimal for machine translation.",3.1 Forest linearization,[0],[0]
"In particular, a topo-
(2005), for all the experiments in this paper, we fixed λ to log2 600.
",3.1 Forest linearization,[0],[0]
"Algorithm 1 Linearization of a packed forest 1: function LINEARIZEFOREST(〈V,E〉,w) 2: v ← FINDROOT(V ) 3: r←",3.1 Forest linearization,[0],[0]
"[] 4: EXPANDSEQ(v, r, 〈V,E〉,w) 5: return r 6: function FINDROOT(V ) 7: for v ∈ V do 8: if v has no parent then 9: return v 10: procedure EXPANDSEQ(v, r, 〈V,E〉,w) 11: for e ∈ E do 12: if head(e) = v then 13: if tails(e) 6= ∅",3.1 Forest linearization,[0],[0]
then 14: for t ∈ SORT(tails(e)) do .,3.1 Forest linearization,[0],[0]
"Sort
tails(e) by word indices.",3.1 Forest linearization,[0],[0]
"15: EXPANDSEQ(t, r, 〈V,E〉,w) 16: l← LINEARIZEEDGE(head(e),w) 17: r.append(〈l, σ(0.0)〉) .",3.1 Forest linearization,[0],[0]
"σ is the sigmoid
function, i.e., σ(x) = 1 1+e−x , x ∈ R.
18:",3.1 Forest linearization,[0],[0]
"l ← c©LINEARIZEEDGES(tails(e),w) .",3.1 Forest linearization,[0],[0]
c© is a unary operator.,3.1 Forest linearization,[0],[0]
"19: r.append(〈l, σ(score(e))",3.1 Forest linearization,[0],[0]
"〉) 20: else 21: l← LINEARIZEEDGE(head(e),w) 22:",3.1 Forest linearization,[0],[0]
"r.append(〈l, σ(0.0)〉) 23: function LINEARIZEEDGE(Xi,j ,w) 24: return X ⊗",3.1 Forest linearization,[0],[0]
"( j−1k=iwk) 25: function LINEARIZEEDGES(v,w) 26: return ⊕v∈vLINEARIZEEDGE(v,w)
logical ordering could ignore “word sequential information” and “parent-child information” in the sentences.
",3.1 Forest linearization,[0],[0]
"For example, for the packed forest in Figure 1a, although “[10]→[1]→[2]→ · · · →[9]→[11]” is a valid topological ordering, the word sequential information of the words (e.g., “John” should be located ahead of the period), which is fairly crucial for translation of languages with fixed pragmatic word order such as Chinese or English, is lost.
",3.1 Forest linearization,[0],[0]
"As another example, for the packed forest in Figure 1a, nodes [2], [9], and [10] are all the children of node [11].",3.1 Forest linearization,[0],[0]
"However, in the topological order “[1]→[2]→ · · · →[9]→[10]→[11],” node [2] is quite far from node [11], while nodes [9] and [10] are both close to node [11].",3.1 Forest linearization,[0],[0]
"The parent-child information cannot be reflected in this topological order, which is not what we would expect.
",3.1 Forest linearization,[0],[0]
"To address the above two problems, we propose a novel linearization algorithm for a packed forest (Algorithm 1).",3.1 Forest linearization,[0],[0]
"The algorithm linearizes the packed forest from the root node (Line 2) to leaf nodes by calling the EXPANDSEQ procedure (Line 15) recursively, while preserving the word order in the sentence (Line 14).",3.1 Forest linearization,[0],[0]
"In this way, word sequential information is preserved.",3.1 Forest linearization,[0],[0]
"Within the
EXPANDSEQ procedure, once a hyperedge is linearized (Line 16), the tails are also linearized immediately (Line 18).",3.1 Forest linearization,[0],[0]
"In this way, parent-child information is preserved.",3.1 Forest linearization,[0],[0]
"Intuitively, different parts of constituent trees should be combined in different ways, therefore we define different operators ( c©, ⊗, ⊕, or ) to represent the relationships between different parts, so that the representations of these parts can be combined in different ways (see Section 3.2 for details).",3.1 Forest linearization,[0],[0]
"Words are concatenated by the operator “ ” with each other, a word and a constituent label is concatenated by the operator “⊗”, the linearization results of child nodes are concatenated by the operator “⊕” with each other, while the unary operator “ c©” is used to indicate that the node is the child node of the previous part.",3.1 Forest linearization,[0],[0]
"Furthermore, each token in the linearized sequence is related to a score, representing the confidence of the parser.
",3.1 Forest linearization,[0],[0]
The linearization result of the packed forest in Figure 1a is shown in Figure 2.,3.1 Forest linearization,[0],[0]
Tokens in the linearized sequence are separated by slashes.,3.1 Forest linearization,[0],[0]
Each token in the sequence is composed of different types of symbols and combined by different operators.,3.1 Forest linearization,[0],[0]
We can see that word sequential information is preserved.,3.1 Forest linearization,[0],[0]
"For example, “NNP⊗John” (linearization result of node [1]) is in front of “VBZ⊗has” (linearization result of node [3]), which is in front of “DT⊗a” (linearization result of node [4]).",3.1 Forest linearization,[0],[0]
"Moreover, parent-child information is also preserved.",3.1 Forest linearization,[0],[0]
"For example, “NP⊗John” (linearization result of node [2]) is followed by “ c©NNP⊗John” (linearization result of node [1], the child of node [2]).
",3.1 Forest linearization,[0],[0]
Note that our linearization method cannot fully recover packed forest.,3.1 Forest linearization,[0],[0]
What we want to do is not to propose a fully recoverable linearization method.,3.1 Forest linearization,[0],[0]
"What we actually want to do is to encode syntax information as much as possible, so that we can improve the performance of NMT.",3.1 Forest linearization,[0],[0]
"As will be shown in Section 4, this goal is achieved.
",3.1 Forest linearization,[0],[0]
"Also note that there is one more advantage of our linearization method: the linearized sequence
is a weighted sequence, while all the previous studies ignored the weights during linearization.",3.1 Forest linearization,[0],[0]
"As will be shown in Section 4, the weights are actually important not only for the linearization of a packed forest, but also for the linearization of a single tree.
",3.1 Forest linearization,[0],[0]
"By preserving only the nodes and hyperedges in the 1-best tree and removing all others, our linearization method can be regarded as a treelinearization method.",3.1 Forest linearization,[0],[0]
"Compared with other treelinearization methods, our method combines several different kinds of information within one symbol, retaining the parent-child information, and incorporating the confidence of the parser in the sequence.",3.1 Forest linearization,[0],[0]
"We examine whether the weights can be useful not only for linear structured tree-based NMT but also for our forest-based NMT.
",3.1 Forest linearization,[0],[0]
"Furthermore, although our method is nonreversible for packed forests, it is reversible for constituent trees, in that the linearization is processed exactly in the depth-first traversal order and all necessary information in the tree nodes has been encoded.",3.1 Forest linearization,[0],[0]
"As far as we know, there is no previous work on linearization of packed forests.",3.1 Forest linearization,[0],[0]
"The linearized packed forest forms the input of the encoder, which has two major differences from the input of a sequence-to-sequence NMT system.",3.2 Encoding the linearized forest,[0],[0]
"First, the input sequence of the encoder consists of two parts: the symbol sequence and the score sequence.",3.2 Encoding the linearized forest,[0],[0]
"Second, each symbol in the symbol sequence consists of several parts (words and constituent labels), which are combined by certain operators ( c©, ⊗, ⊕, or ).",3.2 Encoding the linearized forest,[0],[0]
"Based on these observa-
tions, we propose two new frameworks, which are illustrated in Figure 3.
",3.2 Encoding the linearized forest,[0],[0]
"Formally, the input layer receives the sequence (〈l0, ξ0〉, . . .",3.2 Encoding the linearized forest,[0],[0]
", 〈lT , ξT 〉), where li denotes the i-th symbol and ξi its score.",3.2 Encoding the linearized forest,[0],[0]
"Then, the sequence is fed into the score layer and the symbol layer.",3.2 Encoding the linearized forest,[0],[0]
"The score and symbol layers receive the sequence and output the score sequence ξ = (ξ0, . . .",3.2 Encoding the linearized forest,[0],[0]
", ξT ) and symbol sequence",3.2 Encoding the linearized forest,[0],[0]
"l = (l0, . . .",3.2 Encoding the linearized forest,[0],[0]
", lT ), respectively, from the input.",3.2 Encoding the linearized forest,[0],[0]
Any item l ∈,3.2 Encoding the linearized forest,[0],[0]
"l in the symbol layer has the form
l = o0x1o1 . . .",3.2 Encoding the linearized forest,[0],[0]
"xm−1om−1xm, (9)
where each xk (k = 1, . . .",3.2 Encoding the linearized forest,[0],[0]
",m) is a word or a constituent label, m is the total number of words and constituent labels in a symbol, o0 is “ c©” or empty, and each ok (k = 1, . . .",3.2 Encoding the linearized forest,[0],[0]
",m − 1) is either “⊗”, “⊕”, or “ ”.",3.2 Encoding the linearized forest,[0],[0]
"Then, in the node/operator layer, the x-s and o-s are separated and rearranged as x = (x1, . . .",3.2 Encoding the linearized forest,[0],[0]
", xm, o0, . . .",3.2 Encoding the linearized forest,[0],[0]
", om−1), which is fed to the pre-embedding layer.",3.2 Encoding the linearized forest,[0],[0]
"The pre-embedding layer generates a sequence p = (p1, . .",3.2 Encoding the linearized forest,[0],[0]
.,3.2 Encoding the linearized forest,[0],[0]
", pm, . . .",3.2 Encoding the linearized forest,[0],[0]
", p2m), which is calculated as follows:
p =Wemb[I(x)].",3.2 Encoding the linearized forest,[0],[0]
"(10)
Here, the function I(x) returns a list of the indices in the dictionary for all the elements in x, which consist of words, constituent labels, or operators.",3.2 Encoding the linearized forest,[0],[0]
"In addition, Wemb is the embedding matrix of size (|wword| + |wlabel| + 4) × dword, where |wword| and |wlabel| are the total number of words and constituent labels, respectively, dword is the dimension of the word embedding, and there are four possible operators: “",3.2 Encoding the linearized forest,[0],[0]
"c©,” “⊗,” “⊕,” and “ .”",3.2 Encoding the linearized forest,[0],[0]
"Note
that p is a list of 2m vectors, and the dimension of each vector is dword.
",3.2 Encoding the linearized forest,[0],[0]
"Because the length of the sequence of the input layer is T + 1, there are T + 1 different ps in the pre-embedding layer, which we denote by P = (p0, . . .",3.2 Encoding the linearized forest,[0],[0]
",pT ).",3.2 Encoding the linearized forest,[0],[0]
"Depending on where the score layer is incorporated, we propose two frameworks: Score-on-Embedding (SoE) and Score-onAttention (SoA).",3.2 Encoding the linearized forest,[0],[0]
"In SoE, the k-th element of the embedding layer is calculated as follows:
ek = ξk ∑ p∈pk p, (11)
while in SoA, the k-th element of the embedding layer is calculated as
ek = ∑ p∈pk p, (12)
where k = 0, . . .",3.2 Encoding the linearized forest,[0],[0]
", T .",3.2 Encoding the linearized forest,[0],[0]
Note that ek ∈ Rdword .,3.2 Encoding the linearized forest,[0],[0]
"In this manner, the proposed forest-to-string NMT framework is connected with the conventional sequence-to-sequence NMT framework.
",3.2 Encoding the linearized forest,[0],[0]
"After calculating the embedding vectors in the embedding layer, the hidden vectors are calculated using Equation 5.",3.2 Encoding the linearized forest,[0],[0]
"When calculating the context vector ci-s, SoE and SoA differ from each other.",3.2 Encoding the linearized forest,[0],[0]
"For SoE, the ci-s are calculated using Equation 6 and 7, while for SoA, the αij-s used to calculate the ci-s are determined as follows:
αij = exp(ξja(si−1, hj))∑T k=0",3.2 Encoding the linearized forest,[0],[0]
"exp(ξka(si−1, hk)) .",3.2 Encoding the linearized forest,[0],[0]
"(13)
Then, using the decoder of the sequence-tosequence framework, the sentence of the target language can be generated.",3.2 Encoding the linearized forest,[0],[0]
We evaluate the effectiveness of our forest-based NMT systems on English-to-Chinese and Englishto-Japanese translation tasks3.,4.1 Setup,[0],[0]
"The statistics of the corpora used in our experiments are summarized in Table 1.
",4.1 Setup,[0],[0]
The packed forests of English sentences are obtained by the constituent parser proposed by Huang (2008)4.,4.1 Setup,[0],[0]
"We filtered out the sentences for
3English is commonly chosen as the target language.",4.1 Setup,[0],[0]
"We chose English as the source language because a highperformance forest parser is not available for other languages.
4http://web.engr.oregonstate.edu/ ˜huanlian/software/forest-reranker/ forest-charniak-v0.8.tar.bz2
which the parser cannot generate the packed forest successfully and the sentences longer than 80 words.",4.1 Setup,[0],[0]
"For NIST datasets, we simply choose the first reference among the four English references of NIST corpora, because all of them are independent with each other, according to the documents of NIST datasets.",4.1 Setup,[0],[0]
"For Chinese sentences, we used Stanford segmenter5 for segmentation.",4.1 Setup,[0],[0]
"For Japanese sentences, we followed the preprocessing steps recommended in WAT 20176.
",4.1 Setup,[0],[0]
"We implemented our framework based on nematus8 (Sennrich et al., 2017).",4.1 Setup,[0],[0]
"For optimization, we used the Adadelta algorithm (Zeiler, 2012).",4.1 Setup,[0],[0]
"In order to avoid overfitting, we used dropout (Srivastava et al., 2014) on the embedding layer and hidden layer, with the dropout probability set to 0.2.",4.1 Setup,[0],[0]
"We used the gated recurrent unit (Cho et al., 2014) as the recurrent unit of RNNs, which are bi-directional, with one hidden layer.
",4.1 Setup,[0],[0]
"Based on the tuning result, we set the maximum length of the input sequence to 300, the hidden layer size as 512, the dimension of word embedding as 620, and the batch size for training as 40.",4.1 Setup,[0],[0]
"We pruned the packed forest using the algorithm of Huang (2008), with a threshold of 5.",4.1 Setup,[0],[0]
"If the linearization of the pruned forest is still longer than 300, then we linearize the 1-best parsing tree instead of the forest.",4.1 Setup,[0],[0]
"During decoding, we used beam search, and fixed the beam size to 12.",4.1 Setup,[0],[0]
"For the case of Forest (SoA), with 1 core of Tesla K80 GPU and LDC corpus as the training data, training spent about 10 days, and decoding speed is about 10 sentences per second.
",4.1 Setup,[0],[0]
"5https://nlp.stanford.edu/software/ stanford-segmenter-2017-06-09.zip
6http://lotus.kuee.kyoto-u.ac.jp/WAT/ WAT2017/baseline/dataPreparationJE.html
7LDC2002E18, LDC2003E07, LDC2003E14, Hansards portion of LDC2004T07, LDC2004T08, and LDC2005T06
8https://github.com/EdinburghNLP/ nematus",4.1 Setup,[0],[0]
Table 2 and 3 summarize the experimental results.,4.2 Experimental results,[0],[0]
"To avoid the affect of segmentation errors, the performance were evaluated by character-level BLEU (Papineni et al., 2002).",4.2 Experimental results,[0],[0]
"We compare our proposed models (i.e., Forest (SoE) and Forest (SoA)) with three types of baseline: a string-to-string model (s2s), forest-based models that do not use score sequences (Forest (No score)), and tree-based models that use the 1-best parsing tree (1-best (No score, SoE, SoA)).",4.2 Experimental results,[0],[0]
"For the 1-best models, we preserve the nodes and hyperedges that are used in the 1-best constituent tree in the packed forest, and remove all other nodes and hyperedges, yielding a pruned forest that contains only the 1-best constituent tree.",4.2 Experimental results,[0],[0]
"For the “No score” configurations, we force the input score sequence to be a sequence of 1.0 with the same length as the input symbol sequence, so that neither the embedding layer nor the attention layer are affected by the score sequence.
",4.2 Experimental results,[0],[0]
"In addition, we also perform a comparison with some state-of-the-art tree-based systems that are
publicly available, including an SMT system (Mi et al., 2008) and the NMT systems (Eriguchi et al. (2016)9, Chen et al. (2017)10, and Li et al. (2017)).",4.2 Experimental results,[0],[0]
"For Mi et al. (2008), we use the implementation of cicada11.",4.2 Experimental results,[0],[0]
"For Li et al. (2017), we reimplemented the “Mixed RNN Encoder” model, because of its outstanding performance on the NIST MT corpus.
",4.2 Experimental results,[0],[0]
"We can see that for both English-Chinese and English-Japanese, compared with the s2s baseline system, both the 1-best and forest-based configurations yield better results.",4.2 Experimental results,[0],[0]
This indicates syntactic information contained in the constituent trees or forests is indeed useful for machine translation.,4.2 Experimental results,[0],[0]
"Specifically, we observe the following facts.
",4.2 Experimental results,[0],[0]
"First, among the three different frameworks SoE, SoA, and No-score, the SoA framework performs the best, while the No-score framework per-
9https://github.com/tempra28/tree2seq 10https://github.com/howardchenhd/
Syntax-awared-NMT 11https://github.com/tarowatanabe/ cicada
forms the worst.",4.2 Experimental results,[0],[0]
"This indicates that the scores of the edges in constituent trees or packed forests, which reflect the confidence of the correctness of the edges, are indeed useful.",4.2 Experimental results,[0],[0]
"In fact, for the 1-best constituent parsing tree, the score of the edge reflects the confidence of the parser.",4.2 Experimental results,[0],[0]
"By using this information, the NMT system succeed to learn a better attention, paying much attention to the confident structure and not paying attention to the unconfident structure, which improved the translation performance.",4.2 Experimental results,[0],[0]
This fact is ignored by previous studies on tree-based NMT.,4.2 Experimental results,[0],[0]
"Furthermore, it is better to use the scores to modify the values of attention instead of rescaling the word embeddings, because modifying word embeddings carelessly may change the semantic meanings of words.
",4.2 Experimental results,[0],[0]
"Second, compared with the cases that only using the 1-best constituent trees, using packed forests yields statistical significantly better results for the SoE and SoA frameworks.",4.2 Experimental results,[0],[0]
This shows the effectiveness of using more syntactic information.,4.2 Experimental results,[0],[0]
"Compared with one constituent tree, the packed forest, which contains multiple different trees, describes the syntactic structure of the sentence in different aspects, which together increase the accuracy of machine translation.",4.2 Experimental results,[0],[0]
"However, without using the scores, the 1-best constituent tree is preferred.",4.2 Experimental results,[0],[0]
"This is because without using the scores, all trees in the packed forest are treated equally, which makes it easy to import noise into the encoder.
",4.2 Experimental results,[0],[0]
"Compared with other types of state-of-the-art systems, our systems using only the 1-best tree (1-best(SoE, SoA)) are better than the other treebased systems.",4.2 Experimental results,[0],[0]
"Moreover, our NMT systems using the packed forests achieve the best performance.",4.2 Experimental results,[0],[0]
"These results also support the usefulness of the scores of the edges and packed forests in NMT.
",4.2 Experimental results,[0],[0]
"As for the efficiency, the training time of the SoA system was slightly longer than that of the SoE system, which was about twice of the s2s baseline.",4.2 Experimental results,[0],[0]
The training time of the tree-based system was about 1.5 times of the baseline.,4.2 Experimental results,[0],[0]
"For the
case of Forest (SoA), with 1 core of Tesla P100 GPU and LDC corpus as the training data, training spent about 10 days, and decoding speed was about 10 sentences per second.",4.2 Experimental results,[0],[0]
"The reason for the relatively low efficiency is that the linearized sequences of packed forests were much longer than word sequences, enlarging the scale of the inputs.",4.2 Experimental results,[0],[0]
"Despite this, the training process ended within reasonable time.",4.2 Experimental results,[0],[0]
"Figure 4 illustrates the translation results of an English sentence using several different configurations: the s2s baseline, using only the 1-best tree (SoE), and using the packed forest (SoE).",4.3 Qualitative analysis,[0],[0]
"This is a sentence from NIST MT 03, and the training corpus is the LDC corpus.
",4.3 Qualitative analysis,[0],[0]
"For the s2s case, no syntactic information is utilized, and therefore the output of the system is not a grammatical Chinese sentence.",4.3 Qualitative analysis,[0],[0]
The attributive phrase of “Czech border region” is a complete sentence.,4.3 Qualitative analysis,[0],[0]
"However, the attributive is not allowed to be a complete sentence in Chinese.
",4.3 Qualitative analysis,[0],[0]
"For the case of using 1-best constituent tree, the output is a grammatical Chinese sentence.",4.3 Qualitative analysis,[0],[0]
"However, the phrase “adjacent to neighboring Slovakia” is completely ignored in the translation result.",4.3 Qualitative analysis,[0],[0]
"After analyzing the constituent tree, we found that this phrase was incorrectly parsed as an “adverb phrase”, so that the NMT system paid little attention to it, because of the low confidence given by the parser.
",4.3 Qualitative analysis,[0],[0]
"In contrast, for the case of the packed forest, we can see this phrase was not ignored and was translated correctly.",4.3 Qualitative analysis,[0],[0]
"Actually, besides “adverb phrase”, this phrase was also correctly parsed as an “adjective phrase”, and covered by multiple different nodes in the forest, making it difficult for the encoder to ignore the phrase.
",4.3 Qualitative analysis,[0],[0]
We also noticed that our method performed better on learning attention.,4.3 Qualitative analysis,[0],[0]
"For the example in Figure 4, we observed that for s2s model, the decoder paid attention to the word “Czech” twice, which
causes the output sentence contains the Chinese translation of Czech twice.",4.3 Qualitative analysis,[0],[0]
"On the other hand, for our forest model, by using the syntax information, the decoder paid attention to the phrase “In the Czech Republic” only once, making the decoder generates the correct output.",4.3 Qualitative analysis,[0],[0]
Incorporating syntactic information into NMT systems is attracting widespread attention nowadays.,5 Related work,[0],[0]
"Compared with conventional string-to-string NMT systems, tree-based systems demonstrate a better performance with the help of constituent trees or dependency trees.
",5 Related work,[0],[0]
"The first noteworthy study is Eriguchi et al. (2016), which used Tree-structured LSTM (Tai et al., 2015) to encode the HPSG syntax tree of the sentence in the source-side in a bottom-up manner.",5 Related work,[0],[0]
"Then, Chen et al. (2017) enhanced the encoder with a top-down tree encoder.
",5 Related work,[0],[0]
"As a simple extension of Eriguchi et al. (2016), very recently, Zaremoodi and Haffari (2017) proposed a forest-based NMT method by representing the packed forest with a forest-structured neural network.",5 Related work,[0],[0]
"However, their method was evaluated in small-scale MT settings (each training dataset consists of under 10k parallel sentences).",5 Related work,[0],[0]
"In contrast, our proposed method is effective in a largescale MT setting, and we present qualitative analysis regarding the effectiveness of using forests in NMT.
",5 Related work,[0],[0]
"Although these methods obtained good results, the tree-structured network used by the encoder made the training and decoding relatively slow, therefore restricts the scope of application.
",5 Related work,[0],[0]
Other attempts at encoding syntactic trees have also been proposed.,5 Related work,[0],[0]
"Eriguchi et al. (2017) combined the Recurrent Neural Network Grammar (Dyer et al., 2016) with NMT systems, while Li et al. (2017) linearized the constituent tree and encoded it using RNNs.",5 Related work,[0],[0]
"The training of these methods is fast, because of the linear structures of RNNs.",5 Related work,[0],[0]
"However, all these syntax-based NMT systems used only the 1-best parsing tree, making the systems sensitive to parsing errors.
",5 Related work,[0],[0]
"Instead of using trees to represent syntactic information, some studies use other data structures to represent the latent syntax of the input sentence.",5 Related work,[0],[0]
"For example, Hashimoto and Tsuruoka (2017) proposed translating using a latent graph.",5 Related work,[0],[0]
"However, such systems do not enjoy the benefit of
handcrafted syntactic knowledge, because they do not use a parser trained from a large treebank with human annotations.
",5 Related work,[0],[0]
"Compared with these related studies, our framework utilizes a linearized packed forest, meaning the encoder can encode exponentially many trees in an efficient manner.",5 Related work,[0],[0]
The experimental results demonstrated these advantages.,5 Related work,[0],[0]
"We proposed a new NMT framework, which encodes a packed forest for the source sentence using linear-structured neural networks, such as RNN.",6 Conclusion and future work,[0],[0]
"Compared with conventional string-tostring NMT systems and tree-to-string NMT systems, our framework can utilize exponentially many linearized parsing trees during encoding, without significantly decreasing the efficiency.",6 Conclusion and future work,[0],[0]
This represents the first attempt at using a forest under the string-to-string NMT framework.,6 Conclusion and future work,[0],[0]
"The experimental results demonstrate the effectiveness of our framework.
",6 Conclusion and future work,[0],[0]
"As future work, we plan to design some more elaborate structures to incorporate the score layer in the encoder.",6 Conclusion and future work,[0],[0]
Further improvement in the translation performance is expected to be achieved for the forest-based NMT system.,6 Conclusion and future work,[0],[0]
We will also apply the proposed linearization method to other tasks.,6 Conclusion and future work,[0],[0]
We are grateful to the anonymous reviewers for their insightful comments and suggestions.,Acknowledgements,[0],[0]
We thank Lemao Liu from Tencent AI Lab for his suggestions about the experiments.,Acknowledgements,[0],[0]
We thank Atsushi Fujita whose suggestions greatly improve the readability and the logical soundness of this paper.,Acknowledgements,[0],[0]
This work was done during the internship of Chunpeng Ma at NICT.,Acknowledgements,[0],[0]
Akihiro Tamura is supported by JSPS KAKENHI Grant Number JP18K18110.,Acknowledgements,[0],[0]
Tiejun Zhao is supported by the National Natural Science Foundation of China (NSFC) via grant 91520204 and State High-Tech Development Plan of China (863 program) via grant 2015AA015405.,Acknowledgements,[0],[0]
"Tree-based neural machine translation (NMT) approaches, although achieved impressive performance, suffer from a major drawback: they only use the 1best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors.",abstractText,[0],[0]
"For statistical machine translation (SMT), forestbased methods have been proven to be effective for solving this problem, while for NMT this kind of approach has not been attempted.",abstractText,[0],[0]
"This paper proposes a forest-based NMT method that translates a linearized packed forest under a simple sequence-to-sequence framework (i.e., a forest-to-string NMT model).",abstractText,[0],[0]
"The BLEU score of the proposed method is higher than that of the string-to-string NMT, treebased NMT, and forest-based SMT systems.",abstractText,[0],[0]
Forest-Based Neural Machine Translation,title,[0],[0]
"Since its development by Breiman (2001), random forest has proven to be both accurate and efficient for classification and regression problems.",1. Introduction,[0],[0]
"In regression setting, random forest will predict the conditional mean of a response variable by averaging predictions of a large number of regression trees.",1. Introduction,[0],[0]
"Later then, many other machine learning algorithms were developed upon random forest.",1. Introduction,[0],[0]
"Among them, robust versions of random forest have also been proposed using various methodologies.",1. Introduction,[0],[0]
"Besides the sampling idea (Breiman, 2001) which adds extra randomness, the other variations are mainly based on two ideas: (1) use more robust criterion to construct regression trees (Galimberti et al., 2007; Brence & Brown, 2006; Roy & Larocque, 2012); (2) choose more robust aggregation method (Meinshausen, 2006; Roy & Larocque, 2012; Tsymbal et al., 2006).
",1. Introduction,[0],[0]
"Meinshausen (2006) generalized random forest to pre-
1University of California at San Diego, San Diego, California, USA 2Zillow, Seattle, Washington, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Alexander Hanbo Li <alexanderhanboli@gmail.com>.
Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"dict quantiles by discovering that besides calculating the weighted mean of the observed response variables, one could also get information for the weighted distribution of observed response variables using the sets of local weights generated by random forest.",1. Introduction,[0],[0]
"This method is strongly connected to the adaptive nearest neighbors procedure (Lin & Jeon, 2006) which we will briefly review in section 1.2.",1. Introduction,[0],[0]
"Different from classical k-NN methods that rely on predefined distance metrics, the dissimilarities generated by random forest are data dependent and scale-invariant.
",1. Introduction,[0],[0]
"Another state-of-the-art algorithm AdaBoost (Freund & Schapire, 1995; Freund et al., 1996) has been generalized to be applicable to a large family of loss functions (Friedman, 2001; Mason et al., 1999; Li & Bradic, 2016).",1. Introduction,[0],[0]
"Recent development of more flexible boosting algorithms such as xgboost (Chen & Guestrin, 2016) have become the go-to forest estimators with tabular or matrix data.",1. Introduction,[0],[0]
"One way in which recent boosting algorithms have an advantage over the random forest is the ability to customize the loss function used to reduce the influence of outliers or optimize a metric more suited to the specific problem other than the mean squared error.
",1. Introduction,[0],[0]
"In this paper, we will propose a general framework for forest-type regression which can also be applied to a broad family of loss functions.",1. Introduction,[0],[0]
"It is claimed in (Meinshausen, 2006) that quantile random forest is another nonparametric approach which does not minimize an empirical loss.",1. Introduction,[0],[0]
"However, we will show in fact both random forest and quantile random forest estimators can be re-derived as regression methods using the squared error or quantile loss respectively in our framework.",1. Introduction,[0],[0]
"Inspired by the adaptive nearest neighbor viewpoint, we explore how random forest makes predictions using the local weights generated by ensemble of trees, and connect that with locally weighted regression (Fan & Gijbels, 1996; Tibshirani & Hastie, 1987; Staniswalis, 1989; Newey, 1994; Loader, 2006; Hastie & Loader, 1993).",1. Introduction,[0],[0]
"The intuition is that when predicting the target value (e.g. E[Y |X = x]) at point x, the observations closer to x should receive larger weights.",1. Introduction,[0],[0]
"Different from predefining a kernel, random forest assigns the weights data dependently and adaptively.",1. Introduction,[0],[0]
"After we illustrate the relation between random forest and local regression, we will use random forest weights to design other regression algo-
rithms.",1. Introduction,[0],[0]
"By plugging robust loss functions like Huber loss and Tukey’s redescending loss, we get forest-type regression methods that are more robust to outliers.",1. Introduction,[0],[0]
"Finally, motivated from the truncated squared error loss example, we will show that decreasing the number of nearest neighbors in random forest will also immediately improve its generalization performance.
",1. Introduction,[0],[0]
The layout of this paper is as follows.,1. Introduction,[0],[0]
In Section 1.1 and 1.2 we review random forest and adaptive nearest neighbors.,1. Introduction,[1.0],['In Section 1.1 and 1.2 we review random forest and adaptive nearest neighbors.']
Section 2 introduces the general framework of forest-type regression.,1. Introduction,[1.0],['Section 2 introduces the general framework of forest-type regression.']
In Section 3 we plug in robust regression loss functions to get robust forest algorithms.,1. Introduction,[1.0],['In Section 3 we plug in robust regression loss functions to get robust forest algorithms.']
In Section 4 we motivate from the truncated squared error loss and investigate the importance of choosing right number of nearest neighbors.,1. Introduction,[0],[0]
"Finally, we test our robust forests in Section 5 and show that they are always superior to the traditional formulation in the presence of outliers in both synthetic and real data set.",1. Introduction,[1.0],"['Finally, we test our robust forests in Section 5 and show that they are always superior to the traditional formulation in the presence of outliers in both synthetic and real data set.']"
"Following the notation of Breiman (2001), let θ be the random parameter determining how a tree is grown, and data (X,Y ) ∈ X × Y .",1.1. Random forest,[1.0],"['Following the notation of Breiman (2001), let θ be the random parameter determining how a tree is grown, and data (X,Y ) ∈ X × Y .']"
"For each tree T (θ), let L be the total number of leaves, and Rl denotes the rectangular subspace in X corresponding to the l-th leaf.",1.1. Random forest,[0],[0]
"Then for every x ∈ X , there is exactly one leaf l",1.1. Random forest,[0],[0]
such that x ∈ Rl.,1.1. Random forest,[0],[0]
"Denote this leaf by l(x, θ).
",1.1. Random forest,[0],[0]
"For each tree T (θ), the prediction of a new data point X = x is the average of data values in leaf l(x, θ), that is, Ŷ (x, θ) = ∑n j=1 w(Xi, x, θ)Yi, where
w(Xi, x, θ) = 1I{Xi∈Rl(x,θ)}
#{j : Xj ∈ Rl(x,θ)} .",1.1. Random forest,[0.9999999847012971],"['For each tree T (θ), the prediction of a new data point X = x is the average of data values in leaf l(x, θ), that is, Ŷ (x, θ) = ∑n j=1 w(Xi, x, θ)Yi, where w(Xi, x, θ) = 1I{Xi∈Rl(x,θ)} #{j : Xj ∈ Rl(x,θ)} .']"
"(1)
Finally, the conditional mean E[Y |X = x] is approximated by the averaged prediction of m trees, Ŷ (x) = m−1 ∑m t=1",1.1. Random forest,[0],[0]
"Ŷ (x, θt).",1.1. Random forest,[0],[0]
"After rearranging the terms, we can write the prediction of random forest as
Ŷ (x) = n∑ i=1 w(Xi, x)Yi, (2)
where the averaged weight w(Xi, x) is defined as
w(Xi, x) = 1
m m∑ t=1 w(Xi, x, θt).",1.1. Random forest,[0],[0]
"(3)
From equation (2), the prediction of the conditional expectation E[Y |X = x] is the weighted average of the response values of all observations.",1.1. Random forest,[0],[0]
"Furthermore, it is easy to show that ∑n i=1 w(Xi, x) = 1.",1.1. Random forest,[0],[0]
Lin and Jeon (2006) studies the connection between random forest and adaptive nearest neighbor.,1.2. Adaptive nearest neighbors,[0],[0]
"They introduced the so-called potential nearest neighbors (PNN): A sample point xi is called a k-PNN to a target point x if there exists a monotone distance metric under which xi is among the k closest to x among all the sample points.
",1.2. Adaptive nearest neighbors,[0],[0]
"Therefore, any k-NN method can be viewed as choosing k points from the k-PNNs according to some monotone metric.",1.2. Adaptive nearest neighbors,[0],[0]
"For example, under Euclidean metric, the classical k-NN algorithm sorts the observations by their Euclidean distances to the target point and outputs the k closest ones.",1.2. Adaptive nearest neighbors,[0],[0]
"This is equivalent to weighting the k-PNNs using inverse L2 distance.
",1.2. Adaptive nearest neighbors,[0],[0]
"More interestingly, they prove that those observations with positive weights (3) all belong to the k-PNNs (Lin & Jeon, 2006).",1.2. Adaptive nearest neighbors,[0],[0]
"Therefore, random forests is another weighted kPNN method, but it assigns weights to the observations different from any k-NN method under a pre-defined monotonic distance metric.",1.2. Adaptive nearest neighbors,[0],[0]
"In fact, the random forest weights are adaptive to the data if the splitting scheme is adaptive.",1.2. Adaptive nearest neighbors,[0],[0]
"In this section, we generalize the classical random forest to a general forest-type regression (FTR) framework which is applicable to a broad family of loss functions.",2. General framework for forest-type regression,[0],[0]
"In Section 2.1, we motivate the framework by connecting random forest predictor with locally weighted regression.",2. General framework for forest-type regression,[0],[0]
"Then in Section 2.2, we formally propose the new forest-type regression framework.",2. General framework for forest-type regression,[0],[0]
"In Section 2.3, we rediscover the quantile random forest estimator by plugging the quantile loss function into our framework.",2. General framework for forest-type regression,[0],[0]
Classical random forest can be understood as an estimator of conditional mean E[Y |X].,2.1. Squared error and random forest,[1.0],['Classical random forest can be understood as an estimator of conditional mean E[Y |X].']
"As shown in (2), the estimator Ŷ (x) is weighted average of all response",2.1. Squared error and random forest,[0],[0]
Yi’s.,2.1. Squared error and random forest,[0],[0]
"This special form reminds us of the classical least squares regression, where the estimator is the sample mean.",2.1. Squared error and random forest,[0],[0]
"To be more precise, we rewrite (2) as
n∑ i=1 w(Xi, x)(Yi",2.1. Squared error and random forest,[0],[0]
− Ŷ (x)),2.1. Squared error and random forest,[0],[0]
"= 0. (4)
Equation (4) is the estimating equation (first order condition) of the locally weighted least squares regression (Ruppert & Wand, 1994):
Ŷ (x) = argmin λ∈R n∑ i=1 w(Xi, x)(Yi",2.1. Squared error and random forest,[0],[0]
"− λ)2 (5)
In classical local regression, the weight w(Xi, x) serves as a local metric between the target point x and observation Xi.",2.1. Squared error and random forest,[0],[0]
"Intuitively, observations closer to target x should be given more weights when predicting the response at x. One common choice of such local metric is kernel Kh(Xi, x) = K((Xi − x)/h).",2.1. Squared error and random forest,[0],[0]
"For example, the tricube kernel K(u) =",2.1. Squared error and random forest,[0],[0]
(1 − |u|3)3 1I(|u| ≤ 1) will ignore the impact of observations outside a window centered at x and increase the weight of an observation when it is getting closer to x.,2.1. Squared error and random forest,[0],[0]
"The form of kernel-type local regression is as follows:
argmin λ∈R n∑ i=1 Kh(Xi",2.1. Squared error and random forest,[0],[0]
− x)(Yi,2.1. Squared error and random forest,[0],[0]
"− λ)2,
The random forest weight w(Xi, x) (3) defines a similar data dependent metric, which is constructed using the ensemble of regression trees.",2.1. Squared error and random forest,[0],[0]
"Using an adaptive splitting scheme, each tree chooses the most informative predictors from those at its disposal.",2.1. Squared error and random forest,[0],[0]
"The averaging process then assigns positive weights to these training responses, which are called voting points in (Lin & Jeon, 2006).",2.1. Squared error and random forest,[0],[0]
"Hence via the random forest voting mechanism, those observations close to the target point get assigned positive weights equivalent to a kernel functionality (Friedman et al., 2001).",2.1. Squared error and random forest,[0],[0]
"Note that the formation (5) is just a special case when using squared error loss φ(a, b) = (a−b)2.",2.2. Extension to general loss,[0],[0]
"In more general form, we have the following local regression problem:
Ŷ (x) = argmin s∈F n∑ i=1 w(Xi, x)φ(s(Xi), Yi) (6)
where w(Xi, x) is a local weight, F is a family of functions, and φ(·) is a general loss.",2.2. Extension to general loss,[0.999999975139485],"['In more general form, we have the following local regression problem: Ŷ (x) = argmin s∈F n∑ i=1 w(Xi, x)φ(s(Xi), Yi) (6) where w(Xi, x) is a local weight, F is a family of functions, and φ(·) is a general loss.']"
"For example, when local weight is a kernel and F stands for polynomials of a certain degree, it reduces to local polynomial regression (Fan & Gijbels, 1996).",2.2. Extension to general loss,[0],[0]
"Random forest falls into this framework with squared error loss, a family of constant functions and local weights (3) constructed from ensemble of trees.
",2.2. Extension to general loss,[0],[0]
"Algorithm 1 Forest-type regression Step 1: Calculate local weights w(Xi, x) using ensemble or trees.",2.2. Extension to general loss,[1.0],"['Algorithm 1 Forest-type regression Step 1: Calculate local weights w(Xi, x) using ensemble or trees.']"
"Step 2: Choose a loss φ(·, ·) and a family F of function.",2.2. Extension to general loss,[0],[0]
"Then do the locally weighted regression
Ŷ (x) = argmin s∈F n∑ i=1 w(Xi, x)φ(Yi, s(Xi)).
",2.2. Extension to general loss,[0],[0]
"In Algorithm 1, we summarize the forest-type regression as a general two-step method.",2.2. Extension to general loss,[0],[0]
"Note that here we only focus on local weights generated by random forest, which
uses ensemble of trees to recursively partition the covariate space X .",2.2. Extension to general loss,[0],[0]
"However, there are many other data dependent dissimilarity measures that can potentially be used, such as k-NN, mp-dissimilarity (Aryal et al., 2014), shared nearest neighbors (Jarvis & Patrick, 1973), information-based similarity (Lin et al., 1998), mass-based dissimilarity (Ting et al., 2016), etc.",2.2. Extension to general loss,[0],[0]
And there are many other domain specific dissimilarity measures.,2.2. Extension to general loss,[0],[0]
"To avoid distraction, we will only use random forest weights throughout the rest of this paper.",2.2. Extension to general loss,[0],[0]
Meinshausen (2006) proposed the quantile random forest which can extract the information of different quantiles rather than just predicting the average.,2.3. Quantile loss and quantile random forest,[1.0],['Meinshausen (2006) proposed the quantile random forest which can extract the information of different quantiles rather than just predicting the average.']
"It has been shown that quantile random forest is more robust than the classical random forest (Meinshausen, 2006; Roy & Larocque, 2012).",2.3. Quantile loss and quantile random forest,[0],[0]
"In this section, we show quantile random forest estimator is also a special case of Algorithm 1.",2.3. Quantile loss and quantile random forest,[0],[0]
It is well known that the τ -th quantile of an (empirical) distribution is the constant that minimizes the (empirical) risk using τ - th quantile loss function,2.3. Quantile loss and quantile random forest,[0],[0]
"ρτ (z) = z(τ −1I{z<0}) (Koenker, 2005).",2.3. Quantile loss and quantile random forest,[0],[0]
"Now let the loss function in Algorithm 1 be the quantile loss ρτ (·), F be the family of constant functions, and w(Xi, x) be random forest weights (3).",2.3. Quantile loss and quantile random forest,[1.0],"['Now let the loss function in Algorithm 1 be the quantile loss ρτ (·), F be the family of constant functions, and w(Xi, x) be random forest weights (3).']"
"Solving the optimization problem
Ŷτ (x) = argmin λ∈R n∑ i=1 w(Xi, x)ρτ (Yi − λ),
we get the corresponding first order condition
n∑ i=1 w(Xi, x)(τ",2.3. Quantile loss and quantile random forest,[0],[0]
"− 1I {Yi − Ŷτ (x) < 0}) = 0.
Recall that ∑n i=1 w(Xi, x) = 1, hence, we have
n∑ i=1 w(Xi, x) 1I {Yi < Ŷτ",2.3. Quantile loss and quantile random forest,[0],[0]
"(x)} = τ. (7)
The estimator Ŷτ (x) in (7) is exactly the same estimator proposed in (Meinshausen, 2006).",2.3. Quantile loss and quantile random forest,[0],[0]
"In particular, when τ = 0.5, the equation ∑n i=1 w(Xi, x) 1I {Yi < Ŷ0.5(x)} = 0.5 will give us the median estimator Ŷ0.5(x).",2.3. Quantile loss and quantile random forest,[0],[0]
"Therefore, we have rediscovered quantile random forest from a totally different point of view as a local regression estimator with quantile loss function and random forest weights.",2.3. Quantile loss and quantile random forest,[1.0],"['Therefore, we have rediscovered quantile random forest from a totally different point of view as a local regression estimator with quantile loss function and random forest weights.']"
"From the framework 1, quantile random forest is insensitive to outliers because of the more robust loss function.",3. Robust forest,[0],[0]
"In this section, we test our framework on other robust losses and proposed fixed-point method to solve the estimating
equation.",3. Robust forest,[0],[0]
"In Section 3.1 we choose the famous robust loss – (pseudo) Huber loss, and in Section 3.2, we further investigate a non-convex loss – Tukey’s biweight.",3. Robust forest,[1.0],"['In Section 3.1 we choose the famous robust loss – (pseudo) Huber loss, and in Section 3.2, we further investigate a non-convex loss – Tukey’s biweight.']"
"The Huber loss (Huber et al., 1964)
Hδ(y) =
{ 1 2y
2 for |y| ≤ δ, δ(|y| − 12δ) elsewhere
is a well-known loss function used in robust regression.",3.1. Huber loss,[0],[0]
"The penalty acts like squared error loss when the error is within [−δ, δ] but becomes linear outside this range.",3.1. Huber loss,[1.0],"['The penalty acts like squared error loss when the error is within [−δ, δ] but becomes linear outside this range.']"
"In this way, it will penalize the outliers more lightly but still preserves more efficiency than absolute deviation when data is concentrated in the center and has light tails (e.g. Normal).",3.1. Huber loss,[1.0],"['In this way, it will penalize the outliers more lightly but still preserves more efficiency than absolute deviation when data is concentrated in the center and has light tails (e.g. Normal).']"
"By plugging Huber loss into the FTR framework 1, we get a robust counterpart of random forest.",3.1. Huber loss,[1.0],"['By plugging Huber loss into the FTR framework 1, we get a robust counterpart of random forest.']"
"The estimating equation is
n∑ i=1 wi(x) sign(Ŷ (x)− Yi) min(Ŷ",3.1. Huber loss,[0],[0]
"(x)− Yi, δ) = 0.",3.1. Huber loss,[0],[0]
"(8)
Direct optimization of (8) with local weights is hard, hence instead we will investigate the pseudo-Huber loss (see Figure 1),
Lδ(y) = δ 2 (√ 1 + (y δ )2 − 1 ) which is a smooth approximation of Huber loss (Charbonnier et al., 1997).",3.1. Huber loss,[0],[0]
"The estimating equation
n∑ i=1",3.1. Huber loss,[0],[0]
wpHi (x) ( ŶpH(x)− Yi ) = 0.,3.1. Huber loss,[0],[0]
"(9)
is very similar to that of square error loss if we define a new weight
wpHi (x) = wi(x)√
1 + ( ŶpH(x)−Yi
δ )2 .",3.1. Huber loss,[0.9999999233255116],['(9) is very similar to that of square error loss if we define a new weight wpHi (x) = wi(x)√ 1 + ( ŶpH(x)−Yi δ )2 .']
"(10) Then the (pseudo) Huber estimator can be expressed as
ŶpH(x) =
∑n i=1",3.1. Huber loss,[0],[0]
"w
pH i (x)Yi∑n
i=1",3.1. Huber loss,[0],[0]
w pH,3.1. Huber loss,[0],[0]
"i (x)
.",3.1. Huber loss,[0],[0]
"(11)
Informally, the estimator (11) can be viewed as a weighted average of all the responses Yi’s.",3.1. Huber loss,[0],[0]
"From (10), we know the new weight for pseudo-Huber loss has an extra scaling factor (√
1 + (δ−1u)2 )−1
(12)
and hence will shrink more to zero whenever δ−1|ŶpH(x)− Yi| is large.",3.1. Huber loss,[0],[0]
The tuning parameter δ acts like a control of the level of robustness.,3.1. Huber loss,[0],[0]
"A smaller δ will lead to more shrinkage on the weights of data that have responses far away from the estimator.
",3.1. Huber loss,[0],[0]
The estimating equation (9) can be solved by fix-point method which we propose in Algorithm 2.,3.1. Huber loss,[0],[0]
"For notation simplicity, we will use wi,j to denote w(Xi, xj), where Xi is the i-th training point and xj is the j-th testing point.",3.1. Huber loss,[0],[0]
"The convergence to the unique solution (if exists) is guaranteed by Lemma 1.
",3.1. Huber loss,[0],[0]
Lemma 1.,3.1. Huber loss,[0],[0]
"Define
Kδ(y) =
∑n i=1
wiYi√ 1+( y−Yiδ )
2∑n i=1
wi√ 1+( y−Yiδ ) 2 ,
Algorithm 2 pseudo-Huber loss (δ)
",3.1. Huber loss,[0],[0]
"Input: Test points {xj}mj=1, initial guess {Ŷ (0)(xj)}, local weights wi,j , training responses {Yi}ni=1, and error tolerance 0.",3.1. Huber loss,[0],[0]
"while > 0 do
(a) Update the weights
w (k) i,j = wi,j√ 1 + ( Ŷ (k−1)(xj)−Yi
δ )2 (b) Update the estimator
Ŷ (k)(xj) =
∑n i=1",3.1. Huber loss,[0.9920992263893266],"['Define Kδ(y) = ∑n i=1 wiYi√ 1+( y−Yiδ ) 2∑n i=1 wi√ 1+( y−Yiδ ) 2 , Algorithm 2 pseudo-Huber loss (δ) Input: Test points {xj}mj=1, initial guess {Ŷ (0)(xj)}, local weights wi,j , training responses {Yi}ni=1, and error tolerance 0. while > 0 do (a) Update the weights w (k) i,j = wi,j√ 1 + ( Ŷ (k−1)(xj)−Yi δ )2 (b) Update the estimator Ŷ (k)(xj) = ∑n i=1 w (k) i,j Yi∑n i=1 w (k) i,j (c) Calculate error = 1 m m∑ j=1 ( Ŷ k(xj)− Ŷ (k−1)(xj) )2 (d) k ← k + 1 end while Output the pseudo-Huber estimator: ŶpH(xj) = Ŷ (k)(xj) where ∑n i=1 wi = 1.']"
"w
(k) i,j Yi∑n
i=1",3.1. Huber loss,[0],[0]
w (k),3.1. Huber loss,[0],[0]
"i,j
(c) Calculate error
= 1
m",3.1. Huber loss,[0],[0]
m∑ j=1,3.1. Huber loss,[0],[0]
( Ŷ k(xj)− Ŷ (k−1)(xj) )2,3.1. Huber loss,[0],[0]
(d),3.1. Huber loss,[0],[0]
k,3.1. Huber loss,[0],[0]
"← k + 1
end while Output the pseudo-Huber estimator:
ŶpH(xj) =",3.1. Huber loss,[0],[0]
"Ŷ (k)(xj)
where",3.1. Huber loss,[0],[0]
∑n i=1 wi = 1.,3.1. Huber loss,[0],[0]
"Let K = maxi=1,··· ,n |Yi|.",3.1. Huber loss,[0],[0]
"Then Algorithm 2 can be written as Ŷ (k)(x) = Kδ(Ŷ (k−1)), and converges exponentially to a unique solution as long as δ > 2K.
From Lemma 1, we know it is important to standardize the responses Yi so that δ will be of the same scale for different problems.",3.1. Huber loss,[0],[0]
"In practice, we observe that one will not need to choose δ that satisfies the worst-case condition δ",3.1. Huber loss,[0],[0]
"> K in order for convergence, but making δ too small does lead to slow convergence rate.",3.1. Huber loss,[0],[0]
"For assigning the initial guess Ŷ (0), two simplest ways are to either take the random forest estimator we got or a constant vector equaling to the sample mean.",3.1. Huber loss,[0],[0]
"Throughout the rest of this paper, we will choose the weights to be random forest weights (3).",3.1. Huber loss,[0],[0]
"Non-convex function has played an important role in the context of robust regression (Huber, 2011; Hampel et al., 2011).",3.2. Tukey’s biweight,[0],[0]
"Unlike convex losses, the penalization on the errors can be bounded and hence the contribution of outliers in the estimating equation will eventually vanish.",3.2. Tukey’s biweight,[0],[0]
"Our forest regression framework 1 also incorporates the nonconvex losses which will show through the Tukey’s biweight function Tδ(·) (Huber, 2011), which is an example
of redescending loss whose derivative will vanish to zero as the input goes outside the interval",3.2. Tukey’s biweight,[0],[0]
"[−δ, δ].",3.2. Tukey’s biweight,[0],[0]
"It is defined in the following way:
d
dy Tδ(y) = y",3.2. Tukey’s biweight,[0],[0]
"( 1− y 2 δ2 )2 for |y| ≤ δ,
0 elsewhere.
",3.2. Tukey’s biweight,[0],[0]
"Similarly, by rearranging the estimating equation, we have
Ŷtukey(x) =
∑n i=1",3.2. Tukey’s biweight,[0],[0]
"w
tukey(Xi, x)Yi∑n i=1 w tukey(Xi, x)
where
wtukey(Xi, x) = w(Xi, x) max 1− ( Ŷtukey − Yi δ )2 , 0  with an extra scaling factor (see Figure 2)
",3.2. Tukey’s biweight,[0],[0]
"max { 1− (u δ )2 , 0 } .",3.2. Tukey’s biweight,[0],[0]
"(13)
In another word, the final estimator actually only depends on data with responses inside [−δ, δ], and the importance of any data (Xi, Yi) will be shrinking to zero when |Ŷtukey(x)− Yi| gets closer to the boundary value δ.",3.2. Tukey’s biweight,[0],[0]
"In this section, we will further use the framework 1 to investigate truncated squared error loss, and use this example to motivate the relation between random forest generalization performance and the number of adaptive nearest neighbors.",4. Truncated squared loss and nearest neighbors,[0],[0]
"For the truncated squared error loss
Sδ(y) =
{ 1 2y
2 for |y| ≤ δ, 1 2δ 2 elsewhere
the corresponding estimating equation is∑ |Ŷtrunc(x)−Yi|≤δ w(Xi, x)(Ŷtrunc(x)− Yi) = 0.
If we define a new weight
wtrunc(Xi, x) = w(Xi, x) 1I{|Ŷtrunc(x)− Yi| ≤ δ}, (14)
then the estimator for truncated squared loss is
Ŷtrunc(x) =
∑n i=1",4.1. Truncated squared error,[0],[0]
"w
trunc(Xi, x)Yi∑n i=1 w trunc(Xi, x) .",4.1. Truncated squared error,[0],[0]
"(15)
The estimator (15) is like a trimmed version of the random forest estimator (2).",4.1. Truncated squared error,[0],[0]
We first sort {Yi}ni=1 and trim off the responses where |Ŷtrunc(x),4.1. Truncated squared error,[0],[0]
− Yi| > δ.,4.1. Truncated squared error,[0],[0]
"Therefore, for any truncation level δ, the estimator Ŷtrunc(x) only depends on data satisfying |Ŷtrunc(x) − Yi| ≤ δ with the same local random forest weights (1).",4.1. Truncated squared error,[0],[0]
"In classical random forest, all the data with positive weights (3) are included when calculating the final estimator Ŷ (x).",4.2. Random Forest Nearest Neighbors,[1.0],"['In classical random forest, all the data with positive weights (3) are included when calculating the final estimator Ŷ (x).']"
"However, from section 4.1, we know in order to achieve robustness, some of the data should be dropped out of consideration.",4.2. Random Forest Nearest Neighbors,[0],[0]
"For example, using the truncated squared error loss, we will only consider the data satisfying |Yi − Ŷtrunc(x)| ≤ δ.",4.2. Random Forest Nearest Neighbors,[0],[0]
"In classical random forest, the criterion of tree split is to reduce the mean squared error, then in most cases, data points inside one terminal node will tend to have more similar responses.",4.2. Random Forest Nearest Neighbors,[0],[0]
"So informally larger |Ŷtrim(x)−Yi|will indicate smaller local weightw(Xi, x).",4.2. Random Forest Nearest Neighbors,[0],[0]
"Therefore, instead of solving for (15), we investigate a related estimator
Ŷwt(x) = ∑ w(Xi,x)≥ w(Xi, x)Yi∑ w(Xi,x)≥ w(Xi, x)
(16)
where > 0 is a constant in (0, 1).",4.2. Random Forest Nearest Neighbors,[0],[0]
"Recall that in (Lin & Jeon, 2006), they show all the observations with positive weights are considered voting points for random forest estimator.",4.2. Random Forest Nearest Neighbors,[0],[0]
"However, (16) implies that we should drop observations with weights smaller than a threshold in order for the robustness.",4.2. Random Forest Nearest Neighbors,[0],[0]
"More formally, let σ be a permutation such that w(Xσ(1), x) ≥ · · · ≥ w(Xσ(n0), x) > 0, then (2) is equivalent to
Ŷ (x) = n0∑ i=1",4.2. Random Forest Nearest Neighbors,[0],[0]
"w(Xσ(i), x)Yσ(i).
",4.2. Random Forest Nearest Neighbors,[0],[0]
"Then we can define the k random forest nearest neighbors (k-RFNN) of x to be {Xσ(1), · · · , Xσ(k)}, k ≤ n0, and get predictor
Ŷk(x) = k∑ i=1 w̃(Xσ(i), x)Yσ(i), (17)
where w̃(Xσ(i), x) = w(Xσ(i), x)/ ∑k j=1 w(Xσ(i), x).",4.2. Random Forest Nearest Neighbors,[0],[0]
"In the numerical experiments (Section 5.3), we will test the performance of the estimator (17) with different k, and show that by merely choosing the right number of nearest neighbors, one can largely improve the performance of classical random forest.
Shi and Horvath (2006) proposed a similar ensemble tree based nearest neighbor method.",4.2. Random Forest Nearest Neighbors,[0],[0]
"In their approach, if the observations Xi and Xj lie in the same leaf, then the similarity between them is increased by one.",4.2. Random Forest Nearest Neighbors,[0],[0]
"At the end, the similarities are normalized by dividing the total number of trees in the forest.",4.2. Random Forest Nearest Neighbors,[0],[0]
"Therefore, their weights (similarities) w(Xi, x) will be m−1 ∑m t=1 1I{Xi∈Rl(x,θ)} contrast to (3).",4.2. Random Forest Nearest Neighbors,[0],[0]
"So different from their approach, for random forest, the similarity between Xi and Xj will be increased by 1/#{p :",4.2. Random Forest Nearest Neighbors,[0],[0]
"Xp ∈ Rl(Xi,θ)} if they both lie in the same leaf l(Xi, θ).",4.2. Random Forest Nearest Neighbors,[0],[0]
This means the increment in the similarity also depends on the number of data points in the leaf.,4.2. Random Forest Nearest Neighbors,[0],[0]
"In this section, we plug in the quantile loss, Huber loss and Tukey’s biweight loss into the general forest framework and compare these algorithms with random forest.",5. Experiments,[1.0],"['In this section, we plug in the quantile loss, Huber loss and Tukey’s biweight loss into the general forest framework and compare these algorithms with random forest.']"
"Unless otherwise stated, for both Huber and Tukey forest, the error tolerance is set to be 10−6, and every forest is an ensemble of 1000 trees with maximum terminal node size 10.",5. Experiments,[0],[0]
"The robust parameter δ are set to be 0.005 and 0.8 for Huber and Tukey forest, respectively.",5. Experiments,[0],[0]
"We generate 1000 training data points from a Uniform distribution on [−5, 5] and another 1000 testing points from the same distribution.",5.1. One dimensional toy example,[0],[0]
"The true underlying model is Y = X2 + , ∼ N (0, 1).",5.1. One dimensional toy example,[0],[0]
"But on the training samples, we choose 20% of the data and add noise 2T2 to the responses, where T2 follows t-distribution with degree of freedom 2.
",5.1. One dimensional toy example,[0],[0]
"In Figure 3, we plot the true squared curve and different forest predictions.",5.1. One dimensional toy example,[0],[0]
"It is clear that Huber and Tukey forest achieve competitive robustness as quantile random forest, and can almost recover the true underlying distribution, but random forest is largely impacted by the outliers.",5.1. One dimensional toy example,[0],[0]
"We also repeat the experiments for 20 times, and report the average mean squared error (MSE), mean absolute deviation (MAD) and median absolute percentage error (MAPE) in Table 1.",5.1. One dimensional toy example,[1.0],"['We also repeat the experiments for 20 times, and report the average mean squared error (MSE), mean absolute deviation (MAD) and median absolute percentage error (MAPE) in Table 1.']"
"We generate data from 10 dimensional Normal distribution, i.e. X ∼ N10(~0,Σ).",5.2. Multivariate example,[0],[0]
"Then we test out algorithms on following models.
",5.2. Multivariate example,[0],[0]
"(1) Y = ∑10 i=1X 2 i + and ∼ N (0, 1), Σ = I.
(2) Y = ∑10 i=1X 2 i + and ∼ N (0, 1), Σ = Toeplitz(ρ = 0.7).
",5.2. Multivariate example,[0],[0]
"Then for each model, we randomly choose η proportion of the training samples and add noise 15T2 where T2 follows t-distribution with degree of freedom 2.",5.2. Multivariate example,[0],[0]
"The noise level η ∈ {0, 0.05, 0.1, 0.15, 0.2}.",5.2. Multivariate example,[0],[0]
The results are summarized in Table 2 and 3.,5.2. Multivariate example,[0],[0]
"On the clean data, random forest still play the best, however, Huber forest’s performance is also competitive and lose less efficiency than QRF and Tukey forest.",5.2. Multivariate example,[1.0],"['On the clean data, random forest still play the best, however, Huber forest’s performance is also competitive and lose less efficiency than QRF and Tukey forest.']"
"On the noisy data, all three robust methods outperform random forest.",5.2. Multivariate example,[1.0],"['On the noisy data, all three robust methods outperform random forest.']"
"Among them, Huber forest is most robust and stable.",5.2. Multivariate example,[0],[0]
"In this section, we check how the number of adaptive nearest neighbors k in (17) will have impact on the performance of k-RFNN.",5.3. Nearest neighbors,[0],[0]
"We consider the same two models (1) and (2), and keep both training sample size and testing sample size to be 1000.",5.3. Nearest neighbors,[1.0],"['We consider the same two models (1) and (2), and keep both training sample size and testing sample size to be 1000.']"
"The relations between MSE, MAD and the number of adaptive nearest neighbors are illustrated in Figure 4.",5.3. Nearest neighbors,[0],[0]
Recall that k-RFNN with all 1000 neighbors is equivalent to random forest.,5.3. Nearest neighbors,[0],[0]
"From the figures, we clearly observe a kink at k = 15, which is much less than 1000.",5.3. Nearest neighbors,[0],[0]
"We take two regression datasets from UCI machine learning repository (Lichman, 2013), and one real estate dataset from OpenIntro.",5.4. Real data,[0],[0]
"For each dataset, we randomly choose 2/3 observations for training and the rest for testing.",5.4. Real data,[0],[0]
MSE and MAD are reported by averaging over 20 trials.,5.4. Real data,[0],[0]
The results are presented in Table 4.,5.4. Real data,[0],[0]
"To further test the robustness, we then repeat the experiment but add extra T2 noise to 20%
of the standardized training data response variables everytime.",5.4. Real data,[0],[0]
The results are in Table 5.,5.4. Real data,[0],[0]
"Robust forests outperform random forest in most of the cases except for Ames data sets, on which quantile random forest behaves poorly.",5.4. Real data,[0],[0]
"The experimental results show that Huber forest, Tukey forest and quantile random forest are all much more robust than random forest in the presence of outliers.",6. Conclusion and discussion,[1.0],"['The experimental results show that Huber forest, Tukey forest and quantile random forest are all much more robust than random forest in the presence of outliers.']"
"However, without outliers, Huber forest preserves more efficiency than the other two robust methods.",6. Conclusion and discussion,[0],[0]
"We did not cross validate the parameter δ for different noise levels, so one would
expect even better performance after carefully tuning the parameter.
",6. Conclusion and discussion,[0],[0]
"Besides random forest weights, other data dependent similarities could also be used in Algorithm 1.",6. Conclusion and discussion,[1.0],"['Besides random forest weights, other data dependent similarities could also be used in Algorithm 1.']"
We could also design loss functions which optimizes a metric for specific problems.,6. Conclusion and discussion,[0],[0]
The fixed-point method could be replaced by other more efficient algorithms.,6. Conclusion and discussion,[0],[0]
The framework could be easily extended to classification problems.,6. Conclusion and discussion,[0],[0]
All these will be potential future work.,6. Conclusion and discussion,[0],[0]
Proof.,7.1. Proof of Lemma 1,[0],[0]
"Because Ŷ (k)(x) = Kδ(Ŷ (k−1)) which is a fixedpoint method, we only need to show ∣∣∣K ′δ(y)∣∣∣ < 1 in order for the existence and uniqueness of the solution.",7.1. Proof of Lemma 1,[0],[0]
"Define the normalized weight
w̃i = wi√
1 + ( y−Yi δ
)2 / n∑
i=1 wi√",7.1. Proof of Lemma 1,[0],[0]
"1 + ( y−Yi δ )2 , we have ∑n i=1 w̃i = 1, and
∣∣∣K ′δ(y)∣∣∣ ≤
∣∣∣∣∣∣ n∑ i=1",7.1. Proof of Lemma 1,[0],[0]
w̃iYi  n∑ j=1 (1I(i = j)− w̃j),7.1. Proof of Lemma 1,[0],[0]
y,7.1. Proof of Lemma 1,[0],[0]
− Yj δ2 +,7.1. Proof of Lemma 1,[0],[0]
(y − Yj)2,7.1. Proof of Lemma 1,[0],[0]
"∣∣∣∣∣∣ ≤ 2
n∑ i=1",7.1. Proof of Lemma 1,[0],[0]
"w̃i |Yi| max i=1,··· ,n ( |y",7.1. Proof of Lemma 1,[0],[0]
− Yi| δ2 +,7.1. Proof of Lemma 1,[0],[0]
(,7.1. Proof of Lemma 1,[0],[0]
"y − Yi)2 )
",7.1. Proof of Lemma 1,[0],[0]
= 2 n∑ i=1,7.1. Proof of Lemma 1,[0],[0]
"w̃i |Yi| 1 mini=1,··· ,n (",7.1. Proof of Lemma 1,[0],[0]
"δ2 |y−Yi| + |y − Yi| )
≤ max i=1,··· ,n
|Yi| 1
δ .
",7.1. Proof of Lemma 1,[0],[0]
"Therefore, ∣∣∣K ′δ(y)∣∣∣ < 12 if δ > 2 maxi=1,··· ,n |Yi| = 2K.",7.1. Proof of Lemma 1,[0],[0]
"We would like to thank Stan Humphrys and Zillow for supporting this research, as well as three anonymous referees for their insightful comments.",Acknowledgements,[0],[0]
Part of the implementation in this paper is based on Zillow code library.,Acknowledgements,[0],[0]
This paper introduces a new general framework for forest-type regression which allows the development of robust forest regressors by selecting from a large family of robust loss functions.,abstractText,[0],[0]
"In particular, when plugged in the squared error and quantile losses, it will recover the classical random forest (Breiman, 2001) and quantile random forest (Meinshausen, 2006).",abstractText,[0],[0]
We then use robust loss functions to develop more robust foresttype regression algorithms.,abstractText,[0],[0]
"In the experiments, we show by simulation and real data that our robust forests are indeed much more insensitive to outliers, and choosing the right number of nearest neighbors can quickly improve the generalization performance of random forest.",abstractText,[0],[0]
Forest-type Regression with General Losses  and Robust Forest,title,[0],[0]

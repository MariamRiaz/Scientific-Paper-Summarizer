2	64	For complex emerging events, in particular, user comments can provide relevant, interesting and insightful information beyond the facts reported in the news.
4	71	In this work, we present a socially-informed timeline generation system that jointly generates a news article summary and a user comment summary for each day of an ongoing complex event.
5	109	A sample (gold standard) timeline snippet for Ukraine Crisis is shown in Figure 1.
7	21	1055 While generating timelines from news articles and summarizing user comments have been studied as separate problems (Yan et al., 2011; Ma et al., 2012), their joint summarization for timeline generation raises new challenges.
20	42	Automatic evaluation using ROUGE (Lin and Hovy, 2003) and gold standard timelines indicates that our system can effectively leverage user comments to outperform state-of-the-art approaches on timeline generation.
22	33	Especially, our optimization framework relies on two scoring functions that estimate the importance of including individual article sentences and user comments in the timeline.
24	26	Experiments show that our joint learning model outperforms state-of-the-art ranking algorithms and other joint learning based methods when evaluated on sentence ranking and comment ranking.
25	33	For example, we achieve an NDCG@3 of 0.88 on the Ukraine crisis dataset, compared to 0.77 from Yang et al. (2011) which also conducts joint learning between articles and social context using factor graphs.
39	17	We also collect all articles with comments from NYT in 2013 (henceforth NYT2013) to form a training set for learning importance scoring functions on articles sentences and comments (see Section 3).
41	18	We first introduce a joint learning method that uses graph-based regularization to simultaneously learn two functions — a SENTENCE scorer and a COMMENT scorer — that predict the importance of including an individual news article sentence or a particular user comment in the timeline.
42	23	We train the model on the aforementioned NYT2013 dataset, where 20% of the articles and their comments are reserved for parameter tuning.
69	18	Thus, the objective function to minimize is: Jc(wc) = ||X̃cwc − Ỹc||22 + λc · ||X̃′cwc − Ỹ′c||22 + βc · ||wc||22 (2) Graph-Based Regularization.
70	25	The regularizing constraint is based on two mutually reinforcing hypotheses: (1) the importance of a sentence depends partially on the availability of sufficient insightful comments that touch on topics in the sentence; (2) the importance of a comment depends partially on whether it addresses notable events reported in the sentences.
71	92	For example, we want our model to bias ws to predict a high score for a sentence with high similarity to numerous insightful comments.
73	31	Let R̃ be an N ×M adjacency matrix, where N and M are the numbers of sentences and comments.
76	48	The interplay between the two types of data is encoded in the following regularizing constraint: Js,c(ws,wc) = λsc · ∑ di ∑ xs∈xsdi ,xc∈xcdi Qxs,xc · (xs ·ws − xc ·wc)2 (3) Full Objective Function.
77	26	Thus, the full objective function consists of the three parts discussed above: J(ws,wc) = Js(ws) + Jc(wc) + Js,c(ws,wc) (4) Furthermore, using the following notation, X̃ = [ X̃s 0 0 X̃c ] Ỹ = [ Ỹs Ỹc ] X̃′ = [ X̃′s 0 0 X̃′c ] Ỹ′ = [ Ỹ′s Ỹ′c ] β̃ = [ βsIk 0 0 βcIl ] λ̃ = [ λsI|X′s| 0 0 λcI|X′c| ] L̃ = [ λscI|Xs| −λscQ̃ −λscQ̃T λscI|Xc| ] w = [ ws wc ] we can show a closed form solution to Equation 4 as follows: ŵ = (X̃TL̃X̃ + X̃TX̃ + X̃′Tλ̃X̃′ + β̃)−1(X̃TỸ + X̃′Tλ̃Ỹ′) (5)
79	22	Formally, for each day, our system takes as input a set of sentences Vs and a set of comments Vc to be summarized, and the (automatically generated) timeline T (represented as threads) for days prior to the current day.
80	20	It then identifies a subset S ⊆ Vs as the article summary and a subset C ⊆ Vc as the comment summary by maximizing the following function: Z(S,C; T ) = Squal(S; T )+Cqual(C)+δX (S,C) (6) where Squal(S; T ) measures the quality of the article summary S in the context of the historical timeline represented as event threads T ; Cqual(C) computes the quality of the comment summary C; and X (S,C) estimates the connectivity between S and C. We solve this maximization problem using an alternating optimization algorithm which is outlined in Section 4.4.
81	39	In general, we alternately search for a better article summary S with hill climbing search and a better comment summary C with FordFulkerson algorithm until convergence.
82	23	In the rest of this section, we first describe an entity-centered event threading algorithm to construct event threads T which are used to boost article timeline continuity.
83	23	Then we explain how to compute Squal(S; T ) and Cqual(C) in Section 4.2, followed by X (S,C) in Section 4.3.
100	24	Recall that we learned two separate importance scoring functions for sentences and comments, which will be denoted here as imps(s) and impc(c).
102	34	Squal(S; T ) captures three desired qualities of an article summary: importance (first item), coverage (second item), and the continuity of the current summary to previously generated summaries.
130	64	Input : sentences Vs, comments Vc, threads T , δ, threshold , functions Z(S,C; T ), Squal(S; T ), Cqual(C), X (S,C) Output: article summary S, comment summary C /* Initialize S and C by greedy algorithm and Ford-Fulkerson algorithm */ S0 ←maxS Squal(S; T ); C0 ← maxC Cqual(C) + δX (S0, C); t← 1; ∆Z ←∞; while ∆Z > do /* Step 1: Hill climbing algorithm */ St ← maxS Squal(S; T ) + δX (S,Ct−1); /* Step 2: Ford-Fulkerson algorithm */ Ct ← maxC Cqual(C) + δX (St, C); ∆Z = Z(St, Ct; T )−Z(St−1, Ct−1; T ); t← t+ 1; end Algorithm 1: Generate article summary and comment summary for a given day via alternating optimization .
137	37	Gao et al. (2012) summarize by including the complementary information between articles and tweets, which is estimated by an unsupervised topic model.3 We also consider two state-of-the-art rankers: RankBoost (Freund et al., 2003) and LambdaMART (Burges, 2010).
147	20	(3) We construct a timeline from the human ABSTRACTs provided with each article: we sort them chronologically according to article timestamps and add abstract sentences into each daily summary until reaching the word limit.
159	24	Turkers are presented with a timeline consisting of five consecutive days’ article summaries and four variations of the accompanying comment summary: RANDOMly selected comments, USER’S-PICKS (ranked by positive user ratings), randomly selected EDITOR’S-PICKS and timelines produced by the THREAD+OPTWordVec version of OUR SYSTEM.
189	22	Answer Type Avg ± STD Rated 5 (%) Rated 4 (%) No Thread 2.58 ± 1.20 7% 23% With Threads 3.29 ± 1.28 17% 26% Table 6: Human evaluation on the informativeness of answers written after reading timelines with threads vs. with no thread.
205	29	We presented a socially-informed timeline generation system, which constructs timelines consisting of article summaries and comment summaries.

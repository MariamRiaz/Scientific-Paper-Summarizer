0	68	Text simplification (TS) addresses the translation of an input sentence into one or more simpler sentences.
1	48	It is a useful preprocessing step for several NLP tasks, such as machine translation (Chandrasekar et al., 1996; Mishra et al., 2014) and relation extraction (Niklaus et al., 2016), and has also been shown useful in the development of reading aids, e.g., for people with dyslexia (Rello et al., 2013) or non-native speakers (Siddharthan, 2002).
6	22	This paper focuses on the evaluation of the structural aspects of the task.
7	61	We introduce the semantic measure SAMSA (Simplification Automatic evaluation Measure through Semantic Annotation), the first structure-aware measure for TS in general, and the first to use semantic structure in this context in particular.
9	25	SAMSA focuses on the core semantic components of the sentence, and is tolerant towards the deletion of other units.2 For example, SAMSA will assign a high score to the output split “John got home.
11	17	Splits that alter predicate-argument relations such as “John got home and gave.
14	17	First, it provides means to measure the extent to which the meaning of the source is preserved in the output.
15	23	Second, it provides means for measuring whether the input sentence was split to semantic units of 685 the right granularity.
19	47	UCCA has been shown to be preserved remarkably well across translations (Sulem et al., 2015) and has also been successfully used for machine translation evaluation (Birch et al., 2016) (Section 2).
27	20	Section 2 presents previous work.
91	24	I read that book.” as a simplification of “I read the book that John wrote.”.
92	17	Each output sentence contains one Scene, which has the same Scene elements as the source, and would thus be deemed correct by SAMSA.
101	44	UCCA decomposes each sentence s into a set of Scenes {sc1, sc2, .., scn}, where each scene sci contains a main relation mri (sub-span of sci) and a set of zero or more participants Ai.
109	19	We say that a leaf l in a Scene sc is consistent in a Scenesentence mapping M which maps sc to a sentence s, if there is a word w ∈ s which l aligns to (according to the word alignment A).
118	14	If a Participant (or a Center inside a Participant) is a Scene, its center is the main relation (Process or State) of the Scene.
122	22	Given the input sentence Scenes {sc1, ..., scninp}, the output sentences {s1, ..., snout}, and a mapping between them M∗, SAMSA is defined as: nout ninp 1 2ninp ∑ sci [ 1M∗(sci)(MRi) + 1 ki ki∑ j=1 where MRi is the minimal center of the main relation (Process or State) of sci, and Par (j) i (j = 1, .
128	17	For example, in the Scene “traveling is fun”, the people who are traveling correspond to an implicit Participant.
130	24	For testing the automatic metric, we first build a human evaluation benchmark, using 100 sentences from the complex part of the PWKP corpus and the outputs of six recent simplification systems for these sentences:5 (1) TSM (Zhu et al., 2010) using Tree-Based SMT, (2) RevILP (Woodsend and Lapata, 2011) using Quasi-Synchronous Grammars, (3) PBMT-R (Wubben et al., 2012) using PhraseBased SMT, (4) Hybrid (Narayan and Gardent, 2014), a supervised system using DRS, (5) UNSUP (Narayan and Gardent, 2016), an unsupervised system using DRS, and (6) Split-Deletion (Narayan and Gardent, 2016), the unsupervised system with only structural operations.
135	16	Five in-house annotators with high proficiency in English evaluated the resulting 700 input-output pairs by answering the questions in Table 1.6 Qa addresses grammaticality, Qb and Qc capture two complementary aspects of meaning preservation (the addition and the removal of information) and Qd addresses structural simplicity.
148	18	We further compute an average human score: AvgHuman = 1 3 (G + P + S)
154	19	Experiments are conducted in two settings: (1) a semi-automatic setting where UCCA annotation was carried out manually by a single expert UCCA annotator using the UCCAApp annotation software (Abend et al., 2017), and according to the standard annotation guidelines;8 (2) an automatic setting where the UCCA annotation was carried out by the TUPA parser (Hershcovich et al., 2017).
160	21	A Spearman ρ correlation between the human and SAMSA scores (comparing their rankings) is presented in Table 4.
167	33	The highest correlation with structural simplicity is obtained by the number of sentences with splitting, where SAMSA (automatic and semi-automatic) is second and third highest, although when restricted to multiScene sentences, the correlation for SAMSA (semi-automatic) is higher (0.89, p = 0.009 and 0.77, p = 0.04).
191	14	We use the same implementations of SAMSA.
198	14	Most QATS systems, including OSVCML and OSVCML2 (Nisioi and Nauze, 2016) which scored highest on the shared task, use an ensemble of classifiers based on bag-of-words, POS tags, sentiment information, negation, readability measures and other resources.
203	15	Third, the QATS shared task does not focus on structural simplification, but experiments on different types of systems.
206	29	These promising results also motivate a future combination of SAMSA with classifier-based metrics.
207	38	We presented the first structure-aware metric for text simplification, SAMSA, and the first evaluation experiments that directly target the structural simplification component, separately from the lexical component.
209	19	We empirically demonstrate that strong measures that assess lexical simplification quality (notably SARI), fail to correlate with human judgments when structural simplification is performed by the evaluated systems.
210	22	Our experiments show that SAMSA correlates well with human judgments in such settings, which demonstrates its usefulness for evaluating and tuning statistical simplification systems, and shows that structural evaluation provides a complementary perspective on simplification quality.

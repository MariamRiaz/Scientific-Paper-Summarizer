0	60	Language identification (LID) is an essential first step for NLP on multilingual text.
1	165	In global settings like Twitter, this text is written by authors from diverse linguistic backgrounds, who may communicate with regional dialects (Gonçalves and Sánchez, 2014) or even include parallel translations in the same message to address different audiences (Ling et al., 2013, 2016).
2	127	Such dialectal variation is frequent in all languages and even macro-dialects such as American and British English are composed of local dialects that vary across city and socioeconomic development level (Labov, 1964; Orton et al., 1998).
4	56	As a result, these systems systematically misclassify texts from populations with millions of speakers whose local speech differs from the majority dialects (Hovy and Spruit, 2016; Blodgett et al., 2016).
5	73	Multiple systems have been proposed for broadcoverage LID at the global level (McCandless, 2010; Lui and Baldwin, 2012; Brown, 2014; Jaech et al., 2016).
6	28	However, only a handful of techniques have addressed the challenge of linguistic variability of global data, such as the dialectal variability and multilingual text seen in Figure 1.
7	13	These techniques have typically focused only on limited aspects of variability, e.g., individual dialects like African American Vernacular English (Blodgett et al., 2016), online speech (Nguyen and Doğruöz, 2013), similar languages (Bergsma et al., 2012; Zampieri et al., 2014a), or word-level code switching (Solorio et al., 2014; Rijhwani et al., 2017).
8	34	In this work, our goal is to devise a socially equitable LID, that will enable a massively multilingual, broad-coverage identification of populations speaking underrepresented dialects, multilingual messages, and other linguistic varieties.
10	11	Then, we introduce an LID system, EQUILID, that produces pertoken language assignments and obtains state-ofthe-art performance on four LID tasks (§3), outperforming broad-coverage LID benchmarks by 51 up to 300%.
12	12	Despite known linguistic variation in languages, current broad-coverage LID systems are trained primarily on European-centric sources (e.g., Lui and Baldwin, 2014), often due to data availability.
17	16	Geographic Diversity We create a large-scale dataset of geographically-diverse text by bootstrapping with a people-centric approach (Bamman, 2015) that treats location and languagesspoken as demographic attributes to be inferred for authors.
19	30	Individuals’ locations are inferred using the method of Compton et al. (2014) as implemented by Jurgens et al. (2015).
20	22	The method first identifies the individuals who have reliable ground truth locations from geotagged tweets and then infers the locations of other individuals as the geographic center of their friends’ locations, iteratively applying this inference method to the whole social network.
23	23	To identify monolingual users, we classify multiple tweets by the same individual and consider an author monolingual if they had at least 20 tweets and 95% were labeled with one language `.
25	47	We use this relabeling process to automatically identify misclassified tweets, which when aggregated geographically, can potentially capture regional dialects and topics.1 We construct separate sets of monolinguals using langid.py and CLD2 as classifiers to mitigate the biases of each.
26	23	Social and Topical Diversity Authors modulate their writing style for different social registers (Eisenstein, 2015; Tatman, 2015).
29	9	We also include single-language corpora drawn from slang websites (e.g., Urban Dictionary) and the African American Vernacular English data from Blodgett et al. (2016).
44	34	The encoder and the decoder are 3-layer recurrent neural networks with 512 gated recurrent units (Chung et al., 2014).
45	24	The model is trained to tokenize character sequence input based on white space and output a sequence with each token’s language, with extra token types for punctuation, hashtags, and user mentions.
59	10	Their architecture uses a convolutional network to transform each input word into a vector using its characters and then feed the word vectors to an LSTM encoder that decodes to per-word soft-max distributions over languages.
71	15	Despite being trained for general-purpose, EQUILID also outperformed the benchmark-optimized models of Jaech et al. (2016).
72	22	In the multilingual setting, EQUILID substantially outperforms both Polyglot and CLD2, with over a 300% increase in Macro-F1 over the former.
73	14	Further, because our model can also identify the spans in each language, we view its performance as an important step towards an all-languages solution for detecting sentence and phrase-level switching between languages.
79	11	This is unsurprising, considering that even for a human annotator this task is challenging (or impossible).
99	11	In contrast, EQUILID outperforms both systems at all levels of HDI and provides 30% more observations for countries with the lowest development levels.
103	56	Globally-spoken languages often vary in how they are spoken according to regional dialects, topics, or sociolinguistic factors.
105	65	In this work, we introduce a sociallyequitable LID system, EQUILID, built by (1) creating a dataset representative of the types of diversity within languages and (2) explicitly modeling multilingual and codes-switched communication for arbitrary language pairs.
106	18	We demonstrate that EQUILID significantly outperforms current broad-coverage LID systems and, in a realworld case study on tracking health-related content, show that EQUILID substantially reduces the LID performance disparity between developing and developed countries.
107	162	Our work continues a recent emphasis on NLP for social good by ensuring NLP tools fully represent all people.
108	35	The EQUILID system is publicly available at https: //github.com/davidjurgens/equilid and data is available upon request.

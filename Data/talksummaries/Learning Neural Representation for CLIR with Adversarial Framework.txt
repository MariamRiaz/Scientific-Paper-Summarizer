0	37	Text representation is a crucial problem in most natural language processing (NLP) and information retrieval (IR) tasks.
2	4	In order to bridge the lexical gaps, latent semantic models such as latent semantic analysis (LSA) (Deerwester et al., 1990) have been proposed to abstract away from surface text forms to approximate semantics.
3	9	More recently, text representation learned with neural networks is attracting increasing attention of the IR community (Mitra and Craswell, 2017) and positive results have been reported on various evaluation data sets (Fan et al., 2018).
4	48	Compared to the prosperity in monolingual IR, there have been less advancements in CLIR where documents are written in a language different from that of queries.
5	15	In addition to document ranking, CLIR models need to cross the language barriers, which makes the task intuitively more difficult than monolingual IR.
8	7	However, MT based approaches are far from being a suitable solution for solving CLIR problems (refer to detailed analysis in (Zhou et al., 2012)).
26	7	Comprehensive CLIR experiments reveal that our model is superior to state-of-the-art continuous space models and approaches the machine translation and monolingual baselines.
59	20	We will develop three constraints, namely a matching constraint, a translation constraint and an adversarial constraint, to direct the learning of cross-language and target-specific text embeddings.
60	51	For ease of presentation, let us assume in CLIR we have a source language query qs and a target language document dt.
61	22	The translation of qs in the target language is qt.
63	7	There have been various approaches one can use to encode sentences/documents into dense vectors.
64	35	For instance, models based on convolutional neural networks (Kalchbrenner et al., 2014) and models based on recurrent neural networks (Liu et al., 2016) have been popular choices.
65	37	In order to map queries and documents into the embedding space, we make use of recurrent neural network with the long short-term memory (LSTM) architecture that can deal with vanishing and exploring gradient problems (Hochreiter and Schmidhuber, 1997).
75	45	NNdim is designed to adapt the output dimension and to allow further flexibility for representation learning.
79	16	The translation constraint is developed to minimize the differences between a pair of parallel texts, which serves as a basic requirement in the translation scenario.
82	24	In this paper, we directly employ Google translator to translate queries, which is a popular choice for machine translation that leads to state-of-the-art translation performance.
89	8	Similar to neural models in monolingual settings (Huang et al., 2013), the cross-language pairwise matching constraint is placed on top of the embedding vectors of source language query and target language documents.
96	7	The crosslanguage matching loss Lmatc on cross-language triplet set QDc can be defined with cross-entropy loss as: Lmatc = ∑ (qs,dt+,dt−)∈QDc CE[P (qs), P̂ (qs)] where CE denotes the cross-entropy operator between two distributions and P (qs) is the actual counterpart of P̂ (qs) estimated from annotation with a strategy similar to that in (Dehghani et al., 2017).
103	11	The cross-language matching constraint explicitly captures cross-language ranking signals from cross-language text pairs.
109	9	G generates samples from a source of noisew that satisfies w ∼ Pn(w) and tries to capture the real data distribution Pr.
111	12	The training procedure for G is to try its best to fool D. Let us assume that G generates samples satisfying the distribution Pg that is implicitly decided by G(w).
119	15	We can adjust equation 1 to our settings and obtain the adversarial loss Ladv on a query set Qt and a document set Dt in the target language, as well as a query set Qs in the source language, which can be written as: Ladv = min G max D ∑ x∈Qt,Dt,Qs logNNadv(zx) ◦ lzx where ◦ is the inner product operator.
120	36	Following the training convention of GAN (Goodfellow et al., 2014), the process of learning the language-invariant and task-specific text representation for CLIR should be conducted by jointly minimizing the generator constraint LG and the adversarial loss Ladv, which leads us to the combined objective function L as: L = LG + Ladv According to the rule of playing the minmax game in GAN, G tries its best to maximize the probability that D makes a mistake and D tries its best to distinguish between real data and generated data (in our case, various input sources).
123	8	Optimize G when fixing D through: θ̂G = argminθG L(θG, θ̂D) The optimization can be implemented with mini-batch gradient ascent (for θD) and descent (for θG).
125	18	To perform CLIR experiments, we rely on broadly used data sets released in the bilingual tasks of the cross-language evaluation forum (CLEF) 2.
126	26	We choose to use the data from the year 2000 to 2004.
127	32	Table 1 lists the characteristics of the data set, which include number of documents (Nd), number of distinct words (Nw), the average document length (DLavg) and the number of queries (Nq) in each task.
128	28	We use source language queries in French (Fr), German (De) and Italian (It) to retrieve target language documents in English (En).
129	7	Queries from year 2000 to 2002 are combined to a single task in table 1 since they have the same target set.
130	21	In order to train the representation learning model, we need to construct a data set consisting of annotated text pairs.

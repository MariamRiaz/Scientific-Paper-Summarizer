3	77	Within community Question Answering (cQA) forums, two subtasks are of special relevance when a user poses a new question to the website (Hoogeveen et al., 2018; Lai et al., 2018): (i) finding similar questions (question-question relatedness), and (ii) finding relevant answers to the new question, if they already exist (answer selection).
6	15	It can also be relevant for the forum owners as it can help detect redundancy, eliminate question duplicates, and improve the overall forum structure.
7	85	Subtask (ii) on the other hand is useful for a user who just wants a quick answer to a specific question, without the need of digging through the long answer threads and winnowing good from bad comments or without having to post a question and then wait for an answer.
8	20	Obviously, the two subtasks are interrelated as the information needed to answer a new question is usually found in the threads of highly related questions.
11	20	A new question q is posed for which several potentially related questions are identified in the forum (e.g., by using an information retrieval system); qi in the example is one of these existing questions.
14	30	This is the setting of SemEval-2016 Task 3, and we use its benchmark datasets.
55	17	As argued before, subtask C depends on the other two subtasks.
56	28	Intuitively, if cim is a good comment with respect to the existing question qi, and qi is related to the new question q (subtask A), then cim is likely to be a relevant answer to q.
59	21	Moreover, we cast each cQA subtask as a structured prediction problem in order to model the dependencies between output variables of the same type.
63	15	First, we use a DNN, specifically, a feed-forward NN, to learn task-specific embeddings for the three subtasks, i.e., output embeddings xai,m, x b i and x c i,m for subtasks A, B and C (Figure 2a).
68	19	The input is a tuple (q, qi, c i m) consisting of a new question q, a retrieved question qi, and a comment cim from qi’s answer thread.
77	20	To determine whether a comment cim is good with respect to the thread question qi, we model the interactions between cim and qi by merging their embeddings zcim and zqi , and passing them through a hidden layer: ha1 = f(U a[zqi , zcim ]) (2) where Ua is the weight matrix from the inputs to the first hidden units, f is a non-linear activation function.
78	16	The activations are then fed to a final subtask-specific hidden layer, which combines these signals with the pairwise similarity features φa(qi, c i m).
87	37	Again, we model the direct interactions between q and cim using pairwise features φc(q, cim) and a hidden layer transformation hc1 = f(U c[zq, zcim ]), where U c is a weight matrix.
97	32	As shown in Figure 2b, the graph contains six subgraphs: Ga=(Va, Eaa), Gb=(Vb, Ebb) and Gc=(Vc, Ecc) are associated with the three subtasks, while the bipartite subgraphs Gac=(Va ∪ Vc, Eac), Gbc=(Vb ∪ Vc, Ebc) and Gab=(Va ∪ Vb, Eab) connect nodes across tasks.
98	20	We associate each node u ∈ Vt with an input vector xu, representing the embedding for subtask t, and an output variable yu, representing the class label for subtask t. Similarly, each edge (u, v) ∈ Est is associated with an input feature vector µ(xu,xv), derived from the node-level features, and an output variable yuv ∈ {1, 2, · · · , L}, representing the state transitions for the pair of nodes.1 For notational simplicity, here we do not distinguish between comment and question nodes, rather we use u and v as general indices.
100	18	We use log-linear factors: ψn(yu|x,wtn) = exp(σ(yu,x)Twtn) (6) ψe(yuv|x,wste ) = exp(σ(yuv,x)Twste ) (7) where σ(·) is a feature vector derived from the inputs and the labels.
135	28	Consistently with our notation from Section 3, it features three subtasks: subtask A (i.e., whether a comment cim is a good answer to the question qi in the thread), subtask B (i.e., whether the retrieved question qi is related to the new question q), and subtask C (i.e., whether the comment cim is a relevant answer for the new question q).
145	23	Table 2 shows the results for our individual DNN models (rows in boldface) for subtasks A, B and C on the TEST set.
151	23	Looking at the results for subtask C, we can see that sizeable gains are possible when using gold labels for subtasks A and B as features to DNNC , e.g., adding gold A labels yields +6.90 MAP points.
165	14	Interestingly, we observe the same pattern as with the gold labels: the A-C and B-C connections help individually and in combination, with A-C being more helpful.
169	15	This evinces the problems with the conditional independence assumption and the local normalization in the model.
188	16	We have presented a framework for multitask learning of two community Question Answering problems: question-question relatedness and answer selection.
189	36	We further used a third, auxiliary one, i.e., finding the good comments in a question-comment thread.
190	47	We proposed a twostep framework based on deep neural networks and structured conditional models, with a feedforward neural network to learn task-specific embeddings, which are then used in a pairwise CRF as part of a multitask model for all three subtasks.
192	38	On the other hand, the CRF is able to perform global inference over arbitrary graph structures accounting for the dependencies between subtasks to provide globally good solutions.
195	38	In future work, we plan to model text complexity (Mihaylova et al., 2016), veracity (Mihaylova et al., 2018), speech act (Joty and Hoque, 2016), user profile (Mihaylov et al., 2015), trollness (Mihaylov et al., 2018), and goodness polarity (Balchev et al., 2016; Mihaylov et al., 2017).
196	59	From a modeling perspective, we want to strongly couple CRF and DNN, so that the global errors are backpropagated from the CRF down to the DNN layers.
197	26	It would be also interesting to extend the framework to a cross-domain (Shah et al., 2018) or a cross-language setting (Da San Martino et al., 2017; Joty et al., 2017).
198	39	Trying an ensemble of neural networks with different initial seeds is another possible research direction.

{"sections": [{"text": "Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1018\u20131023, Denver, Colorado, May 31 \u2013 June 5, 2015. c\u00a92015 Association for Computational Linguistics"}, {"heading": "1 Introduction", "text": "Machine translation tuning seeks to find feature weights that maximize translation quality. Recent efforts have focused on methods that scale to large numbers of features (Cherry and Foster, 2012), and among these, PRO has gained popularity (Pairwise Ranking Optimization, Hopkins and May (2011)).\nPRO\u2019s goal is to find feature weights such that the resulting k-best list entries are ranked in the same way that an evaluation function (e.g., BLEU, Papineni et al. (2002)) ranks them. To do this, it labels pairs of translations for each sentence as positive or negative, depending on the gold ranking of the two pair elements given by BLEU. A binary classifier is trained on these labeled examples, resulting in new feature weights, and the procedure is iterated. This\n\u2217Markus Dreyer is now at Amazon, Inc., Seattle, WA.\nprocedure would ordinarily be too expensive since there areO(k2) pairs per sentence, where both k and the number of sentences can be in the thousands, so billions of training examples would be produced per iteration. Therefore, Hopkins and May (2011) use subsampling to consider a small percentage of all pairs per sentence.\nWe present APRO (All-Pairs Ranking Optimization), a tuning approach that, like PRO, uses pairwise ranking for tuning. Unlike PRO, it is not limited to optimizing a small percentage of pairs per sentence. Based on an efficient ranking SVM formulation (Airola et al. (2011), Lee and Lin (2014)), we find, in each iteration, feature weights that minimize ranking errors for all pairs of translations per sentence. This tuning method inherits all the advantages of PRO\u2014it is scalable, effective, easy to implement\u2014and removes its limitations. It does not require meta-tuning of sampling parameters since no sampling is used; it does not need to be run multiple times to obtain reliable results, like MERT (Och, 2003), PRO, MIRA (Chiang et al., 2008) and others, since it uses global optimization and is deterministic given initial feature weights; and it converges quickly."}, {"heading": "2 Notation and Definitions", "text": "For both PRO and APRO, we use the following definitions: A tuning dataset contains S source sentences x1, . . . , xS . Let Ys be the space of all translations of xs. It contains one or more known reference translations ys+. Each translation y s i \u2208 Ys has a fea-\n1018\nture representation1 f(xs, ysi ), or for short, f s i , and a linear classification score hsi = w T f si , where w is a feature weight vector. Given a source sentence xs, a translation decoder can search (often a subset of) Ys and return the k translations ys1, . . . , ysk with the highest classification scores. A k-best list is the list of ys1, . . . , y s k,\u2200s. For each translation ysi we can obtain an evaluation score b(ysi ,y s +), or for short, bsi , which can be the BLEU+1 score (Lin and Och, 2004).2 For a given source sentence xs, let (i, j) denote a pair of translations (ysi , y s j )."}, {"heading": "3 PRO", "text": "We now describe PRO, before constrasting it with our new approach, APRO. For each iteration t from t = 1 . . . T , PRO performs the following steps:\n1. Given current feature weights wt, obtain a kbest list, as defined above, from the translation decoder. For each xs, add to its k-best entries the kbest entries from previous iterations, so that xs now has ks translations; the overall list is called an accumulated k-best list.\n2. For each source sentence xs, first sample up to \u0393 candidate pairs from its translations in the kbest list. Less similar pairs are more likely to become candidate pairs. Similarity in a pair (i, j) here means a small absolute difference dsij between b s i and bsj . The most similar pairs (d s ij < \u03b2) are discarded. Then select the \u039e least similar pairs among the remaining candidate pairs.\n3. For each pair (i, j) from the \u039e selected pairs, add the difference vector (f si\u2212f sj) with class label 1 if bsi > b s j , otherwise add it with class label \u22121. Also add (f sj\u2212f si ) with the opposite label. 4. Train any classifier on the labeled data, resulting in a new weights vector w\u2032. Set wt+1 = \u03a8\u00b7w\u2032+(1\u2212\u03a8)\u00b7wt.\nDependencies between tuning iterations are introduced by the use of accumulated k-best lists and the interpolation of weight vectors in step 4, using an interpolation factor \u03a8. Translation quality varies with different choices for \u0393, \u039e, \u03b2, \u03a8, see Figure 1. The quality varies even when PRO is run multiple times with the same parameters, due to the sampling\n1For simplicity, we leave out nuisance variables like alignments, segmentations, or parse trees, from this description, which may be part of the feature space.\n2But see Nakov et al. (2013) for variants.\nstep. Practitioners would have to perform an expensive grid search multiple times to be sure to obtain good results. APRO seeks to remedy this problem. One could try to improve PRO by experimenting with other pair selection heuristics; APRO circumvents the problem by efficiently selecting all pairs."}, {"heading": "4 APRO", "text": "Our method APRO is, like PRO, a ranking method. We believe that learning to rank is a suitable method for MT tuning because it matches the test-time requirements of correctly predicting the best translations or correctly ranked k-best lists of translations.\nCompared to PRO, we simplify the procedure by removing sampling and labeling steps 2 and 3, thereby removing some of PRO\u2019s implementation complexity and manually set parameters. We run only two steps, corresponding to PRO\u2019s steps 1 and 4: In each tuning iteration, we obtain an accumulated k-best list, then directly find a new w\u2032 that minimizes the loss on that k-best list, which corresponds to PRO\u2019s running of a classifier. APRO\u2019s classification model is an efficient ranking SVM (Airola et al. (2011), Lee and Lin (2014)), described as follows."}, {"heading": "4.1 Model", "text": "For each sentence xs, we define the set of preference pairs as the set of ordered translation pairs for which the evaluation score prefers the first element:\nPs = {(i, j) : bsi > bsj} (1) 4PRO settings: \u0393 = {5k, 8k} = {small, large}, \u039e =\n{50, 100} = {light, dark}, \u03b2 = {.03, .05} = {no dot, dot}.\nFollowing Lee and Lin (2014), we define the loss (or, error) of any sentence s as the sum of its pairwise squared hinge losses:\nLsw = \u2211\n(i,j)\u2208Ps max(0, 1\u2212hsi +hsj)2 (2)\nThat is, no loss is contributed by preference pairs for which the classification score correctly prefers the first element by a large-enough margin, i.e., hsi \u2265 hsj +1; all other preference pairs contribute some loss. We seek to find a weight vector that minimizes the regularized overall loss:\nw\u2032 = argmin w Rw+ C \u00b7 1 N \u2211 s Lsw (3)\nwhere Rw = 12w Tw is a Gaussian regularizer to prevent overfitting and C a constant controlling the relative regularization amount. We divide by N = \u2211 s ks to account for the increasing sizes of accumulated k-best lists between tuning iterations, which leads to increased sentence losses. If this were not done, the relative amount of regularization would decrease in subsequent iterations of tuning.\nAny gradient-based optimization method can be used to find w\u2032. Since the loss is convex, the weights we find given a particular k-best list are optimal. This is different from PRO and Bazrafshan et al. (2012), where the resulting weights depend on the pairs sampled; MIRA, where they depend on the order of sentences processed; and MERT, where optimization is greedy and depends on initial weights."}, {"heading": "4.2 Efficient Computation", "text": "How do we efficiently compute Lsw per sentence? In this and the following subsection, we leave out all sentence indices s for ease of notation; it is understood that we operate on a given sentence.\nA straightforward algorithm to compute Lw would iterate over all preference pairs (i, j) \u2208 P and add up their losses (Joachims, 2002). However, since there are O(k2) pairs per sentence, with potentially thousands of sentences, this would be extremely inefficient. PRO\u2019s solution to this problem is subsampling. The alternative solution we apply is to make the sums over translation pairs efficient by carefully rearranging the terms of the sentence loss,\nmaking use of quantities that can be precomputed efficiently (Airola et al. (2011), Lee and Lin (2014)).\nDefinitions. Let us define those quantities. For a given sentence s, let the set Q contain all members of P that contribute a positive loss to the overall loss term:\nQ = {(i, j) : (i, j) \u2208 P \u2227 (1\u2212hi+hj > 0)} (4)\nWe also define an index notation into Q:\nQi\u2022 = {(i, j) \u2208 Q,\u2200j} qi\u2022 = |Qi\u2022| (5) Q\u2022j = {(i, j) \u2208 Q, \u2200i} q\u2022j = |Q\u2022j | (6) ri\u2022 =\n\u2211 (i,j)\u2208Qi\u2022 hj (7)\nThe bullet (\u2022) can be read as any. Example: Q\u20223 contains pairs \u2208 Q whose second element is translation 3. qi\u2022 and q\u2022j denote corresponding set sizes.\nRearrangement. We use these definitions to express the loss as a sum over only O(k) elements.\nFirst, we simplify the loss expression by summing only over elements from Q, i.e., pairs from P that contribute a positive loss, so the max becomes unnecessary:\nLw = \u2211\n(i,j)\u2208P max(0, 1\u2212hi+hj)2 (8)\n= \u2211\n(i,j)\u2208Q (1\u2212hi+hj)2 (9)\n= \u2211\n(i,j)\u2208Q h2i\u22122hi+1+h2j +2hj\u22122hihj (10)\nWe then use the precomputed quantities defined above to rewrite the sum over O(k2) pairs to a sum over just O(k) elements:\nLw = k\u2211\ni=1\nqi\u2022(h2i\u22122hi+1)+q\u2022i(h2i +2hi)\n\u22122 ri\u2022 hi (11)\nThis step is described in detail below. Our new formulation is simpler but equivalent to Lee and Lin\n(2014). Using order statistics trees (Cormen et al., 2001), the quantities qi\u2022, q\u2022i, and ri\u2022 can be precomputed in O(k log k) time (see details in Lee and Lin (2014)). This precomputation, together with the rearranged loss, allows APRO to make efficient weight updates without having to subsample.\nDetailed derivation. We explain how to derive Equation 11 from Equation 10. First, let us define the following equalities:\u2211\n(1,j)\u2208Q h1 = q1\u2022 \u00b7h1\u2211 (2,j)\u2208Q h2 = q2\u2022 \u00b7h2\n. . . If we do not fix the first pair element to a particu-\nlar value, we have:\u2211 (i,j)\u2208Q hi = \u2211 i qi\u2022 \u00b7hi (12)\nSimilarly: \u2211 (j,1)\u2208Q\nh1 = q\u20221 \u00b7h1\u2211 (j,2)\u2208Q h2 = q\u20222 \u00b7h2\n. . . If we do not fix the second element of each pair to\na particular value, we have:\u2211 (j,i)\u2208Q hi = \u2211 i q\u2022i \u00b7hi (13)\nWe split Equation 10 into separate sums and perform a change of variables in the second sum:\nLw = \u2211\n(i,j)\u2208Q h2i\u22122hi+1+ \u2211 (j,i)\u2208Q h2i +2hi\n\u22122 \u2211\n(i,j)\u2208Q hihj\n(14)\nWe introduce one more equality, where (16) follows from the definition of ri\u2022 in Equation 7:\n\u2211 (i,j)\u2208Q hihj = \u2211 i hi  \u2211 (i,j)\u2208Qi\u2022 hj  (15)\nLang. Train Dev Test Ara-Eng 14.4M 66K 37K Chi-Eng 142.9M 61K 29K Eng-Swe 100.1M 21K 22K Eng-Fra 100.0M 63K 20K Ita-Eng 102.8M 21K 20K Pol-Eng 90.5M 21K 19K\nTable 1: Number of words in the used data sets.\n=\n\u2211\ni\nhi ri\u2022 (16)\nWe now use equalities 12, 13, and 16 to arrive at Equation 11:\nLw = \u2211\ni\nqi\u2022(h2i\u22122hi+1)+ \u2211\ni\nq\u2022i(h2i +2hi)\n\u22122 \u2211\ni\nri\u2022 hi\n= \u2211\ni\nqi\u2022(h2i\u22122hi+1)+q\u2022i(h2i +2hi)\n\u22122ri\u2022 hi"}, {"heading": "5 Experiments", "text": ""}, {"heading": "5.1 Experimental Setup", "text": "We validate APRO on 6 diverse language pairs. For each one, we perform HMM-based word alignment (Vogel et al., 1996) and phrase rule extraction on the training data. We use 20 standard features, incl. 8 reordering features, plus the sparse features listed for PBTM systems in Hopkins and May (2011).5\nFor Ara-Eng and Chi-Eng, we use BOLT Y2 data sets.6 For all other languages, we sample train, dev, and test sets from in-house data. Table 1 describes the different data set sizes. We use 5-gram LMs trained on the target side of the training data; for Ara-Eng and Chi-Eng, we add 2 LMs trained on English Gigaword and other sources.\nWe tune on dev data. In each tuning run, we use k = 500, except for Ara-Eng (k = 1500). We use the same weight initialization for every tuning run, where most features are initialized to 0 and some dense features are initialized to 1 or -1. During tuning, we use case-insensitive BLEU+1. We tune for\n5We use the 500 most frequent words for word pair features. 6For ara-eng, a subset of the training data was chosen whose\nsource side has maximum similarity to the test source side.\nup to 30 iterations,7 where we reset the accumulated k-best list after 10 iterations.8 For PRO, we use \u0393=5000, \u039e=50, \u03b2=0.05, \u03a8=0.1, and (MegaM) regularization strength \u03bb=1 as described in Hopkins and May (2011). For APRO, we use regularization strength C=0.01 and \u03a8=1, which effectively removes the weight interpolation step. We repeat each PRO tuning twice and report the mean of length ratios and case-sensitive BLEU scores on test data. For APRO, no repeated runs are necessary; it gives the same result on any run given initial feature weights.\nFor APRO, we optimize using the implementation by Lee and Lin, which uses a truncated Newton method.9"}, {"heading": "5.2 Results", "text": "We measure the runtime of PRO and APRO. For an accumulated k-best list containing s=2,748 sentences with an average ks=3,600 translation, PRO and APRO take 13 and 8 minutes, respectively. Table 2 shows translation quality after 10 iterations and at convergence. We observe that APRO converges quickly: After running for 10 iterations, it gives higher BLEU scores and better length ratios than PRO for five out of six language pairs. At convergence, PRO has caught up, but for all language\n7Like Hopkins and May (2011), we stop earlier when the accumulated k-best list does not change anymore.\n8This removes bad translations from early iterations and provides good initial weights for the last 20 iterations. This did not decrease but sometimes increase final performance.\n9See http://goo.gl/CVmnoZ. No change to the software is necessary; but in each iteration it must be called with C\u2032 = C\nN , see Equation 3. We have also experimented with a\nchange to the software that scales the loss of each sentence by the number of translation pairs for that sentence; this did not give reliable BLEU improvements over Equation 3.\npairs APRO performs similar or better. One of APRO\u2019s advantages are stable results: Figure 1 compares PRO and APRO for 3 values of \u03a8: For each value, we run PRO eight times with different sampling settings and APRO once. We observe that the different PRO settings result in different BLEU scores. Cherry and Foster (2012) report that they could not find one PRO setting that worked across all language pairs. This suggests that practitioners may have to run expensive grid searches to find optimal PRO performance; this is not necessary with APRO. While PRO performs best with \u03a8 = 0.1, APRO gets good results for \u03a8=1, which is the reason for its fast convergence (Table 2)."}, {"heading": "6 Conclusions", "text": "We have presented APRO, a new tuning method for machine translation. Like PRO, APRO is a batch pairwise ranking method, and as such, it inherits PRO\u2019s advantages of being effective, scalable to large feature sets and easy to fit into the standard batch MT tuning framework. We remove PRO\u2019s sampling step and learn a pairwise ranking over the whole k-best list inO(k log k) time. We have shown that PRO\u2019s different sampling settings result in different final results; by removing these settings we get more reliable results. We find that PRO\u2019s weight interpolation is not necessary for APRO, resulting in faster convergence. At convergence, APRO\u2019s translation quality was found to be similar or better than PRO\u2019s. APRO\u2019s use of global optimization and the lack of randomness lead to more stable tuning with deterministic results."}, {"heading": "Acknowledgments", "text": "We thank Jonathan May, Mark Hopkins, Bill Byrne, Adria Gispert, Gonzalo Iglesias, Steve DeNeefe and the anonymous reviewers for their valuable comments and suggestions."}], "year": 2015, "references": [{"title": "Training linear ranking SVMs in linearithmic time using red-black trees", "authors": ["Antti Airola", "Tapio Pahikkala", "Tapio Salakoski."], "venue": "Pattern Recognition Letters, 32(9):1328\u20131336.", "year": 2011}, {"title": "Tuning as linear regression", "authors": ["Marzieh Bazrafshan", "Tagyoung Chung", "Daniel Gildea."], "venue": "Pro1022", "year": 2012}, {"title": "Batch tuning strategies for statistical machine translation", "authors": ["Colin Cherry", "George Foster."], "venue": "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 427\u2013", "year": 2012}, {"title": "Online large-margin training of syntactic and structural translation features", "authors": ["David Chiang", "Yuval Marton", "Philip Resnik."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 224\u2013233. Association for Compu-", "year": 2008}, {"title": "Tuning as ranking", "authors": ["Mark Hopkins", "Jonathan May."], "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1352\u20131362. Association for Computational Linguistics.", "year": 2011}, {"title": "Optimizing search engines using clickthrough data", "authors": ["Thorsten Joachims."], "venue": "Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 133\u2013142. ACM.", "year": 2002}, {"title": "Large-scale linear RankSVM", "authors": ["Ching-Pei Lee", "Chih-Jen Lin."], "venue": "Neural computation, 26(4):781\u2013817.", "year": 2014}, {"title": "ORANGE: a method for evaluating automatic evaluation metrics for machine translation", "authors": ["Chin-Yew Lin", "Franz Josef Och."], "venue": "Proceedings of Coling 2004, pages 501\u2013507, Geneva, Switzerland, Aug 23\u2013Aug", "year": 2004}, {"title": "A tale about PRO and monsters", "authors": ["Preslav Nakov", "Francisco Guzm\u00e1n", "Stephan Vogel."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 12\u201317, Sofia, Bulgaria, August. Association for", "year": 2013}, {"title": "Minimum error rate training in statistical machine translation", "authors": ["Franz Josef Och."], "venue": "Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 160\u2013167. Association for Computational Linguistics.", "year": 2003}, {"title": "BLEU: a method for automatic evaluation of machine translation", "authors": ["K. Papineni", "S. Roukos", "T. Ward", "W. J Zhu."], "venue": "Proceedings of the 40th annual meeting on association for computational linguistics, pages 311\u2013318.", "year": 2002}, {"title": "HMM-based word alignment in statistical translation", "authors": ["Stephan Vogel", "Hermann Ney", "Christoph Tillmann."], "venue": "Proceedings of the 16th conference on Computational linguistics-Volume 2, pages 836\u2013841. Association for Computational Linguistics.", "year": 1996}], "id": "SP:474c057eed18cb79601700e9d5e60b510e5cd5e0", "authors": [{"name": "Markus Dreyer", "affiliations": []}, {"name": "Yuanzhe Dong", "affiliations": []}], "abstractText": "We present APRO, a new method for machine translation tuning that can handle large feature sets. As opposed to other popular methods (e.g., MERT, MIRA, PRO), which involve randomness and require multiple runs to obtain a reliable result, APRO gives the same result on any run, given initial feature weights. APRO follows the pairwise ranking approach of PRO (Hopkins and May, 2011), but instead of ranking a small sampled subset of pairs from the kbest list, APRO efficiently ranks all pairs. By obviating the need for manually determined sampling settings, we obtain more reliable results. APRO converges more quickly than PRO and gives similar or better translation results.", "title": "APRO: All-Pairs Ranking Optimization for MT Tuning"}